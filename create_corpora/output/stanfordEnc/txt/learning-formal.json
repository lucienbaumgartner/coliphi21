[{"date.published":"2002-02-02","date.changed":"2017-02-17","url":"https://plato.stanford.edu/entries/learning-formal/","author1":"Oliver Schulte","author1.info":"http://www.cs.sfu.ca/~oschulte/","entry":"learning-formal","body.text":"\n\n\nFormal learning theory is the mathematical embodiment of a normative\nepistemology. It deals with the question of how an agent should use\nobservations about her environment to arrive at correct and\ninformative conclusions. Philosophers such as Putnam, Glymour and\nKelly have developed learning theory as a normative framework for\nscientific reasoning and inductive inference. \n\n\nTerminology. Cognitive science and related fields typically\nuse the term “learning” for the process of gaining\ninformation through observation— hence the name “learning\ntheory”. To most cognitive scientists, the term “learning\ntheory” suggests the empirical study of human and animal\nlearning stemming from the behaviourist paradigm in psychology. The\nepithet “formal” distinguishes the subject of this entry\nfrom behaviourist learning theory. Philosophical terms for\nlearning-theoretic epistemology include “logical\nreliability” (Kelly [1996], Glymour [1991]) and\n“means-ends epistemology” (Schulte [1999]).\n\n\nBecause many developments in, and applications of, formal learning\ntheory come from computer science, the term “computational\nlearning theory” is also common. Many results on learning theory\nin computer science are concerned with Valiant’s and Vapnik’s notion\nof learning generalizations that are probably approximately correct\n(PAC learning) (Valiant [1984]). This notion of empirical success was\nintroduced to philosophers by Gilbert Harmann in his Nicode lectures,\nand elaborated in a subsequent book [2007]. Valiant himself provides\nan accessible account of PAC learning and its relationship to the\nproblem of induction in a recent book (Valiant [2013, Ch. 5]). The\npresent article describes a nonstatistical tradition of learning\ntheory stemming from the seminal work of Hilary Putnam [1963] and Mark\nE. Gold [1967]. \n\n\nPhilosophical characteristics. In contrast to other\nphilosophical approaches to inductive inference, learning theory does\nnot aim to describe a universal inductive method or explicate general\naxioms of inductive rationality. Rather, learning theory pursues a\ncontext-dependent means-ends analysis: For a given empirical problem\nand a set of cognitive goals, what is the best method for achieving\nthe goals? Most of learning theory examines  which investigative\nstrategies reliably and efficiently lead to correct beliefs about the\nworld. \n\n\nArticle Overview. Compared to traditional philosphical\ndiscussions of inductive inference, learning theory provides a\nradically new way of thinking about induction and scientific method.\nThe main aim of this article is explain the main concepts of the\ntheory through examples. Running examples are repeated throughout the\nentry; at the same time, the sections are meant to be as independent\nof each other as possible. We use the examples to illustrate some\ntheorems of philosophical interest, and to highlight the key\nphilosophical ideas and insights behind learning theory. \n\n\nReaders interested in the mathematical substance of learning theory\nwill find some references in the\n Bibliography,\n and a summary of the basic definitions in the\n Supplementary Document.\n A text by Jain et al. collects many of the main definitions and\ntheorems [1999]. New results appear in proceedings of annual\nconferences, such as the Conferences on Learning Theory (COLT) and\nAlgorithmic Learning Theory (ALT). The philosophical issues and\nmotivation pertaining to learning-theoretic epistemology are discussed\nextensively in the works of philosophers such as Putnam, Glymour and\nKelly (Putnam [1963], Glymour [1991], Glymour and Kelly [1992], Kelly\n[1996]). \n\nLearning-theoretic analysis assesses dispositions for forming beliefs.\nSeveral terms for belief acquisition processes are in common use in\nphilosophy; I will use “inductive strategy”,\n“inference method” and most frequently “inductive\nmethod” to mean the same thing. The best way to understand how\nlearning theory evaluates inductive methods is to work through some\nexamples. The following presentation begins with some very simple\ninductive problems and moves on to more complicated and more realistic\nsettings. \nLet’s revisit the classic question of whether all ravens are black.\nImagine an ornithologist who tackles this problem by examining one\nraven after another. There is exactly one observation sequence in\nwhich only black ravens are found; all others feature at least one\nnonblack raven. The figure below illustrates the possible observation\nsequences. Dots in the figure denote points at which an observation\nmay be made. A black bird to the left of a dot indicates that at this\nstage, a black raven is observed. Similarly, a white bird to the right\nof a dot indicates that a nonblack raven is observed. Given a \ncomplete sequence  of observations, either all observed ravens are\nblack or nonblack; the figure labels complete observation sequences\nwith the statement that is true of them. The gray fan indicates that\nafter the observation of a white raven, the claim that not all ravens\nare black holds on all observation sequences resulting from further\nobservations. \nIf the world is such that only black ravens are found, we would like\nthe ornithologist to settle on this generalization. (It may be\npossible that some nonblack ravens remain forever hidden from sight,\nbut even then the generalization “all ravens are black” at\nleast gets the observations right.) If the world is such that\neventually a nonblack raven is found, then we would like the\nornithologist to arrive at the conclusion that not all ravens are\nblack. This specifies a set of goals of inquiry. For any given\ninductive method that might represent the ornithologist’s disposition\nto adopt conjectures in the light of the evidence, we can ask whether\nthat method measures up to these goals or not. There are infinitely\nmany possible methods to consider; we’ll look at just two, a skeptical\none and one that boldly generalizes. The  bold method \nconjectures that all ravens are black after seeing that the first\nraven is black. It hangs on to this conjecture unless some nonblack\nraven appears. The skeptical method does not go beyond what is\nentailed by the evidence. So if a nonblack raven is found, the\nskeptical method concludes that not all ravens are black, but\notherwise the method does not make a conjecture one way or another.\nThe figure below illustrates both the bold and the skeptical\nmethod. \n \nDo these methods attain the goals we set out? Consider the bold\nmethod. There are two possibilities: either all observed ravens are\nblack, or some nonblack raven is found. In the first case, the method\nconjectures that all ravens are black and never abandons this\nconjecture. In the second case, the method concludes that not all\nravens are black as soon as the first nonblack raven is found. Hence\nno matter how the evidence comes in, eventually the method\ngives the right answer as to whether all ravens are black and\nsticks with this answer. Learning theorists call such methods\nreliable because they settle on the right answer no matter\nwhat observations the world provides. \nThe skeptical method does not measure up so well. If a nonblack raven\nappears, then the method does arrive at the correct conclusion that\nnot all ravens are black. But if all ravens are black, the skeptic\nnever takes an “inductive leap” to adopt this\ngeneralization. So in that case, the skeptic fails to provide the\nright answer to the question of whether all ravens are black. \nThis illustrates how means-ends analysis can evaluate methods: the\nbold method meets the goal of reliably arriving at the right answer,\nwhereas the skeptical method does not. Note the character of this\nargument against the skeptic: The problem, in this view, is not that\nthe skeptic violates some canon of rationality, or fails to appreciate\nthe “uniformity of nature”. The learning-theoretic\nanalysis concedes to the skeptic that no matter how many black ravens\nhave been observed in the past, the next one could be white. The issue\nis that if all observed ravens are indeed black, then the skeptic\nnever answers the question “are all ravens\nblack?”. Getting the right answer to that question requires\ngeneralizing from the evidence even though the generalization\ncould be wrong. \nAs for the bold method, it’s important to be clear on what it does and\ndoes not achieve. The method will eventually settle on the right\nanswer—but it (or we) may never be certain that it has\ndone so. As\n William James\n put it, “no bell tolls” when science has found the right\nanswer. We are certain that the method will eventually settle on the\nright answer; but we may never be certain that the current answer is\nthe right one. This is a subtle point; the next example illustrates it\nfurther. \nNelson Goodman posed a famous puzzle about inductive inference known\nas the (New) Riddle of Induction ([Goodman 1983]). Our next example is\ninspired by his puzzle. Goodman considered generalizations about\nemeralds, involving the familiar colours of green and blue, as well as\ncertain unusual ones: \nNow let us introduce another predicate less familiar than\n“green”. It is the predicate “grue” and it\napplies to all things examined before t just in case they are\ngreen but to other things just in case they are blue. Then at time\nt we have, for each evidence statement asserting that a given\nemerald is green, a parallel evidence statement asserting that emerald\nis grue. The question is whether we should conjecture that all\nemeralds are green rather than that all emeralds are grue when we\nobtain a sample of green emeralds examined before time t, and\nif so, why. \nClearly we have a family of grue predicates in this problem, one for\neach different “critical time” t; let’s write\ngrue(t) to denote these grue predicates. Following Goodman,\nlet us refer to methods as  projection rules  in discussing\nthis example. A projection rule succeeds in a world just in case it\nsettles on a generalization that is correct in that world. Thus in a\nworld in which all examined emeralds are found to be green, we want\nour projection rule to converge to the proposition that all emeralds\nare green. If all examined emeralds are grue(t), we want our\nprojection rule to converge to the proposition that all emeralds are\ngrue(t). Note that this stipulation treats green and grue\npredicates completely on a par, with no bias towards either. As\nbefore, let us consider two rules: the  natural projection rule\nwhich conjectures that all emeralds are green as long as only green\nemeralds are found, and the gruesome rule which keeps\nprojecting the next grue predicate consistent with the available\nevidence. Expressed in the green-blue vocabulary, the gruesome\nprojection rule conjectures that after observing some number of\nn green emeralds, all future ones will be blue. The figures\nbelow illustrates the possible observation sequences, the natural\nprojection rule, and the gruesome projection rule.  \n \nThe following figure shows the gruesome projection rule.  \n \nHow do these rules measure up to the goal of arriving at a true\ngeneralization? Suppose for the sake of the example that the only\nserious possibilities under consideration are: (1) Either all emeralds\nare green or (2) all emeralds are grue(t) for some critical\ntime t. Then the natural projection rule settles on the\ncorrect generalization no matter what the correct generalization is.\nFor if all emeralds are green, the natural projection rule asserts\nthis fact from the beginning. And suppose that all emeralds are\ngrue(t) for some critical time t. Then at time\nt, a blue emerald will be observed. At this point the natural\nprojection rule settles on the conjecture that all emeralds are\ngrue(t), which must be correct given our assumption about the\npossible observation sequences. Thus no matter what evidence is\nobtained in the course of inquiry—consistent with our background\nassumptions—the natural projection rule eventually settles on a\ncorrect generalization about the colour of emeralds. \nThe gruesome rule does not do as well. For if all emeralds are green,\nthe rule will never conjecture this fact because it keeps projecting\ngrue predicates. Hence there is a possible observation\nsequence—namely those on which all emeralds are green—on\nwhich the gruesome rule fails to converge to the right generalization.\nSo means-ends analysis would recommend the natural projection rule\nover the gruesome rule.  \nThe means-ends analysis of the Riddle of Induction illustrates a\nnumber of philosophically important points that holds for\nlearning-theoretic analysis in general. \nEqual Treatment of All Hypotheses. As in the previous example,\nnothing in this argument hinges on arguments to the effect that\ncertain possibilities are not to be taken seriously a priori. In\nparticular, nothing in the argument says that generalizations with\ngrue predicates are ill-formed, unlawlike, or in some other way a\npriori inferior to “all emeralds are green”. \nLanguage Invariance. The analysis does not depend on the\nvocabulary in which the evidence and generalizations are framed. For\nease of exposition, I have mostly used the green-blue reference frame.\nHowever, grue-bleen speakers would agree that the aim of reliably\nsettling on a correct generalization requires the natural projection\nrule rather than the gruesome one, even if they would want to express\nthe conjectures of the natural rule in their grue-bleen language\nrather than the blue-green language that we have used so far. \nDependence on Context. Though the analysis does not depend on\nlanguage, it does depend on assumptions about what the possible\nobservation sequences are. The example as described above seems to\ncomprise the possibilities that correspond to the colour predicates\nGoodman himself discussed. But means-ends analysis applies just as\nmuch to other sets of possible predicates. Schulte [1999] and\nChart [2000] discuss a number of other versions of the Riddle of\nInduction, in some of which means-ends analysis favours projecting\nthat all emeralds are grue on a sample of all green emeralds. \nOur first two examples feature simple universal generalizations. Some\nsubtle aspects of the concept of long-run reliability, particularly\nits relationship to falsificationism, become apparent if we consider\ngeneralizations that allow for exceptions. To illustrate, let us\nreturn to the world of ravens. This time the ornithological community\nis more guarded in its generalizations concerning the colour of\nravens. Two competing hypotheses are under investigation. \nAssuming that one or the other of these hypotheses is correct, is\nthere an inductive method that reliably settles on the right one? What\nmakes this problem more difficult than our first two is that each\nhypothesis under investigation is consistent with any finite amount of\nevidence. If 100 white ravens and 50 black ravens are found, either\nthe 50 black ravens or the 100 white ravens may be the exception to\nthe rule. In terminology made familiar by\n Karl Popper’s\n work, we may say that neither hypothesis is falsifiable. As a\nconsequence, the inductive strategy from the previous two examples\nwill not work here. This strategy was basically to adopt a\n“bold” universal generalization, such as “all ravens\nare black” or “all emeralds are green”, and to hang\non to this conjecture as long as it “passes muster”.\nHowever, when rules with possible exceptions are under investigation,\nthis strategy is unreliable. For example, suppose that an inquirer\nfirst adopts the hypothesis that “all but finitely many ravens\nare white”. It may be the case that from then on, only black\nravens are found. But each of these apparent counterinstances can be\n“explained away” as an exception. If the inquirer follows\nthe principle of hanging on to her conjecture until the evidence is\nlogically inconsistent with the conjecture, she will never abandon her\nfalse belief that all but finitely many ravens are white, much less\narrive at the correct belief that all but finitely many ravens are\nblack. \nReliable inquiry requires a more subtle investigative strategy. Here\nis one (of many). Begin inquiry with either competing hypothesis, say\n“all but finitely many ravens are black”. Choose some\ncut-off ratio to represent a “clear majority”; for\ndefiniteness, let’s say 70%. If the current conjecture is that all but\nfinitely many ravens are black, change your mind to conjecture that\nall but finitely many ravens are white just in case over 70% of\nobserved ravens are in fact white. Proceed likewise if the current\nconjecture is that all but finitely many ravens are white when over\n70% of observed ravens are in fact black. \nA bit of thought shows that this rule reliably identifies the correct\nhypothesis in the long run, no matter which of the two competing\nhypotheses is correct. For if all but finitely many ravens are black,\neventually the nonblack exceptions to the rule will be exhausted, and\nan arbitrarily large majority of observed ravens will be black.\nSimilarly if all but finitely many ravens are white. \nGeneralizations with exceptions illustrate the relationship between\nPopperian falsificationism and the learning-theoretic idea of reliable\nconvergence to the truth. In some settings of inquiry, notably those\ninvolving universal generalizations, a naively Popperian\n“conjectures-and-refutations” approach of hanging on to\nconjectures until the evidence falsifies them does yield a reliable\ninductive method. In other problems, like the current example, it does\nnot. Generally speaking problems with unfalsifiable hypotheses require\nsomething other than the conjectures-and-refutations recipe for\nreliable methods (this assertion hinges on what exactly one means by\n“falsifiable hypothesis”; see\n Section 3\n (The Limits of Inquiry and the Complexity of Empirical Problems). The moral is that relying on\nfalsifications is sometimes, but not always, the best way for\ninquiry to proceed. \nThis section provides further examples to illustrate\nlearning-theoretic analysis. The examples in this section are more\nrealistic and address methodological issues arising in scientific\npractice. The space constraints of the encyclopedia format allow only\nan outline of the full analysis; there are references to more detailed\ndiscussions below. More case studies may be found in [Kelly 1996, Ch.\n7.7, Harrell 2000]. Readers who wish to proceed\nto the further development of the theory and philosophy of means-ends\nepistemology can skip this section without loss of continuity.  \nOne of the hallmarks of elementary particle physics is the discovery\nof new conservation laws that apply only in the subatomic realm [Ford\n1963, Ne’eman and Kirsh 1983, Feynman 1965]. (Feynman groups one of\nthem, the conservation of Baryon Number, with the other “great\nconservation laws” of energy, charge and momentum.) Simplifying\nsomewhat, conservation principles serve to explain why certain\nprocesses involving elementary particles do  not  occur: the\nexplanation is that some conservation principle was violated (cf.\nOmnes [1971, Ch.2] and Ford [1963]). So a goal of particle inquiry is\nto find a set of conservation principles such that for every process\nthat is possible according to the (already known) laws of physics, but\nfails to be observed experimentally, there is some conservation\nprinciple that rules out that process. And if a process is in fact\nobserved to occur, then it ought to satisfy all conservation laws that\nwe have introduced. \nThis constitutes an inference problem to which we may apply means-ends\nanalysis. An inference method produces a set of conservation\nprinciples in response to reports of observed processes. Means-ends\nanalysis asks which methods are guaranteed to settle on conservation\nprinciples that account for all observations, that is, that rule out\nunobserved processes and allow observed processes. Schulte [2008]\ndescribes an inductive method that accomplishes this goal.  Informally\nthe method may be described as follows.  \nThe logic of conservation laws is such that the observation of some\nreactions entails the possibility of other unobserved ones. The\nlearning-theoretic method rules out all reactions that are not\nentailed. It turns out that the conservation principles that this\nmethod would posit on the currently available evidence are \nempirically equivalent  to the ones that physicists have\nintroduced. Specifically, their predictions agree exactly with the\nconservation of charge, baryon number, muon number, tau number and\nLepton number that is part of the Standard Model of particle physics.  \nFor some physical processes, the only way to get empirically adequate\nconservation principles is by positing that some hidden particles have\ngone undetected. Schulte [2009] extends the analysis such that\nan inductive method may not only introduce conservation laws, but also\nposit unseen particles. The basic principle is again to posit unseen\nparticles in such a way that we rule out as many unobserved reactions\nas possible. When this method is applied to the known particle data,\nit rediscovers the existence of an electron antineutrino. This is one\nof the particles of key concern in current particle physics.  \nThere has been a substantive body of research on learning causal\nrelationships as represented in a causal graph [Spirtes et al. 2000].\nKelly suggested a learning-theoretic analysis of inferring causality\nwhere the evidence is provided in the form of observed significant\ncorrelations among variables of interest (a modern version of\nHume’s “constant conjunctions”). The following\ninductive method is guaranteed to converge to an empirically adequate\ncausal graph as more and more correlations are observed [Schulte, Luo\nand Greiner 2007]. \nSome philosophers of mind have argued that the mind is composed of\nfairly independent modules. Each module has its own\n“input” from other modules and sends “output”\nto other modules. For example, an “auditory analysis\nsystem” module might take as input a heard word and send a\nphonetic analysis to an “auditory input lexicon”. The idea\nof modular organization raises the empirical question of what mental\nmodules there are and how they are linked to each other. A prominent\ntradition of research in cognitive neuroscience has attempted to\ndevelop a model of mental architecture along these lines by studying\nthe responses of normal and abnormal subjects to various stimuli. The\nidea is to compare normal reactions with abnormal ones—often\ncaused by brain damage—so as to draw inferences about which\nmental capacities depend on each other and how. \nGlymour [1994] asked the reliabilist question whether there are\ninference methods that are guaranteed to eventually settle on a true\ntheory of mental organization, given exhaustive evidence about normal\nand abnormal capacities and reactions. He argued that for some\npossible mental architectures, no amount of evidence of the\nstimulus-response kind can distinguish between them. Since the\navailable evidence determines the conjectures of an inductive method,\nit follows that there is no guarantee that a method will settle on the\ntrue model of cognitive architecture. \nIn further discussion, Bub [1994] showed that if we grant certain\nrestrictive assumptions about how mental modules are connected, then a\ncomplete set of behavioural observations would allow a\nneuropsychologist to ascertain the module structure of a (normal)\nmind. In fact, under Bub’s assumptions there is a reliable method for\nidentifying the modular structure. Glymour has also explored to what\nextent richer kinds of evidence would resolve underdetermination of\nmental architecture. (One example of richer evidence are double\ndisassocations. An example of a double dissocation would be a pair of\npatients, one who has a normal capacity for understanding spoken\nwords, but fails to understand written ones, and another who\nunderstands written words but not spoken ones.) \nThese studies illustrate some general features of learning theory: \n1. Generality. The basic notions of the theory are very\ngeneral. Essentially, the theory applies whenever one has a question\nthat prompts inquiry, a number of candidate answers, and some evidence\nfor deciding among the answers. Thus means-ends analysis can be\napplied in any discipline aimed at empirical knowledge, for example\nphysics or psychology. \n2. Context Dependence. Learning theory is pure normative a\npriori epistemology in the sense that it deals with standards for\nassessing methods in possible settings of inquiry. But the approach\ndoes not aim for universal, context-free methodological maxims. The\nmethodological recommendations depend on contingent factors, such as\nthe operative methodological norms, the questions under investigation,\nthe background assumptions that the agent brings to inquiry, the\nobservational means at her disposal, her cognitive capacities, and her\nepistemic aims. As a consequence, to evaluate specific methods in a\ngiven domain, as in the case studies mentioned, one has to study the\ndetails of the case in question. The means-ends analysis often rewards\nthis study by pointing out what the crucial methodological features of\na given scientific enterprise are, and by explaining precisely why and\nhow these features are connected to the success of the enterprise in\nattaining its epistemic aims. \n3. Trade-offs. In the perspective of means-ends epistemology,\ninquiry involves an ongoing struggle with hard choices, rather than\nthe execution of a universal “scientific method”. The\ninquirer has to balance conflicting values, and may consider various\nstrategies such as accepting difficulties in the short run hoping to\nresolve them in the long run. For example in the conservation law\nproblem, there can be conflicts between theoretical parsimony, i.e.,\npositing fewer conservation laws, and ontological parsimony, i.e.,\nintroducing fewer hidden particles. For another example, a particle\ntheorist may accept positing undetected particles in the hopes that\nthey will eventually be observed as science progresses. The ongoing\nsearch for the Higgs boson illustrates this strategy. An important\nlearning-theoretic project is to examine when such tradeoffs arise and\nwhat the options for resolving them are. Section 4 extends\nlearning-theoretic analysis to consider goals in addition to long-run\nreliability. \nAfter seeing a number of examples like the ones described above, one\nbegins to wonder what the pattern is. What is it about an empirical\nquestion that allows inquiry to reliably arrive at the correct answer?\nWhat general insights can we gain into how reliable methods go about\ntesting hypotheses? Learning theorists answer these questions with\ncharacterization theorems. Characterization theorems are\ngenerally of the form “it is possible to attain this standard of\nempirical success in a given inductive problem if and only if the\ninductive problem meets the following conditions”.  \nA fundamental result describes the conditions under which a method can\nreliably find the correct hypothesis among a countably infinite or\nfinite number H1, H2,\n…, Hn, …. of mutually exclusive\nhypotheses that jointly cover all possibilities consistent with the\ninquirer’s background assumptions.  This is possible just in case\neach of the hypotheses is a countable disjunction of refutable\nempirical claims . By “refutable” I mean that if the\nclaim is false, the evidence combined with the inquirer’s background\nassumptions will eventually conclusively falsify that disjunct within\nthe hypothesis (see Kelly [1996, Ch. 3.3]).\nFor illustration, let’s return to the ornithological example with two\nalternative hypotheses: (1) all but finitely many swans are white, and\n(2) all but finitely many swans are black. As we saw, it is possible\nin the long run to reliably settle which of these two hypotheses is\ncorrect. Hence by the characterization theorem, each of the two\nhypotheses must be a disjunction of refutable empirical claims. To see\nthat this indeed is so, observe that “all but finitely many\nswans are white” is logically equivalent to the disjunction \nA recent characterization theorem due to Baltag, Gierasimczuk, and\nSmets emphasizes the topological concept of separability [Baltag et\nal. 2015]. In epistemic terms, topological separation means (lack of)\n underdetermination\n by evidence. For example, the classic first axiom of separation\nrequires that for any two possible states of the world, there are two\npossible observation sequences, each consistent with one state of the\nworld but not the other. Thus the first separation axiom entails that\na complete observation sequence determines a unique state of the\nworld. Baltag et al. define a topological notion of what it means for\nevidence to separate competing hypotheses in an inductive problem, and\nprove that this concept of inductive separability characterizes which\ninductive problems allow reliable learning.  \nA few points will help explain the significance of characterization\ntheorems. \n1. Structure of Reliable Methods. Characterization theorems\ntell us how the structure of reliable methods is attuned to the\nstructure of the hypotheses under investigation. For example, the\ntheorem mentioned establishes a connection between falsifiability and\ntestability, but one that is more attenuated than the naïve\nPopperian envisions: it is not necessary that the hypotheses under\ntest be directly falsifiable; rather, there must be ways of\nstrengthening each hypothesis that yield a countable number of\nrefutable “subhypotheses”. We can think of these refutable\nsubhypotheses as different ways in which the main hypothesis may be\ntrue. (For example, one way in which “all but finitely many\nravens are white” is true is if there are are at most 10 black\nravens; another is if there are at most 100 black ravens, etc.) \n2. Import of Background Assumptions. The characterization\nresult draws a line between the solvable and unsolvable problems.\nBackground knowledge reduces the inductive complexity of a problem;\nwith enough background knowledge, the problem crosses the threshold\nbetween the unsolvable and the solvable. In many domains of empirical\ninquiry, the pivotal background assumptions are those that make\nreliable inquiry feasible. (Kuhn [1970] makes similar points about the\nimportance of background assumptions embodied in a\n“paradigm”).  \n3. Language Invariance. Learning-theoretic characterization\ntheorems concern what Kelly calls the “temporal\nentanglement” of various observation sequences [Kelly\n2000]. Ultimately they rest on entailment relations between given\nevidence, background assumptions and empirical claims. Since logical\nentailment does not depend on the language we use to frame evidence\nand hypotheses, the inductive complexity of an empirical problem as\ndetermined by the characterization theorems is\nlanguage-invariant.  \nA longstanding criticism of convergence to the truth as an aim of\ninquiry is that, while fine in itself, this aim is consistent with any\ncrazy behaviour in the short run [Salmon 1991]. For example, we saw in\nthe New Riddle of Induction that a reliable projection rule can\nconjecture that the next emerald will be blue no matter how many green\nemeralds have been found—as long as eventually the rule\nprojects “all emeralds are green”. One response is that if\nmeans-ends analysis takes into account other epistemic aims in\naddition to long-run convergence, then it can provide\nstrong guidance for what to conjecture in the short run. \nTo illustrate this point, let us return to the Goodmanian Riddle of\nInduction. Ever since Plato, philosophers have considered the idea\nthat stable true belief is better than unstable true belief,\nand epistemologists such as Sklar [1975] have advocated similar\nprinciples of “epistemic conservatism”. Kuhn tells us that\na major reason for conservatism in paradigm debates is the cost of\nchanging scientific beliefs [Kuhn 1970]. In this spirit, learning\ntheorists have examined methods that minimize the number of times that\nthey change their theories before settling on their final conjecture\n[Putnam 1965, Kelly 1996, Jain 1999]. Such\nmethods are said to minimize mind changes.  \nThe New Riddle of Induction turns out to be a nice illustration of\nthis idea. Consider the natural projection rule (conjecture that all\nemeralds are green on a sample of green emeralds). If all emeralds are\ngreen, this rule never changes its conjecture. And if all emeralds are\ngrue(t) for some critical time t, then the natural\nprojection rule abandons its conjecture “all emeralds are\ngreen” at time t—one mind change—and\nthereafter correctly projects “all emeralds are\ngrue(t)”. Remarkably, rules that project grue rather\nthan green do not do as well. For example, consider a rule that\nconjectures that all emeralds are grue(3) after observing one green\nemerald. If two more green emeralds are observed, the rule’s\nconjecture is falsified and it must eventually change its mind, say to\nconjecture that all emeralds are green (supposing that green emeralds\ncontinue to be found). But then at that point, a blue emerald may\nappear, forcing a second mind change. This argument can be generalized\nto show that  the aim of minimizing mind changes allows only the\ngreen predicate to be projected on a sample of all green emeralds \n[Schulte 1999]. We saw in\n Section 1.2\n above how the natural projection rule changes its mind at most once;\nthe figure below illustrates in a typical case how an unnatural\nprojection rule may have to change its mind twice or more. \n \nThe same reasoning applies to the question about whether all ravens\nare black. The bold generalizer that conjectures that all ravens are\nblack after observing samples of only black ravens succeeds with at\nmost one mind change: if indeed all ravens are black, the generalizer\nnever changes its mind at all. And if there is a nonblack raven, the\nrefutation occasions one mind change, but afterwards the question is\nsettled.  \nContrast this with the contrary method that asserts that there is a\nnonblack raven after observing a sample of all black ones. If only\nblack ravens continue to be observed, the contrary method has to\neventually change its mind and assert that “all ravens are\nblack”, or else it fails to arrive at the correct\ngeneralization. But then at that point, a nonblack raven may appear,\nforcing a second mind change. Thus the goal of stable belief places\nstrong constraints on what a method may conjecture in the short run\nfor this problem: on observing only black ravens, the options are\n“all ravens are black” or “no opinion yet”,\nbut not “there is a nonblack raven”.  \nIn the conservation law problem, the restrictive method described in\n Section 2.1\n is the only method that minimizes mind changes. Recall that the\nrestrictive method adopts a set of conservation laws that rule out as\nmany unobserved reactions as possible. It can be shown that if there\nare n known elementary particles whose reactions are observed,\nthis method requires at most n mind changes. (The number of\nelementary particles in the Standard Model is around n = 200).\n \nFor learning causal graphs, the following variant of the method\ndescribed in\n Section 2.2\n minimizes the number of mind changes.\n \nThis example illustrates that sometimes minimizing mind changes\nrequires withholding beliefs. Intuitively, this occurs when there are\ntwo or more equally simple explanations of the data, and the inquirer\nhas to wait until further observations decide between these\npossibilities. Jumping to one of the simple conclusions might lead to\nan unnecessary mind change in case an alternative equally simple\nexplanation turns out to be correct. In such cases there is a\ntrade-off between the goals of achieving stable belief, on the one\nhand, and quickly settling on a true belief on the other [Schulte\n1999]. We discuss the connection between simplicity and stable belief\nin the next section. \nA strong intuition about inductive inference and scientific method is\nthat we should prefer simpler hypotheses over complex ones; see the\n entry on simplicity.\n Statisticians, computer scientists, and other researchers concerned\nwith learning from observations have made extensive use of a\npreference for simplicity to solve practical inductive problems\n[Domingos 1999]. From a foundational point of view, simplicity is\nproblematic for at least two reasons.  \nThe justification problem: Why adopt simple hypotheses? One\nobvious answer is that the world is simple and therefore a complex\ntheory is false. However, the apriori claim that the world is simple\nis highly controversial—see the\n entry on simplicity.\n From a learning-theoretic perspective, dismissing complex hypotheses\nimpairs the reliability of inductive methods. In Kelly’s\nmetaphor, a fixed bias is like a stopped watch: We may happen to use\nthe watch when it is pointing at the right time, but the watch is not\na reliable instrument for telling time [Kelly 2007a, 2010]. \nThe description problem: Epistemologists have worried that\nsimplicity is not an objective feature of a hypothesis, but rather\n“depends on the mode of presentation”, as Nozick puts it.\nGoodman’s Riddle illustrates this point. If generalizations are\nframed in blue-green terms, “all emeralds are green”\nappears simpler than “all emeralds are first green and then\nblue”. But in a grue-bleen language, “all emeralds are\ngrue” appears simpler than “all emeralds are first grue\nand then bleen”. \nLearning theorists have engaged in recent and ongoing efforts to apply\nmeans-ends epistemology to develop a theory of the connection between\nsimplicity and induction that addresses these concerns [Kelly 2010,\nHarmann and Kulkarni 2007, Luo and Schulte 2006, Steel 2009]. It turns\nout that a fruitful perspective is to examine the relationship between\nthe structure of a hypothesis space and the mind change complexity of\nthe corresponding inductive problem. The fundamental idea is that,\nwhile simplicity does not enjoy an a priori connection with truth,\nchoosing simple hypotheses can help an inquirer find the truth more\nefficiently, in the sense of avoiding mind changes.\nKelly’s road metaphor illustrates the idea. Consider two routes\nto the destination, one via a straight highway, the other via back\nroads. Both routes eventually lead to the same point, but the back\nroads entail more twists and turns [Kelly 2007a, 2010].  \nA formalization of this idea takes the form of an Ockham\nTheorem: A theorem that shows (under appropriate restrictions)\nthat an inductive method finds the truth as efficiently as possible\nfor a given problem if and only if the method is the Ockham\nmethod, that is, it selects the simplest hypothesis consistent\nwith the data. An Ockham theorem provides a justification for\nOckham’s inductive razor as a means towards epistemic aims.  \nWhether an Ockham theorem is true depends on the description of the\nOckham method, that is, on the exact definition of simplicity for a\nset of hypotheses. There is a body of mathematical results that\nestablish Ockham theorems using a language-invariant simplicity\nmeasure, which we explain next. \nSay that a hypothesis H from a background set of possible\nhypotheses H is verifiable if there is an evidence\nsequence such that H is the only hypothesis from H that\nis consistent with the evidence sequence. For example, in the black\nraven problem above, the hypothesis “there is a nonblack\nraven” is verifiable since it is entailed by an observation of a\nnonblack raven. The hypothesis “all ravens are black” is\nnot verifiable, since it is not entailed by any finite evidence\nsequence. The following procedure assigns a simplicity rank to each\nhypothesis H from a set of hypotheses H [Apsitis 1994,\nLuo and Schulte 2006]. \nHypotheses with higher simplicity rank are regarded as simpler than\nthose with lower ranks. Simplicity ranks are defined in terms of\nlogical entailment relations, hence are language-invariant. Simplicity\nranks as defined can be seen as degrees of falsifiability in\nthe following sense. Consider a hypothesis of simplicity rank 1. Such\na hypothesis is falsifiable because an evidence sequence that verifies\nan alternative hypothesis of rank 0 falsifies it. Moreover, a\nhypothesis of simplicity rank 1 is persistently falsifiable in the\nsense that it remains falsifiable no matter what evidence sequence\nconsistent with it is observed. A hypothesis of simplicity rank\nn+1 is persistently falsifiable by hypotheses of rank n.\nLet us illustrate the definition in our running examples. \nIn the Riddle of Induction, the verifiable hypotheses are the grue\nhypotheses with critical time t: any sequence of t green emeralds\nfollowed by blue ones entails the corresponding grue(t)\ngeneralization. Thus the grue hypotheses receive simplicity rank 0.\nAfter the grue hypotheses are eliminated, the only remaining\nhypothesis is “all emeralds are green”. Given that it is\nthe only possibility in the restricted hypothesis space, “all\nemeralds are green” is entailed by any sequence of green\nemeralds. Therefore “all emeralds are green” has\nsimplicity rank 1. After removing the all green hypothesis, no\nhypotheses remain. \nIn the raven color problem, the verifiable hypothesis is “a\nnonblack raven will be observed”, which receives simplicity rank\n0. After removing the hypothesis that a nonblack raven will be\nobserved, the only remaining possibility is that only black ravens\nwill be observed, hence this hypothesis is verifiable in the\nrestricted hypothesis space and receives simplicity rank 1. \nThe simplicity rank of a causal graph is given by the number of direct\nlinks not contained in the graph.\nTherefore the fewer direct links are posited by the causal model, the\nhigher its simplicity rank. \nThe simplicity rank of a set of conservation laws is given by the\nnumber of independent laws. (Independence in the sense of linear\nalgebra.) Therefore the more nonredundant laws are introduced by a\ntheory, the higher its simplicity rank. Each law rules out some\nreactions, so maximizing the number of independent laws given the\nobserved reactions is equivalent to ruling out as many unobserved\nreactions as possible. \nThe following theorem shows the connection between the mind-change\ncomplexity of an inductive problem and the simplicity ranking as\ndefined. \nThus for an inductive problem to be solvable with at most n\nmind changes, the maximum simplicity rank of any possible hypothesis\nis n. In the Riddle of Induction, the maximum simplicity rank\nis 1, and therefore this problem can be solved with at most 1 mind\nchange. The next result provides an Ockham theorem connecting\nsimplicity and mind change performance.  \nOckham Theorem. Let H be a set of empirical hypotheses\nwith optimal mind change bound n. Then an inductive method is mind\nchange optimal if and only if it satisfies the following\nconditions. \nThis theorem says that a mind-change optimal method may withhold a\nconjecture as a skeptic would, but if it does adopt a definite\nhypothesis, the hypothesis must be the simplest one, in the sense of\nhaving the maximum simplicity rank. Thus the mind change optimal\nmethods discussed in\n Section 4\n are all Ockham methods that adopt the simplest hypothesis consistent\nwith the data. The Ockham theorem shows a remarkable reversal from the\nlong-standing objection that long-run reliability imposes too few\nconstraints on short-run conjectures: If we add to long-run\nconvergence to the truth the goal of achieving stable belief, then in\nfact there is a unique inductive method that achieves this goal\nin a given empirical problem. Thus the methodological analysis\nswitches from offering no short-run prescriptions to offering a\ncomplete prescription. \nWhile these results establish a fruitful connection between simplicity\nand mind-change optimality, a limitation of the approach is that it\nrequires that some hypotheses must be conclusively entailed by some\nevidence sequence. This is typically not the case for statistical\nmodels, where the probability of a hypothesis may become arbitrarily\nsmall but usually not 0. For instance, consider a coin flip problem\nand the hypothesis “the probability of heads is 90%”. If\nwe observe one million tails, the probability of the hypothesis is\nvery small indeed, but it is not 0, because any number of tails is\nlogically consistent with a high probability of heads. Kevin Kelly has\ndeveloped a notion of simplicity that is appropriate for statistical\nmodels and proved Ockham theorems for this setting (see\n Other Internet Resources).\n  \nKant distinguished between categorical imperatives that one ought to\nfollow regardless of one’s personal aim and circumstances, and\nhypothetical imperatives that direct us to employ our means towards\nour chosen end. One way to think of learning theory is as the study of\nhypothetical imperatives for empirical inquiry. Many epistemologists\nhave proposed various categorical imperatives for inductive inquiry,\nfor example in the form of an “inductive logic” or norms\nof “epistemic rationality”. In principle, there are three\npossible relationships between hypothetical and categorical\nimperatives for empirical inquiry. \n1. The categorical imperative will lead an inquirer to obtain his\ncognitive goals. In that case means-ends analysis vindicates\nthe categorical imperative. For example, when faced with a simple\nuniversal generalization such as “all ravens are black”,\nwe saw above that following the Popperian recipe of adopting the\nfalsifiable generalization and sticking to it until a counterexample\nappears leads to a reliable method. \n2. The categorical imperative may prevent an inquirer from\nachieving his aims. In that case the categorical imperative\nrestricts the scope of inquiry. For example, in the case of\nthe two alternative generalizations with exceptions, the principle of\nmaintaining a universal generalization until it is falsified leads to\nan unreliable method (cf. [Kelly 1996, Ch. 9.4]). \n3. Some methods meet both the categorical imperative and the\ngoals of inquiry, and others don’t. Then we may take the best of both\nworlds and choose those methods that attain the goals of inquiry and\nsatisfy categorical imperatives. (See the further discussion in this\nsection.) \nFor a proposed norm of inquiry, we can apply means-ends analysis to\nask whether the norm helps or hinders the aims of inquiry. This was\nthe spirit of Putnam’s critique of Carnap’s confirmation functions\n[Putnam 1963]: the thrust of his essay was that Carnap’s methods were\nnot as reliable in detecting general patterns as other methods would\nbe. More recently, learning theorists have investigated the power of\nBayesian conditioning (see the entry on\n Bayesian epistemology).\n John Earman has conjectured that if there is any reliable method for\na given problem, then there is a reliable method that proceeds by\nBayesian updating [Earman 1992, Ch.9, Sec.6]. Cory Juhl [1997]\nprovided a partial confirmation of Earman’s conjecture: He proved that\nit holds when there are only two potential evidence items (e.g.,\n“emerald is green” vs. “emerald is blue”). The\ngeneral case is still open. \nEpistemic conservatism is a methodological norm that has been\nprominent in philosophy at least since Quine’s notion of\n“minimal mutilation” of our beliefs [1951]. One version of\nepistemic conservatism, as we saw above, holds that inquiry should\nseek stable belief. Another formulation, closer to Quine’s, is the\ngeneral precept that belief changes in light of new evidence should be\nminimal. Fairly recent work in philosophical logic has proposed a\nnumber of criteria for minimal belief change known as the AGM\naxioms [Gärdenfors 1988]. Learning theorists have shown that\nwhenever there is a reliable method for investigating an empirical\nquestion, there is one that proceeds via minimal changes (as defined\nby the AGM postulates). The properties of reliable inquiry with\nminimal belief changes are investigated in [Martin\nand Osherson 1998, Kelly 1999, Baltag et al. 2015]. \nMuch of computational learning theory focuses on inquirers with\nbounded rationality, that is, agents with cognitive\nlimitations such as a finite memory or bounded computational\ncapacities. Many categorical norms that do not interfere with\nempirical success for logically omniscient agents nonetheless limit\nthe scope of cognitively bounded agents. For example, consider the\nnorm of consistency: Believe that a hypothesis is false as soon as the\nevidence is logically inconsistent with it. The consistency principle\nis part of both Bayesian confirmation theory and AGM belief revision.\nKelly and Schulte [1995] show that consistency prevents even agents\nwith infinitely uncomputable cognitive powers from reliably assessing\ncertain hypotheses. The moral is that if a theory is sufficiently\ncomplex, agents who are not logically omniscient may be unable to\ndetermine immediately whether a given piece of evidence is consistent\nwith the theory, and need to collect more data to detect the\ninconsistency. But the consistency principle—and a fortiori,\nBayesian updating and AGM belief revision— do not acknowledge\nthe usefulness of “wait and see more” as a scientific strategy. \nMore reflection on these and other philosophical issues in means-ends\nepistemology can be found in sources such as [Glymour 1991], [Kelly\n1996, Chs. 2,3], [Glymour and Kelly 1992], [Kelly et al.\n1997], [Glymour 1994], [Bub 1994]. Of\nparticular interest in the philosophy of science may be\nlearning-theoretic models that accommodate historicist and relativist\nconceptions of inquiry, chiefly by expanding the notion of an\ninductive method so that methods may actively select paradigms for\ninquiry; for more details on this topic, see [Kelly 2000, Kelly 1996,\nCh.13]. Booklength introductions to the mathematics of learning theory\nare [Kelly 1996, Martin and Osherson 1998, Jain et al. 1999].\n“Induction, Algorithmic Learning Theory and Philosophy” is\na recent collection of writings on learning theory [Friend et al.\n2007]. Contributions include introductory papers (Harizanov, Schulte),\nmathematical advances (Martin, Sharma, Stephan, Kalantari),\nphilosophical reflections on the strengths and implications of\nlearning theory (Glymour, Larvor, Friend), applications of the theory\nto philosophical problems (Kelly), and a discussion of\nlearning-theoretic thinking in the history of philosophy (Goethe).","contact.mail":"oschulte@sfu.ca","contact.domain":"sfu.ca"}]
