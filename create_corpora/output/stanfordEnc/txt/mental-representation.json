[{"date.published":"2000-03-30","date.changed":"2020-01-21","url":"https://plato.stanford.edu/entries/mental-representation/","author1":"David Pitt","entry":"mental-representation","body.text":"\n\n\nThe notion of a “mental representation” is, arguably, in\nthe first instance a theoretical construct of cognitive science. As\nsuch, it is a basic concept of the Computational Theory of Mind,\naccording to which cognitive states and processes are constituted by\nthe occurrence, transformation and storage (in the mind/brain) of\ninformation-bearing structures (representations) of one kind or\nanother.\n\n\nHowever, on the assumption that a representation is an object with\nsemantic properties (content, reference, truth-conditions,\ntruth-value, etc.), a mental representation may be more broadly\nconstrued as a mental object with semantic properties. As such, mental\nrepresentations (and the states and processes that involve them) need\nnot be understood only in cognitive/computational terms. On this\nbroader construal, mental representation is a philosophical topic with\nroots in antiquity and a rich history and literature predating the\nrecent “cognitive revolution,” and which continues to be\nof interest in pure philosophy. Though most contemporary philosophers\nof mind acknowledge the relevance and importance of cognitive science,\nthey vary in their degree of engagement with its literature, methods\nand results; and there remain, for many, issues concerning the\nrepresentational properties of the mind that can be addressed\nindependently of the computational hypothesis.\n\n\nThough the term ‘Representational Theory of Mind’ is\nsometimes used almost interchangeably with ‘Computational Theory\nof Mind’, I will use it here to refer to any theory that\npostulates the existence of semantically evaluable mental objects,\nincluding philosophy’s stock-in-trade mentalia – thoughts,\nconcepts, percepts, ideas, impressions, notions, rules, schemas,\nimages, phantasms, etc. – as well as the various sorts of\n“subpersonal” representations postulated by cognitive\nscience. Representational theories may thus be contrasted with\ntheories, such as those of Baker (1995), Collins (1987), Dennett\n(1987), Gibson (1966, 1979), Reid (1764/1997), Stich (1983) and Thau\n(2002), which deny the existence of such things.\n\nThe Representational Theory of Mind (RTM) (which goes back at least to\nAristotle) takes as its starting point commonsense mental states, such\nas thoughts, beliefs, desires, perceptions and imagings. Such states\nare said to have “intentionality” – they are\nabout or refer to things, and may be evaluated with\nrespect to properties like consistency, truth, appropriateness and\naccuracy. (For example, the thought that cousins are not related is\ninconsistent, the belief that Elvis is dead is true, the desire to eat\nthe moon is inappropriate, a visual experience of a ripe strawberry as\nred is accurate, an imaging of George Washington with dreadlocks is\ninaccurate.) \nRTM defines such intentional mental states as relations to mental\nrepresentations, and explains the intentionality of the former in\nterms of the semantic properties of the latter. For example, to\nbelieve that Elvis is dead is to be appropriately related to a mental\nrepresentation whose propositional content is that Elvis is\ndead. (The desire that Elvis be dead, the fear\nthat he is dead, the regret that he is dead, etc., involve\ndifferent relations to the same mental representation.) To perceive a\nstrawberry is, on the representational view, to have a sensory\nexperience of some kind which is appropriately related to (e.g.,\ncaused by) the strawberry. \nRTM also understands mental processes such as thinking, reasoning and\nimagining as sequences of intentional mental states. For example, to\nimagine the moon rising over a mountain is, inter alia, to\nentertain a series of mental images of the moon (and a mountain). To\ninfer a proposition q from the propositions p and\nif p then q is (inter alia) to have a sequence of\nthoughts of the form p, if p then q, q. \nContemporary philosophers of mind have typically supposed (or at least\nhoped) that the mind can be naturalized –\ni.e., that all mental facts have explanations in the terms of natural\nscience. This assumption is shared within cognitive science, which\nattempts to provide accounts of mental states and processes in terms\n(ultimately) of features of the brain and central nervous system. In\nthe course of doing so, the various sub-disciplines of cognitive\nscience (including cognitive and computational psychology and\ncognitive and computational neuroscience) postulate a number of\ndifferent kinds of structures and processes, many of which are not\ndirectly implicated by mental states and processes as commonsensically\nconceived. There remains, however, a shared commitment to the idea\nthat mental states and processes are to be explained in terms of\nmental representations. \nIn philosophy, recent debates about mental representation have\ncentered around the existence of propositional attitudes (beliefs,\ndesires, etc.) and the determination of their contents (how they come\nto be about what they are about), and the existence of phenomenal\nproperties and their relation to the content of thought and perceptual\nexperience. Within cognitive science itself, the philosophically\nrelevant debates have been focused on the computational architecture\nof the brain and central nervous system, and the compatibility of\nscientific and commonsense accounts of mentality. \nIntentional Realists such as Dretske (e.g., 1988) and Fodor\n(e.g., 1987) note that the generalizations we apply in everyday life\nin predicting and explaining each other’s behavior (often\ncollectively referred to as “folk psychology”) are both\nremarkably successful and indispensable. What a person believes,\ndoubts, desires, fears, etc. is a highly reliable indicator of what\nthat person will do; and we have no other way of making sense of each\nother’s behavior than by ascribing such states and applying the\nrelevant generalizations. We are thus committed to the basic truth of\ncommonsense psychology and, hence, to the existence of the states its\ngeneralizations refer to. (Some realists, such as Fodor, also hold\nthat commonsense psychology will be vindicated by cognitive science,\ngiven that propositional attitudes can be construed as computational\nrelations to mental representations.) \nIntentional Eliminativists, such as Churchland, (perhaps)\nDennett and (at one time) Stich argue that no such things as\npropositional attitudes (and their constituent representational\nstates) are implicated by the successful explanation and prediction of\nour mental lives and behavior. Churchland (1981) denies that the\ngeneralizations of commonsense propositional-attitude psychology are\ntrue. He argues that folk psychology is a theory of the mind with a\nlong history of failure and decline, and that it resists incorporation\ninto the framework of modern scientific theories (including cognitive\npsychology). As such, it is comparable to alchemy and phlogiston\ntheory, and ought to suffer a comparable fate. Commonsense psychology\nis false, and the states (and representations) it postulates\nsimply don’t exist. (It should be noted that Churchland is not\nan eliminativist about mental representation tout court. See,\ne.g., Churchland 1989.) \nDennett (1987a) grants that the generalizations of commonsense\npsychology are true and indispensable, but denies that this is\nsufficient reason to believe in the entities they appear to refer to.\nHe argues that to give an intentional explanation of a system’s\nbehavior is merely to adopt the “intentional stance”\ntoward it. If the strategy of assigning contentful states to a system\nand predicting and explaining its behavior (on the assumption that it\nis rational – i.e., that it behaves as it should, given\nthe propositional attitudes it should have, given its environment) is\nsuccessful, then the system is intentional, and the\npropositional-attitude generalizations we apply to it are true. But\nthere is nothing more to having a propositional attitude than this.\n(See Dennett 1987a: 29.) \nThough he has been taken to be thus claiming that intentional\nexplanations should be construed instrumentally, Dennett (1991)\ninsists that he is a “moderate” realist about\npropositional attitudes, since he believes that the patterns in the\nbehavior and behavioral dispositions of a system on the basis of which\nwe (truly) attribute intentional states to it are objectively real. In\nthe event that there are two or more explanatorily adequate but\nsubstantially different systems of intentional ascriptions to an\nindividual, however, Dennett claims there is no fact of the matter\nabout what the individual believes (1987b, 1991). This does suggest an\nirrealism at least with respect to the sorts of things Fodor and\nDretske take beliefs to be; though it is not the view that there is\nsimply nothing in the world that makes intentional\nexplanations true. \n(Davidson 1973, 1974 and Lewis 1974 also defend the view that what it\nis to have a propositional attitude is just to be interpretable in a\nparticular way. It is, however, not entirely clear whether they intend\ntheir views to imply irrealism about propositional attitudes.) \nStich (1983) argues that cognitive psychology does not (or, in any\ncase, should not) taxonomize mental states by their semantic\nproperties at all, since attribution of psychological states by\ncontent is sensitive to factors that render it problematic in the\ncontext of a scientific psychology. Cognitive psychology seeks causal\nexplanations of behavior and cognition, and the causal powers of a\nmental state are determined by its intrinsic “structural”\nor “syntactic” properties. The semantic properties of a\nmental state, however, are determined by its extrinsic properties\n– e.g., its history, environmental or intramental relations.\nHence, such properties cannot figure in causal-scientific explanations\nof behavior. (Fodor 1994 and Dretske 1988 are realist attempts to come\nto grips with some of these problems.) Stich proposes a\nsyntactic theory of the mind, on which the semantic\nproperties of mental states play no explanatory role. (Stich\nhas since changed his views on a number of these issues. See Stich\n1996.) \nIt is a traditional assumption among realists about mental\nrepresentations that representational states come in two basic\nvarieties (cf. Boghossian 1995). There are those, such as thoughts,\nthat are composed of concepts and have no phenomenal\n(“what-it’s-like”) features (“qualia”),\nand those, such as sensations, which have phenomenal features but no\nconceptual constituents. (Nonconceptual content is usually defined as\na kind of content that states of a creature lacking concepts might\nnonetheless\n have.[1])\n On this taxonomy, mental states can represent either in a way\nanalogous to expressions of natural languages or in a way analogous to\ndrawings, paintings, maps, photographs or movies. Perceptual states\nsuch as seeing that something is blue, are sometimes thought\nof as hybrid states, consisting of, for example, a non-conceptual\nsensory experience and a belief, or some more integrated compound of\nconceptual and non-conceptual elements. (There is an extensive\nliterature on the representational content of perceptual experience.\nSee the entry on the\n contents of perception.) \nDisagreement over non-conceptual representation concerns the existence\nand nature of phenomenal properties, the role they play in determining\nthe contents of sensory representations, and which kinds of properties\ncan be represented by non-conceptual states. Dennett (1988), for\nexample, denies that there are such things as qualia at all (as they\nare standardly construed); while Brandom (2002), McDowell (1994), Rey\n(1991) and Sellars (1956) deny that they are needed to explain the\ncontent of sensory experience. Among those who accept that experiences\nhave phenomenal content, some (Dretske, Lycan, Tye) argue that it is\nreducible to a kind of intentional content, while others (Block, Loar,\nPeacocke) argue that it is irreducible. (See the discussion in the\nnext section.) A further debate concerns the non-conceptual\nrepresentability of high-level properties such as kind properties and\nmoral properties. (See, e.g., Dretske 1995 and Siegel 2010, and the\nentry on the contents of perception.)  \nSome historical discussions of the representational properties of mind\n(e.g., Aristotle De Anima, Locke 1689/1975, Hume 1739/1978)\nseem to assume that nonconceptual representations – percepts\n(“impressions”), images (“ideas”) and the like\n– are the only (or at least the main) kinds of mental\nrepresentations, and that the mind represents the world in virtue of\nbeing in states that resemble things in it. On such a view,\nall representational states have their content in virtue of their\nsensory phenomenal features. Powerful arguments, however, focusing on\nthe lack of generality (Berkeley Principles of Human\nKnowledge), ambiguity (Wittgenstein 1953) and\nnon-compositionality (Fodor 1981d) of sensory and imagistic\nrepresentations, as well as their unsuitability to function as logical\n(Frege 1918/1997, Geach 1957) or mathematical (Frege 1884/1953)\nconcepts, and the symmetry of resemblance (Goodman 1976), convinced\nphilosophers that no theory of mind can get by with only nonconceptual\nrepresentations construed in this way. (For more discussion, see the\nentry on\n nonconceputal mental content.) \nThere has also been dissent from the traditional claim that conceptual\nrepresentations (thoughts, beliefs) lack phenomenology. Chalmers\n(1996), Flanagan (1992), Goldman (1993), Horgan and Tienson (2002),\nJackendoff (1987), Levine (1993, 1995, 2001), McGinn (1991a), Pitt\n(2004, 2009, 2011, 2013), Searle (1992), Siewert (1998, 2011) and\nStrawson (1994, 2010), claim that purely conceptual (conscious)\nrepresentational states themselves have a proprietary kind of\nphenomenology. This view – bread and butter, it should be said,\namong historical and contemporary Phenomenologists – has been\ngaining momentum of late among analytic philosophers of mind. (See,\ne.g., the essays in Bayne and Montague 2011 and Kriegel 2013, and\nChudnoff 2015, Farkas 2008a, Kriegel 2011, Mendelovici 2018, Montague\n2016.) If this claim is correct, the question of what role\nphenomenology plays in the determination of representational content\nre-arises for conceptual representation; and the eliminativist\nambitions of Sellars, Brandom, Rey, et al. would meet a new obstacle.\nIt would also raise prima facie problems for reductive\nrepresentationalism, as well as for reductive naturalistic theories of\nintentional content, and externalism in general. \nThe view that there is a proprietary phenomenology of conscious\nthought – a cognitive (conceptual,\npropositional) phenomenology – claims that there is\nsomething it’s like to occurrently, consciously think a thought\n(entertain a propositional content), which is as different from other\nkinds of phenomenology (visual, auditory, etc.) as they are from each\nother. Opinions diverge, however, with respect to the role such\nphenomenology plays in determining the contents of\nconceptual/propositional representations. Some (e.g., Siewert) claim\nthat it plays no such role. Others (e.g., Horgan and Tienson,\nStrawson) hold that it determines only “narrow” contents,\nfurther, “broad” contents being determined by extrinsic\nrelations to represented objects and properties. Still others (e.g.,\nFarkas 2008b, Pitt) argue that it is the only kind of\nconceptual content, insisting on a sharp distinction between content\n(sense) and reference. There is also disagreement about whether or not\ncognitive phenomenology determines but is distinct from\nconceptual/propositional content (e.g., Pitt 2004) or is identical to\nit (e.g., Pitt 2009).  \nOutstanding challenges for this thesis include unconscious thought\n(which seems to entail the existence of unconscious phenomenology, on\nthis view), indexical concepts (whose content is standardly taken to\nbe referentially individuated; see Pitt 2013 for an attempt to address\nthis challenge), and nominal concepts (concepts expressed by\nutterances of names, likewise standardly referentially\nindividuated). \nSee the entries on\n consciousness and intentionality\n and\n phenomenal intentionality\n for further discussion. \nAmong realists about non-conceptual representations, the central\ndivision is between representationalists (also called\n“representationists” and “intentionalists”)\n– e.g., Dretske (1995), Harman (1990), Leeds (1993), Lycan\n(1987, 1996), Rey (1991), Thau (2002), Tye (1995, 2000, 2009) –\nand phenomenalists (also called “phenomenists”)\n– e.g., Block (1996, 2003), Chalmers (1996, 2004), Evans (1982),\nLoar (2003a, 2003b), Peacocke (1983, 1989, 1992, 2001), Raffman\n(1995), Shoemaker (1990). Representationalists claim that the\nphenomenal content of a non-conceptual representation – i.e.,\nits phenomenal character – is reducible to a kind of intentional\ncontent, naturalistically construed (à la Dretske). On this\nview, phenomenal contents are extrinsic properties represented by\nnon-conceptual representations. In contrast, phenomenalists claim that\nthe phenomenal content of a non-conceptual mental representation is\nidentical to its intrinsic phenomenal properties. \nThe representationalist thesis is often formulated as the claim that\nphenomenal properties are representational or intentional. However,\nthis formulation is ambiguous between a reductive and a non-reductive\nclaim (though the term ‘representationalism’ is most often\nused for the reductive claim. See Chalmers 2004a). As a reductive\nclaim, it means that the phenomenal content of an experience, the\nproperties that characterize what it is like to have it (i.e.,\nqualia), are certain extrinsic properties it represents. For\nexample, the blueness one might mention in describing one’s\nexperience (perceptual representation) of a clear sky at noon is a\nproperty of the sky, not of one’s experience of it. Blueness is\nrelevant to the characterization of one’s experience because\none’s experience represents it, not because one’s\nexperience instantiates it. An experience of the sky no more\ninstantiates blueness than a thought that snow is cold instantiates\ncoldness. On this view, the phenomenal content of sensory experience\nis explained as its representation of extrinsic properties. (See Byrne\nand Tye 2006, Dretske 1995, Harman 1990, Lycan 1987, 1996 and Tye\n2014, 2015 for elaboration and defense of this “qualia\nexternalism.” See Thompson 2008 and Pitt 2017 for objections to\nthis account.) (See also the entry on\n representational theories of consciousness.) \nAs a non-reductive claim, it means that the phenomenal content of an\nexperience is its intrinsic subjective phenomenal properties, which\nare themselves representational. One’s experience of the sky\nrepresents its color by instantiating phenomenal blueness. Among\nphenomenalists there is disagreement over whether non-conceptual\nrepresentation requires complex structuring of phenomenal properties\n(Block and Peacocke, op. cit., Robinson 1994) or not (Loar 2003b).\nSo-called “Ganzfeld” experiences, in which, for example,\nthe visual field is completely taken up with a uniform experience of a\nsingle color, are a standard test case: Do Ganzfeld experiences\nrepresent anything? (It may be that doubts about the\nrepresentationality of such experiences are simply a consequence of\nthe fact that (outside of the laboratory) we never encounter things\nthat would produce them. Supposing we routinely did (and especially if\nwe had names for them), it seems unlikely such skepticism would\narise.) \nMost (reductive) representationalists are motivated by the conviction\nthat one or another naturalistic explanation of intentionality (see\nthe next section) is, in broad outline, correct, and by the desire to\ncomplete the naturalization of the mental by applying such theories to\nthe problem of phenomenality. (Needless to say, many phenomenalists\nare just as eager to naturalize the phenomenal – though not in\nthe same way.) \nThe main argument for representationalism appeals to the\ntransparency of experience (cf. Tye 2000: 45–51). The\nproperties that characterize what it’s like to have a sensory\nexperience are presented in experience as properties of objects\nperceived: in attempting to attend to an experience, one seems to\n“see through it” to the objects and properties it is\nexperiences\n of.[2]\n They are not presented as properties of the experience itself. If\nnonetheless they were properties of the experience,\nperception would be massively deceptive. But perception is not\nmassively deceptive. In veridical perception, these properties are\nlocally instantiated; in illusion and hallucination, they are not. On\nthis view, introspection is indirect perception: one comes to know\nwhat phenomenal features one’s experience has by coming to know\nwhat objective features it represents. (Cf. also Dretske 1996,\n1999.) \nIn order to account for the intuitive differences between conceptual\nand sensory representations, representationalists appeal to structural\nor functional properties. Dretske (1995), for example, distinguishes\nexperiences and thoughts on the basis of the origin and nature of\ntheir functions: an experience of a property P is a state of\na system whose evolved function is to indicate the presence\nof P in the environment; a thought representing the property\nP, on the other hand, is a state of a system whose\nassigned (learned) function is to calibrate the output of the\nexperiential system. Rey (1991) takes both thoughts and experiences to\nbe relations to sentences in the language of thought, and\ndistinguishes them on the basis of (the functional roles of) such\nsentences’ constituent predicates. Lycan (1987, 1996)\ndistinguishes them in terms of their functional-computational\nprofiles. Tye (2000) distinguishes them in terms of their functional\nroles and the intrinsic structure of their vehicles: thoughts are\nrepresentations in a language-like medium, whereas experiences are\nimage-like representations consisting of “symbol-filled\narrays.” (Cf. the account of mental images in Tye 1991.) \nPhenomenalists tend to make use of the same sorts of features\n(function, intrinsic structure) in explaining some of the intuitive\ndifferences between thoughts and experiences; but they do not suppose\nthat such features exhaust the differences between phenomenal and\nnon-phenomenal representations. For the phenomenalist, it is the\nphenomenal properties of experiences – qualia themselves –\nthat constitute the fundamental difference between experience and\nthought. Peacocke (1992), for example, develops the notion of a\nperceptual “scenario” (an assignment of phenomenal\nproperties to coordinates of a three-dimensional egocentric space),\nwhose content is “correct” (a semantic property) if in the\ncorresponding “scene” (the portion of the external world\nrepresented by the scenario) properties are distributed as their\nphenomenal analogues are in the scenario. \nAnother sort of representation appealed to by some phenomenalists\n(e.g., Chalmers (2003), Block (2003)) is what Chalmers calls a\n“pure phenomenal concept.” A phenomenal concept in general\nis a concept whose denotation is a phenomenal property, and it may be\ndiscursive (‘the color of ripe bananas’), demonstrative\n(‘this color’; Loar 1990/96)), or even more\ndirect. On Chalmers’s view, a pure phenomenal concept\nis (something like) a conceptual/phenomenal hybrid consisting of a\nphenomenological “sample” (an image or an occurrent\nsensation) integrated with (or functioning as) a conceptual component\n(see also Balog 1999 and Papineau 2002). Phenomenal concepts are\npostulated to account for the apparent fact (among others) that, as\nMcGinn (1991b) puts it, “you cannot form [introspective]\nconcepts of conscious properties unless you yourself instantiate those\nproperties.” One cannot have a phenomenal concept of a\nphenomenal property P, and, hence, phenomenal\nbeliefs about P, without having experience of\nP, because P itself is (in some way)\nconstitutive of the concept of P. (Cf. Jackson 1982,\n1986 and Nagel 1974.) (The so-called “ phenomenal concept\nstrategy” puts pure phenomenal concepts to use in defending the\nKnowledge Argument against physicalism. See Loar 1990/96, Chalmers\n2004a. Alter and Walter 2007 is an excellent collection of essays on\nphenomenal concepts. See Conee 1994 and Pitt 2019 for skeptical\nresponses to this strategy.) \nThough imagery has played an important role in the history of\nphilosophy of mind, the important contemporary literature on it is\nprimarily psychological. (Tye 1991 and McGinn 2004 are notable recent\nexceptions.) In a series of psychological experiments done in the\n1970s (summarized in Kosslyn 1980 and Shepard and Cooper 1982),\nsubjects’ response time in tasks involving mental manipulation\nand examination of presented figures was found to vary in proportion\nto the spatial properties (size, orientation, etc.) of the figures\npresented. The question of how these experimental results are to be\nexplained kindled a lively debate on the nature of imagery and\nimagination. \nKosslyn (1980) claims that the results suggest that the tasks were\naccomplished via the examination and manipulation of mental\nrepresentations that themselves have spatial properties – i.e.,\npictorial representations, or images. Others,\nprincipally Pylyshyn (1979, 1981a, 1981b, 2003), argue that the\nempirical facts can be explained in terms exclusively of\ndiscursive, or propositional representations and\ncognitive processes defined over them. (Pylyshyn takes such\nrepresentations to be sentences in a language of thought.) \nThe idea that pictorial representations are literally\npictures in the head is not taken seriously by proponents of\nthe pictorial view of imagery (see, e.g., Kosslyn and Pomerantz 1977).\nThe claim is, rather, that mental images represent in a way that is\nrelevantly like the way pictures represent. (Attention has\nbeen focused on visual imagery – hence the designation\n‘pictorial’; though of course there may be imagery in\nother modalities – auditory, olfactory, etc. – as well.\nSee O’Callaghan 2007 for discussion of auditory imagery.) \nThe distinction between pictorial and discursive representation can be\ncharacterized in terms of the distinction between analog and\ndigital representation (Goodman 1976). This distinction has\nitself been variously understood (Fodor & Pylyshyn 1981, Goodman\n1976, Haugeland 1981, Lewis 1971, McGinn 1989), though a widely\naccepted construal is that analog representation is continuous (i.e.,\nin virtue of continuously variable properties of the representation),\nwhile digital representation is discrete (i.e., in virtue of\nproperties a representation either has or doesn’t have) (Dretske\n1981). (An analog/digital distinction may also be made with respect to\ncognitive processes. (Block 1983.)) On this understanding of\nthe analog/digital distinction, imagistic representations, which\nrepresent in virtue of properties that may vary continuously (such as\nbeing more or less bright, loud, vivid, etc.), would be analog, while\nconceptual representations, whose properties do not vary continuously\n(a thought cannot be more or less about Elvis: either it is or it is\nnot) would be digital. \nIt might be supposed that the pictorial/discursive distinction is best\nmade in terms of the phenomenal/non-phenomenal distinction, but it is\nnot obvious that this is the case. For one thing, there may be\nnon-phenomenal properties of representations that vary continuously.\nMoreover, there are ways of understanding pictorial representation\nthat presuppose neither phenomenality nor analogicity. According to\nKosslyn (1980, 1982, 1983), a mental representation is\n“quasi-pictorial” when every part of the representation\ncorresponds to a part of the object represented, and relative\ndistances between parts of the object represented are preserved among\nthe parts of the representation. But distances between parts of a\nrepresentation can be defined functionally rather than spatially\n– for example, in terms of the number of discrete computational\nsteps required to combine stored information about them. (Cf. Rey\n1981.) \nTye (1991) proposes a view of images on which they are hybrid\nrepresentations, consisting both of pictorial and discursive elements.\nOn Tye’s account, images are “(labeled) interpreted\nsymbol-filled arrays.” The symbols represent discursively, while\ntheir arrangement in arrays has representational significance (the\nlocation of each “cell” in the array represents a specific\nviewer-centered 2-D location on the surface of the imagined\nobject). \nSee the entry on\n mental imagery\n for further discussion. \nThe contents of mental representations are typically taken to be\nabstract objects (properties, relations, propositions, sets, etc.). A\npressing question, especially for the naturalist, is how mental\nrepresentations come to have their contents. Here the issue is not how\nto naturalize content (abstract objects can’t be\nnaturalized), but, rather, how to specify naturalistic\ncontent-determining relations between mental representations\nand the abstract objects they express. There are two basic types of\ncontemporary naturalistic theories of content-determination and\ncausal-informational and\n functional.[3] \nCausal-informational theories (Dretske 1981, 1988, 1995) hold that the\ncontent of a mental representation is grounded in the information it\ncarries about what does (Devitt 1996) or would\n(Fodor 1987, 1990a) cause it to\n occur.[4]\n There is, however, widespread agreement that causal-informational\nrelations are not sufficient to determine the content of mental\nrepresentations. Such relations are common, but representation is not.\nTree trunks, smoke, thermostats and ringing telephones carry\ninformation about what they are causally related to, but they do not\nrepresent (in the relevant sense) what they carry information about. A\nmental representation can be caused by something it does not\nrepresent, and can represent something that has not caused it, whereas\nnothing can be caused by something that doesn’t cause it. \nThe main attempts to specify what makes a causal-informational state a\nmental representation are Asymmetric Dependency Theories\n(e.g., Fodor 1987, 1990a, 1994) and Teleological Theories\n(Dretske 1988, 1995, Fodor 1990b, Millikan 1984, Neander 2017,\nPapineau 1987). The Asymmetric Dependency Theory distinguishes merely\ninformational relations from representational relations on the basis\nof their higher-order relations to each other: informational relations\ndepend upon representational relations, but not vice versa. For\nexample, if tokens of a mental state type are reliably caused by\nhorses, cows-on-dark-nights, zebras-in-the-mist and Great Danes, then\nthey carry information about horses, etc. If, however, such tokens are\ncaused by cows-on-dark-nights, etc. because they were caused\nby horses, but not vice versa, then they represent horses (or the\nproperty horse). \nAccording to Teleological Theories, representational relations are\nthose a representation-producing mechanism has the selected\n(by evolution or learning) function of establishing. For\nexample, zebra-caused horse-representations do not mean\nzebra, because the mechanism by which such tokens are\nproduced has the selected function of indicating horses, not zebras.\nThe horse-representation-producing mechanism that responds to zebras\nis malfunctioning. \nSee the entries on\n  teleological theories of mental content\n and\n  causal theories of mental content. \nFunctional theories (Block 1986, Harman 1973), hold that the content\nof a mental representation is determined, at least in part, by its\n(causal, computational, inferential) relations to other mental\nrepresentations. They differ on whether relata should include all\nother mental representations or only some of them, and on whether to\ninclude external states of affairs. The view that the content of a\nmental representation is determined by its inferential/computational\nrelations with all other representations is holism;\nthe view it is determined by relations to only some other\nmental states is localism (or molecularism). (The\nnon-functional view that the content of a mental state depends on\nnone of its relations to other mental states is\natomism.) Functional theories that recognize no\ncontent-determining external relata have been called\nsolipsistic (Harman 1987). Some theorists posit distinct\nroles for internal and external connections, the former determining\nsemantic properties analogous to sense, the latter determining\nsemantic properties analogous to reference (McGinn 1982, Sterelny\n1989). \n(Reductive) representationalists (Dretske, Lycan, Tye) usually take\none or another of these theories to provide an explanation of the\n(non-conceptual) content of experiential states. They thus tend to be\nexternalists (see the next section) about phenomenological as well as\nconceptual content. Phenomenalists and non-reductive\nrepresentationalists (Block, Chalmers, Loar, Peacocke, Siewert), on\nthe other hand, take it that the representational content of such\nstates is (at least in part) determined by their intrinsic phenomenal\nproperties. Further, those who advocate a phenomenally-based approach\nto conceptual content (Horgan and Tienson, Kriegel, Loar,\nPitt, Searle, Siewert) also seem to be committed to internalist\nindividuation of the content (if not the reference) of such\nstates. \nPersistent indeterminacy problems with\ncausal-informational-teleological theories of content determination\nhave motivated a growing number of (analytic) philosophers to seek a\ndifferent approach, grounded not in external relations of\nrepresentational states but in their intrinsic phenomenal properties.\nThis approach has come to be known as the “Phenomenal\nIntentionality Research Program” (Kriegel 2013), or, simply\n“Phenomenal Intentionality.” These philosophers (including\nBourget, Kriegel, Loar, Mendelovici, Montague, Pitt, Searle, Smithies\n(2012, 2013a and b, 2019), Strawson and Siewert), argue that\ncausal-informational-teleological relations cannot yield the\nfine-grained, determinate content conceptual and perceptual\nrepresentations possess, and that such content can only be delivered\nby phenomenal character. The cognitive phenomenology thesis (discussed\nabove) is an important component of this overall approach.  \nGenerally, those who, like informational theorists, think relations to\none’s (natural or social) environment are (at least partially)\ndeterminative of the content of mental representations are\nexternalists, or anti-individualists (e.g., Burge\n1979, 1986b, 2010, McGinn 1977), whereas those who, like some\nproponents of functional theories, think representational content is\ndetermined by an individual’s intrinsic properties alone, are\ninternalists (or individualists; cf. Putnam 1975,\nFodor\n 1981c).[5] \nThis issue is widely taken to be of central importance, since\npsychological explanation, whether commonsense or scientific, is\nsupposed to be both causal and content-based. (Beliefs and desires\ncause the behaviors they do because they have the contents they do.\nFor example, the desire that one have a beer and the beliefs\nthat there is beer in the refrigerator and that the\nrefrigerator is in the kitchen may explain one’s getting up\nand going to the kitchen.) If, however, a mental\nrepresentation’s having a particular content is due to factors\nextrinsic to it, it is unclear how its having that content\ncould determine its causal powers, which, arguably, must be intrinsic\n(see Stich 1983, Fodor 1982, 1987, 1994). Some who accept the standard\narguments for externalism have argued that internal factors determine\na component of the content of a mental representation. They\nsay that mental representations have both “narrow” content\n(determined by intrinsic factors) and “wide” or\n“broad” content (determined by narrow content plus\nextrinsic factors). (This distinction may be applied to the\nsub-personal representations of cognitive science as well as to those\nof commonsense psychology. See von Eckardt 1993: 189.) \nNarrow content has been variously construed. Putnam (1975), Fodor\n(1982: 114; 1994: 39ff), and Block (1986: 627ff), for example, seem to\nunderstand it as something like de dicto content (i.e.,\nFregean sense, or perhaps character, à la\nKaplan 1989). On this construal, narrow content is context-independent\nand directly expressible. Fodor (1987) and Block (1986), however, have\nalso characterized narrow content as radically inexpressible.\nOn this construal, narrow content is a kind of proto-content, or\ncontent-determinant, and can be specified only indirectly, via\nspecifications of context/wide-content pairings. On both construals,\nnarrow contents are characterized as functions from context to (wide)\ncontent. The narrow content of a representation is determined by\nproperties intrinsic to it or its possessor, such as its syntactic\nstructure or its intramental computational or inferential role. \nBurge (1986b) has argued that causation-based worries about\nexternalist individuation of psychological content, and the\nintroduction of the narrow notion, are misguided. Fodor (1994, 1998)\nhas more recently urged that a scientific psychology might not need\nnarrow content in order to supply naturalistic (causal) explanations\nof human cognition and action, since the sorts of cases they were\nintroduced to handle, viz., Twin-Earth cases and Frege cases, are\neither nomologically impossible or dismissible as exceptions to\nnon-strict psychological laws. \nOn the most common versions of externalism, though intentional\ncontents are externally determined, mental representations themselves,\nand the states they partly constitute, remain “in the\nhead.” More radical versions are possible. One might maintain\nthat since thoughts are individuated by their contents, and some\nthought contents are partially constituted by objects external to the\nmind, then some thoughts are partly constituted by objects external to\nthe mind. On such a view, a singular thought – i.e., a\nthought about a particular object – literally contains\nthe object it is about. It is “object-involving.” Such a\nthought (and the mind that thinks it) thus extend beyond the\nboundaries of the skull. (This appears to be the view articulated in\nMcDowell 1986, on which there is “interpenetration”\nbetween the mind and the world.) \nSee the entries on\n externalism about mental content\n and\n narrow mental content. \nClark and Chalmers (1998) and Clark (2001, 2005, 2008) have argued\nthat mental representations may exist entirely “outside\nthe head.” On their view, which they call “active\nexternalism,” cognitive processes (e.g., calculation) may be\nrealized in external media (e.g., a calculator or pen and paper), and\nthe “coupled system” of the individual mind and the\nexternal workspace ought to count as a cognitive system – a mind\n–in its own right. Symbolic representations on external media\nwould thus count as mental representations. \nClark and Chalmers’s paper has inspired a burgeoning literature\non extended, embodied and interactive cognition. (Menary 2010 is a\nrecent collection of essays. See also the entry on\n embodied cognition.) \nThe leading contemporary version of the Representational Theory of\nMind, the Computational Theory of Mind (CTM), claims that the brain is\na kind of computer and that mental processes are computations.\nAccording to CTM, cognitive states are constituted by computational\nrelations to mental representations of various kinds, and cognitive\nprocesses are sequences of such states. \nCTM develops RTM by attempting to explain all psychological\nstates and processes in terms of mental representation. In the course\nof constructing detailed empirical theories of human and other animal\ncognition, and developing models of cognitive processes implementable\nin artificial information processing systems, cognitive scientists\nhave proposed a variety of types of mental representations. While some\nof these may be suited to be mental relata of commonsense\npsychological states, some – so-called “subpersonal”\nor “sub-doxastic” representations – are not. Though\nmany philosophers believe that CTM can provide the best scientific\nexplanations of cognition and behavior, there is disagreement over\nwhether such explanations will vindicate the commonsense psychological\nexplanations of prescientific RTM. \nAccording to Stich’s (1983) Syntactic Theory of Mind, for\nexample, computational theories of psychological states should concern\nthemselves only with the formal properties of the objects\nthose states are relations to. Commitment to the explanatory relevance\nof content, however, is for most cognitive scientists\nfundamental (Fodor 1981a, Pylyshyn 1984, Von Eckardt 1993). That\nmental processes are computations, that computations are rule-governed\nsequences of semantically evaluable objects, and that the\nrules apply to the symbols in virtue of their content, are central\ntenets of mainstream cognitive science. \nExplanations in cognitive science appeal to a many different kinds of\nmental representation, including, for example, the “mental\nmodels” of Johnson-Laird 1983, the “retinal arrays,”\n“primal sketches” and “2½-D sketches”\nof Marr 1982, the “frames” of Minsky 1974, the\n“sub-symbolic” structures of Smolensky 1989, the\n“quasi-pictures” of Kosslyn 1980, and the\n“interpreted symbol-filled arrays” of Tye 1991 – in\naddition to representations that may be appropriate to the explanation\nof commonsense psychological states. Computational explanations have\nbeen offered of, among other mental phenomena, belief (Fodor 1975,\n2008 Field 1978), visual perception (Marr 1982, Osherson, et al.\n1990), rationality (Newell and Simon 1972, Fodor 1975, Johnson-Laird\nand Wason 1977), language learning and use (Chomsky 1965, Pinker\n1989), and musical comprehension (Lerdahl and Jackendoff 1983). \nA fundamental disagreement among proponents of CTM concerns the\nrealization of personal-level representations (e.g., thoughts) and\nprocesses (e.g., inferences) in the brain. The central debate here is\nbetween proponents of Classical Architectures and proponents\nof Connectionist Architectures. \nThe classicists (e.g., Turing 1950, Fodor 1975, 2000, 2003, 2008,\nFodor and Pylyshyn 1988, Marr 1982, Newell and Simon 1976) hold that\nmental representations are symbolic structures, which\ntypically have semantically evaluable constituents, and that mental\nprocesses are rule-governed manipulations of them that are sensitive\nto their constituent structure. The connectionists (e.g., McCulloch\n& Pitts 1943, Rumelhart 1989, Rumelhart and McClelland 1986,\nSmolensky 1988) hold that mental representations are realized by\npatterns of activation in a network of simple processors\n(“nodes”) and that mental processes consist of the\nspreading activation of such patterns. The nodes themselves are,\ntypically, not taken to be semantically evaluable; nor do the patterns\nhave semantically evaluable constituents. (Though there are versions\nof Connectionism – “localist” versions – on\nwhich individual nodes are taken to have semantic properties (e.g.,\nBallard 1986.) It is arguable, however,\nthat localist theories are neither definitive nor representative of\nthe connectionist program (Smolensky 1988, 1991, Chalmers 1993).) \nClassicists are motivated (in part) by properties thought seems to\nshare with language. Fodor’s Language of Thought Hypothesis\n(LOTH) (Fodor 1975, 1987, 2008), according to which the system of\nmental symbols constituting the neural basis of thought is structured\nlike a language, provides a well-worked-out version of the classical\napproach as applied to commonsense psychology. (Cf. also Marr 1982 for\nan application of classical approach in scientific psychology.)\nAccording to the LOTH, the potential infinity of complex\nrepresentational mental states is generated from a finite stock of\nprimitive representational states, in accordance with recursive\nformation rules. This combinatorial structure accounts for the\nproperties of productivity and systematicity of the\nsystem of mental representations. As in the case of symbolic\nlanguages, including natural languages (though Fodor does not suppose\neither that the LOTH explains only linguistic capacities or that only\nverbal creatures have this sort of cognitive architecture), these\nproperties of thought are explained by appeal to the content of the\nrepresentational units and their combinability into contentful\ncomplexes. That is, the semantics of both language and thought is\ncompositional: the content of a complex representation is\ndetermined by the contents of its constituents and their structural\nconfiguration. (See, e.g.,Fodor and Lepore 2002.)  \nConnectionists are motivated mainly by a consideration of the\narchitecture of the brain, which apparently consists of layered\nnetworks of interconnected neurons. They argue that this sort of\narchitecture is unsuited to carrying out classical serial\ncomputations. For one thing, processing in the brain is typically\nmassively parallel. In addition, the elements whose manipulation\ndrives computation in connectionist networks (principally, the\nconnections between nodes) are neither semantically compositional nor\nsemantically evaluable, as they are on the classical approach. This\ncontrast with classical computationalism is often characterized by\nsaying that representation is, with respect to computation,\ndistributed as opposed to local: representation is\nlocal if it is computationally basic; and distributed if it is not.\n(Another way of putting this is to say that for classicists mental\nrepresentations are computationally atomic, whereas for\nconnectionists they are not.) \nMoreover, connectionists argue that information processing as it\noccurs in connectionist networks more closely resembles some features\nof actual human cognitive functioning. For example, whereas on the\nclassical view learning involves something like hypothesis formation\nand testing (Fodor 1981c), on the connectionist model it is a matter\nof evolving distribution of “weights” (strengths) on the\nconnections between nodes, and typically does not involve the\nformulation of hypotheses regarding the identity conditions for the\nobjects of knowledge. The connectionist network is “trained\nup” by repeated exposure to the objects it is to learn to\ndistinguish; and, though networks typically require many more\nexposures to the objects than do humans, this seems to model at least\none feature of this type of human learning quite well. (Cf. the sonar\nexample in Churchland 1989.) \nFurther, degradation in the performance of such networks in response\nto damage is gradual, not sudden as in the case of a classical\ninformation processor, and hence more accurately models the loss of\nhuman cognitive function as it typically occurs in response to brain\ndamage. It is also sometimes claimed that connectionist systems show\nthe kind of flexibility in response to novel situations typical of\nhuman cognition – situations in which classical systems are\nrelatively “brittle” or “fragile.” \nSome philosophers have maintained that connectionism entails that\nthere are no propositional attitudes. Ramsey, Stich and Garon (1990)\nhave argued that if connectionist models of cognition are basically\ncorrect, then there are no discrete representational states as\nconceived in ordinary commonsense psychology and classical cognitive\nscience. Others, however (e.g., Smolensky 1989), hold that certain\ntypes of higher-level patterns of activity in a neural network may be\nroughly identified with the representational states of commonsense\npsychology. Still others (e.g., Fodor & Pylyshyn 1988, Heil 1991,\nHorgan and Tienson 1996) argue that language-of-thought style\nrepresentation is both necessary in general and realizable within\nconnectionist architectures. (MacDonald & MacDonald 1995 collects\nthe central contemporary papers in the classicist/connectionist\ndebate, and provides useful introductory material as well. See also\nVon Eckardt 2005.) \nWhereas Stich (1983) accepts that mental processes are computational,\nbut denies that computations are sequences of mental representations,\nothers accept the notion of mental representation, but deny that CTM\nprovides the correct account of mental states and processes. \nVan Gelder (1995) denies that psychological processes are\ncomputational. He argues that cognitive systems are dynamic,\nand that cognitive states are not relations to mental symbols, but\nquantifiable states of a complex system consisting of (in the case of\nhuman beings) a nervous system, a body and the environment in which\nthey are embedded. Cognitive processes are not rule-governed sequences\nof discrete symbolic states, but continuous, evolving total states of\ndynamic systems determined by continuous, simultaneous and mutually\ndetermining states of the systems’ components. Representation in\na dynamic system is essentially information-theoretic, though the\nbearers of information are not symbols, but state variables or\nparameters. (See also Port and Van Gelder 1995; Clark 1997a, 1997b,\n2008.) \nHorst (1996), on the other hand, argues that though computational\nmodels may be useful in scientific psychology, they are of no help in\nachieving a philosophical understanding of the intentionality of\ncommonsense mental states. CTM attempts to reduce the\nintentionality of such states to the intentionality of the mental\nsymbols they are relations to. But, Horst claims, the relevant notion\nof symbolic content is essentially bound up with the notions of\nconvention and intention. So CTM involves itself in a vicious\ncircularity: the very properties that are supposed to be reduced are\n(tacitly) appealed to in the reduction. \nSee the entries on the\n computational theory of mind\n and\n computational theory of mind.\n  \nTo say that a mental object has semantic properties is,\nparadigmatically, to say that it is about, or true or false\nof, an object or objects, or that it is true or false\nsimpliciter. Suppose I think that democracy is dying. I am\nthinking about democracy, and if what I think of it (that it is dying)\nis true of it, then my thought is true. According to RTM such states\nare to be explained as relations between agents and mental\nrepresentations. To think that democracy is dying is to token in some\nway a mental representation whose content is that democracy is dying.\nOn this view, the semantic properties of mental states are the\nsemantic properties of the representations they are relations to. \nLinguistic acts seem to share such properties with mental states.\nSuppose I say that democracy is dying. I am talking about\ndemocracy, and if what I say of it (that it is dying) is true of it,\nthen my utterance is true. Now, to say that democracy is dying is (in\npart) to utter a sentence that means that democracy is dying. Many\nphilosophers have thought that the semantic properties of linguistic\nexpressions are inherited from the intentional mental states they are\nconventionally used to express (Grice 1957, Fodor 1978,\nSchiffer1972/1988, Searle 1983). On this view, the semantic properties\nof linguistic expressions are the semantic properties of the\nrepresentations that are the mental relata of the states they are\nconventionally used to express. Fodor has famously argued that these\nstates themselves have a language-like structure. (See the entry on\nthe\n  language of thought hypothesis.)\n  \n(Others, however, e.g., Davidson (1975, 1982) have suggested that the\nkind of thought human beings are capable of is not possible without\nlanguage, so that the dependency might be reversed, or somehow mutual\n(see also Sellars 1956). (But see Martin 1987 for a defense of the\nclaim that thought is possible without language. See also Chisholm and\nSellars 1958.) Schiffer (1987) subsequently despaired of the success\nof what he calls “Intention-Based Semantics.”) \nIt is also widely held that in addition to having such properties as\nreference, truth-conditions and truth – so-called\nextensional properties – expressions of natural\nlanguages also have intensional properties, in virtue of\nexpressing properties or propositions – i.e., in virtue of\nhaving meanings or senses, where two expressions may\nhave the same reference, truth-conditions or truth value, yet express\ndifferent properties or propositions (Frege 1892/1997). If the\nsemantic properties of natural-language expressions are inherited from\nthe thoughts and concepts they express (or vice versa, or both), then\nan analogous distinction may be appropriate for mental\nrepresentations.","contact.mail":"dalanpitt@yahoo.com","contact.domain":"yahoo.com"}]
