[{"date.published":"2007-08-09","date.changed":"2017-08-16","url":"https://plato.stanford.edu/entries/scientific-unity/","author1":"Jordi Cat","entry":"scientific-unity","body.text":"\n\n\n\nThe topic of unity in the sciences can be explored through the\nfollowing questions: Is there one privileged, most basic or\nfundamental concept or kind of thing, and if not, how are the\ndifferent concepts or kinds of things in the universe related? Can the\nvarious natural sciences (e.g.,physics, astronomy, chemistry, biology)\nbe unified into a single overarching theory, and can theories within a\nsingle science (e.g., general relativity and quantum theory in\nphysics, or models of evolution and development in biology) be\nunified? Are theories or models the relevant connected units? What\nother connected or connecting units are there? Does the unification of\nthese parts of science involve only matters of fact or are matters of\nvalue involved as well? What about matters of method, material,\ninstitutional, ethical and other aspects of intellectual cooperation?\nMoreover, what kinds of unity, not just units, in the sciences are\nthere? And is the relation of unification one of reduction,\ntranslation, explanation, logical inference, collaboration or\nsomething else? What roles can unification play in scientific\npractices, their development, application and evaluation? \n\nUnity has a history as well as a logic. Different formulations and\ndebates express intellectual and other resources and interests in\ndifferent contexts. Questions about unity belong partly in a tradition\nof thought that can be traced back to pre-Socratic Greek cosmology, in\nparticular to the preoccupation with the question of the One and the\nMany. In what senses are the world and, as a result, our knowledge of\nit one? A number of representations of the world in terms of a few\nsimple constituents that were considered fundamental emerged:\nParmenides’ static substance, Heraclitus’ flux of\nbecoming, Empedocles’ four elements, Democritus’ atoms, or\nPythagoras’ numbers, Plato’s forms, and Aristotle’s\ncategories. The underlying question of the unity of our types of\nknowledge was explicitly addressed by Plato in the\nSophist as follows: “Knowledge also is surely one, but\neach part of it that commands a certain field is marked off and given\na special name proper to itself. Hence language recognizes many arts\nand many forms of knowledge” (Sophist, 257c). Aristotle\nasserted in On the Heavens that knowledge concerns what is\nprimary, and different “sciences” know different kinds of\ncauses; it is metaphysics that comes to provide knowledge of the\nunderlying kind. \nWith the advent and expansion of Christian monotheism, the\norganization of knowledge reflected the idea of a world governed by\nthe laws dictated by God, its creator and legislator. From this\ntradition emerged encyclopedic efforts such as the\nEtymologies, compiled in the sixth century by the Andalusian\nIsidore, Bishop of Seville, the works of the Catalan Ramon Llull in\nthe Middle Ages and those of the Frenchman Petrus Ramus in the\nRenaissance. Llull introduced iconic tree-diagrams and\nforest-encyclopedias representing the organization of different\ndisciplines including law, medicine, theology and logic. He also\nintroduced more abstract diagrams—not unlike some found in\nCabbalistic and esoteric traditions—in an attempt to\ncombinatorially encode the knowledge of God’s creation in a\nuniversal language of basic symbols. Their combination would be\nexpected to generate knowledge of the secrets of creation and help\narticulate knowledge of universal order (mathesis\nuniversalis), which would, in turn, facilitate communication with\ndifferent cultures and their conversion to Christianity. Ramus\nintroduced diagrams representing dichotomies and gave prominence to\nthe view that the starting point of all philosophy is the\nclassification of the arts and sciences. The encyclopedia organization\nof knowledge served the project of its preservation and\ncommunication. \nThe emergence of a distinctive tradition of scientific thought\naddressed the question of unity through the designation of a\nprivileged method, which involved a privileged language and set of\nconcepts. Formally, at least, it was modeled after the Euclidean ideal\nof a system of geometry. In the late 16th century, Francis Bacon held\nthat one unity of the sciences was the result of our organization of\nrecords of discovered material facts in the form of a pyramid with\ndifferent levels of generalities. These could be classified in turn\naccording to disciplines linked to human faculties. Concomitantly, the\ncontrolled interaction with phenomena of study characterized so-called\nexperimental philosophy. In accordance with at least three\ntraditions—the Pythagorean tradition, the Bible’s dictum\nin the Book of Wisdom and the Italian commercial tradition of\nbookkeeping—, Galileo proclaimed at the turn of the 17th century\nthat the Book of Nature had been written by God in the language of\nmathematical symbols and geometrical truths; and that in it, the story\nof Nature’s laws was told in terms of a reduced set of\nobjective, quantitative primary qualities: extension, quantity of\nmatter and motion. A persisting rhetorical role for some form of\ntheological unity of creation should not be neglected when considering\npre-20th-century attempts to account for the possibility and\ndesirability of some form of scientific knowledge. Throughout the 17th\ncentury, mechanical philosophy and Descartes’ and Newton’s\nsystematization from basic concepts and first laws of mechanics became\nthe most promising framework for the unification of natural\nphilosophy. After the demise of Laplacian molecular physics in the\nfirst half of the 19th century, this role was taken over by ether\nmechanics and, unifying forces and matter, energy physics. \nDescartes and Leibniz gave this tradition a rationalist twist that was\ncentered on the powers of human reason and the ideal of system of\nknowledge, on a foundation of rational principles. It became the\nproject of a universal framework of exact categories and ideas,\na mathesis universalis (Garber 1992 and Gaukroger\n2002). Adapting the scholastic image of knowledge, Descartes proposed\nan image of a tree in which metaphysics is depicted by the roots,\nphysics by the trunk, and the branches depict mechanics, medicine and\nmorals. Leibniz proposed a\ngeneral science in the form of a demonstrative\nencyclopedia. This would be based on a “catalogue of simple\nthoughts” and an algebraic language of symbols,\ncharacteristica universalis, which would render all knowledge\ndemonstrative and allow disputes to be resolved by precise\ncalculation. Both defended the program of founding much of physics on\nmetaphysics and ideas from life science (Smith 2011) (Leibniz’s\nunifying ambitions with symbolic language and physics extended beyond\nscience, to settle religious and political fractures in Europe). By\ncontrast, while sharing a model of geometric axiomatic structure of\nknowledge, Newton’s project of natural philosophy was meant to be\nautonomous from a system of philosophy and, in the new context, still\nendorsed for its model of organization and its empirical reasoning\nvalues of formal synthesis and ontological simplicity (see the entry\non\n Newton\n and Janiak 2008). \nBelief in the unity of science or knowledge, along with the\nuniversality of rationality, was at its strongest during the European\nEnlightenment. The most important expression of the encyclopedic\ntradition came in the mid-eighteenth century from Diderot and\nD’Alembert, editors of the Encyclopédie, ou\ndictionnaire raisonné des sciences, des arts et des\nmétiers (1751–1772). Following earlier\nclassifications by Nichols and Bacon, their diagram presenting the\nclassification of intellectual disciplines was organized in terms of a\nclassification of human faculties. Diderot stressed in his own entry,\n“Encyclopaedia”, that the word signifies the unification\nof the sciences. The function of the encyclopedia was to exhibit the\nunity of human knowledge. Diderot and D’Alembert, in contrast\nwith Leibniz, made classification by subject the primary focus, and\nintroduced cross-references instead of logical connections.  The\nEnlightenment tradition in Germany culminated in Kant’s critical\nphilosophy. \nKant saw as one of the functions of philosophy to determine the\nprecise unifying scope and value of each science. For Kant, the unity\nof science is not the reflection of a unity found in nature, or, even\nless, assumed in a real world behind the apparent phenomena. Rather,\nit has its foundations in the unifying a priori character or function\nof concepts, principles and of Reason itself. Nature is precisely our\nexperience of the world under the universal laws that include some\nsuch concepts. And science, as a system of knowledge, is “a\nwhole of cognition ordered according to principles”, and the\nprinciples on which proper science is grounded are a priori (Preface\nto Metaphysical Foundations of Natural Science). A devoted\nbut not exclusive follower of Newton’s achievements and\ninsights, he maintained through most of his life that mathematization\nand a priori universal laws given by the understanding of it were\npreconditions for genuine scientific character (like Galileo and\nDescartes earlier, and Carnap later, Kant believed that mathematical\nexactness constituted the main condition for the possibility of\nobjectivity). Here Kant emphasized the role of mathematics\ncoordinating a priori cognition and its determined objects of\nexperience. Thus, he contrasted the methods employed by the chemist, a\n“systematic art” organized by empirical regularities, with\nthose employed by the mathematician or physicist, which were organized\nby a priori laws, and held that biology is not reducible to\nmechanics—as the former involves explanations in terms of final\ncauses—(see Critique of Pure Reason, Critique of\nJudgment and Metaphysical Foundations of Natural\nScience). With regards to biology—insufficiently grounded\nin the fundamental forces of matter—its inclusion requires the\nintroduction of the idea of purposiveness (McLaughlin 1991). More\ngenerally, for Kant unity was a regulative principle of reason,\nnamely, an ideal guiding the process of inquiry toward a complete\nempirical science with its empirical concepts and principles grounded\nin the so-called concepts and principles of the understanding that\nconstitute and objectify empirical phenomena (on systematicity as a\ndistinctive aspect of this ideal and on its origin in reason, see\nKitcher 1986 and Hoyningen-Huene 2013). \nKant’s ideas set the frame of reference for discussions of the\nunification of the sciences in German thought throughout the\nnineteenth century (Wood and Hahn 2011). He gave philosophical\ncurrency to the notion of worldview (Weltanschauung) and,\nindirectly, world-picture (Weltbild), establishing among\nphilosophers and scientists the notion of unity of science as an\nintellectual ideal. From Kant, German-speaking Philosophers of Nature\nadopted the image of Nature in terms of interacting forces or powers\nand developed it in different ways; this image found its way to\nBritish natural philosophy. In Great Britain this idealist, unifying\nspirit (and other notions of an idealist and romantic turn) was\narticulated in William Whewell’s philosophy of science. Two\nunifying dimensions are these: his notion of mind-constructed\nfundamental ideas, which form the basis for organizing axioms and\nphenomena and classifying sciences, and the argument for the reality\nof explanatory causes in the form of\nconsilience of induction, wherein a single cause is\nindependently arrived at as the hypothesis explaining different kinds\nof phenomena. \nIn face of expanding researches, the unifying emphasis on\norganization, classification and foundation led to exploring\ndifferences and rationalizing boundaries. The German intellectual\ncurrent culminated in the late nineteenth century in the debates among\nphilosophers such as Windelband, Rickert and Dilthey. In their views\nand those of similar thinkers, a worldview often included elements of\nevaluation and life meaning.  Kant had established the basis for the\nfamous distinction between the natural sciences\n(Naturwissenschaften) and the cultural, or social, sciences\n(Geisteswissesnschaften) popularized in theory of science by\nWilhelm Dilthey and Wilhelm Windelband. Dilthey, Windelband, his\nstudent Heinrich Rickert and Max Weber (although the first two\npreferred Kulturwissenschaften, which excluded psychology)\ndebated over how differences in subject matter between the two kinds\nof sciences forced a distinctive difference between their respective\nmethods. Their preoccupation with the historical dimension of the\nhuman phenomena, along with the Kantian emphasis on the conceptual\nbasis of knowledge, led to the suggestion that the natural sciences\naimed at generalizations about abstract types and properties, whereas\nthe human sciences studied concrete individuals and complexes. The\nhuman case suggested a different approach based on valuation and\npersonal understanding (Weber’s verstehen). For\nRickert, individualized concept formation secured knowledge of\nhistorical individuals by establishing connections to recognized\nvalues (rather than personal valuations). In biology, Ernst Haeckel\ndefended a monistic worldview (Richards 2008). \nThis approach stood in opposition to the prevailing empiricist views\nthat, since the time of Hume, Comte and Mill, held that the moral or\nsocial sciences (even philosophy) relied on conceptual and\nmethodological analogies with geometry and the natural sciences, not\njust astronomy and mechanics, also with biology. In the Baconian\ntradition, Comte emphasized a pyramidal hierarchy of disciplines in\nhis “encyclopedic law” or order, from the most general\nsciences about the simplest phenomena to the most specific sciences\nabout the most complex phenomena, each depending on knowledge from its\nmore general antecedent: from inorganic physical sciences (arithmetic,\ngeometry, mechanics, astronomy, physics and chemistry) to the organic\nphysical ones, such as biology and the new “social\nphysics”, soon to be renamed sociology (Comte 1830–1842).\nMill, instead, pointed to the diversity of methodologies for\ngenerating, organizing and justifying associated knowledge with\ndifferent sciences, natural and human, and the challenges to impose a\nsingle standard (Mill 1843, Book VI). He came to view political\neconomy eventually as an art, a tool for reform more than a system of\nknowledge (Snyder 2006). \nThe Weltbild tradition influenced the physicists Max Planck\nand Ernst Mach, who engaged in a heated debate about the precise\ncharacter of the unified scientific world-picture. Mach’s more\ninfluential view was both phenomenological and Darwinian: the\nunification of knowledge took the form of an analysis of ideas into\nbiologically embodied elementary sensations (neutral monism) and was\nultimately a matter of adaptive economy of thought. Planck adopted a\nrealist view that took science to gradually approach complete truth\nabout the world, and fundamentally adopted the thermodynamical\nprinciples of energy and entropy (on the Mach-Planck debate see\nToulmin 1970). These world-pictures constituted some of the\nalternatives to a long-standing mechanistic view that, since the rise\nof mechanistic philosophy with Descartes and Newton, had informed\nbiology as well as most branches of physics. In the background was the\nperceived conflict between the so-called mechanical and\nelectromagnetic worldviews, which resulted throughout the first two\ndecades of the twentieth century in the work of Albert Einstein\n(Holton 1998).  \nIn the same German tradition and amidst the proliferation of work on\nenergy physics and books on unity of science, the German energeticist\nWilhelm Ostwald declared the 20th century the “Monistic\ncentury”. During the 1904 World’s Fair in St. Louis, the\nGerman psychologist and Harvard professor Hugo Munsterberg organized a\nCongress under the title “Unity of Knowledge”; invited\nspeakers were Ostwald, Ludwig Boltzmann, Ernest Rutherford, Edward\nLeamington Nichols, Paul Langevin and Henri Poincaré. In 1911\nthe International Committee of Monism held its first meeting in\nHamburg, with Ostwald presiding.[1] Two years later it published Ostwald’s\nmonograph, Monism as the Goal of Civilization. In 1912, Mach,\nFelix Klein, David Hilbert, Einstein, and others signed a manifesto\naiming at the development of a comprehensive world-view. Unification\nremained a driving scientific ideal. In the same spirit, Mathieu\nLeclerc du Sablon published his\nL’Unité de la Science (1919), exploring metaphysical\nfoundations, and Johan Hjorst published The Unity of Science\n(1921), sketching out a history of philosophical systems and unifying\nscientific hypotheses. \nThe question of unity engaged science and philosophy alike. In the\n20th century the unity of science became a distinctive theme of the\nscientific philosophy of logical empiricism. Logical\nempiricists—known controversially also as logical\npositivists—and most notably the founding members of the Vienna\nCircle in their Manifesto adopted the Machian banner of “unity\nof science without metaphysics”, a normative criterion of unity\nwith a role in social reform based on the demarcation between science\nand metaphysics: the unity of method and language that included all\nthe sciences, natural and social. A common method did not necessarily\nimply a more substantive unity of content involving theories and their\nconcepts. \nA stronger reductive model within the Vienna Circle was recommended by\nRudolf Carnap in his The Logical Construction of the World\n(1928). While embracing the Kantian connotation of the term\n“constitutive system”, it was inspired by recent formal\nstandards: Hilbert’s axiomatic approach to formulating theories\nin the exact sciences and Frege’s and Russell’s logical\nconstructions in mathematics. It was also predicated on the formal\nvalues of simplicity, rationality, (philosophical) neutrality and\nobjectivity associated with scientific knowledge. In particular,\nCarnap tried to explicate such notions in terms of a rational\nreconstruction of science in terms of a method and a structure based\non logical constructions out of (1) basic concepts in axiomatic\nstructures and (2) rigorous, reductive logical connections between\nconcepts at different levels. \nDifferent constitutive systems or logical constructions would serve\ndifferent (normative) purposes: a theory of science and a theory of\nknowledge. Both foundations raised the issue of the nature and\nuniversality of a physicalist language. \nOne such systems of unified science is the theory of science, in which\nthe construction connects concepts and laws of the different sciences\nat different levels, with physics—with its genuine laws—as\nfundamental, lying at the base of the hierarchy. Because of the\nemphasis on the formal and structural properties of our\nrepresentations, objectivity, rationality and unity go hand in hand.\nCarnap’s formal emphasis developed further in Logical Syntax\nof Language (1934). Alternatively, all scientific concepts could\nbe constituted or constructed in a different system in the protocol\nlanguage out of classes of elementary complexes of experiences,\nscientifically understood, representing experiential concepts.  Carnap\nsubsequently defended the epistemological and methodological\nuniversality of physicalist language and physicalist statements. Unity\nof science in this context was an epistemological project (for a\nsurvey of the epistemological debates, see Uebel 2007; on different\nstrands of the anti-metaphysical normative project of unity see\nFrost-Arnold 2005). \nWhereas Carnap aimed at rational reconstructions, another member of\nthe Vienna Circle, Otto Neurath, favored a more naturalistic and\npragmatic approach, with a less idealized and reductive model of\nunity. His evolving standards of unity were generally motivated by the\ncomplexity of empirical reality and the application of empirical\nknowledge to practical goals. He spoke of an\n“encyclopedia-model”,opposed to the classic ideal of a\npyramidal, reductive “system-model”. The\nencyclopedia-model took into account the presence within science of\nuneliminable and imprecise terms from ordinary language and the social\nsciences and emphasized a unity of language and the local exchanges of\nscientific tools. Specifically, Neurath stressed the\nmaterial-thing-language called “physicalism”, not to be\nconfounded with the emphasis on the vocabulary of physics. its\nmotivation was partly epistemological and Neurath endorsed\nanti-foundationalism: No unified science, like a boat at sea, would\nrest on firm foundations. The scientific spirit abhorred dogmatism.\nThis weaker model of unity emphasized empiricism and the normative\nunity of the natural and the human sciences. \nLike Carnap’s unified reconstructions, Neurath’s had\npragmatic motivations. Unity without reductionism provided a tool for\ncooperation and it was motivated by the need for successful\ntreatment—prediction and control—of complex phenomena in\nthe real world that involved properties studied by different theories\nor sciences (from real forest fires to social policy): unity of\nscience at the point of action (Cat, Cartwright and Chang 1996). It is\nan argument from holism, the counterpart of Duhem’s claim that\nonly clusters of hypotheses are confronted with experience. Neurath\nspoke of a “boat”, a “mosaic”, an\n“orchestration”, and a “universal jargon”.\nFollowing institutions such as the International Committee on Monism\nand the International Council of Scientific Unions, Neurath\nspearheaded a movement for Unity of Science in 1934 that encouraged\ninternational cooperation among scientists and launched the project of\nan International Encyclopedia of Unity of Science. It expressed the\ninternationalism of his socialist convictions and the international\ncrisis that would lead to the Second World War (Kamminga and Somsen\n2016). \nAt the end of the Eighth International Congress of Philosophy, held in\nPrague in September of 1934, Neurath proposed a series of\nInternational Congresses for the Unity of Science. These took place in\nParis, 1935; Copenhagen, 1936; Paris, 1937; Cambridge, England, 1938;\nCambridge, Massachusetts, 1939 and Chicago, 1941. For the organization\nof the congresses and related activities, Neurath founded the Unity of\nScience Institute in 1936, which was renamed in 1937 as the\nInternational Institute for the Unity of Science, alongside the\nInternational Foundation for Visual Education, founded in 1933. The\nInstitute’s executive committee was composed of Neurath, Philip\nFrank and Charles Morris. \nAfter the Second World War, a discussion of unity engaged philosophers\nand scientists in the Inter-Scientific Discussion Group, first the\nScience of Science Discussion Group, in Cambridge, Massachusetts,\n(founded primarily by Philip Frank and Carnap, themselves founders of\nthe Vienna Circle, Quine, Feigl, Bridgman, and the psychologists E.\nBoring and S.S. Stevens in October 1940) which would later become the\nUnity of Science Institute. The group was joined by scientists from\ndifferent disciplines, from quantum mechanics (Kemble and Van Vleck)\nand cybernetics (Wiener) to economics (Morgenstern), as part of what\nwas both a self-conscious extension of the Vienna Circle and a\nreflection of local concerns within a technological culture\nincreasingly dominated by the interest in computers and nuclear\npower. The characteristic feature of the new view of unity was the\nideas of consensus and subsequently, especially within the USI,\ncross-fertilization. These ideas were instantiated in the emphasis on\nscientific operations (operationalism) and the creation of war-boosted\ncross-disciplines such as cybernetics, computation, electro-acoustics,\npsycho-acoustics, neutronics, game theory, and biophysics (Galison\n1998 and Hardcastle 2003). \nIn the late 1960s, Michael Polanyi and Marjorie Grene organized a\nseries of conferences funded by the Ford Foundation on unity of\nscience themes (Grene 1969a, 1969b, 1971). Their general character was\ninterdisciplinary and anti-reductionist. The group was originally\ncalled “Study Group on Foundations of Cultural Unity,” but\nthis was later changed to “Study Group on the Unity of\nKnowledge.” By then, a number of American and international\ninstitutions were already promoting interdisciplinary projects in\nacademic areas (Klein 1990). For both Neurath and Polanyi the\norganization of knowledge and science, the Republic of Science, was\ninseparable from ideals of political organization. \nThe historical introductory sections have aimed to show the\nintellectual centrality, varying formulations, and significance of the\nconcept of unity. The rest of the entry presents a variety of modern\nthemes and views. It will be helpful to introduce a number of broad\ncategories and distinctions that can sort out different kinds of\naccounts and track some relations between them as well as additional\nsignificant philosophical issues. (The categories are not mutually\nexclusive, and they sometimes partly overlap; therefore; while they\nhelp label and characterize different positions, they cannot provide a\nsimple, easy and neatly ordered conceptual map.) \nConnective unity is a weaker notion than the specific ideal of\nreductive unity; this requires asymmetric relations of\nreduction, with assumptions about hierarchies of levels of description\nand the primacy—conceptual, ontological, epistemological, and so\non—of a fundamental representation. The category of connective\nunity helps accommodate and bring attention to the diversity of\nnon-reductive accounts. \nAnother useful distinction is between synchronic and\ndiachronic unity. Synchronic accounts are ahistorical,\nassuming no meaningful temporal relations. Diachronic accounts, by\ncontrast, introduce genealogical hypotheses involving asymmetric\ntemporal and causal relations between entities or states of the\nsystems described. Evolutionary models are of this kind; they may be\nreductive to the extent that the posited original entities are simpler\nand on a lower level of organization and size. Others simply emphasize\nconnection without overall directionality. \nIn general, it is useful to distinguish between ontological\nunity and epistemological unity, even if many accounts\nbear both characteristics and fall under both rubrics. In some cases,\none kind supports the other salient kind in the model. Ontological\nunity is here broadly understood as involving relations between\ndescriptive conceptual elements; in some cases the concepts will\ndescribe entities, facts, properties or relations, and descriptive\nmodels will focus on metaphysical aspects of the unifying connections\nsuch as holism, emergence, or downwards causation. Epistemological\nunity applies to epistemic relations or goals such as\nexplanation. Methodological connections and formal (logical,\nmathematical, etc.) models may belong in this kind. I will not draw\nany strict or explicit distinction between epistemological and\nmethodological dimensions or modes of unity. \nAdditional categories and distinctions include the following:\nvertical unity or inter-level unity is unity of\nelements attached to levels of analysis, composition or organization on a hierarchy, whether for a\nsingle science or more, whereas horizontal unity or\nintra-level unity applies to one single level and to its\ncorresponding kind of system (Wimsatt 2007). Global unity is\nunity of any other variety with a universal quantifier of all kinds of\nelements, aspects or descriptions associated with individual sciences\nas a kind of monism, for instance, taxonomical monism about\nnatural kinds, while local unity applies to a subset\n(Cartwright has distinguished this same-level global form of\nreduction, or \"imperialism\", in Cartwright 1999; see also Mitchell\n2003). Obviously, vertical and horizontal accounts of unity can be\neither global or local. Finally, the rejection of global unity has\nbeen associated with isolationism, keeping independent\ncompeting alternative representations of the same phenomena or\nsystems, as well as local integration, the local connective\nunity of the alternative perspectives. A distinction of methodological\nnature contrasts internal and external perspectives,\naccording to whether the accounts are based naturalistically, on the\nlocal contingent practices of certain scientific communities at a\ngiven time, or based on universal metaphysical assumptions broadly\nmotivated (Ruphy 2017). (Ruphy has criticized Cartwright and Dupré\nfor having adopted external metaphysical positions and defended the\ninternal perspective, also present in the program of the so-called\nMinnesota School, i.e., Kellert et al. 2006.)  \nPhilosophy of science became professionally consolidated in the 1950s\naround a positivist orthodoxy that may be characterized by the\nfollowing set of commitments: a syntactic formal approach to theories,\nlogical deductions and axiomatic systems, a distinction between\ntheoretical and observational vocabularies, and empirical\ngeneralizations. Unity and especially reduction have been understood\nin those terms; specific elements of the dominating accounts would\nstand and fall with the attitudes towards the elements of the\northodoxy mentioned above. First, a reminder:\nReductionism must be distinguished from reduction.\nReductionism is the adoption of reduction as the global ideal of a\nunified structure of scientific knowledge and a measure of its\nprogress towards that ideal. As before, I will consider methodological aspects of unity\nas an extension of epistemological matters, insofar as methodology\nserves epistemology. \nTwo formulations of unification in the logical positivist tradition of\nthe ideal logical structure of science placed the question of unity at\nthe core of philosophy of science: Carl Hempel’s\ndeductive-nomological model of explanation and Ernst Nagel’s\nmodel of reduction. Both are fundamentally epistemological models, and\nboth are specifically explanatory, at least in the sense that\nexplanation serves unification. The emphasis on language and logical\nstructure makes explanatory reduction a form of unity of the\nsynchronic kind. Still, Nagel’s model of reduction is a model of\nscientific structure and explanation as well as of scientific\nprogress. It is based on the problem of relating different theories as\ndifferent sets of theoretical predicates. \nReduction requires two conditions: connectability and\nderivability. Connectability of laws of different theories\nrequires meaning invariance in the form of extensional\nequivalence between descriptions, with bridge principles between\ncoextensive but distinct terms in different theories. \nNagel’s account distinguishes two kinds of\nreductions: homogenous and\nheterogeneous. When both sets of terms overlap, the reduction\nis homogeneous. When the related terms are different, the reduction is\nheterogeneous. Derivability requires a deductive relation between the\nlaws involved. In the quantitative sciences, the derivation often\ninvolved taking a limit. In this sense the reduced science is\nconsidered an approximation to the reducing new one. \nNeo-Nagelian accounts have attempted to solve Nagel’s problem of\nreduction between putatively incompatible theories. Here are a\nfew: \nNagel’s two-term relation account has been modified by weaker\nconditions of analogy and a role for conventions, requiring it to be\nsatisfied not necessarily by the two original theories, \\(T_1\\) and\n\\(T_2\\), which are respectively new and old and more and less general,\nbut by the modified theories \\(T'_1\\) and \\(T'_2\\). Explanatory\nreduction is strictly a four-term relation in which \\(T'_1\\) is\n“strongly analogous” to \\(T_1\\) and corrects, with the\ninsight that the more fundamental theory can offer, the older theory,\n\\(T_2\\), changing it to \\(T'_2\\). Nagel’s account also requires\nthat bridge laws be synthetic identities, in the sense that they be\nfactual, empirically discoverable and testable; in weaker accounts,\nadmissible bridge laws may include elements of convention (Schaffner\n1967; Sarkar 1998). The difficulty lay especially with the task of\nspecifying or giving a non-contextual, transitive account of the\nrelations between \\(T\\) and \\(T'\\) (Wimsatt 1976). \nAn alternative set of semantic and syntactic conditions of reduction\nbears counterfactual interpretations. For instance, syntactic\nconditions in the form of limit relations and ceteris paribus\nassumptions help explain why the reduced theory works where it does\nand fails where it does not (Glymour 1969). \nA different approach to reductionism acknowledges a commitment to\nproviding explanation but rejects the value of a focus on the role of\nlaws. This approach typically draws a distinction between hard\nsciences such as physics and chemistry and special sciences such as\nbiology and the social sciences. It claims that laws that are in a\nsense operative in the hard sciences are not available in the special\nones, or play a more limited and weaker role, and this on account of\nhistorical character, complexity or reduced scope. The rejection of\nempirical laws in biology, for instance, has been argued on grounds of\nhistorical dependence on contingent initial conditions (Beatty 1995),\nand as matter of supervenience (see the entry on\n supervenience)\n of spatio-temporally restricted functional claims on lower level\nmolecular ones, and the multiple realization (see the entry on\n multiple realizability)\n of the former by the latter (Rosenberg 1994; Rosenberg’s argument\nfrom supervenience to reduction without laws must be contrasted with\nFodor’s physicalism about the special sciences about laws without\nreduction (see below and the entry on\n physicalism);\n for a criticism of these views see Sober 1996). This non-Nagelian\napproach assumes further that explanation rests on identities\nbetween predicates and deductive derivations (reduction and\nexplanation might be said to be justified by derivations, but not\nconstituted by them; see Spector 1978). Explanation is provided by lower-level\nmechanisms; their explanatory role is to replace final why-necessarily\nquestions (functional) with proximate how-possibly questions\n(molecular). \nOne suggestion to make sense of the possibility of the supervening\nfunctional explanations without Nagelian reduction is a metaphysical\npicture of composition of powers in explanatory mechanisms (Gillette\n2010). The reductive commitment to the lower level is based on\nrelations of composition, at play in epistemological analysis and\nmetaphysical synthesis, but is merely formal and derivational. We\ninfer what composes the higher level but we cannot simply get all the\nrelevant knowledge of the higher level from our knowledge of the lower\nlevel (see also Auyang 1998). \n \nA more general characterization views reductionism as a research\nstrategy. On this methodological view reductionism can be\ncharacterized by a set of so-called heuristics (non-algorithmic,\nefficient, error-based, purpose-oriented, problem-solving tasks)\n(Wimsatt 2006): heuristics of conceptualization (e.g., descriptive\nlocalization of properties, system-environment interface determinism,\nlevel and entity-dependence), heuristics of model-building and theory\nconstruction (e.g., model intra-systemic localization with emphasis of\nstructural properties over functional ones, contextual simplification\nand external generalization) and heuristics of observation and\nexperimental design (e.g., focused observation, environmental control,\nlocal scope of testing, abstract shared properties, behavioral\nregularity and context-independence of results). \nThe focus had been since the 1930s on a syntactic approach, with\nphysics as the paradigm of science, deductive logical relations as the\nform of cognitive or epistemic goals such as explanation and\nprediction, and theory and empirical laws as paradigmatic units of\nscientific knowledge (Suppe 1977; Grünbaum and Salmon 1988). The\nhistoricist turn in the 1960s, the semantic turn in philosophy of\nscience in the 1970s and a renewed interest in special sciences has\nchanged this focus. The very structure of hierarchy of levels has lost\nits credibility, even for those who believe in it as a model of\nautonomy of levels rather than as an image of fundamentalism. The\nrejection of such models and their emendations have occupied the last\nfour decades of philosophical discussion about unity in and of the\nsciences (especially in connection to psychology and biology, and more\nrecently chemistry). A valuable consequence has been the strengthening\nof philosophical projects and communities devoting more sustained and\nsophisticated attention to special sciences, different from\nphysics. \nThe first target of antireductionist attacks has been Nagel’s\ndemand of extensional equivalence. It has been dismissed as an\ninadequate demand of “meaning invariance” and\napproximation, and with it the possibility of deductive\nconnections. Mocking the positivist legacy of progress through unity,\nempiricism and anti-dogmatism, these constraints have been decried as\nintellectually dogmatic, conceptually weak and methodologically overly\nrestrictive (Feyerabend 1962). The emphasis is placed, instead, on the\nmerits of the new theses of incommensurability and methodological\npluralism. \nA similar criticism of reduction involves a different move: that the\ndeductive connection be guaranteed provided that the old, reduced\ntheory was “corrected” beforehand (Shaffner 1967). The\nevolution and the structure of scientific knowledge could be neatly\ncaptured, using Schaffner’s expression, by “layer-cake\nreduction.” The terms “length” and\n“mass”—or the symbols \\(l\\) and \\(m\\)—, for\ninstance, may be the same in Newtonian and Relativistic mechanics, or\nthe term “electron” the same in classical physics and\nquantum mechanics, or the term “atom” the same in quantum\nmechanics and in chemistry, or “gene” in Mendelian\ngenetics and molecular genetics (see, for instance, Kitcher 1984). But\nthe corresponding concepts, they argued, are not. Concepts or words\nare to be understood as getting their content or meaning within a\nholistic or organic structure, even if the organized wholes are the\ntheories that include them. From this point of view, different wholes,\nwhether theories or Kuhnian paradigms, manifest degrees of conceptual\nincommensurability.  As a result, the derived, reducing theories\ntypically are not the allegedly reduced, older ones; and their\nderivation sheds no relevant insight into the relation between the\noriginal, older one and the new (Feyerabend 1962; Sklar 1967). \nFrom a historical standpoint, the positivist model collapsed the\ndistinction between synchronic and diachronic reduction, that is,\nbetween reductive models of the structure and the evolution, or\nsuccession, of scientific theories. By contrast, historicism, as\nembraced by Kuhn and Feyerabend, drove a wedge between the two\ndimensions and rejected the linear model of scientific change in terms\nof accumulation and replacement. For Kuhn, replacement becomes partly\ncontinuous, partly non-cumulative change in which one world—or,\nless literally, one world-picture, one paradigm—replaces another\n(after a revolutionary episode of crisis and proliferation of\nalternative contenders) (Kuhn 1962). This image constitutes a form\nof pluralism, and, like the reductionism it is meant to\nreplace, it can be either\nsynchronic or diachronic. Here is where Kuhn and\nFeyerabend parted ways. For Kuhn synchronic pluralism only describes\nthe situation of crisis and revolution between paradigms. For\nFeyerabend history is less monistic, and pluralism is and should\nremain a synchronic and diachronic feature of science and culture\n(Feyerabend, here, thought science and society inseparable, and\nfollowed Mill’s philosophy of liberal individualism and\ndemocracy). \nA different kind of antireductionism addresses a more conceptual\ndimension, the problem of categorial reduction:\nMeta-theoretical categories of description and interpretation for\nmathematical formalisms, e.g., criteria of causality, may block full\nreduction. Basic interpretative concepts that are not just variables\nin a theory or model are not reducible to counterparts in fundamental\ndescriptions (Cat 2000 and 2006; the case of individuality in quantum\nphysics has been discussed in Healey 1991; Redhead and Teller 1991 and\nAuyang 1995; in psychology in Block 2003). \nUnity has been considered an epistemic virtue, with different modes of\nunification associated with roles such as demarcation, explanation and\nevidence. \nDemarcation. Certain models of unity, which we may call\ncontainer models, attempt to to demarcate science from non-science.\nThe criteria adopted are typically methodological and normative, not\ndescriptive. Unlike connective models, they serve a dual function of\ndrawing up and policing a boundary that (1) encloses and endorses the\nsciences and (2) excludes other practices. As noted above, some\ndemarcation projects have aimed to distinguish between natural and\nspecial sciences. The more notorious ones, however, have aimed to\nexclude practices and doctrines dismissed under the labels of\nmetaphysics, pseudo-science or popular knowledge. Empirical or not,\nthe applications of standards of epistemic purity are not merely\nidentification or labeling exercises for the sake of carving out\nscientific inquiry as a natural kind or mapping out intellectual\nlandscapes.The purpose is to establish authority and the stakes\ninvolve educational, legal and financial interests. Recent\ncontroversies include not just the teaching of creation science, also\npolemics over the scientific status of, for instance, homeopathy,\nvaccination and models of plant neurology and climate change. \nThe most influential demarcation criterion has been Popper’s\noriginal anti-metaphysics barrier: the condition of empirical\nfalsifiability of scientific statements. It required the logically\npossible relation to basic statements, linked to experience, that can\nprove general hypotheses to be false with certainty. For this purpose\nhe defended the application of a particular deductive argument, the\nmodus tollens (Popper 1935/1951). Another demarcation\ncriterion is explanatory unity, empirically grounded. Hempel’s\ndeductive-nomological model characterizes the scientific explanation\nof events as a logical argument that expresses their expectability in\nterms of their subsumption under an empirically testable\ngeneralization. Explanations in the historical sciences too must fit\nthe model if they are to count as scientific. They could then be brought\ninto the fold as bona fide scientific explanations even if they could\nqualify only as explanation sketches. \nSince their introduction, Hempel’s model and its weaker versions\nhave been challenged as neither generally applicable not\nappropriate. The demarcation criterion of unity is undermined by\ncriteria of demarcation between natural and historical sciences. For\ninstance, historical explanations have a genealogical or narrative\nform, or else they require the historian’s engaging problems or\nissuing a conceptual judgment that brings together meaningfully a set\nof historical facts (recent versions of such decades-old arguments are\nin Cleland 2002, Koster 2009, Wise 2011). According to more radical\nviews, natural sciences such as geology and biology are historical in\ntheir contextual, causal and narrative forms; also that Hempel’s\nmodel, especially the requirement of empirically testable strict\nuniversal laws, is satisfied by neither the physical sciences nor the\nhistorical sciences, including archeology and biology (Ereshefsky\n1992). \nA number of legal decisions have appealed to Popper’s and\nHempel’s criteria, adding the epistemic role of peer review,\npublication and consensus around the sound application of\nmethodological standards. A more recent criterion has sought a\ndifferent kind of demarcation: it is comparative rather than absolute;\nit aims to compare science and popular science; it adopts a broader\nnotion of in the German tradition of Wissenschaften, that is,\nroughly of scholarly fields of research that include formal sciences,\nnatural sciences, human sciences and the humanities; and it emphasizes\nthe role of systematicity, with an emphasis on different forms of\nepistemic connectedness as weak forms of coherence and order\n(Hoyningen-Huene 2013). \nExplanation. Unity has been defended in the wake of authors\nsuch as Kant and Whewell as an epistemic criterion of explanation or\nat least fulfilling an explanatory role. In other words, rather than\nmodeling unification in terms of explanation, explanation is modeled\nin terms of unification. A number of proposals introduce an\nexplanatory measure in terms of the number of independent explanatory\nlaws or phenomena conjoined in a theoretical structure. On this\nrepresentation, unity contributes understanding and confirmation from\nthe fewest basic kinds of phenomena, regardless of explanatory power\nin terms of derivation or argument patterns (Friedman 1974; Kitcher\n1981; Kitcher 1989; Wayne 1996; within a probabilistic framework,\nMyrvold 2003, Sober 2003 and Roche and Sober 2017; see below). \nA weaker position argues that unification is not explanation on the\ngrounds that unification is simply systematization of old beliefs and\noperates as a criterion of theory-choice (Halonen and Hintikka\n1999). \nThe unification account of explanation has been defended within a more\ndetailed cognitive and pragmatist approach. The key is to think of\nexplanations as question-answer episodes involving four elements: the\nexplanation-seeking question about \\(P, P\\)?, the cognitive state\n\\(C\\) of the questioner/agent for whom \\(P\\) calls for explanation,\nthe answer \\(A\\), and the cognitive state \\(C+A\\) in which the need\nfor explanation of \\(P\\) has disappeared. A related account models\nunity in the cognitive state in terms of the comparative increase of\ncoherence and elimination of spurious unity—such as circularity\nor redundancy (Schurz 1999).  Unification is also based on\ninformation-theoretic transfer or inference relations. Unification of\nhypotheses is only a virtue if it unifies data. The last two\nconditions imply that unification yields also empirical\nconfirmation. Explanations are global increases in unification in the\ncognitive state of the cognitive agent (Schurz 1999; Schurz and\nLambert 1994). \nThe unification-explanation link can be defended on the grounds that\nlaws make unifying similarity expectable (hence Hempel-explanatory)\nand this similarity becomes the content of a new belief (Weber and Van\nDyck 2002 contra Halonen and Hintikka 1999). Unification is not the\nmere systematization of old beliefs. Contra Schurz they argue that\nscientific explanation is provided by novel understanding of facts and\nthe satisfaction of our curiosity (Weber and Van Dyck 2002 contra\nSchurz 1999). In this sense, causal explanations, for instance, are\ngenuinely explanatory and do not require an increase of\nunification. \nA contextualist and pluralist account argues that understanding is a\nlegitimate aim of science that is pragmatic and not necessarily\nformal, or a subjective psychological by-product of explanation (De\nRegt and Dieks 2005). In this view explanatory understanding is\nvariable and can have diverse forms, such as causal-mechanical and\nunification, without conflict (De Regt and Dieks 2005). In the same\nspirit, Salmon linked unification to the the epistemic virtue or goal\nof explanation and distinguished between unification and\ncausal-mechanical explanation as forms of scientific explanatory\nunderstanding (Salmon 1998).  \nThe views on scientific explanation have evolved away from the formal\nand cognitive accounts of the epistemic categories. Accordingly, the\nsource of understanding provided by scientific explanations has been\nmisidentified according to some (Barnes 1992). The genuine source for\nimportant, but not all, cases lies, in causal explanation, or causal\nmechanism (Cartwright 1983; Cartwright 1989; see also Glennan 1996,\nCat 2005 and Craver 2007). Mechanistic models of explanation have\nbecome entrenched in philosophical accounts of the life sciences\n(Darden 2006, Craven 2007). As an epistemic virtue, the role of\nunification has been traced to the causal form of the explanation, for\ninstance, in statistical regularities (Schurz 2015). The challenge\nextends to the alleged extensional link between explanation on the one\nhand, and truth and universality on the other (Cartwright 1983,\nDupré 1993, Woodward 2003). In this sense, explanatory unity,\nwhich rests on metaphysical assumptions about components and their\nproperties, also involves a form of ontological or metaphysical unity\n(for a methodological criticism of external, metaphysical\nperspectives, see Ruphy 2016). \nSimilar criticisms extend to the traditionally formalist arguments in\nphysics about fundamental levels; there unification fails to yield\nexplanation in the formal scheme based on laws and their symmetries\n(Cat 1998; Cat 2005). Unification and explanation conflict on the\ngrounds that in biology and physics only causal mechanical\nexplanations answering why-questions yield understanding of the\nconnections that contribute to “true unification”\n(Morrison 2000;[2] Morrison’s choice of standard for\nevaluating the epistemic accounts of unity and explanation and her\nfocus on systematic theoretical connections without reduction has not\nbeen without critics, e.g., Wayne 2002; Plutynski 2005, Karaca\n2012).[3] \nMethodology. Unity has long been understood as a\nmethodological principle, primarily, but not exclusively, in\nreductionist versions (Wimsatt 1976 and Wimsatt 2006 for the case of\nbiology and Cat 1998 for physics). This is different from the case of\nunity through methodological prescriptions. One methodological\ncriterion appeals to the epistemic virtues of simplicity or parsimony,\nwhether epistemological or ontological (Sober 2003). As a formal\nprobabilistic principle of curve-fitting or average predictive\naccuracy, the relevance of unity is objective. Unity plays the role of\nan empirical background theory. \nEvidence. The probabilistic model dovetails with other recent\nformal discussions of unity and coherence within the framework of\nBayesianism (Forster and Sober 1994, sect. 7; Schurz and Lambert 2005\nis also a formal model, with an algebraic approach). More generally,\nthe probabilistic framework articulates formal characterizations of\nunity and introduces its role in evaluations of evidence. As in the\ndual relation to explanation, also in this case, unification is not a\ncondition for relevant evidence but a criterion of evidence (for a\nnon-probabilistic account of the relation between unification and\nconfirmation, see Schurz 1999). The evidentiary role of unification of\nhypotheses or models is related, but not reducible, to the evidentiary\nrole of synthesis of data in statistics.  \nA criterion of unity defended for its epistemic virtue in relation to\nevidence is simplicity, or parsimony (Sober 2013 and 2016).\nComparatively speaking, simpler hypotheses, models or theories present\na higher likelihood of truth, empirical support and accurate\nprediction. From a methodological standpoint, however, appeals to\nparsimony might not be sufficient. Moreover, the connection between\nunity as parsimony and likelihood is not interest-relative, at least\nin the way that the connection between unity and explanation is (Sober\n2003; Forster and Sober 1994 and Sober 2013 and 2016). \nOn the Bayesian approach, the rational comparison and acceptance of\nprobabilistic beliefs in the light of empirical data is constrained by\nBayes’ Theorem for conditional probabilities (where \\(h\\) and\n\\(d\\) are the hypothesis and the data respectively): \nOne explicit Bayesian account of unification as an epistemic,\nmethodological virtue, has introduced the following measure of unity:\na hypothesis \\(h\\) unifies phenomena \\(p\\) and \\(q\\) to the degree\nthat given \\(h, p\\) is statistically/probabilistically relevant to (or\ncorrelated with) \\(q\\) (Myrvold 2003; a probabilistically equivalent\nmeasure of unity in Bayesian terms in McGrew 2003; on the equivalence,\nSchupbach 2005). This measure of unity has been criticized as neither\nnecessary nor sufficient (Lange 2004; Lange’s criticism assumes\nthe unification-explanation link; in a rebuttal, Schupbach has\nrejected this and other assumptions behind Lange’s criticism;\nSchupbach 2005).  In a recent development, Myrvold argues for mutual\ninformation unification, i.e., that hypotheses are said to be\nsupported by their ability to increase the amount of what he calls the\nmutual information of the set of evidence statements; see Myrvold\n2017. The explanatory unification contributed by hypotheses about\ncommon causes is an instance of the information condition. \nFinally, another kind of formal model for a different kind of unity\nstraddles the boundary between formal epistemology and ontology:\ncomputational models of emergence or complexity. They are based on\nsimulations of chaotic dynamical processes such as cellular automata\n(Wolfram 1984; Wolfram 2002). Their supposed superiority to\ncombinatorial models based on aggregative functions of parts of wholes\ndoes not lack defenders (Crutchfield 1994; Crutchfield and Hanson\n1997; Humphreys 2004, 2007 and 2008; Humphreys and Huneman 2008;\nHuneman 2008a and b and 2010). \nUnification without reduction. Reduction is not the sole\nstandard of unity and models of unification without reduction have\nproliferated. In addition, such models introduce in turn new units of\nanalysis. An early influential account centers around the notion\nof interfield theories (Darden and Maull 1977; Darden\n2006). The orthodox central place of theories as the unit of\nscientific knowledge is replaced by that of fields. Examples of such\nfields are genetics, biochemistry and cytology. Different levels of\norganization correspond in this view to different fields: Fields are\nindividuated intellectually by a focal problem, a domain of facts\nrelated to the problem, explanatory goals, methods and a\nvocabulary. Fields import and transform terms and concepts from\nothers. The model is based on the idea that theories and disciplines\ndo not match neat levels of organization within a hierarchy; rather,\nmany of them in their scope and development cut across different such\nlevels. Reduction is a relation between theories within a field, not\nacross fields. \nInterdependence and hybridity. In general, the higher-level\ntheories (for instance, cell physiology) and the lower-level theories\n(for instance, biochemistry) are ontologically and epistemologically\ninter-dependent on matters of informational content and evidential\nrelevance; one cannot be developed without the other (Kincaid 1996;\nKincaid 1997; Wimsatt 1976; Spector 1977). The interaction between\nfields (through researchers’ judgments and borrowings) may\nprovide enabling conditions for subsequent interactions. For instance,\nMaxwell’s adoption of statistical techniques in color research\nenabled the introduction of similar ideas from social statistics in\nhis research in reductive molecular theories of gases; the reduction,\nin turn, enabled experimental evidence from chemistry and acoustics;\nsimilarly different chemical and spectroscopic bases for colors\nprovided chemical evidence in color research (Cat 2013 and 2014). \nThe emergence and development of hybrid disciplines and theories are\nanother instance of non-reductive cooperation or interaction between\nsciences. I noted, above, the post-war emergence of interdisciplinary\nareas of research, the so-called hyphenated sciences such as\nneuro-acoustics, radioastronomy, biophysics, etc. (Klein 1990, Galison\n1997) On a smaller scale, in the domain of, for instance, physics, one\ncan find semiclassical models in quantum physics or models developed\naround phenomena where the limiting reduction relations are singular\nor catastrophic (caustic optics and quantum chaos) (Cat 1998;\nBatterman 2002; Belot 2005). Such semiclassical explanatory models\nhave not found successful quantum substitutes and have placed\nstructural explanations at the heart of the relation between classical\nand quantum physics (Bokulich 2008). The general form of pervasive\ncases of emergence has been characterized with the notion of\ncontextual emergence (Bishop and Atmanspacher 2006): properties,\nbehaviors and their laws on a restricted, lower-level, single-scale,\ndomain are necessary but not sufficient for the properties, behaviors\nof another, e.g., higher-level one, not even of itself. The latter are\nalso determined by contingent contexts (contingent features of the\nstate space of the relevant system). The interstitial formation of\nmore or less stable small-scale syntheses and cross-boundary\n“alliances” has been common in most sciences since the\nearly 20th century. Indeed, it is crucial to development in\nmodel building and growing empirical relevance in fields ranging\nanywhere from biochemistry to cell ecology, or from econophysics to\nthermodynamical cosmology. Similar cases can be found in chemistry and\nthe biomedical sciences  \nConceptual unity. The conceptual dimension of cross-cutting\nhas been developed in connection with the possibility of cross-cutting\nnatural kinds that challenges taxonomical monism. Categories of\ntaxonomy and domains of description are interest-relative, as are\nrationality and objectivity (Khalidi 1998; his view shares positions\nand attitudes with Longino 1989; Elgin 1996 and 1997). Cross-cutting\ntaxonomic systems, then, are not conceptually inconsistent or\ninapplicable. Both the interest-relativity and hybridity feature\nprominently in the context of ontological pluralism (see below). \nAnother, more general, unifying element of this kind is Holton’s\nnotion of themata. Themata are conceptual values that are a\npriori yet contingent (both individual and social), informing and\norganizing presuppositions that factor centrally in the evolution of\nthe science: continuity/discontinuity, harmony, quantification,\nsymmetry, conservation, mechanicism, hierarchy, etc. (Holton 1973).\nUnity of some kind is itself a thematic element. A more complex and\ncomprehensive unit of organized scientific practice is the notion of\nthe various styles of reasoning, such as statistical,\nanalogical modeling, taxonomical, genetic/genealogical or laboratory\nstyles; each is a cluster of epistemic standards, questions, tools,\nontology, and self-authenticating or stabilizing protocols (Hacking\n1996; see below for the relevance of this account of a priori elements\nto claims of global disunity; the account shares distinctive features\nof Kuhn’s notion of paradigm). \nAnother model of non-reductive unification is historical and\ndiachronic: it emphasizes the genealogical and historical identity of\ndisciplines, which has become complex through interaction. The\ninteraction extends to relations between specific sciences, philosophy\nand philosophy of science (Hull 1988). Hull has endorsed an image of\nscience as a process, modeling historical unity after a\nDarwinian-style pattern of evolution (developing an earlier suggestion\nby Popper). Part of the account is the idea of disciplines as\nevolutionary historical individuals, which can be revised with the\nhelp of more recent ideas of biological individuality: hybrid unity as\nan external model of unity as integration or coordination of\nindividual disciplines and disciplinary projects, e.g., characterized\nby a form of occurrence, evolution or development whose tracking and\nidentification involves a conjunction with other disciplines, projects\nand domains of resources, from within science or outside science. This\ndiachronic perspective can accommodate models of discovery, in which\ngenealogical unity integrates a variety of resources that can be both\ntheoretical and applied, or scientific and non-scientific (an example,\nfrom physics, the discovery of superconductivity, can be found in\nHolton, Chang and Jurkowitz 1996). Some models of unity below provide\nfurther examples. \nA generalization of the notion of interfield theories is the idea that\nunity is interconnection: Fields are unified theoretically\nand practically (Grantham 2004). This is an extension of the original\nmodes of unity or identity that single out individual disciplines.\nTheoretical unification involves conceptual, ontological and\nexplanatory relations. Practical unification involves heuristic\ndependence, confirmational dependence and methodological integration.\nThe social dimension of the epistemology of scientific disciplines\nrelies on institutional unity. With regard to disciplines as\nprofessions, this kind of unity has rested on institutional\narrangements such as professional organizations for\nself-identification and self-regulation, university mechanisms of\ngrowth and reproduction through certification, funding and training,\nand communication and record through journals. \nMany examples of unity without reduction are local rather than global,\nand are not merely a phase in a global and linear project or tradition\nof unification (or integration). They are typically focused on science\nas a human activity. From that standpoint, unification is typically\nunderstood or advocated a piecemeal description and strategy of\ncollaboration (on the distinction between global integration and local\ninterdisciplinarity, see Klein 1990). Cases are restricted to specific\nmodels, phenomena or situations. \nMaterial unity. A more recent approach to the connection\nbetween different research areas has focused on a material level of\nscientific practice, with attention to the use of instruments and\nother material objects (Galison 1997, Bowker and Star 1999). For\ninstance, the material unity of natural philosophy in the\n16th and 17th centuries relied on the\ncirculation, transformation and application of objects, in their\nconcrete and abstract representations (Bertoloni-Meli 2006). The\nlatter correspond to the imaginary systems and their representations,\nwhich we call models. The evolution of objects and images across\ndifferent theories and experiments and their developments in\n19th-century natural philosophy provide a historical model\nof scientific development; but the approach is not meant to illustrate\nreductive materialism, since the same objects and models work and are\nperceived as vehicles for abstract ideas, institutions, cultures,\netc., or prompted by them (Cat 2013). On one view, objects are\nregarded as elements in so-called trading zones (see below) with\nshifting meanings in the evolution of 20th-century physics,\nsuch as with the cloud chamber which was first relevant to meteorology\nand next to particle physics (Galison 1997). Alternatively, material\nobjects have been given the status of boundary objects, which\nprovide the opportunity for experts from different fields to\ncollaborate through their respective understanding of the system in\nquestion and their respective goals (Bowker and Star 1999). \nGraphic unity. At the concrete perceptual level, recent\naccounts emphasize the role of visual representations in the sciences\nand suggest what may be called graphic unification of the\nsciences. Their cognitive roles, methodological and rhetorical,\ninclude establishing and disseminating facts and their so-called\nvirtual witnessing, revealing empirical relations, testing their fit\nwith available patterns of more abstract theoretical relations\n(theoretical integration), suggesting new ones, aiding in\ncomputations, serving as aesthetic devices, etc. But these uses are\nnot homogeneous across different sciences and make visible\ndisciplinary differences. We may equally speak of graphic\npluralism.  The rates in the use of diagrams in research\npublications appear to vary along the hard-soft axis of pyramidal\nhierarchy, from physics, chemistry, biology, psychology, economics and\nsociology and political science (Smith et al. 2000): the highest use\ncan be found in physics, intuitively identified by the highest degree\nof hardness understood as consensus, codification, theoretical\nintegration and factual stability to highest interpretive and\ninstability of results. Similarly, the same variation occurs among\nsub-disciplines within each discipline. The kinds of images and their\ncontents also vary across disciplines and within disciplines, ranging\nfrom hand-made images of particular specimens to hand-made or\nmechanically generated images of particulars standing in for types, to\nschematic images of geometric patterns in space or time, or to\nabstract diagrams representing quantitative relations. Importantly,\ngraphic tools circulate like other cognitive tools between areas of\nresearch that they in turn connect (Galison 1997, Daston and Galison\n2007, Lopes 2009; see also Lynch and Woolgar 1990; Baigrie 1996; Jones\nand Galison 1998; Galison 1997; Cat 2001, 2013 and 2014; and Kaiser\n2005). \nDisciplinary unity and collaboration. A field of study has\nfocused on disciplines broadly and their relations. Disciplines\nconstitute a broader unity of analysis of connection in the sciences\nthat is characterized, for instance, by their domain of inquiry,\ncognitive tools and social structure (Bechtel 1987). Unification of\ndisciplines, in that sense, can be interdisciplinary,\nmultidisciplinary, crossdisciplinary and\ntransdisciplinary (Klein 1990, Kellert 2008, Repko 2012). It\nmight involve a researcher borrowing from different disciplines or the\ncollaboration of different researches. Neither modality of\nconnection amounts to a straightforward generalization of, or reduction\nto any single discipline, theory, etc. In either case, the strategic\ndevelopment is typically defended for its heuristic problem-solving or\ninnovative powers, as it is prompted by a problem considered complex\nin that it does not arise or cannot be fully treated within the\npurview of one specific discipline unified or individuated around some\npotentially non-unique set of elements such as scope of empirical\nphenomena, rules, standards, techniques, conceptual and material\ntools, aims, social institutions, etc. Indicators of disciplinary\nunity may vary (Kuhn 1962, Klein 1990, Kellert 2008).\nInterdisciplinary research or collaboration creates a new\ndiscipline or project, such as interfield research, often leaving the\nexistence of the original ones intact. Multidisciplinary work\ninvolves the juxtaposition of the treatments and aims of the different\ndisciplines involved in addressing a common problem.\nCrossdisciplinary work involves borrowing resources from one\ndiscipline to serve the aims of a project in another.\nTransdisciplinary work is a synthetic creation that\nencompasses work from different disciplines (Klein 1990, Kellert 2008,\nBrigandt 2010, Hoffmann, Schmidt and Nersessian 2012, Osbeck et al\n2011, Repko 2012). These different modes of synthesis or connection\nare not mutually exclusive. \nModels of interdisciplinary cooperation and their corresponding\noutcomes are often described using metaphors of different kinds:\ncartographic (domains, boundaries, trading zone, etc),\nlinguistic (pidgin language, communication, translation,\netc), architectural (building blocks, tiles, etc),\nsocio-political (imperialism, hierarchy, republic,\norchestration, negotiation, coordination, cooperation etc) or\nembodied (cross-training). Each selectively highlights and neglects\ndifferent aspects of scientific practice and properties of scientific\nproducts. Cartographic and architectural images, for instance, focus\non spatial and static synchronic relations and simply connected,\ncompatible elements. Socio-political and embodied images emphasize\nactivity and non-propositional elements (Kellert 2008 defends the\nimage of cross-training). \nIn this context, methodological unity often takes the form of\nborrowing standards and techniques for the application of formal and\nempirical methods. They range from calculational techniques and tools\nfor theoretical modeling and simulation of phenomena to techniques for\nmodeling of data, use of instruments and conducting experiments (e.g.,\nthe culture of field experiments and, more recently, randomized\ncontrol trials across natural and social sciences). A key element of\nscientific practice often ignored by philosophical analysis is\nexpertise. As part of different forms of methodological unity, it is\nkey to the acceptance and successful appropriation of\ntechniques. Recent accounts of multidisciplinary collaboration as a\nhuman activity have focused on the dynamics of integrating different\nkinds of expertise around common systems or goals of research (Collins\nand Evans 2007, Gorman 2002). The same perspective can accommodate the\nrecent interest in so-called mixed methods, e.g., different forms of\nintegration of quantitative and qualitative methods and approaches in\nthe social sciences.  \nA general model of local interconnection which has acquired widespread\nattention and application in different sciences is the anthropological\nmodel of trading zone, where hybrid languages and meanings\nare developed that allow for interaction without straightforward\nextension of any party’s original language or framework (Galison\n1997). Galison has applied this kind of anthropological analysis to\nthe subcultures of experimentation. This strategy aims to explain the\nstrength, coherence and continuity of science in terms of local\ncoordinations of intercalated levels of symbolic procedures\nand meanings, instruments and arguments. \nAt the experimental level, instruments, as found objects, acquire new\nmeanings, developments and uses as they bridge over the transitions\nbetween theories, observations or theory-laden observations.\nInstruments and experimental projects in the case of Big Science also\nbring together, synchronically and interactively, the skills,\nstandards and other resources from different communities, and change\neach in turn (on interdisciplinary experimentation see also Osbeck et\nal. 2011). Patterns of laboratory research are shared by the different\nsciences, not just instruments but general strategies of\nreconfiguration of human researchers and natural entities researched\n(Knorr-Cetina 1992), statistical standards (e.g., statistical\nsignificance) and ideals of replication. At the same time, attention\nhas been paid to the different ways on which experimental approaches\ndiffer among the sciences (Knorr-Cetina 1992, Guala 2005, Weber 2005)\nbut also to how they have been transferred (e.g., field experiments\nand randomized control trials) or integrated (e.g., mixed methods\ncombining quantitative and qualitative techniques).  \nEmpirical work in sociology and cognitive psychology on scientific\ncollaboration has led to a broader perspective including a number of\ndimensions of interdisciplinary cooperation, involving identification\nof conflicts and the setting of sufficient so-called common ground\nintegrators: for instance, shared—pre-existing, revised and\nnewly developed— concepts, terminology, standards, techniques,\naims, information, tools, expertise, skills (abstract, dialectical,\ncreative and holistic thinking), cognitive and social ethos\n(curiosity, tolerance, flexibility, humility, receptivity,\nreflexivity, honesty, team-play) social interaction, institutional\nstructures and geography (Cummings and Kiesler 2005, Klein 1990,\nKockelmans 1979, Repko 2012). Sociological studies of scientific\ncollaboration can in principle place the connective models of unity\nwithin the more general scope of social epistemology, for instance, in\nrelation to distributive cognition (beyond the focus on strategies of\nconsensus within communities). \nThe broad and dynamical approach to processes of interdisciplinary\nintegration may effectively be understood to describe the production\nof different sorts and degrees of epistemic emergence. The integrated\naccounts require shared (old or new) assumptions and may involve a\ncase of ontological integration, for instance in causal models.\nSuggested kinds of interdisciplinary causal-model integration are the\nfollowing: sequential causal order in a process or mechanism cutting\nacross disciplinary divides; horizontal parallel integration of\ndifferent causal models of different elements of a complex phenomenon;\nhorizontal joint causal model of the same effect; and vertical or\ncross-level causal integration (see emergent or top-down causality,\nbelow) (Repko 2012, Kockelmans 1979). \nTalk of cooperation and coordination for the purpose of forming hybrid\ncross-disciplines, emergent disciplines or projects and products\nrevolves often around two issues: conflicts and the challenge of\nstriking a balance between cooperation and autonomy. By extension of\nthe discussion of value conflict in moral and political philosophy,\none must acknowledge the extent to which scientific practice is based\non accepting limited conflict over necessary commitments and making\nepistemic and/or non-epistemic compromises (a volitional, not just\ncognitive aspect; on this view against unity as social consensus, see\nRescher 1993, Cat 2005 and 2010; van Bouwel 2009; comp Repko 2012;\nHoffmann, Schmidt and Nersessian 2012). \nAesthetic value. Finally, epistemic values of unity may rely\non subsidiary considerations of aesthetic value. Nevertheless,\nconsideration of beauty, elegance or harmony may also provide\nautonomous grounds for adopting or pursuing varieties of unification\nin terms of simplicity and patterns of order (regularity of specific\nrelations) (McAllister 1996, Glynn 2010 and Orrell 2012). Whether\naesthetic judgements have any epistemic import depends on\nmetaphysical, cognitive or pragmatic assumptions. \nSince Nagel’s influential model of reduction by derivation most\ndiscussions of unity of science have been cast in terms of reductions\nbetween concepts, the entities they describe, and between theories\nincorporating the descriptive concepts. Ontological unity is expressed\nby a preferred set of such ontological units. In terms of concepts\nfeatured in preferred descriptions, explanatory or not, reduction\nendorses taxonomical monism, a privileged set of kinds of\nthings. These privileged kinds are often known as so-called natural\nkinds, although the notion admits of multiple interpretations, ranging\nfrom the more conventionalist to the more essentialistic. Regardless,\nthe fundamental units are ambiguous with respect to their status as\neither entity or property. Reduction may determine the fundamental\nkinds or level through the analysis of entities. A distinctive\nontological model is this: The hierarchy of levels of reduction is\nfixed by\npart-whole relations. The levels of aggregation of entities\nrun all the way down to atomic particles and field parts, rendering\nmicrophysics the fundamental science. \nA classic reference in this kind, away from the syntactic model, is\nOppenheim and Putnam’s “The Unity of Science as a Working\nHypothesis” (Oppenheim and Putnam 1958; Oppenheim and Hempel had\nworked in the 1930s on taxonomy and typology, a question of broad\nintellectual, social and political relevance in Germany at the time).\nOppenheim and Putnam intended to articulate an idea of science as a\nreductive unity of concepts and laws to those of the most elementary\nelements. They also defended it as an empirical hypothesis—not\nan a priori ideal, project or precondition—about\nscience. Moreover, they claimed that its evolution manifested a trend\nin that unified direction out of the smallest entities and lowest\nlevels of aggregation. In an important sense, the evolution of science\nrecapitulates, in the reverse, the evolution of matter, from\naggregates of elementary particles to the formation of complex\norganisms and species (we find a similar assumption in\nWeinberg’s downward arrow of explanation).  Unity, then, is\nmanifested not just in mereological form, but also\ndiachronically, genealogically or historically. \nA weaker form of ontological reduction advocated for the biomedical\nsciences with the causal notion of partial reductions:\nexplanations of localized scope (focused on parts of higher-level\nsystems only) laying out a causal mechanism connecting different\nlevels in the hierarchy of composition and organization (Schaffner\n1993; Schaffner 2006; Scerri has similarly discussed degrees of\nreduction in Scerri 1994). An extensional, domain-relative approach\nintroduces the distinction between “domain preserving” and\n“domain combining” reductions. Domain-preserving\nreductions are intra-level reductions and occur between \\(T_1\\) and\nits predecessor \\(T_2\\). In this parlance, however, \\(T_2\\)\n“reduces” to \\(T_1\\). This notion of\n“reduction” does not refer to any relation of explanation\n(Nickles 1973). \nThe claim that reduction, as a relation of explanation, needs to be a\nrelation between theories or even involve any theory has also been\nchallenged. One such challenge focuses on “inter-level”\nexplanations in the form of compositional redescription and\ncausal mechanisms (Wimsatt 1976). The role of biconditionals or even\nSchaffner-type identities, as factual relations, is heuristic (Wimsatt\n1976). The heuristic value extends to the preservation of the\nhigher-level, reduced concepts, especially for cognitive and pragmatic\nreasons, including reasons of empirical evidence. This amounts to\nrejecting the structural, formal approach to unity and reductionism\nfavored by the logical-positivist tradition.  Reductionism is another\nexample of the functional, purposive nature of scientific\npractice. The metaphysical view that follows is a pragmatic and\nnon-eliminative realism (Wimsatt 2006). As a heuristic, this kind of\nnon-eliminative pragmatic reductionism is a complex stance. It is,\nacross levels, integrative and intransitive, compositional,\nmechanistic and functionally localized, approximative and\nabstractive. It is bound to adopting false idealizations, focusing on\nregularities and stable common behavior, circumstances and\nproperties. It is also constrained in its rational calculations and\nmethods, tool-binding, and problem-relative.  The heuristic value of\neliminative inter-level reductions has been defended as well (Poirier\n2006). \nThe appeal to formal laws and deductive relations is dropped for sets\nof concepts or vocabularies in the replacement analysis\n(Spector 1978). This approach allows for talk of entity reduction or\nbranch reduction, and even direct theory replacement without the\noperation of laws, and circumvents vexing difficulties raised by\nbridge principles and the deductive derivability condition\n(self-reduction, infinite regress, etc). Formal relations only\nguarantee, but do not define, the reduction relation. Replacement\nfunctions are meta-linguistic statements. Like Sellars had argued in\nthe case of explanation, this account distinguishes between reduction\nand testing of reduction, and highlights the role of derivations in\nboth. Finally, replacement can be in practice or in\ntheory. Replacement in practice does not advocate elimination of the\nreduced or replaced entities or concepts (Spector 1978). \nNote, however, the following: the compartmentalization of theories and\ntheir concepts or vocabulary into levels neglects the existence of\nempirically meaningful and causally explanatory relations between\nentities or properties at different levels. If they are neglected as\ntheoretical knowledge and left outside as only bridge principles, the\npossibility of completeness of knowledge is jeopardized.  Maximizing\ncompleteness of knowledge here requires a descriptive unity of all\nphenomena at all levels and anything between these levels. Any bounded\nregion or body of knowledge neglecting such cross-boundary\ninteractions is radically incomplete, and not just confirmationally or\nevidentially so; we may refer to this problem as the problem of\ncross-boundary incompleteness as either intra-level or\nhorizontal incompleteness and, on a hierarchy, the problem of\ninter-level or vertical incompleteness (Kincaid 1997; Cat\n1998). \nThe most radical form of reduction as replacement is often called\neliminativism. The position has made a considerable impact in\nphilosophy of psychology and philosophy of mind (Churchland 1981;\nChurchland 1986). On this view the vocabulary of the reducing theories\n(neurobiology) eliminates and replaces that of the reduced ones\n(psychology), leaving no substantive relation between them (which is\nonly a replacement rule) (see also\n eliminative materialism).\n  \nIn a general semantic account, Sarkar distinguishes different kinds of\nreduction in terms of four criteria, two epistemological and two\nontological: fundamentalism, approximation, abstract hierarchy and\nspatial hierarchy. Fundamentalism implies that the features\nof a system can be explained in terms only of factors and rules from\nanother realm. Abstract hierarchy is the assumption that the\nrepresentation of a system involves a hierarchy of levels of\norganization with the explanatory factors being located at the lower\nlevels. Spatial hierarchy is a special case of abstract\nhierarchy in which the criterion of hierarchical relation is a spatial\npart-whole or containment relation. Strong reduction satisfies the\nthree “substantive” criteria, whereas weak reduction only\nsatisfies fundamentalism. Approximate reductions—strong and\nhierarchical—are those which satisfy the criterion of\nfundamentalism only approximately (Sarkar 1998; the merit of\nSarkar’s proposal resides in its systematic attention to\nhierarchical conditions and, more originally, to different conditions\nof\napproximation; see also Ramsey 1995; Lange 1995; Cat\n2005). \nThe semantic turn extends to more recent notion of models that do not\nfall under the strict semantic or model-theoretic notion of\nmathematical structures (Giere 1999; Morgan and Morrison 1999; Cat\n2005). This is a more flexible framework about relevant formal\nrelations and the scope of relevant empirical situations; and it is\nimplicitly or explicitly adopted by most accounts of unity without\nreduction. One may add the primacy of temporal representation and\ntemporal parts, temporal hierarchy or temporal\ncompositionality, first emphasized by Oppenheim and Putnam as a\nmodel of genealogical or diachronic unity. This framework applies to\nprocesses both of evolution and development (a more recent version in\nMcGivern 2008 and Love and Hütteman 2011). \nThe shift in the accounts of scientific theory from syntactic to\nsemantic approaches has changed conceptual perspectives and,\naccordingly, formulations and evaluations of reductive relations and\nreductionism. However, examples of the semantic approach focusing on\nmathematical structures and satisfaction of set-theoretic relations\nhave focused on syntactic features—including the axiomatic form\nof a theory—in the discussion of reduction (Sarkar 1998, da\nCosta and French 2003). In this sense, the structuralist approach can\nbe construed as a neo-Nagelian account, while an alternative line of\nresearch has championed the more traditional structuralist semantic\napproach (Balzer and Moulines 1996; Moulines 2006; Ruttkamp 2000;\nRuttkamp and Heidema 2005). \nHeaded in the opposite direction, arguments concerning new concepts\nsuch as multiple realizability and supervenience,\nintroduced by Putnam, Kim, Fodor and others, have led to talk of\nhigher-level functionalism, a distinction between type-type and\ntoken-token reductions and the examination of its implications. The\nconcepts of emergence, supervenience and downward causation are\nrelated metaphysical tools for generating and evaluating proposals\nabout unity and reduction in the sciences. This literature has enjoyed\nits chief sources and developments in general metaphysics and in\nphilosophy of mind and psychology (Davidson 1969; Putnam 1975; Fodor\n1975; Kim 1993). \nSupervenience, first introduced by Davidson in discussions of\nmental properties, is the notion that a system with properties on one\nlevel is composed of entities on a lower level and that its properties\nare determined by the properties of the lower-level entities or\nstates. The relation of determination is that no changes at the\nhigher-level occur without changes at the lower level. Like\ntoken-reductionism, supervenience has been adopted by many as the poor\nman’s reductionism (see the entry on\n supervenience).\n A different case for the autonomy of the macrolevel is based on the\nnotion of multiple supervenience (Kincaid 1997; Meyering 2000). \nThe autonomy of the special sciences from physics has been defended in\nterms of a distinction between type-physicalism and\ntoken-physicalism (Fodor 1974; Fodor countered Oppenheim and\nPutnam’s hypothesis under the rubric “the disunity of\nscience”; the entry on\n physicalism).\n The key logical assumption is the type-token distinction, that types\nare realized by more specific tokens, e.g., the type animal is instantiated\nby different species, the type tiger or electron can be instantiated\nby multiple individual token tigers and electrons. Type-physicalism is\ncharacterized by a type-type identity between the\npredicates/properties in the laws of the special sciences and those of\nphysics. By contrast, token-physicalism is based on the token-token\nidentity between the predicates/properties of the special sciences and\nthose of physics; every event under a special law falls under a law of\nphysics and bridge laws express contingent token-identities between\nevents. Token-physicalism operates as a demarcation criterion for\nmaterialism. Fodor argued that the predicates of the special sciences\ncorrespond to infinite or open-ended disjunctions of physical\npredicates, and these disjunctions do not constitute natural kinds\nidentified by an associated law. Token-physicalism is the only\nalternative. All special kinds of events are physical but the special\nsciences are not physics (for criticisms based on the presuppositions\nin Fodor’s argument, see Sober 1999). \nThe denial of remedial, weaker forms of reductionism is the basis for\nthe concept of emergence (Humphreys 1997, Bedau and Humphreys\n2008). Different accounts have attempted to articulate the idea of a\nwhole being different from or more than the mere sum of its parts (see\nthe entry on\n emergent properties).\n Emergence has been described beyond logical relations, synchronically\nas an ontological property and diachronically as a material process of\nfusion, in which the powers of the separate constituents lose their\nseparate existence and effects (Humphreys 1997). This concept has been\nwidely applied in discussions of complexity (see below).\nUnlike the earliest antireductionist models of complexity in terms of\nholism and cybernetic properties, more recent approaches track the\nrole of constituent parts (Simon 1996). Weak emergence has been\nopposed to nominal and strong forms of emergence. The nominal kind\nsimply represents that some macro-properties cannot be properties of\nmicro-constituents. The strong form is based on supervenience and\nirreducibility, with a role for the occurrence of autonomous downwards causation upon any\nconstituents (see below). Weak emergence is linked to processes\nstemming from the states and powers of constituents, with a reductive\nnotion of downwards causation of the system as a resultant of\nconstituents’ effects; yet the connection is not a matter of Nagelian\nformal derivation, but of implementation through, for instance,\ncomputational aggregation and iteration. Weak emergence, then, can be\ndefined in terms of simulation: a macro-property, state or fact is\nweakly emergent if and only if it can be derived from its\nmacro-constituents only by simulation (Bedau 2008) (see entry on\n simulations in science).\n  \nConnected to the concept of emergence is top-down or\ndownward causation. It captures the autonomous and genuine\ncausal power of higher-level entities or states, especially upon\nlower-level ones. The most extreme and most controversial version\ninclude a violation of laws that regulate the lower-level (Meehl and\nSellars 1956; Campbell 1974). Weaker forms require compatibility with\nthe microlaws (for a brief survey and discussion see Robinson 2005; on\ndownward causation without top-down causes, see Craver and Bechtel\n2007, Bishop 2012). The very concept has become the subject of some\ninterdisciplinary interest in the sciences (Ellis, Noble and O’Connor\n2012). \nAnother general argument for the autonomy of the macrolevel in the\nform of non-reductive materialism has been a cognitive type of\nfunctionalism, namely, cognitive pragmatism (Van Gulick 1992). This\naccount links ontology to epistemology. It discusses four pragmatic\ndimensions of representations: the nature of the causal interaction\nbetween theory-user and the theory, the nature of the goals to whose\nrealization the theory can contribute, the role of indexical elements\nin fixing representational content, and differences in the\nindividuating principles applied by the theory to its types (Wimsatt\nand Spector’s arguments above are of this kind). A more\nontologically substantive account of functional reduction is\nRamsey’s bottom-up\nconstruction by reduction: transformation reductions\nstreamline formulations of theories in such a way that they extend\nbasic theories upwards by engineering their application to specific\ncontext or phenomena. As a consequence, they reveal, by construction,\nnew relations and systems that are antecedently absent from a\nscientist’s understanding of the theory—independently of a top\nor reduced theory (Ramsey 1995). A weaker framework of ontological\nunification is categorial unity, wherein abstract categories\nsuch as causality, information, etc, are attached to the\ninterpretation of the specific variables and properties in models of\nphenomena (see Cat 2000, 2001 and 2006). \nA more radical departure from logical-positivist standards of unity is\nthe recent criticism of the methodological values of reductionism and\nunification in the sciences and also its position in culture and\nsociety. From the descriptive standpoint, many views under the rubric\nof disunity are versions of positions mentioned above. The difference\nis mainly normative and a matter of emphasis, perspective, and\nstance. This view argues for the replacement of the emphasis on global\nunity—including unity of method—by emphasizing disunity\nand epistemological and ontological pluralism. \nAn influential picture of disunity comes from related works by the\nmembers of the so-called Stanford School, e.g., John Dupré, Ian\nHacking, Peter Galison, Patrick Suppes and Nancy Cartwright. Disunity\nis, in general terms, a rejection of universalism and uniformity both\nmethodological and metaphysical. While the view can be constructed in\nterms of specific anti-reductionistic claims and positions, they share\nan emphasis on the rejection of restrictive accounts of unity. Through\ntheir work, the rubric of disunity has acquired a visibility parallel\nto the one once acquired by unity, as an inspiring philosophical\nrallying cry.  \n From a methodological point of view, disunity is simply the global\nnegative expression of a model of local unity such trading-zone, by\ncontrast with globalists, formal models (Galison 1998), with an\nemphasis on a plurality of scientific methods (Suppes 1978) and causal\nindeterminism, on a plurality of scientific styles with the function\nof establishing spaces of epistemic possibility, and a disunity of\nscience in terms of plurality of unities (Hacking 1996; Hacking\nfollows the historian A.A. Crombie; for a criticism of Hacking’s\nhistorical epistemology see Kusch 2010).\n \nFrom a metaphysical point of view, the disunity of science can be\ngiven adequate metaphysical foundations that make pluralism compatible\nwith realism (Dupré 1993). Dupré opposes a mechanistic\nparadigm of unity characterized by determinism, reductionism and\nessentialism. The paradigm spreads the values and methods of physics\nto other sciences that he thinks are scientifically and socially\ndeleterious. Disunity appears characterized by three pluralistic\ntheses: against essentialism, there is always a plurality of\nclassifications of reality into kinds; against reductionism, there\nexists equal reality and causal efficacy of systems at different\nlevels of description, that is, the microlevel is not causally\ncomplete, leaving room for downward causation; and against\nepistemological monism, there is no single methodology that supports a\nsingle criterion of scientificity, nor a universal domain of its\napplicability, only a plurality of epistemic and non-epistemic\nvirtues. The unitary concept of science should be understood,\nfollowing the later Wittgenstein, as a family-resemblance concept (For\na criticism of Dupré’s ideas, see Mitchell 2003 and Sklar\n2003). \nAgainst the universalism of explanatory laws, Cartwright has argued\nthat laws cannot be both universal and true, as Hempel required in his\ninfluential account of explanation and demarcation; there exist only\npatchworks of laws and local cooperation. Like Dupré,\nCartwright adopts a kind of scientific realism but denies that there\nis a universal order, whether represented by a theory of everything or\na corresponding a priori metaphysical principle (Cartwright 1983). The\nempirical evidence, she argues, along the same lines as Wimsatt,\nsuggests far more strongly the idea of a dappled world, best\nrepresented by a patchwork of laws, often in local cooperation (e.g.,\nlocal identifications, causal interactions, joint actions and\npiecemeal corrections and correlations). Theories apply only where and\nto the extent that their interpretive models fit the phenomena studied\n(Cartwright 1999). But this is not their alleged universal factual\nscope. They only hold in special conditions like ceteris\nparibus. Cartwright’s pluralism is not just opposed to\nvertical reductionism but also horizontal imperialism, or universalism\nand globalism. She explains their more or less general domain of\napplication in terms of causal capacities and arrangements she calls\nnomological machines (Cartwright 1989; Cartwright 1999). The\nregularities they bring about depend on a shielded environment. As a\nmatter of empiricism, this is the reason that it is in the controlled\nenvironment of laboratories and experiments, where causal interference\nis shielded off, that factual regularities are manifested. The\ncontrolled, stable regular world is an engineered world.\nRepresentation rests on intervention (comp. Hacking 1983). On these\ngrounds, as a matter of holism Cartwright rejects strong distinctions between\nnatural and social sciences, and like Otto Neurath, between the natural and\nthe social world. Whether as a hypothesis or as an ideal, the debates\ncontinue over the form, scope and significance of unification in the\nsciences. Cartwright’s theses and arguments rest on numerous\nassumptions that have been target of insightful criticism (Winsberg et\nal. 200,; Hoefer 2003, Sklar 2003, Howhy 2003, Teller 2004, McArthur\n2006 and Ruphy 2016). \nDisunity and autonomy of levels have been associated, conversely, with\nantirealism, meaning instrumentalist or empiricist heuristics. This\nincludes, for Fodor and Rosenberg, higher-level sciences such as\nbiology and sociology (Fodor 1974; Rosenberg 1994; Huneman 2010). It\nis against this picture that Dupré’s and\nCartwright’s attacks on uniformly global unity and reductionism,\nabove, might seem surprising by including an endorsement, in causal\nterms, of realism.[4] Rohrlich has defended a similar realist\nposition about weaker, conceptual (cognitive) antireductionism,\nalthough on the grounds of the mathematical success of derivational\nexplanatory reductions (Rohrlich 2001). Ruphy, however, has argued\nthat antireductionism merely amounts to a general methodological\nprescription and is too weak to yield uncontroversial metaphysical\nlessons; these are in fact based on general metaphysical commitments\nexternal to scientific practice (Ruphy 2005 and 2016). \nThe question of the metaphysical significance of disunity and\nanti-reductionism takes one straight to the larger issue of the\nepistemology and metaphysics (and aesthetics, social culture and\npolitics) of pluralism. And here one encounters the familiar issues\nand notions such as conceptual schemes, frameworks and worldviews,\nincommensurability, relativism, contextualism and perspectivalism (for\na general discussion see Lynch 1998; on perspectivalism about\nscientific models see Giere 1999 and Rueger 2005). In connection with\nrelativism and instrumentalism, pluralism has typically been\nassociated with antirealism about taxonomical practices. But it has\nbeen defended from the standpoint of realism (for instance,\nDupré 1993 and Chakravartty 2011). Pluralism about knowledge of\nmind-independent facts can be formulated in terms of different ways of\nto distribute properties (sociability-based pluralism), with more\nspecific commitments about the ontological status of the related\nelements and their plural contextual manifestations of powers or\ndispositions (Chakravartty 2011, Cartwright 2007). \nPluralism applies widely to concepts, explanations, virtues, goals,\nmethods, models, and kinds of representations (see above for graphic\npluralism), etc. In this sense, pluralism has been defended as a\ngeneral framework that rejects the ideal of consensus in cognitive,\nevaluative and practical matters, against pure skepticism (nothing\ngoes) or indifferentism (anything goes), including a defense of\npreferential and contextual rationality that notes the role of\ncontextual rational commitments, by analogy with political forms of\nengagement (Rescher 1993, van Bouwel 2009, Cat 2012). \nConsider at least four distinctions—they are formulated about\nconcepts, facts, and descriptions, and they apply also to values,\nvirtues, methods, etc: \nVertical vs. horizontal pluralism. Vertical pluralism is\ninter-level pluralism, the view that there is more than one level of\nfactual description or kind of fact and that each is irreducible,\nequally fundamental, or ontologically/conceptually\nautonomous. Horizontal pluralism is intra-level pluralism, the view\nthat there may be incompatible descriptions or facts on the same level\nof discourse (Lynch 1998). For instance, the plurality of explanatory\ncauses to be chosen from or integrated in biology or physics has been\ndefended as lesson in pluralism (Sober 1999). \nGlobal vs. local pluralism. Global pluralism is pluralism\nabout every type of fact or description. Global horizontal pluralism\nis the view that there may be incompatible descriptions of the same\ntype of fact. Global vertical pluralism is the view that no type of\nfact or description reduces to any other. Local horizontal and\nvertical pluralism are about one type of fact or description (Lynch\n1998). \nIsolationist vs. integrative pluralism. Isolationist\npluralism is about underdetermination; about the choice from a\ndisjunction of equivalent types of descriptions (Mitchell) or of\nincompatible partial representations or models of phenomena in the\nsame intended scope (Longino); the representational incompatibility\nmay be traced to competing values or aims, or assumptions in ceteris\nparibus laws. It is the most common situation in the sciences.\nIntegrative pluralism is the conjunctive or holistic requirement of\ndifferent types of descriptions or facts (Mitchell 2003 and 2009;\ncontrast with the more isolationist position in Longino 2002, her\nessay in Kellert, Longino and Waters 2006, and Longino 2013). In the\nsame spirit, i have mentioned, for instance, the case of mixed methods\nintegrating qualitative and quantitative techniques. This position is\nanalogous to agonistic engagement in political models of deliberative\ndemocracy, between the extremes of so-called consensual mainstreaming\nand antagonistic exclusivism (van Bouwel 2009). Each can be vertical\nor horizontal (see the discussion of interdisciplinary integration,\nabove).  \nInternal vs. external pluralism. From a methodological\nstandpoint, an internal perspective is naturalistic in its reliance on\nthe contingent plurality of scientific practice by any of its\nstandards. This has been defended by members of the so-called\nMinnesota School (Kellert, Longino and Waters 2006) and Ruphy (Ruphy\n2016). The alternative, which Ruphy has attributed to Dupré and\nCartwright is the adoption of a metaphysical commitment external to\nactual scientific practice. \nThese distinctions can accommodate a number of epistemic and\nmetaphysical pluralist accounts including different versions of\ntaxonomical pluralism. These range from the more conventional and\ncontingent (from Elgin 1997 to astronomical kinds in Ruphy 2016), the\nmore grounded in contexts of practices (categorization work in Bowker\nand Star 1999 or quantitative kinds in Cat 2016 and in the life\nsciences and chemistry in Kendig 2016 ) and the interactive\n(Hacking’s interactive kinds in the human sciences) to the more\nmetaphysically substantive. From a methodological standpoint, to the\ndistinctions above we can add the distinction between descriptive and\nevaluative attitudes to pluralism, and contrast them further with the\nactivist approach (defended by Chang in Chang 2012) encouraging\nplurality where productive (Chang focuses on the experimental\nreactivation of historically abandoned programs). As Neurath’s\ndiscussion of unity suggested, also discussions of pluralism are\nmatters of social epistemology, with social and political correlates\nand consequences, for instance regarding issues of toleration and\ndemocracy. \nThe preference for one kind of pluralism over another is typically\nmotivated by epistemic virtues or constraints. Meta-pluralism,\npluralism about pluralism, is obviously conceivable in similar terms,\nas it can be found in the formulation of the so-called pluralist\nstance (Kellert, Longino and Waters 2006). The pluralist stance\nreplaces metaphysical principles with scientific, or empirical,\nmethodological rules and aims that have been “tested”.\nLike Dupré’s and Cartwright’s metaphysical\npositions, its metascientific position must be empirically\ntested. Metascientific conclusions and assumptions cannot be\nconsidered universal or necessary, but local and contingent, relative\nto scientific interests and purposes. Thus, on this view, complexity\ndoes not always require interdisciplinarity (Kellert 2008); and in\nsome situations the pluralist stance will defend reductions or\nspecialization over interdisciplinary integration (Kellert, Longino\nand Waters 2006, Cat 2010 and 2012, Rescher 1993). \nViews on matters of unity and unification make a difference in both\nscience and philosophy. In science they provide strong heuristic or\nmethodological guidance and even justification for hypotheses,\nprojects, and specific goals. In this sense, different rallying cries\nand idioms such as simplicity, unity, disunity, emergence or\ninterdisciplinarity, have been endowed with a normative value. Their\nevaluative role extends broadly. They are used to provide legitimacy,\neven if rhetorically, in social contexts especially in situations\ninvolving sources of funding and profit. They set a standard of what\ncarries the authority and legitimacy of what it is to be\nscientific. As a result, they make a difference in scientific\nevaluation, management and application, especially in public domains\nsuch as healthcare and economic decision-making. For instance,\npointing to the complexity of causal structures challenges traditional\ndeterministic or simple causal strategies of policy decision-making\nwith known risks and unknown effects of known properties (Mitchell\n2009). Last but not least is the influence that implicit assumptions\nabout what unification can do have on science education (Klein\n1990). \nPhilosophically, assumptions about unification help choose what sort\nof philosophical questions to pursue and what target areas to explore.\nFor instance, fundamentalist assumptions typically lead one to address\nepistemological and metaphysical issues in terms of only results and\ninterpretations of fundamental levels of disciplines. Assumptions of\nthis sort help define what counts as scientific and shape scientistic\nor naturalized philosophical projects. In this sense, they determine,\nor at least strongly suggest, what relevant science carries authority\nin philosophical debate. \nAt the end of the day one should not lose sight of the larger context\nthat sustains problems and projects in most disciplines and practices.\nWe are as free to pursue them as Kant’s dove is free to fly,\nthat is, not without the surrounding air resistance to flap its wings\nupon and against. Philosophy was once thought to stand for the\nsystematic unity of the sciences. The foundational character of unity\nbecame the distinctive project of philosophy, in which conceptual\nunity played the role of the standard of intelligibility. In addition,\nthe ideal of unity, frequently under the guise of harmony, has long\nbeen a standard of aesthetic virtue (This image has been eloquently\nchallenged by, for instance, John Bailey and Iris Murdoch; Bailey\n1976; Murdoch 1992).  Unities and unifications help us meet cognitive\nand practical demands upon our life as well as cultural demands upon\nour self-images that are both cosmic and earthly. It is not surprising\nthat talk of the many meanings of unity, namely, fundamental level,\nunification, system, organization, universality, simplicity, atomism,\nreduction, harmony, complexity or totality, can bring an urgent grip\non our intellectual imagination.","contact.mail":"jcat@indiana.edu","contact.domain":"indiana.edu"}]
