[{"date.published":"2013-05-22","url":"https://plato.stanford.edu/entries/continuum-hypothesis/","author1":"Peter Koellner","entry":"continuum-hypothesis","body.text":"\n\nThe continuum hypotheses (CH) is one of the most central open\nproblems in set theory, one that is important for both mathematical\nand philosophical reasons. \n\n The problem actually arose with the birth of set theory; indeed,\nin many respects it stimulated the birth of set theory. In 1874 Cantor\nhad shown that there is a one-to-one correspondence between the\nnatural numbers and the algebraic numbers. More surprisingly, he\nshowed that there is no one-to-one correspondence between the natural\nnumbers and the real numbers. Taking the existence of a one-to-one\ncorrespondence as a criterion for when two sets have the same size\n(something he certainly did by 1878), this result shows that there is\nmore than one level of infinity and thus gave birth to the higher\ninfinite in mathematics. Cantor immediately tried to determine whether\nthere were any infinite sets of real numbers that were\nof intermediate size, that is, whether there was an infinite\nset of real numbers that could not be put into one-to-one\ncorrespondence with the natural numbers and could not be put into\none-to-one correspondence with the real numbers. The continuum\nhypothesis (under one formulation) is simply the statement that\nthere is no such set of real numbers. It was through his attempt to\nprove this hypothesis that led Cantor do develop set theory into a\nsophisticated branch of \nmathematics.[1]\n\n Despite his efforts Cantor could not resolve CH. The problem\npersisted and was considered so important by Hilbert that he placed it\nfirst on his famous list of open problems to be faced by the\n20th century. Hilbert also struggled to resolve CH,\nagain without success. Ultimately, this lack of progress was explained\nby the combined results of Gödel and Cohen, which together showed\nthat CH cannot be resolved on the basis of the axioms that\nmathematicians were employing; in modern terms, CH is independent of\nZermelo-Fraenkel set theory extended with the Axiom of Choice (ZFC). \n\n This independence result was quickly followed by many others. The\nindependence techniques were so powerful that set theorists soon found\nthemselves preoccupied with the meta-theoretic enterprise of proving\nthat certain fundamental statements could not be proved or\nrefuted within ZFC. The question then arose as to whether there were\nways to settle the independent statements. The community of\nmathematicians and philosophers of mathematics was largely divided on\nthis question. The pluralists (like Cohen) maintained that\nthe independence results effectively settled the question by showing\nthat it had no answer. On this view, one could adopt a\nsystem in which, say CH was an axiom and one could adopt a system in\nwhich ¬CH was an axiom and that was the end of the\nmatter—there was no question as to which of two incompatible\nextensions was the “correct”\none. The non-pluralists (like Gödel) held that the\nindependence results merely indicated the paucity of our means for\ncircumscribing mathematical truth. On this view, what was needed were\nnew axioms, axioms that are both justified and sufficient for the\ntask. Gödel actually went further in proposing candidates for new\naxioms—large cardinal axioms—and he conjectured that they\nwould settle CH. \n\n Gödel's program for large cardinal axioms proved to be\nremarkably successful. Over the course of the next 30 years it was\nshown that large cardinal axioms settle many of the questions that\nwere shown to be independent during the era of independence. However,\nCH was left untouched. The situation turned out to be rather ironic\nsince in the end it was shown (in a sense that can be made precise)\nthat although the standard large cardinal axioms effectively settle\nall question of complexity strictly below that of CH, they cannot (by\nresults of Levy and Solovay and others) settle CH itself. Thus, in\nchoosing CH as a test case for his program, Gödel put his finger\nprecisely on the point where it fails. It is for this reason that CH\ncontinues to play a central role in the search for new axioms. \n\n In this entry we shall give an overview of the major approaches to\nsettling CH and we shall discuss some of the major foundational\nframeworks which maintain that CH does not have an answer. The subject\nis a large one and we have had to sacrifice full comprehensiveness in\ntwo dimensions. First, we have not been able to discuss the major\nphilosophical issues that are lying in the background. For this the\nreader is directed to the entry \n “Large Cardinals and Determinacy”, \nwhich contains a general discussion of the\nindependence results, the nature of axioms, the nature of\njustification, and the successes of large cardinal axioms in the realm\n“below CH”. Second, we have not been able to discuss every\napproach to CH that is in the literature. Instead we have restricted\nourselves to those approaches that appear most promising from a\nphilosophical point of view and where the mathematics has been\ndeveloped to a sufficiently advanced state. In the approaches we shall\ndiscuss—forcing axioms, inner model theory, quasi-large\ncardinals—the mathematics has been pressed to a very advanced\nstage over the course of 40 years. And this has made our task somewhat\ndifficult. We have tried to keep the discussion as accessible as\npossible and we have placed the more technical items in the\nendnotes. But the reader should bear in mind that we are presenting a\nbird's eye view and that for a higher resolution at any point\nthe reader should dip into the suggested readings that appear at the\nend of each section.[2]\n\n There are really two kinds of approaches to new\naxioms—the local approach and the global\napproach. On the local approach one seeks axioms that answer questions\nconcerning a specifiable fragment of the universe, such\nas Vω+1 or Vω+2, where\nCH lies. On the global approach one seeks axioms that attempt to\nilluminate the entire structure of the universe of sets. The\nglobal approach is clearly much more challenging. In this entry we\nshall start with the local approach and toward the end we shall\nbriefly touch upon the global approach. \n\n Here is an overview of the entry: Section 1 surveys the\nindependence results in cardinal arithmetic, covering both the case of\nregular cardinals (where CH lies) and singular cardinals. Section 2\nconsiders approaches to CH where one successively verifies a hierarchy\nof approximations to CH, each of which is an “effective”\nversion of CH. This approach led to the remarkable discovery of Woodin\nthat it is possible (in the presence of large cardinals) to have an\neffective failure of CH, thereby showing, that the effective failure\nof CH is as intractable (with respect to large cardinal axioms) as CH\nitself. Section 3 continues with the developments that stemmed from\nthis discovery. The centerpiece of the discussion is the discovery of\na “canonical” model in which CH fails. This formed the\nbasis of a network of results that was collectively presented by\nWoodin as a case for the failure of CH. To present this case in the\nmost streamlined form we introduce the strong logic\nΩ-logic. Section 4 takes up the competing foundational view that\nthere is no solution to CH. This view is sharpened in terms of\nthe generic multiverse conception of truth and that view is\nthen scrutinized. Section 5 continues the assessment of the case for\n¬CH by investigating a parallel case for CH. In the remaining two\nsections we turn to the global approach to new axioms and here we\nshall be much briefer. Section 6 discusses the approach through inner\nmodel theory. Section 7 discusses the approach through quasi-large\ncardinal axioms. \n\nIn this section we shall discuss the independence results in\ncardinal arithmetic. First, we shall treat of the case of regular\ncardinals, where CH lies and where very little is determined in the\ncontext of ZFC. Second, for the sake of comprehensiveness, we shall\ndiscuss the case of singular cardinals, where much more can be\nestablished in the context of ZFC.  The addition and multiplication of infinite cardinal numbers is\ntrivial: For infinite cardinals κ and λ,   The situation becomes interesting when one turns to exponentiation\nand the attempt to compute κλ for infinite\ncardinals.   During the dawn of set theory Cantor showed that for every\ncardinal κ,   There is no mystery about the size of 2n for\nfinite n. The first natural question then is where\n2ℵ0 is located in the aleph-hierarchy: Is it\nℵ1, ℵ2, …, ℵ17\nor something much larger?   The cardinal 2ℵ0 is important since\nit is the size of the continuum (the set of real numbers). Cantor's\nfamous continuum hypothesis (CH) is the statement that\n2ℵ0 =\nℵ1. This is a special case of the generalized\ncontinuum hypothesis (GCH) which asserts that for all α,\n2ℵα =\nℵα+1. One virtue of GCH is that it gives a\ncomplete solution to the problem of computing\nκλ for infinite cardinals: Assuming GCH, if\nκ ≤ λ then κλ =\nλ+; if cf(κ) ≤ λ ≤ κ then\nκλ = κ+; and if λ <\ncf(κ) then κλ = κ.   Very little progress was made on CH and GCH. In fact, in the early\nera of set theory the only other piece of progress beyond\nCantor's result that 2κ > κ (and\nthe trivial result that if κ ≤ λ then\n2κ ≤ 2λ) was König's\nresult that cf(2κ) > κ. The explanation\nfor the lack of progress was provided by the independence results in\nset theory:  To prove this Gödel invented the method of inner\nmodels —he showed that CH and GCH held in the minimal inner\nmodel L of ZFC. Cohen then complemented this result:  He did this by inventing the method of outer models and\nshowing that CH failed in a generic extension \nVB of V. The combined\nresults of Gödel and Cohen thus demonstrate that assuming the\nconsistency of ZFC, it is in principle impossible to settle either CH\nor GCH in ZFC.   In the Fall of 1963 Easton completed the picture by showing that\nfor infinite regular cardinals κ the only constraints\non the function κ ↦ 2κ that are provable in\nZFC are the trivial constraint and the results of Cantor and\nKönig:   Thus, set theorists had pushed the cardinal arithmetic of regular\ncardinals as far as it could be pushed within the confines of\nZFC.  The case of cardinal arithmetic on singular cardinals is much more\nsubtle. For the sake of completeness we pause to briefly discuss this\nbefore proceeding with the continuum hypothesis.   It was generally believed that, as in the case for regular\ncardinals, the behaviour of the function\nκ ↦ 2κ would be relatively unconstrained\nwithin the setting of ZFC. But then Silver proved the following\nremarkable result:[3] It turns out that (by a deep result of Magidor, published in 1977)\nGCH can first fail at ℵω (assuming the\nconsistency of a supercompact cardinal). Silver's theorem shows\nthat it cannot first fail at ℵω1\nand this is provable in ZFC.   This raises the question of whether one can “control”\nthe size of 2ℵδ with a weaker assumption\nthan that ℵδ is a singular cardinal of\nuncountable cofinality such that GCH holds below\nℵδ. The natural hypothesis to consider is\nthat ℵδ is a singular cardinal of uncountable\ncofinality which is a strong limit cardinal, that is, that\nfor all α < ℵδ,\n2α < ℵδ. In 1975\nGalvin and Hajnal proved (among other things) that under this weaker\nassumption there is indeed a bound:  It is possible that there is a jump—in fact, Woodin showed\n(again assuming large cardinals) that it is possible that for all\nκ, 2κ = κ++. What the above\ntheorem shows is that in ZFC there is a provable bound on how big the\njump can be.   The next question is whether a similar situation prevails with\nsingular cardinals of countable cofinality. In 1978 Shelah showed that\nthis is indeed the case. To fix ideas let us concentrate on\nℵω.  One drawback of this result is that the bound is sensitive to the\nactual size of 2ℵ0, which can be anything below\nℵω. Remarkably Shelah was later able to\nremedy this with the development of his pcf (possible cofinalities)\ntheory. One very quotable result from this theory is the\nfollowing:   In summary, although the continuum function at regular cardinals\nis relatively unconstrained in ZFC, the continuum function at singular\ncardinals is (provably in ZFC) constrained in significant ways by the\nbehaviour of the continuum function on the smaller cardinals.  Further Reading: For more cardinal arithmetic see Jech\n(2003). For more on the case of singular cardinals and pcf theory see\nAbraham & Magidor (2010) and Holz, Steffens & Weitz\n(1999).  Let us return to the continuum function on regular cardinals and\nconcentrate on the simplest case, the size of\n2ℵ0. One of Cantor's original approaches\nto CH was by investigating “simple” sets of real\nnumbers (see Hallett (1984), pp. 3–5 and §2.3(b)).  One of the first results in this direction is the\nCantor-Bendixson theorem that every infinite closed set is either\ncountable or contains a perfect subset, in which case it has the same\ncardinality as the set of reals. In other words, CH holds (in this\nformulation) when one restricts one's attention to closed sets\nof reals. In general, questions about “definable” sets of\nreals are more tractable than questions about arbitrary sets of reals\nand this suggests looking at definable versions of the continuum\nhypothesis.  There are three different formulations of the continuum\nhypothesis—the interpolant version,\nthe well-ordering version, and the surjection\nversion. These versions are all equivalent to one another in ZFC but\nwe shall be imposing a definability constraint and in this case there\ncan be interesting differences (our discussion follows\nMartin (1976)). There is really a hierarchy of notions\nof definability—ranging up through the Borel hierarchy, the\nprojective hierarchy, the hierarchy in L(ℝ), and, more\ngenerally, the hierarchy of universally Baire sets—and so each\nof these three general versions is really a hierarchy of versions,\neach corresponding to a given level of the hierarchy of\ndefinability (for a discussion of the hierarchy of\ndefinability see \n§2.2.1 and \n§4.6 of the entry \n “Large Cardinals and Determinacy”).\n The first formulation of CH is that there is\nno interpolant, that is, there is no infinite set A\nof real numbers such that the cardinality of A is strictly\nbetween that of the natural numbers and the real numbers. To obtain\ndefinable versions one simply asserts that there is no\n“definable” interpolant and this leads to a hierarchy of\ndefinable interpolant versions, depending on which notion of\ndefinability one employs. More precisely, for a given pointclass\nΓ in the hierarchy of definable sets of reals, the corresponding\ndefinable interpolant version of CH asserts that there is no\ninterpolant in Γ.   The Cantor-Bendixson theorem shows that there is no interpolant in\nΓ in the case where Γ is the pointclass of closed sets,\nthus verifying this version of CH. This was improved by Suslin who\nshowed that this version of CH holds for Γ where Γ is the\nclass of Σ̰11 sets. One cannot go much further within ZFC—to prove stronger\nversions one must bring in stronger assumptions. It turns out that\naxioms of definable determinacy and large cardinal axioms achieve\nthis. For example, results of Kechris and Martin show that if\nΔ̰1n-determinacy\nholds then this version of CH holds for the pointclass of\nΣ̰1n+1\nsets. Going further, if one assumes ADL(ℝ) then\nthis version of CH holds for all sets of real numbers appearing in\nL(ℝ). Since these hypotheses follow from large cardinal axioms\none also has that stronger and stronger large cardinal assumptions\nsecure stronger and stronger versions of this version of the effective\ncontinuum hypothesis. Indeed large cardinal axioms imply that this\nversion of CH holds for all sets of reals in the definability\nhierarchy we are considering; more precisely, if there is a proper\nclass of Woodin cardinals then this version of CH holds for all\nuniversally Baire sets of reals.  The second formulation of CH asserts that every well-ordering of\nthe reals has order type less than ℵ2. For a given\npointclass Γ in the hierarchy, the corresponding definable\nwell-ordering version of CH asserts that every well-ordering (coded by\na set) in Γ has order type less than ℵ2.   Again, axioms of definable determinacy and large cardinal axioms\nimply this version of CH for richer notions of definability. For\nexample, if ADL(ℝ) holds then this version of CH\nholds for all sets of real numbers in L(ℝ). And if there is a\nproper class of Woodin cardinals then this version of CH holds for all\nuniversally Baire sets of reals.  The third version formulation of CH asserts that there is no\nsurjection ρ : ℝ → ℵ2, or,\nequivalently, that there is no prewellordering of ℝ of length\nℵ2. For a given pointclass Γ in the hierarchy\nof definability, the corresponding surjection version of CH asserts\nthat there is no surjection ρ : ℝ → ℵ2 \nsuch that (the code for) ρ is in Γ.   Here the situation is more interesting. Axioms of definable\ndeterminacy and large cardinal axioms have bearing on this version\nsince they place bounds on how long definable prewellorderings can\nbe. Let \nδ̰1n\nbe the supremum of the lengths of the\nΣ̰1n-prewellorderings\nof reals and let ΘL(ℝ) be the supremum of the\nlengths of prewellorderings of reals where the prewellordering is\ndefinable in the sense of being in L(ℝ). It is a classical\nresult that δ̰11 =\nℵ1. Martin showed that δ̰12\n≤ ℵ2 and that if there is a measurable cardinal\nthen δ̰13\n≤ ℵ3. Kunen and Martin also showed under PD,\nδ̰14\n≤ ℵ4 and Jackson showed that under PD, for each n\n< ω, δ̰1n\n< ℵω. Thus, assuming that there are\ninfinitely many Woodin cardinals, these bounds hold. Moreover, the\nbounds continue to hold regardless of the size of\n2ℵ0. Of course, the question is whether these\nbounds can be improved to show that the prewellorderings are shorter\nthan ℵ2. In 1986 Foreman and Magidor initiated a\nprogram to establish this. In the most general form they aimed to show\nthat large cardinal axioms implied that this version of CH held for\nall universally Baire sets of reals.  Notice that in the context of ZFC, these three hierarchies of\nversions of CH are all successive approximations of CH and in the\nlimit case, where Γ is the pointclass of all sets of reals, they\nare equivalent to CH. The question is whether these approximations can\nprovide any insight into CH itself.   There is an asymmetry that was pointed out by Martin, namely, that\na definable counterexample to CH is a real counterexample, while no\nmatter how far one proceeds in verifying definable versions of CH at\nno stage will one have touched CH itself. In other words, the\ndefinability approach could refute CH but it could not prove it.   Still, one might argue that although the definability approach\ncould not prove CH it might provide some evidence for it. In the case\nof the first two versions we now know that CH holds for all definable\nsets. Does this provide evidence of CH? Martin pointed out (before the\nfull results were known) that this is highly doubtful since in each\ncase one is dealing with sets that are atypical. For example, in the\nfirst version, at each stage one secures the definable version of CH\nby showing that all sets in the definability class have the perfect\nset property; yet such sets are atypical in that assuming AC it is\neasy to show that there are sets without this property. In the second\nversion, at each stage one actually shows not only that each\nwell-ordering of reals in the definability class has ordertype less\nthan ℵ2, but also that it has ordertype less than\nℵ1. So neither of these versions really illuminates\nCH.   The third version actually has an advantage in this regard since\nnot all of the sets it deals with are atypical. For example, while all\nΣ̰11-sets\nhave length less than ℵ1, there are\nΠ̰11-sets\nof length ℵ1. Of course, it could turn out that\neven if the Foreman-Magidor program were to succeed the sets could\nturn out to be atypical in another sense, in which case it would shed\nlittle light on CH. More interesting, however, is the possibility that\nin contrast to the first two versions, it would actually provide an\nactual counterexample to CH. This, of course, would require the\nfailure of the Foreman-Magidor program.  The goal of the Foreman-Magidor program was to show that large\ncardinal axioms also implied that the third version of CH held for all\nsets in L(ℝ) and, more generally, all universally Baire sets. In\nother words, the goal was to show that large cardinal axioms implied\nthat ΘL(ℝ) ≤ ℵ2 and, more\ngenerally, that ΘL(A,ℝ)\n≤ ℵ2 for each universally Baire\nset A.   The motivation came from the celebrated results of Foreman,\nMagidor and Shelah on Martin's Maximum (MM), which showed that\nassuming large cardinal axioms one can always force to obtain a\nprecipitous ideal on ℵ2 without collapsing\nℵ2 (see Foreman, Magidor & Shelah (1988)). The program involved a two-part strategy:  This would show that show that ΘL(ℝ)\n≤ ℵ2 and, more generally that\nΘL(A,ℝ) ≤ ℵ2 for every\nuniversally Baire set A.[4]  In December 1991, the following result dashed the hopes of this\nprogram.  The point is that the hypothesis of this theorem can always be\nforced assuming large cardinals. Thus, it is possible to have\nΘL(ℝ) > ℵ2 (in fact,\nδ̰13\n> ℵ2).   Where did the program go wrong? Foreman and Magidor had an\napproximation to (B) and in the end it turned out that (B) is\ntrue.  So the trouble is with (A).   This illustrates an interesting contrast between our three\nversions of the effective continuum hypothesis, namely, that they can\ncome apart. For while large cardinals rule out definable\ncounterexamples of the first two kinds, they cannot rule out definable\ncounterexamples of the third kind. But again we must stress that they\ncannot prove that there are such counterexamples.   But there is an important point: Assuming large cardinal axioms\n(ADL(ℝ) suffices), although one can produce outer\nmodels in which δ̰13\n> ℵ2 it is not currently known how to\nproduce outer models in which δ̰13\n> ℵ3 or even ΘL(ℝ)\n> ℵ3. Thus it is an open possibility that\nfrom ZFC +ADL(ℝ) one can prove\nΘL(ℝ) ≤ ℵ3. Were this to\nbe the case, it would follow that although large cardinals cannot rule\nout the definable failure of CH they can rule out\nthe definable failure of 2ℵ0 =\nℵ2. This could provide some insight into the size\nof the continuum, underscoring the centrality of\nℵ2.  Further Reading: For more on the three effective versions\nof CH see Martin (1976); for more on the Foreman-Magidor program see\nForeman & Magidor (1995) and the introduction to Woodin (1999).  The above results led Woodin to the identification of a\n“canonical” model in which CH fails and this formed the\nbasis of his an argument that CH is false. In Section 3.1 we will\ndescribe the model and in the remainder of the section we will present\nthe case for the failure of CH. In Section 3.2 we will introduce\nΩ-logic and the other notions needed to make the case. In\nSection 3.3 we will present the case.  The goal is to find a model in which CH is false and which is\ncanonical in the sense that its theory cannot be altered by set\nforcing in the presence of large cardinals. The background motivation\nis this: First, we know that in the presence of large cardinal axioms\nthe theory of second-order arithmetic and even the entire theory of\nL(ℝ) is invariant under set forcing. The importance of this is\nthat it demonstrates that our main independence techniques cannot be\nused to establish the independence of questions about second-order\narithmetic (or about L(ℝ)) in the presence of large\ncardinals. Second, experience has shown that the large cardinal axioms\nin question seem to answer all of the major known open problems about\nsecond-order arithmetic and L(ℝ) and the set forcing invariance\ntheorems give precise content to the claim that these axioms are\n“effectively complete”.[5]  It follows that if ℙ is any homogeneous partial order in\nL(ℝ) then the generic extension L(ℝ)ℙ\ninherits the generic absoluteness of L(ℝ). Woodin discovered\nthat there is a very special partial order\nℙmax that has this feature. Moreover, the\nmodel L(ℝ)ℙmax satisfies ZFC +\n¬CH. The key feature of this model is that it is\n“maximal” (or “saturated”) with respect to\nsentences that are of a certain complexity and which can be shown to\nbe consistent via set forcing over the model; in other words, if these\nsentences can hold (by set forcing over the model)\nthen they do hold in the model. To state this more precisely\nwe are going to have to introduce a few rather technical notions.   There are two ways of stratifying the universe of sets. The first\nis in terms of 〈Vα | α\n∈ On 〉, the second is in terms of\n〈H(κ) | κ ∈ Card〉, where H(κ) is the set\nof all sets which have cardinality less than κ and whose members\nhave cardinality less than κ, and whose members of members have\ncardinality less than κ, and so on. For example, H(ω)\n= Vω and the theories of the structures\nH(ω1) and Vω+1 are mutually\ninterpretable. This latter structure is the structure of second-order\narithmetic and, as mentioned above, large cardinal axioms give us an\n“effectively complete” understanding of this structure. We\nshould like to be in the same position with regard to larger and\nlarger fragments of the universe and the question is whether we should\nproceed in terms of the first or the second stratification.   The second stratification is potentially more\nfine-grained. Assuming CH one has that the theories of\nH(ω2) and Vω+2 are mutually\ninterpretable and assuming larger and larger fragments of GCH this\ncorrespondence continues upward. But if CH is false then the structure\nH(ω2) is less rich than the\nstructure Vω2. In this event the latter\nstructure captures full third-order arithmetic, while the former\ncaptures only a small fragment of third-order arithmetic but is\nnevertheless rich enough to express CH. Given this, in attempting to\nunderstand the universe of sets by working up through it level by\nlevel, it is sensible to use the potentially more fine-grained\nstratification.   Our next step is therefore to understand\nH(ω2). It actually turns out that we will be able to\nunderstand slightly more and this is somewhat technical. We will be\nconcerned with the structure \n〈H(ω2), ∈, INS, AG〉\n⊧ φ, where INS is the non-stationary ideal\non ω1 and AG is the\ninterpretation of (the canonical representation of) a set of\nreals A in L(ℝ). The details will not be important and\nthe reader is asked to just think of H(ω2) along with\nsome “extra stuff” and not worry about the details\nconcerning the extra stuff.[6]  We are now in a position to state the main result:  There are two key points: First, the theory of\nL(ℝ)ℙmax is “effectively\ncomplete” in the sense that it is invariant under set\nforcing. Second, the model L(ℝ)ℙmax\nis “maximal” (or “saturated”) in the sense\nthat it satisfies all Π2-sentences (about the relevant\nstructure) that can possibly hold (in the sense that they can be shown\nto be consistent by set forcing over the model).   One would like to get a handle on the theory of this structure by\naxiomatizing it. The relevant axiom is the following:   Finally, this axiom settles CH:  We will now recast the above results in terms of a strong logic. We\nshall make full use of large cardinal axioms and in this setting we\nare interested in logics that are “well-behaved” in the\nsense that the question of what implies what is not radically\nindependent. For example, it is well known that CH is expressible in\nfull second-order logic. It follows that in the presence of large\ncardinals one can always use set forcing to flip the truth-value of a\npurported logical validity of full second-order logic. However, there\nare strong logics—like ω-logic and β-logic—that\ndo not have this feature—they are well-behaved in the sense that\nin the presence of large cardinal axioms the question of what implies\nwhat cannot be altered by set forcing. We shall introduce a very\nstrong logic that has this feature—Ω-logic. In fact, the\nlogic we shall introduce can be characterized as\nthe strongest logic with this feature (see\nKoellner (2010) for further discussion of strong logics and for a\nprecise statement of this result).  We say that a statement φ is Ω-satisfiable if\nthere exists an ordinal α and a complete Boolean\nalgebra B such\nthat VBα ⊧ φ,\nand we say that φ is Ω-valid if\n∅ ⊧Ω φ. So, the above theorem says\nthat (under our background assumptions), the statement “φ\nis Ω-satisfiable” is generically invariant and in terms of\nΩ-validity this is simply the following:  Thus this logic is robust in that the question of what implies what\nis invariant under set forcing.  Corresponding to the semantic relation ⊧Ω\nthere is a quasi-syntactic proof relation\n⊢Ω. The “proofs” are certain robust\nsets of reals (universally Baire sets of reals) and the test\nstructures are models that are “closed” under these\nproofs. The precise notions of “closure” and\n“proof” are somewhat technical and so we will pass over\nthem in silence.[7]  Like the semantic relation, this quasi-syntactic proof relation is\nrobust under large cardinal assumptions:   Thus, we have a semantic consequence relation and a\nquasi-syntactic proof relation, both of which are robust under the\nassumption of large cardinal axioms. It is natural to ask whether the\nsoundness and completeness theorems hold for these relations. The\nsoundness theorem is known to hold:  It is open whether the corresponding completeness theorem\nholds. The Ω Conjecture is simply the assertion that it\ndoes:   We will need a strong form of this conjecture which we shall call\nthe Strong Ω Conjecture. It is somewhat technical and so we will\npass over it in silence.[8] Recall that one key virtue of large cardinal axioms is that they\n“effectively settle” the theory of second-order arithmetic\n(and, in fact, the theory of L(ℝ) and more) in the sense that in\nthe presence of large cardinals one cannot use the method of set\nforcing to establish independence with respect to statements about\nL(ℝ). This notion of invariance under set forcing played a key\nrole in Section 3.1. We can now rephrase this notion in terms of\nΩ-logic.  The invariance of the theory of L(ℝ) under set forcing can\nnow be rephrased as follows:   Unfortunately, it follows from a series of results originating\nwith work of Levy and Solovay that traditional large cardinal axioms\ndo not yield Ω-complete theories at the level of\nΣ21 since\none can always use a “small” (and hence large cardinal\npreserving) forcing to alter the truth-value of CH.  Nevertheless, if one supplements large cardinal axioms then\nΩ-complete theories are forthcoming. This is the centerpiece of\nthe case against CH.   Let us rephrase this as follows: For each A satisfying (1),\nlet   The theorem says that if there is a proper class of Woodin\ncardinals and the Ω Conjecture holds, then there are\n(non-trivial) Ω-complete theories TA of\nH(ω2) and all such theories contain ¬CH.   It is natural to ask whether there is greater agreement among the\nΩ-complete theories TA. Ideally, there\nwould be just one. A recent result (building on Theorem 5.5) shows\nthat if there is one such theory then there are many such\ntheories.   How then shall one select from among these theories?\nWoodin's work in this area goes a good deal beyond Theorem\n5.1. In addition to isolating an axiom that satisfies (1) of Theorem\n5.1 (assuming Ω-satisfiability), he isolates a very special such\naxiom, namely, the axiom (∗) (“star”) mentioned\nearlier.   This axiom can be phrased in terms of (the provability notion of)\nΩ-logic:   It follows that of the various\ntheories TA involved in Theorem 5.1, there is\none that stands out: The theory T(∗) given by\n(∗). This theory maximizes the Π2-theory of the\nstructure 〈H(ω2), ∈, INS, A | A ∈ 𝒫\n(ℝ) ∩ L(ℝ)〉.   The continuum hypothesis fails in this theory. Moreover, in the\nmaximal theory T(∗) given by (∗) the\nsize of the continuum is ℵ2.[9]  To summarize: Assuming the Strong Ω Conjecture, there is a\n“good” theory of H(ω2) and all such\ntheories imply that CH fails. Moreover, (again, assuming the Strong\nΩ Conjecture) there is a maximal such theory and in that theory\n2ℵ0 = ℵ2.  Further Reading: For the mathematics concerning\nℙmax see Woodin (1999). For an introduction to\nΩ-logic see Bagaria, Castells & Larson (2006). For\nmore on incompatible Ω-complete theories see Koellner & Woodin\n(2009). For more on the case against CH see Woodin (2001a,b, 2005a,b).  The above case for the failure of CH is the strongest known local\ncase for axioms that settle CH. In this section and the next we will\nswitch sides and consider the pluralist arguments to the effect that\nCH does not have an answer (in this section) and to the effect that\nthere is an equally good case for CH (in the next section). In the\nfinal two section we will investigate optimistic global scenarios that\nprovide hope of settling the issue.   The pluralist maintains that the independence results effectively\nsettle the undecided questions by showing that they have no\nanswer. One way of providing a foundational framework for such a view\nis in terms of the multiverse. On this view there is not a\nsingle universe of set theory but rather\na multiverse of legitimate candidates, some of which may be\npreferable to others for certain purposes but none of which can be\nsaid to be the “true” universe. The multiverse\nconception of truth is the view that a statement of set theory\ncan only be said to be true simpliciter if it is true in all universes\nof the multiverse. For the purposes of this discussion we shall say\nthat a statement is indeterminate according to the multiverse\nconception if it is neither true nor false according to the\nmultiverse conception. How radical such a view is depends on the\nbreadth of the conception of the multiverse.  The pluralist is generally a non-pluralist about certain domains of\nmathematics. For example, a strict finitist might be a non-pluralist\nabout PA but a pluralist about set theory and one might be a\nnon-pluralist about ZFC and a pluralist about large cardinal axioms\nand statements like CH.   There is a form of radical pluralism which advocates pluralism\nconcerning all domains of mathematics. On this view any consistent\ntheory is a legitimate candidate and the corresponding models of such\ntheories are legitimate candidates for the domain of\nmathematics. Let us call this the broadest multiverse\nview. There is a difficulty in articulating this view, which may be\nbrought out as follows: To begin with, one must pick a background\ntheory in which to discuss the various models and this leads to a\ndifficult. For example, according to the broad multiverse conception,\nsince PA cannot prove Con(PA) (by the second incompleteness theorem,\nassuming that PA is consistent) there are models of PA + ¬Con(PA)\nand these models are legitimate candidates, that is, they are\nuniverses within the broad multiverse. Now to arrive at this\nconclusion one must (in the background theory) be in a position to\nprove Con(PA) (since this assumption is required to apply the second\nincompleteness theorem in this particular case). Thus, from the\nperspective of the background theory used to argue that the above\nmodels are legitimate candidates, the models in question satisfy a\nfalse\nΣ01-sentence,\nnamely, ¬Con(PA). In short, there is a lack of harmony between\nwhat is held at the meta-level and what is held at the\nobject-level.   The only way out of this difficulty would seem to be to regard\neach viewpoint—each articulation of the multiverse\nconception—as provisional and, when pressed, embrace pluralism\nconcerning the background theory. In other words, one would have to\nadopt a multiverse conception of the multiverse, a multiverse\nconception of the multiverse conception of the multiverse, and so on,\noff to infinity. It follows that such a position can never be fully\narticulated—each time one attempts to articulate the broad\nmultiverse conception one must employ a background theory but since\none is a pluralist about that background theory this pass at using the\nbroad multiverse to articulate the conception does not do the\nconception full justice. The position is thus difficult to\narticulate. One can certainly take the pluralist stance and\ntry to gesture toward or exhibit the view that one\nintends by provisionally settling on a particular background theory\nbut then advocate pluralism regarding that when pressed. The\nview is thus something of a “moving target”. We shall pass\nover this view in silence and concentrate on views that can be\narticulated within a foundational framework.   We will accordingly look at views which embrace non-pluralism with\nregard to a given stretch of mathematics and for reasons of space and\nbecause this is an entry on set theory we will pass over the long\ndebates concerning strict finitism, finitism, predicativism, and start\nwith views that embrace non-pluralism regarding ZFC.   Let the broad multiverse (based on ZFC) be the collection\nof all models of ZFC. The broad multiverse conception of truth (based\non ZFC) is then simply the view that a statement of set theory is true\nsimpliciter if it is provable in ZFC. On this view the statement\nCon(ZFC) and other undecided\nΠ01-statements\nare classified as indeterminate. This view thus faces a difficulty\nparallel to the one mentioned above concerning radical pluralism.   This motivates the shift to views that narrow the class of\nuniverses in the multiverse by employing a strong logic. For example,\none can restrict to universes that are ω-models, β-models\n(i.e., wellfounded), etc. On the view where one takes ω-models,\nthe statement Con(ZFC) is classified as true (though this is sensitive\nto the background theory) but the statement PM (all projective sets\nare Lebesgue measurable) is classified as indeterminate.   For those who are convinced by the arguments (surveyed in the\nentry \n “Large Cardinals and Determinacy”)\nfor large\ncardinal axioms and axioms of definable determinacy, even these\nmultiverse conceptions are too weak. We will follow this route. For\nthe rest of this entry we will embrace non-pluralism concerning large\ncardinal axioms and axioms of definable determinacy and focus on the\nquestion of CH.  The motivation behind the generic multiverse is to grant the case\nfor large cardinal axioms and definable determinacy but deny that\nstatements such as CH have a determinate truth value. To be specific\nabout the background theory let us take ZFC + “There is a proper\nclass of Woodin cardinals” and recall that this large cardinal\nassumption secures axioms of definable determinacy such as PD and\nADL(ℝ).   Let the generic multiverse \n𝕍 be the result of\nclosing V under generic extensions and generic refinements. One\nway to formalize this is by taking an external vantage point and start\nwith a countable transitive model M. The generic multiverse\nbased on M is then the smallest set \n𝕍M\nsuch that \nM ∈ 𝕍M\nand, for each pair of\ncountable transitive models (N, N[G]) such that N ⊧ ZFC and G\n⊆ ℙ is N-generic for some partial order in ℙ\n∈ N, if either N or N[G] is in \n𝕍M\nthen both N and N[G] are in \n𝕍M.   Let the generic multiverse conception of truth be the\nview that a statement is true simpliciter iff it is true in all\nuniverses of the generic multiverse. We will call such a statement\na generic multiverse truth. A statement is said to\nbe indeterminate according to the generic multiverse\nconception iff it is neither true nor false according to the\ngeneric multiverse conception. For example, granting our large\ncardinal assumptions, such a view deems PM (and PD and\nADL(ℝ)) true but deems CH indeterminate.  Is the generic multiverse conception of truth tenable? The answer\nto this question is closely related to the subject of\nΩ-logic. The basic connection between generic multiverse truth\nand Ω-logic is embodied in the following theorem:  Now, recall that by Theorem 3.5, under our background assumptions,\nΩ-validity is generically invariant. It follows that given our\nbackground theory, the notion of generic multiverse truth is robust\nwith respect to Π2-statements. In particular, for\nΠ2-statements, the statement “φ is\nindeterminate” is itself determinate according to the\ngeneric multiverse conception. In this sense the conception of truth\nis not “self-undermining” and one is not sent in a\ndownward spiral where one has to countenance multiverses of\nmultiverses. So it passes the first test. Whether it passes a more\nchallenging test depends on the Ω Conjecture.   The Ω Conjecture has profound consequences for the generic\nmultiverse conception of truth. Let   and, for any specifiable cardinal κ, let   where recall that H(κ+) is the collection of sets\nof hereditary cardinality less than κ+. Thus,\nassuming ZFC and that there is a proper class of Woodin cardinals, the\nset \n𝒱Ω is Turing equivalent to the set of\nΠ2 generic multiverse truths and the\nset \n𝒱Ω(H(κ+)) is precisely\nthe set of generic multiverse truths of H(κ+).   To describe the bearing of the Ω Conjecture on the\ngeneric-multiverse conception of truth, we introduce two Transcendence\nPrinciples which serve as constraints on any tenable conception of\ntruth in set theory—a truth constraint and\na definability constraint.  This constraint is in the spirit of those principles of set\ntheory—most notably, reflection principles—which aim to\ncapture the pretheoretic idea that the universe of sets is so rich\nthat it cannot “be described from below”; more precisely,\nit asserts that any tenable conception of truth must respect the idea\nthat the universe of sets is so rich that truth (or even just\nΠ2-truth) cannot be described in some specifiable\nfragment. (Notice that by Tarski's theorem on the undefinability\nof truth, the truth constraint is trivially satisfied by the standard\nconception of truth in set theory which takes the multiverse to\ncontain a single element, namely, V.)   There is also a related constraint concerning the definability of\ntruth. For a specifiable cardinal κ, set Y ⊆ ω\nis definable in H(κ+) across the\nmultiverse if Y is definable in the structure\nH(κ+) of each universe of the multiverse (possibly by\nformulas which depend on the parent universe).  Notice again that by Tarski's theorem on the undefinability\nof truth, the definability constraint is trivially satisfied by the\ndegenerate multiverse conception that takes the multiverse to contain\nthe single element V. (Notice also that if one modifies the\ndefinability constraint by adding the requirement that the definition\nbe uniform across the multiverse, then the constraint would\nautomatically be met.)   The bearing of the Ω Conjecture on the tenability of the\ngeneric-multiverse conception of truth is contained in the following\ntwo theorems:  In other words, if there is a proper class of Woodin cardinals and\nif the Ω Conjecture holds then the generic multiverse conception\nof truth violates both the Truth Constraint (at δ0)\nand the Definability Constraint (at δ0).   There are actually sharper versions of the above results that\ninvolve H(c+) in place of\nH(δ+0).  In other words, if there is a proper class of Woodin cardinals and\nif the Ω Conjecture holds then the generic-multiverse conception\nof truth violates the Truth Constraint at the level of third-order\narithmetic, and if, in addition, the AD+ Conjecture\nholds, then the generic-multiverse conception of truth violates the\nDefinability Constraint at the level of third-order arithmetic.  There appear to be four ways that the advocate of the generic\nmultiverse might resist the above criticism.   First, one could maintain that the Ω Conjecture is just as\nproblematic as CH and hence like CH it is to be regarded as\nindeterminate according to the generic-multiverse conception of\ntruth. The difficulty with this approach is the following:  Thus, in contrast to CH, the Ω Conjecture cannot be shown to\nbe independent of ZFC + “There is a proper class of Woodin\ncardinals” via set forcing. In terms of the generic multiverse\nconception of truth, we can put the point this way: While the\ngeneric-multiverse conception of truth deems CH to be indeterminate,\nit does not deem the Ω Conjecture to be\nindeterminate. So the above response is not available to the advocate\nof the generic-multiverse conception of truth. The advocate of that\nconception already deems the Ω Conjecture to be\ndeterminate.   Second, one could grant that the Ω Conjecture is determinate\nbut maintain that it is false. There are ways in which one might do\nthis but that does not undercut the above argument. The reason is the\nfollowing: To begin with there is a closely related\nΣ2-statement that one can substitute for the Ω\nConjecture in the above arguments. This is the statement that the\nΩ Conjecture is (non-trivially) Ω-satisfiable, that is,\nthe statement: There exists an ordinal α and a universe V′ of\nthe multiverse such that   and   This Σ2-statement is invariant under set forcing\nand hence is one adherents to the generic multiverse view of truth\nmust deem determinate. Moreover, the key arguments above go through\nwith this Σ2-statement instead of the Ω\nConjecture. The person taking this second line of response would thus\nalso have to maintain that this statement is false. But there is\nsubstantial evidence that this statement is true. The reason\nis that there is no known example of a Σ2-statement\nthat is invariant under set forcing relative to large cardinal axioms\nand which cannot be settled by large cardinal axioms. (Such a\nstatement would be a candidate for an absolutely undecidable\nstatement.) So it is reasonable to expect that this statement is\nresolved by large cardinal axioms. However, recent advances in inner\nmodel theory—in particular, those in Woodin (2010)—provide\nevidence that no large cardinal axiom can refute this\nstatement. Putting everything together: It is very likely that this\nstatement is in fact true ; so this line of response is not\npromising.   Third, one could reject either the Truth Constraint or the\nDefinability Constraint. The trouble is that if one rejects the Truth\nConstraint then on this view (assuming the Ω Conjecture)\nΠ2 truth in set theory is reducible in the sense of\nTuring reducibility to truth in H(δ0) (or,\nassuming the Strong Ω Conjecture, H(c+)). And\nif one rejects the Definability Constraint then on this view (assuming\nthe Ω Conjecture) Π2 truth in set theory is\nreducible in the sense of definability to truth in\nH(δ0) (or, assuming the Strong Ω Conjecture,\nH(c+)). On either view, the reduction is in tension\nwith the acceptance of non-pluralism regarding the background theory\nZFC + “There is a proper class of Woodin cardinals”.   Fourth, one could embrace the criticism, reject the generic\nmultiverse conception of truth, and admit that there are some\nstatements about\nH(δ+0)\n(or H(c+), granting, in addition, the\nAD+ Conjecture) that are true simpliciter but not true in\nthe sense of the generic-multiverse, and yet nevertheless continue to\nmaintain that CH is indeterminate. The difficulty is that any such\nsentence φ is qualitatively just like CH in that it can be forced\nto hold and forced to fail. The challenge for the advocate of this\napproach is to modify the generic-multiverse conception of truth in\nsuch a way that it counts φ as determinate and yet counts CH as\nindeterminate.   In summary: There is evidence that the only way out is the fourth\nway out and this places the burden back on the pluralist—the\npluralist must come up with a modified version of the generic\nmultiverse.  Further Reading: For more on the connection between\nΩ-logic and the generic multiverse and the above criticism of\nthe generic multiverse see Woodin (2011a). For the bearing of recent\nresults in inner model theory on the status of the Ω Conjecture\nsee Woodin (2010).  Let us now turn to a second way in which one might resist the local\ncase for the failure of CH. This involves a parallel case for CH. In\nSection 5.1 we will review the main features of the case for ¬CH\nin order to compare it with the parallel case for CH. In Section 5.2\nwe will present the parallel case for CH. In Section 5.3 we will\nassess the comparison.  Recall that there are two basic steps in the case presented in\nSection 3.3. The first step involves Ω-completeness (and this\ngives ¬CH) and the second step involves maximality (and this gives\nthe stronger 2ℵ0 = ℵ2). For\nease of comparison we shall repeat these features here:   The first step is based on the following result:  Let us rephrase this as follows: For each A satisfying (1),\nlet   The theorem says that if there is a proper class of Woodin\ncardinals and the Strong Ω Conjecture holds, then there are\n(non-trivial) Ω-complete theories TA of\nH(ω2) and all such theories contain ¬CH. In other\nwords, under these assumptions, there is a “good” theory\nand all “good” theories imply ¬CH.   The second step begins with the question of whether there is\ngreater agreement among the Ω-complete\ntheories TA. Ideally, there would be just\none. However, this is not the case.  Then there is an axiom B such that   This raises the issue as to how one is to select from among these\ntheories? It turns out that there is a maximal theory among\nthe TA and this is given by the axiom\n(∗).   if   is Ω-consistent, then   So, of the various theories TA involved\nin Theorem 5.1, there is one that stands out: The\ntheory T(∗) given by (∗). This theory\nmaximizes the Π2-theory of the structure 〈H(ω2), ∈, INS,\nA | A ∈ 𝒫\n(ℝ) ∩ L(ℝ)〉. The fundamental result is that in\nthis maximal theory  The parallel case for CH also has two steps, the first involving\nΩ-completeness and the second involving maximality.   The first result in the first step is the following:  Moreover, up to Ω-equivalence, CH is the unique\nΣ21-statement\nthat is Ω-complete for\nΣ21; that\nis, letting TA be the Ω-complete theory\ngiven by ZFC + A where A is\nΣ21, all\nsuch TA are Ω-equivalent\nto TCH and hence (trivially) all\nsuch TA contain CH. In other words, there is\na “good” theory and all “good” theories imply\nCH.   To complete the first step we have to determine whether this\nresult is robust. For it could be the case that when one considers the\nnext level,\nΣ22 (or\nfurther levels, like third-order arithmetic) CH is no longer part of\nthe picture, that is, perhaps large cardinals imply that there is an\naxiom A such that ZFC + A is Ω-complete for\nΣ22 (or,\ngoing further, all of third order arithmetic) and yet not all\nsuch A have an associated TA which\ncontains CH. We must rule this out if we are to secure the first\nstep.   The most optimistic scenario along these lines is this: The\nscenario is that there is a large cardinal axiom L and\naxioms A→ such that ZFC\n+ L + A→ is\nΩ-complete for all of third-order arithmetic and all such\ntheories are Ω-equivalent and imply CH. Going further, perhaps\nfor each specifiable fragment Vλ of the\nuniverse of sets there is a large cardinal axiom L and\naxioms A→ such that ZFC\n+ L + A→ is\nΩ-complete for the entire theory of Vλ\nand, moreover, that such theories are Ω-equivalent and imply\nCH. Were this to be the case it would mean that for each such λ\nthere is a unique Ω-complete picture\nof Vλ and we would have a unique\nΩ-complete understanding of arbitrarily large fragments of the\nuniverse of sets. This would make for a strong case for new axioms\ncompleting the axioms of ZFC and large cardinal axioms.   Unfortunately, this optimistic scenario fails: Assuming the\nexistence of one such theory one can construct another which differs\non CH:   This still leaves us with the question of existence and the answer\nto this question is sensitive to the Ω Conjecture and the\nAD+ Conjecture:  In fact, under a stronger assumption, the scenario must fail at a\nmuch earlier level.  It is open whether there can be such a theory at the level of\nΣ22. It\nis conjectured that ZFC + ◇ is Ω-complete (assuming large\ncardinal axioms) for\nΣ22.   Let us assume that it is answered positively and return to the\nquestion of uniqueness. For each such axiom A,\nlet TA be the\nΣ22\ntheory computed by ZFC + A in Ω-logic. The question of\nuniqueness simply asks whether TA is\nunique.  This is the parallel of Theorem 5.2.   To complete the parallel one would need that CH is among all of\nthe TA. This is not known. But it is a\nreasonable conjecture.  Should this conjecture hold it would provide a true analogue of\nTheorem 5.1. This would complete the parallel with the first\nstep.   There is also a parallel with the second step. Recall that for the\nsecond step in the previous subsection we had that although the\nvarious TA did not agree, they all contained\n¬CH and, moreover, from among them there is one that stands out,\nnamely the theory given by (∗), since this theory maximizes the\nΠ2-theory of the structure 〈H(ω2), ∈, INS, \nA | A ∈ P\n(ℝ) ∩ L(ℝ)〉. In the present context of CH we\nagain (assuming the conjecture) have that although\nthe TA do not agree, they all contain CH. It\nturns out that once again, from among them there is one that stands\nout, namely, the maximum one. For it is known (by a result of Woodin\nin 1985) that if there is a proper class of measurable Woodin\ncardinals then there is a forcing extension satisfying all\nΣ22\nsentences φ such that ZFC + CH + φ is\nΩ-satisfiable (see Ketchersid, Larson, & Zapletal\n(2010)).  It follows that if the question of existence is answered\npositively with an A that is\nΣ22\nthen TA must be this maximum\nΣ22\ntheory and, consequently, all TA agree\nwhen A is\nΣ22. So,\nassuming that there is a TA where A is\nΣ22,\nthen, although not all TA agree\n(when A is arbitrary) there is one that stands out, namely, the\none that is maximum for\nΣ22\nsentences.   Thus, if the above conjecture holds, then the case of CH\nparallels that of ¬CH, only now\nΣ22 takes\nthe place of the theory of H(ω2).  Assuming that the conjecture holds the case of CH parallels that of\n¬CH, only now\nΣ22 takes\nthe place of the theory of H(ω2): Under the\nbackground assumptions we have:   The two situations are parallel with regard to maximality but in\nterms of the level of Ω-completeness the first is stronger. For\nin the first case we are not just getting Ω-completeness with\nregard to the Π2 theory of H(ω2) (with\nthe additional predicates), rather we are getting Ω-completeness\nwith regard to all of H(ω2). This is\narguably an argument in favour of the case for ¬CH, even granting\nthe conjecture.   But there is a stronger point. There is evidence coming from inner\nmodel theory (which we shall discuss in the next section) to the\neffect that the conjecture is in fact false. Should this\nturn out to be the case it would break the parallel, strengthening the\ncase for ¬CH.   However, one might counter this as follows: The higher degree of\nΩ-completeness in the case for ¬CH is really illusory since\nit is an artifact of the fact that under (∗) the theory of\nH(ω2) is in fact mutually interpretable with that of\nH(ω1) (by a deep result of Woodin). Moreover, this\nlatter fact is in conflict with the spirit of the Transcendence\nPrinciples discussed in Section 4.3. Those principles were invoked in\nan argument to the effect that CH does not have an answer. Thus, when\nall the dust settles the real import of Woodin's work on CH (so\nthe argument goes) is not that CH is false but rather that CH\nvery likely has an answer.   It seems fair to say that at this stage the status of the local\napproaches to resolving CH is somewhat unsettled. For this reason, in\nthe remainder of this entry we shall focus on global approaches to\nsettling CH. We shall very briefly discuss two such\napproaches—the approach via inner model theory and the approach\nvia quasi-large cardinal axioms.  Inner model theory aims to produce “L-like”\nmodels that contain large cardinal axioms. For each large cardinal\naxiom Φ that has been reached by inner model theory, one has an\naxiom of the form V = LΦ. This axiom has the\nvirtue that (just as in the simplest case of V = L) it provides an\n“effectively complete” solution regarding questions\nabout LΦ (which, by assumption,\nis V). Unfortunately, it turns out that the axiom V\n= LΦ is incompatible with stronger\nlarge cardinal axioms Φ'. For this reason, axioms of this form\nhave never been considered as plausible candidates for new\naxioms.   But recent developments in inner model theory (due to Woodin) show\nthat everything changes at the level of a supercompact cardinal. These\ndevelopments show that if there is an inner model N which\n“inherits” a supercompact cardinal from V (in the\nmanner in which one would expect, given the trajectory of inner model\ntheory), then there are two remarkable consequences: First, N\nis close to V (in, for example, the sense that for sufficiently\nlarge singular cardinals λ, N correctly computes\nλ+). Second, N inherits all known large\ncardinals that exist in V. Thus, in contrast to the inner\nmodels that have been developed thus far, an inner model at the level\nof a supercompact would provide one with an axiom that\ncould not be refuted by stronger large cardinal\nassumptions.   The issue, of course, is whether one can have an\n“L-like” model (one that yields an\n“effectively complete” axiom) at this level. There is\nreason to believe that one can. There is now a candidate\nmodel LΩ that yields an axiom V\n= LΩ with the following features: First, V\n= LΩ is “effectively complete.”\nSecond, V = LΩ is compatible with all large\ncardinal axioms. Thus, on this scenario, the ultimate theory would be\nthe (open-ended) theory ZFC + V = LΩ + LCA,\nwhere LCA is a schema standing for “large cardinal\naxioms.” The large cardinal axioms will catch instances of\nGödelian independence and the axiom V\n= LΩ will capture the remaining instances of\nindependence. This theory would imply CH and settle the remaining\nundecided statements. Independence would cease to be an issue.   It turns out, however, that there are other candidate axioms that\nshare these features, and so the spectre of pluralism reappears. For\nexample, there are axioms V\n= LΩS\nand V\n= LΩ(∗). These\naxioms would also be “effectively complete” and compatible\nwith all large cardinal axioms. Yet they would resolve various\nquestions differently than the axiom V\n= LΩ. For example, the axiom, V\n= LΩ(∗)\nwould imply ¬CH. How, then, is one to adjudicate between\nthem?  Further Reading: For an introduction to inner model\ntheory see Mitchell (2010) and Steel (2010). For more on the recent\ndevelopments at the level of one supercompact and beyond see Woodin\n(2010).  This brings us to the second global approach, one that promises to\nselect the correct axiom from among V = LΩ, V\n= LΩS,\nV\n= LΩ(∗),\nand their variants. This approach is based on the remarkable analogy\nbetween the structure theory of L(ℝ) under the assumption of\nADL(ℝ) and the structure theory of\nL(Vλ+1) under the assumption that there is an\nelementary embedding from L(Vλ+1) into itself\nwith critical point below λ. This embedding assumption\nis the strongest large cardinal axiom that appears in the\nliterature.   The analogy between L(ℝ) and\nL(Vλ+1) is based on the observation that\nL(ℝ) is simply L(Vω+1). Thus, λ\nis the analogue of ω, λ+ is the analogue of\nω1, and so on. As an example of the parallel between\nthe structure theory of L(ℝ) under ADL(ℝ) and\nthe structure theory of L(Vλ+1) under the\nembedding axiom, let us mention that in the first case,\nω1 is a measurable cardinal in L(ℝ) and, in the\nsecond case, the analogue of ω1—namely,\nλ+—is a measurable cardinal in\nL(Vλ+1). This result is due to Woodin and is\njust one instance from among many examples of the parallel that are\ncontained in his work.   Now, we have a great deal of information about the structure\ntheory of L(ℝ) under ADL(ℝ). Indeed, as we\nnoted above, this axiom is “effectively complete” with\nregard to questions about L(ℝ). In contrast, the embedding axiom\non its own is not sufficient to imply that\nL(Vλ+1) has a structure theory that fully\nparallels that of L(ℝ) under ADL(ℝ). However,\nthe existence of an already rich parallel is evidence that the\nparallel extends, and we can supplement the embedding axiom by adding\nsome key components. When one does so, something remarkable happens:\nthe supplementary axioms become forcing fragile. This means\nthat they have the potential to erase independence and provide\nnon-trivial information about Vλ+1. For\nexample, these supplementary axioms might settle CH and much\nmore.   The difficulty in investigating the possibilities for the\nstructure theory of L(Vλ+1) is that we have\nnot had the proper lenses through which to view it. The trouble is\nthat the model L(Vλ+1) contains a large piece\nof the universe—namely,\nL(Vλ+1)—and the theory of this\nstructure is radically underdetermined. The results discussed above\nprovide us with the proper lenses. For one can examine the structure\ntheory of L(Vλ+1) in the context of ultimate\ninner models\nlike LΩ, LΩS, LΩ(∗),\nand their variants. The point is that these models can accommodate the\nembedding axiom and, within each, one will be able to compute the\nstructure theory of L(Vλ+1).   This provides a means to select the correct axiom from among V\n= LΩ, V\n= LΩS,\nV\n= LΩ(∗),\nand their variants. One simply looks at the\nL(Vλ+1) of each model (where the embedding\naxiom holds) and checks to see which has the true analogue of the\nstructure theory of L(ℝ) under the assumption of\nADL(ℝ). It is already known that certain pieces of\nthe structure theory cannot hold\nin LΩ. But it is open whether they can hold\nin LΩS.   Let us consider one such (very optimistic) scenario: The true\nanalogue of the structure theory of L(ℝ) under\nADL(ℝ) holds of the\nL(Vλ+1)\nof LΩS\nbut not of any of its variants. Moreover, this structure theory is\n“effectively complete” for the theory\nof Vλ+1. Assuming that there is a proper\nclass of λ where the embedding axiom holds, this gives an\n“effectively complete” theory of V. And,\nremarkably, part of that theory is that V must\nbe LΩS. This\n(admittedly very optimistic) scenario would constitute a very strong\ncase for axioms that resolve all of the undecided statements.   One should not place too much weight on this particular\nscenario. It is just one of many. The point is that we are now in a\nposition to write down a list of definite questions with the following\nfeatures: First, the questions on this list will have\nanswers—independence is not an issue. Second, if the answers\nconverge then one will have strong evidence for new axioms settling\nthe undecided statements (and hence non-pluralism about the universe\nof sets); while if the answers oscillate, one will have evidence that\nthese statements are “absolutely undecidable” and this\nwill strengthen the case for pluralism. In this way the questions of\n“absolute undecidability” and pluralism are given\nmathematical traction.  Further Reading: For more on the structure theory of\nL(Vλ+1) and the parallel with determinacy see\nWoodin (2011b). ","contact.mail":"koellner@fas.harvard.edu","contact.domain":"fas.harvard.edu"}]
