[{"date.published":"2005-10-05","date.changed":"2015-01-07","url":"https://plato.stanford.edu/entries/information-semantic/","author1":"Luciano Floridi","author1.info":"http://www.philosophyofinformation.net/","entry":"information-semantic","body.text":"\n\n\n\n“I love information upon all subjects that come in my way, and\nespecially upon those that are most important.” Thus boldly\ndeclares Euphranor, one of the defenders of Christian faith in\nBerkeley’s Alciphron (Dialogue 1, Section 5, Paragraph 6/10,\nsee Berkeley [1732]). Evidently, information has been an object of\nphilosophical desire for some time, well before the computer\nrevolution, Internet or the dot.com pandemonium (see for example Dunn\n[2001] and Adams [2003]). Yet what does Euphranor love, exactly?\nWhat is information? The question has received many answers\nin different fields. Unsurprisingly, several surveys do not even\nconverge on a single, unified definition of information (see for\nexample Braman [1989], Losee [1997], Machlup and Mansfield [1983],\nDebons and Cameron [1975], Larson and Debons [1983]).\n\n\n\nInformation is notoriously a polymorphic phenomenon and a polysemantic\nconcept so, as an explicandum, it can be associated with\nseveral explanations, depending on the level of abstraction adopted\nand the cluster of requirements and desiderata orientating a\ntheory. The reader may wish to keep this in mind while reading this\nentry, where some schematic simplifications and interpretative\ndecisions will be inevitable. Claude E. Shannon, for one, was very\ncautious:\n\n\n\n\nThe word ‘information’ has been given different meanings\nby various writers in the general field of information theory. It is\nlikely that at least a number of these will prove sufficiently useful\nin certain applications to deserve further study and permanent\nrecognition. It is hardly to be expected that a single concept of\ninformation would satisfactorily account for the numerous possible\napplications of this general field. (italics added). (Shannon\n[1993], p. 180)\n\n\n\nThus, following Shannon, Weaver [1949] supported a tripartite analysis\nof information in terms of\n\n\n\n\n(1) technical problems concerning the quantification of information\nand dealt with by Shannon’s theory\n\n\n\n(2) semantic problems relating to meaning and truth; and\n\n \n\n(3) what he called “influential” problems concerning\nthe impact and effectiveness of information on human behaviour, which\nhe thought had to play an equally important role.\n\n\n\n\nAnd these are only some early examples of the problems raised by any\nanalysis of information.\n\n\n\nIndeed, the plethora of different analyses can be confusing.\nComplaints about misunderstandings and misuses of the very idea of\ninformation are frequently expressed, even if to no apparent avail.\nSayre [1976], for example, criticised the “laxity in use of the\nterm ‘information’” in Armstrong [1968] (see now\nArmstrong [1993]) and in Dennett [1969] (see now Dennett [1986]),\ndespite appreciating several other aspects of their work. More\nrecently, Harms [1998] pointed out similar confusions in Chalmers\n[1996], who \n\n\n\n\n\nseems to think that the information theoretic notion of information\n[see section 3, my addition] is a matter of what possible states there\nare, and how they are related or structured […] rather than of\nhow probabilities are distributed among them. (p. 480).\n\n\n\n\n\nIn order to try to avoid similar pitfalls, this entry has been\norganised into four sections. Section 1 attempts to draw a map of the\nmain senses in which one may speak of semantic information,\nand does so by relying on the analysis of the concept of data\n(depicted in Figure 1 below). Sometimes the several concepts of\ninformation organised in the map can be variously coupled\ntogether. This should not be taken as necessarily a sign of confusion,\nfor in some philosophers it may be the result of an intentional\nbridging. The map is not exhaustive and it is there mainly in order to\navoid some obvious pitfalls and to narrow the scope of this article,\nwhich otherwise could easily turn into a short version of the\nEncyclopedia Britannica. Its schematism is only a starting point for\nfurther research and the reader interested in knowing more may wish to\nconsult Floridi [2011] and Adriaans and van Benthem [2008].\n\n\n\n\nAfter this initial orientation, Section 2 provides a brief\nintroduction to information theory, that is, to the mathematical\ntheory of communication (MTC). MTC deserves a space of its own because\nit is the quantitative approach to the analysis of information that\nhas been most influential among several philosophers. It provides the\nnecessary background to understand several contemporary theories of\nsemantic information, especially Bar-Hillel and Carnap [1953], Dretske\n[1981].\n\n\n\nSection 3 analyses information as semantic content. Section 4 focuses\nentirely on the philosophical understanding of semantic information,\nwhat Euphranor really loves.\n\n\n\nThe reader must also be warned that an initial account of semantic\ninformation as meaningful data will be used as yardstick to\noutline other approaches. Unfortunately, even such a minimalist account\nis open to disagreement. In favour of this approach one may say that at\nleast it is less controversial than others. Of course, a conceptual\nanalysis must start somewhere. This often means adopting some working\ndefinition of the object under scrutiny. But it is not this commonplace\nthat one needs to emphasize here. The difficulty is rather more\ndaunting. Philosophical work on the concept of (semantic) information\nis still at that lamentable stage when disagreement affects even the\nway in which the problems themselves are provisionally phrased and\nframed. Nothing comparable to the well-polished nature of the Gettier\nproblem is yet available, for example. So the “you are\nhere” signal provided in this article might be placed elsewhere\nby other philosophers. The whole purpose is to put the concept of\nsemantic information firmly on the philosophical map. Further\nadjustments will then become possible.\n\n\n\nInformation is a conceptual labyrinth, and in this section we shall\nbegin to have a look at a general map of one of its regions, with the\npurpose of placing ourselves squarely in the semantic area. Figure 1\nsummarises the main distinctions that are going to be introduced. Figure 1.\nAn informational map\n \n\nClearly, percolating through the various points in the map will not\nmake for a linear journey. Using a few basic examples, to illustrate\nthe less obvious steps, will also help to keep our orientation. So let\nus introduce immediately the one to which we shall return more\noften. \n\nMonday morning. You turn on the ignition key of your car, but\nnothing happens: the engine does not even cough. The silence of the\nengine worries you. Unsurprisingly, you also notice that the red light\nof the low battery indicator is flashing. After a few more attempts,\nyou give up and ring the garage. You explain that your husband forgot\nto switch off the lights of the car last night—it is a lie, you\ndid, but you are too ashamed to confess it—and now the battery\nis flat. The mechanic tells you that the instruction manual of your car\nexplains how to use jump leads to start the engine. Luckily, your\nneighbour has everything you need. You read the manual, look at the\nillustrations, follow the instructions, solve the problem and finally\ndrive to the office. \n\nThis everyday episode will be our “fruit fly”. Although\nit is simple and intuitive, it provides enough details to illustrate\nthe many ways in which we understand one of our most important\nresources: information. \n\nIt is common to think of information as consisting of data.\nIt certainly helps, if only to a limited extent. For, unfortunately,\nthe nature of data is not well-understood philosophically either,\ndespite the fact that some important past debates—such as the\none on the given and the one on sense data—have provided at\nleast some initial insights. There still remains the advantage,\nhowever, that the concept of data is less rich, obscure and slippery\nthan that of information, and hence easier to handle. So a data-based\ndefinition of information seems to be a good starting point. \n\nOver the last three decades, several analyses in Information\nScience, in Information Systems Theory, Methodology, Analysis and\nDesign, in Information (Systems) Management, in Database Design and in\nDecision Theory have adopted a General Definition of\nInformation (GDI) in terms of data + meaning.\n\nGDI has become an operational\nstandard, especially in fields that treat data and information as\nreified entities (consider, for example, the now common expressions\n“data mining” and “information management”).\nRecently, GDI has begun to influence the philosophy of computing and\ninformation (Floridi [1999] and Mingers [1997]). \nA clear way of formulating GDI is as a tripartite defintion: \n (GDI.1) \\(\\sigma\\) consists of one or more data; \n (GDI.2) the data in \\(\\sigma\\) are well-formed; \n (GDI.3) the well-formed data in \\(\\sigma\\) are meaningful. \n\nGDI requires a definition of data. This will be provided in the next\nsection. Before, a brief comment on each clause is in order.  \n According to (GDI.1), data are the stuff of which information is\nmade. We shall see that things can soon get more complicated.  \n In (GDI.2), “well-formed” means that the data are\nclustered together correctly, according to the rules (syntax)\nthat govern the chosen system, code or language being analysed. Syntax\nhere must be understood broadly (not just linguistically), as what\ndetermines the form, construction, composition or structuring of\nsomething (engineers, film directors, painters, chess players and\ngardeners speak of syntax in this broad sense). For example, the\nmanual of your car may show (see Figure 2) a two dimensional picture\nof the two cars placed one near the other, not one on top of the\nother. Figure 2.\nHow to jump start your car (Copyright © Bosch UK)\n \n\nThis pictorial syntax (including the linear perspective that\nrepresents space by converging parallel lines) makes the illustrations\npotentially meaningful to the user. Using the same example, the actual\nbattery needs to be connected to the engine in a correct way to\nfunction: this is still syntax, in terms of correct physical\narchitecture of the system (thus a disconnected battery is a syntactic\nproblem). And of course the conversation you carry on with your\nneighbour follows the grammatical rules of English: this is syntax in\nthe ordinary linguistic sense. \n\nRegarding (GDI.3), this is where semantics finally occurs.\n“Meaningful” means that the data must comply with the\nmeanings (semantics) of the chosen system, code or language\nin question. However, let us not forget that semantic information is\nnot necessarily linguistic. For example, in the case of the manual of\nthe car, the illustrations are such as to be visually meaningful to\nthe reader. \n\nAccording to GDI, information cannot be dataless but, in the simplest\ncase, it can consist of a single datum. Now a datum is reducible to\njust a lack of uniformity (diaphora is the Greek word for\n“difference”), so a general definition of a datum is: \n\nDepending on philosophical inclinations, DDD can be applied at three\nlevels: \n Depending on one’s position with respect to the thesis of ontological\nneutrality (section 1.6) and the nature of environmental information\n(section 1.7.1) dedomena in (1) may be either identical with, or what\nmakes possible signals in (2), and signals in (2) are what make\npossible the coding of symbols in (3). \n\nThe dependence of information on the occurrence of syntactically\nwell-formed data, and of data on the occurrence of differences\nvariously implementable physically, explain why information can so\neasily be decoupled from its support. The actual format,\nmedium and language in which semantic information is\nencoded is often irrelevant and hence disregardable. In particular,\nthe same semantic information may be analog or digital, printed on\npaper or viewed on a screen, in English or in some other language,\nexpressed in words or pictures. Interpretations of this\nsupport-independence can vary quite radically. For DDD (above) leaves\nunderdetermined \n\nWe shall now look at each form of neutrality in turn. \n\nA datum is usually classified as the entity exhibiting the anomaly,\noften because the latter is perceptually more conspicuous or less\nredundant than the background conditions. However, the relation of\ninequality is binary and symmetric. A white sheet of paper is not just\nthe necessary background condition for the occurrence of a black dot as\na datum, it is a constitutive part of the [black-dot-on-white-sheet]\ndatum itself, together with the fundamental relation of inequality that\ncouples it with the dot. Nothing seems to be a datum per se.\nRather, being a datum is an external property. So GDI endorses the\nfollowing thesis of taxonomic neutrality: \n\nThe slogan is “data are relata”, but GDI is neutral with\nrespect to the identification of data with specific\nrelata. In our example, GDI refrains from identifying either the red\nlight or the white background as the datum. To understand why there\ncannot be “dataless information”, we shall now look at the\ntypological neutrality of GDI. \n\nGDI also endorses the thesis of typological neutrality: \n Five classifications are quite common, although the\nterminology is not yet standard or fixed. \n\nThey are not mutually exclusive, and one should not\nunderstand them as rigid: depending on circumstances, on the sort of\nanalysis conducted and on the level of abstraction adopted, the same\ndata may fit different classifications. \n\nLet us now return to our question: can there be dataless information?\nGDI does not specify which types of data constitute information. This\ntypological neutrality (TyN, see above) is justified by the\nfact that, when the apparent absence of data is not reducible to the\noccurrence of negative primary data, what becomes available\nand qualifies as information is some further non-primary information\n\\(\\mu\\) about \\(\\sigma\\) constituted by some non-primary data\n(D2)–(D5). For example, if a database query provides an answer,\nit will provide at least a negative answer, e.g., “no\ndocuments found”. This is primary negative information. However,\nif the database provides no answer, either it fails to provide any\ndata at all, in which case no specific information \\(\\sigma\\) is\navailable—so the rule “no information without\ndata” still applies—or it can provide some data to\nestablish, for example, that it is running in a loop. Likewise,\nsilence, this time as a reply to a question, could represent negative\nprimary information, e.g., as implicit assent or denial, or it could\ncarry some non-primary information, e.g., about the fact that the\nperson has not heard the question, or about the amount of noise in the\nroom. \n\nBy rejecting the possibility of dataless information, GDI also\nendorses the following modest thesis of ontological neutrality: \n\nFollowing Landauer and Bennett [1985], and Landauer [1987]; [1991];\n[1996], (ON) is often interpreted materialistically, as advocating the\nimpossibility of physically disembodied information, through the\nequation “representation = physical implementation”, that\nis: \n\n(ON.1) is an inevitable assumption, when working on the physics of\ncomputation, since computer science must necessarily take into account\nthe physical properties and limits of the data carriers. Thus, the\ndebate on (ON.1) has flourished especially in the context of the\nphilosophy of quantum information and computing (see Deutsch [1985];\n[1997] and Di Vincenzo and Loss [1998]; Steane [1998] provides a\nreview). (ON.1) is also the ontological assumption behind the Physical\nSymbol System Hypothesis in AI and Cognitive Science (Newell and Simon\n[1976]). But (ON), and hence GDI, does not specify whether, ultimately,\nthe occurrence of every discrete state necessarily requires a\nmaterial implementation of the data representations. Arguably,\nenvironments in which all entities, properties and processes are\nultimately noetic (e.g., Berkeley, Spinoza), or in which the material or\nextended universe has a noetic or non-extended matrix as its\nontological foundation (e.g., Pythagoras, Plato, Descartes, Leibniz,\nFichte, Hegel), seem perfectly capable of upholding (ON) without\nnecessarily embracing (ON.1). The relata in DDD (above) could be\ndedomena, such as Leibnizian monads, for example. Indeed, the\nclassic realism debate on the ultimate nature of “being”\ncan be reconstructed in terms of the possible interpretations of\n(ON). \n\nAll this explains why GDI is also consistent with two other popular\nslogans, this time favourable to the proto-physical nature of\ninformation and hence completely antithetic to (ON.1): \n and \n\n(ON.2) endorses an information-theoretic, metaphysical monism: the\nuniverse’s essential nature is digital, being fundamentally composed\nof information as data/dedomena instead of matter or energy, with\nmaterial objects as a complex secondary manifestation (a similar\nposition has been defended more recently in physics by Frieden [1998],\nwhose work is based on a loosely Platonist perspective). (ON.2) may\nbut does not have to endorse a computational view of information\nprocesses. (ON.3) advocates a more pluralistic approach along similar\nlines. Both are compatible with GDI. \n\nA final comment concerning (GDI.3) can be introduced by discussing a\nfourth slogan: \n\n(ON.4) is one of the earliest and most popular formulations of GDI\n(see for example Franklin [1995], 34 and Chalmers [1996], 281). The\nformulation usually attributed to Mackay [1969] (yet not to be found\nin that text)—that is, “information is a\ndistinction that makes a difference”—predates\nBateson’s but it is slightly different from it in that, by speaking of\n“distinction” instead of “difference”, it has\nan epistemological rather than an ontological twist. A\n“difference” (a “distinction”) is just a\ndiscrete state, namely a datum, and “making a difference”\nsimply means that the datum is “meaningful”, at least\npotentially. \n\nFinally, let us consider the semantic nature of the data. How data\ncan come to have an assigned meaning and function in a semiotic system\nin the first place is one of the hardest problems in semantics.\nLuckily, the point in question here is not how but\nwhether data constituting information as semantic content can\nbe meaningful independently of an informee. The genetic\nneutrality (GeN) supported by GDI states that: \n\nBefore the discovery of the Rosetta Stone, Egyptian hieroglyphics were\nalready regarded as information, even if their semantics was beyond\nthe comprehension of any interpreter. The discovery of an interface\nbetween Greek and Egyptian did not affect the semantics of the\nhieroglyphics but only its accessibility. This is the weak,\nconditional-counterfactual sense in which (GDI.3) speaks of meaningful\ndata being embedded in information-carriers\ninformee-independently. GeN supports the possibility of\ninformation without an informed subject, to adapt a Popperian\nphrase. Meaning is not (at least not only) in the mind of the\nuser. GeN is to be distinguished from the stronger, realist thesis,\nsupported for example by Dretske [1981], according to which data could\nalso have their own semantics independently of an intelligent\nproducer/informer. This is also known as environmental\ninformation, a concept sufficiently important to deserve a brief\npresentation before we close this first part. \n\nOne of the most often cited example of environmental information is\nthe series of concentric rings visible in the wood of a cut tree trunk,\nwhich may be used to estimate its age. Yet “environmental”\ninformation does not need to be natural. Going back to our\nexample, when you turned the ignition key, the red light of the low\nbattery indicator flashed. This signal too can be interpreted as an\ninstance of environmental information. \n\nEnvironmental information is defined relative to an observer (an\ninformation agent), who is supposed to have no direct access to pure\ndata in themselves. It requires two systems \\(a\\) and \\(b\\)\nto be coupled in such a way that \\(a\\)’s being (of type, or\nin state) \\(F\\) is correlated to \\(b\\) being (of type, or in\nstate) \\(G\\), thus carrying for the observer the information that\n\\(b\\) is \\(G\\) (this analysis is adapted from Barwise and\nSeligman [1997], who improve on a similar account by Dretske\n[1981]): \n\nThe correlation above is usually nomic (it follows some\nlaw). It may be engineered—as in the case of the low battery\nindicator \\((a)\\) whose flashing \\((F)\\) is triggered by,\nand hence it is informative about, the battery \\((b)\\) being flat\n\\((G)\\). Or it may be natural, as when litmus—a natural\ncolouring matter from lichens—is used as an acid-alkali\nindicator because it turns red in acid solutions and blue in alkaline\nsolutions. Other typical examples include the correlation between\nfingerprints and personal identification. \n\nOne may be so used to see the low battery indicator flashing as\ncarrying the information that the battery is flat to find it hard to\ndistinguish, with sufficient clarity, between environmental and\nsemantic information. However, it is important to stress that\nenvironmental information may require or involve no semantics at all.\nIt may consist of (networks or patterns of) correlated data understood\nas mere differences or constraining affordances. Plants (e.g., a\nsunflower), animals (e.g., an amoeba) and mechanisms (e.g., a\nphotocell) are certainly capable of making practical use of\nenvironmental information even in the absence of any (semantic\nprocessing of) meaningful data. \n\nTo summarise, GDI defines information, broadly understood, as\nsyntactically well-formed and meaningful data. Its four types of\nneutrality (TaN, TyN, ON and GeN) represent an obvious advantage, as\nthey make GDI perfectly scalable to more complex cases and reasonably\nflexible in terms of applicability and compatibility. Indeed,\nphilosophers have variously interpreted and tuned these four\nneutralities according to their theoretical needs. \n\nOur next step is to check whether GDI is satisfactory when discussing\nthe most important type of semantic information, namely factual\ninformation. Before addressing this issue, however, we need to pause\nand look at the mathematical theory of communication\n(MTC). \n\nMTC is not the only successful mathematical approach to the concept\nof information. Fisher information (Frieden [2004]) and the\nalgorithmic information theory (Chaitin [1987]) provide two\nother important examples. However, MTC is certainly the most widely\nknown among philosophers. As such, it has had a profound impact on\nphilosophical analyses of semantic information, to which it has\nprovided both the technical vocabulary and at least the initial\nconceptual frame of reference. One needs to grasp its main gist if one\nwishes to make sense of the issuing philosophical debate. \n\nSome features of information are intuitive. We are used to information\nbeing encoded, transmitted and stored. One\nalso expects it to be additive (information \\(a +\\)\ninformation \\(b =\\) information \\(a + b)\\) and\nnon-negative, like other things in life, such as\nprobabilities and interest rates. If you ask a question, the worst\nscenario is that you receive no answer or a wrong answer, which will\nleave you with zero new information. \n\nSimilar properties of information are quantifiable. They are\ninvestigated by the mathematical theory of communication (MTC)\nwith the primary aim of devising efficient ways of encoding and\ntransferring data. \n\nThe name for this branch of probability theory comes from Shannon’s\nseminal work (Shannon and Weaver [1949]). Shannon pioneered this\nfield and obtained many of its principal results, but he acknowledged\nthe importance of previous work done by other researchers and\ncolleagues at Bell laboratories, most notably Nyquist and Hartley (see\nCherry [1978] and Mabon [1975]). After Shannon, MTC became known as\ninformation theory, an appealing but unfortunate label, which\ncontinues to cause endless misunderstandings. Shannon came to regret\nits widespread popularity, and we shall avoid using it in this\ncontext. \n\nThis second part of the article outlines some of the key ideas\nbehind MTC, with the aim of understanding the relation between MTC and\nsome philosophical theories of semantic information. The reader with no\ntaste for mathematical formulae may wish to go directly to section 2.2,\nwhere some conceptual implications of MTC are outlined. The reader\ninterested in knowing more may start by reading Weaver [1949], Pierce\n[1980], Shannon and Weaver [1949 rep. 1998], then Jones [1979], and\nfinally Cover and Thomas [1991]. The latter two are technical texts.\nFloridi [2010] provides a brief and simplified analysis oriented to philosophy\nstudents.\n \n\nMTC has its origin in the field of electrical engineering, as the\nstudy of communication limits. It develops a quantitative approach to\ninformation as a means to answer two fundamental problems: the ultimate\nlevel of data compression (how small can a message be, given the same\namount of information to be encoded?) and the ultimate rate of data\ntransmission (how fast can data be transmitted over a channel?). The\ntwo solutions are the entropy \\(H\\) in equation [9] (see below)\nand the channel capacity \\(C\\). The rest of this section\nillustrates how to get from the problems to the solutions. \n\nTo have an intuitive sense of the approach, let us return to our\nexample. Recall the telephone conversation with the mechanic. In Figure\n2, the wife is the informer, the mechanic is the\ninformee, “the battery is flat” is the (semantic)\nmessage (the informant), there is a coding and decoding\nprocedure through a natural language (English), a channel of\ncommunication (the telephone system) and some possible noise. Informer\nand informee share the same background knowledge about the collection\nof usable symbols (technically known as the alphabet; in the\nexample this is English). Figure 3.\nCommunication model (adapted from Shannon and Weaver [1949])\n \n\nMTC is concerned with the efficient use of the resources indicated in\nFigure 3. Now, the conversation with the mechanic is fairly realistic\nand hence more difficult to model than a simplified case. We shall\nreturn to it later but, in order to introduce MTC, imagine instead a\nvery boring device that can produce only one symbol. Edgar Alan Poe\nwrote a short story in which a raven can answer only\n“nevermore” to any question. Poe’s raven is called a\nunary device. Imagine you ring the garage and your call is\nanswered by Poe’s raven. Even at this elementary level, Shannon’s\nsimple model of communication still applies. It is obvious that the\nraven (a unary device) produces zero amount of\ninformation. Simplifying, we already know the outcome of the\ncommunication exchange, so our ignorance (expressed by our question)\ncannot be decreased. Whatever the informational state of the system\nis, asking appropriate questions (e.g., “Will I be able to make\nthe car start?”, “Can you come to fix the car?”) of\nthe raven does not make any difference. Note that, interestingly\nenough, this is the basis of Plato’s famous argument in the\nPhaedrus against the value of semantic information provided\nby written texts:  \n[Socrates]: Writing, Phaedrus, has this\nstrange quality, and is very like painting; for the creatures of\npainting stand like living beings, but if one asks them a question,\nthey preserve a solemn silence. And so it is with written words; you\nmight think they spoke as if they had intelligence, but if you\nquestion them, wishing to know about their sayings, they always say\nonly one and the same thing [they are unary devices, in our\nterminology]. And every word, when [275e] once it is written, is\nbandied about, alike among those who understand and those who have no\ninterest in it, and it knows not to whom to speak or not to speak;\nwhen ill-treated or unjustly reviled it always needs its father to\nhelp it; for it has no power to protect or help itself.\n \n\nAs Plato well realises a unary source answers every question all the\ntime with only one message, not with silence or message, since silence\ncounts as a message, as we saw in 2.5, when discussing the nature of\nsecondary information. It follows that a completely silent source also\nqualifies as a unary source. And if silencing a source (censorship) may\nbe a nasty way of making a source uninformative, it is well known that\ncrying wolf is a classic case in which an informative source degrades\nto the role of uninformative unary device. \n\nConsider now a binary device that can produce two symbols, like a fair\ncoin \\(A\\) with its two equiprobable symbols \\(\\{h, t\\}\\); or, as\nMatthew 5:37 suggests, “Let your communication be Yea, yea; Nay,\nnay: for whatsoever is more than these cometh of evil”. Before\nthe coin is tossed, the informee (for example a computer) is in a\nstate of data deficit greater than zero: the informee does\nnot “know” which symbol the device will actually\nproduce. Shannon used the technical term “uncertainty” to\nrefer to data deficit. In a non-mathematical context this can be a\nvery misleading term because of the strong epistemological\nconnotations of this term. Remember that the informee can be a simple\nmachine, and psychological, mental or doxastic states are clearly\nirrelevant. \n\nOnce the coin has been tossed, the system produces an amount of\ninformation that is a function of the possible outputs, in this case 2\nequiprobable symbols, and equal to the data deficit that it\nremoves. \n\nLet us now build a slightly more complex system, made of two fair\ncoins \\(A\\) and \\(B\\). The \\(AB\\) system can produce 4 ordered\noutputs: \\(\\langle h, h\\rangle , \\langle h, t\\rangle , \\langle t, h\\rangle , \\langle t, t\\rangle\\). It\ngenerates a data deficit of 4 units, each couple counting as a symbol\nin the source alphabet. In the \\(AB\\) system, the occurrence of each\nsymbol \\(\\langle \\cdot, \\cdot \\rangle\\) removes a higher data deficit than the\noccurrence of a symbol in the \\(A\\) system. In other words, each\nsymbol provides more information. Adding an extra coin would produce a\n8 units of data deficit, further increasing the amount of information\ncarried by each symbol in the \\(ABC\\) system, and so on. \n\nWe are now ready to generalise the examples. Call the number of\npossible symbols \\(N\\). For \\(N = 1\\), the amount of\ninformation produced by a unary device is 0. For \\(N = 2\\), by\nproducing an equiprobable symbol, the device delivers 1 unit of\ninformation. And for \\(N = 4\\), by producing an equiprobable\nsymbol the device delivers the sum of the amount of information\nprovided by a device producing one of two equiprobable symbols (coin\n\\(A\\) in the example above) plus the amount of information\nprovided by another device producing one of two equiprobable symbols\n(coin \\(B)\\), that is, 2 units of information, although the total\nnumber of symbols is obtained by multiplying \\(A\\)’s symbols by\n\\(B\\)’s symbols. Now, our information measure should be a\ncontinuous and monotonic function of the probability of the symbols.\nThe most efficient way of satisfying these requirements is by using\nthe logarithm to the base 2 of the number of possible symbols (the\nlogarithm to the base 2 of a number \\(n\\) is the power to which 2\nmust be raised to give the number \\(n\\), for example\n\\(\\log_2 8 = 3\\), since \\(2^3 = 8)\\). Logarithms have the\nuseful property of turning multiplication of symbols into addition of\ninformation units. By taking the logarithm to the base 2 (henceforth\nlog simply means \\(\\log_2)\\) we have the further advantage of\nexpressing the units in bits. The base is partly a matter of\nconvention, like using centimetres instead of inches, partly a matter\nof convenience, since it is useful when dealing with digital devices\nthat use binary codes to represent data. \n\nGiven an alphabet of \\(N\\) equiprobable symbols, we can now\nuse equation [1]: \n to rephrase some examples more precisely: \nSome communication devices and their information power \n\nThe basic idea is all in equation [1]. Information can be quantified\nin terms of decrease in data deficit (Shannon’s\n“uncertainty”). Unfortunately, real coins are always\nbiased. To calculate how much information they produce one must rely\non the frequency of the occurrences of symbols in a finite series of\ntosses, or on their probabilities, if the tosses are supposed to go on\nindefinitely. Compared to a fair coin, a slightly biased coin must\nproduce less than 1 bit of information, but still more than 0. The\nraven produced no information at all because the occurrence of a\nstring \\(S\\) of “nevermore” was not\ninformative (not surprising, to use Shannon’s more\nintuitive, but psychologistic vocabulary), and that is because the\nprobability of the occurrence of “nevermore” was\nmaximum, so overly predictable. Likewise, the amount of information\nproduced by the biased coin depends on the average\ninformativeness (also known as average surprisal,\nanother unfortunate term to refer to the average statistical rarity)\nof the string \\(S\\) of \\(h\\) and \\(t\\) produced by the\ncoin. The average informativeness of the resulting string \\(S\\)\ndepends on the probability of the occurrence of each symbol.\nThe higher the frequency of a symbol in \\(S\\), the less\ninformation is being produced by the coin, up to the point when the\ncoin is so biased to produce always the same symbol and stops being\ninformative at all, behaving like the raven or the boy who cries\nwolf. \n\nSo, to calculate the average informativeness of \\(S\\) we need to know\nhow to calculate \\(S\\) and the informativeness of the\n\\(i^{\\text{th}}\\) symbol in general. This requires understanding what\nthe probability of the \\(i^{\\text{th}}\\) symbol \\((P_i)\\) to occur is. \n\nThe probability \\(P_i\\) of the \\(i^{\\text{th}}\\) symbol can be\n“extracted” from equation [1], where it is embedded in\n\\(\\log(N)\\), a special case in which the symbols are\nequiprobable. Using some elementary properties of the logarithmic\nfunction, we have: \n\nThe value of \\(1/N = P\\) can range from 0 to 1. If Poe’s raven\nis our source, the probability of it saying “good morning”\nis 0. In the case of the coin, \\(P(h) + P(t) = 1\\), no matter how\nbiased the coin is. Probability is like a cake that gets sliced more\nand more thinly depending on the number of guests, but never grows\nbeyond its original size and, in the worst case scenario, can at most\nbe equal to zero, but never become “negative”. More\nformally, this means: \n\nThe sigma notation in [3] is simply a shortcut that indicates that\nif we add all probabilities values from \\(i = 1\\) to \\(i =\\)\nN their sum is equal to 1. \n\nWe can now be precise about the raven: “nevermore” is not\ninformative at all because \\(P_{nevermore} = 1\\). Clearly, the lower\nthe probability of occurrence of a symbol, the higher is the\ninformativeness of its actual occurrence. The informativeness \\(u\\) of\nthe \\(i^{\\text{th}}\\) symbol can be expressed by analogy with\n\\(-\\log(P)\\) in equation [4]: \n Next, we need to calculate the length of a general string\n\\(S\\). Suppose that the biased coin, tossed 10 times, produces the\nstring: \\(\\langle h, h, t, h, h, t, t, h, h, t\\rangle\\). The (length of the)\nstring \\(S\\) (in our case equal to 10) is equal to the number of times\nthe \\(h\\) type of symbol occurs added to the numbers of times the\n\\(t\\) type of symbol occurs. \n\nGeneralising for \\(i\\) types of symbols: \n\nPutting together equations [4] and [5] we see that the average\ninformativeness for a string of \\(S\\) symbols is the sum of the\ninformativeness of each symbol divided by the sum of all symbols: \n\nTerm [6] can be simplified thus: \n\nNow \\(S_i /S\\) is the frequency with which the \\(i^{\\text{th}}\\)\nsymbol occurs in \\(S\\) when \\(S\\) is finite. If the length of \\(S\\) is\nleft undetermined (as long as one wishes), then the frequency of the\n\\(i^{\\text{th}}\\) symbol becomes its probability \\(P_i\\). So, further\ngeneralising term [7], we have: \n\nFinally, by using equation [4] we can substitute for\n\\(u_i\\) and obtain \n\nEquation [9] is Shannon’s formula for \\(H =\\) uncertainty, which\nwe have called data deficit (actually, Shannon’s original\nformula includes a positive constant \\(K\\) which amounts to a\nchoice of a unit of measure, bits in our case; apparently, Shannon\nused the letter \\(H\\) because of R.V.L. Hartley’s previous\nwork). \n\nEquation [9] indicates that the quantity of information produced by\na device corresponds to the amount of data deficit erased. It is a\nfunction of the average informativeness of the (potentially unlimited)\nstring of symbols produced by the device. It is easy to prove that, if\nsymbols are equiprobable, [9] reduces to [1] and that the highest\nquantity of information is produced by a system whose symbols are\nequiprobable (compare the fair coin to the biased one). \n\nTo arrive at [9] we have used some very simple examples: a raven and a\nhandful of coins. Things in life are far more complex, witness our\nMonday morning accident. For example, we have assumed that the strings\nof symbols are ergodic: the probability distribution for the\noccurrences of each symbol is assumed to be stable through time and\nindependently of the selection of a certain string. Our raven and\ncoins are discrete and zero-memory sources. The\nsuccessive symbols they produce are statistically independent. But in\nreal life occurrences of symbols are often interdependent. Sources can\nbe non-ergodic and have a memory. Symbols can be continuous, and the\noccurrence of one symbol may depend upon a finite number \\(n\\) of\npreceding symbols, in which case the string is known as a Markov chain\nand the source an \\(n^{\\text{th}}\\) order Markov\nsource. Consider for example the probability of hearing\n“n” (followed by the string “ing”) after\nhaving received the string of letters “Good mor_” over the\nphone, when you called the garage. And consider the same example\nthrough time, in the case of a child (the son of the mechanic) who is\nlearning how to answer the phone instead of his father. In brief, MTC\ndevelops the previous analysis to cover a whole variety of more\ncomplex cases. We shall stop here, however, because in the rest of\nthis section we need to concentrate on other central aspects of\nMTC. \n\nThe quantitative approach just sketched plays a fundamental role in\ncoding theory (hence in cryptography) and in data storage and\ntransmission techniques. MTC is primarily a study of the properties of\na channel of communication and of codes that can efficiently encipher\ndata into recordable and transmittable signals. Since data can be\ndistributed either in terms of here/there or now/then, diachronic\ncommunication and synchronic analysis of a memory can be based on the\nsame principles and concepts (our coin becomes a bistable circuit or\nflip-flop, for example). Two concepts that play a pivotal role both in\ncommunication analysis and in memory management are so important to\ndeserve a brief explanation: redundancy and\nnoise. \n\nConsider our \\(AB\\) system. Each symbol occurs with 0.25\nprobability. A simple way of encoding its symbols is to associate each\nof them with two digits, as follows: \n\nIn Code 1 a message conveys 2 bits of information, as expected. Do not\nconfuse bits as bi-nary units of\ninformation (recall that we decided to use log\\(_2\\) also as a\nmatter of convenience) with bits as bi-nary\ndigits, which is what a 2-symbols system like a CD-ROM uses\nto encode a message. Suppose now that the \\(AB\\) system is\nbiased, and that the four symbols occur with the following\nprobabilities: \n\nThis biased system produces less information, so by using Code 1 we\nwould be wasting resources. A more efficient Code 2 (see below) should\ntake into account the symbols’ probabilities, with the following\noutcomes: \n\nIn Code 2, known as Fano Code, a message conveys 1.75 bits of\ninformation. One can prove that, given that probability distribution,\nno other coding system will do better than Fano Code. \n\nIn real life, a good codification is also modestly redundant.\nRedundancy refers to the difference between the physical\nrepresentation of a message and the mathematical representation of the\nsame message that uses no more bits than necessary.\nCompression procedures work by reducing data redundancy, but\nredundancy is not always a bad thing, for it can help to counteract\nequivocation (data sent but never received) and\nnoise (data received but unwanted). A message + noise\ncontains more data than the original message by itself, but the aim of\na communication process is fidelity, the accurate transfer of\nthe original message from sender to receiver, not data increase. We\nare more likely to reconstruct a message correctly at the end of the\ntransmission if some degree of redundancy counterbalances the\ninevitable noise and equivocation introduced by the physical process\nof communication and the environment. Noise extends the informee’s\nfreedom of choice in selecting a message, but it is an undesirable\nfreedom and some redundancy can help to limit it. That is why the\nmanual of your car includes both verbal explanations and pictures to\nconvey (slightly redundantly) the same information. \n\nWe are now ready to understand Shannon’s two fundamental\ntheorems. Suppose the 2-coins biased system \\(AB\\) produces the\nfollowing message: \\(\\langle t, h\\rangle \\langle h, h\\rangle \\langle t, t\\rangle \\langle h,\nt\\rangle \\langle h, t\\rangle\\). Using Fano Code we\nobtain: 11001111010. The next step is to send this string through a\nchannel. Channels have different transmission rates \\((C)\\),\ncalculated in terms of bits per second (bps). Shannon’s fundamental\ntheorem of the noiseless channel states that: \n\nIn other words, if you devise a good code you can transmit symbols\nover a noiseless channel at an average rate as close to\n\\(C/H\\) as one may wish but, no matter how clever the\ncoding is, that average can never exceed \\(C/H\\). We have\nalready seen that the task is made more difficult by the inevitable\npresence of noise. However, the fundamental theorem for a discrete\nchannel with noise comes to our rescue: \n\nRoughly, if the channel can transmit as much or more information than\nthe source can produce, then one can devise an efficient way to code\nand transmit messages with as small an error probability as\ndesired.  \n These two fundamental theorems are among Shannon’s greatest\nachievements. They are limiting results in information theory that\nconstrain any conceptual analysis of semantic information. They are\nthus comparable to Gödel’s, Turing’s, and Church’s theorems in\nlogic and computation. With our message finally sent, we may close\nthis section and return to a more philosophical approach. \n\nFor the mathematical theory of communication (MTC), information is\nonly a selection of one symbol from a set of possible symbols, so a\nsimple way of grasping how MTC quantifies information is by\nconsidering the number of yes/no questions required to determine what\nthe source is communicating. One question is sufficient to determine\nthe output of a fair coin, which therefore is said to produce 1 bit of\ninformation. A 2-fair-coins system produces 4 ordered outputs: \\(\\langle\nh, h\\rangle , \\langle h, t\\rangle , \\langle t, h\\rangle , \\langle t, t\\rangle\\) and therefore\nrequires at least two questions, each output containing 2 bits of\ninformation, and so on. This erotetic (the Greek word for\n“question”) analysis clarifies two important points. \n\nFirst, MTC is not a theory of information in the ordinary sense of\nthe word. In MTC, information has an entirely technical meaning.\nConsider some examples. According to MTC, two equiprobable\n“yes”’s contain the same quantity of information, no\nmatter whether their corresponding questions are “have the lights\nof your car been left switched on for too long, without recharging the\nbattery?” or “would you marry me?”. If we knew that a\ndevice could send us, with equal probabilities, either this article or\nthe whole Stanford Encyclopedia of Philosophy, by receiving\none or the other we would receive very different amounts of bytes of\ndata but actually only one bit of information in the MTC sense of the\nword. On June 1 1944, the BBC broadcasted a line from Verlaine’s\nSong of Autumn: “Les sanglots longs des violons de\nAutumne”. The message contained almost 1 bit of information, an\nincreasingly likely “yes” to the question whether the D-Day\ninvasion was imminent. The BBC then broadcasted the second line\n“Blessent mon coeur d’une longueur monotone”. Another\nalmost meaningless string of letters, but almost another bit of\ninformation, since it was the other long-expected “yes” to\nthe question whether the invasion was to take place immediately. German\nintelligence knew about the code, intercepted those messages and even\nnotified Berlin, but the high command failed to alert the Seventh Army\nCorps stationed in Normandy. Hitler had all the information in\nShannon’s sense of the word, but failed to understand (or believe\nin) the crucial importance of those two small bits of data. As for\nourselves, we were not surprised to conclude in the previous section\nthat the maximum amount of information (again, in the MTC sense of the\nword) is produced by a text where each character is equally\ndistributed, that is by a perfectly random sequence. According to MTC,\nthe classic monkey randomly pressing typewriter keys is indeed\nproducing a lot of information. \n\nSecond, since MTC is a theory of information without meaning (not in\nthe sense of meaningless, but in the sense of not yet meaningful), and\nsince we have seen that [information \\(-\\) meaning = data],\n“mathematical theory of data communication” is a far more\nappropriate description of this branch of probability theory than\n“information theory”. This is not a mere question of\nlabels. Information, as semantic content (more on this shortly), can\nalso be described erotetically as data + queries. Imagine a\npiece of (propositional) information such as “the earth has only\none moon”. It is easy to polarise almost all its semantic\ncontent by transforming it into a [query + binary answer], such as\n[does the earth have only one moon? + yes]. Subtract the\n“yes”—which is at most 1 bit of information, in\nthe equiprobable case of a yes or no answer—and you are left\nwith virtually all the semantic content, fully de-alethicised (from\naletheia, the Greek word for truth; the query is neither true\nnor false). To use a Fregean expression, semantic content is\nunsaturated information, where the latter is semantic\ninformation that has been “eroteticised” and from which a\nquantity of information has been subtracted equal to\n\\(-\\log P(\\text{yes})\\), with \\(P\\) being the\nprobability of the yes-answer. \n\nThe datum “yes” works as a key to unlock the information\ncontained in the query. MTC studies the codification and transmission\nof information by treating it as data keys, that is, as the amount of\ndetails in a signal or message or memory space necessary to saturate\nthe informee’s unsaturated information. As Weaver [1949] remarked\n“the word information relates not so much to what you do say, as\nto what you could say. The mathematical theory of communication deals\nwith the carriers of information, symbols and signals, not with\ninformation itself. That is, information is the measure of your freedom\nof choice when you select a message” (p. 12). \n\nSince MTC deals not with semantic information itself but with the\ndata that constitute it, that is, with messages comprising\nuninterpreted symbols encoded in well-formed strings of signals, it is\ncommonly described as a study of information at the syntactic\nlevel. MTC can be successfully applied in ICT (information and\ncommunication technologies) because computers are syntactical devices.\nWhat remains to be clarified is how \\(H\\) in equation [9] should\nbe interpreted. \n\n\\(H\\) is also known in MTC as entropy. It seems we owe\nthis confusing label to John von Neumann, who recommended it to Shannon: \n“You should call it entropy for two reasons: first, the function\nis already in use in thermodynamics under the same name; second, and\nmore importantly, most people don’t know what entropy really is,\nand if you use the word entropy in an argument you will win\nevery time” (quoted by Golan [2002]). \n Von Neumann proved to be right on both accounts, unfortunately. \n\nAssuming the ideal case of a noiseless channel of communication,\n\\(H\\) is a measure of three equivalent quantities: \n\n\\(H\\) can equally indicate (a) or (b) because, by selecting a\nparticular alphabet, the informer automatically creates a data deficit\n(uncertainty) in the informee, which then can be satisfied (resolved)\nin various degrees by the informant. Recall the erotetic game.\nIf you use a single fair coin, I immediately find myself in a 1 bit\ndeficit predicament: I do not know whether it is head or tail. Use two\nfair coins and my deficit doubles, but use the raven, and my deficit\nbecomes null. My empty glass (point (b) above) is an exact measure of\nyour capacity to fill it (point (a) above). Of course, it makes sense\nto talk of information as quantified by \\(H\\) only if one can\nspecify the probability distribution. \n\nRegarding (c), MTC treats information like a physical quantity, such\nas mass or energy, and the closeness between equation [9] and the\nformulation of the concept of entropy in statistical mechanics was\nalready discussed by Shannon. The informational and the thermodynamic\nconcept of entropy are related through the concepts of probability and\nrandomness (“randomness” is better than\n“disorder” since the former is a syntactical concept\nwhereas the latter has a strongly semantic value, that is, it is easily\nassociated to interpretations, as I used to try to explain to my\nparents when I was young). Entropy is a measure of the amount of\n“mixedupness” in processes and systems bearing energy or\ninformation. Entropy can also be seen as an indicator of reversibility:\nif there is no change of entropy then the process is reversible. A\nhighly structured, perfectly organised message contains a lower degree\nof entropy or randomness, less information in Shannon sense, and hence\nit causes a smaller data deficit, which can be close to zero (remember\nthe raven). By contrast, the higher the potential randomness of the\nsymbols in the alphabet, the more bits of information can be produced\nby the device. Entropy assumes its maximum value in the extreme case of\nuniform distribution, which is to say that a glass of water with a cube\nof ice contains less entropy than the glass of water once the cube has\nmelted, and a biased coin has less entropy than a fair coin. In\nthermodynamics, we know that the greater the entropy, the less\navailable the energy. This means that high entropy corresponds to high\nenergy deficit, but so does entropy in MTC: higher values of \\(H\\)\ncorrespond to higher quantities of data deficit. \n\nWe have seen that, when data are well-formed and meaningful, the\nresult is also known as semantic content (Bar-Hillel and\nCarnap [1953]; Bar-Hillel [1964]). Information, understood as semantic\ncontent, comes in two main varieties: factual and instructional. In our\nexample, one may translate the red light flashing into semantic content\nin two senses: \n\nIn this third part of the article we shall be concerned primarily\nwith (a), so it is better to clear the ground by considering (b) first.\nIt is the last detour in our journey. \n\nInstructional information is a type of semantic content. An\ninstruction booklet, for example, provides instructional information,\neither imperatively—in the form of a recipe: first do this,\nthen do that—or conditionally, in the form of some inferential\nprocedure: if such and such is the case do this, otherwise do\nthat. \n\nInstructional information is not about a situation, a fact, or a\nstate of affairs \\(w\\) and does not model, or describe or\nrepresent \\(w\\). Rather, it is meant to (help to) bring about\n\\(w\\). For example, when the mechanic tells one over the phone to\nconnect a charged battery to the flat battery of one’s car, the\ninformation one receives is not factual, but instructional. \n\nThere are many plausible contexts in which a stipulation (“let\nthe value of \\(x = 3\\)” or “suppose we discover the\nbones of a unicorn”), an invitation (“you are cordially\ninvited to the college party”), an order (“close the\nwindow!”), an instruction (“to open the box turn the\nkey”), a game move (“1.e2-e4 c7-c5” at the beginning\nof a chess game) may be correctly qualified as kinds of instructional\ninformation. The printed score of a musical composition or the digital\nfiles of a program may also be counted as typical cases of\ninstructional information. \n\nAll these instances of information have a semantic side: they have to\nbe at least potentially meaningful (interpretable) to count as\ninformation. Moreover, instructional information may be related to\nfactual (descriptive) information in performative contexts, such as\nchristening (e.g., “this ship is now called HMS The\nInformer”) or programming (e.g., as when deciding the type\nof a variable). The two types of semantic information (instructional\nand factual) may also come together in magic spells, where semantic\nrepresentations of \\(x\\) may be (wrongly) supposed to provide\nsome instructional power and control over \\(x\\). Nevertheless, as\na test, one should remember that instructional information does not\nqualify alethically (cannot be correctly qualified as true or false).\nIn the example, it would be silly to ask whether the information\n“only use batteries with the same rated voltage” is true.\nStipulations, invitations, orders, instructions, game moves, and\nsoftware cannot be true or false. As Wittgenstein remarks “The\nway music speaks. Do not forget that a poem, even though it is\ncomposed in the language of information, is not used in the\nlanguage-game of giving information.” (Zettel,\n§160, see Wittgenstein [1981]) \n\nIn the language game that Wittgenstein seems to have in mind, the\nnotion of “semantic information” is intended in a\ndeclarative or factual mode. Factual information may be true or untrue\n(false, in case one adopts a binary logic). True semantic\ncontent is the most common sense in which information seems to be\nunderstood (Floridi [2004]). Quine [1970, pp. 3–6, 98–99], for\nexample, equates “likeness of meaning” “sameness of\nproposition” and “sameness of objective information”\nby treating propositions as information in the factual sense just\nhighlighted (having the same meaning means conveying the same\nobjective information, though according to Quine, this only rephrases\nthe problem). The factual sense is also one of the most important,\nsince information as true semantic content is a necessary condition\nfor knowledge. Some elaboration is in order, and in the following\nsub-sections we shall briefly look at the concept of data as\nconstraining affordances, at the role played by levels of abstraction\nin the transformation of constraining affordances into factual\ninformation, and finally at the relation between factual information\nand truth. \n\nThe data that constitute factual information allow or invite certain\nconstructs (they are affordances for the information agent\nthat can take advantage of them) and resist or impede some others (they\nare constraints for the same agent), depending on the\ninteraction with, and the nature of, the information agent that\nprocesses them. For example, the red light flashing repetitively and\nthe engine not starting allow you (or any other information agent like\nyou) to construct the information that (a) the battery is flat, while\nmaking it more difficult to you (or any other information agent like\nyou) to construct the information that (b) there is a short circuit\naffecting the proper functioning of the low battery indicator, where\nthe engine fails to start because there is no petrol in the tank, a\nfact not reported by the relevant indicator which is affected by the\nsame short circuit. This is the sense in which data are\nconstraining affordances for (an information agent responsible\nfor) the elaboration of factual information. \n\nIn section 1.3, we saw that the concept of pure data in themselves\n(dedomena) is an abstraction, like Kant’s noumena or Locke’s\nsubstance. The point made was that data are never accessed and\nelaborated (by an information agent) independently of a level of\nabstraction (‘LoA’) (see also the comparable concept\nof “matrix” in Quine [1970]). The time has come to clarify\nwhat a LoA is. \n\nA LoA is a specific set of typed variables, intuitively representable\nas an interface, which establishes the scope and type of data that\nwill be available as a resource for the generation of\ninformation. This concept of LoA is purely epistemological, and it\nshould not be confused with other forms of “levellism”\nthat are more or less explicitly based on an ontological commitment\nconcerning the intrinsic architecture, syntax or structure of the\nsystem discussed (Dennett [1971], Marr [1982], Newell [1982], Simon\n[1969], see now Simon [1996]; Poli [2001] provides a reconstruction of\nontological levellism; more recently, Craver [2004] has analysed\nontological levellism, especially in biology and cognitive\nscience). Ontological levellism has come under increasing attack. Heil\n[2003] and Schaffer [2003] have seriously and convincingly questioned\nits plausibility. However, epistemological levellism is flourishing,\nespecially in computer science (Roever et al. [1998], Hoare\nand Jifeng [1998]), where it is regularly used to satisfy the\nrequirement that systems constructed in levels (in order to tame their\ncomplexity) function correctly. \n\nThrough a LoA, an information agent (the observer) accesses a physical\nor conceptual environment, the system. LoAs are not necessarily\nhierarchical and they are comparable. They are interfaces that mediate\nthe epistemic relation between the observed and the\nobserver. Consider, for example, a motion detector (Figure 4). In the\npast, motion detectors caused an alarm whenever a movement was\nregistered within the range of the sensor, including the swinging of a\ntree branch (object \\(a\\) in Figure 4). The old LoA\\(_1\\)\nconsisted of a single typed variable, which may be labelled\n‘movement’. Nowadays, when a PIR (passive infrared)\nmotion detector registers some movement, it also monitors the presence\nof an infrared signal, so the entity detected has to be something that\nalso emits infrared radiation—usually perceived as heat\n— before the sensor activates the alarm. The new LoA\\(_2\\)\nconsists of two typed variables: ‘movement’ and\n‘infrared radiation’. Clearly, your car (object \\(b\\)\nin Figure 4) leaving your house is present for both LoAs; but for the\nnew LoA\\(_2\\), which is more finely grained, the branch of the\ntree swinging in the garden is absent. Likewise, a stone in the garden\n(object \\(c\\) in Figure 4) is absent for both the new and the old\nLoA, since it satisfies no typed variable of either one. Figure 4.\nAn example of Levels of Abstraction\n \n\nThe method of LoA is an efficient way of making explicit and\nmanaging the ontological commitment of a theory. In our case,\n“the battery is what provides electricity to the car” is a\ntypical example of information elaborated at a driver’s LoA. An\nengineer’s LoA may output something like “12-volt lead-acid\nbattery is made up of six cells, each cell producing approximately 2.1\nvolts”, and an economist’s LoA may suggest that “a\ngood quality car battery will cost between $50 and $100 and, if\nproperly maintained, it should last five years or more”. \n\nData as constraining affordances—answers waiting for the\nrelevant questions—are transformed into factual information by\nbeing processed semantically at a given LoA (alternatively: the\nrelevant question is associated to the right answer at a given LoA).\nOnce data as constraining affordances have been elaborated into factual\ninformation at a given LoA, the next question is whether truth values\nsupervene on factual information. \n\nDoes some factual content qualify as information only if it is true?\nDefenders of the alethic neutrality of semantic information (Fetzer\n[2004] and Dodig-Crnkovic [2005], who criticise Floridi [2004];\nColburn [2000], Fox [1983], among situation theorists Devlin [1991],\nand Scarantino and Piccinini [2010]) argue that meaningful and\nwell-formed data already qualify as information, no matter whether\nthey represent or convey a truth or a falsehood or indeed have no\nalethic value at all. Opponents, on the other hand, object that\n“[…] false information\nand mis-information are not kinds of information—any\nmore than decoy ducks and rubber ducks are kinds of ducks”\n(Dretske [1981], 45) and that “false information is not an\ninferior kind of information; it just is not information” (Grice\n[1989], 371; other philosophers who accept a truth-based definition of\nsemantic information are Barwise and Seligman [1997] and Graham\n[1999]). The result is a definition of factual semantic information as\nwell-formed, meaningful and truthful data (defended in Floridi\n[2005]), where “truthful” is only a stylistic choice to be\npreferred to “true” because it enables one to say that a\nmap conveys factual information insofar as it is truthful. \n\nOnce again, the debate is not about a mere definition, but concerns\nthe possible consequences of the alethic neutrality thesis, three of\nwhich can be outlined here, whereas a fourth requires a longer analysis\nand will be discussed in section 4.1. \n\nIf the thesis “meaningful and well-formed data already qualify\nas information” is correct then \n\nAll these new issues are grafted to some old branches of the\nphilosophical tree.  \n Whether false information is a genuine type of information has\nimportant repercussions on any philosophy and pragmatics of\ncommunication. \n\nThe question about the informative nature (or lack thereof) of\nnecessary truths, tautologies, equations or identity statements is an\nold one, as it runs through Hume, Kant, Frege and Wittgenstein. The\nlatter, for example, interestingly remarked: \n The solution of the problem of hyperintensionality (how one can draw\na semantic distinction between expressions that are supposed to have\nthe same meaning according to a particular theory of meaning that is\nusually model-theoretic or modal in character) depends on how one can\nmake sense of the relation between truth and informativeness in the\ncase of logically equivalent expressions. \n\nFinally, the possibly redundant qualification of information as true\nis also linked with the critique of the deflationary theories of truth\n(DTT), since one could accept a deflationary T-schema as perfectly\ncorrect, while rejecting the explanatory adequacy of DTT. “It is\ntrue that” in “it is true that \\(p\\)” could be\nredundant in view of the fact that there cannot be factual information\nthat is not true, but DTT could mistake this linguistic or conceptual\nredundancy for unqualified dispensability. “It is true\nthat” could be redundant because, strictly speaking, information\nis not a truth-bearer but already encapsulates truth as truthfulness.\nThus, DTT may be satisfactory as theories of truth-ascriptions while\nbeing inadequate as theories of truthfulness. \n\nOnce information is available, knowledge can be built in terms of\njustifiable or explainable semantic\ninformation. An information agent knows that the battery is flat\nnot by merely guessing rightly, but because e.g., it perceives that the\nred light of the low battery indicator flashing and/or that the engine\ndoes not start. In this sense, information provides the basis of any\nfurther scientific investigation. Note, however, that the fact that\ndata may count as resources for (i.e., inputs an agent can use\nto construct) information, and hence for knowledge, rather than\nsources, may lead to constructionist arguments against mimetic\ntheories that interpret information as some sort of picture of the\nworld. The point requires some elaboration. \n\nWhether empirical or conceptual, data make possible only a certain\nrange of information constructs, and not all constructs are made\npossible equally easily. An analogy may help here. Suppose one has to\nbuild a shelter. The design and complexity of the shelter may vary, but\nthere is a limited range of “realistic” possibilities,\ndetermined by the nature of the available resources and constraints\n(size, building materials, location, weather, physical and biological\nenvironment, working force, technical skills, purposes, security, time\nconstraints, etc.). Not any shelter can be built. And the type of\nshelter that will be built more often will be the one that is more\nlikely to take close-to-optimal advantage of the available resources\nand constraints. The same applies to data. Data are at the same time\nthe resources and constraints that make possible the construction of\ninformation. The best information is that better tuned to the\nconstraining affordances available. Thus informational coherence and\nadequacy do not necessarily entail nor support naïve or direct\nrealism, or a correspondence theory of truth as this is ordinarily\npresented. Ultimately, information is the result of a process of data\nmodelling; it does not have to represent or photograph or portray or\nphotocopy, or map or show or uncover or monitor or … the\nintrinsic nature of the system analysed, no more than an igloo\ndescribes the intrinsic nature of snow or the Parthenon indicates the\nreal properties of stones. \n\nWhen semantic content is false, this is a case of\nmisinformation (Fox [1983]). And if the source of\nmisinformation is aware of its nature, one may speak of\ndisinformation, as when one says to the mechanic “my\nhusband forgot to turn the lights off”. Disinformation and\nmisinformation are ethically censurable but may be successful in\nachieving their purpose: tell the mechanic that your husband left the\nlights on last night, and he will still be able to provide you with the\nright advice. Likewise, information may still fail to be successful;\njust imagine telling the mechanic that your car is out of order. \n\nWhat is the relation between MTC and the sort of semantic\ninformation that we have called factual? The mathematical theory of\ncommunication approaches information as a physical phenomenon. Its\ncentral question is whether and how much uninterpreted data can be\nencoded and transmitted efficiently by means of a given alphabet and\nthrough a given channel. MTC is not interested in the meaning,\n“aboutness”, relevance, reliability, usefulness or\ninterpretation of information, but only in the level of detail and\nfrequency in the uninterpreted data, being these symbols, signals or\nmessages. Philosophical approaches differ from MTC in two main\nrespects. \n\nFirst, they seek to give an account of information as\nsemantic content, investigating questions like “how can\nsomething count as information? and why?”, “how can\nsomething carry information about something else?”, “how\ncan semantic information be generated and flow?”, “how is\ninformation related to error, truth and knowledge?”, “when\nis information useful?”. Wittgenstein, for example, remarks\nthat \n\nSecond, philosophical theories of semantic information also seek to\nconnect it to other relevant concepts of information and more complex\nforms of epistemic, mental and doxastic phenomena. For instance,\nDretske [1981] and Barwise and Seligman [1997] attempt to ground\ninformation, understood as factual semantic contents, on environmental\ninformation. The approach is also known as the naturalization of\ninformation. A similar point can be made about Putnam’s twin\nearths argument, the externalization of semantics and\nteleosemantics. \n\nPhilosophical analyses usually adopt a propositional orientation and\nan epistemic outlook, endorsing, often implicitly, the prevalence or\ncentrality of factual information within the map outlined in Figure 1.\nThey tend to base their analyses on cases such as “Paris is the\ncapital of France” or “The Bodleian Library is in\nOxford”. How relevant is MTC to similar researches? \n\nIn the past, some research programs tried to elaborate information\ntheories alternative to MTC, with the aim of incorporating the\nsemantic dimension. Donald M. Mackay [1969] proposed a quantitative\ntheory of qualitative information that has interesting connections with\nsituation logic (see below). According to MacKay, information\nis linked to an increase in knowledge on the receiver’s side:\n“Suppose we begin by asking ourselves what we mean by\ninformation. Roughly speaking, we say that we have gained information\nwhen we know something now that we didn’t know before; when\n‘what we know’ has changed.” (Mackay [1969], p. 10).\nAround the same years, Doede Nauta [1972] developed a\nsemiotic-cybernetic approach. Nowadays, few philosophers follow these\nlines of research. The majority agrees that MTC provides a rigorous\nconstraint to any further theorising on all the semantic and pragmatic\naspects of information. The disagreement concerns the crucial issue of\nthe strength of the constraint. \n\nAt one extreme of the spectrum, any philosophical theory of\nsemantic-factual information is supposed to be very strongly\nconstrained, perhaps even overdetermined, by MTC, somewhat as\nmechanical engineering is by Newtonian physics. Weaver’s\noptimistic interpretation of Shannon’s work is a typical\nexample. \n\nAt the other extreme, any philosophical theory of semantic-factual\ninformation is supposed to be only weakly constrained, perhaps\neven completely underdetermined, by MTC, somewhat as tennis is\nconstrained by Newtonian physics, that is in the most uninteresting,\ninconsequential and hence disregardable sense (see for example Sloman\n[1978] and Thagard [1990]). \n\nThe emergence of MTC in the 1950s generated earlier philosophical\nenthusiasm that has gradually cooled down through the decades.\nHistorically, philosophical theories of semantic-factual information\nhave moved from “very strongly constrained” to “only\nweakly constrained”. Recently, we find positions that carefully\nappreciate MTC for what it can provide in terms of a robust and\nwell-developed statistical theory of correlations between states of\ndifferent systems (the sender and the receiver) according to their\nprobabilities. This can have important consequences in\nmathematically-friendly contexts, such as some approaches to\nnaturalised epistemology (Harms [1998]) or scientific explanation\n(Badino [2004]). \n\nAlthough the philosophy of semantic information has become\nincreasingly autonomous from MTC, two important connections have\nremained stable between MTC and even the most recent philosophical\naccounts: \n\nThe communication model has remained virtually unchallenged, even if\nnowadays theoretical accounts are more likely to consider as basic\ncases multiagent and distributed systems interacting in parallel,\nrather than individual agents related by simple, sequential channels\nof communication. In this respect, the philosophy of information\n(Floridi [2011]; Allo [2010]) is less Cartesian than\n“social”. \n\nIRP refers to the inverse relation between the probability of\n\\(p\\)—which may range over sentences of a given language\n(as in Bar-Hillel and Carnap) or events, situations or possible worlds\n(as in Dretske)—and the amount of semantic information carried\nby \\(p\\) (recall that Poe’s raven, as a unary source provides no\ninformation because its answers are entirely predictable). It states\nthat information goes hand in hand with unpredictability. Popper\n[1935] is often credited as the first philosopher to have advocated\nIRP explicitly. However, systematic attempts to develop a formal\ncalculus involving it were made only after Shannon’s breakthrough. \n\nWe have seen that MTC defines information in terms of probability\nspace distribution. Along similar lines, the probabilistic\napproach to semantic information defines the semantic information\nin \\(p\\) in terms of logical probability space and the inverse\nrelation between information and the probability of \\(p\\). This\napproach was initially suggested by Bar-Hillel and Carnap [1953] (see\nalso Bar-Hillel [1964]) and further developed by Kemeny [1953],\nSmokler [1966], Hintikka and Suppes [1970] and Dretske [1981]. The\ndetails are complex but the original idea is simple. The semantic\ncontent (\\(\\CONT\\)) in \\(p\\) is measured as the complement of\nthe a priori probability of \\(p\\): \n\n\\(\\CONT\\) does not satisfy the two requirements of\nadditivity and conditionalization, which are satisfied by another\nmeasure, the informativeness (\\(\\INF\\)) of \\(p\\), which\nis calculated, following equations [9] and [10], as the reciprocal of\n\\(P(p)\\), expressed in bits, where\n\\(P(p) = 1 - \\CONT(p)\\): \n\nThings are complicated by the fact that the concept of probability\nemployed in equations [10] and [11] is subject to different\ninterpretations. In Bar-Hillel and Carnap [1953], the probability\ndistribution is the outcome of a logical construction of atomic\nstatements according to a chosen formal language. This introduces a\nproblematic reliance on a strict correspondence between observational\nand formal language. In Dretske, the solution is to make probability\nvalues refer to the observed states of affairs \\((s)\\), that\nis: \n where \\(I(s)\\) is Dretske’s notation to refer to the\ninformation contained in \\(s\\). \n\nThe modal approach further modifies the probabilistic\napproach by defining semantic information in terms of modal space and\nin/consistency. The information conveyed by \\(p\\) becomes the set\nof all possible worlds, or (more cautiously) the set of all the\ndescriptions of the relevant possible states of the universe, that are\nexcluded by \\(p\\). \n\nThe systemic approach, developed especially in situation\nlogic (Barwise and Perry 1983, Israel and Perry 1990, Devlin 1991;\nBarwise and Seligman 1997 provide a foundation for a general theory of\ninformation flow) also defines information in terms of states space and\nconsistency. However, it is less ontologically demanding than the modal\napproach, since it assumes a clearly limited domain of application. It\nis also compatible with Dretske’s probabilistic approach,\nalthough it does not require a probability measure on sets of states.\nThe informational content of \\(p\\) is not determined a priori,\nthrough a calculus of possible states allowed by a representational\nlanguage, but in terms of factual content that \\(p\\) carries with\nrespect to a given situation. Information tracks possible transitions\nin a system’s states space under normal conditions. Both Dretske\nand situation theorists require some presence of information already\nimmanent in the environment (environmental information), as\nnomic regularities or constraints. This “semantic\nexternalism” can be controversial. \n\nThe inferential approach defines information in terms of\nentailment space: information depends on valid inference relative to an\ninformation agent’s theory or epistemic state. \n\nEach of the previous extensionalist approaches can be given an\nintentionalist interpretation by considering the relevant space as a\ndoxastic space, in which information is seen as a reduction in the\ndegree of personal uncertainty, given a state of knowledge of the\ninformee. Wittgenstein addressed this distinction in his Remarks\non the Philosophy of Psychology: \n In using the notion of a language game, Wittgenstein seem to have in\nmind here the information game we have already encountered above. \n\nInsofar as they subscribe to the Inverse Relationship Principle, the\nextensionalist approaches outlined in the previous section can be\naffected by what has been defined, with a little hyperbole, as the\nBar-Hillel-Carnap Paradox (Floridi [2004]). \n\nIn a nutshell, we have seen that, following IRP, the less probable\nor possible \\(p\\) is the more semantic information \\(p\\) is\nassumed to be carrying. This explains why most philosophers agree that\ntautologies convey no information at all, for their probability or\npossibility is 1. But it also leads one to consider contradictions\n— which describe impossible states, or whose probability is 0\n— as the sort of messages that contain the highest amount of\nsemantic information. It is a slippery slope. Make a statement less and\nless likely and you gradually increase its informational content, but\nat certain point the statement “implodes” (in the quotation\nbelow, it becomes “too informative to be true”). \n\nBar-Hillel and Carnap [1953] were among the first to make explicit\nthis prima facie counterintuitive inequality. Note how their careful\nwording betrays the desire to defuse the problem: \n\nSince its formulation, BCP has been recognised as an unfortunate, yet\nperfectly correct and logically inevitable consequence of any\nquantitative theory of weakly semantic information. It is\n“weakly” semantic because truth values play no role in\nit. As a consequence, the problem has often been either ignored or\ntolerated (Bar-Hillel and Carnap [1953]) as the price of an otherwise\nvaluable approach. Sometimes, however, attempts have been made to\ncircumscribe its counterintuitive consequences. This has happen\nespecially in Information Systems Theory (Winder [1997])—where\nconsistency is an essential constraint that must remain satisfied for\na database to preserve data integrity—and in Decision Theory,\nwhere inconsistent information is obviously of no use to a decision\nmaker. \n\nIn these cases, whenever there are no possible models that satisfy a\nstatement or a theory, instead of assigning to it the maximum quantity\nof semantic information, three strategies have been suggested: \n\nThe latter approach is close to the strongly semantic\napproach, to which we shall now turn. \n\nThe general hypothesis is that BCP indicates that something has gone\nessentially amiss with the theory of weakly semantic information. It\nis based on a semantic principle that is too weak, namely that\ntruth-values are independent of semantic information. A semantically\nstronger approach, according to which information encapsulates truth,\ncan avoid the paradox and is more in line with the ordinary conception\nof what generally counts as factual information, as we have seen in\nsection 3.2.3. MTC already provides some initial reassurance. MTC\nidentifies the quantity of information associated with, or generated\nby, the occurrence of a signal (an event or the realisation of a state\nof affairs) with the elimination of possibilities (reduction in\nuncertainty) represented by that signal (event or state of\naffairs). In MTC, no counterintuitive inequality comparable to BCP\noccurs, and the line of argument is that, as in the case of MTC, a\ntheory of strongly semantic information, based on alethic and\ndiscrepancy values rather than probabilities, can also successfully\navoid BCP (Floridi [2005]; see Bremer and Cohnitz\n[2004] chap. 2 for an overview; Sequoiah-Grayson [2007] defends the\ntheory of strongly semantic information against recent independent\nobjections from Fetzer [2004] and Dodig-Crnkovic [2005]). \n \nBefore describing this approach, note that some have proposed a\ndifferent alethic approach, one that uses truthlikeness, or\nverisimilitude, to explicate the notion of semantic information\n(Frické 1997; Cevolani 2011, 2014; D’Alfonso 2011). Typically\nthese seek to identify factual information with likeness to the\ncomplete truth about all empirical matters or about some restricted\nrelevant domain of factual interest. These also avoid the BCP, and\nalso do not use probabilities. However, truthlikeness is different\nfrom truth itself in as much as a truth bearer can be like the truth\nwithout actually being true, i.e. while being false, so that\nverisimilitude accounts of information can permit false views or\ntheories to possess information. (Indeed false statements can\nsometimes carry more information than than their true negations on\nthis account; Frické 1997). \n\nBy contrast, on Floridi’s conception semantic-factual information is\ndefined, in terms of data space, as well-formed, meaningful and\ntruthful data. This constrains the probabilistic approach introduced\nabove, by requiring first a qualification of the content as\ntruthful. Once the content is so qualified, the quantity of semantic\ninformation in \\(p\\) is calculated in terms of distance\nof \\(p\\) from the situation/resource \\(w\\) that \\(p\\)\nis supposed to model. Total distance is equivalent to a \\(p\\)\ntrue in all cases (all possible worlds or probability 1), including\n\\(w\\) and hence minimally informative, whereas maximum closeness\nis equivalent to the precise modelling of \\(w\\) at the agreed\nlevel of abstraction. \n\nSuppose there will be exactly three guests for dinner tonight. This\nis our situation \\(w\\). Imagine we are told that \n\nThe degree of informativeness of (T) is zero because, as a\ntautology, (T) applies both to \\(w\\) and to \\(\\neg w\\). (V)\nperforms better, and (P) has the maximum degree of informativeness\nbecause, as a fully accurate, precise and contingent truth, it\n“zeros in” on its target \\(w\\). Generalising, the\nmore distant some semantic-factual information \\(\\sigma\\) is from its\ntarget \\(w\\), the larger is the number of situations to which it\napplies, the lower its degree of informativeness becomes. A tautology\nis a true \\(\\sigma\\) that is most “distant” from the world. \n\nLet us now use ‘\\(\\theta\\)’ to refer to the distance\nbetween a true \\(\\sigma\\) and \\(w\\). Using the more precise vocabulary\nof situation logic, \\(\\theta\\) indicates the degree of support offered\nby \\(w\\) to \\(\\sigma\\). We can now map on the \\(x\\)-axis of a\nCartesian diagram the values of \\(\\theta\\) given a specific \\(\\sigma\\)\nand a corresponding target \\(w\\). In our example, we know that\n\\(\\theta(\\T) = 1\\) and \\(\\theta(\\P) = 0\\). For the sake of simplicity,\nlet us assume that \\(\\theta(\\V) = 0.25\\). We now need a formula to\ncalculate the\ndegree of informativeness \\(\\iota\\) of \\(\\sigma\\) in relation to\n\\(\\theta(s)\\). Floridi (2004, 210–11) mathematically derives\nand motivates the use of the complement of the square value of\n\\(\\theta(\\sigma)\\), that is, [13]: \n\nFigure 5 shows the graph generated by equation [13] when we include\nalso negative values of distance for false \\(\\sigma\\); \\(\\theta\\) ranges\nfrom \\(-1 (=\\) contradiction) to \\(1 (=\\) tautology): Figure 5.\nDegree of informativeness\n \n\nIf \\(\\sigma\\) has a very high degree of informativeness \\(\\iota\\) (very low\n\\(\\theta)\\) we want to be able to say that it contains a large quantity\nof semantic information and, vice versa, the lower the degree of\ninformativeness of \\(\\sigma\\) is, the smaller the quantity of semantic\ninformation conveyed by \\(\\sigma\\) should be. To calculate the quantity\nof semantic information contained in \\(\\sigma\\) relative to\n\\(\\iota(\\sigma)\\) we need to calculate the area delimited by equation\n[13], that is, the definite integral of the function \\(\\iota(\\sigma)\\)\non the interval \\([0, 1]\\). As we know, the maximum quantity of semantic\ninformation (call it \\(\\alpha)\\) is carried by (P), whose \\(\\theta =\n0\\). This is equivalent to the whole area delimited by the\ncurve. Generalising to \\(\\sigma\\) we have: \n\nFigure 6 shows the graph generated by equation [14]. The shaded area\nis the maximum amount of semantic information \\(\\alpha\\) carried by\n\\(\\sigma\\): Figure 6.\nMaximum amount of semantic information \\(\\alpha\\) carried by \\(\\sigma\\)\n \n\nConsider now (V), “there will be some guests tonight”. (V)\ncan be analysed as a (reasonably finite) string of disjunctions, that\nis (V) = [“there will be one guest tonight” or “there\nwill be two guests tonight” or … “there will be\n\\(n\\) guests tonight”], where \\(n\\) is the reasonable\nlimit we wish to consider (things are more complex than this, but here\nwe only need to grasp the general principle). Only one of the\ndescriptions in (V) will be fully accurate. This means that (V) also\ncontains some (perhaps much) information that is simply irrelevant or\nredundant. We shall refer to this “informational waste” in\n(V) as vacuous information in (V). The amount of vacuous information\n(call it \\(\\beta)\\) in (V) is also a function of the distance \\(\\theta\\) of\n(V) from \\(w\\), or more generally: \n Since \\(\\theta(\\V) = 0.25\\), we have \n\nFigure 7 shows the graph generated by equation [16]: Figure 7.\nAmount of semantic information \\(\\gamma\\) carried by \\(\\sigma\\)\n \n The shaded area is the amount of vacuous information \\(\\beta\\) in\n(V). Clearly, the amount of semantic information in (V) is simply the\ndifference between \\(\\alpha\\) (the maximum amount of information that can\nbe carried in principle by \\(\\sigma)\\) and \\(\\beta\\) (the amount of vacuous\ninformation actually carried by \\(\\sigma)\\), that is, the clear area in\nthe graph of Figure 7. So, the amount of semantic information \\(\\gamma\\)\nin \\(\\sigma\\) is: \n\nNote the similarity between [14] and [15]. When \\(\\theta(\\sigma) = 1\\),\nthat is, when the distance between \\(\\sigma\\) and \\(w\\) is maximum,\nthen \\(\\alpha = \\beta\\) and \\(\\gamma(\\sigma) = 0\\). This is what happens\nwhen we consider (T). (T) is so distant from \\(w\\) as to contain only\nvacuous information. In other words, (T) contains as much vacuous\ninformation as (P) contains relevant information. \n\nPhilosophical theories of semantic information have recently\ncontributed to a new area of research in itself, the philosophy of\ninformation (Adams [2003], Floridi [2011]).\n\nThe Routledge Handbook of Philosophy of Information (Floridi\n(ed.) 2016) provides an overview of the scope and depth of current\nwork in the field. Information seems to have become a key concept to\nunlock several philosophical problems. “The most valuable\ncommodity I know of is information”, boldly declares Gordon\nGekko in Oliver Stone’s Wall Street (1987). Euphranor would\nprobably have concurred. The problem is that we still have to agree\nabout what information is exactly.","contact.mail":"luciano.floridi@philosophy.ox.ac.uk","contact.domain":"philosophy.ox.ac.uk"}]
