[{"date.published":"2006-06-30","date.changed":"2018-04-23","url":"https://plato.stanford.edu/entries/defaults-semantics-pragmatics/","author1":"Katarzyna M. Jaszczolt","author1.info":"http://people.pwf.cam.ac.uk/kmj21/","entry":"defaults-semantics-pragmatics","body.text":"\n\n\nThe sense and role of defaults in the semantics/pragmatics landscape\nis changing swiftly and dynamically. First, it is changing due to the\nprogression in the debates concerning the delimitation of explicit\ncontent (Jaszczolt 2009a, 2016a). Second, it is propelled by the\ndebates concerning the literal/nonliteral vis-à-vis salient/nonsalient\ndistinction (Giora & Givoni 2015; Ariel 2016).  Next, it is\ninfluenced by computational linguistics that develops statistical\nmodels for learning compositional meaning using ‘big data’\n(Jurafsky & Martin 2017 [Other Internet Resources]; Liang &\nPotts 2015). In what follows I focus on two main aspects of\ndefaultness in semantics and pragmatics: (i) different\nconceptualisations of defaultness, their provenance and their relative\nmerits, as well as (ii) defaultness vis-à-vis the semantics/pragmatics\nboundary disputes.\n\n\nThe term ‘default meaning’ is used in a variety of ways in\nthe literature, including statistically common interpretation,\npredictable meaning, salient meaning, or automatically retrieved\nmeaning. To begin with a common-sense definition, default\ninterpretation of the speaker’s utterance is normally understood to\nmean salient meaning intended by the speaker, or presumed by the\naddressee to have been intended, and recovered (a) without the help of\ninference from the speaker’s intentions or (b) without conscious\ninferential process altogether.\n\n\nIn post-Gricean pragmatics it has been accepted that communicators\nconvey more information than is contained in the expressions they\nutter. For example, sentences (1a)–(2a) normally convey\n(1b)–(2b).\n\n\n(1a) Tom finished writing a paper and went skating.\n\n(1b) Tom finished writing a paper and then went skating.\n\n(2a) Picasso’s painting is of a crying woman.\n\n(2b) The painting executed by Picasso is of a crying woman.\n\n\n\nSuch additions to the content of the uttered sentence were called by\nGrice (1975) generalized conversational implicatures (GCIs),\nthat is, instances of context-independent pragmatic inference.\nSubsequently, the status of such context-independent additions has\nbecome the subject of heated debates. Some post-Griceans stay close to\nGrice’s spirit and propose that there are salient, unmarked, presumed\nmeanings that occur independently of context (Horn, e.g., 2004, 2012;\nLevinson 1995, 2000; Recanati 2004). Some identify default meanings as\nthose arising automatically in a given situation of discourse\n(Jaszczolt, e.g., 2005, 2010, 2016b; Elder & Jaszczolt 2016).\nOthers reject defaults tout court and subsume such salient\nmeanings under an unnaturally widened category of context-dependent\npragmatic inference (Sperber & Wilson 1986; Carston 2002).\n\n\nNext, some, following Grice, consider such pragmatic contributions to\nutterance meaning to be generalized conversational implicatures\n(Levinson), others classify them as pragmatic input to what is said,\nalbeit using a variety of theory-specific labels (Recanati, Carston),\nreserving the term ‘implicature’ for meanings that can be\nrepresented by a separate logical form and that function independently\nfrom the content of the main utterance in reasoning. Others define\nthem as contributions to primary meanings where the latter cut across\nthe explicit/implicit divide (Jaszczolt). Yet another possibility is\nto regard them as a separate level of what is implicit in what is said\n(Bach 1994, 2007; Horn 2006). In short, the status of such\n‘default’ meanings is still far from clear. However, at\nleast in general terms, there is a reason for drawing a distinction\nbetween salient, automatic enrichments and costly pragmatic inference\nsince some of these pragmatic contributions go through\nnormally, as a matter of course. As Horn (2004: 4–5)\nputs it,\n\n\nWhatever the theoretical status of the distinction, it is apparent\nthat some implicatures are induced only in a special context\n(…), while others go through unless a special context\nis present (…).\n\n\n\nIn the above, the differences in using the term ‘default’\nconsist of the acceptance or rejection of at least the following\nproperties:\n\ncancellability (also known as defeasibility) of preferred\ninterpretations;\n\navailability of preferred interpretations without making use of\nconscious inference;\n\nshorter time required for their formation by the speaker and\nrecognition by the addressee as compared with that required for the\nmeanings induced through inference;\n\nthe availability of preferred interpretations prior to the\ncompletion of the processing of the entire proposition (local,\npre-propositional defaults).\n\nDefaults are also relevant in the discussions of the conventional\nimport of lexical items such as expressives in that their standard\nexpressive (often offensive) meaning does not arise in certain types\nof context. The view on their truth-evaluability (or at least on what\naspects of their meaning are truth-evaluable) is then closely related\nto the value one attaches to this context-dependence (Potts 2005;\nRichard 2008; Sileo 2017). A separate tradition of the use of defaults\nin default inheritance lexical, including computational, semantics\nwill be briefly touched upon in Section 1.5.\n\n\nThe overview of the major perspectives presented in Section 1 makes it\nclear that there is no consensus in the literature as to the unique\nset of properties that default interpretations should exhibit, opening\nup the discussion as to whether the term has only an intra-theoretic\nutility.\n\nDefault interpretations, interpretations producing the standard\ncontent, are defined differently depending on how\n‘default’ is defined: as a default for the lexical item, a\ndefault for the syntactic structure, a default for a particular\nconstruction, or even a default for a particular context (where, in\naddition, there is a necessary correlation with the adopted definition\nof ‘context’). The delimitation of such defaults can\nproceed according to different methods that, again, can affect the\nresults and as such further contribute to the definition of\ndefaults. For example, the psychological route is associated with\nautomatic, inference-free interpretations, while the statistical route\nappeals to quantitative analyses of data, where the latter can pertain\nto corpora of conversations or big databases of word co-occurrence as\nused in statistical, distributional approaches in computational\nsemantics.\n \nWhen analysed in standard truth-conditional semantics, defaults can\ncontribute to the truth-conditional content or affect what is implicit\n– presupposed or implicated (see e.g. Potts 2015). The side on\nwhich we find defaults in this distinction is largely dictated by the\norientation concerning the semantics/pragmatics boundary, where the\nchoice ranges from traditional semantic minimalism to radical versions\nof contextualism. I discuss these in more detail in the following\nsections. But it has to be remembered that the category is tangential\nto such concepts as what is said, conversational implicature,\nconventional implicature, presupposition, or, to use a more general\nterm, projective content (on universals in projective content see\nTonhauser et al. 2013). For example, presuppositions are\nstronger than defaults: presupposition triggers such as\n‘know’, ‘regret’, ‘again’ or\n‘manage’ do not give the hearer much option of\ninterpretation, save admitting some form of metalinguistic or\nquotative reading when these are negated as in (3). \n(3) I didn’t forget about your birthday again; it is the first\ntime it happened.\n \nWhat is said can rely on various types of defaults (Section 2) and\ncontextually salient interpretations (Section 3), but likewise it can\nrely on effortful pragmatic inference from a variety of sources\navailable in the situation of discourse. Relevant implicatures can be\nconventional (Grice 1975; Potts 2005) and conversational generalised,\nthe latter understood either as grammar-driven (Chierchia 2004) or,\nmore loosely, language-system-driven (Levinson 2000 and Section 1.3),\nbut implicatures can also be entirely context-dependent\n(particularised). To add to this multi-dimensionality,\ncontext-dependent implicatures can on some occasions arise\nautomatically, so when our definition of defaults relies on the\ndefinitional criterion of the automaticity of the process, as\ndiscussed above, then, by this definition, such implicatures can also\nbe dubbed ‘defaults’ (Giora & Givoni 2015; Jaszczolt 2016a). In\nshort, pursuing the standard route of analysing the types of content\nwill not get us far with analysing defaults. Said/implicated,\nat-issue, or question-under-discussion-driven analyses (e.g. Roberts\n2004) will encounter defaults on either side of the pertinent\ndichotomies. \nA further complication in linking defaultness with the categories of\nthe said or the unsaid is the fact that even weak implicatures or\npresuppositions adopted through accommodation can enjoy either status.\nIn (4), we can accommodate globally the presupposition in (5) –\neither via inference or automatically. \n(4) Tom says that Ian hasn’t finished writing a novel.\n\n(5) Ian is writing a novel.\n \nAs a result, (5) can enjoy the default status according\nto some of the standard understandings of defaults as automatic, or\nmore frequent, more salient, or even more ‘literal’ interpretations,\nor, alternatively, it can simply be an interpretation that is easier\nto process – arguably, in itself a plausible criterion for\n‘defaultness’. \nNext, conventional implicatures, that is lexical meanings that,\naccording to Grice (1975), do not contribute to what is said, have,\nat first glance, less to do with defaultness: they are entrenched,\nnon-cancellable and form-dependent (detachable), and they cannot be\ncalculated from maxims, principles or heuristics (Horn 1988: 123).\nHowever, more recent inquiries into the related category of\nexpressives gives more scope for pursuing defaultness. Slurs are,\narguably, offensive by default but their derogatory import does not\ncarry across to context of banter and camaraderie. As to whether the\nexpressive content is an implicature or part of what is said, the\nmatter is still hotly discussed (see e.g. Richard 2008; Sileo 2017).\nIn what follows, I try to bring some order into this unwieldy term\nvis-à-vis the semantics/pragmatics distinction and finish with some\nreflections on its usefulness for semantics and pragmatics. \nBe that as it may, default meanings come from default reasoning.\nAccording to Kent Bach (1984), in utterance interpretation we use\n‘jumping to conclusions’, or ‘default\nreasoning’. In other words, speakers know when context-dependent\ninference from the content of the sentence is required and when it is\nnot. When it is not required, they progress, unconsciously, to the\nfirst available and unchallenged alternative. This step is cancellable\nwhen it becomes obvious to the addressee that the resulting meaning is\nnot what the speaker had intended. What is important in this view is\nthe proposed distinction between (conscious) inference and the\nunconscious act of ‘taking a step’, as Bach (1984: 40)\ncalls it, towards the enriched, default interpretation. Such a move to\nthe default meaning is not preceded by a conscious act of deliberation\nas to whether this meaning was indeed intended by the speaker. Rather,\nit just goes through unless it is stopped by some contextual or other\nfactors that render it implausible. \nBach founds his account on the Gricean theory of intentional\ncommunication and therefore he has a ready explanation for the fact\nthat different meanings come with different salience. He makes an\nassumption that intentions allow for different degrees of strength\n(Bach 1987). He also adds that salience has a lot to do with\nstandardisation (Bach 1995; 1998) which consists of interpreting an\nutterance according to a pattern that is established by previous usage\nand as such short-circuits the process of (conscious) inference. In\nshort, ‘jumping to conclusions’ is performed unconsciously\nand effortlessly. \nFor Bach, such default meanings are neither implicatures nor what is\nsaid (or explicatures): they are implicit in what is said, or\nimplicitures. They are a result of ‘fleshing out’\nthe meaning of the sentence in order to arrive at the intended\nproposition, or ‘filling in’ some conceptual gaps in the\nsemantic representation that, only after this filling in, becomes a\nfull proposition. An example of ‘fleshing out’ is given in\n(6b), where the minimal proposition is expanded. ‘Filling\nin’ is exemplified in (7b), where a so-called propositional\nradical is completed. \n(6a) Tom is too young.\n\n(6b) Tom is too young to drive a car.\n\n(7a) Everybody likes philosophy.\n\n(7b) Everybody who reads the SEP likes philosophy. \n \nBut default meanings do not exhaust the category\nmembership of the impliciture: implicitures can be a result of default\nreasoning as well as a context-dependent process of inference.\nAnalogous to the distinctions discussed before, default meanings are\northogonal to the distinction between what is said, impliciture, and\nimplicature: the default/inferential distinction cuts across all\nthree.  \nStephen Levinson (1995, 2000) argues for default interpretations that\nhe calls presumptive meanings and classifies as implicatures.\nHe uses the term borrowed from Grice, generalized conversational\nimplicatures (GCIs), but ascribes some properties to them that\ndifferentiate them from Grice’s GCIs. For Levinson, GCIs are neither\nproperly semantic nor properly pragmatic. They should not be regarded\nas part of semantics as, for example, in Discourse Representation\nTheory (Kamp and Reyle 1993), nor should they be seen as a result of\ncontext-dependent inference performed by the hearer in the process of\nthe recovery of the speaker’s intention. Instead, “they sit\nmidway, systematically influencing grammar and semantics on the one\nhand and speaker-meaning on the other.” (Levinson 2000: 25). \nSuch presumed meanings are the result of rational, communicative\nbehaviour and arise through three assumed heuristics: (1) ‘What\nisn’t said, isn’t’; (2) ‘What is expressed simply is\nstereotypically exemplified’, and (3) ‘What’s said in an\nabnormal way isn’t normal’, called Q, I, and M heuristics\n(principles) respectively. Levinson’s GCIs, unlike their Gricean\nprogenitors, can arise at various stages in utterance processing: the\nhearer need not have processed the whole proposition before arriving\nat some presumed meanings. Also, unlike Grice’s GCIs that are taken to\nbe speaker’s intended meanings, Levinson’s presumptive meanings seem\nto be hearer’s meanings, obtained by the hearer as a result\nof the assumptions he or she made in the process of utterance\ninterpretation (see Saul 2002 and Horn 2006 for discussion). On the\nother hand, like Grice’s GCIs, they are cancellable without\ncontradiction. \nNow, when defaults are delimited by contextual salience, arguably,\ncancellation may not occur except for cases of miscommunication. In\nother words, when the meaning is salient in a given context, it is\nlikely that it had been meant by the speaker unless the speaker\nmisjudged the common ground. But when they are understood as\nlanguage-system-driven meanings, à la Levinson’s GCIs, cancellability\nconstitutes direct evidence of such defaultness. Salient components of\nmeaning added to the overtly expressed content (in the form of\nadditional information or choices of interpretation) tend to be\nentrenched and as such difficult to cancel. But as Jaszczolt (2009a,\n2016a) demonstrates, cancellability is a property that does not side\nwith implicit as opposed to explicit content but rather with salience.\nIf the main intended message is communicated indirectly, as in (8b),\nthen it is the implicature (8c) that is difficult to cancel.  \n(8) (Fred and Wilma talking about Wilma’s piano recital)\n\n(8a) Fred: Was the recital a success?\n\n(8b) Wilma: Lots of people left before the end.\n\n(8c) The recital was not a success.\n \nThe presence or absence of cancellation in utterance interpretation is\nstill a matter of dispute. It is difficult at present to decide\nbetween the rival views (i) that a particular GCI arose and was\nsubsequently cancelled or (ii) that it did not arise at all due to\nbeing blocked by the context. There is not sufficient experimental\nevidence to support either stance. The answer to this question is\nclosely dependent on the answer to the so-called globalism-localism\ndispute. If, as Levinson claims, default interpretations arise\n‘locally’, out of the processing of a pre-propositional\nunit such as a word or a phrase, then they have to be subjected to\nfrequent cancellation once the proposition has been processed. If,\nhowever, despite the incrementality of the interpretation process they\narise post-propositionally, or ‘globally’, in accordance\nwith Grice’s original assumption, then utterance interpretation can\nproceed without costly backtracking (see Geurts 2009; Jaszczolt 2008,\n2009a, 2016a; Noveck & Sperber 2004). \nGricean pragmatics is not the only approach in which defaults are\ndiscussed. Defaults and nonmonotonic reasoning are also well\nentrenched in\n computational linguistics.\n Defaults are distinguished there with respect to various units of\nmeaning, from morphemes and words to multisentential units (Asher\n& Lascarides 1995; Lascarides & Copestake 1998). In this\nsection I focus on intersentential default links and in the next I\nplace ‘glue logic’ in the context of some other understandings of\ndefaults in computational semantics.  \nThe tradition of defaults in nonmonotonic reasoning can be traced back\nto Humboldt, Jespersen and Cassirer, and more recently to Reiter’s\n(1980) default logic and his default rules of the form: \nA:B\nC\n \nwhere C can be concluded if A has been concluded and\nB can be assumed (and not B cannot be proven). Such\ndefaults can be built into standard logic: \nBut the resulting logic will become nonmonotonic because there are\ndefault rules and default operators in the language. The literature on\nthe topic is vast and is best considered as a separate topic from our\ncurrent concern (see e.g., Thomason (1997) for an overview). \nThe best example of how default interpretations can be accounted for\nin formal semantic theory is Segmented Discourse Representation Theory\n(SDRT, e.g., Asher & Lascarides 2003). SDRT is an offshoot of\nDiscourse Representation Theory, a dynamic semantic approach to\nmeaning according to which meaning arises incrementally through\ncontext change. In SDRT, defaults are regarded as highly probable\nroutes that an interpretation of a sentence may take in a particular\nsituation of discourse. There are rules of discourse, so-called\nrhetorical structure rules, that produce such default\ninterpretations. These rules spell out the overall assumption that\ndiscourse is coherent and that this coherence can be further\nelaborated on by proposing a set of regularities. For example, two\nevents represented as two consecutive utterances are presumed to stand\nin the relation of Narration, where the event described in\nthe first utterance precedes the one from the second utterance. If the\nsecond utterance describes a state, then it stands in the relation of\nBackground to the first one. There are many other types of\nsuch relations, among them Explanation and Elaboration. Axioms prevent\na relation from being of two incompatible types at the same time. The\nrelations between states and events are computed as strong\nprobabilities, in the process called defeasible reasoning. The laws of\nreasoning are ‘defeasible’ in the sense that if the\nantecedent of a default rule is satisfied, then its consequent is\nnormally, but not always, satisfied. The inference normally,\nbut not always, obtains: ceteris paribus, the relation\npredicted by the law obtains, but in certain circumstances it may not.\nIt is also nonmonotonic in that the relation may disappear with the\ngrowth of information. \nSDRT includes the following components: (i) the semantics of sentences\nalone, that is the underspecified output of the syntactic processing\nof the sentences; (ii) the semantics of information content, that is,\nfurther addition to these underdetermined meanings, including default\nadditions summarised by rhetorical structure rules; and (iii) the\nsemantics of information packaging that ‘glues’ such\nenriched representations by means of the rules of the rhetorical\nstructure of discourse. This ‘gluing together’ is\ndefeasible, in that the rules result in the dependency\nA>B, that is ‘if A, then normally\nB’, where A and B stand for the\nenriched propositional representations of two sentences. In other\nwords, they stand for the meanings of two consecutive utterances. \nThe main strength of this approach is that it is fully formalized and\nit allows for computational modelling of discourse that takes\npragmatic links between utterances seriously and incorporates them in\nthe semantics. Next, it also aspires to cognitive reality and although\nthe cognitive reality of the particular rules can be disputed, the\nview of discourse processing that they jointly produce is highly\nplausible. Finally, as the authors often stress, SDRT allows them, for\nmost part, to model discourse without recourse to speakers’\nintentions. However, a direct comparison with Gricean accounts of\ndefaults is precluded by the fact that we would not be comparing like\nwith like. In SDRT, the default interpretations are the defaults that\nare formalized with respect to the actually occurring discourse: there\nare rules that tell us how to take two events represented in two\nconsecutive sentences, there are also rules that specify the relation\nbetween them depending on some features of their content. Gricean\ndefaults are, on the contrary, defaults for speakers’ overall\nknowledge state: they may arise because the speaker did not\nsay something he or she could have said or because the\nspeaker assumed some cultural or social information to be shared\nknowledge. For example, we cannot formalize the interpretation of (9a)\nas (9b) by means of rhetorical structure rules. The interpretation of\n(9a) as (9b) fits under the SDRT component (ii) rather than (iii)\nabove, i.e., the semantics of information content rather than\npackaging. \n(9a) Pablo’s painting is of a crying woman.\n\n(9b) Picasso’s painting is of a crying woman.\n \nFinally, it has to be mentioned that the discourse relations that for\nAsher and Lascarides belong to the ‘glue logic’ can alternatively be\nconceived of as part of the grammar proper: Lepore & Stone (2015),\nfor example, incorporate conventions into minimalistically understood,\ngrammar-driven semantics, and a fortiori into grammar proper;\nfollowing Lewis’s (1979) ideas on convention and ‘scorekeeping’, they\npropose that “semantics describes interlocutors’ social competence in\ncoordinating on the conversational record” (Lepore & Stone 2015:\n256). Merits of putting conventions into grammar are, however, not\neasy to find (for a review see Jaszczolt 2016b).  \nThe computational semantics landscape contains a few landmarks in\nwhich the concept of a default figures prominently, albeit under\ndifferent labels. I have already discussed the role of defaults and\ninheritance reasoning in artificial intelligence research in the\nexample of SDRT. This kind of research in computational linguistics is\narguably the closest to theoretical linguistic semantics and\npragmatics in that it directly appeals to human practices in\nreasoning. Pelletier & Elio (2005) refer to this characteristic as\nthe psychologism of nonmonotonic logics, and thus a property that was\nso fiercely banished from logic by Frege as a form of a ‘corrupting\nintrusion’, in that ‘being true is quite different from\nbeing held as true’ (Frege 1893: 202). Pelletier and Elio\nwrite: \nOther landmarks include research on default feature specification in\nsyntactic theory and default lexical inheritance (e.g. Gazdar et\nal. 1985; Boguraev & Pustejovsky 1990; Lascarides et al.\n1996), where default inheritance comes from a simple idea pertaining\nto all taxonomies: regular features belonging to an entity of a\ncertain type are inherited from the categories higher up in the\ntaxonomic hierarchy, that is simply by virtue of the membership of a\ncertain ontological type. As a result, only the non-default features\nhave to be attended to (on various semantic networks in computational\nlinguistics see also Stone 2016). To generalize, this line of research\ncan lead to incorporation of information into logical forms,\nincluding, as can be seen in the example of SDRT, dynamic logical\nforms of discourses. In a different camp there are statistical,\ndistributional approaches to meaning where meaning is derived from\ninformation about co-occurrence of items gleaned from corpora and then\nquantitatively analysed. This orientation gave rise to current\nvector-based approaches (see, e.g., Jurafsky & Martin 2017 [Other\nInternet Resources]; Coecke et al. 2010 and for discussion\nLiang & Potts 2015). Vector semantics exploits the finding that\ndates back at least to Harris (1954) and Firth (1957) that the meaning\nof a word can be computed from the distribution of the words in its\nimmediate context.  The term ‘vector semantics’ derives\nfrom the representation of the quantitative values in this\ndistribution called a ‘vector’, where the latter is\ndefined as a distributional model that presents information in the\nform of a co-occurrence matrix. Vectors have been around since the\n1950s but it is only recently that such distributional methods have\nbeen combined with logic-based approaches to meaning (see Liang &\nPotts 2015). Vectors can measure the similarity of texts with respect\nto a lexical item, the similarity of lexical items with respect to\nsources, or, what interests us most, the co-occurrence of selected\nwords in a selection of contexts (using additional methods to rule out\nco-occurrence by chance). In distributional semantics therefore the\nsalient or default meaning is the meaning given by the observed high\nco-occurrence or, in other words, delimited by the high conditional\nprobability of its occurrence in the context of other words. \nCurrent compositional semantics is beginning to combine compositional\nsemantic theory (logic-based approaches discussed above) with\nstatistical models, conforming to the standard view of\ncompositionality on which complex meanings are a function of lexical\nmeanings and the mode of combination, arrived at through a recursive\nprocess, but at the same time aiming at capturing the generalization\nfrom (finite) past experiences that would inform machine learning.\nDefaults arise in this context in several different forms: (i) as\nshortcuts to standard meanings of more semantically predictable\ncategories, that is, closed-class words such as determiners, pronouns\nor sentential connectives. (This can be extended perhaps to types of\npredictable projective content such as various types of implicature or\npresupposition; see Tonhauser et al. 2013); (ii) as\npredictable cross-sentential discourse relations; (iii) as predictable\ndiscourse-anaphoric links; (iv) as meaning arising from frequent\nsyntagmatic associations; (v) as meaning arising from frequent\nconversational scenarios, to name a few salient concepts. In this new,\npositively eclectic orientation in computational linguistics that\ncombines logical and statistical approaches, the label ‘default’ is\nlikely to lead to more confusion than utility in that it can pertain\nto either of the two contributing orientations. On the other hand, if\nthe findings lead to the same set of what we can call ‘shortcuts\nthrough possible interpretations’, the confusion may be of merely a\nmethodological rather than ontological importance. \nOptimality-Theory pragmatics (OT pragmatics, Blutner 2000; Blutner and\nZeevat 2004; ) is another attempt at a computational modelling of\ndiscourse but unlike SDRT it makes use of a post-Gricean,\nintention-based account of discourse interpretation. The process of\ninterpretation is captured in a set of pragmatic constraints. The\npragmatic additions to the underdetermined output of syntax are\ngoverned by a rationality principle called an optimization procedure\nthat is spelled out as a series of constraints. These constraints are\nranked as to their strength and they are defeasible, that is, they can\nbe violated (see Zeevat 2000, 2004). The resulting interpretation of\nan utterance is the outcome of the working of such constraints. OT\npragmatics formalizes and extends the Gricean principles of\ncooperative communicative behaviour as found in Horn (1984) and\nLevinson (1995, 2000). For example, STRENGTH means preference for\nreadings that are informationally stronger, CONSISTENCY means\npreference for interpretations that do not conflict with the extant\ncontext, FAITH-INT stands for ‘faithful interpretation’,\nthat is interpreting the utterance without leaving out any aspect of\nwhat the speaker says. The ordering of these constraints is FAITH-INT,\nCONSISTENCY, STRENGTH. The interaction of such constraints, founded on\nLevinson’s heuristics, explains how the hearer arrives at the intended\ninterpretation. At the same time, this model can be regarded as\nproducing default, presumed interpretations. With respect to finding\nan antecedent for an anaphor, for example, the interaction of the\nconstraints explains the general tendency to look for the referent in\nthe immediately preceding discourse rather than in the more remote\nfragments or, rather than constructing a referent ad hoc. In\nother words, it explains the preference for binding over accommodation\n(van der Sandt 1992, 2012). \nDefaults in OT pragmatics combine the precision of a formal account\nwith the psychological reality of Gricean intention-based\nexplanations. The main difference is that they don’t seem to be\ndefeasible: OT pragmatics tells us how an actual interpretation arose,\nrather than what the default interpretation could be. Constraints are\nranked, so to speak, post hoc: they explain what actually\nhappened and why, rather than what should happen according to the\nrules of rational communicative behaviour. In other words, context is\nincorporated even sooner into the process of utterance interpretation\nthan in Gricean accounts and allows for non-defeasible, albeit\nstandard, default, interpretations. With respect to this feature they\nresemble defaults of Default Semantics discussed in Section 1.8. \nIn truth-conditional pragmatics (Recanati, e.g. 2004, 2010), the\nmeaning of an utterance consists of the output of syntactic processing\ncombined with the output of pragmatic processing. Pragmatic\nprocessing, however, is not necessarily fulfilled by conscious\ninference: processes that enrich the output of syntax are\nsub-doxastic, direct, and automatic. The resulting representation of\nutterance meaning is the only representation that has cognitive\nreality and it is subject to truth-conditional analysis. On this\naccount, the content of an utterance is arrived at directly, similar\nto the act of perception of an object. Recanati calls this view\nanti-inferentialist in that “communication is as direct as\nperception” (Recanati 2002: 109): the processing of the\nspeaker’s intentions is (at least normally) direct, automatic, and\nunreflective. Such processes enriching the actually uttered content\nare called primary pragmatic processes. Some of them make use of\ncontextual information, others are context-independent. So, they\ninclude some cases of Grice’s GCIs as well as some particularised\nimplicatures (PCIs; on implied content see also Tonhauser et\nal. 2013) – but only the ones which further develop the\nlogical form of the uttered sentence. When the pragmatic addition\nconstitutes a separate thought, it is, on this account, an implicature\nproper, arrived at through a secondary, conscious, and reflective\npragmatic process. \nThere are two kinds of enrichment of the content obtained through the\nsyntactic processing: (i) completing of a semantically incomplete\nproposition as in (10b), called saturation, and (ii) further\nelaboration of the meaning of the sentence that is not guided by any\nsyntactic or conceptual gaps but instead is merely triggered by the\nhearer’s opinion that something other than the bare meaning of the\nsentence was intended, as in (11b). The latter process is called\nfree enrichment. \n(10a) The fence isn’t strong enough.\n\n(10b) The fence isn’t strong enough to withstand the gales.\n\n(11a) John hasn’t eaten.\n\n(11b) John hasn’t eaten dinner yet.\n \nDefault interpretations are here defaults for processing of an\nutterance in a particular context. Automatic and unconscious\nenrichment produces a default interpretation of the utterance and\n“[o]nly when there is something wrong does the hearer suspend or\ninhibit the automatic transition which characterizes the normal cases\nof linguistic communication”. (Recanati 2002: 109). To sum up,\nsuch defaults ensue automatically, directly, without the effort of\ninference. They are cancellable, they can make use of contextual\nclues, but they are not ‘processes’ in any cognitively\ninteresting sense of the term: they don’t involve conscious inference,\nalbeit, in Recanati’s terminology, they involve inference in the broad\nsense: the agent is not aware of performing an inference but is aware\nof the consequences of this pragmatic enrichment of the interpreted\nsentence. \nOne of the main questions to ask about any theory of utterance\ninterpretation is what sources information about meaning comes from.\nIn Default Semantics, on the revised version of the theory (Jaszczolt,\ne.g., 2009, 2010, 2016a), utterance meaning is the outcome of merging\nof information that comes from five sources: (i) word meaning and\nsentence structure (WS); (ii) situation of discourse (SD); (iii)\nproperties of human inferential system (IS); (iv) stereotypes and\npresumptions about society and culture (SC); and world knowledge (WK).\nWS is the output of the syntactic processing of the sentence, or its\nlogical form. SD stands for the broadly understood context in which\nthe discourse is immersed. IS pertains to properties of mental states\nwhich trigger certain types of interpretations. For example, the\nproperty of intentionality ensures that we normally use referring\nexpressions with a referential intention that is the strongest for the\ngiven context. SC pertains to the background knowledge of societal\nnorms and customs and cultural heritage. WK encompasses information\nabout physical laws, nature, environment, etc. It is important to\nstress that the four sources that accompany WS do not merely enrich\nthe output of the latter. All of the sources are equally powerful and\ncan override each other’s output. This constitutes a substantial\nbreakaway from the established boundary between explicit and implicit\ncontent.  \nThe identification of the sources also allows us to propose a\nprocessing model in Default Semantics in which three types of\ncontribution to utterance interpretation are distinguished: (i)\nprocessing of the sentence (called combination of word meaning and\nsentence structure, WS); (ii) conscious pragmatic inference (CPI) from\nthree of the sources distinguished above: SD, SC, and WK; and (iii)\ntwo kinds of default, automatic meanings: cognitive defaults (CD)\ntriggered by the source IS, and social, cultural and world-knowledge\ndefaults (SCWD).  \nThe primary meaning is arrived at through the interaction of these\nprocesses and therefore need not bear close resemblance to the logical\nform of the sentence; the output of WS can vary in significance as\ncompared with the output of other types of processes. For example, to\nborrow Bach’s (1994) scenario, let us imagine little Johnny cutting\nhis finger and crying, to which his mother reacts by uttering\n(12a). \n(12a) You are not going to die.\n \nThe what is said/explicature of (12a) is something to the\neffect of (12b). There may also be other communicated meanings but\nthose fall in the domain of implicatures. \n(12b) You are not going to die from this cut.\n \nIn Default Semantics, the primary content of an utterance is its most\nsalient meaning. This is so even when this meaning does not bear any\nresemblance to the logical form derived from the syntactic structure\nof the uttered sentence. In other words, CPI can override WS and\nproduce, say, (12c) as utterance meaning (called  primary\nmeaning, represented in a merger representation) for the\ngiven context. The explicit content of the utterance need not be even\npartially isomorphic with the meaning of the uttered sentence: it need\nnot amount to the development of the sentence’s logical form. \n(12c) There is nothing to worry about.\n \nCDs and SCWDs are default interpretations. Similar to Recanati’s\nautomatic free enrichment, these default meanings cut across Grice’s\nGCI/PCI divide. Some of them arise due to the properties of words or\nconstructions used and are present by default independently of the\ncontext of the utterance, while others are default meanings for the\nparticular situation of discourse. CDs are default interpretations\nthat are triggered by the properties of mental states. For example,\nwhen speakers use a definite description in an utterance, they\nnormally use it referentially (about a particular, known,\nintersubjectively recognisable individual) rather than attributively\n(about whoever fits the description). This default referential use can\nbe given a functional as well as a cognitive explanation. Firstly, it\ncan be explained in terms of the strength of the referential intention\nassociated with the act of utterance: ceteris paribus, humans provide\nthe strongest information relevant and available to them. At the same\ntime, in cognitive terms, it can be explained through the property of\nmental states that underlie the speaker’s speech act: this is the\nproperty of intentionality or aboutness, in the\nsense in which the mental state is about a particular object, be it a\nperson, thing, or situation. Like the strongest referring, so the\nstrongest aboutness, is the norm, the default. For example, the\ndescription ‘the architect who designed St Paul’s\ncathedral’ in (13a) is likely to be interpreted as\n‘Christopher Wren’, as in (13b). \n(13a) The architect who designed St Paul’s cathedral was a genius.\n\n(13b) Sir Christopher Wren was a genius.\n \nNext, SCWDs are default interpretations that arise due to the shared\ncultural and social background of the interlocutors. To use a well\nworn example, in (14a), it is the shared presumption that babies are\nraised by their own mothers that allows the addressee to arrive at\n(14b). \n(14a) The baby cried and the mother picked it up.\n\n(14b) The baby cried and the baby’s mother picked it up.\n \nIn CDs and SCWDs, no conscious inference is involved. The natural\nconcomitant of reducing the role of the logical form (WS) to one of\nfour equally potent constituents of utterance meaning is a revised\nview of compositionality. The compositional nature of meaning is\nretained as a methodological assumption but this compositionality is\nnow sought at the level of the merger of information from the five\nsources, arrived at through the interaction of the four identified\nprocesses. The output of these processes is called merger\nrepresentation and is expected to be a compositional structure.\nCurrent research focuses of providing an algorithm for the interaction\nof the output of the identified processes. \nIt is evident from the sample of approaches presented above that the\nnotion of default meaning is used slightly differently in each of\nthem. We can extract the following differences in the understanding of\ndefault interpretations: \n[1a] Defaults belong to competence.\n\nvs.\n\n[1b] Defaults belong to performance.\n \n[2a] Defaults are context-independent.\n\nvs.\n\n[2b] Defaults can make use of contextual information.\n \n[3a] Defaults are easily defeasible.\n\nvs.\n\n[3b] Defaults are not normally defeasible.\n \n[4a] Defaults are a result of subdoxastic, automatic process.\n\nvs.\n\n[4b] Defaults can involve conscious pragmatic inference.\n \n[5a] Defaults are developments of the logical form of the uttered\nsentence.\n\nvs.\n\n[5b] Defaults need not enrich the logical form of the sentence but may\noverride it.\n \n[6a] Defaults can all be classified as one type of pragmatic process.\n\nvs.\n\n[6b] Defaults come from qualitatively different sources in utterance\nprocessing.\n \nThere is also disagreement concerning the following properties, to be\ndiscussed below: \n[7a] Defaults are always based on a complete proposition.\n\nvs.\n\n[7b] Defaults can be ‘local’,\n‘sub-propositional’, based on a word or a phrase.\n \n[8a] Defaults necessarily arise quicker than non-default meanings.\nHence they can be tested for experimentally by measuring the time of\nprocessing of the utterance.\n\nvs.\n\n[8b] Defaults do not necessarily arise quicker than non-default\nmeanings because both types of meaning can be based on conscious,\neffortful inference. Hence, the existence of defaults cannot be tested\nexperimentally by measuring the time of processing of the utterance.\n \nThese are the most standardly accepted characteristics of default\ninterpretations in theoretical semantics and pragmatics. We shall not\ninclude here definitional characteristics of defaults in computational\nlinguistics as these are a subject for a separate study. Some of the\nproperties in [1]–[8] are interrelated, some of the others just tend\nto occur together. Levinson’s presumptive meanings, for example, are\ndefeasible, i.e., fulfil [3a], local [7b], pertain to competence [1a],\nand are faster to process than inferential meanings [8a]. They are\ncompetence defaults of the type [1a] because they arise independently\nof the situation of discourse and are triggered by the construction\nalone, due to the presumed default scenario that it pertains to. For\nexample, scalar inference from ‘many’ to ‘not\nall’ is a case of a competence-based, context-independent, local\ndefault. Similarly, the rhetorical structure rules of SDRT give rise to\ncompetence defaults. (15b) is a result of the common, shared knowledge\nthat pushing normally results in falling. \n(15a) You pushed me and I fell.\n\n(15b) You pushed me and as a result I fell.\n \nOn Levinson’s account, such defaults arise as soon as the relevant\nword or expression is processed and as soon as the situation is clear\nto the addressee. Such meanings can subsequently be cancelled if\nfurther context witnesses against them. \nAs regards feature 7, it is at least conceivable that presumed\nmeanings arise as soon as the triggering word or construction has been\nprocessed by the hearer. For Levinson (1995, 2000), salient meanings\nhave this property of arising even before the processing of the\nsentence is completed. In other words, they arise\npre-propositionally or locally. Discourse\ninterpretation proceeds incrementally and similarly the assignment of\ndefault meanings to the processed segments is incremental. For\nexample, the scalar term many in (16a) triggers the presumed\nmeaning not all as soon as it has been processed. The\nsubscript d in (16b) stands for the default meaning and is\nplaced immediately after the triggering construction. \n(16a) Many people liked Peter Carey’s new novel.\n\n(16b) Many (d many but not all) people liked Peter Carey’s\nnew novel.\n \nSimilarly, ‘paper cup’ and ‘tea cup’ give rise\nto presumed meanings locally, as in (17b) and (18b) respectively. \n(17a) Those paper cups are not suitable for hot drinks.\n\n(17b) Those paper cups (d cups made of paper) are not\nsuitable for hot drinks.\n \n(18a) I want three tea cups, three saucers and three spoons please.\n\n(18b) I want three tea cups (d cups used for drinking tea),\nthree saucers and three spoons please.\n \nInferences such as those in (17b) and (18b) are very common. They are,\nhowever, substantially different from the inference in (16b) in that\nthe resulting meaning is the lexical meaning of the collocation,\nsimilar to that of a compound. Other examples include ‘pocket\nknife’ vs. e.g., ‘bread knife’, and ‘coffee\nspoon’ vs. e.g., ‘silver spoon’. It is worth\nremembering that on Levinson’s account, presumed, salient\ninterpretations can be explained through the principles of rational\ncommunicative behaviour summed up as his Q, I and M heuristics (see\nSection 1.2 and Levinson 1995, 2000). (16b) arises through the\nQ-heuristic, ‘What isn’t said isn’t’, while (17b) and\n(18b) arise through the I-heuristic, ‘What is expressed simply\nis stereotypically exemplified’. Most generally, the defaults\nthat arise through the Q-heuristic exploit a comparison with what was\nnot, but might have been, said. For example, ‘most’\ntriggers an inference to a denial of a stronger item\n‘all’; ‘believe’ triggers an inference to\n‘not know’. At the same time, they are all easily\ncancellable, as (16c) illustrates. \n(16c) Many, and possibly all, people liked Peter Carey’s new novel.\n \nI-heuristic exploits only what there is in the sentence: it is an\ninference to a stereotype and as such is not so easily cancellable.\nFor example, (19) and (20) seem rather bizarre. \n(19) Those paper cups, I mean cups used for storing paper, are full.\n\n(20) I want three tea cups, I mean cups used for storing tea leaves.\n \nPerhaps the fact that these defaults are not so easily cancellable\ncomes from their property of resembling lexical compounds and, like in\nthe case of compounds, the link between the juxtaposed lexemes is very\nstrong in their case. If indeed it is plausible to treat them on a par\nwith compounds, then they are not very useful as a supporting argument\nfor local defaults: instead of defaults, we have lexical meaning of\ncompounds. \nLocal defaults allow us to dispose of the level of an underspecified\npropositional representation in semantic theory. Since the inferences\nproceed incrementally, then as soon as the triggering expression is\nencountered, there is no level of a minimal proposition that would\nconstitute a foundation for further inferences. If there is one, it is\njust accidental, in that the triggering item may just happen to be\nplaced at the end of the sentence, for example ‘tea cups’\nin the first clause of (20) above. But it is also important to note\nthat the status of such defaults is still far from clear. For example,\nLevinson’s defaults are local, but at the same time\n“cancellable” to the extent that the context may prevent\nthem from arising. This leads to a difficulty in examples such as\n(21)–(22). \n(21) You are allowed five attempts to get the prize.\n\n(22) You are allowed to do five minutes of piano practice today\nbecause it is late.\n \nIt is clear that in (21) ‘five’ is to be understood as\n‘at most five’. How are we to model the process of\nutterance interpretation for this case? Are we to propose that the\ninference from ‘at least five’ to ‘exactly\nfive’ takes place and is then cancelled? Or are we to propose\nthat ‘five’ is by default ‘at least five’ (or\nunderdetermined five, or ‘exactly five’, depending on the\norientation (see Horn 1992; Koenig 1993; Bultinck 2005) and becomes\naltered in the process of pragmatic inference to ‘at most\nfive’ in the context of ‘allow’? But then,\n‘allow’ is also present in (22) and the inference to\n‘at most’ is not at all salient: doing a longer piano\npractice is generally preferred but may not be what the addressee\nlikes doing and ‘five’ may end up, in this context, to\nmean ‘as little as five’ or ‘five or more’,\nstressing that more than five is not expected but allowed. In (23),\nthe problem is even more salient. If ‘five’ triggers\nlocally the ‘exactly’ meaning, then the default has to be\ncancelled immediately afterwards when ‘are needed’ has\nbeen processed and the ‘at least’ interpretation becomes\nobvious. \n(23) Five votes are needed to pass the proposal.\n \nAlternatively, we can stipulate that the first inference takes place\nafter the word ‘needed’. It is clear that a lot needs to\nbe done to clarify the notion of local defaults: most importantly, (i)\nwhat counts as the triggering unit, (ii) to what extent context is\nconsulted, and (iii) how common cancellation is. But it seems that if\ndefaults prove to be so local as to arise out of words or even\nmorphemes, then they are part of the computational power of grammar\nand they belong to grammar and lexicon rather than to semantics and\npragmatics. Chierchia (2004) and Landman (2000) represent this view.\nChierchia argues that since scalar implicatures do not arise in\ndownward-entailing contexts (contexts that license inference from a\nset to its subset), there is a clear syntactic constraint on their\nbehaviour (but see Chemla et al. 2011). Jaszczolt (2012)\ncalls such units that give rise to defaults or inferential\nmodification ‘fluid characters’, employing Kaplan’s (1989)\ncontent-character distinction, to emphasise the fact that the unit of\nmeaning that leads to inference or to a default meaning varies from\ncontext to context and from speaker to speaker: characters are ‘fluid’\nbecause they correspond to ‘flexible inferential bases’ or ‘flexible\ndefault bases’. But much more theorizing and substantial empirical\nsupport are needed to establish the exact size of such local domains\nand the corresponding fluid characters. \nAs far as feature [8] is concerned, some experimental work has been\nperformed to help decide between [8a] and [8b], measuring the recovery\ntime for the default meaning as opposed to the non-default one. The\ndevelopment of the ability to use scalar inferences has also been\ntested (Noveck 2001; Papafragou & Musolino 2003; Musolino 2004;\nNoveck and Sperber 2004; Geurts 2010). It has been argued on the basis\nof some evidence that default interpretations are not faster to\nproduce and can be absent altogether from processing in the case of\nfive-year old subjects. Noveck (2004) provides the following evidence\nagainst Levinson’s automatic and fast defaults. Children were\npresented with some descriptions of situations in which the order of\nthe events was inverted in narration. They had to assess whether the\ndescription was true or false. The outcome was that the children who\nagreed with the inverted description reacted faster than the ones who\ndisagreed. It was then concluded that enriching ‘and’ to\n‘and then’ is not automatic: it takes time. And, if\npragmatically enriched responses take longer, then they cannot be the\ndefault ones (see Noveck 2004: 314). Similarly, with scalar terms, if\none could demonstrate that the enriched readings, such as ‘some\nbut not all’ for ‘some’, arise faster than\n‘some but not necessarily not all’, one would have strong\nevidence in support of the defaults view. \nThe problem is that all these experiments assume Levinson’s notion of\na fast and inference-free default while this is, as we have seen, by\nno means the only understanding of default interpretations, and,\narguably, not even the most commonly assumed one. The experimenters\ntalk of arguments for and against ‘the Default View’,\n‘the Default Model’ (see also Bezuidenhout and Morris\n2004, Breheny et al 2006), while, in fact there is no such unique\nmodel to be falsified: there are very different understandings of\ndefaultness even in post-Gricean pragmatics alone, as is evident from\nSection 1. The list of possible defining characteristics of default\ninterpretations in [1]–[8] shows that one cannot talk about\nthe default meaning. At the same time, it is much harder to\nprovide any experimental evidence for or against salient meaning that\ndraw on some contextual information, arise late in utterance\nprocessing, and are not normally cancellable. The latter also seem\nmuch more intuitively plausible than Levinson’s rigid defaults\nin that they are simply shortcuts through costly pragmatic inference\nand as such can be triggered by the situation itself rather than by\nthe properties of a lexical item or construction at large. They are\njust normal, unmarked meanings for the context at hand and it is not\nimprobable that such default, salient interpretations will prove to\nconstitute just the polar end of a scale of degrees of inference\nrather than have qualitatively different properties from non-default,\nclearly inference-based interpretations. They will occupy the area\ntowards the ‘zero’ end of the scale of inference but will\nnot trigger the dichotomy ‘default vs. inferential\ninterpretation’. But since it is debatable whether salience\nought to be equated with defaultness in he first place, our\nterminological quandary comes back with full strength (see Section\n3). \nIt is also difficult to pinpoint the boundary between default and\nnon-default interpretations when we allow context and inference to\nplay a role in default meanings, that is when we allow [2b] and [8b].\nThis does not mean, however, that we should pour them out with the\nbath water and resort to proposing nonce-inference in the case of\nevery single utterance produced in discourse. When context-dependence\nof defaults is allowed, then the main criterion for such meanings is\ntheir subdoxastic arrival. When conscious inference is allowed, then\nthe main criterion is the fact that only minimal contextual input is\nallowed, such as, say, the co-text in (24). In (24), the definite\ndescription ‘the first daughter’ has the attributive\nrather than referential reading. \n(24) The first daughter to be born to Mr and Mrs Brown will be called\nScarlett.\n \nOn a traditional Gricean view of post-propositional, sentence-based\npragmatic inference, we have here the default attributive reading: the\nexpression ‘to be born’ and the future auxiliary\n‘will’ signal that no particular, extant, known individual\nis referred to. This is also the view followed in Default Semantics\n(Section 1.8) where both inference and defaults are ‘ assumed to\nbe global’ – ‘assumed’ in the sense of a methodological\nassumption put in place until we have the means to test the actual\nlength of fluid characters and the content of the corresponding\ndefault bases. In other words, information arrived at through WS\nmerges with that from CPI, CD and SCWD when all of the WS is\nready. But in Default Semantics there is no default involved in (24):\nwe have WS merging with CPI to produce the attributive reading. On\nLevinson’s presumptive meanings account (Section 1.3), it can be\nstipulated that (24) would fall in-between GCIs and PCIs: the only\ncontext that is required is the sentence itself, so the example is not\ndifferent from any other cases of GCIs. But the locality of the GCI is\nthe problem: depending on how we construct the length of the\ntriggering expression, we obtain a GCI or a PCI. When we construe it\nas ‘the first daughter’, the sub-part of the definite noun\nphrase, then we obtain the referential reading as the default, to be\ncancelled by ‘to be born’. In short, we don’t know yet, at\nthe current state of theorizing and experimenting, which of the\npotential defining characteristics of defaults to employ. Neither are\nwe ready to propose the demarcation line between default and\nnon-default interpretations. We can conceive of the first as shortcuts\nthrough inference but such a definition will not suffice for\ndelimiting a category. We can, however, concede that default\ninterpretations are governed by principles of rational behaviour in\ncommunication, be it Gricean maxims, neo-Gricean principles or\nheuristics, the logic of information structuring of SDRT, or a version\nof defeasible logic as presented above. \nAll in all, it appears that the diversity of default interpretations\npertains not only to their features listed in [1]–[8] but also\nto their provenance. This diversified use makes the term heavily\ntheory-dependent. \nIn pragmatic theory, the term ‘default’ is often used in association\nwith the term ‘salience’, so it is important to clarify the\nsimilarities and differences between them. For Giora (e.g. 2003; Giora\n& Givoni 2015), salience is independent from literality of an\ninterpretation and depends merely on ‘accessibility in memory due to\nsuch factors as frequency of use or experiential familiarity’ (Giora\n2003: 33). She clearly distinguishes salience from defaultness in that\nfor her salience concerns meanings, while defaultness concerns\ninterpretations: \nThis, however, can lead to a problem with reconciling defaultness with\nsalience in particular cases, making her propose degrees of\ndefaultness (ibid.), and to a rather counterintuitive diluting of the\nconcept of a default. For example, sarcasm can rely on non-salient but\ndefault interpretation – non-salient when the interpretation is\ncompositionally put together instead of being processed as a\nconventionalised unit. \nOn the other hand, for Jaszczolt (e.g. 2016a) defaultness relies\nprecisely on salience that leads to automatic meaning retrieval. She\ncalls this view Salience-Based Contextualism: the meaning of an\nutterance is derived through a variety of interacting processes, some\nof which rely on automatic interpretations such as cognitive defaults\nor socio-cultural and world knowledge defaults identified in the\ntheory of Default Semantics and discussed in Section 1.8. Such\ndefaults are defaults for the context and for the speaker, but\nsalience that predicts them is not. According to Salience-Based\nContextualism, words and structures can trigger salient, automatically\nretrieved meanings. This is guaranteed by the fact that language is a\nsocio-cultural as well as a cognitive phenomenon and as such is shaped\nby its common use in discourse on the one hand, and by the structure\nand operations of the brain on the other (see Jaszczolt 2016a: 50).\nSalience is situation-free (although not always co-text free –\nsee above on fluid characters), defaultness is not: it is easy to\nimagine a speaker who does not make use of the available salient\ninterpretation because he or she lacks the necessary sociocultural\nbackground, knowledge of the laws of physics, or is guided by the\ncontext towards a different interpretation. Defaultness applies to a\nflexible unit on the basis of which an interpretation is formed (a\nfluid character). Defaults in conversation result from emergent\nintentionality (Haugh 2008, 2011): they rely on the process of\nco-construction of meaning. So, conversational defaults subsume\nsalient meanings – literal or not, such as Giora’s salient\nmeanings understood as conventional, prototypical, familiar, or\nfrequent. \nOne of the important corollaries of this salience-based defaultness is\nthe possible redundancy of the literal/nonliteral distinction. If\nwords exhibit strong influences on each other in a string as well as\ninfluences from the situation of discourse (sometimes called\n‘lateral’ and ‘top-down influences’,\nrespectively – see e.g. Recanati 2012), then we have little\nreason for postulating literal meaning. For example, in (25), we have\nlittle reason for postulating ‘literal’ meanings of\n‘city’ or ‘asleep’: either of the words may\naccommodate to fit the other, and the appropriate interpretation will\nfollow. \n(25) The city is asleep. (from Recanati 2012: 185).\n \nIf ‘city’ means ‘inhabitants of the city’,\n‘asleep’ applies to it directly. If it means the place\nwith its infrastructure, ‘asleep’ has to adjust to mean\nsomething to the effect of ‘quiet’, ‘dark’ or\n‘showing no movement’. But neither of the processes has a\nclear point of departure: there is no obvious, clearly definable move\nfrom literal to non-literal. Such co-occurrence comes with degrees of\nsalience of certain meanings. Such options can also be viewed as\n‘probabilistic meanings’ that are ‘contextually\naffirmed’, to use Allan’s (2011: 185) terminology, through\nnonmonotonic inferences either in the co-text or by some other factor\nin the common ground. \nHowever, probabilistic meanings presuppose ambiguity, while in general\nthe salience- and default-oriented semantics and pragmatics relies on\nthe assumption of underspecification. While in the case of (26)-(27)\nan ambiguity account appears justified when viewed from the\nperspective of the inventory of the lexicon in a language system (in\nthat one would expect an analogy from ‘leopard’ and\n‘fox’ to ‘lamb’ and ‘goat’, while in the\ncontext of the sentence this analogy is not present, as shown in (26a)\nand (27a)), most cases of lexical adjustment cannot be traced back to\nproperties of entries in the lexical inventory. \n(26) Jacqueline prefers leopard to fox.\n\n(27) Harry prefers lamb to goat. \n(26a) Jacqueline prefers leopard skin to fox fur.\n\n(27a) Harry prefers eating lamb to eating goat. \n(from Allan 2011: 180). Probabilistic meaning, according to Allan,\nought to be included in the lexicon: a lexeme ought to be listed in\nthe lexicon with different interpretations, annotated for their\nprobability and circumstances in which this meaning is likely to\noccur. He calls such probabilistic meanings ‘grades of\nsalience’. \nIt is evident that this proposal brings us to the territory of\nvector-based semantics in computational linguistics, while, on the\nother hand, accounts based on intention- and context-driven adjustment\nsuch as Recanati’s and Jaszczolt’s pull in the direction\nof post-Gricean pragmatics. But as Sections 1.1-1.8 demonstrate, the\ntwo traditions are not necessarily incompatible. Lexical salience and\nradical contextualism about the lexicon point in the same direction as\ndistributional accounts in computational semantics: we have\nprobabilities of certain meanings because these are meanings derived\nfrom the ‘company a word keeps’, to adapt Firth’s\n(1957: 11) famous dictum. All in all, content words are strongly\ncontext-dependent – to the extent that perhaps indexicality\nought to be viewed not as a defining feature of some lexical items but\nas a gradable feature of the entire lexicon. But what counts as\nindexicality is a separate theoretical question that cannot be pursued\nhere. \nNext, there is one more reason why salience has to be clearly\ndistinguished from defaultness. Let us consider demonstratives. The\nobject referred to by using ‘that’ can be located with the\nhelp of (i) the recognition of the speaker’s intention, or (ii)\nthe act of pointing, or even (iii) the presence of a particular\nprominent object in the visual field of the interlocutors. All these\ncombine to delimit the concept of salience: such an object has to be\n(made) salient for the linguistic demonstration to succeed. Here\nsalient meaning is entirely, or almost entirely (allowing for\nthe grammatical rendering of e.g. the proximal/distal distinction)\ndetermined by the given context and by the speaker’s knowledge\nthat it is the relevant context (see Lewis 1979 on\nscorekeeping; Cappelen and Dever 2016 for a discussion). What is\nimportant for us here is that salience can be produced by the\nuse of a context-dependent term: objects are brought to salience by\nthe use of an indexical. Salience so understood is still compatible\nwith the situation-independent concept of salience discussed above (to\ndistinguish it from defaultness) in that it is the semantic meaning,\nthe character (Kaplan 1989) of the demonstrative that triggers the\nbringing-to-salience process. \nNow, on the one hand, linguistic research informs us that expressions\nwith thin semantic content such as anaphorically used demonstrative\npronouns or personal pronouns are employed for referents whose\ncognitive status is high. In other words, they are used when the\nobject is in focus of attention or at least activated in memory\n(Gundel et al. 1993; see Jaszczolt 2002: 140–149 for a discussion). On\nthe other hand, when combined with an act of demonstration, the object\ncan be made salient. Cappelen and Dever (2016) discuss here\ntwo types of successful referring by demonstratives: pointing and\nintending (i.e. (i) and (ii) above), contrasted with prominence (i.e.\n(iii) above). The first creates salience, while the latter pertains to\nextant salience; the first brings entities into focus, while the\nlatter exploits their in-focus cognitive status. What is of particular\ninterest to semanticists (of both orientations discussed here, Gricean\nand computational) is that the first type allows for accommodation\n(Lewis 1979): objects are made more salient when communication\nrequires it. \nTo conclude, salience clearly differs from defaultness but for\nexpressions (words, phrases, sentences) for which delimiting default\ninterpretations makes sense, salience can provide an explanans. \nThis comparison of various selected approaches to default\ninterpretations in semantics and pragmatics allows for some\ngeneralizations. Firstly, it is evident from the surveyed literature\nthat, contrary to the assumptions of some experimental pragmaticists,\nthere is no one, unique ‘default model’ of utterance\ninterpretation. Instead, default (and salient) meanings are recognised\nin many approaches to utterance interpretation but they are defined by\ndifferent sets of characteristic features. Next, in the present state\nof theorizing, data-based analyses and experimenting, while the\nrationale for default interpretations is strong, some of the\nproperties of such interpretations are still in need of further\ninvestigation. For example, the discussions of locality of defaults\nand their subdoxastic arrival are in need of empirical support before\nthey can be taken any further. In other words, a fluid character is in\nneed of empirical identification. \nMoreover, the principle and method for delimiting default\ninterpretation as distinguished from inferential interpretation is\nstill a task for the future. The existence of a shortcut through\ncostly inference is an appealing and hardly controversial thesis but\nthe exact properties of such meanings are still subject to\ndisputes. \nNext, the automatic arrival at context-dependent meanings has to be\ndiscussed as part of the debate between the direct access view and the\nmodular view of language processing. Direct access predicts that\ncontext is responsible for activating relevant senses to the extent\nthat the salience of the particular sense of a lexical item does not\nplay a part. According to the modular view, lexical meanings that are\nnot appropriate for the context are also activated, only to be\nsuppressed at the next stage of processing. With the rise of theories\nthat sit between these polar views, the question of the compatibility\nof the salience in the lexicon and the default status of utterance\ninterpretations requires more attention. What can be attributed to the\nlexicon (or, in terms of Default Semantics, what exactly is the scope\nof WS) and what to the context of utterance, remains an unresolved\nquestion. \nFinally, whether we approach defaults through distributional\ncomputational semantics, theoretical truth-conditional semantics,\npost-Gricean pragmatics, or some version of a combined view, progress\nin research on defaults in human reasoning will necessarily require\nprogress in technology. No matter how powerful our theories are, they\nwill have to be tested either on large corpora, or through\nneuroimaging: more traditional methods of psycholinguistic experiments\nor small databases will always leave a wide margin of doubt as to ‘is\nit really how human reasoning works’? If there are big generalizations\nto be made regarding how we jump to conclusions, these will have to be\nmodern equivalents of the 19th century phenomenological ideas, founded\non intentionality of mental states, informativeness of acts of\ncommunication, all predicted by assumed efficiency (but not\nnecessarily cooperation), but with access to modern methods of\nempirical corroboration (or falsification).","contact.mail":"kmj21@cam.ac.uk","contact.domain":"cam.ac.uk"}]
