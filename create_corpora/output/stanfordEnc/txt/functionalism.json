[{"date.published":"2004-08-24","date.changed":"2018-07-20","url":"https://plato.stanford.edu/entries/functionalism/","author1":"Janet Levin","author1.info":"http://dornsife.usc.edu/cf/faculty-and-staff/faculty.cfm?pid=1003452","entry":"functionalism","body.text":"\n\n\nFunctionalism in the philosophy of mind is the doctrine that what\nmakes something a mental state of a particular type does not depend on\nits internal constitution, but rather on the way it functions, or the\nrole it plays, in the system of which it is a part. This doctrine is\nrooted in Aristotle's conception of the soul, and has antecedents in\nHobbes's conception of the mind as a “calculating\nmachine”, but it has become fully articulated (and popularly\nendorsed) only in the last third of the 20th century. Though the term\n‘functionalism’ is used to designate a variety of\npositions in a variety of other disciplines, including psychology,\nsociology, economics, and architecture, this entry focuses exclusively\non functionalism as a philosophical thesis about the nature of mental\nstates.\n\n\nThe following sections will trace the intellectual antecedents of\ncontemporary functionalism, sketch the different types of\nfunctionalist theories, and discuss the most serious objections to\nthem.\n\nFunctionalism is the doctrine that what makes something a thought,\ndesire, pain (or any other type of mental state) depends not on its\ninternal constitution, but solely on its function, or the role it\nplays, in the cognitive system of which it is a part. More precisely,\nfunctionalist theories take the identity of a mental state to be\ndetermined by its causal relations to sensory stimulations, other\nmental states, and behavior. \nFor (an avowedly simplistic) example, a functionalist theory might\ncharacterize pain as a state that tends to be caused by\nbodily injury, to produce the belief that something is wrong with the\nbody and the desire to be out of that state, to produce anxiety, and,\nin the absence of any stronger, conflicting desires, to cause wincing\nor moaning. According to this theory, all and only creatures with\ninternal states that meet these conditions, or play these roles, are\ncapable of being in pain. \nSuppose that, in humans, there is some distinctive kind of neural\nactivity (C-fiber stimulation, for example) that meets these\nconditions. If so, then according to this functionalist theory, humans\ncan be in pain simply by undergoing C-fiber stimulation. But the\ntheory permits creatures with very different physical constitutions to\nhave mental states as well: if there are silicon-based states of\nhypothetical Martians or inorganic states of hypothetical androids\nthat also meet these conditions, then these creatures, too, can be in\npain. As functionalists often put it, pain can be realized by\ndifferent types of physical states in different kinds of creatures, or\nmultiply realized. (See entry on\n multiple realizability.)\n Indeed, since descriptions that make explicit reference only to a\nstate's causal relations with stimulations, behavior, and one another\nare what have come to be known as “topic-neutral” (Smart\n1959) — that is, as imposing no logical restrictions on the\nnature of the items that satisfy the descriptions — then it's\nalso logically possible for non-physical states to play the\nrelevant roles, and thus realize mental states, in some systems as\nwell. So functionalism is compatible with the sort of dualism that\ntakes mental states to cause, and be caused by, physical states. \nStill, though functionalism is officially neutral between materialism\nand dualism, it has been particularly attractive to materialists,\nsince many materialists believe (or argue; see Lewis, 1966) that it is\noverwhelmingly likely that any states capable of playing the roles in\nquestion will be physical states. If so, then functionalism can stand\nas a materialistic alternative to the Psycho-Physical Identity Thesis\n(introduced in Place 1956, Feigl 1958, and Smart 1959, and defended\nmore recently in Hill 1991, and Polger 2011), which holds that each\ntype of mental state is identical with a particular type of\nneural state. This thesis seems to entail that no creatures\nwith brains unlike ours can share our sensations, beliefs, and\ndesires, no matter how similar their behavior and internal\norganization may be to our own, and thus functionalism, with its claim\nthat mental states can be multiply realized, has been regarded as\nproviding a more inclusive, less “(species-) chauvinistic”\n(Block 1980b) — theory of the mind that is compatible with\nmaterialism. (More recently, however, some philosophers have contended\nthat the identity thesis may be more inclusive than functionalists\nassume; see Section 6 for further discussion.) \nWithin this broad characterization of functionalism, however, a number\nof distinctions can be made. One of particular importance is the\ndistinction between theories in which the functional characterizations\nof mental states purport to provide analyses of the meanings of our\nmental state terms (or otherwise restrict themselves to a priori\ninformation), and theories that permit functional characterizations of\nmental states to appeal to information deriving from scientific\nexperimentation (or speculation). (See Shoemaker 1984c, and Rey 1997,\nfor further discussion and more fine-grained distinctions.) There are\nother important differences among functionalist theories as well.\nThese (sometimes orthogonal) differences, and the motivations for\nthem, can best be appreciated by examining the origins of\nfunctionalism and tracing its evolution in response both to explicit\ncriticisms of the thesis and changing views about the nature of\npsychological explanation. \nAlthough functionalism attained its greatest prominence as a theory of\nmental states in the last third of the 20th century, it has\nantecedents in both modern and ancient philosophy, as well as in early\ntheories of computation and artificial intelligence. \nThe earliest view that can be considered an ancestor of functionalism\nis Aristotle's theory of the soul (350 BCE). In contrast to Plato's\nclaim that the soul can exist apart from the body, Aristotle argued\n(De Anima Bk. II, Ch. 1) that the (human) soul is the\nform of a natural, organized human body — the set of\npowers or capacities that enable it to express its “essential\nwhatness”, which for Aristotle is a matter of fulfilling the\nfunction or purpose that defines it as the kind of thing it is. Just\nas the form of an axe is whatever enables it to cut, and the form of\nan eye is whatever enables it to see, the (human) soul is to be\nidentified with whichever powers and capacities enable a natural,\norganized human body to fulfill its defining function, which,\naccording to Aristotle, is to survive and flourish as a living,\nacting, perceiving, and reasoning being. So, Aristotle argues, the\nsoul is inseparable from the body, and comprises whichever capacities\nare required for a body to live, perceive, reason, and act. (See\nShields, 1990, and Nelson, 1990, for further debate about whether\nAristotle's view can be considered to be a version of functionalism.)\n \nA second, relatively early, ancestor of contemporary functionalism is\nHobbes's (1651) account of reasoning as a kind of computation that\nproceeds by mechanistic principles comparable to the rules of\narithmetic. Reasoning, he argues, is “nothing but\nreckoning, that is adding and subtracting, of the\nconsequences of general names agreed upon for the marking and\nsignifying of our thoughts.” (Leviathan, Ch.\n5) In addition, Hobbes suggests that reasoning — along with\nimagining, sensing, and deliberating about action, all of which\nproceed according to mechanistic principles — can be performed\nby systems of various physical types. As he puts it in his\nIntroduction to Leviathan, where he likens a commonwealth to\nan individual human, “why may we not say that all automata\n(engines that move themselves by springs and wheels…) have an\nartificial life? For what is the heart but a spring; and the nerves\nbut so many strings, and the joints but so many wheels…”.\nIt was not until the middle of the 20th century, however, that it\nbecame common to speculate that thinking may be nothing more than\nrule-governed computation that can be carried out by creatures of\nvarious physical types. \nIn a seminal paper (Turing 1950), A.M. Turing proposed that the\nquestion, “Can machines think?” can be replaced by the\nquestion, “Is it theoretically possible for a finite state\ndigital computer, provided with a large but finite table of\ninstructions, or program, to provide responses to questions that would\nfool an unknowing interrogator into thinking it is a human\nbeing?” Now, in deference to its author, this question is most\noften expressed as “Is it theoretically possible for a finite\nstate digital computer (appropriately programmed) to pass the Turing\nTest?” (See Turing Test entry.) \nIn arguing that this question is a legitimate replacement for the\noriginal (and speculating that its answer is “yes”),\nTuring identifies thoughts with states of a system defined solely by\ntheir roles in producing further internal states and verbal outputs, a\nview that has much in common with contemporary functionalist theories.\nIndeed, Turing's work was explicitly invoked by many theorists during\nthe beginning stages of 20th century functionalism, and was the avowed\ninspiration for a class of theories, the “machine state”\ntheories most firmly associated with Hilary Putnam (1960, 1967) that\nhad an important role in the early development of the doctrine.  \nOther important recent antecedents of functionalism are the\nbehaviorist theories that emerged in the early-to-mid twentieth\ncentury. These include both the empirical psychological theories\nassociated primarily with Watson and Skinner, and the\n“logical” or “analytical” behaviorism of\nphilosophers such as Malcolm (1968) and Ryle (1949) (and, arguably,\nWittgenstein 1953). Though functionalism is significantly different\nfrom behaviorism in that the latter attempts to explain behavior\nwithout any reference whatsoever to mental states and processes, the\ndevelopment of two important strains of functionalism,\n“psychofunctionalism” and “analytical”\nfunctionalism, can both be profitably viewed as attempts to rectify\nthe difficulties, respectively, of empirical and logical behaviorism,\nwhile retaining certain important insights of those theories. \nAs an empirical psychological theory, behaviorism holds that the\nbehavior of humans (and other animals) can be explained by appealing\nsolely to behavioral dispositions, that is, to the lawlike tendencies\nof organisms to behave in certain ways, given certain environmental\nstimulations. Behavioral dispositions, unlike thoughts, feelings, and\nother internal states that can be directly observed only by\nintrospection, are objectively observable and are indisputably part of\nthe natural world. Thus they seemed to be fit entities to figure\ncentrally in the emerging science of psychology. Also, behaviorist\ntheories promised to avoid a potential regress that appeared to\nthreaten psychological explanations invoking internal representations,\nnamely, that to specify how such representations produce the behaviors\nin question, one must appeal to an internal intelligent agent (a\n“homunculus”) who interprets the representations, and\nwhose skills would themselves have to be explained. \nThe promise of behaviorism lay in its conviction that there could be a\nscience of human behavior as objective and explanatory as other\n“higher-level” sciences such as chemistry and biology.\nBehaviorism indeed had some early successes, especially in the domain\nof animal learning, and its principles are still used, at least for\nheuristic purposes, in various areas of psychology. But as many\npsychologists (and others, e.g. Chomsky 1959) have argued, the\nsuccesses of behaviorism seem to depend upon the experimenters'\nimplicit control of certain variables which, when made explicit,\ninvolve ineliminable reference to organisms' other mental states. For\nexample, rats are typically placed into an experimental situation at a\ncertain fraction of their normal body weight — and thus can be\nassumed to feel hunger and to want the food\nrewards contingent upon behaving in certain ways. Similarly, it is\nassumed that humans, in analogous experimental situations,\nwant to cooperate with the experimenters, and\nunderstand and know how to follow the instructions. It seemed\nto the critics of behaviorism, therefore, that theories that\nexplicitly appeal to an organism's beliefs, desires, and other mental\nstates, as well as to stimulations and behavior, would provide a\nfuller and more accurate account of why organisms behave as they do.\nThey could do so, moreover, without compromising the objectivity of\npsychology as long as the mental states to which these theories appeal\nare introduced as states that together play a role in the\nproduction of behavior, rather than states identifiable solely by\nintrospection. Thus work was begun on a range of\n“cognitive” psychological theories which reflected these\npresumptions, and an important strain of contemporary functionalism,\n“psycho-functionalism” (Fodor 1968, Block and Fodor 1972)\ncan be seen a philosophical endorsement of these new cognitive\ntheories of mind. \nLogical behaviorism, in contrast to behaviorism as a psychological\ntheory, is a thesis about the meanings of our mental state terms or\nconcepts. According to logical behaviorism, all statements about\nmental states and processes are equivalent in meaning to statements\nabout behavioral dispositions. So, for (again, an overly simplified)\nexample, “Henry has a toothache” would be equivalent in\nmeaning to a statement such as “Henry is disposed (all things\nbeing equal) to cry out or moan and to rub his jaw”. And\n“Amelia is thirsty” would be equivalent to a statement\nsuch as “If Amelia is offered some water, she will be disposed\n(all things being equal) to drink it.” These candidate\ntranslations, like all behavioristic statements, eschew reference to\nany internal states of the organism, and thus do not threaten to\ndenote, or otherwise induce commitment to, properties or processes\n(directly) observable only by introspection. In addition, logical\nbehaviorists argued that if statements about mental states were\nequivalent in meaning to statements about behavioral dispositions,\nthere could be an unproblematic account of how mental state terms\ncould be applied both to oneself and others, and how they could be\ntaught and learned. \nHowever, as many philosophers have pointed out (Chisholm 1957; Geach\n1957), logical behaviorism provides an implausible account of the\nmeanings of our mental state terms, since, intuitively, a subject can\nhave the mental states in question without the relevant behavioral\ndispositions — and vice versa. For example, Gene may believe\nthat it's going to rain even if he's not disposed to wear a raincoat\nand take an umbrella when leaving the house (or to perform any other\ncluster of rain-avoiding behaviors), if Gene doesn't mind, or actively\nenjoys, getting wet. And subjects with the requisite motivation can\nsuppress their tendencies to pain behavior even in the presence of\nexcruciating pain, while skilled actors can perfect the lawlike\ndisposition to produce pain behavior under certain conditions, even if\nthey don't actually feel pain. (Putnam 1965) The problem, these\nphilosophers argued, is that no mental state, by itself, can be\nplausibly assumed to give rise to any particular behavior unless one\nalso assumes that the subject possesses additional mental states of\nvarious types. And so, it seemed, it was not in fact possible to give\nmeaning-preserving translations of statements invoking pains, beliefs,\nand desires in purely behavioristic terms. Nonetheless, the idea that\nour common sense concepts of mental states reveal an essential tie\nbetween mental states and their typical behavioral expressions is\nretained, and elaborated, in contemporary “analytic”\nfunctionalist theories. \nGiven this history, it is helpful to think of functionalist theories\nas belonging to one of three major strains — “machine\nfunctionalism”, “psychofunctionalism” and\n“analytic functionalism” — and to see them as\nemerging, respectively, from early AI theories, empirical behaviorism,\nand logical behaviorism. It's important to recognize, however, that\nthere is at least some overlap in the bloodlines of these different\nstrains of functionalism, and also that there are functionalist\ntheories, both earlier and more recent, that fall somewhere in\nbetween. For example, Wilfrid Sellars's (1956) account of mental\nstates as “theoretical entities” is widely regarded as an\nimportant early version of functionalism, but it takes the proper\ncharacterization of thoughts and experiences to depend partially on\ntheir role in providing a scientific explanation of behavior, and\npartly on what he calls the “logic”, or the a priori\ninterrelations, of the relevant concepts. Still, it is instructive to\ngive separate treatment to the three major strains of the doctrine, as\nlong as these caveats are kept in mind. \nThe early functionalist theories of Putnam (1960, 1967) can be seen as\na response to the difficulties facing behaviorism as a scientific\npsychological theory, and as an endorsement of the (new) computational\ntheories of mind which were becoming increasingly significant rivals\nto it. (But see Putnam 1988, for subsequent doubts about machine\nfunctionalism, Chalmers 1996b, for a response, and Shagrir 2005, for a\ncomprehensive account of the evolution of Putnam's views on the\nsubject) \nAccording to Putnam's machine state functionalism, any\ncreature with a mind can be regarded as a Turing machine (an idealized\nfinite state digital computer), whose operation can be fully specified\nby a set of instructions (a “machine table” or program)\neach having the form: \nA machine table of this sort describes the operation of a\ndeterministic automaton, but most machine state\nfunctionalists (e.g. Putnam 1967) take the proper model for the mind\nto be that of a probabilistic automaton: one in which the\nprogram specifies, for each state and set of inputs, the\nprobability with which the machine will enter some subsequent\nstate and produce some particular output. \nOn either model, however, the mental states of a creature are to be\nidentified with such “machine table states”\n(S1,…,Sn). These states\nare not mere behavioral dispositions, since they are specified in\nterms of their relations not only to inputs and outputs, but also to\nthe state of the machine at the time. For example, if believing it\nwill rain is regarded as a machine state, it will not be regarded\nas a disposition to take one's umbrella after looking at the weather\nreport, but rather as a disposition to take one's umbrella if one\nlooks at the weather report and is in the state of wanting to\nstay dry. So machine state functionalism can avoid what many have\nthought to be a fatal difficulty for behaviorism. In addition,\nmachines of this sort provide at least a simple model of how internal\nstates whose effects on output occur by means of mechanical processes\ncan be viewed as representations (though the question of\nwhat, exactly, they represent has been an ongoing topic of\ndiscussion (see sections 4.4–5). Finally, machine table states\nare not tied to any particular physical (or other) realization; the\nsame program, after all, can be run on different sorts of computer\nhardware. \nIt's easy to see, therefore, why Turing machines provided a fruitful\nmodel for early functionalist theories. However, because machine table\nstates are total states of a system, the early functionalist equation\nof mental states with machine table states faded in importance as a\nmodel for the functional characterization of the complex of distinct\ninternal states that can be simultaneously realized in a human (or\nother) subject (Block and Fodor 1972; Putnam 1973). Nonetheless, the\nidea that internal states can be fully described in terms of their\nrelations to input, output, and one another, and can figure\nin lawlike descriptions, and predictions, of a system's output, was a\nrich and important idea that is retained by contemporary functionalist\ntheories. And many functionalists (e.g. Rey 1997) argue that mental\nstates are best regarded as computational states (but see Piccinini\n2004 for dissent and the entry\n The Computational Theory of Mind\n for a comprehensive discussion of this question).  \nA second strain of functionalism, psycho-functionalism, derives\nprimarily from reflection upon the goals and methodology of\n“cognitive” psychological theories. In contrast to the\nbehaviorists' insistence that the laws of psychology appeal only to\nbehavioral dispositions, cognitive psychologists argue that the best\nempirical theories of behavior take it to be the result of a complex\nof mental states and processes, introduced and individuated in terms\nof the roles they play in producing the behavior to be explained. For\nexample (Fodor's, in his 1968, Ch. 3), a psychologist may begin to\nconstruct a theory of memory by postulating the existence of\n“memory trace” decay, a process whose occurrence or\nabsence is responsible for effects such as memory loss and retention,\nand which is affected by stress or emotion in certain distinctive\nways. \nOn a theory of this sort, what makes some neural process an instance\nof memory trace decay is a matter of how it functions, or the role it\nplays, in a cognitive system; its neural or chemical properties are\nrelevant only insofar as they enable that process to do what trace\ndecay is hypothesized to do. And similarly for all mental states and\nprocesses invoked by cognitive psychological theories. Cognitive\npsychology, that is, is intended by its proponents to be a\n“higher-level” science like biology, and thus to have\nautonomy from lower-level sciences such as neurophysiology: just as,\nin biology, physically disparate entities can all be hearts as long as\nthey function to circulate blood in a living organism, and physically\ndisparate entities can all be eyes as long as they enable an organism\nto see, disparate physical structures or processes can be instances of\nmemory trace decay — or more familiar phenomena such as\nthoughts, sensations, and desires — as long as they play the\nroles described by the relevant cognitive theory. \nPsycho-functionalism, therefore, can be seen as straightforwardly\nadopting the methodology of cognitive psychology in its\ncharacterization of mental states and processes as entities defined by\ntheir role in a cognitive psychological theory. All versions of\nfunctionalism, however, can be regarded as characterizing mental\nstates in terms of their roles in some psychological theory\nor other. (A more formal account of this will be given in Section 4.1\nbelow.) What is distinctive about psycho-functionalism is its claim\nthat mental states and processes are just those entities, with just\nthose properties, postulated by the best scientific\nexplanation of human behavior. This means, first, that the form of the\ntheory can diverge from the “machine table” specifications\nof machine state functionalism. It also means that the information\nused in the functional characterization of mental states and processes\nneedn't be restricted to what is considered common knowledge or common\nsense, but can include information available only by careful\nlaboratory observation and experimentation. For example, a\npsychofunctional theory might be able to distinguish phenomena such as\ndepression from sadness or listlessness even though the distinctive\ncauses and effects of these syndromes are difficult to untangle solely\nby consulting intuitions or appealing to common sense. And\npsychofunctional theories will not include characterizations of mental\nstates for which there is no scientific evidence, such as buyer's\nregret or hysteria, even if the existence and efficacy of such states\nis something that common sense affirms. \nThis may seem to be an unmitigated advantage, since psycho-functional\ntheories can avail themselves of all the tools of inquiry available to\nscientific psychology, and will presumably make all, and only, the\ndistinctions that are scientifically sound. This methodology, however,\nleaves psycho-functionalism open to the charge that it, like the\nPsycho-Physical Identity Thesis, may be overly\n“chauvinistic” (Block 1980b), since creatures whose\ninternal states share the rough, but not fine-grained, causal patterns\nof ours wouldn't count as sharing our mental states. Many\npsycho-functionalists may not regard this as an unhappy consequence,\nand argue that it's appropriate to treat only those who are\npsychologically similar as having the same mental states. But there is\na more serious worry about the thesis, namely, that if the laws of the\nbest empirical psychological theories diverge from even the broad\ncontours of our “folk psychology” — that is, our\ncommon sense beliefs about the causal roles of our thoughts,\nsensations, and perceptions — it will be hard to take\npsycho-functional theories as providing an account of our mental\nstates, rather than merely changing the subject (Loar 1981, Stich\n1983, Greenwood 1991). Many theorists, however (Horgan and Woodward\n1985), argue that it's likely that future psychological theories will\nbe recognizably close to “folk psychology”, though this\nquestion has been the subject of debate (Churchland 1981). \nBut there is another important strain of functionalism,\n“analytic” functionalism, that takes there to be reason to\nrestrict the defining theory not just to generalizations sufficiently\nclose to those that “the folk” take to hold between mental\nstates, environmental stimulations, and behavior, but rather to a\npriori information about these relations. (See Smart 1959,\nArmstrong 1968, Shoemaker 1984a,b,c, Lewis 1972, and Braddon-Mitchell\nand Jackson 1996/2007.) This is because, for analytic functionalists,\nthere are equally important goals that require strictly a priori\ncharacterizations of mental states. \nLike the logical behaviorism from which it emerged, the goal of\nanalytic functionalism is to provide “topic-neutral”\ntranslations, or analyses, of our ordinary mental state terms or\nconcepts. Analytic functionalism, of course, has richer resources than\nlogical behaviorism for such translations, since it permits reference\nto the causal relations that a mental state has to stimulations,\nbehavior, and other mental states. Thus the statement\n“Blanca wants some coffee” need not be rendered, as\nlogical behaviorism requires, in terms such as “Blanca is\ndisposed to order coffee when it is offered”, but rather as\n“Blanca is disposed to order coffee when it is offered,\nif she has no stronger desire to avoid coffee”. But\nthis requires any functional “theory” acceptable to\nanalytic functionalists to include only generalizations about mental\nstates, their environmental causes, and their joint effects on\nbehavior that are so widely known and “platitudinous” as\nto count as analyzing our ordinary concepts of the mental\nstates in question. \nA good way to see why analytic functionalists insist that functional\ncharacterizations provide meaning analyses is to revisit a debate that\noccurred in the early days of the Psycho-Physical Identity Theory, the\nthesis that each type of mental state can be identified with some type\nof brain state or neural activity. For example, early identity\ntheorists (e.g. Smart 1959) argued that it makes perfect sense (and\nmay well be true) to identify pain with C-fiber\nstimulation. The terms ‘pain’ and ‘C-fiber\nstimulation’, they acknowledged, do not have the same\nmeaning, but nonetheless they can denote the same state; the\nfact that an identity statement is not a priori, they argued, does not\nmean that it is not true. And just because I need not consult some\nsort of brain scanner when reporting that I'm in pain doesn't mean\nthat the pain I report is not a neural state that a brain scanner\ncould (in principle) detect. \nAn important — and enduring — objection to this argument,\nhowever, was raised early on by Max Black (reported in Smart 1959).\nBlack argued, following Frege (1892), that the only way that terms\nwith different meanings can denote the same state is to express\ndifferent properties, or “modes of presentation” of that\nstate. But this implies, he argued, that if terms like\n‘pain’, ‘thought’ and ‘desire’ are\nnot equivalent in meaning to any physicalistic descriptions, they can\ndenote physical states only by expressing irreducibly mental\nproperties of them. Thus, even if ‘pain’ and\n‘C-fiber stimulation’ pick out a single type of neural\nstate, this state must have two types of properties, physical\nand mental, by means of which the identification can be made. This\nargument has come to be known as the “Distinct Property\nArgument”, and is taken by its proponents to undermine a\nthorough-going materialistic theory of the mind. (See White 1986 and\n2007, for more recent versions of this argument, and Block 2007, for a\nresponse.) \nThe appeal of meaning-preserving functional characterizations,\ntherefore, is that in providing topic-neutral equivalents of our\nmental state terms and concepts, they blunt the anti-materialistic\nforce of the Distinct Property Argument. True enough, analytic\nfunctionalists can acknowledge, terms like ‘pain’,\n‘thought’, and ‘desire’ are not equivalent to\nany descriptions expressed in the language of physics, chemistry, or\nneurophysiology. But if there are functional descriptions\nthat preserve the meanings of these terms, then a creature's mental\nstates can be identified simply by determining which of that\ncreature's internal states and processes play the relevant functional\nroles (see Lewis 1966). And since the capacity to play these roles is\nmerely a matter of having certain causal relations to stimulations,\nbehavior, and one another, the possession of these properties is\ncompatible with a materialistic theory of the mind. \nA major question, of course, is whether a theory that limits itself to\na priori information about the causal relations between stimulations,\nmental states, and behavior can make the right distinctions among\nmental states. This question will be pursued further in Section 4. \nThere is yet another distinction between kinds of functional theory\n— one that crosscuts the distinctions described so far —\nthat is important to note. This is the distinction between what has\ncome to be known as “role” functionalism and\n“realizer” (or “filler”) functionalism\n(McLaughlin 2006). To see the difference between these types of\ntheory, consider—once again—the (avowedly simplistic)\nexample of a functional theory of pain introduced in the first\nsection. \nAs noted earlier, if in humans this functional role is played by\nC-fiber stimulation, then, according to this functionalist theory,\nhumans can be in pain simply by undergoing C-fiber stimulation. But\nthere is a further question to be answered, namely, what is the\nproperty of pain itself? Is it the higher-level relational property of\nbeing in some state or other that plays the “pain role”in\nthe theory, or the C-fiber stimulation that actually plays this\nrole? \nRole functionalists identify pain with that higher-level relational\nproperty. Realizer functionalists, however, take a functional theory\nmerely to provide definite descriptions of whichever\nlower-level properties satisfy the functional\ncharacterizations. On these views (also called “functional\nspecification” theories), if the property that occupies the\ncausal role of pain in human beings is C-fiber stimulation, then pain\n(or at least pain-in-humans) would be C-fiber stimulation,\nrather than the higher-level property of having some lower-level state\nthat plays the relevant role. (This is not to suggest that there is a\ndifference in kind between higher-level “role” properties\nand the lower-level “realizations” of those roles, since\nit may be that, relative to even lower-level descriptions, those\nrealizations can be characterized as functional states themselves\n(Lycan 1987). \nSome of the earliest versions of analytic functionalism (Lewis 1966,\nArmstrong 1968 — but see Lewis 1980, for a modification) were\npresented as functional specification theories, as topic-neutral\n“translations” of mental state terms that could pave the\nway for a psycho-physical identity theory by defusing the Distinct\nProperty Argument (see section 3.3). However, if there are differences\nin the physical states that satisfy the functional definitions in\ndifferent (actual or hypothetical) creatures, such theories—like\nmost versions of the identity theory—would violate a key\nmotivation for functionalism, namely, that creatures with states that\nplay the same role in the production of other mental states and\nbehavior possess, literally, the same mental states.  \nIt may be that there are some important, more general, physical\nsimilarities between the neural states of seemingly disparate\ncreatures that satisfy a given functional characterization (see\nBechtel and Mundale 1999, Churchland 2005, and Polger and Shapiro,\n2012—but see Aizawa and Gillett, 2009 for dissent; this issue\nwill be discussed further in Section 6). However, even if this is so,\nit is unlikely that these similarities hold of all the\ncreatures, including Martians and other hypothetical beings, who could\nshare our functional organization, and thus our theory of mental\nstates would remain, in Block's (1980) terms, overly\n“chauvinistic”. One could counter the charge of\nchauvinism, of course, by suggesting that all creatures with\nlower-level states that satisfy a given functional characterization\npossess a common (lower-level) disjunctive state or property.\nOr one could suggest that, even if all creatures possessing states\nthat occupy (for example) the pain role are not literally in the same\nmental state, they nonetheless share a closely related higher-level\nproperty (call it, following Lewis 1966 (note 6), “the attribute\nof having pain”). But neither alternative, for many\nfunctionalists, goes far enough to preserve the basic functionalist\nintuition that functional commonality trumps physical diversity in\ndetermining whether creatures can possess the same mental states. Thus\nmany functionalists—both a priori and empirical—advocate\nrole functionalism, which, in addition to avoiding chauvinism, permits\nmental state terms to be rigid designators (Kripke 1972), denoting the\nsame items—those higher-level “role”\nproperties—in all possible worlds.  \nOn the other hand, some functionalists—here, too, both a priori\nand empirical—consider realizer functionalism to be in a better\nposition than role functionalism to explain the causal efficacy of the\nmental. If I stub my toe and wince, we believe that my toe stubbing\ncauses my pain, which in turn causes my wincing. But, some have argued\n(Malcolm 1968; Kim 1989, 1998), if pain is realized in me by some\nneural event-type, then insofar as there are purely physical law-like\ngeneralizations linking events of that type with wincings, one can\ngive a complete causal explanation of my wincing by citing the\noccurrence of that neural event (and the properties by virtue of which\nit figures in those laws). And thus it seems that the higher-level\nrole properties of that event are causally irrelevant. This is known\nas the “causal exclusion problem”, which is claimed to\narise not just for functional role properties, but for dispositional\nproperties in general (Prior, Pargetter, and Jackson 1982)—and\nindeed for any sort of mental states or properties not type-identical\nto those invoked in physical laws. This problem will be discussed\nfurther in Section 5.2. \nSo far, the discussion of how to provide functional characterizations\nof individual mental states has been vague, and the examples avowedly\nsimplistic. Is it possible to do better, and, if so, which version of\nfunctionalism is likely to have the greatest success? These questions\nwill be the focus of this section, and separate treatment will be\ngiven to experiential (often called 'qualitative' or 'phenomenal')\nstates, such as perceptions and bodily sensations, which have a\ndistinctive qualitative character or “feel”, and\nintentional states, such as thoughts, beliefs, and desires, which\npurport to represent the world in various ways To be sure, there is\nincreasing consensus that experiential states have representational\ncontents and intentional states have qualitative character and thus\nthat these two groups may not be mutually exclusive (see Horgan and\nTienson, 2002). Nonetheless I will discuss them separately to focus on\nwhat all agree to be the distinctive features of each.  \nFirst, however, it is important to get more precise about how exactly\nfunctional definition is supposed to work. This can be done by\nfocusing on a general method for constructing functional definitions\nintroduced by David Lewis (1972; building on an idea of Frank\nRamsey's), which has become standard practice for functionalists of\nall varieties. Articulating this method will help in evaluating the\nstrengths and weaknesses of the different varieties of\nfunctionalism—while displaying some further challenges that\narise for them all. \nThe key feature of this now-canonical method is to treat mental states\nand processes as being implicitly defined by the Ramsey\nsentence of one or another psychological theory — common\nsense, scientific, or something in between. (Analogous steps, of\ncourse, can be taken to produce the Ramsey-sentence of any\ntheory, psychological or otherwise). For (a still simplistic) example,\nconsider the sort of generalizations about pain introduced before:\npain tends to be caused by bodily injury; pain tends to produce the\nbelief that something is wrong with the body and the desire to be out\nof that state; pain tends to produce anxiety; pain tends to produce\nwincing or moaning. \nTo construct the Ramsey-sentence of this “theory”, the\nfirst step is to conjoin these generalizations, then replace all names\nof different types of mental states with different variables, and then\nexistentially quantify those variables, as follows: \nSuch a statement is free of any mental state terms. It includes only\nquantifiers that range over mental states, terms that denote\nstimulations and behavior, and terms that specify various causal\nrelations among them. It can thus be regarded as providing implicit\ndefinitions of the mental state terms of the theory. An individual\nwill have those mental states just in case it possesses a family of\nfirst-order states that interact in the ways specified by the theory.\n(Though functionalists of course acknowledge that the first-order\nstates that satisfy the functional definitions may vary from species\nto species — or even from individual to individual — they\nspecify that, for each individual, the functional definitions be\nuniquely satisfied.) \nA helpful way to think of the Ramsey sentence of a psychological\ntheory is to regard it as defining a system's mental states “all\nat once” as states that interact with stimulations in various\nways to produce behavior (See Lewis 1972; also see Field 1980 for a\nmore technical elaboration of Lewis's method, and an account of some\ncrucial differences between this kind of characterization and the one\nLewis initially proposed.) This makes it clear that, in the classic\nformulations of functional theories, mental states are intended to be\ncharacterized in terms of their relations to stimulations, behavior,\nand all the other states that may be permissibly invoked by\nthe theory in question, and thus certain functional theories may have\nmore resources for individuating mental states than suggested by the\ncrude definitions used as examples. The next three sections will\ndiscuss the potential of various sorts of functionalist theory for\ngiving adequate characterizations of experiential and intentional\nstates—and also for specifying the inputs and outputs of the\nsystem.  \nThe common strategy in the most successful treatments of perceptual\nexperiences and bodily sensations (Shoemaker 1984a, Clark 1993;\nadumbrated in Sellars 1956) is to individuate experiences of various\ngeneral types (color experiences, experiences of sounds, feelings of\ntemperature) in part by appeal to their positions in the\n“quality spaces” associated with the relevant sense\nmodalities — that is, the (perhaps multidimensional) matrices\ndetermined by judgments about the relative similarities and\ndifferences among the experiences in question. So, for example, the\nexperience of a very reddish-orange could be (partially) characterized\nas the state produced by the viewing of a color swatch within some\nparticular range, which tends to produce the judgment or belief that\nthe state just experienced is more similar to the experience of red\nthan of orange. (Analogous characterizations, of course, will have to\nbe given of these other color experiences.) The judgments or beliefs\nin question will themselves be (partially) characterized in terms of\ntheir tendencies to produce sorting or categorization behavior of\ncertain specified kinds. \nThis strategy may seem fatal to analytic functionalism, which\nrestricts itself to the use of a priori information to distinguish\namong mental states, since it's not clear that the information needed\nto distinguish among experiences such as color perceptions will result\nfrom conceptual analysis of our mental state terms or concepts.\nHowever, this problem may not be as dire as it seems. For example, if\nsensations and perceptual experiences are characterized in terms of\ntheir places in a “quality space” determined by a person's\npre-theoretical judgments of similarity and dissimilarity (and perhaps\nalso in terms of their tendencies to produce various emotional\neffects), then these characterizations may qualify as a\npriori, even though they would have to be elicited by a kind of\n“Socratic questioning”. \nThere are limits to this strategy, however (see Section 5.5.1 on the\n“inverted spectrum” problem), which seem to leave two\noptions for analytic functionalists: fight — that is, deny that\nit's coherent to suppose that there are the distinctions that the\ncritics suggest, or switch — that is, embrace another version of\nfunctionalism in which the characterizations of mental states, though\nnot conceptual truths, can provide information rich enough to\nindividuate the states in question. To switch, however, would be to\ngive up the benefits (if any) of a theory that offers\nmeaning-preserving translations of our mental state terms. \nThere has been significant skepticism, however, about whether any\nfunctionalist theory — analytic or scientific — can\ncapture what seems to be the distinctive qualitative character of\nexperiential states such as color perceptions, pains, and other bodily\nsensations; these questions will be addressed in section 5.5\nbelow. \nOn the other hand, intentional states such as beliefs, thoughts, and\ndesires (sometimes called “propositional attitudes”) have\noften been thought to be easier to characterize functionally than\nexperiential states such as paints and color experiences (but not\nalways: see Searle 1992, G. Strawson 1994, Horgan and Tienson 2002,\nKriegel 2003, and Pitt 2008, who suggest that intentional states have\nqualitative character as well). We can begin by characterizing beliefs\nas (among other things) states produced in certain ways by\nsense-perception or inference from other beliefs, and desires as\nstates with certain causal or counterfactual relations to the system's\ngoals and needs, and specify further how (according to the relevant\ncommon sense or empirical theory) beliefs and desires tend to interact\nwith one another, and other mental states, to produce behavior.  \nOnce again, this characterization is crude, and needs more detail.\nMoreover, there are some further questions about characterizing\nintentional states—particularly belief— that have emerged\nin recent discussions. Once is whether a subject should be regarded as\nbelieving that p if there is a mismatch between her avowals that p and\nthe characteristic behaviors associated with believing that p in\nstandard circumstances: do avowals outweigh behaviors, or vice\nversa—or are there pragmatic factors that determine what the\nanswer should be in different contexts? (See Gendler, 2008, and\nSchwitzgebel, 2010). Another question is whether the states that\ninteract with desires (and other mental states) to produce behavior\nare best regarded as “full on” or “outright”\nbeliefs, or rather as representations of the world for which\nindividuals have varying degrees of confidence. (See Staffel, 2013,\nand the many contributions to Huber and Schmidt-Petri, 2009, and Ebert\nand Smith, 2012, for further discussion. Functionalism, at least\narguably, can accommodate a number of different answers to these\nquestions, but the project of characterizing beliefs may not be\nstraightforward.  \nIn dependently of these questions, functionalists need to say\nmore(outright or not) about what makes a state a particular belief\n(outright or not) or desire, for example, the belief — or desire\n— that it will snow tomorrow. Most functional theories describe\nsuch states as different relations (or “attitudes”) toward\nthe same state of affairs or proposition (and to describe the belief\nthat it will snow tomorrow and the belief that it will rain tomorrow\nas the same attitude toward different propositions). This permits\ndifferences and similarities in the contents of intentional states to\nbe construed as differences and similarities in the propositions to\nwhich these states are related. But what makes a mental state a\nrelation to, or attitude toward, some proposition P? And can these\nrelations be captured solely by appeal to the functional roles of the\nstates in question? \nThe development of conceptual role semantics may seem to provide an\nanswer to these questions: what it is for Julian to believe that P is\nfor Julian to be in a state that has causal and counterfactual\nrelations to other beliefs and desires that mirror certain\ninferential, evidential, and practical (action-directed) relations\namong propositions with those formal structures (Field 1980; Loar\n1981; Block 1986). This proposal raises a number of important\nquestions. One is whether states capable of entering into such\ninterrelations can (must?) be construed as being, or including\nelements of, a “language of thought” (Fodor 1975; Harman\n1973; Field 1980; Loar 1981). Another is whether idiosyncracies in the\ninferential or practical proclivities of different individuals make\nfor differences in (or incommensurabilities between) their intentional\nstates. (This question springs from a more general worry about the\nholism of functional specification, which will be discussed\nmore generally in Section 5.1.) \nYet another challenge for functionalism are the widespread intuitions\nthat support “externalism”, the thesis that what mental\nstates represent, or are about, cannot be characterized without appeal\nto certain features of the environments in which those individuals are\nembedded. Thus, if one individual's environment differs from\nanother's, they may count as having different intentional states, even\nthough they reason in the same ways, and have exactly the same\n“take” on those environments from their own points of\nview. \nThe “Twin Earth” scenarios introduced by Putnam (1975) are\noften invoked to support an externalist individuation of beliefs about\nnatural kinds such as water, gold, or tigers. Twin Earth, as Putnam\npresents it, is a (hypothetical) planet on which things look, taste,\nsmell and feel exactly the way they do on Earth, but which have\ndifferent underlying microscopic structures; for example, the stuff\nthat fills the streams and comes out of the faucets, though it looks\nand tastes like water, has molecular structure XYZ rather than\nH2O. Many theorists find it intuitive to think that we\nthereby mean something different by our term\n‘water’ than our Twin Earth counterparts mean by theirs,\nand thus that the beliefs we describe as beliefs about water are\ndifferent from those that our Twin Earth counterparts would describe\nin the same way. Similar conclusions, they contend, can be drawn for\nall cases of belief (and other intentional states) regarding natural\nkinds. \nThe same problem, moreover, appears to arise for other sorts of belief\nas well. Tyler Burge (1979) presents cases in which it seems intuitive\nthat a person, Oscar, and his functionally equivalent counterpart have\ndifferent beliefs about various syndromes (such as arthritis) and\nartifacts (such as sofas) because the usage of these terms by their\nlinguistic communities differ. For example, in Oscar's community, the\nterm ‘arthritis’ is used as we use it, whereas in his\ncounterpart's community ‘arthritis’ denotes inflammation\nof the joints and also various maladies of the thigh. Burge's\ncontention is that even if Oscar and his counterpart both complain\nabout the ‘arthritis’ in their thighs and make exactly the\nsame inferences involving ‘arthritis’, they mean different\nthings by their terms and must be regarded as having different\nbeliefs. If these cases are convincing, then there are differences\namong types of intentional states that can only be captured by\ncharacterizations of these states that make reference to the practices\nof an individual's linguistic community. These, along with the Twin\nEarth cases, suggest that if functionalist theories cannot make\nreference to an individual's environment, then capturing the\nrepresentational content of (at least some) intentional states is\nbeyond the scope of functionalism. (See Section 4.4 for further\ndiscussion, and Searle 1980, for related arguments against\n“computational” theories of intentional states.) \nOn the other hand, the externalist individuation of intentional states\nmay fail to capture some important psychological commonalities between\nourselves and our counterparts that are relevant to the explanation of\nbehavior. If my Twin Earth counterpart and I have both come in from a\nlong hike, declare that we're thirsty, say “I want some\nwater” and head to the kitchen, it seems that our behavior can\nbe explained by citing a common desire and belief. Some theorists,\ntherefore, have suggested that functional theories should attempt\nmerely to capture what has been called the “narrow\ncontent” of beliefs and desires — that is, whichever\nrepresentational features individuals share with their various Twin\nEarth counterparts. There is no consensus, however, about just how\nfunctionalist theories should treat these “narrow”\nrepresentational features (Block 1986; Loar 1987, Yli-Vakkuti and\nHawthorne, 2018), and some philosophers have expressed skepticism\nabout whether such features should be construed as representations at\nall (Fodor 1994; also see entry on Narrow Content). Even if a\ngenerally acceptable account of narrow representational content can be\ndeveloped, however, if the intuitions inspired by “Twin\nEarth” scenarios remain stable, then one must conclude that the\nfull representational content of intentional states cannot be captured\nby “narrow” functional characterizations alone (and this\nwill be true as well for certain sorts of qualitative states, e.g.\ncolor experiences, if they too have representational content). \nConsiderations about whether certain sorts of beliefs are to be\nexternally individuated raise the related question about how best to\ncharacterize the stimulations and behaviors that serve as inputs\nand outputs to a system. Should they be construed as events\ninvolving objects in a system's environment (such as fire trucks,\nwater and lemons), or rather as events in that system's sensory and\nmotor systems? Theories of the first type are often called\n“long-arm” functional theories (Block 1990), since they\ncharacterize inputs and outputs — and consequently the states\nthey are produced by and produce — by reaching out into the\nworld. Adopting a “long-arm” theory would prevent our Twin\nEarth counterparts from sharing our beliefs and desires, and may thus\nhonor intuitions that support an externalist individuation of\nintentional states (though further questions may remain about what\nQuine has called the “inscrutability of reference”; see\nPutnam 1988). \nIf functional characterizations of intentional states are intended to\ncapture their “narrow contents”, however, then the inputs\nand outputs of the system will have to be specified in a way that\npermits individuals in different environments to be in the same\nintentional state. On this view inputs and outputs may be better\ncharacterized as activity in specific sensory receptors and motor\nneurons. But this (“short-arm”) option also restricts the\nrange of individuals that can share our beliefs and desires, since\ncreatures with different neural structures will be prevented from\nsharing our mental states, even if they share all our behavioral and\ninferential dispositions. (In addition, this option would not be open\nto analytic functionalist theories, since generalizations that link\nmental states to neurally specified inputs and outputs would not,\npresumably, have the status of conceptual truths.) \nPerhaps there is a way to specify sensory stimulations that abstracts\nfrom the specifics of human neural structure enough to include any\npossible creature that intuitively seems to share our mental states,\nbut is sufficiently concrete to rule out entities that are clearly not\ncognitive systems (such as the economy of Bolivia; see Block 1980b).\nIf there is no such formulation, however, then functionalists will\neither have to dispel intuitions to the effect that certain systems\ncan't have beliefs and desires, or concede that their theories may be\nmore “chauvinistic” than initially hoped. \nClearly, the issues here mirror the issues regarding the individuation\nof intentional states discussed in the previous section. More work is\nneeded to develop the “long-arm” and\n“short-arm” alternatives, and to assess the merits and\ndeficiencies of both. \nThe previous sections were by and large devoted to the presentation of\nthe different varieties of functionalism and the evaluation of their\nrelative strengths and weaknesses. There have been many objections to\nfunctionalism, however, that apply to all versions of the theory. Some\nof these have already been introduced in earlier discussions, but\nthey, and many others, will be addressed in more detail here. \nOne difficulty for every version of the theory is that functional\ncharacterization is holistic. Functionalists hold that mental\nstates are to be characterized in terms of their roles in a\npsychological theory—be it common sense, scientific, or\nsomething in between—but all such theories incorporate\ninformation about a large number and variety of mental states. Thus if\npain is interdefined with certain highly articulated beliefs and\ndesires, then animals who don't have internal states that play the\nroles of our articulated beliefs and desires can't share our pains,\nand humans without the capacity to feel pain can't share certain (or\nperhaps any) of our beliefs and desires. In addition, differences in\nthe ways people reason, the ways their beliefs are fixed, or the ways\ntheir desires affect their beliefs — due either to cultural or\nindividual idiosyncracies — might make it impossible for them to\nshare the same mental states. These are regarded as serious worries\nfor all versions of functionalism (see Stich 1983, Putnam 1988). \nSome functionalists, however (e.g. Shoemaker 1984c), have suggested\nthat if a creature has states that approximately realize our\nfunctional theories, or realize some more specific defining\nsubset of the theory particularly relevant to the specification of\nthose states, then they can qualify as being mental states of the same\ntypes as our own. The problem, of course, is to specify more precisely\nwhat it is to be an approximate realization of a theory, or what\nexactly a “defining” subset of a theory is intended to\ninclude, and these are not easy questions. (They have particular bite,\nmoreover, for analytic functionalist theories, since\nspecifying what belongs inside and outside the “defining”\nsubset of a functional characterization raises the question of what\nare the conceptually essential, and what the merely collateral,\nfeatures of a mental state, and thus raise serious questions about the\nfeasibility of (something like) an analytic-synthetic distinction.\n(Quine 1953, Rey 1997)). \nAnother worry for functionalism is the “causal exclusion\nproblem”, introduced in section 3.4: the worry about whether\nrole functionalism can account for what we take to be the causal\nefficacy of our mental states (Malcolm 1968, Kim 1989, 1998). For\nexample, if pain is realized in me by some neural state-type, then\ninsofar as there are purely physical law-like generalizations linking\nstates of that type with pain behavior, one can give a complete causal\nexplanation of my behavior by citing the occurrence of that neural\nstate (and the properties by virtue of which it figures in those\nlaws). And thus, some have argued, the higher-level role properties of\nthat state—its being a pain—are causally irrelevant. \nThere have been a number of different responses to this problem. Some\n(e.g. Loewer 2002, 2007, Antony and Levine 1997, Burge 1997, Baker\n1997) suggest that it arises from an overly restrictive account of\ncausation, in which a cause must “generate” or\n“produce” its effect, a view which would count the\nmacroscopic properties of other special sciences as causally\nirrelevant as well. Instead, some argue, causation should be regarded\nas a special sort of counterfactual dependence between states of\ncertain types (Loewer 2002, 2007, Fodor 1990, Block 1997), or as a\nspecial sort of regularity that holds between them (Melnyk 2003). If\nthis is correct, then functional role properties (along with the other\nmacroscopic properties of the special sciences) could count as\ncausally efficacious (but see Ney 2012 for dissent). However, the\nplausibility of these accounts of causation depends on their prospects\nfor distinguishing bona-fide causal relations from those that are\nclearly epiphenomenal, and some have expressed skepticism about\nwhether they can do the job, among them Crane 1995, Kim 2007, Jackson\n1995, Ludwig 1998, and McLaughlin 2006, forthcoming. (On the other\nhand, see Lyons (2006) for an argument that if functional properties\nare causally inefficacious, this can be viewed as a  benefit \nof the theory.) \nYet other philosophers argue that causation is best regarded as a\nrelation between types of events that must be invoked to provide\nsufficiently general explanations of behavior (Antony and Levine 1997,\nBurge 1997, Baker 1997). Though many who are moved by the exclusion\nproblem (e.g. Kim, Jackson) maintain that there is a difference\nbetween generalizations that are truly causal and those that\ncontribute in some other (merely epistemic) way to our understanding\nof the world, theorists who advocate this response to the problem\ncharge that this objection, once again, depends on a restrictive view\nof causation that would rule out too much. \nAnother problem with views like the ones sketched above, some argue\n(Kim 1989, 1998), is that mental and physical causes would thereby\noverdetermine their effects, since each would be causally\nsufficient for their production. And, though some theorists argue that\noverdetermination is widespread and unproblematic (see Loewer 2002,\nand also Shaffer, 2003, and Sider 2003, for a more general discussion\nof overdetermination), others contend that there is a special relation\nbetween role and realizer that provides an intuitive explanation of\nhow both can be causally efficacious without counting as\noverdetermining causes. For example, Yablo (1992), suggests that\nmental and physical properties stand in the relation of determinable\nand determinate (just as red stands to scarlet), and argues that our\nconviction that a cause should be commensurate with its effects\npermits us to take the determinable, rather than the determinate,\nproperty to count as causally efficacious in psychological\nexplanation. Bennett (2003) suggests, alternatively, that the realizer\nproperties metaphysically necessitate the role properties in a\nway that prevents them from satisfying the conditions for\noverdetermination. Yet another suggestion (Wilson, 1999, 2011, and\nShoemaker, 2001) is that the causal powers of mental properties are\nincluded among (or are proper subsets of) the causal powers of the\nphysical properties that realize them. (See also Macdonald and\nMacdonald 1995, Witmer, 2003, Yates, 2012, and Strevens, 2012, for\nrelated views.)  \nThere has been substantial recent work on the causal exclusion\nproblem, which, as noted earlier, arises for any non-reductive theory\nof mental states. (See the entry on Mental Causation, as well as\nBennett 2007, and Funkhouser 2007, for further discussion and\nextensive bibliographies.) But it is worth discussing a related worry\nabout causation that arises exclusively for role-functionalism (and\nother dispositional theories), namely, the problem of\n“metaphysically necessitated effects” (Rupert 2006,\nBennett 2007). If pain is functionally defined (either by an a\npriori or an empirical theory) as the state of being in some\nlower-level state or other that, in certain circumstances causes\nwincing, then it seems that the generalization that pain causes\nwincing (in those circumstances) is at best uninformative, since the\nstate in question would not be pain if it didn't. And, on the\nHumean view of causation as a contingent relation, the causal claim\nwould be false. Davidson (1980b) once responded to a similar argument\nby noting that even if a mental state M is defined in terms of its\nproduction of an action A, it can often be redescribed in other terms\nP such that 'P caused A' is not a logical truth. But it's unclear\nwhether any such redescriptions are available to role (vs. realizer)\nfunctionalists. \nSome theorists (e.g. Antony and Levine 1997) have responded by\nsuggesting that, though mental states may be defined in terms of some\nof their effects, they have other effects that do not follow\nfrom those definitions which can figure into causal generalizations\nthat are contingent, informative, and true. For example, even if it\nfollows from a functional definition that pain causes wincing (and\nthus that the relation between pain and wincing cannot be truly\ncausal), psychologists may discover, say, that pain produces\nresilience (or submissive behavior) in human beings. One might worry,\nnonetheless, that functional definitions threaten to leave too many\ncommonly cited generalizations outside the realm of contingency, and\nthus causal explanation: surely, we may think, we want to affirm\nclaims such as “pain causes wincing”. Such claims could be\naffirmed, however, if (as seems likely) the most plausible functional\ntheories define sensations such as pain in terms of a small subset of\ntheir distinctive psychological, rather than behavioral,\neffects (see section 4.2). \nA different line of response to this worry (Shoemaker 1984d, 2001) is\nto deny the Humean account of causation altogether, and contend that\ncausal relations are themselves metaphysically necessary, but this\nremains a minority view. (See also Bird, 2002, and Latham, 2011, for\nfurther discussion.) \nAnother important question concerns the beliefs that we have about our\nown “occurrent” (as opposed to dispositional) mental\nstates such as thoughts, sensations, and perceptions. We seem to have\nimmediately available, non-inferential beliefs about these states, and\nthe question is how this is to be explained if mental states are\nidentical with functional properties. \nThe answer depends on what one takes these introspective beliefs to\ninvolve. Broadly speaking, there are two dominant views of the matter\n(but see Peacocke 1999, Ch. 5 for further alternatives). One popular\naccount of introspection — the “inner sense” model\non which introspection is taken to be a kind of “internal\nscanning” of the contents of one's mind (Armstrong 1968) —\nhas been taken to be unfriendly to functionalism, on the grounds that\nit's hard to see how the objects of such scanning could be\nsecond-order relational properties of one's neural states (Goldman\n1993). Some theorists, however, have maintained that functionalism can\naccommodate the special features of introspective belief on the\n“inner sense” model, since it would be only one of many\ndomains in which it's plausible to think that we have immediate,\nnon-inferential knowledge of causal or dispositional properties\n(Armstrong 1993; Kobes 1993; Sterelney 1993). A full discussion of\nthese questions goes beyond the scope of this entry, but the articles\ncited above are just three among many helpful pieces in the Open Peer\nCommentary following Goldman (1993), which provides a good\nintroduction to the debate about this issue. \nAnother account of introspection, identified most closely with\nShoemaker (1996a,b,c,d), is that the immediacy of introspective belief\nfollows from the fact that occurrent mental states and our\nintrospective beliefs about them are functionally interdefined. For\nexample, one satisfies the definition of being in pain only if one is\nin a state that tends to cause (in creatures with the requisite\nconcepts who are considering the question) the belief that one is in\npain, and one believes that one is in pain only if one is in a state\nthat plays the belief role, and is caused directly by the pain itself.\nOn this account of introspection, the immediacy and non-inferential\nnature of introspective belief is not merely compatible with\nfunctionalism, but required by it. \nBut there is an objection, most recently expressed by George Bealer\n(1997; see also Hill 1993), that, on this model an introspective\nbelief can only be defined in one of two unsatisfactory ways: either\nas a belief produced by a (second-order) functional state specified\n(in part) by its tendency to produce that very type of belief —\nwhich would be circular — or as a belief about the first-order\nrealization of the functional state, rather than that state\nitself. Functionalists have suggested, however (Shoemaker 2001,\nMcCullagh 2000, Tooley 2001), that there is a way of understanding the\nconditions under which beliefs can be caused by, and thus be about,\none's second-order functional states that permits mental states and\nintrospective beliefs about them to be non-circularly defined (but see\nBealer 2001, for a skeptical response). A full treatment of this\nobjection involves the more general question of whether second-order\nproperties can have causal efficacy, and is thus beyond the scope of\nthis discussion (see section 5.2 and Mental Causation entry). But even\nif this objection can ultimately be deflected, it suggests that\nspecial attention must be paid to the functional characterizations of\n“self-directed” mental states. \nYet another objection to functionalist theories of any sort is that\nthey do not capture the interrelations that we take to be definitive\nof beliefs, desires, and other intentional states. Whereas even\nanalytic functionalists hold that mental states— and also their\ncontents— are implicitly defined in terms of their (causal or\nprobabilistic) roles in producing behavior, these critics\nunderstand intentional states to be implicitly defined in terms of\ntheir roles in rationalizing, or making sense of,\nbehavior. This is a different enterprise, they claim, since\nrationalization, unlike causal explanation, requires showing how an\nindividual's beliefs, desires, and behavior conform, or at least\napproximate, to certain a priori norms or ideals of\ntheoretical and practical reasoning — prescriptions about which\nbeliefs and desires we should have, how we should\nreason, or what, given our beliefs and desires, we ought to\ndo. (See Davidson 1980c, Dennett 1978, and McDowell 1985 for classic\nexpressions of this view.) Thus the defining\n(“constitutive”) normative or rational relations among\nintentional states expressed by these principles cannot be expected to\ncorrespond to causal and probabilistic relations among our internal\nstates, sensory stimulations and behavior, since they constitute a\nkind of explanation that has sources of evidence and standards for\ncorrectness that are different from those of empirical theories\n(Davidson 1980c). One can't, that is, extract facts from values. \nThus, although attributions of mental states can in some sense explain\nbehavior by permitting an observer to “interpret” it as\nmaking sense, they should not be expected to denote entities that\nfigure in empirical generalizations, either common sense or\nscientific. (This is not to say, these theorists stress, that there\nare no causes, or empirical laws of, behavior. These, however, will be\nexpressible only in the vocabularies of the neurosciences, or other\nlower-level sciences, and not as relations among beliefs, desires and\nbehavior.) \nFunctionalists have replied to these worries in different ways. Many\njust deny the intuition behind the objection, and maintain that even\nthe strictest conceptual analyses of our intentional terms and\nconcepts purport to define them in terms of their bona-fide causal\nroles, and that any norms they reflect are explanatory rather than\nprescriptive. They argue, that is, that if these generalizations are\nidealizations, they are the sort of idealizations that occur in any\nscientific theory: just as Boyle's Law depicts the relations between\nthe temperature, pressure, and volume of a gas under certain ideal\nexperimental conditions, our a priori theory of the mind consists of\ndescriptions of what normal humans would do under (physically\nspecifiable) ideal conditions, not prescriptions as to what they\nshould, or are rationally required, to do. \nOther functionalists agree that we may advert to various norms of\ninference and action in attributing beliefs and desires to others, but\ndeny that there is any in principle incompatibility between normative\nand empirical explanations. They argue that if there are causal\nrelations among beliefs, desires, and behavior that even approximately\nmirror the norms of rationality, then the attributions of intentional\nstates can be empirically confirmed (Fodor 1990; Rey 1997). In\naddition, many who hold this view suggest that the principles of\nrationality that intentional states must meet are quite minimal, and\ncomprise at most a weak set of constraints on the contours of our\ntheory of mind, such as that people can't, in general, hold\n(obviously) contradictory beliefs, or act against their (sincerely\navowed) strongest desires (Loar 1981). Still others suggest that the\nintuition that we attribute beliefs and desires to others according to\nrational norms is based on a fundamental mistake; these states are\nattributed not on the basis of whether they rationalize the behavior\nin question, but whether those subjects can be seen as using\nprinciples of inference and action sufficiently like our own —\nbe they rational, like Modus Ponens, or irrational, like the Gambler's\nFallacy or the now familiar instances of “predictable\nirrationality” documented in Kahneman, 2011. (See Stich 1981,\nand Levin 1988, for discussion of this question, and for a more\ngeneral debate about the compatibility of normative and psychological\nprinciples, see Rey, 2007, and Wedgwood, 2007. See also Glüer and\nWikforss, 2009, 2013, and for further discussion, the entry, The\nNormativity of Meaning and Content.) \nNonetheless, although many functionalists argue that the\nconsiderations discussed above show that there is no in principle bar\nto a functionalist theory that has empirical force, these worries\nabout the normativity of intentional ascription continue to fuel\nskepticism about functionalism (and, for that matter, any scientific\ntheory of the mind that uses intentional notions). \nIn addition to these general worries about functionalism, there are\nparticular questions that arise for functional characterizations of\nexperiential or phenomenal states. These questions will be discussed\nin the following section. \nFunctionalist theories of all varieties — whether analytic or\nempirical, FSIT or functional specification — attempt to\ncharacterize mental states exclusively in relational, specifically\ncausal, terms. A common and persistent objection, however, is that no\nsuch characterizations can capture the phenomenal character, or\n“qualia”, of experiential states such as perceptions,\nemotions, and bodily sensations, since they would leave out certain\nessential properties of those experiential states, namely, “what\nit's like” (Nagel 1974) to have them. The next three sections\nwill present the most serious worries about the ability of\nfunctionalist theories to give an adequate characterization of these\nstates. (These worries, of course, will extend to intentional states,\nif, as some philosophers argue, “what it's like” to have\nthem is among their essential properties as well. (See Searle 1992, G.\nStrawson, 1986, Horgan and Tienson, 2002, Kriegel 2003, Pitt 2008, for\nearly presentations of this view, and see Bayne and Montague, 2011,\nand Smithies, 2013a and 2013b for more general discussions of whether\nintentional states possess phenomenal character— often called\n“cognitive phenomenology”— and if so, what, more\nprecisely, it is.) \nThe first to be considered are the “absent” and\n“inverted” qualia objections most closely associated with\nNed Block (1980b; see also Block and Fodor 1972). The “inverted\nqualia” objection to functionalism maintains that there could be\nan individual who (for example) is in a state that satisfies the\nfunctional definition of our experience of red, but is experiencing\ngreen instead—and similarly for all the colors in the spectrum.\nIt is a descendant of the claim, discussed by philosophers from Locke\nto Wittgenstein, that there could be an individual with an\n“inverted spectrum” who is behaviorally indistinguishable\nfrom someone with normal color vision; both objections trade on the\ncontention that the purely relational characterizations in question\ncannot make distinctions among distinct experiences with isomorphic\ncausal patterns. (Nida-Rümelin, 1996, argues that the science of\ncolor vision leaves open the possibility that there could be\nfunctionally equivalent red-green “inverts”, but even if\ninverted qualia are not really an empirical possibility for human\nbeings, given certain asymmetries in our “quality space”\nfor color, and differences in the relations of color experiences to\nother mental states such as emotions (Hardin 1988), it seems possible\nthat there are creatures with perfectly symmetrical color quality\nspaces for whom a purely functional characterization of color\nexperience would fail.) \nA related objection, the “absent qualia” objection,\nmaintains that there could be creatures functionally equivalent to\nnormal humans whose mental states have no qualitative character at\nall. In his well-known “Chinese nation”\nthought-experiment, Block (1980b) invites us to imagine that the\npopulation of China (chosen because its size approximates the number\nof neurons in a typical human brain) is recruited to duplicate his\nfunctional organization for a period of time, receiving the equivalent\nof sensory input from an artificial body and passing messages back and\nforth via satellite. Block argues that such a\n“homunculi-headed” system — or\n“Blockhead”, as it has come to be called — would not\nhave mental states with any qualitative character (other than the\nqualia possessed by the individuals themselves), and thus that there\ncould be states functionally equivalent to sensations or perceptions\nthat lack their characteristic “feels”. Conversely, some\nargue that functional role is not necessary for qualitative\ncharacter: for example, it seems that one could have mild, but\ndistinctive, twinges that have no typical causes or characteristic\neffects. \nAll these objections purport to have characterized a creature with the\nfunctional organization of normal human beings, but without any, or\nthe right sort, of qualia (or vice versa), and thus to have produced a\ncounterexample to functional theories of experiential states. One line\nof response, initially advanced by Sydney Shoemaker (1994b), is that\nalthough functional duplicates of ourselves with inverted qualia may\nbe possible, duplicates with absent qualia are not, since their\npossibility leads to untenable skepticism about the qualitative\ncharacter of one's own mental states. This argument has been\nchallenged, however (Block 1980b; but see Shoemaker's response in\n1994d, and Balog, 1999, for a related view), and the more common\nresponse to these objections—particularly to the absent qualia\nobjection— is to question whether scenarios involving creatures\nsuch as Blockheads provide genuine counterexamples to functionalist\ntheories of experiential states.  \nFor example, some theorists (Dennett 1978; Levin 1985; Van Gulick\n1989) argue that these scenarios provide clear-cut counterexamples\nonly to crude functional theories, and that attention to the\nsubtleties of more sophisticated characterizations will undermine the\nintuition that functional duplicates of ourselves with absent qualia\nare possible (or, conversely, that there are qualitative states\nwithout distinctive functional roles). The plausibility of this line\nof defense is often questioned, however, since there is tension\nbetween the goal of increasing the sophistication (and thus the\nindividuative powers) of the functional definitions, and the goal (for\nanalytic functionalists) of keeping these definitions within the\nbounds of the a priori (though see Section 4.2), or (for\npsycho-functionalists) broad enough to be instantiable by creatures\nother than human beings. A related suggestion is that absent qualia\nseem possible only because of our imaginative shortcomings, in\nparticular, that it is hard for us to attend, at any one time, to all\nthe relevant features of even the simplest functional characterization\nof experiential states; another is that the intuition that Blockheads\nlack qualia is based on prejudice—against creatures with\nunfamiliar shapes and extended reaction times (Dennett 1978), or\ncreatures with parts widely distributed in space (Lycan, 1981,\nSchwitzgebel 2015 and commentary). \nThere are other responses to analogous absent qualia arguments that\nare prominent in the literature, but the target of those arguments is\nbroader. Block's argument was initially presented as a challenge\nexclusively to functionalist theories, both analytic and empirical,\nand not generally to physicalistic theories of experiential states;\nthe main concern was that the purely relational resources of\nfunctional description were incapable of capturing the intrinsic\nqualitative character of states such as feeling pain, or seeing red.\n(Indeed, in Block's 1980b, p. 291, he suggests that qualitative states\nmay best be construed as “composite state[s] whose components\nare a quale and a [functional state],” and adds, in an\nendnote (note 22) that the quale “might be identified\nwith a physico-chemical state”.) But there are similar\nobjections that have been raised against all physicalistic theories of\nexperiential states that are important to consider in evaluating the\nprospects for functionalism. These will be discussed in the next two\nsections. \nOne important objection, advanced by (among others) Kripke (1972) and\nChalmers (1996a), derives from Descartes's well-known argument in the\nSixth Meditation (1641) that since he can clearly and\ndistinctly conceive of himself existing apart from his body (and vice\nversa), and since the ability to clearly and distinctly conceive of\nthings as existing apart guarantees that they are in fact distinct, he\nis in fact distinct from his body. \nChalmers's version of the argument (1996a, 2002), known as the\n“Zombie Argument”, has been particularly influential. The\nfirst premise of this argument is that it is conceivable, in\na special, robust, “positive” sense, that there are\nmolecule-for-molecule duplicates of oneself with no qualia (call them\n“zombies”, following Chalmers 1996a). The second premise\nis that scenarios that are “positively” conceivable in\nthis way represent real, metaphysical, possibilities. Thus, he\nconcludes, zombies are possible, and functionalism — or, more\nbroadly, physicalism — is false. The force of the Zombie\nArgument is due in large part to the way Chalmers defends its two\npremises; he provides a detailed account of just what is required for\nzombies to be conceivable, and also an argument as to why the\nconceivability of zombies entails their possibility (see also Chalmers\n2002, 2006, 2010, Ch. 6, and Chalmers and Jackson 2002). This account,\nbased on a more comprehensive theory of how we can evaluate claims\nabout possibility and necessity known as “two-dimensional\nsemantics”, reflects an increasingly popular way of thinking\nabout these matters, but remains controversial. (For alternative ways\nof explaining conceivability, see Kripke (1986), Hart (1988); for\ncriticism of the argument from two-dimensional semantics, see Yablo\n2000, 2002, Bealer 2002, Stalnaker 2002, Soames 2004, Byrne and Prior\n2006; but see also Chalmers 2006.) \nIn a related challenge, Joseph Levine (1983, 1993, 2001) argues that,\neven if the conceivability of zombies doesn't entail that\nfunctionalism (or more broadly, physicalism) is false, it opens an\n“explanatory gap” not encountered in other cases of\ninter-theoretical reduction, since the qualitative character of an\nexperience cannot be deduced from any physical or functional\ndescription of it. Such attempts thus pose, at very least, a unique\nepistemological problem for functionalist (or physicalist) reductions\nof qualitative states. \nIn response to these objections, analytic functionalists contend, as\nthey did with the inverted and absent qualia objections, that\nsufficient attention to what is required for a creature to duplicate\nour functional organization would reveal that zombies are not really\nconceivable, and thus there is no threat to functionalism and no\nexplanatory gap. A related suggestion is that, while zombies may\nnow seem conceivable, we will eventually find them\ninconceivable, given the growth of empirical knowledge, just as we now\nfind it inconceivable that there could be H2O without water (Yablo\n1999). Alternatively, some suggest that the inconceivability of\nzombies awaits the development of new concepts that can provide\na link between our current phenomenal and physical concepts (Nagel\n1975, 2000), while others (McGinn 1989) agree, but deny that humans\nare capable of forming such concepts.  \nNone of these responses, however, would be an effective defense of\nPsychofunctionalism, which does not attempt to provide analyses of\nexperiential concepts (or suggest that there would, or could, be any\nto come). But there is an increasingly popular strategy for defending\nphysicalism against these objections that could be used to defend\nPsychofunctionalism, namely, to concede that there can be no\nconceptual analyses of qualitative concepts (such as what it's\nlike to see red or what it's like to feel pain) in\npurely functional terms, and focus instead on developing arguments to\nshow that the conceivability of zombies neither implies that such\ncreatures are possible nor opens up an explanatory gap. \nOne line of argument (Block and Stalnaker 1999; Yablo 2000) contends\nthat the conceivability of (alleged) counterexamples to\npsycho-physical or psycho-functional identity statements, such as\nzombies, has analogues in other cases of successful inter-theoretical\nreduction, in which the lack of conceptual analyses of the terms to be\nreduced makes it conceivable, though not possible, that the identities\nare false. However, the argument continues, if these cases routinely\noccur in what are generally regarded as successful reductions in the\nsciences, then it's reasonable to conclude that the conceivability of\na situation does not entail its possibility. \nA different line of argument (Horgan 1994; Loar 1990; Lycan 1990; Hill\n1997, Hill and McLaughlin 1999, Balog 1999) maintains that, while\ngenerally the conceivability of a scenario entails its possibility,\nscenarios involving zombies stand as important exceptions. The\ndifference is that the phenomenal, or “what it's like”,\nconcepts used to describe the properties of experience that we\nconceive zombies to lack are significantly different from the\nthird-personal, discursive concepts of our common sense and scientific\ntheories such as mass, force or charge; they\ncomprise a special class of non-discursive, first-personal,\nperspectival representations of those properties. Whereas conceptually\nindependent third-personal concepts x and y may\nreasonably be taken to express metaphysically independent properties,\nor modes of presentation, no such metaphysical conclusions can be\ndrawn when one of the concepts in question is third-personal and the\nother is phenomenal, since these concepts may merely be\npicking out the same properties in different ways. Thus, the\nconceivability of zombies, dependent as it is on our use of phenomenal\nconcepts, provides no evidence of their metaphysical possibility. \nKey to this line of defense is the claim that these special phenomenal\nconcepts can denote functional (or physical) properties without\nexpressing some irreducibly qualitative modes of presentation of them,\nfor otherwise it couldn't be held that these concepts do in fact apply\nto our functional (or physical) duplicates, even though it's\nconceivable that they don't. This, not surprisingly, has been\ndisputed, and there is currently much discussion in the literature\nabout the plausibility of this claim. If this line of defense is\nsuccessful, however, it can also provide a response to the\n“Distinct Property Argument”, discussed in section 3.3.\n(See Chalmers 1999, Holman, 2013 for criticism of this view, but see\nthe responses of Loar 1999, and Hill and McLaughlin 1999, Balog, 2012,\nLevin, 2008, forthcoming, Diaz-Leon, 2010, 2014; see also see Levin\n2002, 2008, and Shroer, 2010, for the presentation, if not\nendorsement, of a hybrid view.)  \nIn another important, related, challenge to functionalism (and, more\ngenerally, physicalism), Thomas Nagel (1974) and Frank Jackson (1982)\nargue that a person could know all the physical and functional facts\nabout a certain type of experience and still not “know what it's\nlike” to have it. This is known as the “Knowledge\nArgument”, and its conclusion is that there are certain\nproperties of experiences — the “what it's like” to\nsee red, feel pain, or sense the world through echolocation —\nwhich cannot be identified with functional (or physical) properties.\nThough neither Nagel (2000) nor Jackson (1998) now endorse this\nargument, many philosophers contend that it raises special problems\nfor any physicalistic view (see Alter 2007, and, in response, Jackson\n2007). \nAn early line of defense against these arguments, endorsed primarily\nbut not exclusively by a priori functionalists, is known as the\n“Ability Hypothesis”. (Nemirow 1990, 2007, Lewis 1990,\nLevin 1986). “Ability” theorists suggest that knowing what\nit's like to see red or feel pain is merely a sort of\npractical knowledge, a “knowing how” (to imagine,\nremember, or re-identify, a certain type of experience) rather than a\nknowledge of propositions or facts. (See Tye 2000, for a summary of\nthe pros and cons of this position; for further discussion, see the\nessays in Ludlow, Nagasawa, and Stoljar 2004.) An alternative view\namong contemporary functionalists is that coming to know what it's\nlike to see red or feel pain is indeed to acquire propositional\nknowledge uniquely afforded by experience, expressed in terms of\nfirst-personal concepts of those experiences. But, the argument\ncontinues, this provides no problem for functionalism (or\nphysicalism), since these special first-personal concepts need not\ndenote, or introduce as “modes of presentation”, any\nirreducibly qualitative properties. This view, of course, shares the\nstrengths and weaknesses of the analogous response to the\nconceivability arguments discussed above. If it is plausible, however,\nit can also challenge the argument of some philosophers (e.g.,\nChalmers, 2002, Stoljar, 2001, and Alter, 2016) that maintains that no\nphysicalistic theory, not even fundamental physics, can provide\nanything but a relational characterization of the items in their\ndomains—their structure and dynamics—and concludes that no\nphysicalistic theory can capture what seems, from the inside, to be\nthe intrinsic, non-relational properties of our experiential states.\n(See the essays in Alter and Nagasawa, 2015, Part III, for further\ndiscussion.)  \nThere is one final strategy for defending a functionalist account of\nqualitative states against all of these objections, namely,\neliminativism (Dennett 1988; Rey 1997, Frankish, 2016). One can, that\nis, deny that there are any such things as irreducible\nqualia, and maintain that the conviction that such things do,\nor perhaps even could, exist is due to illusion — or\nconfusion. \nIn the last part of the 20th century, functionalism stood as the\ndominant theory of mental states. Like behaviorism, functionalism\ntakes mental states out of the realm of the “private” or\nsubjective, and gives them status as entities open to scientific\ninvestigation. But, in contrast to behaviorism, functionalism's\ncharacterization of mental states in terms of their roles in the\nproduction of behavior grants them the causal efficacy that common\nsense takes them to have. And in permitting mental states to be\nmultiply realized, functionalism seems to offer an account of mental\nstates that is compatible with materialism, without limiting the class\nof those with minds to creatures with brains like ours. \nMore recently, however, there has been a resurgence of interest in the\npsycho-physical (type-) identity thesis, fueled in part by the\ncontention that, in the actual practice of neuroscience, neural states\nare type-individuated more coarsely than early identity theorists such\nas Place, Feigl, and Smart assumed. If this is so, then it may well be\nthat creatures that differ from us in their fine-grain\nneurophysiological make-up can nonetheless share our neural states,\nand thus that the psycho-physical identity thesis can claim some of\nthe scope once thought to be exclusive to functionalism. The\nplausibility of this thesis depends, first, on whether or not such\ncreatures would in fact be our functional equivalents, and if so,\nwhether or not their underlying similarities would in fact be\n(coarse-grain) neural similarities, and not (finer-grain)\npsycho-functional similarities. (See Bechtel 2012, Bickle 2012,\nMcCauley 2012, and Shapiro and Polger 2012, Polger and Shapiro, 2016,\nAizawa and Gillett, forthcoming,and the essays in DeJoong and Shouten\n2012, for further discussion; see also the entry on Multiple\nRealizability.) Even so, it seems that there could be creatures, both\nbiological and non-biological, that are functionally equivalent to us\nbut do not possess even our coarse-grain neural properties. If so, and\nif these creatures can plausibly be regarded as sharing our mental\nstates—to be sure, a controversial thesis—then even if\nneural states can be individuated more coarsely, functionalism will\nretain its claim to greater universality than the identity thesis.\n \nThere remain other substantial questions about functionalism. Most\ndiscussions of the prospects for functionalism focus on its adequacy\nas an account of familiar experiential states such as sensational and\nperceptual experiences, and familiar intentional states such as\nbeliefs and desires. But although some philosophers have considered\nwhether there can be adequate functionalist characterizations of\nemotions and moods (e.g. Rey, 1990, Nussbaum, 2003, deHoog, et al,\n2011) there is increasing interest in these questions, and more work\nneeds to be done. In addition, there is increasing interest in\ndetermining whether there can be plausible functional\ncharacterizations of non-standard perceptual experiences, such as\nsynaesthesia, and various sorts of altered states of consciousness\nthat can arise from the ingestion of drugs or from focused meditation.\n(See Gray et al. 2002, 2004, and Deroy, 2017, for discussions of\nsynaesthesia. For general discussions of altered states of\nconsciousness, see Velmans and Schneider, eds. (2007), and Thompson,\n(2015). \nYet another question is whether functional theories can accommodate\nnon-standard views about the location of mental states, such as the\nhypothesis of extended cognition, which maintains that certain mental\nstates such as memories—and not just their representational\ncontents—can reside outside the head. This question has\nimplications not only for the viability of a functionalist\ncharacterization of memory, but also of beliefs, emotions, and moods.\n(See Clark and Chalmers 2002, Clark, 2008, Adams and Aizawa 2008,\nRupert 2009, Sprevack 2009, and the essays in Menary, 2010, for\nfurther discussion.) \nIn general, the sophistication of functionalist theories has increased\nsince their introduction, but so has the sophistication of the\nobjections to functionalism, especially to functionalist accounts of\nmental causation (section 5.2), introspective knowledge (Section 5.3),\nand the qualitative character of experiential states (Section 5.5).\nFor those unconvinced of the plausibility of dualism, however, and\nunwilling to restrict mental states to creatures physically like\nourselves, the initial attractions of functionalism remain. The\nprimary challenge for future functionalists, therefore, will be to\nmeet these objections to the doctrine, either by articulating a\nfunctionalist theory in increasingly convincing detail, or by showing\nhow the intuitions that fuel these objections can be explained\naway.","contact.mail":"levin@usc.edu","contact.domain":"usc.edu"}]
