[{"date.published":"2019-06-03","url":"https://plato.stanford.edu/entries/phil-multimodallogic/","author1":"Sonja Smets","author1.info":"https://staff.fnwi.uva.nl/f.r.velazquezquesada/","entry":"phil-multimodallogic","body.text":"\n\n\n\n\nHere is what I consider one of the biggest mistakes of all in modal\nlogic: concentration on a system with just one modal operator. The\nonly way to have any philosophically significant results in deontic\nlogic or epistemic logic is to combine these operators with: tense\noperators (otherwise how can you formulate principles of change?); the\nlogical operators (otherwise how can you compare the relative with the\nabsolute?); the operators like historical or\nphysical necessity (otherwise how can you relate the agent to\nhis environment?); and so on and so on. —Scott\n(1970: 161)\n\n\n\nConsider the following seemingly possible situation: \n\n\n\n\nAnn believes that Bob assumes that \\(\\underbrace{\\textit{Ann\nbelieves that Bob’s assumption is wrong.}}_{\\varphi}\\) \n\n\n\n\nNow, here is a tricky question: is \\(\\varphi\\) (“Ann\nbelieves that Bob’s assumption is wrong”) true or\nfalse? Paraphrasing Pacuit and Roy (2017:\n Section 6),\n suppose \\(\\varphi\\) is true. So, what \\(\\varphi\\) represents is true,\nthat is, Ann believes that Bob’s assumption is wrong. Moreover,\nby belief introspection, she believes that “she believes\nBob’s assumption is wrong”, that is, she believes\nBob’s assumption. But the description of the situation tells us\nthat Ann believes that Bob assumes \\(\\varphi\\); then, in fact, Ann\nbelieves that Bob’s assumption is correct. Thus, \\(\\varphi\\),\n“Ann believes that Bob’s assumption is\nwrong”, is false.\n\n\nHence, \\(\\varphi\\) must be false. Then, following Pacuit and Roy\n(2017:\n Section 6)\n again, Ann believes that Bob’s assumption is correct, that is,\nAnn believes \\(\\varphi\\) is correct. Furthermore, the description of\nthe situation states that “Ann believes that Bob assumes\nthat Ann believes that Bob’s assumption is wrong”,\nwhich, given that \\(\\varphi\\) is Bob’s assumption, can be\nrewritten as “Ann believes that Bob assumes that Ann\nbelieves that \\(\\varphi\\) is wrong”. But then, not only Ann\nbelieves that she believes that \\(\\varphi\\) is correct; she also\nbelieves that Bob assumption is that she believes that \\(\\varphi\\) is\nwrong. Thus, it is the case that she believes Bob’s assumption\nis wrong (Ann believes that Bob’s assumption is that she\nbelieves that \\(\\varphi\\) is wrong, but she believes that is wrong:\nshe believes that \\(\\varphi\\) is correct). So, \\(\\varphi\\) is\ntrue.\n\n\nSome readers may wonder, why do I need to know whether Ann\nbelieves that Bob’s assumption is wrong? One of the reasons\nis that, just as\n Russell’s paradox\n suggests that not every collection can constitute a set, this\nsituation, known as the Brandenburger-Keisler Paradox\n(Brandenburger & Keisler 2006), suggests that not every\ndescription of beliefs can be ‘represented’. Now, with a\nbetter motivation, one may wonder again: is \\(\\varphi\\) true or false?\nOr, maybe better, is there a formal setting that gives an answer?\n\n\nIt becomes immediately clear that no system involving a single\nmodality can deal with this situation, as the description includes not\nonly two agents (so, at least two modalities would be required), but\nalso two different concepts: beliefs and\nassumptions. Thus, to make formal sense of this situation,\none requires a system that allows us to deal not only with different\nattitudes, but also with the complex relationship between them. To\nmake formal sense of this (and other similar) situation(s), one\nrequires a multi-modal system.\n\n\n\n\nModal logics are particularly well suited to study a wide range of\nphilosophical concepts, including rational beliefs, obligations,\nknowledge, intentions, desires, evidence and preferences, among many\nothers. Such an analysis provides us with the key insights of the\nbasic building blocks and principles that regulate different\nbehaviors, which is important in a wide range of academic disciplines\nincluding Artificial Intelligence, Psychology, Social Science and even\nPhysics. The concepts we look at have specific context-dependent\nfeatures, which indicates that they can be best studied using models\nthat can express different modes of truth (e.g., both global and local\ntruth). But as Scott’s (1970) quote above suggests, there is\nsomething missing when such philosophical concepts are studied in\nisolation. A big part of what defines a concept lies in the way it\ninteracts with others. For instance, rational beliefs are\nexpected to rely on proper arguments, justifications\nor evidence; disjunctions may not behave as they do\nin natural language in the context of obligations;\nknowledge is better understood when looking for the\nactions that modify it; intentions may be understood\nas derived from desires and beliefs. What is\nrequired for this study are logical systems with more than one modal\noperator, commonly known as multi-modal logics, describing not only\nthe isolated properties of the individual concepts, but also the way\nthey relate to one another. Indeed, multi-modal logics have been\ndesigned for a wide range of applications, including reasoning about\ntime, space, knowledge, beliefs, intentions, desires, obligations,\nactions such as public and private communication, observations,\nmeasurements, moves in a game and others. \nThe present text intends to give a brief (but broad) overview of the\ninteraction between many different philosophical concepts, and to show\nhow the use of multi-modal logical systems can shed some light on\nthese concepts’ interaction. We start in\n section 2\n (Defining concepts in terms of others) by discussing basic\nscenarios that, starting from existing systems, use a combination of\n‘syntactic’ and ‘semantic’ strategies for\ndefining further concepts. These cases are based on the idea that some\nnotions can be defined in terms of others, with the famous\nunderstanding of knowledge as justified true belief being one of the\nmost notable examples. An alternative to this idea is to consider that\nthe involved concepts emerge independently, but are still somehow\nrelated, as the case of the relationship between knowledge and time.\nFrom a formal perspective, this amounts to looking at the different\nmodes in which two (or more) existing systems can be combined.\n Section 3\n on General strategies for combining modal systems presents\nan overview of some of the most relevant strategies. After this\nslightly technical excursion, the discussion takes a philosophical\nperspective, describing first combinations of multiple modalities\n (section 4\n on Significant interactions between modalities), and\nfinishing with examples of cases where the interaction between\nmodalities sheds light on philosophical issues\n (section 5\n on Multi-modal systems in philosophical discussions). \nA note on notation and the level of\ntechnicality To discuss aspects of multi-modal logic, this\nentry assumes basic knowledge of\n modal logic,\n specifically about its language and its relational\n ‘possible worlds’\n semantics (though other semantic models will be mentioned too). In\nparticular, a relational model is understood as a tuple containing a\nset of possible worlds, one or more (typically binary) relations\nbetween them, and a valuation indicating what each possible\nworld actually represents. Such structures can be described by\ndifferent modal languages. We will use \\(\\cL\\) to denote the standard\npropositional language, and \\(\\cL_{\\left\\{ O_1, \\ldots, O_n\n\\right\\}}\\) to denote its extension with modalities \\(O_1\\), …,\n\\(O_n\\). Given a relational model M and a formula \\(\\varphi\\),\nwe will use \\(\\llbracket \\varphi \\rrbracket^{M}\\) to denote the set of\nworlds in M where \\(\\varphi\\) holds. Readers can find more\ndetails about the basics of modal logic not only in the referred SEP\nentries, but also in the initial chapters of Blackburn, Rijke, &\nVenema (2001) and van Benthem (2010), and also in Blackburn & van\nBenthem (2006). \nStill, the goal of this text is not to provide a comprehensive study\nof the topic, but rather to highlight the most interesting and\nintriguing aspects. Thus, although some level of formal discussion\nwill be used, most technical details will be restricted to the\n appendix. \nIn order to use systems with multiple modalities, the question is how\nto build such settings. One of the most important points is to decide\nwhether one of the concepts to be studied is ‘more\nfundamental’ than the other, in the sense that the latter can be\ndefined in terms of the former. As mentioned, the famous understanding\nof knowledge as justified true belief is one of the most notable\nexamples. Others are equally relevant, as a definition of beliefs in\nterms of the available arguments/evidence/justifications, or a\ndefinition of epistemic notions for a group in terms of the epistemic\nnotions of its members. Yet, the basic alethic modal logic of\nnecessity and possibility already provides a paradigmatic example of\nhow to define the relationship between two concepts. \nThe basic alethic modal logic contains both a possibility\n\\((\\Diamond)\\) and a necessity \\((\\Box)\\) modality. Most\nformal presentations of this system take one of these modalities as\nthe primitive syntactic operator (say, \\(\\Diamond)\\), and then define\nthe other as its modal dual \\((\\oBox\\varphi := \\lnot\n\\oDiamond \\lnot \\varphi)\\). This is a seemingly harmless\nsyntactic interdefinability, and comes from the fact that\n\\(\\Diamond\\) and \\(\\Box\\) are semantically interpreted in terms of the\nexistential and universal\n quantifiers,\n respectively. It is, in some sense, similar to\nthe interdefinability of Boolean operators in classic propositional\nlogic. Nevertheless, it already reflects important underlying\nassumptions. From a classic point of view, something is\nnecessary if and only if it is not the case that its negation is\npossible \\((\\oBox\\varphi \\leftrightarrow \\lnot \\oDiamond \\lnot\n\\varphi)\\), and something is possible if and only if it is not the\ncase that its negation is necessary \\((\\oDiamond \\varphi\n\\leftrightarrow \\lnot \\oBox\\lnot \\varphi)\\). However, this may not be\nthe case in all settings. For example, while \\(\\oDiamond \\varphi\n\\rightarrow \\lnot \\Box \\lnot\\varphi\\) is\n intuitionistically acceptable\n (the existence of a possibility where \\(\\varphi\\) holds implies that\nnot every possibility makes \\(\\varphi\\) false), its converse \\(\\lnot\n\\oBox \\lnot\\varphi \\rightarrow \\oDiamond \\varphi\\)\n is not\n (the fact that not every possibility makes \\(\\varphi\\) false is not\nenough to guarantee the existence of a possibility where\n\\(\\varphi\\) is true). Thus, one should always be careful when defining\na modality in terms of another. \nWhere the above examples started from a uni-modal logic, we provide\nnow an example in which we start from a homogeneous multi-modal logic.\nOur setting is a logic consisting of a number of basic modalities of\nthe same type, all being semantically interpreted via the same type of\nrelation. Our example is the basic multi-agent epistemic\nlogic. This setting is already multi-modal, as its language\n\\(\\cL_{\\left\\{ \\oK{1}, \\ldots,\\oK{n} \\right\\}}\\) has a knowledge\nmodality \\(K_i\\) for each agent \\(i \\in \\ttA\\). (In fact, this basic\nmulti-agent epistemic logic is the fusion\n (section 3.1)\n of several single-agent epistemic logic systems, one for each agent\n\\(i \\in \\ttA\\).) Still, when the set of agents is finite (say,\n\\(\\left| \\ttA\\right| = n)\\), one can define a brand new modality for\nthe group epistemic notion of everybody knows: \nIn a similar way we can define a modality for everybody\nbelieves in the logic with language \\(\\cL_{\\left\\{ \\oB{1},\n\\ldots, \\oB{n} \\right\\}}\\) as \nThese definitions assume that the knowledge/beliefs of a group of\nagents corresponds to the conjunction of the agent’s individual\nknowledge/beliefs. However, in the context of\n social epistemology,\n the reduction of group attitudes to the mere sum of those of the\nindividuals is contentious, especially when one focuses on group\n beliefs.[1] \nAnother example of the interdefinability of modal concepts deals with\nthe relationship between knowledge and belief. In\n epistemology,\n researchers are searching for the correct characterization of\nknowledge, and a common trend has been to view knowledge as a form of\n justified true belief\n (an idea that can be traced back to Plato’s dialogue\nTheaetetus). Gettier’s\n famous counterexamples\n showed that such a simple characterization of knowledge is not\nsufficient: a further condition is required, such as safety,\nsensitivity, robustness or stability. In spite of this, a\ncharacterization of knowledge as justified true belief is an important\nfirst step. Classic\n epistemic logic\n does not explicitly deal with the notion of\n justification,[2]\n so a starting point is a simpler understanding of knowledge as true\nbelief. \nOne can take a doxastic relational model with its relation\n\\(R_B\\) being serial, transitive and Euclidean (a KD45\nsetting), and use a modality B semantically interpreted with\nrespect to \\(R_B\\) in the standard way. In this setting, two options\narise. The first one is syntactic, as in the examples that\nhave been discussed so far, and consists in defining a modality for\nknowledge as ‘true belief’: \\(K'\\varphi := B\\varphi\n\\land \\varphi\\). The second is semantic, and consists in\ndefining an epistemic equivalence relation \\(R_K\\) as the reflexive\nand symmetric closure of the doxastic relation, then using it in the\nstandard way to give the semantic interpretation of a modality\nK. \nIt should be noted that the two approaches are not equivalent.\nConsider the following doxastic model (from Halpern, Samet, &\nSegev 2009a), with the serial, transitive and Euclidean\ndoxastic relation \\(R_B\\) represented by dashed arrows, and\nits derived reflexive, transitive and symmetric (i.e., equivalence)\nepistemic relation \\(R_K\\) represented by solid ones. \nFigure 1 [An\n extended description of figure 1\n is in the supplement.] \nNote how the agent believes p on every world in the model,\n\\(\\llbracket \\oB{}p \\rrbracket^{M} = \\left\\{ {w_1, w_2, w_3}\n\\right\\}\\); then, as the syntactic approach states that\n\\({K'\\varphi}\\) holds in those worlds in which \\(B\\varphi \\land\n\\varphi\\) is the case, we have \nHowever, according to the semantic approach, \\(K\\varphi\\) holds in\nthose worlds from which all epistemically accessible situations\nsatisfy \\(\\varphi\\), so \\(\\llbracket K p \\rrbracket^{M} = \\left\\{ w_1\n\\right\\}\\). Thus, \\({K'}\\) and K are not equivalent. One of\nthe reasons for this mismatch is that the two options do not enforce\nthe same properties on the derived notion of knowledge. For example,\nwhile the semantic approach enforces negative introspection (by making\n\\(R_K\\) an equivalence relation), the syntactic one does not. In fact,\nthis property fails at \\(w_3\\), as \\(\\lnot {K'p}\\) is true \\(({B\np} \\land p\\) fails, as p fails) but still\n\\(K'\\lnot{K'p}\\) (unfolded as \\({B (\\lnot {B p} \\lor \\lnot p)}\n\\land (\\lnot B p \\lor \\lnot p))\\) is\n false.[3] \n\n Section 4.1\n comes back on the relationship between these two concepts, recalling\nalternative multi-modal accounts that relate knowledge and belief\nwhile doing justice to the involved epistemological subtleties. \nThe second option in the previous case is, as described, semantic: it\ntakes the semantic counterpart of an existing modality(ies), and then\nextracts from it (them) a further semantic component in terms of which\na new modality can be defined. Here are two further examples of this\nstrategy. \nConsider again the basic multi-agent epistemic logic with language\n\\(\\cL_{\\left\\{ \\oK{1}, \\ldots, \\oK{n} \\right\\}}\\). As mentioned above,\nthis setting is multi-modal, as its language contains, for each agent\n\\(i \\in \\ttA\\), a knowledge modality \\(K_i\\) that is semantically\ninterpreted in the standard way with respect to a matching epistemic\nrelation \\(R_i\\). While a modality for the concept of everybody\nknows (E) is syntactically definable (provided the set of\nagents is finite), other group epistemic notions, such as distributed\nknowledge and common knowledge are\n not.[4] \nConsider first the notion of distributed knowledge,\nunderstood as describing what the agents would know if they shared all\ntheir information. From this intuitive definition, it is clear that\nthis concept can be defined semantically in terms of the agent’s\nindividual epistemic relations. More precisely, a relation describing\nthe distributed knowledge modality should correspond to the\nintersection of the individual epistemic relations, \\(R_D :=\n\\bigcap_{i \\in \\ttA} R_i\\). Thus, given an evaluation point w,\na world u will be considered possible after the agents share\nall they know if and only if all of them considered it possible before\nthe communication (or, in other words, u will be considered\npossible if and only if no one can discard it). One simply\nextends the language with a modality D, semantically\ninterpreted with respect to this new relation: \nAnother important notion, crucial in the study of social interaction,\nis\n common knowledge.\n This concept can be described as what everybody knows, everybody\nknows that everybody knows, everybody knows that everybody knows that\neverybody knows, and so on. Just as with distributed knowledge, this\nnotion does not require the addition of further semantic components:\nthe individual epistemic indistinguishability relations already\nprovide everything that is needed to make the definition explicit. If\none defines an epistemic relation for the “everybody\nknows” modality in the natural way \\((R_E := \\bigcup_{i \\in\n\\ttA} R_i)\\), and then define \\(R_C\\) as the transitive closure of\n\\(R_E\\), \none can simply extend the language with a modality C,\nsemantically interpreted in terms of \\(R_C\\): \nAt world w a formula \\(\\varphi\\) is commonly known among the\nagents if and only if \\(\\varphi\\) is the case in every world\n(the “for all” in C’s semantic\ninterpretation) that can be reached by any finite non-zero\nsequence of transitions in \\(R_E\\) (the fact that \\(R_C\\) is the\ntransitive closure of \\(R_E)\\). In other words, \\(\\varphi\\) is\ncommonly known among the agents if and only if everybody knows\n\\(\\varphi\\) (any sequence of length 1), everybody knows that everybody\nknows \\(\\varphi\\) (any sequence of length 2), and so\n on.[5] \nThere are more elaborated examples of frameworks extending a given\nsetting with modalities that ‘extract’ further information\nfrom the semantic model. One of them is evidence logic,\nintroduced in van Benthem & Pacuit (2011), and further developed\nin van Benthem, Fernández-Duque, & Pacuit (2014) and\nBaltag, Bezhanishvili, et al. (2016). It follows the idea of\nrepresenting the evidence the agent has collected, and looks at how\nthis evidence gives support to further epistemic notions (e.g.,\nknowledge and beliefs).  The semantics is given by a basic\nneighborhood model (Montague 1970; Scott 1970): a tuple of the form\n\\(M = {\\langle W, N, V \\rangle}\\) where W and V are a\nnon-empty set of possible worlds and an atomic valuation, respectively\n(as in standard relational models), and \\(N:W \\to {\\wp(\\wp(W))}\\) is a\nneighborhood function assigning, to every possible world, a set of\nsets of possible worlds (so \\(N(w) \\subseteq {\\wp(W)}\\) is\nw’s neighborhood). In evidence logic, the\nneighborhood function is assumed to be constant (i.e., \\(N(w) = N(u)\\)\nfor any \\(w,u \\in W)\\), and thus the model can be simply understood as\na tuple \\({\\langle W, E, V \\rangle}\\), with \\(E \\subseteq {\\wp(W)}\\)\nthe (constant) neighborhood. This neighborhood, intuitively containing\nthe basic pieces of evidence the agent has collected, is required to\nsatisfy two additional properties: evidence per se is never\ncontradictory \\((\\emptyset \\not\\in E)\\), and the agent knows her\n‘space’ \\((W \\in E)\\). \nSyntactically, a neighborhood model can be described by a modal\nlanguage \\(\\cL_{\\left\\{ \\oBox \\right\\}}\\), as is typically done in\nstandard neighborhood models. There are at least two possibilities for\nthe semantic interpretation of the \\({\\oBox}\\) modality (Areces &\nFigueira 2009), and the one chosen in evidence logic is the\nfollowing: \nThus, in this setting, \\({\\oBox\\varphi}\\) expresses that “the agent has evidence\nsupporting \\(\\varphi\\)”. \nWhat is the epistemic state of the agent that such a model entails? In\nother words, given such a model, how can we define epistemic notions\nsuch as knowledge and belief? \nIn the case of knowledge, one can follow the traditional single-agent\nidea: all worlds in the model play a role in the agent’s\nepistemic state, and thus one can say that the agent knows a\ngiven formula \\(\\varphi\\) if and only if \\(\\varphi\\) is true in every\nworld of the model. For this, evidence logic uses a global\nmodality A: \nIn the case of beliefs, there are more alternatives. A straightforward\nidea says that the agent believes \\(\\varphi\\) if and only if she has\nevidence supporting \\(\\varphi\\) (a syntactic definition of the form\n\\(B\\varphi := \\oBox\\varphi)\\). However, this would allow the agent to\nhave contradictory beliefs, as two pieces of evidence might contradict\nthemselves (there may be \\(X, Y \\in E\\) such that \\(X \\cap Y =\n\\emptyset\\), and thus \\(Bp \\land B{\\lnot p}\\) could be satisfiable).\nMore importantly, this would be a ‘lazy’ approach, as the\nagent would be able to collect evidence (thus defining E), but\nnevertheless she would not be doing any ‘reasoning’ with\nit. \nA more interesting idea is to define (semantically) a notion of belief\nin terms of combinations of pieces of evidence. In van\nBenthem and Pacuit (2011), the authors propose (roughly speaking) that\nbeliefs should be given by the maximal consistent ways in\nwhich evidence can be combined, stating that the agent believes\n\\(\\varphi\\) if and only if all maximally consistent\ncombination of pieces of evidence support \\(\\varphi\\). More\nprecisely, \nGiven these definitions, it is clear that knowledge implies both\nbelief and evidence (i.e., both \\(A\\varphi \\rightarrow B\\varphi\\) and\n\\(A\\varphi \\rightarrow \\oBox\\varphi\\) are valid). Still, it is\ninteresting to note not only that the agent might believe a given\n\\(\\varphi\\) without having a basic piece of evidence supporting it\n\\((B \\varphi \\rightarrow \\oBox\\varphi\\) is NOT valid, as\nbeliefs are defined in terms of combined pieces of evidence),\nbut also that she might have a basic piece of evidence supporting\n\\(\\varphi\\) without believing \\(\\varphi\\) \\((\\oBox\\varphi \\rightarrow\nB\\varphi\\) is NOT valid, as the basic evidence supporting\n\\(\\varphi\\) not be part of all maximally consistent combinations). \nIn this setting, at least when E is finite (and in many other\ncases), beliefs are consistent (i.e., \\(\\neg B \\bot)\\); still, the\nsetting also allows ‘bad’ models in which beliefs can turn\nout to be inconsistent. In Baltag, Bezhanishvili, et al. (2016), the\nauthors provide an example of such a model, and then solve the problem\nby extending the setting to a topological approach. Indeed, the\nauthors use the topology generated by E, which\nintuitively describes the different ways in which the available pieces\nof evidence can be\n combined.[6]\n This is reasonable as, while E can be understood as containing\nthe pieces of evidence the agent has received from external sources\n(observations, communication), the topology \\(\\tau_{E}\\) can be\nunderstood as the different ways in which she can\n‘extract’ further information from them (i.e., the result\nof her own reasoning processes). Given the topology, it is possible to\ndefine (semantically) further epistemic notions, such as arguments,\njustifications, consistent beliefs, consistent conditional beliefs,\nand different forms of knowledge. For more on this, we refer to\nBaltag, Bezhanishvili, et al. (2016: Section 2). \nAs we have seen, a new modality can be introduced in syntactic terms\n(using the language to provide a formula defining the new concept),\nbut also in a semantic way (using the semantic counterparts of the\nexisting modalities to define a further semantic notion, which in turn\nis used to interpret the new modality). Our examples so far have been\nrestricted to the use of one of these two strategies, but their\ninterplay is also possible. The case to be discussed here concerns the\n plausibility models\n of Board (2004); Baltag and Smets (2006, 2008); van Benthem (2007);\nhere, the presentation of Baltag and Smets (2008) is used. \nA plausibility model is a relational model \\(M = {\\langle W, \\leq, V\n\\rangle}\\) in which the binary relation \\(\\leq\\) is interpreted as\ndescribing the plausibility ordering the agent assigns to her\nepistemic possibilities \\((w \\leq u\\) indicates that, for the agent,\nworld w is at least as plausible as world u). In the\nsingle-agent case, the plausibility relation \\(\\leq\\) is\nrequired to be a well-preorder: a total relation which is\nboth reflexive and transitive, and such that every non-empty subset of the\ndomain has \\(\\leq\\)-minimal elements. These minimal elements in W are\nthen understood as the agent’s most plausible worlds.\nWe see below that what is true in all the most plausible worlds\ncharacterizes what an agent believes. \nTo start, take a modality \\([\\leq]\\) semantically interpreted via the\nplausibility relation \\(\\leq\\), \nThis modality has the properties of an S4 modal operator; hence, it is\nfactive, positively introspective but not negatively introspective. In\nBaltag and Smets (2008), it is argued that this modality is well\nsuited to express a version of Lehrer’s indefeasible\n(“weak”, non-negatively-introspective) type of\nknowledge (Lehrer 1990; Lehrer & Paxson 1969), and the\nauthors explain how it can be understood as belief that is persistent\nunder revision with any true piece of information. Using this\nmodality (also read as safe belief in Baltag & Smets\n2008), it is possible to define syntactically a notion of simple\nbelief as truth in the most plausible worlds:  \nAs simple as a plausibility model is, it is powerful enough to encode\na wide range of different epistemic concepts, all of which can be\nbrought to light by the proper semantic definitions. First, we define\na relation of epistemic possibility (or indistinguishability)\n\\(\\sim\\) by taking it to be the universal relation, \nthus understanding that two worlds are epistemically indistinguishable\nif and only if they can be compared via\n \\(\\leq\\).[7]\n Then, a notion of S5-knowledge can be expressed by introducing a\nmodality K semantically interpreted via \\(\\sim\\): \nWith this new modality K it is possible to define,\nsyntactically, the finer notion of conditional belief\n\\(B^{\\psi}\\), intuitively describing what the agent would have\nbelieved was true had she learnt that a certain condition \\(\\psi\\) is\nthe case. Indeed, \nfor \\({\\hK}\\) the modal dual of K (i.e., \\(\\hK\\psi := \\lnot\nK\\lnot \\psi)\\). This extended language \\(\\cL_{\\left\\{ [{\\leq}], K\n\\right\\}}\\) can also express a notion of strong belief, \\(Sb\n\\varphi\\), semantically understood as true whenever all\n\\(\\varphi\\)-worlds are strictly more plausible than all\n\\(\\lnot\\varphi\\)-worlds, and syntactically defined as  \nFinally, note how a plausibility relation defines, semantically,\nlayers or spheres of equally-plausible worlds, with the spheres\nthemselves ordered according to their plausibility so that every\nstrong belief characterizes one of the spheres. This will turn every\nplausibility model into a sphere model (Grove 1988; Spohn 1988),\nmaking it perfectly fit to model\n belief revision.\n Still, even though in \\(\\cL_{\\left\\{ [{\\leq}], K \\right\\}}\\) there\nare formulas expressing that \\(\\varphi\\) holds in the most\nplausible sphere (the mentioned \\(B\\varphi\\), given by\n\\(\\langle{\\leq}\\rangle[{\\leq}]\\varphi)\\), no formula can express,\ne.g., that \\(\\varphi\\) holds in the next to most plausible\nworlds. One way to fix this ‘problem’ is to define (now\nsemantically) the strict plausibility relation \\({<} :=\n{\\leq} \\cup {\\not\\geq}\\) (with \\(\\geq\\) the converse of\n\\(\\leq\\), defined in the standard way, \\({\\geq} := \\left\\{ (u,w) \\in W\n\\times W \\mid w \\leq u \\right\\})\\), and then introduce a standard\nmodality for it: \nWith this new modality, one can provide syntactic definitions for the\nconcepts described above. Indeed, while the formula \\(\\lambda_0 :=\n[<]\\bot\\) characterizes the most plausible worlds (so \\(K\n(\\lambda_0 \\rightarrow\\varphi)\\) expresses that the most plausible\nworlds satisfy \\(\\varphi\\), just as \\(B\\varphi\\) does), the formula\n\\(\\lambda_1 := \\lnot \\lambda_0 \\land [<]\\lambda_0\\) characterizes\nthe next to most plausible worlds (so \\(K(\\lambda_1\n\\rightarrow\\varphi)\\) expresses that the next to most plausible worlds\nsatisfy \\(\\varphi)\\). This procedure can be repeated, producing\nformulas \\(\\lambda_i\\) characterizing each layer, and thus it is\npossible to deal syntactically with a qualitative degree of\nbeliefs (Grove 1988; Spohn 1988), looking for what holds\n‘from some level up’ (see also Velázquez-Quesada\n2017). \nThis new modality \\([<]\\) allows us to define even more\nepistemic notions. For example, a formula \\(\\varphi\\) is weakly\nsafely believed (a belief which might be lost but is never\nreversed when revising with true information) if and only if \\(\\varphi\n\\land [{<}] \\varphi\\) holds. More details can be found in Baltag\nand Smets (2008: Subsection 2.4). \nJust as some multi-modal systems are created by extending existing\nones, some others are born with multiple modalities in mind. Among\nthem,\n propositional dynamic logic\n (Harel, Kozen, & Tiuryn 2000) and Boolean modal logic\n(Gargov & Passy 1990; Gargov, Passy, & Tinchev 1987) deserve a\nspecial mention. The reason is that they both define, within the\nlanguage, operators for building new modalities from a collection of\nbasic ones. As a consequence, both systems contain an\ninfinite number of modalities. \nFollowing earlier approaches to reason about programs in Engeler\n(1967) and Hoare (1969), Propositional dynamic logic (PDL), the logic of\nprograms (Harel, Kozen, & Tiuryn 2000), intends to describe what\nprograms can achieve. Semantically, programs are interpreted in\nstandard relational models, with one binary relation \\(R_a\\) for every\nbasic program a; syntactically, the language contains\na modality \\([a]\\) for each such a. \nSo far, PDL is technically similar to a multi-agent epistemic\nlogic (the difference being, besides the symbols used for the\nmodalities, the fact that there are no restrictions on the relations\nfor the basic\n programs).[8]\n The crucial insight is, however, that basic programs can be\ncomposed in order to create more complex ones: one can think\nof executing one program after another, or repeating some of them a\nnumber of times. Thus, these basic modalities are not enough. For\nthis, a new syntactic entity is created: besides formulas, the\nlanguage of PDL contains a set of basic programs\ntogether with program constructors representing those for\nregular expressions (Kleene 1956). Formally, formulas\n\\(\\varphi\\) and programs \\(\\alpha\\) of the\nPDL-language \\(\\cL_{\\textit{PDL}}\\) are defined\nsimultaneously via mutual recursion as \nwith p an atomic proposition coming from a given set, and\na a basic program coming from a given set. For formulas, the\nintended reading of the Boolean operators is standard, and formulas of\nthe form \\([\\alpha]\\varphi\\) express that “every execution\nof program \\(\\alpha\\) from the current state leads to a state\nsatisfying \\(\\varphi\\)”. For programs, while the basic\nprograms simply represent themselves, “\\(\\varphi \\qbin\\)”\nis a program that ‘does nothing’ when \\(\\varphi\\) is the\ncase but ‘fails’ otherwise (essentially, a test\nfor \\(\\varphi)\\), “\\(\\alpha \\scbin \\beta\\)” represents the\nprogram that results from executing \\(\\alpha\\) and then executing\n\\(\\beta\\) (their sequential composition), “\\(\\alpha\n\\bcup \\beta\\)” represents the program that results from\nexecuting either \\(\\alpha\\) or else \\(\\beta\\) (their\nnon-deterministic choice), and\n“\\({\\alpha^{\\ast}}\\)” represents the program that results\nfrom repeating \\(\\alpha\\) a finite number of times \\((\\alpha\\)’s\niteration). \nWith these program constructors it is possible to build more complex\nprograms. Famous examples are \nThen, it is possible to build formulas as \\(p \\rightarrow [(q \\qbin\n\\scbin a) \\bcup (\\lnot q \\qbin \\scbin b)]r\\) (“if p\nholds, then r will be achieved by choosing between actions\na and b according to whether q holds”)\nand \\(\\lnot p \\rightarrow \\langle a \\scbin (\\lnot q \\qbin \\scbin\na)^{\\ast} \\scbin q \\qbin \\rangle p\\) (“if the desired\nrequirement p is not true yet, it is possible to achieve it by\na repeated execution of a”). \nFor the semantic interpretation, a relation \\(R_\\alpha\\) is required\nfor each program \\(\\alpha\\). However, while the relations \\(R_a\\) for\nbasic programs are arbitrary, those for complex programs should behave\naccording to their intended meaning. The simplest way to obtain this\nis to take the relations for the basic programs, and then\ndefine those for complex programs in an inductive way. This\nand further details about PDL can be found in Troquard and\nBalbiani (2019:\n [Section 2). \nThe Boolean modal logic of Gargov and Passy 1990 and Gargov,\nPassy, and Tinchev 1987) follows a similar strategy. The difference is\nthat, while PDL focuses on constructors for regular\nexpressions (sequential composition, non-deterministic choice, finite\niteration), Boolean modal logic focuses on constructors for the\nBoolean algebra over relations: complement \\((\\bdash)\\), union\n\\((\\bcup)\\) and intersection \\((\\bcap)\\), together with a\n‘global’ constant \\((\\boldsymbol{1})\\). More\nprecisely, \nThe semantic interpretation follows the same steps as in PDL:\nrelations \\(R_a\\) for the basic modalities a are assumed, and\nrelations for complex ones are defined in the expected way (with\n\\({\\boldsymbol{1}}\\) being interpreted with respect to the global\nrelation \\(W \\times W)\\). \nInterestingly, by combining the negation over formulas and the Boolean\ncomplement over relations, it is possible to define the following\noperator (often called window (see Goldblatt 1974; van\nBenthem 1979; Gargov, Passy, & Tinchev 1987): \nWindow is an extremely natural operator that complements the standard\nuniversal modality. Indeed, while formulas of the form\n\\([\\alpha]\\varphi\\) express that all executions of \\(\\alpha\\)\nreach a \\(\\varphi\\)-state, \nformulas of the form \\(\\oubracket{.7em}{\\alpha}\\varphi\\) express that\nall \\(\\varphi\\)-states are reachable by an execution of\n\\(\\alpha\\): \nNot only that: window allows a smooth interaction between the\nconstructors \\(\\bcup\\) and \\(\\bcap\\). As discussed in Blackburn,\nRijke, and Venema (2001: 427),  \n[i]n a sense, the relations are divided into two kingdoms: the\nordinary \\([\\alpha]\\) modalities govern relations built with\n\\(\\bcup\\), the window modalities \\(\\oubracket{.7em}{\\alpha}\\) govern\nthe relations built with \\(\\bcap\\), and the \\(\\bdash\\) constructor\nacts as a bridge between the two realms: \nOf course, many other program constructors can be used. Among them,\none worthy of mention is that for the\n converse\n of a given relation. Modalities for the converse of a relation have\nbeen used in, e.g.,\n tense logic,\n with the ‘past’ modalities (H and P, the universal and existential versions, respectively) interpreted semantically in terms of the converse of the relation used for interpreting the ‘future’ modalities (G and F, respectively). \nThe case of dynamic epistemic logic, the study of modal\nlogics of model change, is of particular interest. In these systems,\nthe relationship between their modalities is special. Here we will\nonly recall the basic notions, referring the reader to the\n SEP entry\n by Baltag and Renne (2016) for an in-depth discussion \nIn a nutshell, a dynamic epistemic logic (DEL)\nframework has two components. The ‘static’ part consists\nof a ‘standard’ modal system: a language including one or\nmore modalities for the one or more concepts under study, together\nwith the semantic model on which the formulas are interpreted. The\n‘dynamic’ part consists of modalities expressing different\nways in which the studied concept(s) might change, with the crucial\ninsight being that these modalities are semantically interpreted not\non the given model, but rather on one that results from\ntransforming the given one in an appropriate way. \nThe discussion here will focus on the paradigmatic DEL case,\n public announcement logic\n (PAL), which studies the interaction of knowledge and public\n communication.[9]\n Syntactically, its language extends the basic epistemic language\n\\(\\cL_{\\left\\{ K \\right\\}}\\) with a modality \\([\\chi{!}]\\) (for\n\\(\\chi\\) a formula of the language), thanks to which it is possible to\nbuild formulas of the form \\([\\chi{!}]\\varphi\\): “after\n\\(\\chi\\) is publicly announced, \\(\\varphi\\) will be the\ncase”. Within this new language \\(\\cL_{\\left\\{ K, {!}\n\\right\\}}\\) it is possible to build formulas describing the\nknowledge the agent will have after a public communication\naction; one example is \\([(p \\land q){!}] Kq\\), expressing that\n“after \\(p \\land q\\) is publicly announced, the agent will\nknow q”. For the semantic interpretation, the public\nannouncement of any given \\(\\chi\\) is taken to be completely\ntrustworthy; thus, the agent reacts to it by eliminating all\n\\(\\lnot\\chi\\) possibilities from consideration. More precisely, given\na model \\(M = {\\langle W, R, V \\rangle}\\) and a formula \\(\\chi \\in\n\\cL_{\\left\\{ K, {!} \\right\\}}\\), the model \\(M_{\\chi{!}} = \\langle\nW_{\\chi{!}}, R_{\\chi{!}}, V_{\\chi{!}} \\rangle\\) is defined as \nNote how, while \\(W_{\\chi{!}}\\) is the set of worlds of the original model\nwhere \\(\\chi\\) holds, \\(R_{\\chi{!}}\\) is the restriction of the\noriginal epistemic relation to the new domain, and so is the new\nvaluation function \\(V_{\\chi{!}}\\). Then, \nThus, \\(\\varphi\\) is the case after \\(\\chi\\) is publicly announced at\nw in M (in symbols, \\((M, w) \\Vdash [\\chi{!}]\\varphi)\\)\nif and only if \\(\\varphi\\) is true at w in the situation that\nresults from \\(\\chi\\)’s announcement (in symbols,\n\\((M_{\\chi{!}}, w) \\Vdash \\varphi)\\) whenever \\(\\chi\\) can actually be\nannounced (in symbols, \\((M, w) \\Vdash\n \\chi)\\).[10]\n Note that the public announcement modality \\([\\chi{!}]\\) is\nintroduced semantically, as its semantic interpretation\nrequires ‘extracting’ further information from the initial\nmodel, just as the intersection of individual epistemic relations is\nused to create the relation for distributed knowledge. Still, it uses\na ‘more advanced’ version of such a strategy: it performs\nan operation over the full model, thus creating a new one in\norder to evaluate formulas that fall inside the scope of the new\nmodality. \nWith the semantic interpretation of \\([\\chi{!}]\\) given, it is now\npossible to answer the crucial question in this setting: what is the\neffect of a public announcement on an agent’s knowledge? Or,\nmore precisely, how is the agent’s knowledge after an\nannouncement related to her knowledge before it? Here is the\nanswer: \nThis validity characterizes the agent’s knowledge after the\naction in terms of the knowledge she had, before the action, about\nthe effects of the action. It tells us that after the public\nannouncement of \\(\\chi\\) the agent will know \\(\\varphi\\),\n\\([\\chi{!}]K\\varphi\\), if and only if, provided \\(\\chi\\) could be\nannounced, ‘\\(\\chi \\rightarrow \\)’, she knew that its\ntruthful public announcement would make \\(\\varphi\\) true, \\(K(\\chi\n\\rightarrow [\\chi{!}]\\varphi)\\). Note how this bridge\nprinciple, relating the two involved modalities, is not\n‘chosen’: it arises as a consequence of the given\ndefinition of what knowledge is (truth in all epistemic possibilities)\nand the given understanding of what a public announcement does\n(discard all possibilities where the announcement fails). \nThe given semantic interpretation of \\([\\chi{!}]\\) also gives rise to\nother validities. Among them, consider the following: \nThese validities, together with the previous one characterizing\n\\([\\chi{!}]K\\varphi\\), are known as the reduction axioms.\nHere is our first twist: a careful look at these formulas reveals that\neach one of them characterizes the truth of an announcement formula\n\\([\\chi{!}]\\varphi\\) (the left-hand side of \\(\\leftrightarrow\\)) in terms of formulas (the right-hand side of \\(\\leftrightarrow\\)) whose sub-formulas appearing under the scope of \\([\\chi{!}]\\) are less complex. Moreover: the formula dealing with atoms eliminates \\([\\chi{!}]\\). Thus, given any concrete formula in \\(\\cL_{\\left\\{ K, {!}\n\\right\\}}\\), successive applications of these axioms will eventually\nproduce a semantically equivalent formula where no\n\\([\\chi{!}]\\) modality appears. This indicates that,\nexpressivity-wise, the public announcement modalities\n\\([\\chi{!}]\\) are not really needed: anything that can be expressed\nwith them can be also expressed by a formula without them. More\nprecisely, for any formula \\(\\varphi\\) in \\(\\cL_{\\left\\{ K, {!}\n\\right\\}}\\), there is a formula\n\\({\\operatorname{tr}(\\varphi)}\\) in \\(\\cL_{\\left\\{ K \\right\\}}\\) such\nthat, for any \\((M, w)\\), \nThis truth-preserving translation, whose precise definition\ncan be found in van Ditmarsch, van der Hoek, and Kooi (2008: Section\n7.4), shows that the public announcement modality can also be seen as\nhaving a syntactic definition: any formula involving\n\\([\\chi{!}]\\) can be rewritten within \\(\\cL_{\\left\\{ K\n \\right\\}}\\).[11]\n Nevertheless, this is not a ‘one line’ translation, as it\nis the case, e.g., for the ‘everybody knows’ modality\nE. The translation is given by a recursive approach,\nwith the modality defined in a different way depending on the formula\none needs to place under its scope. This leads us to the second twist:\nbecause of this recursive definition, even though adding \\([\\chi{!}]\\)\ndoes not increases the language’s expressivity, its addition\ndoes change the properties of the logical system. Indeed, in\n\\(\\cL_{\\left\\{ K, {!} \\right\\}}\\), the rule of uniform\nsubstitution of atomic propositions by arbitrary formulas is not\nvalidity-preserving anymore. Consider the following formula, stating\nthat “after the public announcement of p, the agent\nwill know that p is the case”: \n\n\\[\n\\Vdash [p{!}]Kp.\n\\]\n\n The\nformula is valid: a truthful public announcement of p discards\nworlds from the original model M where p was not the\ncase. Hence, the resulting \\(M_{p{!}}\\) will have only worlds\nsatisfying p, thus making \\(Kp\\) true Now consider the\nformula below, which results from substituting p by \\(p \\land\n\\lnot Kp\\) in the previous validity: \n\n\\[\n[(p \\land \\lnot Kp){!}] K(p \\land \\lnot Kp).\n\\]\n\n The above formula\nstates now that  \nafter the public announcement of “p is true and the\nagent does not know it”, she will know that “p is\ntrue and she does not know it”.  \nThis formula can be equivalently stated (by distributing K over \\(\\land\\) in the sub-formula under the scope of \\([(p \\land \\lnot Kp){!}]\\)) as \nafter the public announcement of “p is true and you\ndo not know it”, the agent will know both that p is true\nand that she does not know it.  \nBut now something is odd: after hearing \\(p \\land \\lnot Kp\\), the\nagent surely should know that p is the case \\((Kp)\\). But then,\nhow is it possible that, at the same time, she knows that she does not\nknow it \\((K\\lnot Kp)\\)? \nThe suspicions are correct: the formula is not valid, and the model\nbelow on the left provides a counter-example. \nFigure 2 [An\n extended description of figure 2\n is in the supplement.] \nIn \\((M, w)\\), the atomic proposition p is the case, but the\nagent does not know it: \\((M, w) \\Vdash p \\land \\lnot Kp\\). Thus, \\(p\n\\land \\lnot Kp\\) can be truthfully announced, which produces the\npointed model \\((M_{(p \\land \\lnot Kp){!}}, w)\\) on the right. Note\nhow w has survived the operation (it satisfies \\(p \\land \\lnot\nKp)\\), but u has not (it does not satisfy \\(p \\land \\lnot Kp\\),\nas it makes p false). In the resulting pointed model, the agent\nindeed knows that p is the case: \\((M_{(p \\land \\lnot Kp){!}},\nw) \\Vdash Kp\\). Nevertheless, she does not know that she does not know\np: \\((M_{(p \\land \\lnot Kp){!}}, w) \\not\\Vdash K\\lnot Kp\\); in\nfact, she knows that she knows p: \\((M_{(p \\land \\lnot Kp){!}},\nw) \\Vdash\n KKp\\).[12] \nRecapitulating, dynamic epistemic logics deal with modal operators for\nmodel operations, thus allowing the explicit representation of actions\nand the way they affect the concept under study. The particular\nrelationship between the ‘static’ concept and the\n‘dynamic’ action can be described by bridge principles\nthat arise naturally, and yet this does not come with an additional\ncost, as the model-operation and dynamic-modality machinery can be\nembedded into the static base logic. This has important repercussions,\nparticularly complexity-wise, as will be discussed in\n section 3.4. \nThe previous section focused on some of the ways one can take a system\nwith a single modality and create a system with multiple modalities\nfrom it. Another alternative to build a multi-modal system is to take\nexisting uni-modal systems, and then put them together by using a\nparticular strategy. This section contains a brief description of some\nof the possible techniques; for a deeper discussion, the reader is\nreferred to the SEP entry on\n combining logics\n by Carnielli and Coniglio (2016). \nThe method of\n fusion\n of modal logics (introduced in Thomason 1984) was developed\nwith the idea of combining relation-based (hence\nnormal) modal logics in both a syntactic way (by putting\ntogether their respective Hilbert-style axiom systems) and a semantic\nway (by taking the relations corresponding to the modality of each\nsystem, and putting them together in a single\n model).[13]\n Although the fusion of modal systems is fairly simple, the\ntransference results that guarantee that properties are\npreserved (e.g., whether the combination of the sound and complete\naxiomatization of the existing systems is indeed sound and complete\nfor the resulting one) are not straightforward (see, e.g., Kracht\n& Wolter 1991, 1997; Fine & Schurz 1996; Schurz 2011). \nWhen this strategy is followed, and leaving technical details aside,\nthe most important decision is the possible introduction of\nbridge principles that link the main modalities of the\nsystems to be combined. Paraphrasing Schurz (1991), a schema\n\\(\\varphi\\) is a bridge principle if and only if it contains\nat least one schematic letter which has at least one occurrence within\nthe scope of the modality of one system and at least one occurrence\nwithin the scope of the modality of the other. (This definition was\ngiven in the context of the David Hume’s discussion on whether\nought can be derived from is; see\n Section 1\n of\n combining logics.) \nIn order to provide a better explanation of this technique, here we\nwill discuss the construction of a simple temporal epistemic logic. On\nthe epistemic side, recall that the basic\n epistemic logic\n system is given, syntactically, by the language \\(\\cL_{\\left\\{ K\n\\right\\}}\\), and semantically, by a relational model. In it, the\nmodality K is semantically interpreted in terms of a binary\nrelation \\(R_K\\). On the temporal side, define the\n‘future’ fragment of the basic\n temporal (tense) logic\n as a system which is syntactically specified by the language\n\\(\\cL_{\\left\\{ G \\right\\}}\\) (with G a universal\nquantification on the future, and F its existential\ncounterpart given by \\(F\\varphi := \\lnot G\\lnot \\varphi)\\), and\nsemantically, by a relational model with \\(R_G\\) as the crucial\nrelation. \nThe fusion of these systems is syntactically specified by the\nlanguage \\(\\cL_{\\left\\{ K, G \\right\\}}\\) (i.e., a language freely\ngenerated by the union of the modalities of \\(\\cL_{\\left\\{ K\n\\right\\}}\\) and \\(\\cL_{\\left\\{ G \\right\\}})\\). Formulas of this\nlanguage are semantically interpreted in relational models of\nthe form \\({\\langle W, R_K, R_G, V \\rangle}\\) such that \\({\\langle W,\nR_K, V \\rangle}\\) is a model for \\(\\cL_{\\left\\{ K \\right\\}}\\) and\n\\({\\langle W, R_G, V \\rangle}\\) is a model for \\(\\cL_{\\left\\{ G\n\\right\\}}\\). For the semantic interpretation, formulas of the new\nlanguage are interpreted in the standard way, with each modality using\nits correspondent relation. With respect to axiom systems, it is\nenough to put together those of the individual logics. \nBut we are not done yet. As mentioned before, the most interesting\npart is the possible inclusion of bridge principles. So, which is the\nproper interaction between\n time and knowledge?\n One might require perfect recall: the agent’s\nknowledge is not decreased over time or, in other words, uncertainty\nat any moment should have been ‘inherited’ from\nuncertainty from the past. This corresponds to the following bridge\nprinciple: \nThis is clearly an idealization, and as such it makes sense only under\ncertain interpretations; still, it might imply more than meets the\neye. Assuming that the agent never forgets the truth-value of an\natomic proposition p might be reasonable; but, what if\n\\(\\varphi\\) is a more complex formula, in particular one involving the\nepistemic modality? For example, take the formula \\(\\lnot Kp \\land\n\\lnot K\\lnot p\\) (“the agent does not know whether\np”), yielding the instance \\(K(\\lnot Kp \\land \\lnot\nK\\lnot p) \\rightarrow GK(\\lnot Kp \\land \\lnot K\\lnot p)\\)\n(“if the agent knows of her ignorance about whether\np, then she will always know about such ignorance”).\nIs this within the expected consequences? \nA related property is that of no learning (the agent’s\nknowledge is not increased over time; in other words, any current\nuncertainty will be preserved). This property corresponds to \nA slight elaboration on these and related properties can be found on\nthe discussion on time and knowledge\n (section 4.2;\n for a deeper study, see Halpern & Vardi 1989; van Benthem &\nPacuit 2006, albeit in a different semantic setting). \nThe fusion method provides a simple yet powerful strategy for adding a\nfurther aspect to an existing modal system by using another already\nexisting system dealing with this further aspect independently.\nIndeed, the discussed example can be seen as adding a\ntemporal aspect to the standard study of the properties of\nknowledge. Besides the traditional epistemic questions (e.g., whether\nknowledge should be positively/negatively introspective), one can also\ndiscuss not only whether knowledge should change, but also the\ndifferent ways in which it might so. \nThis idea of adding a temporal aspect makes sense not only for\nknowledge, but also for other modal concepts. For example, one can\nthink of adding a temporal feature to a modal system for preferences,\nthus discussing different ways in which the preferences of an agent\nmight change over time (and also why they do so, if further\ndynamic machinery is added to talk about actions and\ntheir consequences; Grüne-Yanoff & Hansson 2009; Liu 2011).\nSimilarly, adding a temporal aspect to modal systems of\n deontic logic\n raises interesting concepts and questions, an example being the\nnotion of deontic deadlines, discussed in\n section 4.7 on\n obligations and time. \nThe study of some concepts such as preferences or obligations gives\nraise to an epistemic concern: how much do the involved agents\nknow about such preferences and obligations? In most examples\nwhere such concepts play a role, whether or not the agent knows about\nthe involved preferences or obligations makes an important difference.\nIn case of the first, should an agent act according to her and other\nagents’ preferences, even when she does not know what these\npreferences are? In case of the second, is an agent compelled to obey\na duty even when she does not know what the duty is? \nThe fusion of a basic preference/deontic setting and epistemic logic\nprovides basic formal tools to discuss the epistemic aspects of\npreferences and obligations. For example, consider the\n paradox of epistemic obligation:\n a bank is being robbed (r), and the guards ought to know about\nthe robbery \\((OKr)\\). But knowledge is factive \\((Kr \\rightarrow\nr)\\), so then the bank ought to be robbed \\((Or)\\)! More on these\nconcerns (under different formal systems) can be found within the\ndiscussion on knowledge and obligations\n (section 4.8). \nFor a deeper study on the fusion of modal logics, the reader is\nreferred to Wolter (1998), Gabbay, Kurucz, Wolter, and Zakharyaschev\n(2003: Chapter 4), and Kurucz (2006: Section 2). Further examples of\nfusion can be found\n in the SEP entry\n discussing methods for\n combining logics.\n Still, before closing this subsection, we add a word of caution. One\nneeds to be careful when building the fusion of modal systems. This is\nbecause, in the system that results from the fusion, there are already\nformulas combining the modalities of its different fragments. Then,\neven if no particular bridge (valid) principles are enforced, the\nlanguage might gain in expressive power, which might increase\nits\n complexity\n profile.\n Section 3.4\n on complexity issues elaborates on this important but often forgotten\naspect. \nThe fusion of modal systems produces a rich language that allows us to\nexpress the different ways in which the involved modalities interact\n(the bridge principles). Still, from a semantic perspective, there is\nstill just one point of reference, as all formulas of this\nricher language are still evaluated on a single possible world. \nThe strategy of defining a\n product\n of modal logics (introduced in Segerberg 1973 and Šehtman\n1978) shares the idea of using a language that is freely generated by\nthe union of the modalities of the original languages. But, on the\nsemantic side, the approach is quite different: instead of working on\na one-dimension domain, it works on a multi-dimensional\ndomain that has one dimension for each one of the involved aspects\n(i.e., modalities). More precisely, if the semantic models of the\nto-be-combined systems are \\(M_1 = {\\langle W_1, R_1, V_1 \\rangle}\\)\nand \\(M_2 = {\\langle W_2, R_2, V_2 \\rangle}\\), the models where\nformulas of the resulting language are evaluated are now of the form\n\\(M' = {\\langle W_1 \\times W_2, R'_1, R'_2, V_1 \\times V_2\n\\rangle}\\). The domain \\(W_1 \\times W_2\\) is, then, the standard\nCartesian product of the original domains, and the valuation \\(V_1\n\\times V_2\\) is such than an atom p is true in a world \\((w_1,\nw_2)\\) if and only if p was true at \\(w_1\\) in \\(M_1\\) and also\ntrue at \\(w_2\\) in \\(M_2\\) (i.e., \\((V_1 \\times V_2)(p) := V_1(p)\n\\times V_2(p))\\). For the relations, each one of them is given as in\ntheir original models, restricted now to their respective dimensions:\n \nThe product of modal logics is a many-dimensional modal logic\n(Gabbay et al. 2003; Marx & Venema 1997; Venema 1992). Within\nthese models, formulas are now evaluated in pairs \\((w_1, w_2)\\), with\neach modality semantically interpreted in the standard way (but now\nwith respect the new version of its matching relation): \nThis specific way of interpreting each one of the original modalities\nyields another crucial difference between the fusion and the product\nof modal systems: the latter enforces, by its own nature, certain\nbridge principles (on top of those that might be added). Indeed,\nbecause of the definition of the relations and the modalities’\nsemantic interpretation, the following schemas are valid: \nThe product of modal systems, with its n-dimensional nature, is\na very useful tool and, in particular, it has been of help for dealing\nwith the philosophical semantics technique of\n two-dimensionalism\n (see also Chalmers 2006; Stalnaker 1978). This technique has been\napplied in different fields. In linguistics, it is the basis of David\nKaplan’s semantic framework for\n indexicals\n (Kaplan 1989), which in turn has been used to explain conventional\nsemantic rules governing context-dependent expressions as\n‘I’ and ‘now’. Consider, for\nexample, a setting built to talk about the features of a group of\nfriends at different times; the context in which formulas will be\nevaluated can be defined as a tuple \\((w, a, m)\\), with \\(w \\in W\\) a\npossible world, \\(a \\in \\ttA\\) an agent within that world and \\(m \\in\nT\\) a moment in time when the agent exists in that world. Then, a\nsentence of the form “I am tired now” corresponds\nsimply to an atom “tired”, with its truth-value\nbeing potentially different in different contexts, depending on\nwhether, in the given world w, the given agent a is\ntired at the given moment m. Moreover: suppose the setting contains an alethic possibility relation between worlds \\((R \\subseteq W \\times\nW)\\), a friendship relation between agents \\(({\\asymp}\n\\subseteq \\ttA\\times \\ttA)\\) and a temporal future relation\nbetween moments \\((R_G \\subseteq T \\times T)\\). Then, one can use matching modalities (the universal ones, \\(\\oBox\\) and \\([\\asymp]\\), for the first two; the existential one \\({F}\\) for the third) to express sentences as “I have a friend who is playing right now and necessarily will be tired at some moment later” \\((\\langle \\asymp\\rangle(\\textit{playing} \\land\n\\oBox F\\textit{ tired}))\\) and “if one of my friends is\nplaying now, all of them might be playing later”\n\\((\\langle\\asymp\\rangle \\textit{playing} \\rightarrow \\Diamond\nF[\\asymp]\\textit{playing})\\). \nIn philosophy of mind, two-dimensional semantics has been used by\nDavid Chalmers (combining both epistemic and modal domains) to provide\narguments against materialism in philosophy of mind (details\ncan be found in Chalmers 2009). \nA final example of the product of two modal logics (though not\noriginally conceived as such, and presented in a slightly different\nway), is the Facebook Logic of Seligman, Liu, & Girard\n(2011, 2013), useful for talking about friends and social information\nflow. The setting can be seen as the combination of a standard\nsingle-agent epistemic logic and a modal logic for social networks\n(cf. Baltag, Christoff, Rendsvig, & Smets 2019; Smets &\nVelázquez-Quesada 2017). Its semantic model consists on two\ndomains (possible worlds W, agents \\(\\ttA)\\) and two relations:\na binary epistemic relation \\({\\sim_a} \\subseteq (W \\times W)\\) for\neach agent \\(a \\in \\ttA\\), and a binary friendship relation\n\\({\\asymp_w} \\subseteq (\\ttA\\times \\ttA)\\) for each world \\(w \\in W\\).\nOn the syntactic side, the language is freely generated by the\nstandard Boolean operators and two universal modalities, K\n(knowledge) and \\([\\asymp]\\) (friendship). These formulas are\nevaluated in pairs (world, agent), with the key\nclauses being the following: \nNote that the modalities are indexical in both the world\nand the agent. Thus, while formulas of the form \\(K\\varphi\\)\nare read as “I know \\(\\varphi\\)”, formulas of the\nform \\([\\asymp]\\varphi\\) are read as “all my friends satisfy\n\\(\\varphi\\)”. \nThe given examples show how the product strategy can be used to\n‘temporalize’ and/or ‘epistemize’ a given\nmodal system (Kaplan’s semantic framework can be understood as\nthe temporalization of an alethic system, and the described\nFacebook Logic can be understood as the\n‘epistemization’ of a social network setting). For more on\nthe products of modal logics, the reader is referred to the\nalready-mentioned\n combining logics,\n and also to Gabbay et al. (2003: Chapter 5), Kurucz (2006: Section\n3) and van Benthem, Bezhanishvili, et al. (2006). \nThe strategies of fusion and product for combining modal logics rely\nin merging both the languages and the semantic models of the modal\nlogics to be combined. In the\n fibring\n strategy (called fibring by functions in Carnielli,\nConiglio, et al. 2008), the languages are also merged, but the\nsemantic models remain separated. Formulas can be evaluated in pointed\nmodels of any of the original systems, in the following way. When the\nmodality to be semantically evaluated ‘matches’ the chosen\nsemantic model, the evaluation is done as in the original system; when\nthe modality comes from the other system, the fibring strategy uses a\ntransfer mapping to obtain a model and an evaluation point in\nthe class of models for the modality under evaluation, and then the\nevaluation proceeds as in the original system. Thus, modal fibring\nrequires a correspondence between the class of models of each one of\nthe systems, and uses it to move between them when the modality under\nevaluation requires it. \nMore precisely, let \\(\\cL_{\\left\\{ \\Box_{1} \\right\\}}\\) and\n\\(\\cL_{\\left\\{ \\Box_{2} \\right\\}}\\) be the languages of the system to\nbe combined, and let \\(\\cM_1\\) and \\(\\cM_2\\) be their correspondent\nclasses of models. Let \\(h_1\\) be a transfer mapping,\ntaking a world of any model in \\(\\cM_1\\), and returning a pair\nconsisting of a model \\(M_2\\) in \\(\\cM_2\\) and a world \\(w_2\\) in\n\\(M_2\\); let \\(h_2\\) be a transfer mapping in the other\ndirection, taking a world of any model in \\(\\cM_2\\), and returning a\npair consisting of a model \\(M_1\\) in \\(\\cM_1\\) and a world \\(w_1\\) in\n\\(M_1\\). Formulas of the language \\(\\cL_{\\left\\{ \\Box_{1}, \\Box_{2}\n\\right\\}}\\) can be evaluated in either tuples of the form \\(\\langle\nh_1, h_2, M_1, w_1 \\rangle\\) (with \\(w_1\\) in \\(M_1 = \\langle W_1,\nR_1, V_1 \\rangle\\) and \\(M_1\\) in \\(\\cM_1)\\) or else tuples of the\nform \\(\\langle h_1, h_2, M_2, w_2 \\rangle\\) (with \\(w_2\\) in \\(M_2 =\n\\langle W_2, R_2, V_2 \\rangle\\) and \\(M_2\\) in \\(\\cM_2)\\). In the\nfirst case, the semantic interpretation of Boolean operators is as\nusual; for the modality \\(\\Box_{1}\\), \nThus, modalities ‘matching’ the model are evaluated as in their original systems. Then, for the modality \\(\\Box_{2}\\) of the\nother system, the transfer mapping \\(h_1\\) is used: \nIn other words, when \\(\\Box_{2}\\) needs to be evaluated, the transfer\nmapping uses current evaluation point \\(w_1\\) to obtain a pointed\nsemantic model \\(h_1(w_1) = (M_2, w_2)\\) where the modality will be\nevaluated. When the analogous situation arises, facing the evaluation\nof \\(\\Box_{1}\\) on a tuple \\(\\langle h_1, h_2, M_2, w_2 \\rangle\\), it\nis the turn of the second transfer function \\(h_2\\) to make its\nappearance, taking us then from \\(\\langle h_1, h_2, M_2, w_2 \\rangle\n\\Vdash \\Box_{2}\\varphi\\) to \\(\\langle h_1, h_2, h_2(w_2) \\rangle\n\\Vdash \\Box_{2}\\varphi\\). \nFor more details on the fibring of modal logics, the reader is\nreferred to Gabbay (1999: Chapter 3). For other forms of fibring, see\n Section 4.3\n of\n combining logics. \nSo far, this text has described different ways in which a multi-modal\nsystem can emerge. We have briefly discussed how a single modal system\ncan give rise to a multi-modal one by providing either syntactic or\nsemantic definitions of new concepts\n (section 2),\n and also how two or more modal systems can be combined in order to\nproduce a multi-modal one\n (section 3).\n As the provided examples have shown (and the examples in\n section 4\n will continue to do), the addition of modalities allows us to\nestablish and/or find significant relationships between the involved\nconcepts, thus providing a better understanding of what each one of\nthem is. \nBut there is also another side to this coin. By adding modalities to a\nsystem, one increases its expressivity, but this may also have the\nundesirable consequence of raising its\n computational complexity.\n Indeed, a modal language allows us to describe a certain class of\nmodels. If the language is fairly simple, then deciding whether a\ngiven formula is true in a given world of a given model (the\nmodel-checking problem) and deciding whether a given formula\nis true in all worlds of all models in a given class (the\nvalidity problem) are simple tasks. Now suppose a more\nexpressive language is used. It is then possible to distinguish models\nthat were, from the first language’s perspective, the same\n(see, e.g., the appendix on the non-definability of distributed and common knowledge within \\(\\cL_{\\left\\{ \\oK{1}, \\ldots, \\oK{n} \\right\\}}\\)).\nHowever, intuitively, we might then need to make a stronger effort to\nsee those differences: we might need more time to make the\ncalculations, and we might need more space to save intermediate\nresults. In a single sentence, expressivity and complexity go hand in\nhand, and an increase in the first typically produces an increase in\nthe second. \nThe simplest example of this phenomenon is given by the relationship\nbetween the two best-known logical languages, the propositional and\nthe first-order predicate one, when used to describe first-order\nmodels. The validity problem for the propositional language, which can\nbe understood as one that only allows us to talk about the properties\n(i.e., monadic predicates) of a single object and their Boolean\ncombination, is decidable: there are effective procedures\nthat can answer the validity question for any given propositional\nformula. The first-order predicate language can see much more (all\nobjects of the domain, together with their properties and their\nn-ary relations, among others), but this comes at a price: its\nvalidity problem is undecidable, as there is no effective\nprocedure that can answer the validity question for all its\nformulas. \nIn the modal realm there are also such cases, some of them in which\nseemingly harmless combinations produce dramatic results. An example\nof this can be found in Blackburn, Rijke, and Venema (2001: Section\n6.5), where it is shown that the fusion of two decidable systems, a\nPDL-like system (with sequential composition and intersection\nas the syntactic constructors) and a system with the global modality\n(Goranko & Passy 1992), crosses the border into undecidability.\nEven if the new multi-agent system turns out not to be undecidable,\nits complexity might be such that solving its validity problem for\nrelatively small instances is, for all practical purposes, impossible.\nAn example of such case is the basic multi-agent epistemic logic, with\nno requirements on the accessibility relations. The validity problem\nfor formulas in \\(\\cL_{\\left\\{ \\oK{1}, \\ldots, \\oK{n} \\right\\}}\\) is\n PSPACE: the space (and thus time) required to decide whether any given \\(\\varphi\\) is valid is given by a polynomial function. However, adding the common knowledge\noperator makes the validity problem for formulas in \\(\\cL_{\\left\\{\n\\oK{1}, \\ldots, \\oK{n}, C \\right\\}}\\) EXPTIME (sometimes also called\n EXP):\n the required time is now given by an exponential\n function.[14] \nA major methodological issue is then to strike a proper balance\nbetween expressive power and computational complexity, with the best\nmulti-modal systems being those that manage to achieve a good\ncompromise in this sense. We end this section noticing briefly that,\nin the case of the combination of modal logics, complexity\ndepends deeply on the assumed bridge axioms. A famous example of this\nis the landmark paper by Halpern & Vardi (1989) on the complexity\nof (96!) epistemic and temporal logics over interpreted\nsystems, all of them differing on the used language (single or\nmultiple-agents, common knowledge or lack of) and the assumed bridge\nprinciples (the aforementioned perfect recall and no\nlearning, synchronicity, unique or multiple initial\nstate). \nThe previous sections have described several ways of obtaining\nmulti-modal systems. The current one presents some of the most\ninteresting examples, together with the discussions that arise\nfrom the interplay of the modalities involved. \nThe interplay between knowledge and belief is an important topic in\nepistemology. Historically, one of the most important proposals is\nPlato’s characterization of knowledge as\n justified true belief,\n which has been one of the motivations used in the development of\n justification logic.\n However, can knowledge be truly defined as justified true belief? The\n examples\n provided (among others) in Gettier (1963) seem to go against this\nidea. Gettier describes situations in which an agent believes a given\n\\(\\varphi\\) and has a justification for it; moreover, \\(\\varphi\\) is\nindeed the case. Nevertheless, the justification is not an appropriate\none: \\(\\varphi\\) happens to be the case because of some other lucky\nunrelated circumstances. This has lead to proposals that focus on the\nrequirement of a correct justification (the no false\nlemma: Clark 1963; Armstrong 1973; Shope 1983). Some others have\nused a stronger indefeasibility requirement, stating that\nknowledge is justified true belief that cannot be defeated by true\ninformation, i.e., there is no true proposition \\(\\psi\\) such that, if\nthe agent were to learn that \\(\\psi\\) was the case, would lead her to\ngive up her belief, or to be no longer justified in holding it (Klein\n1971; Lehrer & Paxson 1969; Swain 1974). The aforementioned\ntopological modal approach of Baltag, Bezhanishvili, et al. (2016)\nrelates this idea with other epistemic concepts, and a deeper\ndiscussion on what it means to know something can be found in\n the analysis of knowledge\n by Ichikawa and Steup (2018). \nThere are also other alternatives. An interesting proposal, discussed\nin Lenzen (1978) and Williamson (2002), follows the other direction:\nstart from a chosen notion of knowledge, and then weaken it in order\nto obtain a ‘good’ (e.g., consistent, introspective,\npossibly false) notion of belief. These ideas have been discussed in\nformal settings. In Stalnaker (2006), the author argues that the\n“true” logic of knowledge is the modal logic S4.2, given\nby the standard K axiom \\((K(\\varphi \\rightarrow\\psi)\n\\rightarrow (K\\varphi \\rightarrow K\\psi))\\) and the generalization\nrule \\((K\\varphi\\) for every validity \\(\\varphi)\\), together with\nveridicality \\((K\\varphi \\rightarrow \\varphi\\): knowledge is\ntruthful), positive introspection \\((K\\varphi \\rightarrow KK\\varphi\\):\nif the agent knows \\(\\varphi\\), then she knows that she knows it) and\nthe ‘convergence’ principle \\((\\hK K\\varphi \\rightarrow\nK\\hK\\varphi\\): if the agent considers it possible to know \\(\\varphi\\),\nthen she knows that she considers \\(\\varphi\\) a possibility). In this\nsetting, Stalnaker (2006) argues that belief can be defined as the\nepistemic possibility of knowledge, that is, \nNote how this is exactly what the definition of belief in the\npreviously discussed plausibility models entails: if the modality\n\\([\\leq]\\) is understood as indefeasible knowledge (Lehrer 1990;\nLehrer & Paxson 1969), then \\(B\\varphi :=\n\\langle{\\leq}\\rangle[{\\leq}]\\varphi\\) states that belief is the\npossibility of knowledge. In this context, it is a small step to move\nfrom studying simple beliefs to conditional beliefs. A complete\naxiomatization of the logic of indefeasible knowledge and conditional\nbelief, first posed as an open question in Board (2004), was provided\nwith a solution in Baltag and Smets (2008). \nA further proposal that uses knowledge as the basic notion is that of\nBaltag, Bezhanishvili, Özgün, and Smets (2013), which\ngeneralizes Stalnaker’s (2006) formalization by using a\ntopological (neighborhood) semantics. An important feature of\nthe notion of belief that arises in this setting is that it is\nsubjectively indistinguishable from knowledge: an agent believes\n\\(\\varphi\\) \\((B\\varphi)\\) if and only if she believes that she knows\nit \\((BK\\varphi)\\). \nTemporal-epistemic approaches have been briefly mentioned in this\ntext.\n Indeed, many logical systems have been used to describe the way in\nwhich the knowledge of agents changes over time. The proposals include\nnot only interpreted systems (IS; Fagin et al. 1995)\nbut also epistemic-temporal logic (ETL; Parikh &\nRamanujam 2003), logics of\n agency\n (e.g., see to it that logic,\n STIT;\n Belnap, Perloff, & Xu 2001) and the DEL approach\nmentioned before\n (section 2.8).\n In all of them, an important point of discussion is the interaction\nbetween the temporal and epistemic modalities. \nAs mentioned before, two famous requirements have been those of\nperfect recall (the agent’s knowledge is not decreased\nover time) and no learning (the agent’s knowledge is\nnot increased over time). In the simple fusion of epistemic logic and\nthe future fragment of tense logic described above, these two\nrequirements can be expressed, respectively, as  \nFor some, the no learning condition might be too harsh, as it\nseems to say that the passage of time never helps to increase\nknowledge. A related but more reasonable condition is that of no\nmiracles, introduced in a slightly richer setting in van Benthem\nand Pacuit (2006), which states that the uncertainty of the agents\ncannot be erased by the same\n event.[15]\n A further interaction property is that of synchronicity,\nwhich states that epistemic uncertainty only happens among epistemic\nsituations that occur at the same moment of time. For example, the\nagent always knows ‘what time it is’, as she might not\nknow which action was executed, but she always knows that some action\nhas taken place. \nFor more information on the interaction of time and knowledge, the\nreader is referred, among others, to Halpern, van der Meyden, and\nVardi (2004); van Benthem, Gerbrandy, et al. (2009). See also van\nBenthem and Dégremont (2010) and Dégremont (2010) for\nanalogous interactions between time and beliefs, with the\nlatter represented by plausibility preorders similar to the\nplausibility models described before. \nThe interplay between questions and propositions is an important\nfactor in driving reasoning, communication, and general processes of\ninvestigation (Hintikka 2007; Hintikka, Halonen, & Mutanen 2002).\nIndeed,  \n[s]cientific investigation and explanation proceed in part through the\nposing and answering of questions, and human-computer interaction is\noften structured in terms of queries and answers. (from the SEP entry\non\n questions\n by Cross & Roelofsen 2018) \nBut then, what is the relationship between an agent’s knowledge\nand her questions? Maybe more important: given that different agents\nmight be posing different questions (i.e., they might be interested in\ndifferent issues), what is the relationship between the knowledge of\ndifferent agents? \nThe proposal of Boddy (2014) and Baltag, Boddy, and Smets (2018)\nstudies these concerns (then also studying what the ‘real’\ncommon and distributed knowledge of a group is). Their model (based on\nthe epistemic issue model introduced in van Benthem &\nMinica 2012) assumes that agents have not only their individual\nknowledge, but also their individual issues: the topics that\neach one of them has put on the table, which determine their\nindividual agenda on what is currently under investigation. On the\nsyntactic side, besides the standard knowledge modality \\((K_i\\) for\neach agent i), there is also a modality \\(Q_{i}\\varphi\\), read\nas “\\(\\varphi\\) can be known solely based on learnable\nanswers to i’s questions”. In other words,\n\\(Q_a\\) describes the maximum knowledge agent a can acquire,\ngiven her questions and the answers that are learnable for her. Thus,\nas a principle, if a knows \\(\\varphi\\), she can know it solely\nbased on answers to her question(s): \nMore interesting is the relationship between agent a’s\nknowledge and that of other agent b: in order for an agent to\nconsider any potential knowledge, such knowledge must be relevant for\nher in the sense that she can distinguish it as a possible answer to\none of her questions. In other words,  \n[a]gents are therefore only able to coherently represent the knowledge\nof others […] if the fact that they (the others) possess this\nknowledge […] is relevant to them. (Boddy 2014: 28)  \nThus, “if b knows something that is relevant to a,\nthen it is relevant to a that b knows this” and\n \nif b can know (given her issue) anything that is relevant to\na, then this fact (that b’s potential knowledge\nincludes potential knowledge of a) is itself relevant to\na.  \nIn symbols, \nA more in-depth discussion about the consequences of adding the\nagent’s issues to the picture (including alternative definitions\nfor the group’s distributed and common knowledge) can be found\nin the above references. \nIn the context of the design and implementation of autonomous agents,\none of the most famous architectures is the\nbelief-desire-intention (BDI) model (Bratman 1987;\nHerzig, Lorini, Perrussel, & Xiao 2017). \nDeveloped initially as a model of human practical reasoning (Bratman\n1987), the BDI model proposes an explanation of practical\nreasoning involving action, intention, belief, goal, will,\ndeliberation and several other concepts. Thus, it is natural to think\nabout combining simple modal logics for some of these notions in order\nto define logics for such richer settings. Indeed, several formal\nsemantics for such models have been proposed, some of them based on\ndiverse temporal logics (Cohen & Levesque 1990; Governatori,\nPadmanabhan, & Sattar 2002; Rao & Georgeff 1991), some others\nbased on dynamic logics (van der Hoek, van Linder, & Meyer 1999;\nSingh 1998), and some based on both (Wooldridge 2000). The crucial\npart in most of them is the interaction between these different\nattitudes. For example, on the one hand, if an agent intends to\nachieve something (say, \\(I\\varphi)\\), one would expect for her to\ndesire that something \\((D\\varphi)\\); otherwise, it does not make\nsense to devote resources to achieve it. On the other hand, desiring\nsomething should not imply an intention to achieve it: it does not\nseem reasonable to commit resources to all our desires, even the\nunrealistic ones (and, perhaps more importantly, intention and desires\nwould collapse into a single notion). Moreover, it seems clear that an\nagent who desires to be rich \\((Dr)\\) does not necessarily believe\nthat she is rich \\((Br)\\). Finally, if an agent has an intention to\nwrite a book \\((Ib)\\), should she believe that she will write it\n\\((BFb)\\), thus ruling out all possible unforeseen circumstances that\ncould prevent her from doing it? \nA concise description of this interaction in some of these proposals\ncan be found in the first part of\n Subsection 4.2\n in the SEP entry on\n the logic of action\n written by Segerberg, Meyer, and Kracht (2016). \nModal first-order (i.e., quantified modal) logic is perhaps one of the\nmost intriguing multi-modal systems, as the combination of quantifiers\nand modalities raises several interesting questions. Here we will\ndiscuss briefly two important points; readers interested in a further\ndiscussion are referred to the SEP discussion on\n quantified modal logic\n by Garson (2018). \nThe modal first-order language is built in a straightforward way:\nsimply take the classical\n first-order language,\n with its universal \\((\\forall)\\) and existential \\((\\exists)\\)\noperators indicating quantification over objects, and add the two\nbasic modal alethic operators, necessity \\((\\Box)\\) and possibility\n\\((\\Diamond)\\). The resulting language turns out to be very\nexpressive, allowing us to distinguish between the de dicto\nand the de re readings of natural language sentences (a\ncontrast that can be traced back to Aristotle; see Nortmann 2002). For\nexample, assume that an individual f has exactly 3 sisters, and\nconsider the sentence “the number of sisters of f is\nnecessarily greater than 2”. The claim can be understood in\ntwo different ways. Under a de dicto interpretation, it\nstates that the number of sisters that f has is\nnecessarily greater than 2, but this is clearly questionable: under\ndifferent circumstances, f might have had either more or else fewer sisters.\nHowever, under a de re interpretation, the claim states that\nthe number of sisters that f has, the number 3, is\nnecessarily greater than 2: this is definitely true, at least when\nrestricting ourselves to the standard understanding of numbers. \nIn modal first-order logic, the difference between de re and\nde dicto is given by\n the scope of the involved quantifiers and modal operators.\n On the one hand, a de dicto (“of the\nproposition”) sentence indicates a property of a proposition,\nwith the involved quantifier occurring under the scope of modalities.\nFor example, the de dicto reading of the previous sentence is\ngiven by the formula \\(\\oBox\\left(\\exists x (x = s(f) \\land x > 2)\n\\right)\\) (with s a function returning its parameter’s\nnumber of sisters). On the other hand, a de re (“of the\nthing”) sentence indicates a property of an object, with the\ninvolved modality occurring under the scope of quantifiers. For\nexample, the de re reading of the previous sentence is given\nby the formula \\(\\exists x \\left( x = s(f) \\land \\oBox(x > 2)\n\\right)\\). This crucial distinction can be exemplified by the\ndifference between some agent i knowing that there is someone\nthat makes her Happy (but maybe without knowing who this\nperson is), \\(K_i\\exists x H(x, i)\\), and the always preferred\nexistence of someone who i knows makes her happy \\((\\exists x\nK_i H(x, i))\\). \nBut the expressivity comes with a cost. As usual in multi-modal\nsystems, the crucial question is the interaction between the involved\nmodalities, and in this case, the discussion typically centers on the\nfollowing two: the Barcan formula, \\(\\forall x \\oBox Px\n\\rightarrow \\oBox\\forall x Px\\), and its converse, \\(\\oBox\\forall x Px\n\\rightarrow \\forall x \\oBox Px\\) (see Barcan 1946). The reason for the\ncontroversy becomes clear when the generic predicate P is\nreplaced by, say, the formula \\(\\exists x (x=y)\\), which can be read\nas “x exists”. Then, the first formula\nbecomes \nstating that if everything exists necessarily then it is necessary\nthat everything exists. In terms of a possible worlds semantic model,\nthis boils down to stating that every object existing in an\nalternative possible world should also exist in the current one: when\none moves to alternative scenarios, the domain does not grow.\nAnalogously, the second formula becomes  \nstating that if it is necessary that everything exists then everything\nexists necessarily. In terms of a possible worlds semantic model, this\nboils down to stating that every object existing in the current world\nshould also exist in an alternative possible one: when one moves to\nalternative scenarios, the domain does not shrink. \nThus, a decision about whether such principles hold corresponds to\nanswering a crucial question when building a model for the modal\nfirst-order language: what is the relationship between the domains of\nthe different possible worlds? On the one hand, from the perspective\nof\n actualism,\n everything there is (everything that can in any sense be said to be)\nis actual, that is, it exists; hence, there is a fixed domain\nacross all possibilities. On the other hand, from the perspective of\n possibilism,\n ‘the things that exist’ include possible but non-actual\nobjects; hence, different possible worlds might have different\ndomains. There is a large literature on the discussion between these\ntwo positions, as the provided references show. \nThe notion of\n intention\n is crucial in BDI systems, as it in some sense defines the\nchoices the agent will make, thus affecting her behavior. Thus, the\ndynamics of intention is also a crucial subject, as it\ndescribes the way intentions are generated, preserved, modified or\ndiscarded. \nFor an initial point, how do intentions change after the agent learns\na new piece of information? According to Roy (2008: Chapter 5), if the\noriginal intentions are compatible with the new information, then they\nare ‘reshaped’; otherwise, the agent discards them without\ncreating any new intention (or, analogously, generating an intention\nfor something that has been already achieved). Thus, after an\nannouncement of \\(\\chi\\) the agent intends to do \\(\\varphi\\) if and\nonly if \\(\\chi\\) is compatible with her intentions and \\(\\varphi\\) is\na restricted consequence of the agent’s initial intentions, or\nelse \\(\\varphi\\) is a ‘known’ consequence of\n\\(\\chi\\)’s announcement. In a formula, \nThere are other proposals. In van der Hoek, Jamroga, and Wooldridge\n(2007), intentions are defined, roughly speaking, as plans the agent\nbelieves have not yet been fulfilled. As a consequence of this,\nchanges in the agent’s beliefs lead to changes on her\nintentions. For example, after any observation, the agent will drop\nintentions that she believes have been accomplished: \nMoreover, she will drop any intention she believes it is impossible to\nachieve: \nBut, just as changes in the agent’s information (knowledge,\nbeliefs) should trigger changes in her intentions, changes in her\nintentions may also trigger changes in (some of) her beliefs. Intuitively,\nhaving the intention to achieve a given \\(\\varphi\\) reduces the\nactions that the agent ‘can’ perform, from the ones she\ncan actually carry on, to those that will still allow (and maybe\nassure) that \\(\\varphi\\) will be achieved. In other words, a change in\nthe agent’s intentions triggers also a change in her beliefs\nabout the (sequence of) actions that will be available in the future.\nThis is the idea followed in Icard, Pacuit, and Shoham (2010), which\nstudies the interaction between intention revision and belief revision\nby introducing postulates for both actions, with these postulates\ndescribing the two processes’ interplay. In the interesting case\nof intention revision, the postulates state that (i) a new intention\nwill take precedence over previous ones (and thus old ones should be\neliminated when in conflict), (ii) modulo coherence, no further change\nshould be made on the agent’s intentions (in particular, no\nextraneous intentions should be added), and (iii) non-contingent\nbeliefs do not change with intention\n revision.[16] \nAs the reader might guess, adding a temporal dimension is typically a\ngood idea, as in most cases it enriches the initial system by allowing\nus to talk about how the concept changes. Besides epistemic\nsettings, others that benefit from this are systems of\n deontic logic,\n which study the properties of concepts as permissions (e.g.,\n“\\(\\varphi\\) is allowed”) and obligations (e.g.,\n“\\(\\varphi\\) is required”). Such systems are extremely\nuseful, as they involve topics such as law, social and business\norganizations, and even security systems. \nOne of the interesting concepts that arise when time and obligations\ninteract with each other is the notion of deontic deadlines:\nobligations that need to be fulfilled only once, at a time of\none’s choosing, as long as it is before certain condition become\ntrue. Indeed,  \n[…] deontic deadlines are interactions between two dimensions:\na deontic (normative) dimension and a temporal dimension. So, to study\n[them], it makes sense to take a […] temporal logic […]\nand a standard deontic logic […], and combine the two in one\nsystem. (Broersen, Dignum, Dignum, & Meyer 2004: 43)  \nSuch formal systems help to provide a proper understanding of what a\ndeadline is: as the aforementioned reference asks,  \nis a deadline (1) an obligation at a certain point in time to achieve\nsomething before another point in time, or (2) is a deadline simply an\nobligation that persists in time until a deadline is reached, or (3)\nis it both?  \nThen, the formal setting also allows the possibility to make further\nfiner distinctions, as the one between an obligation to always satisfy\na given \\(\\varphi\\) (in symbols, and with O a modality for\nobligation, \\(OG\\varphi)\\) and an obligation for \\(\\varphi\\) that\nshould be always fulfilled \\((GO\\varphi)\\). Further and deeper\ndiscussions on deontic deadlines can be found in Broersen et al.\n(2004); Broersen (2006); Brunel, Bodeveix, & Filali (2006);\nDemolombe, Bretier, & Louis (2006); Governatori, Hulstijn,\nRiveret, & Rotolo (2007); and Demolombe (2014), among others. \nEqually important is the relationship between knowledge and\nobligations, as it is shown by the aforementioned\n paradox of epistemic obligation,\n which arises within the fusion\n (section 3.1)\n of a\n standard deontic logic\n and a standard epistemic logic. But the relationship between these\nconcepts goes beyond their interaction in such a basic system. For\nexample, if an agent does not know about the existence of an\nobligation, should she be expected to fulfill it? In some cases the\nanswer seems to be “no”: a physician whose neighbor is\nhaving a heart attack has no obligation to provide assistance unless\nshe knows about the emergency. Still, in some other cases, the answer\nseems to be “yes”: the juridical principle\n“ignorantia juris non excusat” (roughly,\nignorance of the law is not excuse) is an example of this. \nThere have been proposals dealing with these issues. One of them is by\nPacuit, Parikh, & Cogan (2006), which uses a setting in which\nactions can be considered “good” or “bad”. It\nintroduces a notion of knowledge-based obligation under which\nan agent is obliged to perform an action \\(\\alpha\\) if and only if\n\\(\\alpha\\) is an action which the agent can perform and she\nknows that it is good to perform \\(\\alpha\\). This is then a\nform of absolute obligation which remains until the agent\nperforms the required action. \nInterestingly, the involvement of knowledge gives raise to forms of\n‘defeasible’ obligations that can disappear in the light\nof new information. For example, having being informed about her\nneighbor’s illness, the physician could have the obligation to\nadminister a certain drug; however, this obligation would disappear if\nshe were to learn that the neighbor is allergic to this medication.\nThis ‘weaker’ form of obligation can also be captured\nwithin the setting discussed in Pacuit et al. (2006). \nThe interaction between knowledge and obligations is not limited to\nthe way knowledge ‘defines’ obligations. An important role\nis also played by whether the agent consciously violates her\ncommitments. In fact, most juridical systems contain the principle\nthat an act is only unlawful if the agent conducting it has a\n‘guilty mind’ (mens rea): for the agent to be\nguilty, she must have committed the act intentionally/purposely. Of\ncourse, there are different levels of ‘guilty minds’, and\nsome legal systems distinguish between them in order to assign\n‘degrees of culpability’ (e.g., an homicide is considered\nmore severe if done intentionally rather than accidentally). For\nexample, on the one hand, stating that it is illegal to do\n\\(\\alpha\\) negligently means that it is illegal to do\n\\(\\alpha\\) while being aware that the action carries a substantial and\nunjustifiable risk. On the other hand, stating that it is illegal to\ndo \\(\\alpha\\) knowingly means that it is illegal to do\n\\(\\alpha\\) while being certain that this conduct will lead to the\nresult.[17]\nThese and other modes of mens rea are formalized in Broersen\n(2011) within the\n STIT\n logic framework. \nAs the previous sections indicate, the specific interplay between\ndifferent modalities (the way they are combined and which bridge\nprinciples hold) is crucial to provide an accurate representation and\nanalysis of different philosophical concepts. In fact, in several\noccasions, the combination of different modalities have shed light on\nphilosophical issues.  We will illustrate this for the concepts of\nabduction, knowability, ‘believing to know’, truthmakers\nand the interplay between assumptions and beliefs while keeping in\nmind an endless list of other philosophical paradoxes and problems\nthat all arise in a multi-modal setting. (Among many others, see the\nYablo paradox in Yablo (1985, 1993) as well as the SEP discussions on\n deontic paradoxes\n and on\n paradoxes without self-reference.\n See also the SEP analyses on the\n knower paradox,\n on\n dynamic epistemic paradoxes\n and on the\n surprise examination paradox;\n for the latter, see also a proposed solution in Baltag and Smets\n(2010\n Other Internet Resources).) \nThe term\n abduction\n has been used in related but sometimes different senses. Roughly\nspeaking, abductive reasoning (also called inference to the best\nexplanation, retroduction, and hypothetical,\nadductive or presumptive reasoning, among many other\nterms) can be understood as the process through which an\nagent (or a group of them) looks for an explanation of a surprising\nobservation. Many forms of intellectual tasks, such as medical and\nfault diagnosis, legal reasoning, natural language understanding, and\n(last but not least) scientific discovery, belong to this category,\nthus making abduction one of the most important reasoning\nprocesses. \nIn its simplest form, abduction can best be described with\n Peirce’s\n 1903 schema (Hartshorne & Weiss 1934: CP 5.189): \nThis is the understanding that has been most frequently cited and used\nwhen providing formal approaches to abductive reasoning. Still,\ntypical definitions of an abductive problem and its solution(s) have\nbeen given in terms of a (propositional, first-order) theory and a\nformula, leaving the attitudes of the involved agents out of the\npicture. \nHowever, there have been also proposals that formalize (parts of) the\nabductive process in terms of diverse epistemic concepts (e.g.,\nLevesque 1989; Boutilier & Becher 1995). Among them,\nVelázquez-Quesada, Soler-Toscano, &\nNepomuceno-Fernández (2013) understand abductive reasoning as a\nprocess of belief change that is triggered by an observation and\nguided by the knowledge the agent has. In symbols\n(Velázquez-Quesada 2015), abductive reasoning from a surprising\nobservation \\(\\psi\\) to a belief \\(\\varphi\\) can be described as \nstating thus that if the agent knows \\(\\varphi \\rightarrow \\psi\\) and\nan announcement of \\(\\psi\\) (“\\([\\psi{!}]\\)”) makes her\nknow it \\((\\psi)\\), then she can perform an act of belief\nrevision with \\(\\varphi\\) (“\\([\\varphi\\Uparrow]\\)”)\nin order to believe it. This formalization emphasizes not only that\nthe agent’s initial knowledge plays a crucial role in the\ngeneration of possible abductive solutions, but also that the chosen\nsolution can only be accepted in a weak way, therefore making it a\ncandidate for being discarded in the light of further information. \nOther proposals have incorporated further aspects into the picture.\nOne of them, Ma & Pietarinen (2016), follows Peirce’s latter\nunderstanding of abductive reasoning (called then\nretroduction: “given a (surprising) fact C, if\nA implies C, then it is to be inquired whether A\nplausibly holds”; Peirce 1967: 856) as a form of reasoning from\nsurprise to inquiry. This can possibly be related to the\nnotions of issues and questions described in \nsection 4.3. As the authors mention,\n \n[t]he important discovery is that [, in the new formulation,] the\nconclusion is presented in a kind of interrogative mood. But the\ninterrogative mood does not merely mean that a question is raised. In\nfact, it means that the possible conjecture A becomes the\nsubject of inquiry: the purpose is to determine whether that A\nis indeed plausible or not. Peirce termed such mood “the\ninvestigand mood”. Hence abduction can be viewed as the dynamic\nprocess toward a plausible conjecture and, ultimately, toward a\nlimited set of the most plausible conjectures. \n This paradox\n emerges from what is commonly known as the verificationist thesis\n(VT), which claims that all truths are verifiable.\nFormalizing this thesis in a multi-modal logic that combines a\nknowledge operator with a possibility operator would yield \nwith \\(\\Diamond K\\varphi\\) read as “it is possible to\nknow \\(\\varphi\\)”. In this context, the paradox refers to\nFitch’s argument containing an idea conveyed to him in 1945\nwhich shows that, if all truths are knowable, then all truths are\nalready known. As the argument goes, we clearly do not know all truths\n(as we are not omniscient!); hence, the premise has to be false: not\nall truths are knowable. The paradox can be summarized by the\nderivation \nwhich poses a problem for the non-omniscient verificationist. The\nderivation that leads to the paradox as we have stated it here is\nbased on a multi-modal logical system in which at least the following\nprinciples hold: (i) the principle of non-contradiction, to capture\nthat contradictions cannot be true and can also not be considered\npossible, (ii) the classical laws of double negation, transitivity of\nthe material implication and substitution, (iii) normality of the\nmodal logic operator K, the modal logic principle T\nstating that knowledge is truthful, and the normality of the modal\npossibility operator \\(\\Diamond\\). The simplest presentation of the\nparadox which shows how it leads to the unwanted equivalence between\ntruth and knowledge, can be found in van Benthem (2004). Start with\nthe formula stating the verificationist thesis, \\(\\varphi \\to \\Diamond\nK\\varphi\\), and substitute \\(\\varphi\\) with \\((p \\land \\lnot\nKp)\\): \nThis paradox gave rise to an active debate in the philosophical\nliterature, leading us to signal out two main types of proposed\nsolutions: those proposing a weakening of our logical principles (as\nin paraconsistent, intuitionistic or weaker modal logics) while\nkeeping the verification thesis, and those that in contrast do not\nchange/restrict the underlying logic but propose a specific\nformalization or reading of the verificationist\n thesis.[18]\n While we refer the reader to the SEP entry on\n epistemic paradoxes\n for an overview of these proposed solutions, here it is illustrative\nto highlight how this paradox, which in some sense arises from\ncombining a modal logic for knowledge (K) with a modal logic\nfor possibility \\((\\Diamond)\\), can be ‘demystified’ by\nthe further introduction of a modality for communication (related to\nthe public announcement modality of PAL). Indeed, according\nto van Benthem (2004), what the verificationist thesis expresses is\nnot about ‘static’ knowability, but rather about\na form of learnability: “what is true may come to be\nknown” (van Benthem 2004). This statement can be formally stated\nin a suitable arbitrary announcement framework as: \nwhich is read as “if \\(\\varphi\\) is the case, then there is\na formula \\(\\psi\\) after whose announcement \\(\\varphi\\) will be\n known”.[19]\n This reading of the verificationist thesis brings us in touch with a\nnumber of results in dynamic epistemic logic on unsuccessful\nformulas (those that become false after being truthfully announced;\nvan Ditmarsch & Kooi 2006; van Benthem 2011; Holliday & Icard\n2010), which indicate that indeed not all sentences are learnable. In\nfact, this solution shows us that \n[…] there is no saving VT—but there is also no such\ngloom. For in losing a principle, we gain a general logical study of\nknowledge and learning actions, and their subtle properties. The\nfailure of naive verificationism just highlights the intriguing ways\nin which human communication works. (van Benthem 2004: 105) \n \nOn first sight it seems natural to say that one can believe to\n‘know’ something, even when in fact one does not actually\nknow it. So believing to know something is philosophically conceived\nto be different from claiming true knowledge. Yet, under the\nassumption that what is known is also believed, this specific\ninterplay between modalities for knowledge and belief can lead us into\ntrouble if we identify belief with a\nKD45-modality B, and knowledge\nwith a S5-modality for K. For\nsuppose \\(BK\\varphi \\land \\lnot K\\varphi\\) is assumed. Then, by\nnegative introspection of the second conjunct, we derive \\(K\\lnot\nK\\varphi\\). But as knowledge implies belief, we derive \\(B\\lnot\nK\\varphi\\). This together with the first conjunct \\(BK\\varphi\\) will\ngive us, by additivity of belief, \\(B(K\\varphi \\land \\lnot\nK\\varphi)\\). Hence we derive the belief in a contradiction, which is\nnot compatible with the assumption of consistency of beliefs (axiom\nD) in\nKD45. This problem is known as the\nparadox of the perfect believer (and also as the Voorbraak\nparadox), as it was originally (but equivalently) described (Voorbraak\n1993) as the derivability of the bridge principle \\(BK\\varphi\n\\rightarrow K\\varphi\\), which states that a belief in knowing a given\n\\(\\varphi\\) is enough to know \\(\\varphi\\). (The derivation of\n\\(BK\\varphi \\rightarrow K\\varphi\\) also relies on the negative\nintrospection of knowledge, the normality and consistency of beliefs,\nand the bridge principle stating that knowledge implies belief; Gochet\n& Gribomont 2006: 114.) \nAfter presenting this problem, Voorbraak (1993) proposed to deal with\nit by discarding the bridge principle \\(K\\varphi \\rightarrow\n{B\\varphi}\\). Another option is to allow inconsistent beliefs (Gochet\n& Gribomont 2006: Section 2.6). Still, a further possible\nsolution, closer to the spirit of these notes, is to consider an\nintermediate notion of ’knowledge’ that is not as strong\nas the absolute irrevisable (i.e., irrevocable) notion given by the\nS5 modal operator K. More\nprecisely, the proposal in Baltag and Smets (2008) looks at Lehrer’s\ndefeasibility theory of knowledge (Lehrer 1990; Lehrer &\nPaxson 1969), and works with the indefeasible (“weak”,\nnon-negatively-introspective) knowledge given, in the\n plausibility models\n discussed above, by the modality \\([\\leq]\\) (read before also as\nsafe belief). Indeed, Lehrer and Stalnaker call this concept\ndefeasible knowledge, a form of knowledge that might be\ndefeated by false evidence, but cannot be defeated by\ntrue evidence. The concept satisfies both the truth axiom\n\\(([\\leq]\\varphi \\rightarrow \\varphi)\\) and positive introspection\n\\(([\\leq]\\varphi \\rightarrow [\\leq][\\leq]\\varphi)\\), but it lacks\nnegative introspection; thus, the previous derivation of inconsistent\nbeliefs from an agent mistakenly believing that she (defeasibly) knows\n\\(\\varphi\\) \\(({B[\\leq]\\varphi} \\land \\lnot [\\leq]\\varphi)\\) is no\nlonger possible. Instead, it can be easily shown how a belief in\ndefeasible knowledge, \\({B[\\leq]\\varphi}\\), is equivalent to a simple\nbelief, \\({B\\varphi}\\). \nParaphrasing Fine (2017), a truthmaker is something on the\nside of the world, as a fact or a state of affairs, making true\nsomething on the side of language or thought, as a statement or a\nproposition. Truthmaking has been an important topic in both\nmetaphysics and semantics. For the first, “truthmaking serves as\na conduit taking us from language or thought to an understanding of\nthe world” (Fine 2017: 556); for the second, it provides\nadequate semantics for a given language by establishing how the world\nmakes sentences of the language true. \nIn Fine (2017), the author explains the basic framework of truthmaker\n(‘exact’) semantics for propositional logic. It is based\nnot on possible worlds, but rather on states or\nsituations; the crucial difference is that, while a possible\nworld settles the truth-value of any possible statement (i.e., given a\nformula and a possible world, the formula is either true or else\nfalse), a situation might not be enough to decide whether a given\nsentence holds. \nFormally, a state space is a tuple \\({\\langle S, \\sqsubseteq\n\\rangle}\\) where S is a non-empty set of states and\n\\({\\sqsubseteq} \\subseteq (S \\times S)\\) is a partial order (i.e., a\nreflexive, transitive and antisymmetric relation), with \\(s_1\n\\sqsubseteq s_2\\) understood as “state \\(s_2\\) extends state\n\\(s_1\\)”. It is assumed that any pair of states has a\nleast upper bound (i.e., a supremum); formally, for\nany \\(s_1, s_2 \\in S\\) there is \\(t_1 \\sqcup t_2 \\in S\\)\nsatisfying \nThis supremum \\(t_1 \\sqcup t_2\\) (its uniqueness follows from\n\\(\\sqsubseteq\\)’s antisymmetry) can be understood as the\n‘sum’, ‘merge’ or ‘fusion’ of\nstates \\(t_1\\) and \\(t_2\\), and it provides the crucial tool for\ndeciding whether a ‘conjunction’ is the case, as shown\nbelow. \nA state model is a tuple \\({\\langle S, \\sqsubseteq, V\n\\rangle}\\) with \\({\\langle S, \\sqsubseteq \\rangle}\\) a state space and\n\\(V:\\mathtt{P}\\to (\\wp(S) \\times \\wp(S))\\) a valuation function\nreturning not only set of states that make a given atom p true\n(abbreviated as \\(V^+(p))\\), but also the set of states that make it\nfalse (abbreviated as \\(V^-(p))\\). In principle, given an atom\np, there needs to be no relation between the two sets. They\nmight be overlapping \\((V^+(p) \\cap V^-(p) \\neq \\emptyset)\\), thus\nyielding a state that makes p both true and false; they might\nbe limited \\((V^+(p) \\cup V^-(p) \\neq S)\\), thus yielding a state that\nmakes p neither true nor false; they might be neither, thus\nbeing exclusive \\((V^+(p) \\cap V^-(p) = \\emptyset)\\) and exhaustive\n\\((V^+(p) \\cup V^-(p) = S)\\), and making the states behave as possible worlds\nwith respect to p. \nGiven a state model, the relations \\(\\Vvdash_v\\) (verified by a\nstate) and \\(\\Vvdash_f\\) (falsified by a state) are defined as\nfollows. \nNote the clauses for verifying a conjunction and falsifying a\ndisjunction. A state makes a conjunction true if and only if it is the\nfusion of states that verify the respective conjuncts \\(\\varphi\\) and\n\\(\\psi\\). Analogously, a state makes a disjunction false if and only\nif it is the fusion of states that falsify the respective disjuncts\n\\(\\varphi\\) and \\(\\psi\\). \nTruthmaker semantics can be seen from a (multi)modal perspective (van\nBenthem 1989), since a state model \\({\\langle S, \\sqsubseteq, V\n\\rangle}\\) can be understood as a modal information logic, and thus\ncan be described by modal languages. One interesting possibility (van\nBenthem 2018: Section 13) starts by taking two modalities,\n\\(\\langle\\sqsubseteq\\rangle\\varphi\\) and\n\\(\\langle\\sqsupseteq\\rangle\\varphi\\), whose semantic interpretation is\ngiven in the standard modal way, with the first modality relying on\nthe partial order \\(\\sqsubseteq\\), and the second relying on its\nconverse\n \\(\\sqsupseteq\\).[20]\n Then, one can add a (binary) modality describing least upper\nbound \nand a ‘dual’ one describing the infimum (the\ngreatest lower\n bound)[21] \nWith these tools, it is possible to define a faithful translation from\ntruthmaker logic into modal information logic (see van Benthem 2018:\nSection 13 for details). This translation brings methods from modal\nlogic to the study of truthmaking. More important is the fact that it\nmakes truthmaker semantics, a framework that works by providing a new\nmeaning to Boolean connectives, completely compatible with classical\n(modal) logic, which keeps standard definitions but extends the\nframework’s expressivity by studying much richer languages. \nWe finish this text by returning to the beginning. So, given that \nAnn believes that Bob assumes that \\(\\underbrace{\\textit{Ann\nbelieves that Bob's assumption is wrong}.}_{\\varphi}\\)  \nis the case, is \\(\\varphi\\) (“Ann believes that Bob’s\nassumption is wrong”) true or false? \nAs explained in Pacuit (2007), in order to show that this situation\ncannot be ‘represented’, the original paper (Brandenburger\n& Keisler 2006) introduces a belief model. This structure\nrepresents each agent’s beliefs about the beliefs of the other\nagent. More precisely, a belief model is a two-sorted structure, one\nsort for each agent, with each sort representing an epistemic state\nthat its agent might have. The model’s first component is its\ndomain, given by the union of \\(W_a\\) and \\(W_b\\), the disjoint sets\nof states of Ann and Bob, respectively. The model also has a relation\nfor each agent, \\(R_a\\) and \\(R_b\\), with \\(R_auv\\) (restricted to \\(u\n\\in W_a\\) and \\(v \\in W_b)\\) read as “in state u, Ann\nconsiders v possible, and analogous for \\(R_bvu\\). Again,\nthe structure represents each agent’s beliefs about the beliefs\nof the other, so each collection \\(\\cU_b\\) of subsets of \\(W_b\\) can\nbe understood as a language for Ann (the beliefs she might have about\nBob’s beliefs), and analogous for Bob; a full language is then\ndefined as the union of a language for each agent. For the involved\nepistemic attitudes, Ann believes a given \\(U \\in \\cU_b\\) if and only\nif the set of states that she considers possible is a subset\nof U. On the other hand, an assumption is understood as the\nstrongest belief, so Ann assumes a given \\(U \\in \\cU_a\\) if and only\nif the set of states she considers possible is exactly\nU. \nWith these tools, it is now possible to make precise the claim that\nthe situation described above cannot be represented. A language is\nsaid to be complete for a belief model if and only if every\npossible statement in a player’s language (i.e., every statement\nin her language that is true in at least one state) can be assumed by\nthe player. It is then possible to show, using a diagonal argument,\nthat no belief model is complete for ‘its first-order\nlanguage’, i.e., the language containing all first-order\ndefinable subsets of the model’s domain.","contact.mail":"S.J.L.Smets@uva.nl","contact.domain":"uva.nl"},{"date.published":"2019-06-03","url":"https://plato.stanford.edu/entries/phil-multimodallogic/","author1":"Sonja Smets","author1.info":"https://staff.fnwi.uva.nl/f.r.velazquezquesada/","entry":"phil-multimodallogic","body.text":"\n\n\n\n\nHere is what I consider one of the biggest mistakes of all in modal\nlogic: concentration on a system with just one modal operator. The\nonly way to have any philosophically significant results in deontic\nlogic or epistemic logic is to combine these operators with: tense\noperators (otherwise how can you formulate principles of change?); the\nlogical operators (otherwise how can you compare the relative with the\nabsolute?); the operators like historical or\nphysical necessity (otherwise how can you relate the agent to\nhis environment?); and so on and so on. —Scott\n(1970: 161)\n\n\n\nConsider the following seemingly possible situation: \n\n\n\n\nAnn believes that Bob assumes that \\(\\underbrace{\\textit{Ann\nbelieves that Bob’s assumption is wrong.}}_{\\varphi}\\) \n\n\n\n\nNow, here is a tricky question: is \\(\\varphi\\) (“Ann\nbelieves that Bob’s assumption is wrong”) true or\nfalse? Paraphrasing Pacuit and Roy (2017:\n Section 6),\n suppose \\(\\varphi\\) is true. So, what \\(\\varphi\\) represents is true,\nthat is, Ann believes that Bob’s assumption is wrong. Moreover,\nby belief introspection, she believes that “she believes\nBob’s assumption is wrong”, that is, she believes\nBob’s assumption. But the description of the situation tells us\nthat Ann believes that Bob assumes \\(\\varphi\\); then, in fact, Ann\nbelieves that Bob’s assumption is correct. Thus, \\(\\varphi\\),\n“Ann believes that Bob’s assumption is\nwrong”, is false.\n\n\nHence, \\(\\varphi\\) must be false. Then, following Pacuit and Roy\n(2017:\n Section 6)\n again, Ann believes that Bob’s assumption is correct, that is,\nAnn believes \\(\\varphi\\) is correct. Furthermore, the description of\nthe situation states that “Ann believes that Bob assumes\nthat Ann believes that Bob’s assumption is wrong”,\nwhich, given that \\(\\varphi\\) is Bob’s assumption, can be\nrewritten as “Ann believes that Bob assumes that Ann\nbelieves that \\(\\varphi\\) is wrong”. But then, not only Ann\nbelieves that she believes that \\(\\varphi\\) is correct; she also\nbelieves that Bob assumption is that she believes that \\(\\varphi\\) is\nwrong. Thus, it is the case that she believes Bob’s assumption\nis wrong (Ann believes that Bob’s assumption is that she\nbelieves that \\(\\varphi\\) is wrong, but she believes that is wrong:\nshe believes that \\(\\varphi\\) is correct). So, \\(\\varphi\\) is\ntrue.\n\n\nSome readers may wonder, why do I need to know whether Ann\nbelieves that Bob’s assumption is wrong? One of the reasons\nis that, just as\n Russell’s paradox\n suggests that not every collection can constitute a set, this\nsituation, known as the Brandenburger-Keisler Paradox\n(Brandenburger & Keisler 2006), suggests that not every\ndescription of beliefs can be ‘represented’. Now, with a\nbetter motivation, one may wonder again: is \\(\\varphi\\) true or false?\nOr, maybe better, is there a formal setting that gives an answer?\n\n\nIt becomes immediately clear that no system involving a single\nmodality can deal with this situation, as the description includes not\nonly two agents (so, at least two modalities would be required), but\nalso two different concepts: beliefs and\nassumptions. Thus, to make formal sense of this situation,\none requires a system that allows us to deal not only with different\nattitudes, but also with the complex relationship between them. To\nmake formal sense of this (and other similar) situation(s), one\nrequires a multi-modal system.\n\n\n\n\nModal logics are particularly well suited to study a wide range of\nphilosophical concepts, including rational beliefs, obligations,\nknowledge, intentions, desires, evidence and preferences, among many\nothers. Such an analysis provides us with the key insights of the\nbasic building blocks and principles that regulate different\nbehaviors, which is important in a wide range of academic disciplines\nincluding Artificial Intelligence, Psychology, Social Science and even\nPhysics. The concepts we look at have specific context-dependent\nfeatures, which indicates that they can be best studied using models\nthat can express different modes of truth (e.g., both global and local\ntruth). But as Scott’s (1970) quote above suggests, there is\nsomething missing when such philosophical concepts are studied in\nisolation. A big part of what defines a concept lies in the way it\ninteracts with others. For instance, rational beliefs are\nexpected to rely on proper arguments, justifications\nor evidence; disjunctions may not behave as they do\nin natural language in the context of obligations;\nknowledge is better understood when looking for the\nactions that modify it; intentions may be understood\nas derived from desires and beliefs. What is\nrequired for this study are logical systems with more than one modal\noperator, commonly known as multi-modal logics, describing not only\nthe isolated properties of the individual concepts, but also the way\nthey relate to one another. Indeed, multi-modal logics have been\ndesigned for a wide range of applications, including reasoning about\ntime, space, knowledge, beliefs, intentions, desires, obligations,\nactions such as public and private communication, observations,\nmeasurements, moves in a game and others. \nThe present text intends to give a brief (but broad) overview of the\ninteraction between many different philosophical concepts, and to show\nhow the use of multi-modal logical systems can shed some light on\nthese concepts’ interaction. We start in\n section 2\n (Defining concepts in terms of others) by discussing basic\nscenarios that, starting from existing systems, use a combination of\n‘syntactic’ and ‘semantic’ strategies for\ndefining further concepts. These cases are based on the idea that some\nnotions can be defined in terms of others, with the famous\nunderstanding of knowledge as justified true belief being one of the\nmost notable examples. An alternative to this idea is to consider that\nthe involved concepts emerge independently, but are still somehow\nrelated, as the case of the relationship between knowledge and time.\nFrom a formal perspective, this amounts to looking at the different\nmodes in which two (or more) existing systems can be combined.\n Section 3\n on General strategies for combining modal systems presents\nan overview of some of the most relevant strategies. After this\nslightly technical excursion, the discussion takes a philosophical\nperspective, describing first combinations of multiple modalities\n (section 4\n on Significant interactions between modalities), and\nfinishing with examples of cases where the interaction between\nmodalities sheds light on philosophical issues\n (section 5\n on Multi-modal systems in philosophical discussions). \nA note on notation and the level of\ntechnicality To discuss aspects of multi-modal logic, this\nentry assumes basic knowledge of\n modal logic,\n specifically about its language and its relational\n ‘possible worlds’\n semantics (though other semantic models will be mentioned too). In\nparticular, a relational model is understood as a tuple containing a\nset of possible worlds, one or more (typically binary) relations\nbetween them, and a valuation indicating what each possible\nworld actually represents. Such structures can be described by\ndifferent modal languages. We will use \\(\\cL\\) to denote the standard\npropositional language, and \\(\\cL_{\\left\\{ O_1, \\ldots, O_n\n\\right\\}}\\) to denote its extension with modalities \\(O_1\\), …,\n\\(O_n\\). Given a relational model M and a formula \\(\\varphi\\),\nwe will use \\(\\llbracket \\varphi \\rrbracket^{M}\\) to denote the set of\nworlds in M where \\(\\varphi\\) holds. Readers can find more\ndetails about the basics of modal logic not only in the referred SEP\nentries, but also in the initial chapters of Blackburn, Rijke, &\nVenema (2001) and van Benthem (2010), and also in Blackburn & van\nBenthem (2006). \nStill, the goal of this text is not to provide a comprehensive study\nof the topic, but rather to highlight the most interesting and\nintriguing aspects. Thus, although some level of formal discussion\nwill be used, most technical details will be restricted to the\n appendix. \nIn order to use systems with multiple modalities, the question is how\nto build such settings. One of the most important points is to decide\nwhether one of the concepts to be studied is ‘more\nfundamental’ than the other, in the sense that the latter can be\ndefined in terms of the former. As mentioned, the famous understanding\nof knowledge as justified true belief is one of the most notable\nexamples. Others are equally relevant, as a definition of beliefs in\nterms of the available arguments/evidence/justifications, or a\ndefinition of epistemic notions for a group in terms of the epistemic\nnotions of its members. Yet, the basic alethic modal logic of\nnecessity and possibility already provides a paradigmatic example of\nhow to define the relationship between two concepts. \nThe basic alethic modal logic contains both a possibility\n\\((\\Diamond)\\) and a necessity \\((\\Box)\\) modality. Most\nformal presentations of this system take one of these modalities as\nthe primitive syntactic operator (say, \\(\\Diamond)\\), and then define\nthe other as its modal dual \\((\\oBox\\varphi := \\lnot\n\\oDiamond \\lnot \\varphi)\\). This is a seemingly harmless\nsyntactic interdefinability, and comes from the fact that\n\\(\\Diamond\\) and \\(\\Box\\) are semantically interpreted in terms of the\nexistential and universal\n quantifiers,\n respectively. It is, in some sense, similar to\nthe interdefinability of Boolean operators in classic propositional\nlogic. Nevertheless, it already reflects important underlying\nassumptions. From a classic point of view, something is\nnecessary if and only if it is not the case that its negation is\npossible \\((\\oBox\\varphi \\leftrightarrow \\lnot \\oDiamond \\lnot\n\\varphi)\\), and something is possible if and only if it is not the\ncase that its negation is necessary \\((\\oDiamond \\varphi\n\\leftrightarrow \\lnot \\oBox\\lnot \\varphi)\\). However, this may not be\nthe case in all settings. For example, while \\(\\oDiamond \\varphi\n\\rightarrow \\lnot \\Box \\lnot\\varphi\\) is\n intuitionistically acceptable\n (the existence of a possibility where \\(\\varphi\\) holds implies that\nnot every possibility makes \\(\\varphi\\) false), its converse \\(\\lnot\n\\oBox \\lnot\\varphi \\rightarrow \\oDiamond \\varphi\\)\n is not\n (the fact that not every possibility makes \\(\\varphi\\) false is not\nenough to guarantee the existence of a possibility where\n\\(\\varphi\\) is true). Thus, one should always be careful when defining\na modality in terms of another. \nWhere the above examples started from a uni-modal logic, we provide\nnow an example in which we start from a homogeneous multi-modal logic.\nOur setting is a logic consisting of a number of basic modalities of\nthe same type, all being semantically interpreted via the same type of\nrelation. Our example is the basic multi-agent epistemic\nlogic. This setting is already multi-modal, as its language\n\\(\\cL_{\\left\\{ \\oK{1}, \\ldots,\\oK{n} \\right\\}}\\) has a knowledge\nmodality \\(K_i\\) for each agent \\(i \\in \\ttA\\). (In fact, this basic\nmulti-agent epistemic logic is the fusion\n (section 3.1)\n of several single-agent epistemic logic systems, one for each agent\n\\(i \\in \\ttA\\).) Still, when the set of agents is finite (say,\n\\(\\left| \\ttA\\right| = n)\\), one can define a brand new modality for\nthe group epistemic notion of everybody knows: \nIn a similar way we can define a modality for everybody\nbelieves in the logic with language \\(\\cL_{\\left\\{ \\oB{1},\n\\ldots, \\oB{n} \\right\\}}\\) as \nThese definitions assume that the knowledge/beliefs of a group of\nagents corresponds to the conjunction of the agent’s individual\nknowledge/beliefs. However, in the context of\n social epistemology,\n the reduction of group attitudes to the mere sum of those of the\nindividuals is contentious, especially when one focuses on group\n beliefs.[1] \nAnother example of the interdefinability of modal concepts deals with\nthe relationship between knowledge and belief. In\n epistemology,\n researchers are searching for the correct characterization of\nknowledge, and a common trend has been to view knowledge as a form of\n justified true belief\n (an idea that can be traced back to Plato’s dialogue\nTheaetetus). Gettier’s\n famous counterexamples\n showed that such a simple characterization of knowledge is not\nsufficient: a further condition is required, such as safety,\nsensitivity, robustness or stability. In spite of this, a\ncharacterization of knowledge as justified true belief is an important\nfirst step. Classic\n epistemic logic\n does not explicitly deal with the notion of\n justification,[2]\n so a starting point is a simpler understanding of knowledge as true\nbelief. \nOne can take a doxastic relational model with its relation\n\\(R_B\\) being serial, transitive and Euclidean (a KD45\nsetting), and use a modality B semantically interpreted with\nrespect to \\(R_B\\) in the standard way. In this setting, two options\narise. The first one is syntactic, as in the examples that\nhave been discussed so far, and consists in defining a modality for\nknowledge as ‘true belief’: \\(K'\\varphi := B\\varphi\n\\land \\varphi\\). The second is semantic, and consists in\ndefining an epistemic equivalence relation \\(R_K\\) as the reflexive\nand symmetric closure of the doxastic relation, then using it in the\nstandard way to give the semantic interpretation of a modality\nK. \nIt should be noted that the two approaches are not equivalent.\nConsider the following doxastic model (from Halpern, Samet, &\nSegev 2009a), with the serial, transitive and Euclidean\ndoxastic relation \\(R_B\\) represented by dashed arrows, and\nits derived reflexive, transitive and symmetric (i.e., equivalence)\nepistemic relation \\(R_K\\) represented by solid ones. \nFigure 1 [An\n extended description of figure 1\n is in the supplement.] \nNote how the agent believes p on every world in the model,\n\\(\\llbracket \\oB{}p \\rrbracket^{M} = \\left\\{ {w_1, w_2, w_3}\n\\right\\}\\); then, as the syntactic approach states that\n\\({K'\\varphi}\\) holds in those worlds in which \\(B\\varphi \\land\n\\varphi\\) is the case, we have \nHowever, according to the semantic approach, \\(K\\varphi\\) holds in\nthose worlds from which all epistemically accessible situations\nsatisfy \\(\\varphi\\), so \\(\\llbracket K p \\rrbracket^{M} = \\left\\{ w_1\n\\right\\}\\). Thus, \\({K'}\\) and K are not equivalent. One of\nthe reasons for this mismatch is that the two options do not enforce\nthe same properties on the derived notion of knowledge. For example,\nwhile the semantic approach enforces negative introspection (by making\n\\(R_K\\) an equivalence relation), the syntactic one does not. In fact,\nthis property fails at \\(w_3\\), as \\(\\lnot {K'p}\\) is true \\(({B\np} \\land p\\) fails, as p fails) but still\n\\(K'\\lnot{K'p}\\) (unfolded as \\({B (\\lnot {B p} \\lor \\lnot p)}\n\\land (\\lnot B p \\lor \\lnot p))\\) is\n false.[3] \n\n Section 4.1\n comes back on the relationship between these two concepts, recalling\nalternative multi-modal accounts that relate knowledge and belief\nwhile doing justice to the involved epistemological subtleties. \nThe second option in the previous case is, as described, semantic: it\ntakes the semantic counterpart of an existing modality(ies), and then\nextracts from it (them) a further semantic component in terms of which\na new modality can be defined. Here are two further examples of this\nstrategy. \nConsider again the basic multi-agent epistemic logic with language\n\\(\\cL_{\\left\\{ \\oK{1}, \\ldots, \\oK{n} \\right\\}}\\). As mentioned above,\nthis setting is multi-modal, as its language contains, for each agent\n\\(i \\in \\ttA\\), a knowledge modality \\(K_i\\) that is semantically\ninterpreted in the standard way with respect to a matching epistemic\nrelation \\(R_i\\). While a modality for the concept of everybody\nknows (E) is syntactically definable (provided the set of\nagents is finite), other group epistemic notions, such as distributed\nknowledge and common knowledge are\n not.[4] \nConsider first the notion of distributed knowledge,\nunderstood as describing what the agents would know if they shared all\ntheir information. From this intuitive definition, it is clear that\nthis concept can be defined semantically in terms of the agent’s\nindividual epistemic relations. More precisely, a relation describing\nthe distributed knowledge modality should correspond to the\nintersection of the individual epistemic relations, \\(R_D :=\n\\bigcap_{i \\in \\ttA} R_i\\). Thus, given an evaluation point w,\na world u will be considered possible after the agents share\nall they know if and only if all of them considered it possible before\nthe communication (or, in other words, u will be considered\npossible if and only if no one can discard it). One simply\nextends the language with a modality D, semantically\ninterpreted with respect to this new relation: \nAnother important notion, crucial in the study of social interaction,\nis\n common knowledge.\n This concept can be described as what everybody knows, everybody\nknows that everybody knows, everybody knows that everybody knows that\neverybody knows, and so on. Just as with distributed knowledge, this\nnotion does not require the addition of further semantic components:\nthe individual epistemic indistinguishability relations already\nprovide everything that is needed to make the definition explicit. If\none defines an epistemic relation for the “everybody\nknows” modality in the natural way \\((R_E := \\bigcup_{i \\in\n\\ttA} R_i)\\), and then define \\(R_C\\) as the transitive closure of\n\\(R_E\\), \none can simply extend the language with a modality C,\nsemantically interpreted in terms of \\(R_C\\): \nAt world w a formula \\(\\varphi\\) is commonly known among the\nagents if and only if \\(\\varphi\\) is the case in every world\n(the “for all” in C’s semantic\ninterpretation) that can be reached by any finite non-zero\nsequence of transitions in \\(R_E\\) (the fact that \\(R_C\\) is the\ntransitive closure of \\(R_E)\\). In other words, \\(\\varphi\\) is\ncommonly known among the agents if and only if everybody knows\n\\(\\varphi\\) (any sequence of length 1), everybody knows that everybody\nknows \\(\\varphi\\) (any sequence of length 2), and so\n on.[5] \nThere are more elaborated examples of frameworks extending a given\nsetting with modalities that ‘extract’ further information\nfrom the semantic model. One of them is evidence logic,\nintroduced in van Benthem & Pacuit (2011), and further developed\nin van Benthem, Fernández-Duque, & Pacuit (2014) and\nBaltag, Bezhanishvili, et al. (2016). It follows the idea of\nrepresenting the evidence the agent has collected, and looks at how\nthis evidence gives support to further epistemic notions (e.g.,\nknowledge and beliefs).  The semantics is given by a basic\nneighborhood model (Montague 1970; Scott 1970): a tuple of the form\n\\(M = {\\langle W, N, V \\rangle}\\) where W and V are a\nnon-empty set of possible worlds and an atomic valuation, respectively\n(as in standard relational models), and \\(N:W \\to {\\wp(\\wp(W))}\\) is a\nneighborhood function assigning, to every possible world, a set of\nsets of possible worlds (so \\(N(w) \\subseteq {\\wp(W)}\\) is\nw’s neighborhood). In evidence logic, the\nneighborhood function is assumed to be constant (i.e., \\(N(w) = N(u)\\)\nfor any \\(w,u \\in W)\\), and thus the model can be simply understood as\na tuple \\({\\langle W, E, V \\rangle}\\), with \\(E \\subseteq {\\wp(W)}\\)\nthe (constant) neighborhood. This neighborhood, intuitively containing\nthe basic pieces of evidence the agent has collected, is required to\nsatisfy two additional properties: evidence per se is never\ncontradictory \\((\\emptyset \\not\\in E)\\), and the agent knows her\n‘space’ \\((W \\in E)\\). \nSyntactically, a neighborhood model can be described by a modal\nlanguage \\(\\cL_{\\left\\{ \\oBox \\right\\}}\\), as is typically done in\nstandard neighborhood models. There are at least two possibilities for\nthe semantic interpretation of the \\({\\oBox}\\) modality (Areces &\nFigueira 2009), and the one chosen in evidence logic is the\nfollowing: \nThus, in this setting, \\({\\oBox\\varphi}\\) expresses that “the agent has evidence\nsupporting \\(\\varphi\\)”. \nWhat is the epistemic state of the agent that such a model entails? In\nother words, given such a model, how can we define epistemic notions\nsuch as knowledge and belief? \nIn the case of knowledge, one can follow the traditional single-agent\nidea: all worlds in the model play a role in the agent’s\nepistemic state, and thus one can say that the agent knows a\ngiven formula \\(\\varphi\\) if and only if \\(\\varphi\\) is true in every\nworld of the model. For this, evidence logic uses a global\nmodality A: \nIn the case of beliefs, there are more alternatives. A straightforward\nidea says that the agent believes \\(\\varphi\\) if and only if she has\nevidence supporting \\(\\varphi\\) (a syntactic definition of the form\n\\(B\\varphi := \\oBox\\varphi)\\). However, this would allow the agent to\nhave contradictory beliefs, as two pieces of evidence might contradict\nthemselves (there may be \\(X, Y \\in E\\) such that \\(X \\cap Y =\n\\emptyset\\), and thus \\(Bp \\land B{\\lnot p}\\) could be satisfiable).\nMore importantly, this would be a ‘lazy’ approach, as the\nagent would be able to collect evidence (thus defining E), but\nnevertheless she would not be doing any ‘reasoning’ with\nit. \nA more interesting idea is to define (semantically) a notion of belief\nin terms of combinations of pieces of evidence. In van\nBenthem and Pacuit (2011), the authors propose (roughly speaking) that\nbeliefs should be given by the maximal consistent ways in\nwhich evidence can be combined, stating that the agent believes\n\\(\\varphi\\) if and only if all maximally consistent\ncombination of pieces of evidence support \\(\\varphi\\). More\nprecisely, \nGiven these definitions, it is clear that knowledge implies both\nbelief and evidence (i.e., both \\(A\\varphi \\rightarrow B\\varphi\\) and\n\\(A\\varphi \\rightarrow \\oBox\\varphi\\) are valid). Still, it is\ninteresting to note not only that the agent might believe a given\n\\(\\varphi\\) without having a basic piece of evidence supporting it\n\\((B \\varphi \\rightarrow \\oBox\\varphi\\) is NOT valid, as\nbeliefs are defined in terms of combined pieces of evidence),\nbut also that she might have a basic piece of evidence supporting\n\\(\\varphi\\) without believing \\(\\varphi\\) \\((\\oBox\\varphi \\rightarrow\nB\\varphi\\) is NOT valid, as the basic evidence supporting\n\\(\\varphi\\) not be part of all maximally consistent combinations). \nIn this setting, at least when E is finite (and in many other\ncases), beliefs are consistent (i.e., \\(\\neg B \\bot)\\); still, the\nsetting also allows ‘bad’ models in which beliefs can turn\nout to be inconsistent. In Baltag, Bezhanishvili, et al. (2016), the\nauthors provide an example of such a model, and then solve the problem\nby extending the setting to a topological approach. Indeed, the\nauthors use the topology generated by E, which\nintuitively describes the different ways in which the available pieces\nof evidence can be\n combined.[6]\n This is reasonable as, while E can be understood as containing\nthe pieces of evidence the agent has received from external sources\n(observations, communication), the topology \\(\\tau_{E}\\) can be\nunderstood as the different ways in which she can\n‘extract’ further information from them (i.e., the result\nof her own reasoning processes). Given the topology, it is possible to\ndefine (semantically) further epistemic notions, such as arguments,\njustifications, consistent beliefs, consistent conditional beliefs,\nand different forms of knowledge. For more on this, we refer to\nBaltag, Bezhanishvili, et al. (2016: Section 2). \nAs we have seen, a new modality can be introduced in syntactic terms\n(using the language to provide a formula defining the new concept),\nbut also in a semantic way (using the semantic counterparts of the\nexisting modalities to define a further semantic notion, which in turn\nis used to interpret the new modality). Our examples so far have been\nrestricted to the use of one of these two strategies, but their\ninterplay is also possible. The case to be discussed here concerns the\n plausibility models\n of Board (2004); Baltag and Smets (2006, 2008); van Benthem (2007);\nhere, the presentation of Baltag and Smets (2008) is used. \nA plausibility model is a relational model \\(M = {\\langle W, \\leq, V\n\\rangle}\\) in which the binary relation \\(\\leq\\) is interpreted as\ndescribing the plausibility ordering the agent assigns to her\nepistemic possibilities \\((w \\leq u\\) indicates that, for the agent,\nworld w is at least as plausible as world u). In the\nsingle-agent case, the plausibility relation \\(\\leq\\) is\nrequired to be a well-preorder: a total relation which is\nboth reflexive and transitive, and such that every non-empty subset of the\ndomain has \\(\\leq\\)-minimal elements. These minimal elements in W are\nthen understood as the agent’s most plausible worlds.\nWe see below that what is true in all the most plausible worlds\ncharacterizes what an agent believes. \nTo start, take a modality \\([\\leq]\\) semantically interpreted via the\nplausibility relation \\(\\leq\\), \nThis modality has the properties of an S4 modal operator; hence, it is\nfactive, positively introspective but not negatively introspective. In\nBaltag and Smets (2008), it is argued that this modality is well\nsuited to express a version of Lehrer’s indefeasible\n(“weak”, non-negatively-introspective) type of\nknowledge (Lehrer 1990; Lehrer & Paxson 1969), and the\nauthors explain how it can be understood as belief that is persistent\nunder revision with any true piece of information. Using this\nmodality (also read as safe belief in Baltag & Smets\n2008), it is possible to define syntactically a notion of simple\nbelief as truth in the most plausible worlds:  \nAs simple as a plausibility model is, it is powerful enough to encode\na wide range of different epistemic concepts, all of which can be\nbrought to light by the proper semantic definitions. First, we define\na relation of epistemic possibility (or indistinguishability)\n\\(\\sim\\) by taking it to be the universal relation, \nthus understanding that two worlds are epistemically indistinguishable\nif and only if they can be compared via\n \\(\\leq\\).[7]\n Then, a notion of S5-knowledge can be expressed by introducing a\nmodality K semantically interpreted via \\(\\sim\\): \nWith this new modality K it is possible to define,\nsyntactically, the finer notion of conditional belief\n\\(B^{\\psi}\\), intuitively describing what the agent would have\nbelieved was true had she learnt that a certain condition \\(\\psi\\) is\nthe case. Indeed, \nfor \\({\\hK}\\) the modal dual of K (i.e., \\(\\hK\\psi := \\lnot\nK\\lnot \\psi)\\). This extended language \\(\\cL_{\\left\\{ [{\\leq}], K\n\\right\\}}\\) can also express a notion of strong belief, \\(Sb\n\\varphi\\), semantically understood as true whenever all\n\\(\\varphi\\)-worlds are strictly more plausible than all\n\\(\\lnot\\varphi\\)-worlds, and syntactically defined as  \nFinally, note how a plausibility relation defines, semantically,\nlayers or spheres of equally-plausible worlds, with the spheres\nthemselves ordered according to their plausibility so that every\nstrong belief characterizes one of the spheres. This will turn every\nplausibility model into a sphere model (Grove 1988; Spohn 1988),\nmaking it perfectly fit to model\n belief revision.\n Still, even though in \\(\\cL_{\\left\\{ [{\\leq}], K \\right\\}}\\) there\nare formulas expressing that \\(\\varphi\\) holds in the most\nplausible sphere (the mentioned \\(B\\varphi\\), given by\n\\(\\langle{\\leq}\\rangle[{\\leq}]\\varphi)\\), no formula can express,\ne.g., that \\(\\varphi\\) holds in the next to most plausible\nworlds. One way to fix this ‘problem’ is to define (now\nsemantically) the strict plausibility relation \\({<} :=\n{\\leq} \\cup {\\not\\geq}\\) (with \\(\\geq\\) the converse of\n\\(\\leq\\), defined in the standard way, \\({\\geq} := \\left\\{ (u,w) \\in W\n\\times W \\mid w \\leq u \\right\\})\\), and then introduce a standard\nmodality for it: \nWith this new modality, one can provide syntactic definitions for the\nconcepts described above. Indeed, while the formula \\(\\lambda_0 :=\n[<]\\bot\\) characterizes the most plausible worlds (so \\(K\n(\\lambda_0 \\rightarrow\\varphi)\\) expresses that the most plausible\nworlds satisfy \\(\\varphi\\), just as \\(B\\varphi\\) does), the formula\n\\(\\lambda_1 := \\lnot \\lambda_0 \\land [<]\\lambda_0\\) characterizes\nthe next to most plausible worlds (so \\(K(\\lambda_1\n\\rightarrow\\varphi)\\) expresses that the next to most plausible worlds\nsatisfy \\(\\varphi)\\). This procedure can be repeated, producing\nformulas \\(\\lambda_i\\) characterizing each layer, and thus it is\npossible to deal syntactically with a qualitative degree of\nbeliefs (Grove 1988; Spohn 1988), looking for what holds\n‘from some level up’ (see also Velázquez-Quesada\n2017). \nThis new modality \\([<]\\) allows us to define even more\nepistemic notions. For example, a formula \\(\\varphi\\) is weakly\nsafely believed (a belief which might be lost but is never\nreversed when revising with true information) if and only if \\(\\varphi\n\\land [{<}] \\varphi\\) holds. More details can be found in Baltag\nand Smets (2008: Subsection 2.4). \nJust as some multi-modal systems are created by extending existing\nones, some others are born with multiple modalities in mind. Among\nthem,\n propositional dynamic logic\n (Harel, Kozen, & Tiuryn 2000) and Boolean modal logic\n(Gargov & Passy 1990; Gargov, Passy, & Tinchev 1987) deserve a\nspecial mention. The reason is that they both define, within the\nlanguage, operators for building new modalities from a collection of\nbasic ones. As a consequence, both systems contain an\ninfinite number of modalities. \nFollowing earlier approaches to reason about programs in Engeler\n(1967) and Hoare (1969), Propositional dynamic logic (PDL), the logic of\nprograms (Harel, Kozen, & Tiuryn 2000), intends to describe what\nprograms can achieve. Semantically, programs are interpreted in\nstandard relational models, with one binary relation \\(R_a\\) for every\nbasic program a; syntactically, the language contains\na modality \\([a]\\) for each such a. \nSo far, PDL is technically similar to a multi-agent epistemic\nlogic (the difference being, besides the symbols used for the\nmodalities, the fact that there are no restrictions on the relations\nfor the basic\n programs).[8]\n The crucial insight is, however, that basic programs can be\ncomposed in order to create more complex ones: one can think\nof executing one program after another, or repeating some of them a\nnumber of times. Thus, these basic modalities are not enough. For\nthis, a new syntactic entity is created: besides formulas, the\nlanguage of PDL contains a set of basic programs\ntogether with program constructors representing those for\nregular expressions (Kleene 1956). Formally, formulas\n\\(\\varphi\\) and programs \\(\\alpha\\) of the\nPDL-language \\(\\cL_{\\textit{PDL}}\\) are defined\nsimultaneously via mutual recursion as \nwith p an atomic proposition coming from a given set, and\na a basic program coming from a given set. For formulas, the\nintended reading of the Boolean operators is standard, and formulas of\nthe form \\([\\alpha]\\varphi\\) express that “every execution\nof program \\(\\alpha\\) from the current state leads to a state\nsatisfying \\(\\varphi\\)”. For programs, while the basic\nprograms simply represent themselves, “\\(\\varphi \\qbin\\)”\nis a program that ‘does nothing’ when \\(\\varphi\\) is the\ncase but ‘fails’ otherwise (essentially, a test\nfor \\(\\varphi)\\), “\\(\\alpha \\scbin \\beta\\)” represents the\nprogram that results from executing \\(\\alpha\\) and then executing\n\\(\\beta\\) (their sequential composition), “\\(\\alpha\n\\bcup \\beta\\)” represents the program that results from\nexecuting either \\(\\alpha\\) or else \\(\\beta\\) (their\nnon-deterministic choice), and\n“\\({\\alpha^{\\ast}}\\)” represents the program that results\nfrom repeating \\(\\alpha\\) a finite number of times \\((\\alpha\\)’s\niteration). \nWith these program constructors it is possible to build more complex\nprograms. Famous examples are \nThen, it is possible to build formulas as \\(p \\rightarrow [(q \\qbin\n\\scbin a) \\bcup (\\lnot q \\qbin \\scbin b)]r\\) (“if p\nholds, then r will be achieved by choosing between actions\na and b according to whether q holds”)\nand \\(\\lnot p \\rightarrow \\langle a \\scbin (\\lnot q \\qbin \\scbin\na)^{\\ast} \\scbin q \\qbin \\rangle p\\) (“if the desired\nrequirement p is not true yet, it is possible to achieve it by\na repeated execution of a”). \nFor the semantic interpretation, a relation \\(R_\\alpha\\) is required\nfor each program \\(\\alpha\\). However, while the relations \\(R_a\\) for\nbasic programs are arbitrary, those for complex programs should behave\naccording to their intended meaning. The simplest way to obtain this\nis to take the relations for the basic programs, and then\ndefine those for complex programs in an inductive way. This\nand further details about PDL can be found in Troquard and\nBalbiani (2019:\n [Section 2). \nThe Boolean modal logic of Gargov and Passy 1990 and Gargov,\nPassy, and Tinchev 1987) follows a similar strategy. The difference is\nthat, while PDL focuses on constructors for regular\nexpressions (sequential composition, non-deterministic choice, finite\niteration), Boolean modal logic focuses on constructors for the\nBoolean algebra over relations: complement \\((\\bdash)\\), union\n\\((\\bcup)\\) and intersection \\((\\bcap)\\), together with a\n‘global’ constant \\((\\boldsymbol{1})\\). More\nprecisely, \nThe semantic interpretation follows the same steps as in PDL:\nrelations \\(R_a\\) for the basic modalities a are assumed, and\nrelations for complex ones are defined in the expected way (with\n\\({\\boldsymbol{1}}\\) being interpreted with respect to the global\nrelation \\(W \\times W)\\). \nInterestingly, by combining the negation over formulas and the Boolean\ncomplement over relations, it is possible to define the following\noperator (often called window (see Goldblatt 1974; van\nBenthem 1979; Gargov, Passy, & Tinchev 1987): \nWindow is an extremely natural operator that complements the standard\nuniversal modality. Indeed, while formulas of the form\n\\([\\alpha]\\varphi\\) express that all executions of \\(\\alpha\\)\nreach a \\(\\varphi\\)-state, \nformulas of the form \\(\\oubracket{.7em}{\\alpha}\\varphi\\) express that\nall \\(\\varphi\\)-states are reachable by an execution of\n\\(\\alpha\\): \nNot only that: window allows a smooth interaction between the\nconstructors \\(\\bcup\\) and \\(\\bcap\\). As discussed in Blackburn,\nRijke, and Venema (2001: 427),  \n[i]n a sense, the relations are divided into two kingdoms: the\nordinary \\([\\alpha]\\) modalities govern relations built with\n\\(\\bcup\\), the window modalities \\(\\oubracket{.7em}{\\alpha}\\) govern\nthe relations built with \\(\\bcap\\), and the \\(\\bdash\\) constructor\nacts as a bridge between the two realms: \nOf course, many other program constructors can be used. Among them,\none worthy of mention is that for the\n converse\n of a given relation. Modalities for the converse of a relation have\nbeen used in, e.g.,\n tense logic,\n with the ‘past’ modalities (H and P, the universal and existential versions, respectively) interpreted semantically in terms of the converse of the relation used for interpreting the ‘future’ modalities (G and F, respectively). \nThe case of dynamic epistemic logic, the study of modal\nlogics of model change, is of particular interest. In these systems,\nthe relationship between their modalities is special. Here we will\nonly recall the basic notions, referring the reader to the\n SEP entry\n by Baltag and Renne (2016) for an in-depth discussion \nIn a nutshell, a dynamic epistemic logic (DEL)\nframework has two components. The ‘static’ part consists\nof a ‘standard’ modal system: a language including one or\nmore modalities for the one or more concepts under study, together\nwith the semantic model on which the formulas are interpreted. The\n‘dynamic’ part consists of modalities expressing different\nways in which the studied concept(s) might change, with the crucial\ninsight being that these modalities are semantically interpreted not\non the given model, but rather on one that results from\ntransforming the given one in an appropriate way. \nThe discussion here will focus on the paradigmatic DEL case,\n public announcement logic\n (PAL), which studies the interaction of knowledge and public\n communication.[9]\n Syntactically, its language extends the basic epistemic language\n\\(\\cL_{\\left\\{ K \\right\\}}\\) with a modality \\([\\chi{!}]\\) (for\n\\(\\chi\\) a formula of the language), thanks to which it is possible to\nbuild formulas of the form \\([\\chi{!}]\\varphi\\): “after\n\\(\\chi\\) is publicly announced, \\(\\varphi\\) will be the\ncase”. Within this new language \\(\\cL_{\\left\\{ K, {!}\n\\right\\}}\\) it is possible to build formulas describing the\nknowledge the agent will have after a public communication\naction; one example is \\([(p \\land q){!}] Kq\\), expressing that\n“after \\(p \\land q\\) is publicly announced, the agent will\nknow q”. For the semantic interpretation, the public\nannouncement of any given \\(\\chi\\) is taken to be completely\ntrustworthy; thus, the agent reacts to it by eliminating all\n\\(\\lnot\\chi\\) possibilities from consideration. More precisely, given\na model \\(M = {\\langle W, R, V \\rangle}\\) and a formula \\(\\chi \\in\n\\cL_{\\left\\{ K, {!} \\right\\}}\\), the model \\(M_{\\chi{!}} = \\langle\nW_{\\chi{!}}, R_{\\chi{!}}, V_{\\chi{!}} \\rangle\\) is defined as \nNote how, while \\(W_{\\chi{!}}\\) is the set of worlds of the original model\nwhere \\(\\chi\\) holds, \\(R_{\\chi{!}}\\) is the restriction of the\noriginal epistemic relation to the new domain, and so is the new\nvaluation function \\(V_{\\chi{!}}\\). Then, \nThus, \\(\\varphi\\) is the case after \\(\\chi\\) is publicly announced at\nw in M (in symbols, \\((M, w) \\Vdash [\\chi{!}]\\varphi)\\)\nif and only if \\(\\varphi\\) is true at w in the situation that\nresults from \\(\\chi\\)’s announcement (in symbols,\n\\((M_{\\chi{!}}, w) \\Vdash \\varphi)\\) whenever \\(\\chi\\) can actually be\nannounced (in symbols, \\((M, w) \\Vdash\n \\chi)\\).[10]\n Note that the public announcement modality \\([\\chi{!}]\\) is\nintroduced semantically, as its semantic interpretation\nrequires ‘extracting’ further information from the initial\nmodel, just as the intersection of individual epistemic relations is\nused to create the relation for distributed knowledge. Still, it uses\na ‘more advanced’ version of such a strategy: it performs\nan operation over the full model, thus creating a new one in\norder to evaluate formulas that fall inside the scope of the new\nmodality. \nWith the semantic interpretation of \\([\\chi{!}]\\) given, it is now\npossible to answer the crucial question in this setting: what is the\neffect of a public announcement on an agent’s knowledge? Or,\nmore precisely, how is the agent’s knowledge after an\nannouncement related to her knowledge before it? Here is the\nanswer: \nThis validity characterizes the agent’s knowledge after the\naction in terms of the knowledge she had, before the action, about\nthe effects of the action. It tells us that after the public\nannouncement of \\(\\chi\\) the agent will know \\(\\varphi\\),\n\\([\\chi{!}]K\\varphi\\), if and only if, provided \\(\\chi\\) could be\nannounced, ‘\\(\\chi \\rightarrow \\)’, she knew that its\ntruthful public announcement would make \\(\\varphi\\) true, \\(K(\\chi\n\\rightarrow [\\chi{!}]\\varphi)\\). Note how this bridge\nprinciple, relating the two involved modalities, is not\n‘chosen’: it arises as a consequence of the given\ndefinition of what knowledge is (truth in all epistemic possibilities)\nand the given understanding of what a public announcement does\n(discard all possibilities where the announcement fails). \nThe given semantic interpretation of \\([\\chi{!}]\\) also gives rise to\nother validities. Among them, consider the following: \nThese validities, together with the previous one characterizing\n\\([\\chi{!}]K\\varphi\\), are known as the reduction axioms.\nHere is our first twist: a careful look at these formulas reveals that\neach one of them characterizes the truth of an announcement formula\n\\([\\chi{!}]\\varphi\\) (the left-hand side of \\(\\leftrightarrow\\)) in terms of formulas (the right-hand side of \\(\\leftrightarrow\\)) whose sub-formulas appearing under the scope of \\([\\chi{!}]\\) are less complex. Moreover: the formula dealing with atoms eliminates \\([\\chi{!}]\\). Thus, given any concrete formula in \\(\\cL_{\\left\\{ K, {!}\n\\right\\}}\\), successive applications of these axioms will eventually\nproduce a semantically equivalent formula where no\n\\([\\chi{!}]\\) modality appears. This indicates that,\nexpressivity-wise, the public announcement modalities\n\\([\\chi{!}]\\) are not really needed: anything that can be expressed\nwith them can be also expressed by a formula without them. More\nprecisely, for any formula \\(\\varphi\\) in \\(\\cL_{\\left\\{ K, {!}\n\\right\\}}\\), there is a formula\n\\({\\operatorname{tr}(\\varphi)}\\) in \\(\\cL_{\\left\\{ K \\right\\}}\\) such\nthat, for any \\((M, w)\\), \nThis truth-preserving translation, whose precise definition\ncan be found in van Ditmarsch, van der Hoek, and Kooi (2008: Section\n7.4), shows that the public announcement modality can also be seen as\nhaving a syntactic definition: any formula involving\n\\([\\chi{!}]\\) can be rewritten within \\(\\cL_{\\left\\{ K\n \\right\\}}\\).[11]\n Nevertheless, this is not a ‘one line’ translation, as it\nis the case, e.g., for the ‘everybody knows’ modality\nE. The translation is given by a recursive approach,\nwith the modality defined in a different way depending on the formula\none needs to place under its scope. This leads us to the second twist:\nbecause of this recursive definition, even though adding \\([\\chi{!}]\\)\ndoes not increases the language’s expressivity, its addition\ndoes change the properties of the logical system. Indeed, in\n\\(\\cL_{\\left\\{ K, {!} \\right\\}}\\), the rule of uniform\nsubstitution of atomic propositions by arbitrary formulas is not\nvalidity-preserving anymore. Consider the following formula, stating\nthat “after the public announcement of p, the agent\nwill know that p is the case”: \n\n\\[\n\\Vdash [p{!}]Kp.\n\\]\n\n The\nformula is valid: a truthful public announcement of p discards\nworlds from the original model M where p was not the\ncase. Hence, the resulting \\(M_{p{!}}\\) will have only worlds\nsatisfying p, thus making \\(Kp\\) true Now consider the\nformula below, which results from substituting p by \\(p \\land\n\\lnot Kp\\) in the previous validity: \n\n\\[\n[(p \\land \\lnot Kp){!}] K(p \\land \\lnot Kp).\n\\]\n\n The above formula\nstates now that  \nafter the public announcement of “p is true and the\nagent does not know it”, she will know that “p is\ntrue and she does not know it”.  \nThis formula can be equivalently stated (by distributing K over \\(\\land\\) in the sub-formula under the scope of \\([(p \\land \\lnot Kp){!}]\\)) as \nafter the public announcement of “p is true and you\ndo not know it”, the agent will know both that p is true\nand that she does not know it.  \nBut now something is odd: after hearing \\(p \\land \\lnot Kp\\), the\nagent surely should know that p is the case \\((Kp)\\). But then,\nhow is it possible that, at the same time, she knows that she does not\nknow it \\((K\\lnot Kp)\\)? \nThe suspicions are correct: the formula is not valid, and the model\nbelow on the left provides a counter-example. \nFigure 2 [An\n extended description of figure 2\n is in the supplement.] \nIn \\((M, w)\\), the atomic proposition p is the case, but the\nagent does not know it: \\((M, w) \\Vdash p \\land \\lnot Kp\\). Thus, \\(p\n\\land \\lnot Kp\\) can be truthfully announced, which produces the\npointed model \\((M_{(p \\land \\lnot Kp){!}}, w)\\) on the right. Note\nhow w has survived the operation (it satisfies \\(p \\land \\lnot\nKp)\\), but u has not (it does not satisfy \\(p \\land \\lnot Kp\\),\nas it makes p false). In the resulting pointed model, the agent\nindeed knows that p is the case: \\((M_{(p \\land \\lnot Kp){!}},\nw) \\Vdash Kp\\). Nevertheless, she does not know that she does not know\np: \\((M_{(p \\land \\lnot Kp){!}}, w) \\not\\Vdash K\\lnot Kp\\); in\nfact, she knows that she knows p: \\((M_{(p \\land \\lnot Kp){!}},\nw) \\Vdash\n KKp\\).[12] \nRecapitulating, dynamic epistemic logics deal with modal operators for\nmodel operations, thus allowing the explicit representation of actions\nand the way they affect the concept under study. The particular\nrelationship between the ‘static’ concept and the\n‘dynamic’ action can be described by bridge principles\nthat arise naturally, and yet this does not come with an additional\ncost, as the model-operation and dynamic-modality machinery can be\nembedded into the static base logic. This has important repercussions,\nparticularly complexity-wise, as will be discussed in\n section 3.4. \nThe previous section focused on some of the ways one can take a system\nwith a single modality and create a system with multiple modalities\nfrom it. Another alternative to build a multi-modal system is to take\nexisting uni-modal systems, and then put them together by using a\nparticular strategy. This section contains a brief description of some\nof the possible techniques; for a deeper discussion, the reader is\nreferred to the SEP entry on\n combining logics\n by Carnielli and Coniglio (2016). \nThe method of\n fusion\n of modal logics (introduced in Thomason 1984) was developed\nwith the idea of combining relation-based (hence\nnormal) modal logics in both a syntactic way (by putting\ntogether their respective Hilbert-style axiom systems) and a semantic\nway (by taking the relations corresponding to the modality of each\nsystem, and putting them together in a single\n model).[13]\n Although the fusion of modal systems is fairly simple, the\ntransference results that guarantee that properties are\npreserved (e.g., whether the combination of the sound and complete\naxiomatization of the existing systems is indeed sound and complete\nfor the resulting one) are not straightforward (see, e.g., Kracht\n& Wolter 1991, 1997; Fine & Schurz 1996; Schurz 2011). \nWhen this strategy is followed, and leaving technical details aside,\nthe most important decision is the possible introduction of\nbridge principles that link the main modalities of the\nsystems to be combined. Paraphrasing Schurz (1991), a schema\n\\(\\varphi\\) is a bridge principle if and only if it contains\nat least one schematic letter which has at least one occurrence within\nthe scope of the modality of one system and at least one occurrence\nwithin the scope of the modality of the other. (This definition was\ngiven in the context of the David Hume’s discussion on whether\nought can be derived from is; see\n Section 1\n of\n combining logics.) \nIn order to provide a better explanation of this technique, here we\nwill discuss the construction of a simple temporal epistemic logic. On\nthe epistemic side, recall that the basic\n epistemic logic\n system is given, syntactically, by the language \\(\\cL_{\\left\\{ K\n\\right\\}}\\), and semantically, by a relational model. In it, the\nmodality K is semantically interpreted in terms of a binary\nrelation \\(R_K\\). On the temporal side, define the\n‘future’ fragment of the basic\n temporal (tense) logic\n as a system which is syntactically specified by the language\n\\(\\cL_{\\left\\{ G \\right\\}}\\) (with G a universal\nquantification on the future, and F its existential\ncounterpart given by \\(F\\varphi := \\lnot G\\lnot \\varphi)\\), and\nsemantically, by a relational model with \\(R_G\\) as the crucial\nrelation. \nThe fusion of these systems is syntactically specified by the\nlanguage \\(\\cL_{\\left\\{ K, G \\right\\}}\\) (i.e., a language freely\ngenerated by the union of the modalities of \\(\\cL_{\\left\\{ K\n\\right\\}}\\) and \\(\\cL_{\\left\\{ G \\right\\}})\\). Formulas of this\nlanguage are semantically interpreted in relational models of\nthe form \\({\\langle W, R_K, R_G, V \\rangle}\\) such that \\({\\langle W,\nR_K, V \\rangle}\\) is a model for \\(\\cL_{\\left\\{ K \\right\\}}\\) and\n\\({\\langle W, R_G, V \\rangle}\\) is a model for \\(\\cL_{\\left\\{ G\n\\right\\}}\\). For the semantic interpretation, formulas of the new\nlanguage are interpreted in the standard way, with each modality using\nits correspondent relation. With respect to axiom systems, it is\nenough to put together those of the individual logics. \nBut we are not done yet. As mentioned before, the most interesting\npart is the possible inclusion of bridge principles. So, which is the\nproper interaction between\n time and knowledge?\n One might require perfect recall: the agent’s\nknowledge is not decreased over time or, in other words, uncertainty\nat any moment should have been ‘inherited’ from\nuncertainty from the past. This corresponds to the following bridge\nprinciple: \nThis is clearly an idealization, and as such it makes sense only under\ncertain interpretations; still, it might imply more than meets the\neye. Assuming that the agent never forgets the truth-value of an\natomic proposition p might be reasonable; but, what if\n\\(\\varphi\\) is a more complex formula, in particular one involving the\nepistemic modality? For example, take the formula \\(\\lnot Kp \\land\n\\lnot K\\lnot p\\) (“the agent does not know whether\np”), yielding the instance \\(K(\\lnot Kp \\land \\lnot\nK\\lnot p) \\rightarrow GK(\\lnot Kp \\land \\lnot K\\lnot p)\\)\n(“if the agent knows of her ignorance about whether\np, then she will always know about such ignorance”).\nIs this within the expected consequences? \nA related property is that of no learning (the agent’s\nknowledge is not increased over time; in other words, any current\nuncertainty will be preserved). This property corresponds to \nA slight elaboration on these and related properties can be found on\nthe discussion on time and knowledge\n (section 4.2;\n for a deeper study, see Halpern & Vardi 1989; van Benthem &\nPacuit 2006, albeit in a different semantic setting). \nThe fusion method provides a simple yet powerful strategy for adding a\nfurther aspect to an existing modal system by using another already\nexisting system dealing with this further aspect independently.\nIndeed, the discussed example can be seen as adding a\ntemporal aspect to the standard study of the properties of\nknowledge. Besides the traditional epistemic questions (e.g., whether\nknowledge should be positively/negatively introspective), one can also\ndiscuss not only whether knowledge should change, but also the\ndifferent ways in which it might so. \nThis idea of adding a temporal aspect makes sense not only for\nknowledge, but also for other modal concepts. For example, one can\nthink of adding a temporal feature to a modal system for preferences,\nthus discussing different ways in which the preferences of an agent\nmight change over time (and also why they do so, if further\ndynamic machinery is added to talk about actions and\ntheir consequences; Grüne-Yanoff & Hansson 2009; Liu 2011).\nSimilarly, adding a temporal aspect to modal systems of\n deontic logic\n raises interesting concepts and questions, an example being the\nnotion of deontic deadlines, discussed in\n section 4.7 on\n obligations and time. \nThe study of some concepts such as preferences or obligations gives\nraise to an epistemic concern: how much do the involved agents\nknow about such preferences and obligations? In most examples\nwhere such concepts play a role, whether or not the agent knows about\nthe involved preferences or obligations makes an important difference.\nIn case of the first, should an agent act according to her and other\nagents’ preferences, even when she does not know what these\npreferences are? In case of the second, is an agent compelled to obey\na duty even when she does not know what the duty is? \nThe fusion of a basic preference/deontic setting and epistemic logic\nprovides basic formal tools to discuss the epistemic aspects of\npreferences and obligations. For example, consider the\n paradox of epistemic obligation:\n a bank is being robbed (r), and the guards ought to know about\nthe robbery \\((OKr)\\). But knowledge is factive \\((Kr \\rightarrow\nr)\\), so then the bank ought to be robbed \\((Or)\\)! More on these\nconcerns (under different formal systems) can be found within the\ndiscussion on knowledge and obligations\n (section 4.8). \nFor a deeper study on the fusion of modal logics, the reader is\nreferred to Wolter (1998), Gabbay, Kurucz, Wolter, and Zakharyaschev\n(2003: Chapter 4), and Kurucz (2006: Section 2). Further examples of\nfusion can be found\n in the SEP entry\n discussing methods for\n combining logics.\n Still, before closing this subsection, we add a word of caution. One\nneeds to be careful when building the fusion of modal systems. This is\nbecause, in the system that results from the fusion, there are already\nformulas combining the modalities of its different fragments. Then,\neven if no particular bridge (valid) principles are enforced, the\nlanguage might gain in expressive power, which might increase\nits\n complexity\n profile.\n Section 3.4\n on complexity issues elaborates on this important but often forgotten\naspect. \nThe fusion of modal systems produces a rich language that allows us to\nexpress the different ways in which the involved modalities interact\n(the bridge principles). Still, from a semantic perspective, there is\nstill just one point of reference, as all formulas of this\nricher language are still evaluated on a single possible world. \nThe strategy of defining a\n product\n of modal logics (introduced in Segerberg 1973 and Šehtman\n1978) shares the idea of using a language that is freely generated by\nthe union of the modalities of the original languages. But, on the\nsemantic side, the approach is quite different: instead of working on\na one-dimension domain, it works on a multi-dimensional\ndomain that has one dimension for each one of the involved aspects\n(i.e., modalities). More precisely, if the semantic models of the\nto-be-combined systems are \\(M_1 = {\\langle W_1, R_1, V_1 \\rangle}\\)\nand \\(M_2 = {\\langle W_2, R_2, V_2 \\rangle}\\), the models where\nformulas of the resulting language are evaluated are now of the form\n\\(M' = {\\langle W_1 \\times W_2, R'_1, R'_2, V_1 \\times V_2\n\\rangle}\\). The domain \\(W_1 \\times W_2\\) is, then, the standard\nCartesian product of the original domains, and the valuation \\(V_1\n\\times V_2\\) is such than an atom p is true in a world \\((w_1,\nw_2)\\) if and only if p was true at \\(w_1\\) in \\(M_1\\) and also\ntrue at \\(w_2\\) in \\(M_2\\) (i.e., \\((V_1 \\times V_2)(p) := V_1(p)\n\\times V_2(p))\\). For the relations, each one of them is given as in\ntheir original models, restricted now to their respective dimensions:\n \nThe product of modal logics is a many-dimensional modal logic\n(Gabbay et al. 2003; Marx & Venema 1997; Venema 1992). Within\nthese models, formulas are now evaluated in pairs \\((w_1, w_2)\\), with\neach modality semantically interpreted in the standard way (but now\nwith respect the new version of its matching relation): \nThis specific way of interpreting each one of the original modalities\nyields another crucial difference between the fusion and the product\nof modal systems: the latter enforces, by its own nature, certain\nbridge principles (on top of those that might be added). Indeed,\nbecause of the definition of the relations and the modalities’\nsemantic interpretation, the following schemas are valid: \nThe product of modal systems, with its n-dimensional nature, is\na very useful tool and, in particular, it has been of help for dealing\nwith the philosophical semantics technique of\n two-dimensionalism\n (see also Chalmers 2006; Stalnaker 1978). This technique has been\napplied in different fields. In linguistics, it is the basis of David\nKaplan’s semantic framework for\n indexicals\n (Kaplan 1989), which in turn has been used to explain conventional\nsemantic rules governing context-dependent expressions as\n‘I’ and ‘now’. Consider, for\nexample, a setting built to talk about the features of a group of\nfriends at different times; the context in which formulas will be\nevaluated can be defined as a tuple \\((w, a, m)\\), with \\(w \\in W\\) a\npossible world, \\(a \\in \\ttA\\) an agent within that world and \\(m \\in\nT\\) a moment in time when the agent exists in that world. Then, a\nsentence of the form “I am tired now” corresponds\nsimply to an atom “tired”, with its truth-value\nbeing potentially different in different contexts, depending on\nwhether, in the given world w, the given agent a is\ntired at the given moment m. Moreover: suppose the setting contains an alethic possibility relation between worlds \\((R \\subseteq W \\times\nW)\\), a friendship relation between agents \\(({\\asymp}\n\\subseteq \\ttA\\times \\ttA)\\) and a temporal future relation\nbetween moments \\((R_G \\subseteq T \\times T)\\). Then, one can use matching modalities (the universal ones, \\(\\oBox\\) and \\([\\asymp]\\), for the first two; the existential one \\({F}\\) for the third) to express sentences as “I have a friend who is playing right now and necessarily will be tired at some moment later” \\((\\langle \\asymp\\rangle(\\textit{playing} \\land\n\\oBox F\\textit{ tired}))\\) and “if one of my friends is\nplaying now, all of them might be playing later”\n\\((\\langle\\asymp\\rangle \\textit{playing} \\rightarrow \\Diamond\nF[\\asymp]\\textit{playing})\\). \nIn philosophy of mind, two-dimensional semantics has been used by\nDavid Chalmers (combining both epistemic and modal domains) to provide\narguments against materialism in philosophy of mind (details\ncan be found in Chalmers 2009). \nA final example of the product of two modal logics (though not\noriginally conceived as such, and presented in a slightly different\nway), is the Facebook Logic of Seligman, Liu, & Girard\n(2011, 2013), useful for talking about friends and social information\nflow. The setting can be seen as the combination of a standard\nsingle-agent epistemic logic and a modal logic for social networks\n(cf. Baltag, Christoff, Rendsvig, & Smets 2019; Smets &\nVelázquez-Quesada 2017). Its semantic model consists on two\ndomains (possible worlds W, agents \\(\\ttA)\\) and two relations:\na binary epistemic relation \\({\\sim_a} \\subseteq (W \\times W)\\) for\neach agent \\(a \\in \\ttA\\), and a binary friendship relation\n\\({\\asymp_w} \\subseteq (\\ttA\\times \\ttA)\\) for each world \\(w \\in W\\).\nOn the syntactic side, the language is freely generated by the\nstandard Boolean operators and two universal modalities, K\n(knowledge) and \\([\\asymp]\\) (friendship). These formulas are\nevaluated in pairs (world, agent), with the key\nclauses being the following: \nNote that the modalities are indexical in both the world\nand the agent. Thus, while formulas of the form \\(K\\varphi\\)\nare read as “I know \\(\\varphi\\)”, formulas of the\nform \\([\\asymp]\\varphi\\) are read as “all my friends satisfy\n\\(\\varphi\\)”. \nThe given examples show how the product strategy can be used to\n‘temporalize’ and/or ‘epistemize’ a given\nmodal system (Kaplan’s semantic framework can be understood as\nthe temporalization of an alethic system, and the described\nFacebook Logic can be understood as the\n‘epistemization’ of a social network setting). For more on\nthe products of modal logics, the reader is referred to the\nalready-mentioned\n combining logics,\n and also to Gabbay et al. (2003: Chapter 5), Kurucz (2006: Section\n3) and van Benthem, Bezhanishvili, et al. (2006). \nThe strategies of fusion and product for combining modal logics rely\nin merging both the languages and the semantic models of the modal\nlogics to be combined. In the\n fibring\n strategy (called fibring by functions in Carnielli,\nConiglio, et al. 2008), the languages are also merged, but the\nsemantic models remain separated. Formulas can be evaluated in pointed\nmodels of any of the original systems, in the following way. When the\nmodality to be semantically evaluated ‘matches’ the chosen\nsemantic model, the evaluation is done as in the original system; when\nthe modality comes from the other system, the fibring strategy uses a\ntransfer mapping to obtain a model and an evaluation point in\nthe class of models for the modality under evaluation, and then the\nevaluation proceeds as in the original system. Thus, modal fibring\nrequires a correspondence between the class of models of each one of\nthe systems, and uses it to move between them when the modality under\nevaluation requires it. \nMore precisely, let \\(\\cL_{\\left\\{ \\Box_{1} \\right\\}}\\) and\n\\(\\cL_{\\left\\{ \\Box_{2} \\right\\}}\\) be the languages of the system to\nbe combined, and let \\(\\cM_1\\) and \\(\\cM_2\\) be their correspondent\nclasses of models. Let \\(h_1\\) be a transfer mapping,\ntaking a world of any model in \\(\\cM_1\\), and returning a pair\nconsisting of a model \\(M_2\\) in \\(\\cM_2\\) and a world \\(w_2\\) in\n\\(M_2\\); let \\(h_2\\) be a transfer mapping in the other\ndirection, taking a world of any model in \\(\\cM_2\\), and returning a\npair consisting of a model \\(M_1\\) in \\(\\cM_1\\) and a world \\(w_1\\) in\n\\(M_1\\). Formulas of the language \\(\\cL_{\\left\\{ \\Box_{1}, \\Box_{2}\n\\right\\}}\\) can be evaluated in either tuples of the form \\(\\langle\nh_1, h_2, M_1, w_1 \\rangle\\) (with \\(w_1\\) in \\(M_1 = \\langle W_1,\nR_1, V_1 \\rangle\\) and \\(M_1\\) in \\(\\cM_1)\\) or else tuples of the\nform \\(\\langle h_1, h_2, M_2, w_2 \\rangle\\) (with \\(w_2\\) in \\(M_2 =\n\\langle W_2, R_2, V_2 \\rangle\\) and \\(M_2\\) in \\(\\cM_2)\\). In the\nfirst case, the semantic interpretation of Boolean operators is as\nusual; for the modality \\(\\Box_{1}\\), \nThus, modalities ‘matching’ the model are evaluated as in their original systems. Then, for the modality \\(\\Box_{2}\\) of the\nother system, the transfer mapping \\(h_1\\) is used: \nIn other words, when \\(\\Box_{2}\\) needs to be evaluated, the transfer\nmapping uses current evaluation point \\(w_1\\) to obtain a pointed\nsemantic model \\(h_1(w_1) = (M_2, w_2)\\) where the modality will be\nevaluated. When the analogous situation arises, facing the evaluation\nof \\(\\Box_{1}\\) on a tuple \\(\\langle h_1, h_2, M_2, w_2 \\rangle\\), it\nis the turn of the second transfer function \\(h_2\\) to make its\nappearance, taking us then from \\(\\langle h_1, h_2, M_2, w_2 \\rangle\n\\Vdash \\Box_{2}\\varphi\\) to \\(\\langle h_1, h_2, h_2(w_2) \\rangle\n\\Vdash \\Box_{2}\\varphi\\). \nFor more details on the fibring of modal logics, the reader is\nreferred to Gabbay (1999: Chapter 3). For other forms of fibring, see\n Section 4.3\n of\n combining logics. \nSo far, this text has described different ways in which a multi-modal\nsystem can emerge. We have briefly discussed how a single modal system\ncan give rise to a multi-modal one by providing either syntactic or\nsemantic definitions of new concepts\n (section 2),\n and also how two or more modal systems can be combined in order to\nproduce a multi-modal one\n (section 3).\n As the provided examples have shown (and the examples in\n section 4\n will continue to do), the addition of modalities allows us to\nestablish and/or find significant relationships between the involved\nconcepts, thus providing a better understanding of what each one of\nthem is. \nBut there is also another side to this coin. By adding modalities to a\nsystem, one increases its expressivity, but this may also have the\nundesirable consequence of raising its\n computational complexity.\n Indeed, a modal language allows us to describe a certain class of\nmodels. If the language is fairly simple, then deciding whether a\ngiven formula is true in a given world of a given model (the\nmodel-checking problem) and deciding whether a given formula\nis true in all worlds of all models in a given class (the\nvalidity problem) are simple tasks. Now suppose a more\nexpressive language is used. It is then possible to distinguish models\nthat were, from the first language’s perspective, the same\n(see, e.g., the appendix on the non-definability of distributed and common knowledge within \\(\\cL_{\\left\\{ \\oK{1}, \\ldots, \\oK{n} \\right\\}}\\)).\nHowever, intuitively, we might then need to make a stronger effort to\nsee those differences: we might need more time to make the\ncalculations, and we might need more space to save intermediate\nresults. In a single sentence, expressivity and complexity go hand in\nhand, and an increase in the first typically produces an increase in\nthe second. \nThe simplest example of this phenomenon is given by the relationship\nbetween the two best-known logical languages, the propositional and\nthe first-order predicate one, when used to describe first-order\nmodels. The validity problem for the propositional language, which can\nbe understood as one that only allows us to talk about the properties\n(i.e., monadic predicates) of a single object and their Boolean\ncombination, is decidable: there are effective procedures\nthat can answer the validity question for any given propositional\nformula. The first-order predicate language can see much more (all\nobjects of the domain, together with their properties and their\nn-ary relations, among others), but this comes at a price: its\nvalidity problem is undecidable, as there is no effective\nprocedure that can answer the validity question for all its\nformulas. \nIn the modal realm there are also such cases, some of them in which\nseemingly harmless combinations produce dramatic results. An example\nof this can be found in Blackburn, Rijke, and Venema (2001: Section\n6.5), where it is shown that the fusion of two decidable systems, a\nPDL-like system (with sequential composition and intersection\nas the syntactic constructors) and a system with the global modality\n(Goranko & Passy 1992), crosses the border into undecidability.\nEven if the new multi-agent system turns out not to be undecidable,\nits complexity might be such that solving its validity problem for\nrelatively small instances is, for all practical purposes, impossible.\nAn example of such case is the basic multi-agent epistemic logic, with\nno requirements on the accessibility relations. The validity problem\nfor formulas in \\(\\cL_{\\left\\{ \\oK{1}, \\ldots, \\oK{n} \\right\\}}\\) is\n PSPACE: the space (and thus time) required to decide whether any given \\(\\varphi\\) is valid is given by a polynomial function. However, adding the common knowledge\noperator makes the validity problem for formulas in \\(\\cL_{\\left\\{\n\\oK{1}, \\ldots, \\oK{n}, C \\right\\}}\\) EXPTIME (sometimes also called\n EXP):\n the required time is now given by an exponential\n function.[14] \nA major methodological issue is then to strike a proper balance\nbetween expressive power and computational complexity, with the best\nmulti-modal systems being those that manage to achieve a good\ncompromise in this sense. We end this section noticing briefly that,\nin the case of the combination of modal logics, complexity\ndepends deeply on the assumed bridge axioms. A famous example of this\nis the landmark paper by Halpern & Vardi (1989) on the complexity\nof (96!) epistemic and temporal logics over interpreted\nsystems, all of them differing on the used language (single or\nmultiple-agents, common knowledge or lack of) and the assumed bridge\nprinciples (the aforementioned perfect recall and no\nlearning, synchronicity, unique or multiple initial\nstate). \nThe previous sections have described several ways of obtaining\nmulti-modal systems. The current one presents some of the most\ninteresting examples, together with the discussions that arise\nfrom the interplay of the modalities involved. \nThe interplay between knowledge and belief is an important topic in\nepistemology. Historically, one of the most important proposals is\nPlato’s characterization of knowledge as\n justified true belief,\n which has been one of the motivations used in the development of\n justification logic.\n However, can knowledge be truly defined as justified true belief? The\n examples\n provided (among others) in Gettier (1963) seem to go against this\nidea. Gettier describes situations in which an agent believes a given\n\\(\\varphi\\) and has a justification for it; moreover, \\(\\varphi\\) is\nindeed the case. Nevertheless, the justification is not an appropriate\none: \\(\\varphi\\) happens to be the case because of some other lucky\nunrelated circumstances. This has lead to proposals that focus on the\nrequirement of a correct justification (the no false\nlemma: Clark 1963; Armstrong 1973; Shope 1983). Some others have\nused a stronger indefeasibility requirement, stating that\nknowledge is justified true belief that cannot be defeated by true\ninformation, i.e., there is no true proposition \\(\\psi\\) such that, if\nthe agent were to learn that \\(\\psi\\) was the case, would lead her to\ngive up her belief, or to be no longer justified in holding it (Klein\n1971; Lehrer & Paxson 1969; Swain 1974). The aforementioned\ntopological modal approach of Baltag, Bezhanishvili, et al. (2016)\nrelates this idea with other epistemic concepts, and a deeper\ndiscussion on what it means to know something can be found in\n the analysis of knowledge\n by Ichikawa and Steup (2018). \nThere are also other alternatives. An interesting proposal, discussed\nin Lenzen (1978) and Williamson (2002), follows the other direction:\nstart from a chosen notion of knowledge, and then weaken it in order\nto obtain a ‘good’ (e.g., consistent, introspective,\npossibly false) notion of belief. These ideas have been discussed in\nformal settings. In Stalnaker (2006), the author argues that the\n“true” logic of knowledge is the modal logic S4.2, given\nby the standard K axiom \\((K(\\varphi \\rightarrow\\psi)\n\\rightarrow (K\\varphi \\rightarrow K\\psi))\\) and the generalization\nrule \\((K\\varphi\\) for every validity \\(\\varphi)\\), together with\nveridicality \\((K\\varphi \\rightarrow \\varphi\\): knowledge is\ntruthful), positive introspection \\((K\\varphi \\rightarrow KK\\varphi\\):\nif the agent knows \\(\\varphi\\), then she knows that she knows it) and\nthe ‘convergence’ principle \\((\\hK K\\varphi \\rightarrow\nK\\hK\\varphi\\): if the agent considers it possible to know \\(\\varphi\\),\nthen she knows that she considers \\(\\varphi\\) a possibility). In this\nsetting, Stalnaker (2006) argues that belief can be defined as the\nepistemic possibility of knowledge, that is, \nNote how this is exactly what the definition of belief in the\npreviously discussed plausibility models entails: if the modality\n\\([\\leq]\\) is understood as indefeasible knowledge (Lehrer 1990;\nLehrer & Paxson 1969), then \\(B\\varphi :=\n\\langle{\\leq}\\rangle[{\\leq}]\\varphi\\) states that belief is the\npossibility of knowledge. In this context, it is a small step to move\nfrom studying simple beliefs to conditional beliefs. A complete\naxiomatization of the logic of indefeasible knowledge and conditional\nbelief, first posed as an open question in Board (2004), was provided\nwith a solution in Baltag and Smets (2008). \nA further proposal that uses knowledge as the basic notion is that of\nBaltag, Bezhanishvili, Özgün, and Smets (2013), which\ngeneralizes Stalnaker’s (2006) formalization by using a\ntopological (neighborhood) semantics. An important feature of\nthe notion of belief that arises in this setting is that it is\nsubjectively indistinguishable from knowledge: an agent believes\n\\(\\varphi\\) \\((B\\varphi)\\) if and only if she believes that she knows\nit \\((BK\\varphi)\\). \nTemporal-epistemic approaches have been briefly mentioned in this\ntext.\n Indeed, many logical systems have been used to describe the way in\nwhich the knowledge of agents changes over time. The proposals include\nnot only interpreted systems (IS; Fagin et al. 1995)\nbut also epistemic-temporal logic (ETL; Parikh &\nRamanujam 2003), logics of\n agency\n (e.g., see to it that logic,\n STIT;\n Belnap, Perloff, & Xu 2001) and the DEL approach\nmentioned before\n (section 2.8).\n In all of them, an important point of discussion is the interaction\nbetween the temporal and epistemic modalities. \nAs mentioned before, two famous requirements have been those of\nperfect recall (the agent’s knowledge is not decreased\nover time) and no learning (the agent’s knowledge is\nnot increased over time). In the simple fusion of epistemic logic and\nthe future fragment of tense logic described above, these two\nrequirements can be expressed, respectively, as  \nFor some, the no learning condition might be too harsh, as it\nseems to say that the passage of time never helps to increase\nknowledge. A related but more reasonable condition is that of no\nmiracles, introduced in a slightly richer setting in van Benthem\nand Pacuit (2006), which states that the uncertainty of the agents\ncannot be erased by the same\n event.[15]\n A further interaction property is that of synchronicity,\nwhich states that epistemic uncertainty only happens among epistemic\nsituations that occur at the same moment of time. For example, the\nagent always knows ‘what time it is’, as she might not\nknow which action was executed, but she always knows that some action\nhas taken place. \nFor more information on the interaction of time and knowledge, the\nreader is referred, among others, to Halpern, van der Meyden, and\nVardi (2004); van Benthem, Gerbrandy, et al. (2009). See also van\nBenthem and Dégremont (2010) and Dégremont (2010) for\nanalogous interactions between time and beliefs, with the\nlatter represented by plausibility preorders similar to the\nplausibility models described before. \nThe interplay between questions and propositions is an important\nfactor in driving reasoning, communication, and general processes of\ninvestigation (Hintikka 2007; Hintikka, Halonen, & Mutanen 2002).\nIndeed,  \n[s]cientific investigation and explanation proceed in part through the\nposing and answering of questions, and human-computer interaction is\noften structured in terms of queries and answers. (from the SEP entry\non\n questions\n by Cross & Roelofsen 2018) \nBut then, what is the relationship between an agent’s knowledge\nand her questions? Maybe more important: given that different agents\nmight be posing different questions (i.e., they might be interested in\ndifferent issues), what is the relationship between the knowledge of\ndifferent agents? \nThe proposal of Boddy (2014) and Baltag, Boddy, and Smets (2018)\nstudies these concerns (then also studying what the ‘real’\ncommon and distributed knowledge of a group is). Their model (based on\nthe epistemic issue model introduced in van Benthem &\nMinica 2012) assumes that agents have not only their individual\nknowledge, but also their individual issues: the topics that\neach one of them has put on the table, which determine their\nindividual agenda on what is currently under investigation. On the\nsyntactic side, besides the standard knowledge modality \\((K_i\\) for\neach agent i), there is also a modality \\(Q_{i}\\varphi\\), read\nas “\\(\\varphi\\) can be known solely based on learnable\nanswers to i’s questions”. In other words,\n\\(Q_a\\) describes the maximum knowledge agent a can acquire,\ngiven her questions and the answers that are learnable for her. Thus,\nas a principle, if a knows \\(\\varphi\\), she can know it solely\nbased on answers to her question(s): \nMore interesting is the relationship between agent a’s\nknowledge and that of other agent b: in order for an agent to\nconsider any potential knowledge, such knowledge must be relevant for\nher in the sense that she can distinguish it as a possible answer to\none of her questions. In other words,  \n[a]gents are therefore only able to coherently represent the knowledge\nof others […] if the fact that they (the others) possess this\nknowledge […] is relevant to them. (Boddy 2014: 28)  \nThus, “if b knows something that is relevant to a,\nthen it is relevant to a that b knows this” and\n \nif b can know (given her issue) anything that is relevant to\na, then this fact (that b’s potential knowledge\nincludes potential knowledge of a) is itself relevant to\na.  \nIn symbols, \nA more in-depth discussion about the consequences of adding the\nagent’s issues to the picture (including alternative definitions\nfor the group’s distributed and common knowledge) can be found\nin the above references. \nIn the context of the design and implementation of autonomous agents,\none of the most famous architectures is the\nbelief-desire-intention (BDI) model (Bratman 1987;\nHerzig, Lorini, Perrussel, & Xiao 2017). \nDeveloped initially as a model of human practical reasoning (Bratman\n1987), the BDI model proposes an explanation of practical\nreasoning involving action, intention, belief, goal, will,\ndeliberation and several other concepts. Thus, it is natural to think\nabout combining simple modal logics for some of these notions in order\nto define logics for such richer settings. Indeed, several formal\nsemantics for such models have been proposed, some of them based on\ndiverse temporal logics (Cohen & Levesque 1990; Governatori,\nPadmanabhan, & Sattar 2002; Rao & Georgeff 1991), some others\nbased on dynamic logics (van der Hoek, van Linder, & Meyer 1999;\nSingh 1998), and some based on both (Wooldridge 2000). The crucial\npart in most of them is the interaction between these different\nattitudes. For example, on the one hand, if an agent intends to\nachieve something (say, \\(I\\varphi)\\), one would expect for her to\ndesire that something \\((D\\varphi)\\); otherwise, it does not make\nsense to devote resources to achieve it. On the other hand, desiring\nsomething should not imply an intention to achieve it: it does not\nseem reasonable to commit resources to all our desires, even the\nunrealistic ones (and, perhaps more importantly, intention and desires\nwould collapse into a single notion). Moreover, it seems clear that an\nagent who desires to be rich \\((Dr)\\) does not necessarily believe\nthat she is rich \\((Br)\\). Finally, if an agent has an intention to\nwrite a book \\((Ib)\\), should she believe that she will write it\n\\((BFb)\\), thus ruling out all possible unforeseen circumstances that\ncould prevent her from doing it? \nA concise description of this interaction in some of these proposals\ncan be found in the first part of\n Subsection 4.2\n in the SEP entry on\n the logic of action\n written by Segerberg, Meyer, and Kracht (2016). \nModal first-order (i.e., quantified modal) logic is perhaps one of the\nmost intriguing multi-modal systems, as the combination of quantifiers\nand modalities raises several interesting questions. Here we will\ndiscuss briefly two important points; readers interested in a further\ndiscussion are referred to the SEP discussion on\n quantified modal logic\n by Garson (2018). \nThe modal first-order language is built in a straightforward way:\nsimply take the classical\n first-order language,\n with its universal \\((\\forall)\\) and existential \\((\\exists)\\)\noperators indicating quantification over objects, and add the two\nbasic modal alethic operators, necessity \\((\\Box)\\) and possibility\n\\((\\Diamond)\\). The resulting language turns out to be very\nexpressive, allowing us to distinguish between the de dicto\nand the de re readings of natural language sentences (a\ncontrast that can be traced back to Aristotle; see Nortmann 2002). For\nexample, assume that an individual f has exactly 3 sisters, and\nconsider the sentence “the number of sisters of f is\nnecessarily greater than 2”. The claim can be understood in\ntwo different ways. Under a de dicto interpretation, it\nstates that the number of sisters that f has is\nnecessarily greater than 2, but this is clearly questionable: under\ndifferent circumstances, f might have had either more or else fewer sisters.\nHowever, under a de re interpretation, the claim states that\nthe number of sisters that f has, the number 3, is\nnecessarily greater than 2: this is definitely true, at least when\nrestricting ourselves to the standard understanding of numbers. \nIn modal first-order logic, the difference between de re and\nde dicto is given by\n the scope of the involved quantifiers and modal operators.\n On the one hand, a de dicto (“of the\nproposition”) sentence indicates a property of a proposition,\nwith the involved quantifier occurring under the scope of modalities.\nFor example, the de dicto reading of the previous sentence is\ngiven by the formula \\(\\oBox\\left(\\exists x (x = s(f) \\land x > 2)\n\\right)\\) (with s a function returning its parameter’s\nnumber of sisters). On the other hand, a de re (“of the\nthing”) sentence indicates a property of an object, with the\ninvolved modality occurring under the scope of quantifiers. For\nexample, the de re reading of the previous sentence is given\nby the formula \\(\\exists x \\left( x = s(f) \\land \\oBox(x > 2)\n\\right)\\). This crucial distinction can be exemplified by the\ndifference between some agent i knowing that there is someone\nthat makes her Happy (but maybe without knowing who this\nperson is), \\(K_i\\exists x H(x, i)\\), and the always preferred\nexistence of someone who i knows makes her happy \\((\\exists x\nK_i H(x, i))\\). \nBut the expressivity comes with a cost. As usual in multi-modal\nsystems, the crucial question is the interaction between the involved\nmodalities, and in this case, the discussion typically centers on the\nfollowing two: the Barcan formula, \\(\\forall x \\oBox Px\n\\rightarrow \\oBox\\forall x Px\\), and its converse, \\(\\oBox\\forall x Px\n\\rightarrow \\forall x \\oBox Px\\) (see Barcan 1946). The reason for the\ncontroversy becomes clear when the generic predicate P is\nreplaced by, say, the formula \\(\\exists x (x=y)\\), which can be read\nas “x exists”. Then, the first formula\nbecomes \nstating that if everything exists necessarily then it is necessary\nthat everything exists. In terms of a possible worlds semantic model,\nthis boils down to stating that every object existing in an\nalternative possible world should also exist in the current one: when\none moves to alternative scenarios, the domain does not grow.\nAnalogously, the second formula becomes  \nstating that if it is necessary that everything exists then everything\nexists necessarily. In terms of a possible worlds semantic model, this\nboils down to stating that every object existing in the current world\nshould also exist in an alternative possible one: when one moves to\nalternative scenarios, the domain does not shrink. \nThus, a decision about whether such principles hold corresponds to\nanswering a crucial question when building a model for the modal\nfirst-order language: what is the relationship between the domains of\nthe different possible worlds? On the one hand, from the perspective\nof\n actualism,\n everything there is (everything that can in any sense be said to be)\nis actual, that is, it exists; hence, there is a fixed domain\nacross all possibilities. On the other hand, from the perspective of\n possibilism,\n ‘the things that exist’ include possible but non-actual\nobjects; hence, different possible worlds might have different\ndomains. There is a large literature on the discussion between these\ntwo positions, as the provided references show. \nThe notion of\n intention\n is crucial in BDI systems, as it in some sense defines the\nchoices the agent will make, thus affecting her behavior. Thus, the\ndynamics of intention is also a crucial subject, as it\ndescribes the way intentions are generated, preserved, modified or\ndiscarded. \nFor an initial point, how do intentions change after the agent learns\na new piece of information? According to Roy (2008: Chapter 5), if the\noriginal intentions are compatible with the new information, then they\nare ‘reshaped’; otherwise, the agent discards them without\ncreating any new intention (or, analogously, generating an intention\nfor something that has been already achieved). Thus, after an\nannouncement of \\(\\chi\\) the agent intends to do \\(\\varphi\\) if and\nonly if \\(\\chi\\) is compatible with her intentions and \\(\\varphi\\) is\na restricted consequence of the agent’s initial intentions, or\nelse \\(\\varphi\\) is a ‘known’ consequence of\n\\(\\chi\\)’s announcement. In a formula, \nThere are other proposals. In van der Hoek, Jamroga, and Wooldridge\n(2007), intentions are defined, roughly speaking, as plans the agent\nbelieves have not yet been fulfilled. As a consequence of this,\nchanges in the agent’s beliefs lead to changes on her\nintentions. For example, after any observation, the agent will drop\nintentions that she believes have been accomplished: \nMoreover, she will drop any intention she believes it is impossible to\nachieve: \nBut, just as changes in the agent’s information (knowledge,\nbeliefs) should trigger changes in her intentions, changes in her\nintentions may also trigger changes in (some of) her beliefs. Intuitively,\nhaving the intention to achieve a given \\(\\varphi\\) reduces the\nactions that the agent ‘can’ perform, from the ones she\ncan actually carry on, to those that will still allow (and maybe\nassure) that \\(\\varphi\\) will be achieved. In other words, a change in\nthe agent’s intentions triggers also a change in her beliefs\nabout the (sequence of) actions that will be available in the future.\nThis is the idea followed in Icard, Pacuit, and Shoham (2010), which\nstudies the interaction between intention revision and belief revision\nby introducing postulates for both actions, with these postulates\ndescribing the two processes’ interplay. In the interesting case\nof intention revision, the postulates state that (i) a new intention\nwill take precedence over previous ones (and thus old ones should be\neliminated when in conflict), (ii) modulo coherence, no further change\nshould be made on the agent’s intentions (in particular, no\nextraneous intentions should be added), and (iii) non-contingent\nbeliefs do not change with intention\n revision.[16] \nAs the reader might guess, adding a temporal dimension is typically a\ngood idea, as in most cases it enriches the initial system by allowing\nus to talk about how the concept changes. Besides epistemic\nsettings, others that benefit from this are systems of\n deontic logic,\n which study the properties of concepts as permissions (e.g.,\n“\\(\\varphi\\) is allowed”) and obligations (e.g.,\n“\\(\\varphi\\) is required”). Such systems are extremely\nuseful, as they involve topics such as law, social and business\norganizations, and even security systems. \nOne of the interesting concepts that arise when time and obligations\ninteract with each other is the notion of deontic deadlines:\nobligations that need to be fulfilled only once, at a time of\none’s choosing, as long as it is before certain condition become\ntrue. Indeed,  \n[…] deontic deadlines are interactions between two dimensions:\na deontic (normative) dimension and a temporal dimension. So, to study\n[them], it makes sense to take a […] temporal logic […]\nand a standard deontic logic […], and combine the two in one\nsystem. (Broersen, Dignum, Dignum, & Meyer 2004: 43)  \nSuch formal systems help to provide a proper understanding of what a\ndeadline is: as the aforementioned reference asks,  \nis a deadline (1) an obligation at a certain point in time to achieve\nsomething before another point in time, or (2) is a deadline simply an\nobligation that persists in time until a deadline is reached, or (3)\nis it both?  \nThen, the formal setting also allows the possibility to make further\nfiner distinctions, as the one between an obligation to always satisfy\na given \\(\\varphi\\) (in symbols, and with O a modality for\nobligation, \\(OG\\varphi)\\) and an obligation for \\(\\varphi\\) that\nshould be always fulfilled \\((GO\\varphi)\\). Further and deeper\ndiscussions on deontic deadlines can be found in Broersen et al.\n(2004); Broersen (2006); Brunel, Bodeveix, & Filali (2006);\nDemolombe, Bretier, & Louis (2006); Governatori, Hulstijn,\nRiveret, & Rotolo (2007); and Demolombe (2014), among others. \nEqually important is the relationship between knowledge and\nobligations, as it is shown by the aforementioned\n paradox of epistemic obligation,\n which arises within the fusion\n (section 3.1)\n of a\n standard deontic logic\n and a standard epistemic logic. But the relationship between these\nconcepts goes beyond their interaction in such a basic system. For\nexample, if an agent does not know about the existence of an\nobligation, should she be expected to fulfill it? In some cases the\nanswer seems to be “no”: a physician whose neighbor is\nhaving a heart attack has no obligation to provide assistance unless\nshe knows about the emergency. Still, in some other cases, the answer\nseems to be “yes”: the juridical principle\n“ignorantia juris non excusat” (roughly,\nignorance of the law is not excuse) is an example of this. \nThere have been proposals dealing with these issues. One of them is by\nPacuit, Parikh, & Cogan (2006), which uses a setting in which\nactions can be considered “good” or “bad”. It\nintroduces a notion of knowledge-based obligation under which\nan agent is obliged to perform an action \\(\\alpha\\) if and only if\n\\(\\alpha\\) is an action which the agent can perform and she\nknows that it is good to perform \\(\\alpha\\). This is then a\nform of absolute obligation which remains until the agent\nperforms the required action. \nInterestingly, the involvement of knowledge gives raise to forms of\n‘defeasible’ obligations that can disappear in the light\nof new information. For example, having being informed about her\nneighbor’s illness, the physician could have the obligation to\nadminister a certain drug; however, this obligation would disappear if\nshe were to learn that the neighbor is allergic to this medication.\nThis ‘weaker’ form of obligation can also be captured\nwithin the setting discussed in Pacuit et al. (2006). \nThe interaction between knowledge and obligations is not limited to\nthe way knowledge ‘defines’ obligations. An important role\nis also played by whether the agent consciously violates her\ncommitments. In fact, most juridical systems contain the principle\nthat an act is only unlawful if the agent conducting it has a\n‘guilty mind’ (mens rea): for the agent to be\nguilty, she must have committed the act intentionally/purposely. Of\ncourse, there are different levels of ‘guilty minds’, and\nsome legal systems distinguish between them in order to assign\n‘degrees of culpability’ (e.g., an homicide is considered\nmore severe if done intentionally rather than accidentally). For\nexample, on the one hand, stating that it is illegal to do\n\\(\\alpha\\) negligently means that it is illegal to do\n\\(\\alpha\\) while being aware that the action carries a substantial and\nunjustifiable risk. On the other hand, stating that it is illegal to\ndo \\(\\alpha\\) knowingly means that it is illegal to do\n\\(\\alpha\\) while being certain that this conduct will lead to the\nresult.[17]\nThese and other modes of mens rea are formalized in Broersen\n(2011) within the\n STIT\n logic framework. \nAs the previous sections indicate, the specific interplay between\ndifferent modalities (the way they are combined and which bridge\nprinciples hold) is crucial to provide an accurate representation and\nanalysis of different philosophical concepts. In fact, in several\noccasions, the combination of different modalities have shed light on\nphilosophical issues.  We will illustrate this for the concepts of\nabduction, knowability, ‘believing to know’, truthmakers\nand the interplay between assumptions and beliefs while keeping in\nmind an endless list of other philosophical paradoxes and problems\nthat all arise in a multi-modal setting. (Among many others, see the\nYablo paradox in Yablo (1985, 1993) as well as the SEP discussions on\n deontic paradoxes\n and on\n paradoxes without self-reference.\n See also the SEP analyses on the\n knower paradox,\n on\n dynamic epistemic paradoxes\n and on the\n surprise examination paradox;\n for the latter, see also a proposed solution in Baltag and Smets\n(2010\n Other Internet Resources).) \nThe term\n abduction\n has been used in related but sometimes different senses. Roughly\nspeaking, abductive reasoning (also called inference to the best\nexplanation, retroduction, and hypothetical,\nadductive or presumptive reasoning, among many other\nterms) can be understood as the process through which an\nagent (or a group of them) looks for an explanation of a surprising\nobservation. Many forms of intellectual tasks, such as medical and\nfault diagnosis, legal reasoning, natural language understanding, and\n(last but not least) scientific discovery, belong to this category,\nthus making abduction one of the most important reasoning\nprocesses. \nIn its simplest form, abduction can best be described with\n Peirce’s\n 1903 schema (Hartshorne & Weiss 1934: CP 5.189): \nThis is the understanding that has been most frequently cited and used\nwhen providing formal approaches to abductive reasoning. Still,\ntypical definitions of an abductive problem and its solution(s) have\nbeen given in terms of a (propositional, first-order) theory and a\nformula, leaving the attitudes of the involved agents out of the\npicture. \nHowever, there have been also proposals that formalize (parts of) the\nabductive process in terms of diverse epistemic concepts (e.g.,\nLevesque 1989; Boutilier & Becher 1995). Among them,\nVelázquez-Quesada, Soler-Toscano, &\nNepomuceno-Fernández (2013) understand abductive reasoning as a\nprocess of belief change that is triggered by an observation and\nguided by the knowledge the agent has. In symbols\n(Velázquez-Quesada 2015), abductive reasoning from a surprising\nobservation \\(\\psi\\) to a belief \\(\\varphi\\) can be described as \nstating thus that if the agent knows \\(\\varphi \\rightarrow \\psi\\) and\nan announcement of \\(\\psi\\) (“\\([\\psi{!}]\\)”) makes her\nknow it \\((\\psi)\\), then she can perform an act of belief\nrevision with \\(\\varphi\\) (“\\([\\varphi\\Uparrow]\\)”)\nin order to believe it. This formalization emphasizes not only that\nthe agent’s initial knowledge plays a crucial role in the\ngeneration of possible abductive solutions, but also that the chosen\nsolution can only be accepted in a weak way, therefore making it a\ncandidate for being discarded in the light of further information. \nOther proposals have incorporated further aspects into the picture.\nOne of them, Ma & Pietarinen (2016), follows Peirce’s latter\nunderstanding of abductive reasoning (called then\nretroduction: “given a (surprising) fact C, if\nA implies C, then it is to be inquired whether A\nplausibly holds”; Peirce 1967: 856) as a form of reasoning from\nsurprise to inquiry. This can possibly be related to the\nnotions of issues and questions described in \nsection 4.3. As the authors mention,\n \n[t]he important discovery is that [, in the new formulation,] the\nconclusion is presented in a kind of interrogative mood. But the\ninterrogative mood does not merely mean that a question is raised. In\nfact, it means that the possible conjecture A becomes the\nsubject of inquiry: the purpose is to determine whether that A\nis indeed plausible or not. Peirce termed such mood “the\ninvestigand mood”. Hence abduction can be viewed as the dynamic\nprocess toward a plausible conjecture and, ultimately, toward a\nlimited set of the most plausible conjectures. \n This paradox\n emerges from what is commonly known as the verificationist thesis\n(VT), which claims that all truths are verifiable.\nFormalizing this thesis in a multi-modal logic that combines a\nknowledge operator with a possibility operator would yield \nwith \\(\\Diamond K\\varphi\\) read as “it is possible to\nknow \\(\\varphi\\)”. In this context, the paradox refers to\nFitch’s argument containing an idea conveyed to him in 1945\nwhich shows that, if all truths are knowable, then all truths are\nalready known. As the argument goes, we clearly do not know all truths\n(as we are not omniscient!); hence, the premise has to be false: not\nall truths are knowable. The paradox can be summarized by the\nderivation \nwhich poses a problem for the non-omniscient verificationist. The\nderivation that leads to the paradox as we have stated it here is\nbased on a multi-modal logical system in which at least the following\nprinciples hold: (i) the principle of non-contradiction, to capture\nthat contradictions cannot be true and can also not be considered\npossible, (ii) the classical laws of double negation, transitivity of\nthe material implication and substitution, (iii) normality of the\nmodal logic operator K, the modal logic principle T\nstating that knowledge is truthful, and the normality of the modal\npossibility operator \\(\\Diamond\\). The simplest presentation of the\nparadox which shows how it leads to the unwanted equivalence between\ntruth and knowledge, can be found in van Benthem (2004). Start with\nthe formula stating the verificationist thesis, \\(\\varphi \\to \\Diamond\nK\\varphi\\), and substitute \\(\\varphi\\) with \\((p \\land \\lnot\nKp)\\): \nThis paradox gave rise to an active debate in the philosophical\nliterature, leading us to signal out two main types of proposed\nsolutions: those proposing a weakening of our logical principles (as\nin paraconsistent, intuitionistic or weaker modal logics) while\nkeeping the verification thesis, and those that in contrast do not\nchange/restrict the underlying logic but propose a specific\nformalization or reading of the verificationist\n thesis.[18]\n While we refer the reader to the SEP entry on\n epistemic paradoxes\n for an overview of these proposed solutions, here it is illustrative\nto highlight how this paradox, which in some sense arises from\ncombining a modal logic for knowledge (K) with a modal logic\nfor possibility \\((\\Diamond)\\), can be ‘demystified’ by\nthe further introduction of a modality for communication (related to\nthe public announcement modality of PAL). Indeed, according\nto van Benthem (2004), what the verificationist thesis expresses is\nnot about ‘static’ knowability, but rather about\na form of learnability: “what is true may come to be\nknown” (van Benthem 2004). This statement can be formally stated\nin a suitable arbitrary announcement framework as: \nwhich is read as “if \\(\\varphi\\) is the case, then there is\na formula \\(\\psi\\) after whose announcement \\(\\varphi\\) will be\n known”.[19]\n This reading of the verificationist thesis brings us in touch with a\nnumber of results in dynamic epistemic logic on unsuccessful\nformulas (those that become false after being truthfully announced;\nvan Ditmarsch & Kooi 2006; van Benthem 2011; Holliday & Icard\n2010), which indicate that indeed not all sentences are learnable. In\nfact, this solution shows us that \n[…] there is no saving VT—but there is also no such\ngloom. For in losing a principle, we gain a general logical study of\nknowledge and learning actions, and their subtle properties. The\nfailure of naive verificationism just highlights the intriguing ways\nin which human communication works. (van Benthem 2004: 105) \n \nOn first sight it seems natural to say that one can believe to\n‘know’ something, even when in fact one does not actually\nknow it. So believing to know something is philosophically conceived\nto be different from claiming true knowledge. Yet, under the\nassumption that what is known is also believed, this specific\ninterplay between modalities for knowledge and belief can lead us into\ntrouble if we identify belief with a\nKD45-modality B, and knowledge\nwith a S5-modality for K. For\nsuppose \\(BK\\varphi \\land \\lnot K\\varphi\\) is assumed. Then, by\nnegative introspection of the second conjunct, we derive \\(K\\lnot\nK\\varphi\\). But as knowledge implies belief, we derive \\(B\\lnot\nK\\varphi\\). This together with the first conjunct \\(BK\\varphi\\) will\ngive us, by additivity of belief, \\(B(K\\varphi \\land \\lnot\nK\\varphi)\\). Hence we derive the belief in a contradiction, which is\nnot compatible with the assumption of consistency of beliefs (axiom\nD) in\nKD45. This problem is known as the\nparadox of the perfect believer (and also as the Voorbraak\nparadox), as it was originally (but equivalently) described (Voorbraak\n1993) as the derivability of the bridge principle \\(BK\\varphi\n\\rightarrow K\\varphi\\), which states that a belief in knowing a given\n\\(\\varphi\\) is enough to know \\(\\varphi\\). (The derivation of\n\\(BK\\varphi \\rightarrow K\\varphi\\) also relies on the negative\nintrospection of knowledge, the normality and consistency of beliefs,\nand the bridge principle stating that knowledge implies belief; Gochet\n& Gribomont 2006: 114.) \nAfter presenting this problem, Voorbraak (1993) proposed to deal with\nit by discarding the bridge principle \\(K\\varphi \\rightarrow\n{B\\varphi}\\). Another option is to allow inconsistent beliefs (Gochet\n& Gribomont 2006: Section 2.6). Still, a further possible\nsolution, closer to the spirit of these notes, is to consider an\nintermediate notion of ’knowledge’ that is not as strong\nas the absolute irrevisable (i.e., irrevocable) notion given by the\nS5 modal operator K. More\nprecisely, the proposal in Baltag and Smets (2008) looks at Lehrer’s\ndefeasibility theory of knowledge (Lehrer 1990; Lehrer &\nPaxson 1969), and works with the indefeasible (“weak”,\nnon-negatively-introspective) knowledge given, in the\n plausibility models\n discussed above, by the modality \\([\\leq]\\) (read before also as\nsafe belief). Indeed, Lehrer and Stalnaker call this concept\ndefeasible knowledge, a form of knowledge that might be\ndefeated by false evidence, but cannot be defeated by\ntrue evidence. The concept satisfies both the truth axiom\n\\(([\\leq]\\varphi \\rightarrow \\varphi)\\) and positive introspection\n\\(([\\leq]\\varphi \\rightarrow [\\leq][\\leq]\\varphi)\\), but it lacks\nnegative introspection; thus, the previous derivation of inconsistent\nbeliefs from an agent mistakenly believing that she (defeasibly) knows\n\\(\\varphi\\) \\(({B[\\leq]\\varphi} \\land \\lnot [\\leq]\\varphi)\\) is no\nlonger possible. Instead, it can be easily shown how a belief in\ndefeasible knowledge, \\({B[\\leq]\\varphi}\\), is equivalent to a simple\nbelief, \\({B\\varphi}\\). \nParaphrasing Fine (2017), a truthmaker is something on the\nside of the world, as a fact or a state of affairs, making true\nsomething on the side of language or thought, as a statement or a\nproposition. Truthmaking has been an important topic in both\nmetaphysics and semantics. For the first, “truthmaking serves as\na conduit taking us from language or thought to an understanding of\nthe world” (Fine 2017: 556); for the second, it provides\nadequate semantics for a given language by establishing how the world\nmakes sentences of the language true. \nIn Fine (2017), the author explains the basic framework of truthmaker\n(‘exact’) semantics for propositional logic. It is based\nnot on possible worlds, but rather on states or\nsituations; the crucial difference is that, while a possible\nworld settles the truth-value of any possible statement (i.e., given a\nformula and a possible world, the formula is either true or else\nfalse), a situation might not be enough to decide whether a given\nsentence holds. \nFormally, a state space is a tuple \\({\\langle S, \\sqsubseteq\n\\rangle}\\) where S is a non-empty set of states and\n\\({\\sqsubseteq} \\subseteq (S \\times S)\\) is a partial order (i.e., a\nreflexive, transitive and antisymmetric relation), with \\(s_1\n\\sqsubseteq s_2\\) understood as “state \\(s_2\\) extends state\n\\(s_1\\)”. It is assumed that any pair of states has a\nleast upper bound (i.e., a supremum); formally, for\nany \\(s_1, s_2 \\in S\\) there is \\(t_1 \\sqcup t_2 \\in S\\)\nsatisfying \nThis supremum \\(t_1 \\sqcup t_2\\) (its uniqueness follows from\n\\(\\sqsubseteq\\)’s antisymmetry) can be understood as the\n‘sum’, ‘merge’ or ‘fusion’ of\nstates \\(t_1\\) and \\(t_2\\), and it provides the crucial tool for\ndeciding whether a ‘conjunction’ is the case, as shown\nbelow. \nA state model is a tuple \\({\\langle S, \\sqsubseteq, V\n\\rangle}\\) with \\({\\langle S, \\sqsubseteq \\rangle}\\) a state space and\n\\(V:\\mathtt{P}\\to (\\wp(S) \\times \\wp(S))\\) a valuation function\nreturning not only set of states that make a given atom p true\n(abbreviated as \\(V^+(p))\\), but also the set of states that make it\nfalse (abbreviated as \\(V^-(p))\\). In principle, given an atom\np, there needs to be no relation between the two sets. They\nmight be overlapping \\((V^+(p) \\cap V^-(p) \\neq \\emptyset)\\), thus\nyielding a state that makes p both true and false; they might\nbe limited \\((V^+(p) \\cup V^-(p) \\neq S)\\), thus yielding a state that\nmakes p neither true nor false; they might be neither, thus\nbeing exclusive \\((V^+(p) \\cap V^-(p) = \\emptyset)\\) and exhaustive\n\\((V^+(p) \\cup V^-(p) = S)\\), and making the states behave as possible worlds\nwith respect to p. \nGiven a state model, the relations \\(\\Vvdash_v\\) (verified by a\nstate) and \\(\\Vvdash_f\\) (falsified by a state) are defined as\nfollows. \nNote the clauses for verifying a conjunction and falsifying a\ndisjunction. A state makes a conjunction true if and only if it is the\nfusion of states that verify the respective conjuncts \\(\\varphi\\) and\n\\(\\psi\\). Analogously, a state makes a disjunction false if and only\nif it is the fusion of states that falsify the respective disjuncts\n\\(\\varphi\\) and \\(\\psi\\). \nTruthmaker semantics can be seen from a (multi)modal perspective (van\nBenthem 1989), since a state model \\({\\langle S, \\sqsubseteq, V\n\\rangle}\\) can be understood as a modal information logic, and thus\ncan be described by modal languages. One interesting possibility (van\nBenthem 2018: Section 13) starts by taking two modalities,\n\\(\\langle\\sqsubseteq\\rangle\\varphi\\) and\n\\(\\langle\\sqsupseteq\\rangle\\varphi\\), whose semantic interpretation is\ngiven in the standard modal way, with the first modality relying on\nthe partial order \\(\\sqsubseteq\\), and the second relying on its\nconverse\n \\(\\sqsupseteq\\).[20]\n Then, one can add a (binary) modality describing least upper\nbound \nand a ‘dual’ one describing the infimum (the\ngreatest lower\n bound)[21] \nWith these tools, it is possible to define a faithful translation from\ntruthmaker logic into modal information logic (see van Benthem 2018:\nSection 13 for details). This translation brings methods from modal\nlogic to the study of truthmaking. More important is the fact that it\nmakes truthmaker semantics, a framework that works by providing a new\nmeaning to Boolean connectives, completely compatible with classical\n(modal) logic, which keeps standard definitions but extends the\nframework’s expressivity by studying much richer languages. \nWe finish this text by returning to the beginning. So, given that \nAnn believes that Bob assumes that \\(\\underbrace{\\textit{Ann\nbelieves that Bob's assumption is wrong}.}_{\\varphi}\\)  \nis the case, is \\(\\varphi\\) (“Ann believes that Bob’s\nassumption is wrong”) true or false? \nAs explained in Pacuit (2007), in order to show that this situation\ncannot be ‘represented’, the original paper (Brandenburger\n& Keisler 2006) introduces a belief model. This structure\nrepresents each agent’s beliefs about the beliefs of the other\nagent. More precisely, a belief model is a two-sorted structure, one\nsort for each agent, with each sort representing an epistemic state\nthat its agent might have. The model’s first component is its\ndomain, given by the union of \\(W_a\\) and \\(W_b\\), the disjoint sets\nof states of Ann and Bob, respectively. The model also has a relation\nfor each agent, \\(R_a\\) and \\(R_b\\), with \\(R_auv\\) (restricted to \\(u\n\\in W_a\\) and \\(v \\in W_b)\\) read as “in state u, Ann\nconsiders v possible, and analogous for \\(R_bvu\\). Again,\nthe structure represents each agent’s beliefs about the beliefs\nof the other, so each collection \\(\\cU_b\\) of subsets of \\(W_b\\) can\nbe understood as a language for Ann (the beliefs she might have about\nBob’s beliefs), and analogous for Bob; a full language is then\ndefined as the union of a language for each agent. For the involved\nepistemic attitudes, Ann believes a given \\(U \\in \\cU_b\\) if and only\nif the set of states that she considers possible is a subset\nof U. On the other hand, an assumption is understood as the\nstrongest belief, so Ann assumes a given \\(U \\in \\cU_a\\) if and only\nif the set of states she considers possible is exactly\nU. \nWith these tools, it is now possible to make precise the claim that\nthe situation described above cannot be represented. A language is\nsaid to be complete for a belief model if and only if every\npossible statement in a player’s language (i.e., every statement\nin her language that is true in at least one state) can be assumed by\nthe player. It is then possible to show, using a diagonal argument,\nthat no belief model is complete for ‘its first-order\nlanguage’, i.e., the language containing all first-order\ndefinable subsets of the model’s domain.","contact.mail":"F.R.VelazquezQuesada@uva.nl","contact.domain":"uva.nl"}]
