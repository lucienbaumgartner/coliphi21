[{"date.published":"2003-05-20","date.changed":"2019-06-03","url":"https://plato.stanford.edu/entries/consequentialism/","author1":"Walter Sinnott-Armstrong","author1.info":"http://sites.duke.edu/wsa/","entry":"consequentialism","body.text":"\n\n\n\nConsequentialism, as its name suggests, is simply the view that\nnormative properties depend only on consequences. This historically\nimportant and still popular theory embodies the basic intuition that\nwhat is best or right is whatever makes the world best in the future,\nbecause we cannot change the past, so worrying about the past is no\nmore useful than crying over spilled milk.  This general approach can\nbe applied at different levels to different normative properties of\ndifferent kinds of things, but the most prominent example is probably\nconsequentialism about the moral rightness of acts, which holds that\nwhether an act is morally right depends only on the consequences of\nthat act or of something related to that act, such as the motive\nbehind the act or a general rule requiring acts of the same kind.\n\n\nThe paradigm case of consequentialism is utilitarianism, whose\nclassic proponents were Jeremy Bentham (1789), John Stuart Mill (1861),\nand Henry Sidgwick (1907). (For predecessors, see Schneewind 1997, 2002.)\nClassic utilitarians held hedonistic act consequentialism. Act\nconsequentialism is the claim that an act is morally right if and\nonly if that act maximizes the good, that is, if and only if the total\namount of good for all minus the total amount of bad for all is greater\nthan this net amount for any incompatible act available to the agent on\nthat occasion. (Cf. Moore 1912, chs. 1–2.) Hedonism then\nclaims that pleasure is the only intrinsic good and that pain is the\nonly intrinsic bad.  \nThese claims are often summarized in the slogan that an act is\nright if and only if it causes “the greatest happiness for the\ngreatest number.” This slogan is misleading, however. An act can\nincrease happiness for most (the greatest number of) people but still\nfail to maximize the net good in the world if the smaller number of\npeople whose happiness is not increased lose much more than the\ngreater number gains. The principle of utility would not allow that\nkind of sacrifice of the smaller number to the greater number unless\nthe net good overall is increased more than any alternative.  \n\nClassic utilitarianism is consequentialist as opposed to\ndeontological because of what it denies. It denies that moral rightness\ndepends directly on anything other than consequences, such as whether\nthe agent promised in the past to do the act now. Of course, the fact\nthat the agent promised to do the act might indirectly affect the act’s\nconsequences if breaking the promise will make other people unhappy.\nNonetheless, according to classic utilitarianism, what makes it morally\nwrong to break the promise is its future effects on those other people rather\nthan the fact that the agent promised in the past. \n\nSince classic utilitarianism reduces all morally relevant factors\n(Kagan 1998, 17–22) to consequences, it might appear simple. However,\nclassic utilitarianism is actually a complex combination of many\ndistinct claims, including the following claims about the moral\nrightness of acts: Consequentialism = whether an act is morally right depends only on\nconsequences (as opposed to the circumstances or the intrinsic\nnature of the act or anything that happens before the act). \nActual Consequentialism = whether an act is morally right depends\nonly on the actual consequences (as opposed to foreseen,\nforeseeable, intended, or likely consequences). \nDirect Consequentialism = whether an act is morally right depends\nonly on the consequences of that act itself (as opposed to the\nconsequences of the agent’s motive, of a rule or practice that covers\nother acts of the same kind, and so on). \nEvaluative Consequentialism = moral rightness depends only on the\nvalue of the consequences (as opposed to non-evaluative features of the\nconsequences). \nHedonism = the value of the consequences depends only on the\npleasures and pains in the consequences (as opposed\nto other supposed goods, such as freedom, knowledge, life, and so on). \n\nMaximizing Consequentialism = moral rightness depends only on which\nconsequences are best (as opposed to merely satisfactory or an\nimprovement over the status quo). \nAggregative Consequentialism = which consequences are best is some\nfunction of the values of parts of those consequences (as\nopposed to rankings of whole worlds or sets of consequences). \nTotal Consequentialism = moral rightness depends only on the\ntotal net good in the consequences (as opposed to the average\nnet good per person). \nUniversal Consequentialism = moral rightness depends on the\nconsequences for all people or sentient beings (as opposed to\nonly the individual agent, members of the individual’s society,\npresent people, or any other limited group). \nEqual Consideration = in determining moral rightness, benefits to\none person matter just as much as similar benefits to any\nother person (as opposed to putting more weight on the worse or worst off). \nAgent-neutrality = whether some consequences are better than others\ndoes not depend on whether the consequences are evaluated from the\nperspective of the agent (as opposed to an observer). \n\nThese claims could be clarified, supplemented, and subdivided\nfurther. What matters here is just that most pairs of these claims are\nlogically independent, so a moral theorist could consistently accept\nsome of them without accepting others. Yet classic utilitarians\naccepted them all.  That fact makes classic utilitarianism a more\ncomplex theory than it might appear at first sight. \n\nIt also makes classic utilitarianism subject to attack from many\nangles. Persistent opponents posed plenty of problems for classic\nutilitarianism. Each objection led some utilitarians to give up some of\nthe original claims of classic utilitarianism. By dropping one or more\nof those claims, descendants of utilitarianism can construct a wide\nvariety of moral theories. Advocates of these theories often call them\nconsequentialism rather than utilitarianism so that their theories will\nnot be subject to refutation by association with the classic\nutilitarian theory. \n\nThis array of alternatives raises the question of which moral\ntheories count as consequentialist (as opposed to deontological) and\nwhy. In actual usage, the term “consequentialism” seems to\nbe used as a family resemblance term to refer to any descendant of\nclassic utilitarianism that remains close enough to its ancestor in the\nimportant respects. Of course, different philosophers see different\nrespects as the important ones. Hence, there is no agreement on which\ntheories count as consequentialist under this definition. \n\nTo resolve this vagueness, we need to determine which of the various\nclaims of classic utilitarianism are essential to consequentialism. One\nclaim seems clearly necessary. Any consequentialist theory must accept\nthe claim that I labeled “consequentialism”, namely, that\ncertain normative properties depend only on consequences. If that claim\nis dropped, the theory ceases to be consequentialist. \n\nIt is less clear whether that claim by itself is sufficient to make\na theory consequentialist. Several philosophers assert that a moral\ntheory should not be classified as consequentialist unless it is\nagent-neutral (McNaughton and Rawling 1991, Howard-Snyder 1994, Pettit\n1997). This narrower definition is motivated by the fact that many\nself-styled critics of consequentialism argue against\nagent-neutrality.  Other philosophers prefer a broader definition that does not\nrequire a moral theory to be agent-neutral in order to be\nconsequentialist (Bennett 1989; Broome 1991, 5–6; and Skorupski\n1995). Criticisms of agent-neutrality can then be understood as\ndirected against one part of classic utilitarianism that need not be\nadopted by every moral theory that is consequentialist. Moreover,\naccording to those who prefer a broader definition of\nconsequentialism, the narrower definition conflates independent claims\nand obscures a crucial commonality between agent-neutral\nconsequentialism and other moral theories that focus exclusively on\nconsequences, such as moral egoism and recent self-styled\nconsequentialists who allow agent-relativity into their theories of\nvalue (Sen 1982, Broome 1991, Portmore 2001, 2003). \n\nA definition solely in terms of consequences might seem too broad,\nbecause it includes absurd theories such as the theory that an act is\nmorally right if it increases the number of goats in Texas. Of course,\nsuch theories are implausible. Still, it is not implausible to call\nthem consequentialist, since they do look only at consequences. The\nimplausibility of one version of consequentialism does not make\nconsequentialism implausible in general, since other versions of\nconsequentialism still might be plausible. \n\nBesides, anyone who wants to pick out a smaller set of moral\ntheories that excludes this absurd theory may talk about evaluative\nconsequentialism, which is the claim that moral rightness depends only\non the value of the consequences. Then those who want to talk about the\neven smaller group of moral theories that accepts both evaluative\nconsequentialism and agent-neutrality may describe them as\nagent-neutral evaluative consequentialism. If anyone still insists on\ncalling these smaller groups of theories by the simple name,\n‘consequentialism’, this narrower usage will not affect any\nsubstantive issue. \n\nStill, if the definition of consequentialism becomes too broad, it\nmight seem to lose force. Some philosophers have argued that any moral\ntheory, or at least any plausible moral theory, could be represented\nas a version of consequentialism (Sosa 1993, Portmore 2009, Dreier\n1993 and 2011; but see Brown 2011). If so, then it means little to\nlabel a theory as consequentialist. The real content comes only by\ncontrasting theories that are not consequentialist. \n\nIn the end, what matters is only that we get clear about which\ntheories a particular commentator counts as consequentialist or not\nand which claims are supposed to make them consequentialist or\nnot. Only then can we know which claims are at stake when this\ncommentator supports or criticizes what they call\n“consequentialism”. Then we can ask whether each objection really\nrefutes that particular claim. \n\nSome moral theorists seek a single simple basic principle because they\nassume that simplicity is needed in order to decide what is right when\nless basic principles or reasons conflict. This assumption seems to\nmake hedonism attractive.  Unfortunately, however, hedonism is not as\nsimple as they assume, because hedonists count both pleasures and\npains. Pleasure is distinct from the absence of pain, and pain is\ndistinct from the absence of pleasure, since sometimes people feel\nneither pleasure nor pain, and sometimes they feel both at\nonce. Nonetheless, hedonism was adopted partly because it seemed\nsimpler than competing views. \n\nThe simplicity of hedonism was also a source of opposition. From the\nstart, the hedonism in classic utilitarianism was treated with\ncontempt. Some contemporaries of Bentham and Mill argued that hedonism\nlowers the value of human life to the level of animals, because it\nimplies that, as Bentham said, an unsophisticated game (such as\npush-pin) is as good as highly intellectual poetry if the game creates\nas much pleasure (Bentham 1843).  Quantitative hedonists\nsometimes respond that great poetry almost always creates more\npleasure than trivial games (or sex and drugs and rock-and-roll),\nbecause the pleasures of poetry are more certain (or probable),\ndurable (or lasting), fecund (likely to lead to other pleasures), pure\n(unlikely to lead to pains), and so on. \n\nMill used a different strategy to avoid calling push-pin as good as\npoetry. He distinguished higher and lower qualities of pleasures\naccording to the preferences of people who have experienced both kinds\n(Mill 1861, 56; compare Plato 1993 and Hutcheson 1755, 421–23). This\nqualitative hedonism has been subjected to much criticism,\nincluding charges that it is incoherent and does not count as hedonism\n(Moore 1903, 80–81; cf. Feldman 1997, 106–24). \n\nEven if qualitative hedonism is coherent and is a kind of hedonism, it\nstill might not seem plausible. Some critics argue that not\nall pleasures are valuable, since, for example, there is no\nvalue in the pleasures that a sadist gets from whipping a victim or\nthat an addict gets from drugs. Other opponents object that not\nonly pleasures are intrinsically valuable, because other\nthings are valuable independently of whether they lead to pleasure or\navoid pain. For example, my love for my wife does not seem to become\nless valuable when I get less pleasure from her because she contracts\nsome horrible disease. Similarly, freedom seems valuable even when it\ncreates anxiety, and even when it is freedom to do something (such as\nleave one’s country) that one does not want to do. Again, many people\nvalue knowledge of distant galaxies regardless of whether this knowledge\nwill create pleasure or avoid pain. \n\nThese points against hedonism are often supplemented with the story\nof the experience machine found in Nozick (1974, 42–45; cf. De Brigard 2010 and the movie,\nThe Matrix. People on this machine believe they are\nspending time with their friends, winning Olympic gold medals and Nobel prizes,\nhaving sex with their favorite lovers, or doing whatever gives them the\ngreatest balance of pleasure over pain. Although they have no real\nfriends or lovers and actually accomplish nothing, people on the\nexperience machine get just as much pleasure as if their beliefs were\ntrue. Moreover, they feel no (or little) pain. Assuming that the\nmachine is reliable, it would seem irrational not to hook oneself up to\nthis machine if pleasure and pain were all that mattered, as\nhedonists claim. Since it does not seem irrational to refuse\nto hook oneself up to this machine, hedonism seems inadequate. The\nreason is that hedonism overlooks the value of real\nfriendship, knowledge, freedom, and achievements, all of which are\nlacking for deluded people on the experience machine. \n\nSome hedonists claim that this objection rests on a\nmisinterpretation of hedonism. If hedonists see pleasure and pain as\nsensations, then a machine might be able to reproduce those\nsensations. However, we can also say that a mother is pleased that her\ndaughter gets good grades. Such propositional pleasure occurs\nonly when the state of affairs in which the person takes pleasure\nexists (that is, when the daughter actually gets good grades). But the\nrelevant states of affairs would not really exist if one were hooked\nup to the experience machine. Hence, hedonists who value propositional\npleasure rather than sensational pleasure can deny that more pleasure\nis achieved by hooking oneself up to such an experience machine\n(Feldman 1997, 79–105; see also Tännsjö 1998 and\nFeldman 2004 for more on hedonism). \n\nA related position rests on the claim that what is good is desire\nsatisfaction or the fulfillment of preferences; and what is bad is the\nfrustration of desires or preferences. What is desired or preferred is\nusually not a sensation but is, rather, a state of affairs, such as\nhaving a friend or accomplishing a goal. If a person desires or prefers\nto have true friends and true accomplishments and not to be deluded,\nthen hooking this person up to the experience machine need not maximize\ndesire satisfaction. Utilitarians who adopt this theory of value can\nthen claim that an agent morally ought to do an act if and only if that\nact maximizes desire satisfaction or preference fulfillment (that is, the degree to which the act achieves whatever is desired or preferred). What maximizes desire satisfaction or preference fulfillment need not maximize sensations of pleasure when what is desired or preferred is not a sensation of pleasure. This position is\nusually described as preference utilitarianism. \n\nOne problem for preference utilitarianism concerns how to make\ninterpersonal comparisons (though this problem also arises for several\nother theories of value). If we want to know what one person prefers,\nwe can ask what that person would choose in conflicts. We cannot,\nhowever, use the same method to determine whether one person’s\npreference is stronger or weaker than another person’s preference,\nsince these different people might choose differently in the decisive\nconflicts. We need to settle which preference (or pleasure) is\nstronger because we may know that Jones prefers A’s being done to A’s\nnot being done (and Jones would receive more pleasure from A’s being\ndone than from A’s not being done), whereas Smith prefers A’s not\nbeing done (and Smith would receive more pleasure from A’s not being\ndone than from A’s being done). To determine whether it is right to do\nA or not to do A, we must be able to compare the strengths of Jones’s\nand Smith’s preferences (or the amounts of pleasure each would receive\nin her preferred outcome) in order to determine whether doing A or not\ndoing A would be better overall. Utilitarians and consequentialists\nhave proposed many ways to solve this problem of interpersonal\ncomparison, and each attempt has received criticisms. Debates about\nthis problem still rage. (For a recent discussion with references, see\nCoakley 2015.) \n\nPreference utilitarianism is also often criticized on the grounds that\nsome preferences are misinformed, crazy, horrendous, or trivial. I\nmight prefer to drink the liquid in a glass because I think that it is\nbeer, though it really is strong acid. Or I might prefer to die merely because\nI am clinically depressed. Or I might prefer to torture children. Or I\nmight prefer to spend my life learning to write as small as possible.\nIn all such cases, opponents of preference utilitarianism can deny that\nwhat I prefer is really good. Preference utilitarians can respond by\nlimiting the preferences that make something good, such as by referring\nto informed desires that do not disappear after therapy (Brandt 1979).\nHowever, it is not clear that such qualifications can solve all of the\nproblems for a preference theory of value without making the theory\ncircular by depending on substantive assumptions about which\npreferences are for good things. \n\nMany consequentialists deny that all values can be reduced to any\nsingle ground, such as pleasure or desire satisfaction, so they instead\nadopt a pluralistic theory of value. Moore’s ideal\nutilitarianism, for example, takes into account the values of\nbeauty and truth (or knowledge) in addition to pleasure (Moore 1903,\n83–85, 194; 1912). Other consequentialists add the intrinsic values of\nfriendship or love, freedom or ability, justice or fairness, desert, life, virtue, and so on. \n\nIf the recognized values all concern individual welfare, then the\ntheory of value can be called welfarist (Sen 1979). When a\nwelfarist theory of value is combined with the other elements of\nclassic utilitarianism, the resulting theory can be called\nwelfarist consequentialism. \n\nOne non-welfarist theory of value is perfectionism, which\nclaims that certain states make a person’s life good without\nnecessarily being good for the person in any way that increases that\nperson’s welfare (Hurka 1993, esp. 17). If this theory of value is\ncombined with other elements of classic utilitarianism, the resulting\ntheory can be called perfectionist consequentialism or, in\ndeference to its Aristotelian roots, eudaemonistic\nconsequentialism. \n\nSimilarly, some consequentialists hold that an act is right if and\nonly if it maximizes some function of both happiness and capabilities\n(Sen 1985, Nussbaum 2000). Disabilities are then seen as bad regardless\nof whether they are accompanied by pain or loss of pleasure. \n\nOr one could hold that an act is right if it maximizes respect for\n(or minimizes violations of) certain specified moral rights. Such\ntheories are sometimes described as a utilitarianism of\nrights. This approach could be built into total consequentialism\nwith rights weighed against happiness and other values or,\nalternatively, the disvalue of rights violations could be lexically\nranked prior to any other kind of loss or harm (cf. Rawls 1971, 42).\nSuch a lexical ranking within a consequentialist moral theory would\nyield the result that nobody is ever justified in violating rights for\nthe sake of happiness or any value other than rights, although it would\nstill allow some rights violations in order to avoid or prevent other\nrights violations. \n\nWhen consequentialists incorporate a variety of values, they need to\nrank or weigh each value against the others. This is often difficult.\nSome consequentialists even hold that certain values are\nincommensurable or incomparable in that no comparison of their values\nis possible (Griffin 1986 and Chang 1997). This position allows\nconsequentialists to recognize the possibility of irresolvable moral\ndilemmas (Sinnott-Armstrong 1988, 81; Railton 2003, 249–91). \n\nPluralism about values also enables consequentialists to handle many\nof the problems that plague hedonistic utilitarianism. For example,\nopponents often charge that classical utilitarians cannot explain our\nobligations to keep promises and not to lie when no pain is caused or\npleasure is lost. Whether or not hedonists can meet this challenge,\npluralists can hold that knowledge is intrinsically good and/or that\nfalse belief is intrinsically bad. Then, if deception causes false\nbeliefs, deception is instrumentally bad, and agents ought not to lie\nwithout a good reason, even when lying causes no pain or loss of\npleasure. Since lying is an attempt to deceive, to lie is to attempt to\ndo what is morally wrong (in the absence of defeating factors).\nSimilarly, if a promise to do an act is an attempt to make an audience\nbelieve that the promiser will do the act, then to break a promise is\nfor a promiser to make false a belief that the promiser created or tried to create.\nAlthough there is more tale to tell, the disvalue of false belief can\nbe part of a consequentialist story about why it is morally wrong to\nbreak promises. \n\nWhen such pluralist versions of consequentialism are not welfarist,\nsome philosophers would not call them utilitarian. However,\nthis usage is not uniform, since even non-welfarist views are sometimes\ncalled utilitarian. Whatever you call them, the important point is that\nconsequentialism and the other elements of classical utilitarianism are\ncompatible with many different theories about which things are good or\nvaluable. \n\nInstead of turning pluralist, some consequentialists foreswear the\naggregation of values. Classic utilitarianism added up the values\nwithin each part of the consequences to determine which total set of\nconsequences has the most value in it. One could, instead, aggregate\ngoods for each individual but not aggregate goods of separate\nindividuals (Roberts 2002). Or one could give up aggregation\naltogether and just rank total sets of consequences or total worlds\ncreated by acts without breaking those worlds down into valuable\nparts. One motive for this move is Moore’s principle of organic unity\n(Moore 1903, 27–36), which claims that the value of a combination or “organic unity” of two or more things cannot be calculated simply by adding the values of the things that are combined or unified. For example, even if punishment of a criminal\ncauses pain, a consequentialist can hold that a world with both the\ncrime and the punishment is better than a world with the crime but not\nthe punishment, perhaps because the former contains more\njustice. Similarly, a world might seem better when people do not get\npleasures that they do not deserve. Cases like these lead some\nconsequentialists to deny that moral rightness is any function of the\nvalues of particular effects of acts. Instead, they compare the whole\nworld (or total set of consequences) that results from an action with\nthe whole world that results from not doing that action. If the former\nis better, then the action is morally right (J.J.C. Smart 1973, 32;\nFeldman 1997, 17–35). This approach can be called holistic\nconsequentialism or world utilitarianism. \n\nAnother way to incorporate relations among values is to consider\ndistribution. Compare one outcome where most people are\ndestitute but a few lucky people have extremely large amounts of goods\nwith another outcome that contains slightly less total goods but where\nevery person has nearly the same amount of goods. Egalitarian critics\nof classical utilitarianism argue that the latter outcome is better, so\nmore than the total amount of good matters. Traditional hedonistic\nutilitarians who prefer the latter outcome often try to justify\negalitarian distributions of goods by appealing to a principle of\ndiminishing marginal utility. Other consequentialists, however,\nincorporate a more robust commitment to equality. Early on, Sidgwick\n(1907, 417) responded to such objections by allowing distribution to\nbreak ties between other values. More recently, some consequentialists\nhave added some notion of fairness (Broome 1991, 192–200) or desert\n(Feldman 1997, 154–74) to their test of which outcome is best. (See\nalso Kagan 1998, 48–59.) Others turn to prioritarianism, which puts more weight on people who are worse off (Adler and Norheim forthcoming). Such consequentialists do not simply add up values; they look at patterns. \n\nA related issue arises from population change. Imagine that a\ngovernment considers whether to provide free contraceptives to curb a\nrise in population. Without free contraceptives, overcrowding will\nbring hunger, disease, and pain, so each person will be worse off.\nStill, each new person will have enough pleasure and other goods that\nthe total net utility will increase with the population. Classic\nutilitarianism focuses on total utility, so it seems to imply that\nthis government should not provide free contraceptives. That seems\nimplausible to many utilitarians. To avoid this result, some\nutilitarians claim that an act is morally wrong if and only if its\nconsequences contain more pain (or other disvalues) than an\nalternative, regardless of positive values (cf. R. N. Smart 1958). This negative\nutilitarianism implies that the government should provide\ncontraceptives, since that program reduces pain (and other disvalues),\neven though it also decreases total net pleasure (or good).\nUnfortunately, negative utilitarianism also seems to imply that the\ngovernment should painlessly kill everyone it can, since dead people\nfeel no pain (and have no false beliefs, diseases, or disabilities\n– though killing them does cause loss of ability). A more popular response is average\nutilitarianism, which says that the best consequences are those with\nthe highest average utility (cf. Rawls 1971, 161–75). The average\nutility would be higher with the contraceptive program than without\nit, so average utilitarianism yields the more plausible\nresult—that the government should adopt the contraceptive\nprogram. Critics sometimes charge that the average utility could also\nbe increased by killing the worst off, but this claim is not at all\nclear, because such killing would put everyone in danger (since, after\nthe worst off are killed, another group becomes the worst off, and\nthen they might be killed next). Still, average utilitarianism faces\nproblems of its own (such as “the mere addition paradox”\nin Parfit 1984, chap. 19). In any case, all maximizing\nconsequentialists, whether or not they are pluralists, must decide\nwhether moral rightness depends on maximizing total good or average good. \n\nA final challenge to consequentialists’ accounts of value\nderives from Geach 1956 and has been pressed recently by Thomson 2001.\nThomson argues that “A is a good X” (such as a good poison)\ndoes not entail “A is good”, so the term “good”\nis an attributive adjective and cannot legitimately be used without\nqualification. On this view, it is senseless to call something good\nunless this means that it is good for someone or in some respect or for\nsome use or at some activity or as an instance of some kind.\nConsequentialists are supposed to violate this restriction when they\nsay that the total or average consequences or the world as a whole is\ngood without any such qualification. However, consequentialists can\nrespond either that the term “good” has predicative uses in\naddition to its attributive uses or that when they call a world or\ntotal set of consequences good, they are calling it good for\nconsequences or for a world (Sinnott-Armstrong 2003a). If so, the fact\nthat “good” is often used attributively creates no problem\nfor consequentialists. \n\nA second set of problems for classic utilitarianism is\nepistemological. Classic utilitarianism seems to require that agents\ncalculate all consequences of each act for every person for all time.\nThat’s impossible. \n\nThis objection rests on a misinterpretation. These critics assume that the\nprinciple of utility is supposed to be used as a decision\nprocedure or guide, that is, as a method that agents\nconsciously apply to acts in advance to help them make decisions.\nHowever, most classic and contemporary utilitarians and\nconsequentialists do not propose their principles as decision\nprocedures. (Bales 1971) Bentham wrote, “It is not to be expected\nthat this process [his hedonic calculus] should be strictly pursued\npreviously to every moral judgment.” (1789, Chap. IV, Sec. VI)\nMill agreed, “it is a misapprehension of the utilitarian mode of\nthought to conceive it as implying that people should fix their minds\nupon so wide a generality as the world, or society at large.”\n(1861, Chap. II, Par. 19) Sidgwick added, “It is not necessary\nthat the end which gives the criterion of rightness should always be\nthe end at which we consciously aim.” (1907, 413) \n\nInstead, most consequentialists claim that overall utility is the\ncriterion or standard of what is morally right or\nmorally ought to be done. Their theories are intended to spell out the\nnecessary and sufficient conditions for an act to be morally right,\nregardless of whether the agent can tell in advance whether those\nconditions are met. Just as the laws of physics govern golf ball\nflight, but golfers need not calculate physical forces while planning\nshots; so overall utility can determine which decisions are morally\nright, even if agents need not calculate utilities while making\ndecisions. If the principle of utility is used as a criterion of the\nright rather than as a decision procedure, then classical\nutilitarianism does not require that anyone know the total consequences\nof anything before making a decision. \n\nFurthermore, a utilitarian criterion of right implies that it would\nnot be morally right to use the principle of utility as a decision\nprocedure in cases where it would not maximize utility to try to\ncalculate utilities before acting. Utilitarians regularly argue that\nmost people in most circumstances ought not to try to calculate\nutilities, because they are too likely to make serious miscalculations\nthat will lead them to perform actions that reduce utility. It is even\npossible to hold that most agents usually ought to follow their moral\nintuitions, because these intuitions evolved to lead us to perform acts\nthat maximize utility, at least in likely circumstances (Hare 1981,\n46–47). Some utilitarians (Sidgwick 1907, 489–90) suggest that a\nutilitarian decision procedure may be adopted as an esoteric morality\nby an elite group that is better at calculating utilities, but\nutilitarians can, instead, hold that nobody should use the principle of\nutility as a decision procedure. \n\nThis move is supposed to make consequentialism self-refuting,\naccording to some opponents. However, there is nothing incoherent about\nproposing a decision procedure that is separate from one’s criterion of\nthe right. Similar distinctions apply in other normative realms. The\ncriterion of a good stock investment is its total return, but the best\ndecision procedure still might be to reduce risk by buying an index\nfund or blue-chip stocks. Criteria can, thus, be self-effacing without\nbeing self-refuting (Parfit 1984, chs. 1 and 4). \n\nOthers object that this move takes the force out of\nconsequentialism, because it leads agents to ignore consequentialism\nwhen they make real decisions. However, a criterion of the right can be\nuseful at a higher level by helping us choose among available decision\nprocedures and refine our decision procedures as circumstances change\nand we gain more experience and knowledge. Hence, most\nconsequentialists do not mind giving up consequentialism as a direct\ndecision procedure as long as consequences remain the criterion of\nrightness (but see Chappell 2001). \n\nIf overall utility is the criterion of moral rightness, then it\nmight seem that nobody could know what is morally right. If so,\nclassical utilitarianism leads to moral skepticism. However,\nutilitarians insist that we can have strong reasons to believe that\ncertain acts reduce utility, even if we have not yet inspected or\npredicted every consequence of those acts. For example, in normal\ncircumstances, if someone were to torture and kill his children, it is\npossible that this would maximize utility, but that is very unlikely.\nMaybe they would have grown up to be mass murders, but it is at least\nas likely that they would grow up to cure serious diseases or do other great\nthings, and it is much more likely that they would have led normally\nhappy (or at least not destructive) lives. So observers as well as\nagents have adequate reasons to believe that such acts are morally\nwrong, according to act utilitarianism. In many other cases, it will\nstill be hard to tell whether an act will maximize utility, but that\nshows only that there are severe limits to our knowledge of what is\nmorally right. That should be neither surprising nor problematic for\nutilitarians. \n\nIf utilitarians want their theory to allow more moral knowledge,\nthey can make a different kind of move by turning from actual\nconsequences to expected or expectable consequences. Suppose that Alice\nfinds a runaway teenager who asks for money to get home. Alice wants to\nhelp and reasonably believes that buying a bus ticket home for this\nrunaway will help, so she buys a bus ticket and puts the runaway on the\nbus. Unfortunately, the bus is involved in a freak accident, and the\nrunaway is killed. If actual consequences are what determine moral\nwrongness, then it was morally wrong for Alice to buy the bus ticket\nfor this runaway. Opponents claim that this result is absurd enough to\nrefute classic utilitarianism. \n\nSome utilitarians bite the bullet and say that Alice’s act was\nmorally wrong, but it was blameless wrongdoing, because her motives\nwere good, and she was not responsible, given that she could not have\nforeseen that her act would cause harm. Since this theory makes actual\nconsequences determine moral rightness, it can be called actual\nconsequentialism. \n\nOther responses claim that moral rightness depends on foreseen,\nforeseeable, intended, or likely consequences, rather than actual ones.\nImagine that Bob does not in fact foresee a bad consequence that would\nmake his act wrong if he did foresee it, but that Bob could easily have\nforeseen this bad consequence if he had been paying attention. Maybe he\ndoes not notice the rot on the hamburger he feeds to his kids which\nmakes them sick. If foreseen consequences are what matter,\nthen Bob’s act is not morally wrong. If foreseeable\nconsequences are what matter, then Bob’s act is morally wrong, because\nthe bad consequences were foreseeable. Now consider Bob’s wife, Carol,\nwho notices that the meat is rotten but does not want to have to buy\nmore, so she feeds it to her children anyway, hoping that it will not\nmake them sick; but it does. Carol’s act is morally wrong if foreseen\nor foreseeable consequences are what matter, but not if what matter are\nintended consequences, because she does not intend to make her\nchildren sick. Finally, consider Bob and Carol’s son Don, who does not\nknow enough about food to be able to know that eating rotten meat can\nmake people sick. If Don feeds the rotten meat to his little sister,\nand it makes her sick, then the bad consequences are not intended,\nforeseen, or even foreseeable by Don, but those bad results are still\nobjectively likely or probable, unlike the case of\nAlice. Some philosophers deny that probability can be fully objective,\nbut at least the consequences here are foreseeable by others who are\nmore informed than Don can be at the time. For Don to feed the rotten\nmeat to his sister is, therefore, morally wrong if likely consequences\nare what matter, but not morally wrong if what matter are foreseen or\nforeseeable or intended consequences. \n\nConsequentialist moral theories that focus on actual or objectively\nprobable consequences are often described as objective\nconsequentialism (Railton 1984). In contrast, consequentialist\nmoral theories that focus on intended or foreseen consequences are\nusually described as subjective consequentialism.\nConsequentialist moral theories that focus on reasonably foreseeable\nconsequences are then not subjective insofar as they do not depend on\nanything inside the actual subject’s mind, but they are subjective\ninsofar as they do depend on which consequences this particular subject\nwould foresee if he or she were better informed or more rational. \n\nOne final solution to these epistemological problems deploys the legal\nnotion of proximate cause. If consequentialists define consequences in\nterms of what is caused (unlike Sosa 1993), then which future events\ncount as consequences is affected by which notion of causation is used\nto define consequences. Suppose I give a set of steak knives to a\nfriend. Unforeseeably, when she opens my present, the decorative\npattern on the knives somehow reminds her of something horrible that\nher husband did. This memory makes her so angry that she voluntarily\nstabs and kills him with one of the knives. She would not have killed\nher husband if I had given her spoons instead of knives.  Did my\ndecision or my act of giving her knives cause her husband’s death?\nMost people (and the law) would say that the cause was her act, not\nmine. Why? One explanation is that her voluntary act intervened in the\ncausal chain between my act and her husband’s death. Moreover, even if\nshe did not voluntarily kill him, but instead she slipped and fell on\nthe knives, thereby killing herself, my gift would still not be a\ncause of her death, because the coincidence of her falling intervened\nbetween my act and her death. The point is that, when voluntary acts\nand coincidences intervene in certain causal chains, then the results\nare not seen as caused by the acts further back in the chain of\nnecessary conditions (Hart and Honoré 1985). Now, if we assume\nthat an act must be such a proximate cause of a harm in order for that\nharm to be a consequence of that act, then consequentialists can claim\nthat the moral rightness of that act is determined only by such\nproximate consequences. This position, which might be called\nproximate consequentialism, makes it much easier for agents\nand observers to justify moral judgments of acts because it obviates\nthe need to predict non-proximate consequences in distant times and\nplaces. Hence, this move is worth considering, even though it has\nnever been developed as far as I know and deviates far from traditional\nconsequentialism, which counts not only proximate consequences but all\nupshots — that is, everything for which the act is a causally\nnecessary condition. \n\nAnother problem for utilitarianism is that it seems to overlook\njustice and rights. One common illustration is called Transplant.\nImagine that each of five patients in a hospital will die without an\norgan transplant. The patient in Room 1 needs a heart, the patient in\nRoom 2 needs a liver, the patient in Room 3 needs a kidney, and so on.\nThe person in Room 6 is in the hospital for routine tests. Luckily (for\nthem, not for him!), his tissue is compatible with the other five\npatients, and a specialist is available to transplant his organs into\nthe other five. This operation would save all five of their lives, while killing\nthe “donor”. There is no other way to save any of the other five\npatients (Foot 1966, Thomson 1976; compare related cases in Carritt\n1947 and McCloskey 1965). \n\nWe need to add that the organ recipients will emerge healthy, the\nsource of the organs will remain secret, the doctor won’t be caught or\npunished for cutting up the “donor”, and the doctor knows all of this\nto a high degree of probability (despite the fact that many others\nwill help in the operation). Still, with the right details filled in (no matter how unrealistic),\nit looks as if cutting up the “donor” will maximize utility, since\nfive lives have more utility than one life (assuming that the five\nlives do not contribute too much to overpopulation). If so, then\nclassical utilitarianism implies that it would not be morally wrong\nfor the doctor to perform the transplant and even that it would be\nmorally wrong for the doctor not to perform the transplant. Most\npeople find this result abominable. They take this example to show how\nbad it can be when utilitarians overlook individual rights, such as\nthe unwilling donor’s right to life. \n\nUtilitarians can bite the bullet, again. They can deny that it is\nmorally wrong to cut up the “donor” in these circumstances. Of course,\ndoctors still should not cut up their patients in anything close to\nnormal circumstances, but this example is so abnormal and unrealistic that we should\nnot expect our normal moral rules to apply, and we should not trust our\nmoral intuitions, which evolved to fit normal situations (Sprigge\n1965). Many utilitarians are happy to reject common moral intuitions in\nthis case, like many others (cf. Singer 1974, Unger 1996, Norcross\n1997). \n\nMost utilitarians lack such strong stomachs (or teeth), so they\nmodify utilitarianism to bring it in line with common moral intuitions,\nincluding the intuition that doctors should not cut up innocent\npatients. One attempt claims that a killing is worse than a death. The\ndoctor would have to kill the “donor” in order to prevent the deaths of\nthe five patients, but nobody is killed if the five patients die. If\none killing is worse than five deaths that do not involve killing, then\nthe world that results from the doctor performing the transplant is\nworse than the world that results from the doctor not performing the\ntransplant. With this new theory of value, consequentialists can agree\nwith others that it is morally wrong for the doctor to cut up the\n“donor” in this example. \n\nA modified example still seems problematic. Just suppose that the\nfive patients need a kidney, a lung, a heart, and so forth because they\nwere all victims of murder attempts. Then the world will contain the\nfive killings of them if they die, but not if they do not die. Thus,\neven if killings are worse than deaths that are not killings, the world\nwill still be better overall (because it will contain fewer killings as\nwell as fewer deaths) if the doctor cuts up the “donor” to save the\nfive other patients. But most people still think it would be morally\nwrong for the doctor to kill the one to prevent the five killings. The\nreason is that it is not the doctor who kills the five, and the\ndoctor’s duty seems to be to reduce the amount of killing that she\nherself does. In this view, the doctor is not required to\npromote life or decrease death or even decrease killing by\nother people. The doctor is, instead, required to honor the\nvalue of life by not causing loss of life (cf. Pettit 1997). \n\nThis kind of case leads some consequentialists to introduce\nagent-relativity into their theory of value (Sen 1982, Broome 1991,\nPortmore 2001, 2003). To apply a consequentialist moral theory, we need\nto compare the world with the transplant to the world without the\ntransplant. If this comparative evaluation must be agent-neutral, then,\nif an observer judges that the world with the transplant is better, the\nagent must make the same judgment, or else one of them is mistaken.\nHowever, if such evaluations can be agent-relative, then it could be\nlegitimate for an observer to judge that the world with the transplant\nis better (since it contains fewer killings by anyone), while it is\nalso legitimate for the doctor as agent to judge that the world with\nthe transplant is worse (because it includes a killing by\nhim). In other cases, such as competitions, it might maximize the\ngood from an agent’s perspective to do an act, while maximizing\nthe good from an observer’s perspective to stop the agent from\ndoing that very act. If such agent-relative value makes sense, then it\ncan be built into consequentialism to produce the claim that an act is\nmorally wrong if and only if the act’s consequences include less\noverall value from the perspective of the agent. This\nagent-relative consequentialism, plus the claim that the world\nwith the transplant is worse from the perspective of the doctor, could\njustify the doctor’s judgment that it would be morally wrong for him to\nperform the transplant. A key move here is to adopt the agent’s\nperspective in judging the agent’s act. Agent-neutral\nconsequentialists judge all acts from the observer’s perspective,\nso they would judge the doctor’s act to be wrong, since the world\nwith the transplant is better from an observer’s perspective. In\ncontrast, an agent-relative approach requires observers to adopt the\ndoctor’s perspective in judging whether it would be morally wrong for\nthe doctor to perform the transplant. This kind of agent-relative\nconsequentialism is then supposed to capture commonsense moral\nintuitions in such cases. \n\nAgent-relativity is also supposed to solve other problems. W. D.\nRoss (1930, 34–35) argued that, if breaking a promise created only\nslightly more happiness overall than keeping the promise, then the\nagent morally ought to break the promise according to classic\nutilitarianism. This supposed counterexample cannot be avoided simply\nby claiming that keeping promises has agent-neutral value, since\nkeeping one promise might prevent someone else from keeping another\npromise. Still, agent-relative consequentialists can respond that\nkeeping a promise has great value from the perspective of the agent who\nmade the promise and chooses whether or not to keep it, so the world\nwhere a promise is kept is better from the agent’s perspective than\nanother world where the promise is not kept, unless enough other values\noverride the value of keeping the promise. In this way, agent-relative\nconsequentialists can explain why agents morally ought not to break\ntheir promises in just the kind of case that Ross raised. \n\nSimilarly, critics of utilitarianism often argue that utilitarians\ncannot be good friends, because a good friend places more weight on the\nwelfare of his or her friends than on the welfare of strangers, but\nutilitarianism requires impartiality among all people. However,\nagent-relative consequentialists can assign more weight to the welfare\nof a friend of an agent when assessing the value of the consequences of\nthat agent’s acts. In this way, consequentialists try to capture common\nmoral intuitions about the duties of friendship (see also Jackson 1991). \n\nOne final variation still causes trouble. Imagine that the doctor\nherself wounded the five people who need organs. If the doctor does not\nsave their lives, then she will have killed them herself. In this case,\neven if the doctor can disvalue killings by herself more than killings\nby other people, the world still seems better from her own perspective\nif she performs the transplant. Critics will object that it is,\nnonetheless, morally wrong for the doctor to perform the transplant.\nMany people will not find this intuition as clear as in the other\ncases, but those who do find it immoral for the doctor to perform the\ntransplant even in this case will want to modify consequentialism in\nsome other way in order to yield the desired judgment. \n\nThis problem cannot be solved by building rights or fairness or\ndesert into the theory of value. The five do not deserve to die, and\nthey do deserve their lives, just as much as the one does. Each option\nviolates someone’s right not to be killed and is unfair to someone. So\nconsequentialists need more than just new values if they want to avoid\nendorsing this transplant. \n\nOne option is to go indirect. A direct consequentialist holds\nthat the moral qualities of something depend only on the consequences\nof that very thing. Thus, a direct consequentialist about motives\nholds that the moral qualities of a motive depend on the consequences\nof that motive. A direct consequentialist about virtues holds that the\nmoral qualities of a character trait (such as whether or not it is a\nmoral virtue) depend on the consequences of that trait (Driver 2001a,\nHurka 2001, Jamieson 2005, Bradley 2005). A direct consequentialist\nabout acts holds that the moral qualities of an act depend on the\nconsequences of that act. Someone who adopts direct consequentialism\nabout everything is a global direct consequentialist (Pettit\nand Smith 2000, Driver 2012). \n\nIn contrast, an indirect consequentialist holds that the\nmoral qualities of something depend on the consequences of something\nelse. One indirect version of consequentialism is motive\nconsequentialism, which claims that the moral qualities of an act\ndepend on the consequences of the motive of that act (compare Adams\n1976 and Sverdlik 2011). Another indirect version is virtue\nconsequentialism, which holds that whether an act is morally\nright depends on whether it stems from or expresses a state of\ncharacter that maximizes good consequences and, hence, is a\nvirtue. \n\nThe most common indirect consequentialism is rule\nconsequentialism, which makes the moral rightness of an act\ndepend on the consequences of a rule (Singer 1961). Since a rule is an abstract\nentity, a rule by itself strictly has no consequences. Still,\nobedience rule consequentialists can ask what would happen if\neverybody obeyed a rule or what would happen if everybody violated a\nrule. They might argue, for example, that theft is morally wrong\nbecause it would be disastrous if everybody broke a rule against\ntheft. Often, however, it does not seem morally wrong to break a rule\neven though it would cause disaster if everybody broke it. For\nexample, if everybody broke the rule “Have some children”,\nthen our species would die out, but that hardly shows it is morally\nwrong not to have any children. Luckily, our species will not die out\nif everyone is permitted not to have children, since enough people\nwant to have children. Thus, instead of asking, “What would\nhappen if everybody did that?”, rule consequentialists should\nask, “What would happen if everybody were permitted to do\nthat?” People are permitted to do what violates no accepted\nrule, so asking what would happen if everybody were permitted to do an\nact is just the flip side of asking what would happen if people\naccepted a rule that forbids that act. Such acceptance rule\nconsequentialists then claim that an act is morally wrong if and\nonly if it violates a rule whose acceptance has better consequences\nthan the acceptance of any incompatible rule. In some accounts, a rule\nis accepted when it is built into individual consciences (Brandt\n1992). Other rule utilitarians, however, require that moral rules be\npublicly known (Gert 2005; cf. Sinnott-Armstrong 2003b) or built into\npublic institutions (Rawls 1955). Then they hold what can be called\npublic acceptance rule consequentialism: an act is morally\nwrong if and only if it violates a rule whose public acceptance\nmaximizes the good. \n\nThe indirectness of such rule utilitarianism provides a way to remain\nconsequentialist and yet capture the common moral intuition that it is\nimmoral to perform the transplant in the above situation. Suppose\npeople generally accepted a rule that allows a doctor to transplant\norgans from a healthy person without consent when the doctor believes\nthat this transplant will maximize utility. Widely accepting this rule\nwould lead to many transplants that do not maximize utility, since\ndoctors (like most people) are prone to errors in predicting\nconsequences and weighing utilities. Moreover, if the rule is publicly\nknown, then patients will fear that they might be used as organ\nsources, so they would be less likely to go to a doctor when they need\none. The medical profession depends on trust that this public rule\nwould undermine. For such reasons, some rule utilitarians conclude\nthat it would not maximize utility for people generally to accept a\nrule that allows doctors to transplant organs from unwilling\ndonors. If this claim is correct, then rule utilitarianism implies\nthat it is morally wrong for a particular doctor to use an unwilling\ndonor, even for a particular transplant that would have better\nconsequences than any alternative even from the doctor’s own\nperspective. Common moral intuition is thereby preserved. \n\nRule utilitarianism faces several potential counterexamples (such as\nwhether public rules allowing slavery could sometimes maximize utility)\nand needs to be formulated more precisely (particularly in order to\navoid collapsing into act-utilitarianism; cf. Lyons 1965). Such\ndetails are discussed in another entry in this encyclopedia (see\nHooker on rule-consequentialism). Here I just want to point out that\ndirect consequentialists find it convoluted and implausible to judge a particular act by\nthe consequences of something else (Smart 1956). Why should mistakes\nby other doctors in other cases make this doctor’s act morally wrong,\nwhen this doctor knows for sure that he is not mistaken in this case?\nRule consequentialists can respond that we should not claim special\nrights or permissions that we are not willing to grant to every other\nperson, and that it is arrogant to think we are less prone to mistakes\nthan other people are. However, this doctor can reply that he is\nwilling to give everyone the right to violate the usual rules in the\nrare cases when they do know for sure that violating those rules\nreally maximizes utility. Anyway, even if rule utilitarianism accords\nwith some common substantive moral intuitions, it still seems\ncounterintuitive in other ways. This makes it worthwhile to consider\nhow direct consequentialists can bring their views in line with common\nmoral intuitions, and whether they need to do so. \n\nAnother popular charge is that classic utilitarianism demands too\nmuch, because it requires us to do acts that are or should be moral\noptions (neither obligatory nor forbidden). (Scheffler 1982) For\nexample, imagine that my old shoes are serviceable but dirty, so I want\na new pair of shoes that costs $100. I could wear my old shoes and give\nthe $100 to a charity that will use my money to save someone else’s\nlife. It would seem to maximize utility for me to give the $100 to the\ncharity. If it is morally wrong to do anything other than what\nmaximizes utility, then it is morally wrong for me to buy the shoes.\nBut buying the shoes does not seem morally wrong. It might be morally\nbetter to give the money to charity, but such contributions seem\nsupererogatory, that is, above and beyond the call of duty. Of course,\nthere are many more cases like this. When I watch television, I always\n(or almost always) could do more good by helping others, but it does\nnot seem morally wrong to watch television. When I choose to teach\nphilosophy rather than working for CARE or the Peace Corps, my choice\nprobably fails to maximize utility overall. If we were required to\nmaximize utility, then we would have to make very different choices in\nmany areas of our lives. The requirement to maximize utility, thus,\nstrikes many people as too demanding because it interferes with the\npersonal decisions that most of us feel should be left up to the\nindividual. \n\nSome utilitarians respond by arguing that we really are morally\nrequired to change our lives so as to do a lot more to increase\noverall utility (see Kagan 1989, P. Singer 1993, and Unger 1996). Such\nhard-liners claim that most of what most people do is morally wrong,\nbecause most people rarely maximize utility. Some such wrongdoing\nmight be blameless when agents act from innocent or even desirable\nmotives, but it is still supposed to be moral wrongdoing. Opponents of\nutilitarianism find this claim implausible, but it is not obvious that\ntheir counter-utilitarian intuitions are reliable or well-grounded\n(Murphy 2000, chs. 1–4; cf. Mulgan 2001, Singer 2005, Greene 2013). \n\nOther utilitarians blunt the force of the demandingness objection by\nlimiting direct utilitarianism to what people morally ought to do.\nEven if we morally ought to maximize utility, it need not be morally\nwrong to fail to maximize utility. John Stuart Mill, for example,\nargued that an act is morally wrong only when both it fails to\nmaximize utility and its agent is liable to punishment for the failure\n(Mill 1861). It does not always maximize utility to punish people for\nfailing to maximize utility. Thus, on this\nview, it is not always morally wrong to fail to do what one morally\nought to do. If Mill is correct about this, then utilitarians can say\nthat we ought to give much more to charity, but we are not required or\nobliged to do so, and failing to do so is not morally wrong (cf. Sinnott-Armstrong 2005). \n\nMany utilitarians still want to avoid the claim that we morally\nought to give so much to charity. One way around this claim uses a\nrule-utilitarian theory of what we morally ought to do. If it costs too\nmuch to internalize rules implying that we ought to give so much to\ncharity, then, according to such rule-utilitarianism, it is not true\nthat we ought to give so much to charity (Hooker 2000, ch. 8). \n\nAnother route follows an agent-relative theory of value. If there is\nmore value in benefiting oneself or one’s family and friends than\nthere is disvalue in letting strangers die (without killing them),\nthen spending resources on oneself or one’s family and friends would\nmaximize the good. A problem is that such consequentialism would seem\nto imply that we morally ought not to contribute those resources to\ncharity, although such contributions seem at least permissible. \n\nMore personal leeway could also be allowed by deploying the legal\nnotion of proximate causation. When a starving stranger would stay\nalive if and only if one contributed to a charity, contributing to the\ncharity still need not be the proximate cause of the stranger’s life,\nand failing to contribute need not be the proximate cause of his or her\ndeath. Thus, if an act is morally right when it includes the most net\ngood in its proximate consequences, then it might not be morally wrong\neither to contribute to the charity or to fail to do so. This potential position, as mentioned above, has not yet been developed, as far as I know. \n\nYet another way to reach this conclusion is to give up maximization\nand to hold instead that we morally ought to do what creates enough\nutility. This position is often described as satisficing\nconsequentialism (Slote 1984). According to satisficing\nconsequentialism, it is not morally wrong to fail to contribute to a\ncharity if one contributes enough to other charities and if the money\nor time that one could contribute does create enough good, so it is not\njust wasted. (For criticisms, see Bradley 2006.) A related\nposition is progressive consequentialism, which holds that we\nmorally ought to improve the world or make it better than it would be\nif we did nothing, but we don’t have to improve it as much as we can\n(Elliot and Jamieson, 2009). Both satisficing and progressive\nconsequentialism allow us to devote some of our time and money to\npersonal projects that do not maximize overall good.  A more radical set of proposals confines consequentialism to judgements about how good an act is on a scale (Norcross 2006) or to degrees of wrongness and rightness (Sinhababu 2018). A consequentialist can refuse to say whether it is absolutely right or wrong to give $1000 to charity, for example, but still say that giving $1000 to charity is better and more right than giving only $100 and simultaneously worse as well as more wrong than giving $10,000. A related contrastivist consequentialism could say that one ought to give $1000 in contrast with $100 but not in contrast with $10,000 (cf. Snedegar 2017). \n\nOpponents still object that all such consequentialist theories are\nmisdirected. When I decide to visit a friend instead of working for a\ncharity, I can know that my act is not immoral even if I have not\ncalculated that the visit will create enough overall good or that it\nwill improve the world. These critics hold that friendship requires us\nto do certain favors for friends without weighing our friends’ welfare\nimpartially against the welfare of strangers. Similarly, if I need to\nchoose between saving my drowning wife and saving a drowning stranger,\nit would be “one thought too many” (Williams 1981) for me to calculate\nthe consequences of each act. I morally should save my wife\nstraightaway without calculating utilities. \n\nIn response, utilitarians can remind critics that the principle of\nutility is intended as only a criterion of right and not as a decision\nprocedure, so utilitarianism does not imply that people ought to\ncalculate utilities before acting (Railton 1984). Consequentialists can\nalso allow the special perspective of a friend or spouse to be\nreflected in agent-relative value assessments (Sen 1982, Broome 1991,\nPortmore 2001, 2003) or probability assessments (Jackson 1991). It\nremains controversial, however, whether any form of consequentialism\ncan adequately incorporate common moral intuitions about\nfriendship. \n\nEven if consequentialists can accommodate or explain away common\nmoral intuitions, that might seem only to answer objections without yet\ngiving any positive reason to accept consequentialism. However, most\npeople begin with the presumption that we morally ought to\nmake the world better when we can. The question then is only whether\nany moral constraints or moral options need to be added to the basic\nconsequentialist factor in moral reasoning. (Kagan 1989, 1998) If no\nobjection reveals any need for anything beyond consequences, then\nconsequences alone seem to determine what is morally right or wrong,\njust as consequentialists claim. \n\nThis line of reasoning will not convince opponents who remain\nunsatisfied by consequentialist responses to objections. Moreover, even\nif consequentialists do respond adequately to every proposed objection,\nthat would not show that consequentialism is correct or even\ndefensible. It might face new problems that nobody has yet recognized.\nEven if every possible objection is refuted, we might have no reason to\nreject consequentialism but still no reason to accept it. \n\nIn case a positive reason is needed, consequentialists present a\nwide variety of arguments. One common move attacks opponents. If the\nonly plausible options in moral theory lie on a certain list (say,\nKantianism, contractarianism, virtue theory, pluralistic intuitionism,\nand consequentialism), then consequentialists can argue for their own\ntheory by criticizing the others. This disjunctive syllogism\nor process of elimination will be only as strong as the set of\nobjections to the alternatives, and the argument fails if even one\ncompetitor survives. Moreover, the argument assumes that the original\nlist is complete. It is hard to see how that assumption could be\njustified. \n\nConsequentialism also might be supported by an inference to the\nbest explanation of our moral intuitions. This argument might\nsurprise those who think of consequentialism as counterintuitive, but\nin fact consequentialists can explain many moral intuitions that\ntrouble deontological theories. Moderate deontologists, for example,\noften judge that it is morally wrong to kill one person to save five\nbut not morally wrong to kill one person to save a million. They never\nspecify the line between what is morally wrong and what is not morally\nwrong, and it is hard to imagine any non-arbitrary way for\ndeontologists to justify a cutoff point. In contrast,\nconsequentialists can simply say that the line belongs wherever the\nbenefits outweigh the costs (including any bad side\neffects). Similarly, when two promises conflict, it often seems clear\nwhich one we should keep, and that intuition can often be explained by\nthe amount of harm that would be caused by breaking each promise. In\ncontrast, deontologists are hard pressed to explain which promise is\noverriding if the reason to keep each promise is simply that it was\nmade (Sinnott-Armstrong 2009).  If consequentialists can better\nexplain more common moral intuitions, then consequentialism might have\nmore explanatory coherence overall, despite being counterintuitive in\nsome cases. (Compare Sidgwick 1907, Book IV, Chap. III; and Sverdlik\n2011.) And even if act consequentialists cannot argue in this way, it\nstill might work for rule consequentialists (such as Hooker 2000). \n\nConsequentialists also might be supported by deductive\narguments from abstract moral intuitions. Sidgwick (1907, Book III,\nChap. XIII) seemed to think that the principle of utility follows from\ncertain very general self-evident principles, including\nuniversalizability (if an act ought to be done, then every other act\nthat resembles it in all relevant respects also ought to be done),\nrationality (one ought to aim at the good generally rather than at any\nparticular part of the good), and equality (“the good of any one\nindividual is of no more importance, from the point of view ... of the\nUniverse, than the good of any other”). \n\nOther consequentialists are more skeptical about moral intuitions, so\nthey seek foundations outside morality, either in non-normative facts\nor in non-moral norms. Mill (1861) is infamous for his\n“proof” of the principle of utility from empirical\nobservations about what we desire (cf. Sayre-McCord 2001). In\ncontrast, Hare (1963, 1981) tries to derive his version of\nutilitarianism from substantively neutral accounts of morality, of\nmoral language, and of rationality (cf. Sinnott-Armstrong\n2001). Similarly, Gewirth (1978) tries to derive his variant of\nconsequentialism from metaphysical truths about actions. \n\nYet another argument for a kind of consequentialism is\ncontractarian. Harsanyi (1977, 1978) argues that all informed,\nrational people whose impartiality is ensured because they do not know\ntheir place in society would favor a kind of consequentialism. Broome\n(1991) elaborates and extends Harsanyi’s argument. \n\nOther forms of arguments have also been invoked on behalf of\nconsequentialism (e.g. Cummiskey 1996, P. Singer 1993;\nSinnott-Armstrong 1992). However, each of these arguments has also\nbeen subjected to criticisms. \n\nEven if none of these arguments proves consequentialism, there still\nmight be no adequate reason to deny consequentialism. We might have no\nreason either to deny consequentialism or to assert it.\nConsequentialism could then remain a live option even if it is not\nproven.","contact.mail":"ws66@duke.edu","contact.domain":"duke.edu"}]
