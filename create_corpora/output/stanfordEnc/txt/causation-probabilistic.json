[{"date.published":"1997-07-11","date.changed":"2018-03-09","url":"https://plato.stanford.edu/entries/causation-probabilistic/","author1":"Christopher Hitchcock","author1.info":"http://hss.divisions.caltech.edu/people/christopher-r-hitchcock","entry":"causation-probabilistic","body.text":"\n\n\n“Probabilistic Causation” designates a group of theories\nthat aim to characterize the relationship between cause and effect\nusing the tools of probability theory. The central idea behind these\ntheories is that causes change the probabilities of their effects.\nThis article traces developments in probabilistic causation, including\nrecent developments in causal modeling.\n\n\nThis entry surveys the main approaches to characterizing causation in\nterms of probability. Section 1 provides some of the motivation for\nprobabilistic approaches to causation, and addresses a few preliminary\nissues. Section 2 surveys theories that aim to characterize causation\nin terms of probability-raising. Section 3 surveys developments in\ncausal modeling. Section 4 covers probabilistic accounts of actual\ncausation.\n\n\n\n\n\nIn this section, we will provide some motivation for trying to\nunderstand causation in terms of probabilities, and address a couple\nof preliminary issues. \nAccording to David Hume, causes are invariably followed by their\neffects:  \nWe may define a cause to be an object, followed by another, and\nwhere all the objects similar to the first, are followed by objects\nsimilar to the second. (1748: section VII)  \nAttempts to analyze causation in terms of invariable patterns of\nsuccession are referred to as “regularity theories” of\ncausation. There are a number of well-known problems facing regularity\ntheories, at least in their simplest forms, and these may be used to\nmotivate probabilistic approaches to causation. Moreover, an overview\nof these difficulties will help to give a sense of the kinds of\nproblem that any adequate theory of causation would have to solve. \n(i) Imperfect Regularities. The first difficulty is that most\ncauses are not invariably followed by their effects. For example,\nsmoking is a cause of lung cancer, even though some smokers do not\ndevelop lung cancer. Imperfect regularities may arise for two\ndifferent reasons. First, they may arise because of the\nheterogeneity of circumstances in which the cause arises. For\nexample, some smokers may have a genetic susceptibility to lung\ncancer, while others do not; some non-smokers may be exposed to other\ncarcinogens (such as asbestos), while others are not. Second,\nimperfect regularities may also arise because of a failure of\nphysical determinism. If an event is not determined to occur,\nthen no other event can be (or be a part of) a sufficient condition\nfor that event. The success of quantum mechanics—and to a lesser\nextent, other theories employing probability—has shaken our\nfaith in determinism. Thus it has struck many philosophers as\ndesirable to develop a theory of causation that does not presuppose\ndeterminism. \nThe central idea behind probabilistic theories of causation is that\ncauses change the probability of their effects; an effect may\nstill occur in the absence of a cause or fail to occur in its\npresence. Thus smoking is a cause of lung cancer, not because all\nsmokers develop lung cancer, but because smokers are more\nlikely to develop lung cancer than non-smokers. This is entirely\nconsistent with there being some smokers who avoid lung cancer, and\nsome non-smokers who succumb to it. \n(ii) Irrelevance. A condition that is invariably followed by\nsome outcome may nonetheless be irrelevant to that outcome. Salt that\nhas been hexed by a sorcerer invariably dissolves when placed in water\n(Kyburg 1965), but hexing does not cause the salt to dissolve. Hexing\ndoes not make a difference for dissolution. Probabilistic\ntheories of causation capture this notion of making a difference by\nrequiring that a cause make a difference for the probability of its\neffect. \n(iii) Asymmetry. If A causes B, then,\ntypically, B will not also cause A. Smoking causes lung\ncancer, but lung cancer does not cause one to smoke. One way of\nenforcing the asymmetry of causation is to stipulate that causes\nprecede their effects in time. But it would be nice if a theory of\ncausation could provide some explanation of the directionality of\ncausation, rather than merely stipulate it. Some proponents of\nprobabilistic theories of causation have attempted to use the\nresources of probability theory to articulate a substantive account of\nthe asymmetry of causation. \n(iv) Spurious Regularities. Suppose that a cause is regularly\nfollowed by two effects. Here is an example from Jeffrey (1969):\nSuppose that whenever the barometric pressure in a certain region\ndrops below a certain level, two things happen. First, the height of\nthe column of mercury in a particular barometer drops below a certain\nlevel. Shortly afterwards, a storm occurs. This situation is shown\nschematically in Figure 1. Then, it may well also be the case that\nwhenever the column of mercury drops, there will be a storm. If so, a\nsimple regularity theory would seem to rule that the drop of the\nmercury column causes the storm. In fact, however, the\nregularity relating these two events is spurious. The ability\nto handle such spurious correlations is probably the greatest source\nof attraction for probabilistic theories of causation. \nFigure 1 \nIn this sub-section, we will review some of the basics of the\nmathematical theory of probability, and introduce some notation.\nReaders already familiar the mathematics of probability may wish to\nskip this section. \nProbability is a function, P, that assigns values between zero and\none, inclusive. Usually the arguments of the function are taken to be\nsets, or propositions in a formal language. The formal term for these\narguments is ‘events’. We will here use the notation that\nis appropriate for propositions, with ‘\\(\\nsim\\)’\nrepresenting negation, ‘&’ representing conjunction,\nand ‘\\(\\vee\\)’ representing disjunction. Sometimes when\nthere is a long conjunction, this is abbreviated by using commas instead\nof ampersands. The domain of a probability function has the structure\nof a field or a Boolean algebra. This means that the\ndomain is closed under complementation and the taking of finite unions\nor intersections (for sets), or under negation, conjunction, and\ndisjunction (for propositions). Thus if A and B are\nevents in the domain of P, so are \\({\\nsim}A\\), \\(A \\amp B\\), and \\(A\n\\vee B\\). \nSome standard properties of probability are the following: \nIn addition to probability theory, the entry will use basic notation from set\ntheory and logic. Sets will appear in boldface. \nSome further definitions: \nIf \\(\\PP(B) = 0\\), then the ratio in the definition of conditional\nprobability is undefined. There are, however, a variety of technical\ndevelopments that will allow us to define \\(\\PP(A \\mid B)\\) when\n\\(\\PP(B)\\) is 0. We will ignore this problem here. \nAs a convenient shorthand, a probabilistic statement that contains\nonly a variable or set of variables, but no values, will be understood\nas a universal quantification over all possible values of the\nvariable(s). Thus if \\(\\bX = \\{X_1 , \\ldots ,X_m\\}\\) and \\(\\bY = \\{Y_1\n, \\ldots ,Y_n\\}\\), we may write \nas shorthand for \n(where the domain of quantification for each variable will be the\nrange of the relevant random variable). \nCausal relations are normally thought to be objective features of the\nworld. If they are to be captured in terms of probability theory, then\nprobability assignments should represent some objective feature of the\nworld. There are a number of attempts to interpret probabilities\nobjectively, the most prominent being frequency\ninterpretations and propensity interpretations. Most\nproponents of probabilistic theories of causation have understood\nprobabilities in one of these two ways. Notable exceptions are Suppes\n(1970), who takes probability to be a feature of a model of a\nscientific theory; and Skyrms (1980), who understands the relevant\nprobabilities to be the subjective probabilities of a certain kind of\nrational agent. \nIt is common to distinguish between general, or\ntype-level causation, on the one hand, and singular,\ntoken-level or actual causation, on the other. This\nentry adopts the terms general causation and actual\ncausation. Causal claims usually have the structure\n‘C causes E’. C and E are the\nrelata of the causal claim; we will discuss causal relata in\nmore detail in the next section. General causation and actual\ncausation are often distinguished by their relata. General\ncausal claims, such “smoking causes lung cancer” typically\ndo not refer to particular individuals, places, or times, but only to\nevent-types or properties. Singular causal claims, such as\n“Jill’s heavy smoking during the 2000s caused her to\ndevelop lung cancer”, typically do make reference to particular\nindividuals, places, and times. This is an imperfect guide, however;\nfor example, some theories of general causation to be discussed below\ntake their causal relata to be time-indexed. \nA related distinction is that general causation is concerned with a\nfull range of possibilities, whereas actual causation is concerned\nwith how events actually play out in a specific case. At a minimum, in\nclaims of actual causation, “cause” functions as a success\nverb. The claim “Jill’s heavy smoking during the 2000s\ncaused her to develop lung cancer” implies that Jill smoked\nheavily during the 2000s and that she developed lung cancer. \nThe theories to be discussed in Sections\n 2\n and\n 3\n below primarily concern general causation, while\n Section 4\n discusses theories of actual causation. \nA number of different candidates have been proposed for the relata of\ncausal relations. The relata of actual causal relations are often\ntaken to be events (not to be confused with events in the\npurely technical sense), although some authors (e.g., Mellor 2004)\nargue that they are facts. The relata of general causal\nrelations are often taken to be properties or\nevent-types. For purposes of definiteness, \nevents will refer to the relata of actual causation, and\nfactors will refer to the relata of general causation. These\nterms are not intended to imply a commitment to any particular view on\nthe nature of the causal relata. \nIn probabilistic approaches to causation, causal relata are\nrepresented by events or random variables in a probability space.\nSince the formalism requires us to make use of negation, conjunction,\nand disjunction, the relata must be entities (or be accurately\nrepresented by entities) to which these operations can be meaningfully\napplied. \nIn some theories, the time at which an event occurs or a property is\ninstantiated plays an important role. In such cases, it will be useful\nto include a subscript indicating the relevant time. Thus the relata\nmight be represented by \\(C_t\\) and \\(E_{t'}\\). If the relata are\nparticular events, this subscript is just a reminder; it adds no\nfurther information. For example, if the event in question is the\nopening ceremony of the Rio Olympic games, the subscript\n‘8/5/2016’ is not necessary to disambiguate it from other\nevents. In the case of properties or event-types, however, such\nsubscripts do add further information. The time index need not refer\nto a date or absolute time. It could refer to a stage in the\ndevelopment of a particular kind of system. For example, exposure to\nlead paint in children can cause learning disabilities. Here the time\nindex would indicate that it is exposure in children, that\nis, in the early stages of human life, that causes the effect in\nquestion. The time indices may also indicate relative times. Exposure\nto the measles virus causes the appearance of a rash approximately two\nweeks later. We might indicate this time delay by assigning exposure a\ntime index of \\(t = 0\\), and rash an index of \\(t = 14\\) (for 14\ndays). \nIt is standard to assume that causes and effects must be\ndistinct from one another. This means that they must not\nstand in logical relations or part-whole relations to one another.\nLewis 1986a contains a detailed discussion of the relevant notion of\ndistinctness. We will typically leave this restriction tacit. \nPsillos 2009 provides an overview of regularity theories of causation.\nLewis 1973 contains a brief but clear and forceful overview of\nproblems with regularity theories. The entry for\n scientific explanation\n contains discussions of some of these problems. \nHájek and Hitchcock 2016b is a short introduction to probability\ntheory geared toward philosophical applications. Billingsley 1995 and\nFeller 1968 are two standard texts on probability theory. The entry\nfor\n interpretations of probability\n includes a brief introduction to the formalism of probability theory,\nand discusses the various interpretations of probability. Galavotti\n2005 and Gillies 2000 are good surveys of philosophical theories of\nprobability. Hájek and Hitchcock 2016a includes essays covering the\nmajor interpretations of probability.  \nThe Introduction of Eells 1991 provides a good overview of the\ndistinction between general and actual causation. \nBennett 1988 is an excellent discussion of facts and events in the\ncontext of causation. Ehring 2009 is a survey of views about causal\nrelata. See also the entries for\n the metaphysics of causation,\n events,\n facts,\n and\n properties. \nThe theories canvassed in this section all develop the basic idea that\ncauses raise the probability of their effects. These theories were\namong the leading theories of causation during the second half of the\n20th century. Today, they have largely been supplanted by\nthe causal modeling approaches discussed in\n Section 3. \nThe central idea that causes raise the probability of their effects\ncan be expressed formally using conditional probability. C\nraises the probability of E just in case: \nIn words, the probability that E occurs, given that C\noccurs, is higher than the unconditional probability that E\noccurs. Alternately, we might say that C raises the probability\nof E just in case: \nthe probability that E occurs, given that C occurs, is\nhigher than the probability that E occurs, given that C\ndoes not occur. These two formulations turn out to be equivalent in\nthe sense that inequality \\(\\PR_1\\) will hold just in case \\(\\PR_2\\)\nholds. Some authors (e.g., Reichenbach 1956, Suppes 1970, Cartwright\n1979) have formulated probabilistic theories of causation using\ninequalities like \\(\\PR_1\\), others (e.g., Skyrms 1980, Eells 1991)\nhave used inequalities like \\(\\PR_2\\). This difference is mostly\nimmaterial, but for consistency we will stick with (\\(\\PR_2)\\). Thus a\nfirst stab at a probabilistic theory of causation would be: \nPR has some advantages over the simplest version of a regularity\ntheory of causation (discussed in\n Section 1.1\n above). PR is compatible with imperfect regularities: C may\nraise the probability of E even though instances of C\nare not invariably followed by instances of E. Moreover, PR\naddresses the problem of relevance: if C is a cause of\nE, then C makes a difference for the probability of\nE. But as it stands, PR does not address either the problem of\nasymmetry, or the problem of spurious correlations. PR does not\naddress the problem of asymmetry because probability-raising turns out\nto be symmetric: \\(\\PP(E \\mid C) \\gt \\PP(E \\mid {\\nsim}C)\\),\nif and only if \\(\\PP(C \\mid E) \\gt \\PP(C \\mid {\\nsim}E)\\).\nThus PR by itself cannot determine whether C is the cause of\nE or vice versa. PR also has trouble with spurious\ncorrelations. If C and E are both caused by some\nthird factor, A, then it may be that \\(\\PP(E \\mid C) \\gt\n\\PP(E \\mid {\\nsim}C)\\) even though C does not cause\nE. This is the situation shown in\n Figure 1\n above. Here, C is the drop in the level of mercury in a\nbarometer, and E is the occurrence of a storm. Then we would\nexpect that \\(\\PP(E \\mid C) \\gt \\PP(E \\mid {\\nsim}C)\\). In\nthis case, atmospheric pressure is referred to as a\nconfounding factor. \nHans Reichenbach’s The Direction of Time was published\nposthumously in 1956. In it, Reichenbach is concerned with the origins\nof temporally asymmetric phenomena, particularly the increase in\nentropy dictated by the second law of thermodynamics. In this work, he\npresents the first fully developed probabilistic theory of causation,\nalthough some of the ideas can be traced back to an earlier paper from\n1925 (Reichenbach 1925). \nReichenbach introduced the terminology of screening off to\ndescribe a particular type of probabilistic relationship. If \\(\\PP(E\n\\mid A \\amp C) = \\PP(E \\mid C)\\), then C is said to\nscreen A off from E. When \\(\\PP(A \\amp C) \\gt 0\\), this\nequality is equivalent to \\(\\PP(A \\amp E \\mid C) = \\PP(A \\mid\nC) \\times \\PP(E \\mid C)\\); i.e., A and E are\nprobabilistically independent conditional upon C. \nReichenbach recognized that there were two kinds of causal structure\nin which C will typically screen A off from E.\nThe first occurs when A causes C, which in turn causes\nE, and there is no other route or process by which A\neffects E. This is shown in Figure 2. \nFigure 2 \nIn this case, Reichenbach said that C is causally\nbetween A and E. We might say that C is an\nintermediate cause between A and E, or that C is\na proximate cause of E and A a distal cause of E.\nFor example, unprotected sex (A) causes AIDS (E) only by\ncausing HIV infection (C). Then we would expect that among\nthose already infected with HIV, those who became infected through\nunprotected sex would be no more likely to contract AIDS than those\nwho became infected in some other way. \nThe second type of case that produces screening off occurs when\nC is a common cause of A and E, such as in the\nbarometer example depicted in\n Figure 1.\n A drop in atmospheric pressure (C) causes both a drop in the\nlevel of mercury in a barometer (A) and a storm (E).\n(This notation is slightly different from one used earlier.) The\natmospheric pressure will screen off the barometer reading from the\nweather: given that the atmospheric pressure has dropped, the\nreading of the barometer makes no difference for the probability of\nwhether a storm will occur. \nReichenbach used the apparatus of screening off to address the problem\nof spurious correlations. In our example, while a drop in the column\nof mercury (A) raises the probability of a storm (E)\noverall, it does not raise the probability of a storm when we further\ncondition on the atmospheric pressure. That is, if A and\nE are spuriously correlated, then A will be screened off\nfrom E by a common cause. More specifically, suppose that\n\\(C_t\\) and \\(E_{t'}\\) are events that occur at times t and\n\\(t'\\) respectively. Then \nNote the restriction of \\(t''\\) to times earlier than or\nsimultaneously with the occurrence of \\(C_t\\). That is because causal\nintermediates between \\(C_t\\) and \\(E_{t'}\\) will often screen \\(C_t\\)\noff from \\(E_{t'}\\). In such cases we still want to say that \\(C_t\\)\nis a cause of \\(E_{t'}\\), albeit a distal or indirect cause. \nSuppes (1970) independently offered an equivalent definition of\ncausation, although his motivation for the no-screening-off condition\nwas different from Reichenbach’s. Suppes extended the framework\nin a number of directions. While Reichenbach was interested in\nprobabilistic causation primarily in connection with issues that arise\nwithin the foundations of statistical mechanics, Suppes was interested\nin defining causation within the framework of probabilistic models of\nscientific theories. For example, Suppes offers an extended discussion\nof causation in the context of psychological models of learning. \nReichenbach (1956) formulated a principle he dubbed the ‘Common Cause\nPrinciple’ (CCP). Suppose that events A and B are\npositively correlated, i.e., that \nBut suppose that neither A nor B is a cause of the\nother. Then Reichenbach maintained that there will be a common cause,\nC, of A and B, satisfying the following\nconditions: \nWhen events A, B, and C satisfy these conditions,\nthey are said to form a conjunctive fork. 5 and 6 follow from\nC being a cause of A and a cause of B. Conditions\n2 and 3 stipulate that C and \\({\\nsim}C\\) screen off A\nfrom B. \nConditions 2 through 6 mathematically entail 1. Reichenbach says that\nthe common cause explains the correlation between A\nand B. The idea is that probabilistic correlations that are not\nthe result of one event causing another are ultimately derived from\nprobabilistic correlations that do result from a causal\nrelationship. \nReichenbach’s definition of causation, discussed in\n Section 2.2\n above, appeals to time order: it requires that a cause occur earlier\nthan its effect. But Reichenbach also thought that the direction from\ncauses to effects can be identified with a pervasive statistical\nasymmetry. Suppose that events A and B are correlated,\nand that C satisfies conditions 2–6 above, so that\nABC form a conjunctive fork. If C occurs earlier than\nA and B, and there is no event satisfying 2 through 6\nthat occurs later than A and B, then ACB is said\nto form a conjunctive fork open to the future. Analogously,\nif there is a later event satisfying 2 through 6, but no earlier\nevent, we have a conjunctive fork open to the past. If an\nearlier event C and a later event D both satisfy 2\nthrough 6, then ACBD forms a closed fork.\nReichenbach’s proposal was that the direction from cause to\neffect is the direction in which open forks predominate. In our world,\nthere are a great many forks open to the future, few or none open to\nthe past. However, we shall see in\n section 3.6\n below that conjunctive forks are not the best structures for\nidentifying causal direction.  \nIn the Reichenbach-Suppes definition of causation, the inequality\n\\(\\PP(E_{t'} \\mid C_t) \\gt \\PP(E_{t'} \\mid {\\nsim}C_t)\\) is\nnecessary, but not sufficient, for causation. It is not sufficient,\nbecause it may hold in cases where \\(C_t\\) and \\(E_{t'}\\) share a\ncommon cause. Unfortunately, common causes can also give rise to cases\nwhere this inequality is not necessary for causation either. Suppose,\nfor example, that smoking is highly correlated with living in the\ncountry: those who live in the country are much more likely to smoke\nas well. Smoking is a cause of lung cancer, but suppose that city\npollution is an even stronger cause of lung cancer. Then it may be\nthat smokers are, over all, less likely to suffer from lung cancer\nthan non-smokers. Letting C represent smoking, B living\nin the country, and E lung cancer, \\(\\PP(E \\mid C) \\lt\n\\PP(E \\mid {\\nsim}C)\\). Note, however, that if we conditionalize\non whether one lives in the country or in the city, this inequality is\nreversed: \\(\\PP(E \\mid C \\amp B) \\gt \\PP(E \\mid {\\nsim}C \\amp\nB)\\), and \\(\\PP(E \\mid C \\amp{\\nsim}B) \\gt \\PP(E \\mid {\\nsim}C\n\\amp{\\nsim}B)\\). Such reversals of probabilistic inequalities are\ninstances of “Simpson’s Paradox”. The problem that\nSimpson’s paradox creates for probabilistic theories of\ncausation was pointed out by Nancy Cartwright (1979) and Brian Skyrms\n(1980) at about the same time. \nCartwright and Skyrms sought to rectify the problem by replacing\nconditions (ii) and (iii) of\n Reich\n with the requirement that causes must raise the probabilities of\ntheir effects in various background contexts. Cartwright\nproposed the following definition: \nSkyrms proposed a slightly weaker condition: a cause must raise the\nprobability of its effect in at least one background context, and\nlower it in none. A background context is a conjunction of factors.\nWhen such a conjunction of factors is conditioned on, those factors\nare said to be “held fixed”. To specify what the\nbackground contexts will be, then, we must specify what factors are to\nbe held fixed. In the previous example, we saw that the true causal\nrelevance of smoking for lung cancer was revealed when we held country\nliving fixed, either positively (conditioning on \\(B)\\) or negatively\n(conditioning on \\({\\nsim}B)\\). This suggests that in evaluating the\ncausal relevance of C for E, we need to hold fixed other\ncauses of E, either positively or negatively. This suggestion\nis not entirely correct, however. Let C and E be smoking\nand lung cancer, respectively. Suppose D is a causal\nintermediary, say the presence of tar in the lungs. If C causes\nE exclusively via D, then D will screen C\noff from E: given the presence (absence) of tar in the lungs,\nthe probability of lung cancer is not affected by whether the tar got\nthere by smoking. Thus we will not want to hold fixed any causes of\nE that are themselves caused by C. Let us call the set\nof all factors that are causes of E, but are not caused by\nC, the set of independent causes of E. A\nbackground context for C and E will then be a maximal\nconjunction, each of whose conjuncts is either an independent cause of\nE, or the negation of an independent cause of E. \nNote that the specification of factors that need to be held fixed\nappeals to causal relations, so the theory no longer offers a\nreductive analysis of causation. Nonetheless, the theory\nimposes probabilistic constraints upon possible causal relations in\nthe sense that a given set of probability relations will be\nincompatible with at least some systems of causal relations. Note also\nthat we have dropped the subscripts referring to times. Cartwright\nclaimed that it is not necessary to appeal to the time order of events\nto distinguish causes from effects in her theory. That is because it\nwill no longer be true in general that if C raises the\nprobability of E in every relevant background context B,\nthen E raise will raise the probability of C in every\nbackground context \\(B'\\). The reason is that the construction of the\nbackground contexts ensures that the background contexts relevant to\nassessing C’s causal relevance for E are different\nfrom those relevant to assessing E’s causal relevance for\nC. However, Davis (1988) and Eells (1991) both argue cogently\nthat Cartwright’s account will still sometimes rule that effects\nbring about their causes. \nCartwright defined a cause as a factor that increases the probability\nof its effect in every background context. But it is easy to see that\nthere are other possible probability relations between C and\nE. Eells (1991) proposes the following taxonomy: \n\\(C_t\\) is causally relevant for \\(E_{t'}\\) if and only if it\nis a positive, negative, or mixed cause of \\(E_{t'}\\); i.e., if and\nonly if \\(t \\lt t'\\) and \\(C_t\\) is not causally neutral for\n\\(E_{t'}\\). \nIt should be apparent that when constructing background contexts for\nC and E one should hold fixed not only (positive) causes\nof E that are independent of \\(C,\\) but also negative and mixed\ncauses of E; in other words, one should hold fixed all factors\nthat are causally relevant for E, except those for which\nC is causally relevant. This suggests that causal relevance,\nrather than positive causation, is the most basic metaphysical\nconcept. \nEells’s taxonomy brings out an important distinction. It is one\nthing to ask whether C is causally relevant to E in\nsome way; it is another to ask in which way C is\ncausally relevant to E. To say that C causes E is\nthen potentially ambiguous: it might mean that C is causally\nrelevant to E; or it might mean that C is a positive\ncause of E. Probabilistic theories of causation can be used to\nanswer both types of question. \nEells claims that general causal claims must be relativized to a\npopulation. A very heterogeneous population will include a great many\ndifferent background conditions, while a homogeneous population will\ncontain few. A heterogeneous population can always be subdivided into\nhomogeneous subpopulations. It will often happen that C is a\nmixed cause of E relative to a population P, while being a\npositive cause, negative cause, or causally neutral for E in\nvarious subpopulations of P. \nAccording to both\n Cart\n and\n Eells,\n a cause must raise the probability of its effect in every\nbackground context. This has been called the requirement of\ncontextual-unanimity. Dupré (1984) raises the following\ncounterexample to the contextual unanimity requirement. Suppose that\nthere is a very rare gene that has the following effect: those that\npossess the gene have their chances of contracting lung cancer\nlowered when they smoke. In this scenario, there would be a\nbackground context in which smoking lowers the probability of lung\ncancer: thus smoking would not be a cause of lung cancer according to\nthe contextual-unanimity requirement. Nonetheless, it seems unlikely\nthat the discovery of such a gene would lead us to abandon the claim\nthat smoking causes lung cancer.  \nDupré suggests instead that we should deem C to be a cause of\nE if it raises the probability of E in a ‘fair\nsample’—a sample that is representative of the population\nas a whole. Mathematically, this amounts to the requirement that \nwhere B ranges over the relevant background contexts. This is\nthe same as requiring that C must raise the probability of\nE in a weighted average of background contexts, where\neach background context is weighted by the product of \\(\\PP(B)\\) and\nthe absolute value of \nDupré’s account surely comes closer to capturing our ordinary\nuse of causal language. Indeed, the inequality in\n Dupré\n is what one looks for in randomized trials. If one randomly\ndetermines which members of a population receive a treatment\n(C) and which do not \\(({\\nsim}C)\\), then the distribution of\nbackground conditions B ought to be the same in both groups,\nand ought to reflect the frequency of these conditions in the\npopulation. Thus we would expect the frequency of E to be\nhigher in the treatment group just in case inequality Dupré\nholds.  \nOn the other hand, Eells’s population-relative formulation allows\nus to make more precise causal claims: in the population as a whole,\nsmoking is a mixed cause of lung cancer; in the sub-population of\nindividuals who lack the protective gene, smoking is a positive cause\nof lung cancer; in the sub-population consisting of individuals who\npossess the gene, smoking is a negative cause of lung cancer. \nIn any event, this debate does not really seem to be about the\nmetaphysics of causation. As we saw in the previous section, causal\nrelevance is really the basic metaphysical concept. The dispute\nbetween Dupré and Eells is really a debate about how best to use the\nword ‘cause’ to pick out a particular species of causal\nrelevance. Dupré’s proposed usage will count as (positive)\ncauses many things that will be mixed causes in Eells’s proposed\nusage. But there does not seem to be any underlying disagreement about\nwhich factors are causally relevant. (For defense of a similar\nposition, see Twardy and Korb 2004.) \nThe program described in this section did much to illuminate the\nrelationship between causation and probability. In particular, it\nhelped us to better understand the way in which causal structure can\ngive rise to probabilistic relations of screening off. However,\ndespite the mathematical framework of the program, and points of\ncontact with statistics and experimental methodology, this program did\nnot give rise to any new computational tools, or suggest any new\nmethods for detecting causal relationships. For this reason, the\nprogram has largely been supplanted by the causal modeling tools\ndescribed in the next section. \nThe main works surveyed in this section are Reichenbach 1956, Suppes\n1970, Cartwright 1979, Skyrms 1980, and Eells 1991. Williamson 2009\nand Hitchcock 2016 are two further surveys that cover a number of the\ntopics discussed in this section. The entries for\n Hans Reichenbach\n and\n Reichenbach’s Common Cause Principle\n include discussions of Reichenbach’s program and the status of\nhis Common Cause Principle. Salmon (1984) contains an extensive\ndiscussion of conjunctive forks. The entry for\n Simpson’s paradox\n contains further discussion of some of the issues raised in\n Section 2.4. \nThe discussion of the previous section conveys some of the complexity\nof the problem of inferring causal relationships from probabilistic\ncorrelations. Fairly recently, a number of techniques have been\ndeveloped for representing systems of causal relationships, and for\ninferring causal relationships from probabilities. The name\n‘causal modeling’ is often used to describe the new\ninterdisciplinary field devoted to the study of methods of causal\ninference. This field includes contributions from statistics,\nartificial intelligence, philosophy, econometrics, epidemiology, and\nother disciplines. Within this field, the research programs that have\nattracted the greatest philosophical interest are those of the\ncomputer scientist Judea Pearl and his collaborators, and of the\nphilosophers Peter Spirtes, Clark Glymour, and Richard Scheines (SGS)\nand their collaborators. The most significant works of these authors\nare Pearl (2009) (first published in 2000), and Spirtes et al. (2000)\n(first published in 1993). \nEvery causal model involves a set of variables \\(\\bV\\). The variables\nin \\(\\bV\\) may include, for example, the education-level, income, and\noccupation of an individual. A variable could be binary, its values\nrepresenting the occurrence or non-occurrence of some event, or the\ninstantiation or non-instantiation of some property. But as the\nexample of income suggests, a variable could have multiple values or\neven be continuous. \nA probabilistic causal model also includes a probability measure P. P\nis defined over propositions of the form \\(X = x\\), where X is\na variable in \\(\\bV\\) and x is a value in the range of\nX. P is also defined over conjunctions, disjunctions, and\nnegations of such propositions. It follows that conditional\nprobabilities over such propositions will be well-defined whenever the\nevent conditioned on has positive probability. P is usually understood\nto represent some kind of objective probability. \nCausal relationships among the variables in \\(\\bV\\) are represented by\ngraphs. We will consider two types of graphs. The first is\nthe directed acyclic graph (DAG). A directed graph\n\\(\\bG\\) on variable set \\(\\bV\\) is a set of ordered pairs of variables\nin \\(\\bV\\). We represent this visually by drawing an arrow from\nX to Y just in case \\(\\langle X, Y\\rangle\\) is in\n\\(\\bG\\). Figure 3 shows a directed graph on variable set \\(\\bV = \\{S,\nT, W, X, Y, Z\\}\\). \nFigure 3 \nA path in a directed graph is a non-repeating sequence of\narrows that have endpoints in common. For example, there is a path\nfrom X to Z, which we can write as \\(X \\leftarrow T\n\\rightarrow Y \\rightarrow Z\\). A directed path is a path in\nwhich all the arrows align by meeting tip-to-tail; for example, there\nis a directed path \\(S \\rightarrow T \\rightarrow Y \\rightarrow Z\\). A\ndirected graph is acyclic, and hence a DAG, if there is no\ndirected path from a variable to itself. The graph in\n Figure 3\n is a DAG. \nThe relationships in the graph are often described using the language\nof genealogy. The variable X is a parent of Y\njust in case there is an arrow directed from X to Y.\n\\(\\PA(Y)\\) will denote the set of all parents of Y. In\n Figure 3,\n \\(\\PA(Y) = \\{T, W\\}\\). X is an ancestor of Y\n(and Y is a descendant of X) just in case there\nis a directed path from X to Y. However, it will be\nconvenient to deviate slightly from the genealogical analogy and\ndefine ‘descendant’ so that every variable is also\na descendant of itself. \\(\\DE(X)\\) denotes the set of all descendants of\nX. In\n Figure 3\n \\(\\DE(T) = \\{T, X, Y, Z\\}\\). \nAn arrow from Y to Z in a DAG represents that Y\nis a direct cause of Z. Roughly, this means that the\nvalue of Y makes some causal difference for the value of\nZ, and that Y influences Z through some process\nthat is not mediated by any other variable in \\(\\bV\\). Directness is\nrelative to a variable set. We will call the system of direct causal\nrelations represented in a DAG such as\n Figure 3\n the causal structure on the variable set \\(\\bV\\). \nA second type of graph that we will consider is an acyclic\ndirected mixed graph (ADMG). An\nADMG, will contain double-headed arrows, as well as single-headed\narrows. A double-headed arrow represents a latent common\ncause. A latent common cause of variables X and Y is a\ncommon cause that is not included in the variable set \\(\\bV\\). For\nexample, suppose that X and Y share a common cause\nL (Figure 4(a)). An ADMG on the variable set \\(\\bV = \\{X, Y\\}\\)\nwill look like Figure 4(b). \nFigure 4 \nWe only need to represent missing common causes in this way when they\nare closest common causes. That is, a graph on \\(\\bV\\) should\ncontain a double-headed arrow between X and Y when there\nis a variable L that is omitted from \\(\\bV\\), such that if\nL were added to \\(\\bV\\) it would be a direct cause of\nX and Y. Double-headed arrows do not give rise to\n“genealogical” relationships: in\n Figure 4(b),\n X is not a parent, ancestor, or descendant of Y. \nIn an ADMG, we expand the definition of a path to include\ndouble-headed arrows. Thus, \\(X \\leftrightarrow Y\\) is a path in the\nADMG shown in\n Figure 4(b).\n Directed path retains the same meaning, and a directed path\ncannot contain double-headed arrows. An ADMG cannot include a directed\npath from a variable to itself. \nWe will adopt the convention that both DAGs and ADMGs represent the\npresence and absence of both direct causal relationships and\nlatent common causes. For example the DAG in\n Figure 3\n represents that T is a direct cause of Y, that T\nis not a direct cause of Z, and that there are no latent common\ncauses of any variables. \nWe will be interested in a variety of problems that have a general\nstructure. There will be a query concerning some causal\nfeature of the system being investigated. A query may concern: \nA given problem will also have a set of inputs. These fall into a\nvariety of categories: \nIn realistic scientific cases, we never directly observe the true\nprobability distribution P over a set of variables. Rather, we observe\nfinite data that approximate the true probability when sample sizes\nare large enough and observation protocols are well-designed. Since\nour primary concern is with the philosophical issue of how\nprobabilities determine or constrain causal structure, we will not\naddress these important practical concerns. An answer to a query that\ncan be determined from the true probabilities is said to be\nidentifiable. For instance, if we can determine the correct\nDAG on a variable set \\(\\bV\\) from the probability distribution on\n\\(\\bV\\), the DAG is identifiable. \nThe most important principle connecting the causal structure on\n\\(\\bV\\), as represented in a graph \\(\\bG\\), and the probability\ndistribution P on \\(\\bV\\) is the Markov Condition (MC). Let\nus first consider the case where \\(\\bG\\) is a DAG. Then P satisfies\nthe Markov Condition (MC) relative to \\(\\bG\\) if and only it\nsatisfies these three conditions: \nThese three conditions are equivalent when \\(\\bG\\) is a DAG. \nLet us take some time to explain each of these formulations. \nMCScreening_off says that the parents of variable X\nscreen X off from all other variables, except for the\ndescendants of X. Given the values of the variables that are\nparents of X, the values of the variables in \\(\\bY\\) (which\nincludes no descendants of \\(X)\\), make no further difference to the\nprobability that X will take on any given value. \nMCFactorization tells us that once we know the conditional\nprobability distribution of each variable given its parents, \\(\\PP(X_i\n\\mid \\PA(X_i))\\), we can compute the complete joint distribution\nover all of the variables. This captures Reichenbach’s idea that\nprobability relations between variables that are not related as cause\nand effect are nonetheless derived from probability relations between\ncauses and effects. \nMCd-separation uses the graphical notion of\nd-separation, introduced by Pearl (1988). Let \\(X, Y \\in \\bV,\n\\bZ \\subseteq \\bV \\setminus \\{X, Y\\}\\). As noted above, a path from\nX to Y is a sequence of variables \\(\\langle X = X_1 ,\n\\ldots ,X_k = Y\\rangle\\) such that for each \\(X_i\\), \\(X_{i+1}\\),\nthere is either an arrow from \\(X_i\\) to \\(X_{i+1}\\) or an arrow from\n\\(X_{i+1}\\) to \\(X_i\\) in \\(\\bG\\). A variable \\(X_i , 1 \\lt i \\lt k\\)\nis a collider on the path just in case there is an arrow from\n\\(X_{i-1}\\) to \\(X_i\\) and from \\(X_{i+1}\\) to \\(X_i\\). That is,\n\\(X_i\\) is a collider on a path just in case two arrows converge on\n\\(X_i\\) in the path. \\(\\bZ\\) d-separates X and Y\njust in case every path \\(\\langle X = X_1 , \\ldots ,X_k = Y\\rangle\\)\nfrom X to Y contains at least one variable \\(X_i\\) such\nthat either: (i) \\(X_i\\) is a collider, and no descendant of \\(X_i\\)\n(including \\(X_i\\) itself) is in \\(\\bZ\\); or (ii) \\(X_i\\) is not a\ncollider, and \\(X_i\\) is in \\(\\bZ\\). MCd-separation\nstates that d-separation is sufficient for conditional\nindependence. \nNote that MC provides sufficient conditions for variables to be\nprobabilistically independent, conditional on others, but no necessary\ncondition. The Markov Condition entails many of the same screening off\nrelations as Reichenbach’s Common Cause Principle, discussed in\n Section 2.3\n above. Here are some examples: \nFigure 5 \nIn Figure 5, MC implies that X screens Y off from all of\nthe other variables, and that W screens Z off from all\nof the other variables. This is most easily seen from MCScreening\noff. W also screens T off from all of the other\nvariables, which is most easily seen from\nMCd-separation. MC does not imply that T\nscreens Y off from Z (or indeed anything from anything).\nWhile Y and Z do have a common cause that screens them\noff (W), not all common causes screen them off (T does\nnot have to), and not everything that screens them off is a common\ncause (X screens them off but is not a common cause). \nFigure 6 \nIn Figure 6, MC entails that X and Y will be\nunconditionally independent, but not that they will be independent\nconditional on Z. This is most easily seen from\nMCd-separation. \nMC is not expected to hold for arbitrary sets of variables \\(\\bV\\),\neven when the graph \\(\\bG\\) accurately represents the causal relations\namong those variables. For example, MC will typically fail in the\nfollowing kinds of case: \nIf there are latent common causes, we expect MCScreening\noff and MCFactorization to fail if we apply them in a\nnaïve way. For example, suppose that the true causal structure on\n\\(\\bV = \\{X, Y, Z\\}\\) is shown by the ADMG in Figure 7. \nFigure 7 \nY is the only parent of Z shown in the graph, and if we\ntry to apply MCScreening_off, it tells us that Y\nshould screen X off from Z. However, we would expect\nX and Z to be correlated, even when we condition on\nY, due to the latent common cause. The problem is that the\ngraph is missing a relevant parent of Z, namely the omitted\ncommon cause. However, suppose that the probability distribution is\nsuch that if the latent cause L were added, the\nprobability distribution over the expanded set of variables would\nsatisfy MC with respect to the resulting DAG. Then it turns out that\nthe probability distribution will still satisfy\nMCd-separation with respect to the ADMG of\n Figure 8.\n This requires us to expand the definition of d-separation to\ninclude paths with double-headed arrows. For instance, Z is a\ncollider on the path \\(Y \\rightarrow Z \\leftrightarrow X\\) (since\nZ has two arrows pointing into it), but X is not a\ncollider on the path \\(Y \\leftarrow X \\leftrightarrow Z\\). Thus we\nwill say that a probability distribution P satisfies the Markov\nCondition relative to an ADMG just in case it satisfies\nMCd-separation. \nBoth SGS 2000 and Pearl 2009 contain statements of a principle called\nthe Causal Markov Condition (CMC), but they mean different\nthings. In Pearl’s formulation, CMC is just a statement of a\nmathematical theorem: Pearl and Verma (1991) prove if each variable in\n\\(\\bV\\) is a deterministic product of its parents in \\(\\bV\\), together\nwith an error term; and the errors are probabilistically independent\nof each other; then the probability distribution on \\(\\bV\\) will\nsatisfy MC with respect to the DAG \\(\\bG\\). Pearl interprets this\nresult in the following way: Macroscopic systems, he believes, are\ndeterministic. In practice, however, we never have access to all of\nthe causally relevant variables affecting a macroscopic system. But if\nwe include enough variables in our model so that the excluded\nvariables are probabilistically independent of one another, then our\nmodel will satisfy the MC, and we will have a powerful set of analytic\ntools for studying the system. Thus MC characterizes a point at which\nwe have constructed a useful approximation of the complete system. \nIn SGS 2000, the CMC has more the status of an empirical posit. If\n\\(\\bV\\) is set of macroscopic variables that are well-chosen, meaning\nthat they are free from the sorts of defects described in points (ii)\nand (iii) above; \\(\\bG\\) is a graph representing the causal structure\non \\(\\bV\\); and P is the objective probability distribution resulting\nfrom this causal structure; then P can be expected to satisfy MC\nrelative to \\(\\bG\\). More precisely, P will satisfy all three versions\nof MC if \\(\\bG\\) is a directed acyclic graph, and P will satisfy\nMCd-separation if \\(\\bG\\) is an ADMG with\ndouble-headed arrows. SGS defend this empirical posit in two different\nways: \nCartwright (1993, 2007: chapter 8) has argued that MC need not hold\nfor genuinely indeterministic systems. Hausman and Woodward (1999,\n2004) attempt to defend MC for indeterministic systems. \nA causal model that comprises a DAG and a probability distribution\nthat satisfies MC is called a causal Bayes net (CBN). A\ncausal model incorporating an ADMG and probability distribution\nsatisfying MCd-separation is called a\nsemi-Markov causal model (SMCM). \nThe MC states a sufficient condition but not a necessary condition for\nconditional probabilistic independence. As such, the MC by itself can\nnever entail that two variables are conditionally or unconditionally\ndependent. The Minimality and Faithfulness Conditions are two\nprinciples that posit necessary conditions for probabilistic\nindependence. The terminology comes from Spirtes et al. (2000). Pearl\nprovides analogous conditions with different terminology. \n(i) The Minimality Condition. Suppose that the acyclic\ndirected graph \\(\\bG\\) on variable set \\(\\bV\\) satisfies MC with\nrespect to the probability distribution P. The Minimality Condition\nasserts that no sub-graph of \\(\\bG\\) over \\(\\bV\\) also satisfies the\nMarkov Condition with respect to P. (A subgraph of \\(\\bG\\) is a graph\nover \\(\\bV\\) that results from removing arrows from \\(\\bG)\\). As an\nillustration, consider the variable set \\(\\{X, Y\\}\\), let there be an\narrow from X to Y, and suppose that X and\nY are probabilistically independent of each other according to\nprobability function P. This graph would satisfy the MC with respect\nto P: none of the independence relations mandated by the MC are absent\n(in fact, the MC mandates no independence relations). But this graph\nwould violate the Minimality Condition with respect to P, since the\nsubgraph that omits the arrow from X to Y would also\nsatisfy the MC. The Minimality Condition implies that if there is an\narrow from X to Y, then X makes a probabilistic\ndifference for Y, conditional on the other parents of Y.\nIn other words, if \\(\\bZ = \\PA(Y) \\setminus \\{X\\}\\), there exist\n\\(\\bz\\), y, x, \\(x'\\) such that \n(ii) The Faithfulness Condition. The Faithfulness Condition\nsays that all of the (conditional and unconditional) probabilistic\nindependencies that exist among the variables in \\(\\bV\\) are\nrequired by the MC. For example, suppose that \\(\\bV = \\{X, Y,\nZ\\}\\). Suppose also that X and Y are unconditionally\nindependent of one another, but dependent, conditional upon Z.\n(The other two variable pairs are dependent, both conditionally and\nunconditionally.) The graph shown in\n Figure 8\n does not satisfy the faithfulness condition with respect to this\ndistribution (colloquially, the graph is not faithful to the\ndistribution). MC, when applied to the graph of\n Figure 8,\n does not imply the independence of X and Y. By\ncontrast, the graph shown in\n Figure 6\n above is faithful to the described distribution. Note that\n Figure 8\n does satisfy the Minimality Condition with respect to the\ndistribution; no subgraph satisfies MC with respect to the described\ndistribution. In fact, the Faithfulness Condition is strictly stronger\nthan the Minimality Condition. \nFigure 8 \nThe Faithfulness Condition implies that the causal influences of one\nvariable on another along multiple causal routes do not\n‘cancel’. In Figure 8, X influences Y along\ntwo different directed paths. If the effect of one path is to exactly\nundo the influence along the other path, then X and Y\nwill be probabilistically independent. The Faithfulness Condition\nforbids such exact cancellation. This ‘no canceling’\ncondition seems implausible as a metaphysical or conceptual constraint\nupon the connection between causation and probabilities. For example,\nif one gene codes for the production of a particular protein, and\nsuppresses another gene that codes for the same protein, the operation\nof the first gene will be independent of the presence of the protein.\nCartwright (2007: chapter 6) and Andersen (2103) argue that violations\nof faithfulness are widespread. \nThe Faithfulness Condition is a methodological principle\nrather than a metaphysical principle. Given a distribution on \\(\\{X,\nY, Z\\}\\) in which X and Y are independent, we should\ninfer that the causal structure is that depicted in\n Figure 6,\n rather than\n Figure 8.\n This is not because\n Figure 8\n is conclusively ruled out by the distribution, but rather because it\nis preferable to postulate a causal structure that implies\nthe independence of X and Y rather than one that is\nmerely consistent with independence. \nThe original hope of Reichenbach and Suppes was to provide a reduction\nof causation to probabilities. To what extent has this hope been\nrealized within the causal modeling framework? Causal modeling does\nnot offer a reduction in the traditional philosophical sense; that is,\nit does not offer an analysis of the form ‘X causes\nY if and only if…’ where the right hand side of\nthe bi-conditional makes no reference to causation. Instead, it offers\na series of postulates about how causal structure constrains the\nvalues of probabilities. Still, if we have a set of variables \\(\\bV\\)\nand a probability distribution P on \\(\\bV\\), we may ask if P suffices\nto pick out a unique causal graph \\(\\bG\\) on \\(\\bV\\). \nPearl (1988: Chapter 3) proves the following theorem: \nIf \nthen it will be possible to uniquely identify \\(\\bG\\) on the basis of\nP. \nIn many ways, this result successfully executes the sort of project\ndescribed in Section 2\nabove. That is, making the same sorts of assumptions about\ntime-indexing, and substantive assumptions about the connection\nbetween probability and causation, it establishes that it is possible\nto identify causal structure using probabilities. \nIf we don’t have information about time ordering, or other\nsubstantive assumptions restricting the possible causal structures\namong the variables in \\(\\bV\\), then it will not always be possible to\nidentify the causal structure from probability alone. In general,\ngiven a probability distribution P on \\(\\bV\\), it is only possible to\nidentify a Markov equivalence class of causal structures.\nThis will be the set of all DAGs on \\(\\bV\\) that (together with MC)\nimply all and only the conditional independence relations contained in\nP. The PC algorithm (SGS 2000: 84–85), named for its\ntwo creators (Peter Spirtes and Clark Glymour), is one\nalgorithm that generates the Markov equivalence class for any given\nprobability distribution.\n \nConsider two simple examples involving three variables \\(\\{X, Y,\nZ\\}\\). Suppose our probability distribution has the following\nproperties: \nThen the Markov equivalence class is: \nWe cannot determine from the probability distribution, together with\nMC and Faithfulness, which of these structures is correct. \nOn the other hand, suppose the probability distribution is as\nfollows: \nThen the Markov equivalence class is: \nNote that the first probability distribution on \\(\\{X, Y, Z\\}\\) is\nthat characterized by Reichenbach’s Common Cause Principle. The\nsecond distribution reverses the relations between X and\nZ: they are unconditionally independent and\nconditionally dependent. Contrary to Reichenbach, it is\nactually the latter pattern of dependence relations that is most\nuseful for orienting the causal arrows in the graph. In the last\ncausal structure shown, Y is a collider on the path from\nX to Z. MCd-separation implies that\ncolliders give rise to distinctive conditional independence relations,\nwhile all three types of non-collider give rise to the same\nconditional independence relations. Many of the algorithms that have\nbeen developed for inferring causal structure from probabilities work\nby searching for colliders (see, e.g., SGS 2000: Chapter 5). \nThe identifiability results discussed so far all assume that the\ncorrect causal graph is a DAG. However, it is common that latent\nvariables will be present, and even more common that we might wish to\nallow for the possibility of latent variables (whether they are\nactually there or not). If we allow that the correct causal graph may\ncontain double-headed arrows, we can still apply\nMCd-separation, and ask which graphs imply the same\nsets of conditional independence relations. The\nMarkov equivalence class will be larger than it was when we did not\nallow for latent variables. For instance, given the last set of\nprobability relations described above, the graph \nis no longer the only one compatible with this distribution. The\nstructure \nis also possible, as are several others. \nA conditional probability such as \\(\\PP(Y = y \\mid X = x)\\) gives\nus the probability that Y will take the value y, given\nthat X has been observed to take the value x.\nOften, however, we are interested in predicting the value of Y\nthat will result if we intervene to set the value of X\nequal to some particular value x. Pearl writes \\(\\PP(Y = y\n\\mid \\do(X = x))\\) to characterize this probability. What is the\ndifference between observation and intervention? When we merely\nobserve the value that a variable takes, we are learning about the\nvalue of the variable when it is caused in the normal way, as\nrepresented in our causal model. Information about the value of the\nvariable will also provide us with information about its causes, and\nabout other effects of those causes. However, when we intervene, we\noverride the normal causal structure, forcing a variable to take a\nvalue it might not have taken if the system were left alone. The value\nof the variable is determined completely by our intervention, the\ncausal influence of the other variables being completely overridden.\nGraphically, we can represent the effect of this intervention by\neliminating the arrows directed into the variables intervened upon.\nSuch an intervention is sometimes described as ‘breaking’\nthose arrows.  \nA causal model can be used to predict the effects of such an\nintervention. Suppose we have a causal model in which the probability\ndistribution P satisfies MC on the causal DAG \\(\\bG\\) over the\nvariable set \\(\\bV = \\{X_1, X_2 ,\\ldots ,X_n\\}\\). The most useful\nversion of MC for thinking about interventions is\nMCFactorization (see\n Section 3.3),\n which tells us: \nNow suppose that we intervene by setting the value of \\(X_k\\) to\n\\(x_k\\). The post-intervention probability \\(\\PP'\\) is the result of\naltering the factorization as follows: \nwhere \\(\\PP'(X_k = x_k) = 1\\). The conditional probabilities of the\nform \\(\\PP(X_i \\mid \\PA(X_i))\\) for \\(i \\ne k\\) remain unchanged\nby the intervention. \nThis treatment of interventions has been expanded in a number of\ndirections. The ‘manipulation theorem’ (theorem 3.6 of SGS\n2000) generalizes the formula to cover a much broader class of\ninterventions, including ones that don’t break all the arrows\ninto the variables that are intervened on. Pearl (2009: Chapter 3)\ndevelops an axiomatic system he calls the ‘do-calculus’\nfor computing post-intervention probabilities that can be applied to\nsystems with latent variables.  \nCausal modeling is a burgeoning area of research. This entry has largely\nignored work on computational methods, as well as applications of the\ntools discussed here. Rather, the focus has been on the conceptual\nunderpinnings of recent programs in causal modeling, with special\nattention to the connection between causation and probability. It has\nalso focused on what it possible to learn about causation “in\nprinciple” on the basis of probabilities, while ignoring the\npractical problems of making causal inferences on the basis of finite\ndata samples (which inevitably deviate from the true\nprobabilities). \nThe entry on Causal Models covers all of the material in this section\nin greater detail. The most important works surveyed in this section\nare Pearl 2009 and Spirtes, Glymour, & Scheines 2000. Pearl 2010\nis a short overview of Pearl’s program, and Pearl et al. 2016 is\na longer overview. The latter, in particular, assumes relatively\nlittle technical background. Scheines 1997 and the Introduction of\nGlymour & Cooper 1999 are accessible introductions to the SGS\nprogram. Neapolitan 2004 is a text book that treats Bayes nets in\ncausal and noncausal contexts. Neapolitan & Jiang 2016 is a short\noverview of this topic. Hausman 1999, Glymour 2009, Hitchcock 2009,\nand Eberhardt 2017 are short overviews that cover some of the topics\nraised in this section. The entry on\n causation and manipulability\n contains extensive discussion of interventions, and some discussion\nof causal models.  \nMany philosophers and legal theorists have been interested in the\nrelation of actual causation. This concerns the assignment of\ncausal responsibility for an event, based on how events actually play\nout. For example, suppose that Billy and Suzy each throw a rock at a\nbottle, and that each has a certain probability of hitting and\nbreaking it. As it happens, Suzy’s rock hits the bottle, and\nBilly’s doesn’t. As things actually happened, we would say\nthat Suzy’s throw caused the bottle to shatter, while\nBilly’s didn’t. Nonetheless, Billy’s throw increased\nthe probability that the bottle would shatter, and it would be\nidentified as a cause by the theories described in sections\n 2\n and\n 3.\n Billy’s throw had a tendency to shatter the bottle; it was a\npotential cause of the bottle shattering; it was the sort of thing\nthat generally causes shattering; but it did not actually cause the\nbottle to shatter.  \nA number of authors have attempted to provide probabilistic analyses\nof actual causation. Some, such as Eells (1991: chapter 6), Kvart\n(1997, 2004), and Glynn\n(2011), pay careful attention to the way in which probabilities change\nover time. Some, such as Dowe (2004) and Schaffer (2001), combine\nprobabilities with the resources of a process theory of causation.\nSome, such as Lewis (1986b), Menzies (1989), and Noordhof (1999),\nemploy probabilities together with counterfactuals to analyze actual\ncausation. And others such as Beckers & Vennekens (2016),\nFenton-Glynn (2017), Halpern (2016: Section 2.5), Hitchcock (2004a),\nand Twardy & Korb (2011) employ causal modeling tools similar to\nthose described in\n Section 3.\n We will describe two of those theories—Lewis (1986b) and\nFenton-Glynn (2017)—in more detail in sections\n 4.3\n and\n 4.4\n below.  \nIn\n Section 2.5\n above, we saw that Eells (1991) defines a variety of different ways\nin which C can be causally relevant for E. C can\nbe a positive, negative, or mixed cause of E depending upon\nwhether C raises, lowers, or leaves unchanged the probability\nof E in various background conditions \\(B_i\\). A natural\nsuggestion is that (i) an actual cause of E is a type of\npositive cause of E; but (ii) for assessing actual causation,\nonly the background condition that actually obtains is\nrelevant. Putting these ideas together, we get: \nAs we shall see in the next section, this type of analysis is\nvulnerable to two types of counterexamples: cases where causes seem to\nlower (or leave unchanged) the probabilities of their effects; and\ncases where non-causes seem to raise the probabilities of events that\nare not their effects. Most of the theories mentioned in the previous\nsection can be seen as attempts to improve upon AC1 to deal with these\ntypes of counterexample. \nActual causes can sometimes lower the probability of their effects in\ncases of preemption: Suppose that Billy and Suzy are aiming\nrocks at a bottle. Billy decides that he will give Suzy the\nopportunity to throw first; he will throw his rock just in case Suzy\ndoesn’t throw hers. For mathematical convenience, we will assume\nthat there is some small probability—0.1 say—that Billy\ndoes not faithfully execute his plan. Billy is a more accurate thrower\nthan Suzy. If Billy throws his rock, there is a 90% chance that it\nwill shatter the bottle; if Suzy throws, she has a 50% chance of\nsuccess. Suzy throws her rock and Billy doesn’t; Suzy’s\nrock hits the bottle and smashes it. By throwing, Suzy lowered the\nprobability of shattering from 81% (the probability that Billy would\nboth throw and hit if Suzy hadn’t thrown) to 54.5%\n(accommodating the small probability that Billy will throw even if\nSuzy throws). Suzy’s throw preempts Billy’s\nthrow: she prevents Billy from throwing, and substitutes her own, less\nreliable throw. Nonetheless, Suzy’s throw actually caused the\nbottle to shatter. \nChanging the example slightly gives us a case of a probability-raising\nnon-cause. Suppose that Billy and Suzy throw their rocks\nsimultaneously. As it happens, Suzy’s throw hits the bottle and\nBilly’s misses. Nonetheless, Billy’s throw increased the\nprobability that the bottle would shatter from 50% (the probability\nthat Suzy would hit) to 95% (the probability that at least one of them\nwould hit). But Billy’s throw did not in fact cause the bottle\nto shatter. In the terminology of Schaffer (2001), Billy’s throw\nis a fizzler. It had the potential to shatter the bottle, but\nit fizzled out, and something else actually caused the bottle to\nbreak. \nDavid Lewis is the best-known advocate of a counterfactual theory of\ncausation. In Lewis 1973, he offered a counterfactual theory of\ncausation under the assumption of determinism. Lewis 1986b presented a\nprobabilistic extension to this counterfactual theory of\ncausation. \nLewis defines a relation of causal dependence that is\nsufficient, but not necessary for causation. \nThe counterfactual in (iii) is to be understood in terms of possible\nworlds: it says that in the nearest possible world(s) where C\ndoes not occur, the probability of E is less than or equal to\ny. (There needn’t be a single value that the probability\nwould have been. It can take on different values in the closest\npossible worlds, as long as all of those values are less than or equal\nto y.) On this account, the relevant notion of\n‘probability-raising’ is not understood in terms of\nconditional probabilities, but in terms of unconditional probabilities\nin different possible worlds. \nLewis defines causation (what we are calling “actual\ncausation”) to be the ancestral of causal dependence;\nthat is: \nThis definition guarantees that causation will be transitive: if\nC causes D, and D causes E, then C\ncauses E. This modification is useful for addressing certain\ntypes of preemption. Consider the example from the previous section,\nwhere Suzy throws her rock, preempting Billy. We can interpolate an\nevent D between Suzy’s throw, C, and the\nbottle’s shattering E. Let D be the presence of\nSuzy’s rock on its actual trajectory, at some time after Billy\nhas already failed to throw. If Suzy hadn’t thrown, D\nwould have been much less likely. And if D hadn’t\noccurred, E would have been much less probable. Since D\noccurs after Billy has already declined to throw, if D\nhadn’t occurred, there would not have been any rock on\na trajectory toward the bottle. Thus there is a chain of causal\ndependence from C to D to E.  \nDespite this success, it has been widely acknowledged (even by Lewis\nhimself) that Lewis’s probabilistic theory has problems with\nother types of preemption, and with probability-raising\nnon-causes. \nFenton-Glynn (2017) offers an analysis of actual causation that is\nbased on the definition of Halpern and Pearl (2005), who consider only\nthe deterministic case. What follows here is a simplified version of\nFenton-Glynn’s proposal, as one example of an analysis employing\ncausal models. \nLet \\(\\bV\\) be a set of time-indexed, binary variables, which we\nassume to include any common causes of variables in \\(\\bV\\) (so that\nthe correct causal graph on \\(\\bV\\) is a DAG). Let \\(*\\) be an assignment\nfunction that assigns to each variable \\(X\\) in \\(\\bV\\) one of its\npossible values. Intuitively, \\(*\\) identifies the actual value\nof each variable. We will denote \\(*(X)\\) by \\(x^*\\), and \\(x'\\)\nwill denote the non-actual value of \\(X\\). If \\(\\bX\\) is a set of\nvariables in \\(\\bV\\), \\(\\bX\\) = \\(\\bx^*\\) will be a proposition stating that\neach variable in \\(\\bX\\) takes the actual value assigned by \\(*\\). Let P\nbe a probability function on \\(\\bV\\) representing objective\nprobability, which we assume to satisfy the Markov and Minimality\nConditions (Sections\n 3.3\n and\n 3.4\n above). We also assume that P assigns positive probability to every\npossible assignment of values to variables in \\(\\bV\\). \nGiven the identifiability result described in\n Section 3.5\n above, we can recover the correct causal graph \\(\\bG\\) from the probability\nfunction P together with the time-indices of the variables. We can now\nuse P and \\(\\bG\\) to compute the effects of interventions, as described in\n section 3.6\n above. We now define actual causation as follows: \nIntuitively, this is what is going on: If \\(X = x^*\\) is an actual\ncause of \\(Y = y^*\\) then there has to be at least one directed path\nfrom \\(X\\) to \\(Y\\). \\(\\bZ\\) will consist of variables that lie\nalong some (but not necessarily all) of these paths. (If \\(X\\) is a\ndirect cause of \\(Y\\), then \\(\\bZ\\) can be empty.). F-G requires\nthat \\(X = x^*\\) raises the probability of \\(Y = y^*\\) in the sense that\ninterventions that set \\(X\\) to \\(x^*\\) result in higher\nprobabilities for \\(Y = y^*\\) than interventions that set \\(X\\) to\n\\(x'\\). Specifically, \\(X = x^*\\) must raise the probability of \\(Y =\ny^*\\) when we also intervene to set the variables in \\(\\bW\\) to their\nactual values. \\(\\bW = \\bw^*\\) is like a background context of the sort\ndiscussed in\n Section 2.4,\n except that \\(\\bW\\) may include some variables that are descendants\nof \\(X\\). Moreover, \\(X = x^*\\) must raise the probability of \\(Y =\ny^*\\) in conjunction with any combination of variables in \\(\\bZ\\) being\nset to their actual values. The idea is that the probabilistic impact\nof \\(X\\) on \\(Y\\) is being constrained to flow through the\nvariables in \\(\\bZ\\), and at every stage in the process, the value of\nthe variables in \\(\\{X\\} \\cup \\bZ\\) must confer a higher probability\non \\(Y = y^*\\) than the baseline probability that would have resulted\nif \\(X\\) had been set to \\(x'\\). \nLet’s see how this account handles the problem cases from\n section 4.2.\n For the example of preemption, we will use the following\nvariables: \nThe subscripts indicate the relative times of the events, with larger\nnumbers corresponding to later times. The actual values of the\nvariables are \\(\\ST_0= 1\\), \\(\\BT_1= 0\\), and \\(\\BS_2= 1\\). The\nprobabilities are: \n(Note that we have added a small probability for the bottle to shatter\ndue to some other cause, even if neither Suzy nor Billy throw their\nrock. This ensures that the probabilities of all assignments of values\nto the variables are positive.) The corresponding graph is shown in\nFigure 9. \nFigure 9 \nApplying F-G, we can take \\(\\bW = \\{\\BT_1\\}\\), \\(\\bZ = \\varnothing\\).\nWe have: \nHolding fixed that Billy doesn’t throw, Suzy’s throw\nraises the probability that the bottle will shatter. Thus the\nconditions are met for \\(\\ST = 1\\) to be an actual cause of \\(\\BS =\n1\\). \nTo treat the case of fizzling from\n Section 4.2,\n let \nThe actual values are \\(\\ST_0= 1\\), \\(\\BT_0= 1\\), \\(\\SH_1= 1\\),\n\\(\\BH_1= 0\\), and \\(\\BS_2= 1\\). The probabilities are: \nAs before, we have assigned probabilities close to, but not equal to,\nzero and one for some of the possibilities. The graph is shown in\nFigure 10. \nFigure 10 \nWe want to show that \\(\\BT_0= 1\\) is not an actual cause of \\(\\BS_2=\n1\\) according to F-G. We will show this by means of a dilemma: is\n\\(\\BH_1\\in \\bW\\) or is \\(\\BH_1\\in \\bZ\\)? \nSuppose first that \\(\\BH_1\\in \\bW\\). Then, regardless of whether\n\\(\\ST_0\\) and \\(\\SH_1\\) are in \\(\\bW\\) or \\(\\bZ\\), we will need to\nhave  \nBut in fact both of these probabilities are equal to .95. If we\nintervene to set \\(\\BH_1\\) to 0, intervening on \\(\\BT_0\\) makes no\ndifference to the probability of \\(\\BS_2= 1\\). \nSo let us suppose instead that \\(\\BH_1\\in \\bZ\\). Then we will need to\nhave  \nThis inequality is slightly different, since \\(\\BH_1= 0\\) does\nnot appear in the second conditional probability. Nonetheless we have\n \nand \n(The second probability is a tiny bit larger, due to the very small\nprobability that Billy’s rock will hit even if he doesn’t\nthrow it.) \nSo regardless of whether \\(\\BH_1\\in \\bW\\) or is \\(\\BH_1\\in \\bZ\\),\ncondition F-G is not satisfied, and \\(\\BT_0= 1\\) is not judged to be\nan actual cause of \\(\\BS_2= 1\\). The key idea is that it is not enough\nfor Billy’s throw to raise the probability of the bottle\nshattering; Billy’s throw together with what happens afterwards\nhas to raise the probability of shattering. As things actually\nhappened, Billy’s rock missed the bottle. Billy’s throw\ntogether with his rock missing does not raise the probability\nof shattering. \nNote that this treatment of fizzling requires that we include\nvariables for whether the rocks hit the bottle. If we try to model\nthis case using just three variables, \\(\\BT\\), \\(\\ST\\), and \\(\\BS\\),\nwe will incorrectly judge that Billy’s throw is a cause of the\nbottle shattering. This raises the question of what is the\n“right” model to use, and whether we can know if we have\nincluded “enough” variables in our model. Fenton-Glynn\n(2017) includes some discussion of these tricky issues. \nWhile this section describes some success stories, it is safe to say\nthat no analysis of actual causation is widely believed to perfectly\ncapture all of our pre-theoretic intuitions about hypothetical cases.\nIndeed, it is not clear that these intuitions form a coherent set, or\nthat they are perfectly tracking objective features of the world.\nGlymour et al. (2010) raise a number of challenges to the general\nproject of trying to provide an analysis of actual causation. \nThe anthologies Collins et al. 2004 and Dowe & Noordhof 2004\ncontain a number of essays on topics related to the discussion of this\nsection. Hitchcock 2004b has an extended discussion of the problem\nposed by fizzlers. Hitchcock 2015 is an overview of Lewis’s work\non causation. The entry for\n counterfactual theories of causation\n discusses Lewis’s work, and counterfactual theories of\ncausation more generally. ","contact.mail":"cricky@caltech.edu","contact.domain":"caltech.edu"}]
