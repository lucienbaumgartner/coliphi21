[{"date.published":"2000-11-29","date.changed":"2020-09-10","url":"https://plato.stanford.edu/entries/qm/","author1":"Jenann Ismael","author1.info":"https://www.jenanni.com/","entry":"qm","body.text":"\n\n\n\nQuantum mechanics is, at least at first glance and at least in part, a\nmathematical machine for predicting the behaviors of microscopic\nparticles — or, at least, of the measuring instruments we use to\nexplore those behaviors — and in that capacity, it is spectacularly\nsuccessful: in terms of power and precision, head and shoulders above\nany theory we have ever had. Mathematically, the theory is well\nunderstood; we know what its parts are, how they are put together, and\nwhy, in the mechanical sense (i.e., in a sense that can be answered by\ndescribing the internal grinding of gear against gear), the whole thing\nperforms the way it does, how the information that gets fed in at one\nend is converted into what comes out the other. The question of what\nkind of a world it describes, however, is controversial; there is very\nlittle agreement, among physicists and among philosophers, about what\nthe world is like according to quantum mechanics. Minimally\ninterpreted, the theory describes a set of facts about the way the\nmicroscopic world impinges on the macroscopic one, how it affects our\nmeasuring instruments, described in everyday language or the language\nof classical mechanics. Disagreement centers on the question of what a\nmicroscopic world, which affects our apparatuses in the prescribed\nmanner, is, or even could be, like intrinsically; or how those\napparatuses could themselves be built out of microscopic parts of the\nsort the theory\n describes.[1]\n\n\n\n\nThat is what an interpretation of the theory would provide: a proper\naccount of what the world is like according to quantum mechanics,\nintrinsically and from the bottom up. The problems with giving an\ninterpretation (not just a comforting, homey sort of interpretation,\ni.e., not just an interpretation according to which the world isn’t too\ndifferent from the familiar world of common sense, but any\ninterpretation at all) are dealt with in other sections of this\nencyclopedia. Here, we are concerned only with the mathematical heart\nof the theory, the theory in its capacity as a mathematical machine,\nand — whatever is true of the rest of it — this part of the\ntheory makes exquisitely good sense.\n\n\n\nPhysical systems are divided into types according to\ntheir unchanging (or ‘state-independent’) properties, and\nthe state of a system at a time consists of a complete\nspecification of those of its properties that change with time (its\n‘state-dependent’ properties). To give a complete\ndescription of a system, then, we need to say what type of system it is\nand what its state is at each moment in its history.  \n\nA physical quantity is a mutually exclusive and\njointly exhaustive family of physical properties (for those who know\nthis way of talking, it is a family of properties with the structure of\nthe cells in a partition). Knowing what kinds of values a quantity\ntakes can tell us a great deal about the relations among the properties\nof which it is composed. The values of a bivalent quantity, for\ninstance, form a set with two members; the values of a real-valued\nquantity form a set with the structure of the real numbers. This is a\nspecial case of something we will see again and again, viz.,\nthat knowing what kind of mathematical objects represent the elements\nin some set (here, the values of a physical quantity; later, the states\nthat a system can assume, or the quantities pertaining to it) tells us\na very great deal (indeed, arguably, all there is to know) about the\nrelations among them. \n\nIn quantum mechanical contexts, the term\n‘observable’ is used interchangeably with\n‘physical quantity’, and should be treated as a technical\nterm with the same meaning. It is no accident that the early developers\nof the theory chose the term, but the choice was made for reasons that\nare not, nowadays, generally accepted. The state-space\nof a system is the space formed by the set of its possible\n states,[2]\n i.e., the physically possible ways of\ncombining the values of quantities that characterize it internally. In\nclassical theories, a set of quantities which forms a supervenience\nbasis for the rest is typically designated as ‘basic’ or\n‘fundamental’, and, since any mathematically possible way\nof combining their values is a physical possibility, the state-space\ncan be obtained by simply taking these as\n coordinates.[3]\n So, for instance, the state-space of a classical mechanical system\ncomposed of \\(n\\) particles, obtained by specifying the values of\n\\(6n\\) real-valued quantities — three components of position, and\nthree of momentum for each particle in the system — is a\n\\(6n\\)-dimensional coordinate space. Each possible state of such\na system corresponds to a point in the space, and each point in the\nspace corresponds to a possible state of such a system. The situation\nis a little different in quantum mechanics, where there are\nmathematically describable ways of combining the values of the\nquantities that don’t represent physically possible states. As we will\nsee, the state-spaces of quantum mechanics are special kinds of vector\nspaces, known as Hilbert spaces, and they have more internal structure\nthan their classical counterparts. \n\nA structure is a set of elements on which certain\noperations and relations are defined, a mathematical\nstructure is just a structure in which the elements are\nmathematical objects (numbers, sets, vectors) and the operations\nmathematical ones, and a model is a mathematical\nstructure used to represent some physically significant structure in\nthe world. \n\nThe heart and soul of quantum mechanics is contained in the Hilbert\nspaces that represent the state-spaces of quantum mechanical systems.\nThe internal relations among states and quantities, and everything this\nentails about the ways quantum mechanical systems behave, are all woven\ninto the structure of these spaces, embodied in the relations among the\nmathematical objects which represent\n them.[4]\n This means that\nunderstanding what a system is like according to quantum mechanics is\ninseparable from familiarity with the internal structure of those\nspaces. Know your way around Hilbert space, and become familiar with\nthe dynamical laws that describe the paths that vectors travel through\nit, and you know everything there is to know, in the terms provided by\nthe theory, about the systems that it describes. \n\nBy ‘know your way around’ Hilbert space, I mean\nsomething more than possess a description or a map of it; anybody who\nhas a quantum mechanics textbook on their shelf has that. I mean know\nyour way around it in the way you know your way around the city in\nwhich you live. This is a practical kind of knowledge that comes in\ndegrees and it is best acquired by learning to solve problems of the\nform: How do I get from A to B? Can I get there without passing through\nC? And what is the shortest route? Graduate students in physics spend\nlong years gaining familiarity with the nooks and crannies of Hilbert\nspace, locating familiar landmarks, treading its beaten paths, learning\nwhere secret passages and dead ends lie, and developing a sense of the\noverall lay of the land. They learn how to navigate Hilbert space in\nthe way a cab driver learns to navigate his city. \n\nHow much of this kind of knowledge is needed to approach the\nphilosophical problems associated with the theory? In the beginning,\nnot very much: just the most general facts about the geometry of the\nlandscape (which is, in any case, unlike that of most cities,\nbeautifully organized), and the paths that (the vectors representing\nthe states of) systems travel through them. That is what will be\nintroduced here: first a bit of easy math, and then, in a nutshell, the\ntheory. \n\nA vector \\(A\\), written ‘\\(\\ket{A}\\)’, is a\nmathematical object characterized by a length, \\(|A|\\), and a direction. A\nnormalized vector is a vector of length 1; i.e., \\(|A| = 1\\). Vectors can\nbe added together, multiplied by constants (including complex\nnumbers), and multiplied together. Vector addition maps any pair of\nvectors onto another vector, specifically, the one you get by moving\nthe second vector so that its tail coincides with the tip of the\nfirst, without altering the length or direction of either, and then\njoining the tail of the first to the tip of the second. This addition\nrule is known as the parallelogram law. So, for example, adding\nvectors \\(\\ket{A}\\) and \\(\\ket{B}\\) yields vector \\(\\ket{C} (= \\ket{A} + \\ket{B})\\) as\nin Figure 1:  Figure 1.\nVector Addition \n\nMultiplying a vector \\(\\ket{A}\\) by \\(n\\), where \\(n\\) is a\nconstant, gives a vector which is the same direction as \\(\\ket{A}\\) but\nwhose length is \\(n\\) times \\(\\ket{A}\\)’s length.  \n\nIn a real vector space, the\n (inner or dot) product\n of a pair of vectors \\(\\ket{A}\\) and \\(\\ket{B}\\), written\n‘\\(\\braket{A}{B}\\)’ is a scalar equal to the product of their\nlengths (or ‘norms’) times the cosine of the angle,\n\\(\\theta\\), between them: \n\nLet \\(\\ket{A_1}\\) and \\(\\ket{A_2}\\) be vectors of length 1\n(“unit vectors”) such that \\(\\braket{A_1}{A_2} = 0\\). (So\nthe angle between these two unit vectors must be 90 degrees.) Then we\ncan represent any two-dimensional vector \\(\\ket{B}\\) in terms of our unit vectors\nas follows:  \n\nFor example, here is a graph which shows how \\(\\ket{B}\\) can be represented\nas the sum of the two unit vectors \\(\\ket{A_1}\\) and \\(\\ket{A_2}\\):  Figure 2.\nRepresenting \\(\\ket{B}\\) by Vector Addition of Unit Vectors \n\nNow the definition of the inner product \\(\\braket{A}{B}\\) has to be\nmodified to apply to complex spaces. Let \\(c^*\\) be the complex\nconjugate of \\(c\\). (When \\(c\\) is a complex number of the\nform \\(a \\pm bi\\), then the complex conjugate\n\\(c^*\\) of \\(c\\) is defined as follows: \n\nSo, for all complex numbers \\(c\\), \\([c^*]^* = c\\),\nbut \\(c^* = c\\) just in case \\(c\\) is real.) Now\ndefinition of the inner product of \\(\\ket{A}\\) and \\(\\ket{B}\\) for complex spaces\ncan be given in terms of the conjugates of complex coefficients as\nfollows. Where \\(\\ket{A_1}\\) and \\(\\ket{A_2}\\) are the unit\nvectors described earlier, \\(\\ket{A} = a_1 \\ket{A_1} + a_2 \\ket{A_2}\\) and \\(\\ket{B} = b_1 \\ket{A_1} + b_2 \\ket{A_2}\\), then  \n\nThe most general and abstract notion of an inner product, of which\nwe’ve now defined two special cases, is as follows. \\(\\braket{A}{B}\\) is an\ninner product on a vector space \\(V\\) just in case \n\nIt follows from this that  \n\nand  \n\nA vector space is a set of vectors closed under\naddition, and multiplication by constants, an inner product\nspace is a vector space on which the operation of vector\nmultiplication has been defined, and the dimension of\nsuch a space is the maximum number of nonzero, mutually orthogonal\nvectors it contains.  \n\nAny collection of \\(N\\) mutually orthogonal vectors of length 1 in an\n\\(N\\)-dimensional vector space constitutes an orthonormal\nbasis for that space. Let \\(\\ket{A_1}, \\ldots, \\ket{A_N}\\) be such a collection of unit vectors. Then every\nvector in the space can be expressed as a sum of the form: \n\nwhere \\(b_i = \\braket{B}{A_i}\\). The \\(b_i\\)’s here are\nknown as \\(B\\)’s expansion coefficients in the \\(A\\)-basis.[5] \n\nNotice that: \n and \n\nThere is another way of writing vectors, namely by writing their\nexpansion coefficients (relative to a given basis) in a column, like\nso:  \n\nwhere \\(q_i = \\braket{Q}{A_i}\\) and the \\(A_i\\) are the\nchosen basis vectors.  \n\nWhen we are dealing with vector spaces of infinite dimension, since\nwe can’t write the whole column of expansion coefficients needed to\npick out a vector since it would have to be infinitely long, so instead\nwe write down the function (called the ‘wave function’ for\n\\(Q\\), usually represented \\(\\psi(i))\\) which has those coefficients as values. We write down, that is, the\nfunction: \n\nGiven any vector in, and any basis for, a vector space, we can obtain\nthe wave-function of the vector in that basis; and given a\nwave-function for a vector, in a particular basis, we can construct the\nvector whose wave-function it is. Since it turns out that most of the\nimportant operations on vectors correspond to simple algebraic\noperations on their wave-functions, this is the usual way to represent\nstate-vectors.  \n\nWhen a pair of physical systems interact, they form a composite\nsystem, and, in quantum mechanics as in classical mechanics, there is a\nrule for constructing the state-space of a composite system from those\nof its components, a rule that tells us how to obtain, from the\nstate-spaces, \\(H_A\\) and \\(H_B\\) for \\(A\\) and \\(B\\),\nrespectively, the state-space — called the ‘tensor\nproduct’ of \\(H_A\\) and \\(H_B\\), and written\n\\(H_A \\otimes H_B\\) — of the pair. There are two important\nthings about the rule; first, so long as \\(H_A\\) and\n\\(H_B\\) are Hilbert spaces, \\(H_A \\otimes H_B\\) will\nbe as well, and second, there are some facts about the way\n\\(H_A \\otimes H_B\\) relates to \\(H_A\\) and\n\\(H_B\\), that have surprising consequences for the relations\nbetween the complex system and its parts. In particular, it turns out\nthat the state of a composite system is not uniquely defined by those\nof its components. What this means, or at least what it appears to\nmean, is that there are, according to quantum mechanics, facts about\ncomposite systems (and not just facts about their spatial\nconfiguration) that don’t supervene on facts about their components; it\nmeans that there are facts about systems as wholes that don’t supervene\non facts about their parts and the way those parts are arranged in\nspace. The significance of this feature of the theory cannot be\noverplayed; it is, in one way or another, implicated in most of its\nmost difficult problems. \n\nIn a little more detail: if \\(\\{v_{i}^A\\}\\) is an orthonormal basis\nfor \\(H_A\\) and \\(\\{u_{j}^B\\}\\) is an orthonormal basis for \\(H_B\\), then the\nset of pairs \\((v_{i}^A, u_{j}^B)\\) is taken to form an\northonormal basis for the tensor product space \\(H_A \\otimes H_B\\). The\nnotation \\(v_i^A \\otimes u_j^B\\) is used\nfor the pair \\((v_{i}^A,u_{j}^B)\\), and inner product on \\(H_A \\otimes H_B\\)\nis defined as:[6] \n\nIt is a result of this construction that although every vector in\n\\(H_A \\otimes H_B\\) is a linear sum of vectors expressible in the form\n\\(v^A \\otimes u^B\\), not every vector in the space is itself\nexpressible in that form, and it turns out that  \n\nAn operator \\(O\\) is a mapping of a vector space onto\nitself; it takes any vector \\(\\ket{B}\\) in a space onto another\nvector \\(\\ket{B'}\\) also in\nthe space; \\(O \\ket{B} = \\ket{B'}\\). Linear operators are operators\nthat have the following properties:  \n\nJust as any vector in an \\(N\\)-dimensional space can be represented by a\ncolumn of \\(N\\) numbers, relative to a choice of basis for the space, any\nlinear operator on the space can be represented in a column notation by\n\\(N^2\\) numbers:  \n\nwhere \\(O_{ij} = \\braket{A_i}{O \\mid A_j}\\) and the \\(A_N\\) are the basis\nvectors of the space. The effect of the linear operator \\(O\\) on the vector\n\\(B\\) is, then, given by  \n\nTwo more definitions before we can say what Hilbert spaces are, and\nthen we can turn to quantum mechanics. \\(\\ket{B}\\) is an\n eigenvector of \\(O\\) with\neigenvalue \\(a\\) if, and only if, \\(O \\ket{B} = a \\ket{B}\\).\nDifferent operators can have different eigenvectors, but the\neigenvector/operator relation depends only on the operator and vectors\nin question, and not on the particular basis in which they are\nexpressed; the eigenvector/operator relation is, that is to say,\ninvariant under change of basis. A Hermitean operator\nis an operator which has the property that there is an orthonormal\nbasis consisting of its eigenvectors and those eigenvalues are all\nreal.  \n\nA Hilbert space, finally, is a vector space on\nwhich an inner product is defined, and which is complete, i.e., which\nis such that any Cauchy sequence of vectors in the space converges to a\nvector in the space. All finite-dimensional inner product spaces are\ncomplete, and I will restrict myself to these. The infinite case\ninvolves some complications that are not fruitfully entered into at\nthis stage. \n\nFour basic principles of quantum mechanics are:  Physical States.\nEvery physical system is associated with a Hilbert Space, every unit\nvector in the space corresponds to a possible pure state of the system,\nand every possible pure state, to some vector in the\n space.[7] Physical Quantities.\nHermitian operators in the Hilbert space associated with a system\nrepresent physical quantities, and their eigenvalues represent the\npossible results of measurements of those quantities.  There is an operator, called the Hamiltonian, that plays a special\nrole in quantum theory because the dynamics of a system can be\nconveniently formulated by tracking its evolution. The Hamiltonian\n– written \\(H\\), or \\(\\hat{H}\\) – stands for the total\nenergy of the system. Its eigenvalues are the possible results that\nmight be obtained in measurements of total energy. It is given by\nsumming over the kinetic and potential energies of the system’s\ncomponents. Composition.\nThe Hilbert space associated with a complex system is the tensor\nproduct of those associated with the simple systems (in the standard,\nnon-relativistic, theory: the individual particles) of which it is\ncomposed.  Contexts of type 1: Given the state of a system at\n\\(t\\) and the forces and constraints to which it is subject, there is\nan equation, ‘Schrödinger’s\nequation’, that gives the state at any other time \\(U\n\\ket{v_t} \\rightarrow \\ket{v_{t'}}\\).[8]\n The important properties of \\(U\\) for our\npurposes are that it is deterministic, which is to\nsay that it takes the state of a system at one time into a unique\nstate at any other, it is unitary, which means that\nit is an automorphism of the Hilbert space on which it acts (i.e., a\nmapping of that space onto itself that preserves the linear space\nstructure and inner product), and it is linear, which\nis to say that if it takes a state \\(\\ket{A}\\) onto the state\n\\(\\ket{A'}\\), and it takes the state \\(\\ket{B}\\) onto the state\n\\(\\ket{B'}\\), then it takes any state of the form \\(\\alpha \\ket{A} +\n\\beta \\ket{B}\\) onto the state \\(\\alpha \\ket{A'} + \\beta\n\\ket{B'}\\). Contexts of type 2 (“Measurement\n Contexts”):[9]\nCarrying out a “measurement” of an observable \\(B\\) on a\nsystem in a state \\(\\ket{A}\\) has the effect of collapsing the system\ninto a \\(B\\)-eigenstate corresponding to the eigenvalue observed. This\nis known as the Collapse\nPostulate. Which particular \\(B\\)-eigenstate it\ncollapses into is a matter of probability, and the probabilities are\ngiven by a rule known as Born’s Rule: \n\nThere are two important points to note about these two kinds of\ncontexts: \n\nI remarked above that in the same way that all the information we have\nabout the relations between locations in a city is embodied in the\nspatial relations between the points on a map which represent them, all\nof the information that we have about the internal relations among (and\nbetween) states and quantities in quantum mechanics is embodied in the\nmathematical relations among the vectors and operators which represent\n them.[10]\n From a mathematical point of view, what\nreally distinguishes quantum mechanics from its classical predecessors\nis that states and quantities have a richer structure; they form\nfamilies with a more interesting network of relations among their\nmembers.  \n\nAll of the physically consequential features of the behaviors of\nquantum mechanical systems are consequences of mathematical properties\nof those relations, and the most important of them are easily\nsummarized: Any way of adding vectors in a Hilbert space or\nmultiplying them by scalars will yield a vector that is also in the\nspace. In the case that the vector is normalized, it will, from (3.1),\nrepresent a possible state of the system, and in the event that it is\nthe sum of a pair of eigenvectors of an observable \\(B\\) with distinct\neigenvalues, it will not itself be an eigenvector of \\(B\\), but will be\nassociated, from (3.4b), with a set of probabilities for showing one or\nanother result in \\(B\\)-measurements. For any Hermitian operator on a Hilbert space, there are\nothers, on the same space, with which it doesn’t share a full set of\neigenvectors; indeed, it is easy to show that there are other such\noperators with which it has no eigenvectors in common. \n\nIf we make a couple of additional interpretive assumptions, we can say\nmore. Assume, for instance, that  Every Hermitian operator on the Hilbert space\nassociated with a system represents a distinct observable, and (hence)\nevery normalized vector, a distinct state, and A system has a value for observable \\(A\\) if, and only if, the\nvector representing its state is an eigenstate of the \\(A\\)-operator. The\nvalue it has, in such a case, is just the eigenvalue associated with\nthat\n eigenstate.[11] \n\nIt follows from (P2), by (3.1), that no quantum mechanical state is an\neigenstate of all observables (and indeed that there are observables\nwhich have no eigenstates in common), and so, by (3.2), that\nno quantum mechanical system ever has simultaneous values for all of\nthe quantities pertaining to it (and indeed that there are pairs of\nquantities to which no state assigns simultaneous values).  \n\nThere are Hermitian operators on the tensor product\n\\(H_1 \\otimes H_2\\) of a pair of Hilbert spaces\n\\(H_1\\) and \\(H_2\\) ... In the event that \\(H_1\\) and\n\\(H_2\\) are the state spaces of systems \\(S1\\) and \\(S2\\),\n\\(H_1 \\otimes H_2\\) is the state-space of the complex\nsystem \\((S1+S2)\\). It follows from this by (4.1) that there are\nobservables pertaining to \\((S1+S2)\\) whose values are not determined by\nthe values of observables pertaining to the two individually. \n\nThese are all straightforward consequences of taking vectors and\noperators in Hilbert space to represent, respectively, states and\nobservables, and applying Born’s Rule (and later (4.1) and (4.2)), to\ngive empirical meaning to state assignments. That much is perfectly\nwell understood; the real difficulty in understanding quantum mechanics\nlies in coming to grips with their implications — physical,\nmetaphysical, and epistemological. \nAnyone trying to come to an understanding about what quantum mechanics\nsays about the world has to grapple with one remaining fact. This\nproblem is not an issue with Hilbert spaces, but of the dynamics\n– the rules that describe the trajectories that systems follow\nthrough the space. From a physical point of view, it is far more\nworrisome than anything discussed to this point. It not only presents\ndifficulties to someone trying to provide an interpretation\nof the theory, but also seems to point to a logical inconsistency in\nthe theory’s foundations. \n\nSuppose that we have a system \\(S\\) and a device \\(S^*\\) which measures an\nobservable \\(A\\) on \\(S\\) with values \\(\\{a_1,\na_2, a_3, ...\\}\\). Then there is some\nstate of \\(S^*\\) (the ‘ground state’), and some observable \\(B\\)\nwith values \\(\\{b_1, b_2,\nb_3, ...\\}\\) pertaining to \\(S^*\\) (its ‘pointer\nobservable’, so called because it is whatever plays the role of\nthe pointer on a dial on the front of a schematic measuring instrument\nin registering the result of the experiment), which are such that, if\n\\(S^*\\) is started in its ground state and interacts in an appropriate way\nwith \\(S\\), and if the value of \\(A\\) immediately before the interaction is\n\\(a_1\\), then \\(B\\)’s value immediately thereafter is\n\\(b_1\\). If, however, \\(A\\)’s value immediately before the\ninteraction is \\(a_2\\), then \\(B\\)’s value afterwards is\n\\(b_2\\); if the value of \\(A\\) immediately before the\ninteraction is \\(a_3\\), then \\(B\\)’s value immediately after\nis \\(b_3\\), and so on. That is just what it\nmeans to say that \\(S^*\\) measures \\(A\\). So, if we represent the\njoint, partial state of \\(S\\) and \\(S^*\\) (just the part of it which specifies\nthe value of [\\(A\\) on \\(S\\) & \\(B\\) on \\(S^*\\)], the observable whose values\ncorrespond to joint assignments of values to the measured observable on\n\\(S\\) and the pointer observable on \\(S^*\\)) by the vector\n\\(\\ket{A=a_i}_s \\ket{B=b_i}_{s^*}\\), and let “\\(\\rightarrow\\)”\nstand in for the dynamical description of the interaction between\nthe two, to say that \\(S^*\\) is a measuring instrument for \\(A\\) is to say\nthat the dynamical laws entail that, \n\nand so on.[12] \n\nIntuitively, \\(S^*\\) is a measuring instrument for an observable \\(A\\) just in\ncase there is some observable feature of \\(S^*\\) (it doesn’t matter what,\njust something whose values can be ascertained by looking at the\ndevice), which is correlated with the \\(A\\)-values of systems fed into it\nin such a way that we can read those values off of \\(S^*\\)’s observable\nstate after the interaction. In philosophical parlance, \\(S^*\\) is a\nmeasuring instrument for \\(A\\) just in case there is some observable\nfeature of \\(S^*\\) which tracks or indicates the \\(A\\)-values\nof systems with which it interacts in an appropriate way.  \n\nNow, it follows from (3.1), above, that there are states of \\(S\\) (too\nmany to count) which are not eigenstates of \\(A\\), and if we consider what\nSchrödinger’s equation tells us about the joint evolution of \\(S\\) and\n\\(S^*\\) when \\(S\\) is started out in one of these, we find that the state of the\npair after interaction is a superposition of eigenstates of [\\(A\\) on \\(S\\)\n& \\(B\\) on \\(S^*\\)]. It doesn’t matter what observable on \\(S\\) is being\nmeasured, and it doesn’t matter what particular superposition \\(S\\) starts\nout in; when it is fed into a measuring instrument for that observable,\nif the interaction is correctly described by Schrödinger’s\nequation, it follows just from the linearity of the \\(U\\) in that equation,\nthe operator that effects the transformation from the earlier to the\nlater state of the pair, that the joint state of \\(S\\) and the apparatus\nafter the interaction is a superposition of eigenstates of this\nobservable on the joint system. \n\nSuppose, for example, that we start \\(S^*\\) in its ground state, and \\(S\\) in\nthe state It is a consequence of the rules for obtaining the state-space of the\ncomposite system that the combined state of the pair is  and it follows from the fact that \\(S^*\\) is a measuring instrument for \\(A\\),\nand the linearity of \\(U\\) that their combined state after\ninteraction, is  \n This, however, is inconsistent with the dynamical rule for contexts of\ntype 2, for the dynamical rule for contexts of type 2 (and if there are\nany such contexts, this is one) entails that the state of the\npair after interaction is either  \n\nor \n\nIndeed, it entails that there is a precise probability of \\(\\frac{1}{2}\\) that it\nwill end up in the former, and a probability of \\(\\frac{1}{2}\\) that it will end up\nin the latter.  \n\nWe can try to restore logical consistency by giving up the dynamical\nrule for contexts of type 2 (or, what amounts to the same thing, by\ndenying that there are any such contexts), but then we have\nthe problem of consistency with experience. For it was no mere blunder\nthat that rule was included in the theory; we know what a\nsystem looks like when it is in an eigenstate of a given observable,\nand we know from looking that the measuring apparatus after\nmeasurement is in an eigenstate of the pointer observable. And so we\nknow from the outset that if a theory tells us something else\nabout the post-measurement states of measuring apparatuses, whatever\nthat something else is, it is wrong. \n\nThat, in a nutshell, is the Measurement Problem in quantum\nmechanics; any interpretation of the theory, any detailed story about\nwhat the world is like according to quantum mechanics, and in\nparticular those bits of the world in which measurements are going on,\nhas to grapple with it. \n\nIf we don’t want to lose the distinction between pure and mixed\nstates, we need a way of representing the weighted sum of a set of pure\nstates (equivalently, of the probability functions associated with\nthem) that is different from adding the (suitably weighted) vectors\nthat represent them, and that means that we need either an alternative\nway of representing mixed states, or a uniform way of representing both\npure and mixed states that preserves the distinction between them.\nThere is a kind of operator in Hilbert spaces, called a density\noperator, that serves well in the latter capacity, and it\nturns out not to be hard to restate everything that has been said about\nstate vectors in terms of density operators. So, even though it is\ncommon to speak as though pure states are represented by vectors, the\nofficial rule is that states – pure and mixed, alike – are\nrepresented in quantum mechanics by density operators. \n\nAlthough mixed states can, as I said, be used to represent\nour ignorance of the states of systems that are actually in one or\nanother pure state, and although this has seemed to many to be an\nadequate way of interpreting mixtures in classical contexts, there are\nserious obstacles to applying it generally to quantum mechanical\nmixtures. These are left for detailed discussion in the other entries\non quantum mechanics in the Encyclopedia. \n\nEverything that has been said about observables, strictly speaking,\napplies only to the case in which the values of the observable form a\ndiscrete set; the mathematical niceties that are needed to generalize\nit to the case of continuous observables are\ncomplicated, and raise problems of a more technical nature. These, too,\nare best left for detailed discussion. \n\nThis should be all the initial preparation one needs to\napproach the philosophical discussion of quantum mechanics,\nbut it is only a first step. The more one learns about the\nrelationships among and between vectors and operators in Hilbert space,\nabout how the spaces of simple systems relate to those of complex ones,\nand about the equation which describes how state-vectors move through\nthe space, the better will be one’s appreciation of both the nature and\nthe difficulty of the problems associated with the theory. The funny\nbackwards thing about quantum mechanics, the thing that makes it\nendlessly absorbing to a philosopher, is that the more one learns, the\nharder the problems get.","contact.mail":"ji2266@columbia.edu","contact.domain":"columbia.edu"}]
