[{"date.published":"2009-03-05","url":"https://plato.stanford.edu/entries/logic-dialogical/","author1":"Laurent Keiff","entry":"logic-dialogical","body.text":"\n\n\nThe expression dialogical logic refers to a research\ntradition that can be traced back to Greek antiquity, when logic was\nconceived as the systematic study of dialogues in which two parties\nexchange arguments over a central claim. In its modern form,\ndialogical logic uses concepts of game theory to design dialogue games\nthat provide a semantics for a wide range of logical systems. The\nmodern approach, originally developed in the context of constructive\nmathematics and logic, has proved to be fruitful for the study,\ncomparison and combination of various logical systems, such as\nparaconsistent, free, modal, and substructural logics.\n\n\nThe dialogical approach to logic stems from the introduction of\ngame-theoretical concepts in the definition of fundamental logical\nnotions. A historical sketch of the relations between logic and games\ncan be found in the entry on \n logic and games,\n and a detailed account can be found in Lorenz (2001).  Dialogical logic, as we\nknow it today, comes from Paul Lorenzen in his work on the\noperative approach to constructive logic and mathematics.  Lorenzen's\ndialogical approach was invented as a solution to some of the problems\nof the operative program.  (For details on operative logic, see\nLorenzen (1955)). In particular, the operative notion\nof derivation, which is essential to the definition of the\noperative notion of proposition, is, in general,\nundecidable. Furthermore, even if the derivation predicate were\ndecidable, a serious problem would remain: defining a proposition via\nthe notion of proof has the strange consequence that undecided\npropositions are not propositions at all. To address these problems,\nLorenzen and Lorenz proposed the concept of dialogue: \nTo briefly sketch the central concept, let us say that dialogues are\ngames where what is at stake is a formula. The set of rules is\ndesigned in such a way that the formula is valid (in some definite\nsense of the term) iff the player defending the formula has a winning\nstrategy in the game.  An important aspect of constructivity in\ndialogical logic is obvious in this definition: infinity plays no\nrole, i.e., it does not rely on a quantification over the set of\nmodels.  The dialogical notion of proof is based on the notion of\ngame, and, as mentioned in the quote above, dialogue games are\nfinitary. \nThe dialogical approach yielded a semantics for intuitionistic and\nclassical logic. Landmark publications include: Lorenzen (1958);\nLorenz (1961); Stegmüller (1964); Lorenzen and Lorenz (1978); and\nFelscher (1985). The progressive clarification of the main concepts\nduring the 70s opened the way, from the 80s up to present times, to an\nactive research programme. During this period, Rahman and\ncollaborators developed the original ideas into a conceptual framework\nthat, for reasons the following sections will set out, proved useful\nfor studying, comparing and combining non-classical logics (see\nRückert 2001). \nAnother tradition in dialogical logic developed in parallel with the\njust-described one, with occasional and fruitful contacts with\ndialogical logic.  The parallel tradition consists of the study of\nconcrete dialogues, such as those that occur, for example, in natural\nlanguages.  The aim of the parallel tradition was the study of the\nunderlying logical regularities of these concrete dialogues. This\ntradition includes (to name but a few) the new rhetoric of Perelman\n(Perelman & L. Olbrechts-Tyteca 1958), Toulmin's argumentation\ntheory (Toulmin 1958), Barth and Krabbe's theory of dialogue (Barth\n& Krabbe 1982), and Woods' work in argumentation theory\n(Woods et al. 2000). There has recently been an effort to\nbridge the two traditions of dialogical logic, especially in the\ncontext of the logical analysis of legal and more generally\nnonmonotonic reasoning.  For more on these efforts, see, Prakken\n(2005). \nDialogues provide a way to specify the semantics of a given logic.\nThis section is devoted to a formal description of the rules of\ndialogical games for first-order logic in both its classical and\nintuitionistic versions. A detailed account of these rules can be\nfound in Rahman & Keiff (2004) and Rahman & Tulenheimo\n(2006). For a textbook presentation (in French), see Fontaine &\nRedmond (2008). We first define a\nlanguage, FO[τ], as the result of enriching a\nfirst-order language over vocabulary τ with the following\nmetalogical symbols: \n\nAn expression of our language is either a first-order formula\nor one of the symbols listed above under (ii.). A dialogically\nsigned expression is a triple\n〈X, f, e〉,\nwhere X is a label, f is a force symbol\nand e is an expression. For convenience we\nwrite X-f-e. The intended meaning\nof such expressions is that player X played a move\ncorresponding to expression e, and this move has to be\nconsidered as an attack (?) or a defence (!). We\nuse X and Y as variables ranging on\n{O, P}, always assuming that\nX ≠ Y. It should be emphasized that it is\nnot necessary to conceive the players of dialogical games as empirical\nhuman beings involved in a concrete game. They are often best seen as\nidealized agents, described by a strategy function, even if the\nconnection with actual epistemic subjects is an important part of the\ndialogical foundation of meaning. \nLet us now introduce the rules of the dialogical games. There are two\nkinds of such rules. Particle rules abstractly\ndescribe the way a formula can be attacked and defended,\naccording to its main connective. Structural rules, on the\nother hand, specify the general organization of the game. \nA particle rule (also known as an argumentation form) abstractly\ndescribes the way a formula of a given main connective may be objected\nto, and how to answer the objection. By definition, an argumentation\nform is a tuple consisting of (1) an assertion, (2) a set of attacks,\n(3) a set of defences, and (4) a relation specifying for each attack\nthe corresponding defence(s).  Argumentation forms are abstract in the\nsense that, in their definition, no reference is made to the context\nof argumentation in which the rule is applied (understood as a\nsituation in a process of argumentation, e.g., as the set of argument\nmoves made before the assertion for which the particle rule is\ndefined). The particle rules thus constitute the local\nsemantics of a logic, for they determine the dialogical meaning\nof each logical constant but say nothing about the way this meaning\nmay be related to anything else. Yet the local semantics given by the\nparticle rules are intrinsically dependent of the notion of dialogue,\nsince they describe sequences of language acts. \nIn the following tables, A and B are formulas and\nA[x/c] denotes the formula resulting from\nthe substitution of c for any free occurrence of the variable\nx in A.  Notice that there is no argumentation form\nfor atomic formulas. \nIn the context of a dialogue, a pair consisting of an attack and the\ncorresponding defence is called a round. The attack is said\nto open the round, and the defence to close it. \nThe explication of these rules is fairly obvious. Disjunction and\nconjunction differ only by the player who has the choice of the\nimmediate subformula with which the game will proceed: in a\nconjunction, the challenger may choose, confident that either disjunct\ncan be refuted; in a disjunction the choice lies with the defender.\nThus, to defend a conjunction, a player must be able to defend any of\nthe conjuncts, while in the case of a disjunction, it is sufficient to\nbe able to defend one of the disjuncts. The rules are similar in the\ncase of quantifiers: when attacking a universal quantifier, the\nchallenger can choose the instantiation he fancies for the bound\nvariable. When the assertion is existentially quantified, the defender\nchooses the instantiation. There is admittedly something less\nimmediately intuitive in the case of negation and implication. In both\ncases, the attack bears a defence force (!). One may convince\nhimself this is indeed correct by considering the following: in a\ndialectical situation, the only way to attack the assertion\n¬A is to assert A, and be prepared to defend\nthis assertion. Thus there is no proper defence against such an\nattack, but it may be possible to counterattack the assertion\nof A. Along the same lines, to challenge an implication\nessentially amounts to providing a proof of the antecedent and\nclaiming that the other player will fail to build a proof of the\nconsequent from it. The defence against such an attack then consists\nof a proof of the consequent. As underlined in the historical\noverview, dialogical logic was born in the context of constructivism,\nso it is not a surprise that the attack against ¬A\nand A→B is the same: the constructive negation\nof A reads as\nA→⊥. \nIt should be noted that this phenomenon is by no means a trifle: as\nwill be shown later, stipulations about the way the Proponent can make\nuse of the assertive content of such attacks by the Opponent are\nprecisely what yields a variety of dialogical systems corresponding to\n(e.g.) minimal logic, intuitionistic logic, free logics, or\nparaconsistent logics (see\n Section 3: Dialogues for Non-Classical Notions of Validity\n and the supplementary document\n Some Dialogical Systems for Non-Classical Logics.). \nAnother way to understand the particle rules is to think of them as\ndescribing the evolution of the\nstate of the (structurally unspecified)\ndialogue. States of the dialogue contain information on the\nformula about which the debate is running and on the mapping of roles\n(challenger and defender) onto the set of players. Let\nA ∈ FO[τ]. Let\nC={c0, c1,\n…} be a set of individual constants. A state of the dialogue\nfor A is a triple\n S=〈ρ, σ, Φ〉 where: \nNote that the player label of Φ is independent of the\nrole distribution defined by ρ, i.e., the player that\nasserts a formula in a dialogue may be either challenger or\ndefender. We say that the state of the dialogue\nS2 = 〈ρ2, σ2,\nΦ2〉 is reachable from the state\nS1 =\n〈ρ1, σ1, Φ1〉\niff S2 follows from S1 as a\nresult of the players making the moves stipulated by the corresponding\nparticle rules, in the roles determined by ρ1. The\nplayer whose role is challenger (?)  states an attack, the other (!)\nstates a defence. Thus particle rules tell us what states of the\ndialogue are reachable from a given state\nS1 = 〈ρ1, σ1,\nΦ1〉, according to the main connective in the\nformula B in Φ1. What follows is a recursive\ndefinition of the reachability relation between states. As already\nmentioned, ρ1−1(!) denotes the player\ndefending the formula at stake in the corresponding state of the\ndialogue (i.e., under a specified role assignment), and\nρ1−1(?) denotes the challenger of this\nformula. Let Φ1 =\nρ1−1(!)-B. S2\n= 〈ρ2, σ2,\nΦ2〉 is reachable from the state \nif S2 satisfies the following: \n  Particle rule for conjunction.  If B\n  is of the form C∧D, then\n  both S2 and S3 are\n  reachable, namely: \n  according to the choice of ρ1−1(?),\n  between the two attacks ?-L and ?-R. The role\n  assignment is not altered. \n  Particle rule for disjunction.  If B is of\n  the form C∨D, then both S2\n  and S3 are reachable, namely: \n  according to the choice of ρ1−1(!),\n  after an attack ?-∨ of\n  ρ1−1(?). The role assignment is not\n  altered. \nLet us now turn to the less obvious rules for negation and\nimplication. \n  Particle rule for negation.  If B is of\n  the form ¬C, then \nNotice that the distribution of roles is inverted\n(ρ1′), so that in the new state of the\ndialogue, the player that was previously challenger of ¬C\nis now defender of C. Nevertheless, the\nmove ρ1′−1(!)-C is an\nattack. \n  Particle rule for implication.  If B is of\n  the form C→D, then \nAgain, to attack an implication amounts to being prepared to defend\nits antecedent, so it should be noted that the move\nρ1′−1(!)-C counts as an\nattack. The game will then proceed, up to the choice of\nρ1′−1(?), according to the\nrelevant particle rule for C, or to a new state of the\ndialogue \nNote that the role assignment has changed again\n(to ρ1′′=ρ1), so that\nthe player defending C→D in S1 is\nnow defending D in S3. \nParticle rules for the quantifiers present no difficulty: as for\ndisjunction and conjunction, the only difference is the player who\nchooses the instantiation of the bounded variable. \n  Particle rule for universal quantifier.\n  If B is of the form ∀xC(x),\n  then \n  where ci is a constant chosen by\n  ρ1−1(?) when attacking with\n  ?-∀x/ci, and\n  σ1[x/ci] stipulates\n  that the occurrences of x that were bound by the quantifier\n  are now to be interpreted as ci. \n  Particle rule for existential quantifier.\n  If B is of the form ∃xC(x),\n  then \n  where ci is a constant chosen by\n  ρ1−1(!) when defending against the\n  attack ?-∃ of ρ1−1(?), and\n  σ1[x/ci] stipulates\n  that the occurrences of x that were bound by the quantifier\n  are now to be interpreted as ci. \nIn the same way as particle rules describe the local meaning of the\nlogical constants, structural rules determine their global\nsemantics. As is the case in the context of substructural logics, the\nnotion of proof in a given dialogue system is determined by\nthe structural rules. Structural rules thus describe the way an\nargumentation is built, which means they are responsible for the\ngeneral organization of the dialogues.  The structural rules are meant\nto organize the application of the particle rules in such a way that\nthe set of moves resulting from the application of the rules to an\ninitial formula (called the thesis) yields a dialogue that\ncan be seen as a valid argument for the thesis. There is, of course, a\nwide range of notions of validity, but here we are particularly\ninterested in logical validity. So the rules should be\ndesigned in such a way that a certain type of completion of the\ndialogue for a given thesis constitutes a proof of its logical\nvalidity. But it should be noted that other normative concepts could\nbe used to shape the structural rules, e.g., adequacy to idealized\nempirical argumentation, like it is in, for example, legal\nargumentation theory. See the end of\n Section 2.2.2 for some general comments on the\nformulation of structural rules. \nAs will be emphasized in the next section, the notion of proof in\nthe context of logical dialogues is based on the existence of a\nwinning strategy for the Proponent. This will be reflected in the\ndefinitions we use. A dialogue can be thought of as a set of\ndialogical games, which are in turn sequences of dialogically\nsigned expressions\nX-f-e. Dialogical games are\nstructured as a tree, the root of which is constituted by a\n(possibly empty) sequence of premises together with the thesis of the\ndialogue in the final position. Splits in the dialogue tree are\ngenerated by the propositional choices of the Opponent. Any possible\nattack by the Opponent against a conjunction, any possible defence of\na disjunction, and either possible reaction in the case of an attack\nby the Proponent against a conditional he defends (counterattack or\ndefence) will generate a new branch in the dialogue tree. No move of\nthe Proponent will open a new branch. A completed dialogue tree will\nthus contain all the Opponent's possible choices. \nAs already mentioned, a dialogue is a set of sequences of\ndialogically signed expressions. All sequences have as a common root a\n(possibly empty) sequence of premises, together with the thesis. All\nother members of the games are termed moves, and we say that\na player makes a move. According to the player making the\nmove, we talk about P-moves or\nO-moves. Any move is either an\nattack or a defence. The particle rules stipulate\nexactly which of the moves are to be counted as attacks. Obviously,\nany move which is not an attack is a defence. A move\nX-f-e is said to have a\npropositional content iff e is a first-order formula\n(e ∈ FO[τ]). D(A)\ndenotes the dialogue with, as a thesis, a move of the form\nP-!-A, and we say that\nD(A) is a dialogue for A. There\nexists a dialogue for A iff\nA ∈ FO[τ]. Premises of a\ndialogue must have a propositional content, and are moves of the form\nO-!-A occurring at the beginning of the\ndialogue. D(A;A1, …,\nAn) denotes a dialogue for A\nwith premises of propositional content A1, …,\nAn. Δ1, …,\nΔn denote the dialogical games that are members of\nD(A). Δ1[n]\ndenotes the n-th member of the sequence Δ1,\nand we talk of the rank n of the move\nΔ[n]: when writing down a dialogue, one keeps track of\nthe assertion/attack relation by adding an extra label to the attack\nmoves, namely the rank of the assertion attacked. This will become\nclear in the examples. \nNow let us state the structural rules. \n  SR-0: Starting Rule.   For any Δ\n  ∈ D(A), the thesis has position\n  0: \nFor any n > 0 and for any Δ\n∈ D(A) such that Δ[n]\nexists, if n is even then Δ[n] denotes\na P-move and otherwise denotes\nan O-move. If the set of premises is not empty, then\nall the dialogical games contain\nit. Let A0, …, Ai be the\npropositional content of the premises. Then for all\nΔ ∈ D(A), Δ begins\nwith i terms of\nrank H0, …, Hi\nsuch that\nΔ[H0] = \nO-!-A0, …,\nΔ[Hi]=O-!-Ai.These\nmoves are the premises of the\ndialogue D(A). The set of all premises\nof D(A) together with the thesis is called\nthe root of D(A). \nAny move following the thesis is a reaction to a previous move by the\nother player, and must comply with all the structural and particle\nrules of the dialogue. \nNotice that the rules of a dialogical system cannot include both\nSR-1i and SR-1c (see Section 2.2). \n  SR-2: Branching Rule For Dialogical Games. \n  Let Δ ∈ D(A) be a dialogical\n  game of even length (that is, where O is to\n  play). There are three cases in which Δ will be extended in\n  such a way that it will generate two distinct (new) games\n  Δ1 and Δ2. Let n be the\n  length of Δ and m be the number of premises\n  of D(A), then for all i ∈\n  {H0, …, Hm,0, …, n},\n  Δ1[i]=Δ2[i]. \n      Here the dots stand for an attack corresponding to the relevant\n      particle rule, according to formula B. \nNo other game situation will generate distinct dialogical games, i.e.,\nin any other case, the next move will be\nΔ[n+1]. Actually, one could make SR-2 symmetric, and\nlet P generate new games too. But, as the following\nrule will show, it is always strategically the best choice\nfor P to stay in the same context. \nNotice that the explicit reference to logical constants here is just a\nconvenient way to give a formally precise account of the notion\nof O-choice. Actually, a general formulation\n(although less precise) for this rule would be: any game situation\nwere O is to play and has to chose between several\nmoves will generate a distinct game for every choice available\nto O. \n  SR-3a: Winning Rule For Dialogical Games.   A\n  dialogical game Δ ∈ D(A) is\n  said to be closed iff there is some atomic formula which\n  has been played by both players. More precisely, Δ is closed\n  iff there are two integers m and n and an atomic\n  formula α ∈ Sub(A)∪{A}\n  such that the propositional content of Δ[m] is\n  α and is identical to the propositional content of\n  Δ[n], and exactly one of\n  {Δ[m], Δ[n]} is\n  a P-move (the other one being, consequently,\n  an O-move). A dialogical game is open iff\n  it is not closed. \n  A dialogical game is finished iff it is closed or the rules\n  do not allow any further move by the player who has to move. Let\n  Δ be a finished game. If Δ is closed, the player who\n  stated the thesis (i.e., P according to rule\n  SR-0) wins it, otherwise he loses it. A finished\n  game cannot be extended. \nNotice that D(A) can be seen as\na sequence of games, in the sense that the order in\nwhich O chooses to play the different dialogical\ngames of the dialogue yields a different course for the dialogue. Such\nan order on the games of a dialogue D(A) is\ncalled a play\nof D(A). 〈D(A), p〉\ndenotes the play p of\ndialogue D(A). P cannot introduce atomic formulas. That\nis, P can make a move whose propositional content is\nan atomic formula α in a play p\nof D(A) iff O introduced\nα in a previous move. Atomic formulas cannot be attacked. \nBecause of the formal restriction, the game for quantifiers is\nasymmetric, in the sense that any time he can, O will\ntry to introduce a new constant (in order to\nprevent P from using the\ninformation O already conceded); and for dual\nreasons, P will always try to use the constants\nalready conceded. Some important aspects of the meaning of the SR-5\nrule are discussed in the second example of Section 2.3. \nTo state the next rule, we first need some definitions. Definition: Strict Repetitions \n  A constant is said to be used by a player if the player\n  chooses it to attack a universal quantifier or to defend an\n  existential quantifier. A constant is said to be new if it\n  is used by a player and has not been used by either player in a\n  previous move. \n  Let Δ[m] X-?-e be an attack\n  against some previous move Δ[n]. We say that\n  Δ[m] is a strict repetition iff either (i)\n  there exists some move Δ[k] such\n  that n<k<m, and Δ[k]\n  is an attack against Δ[n] with an\n  expression e identical to the expression in\n  Δ[m]; or (ii) Δ[m] is an attack\n  against an universal quantifier asserted in Δ[n],\n  introducing a new constant, and there exists some move\n  Δ[k] such\n  that n<k<m, and Δ[k]\n  also attacks Δ[n] introducing a new constant. \n  Let Δ[m] X-!-e be a defence\n  against some previous attack Δ[n]. We say that\n  Δ[m] is a strict repetition iff either (i)\n  there exists some move Δ[k] such\n  that n<k<m, and Δ[k]\n  is a defence against Δ[n] with an\n  expression e identical to the one in Δ[m];\n  or (ii) Δ[m] is a defence of an existential\n  quantifier, introducing a new constant, and there exists\n  some move Δ[k] such\n  that n<k<m, and Δ[k]\n  defends the same quantifier, also by introducing a constant\n  which was new at k. \n  Nothing else is a strict repetition. \nWe can now state the next rule, which has classical and intuitionistic\nvariants corresponding respectively to SR-1c and\nSR-1i: \nThe rules of the dialogical games are defined, but now the question\nis: how do such games relate to logic in the first place? In the\ntradition of dialogical logic, it is usual to define validity using\nthe notion of winning strategy for the Proponent. \nA strategy for player X in a dialogical game\nis a function taking histories (i.e., sequences of moves of the game\nwhose first member is the thesis (or the set of premises and the\nthesis) and such that all subsequent moves comply with the rules)\nwhere the last move is a Y-move as arguments, and\n(legal) X-moves as values. In other terms, a strategy\nis a function that tells to a player what to do according to what has\npreviously happened in the game. A strategy in this sense must\ntell X what to do against any possible\nsequence of Y-moves (i.e., in all possible\nhistories). A winning strategy for X is a\nstrategy such that X will win the game if he makes\nall his moves according to the strategy. Notice that the relevant\narguments for a winning strategy for X are sequences\nof moves that differ in the Y-moves, since\nthe X-moves are determined by the strategy\nitself. \nThe structural rules, in the version presented here, are conceived\nwith the purpose of reflecting the notion of strategy in the way the\n(global) game is organised. Indeed, P cannot win a\nplay of D(A) unless he is able to win the\ngame against all possible moves by O: each dialogical\ngame is defined by a sequence of choices of O, so the\nset of all the games is the set of all\npossible O-choices in the dialogue. Thus we can\ndefine the notion of validity without explicit reference to\nstrategy: \n  Definition (Validity): \n  A first-order sentence A is said to be dialogically\n  valid if all dialogical games belonging to the\n  dialogue D(A) are closed. \nMore generally, we can define a notion of (dia)logical consequence: \n  Definition (Dialogical Consequence): \n  A first-order sentence A is said to be a dialogical\n  consequence of a finite set\n  Γ={A0, …, An}\n  of first-order sentences if all dialogical games belonging to the\n  dialogue D(A), whose root consists of a\n  set of premises of propositional\n  content A0, …, An\n  and A as a thesis, are closed. \nAn interesting philosophical property of the dialogical approach is\nthat the difference between notions of logical consequence is\nexpressed as a difference in the structural rules. This feature is\nexemplified by the set of rules presented in the previous section. If\none takes the whole set except SR-1i, then it can be shown\nthat an FO sentence is dialogically valid iff it is a\nvalid sentence of FO classical logic. If, on the\nother hand, one takes the whole set of rules except SR-1c and\nSR-6c, then an FO sentence is dialogically\nvalid iff it is a valid sentence of FO intuitionistic\nlogic. \nTo see how such characterization theorems can be proved, observe that\nthe states of the game as described in the particle rules correspond\nexactly to the tableau rules for the same connectives when embedded in\na dialogue. For a thorough introduction to tableau methods, see\nd'Agostino et al (1999). The O-signed\nformulas of the states of the dialogue correspond\nto T-labeled formulas of the tableaux,\nwhile P-formulas correspond to the F-labeled\nformulas. Now observe that the branching rules of dialogical games\ncorrespond to the branching rules of tableaux: dialogical games split\nwhen O defends a disjunction\n(T-A∨B), attacks\na P-conjunction\n(F-A∧B), or reacts to an attack against\nhis assertion of a conditional\n(T-A→B). The match between quantifier\nrules can be seen thus: when O defends an existential\nquantifier (T-∃xA) or attacks a universal\nquantifier (F-∀xA), his best option is to\nprevent P from using atomic formulas he himself\nconceded previously in the game (remember the formal restriction SR-5)\nso any time he can, he will introduce a new constant. Intuitionistic\ntableaux are a little more complicated, for the set of formulas to\nwhich the expansion rules can be applied is a subset of the formulas\non the branch, so a marking device is needed in order to keep track of\nwhat formulas are available at a given stage of the tree-building\nprocess. Complete descriptions and proofs can be found in Rahman\n(1993). An earlier formulation of the proofs related to natural\ndeduction and sequent calculus can be found in Haas (1980), and\nFelscher (1985). As to Haas (1980) Felscher remarks “it seems\nthat the technical gaps contained in this work are only minor and can\nactually be filled”, (1985, p. 351). \nWhen considering dialogues for validity, there is a straightforward\nway to transform a dialogue into a tableau and back. Thus the\ndifference is not so much technical, but rather philosophical. It is\nalso twofold. First, as already noted, dialogue systems are not\nnecessarily intended to capture a notion of validity. Concrete plays\nof the dialogical games could include errors, fallacies, failure in\nproof search, etc. Thus the dialogues that do characterize a definite\nnotion of validity can be seen as an abstraction from concrete,\nempirical dialogue games. This leads to the second point: it has been\nclaimed (e.g., in Lorenzen & Lorenz 1978) that the genetic link\nbetween concrete dialogues and validity dialogues explain why\nthe rules of validity games are the way they are. Extrapolating from\nthis point, one would say then that the dialogical approach offers a\nphilosophical standpoint that also gives an explanation of the\ntableaux rules. \nThe last point is of particular interest. The branchings that occur in\na tableau proof receive a natural explanation in a dialogical\nperspective, namely in terms of strategies. Actually, one can show\nthat a tableau proof is a reduct of the extensive form of the\ndialogical game, where O's choices are the only ones\nthat are taken into account. Such a reduct is useful since it exhibits\nthe winning strategy: P has a winning strategy if,\nand only if, any leaf of the tree is a P move. To see\nthe connection with the usual tableau closure rule, consider the\nfollowing. The propositional content of such a move can only be an\natomic formula (else there would be challenges available\nto O), and the formal restriction warrants that the\nsame atomic formula has been introduced by O earlier\nin the same branch. \nIt is thus possible to understand tableau proofs as a form of\nmetalogical reasoning about a game, whose features determine\nand explain the form of the tableau rules. \nFrom the dialogical perspective, as already noted, differences between\nlogical systems are conceived as differences in the sets of structural\nrules. In this respect, dialogues are akin to the substructural\napproach (see the entry\non substructural logics). This\nfeature has a philosophical importance that has been elaborated in\nJ. C. Beall and G. Restall's series of papers dedicated to logical\npluralism (e.g., see Restall 2002).  Quine argues that it makes no\nsense to talk about a plurality of logics, because this plurality is\njust linguistic, not logical. Changing the meaning of the logical\nconstants amounts to simply changing the subject, i.e., changing of\nidiom. Now, says Quine, when a translation suggests that a speaker is\nmaking use of another notion of logical consequence between the\nassertions he makes, Occam's razor (in the form of the Charity\nPrinciple) tells us that it is more parsimonious to consider that our\ntranslation of what the speaker says is incorrect, rather than the\nspeaker making use of another logic. So logical changes are just\nlinguistic changes (e.g., paraconsistent negation is, in this\nview, not talking about the meaning of “not”, but\nrather about some other indigenous connective), and there cannot be\nany controversy about the meaning of the logical constants. But from a\ndialogical point of view, in so far as local semantics (i.e., the\nintroduction/elimination rules, or, dialogically, the particle rules)\nstay untouched, there seem to be strong grounds to the claim that we\nare indeed talking about the same language. So the different\nsets of structural rules actually define different theories of\ninference, and there seem to be no unquestionable grounds for the\nclaim that one of them is the only correct one. \nThere is no general theory of the way structural rules should be\nformulated, and there is no unique language in which all possible\nstructural rules should be expressed. There are, nevertheless, some\nregular patterns that may be worth noting. There is a core of\nstructural rules that remain fairly unchanged from one system to\nanother: these rules define what a game is, who the players are, the\norder of the moves and what a winning move is (i.e., rules SR-0, 2,\n3a, 3b, 4). The structural rules that are altered in\norder to produce the dialogical systems overviewed\nin Section 3 are those that remain. They stipulate\nwhich moves can be attacked, when a defence can be made, and what can\nbe asserted by the players. Now, with the exception of the modal\nsystems, many of the dialogical systems in the literature are\nsubclassical, in the sense that the set of valid formulas of these\nsystems is a subset of the set of classically valid formulas.  A\ntypical modus operandi to produce a subclassical system is to\nmodify the rules in order to restrict the moves available to the\nProponent, thus restricting the set of his winning strategies (i.e., of\nthe dialogically valid formulas).\n Section 3\n contains\nvarious detailed examples of such restriction-generated systems, and\nthe interested reader may also consult the supplementary document\n Some Dialogical Systems for Non-Classical Logics.\n  Details of the\nconnection between structural rules of Gentzen-Style sequent calculi\nand their dialogical counterparts are given in\n Section 4. \nAs a legacy from the philosophical stance of the fathers of the\ndialogical approach, the systems of dialogical logic are usually\nconstructive procedures to prove the validity of formulas. Let the\nlength of a dialogue be the sum of the length of all its finished\ngames. Notice that, in the case of propositional logic, the\nSR-6 rules ensure that dialogues for a finite root (i.e., a\nroot consisting of a finite set of premises and a thesis, all being\nformulas of finite length) are of finite length. Indeed, each\nattack/defence pair in a game eliminates one connective from the\nformula at stake, in the sense that the game will proceed with respect\nto a strict subformula of the formula which has been attacked and\ndefended. So after finitely many such pairs, the game will finish,\nreaching the atoms of the formulas in the root of the dialogue, which\n(according to SR-5) cannot be attacked, since all attacks and defences\nallowed by SR-6 have been performed. Finitely many moves of such a\ngame will yield a splitting between exactly two finite games, and so\non. So the length of the whole dialogue is finite. This property is\nconserved in all the non-classical variants of propositional logic\npresented in Section 3 and the supplementary document\n Some Dialogical Systems for Non-Classical Logics,\n and plays an important role in the GTS-style dialogues\nof\n Section 5. \nNevertheless, this doesn't mean that every system of\ndialogical logic will constitute a constructive decision\nprocedure. For instance, one can give dialogue rules for second-order\nlogic using lambda-abstraction, and such a system would not be a\ndecision procedure. The reason is that even though one could prove the\nsystem sound and complete (i.e., that there is a winning strategy\nfor P in a dialogue for a second order\nformula A iff A is valid), there is no way to\nsystematically define such a winning strategy. The finding of the\nstrategy requires from P what one could see as a\n“creative” step, in the sense that there is no mechanical\nway to compute all the moves of an arbitrary strategy. \nBeing essentially procedural, dialogues well capture the dynamic\naspects of logic. It was already stated that the point of using\ndialogues to give a semantics to intuitionistic logic: the\nSR-1i rule amounts to requiring of P\nthat at any stage of the game he is able to provide grounds\nfor his assertions without having to rely on later concessions\nof O (i.e., attacks against a negation or a\nconditional). (See the third example in Section 2.3.) \nFruitful research in the context of legal reasoning has\nshown that dialogues can be devised where some of the rules of the\ndialogue can be discussed and modified within the very process of the\ndialogue. V and F operators of\nconnexive dialogical logic provide an example of the way a change in\nthe rules can be coded in the syntax (see Section 4 of supplementary\ndocument\nthe Some Dialogical Systems for Non-Classical Logics). \nLet us examine some concrete examples of how a dialogue is built in\nthe case of simple formulas. A dialogical proof of validity is written\nin the form of a table, with as a main division one column\nfor O and one for P. Each line of a\ntable bears one move of the corresponding player. Each of the two\n(O and P) columns is divided in\nthree: the outer sub-column bears the rank label of the move; when the\nmove is an attack, the inner sub-column bears the rank of the attacked\nmove; finally, the centre sub-column indicates the dialogical\nexpression contained in the move. An attack and the corresponding\ndefence (when it is performed) are written on the same line. Thus a\ncompleted line represents a closed round. \nLet us begin with a contingent formula. \nHere the Opponent makes a redundant move, namely conceding that\nα holds to defend the disjunction asserted in 1. Move 4 closes\nthis dialogical game, then O has the right to switch\nto a new game with 3′, where he wins. P has to\nmove, and there is nothing to attack or defend. This play of the game\nis finished and not closed; O wins, the formula is not\nvalid. \nLet us now turn to the proof of a simple tautology, a proof which\nis almost trivial, and yet displays some of the most important aspects\nof dialogical proof theory. \nThis basic dialogue contains just one game, including moves 0 to\n2. The dialogue is obviously closed. Now, such a dialogical proof\nfeatures a dynamics in the flow of information that is proper to game\nsemantics of the dialogical kind. One way to make this flow explicit\nis to extend the game with some (abstract sketch of) dialectical\nreasoning about the atomic formula. This is what is informally noted\nhere as moves 3 to 6. Those moves are not a part of the actual\ndialogue but a representation of the following\nconsiderations. The justification of the assertion of a complex\nsentence in a dialogue is given with respect to its subsentences. The\nprocess is recursive, and eventually stops when reaching atomic\nsentences. Now the justification of such atomic assertions is not\nconsidered in the formulation of the game when one wants to capture\nthe notion of validity. The formal rule says that whatever concept of\njustification for atomic sentences is good enough\nfor O will suffice for P. But there\nis more to say within a game-theoretical framework about the\nconnection between formal dialogues and other kind of argumentation\nprocesses where atomic sentences are justified. Such processes are\nprecisely what we refer to with !α. \nIn 3, the Opponent asks on what grounds the Proponent asserted the\natom α. Now the Proponent's answer is a counterattack (move\n4). P's strategy for grounding his assertion that\nα holds can be paraphrased thus: “I don't have my own\njustification, but whatever grounds you assumed\nwhen you asserted α are good enough for me”. This\nso-called copycat strategy is the core of the formal\nrestriction (SR-5). From this point of view, atoms are nothing but\nunknown or arbitrary formulas, for which the proof strategy may even\nnot be known. SR-5 structurally reflects the existence of an abstract\nstrategy, which is a winning strategy regardless of the concrete\nnature or shape of the proof of the relevant atom. \nThe following example illustrates the insights that dialogical logic\noffers on the difference between classical and intuitionistic\nlogic: \nTo defend against attack 1, P has to choose\n¬α, because the other disjunct is an atom that he cannot\nstate before O has conceded it. In attacking the\nnegation in 3, O concedes the means to defend the\nother disjunct. With classical rules, P can make use\nof this information to defend again in 4 and win. Such a defence is\nnot allowed in intuitionistic logic, which takes seriously the\nprocedural nature of the proof. P's defence in 2 will\nlead to a loss because P has to choose without\nknowing which disjunct he has a proof for. When he eventually gets the\ninformation to justify a choice, it will be too late\nintuitionistically. \nThe following example illustrates the importance of the flow of\ninformation within a proof. \nThe decisive move is the defence 6, where P defends\nagain against attack 1, bearing in mind the constant chosen\nby O in his attack 5. O's attack in\n7 gives P the right atom in order to defend against\n5. The\n dialogue system for free logic shows the\nimportance of taking the choice of an interpretation for variables as\nan explicit move. \nAs has been mentioned already, dialogical logic has converted itself\ninto a conceptual framework of sufficient generality to be able to\nexpress, combine and compare a number of diverse notions of validity\nof logical inference. Actually, the idea of dialogical logic as a\ngeneral framework emerged during the late 1990s, and represents a\nradical change from the strict constructivism of the origins. Here, we\nshall concentrate on two examples, namely the dialogical systems for\nnormal modal logics and for linear logic. See the supplementary \ndocument\nthe Some Dialogical Systems for Non-Classical Logics for\ndialogical systems for free, paraconsistent and connexive logics. \nModal dialogues are developed in Rahman and Rückert (1997).  See\nthe entry on Modal Logic for an\noverview.  \nLet us extend our vocabulary with two modal operators, □ and\n♢, which as usual we intend to read as (alethic) necessity\n(resp. possibility). In order to define the particle rules\nfor such operators, we must first adjust the syntax of the dialogical\nmoves. One can see modalities as making explicit the context in which\nan assertion is made. In this perspective, modal dialogues should\nexhibit in the syntax the contextual nature of the\nmoves. A modal (dialogically signed) formula thus has the\nform X-f-e-ν where\nX and f are the same as usual, ν is a label\n(i.e., a string of integers, which will be explained later) denoting\nthe dialogical context, and e is an expression of\nour enriched language, including, for any label ν, an expression of\nthe form □/ν. Particle rules for modalities are stated in the\nfollowing table: \nParticle rules can also be defined with respect to the accessibility\nrelation between states of the modal game, which are tuples\nof the form: S=〈ρ, σ, Φ, λ〉,\nwhere ρ and σ are the same as usual, Φ is a modal\nformula, and λ is an assignment of dialogical contexts to\nformulas. \nLet S1 =\n〈ρ, σ, ρ−1(!)-□A\n, λ〉.  S2 is accessible\nfrom S1 iff \nwhere λA/ν denotes the result of\nextending λ assigning context ν to the\nformula A. S2 is reached after an attack\nρ−1(?)-□/ν, where ν is a dialogical context\nchosen by ρ−1(?). \nLet S1 =\n〈ρ, σ, ρ−1(!)-♢A, λ〉. S2 is accessible\nfrom S1 iff \nwhere λA/ν denotes the result of\nextending λ assigning context ν to the\nformula A. S2 is reached after an attack\nρ−1(?)-♢. ν is a dialogical context\nchosen by ρ−1(!). \nSince the development of the possible worlds semantics for modal\nlogic, differences between modal logics are usually understood as\ndifferences in the properties of the accessibility relation in Kripke\nmodels. Now, this relation is dialogically captured by the structural\nrules stipulating, in the context of a modal game, what labels can be\nused by the players in order to attack and defend modal\nassertions. Let us be more precise. The syntax of such labels obeys\nthe following: \nThe original context has rank 1. For any context of\nrank n, its successors have rank n+1. We say that a\nplayer uses a label when he chooses this label to attack a\n□ operator or to defend a ♢ operator. A\nplayer introduces a label ν, and a label is new\niff the player uses the label in some move Δ[n] and\nthere is no previous move Δ[m] in the same game where\nν is used. \nIt is important here to keep in mind that modal dialogues\nfeature two distinct tree structures. First, a dialogical\ngame is a tree whose branches are plays of the game, and a\nbranching occurs when O has a choice between\ndifferent moves. Second, the dialogical contexts are\nstructured as a tree, where a branch is a chain of contexts connected\nby a successor relation. The contexts of the dialogical\nexpressions in a single play of a dialogical game may well be\nstructured as a branching tree with the original context as a\nroot. \nSome of the structural rules have to be rephrased along the following\nlines: \nLet us now give the structural rules that will specifically yield a\ndialogical notion of validity that is sound and complete with respect\nto the principal normal modal systems. \nFor the label accessibility rule, the idea is straightforward. The\nminimal K-accessibility relation is expressed by\nletting P use the label of a successor of the context\nhe is playing in, provided of course that O already\nconceded its existence (introduced it). Reflexivity amounts to\nletting P choose the label of the context he is\nalready playing in. Symmetry is captured by assuming that when a\ncontext has access to a successor, then this context is accessible\nfrom the successor. Transitivity frees P from the\nobligation to choose an immediate successor (or predecessor\nin the presence of symmetry). The formulation of the structural rule\nfor the following systems is just the result of a combination of these\nnotions. Remember that P's choices of labels are\nrestricted by SR-7. \nIn the case of a serial accessibility relation, characteristic of the\nsystem D, the formal rule SR-7 is inadequate: if we want to\ncapture the fact that any context has access to at least another one,\nthen we clearly need to let P make use of this\nassumption without needing any previous concession\nby O. In this case, just one modal rule is\nneeded. \nActually, the only if part of the condition in SR-7D is\nredundant, for it is P's strategical interest to try\nto stay in the contexts given by O because of the\nformal restriction (SR-5). This restriction ensures that every move in\nthe dialogues with the (SR-7D) rule strictly corresponds to\nwhat can be assumed about a serial model. \nBlackburn (2001) presents a natural way of bringing together hybrid\nmodal logics and dialogues. The hybridization of a modal language\namounts to extending its expressive power in such a way that it\nbecomes possible to refer in the object language to a particular state\nof the model (see e.g., Blackburn 2000). One of the salient virtues\nof hybrid languages is their ability to express straightforwardly a\nwide range of frame conditions with object-language\nformulas. Investigators of dialogical proof systems welcomed the\nsuggested techniques, which proved particularly useful in the context\nof temporal dialogues (Rahman, Gorisse & Damien 2004) or\nnon-normal modal dialogics (Rahman 2002). Hybridization made it\npossible to devise a special kind of abductive dialogue where the\nProponent searches for the minimal frame conditions to yield a winning\nstrategy for a given formula (Keiff 2004). \nSee the entry on Linear Logic for a\ngeneral overview of the field. Linear game semantics were introduced\nby Blass (1992), then further developed by various people including\nAbramsky, Jagadesan, Hyland, Girard himself (the founder of linear\nlogic) and Japardize. Lorenz/Lorenzen-style dialogues were introduced\nin Rahman (2002). \nFollowing the inventor of linear logic, one could say that the\nfundamental intuition at the root of the field is the following: the\nsubject matter of logic is interaction, or rather the “well\nhidden geometrical structure” of it (see Girard 1999). This\nnotion is declined in two principal ideas (see e.g., Blass 1998): the\nconception of negation as a role switch and of the occurrence of a\nformula in a proof as a (bounded) resource. As first shown in Blass\n(1992), game semantics is a natural setting for these ideas. \nLinear negation is the same as dialogical negation:\nit consists of a role switch between the players. \nLocalization of formulas: the conceptual framework of\nlinear logic is akin to the Brouwer-Heyting-Kolmogorov approach of a\nsemantics of proofs. To this conception of proofs as objects, linear\nlogic adds the computation-driven intuition that each occurrence of\nthe same formula in a proof must be taken as a distinct resource for\nthe inference process. The basic idea stems from the consideration\nthat the occurrence of a formula in a proof is located\nsomewhere, and that one should take seriously the differences in\nlocation. Hence the linear logical consequence relation is\nresource-sensitive. Weakening, expansion and contraction rules are\nrejected, for they say respectively that a redundant premise can be\nadded in a derivation, that a given premise can always be used twice,\nand that two distinct tokens of the same premise type can be\nconsidered the same. In a sequent Σ ⊢ A, Σ\ndenotes a multiset of formulas (i.e., a set together with a function\ngiving for each member of the set the number of its occurences in the\nset, to the effect that {A} and {A, A}\ndenote the same set, but different multisets). \nIn the dialogical framework, each move is an action. It is therefore\nvery natural to consider that two distinct moves are different\nactions, consuming different resources, even when the two moves have\nthe same propositional content. More precisely,    An atomic O-formula has been used iff\nthis formula is the propositional content of\na P-move. Atomic P-formulas are used\nby the very move in which they appear.   A complex formula A has been used iff all the\npossible aggressive and defensive moves related to A have\nbeen stated. \nThis general definition will be made more precise when we state the\nparticle rules for linear connectives. In order to keep track of the\nuse of formulas in the course of the dialogue, one may use a\nbracketing device: once a formula has been used, its propositional\ncontent is bracketed. This allows us to formulate a notion of linear\nvalidity: \nLinear validity: A formula A is linearly\nvalid iff there is a closed dialogue\nfor P-!-A such that the propositional\ncontent of any move has been used (and therefore is bracketed). \nLinear particles offer a very fine-grained perception of the way\npieces of information are combined in a proof (which is one of the\nmain points of Substructural\nLogic). Let us take an example: the two multiplicative\nparticles. We will follow the notation used in Blass\n(1992). Multiplicative conjunction, (⊗), known as\ntensor, has the following Gentzen-style particle rules: \nAll the information contained in the premises is conserved in the\nconclusion, and nothing else is added (except the relevant\nparticle). Compare with the following rules for multiplicative\ndisjunction (⅋), known as par: \nThe meanings of the two multiplicative particles are obviously dual to\neach other. Both pieces of information A and B are\npresent in the premises. The main difference lies in the geometry of\nthe proof: the introduction of tensor on the right of a\nsequent needs two premises, while par needs two premises when\nintroduced on the left. Now from the dialogical point of view, these\nrules have to be read analytically, i.e., bottom up, and a\ntwo-premises rule means a splitting in the corresponding\ndialogue. Such splittings are captured by a notion of context. Linear\ndialogues are contextual in a sense akin to modal dialogues. In other\nterms, the flow of information within the proof is constrained by an\nexplicit structure of contexts, ordered by a relation of\nsubordination. As in the modal case, the introduction of a new context\nwill always be a consequence of the Opponent's choices. The Proponent\nwill stay in the same context as long as he can. \nA sequent Γ ⊢ A is the statement that from\nassumptions Γ,  one could infer\nconclusion A. From the dialogical point of view, assumptions\nare the Opponent's concessions, while conclusions are the Proponent's\nclaims. Thus, the rules above indicate that splitting\nfor tensor occurs when it is asserted by the Proponent, so\nthe dialogical particle rule will let the challenger choose the\ncontext where the dialogue will proceed. Dually, par will\ngenerate a splitting when asserted by the Opponent, thus the particle\nrule will let the defender choose the context. \nNow, the splitting between contexts can have a slightly different\ndialogical meaning. Consider the three rules for additive conjunction\n(∧): \nAs in the case of multiplicative conjunction, the challenger will\nchoose the context, but here the assumptions contained in the context\nare the same. To understand the difference, notice that there are two\nrules of left-introduction. Dialogically, this means that when the\nOpponent has asserted A∧B, there are two\ndistinct games available to the Proponent (one where the Opponent will\ndefend A and one where he will defend B). In the\nsame way, the two premises of the rule of right-introduction\ncorrespond to two distinct games. They are jointly mentioned in the\nsame rule since the choice between them lies with the challenger,\nwhich happens to be the Opponent, so the validity of the conclusion,\ni.e., a winning strategy for the Proponent, must include a winning\nstrategy in both games. \nThe occasions where a choice of context is needed will be determined\nby the particle rules, but a structural rule is needed first in order\nto regulate the opening of contexts in a dialogue. \nNow, the previous notions immediately call for a rephrasing of the\nformal rule SR-5: \nFor the sake of brevity, we will concentrate on the multiplicative\nfragment of linear logic, i.e., which connectives are tensor\n(⊗), par (⅋), linear implication\n(⊸), and negation (¬). \nParticle rules for the multiplicative connectives are defined with\nrespect to states of the linear game, which are tuples of the\nform: S=〈ρ, σ, Φ, λ〉, where ρ\nand σ are as usual, Φ is a linear formula, and λ is\nan assignment of dialogical contexts to formulas. \nConcerning tensor, the challenger will choose the conjunct to be\ndefended and the context where it should be defended. \n  Particle rule for tensor: \n  Let S1 =\n  〈ρ, σ, ρ−1(!)-A⊗B, λφ/ν〉,\n  where λφ/ν assigns context ν to the\n  formula\n  ρ−1(!)-A⊗B. Both S2\n  and S3 are accessible\n  from S1: \n  where λA/μ denotes the result of\n  extending λ by assigning context μ to the\n  formula A. S2 is reached after an\n  attack ρ−1(?)-R/μ, where μ is a\n  dialogical subcontext of ν chosen by\n  ρ−1(?). \n  where λB/π denotes the result of\n  extending λ by assigning context π to the\n  formula B. S2 is reached after an\n  attack ρ−1(?)-L/π, where π is a\n  dialogical subcontext of ν chosen by\n  ρ−1(?). \nThe bracketing device will be as follows: the\nexpression A⊗B is considered used and is\nbracketed iff both states S2\nand S3 have been reached. \nWith par, the defender will choose the disjunct to be defended and the\ncontext where it should be defended. He will nevertheless have to\ndefend both disjuncts. Here lies one of the main points that make\ndialogical semantics essential to linear logic. The multiplicative\ndisjunction has “conjunctive features”, as Girard (1999)\nputs it: a proof of A⅋B involves a proof\nof A and a proof of B. Now the main difference\nbetween conjunction and disjunction in a dialogue is the player\n(ρ−1(!)  or ρ−1(?)) who\nchooses how the game will proceed. What makes par a disjunction is\nthus the fact that it is the defender who has the choice of\nthe order in which the proofs are given and the context where they\nwill be given.  These considerations lead to the following particle\nrule for par: \n  Particle rule for par.  \n  Let S1 =\n  〈ρ, σ, ρ−1(!)-A⅋B, λφ/ν〉,\n  where λφ/ν assigns context ν to the\n  formula\n  ρ−1(!)-A⅋B. Both S2\n  and S3 are accessible\n  from S1, according to the choice of\n  ρ−1(!): \n  where λA/μ denotes the result of\n  extending λ by assigning context μ to the\n  formula A. S2 is reached after an\n  attack ρ−1(?)-⅋. μ is a dialogical\n  subcontext of ν chosen by ρ−1(!). \n  where λB/π denotes the result of\n  extending λ by assigning context π to the\n  formula B. S2 is reached after an\n  attack ρ−1(?)-L/π, where π is a\n  dialogical subcontext of ν chosen by\n  ρ−1(!). \nThe expression A⅋B is considered used and is\nbracketed iff both states S2\nand S3 have been reached. \nAs already noted, linear negation is essentially the usual dialogical\nnegation, i.e., a role switch, that we noted using a priming on\nρ. There is no contextual change. \n  Particle rule for linear negation. \n  Let S1 =\n  〈ρ, σ, ρ−1(!)-¬A, λφ/ν〉,\n  where λφ/ν assigns context ν to the\n  formula\n  ρ−1(!)-¬A. S2\n  is accessible from S1 iff: \n  The expression ¬A is considered used and is bracketed\n  iff state S2 has been reached. \nLinear implication is defined as ¬A⅋B, which makes\nit a multiplicative connective. If one insists on giving it a particle\nrule, then it will be as follows. \n  Particle rule for linear implication. \n  Let S1 =\n  〈ρ, σ, ρ−1(!)-A⊸B, λφ/ν〉,\n  where λφ/ν assigns context ν to the\n  formula\n  ρ−1(!)-A⊸B.  S2\n  is accessible from S1 iff: \n  where λA/μ denotes the result of\n  extending λ by assigning context μ to the\n  formula A and μ is a dialogical subcontext of ν\n  chosen by ρ−1(!). The game may then proceed,\n  according to the choice of ρ−1(!), according to\n  the relevant particle rule for the formula A, or to the\n  following state of the game: \n  where λB/π denotes the result of\n  extending λ by assigning context π to the\n  formula B, where π is a dialogical subcontext of ν\n  chosen by ρ−1(!). \n  The expression A⊸B is considered used and\n  is bracketed iff both states S2\n  and S3 have been reached. \nFor a discussion of paraconsistent, free, and connexive logics, see the\nsupplementary document Some Dialogical Systems for Non-Classical Logics. \nOne of the strengths of dialogues is the intuitivity of the strategy\nbuilding when writing a proof. The freedom that players enjoy when\nchoosing the next move may obscure the connection between the\nstructural rules of dialogues and the structural rules of\nGentzen-style sequent calculi\n(see Substructural logics). There\nis nevertheless a clear correspondence, that we will make explicit now\nfor the main structural rules. \nExchange: (commutativity of premise combination) a\nplayer can attack any move of the other, and P can\nuse O's concessions, regardless of the order of these\nmoves. Dropping exchange forces players to follow the order of the\nmoves as well as the order of subformulas in conjunctions (i.e., the\nchallenger should attack a conjunction first with\n?L and then with\n?R). Furthermore, a concession\nby O is available for P\niff P already used all the previous concessions. To\nsee why such a restriction is needed, consider a dialogue for the\nformula\n(α→(β→γ))→(β→(α→γ),\nwhich is valid if, and only if, the logic features exchange. \nClearly, P has a winning strategy because he is\nallowed to use O's concessions in any order he\npleases. Were he to follow the order of the concessions, no move would\nbe available to him at 6, and the formula would not be valid. \nContraction: the contraction rule says that when two\noccurrences of a formula are present in a sequent, one of them can be\neliminated. In the dialogues, proceeding from the conclusion down to\nits subformulas, contraction must be seen as corresponding to the\npossibility for the Proponent to use twice a formula conceded by the\nOpponent. Dropping it calls for a marking system in order to keep\ntrack of the concessions that have been used, as described in the\nlinear dialogues. \nWeakening: this structural rule allows the\nintroduction of redundant premises, and has been one of the targets\nof Relevance Logic. In the\ndialogues, weakening corresponds to the fact that not all the\nconcessions of the Opponent have to be actually used by the Proponent\nin the proof (i.e., either attacked or, in the case of an atom, used to\ndefend against an attack). As explained in Section 3.2, \ndialogical systems without weakening should feature a\nsyntactic way of marking the use of a premise. \nIn this example, the concession of α in move 3 is used in move 4\n(as shown by the brackets), but move 2 only uses half of the\nconcession in move 1. The concession of β is\nredundant, P has a winning strategy only if the rules\nallow for weakening (i.e., there is no rule requiring all concessions\nto be used in order to win). \nExpansion: in a sequent calculus where weakening is\nabsent, expansion allows the addition of another occurrence of a\nformula whenever there is already one in a sequent. From a dialogical\npoint of view, expansion amounts to considering that the use of one\noccurrence of a premise uses all the other occurrences. \nGame-theoretical semantics (GTS) is a well-known approach to semantics\nfor natural and formal languages, originating in the work of Jaakko\nHintikka (see Hintikka & Sandu (1997) for a general\npresentation). The fact that GTS and dialogical logic are sisters has\nbeen widely acknowledged. The differences between the original\napproaches have been discussed too: while GTS relates to the study of\ntruth in a model, dialogical logic explores the possibilities of a\ncertain type of proof-theoretical approach to validity. Despite a\nclose relationship between the two approaches, no thorough analysis of\ntheir interaction had been undertaken until Rahman & Tulenheimo\n2006, with the exception of an excellent paper by Esa Saarinen\n(1978). \nIn Rahman & Tulenheimo 2006, this task is carried out\nsystematically. More precisely, Rahman and Tulenheimo have worked out\nfor classical propositional logic and classical first-order logic an\nexact connection between ‘intuitionistic dialogues with\nhypotheses’ and semantic games. Actually, it is not that\nsurprising since the former can be thought of as implementing an\nintuitionistic proof theory supplemented with an axiom schema of the\nexcluded middle. \nThe main result at the interface between dialogical logic and GTS is\nthat the existence of a winning strategy for P in a\ndialogue D(A, H1,\n…, Hn) corresponding to a\nsentence A with a finite number of\nhypotheses Hi expressing those instances\nof the third excluded which are relevant to that sentence, gives rise\nto a family of Eloise’s winning strategies in semantic\ngames G(A, M), one strategy for each\nmodel M; and, conversely, it is shown how to construct a\nwinning strategy for Proponent in the\ndialogue D(A, H1,\n…, Hn) out of Eloise’s winning\nstrategies in games G(A, M). A definition of\nthe notion of ‘relevant instances of the excluded middle’ is given\nbelow, for propositional and first-order logic. In the latter case, a\nvariant of the usual version is preferred. The proofs are constructive\nin the sense that it is explicitly shown how a strategy for one type\nof game is built using a strategy for the other type of game. One\ncorollary of the paper is that each disjunct of the hypotheses of the\ndialogue at stake yields the dialogical version of truth in a\nmodel. Actually the central idea of the paper is based on the notion\nof material dialogues, which furnishes the dialogical version of the\nsatisfiability of a formula relative to a model. \nIn fact, there are two rather straightforward approaches one can\nassume; they give rise to what are known as ‘alethic’ and\n‘material’ dialogues (see e.g., Rahman & Keiff\n2004). As dialogues are designed for dealing with validity, some\nadditional ingredient must be introduced into dialogues in order to\nmake them capable of dealing with material truth. Alethic dialogues\nare simply obtained by relativizing a dialogue to a model. Hence a\npart of the specification of an alethic dialogue in the case of\npropositional logic will be a valuation function, and in the case of\nfirst-order logic a τ-structure for an appropriate vocabulary\nτ. \nBy contrast, the idea behind material dialogues is to avoid having an\nextra component to dialogues (such as a specification of a model);\nthey are meant to do with the resources of dialogues proper (which are\ndesigned for dealing with validity), and the idea is to\n‘approximate’ characterization of truth by adding a\nsufficient amount of additional hypotheses − taken to be initial\nconcessions of Opponent − which would serve to specify a model\nby using the resources of the object language only. \nWhat is a sufficient amount, then? In the case of propositional logic,\nwhen discussing the truth of a formula A, any relevant model\ncan be specified in terms of propositional formulas, namely literals\n(positive or negative atomic formulas). Moreover, it suffices to\nspecify a finite number of such literals. The relevant models are\nidentified by going through all propositional\natoms pi appearing in A (there\nare only finitely many of these atoms) and choosing, for\nall i, either pi or its negation\n¬pi. Those are the instances of the excluded\nmiddle relevant to the material truth of the formula at stake in the\npropositional case. In this way any relevant model—any\ntruth-value distribution—can be specified. \nFor first-order logic, this approach has the obvious downside that in\ngeneral there is no way of capturing a τ-structure in terms of a\nfinite number of first-order sentences. Take for example a\n{P}-structure M with an infinite domain M =\n{di : i < ω}, where P\nis unary. To exhaustively describe M in terms of first-order\nsentences, we need an infinite list 〈li\n: i < ω〉 of literals,\nwhere li := Pci,\nif di ∈ PM,\nand li := ¬Pci,\nif di ∉ >PM. (By\nstipulation, the constant ci stands for the\nelement di.) \nMathematically there is of course nothing problematic about such\ninfinite lists of hypotheses. But one desideratum in designing\ndialogues typically is that it should be possible to think of them as\nhumanly manageable, ideally temporal processes. Such a process cannot\nreally begin by going through an infinity of hypotheses. This is why\nmaterial dialogues with an infinity of hypotheses should be considered\nunsatisfactory. So what can we do? A solution to this dilemma, found\nby Tero Tulenheimo, has been developed in Rahman & Tulenheimo\n(2005): given a vocabulary of one unary relation symbol P, a\nrelevant piece of finite information that the models of classical\nfirst-order logic must satisfy, is expressed by this sentence: \nThat is, whatever the value c of x, the\ninstance Pc ∨ ¬Pc of tertium non\ndatur must hold. What type of question concerning the sentence\n∀x(Px ∨ ¬Px) should we ask in\norder for the answer to identify a (possibly infinite) model? Clearly,\nwe should ask Opponent to choose a Skolem function for this\nsentence. No finite amount of questions of the type\n?-∀ x/c will reveal this\ninformation, if there are infinitely many values for x\navailable. On the other hand, a Skolem function \nexpressly says, for each possible value ci\nof x, which of the disjuncts Opponent considers as being\nsatisfied by ci. This is exactly what it means to\nspecify a model of vocabulary {P} with the domain\n{c0, c1, …}. \nNow for a finite vocabulary τ, the finite information we use for\nspecifying a model will be extracted from the sentences \none for each R ∈ τ of arity n. We introduce a\nnew mode of question, which enables one to ask about a Skolem function\nfor an operator. xhere denotes a finite sequence of\nvariables x1,\n…, xn, and\n∀xstands for ∀x1…∀xn. When asked about a\nsentence of the form\n∀x(Rx ∨ ¬Rx), the\nquestion \nmust be answered by providing a second-order object, namely a Skolem\nfunction \nfor the unique token of the disjunction ∨ appearing in\n∀x(Rx ∨\n¬Rx). (The double ‘?’ indicates that\nthe answer should be a second-order object.) If O\nasserts that f is such a function, P is able\nto read the interpretation of the relation symbol R from the\nfunction f. P can draw all kinds of\ninferences from it, for instance check whether the relation symbol is\nsatisfied by at least one tuple, by checking whether left\n∈ Im(f) or not. \nThe way in which we extract a model from the sentences\n∀x(Rx ∨ ¬Rx) is by\ntaking them as initial concessions of O, and asking\nthe question of ??-∨ with respect to each sentence. The questions\n??-∨ give rise to the following new structural rule: \n  SR-15: Skolem Function Rule.  \n  If O has conceded that f is a Skolem\n  function for ∨ in \n  then O must also, if asked, concede all instances\n  of this second-order concession. That is, for any tuple c\n  interpreting the variables x, he must\n  concede Rc, if f(c) = left,\n  and ¬Rc, if f(c)\n  = right. Accordingly, after O has replied\n  using some f to a question ??-∨, P is\n  always entitled to pose the question \n  for any tuple c, asking O to confirm that\n  indeed he concedes that the tuple c satisfies the\n  disjunct f(c). O has no real choice\n  for his answer: the reply is fully predetermined by his choice\n  of f and the requirement that O must be\n  coherent in his replies. \nFurther investigations on the phenomena of imperfect information in\ndialogues can be found in Rahman & Dégremont (2006).","contact.mail":"laurent.keiff@gmail.com","contact.domain":"gmail.com"}]
