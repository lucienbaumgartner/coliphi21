[{"date.published":"2015-11-13","url":"https://plato.stanford.edu/entries/scientific-method/","author1":"Hanne Andersen","author2":"Brian Hepburn","author1.info":"http://www.ind.ku.dk/ansatte-automatisk-liste/?pure=da/persons/52310","entry":"scientific-method","body.text":"\n\nScience is an enormously successful human enterprise. The study of\nscientific method is the attempt to discern the activities by which\nthat success is achieved. Among the activities often identified as\ncharacteristic of science are systematic observation and\nexperimentation, inductive and deductive reasoning, and the formation\nand testing of hypotheses and theories. How these are\ncarried out in detail can vary greatly, but characteristics like these\nhave been looked to as a way of demarcating scientific activity from\nnon-science, where only enterprises which employ some canonical form\nof scientific method or methods should be considered science (see also\nthe entry on\nscience and pseudo-science).  \nOn the other hand, more recent debate has questioned whether there is\nanything like a fixed toolkit of methods which is common across\nscience and only science.\n\nScientific method should be distinguished from the aims and\nproducts of science, such as knowledge, predictions, or\ncontrol. Methods are the means by which those goals are\nachieved. Scientific method should also be distinguished from\nmeta-methodology, which includes the values and justifications behind\na particular characterization\nof scientific method (i.e., a methodology) —\nvalues such as objectivity, reproducibility, simplicity,\nor past successes. Methodological rules are proposed to govern method\nand it is a meta-methodological question whether methods obeying those\nrules satisfy given values.  Finally, method is distinct, to some degree, from\nthe detailed and contextual practices through which methods are\nimplemented. The latter might range over: specific laboratory\ntechniques; mathematical formalisms or other specialized languages\nused in descriptions and reasoning; technological or other material\nmeans; ways of communicating and sharing results, whether with other\nscientists or with the public at large; or the conventions, habits,\nenforced customs, and institutional controls over how and what science\nis carried out.\n\nWhile it is important to recognize these distinctions, their\nboundaries are fuzzy. Hence, accounts of method cannot be entirely\ndivorced from their methodological and meta-methodological motivations\nor justifications, Moreover, each aspect plays a crucial role in\nidentifying methods. Disputes about method have therefore played out\nat the detail, rule, and meta-rule levels. Changes in beliefs about\nthe certainty or fallibility of scientific knowledge, for instance\n(which is a meta-methodological consideration of what we can hope for\nmethods to deliver), have meant different emphases on deductive and\ninductive reasoning, or on the relative importance attached to\nreasoning over observation (i.e., differences over particular\nmethods.) Beliefs about the role of science in society will affect the\nplace one gives to values in scientific method. \n\nThe issue which has shaped debates over scientific method the most in\nthe last half century is the question of how pluralist do we need to be\nabout method? Unificationists continue to hold out for one method\nessential to science; nihilism is a form of radical pluralism, which\nconsiders the effectiveness of any methodological prescription to be\nso context sensitive as to render it not explanatory on its own. Some\nmiddle degree of pluralism regarding the methods embodied in\nscientific practice seems appropriate. But the details of scientific\npractice vary with time and place, from institution to\ninstitution, across scientists and their subjects of\ninvestigation. How significant are the variations for understanding\nscience and its success? How much can method be abstracted from\npractice? This entry describes some of the attempts to\ncharacterize scientific method or methods, as well as arguments for a more\ncontext-sensitive approach to methods embedded in actual scientific\npractices.\n\nThis entry could have been given the title Scientific Methods and\ngone on to fill volumes, or it could have been extremely short,\nconsisting of a brief summary rejection of the idea that there is any\nsuch thing as a unique Scientific Method at all. Both unhappy\nprospects are due to the fact that scientific activity varies so much\nacross disciplines, times, places, and scientists that any account\nwhich manages to unify it all will either consist of overwhelming\ndescriptive detail, or trivial generalizations. The choice of scope for the present entry is more optimistic,\ntaking a cue from the recent movement in philosophy of science toward\na greater attention to practice: to what scientists actually do. This\n“turn to practice” can be seen as the latest form of\nstudies of methods in science, insofar as it represents an attempt at\nunderstanding scientific activity, but through accounts that are neither\nmeant to be universal and unified, nor singular and narrowly\ndescriptive. To some extent, different scientists at different times\nand places can be said to be using the same method even though, in\npractice, the details are different. Whether the context in which methods are carried out will be\nat all relevant, or to what extent it will be so, will depend largely\non what one takes the aims of science to be and what one’s own\naims are.  For most of the history of scientific methodology the\nassumption has been that the most important output of science is\nknowledge and so the aim of methodology should be to discover those\nmethods by which scientific knowledge is generated. Science was seen to embody the most successful form of reasoning\n(but which form?) to the most certain knowledge claims (but how\ncertain?) on the basis of systematically collected evidence (but what\ncounts as evidence and, in particular, should the evidence of the\nsenses or rather of rational insight take\nprecedence?) Section 2 surveys some of the\nhistory, pointing to two major themes. One theme is seeking the right\nbalance between observation and reasoning (and the attendant forms of\nreasoning which employ them); the other is how certain scientific\nknowledge is or can be. Section 3 turns to 20th\ncentury debates on scientific method. In the second half of the\n20th century the epistemic privilege of science faced\nseveral challenges and many philosophers of science abandoned the\nreconstruction of the logic of scientific method. Views\nchanged significantly regarding which functions of science ought to be\ncaptured and why. For some, the success of science was better\nidentified with social or cultural features. Historical and\nsociological turns in the philosophy of science were made, with a\ndemand that greater attention be paid to the non-epistemic aspects of\nscience, such as sociological, institutional, material, and political\nfactors. Even outside of those movements there was an increased\nspecialization in the philosophy of science, with more and more focus\non specific fields within science. The combined upshot was very few\nphilosophers arguing any longer for a grand unified methodology of\nscience. Sections 3 and 4 surveys the main positions on scientific\nmethod in 20th century philosophy of science, focusing on\nwhere they differ in their preference for confirmation or\nfalsification or for waiving the idea of a special scientific method\naltogether. In recent decades, attention has primarily been paid to scientific\nactivities traditionally falling under the rubric of method, such as\nexperimental design and general laboratory practice, the use of\nstatistics, the construction and use of models and diagrams,\ninterdisciplinary collaboration, and science communication.  Sections\n4–6 attempt to construct a map of the current domains of the\nstudy of methods in science.  As these sections illustrate, the question of method is still\ncentral to the discourse about science. Scientific method remains a\ntopic for education, for science policy, and among scientists. It\narises in the public domain where the demarcation of science is at\nissue. Some philosophers have recently returned, therefore, to the\nquestion of what it is that makes science a unique cultural product.\nThis entry will close with some of these recent attempts at discerning\nand encapsulating the activities by which scientific knowledge is\nachieved. Attempting a history of scientific method compounds the vast scope\nof the topic. This section briefly surveys the background to modern\nmethodological debates. What can be called the classical view goes\nback to antiquity, and represents a point of departure for later\ndivergences.[1] We begin with a point made by Laudan (1968)\nin his historical survey of scientific method: Perhaps the most serious inhibition to the\nemergence of the history of theories of scientific method as a\nrespectable area of study has been the tendency to conflate it with\nthe general history of epistemology, thereby assuming that the\nnarrative categories and classificatory pigeon-holes applied to the\nlatter are also basic to the former. (1968: 5) \nTo see knowledge about the natural world as falling under knowledge more\ngenerally is an understandable conflation.\nHistories of theories of method would naturally\nemploy the same narrative categories and classificatory\npigeon holes.\nAn important theme of the history of epistemology, for example, is\nthe unification of knowledge, a theme reflected in the question\nof the unification of method in science. Those who have identified\ndifferences in kinds of knowledge have often likewise identified\ndifferent methods for achieving that kind of knowledge (see the entry on\nthe unity of science). Related to the diversities of what is known, and how, are\ndifferences over what can be known.  Plato\n(429–347 B.C.E) distinguished the realms of things into the\nvisible and the intelligible. Only the latter, the Forms, could\nbe objects of knowledge. The intelligible truths could be known with\nthe certainty of geometry and deductive reasoning. What could be\nobserved of the material world, however, was by definition imperfect\nand deceptive, not ideal. The Platonic way of knowledge therefore emphasized\nreasoning as a method, downplaying the importance of observation.\nAristotle (384–322 B.C.E) disagreed, locating the Forms in the\nnatural world as the fundamental principles to be discovered through\nthe inquiry into nature. Aristotle is recognized as giving the earliest systematic treatise\non the nature of scientific inquiry in the western tradition, one\nwhich embraced observation and reasoning about the natural world. In\nthe Prior and Posterior Analytics, Aristotle\nreflects first on the aims and then the methods of inquiry into\nnature. A number of features can be found which are still considered\nby most to be essential to science.  For Aristotle, empiricism,\ncareful observation (but passive observation, not controlled\nexperiment), is the starting point, though the aim is not merely recording of\nfacts. Science (epistêmê), for\nAristotle, is a body of properly arranged knowledge or\nlearning—the empirical facts, but also their ordering and\ndisplay are of crucial importance. The aims of discovery, ordering,\nand display of facts partly determine the methods required of\nsuccessful scientific inquiry. Also determinant is the nature of the\nknowledge being sought, and the explanatory causes proper to that kind\nof knowledge (see the discussion of the four causes in the entry on \n Aristotle on causality). In addition to careful observation, then, scientific method\nrequires a logic as a system of reasoning for properly arranging, but\nalso inferring beyond, what is known by observation. Methods of reasoning\nmay include\ninduction, prediction, or analogy, among others. Aristotle’s\nsystem (along with his catalogue of fallacious reasoning) was\ncollected under the title the Organon. This title would be\nechoed in later works on scientific reasoning, such as Novum\nOrganon by Francis Bacon, and Novum Organon Restorum by\nWilliam Whewell (see below). In the Organon reasoning is\ndivided primarily into two forms, a rough division which persists\ninto modern times. The division, known most commonly today as\ndeductive versus inductive method, appears in other eras and\nmethodologies as analysis/​synthesis,\nnon-ampliative/​ampliative, or even\nconfirmation/​verification. The basic idea is that\nthere are two “directions” to proceed in our methods of\ninquiry: one away from what is observed, to the more fundamental,\ngeneral, and encompassing principles; the other, leads from the\nfundamental and general to other possible specific instantiations of\nthose principles. The basic aim and method of inquiry identified here can be seen as\na theme running throughout the next two millennia of reflection on\nthe correct way to seek after knowledge: carefully observe nature and\nthen seek rules or principles which explain or predict its\noperation. The Aristotelian corpus provided the framework for a\ncommentary tradition on scientific method independent of the science\nitself (its physics and cosmos.) During the medieval period, figures\nsuch as Albertus Magnus (1206–1280), Thomas Aquinas\n(1225–1274), Robert Grosseteste (1175–1253), Roger Bacon\n(1214/1220–1292), William of Ockham (1287–1347), Andreas\nVesalius (1514–1546), Giacomo Zabarella (1533–1589) all\nworked to clarify the kind of knowledge which could be obtained by\nobservation and induction, the source of justification of induction,\nand the best rules for its \napplication.[2]\n Many of their contributions we now think\nof as essential to science (see also Laudan 1968). As Aristotle and\nPlato had employed a framework of reasoning either “to the\nforms” or “away from the forms”, medieval thinkers\nemployed directions away from the phenomena or back to the phenomena.\nIn analysis, a phenomena was examined to discover its basic\nexplanatory principles; in synthesis, explanations of a phenomena\nwere constructed from first principles. During the Scientific Revolution these various strands of argument,\nexperiment, and reason were forged into a dominant epistemic\nauthority.  The 16th–18th centuries were\na period of not only dramatic advance in knowledge about the\noperation of the natural world—advances in mechanical, medical,\nbiological, political, economic explanations—but also of\nself-awareness of the revolutionary changes taking place, and intense\nreflection on the source and legitimation of the method by which the\nadvances were made.  The struggle to establish the new authority\nincluded methodological moves. The Book of Nature, according to the\nmetaphor of Galileo Galilei (1564–1642) or Francis Bacon\n(1561–1626), was written in the language of mathematics, of\ngeometry and number. This motivated an emphasis on mathematical\ndescription and mechanical explanation as important aspects of\nscientific method. Through figures such as Henry More and Ralph\nCudworth, a neo-Platonic emphasis on the importance of metaphysical\nreflection on nature behind appearances, particularly regarding the\nspiritual as a complement to the purely mechanical, remained an\nimportant methodological thread of the Scientific Revolution (see\nthe entries on\n Cambridge platonists;\n Boyle;\n Henry More;\n Galileo). In Novum Organum (1620), Bacon was critical of the\nAristotelian method for proceeding too quickly and leaping from\nparticulars to universals, largely as dictated by the syllogistic form\nof reasoning which regularly mixed those two types of propositions.\nBacon aimed at the invention of new arts, of principles, of\ndesignations and directions for works. His method would be grounded in\nmethodical collection of data and observations, coupled with\ncorrection of our senses (and particularly, strictures for the\navoidance of the Idols, as he called them, kinds of systematic errors\nto which naïve observers are prone.) The community of scientists\ncould then climb, by a careful, gradual and unbroken ascent, to\nreliable general claims. Bacon’s method has been criticized as impractical and too\ninflexible for any living, practicing scientist. Whewell would later\ncriticize Bacon in his System of Logic for paying too little\nattention to the practices of scientists. It is hard to find\nconvincing examples of Bacon’s method being put in to practice\nin the history of science, but there are a few who have been held up\nas real examples of 16th century scientific, inductive\nmethod, even if not in the rigid Baconian mold: figures such as\nRobert Boyle (1627–1691) and William Harvey (1578–1657)\n(see the entry on Bacon). It is to Isaac Newton (1642–1727), however, that historians\nof science and methodologists have paid the greatest attention, by\nfar. Given the enormous success of his Principia Mathematica\nand Opticks, this is understandable. The study of\nNewton’s method has had two main thrusts: the implicit method\nof the experiments and reasoning presented in the Opticks, and the\nexplicit methodological rules given as the Rules for Philosophising\n(the Regulae) in Book III of\nthe Principia.[3]\n Newton’s law of gravitation, the\nlinchpin of his new cosmology, broke with explanatory conventions of\nnatural philosophy, first for apparently proposing action at a\ndistance, but more generally for not providing “true”,\nphysical causes. The argument for his System of the World\n(Principia, Book III) was based on phenomena, not reasoned\nfirst principles. This was viewed (mainly on the continent) as\ninsufficient for proper natural philosophy. The Regulae counter this\nobjection, re-defining the aims of natural philosophy by\nre-defining the method natural philosophers should follow. To his list of methodological prescriptions should be added Newton’s famous phrase\n“hypotheses non fingo” (commonly translated as\n“I frame no hypotheses”.) The scientist was not to invent\nsystems but infer explanations from observations, as Bacon had\nadvocated. This would come to be known as inductivism. In the century\nafter Newton, significant clarifications of the Newtonian method were\nmade. Colin Maclaurin (1698–1746), for instance, reconstructed\nthe essential structure of the method as having complementary\nanalysis and synthesis phases, one proceeding away from the phenomena\nin generalization, the other from the general propositions to derive\nexplanations of new phenomena. Denis Diderot (1713–1784) and\neditors of the Encyclopédie did much to consolidate\nand popularize Newtonianism, as did Francesco Algarotti\n(1721–1764). The emphasis was often the same, as much on the\ncharacter of the scientist as on their process, a character which is\nstill commonly assumed. The scientist is humble in the face of\nnature, not beholden to dogma, obeys only his eyes, and follows the\ntruth wherever it leads. It was certainly Voltaire (1694–1778)\nand du Chatelet (1706–1749) who were most influential in\npropagating the latter vision of the scientist and their craft, with\nNewton as hero. Scientific method became a revolutionary force of the\nEnlightenment.  (See also the entries on\nNewton,\nLeibniz,\nDescartes,\nBoyle,\nHume,\nenlightenment,\nas well as Shank 2008 for a historical overview.) Not all 18th century reflections on scientific method\nwere so celebratory. Famous also are George Berkeley’s\n(1685–1753) attack on the mathematics of the new science, as\nwell as the over-emphasis of Newtonians on observation; and David\nHume’s (1711–1776) undermining of the warrant offered for\nscientific claims by inductive justification (see the entries on:\nGeorge Berkeley;\nDavid Hume;\nHume’s Newtonianism and Anti-Newtonianism).\n  Hume’s problem of induction motivated\nImmanuel Kant (1724–1804) to seek new foundations for empirical\nmethod, though as an epistemic reconstruction, not as any set of\npractical guidelines for scientists. Both Hume and Kant influenced the\nmethodological reflections of the next century, such as the debate\nbetween Mill and Whewell over the certainty of inductive inferences in\nscience. The debate between John Stuart Mill (1806–1873) and William\nWhewell (1794–1866) has become the canonical methodological\ndebate of the 19th century. Although often characterized\nas a debate between inductivism and hypothetico-deductivism, the role\nof the two methods on each side is actually more complex. On the\nhypothetico-deductive account, scientists work to come up with\nhypotheses from which true observational consequences can be\ndeduced—hence, hypothetico-deductive. Because Whewell\nemphasizes both hypotheses and deduction in his account of method, he\ncan be seen as a convenient foil to the inductivism of Mill. However,\nequally if not more important to Whewell’s portrayal of\nscientific method is what he calls the “fundamental\nantithesis”. Knowledge is a product of the objective (what we\nsee in the world around us) and subjective (the contributions of our\nmind to how we perceive and understand what we experience, which he\ncalled the Fundamental Ideas). Both elements are essential according\nto Whewell, and he was therefore critical of Kant for too much focus\non the subjective, and John Locke (1632–1704) and Mill for too\nmuch focus on the senses. An interesting aspect of Whewell’s\nfundamental ideas is that they can be discipline relative. An idea\ncan be fundamental even if it is necessary for knowledge only within\na given scientific discipline (e.g., chemical affinity for\nchemistry). (This distinguishes fundamental ideas from the forms and\ncategories of intuition of Kant. See\nWhewell entry.) Clarifying fundamental ideas is therefore an essential part of\nscientific method and scientific progress. Whewell called this process\n“Discoverer’s Induction”. It was induction,\nfollowing Bacon or Newton, but Whewell sought to revive Bacon’s\naccount by emphasising the role of ideas in the clear and careful\nformulation of inductive hypotheses.  Whewell’s induction is not\nmerely the collecting of objective facts.  The subjective plays a role\nthrough what Whewell calls the Colligation of Facts, a creative act of\nthe scientist, the invention of a theory. A theory is then confirmed\nby testing, where more facts are brought under the theory, called the\nConsilience of Inductions. Whewell felt that this was the method by\nwhich the true laws of nature could be discovered: clarification of\nfundamental concepts, clever invention of explanations, and careful\ntesting. Mill, in his critique of Whewell, and others who have cast\nWhewell as a fore-runner of the hypothetico-deductivist view, seem to\nhave under-estimated the importance of this discovery phase in\nWhewell’s understanding of method (Snyder 1997a,b,\n1999). Down-playing the discovery phase would come to characterize\nmethodology of the early 20th century\n(see section 3). Mill, in his System of Logic, puts forward instead a\nnarrower view of induction as the essence of scientific method. For\nMill, induction is the search first for regularities among\nevents. Among those regularities, some will continue to hold for\nfurther observations, eventually gaining the status of laws. One can\nalso look for regularities among the laws discovered in one domain,\ni.e., for a law of laws. Which “law law” will hold is time\nand discipline dependent and should be held open to revision. One\nexample is the Law of Universal Causation, and Mill put forward\nspecific methods for identifying causes—now commonly known as\nMill’s methods. These five methods look for circumstances which\nare common among the phenomena of interest, those which are absent\nwhen the phenomena are, or those for which both vary\ntogether. Mill’s methods are still seen as capturing basic\nintuitions about experimental methods for finding the relevant\nexplanatory factors (System of Logic (1843), see\nMill entry). The methods advocated by Whewell and Mill, in the end,\n look similar. Both involve induction and generalization to covering\n laws. They differ dramatically, however, with respect to the\n necessity of the knowledge arrived at; that is, at the\n meta-methodological level (see the entries on\nWhewell and \nMill entries). The quantum and relativistic revolutions in physics in the early\n20th century had a profound effect on methodology. The\nconceptual foundations of both of these physical theories were taken\nto show the defeasibility of even the most seemingly secure\ncommonsense intuitions about space, time and physical\nbodies. Certainty of knowledge about the natural world was therefore\nrecognized as unattainable, and instead a renewed empiricism was\nsought, which rendered science fallible but at the same time\nrationally justified. In support of this, analysis of the reasoning of scientists emerged\naccording to which the aspects of scientific method which were of\nprimary importance were\nthe means of testing and confirming of theories.\nA distinction in\nmethodology was made between the contexts of discovery and of\njustification.\nThe distinction could be used as a wedge between, on the one hand the\nparticularities of where and how theories or hypotheses are arrived at\nand, on the other, the underlying reasoning scientists use (whether or\nnot they are aware of it) when assessing theories and judging their\nadequacy on the basis of the available evidence. By and large, for\nmost of the 20th century, philosophy of science focused on\nthe second context, although philosophers differed on whether to focus\non confirmation or refutation as well as on the many details of how\nconfirmation or refutation could or could not be brought about. By the\nmid-20th century these attempts at defining the method of\njustification and the context distinction itself came under pressure.\nDuring the same period, philosophy of science developed rapidly, and\nfrom section 4 this entry will\ntherefore shift from a primarily historical treatment of the\nscientific method towards a primarily thematic one. Advances in logic and probability held out promise of the\npossibility of elaborate reconstructions of scientific theories and\nempirical methods. The best example of this is Rudolf\nCarnap’s The Logical Structure of the World (1928)\nHere, Carnap attempted to show that a scientific theory could be\nunderstood as a formal axiomatic system—that is, a\nlogic. Insofar as that system referred to the world, it did so\nbecause some of its basic sentences could be understood in terms of\nobservations or operations which one could perform to test them. The\nrest of the theoretical system, including sentences using theoretical\nor unobservable terms (like electron or force) would then either be\nmeaningful because they could be reduced to observations, or they had\npurely logical meanings (called analytic, like mathematical\nidentities). This has been referred to as the verifiability criterion\nof meaning. According to the criterion, any statement not either\nanalytic or verifiable was strictly meaningless. Although the view\nwas endorsed by Carnap in 1928, he would later come to see it as too\nrestrictive (Carnap 1956).  Another familiar version of this idea\nis operationalism of Percy William Bridgman. In The Logic of\nModern Physics (1927) Bridgman asserted that every physical\nconcept could be defined in terms of the operations one would perform\nto verify the application of that concept. Making good on the\noperationalisation of a concept even as simple as length, however,\ncan easily become enormously complex (for measuring very small\nlengths, for instance) or impractical (measuring large distances like\nlight years.)  Carl Hempel’s (1950, 1951) criticisms of the verifiability\ncriterion of meaning had enormous influence. He pointed out that\nuniversal generalizations, such as most scientific laws, were not\nstrictly meaningful on the criterion. Verifiability and\noperationalism both seemed too restrictive to capture standard\nscientific aims and practice. And the tenuous connection between\nthese reconstructions and actual scientific practice was criticized\nin another way. In both approaches, what are scientific methods are\ninstead recast in methodological roles. Measurements, for example,\nwere looked to as ways of giving meanings to terms. The aim of the\nphilosopher of science was not to understand the methods per\nse, but to use them to reconstruct theories, their meanings, and\ntheir relation to the world. When scientists perform these\noperations, however, they will not report that they are doing them to\ngive meaning to terms in a formal axiomatic system. This disconnect\nbetween methodology and the details of actual scientific practice\nwould seem to violate the empiricism the Logical Positivists, or\nBridgman, were committed to. The view that methodology should\ncorrespond to practice (to some extent) has been called historicism,\nor intuitionism. We turn to these criticisms and responses\nin section\n3.4.[4] Positivism also had to contend with the recognition that a purely\ninductivist approach, along the lines of Bacon-Newton-Mill, was\nuntenable. There was no pure observation, for starters. All\nobservation was theory laden. Theory is required to make any\nobservation, therefore not all theory can be derived from observation\nalone. (See also the entry on\ntheory and observation in science).  \nEven granting an observational basis, Hume had already pointed out\nthat one could not\nargue for inductive conclusions without begging the question by\npresuming the success of the inductive method. Likewise,\npositivist attempts at analyzing how a generalization can be confirmed\nby observations of its instances were subject to a number of\ncriticisms. In his riddle of induction, Goodman (1965) pointed out\nthat for a set of observations, there will be multiple hypotheses that\nare equally supported. For example, the observation that all emeralds\nexamined before today were green would support equally the two\ngeneralization ‘all emeralds are green’ and ‘all\nemeralds are grue’ where ‘x is grue’ iff\neither x has been examined before today and is green\nor x has not been examined before today and is blue. Goodman\nsuggested that one could distinguish between generalizations that were\nsupported by their instances and those that were not by comparing the\nentrenchment of their predicates—that is, the degree to which\nthey have formed part of generalizations that have successfully been\nprojected to account for new instances. In this way ‘all\nemeralds are green’ could be distinguished as more entrenched\nthan ‘all emeralds are grue’. In the ‘Raven\nParadox’, Hempel (1965) pointed out that if an observation\nconfirms a given hypothesis, it also confirms all other hypotheses\nthat are logically equivalent to it. For example, the generalization\n‘all ravens are black’ is logically equivalent to the\ngeneralization ‘all non-black objects are non-ravens’, and\nthe observation of a black raven, a red herring and a white shoe would\ntherefore all confirm the hypothesis that ravens are black. Many find\nthis paradoxical, but Hempel maintained that our intuition is based on\na tacit appeal to background knowledge on the prevalence of ravens and\nnon-ravens that prompt us to give more weight to evidence of ravens\nbeing black than to evidence of non-black items being non-ravens. (for\nmore on these points of criticism as well as how they have been met,\nsee the entries on\nconfirmation and\nthe problem of induction). \nWe shall return to more recent attempts at explaining how observations\ncan serve to confirm a scientific theory\nin section 4 below. The standard starting point for a non-inductive analysis of the\nlogic of confirmation is known as the Hypothetico-Deductive (H-D)\nmethod.  \nIn its simplest form, the idea is that a theory, or more specifically\na sentence of that theory which expresses some hypothesis, is\nconfirmed by its true consequences. As noted\nin section 2, this method had been\nadvanced by Whewell in the 19th century, as well as Nicod\n(1924) and others in the 20th century. Often,\nHempel’s (1966) description of the H-D method illustrated by the\ncase of Semmelweiss’ inferential procedures in establishing the\ncause of childbed fever has been presented as a key account of H-D as\nwell as a foil for criticism of the H-D account of confirmation (see,\nfor example, Lipton’s (2004) discussion of inference to the best\nexplanation; also the entry on\nconfirmation).\nHempel described Semmelsweiss’ procedure as\nexamining various hypotheses that would answer the question about the\ncause of childbed fever. Some hypotheses conflicted with observable\nfacts and could be rejected as false immediately. Others needed to be\ntested experimentally by deducing which observable events should\nfollow if the hypothesis were true (what Hempel called the test\nimplications of the hypothesis), then conducting an experiment and\nobserving whether or not the test implications occurred. If the\nexperiment showed the test implication to be false, the hypothesis\ncould be rejected. On the other hand, if the experiment showed the\ntest implications to be true, this did not prove the hypothesis\ntrue. Although the confirmation of a test implication does not verify\na hypothesis, Hempel did allow that “it provides at least some\nsupport, some corroboration or confirmation for it” (Hempel\n1966: 8). The degree of this support then depends on the quantity,\nvariety and precision of the supporting evidence. Another approach that took off from the difficulties with inductive\ninference was\nKarl Popper’s \ncritical rationalism or falsificationism (Popper 1959,\n1963). Falsification is deductive and similar to H-D in that it\ninvolves scientists deducing observational consequences from the\nhypothesis under test. For Popper, however, the important point was\nnot whatever confirmation successful prediction offered to the\nhypotheses but rather the logical asymmetry between such\nconfirmations, which require an inductive inference, versus\nfalsification, which can be based on a deductive inference. This\nsimple opposition was later questioned, by Lakatos, among others.\n(See the entry on\nhistoricist theories of scientific rationality.) Popper stressed that, regardless of the amount of confirming\nevidence, we can never be certain that a hypothesis is true without\ncommitting the fallacy of affirming the consequent. Instead, Popper\nintroduced the notion of corroboration as a measure for how well a\ntheory or hypothesis has survived previous testing—but without\nimplying that this is also a measure for the probability that it is\ntrue. Popper was also motivated by his doubts about the scientific status\nof theories like the Marxist theory of history or psycho-analysis,\nand so wanted to draw a line of demarcation between science and\npseudo-science.  Popper saw this as an importantly different\ndistinction than demarcating science from metaphysics. The latter\ndemarcation was the primary\nconcern of many logical empiricists. Popper used the idea of\nfalsification to draw a line instead between pseudo and proper science.\nScience was science because it\nsubjected its theories to rigorous tests which offered a high\nprobability of failing and thus refuting the theory. The aim was not,\nin this way, to verify a theory. This could be done all too easily,\neven in cases where observations were at first inconsistent with the\ndeduced consequences of the theory, for example by introducing\nauxiliary hypotheses designed explicitly to save the theory,\nso-called ad hoc modifications. This was what he saw done in\npseudo-science where the theories appeared to be able to explain\nanything that happened within the field to which they applied.  In\ncontrast, science is risky; if observations showed the predictions\nfrom a theory to be absent, the theory would be refuted. Hence,\nscientific hypotheses must be falsifiable. Not only must there exist\nsome possible observation statement which could falsify the\nhypothesis or theory, were it observed, (Popper called these the\nhypothesis’ potential falsifiers) it is crucial to the\nPopperian scientific method that such falsifications be sincerely\nattempted on a regular basis. The more potential falsifiers of a hypothesis, the more falsifiable\nit would be, and the more the hypothesis claimed. Conversely,\nhypotheses without falsifiers claimed very little or nothing at all.\nOriginally, Popper thought that this meant the introduction of ad\nhoc hypotheses only to save a theory should not be countenanced\nas good scientific method. These would undermine the falsifiabililty\nof a theory. However, Popper later came to recognize that the\nintroduction of modifications (immunizations, he called them) was\noften an important part of scientific development. Responding to\nsurprising or apparently falsifying observations often generated\nimportant new scientific insights. Popper’s own example was the\nobserved motion of Uranus which originally did not agree with\nNewtonian predictions, but the ad hoc hypothesis of an outer\nplanet explained the disagreement and led to further falsifiable\npredictions. Popper sought to reconcile the view by blurring the\ndistinction between falsifiable and not falsifiable, and speaking\ninstead of degrees of testability (Popper 1985: 41f.). From the 1960s on, sustained meta-methodological criticism emerged\nthat drove the philosophical focus away from scientific method.\nSomething brief about those criticisms must be said here, but\nrecommendations for further reading can be found at the end of the\nentry.  Thomas Kuhn’s The Structure of Scientific\nRevolutions (1962) begins with a well-known shot across the bow\nfor philosophers of science: History, if viewed as a repository for more than\nanecdote or chronology, could produce a decisive transformation in the\nimage of science by which we are now possessed. (1962: 1) The kind of image Kuhn wanted to transform was the\na-historical, rational reconstruction sought by many of the Logical\nPositivists, though Carnap and other positivists were actually quite sympathetic\nto Kuhn’s views. (See the entry on the\nVienna Circle).  \nKuhn shares with other of his contemporaries, such as Feyerabend and\nLakatos, a commitment to a more empirical approach to philosophy of\nscience. Namely, the history of science provides important data,\nand necessary checks, for philosophy of science, including any theory\nof scientific method. An examination of the history of science reveals, according to\nKuhn, that scientific development occurs in alternating phases. During\nnormal science,\nthe members of the scientific community adhere to\nthe paradigm in place.\nTheir commitment to the paradigm means a\ncommitment to the puzzles to be solved and the acceptable ways of\nsolving them. Confidence in the paradigm remains so long as steady\nprogress is made in solving the shared puzzles. Method in this normal\nphase operates within a disciplinary matrix (Kuhn’s later\nconcept of a paradigm) which includes standards for problem solving,\nas well as defines the range of problems the method should be applied\nto.  An important part of a disciplinary matrix is the set of values\nwhich provide the norms and aims for scientific method. The main\nvalues that Kuhn identifies are prediction, problem solving,\nsimplicity, consistency, and plausibility. An important by-product of normal science, however, is the\naccumulation of puzzles which cannot be solved utilizing the resources\nof the current paradigm. Once the accumulation of these anomalies has\nreached some critical mass, it can trigger a communal shift to a new\nparadigm and a new phase of normal science. Importantly, the values\nthat provide the norms and aims for scientific method may have\ntransformed in the meantime. Method may therefore be relative to\ndiscipline, time or place  Feyerabend also identified the aims of science as progress, but\nargued that any methodological prescription would only stifle that\nprogress (Feyerabend 1988). His arguments are grounded in re-examining\naccepted “myths” about the history of science. Heroes of\nscience, like Galileo, are shown to be just as reliant on rhetoric and\npersuasion as they are on reason and demonstration. Others, like\nAristotle, are shown to be far more reasonable and far-reaching in\ntheir outlooks then they are given credit for. As a consequence, the\nonly rule that could provide what he took to be sufficient freedom was\nthe vacuous “anything goes”. More generally, even the\nmethodological restriction that science is the best way to pursue\nknowledge, and to increase knowledge, is too restrictive. Feyerabend\nsuggested instead that science might, in fact, be a threat to a free\nsociety, because it and its myth had become so dominant (Feyerabend\n1978). An even more fundamental kind of criticism was offered by several\nsociologists of science from the 1970s onwards who dismissed what they\nsaw as a false distinction between philosophical accounts of the\nrational development of science and sociological accounts of the\nirrational mistakes. Instead, they adhered to a symmetry thesis on\nwhich any causal explanation of how scientific knowledge is\nestablished needs to be symmetrical in explaining truth and falsity,\nrationality and irrationality, success and mistakes by the same causal\nfactors (see, e.g., Barnes and Bloor 1982, Bloor 1991). Movements in\nthe Sociology of Science, like the Strong Programme, or in the social\ndimensions and causes of knowledge more generally\nled to extended and close examination of detailed case studies in\ncontemporary science and its history.\n(See the entries on\nthe social dimensions of scientific knowledge\n and\nsocial epistemology.)\nWell-known examinations by\nLatour and Woolgar (1979/1986), Knorr-Cetina (1981), Pickering (1984),\nShapin and Schaffer (1985) seemed to bear out that it was social\nideologies (on a macro-scale) or individual interactions and\ncircumstances (on a micro-scale) which were the primary causal factors\nin determining which beliefs gained the status of scientific\nknowledge.  As they saw it, in other words, explanatory appeals to\nscientific method were not empirically well grounded. By the close of the 20th century the search by\nphilosophers for the scientific method was flagging. Nola and Sankey\n(2000b) could introduce their volume on method by remarking that\n“For some, the whole idea of a theory of scientific method is\nyester-year’s debate …”. Despite the many difficulties that philosophers encountered in\ntrying to providing a clear methodology of conformation (or\nrefutation), still important progress has been made on understanding\nhow observation can provide evidence for a given theory. Work in\nstatistics has been crucial for understanding how theories can be\ntested empirically, and in recent decades a huge literature has\ndeveloped that attempts to recast confirmation in Bayesian terms. Here\nthese developments can be covered only briefly, and we refer to the\nentry on\nconfirmation for further details and references. Statistics has come to play an increasingly important role in the\nmethodology of the experimental sciences from the 19th\ncentury onwards. At that time, statistics and probability theory took\non a methodological role as an analysis of inductive inference, and\nattempts to ground the rationality of induction in the axioms of\nprobability theory have continued throughout the 20th\ncentury and in to the present. Developments in the theory of\nstatistics itself, meanwhile, have had a direct and immense influence\non the experimental method, including methods for measuring the\nuncertainty of observations such as the Method of Least Squares\ndeveloped by Legendre and Gauss in the early 19th century,\ncriteria for the rejection of outliers proposed by Peirce by the\nmid-19th century, and the significance tests developed by\nGosset (a.k.a. “Student”), Fisher, Neyman & Pearson\nand others in the 1920s and 1930s (see, e.g., Swijtink 1987 for a\nbrief historical overview; and also the entry\non C.S. Peirce). These developments within statistics then in turn led to a\nreflective discussion among both statisticians and philosophers of\nscience on how to perceive the process of hypothesis testing: whether\nit was a rigorous statistical inference that could provide a numerical\nexpression of the degree of confidence in the tested hypothesis, or if\nit should be seen as a decision between different courses of actions\nthat also involved a value component. This led to a major controversy\namong Fisher on the one side and Neyman and Pearson on the other (see\nespecially Fisher 1955, Neyman 1956 and Pearson 1955, and for analyses\nof the controversy, e.g., Howie 2002, Marks 2000, Lenhard 2006). On\nFisher’s view, hypothesis testing was a methodology for when to\naccept or reject a statistical hypothesis, namely that a hypothesis\nshould be rejected by evidence if this evidence would be unlikely\nrelative to other possible outcomes, given the hypothesis were\ntrue. In contrast, on Neyman and Pearson’s view, the consequence\nof error also had to play a role when deciding between\nhypotheses. Introducing the distinction between the error of rejecting\na true hypothesis (type I error) and accepting a false hypothesis\n(type II error), they argued that it depends on the consequences of\nthe error to decide whether it is more important to avoid rejecting a\ntrue hypothesis or accepting a false one. Hence, Fisher aimed for a\ntheory of inductive inference that enabled a numerical expression of\nconfidence in a hypothesis. To him, the important point was the search\nfor truth, not utility. In contrast, the Neyman-Pearson approach\nprovided a strategy of inductive behaviour for deciding between\ndifferent courses of action. Here, the important point was not whether\na hypothesis was true, but whether one should act as if it was. Similar discussions are found in the philosophical literature. On\nthe one side, Churchman (1948) and Rudner (1953) argued that because\nscientific hypotheses can never be completely verified, a complete\nanalysis of the methods of scientific inference includes ethical\njudgments in which the scientists must decide whether the evidence is\nsufficiently strong or that the probability is sufficiently high to\nwarrant the acceptance of the hypothesis, which again will depend on\nthe importance of making a mistake in accepting or rejecting the\nhypothesis. Others, such as Jeffrey (1956) and Levi (1960) disagreed\nand instead defended a value-neutral view of science on which\nscientists should bracket their attitudes, preferences, temperament,\nand values when assessing the correctness of their inferences. For\nmore details on this value-free ideal in the philosophy of science and\nits historical development, see Douglas (2009) and Howard (2003). In recent decades, philosophical discussions of the evaluation of\nprobabilistic hypotheses by statistical inference have largely focused\non Bayesianism that understands probability as a measure of a\nperson’s degree of belief in an event, given the available\ninformation, and frequentism that instead understands probability as a\nlong-run frequency of a repeatable event. Hence, for Bayesians\nprobabilities refer to a state of knowledge, whereas for frequentists\nprobabilities refer to frequencies of events (see, e.g., Sober 2008,\nchapter 1 for a detailed introduction to Bayesianism and frequentism\nas well as to likelihoodism). Bayesianism aims at providing a\nquantifiable, algorithmic representation of belief revision, where\nbelief revision is a function of prior beliefs (i.e., background\nknowledge) and incoming evidence. Bayesianism employs a rule based on\nBayes’ theorem, a theorem of the probability calculus which\nrelates conditional probabilities. The probability that a particular\nhypothesis is true is interpreted as a degree of belief, or credence,\nof the scientist. There will also be a probability and a degree of\nbelief that a hypothesis will be true conditional on a piece of\nevidence (an observation, say) being true. Bayesianism proscribes that\nit is rational for the scientist to update their belief in the\nhypothesis to that conditional probability should it turn out that the\nevidence is, in fact, observed. Originating in the work of Neyman and\nPerson, frequentism aims at providing the tools for reducing long-run\nerror rates, such as the error-statistical approach developed by Mayo\n(1996) that focuses on how experimenters can avoid both type I and\ntype II errors by building up a repertoire of procedures that detect\nerrors if and only if they are present. Both Bayesianism and\nfrequentism have developed over time, they are interpreted in\ndifferent ways by its various proponents, and their relations to\nprevious criticism to attempts at defining scientific method are seen\ndifferently by proponents and critics. The literature, surveys,\nreviews and criticism in this area are vast and the reader is referred\nto the entries on\nBayesian epistemology and\nconfirmation. Attention to scientific practice, as we have seen, is not itself\nnew. However, the turn to practice in the philosophy of science of\nlate can be seen as a correction to the pessimism with respect to\nmethod in philosophy of science in later parts of the 20th\ncentury, and as an attempted reconciliation between sociological and\nrationalist explanations of scientific knowledge. Much of this work\nsees method as detailed and context specific problem-solving\nprocedures, and methodological analyses to be at the same time\ndescriptive, critical and advisory (see Nickles 1987 for an exposition\nof this view).  The following section contains a survey of some of the\npractice focuses. In this section we turn fully to topics rather than\nchronology. A problem with the distinction between the contexts of discovery\nand justification that figured so prominently in philosophy of science\nin the first half of the 20th century\n(see section 2) is that no such\ndistinction can be clearly seen in scientific activity (see Arabatzis\n2006). Thus, in recent decades, it has been recognized that study of\nconceptual innovation and change should not be confined to psychology\nand sociology of science, but are also important aspects of scientific\npractice which philosophy of science should address (see also the  entry on\nscientific discovery). \nLooking for the practices that drive conceptual innovation has led\nphilosophers to examine both the reasoning practices of scientists and\nthe wide realm of experimental practices that are not directed\nnarrowly at testing hypotheses, that is, exploratory\nexperimentation. Examining the reasoning practices of historical and contemporary\nscientists, Nersessian (2008) has argued that new scientific concepts\nare constructed as solutions to specific problems by systematic\nreasoning, and that of analogy, visual representation and\nthought-experimentation are among the important reasoning practices\nemployed. These ubiquitous forms of reasoning are reliable—but\nalso fallible—methods of conceptual development and change. On\nher account, model-based reasoning consists of cycles of construction,\nsimulation, evaluation and adaption of models that serve as interim\ninterpretations of the target problem to be solved. Often, this\nprocess will lead to modifications or extensions, and a new cycle of\nsimulation and evaluation. However, Nersessian also emphasizes that creative model-based reasoning cannot be applied\nas a simple recipe, is not always productive of solutions, and even\nits most exemplary usages can lead to incorrect solutions. (Nersessian\n2008: 11) Thus, while on the one hand she agrees with many previous\nphilosophers that there is no logic of discovery, discoveries can derive\nfrom reasoned processes, such that a large and integral part of\nscientific practice is the creation of concepts through which to\ncomprehend, structure, and communicate about physical phenomena\n…. (Nersessian 1987: 11) Similarly, work on heuristics for discovery and\ntheory construction by scholars such as Darden (1991) and Bechtel\n& Richardson (1993) present science as problem solving and\ninvestigate scientific problem solving as a special case of\nproblem-solving in general. Drawing largely on cases from the\nbiological sciences, much of their focus has been on reasoning\nstrategies for the generation, evaluation, and revision of\nmechanistic explanations of complex systems. Addressing another aspect of the context distinction, namely the\ntraditional view that the primary role of experiments is to test\ntheoretical hypotheses according to the H-D model, other philosophers\nof science have argued for additional roles that experiments can play.\nThe notion of exploratory experimentation was introduced to describe\nexperiments driven by the desire to obtain empirical regularities and\nto develop concepts and classifications in which these regularities\ncan be described (Steinle 1997, 2002; Burian 1997; Waters\n2007)). However the difference between theory driven experimentation\nand exploratory experimentation should not be seen as a sharp\ndistinction. Theory driven experiments are not always directed at\ntesting hypothesis, but may also be directed at various kinds of\nfact-gathering, such as determining numerical parameters. Vice\nversa, exploratory experiments are usually informed by theory in\nvarious ways and are therefore not theory-free. Instead, in\nexploratory experiments phenomena are investigated without first\nlimiting the possible outcomes of the experiment on the basis of\nextant theory about the phenomena. In recent years, the development of high throughput instrumentation\nin molecular biology and neighbouring fields has given rise to a\nspecial type of exploratory experimentation that collects and analyses\nvery large amounts of data, and these new ‘omics’\ndisciplines are often said to represent a break with the ideal of\nhypothesis-driven science (Burian 2007; Elliott 2007; Waters 2007;\nO’Malley 2007) and instead described as data-driven research\n(Leonelli 2012; Strasser 2012) or as a special kind of\n“convenience experimentation” in which many experiments\nare done simply because they are extraordinarily convenient to perform\n(Krohs 2012). The field of omics just described is possible because of the\nability of computers to process, in a reasonable amount of time, the\nhuge quantities of data required. Computers allow for more elaborate\nexperimentation (higher speed, better filtering, more variables,\nsophisticated coordination and control), but also, through modelling\nand simulations, might constitute a form of experimentation\nthemselves. Here, too, we can pose a version\nof the general question of method versus practice: does the\npractice of using computers fundamentally change scientific method, or merely\nprovide a more efficient means of implementing standard methods? Because computers can be used to automate measurements,\nquantifications, calculations, and statistical analyses where, for\npractical reasons, these operations cannot be otherwise carried out,\nmany of the steps involved in reaching a conclusion on the basis of an\nexperiment are now made\ninside a “black box”,\nwithout the direct involvement or awareness of a human.\nThis has epistemological implications, regarding what we can know, and\nhow we can know it. To have confidence in the results, computer\nmethods are therefore subjected to tests of verification and\nvalidation. The distinction between verification and validation is easiest to\ncharacterize in the case of computer simulations. In a typical\ncomputer simulation scenario computers are used to numerically\nintegrate differential equations for which no analytic solution is\navailable. The equations are part of the model the scientist uses to\nrepresent a phenomenon or system under investigation. Verifying a\ncomputer simulation means checking that the equations of the model are\nbeing correctly approximated. Validating a simulation means checking\nthat the equations of the model are adequate for the inferences one\nwants to make on the basis of that model. A number of issues related to computer simulations have been\nraised.  The identification of validity and verification as the\ntesting methods has been criticized. Oreskes et al. (1994) raise\nconcerns that “validiation”, because it suggests deductive\ninference, might lead to over-confidence in the results of\nsimulations. The distinction itself is probably too clean, since\nactual practice in the testing of simulations mixes and moves back and\nforth between the two (Weissart 1997; Parker 2008a; Winsberg\n2010). Computer simulations do seem to have a non-inductive character,\ngiven that the principles by which they operate are built in by the\nprogrammers, and any results of the simulation follow from those\nin-built principles in such a way that those results could, in\nprinciple, be deduced from the program code and its inputs. The status\nof simulations as experiments has therefore been examined (Kaufmann\nand Smarr 1993; Humphreys 1995; Hughes 1999; Norton and Suppe\n2001). This literature considers the epistemology of these\nexperiments: what we can learn by simulation, and also the kinds\nof justifications which can be given in applying that knowledge to the\n“real” world. (Mayo 1996; Parker 2008b). As pointed out,\npart of the advantage of computer simulation derives from the fact\nthat huge numbers of calculations can be carried out without requiring\ndirect observation by the experimenter/​simulator. At the same\ntime, many of these calculations are approximations to the\ncalculations which would be performed first-hand in an ideal\nsituation. Both factors introduce uncertainties into the inferences\ndrawn from what is observed in the simulation. For many of the reasons described above, computer simulations do\nnot seem to belong clearly to either the experimental or theoretical\ndomain. Rather, they seem to crucially involve aspects of both. This\nhas led some authors, such as Fox Keller (2003: 200) to argue that we ought to\nconsider computer simulation a “qualtitatively different way of\ndoing science”. The literature in general tends to\nfollow Kaufmann and Smarr (1993) in referring to computer simulation\nas a “third way” for scientific methodology (theoretical\nreasoning and experimental practice are the first two ways.). It\nshould also be noted that the debates around these issues have tended\nto focus on the form of computer simulation typical in the physical\nsciences, where models are based on dynamical equations. Other forms\nof simulation might not have the same problems, or have problems of\ntheir own (see the entry on\ncomputer simulations in science). Despite philosophical disagreements, the idea of the\nscientific method still figures prominently in contemporary discourse\non many different topics, both within science and in society at large.\nOften, reference to scientific method is used in ways that convey\neither the legend of a single, universal method characteristic of all\nscience, or grants to a particular method or set of methods privilege\nas a special ‘gold standard’, often with reference to\nparticular philosophers to vindicate the claims. Discourse on\nscientific method also typically arises when there is a need to\ndistinguish between science and other activities, or for justifying\nthe special status conveyed to science. In these areas, the\nphilosophical attempts at identifying a set of methods characteristic\nfor scientific endeavors are closely related to the philosophy of\nscience’s classical problem of demarcation (see the entry on \nscience and pseudo-science)\nand to the philosophical analysis of the social dimension of\nscientific knowledge and the role of science in democratic\nsociety. One of the settings in which the legend of a single, universal\nscientific method has been particularly strong is science education\n(see, e.g., Bauer 1992; McComas 1996; Wivagg & Allchin\n2002).[5] Often,\n‘the scientific method’ is presented in textbooks and\neducational web pages as a fixed four or five step procedure starting\nfrom observations and description of a phenomenon and progressing\nover formulation of a hypothesis which explains the phenomenon,\ndesigning and conducting experiments to test the hypothesis,\nanalyzing the results, and ending with drawing a conclusion. Such\nreferences to a universal scientific method can be found in\neducational material at all levels of science education (Blachowicz\n2009), and numerous studies have shown that the idea of a general and\nuniversal scientific method often form part of both students’\nand teachers’ conception of science (see, e.g., Aikenhead 1987;\nOsborne et al. 2003). Although occasionally phrased with reference to the H-D method,\nimportant historical roots of the legend in science education of a\nsingle, universal scientific method are the American philosopher and\npsychologist Dewey’s account of inquiry in How We Think\n(1910) and the British mathematician Karl Pearson’s account of\nscience in Grammar of Science (1892). On Dewey’s\naccount, inquiry is divided into the five steps of (i) a felt difficulty, (ii) its location and\ndefinition, (iii) suggestion of a possible solution, (iv) development\nby reasoning of the bearing of the suggestions, (v) further\nobservation and experiment leading to its acceptance or\nrejection. (Dewey 1910: 72) Similarly, on Pearson’s account, scientific\ninvestigations start with measurement of data and observation of\ntheir correction and sequence from which scientific laws can be\ndiscovered with the aid of creative imagination. These laws have to\nbe subject to criticism, and their final acceptance will have equal\nvalidity for “all normally constituted minds”. Both\nDewey’s and Pearson’s accounts should be seen as\ngeneralized abstractions of inquiry and not restricted to the realm\nof science—although both Dewey and Pearson referred to their\nrespective accounts as ‘the scientific method’. Occasionally, scientists make sweeping statements about a simple\nand distinct scientific method, as exemplified by Feynman’s\nsimplified version of a conjectures and refutations method presented,\nfor example, in the last of his 1964 Cornell Messenger\n lectures.[6]\nHowever, just as often scientists have come to the same conclusion as\nrecent philosophy of science that there is not any unique, easily\ndescribed scientific method. For example, the physicist and Nobel\nLaureate Weinberg described in the paper “The Methods of\nScience … And Those By Which We Live” (1995) how The fact that the standards of scientific success\nshift with time does not only make the philosophy of science\ndifficult; it also raises problems for the public understanding of\nscience. We do not have a fixed scientific method to rally around and\ndefend. (1995: 8) Reference to the scientific method has also often been used to\nargue for the scientific nature or special status of a particular\nactivity.  Philosophical positions that argue for a simple and unique\nscientific method as a criterion of demarcation, such as Popperian\nfalsification, have often attracted practitioners who felt that they\nhad a need to defend their domain of practice. For example, references\nto conjectures and refutation as the scientific method are abundant in\nmuch of the literature on complementary and alternative medicine\n(CAM)—alongside the competing position that CAM, as an\nalternative to conventional biomedicine, needs to develop its own\nmethodology different from that of science. Also within mainstream science, reference to the scientific method\nis used in arguments regarding the internal hierarchy of disciplines\nand domains. A frequently seen argument is that research based on the\nH-D method is superior to research based on\ninduction from observations because in deductive inferences the\nconclusion follows necessarily from the premises. (See, e.g.,\nParascandola (1998) for an analysis of how this argument has been made\nto downgrade epidemiology compared to the laboratory sciences.)\nSimilarly, based on an examination of the practices of major funding\ninstitutions such as the National Institutes of Health (NIH), the\nNational Science Foundation (NSF) and the Biomedical Sciences Research\nPractices (BBSRC) in the UK, O’Malley et al. (2009) have argued\nthat funding agencies seem to have a tendency to adhere to the view\nthat the primary activity of science is to test hypotheses, while\ndescriptive and exploratory research is seen as merely preparatory\nactivities that are valuable only insofar as they fuel\nhypothesis-driven research. In some areas of science, scholarly publications are structured in\na way that may convey the impression of a neat and linear process of\ninquiry from stating a question, devising the methods by which to\nanswer it, collecting the data, to drawing a conclusion from the\nanalysis of data. For example, the codified format of publications in\nmost biomedical journals known as the IMRAD format (Introduction,\nMethod, Results, Analysis, Discussion) is explicitly described by the\njournal editors as “not an arbitrary publication format but\nrather a direct reflection of the process of scientific\ndiscovery” (see the so-called “Vancouver\nRecommendations”, ICMJE 2013: 11). However, scientific\npublications do not in general reflect the process by which the\nreported scientific results were produced. For example, under the\nprovocative title “Is the scientific paper a fraud?”,\nMedawar argued that scientific papers generally misrepresent how the\nresults have been produced (Medawar 1963/1996). Similar views have\nbeen advanced by philosophers, historians and sociologists of science\n(Gilbert 1976; Holmes 1987; Knorr-Cetina 1981; Schickore 2008; Suppe\n1998) who have argued that scientists’ experimental practices\nare messy and often do not follow any recognizable\npattern. Publications of research results, they argue, are\nretrospective reconstructions of these activities that often do not\npreserve the temporal order or the logic of these activities, but are\ninstead often constructed in order to screen off potential criticism\n(see Schickore 2008 for a review of this work). Philosophical positions on the scientific method have also made it\ninto the court room, especially in the US where judges have drawn on\nphilosophy of science in deciding when to confer special status to\nscientific expert testimony. A key case is Daubert vs Merrell Dow\nPharmaceuticals (92-102, 509 U.S. 579, 1993). In this case, the\nSupreme Court argued in its 1993 ruling that trial judges must ensure\nthat expert testimony is reliable, and that in doing this the court\nmust look at the expert’s methodology to determine whether the\nproffered evidence is actually scientific knowledge. Further,\nreferring to works of Popper and Hempel the court stated that ordinarily, a key question to be answered in\ndetermining whether a theory or technique is scientific knowledge\n… is whether it can be (and has been) tested.  (Justice\nBlackmun, Daubert v. Merrell Dow Pharmaceuticals; see Other Internet\nResources for a link to the opinion) But as argued by Haack (2005a,b, 2010) and by\nFoster & Hubner (1999), by equating the question of whether a\npiece of testimony is reliable with the question whether it is\nscientific as indicated by a special methodology, the court was\nproducing an inconsistent mixture of Popper’s and\nHempel’s philosophies, and this has later led to considerable\nconfusion in subsequent case rulings that drew on the Daubert case\n(see Haack 2010 for a detailed exposition). The difficulties around identifying the methods of science are also\nreflected in the difficulties of identifying scientific misconduct in\nthe form of improper application of the method or methods of science.\nOne of the first and most influential attempts at defining misconduct\nin science was the US definition from 1989 that defined misconduct as fabrication, falsification, plagiarism, or\nother practices that seriously deviate from those that are commonly\naccepted within the scientific community. (Code of Federal\n Regulations, part 50, subpart A.,\nAugust 8, 1989, italics added) However, the “other practices that\nseriously deviate” clause was heavily criticized because it\ncould be used to suppress creative or novel science. For example, the\nNational Academy of Science stated in their report Responsible\nScience (1992) that it wishes to discourage the possibility that a\nmisconduct complaint could be lodged against scientists based solely\non their use of novel or unorthodox research methods. (NAS: 27) This clause was therefore later removed from the\ndefinition. For an entry into the key philosophical literature on\nconduct in science, see Shamoo & Resnick (2009). The question of the source of the success of science has been at\nthe core of philosophy since the beginning of modern science. If\nviewed as a matter of epistemology more generally, scientific method\nis a part of the entire history of philosophy. Over that time, science\nand whatever methods its practioners may employ have changed dramatically. Today,\nmany philosophers have taken up the banners of pluralism or of\npractice to focus on what are, in effect, fine-grained and\ncontextually limited examinations of scientific method. Others hope to\nshift perspectives in order to provide a renewed general account of\nwhat characterizes the activity we call science. One such perspective has been offered recently by Hoyningen-Huene\n(2008, 2013), who argues from the history of philosophy of science\nthat after three lengthy phases of characterizing science by its\nmethod, we are now in a phase where the belief in the existence of a\npositive scientific method has eroded and what has been left to\ncharacterize science is only its fallibility. First was a phase from\nPlato and Aristotle up until the 17th century where the\nspecificity of scientific knowledge was seen in its absolute certainty\nestablished by proof from evident axioms; next was a phase up to the\nmid-19th century in which the means to establish the\ncertainty of scientific knowledge had been generalized to include\ninductive procedures as well. In the third phase, which lasted until\nthe last decades of the 20th century, it was recognized\nthat empirical knowledge was fallible, but it was still granted a\nspecial status due to its distinctive mode of production. But now in\nthe fourth phase, according to Hoyningen-Huene, historical and\nphilosophical studies have shown how “scientific methods with\nthe characteristics as posited in the second and third phase do not\nexist” (2008: 168) and there is no longer any consensus among\nphilosophers and historians of science about the nature of\nscience. For Hoyningen-Huene, this is too negative a stance, and he\ntherefore urges the question about the nature of science anew. His own\nanswer to this question is that “scientific knowledge differs\nfrom other kinds of knowledge, especially everyday knowledge,\nprimarily by being more systematic” (Hoyningen-Huene 2013:\n14). Systematicity can have several different dimensions: among them are more\nsystematic descriptions, explanations, predictions, defense of\nknowledge claims, epistemic connectedness, ideal of completeness,\nknowledge generation, representation of knowledge and critical\ndiscourse. Hence, what characterizes science is the greater care in\nexcluding possible alternative explanations, the more detailed\nelaboration with respect to data on which predictions are based, the\ngreater care in detecting and eliminating sources of error, the more\narticulate connections to other pieces of knowledge, etc. On this\nposition, what characterizes science is not that the methods employed\nare unique to science, but that the methods are more carefully\nemployed. Another, similar approach has been offered by Haack (2003). She\nsets off, similar to Hoyningen-Huene, from a dissatisfaction with the\nrecent clash between what she calls Old Deferentialism and New\nCynicism. The Old Deferentialist position is that science progressed\ninductively by accumulating true theories confirmed by empirical\nevidence or deductively by testing conjectures against basic\nstatements; while the New Cynics position is that science has no\nepistemic authority and no uniquely rational method and is merely just\npolitics. Haack insists that contrary to the views of the New Cynics,\nthere are objective epistemic standards, and there is something\nepistemologically special about science, even though the Old\nDeferentialists pictured this in a wrong way. Instead, she offers a\nnew Critical Commonsensist account on which standards of good, strong,\nsupportive evidence and well-conducted, honest, thorough and\nimaginative inquiry are not exclusive to the sciences, but the\nstandards by which we judge all inquirers. In this sense, science does\nnot differ in kind from other kinds of inquiry, but it may differ in\nthe degree to which it requires broad and detailed background\nknowledge and a familiarity with a technical vocabulary that only\nspecialists may possess.","contact.mail":"hanne.andersen@ind.ku.dk","contact.domain":"ind.ku.dk"},{"date.published":"2015-11-13","url":"https://plato.stanford.edu/entries/scientific-method/","author1":"Hanne Andersen","author2":"Brian Hepburn","author1.info":"http://www.ind.ku.dk/ansatte-automatisk-liste/?pure=da/persons/52310","entry":"scientific-method","body.text":"\n\nScience is an enormously successful human enterprise. The study of\nscientific method is the attempt to discern the activities by which\nthat success is achieved. Among the activities often identified as\ncharacteristic of science are systematic observation and\nexperimentation, inductive and deductive reasoning, and the formation\nand testing of hypotheses and theories. How these are\ncarried out in detail can vary greatly, but characteristics like these\nhave been looked to as a way of demarcating scientific activity from\nnon-science, where only enterprises which employ some canonical form\nof scientific method or methods should be considered science (see also\nthe entry on\nscience and pseudo-science).  \nOn the other hand, more recent debate has questioned whether there is\nanything like a fixed toolkit of methods which is common across\nscience and only science.\n\nScientific method should be distinguished from the aims and\nproducts of science, such as knowledge, predictions, or\ncontrol. Methods are the means by which those goals are\nachieved. Scientific method should also be distinguished from\nmeta-methodology, which includes the values and justifications behind\na particular characterization\nof scientific method (i.e., a methodology) —\nvalues such as objectivity, reproducibility, simplicity,\nor past successes. Methodological rules are proposed to govern method\nand it is a meta-methodological question whether methods obeying those\nrules satisfy given values.  Finally, method is distinct, to some degree, from\nthe detailed and contextual practices through which methods are\nimplemented. The latter might range over: specific laboratory\ntechniques; mathematical formalisms or other specialized languages\nused in descriptions and reasoning; technological or other material\nmeans; ways of communicating and sharing results, whether with other\nscientists or with the public at large; or the conventions, habits,\nenforced customs, and institutional controls over how and what science\nis carried out.\n\nWhile it is important to recognize these distinctions, their\nboundaries are fuzzy. Hence, accounts of method cannot be entirely\ndivorced from their methodological and meta-methodological motivations\nor justifications, Moreover, each aspect plays a crucial role in\nidentifying methods. Disputes about method have therefore played out\nat the detail, rule, and meta-rule levels. Changes in beliefs about\nthe certainty or fallibility of scientific knowledge, for instance\n(which is a meta-methodological consideration of what we can hope for\nmethods to deliver), have meant different emphases on deductive and\ninductive reasoning, or on the relative importance attached to\nreasoning over observation (i.e., differences over particular\nmethods.) Beliefs about the role of science in society will affect the\nplace one gives to values in scientific method. \n\nThe issue which has shaped debates over scientific method the most in\nthe last half century is the question of how pluralist do we need to be\nabout method? Unificationists continue to hold out for one method\nessential to science; nihilism is a form of radical pluralism, which\nconsiders the effectiveness of any methodological prescription to be\nso context sensitive as to render it not explanatory on its own. Some\nmiddle degree of pluralism regarding the methods embodied in\nscientific practice seems appropriate. But the details of scientific\npractice vary with time and place, from institution to\ninstitution, across scientists and their subjects of\ninvestigation. How significant are the variations for understanding\nscience and its success? How much can method be abstracted from\npractice? This entry describes some of the attempts to\ncharacterize scientific method or methods, as well as arguments for a more\ncontext-sensitive approach to methods embedded in actual scientific\npractices.\n\nThis entry could have been given the title Scientific Methods and\ngone on to fill volumes, or it could have been extremely short,\nconsisting of a brief summary rejection of the idea that there is any\nsuch thing as a unique Scientific Method at all. Both unhappy\nprospects are due to the fact that scientific activity varies so much\nacross disciplines, times, places, and scientists that any account\nwhich manages to unify it all will either consist of overwhelming\ndescriptive detail, or trivial generalizations. The choice of scope for the present entry is more optimistic,\ntaking a cue from the recent movement in philosophy of science toward\na greater attention to practice: to what scientists actually do. This\n“turn to practice” can be seen as the latest form of\nstudies of methods in science, insofar as it represents an attempt at\nunderstanding scientific activity, but through accounts that are neither\nmeant to be universal and unified, nor singular and narrowly\ndescriptive. To some extent, different scientists at different times\nand places can be said to be using the same method even though, in\npractice, the details are different. Whether the context in which methods are carried out will be\nat all relevant, or to what extent it will be so, will depend largely\non what one takes the aims of science to be and what one’s own\naims are.  For most of the history of scientific methodology the\nassumption has been that the most important output of science is\nknowledge and so the aim of methodology should be to discover those\nmethods by which scientific knowledge is generated. Science was seen to embody the most successful form of reasoning\n(but which form?) to the most certain knowledge claims (but how\ncertain?) on the basis of systematically collected evidence (but what\ncounts as evidence and, in particular, should the evidence of the\nsenses or rather of rational insight take\nprecedence?) Section 2 surveys some of the\nhistory, pointing to two major themes. One theme is seeking the right\nbalance between observation and reasoning (and the attendant forms of\nreasoning which employ them); the other is how certain scientific\nknowledge is or can be. Section 3 turns to 20th\ncentury debates on scientific method. In the second half of the\n20th century the epistemic privilege of science faced\nseveral challenges and many philosophers of science abandoned the\nreconstruction of the logic of scientific method. Views\nchanged significantly regarding which functions of science ought to be\ncaptured and why. For some, the success of science was better\nidentified with social or cultural features. Historical and\nsociological turns in the philosophy of science were made, with a\ndemand that greater attention be paid to the non-epistemic aspects of\nscience, such as sociological, institutional, material, and political\nfactors. Even outside of those movements there was an increased\nspecialization in the philosophy of science, with more and more focus\non specific fields within science. The combined upshot was very few\nphilosophers arguing any longer for a grand unified methodology of\nscience. Sections 3 and 4 surveys the main positions on scientific\nmethod in 20th century philosophy of science, focusing on\nwhere they differ in their preference for confirmation or\nfalsification or for waiving the idea of a special scientific method\naltogether. In recent decades, attention has primarily been paid to scientific\nactivities traditionally falling under the rubric of method, such as\nexperimental design and general laboratory practice, the use of\nstatistics, the construction and use of models and diagrams,\ninterdisciplinary collaboration, and science communication.  Sections\n4–6 attempt to construct a map of the current domains of the\nstudy of methods in science.  As these sections illustrate, the question of method is still\ncentral to the discourse about science. Scientific method remains a\ntopic for education, for science policy, and among scientists. It\narises in the public domain where the demarcation of science is at\nissue. Some philosophers have recently returned, therefore, to the\nquestion of what it is that makes science a unique cultural product.\nThis entry will close with some of these recent attempts at discerning\nand encapsulating the activities by which scientific knowledge is\nachieved. Attempting a history of scientific method compounds the vast scope\nof the topic. This section briefly surveys the background to modern\nmethodological debates. What can be called the classical view goes\nback to antiquity, and represents a point of departure for later\ndivergences.[1] We begin with a point made by Laudan (1968)\nin his historical survey of scientific method: Perhaps the most serious inhibition to the\nemergence of the history of theories of scientific method as a\nrespectable area of study has been the tendency to conflate it with\nthe general history of epistemology, thereby assuming that the\nnarrative categories and classificatory pigeon-holes applied to the\nlatter are also basic to the former. (1968: 5) \nTo see knowledge about the natural world as falling under knowledge more\ngenerally is an understandable conflation.\nHistories of theories of method would naturally\nemploy the same narrative categories and classificatory\npigeon holes.\nAn important theme of the history of epistemology, for example, is\nthe unification of knowledge, a theme reflected in the question\nof the unification of method in science. Those who have identified\ndifferences in kinds of knowledge have often likewise identified\ndifferent methods for achieving that kind of knowledge (see the entry on\nthe unity of science). Related to the diversities of what is known, and how, are\ndifferences over what can be known.  Plato\n(429–347 B.C.E) distinguished the realms of things into the\nvisible and the intelligible. Only the latter, the Forms, could\nbe objects of knowledge. The intelligible truths could be known with\nthe certainty of geometry and deductive reasoning. What could be\nobserved of the material world, however, was by definition imperfect\nand deceptive, not ideal. The Platonic way of knowledge therefore emphasized\nreasoning as a method, downplaying the importance of observation.\nAristotle (384–322 B.C.E) disagreed, locating the Forms in the\nnatural world as the fundamental principles to be discovered through\nthe inquiry into nature. Aristotle is recognized as giving the earliest systematic treatise\non the nature of scientific inquiry in the western tradition, one\nwhich embraced observation and reasoning about the natural world. In\nthe Prior and Posterior Analytics, Aristotle\nreflects first on the aims and then the methods of inquiry into\nnature. A number of features can be found which are still considered\nby most to be essential to science.  For Aristotle, empiricism,\ncareful observation (but passive observation, not controlled\nexperiment), is the starting point, though the aim is not merely recording of\nfacts. Science (epistêmê), for\nAristotle, is a body of properly arranged knowledge or\nlearning—the empirical facts, but also their ordering and\ndisplay are of crucial importance. The aims of discovery, ordering,\nand display of facts partly determine the methods required of\nsuccessful scientific inquiry. Also determinant is the nature of the\nknowledge being sought, and the explanatory causes proper to that kind\nof knowledge (see the discussion of the four causes in the entry on \n Aristotle on causality). In addition to careful observation, then, scientific method\nrequires a logic as a system of reasoning for properly arranging, but\nalso inferring beyond, what is known by observation. Methods of reasoning\nmay include\ninduction, prediction, or analogy, among others. Aristotle’s\nsystem (along with his catalogue of fallacious reasoning) was\ncollected under the title the Organon. This title would be\nechoed in later works on scientific reasoning, such as Novum\nOrganon by Francis Bacon, and Novum Organon Restorum by\nWilliam Whewell (see below). In the Organon reasoning is\ndivided primarily into two forms, a rough division which persists\ninto modern times. The division, known most commonly today as\ndeductive versus inductive method, appears in other eras and\nmethodologies as analysis/​synthesis,\nnon-ampliative/​ampliative, or even\nconfirmation/​verification. The basic idea is that\nthere are two “directions” to proceed in our methods of\ninquiry: one away from what is observed, to the more fundamental,\ngeneral, and encompassing principles; the other, leads from the\nfundamental and general to other possible specific instantiations of\nthose principles. The basic aim and method of inquiry identified here can be seen as\na theme running throughout the next two millennia of reflection on\nthe correct way to seek after knowledge: carefully observe nature and\nthen seek rules or principles which explain or predict its\noperation. The Aristotelian corpus provided the framework for a\ncommentary tradition on scientific method independent of the science\nitself (its physics and cosmos.) During the medieval period, figures\nsuch as Albertus Magnus (1206–1280), Thomas Aquinas\n(1225–1274), Robert Grosseteste (1175–1253), Roger Bacon\n(1214/1220–1292), William of Ockham (1287–1347), Andreas\nVesalius (1514–1546), Giacomo Zabarella (1533–1589) all\nworked to clarify the kind of knowledge which could be obtained by\nobservation and induction, the source of justification of induction,\nand the best rules for its \napplication.[2]\n Many of their contributions we now think\nof as essential to science (see also Laudan 1968). As Aristotle and\nPlato had employed a framework of reasoning either “to the\nforms” or “away from the forms”, medieval thinkers\nemployed directions away from the phenomena or back to the phenomena.\nIn analysis, a phenomena was examined to discover its basic\nexplanatory principles; in synthesis, explanations of a phenomena\nwere constructed from first principles. During the Scientific Revolution these various strands of argument,\nexperiment, and reason were forged into a dominant epistemic\nauthority.  The 16th–18th centuries were\na period of not only dramatic advance in knowledge about the\noperation of the natural world—advances in mechanical, medical,\nbiological, political, economic explanations—but also of\nself-awareness of the revolutionary changes taking place, and intense\nreflection on the source and legitimation of the method by which the\nadvances were made.  The struggle to establish the new authority\nincluded methodological moves. The Book of Nature, according to the\nmetaphor of Galileo Galilei (1564–1642) or Francis Bacon\n(1561–1626), was written in the language of mathematics, of\ngeometry and number. This motivated an emphasis on mathematical\ndescription and mechanical explanation as important aspects of\nscientific method. Through figures such as Henry More and Ralph\nCudworth, a neo-Platonic emphasis on the importance of metaphysical\nreflection on nature behind appearances, particularly regarding the\nspiritual as a complement to the purely mechanical, remained an\nimportant methodological thread of the Scientific Revolution (see\nthe entries on\n Cambridge platonists;\n Boyle;\n Henry More;\n Galileo). In Novum Organum (1620), Bacon was critical of the\nAristotelian method for proceeding too quickly and leaping from\nparticulars to universals, largely as dictated by the syllogistic form\nof reasoning which regularly mixed those two types of propositions.\nBacon aimed at the invention of new arts, of principles, of\ndesignations and directions for works. His method would be grounded in\nmethodical collection of data and observations, coupled with\ncorrection of our senses (and particularly, strictures for the\navoidance of the Idols, as he called them, kinds of systematic errors\nto which naïve observers are prone.) The community of scientists\ncould then climb, by a careful, gradual and unbroken ascent, to\nreliable general claims. Bacon’s method has been criticized as impractical and too\ninflexible for any living, practicing scientist. Whewell would later\ncriticize Bacon in his System of Logic for paying too little\nattention to the practices of scientists. It is hard to find\nconvincing examples of Bacon’s method being put in to practice\nin the history of science, but there are a few who have been held up\nas real examples of 16th century scientific, inductive\nmethod, even if not in the rigid Baconian mold: figures such as\nRobert Boyle (1627–1691) and William Harvey (1578–1657)\n(see the entry on Bacon). It is to Isaac Newton (1642–1727), however, that historians\nof science and methodologists have paid the greatest attention, by\nfar. Given the enormous success of his Principia Mathematica\nand Opticks, this is understandable. The study of\nNewton’s method has had two main thrusts: the implicit method\nof the experiments and reasoning presented in the Opticks, and the\nexplicit methodological rules given as the Rules for Philosophising\n(the Regulae) in Book III of\nthe Principia.[3]\n Newton’s law of gravitation, the\nlinchpin of his new cosmology, broke with explanatory conventions of\nnatural philosophy, first for apparently proposing action at a\ndistance, but more generally for not providing “true”,\nphysical causes. The argument for his System of the World\n(Principia, Book III) was based on phenomena, not reasoned\nfirst principles. This was viewed (mainly on the continent) as\ninsufficient for proper natural philosophy. The Regulae counter this\nobjection, re-defining the aims of natural philosophy by\nre-defining the method natural philosophers should follow. To his list of methodological prescriptions should be added Newton’s famous phrase\n“hypotheses non fingo” (commonly translated as\n“I frame no hypotheses”.) The scientist was not to invent\nsystems but infer explanations from observations, as Bacon had\nadvocated. This would come to be known as inductivism. In the century\nafter Newton, significant clarifications of the Newtonian method were\nmade. Colin Maclaurin (1698–1746), for instance, reconstructed\nthe essential structure of the method as having complementary\nanalysis and synthesis phases, one proceeding away from the phenomena\nin generalization, the other from the general propositions to derive\nexplanations of new phenomena. Denis Diderot (1713–1784) and\neditors of the Encyclopédie did much to consolidate\nand popularize Newtonianism, as did Francesco Algarotti\n(1721–1764). The emphasis was often the same, as much on the\ncharacter of the scientist as on their process, a character which is\nstill commonly assumed. The scientist is humble in the face of\nnature, not beholden to dogma, obeys only his eyes, and follows the\ntruth wherever it leads. It was certainly Voltaire (1694–1778)\nand du Chatelet (1706–1749) who were most influential in\npropagating the latter vision of the scientist and their craft, with\nNewton as hero. Scientific method became a revolutionary force of the\nEnlightenment.  (See also the entries on\nNewton,\nLeibniz,\nDescartes,\nBoyle,\nHume,\nenlightenment,\nas well as Shank 2008 for a historical overview.) Not all 18th century reflections on scientific method\nwere so celebratory. Famous also are George Berkeley’s\n(1685–1753) attack on the mathematics of the new science, as\nwell as the over-emphasis of Newtonians on observation; and David\nHume’s (1711–1776) undermining of the warrant offered for\nscientific claims by inductive justification (see the entries on:\nGeorge Berkeley;\nDavid Hume;\nHume’s Newtonianism and Anti-Newtonianism).\n  Hume’s problem of induction motivated\nImmanuel Kant (1724–1804) to seek new foundations for empirical\nmethod, though as an epistemic reconstruction, not as any set of\npractical guidelines for scientists. Both Hume and Kant influenced the\nmethodological reflections of the next century, such as the debate\nbetween Mill and Whewell over the certainty of inductive inferences in\nscience. The debate between John Stuart Mill (1806–1873) and William\nWhewell (1794–1866) has become the canonical methodological\ndebate of the 19th century. Although often characterized\nas a debate between inductivism and hypothetico-deductivism, the role\nof the two methods on each side is actually more complex. On the\nhypothetico-deductive account, scientists work to come up with\nhypotheses from which true observational consequences can be\ndeduced—hence, hypothetico-deductive. Because Whewell\nemphasizes both hypotheses and deduction in his account of method, he\ncan be seen as a convenient foil to the inductivism of Mill. However,\nequally if not more important to Whewell’s portrayal of\nscientific method is what he calls the “fundamental\nantithesis”. Knowledge is a product of the objective (what we\nsee in the world around us) and subjective (the contributions of our\nmind to how we perceive and understand what we experience, which he\ncalled the Fundamental Ideas). Both elements are essential according\nto Whewell, and he was therefore critical of Kant for too much focus\non the subjective, and John Locke (1632–1704) and Mill for too\nmuch focus on the senses. An interesting aspect of Whewell’s\nfundamental ideas is that they can be discipline relative. An idea\ncan be fundamental even if it is necessary for knowledge only within\na given scientific discipline (e.g., chemical affinity for\nchemistry). (This distinguishes fundamental ideas from the forms and\ncategories of intuition of Kant. See\nWhewell entry.) Clarifying fundamental ideas is therefore an essential part of\nscientific method and scientific progress. Whewell called this process\n“Discoverer’s Induction”. It was induction,\nfollowing Bacon or Newton, but Whewell sought to revive Bacon’s\naccount by emphasising the role of ideas in the clear and careful\nformulation of inductive hypotheses.  Whewell’s induction is not\nmerely the collecting of objective facts.  The subjective plays a role\nthrough what Whewell calls the Colligation of Facts, a creative act of\nthe scientist, the invention of a theory. A theory is then confirmed\nby testing, where more facts are brought under the theory, called the\nConsilience of Inductions. Whewell felt that this was the method by\nwhich the true laws of nature could be discovered: clarification of\nfundamental concepts, clever invention of explanations, and careful\ntesting. Mill, in his critique of Whewell, and others who have cast\nWhewell as a fore-runner of the hypothetico-deductivist view, seem to\nhave under-estimated the importance of this discovery phase in\nWhewell’s understanding of method (Snyder 1997a,b,\n1999). Down-playing the discovery phase would come to characterize\nmethodology of the early 20th century\n(see section 3). Mill, in his System of Logic, puts forward instead a\nnarrower view of induction as the essence of scientific method. For\nMill, induction is the search first for regularities among\nevents. Among those regularities, some will continue to hold for\nfurther observations, eventually gaining the status of laws. One can\nalso look for regularities among the laws discovered in one domain,\ni.e., for a law of laws. Which “law law” will hold is time\nand discipline dependent and should be held open to revision. One\nexample is the Law of Universal Causation, and Mill put forward\nspecific methods for identifying causes—now commonly known as\nMill’s methods. These five methods look for circumstances which\nare common among the phenomena of interest, those which are absent\nwhen the phenomena are, or those for which both vary\ntogether. Mill’s methods are still seen as capturing basic\nintuitions about experimental methods for finding the relevant\nexplanatory factors (System of Logic (1843), see\nMill entry). The methods advocated by Whewell and Mill, in the end,\n look similar. Both involve induction and generalization to covering\n laws. They differ dramatically, however, with respect to the\n necessity of the knowledge arrived at; that is, at the\n meta-methodological level (see the entries on\nWhewell and \nMill entries). The quantum and relativistic revolutions in physics in the early\n20th century had a profound effect on methodology. The\nconceptual foundations of both of these physical theories were taken\nto show the defeasibility of even the most seemingly secure\ncommonsense intuitions about space, time and physical\nbodies. Certainty of knowledge about the natural world was therefore\nrecognized as unattainable, and instead a renewed empiricism was\nsought, which rendered science fallible but at the same time\nrationally justified. In support of this, analysis of the reasoning of scientists emerged\naccording to which the aspects of scientific method which were of\nprimary importance were\nthe means of testing and confirming of theories.\nA distinction in\nmethodology was made between the contexts of discovery and of\njustification.\nThe distinction could be used as a wedge between, on the one hand the\nparticularities of where and how theories or hypotheses are arrived at\nand, on the other, the underlying reasoning scientists use (whether or\nnot they are aware of it) when assessing theories and judging their\nadequacy on the basis of the available evidence. By and large, for\nmost of the 20th century, philosophy of science focused on\nthe second context, although philosophers differed on whether to focus\non confirmation or refutation as well as on the many details of how\nconfirmation or refutation could or could not be brought about. By the\nmid-20th century these attempts at defining the method of\njustification and the context distinction itself came under pressure.\nDuring the same period, philosophy of science developed rapidly, and\nfrom section 4 this entry will\ntherefore shift from a primarily historical treatment of the\nscientific method towards a primarily thematic one. Advances in logic and probability held out promise of the\npossibility of elaborate reconstructions of scientific theories and\nempirical methods. The best example of this is Rudolf\nCarnap’s The Logical Structure of the World (1928)\nHere, Carnap attempted to show that a scientific theory could be\nunderstood as a formal axiomatic system—that is, a\nlogic. Insofar as that system referred to the world, it did so\nbecause some of its basic sentences could be understood in terms of\nobservations or operations which one could perform to test them. The\nrest of the theoretical system, including sentences using theoretical\nor unobservable terms (like electron or force) would then either be\nmeaningful because they could be reduced to observations, or they had\npurely logical meanings (called analytic, like mathematical\nidentities). This has been referred to as the verifiability criterion\nof meaning. According to the criterion, any statement not either\nanalytic or verifiable was strictly meaningless. Although the view\nwas endorsed by Carnap in 1928, he would later come to see it as too\nrestrictive (Carnap 1956).  Another familiar version of this idea\nis operationalism of Percy William Bridgman. In The Logic of\nModern Physics (1927) Bridgman asserted that every physical\nconcept could be defined in terms of the operations one would perform\nto verify the application of that concept. Making good on the\noperationalisation of a concept even as simple as length, however,\ncan easily become enormously complex (for measuring very small\nlengths, for instance) or impractical (measuring large distances like\nlight years.)  Carl Hempel’s (1950, 1951) criticisms of the verifiability\ncriterion of meaning had enormous influence. He pointed out that\nuniversal generalizations, such as most scientific laws, were not\nstrictly meaningful on the criterion. Verifiability and\noperationalism both seemed too restrictive to capture standard\nscientific aims and practice. And the tenuous connection between\nthese reconstructions and actual scientific practice was criticized\nin another way. In both approaches, what are scientific methods are\ninstead recast in methodological roles. Measurements, for example,\nwere looked to as ways of giving meanings to terms. The aim of the\nphilosopher of science was not to understand the methods per\nse, but to use them to reconstruct theories, their meanings, and\ntheir relation to the world. When scientists perform these\noperations, however, they will not report that they are doing them to\ngive meaning to terms in a formal axiomatic system. This disconnect\nbetween methodology and the details of actual scientific practice\nwould seem to violate the empiricism the Logical Positivists, or\nBridgman, were committed to. The view that methodology should\ncorrespond to practice (to some extent) has been called historicism,\nor intuitionism. We turn to these criticisms and responses\nin section\n3.4.[4] Positivism also had to contend with the recognition that a purely\ninductivist approach, along the lines of Bacon-Newton-Mill, was\nuntenable. There was no pure observation, for starters. All\nobservation was theory laden. Theory is required to make any\nobservation, therefore not all theory can be derived from observation\nalone. (See also the entry on\ntheory and observation in science).  \nEven granting an observational basis, Hume had already pointed out\nthat one could not\nargue for inductive conclusions without begging the question by\npresuming the success of the inductive method. Likewise,\npositivist attempts at analyzing how a generalization can be confirmed\nby observations of its instances were subject to a number of\ncriticisms. In his riddle of induction, Goodman (1965) pointed out\nthat for a set of observations, there will be multiple hypotheses that\nare equally supported. For example, the observation that all emeralds\nexamined before today were green would support equally the two\ngeneralization ‘all emeralds are green’ and ‘all\nemeralds are grue’ where ‘x is grue’ iff\neither x has been examined before today and is green\nor x has not been examined before today and is blue. Goodman\nsuggested that one could distinguish between generalizations that were\nsupported by their instances and those that were not by comparing the\nentrenchment of their predicates—that is, the degree to which\nthey have formed part of generalizations that have successfully been\nprojected to account for new instances. In this way ‘all\nemeralds are green’ could be distinguished as more entrenched\nthan ‘all emeralds are grue’. In the ‘Raven\nParadox’, Hempel (1965) pointed out that if an observation\nconfirms a given hypothesis, it also confirms all other hypotheses\nthat are logically equivalent to it. For example, the generalization\n‘all ravens are black’ is logically equivalent to the\ngeneralization ‘all non-black objects are non-ravens’, and\nthe observation of a black raven, a red herring and a white shoe would\ntherefore all confirm the hypothesis that ravens are black. Many find\nthis paradoxical, but Hempel maintained that our intuition is based on\na tacit appeal to background knowledge on the prevalence of ravens and\nnon-ravens that prompt us to give more weight to evidence of ravens\nbeing black than to evidence of non-black items being non-ravens. (for\nmore on these points of criticism as well as how they have been met,\nsee the entries on\nconfirmation and\nthe problem of induction). \nWe shall return to more recent attempts at explaining how observations\ncan serve to confirm a scientific theory\nin section 4 below. The standard starting point for a non-inductive analysis of the\nlogic of confirmation is known as the Hypothetico-Deductive (H-D)\nmethod.  \nIn its simplest form, the idea is that a theory, or more specifically\na sentence of that theory which expresses some hypothesis, is\nconfirmed by its true consequences. As noted\nin section 2, this method had been\nadvanced by Whewell in the 19th century, as well as Nicod\n(1924) and others in the 20th century. Often,\nHempel’s (1966) description of the H-D method illustrated by the\ncase of Semmelweiss’ inferential procedures in establishing the\ncause of childbed fever has been presented as a key account of H-D as\nwell as a foil for criticism of the H-D account of confirmation (see,\nfor example, Lipton’s (2004) discussion of inference to the best\nexplanation; also the entry on\nconfirmation).\nHempel described Semmelsweiss’ procedure as\nexamining various hypotheses that would answer the question about the\ncause of childbed fever. Some hypotheses conflicted with observable\nfacts and could be rejected as false immediately. Others needed to be\ntested experimentally by deducing which observable events should\nfollow if the hypothesis were true (what Hempel called the test\nimplications of the hypothesis), then conducting an experiment and\nobserving whether or not the test implications occurred. If the\nexperiment showed the test implication to be false, the hypothesis\ncould be rejected. On the other hand, if the experiment showed the\ntest implications to be true, this did not prove the hypothesis\ntrue. Although the confirmation of a test implication does not verify\na hypothesis, Hempel did allow that “it provides at least some\nsupport, some corroboration or confirmation for it” (Hempel\n1966: 8). The degree of this support then depends on the quantity,\nvariety and precision of the supporting evidence. Another approach that took off from the difficulties with inductive\ninference was\nKarl Popper’s \ncritical rationalism or falsificationism (Popper 1959,\n1963). Falsification is deductive and similar to H-D in that it\ninvolves scientists deducing observational consequences from the\nhypothesis under test. For Popper, however, the important point was\nnot whatever confirmation successful prediction offered to the\nhypotheses but rather the logical asymmetry between such\nconfirmations, which require an inductive inference, versus\nfalsification, which can be based on a deductive inference. This\nsimple opposition was later questioned, by Lakatos, among others.\n(See the entry on\nhistoricist theories of scientific rationality.) Popper stressed that, regardless of the amount of confirming\nevidence, we can never be certain that a hypothesis is true without\ncommitting the fallacy of affirming the consequent. Instead, Popper\nintroduced the notion of corroboration as a measure for how well a\ntheory or hypothesis has survived previous testing—but without\nimplying that this is also a measure for the probability that it is\ntrue. Popper was also motivated by his doubts about the scientific status\nof theories like the Marxist theory of history or psycho-analysis,\nand so wanted to draw a line of demarcation between science and\npseudo-science.  Popper saw this as an importantly different\ndistinction than demarcating science from metaphysics. The latter\ndemarcation was the primary\nconcern of many logical empiricists. Popper used the idea of\nfalsification to draw a line instead between pseudo and proper science.\nScience was science because it\nsubjected its theories to rigorous tests which offered a high\nprobability of failing and thus refuting the theory. The aim was not,\nin this way, to verify a theory. This could be done all too easily,\neven in cases where observations were at first inconsistent with the\ndeduced consequences of the theory, for example by introducing\nauxiliary hypotheses designed explicitly to save the theory,\nso-called ad hoc modifications. This was what he saw done in\npseudo-science where the theories appeared to be able to explain\nanything that happened within the field to which they applied.  In\ncontrast, science is risky; if observations showed the predictions\nfrom a theory to be absent, the theory would be refuted. Hence,\nscientific hypotheses must be falsifiable. Not only must there exist\nsome possible observation statement which could falsify the\nhypothesis or theory, were it observed, (Popper called these the\nhypothesis’ potential falsifiers) it is crucial to the\nPopperian scientific method that such falsifications be sincerely\nattempted on a regular basis. The more potential falsifiers of a hypothesis, the more falsifiable\nit would be, and the more the hypothesis claimed. Conversely,\nhypotheses without falsifiers claimed very little or nothing at all.\nOriginally, Popper thought that this meant the introduction of ad\nhoc hypotheses only to save a theory should not be countenanced\nas good scientific method. These would undermine the falsifiabililty\nof a theory. However, Popper later came to recognize that the\nintroduction of modifications (immunizations, he called them) was\noften an important part of scientific development. Responding to\nsurprising or apparently falsifying observations often generated\nimportant new scientific insights. Popper’s own example was the\nobserved motion of Uranus which originally did not agree with\nNewtonian predictions, but the ad hoc hypothesis of an outer\nplanet explained the disagreement and led to further falsifiable\npredictions. Popper sought to reconcile the view by blurring the\ndistinction between falsifiable and not falsifiable, and speaking\ninstead of degrees of testability (Popper 1985: 41f.). From the 1960s on, sustained meta-methodological criticism emerged\nthat drove the philosophical focus away from scientific method.\nSomething brief about those criticisms must be said here, but\nrecommendations for further reading can be found at the end of the\nentry.  Thomas Kuhn’s The Structure of Scientific\nRevolutions (1962) begins with a well-known shot across the bow\nfor philosophers of science: History, if viewed as a repository for more than\nanecdote or chronology, could produce a decisive transformation in the\nimage of science by which we are now possessed. (1962: 1) The kind of image Kuhn wanted to transform was the\na-historical, rational reconstruction sought by many of the Logical\nPositivists, though Carnap and other positivists were actually quite sympathetic\nto Kuhn’s views. (See the entry on the\nVienna Circle).  \nKuhn shares with other of his contemporaries, such as Feyerabend and\nLakatos, a commitment to a more empirical approach to philosophy of\nscience. Namely, the history of science provides important data,\nand necessary checks, for philosophy of science, including any theory\nof scientific method. An examination of the history of science reveals, according to\nKuhn, that scientific development occurs in alternating phases. During\nnormal science,\nthe members of the scientific community adhere to\nthe paradigm in place.\nTheir commitment to the paradigm means a\ncommitment to the puzzles to be solved and the acceptable ways of\nsolving them. Confidence in the paradigm remains so long as steady\nprogress is made in solving the shared puzzles. Method in this normal\nphase operates within a disciplinary matrix (Kuhn’s later\nconcept of a paradigm) which includes standards for problem solving,\nas well as defines the range of problems the method should be applied\nto.  An important part of a disciplinary matrix is the set of values\nwhich provide the norms and aims for scientific method. The main\nvalues that Kuhn identifies are prediction, problem solving,\nsimplicity, consistency, and plausibility. An important by-product of normal science, however, is the\naccumulation of puzzles which cannot be solved utilizing the resources\nof the current paradigm. Once the accumulation of these anomalies has\nreached some critical mass, it can trigger a communal shift to a new\nparadigm and a new phase of normal science. Importantly, the values\nthat provide the norms and aims for scientific method may have\ntransformed in the meantime. Method may therefore be relative to\ndiscipline, time or place  Feyerabend also identified the aims of science as progress, but\nargued that any methodological prescription would only stifle that\nprogress (Feyerabend 1988). His arguments are grounded in re-examining\naccepted “myths” about the history of science. Heroes of\nscience, like Galileo, are shown to be just as reliant on rhetoric and\npersuasion as they are on reason and demonstration. Others, like\nAristotle, are shown to be far more reasonable and far-reaching in\ntheir outlooks then they are given credit for. As a consequence, the\nonly rule that could provide what he took to be sufficient freedom was\nthe vacuous “anything goes”. More generally, even the\nmethodological restriction that science is the best way to pursue\nknowledge, and to increase knowledge, is too restrictive. Feyerabend\nsuggested instead that science might, in fact, be a threat to a free\nsociety, because it and its myth had become so dominant (Feyerabend\n1978). An even more fundamental kind of criticism was offered by several\nsociologists of science from the 1970s onwards who dismissed what they\nsaw as a false distinction between philosophical accounts of the\nrational development of science and sociological accounts of the\nirrational mistakes. Instead, they adhered to a symmetry thesis on\nwhich any causal explanation of how scientific knowledge is\nestablished needs to be symmetrical in explaining truth and falsity,\nrationality and irrationality, success and mistakes by the same causal\nfactors (see, e.g., Barnes and Bloor 1982, Bloor 1991). Movements in\nthe Sociology of Science, like the Strong Programme, or in the social\ndimensions and causes of knowledge more generally\nled to extended and close examination of detailed case studies in\ncontemporary science and its history.\n(See the entries on\nthe social dimensions of scientific knowledge\n and\nsocial epistemology.)\nWell-known examinations by\nLatour and Woolgar (1979/1986), Knorr-Cetina (1981), Pickering (1984),\nShapin and Schaffer (1985) seemed to bear out that it was social\nideologies (on a macro-scale) or individual interactions and\ncircumstances (on a micro-scale) which were the primary causal factors\nin determining which beliefs gained the status of scientific\nknowledge.  As they saw it, in other words, explanatory appeals to\nscientific method were not empirically well grounded. By the close of the 20th century the search by\nphilosophers for the scientific method was flagging. Nola and Sankey\n(2000b) could introduce their volume on method by remarking that\n“For some, the whole idea of a theory of scientific method is\nyester-year’s debate …”. Despite the many difficulties that philosophers encountered in\ntrying to providing a clear methodology of conformation (or\nrefutation), still important progress has been made on understanding\nhow observation can provide evidence for a given theory. Work in\nstatistics has been crucial for understanding how theories can be\ntested empirically, and in recent decades a huge literature has\ndeveloped that attempts to recast confirmation in Bayesian terms. Here\nthese developments can be covered only briefly, and we refer to the\nentry on\nconfirmation for further details and references. Statistics has come to play an increasingly important role in the\nmethodology of the experimental sciences from the 19th\ncentury onwards. At that time, statistics and probability theory took\non a methodological role as an analysis of inductive inference, and\nattempts to ground the rationality of induction in the axioms of\nprobability theory have continued throughout the 20th\ncentury and in to the present. Developments in the theory of\nstatistics itself, meanwhile, have had a direct and immense influence\non the experimental method, including methods for measuring the\nuncertainty of observations such as the Method of Least Squares\ndeveloped by Legendre and Gauss in the early 19th century,\ncriteria for the rejection of outliers proposed by Peirce by the\nmid-19th century, and the significance tests developed by\nGosset (a.k.a. “Student”), Fisher, Neyman & Pearson\nand others in the 1920s and 1930s (see, e.g., Swijtink 1987 for a\nbrief historical overview; and also the entry\non C.S. Peirce). These developments within statistics then in turn led to a\nreflective discussion among both statisticians and philosophers of\nscience on how to perceive the process of hypothesis testing: whether\nit was a rigorous statistical inference that could provide a numerical\nexpression of the degree of confidence in the tested hypothesis, or if\nit should be seen as a decision between different courses of actions\nthat also involved a value component. This led to a major controversy\namong Fisher on the one side and Neyman and Pearson on the other (see\nespecially Fisher 1955, Neyman 1956 and Pearson 1955, and for analyses\nof the controversy, e.g., Howie 2002, Marks 2000, Lenhard 2006). On\nFisher’s view, hypothesis testing was a methodology for when to\naccept or reject a statistical hypothesis, namely that a hypothesis\nshould be rejected by evidence if this evidence would be unlikely\nrelative to other possible outcomes, given the hypothesis were\ntrue. In contrast, on Neyman and Pearson’s view, the consequence\nof error also had to play a role when deciding between\nhypotheses. Introducing the distinction between the error of rejecting\na true hypothesis (type I error) and accepting a false hypothesis\n(type II error), they argued that it depends on the consequences of\nthe error to decide whether it is more important to avoid rejecting a\ntrue hypothesis or accepting a false one. Hence, Fisher aimed for a\ntheory of inductive inference that enabled a numerical expression of\nconfidence in a hypothesis. To him, the important point was the search\nfor truth, not utility. In contrast, the Neyman-Pearson approach\nprovided a strategy of inductive behaviour for deciding between\ndifferent courses of action. Here, the important point was not whether\na hypothesis was true, but whether one should act as if it was. Similar discussions are found in the philosophical literature. On\nthe one side, Churchman (1948) and Rudner (1953) argued that because\nscientific hypotheses can never be completely verified, a complete\nanalysis of the methods of scientific inference includes ethical\njudgments in which the scientists must decide whether the evidence is\nsufficiently strong or that the probability is sufficiently high to\nwarrant the acceptance of the hypothesis, which again will depend on\nthe importance of making a mistake in accepting or rejecting the\nhypothesis. Others, such as Jeffrey (1956) and Levi (1960) disagreed\nand instead defended a value-neutral view of science on which\nscientists should bracket their attitudes, preferences, temperament,\nand values when assessing the correctness of their inferences. For\nmore details on this value-free ideal in the philosophy of science and\nits historical development, see Douglas (2009) and Howard (2003). In recent decades, philosophical discussions of the evaluation of\nprobabilistic hypotheses by statistical inference have largely focused\non Bayesianism that understands probability as a measure of a\nperson’s degree of belief in an event, given the available\ninformation, and frequentism that instead understands probability as a\nlong-run frequency of a repeatable event. Hence, for Bayesians\nprobabilities refer to a state of knowledge, whereas for frequentists\nprobabilities refer to frequencies of events (see, e.g., Sober 2008,\nchapter 1 for a detailed introduction to Bayesianism and frequentism\nas well as to likelihoodism). Bayesianism aims at providing a\nquantifiable, algorithmic representation of belief revision, where\nbelief revision is a function of prior beliefs (i.e., background\nknowledge) and incoming evidence. Bayesianism employs a rule based on\nBayes’ theorem, a theorem of the probability calculus which\nrelates conditional probabilities. The probability that a particular\nhypothesis is true is interpreted as a degree of belief, or credence,\nof the scientist. There will also be a probability and a degree of\nbelief that a hypothesis will be true conditional on a piece of\nevidence (an observation, say) being true. Bayesianism proscribes that\nit is rational for the scientist to update their belief in the\nhypothesis to that conditional probability should it turn out that the\nevidence is, in fact, observed. Originating in the work of Neyman and\nPerson, frequentism aims at providing the tools for reducing long-run\nerror rates, such as the error-statistical approach developed by Mayo\n(1996) that focuses on how experimenters can avoid both type I and\ntype II errors by building up a repertoire of procedures that detect\nerrors if and only if they are present. Both Bayesianism and\nfrequentism have developed over time, they are interpreted in\ndifferent ways by its various proponents, and their relations to\nprevious criticism to attempts at defining scientific method are seen\ndifferently by proponents and critics. The literature, surveys,\nreviews and criticism in this area are vast and the reader is referred\nto the entries on\nBayesian epistemology and\nconfirmation. Attention to scientific practice, as we have seen, is not itself\nnew. However, the turn to practice in the philosophy of science of\nlate can be seen as a correction to the pessimism with respect to\nmethod in philosophy of science in later parts of the 20th\ncentury, and as an attempted reconciliation between sociological and\nrationalist explanations of scientific knowledge. Much of this work\nsees method as detailed and context specific problem-solving\nprocedures, and methodological analyses to be at the same time\ndescriptive, critical and advisory (see Nickles 1987 for an exposition\nof this view).  The following section contains a survey of some of the\npractice focuses. In this section we turn fully to topics rather than\nchronology. A problem with the distinction between the contexts of discovery\nand justification that figured so prominently in philosophy of science\nin the first half of the 20th century\n(see section 2) is that no such\ndistinction can be clearly seen in scientific activity (see Arabatzis\n2006). Thus, in recent decades, it has been recognized that study of\nconceptual innovation and change should not be confined to psychology\nand sociology of science, but are also important aspects of scientific\npractice which philosophy of science should address (see also the  entry on\nscientific discovery). \nLooking for the practices that drive conceptual innovation has led\nphilosophers to examine both the reasoning practices of scientists and\nthe wide realm of experimental practices that are not directed\nnarrowly at testing hypotheses, that is, exploratory\nexperimentation. Examining the reasoning practices of historical and contemporary\nscientists, Nersessian (2008) has argued that new scientific concepts\nare constructed as solutions to specific problems by systematic\nreasoning, and that of analogy, visual representation and\nthought-experimentation are among the important reasoning practices\nemployed. These ubiquitous forms of reasoning are reliable—but\nalso fallible—methods of conceptual development and change. On\nher account, model-based reasoning consists of cycles of construction,\nsimulation, evaluation and adaption of models that serve as interim\ninterpretations of the target problem to be solved. Often, this\nprocess will lead to modifications or extensions, and a new cycle of\nsimulation and evaluation. However, Nersessian also emphasizes that creative model-based reasoning cannot be applied\nas a simple recipe, is not always productive of solutions, and even\nits most exemplary usages can lead to incorrect solutions. (Nersessian\n2008: 11) Thus, while on the one hand she agrees with many previous\nphilosophers that there is no logic of discovery, discoveries can derive\nfrom reasoned processes, such that a large and integral part of\nscientific practice is the creation of concepts through which to\ncomprehend, structure, and communicate about physical phenomena\n…. (Nersessian 1987: 11) Similarly, work on heuristics for discovery and\ntheory construction by scholars such as Darden (1991) and Bechtel\n& Richardson (1993) present science as problem solving and\ninvestigate scientific problem solving as a special case of\nproblem-solving in general. Drawing largely on cases from the\nbiological sciences, much of their focus has been on reasoning\nstrategies for the generation, evaluation, and revision of\nmechanistic explanations of complex systems. Addressing another aspect of the context distinction, namely the\ntraditional view that the primary role of experiments is to test\ntheoretical hypotheses according to the H-D model, other philosophers\nof science have argued for additional roles that experiments can play.\nThe notion of exploratory experimentation was introduced to describe\nexperiments driven by the desire to obtain empirical regularities and\nto develop concepts and classifications in which these regularities\ncan be described (Steinle 1997, 2002; Burian 1997; Waters\n2007)). However the difference between theory driven experimentation\nand exploratory experimentation should not be seen as a sharp\ndistinction. Theory driven experiments are not always directed at\ntesting hypothesis, but may also be directed at various kinds of\nfact-gathering, such as determining numerical parameters. Vice\nversa, exploratory experiments are usually informed by theory in\nvarious ways and are therefore not theory-free. Instead, in\nexploratory experiments phenomena are investigated without first\nlimiting the possible outcomes of the experiment on the basis of\nextant theory about the phenomena. In recent years, the development of high throughput instrumentation\nin molecular biology and neighbouring fields has given rise to a\nspecial type of exploratory experimentation that collects and analyses\nvery large amounts of data, and these new ‘omics’\ndisciplines are often said to represent a break with the ideal of\nhypothesis-driven science (Burian 2007; Elliott 2007; Waters 2007;\nO’Malley 2007) and instead described as data-driven research\n(Leonelli 2012; Strasser 2012) or as a special kind of\n“convenience experimentation” in which many experiments\nare done simply because they are extraordinarily convenient to perform\n(Krohs 2012). The field of omics just described is possible because of the\nability of computers to process, in a reasonable amount of time, the\nhuge quantities of data required. Computers allow for more elaborate\nexperimentation (higher speed, better filtering, more variables,\nsophisticated coordination and control), but also, through modelling\nand simulations, might constitute a form of experimentation\nthemselves. Here, too, we can pose a version\nof the general question of method versus practice: does the\npractice of using computers fundamentally change scientific method, or merely\nprovide a more efficient means of implementing standard methods? Because computers can be used to automate measurements,\nquantifications, calculations, and statistical analyses where, for\npractical reasons, these operations cannot be otherwise carried out,\nmany of the steps involved in reaching a conclusion on the basis of an\nexperiment are now made\ninside a “black box”,\nwithout the direct involvement or awareness of a human.\nThis has epistemological implications, regarding what we can know, and\nhow we can know it. To have confidence in the results, computer\nmethods are therefore subjected to tests of verification and\nvalidation. The distinction between verification and validation is easiest to\ncharacterize in the case of computer simulations. In a typical\ncomputer simulation scenario computers are used to numerically\nintegrate differential equations for which no analytic solution is\navailable. The equations are part of the model the scientist uses to\nrepresent a phenomenon or system under investigation. Verifying a\ncomputer simulation means checking that the equations of the model are\nbeing correctly approximated. Validating a simulation means checking\nthat the equations of the model are adequate for the inferences one\nwants to make on the basis of that model. A number of issues related to computer simulations have been\nraised.  The identification of validity and verification as the\ntesting methods has been criticized. Oreskes et al. (1994) raise\nconcerns that “validiation”, because it suggests deductive\ninference, might lead to over-confidence in the results of\nsimulations. The distinction itself is probably too clean, since\nactual practice in the testing of simulations mixes and moves back and\nforth between the two (Weissart 1997; Parker 2008a; Winsberg\n2010). Computer simulations do seem to have a non-inductive character,\ngiven that the principles by which they operate are built in by the\nprogrammers, and any results of the simulation follow from those\nin-built principles in such a way that those results could, in\nprinciple, be deduced from the program code and its inputs. The status\nof simulations as experiments has therefore been examined (Kaufmann\nand Smarr 1993; Humphreys 1995; Hughes 1999; Norton and Suppe\n2001). This literature considers the epistemology of these\nexperiments: what we can learn by simulation, and also the kinds\nof justifications which can be given in applying that knowledge to the\n“real” world. (Mayo 1996; Parker 2008b). As pointed out,\npart of the advantage of computer simulation derives from the fact\nthat huge numbers of calculations can be carried out without requiring\ndirect observation by the experimenter/​simulator. At the same\ntime, many of these calculations are approximations to the\ncalculations which would be performed first-hand in an ideal\nsituation. Both factors introduce uncertainties into the inferences\ndrawn from what is observed in the simulation. For many of the reasons described above, computer simulations do\nnot seem to belong clearly to either the experimental or theoretical\ndomain. Rather, they seem to crucially involve aspects of both. This\nhas led some authors, such as Fox Keller (2003: 200) to argue that we ought to\nconsider computer simulation a “qualtitatively different way of\ndoing science”. The literature in general tends to\nfollow Kaufmann and Smarr (1993) in referring to computer simulation\nas a “third way” for scientific methodology (theoretical\nreasoning and experimental practice are the first two ways.). It\nshould also be noted that the debates around these issues have tended\nto focus on the form of computer simulation typical in the physical\nsciences, where models are based on dynamical equations. Other forms\nof simulation might not have the same problems, or have problems of\ntheir own (see the entry on\ncomputer simulations in science). Despite philosophical disagreements, the idea of the\nscientific method still figures prominently in contemporary discourse\non many different topics, both within science and in society at large.\nOften, reference to scientific method is used in ways that convey\neither the legend of a single, universal method characteristic of all\nscience, or grants to a particular method or set of methods privilege\nas a special ‘gold standard’, often with reference to\nparticular philosophers to vindicate the claims. Discourse on\nscientific method also typically arises when there is a need to\ndistinguish between science and other activities, or for justifying\nthe special status conveyed to science. In these areas, the\nphilosophical attempts at identifying a set of methods characteristic\nfor scientific endeavors are closely related to the philosophy of\nscience’s classical problem of demarcation (see the entry on \nscience and pseudo-science)\nand to the philosophical analysis of the social dimension of\nscientific knowledge and the role of science in democratic\nsociety. One of the settings in which the legend of a single, universal\nscientific method has been particularly strong is science education\n(see, e.g., Bauer 1992; McComas 1996; Wivagg & Allchin\n2002).[5] Often,\n‘the scientific method’ is presented in textbooks and\neducational web pages as a fixed four or five step procedure starting\nfrom observations and description of a phenomenon and progressing\nover formulation of a hypothesis which explains the phenomenon,\ndesigning and conducting experiments to test the hypothesis,\nanalyzing the results, and ending with drawing a conclusion. Such\nreferences to a universal scientific method can be found in\neducational material at all levels of science education (Blachowicz\n2009), and numerous studies have shown that the idea of a general and\nuniversal scientific method often form part of both students’\nand teachers’ conception of science (see, e.g., Aikenhead 1987;\nOsborne et al. 2003). Although occasionally phrased with reference to the H-D method,\nimportant historical roots of the legend in science education of a\nsingle, universal scientific method are the American philosopher and\npsychologist Dewey’s account of inquiry in How We Think\n(1910) and the British mathematician Karl Pearson’s account of\nscience in Grammar of Science (1892). On Dewey’s\naccount, inquiry is divided into the five steps of (i) a felt difficulty, (ii) its location and\ndefinition, (iii) suggestion of a possible solution, (iv) development\nby reasoning of the bearing of the suggestions, (v) further\nobservation and experiment leading to its acceptance or\nrejection. (Dewey 1910: 72) Similarly, on Pearson’s account, scientific\ninvestigations start with measurement of data and observation of\ntheir correction and sequence from which scientific laws can be\ndiscovered with the aid of creative imagination. These laws have to\nbe subject to criticism, and their final acceptance will have equal\nvalidity for “all normally constituted minds”. Both\nDewey’s and Pearson’s accounts should be seen as\ngeneralized abstractions of inquiry and not restricted to the realm\nof science—although both Dewey and Pearson referred to their\nrespective accounts as ‘the scientific method’. Occasionally, scientists make sweeping statements about a simple\nand distinct scientific method, as exemplified by Feynman’s\nsimplified version of a conjectures and refutations method presented,\nfor example, in the last of his 1964 Cornell Messenger\n lectures.[6]\nHowever, just as often scientists have come to the same conclusion as\nrecent philosophy of science that there is not any unique, easily\ndescribed scientific method. For example, the physicist and Nobel\nLaureate Weinberg described in the paper “The Methods of\nScience … And Those By Which We Live” (1995) how The fact that the standards of scientific success\nshift with time does not only make the philosophy of science\ndifficult; it also raises problems for the public understanding of\nscience. We do not have a fixed scientific method to rally around and\ndefend. (1995: 8) Reference to the scientific method has also often been used to\nargue for the scientific nature or special status of a particular\nactivity.  Philosophical positions that argue for a simple and unique\nscientific method as a criterion of demarcation, such as Popperian\nfalsification, have often attracted practitioners who felt that they\nhad a need to defend their domain of practice. For example, references\nto conjectures and refutation as the scientific method are abundant in\nmuch of the literature on complementary and alternative medicine\n(CAM)—alongside the competing position that CAM, as an\nalternative to conventional biomedicine, needs to develop its own\nmethodology different from that of science. Also within mainstream science, reference to the scientific method\nis used in arguments regarding the internal hierarchy of disciplines\nand domains. A frequently seen argument is that research based on the\nH-D method is superior to research based on\ninduction from observations because in deductive inferences the\nconclusion follows necessarily from the premises. (See, e.g.,\nParascandola (1998) for an analysis of how this argument has been made\nto downgrade epidemiology compared to the laboratory sciences.)\nSimilarly, based on an examination of the practices of major funding\ninstitutions such as the National Institutes of Health (NIH), the\nNational Science Foundation (NSF) and the Biomedical Sciences Research\nPractices (BBSRC) in the UK, O’Malley et al. (2009) have argued\nthat funding agencies seem to have a tendency to adhere to the view\nthat the primary activity of science is to test hypotheses, while\ndescriptive and exploratory research is seen as merely preparatory\nactivities that are valuable only insofar as they fuel\nhypothesis-driven research. In some areas of science, scholarly publications are structured in\na way that may convey the impression of a neat and linear process of\ninquiry from stating a question, devising the methods by which to\nanswer it, collecting the data, to drawing a conclusion from the\nanalysis of data. For example, the codified format of publications in\nmost biomedical journals known as the IMRAD format (Introduction,\nMethod, Results, Analysis, Discussion) is explicitly described by the\njournal editors as “not an arbitrary publication format but\nrather a direct reflection of the process of scientific\ndiscovery” (see the so-called “Vancouver\nRecommendations”, ICMJE 2013: 11). However, scientific\npublications do not in general reflect the process by which the\nreported scientific results were produced. For example, under the\nprovocative title “Is the scientific paper a fraud?”,\nMedawar argued that scientific papers generally misrepresent how the\nresults have been produced (Medawar 1963/1996). Similar views have\nbeen advanced by philosophers, historians and sociologists of science\n(Gilbert 1976; Holmes 1987; Knorr-Cetina 1981; Schickore 2008; Suppe\n1998) who have argued that scientists’ experimental practices\nare messy and often do not follow any recognizable\npattern. Publications of research results, they argue, are\nretrospective reconstructions of these activities that often do not\npreserve the temporal order or the logic of these activities, but are\ninstead often constructed in order to screen off potential criticism\n(see Schickore 2008 for a review of this work). Philosophical positions on the scientific method have also made it\ninto the court room, especially in the US where judges have drawn on\nphilosophy of science in deciding when to confer special status to\nscientific expert testimony. A key case is Daubert vs Merrell Dow\nPharmaceuticals (92-102, 509 U.S. 579, 1993). In this case, the\nSupreme Court argued in its 1993 ruling that trial judges must ensure\nthat expert testimony is reliable, and that in doing this the court\nmust look at the expert’s methodology to determine whether the\nproffered evidence is actually scientific knowledge. Further,\nreferring to works of Popper and Hempel the court stated that ordinarily, a key question to be answered in\ndetermining whether a theory or technique is scientific knowledge\n… is whether it can be (and has been) tested.  (Justice\nBlackmun, Daubert v. Merrell Dow Pharmaceuticals; see Other Internet\nResources for a link to the opinion) But as argued by Haack (2005a,b, 2010) and by\nFoster & Hubner (1999), by equating the question of whether a\npiece of testimony is reliable with the question whether it is\nscientific as indicated by a special methodology, the court was\nproducing an inconsistent mixture of Popper’s and\nHempel’s philosophies, and this has later led to considerable\nconfusion in subsequent case rulings that drew on the Daubert case\n(see Haack 2010 for a detailed exposition). The difficulties around identifying the methods of science are also\nreflected in the difficulties of identifying scientific misconduct in\nthe form of improper application of the method or methods of science.\nOne of the first and most influential attempts at defining misconduct\nin science was the US definition from 1989 that defined misconduct as fabrication, falsification, plagiarism, or\nother practices that seriously deviate from those that are commonly\naccepted within the scientific community. (Code of Federal\n Regulations, part 50, subpart A.,\nAugust 8, 1989, italics added) However, the “other practices that\nseriously deviate” clause was heavily criticized because it\ncould be used to suppress creative or novel science. For example, the\nNational Academy of Science stated in their report Responsible\nScience (1992) that it wishes to discourage the possibility that a\nmisconduct complaint could be lodged against scientists based solely\non their use of novel or unorthodox research methods. (NAS: 27) This clause was therefore later removed from the\ndefinition. For an entry into the key philosophical literature on\nconduct in science, see Shamoo & Resnick (2009). The question of the source of the success of science has been at\nthe core of philosophy since the beginning of modern science. If\nviewed as a matter of epistemology more generally, scientific method\nis a part of the entire history of philosophy. Over that time, science\nand whatever methods its practioners may employ have changed dramatically. Today,\nmany philosophers have taken up the banners of pluralism or of\npractice to focus on what are, in effect, fine-grained and\ncontextually limited examinations of scientific method. Others hope to\nshift perspectives in order to provide a renewed general account of\nwhat characterizes the activity we call science. One such perspective has been offered recently by Hoyningen-Huene\n(2008, 2013), who argues from the history of philosophy of science\nthat after three lengthy phases of characterizing science by its\nmethod, we are now in a phase where the belief in the existence of a\npositive scientific method has eroded and what has been left to\ncharacterize science is only its fallibility. First was a phase from\nPlato and Aristotle up until the 17th century where the\nspecificity of scientific knowledge was seen in its absolute certainty\nestablished by proof from evident axioms; next was a phase up to the\nmid-19th century in which the means to establish the\ncertainty of scientific knowledge had been generalized to include\ninductive procedures as well. In the third phase, which lasted until\nthe last decades of the 20th century, it was recognized\nthat empirical knowledge was fallible, but it was still granted a\nspecial status due to its distinctive mode of production. But now in\nthe fourth phase, according to Hoyningen-Huene, historical and\nphilosophical studies have shown how “scientific methods with\nthe characteristics as posited in the second and third phase do not\nexist” (2008: 168) and there is no longer any consensus among\nphilosophers and historians of science about the nature of\nscience. For Hoyningen-Huene, this is too negative a stance, and he\ntherefore urges the question about the nature of science anew. His own\nanswer to this question is that “scientific knowledge differs\nfrom other kinds of knowledge, especially everyday knowledge,\nprimarily by being more systematic” (Hoyningen-Huene 2013:\n14). Systematicity can have several different dimensions: among them are more\nsystematic descriptions, explanations, predictions, defense of\nknowledge claims, epistemic connectedness, ideal of completeness,\nknowledge generation, representation of knowledge and critical\ndiscourse. Hence, what characterizes science is the greater care in\nexcluding possible alternative explanations, the more detailed\nelaboration with respect to data on which predictions are based, the\ngreater care in detecting and eliminating sources of error, the more\narticulate connections to other pieces of knowledge, etc. On this\nposition, what characterizes science is not that the methods employed\nare unique to science, but that the methods are more carefully\nemployed. Another, similar approach has been offered by Haack (2003). She\nsets off, similar to Hoyningen-Huene, from a dissatisfaction with the\nrecent clash between what she calls Old Deferentialism and New\nCynicism. The Old Deferentialist position is that science progressed\ninductively by accumulating true theories confirmed by empirical\nevidence or deductively by testing conjectures against basic\nstatements; while the New Cynics position is that science has no\nepistemic authority and no uniquely rational method and is merely just\npolitics. Haack insists that contrary to the views of the New Cynics,\nthere are objective epistemic standards, and there is something\nepistemologically special about science, even though the Old\nDeferentialists pictured this in a wrong way. Instead, she offers a\nnew Critical Commonsensist account on which standards of good, strong,\nsupportive evidence and well-conducted, honest, thorough and\nimaginative inquiry are not exclusive to the sciences, but the\nstandards by which we judge all inquirers. In this sense, science does\nnot differ in kind from other kinds of inquiry, but it may differ in\nthe degree to which it requires broad and detailed background\nknowledge and a familiarity with a technical vocabulary that only\nspecialists may possess.","contact.mail":"brian.hepburn@wichita.edu","contact.domain":"wichita.edu"}]
