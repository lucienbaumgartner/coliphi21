[{"date.published":"2009-01-30","date.changed":"2017-02-27","url":"https://plato.stanford.edu/entries/clinical-research/","author1":"David Wendler","entry":"clinical-research","body.text":"\n\nClinical research attempts to address a relatively straightforward,\nand extremely important challenge: how do we determine whether one \nmedical intervention is better than another, whether it offers greater clinical benefit and/or poses fewer risks? Clinicians may one day be\nable to answer these questions by relying on computer models, thereby\navoiding reliance on clinical research and the ethical concerns it\nraises. Until that day, clinical researchers begin by testing\npotential new medical interventions in the laboratory, and often in\nanimals. While these methods can provide valuable information and, in\nthe case of animal research, raise important ethical issues of their\nown, potential new interventions eventually must be tested in\nhumans. Potential new interventions which work miracles in test tubes\nand in mice, often leave humans untouched, or worse off.\n\nThe human tests of a medical intervention typically pose some risks to subjects no matter how many laboratory and animal tests have preceded them. In this way, the process of collecting data to improve health and well-being exposes research subjects to risks for the benefit of future patients. These studies thus provide a clear\nexample of the central ethical challenge posed by clinical\nresearch: When is it ethically permissible to expose research subjects to risks of harm for the benefit of others? The present entry focuses on this concern, and canvasses the\nmost prominent attempts to address it. The present entry largely\nbrackets the range of interesting and important ethical challenges that\narise in the course of conducting clinical research: How should it be\nreviewed? Who may conduct it? What must potential subjects understand\nto give valid consent? May it be conducted in countries that will not\nbe able to afford the intervention being tested? Do investigators have\nany obligations to treat unrelated medical conditions they uncover in\nthe course of their research?\n\nOne might attempt to address the central ethical challenge\nby limiting clinical research to the medical setting, offering\nexperimental interventions to patients who want to try them. This\napproach, which has the virtue of evaluating interventions in the\nprocess of trying to help individual patients, can make sense for comparisons of two or more interventions that are widely accepted and already in clinical use. In contrast, this approach poses enormous\nscientific and practical problems with respect to testing new interventions. On the practical side, who would be\nwilling to manufacture a new intervention without knowing whether it\nworks? What dose should be used? How often should the new drug be\ntaken? More importantly, this approach might not yield reliable\ninformation as to whether the new treatment is useful or harmful until\nhundreds, perhaps thousands of people have received it. Clinical\nresearch is designed to address these concerns by systematically\nexposing a small number of individuals, including very sick ones, to\npotential new treatments. Many activities, driving a car, smoking a\ncigarette, flushing our waste down the drain, expose others to risks of\nharm. Nonetheless, there has been surprisingly little philosophical\nanalysis of the conditions under which it is acceptable to do this\n(Hayenhjelm and Wolff 2012). Therefore, in addition to being of value\nin its own right, evaluation of the ethics of clinical research\nprovides an opportunity to consider one of the more fundamental\nconcerns in moral theory: when is it acceptable to expose some\nindividuals to risks of harm for the potential benefit of others?\n\nHuman subjects research is research which studies humans, as\nopposed to animals, atoms, or asteroids. Assessment of whether humans prefer 100 dollars or a 1% chance of\n10,000 dollars constitutes human subjects research. Clinical research\nrefers to the subset of human subjects research which focuses on interventions to\nimprove human health and well-being. The present analysis focuses on research that is designed to\nimprove human health and well-being by identifying better methods to\ntreat, cure or prevent illness. This focus on treating, curing and\npreventing illness is intended to bracket the question of\nwhether research on enhancements qualifies as clinical research. Such\nresearch has the potential to improve well-being, allowing us to remember more and worry less, without identifying methods to address illness. We shall also bracket the question of whether quality improvement\nand quality assurance projects qualify as clinical research. To\nbriefly consider the type of research at the heart of this debate,\nconsider a hospital which proposes to evaluate the impact of\nchecklists on the quality of patient care. Half the nurses in the\nhospital are told to continue to provide care as usual; the other half\nare provided with a checklist and instructed to mechanically check off\neach item as they complete it when caring for their\npatients. The question\nof whether this activity constitutes clinical research is of\ntheoretical interest for clarifying the precise boundaries of the\nconcept. Should we say that this is not clinical research because the\nchecklist is used by the nurses, not administered to the patients? Or\nshould we say this is clinical research because it involves the\nsystematic testing of a hypothesis which is answered by collecting\ndata on patient outcomes? And this theoretical clarification has significant practical implications, determining whether these activities must satisfy existing\nregulations for clinical research, including whether the clinicians\nneed to obtain patients’ informed consent to use the checklist. While clinical medicine is enormously better than it was 100 or\neven 50 years ago, there remain many diseases against which current\nclinical medicine offers an inadequate response. To name just a few,\nmalaria kills over a million people, mostly children, every year;\nchronic diseases, chief among them heart disease and stroke, kill\nmillions each year, and there currently are no effective treatments\nfor Alzheimer disease. The social value of clinical research lies in\nits ability to collect information that might be useful to identifying\nimproved methods to treat these conditions.  Yet, it is the rare\nclinical research study which definitively establishes that a\nparticular method is effective and safe for treating, curing or\npreventing some illness. The success of specific research studies more\ncommonly lies in the gathering of information needed to inform future\nstudies. Prior to establishing the efficacy of an experimental treatment for\na given condition, researchers typically need to identify the cause of\nthe condition, possible mechanisms for treating it, a safe and\neffective dose, and ways of testing whether the drug is having an\neffect on the disease. The process of testing potential new treatments can take 10-15\nyears, and is standardly divided into phases. Formalized phase 0\nstudies are a relatively recent phenomenon involving the testing of\ninterventions and methods which might be used in later phase\nstudies. A phase 0 study might be designed to determine the mechanism\nof action of a particular drug and evaluate different ways to\nadminister it. Phase 1 studies are the earliest tests of a new\nintervention and are conducted in small numbers of individuals. Phase\n1 studies are designed to evaluate the pharmacokinetics and\npharmacodynamics of new treatments, essentially evaluating how the\ndrug influences the human body and how the human body influences the\ndrug. Phase 1 studies also evaluate the risks of the treatment and\nattempt to identify an appropriate dose to be used in subsequent phase\n2 studies.  Phase 1 studies pose risks and frequently offer little if\nany potential for clinical benefit to subjects. As a result, a\nsignificant amount of the ethical concern over clinical research\nfocuses on phase 1 studies. If phase 1 testing is successful, potential new treatments go on to\nlarger phase 2 studies which are designed to further assess risks and\nalso to evaluate whether there is any evidence that the treatment\nmight be beneficial. Successful phase 2 studies are followed by phase\n3 studies which involve hundreds, sometimes thousands of\npatients. Phase 3 studies are designed to provide a rigorous test of\nthe efficacy of a treatment and frequently involve randomization of\nsubjects to the new treatment or a control, which might be standard\nexisting treatment or a placebo. Finally, post-marketing or phase 4\nstudies evaluate the use of interventions in clinical practice. Clinical trials of experimental treatments typically include purely\nresearch procedures, such as blood draws, imaging scans, or biopsies,\nthat are performed to collect data regarding the treatment under\nstudy.  Analysis of the ethics of clinical research thus requires\nevaluation of three related risk-benefit profiles: (a) the\nrisk-benefit profile of the interventions(s) under\nstudy; (b) the risk-benefit profile of the included research\nprocedures; and (c) the risk-benefit profile of the study as a\nwhole. Potential new treatments sometimes are in the ex ante interests of\nresearch subjects. For example, the risks posed by an experimental\ncancer treatment might be justified by the possibility that it will\nextend subjects’ lives. Moreover, the risk/benefit profile of the\ntreatment might be as favorable to subjects as the risk/benefit\nprofile of the available alternatives. In these cases, receipt of the\nexperimental intervention ex ante promotes subjects’ interests.  In\nother cases, participation in research poses ‘net’ risks,\nthat is, risks of harm which are not, or not entirely, justified by\npotential clinical benefits to individual subjects. Experimental\ninterventions sometimes pose net risks. A first in human trial of an\nexperimental treatment might involve a single dose to see whether\nhumans can tolerate it. And it might occur in healthy individuals who have no need of treatment. These studies pose risks to subjects and\noffer essentially no chance for clinical benefit. The qualifier to ‘essentially’ no chance of clinical benefit is intended to capture the fact that the research procedures\nincluded in clinical trials may inadvertently end up providing some clinical benefit to some subjects. For example, a biopsy that is used to collect research data may disclose a previously unidentified and treatable condition. The chance for such benefit, albeit real, is typically so\nremote that it is not sufficient to compensate for the risks of the\nprocedure. Whether a study as a whole poses net risks depends on\nwhether the potential benefits of the experimental intervention\ncompensate for its risks plus the net risks of the research procedures\nincluded in the study. Clinical research which poses net risks raises important ethical\nconcern.  Net-risk studies raise concern that subjects are being used\nas mere means to collect information to benefit future\npatients. Research procedures that pose net risks may seem to raise\nless concern when they are embedded within a study which offers a\nfavorable risk-benefit profile overall. Yet, since these procedures\npose net risks, and since the investigators could provide subjects\nwith the new potential treatment alone, they require justification. An\ninvestigator who is about to insert a needle into a research subject\nto obtain some blood purely for laboratory purposes faces the question\nof whether doing so is ethically justified, even when the procedure is included in a study that offers subjects the potential for important medical benefit. The goal of ethical\nanalyses of clinical research is to provide an answer.  Clinical\nresearch poses three types of net risks: absolute, relative, and\nindirect (Rid and Wendler 2011). Absolute net risks arise when the\nrisks of an intervention or procedure are not justified by its\npotential clinical benefits. Most commentators focus on this\npossibility with respect to research procedures which pose some risks\nand offer no chance of clinical benefit, such as blood draws to obtain\ncells for laboratory studies.  Research with healthy volunteers is\nanother example which frequently offers no chance for clinical\nbenefit. Clinical research also poses absolute net risks when it\noffers a chance for clinical benefit which is not sufficient to\njustify the risks subjects face. A kidney biopsy to obtain tissue from\npresumed healthy volunteers may offer some very low chance of\nidentifying an unrecognized and treatable pathology. This intervention\nnonetheless poses net risks if the chance for clinical benefit for the subjects is not\nsufficient to justify the risks of their undergoing the biopsy. Relative net risks arise when the risks of a research intervention\nare justified by its potential clinical benefits, but the\nintervention’s risk-benefit profile is less favorable than the\nrisk-benefit profile of one or more available alternatives. Imagine\nthat investigators propose a randomized-controlled trial to compare an\ninexpensive drug against an expensive and somewhat more effective\ndrug. Such trials make sense when, in the absence of a direct\ncomparison, it is unclear whether the increased effectiveness of the\nmore expensive drug justifies its costs. In this case, receipt of the\ncheaper drug would be contrary to subjects’ interest in comparison to\nreceiving the more expensive drug. The trial thus poses relative net\nrisks to subjects. Indirect net risks arise when a research intervention has a\nfavorable risk-benefit profile, but the intervention diminishes the\nrisk-benefit profile of other interventions provided as part of or in\nparallel to the study. For example, an experimental drug for cancer\nmight undermine the effectiveness of other drugs individuals are\ntaking for their condition. The risks of research participation can be\ncompounded if the indicated response to the harm in question posse additional risks. Kidney damage suffered as the result of research participation might lead to the need for\nshort-term dialysis which poses additional risks to the individual; a subject who experiences a postlumbar\npuncture headache might need a ‘blood patch’ which\nposes some risk of blood entering the\nepidural space which would call for a further response which brings with it additional risks. While commentators tend to focus on the risks of\nphysical harm, participation in clinical research can pose other\ntypes of risks as well, including psychological, economic, and social\nrisks. Depending on the study and the circumstances, individuals who\nare injured as the result of participating in research might incur\nsignificant expenses. Most guidelines and regulations stipulate that\nevaluation of the acceptability of clinical research studies should\ntake into account all the different risks to which subjects are\nexposed. To assess the ethics of exposing subjects to risks, one needs an account of\nwhy exposing others to risks raises ethical concern in the first place.\nBeing exposed to risks obviously raises concern to the extent that the\npotential harm to which the risk refers is realized: the chance of a\nheadache turns into an actual headache. Being exposed to risks also can\nlead to negative consequences as a result of the recognition that one is at\nrisk of harm. Individuals who recognize that they face a risk may become\nfrightened; they also may take costly or burdensome measures to protect\nthemselves. In contrast, the literature on the ethics of clinical research\nimplicitly assumes that being exposed to risks is not itself harmful. The\nmere fact that subjects are exposed to risks is not regarded as necessarily making them worse off Increasingly, researchers are storing human biological samples and\nusing them in future research projects. These studies raise difficult\nquestions regarding the possibility of what might be called\n‘contribution’ and ‘information’ risks. The\nformer question concerns the conditions under which it is acceptable\nto ask individuals to contribute to answering the scientific question\nposed by a given study (Jonas 1969). The frequent neglect of this\nissue may trace to a narrow understanding of subjects’\ninterests. Individuals undoubtedly have an interest in avoiding the\nkinds of physical harms they face in clinical research. It seems that\nindividuals’ interests also may be implicated, and possibly thwarted,\nwhen they contribute to particular projects, activities and goals. Imagine that an individual provides a blood sample which\ninvestigators store and use in future research projects designed to\npromote goals which conflict with the individual’s fundamental values. Can such research\nharm the individual if they never learn about the results and are\nnever personally affected by them? Are the interests of an individual\nwho fundamentally opposes cloning, and constructs her life around\nefforts to stop it, set back if she contributes to a research study\nthat identifies improved methods to clone human beings? With respect\nto information risks, investigators used DNA samples obtained from\nmembers of the Havasupai tribe to study “theories of the tribe’s\ngeographical origins.” The study’s conclusion that early members of\nthe tribe had migrated from Asia across the Bering Strait contradicted\nthe tribe’s own views that they originated in the Grand Canyon (Harmon\n2010). Can learning the truth about the origins of one’s tribal group\nharm members of the tribe? Exposing research subjects to risks of harm is considered morally\nproblematic largely because it has the potential to result in their\nbeing harmed. In addition, guidelines and regulations on clinical\nresearch are replete with admonitions to expose subjects to risks only\nwhen doing so is justified by the value of the study in question. This\nfocus reveals an important although typically implicit feature of most\nanalyses of the ethics of clinical research. It is often said that the\nethics of clinical research concerns the protection of research\nsubjects. One might conclude that exposing subjects to risks is\nregarded as problematic only to the extent that it has the potential\nto harm them. On this view, analysis of the appropriateness of\ninvestigators exposing subjects to risks would be limited to the\npossibility of making subjects worse off. In fact, while the\nprotection of research subjects is important, it does not exhaust the\nethics of clinical research. Guidelines and regulations also reflect\nimplicit principles regarding what constitutes appropriate\ninvestigator behavior that are independent of the possibility of\nmaking subjects worse off. Put generally, a full analysis of the ethics of exposing subjects to risks needs to justify both the treatment of the subjects and the behavior of the researchers. The future oriented aspect of clinical research is worth\nemphasizing. The fundamental ethical concern raised by clinical\nresearch is whether and when it can be acceptable to expose some\nindividuals to risks and burdens for the benefit of others. In\ngeneral, the answer to this question depends crucially on the others\nin question, and their relationship to those who are being exposed to\nthe risks. It is one thing to expose a consenting adult to risks to\nsave the health or life of an identified and present other,\nparticularly when the two individuals are first degree relatives. It\nis another thing, or seems to many to be another thing, to expose\nconsenting individuals to risks to help unknown and unidentified, and\npossibly future others. Almost no one objects to operating on a\nhealthy, consenting adult to obtain a kidney that might save an ailing\nsibling, even though the operation poses some risk of serious harm and offers the donor no potential for clinical benefit. Greater\nconcern is raised by attempts to obtain a kidney from a healthy,\nconsenting adult and give it to an unidentified\nindividual. Commentators express even greater ethical concern as the\npath from risk exposure to benefit becomes longer and more\ntenuous. Many clinical research studies expose subjects to risks in\norder to collect generalizable information which, if combined with the\nresults of other, as yet non-existent studies, may eventually benefit\nfuture patients through the identification of a new intervention, assuming the appropriate regulatory authorities\napprove it, some company or group chooses to manufacture it, and\npatients can afford to purchase it. The potential benefits of clinical\nresearch may thus be realized someday, but the risks and burdens are\nclear and present. Attempts to determine when it is acceptable to conduct clinical\nresearch have been significantly influenced by its history, by how it\nhas been conducted and, in particular, by how it has been misconducted\n(Lederer 1995; Beecher 1966). Thus, to understand the current state of\nthe ethics of clinical research, it is useful to know something of its\npast. \n\nModern clinical research may have begun on the 20th of May,\n1747, aboard the HMS Salisbury. James Lind, the ship’s surgeon, was\nconcerned with the costs scurvy was exacting on British sailors, and\nwas skeptical of some of the interventions, cider, elixir of vitriol,\nvinegar, sea-water, being used to treat it. Unlike other clinicians of his day, Lind did not simply assume that he was correct and treat his\npatients accordingly. He designed a study to test whether he\nwas right. He chose 12 sailors from among the 30 or so Salisbury’s\ncrew members who were suffering from scurvy, and divided them into six\ngroups of 2 sailors each. Lind assigned a different intervention to\neach of the groups, including two sailors turned research subjects who\nreceived 2 oranges and 1 lemon each day. Within a week these two were\nsailors again; the others remained patients, and several were dying. \nThe ethics of clinical research begins by asking how we should think\nabout the fate of these latter sailors. Do they have a moral claim\nagainst Lind? Did Lind treat them appropriately? It is widely assumed\nthat physicians should do what they think is best for the patient in\nfront of them. Lind, despite being a physician, did not follow this\nmaxim. He felt strongly that giving sea water to individuals with\nscurvy was a bad idea, but he gave sea water to 2 of the sailors in\nhis study to test whether he, or others, were right. To put the\nfundamental concern raised by clinical research in its simplest form:\nDid Lind sacrifice these two sailors, patients under his care, for the\nbenefit of others? \n\nLind’s experiments represent perhaps the first modern clinical trial\nbecause he attempted to address one of the primary challenges facing\nthose who set out to evaluate medical treatments. How does one show\nthat any differences in the outcomes of the treatments under study are a result of\nthe treatments themselves, and not a result of the patients who\nreceived them, or other differences in the patients’ environment or diet? How\ncould Lind be confident that the improvements in the two\nsailors were the result of the oranges and lemons, and\nnot a result of the fact that he happened to give this particular\ntreatment to the two patients who occupied the most salutary rooms on the ship?\nLind tried to address the challenge of confounding variables by beginning with patients who\nwere as similar as possible. He carefully chose the 12 subjects for\nhis experiment from a much larger pool of ailing sailors; he also\ntried to ensure that all 12 received the same rations each day, apart\nfrom the treatments provided as part of his study. It is also worth\nnoting that Lind’s dramatic results were largely ignored for decades,\nleading to uncounted and unnecessary deaths, and highlighting the\nimportance of combining clinical research with effective promulgation and \nimplementation. The Royal Navy did not adopt citrus rations for another 50 years\n(Sutton 2003), at which point scurvy essentially disappeared from the\nRoyal Navy. \n\nLind’s experiments, despite controlling for a number of factors, did\nnot exclude the possibility that his own choices of which sailors got\nwhich treatment influenced the results. More recent experiments,\nincluding the first modern randomized, placebo controlled trial of\nStreptomycin for TB in 1948 (D’Arcy Hart 1999), attempt to address\nthis concern by assigning treatments to patients using a random\nselection process. By randomly assigning patients to treatment groups\nthese studies ushered in the modern era of controlled, clinical\ntrials. And, by taking the choice of which treatment a given patient\nreceives out of the hands of the treating clinician, these trials\nunderscore and, some argue, exacerbate the ethical concerns raised by\nclinical research (Hellman and Hellman 1991). A foundational principle\nof clinical medicine is the importance of individual judgment. A\nphysician who decides which treatments her patients receive by\nflipping a coin is guilty of malpractice. A clinical investigator who\nrelies on the same methods receives awards and gets published in elite journals. One might conclude that sacrifice of the interests of\nsome, often sick patients, for the benefit of future patients, is essentially mandated by the scientific method (Miller & Weijer 2006; Rothman\n2000). The history of clinical research seems to provide tragic support for this view. \n\nThe history of clinical research is littered with abuses. Indeed, one account maintains that the history of\npediatric research is “largely one of child abuse”\n(Lederer and Grodin 1994, 19; also see Lederer 2003). This history has had a significant influence on how research ethicists understand\nthe concerns raised by clinical research and on how\npolicy makers attempt to address them. In particular, policy makers have responded to previous abuses by developing guidelines\nintended to prevent their recurrence. \n\nThe most influential abuses in this regard were the horrific experiments conducted by Nazi physicians\nduring WW II (abuses perpetrated by Japanese physicians were equally horrific, but have received significantly less attention). Response to these abuses led to the Nuremberg Code (Grodin & Annas 1996;\nShuster 1997), which is frequently regarded as the\nfirst set of formal guidelines for clinical research, an ironic claim\non two counts. First, there is some debate over whether the Nuremberg\nCode was intended to apply generally to clinical research or whether,\nas a legal ruling in a specific trial, it was intended to address only\nthe cases before the court (Katz 1996). Second, the Germans themselves had\ndeveloped systematic research guidelines as early as 1931 (Vollmann & Winau\n1996). These guidelines were still legally in force at the time of the\nNazi atrocities and clearly prohibited a great deal of what the Nazi\ndoctors did. \n\nIn addition to being ignored by practicing researchers, wide consensus\ndeveloped by the end of the 1950s that the Nuremberg Code was\ninadequate to the ethics of clinical research. Specifically, the\nNuremberg Code did not include a requirement that clinical research\nreceive independent ethics review and approval. In addition, the first\nand longest principle in the Nuremberg Code states that informed\nconsent is “essential” to ethical clinical research\n(Nuremberg Military Tribunal 1947). This requirement provides a\npowerful safeguard against the abuse of research subjects. It also\nappears to preclude clinical research with individuals who cannot\nconsent. \n\nOne could simply insist that the informed consent of subjects is necessary\nto ethical clinical research and accept the opportunity costs thus\nincurred. the impossibility of conducting clinical research on conditions unique to children or unconscious adults. Representatives of the World Medical Association, who hoped\nto avoid these costs, began meeting in the early 1960s to develop\nguidelines, which would become known as the Declaration of Helsinki,\nto address the perceived shortcomings of the Nuremberg Code (Goodyear,\nKrleza-Jeric, and Lemmens 2007). They recognized that insisting on\ninformed consent as a necessary condition for clinical research would\npreclude a good deal of research designed to find better ways to treat\ndementia and conditions affecting children, as well as research in\nemergency situations. Regarding consent as necessary precludes such\nresearch even when it poses only minimal risks or offers subjects a\ncompensating potential for important clinical benefit. The challenge,\nstill facing us today, is to identify protections for research\nsubjects which are sufficient to protect them without being so strict\nas to preclude appropriate research designed to benefit the groups to\nwhich they belong. \n\nThe Declaration of Helsinki (World Medical Organization 1996) allows\nindividuals who cannot consent to be enrolled in clinical research\nbased on the permission of the subject’s representative. The U.S.\nfederal regulations governing clinical research take a similar\napproach.  These regulations are not laws in the strict sense of being\npassed by Congress and applying to all research conducted on\nU.S. soil. Instead, the regulations represent administrative laws\nwhich effectively attach to clinical research at the beginning and the\nend. Research conducted using U.S. federal monies, for instance,\nresearch funded by the NIH, or research involving NIH researchers,\nmust follow the U.S. regulations (Department of Health and Human\nServices 2005). Research that is included as part of an application for approval from the U.S. FDA\nalso must have been conducted according to FDA regulations which,\nexcept for a few exceptions, are essentially the same. Although many\ncountries now have their own national regulations (Brody 1998), the\nU.S. regulations continue to exert enormous influence around the world\nbecause so much clinical research is conducted using U.S. federal\nmoney and U.S. federal investigators, and the developers of medical\ntreatments often want to obtain approval for the U.S. market. \n\nThe abuses perpetrated as part of the infamous Tuskegee syphilis study\nwere made public in 1972, 40 years after the study was initiated. The\nresulting outcry led to the formation of the U.S. National Commission,\nwhich was charged with evaluating the ethics of clinical research with\nhumans and developing recommendations for appropriate\nsafeguards. These deliberations resulted in a series of\nrecommendations for the conduct of clinical research, which became the\nframework for existing U.S. regulations. The U.S. regulations, like\nmany regulations, place no clear limits on the risks to which\ncompetent and consenting adults may be exposed. In contrast, strict\nlimits are placed on the level of research risks to which those unable\nto consent may be exposed, particularly children. In the case of\npediatric research, the standard process for review and approval is\nlimited to studies that offer a ‘prospect of direct’\nbenefit and research that poses minimal risk or a minor increase over\nminimal risk. Studies that do not qualify in one of these categories\nmust be reviewed by an expert panel and approved by a high government\nofficial. While this 4th\ncategory offers important flexibility, it implies that, at least in principle, U.S. regulations do not\nmandate a ceiling on the risks to which pediatric research subjects\nmay be exposed for the benefit of others. This reinforces the\nimportance of considering how we might justify exposing subjects to\nresearch risks, both minimal and greater than minimal, for the benefit\nof others.  \n\nSeveral attempts have been made to justify exposing research subjects\nto risks for the benefit of future patients. Lind’s experiments on\nscurvy exemplify the fact that clinical research is often conducted by\nclinicians and often is conducted on patients. Many commentators have\nthus assumed that the ethics of clinical research should be governed\nby the ethics of clinical care, and the methods of research should not\ndiverge from the methods that are acceptable in clinical care. On\nthis approach, subjects should not be denied any beneficial treatments\navailable in the clinical setting and they should not be exposed to\nany risks not present in the clinical setting. \n\nSome proponents (Rothman 2000) argue that this approach is implied by\nthe kind of treatment that patients, understood as individuals who\nhave a condition or illness needing treatment, are owed. Such\nindividuals are owed treatment that promotes, or at least is\nconsistent with their medical interests. Others (Miller & Weijer\n2006) argue that the norms of clinical research derive largely from\nthe obligations that bear on clinicians. These commentators argue that\nit is unacceptable for a physician to participate in, or even support\nthe participation of her patients in a clinical trial unless that\ntrial is consistent with the patients’ medical interests. To do less\nis to provide substandard medical treatment and to violate one’s\nobligations as a clinician. \n\nThe claim that the treatment of research subjects should be consistent\nwith the norms which govern clinical care has been applied most\nprominently to the ethics of randomized clinical trials (Hellman &\nHellman 1991). Randomized trials determine which treatment a given\nresearch subject receives based on a random process, not based on\nclinical judgment of which treatment would be best for that\npatient. Lind assigned the different existing treatments for scurvy to\nthe sailors in his study based not on what he thought was best for\nthem, but based on what he thought would yield an effective\ncomparative test. Lind did not give each intervention to the same\nnumber of sailors because he thought that all the interventions had an\nequal chance of being effective. To the contrary, he did this because\nhe was confident that several of the interventions were harmful and\nthis design was the best way to prove it. Contemporary clinical\nresearchers go even further, assigning subjects to treatments \nrandomly. Because this aspect of\nclinical research represents a clear departure from the practice of\nclinical medicine it appears to sacrifice the interests of subjects in\norder to collect valid data. \n\nOne of the most influential responses to this concern(Freedman 1987) argues that randomization is\nacceptable when the study in question satisfies what has come to be\nknown as ‘clinical equipoise.’ Clinical equipoise obtains\nwhen, for the population of patients from which subjects will be\nselected, the available clinical evidence does not favor one of the\ntreatments being used over the others. In addition, it must be the\ncase that there are no treatments available outside the trial that are\nbetter than those used in the trial. Satisfaction of these conditions\nseems to imply that the interests of research subjects will not be\nundermined in the service of collecting scientific information.  If\nthe available data do not favor any of the treatments being used,\nrandomizing subjects seems as good a process as any other for choosing\nwhich treatment they receive. \nProponents of clinical equipoise as an ethical requirement for clinical research determine whether equipoise obtains not by appeal to the\nbelief states of individual clinicians, but based on whether there is\nconsensus among the community of experts regarding which treatment is\nbest. Lind believed that sea water was ineffective for the treatment\nof scurvy. Yet, in the absence of agreement among the community of\nexperts, this view essentially constituted an individual preference\nrather than a clinical norm. This suggests that it was acceptable\nfor Lind to randomly assign sailors under his care to the prevailing\ntreatments in order to test, in essence, whose preferred treatment was\nthe best. In this way, the existence of uncertainty within the\ncommunity of experts seems to offer a way to reconcile the methods of\nclinical research with the norms of clinical medicine. \n\nCritics respond that even when clinical equipoise obtains for the\npopulation of patients, the specific circumstances of individual\npatients within that population may imply that one of the treatments\nunder investigation is better for them (Gifford 2007). A specific\npatient may have reduced liver function which places her at greater\nrisk of harm if she receives a treatment metabolized by the\nliver. And some patients may have personal preferences which incline\nthem toward one treatment rather than another (e.g., they may prefer a\none-time riskier procedure to multiple, lower risk procedures which\npose the same collective risk). Current debate focuses on whether\nrandomized clinical trials can take these possibilities into account\nin a way that is consistent with the norms of clinical medicine. \n\nEven if the existence of clinical equipoise can justify some\nrandomized trials, a significant problem remains, namely, many studies and procedures which are\ncrucial to the identification and development of improved methods for\nprotecting and advancing health and well-being are \ninconsistent with subjects’ medical interests. This concern\narises for many phase 1 studies which offer essentially no chance for\nmedical benefit and pose at least some risks, and to that extent are\ninconsistent with the subjects’ medical interests. \n\nPhase 3 studies which randomize subjects to a potential new treatment\nor existing standard treatment, and satisfy clinical equipoise,\ntypically include non-beneficial procedures, such as additional blood\ndraws, to evaluate the drugs being tested. Enrollment in these studies may be consistent with\nsubjects’ medical interests in the sense that the overall risk-benefit\nratio that the study offers is at least as favorable as the available\nalternatives. Yet, evaluation of the overall risk-benefit profile of the study masks the\nfact that it includes individual procedures which are contrary\nto subjects’ medical interests, and contrary to the norms of clinical\nmedicine. \nThe attempt to protect research subjects by appeal to the obligations\nclinicians have to promote the medical interests of their patients\nalso seems to leave healthy volunteers unprotected. Alternatively,\nproponents might characterize this position in terms of clinicians’\nobligations to others in general: clinicians should not perform\nprocedures on others unless doing so promotes the individual’s\nclinical interests. This approach seems to preclude essentially all\nresearch with healthy volunteers. For example, many phase 1 studies\nare conducted in healthy volunteers to determine a safe dose of the\ndrug under study. These studies, vital to drug development, are\ninconsistent with the principle that clinicians should expose\nindividuals to risks only when doing so is consistent with their\nclinical interests. It follows that appeal to clinical equipoise alone\ncannot render clinical research consistent with the norms of clinical\npractice. \n\nCommentators sometimes attempt to justify net-risk procedures that are\nincluded within studies, and studies that overall pose net risks by\ndistinguishing between ‘therapeutic’ and\n‘non-therapeutic’ research (Miller and Weijer 2006). The claim is that the demand\nof consistency with subjects’ medical interests applies only to\ntherapeutic research; non-therapeutic research studies and procedures\nmay diverge from these norms to a certain extent, provided subjects’\nmedical interests are not significantly compromised. The distinction\nbetween therapeutic and non-therapeutic research is sometimes based on\nthe design of the studies in question, and sometimes based on the intentions of\nthe investigators. Studies designed to benefit subjects, or\ninvestigators who intend to benefit subjects are conducting\ntherapeutic studies. Those designed to collect generalizable knowledge\nor in which the investigators intend to do so constitute\nnon-therapeutic research. \n\nThe problem with the distinction between therapeutic and\nnon-therapeutic research so defined is that research itself often is\ndefined as a practice designed to collect generalizable knowledge and\nconducted by investigators who intend to achieve this end (Levine\n1988). On this definition, all research qualifies as\nnon-therapeutic. Conversely, most investigators intend to benefit\ntheir subjects in some way. Perhaps they design the study in a way\nthat provides subjects with clinically useful findings, or they\nprovide minor care not required for research purposes, or referrals to\ncolleagues. Even if one can make good on the distinction between\ntherapeutic and non-therapeutic research in theory, these practices\nappear to render it irrelevant to the practice of clinical\nresearch. More importantly, it is not clear why investigators’\nresponsibilities to patients, or patients’ claims on investigators,\nshould vary as a function of this distinction. Why think\nthat investigators are allowed to expose patients to some risks for\nthe benefit of others, but only in the context of research that is not\ndesigned to benefit the subjects? To apply this proposed resolution to pediatric\nresearch, why might it be acceptable to\nexpose infants to risks for the benefit of others, but only in the\ncontext of studies which offer the infants no chance for personal\nbenefit? \n\nTo take one possibility, it is not clear that this view can be\ndefended by appeal to physicians’ role responsibilities. A prima facie\nplausible view holds that physicians’ role responsibilities apply to\nall encounters between physicians and patients who need medical\ntreatment. This view would imply that physicians may not compromise\npatients’ medical interests when conducting therapeutic studies, but\nalso seems to prohibit non-therapeutic research procedures with\npatients. Alternatively, one might argue that physicians’ role\nresponsibilities apply only in the context of clinical care and so do\nnot apply in the context of clinical research at all. This\narticulation yields a more plausible view, but does not support the\nuse of the therapeutic/ non-therapeutic distinction. It provides no\nreason to think that physicians’ obligations differ based on the type\nof research in question. \nRecent critics argue that these problems highlight the fundamental\nconfusion that results when one attempts to evaluate clinical research\nbased on norms appropriate to clinical medicine. They instead\ndistinguish between the ethics of clinical research and the ethics of\nclinical care, arguing that it is inappropriate to assume that\ninvestigators are subject to the claims and obligations which apply to\nphysicians, despite the fact that the individuals who conduct clinical\nresearch often are physicians (Miller and Brody 2007). \n\nThe claim that clinical research should satisfy the norms of clinical\nmedicine has this strong virtue: it provides a clear method to\nprotect individual research subjects and reassure the public that they\nare being so protected. If research subjects must be treated\nconsistent with their medical interests, we can be reasonably\nconfident that improvements in clinical medicine will not be won at\nthe expense of exploiting them. Most accounts of the ethics of\nclinical research now recognize the limitations of this approach and\nstruggle to find ways to ensure that research subjects are not exposed\nto excessive risks without assuming that the claims of clinical\nmedicine apply to clinical researchers (Emanuel, Wendler, and Grady\n2000; CIOMS 2002). Dismissal of the distinction between therapeutic\nand non-therapeutic research thus yields an increase in both\nconceptual clarity and concern regarding the potential for\nabuse of research subjects. \n\nClinicians, first trained as physicians taught to act in the best\ninterests of the patient in front of them, often struggle with the\nprocess of exposing some patients to risky procedures for the benefit\nof others. It is one thing for philosophers to insist, no matter how\naccurately, that research subjects are not patients and need not be\ntreated according to the norms of clinical medicine. It is another\nthing for clinical researchers to regard research subjects who are\nsuffering from disease and illness as anything other than\npatients. These clinical instincts, while understandable and laudable,\nhave the potential to obscure the true nature of clinical research, as\ninvestigators and subjects alike try to convince themselves that\nclinical research involves nothing more than the provision of clinical\ncare. One way to try to address this collective and often willful\nconfusion would be to identify a justification for exposing research\nsubjects to net risks for the benefit of others.  \n\nIt is often said that those working in bioethics are obsessed with the\nprinciple of respect for individual autonomy. Advocates of this view of bioethicists\ncite the high esteem accorded in the field to the requirement of obtaining\nindividual informed consent and the frequent attempts to resolve\nbioethical challenges by citing its satisfaction. One might assume\nthat this view within bioethics traces to implicit endorsement of a libertarian analysis according to\nwhich it is permissible for competent and informed individuals to do\nwhatever they prefer, provided those with whom they interact are\ncompetent, informed and in agreement. In the words of Mill,\ninvestigators should be permitted to conduct research and expose\nsubjects to risks provided they obtain subjects’ “free,\nvoluntary, and undeceived consent and participation” (On\nLiberty, page 11). Setting aside the question of whether this view accurately characterizes bioethics and bioethicists generally, it does not apply to the vast majority of work done on the\nethics of clinical research. Almost no one in the field\nargues that it is permissible for investigators to conduct any\nresearch they want provided they obtain the free and informed consent\nof the subjects they enroll. \n\nCurrent research ethics does place significant weight on informed\nconsent and many regulations and guidelines devote much of their\nlength to articulating the requirement for informed consent. Yet, as\nexemplified by the response to the Nuremberg Code, almost no one\nregards informed consent as necessary and sufficient for ethical\nresearch.  Most regulations and guidelines, beginning with the \nDeclaration of Helsinki, first adopted in 1964 (World Medical Organization 1996), allow\ninvestigators to conduct research on human subjects only when it has\nbeen approved by an independent group charged with ensuring that the\nstudy is ethically acceptable. Most regulations further place\nlimitations on the types of research that independent ethics\ncommittees may approve. They must find that the research has important\nsocial value and the risks have been minimized before approving it,\nthereby restricting the types of research to which even competent\nadults may consent. Are these requirements justified, or are they\ninappropriate infringements on the free actions of competent\nindividuals?  The importance of answering this question goes beyond\nits relevance to debates over Libertarianism. Presumably, the\nrequirements placed on clinical research have the effect of reducing\nto some extent the number of research studies that get conducted. The\nfact that at least some of the prohibited studies likely would have\nimportant social value, helping to identify better ways to promote\nhealth and well-being, provides a normative reason to eliminate the\nrestrictions, unless there is some compelling reason to retain\nthem. \n\nOne might regard the limitations as betraying the paternalism embedded\nin most approaches to the ethics of clinical research (Miller and Wertheimer 2007). Although the\ncharge of paternalism often carries with it some degree of\ncondemnation, there is a strong history of what is regarded as\nappropriate paternalism in the context of clinical research. This too\nmay have evolved from clinical medicine. Clinicians are charged with\nprotecting and promoting the interests of the patient “in front of\nthem”. Clinician researchers, who frequently begin their careers as\nclinicians, may regard themselves as similarly charged. However, if we\naccept the thesis that clinical research is normatively distinct from\nclinical care, we need some reason to think that the norms for\nclinical care are relevant to clinical research. The fact that these\nrestrictions on the options available to competent adults in the\ncontext of clinical research trace to its close relationship with\nclinical care does not constitute a justification for applying the\nrestrictions to this normatively distinct context. As noted, this is\nespecially important given that the restrictions at least sometimes\nblock otherwise socially valuable research. \n\nThe libertarian claim that valid informed consent is necessary and\nsufficient to justify exposing research subjects to risks for the\nbenefit of others seems to imply, consistent with the first principle\nof the Nuremberg Code, that research with individuals who cannot\nconsent is unethical. This plausible and tempting claim commits one to\nthe view that research with children, research in many emergency\nsituations, and research with the demented elderly all are ethically\nimpermissible. One could consistently maintain such a view but the\nsocial costs of adopting it would be great. It is estimated, for\nexample, that approximately 70% of medications provided to children\nhave not been tested in children, even for basic safety and efficacy\n(Roberts, Rodriquez, Murphy, Crescenzi 2003; Field & Behrman 2004;\nCaldwell, Murphy, Butow, and Craig 2004). Absent clinical research with\nchildren, pediatricians will be forced to continue to provide\nsometimes inappropriate treatment, leading to significant harms that\ncould have been avoided by pursuing clinical research to identify\nbetter approaches. \n\nOne response would be to argue that the Libertarian analysis is not\nintended as an analysis of the conditions under which clinical\nresearch is acceptable. Instead, the claim might be that it provides\nan analysis of the conditions under which it is acceptable to conduct\nclinical research with competent adults. Informed consent is necessary\nand sufficient for enrolling competent adults in research. While this\nview does not imply that research with subjects who cannot consent is\nimpermissible, it faces the not insignificant challenge of providing\nan account for why such research might be acceptable. \nBracketing the question of individuals who cannot consent, many of the\nlimitations on clinical research apply to research with competent\nadults. How might these limitations be justified? One approach would be to essentially grant the Libertarian analysis on theoretical\ngrounds, but then argue that the conditions for its implementation are\nrarely realized in practice. In particular, there are good reasons,\nand significant empirical data, to question how often clinical\nresearch actually involves subjects who are sufficiently informed to\nprovide valid consent. Even otherwise competent adults often fail to\nunderstand clinical research sufficiently to make their own informed\ndecisions regarding whether to enroll (Flory and Emanuel 2004). \nTo consider an example which is much discussed in the research ethics\nliterature, it is commonly assumed that valid consent for randomized\nclinical trials requires individuals to understand randomization. It\nrequires individuals to understand that the treatment they will\nreceive, if they enroll in the study, will be determined by a process\nwhich does not take into account which of the treatments is better for\nthem (Kupst 2003). There is an impressive wealth of data which\nsuggests that many, perhaps most individuals who participate in\nclinical research do not understand this (Snowden 1997; Featherstone\nand Donovan 2002; Appelbaum 2004). The data also suggest that these\nfailures of understanding often are resistant to educational\ninterventions. \n\nIt is sometimes argued that the restrictions placed on clinical\nresearch studies, such as the requirements for independent review and\nminimizing risks, are justified on the grounds of soft\npaternalism. Paternalism involves interfering with the liberty of\nagents for their own benefit (Feinberg 1986; see also entry\non paternalism). As the terms are used\nin the present debate, ‘soft’ paternalism involves\ninterfering with the liberty of an individual in order to promote\ntheir interests on the grounds that the action being interfered with\nis the result of impaired decision-making: “A\nfreedom-restricting intervention is based on soft paternalism only\nwhen the target’s decision-making is substantially impaired, when the\nagent lacks (or we have reason to suspect that he lacks) the\ninformation or capacity to protect his own interests—as\nwhen A prevents B from drinking the liquid in a glass\nbecause A knows it contains poison but B does not”\n(Miller & Wertheimer 2007). ‘Hard’ paternalism, in\ncontrast, involves interfering with the liberty of an individual in\norder to promote their interests, despite the fact that the action\nbeing interfered with is the result of an informed and voluntary\nchoice by a competent individual. \n\nIf the myriad restrictions on clinical research were justified on the\nbasis of hard paternalism they would represent restrictions on\nindividuals’ autonomous actions. However, the data on the extent to\nwhich otherwise competent adults fail to understand what they need to\nunderstand to provide valid consent suggests that the limitations can\ninstead be justified on the grounds of soft paternalism. This suggests that while\nthe restrictions may limit the liberty of adult research subjects, they\ndo not limit their autonomy. In this way, one may regard\nmany of the regulations on clinical research not as inconsistent with\nthe libertarian ideal, but instead as starting from that ideal and\nrecognizing that otherwise competent adults often fail to attain\nit. \n\nEven if most research participants have sufficient understanding to provide valid consent, it would not\nfollow that there should be no limitations on\nresearch with competent adults. The conditions on what one individual may do to another\nare not exhausted by what the second individual consents to.  Perhaps\nsome individuals may choose for themselves to be treated with a lack\nof respect, even tortured. It does not follow that it is acceptable\nfor me or you to treat them accordingly. As independent moral agents\nwe need sufficient reason to believe that our actions, especially the\nways in which we treat others, are appropriate, and this evaluation\nconcerns, in typical cases, more than just the fact that the affected\nindividuals consented to them. \n\nUnderstood in this way, many of the limitations on the kinds of\nresearch to which competent adults may consent are not justified, or\nat least not solely justified, on paternalistic grounds. Instead,\nthese limitations point to a crucial and often overlooked concern in\nresearch ethics. The regulations for clinical research often are\ncharacterized as protecting the subjects of research from\nharm. Although this undoubtedly is an important and perhaps primary\nfunction of the regulations, they also have an important role in\nlimiting the extent to which investigators harm research subjects, and\nlimiting the extent to which society supports and benefits from a\nprocess which inappropriately harms others. It is not just that research subjects\nshould not be exposed to risk of harm without compelling\nreason. Investigators should not expose them to such risks without\ncompelling reason, and society should not support and benefit from their doing so. \n\nThis aspect of the ethics of clinical research has strong connections\nwith the view that the obligations of clinicians restrict what sort of\nclinical research they may conduct. On that view, it is the fact that\none is a physician and is obligated to promote the best interests of\nthose with whom one interacts professionally which determines what one\nis allowed to do to subjects. This connection highlights the pressing\nquestions that arise once we attempt to move beyond the view that\nclinical research is subject to the norms of clinical medicine. There\nis a certain plausibility to the claim that a researcher is not acting\nas a clinician and so may not be subject to the obligations that bear\non clinicians. Or perhaps we might say that the researcher/subject\ndyad is distinct from the physician/patient dyad and is not\nnecessarily subject to the same norms. But, once one concludes that we\nneed an account of the ethics of clinical research, distinct from\nthe ethics of clinical care, one is left with the question of which\nlimitations apply to what researchers may do to research subjects. \n\nIt seems clear that researchers may not expose research subjects to\nrisks without sufficient justification, and also clear that this claim\napplies even to those who provide free and informed consent. The\ncurrent challenge then is to develop an analysis of the conditions\nunder which it is acceptable for investigators to expose subjects to\nrisks and determine to what extent current regulations need to be\nmodified to reflect this analysis. To consider briefly the extent of\nthis challenge, and to underscore and clarify the claim that the\nethics of clinical research go beyond the protection of research\nsubjects to include the independent consideration of what constitutes\nappropriate behavior on the part of investigators, consider an\nexample. \n\nPhysical and emotional abuse cause enormous suffering, and a good deal\nof research is designed to study various methods to reduce instances\nof abuse and also to help victims recover from being abused. Imagine\nthat a team of investigators establishes a laboratory to promote the\nlatter line of research. The investigators will enroll consenting\nadults and, to mimic the experience of extended periods of abuse in\nreal life, they will abuse their subjects emotionally and physically\nfor a week. The abused subjects will then be used in studies to\nevaluate the efficacy of different methods for helping victims to cope\nwith the effects of abuse.  \n\nThe proper response to this proposal is to point out that the fact the\nsubjects are competent and give informed consent does not establish\nthat it is ethically acceptable. One needs to consider many other\nthings. Is the experiment sufficiently similar to real life abuse that\nits results will have external validity? Are there less risky ways to\nobtain the same results? Finally, even if these questions are\nanswered in a way which supports the research, the question remains \nwhether investigators may treat their subjects in this way. The\nfact that essentially everyone working in research ethics would hold\nthat this study is unethical—investigators are not permitted to\ntreat subjects in this way—suggests that research ethics, both\nin terms of how it is practiced and how it should be practiced, goes\nbeyond respect for individual autonomy to include independent\nstandards on investigator behavior. Defining those standards\nrepresents one of the more important challenges for research\nethics.  \n\nAs exemplified by Lind’s experiments on treatments for scurvy,\nclinical research studies were first conducted by clinicians wondering\nwhether the methods they were using were effective. To answer this\nquestion, the clinicians altered the ways in which they treated their\npatients in order to yield information that would allow them to assess\ntheir methods. In this way, clinical research studies intially were\npart of, but an exception to standard clinical practice. As a result,\nclinical research came to be seen as an essentially unique\nactivity. And widespread recognition of clinical research’s scandals\nand abuses led to the view that this activity needed its own extensive\nregulations. \nMore recently, some commentators have come to question the view that\nclinical research is a unique human activity, as well as the\nregulations and guidelines which result from this view. In particular,\nit has been argued that this view has led to overly restrictive\nrequirements on clinical research, requirements that hinder\nscientists’ ability to improve medical care for future patients, and\nalso fail to respect the liberty of potential research subjects. This\nview is often described in terms of the claim that many regulations\nand guidelines for clinical research are based on an unjustified\n‘research exceptionalism’ (Wertheimer 2010). \n\nThe central ethical concern raised by clinical research involves the\npractice of exposing subjects to risks for the benefit of others. Yet,\nour everday activities frequently expose some to risks for the benefit\nof others. When you drive to the store, you expose your neighbors to\nsome increased risk of pollution for the benefits you derive from\nshopping; speeding ambulances expose pedestrians to risks for the\nbenefit of the patients they carry; factories expose their workers to\nrisks for the benefit of their customers; charities expose volunteers\nto risks for the benefit of recipients. Despite this similarity,\nnon-beneficial clinical research is widely regarded as ethically\nproblematic and is subject to significantly greater regulation,\nreview, and oversight (Wilson and Hunter 2010). Almost no one regards\ndriving, ambulances, charities, or factories as inherently\nproblematic. Even those who are not great supporters of a given\ncharity do not argue that it treats its volunteers as guinea pigs. And\nno one argues that charitable activities should satisfy the\nrequirements that are routinely applied to clinical research, such as\nthe requirements for independent review and written consent based on\nan exhaustive description of the risks and potential benefits of the\nactivity, its purpose, duration, scope, and procedures. \n\nGiven that many activities expose some to risks for the benefit of\nothers, yet are not subject to such extensive regulation, some\ncommentators conclude that many of the requirements for clinical\nresearch are unjustified (Sachs 2010, Stewart et al. 2008, and\nSullivan 2008). This work is based on the assumption that, when it\ncomes to regulation and ethical analysis, we should treat clinical\nresearch the way we treat other activities in daily life which involve\nexposing some to risks for the benefit of others. And this assumption\nleads to a straightforward solution to our central ethical problem of\njustifying the practice of exposing research subjects to risks for the\nbenefit of others. \n\nExposing factory workers to risks for the benefit of others is deemed ethically \nacceptable when they agree to do the work and are paid a fair\nwage. The solution suggested for the ethical concern of non-beneficial\nresearch is to obtain consent and pay research\nsubjects a sufficient wage for their efforts. This view is much less\nrestrictive than current regulations for clinical research, but seems\nto be less permissive than a Libertarian analysis. The latter\ndifference is evident in claims that research studies should treat\nsubjects fairly and not exploit them, even if individuals consent to\nbeing so treated. \n\nThe gap between this approach and the traditional view of research\nethics is evident in the fact that advocates of the traditional view\ntend to regard payment of research subjects as exacerbating rather\nthan resolving its ethical concerns, raising, among others, worries of\nundue inducement and commodification. Those who are concerned about\nresearch exceptionalism, in contrast, tend to regard payment as it is\nregarded in most other contexts in daily life: some is good and more\nis better. \n\nThe claims of research exceptionalism have led to valuable discussion\nof the extent to which clinical research differs from other activities\nwhich pose risks to participants for the benefit of others and whether\nany of the differences justify the extensive regulations and\nguidelines standardly applied to clinical research. Proponents of\nresearch exceptionalism who regard many of the existing regulations as\nunjustified face the challenge of articulating an appropriate set of\nregulations for clinical research. While comparisons to factory work\nprovide a useful lens for thinking about the ethics of clinical\nresearch, it is not immediately obvious what positive recommendations\nfollow from this perspective. After all, it is not as if there is\ngeneral consensus regarding the regulations to which industry should\nbe subject. Some endorse minimum wage laws; others oppose them. There\nare further arguments over whether workers should be able to unionize;\nwhether governments should set safety standards for industry; whether\nthere should be rules protecting workers against discrimination. \n\nA few commentators (Caplan 1984; Harris 2005; Heyd 1996) have\nconsidered the possibility of justifying the exposure of \nsubjects to risks for the benefit of others on the grounds that there\nis an obligation to participate in clinical research. One might\ntry to ground this obligation in the fact that current individuals have\nbenefited from clinical research conducted on individuals in the past.\nAt least all individuals who have access to medical care have benefited\nfrom the efforts of previous research subjects in the form of effective\nvaccines and better medical treatment. \n\nCurrent participation in clinical research typically benefits future\npatients. However, if we incur an obligation for the benefits we have\nreceived from previous research studies, we presumably are obligated\nto the patients who participated in those studies, an obligation we\ncannot discharge by participating in current studies. This approach\nalso does not provide a way to justify the very first clinical trials,\nsuch as Lind’s, which of necessity enrolled subjects who had never\nbenefitted from previous clinical research. \n\nAlternatively, one might argue that the obligation to participate does\nnot trace to benefits the individuals in fact received from the\nefforts of previous research participants. Rather, the obligation is\nto the overall social system of which clinical research is a part\n(Brock 1994). For example, one might argue that individuals acquire\nthis obligation as the result of being raised in the context of a\ncooperative scheme or society. We are obligated to do our part because\nof the many benefits we have enjoyed as a result of being born within\nsuch a scheme. \n\nThe first challenge for this view is to explain why the mere enjoyment\nof benefits, without some prospective agreement to respond in kind,\nobligates individuals to help others. Presumably, your doing a nice\nthing for me yesterday, without my knowledge or invitation, does not\nobligate me to do you a good turn today. This concern seems even\ngreater with respect to pediatric research. Children certainly benefit\nfrom previous research studies, but typically do so unknowingly and\noften with vigorous opposition. The example of pediatric research\nmakes the further point that justification of non-beneficial research\non straightforward contractualist grounds will be difficult at best.\nContract theories have difficulties with those groups, such as\nchildren, who do not accept in any meaningful way the benefits of the\nsocial system under which they live (Gauthier 1990). \n\nIn a Rawlsian vein, one might try to establish an obligation to\nparticipate in non-beneficial research based on the choices\nindividuals would make regarding the structure of society from a\nposition of ignorance regarding their own place within that society,\nfrom behind a veil of ignorance (Rawls 1999). To make this argument,\none would have to modify the Rawlsian argument in several\nrespects. The knowledge that one is currently living could well bias\none’s decision against the conduct of clinical research. Those who\nknow they are alive at the time the decision is being made have\nalready reaped many of the benefits they will receive from the conduct\nof clinical research. \n\nTo avoid these biases, we might stretch the veil of ignorance to\nobscure the generation to which one belongs—past, present or\nfuture (Brock 1994). Under a veil of ignorance so stretched,\nindividuals might choose to participate in clinical research,\nincluding non-beneficial research as long as the benefits of the\npractice exceed its overall burdens. One could then argue that justice\nas fairness gives all individuals an obligation to participate in\nclinical research when their turn comes.  This approach seems to have\nthe advantage of explaining why we can expose even children to some\nrisks for the benefit of others, and why parents can give permission\nfor their children to participate in such research. This argument also\nseems to imply not simply that clinical research is acceptable, but\nthat, in a range of cases, individuals have an obligation to participate in it. It implies\nthat adults whose turn has come are obligated to participate in clinical research,\nalthough for practical reasons we might refrain from forcing them to\ndo so. \n\nThis justification for clinical research faces several challenges. First,\nRawlsian arguments typically are used to determine the basic structure\nof society, that is, to determine a fair arrangement of the basic\ninstitutions within the society (Rawls 1999). If the structure\nof society meets these basic conditions, members of the society cannot\nargue that the resulting distribution of benefits and burdens is\nunfair. Yet, even when the structure of society meets the conditions\nfor fairness, it does not follow that individuals are obligated to\nparticipate in the society so structured. Competent adults can decide\nto leave a society that meets these conditions rather than enjoy its benefits (whether they have any\nbetter places to go is another question). The right of exit suggests\nthat the fairness of the system does not generate an obligation to\nparticipate, but rather defends the system against those\nwho would argue that it is unfair to some of the participants over\nothers. At most, then, the present argument can show that it is not\nunfair to enroll a given individual in a research study, that this is\na reasonable thing for all individuals, including those who are unable\nto consent. \n\nSecond, it is important to ask on what grounds individuals behind\nthe veil of ignorance make their decisions. In particular: are these\ndecisions constrained or guided by moral considerations? (Dworkin 1989;\nStark 2000). It seems plausible to think that they would\nbe. After all, we are seeking the\nethical approach or policy with respect to clinical research. The\nproblem, then, is that the answer we get in this case may depend\nsignificantly on which ethical constraints are built into the system,\nrendering the approach question begging. Most importantly, we are considering whether it is ethical to expose subjects who cannot consent to risks for the benefit of others. If it isn’t, then it seems that this should be a limitation on the choices individuals can make from behind the veil of ignorance, in which case appeal to those choices will not be able to justify non-beneficial pediatric research, nor non-beneficial\nresearch with incompetent adults. And if this research is ethical it is unclear why we need this mechanism to justify it.  \n\nProponents might avoid this dilemma by assuming that individuals\nbehind the veil of ignorance will make decisions based purely on\nself-interest, unconstrained by moral limits or\nconsiderations. Presumably, many different systems would satisfy this\nrequirement. In particular, the system that produces the greatest\namount of benefits overall may well be one that we regard as\nunethical. Many endorse the view that clinical research studies which\noffer no potential benefit to subjects and pose a high chance of\nserious risk, such as death, are unethical, independent of the\nmagnitude of the social value to be gained. For example, almost all research ethicists would\nregard as unethical a study which intentionally infects a few subjects\nwith the HIV virus, even when the study offers the potential to identify\na cure for AIDS. Yet, individuals behind the veil of ignorance who\nmake decisions based solely on self-interest might well allow this\nstudy on the grounds that it offers a positive cost-benefit ratio\noverall: the high risks to a few subjects are clearly outweighed by\nthe potential to save the lives of millions. \n\nThe question here is not whether a\nreasonable person would choose to make the poor even worse off in\norder to elevate the status of those more privileged. Rather, both\noptions involve some individuals being in unfortunate circumstances,\nnamely, infected with the HIV virus. The difference is that the one\noption (not conducting the study) involves many more individuals\nbecoming infected over time, whereas the other option involves\nsignificantly fewer individuals being infected, but some as the result\nof being injected in the process of identifying an effective\nvaccine. Since the least desirable circumstances (being infected with\nHIV) are the same in both cases, the reasonable choice, even if one\nendorses the maximin strategy, seems to be whichever option reduces\nthe total number of individuals who are in those circumstances,\nrevealing that, in the present case at least, the Rawlsian approach\nseems not to take into account the way in which individuals end up in\nthe positions they occupy. \n\nLimits on risks are a central part of almost all\ncurrent research regulations and guidelines. With respect to those who can\nconsent, there is an essentially implicit agreement that the risks\nshould not be too high in the context of non-beneficial research (as\nnoted some argue that there should not be any net risks to even\ncompetent adults in the context of so-called therapeutic\nresearch). However, there is no consensus regarding how to determine\nwhich risks are acceptable in this context. With respect to those who cannot consent, many commentators argue that\nnon-beneficial research is acceptable provided that the net risks are\nvery low. The challenge, currently faced by many in clinical research,\nis to identify a standard, and find a reliable way to implement it,\nfor what constitutes a sufficiently low risk in this context. An\ninteresting and important question in this regard is whether the level\nof acceptable risks varies depending on the particular class of\nindividuals who cannot consent. Is the level of acceptable risks the\nsame for individuals who were once competent, such as previously\ncompetent adults with Alzheimer disease, individuals who are not now\nbut are expected to become competent, such as healthy children, and\nindividuals who are not now and likely never will be competent, such\nas individuals born with severe cognitive disabilities? \n\nSome argue that the risks of clinical research qualify as sufficiently\nlow when they are ‘negligible’, understood as risks that\ndo not pose any chance of serious harm (Nicholson 1986). Researchers\nwho ask children a few questions for research purposes may expose them\nto risks no more worrisome than that of being mildly upset for a few\nminutes. It seems not implausible that exposing subjects to a risk of minor harm for the benefit of others does not raise ethical concern. Or one might argue that the ethical concerns it raises do not merit serious ethical concern. Despite\nthe plausibility of these views, very few studies\nsatisfy the negligible risk standard. Even routine procedures that are\nwidely accepted in pediatric research, such as single blood draws,\npose some, typically very low risk of more than negligible harm.   \n\nOthers (Kopelman 2000; Resnik 2005) define risks as sufficiently low\nor ‘minimal’ when they do not exceed the risks individuals\nface during the performance of routine examinations. This standard\nprovides a clear and quantifiable threshold for acceptable risks. Yet, the risks of routine medical procedures for healthy\nindividuals are so low that this standard seems to prohibit intuitively acceptable research. This approach faces the additional\nproblem that, as the techniques of clinical medicine become safer and\nless invasive, increasing numbers of procedures used in non-beneficial\nresearch would be deemed excessively risky. And, at a theoretical\nlevel, one might wonder why we should think that the risks we\ncurrently happen to accept in the context of clinical care for healthy children should\ndefine the level of risk that is acceptable in clinical research. Why think that the ethical acceptability of a non-beneficial blood draw in pediatric research depends on whether clinicians still use blood draws as part of clinical screening for healthy children? \n\nMany guidelines (U.S. Department of Health and Human Services 2005;\nAustralian National Health and Medical Research Council 1999) and\ncommentators take the view that non-beneficial research is ethically\nacceptable as long as the risks do not exceed the risks individuals face\nin daily life. Many of those\ninvolved in clinical research implicitly assume that this minimal risk\nstandard is essentially equivalent to the negligible risk standard. If\nthe risks of research are no greater than the risks individuals face\nin daily life, then the research does not pose risk of any serious\nharm. As an attitude toward many of the risks we face in daily life,\nthis view makes sense.  We could not get through our daily lives if we\nwere conscious of all the risks we face. Crossing the street poses\nmore risks than one can catalog, much less process readily. When these\nrisks are sufficiently low, psychologically healthy individuals place\nthem in the cognitive background, ignoring them unless the\ncircumstances provide reason for special concern (e.g.  one hears a\nsiren, or sees a large gap in the sidewalk). \n\nPaul Ramsey reports that during the deliberations of the National\nCommission on pediatric research, members often used the terms minimal\nand negligible risks in a way which seemed to imply that they were\nwilling to allow minimal risk research, even with children, on the\ngrounds that it poses no chance of serious harm (Ramsey 1978).  The\nmembers then went on to argue that an additional ethical requirement\nfor such research is a guarantee of compensation for any serious\nresearch injuries. This approach to minimal risk pediatric research\nhighlights nicely the somewhat confused attitudes we often have toward\nrisks, especially those of daily life. \n\nWe go about our daily lives as though harms with very low probability are not going to\noccur, effectively treating low probability harms as zero probability\nevents. To this extent, we are not Bayesians about the risks of daily\nlife. We treat some possible harms as impossible for the purposes of\ngetting through the day. This attitude, crucial to living our lives,\ndoes not imply that there are no serious risks in daily life. The fact\nthat our attitude toward the risks of everyday life is justified by\nits ability to help us to get through the day undermines its ability\nto provide an ethical justification for exposing research subjects to\nthe same risks in the context of non-beneficial research (Ross &\nNelson 2006). \n\nFirst, the extent to which we ignore the risks of daily life is not\na fully rational process. In many cases, our attitude regarding risks\nis a function of features of the situation that are not correlated\ndirectly with the risk level, such as our perceived level of control\nand our familiarity with the activity (Tversky, Kahneman 1974; Tversky,\nKahneman 1981; Slovic 1987; Weinstein 1989). Second, to the extent that\nthe process of ignoring some risks is rational, we are involved in a\nprocess of determining which risks are worth paying attention to.\nSome risks are so low that they are not worth paying attention to.\nConsideration of them would be more harmful (would cost us more)\nthan the expected value of being aware of them in the first place. \n\nTo some extent, then, our attitudes in this regard are based on a\nrational cost/benefit analysis. To that extent, these attitudes do not\nprovide an ethical argument for exposing research subjects to risks\nfor the benefit of others. The fact that the costs to an individual of\npaying attention to a given risk in daily life are greater than the\nbenefits to that individual does not seem to have any relevance for\nwhat risks we may expose them to for the benefit of others. Finally,\nthere is a chance of serious harm from many of the activities of daily\nlife.  This reveals that the ‘risks of daily life’\nstandard does not preclude the chance of some subjects experiencing\nserious harm.  Indeed, one could put the point in a much stronger\nway. Probabilities being what they are, the risks of daily life\nstandard implies that if we conduct enough minimal risk research\neventually a few subjects will die and scores will suffer permanent\ndisability. \n\nAs suggested above, a more plausible line of argument would be to\ndefend clinical research that poses minimal risks on the grounds that\nit does not increase the risks to which subjects are exposed.\nIt seems plausible to assume that at any given time an individual will\neither be participating in research or involved in the activities of\ndaily life. But, by assumption, the risks of the two activities are\nessentially equivalent, implying that enrollment in the study, as\nopposed to allowing the subject to continue to participate in the\nactivities of daily life does not increase the risks to which he is\nexposed. \n\nThe problem with this argument is that the risks of research\noften are additive rather than substitutive. For example, participation in a study might require the subject to drive to the\nclinic for a research visit. The present defense succeeds to the\nextent that this trip replaces another trip in the car, or some\nsimilarly risky activity in which the subject would have been\notherwise involved. In practice, this often is not the case. The\nsubject instead may simply put off the trip to the mall until\nafter the research visit. In that case, the subject’s risk of serious\ninjury from a car trip may be doubled as a result of her participation\nin research. Moreover, we accept many risks in daily life because the\nrelevant activities offer those who pursue them a chance of personal\nbenefit. We allow children to take the bus because we assume that the\nbenefits of receiving an education justify the risks. The fact that we\naccept these risks given the potential benefits provides no reason to\nthink that the same risks or even the same level of risk would be\nacceptable in the context of an activity, including a non-beneficial\nresearch study, which offers no chance of medical benefit. Finally,\nand strictly speaking, this justification seems to imply that\ninvestigators should evaluate what risks individuals would face if\nthey did not enroll in the research, and enroll only those who would\notherwise face similar or greater levels of risk. \n\nIn one of the most influential papers in the history of research\nethics, Hans Jonas (1969) argues that the progress clinical\nresearch offers is normatively optional, whereas the need to protect\nindividuals from the harms to which clinical research exposes them is\nmandatory. He writes: \n\nJonas’s view does not imply that clinical research is necessarily\nunethical, but the conditions on when it may be conducted are very\nstrict. This argument may seem plausible to the extent that one\nregards, as Jonas does, the benefits of clinical research to be ones\nthat make an acceptable state in life even better. The example of\narthritis cited by Jonas characterizes this view. Curing arthritis,\nlike curing dyspepsia, baldness, and the minor aches and pains of\nliving and aging, may be nice, but may be thought to address no profound\nproblem in our lives. If this were all that clinical research had to\noffer, we might be reluctant to accept many risks in order to\nachieve its goals. We should not, in particular, take much chance of\nwronging individuals, or exploiting them to realize these goals. \n\nThis argument makes sense to the extent that one regards the status\nquo as acceptable. Yet, without further argument, it is not clear why\none should accept this view; it seems almost certain that those\nsuffering from serious illness that might be addressed by future\nresearch will not accept it. Judgments regarding the present state of\nsociety concern very general level considerations and a determination\nthat society overall is doing fairly well is consistent with many\nindividuals suffering terrible diseases. Presumably, the suffering of\nthese individuals provides some reason to conduct clinical\nresearch. In response, one might understand Jonas to be arguing that\nthe present state of affairs involves sufficiently good medicine and\nadequately flourishing lives such that the needs which could now be\naddressed by additional clinical research are not of sufficient\nimportance to justify the risks raised by conducting it. It might have\nbeen the case, at some point in the past, that life was sufficiently\nnasty, brutish and short to justify running the risk of exploiting\nresearch subjects in the process of identifying through clinical\nresearch ways to improve the human lot. But, we have advanced, in part\nthanks to the conduct of clinical research, well beyond that\npoint. This reading need not interpret Jonas as ignoring the fact that\nthere remain serious ills to be cured. Instead, he might be arguing\nthat these ills, while real and unfortunate, are not of sufficient\ngravity, or perhaps prevalence to justify the risks of conducting\nclinical research.  \n\nThis view implicitly expands the ethical concerns raised by clinical\nresearch. We have been focusing on the importance of protecting\nindividual research subjects. However, Jonas assumes that clinical\nresearch also threatens society in some sense. There are at least two\npossibilities here. First, it might be thought that the conduct of\nunethical research reaches beyond individual investigators to taint\nsociety as a whole. This does not seem unreasonable given that\nclinical research typically is conducted in the name of and often for\nthe benefit of society. Second, one might be concerned that allowing\ninvestigators to expose research subjects to some risks for the\nbenefit of others might put us on a slippery slope that ends with\nserious abuses throughout society. \n\nAn alternative reading would be to interpret Jonas as arguing from\na version of the active-passive distinction. It is often claimed that\nthere is a profound moral difference between actively causing harm\nversus merely allowing harm to occur, between killing\nsomeone versus allowing them to die, for example. Jonas often seems to\nappeal to this distinction when evaluating the ethics of clinical\nresearch. The idea is that conducting clinical research involves\ninvestigators actively exposing individuals to risks of harm and, when\nthose harms are realized, it involves investigators actively harming\nthem. The investigator who injects a subject with an experimental\nmedication in the context of a non-beneficial study actively exposes\nthe individual to risks for the benefit of others and actively harms,\nperhaps even kills those who suffer harm as a result. And, to the\nextent that clinical research is conducted in the name of and for the\nbenefit of society in general, one can say without too much difficulty\nthat society is complicit in causing these harms. Not conducting clinical\nresearch, in contrast, involves our allowing individuals to be subject\nto diseases that we might otherwise have been able to avoid or cure.\nAnd this situation, albeit tragic and unfortunate, has the virtue of\nnot involving clear moral wrongdoing. \n\nThe problem with at least this version of the argument is that the\nbenefits of clinical research often involve finding safer ways to\ntreat disease. The benefits of this type of clinical research, to the\nextent they are realized, involve clinicians being able to provide\nless harmful, less toxic medications to patients. Put differently,\nmany types of clinical research offer the potential to identify\nmedical treatments which harm patients less than current ones. This\nnot an idle goal. One study found that the incidence of serious\nadverse events from the appropriate use of clinical medications\n(i.e. excluding such things as errors in drug administration,\nnoncompliance, overdose, and drug abuse) in hospitalized patients was\n6.7%. The same study, using data from 1994, concludes that the\napproved and properly prescribed use of medications is likely the\n5th leading cause of death in the US (Lazarou, Pomeranz,\nand Corey 1998). \n\nThese data suggest that the normative calculus is significantly more\ncomplicated than the present reading of Jonas suggests. The question\nis not whether it is permissible to risk harming some individuals in\norder to make other individuals slightly better off. Instead, we have\nto decide how to trade off the possibility of clinicians exposing\npatients to greater risks of harm (albeit with a still favorable risk-benefit ratio) in the process of treating them\nversus clinical researchers exposing subjects to risk of harm in the\nprocess of trying to identify improved methods to treat others. This\nis not to say that there is no normative difference between these two\nactivities, only that that difference is not accurately described as\nthe difference between harming individuals versus improving their lot\nbeyond some already acceptable status quo. It is not even a difference\nbetween harming some individuals versus allowing other individuals to\nsuffer harms. The argument that needs to be made is that harming\nindividuals in the process of conducting clinical research potentially\ninvolves a significant moral wrong not present when clinicians harm\npatients in the process of treating them. \nThe primary concern here is that, by exposing subjects to risks\nof harm, the process of conducting clinical research involves the\nthreat of exploitation of a particular kind. It runs the risk of\ninvestigators treating persons as things, devoid of any interests of\ntheir own. The worry here is not so much that investigators and\nsubjects enter together into the shared activity of clinical research\nwith different, perhaps even conflicting goals. The concern is rather\nthat, in the process of conducting clinical research, investigators\ntreat subjects as if they had no goals at all or, perhaps, that any\ngoals they might have are normatively irrelevant. \n\nJonas argues that this concern can be addressed, and the process of\nexperimenting on some to benefit others made ethically acceptable,\nonly when the research subjects share the goals of the research\nstudy. Ethically appropriate research, on Jonas’s\nview, is marked by: “appropriation of the research purpose into\nthe person’s own scheme of ends” (Jonas 1969, 236). And assuming\nthat it is in one’s interests to achieve one’s, at least, proper\ngoals, it follows that, by participating in research, subjects will be\nacting in their own interests, despite the fact that they are thereby\nbeing exposed to risky procedures which are performed to collect\ninformation to benefit others. \n\nJonas claims in some passages that research subjects, at least those\nwith an illness, can share the goals of a clinical research study only\nwhen they have the condition or illness under study (Jonas\n1969). These passages reveal something of the account of human\ninterests on which Jonas’s arguments rely. On standard preference\nsatisfaction accounts of human interests, what is in a given\nindividual’s interests depends on what the individual happens to want\nor prefer, or the goals the individual happens to endorse, or the\ngoals the individual would endorse in some idealized state scrubbed\nclean of the delusions, misconceptions and confusion which inform our\nactual preferences (Griffin 1986). On this view, participation in\nclinical research would promote an individual’s interests as long as\nshe was well informed and wanted to participate. This would be so\nwhether or not she had the condition being studied. Jonas’s view, in\ncontrast, seems to be that there are objective conditions under which\nindividuals can share the goals of a given research study. They can\nendorse the cause of curing or at least finding treatments for\nAlzheimer disease only if they suffer from the disease\nthemselves.  \n\nOne possible objection would be to argue that there are many reasons\nwhy an individual might endorse the goals of a given study, apart from\nthe fact of having the disease themselves. One might have family\nmembers with the disease, or co-religionists, or have adopted improved\ntreatment of the disease as an important personal goal.\n\nThe larger question is whether subjects endorsing the goals of a\nclinical research study is a necessary condition on its\nacceptability. Recent commentators and guidelines rarely, if ever,\nadopt this condition, although at least some of them might be assuming\nthat the requirement to obtain free and informed consent will ensure its\nsatisfaction. It might be assumed, that is, that competent, informed, and free\nindividuals will enroll in research only when they share the goals of\nthe study in question. \n\nJonas was cognizant of the extent to which the normative concerns\nraised by clinical research are not exhausted by the risks to which\nsubjects are exposed, but also include the extent to which\ninvestigators and by implication society are the agents of their \nexposure to risks. For this reason, he recognized that the libertarian response\nis inadequate, even with respect to competent adults who truly\nunderstand. Finally, to the extent Jonas’s claims rely on an objective\naccount of human interests, one may wonder whether he adopts an overly\nrestrictive one. Why should we think, on an objective account, that\nindividuals will have an interest in contributing to the goals of a\ngiven study only when they have the disease it addresses? Moreover,\nalthough we will not pursue the point here, appeal to an objective\naccount of human interests raises the possibility of justifying the\nprocess of exposing research subjects to risks for the benefit of\nothers on the grounds that contributing to valuable projects,\nincluding presumably some clinical research studies, is objectively in\n(most) individuals’ interests (Wendler 2010). \n\nThe fundamental ethical challenge posed by clinical research is\nwhether it is acceptable to expose some to research risks for the\nbenefit of others. In the standard formulation, the one we have been\nconsidering to this point, the benefits that others enjoy as the\nresult of subjects’ participation in clinical research are medical and\nhealth benefits, better treatments for disease, better methods to\nprevent disease. \n\nIndustry funded research introduces the potential for a very different\nsort of benefit and thereby potentially alters, in a fundamental way,\nthe moral concerns raised by clinical research.  Pharmaceutical\ncompanies typically focus on generating profit and increasing stock\nprice and market share. Indeed, it is sometimes argued that\ncorporations have an obligation to their shareholders to pursue\nincreased market share and share price (Friedman 1970). This approach\nmay well lead companies to pursue new medical treatments which have\nlittle or no potential to improve overall health and well-being\n(Huskamp 2006; Croghan and Pittman 2004).  “Me-too” drugs\nare the classic example here. These are drugs identical in all\nclinically relevant respects to approved drugs already in use. The\ndevelopment of a me-too drug offers the potential to redistribute\nmarket share without increasing overall health and well-being. \n\nThere is considerable debate regarding how many me-too drugs there\nreally are and what is required for a drug to qualify as effectively\nidentical (Garattini 1997). For example, if the existing treatment needs to be\ntaken with meals, but a new treatment need not, is that a clinically\nrelevant advance? Bracketing these questions, a drug company may well\nbe interested in a drug which clearly qualifies as a me-too drug. The\ncompany may be able, by relying on a savvy marketing department, to\nconvince physicians to prescribe, and consumers to request the new\none, thus increasing profit for the company without advancing health\nand well-being. \n\nThe majority of clinical research was once conducted by governmental\nagencies. For example, the US NIH is likely the largest governmental sponsor of clinical research in the world. However, its research budget has declined over the past 20 years (Mervis 2004, 2008), and it is estimated that a majority,\nperhaps a significant majority of clinical research studies are\nnow conducted by industry: “as recently as 1991 eighty per cent of\nindustry-sponsored trials were conducted in academic health\ncenters…Impatient with the slow pace of academic bureaucracies,\npharmaceutical companies have moved trials to the private sector,\nwhere more than seventy per cent of them are now conducted”\n(Elliott 2008, Angell 2008, Miller and Brody 2005). \n\nIn addition to transforming the fundamental ethical challenge posed by\nclinical research, industry sponsored research has the potential to\ntransform the way that many of the specific ethical concerns are\naddressed within that context.  For example, the possibility that investigators and\nfunders may earn significant amounts of money from their participation\nin clinical research might, it is thought, warp their judgment in ways\nthat conflict with appropriate protection of research subjects\n(Fontanarosa, Flanagin, and DeAngelis 2005). When applied to\ninvestigators and funders this concern calls into question the very\nsignificant percentage of research funded by and often conducted by\nfor-profit organizations. Skeptics might wonder whether the goal of\nmaking money has any greater potential to influence judgment\ninappropriately compared to many other motivations that are widely\naccepted, even esteemed in the context of clinical research, such as\ngaining tenure and fame, impressing one’s colleagues, or winning the\nNobel Prize. \n\nFinancial conflicts of interest in clinical research point to a\ntension between relying on profits to motivate research versus\ninsulating drug development and testing from the profit motive as a\nway of protecting research subjects and future patients (Psaty and\nKronmal 2008). Finally, if industry can make billions of dollars from the development\nof a single drug one wonders what constitutes an appropriate response\nto the subjects who were vital to the development of the drug in\nquestion. On a standard definition, whether a given transaction is fair depends on the risks and burdens that each party to the transaction bears and the extent to which others benefit from the party’s\nparticipation in the transaction (see entry on\n exploitation). A series of clinical\nresearch studies can result in a company earning tens of billions of dollars\nin profits. Recognizing that a fair level of benefit is a complex\nfunction of participants’ inputs compared to the inputs of others, and\nthe extent to which third parties benefit from those inputs, it is\ndifficult to see how one might fill in the details of this scenario to\nshow that the typically minimal, or non-existent compensation offered\nto research participants is fair. \n\nAt the same time, addressing this potential for exploitation by\noffering substantial payments to research participants who contribute to especially lucrative studies would introduce its own set\nof ethical concerns: is payment an appropriate response to the kind of\ncontribution made by research participants; might payment constitute\nan undue inducement to participate; will payment undermine other\nparticipants’ altruistic motivations; to what extent does payment\nencourage research subject to provide misleading or false information\nto investigators in order to enroll and remain in research studies? In\nthe end, then, as commentators struggle to address the existing\nethical concerns raised by clinical research, its conduct in the real\nworld raises new ethical concerns and, thereby, offers opportunities\nfor philosophers looking for interesting, not to mention practically\nvery important issues in need of analysis and resolution. ","contact.mail":"dwendler@nih.gov","contact.domain":"nih.gov"}]
