[{"date.published":"2019-01-18","url":"https://plato.stanford.edu/entries/counterfactuals/","author1":"William Starr","author1.info":"http://williamstarr.net","entry":"counterfactuals","body.text":"\n\n\nModal discourse concerns alternative ways things can be, e.g., what\nmight be true, what isn’t true but could have been, what should\nbe done. This entry focuses on counterfactual\nmodality which concerns what is not, but could or would have\nbeen. What if Martin Luther King had died when he was stabbed in 1958\n(Byrne 2005: 1)? What if the Americas\nhad never been colonized? What if I were to put that box over here and\nthis one over there? These modes of thought and speech have been the\nsubject of extensive study in philosophy, linguistics, psychology,\nartificial intelligence, history, and many other allied fields. These\ndiverse investigations are united by the fact that counterfactual\nmodality crops up at the center of foundational questions in these\nfields.\n\n\nIn philosophy, counterfactual modality has given rise to difficult\nsemantic, epistemological, and metaphysical questions:\n\nSemantic   How do we communicate and\nreason about possibilities which are remote from the way things\nactually are?\n\nEpistemic   How can our experience in\nthe actual world justify thought and talk about remote\npossibilities?\n\nMetaphysical   Do these remote\npossibilities exist independently from the actual world, or are they\ngrounded in things that actually exist?\n\nThese questions have attracted significant attention in recent\ndecades, revealing a wealth of puzzles and insights. While other\nentries address the\n epistemic—the epistemology of modality—and\n metaphysical\n questions—possible worlds\n and\n actualism—this\n entry focuses on the semantic question. It will aim to refine this\nquestion, explain its central role in certain philosophical debates,\nand outline the main semantic analyses of counterfactuals.\n\n\n\n Section 1\n begins with a working definition of counterfactual conditionals\n (§1.1),\n and then surveys how counterfactuals feature in theories of agency,\nmental representation, and rationality\n (§1.2),\n and how they are used in metaphysical analysis and scientific\nexplanation\n (§1.3).\n Section 1.4 then details several ways in which the logic and\ntruth-conditions of counterfactuals are puzzling. This sets the stage\nfor the sections\n 2\n and\n 3,\n which survey semantic analyses of counterfactuals that attempt to\nexplain this puzzling behavior.\n\n\n\n Section 2\n focuses on two related analyses that were primarily developed to\nstudy the logic of counterfactuals: strict conditional\nanalyses and similarity analyses. These analyses were not originally\nconcerned with saying what the truth-conditions of particular\ncounterfactuals are. Attempts to extend them to that domain, however,\nhave attracted intense criticism.\n Section 3\n surveys more recent analyses that offer more explicit models of when\ncounterfactuals are true. These analyses include premise semantics\n (§3.1),\n conditional probability analyses\n (§3.2)\n and structural equations/causal models\n (§3.3).\n They are more closely connected to work on counterfactuals in\npsychology, artificial intelligence, and the philosophy of\nscience.\n\n\nSections\n 2\n and\n 3\n of this entry employ some basic tools from set theory and logical\nsemantics. But these sections also provide intuitive characterizations\nalongside formal definitions, so familiarity with these tools is not a\npre-requisite. Readers interested in more familiarity with these tools\nwill find\n basic set theory,\n as well as Gamut (1991) and Sider\n(2010) useful.\n\nThis section begins with some terminological issues\n (§1.1).\n It then provides two broad surveys of research that places\ncounterfactuals at the center of key philosophical issues.\n Section 1.2\n covers the role of counterfactuals in theories of rational agency,\nmental representation, and knowledge.\n Section 1.3\n focuses on the central role of counterfactuals in metaphysics and the\nphilosophy of science.\n Section 1.4\n will then bring a bit of drama to the narrative by explaining how\ncounterfactuals are deeply puzzling from the perspective of classical\nand modal logics alike. \nIn philosophy and related fields, counterfactuals are taken to be\nsentences like:  \nThis entry will follow this widely used terminology to avoid\nconfusion. However, this usage also promotes a confusion worth\ndispelling. Counterfactuals are not really conditionals with\ncontrary-to-fact antecedents. For example\n (2)\n can be used as part of an argument that the antecedent is true (Anderson\n1951): \nOn these grounds, it might be better to speak instead of\nsubjunctive conditionals, and reserve the term\ncounterfactual for subjunctive conditionals whose antecedent\nis assumed to be false in the\n discourse.[1]\n While slightly more enlightened, this use of the term does not match\nthe use of counterfactuals in the sprawling philosophical and\ninterdisciplinary literature surveyed here, and has its own drawbacks\nthat will be discussed shortly. This entry will use counterfactual\nconditional and subjunctive conditional interchangeably,\nhoping to now have dispelled the suggestion that all counterfactuals,\nin that sense, have contrary-to-fact antecedents. \nThe terminology of indicative and subjunctive conditionals is also\nvexed, but it aims to get at a basic contrast which begins between two\ndifferent forms of conditionals that can differ in truth value.\n (3)\n and\n (4)\n can differ in truth-value while holding fixed the world they are\nbeing evaluated\n in.[2] \nIt is easy to imagine a world where\n (3)\n is true, and\n (4)\n false. Consider a world like ours where Kennedy was assassinated.\nFurther suppose Oswald didn’t do it, but some lone fanatic did\nfor deeply idiosyncratic reasons. Then\n (3)\n is true and\n (4)\n false. Another aspect of the contrast between indicative and\nsubjunctive conditionals is illustrated in\n (5)\n and\n (6).\n  \nIndicatives like\n (5)\n are infelicitous when their antecedent has been denied, unlike the\nsubjunctives like\n (6)\n and\n (7)\n (Stalnaker 1975; Veltman 1986). \nThe indicative and subjunctive conditionals above differ from each\nother only in particular details of their linguistic form. It is\ntherefore plausible to explain their contrasting semantic behavior in\nterms of the semantics of those linguistic differences. Indicatives,\nlike\n (3)\n and\n (5),\n feature verbs in the simple past tense form, and no modal auxiliary\nin the consequent. Subjunctives, like\n (4)\n and\n (6),\n feature verbs in the past perfect (or “pluperfect”) with\na modal would in the consequent. Something in the\nneighborhood of these linguistic and semantic differences constitutes\nthe distinction between indicative and subjunctive\nconditionals—summarized in\n Figure 1.[3] \nFigure 1: Rough Guide to Indicative and\nSubjunctive Conditionals \nAs with most neighborhoods, there are heated debates about the exact\nboundaries and the names—especially when future-oriented\nconditionals are included. These debates are surveyed in the\nsupplement\n Indicative and Subjunctive Conditionals.\n The main entry will rely only on the agreed-upon paradigm examples\nlike\n (3)\n and\n (4).\n The labels indicative and subjunctive are also\nflawed since these two kinds of conditionals are not really\ndistinguished on the basis of whether they have indicative or\nsubjunctive mood in the antecedent or\n consequent.[4]\n But the terminology is sufficiently entrenched to permit this\ndistortion of linguistic reality. \nMuch recent work has been devoted to explaining how the semantic\ndifferences between indicative and subjunctive conditionals can be\nderived from their linguistic differences—rather than treating\nthem as semantically unrelated. Much of this work has been done in\nlight of Kratzer’s (1986, 2012)\ngeneral approach to modality according to which all conditionals are\ntreated as two-place modal operators. This approach is also discussed\nin the supplement\n Indicative and Subjunctive Conditionals.[5]\n This entry will focus on the basic logic and truth-conditions of\nsubjunctive conditionals as a whole, and will use the following\nnotation for them (following Stalnaker\n 1968).[6] \nThis project and notation has an important limitation that should be\nhighlighted: it combines the meaning of the modal would and\nif…then… into a single connective\n“\\(>\\)”. This makes it difficult to adequately\nrepresent subjunctive conditionals like:  \nConditionals like\n (8a)\n have figured in debates about the semantics of counterfactuals and\nhave been modeled either as a related connective (D.\nLewis 1973b: §1.5) or a normal\nwould-subjunctive conditional embedded under might\n(Stalnaker 1980, 1984: Ch.7). But the\nmore complex examples\n (8b)–(8d)\n highlight the need for a more refined compositional analysis, like\nthose surveyed in\n Indicative and Subjunctive Conditionals.\n So, while this notation will be used in\n §1.4\n and throughout\n §2\n and\n §3,\n it should be regarded as an analytic convenience rather than a\ndefensible assumption. \nCounterfactuals have played prominent and interconnected roles in\ntheories of rational agency. They have figured prominently in views of\nwhat agency and free will amount to, and played important roles in\nparticular theories of mental representation, rational decision\nmaking, and knowledge. This section will outline these uses of\ncounterfactuals and begin to paint a broader picture of how\ncounterfactuals connect to central philosophical questions. \nA defining feature of agents is that they make choices. Suppose a\ncitizen votes, and in doing so chooses to vote for X rather\nthan Y. It is hard to see how this act can be a choice without\na corresponding counterfactual being true:  \nThe idea that choice entails the ability to do otherwise has been\ntaken by many philosophers to underwrite our practice of holding\nagents responsible for their choices. But understanding the precise\nmeaning of the counterfactual could have claim in\n (9)\n requires navigating the classic problem of free will: if we live in a\nuniverse where the current state of the universe is determined (or\nnear enough) by the prior state of the universe and the physical laws,\nthen it seems like every action of every agent, including their\n“choices”, are predetermined. So interpreting this\nintuitively plausible counterfactual\n (9)\n leads quite quickly to a deep philosophical dilemma. One can\nmaintain, with some Incompatibilists, that\n (9)\n is a false claim about what’s physically possible, and revisit\nthe understanding of agency, choice, and responsibility\nabove—the entry\n incompatibilist theories of free will\n explores this\n further.[7]\n Alternatively, one can maintain that\n (9)\n is a true claim about some non-physical sense of possibility, and\nexplain how that is appropriate to our understanding of choice and\nresponsibility—the entry\n compatibilism\n explores this further. It is wrong to construe debates about free\nwill as just debates about the meaning of counterfactuals.\nBut, the semantics of counterfactuals can have a substantive impact on\ndelimiting the space of possible solutions, and perhaps even deciding\nbetween them. The same is true for research on counterfactual thinking\nin psychology. \nExperiments in social psychology suggest that belief in free will is\nlinked to increased counterfactual thinking (Alquist\net al. 2015). Further, they have\nshown that counterfactually reflecting on past events and choices is\none significant way humans imbue life experiences with meaning and\ncreate a sense of self (Galinsky et al. 2005;\nHeintzelman et al. 2013; Kray et al. 2010). Incompatibilists\nmight be able to cite this result as an explanation for why so many\npeople believe they have free will. It is a specific form of wishful\nthinking: it is interwoven with the practices of counterfactual\nreflection that give our lives meaning. Seto et\nal. (2015) support this idea by showing that variation in\nsubjects’ belief in free will predicts how much meaning they\nderive from relevant instances of counterfactual reflection. This\nmight even be used as part of a pragmatic argument for believing in\nfree will: roughly, belief in free will is so practically important,\nand our knowledge of the world so incomplete, that it is rational to\nbelieve that it\n exists.[8] \nCounterfactual reflection is not just used for the\n“sentimental” purposes discussed above, but as part of\nwhat Byrne (2005) calls rational\nimagination. This capacity is implicated in many philosophical\ndefinitions of rational agency. According to the standard model,\nagency involves intentional action—see entries\n agency\n and\n action.\n While choices are intentional actions, intentional actions are a more\ngeneral class of actions which, on most views, are in part caused by\nintentions—see entry\n intention.\n One prominent understanding of intentions is that they are\nprospective (forward looking) mental states that play a crucial role\nin planning actions. Byrne (2005, 2016:\n138) details psychological evidence showing that counterfactual\nthinking is central to forming rational intentions. People use\ncounterfactual thinking after particular events to formulate plans\nthat will improve the outcome of their actions in related scenarios.\nExamples include aviation pilots thinking after a near-accident\n“if I had understood the controller’s words accurately, I\nwouldn’t have initiated the inappropriate landing\nattempt”, and blackjack players thinking “If I’d\ngotten the 2, I would have beaten the dealer”. People who reason\nin this way show more persistence and improved performance in related\ntasks, while those who dwell on how things could have been worse, or\ndo not counterfactually reflect at all, show less persistence and no\nimprovement in performance. Finally, human rationality can become\ndisordered when counterfactual thinking goes astray, e.g., in\ndepression, anxiety, and schizophrenia (Byrne\n2016: 140–143). \nThis psychological research shows that rational human agents\ndo learn from the past and plan for the future engaging in\ncounterfactual thinking. Many researchers in artificial intelligence\nhave voiced similar ideas (Ginsberg 1985; Pearl\n1995; Costello & Mccarthy 1999). But, this view is distinct\nfrom a stronger philosophical claim: that the nature of rational\nagency consists, in part, in the ability to perform counterfactual\nthinking. Some versions of causal decision theory make precisely this\nclaim, and do so to capture similar patterns of rational behavior.\nNewcomb’s Problem (Nozick 1969)\nconsists of a decision problem which challenges the standard way of\narticulating the idea that rational agents maximize expected utility,\nand, according to some philosophers (Stalnaker\n1972 [1980]; Gibbard & Harper 1978), shows that causal or\ncounterfactual reasoning must be included in rational decision\nprocedures—see the entry\n causal decision theory\n for further details. In a similar vein, work on belief revision\ntheory explores how a rational agent should revise their beliefs when\nthey are inconsistent with something they have just learned—much\nlike a counterfactual antecedent demands—and uses structures\nthat formally parallel those used in the semantics of counterfactuals\n(Harper 1975; Gärdenfors 1978, 1982; Levi\n1988). See\n formal representations of belief\n for further discussion of this literature. \nThe idea that counterfactual reasoning is central to rational agency\nhas surfaced in another way in cognitive science and artificial\nintelligence, where encoding counterfactual-supporting relationships\nhas emerged as a major theory of mental representation (Chater\net al. 2010). These disciplines also\nstudy how states of mind like belief, desire, and intention explain\nrational agency. But they are not satisfied with just showing that\ncertain states of mind can explain certain choices and actions. They\naim to explain how those particular states of mind lead to\nthose choices and actions. They do so by characterizing those states\nof mind in terms of representations, and formulating particular\nalgorithms for using those representations to learn, make choices and\nperform\n actions.[9]\n Many recent advances in cognitive science and artificial intelligence\nshare a starting point with Bayesian epistemology: agents must learn\nand decide what to do despite being uncertain what exactly the world\nis like, and these processes can be modeled in the probability\ncalculus. On a simple Bayesian approach, an agent represents the world\nwith a probability distribution over binary facts or variables that\nrepresent what the world is like. But even for very simple domains the\nprobability calculus does not provide computationally tractable\nrepresentations and algorithms for implementing Bayesian intelligence.\nThe tools of Bayesian networks, structural equations\nand causal models, developed by Spirtes,\nGlymour, and Scheines (1993, 2000)\nand Pearl (2000, 2009) address this\nlimitation, and also afford simple algorithms for causal and\ncounterfactual reasoning, among other cognitive processes. This\nframework represents an agent’s knowledge in a way that puts\ncounterfactuals and causal connections at the center, and the tools it\nprovides have been influential beyond cognitive science and AI. It has\nalso been applied to topics covered later in this entry: the semantic\nanalyses of counterfactuals\n (§3.2)\n and metaphysical dependence, causation and scientific explanation\n (§1.3).\n For this reason, it will be useful to describe its basics now, though\nstill focusing on its applications to mental representation. What\nfollows is a simplified version of the accessible introduction in\nSloman (2005: Ch.4). For a more thorough\nintroduction, see Pearl (2009:\nCh.1). \nIn a Bayesian framework, probabilities are real numbers between 0 and\n1 assigned to propositional variables A, B,\nC,…. These probabilities reflect an agent’s\nsubjective credence, e.g., \\(P(A)=0.6\\) reflects that they think\nA is slightly more likely than not to be\n true.[10]\n At the heart of Bayesian Networks are the concepts of conditional\nprobability and two variables being probabilistically\nindependent. \\(P(B \\mid A)\\) is the credence in B\nconditional on A being true and is defined as follows: \nConditional probabilities allow one to say when B is\nprobabilistically independent of A: when an agent’s\ncredence in B is the same as their credence in B\nconditional on A and conditional on \\(\\neg A\\). \nBayesian networks represent relations of probabilistic dependence. For\nexample, an agent’s knowledge about a system containing eight\nvariables could be represented by the directed acyclic graph and\nsystem of structural equations between those variables in\n Figure 2. \nFigure 2: Bayesian Network and\nStructural Equations. [An\n extended description of figure 2\n is in the supplement.] \nWhile the arrows mark relations of probabilistic dependence, the\nequations characterize the nature of the dependence, e.g.,\n“\\(H\\dequal F\\lor G\\)” means that the value of H is\ndetermined by the value of \\(F\\lor G\\) (but not vice versa).[11]\n This significantly reduces the number of values that must be\n stored.[12]\n But it also stores information that is useful to agents. It\nfacilitates counterfactual reasoning—e.g., if C had been\ntrue then G would have been true—reasoning about\nactions—e.g., if we do A then C will be\ntrue—and explanatory reasoning—e.g., H is true in\npart because C is true (Pearl\n2002). \nThe usefulness of Bayesian networks is evidenced by their many\napplications in psychology (e.g., Glymour 2001;\nSloman 2005) and artificial intelligence (e.g., Pearl\n2009, 2002)). They are among the key\nrepresentations employed in autonomous vehicles (Thrun\net al. 2006; Parisien & Thagard\n2008), and have been applied to a wide range of cognitive\nphenomena: \nAs Sloman (2005: 177) highlights, this\nform of representation fits well with a guiding idea of embodied\ncognition: mental representations in biological agents are constrained\nby the fact that their primary function is to facilitate successful\naction despite uncertain information and bounded computational\nresources. Bayesian networks have also been claimed to address a deep\nand central issue in artificial intelligence called the frame problem\n(e.g., Glymour 2001: Ch. 3). For the\npurposes of this entry, it is striking how fruitful this approach to\nmental representation has been, since counterfactual dependence is at\nits core. \nCounterfactual dependence has also featured prominently in theories of\nmental content, which explain how a mental representation like the\nconcept dog comes to represent dogs.\nInformational theories take their inspiration from natural\nrepresentations like tree rings, which represent, in some sense, how\nold the tree is (Dretske 2011). While\nsome accounts in this family are called “causal theories of\nmental content”, it is somewhat limiting to formulate the view\nas: X represents Y just in case Y causes\nX. Even for the tree rings, it is metaphysically controversial\nto claim that the tree rings are caused by the age of the tree, rather\nthan thinking they have a common cause or are merely causally related\nvia a number of laws and factors, e.g., rainfall, seasons, growth\nperiods. For this and other reasons, Dretske\n(1981, 1988, 2002) formulates the relationship in terms of\nconditional probabilities: \nOn this view, the state of the tree rings carries the information that\nthe tree is a certain age, since given the background conditions in\nour world the relevant conditional probability is 1. As argued by\nLoewer (1983: 76) and Cohen\nand Meskin (2006), this formulation\nintroduces problematic issues in how to interpret the probabilities\ninvolved and these problems are avoided by a counterfactual\nformulation: \nEven this theory of information requires several elaborations to\nfurnish a plausible account of mental content. For example, Dretske\n(1988, 2002) holds that a mental\nrepresentation r represents that a is F just in\ncase r has the function of indicating that a is\nF. The teleological (“function”) component is added\nto explain how a deer on a dark night can cause tokens of the concept\ndog without being part of the information\ncarried by thoughts that token dog. Fodor\n(1987, 1990) pursues another,\nnon-teleological solution, the asymmetric dependence theory.\nCounterfactuals feature here in another way: \nThis approach also appeals to laws, which are another key\nphilosophical concept connected to counterfactuals—see\n §1.3\n below. \nCounterfactuals are not just used to analyze how a given mental state\nrepresents reality, but also when a mental state counts as knowledge.\nNumerous counterexamples, like Gettier cases, make the identification\nof knowledge with justified true belief problematic—for further\ndetails see\n the analysis of knowledge.\n But some build on this analysis by proposing further conditions to\naddress these counterexamples. Two counterfactual conditions are\nprominent in this literature: \nBoth concepts are ways of articulating the idea that S’s\nbeliefs must be formed in a way that is responsive to p being\ntrue. The semantics of counterfactuals have interacted with this\nproject in a number of ways: in establishing their non-equivalence,\nrefining them, and adjudicating putative counterexamples. \nCounterfactuals have played an equally central role in metaphysics and\nthe philosophy of science. They have featured in metaphysical theories\nof causation, supervenience, grounding, ontological dependence, and\ndispositions. They have also featured in issues at the intersection of\nmetaphysics and philosophy of science like laws of nature and\nscientific explanation. This section will briefly overview these\napplications, largely linking to related entries that cover these\napplications in more depth. But, this overview is more than just a\nlist of how counterfactuals have been applied in these areas. It helps\nidentify a cluster of inter-related concepts (and/or properties) that\nare fruitfully studied together rather than in isolation. \nMany philosophers have proposed to analyze causal concepts in terms of\ncounterfactuals (e.g., D. Lewis 1973a,\nMackie 1974). The basic idea is that\n (10)\n can be understood in terms of something like\n (11)\n (see\n counterfactual theories of causation\n for further discussion).  \nThis basic idea has been elaborated and developed in several ways.\nD. Lewis (1973a, c) refines it using his\nsimilarity semantics for counter­factuals—see\n §2.3.\n The resulting counterfactual analysis of causation faces a number of\nchallenges—see\n counterfactual theories of causation\n for discussion and references. But this has simply inspired a new\nwave of counterfactual analyses that use different tools. \nHitchcock (2001, 2007) and Woodward\n(2003: Ch.5) develop counterfactual\nanalyses of causation using the tools of Bayesian networks (or\n“causal models”) and structural equations described back\nin\n §1.2.3.\n The rough idea of the analysis is as follows. Given a graph like the\none in\n Figure 2,\n X can be said to be a cause of Y just in case there is\na path from X to Y and changing just the value of\nX changes the value of Y. According to Hitchcock\n(2001) and Woodward\n(2002, 2003), this analysis of\ncausation counts as a counterfactual analysis because the basic\nstructural equations, e.g., \\(C\\dequal A\\land B\\), are best understood\nas primitive counterfactual claims, e.g., if A and B had\nbeen true, C would have been true. While not all theories of\ncausation that employ structural equations are counterfactual\ntheories, structural equations are central to many of the contemporary\ncounterfactual theories of\n causation.[13]\n See\n counterfactual theories of causation\n for further developments and critical reactions to this account of\ncausation. \nRecently, Schaffer (2016) and Wilson\n(2018) have also used structural\nequations to articulate a counterfactual theory of metaphysical grounding.[14]\n Metaphysical grounding is a concept widely employed in metaphysics\nthroughout its history, but has been the focus of intense attention\nonly recently—see entry\n metaphysical grounding\n for further details. As Schaffer (2016)\nputs it, the fact that Koko the gorilla lives in California is not a\nfundamental fact because it is grounded in more basic facts about the\nphysical world, perhaps facts about spacetime and certain physical\nfields. Statements articulating these grounding facts constitute\ndistinct metaphysical explanations. So conceived, metaphysical\ngrounding is among the most central concepts in metaphysics. The key\nproposals in Schaffer (2016) and Wilson\n(2018) are to use structural equations\nto model grounding relations, and not just causal relations, and in\ndoing so capture parallels between causation and grounding. Indeed,\nthey define grounding in terms of structural equations in the same way\nas the authors above defined causation in terms of structural\nequations. The key difference is that the equations articulate what\ngrounds what. While this approach to grounding has its critics (e.g.,\nKoslicki 2016), it is worth noting here\nsince it places counterfactuals at the center of metaphysical explanations.[15]\n Counterfactuals have been implicated in other key metaphysical\ndebates. Work on dispositions is a prominent example. A glass’s\nfragility is a curious property: the glass has it in virtue of\npossibly shattering in certain conditions, even if those\nconditions are never manifested in the actual world, unlike say, the\nglass’s shape. This dispositional property is quite naturally\nunderstood in terms of a counterfactual claim:  \nEarly analyses of this form were pursued by Ryle\n(1949), Quine\n(1960), and Goodman (1955), and\nhave remained a major position in the literature on dispositions. See\n dispositions\n for further discussion and references. \nIt is not just metaphysical explanation where counterfactuals\nhave been central. They also feature prominently in accounts of\nscientific explanation and laws of nature. Strict empiricists\nhave attempted to characterize scientific explanation without reliance\non counterfactuals, despite the fact that they tend to creep\nin—for further background on this see\n scientific explanation.\n Scientific explanations appeal to laws of nature, and laws of nature\nare difficult to separate from counterfactuals. Laws of nature are\ncrucially different from accidental generalizations, but how? One\nprominent idea is that they “support counterfactuals”. As\nChisholm (1955: 97) observed, the\ncounterfactual\n (14)\n follows from the corresponding law\n (13)\n but the counterfactual\n (16)\n does not follow from the corresponding accidental generalization\n (15).\n  \nA number of prominent views have emerged from pursuing this\nconnection. Woodward (2003) argues that\nthe key feature of an explanation is that it answers\nwhat-if-things-had-been-different questions, and integrates\nthis proposal with a structural equations approach to causation and\n counterfactuals.[16]Lange (1999, 2000, 2009) proposes an\nanti-reductionist account of laws according to which they are\nidentified by their invariance under certain counterfactuals. Maudlin\n(2007: Ch.1) also proposes an\nanti-reductionist account of laws, but instead uses laws to define the\ntruth-conditions of counterfactuals relevant to physical explanations.\nFor more on these views see\n laws of nature. \nIt should now be clear that a wide variety of central philosophical\ntopics rely crucially on counterfactuals. This highlights the need to\nunderstand their semantics: how can we systematically specify what the\nworld must be like if a given counterfactual is true and capture\npatterns of valid inference involving them? It turns out to be rather\ndifficult to answer this question using the tools of classical logic,\nor even modal logic. This section will explain why. \nLogical semantics (Frege 1893; Tarski 1936;\nCarnap 1948) provided many useful analyses of English\nconnectives like and and not using Boolean\ntruth-functional connectives like \\(\\land\\) and \\(\\neg\\).\nUnfortunately, such an analysis is not possible for counterfactuals.\nIn truth-functional semantics, the truth of a complex sentence is\ndetermined by the truth of its parts because a connective’s\nmeaning is modeled as a truth-function—a function from one or\nmore truth-values to another. Many counterfactuals have false\nantecedents and consequents, but some are true and others false.\n (17a)\n is false—given Joplin’s critiques of\nconsumerism—and\n (17b)\n is true. \nIt may be useful to state the issue a bit more precisely. \nIn truth-functional semantics, the truth-value (True/False: 1/0) of a\ncomplex sentence is determined by the truth-values of its parts and\nparticular truth-function expressed by the connective. This is\nillustrated by the truth-tables for negation \\(\\neg\\), conjunction\n\\(\\land\\), and the material conditional \\(\\supset\\) in\n Figure 3. \nFigure 3: Negation (\\(\\neg\\)),\nConjunction (\\(\\land\\)), Material Conditional (\\(\\supset\\)) \nTruth-functional logic is inadequate for counterfactuals not just\nbecause the material conditional \\(\\supset\\) does not capture the fact\nthat some counterfactuals with false antecedents like\n (17a)\n are false. It is inadequate because there is, by definition, no\ntruth-functional connective whatsoever that simultaneously combines\ntwo false sentences to make a true one like\n (17b)\n and combines two false ones to make a false one like\n (17a).\n In contemporary philosophy, this is overwhelmingly seen as a failing\nof classical logic. But there was a time at which it fueled skepticism\nabout whether counterfactuals really make true or false claims about\nthe world at all. Quine (1960: §46, 1982:\nCh.3) voices this skepticism and supports it by highlighting\npuzzling pairs like\n (18)\n and\n (19):\n  \nQuine (1982: Ch.3) suggests that no\nstate of the world could settle whether\n (19a)\n or\n (19b)\n is true. Similarly he contends that it is not the world, but\nsympathetically discerning the speaker’s imagination and purpose\nin speaking that matters for the truth of\n (18b)\n versus\n (18a)\n (Quine 1960: §46). Rather than\npromoting skepticism about a semantic analysis of counterfactuals,\nLewis (1973b: 67) took these examples as\nevidence that their truth-conditions are\ncontext-sensitive: the possibilities that are\nconsidered when evaluating the antecedent are constrained by the\ncontext in which the counterfactual is asserted, including the\nintentions and practical ends of the speaker. All contemporary\naccounts of counterfactuals incorporate some version of this\n idea.[17] \nPerhaps the most influential semantic puzzle about counterfactuals was\nhighlighted by Goodman (1947), who\nnoticed that adding more information to the antecedent can actually\nturn a true counterfactual into a false one. For example,\n (20a)\n could be true, while\n (20b)\n is false. \nLewis (1973c: 419; 1973b: 10) dramatized\nthe problem by considering sequences such as\n (21),\n where adding more information to the antecedent repeatedly flips the\ntruth-value of the counterfactual. \nThe English discourse\n (21)\n is clearly consistent: it is nothing like saying I shirked my\nduty and I did not shirk my duty. This property of\ncounterfactual antecedents is known by a technical name,\nnon-monotonicity, and is one of the features all contemporary\naccounts are designed to capture. As will be discussed in\n §2.2,\n even modal logic does not have the resources to capture semantically\nnon-monotonic operators. \nGoodman (1947) posed another influential\nproblem. Examples\n (20a)\n and\n (20b)\n show that the truth-conditions of counterfactuals depend on assumed\nbackground facts like the presence of oxygen. However, a\nmoment’s reflection reveals that specifying all of these\nbackground facts is quite difficult. The match must be dry, oxygen\nmust be present, wind must be below a certain threshold, the friction\nbetween the striking surface and the match must be sufficient to\nproduce heat, that heat must be sufficient to activate the chemical\nenergy stored in the match head, etc. Further, counterfactuals like\n (20a)\n also rely for their truth on physical laws specific to our world,\ne.g., the conservation of energy. Goodman’s problem is this: it\nis difficult to adequately specify these background conditions and\nlaws without further appealing to counterfactuals. This is clearest\nfor laws. As discussed in\n §1.3,\n some have aimed to distinguish laws from accidental generalizations\nby noting that only the former support counterfactuals. But if this is\na defining feature of laws, and laws are part of the definition of\nwhen a counterfactual is true, circularity becomes a concern. Explicit\nanalyses of laws in terms of counterfactuals, like Lange\n(2009), would make an analysis of\ncounterfactuals in terms of laws circular. \nThe potential circularity for background conditions takes a bit more\nexplanation. Suppose one claims to have specified all of the\nbackground conditions relevant to the truth of\n (20a),\n as in\n (22a).\n Then it is tempting to say that\n (20a)\n is true because\n (22c)\n follows from\n (22a),\n (22c), and the physical laws. \nBut now suppose there is an agent seeing to it that a fire is not\nstarted, and will only strike the match if it is wet. In this case the\ncounterfactual\n (20a)\n is intuitively false. However, unless one adds the counterfactual,\nif the match were struck, it would have to be wet, to the\nbackground conditions,\n (22c)\n still follows from\n (22a),\n (22c), and the physical laws. That would incorrectly predict\nthe counterfactual to be true. In short, it seems that the background\nconditions must themselves consist of counterfactuals. Any analysis of\ncounterfactuals that captures their sensitivity to background facts\nmust either eliminate these appeals to counterfactuals, or show how\nthis appeal is non-circular, e.g., part of a recursive, non-reductive\nanalysis. \nTo summarize, this section has identified three key theses about the\nsemantics of counterfactuals and a central problem: \nThese theses, along with Goodman’s Problem, were once grounds\nfor skepticism about the coherence of counterfactual discourse. But\nwith advances in semantics and pragmatics, they have instead become\nthe central features of counterfactuals that contemporary analyses aim\nto capture. \nThis section will survey two semantic analyses of counterfactuals: the\nstrict conditional analysis and the\nsimilarity analysis. These conceptually related\nanalyses also have a shared explanatory goal: to capture logically\nvalid inferences involving counterfactuals, while treating them\nnon-truth-functionally, leaving room for their context dependence, and\naddressing the non-monotonic interpretation of counterfactual\nantecedents. Crucially, these analyses abstract away Goodman’s\nProblem because they are not primarily concerned with the\ntruth-conditions of particular counterfactuals—just as classical\nlogic does not take a stand on which atomic sentences are actually\ntrue. Instead, they say only enough about truth-conditions to settle\nmatters of logic, e.g., if \\(\\phi\\) and \\(\\phi>\\psi\\) are true,\nthen \\(\\psi\\) is true. Sections\n 2.5\n and\n 2.6\n will revisit questions about the truth-conditions of particular\ncounterfactuals, Goodman’s Problem and the philosophical\nprojects surveyed in\n §1. \nThe following subsections will detail strict conditional and\nsimilarity analyses. But it is useful at the outset to consider\nsimplified versions of these two analyses alongside each other. This\nwill clarify their key differences and similarities. Both analyses are\nalso stated in the framework of possible world semantics developed in\nKripke (1963) for modal logics. The\nfollowing subsection provides this background and an overview of the\ntwo analyses. \nThe two key concepts in possible worlds semantics are possible worlds\nand accessibility spheres (or relations). Intuitively, a possible\nworld w is simply a way the world could be or could have been.\nFormally, they are treated as primitive points in the set of all\npossible worlds W. But their crucial role comes in assigning\ntruth-conditions to sentences: a sentence \\(\\phi\\) can only said to be\ntrue given a possible world w, but since w is genuinely\npossible, it cannot be the case that both \\(\\phi\\) and \\(\\neg\\phi\\)\nare true at w. Accessibility spheres provide additional\nstructure for reasoning about what’s possible: for each world\nw, \\(R(w)\\) is the set of worlds accessible from\n w.[18]\n This captures the intuitive idea that given a possible world\nw, a certain range of other worlds \\(R(w)\\) are possible, in a\nvariety of senses. \\(R_1(w)\\) might specify what’s nomologically\npossible in w by including only worlds where w’s\nnatural laws hold, while \\(R_2(w)\\) specifies what’s\nmetaphysically possible in w. \nThese tools furnish truth-conditions for a formal language including\nnon-truth-functional necessity (\\({{\\medsquare}}\\)) and possibility\n(\\({{\\meddiamond}}\\))\n operators:[19] \n\nIn classical logic, the meaning of \\(\\phi\\) is simply its truth-value.\nBut in modal logic, it is the set of possible worlds where \\(\\phi\\) is\ntrue: \\({\\llbracket}\\phi{\\rrbracket}\\). So \\(\\phi\\) is true in\nw, relative to v and R, just in case\n\\(w\\in{\\llbracket}\\phi{\\rrbracket}^R_v\\): \n\nOnly clauses 6 and 7 rely crucially on this richer notion of meaning.\n\\({{\\medsquare}}\\phi\\) says that in all accessible worlds \\(R(w)\\),\n\\(\\phi\\) is true. \\({{\\meddiamond}}\\phi\\) says that there are some\naccessible worlds where \\(\\phi\\) is true. Logical concepts like\nconsequence are also defined in terms of relations between sets of\npossible worlds. The intersection of the premises must be a subset of\nthe conclusion (i.e., every world where the premises are true, the\nconclusion is true): \nGiven this framework, the strict analysis can be formulated very\nsimply: \\(\\phi > \\psi\\) should be analyzed as\n\\({{\\medsquare}}(\\phi\\supset\\psi)\\). This says that all accessible\n\\(\\phi\\)-worlds are \\(\\psi\\)-worlds. This analysis can be depicted as\nin\n Figure 4.[20] \nFigure 4: Truth in \\(w_0\\) relative to\nR. [An\n extended description of figure 4\n is in the supplement.]  \nThe red circle delimits the worlds accessible from \\(w_0\\), the\nx-axis divides \\(\\phi\\) and \\(\\neg\\phi\\)-worlds, and the\ny-axis \\(\\psi\\) and \\(\\neg\\psi\\)-worlds.\n\\({{\\medsquare}}(\\phi\\supset\\psi)\\) says that there are no worlds in\nthe blue shaded region. \nIt is crucial to highlight that this semantics does not\ncapture the non-monotonic interpretation of counterfactual\nantecedents. For example, \\({\\llbracket}\\mathsf{A}\\land\n\\mathsf{B}{\\rrbracket}^R_v\\) is a subset of\n\\({\\llbracket}\\mathsf{A}{\\rrbracket}\\), and this means that any time\n\\({{\\medsquare}}(\\mathsf{A\\supset C})\\) is true, so is\n\\({{\\medsquare}}(\\mathsf{(A\\land B)\\supset C})\\). After all, if all\n\\(\\mathsf{A}\\)-worlds are in the red quadrant of\n Figure 4,\n so are all of the \\(\\mathsf{A\\land B}\\)-worlds, since the\n\\(\\mathsf{A\\land B}\\)-worlds are just a subset of the\n\\(\\mathsf{A}\\)-worlds. A crucial point here is that on this semantics\nthe domain of worlds quantified over by a counterfactual is constant\nacross counterfactuals with different antecedents. As will be\ndiscussed in\n §2.2,\n advocates of strict conditional analyses aim to instead capture the\nnon-monotonic behavior of antecedents pragmatically by incorporating\nit into a model of their context-sensitivity. The most important\ndifference between strict analyses and similarity analyses is that\nsimilarity analyses capture this non-monotonicity semantically. \nOn the similarity analysis, \\(\\phi >\\psi\\) is true in \\(w_0\\),\nroughly, just in case all the \\(\\phi\\)-worlds most similar to \\(w_0\\)\nare \\(\\psi\\)-worlds. To model this notion of similarity, one needs\nmore than a simple accessibility sphere. One way to capture it is with\nwith a nested system of spheres \\(\\mathcal{R}\\) around a possible\nworld \\(w_0\\) (D. Lewis 1973b:\n§1.3)—this is just a particular kind of set of\naccessibility spheres. As one goes out in the system, one gets to less\nand less similar worlds. This analysis can be depicted as in\n Figure 5.[21] \nFigure 5: Truth in \\(w_0\\) relative to\n\\(\\mathcal{R}\\). [An\n extended description of figure 5\n is in the supplement.] \nThe most similar \\(\\phi\\)-worlds are in the innermost gray region. So,\nthis analysis excludes any worlds from being in the shaded\ninnermost blue region. Comparing Figures\n 4\n and\n 5,\n one difference stands out: the similarity analyses does not require\nthat there be no \\(\\phi\\land\\neg\\psi\\)-worlds in any sphere,\njust in the innermost sphere. For example, world \\(w_1\\) does not\nprevent the counterfactual \\(\\phi >\\psi\\) from being true. It is\nnot in the \\(\\phi\\)-sphere most similar to w. This is the key\nto semantically capturing the non-monotonic interpretation of\nantecedents. The truth of \\(\\mathsf{A > C}\\) does not guarantee the\ntruth of \\(\\mathsf{(A\\land B)> C}\\) precisely because the most\nsimilar \\(\\mathsf{A}\\)-worlds may be in the innermost sphere, and the\nmost similar \\(\\mathsf{A\\land B}\\) may be in an intermediate sphere,\nand include worlds like \\(w_1\\) where the consequent is false. In this\nsense, the domain of worlds quantified over by a similarity-based\ncounterfactual varies across counterfactuals with different\nantecedents, though it does express a strict conditional over this\nvarying domain. For this reason, D. Lewis\n(1973b) and many others call the similarity analysis a\nvariably-strict analysis. \nSince antecedent monotonicity is the key division between strict and\nsimilarity analyses, it is worthwhile being a bit more precise about\nwhat it is, and what its associated inference patterns are. \nThe crucial patterns associated with antecedent monotonicity are: \nAS and SDA clearly follow from antecedent monotonicity. By contrast,\nTransitivity and a plausible auxiliary assumption entail antecedent\n monotonicity,[22]\n and the same is true for\n Contraposition.[23]\n With these basics in place, it is possible to focus in on each of\nthese analyses in more detail. In doing so, it will become clear that\nthere are important differences even among variants of the similarity\nanalysis and variants of the strict analysis. This entry will focus on\nwhat these analyses predict about valid inferences involving\ncounterfactuals. \nThe strict conditional analysis has a long history, but its\ncontemporary form was first articulated by\n Peirce:[24] \n“If A is true then B is true”… is\nexpressed by saying, “In any possible state of things,\n[w], either \\([A]\\) is not true [in w], or \\([B]\\) is\ntrue [in w]”. (Peirce 1896:\n33) \nC.I. Lewis (1912, 1914) defended the\nstrict conditional analysis of subjunctives and developed an axiomatic\nsystem for studying their logic, but offered no semantics. A precise\nmodel-theoretic semantics for the strict conditional was first\npresented in Carnap (1956: Ch. 5).\nHowever, that account did not appeal to accessibility relations, and\nranged only over logically possible worlds. Since counterfactuals are\noften non-logical, it it was only after Kripke\n(1963) introduced a semantics for modal logic featuring an\naccessibility relation, that the modern form of the strict analysis\nwas precisely\n formulated:[25] \n\nJust as the logic of \\({{\\medsquare}}\\) will vary with constraints\n that can be placed on R, so too will the logic of strict\n conditionals.[26]\n For example, if one does not assume that\n\\(w\\in R(w)\\) then modus ponens will not hold for the strict\nconditional: \\(\\psi\\) will not follow from \\(\\phi\\) and\n\\({{\\medsquare}}(\\phi\\supset\\psi)\\). But even without settling these\nconstraints, some basic logical properties of the analysis can be\n established. The discussion to follow is by no means\n exhaustive.[27]\n Instead, it will highlight the logical\npatterns which are central to the debates between competing\nanalyses. \n\n The core idea of the\n basic strict analysis\n leads to the following validities. \n\n  In these validities, some see a plausible and attractive\n  logic (C.I. Lewis 1912, 1914). Others\n  see them as “so utterly devoid of rationality [as to be]\n  a reductio ad absurdum of any view which involves\n  them” (Nelson 1933: 271),\n  earning them the title paradoxes of strict\n  implication. Patterns 3 and 4 are more central to debates about\n  counterfactuals, so they will be the focus here. Pattern 3 clearly\n  follows from the core idea of the basic\n  strict analysis: the premise guarantees that there are no\n  accessible \\(\\phi\\)-worlds, from which it vacuously follows that all\n  accessible \\(\\phi\\)-worlds are \\(\\psi\\)-worlds. Much the same is\n  true of pattern 4: if all the accessible worlds are \\(\\psi\\)-worlds\n  then all the accessible \\(\\phi\\)-worlds are \\(\\psi\\)-worlds. Both 3\n  and 4 are seem incorrect for English counterfactuals.  Contrary to pattern 3, the false (23b) does not intuitively follow from the true (23a). Similarly, for pattern 4. Suppose one’s origin from a particular sperm and egg is an essential feature of oneself. Then (24a) is true.  \n\nAnd, yet, many would hesitate to\ninfer (24b) on the basis\nof (24a). Each of these patterns follow\nfrom the core idea of the strict analysis. While these counterexamples\nmay not constitute a conclusive objection, they do present a problem\nfor the basic strict analysis. The second wave strict analyses\nsurveyed in §2.2.1 are\ndesigned to solve it, however. They are also designed to address\nanother suite of validities that are even more problematic. \n\nThe strict analysis is widely criticized for validating antecedent\nmonotonic patterns. It is worth saying a bit more precisely,\nusing Definition 9\nand Figure 6,\nwhy antecedent monotonicity holds for the strict\nconditional. Figure 6: Strict Conditionals are Antecedent Monotonic. [An extended description of figure 6 is in the supplement.] \nIf \\(\\phi_1\\strictif\\psi\\) is true, then the shaded blue region is empty, and the position of \\(\\phi_2\\) reflects the fact that \\({\\llbracket}\\phi_2{\\rrbracket}^R_v\\subseteq{\\llbracket}\\phi_1{\\rrbracket}^R_v\\)—recall that all worlds above the x-axis are \\(\\phi_1\\)-worlds. Since the shaded blue region within \\(\\phi_2\\) is also empty, all \\(\\phi_2\\) worlds in \\(R(w)\\) are \\(\\psi\\)-worlds. That is, \\(\\phi_2\\strictif \\psi\\) is true. \nRecall that Transititivity  and Contraposition  entail antecedent monotonicity, so it remains to show that both hold for the strict conditional. To see why Contraposition  holds for the strict conditional, note again that if \\(\\phi\\strictif\\psi\\) is true in w, then all \\(\\phi\\)-worlds in \\(R(w)\\) are \\(\\psi\\)-worlds, as depicted in the left Venn diagram in Figure  7. Now suppose w is a \\(\\neg\\psi\\)-world in \\(R(w)\\). As the diagram makes clear, w has to be a \\(\\neg\\phi\\)-world, and so \\(\\neg\\psi\\strictif\\neg\\phi\\) must be true in w. Similarly, if \\(\\neg\\psi\\strictif\\neg\\phi\\) is true in w, then all \\(\\neg\\psi\\)-worlds in \\(R(w)\\) are \\(\\neg\\phi\\)-worlds, as depicted in the right Venn diagram in Figure  7. Now suppose w is a \\(\\phi\\)-world in \\(R(w)\\). As depicted, w has to be a \\(\\psi\\)-world, and so \\(\\phi\\strictif\\psi\\) must be true in w. Figure 7: \\(w\\in {\\llbracket\\phi\\strictif\\psi\\rrbracket}^R_v \\iff w\\in {\\llbracket\\neg\\psi\\strictif\\neg\\phi\\rrbracket}^R_v\\) (Contraposition).  [An extended description of figure 7 is in the supplement.] \nThe validity of Transititivity  for the strict conditional is also easy to see with a Venn diagram. Figure 8: \\(w\\in{\\llbracket\\phi_2\\strictif\\phi_1\\rrbracket}^R_v\\cap{ \\llbracket\\phi_1\\strictif\\psi\\rrbracket}^R_v\\Leftrightarrow w\\in{\\llbracket\\phi_2\\strictif\\psi\\rrbracket}^R_v\\) (Transitivity). [An extended description of figure 8 is in the supplement.] \nThe premises guarantee that all \\(\\phi_2\\)-worlds in \\(R(w)\\) are\n\\(\\phi_1\\)-worlds, and that all \\(\\phi_1\\)-worlds in \\(R(w)\\) are\n \\(\\psi\\)-worlds. That gives one the relationships depicted\n in Figure 8. To show that\n \\(\\phi_2\\strictif\\psi\\) follows, suppose that w is a\n \\(\\phi_2\\)-world in \\(R(w)\\). As\n Figure 8\n makes evident, w must then be a \\(\\psi\\)-world. \nAntecedent monotonic patterns are an ineliminable part of a strict\nconditional logic. Examples of them often sound compelling. For\n example, the transitive inference\n (25)\n sounds perfectly reasonable, as does the antecedent strengthening\n inference\n (26). \n\n Similar examples for\n SDA\n are easy to find. However,\n counterexamples to each of the four patterns have been offered. \n\n Counterexamples to\n Antecedent Strengthening\n were already discussed back in\n §1.4.\n Against Transititivity,\n Stalnaker (1968: 48) points out that\n (27c)\n does not intuitively follow from\n (27a)\n and\n (27b).\n   \n\nContra Contraposition, D. Lewis\n(1973b: 35) presents (28).  \n\nSuppose Boris wanted to go, but stayed away to avoid\nOlga. Then (28b) is false. Further suppose\nthat Olga would have been even more excited to attend if Boris had. In\nthat case (28a) is\ntrue. Against SDA, Mckay\n& van Inwagen (1977: 354) offer: \n\n (29b) does not intuitively follow\n from (29a). \n\nThese counterexamples have been widely taken to be conclusive evidence\nagainst the strict analysis (e.g., D. Lewis\n1973b; Stalnaker 1968), since they follow from the core\nassumptions of that analysis. As a\nresult, D. Lewis (1973b)\nand Stalnaker (1968) developed\nsimilarity analyses which build the non-monotonicity of antecendents\ninto the semantics of\ncounterfactuals—see §2.3. However,\nthere was a subsequent wave of strict analyses designed to\nsystematically address these counterexamples. In fact, they do so by\nunifying two features of counterfactuals: the non-monotonic\ninterpretation of their antecedents and their context-sensitivity. \n\nBeginning with Daniels and Freeman\n(1980) and Warmbrōd\n(1981a,b), there was a second wave of strict analyses developed\nexplicitly to address the non-monotonic interpretation of\ncounterfactual antecedents. Warmbrōd\n(1981a,b), Lowe (1983, 1990),\nand Lycan (2001) account for the\ncounterexamples to antecedent monotonic patterns within a systematic\ntheory of how counterfactuals are context-sensitive. More\nrecently, Gillies (2007) has argued that\na strict analysis along those lines is actually preferable to an\naccount that builds the non-monotonicity of counterfactual antecedents\ninto their semantics, i.e., similarity analyses. This section will\noutline the basic features of these second wave strict conditional\nanalyses. \n\nThe key idea in Warmbrōd (1981a,b)\nis that the accessibility sphere in the basic strict analysis should\nbe viewed as a parameter of the context. Roughly, the idea is that\n\\(R(w)\\) corresponds to background facts assumed by the participants\nof a discourse context. For example, if they are assuming propositions\n(modeled as sets of possible worlds) A, B, and C\nthen \\(R(w)=A\\cap B\\cap C\\). The other key idea is that trivial strict\nconditionals are not pragmatically useful in conversation. If a strict\nconditional \\(\\mathsf{A\\strictif C}\\) is asserted in a context with\nbackground facts \\(R(w)\\) and \\(\\mathsf{A}\\) is inconsistent with\n\\(R(w)\\)—\\({\\llbracket}\\mathsf{A}{\\rrbracket}^R_v\\cap\nR(w)={\\emptyset}\\), then asserting \\(\\mathsf{A\\strictif C}\\) does not\nprovide any information. If there are no \\(\\mathsf{A}\\)-worlds in\n\\(R(w)\\), then, trivially, all \\(\\mathsf{A}\\)-worlds in \\(R(w)\\) are\n\\(\\mathsf{C}\\)-worlds. Warmbrōd\n(1981a,b) proposes that conversationalists adapt a pragmatic\nrule of charitable interpretation to avoid trivialization: \n\nOn this view, \\(R(w)\\) may very well change over the course of a\ndiscourse as a result of conversationalists adhering\nto (P). This part of the view is central to\nexplaining away counterexamples to antecedent monotonic\nvalidities. \n\nConsider again the example from Goodman\n1947 that appeared to be a counterexample\nto Antecedent Strengthening.  \n\nNow note that if (30a) is going to come out\ntrue, the proposition that there is oxygen in the room O must\nbe true in all worlds in the initial accessibility sphere\n\\(R_0(w)\\). However, if (30b) is interpreted\nagainst \\(R_0(w)\\), the antecedent will be inconsistent with\n\\(R_0(w)\\) and so express a trivial, uninformative\nproposition. Warmbrōd (1981a,b)\nproposes that in interpreting (30b) we are\nforced by to adopt a new, modified accessibility sphere \\(R_1(w)\\)\nwhere O is no longer assumed. But if this is\nright, (30a) and (30b)\ndon’t constitute a counterexample to Antecedent\nStrengthening because they are interpreted against different\naccessibility spheres. It’s like saying All current\nU.S. presidents are intelligent doesn’t entail All\ncurrent U.S. presidents are unintelligent because this sentence\nbefore Donald Trump was sworn in was true, but uttering it afterwards\nwas false. There is an equivocation of context, or\nso Warmbrōd (1981a,b) contends. \n\nWarmbrōd (1981a,b) outlines\nparallel explanations of the counterexamples presented\nto SDA, Contraposition,\nand Transititivity. This significantly\ncomplicates the issue of whether antecedent monotonicity is the key\nissue in understanding the semantics of counterfactuals. It appears\nthat the non-monotonic interpretation of counterfactual antecedents\ncan either be captured pragmatically in the way that accessibility\nspheres change in context (Warmbrōd\n1981a,b), or it can be captured semantically as we will see\nfrom similarity analyses in §2.3. There\nare significant limitations to Warmbrōd’s\n((1981a,b)) analysis: it does not\ncapture nested conditionals, and does not actually predict how\n\\(R(w)\\) evolves to\nsatisfy (P). Fintel\n(2001) and Gillies (2007) offer\naccounts that remove these limitations, and pose a challenge for\ntraditional similarity analyses. \n\nFintel (2001)\nand Gillies (2007) propose analyses\nwhere counterfactuals have strict truth-conditions, but they also have\na dynamic meaning which effectively changes \\(R(w)\\)\nnon-monotonically. They argue that such a theory can better explain\nparticular phenomena. Chief among them is reverse Sobel\nsequences. Recall the sequence of\ncounterfactuals (21) presented by Lewis\n(1973b, 1973c: 419), and attributed to\nHoward Sobel. Reversing these sequences is not felicitous:  \n\nFintel (2001)\nand Gillies (2007) observe that\nsimilarity analyses render sequences\nlike (31) semantically\nconsistent. Their theories predict this infelicity by providing a\ntheory of how counterfactuals in context can change\n\\(R(w)\\). Unlike Fintel\n(2001), Gillies (2007) does not\nrely essentially on a similarity ordering over possible worlds to\ncompute these changes to \\(R(w)\\), and so clearly counts as a second\nwave strict analysis.[28] The debate over whether counterfactuals are\nbest given a strict or similarity analysis is very much\nongoing. Moss\n(2012), Starr (2014),\nand K. Lewis (2018) have proposed three\ndifferent ways of explaining reverse Sobel sequences within a\nsimilarity analysis. But Willer (2015, 2017,\n2018) has argued on the basis of other data that a dynamic\nsecond wave strict analysis is preferable. This argument takes one\ninto a logical comparison of strict and similarity analyses, which\nwill be taken up in §2.4 after the\nsimilarity analysis has been presented in more detail. \n\nRecall the rough idea of the similarity analysis sketched\nin §2.1: worlds can be ordered by\ntheir similarity to the actual world, and counterfactuals say that the\nmost similar—or least different—worlds where the\nantecedent is true are worlds where the consequent is also true. This\nidea is commonly attributed to David Lewis and Robert Stalnaker, but\nthe actual history is a bit more nuanced. Although publication dates\ndo not tell the full story, the approach was developed roughly\ncontemporaneously by Stalnaker\n(1968), Stalnaker and Thomason\n(1970), D. Lewis\n(1973b), Nute (1975b),\nand Sprigge\n(1970).[29] And, there is an even earlier statement of\nthe view: \n\nWhen we allow for the possibility of the antecedent’s being true\nin the case of a counterfactual, we are hypothetically substituting a\ndifferent world for the actual one. It has to be supposed that this\nhypothetical world is as much like the actual one as possible so that\nwe will have grounds for saying that the consequent would be realized\nin such a world. (Todd 1964: 107) \n\nRecall the major difference between this proposal and\nthe basic strict analysis: the similarity\nanalysis uses a graded notion of similarity instead of an absolute\nnotion of accessibility. It also allows most similar worlds to vary\nbetween counterfactuals with different antecedents. These differences\ninvalidate antecedent monotonic inference patterns. This section will\nintroduce similarity analyses in a bit more formal detail and describe\nthe differences between analyses within this family. \n\nThe similarity analysis has come in many varieties and formulations,\nincluding the system of spheres approach informally described\nin §2.1. That formulation is\neasiest for comparison to strict analyses. But there is a different\nformulation that is more intuitive and better facilitates comparison\namong different similarity analyses. This formulation appeals to a\n(set) selection function f, which takes a world w, a\nproposition p, and returns the set of p-worlds most\nsimilar to w: \\(f(w,p)\\).[30] \\(\\phi>\\psi\\) is then said to be true\nwhen the most f-similar \\(\\phi\\)-worlds to w are\n\\(\\psi\\)-worlds, i.e., every world in\n\\(f(w,{\\llbracket}\\phi{\\rrbracket}^f_v)\\) is in\n\\({\\llbracket}\\psi{\\rrbracket}^f_v\\). The basics of this approach can\nbe summed up thus. \n\nAs noted, this formulation makes the limit assumption: \\(\\phi\\)-worlds\ndo not get indefinitely more and more similar\nto w. While D. Lewis (1973b)\nrejected this assumption, adopting it will serve exposition. It is\ndiscussed at length in the supplement Formal\nConstraints on Similarity. The logic of counterfactuals generated\nby a similarity analysis will depend on the constraints imposed\non f. Different theorists have defended different\nconstraints. Table 1 lists them, where\n\\(p,q\\subseteq W\\) and \\(w\\in W\\): Table 1: Candidate Constraints on Selection Functions \n\nModulo the limit assumption, Table\n2 provides an overview of which analyses have adopted which\nconstraints. Table 2: Similarity Analyses, modulo Limit Assumption \n\nsimply enforces that \\(f(w,p)\\) is indeed a set\nof p-worlds. Recall that \\(f(w,p)\\) is supposed to be the set\nof most similar p-worlds to w. The other constraints\ncorrespond to certain logical validities, as detailed in the\nsupplement Formal Constraints on\nSimilarity. This means that Pollock\n(1976) endorses the weakest logic for counterfactuals\nand Stalnaker (1968) the strongest. It\nis worth seeing how, independently of constraints (b)–(d), this\nsemantics invalidates an antecedent monotonicity\npattern like Antecedent Strengthening. \n\nConsider an instance of Antecedent Strengthening\ninvolving \\(\\mathsf{A > C}\\) and \\(\\mathsf{(A\\land B)>C}\\), and\nwhere the space of worlds is that given in Table\n3. Table 3: A space of worlds W, and truth-values at each world \nNow evaluate \\(\\mathsf{A > C}\\) and \\(\\mathsf{(A\\land B)>C}\\) in \\(w_{5}\\) using a selection function \\(f_1\\) with the following features: \n\\(f_1(w_{5},{\\llbracket}\\mathsf{A}{\\rrbracket}^{f_1}_v)=\\{w_{2}\\}\\) \n\\(f_1(w_{5},{\\llbracket}\\mathsf{A}\\land\\mathsf{B}{\\rrbracket}^{f_1}_v)=\\{w_{1}\\}\\) \n\nSince \\(\\mathsf{C}\\) is true in \\(w_{2}\\), \\(\\mathsf{A > C}\\) is\ntrue in \\(w_{5}\\) according to \\(f_1\\). But, since \\(\\mathsf{C}\\) is\nfalse in \\(w_{1}\\), \\(\\mathsf{(A\\land B) > C}\\) is false in\n\\(w_{5}\\) according to \\(f_1\\). No constraints are needed here other\nthan success. While \\(f_1\\)\nsatisfies uniqueness, the\ncounterexample works just as well if, say,\n\\(f_1(w_{5},{\\llbracket}\\mathsf{A}{\\rrbracket}^{f_1}_v)=\\{w_{2},w_0\\}\\). Accordingly,\nall similarity analyses allow for the non-monotonic interpretation of\ncounterfactual antecedents. \n\nWhile Stalnaker (1968)\nand D. Lewis (1973b) remain the most\npopular similarity analyses, there are substantial logical issues\nwhich separate similarity analyses. These issues, and the constraints\nunderlying them, are detailed in the\nsupplement Formal Constraints on\nSimilarity. Table 4 summarizes\nwhich validities go with which constraints. Table 4: Selection Constraints & Associated Validities \n\nA few comments are in order here, though.  Strong centering is\nsufficient but not necessary for Modus Ponens, weak centering would\ndo: \\(w\\in f(w,p)\\) if \\(w\\in p\\). LT and LAS follow from SSE, and\nallow similarity theorists to say why some instances\nof Transititivity\nand Antecedent Strengthening are intuitively\ncompelling. \n\nThe issue of whether a second wave strict analysis\n(§2.2.1) or a similarity\nanalysis provides a better logic of counterfactuals is very much an\nopen and subtle issue. As\nsections 2.2.1\nand 2.3 detailed, both analyses have their own\nway of capturing the non-monotonic interpretation of antecedents. Both\nanalyses also have their own way of capturing instances of monotonic\ninferences that do sound good. Perhaps this issue is destined for a\nstalemate.[31]\nBut before declaring it such, it is important to investigate two\npatterns that are potentially more\ndecisive: Simplification of Disjunctive\nAntecedents, and a pattern not yet discussed\ncalled Import-Export. \n\nBoth SDA\nand Import-Export are valid in a strict\nanalyses and invalid on standard similarity analyses. Crucially, the\ncounterexamples to them that have been offered by similarity theorists\nare significantly less compelling than those offered to patterns\nlike Antecedent Strengthening. Import-Export\nrelates counterfactuals like (33a)\nand (33b).  \n\nIt is hard to imagine one being true without the\nother. The basic strict analysis agrees:\nit renders them equivalent. \n\n But it is not valid on a\n similarity analysis.[32]\n While Import-Export is generally regarded\nas a plausible principle, some have challenged\nit. Kaufmann (2005: 213) presents an\nexample involving indicative conditionals which can be adapted to\nsubjunctives. Consider a case where there is a wet match which will\nlight if tossed in the campfire, but not if it is struck. It has not\nbeen lit. Consider now:  \n\nOne might then deny (34a). This match would\nnot have lit if it had been struck, and if it had lit it would have to\nhave been thrown into the campfire. (34b),\non the other hand, seems like a straightforward logical\ntruth. However, it is worth noting that this intuition\nabout (34a) is very fragile. The slight\nvariation of (34a)\nin (35) is easy to hear as\ntrue. \n\nThis subtle issue may be moot, however. Starr\n(2014) shows that a dynamic semantic implementation of the\nsimilarity analysis can\nvalidate Import-Export, so it may not be\nimportant for settling between strict and similarity analyses. \n\n As for the\n Simplification of Disjunctive Antecedents (SDA),\n Fine\n(1975), Nute\n(1975b), Loewer (1976),\nand Warmbrōd (1981) each object to\nthe similarity analysis predicting that this pattern is\ninvalid. Counterexamples like (29)\nfrom Mckay & van Inwagen 1977: 354)\nhave a suspicious feature. \n\nStarr (2014: 1049)\nand Warmbrōd (1981a: 284) observe\n that\n (29a)\n seems to be another way of saying\nthat Spain would never have fought for the\nAllies. While Warmbrōd (1981a: 284)\nuses this to pragmatically explain-away this counterexample to his\nstrict analysis, Starr (2014: 1049)\nmakes a further critical point: it sounds inconsistent to\n say\n (29a)\n after asserting that Spain could have fought for the Allies.  \n\nStarr (2014: 1049) argues that this\nmakes it inconsistent for a similarity theorist to regard this as a\n counterexample to\n SDA. On a similarity analysis\nof the could claim, it follows that there are no worlds in\nwhich Spain fought for the Allies most similar to the actual world:\n\\(f(w_@,{\\llbracket}\\mathsf{Allies}{\\rrbracket})={\\emptyset}\\). But if\n that’s the case, then\n (29b)\n is vacuously\ntrue on a similarity analysis, and so a similarity theorist cannot\nconsistently claim that this is a case where the premise is true and\nconclusion false. It is, however, too soon for the strict theorist to\ndeclare victory. Nute\n(1980a), Alonso-Ovalle (2009),\nand Starr (2014: 1049) each develop\nsimilarity analyses where disjunction is given a non-Boolean\n interpretation to validate\n SDA\n without validating\nthe other antecedent monotonic patterns. But even this is not the end\n of the\n SDA\n debate. \n\nNute (1980b: 33) considers a similar\nantecedent simplification pattern involving negated conjunctions: \n\n Nute (1980b: 33) presents\n (37)\n in favor of SNCA.  \n\nNote that \\(\\mathsf{\\neg(N\\land A)}\\) and \n\\(\\mathsf{\\neg N\\lor\\neg A}\\) are Boolean equivalents. However, \nnon-Boolean analyses like Nute (1980a), \nAlonso-Ovalle (2009),\nand Starr (2014: 1049) designed to\n capture\n SDA\n break this equivalence, and so fail\n to predict that\n SNCA\n is valid. Willer (2015, 2017) develops a\ndynamic strict analysis which validates both\n SDA\n and SNCA. Fine (2012a,b) advocates for a\ndeparture from possible worlds semantics altogether in order to\ncapture both\n SDA and SNCA. However, these\n accounts also face counterexamples. Fine\n(2012a,b) and Willer (2015, 2017)\nrender \\((\\neg\\phi_1\\lor\\neg\\phi_2)>\\psi\\) and\n\\(\\neg(\\phi_1\\land\\phi_2)>\\psi\\) equivalent,\nwhile Champollion, Ciardelli, and Zhang\n(2016) present a powerful counterexample to this\nequivalence. \n\nChampollion, Ciardelli, and Zhang (2016)\nconsider a light which is on when switches A and B are\nboth up, or both down. Currently, both switches are up, and the light\nis on. Consider\n (38a)\n and\n (38b)\n whose antecedents are Boolean equivalents:  \n\nWhile\n (38a)\n is intuitively true,\n (38b)\n is\n not.[33]\n This is not a counterexample to\n SNCA,\n since the premise of that pattern is false. But such a counterexample \nis not hard to think\n up.[34] \n\nSuppose the baker’s apprentice completely failed at baking our\ncake. It was burnt to a crisp, and the thin, lumpy frosting came out\npuke green. The baker planned to redecorate it to make it at least\nlook delicious, but did not have time. We may explain our extreme\ndissatisfaction by asserting\n (39a).\n But the\nbaker should not infer\n (39b)\n and assume that his redecoration plan would have worked.  \n\n Willer (2017: §4.2) suggests that\n such a counterexample trades on interpreting \n\\(\\mathsf{\\neg(B\\land U)>H}\\) \nas \n\\(\\mathsf{\\neg B\\land\\neg U)>H}\\), \nand provides an\nindependent explanation of this on the basis of how negation and\nconjunction interact. If this is right, then an analysis which\n validates\n SDA\n and\n SNCA\n without rendering \\(\\neg(\\phi_1\\land\\phi_2)>\\psi\\) and\n\\(\\neg\\phi_1\\lor\\neg\\phi_2>\\psi\\) equivalent is what’s\nneeded. Ciardelli, Zhang, and Champollion\n(forthcoming) develop just such an\nanalysis. As Ciardelli, Zhang, and Champollion\n(forthcoming: §6.4) explain, SDA\nand SNCA turn out to be valid for very different\nreasons. Champollion, Ciardelli, and Zhang\n(2016) and Ciardelli, Zhang, and Champollion (forthcoming)\nalso argue that the falsity of (38b)\ncannot be predicted on a similarity analysis. This example must be\nadded to a long list of examples which have been presented not as\ncounterexamples to the logic of the similarity analysis, but to what\nit predicts (or fails to predict) about the truth of particular\ncounterfactuals in particular contexts. This will be the topic\n of\n §2.5,\n where it will also be\nexplained why the strict analysis faces similar challenges. \n\nWhere does this leave us in logical the debate between strict and\nsimilarity analyses of counterfactuals?\nEven Import-Export\nand SDA fail to clearly identify one analysis as\nsuperior. It is possible to capture SDA on either\nanalysis. Existing similarity analyses that\nvalidate SDA, however, also\ninvalidate SNCA (Alonso-Ovalle\n2009; Starr 2014). By contrast existing strict analyses that\nvalidate SDA also\nvalidate SNCA (Willer 2015,\n2017). However, this is far from decisive. The validity of SNCA\nis still being investigated, and it is far from clear that it is\nimpossible to have a similarity analysis that validates\nboth SDA and SNCA, or a strict analysis that\nvalidates only SDA (perhaps using a non-Boolean\nsemantics for disjunction). So even SNCA may fail to be the conclusive\npattern needed to separate these analyses. \n\nIn their own ways, Stalnaker (1968,\n1984) and D. lewis (1973b) are\ncandid that the similarity analysis is not a complete analysis of\ncounterfactuals. As should be clear\nfrom §2.3, the formal constraints they\nplace on similarity are quite minimal and only serve to settle matters\nof logic. There are, in general, very many possible selection\nfunctions—and corresponding conceptions of similarity—for\nany given counterfactual. To explain how a given counterfactual\nlike (40) expresses a true proposition, a\nsimilarity analysis must specify which particular conception of\nsimilarity informs it.  \n\nOf course, the strict analysis is in the same position. It cannot\npredict the truth of (40) without specifying\na particular accessibility relation. In turn, the same question\narises: on what basis do ordinary speakers determine some worlds to be\naccessible and others not? This section will overview attempts to\nanswer these questions, and the many counterexamples those attempts\nhave invited. These counterexamples have been a central motivation for\npursuing alternative semantic analyses, which will be covered\nin §3. While this section follows\nthe focus of the literature on the similarity analysis\n(§2.5.1), §2.5.2\nwill briefly detail how parallel criticisms apply to strict\nanalyses. \n\nWhat determines which worlds are counted as most similar when\nevaluating a counterfactual? Stalnaker\n(1968) explicitly sets this issue aside,\nbut D. Lewis (1973b: 92) makes a clear\nproposal: \n\nJust as counterfactuals are context-dependent and vague, so is our\nintuitive notion of overall similarity. In comparing cost of living,\nNew York and San Francisco may count as similar, but not in comparing\ntopography. And yet, Lewis’ (1973b: 92)\nProposal has faced a barrage of counterexamples. Lewis and\nStalnaker parted ways in their responses to these counterexamples,\nthough both grant that Lewis’ (1973b: 92)\nProposal was not viable. Stalnaker (1984:\nCh.7) proposes the projection strategy: similarity is\ndetermined by the way we “project our epistemic policies onto\nthe world”. D. Lewis 1979)\nproposes a new system of weights that amounts to a kind of\ncurve-fitting: we must first look to which counterfactuals are\nintuitively true, and then find ways of weighting respects of\nsimilarity—however complex—that support the truth of\ncounterfactuals. Since Lewis’ (1973b: 92)\nProposal and Lewis’ (1979)\nsystem of weights are more developed, and have received extensive\ncritical attention, they will be the focus of this\nsection.[35]\nIt will begin with the objections to Lewis’\n(1973b: 92) Proposal that motivated Lewis’\n(1979) system of weights, and then some\nobjections to that approach. \n\nFine (1975: 452) presents\nthe future similarity objection\nto Lewis’ (1973b: 92)\nProposal. (41) is plausibly a true\nstatement about world history.  \n\nSuppose, optimistically, that there never will be a nuclear\nholocaust. Then, for every \\(\\mathsf{B\\land H}\\)-world, there will be\na more similar \\(\\mathsf{B\\land\\neg H}\\)-world, one where a small\ndifference prevents the holocaust, such as a malfunction in the\nelectrical detonation system. In short, a world where Nixon presses\nthe button and a malfunction prevents a nuclear holocaust is more like\nour own than one where there is a nuclear holocaust that changes the\nface of the planet. But then Lewis’ (1973b: 92)\nProposal incorrectly predicts\nthat (41) is false. \n\nTichý (1976: 271) offers a\nsimilar\ncounterexample. Given\n (42a)–(42c),\n (42d)\n sounds false. \n Lewis’ (1973b: 92) Proposal  does not seem to predict the falsity of (42d). After all, Jones is wearing his hat in the actual world, so isn’t a world where it’s not raining and he’s wearing his hat more similar to the actual one than one where it’s not raining and he isn’t wearing his hat? \n(1979: 472) responds to these examples by proposing a ranked system of weights that give what he calls the standard resolution of similarity, which may be further modulated in context:\n While weight 2 gives high importance to keeping particular facts fixed up to the change required by the counterfactual, weight 4 makes clear that particular facts after that point need not be kept fixed. In the case of (42d) the fact that Jones is wearing his hat need not be kept fixed. It was a post-rain fact, so when one counterfactually supposes that it had not been raining, there is no reason to assume that Jones is still wearing his hat. Similarly, with example (41). A world where Nixon pushes the button, a small miracle occurs to short-circuit the equipment and the nuclear holocaust is prevented will count as less similar than one where there is no small miracle and a nuclear holocaust results. A small-miracle and no-holocaust world is similar to our own only in one insignificant respect (particular matters of fact) and dissimilar in one important respect (the small miracle). \nIt is clear, however, that Lewis’ (1979) System of Weights  is insufficiently general. Particular matters of fact often are held fixed.  Example (43) crucially holds fixed the outcome of a highly contingent particular fact: the coin outcome. Cases of this kind are discussed extensively by Edgington (2004). Example (44) shows that a chancy outcome is not an essential feature of these cases. Noting the existence of recalcitrant cases, (1979: 472) simply says he wishes he knew why they came out differently. Additional counterexamples to the Lewis’ (1979) System of Weights  have been proposed by Bowie (1979), Kment (2006), and Wasserman (2006).[36]Kment (2006: 458) proposes a new similarity metric to handle this example which is sensitive to the way particular facts are explained, and is integrated into a general account of metaphysical modality in Kment (2014). Ippolito (2016) proposes a new theory of how context determines similarity for counterfactuals which aims to make the correct predictions about many of the above cases. \nAnother response to these counterexamples has been to develop alternative semantic analyses of counterfactuals such as premise semantics (Kratzer 1989, 2012; Veltman 2005) and causal models (Schulz 2007 2011;  Briggs 2012; Kaufmann 2013). These accounts start from the observation that the counterexamples can be easily explained in a model where matters of fact depend on each other. In (42), when we counterfactually retract the fact that it rained, we don’t keep the fact that the man was wearing his hat because that fact depended on it raining. Hence, (42d) is false. In (43), when we counterfactually retract that you didn’t bet on heads, we keep the fact that the coin came up heads because it is independent of the fact that you didn’t bet on heads. These accounts offer models of how laws, and law-like generalizations, make facts dependent on each other, and argue that once this is done, there is no work left for similarity to do in the semantics of counterfactuals. While these accounts are the focus of §3, it is worth presenting one of the additional counterexamples to the similarity analysis that has emerged from this literature. \nRecall (38) from §2.4. Champollion, Ciardelli, and Zhang (2016) and Ciardelli, Zhang, and Champollion (forthcoming) argue on the basis of this example that any similarity analysis will make incorrect predictions about the truth-conditions of counterfactuals. In this example a light is on either when Switch A and B are both up, or they are both down. Otherwise the light is off. Suppose both switches are up and the light is on. Intuitively, (38a) is true, as are \\(\\mathsf{\\neg A >\\neg L}\\) and \\(\\mathsf{\\neg B >\\neg L}\\), but (38b) is false. Champollion, Ciardelli, and Zhang (2016: 321) argue that a similarity analysis cannot predict \\(\\mathsf{\\neg A >\\neg L}\\) and \\(\\mathsf{\\neg B >\\neg L}\\) to be true, while (38b) is false. In order for \\(\\mathsf{\\neg A >\\neg L}\\) to be true, the particular fact that Switch B is up must count towards similarity. Similarly, for \\(\\mathsf{\\neg B >\\neg L}\\) to be true, the particular fact that Switch A is up must count towards similarity. But then it follows that (38b) is true on a similarity analysis: the most similar worlds where A and B are not both up have to either be worlds where Switch B is down but Switch A is still up, or Switch A is down and Switch B is still up. In those worlds, the light would be off, so the similarity analysis incorrectly predicts (38b) to be true. Champollion, Ciardelli, and Zhang (2016) instead pursue a semantics in terms of causal models where counterfactually making \\(\\neg \\mathsf{(A\\land B)}\\) true and making \\(\\mathsf{\\neg A\\lor\\neg B}\\) true come apart. \nDo strict analyses avoid the troubles faced by similarity analyses when it comes to truth-conditions? This question is difficult to answer, and has not been explicitly discussed in the literature. Other than the theory of Warmbrōd (1981a,b), strict theorists have not made proposals for the accessibility relation analogous to Lewis’ (1973b: 92) Proposal  for similarity. And, Warmbrōd’s proposal about the pragmatics of the accessibility relation is this: \n\nAll subsequent second wave strict analyses have ended up in similar\nterritory. The dynamic analyses developed\nby Fintel\n(2001), Gillies (2007),\nand Willer (2015, 2017, 2018) assign\nstrict truth-conditions to counterfactuals, but have them induce\nchanges in an evolving space of possible worlds. These changes must\nrender the antecedent consistent with an evolving body of\ndiscourse. While Fintel (2001)\nand Willer (2018) explicitly appeal to a\nsimilarity ordering for this purpose, Gillies\n(2007) and Willer (2017) do\nnot. Nevertheless, the formal structures used\nby Gillies (2007)\nand Willer (2017) for this purpose give\nrise to the same question: which facts stay and which facts go when\nrendering the counterfactual antecedent consistent? Accordingly, at\npresent, it does not appear that the strict analysis avoids the kinds\nof concerns raised for the similarity analysis\nin §2.5.1. \nRecall Goodman’s Problem\nfrom §1.4: the truth-conditions of\ncounterfactuals intuitively depend on background facts and laws, but\nit is difficult to specify these facts and laws in a way that does not\nitself appeal to counterfactuals. Strict and similarity analyses make\nprogress on the logic of conditionals without directly confronting\nthis problem. But the discussion\nof § 2.5 makes salient a\nrelated problem. Lewis’ (1979) System of\nWeights amounts to reverse-engineering a similarity relation to\nfit the intuitive truth-conditions of counterfactuals. While\nLewis’ (1979) approach avoids\ncharacterizing laws and facts in counterfactual\nterms, Bowie (1979: 496–497)\nargues that it does not explain why certain counterfactuals are true\nwithout appealing to counterfactuals. Suppose one asks why certain\ncounterfactuals are true and the similarity theorist replies with\nLewis’ (1979) recipe for\nsimilarity. If one asks why those facts about similarity make\ncounterfactuals true, the similarity theorist cannot reply that they\nare basic self-evident truths about the similarity of worlds. Instead,\nthey must say that those similarity facts make those counterfactuals\ntrue. Bowie’s (1979:\n496–497) criticism is that this is at best uninformative,\nand at worst circular. \nA related concern is voiced by Horwich (1987:\n172) who asks “why we should have evolved such a baroque\nnotion of counterfactual dependence”, namely that captured\nby Lewis’ (1979) System of\nWeights. The concern has two components: why would humans find it\nuseful, and why would human psychology ground counterfactuals in this\nconcept of similarity rather than our ready-at-hand intuitive concept\nof overall similarity? These questions are given more weight given the\ncentrality of counterfactuals to human rationality and scientific\nexplanation outlined in §1. Psychological\ntheories of counterfactual reasoning and representation have found\ntools other than similarity more fruitful\n(§1.2). Similarly, work on\nscientific explanation has not assigned any central role for\nsimilarity (1.3), and\nas Hájek (2014: 250) puts it:\n \nScience has no truck with a notion of similarity; nor does\nLewis’ (1979) ordering of what\nmatters to similarity have a basis in science. \n Morreau (2010) has recently argued on\n formal grounds that similarity is poorly suited to the task assigned\n to it by the similarity analysis. The similarity analysis, especially\n as elaborated by D. Lewis (1979), tries\n to weigh some similarities between worlds against their differences\n to arrive at a notion of overall comparative similarity between those\n worlds. Morreau (2010: 471) argues\n that:\n \n[w]e cannot add up similarities or weigh them against differences. Nor\ncan we combine them in any other way… No useful comparisons of\noverall similarity result. (Morreau 2010:\n§4)\n  \narticulates this argument formally via a reinterpretation of\nArrow’s Theorem in social choice theory. Arrow’s Theorem\nshows that it is not possible to aggregate individuals’\npreferences regarding some alternative outcomes into a coherent\n“collective preference” ordering over those outcomes,\ngiven minimal assumptions about their rationality and autonomy. As\nsummarized in §6.3\nof Arrow’s\ntheorem, Morreau (2010) argues that\nthe same applies to aggregating respects of similarity and difference:\nthere is no way to add them up into a coherent notion of overall\nsimilarity. \nStrict and similarity analyses of counterfactuals showed that it was\npossible to address the semantic puzzles described\nin §1.4 with formally explicit\nlogical models. This dispelled widespread skepticism of\ncounterfactuals and established a major area of interdisciplinary\nresearch. Strict analyses have been revealed to provide a stronger,\nmore classical, logic, but must be integrated with a pragmatic\nexplanation of how counterfactual antecedents are interpreted\nnon-monotonically. Similarity analyses provide a much weaker, more\nnon-classical, logic, but capture the non-monotonic interpretation of\ncounterfactual antecedents within their core semantic model. It is now\na highly subtle and intensely debated question which analysis provides\na better logic for counterfactuals, and which version of each kind of\nanalysis is best. This intense scrutiny and development has also\ngenerated a wave of criticism focused on their treatment of\ntruth-conditions, Goodman’s Problem, and\nintegration with thinking about counterfactuals in psychology and the\nphilosophy of science\n(§2.5, §2.6). None\nof these criticisms are absolutely conclusive, and these two analyses,\nparticularly the similarity analysis, remain standard in philosophy\nand linguistics. However, the criticisms are serious enough to merit\nexploring alternative analyses. These alternative accounts take\ninspiration from a particular diagnosis of the counterexamples\ndiscussed in §2.5: facts\ndepend on each other, so counterfactually assuming p involves\nnot just giving up not-p, but any facts which depended\non not-p. The next section will examine analyses of this\nkind. \nSimilarity and strict analyses nowhere refer to facts, or\npropositions, depending on each\nother. Indeed, 1979 was primarily\nconcerned with explaining which true counterfactuals, given a\nsimilarity analysis, manifest a relation of counterfactual\ndependence. Other analyses have instead started with the idea that\nfacts depend on each other, and then explain how these relations of\ndependence make counterfactuals true. As will become clear, none of\nthese analyses endorse the naive idea that \\(\\mathsf{A > B}\\) is\ntrue only when B counterfactually depends on A. The\ndependence can be more complex, indirect, or B could just be\ntrue and independent of A. Theories in this family differ\ncrucially in how they model counterfactual dependence. In premise\nsemantics (§3.1) dependence is modeled in\nterms of how facts, which are modeled as parts of worlds, are\ndistributed across a space of worlds that has been constrained by\nlaws, or law-like generalizations. In probabilistic semantics\n(§3.2), this dependence is modeled as\nsome form of conditional probability. In Bayesian networks, structural\nequations, and causal models\n(§3.3), it is modeled in\nterms of the Bayesian networks discussed at the beginning\nof §1.2.3. Because theories of\nthese three kinds are very much still in development and often involve\neven more sophisticated formal models than those covered\nin §2, this section will have to be more\ncursory than §2 to ensure breadth and\naccessibility. \nVeltman (1976)\nand Kratzer (1981b) approached\ncounterfactuals from a perspective closer\nto Goodman (1947): counterfactuals\ninvolve explicitly adjusting a body of premises, facts or propositions\nto be consistent with the counterfactual’s antecedent, and\nchecking to see if the consequent follows from the revised premise\nset—in a sense of “follow” to be articulated\ncarefully. Since facts or premises hang together, changing one\nrequires changing others that depend on it. The function of\ncounterfactuals is to allow us to probe these connections between\nfacts. While D. Lewis (1981) proved that\nthe Kratzer (1981b) analysis was a\nspecial case of similarity semantics, subsequent refinements of\npremise semantics in Kratzer (1989, 1990, 2002,\n2012) and Veltman (2005)\nevidenced important differences. Kratzer (1989:\n626) nicely captures the key difference: \n[I]t is not that the similarity theory says anything false about [particular] examples… It just doesn’t say enough. It stays vague where our intuitions are relatively sharp. I think we should aim for a theory of counterfactuals that is able to make more concrete predictions with respect to particular examples. \nFrom a logical point of view, premise semantics and similarity semantics do not diverge. They diverge in the concrete predictions made about the truth-conditions of counterfactuals in particular contexts without adding additional constraints to the theory like Lewis’ (1979) System of Weights. \nHow does premise semantics aim to improve on the predictions of similarity semantics? It re-divides the labor between context and the semantics of counterfactuals to more accurately capture the intuitive truth-conditions of counterfactuals, and intuitive characterizations of how context influences counterfactuals. In premise semantics, context provides facts and law-like relations among them, and the counterfactual semantics exploits this information. By contrast, the similarity analysis assumes that context somehow makes a similarity relation salient, and has to make further stipulations like Lewis’ (1979) System of Weights  about how facts and laws enter into the truth-conditions of counterfactuals in particular contexts. This can be illustrated by considering how Tichý’s (1976) example (42) is analyzed in premise semantics. This illustration will use the Veltman (2005) analysis because it is simpler than Kratzer (1989, 2012)—that is not to say it is preferable. The added complexity in Kratzer (1989, 2012) provides more flexibility and a broader empirical range including quantification and modal expressions other than would-counterfactuals. \nRecall Tichý’s (1976) example, with the intuitively false counterfactual (42d):   Veltman (2005) models how the sentences leading up to the counterfactual (42d) determine the facts and laws relevant to its interpretation. The law-like generalization in (42a) is treated as a strict conditional which places a hard constraint on the space of worlds relevant to evaluating the counterfactual.[37] The particular facts introduced by (42c) provide a soft constraint on the worlds relevant to interpreting the counterfactual. Figure  9 illustrates this model of the context and its evolution, including a third atomic sentence \\(\\mathsf{H}\\) for reasons that will become clear shortly. \\(\\hspace{15px}\\underrightarrow{\\medsquare(\\mathsf{R\\supset W})}\\) \\(\\quad\\underrightarrow{\\mathsf{R\\land W}}\\) Figure 9: Context for (42), Facts in Bold, Laws Crossing out Worlds \nOn this model a context provides a set of worlds compatible with the facts, in \\(C_2\\) \\(\\textit{Facts}_{C_2}={\\{w_6,w_7\\}}\\), and the set of worlds compatible with the laws, in \\(C_2\\) \\(\\textit{Universe}_{C_2}={\\{w_0,w_1,w_2,w_3,w_6,w_7\\}}\\). This model of context is one essential component of the analysis, but so too is the way Veltman (2005) models worlds, situations, and dependencies between facts. These further components allow Veltman (2005) to offer a procedure for “retracting” the fact that \\(\\mathsf{R}\\) holds from a world. \nVeltman’s (2005) analysis of counterfactuals identifies possible worlds with atomic valuations (functions from atomic sentences to truth-values) like those depicted in Figure  9. So \\(w_6={\\{{\\langle \\mathsf{R},1\\rangle},{\\langle \\mathsf{W},1\\rangle},{\\langle \\mathsf{H},0\\rangle}\\}}\\). This makes it possible to offer a simple model of situations, which are parts of worlds: any subset of a world.[38] It is now easy to think about one fact (sentence having a truth-value) as determining another fact (sentence having a truth value). In context \\(C_3\\), \\(\\mathsf{R}\\) being 1 determines that \\(\\mathsf{W}\\) will be 1. Once you know that \\(\\mathsf{R}\\) is assigned to 1, you know that \\(\\mathsf{W}\\) is too. Veltman’s (2005) proposal is that speakers evaluate a counterfactual by retracting the fact that the antecedent is false from the worlds in the context, which gives you some situations, and then consider all those worlds that contain those situations, are compatible with the laws, and make the antecedent true. If the consequent is true in all of those worlds, then we can say that the counterfactual is true in (or supported by) the context. So, to evaluate \\(\\neg \\mathsf{R>W}\\), one first retracts the fact that \\(\\mathsf{R}\\) is true, i.e., that \\(\\mathsf{R}\\) is assigned to 1, then one finds all the worlds consistent with the laws that contain those situations and assign \\(\\mathsf{R}\\) to 0. If all of those worlds are also \\(\\mathsf{W}\\) worlds, then the counterfactual is true in (or supported by) the context. For Veltman (2005), the characterization of this retraction process relies essentially on the idea of facts determining other facts. \nAccording to Veltman (2005), when you are “retracting” a fact from the facts in the context, you begin by considering each \\(w\\in \\textit{Facts}_C\\) and find the smallest situations in w which contain only undetermined facts—he calls such a situation a basis for w. This is a minimal situation which, given the laws constraining \\(\\textit{Universe}_C\\), determines all the other facts about that world. For example, \\(w_6\\) has only one basis, namely \\(s_0={\\{{\\langle \\mathsf{R},1\\rangle},{\\langle \\mathsf{H},0\\rangle}\\}}\\), and \\(w_7\\) has only one basis, namely \\(s_1={\\{{\\langle \\mathsf{R},1\\rangle},{\\langle \\mathsf{H},1\\rangle}\\}}\\). Once you have the bases for a world, you can retract a fact by finding the smallest change to the basis that no longer forces that fact to be true. So retracting the fact that \\(\\mathsf{R}\\) is true from \\(s_0\\) produces \\(s'_0={\\{{\\langle \\mathsf{H},0\\rangle}\\}}\\), and retracting it from \\(s_1\\) produces \\(s'_1={\\{{\\langle \\mathsf{H},1\\rangle}\\}}\\). The set consisting of these two situations is the premise set. \nTo evaluate \\(\\mathsf{\\neg R>W}\\), one finds the set of worlds from \\(\\textit{Universe}_{C_3}\\) that contains some member of the premise set \\(s'_0\\) or \\(s'_1\\): \\({\\{w_0,w_1,w_2,w_3\\}}\\)—these are the worlds consistent with the premise set and the laws. Are all of the \\(\\neg \\mathsf{R}\\)-worlds in \\({\\{w_0,w_1,w_2,w_3\\}}\\) also \\(\\mathsf{W}\\)-worlds? No, \\(w_2\\) and \\(w_3\\) are not. Thus, \\(\\neg \\mathsf{R>W}\\) is not true in (or supported by) the context \\(C_3\\). This was the intuitively correct prediction about example (42). Of course, the similarity analysis supplemented with Lewis’ (1979) System of Weights  also makes this prediction. But consider again example (43), which is not predicted:  This example relies seamlessly on three pieces of background knowledge about how betting works: If you don’t bet, you don’t win: \\(\\mathsf{\\medsquare(\\neg B\\supset\\neg W)}\\) If you bet and it comes up heads, you win: \\(\\mathsf{\\medsquare((B\\land H)\\supset W)}\\) If you bet and it doesn’t come up heads, you don’t win: \\(\\mathsf{\\medsquare((B\\land\\neg H)\\supset\\neg W)}\\) \nAnd it specifies facts: \\(\\mathsf{\\neg B\\land H}\\). The resulting context is detailed in Figure  10: Figure 10: Context for (43) \nNow, consider the counterfactual \\(\\mathsf{B>W}\\). The first step is to retract the fact that \\(\\mathsf{B}\\) is false from each world in \\(\\textit{Facts}_{C_{(43)}}\\). That’s just \\(w_2\\). This world has two bases—minimal situations consisting of undetermined facts—\\(s_0={\\{{\\langle \\mathsf{B},0\\rangle},{\\langle \\mathsf{H},1\\rangle}\\}}\\) and \\(s_1={\\{{\\langle \\mathsf{H},1\\rangle},{\\langle \\mathsf{W},0\\rangle}\\}}\\).[39] The next step is to retract the fact that \\(\\mathsf{B}\\) is false from both bases. For \\(s_0\\) this yields \\(s'_0={\\{{\\langle \\mathsf{H},1\\rangle}\\}}\\) and for \\(s_1\\) this also yields \\(s'_0\\)—since the fact that you didn’t win together with the fact that the coin came up heads, forces it to be false that you bet. Given this situation, the premise set consists of the two worlds in Universe(43) that contain \\(s'_0\\): \\({\\{w_2,w_7\\}}\\). Now, are all of the \\(\\mathsf{B}\\)-worlds in this set also \\(\\mathsf{W}\\)-worlds? Yes, \\(w_7\\) is the only \\(\\mathsf{B}\\)-world, and it is also a \\(\\mathsf{W}\\)-world. So Veltman (2005) correctly predicts that (43) is true in (supported by) its natural context. \nIt should now be more clear how premise semantics delivers on its promise to be more predictive than similarity semantics when it comes to counterfactuals in context, and affords a more natural characterization of how a context informs the interpretation of counterfactuals. This analysis was crucially based on the idea that some facts determine other facts, and that the process of retracting a fact is constrained by these relations. However, even premise semantics has encountered counterexamples. \nSchulz (2007: 101) poses the following counterexample to Veltman (2005).  Intuitively, (45d) is true in the context. Figure  11 details the context predicted for it by Veltman (2005). Figure 11: Context for (45d) \nThere are two bases for \\(w_4\\): \\(s_0={\\{{\\langle \\mathsf{A},1\\rangle},{\\langle \\mathsf{L},0\\rangle}\\}}\\)—the fact that Switch A is up and the light is off determines that Switch B is down—and \\(s_1={\\{{\\langle \\mathsf{A},1\\rangle},{\\langle \\mathsf{B},0\\rangle}\\}}\\)—the fact that Switch A is up and the fact that B is down determines that the light is off. (No smaller situation would determine the facts of \\(w_4\\).) Retracting \\(\\mathsf{B}\\)’s falsity from \\(s_0\\) leads to trouble. \\(s_0\\) forces \\(\\mathsf{B}\\) to be false, but there are two ways of changing this. First, one can remove the fact that the light is on, yielding \\(s'_0={\\{{\\langle \\mathsf{A},1\\rangle}\\}}\\). Second, one can eliminate the fact that Switch A is up, yielding \\(s''_0={\\{{\\langle \\mathsf{L},0\\rangle}\\}}\\). Because of \\(s''_0\\), the premise set will contain \\(w_2\\), meaning it allows that in retracting the fact that Switch B is down one can give up the fact that Switch A is up. But then there is a \\(\\mathsf{B}\\)-world where \\(\\mathsf{L}\\) is false, and \\(\\mathsf{B>L}\\) is incorrectly predicted to be false. \nIntuitively, the analysis went wrong in allowing the removal of the fact that Switch A is up when retracting the fact that Switch B is down. Schulz (2007: §5.5) provides a more sophisticated version of this diagnosis: although the fact that Switch A is up and the fact that the light is off together determine that Switch B is down, only the fact that the light is off depends on the fact that Switch B is down. If one could articulate this intuitive concept of dependence, and instead only retract facts that depend on the fact you are retracting (in this case the fact that B is down), then the error could be avoided. It is unclear how to implement this kind of dependence in Veltman’s (2005) framework. Schulz (2007: §5.5) goes on show that structural equations and causal models provide the necessary concept of dependence—for more on this approach see §3.3 below. After all, it seems plausible that the light being off causally depends on Switch B being down, but Switch A being up does not causally depend on Switch B being down. It remains to be seen whether the more powerful framework developed by Kratzer (1989, 2012) can predict (45). \nWhile premise semantics has been prominent among linguists, probabilistic theories have been very prominent among philosophers thinking about knowledge and scientific explanation.[40]Adams (1965, 1975) made a seminal proposal in this literature: \nHowever, Adams (1970) was also aware\nthat indicative/subjunctive pairs\nlike (3)/(4)\ndiffer in their assertability. To explain this, he proposed\nthe prior probability analysis of\ncounterfactuals (Adams 1976): \nIt would seem that this analysis accurately predicts our intuitions\nin (45) about \\(\\mathsf{B>L}\\). Let\n\\(P_0\\) be an agent’s credence before learning that Switch B is\ndown. (45a) requires that\n\\(P_0(\\mathsf{L}\\mid \\mathsf{A\\land B})\\) is (or is close to)\n1, (45b) requires that \\(P_0(\\mathsf{\\neg\nL}\\mid \\mathsf{\\neg A\\lor \\neg B})\\) is (or is close to) 1. The agent\nalso learns that Switch A is up, so \\(P_0(\\mathsf{A})\\) is (or is\nclose to) 1. All of this together seems to guarantee that\n\\(P_0(\\mathsf{B\\mid L})\\) is also very high. However, this is due to\nan inessential artifact of the example: the agent learned that Switch\nB was down after learning that Switch A is up. This detail\ndoes not matter to the intuition. As was seen with\nexample (43), we often hold fixed facts that\nhappen after the antecedent turns out false. Indeed, Adams’\nPrior Probability Analysis makes the incorrect prediction\nthat (43) is unassertible in its natural\ncontext. \nThis problem for Adams’ Prior Probability Analysis is addressed in Edgington (2003, 2004: 21) who amends the analysis: \\(P_0\\) may also reflect any facts the agent learns after they learn that the antecedent is false, provides that those facts are causally independent of the antecedent. This parallels the idea pursued by Schulz (2007: Ch.5) to integrate causal dependence into the analysis of counterfactuals. This idea was also pursued in a probabilistic framework by Kvart (1986, 1992). Kvart (1986, 1992), however, does not propose a prior probability analysis and does not regard the probabilities as subjective credences: they are instead objective probabilities (propensity or objective chance). Skyrms (1981) also proposes a propensity account, but pursues a prior propensity account analogous to the subjective one proposed by Adams (1976). \nObjective probability analyses have been popular among philosophers trying to capture the way that counterfactuals feature in physical explanations, and why they are so useful to agents like us in worlds like ours. Loewer (2007) is a good example of such an account, who grounds the truth of certain counterfactuals regarding our decisions like (46) in statistical mechanical probabilities.  Loewer (2007) proposes that (46) is true just in case (where \\(P_{\\textit{SM}}\\) is the statistical mechanical probability distribution and \\(M(t)\\) is a description of the macro-state of the universe at t):  Loewer (2007) acknowledges that this analysis is limited to counterfactuals like (46). He argues that it can address the philosophical objections to the similarity analysis discussed in §2.6, namely why counterfactuals are useful in scientific explanations, and for agents like us in a world like our own. \nConditional probability analyses do not proceed by assigning\ntruth-conditions to (all) counterfactuals. They instead associate them\nwith certain conditional\nprobabilities.[41] This makes it difficult to integrate the\ntheory into a comprehensive compositional semantics and logic for a\nnatural language. Kaufmann (2005 2008)\nmakes important advances here, but it remains an open issue for\nconditional probability analyses. Leitgeb\n(2012a,b) thoroughly develops a new conditional probability\nanalysis which regards \\(\\mathsf{\\phi>\\psi}\\) as true when the\nrelevant conditional probability is sufficiently\nhigh.[42] But\nconditional probability analyses have other limitations. Without\nfurther development, these analyses are limited in their ability to\nexplain how humans judge particular counterfactuals to be true. There\nis a large literature in psychology, beginning\nwith Kahneman, Slovic, and Tversky 1982,\nshowing that human reasoning diverges in predictable way from precise\nprobabilistic reasoning. Even if these performance differences\ndidn’t turn up in counterfactuals and conditional probabilities,\nthere is an implementation issue. As discussed\nin §1.2.3, directly implementing\nprobabilistic knowledge makes unreasonable demands on memory. Bayesian\nNetworks are one proposed solution to this implementation issue. They\nare also used in the analysis of causal dependence\n(§1.3), which conditional\nprobability analyses must appeal to anyway. Since Bayesian Networks\ncan also be used to directly formulate a semantics of counterfactuals,\nthey provide an worthwhile alternative to conditional probability\nanalyses despite proceeding from similar assumptions. \nRecall from §1.2.3 the basic idea of a Bayesian Network: rather than storing probability values for all possible combinations of some set of variables, a Bayesian Network represents only the conditional probabilities of variables whose values depend on each other. This can be illustrated for (45).  Sentences (45a)-(45c) can be encoded by the Bayesian Network and structural equations in Figure  12. Figure\n12: Bayesian Network and Structural Equations for\n (45)  Recall that \\(L\\dequal A\\land B\\) means that the value of\nL equals the value of \\(A\\land B\\), but also asymmetrically\ndepends on the value of \\(A\\land B\\): the value of \\(A\\land B\\)\ndetermines the value of L, and not vice-versa. How, given the\nnetwork in\n Figure 12,\n does one evaluate the counterfactual \\(\\mathsf{B>N}\\)? Several\ndifferent answers have been given to this question. \nPearl (1995, 2000, 2009, 2013: Ch.7)\nproposes: \nOn this approach, one simply deletes the assignment \\(B=0\\), replaces\nit with \\(B=1\\), and solves for L using the equation \\(L\\dequal\nA\\land B\\). Since the deletion of \\(B=0\\) does not effect the\nassignment \\(A=1\\), it follows that \\(L=1\\) and that the\ncounterfactual is true. This simple recipe yields the right result.\nPearl nicely sums up the difference between this kind of analysis and\na similarity analysis: \nIn contrast with Lewis’s theory, counterfactuals are not based\non an abstract notion of similarity among hypothetical worlds;\ninstead, they rest directly on the mechanisms (or “laws,”\nto be fancy) that produce those worlds and on the invariant properties\nof those mechanisms. Lewis’s elusive “miracles” are\nreplaced by principled [interventions] which represent the minimal\nchange (to a model) necessary for establishing the antecedent…\nThus, similarities and priorities—if they are ever\nneeded—may be read into the [interventions] as an\nafterthought… but they are not basic to the analysis. (Pearl\n2009: 239–240) \nAs interventionism is stated above, it does not apply to conditionals\nwith logically complex antecedents or consequents. This limitation is\naddressed by Briggs (2012), who also\naxiomatizes and compares the resultant logic to D.\nLewis (1973b) and Stalnaker\n(1968)—significantly extending\nthe analysis and results in Pearl (2009:\nCh.7). Integrations of causal models with premise semantics\n(Schulz 2007, 2011; Kaufmann 2013; Santorio\n2014; Champollion, Ciardelli, & Zhang 2016; Ciardelli, Zhang,\n& Champollion forthcoming) provide another way of\nincorporating an interventionist analysis into a fully compositional\nsemantics. However, interventionism does face other limitations. \nHiddleston (2005) presents the following\nexample. \n\n (48c)\n is intuitively true in this context. The network for\n (48)\n is given in\n Figure 13. \nFigure 13: Bayesian Network and\nStructural Equations for\n (48)\n  \nHiddleston (2005) observes that\ninterventionism does not predict \\(\\mathsf{F>B}\\) to be true. It\ntells one to delete the arrow going in to F, set its value to\n1, and project the consequences of doing so. However, none of the\nother values depend on F so they keep their actual values:\n\\(L=0\\) and \\(B=0\\). Accordingly, \\(\\mathsf{F>B}\\) is false,\ncontrary to intuition. Further, because the intervention on F\nhas destroyed its connection to B, it’s not even possible\nto tweak interventionism to allow values to flow backwards (to the\nleft) through the\n network.[43]\n Hiddleston’s (2005)\ncounterexample highlights the possibility of another kind of\ncounterexample featuring embedded conditionals. Consider again the\nnetwork in\n Figure 12.\n The following counterfactual seems true (Starr\n2012: 13). \nAnd, considering a simple match, Fisher (2017b:\n§1) observes that\n (50b)\n is intuitively false. \nIn both cases, interventionism is destined to make the wrong\nprediction. With\n (49),\n the intervention in the first antecedent removes the connection\nbetween Switch A and the light, so when the antecedent of the\nconsequent is made true by intervention, it does not result in\nL’s value becoming 0. And so the whole counterfactual\ncomes out false. Similarly with\n (50b),\n when the first antecedent is made true by intervention, it stays true\neven after the second antecedent is evaluated. Hence the whole\nconditional is predicted to be true. Fisher\n(2017a) also observes that interventionism also has no way of\ntreating counterlegal counterfactuals like if Switch A had alone\ncontrolled the light, the light would be on. \nThese counterexamples to interventionism have stimulated alternative\naccounts like Hiddleston’s (2005)\nminimal network analysis and further developments of that\nanalysis (Rips 2010; Rips & Edwards 2013;\nFisher 2017b). Instead of modifying an existing network to make\nthe antecedent true, this analysis considers alternate networks where\nonly the parent nodes of the antecedent which directly influence it\nare changed to make the antecedent come true. However, Pearl’s\n(2009) interventionist analysis has also\nbeen incorporated into the extended structural models\nanalysis (Lucas & Kemp 2015). This\nanalysis aims to capture interventions as a special case of a more\ngeneral proposal about how antecedents are made true. One important\naspect of this proposal is that interventions often involve inserting\na hidden node that amounts to an unknown cause of the antecedent. The\nanalysis of Snider and Bjorndahl (2015)\npursues a third idea: counterfactuals are not interpreted by\nmanipulating a background network, but instead serve to constrain the\nclass of possible networks compatible with the information shared in a\nconversation, as in Stalnaker’s (1978)\ntheory of\n assertion.[44]\n Among these relations can be cause-to-effect networks as in\n (45d),\n but also networks that involve the antecedent and consequent having a\ncommon cause, as in\n (48c).\n As should be clear, this is a rapidly developing area of research\nwhere it is not possible to identify one analysis as standard or\nrepresentative. It does bear emphasizing that this literature is\ndriven not only by precise formal models, but also by experimental\ndata which is brought to bear on the predictions of these\nanalyses. \nA few final philosophical remarks are in order about the kinds of\nanalyses discussed here. If one follows Woodward\n(2002) and Hitchcock\n(2001) in their interpretation of\nthese networks, a structural equation should be viewed as a primitive\ncounterfactual. It follows that this is a non-reductive analysis of\ncounterfactual dependence: it only explains how the truth of\narbitrarily complex counterfactual sentences are grounded in basic\nrelations of counterfactual dependence. However, note in the earlier\nquotation above from Pearl (2009:\n239–240) that he interprets structural equations as basic\nmechanisms or laws, and so arguably counts as an analysis of\ncounterfactuals in terms of laws. These amount to two very different\nphilosophical positions that interact with the philosophical debates\n surveyed in\n §1.3. \n\nIt is also worth noting that while many working in this framework\napply these networks to causal relations, there is no reason to assume\nthat the analysis would not apply to other kinds of dependence\nrelations. For example, constitutional dependence is at the heart of\ncounterfactuals like:  \nFrom a Bayesian Network approach to mental representation\n (§1.2.3),\n this makes perfect sense: the networks encode probabilistic\ndependence which can come from causal or constitutional facts. \nFinally, it is worth highlighting that the philosophical objections\ndirected at the similarity analysis in\n §2.6\n are addressed, at least to some degree, by structural equation\nanalyses. Because the central constructs of this\nanalysis—structural equations and Bayesian Networks—are\nalso employed in models of mental representation, causation, and\nscientific explanation, it grounds counterfactuals in a construct\nalready taken to explain how creatures like us cope with a world like\nthe one we live in. \nPremise semantics\n (3.1),\n conditional probability analyses\n (§3.2)\n and structural equation analyses\n (§3.3)\n all aim to analyze counterfactuals by focusing on certain relations\nbetween facts, rather than similarities between worlds. These accounts\nmake clearer and more accurate predictions about particular\ncounterfactuals in context than similarity analyses. But, ultimately,\nboth premise semantics and conditional probability analyses had to\nincorporate causal dependence into their theories. Structural equation\nanalyses do this from the start, and improve further on the\npredictions of premise semantics and conditional probability analyses.\nAnother strength of this analysis is that it integrates elegantly into\nthe broader applications of counterfactuals in theories of\nrationality, mental representation, causation, and scientific\nexplanation surveyed in\n §1.1.\n There is still rapid development of structural equation analyses,\nthough, so it is too early to say where the analysis will stabilize,\nor how it will fair under thorough critical examination. \nPhilosophers, linguists, and psychologists remain fiercely divided on\nhow to best understand counterfactuals. Rightly so. They are at the\ncenter of questions of deep human interest\n (§1).\n The renaissance on this topic in the 1970s and 1980s focused on\naddressing certain semantic puzzles and capturing the logic of\ncounterfactuals\n (§2).\n From this seminal literature, similarity analyses (D.\nLewis 1973b; Stalnaker 1968) have enjoyed\nthe most widespread popularity in philosophy\n (§2.3).\n But the logical debate between similarity and strict analyses is\nstill raging, and strict analyses provide a viable logical alternative\n (§2.4).\n Criticisms of these logical analyses have focused recent debates on\nour intuitions about particular utterances of counterfactuals in\nparticular contexts. Structural equation analyses\n (§3.3)\n have emerged as a particularly prominent alternative to similarity\nand strict analyses, which claims to improve on both in significant\nrespects. These analyses are now being actively developed by\nphilosophers, linguists, psychologists, and computer scientists.","contact.mail":"will.starr@cornell.edu","contact.domain":"cornell.edu"}]
