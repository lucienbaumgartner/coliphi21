[{"date.published":"2017-02-23","date.changed":"2021-03-22","url":"https://plato.stanford.edu/entries/logic-dependence/","author1":"Pietro Galliani","entry":"logic-dependence","body.text":"\n\n\nDependence logic is an extension of first-order logic which adds to it\ndependence atoms, that is, expressions of the form\n\\(\\eqord(x_1 \\ldots x_n, y)\\) which assert that the value of \\(y\\) is\nfunctionally dependent on (in other words, determined by) the values\nof \\(x_1 \\ldots x_n\\). These atoms permit the specification of\nnon-linearly ordered dependency patterns between variables,\nmuch in the same sense of IF-Logic slashed quantifiers; but,\ndifferently from IF-logic, dependence logic separates quantification\nfrom the specification of such dependence/independence conditions.\n\n\nThe principal semantics of dependence logic, called team\nsemantics, generalizes Tarski’s semantics by letting\nexpressions be satisfied or not satisfied with respect to\nsets of variable assignments rather than with respect to\nsingle assignments. This semantics pre-dates the development of\ndependence logic proper, and it was originally developed by Wilfrid\nHodges in the context of IF-logic (Hodges 1997). There also exists a\ngame-theoretic semantics for dependence logic, based on games of\nimperfect information and roughly analogous to the game-theoretic\nsemantics for independence-friendly logic (Väänänen\n2007a). Sensu stricto, the term “dependence\nlogic” refers exclusively to the language obtained by adding the\nabove-mentioned functional dependence atoms to the language of\nfirst-order logic; but the term is also used, in a more general sense,\nto refer to the the area of research that studies the properties of\nlogics obtained by adding various notions of dependence and\nindependence to first order logic, such as independence\nlogic (Grädel & Väänänen 2013),\nintuitionistic dependence logic (Yang 2013) or inclusion\nlogic (Galliani 2012, Galliani & Hella 2013), or even those\nof logics extending other logical frameworks through similar\natoms, as in the case of modal dependence logic\n(Väänänen 2008).\n\n In this article, the term “dependence logic” will be\nused to refer to dependence logic proper, and the term “logics\nof dependence and independence” will instead be used to refer to\nits variants and generalizations.\n\nOne feature of first order logic which accounts for much of its\nexpressivity and applicability is the fact that it allows quantifiers\nto be nested, and, hence, it permits the specification of\ndependency patterns between quantified variables. Consider,\nfor example, the (hopefully false) statement that “every boy\nloves some girl that loves some other boy”. It can be\nstraightforwardly translated into first order logic as  \nwhose truth condition, according to Tarski’s usual semantics, is\nprecisely what one would expect: the above expression is true if and\nonly if for every boy \\(b\\) it is possible to find a girl \\(g\\) and a\nboy \\(b'\\) such that \\(b\\) loves \\(g\\) and \\(g\\) loves \\(b'\\) and\n\\(b\\) and \\(b'\\) are not the same. The identity of the girl \\(g\\) may\nof course depend on the identity of the first boy \\(b\\)—after\nall, for this expression to be true we do not require that all boys\nare in love with all girls—and, furthermore, the identity of the\nsecond boy \\(b'\\) may depend on both the identity of the\nfirst boy \\(b\\) (since \\(b'\\) must be different from \\(b\\)) and from\nthe identity of the girl \\(g\\) that \\(b\\) loves. So the dependency\npattern between our quantified variables is as follows: \\(y\\)\ndepends on \\(x\\), while \\(z\\) depends on both \\(x\\) and \\(y\\). From a\nsyntactic perspective, this is reflected by the fact that \\(\\exists\ny\\) is in the scope of \\(\\forall x\\) while \\(\\exists z\\) is\nin the scope of both \\(\\forall x\\) and \\(\\exists y\\). \nDifferences in the dependency patterns between operators can be used\nto formalize important distinctions, such as for example the one\nbetween the continuity of a function \\(f\\)  \nand its uniform continuity  \nor, in intensional extensions of first order logic, to express the\ndifference between De Dicto and De Re readings\n(e.g., “It is possible for every person to be crazy” may\nbe understood either as stating that it for every person \\(p\\), it is\npossible for \\(p\\) to be crazy, \\(\\forall x (\\person (x)\n\\rightarrow \\Diamond \\crazy (x))\\), or as stating that it is\npossible that everyone is crazy together, \\(\\Diamond \\forall x\n(\\person (x) \\rightarrow \\crazy (x))\\)). \nDependency patterns between quantified variables in first order logic\nare necessarily transitive, as it is made evident by their\nconnections with the scopes of the corresponding sub-expressions: if\n\\(\\exists y\\) is in the scope of \\(\\forall x\\) and \\(\\exists z\\) is in\nthe scope of \\(\\exists y\\) then necessarily \\(\\exists z\\) will be in\nthe scope of (and, therefore, dependent from) \\(\\forall x\\).\nFurthermore, the set of all quantifiers in whose scope some subformula\n\\(\\alpha\\) lies is linearly ordered: if \\(\\alpha\\) is in the scope of\n\\(Q_1 x_1\\) and \\(Q_2 x_2\\), then either \\(Q_1 x_1\\) is in the scope\nof \\(Q_2 x_2\\) or vice versa. \nThis limits the expressive possibilities of first order logic. For\nexample, let us suppose that we wish to amend our previous assertion\nabout boys and girls as follows: every boy loves some girl that loves\nsome other boy, and this second boy can be chosen independently on the\nfirst one. What this means, intuitively speaking, is simple enough:\nfor every boy \\(b\\) we can find a girl \\(g\\) such that \\(b\\) loves\n\\(g\\), and for every such girl we can find a boy \\(b'\\) such that\n\\(g\\) loves \\(b'\\) and \\(b \\not = b'\\), and furthermore we can find\nthe identity of the second boy \\(b'\\) without knowing that of \\(b\\),\non the basis of the identity of the girl \\(g\\) alone. This can still\nbe the true in some scenarios, such as for example if two boys \\(b_1\\)\nand \\(b_2\\) love respectively two girls \\(g_1\\) and \\(g_2\\), who\nhowever love only \\(b_2\\) and \\(b_1\\) respectively. However, it is\neasily seen that it is not equivalent to our previous statement: for\nexample, if our universe consists (as in (b) above) of two boys \\(b\\)\nand \\(b'\\) and a girl \\(g\\), and \\(b\\) and \\(b'\\) both love \\(g\\) who\nloves both of them, then our previous assertion is true but the\ncurrent one is false. \nTwo scenarios in which (\\(\\ref{eq:boygirl1}\\)) is true. In (a), \\(z\\)\ncan be chosen independently from \\(x\\); in (b), it cannot. \nHowever, it is not clear how to formalize this condition in first\norder logic. In essence, we would need to modify\n(\\(\\ref{eq:boygirl1}\\)) so that \\(z\\) is not in the scope of \\(x\\),\nand hence it does not depend on it; however, we would still want \\(z\\)\nto depend on \\(y\\) and \\(y\\) on \\(x\\). As just discussed, however,\nsuch a dependency pattern is not realizable in first-order logic. We\ncan sidestep the issue by resorting to higher-order quantification:\nindeed, one can see that the expression  \ncaptures our intended interpretation, but only at the cost of explicit\nexistential quantification over functions. \nA possible alternative would be to expand the syntax of first order\nlogic in order to lift the restrictions about dependency patterns\nbetween quantified variables. This is the route taken by branching\nquantifier logic (Henkin 1961), in which the truth conditions of (\\(\\ref{boygirl2}\\))\ncorrespond to those of  \nand to independence-friendly logic, in which\n(\\(\\ref{boygirl2}\\)) is equivalent to  \nWe will not give here a detailed explanation of the semantics of these\ntwo formalisms; suffice to say, in (\\(\\ref{boygirl3}\\)) the value of\n\\(w\\) does not depend on the values of \\(x\\) and \\(y\\) (although it\nmay depend on the value of \\(z\\)), as they belong to different\n“rows” of the complex quantifier\n\\(\\left(\\begin{smallmatrix} \\forall x &\\exists y\\\\ \\forall z\n&\\exists w \\end{smallmatrix}\\right)\\), while in\n(\\(\\ref{boygirl4}\\)) the value of \\(z\\) does not depend on the value\nof \\(x\\), because this dependency is explicitly “slashed\naway” by the quantifier (\\(\\exists z / x\\)). \nOne feature common to branching quantifier logic and independence\nfriendly logic, as we can see, is that they do not separate the\nquantification of variables from the specification of non-standard\npatterns of dependence: as in the case of first order logic, whether a\nquantified variable \\(v_1\\) will or will not depend on some other\nquantified variable \\(v_2\\) will be determined by the respective\nposition and form of their quantifiers. \nDependence logic takes a different approach to the problem of\nextending first order logic in order to represent\n(\\(\\ref{boygirl2}\\)). Compared to (\\(\\ref{eq:boygirl1}\\)), the only\nnovel condition is the one that states that the value of \\(z\\) is\ndetermined by (that is, functionally dependent on) the value\nof \\(y\\); and this corresponds to a new atomic condition \\(\\eqord(y,\nz)\\), called a dependence atom, whose intended meaning is\nthat (the value of) \\(z\\) is a function of the value of \\(y\\).\nDifferently from the cases of branching quantifier logic or\nindependence-friendly logic, this is a condition over the values that\n\\(y\\) and \\(z\\) can take, not a condition over the behaviour of the\nquantifier \\(\\exists z\\): indeed, there is in general no reason to\nrequire that \\(z\\) is a quantified variable at all—it might well\nbe a free variable instead, or some complex term involving multiple\nvariables. \nIn dependence logic, (\\(\\ref{boygirl2}\\)) can be formalized as  \nThe truth conditions of (\\(\\ref{boygirl2}\\)), (\\(\\ref{boygirl3}\\)),\n(\\(\\ref{boygirl4}\\)) and (\\(\\ref{boygirl5}\\)) are precisely the same:\nany model that satisfies one of these expressions (in the respective\nlanguages) satisfies all four. More in general, as we will see, the\nexpressive powers of existential second-order logic,\nindependence-friendly logic and dependence logic with respect to\ndefinability of classes of models are precisely the same. This\nis, however, not the case for formulas with free variables; and\nfurthermore, these logics can be extended and modified along markedly\ndifferent lines. \nTeam semantics, first developed by Wilfrid Hodges in the context of\nindependence friendly logic (Hodges 1997), is a generalization of\nTarski’s semantics for first order logic to the case of multiple\nassignments of elements to variables. Sets of such assignments, called\nteams for historical reasons, constitute the fundamental\nsemantic notion of team semantics, and formulas are satisfied or not\nsatisfied with respect to them rather than with respect to single\nassignments. The connection between team semantics and Tarski\nsemantics is shown by the following result, which holds in dependence\nlogic as well as in all its first order variants: \nConservativity:\n\nA first order formula is satisfied by a team \\(X\\) (in the sense of\nteam semantics) if and only if all assignments \\(s \\in X\\) satisfy it\n(in the sense of Tarski semantics).  \nMore in general, teams can be understood as belief sets,\nrepresenting the set of all states of the world (=assignments) that\nsome agent believes possible. Then a team \\(X\\) will satisfy some\nformula \\(\\phi\\) if and only if \\(\\phi\\) holds when \\(X\\) is the set\nof all possible states; and in this case, we will write \\(X \\models\n\\phi\\) (or \\(M, X \\models \\phi\\) if the choice of the model \\(M\\) is\nnot clear). In this section, we will examine the rules of team\nsemantics and their interpretation in terms of this principle; then,\nin the next section, we will discuss how it also arises from the\nimperfect-information game-theoretic semantics for dependence\nlogic. \nThe condition for the new dependence atoms \\(\\eqord(x_1 \\ldots x_n,\ny)\\), which correspond to the statement that the value of \\(y\\) is a\nfunction of the values of \\(x_1 \\ldots x_n\\), is easily\nunderstood: \nTS-dep:\n\n\\(X \\models ~\\eqord(x_1 \\ldots x_n, y)\\) if and only if any two\nassignments \\(s_1, s_2 \\in X\\) which agree on the values of \\(x_1\n\\ldots x_n\\) also agree on the value of \\(y\\).  \nFor example, suppose that \\(X\\) is a set of assignments over the three\nvariables \\(x_1\\), \\(x_2\\) and \\(y\\), where \\(x_1\\) represents the\nnationality of a candidate to a position, \\(x_2\\) represents their\nscore (according to a suitable evaluation method) and \\(y\\) represents\nwhether they were accepted or rejected. Then the atom \\(\\eqord(x_2,\ny)\\) corresponds to the statement that the offer is determined by the\nscore alone: if two candidates have the same score they will receive\nexactly the same offer, regardless of any other factor. A special case\nof dependence atom is given by the constancy atoms\n\\(\\eqord(y)\\), which—as per the above semantics—are\nsatisfied by a team if and only if all of its assignments agree over\nthe value of \\(y\\). \nTable 1: A team \\(X\\) in which \\(y = x_1\n+ x_2\\). Here \\(y\\) is a function of \\(x_1\\) and \\(x_2\\), and hence\n\\(=\\!\\!(x_1 x_2, y)\\) holds; however, \\(y\\) is not a function of\n\\(x_1\\) alone, so \\(=\\!\\!(x_1, y)\\) does not hold. \nUnder the same interpretation, the rules for first-order literals and\nconjunctions (for simplicity, we will assume that our expressions are\nin negation normal form; and, as is customary, we will assume that the\nnegations of dependence atoms are never satisfied) are easy to\nderive: \nTS-lit:\n\nFor all first-order literals \\(\\alpha\\), \\(X \\models \\alpha\\) if and\nonly if for all assignments \\(s \\in X\\), \\(s \\models \\alpha\\) in the\nusual Tarski semantics sense;  \nTS-\\(\\land\\):\n\n\\(X \\models \\phi \\land \\psi\\) if and only if \\(X \\models \\phi\\) and\n\\(X \\models \\psi\\). \nIt is worth pointing out that, as we can already see by these rules,\nthe law of the excluded middle does not hold in dependence\nlogic (just as it does not hold in independence friendly logic): for\nexample, if a team \\(X\\) contains both assignments \\(s\\) with \\(s(x) =\ns(y)\\) and assignments \\(s'\\) with \\(s'(x) \\not = s'(y)\\) then \\(X\n\\not \\models x=y\\) and \\(X \\not \\models x\\not = y\\). In this section,\nin any case, we will present the language of dependence logic without\nan explicit negation operator; then, later, we will discuss the\nconsequences of adding it to its language. \nWhat about universal quantification? In which circumstances should a\nuniversally quantified expression \\(\\forall v \\psi\\) hold in a team?\nAgain, we must recall the intuition according to which a team\nrepresents a set of possible states of things. If we wish to evaluate\n\\(\\forall v \\psi\\), with respect to which possible states of things\nshould we evaluate \\(\\psi\\)? The natural answer is that we should\nconsider all states of things that differ from ones in \\(X\\) only with\nrespect to the value of \\(v\\). This justifies the following rule: \nTS-\\(\\forall\\):\n\n\\(X \\models \\forall v \\psi\\) if and only if \\(X[M/v] \\models \\phi\\),\nwhere \\(X[M/v]\\) is the set \\(\\{s' : \\exists s \\in X \\mbox{ s.t. } s'\n\\sim_v x\\}\\)  \nwhere \\(s' \\sim_v s\\) means that the two assignments \\(s\\) and \\(s'\\)\ndiffer from each other at most with respect to the value of the\nvariable \\(v\\). \nTable 2: \\(X\\) and \\(X[M/y]\\) in a model\nwith two elements \\(0\\) and \\(1\\). \nLet us now consider disjunction. When should \\(\\phi \\lor \\psi\\) hold?\nTo answer this, let us recall—once again—that teams can be\nunderstood as sets of possible states of things, and that therefore\nthe union of two teams \\(Y\\) and \\(Z\\) represents all states of things\nwhich may occur if \\(Y\\) or \\(Z\\) is the case. Therefore, if the two\nformulas \\(\\phi\\) and \\(\\psi\\) are satisfied by the set of teams\n\\(\\{Y_1 \\ldots Y_n, \\ldots\\}\\) and \\(\\{Z_1 \\ldots Z_n, \\ldots\\}\\)\nrespectively, their disjunction \\(\\phi \\lor \\psi\\) should be satisfied\nby the set of teams \\(\\{Y_i \\cup Z_j : i,j \\in 1, \\ldots\\}\\), or,\nequivalently, \nTS-\\(\\lor\\):\n\n\\(X \\models \\phi \\lor \\psi\\) if and only if \\(X=Y \\cup Z\\) for two\nteams \\(Y\\) and \\(Z\\) such that \\(Y \\models \\phi\\) and \\(Z \\models\n\\psi\\).  \nIt is worth pointing out here that we do not require, in\ngeneral, that \\(Y\\) and \\(Z\\) are disjoint. Because of the\ndownwards closure property, which we will discuss soon, this\nadditional condition would make no difference for the semantics of\ndependence logic proper; but in the case of certain extensions and\nvariants of dependence logic, that additional requirement would\nconflict with the principle of locality according to which\nthe satisfaction conditions of an expression depend only on the values\nof the variables which occur free in it (Galliani 2012). \nIt is also important to note that, in dependence logic, disjunction is\nnot idempotent: for example, \\(\\eqord(x,y) \\lor \\eqord(x,y)\\)\nis not equivalent to \\(\\eqord(x,y)\\), and it is satisfied by a team\n\\(X\\) if and only if for every three assignments in \\(X\\)\nwhich agree on \\(x\\) at least two agree on \\(y\\). This may\nappear somewhat counter-intuitive; but it is a straightforward\nconsequence of the fact that, under our interpretation, \\(\\eqord(x,y)\n\\lor \\eqord(x,y)\\) is to be read as “every possible state of\nthings comes from one of two sets of states of things, and in both of\nthem \\(y\\) is a function of \\(x\\)”. Since the union of functions\nis not in general a function, it comes to little surprise that\ndisjunction in dependence logic is not idempotent. \nFinally, we consider the case of existential quantification. When is\nthe expression \\(\\exists v \\psi\\) satisfied by a team? In order to\nanswer this, we may begin by considering the interpretation of the\nrestriction operator which, given any team \\(X\\), results in\nthe team \\(X_{\\backslash v}\\) obtained by removing the variable \\(v\\)\n(if present) from all assignments \\(s \\in X\\) (and then, since \\(X\\)\nis a set, by collapsing identical assignments). This could be\nunderstood as a forgetting operation, through which we delete\nall information about the value of \\(v\\)—for example, because\nwhat we believed about this value was unreliable, or because this\nvalue has been altered. Now suppose that \\(X_{\\backslash v} =\nY_{\\backslash v}\\): then, in our interpretation, this means that the\nsets of possible states of things represented by \\(X\\) and \\(Y\\)\ndisagree at most with respect to the value of \\(v\\). Thus, if \\(Y\\)\nsatisfies the condition \\(\\phi\\), we may say that \\(X\\) would satisfy\n\\(\\phi\\) if not for the value of \\(y\\), or, equivalently,\nthat \\(X\\) satisfies \\(\\exists v \\psi\\). This justifies the following\nrule: \nTS-\\(\\exists\\):\n\n\\(X \\models \\exists v \\psi\\) if and only if there exists some \\(Y\\),\nover the variables of \\(X\\) and \\(v\\), such that \\(X_{\\backslash v} =\nY_{\\backslash v}\\) and \\(Y \\models \\psi\\).  \nIt is straightforward to verify that this is the case if and only if\n\\(Y\\) is of the form \\(X[F/y] = \\{s[a/y] : s \\in X, a \\in F(s)\\}\\) for\nsome function \\(F\\) from assignments in \\(X\\) to nonempty sets of\nelements of our model. \nIt is worth pointing out here that it is not in general required by\nthe above definition that \\(X\\) and \\(Y\\) contain the same number of\nassignments: a single assignment in \\(X\\) may well correspond to\nmultiple assignments in \\(Y\\), and—if \\(v\\) is already a\nvariable occurring in the assignments of \\(X\\)—a single\nassignment in \\(Y\\) may also correspond to multiple assignments in\n\\(X\\). \nTable 3: \\(X\\) and \\(X[F/y]\\) for\n\\(F(s_0) = \\{0,1\\}\\), \\(F(s_1) = \\{0\\}\\) \nWe will postpone an in-depth discussion of the properties of\ndependence logic to after the specification of its game-theoretic\nsemantics. However, we conclude this section with the following three\nimportant consequences of the above-given rules: \nLocality:\n\nIf the restrictions of \\(X\\) and \\(Y\\) to the variables occurring free\nin \\(\\phi\\) are the same then \\(X \\models \\phi\\) if and only if \\(Y\n\\models \\phi\\).  \nDownwards closure:\n\nIf \\(X \\models \\phi\\) and \\(Y \\subseteq X\\) then \\(Y \\models \\phi\\).\n \nEmpty set property:\n\nIf \\(\\emptyset\\) is the team containing no assignments then\n\\(\\emptyset \\models \\phi\\) for all dependence logic formulas \\(\\phi\\).\n \nThe locality principle, together with the conservativity principle\nmentioned at the beginning of this section, constitutes an important\n“sanity condition” that any variant and extension of\ndependence logic should satisfy. The same cannot be said about\ndownwards closure and the empty set property, which—as we will\nsee—are violated by variants of dependence logic. \nFinally, we need to define the truth of a dependence logic\nsentence with respect to a model. Since a sentence has no free\nvariables, by the locality principle we have at once that either all\nnonempty teams satisfy it or no nonempty team satisfies it. This is\nanalogous to the case of Tarski’s semantics, in which a sentence\nis either satisfied by all variable assignments or by none of them.\nThus, we can define truth in the usual way: \nTruth in team semantics:\n\nA sentence \\(\\phi\\) is true in a model \\(M\\) if and only if \\(M,\n\\{\\emptyset\\} \\models \\phi\\), where \\(\\{\\emptyset\\}\\) is the team\ncontaining only the empty assignment. In this case, we write that \\(M\n\\models \\phi\\).  \nAs mentioned, the game-theoretic semantics for dependence logic is a\nvariant of the imperfect-information semantics for\nindependence-friendly logic, which is itself an adaptation of the\ngame-theoretic semantics of first-order logic. We refer the reader to\n(Väänänen 2007a) for a formal, detailed definition of\nthis semantics. \nIn game-theoretic semantics, a sentence \\(\\phi\\) and a model \\(M\\) are\nmade to correspond to a (usually two-player) game \\(G_M(\\phi)\\). Then\ntruth is defined in terms of the existence of winning\nstrategies for one of the players (who, in this work, will be\ncalled simply “Player \\(0\\)”): in other words, if\n\\(\\sigma_0\\) is a (possibly non-deterministic) strategy for Player\n\\(0\\) and \\(\\Pi(G_M(\\phi), \\sigma_0)\\) is the set of all plays which\nare compatible with \\(\\sigma_0\\) then \\(\\phi\\) is true if and only if\nevery play in \\(\\Pi(G_M(\\phi), \\sigma_0)\\) is winning for Player\n\\(0\\). It is possible to think of the game \\(G_M(\\phi)\\) as a debate\nbetween two players, one of whom (Player \\(0\\)) wishes to demonstrate\nthat it is the case that \\(\\phi\\) while the other (Player \\(1\\))\nwishes to demonstrate that it is not the case that \\(\\phi\\). \nAs in the case of first-order logic and independence-friendly logic,\nin the imperfect-information game for dependence logic the positions\nof the game are pairs \\((\\theta, s)\\), where \\(\\theta\\) is an instance\nof a subformula of \\(\\phi\\) (that is, multiple occurrences of the same\nexpression as a subformula of \\(\\phi\\) are to be considered\nseparately) and \\(s\\) is a variable assignment over the model\n \\(M\\).[1]\n The initial position is \\((\\phi, \\emptyset)\\), where \\(\\emptyset\\) is\nthe empty assignment; and a non-deterministic strategy \\(\\sigma_0\\)\nfor Player \\(0\\) selects, for every disjunction and existential\nquantification, one or more successors of the current\nposition according to the following rules: \nIf the current position is of the form \\((\\psi \\lor \\theta, s)\\) then\nits successors are \\((\\psi, s)\\) and \\((\\theta, s)\\); \nIf the current position is of the form \\((\\exists v \\psi, s)\\) then\nits successors are all positions \\((\\psi, s')\\) with \\(s' \\sim_v\ns\\). \nSimilarly, the successors of \\((\\psi \\land \\theta, s)\\) are \\((\\psi,\ns)\\) and \\((\\theta, s)\\), and the successors of \\((\\forall v \\psi,\ns)\\) are all positions of the form \\((\\psi, s')\\) for \\(s' \\sim_v s\\);\nbut a strategy for Player \\(0\\) cannot specify a successor for these\npositions, as it is assumed that Player \\(1\\) chooses which position\nfollows them. \nA sequence of positions \\(\\overline \\rho = \\rho_0 \\rho_1 \\ldots\n\\rho_n\\) is a play of \\(G_M(\\phi)\\) if and only if \n\\(\\rho_0 = (\\phi, \\emptyset)\\); \nFor all \\(i = 1 \\ldots n\\), \\(\\rho_{i}\\) is a successor of\n\\(\\rho_{i-1}\\). \nIf furthermore \\(\\rho_{i+1} \\in \\sigma_0(\\rho_i)\\) whenever \\(\\rho_i\\)\ncorresponds to a disjunction or an existential quantifier, we say that\n\\(\\overline \\rho\\) respects the strategy \\(\\sigma_0\\); and as\nmentioned, we write \\(\\Pi(G_M(\\phi), \\sigma_0)\\) for the set of all\nplays over \\(G_M(\\phi)\\) which respect \\(\\sigma_0\\). \nWe say that a strategy \\(\\sigma_0\\) is winning if every play\n\\(\\overline \\rho\\) which ends in a position \\((\\alpha, s)\\) where\n\\(\\alpha\\) is a first-order literal is such that the assignment \\(s\\)\nsatisfies \\(\\alpha\\) in the usual sense of Tarski’s semantics.\nDependence atoms—and the plays which ends in dependence\natoms—are of no relevance for deciding whether a given strategy\nis winning. However, they are used to specify whether a given strategy\nis uniform: \nUniformity condition\n\nA strategy \\(\\sigma_0\\) for \\(G_M(\\phi)\\) is uniform if any two plays\n\\(\\overline \\rho, \\overline \\gamma \\in \\Pi(G_M(\\phi), \\sigma_0)\\)\nwhich end in two positions \\((\\eqord(x_1 \\ldots x_n, y), s)\\),\n\\((\\eqord(x_1 \\ldots x_n, y), s')\\) for the same instance of the\ndependence atom \\(\\eqord(x_1 \\ldots x_n, y)\\) we have that  \nThen we can define truth in game-theoretic semantics as follows: \nTruth in game-theoretic semantics:\n\nA sentence \\(\\phi\\) is true in a model \\(M\\) (with respect to\ngame-theoretic semantics) if and only if Player \\(0\\) has a uniform\nwinning strategy in \\(G_M(\\phi)\\). \nIt can be shown that this notion is equivalent to the notion of truth\nin team semantics. In fact, we can show more than this. If, for any\nteam \\(X\\) and formula \\(\\phi\\), the game \\(G_{M,X}(\\phi)\\) is played\nas \\(G_M(\\phi)\\) but with the initial position chosen randomly for\nevery play from \\(\\{(\\phi, s) : s \\in X\\}\\), then the following\nholds: \nEquivalence of GTS and team semantics:\n\nA formula \\(\\phi\\) is satisfied by a team \\(X\\) (with respect to a\nmodel \\(M\\)) if and only if Player \\(0\\) has a uniform winning\nstrategy in \\(G_{M,X}(\\phi)\\). \nThis result, as an aside, makes it clear why the team semantics of\ndependence logic satisfies the empty set property and the downwards\nclosure property. Indeed, if \\(X = \\emptyset\\) then every strategy for\nPlayer \\(0\\) in \\(G_{M, X}(\\phi)\\) is trivially winning and uniform;\nand if \\(X \\subseteq Y\\) then any uniform winning strategy for Player\n\\(0\\) in \\(G_{M, X}(\\phi)\\) is also a uniform winning strategy for\nPlayer \\(0\\) in \\(G_{M, Y}(\\phi)\\). \nSentence-wise, dependence logic is equivalent to the existential\nfragment \\(\\Sigma_1^1\\) of second-order logic. More precisely, it can\nbe proved (Väänänen 2007a) that \nSentence-wise equivalence of dependence logic and\n\\(\\Sigma_1^1\\):\n\nFor every dependence logic sentence \\(\\phi\\) there exists a\n\\(\\Sigma_1^1\\) sentence \\(\\phi^*\\) such that  \nSimilarly, for every \\(\\Sigma_1^1\\) sentence \\(\\phi^*\\) there exists a\ndependence logic sentence \\(\\phi\\) such that (\\(\\ref{eq:DLESO}\\))\nholds. \nSince Fagin’s Theorem (Fagin 1974) shows that a property of\nfinite models is definable in \\(\\Sigma_1^1\\) if and only if it is\nrecognizable in polynomial time by a nondeterministic Turing machine\n(that is, if and only if it is in NPTIME), it follows at once that \nDependence logic and NPTIME:\n\nFor any dependence logic sentence \\(\\phi\\), the class of all finite\nmodels which satisfy it is in NPTIME. Furthermore,for any NPTIME class\n\\(\\mathcal K\\) of finite models, there exists a dependence logic\nsentence \\(\\phi\\) such that \\(M \\models \\phi\\) if and only if \\(M \\in\n\\mathcal K\\). \nAnother direct consequence of the equivalence between dependence logic\nand \\(\\Sigma_1^1\\) on the level of sentences is that the compactness\ntheorem and the Löwenheim-Skolem theorem both hold for dependence\nlogic too (Väänänen 2007a): \nCompactness:\n\nIf a set \\(\\Phi\\) of finite dependence logic sentences is not\nsatisfiable in any model then some finite subset \\(\\Phi_0 \\subseteq_f\n\\Phi\\) of it is already not satisfiable. \nLöwenheim-Skolem theorem:\n\nIf a dependence logic sentence has an infinite model then it has\nmodels of all infinite cardinalities. \nHowever, matters are more delicate when it comes to formulas with free\nvariables. Then it is possible to show (Kontinen &\nVäänänen 2009) that dependence logic corresponds to the\ndownwards-closed fragment of existential second order\nlogic: \nTeam definability in dependence logic\n\nA set \\(\\mathcal X\\) of teams over a model \\(M\\) and a set \\(V\\) of\nvariables is of the form \\(\\{X : M, X \\models \\phi\\}\\) for some\ndependence logic formula \\(\\phi\\), with free variables in \\(V\\), if\nand only if \n\\(\\mathcal X\\) is nonempty; \n\\(\\mathcal X\\) is downwards closed, that is, \\(Y \\subseteq X \\in\n\\mathcal X \\Rightarrow Y \\in \\mathcal X\\); \n\\(\\mathcal X\\) is \\(\\Sigma_1^1\\)-definable in \\(M\\), that is, there\nexists a \\(\\Sigma_1^1\\) sentence \\(\\Psi(R)\\), over the\nvocabulary of \\(M\\) plus the new \\(|V|\\)-ary relation symbol \\(R\\),\nsuch that  \nwhere \\(\\textrm{Rel}(X)\\) is the \\(|V|\\)-ary relation \\(\\{s(V) : s \\in\nX\\}\\) which corresponds to the team \\(X\\). \nIn (Durand & Kontinen 2012), the effect of restricting the number of\ndependent variables of dependence atoms or the number of universal\nquantifiers was examined. It was shown that both of these ways of\ndefining fragments of dependence logic give rise of hierarchies: \nFor all \\(k\\), let \\(\\mathcal D(k-\\forall)\\) be dependence logic\nrestricted to at most \\(k\\) universal quantifiers and let \\(\\mathcal\nD(k-dep)\\) be dependence logic restricted to dependency atoms of the\nform \\(\\eqord(\\vec x, y)\\) for \\(|\\vec x| \\leq k\\). Then  \nand \nwith respect to the expressive power of sentences. \nSo far, we assumed that all dependence logic expressions are in\nnegation normal form, and that dependence atoms are never negated.\nAdding an explicit negation operator to the language of dependence\nlogic, on the other hand, is somewhat problematic, owing to the fact\nthat existential second order logic is not closed under negation.\nIndeed, the “obvious” negation rule  \ngreatly increases the expressive power of dependence logic, extending\nit to team logic (Väänänen 2007a,b), which is,\nin a very strong sense, equivalent to full second order logic\n(Kontinen & Nurmi 2009). \nA less strong, “dual” negation \\(\\lnot\\) can be defined in\nterms of de Morgan’s rules, \\(\\lnot(\\phi \\lor [\\land] \\psi)\n\\equiv (\\lnot \\phi) \\land [\\lor] (\\lnot \\psi)\\) and \\(\\lnot (\\exists v\n[\\forall v] \\phi) \\equiv \\forall v [\\exists v] (\\lnot \\phi)\\), plus\nthe law of double negation \\(\\lnot \\lnot \\phi \\equiv \\psi\\) and the\nrule  \nfor negations of dependence atoms (Väänänen 2007a,b).\nThe resulting language is expressively equivalent to negation-free\ndependence logic, and, in fact, the description of dependence logic of\n(Väänänen 2007a) considers this negation as part of its\nlanguage; however, as shown in (Kontinen & Väänänen\n2011), the satisfaction conditions of a dependence logic formula and\nthose of its negation have little connection to one another. More\nprecisely: \nDual negation and dependence logic:\n\nFor any two dependence logic formulas \\(\\phi\\) and \\(\\psi\\) such that\n\\(\\phi \\land \\psi\\) is not satisfiable, there exists a dependence\nlogic formula \\(\\theta\\) such that  \nand \nfor all models \\(M\\) and teams \\(X\\). \nThus, nothing in general can be said about the dual negation of\n\\(\\phi\\) except that it is equivalent to some dependence logic\nexpression which is not satisfied by any team which satisfies\n\\(\\phi\\). Since, as already mentioned, the law of the excluded middle\nfails in dependence logic, this is not a very informative property; in\nparticular, it is possible to find in dependence logic (with dual\nnegation) equivalent expressions with non-equivalent negations, like\nfor example \\(x \\not = x \\land y \\not = y\\) and\n\\(\\lnot\\eqord(x,y)\\). \nLike independence friendly logic, dependence logic can define its own\ntruth operator (Väänänen 2007a), that is, if for all\nformulas \\(\\phi\\) we have that \\(\\lceil \\phi\\rceil\\) is the Gödel\nnumber of \\(\\phi\\) then we can find a formula \\(\\tau(x)\\), with \\(x\\)\nas its only free variable, such that  \nfor all models \\(M\\) which satisfy Peano’s axioms for natural\nnumbers. This is not in contradiction with Tarski’s\nundefinability theorem, because dependence logic is not closed under\ncontradictory negation. \nThe problem of deciding whether a dependence logic sentence is valid\n(that is, true in all models) is non-arithmetical, and in fact\ncomplete with respect to the \\(\\Pi_2\\) class of the Levy hierarchy.\nNonetheless, the proof theory of dependence logic has been studied. In\nparticular, in (Kontinen & Väänänen 2013), a sound\nand complete proof system has been developed for the problem of\nfinding the first order consequences of a dependence logic\ntheory. \nIn this section, we will briefly summarize the properties of the most\nstudied variants of dependence logic. Many such variants exist, and\nmuch work has been done on their classification and comparison. In\nthis work, we will only mention those variants which are of special\nsignificance because of their relationship with dependence logic\nproper. \nRather than extending first order logic with dependence atoms\n\\(\\eqord(\\vec x, y)\\), independence logic (Grädel &\nVäänänen 2013) extends it with independence\natoms \\(\\vec x \\mathop{\\bot_{\\vec z}} \\vec y\\), whose intended\ninterpretation is “for any possible choice of \\(\\vec z\\), the\npossible values of \\(\\vec x\\) and \\(\\vec y\\) are\nindependent”—in other words, given any fixed choice of\n\\(\\vec z\\), knowing the value taken by \\(\\vec x\\) would not convey any\ninformation about the value taken by \\(\\vec y\\). This is a notion of\nsignificant conceptual importance: for example, one may want to\nexpress that—if one does not know the encryption\nkey—seeing the encrypted version of a message carries no\ninformation about the corresponding clear-text version. If \\(x\\)\nrepresents the encrypted message and \\(y\\) represents the plain-text\none, then this corresponds to the condition \\(x \\mathop{\\bot} y\\),\nwhere \\(\\vec z\\) in this case is empty. Similarly, if \\(k\\) represents\nthe key then \\(x \\mathop{\\bot} k\\) represents the claim that the key\ncannot be inferred from the encrypted message; and the conjunction\ndependence atom \\(\\eqord(k, x, y)\\) (which, as we will soon see, can\nbe represented in independence logic) represents the claim that the\nplain-text message can be decoded given the encrypted message and the\nkey. \nFormally, the satisfaction rule for independence atoms can be given as\nfollows: \nTS-indep:\n\n\\(M \\models_X \\vec x \\mathop{\\bot_{\\vec z}} \\vec y\\) if and only if\nfor all \\(s, s' \\in X\\) with \\(s(\\vec z) = s'(\\vec z)\\) there exists a\n\\(s'' \\in X\\) with \\(s''(\\vec z\\, \\vec x) = s(\\vec{x}\\, \\vec{z})\\) and\n\\(s''(\\vec y) = s'(\\vec y)\\). \nIndependence logic is strictly more expressive than dependence logic:\nindeed, it lacks the downwards closure property, and the dependence\natom \\(\\eqord(\\vec x, y)\\) is equivalent to the independence atom \\(y\n\\mathop{\\bot_{\\vec x}} y\\). Furthermore, it can also be shown\n(Galliani & Väänänen 2014) that conditioned\nindependence atoms \\(\\vec x \\mathop{\\bot_{\\vec y}} \\vec z\\) can be\ndefined in terms of unconditional independence atoms \\(\\vec x\n\\mathop{\\bot} \\vec y\\). \nSentence-wise, independence logic is also equivalent to existential\nsecond order logic \\(\\Sigma_1^1\\); but formula-wise, it is more\nexpressive, and it was shown in Galliani 2012 that it can capture all\nnonempty \\(\\Sigma_1^1\\)-definable team properties. \nInclusion logic (Galliani 2012, Galliani & Hella 2013) extends\nfirst-order logic with inclusion atoms \\(\\vec x \\subseteq\n\\vec y\\), reminiscent of the inclusion dependencies of database\ntheory. Its semantics is: \nTS-inc:\n\n\\(M \\models_X \\vec x \\subseteq \\vec y\\) if and only if for all \\(s \\in\nX\\) there exists a \\(s' \\in X\\) such that \\(s(\\vec x) = s'(\\vec\ny)\\). \nDifferently from dependence and independence logic, inclusion logic is\n(sentence-wise) strictly weaker than existential second order logic.\nIn fact, it can be shown (Galliani & Hella 2013) to be equivalent\nto the positive fragment of greatest fixed point logic, and,\ntherefore, to capture PTIME properties of models over finite ordered\nmodels. Formula-wise, inclusion logic is strictly weaker than\nindependence logic but incomparable with dependence logic: indeed, the\nsatisfiability conditions of its formulas are not downwards closed,\nbut they are closed by unions in the sense that  \nTeam logic (Väänänen 2007a,b; Kontinen & Nurmi\n2009) extends dependence logic by adding to it a contradictory\nnegation \\(\\lnot\\). It is equi-expressive with full second order\nlogic, both in terms of definability of classes of models\n(Väänänen 2007b) and with respect to the classes of teams that team logic\nexpressions can define with respect to a given model (Kontinen &\nNurmi 2009). In (Lück 2019), a Hilbert-style axiomatization for Team Logic (and for its modal and propositional equivalents) was found that is complete for its dependence-free fragment (that is, for the fragment in which dependence atoms do not appear). \nIntuitionistic dependence logic (Abramsky &\nVäänänen 2009; Yang 2013) extends dependence logic by\nadding an implication connective \\(\\phi \\rightarrow \\psi\\), whose\nsatisfaction rules are given in team semantics by \nTS-\\(\\rightarrow\\):\n\n\\(X \\models \\phi \\rightarrow \\psi\\) if and only if for all subsets\n\\(Y\\) of \\(X\\), if \\(Y \\models \\phi\\) then \\(Y \\models \\psi\\). \nThis operator is called the “intuitionistic implication”,\nbecause of the similarity between its semantics and the one of the\nimplication operator in Kripke’s semantics for intuitionistic\nlogic (Kripke 1965). Its interpretation in terms of belief is quite\nstraightforward: if the assignments in \\(X\\) represent the states\nof thing that some agent believes possible, then a subset \\(Y\\)\nof \\(X\\) may represent the result of a belief update in which\nthe agent rejects some previously believed possible states of thing,\nand \\(\\phi \\rightarrow \\psi\\) states than any such update that would\ncause \\(\\phi\\) to hold would also cause \\(\\psi\\) to hold. From this\nstandpoint, this is a very natural concept which permits us to\ndescribe predictions about how such an agent’s overall belief\nstate would react to belief updates. \nHowever, because of the second order universal quantification implicit\nin its semantics, this connective suffices to greatly increase the\nexpressive complexity of the logic: in particular, as shown in (Yang\n2013), any sentence of second order logic is equivalent to some\nsentence of intuitionistic dependence logic. Intuitionistic dependence\nlogic retains the downwards closure property: if a team satisfies an\nintuitionistic dependence logic formula then so do all of its\nsubsets. \nThe variants and extensions of Dependence Logic seen above are all\ngenerated from First Order Logic (with Team Semantics) by introducing\nnew atoms or connectives. It is possible to consider generalized\ndependence atoms (Kuusisto 2015), much in the same way in which\ngeneralized quantifiers are introduced in classical First Order Logic,\nand ask questions like: \nNo complete answer to these questions is known at the moment. Some\npartial results, however, are known: \nThese are all partial results, however, and the general theory of\ndependencies and connectives in Team Semantics is still in its\ninfancy.  \nA related topic is the study of extensions of Dependence Logic via\ngeneralized quantifiers (Engström 2012). An interesting result\nalong these lines consists in axiomatization for the extension of\nDependence Logic via the quantifier \\(Q\\) “there exist\nuncountably many…”, which is sound and complete for the\n\\(\\textbf{FO}(Q)\\) consequences of a theory (Engström, Kontinen\n& Väänänen 2017).  \nAlso worth pointing out in this context is the work of (Kontinen\n& Yang 2019), which found a logic based on Team Semantics (with\ndifferent choices of connectives than the “standard” ones\nof Dependence Logic) whose formulas capture precisely the\nfirst-order-definable properties of teams. \nThe dependence and independence atoms considered so far express\nrelationships between the possible values of variables in a\nset of assignments. However, the same notions of dependence and\nindependence can be equally naturally be applied to proposition\nthemselves, as it happens in natural language expression such as for\ninstance “Whether he will or will not pass the course depends\nonly on the content of his final exam”. \nPropositional Dependence Logic consider such atoms within the context\nof propositional logic. Propositional dependence logic teams are sets\nof valuations \\(v\\) from propositional atoms \\(p_1 \\ldots\np_n\\) to \\(\\{T, F\\}\\). Its semantic rules – and their\njustifications – mirror very closely the ones of first order\nteam semantics, and the rule for dependence atoms is \nPTS-dep:\n\n\\(X \\models \\eqord(p_1 \\ldots p_n, q)\\) if and only if any two\nvaluations \\(v_1, v_2 \\in X\\) which agree on the values of \\(p_1\n\\ldots p_n\\) also agree on the value of \\(q\\). \nMany of the variants and generalizations of first order dependence\nlogic can be lowered to the propositional level without any\ndifficulty: thus, for example, it is possible to study the properties\nof propositional inclusion logic, propositional team logic,\npropositional intuitionistic dependence logic and so on. \nWhereas (first order) dependence logic is strictly more expressive\nthan first order logic, propositional dependence logic is not more\nexpressive than propositional logic, as it follows immediately from\nthe fact that all propositional functions are expressible in\npropositional logic. There exists, however, a close relation between\nthe teams of propositional dependence logic and the information\nstates of inquisitive logic (Groenendijk 2009; Ciardelli\n& Roelofsen 2011), a semantic framework for the study of the\nnotion of meaning and information exchange: in particular, the\nimplication of inquisitive logic is exactly the same as the one of\npropositional intuitionistic dependence logic. \nAxiomatizations for propositional dependence logic and many of its\nextensions can be found in (Yang & Väänänen 2016);\nand the analysis of the computational complexity of this formalism\n(and of related propositional logics based on Team Semantics) can be\nfound in (Virtema 2017; Hannula et al. 2018). \nModal dependence logic (Väänänen 2008) and its variants\nextend modal logic by adding to it the same dependence atoms\n\\(\\eqord(p_1 \\ldots p_n, q)\\) already considered in the case of\npropositional dependence logic. \nIts satisfaction conditions can be defined through a variant of team\nsemantics in which teams are replaced by sets of possible\nworlds. \nMuch research has investigated the complexity-theoretic properties of\nthis logic, of its fragments, and its extensions (Ebbing, Lohmann,\n& Yang 2011; Ebbing & Lohmann 2012; Lohmann & Vollmer\n2013). \nModal Independence Logic has also been investigated in (Kontinen et al, 2017). \n \nLinear Temporal Logic may also be given a “Team Semantics”\nof sorts, in which formulas are evaluated with respect to sets of\ntraces (that is to say, sets of sequences of states), representing\npossible computations of a system. Such a logical framework can be\nused for the specification and verification of\nhyperproperties (Krebs et al. 2017, Other Internet Resources;\nLück 2020), that is to say, properties like “The system\nterminates within a bounded amount of time” whose truth cannot\nbe ascertained by checking every possible trace of the system on its\nown but only by looking at the set of all possible traces as a whole. \nAs teams correspond to sets of assignments, it is natural to consider\nthe possibility of extensions of team semantics in which satisfaction\nis defined instead with respect to multiteams (i.e.,\nmultisets of assignments) or probability distributions over\nassignments. \nThe first possibility has been studied in (Durand et al. 2018a), while\nthe second has been studied in (Durand et al. 2018b). The second work,\nin particular, has led to interesting connections to problems of\ndescriptive complexity over the reals and metafinite model theory\n(Hannula et al. 2019, Hannula et al. 2020).  \nThere is a straightforward connection between the teams of team\nsemantics and the relations studied in relational database theory:\ngiven a team \\(X\\) and a tuple of variables \\(\\vec v = v_1 \\ldots\nv_k\\) occurring in its assignments, it is possible to define the\nrelation \\(X(\\vec v) = \\{\\langle s(v_1), \\ldots, s(v_n)\\rangle : s \\in\nX\\}\\). Furthermore, the dependency atoms studied in dependence logic\nand its variants are analogous to – and in many cases, derived\nfrom – dependencies considered in database theory such as\nfunctional dependencies (Väänänen 2007a),\nmultivalued dependencies (Engström 2012), and\ninclusion and exclusion dependencies (Galliani 2012). The\nrelationship between dependence logic and database theory contributed\nnot only to the further development of dependence logic, but also to\nthat of database theory: for instance, in Hannula & Kontinen 2016\na finite axiomatization of the unrestricted implication problem for\ninclusion, functional, and embedded multivalued database-theoretic\ndependencies was found through the study of a similar problem within\nthe context of team semantics. \nAs discussed in (Yang 2014) and (Yang & Väänänen 2016),\nthere exists a close connection between (propositional) intuitionistic\ndependence logic and inquisitive logic (Ciardelli &\nRoelofsen, 2011), a framework for the study of meaning and information\nexchange between agents. More in general, the dependency atoms and\nconnectives of studied in team semantics admit natural interpretations\nin terms of belief states and belief updates, as\ndiscussed in (Galliani 2015). At this time, the exact nature of the\nrelationship between such logics and dynamic-epistemic logic and its\nvariants (Van Ditmarsch, van Der Hoek, & Kooi 2007) is largely\nunexplored, but there is ample reason to suspect further connections\nbetween these two areas of mathematical and philosophical logic. \nArrow’s theorem (Arrow 1950) is a profoundly influential result\nof social choice theory that, in brief, shows that no voting system\n(that is, no system for converting rankings of individual preferences\nbetween alternatives into a global, societal-level preference ranking)\nexists that can satisfy three reasonable-sounding conditions,\nnamely \nIf every voter prefers \\(A\\) to \\(B\\), the group as a whole prefers\n\\(A\\) and \\(B\\); \nWhether the group as a whole prefers \\(A\\) to \\(B\\) or vice versa\ndepends exclusively on every voter’s preferences concerning\n\\(A\\) and \\(B\\), and not on their preferences concerning\nother possible alternatives; \nNo single voter is a dictator, that is, the group’s\npreferences are not determined by the preferences of any single\nvoter. \nAs the wording itself suggests, the second and third conditions admit\na natural reading in terms of dependence and independence: in fact, as\nshown in Pacuit & Yang 2016, Arrow’s theorem can be\nformalized in independence logic and proved in a suitable natural\ndeduction system. \nIn (Hyttinen, Paolini, & Väänänen 2015) a variant of\npropositional team logic, called quantum team logic, is\nintroduced. In this formalism, teams are replaced by quantum\nteams, which differ from the ordinary teams of propositional team\nlogic in that they allow for the values of certain variables to be\nindeterminate with respect to certain valuations and in that\nthey allow for multiple instances of the same valuation (thus adding a\nquantitative aspect to team semantics). A semantics is then defined\nover quantum teams for a language that allows for the specification of\ninequalities concerning the probabilities of events, and a\nsound and complete proof system is developed for it; and finally, it\nis shown that Bell’s inequalities admit counterexamples\nin this systems, as they do according to the predictions of quantum\nmechanics and according to experimental evidence (Einstein, Podolsky,\n& Rosen 1935; Bell 1964; Aspect, Grangier, & Roger 1981),\nwhile they do not so in the classical version of this\nframework.","contact.mail":"pgallian@gmail.com","contact.domain":"gmail.com"}]
