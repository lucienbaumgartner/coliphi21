[{"date.published":"2003-09-15","date.changed":"2018-08-27","url":"https://plato.stanford.edu/entries/reasoning-moral/","author1":"Henry S. Richardson","author1.info":"http://explore.georgetown.edu/people/richardh/?action=viewgeneral","entry":"reasoning-moral","body.text":"\n\n\nWhile moral reasoning can be undertaken on another’s behalf, it\nis paradigmatically an agent’s first-personal (individual or\ncollective) practical reasoning about what, morally, they ought to do.\nPhilosophical examination of moral reasoning faces both distinctive\npuzzles – about how we recognize moral considerations and cope\nwith conflicts among them and about how they move us to act –\nand distinctive opportunities for gleaning insight about what we ought\nto do from how we reason about what we ought to do. \n\n\nPart I of this article characterizes moral reasoning more fully,\nsituates it in relation both to first-order accounts of what morality\nrequires of us and to philosophical accounts of the metaphysics of\nmorality, and explains the interest of the topic. Part II then takes\nup a series of philosophical questions about moral reasoning, so\nunderstood and so situated. \n\nThis article takes up moral reasoning as a species of practical\nreasoning – that is, as a type of reasoning directed towards\ndeciding what to do and, when successful, issuing in an intention (see\nentry on\n practical reason).\n Of course, we also reason theoretically about what morality requires\nof us; but the nature of purely theoretical reasoning about ethics is\nadequately addressed in the various articles on\n ethics.\n It is also true that, on some understandings, moral reasoning\ndirected towards deciding what to do involves forming judgments about\nwhat one ought, morally, to do. On these understandings, asking what\none ought (morally) to do can be a practical question, a certain way\nof asking about what to do. (See\n section 1.5\n on the question of whether this is a distinctive practical question.)\nIn order to do justice to the full range of philosophical views about\nmoral reasoning, we will need to have a capacious understanding of\nwhat counts as a moral question. For instance, since a prominent\nposition about moral reasoning is that the relevant considerations are\nnot codifiable, we would beg a central question if we here defined\n “morality”\n as involving codifiable principles or rules. For present purposes, we\nmay understand issues about what is right or wrong, or virtuous or\nvicious, as raising moral questions.  \nEven when moral questions explicitly arise in daily life, just as when\nwe are faced with child-rearing, agricultural, and business questions,\nsometimes we act impulsively or instinctively rather than pausing to\nreason, not just about what to do, but about what we ought to do.\nJean-Paul Sartre described a case of one of his students who came to\nhim in occupied Paris during World War II, asking advice about whether\nto stay by his mother, who otherwise would have been left alone, or\nrather to go join the forces of the Free French, then massing in\nEngland (Sartre 1975). In the capacious sense just described, this is\nprobably a moral question; and the young man paused long enough to ask\nSartre’s advice. Does that mean that this young man was\nreasoning about his practical question? Not necessarily. Indeed,\nSartre used the case to expound his skepticism about the possibility\nof addressing such a practical question by reasoning. But what is\nreasoning? \nReasoning, of the sort discussed here, is active or explicit thinking,\nin which the reasoner, responsibly guided by her assessments of her\nreasons (Kolodny 2005) and of any applicable requirements of\nrationality (Broome 2009, 2013), attempts to reach a well-supported\nanswer to a well-defined question (Hieronymi 2013). For Sartre’s\nstudent, at least such a question had arisen. Indeed, the question was\nrelatively definite, implying that the student had already engaged in\nsome reflection about the various alternatives available to him\n– a process that has well been described as an important phase\nof practical reasoning, one that aptly precedes the effort to make up\none’s mind (Harman 1986, 2). \nCharacterizing reasoning as responsibly conducted thinking of course\ndoes not suffice to analyze the notion. For one thing, it fails to\naddress the fraught question of reasoning’s relation to\ninference (Harman 1986, Broome 2009). In addition, it does not settle\nwhether formulating an intention about what to do suffices to conclude\npractical reasoning or whether such intentions cannot be adequately\nworked out except by starting to act. Perhaps one cannot adequately\nreason about how to repair a stone wall or how to make an omelet with\nthe available ingredients without actually starting to repair or to\ncook (cf. Fernandez 2016). Still, it will do for present purposes. It\nsuffices to make clear that the idea of reasoning involves norms of\nthinking. These norms of aptness or correctness in practical thinking\nsurely do not require us to think along a single prescribed pathway,\nbut rather permit only certain pathways and not others (Broome 2013,\n219). Even so, we doubtless often fail to live up to them.  \nOur thinking, including our moral thinking, is often not explicit. We\ncould say that we also reason tacitly, thinking in much the same way\nas during explicit reasoning, but without any explicit attempt to\nreach well-supported answers. In some situations, even moral ones, we\nmight be ill-advised to attempt to answer our practical questions by\nexplicit reasoning. In others, it might even be a mistake to reason\ntacitly – because, say, we face a pressing emergency. “Sometimes\nwe should not deliberate about what to do, and just drive” (Arpaly and\nSchroeder 2014, 50). Yet even if we are not called upon to think\nthrough our options in all situations, and even if sometimes it would\nbe positively better if we did not, still, if we are called upon to do\nso, then we should conduct our thinking responsibly: we should\nreason. \nRecent work in empirical ethics has indicated that even when we are\ncalled upon to reason morally, we often do so badly. When asked to\ngive reasons for our moral intuitions, we are often\n“dumbfounded,” finding nothing to say in their defense\n(Haidt 2001). Our thinking about hypothetical moral scenarios has been\nshown to be highly sensitive to arbitrary variations, such as in the\norder of presentation. Even professional philosophers have been found\nto be prone to such lapses of clear thinking (e.g., Schwitzgebel &\nCushman 2012). Some of our dumbfounding and confusion has been laid at\nthe feet of our having both a fast, more emotional way of processing\nmoral stimuli and a slow, more cognitive way (e.g., Greene 2014). An\nalternative explanation of moral dumbfounding looks to social norms of\nmoral reasoning (Sneddon 2007). And a more optimistic reaction to our\nconfusion sees our established patterns of “moral consistency\nreasoning” as being well-suited to cope with the clashing input\ngenerated by our fast and slow systems (Campbell & Kumar 2012) or\nas constituting “a flexible learning system that generates and updates\na multidimensional evaluative landscape to guide decision and action”\n(Railton, 2014, 813).  \nEventually, such empirical work on our moral reasoning may yield\nrevisions in our norms of moral reasoning. This has not yet happened.\nThis article is principally concerned with philosophical issues posed\nby our current norms of moral reasoning. For example, given those\nnorms and assuming that they are more or less followed, how do moral\nconsiderations enter into moral reasoning, get sorted out by it when\nthey clash, and lead to action? And what do those norms indicate about\nwhat we ought to do do? \nThe topic of moral reasoning lies in between two other commonly\naddressed topics in moral philosophy. On the one side, there is the\nfirst-order question of what moral truths there are, if any. For\ninstance, are there any true general principles of morality, and if\nso, what are they? At this level utilitarianism competes with\nKantianism, for instance, and both compete with anti-theorists of\nvarious stripes, who recognize only particular truths about morality\n(Clarke & Simpson 1989). On the other side, a quite different sort\nof question arises from seeking to give a metaphysical grounding for\nmoral truths or for the claim that there are none. Supposing there are\nsome moral truths, what makes them true? What account can be\ngiven of the truth-conditions of moral statements? Here arise familiar\nquestions of\n moral skepticism\n and\n moral relativism;\n here, the idea of “a reason” is wielded by many hoping to\ndefend a non-skeptical moral metaphysics (e.g., Smith 2013). The topic\nof moral reasoning lies in between these two other familiar topics in\nthe following simple sense: moral reasoners operate with what they\ntake to be morally true but, instead of asking what makes\ntheir moral beliefs true, they proceed responsibly to attempt to\nfigure out what to do in light of those considerations. The\nphilosophical study of moral reasoning concerns itself with the nature\nof these attempts.  \nThese three topics clearly interrelate. Conceivably, the relations\nbetween them would be so tight as to rule out any independent interest\nin the topic of moral reasoning. For instance, if all that could\nusefully be said about moral reasoning were that it is a matter of\nattending to the moral facts, then all interest would devolve upon the\nquestion of what those facts are – with some residual focus on\nthe idea of moral attention (McNaughton 1988). Alternatively, it might\nbe thought that moral reasoning is simply a matter of applying the\ncorrect moral theory via ordinary modes of deductive and empirical\nreasoning. Again, if that were true, one’s sufficient goal would\nbe to find that theory and get the non-moral facts right. Neither of\nthese reductive extremes seems plausible, however. Take the potential\nreduction to getting the facts right, first.  \nContemporary advocates of the importance of correctly perceiving the\nmorally relevant facts tend to focus on facts that we can perceive\nusing our ordinary sense faculties and our ordinary capacities of\nrecognition, such as that this person has an infection or\nthat this person needs my medical help. On such a footing, it\nis possible to launch powerful arguments against the claim that moral\nprinciples undergird every moral truth (Dancy 1993) and for the claim\nthat we can sometimes perfectly well decide what to do by acting on\nthe reasons we perceive instinctively – or as we have been\ntrained – without engaging in any moral reasoning. Yet this is\nnot a sound footing for arguing that moral reasoning, beyond\nsimply attending to the moral facts, is always unnecessary. On the\ncontrary, we often find ourselves facing novel perplexities and moral\nconflicts in which our moral perception is an inadequate guide. In\naddressing the moral questions surrounding whether society ought to\nenforce surrogate-motherhood contracts, for instance, the scientific\nand technological novelties involved make our moral perceptions\nunreliable and shaky guides. When a medical researcher who has noted\nan individual’s illness also notes the fact that diverting\nresources to caring, clinically, for this individual would inhibit the\nprogress of my research, thus harming the long-term health chances of\nfuture sufferers of this illness, he or she comes face to face\nwith conflicting moral considerations. At this juncture, it is far\nless plausible or satisfying simply to say that, employing one’s\nordinary sensory and recognitional capacities, one sees what is to be\ndone, both things considered. To posit a special faculty of moral\nintuition that generates such overall judgments in the face of\nconflicting considerations is to wheel in a deus ex machina.\nIt cuts inquiry short in a way that serves the purposes of fiction\nbetter than it serves the purposes of understanding. It is plausible\ninstead to suppose that moral reasoning comes in at this point\n(Campbell & Kumar 2012).  \nFor present purposes, it is worth noting, David Hume and the moral\nsense theorists do not count as short-circuiting our understanding of\nmoral reasoning in this way. It is true that Hume presents himself,\nespecially in the Treatise of Human Nature, as a disbeliever\nin any specifically practical or moral reasoning. In doing so,\nhowever, he employs an exceedingly narrow definition of\n“reasoning” (Hume 2000, Book I, Part iii, sect. ii). For\npresent purposes, by contrast, we are using a broader working gloss of\n“reasoning,” one not controlled by an ambition to parse\nout the relative contributions of (the faculty of) reason and of the\npassions. And about moral reasoning in this broader sense, as\nresponsible thinking about what one ought to do, Hume has many\ninteresting things to say, starting with the thought that\nmoral reasoning must involve a double correction of\nperspective (see\n section 2.4)\n adequately to account for the claims of other people and of the\nfarther future, a double correction that is accomplished with the aid\nof the so-called “calm passions.” \nIf we turn from the possibility that perceiving the facts aright will\ndisplace moral reasoning to the possibility that applying the correct\nmoral theory will displace – or exhaust – moral reasoning,\nthere are again reasons to be skeptical. One reason is that moral\ntheories do not arise in a vacuum; instead, they develop against a\nbroad backdrop of moral convictions. Insofar as the first potentially\nreductive strand, emphasizing the importance of perceiving moral\nfacts, has force – and it does have some – it also tends\nto show that moral theories need to gain support by systematizing or\naccounting for a wide range of moral facts (Sidgwick 1981). As in most\nother arenas in which theoretical explanation is called for, the\ndegree of explanatory success will remain partial and open to\nimprovement via revisions in the theory (see\n section 2.6).\n Unlike the natural sciences, however, moral theory is an endeavor\nthat, as John Rawls once put it, is “Socratic” in that it\nis a subject pertaining to actions “shaped by\nself-examination” (Rawls 1971, 48f.). If this observation is\ncorrect, it suggests that the moral questions we set out to answer\narise from our reflections about what matters. By the same token\n– and this is the present point – a moral theory is\nsubject to being overturned because it generates concrete implications\nthat do not sit well with us on due reflection. This being so, and\ngranting the great complexity of the moral terrain, it seems highly\nunlikely that we will ever generate a moral theory on the basis of\nwhich we can serenely and confidently proceed in a deductive way to\ngenerate answers to what we ought to do in all concrete cases. This\nconclusion is reinforced by a second consideration, namely that\ninsofar as a moral theory is faithful to the complexity of the moral\nphenomena, it will contain within it many possibilities for conflicts\namong its own elements. Even if it does deploy some priority rules,\nthese are unlikely to be able to cover all contingencies. Hence, some\nmoral reasoning that goes beyond the deductive application of the\ncorrect theory is bound to be needed.  \nIn short, a sound understanding of moral reasoning will not take the\nform of reducing it to one of the other two levels of moral philosophy\nidentified above. Neither the demand to attend to the moral facts nor\nthe directive to apply the correct moral theory exhausts or\nsufficiently describes moral reasoning.  \nIn addition to posing philosophical problems in its own right, moral\nreasoning is of interest on account of its implications for moral\nfacts and moral theories. Accordingly, attending to moral reasoning\nwill often be useful to those whose real interest is in determining\nthe right answer to some concrete moral problem or in arguing for or\nagainst some moral theory. The characteristic ways we attempt to work\nthrough a given sort of moral quandary can be just as revealing about\nour considered approaches to these matters as are any bottom-line\njudgments we may characteristically come to. Further, we may have\nfirm, reflective convictions about how a given class of problems is\nbest tackled, deliberatively, even when we remain in doubt about what\nshould be done. In such cases, attending to the modes of moral\nreasoning that we characteristically accept can usefully expand the\nset of moral information from which we start, suggesting ways to\nstructure the competing considerations.  \nFacts about the nature of moral inference and moral reasoning may have\nimportant direct implications for moral theory. For instance, it might\nbe taken to be a condition of adequacy of any moral theory that it\nplay a practically useful role in our efforts at self-understanding\nand deliberation. It should be deliberation-guiding (Richardson 2018,\n§1.2). If this condition is accepted, then any moral theory that\nwould require agents to engage in abstruse or difficult reasoning may\nbe inadequate for that reason, as would be any theory that assumes\nthat ordinary individuals are generally unable to reason in the ways\nthat the theory calls for. J.S. Mill (1979) conceded that we are\ngenerally unable to do the calculations called for by utilitarianism,\nas he understood it, and argued that we should be consoled by the fact\nthat, over the course of history, experience has generated secondary\nprinciples that guide us well enough. Rather more dramatically, R. M.\nHare defended utilitarianism as well capturing the reasoning of\nideally informed and rational “archangels” (1981). Taking seriously a\ndeliberation-guidance desideratum for moral theory would favor,\ninstead, theories that more directly inform efforts at moral reasoning\nby we “proletarians,” to use Hare’s contrasting term.  \nAccordingly, the close relations between moral reasoning, the moral\nfacts, and moral theory do not eliminate moral reasoning as a topic of\ninterest. To the contrary, because moral reasoning has important\nimplications about moral facts and moral theories, these close\nrelations lend additional interest to the topic of moral reasoning.\n \nThe final threshold question is whether moral reasoning is truly\ndistinct from practical reasoning more generally understood. (The\nquestion of whether moral reasoning, even if practical, is\nstructurally distinct from theoretical reasoning that simply proceeds\nfrom a proper recognition of the moral facts has already been\nimplicitly addressed and answered, for the purposes of the present\ndiscussion, in the affirmative.) In addressing this final question, it\nis difficult to overlook the way different moral theories project\nquite different models of moral reasoning – again a link that\nmight be pursued by the moral philosopher seeking leverage in either\ndirection. For instance, Aristotle’s views might be as follows:\na quite general account can be given of practical reasoning, which\nincludes selecting means to ends and determining the constituents of a\ndesired activity. The difference between the reasoning of a vicious\nperson and that of a virtuous person differs not at all in its\nstructure, but only in its content, for the virtuous person pursues\ntrue goods, whereas the vicious person simply gets side-tracked by\napparent ones. To be sure, the virtuous person may be able to achieve\na greater integration of his or her ends via practical reasoning\n(because of the way the various virtues cohere), but this is a\ndifference in the result of practical reasoning and not in its\nstructure. At an opposite extreme, Kant’s categorical imperative\nhas been taken to generate an approach to practical reasoning (via a\n“typic of practical judgment”) that is distinctive from\nother practical reasoning both in the range of considerations it\naddresses and its structure (Nell 1975). Whereas prudential practical\nreasoning, on Kant’s view, aims to maximize one’s\nhappiness, moral reasoning addresses the potential universalizability\nof the maxims – roughly, the intentions – on which one\nacts. Views intermediate between Aristotle’s and Kant’s in\nthis respect include Hare’s utilitarian view and Aquinas’\nnatural-law view. On Hare’s view, just as an ideal prudential\nagent applies maximizing rationality to his or her own preferences, an\nideal moral agent’s reasoning applies maximizing rationality to\nthe set of everyone’s preferences that its archangelic capacity\nfor sympathy has enabled it to internalize (Hare 1981). Thomistic,\nnatural-law views share the Aristotelian view about the general unity\nof practical reasoning in pursuit of the good, rightly or wrongly\nconceived, but add that practical reason, in addition to demanding\nthat we pursue the fundamental human goods, also, and distinctly,\ndemands that we not attack these goods. In this way, natural-law views\nincorporate some distinctively moral structuring – such as the\ndistinctions between doing and allowing and the so-called\n doctrine of double effect’s\n distinction between intending as a means and accepting as a\nby-product – within a unified account of practical reasoning\n(see entry on the\n natural law tradition in ethics).\n In light of this diversity of views about the relation between moral\nreasoning and practical or prudential reasoning, a general account of\nmoral reasoning that does not want to presume the correctness of a\ndefinite moral theory will do well to remain agnostic on the question\nof how moral reasoning relates to non-moral practical reasoning.  \nTo be sure, most great philosophers who have addressed the nature of\nmoral reasoning were far from agnostic about the content of the\ncorrect moral theory, and developed their reflections about moral\nreasoning in support of or in derivation from their moral theory.\nNonetheless, contemporary discussions that are somewhat agnostic about\nthe content of moral theory have arisen around important and\ncontroversial aspects of moral reasoning. We may group these around\nthe following seven questions:  \nThe remainder of this article takes up these seven questions in turn.\n \nOne advantage to defining “reasoning” capaciously, as\nhere, is that it helps one recognize that the processes whereby we\ncome to be concretely aware of moral issues are integral to moral\nreasoning as it might more narrowly be understood. Recognizing moral\nissues when they arise requires a highly trained set of capacities and\na broad range of emotional attunements. Philosophers of the moral\nsense school of the 17th and 18th centuries stressed innate emotional\npropensities, such as sympathy with other humans. Classically\ninfluenced virtue theorists, by contrast, give more importance to the\ntraining of perception and the emotional growth that must accompany\nit. Among contemporary philosophers working in empirical ethics there\nis a similar divide, with some arguing that we process situations\nusing an innate moral grammar (Mikhail 2011) and some emphasizing the\nrole of emotions in that processing (Haidt 2001, Prinz 2007, Greene\n2014). For the moral reasoner, a crucial task for our capacities of\nmoral recognition is to mark out certain features of a situation as\nbeing morally salient. Sartre’s student, for instance, focused\non the competing claims of his mother and the Free French, giving them\neach an importance to his situation that he did not give to eating\nFrench cheese or wearing a uniform. To say that certain features are\nmarked out as morally salient is not to imply that the features thus\nsingled out answer to the terms of some general principle or other: we\nwill come to the question of particularism, below. Rather, it is\nsimply to say that recognitional attention must have a selective\nfocus.  \nWhat will be counted as a moral issue or difficulty, in the sense\nrequiring moral agents’ recognition, will again vary by moral\ntheory. Not all moral theories would count filial loyalty and\npatriotism as moral duties. It is only at great cost, however, that\nany moral theory could claim to do without a layer of moral thinking\ninvolving situation-recognition. A calculative sort of utilitarianism,\nperhaps, might be imagined according to which there is no need to spot\na moral issue or difficulty, as every choice node in life\npresents the agent with the same, utility-maximizing task. Perhaps\nJeremy Bentham held a utilitarianism of this sort. For the more\nplausible utilitarianisms mentioned above, however, such as\nMill’s and Hare’s, agents need not always calculate\nafresh, but must instead be alive to the possibility that because the\nordinary “landmarks and direction posts” lead one astray\nin the situation at hand, they must make recourse to a more direct and\ncritical mode of moral reasoning. Recognizing whether one is in one of\nthose situations thus becomes the principal recognitional task for the\nutilitarian agent. (Whether this task can be suitably confined, of\ncourse, has long been one of the crucial questions about whether such\nindirect forms of utilitarianism, attractive on other grounds, can\nprevent themselves from collapsing into a more Benthamite, direct\nform: cf. Brandt 1979.)  \nNote that, as we have been describing moral uptake, we have not\nimplied that what is perceived is ever a moral fact. Rather, it might\nbe that what is perceived is some ordinary, descriptive feature of a\nsituation that is, for whatever reason, morally relevant. An account\nof moral uptake will interestingly impinge upon the metaphysics of\nmoral facts, however, if it holds that moral facts can be perceived.\nImportantly intermediate, in this respect, is the set of judgments\ninvolving so-called “thick” evaluative concepts –\nfor example, that someone is callous, boorish, just, or brave (see the\nentry on\n thick ethical concepts).\n These do not invoke the supposedly “thinner” terms of\noverall moral assessment, “good,” or “right.”\nYet they are not innocent of normative content, either. Plainly, we do\nrecognize callousness when we see clear cases of it. Plainly, too\n– whatever the metaphysical implications of the last fact\n– our ability to describe our situations in these thick\nnormative terms is crucial to our ability to reason morally.  \nIt is debated how closely our abilities of moral discernment are tied\nto our moral motivations. For Aristotle and many of his ancient\nsuccessors, the two are closely linked, in that someone not brought up\ninto virtuous motivations will not see things correctly. For instance,\ncowards will overestimate dangers, the rash will underestimate them,\nand the virtuous will perceive them correctly (Eudemian\nEthics 1229b23–27). By the Stoics, too, having the right\nmotivations was regarded as intimately tied to perceiving the world\ncorrectly; but whereas Aristotle saw the emotions as allies to enlist\nin support of sound moral discernment, the Stoics saw them as inimical\nto clear perception of the truth (cf. Nussbaum 2001).  \nThat one discerns features and qualities of some situation that are\nrelevant to sizing it up morally does not yet imply that one\nexplicitly or even implicitly employs any general claims in describing\nit. Perhaps all that one perceives are particularly embedded features\nand qualities, without saliently perceiving them as\ninstantiations of any types. Sartre’s student may be focused on\nhis mother and on the particular plights of several of his fellow\nFrenchmen under Nazi occupation, rather than on any purported\nrequirements of filial duty or patriotism. Having become aware of some\nmoral issue in such relatively particular terms, he might proceed\ndirectly to sorting out the conflict between them. Another\npossibility, however, and one that we frequently seem to exploit, is\nto formulate the issue in general terms: “An only child should\nstick by an otherwise isolated parent,” for instance, or\n“one should help those in dire need if one can do so without\nsignificant personal sacrifice.” Such general statements would\nbe examples of “moral principles,” in a broad sense. (We\ndo not here distinguish between principles and rules. Those who do\ninclude Dworkin 1978 and Gert 1998.)  \nWe must be careful, here, to distinguish the issue of whether\nprinciples commonly play an implicit or explicit role in moral\nreasoning, including well-conducted moral reasoning, from the issue of\nwhether principles necessarily figure as part of the basis of moral\ntruth. The latter issue is best understood as a metaphysical question\nabout the nature and basis of moral facts. What is currently known as\n moral particularism\n is the view that there are no defensible moral principles and that\nmoral reasons, or well-grounded moral facts, can exist independently\nof any basis in a general principle. A contrary view holds that moral\nreasons are necessarily general, whether because the sources of their\njustification are all general or because a moral claim is ill-formed\nif it contains particularities. But whether principles play a useful\nrole in moral reasoning is certainly a different question from whether\nprinciples play a necessary role in accounting for the ultimate\ntruth-conditions of moral statements. Moral particularism, as just\ndefined, denies their latter role. Some moral particularists seem also\nto believe that moral particularism implies that moral\nprinciples cannot soundly play a useful role in reasoning. This claim\nis disputable, as it seems a contingent matter whether the relevant\nparticular facts arrange themselves in ways susceptible to general\nsummary and whether our cognitive apparatus can cope with them at all\nwithout employing general principles. Although the metaphysical\ncontroversy about moral particularism lies largely outside our topic,\nwe will revisit it in\n section 2.5,\n in connection with the weighing of conflicting reasons.  \nWith regard to moral reasoning, while there are some self-styled\n“anti-theorists” who deny that abstract structures of\nlinked generalities are important to moral reasoning (Clarke, et al.\n1989), it is more common to find philosophers who recognize both some\nrole for particular judgment and some role for moral principles. Thus,\nneo-Aristotelians like Nussbaum who emphasize the importance of\n“finely tuned and richly aware” particular discernment\nalso regard that discernment as being guided by a set of generally\ndescribable virtues whose general descriptions will come into play in\nat least some kinds of cases (Nussbaum 1990). “Situation\nethicists” of an earlier generation (e.g. Fletcher 1997)\nemphasized the importance of taking into account a wide range of\ncircumstantial differentiae, but against the background of some\ngeneral principles whose application the differentiae help sort out.\nFeminist ethicists influenced by Carol Gilligan’s path breaking\nwork on moral development have stressed the moral centrality of the\nkind of care and discernment that are salient and well-developed by\npeople immersed in particular relationships (Held 1995); but this\nemphasis is consistent with such general principles as “one\nought to be sensitive to the wishes of one’s friends”(see\nthe entry on\n feminist moral psychology).\n Again, if we distinguish the question of whether principles are\nuseful in responsibly-conducted moral thinking from the question of\nwhether moral reasons ultimately all derive from general principles,\nand concentrate our attention solely on the former, we will see that\nsome of the opposition to general moral principles melts away.  \nIt should be noted that we have been using a weak notion of\ngenerality, here. It is contrasted only with the kind of strict\nparticularity that comes with indexicals and proper names. General\nstatements or claims – ones that contain no such particular\nreferences – are not necessarily universal generalizations,\nmaking an assertion about all cases of the mentioned type.\nThus, “one should normally help those in dire need” is a\ngeneral principle, in this weak sense. Possibly, such logically loose\nprinciples would be obfuscatory in the context of an attempt to\nreconstruct the ultimate truth-conditions of moral statements. Such\nlogically loose principles would clearly be useless in any attempt to\ngenerate a deductively tight “practical syllogism.” In our\nday-to-day, non-deductive reasoning, however, such logically loose\nprinciples appear to be quite useful. (Recall that we are\nunderstanding “reasoning” quite broadly, as responsibly\nconducted thinking: nothing in this understanding of reasoning\nsuggests any uniquely privileged place for deductive inference: cf.\nHarman 1986. For more on defeasible or “default”\nprinciples, see\n section 2.5.)\n  \nIn this terminology, establishing that general principles are\nessential to moral reasoning leaves open the further question whether\nlogically tight, or exceptionless, principles are also essential to\nmoral reasoning. Certainly, much of our actual moral reasoning seems\nto be driven by attempts to recast or reinterpret principles so that\nthey can be taken to be exceptionless. Adherents and\ninheritors of the natural-law tradition in ethics (e.g. Donagan 1977)\nare particularly supple defenders of exceptionless moral principles,\nas they are able to avail themselves not only of a refined tradition\nof casuistry but also of a wide array of subtle – some would say\noverly subtle – distinctions, such as those mentioned above\nbetween doing and allowing and between intending as a means and\naccepting as a byproduct.  \nA related role for a strong form of generality in moral reasoning\ncomes from the Kantian thought that one’s moral reasoning must\ncounter one’s tendency to make exceptions for oneself.\nAccordingly, Kant holds, as we have noted, that we must ask whether\nthe maxims of our actions can serve as universal laws. As most\ncontemporary readers understand this demand, it requires that we\nengage in a kind of hypothetical generalization across agents, and ask\nabout the implications of everybody acting that way in those\ncircumstances. The grounds for developing Kant’s thought in this\ndirection have been well explored (e.g., Nell 1975, Korsgaard 1996,\nEngstrom 2009). The importance and the difficulties of such a\nhypothetical generalization test in ethics were discussed the\ninfluential works Gibbard 1965 and Goldman 1974.  \nWhether or not moral considerations need the backing of general\nprinciples, we must expect situations of action to present us with\nmultiple moral considerations. In addition, of course, these\nsituations will also present us with a lot of information that is not\nmorally relevant. On any realistic account, a central task of moral\nreasoning is to sort out relevant considerations from irrelevant ones,\nas well as to determine which are especially relevant and which only\nslightly so. That a certain woman is Sartre’s student’s\nmother seems arguably to be a morally relevant fact; what\nabout the fact (supposing it is one) that she has no other children to\ntake care of her? Addressing the task of sorting what is morally\nrelevant from what is not, some philosophers have offered general\naccounts of moral relevant features. Others have given accounts of how\nwe sort out which of the relevant features are most relevant,\na process of thinking that sometimes goes by the name of\n“casuistry.” \nBefore we look at ways of sorting out which features are morally\nrelevant or most morally relevant, it may be useful to note a\nprior step taken by some casuists, which was to attempt to set out a\nschema that would capture all of the features of an action or\nproposed action. The Roman Catholic casuists of the middle ages did so\nby drawing on Aristotle’s categories. Accordingly, they asked,\nwhere, when, why, how, by what means, to whom, or by whom the action\nin question is to be done or avoided (see Jonsen and Toulmin 1988).\nThe idea was that complete answers to these questions would contain\nall of the features of the action, of which the morally relevant ones\nwould be a subset. Although metaphysically uninteresting, the idea of\nattempting to list all of an action’s features in this way\nrepresents a distinctive – and extreme – heuristic for\nmoral reasoning.  \nTurning to the morally relevant features, one of the most developed\naccounts is Bernard Gert’s. He develops a list of features\nrelevant to whether the violation of a moral rule should be generally\nallowed. Given the designed function of Gert’s list, it is\nnatural that most of his morally relevant features make reference to\nthe set of moral rules he defended. Accordingly, some of Gert’s\ndistinctions between dimensions of relevant features reflect\ncontroversial stances in moral theory. For example, one of the\ndimensions is whether “the violation [is] done intentionally or\nonly knowingly” (Gert 1998, 234) – a distinction that\nthose who reject the doctrine of double effect would not find\nrelevant.  \nIn deliberating about what we ought, morally, to do, we also often\nattempt to figure out which considerations are most relevant.\nTo take an issue mentioned above: Are surrogate motherhood contracts\nmore akin to agreements with babysitters (clearly acceptable) or to\nagreements with prostitutes (not clearly so)? That is, which feature\nof surrogate motherhood is more relevant: that it involves a contract\nfor child-care services or that it involves payment for the intimate\nuse of the body? Both in such relatively novel cases and in more\nfamiliar ones, reasoning by analogy plays a large role in ordinary\nmoral thinking. When this reasoning by analogy starts to become\nsystematic – a social achievement that requires some historical\nstability and reflectiveness about what are taken to be moral norms\n– it begins to exploit comparison to cases that are\n“paradigmatic,” in the sense of being taken as settled.\nWithin such a stable background, a system of casuistry can develop\nthat lends some order to the appeal to analogous cases. To use an\nanalogy: the availability of a widely accepted and systematic set of\nanalogies and the availability of what are taken to be moral norms may\nstand to one another as chicken does to egg: each may be an\nindispensable moment in the genesis of the other.  \nCasuistry, thus understood, is an indispensable aid to moral\nreasoning. At least, that it is would follow from conjoining two\nfeatures of the human moral situation mentioned above: the\nmultifariousness of moral considerations that arise in particular\ncases and the need and possibility for employing moral principles in\nsound moral reasoning. We require moral judgment, not simply a\ndeductive application of principles or a particularist bottom-line\nintuition about what we should do. This judgment must be responsible\nto moral principles yet cannot be straightforwardly derived from them.\nAccordingly, our moral judgment is greatly aided if it is able to rest\non the sort of heuristic support that casuistry offers. Thinking\nthrough which of two analogous cases provides a better key to\nunderstanding the case at hand is a useful way of organizing our moral\nreasoning, and one on which we must continue to depend. If we lack the\nkind of broad consensus on a set of paradigm cases on which the\nRenaissance Catholic or Talmudic casuists could draw, our casuistic\nefforts will necessarily be more controversial and tentative than\ntheirs; but we are not wholly without settled cases from which to\nwork. Indeed, as Jonsen and Toulmin suggest at the outset of their\nthorough explanation and defense of casuistry, the depth of\ndisagreement about moral theories that characterizes a pluralist\nsociety may leave us having to rest comparatively more weight\non the cases about which we can find agreement than did the classic\ncasuists (Jonsen and Toulmin 1988).  \nDespite the long history of casuistry, there is little that can\nusefully be said about how one ought to reason about competing\nanalogies. In the law, where previous cases have precedential\nimportance, more can be said. As Sunstein notes (Sunstein 1996, chap.\n3), the law deals with particular cases, which are always\n“potentially distinguishable” (72); yet the law also\nimposes “a requirement of practical consistency” (67).\nThis combination of features makes reasoning by analogy particularly\ninfluential in the law, for one must decide whether a given case is\nmore like one set of precedents or more like another. Since the law\nmust proceed even within a pluralist society such as ours, Sunstein\nargues, we see that analogical reasoning can go forward on the basis\nof “incompletely theorized judgments” or of what Rawls\ncalls an “overlapping consensus” (Rawls 1996). That is,\nalthough a robust use of analogous cases depends, as we have noted, on\nsome shared background agreement, this agreement need not extend to\nall matters or all levels of individuals’ moral thinking.\nAccordingly, although in a pluralist society we may lack the kind of\ncomprehensive normative agreement that made the high casuistry of\nRenaissance Christianity possible, the path of the law suggests that\nnormatively forceful, case-based, analogical reasoning can still go\non. A modern, competing approach to case-based or precedent-respecting\nreasoning has been developed by John F. Horty (2016). On Horty’s\napproach, which builds on the default logic developed in (Horty 2012),\nthe body of precedent systematically shifts the weights of the reasons\narising in a new case. \nReasoning by appeal to cases is also a favorite mode of some recent\nmoral philosophers. Since our focus here is not on the methods of\nmoral theory, we do not need to go into any detail in comparing\ndifferent ways in which philosophers wield cases for and against\nalternative moral theories. There is, however, an important and\nbroadly applicable point worth making about ordinary reasoning by\nreference to cases that emerges most clearly from the philosophical\nuse of such reasoning. Philosophers often feel free to imagine cases,\noften quite unlikely ones, in order to attempt to isolate relevant\ndifferences. An infamous example is a pair of cases offered by James\nRachels to cast doubt on the moral significance of the distinction\nbetween killing and letting die, here slightly redescribed. In both\ncases, there is at the outset a boy in a bathtub and a greedy older\ncousin downstairs who will inherit the family manse if and only if the\nboy predeceases him (Rachels 1975). In Case A, the cousin hears a\nthump, runs up to find the boy unconscious in the bath, and reaches\nout to turn on the tap so that the water will rise up to drown the\nboy. In Case B, the cousin hears a thump, runs up to find the boy\nunconscious in the bath with the water running, and decides to sit\nback and do nothing until the boy drowns. Since there is surely no\nmoral difference between these cases, Rachels argued, the general\ndistinction between killing and letting die is undercut. “Not so\nfast!” is the well-justified reaction (cf. Beauchamp 1979). Just\nbecause a factor is morally relevant in a certain way in comparing one\npair of cases does not mean that it either is or must be relevant in\nthe same way or to the same degree when comparing other cases. Shelly\nKagan has dubbed the failure to take account of this fact of\ncontextual interaction when wielding comparison cases the\n“additive fallacy” (1988). Kagan concludes from this that\nthe reasoning of moral theorists must depend upon some theory that\nhelps us anticipate and account for ways in which factors will\ninteract in various contexts. A parallel lesson, reinforcing what we\nhave already observed in connection with casuistry proper, would apply\nfor moral reasoning in general: reasoning from cases must at least\nimplicitly rely upon a set of organizing judgments or beliefs, of a\nkind that would, on some understandings, count as a moral\n“theory.” If this is correct, it provides another kind of\nreason to think that moral considerations could be crystallized into\nprinciples that make manifest the organizing structure involved.  \nWe are concerned here with moral reasoning as a species of practical\nreasoning – reasoning directed to deciding what to do and, if\nsuccessful, issuing in an intention. But how can such practical\nreasoning succeed? How can moral reasoning hook up with motivationally\neffective psychological states so as to have this kind of causal\neffect? “Moral psychology” – the traditional name\nfor the philosophical study of intention and action – has a lot\nto say to such questions, both in its traditional, a priori\nform and its newly popular empirical form. In addition, the\nconclusions of moral psychology can have substantive moral\nimplications, for it may be reasonable to assume that if there are\ndeep reasons that a given type of moral reasoning cannot be\npractical, then any principles that demand such reasoning are unsound.\nIn this spirit, Samuel Scheffler has explored “the importance\nfor moral philosophy of some tolerably realistic understanding of\nhuman motivational psychology” (Scheffler 1992, 8) and Peter\nRailton has developed the idea that certain moral principles might\ngenerate a kind of “alienation” (Railton 1984). In short,\nwe may be interested in what makes practical reasoning of a certain\nsort psychologically possible both for its own sake and as a way of\nworking out some of the content of moral theory.  \nThe issue of psychological possibility is an important one for all\nkinds of practical reasoning (cf. Audi 1989). In morality, it is\nespecially pressing, as morality often asks individuals to depart from\nsatisfying their own interests. As a result, it may appear that moral\nreasoning’s practical effect could not be explained by a simple\nappeal to the initial motivations that shape or constitute\nsomeone’s interests, in combination with a requirement, like\nthat mentioned above, to will the necessary means to one’s ends.\nMorality, it may seem, instead requires individuals to act on ends\nthat may not be part of their “motivational set,” in the\nterminology of Williams 1981. How can moral reasoning lead people to\ndo that? The question is a traditional one. Plato’s\nRepublic answered that the appearances are deceiving, and\nthat acting morally is, in fact, in the enlightened self-interest of\nthe agent. Kant, in stark contrast, held that our transcendent\ncapacity to act on our conception of a practical law enables us to set\nends and to follow morality even when doing so sharply conflicts with\nour interests. Many other answers have been given. In recent times,\nphilosophers have defended what has been called\n“internalism” about morality, which claims that there is a\nnecessary conceptual link between agents’ moral judgment and\ntheir motivation. Michael Smith, for instance, puts the claim as\nfollows (Smith 1994, 61): \nEven this defeasible version of moral judgment internalism may be too\nstrong; but instead of pursuing this issue further, let us turn to a\nquestion more internal to moral reasoning. (For more on the issue of\nmoral judgment internalism, see\n moral motivation.)\n  \nThe traditional question we were just glancing at picks up when moral\nreasoning is done. Supposing that we have some moral conclusion, it\nasks how agents can be motivated to go along with it. A different\nquestion about the intersection of moral reasoning and moral\npsychology, one more immanent to the former, concerns how motivational\nelements shape the reasoning process itself.  \nA powerful philosophical picture of human psychology, stemming from\nHume, insists that beliefs and desires are distinct existences (Hume\n2000, Book II, part iii, sect. iii; cf. Smith 1994, 7). This means\nthat there is always a potential problem about how reasoning, which\nseems to work by concatenating beliefs, links up to the motivations\nthat desire provides. The paradigmatic link is that of instrumental\naction: the desire to Ψ links with the belief that by Φing in\ncircumstances C one will Ψ. Accordingly, philosophers who\nhave examined moral reasoning within an essentially Humean,\nbelief-desire psychology have sometimes accepted a constrained account\nof moral reasoning. Hume’s own account exemplifies the sort of\nconstraint that is involved. As Hume has it, the calm passions support\nthe dual correction of perspective constitutive of morality, alluded\nto above. Since these calm passions are seen as competing with our\nother passions in essentially the same motivational coinage, as it\nwere, our passions limit the reach of moral reasoning.  \nAn important step away from a narrow understanding of Humean moral\npsychology is taken if one recognizes the existence of what Rawls has\ncalled “principle-dependent desires” (Rawls 1996, 82–83;\nRawls 2000, 46–47). These are desires whose objects cannot be\ncharacterized without reference to some rational or moral principle.\nAn important special case of these is that of\n“conception-dependent desires,” in which the\nprinciple-dependent desire in question is seen by the agent as\nbelonging to a broader conception, and as important on that account\n(Rawls 1996, 83–84; Rawls 2000, 148–152). For instance,\nconceiving of oneself as a citizen, one may desire to bear one’s\nfair share of society’s burdens. Although it may look like any\ncontent, including this, may substitute for Ψ in the Humean\nconception of desire, and although Hume set out to show how moral\nsentiments such as pride could be explained in terms of simple\npsychological mechanisms, his influential empiricism actually tends to\nrestrict the possible content of desires. Introducing\nprinciple-dependent desires thus seems to mark a departure from a\nHumean psychology. As Rawls remarks, if “we may find ourselves\ndrawn to the conceptions and ideals that both the right and the good\nexpress … , [h]ow is one to fix limits on what people might be\nmoved by in thought and deliberation and hence may act from?”\n(1996, 85). While Rawls developed this point by contrasting\nHume’s moral psychology with Kant’s, the same basic point\nis also made by neo-Aristotelians (e.g., McDowell 1998).  \nThe introduction of principle-dependent desires bursts any would-be\nnaturalist limit on their content; nonetheless, some philosophers hold\nthat this notion remains too beholden to an essentially Humean picture\nto be able to capture the idea of a moral commitment. Desires, it may\nseem, remain motivational items that compete on the basis of strength.\nSaying that one’s desire to be just may be outweighed by\none’s desire for advancement may seem to fail to capture the\nthought that one has a commitment – even a non-absolute one\n– to justice. Sartre designed his example of the student torn\nbetween staying with his mother and going to fight with the Free\nFrench so as to make it seem implausible that he ought to decide\nsimply by determining which he more strongly wanted to do.  \nOne way to get at the idea of commitment is to emphasize our capacity\nto reflect about what we want. By this route, one might distinguish,\nin the fashion of Harry Frankfurt, between the strength of our desires\nand “the importance of what we care about” (Frankfurt\n1988). Although this idea is evocative, it provides relatively little\ninsight into how it is that we thus reflect. Another way to\nmodel commitment is to take it that our intentions operate at a level\ndistinct from our desires, structuring what we are willing to\nreconsider at any point in our deliberations (e.g. Bratman 1999).\nWhile this two-level approach offers some advantages, it is limited by\nits concession of a kind of normative primacy to the unreconstructed\ndesires at the unreflective level. A more integrated approach might\nmodel the psychology of commitment in a way that reconceives the\nnature of desire from the ground up. One attractive possibility is to\nreturn to the Aristotelian conception of desire as being for the sake\nof some good or apparent good (cf. Richardson 2004). On this\nconception, the end for the sake of which an action is done plays an\nimportant regulating role, indicating, in part, what one will\nnot do (Richardson 2018, §§8.3–8.4). Reasoning about final\nends accordingly has a distinctive character (see Richardson 1994,\nSchmidtz 1995). Whatever the best philosophical account of the notion\nof a commitment – for another alternative, see (Tiberius\n2000) – much of our moral reasoning does seem to involve\nexpressions of and challenges to our commitments (Anderson and Pildes\n2000).  \nRecent experimental work, employing both survey instruments and brain\nimaging technologies, has allowed philosophers to approach questions\nabout the psychological basis of moral reasoning from novel angles.\nThe initial brain data seems to show that individuals with damage to\nthe pre-frontal lobes tend to reason in more straightforwardly\nconsequentialist fashion than those without such damage (Koenigs et\nal. 2007). Some theorists take this finding as tending to confirm that\nfully competent human moral reasoning goes beyond a simple weighing of\npros and cons to include assessment of moral constraints (e.g.,\nWellman & Miller 2008, Young & Saxe 2008). Others, however,\nhave argued that the emotional responses of the prefrontal lobes\ninterfere with the more sober and sound, consequentialist-style\nreasoning of the other parts of the brain (e.g. Greene 2014). The\nsurvey data reveals or confirms, among other things, interesting,\nnormatively loaded asymmetries in our attribution of such concepts as\nresponsibility and causality (Knobe 2006). It also reveals that many\nof moral theory’s most subtle distinctions, such as the\ndistinction between an intended means and a foreseen side-effect, are\ndeeply built into our psychologies, being present cross-culturally and\nin young children, in a way that suggests to some the possibility of\nan innate “moral grammar” (Mikhail 2011).  \nA final question about the connection between moral motivation and\nmoral reasoning is whether someone without the right motivational\ncommitments can reason well, morally. On Hume’s official, narrow\nconception of reasoning, which essentially limits it to tracing\nempirical and logical connections, the answer would be yes. The\nvicious person could trace the causal and logical implications of\nacting in a certain way just as a virtuous person could. The only\ndifference would be practical, not rational: the two would not act in\nthe same way. Note, however, that the Humean’s affirmative\nanswer depends on departing from the working definition of\n“moral reasoning” used in this article, which casts it as\na species of practical reasoning. Interestingly, Kant can answer\n“yes” while still casting moral reasoning as practical. On\nhis view in the Groundwork and the Critique of Practical\nReason, reasoning well, morally, does not depend on any prior\nmotivational commitment, yet remains practical reasoning. That is\nbecause he thinks the moral law can itself generate motivation.\n(Kant’s Metaphysics of Morals and Religion\noffer a more complex psychology.) For Aristotle, by contrast, an agent\nwhose motivations are not virtuously constituted will systematically\nmisperceive what is good and what is bad, and hence will be unable to\nreason excellently. The best reasoning that a vicious person is\ncapable of, according to Aristotle, is a defective simulacrum of\npractical wisdom that he calls “cleverness”\n(Nicomachean Ethics 1144a25).  \nMoral considerations often conflict with one another. So do moral\nprinciples and moral commitments. Assuming that filial loyalty and\npatriotism are moral considerations, then Sartre’s student faces\na moral conflict. Recall that it is one thing to model the metaphysics\nof morality or the truth conditions of moral statements and another to\ngive an account of moral reasoning. In now looking at conflicting\nconsiderations, our interest here remains with the latter and not the\nformer. Our principal interest is in ways that we need to structure or\nthink about conflicting considerations in order to negotiate well our\nreasoning involving them.  \nOne influential building-block for thinking about moral conflicts is\nW. D. Ross’s notion of a “prima facie\nduty”. Although this term misleadingly suggests mere appearance\n– the way things seem at first glance – it has stuck. Some\nmoral philosophers prefer the term “pro tanto\nduty” (e.g., Hurley 1989). Ross explained that his term provides\n“a brief way of referring to the characteristic (quite distinct\nfrom that of being a duty proper) which an act has, in virtue of being\nof a certain kind (e.g., the keeping of a promise), of being an act\nwhich would be a duty proper if it were not at the same time of\nanother kind which is morally significant.” Illustrating the\npoint, he noted that a prima facie duty to keep a promise can\nbe overridden by a prima facie duty to avert a serious\naccident, resulting in a proper, or unqualified, duty to do the latter\n(Ross 1988, 18–19). Ross described each prima facie duty as a\n“parti-resultant” attribute, grounded or explained by one\naspect of an act, whereas “being one’s [actual]\nduty” is a “toti-resultant” attribute resulting from\nall such aspects of an act, taken together (28; see Pietroski 1993).\nThis suggests that in each case there is, in principle, some function\nthat generally maps from the partial contributions of each prima\nfacie duty to some actual duty. What might that function be? To\nRoss’s credit, he writes that “for the estimation of the\ncomparative stringency of these prima facie obligations no\ngeneral rules can, so far as I can see, be laid down” (41).\nAccordingly, a second strand in Ross simply emphasizes, following\nAristotle, the need for practical judgment by those who have been\nbrought up into virtue (42).  \nHow might considerations of the sort constituted by prima\nfacie duties enter our moral reasoning? They might do so\nexplicitly, or only implicitly. There is also a third, still weaker\npossibility (Scheffler 1992, 32): it might simply be the case that if\nthe agent had recognized a prima facie duty, he\nwould have acted on it unless he considered it to be overridden. This\nis a fact about how he would have reasoned.  \nDespite Ross’s denial that there is any general method for\nestimating the comparative stringency of prima facie duties,\nthere is a further strand in his exposition that many find\nirresistible and that tends to undercut this denial. In the very same\nparagraph in which he states that he sees no general rules for dealing\nwith conflicts, he speaks in terms of “the greatest balance of\nprima facie rightness.” This language, together with\nthe idea of “comparative stringency,” ineluctably suggests\nthe idea that the mapping function might be the same in each case of\nconflict and that it might be a quantitative one. On this conception,\nif there is a conflict between two prima facie duties, the\none that is strongest in the circumstances should be taken to win.\nDuly cautioned about the additive fallacy (see\n section 2.3),\n we might recognize that the strength of a moral consideration in one\nset of circumstances cannot be inferred from its strength in other\ncircumstances. Hence, this approach will need still to rely on\nintuitive judgments in many cases. But this intuitive judgment will be\nabout which prima facie consideration is stronger in the\ncircumstances, not simply about what ought to be done.  \nThe thought that our moral reasoning either requires or is benefited\nby a virtual quantitative crutch of this kind has a long pedigree. Can\nwe really reason well morally in a way that boils down to assessing\nthe weights of the competing considerations? Addressing this question\nwill require an excursus on the nature of moral reasons. Philosophical\nsupport for this possibility involves an idea of practical\ncommensurability. We need to distinguish, here, two kinds of practical\ncommensurability or incommensurability, one defined in metaphysical\nterms and one in deliberative terms. Each of these forms might be\nstated evaluatively or deontically. The first, metaphysical sort of\nvalue incommensurability is defined directly in terms of what is the\ncase. Thus, to state an evaluative version: two values are\nmetaphysically incommensurable just in case neither is better than the\nother nor are they equally good (see Chang 1998). Now, the\nmetaphysical incommensurability of values, or its absence, is only\nloosely linked to how it would be reasonable to deliberate. If all\nvalues or moral considerations are metaphysically (that is, in fact)\ncommensurable, still it might well be the case that our access to the\nultimate commensurating function is so limited that we would fare ill\nby proceeding in our deliberations to try to think about which\noutcomes are “better” or which considerations are\n“stronger.” We might have no clue about how to measure the\nrelevant “strength.” Conversely, even if metaphysical\nvalue incommensurability is common, we might do well, deliberatively,\nto proceed as if this were not the case, just as we proceed in\nthermodynamics as if the gas laws obtained in their idealized form.\nHence, in thinking about the deliberative implications of\n incommensurable values,\n we would do well to think in terms of a definition tailored to the\ndeliberative context. Start with a local, pairwise form. We may say\nthat two options, A and B, are deliberatively commensurable just in\ncase there is some one dimension of value in terms of which, prior to\n– or logically independently of – choosing between them,\nit is possible adequately to represent the force of the considerations\nbearing on the choice.  \nPhilosophers as diverse as Immanuel Kant and John Stuart Mill have\nargued that unless two options are deliberatively commensurable, in\nthis sense, it is impossible to choose rationally between them.\nInterestingly, Kant limited this claim to the domain of prudential\nconsiderations, recognizing moral reasoning as invoking considerations\nincommensurable with those of prudence. For Mill, this claim formed an\nimportant part of his argument that there must be some one, ultimate\n“umpire” principle – namely, on his view, the\nprinciple of utility. Henry Sidgwick elaborated Mill’s argument\nand helpfully made explicit its crucial assumption, which he called\nthe “principle of superior validity” (Sidgwick 1981; cf.\nSchneewind 1977). This is the principle that conflict between distinct\nmoral or practical considerations can be rationally resolved only on\nthe basis of some third principle or consideration that is both more\ngeneral and more firmly warranted than the two initial competitors.\nFrom this assumption, one can readily build an argument for the\nrational necessity not merely of local deliberative commensurability,\nbut of a global deliberative commensurability that, like Mill and\nSidgwick, accepts just one ultimate umpire principle (cf. Richardson\n1994, chap. 6).  \nSidgwick’s explicitness, here, is valuable also in helping one\nsee how to resist the demand for deliberative commensurability.\nDeliberative commensurability is not necessary for proceeding\nrationally if conflicting considerations can be rationally dealt with\nin a holistic way that does not involve the appeal to a principle of\n“superior validity.” That our moral reasoning can proceed\nholistically is strongly affirmed by Rawls. Rawls’s\ncharacterizations of the influential ideal of\n reflective equilibrium\n and his related ideas about the nature of justification imply that we\ncan deal with conflicting considerations in less hierarchical ways\nthan imagined by Mill or Sidgwick. Instead of proceeding up a ladder\nof appeal to some highest court or supreme umpire, Rawls suggests,\nwhen we face conflicting considerations “we work from both\nends” (Rawls 1999, 18). Sometimes indeed we revise our more\nparticular judgments in light of some general principle to which we\nadhere; but we are also free to revise more general principles in\nlight of some relatively concrete considered judgment. On this\npicture, there is no necessary correlation between degree of\ngenerality and strength of authority or warrant. That this holistic\nway of proceeding (whether in building moral theory or in\ndeliberating: cf. Hurley 1989) can be rational is confirmed by the\npossibility of a form of justification that is similarly holistic:\n“justification is a matter of the mutual support of many\nconsiderations, of everything fitting together into one coherent\nview” (Rawls 1999, 19, 507). (Note that this statement, which\nexpresses a necessary aspect of moral or practical justification,\nshould not be taken as a definition or analysis thereof.) So there is\nan alternative to depending, deliberatively, on finding a dimension in\nterms of which considerations can be ranked as “stronger”\nor “better” or “more stringent”: one can\ninstead “prune and adjust” with an eye to building more\nmutual support among the considerations that one endorses on due\nreflection. If even the desideratum of practical coherence is subject\nto such re-specification, then this holistic possibility really does\nrepresent an alternative to commensuration, as the deliberator, and\nnot some coherence standard, retains reflective sovereignty\n(Richardson 1994, sec. 26). The result can be one in which the\noriginally competing considerations are not so much compared as\ntransformed (Richardson 2018, chap. 1) \nSuppose that we start with a set of first-order moral considerations\nthat are all commensurable as a matter of ultimate, metaphysical fact,\nbut that our grasp of the actual strength of these considerations is\nquite poor and subject to systematic distortions. Perhaps some people\nare much better placed than others to appreciate certain\nconsiderations, and perhaps our strategic interactions would cause us\nto reach suboptimal outcomes if we each pursued our own unfettered\njudgment of how the overall set of considerations plays out. In such\ncircumstances, there is a strong case for departing from maximizing\nreasoning without swinging all the way to the holist alternative. This\ncase has been influentially articulated by Joseph Raz, who develops\nthe notion of an “exclusionary reason” to occupy this\nmiddle position (Raz 1990).  \n“An exclusionary reason,” in Raz’s terminology,\n“is a second order reason to refrain from acting for some\nreason” (39). A simple example is that of Ann, who is tired\nafter a long and stressful day, and hence has reason not to act on her\nbest assessment of the reasons bearing on a particularly important\ninvestment decision that she immediately faces (37). This notion of an\nexclusionary reason allowed Raz to capture many of the complexities of\nour moral reasoning, especially as it involves principled commitments,\nwhile conceding that, at the first order, all practical reasons might\nbe commensurable. Raz’s early strategy for reconciling\ncommensurability with complexity of structure was to limit the claim\nthat reasons are comparable with regard to strength to reasons of a\ngiven order. First-order reasons compete on the basis of strength; but\nconflicts between first- and second-order reasons “are resolved\nnot by the strength of the competing reasons but by a general\nprinciple of practical reasoning which determines that exclusionary\nreasons always prevail” (40).  \nIf we take for granted this “general principle of practical\nreasoning,” why should we recognize the existence of any\nexclusionary reasons, which by definition prevail independently of any\ncontest of strength? Raz’s principal answer to this question\nshifts from the metaphysical domain of the strengths that various\nreasons “have” to the epistemically limited viewpoint of\nthe deliberator. As in Ann’s case, we can see in certain\ncontexts that a deliberator is likely to get things wrong if he or she\nacts on his or her perception of the first-order reasons. Second-order\nreasons indicate, with respect to a certain range of first-order\nreasons, that the agent “must not act for those\nreasons” (185). The broader justification of an exclusionary\nreason, then, can consistently be put in terms of the commensurable\nfirst-order reasons. Such a justification can have the following form:\n“Given this agent’s deliberative limitations, the balance\nof first-order reasons will likely be better conformed with if he or\nshe refrains from acting for certain of those reasons.” \nRaz’s account of exclusionary reasons might be used to reconcile\nultimate commensurability with the structured complexity of our moral\nreasoning. Whether such an attempt could succeed would depend, in\npart, on the extent to which we have an actual grasp of first-order\nreasons, conflict among which can be settled solely on the basis of\ntheir comparative strength. Our consideration, above, of casuistry,\nthe additive fallacy, and deliberative incommensurability may combine\nto make it seem that only in rare pockets of our practice do we have a\ngood grasp of first-order reasons, if these are defined, à la\nRaz, as competing only in terms of strength. If that is right, then we\nwill almost always have good exclusionary reasons to reason on some\nother basis than in terms of the relative strength of first-order\nreasons. Under those assumptions, the middle way that Raz’s idea\nof exclusionary reasons seems to open up would more closely approach\nthe holist’s. \nThe notion of a moral consideration’s “strength,”\nwhether put forward as part of a metaphysical picture of how\nfirst-order considerations interact in fact or as a suggestion about\nhow to go about resolving a moral conflict, should not be confused\nwith the bottom-line determination of whether one consideration, and\nspecifically one duty, overrides another. In Ross’s example of\nconflicting prima facie duties, someone must choose between\naverting a serious accident and keeping a promise to meet someone.\n(Ross chose the case to illustrate that an “imperfect”\nduty, or a duty of commission, can override a strict, prohibitive\nduty.) Ross’s assumption is that all well brought-up people\nwould agree, in this case, that the duty to avert serious harm to\nsomeone overrides the duty to keep such a promise. We may take it, if\nwe like, that this judgment implies that we consider the duty to save\na life, here, to be stronger than the duty to keep the promise; but in\nfact this claim about relative strength adds nothing to our\nunderstanding of the situation. Yet we do not reach our practical\nconclusion in this case by determining that the duty to save\nthe boy’s life is stronger. The statement that this duty is here\nstronger is simply a way to embellish the conclusion that of the two\nprima facie duties that here conflict, it is the one that\nstates the all-things-considered duty. To be “overridden”\nis just to be a prima facie duty that fails to generate an\nactual duty because another prima facie duty that conflicts\nwith it – or several of them that do – does generate an\nactual duty. Hence, the judgment that some duties override others can\nbe understood just in terms of their deontic upshots and without\nreference to considerations of strength. To confirm this, note that we\ncan say, “As a matter of fidelity, we ought to keep the promise;\nas a matter of beneficence, we ought to save the life; we cannot do\nboth; and both categories considered we ought to save the life.”\n \nUnderstanding the notion of one duty overriding another in this way\nputs us in a position to take up the topic of\n moral dilemmas.\n Since this topic is covered in a separate article, here we may simply\ntake up one attractive definition of a moral dilemma.\nSinnott-Armstrong (1988) suggested that a moral dilemma is a situation\nin which the following are true of a single agent: \nThis way of defining moral dilemmas distinguishes them from the kind\nof moral conflict, such as Ross’s\npromise-keeping/accident-prevention case, in which one of the duties\nis overridden by the other. Arguably, Sartre’s student faces a\nmoral dilemma. Making sense of a situation in which neither of two\nduties overrides the other is easier if deliberative commensurability\nis denied. Whether moral dilemmas are possible will depend crucially\non whether “ought” implies “can” and whether\nany pair of duties such as those comprised by (1) and (2) implies a\nsingle, “agglomerated” duty that the agent do both\nA and B. If either of these purported principles of\nthe logic of duties is false, then moral dilemmas are possible.  \nJonathan Dancy has well highlighted a kind of contextual variability\nin moral reasons that has come to be known as “reasons\nholism”: “a feature that is a reason in one case may be no\nreason at all, or an opposite reason, in another” (Dancy 2004).\nTo adapt one of his examples: while there is often moral reason not to\nlie, when playing liar’s poker one generally ought to lie;\notherwise, one will spoil the game (cf. Dancy 1993, 61). Dancy argues\nthat reasons holism supports moral particularism of the kind discussed\nin\n section 2.2,\n according to which there are no defensible moral principles. Taking\nthis conclusion seriously would radically affect how we conducted our\nmoral reasoning. The argument’s premise of holism has been\nchallenged (e.g., Audi 2004, McKeever & Ridge 2006). Philosophers\nhave also challenged the inference from reasons holism to\nparticularism in various ways. Mark Lance and Margaret Olivia Little\n(2007) have done so by exhibiting how defeasible generalizations, in\nethics and elsewhere, depend systematically on context. We\ncan work with them, they suggest, by utilizing a skill that is similar\nto the skill of discerning morally salient considerations, namely the\nskill of discerning relevant similarities among possible worlds. More\ngenerally, John F. Horty has developed a logical and semantic account\naccording to which reasons are defaults and so behave holistically,\nbut there are nonetheless general principles that explain how they\nbehave (Horty 2012). And Mark Schroeder has argued that our holistic\nviews about reasons are actually better explained by supposing that\nthere are general principles (Schroeder 2011).  \nThis excursus on moral reasons suggests that there are a number of\ngood reasons why reasoning about moral matters might not simply reduce\nto assessing the weights of competing considerations.  \nIf we have any moral knowledge, whether concerning general moral\nprinciples or concrete moral conclusions, it is surely very imperfect.\nWhat moral knowledge we are capable of will depend, in part, on what\nsorts of moral reasoning we are capable of. Although some moral\nlearning may result from the theoretical work of moral philosophers\nand theorists, much of what we learn with regard to morality surely\narises in the practical context of deliberation about new and\ndifficult cases. This deliberation might be merely instrumental,\nconcerned only with settling on means to moral ends, or it might be\nconcerned with settling those ends. There is no special problem about\nlearning what conduces to morally obligatory ends: that is an ordinary\nmatter of empirical learning. But by what sorts of process can we\nlearn which ends are morally obligatory, or which norms morally\nrequired? And, more specifically, is strictly moral learning possible\nvia moral reasoning?  \nMuch of what was said above with regard to moral uptake applies again\nin this context, with approximately the same degree of dubiousness or\npersuasiveness. If there is a role for moral perception or for\nemotions in agents’ becoming aware of moral considerations,\nthese may function also to guide agents to new conclusions. For\ninstance, it is conceivable that our capacity for outrage is a\nrelatively reliable detector of wrong actions, even novel ones, or\nthat our capacity for pleasure is a reliable detector of actions worth\ndoing, even novel ones. (For a thorough defense of the latter\npossibility, which intriguingly interprets pleasure as a judgment of\nvalue, see Millgram 1997.) Perhaps these capacities for emotional\njudgment enable strictly moral learning in roughly the same way that\nchess-players’ trained sensibilities enable them to recognize\nthe threat in a previously unencountered situation on the chessboard\n(Lance and Tanesini 2004). That is to say, perhaps our moral emotions\nplay a crucial role in the exercise of a skill whereby we come to be\nable to articulate moral insights that we have never before attained.\nPerhaps competing moral considerations interact in contextually\nspecific and complex ways much as competing chess considerations do.\nIf so, it would make sense to rely on our emotionally-guided\ncapacities of judgment to cope with complexities that we cannot model\nexplicitly, but also to hope that, once having been so guided, we\nmight in retrospect be able to articulate something about the lesson\nof a well-navigated situation.  \nA different model of strictly moral learning puts the emphasis on our\nafter-the-fact reactions rather than on any prior, tacit emotional or\njudgmental guidance: the model of “experiments in living,”\nto use John Stuart Mill’s phrase (see Anderson 1991). Here, the\nbasic thought is that we can try something and see if “it\nworks.” For this to be an alternative to empirical learning\nabout what causally conduces to what, it must be the case that we\nremain open as to what we mean by things “working.” In\nMill’s terminology, for instance, we need to remain open as to\nwhat are the important “parts” of happiness. If we are,\nthen perhaps we can learn by experience what some of them are –\nthat is, what are some of the constitutive means of happiness. These\npaired thoughts, that our practical life is experimental and that we\nhave no firmly fixed conception of what it is for something to\n“work,” come to the fore in Dewey’s pragmatist\nethics (see esp. Dewey 1967 [1922]). This experimentalist conception\nof strictly moral learning is brought to bear on moral reasoning in\nDewey’s eloquent characterizations of “practical\nintelligence” as involving a creative and flexible approach to\nfiguring out “what works” in a way that is thoroughly open\nto rethinking our ultimate aims.  \nOnce we recognize that moral learning is a possibility for us, we can\nrecognize a broader range of ways of coping with moral conflicts than\nwas canvassed in the last section. There, moral conflicts were\ndescribed in a way that assumed that the set of moral considerations,\namong which conflicts were arising, was to be taken as fixed. If we\ncan learn, morally, however, then we probably can and should revise\nthe set of moral considerations that we recognize. Often, we do this\nby re-interpreting some moral principle that we had started with,\nwhether by making it more specific, making it more abstract, or in\nsome other way (cf. Richardson 2000 and 2018).  \nSo far, we have mainly been discussing moral reasoning as if it were a\nsolitary endeavor. This is, at best, a convenient simplification. At\nworst, it is, as Jürgen Habermas has long argued, deeply\ndistorting of reasoning’s essentially dialogical or\nconversational character (e.g., Habermas 1984; cf. Laden 2012). In any\ncase, it is clear that we often do need to reason morally with one\nanother.  \nHere, we are interested in how people may actually reason with one\nanother – not in how imagined participants in an original\nposition or ideal speech situation may be said to reason with one\nanother, which is a concern for moral theory, proper. There are two\nsalient and distinct ways of thinking about people morally reasoning\nwith one another: as members of an organized or corporate body that is\ncapable of reaching practical decisions of its own; and as autonomous\nindividuals working outside any such structure to figure out with each\nother what they ought, morally, to do.  \nThe nature and possibility of collective reasoning within an organized\ncollective body has recently been the subject of some discussion.\nCollectives can reason if they are structured as an agent. This\nstructure might or might not be institutionalized. In line with the\ngloss of reasoning offered above, which presupposes being guided by an\nassessment of one’s reasons, it is plausible to hold that a\ngroup agent “counts as reasoning, not just rational, only if it\nis able to form not only beliefs in propositions – that\nis, object-language beliefs – but also belief about\npropositions” (List and Pettit 2011, 63). As List and Pettit\nhave shown (2011, 109–113), participants in a collective agent\nwill unavoidably have incentives to misrepresent their own preferences\nin conditions involving ideologically structured disagreements where\nthe contending parties are oriented to achieving or avoiding certain\noutcomes – as is sometimes the case where serious moral\ndisagreements arise. In contexts where what ultimately matters is how\nwell the relevant group or collective ends up faring, “team\nreasoning” that takes advantage of orientation towards the\ncollective flourishing of the group can help it reach a collectively\noptimal outcome (Sugden 1993, Bacharach 2006; see entry on\n collective intentionality).\n Where the group in question is smaller than the set of persons,\nhowever, such a collectively prudential focus is distinct from a moral\nfocus and seems at odds with the kind of impartiality typically\nthought distinctive of the moral point of view. Thinking about what a\n“team-orientation” to the set all persons might look like might bring\nus back to thoughts of Kantian universalizability; but recall that\nhere we are focused on actual reasoning, not hypothetical reasoning.\nWith regard to actual reasoning, even if individuals can take up such\nan orientation towards the “team” of all persons, there is serious\nreason, highlighted by another strand of the Kantian tradition, for\ndoubting that any individual can aptly surrender their moral judgment\nto any group’s verdict (Wolff 1998).  \nThis does not mean that people cannot reason together, morally. It\nsuggests, however, that such joint reasoning is best pursued as a\nmatter of working out together, as independent moral agents, what they\nought to do with regard to an issue on which they have some need to\ncooperate. Even if deferring to another agent’s verdict as to\nhow one morally ought to act is off the cards, it is still possible\nthat one may licitly take account of the moral testimony of others\n(for differing views, see McGrath 2009, Enoch 2014). \nIn the case of independent individuals reasoning morally with one\nanother, we may expect that moral disagreement provides the occasion\nrather than an obstacle. To be sure, if individuals’ moral\ndisagreement is very deep, they may not be able to get this reasoning\noff the ground; but as Kant’s example of Charles V and his\nbrother each wanting Milan reminds us, intractable disagreement can\narise also from disagreements that, while conceptually shallow, are\ncircumstantially sharp. If it were true that clear-headed\njustification of one’s moral beliefs required seeing them as\nbeing ultimately grounded in a priori principles, as G.A. Cohen argued\n(Cohen 2008, chap. 6), then room for individuals to work out their\nmoral disagreements by reasoning with one another would seem to be\nrelatively restricted; but whether the nature of (clearheaded) moral\ngrounding is really so restricted is seriously doubtful (Richardson\n2018, §9.2). In contrast to what such a picture suggests,\nindividuals’ moral commitments seem sufficiently open to being\nre-thought that people seem able to engage in principled – that\nis, not simply loss-minimizing – compromise (Richardson 2018,\n§8.5).  \nWhat about the possibility that the moral community as a whole –\nroughly, the community of all persons – can reason? This\npossibility does not raise the kind of threat to impartiality that is\nraised by the team reasoning of a smaller group of people; but it is\nhard to see it working in a way that does not run afoul of the concern\nabout whether any person can aptly defer, in a strong sense, to the\nmoral judgments of another agent. Even so, a residual possibility\nremains, which is that the moral community can reason in just one way,\nnamely by accepting or ratifying a moral conclusion that has already\nbecome shared in a sufficiently inclusive and broad way (Richardson\n2018, chap. 7). ","contact.mail":"richardh@georgetown.edu","contact.domain":"georgetown.edu"}]
