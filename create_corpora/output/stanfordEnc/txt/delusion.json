[{"date.published":"2009-09-16","date.changed":"2018-01-29","url":"https://plato.stanford.edu/entries/delusion/","author1":"Lisa Bortolotti","author1.info":"https://sites.google.com/site/lisabortolottiphilosophy/","entry":"delusion","body.text":"\n\n\n\nThis entry focuses on the phenomenon of clinical delusions. Although\nthe nature of delusions is controversial, as we shall see, delusions\nare often characterised as strange beliefs that appear in the context\nof mental distress. Indeed, clinical delusions are a symptom of\npsychiatric disorders such as dementia and schizophrenia, and they\nalso characterize delusional disorders.  The following case\ndescriptions include one instance of erotomania, the delusion that\none is loved by someone else, often of higher status, and one instance\nof Cotard delusion, the delusion that one is dead or disembodied.\n\nShe realized he was empty without her and was pursuing\nher, but enemies were preventing them from uniting. The enemies\nincluded a number of people: people in her family, her classmates,\nneighbours and many other persons who were plotting to keep them\napart. She knew that her conclusions were accurate because he would\nsend messages to her proving his love. These messages would often\npresent themselves as the license plates on cars of a certain state,\nthe color purple and other indications that she received from the\nenvironment that proved to her that he loved her. (Jordan et\nal. 2006, p. 787) \n\n\nShe repeatedly stated that she was dead and was adamant that she had\ndied two weeks prior to the assessment (i.e. around the time of her\nadmission on 19/11/2004). She was extremely distressed and tearful as\nshe related these beliefs, and was very anxious to learn whether or not\nthe hospital she was in, was ‘heaven’. When asked how she\nthought she had died, LU replied ‘I don’t know how. Now I\nknow that I had a flu and came here on 19th November. Maybe I died of\nthe flu.’ Interestingly, LU also reported that she felt ‘a\nbit strange towards my boyfriend. I cannot kiss him, it feels\nstrange—although I know that he loves me.’ (McKay and\nCipolotti 2007, p. 353)\n \n\n\n\nThe category of delusions is not homogeneous, and we find that\ndifferent delusions have different features. Some delusions have\nimplausible content (as we saw in the case of Cotard). Other\nso-called bizarre delusions include mirrored self\nmisidentification (the delusion that the person in the mirror is not\none’s reflection but a stranger), and the Capgras delusion (the\ndelusion that the spouse or a relative has been replaced by an\nimpostor). The content of other delusions can be plausible and even\ntrue (as in erotomania). One can have the delusion that one is an\nuncomprehended genius, that one’s spouse is unfaithful, or that one’s\nneighbor is a terrorist, and these may be true beliefs.  What makes\nall the above examples instances of delusions is that they\nare rigid to some extent, that is, they are not easily given\nup in the face of challenges and they tend to resist\ncounterevidence. Moreover, delusions are reported sincerely and with\nconviction, although the behavior of people with delusions is not\nalways perfectly consistent with the content of their delusions and\ntheir conviction in the delusional content can fluctuate. Another\ncommon feature is that, for people experiencing delusions, the\ndelusion is often source of distress, and it is found to compromise\ngood functioning. For instance, people who have delusions of\npersecution and believe that they are followed by malevolent others\nlive in a state of great anxiety and can give up their jobs, stop\ncommunicating with their families, and move cities as a result.\n\n\nThe following first-personal account of delusions illustrates the\npervasive effects of delusions on people’s lives:\n\n\nI increasingly heard voices (which I’d always called\n“loud thoughts” or “impulses with words”)\ncommanding me to take destructive action. I concluded that other\npeople were putting these “loud thoughts” in my head and controlling\nmy behavior in an effort to ruin my life. I smelled blood and decaying\nmatter where no blood or decaying matter could be found (for example,\nin the classrooms at school). I had difficulty concentrating, I\nfantasized excessively, and I had trouble sleeping and eating. (Bockes\n1985, p. 488)\n\n\n\nThis entry only starts to address some of the philosophical debates\ncentered on delusions. Section 1 provides an overview of the\nphilosophical significance of delusions. Section 2 introduces the\nissues surrounding the controversial definition of delusions, and some\nof the common distinctions between types of delusions are\nexplained. Section 3 discusses the most prominent theoretical\napproaches to the nature and formation of delusions and the conceptual\nquestions emerging from such approaches are highlighted. Section 4\nreviews three of the most discussed themes in the philosophical\nliterature on delusions: whether delusions are irrational; whether\nthey are beliefs; and to what extent they overlap with cases of\nself-deception. The examination of the issues above often culminates\nin the attempt to understand how delusions differ from other\npathological and non-pathological beliefs.\n\n\n\nIn recent years, delusions have attracted the attention of\nphilosophers in at least three distinct areas. Here is a summary of\nthe general issues that have been addressed and some examples of\nspecific debates for each of these areas.  In the philosophy of mind and the philosophy of psychology, there\nhave been various attempts to understand the cognitive processes\nresponsible for the formation of delusions, based on the assumption,\nwidely shared in cognitive neuropsychology, that understanding such\nprocesses can lead to the formulation of more empirically sound\ntheories of normal cognition (see Marshall and Halligan 1996,\npp. 5–6; Langdon and Coltheart 2000, pp. 185–6). For\ninstance, let’s assume that delusions are pathological beliefs. How do\nthey come about?  Do people form delusional beliefs as a response to\nbizarre experiences?  Do they form delusional beliefs because they\nhave some reasoning deficit?  \n\nAs the above questions already suggest, the study of delusions raises\nconceptual questions about intentionality, and about the relationship\nbetween intentionality, rationality and self-knowledge.  Moreover, it\ninvites us to reconsider the interaction between perception,\ncognition, and intentional behavior.  One basic question is what comes\nfirst, the experience or the belief (see Campbell 2001): are delusions\nbizarre convictions that alter one’s way of seeing the world, or are\nthey hypotheses formulated to account for some unusual experiences,\nand then endorsed as beliefs? Another debated issue is whether\ndelusions should be characterized as beliefs at all, given that they\nshare features with acts of imagination (Currie 2000), desires (Egan\n2009) and perceptions (Hohwy and Rajan 2012). Can delusions be beliefs\nif they present significant deviations from norms of rationality, and\nare often neither consistent with a person’s beliefs nor responsive to\nthe available evidence? Bayne and Pacherie (2005) and Bortolotti\n(2009) offer defenses of the doxastic nature of delusions, but this is\nstill a hotly debated issue. An interesting position defended\nby Schwitzgebel (2012) is that delusions are in-between states\n(neither beliefs nor non-beliefs), because they match only in part the\ndispositional profile of beliefs. Schwitzgebel’s position has been\nchallenged by philosophers who argue that delusions play a belief-role\nin explaining and predicting intentional action (see Bortolotti 2012;\nBayne and Hattiangadi 2013).   Another strand of investigation developing in this area concerns\nthe possible failures of self knowledge exhibited by people with\ndelusions.  There are several manifestations of poor knowledge of the\nself in delusions (see Kircher and David 2003; Amador and David\n1998). People reporting delusions of passivity may not recognize a\nmovement or a thought as their own, and thus have a distorted sense of\ntheir personal boundaries (e.g., Stephens and Graham 2000). People\nwith delusions may act or feel in a way that is incompatible with the\ncontent of their delusions, or be unable to endorse the content of\ntheir delusion with reasons that are regarded by others as good\nreasons (e.g., Gallagher 2009; Bortolotti and Broome 2008, 2009;\nFernández 2010). Finally, people reporting delusions may\nencounter difficulties in remembering their experienced past and in\nprojecting themselves into the future, because they construct\nunreliable self narratives (e.g., Gerrans 2009, 2014). \n\nIn addition to the literature on the etiology of delusions and their\nstatus as beliefs, there is also a growing literature in the\nphilosophy of psychiatry on other aspects of the nature of delusions\nand on the impact of delusions on people’s mental health. This\nliterature aims at addressing the conceptualization of delusional\nexperience and of delusional beliefs in the wider context of\npsychiatric research and clinical practice. General debates in the\nphilosophy of psychiatry are often applied to delusions more\nspecifically, such as whether delusions are natural kinds (e.g.,\nSamuels 2009), and whether they are a pathological phenomenon (e.g.,\nFulford 2004). \n\nIf we acknowledge that delusions are pathological, there are at least\nsix possible non-exclusive answers to what makes delusions\npathological: Delusions are pathological because they present themselves as\nwhat they are not. They resemble beliefs but do not share some of the\ncore features of beliefs such as action guidance, and are irrational\nto a higher degree than or in a qualitatively different way from\nirrational beliefs (for a discussion of aspects of this view, see\nCurrie and Jureidini 2001 and Frankish 2009). Delusions are pathological because they are signs that the\nperson inhabits a fictional, non-actual reality and no longer shares\nsome fundamental beliefs and practices with the people around her (for\ndifferent versions of this view, see Stephens and Graham 2004 and\n2006; Sass 1994; Gallagher 2009; Rhodes and Gipps 2008). Delusions are pathological because they are puzzling and\nunsettling – and defy folk-psychological\nexpectations –. This also makes them difficult to\nrationalize and interpret (this idea is explored in Campbell\n2001 and Murphy 2012). Delusions are pathological because (differently from many\nirrational beliefs) they negatively affect a person’s well-being\ncausing impaired social functioning, social isolation and withdrawal\n(see Garety and Freeman 1999 for a multidimensional account of\ndelusions, and Bolton 2008 for a harm-related account of mental\nillness in general). Delusions are pathological because they have forensic\nimplications, that is, implications for judgements about whether\nagents can be held legally accountable for their actions. Hohwy and\nRajan (2012) argue that we tend to attribute delusions when we notice\nsignificant impairments in decision-making, autonomy, and\nresponsibility. Delusions are pathological because of their\netiology. Differently from other beliefs, they are produced by\nmechanisms that are dysfunctional or defective.  For instance, the\nprocess of their formation may be characterized by perceptual\naberrations, reasoning biases or deficits. \n\nThe challenge for (i) is to account for the difference\nin kind between the irrationality of common beliefs that are\nungrounded and resistant to change (such as superstitious beliefs or\nbeliefs in alien abductions) and the irrationality of delusions. There\nis abundance of evidence that delusional phenomena are widespread in\nthe normal population, which suggests that a sharp dichotomy between\nthe normal and the pathological would be at best a simplification (see data in\nMaher 1974, Johns and van Os 2001, and Bentall 2003). \n\nAccounts in (ii) and (iii) may be plausible for some delusions that\nappear to defy commonsense and are accompanied by a certain type of\nheightened experience, but do not seem to apply equally well to more\nmundane delusions such as jealousy or persecution. Moreover, it is not\nalways obvious that ascribing a delusion as a belief to someone makes\nthe behavior of that person particularly difficult to explain or to\npredict. \n\nThe view described in (iv) is very attractive because it captures the\ndistinction between delusions and irrational beliefs in terms of their\neffects on other aspects of a person’s psychological and social\nlife. However, using the notions of well-being and harm in accounts of\ndelusions can be problematic, since it is possible for some people to\nlive with the delusion in a way that is preferable to living without\nthe delusion: ceasing to believe that one is a famous TV broadcaster\nafter many years, and starting to accept that one has been mentally\nunwell instead, can cause low self esteem leading to depression and\nsuicidal thoughts. Indeed, in the philosophical and psychiatric\nliterature there have been recent explorations of the idea that some\ndelusions may be adaptive in some sense, psychologically,\nbiologically, and even epistemically (McKay and Dennett 2009, Fineberg\nand Corlett 2016, Bortolotti 2016).  \nChallenges for a forensic account of delusions in (v) lie in the\nheterogeneity of the behavior exhibited by those who experience\ndelusions. Although some delusions can be accompanied by severe\nfailures of autonomous decision-making and give rise to action for\nwhich the agent is not held accountable, it is not obvious that these\nare generalisable phenomena. Does the mere presence of delusions\nindicate lack of autonomy or responsibility? Broome et\nal. (2010) and Bortolotti et al. (2014) discuss case\nstudies raising interesting issues about the role of delusions in\ncriminal action. \nThe etiological answer to the question why delusions are pathological\nin (vi) needs to be better explored. So far, the consensus seems to be\nthat reasoning biases affect normal reasoning, and are not present\nonly in people with delusions. Perceptual aberrations can explain the\nformation of some delusions, but are not always a core factor in the\nformation of all delusions. A problem with the hypothesis evaluation\nsystem involved in the formation of beliefs may be at the origin of\nall delusions, but there is no agreement as to whether the problem is\na permanent deficit or a performance error. Thus, it is not clear\nwhether etiological considerations can support a categorical\ndistinction between pathological and non-pathological beliefs. The\ntheory that delusions are due to a disruption of prediction-error\nsignals may be able to vindicate this approach, although it is not\nclear what the link would be between such a disruption and the\npathological nature of the beliefs adopted as a result of it. \n\nMoral psychology and neuroethics investigate the implications of the\ndebates on the nature of delusions in the philosophy of mind and the\nphilosophy of psychiatry for the type of participation in the moral\ncommunity to which people with delusions are entitled. This includes\nthe attempt to understand better how people’s rights and\nresponsibilities are affected by their having delusions. For instance,\nit is important to determine when people with delusions no longer have\nthe capacity to consent to being treated in a certain way, and to\nsafeguard their interests by ensuring that they receive good care. It\nis also important to understand whether they can be regarded as morally\nresponsible for their actions if they commit acts of violence or other\ncrimes that can be motivated by their believing the content of their\ndelusion. \n\nAs a consequence of the failures in rationality and self knowledge\nthat may characterize people with delusions in the acute phase of their\nmental illness, they may appear as if they were ‘in two\nminds’, and they may not always present themselves as unified\nagents with a coherent set of beliefs and preferences (e.g., Kennett and\nMatthews 2009). As a result, they may be (locally or temporally) unable\nto exercise their capacity for autonomous thought and action. \n\nWe saw some examples of delusions, but no definition yet. How are\ndelusions defined and classified? \n\nCommonly used definitions of delusions make explicit reference to\ntheir surface features rather than to the underlying mechanisms\nresponsible for their formation. Surface features refer to the\nbehavioral manifestations of the delusions, and are often described in\nepistemic terms, that is, their description involves the concept of\nbelief, truth, rationality or justification (e.g., delusions are\nbeliefs held with conviction in spite of having little empirical\nsupport). According to the Glossary in the Diagnostic and\nStatistical Manual of Mental Disorders (DSM-IV 2000, p. 765 and\nDSM-5 2013, p. 819), delusions are false beliefs based on incorrect\ninference about external reality that persist despite evidence to the\ncontrary: \n\nPhilosophers interested in the nature of delusions have asked a number\nof questions which highlight the weaknesses of the DSM definition. For\ninstance, how can we tell delusions apart from other pathologies\ninvolving cognitive impairments or deficits? How can we distinguish\ndelusions from non-pathological, but similarly false or unjustified\nbeliefs? These questions aim at capturing both what is distinctive\nabout delusions, and what makes them pathological. \n\nCounterexamples are easily found to the DSM definition of delusion:\nthere are delusions that do not satisfy all of the proposed criteria,\nand there are irrational beliefs that do, even though they are not\ncommonly regarded as delusional. Coltheart summarizes the main problems\nwith the DSM definition: \nThe Diagnostic and Statistical Manual of Mental Disorders has\nbeen updated recently and although no changes appear in the Glossary,\nsome interesting shifts can be noted in the description of delusions\nwhich appear in the section on schizophrenia (compare DSM-IV, p. 275\nand DSM-IV-TR p. 299 with DSM-5, p. 87). The new description seems to\ntake into account some of the issues identified by Coltheart and\nothers. For instance, in the DSM-5 delusions are described not as\nfalse, but as “fixed beliefs that are not amenable to change in\nlight of conflicting evidence”. Leaving the details aside, some\ngeneral comments apply to the style of the DSM definitions and\ndescriptions of delusions. In so far as delusions are defined and\ndescribed as irrational beliefs, it is difficult for them to be\nuniquely identified because their epistemic ‘faults’ are\nshared with other symptoms of psychiatric disorders, and with\nnon-pathological beliefs. But definitions such as the ones in the DSM\ncannot probably be expected to provide necessary and sufficient\nconditions for the phenomena they aim to define. At best, they can\nprove diagnostically useful and guide further research by conveniently\ndelimitating an area of investigation worth pursuing.  \nA widespread critique of the DSM definition is that not enough weight\nis given to the consequences of having the delusion for the well-being\nof the person reporting it. Some recent definitions of delusion make\nmore explicit reference to “disrupted functioning”(e.g.,\nMcKay et al. 2005a, p. 315). Freeman (2008, pp. 24–26)\nhighlights the multi-dimensional nature of delusions and lists among\nthe main characteristics of delusions not just that delusions are\nunfounded, firmly held, and resistant to change, but also that they\nare preoccupying and distressing, and that they interfere with the\nsocial dimension of a person’s life. \n\nDelusions used to be divided into functional and\norganic. Now the distinction is regarded by most obsolete, at\nleast in its original characterization. A delusion was called\n‘organic’ if it was the result of brain damage (usually due\nto injuries affecting the right cerebral hemisphere). A delusion was\ncalled ‘functional’ if it had no known organic cause and\nwas explained primarily via psychodynamic or motivational factors. It\nhas become more and more obvious with the development of\nneuropsychiatry that the two categories overlap. Today, the received\nview is that there is a biological basis for all types of delusions,\nbut that in some cases it has not been identified with precision yet.\nSome studies have reported very little difference between the\nphenomenology and symptomatology of delusions that were once divided\ninto organic and functional (Johnstone et al. 1988). \n\nAs we saw, in persecutory delusions, people believe that they are\nfollowed and treated with hostility, and that others want to harm them.\nIn delusions of mirrored-self misidentification, people usually\npreserve the capacity to recognize images in the mirror as reflections,\nbut do not recognize their own face reflected in the mirror and come to\nthink that there is a person in the mirror, a stranger who looks very\nmuch like they do. In either case, the delusion is resistant to\ncounterevidence and has pervasive effects on one’s life. One of\nthe differences is that persecutory delusions are\npolythematic, that is, they extend to more than one theme,\nwhere the themes can be interrelated. Delusions of mirrored-self\nmisidentification are monothematic, and apart from the content\nof delusion itself, no other (unrelated) bizarre belief needs to be\nreported by the same person. Thus, a person who systematically fails to\nrecognize her image in the mirror and comes to think that there is a\nperson identical to her following her around (as in mirrored-self\nmisidentification), but has no other unusual beliefs, has a\nmonothematic delusion. Other examples of monothematic delusions often\nreferred to in the philosophical literature are Capgras and Cotard. The\nCapgras delusion involves the belief that a dear one (a close relative\nor the spouse) has been replaced by an impostor. The Cotard delusion\ninvolves the belief that one is disembodied or dead. Delusions of\npersecution are very common polythematic delusions. A person who\nbelieves that she is surrounded by alien forces and that they control her own actions\nand are slowly taking over people’s bodies might have a number of\ndifferent delusions (persecution and alien control). These delusions\nare interrelated and are manifest in the interpretation of most events\noccurring in the person’s life. Other examples of delusions that\naffect many aspects of one’s cognitive life are the belief that\none is a genius but is often misunderstood by others (grandeur), and\nthe belief that one is loved by a famous or powerful person\n(erotomania). \n\nMonothematic delusions tend to be circumscribed whereas\npolythematic delusions tend to be elaborated (see Davies and\nColtheart 2000 for more detailed explanation and examples). The\ndistinction between circumscribed and elaborated delusions is relevant\nto the level of integration between delusions and a person’s\nother intentional states and to the extent to which the person’s\nendorsement of the delusion is manifested in verbal reports and\nobservable behavior. Delusions might be more or less circumscribed. A\ndelusion is circumscribed if it does not lead to the formation of other\nintentional states whose content is significantly related to the\ncontent of the delusion, nor does it have pervasive effects on the\nbehavior of the person reporting the delusion. For instance, a person\nwith Capgras who believes that his wife has been substituted by an\nimpostor but shows no preoccupation for his wife and does not go and\nlook for her, appears to have a circumscribed delusion. A delusion can\nbe elaborated, if the person reporting the delusion draws consequences\nfrom the delusional state and forms other beliefs that revolve around\nthe theme of the delusion. For instance, a person with Capgras can\ndevelop paranoid thoughts related to the content of the delusion, along\nthe lines that the impostor has evil intentions and will cause harm\nwhen the occasion presents itself. \n\nDepending on whether the delusion seems to be reported on the basis\nof some reasons, and defended with arguments, delusions can be\ndescribed as primary or secondary. The traditional\nway of distinguishing primary from secondary delusions relied on the\nnotion that primary delusions ‘arise out of nowhere’\n(Jaspers 1963). This traditional characterization of the distinction\nhas been found problematic, because it is difficult to establish\nwhether there are antecedents of the delusion in a person’s line\nof reasoning, and for other methodological and clinical reasons (e.g.,\nMiller and Karoni 1996, p. 489). New readings of the distinction have\nbeen provided in the recent philosophical literature on delusions,\nwhere the need arises for distinguishing between people who can endorse\nthe content of their delusions with reasons, and people who cannot\n(e.g. Bortolotti and Broome 2008 talk about authored and un-authored\ndelusions; and Aimola Davies and Davies 2009 distinguish between\npathologies of belief and pathological beliefs on similar lines). \n\nThere are several theoretical approaches to delusion formation which\nattempt to explain the surface features of delusions by reference to\nabnormal experiences, reasoning biases, neuropsychological deficits,\nmotivational factors, and prediction error, but the task of describing\nthe behavioral manifestations of delusions, and reconstructing their\netiology is made difficult by the variation observed both in the form\nand in the content of delusions. \n\nWhen the distinction between functional and organic delusion was\nstill widely accepted, functional delusions were primarily explained on\nthe basis of psychodynamic factors, whereas organic delusions primarily\nreceived a neurobiological explanation. At the present stage of\nempirical investigation in the formation of delusional states, the\nreceived view is that all delusions are due to neuropsychological\ndeficits, which might include motivational factors. \n\nAccording to psychodynamic accounts, there needs to be no\nneurobiological deficits and delusions are caused by motivational\nfactors alone. For instance, delusions of persecution would be\ndeveloped in order to protect one from low self-esteem and depression,\nand would be due to the attribution of negative events to some\nmalevolent other rather than to oneself. The delusion would be part of\na defense mechanism. Other delusions, such as Capgras, have\nalso received a psychodynamic interpretation: a young woman believes\nthat her father has been replaced by a stranger looking just like him\nin order to make her sexual desire for him less socially\nobjectionable.  In this way, the delusion would have the function to\nreduce anxiety and sense of guilt. Psychodynamic accounts of the\nCapgras delusion have been strongly criticized on the basis of recent\nfindings about the type of brain damage that characterizes people with\nCapgras and affects their face recognition system. Psychodynamic\naccounts of other delusions that are supposed to play a defensive or\nself-enhancing role (e.g., persecution, anosognosia and erotomania)\nare still very popular. \n\nNeuropsychological accounts of delusions offer very satisfactory\naccounts of some delusions, as one can often identify with some\nprecision the damaged region of the brain and the causal link between\nthe damage and the formation of the delusion. Neuropsychological\naccounts of other delusions—once regarded as\n‘functional’—are also being developed and\nexplored. For some delusions, hybrid accounts have been proposed,\nwhere a combination of different factors (including motivation)\nsignificantly contribute to the formation of the delusion (e.g. McKay\net al. 2007). One such case seems to be the Reverse Othello\nSyndrome, the delusion that a spouse or romantic partner is still\nfaithful when this is no longer the case. The belief can be regarded\nas a defense against the suffering that the acknowledgement of the\ninfidelity of one’s partner would cause (see example in Butler 2000 as\ncited and discussed by McKay et al. 2005a, p. 313). \n\nAccording to popular neuropsychological accounts, delusions are the\nresult of a cognitive failure, which can be an abnormal perceptual\nexperience (Maher 1974); an abnormal experience accompanied by milder\ndysfunctions such as reasoning biases (Garety and Freeman 1999; Garety\net al. 2001); a breakdown of certain aspects of perception\nand cognition including a deficit in hypothesis evaluation (Langdon\nand Coltheart 2000); or a failure of predictive coding (Fletcher and\nFrith 2009; Corlett et al. 2010).   In the two-factor theory framework, an abnormal event is\nresponsible for the formation of the delusion. The young woman who\nthinks that her father has been replaced by an impostor would form\nthis belief because she has reduced autonomic response to familiar\nfaces, and this affects her capacity to recognize the face of the man\nin front of her as her father’s face, even if she can judge that the\nface is identical (or virtually identical) to that of her father. But\nthis abnormal event (reduction of autonomic response) is not the only\nfactor responsible for the formation of the delusion. In order to\nexplain why the thought that a dear one has been replaced by an\nimpostor is adopted as a plausible explanation of the abnormal event,\none also needs to advocate a deficit at the level of hypothesis\nevaluation (Coltheart 2007), or the presence of exaggerated\nattributional or data-gathering biases, such as the tendency to\n‘jump to conclusion’ on the basis of limited evidence\n(Garety and Freeman 1999). \nAccording to the prediction-error theory, expectations are formed\nabout experience, and greater attention is paid to those events which\ndefy expectations. The discrepancy between what is expected and the\ninformation taken in is an important part of the way learning\noccurs. When expectations are not met, a prediction error is coded,\nand the representation of the world is updated accordingly. A\nprediction-error signal is disrupted when events invested of special\nsignificance (in psychosis this may be due to dopamine dysregulation)\ncause one to update one’s current (correct) beliefs about reality. The\nwoman who see her father and does not get the usual autonomic response\nexperiences an unexpected event which gives rise to a prediction\nerror. The reaction to the signal is to attempt an explanation of the\nunexpected event (’That man is not my father!’). This results in the\nformation of a delusion (Corlett et al. 2007).  \n\nAnother distinction, introduced and developed in the philosophical\nliterature on delusions, is between bottom-up and\ntop-down theories, where these labels are meant to refer to\nthe direction of the causal relation between experience and belief in\nthe formation of the delusion. Bottom-up theorists argue that the\ndirection of causal explanation is from the experience to the\nbelief. Top-down theorists argue that the direction of causal\nexplanation is from the belief to the experience. Notice that not\neverybody finds the distinction useful. For instance, Hohwy and\nRosenberg (2005) and Hohwy (2004) argue that the distinction loses its\nappeal in the framework proposed by prediction-error theorists given\nthat delusion formation involves both bottom-up and top-down\nprocesses. A person’s prior expectations affect the way in which the\nperceptual signals are processed and give rise to unusual\nexperiences. Then, the unusual experiences go through reality testing\nand are subject to further interpretation, after which they become a\ncentral factor in the formation of the delusional belief.  \n\nFor bottom-up theorists, delusions involve modifications of the belief\nsystem that are caused by ‘strange experiences’ due to\norganic malfunction (Bayne and Pacherie 2004a; Davies et\nal. 2001). For instance, I experience people watching me with\nsuspicion or hostility, and as a result I form the hypothesis that\nthey want to harm me; or something does not feel right when I see my\nsister’s face, and as a result I come to believe that the person I am\nlooking at is not really my sister but an impostor. \n\nWhat would top-down theorists say about the same examples? I believe\nthat people want to harm me, and as a result I perceive them as\nlooking at me malevolently; or I believe that someone looking almost\nidentical to my sister has replaced her, and as a result the person\nclaiming to be my sister doesn’t look to me as my sister does. The\ntop-down thesis about delusion formation has been proposed especially\nfor monothematic delusions such as Capgras (Campbell 2001; Eilan 2000)\nand for delusions of passivity, when people report that there are\nexternal influences on their thoughts and actions (Sass 1994; Graham\nand Stephens 1994; Stephens and Graham 2000). \n\nBoth bottom-up and top-down\ntheories face challenges: whereas top-down theorists need to account for where the\nbelief comes from, and why it is so successful in affecting perceptual\nexperiences, bottom-up theorists are pressed to explain why people tend\nto endorse a bizarre hypothesis to explain their unusual experiences,\ngiven that hypotheses with higher probability should be available to\nthem. \n\nWithin the bottom-up camp, further divisions apply. For some, it is\ncorrect to say that the delusional belief explains the\nexperience. Others claim that the delusion is an endorsement\nof the experience. According to the explanationist account (Maher 1999;\nStone and Young 1997), the content of experience is vaguer than the\ncontent of the delusion, and the delusion plays the role of one\npotential explanation for the experience. For instance, in the Capgras\ndelusion, the experience would be that of someone looking very much\nlike my sister but not being my sister. The delusion would be an\nexplanation of the fact that the woman looks like my sister, but her\nface feels strange to me: the woman must be an impostor. In persecution, the\nexperience would be that of some people as being hostile, and the\ndelusion would be an explanation why they seem hostile: they have an\nintention to harm me. This account leaves it open that the same\nexperience could have been explained differently (i.e., without any\nappeal to the delusional hypothesis). \n\nAccording to the rival account, the endorsement account (Bayne and\nPacherie 2004a; Pacherie et al. 2006), the content of the\nexperience is already as conceptually rich as the content of the\ndelusion. The delusion is not an explanation of the experience, but an\nendorsement of it: the content of the experience is taken as veridical\nand believed. In Capgras, the experience is that of a woman looking\nvery much like my sister but being an impostor, and when the experience\nis endorsed, it becomes the delusional belief that my sister has been\nreplaced by an impostor. In persecution, the experience is that of\npeople having an intention to harm me, and when it is endorsed, it\nbecomes the delusional belief that those people want to harm me. \n\nBoth versions of the bottom-up theory seem to imply that the\ndelusion starts with a conscious experience, or better, with an\nexperience whose content is available to a person as something to be\nexplained or to be endorsed. But Coltheart (2005b) suggests instead\nthat in the typical case the process of delusion formation starts with\nan event that a person is not aware of, such as the absence of an\nautonomic response. \n\nIf the delusional belief comes from the experience, why is the\ndelusional hypothesis preferred to more probable and plausible\nhypotheses (in the explanationist language), or why is the content of the\nexperience endorsed in spite of low probability and plausibility (in\nthe language of the endorsement account)? There are several replies\nto this objection in the literature, which have given rise to \ncompeting theories of delusion formation. Bottom-up theorists can be\ndivided in those who think that the unusual experience is sufficient\nfor the formation of the delusion (one-factor theorists), and\nthose who think that the unusual experience is only one factor in the\nformation of the delusion (two-factor theorists). \n\nFor some one-factor theorists (Maher 1974), the delusion is a\nreasonable hypothesis given the strangeness of the\nexperience, or the strange experience is in a sensory modality or at a\nprocessing stage where further reality testing is not available (Hohwy\nand Rosenberg 2005). But other one-factor theorists (e.g. Gerrans\n2002a) argue that, although it may be reasonable to articulate a\ndelusional hypothesis, it is not rational to maintain it in the face\nof counterevidence. For two-factor theorists (Davies et\nal. 2001; Stone and Young 1997), the delusion is formed in order\nto explain a puzzling experience or a failed prediction, but the\npresence of the experience or the failed prediction is not sufficient\nfor the formation of the delusion. The mechanism responsible for the\nformulation of the delusional hypothesis must be affected by reasoning\nbiases or deficits. Recent developments of this theory have been\noffered by Aimola Davies and Davies 2009, by Coltheart et\nal. 2010, and by Davies and Egan 2013.   Thus, there are three main positions as to whether reasoning is\nimpaired in people with delusions: (1) it is not impaired at all or\nthe apparent impairment is due to a performance error rather than to a\nlimitation of reasoning competence; (2) it is impaired due to a\nhypothesis evaluation deficit, and possibly reasoning biases; (3) it\nis impaired due to reasoning biases only. Although the predominance of\ncertain reasoning styles and the presence of reasoning biases in\npeople with delusions have been studied extensively, the available\nevidence does not seem to clearly prioritise one of the three options\nabove. It is difficult at this stage of theoretical development to\nestablish whether a certain reasoning “mistake” is due to\na failure of competence or a failure of performance, or to specify\nexactly what processes are involved in the hypothesis evaluation\nsystem. \n\nBy reference to monothematic delusions, Max Coltheart explains the\ntwo main factors involved in the formation of delusions as follows: \n\nIn Davies et al. (2001) and Coltheart (2007), factor two is\ndescribed in more details. First there is the generation of a\nhypothesis which serves as an explanation of the experience or an endorsement\nof the content of the experience. Second, there is a failure in\nrejecting the hypothesis, even when it is not supported by the\navailable evidence and it is implausible given the person’s\nbackground beliefs—such a failure is probably due to frontal\nright hemisphere damage. Finally the hypothesis is accepted, attended\nto and reported, and can be subject to further (personal-level)\nevaluation when counterevidence emerges. When it is endorsed, the\nhypothesis is regarded as more plausible, more probable, and more\nexplanatory than relevant alternatives. This influential account of the\nneuropsychology of delusions appeals to general mechanisms of belief\nformation, namely hypothesis generation and evaluation, and is\ncompatible both with the view that people with delusions have\n‘non-optimal hypothesis-testing strategies’ (Kihlstrom and\nHoyt 1988, p. 96) and with the thesis that these sub-optimal\nstrategies may be caused by damage to the right hemisphere\n(Ramachandran and Blakeslee 1998) which would be responsible for\nexamining the fit between hypothesis and reality. \n\nA similar story is told for polythematic delusions, self-deception,\nand delusion- and confabulation-like episodes in the normal population,\nalthough in such cases a single deficit could be at the origin of the\nreported belief (see McKay et al. 2005a). Experiential\ninformation is misinterpreted due to attentional or data-gathering\nbiases that affect the generation of hypotheses or to powerful\nmotivational factors. \n\nThe prediction-error theory of delusion formation differs from the\ntwo-factor account in that it is not wedded to the doxastic nature of\ndelusions and it focuses on the similarities between delusions and\nperceptual illusions (Hohwy 2012, 2013). There need be no specific\nreasoning deficit which contributes to the formation of the delusion,\nbut a disruption in the coding of the prediction error, which causes\naccurate beliefs to be revised, with the result that they become\ninaccurate. The choice between 1-factor and 2-factor theories depends\non a sharp distinction between perception and reasoning.  The\npredictive error approach to delusions assumes an architecture on\nwhich this distinction is harder to draw, since even the most\nparadigmatically perceptual processing draws on predictions.  \n\nThis section focuses on three debates that have animated the\nphilosophical literature on delusions in recent years. They can all be\nseen as attempts to examine the extent to which the reasoning patterns\nand styles exhibited by people with delusions are continuous with\nthose exhibited by people who have no known pathology of\ncognition. \n\nThere is no doubt that the definitions of delusions in DSM-IV and\nDSM-5 characterise delusions as irrational beliefs. However, in the\nphilosophical literature on delusions, the status of delusions as\nirrational beliefs does not go unchallenged. Are delusions really\nirrational? \n\nIn a number of influential papers Brendan Maher (1974, 1988, 1999,\n2003) argues that delusions are not ill-formed beliefs, and that there\nis nothing irrational in the relationship between the evidence\nsupporting the delusional hypothesis and the formation of such a\nhypothesis. According to Maher, the abnormality of the delusion is\nentirely due to the abnormality of the experiences on the basis of\nwhich the delusion is formed. By reference to Maher’s model,\nBlaney (1999) describes delusions as ‘false but\nreasonable’. Some difficulties have been identified with this\nstrategy. A first difficulty is that there seem to be people who suffer\nfrom the same type of brain damage, and plausibly have the same\nexperience, as the people who develop the delusion, but do not accept\nany delusional hypotheses. How can these people avoid forming a\ndelusion? One possible answer is that those who have strange\nexperiences and do not form the delusion have hypothesis-evaluation\nmechanisms that work efficiently, and thus end up rejecting hypotheses\nwith low probability and plausibility. But those who have strange\nexperiences and do form the delusion are instead affected by an\nadditional problem, a deficit at the level of hypothesis evaluation,\nwhich can be conceived as a failure of rationality. \n\nAnother difficulty with Maher’s original account of delusions\nas ‘false but reasonable’ is that, even if the abnormality\nof the experience were to satisfactorily explain the acceptance of the\ndelusional hypothesis and the formation of the delusion, this would not\nbe sufficient to guarantee that the behavior of people with delusions\nis overall rational. We would still have to explain why delusions are\nmaintained in the face of counterevidence once the delusional\nhypothesis has been formed and endorsed (see Gerrans 2002a). One aspect\nof the notion of rationality for beliefs is that people are disposed to\nrevise or abandon beliefs that seem to be in conflict with the acquired\nevidence. The “incorrigibility” of delusions speaks in\nfavor of their being held irrationally. \n\nLet’s concede that maintaining delusions (if not forming them)\nis irrational. Which norms of rationality are violated by the obstinate\nattachment to a delusional hypothesis? One norm that does seem to be\ninfringed by delusions is consistency, where this is intended both as\nconsistency between the delusion and the person’s other beliefs,\nand consistency between the delusion and the person’s\nbehavior. \nRationality is a normative constraint of consistency and coherence\non the formation of a set of beliefs and thus is prima facie violated\nin two ways by the delusional subject. First she accepts a belief that\nis incoherent with the rest of her beliefs, and secondly she refuses to\nmodify that belief in the face of fairly conclusive counterevidence and\na set of background beliefs that contradict the delusional belief\n(Gerrans 2000, p. 114). \n\nDelusions do not seem to respect the idea that the belief system\nforms a coherent whole and that adjustments to one belief will require\nadjustments to many others (Young 2000, p. 49). \n\nIn the course of the same interview, a woman may claim that her\nhusband died four years earlier and was cremated and that her husband\nis a patient in the same hospital where she is (Breen et al.\n2000, p. 91). In Capgras delusion, people may worry about the\ndisappearance of their loved one, but also be cooperative and even\nflirtatious with the alleged impostor (see Lucchelli and Spinnler\n2007). This suggests that delusions do not always give rise to\nappropriate action (Bleuler 1950; Sass 2001), although they must be\nreported either spontaneously or after questioning, or they could not\nbe diagnosed as delusions. How can we square people’s apparent strong\nconviction in the content of the delusion with their failure to act on\nit? One hypothesis is that the content of the delusion is not\ngenuinely believed. Another hypothesis is that the content of the\ndelusion is genuinely believed but not coverted into action, because\nthe person fails to acquire or maintain the motivation to act (this\nwould be consistent with negative symptoms of schizophrenia, see\nBortolotti and Broome 2012).   One should not be too impressed by ‘behavioural\ninertia’ in people with delusions, as there are many examples of\npeople acting on their delusions. Affected by perceptual delusional\nbicephaly, the delusion that one has two heads, a man who believed\nthat the second head belonged to his wife’s gynecologist attempted to\nattack it with an axe. When the attack failed he attempted it to shoot\nit down—as a consequence he was hospitalized with gunshot\nwounds (Ames 1984). Cases of Cotard delusion have been reported where\npeople stop eating and bathing themselves as a consequence of\nbelieving that they are dead (Young and Leafhead 1996). \n\nOther possible violations of norms of rationality come from the\nrelationship between the content of the delusion and the available\nevidence. Resistance to revising or abandoning the delusion in the face\nof powerful counterevidence or counterargument is a sign of\nirrationality in normal and abnormal cognition alike: people with\ndelusions ignore relevant evidence or attempt to defend their beliefs\nfrom apparent objections with obvious confabulations. Often these\nattempts are deeply perplexing, as the reasons offered for believing in\nthe content of their delusions do not seem to be good reasons: in one\nof the examples of delusions offered at the start, a woman\nincorrectly believed that a man was in love with her and claimed that\nhe was sending her secret love messages hidden in the license plates on\ncars of a certain state. \n\nThus, delusions may be inconsistent with a person’s beliefs\nand behavior, are typically unresponsive to both counterevidence and\ncounterargument, and are often defended by weak evidence or argument.\nThe empirical literature suggests\nthat the reasoning performance of people with delusions reflects\ndata-gathering and attribution biases. For instance, it has been argued\nthat people with delusions ‘jump to conclusions’; they need\nless evidence to be convinced that a hypothesis is true (Garety 1991;\nHuq et al. 1988; Garety and Freeman 1999), and are more hasty\nin their decisions (Moritz and Woodward 2005; Fine et al.\n2007). Other biases have also been noted: people with delusions of\npersecution tend to attribute the responsibility of negative events to\nother people (e.g., McKay et al. 2005b); in the Cotard\ndelusion there seems to be a tendency to attribute the responsibility\nof negative events to oneself (Young and Leafhead 1996; Gerrans 2000;\nMcKay and Cipolotti 2007). There are further studies suggesting that\npeople with delusions are worse than controls at inhibiting the\nevidence of their senses when it conflicts with other things they know\n(Langdon et al. 2008b) and that they have an accentuated need\nfor closure which comprises a desire for clarity and structure (see\nKruglanski 1989, p. 14). These data are not by themselves sufficient to\nsupport the view that delusions are irrational, but show interesting\ndeviations from statistically normal performance in the behavior of\npeople with delusions. \n\nA very recent debate relevant to the rationality of delusions concerns\nthe step from abnormal data gathered via perception and the delusional\nbelief. (This is primarily an issue that emerged among two-factor\ntheorists, so the language used below is acceptable to them, but the\nproblem can be reformulated in terms that are friendly to\nprediction-error theorists.) Coltheart et al. 2010 argue that\nthe step from abnormal data to belief is an instance of abductive\ninference, as those who end up endorsing a delusional belief need to\nselect an explanatory hypothesis for their abnormal data from a range\nof relevant hypotheses. Coltheart and colleagues use the Bayesian\nmodel of abductive inference which invites us to ask two questions:\nWhich hypothesis better explains the data? Which hypothesis is the\nmost plausible given what we already know? In the case of delusions,\nthey argue, it is reasonable to adopt the delusional hypothesis given\nthe data, and the good fit between hypothesis and data swamps general\nconsiderations about the overall implausibility of the\nhypothesis. What may not be reasonable is the fact that people with\ndelusions hang onto their delusions even when they keep gathering\nevidence against it—that is, the delusional belief is not\ncorrectly updated in the light of new information. The authors argue\nthat the information undermining the delusional hypothesis does not\npresent itself as disconfirming evidence to the person with the\ndelusion. Thus, the new evidence is interpreted in the light of the\ndelusion and confabulation is used to fill the gaps. The behaviour of\nthe person with the delusion is not very different from that of an\nobstinate scientist refusing to see the new data as undermining the\nsupport for the theory she proposed and she is now deeply committed\nto.  \nMcKay 2012 offers some criticism of the account by Coltheart and\ncolleagues, and raises the following points among others: (1) it is\nnot a perfectly rational response to adopt the delusional hypothesis\nas an explanation for the abnormal data, unless the probability of the\ndelusional hypothesis before any abnormal data is gathered is very\nhigh, and this is implausible given the content of some delusional\nhypotheses (“my wife has been replaced by an almost identical\nimpostor”); (2) factor two as described by Coltheart and colleagues\n(i.e., a failure to update a belief in the light of conflicting\nevidence) cannot precede factor one or be acquired at the same time as\nfactor one, because such a form of conservatism would prevent the\nperson from adopting the delusional hypothesis in the first\nplace. McKay’s positive account is that factor two is not a bias\ntowards conservatism (which causes new data conflicting with the\ndelusional hypothesis to be discounted), but a bias towards\nexplanatory adequacy (which causes the delusional hypothesis\nto be adopted and maintained because it fits the abnormal data so\nwell). McKay also argues that his account is compatible with\nprediction-error theories of delusion formation: \nThe debate is reviewed by Davies and Egan (2013) who helpfully focus\non the distinction between the adoption and the maintenance of the\ndelusional hypothesis and argue that there is no need to postulate an\nadditional reason why people hang on to their delusions (a bias\ntowards conservatism or empirical adequacy). Once the delusional\nhypothesis is adopted as an explanation for or an endorsement of the\nabnormal data, it is normatively correct from a Bayesian point of view\nthat it will not be updated or revised for conflicting with previous\nbeliefs. New evidence would be necessary to prompt an update or a\nrevision. That said, critical evaluation of the delusional hypothesis\nafter adoption can still occur if we consider that the delusional\nbelief was formed as prepotent doxastic response to abnormal data and\nthus it is likely to be compartmentalised. In a fragmented belief\nsystem, it could be the case that the compartmentalised belief is\nassessed on the basis of previous beliefs.  The debate described above (in a very simplified way) is an\nattempt to specify what the second factor is in a two-factor account\nof delusion formation. However, as Davies and Egan themselves\nacknowledge, the application of idealised models of inference such as\nBayesianism is somehow limited when we are considering actual belief\nsystems. Even when no pathology is present, biases affecting the\nadoption and evaluation of hypotheses are going to be the\n(statistical) norm, which makes it difficult to uniquely identify the\nproblem with the adoption and the persistence of delusional\nbeliefs. \n\nAlthough delusions can be irrational to a higher degree than normal\nbeliefs, as they may be less consistent with a person’s other beliefs\nand actions and more resistant to counterevidence, they do not seem to\nbe irrational in a qualitatively different way from normal\nbeliefs. This would suggest that they are continuous with irrational\nbeliefs, although (as we shall see in the next section) there exist\nsophisticated philosophical arguments challenging the continuity\nclaim. \n\nAccording to the doxastic conception of delusions (dominant among\npsychologists and psychiatrists), delusions are belief \nstates—it is an important diagnostic features of delusions that they can lead\nto action and that they can be reported with conviction, and\nthus that they behave as typical beliefs. (See the entry on \n  belief.)  But there is an increasing\ninfluential view in philosophy warning that the doxastic\ncharacterization of delusions would lead to an oversimplification of\nthe phenomenon. Although some of the alternative accounts of delusions\n(e.g., experiential, phenomenological and metarepresentational) are\ncritical towards standard doxastic conceptions, they do not necessarily\ndeny that the phenomenon of delusions involves the formation of normal\nor abnormal beliefs. Rather, the central idea seems to be that, even\nif people with delusions report false or irrational beliefs, paying\nattention only to their first-order cognitive states and to the\ndoxastic dimension of their pathology can lead to a partial and\nincorrect view of the phenomenon of delusions (see also Radden\n2010). \n\nSome authors emphasize the experiential and\nphenomenological character of delusions over the doxastic one\n(e.g., Sass 1994; Gold and Hohwy 2000), and others conceive of delusions\nnot as mere representations of a person’s experienced reality,\nbut as attitudes towards representations (e.g., Currie 2000; Currie and\nJureidini 2001; Stephens and Graham 2006). Gallagher 2009 argues that\nan explanation of the delusion as a mere cognitive error would be\ninadequate, and introduces the terminology of delusional\nrealities, modes of experience which involve shifts in familiarity\nand sense of reality and encompass cognition, bodily changes, affect,\nsocial and environmental factors. \n\nMost of the authors who deny belief status to delusions have a\nnegative and a positive thesis. The positive thesis is an alternative\naccount of what delusions are. For instance, one might argue that\ndelusions are acts of imagination mistakenly taken by a person to have\nbelief status (Currie and Ravenscroft 2002) or empty speech acts with\nno intentional import (Berrios 1991). The negative thesis is an account\nof why delusions are not beliefs. Beliefs have certain characteristics,\nthat is, they are formed and revised on the basis of evidence, they are\nconsistent with other beliefs, they are action guiding in the relevant\ncircumstances. If delusions do not share these characteristics, then\nthey are not beliefs. Let us list some of the arguments for the negative thesis: \n\nThese arguments are central to the debate about the doxastic nature\nof delusions (Bortolotti 2009). For instance, Currie and Jureidini\n(2001, p. 161) argue that delusions are more plausibly imaginings than\nbeliefs, because delusions ‘fail, sometimes spectacularly, to be\nintegrated with what the subject really does believe’, whereas\nthere is no requirement that imaginings are consistent with what the\nperson believes. Berrios (1991) argues that delusions cannot be\nbeliefs, because, as explanations for an abnormal experience, they are\nnot regarded even by the person reporting them as more probable than\nalternative explanations of the experience. Berrios reaches the\nextraordinary conclusions that delusions are not even intentional\nstates, but utterances without meaning, “empty speech\nacts”. \n\nAssessing arguments in (1) to (3) requires assessing empirical and\nconceptual claims. Let’s consider (1), the ‘bad\nintegration’ objection to the belief status of delusions. In\norder to see whether the conclusion is convincing, we need to examine\nan empirical claim about delusions first: Do delusions really fail to\nintegrate with a person’s beliefs? Then, we need to assess a\nconceptual claim, the claim that not being integrated with a\nperson’s beliefs prevents delusions from being beliefs at all. In\nmany cases, we shall find that the alleged ‘fault’ of\ndelusions has been exaggerated (e.g., delusions sometimes integrate\nwell with beliefs), but that it is correct to claim that delusions\nexhibit that mark of irrationality (bad integration) to a higher degree\nthan ordinary beliefs. \n\nThe most common versions of anti-doxastic arguments seem to rely on\nan idealization of normal belief states, and impose constraints on\ndelusions that typical beliefs would not meet. The assumption seems to\nbe that beliefs are essentially rational, and that delusions are not\nbeliefs because they are not rational. But the abundant psychological\nevidence on familiar irrationality tells us that ordinary beliefs are\noften irrational in exactly the same way as delusions can be—although \nto a lesser degree. It is sufficient to think about hypocrisy,\nabout prejudiced and superstitious beliefs, and about the many biases\nthat affect belief updating in normal cognition to realize that the\nsame kinds of irrationality that we find in delusions are also common\nin many ordinary beliefs (e.g., Nisbett and Ross 1980). For the\ndoxastic conception of delusions, the greatest challenge is to provide\na satisfactory reply to the double-bookkeeping objection: if people\ntruly believe the content of their delusions, why is their behavior\noften inconsistent with it? Aren’t beliefs distinct from other\nintentional states in virtue of their action-guiding character? A more\ngeneral worry is that the very notion of belief is not theoretically\nuseful if the criteria for what counts as a belief become too\nloose. \n\nIndependent of any given answer to the question whether delusions\nare beliefs, two opposed conceptions of delusions contend the\nphilosophical scene. One highlights the discontinuity between delusions\nand beliefs, and between normal and abnormal cognition, with\nconsequences for the conceptualization of the disorder, but also for\nthe availability of therapeutic options, such as cognitive behavioral\ntherapy, to people with delusions. The other view insists that there is\ncontinuity between delusions and beliefs, and attempts to gather data\nboth suggesting that people with delusions can reason in much the same\nway as people without, and that delusion-like ideas are widespread in\nthe normal population. Bentall 2003, for instance, gathered a vast\namount of empirical data about the temporal variations in delusions\nreported by people affected by psychopathologies, and the presence of\ndelusion-like beliefs in the normal population. \n\nThere is no consensus on whether self deception and delusion\nsignificantly overlap. Self deception has been traditionally\ncharacterized as driven by motivational factors. Delusions are now\nprimarily accounted in neurobiological terms, and theories of delusion\nformation involve reference to perceptual and cognitive impairments.\nHowever, motivational factors can still play an important role in the\nexplanation of some delusions, for instance by partially determining\nthe specific content of the reported delusional state. Thus, one\nplausible view is that self-deception and delusion are distinct\nphenomena that may overlap in some circumstances (for further analysis,\nsee Bayne and Fernàndez 2008). There are three arguments for the\nview that delusions and self-deception can overlap. \n\nThe first view about the relationship between delusions and\nself-deception is that, when they overlap, they do so because they both\ninvolve a motivationally biased treatment of evidence. If we agree with\ndeflationists that the motivationally biased treatment of the evidence\nis the key feature of self-deception (Mele 2001 and 2008), then people\nwith delusions can be said to be self-deceived if they treat the\nevidence at their disposal in a motivationally biased way, or if they\nsearch for evidence in a motivationally biased way. This does not seem\nto be generally the case, but it is useful to distinguish between\ndifferent types of delusions. Some delusions of misidentification (at\nleast according to neuropsychological accounts) do not seem to be akin\nto self-deception, given that there is no fundamental role for\nmotivational biases in the explanation of how a person comes to hold or\nretain the delusion. A different analysis might be appropriate for\nother delusions, such as delusions of jealousy or persecution. \n\nThe second view is that (some) delusions are extreme cases of\nself-deception and that they have a protective and adaptive\nfunction (see Hirstein 2005). An example is offered by Ramachandran,\nwho discusses anosognosia, the denial of illness, and\nsomatoparaphrenia, the delusion that a part of one’s body belongs\nto someone else. Ramachandran (1996) reports the case of a woman (FD)\nwho suffered from a right hemisphere stroke which left her with left\nhemiplegia. FD could not move without a wheelchair and could not move\nher left arm. But when she was asked whether she could walk and she\ncould engage in activities which require both hands (such as clapping),\nshe claimed that she could. Ramachandran advances the hypothesis that\nbehaviors giving rise to confabulations and delusions are an\nexaggeration of normal defense mechanisms that have an adaptive\nfunction, as they allow us to create a coherent system of beliefs and\nto behave in a stable manner. In normal subjects, the left hemisphere\nproduces confabulatory explanations aimed at preserving the status\nquo (‘I’m not ill’; ‘My arm can\nmove’), but the right hemisphere does its job and detects an\nanomaly between the hypotheses generated by the left hemisphere and\nreality. So, it forces a revision of the belief system. In patients\nsuch as FD, the discrepancy detector no longer works. It is very\nplausible that the delusions reported by people with anosognosia\ninvolve motivational aspects. But whether we believe that these\ndelusions are an exaggerated form of self-deception depends on the\npreferred theoretical characterization of self-deception. \n\nThe third view about the potential overlap of delusions and\nself-deception is that the very existence of delusions (which\nshows that doxastic conflict is possible) can help us vindicate the\ntraditional account of self-deception, according to which a person has\ntwo contradictory beliefs, but she is aware of only one of them,\nbecause she is motivated to remain unaware of the other (McKay et\nal. 2005a, p. 314). This account derives from Donald\nDavidson’s theory of self-deception (e.g. Davidson 1982 and\n1985b). When I deceive myself, I believe a true proposition but act in\nsuch a way as to causing myself to believe the negation of that\nproposition. Neil Levy argues that the conditions for self-deception\nset by the traditional approach are not necessary for self-deception,\nbut that the case of FD described by Ramachandran (1996) is living\nproof that a person can, at the same time, believe that her arm is\nparalyzed, and believe that she can move her arm. Moreover, it is the\nbelief that her arm is paralyzed that causes her to acquire the belief\nthat her arm is not. This is Levy’s analysis of the typical\nperson with anosognosia Levy (2008, p. 234): \n\nIf this analysis is correct, at least one case of delusion (e.g.,\nanosognosia) involves doxastic conflict. The most controversial aspect\nof this analysis concerns condition (2). Is the belief that their limb\nis impaired truly available to people affected by anosognosia? One\ncould argue that, given that they probably have a deficit in the\ndiscrepancy detector of the right hemisphere of the brain, they have no\nawareness of the impairment they deny (see also Hirstein 2005). But\nLevy’s reply is that availability comes in degrees. He suggests\nthat, given that people with paralysis and anosognosia often avoid\ntasks that would require mobility when costs for failure are high, and\ngiven that they can acknowledge some difficulties in movement (and say\n‘I have arthritis’ or ‘My left arm has always been\nweaker’), it is plausible that they have some awareness of their\nimpairment—although they may lack a fully formed and conscious\nbelief about it. \n\nThe debate about the differences between delusion and\nself-deception has centred on whether delusions (just like ordinary\ninstances of self-deception) are explicable from a folk-psychological\npoint of view (Bortolotti and Mameli 2012; Murphy 2012, 2013). Murphy\nargues that we diagnose delusions when folk psychology runs out of\nresources for understanding what someone seems to report as a genuine\nbelief. By contrast, self-deception does not challenge our\nfolk-psychological generalisations, because we expect people’s beliefs\nto be influenced by their desires at least on some occasions (e.g.,\nwhen stakes are high). Bortolotti and Mameli maintain that the gap\nbetween self-deception and motivated delusions (such as anosognosia)\nis narrower than the gap between self-deception and apparently\nnon-motivated delusions, but even in the latter case folk psychology\ncan account for the delusional belief as an explanation (irrational as\nit may be) of the delusional experience.  \nIn sum, the views summarized here show that it can be very difficult\nto justify clear-cut distinctions between delusion and\nself-deception. It is diagnostically and scientifically useful to\nmaintain a distinction between symptoms of conditions such as amnesia,\ndementia, or schizophrenia, and the irrational beliefs that\ncharacterize normal cognition, but one should acknowledge that there\nare also many elements of genuine overlap. ","contact.mail":"l.bortolotti@bham.ac.uk","contact.domain":"bham.ac.uk"}]
