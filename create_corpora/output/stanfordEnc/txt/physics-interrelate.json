[{"date.published":"2001-01-02","date.changed":"2016-07-18","url":"https://plato.stanford.edu/entries/physics-interrelate/","author1":"Robert Batterman","entry":"physics-interrelate","body.text":"\n\n\n\nMany issues in the philosophy of science concern the nature of theories\nand certain relations that may obtain between them. Typically, one is\ninterested in the degree to which a successor to a given theory “goes\nbeyond” (both descriptively and explanatorily) the theory it succeeds.\nMost often these issues are framed in the context of reductive\nrelations between theories. When does a theory \\(T'\\) reduce\nto a theory \\(T\\)? How is one to understand the nature of this\nreduction relation? Interestingly, there are two distinct, yet, related\nways of understanding the reductive relationship between \\(T\\) and\n\\(T'\\). Thomas Nickles noted this in a paper entitled “Two\nConcepts of Intertheoretic Reduction.” On the one hand, there is the\n“philosopher’s” sense of reduction on which the supplanted theory is\nsaid to reduce to the newer more encompassing theory. On the other\nhand, the “physicist’s” sense of reduction puts things the other way.\nThe newer, typically more refined theory is said to reduce to the older\ntypically less encompassing theory in some sort of limit. These two\nsenses of reduction will be discussed in turn. \n\n\n\nMost contemporary discussions of reductive relations between a pair of\ntheories owe considerable debt to the work by Ernest Nagel. In The\nStructure of Science, Nagel asserts that “[r]eduction … is the\nexplanation of a theory or a set of experimental laws established in\none area of inquiry, by a theory usually though not invariably\nformulated for some other domain.” (Nagel 1961, 338) The general\nschema here is as follows:  \n\nShowing how these derivations are possible for “paradigm” examples\nof intertheoretic reduction turns out to be rather difficult. \n\nNagel distinguishes two types of reductions on the basis of whether\nor not the vocabulary of the reduced theory is a subset of the reducing\ntheory. If it is—that is, if the reduced theory \\(T'\\)\ncontains no descriptive terms not contained in the reducing theory\n\\(T\\), and the terms of \\(T'\\) are understood to have\napproximately the same meanings that they have in \\(T\\), then\nNagel calls the reduction of \\(T'\\) by \\(T\\)\n“homogeneous.” In this case, while the reduction may very well be\nenlightening in various respects, and is part of the “normal\ndevelopment of a science,” most people believe that there is nothing\nterribly special or interesting from a philosophical point of view\ngoing on here. (Nagel 1961, 339.) \n\nLawrence Sklar (1967, 110–111) points out that, from a\nhistorical perspective, this attitude is somewhat naive. The number of\nactual cases in the history of science where a genuine homogeneous\nreduction takes place are few and far between. Nagel, himself, took as\na paradigm example of homogeneous reduction, the reduction of the\nGalilean laws of falling bodies to Newtonian mechanics. But, as Sklar\npoints out, what actually can be derived from the Newtonian theory are\napproximations to the laws of the reduced Galilean theory. The\napproximations, of course, are strictly speaking incompatible\nwith the actual laws and so, despite the fact that no concepts appear\nin the Galilean theory that do not also appear in the Newtonian theory,\nthere is no deductive derivation of the laws of the one from\nthe laws of the other. Hence, strictly speaking, there is no\nreduction on the deductive Nagelian model. \n\nOne way out of this problem for the proponent of Nagel-type\nreductions is to make a distinction between explaining a theory (or\nexplaining the laws of a given theory) and explaining it away. (Sklar\n1967, 112–113) Thus, we may still speak of reduction if the\nderivation of the approximations to the reduced theory’s laws serves to\naccount for why the reduced theory works as well as it does in its\n(perhaps more limited) domain of applicability. This is consonant with\nmore sophisticated versions of Nagel-type reductions in which part of\nthe very process of reduction involves revisions to the reduced theory.\nThis process arises as a natural consequence of trying to deal with\nwhat Nagel calls “heterogeneous” reductions. \n\nThe task of characterizing reduction is more involved when the\nreduction is heterogeneous—that is, when the reduced theory\ncontains terms or concepts that do not appear in the reducing theory.\nNagel takes, as a paradigm example of heterogeneous reduction, the\n(apparent) reduction of thermodynamics, or at least some parts of\nthermodynamics, to statistical\n mechanics.[1]\n For instance, thermodynamics contains the concept of temperature\n(among others) that is lacking in the reducing theory of statistical\nmechanics. \n\nNagel notes that “if the laws of the secondary science [the reduced\ntheory] contain terms that do not occur in the theoretical assumptions\nof the primary discipline [the reducing theory] … , the logical\nderivation of the former from the latter is prima facie\nimpossible.” (Nagel 1961, 352) As a consequence, Nagel introduces\ntwo “necessary formal conditions” required for the reduction to take\nplace: \n\nThe connectability condition brings with it a number of interpretive\nproblems. Exactly what is, or should be, the status of the “suitable\nrelations,” often called bridge “laws” or bridge hypotheses? Are they\nestablished by linguistic investigation alone? Are they factual\ndiscoveries? If the latter, what sort of necessity do they involve? Are\nthey identity relations that are contingently necessary or will some\nsort of weaker relation, such as nomic coextensivity, suffice? Much of\nthe philosophical literature on reduction addresses these questions\nabout the status of the bridge\n laws.[2] \n\nThe consideration of certain examples lends plausibility to the\nidea, prevalent in the literature, that the bridge laws should be\nconsidered to express some kind of identity relation. For instance,\nSklar notes that the reduction of the “theory” of physical optics to\nthe theory of electromagnetic radiation proceeds by\nidentifying one class of entities — light waves —\nwith (part of) another class — electromagnetic radiation. He says\n“… the place of correlatory laws [bridge laws] is taken by\nempirically established identifications of two classes of\nentities. Light waves are not correlated with electromagnetic waves,\nfor they are electromagnetic waves.” (Sklar 1967, 120) In\nfact, if something like Nagelian reduction is going to work, it is\ngenerally accepted that the bridge laws should reflect the existence of\nsome kind of synthetic identity. \n\nKenneth Schaffner calls the bridge laws “reduction functions.” He\ntoo notes that they must be taken to reflect synthetic identities\nsince, at least initially, they require empirical support for their\njustification. “Genes were not discovered to be DNA via the analysis of\nmeaning; important and difficult empirical research was\nrequired to make such an identification.” (Schaffner 1976, 614–615) \n\nNow one problem facing this sort of account was forcefully presented\nby Feyerabend in “Explanation, Reduction, and Empiricism.” (Feyerabend\n1962) Consider the term “temperature” as it functions in classical\nthermodynamics. This term is defined in terms of Carnot cycles and is\nrelated to the strict, nonstatistical second law as it appears in that\ntheory. The so-called reduction of classical thermodynamics to\nstatistical mechanics, however, fails to identify or associate\nnonstatistical features in the reducing theory, statistical\nmechanics, with the nonstatistical concept of temperature as it appears\nin the reduced theory. How can one have a genuine reduction, if terms\nwith their meanings fixed by the role they play in the reduced theory\nget identified with terms having entirely different meanings? Classical\nthermodynamics is not a statistical theory. The very possibility of\nfinding a reduction function or bridge law that captures the concept of\ntemperature and the strict, nonstatistical, role it plays in the\nthermodynamics seems impossible. \n\nThe plausibility of this argument, of course, depends on certain\nviews about how meaning accrues to theoretical terms in a theory.\nHowever, just by looking at the historical development of\nthermodynamics one thing seems fairly clear. Most physicists, now,\nwould accept the idea that our concept of temperature and our\nconception of other “exact” terms that appear in classical\nthermodynamics such as “entropy,” need to be modified in light of the\nalleged reduction to statistical mechanics. Textbooks, in fact,\ntypically speak of the theory of “statistical thermodynamics.” The very\nprocess of “reduction” often leads to a corrected version of the\nreduced theory. \n\nIn fact, Schaffner and others have developed sophisticated Nagelian\ntype schemas for reduction that explicitly try to capture these\nfeatures of actual theory change. The idea is explicitly to include in\nthe model, the “corrected reduced theory” such as statistical\nthermodynamics. Thus, Schaffner (1976, 618) holds that \\(T\\)\nreduces \\(T'\\) if and only if there is a corrected version\nof \\(T'\\), call it \\(T'^*\\) such that \n\nMuch work clearly is being done here by the intuitive conception of\n“strong analogy” between the reduced theory \\(T'\\) and the\ncorrected reduced theory \\(T'^*\\). In some cases, as\nsuggested by Nickles (1973) and Wimsatt (1976), the conception of\nstrong analogy may find further refinement by appeal to what was\nreferred to as the “physicist’s” sense of reduction. \n\nPhilosophical theories of reduction would have it that, say, quantum\nmechanics reduces classical mechanics through the derivation of the\nlaws of classical physics from those of quantum physics. Most\nphysicists would, on the other hand, speak of quantum mechanics\nreducing to classical mechanics in some kind of correspondence limit\n(e.g., the limit as Planck’s constant \\((h/2\\pi)\\) goes to zero).\nThus, the second type of intertheoretic reduction noted by Nickles fits\nthe following schema: \n\nHere \\(T_f\\) is the typically newer, more\nfine theory, \\(T_c\\) is the typically older,\ncoarser theory, and \\(\\varepsilon\\) is a fundamental parameter appearing in\n\\(T_f\\) . \n\nOne must take the equality here with a small grain of salt. In those\nsituations where Schema R can be said to hold, it is\nlikely not the case that every equation or formula from\n\\(T_f\\) will yield a corresponding equation of\n\\(T_c\\) . \n\nEven given this caveat, the equality in Schema R\ncan hold only if the limit is “regular.” In such circumstances, it can\nbe argued that it is appropriate to call the limiting relation a\n“reduction.” If the limit in Schema R is singular,\nhowever, the schema fails and it is best to talk simply about\nintertheoretic relations. \n\nOne should understand the difference between regular and singular\nlimiting relations as follows. If the solutions of the relevant\nformulae or equations of the theory \\(T_f\\) are\nsuch that for small values of \\(\\varepsilon\\) they smoothly approach\nthe solutions of the corresponding formulas in\n\\(T_c\\), then Schema R will\nhold. For these cases we can say that the “limiting behavior” as\n\\(\\varepsilon \\rightarrow 0\\) equals the “behavior in the limit” where\n\\(\\varepsilon = 0\\). On the other hand, if the behavior in the\nlimit is of a fundamentally different character than the\nnearby solutions one obtains as \\(\\varepsilon \\rightarrow 0\\), then the schema will\nfail. \n\nA nice example illustrating this distinction is the following:\nConsider the quadratic equation \\(x^2 + x - 9\\varepsilon = 0\\). Think of \\(\\varepsilon\\) as a small expansion or\nperturbation parameter. The equation has two roots for any value of\n\\(\\varepsilon\\) as \\(\\varepsilon \\rightarrow 0\\). In a well-defined sense, the solutions\nto this quadratic equation as \\(\\varepsilon \\rightarrow 0\\) smoothly approach\nsolutions to the “unperturbed” \\((\\varepsilon = 0)\\) equation\n\\(x^2 + x = 0\\); namely, \\(x = 0, -1\\). On the other hand, the equation\n\\(x^2\\varepsilon + x - 9 = 0\\) has two\nroots for any value of \\(\\varepsilon \\gt 0\\) but has for its\n“unperturbed” solution only one root; namely, \\(x = 9\\). The\nequation suffers a reduction in order when \\(\\varepsilon = 0\\). Thus, the\ncharacter of the behavior in the limit \\(\\varepsilon = 0\\) differs\nfundamentally from the character of its limiting behavior. Not all\nsingular limits result from reductions in order of the equations.\nNevertheless, these latter singular cases are much more prevalent than\nthe former. \n\nA paradigm case where a limiting reduction of the form\n\\(\\mathbf{R}\\) rather straightforwardly holds is that of classical\nNewtonian particle mechanics (NM) and the special theory of relativity\n(SR). In the limit where \\((v/c)^2\\rightarrow 0\\), SR\nreduces to NM. Nickles says “epitomizing [the intertheoretic reduction\nof SR to NM] is the reduction of the Einsteinian formula for\nmomentum, \n\nwhere \\(m_0\\) is the rest mass, to the classical formula\n\\(p = m_0 v\\) in the limit as\n\\(v\\rightarrow 0\\).”[3]\n (Nickles 1973, 182)  \n\nThis is a regular limit—there are no singularities or\n“blowups” as the asymptotic limit is approached. As noted one way of\nthinking about this is that the exact solutions for small but nonzero\nvalues of \\(|\\varepsilon\\)| “smoothly [approach] the unperturbed or\nzeroth-order solution [\\(\\varepsilon\\) set identically equal to zero] as\n\\(\\varepsilon \\rightarrow 0\\).” In the case where the limit is singular\n“the exact solution for \\(\\varepsilon = 0\\) is fundamentally different in\ncharacter from the ‘neighboring’ solutions obtained in\nthe limit \\(\\varepsilon \\rightarrow 0\\).” (Bender and Orszag 1978, 324) \n\nIn the current context, one can express the regular nature of the\nlimiting relation in the following way. The fundamental expression\nappearing in the Lorentz transformations of SR, can be expanded in a\nTaylor series as \n\nand so the limit is analytic. This means that (at least some)\nquantities or expressions of SR can be written as Newtonian or\nclassical quantities plus an expansion of corrections in powers of\n\\((v/c)^2\\). So one may think of this\nrelationship between SR and NM as a regular perturbation\nproblem. \n\nExamples like this have led some investigators to think of limiting\nrelations as forming a kind of new rule of inference which would allow\none to more closely connect the physicists’ sense of reduction with\nthat of the philosophers’. Fritz Rohrlich, for example, has argued that\nNM reduces (in the philosophers’ sense) to SR because the\nmathematical framework of SR reduces (in the physicists’\nsense) to the mathematical framework of NM. The idea is that\nthe mathematical framework of NM is “rigorously derived” from that of\nSR in a “derivation which involves limiting procedures.” (Rohrlich\n1988, 303) Roughly speaking, for Rohrlich a “coarser” theory is\nreducible to a “finer” theory in the philosophers’ sense of being\nrigorously deduced from the latter just in case the mathematical\nframework of the finer theory reduces in the physicists’ sense to the\nmathematical framework of the coarser theory. In such cases, we will\nhave a systematic explication of the idea of “strong analogy” to which\nSchaffner appeals in his model of philosophical reduction. The\ncorrected theory \\(T'^*\\) in this context is the perturbed\nNewtonian theory as expressed in the Taylor expansion given above. The\n“strong analogy” between Newtonian theory \\(T'\\) and the\ncorrected \\(T'^*\\) is expressed by the existence of the\nregular Taylor series expansion. \n\nAs noted the trouble with maintaining that this relationship between\nthe philosophical and “physical” models of reduction holds generally is\nthat far more often than not the limiting relations between the\ntheories are singular and not regular. In such situations,\nSchema R fails to hold. Paradigm cases here include\nthe relationships between classical mechanics and quantum mechanics,\nthe ray theory of light and the wave theory, and thermodynamics and\nstatistical mechanics of systems in critical states. \n\nDespite the fact that limiting relations between theories may be\nsingular in this way, it is (at times) useful and appropriate to think\nof physical theories as forming a hierarchy related by length or\nenergy scales. The idea is that different theories may apply at\ndifferent length or energy scales. If one takes this idea seriously,\nthen it may very well be the case that each theory in this hierarchy\nwill be phenomenological relative to those theories at higher energies\nor shorter distances. Equivalently, such a hierarchy may form a tower\nof effective theories. An effective theory is one that\ndescribes the relevant phenomena in a circumscribed domain—a\ndomain characterized by a range of energies, for example. The idea of effective theories is not new. In the 19th century and\nearlier, scientists developed continuum equations such as the\nNavier-Cauchy equations describing the behavior of isotropic elastic\nsolids and the Navier-Stokes equations for incompressible viscous\nfluids. These equations were, and still are, remarkably safe. This\nmeans that once one inputs the appropriate values for a few\nphenomenological parameters (such as Young’s modulus and the sheer\nstress in the Navier-Cauchy equations), one arrives at equation models\nthat allow us to build bridges and buildings that do not collapse. It\nis remarkable that a theory/model that almost entirely fails\nto refer to the details of the atomic and molecular structure of a\nsteel beam, say, can be so successful and safe. A question of deep\nphilosophical interest concerns how this can be the case. The\nphenomenological parameters must encode at least some details about\nthe atomic and molecular make up of the beam. (Hence, the “almost” in\nthe statement above.)  \nHowever, this raised an important question: Can one tell a story\nbridging the models at the atomic scale and those at the continuum\nscale of centimeters and greater? Reductionists typically believe\nthat it is possible to connect, and presumably to derive, the\ncontinuum models starting from atomic scale details. There has been a\nbattle for two centuries, at least, between those who are persuaded that\nsuch a bottom-up story can be told, and those such as Duhem, Mach, and\nothers who have championed a top-down modeling strategies. In the 19th\ncentury this took the form of a heated dispute between so-called\nrari-constancy and multi-constancy theorists who, respectively, tried\nto determine the continuum equations from top-down (ignoring unknown\nmicro details) considerations, and theorists trying to determine the\ncontinuum equations with small scale atomic assumptions guiding the\nconstructions. In fact, surprisingly, the former\nprevailed. (Todhunter and Pearson 1960; Batterman 2012)  The debate between bottom-up, reductionist modelers and top-down,\ncontinuum modelers receives its modern presentation, at least in part,\nin the debates about the existence and nature of emergent phenomena.\nOne area of recent interest where this occurs is in our understanding\nof effective quantum field theories. In quantum field theory, for instance, there has been considerable\nsuccess in in showing how a theory appropriate for some range of\nenergy scales is related to a theory for another range via a process\nof renormalization (Bain 2012). Renormalization provides a kind of limiting\nrelationship between theories at different scales despite the fact\nthat the reductive Schema R typically fails because\nof divergences related to singular limits. The physics at one scale\nis relatively independent of that at some higher energy (shorter\nlength). In effect, renormalization is a mathematical scheme for\ncharacterizing how the structure of interactions changes with changing\nscale: it turns out that the domain characterized by some lower energy\n(or larger length) scale is surprisingly and remarkably decoupled from\nthat of higher energies (or smaller lengths). In other words, the\ndecoupling entails that the higher energy regime does not much effect\nthe behaviors and character of the lower energy regimes. \nNew work, more generally on the problem modeling systems at widely\ndifferent scales (10+ orders of magnitude), in nano chemistry and in\nmaterials science, brings some hope that the all-or-nothing dichotomy\nbetween reduction and emergence can be somewhat blunted. As noted, a\nquestion of real philosophical interest concerns how to understand the\nrelative autonomy of theories and models at large scales. (Why, again,\nare the continuum equations so safe for large scale modeling?)\nContemporary work in applied mathematics on so-called homogenization\ntheory is beginning to provide interesting connections across these\nwidely separated scales. (Torquato 2002; Phillips 2001) \nThe mathematics of renormalization is best understood as an instance\nof this general strategy for homogenization or upscaling. (Batterman\n2012) It is crucial for a contemporary understanding of relations\nbetween theories. It is fair to say, however, that being able to\nunderstand such intertheoretic relations via homogenization and\nrenormalization techniques does not entail the existence of reductive\nrelations between the theories either in the philosophers’ or\nthe physicists’ sense of the term. However, such an\nunderstanding may very well lead to a more nuanced and precise\ncharacterization of the debates about reduction and emergence. \n\nIt seems reasonable to expect something like philosophical\nreductions to be possible in those situations where Schema\nR holds. On the other hand, neither philosophical nor\n“physical” reduction seems possible when the limiting correspondence\nrelation between the theories is singular. Perhaps in such cases it is\nbest to speak simply of intertheoretic relations rather than\nreductions. It is here that much of philosophical and physical interest\nis to be found. This claim and the following discussion should not be\ntaken to be anything like the received view among philosophers of\nscience. Instead, they reflect the views of the author. \n\nNevertheless, here is a passage from a recent paper by Michael Berry\nwhich expresses a similar point of view. \nEven within physical science, reduction between different\nlevels of explanation is problematic—indeed, it is almost always\nso. Chemistry is supposed to have been reduced to quantum mechanics,\nyet people still argue over the basic question of how quantum\nmechanics can describe the shape of a molecule. The statistical\nmechanics of a fluid reduces to its thermodynamics in the limit of\ninfinitely many particles, yet that limit breaks down near the\ncritical point, where liquid and vapour merge, and where we never see\na continuum no matter how distantly we observe the particles\n… . The geometrical (Newtonian) optics of rays should be\nthe limit of wave optics as the wavelength becomes negligibly small,\nyet … the reduction (mathematically similar to that of\nclassical to quantum mechanics) is obstructed by singularities\n… . \nMy contention … will be that many difficulties associated\nwith reduction arise because they involve singular limits.\nThese singularities have both negative and positive aspects: they\nobstruct the smooth reduction of more general theories to less general\nones, but they also point to a great richness of borderland physics\nbetween theories. (Berry 2001, 43) \n\nWhen Schema R fails this is because the mathematics\nof the particular limit \\((\\varepsilon \\rightarrow 0)\\) is singular. One can ask\nwhat, physically, is responsible for this mathematical singularity. In\ninvestigating the answer to this question one will often find that the\nmathematical blow-up reflects a physical impossibility. For instance,\nif Schema R held when \\(T_f\\)\nis the wave theory of light and \\(T_c\\) is the\nray theory (geometrical optics), then one would expect to recover rays\nin the shortwave limit \\(\\lambda \\rightarrow 0\\) of the wave theory. On the ray\ntheory, rays are the carriers of energy. But in certain situations\nfamilies of rays can focus on surfaces or lines called “caustics.”\nThese are not strange esoteric situations. In fact, rainbows are, to a\nfirst approximation, described by the focusing of sunlight on these\nsurfaces following its refraction and reflection through raindrops.\nHowever, according to the ray theory, the intensity of the light on\nthese focusing surfaces would be infinite. This is part of the\nphysical reason for the mathematical singularities. See also the discussion of the rainbow by Pincock 2011, and Belot 2005. \n\nOne is led to study the asymptotic domain in which the parameter\n\\(\\varepsilon\\) in Schema R approaches 0. In the example\nabove, this is the short wavelength limit. Michael Berry (1980; 1990;\n1994a; 1994b) has done much research on this and other asymptotic\ndomains. He has found that in the asymptotic borderlands between such\ntheories there emerge phenomena whose explanation requires in some\nsense appeal to a third intermediate theory. This is a claim\n(Batterman 2002) that when taken literally, has raised a number of\nhackles in the literature. However, understood in terms of the\nmathematics of characteristics and wavefronts, as was originally\nintended, the current author believes some of the debates are\nmisdirected. The emergent structures (the rainbow itself is one of\nthem) are not fully explainable either in terms of the finer wave\ntheory or in terms of the ray theory alone. Instead, aspects of both\ntheories (through asymptotic investigation of the wave equations) are\nrequired for a full understanding of these emergent phenomena.  \n\nThis fact calls into question certain received views about the nature\nof intertheoretic relations. The wave theory, for example, is surely\nthe fundamental theory. Nevertheless, these considerations seem to\nshow that that theory is itself explanatorily deficient. There are\nphenomena within its scope whose explanations require examining\nthe asymptotics of the appropriate equation. This involves\npaying attention to mathematical structures called characteristics and\nwavefronts. See Bóna and Slawinski 2011. These mathematical\ninvestigations of the deep asymptotic structure of hyperbolic\nequations are not at all like the straightforward derivations from\ninitial data that are typical of in principle derivations\noften referred to in carrying out the dictates of Nagel style\nexplanatory reductions. A similar situation arises in the asymptotic\ndomain between quantum mechanics and classical mechanics where\nPlanck’s constant can be considered asymptotically small. (See Belot\n2005 for an alternative point of view.) \nThere is much here worthy of further philosophical study. Some very\nrecent work by Butterfield (2011), Butterfield and Bouatta (2011),\nNorton (2012), Menon and Callender (2012) challenges the point of view\nsuggested by the above discussion. These authors address issues about\nthe nature of infinite idealizations, reduction, and emergence. A\ncommon theme is that it is possible to reconcile emergence and\nreduction. By and large these authors adopt a Nagelian sense of\nreduction as definitional extension. For a contrary point of view one\ncan see Batterman (2002; 2012).\n","contact.mail":"rbatterm@pitt.edu","contact.domain":"pitt.edu"}]
