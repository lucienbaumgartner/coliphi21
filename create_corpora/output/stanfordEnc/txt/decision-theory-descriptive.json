[{"date.published":"2017-09-26","url":"https://plato.stanford.edu/entries/decision-theory-descriptive/","author1":"Jake Chandler","author1.info":"http://www.jakechandler.net","entry":"decision-theory-descriptive","body.text":"\n\n\nDescriptive decision theory is concerned with characterising and\nexplaining regularities in the choices that people are disposed to\nmake. It is standardly distinguished from a parallel enterprise,\nnormative decision theory, which seeks to provide an account of the\nchoices that people ought to be disposed to make. Much of the\nwork in this area has been devoted to the building and testing of\nformal models that aim to improve on the descriptive adequacy of a\nframework known as “Subjective Expected Utility” (SEU).\nThis adequacy was first called into question in the middle of the last\ncentury and further challenged by a slew of experimental work in\npsychology and economics from the mid 1960s onwards.\n\n\nThis entry first sketches out the basic commitments of SEU, before\nmoving on to some of its best-known empirical shortcomings and a small\nselection of those models that have been proposed to supersede it. The\nrelation between descriptive decision theory and its normative\ncounterpart is then discussed, drawing some connections with a number\nof related topics in the philosophical\n literature.[1]\n\nThe canonical theory of choice—Subjective Expected\nUtility (SEU)—owes its inception to the work of Savage\n(1954), building on previous contributions by De Finetti (1937),\nRamsey (1931) and von Neumann and Morgenstern (1947). It offers a\nhomogenous treatment of both decisions under\n“risk”—situations in which the decision\nmaker has knowledge of, or holds firm beliefs regarding, the objective\nprobabilities of all events pertinent to the success of his or her\nactions—and decisions under\n“uncertainty”—in which he or she does not.\nIn its non-normative incarnation, it proposes at the very least that\nagents can be described as if: \nOntologically bolder incarnations of the view have it that agents are\nso describable because they really do have degrees of belief\nand desires, introspectively familiar psychological states, that\ndetermine their preferences and choices in such a manner. \nA number of important formal results, known as “representation\ntheorems”, show that this claim about describability can be\nderived from a set of prima facie plausible general\nprinciples, aka “postulates” or “axioms”,\npertaining to the agents’ preferences over acts. Furthermore,\nnot only are these axioms collectively sufficient to derive\nSEU’s claim, but a significant proper subset of them also turn\nout to be individually necessary. Unsurprisingly then, much\nof the work on assessing the empirical adequacy of SEU has focused on\nthe testing of the aforementioned axioms. Such tests could, in the\nbest case, undermine a key reason to endorse the claim and, in the\nworst, provide grounds to reject it. Accordingly, a brief sketch of\nSavage’s own early result is in order. \nIn Savage’s framework, acts are modelled as functions\nthat map possible states of the world to outcomes,\nthe consequences, if you wish, of carrying out the relevant act in the\nrelevant state of nature. The set of acts will be denoted by\n\\(\\mathcal{A}=\\{f_1, f_2,\\ldots g_1, g_2 \\ldots\\}\\), the set of states\nby \\(\\mathcal{S}=\\{s_1, s_2,\\ldots\\}\\) and the set of outcomes by\n\\(\\mathcal{X}=\\{x_1, x_2,\\ldots,x_n\\}\\). For present purposes, it can\nbe assumed that the acts considered are simple, i.e., that\ntheir range is finite. An act will be called\n“constant” if and only if it maps all states onto\none same outcome. Sets of states, also known as events, will\nbe denoted by upper-case letters \\(A_1, A_2,\\ldots, B_1, B_2, \\ldots\\)\netc. The set of such events will be denoted by \\(\\mathcal{E}\\).\n\\(E_i^f\\) will denote the set of states that the act \\(f\\) maps onto\noutcome \\(x_i\\), i.e., \\(\\{s\\in\\mathcal{S}: f(s)=x_i\\}\\). It will also\nbe useful to denote by \\(fAg\\) the act that maps the states in \\(A\\)\nto the same outcomes that \\(f\\) does and the states outside of \\(A\\)\nto the same outcomes that \\(g\\) does. \nThe agent’s choice dispositions at a given point in time are\ntaken to be determined by his or her preferences, in such a way that,\nfrom any set of particular acts, the agent is liable to choose all and\nonly those acts to which no other act is strictly preferred.\n\\(f\\succeq g\\) will denote the fact that an agent finds act \\(f\\) to\nbe no less desirable than act \\(g\\). \\(\\succ\\) (strict preference) and\n\\(\\sim\\) (indifference) respectively stand for the asymmetric and\nsymmetric parts of \\(\\succeq\\), so that \\(f\\succ g\\) iff \\(f\\succeq\ng\\) but not \\(g\\succeq f\\) and \\(f\\sim g\\) iff both \\(f\\succeq g\\) and\n\\(g\\succeq f\\). It is convenient to extend this preference relation to\nthe set of outcomes by setting, for all outcomes \\(x_1\\) and \\(x_2\\),\n\\(x_1\\succeq x_2\\) iff the constant act that yields \\(x_1\\) in all\nstates is weakly preferred to the one that yields \\(x_2\\) in all\nstates. \nSavage proves that there exists a certain specific set of constraints\non preference orderings over acts that will be satisfied if and only\nif this ordering is representable by a real-valued function \\(U\\) with\ndomain \\(\\mathcal{A}\\) (so that \\(f\\succeq g\\) iff \\(U(f)\\succeq\nU(g)\\)), such that  \nwhere \\(u : \\mathcal{X}\\mapsto \\mathbb{R}\\) is a consequence utility\nfunction unique up to positive linear transformation and \\(P:\n\\mathcal{S}\\mapsto [0,1]\\) is a unique subjective probability\nfunction, satisfying \\(P(\\varnothing)=0\\), \\(P(\\mathcal{S})=1\\), and\nthe finite additivity property \\(P(A\\cup B)=P(A)+P(B)\\) for all\ndisjoint events \\(A,B\\). In other words, \\(U\\) returns the sum of the\nutilities of the possible outcomes, each multiplied by the subjective\nprobability of the set of states which are mapped onto that\noutcome. \nFor the case in which \\(\\mathcal{X}\\) is finite, Savage’s set of\naxioms numbers six. Only three of these, however, make an appearance\nin the subsequent discussion. The first requires no comment: \nWeak Order \\(\\succeq\\) is a weak order, that is: it\nis both transitive (for all acts \\(f, g, h\\): if \\(f\\succeq g\\) and\n\\(g\\succeq h\\), then \\(f\\succeq h\\)) and complete (for all acts \\(f,\ng\\): either \\(f\\succeq g\\) or \\(g\\succeq f\\)). \nThe second tells us that, in comparing two acts, one ignores their\nbehaviour on the set of states in which they have identical\nconsequences: \nSure-Thing For all acts \\(f, g, h, h'\\) and any event\n\\(A\\): \\(fAh\\succeq gAh\\) iff \\(fAh'\\succeq gAh'\\). \nThe third is given as follows: \nWeak Comparative Probability For all outcomes\n\\(x_1,x_2,x_3,x_4\\) and events \\(A,B\\): if \\(x_1\\succ x_2\\) and\n\\(x_3\\succ x_4\\), then \\(x_1Ax_2\\succeq x_1Bx_2\\) iff \\(x_3Ax_4\\succeq\nx_3Bx_4\\). \nThe rationale for its proposal lies in the idea that, if \\(x_1\\succ\nx_2\\), then \\(x_1Ax_2\\succeq x_1Bx_2\\) reflects a commitment to the\nclaim that \\(A\\) is at least as probable as \\(B\\), and hence, so too\nmust \\(x_3Ax_4\\succeq x_3Bx_4\\), when \\(x_3\\succ x_4\\). \nThese three conditions, it should be noted, are individually necessary\nfor SEU representability, so that any SEU maximizer must satisfy them.\nIn addition, Savage proposes two further non-necessary, aka\n“structural”, conditions—respectively known as\n“Non-Degeneracy” and “Small Event Continuity”,\nas well as a further, necessary, condition of “Eventwise\nMonotonicity”, which tells us that, under certain mild\ncircumstances, the result of replacing one or more occurrences of a\ngiven outcome by another will yield a preferred act if and only if the\nnew outcome is preferred to the original. \nWith all this in hand, Savage’s result can be established as\nfollows. First, one introduces a relation of “subjective\ncomparative probability” \\(\\unrhd\\), such that \\(A\\unrhd B\\) iff\nfor all outcomes \\(x_1\\) and \\(x_2\\) such that \\(x_1\\succ x_2\\),\n\\(x_1Ax_2\\succeq x_2Ax_1\\) iff \\(x_1Bx_2\\succeq x_2Bx_1\\).\nSavage’s axioms can then be shown to ensure that \\(\\unrhd\\)\nsatisfies a number of appropriate properties, with Small Event\nContinuity ensuring that \\(\\unrhd\\) is representable by a subjective\nprobability function \\(P\\) that is unique. It is worth noting that, in\nthe presence of Weak Comparative Probability, it is mainly the\nSure-Thing principle that allows the derivation of the additivity\nproperty of \\(P\\). \nSecond, using these axioms again, it can then be established that an\nagent is indifferent between any two acts that, for each outcome,\nassign equal probabilities to the respective sets of states that they\neach map onto that outcome. In other words: \nState Neutrality If \\(P_f=P_g\\), then \\(f\\sim g\\),\nwhere \\(P_f(x_i) = P(E^f_i)\\). \nSince it can also be shown that, for every lottery \\(P\\) in\n\\(\\mathcal{P}\\), there exists an act \\(f\\) such that \\(P_f=P\\), the\nimportant upshot of this result is that one can effectively simplify\nthe representation of the agent’s preferences over acts,\nrecasting them as preferences over the smaller set \\(\\mathcal{P}\\) of\nso-called subjective lotteries, i.e., subjective probability\ndistributions over outcomes. To simplify notation, the preference\nrelation over \\(\\mathcal{P}\\) will be denoted by the same symbol,\n\\(\\succeq\\), allowing context to disambiguate. \nA further application of the axioms lets us establish that these\npreferences over lotteries satisfy three important properties: (i) a\n“Mixture Weak Order” condition, requiring the preferences\nover lotteries to be transitive and complete, (ii) a “Mixture\nContinuity” condition, the details of which are not of\nimportance here and finally (iii) an “Independence”\ncondition, which, alongside the ordering condition, will be the focus\nof considerable discussion in what follows. \nTo present this last condition, one more definition is required,\nalongside a piece of notation: For any two lotteries \\(P_f\\) and\n\\(P_g\\) and \\(\\lambda\\in[0,1]\\), one can define a third simple lottery\n\\(\\lambda P_f + (1-\\lambda)P_g\\) in \\(\\mathcal{P}\\), the\n\\(\\lambda\\)-mixture of \\(P_f\\) and \\(P_g\\), by setting \\((\\lambda P_f\n+ (1-\\lambda)P_g)(x)\\), the probability assigned to outcome \\(x\\) by\nthe mixture lottery, equal to \\(\\lambda P_f(x) + (1-\\lambda)P_g(x)\\).\nIt is heuristically useful to think of \\(\\lambda P_f +\n(1-\\lambda)P_g\\) as a higher-order lottery that yields a probability\nof \\(\\lambda\\) of playing lottery \\(P_f\\) and a complementary\nprobability of playing \\(P_g\\). The condition then reads: \nIndependence For all acts \\(f, g\\) and \\(h\\) and all\n\\(\\lambda\\in(0,1]\\): \\(P_f\\succeq P_g\\) iff \\(\\lambda P_f +\n(1-\\lambda) P_h\\succeq \\lambda P_g + (1-\\lambda) P_h\\). \nThe proof is then completed by appealing to a result of von Neumann\nand Morgenstern (1947), which shows that the aforementioned trio of\nproperties is necessary and sufficient for the representability of\n\\(\\succeq\\) by a function \\(U\\) such that  \nwhere \\(u : \\mathcal{X}\\mapsto \\mathbb{R}\\) is a consequence utility\nfunction unique up to positive linear transformation. \nThe probability triangle (aka “Marschak-Machina\ntriangle”) offers a helpful visual representation of preferences\nover the space of lotteries over \\(\\{x_1, x_2, x_3\\}\\), with\n\\(x_3\\succ x_2 \\succ x_1\\). Since, for any \\(P\\in \\mathcal{P}\\),\n\\(P(x_2)= 1- P(x_1)-P(x_3)\\), one can represent the situation\ntwo-dimensionally, with lotteries appearing as points in a unit\ntriangle in which the horizontal axis gives us \\(P(x_1)\\) and the\nvertical one gives us \\(P(x_3)\\). The northwestern, southwestern and\nsoutheastern corners respectively correspond to the lotteries yielding\n\\(x_3, x_2\\) and \\(x_1\\) for sure. \nNow, as is easily demonstrated, SEU is committed to \nStochastic Dominance For all acts \\(f\\) and \\(g\\):\nif, for any outcome \\(x\\), the probability according to \\(P_f\\) of\nobtaining an outcome that is weakly preferred to \\(x\\) is at least as\ngreat as the corresponding probability according to \\(P_g\\) (in other\nwords: \\(\\sum_{\\{y\\in\\mathcal{X}: y\\succeq x\\}} P_f(y)\\) \\(\\geq\\)\n\\(\\sum_{\\{y\\in\\mathcal{X}: y\\succeq x\\}} P_g(y)\\)), then \\(P_f\\succeq\nP_g\\). \nIndeed, the above principle follows from Independence and is in fact\nequivalent to Savage’s Eventwise Monotonicity\ncondition, given the other conditions in place (Grant 1995). Therefore\nlotteries become increasingly preferred both as one moves north and as\none moves west, since, in doing either, one shifts probability from a\nless to a more preferred outcome (from \\(x_2\\) to \\(x_3\\) when moving\nnorth and from \\(x_1\\) to \\(x_2\\) when moving west). The indifference\ncurves are hence upward-sloping. Steeper slopes correspond to greater\nrisk aversion, in the following sense: northeastern movements increase\nthe spread of the distribution, i.e., the degree of risk involved,\nshifting probabilities from the middle outcome (\\(x_2\\)) to the\nextremal ones (\\(x_1\\) and \\(x_3\\)). The steeper the indifference\ncurve, the greater an increase in probability of the best outcome is\nrequired in order to compensate for this increased risk. SEU clearly\nalso requires that indifference curves be both linear and\n parallel.[2]\n To illustrate: \nFigure 1 \nAlthough SEU continues to enjoy widespread support as a normative\nmodel of choice behaviour (though see\n Section 5\n below), it is no longer generally taken to be descriptively adequate.\nA number of substantial deviations from its predictions were noted as\nearly as the 1950s and early 1960s by the likes of Allais (1953a,b)\nand Ellsberg (1961) and further investigated in the 1970s. These\nobservations led to the development of alternative models whose own\npredictive consequences have become the focus of extensive testing in\nthe past three decades or\n so.[3] \nAllais (1953a: 527) considered hypothetical preferences revealed by\nchoices taken from two respective menus of lotteries yielding various\nincrements in wealth with various objective probabilities, one\ncontaining \\(P_1\\) and \\(P_2\\) below, the other \\(P_3\\) and\n\\(P_4\\): \n(a) \n(b) \n(c) \n(d) \nFigure 2 \nHe claimed that, for a substantial proportion of agents, one would\nfind that \\(P_{1}\\succ P_{2}\\) and \\(P_{4}\\succ P_{3}\\) (call these\nthe “Allais preferences”). However, on the\nassumptions that (i) the subjects’ degrees of belief align\nthemselves with the objective probabilities given and (ii) the\noutcomes can be adequately characterised entirely in terms of the\nassociated changes in level of wealth, such a combination of\npreferences runs contrary to Independence. More specifically, it runs\ncounter to the special case of the principle, according to which the\nsubstitution of a common “consequence”, i.e., lottery, in\na pair of mixtures leave the order of preference unchanged: \nCommon Consequence For all acts \\(f, g, h, h'\\) and\n\\(\\lambda\\in(0,1]\\):  \nTo see why, let \\(\\lambda=0.11\\), \\(Q_1\\) (the\n“consequence” common to \\(P_1\\) and \\(P_2\\)) be a lottery\nyielding $\\(1\\)M for sure, \\(Q_2\\) be a lottery yielding $\\(5\\)M with\nprobability \\(10/11\\) and \\(\\$0\\) otherwise, and finally \\(Q_3\\) (the\n“consequence” common to \\(P_3\\) and \\(P_4\\)) a lottery\nyielding \\(\\$0\\) for sure. \\(P_1\\) turns out to be a\n\\(\\lambda\\)-mixture of \\(Q_1\\) and \\(Q_1\\), \\(P_2\\) one of \\(Q_2\\) and\n\\(Q_1\\), \\(P_3\\) one of \\(Q_1\\) and \\(Q_3\\) and \\(P_4\\) one of \\(Q_2\\)\nand \\(Q_3\\). This is probably best seen by considering the decision\ntrees representing the corresponding compound lotteries: \n(a) \n(b) \n(c) \n(d) \nFigure 3 \nThe upshot of this, by Common Consequence, is then that \\(P_1\\succeq\nP_2\\) iff \\(P_3\\succeq\n P_4\\).[4] \nThe probability triangle affords a helpful illustration of the\nincompatibility of the Allais preferences with SEU. Indeed, the\nsegments connecting \\(P_1\\) and \\( P_2\\), on the one hand, and \\(\nP_3\\) and \\(P_4\\) on the other are parallel, so that an EU maximiser,\nwhose indifference curves are also parallel, would be incapable of\nexhibiting the modal preferences, since no pair of indifference curves\ncould be, as required, such that one crosses the segment \\([P_1,P_2]\\)\nfrom below while the other crosses \\([P_3,P_4]\\) from above: \nFigure 4 \nIn addition to the above, which has come to be known as the Common\nConsequence problem, a further issue, the Common Ratio\nproblem, was suggested by Allais (1953a: 529–530). The\ndifficulty this time concerned a further consequence of Independence,\nwhich tells us that the order of preference between two\nidentically-weighted mixtures that share a common component lottery is\nunaffected by a change in the mixture weight: \nCommon Ratio For all acts \\(f,g,h\\) and\n\\(\\lambda,\\gamma\\in(0,1]\\):  \nA presentation of the relevant pairs of options will not be given\nhere. Note simply that, here again, the problematic choices turn out\nto involve two pairs of options whose respective corresponding\nsegments in the probability triangle run\n parallel.[5] \nA number of experimental studies in the 1960s and 1970s subsequently\nconfirmed the robustness of the effects uncovered by Allais. Slovic\n& Tversky (1974), for example, report that 17 out of 29 (59%) of\nsubjects in their study exhibit Allais preferences in their\ninvestigation of the Common Consequence problem. See MacCrimmon &\nLarson (1979) for a helpful summary of this and other early work and\nfurther data of their own. \nSince the late 1970s, a considerable number of generalisations of SEU\nhave been devised to accommodate the problematic preference patterns.\nA brief survey of these is provided in the following subsection. \nA substantial proportion of the responses to Allais-type phenomena\nhave involved generalisations of SEU that remain conservative enough\nto preserve the requirement of what Machina & Schmeidler (1992)\ncall “probabilistic sophistication”: that\npreferences over acts reduce to preferences over lotteries and that\nthese in turn obey Mixture Weak Order, Mixture Continuity and\nStochastic Dominance, if not\n Independence.[6]\n Machina & Schmeidler offer an axiomatic characterisation of\nprobabilistically sophisticated preferences that gives up\nSavage’s Sure-Thing condition, which plays a critical role in\nthe derivation of Independence, and retains the remainder of his\nconditions. Since the Sure-Thing principle, however, also\nplays an important role in ensuring the existence of a suitable\nprobability distribution over the set of events, they strengthen the\nWeak Comparative Probability condition to the following: \nStrong Comparative Probability For all outcomes\n\\(x_1,x_2,x_3,x_4\\), acts \\(f, g\\) and disjoint events \\(A,B\\): if\n\\(x_1\\succ x_2\\) and \\(x_3\\succ x_4\\), then \\(x_1Ax_2Bf\\succeq\nx_2Ax_1Bf\\) iff \\(x_3Ax_4Bg\\succeq x_4Ax_3Bg\\). \nwhere \\(x_1Ax_2Bf\\) denotes the act that yields \\(x_1\\) for all \\(s\\in\nA\\), outcome \\(x_2\\) for all \\(s\\in B\\) and \\(f(s)\\) for all other\n\\(s\\). They then offer a correspondingly amended account of the\nproposed correspondence between the subjective qualitative probability\nand preference relations, proposing that, if \\(x_1\\succ x_2\\), then\n\\(A\\unrhd B\\) iff \\(x_1Ax_2Bf\\succeq x_2Ax_1Bf\\). \nAmong the models of probabilistically sophisticated preferences that\ndo not satisfy Independence and, more specifically, do not impose the\nproperty of parallelism of indifference curves, a number\nstill satisfy a weaker principle that imposes linearity,\nnamely: \nBetweenness For all acts \\(f\\) and \\(g\\) and\n\\(\\lambda\\in[0,1]\\): if \\(P_f\\sim P_g\\), then \\(P_f\\sim \\lambda P_f +\n(1-\\lambda) P_g\\). \nThis is notably the case of Weighted Utility (WU) (Chew &\nMacCrimmon 1979; Chew 1983), which proposes that the summands in the\nexpected utility formula each be multiplied by a corresponding weight,\nso that preferences between lotteries are representable by the more\ngeneral functional  \nwhere \\(w\\) is a positive real-valued function on \\(\\mathcal{X}\\). If\n\\(w\\) is constant, one recovers the EU functional. The incorporation\nof weights accommodates Allais preferences by allowing indifference\ncurves to “fan out” from a single intersection located in\nthe quadrant to the southwest of the probability triangle. These\ncurves become steeper, and hence represent a greater degree of risk\naversion, as one moves northwest, in the direction of increasingly\npreferred lotteries. A suitably placed intersection allows\nindifference curves to cross both \\([P_1,P_2]\\) from below and\n\\([P_3,P_4]\\) from above, as\n required.[7] \nThere is however substantial evidence that the linearity of\nindifference curves isn’t any more empirically adequate that\ntheir parallelism (see Camerer & Ho 1994 for a survey) and a\nnumber of models of probabilistically sophisticated preferences give\nup on Betweenness too. The best known of these is undoubtedly Rank\nDependent Utility (RDU), a version of which was first proposed by\nQuiggin\n (1982).[8]\n To present the proposal in functional form, it will be assumed that\nthe subscripts associated with each outcome in \\(\\mathcal{X}\\)\nindicate increasing order of preference, so that \\(x_1\\preceq\nx_2\\preceq \\ldots \\preceq x_n\\) and hence \\(\\bigcup\\limits_{j=i}^{n}\nE^{f}_{j}\\) is the event given which \\(f\\) yields an outcome at least\nas preferable as \\(x_i\\). RDU proposes:  \nwhere \\(w : [0,1]\\mapsto[0,1]\\) is a strictly increasing probability\nweighting function, such that \\(w(0)=0\\) and \\(w(1)=1\\). In other\nwords: the utility of a lottery is equal to the sum of the marginal\nutility contributions of the outcomes, each multiplied by the weighted\nprobability of obtaining an outcome that is at least as preferable\n(the marginal contribution of \\(x_1\\) is \\(u(x_1)\\) and its associated\nmultiplier is \\(w\\big(P(\\{\\mathcal{S}\\})\\big)=w(1)=1\\)). If \\(w\\) is\nthe identity function, so that \\(w\\circ P=P\\), it turns out that one\nrecovers the expected utility functional. If not, a suitable choice of\n\\(w\\) enables one to recover the Allais preferences. To see how,\nassume for simplicity that \\(u(0)=0\\). One then has \\(P_1\\succ P_2\\)\niff  \nand \\(P_4\\succ P_3\\) iff \\(u(5)w(0.1)>u(1)w(0.11)\\). This implies\nthat the preferences will be recovered by having \\(w\\) be such that\n\\(w(1)-w(0.99)>w(0.11)-w(0.1)\\), so that a difference in\nprobability of \\(0.01\\) has a greater impact at the higher end of the\nprobability scale than it does towards its relatively lower\n end.[9] \nIt should be noted that RDU is itself a special case of what is\nperhaps the best known alternative to SEU, Kahneman &\nTversky’s Cumulative Prospect Theory (Tversky &\nKahneman 1992), which earned Kahneman a Nobel Prize in\nEconomics in 2002. This model generalises RDU by introducing a\nreference point, an outcome that partitions the set of\noutcomes into positive and negative subsets, according to whether\nthese are strictly preferred or strictly dispreferred to it.\nTwo probability transformation functions, \\(w^+\\) and\n\\(w^-\\), are then involved in the preference functional: \\(w^+\\) in\ndetermining the utility contributions of the negative outcomes and\n\\(w^-\\) playing an analogous role in relation to that of the positive\nones. RDU is recovered when \\(w^+\\) is the dual of \\(w^+\\). \nWhile RDU does not satisfy Independence, it does satisfy a weakening\nof this principle known as “Ordinal Independence” (Green\n& Jullien 1988). This principle is presented as a constraint on\nthe cumulative distribution functions (cdf) corresponding to\nvarious lotteries, which return, for each \\(x_i\\), the probability of\nobtaining an outcome that is no better than \\(x_i\\) (i.e., an outcome\n\\(x_j\\), with \\(j\\leq i\\)). The cdf corresponding to \\(P_f\\) shall be\ndenoted by \\(F\\). We then have \nOrdinal Independence For all acts \\(f,f',g\\) and\n\\(g'\\) and subsets \\(A\\) of \\(\\mathcal{X}\\): If \\(P_f\\succeq P_g\\),\nand \nthen \\(P_{f'}\\succeq\n P_{g'}\\).[10] \nThe constraint can more helpfully be put as follows: In comparing two\nacts, one ignores the values of their respective cdf’s on the\nset of outcomes with respect to which they agree. It is easily\nverified that the Allais preferences are consistent with this\nprinciple. Given probabilistic sophistication, Ordinal Independence\ncan itself be derived from a constraint on preferences over acts known\nas “Comonotonic Independence”, presented in\n Subsection 3.2.1\n below. Wakker (2010) offers a textbook introduction to RDU and\nCumulative Prospect Theory, as well as to related treatments of the\nissues discussed in the next section. \nIn another classic challenge to SEU, Ellsberg (1961) asked subjects to\nconsider a setup in which an urn contains 30 red balls and 60 black or\nyellow balls in unknown relative proportions and report their\npreferences between various bets on the colour of a ball drawn at\nrandom from the urn. The preferences elicited were the ones holding\nbetween\\(f_1\\) and \\(g_1\\) below, on the one hand, and \\(f_2\\) and\n\\(g_2\\), on the other: \nEllsberg reported that a majority of subjects exhibited the\npreferences \\(f_1\\succ g_1\\), but \\(g_2\\succ f_2\\), an instance of a\nphenomenon that has come to be known as ambiguity aversion: a\nrelative preference for betting on events of known rather than unknown\n(“ambiguous”) probability. \nIf one grants that the outcomes are adequately characterised in sole\nterms of associated changes in level of wealth, these “Ellsberg\npreferences” stand in direct contradiction with Savage’s\nSure-Thing principle. These preferences also violate Machina &\nSchmeidler’s Strong Comparative Probability principle, on the\nnatural assumption that the subjects strictly prefer the outcome\n\\(\\$100\\) to the outcome \\(\\$0\\). And indeed it is easy to see that\nthe Ellsberg preferences are inconsistent with probabilistic\nsophistication. More specifically, they are incompatible with its\nbeing the case that both (i) the decision maker’s preferences\nover acts are reducible to preferences over corresponding lotteries\nover outcomes, generated by an assignment of subjective probabilities\nto the set of events and (ii) he or she partially orders these\nlotteries by first-order stochastic dominance. To see why, assume that\nthese conditions hold. Note first that \\(P_{g_1}\\) would\nstochastically dominate \\(P_{f_1}\\) if and only if \\(P(\\{b\\})\\geq\nP(\\{r\\})\\) and that \\(P_{f_2}\\) would stochastically dominate\n\\(P_{g_2}\\) if and only if \\(P(\\{r\\})\\geq P(\\{b\\})\\). \\(f_1\\succ g_1\\)\nwould entail that \\(P_{g_1}\\) does not stochastically dominate\n\\(P_{f_1}\\), and hence that \\(P(\\{r\\}) > P(\\{b\\})\\). But \\(g_2\\succ\nf_2\\) would entail that \\(P_{f_2}\\) does not stochastically dominate\n\\(P_{g_2}\\), and hence that \\(P(\\{b\\})> P(\\{r\\})\\).\nContradiction. \nConsiderable empirical evidence has confirmed Ellsberg’s\ninformal observations and related phenomena (beginning with Becker\n& Brownson 1964 and including classic studies such as Slovic &\nTversky 1974 and MacCrimmon & Larsson 1979; see the classic\nCamerer & Weber 1992, as well as the more up-to-date Trautmann\n& van de Kuilen 2015, for further details) and the literature now\ncontains a substantial number of generalisations of SEU that can\naccommodate these. \nOne prominent weakening of SEU that is capable of accommodating the\nEllsberg cases is Choquet Expected Utility (CEU), initially\nproposed by Schmeidler (1989). The key concept in its representation\nof preferences is that of a capacity: a function \\(v :\n\\mathcal{E}\\mapsto [0,1]\\), such that \\(v(\\varnothing)=0\\),\n\\(v(\\mathcal{S})=1\\) and, for all \\(A, B\\in \\mathcal{E}\\),\n\\(A\\subseteq B\\) implies \\(v(A)\\leq v(B)\\). One can think of this as a\nkind of non-additive “probability” function, since the\nadditivity property, according to which \\(v(A\\cup B)=v(A)+v(B)\\) for\ndisjoint events \\(A\\) and \\(B\\), does not hold. As with the\npresentation of RDU, the convention here is that the indices\nassociated with the outcomes indicate increasing preference, so that,\nagain, \\(\\bigcup\\limits_{j=i}^{n} E^{f}_{j}\\) is the event given which\n\\(f\\) yields an outcome at least as preferable as \\(x_i\\). CEU\nproposes:  \nOn this suggestion, then an act is valued by the sum of the marginal\nutility contributions of the outcomes, each multiplied by the capacity\nof the event given which that act would yield an outcome that is at\nleast as preferable. There are obvious formal similarities here with\nRDU and, in fact, the latter can be viewed as the special case of CEU\nin which the decision maker’s capacities are derived from his or\nher probabilistic degrees of belief by a probability weighting\nfunction (\\(v=w\\circ\n P\\)).[11] \nReturning to the Ellsberg preferences in the three colour problem, it\nis easy to see that \\(f_1\\succ g_1\\) iff \\(v(\\{r\\}) > v(\\{b\\})\\)\nand \\(g_2\\succ f_2\\) iff \\(v(\\{b,y\\}) > v(\\{r,y\\})\\). These\ninequalities obviously cannot be simultaneously satisfied in special\ncases in which \\(c\\) is additive and indeed, in such cases, CEU\nreduces to SEU. In the more general case, there is no problem: let\n\\(v\\), for instance, be such that:  \nGilboa (1987) and Wakker (1989) have both provided axiomatisations of\nthe proposal in a Savage framework. The key distinguishing feature of\nthese is the effective restriction of Savage’s Sure-Thing\nprinciple to particular kinds of sets of acts: \nComonotonic Sure-Thing For all acts \\(f, g, h, h'\\)\nand any event \\(A\\): if \\(fAh\\), \\(gAh\\), \\(fAh'\\) and \\(fAh'\\) are\ncomonotonic, then \\(fAh\\succeq gAh\\) iff \\(fAh'\\succeq gAh'\\). \nwhere two acts \\(f\\) and \\(g\\) are comonotonic iff, there are\nno two states \\(s_1\\) and \\(s_2\\), such that \\(f(s_1)\\succ f(s_2)\\)\nbut \\(g(s_2)\\succ g(s_1)\\), or again iff \\(f\\) and \\(g\\) yield\norderings of states by desirability of associated consequence that are\njointly consistent (Chew & Wakker 1996). Clearly, the Ellsberg\npreferences are perfectly compatible with this weakening of the\nSure-Thing principle, since the acts involved are not comonotonic. For\ninstance, \\(f_1(r)\\succ f_1(b)\\) but \\(f_2(b)\\succ\n f_2(r)\\).[12] \nThe capacity that was used above to illustrate the consistency of CEU\nwith Ellsberg-style preferences has a noteworthy property: it is\nconvex, meaning that it is such that, for all\n\\(A,B\\in\\mathcal{E}\\),  \nIt has been shown by Schmeidler (1986) that, if convexity of\ncapacities is imposed, CEU becomes a special case of an approach known\nas Maxmin Expected Utility (MEU) (Gilboa & Schmeidler\n1989), which represents the decision maker as maximising minimum\nexpected utility across a non-empty set of probability functions\n\\(\\Gamma\\) on \\(\\mathcal{X}\\), so that:  \nThe specific connection is the following: a CEU maximiser with respect\nto a convex capacity \\(v\\) is an EU maxminer over the so-called\ncore of \\(v\\), defined as the set of probability functions\nthat assign, for every event, a probability that is at least as great\nas the capacity assigned to that event by \\(v\\): \\(\\{P\\in\\mathcal{P}:\nP(A)\\geq v(A), \\forall A\\in\\mathcal{E}\\}\\). \nNow a common, but not mandatory, interpretation of \\(\\Gamma\\) is that\nit corresponds to the set of objective probability assignments that\nthe decision maker takes to be consistent with his or her evidence. In\nview of the result just flagged out, this in turn invites an\ninterpretation of capacities as lower estimates of objective\nprobabilities. More specifically, a CEU maximiser whose capacity is\nconvex can be interpreted as considering possible all and only those\nassignments of objective probabilities that are consistent with the\nlower estimates given by that capacity. This interpretation of the\ncapacity in the particular example at hand is obviously particularly\ntempting, as \\(\\nicefrac{1}{3}\\) and \\(\\nicefrac{2}{3}\\) constitute\nplausible lower bounds on the decision maker’s estimates of the\nprobabilities of \\(\\{r\\}\\) and \\(\\{b,y\\}\\), respectively. \nIf one interprets \\(\\Gamma\\) this way, relaxing CEU with convex\ncapacities to MEU becomes an attractive option, since it allows one to\nnot only model Ellsberg preferences but also accommodate the\npreferences of decision makers whose views on objective probabilities\ncannot simply be captured in terms of lower estimates (for example,\nthose involving commitments to certain facts about ratios of\nprobabilities). Due to space considerations, the details of the\naxiomatic treatment of MEU are omitted\n here.[13] \nStill, MEU remains rather restrictive, as it enforces a fairly radical\nform of ambiguity aversion. One popular generalisation of the model,\n\\(\\alpha-\\)MEU (Ghirardato et al. 2004), proposes\nthat the preferences imposed by MEU lie only at one end of a spectrum\nof possible ambiguity aversion, captured by the following weakening of\n\\((\\ref{eq:MEU})\\):  \nwhere \\(\\alpha\\in[0,1]\\). With \\(\\alpha=1\\), one recovers the highly\nambiguity-averse MEU. With \\(\\alpha=0\\), we have strongly\nambiguity-loving preferences. The parameter \\(\\alpha\\) is thus in a\nsense interpretable as a measure of ambiguity\naversion.[14],[15] \nJust as with MEU, however, \\(\\alpha\\)-MEU restricts its attention to\nextremal expected utilities (in this instance best- as well as\nworst-case). A popular class of proposals allows for the full range of\nexpected utilities across \\(\\Gamma\\) to be factored in, by\nsupplementing the multiple prior model with a higher order\nprobability distribution \\(\\mu\\). One well-known functional form,\nthat notably features in the “Smooth Model” of\nKlibanoff et al. (2005), involves taking the expectation,\nrelative to \\(\\mu\\), of the weighted expected utilities,\nrelative to the members of \\(\\Gamma\\):  \nA concave \\(\\Phi\\) will overweigh low expected utilities, resulting in\nrelatively ambiguity-averse preferences. \nWhile all models mentioned above impose transitivity on preferences,\nthere is a long history of investigating possible violations of the\nprinciple, both with respect to choice under certainty and choice\nunder risk. Regarding the latter, in a classic early study, Tversky\n(1969), suggested significant systematic violations of the\ntransitivity of strict preference, which is entailed by that of weak\npreference, in relation to a series of lotteries\n\\(P_1\\)–\\(P_5\\), each offering a chance \\(p_i\\) of receiving a\nprize \\(x_i\\) and a complementary chance of receiving nothing: \nTversky took his data to suggest that a significant number of subjects\nwere prone to expressing strict preferences for each lottery over its\nimmediate successor, but a strict preference for the last lottery over\nthe first. He proposed that these subjects ranked adjacent lotteries\nby mere payoff as the differences in the probabilities of winning were\nbarely perceptible, but took probability of winning into consideration\nin the comparison between \\(P_1\\) and \\(P_5\\), since the difference in\nvalues there was large. Although Tversky’s results were later\nreplicated, it should be noted that there is ongoing controversy\nsurrounding the level of empirical support for intransitive preference\n(see Regenwetter et al. 2011 for a recent literature\nreview). \nIntransitivities of a somewhat different kind are also predicted by\nLoomes & Sugden’s (1982, 1987) Regret\n Theory.[16]\n The guiding idea behind this proposal is that the appreciation of a\ngiven outcome in a given state is an essentially comparative matter.\nIt is determined by the regret (or the rejoicement) associated with\nthe thought that the alternatively available acts would have led, in\nthe same circumstances, to a particular set of alternative outcomes.\nIn the special case of binary alternatives, this intuition translates\ninto the following menu-dependent preference functional:  \nwhere \\(M: \\mathcal{X}\\times\\mathcal{X}\\mapsto \\mathbb{R}\\) is a\ncomparative utility function that is increasing in its first argument\nand non-decreasing in its second. In their discussion of the\nframework, Loomes & Sugden present things equivalently as follows:\n \nwhere \\(\\Psi \\big(f(s),g(s)\\big)\\) is defined as\n\\(M\\big(f(s),g(s)\\big)-M\\big(g(s),f(s)\\big)\\). This quantity thus\ncorresponds to the net balance of regret/rejoicement associated with\nchoosing \\(f\\) over \\(g\\) in states \\(s\\). Depending on the\nproperties of \\(\\Psi\\), decision makers can be characterised as being\n‘regret-neutral’, ‘regret-averse’ or even\n‘regret-seeking’. Regret neutrality corresponds to the\ncase in which, for all \\(x_1,x_2,x_3\\in \\mathcal{X}\\), \nUnder these conditions, choice behaviour is consistent with\nSEU. Regret aversion corresponds to the situation in which \\(\\Psi\\)\nsatisfies the following convexity requirement: for \\(x_1\\succ x_2\\succ\nx_3\\), \nLoomes & Sugden (1982) have shown that, at least under the\nassumption of probabilistic independence of the lotteries involved,\nthis type of disposition can predict both the Common Consequence and\nthe Common Ratio effects: Regret Theory does not entail\nIndependence.[17] \nTo obtain a sense of the violations of transitivity predicted by\nRegret Theory, here is an example due to Loomes & Sugden 1987.\nAssume convexity of \\(\\Psi\\) and consider the following decision\nproblem, where \\(x_1\\prec x_2\\prec x_3\\) and\n\\(P(A_i)=\\nicefrac{1}{3}\\): \nAccording to Regret Theory, \\(f\\succ g\\) iff  \nConvexity of \\(\\Psi\\) will ensure that this inequality holds. By\nsimilar reasoning, it can then be established that \\(g\\succ h\\) and\n\\(h\\succ\n f\\).[18] \nThe above example also clearly demonstrates that Regret Theory permits\nviolations of State Neutrality, since the different acts yield the\nsame probability distributions over outcomes. Loomes & Sugden\n(1987) further show that violations of Stochastic Dominance are\nlicensed by their model. However, in spite of these departures from\northodoxy, it should be noted that Regret Theory retains a number of\nother strong consequences of SEU, including the Sure-Thing principle,\nas well as Betweenness for probabilistically independent\ndistributions. An instructive axiomatisation of a generalisation of\n\\((\\ref{eqn:RT})\\) to finite menus is offered in Sugden 1993. See\nBleichrodt & Wakker 2015 for a clear overview of the framework,\nand its relation to the experimental data. \nAlthough the issue comes last in this catalogue of empirical\nchallenges to SEU, early doubts regarding the empirical adequacy of\nthe completeness assumption were aired by the very architects of the\nframework, including von Neumann & Morgenstern (1947: 630) and\nSavage (1954: 21). For instance, von Neumann & Morgenstern write:\n \nIt is very dubious, whether the idealization of reality which treats\nthis postulate as a valid one, is appropriate or even convenient.  \nFailure of completeness has been claimed to stem both from either (i)\nincompleteness in judgments of comparative probability or (ii)\nincompleteness in preferences between outcomes. Both sources of\nincompleteness can be handled in “multi-prior expected multi\nutility” models, which offer what one might call a\n“supervaluationist” representation of preferences over\nacts, as follows:  \nwhere \\(\\Phi\\) is a set of pairs of probability and utility functions.\nDue to space considerations, axiomatic details are left out here. The\ninterested reader is referred to the recent general treatment given by\nGalaabaatar & Karni (2013), who relate their results to important\nearlier work by the likes of Bewley (1986), Seidenfeld et al.\n(1995), Ok et al. (2012), and Nau (2006), among others. \nWhile it was fairly immediately recognised that Allais had\ndemonstrated an empirical shortcoming of SEU, it is important to note\nthat his ambitions somewhat outstripped this achievement. He further\nsuggested that his findings also give reason to doubt the\nnormative adequacy of the theory. On his view, two types of\nconsideration can be brought to the table in the assessment of a\ntheory of rational choice. The first is a demonstration that the\ntheory deductively follows from, or lies in logical conflict with,\nvarious general principles of secure epistemic standing. The second is\na body of experimental evidence regarding  \nthe conduct of persons who, one has reason in other respects\n[(“that is on criteria that are free of all reference to any\nconsideration of random choice.”)] to believe, act rationally.\n(Allais 1953b:\n 34)[19] \nHowever, he found no adequate evidence of the first kind that could be\nmarshalled to support anything quite as strong as SEU. He rejected,\nfor instance, Marschak’s (1951) “long-run success”\nargument for expected utility maximisation in situations of risk\n(Allais 1953b: 70–73). He did grant the existence of a\n“consistency” requirement according to which  \na man will be deemed to act rationally (a) if he pursues ends that are\nmutually consistent (i.e., not contradictory), (b) if he employs means\nthat are appropriate to these ends. (Allais 1953b: 78)  \nBut, this requirement, he claimed, simply entailed that preferences\nover lotteries be weakly ordered and satisfy Stochastic Dominance.\nThis left data on choice behaviour to adjudicate on the further\ncommitments of SEU. This data, in his view, clearly supported the\nrational permissibility of violating Independence. \nSavage did not explicitly discuss the probative force of the\ncollective preferences of his peers in relation to Allais’\ncases. He did however comment on the bearing of his own\npersonal preferences, which Allais had famously elicited from him at a\nParis symposium 1952 and which found themselves in violation of the\nrecommendations of SEU . Granting that it would have been irrational\nfor him to maintain both these preferences and a commitment to the\nnormative adequacy of his axioms, he reported that further\n“reflection” inclined him to revise the former, judging\nthese to have been in error, on par with a logical inconsistency in\nbeliefs. This fact, he claimed, entitled him to retain his normative\ncommitments (see Savage 1952:\n 101–103).[20]\n Since it is easy to surmise that Savage took his own inclinations to\nbe representative of those of the population at large, his comments\nhave been widely taken to implicitly suggest an alternative\nexperimental route to the testing of theories of rational choice. (See\nSlovic & Tversky 1974 and Jallais & Pradier 2005. This is also\nthe view of Ellsberg, who offers, in Ch. 1 of his 1961 doctoral\ndissertation, reprinted as Ellsberg 2001, a worthwhile discussion of\nthe issues of present interest, with Zappia 2016 providing a recent\nphilosophically-oriented discussion.). This procedure would involve\ndetermining, not whether certain decision makers exhibit patterns of\npreference proscribed by the theory, but whether they still exhibit\nsuch patterns after reflection on their conflict with the\ntheory’s basic axioms. \nA number of studies set out to test the normative adequacy of SEU\nalong the proposed lines. MacCrimmon (1968) reported violations, in a\nsample of experienced business executives, of a wide range of\nconsequences of SEU, a number of which persisted after subjects were\nnotably provided with considerations both supporting and undermining\nthese principles. Those principles with respect to which offending\npreferences were later corrected included most notably Transitivity\nand Stochastic Dominance. Allais- or Ellsberg-style preferences were\nsubstantially more resilient, however, a fact confirmed in a later\nstudy by Slovic & Tversky (1974). Another type of resilience of\npreferences, not considered by Savage, was more recently investigated\nby van de Kuilen & Wakker (2006). They studied the effects of\nproviding feedback on decision outcomes on the prevalence of common\nconsequence effects in sequences of choices, finding, however, a\nsignificant reduction in SEU violations. \nIn spite of a long-standing tradition of bringing to bear theories of\nrational choice on various philosophical\n problems,[21]\n the issue of the potential relevance of descriptive decision theory\nto its normative counterpart does not appear to have sparked much\ninterest in the philosophical community. Allais’ challenge to\nSavage has largely been ignored in the philosophical\n literature.[22] \nHaving said this, a fair amount of philosophical attention has been\ndevoted to the related issue of the connection between norms of\nreasoning and observed patterns of inference. One\ninfluential line of thought to be found there, which seems pertinent\nto Allais’ claims, originates in Goodman’s discussion of\nthe justification of inductive reasoning. On his view,  \n[t]he task of formulating rules that define the difference between\nvalid and invalid inductive inferences is much like the task of\ndefining any term with an established usage. (Goodman 1965: 66)  \nJust as semantic analyses can be endorsed on the basis of providing\ngood systematisations of a set of intuitions regarding the\napplicability of particular terms in particular situations, Goodman\nclaims, normative theories of reasoning can similarly be justified by\ntheir good fit with “the particular…inferences we\nactually make and sanction” (Goodman 1965: 63): no further\nconsiderations are required in order to be able to endorse a\nparticular principle as rationally binding. \nGoodman’s discussion is a brief one and, on our reading at\nleast, leaves open a number of questions. Should we admit as relevant\nany considerations beyond observed patterns of inference, such as\nproperties of long-run convergence to the truth, and so on? To whom\ndoes “we” refer to when Goodman speaks of “the\nparticular…inferences we actually make and sanction”?\nExperts? The human population at large? Should we be circumscribing\nthe class of relevant inferences to those judgments that one might\nwant to call “considered”? These are important matters to\nsettle. Indeed, a certain combination of answers to\nthese—entailing that the justification of normative theories of\nreasoning hinges entirely on their ability to systematise\n“immediate and untutored” inferential dispositions\nobserved in the general population—notoriously led Cohen (1981)\nto endorse the startling claim that, since normative and descriptive\nmodels are borne of the very same data set, behavioural evidence is in\nprinciple incapable of establishing human irrationality. For further\ndiscussion of this general topic, see for instance Stich (1990: Ch.\n4), Stein (1996: Ch. 5), Stanovich (1999: Ch. 1), and Thagard\n (1982).[23] \nAlthough neither Allais nor Goodman draw the connection, a potential\njustification for the evidential relevance of experimental data in\nnormative theory building can perhaps be sought in the literature on\nthe Condorcet Jury Theorem and related\n results.[24]\n This theorem tells us that, under certain conditions, the probability\nthat a majority verdict, with regards to a particular matter, in a\ngroup of \\(n\\) minimally reliable people casting yes/no votes on a\nparticular question converges to 1 as \\(n\\) tends to infinity,\nconverging more quickly the greater the individual reliabilities.\nFurthermore, majority reliability reaches significant levels, even\ngiven very limited individual reliability, for fairly modest group\nsizes. Of course, the issue of interest does not quite fit that\nspecific model: while the expression of Allais preferences can be\narguably interpreted as a “vote” against the normative\nadequacy of Independence, the expression of preferences consonant with\nthis principle can hardly be interpreted as a vote in favour of\nit. \nFinally, while this section has focused on the issue of the bearing of\ndescriptive decision theory on its normative counterpart, it should be\nnoted that there has been some discussion of the converse direction of\ninfluence. Both Guala (2000) and Starmer (2005) have argued that the\ndevelopment of descriptive theories of choice has been guided by a\nbias towards retaining a core of principles taken to be normatively\nadequate. In the case of decision making under risk these are\nessentially the transitivity component of Weak Order and Stochastic\nDominance, which are satisfied according to the vast majority of\nnon-SEU theories that have been developed to\n date.[25]\n Starmer claims to find an argument justifying this practise in a\nwell-known paper by Friedman and Savage (1952). This line of thought,\nwhich Starmer takes issue with, proceeds from the assumption that bona\nfide principles of rationality would be evident as such to most\nsubjects and that decision makers will accordingly behave in line with\nthem. \nWhile the philosophical literature on the topic remains rather sparse,\nthere is no shortage of first-rate summaries in the economics and\npsychology literatures. For thorough presentations of the technical\nresults referred to in\n Section 1,\n see Fishburn (1970: Ch. 14) or the slightly less detailed Kreps\n(1988: Ch. 9). Ch. 3 of Joyce (1999) is also helpful here. Regarding\nthe literature on Independence specifically, discussed in\n Section 2,\n see Machina (1987), Starmer (2000) and Weber & Camerer (1987).\nRegarding the issue of probabilistic belief specifically, discussed in\n Section 3,\n see Camerer & Weber (1992), Etner et al. (2012), Gilboa\n& Marinacci (2013), Machina & Siniscalchi (2014), and\nTrautmann & van de Kuilen (2015).A number of broader surveys cover\nboth the above issues, and some. These include most notably Camerer\n(1995) and the excellent Sugden (2004). Finally, for a clear and\ndetailed historical account of the development of the experimental\nliterature on decision-making, see Heukelom (2014).","contact.mail":"jake.chandler@cantab.net","contact.domain":"cantab.net"}]
