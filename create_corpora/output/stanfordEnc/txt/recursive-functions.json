[{"date.published":"2020-04-23","url":"https://plato.stanford.edu/entries/recursive-functions/","author1":"Walter Dean","author1.info":"http://go.warwick.ac.uk/whdean","entry":"recursive-functions","body.text":"\n\n\n[Editor's Note: The following new entry by Walter Dean replaces the\n former entry\n on this topic by the previous authors.]\n\n\n\nThe recursive functions are a class of functions on the\nnatural numbers studied in computability theory, a branch of\ncontemporary mathematical logic which was originally known\nas recursive function theory. Such functions take their name\nfrom the process of recursion by which the value of a\nfunction is defined by the application of the same function applied to\nsmaller arguments.\n\n\nThis process may be illustrated by considering the familiar factorial\nfunction \\(x!\\)—i.e., the function which returns the product \\(1\n\\times 2 \\times \\ldots \\times x\\) if \\(x > 0\\) and 1 otherwise. An\nalternative recursive definition of this function is as follows: \n\n\\[\\begin{align}\n\\label{defnfact}\n\\fact(0) & =  1 \\\\  \\nonumber\n\\fact(x+1) & =  (x+1) \\times \\fact(x) \\end{align}\\]\n\n\nSuch a definition might at first appear circular in virtue of the fact\nthat the value of \\(\\fact(x)\\) on the left hand side is defined in\nterms the same function on the righthand side. However a\ncharacteristic feature of recursive definitions is that they allow for\nthe values of functions which they describe to be calculated by\nsuccessively “unwinding” the clause for \\(x > 0\\) until\nthe clause for \\(x = 0\\) (the so-called base case) is\nreached. For instance the value of \\(fact(4)\\) may be calculated using the preceding definition as follows: \n\n\\[\\begin{align} \\label{factcalc}\n\\fact(4) &= 4 \\times \\fact(3) \\\\\n& = 4 \\times (3 \\times \\fact(2))  \\nonumber \\\\\n& = 4 \\times (3 \\times (2 \\times \\fact(1)))  \\nonumber \\\\\n &=4 \\times (3 \\times (2 \\times 1 \\times (\\fact(0))))  \\nonumber \\\\\n& = 4 \\times (3 \\times (2 \\times (1 \\times 1)))  \\nonumber \\\\\n& = 24  \\nonumber \\\\\n\\end{align}\\]  \n\n\nUnderstood in this way, the defining equations (\\ref{defnfact}) provide an\nalgorithm for computing \\(\\fact(x)\\)—i.e. an effective procedure for calculating its values which can be carried out by a human or mechanical computing device within a finite number of steps. It is for this reason that a class of recursive definitions similar to that exemplified by (\\ref{defnfact})— i.e. the general recursive functions—were first employed as the mathematical model of computation on which recursive function theory was originally founded.\n\n\nSection 1 of this entry provides an overview of the foundational developments in logic and mathematics which led to the founding of recursive function theory in the 1930s.  Section 2 surveys different forms of recursive definitions, inclusive of the primitive and partial recursive functions which are most central to the classical development of this subject.  Section 3 provides an overview of computability theory, inclusive of the so-called Recursion Theorem (Section 3.4)—a result which highlights the centrality of recursion to computation in general as well as its relationship to self-reference.  Subsequent updates to this entry will provide an overview of subrecursive hierarchies employed in proof theory and computer science as well as a more comprehensive treatment of contemporary computability theory.\n\n\nNB: This section assumes familiarity with some of the terminology\nintroduced in\n Section 2\n and\n Section 3.\n Readers looking for a technical overview of recursive functions or\ncomputability theory are advised to start there. \nExamples of recursive definitions can be found intermittently in the\nhistory of ancient and medieval mathematics. A familiar illustration\nis the sequence \\(F_i\\) of Fibonacci numbers\n\\(1,1,2,3,5,8,13, \\ldots\\) given by the recurrence \\(F_0 = 1, F_1 =\n1\\) and \\(F_{n} = F_{n-1} + F_{n-2}\\) (see\n Section 2.1.3).\n The definition of this sequence has traditionally been attributed to\nthe thirteenth century Italian mathematician Leonardo of Pisa (also\nknown as Fibonacci) who introduced it in his Liber Abaci in the context of an example involving population genetics (see\nFibonacci 1202 [2003, 404–405]). But descriptions of\nsimilar sequences can also be found in Greek, Egyptian, and Sanskrit\nsources dating as early as 700 BCE (see, e.g., Singh 1985). \nGeneral interest in recursion as a mode of function definition\noriginated in the mid-nineteenth century as part of the broader\nprogram of arithmetizing analysis and the ensuing discussions of the\nfoundations of arithmetic itself. In this context, the formulation of\nrecursive definitions for number theoretic functions was closely tied\nto the isolation of mathematical induction as a mode of reasoning\nabout the natural numbers. It was in this setting in which Grassmann\n(1861) and Peirce (1881) first gave the familiar recursive\ndefinitions of addition and\n multiplication:[1] \nThey then used these definition to prove the associative, commutative,\nand distributive laws for these\n operations.[2] \nThe first person to employ the expression “definition by\nrecursion” appears to have been Dedekind in his essay Was\nsind und was sollen die Zahlen (1888). This work presents a set\ntheoretic foundation for arithmetic wherein Dedekind demonstrated that\nit was possible to state and prove the existence and uniqueness of\nfunctions defined by primitive recursion as mathematical theorems\n(§125–126). He formulated recursive definitions of addition\n(§135), multiplication (§147), and exponentiation\n(§155) and then also formally proved by induction that the\nfunctions so defined satisfy the expected algebraic identities. The\nfirst two of these definitions would later be adopted by Peano (1889)\nas defining the symbols \\(+\\) and \\(\\times\\) in the direct\naxiomatization of arithmetic he based on Dedekind’s\nmonograph. \nThe first work devoted exclusively to recursive definability was\nSkolem’s (1923) paper  \nThe foundations of elementary arithmetic established by the recursive\nmode of thought, without the use of apparent variables ranging over\ninfinite domains.  \nThis work is significant with respect to the subsequent development of\ncomputability theory for at least three reasons. First, it contains a\ninformal description of what we now call the primitive recursive\nfunctions. Second, it can be regarded as the first place where recursive definability is linked to effective computability (see also Skolem 1946).  And third, it demonstrates that a wide range of functions and relations are primitive recursive in a manner which anticipates  Gödel’s (1931) use of primitive recursion for the arithmetization of syntax.  \n \nOne of Skolem’s stated goals was to present a logical foundation for number theory which avoids the use of unrestricted quantifiers. He was inspired in this regard by the observation that it is possible to develop much of elementary arithmetic without the use of the expressions “always” (i.e. for all) and “sometimes”  (i.e. there exists) which figure in the formalization of number theory given by Russell and Whitehead in Principia Mathematica (1910–1913).  This was to be accomplished by formulating arithmetical theorems as what he referred to as functional assertions.  These took the form of identities between terms defined by primitive recursive operations which Skolem referred to as descriptive functions.  For instance, the commutativity of addition is expressed in this form by an equation with free variables\n \nIn cases where such statements are provable in the system Skolem\ndescribes, the intended interpretation is that the claim holds\nuniversally for all natural numbers—e.g., \\(\\forall x \\forall y\n(x + y = y + x)\\). But in Skolem’s system there is no means\nof negating such a statement to express a bare existential assertion\nwithout producing a witness. \nStatements like (\\ref{funassert}) would later be referred to by\nHilbert & Bernays (1934) (who provided the first textbook treatment of recursion) as verifiable in the sense that\ntheir individual instances can be verified computationally by\nreplacing variables with concrete numerals. This is accomplished by\nwhat Skolem referred to as the “recursive mode of\nthought”. The sense of this phrase is clarified by the following properties of the system he describes:  \nTaking these principles as a foundation, Skolem showed how to obtain\nrecursive definitions of the predecessor and subtraction functions,\nthe less than, divisibility, and primality\nrelations, greatest common divisors, least common\nmultiples, and bounded sums and products which are similar to those given in   Section 2.1.2  below. \nOverall Skolem considered instances of what we\nwould now refer to as primitive recursion, course of values recursion,\ndouble recursion, and recursion on functions of type \\(\\mathbb{N}\n\\rightarrow \\mathbb{N}\\). He did not, however, introduce general schemas so as to systematically distinguish these modes of definition. Nonetheless,\nproperties i–iv of Skolem’s treatment provide a means of\nassimilating calculations like (\\ref{factcalc}) to derivations in\nquantifier-free first-order logic.  It is thus not difficult to discern in (Skolem 1923) the kernel of the system we now know as Primitive Recursive\nArithmetic (as later formally introduced by Hilbert & Bernays 1934, ch. 7). \nThe next important steps in the development of a general theory of\nrecursive function arose as a consequence of the interaction between\n Hilbert’s Program and Gödel’s\n(1931) proof of the Incompleteness Theorems.  Hilbert (1900) had announced the goal of proving the consistency of arithmetic—and ultimately also analysis and set theory— in the face of the set theoretic paradoxes.   His initial plans for carrying out such a proof are described in a series of lectures and addresses in the 1910s–1920s which provide a description of what would come to be called the finitary standpoint—i.e., the fragment of mathematical reasoning pertaining to finite combinatorial objects which was intended to serve as the secure basis for a consistency proof.   The proof itself was to be carried out using the methods of what Hilbert referred to as metamathematics—i.e., the formal study of axioms and derivations which would grow into the subject now known as proof theory. \nIn one of his initial descriptions of this program Hilbert (1905)\nsketched the basic form which a metamathematical proof of consistency\nmight take. Suppose, for instance, that \\(\\mathsf{T}\\) is a\nmathematical theory about which it is possible to prove the following\nconditional: \nWere it possible to provide a mathematical demonstration of i), it\nmight seem possible to conclude \nHowever Poincaré (1906) observed that Hilbert’s approach\n relies on mathematical induction in inferring ii from i.   He objected on this basis that this renders Hilbert’s proposed method circular in the case that the system \\(\\mathsf{T}\\) in question itself subsumes principles intended to formalize induction.[3] \nTogether with his collaborators Ackermann and Bernays, Hilbert developed metamathematics considerably during the 1910–1920s.  This served as the basis of  Hilbert’s (1922) lecture wherein he replied to Poincaré by making a systematic distinction between “formal“ occurrences of mathematical induction in the object language and the metatheoretic use of induction as a “contentual“ [inhaltliche] principle used in order to reason about proofs as finite combinatorial objects.  It was also in this context in which Hilbert connected the latter form of induction to the “construction and deconstruction of number signs” (1922, 1123). \n \nAs is made clear in subsequent presentations, Hilbert understood\n“number signs” to be unary numerals written in stroke\nnotation of the form  \nSuch expressions can be operated on concretely by adjoining or\nremoving strokes in a manner which mirrors the arithmetical operations\nof successor and predecessor which figure in Skolem’s\n“recursive mode of thought“. This observation in turn informed Hilbert’s explanation of the meaning of functional assertions like (\\ref{funassert}) in terms of their logical derivability from recursive definitions which also serve as procedures for computing the values of functions they define  (Hilbert 1920, 54–57). \nHilbert first described a logical calculus for finitary number theory\nincluding “recursion and intuitive induction for finite\ntotalities” in (1923, 1139).[4]\nAlthough this presentation also included a discussion of definition by simultaneous recursion, a more extensive  treatment of what we would now recognize as recursion schemes is given in his well known paper “On the infinite” (1926).  This includes a discussion of what Hilbert calls ordinary recursion (which is similar to Skolem’s description of primitive recursion), transfinite recursion, as well as recursion at higher types.   This treatment makes clear that Hilbert and his collaborators had taken substantial steps towards developing a general theory of recursive definability.  Ultimately, however, the influence of Hilbert’s presentations was diminished in light of the more precise formulation of primitive recursion which Gödel would soon provide.[5] \nGödel’s (1931, 157–159) definition was as\nfollows: \nA number-theoretic function \\(\\phi(x_1,\\ldots,x_n)\\) is said to be\nrecursively defined in terms of the number-theoretic\nfunctions \\(\\psi(x_1,x_2,\\ldots,x_{n-1})\\) and \\(\\mu(x_1,x_2,\\ldots,\nx_{n+1})\\) if \nholds for all \\(x_2,\\ldots,x_n,k\\). \nA number-theoretic function \\(\\phi\\) is said to be recursive\nif there is a finite sequence of number-theoretic functions \\(\\phi_1 ,\n\\phi_2 , \\ldots \\phi_n\\) that ends with \\(\\phi\\) and has the property\nthat every function \\(\\phi_k\\) of the sequence is recursively defined\nin terms of two of the preceding functions, or results from any of the\npreceding functions by substitution, or, finally, is a constant or the\nsuccessor function \\(x + 1\\)…. A relation \\(R(x_1, \\ldots ,\nx_n)\\) between natural numbers is said to be recursive if\nthere is a recursive function \\(\\phi(x_1 \\ldots , x_n)\\) such that,\nfor all \\(x_1, x_2, \\ldots, x_n\\)  \nPutting aside Gödel’s use of the term “recursive”\nrather than “primitive recursive” (which will be explained\nbelow), this exposition comes close to coinciding with the\ncontemporary definition of the primitive recursive functions given in\n Section 2.1.[6]\n Gödel’s definition also improved upon those of his\npredecessors by clearly defining the class of initial functions which\nare allowed in primitive recursive definitions and by stating that\neach primitive recursive function possesses a definition in terms of a sequence of functions showing how it is built up from initial functions. This makes clear that the primitive recursive functions constitute a mathematically well-defined class of functions on the natural numbers (which will be denoted here as  \\(\\mathbf{PR}\\)).  Gödel additionally proved that the primitive recursive relations—defined as characteristic\nfunctions via (\\ref{prch})—are closed under propositional\noperations and quantification bounded by a primitive recursive\nfunction (see  Section 2.1.2). \nThe foregoing definition appears in Gödel’s well-known\n(1931) paper “On formally undecidable propositions of\nPrincipia mathematica and related systems I”. As he\nobserves immediately before presenting it, the definition of primitive\nrecursion is in fact a digression from the main focus of the\npaper—i.e., proving the incompleteness of the axiomatic system of arithmetic he calls \\(\\mathsf{P}\\). In order to understand Gödel’s contribution to the initial development of recursive function theory, it will be useful to attend both to some features of this system and also to his proof of the First Incompleteness Theorem itself.  (Additional details and\ncontext are provided in the entry on\n Gödel’s incompleteness theorems.) \nSystem \\(\\mathsf{P}\\) is obtained from that of Whitehead and\nRussell’s Principia Mathematica (1910–1913)  by omitting the ramification of types, taking the natural numbers as the lowest type, and adding for them the second-order Peano axioms. It is hence a fixed formal system with finitely many non-logical\naxioms sufficient for the development of elementary number\n theory.[7]\nRecall also that an arithmetical system is said to be \\(\\omega\\)-consistent if it does not prove both \\(\\exists x \\varphi(x)\\) and \\(\\neg \\varphi(\\overline{n})\\) for each natural number \\(n \\in \\mathbb{N}\\) (where \\(\\overline{n} =_{\\mathrm{df}} s(s(\\ldots s(0)))\\) \\(n\\)-times) and that \\(\\omega\\)-consistency implies simple consistency (i.e., the non-derivability of a formula and its negation).\n  \nThe incompleteness theorem which Gödel proved\nstates that if \\(\\mathsf{P}\\) is ω-consistent, then there exists\na formula \\(G_{\\mathsf{P}}\\) which is undecidable in\n\\(\\mathsf{P}\\)—i.e., neither provable nor refutable from its\naxioms. In order to obtain such a formula, Gödel first demonstrated how it is possible to express various syntactic and metatheoretic properties of\n\\(\\mathsf{P}\\)-formulas and proofs as primitive recursive relations\nvia a technique which has come to be known as the arithmetization of syntax\n(see the entry on Gödel’s incompleteness theorems).\n Second, he showed that for every primitive recursive relation\n\\(R(x_1,\\ldots,x_k)\\) there exists a “class sign” (i.e.,\nformula) \\(\\varphi_R(x_1,\\ldots,x_n)\\) of \\(\\mathsf{P}\\) such that the\nfact that \\(R(x_1,\\ldots,x_n)\\) holds of (or does not hold of) a given\ntuple of numbers \\(n_1,\\ldots,n_k\\) is mirrored by the provability (or\nrefutability) in \\(\\mathsf{P}\\) of the corresponding instance of\n\\(\\varphi_R(x_1,\\ldots,x_n)\\) when the formal numeral\n\\(\\overline{n} = s(s(\\ldots s(0)))\\) (\\(n\\)-times) is substituted for \\(x_i\\)—i.e., \nAccording to the terminology Gödel would later introduce in (1934), in such a case \\(\\varphi_R(x_1,\\ldots,x_n)\\) represents\n\\(R(x_1,\\ldots,x_n)\\). In this presentation, he also generalized\nhis prior definition to say that a function \\(f(x_1,\\ldots,x_n)\\) is\nrepresentable in \\(\\mathsf{P}\\) just in case there exists a formula\n\\(\\varphi_f(x_1,\\ldots,x_k,y)\\) such that for all \\(n_1,\\ldots,x_k,m\n\\in \\mathbb{N}\\),  \nGödel’s arithmetization of syntax provides a means of\nassigning to each primitive symbol, term, formula, and proof\n\\(\\alpha\\) of \\(\\mathsf{P}\\) a unique Gödel number\n\\(\\ulcorner \\alpha \\urcorner \\in \\mathbb{N}\\) according to its\nsyntactic structure. This technique takes advantage of the familiar\nobservation that a finite sequence of numbers \\(n_1,\\ldots,n_k\\) can\nbe encoded as a product of prime powers \\(2^{n_1} \\cdot 3^{n_2} \\cdot\n\\ldots p_k^{n_k}\\) so that various correlative operations on sequences\ncan be shown to be primitive recursive—e.g., the operation which takes\ntwo numbers \\(x\\) and \\(y\\) encoding sequences and returns the code \\(x * y\\) of the result of concatenating \\(x\\) followed by \\(y\\). Gödel\nproceeded on this basis to show that a sequence of\nnotions about the syntax and proof theory of \\(\\mathsf{P}\\) are primitive recursive—e.g., the function\n\\(\\textrm{Neg}(x)\\) which returns the Gödel number of the negation of the formula\ncoded by \\(x\\) can be defined as \\(\\ulcorner \\neg \\urcorner * x\\). The\navailability of the relevant recursive definitions thus falls out\nnaturally since the inductive definitions of syntactic notions like\nwell-formed formula generalize the “construction and\ndeconstruction of number signs” in the sense described by\n Hilbert.[8] \nThe penultimate definition in Gödel’s list is the relation\n\\(\\mathsf{Proof}_{\\mathsf{P}}(x,y)\\) which holds between the\nGödel number of a \\(\\mathsf{P}\\)-formula \\(\\varphi\\) and the\nGödel number of a finite sequence of \\(\\mathsf{P}\\)-formulas\n\\(\\psi_1,\\ldots, \\psi_n\\) just in case the latter is a correctly\nformed derivation of the former from the axioms of\n\\(\\mathsf{P}\\)—i.e., \n\\(\\mathsf{Proof}_{\\mathsf{P}}(\\ulcorner \\psi_1,\\ldots, \\psi_n\n\\urcorner, \\ulcorner \\varphi \\urcorner))\\) iff \\(\\mathsf{P} \\vdash\n\\varphi\\) via a derivation \\(\\psi_1,\\ldots,\\psi_n\\) in which each\n\\(\\psi_i\\) is either an axiom of \\(\\mathsf{P}\\) or follows from prior\nformulas via its rules of inference.  \nFrom (\\ref{rep}) it follows that there exists a formula\n\\(\\textrm{Proof}_{\\mathsf{P}}(x,y)\\) of \\(\\mathsf{P}\\) which\nrepresents \\(\\mathsf{Proof}_{\\mathsf{P}}(x,y)\\) and thus also a\nformula \nGödel famously named the latter formula \\(\\sc{BEW}(x)\\) (for\nbeweisbar) as it can be understood to express that there\nexists a proof from the axioms of \\(\\mathsf{P}\\) of the formula with\nGödel number \\(y\\). But unlike the other formulas representing\nprimitive recursive relations which figure in its definition,\n\\(\\textrm{Prov}_{\\mathsf{P}}(x)\\) contains an unbounded existential quantifier.\nAnd thus as Gödel is careful to observe, there is no reason to\nexpect that it defines a primitive recursive relation. \nIt is, nonetheless, this formula which Gödel uses to construct a\nsentence which is undecidable in \\(\\mathsf{P}\\). This can be\naccomplished by the application of the so-called Diagonal Lemma\n (see Gödel’s incompleteness theorems)\n which states that for every formula \\(\\varphi(x)\\) of \\(\\mathsf{P}\\),\nthere exists a sentence \\(\\psi_{\\varphi}\\) such that  \nWhen applied to the formula \\(\\neg \\textrm{Prov}_{\\mathsf{P}}(x)\\),\nthe Diagonal Lemma yields a sentence \\(G_{\\mathsf{P}}\\)—i.e.,\nthe so-called Gödel sentence for\n\\(\\mathsf{P}\\)—such that \\(\\mathsf{P} \\vdash G_P\n\\leftrightarrow \\neg \\textrm{Prov}_{\\mathsf{P}}(\\ulcorner\nG_{\\mathsf{P}} \\urcorner)\\). \\(G_{\\mathsf{P}}\\) is thus interpretable as “saying of itself” that it is unprovable in \\(\\mathsf{P}\\).  Gödel showed that this formula has the following properties:  \nThis constitutes what is now known as Gödel’s First\nIncompleteness Theorem. \nThe proof of this fact relies explicitly on the\nrepresentability of the relation \\(\\mathsf{Proof}_{\\mathsf{P}}(x,y)\\)\nin \\(\\mathsf{P}\\) which in turn derives from its primitive\nrecursiveness. But the techniques on which Gödel’s proof relies\nalso contributed to the subsequent development of computability theory in\nseveral additional ways. First, it follows from the possibility of\nGödel numbering the formulas of \\(\\mathsf{P}\\) that we may also\neffectively enumerate them as \\(\\varphi_0(x), \\varphi_1(x),\n\\varphi_2(x), \\ldots\\)—e.g., in increasing order of \\(\\ulcorner\n\\varphi_i \\urcorner\\). This provides a mechanism for referring to\nformulas via their indices which in turn served as an important\nprecedent for Kleene’s (1936a) use of a similar indexation of\ngeneral recursive definitions in his proof of the Normal Form Theorem\n(see\n Section 2.2.2).\n Second, the proof of the Diagonal Lemma also demonstrates how it is\npossible to formalize the substitution of terms for free variables in\na manner which may be understood to yield an effective form of\nCantor’s diagonal argument\n (see the entry on self-reference).\n This technique served as an important precedent for the use of\ndiagonalization in results such as the undecidability of the Halting\nProblem (Turing 1937, see\n Section 3.2),\n the Recursion Theorem (Kleene 1938, see\n Section 3.4),\n and the Hierarchy Theorem (Kleene 1943, see\n Section 3.6).\n \nAnother significant contribution of Gödel’s paper derives\nfrom the fact that after proving the incompleteness of \\(\\mathsf{P}\\),\nhe took several steps towards isolating features of axiomatic theories which are sufficient \nto ensure that they satisfy analogous undecidability results. In addition to being sufficiently strong to\nsatisfy (\\ref{rep}), the other requirement which he identifies is that\n“the class of axioms and the rules of inference \\(\\ldots\\) are\nrecursively definable” (1931, 181). As he notes, these features\nhold both of Zermelo-Fraenkel set theory \\([\\mathsf{ZF}\\)] and a\nfirst-order arithmetical system similar to what we now call\nfirst-order Peano arithmetic \\([\\mathsf{PA]}\\), relative to an\nappropriate Gödel numbering of their axioms. In particular, while\nneither of these systems is finitely axiomatizable, they may\nbe axiomatized by a finite number of schemes (e.g., of induction or\ncomprehension) such that the relation \\(\\ulcorner \\varphi\n\\urcorner\\) is the Gödel number of an axiom of T\nis primitive recursive. \nThis observation set the stage for Gödel’s subsequent\nrevisiting of the incompleteness theorems in the lectures (1934)\nwherein he suggests a significant generalization of his original\n(1931) definition of recursiveness. Gödel starts out by providing\nthe following informal characterization of the requirements of the\ntheories just described: \nWe require that the rules of inference, and the definitions of\nmeaningful formulas and axioms, be constructive; that is, for each\nrule of inference there shall be a finite procedure for determining\nwhether a given formula \\(B\\) is an immediate consequence (by that\nrule) of given formulas \\(A_1, \\ldots, A_n\\) and there shall be a\nfinite procedure for determining whether a given formula \\(A\\) is a\nmeaningful formula or an axiom. (Gödel 1934, 346) \nHe also makes clear that what he calls “recursiveness” is\nto be initially regarded as an informal notion which he is\nattempting to make precise: \nRecursive functions have the important property that, for each given\nset of values of the arguments, the value of the function can be\ncomputed by a finite procedure. Similarly, recursive relations\n(classes) are decidable in the sense that, for each given\n\\(n\\)-tuple of natural numbers, it can be determined by a finite\nprocedure whether the relation holds or does not hold (the number\nbelongs to the class or not), since the representing function is\ncomputable. (Gödel 1934, 348) \nOne of Gödel’s goals was thus to provide a mathematical\ndefinition of the term “recursive” which generalizes prior\nexamples of recursive definability in a manner but also captures to as great an extent as possible the class of functions computable by a finite procedure. This led him to define the so-called general recursive functions\n(see\n Section 1.5)\n whose isolation in turn played an important role in the formulation\nof Church’s Thesis (see\n Section 1.6).\n However Gödel’s definition also took place against the\nbackdrop of other work which had been inspired by Hilbert’s\noriginal consideration of different forms of recursive definitions. It\nwill now be useful to examine these developments. \nAlready at the time of (1926), Hilbert had anticipated that it would be\npossible to formulate definitions of functions whose values could be\ncomputed in a recursive manner but which are not themselves primitive\nrecursive. In order to illustrate how such a definition might be\nobtained, he presented a heuristic argument involving the following\nsequence of functions: \nThe functions in this sequence are defined so that\n\\(\\alpha_{i+1}(x,y+1)\\) is obtained by primitive recursion as\n\\(\\alpha_i(\\alpha_{i+1}(x,y),x)\\), together with an appropriate base\ncase. It thus makes sense mathematically to consider the function  \nwherein the first argument \\(i\\) represents the position of the\nfunction \\(\\alpha_i(x,y)\\) in the prior list. For fixed \\(i,n,m \\in\n\\mathbb{N}\\) it is thus possible to effectively compute the value of\n\\(\\alpha(i,n,m)\\) by first constructing the definition of\n\\(\\alpha_i(x,y)\\) and then evaluating it at \\(n,m\\). But it is\nalso easy to see that \\(\\alpha_{i+1}(x,x)\\) will eventually dominate\n\\(\\alpha_i(x,x)\\) for sufficiently large \\(x\\). This in turn suggests\nthat \\(\\alpha(i,x,y)\\) cannot be defined by a finite number of\napplications of the primitive recursion scheme and is thus not itself\nprimitive recursive. \nThe specification of \\(\\alpha(i,x,y)\\) just given does not itself have\nthe form of a recursive definition. But it is possible to define\nsimilar functions in a manner which generalizes the format of the\nscheme (\\ref{gprimrec}). One means of doing so is to first use\nrecursion on the type \\(\\mathbb{N} \\rightarrow \\mathbb{N}\\)—a\nsimple form of recursion at higher types as envisioned by Skolem and \nHilbert—to define an iteration functional as follows:\n \n\\(\\mathcal{Iter}\\) takes as arguments a function \\(\\phi:\\mathbb{N}\n\\rightarrow \\mathbb{N}\\) as well as a number \\(x \\in \\mathbb{N}\\) and\nis defined so that \\(\\mathcal{Iter}(\\phi,n) =\n\\phi^{n+1}(x)\\)—i.e., the function which is the \\(n\\)th\niterate of \\(\\phi\\). We may now define a function \\(\\beta\\) of type\n\\(\\mathbb{N} \\rightarrow (\\mathbb{N} \\rightarrow \\mathbb{N})\\) as\nfollows:  \nIt can then be verified that  \nOn this basis, we may now define a variant of the so-called\nAckermann-Péter function as \\(\\pi(i,x) =\n\\beta(i)(x)\\)—i.e., the result of applying the function\n\\(\\beta(i)\\) to the argument \\(x\\). \\(\\pi(i,x)\\) has the same order of\ngrowth as \\(\\alpha_i(x,x)\\) and it is possible to prove via the\nargument sketched above that \\(\\pi(i,x)\\) is not primitive recursive\n(see, e.g., Péter 1967, ch. 9). Based on earlier work of Ackermann\n(1928), Péter (1935) also showed that \\(\\pi(i,x)\\) may also be\ndefined by a so-called doubly recursive definition of the\nfollowing form which takes only natural numbers as\n arguments:[9] \nThe third clause in this definition defines the value of \\(\\pi(i,x)\\)\nin terms of the value \\(\\pi(i,x-1)\\) rather than \\(\\pi(i-1,x-1)\\) in\nanalogy with the scheme (\\ref{gprimrec}). It may thus not be\nimmediately obvious that the definition (\\ref{pidef}) describes an\nalgorithm for computing the values of \\(\\pi(i,x)\\) which always\nterminates in the manner illustrated by the calculation\n(\\ref{factcalc}). Note, however, with each recursive application\neither \\(i\\) decreases, or \\(i\\) remains the same and \\(x\\)\ndecreases. It thus follows that each time \\(x\\) reaches 0, \\(i\\)\nwill start to decrease so that the base case is eventually reached.\nThus although the value of \\(\\pi(i,x)\\) grows very rapidly—e.g.,\n\\(\\pi(4,3) = 2^{2^{65536}}-3\\)—it is still reasonable to regard\n(\\ref{pidef}) as satisfying\nGödel’s requirement that a recursively defined function is\ncomputable by a finite procedure. \nSystematic consideration of such alternative recursion schemes\nexemplified by (\\ref{pidef}) was initiated by Péter (1932). It\nwas also she who introduced the term “primitive recursive”\nto describe the class of functions given by Gödel’s scheme\n(\\ref{gprimrec}), a choice which would become standard after its\nadoption by Kleene (1936a). Péter additionally showed that\nHilbert’s (1926) formulation of “ordinary recursion”\nis equivalent to primitive recursion, and that the primitive recursive\nfunctions are closed under course of values recursion, as well as\nso-called nested recursions of one variable. Such studies led\nto her book (Péter 1967), whose original German edition\nRekursive Funktionen (1951) was the first monograph devoted\nto recursive functions. Together with the later work of Grzegorczyk\n(1953), these developments also inspired the investigation of various\nsubrecursive hierarchies which would later play a role in proof theory\nand computer science.[10] \nThe immediate source for Gödel’s discussion of recursion in 1934 was not Ackermann or Péter’s work but rather a private communication with Herbrand, who in two previous papers (1930, 1932) had proposed a related means of generalizing recursive definitions.\nGödel’s informal description of Herbrand’s suggestion\nwas as follows:[11] \nIf \\(\\phi\\) denotes an unknown function, and \\(\\psi_1,\\ldots,\\psi_k\\)\nare known functions, and if the \\(\\psi\\)’s and \\(\\phi\\) are\nsubstituted in one another in the most general fashions and certain\npairs of the resulting expressions are equated, then, if the resulting\nset of functional equations has one and only one solution for\n\\(\\phi\\), \\(\\phi\\) is a recursive function. (Gödel 1934, 308) \nAs an illustration, consider the following set of equations:  \nIn this case, the “unknown” function denoted by\n\\(\\phi(x)\\) is specified in terms of the auxiliary function\n\\(\\psi(x)\\) in such a way that \\(\\phi(x)\\) appears only once on the\nlefthand side of the equations (other than the base case).\nNonetheless, such a system of equations is unlike a primitive\nrecursive definition in that it does not specify a unique means for\ncomputing the values of \\(\\phi(n)\\) by “deconstructing”\n\\(n\\) in the deterministic manner illustrated by calculations such\nas (\\ref{factcalc}). \nIn the general case there is indeed no guarantee that there will exist\na unique extensional function satisfying such a definition. But in\nthe case of this example it can be shown that \\(2 \\times x\\) is the unique\nfunction of type \\(\\mathbb{N} \\rightarrow \\mathbb{N}\\) satisfying\n\\(\\phi(x)\\) in the system of equations (\\ref{genrecex}). This may be\nillustrated by considering the following calculation of\n\\(\\phi(2)\\): \nAs Gödel notes, such a calculation may be understood as a\nderivation in quantifier-free first-order logic wherein the only rules\nwhich are allowed are the substitution of numerals for variables and\nthe replacement of a term on the righthand side of an equation by a\nnumeral for which the corresponding identity has already been\nderived. \nGödel introduced the term general recursive to describe\na function defined in this manner. Following the modernized\npresentation of Odifreddi (1989, ch. I.2) this class may be specified on\nthe basis of the following initial\n definitions:[12] \nDefinition 1.1 \nThe class of numerals is the smallest set containing 0 and\nclosed under the successor function \\(x \\mapsto s(x)\\). We write\n\\(\\overline{n}\\) for the numeral \\(s(s(\\ldots s(0)))\\)\n\\(n\\)-times. \nThe class of terms is the smallest set containing the\nnumerals, variables \\(x_0,x_1, \\ldots\\) and closed under the\noperations \\(t \\mapsto s(t)\\) and \\(t_1,\\ldots,t_n \\mapsto\n\\psi^n_i(t_1,\\ldots,t_n)\\) where \\(t,t_1,\\ldots,t_n\\) are terms and\n\\(\\psi^n_i\\) is a primitive \\(n\\)-ary functional symbol. \nIf \\(t\\) and \\(u\\) are terms and \\(t\\) is of the form\n\\(\\psi^n_i(t_1,\\ldots,t_n)\\) where \\(t_1,\\ldots,t_n\\) do not contain\nany functional symbols other than \\(s\\), then \\(t = u\\) is an\nequation. \nA system of equations is a finite set of equations.\n\\(\\mathcal{E}(\\psi_1,\\ldots,\\psi_n,\\vec{x})\\) will be used to denote a\nsystem of equations containing primitive functional symbols\n\\(\\psi_1,\\ldots,\\psi_n\\) and variables among \\(\\vec{x} = x_1,\\ldots,\nx_k\\). \nHerbrand (1932) gave a semantic characterization of what it means for\na number theoretic function \\(f\\) to be defined by a system of\nequations \\(\\mathcal{E}(\\psi_1,\\ldots,\\psi_n,\\vec{x})\\) by requiring\nboth that there is a solution to the system and that \\(f\\) coincides\nwith the function determined as \\(\\psi_1\\) for every solution. He also\nsuggested that this fact should be proved intuitionistically, which\nmight in turn be thought to yield an effective procedure for computing\nthe values of\n \\(f\\).[13]\n He did not, however, specify a formal system in which such a proof\nshould be carried out. And thus Gödel suggested (essentially) the\nfollowing syntactic replacement for Herbrand’s definition: \nDefinition 1.2: A function \\(f:\\mathbb{N}^k\n\\rightarrow \\mathbb{N}\\) is general recursive if there is a\nsystem of equations \\(\\mathcal{E}(\\psi_1,\\ldots,\\psi_n,\\vec{x})\\) such\nthat if \\(\\psi^k_i\\) is the leftmost functional symbol in the last\nequation of \\(\\mathcal{E}\\) then for all \\(n_1,\\ldots,n_k, m \\in\n\\mathbb{N}\\) \nif and only if the equation \nis derivable from the equations comprising \\(\\mathcal{E}\\) via the\nfollowing two rules: \nIn such a case we say that \\(\\mathcal{E}\\) defines \\(f\\) with\nrespect to \\(\\psi^k_i\\).  \nIt can be verified that the system of equations (\\ref{genrecex}) and\nthe derivation (\\ref{genreccal}) exhibited above satisfy the foregoing\nrequirements, thus illustrating how it is possible to mechanically calculate using a system of general recursive equations.  However certain systems—e.g., \\(\\{\\phi(x) = 0, \\phi(x) =\ns(0)\\}\\)—are inconsistent in the sense of not being satisfied by\nany function on the natural numbers, while\nothers—e.g., \\(\\{\\phi(x) = \\phi(x)\\}\\)—are not satisfied\nuniquely. One evident drawback of Gödel’s definition of\ngeneral recursiveness is thus that there is no apparent means of\nestablishing whether a given system of equations \\(\\mathcal{E}\\)\ndetermines a unique function (even if only partially defined).   This is one of the reasons why Gödel’s characterization has been replaced by other extensionally equivalent definitions such as Kleene’s partial recursive functions  (see\n Section 2.2)\n in the subsequent development of computability theory. \nBy formalizing his informal characterization of recursiveness via\n Definition 1.2,\n Gödel succeeded in formulating a definition which subsumes the\nprimitive recursion scheme (\\ref{gprimrec}), the definition of the\nAckermann-Péter function, as well as several other schemes\nconsidered by Hilbert. Gödel’s definition of general\nrecursiveness thus also defined a class \\(\\mathbf{GR}\\) of functions of type\n\\(\\mathbb{N}^k \\rightarrow \\mathbb{N}\\) which properly subsumes the primitive recursive functions  \\(\\mathbf{PR}\\).  Moreover, we now know that the class of functions representable in \\(\\mathsf{P}\\) (and in fact in far weaker arithmetical\nsystems) corresponds not to the primitive recursive functions, but\nrather to the general recursive functions. Weakening the hypothesis\nthat the set of (Gödel numbers) of the axioms of a formal system\nto the requirement that they be general recursive rather than\nprimitive recursive thus indeed provides a generalization of the First\nIncompleteness Theorem the manner in which Gödel envisioned. \nThe definition of \\(\\mathbf{GR}\\) is also of historical importance because\nit was the first among several equivalent (and nearly\ncontemporaneous) definitions of what were originally called the\nrecursive functions but are now often referred to as the\ncomputable functions (see\n Section 2.2).\n These developments also contributed to one of the two final chapters in the study of recursive definability prior to the initiation of computability theory\nas an independent subject—i.e., the isolation and eventual\nadoption of what is now known as Church’s Thesis. \nChurch’s Thesis corresponds to the claim that the class of\nfunctions which are computable by a finite mechanical\nprocedure—or, as it is traditionally said, are effectively\ncomputable—coincides with the class of general recursive\nfunctions—i.e., \nIt may appear that Gödel already proposed a version of\nChurch’s Thesis in 1934. However, he did not immediately endorse\nit upon its first explicit articulation by\n Church.[14]\n And since the surrounding history is complex it will be useful to\nrecord the following observations as a prelude to\n Sections 2 and 3.[15]\n (See also the entries on\n Church’s Thesis\n and\n computational complexity theory.) \nGödel delivered the lectures (Gödel 1934) while he was\nvisiting Princeton in the spring of 1934. Already at that time Church,\ntogether with his students Kleene and Rosser, had made substantial\nprogress in developing the formal system of function application and\nabstraction now known as the untyped lambda calculus. This\nsystem also provides a means of representing natural numbers as formal\nterms—i.e., as so-called Church numerals. This leads to\na notion of a function being lambda-definable \nwhich is similar in form to (\\ref{repfun}). Church’s definition\nthus also characterize a class \\(\\mathbf{L}\\) of lambda-definable\nfunctions which is similar in form to that of \\(\\mathbf{GR}\\). During this\nperiod, Kleene demonstrated that a wide range of number theoretic\nfunctions were included in \\(\\mathbf{L}\\), in part by showing how it is possible to   implement primitive recursion in the lambda calculus. This ultimately led Church to propose in early 1934 that the lambda-definable functions coincide\nwith those possessing the property which he called “effective\n calculability”.[16] \nA natural conjecture was thus that lambda-definability coincided\nextensionally with general recursiveness. Unlike (CT)—which\nequates an informally characterized class of functions with one possessing a precise mathematical definition—the statement \\(\\mathbf{GR} =\n\\mathbf{L}\\) potentially admits to formal demonstration. Such a demonstration\nwas given by Church (1936b; and in greater detail by Kleene 1936b)\nproviding the first of several extensional equivalence results which\nKleene (1952, sec. 62) would eventually cite as evidence of what he\nproposed to call “Church’s Thesis”. \nChurch’s Thesis underlies contemporary computability theory in\nthe sense that it justifies the assumption that by studying computability relative to a single formalism (such as \\(\\mathbf{GR}\\)  or \\(\\mathbf{L}\\)) we are thereby providing a general account of which functions can and\ncannot be effectively computed in principle by an algorithm. In light of this, it will\nbe useful to catalog some additional evidence for Church’s\nThesis in the form of the equivalence of \\(\\mathbf{GR}\\)  with several other\ncomputational formalisms presented in the Stanford Encyclopedia: \nLet \\(\\mathsf{T}\\) be a consistent, computably axiomatizable theory\nextending \\(\\mathsf{Q}\\) (i.e., Robinson arithmetic). Then the class\nof functions \\(\\mathbf{F}_{\\mathsf{T}}\\) which is representable in\n\\(\\mathsf{T}\\) in the sense of (\\ref{repfun}) above (with\n\\(\\mathsf{T}\\) replacing \\(\\mathsf{P}\\)) is such that\n\\(\\mathbf{F}_{\\mathsf{T}} = \\mathbf{GR}\\). (See\n representability in the entry on Gödel’s incompleteness theorems\n and Odifreddi (1989, ch. I.3).) \nThe class \\(\\mathbf{REC}\\)  consisting of the total functions which are\nmembers of the class of partial recursive functions (formed\nby closing the class \\(\\mathbf{PR}\\)  under the unbounded minimization\noperation) is such that \\(\\mathbf{REC} = \\mathbf{GR}\\). (See\n Section 2.2.1\n and Odifreddi (1989, ch. I.2).) \nThe class \\(\\mathbf{CL}\\) of functions representable in\n Combinatory Logic\n (a formal system related to the lambda calculus) is such that\n\\(\\mathbf{CL} = \\mathbf{GR}\\). (See\n computable functions and arithmetic in the entry on combinatory logic\n and Bimbó (2012, ch. 5.3).) \nThe class \\(\\mathbf{T}\\) of functions computable by a\n Turing machine\n (under several variants of its definition) is such that \\(\\mathbf{T}\n= \\mathbf{GR}\\). (See\n alternative historical models of computability in the entry on Turing machines\n and Odifreddi (1989, ch. I.4).) \nThe class \\(\\mathbf{U}\\) of functions computable by Unlimited\nRegister Machines introduced by Shepherdson & Sturgis (1963)\nis such that \\(\\mathbf{U} = \\mathbf{GR}\\). (See Cutland (1980, ch.\n1–3) and Cooper (2004, ch. 2).) \nEquivalence results of these forms testify to the mathematical\nrobustness of the class \\(\\mathbf{GR}\\) and thereby also to that of the informal notion of effective computability itself. As we have seen, Gödel was\noriginally led to the formulation of general recursiveness by\nattempting to analyze the background notion of recursive definition as\na model of effective computation as inspired by the foundational\ndevelopments of the late nineteenth and early twentieth\n centuries.[17]\n Further discussion of how the work of Church, Turing, and Post can be\nseen as providing independently motivated analyses of computability\nwhich also support Church’s Thesis can be found in Gandy (1980)\nand Sieg (1994, 1997, 2009). \nIn addition to the goal of widening the scope of\nGödel’s Incompleteness Theorems, another motivation for\nwork on recursive functions during the 1930s was the study of\nso-called undecidable (or unsolvable)\nproblems. The original example of such a problem was that of\ndetermining whether a given formula \\(\\varphi\\) of first-order logic\nis valid—i.e., true in all of its models. This was\nfirst described as the Entscheidungsproblem (or\ndecision problem) for first-order logic by Hilbert &\nAckermann in their textbook Grundzüge der theoretischen Logik (1928):[18] \nThe Entscheidungsproblem is solved if one knows a procedure,\nwhich permits the decision of the universality [i.e., validity] or\nsatisfiability of a given logical expression by finitely many\noperations. The solution of the problem of decision is of fundamental\nimportance to the theory of all domains whose propositions can be\nlogically described using finitely many axioms. (Hilbert &\nAckermann 1928,\n 73)[19] \nThis passage illustrates another sense in which the question of the\ndecidability of logical derivability is connected to the concerns\nwhich had initiated Hilbert’s study of metamathematics. For note\nthat if \\(\\Gamma\\) is a finite set of axioms\n\\(\\{\\gamma_1,\\ldots,\\gamma_k\\}\\), then the question of whether\n\\(\\psi\\) is a logical consequence of \\(\\Gamma\\) is equivalent to\nwhether the sentence \\(\\varphi=_{\\textrm{df}} (\\gamma_1 \\wedge \\ldots\n\\wedge \\gamma_k) \\rightarrow \\psi\\) is logically valid. By\n Gödel’s Completeness Theorem (see the entry on Gödel)\n for first-order logic, this is equivalent to the derivability of\n\\(\\varphi\\) from Hilbert & Ackermann’s axiomatization\nof first-order logic. A positive answer to the\nEntscheidungsproblem could thus be interpreted as showing\nthat it is possible to mechanize the search for proofs in mathematics\nin the sense of allowing us to algorithmically determine if a formula expressing an open question (e.g. the Riemann Hypothesis) is a logical consequence of a suitably powerful finitely axiomatized theory (e.g.,\nGödel-Bernays set theory). \nIn addition to analyzing the notion of effective computability itself,\nthe mathematical goal of both Turing (1937) and Church (1936a,b) was\nto provide a mathematically precise negative answer to the\nEntscheidungsproblem. The answers which they provided can be\nunderstood as proceeding in three phases:  \nThe first of these steps can be undertaken by defining  \nwhere \\(\\ulcorner \\cdot \\urcorner\\) is a Gödel numbering of the\nlanguage of \\(\\varphi\\) as described in\n Section 1.3.\n The second step of Turing and Church’s negative answer to the\nEntscheidungsproblem relied on their prior specification of\nsimilar decision problems for the models \\(\\mathbf{T}\\),\n\\(\\mathbf{L}\\), and \\(\\mathbf{GR}\\). Together with Kleene (1936a), they\nshowed the following: \nProposition 1.1: The characteristic functions of the\nfollowing sets are not computable with respect to the relevant model: \n\\(\\HP_T = \\{\\langle i,n \\rangle : \\text{the Turing machine $T_i$ halts\non input $n$}\\}\\) \n\\(\\HP_L = \\{\\ulcorner M \\urcorner : \\text{the untyped $\\lambda$-term\n$M$ has a normal form}\\}\\) \n\\(\\HP_{\\textit{GR}} = \\{\\ulcorner \\mathcal{E} \\urcorner :\\) the system\nof equations \\(\\mathcal{E}\\)-term determines a general recursive\nfunction\\(\\}\\) \nFor instance, Part i of\n Proposition 1.1\n shows that there is no Turing machine which outputs 1 if \\(T_i\\)\nhalts on \\(n\\) and 0 otherwise. This is thus a formulation of\nTuring’s well-known\n unsolvability of the Halting Problem (see the entry on Turing machines).\n Part ii and iii would also now be described as expressing that the\nsets \\(\\HP_T,\\) \\(\\HP_L,\\) and \\(\\HP_{\\textit{GR}}\\) are all\nundecidable. By taking into account the equivalence results\nsummarized in\n Section 1.6,\n Proposition 1.1 thus shows that membership in these sets cannot be\ndecided relative to any of the models in question. \nOn this basis, Turing (for \\(\\mathbf{T}\\)) and Church (for\n\\(\\mathbf{L}\\) and \\(\\mathbf{GR}\\)) then proved the following: \nProposition 1.2: If \\(V\\) were decidable (with\nrespect to any of the models in question), then \\(\\HP_T, \\HP_L\\), and\n\\(\\HP_{GR}\\) would be as well. \nThe proofs which Turing and Church gave of these facts are\nconstructive in the sense that they show how to effectively transform\nan individual instance of one of the models into a first-order formula\nsuch that the formula is valid if and only if the instance possesses\nthe property in question—e.g., given a Turing machine \\(T_i\\)\nand input \\(n \\in \\mathbb{N}\\), we construct a formula\n\\(\\varphi_{i,n}\\) such that the computation \\(T_i(n)\\) halts if and\nonly if \\(\\varphi_{i,n}\\) is valid. This method thus anticipates the\ndefinition of  many-one reducibility given in\n Section 3.5.1\n below. \nIn conjunction with the other arguments which Church and Turing had\nalready offered in favor of Church’s Thesis (see\n Section 1.6),\n Propositions\n 1.1\n and\n 1.2\n can thus be taken to show that the Entscheidungsproblem is\nindeed not decidable in the informal sense described by Hilbert &\nAckermann (1928)—i.e., not decidable by a “mechanical\nprocedure using finitely many operations”. As we will see in\n Section 3, the desire to develop a general theory of such undecidability results and the relations which they bear to one another was an important motivation for the further development of computability theory starting in the 1940s. \nThe developments just described form part of the prehistory of the\nsubfield of  contemporary mathematical logic which was originally known as\nrecursive function theory (or more simply as recursion\ntheory). This subject was initiated in earnest by Kleene, Turing,\nand Post starting in the late 1930s, directly on the basis of the\npapers containing the equivalence and undecidability results\nsummarized in\n Section 1.6\n and\n Section 1.7.\n Of particular importance are the papers (1936a, 1938, 1943,\n1955a,b,c) of Kleene. These respectively contain the definition of the\npartial recursive functions, the proof of their equivalence to\n\\(\\mathbf{GR}\\), the Normal Form Theorem, the Recursion Theorem, and the\ndefinitions of the arithmetical and analytical hierarchies. Of equal\nimportance are the papers (1937, 1939) of Turing (which\nrespectively contain the undecidability of the Halting Problem and the\ndefinition of Turing reducibility) and the paper (1944) of\nPost (which introduced many-one and one-one reducibility and formulated what would come to be\nknown as Post’s Problem). \nThese developments will be surveyed in\n Section 3.\n As we will see there, an important theme in the early stages of\ncomputability theory was the characterization of a notion of effective\ncomputability which is capable of supporting rigorous proofs grounded\nin intuitions about algorithmic calculability but which abstracts away\nfrom the details of the models mentioned in\n Section 1.6.\n To this end, Gödel’s original definition of the general\nrecursive equations was replaced in early textbook treatments (e.g.,\nShoenfield 1967, Rogers 1987) by Kleene’s definition of the\npartial recursive functions in terms of the unbounded minimization\noperator introduced in\n Section 2.2.\n This characterization has in turn been replaced by machine-based\ncharacterizations such as those of Turing (1937) or Shepherdson &\nSturgis (1963) in later textbooks (e.g., Soare 1987, Cutland 1980)\nwhich are closer in form to informally described computer\nprograms. \nWhat is retained in these treatments is an understanding of\ncomputation as a means of operating in an effective manner on finite\ncombinatorial objects which can still be understood to fall under\nthe “recursive mode of thought” as understood by early\ntheorists such as Skolem, Hilbert, Gödel, and Péter. But\nat the same time, many of the basic definitions and results in\nrecursive function theory are only indirectly related to recursive\ndefinability in the informal sense described in this section.\n In light of this, Soare (1996) proposed that recursive function theory should be\nrenamed computability theory and that we should\naccordingly refer to what were traditionally known as the\nrecursive functions as the computable functions. \nSuch a change in terminology has been largely adopted in contemporary\npractice and is reflected in recent textbooks such as Cooper (2004)\nand Soare (2016). Nonetheless, both sets of terminology are still\nwidely in use, particularly in philosophical and historical\nsources. Readers are thus advised to keep in mind the\nterminological discussion at the beginning of\n Section 3. \nNB: Readers looking for a mathematical overview of recursive\nfunctions are advised to start here. Discussion of the historical \ncontext for the major definitions and results of this section can be\nfound in Section 1. \nThis section presents definitions of the major classes of recursively\ndefined functions studied in computability theory. Of these the\nprimitive recursive functions \\(\\mathbf{PR}\\) and the partial recursive\nfunctions \\(\\mathbf{PartREC}\\) are the most fundamental. The former are\nbased on a formalization of the process of recursion described in the\nintroduction to this entry and include virtually all number theoretic\nfunctions studied in ordinary mathematics. The partial recursive functions are\nformed by closing the primitive recursive functions under the\noperation of unbounded minimization—i.e., that of\nsearching for the smallest witness to a decidable predicate.  The class of  recursive functions  \\(\\mathbf{REC}\\)—i.e., the partial recursive functions which are defined on all inputs—has traditionally been taken to correspond via Church’s Thesis\n (Section 1.6) to those which can be effectively computed by an algorithm.\n \nThe following notional conventions will be employed in the remainder\nof this entry: \n\\(\\mathbb{N} =\\{0,1,2,\\ldots\\}\\) denotes the set of natural numbers,\n\\(\\mathbb{N}^k\\) denotes the cross product \\(\\mathbb{N} \\times \\ldots\n\\times \\mathbb{N}\\) \\(k\\)-times, and \\(\\vec{n}\\) denotes a vector\nof fixed numbers \\(n_0,\\ldots,n_{k-1}\\) (when the arity is clear from\ncontext). \nLowercase Roman letters \\(f,g,h,\\ldots\\) denote functions of type\n\\(\\mathbb{N}^k \\rightarrow \\mathbb{N}\\) (for some\n\\(k\\))—i.e., the class of functions with domain\n\\(\\mathbb{N}^k\\) and range \\(\\mathbb{N}\\). For a fixed \\(j\\),\n\\(f:\\mathbb{N}^j \\rightarrow \\mathbb{N}\\) expresses that \\(f\\) is a\n\\(j\\)-ary function (or has arity\n\\(j\\))—i.e., \\(f\\) has domain \\(\\mathbb{N}^j\\) and range\n\\(\\mathbb{N}\\). \n\\(x_0,x_1,x_2, \\dots\\) are used as formal variables over\n\\(\\mathbb{N}\\) for the purpose of indicating the argument of functions.\n\\(x,y,z,\\ldots\\) will also be used informally for arbitrary variables\nfrom this list. \\(\\vec{x}\\) will be used to abbreviate a vector of\nvariables \\(x_0,\\ldots,x_{k-1}\\) (when the arity is clear from\ncontext). \nBoldface letters \\(\\mathbf{X}, \\mathbf{Y}, \\mathbf{Z},\\ldots\\) (or\nabbreviations like \\(\\mathbf{PR}\\)) will be used to denote classes of\nfunctions which are subsets of \\(\\bigcup_{k \\in \\mathbb{N}}(\n\\mathbb{N}^k \\rightarrow \\mathbb{N})\\). \nCalligraphic letters \\(\\mathcal{F},\\mathcal{G},\\mathcal{H},\\ldots\\)\n(or abbreviations like \\(\\mathcal{Comp}^j_k\\)) will be used to denote\nfunctionals on \\(\\mathbb{N}^k \\rightarrow\n\\mathbb{N}\\)—i.e., operations which map one or more functions of\ntype \\(\\mathbb{N}^k \\rightarrow \\mathbb{N}\\) (possibly of different\narities) to other functions. \nUppercase letters \\(R,S,T, \\ldots\\) will be used to denote\nrelations—i.e., subsets of \\(\\mathbb{N}^k\\)—with\nthe range \\(A,B,C, \\ldots\\) reserved to denote unary\nrelations—i.e., subsets of \\(\\mathbb{N}\\). \nThe characteristic function of a relation \\(R \\subseteq\n\\mathbb{N}^k\\) is denoted by\n\\(\\chi_R(x_0,\\ldots,x_{k-1})\\)—i.e.,  \nA class \\(\\mathbf{X}\\) of recursively defined functions may be\nspecified by giving a class of initial functions \\(I_{\\mathbf{X}}\\)\nwhich is then closed under one or more functionals from a class\n\\(Op_{\\mathbf{X}}\\). It is in general possible to define a class in\nthis manner on an arbitrary set of initial functions. However, all of the\nfunction classes considered in this entry will determine functions of\ntype \\(\\mathbb{N}^k \\rightarrow \\mathbb{N}\\)—i.e., they will\ntake \\(k\\)-tuples of natural numbers as inputs and (if defined)\nreturn a single natural number as output. \nIn the case of the primitive recursive functions \\(\\mathbf{PR}\\), the initial\nfunctions include the nullary zero function \\(\\mathbf{0}\\) which\nreturns the value 0 for all inputs (and can thus be treated as a constant\nsymbol), \\(s(x)\\) denotes the unary successor function \\(x\n\\mapsto x + 1\\), and \\(\\pi^k_i\\) denotes the \\(k\\)-ary\nprojection function on to the \\(i\\)th argument (where \\(0\n\\leq i < k\\))—i.e.,  \nThis class of functions will be denoted by \\(I_{\\mathbf{PR}} =\n\\{\\mathbf{0}, s, \\pi^k_i\\}\\). Note that since\n\\(\\pi^k_i\\) is a distinct function for each \\(i,k \\in \\mathbb{N}\\),\n\\(I_{\\mathbf{PR}}\\) already contains infinitely many functions. \nThe functionals of \\(\\mathbf{PR}\\) are those of composition and\nprimitive recursion. Composition takes \\(j\\) functions \\(g_0,\n\\ldots, g_{j-1}\\) of arity \\(k\\) and a single function \\(f\\) of\narity \\(j\\) and returns their composition—i.e., the\nfunction  \nof type \\(\\mathbb{N}^k \\rightarrow \\mathbb{N}\\). As an example,\nsuppose that \\(f\\) is the multiplication function \\(\\textit{mult}(x,y)\\), \\(g_0\\) is the constant 3 function (which we may think of as implicitly taking a single argument), and \\(g_1(x)\\) is the successor function \\(s(x)\\). Then the composition of \\(f\\) with \\(g_0\\) and \\(g_1\\) is the unary function \\(h(x) = f(g_0(x),g_1(x)) = mult(3, s(x))\\) which we would conventionally denote by \\(3 \\times (x+1)\\). \nThe operation of composition may be understood as a class of\nfunctionals which for each \\(j,k \\in \\mathbb{N}\\) takes as inputs\n\\(j\\) functions \\(g_0, \\ldots, g_{j-1}\\) of arity \\(k\\) and a single\nfunction \\(f\\) of arity \\(j\\) and returns as output the\n\\(k\\)-ary function \\(h\\) which composes these functions in the manner\njust illustrated. This is described by the following scheme: \nDefinition 2.1: \n\nSuppose that \\(f:\\mathbb{N}^j \\rightarrow \\mathbb{N}\\) and \\(g_0, \\ldots, g_{j-1} : \\mathbb{N}^k \\rightarrow \\mathbb{N}\\). Then the term \\(\\mathcal{Comp}^j_k[f,g_0,\\ldots,g_{j-1}]\\) denotes the function \nof type \\(\\mathbb{N}^k \\rightarrow \\mathbb{N}.\\) \nPrimitive recursion is also a functional operation. In the simplest\ncase, it operates by taking a single unary function \\(g(x)\\) and a\nnatural number \\(n \\in \\mathbb{N}\\) and returns the unary function\ndefined by  \nIn such a definition, the first clause (known as the base\ncase) determines the value of \\(h\\) at 0, while the second clause\ndetermines how its value at \\(x+1\\) depends on its value at \\(x\\). In\nthis case it is easy to see that the value of \\(x\\) determines how\nmany times the function \\(g\\) is iterated (i.e., applied to\nitself) in determining the value of \\(h\\). For instance, if \\(n = 3\\)\nand \\(g(x) = mult(x,x)\\), then \\(h(x) = 3^{x+1}\\)—i.e., the\n\\(x+1\\)st iterate of the map \\(x \\mapsto 3 \\times x\\). \nThe full primitive recursion scheme generalizes (\\ref{prex1}) in two\nways. First, it allows the value of the function \\(h\\) at \\(x+1\\) to\ndepend not just on its own value at \\(x\\), but also on the value\nof the variable \\(x\\) itself. This leads to the scheme  \nFor instance, the definition of the factorial function \\(\\fact(x)\\)\ndefined in the introduction to this entry can be obtained via\n(\\ref{prex2}) with \\(n = 1\\) and \\(g(x_0,x_0) =\ntimes(s(x_0),x_0)\\). \nA second possible generalization to (\\ref{prex1}) results from\nallowing the value of \\(h\\) to depend on a finite sequence of\nauxiliary variables known as parameters which may also be\narguments to the base case. In the case of a single parameter \\(x\\),\nthis leads to the scheme  \nThe addition function \\(\\textit{add}(x,y)\\) may, for instance, be\ndefined in this way by taking \\(f(x_0) = x_0\\) and \\(g(x_0,x_1) =\ns(x_1)\\). This definition can also be thought of as specifying that\nthe sum \\(x+y\\) is the value obtained by iterating the application of the successor function \\(y\\) times starting from the initial value \\(x\\) in the manner of (\\ref{prex1}).\nSimilarly, \\(\\textit{mult}(x,y)\\) may be defined by taking \\(f(x_0) =\n0\\) and \\(g(x_0,x_1) = add(x_0,x_1)\\). This defines the product \\(x\n\\times y\\) as the value obtained by iterating the function\nwhich adds \\(x\\) to its argument \\(y\\) times starting from the initial\nvalue 0. \nSuch definitions may thus be understood to provide algorithms for\ncomputing the values of the functions so\n defined.[20]\n For observe that each natural number \\(n\\) is either equal to 0 or\nis of the form \\(m+1\\) for some \\(m \\in \\mathbb{N}\\). If we now\nintroduce the abbreviation \\(\\overline{n} = s(s(s \\ldots\n(s(\\mathbf{0}))))\\) \\(n\\)-times, the result of applying the\nsuccessor function \\(s\\) to a number denoted by \\(\\overline{n}\\) thus\nyields the number denoted by \\(\\overline{n+1}\\). We may thus compute\nthe value of \\(x + y\\) using the prior recursive definition of\naddition as follows: \nThe full definition of the primitive recursion operation combines both\ngeneralizations of (\\ref{prex1}) into a single scheme which takes as\narguments a \\(k\\)-ary function \\(f\\), a \\(k+2\\)-ary function \\(g\\),\nand returns a \\(k+1\\)-ary function \\(h\\) defined as follows  \nHere the first \\(k\\) arguments \\(x_0,\\ldots,x_{k-1}\\) to \\(g\\) are\nthe parameters, the \\(k+1\\)st argument \\(y\\) is the recursion\nvariable, and the \\(k+2\\)nd argument \\(h(x_0,\\ldots,x_{k-1},y)\\)\ngives the prior value of \\(h\\). An elementary set theoretic argument\nshows that for each \\(k \\in \\mathbb{N}\\), if \\(f\\) is \\(k\\)-ary and\n\\(g\\) is \\(k+2\\)-ary, then a there is a unique \\(k+1\\)-ary function\n\\(h\\) satisfying (\\ref{prscheme})—see, e.g., (Moschovakis 1994,\nch. 5). \nIt will again be useful to introduce a formal scheme for referring to  functions defined in\nthis manner: \nDefinition 2.2: Suppose that \\(f:\\mathbb{N}^k\n\\rightarrow \\mathbb{N}\\) and \\(g: \\mathbb{N}^{k+2} \\rightarrow\n\\mathbb{N}\\). Then the term \\(\\mathcal{PrimRec}_k[f,g]\\) denotes the\nunique function of type \\(\\mathbb{N}^{k+1} \\rightarrow \\mathbb{N}\\)\nsatisfying (\\ref{prscheme}).  \nWe may now formally define the class \\(\\mathbf{PR}\\) of primitive recursive\nfunctions as follows: \nDefinition 2.3: \n\n The class of primitive recursive functions \\(\\mathbf{PR}\\) is the smallest class of functions containing the initial functions \\(I_{\\mathbf{PR}} = \\{\\mathbf{0}, s, \\pi^k_i\\}\\) and closed under the functionals \nWith the definition of \\(\\mathbf{PR}\\)in place, we may also define what it\nmeans for a relation \\(R \\subseteq \\mathbb{N}^k\\) to be primitive\nrecursive: \nDefinition 2.4: \\(R \\subseteq \\mathbb{N}^k\\) is a\nprimitive recursive relation just in case its characteristic\nfunction  \nis a primitive recursive function.  \n\n Definition 2.4\n thus conventionalizes the characterization of a primitive recursive\nrelation \\(R \\subseteq \\mathbb{N}^k\\) as one for which there exists an\nalgorithm similar to that illustrated above which returns the output 1\non input \\(\\vec{n}\\) if \\(R\\) holds of \\(\\vec{n}\\) and the output 0 if\n\\(R\\) does not hold of \\(\\vec{n}\\). As will become clear below, most\nsets and relations on the natural numbers which are considered in\neveryday mathematics—e.g., the set PRIMES of prime\nnumbers or the relation \n\n\\[\\textit{DIV} = \\{\\langle n, m \\rangle : n\n\\textit{ divides } m \\textit{ without remainder}\\}\\]\n\n—are primitive recursive. \nThe foregoing definition specifies \\(\\mathbf{PR}\\) as the minimal\nclosure of \\(I_{\\mathbf{PR}}\\) under the functions in\n\\(Op_{\\mathbf{PR}}\\). In other words, \\(\\mathbf{PR}\\) may be equivalently\ndefined as the subclass of \\(\\bigcup_{k \\in \\mathbb{N}}(\\mathbb{N}^k\n\\rightarrow \\mathbb{N})\\) satisfying the following properties: \nAnother consequence of\n Definition 2.3\n is thus that each function \\(f \\in \\mathbf{PR}\\) possesses a\nspecification which shows how it may be defined from the initial\nfunctions \\(I_{\\mathbf{PR}}\\) in terms of a finite number of\napplications of composition and primitive recursion. This process may\nbe illustrated by further considering the definitions of\nthe functions \\(\\textit{add}(x,y)\\) and \\(\\textit{mult}(x,y)\\) given\nabove. \nNote first that although the familiar recursive definitions of\naddition (\\ref{defnadd}) and multiplication (\\ref{defnmult}) fit the\nformat of (\\ref{prex3}), they do not fit the format of\n(\\ref{prscheme}) which in this case requires that the argument \\(g\\)\nto the primitive recursion scheme be a \\(3\\)-ary function. It is,\nhowever, possible to provide a definition of \\(\\textit{add}(x,y)\\) in\nthe official form by taking \\(f(x_0) = \\pi^1_0(x_0)\\)—i.e., the\nidentity function—and \\(g(x_0,x_1,x_2) =\n\\mathcal{Comp}^1_3[s,\\pi^3_1]\\)—i.e., the function which results\nfrom composing the successor function with the \\(3\\)-ary projection\nfunction on to its second argument. The expression\n\\(\\mathcal{PrimRec}_1[\\pi^1_0,\\mathcal{Comp}^1_3[s,\\pi^3_1]]\\) may then be\nunderstood as a term which encodes the definition we have\nprovided for addition. Multiplication can then be defined via\n(\\ref{prscheme}) with \\(f = \\mathbf{0}\\) and \\(g(x_0,x_1,x_2) =\n\\mathcal{Comp}^2_3[add,\\pi^3_0,\\pi^3_2]\\). Thus\n\n\\[\\mathcal{PrimRec}_1[\\mathbf{0},\\mathcal{Comp}^2_3[add,\\pi^3_0,\\pi^3_2]]\\]\n\n—or in explicit form \n\n\\[\\mathcal{PrimRec}_1[\\mathbf{0},\\mathcal{Comp}^2_3[\\mathcal{PrimRec}_1[\\pi^1_0,\\mathcal{Comp}^1_3[s,\\pi^3_1]],\\pi^3_0,\\pi^3_2]]\\]\n\n—can be taken as a similar term encoding the definition of multiplication\nwe have abbreviated by \\(\\textit{mult}(x,y)\\). \nThese examples illustrate that the simpler recursion schemes which are\nemployed in many informal recursive definitions may be assimilated to\n Definition 2.3—e.g.,\n the function \\(h(x,y)\\) defined in (\\ref{prex3}) maybe obtained as\n\\(\\mathcal{PrimRec}_1[f,\\mathcal{Comp}^2_3[g,\\pi^3_1,\\pi^3_2]]\\). Repeated\nuse of this and similar observations will be made (generally without\ncomment) in the examples provided in  Section 2.1.2. \nAnother consequence of the fact that every \\(f \\in\n\\mathbf{PR}\\) is defined by a term given in this manner by (\\ref{prmc}) is the\nfollowing: \nProposition 2.1: The class of functions \\(\\mathbf{PR}\\) is\ncountable. \nThis can be demonstrated by showing that it is possible to enumerate\n\\(\\mathbf{PR}\\) as \\(f_0,f_1,f_2,\\ldots\\) by introducing a Gödel\nnumbering of terms formed from the expressions \\(\\mathbf{0},s,\\pi^k_i,\n\\mathcal{Comp}^j_k\\) and \\(\\mathcal{PrimRec}_k\\) in the manner described in\n Section 1.3.\n Since there are uncountably many functions of type \\(\\mathbb{N}^k\n\\rightarrow \\mathbb{N}\\) for all \\(k > 0\\), this observation also\nprovides a non-constructive demonstration that there exist number\ntheoretic functions which are not primitive recursive. \nAlmost all number theoretic functions and relations encountered in ordinary\nmathematics can be shown to be primitive recursive. In order to\nillustrate the extent of this class, we will present here a\nstandard sequence of definitions which can be traced historically to\nSkolem (1923). This can be used to show that the sequence coding\n\\(\\langle \\ldots \\rangle\\) and decoding \\((\\cdot)_i\\) operations\ndefined below are primitive recursive.  This is in turn required for\nGödel’s arithmetization of syntax (see\n Section 1.3)\n as well as results like the Normal Form Theorem\n (2.3)  which will be discussed below. \nFor each \\(k \\in \\mathbb{N}\\) the constant \\(k\\)-function defined\nas \\(\\const_k(x) = k\\) is primitive recursive. This is because we can\ninductively define  \nWe have already seen that the addition function \\(\\textit{add}(x,y)\\) can be defined by primitive recursion in terms of repeated application of successor and that the multiplication function \\(\\mathit{mult}(x,y)\\) can be defined by primitive recursion in terms of repeated application of addition.  We can continue this sequence by observing\nthat the exponentiation function \\(x^y\\) can be defined by primitive\nrecursion in terms of repeated multiplication as follows:  \nThe super-exponentiation function \ncan be defined by primitive recursion in terms of repeated\nexponentiation as as follows:  \nThe sequence of functions \nwhose \\(i+1\\)st member is defined in terms of primitive recursion of\nthe \\(i\\)th member form a hierarchy of functions whose values grow\nincreasingly quickly in proportion to their inputs. While each\nfunction in this sequence is primitive recursive, we can also consider the function\n\\(\\alpha(x,y)\\) defined as \\(\\alpha_x(y,y)\\)—a version of the\nso-called Ackermann-Péter function defined in\n Section 1.4—whose\n values are not bounded by any fixed function \\(\\alpha_i\\). \n As it can be shown that the values of   \\(\\alpha(x,y)\\)  are not bounded by any of the functions \\(\\alpha_i(x,y)\\), this shows that \\(\\alpha(x,y)\\) cannot be defined by any finite number of applications of the scheme \\(\\mathcal{PrimRec}_1\\).   This provides a constructive proof that there exist functions of type \\(\\mathbb{N}^2 \\rightarrow \\mathbb{N}\\) which are not primitive recursive. \nThe proper predecessor function is given by  \nThis function is primitive recursive since it may be defined as  \nNote that the second clause of (\\ref{pred}) does not depend on the prior value\nof \\(\\textit{pred}(y)\\). But this definition can still be conformed to\nthe scheme (\\ref{prscheme}) by taking \\(f(x_0) = \\mathbf{0}\\) and\n\\(g(x_0,x_1,x_2) = \\pi^3_1\\). \nThe proper subtraction function is given by  \nThis function is also primitive recursive since it may be defined as\n \nThe absolute difference function is defined as  \n\\(|x - y|\\) may be defined by composition as \\((x \\dotminus y) + (y\n\\dotminus x)\\) and is hence primitive recursive since \\(\\dotminus\\)\nis. \nThe signum function is defined as  \nThis function may be defined by composition as \\(\\textit{sg}(x) = 1\n\\dotminus (1 \\dotminus x)\\) and is hence primitive recursive as is the\ninverted signum function defined by\n\\(\\overline{\\textit{sg}}(x) = 1 \\dotminus \\textit{sg}(y)\\) which\nreturns 1 if \\(x = 0\\) and 1 otherwise. \nThe minimum and maximum functions may be similarly defined by\ncomposition from functions previously seen to be primitive recursive\nas follows:  \nThe characteristic functions of the less than relation\n(\\(<\\)) and equality relation (\\(=\\)) on the natural\nnumbers are definable as follows:  \nThese relations are hence primitive recursive. \nAs the less than or equal to relation (\\(\\leq\\)) is logically\nequivalent to \\(x < y \\vee x = y\\) it will follow from the next set\nof observations that this relation is also primitive recursive. The is\nadditionally true of \\(x > y\\), \\(x \\geq y\\) and \\(x \\neq\ny\\). \nThe set of primitive recursive relations is closed under boolean\noperations. In other words, if \\(P(\\vec{x})\\) and \\(Q(\\vec{x})\\)\nare primitive recursive, then so are \\(\\neg P(\\vec{x})\\), \\(P(\\vec{x})\n\\wedge Q(\\vec{x})\\), \\(P(\\vec{x}) \\vee Q(\\vec{x})\\), \\(P(\\vec{x})\n\\rightarrow Q(\\vec{x}),\\) and \\(P(\\vec{x}) \\leftrightarrow\nQ(\\vec{x})\\). \nGiven the interdefinability of the classical connectives, this follows\nupon noting the following:  \nSuppose that \\(f(\\vec{x},z)\\) is primitive recursive. Then the\nbounded sum \\(g(\\vec{x},y) = \\Sigma_{i=0}^y f(\\vec{x},i)\\)\nand the bounded product \\(h(\\vec{x},y) = \\Pi_{i=0}^y\nf(\\vec{x},i)\\) are both primitive recursive as they may be\nrespectively defined as follows:  \nThe set of primitive recursive relations is also closed under\nbounded quantification—i.e., if \\(R(\\vec{x},z)\\) is a\nprimitive recursive relation, then so are the relations \\(\\forall z\n\\leq y R(\\vec{x},z)\\) and \\(\\exists z \\leq y R(\\vec{x},z)\\). These may\nbe respectively defined as follows as follows:  \nThe set of primitive recursive relations is also closed under\nbounded minimization. This is to say that if \\(R(\\vec{x},z)\\)\nis a primitive recursive relation, then so is the function\n\\(m_R(\\vec{x},y)\\) which returns the least \\(z\\) less than or equal to \\(y\\) such\nthat \\(R(\\vec{x},z)\\) holds if such a \\(z\\) exists and \\(y+1\\)\notherwise—i.e.,  \nTo see this, observe that if \\(R(\\vec{x},z)\\) is primitive recursive,\nthen so is \\(\\forall z \\leq y \\neg R(\\vec{x},z)\\). It is then not\ndifficult to verify that  \nA natural number \\(y\\) is said to be divisible by \\(x\\) just\nin case there exists a \\(z\\) such that \\(x \\times z = y\\)—i.e.,\n\\(x\\) divides \\(y\\) without remainder. In this case we write \\(x\n\\divides y\\). Note that if \\(x \\divides y\\) holds, then this must be\nwitnessed by a divisor \\(z \\leq y\\) such that \\(x \\times z = y\\). We\nmay thus define \\(x \\divides y\\) in the following manner which shows\nthat it is primitive recursive:  \nWe may also define the non-divisibility relations \\(x\n\\notdivides y\\) as \\(\\neg(x \\divides y)\\) which shows that it too is\nprimitive recursive. \nNext recall that a natural number \\(x\\) is prime just in case\nit is greater than 1 and is divisible by only 1 and itself. We may\nthus define the relation \\(\\textit{Prime}(x)\\) in the following manner\nwhich shows that it is primitive recursive:  \nThe primes form a familiar infinite sequence \\(p_0 = 2,\\) \\(p_1 = 3,\\)\n\\(p_2 = 5,\\) \\(p_3 = 7,\\) \\(p_4 = 11,\\)…. Let \\(p(x) =\np_x\\)—i.e., the function which returns the \\(x\\)th prime\nnumber. \\(p(x)\\) can be defined by primitive recursion relative to the\nfunction \\(\\nextPrime(x)\\) which returns the least \\(y > x\\) such\nthat \\(y\\) is prime as follows:  \nRecall that Euclid’s Theorem states that there is always a prime\nnumber between \\(x\\) and \\(x! + 1\\) and also that \\(x! = \\fact(x)\\) is\nprimitive recursive. It thus follows that \\(\\nextPrime(x)\\) can be\ndefined via bounded minimization as follows:  \nIt thus follows that \\(p(x)\\) is primitive recursive. \nThe foregoing sequence of definitions provides some evidence for the\nrobustness of the class of primitive recursive relations and\nfunctions. Further evidence is provided by the fact that it is\npossible to develop the machinery for coding and decoding finite\nsequences of natural numbers and for performing various combinatorial\noperations on sequences—e.g., adjunction of an element,\nconcatenation, extracting a subsequence, substituting one element for\nanother, etc. The primitive recursiveness of these operations\nunderpins Gödel’s arithmetization of syntax as described in\n Section 1.3.\n We present here only the basic definitions required to demonstrate\nthe primitive recursiveness of the \\(k\\)-tupling and projection\nfunctions which are required for results in computability theory such\nas the Normal Form Theorem\n (2.3)\n discussed below. \nGiven a finite sequence of natural numbers \\(n_0,n_1,\\ldots,n_{k-1}\\)\nwe define its code to be the number  \nwhere \\(p_i\\) is the \\(i\\)th prime number as defined above. In\nother words, the code of \\(n_0,n_1,\\ldots,n_{k-1}\\) is the natural\nnumber resulting from taking the product of the numbers \\(p_i^{n_i +\n1}\\) for \\(0 \\leq i \\leq k-1\\). This will be denote by \\(\\langle\nn_0,n_1,\\ldots,n_{k-1} \\rangle\\)—e.g.,  \n(Note that 1 is added to each exponent so that, e.g., 3, 1, 4, 1, 5\nhas a distinct code from that of 3, 1, 4, 1, 5, 0, etc.—i.e., so\nthat the coding operation is injective.) \nThe operation which takes a sequence of arbitrary length to its code\ndoes not have a fixed arity and hence is not given by a single\nprimitive recursive function. But it is not hard to see that if we\nrestrict attention to sequences of given length \\(k\\), then\n\\(\\langle n_0,n_1,\\ldots,n_{k-1} \\rangle : \\mathbb{N}^k \\rightarrow\n\\mathbb{N}\\) is primitive recursive as it is simply the bounded\nproduct given by (\\ref{primecode}). Consider next the function\n\\(\\textit{element}(s,i) = n_i\\) where \\(s = \\langle\nn_0,n_1,\\ldots,n_{k-1} \\rangle\\) and \\(0 \\leq i \\leq k-1\\) and which\nreturns 0 when \\(i\\) is not in this range or \\(s = 0\\) or 1 (and\nthus not a code of a sequence). In order to see that\n\\(\\textit{element}(s,i)\\) is also primitive recursive, first observe\nthat it is possible to recover \\(\\textit{len}(s)\\)—i.e., the\nlength of the sequence coded by \\(s\\)—by searching for\nthe least \\(i < s\\) such that \\(p_i \\divides s\\) and \\(p_{i+1}\n\\notdivides s\\). Since \\(s\\) also bounds all the primes \\(p_i\\)\nwhich divide it we may define  \nIt is straightforward to see that a function defined by cases with\nprimitive recursive conditions is primitive recursive. So\n\\(\\textit{len}(s)\\) is primitive recursive as well. \nFinally observe that \\(\\textit{element}(s,i)\\) is equal to the\nsmallest exponent \\(n\\) such that \\(p_i^{n+1} \\divides s\\) but\n\\(p_i^{n+2} \\notdivides s\\) and that such an exponent is also bounded\nby \\(s\\). We may thus provide a primitive recursive definition of\n\\(\\textit{element}(s,i)\\) as follows:  \nThe conventional abbreviation \\((s)_i = \\textit{element}(s,i)\\) will\nbe employed for this function below. \nThe primitive recursive functions and relations encompass a broad\nclass including virtually all those encountered in ordinary\nmathematics outside of logic or computability theory. This is\nillustrated in part by the fact that \\(\\mathbf{PR}\\) contains functions such\nas \\(supexp(x,y)\\) which grow far faster than those whose values we\ncan feasibly compute in practice in the sense studied in computational complexity theory. But the robustness of the class \\(\\mathbf{PR}\\) is also attested to by the fact that its definition\nis invariant with respect to a variety of modifications—e.g.,\nwith respect to the classes of initial functions \\(I_{\\mathbf{PR}}\\)\nand functionals \\(Op_{\\mathbf{PR}}\\) on which its definition is\nbased. \nAs an initial illustration, consider the following scheme of so-called\npure iteration:  \nIt is easy to see that the function \\(h\\) defined by (\\ref{pureiter}) from \\(g\\) in this manner is the \\(x^{\\mathrm{th}}\\)–iterate of \\(g\\)— i.e., \\(g^{x}(y)=_{\\mathrm{df}} g(g(\\ldots g(y)))\\) \\(x\\)–times with the convention that \\(g^0(y) = y\\).  We will denote this functional by \\(\\mathcal{Iter}[g,x]\\). The scheme (\\ref{pureiter}) thus generalizes (\\ref{prex1}) by making the value of base case an argument to \\(h\\). But it is an apparent restriction of\n(\\ref{prscheme}) in the sense that \\(h\\) cannot depend on either the\nrecursion variable or additional parameters. \nSuppose we now consider an alternative class of initial functions\n\\(In_{\\mathbf{IT}}\\) containing \\(s,\\pi^k_i\\), the binary coding\nfunction \\(\\langle x,y \\rangle\\), and the decoding functions \\((x)_0\\)\nand \\((x)_1\\) defined at the end of \n Section 2.1.2.\n(Note that these operate analogously to the first and second production\nfunctions \\(\\pi^2_0\\) and \\(\\pi^2_1\\) operating on codes of\nordered pairs.) Now define \\(\\mathbf{IT}\\) to be the smallest class of\nfunctions containing \\(In_{\\mathbf{IT}}\\) and closed under the\nfunctionals \\(Op_{\\mathbf{IT}} =\n\\{\\mathcal{Comp}^i_j,\\mathcal{Iter}\\}\\). \nTheorem 2.1 (Robinson 1947): The class \\(\\mathbf{IT}\\) is\nequal to the class \\(\\mathbf{PR}\\) of primitive recursive functions. \nThis illustrates that if we slightly enlarge the class of initial\nfunctions, it is still possible to obtain the entire class \\(\\mathbf{PR}\\)\nvia a scheme of functional iteration which at first appears less\ngeneral than primitive recursion. See Odifreddi (1989, ch. I.5) for an\naccount of further improvements which can be obtained in this\ndirection. \nOther results show that the class \\(\\mathbf{PR}\\) also remains stable if\nprimitive recursion is replaced with other schemes which may initially\nappear more general. The most familiar of these is the scheme of\ncourse of values recursion which is traditionally illustrated\nusing the so-called Fibonacci function \\(\\fib(x)\\) which was\nbriefly discussed at the beginning of\n Section 1.\n This may be defined as follows:  \nThis definition can readily be used to calculate the values of\n\\(\\fib(x)\\) in a recursive manner—e.g.,  \nThis gives rises to the familiar sequence 0, 1, 1, 2, 5, 8, 13, 21,\n34, 55, 89, 144,… wherein \\(F_0 =0,\\) \\(F_1 = 1,\\) and\n\\(F_{i+2} = F_{i+1} + F_i.\\) Note, however, the definition\n(\\ref{fibdefn}) cannot be directly assimilated to the primitive\nrecursion scheme (\\ref{prscheme}) since the third clause defines the\nvalue of \\(\\fib(y+1)\\) in terms of both \\(\\fib(y)\\) and\n\\(\\fib(y-1)\\). It is, however, still possible to show that \\(\\fib \\in\n\\mathbf{PR}\\). One means of doing this is to again make use of the\nbinary coding and projection functions to first define an auxiliary\nfunction \\(g(0) = \\langle 0,1 \\rangle\\) and \nwhich enumerates the pairs \\(\\langle F_0,F_1 \\rangle\\), \\(\\langle F_1,\nF_2 \\rangle, \\ldots\\) It is then easy to see that \\(\\fib(y) =\n(g(y))_0\\). \n(\\ref{fibdefn}) is thus an instance where the value of the function\n\\(h\\) at \\(y\\) depends on the values \\(h(y-1)\\) and \\(h(y-2)\\) of its\ngraph (for \\(y \\geq 2\\)). It is, of course, also possible to consider\ncases where \\(h(y)\\) depends on an arbitrary number of its preceding\nvalues \\(h(0), \\ldots, h(y-1)\\). To this end, suppose we are given\n\\(h(\\vec{x},y)\\) and then define  \nWe then say that \\(h(\\vec{x},y)\\) is defined by course of values\nrecursion from \\(f(\\vec{x})\\) and \\(g(\\vec{x},y,z)\\) if  \nSuppose that we now let \\(\\mathcal{CV}_k[f,g]\\) denote the\ncorresponding functional operation and let \\(\\mathbf{CV}\\) be the\nsmallest class of functions containing \\(In_{\\mathbf{PR}}\\) and closed\nunder \\(\\mathcal{Comp}^j_k\\) and \\(\\mathcal{CV}_k\\). Then since it is\neasy to see that \\(\\widetilde{h}(\\vec{x},y)\\) is primitive recursive\nif \\(h(\\vec{x},y)\\) is, we also have the following: \nTheorem 2.2 (Péter 1935): The class\n\\(\\mathbf{CV}\\) is equal to the class \\(\\mathbf{PR}\\) of primitive recursive\nfunctions. \nSince course of values recursion is occasionally used in mathematical practice,\nit is significant that it does not lead outside the class of primitive\nrecursive functions. There are, however, a number of other possible\nways in which the scheme (\\ref{prscheme}) might also be generalized,\nincluding what are known as double recursion and nested\nrecursion. The definition of the Ackermann-Péter function\n\\(\\pi(x,y)\\) in\n Section 1.4\n exhibits the former since its value at \\(x,y\\) depends on its value\nat both \\(x-1\\) and \\(y-1\\) and also the latter since the\noccurrence of the defined function \\(\\pi(x,y)\\) is\n“nested” within itself (rather than an auxiliary function)\non the righthand side of the third clause. Although such definitions\narise less often in practice, they are important historically due to\ntheir occurrence in Hilbert’s original discussion of recursion\n(see\n Section 1.3).\n Such schemes were considered systematically by Péter (1967)\nwho showed that unnested double recursion on its own also does not\nlead outside the class of primitive recursive functions. \nWe have now seen two ways of showing that there exist number theoretic\nfunctions which are not primitive recursive—i.e., by observing\nthat while there are only countably many primitive recursive functions\nthere are uncountably many functions of type \\(\\mathbb{N}^k\n\\rightarrow \\mathbb{N}\\) (\\(k > 0\\)) and also by constructing a\nfunction such as \\(\\alpha(x,y) = \\alpha_x(y,y)\\) which grows faster\nthan any primitive recursive function. A third proof—originally\ndue to Hilbert & Bernays (1934, ch. 7)—is based on the\nobservation that it is possible to enumerate the class \\(\\mathbf{PR}\\) as\n\\(g_0(x),g_1(x),g_2(x), \\ldots\\)—e.g., by Gödel numbering\nthe sorts of definitions considered at the end of\n Section 2.1.1.\n If we then consider the modified diagonal function  \nit is easy to see that this  function also cannot be primitive recursive. For if\n\\(\\delta(x)\\) coincided with some function \\(g_j(x)\\) in the\nenumeration, then we would have \\(g_j(j) = \\delta(j) = g_j(j) + 1\\), a\ncontradiction. Note that this also shows that relative to such an\nenumeration the universal function \\(u_1(i,x) =\ng_i(\\vec{x})\\) for unary primitive recursive functions cannot itself\nbe primitive recursive as we could otherwise define \\(\\delta(x)\\) as\n\\(u_1(x,x) + 1\\). Hilbert & Bernays (1939, ch. 5) would later discuss\nthis observation in regard to what has become known as their\ndenotational paradox—see, e.g., (Priest 1997). \nOn the other hand, there are intuitively effective procedures for\ncomputing each of these functions. For instance, in the case of\n\\(\\delta(x)\\) we can proceed as follows:  \nThis illustrates that although \\(\\alpha(x,y)\\), \\(\\delta(x)\\), and\n\\(u_1(i,x)\\) are not primitive recursive, they are still\neffectively computable in the sense discussed in\n Section 1.6.\n There is thus a natural motivation for seeking to expand the\ndefinition of the class \\(\\mathbf{PR}\\) so as to encompass such intuitively\ncomputable functions. \nOne means by which this can be accomplished builds on the observation\nthat the bounded minimization operation \\(m_R(\\vec{x},y)\\) admits to a\nstraightforward algorithmic characterization—i.e., to compute\nthe value of \\(m_R(\\vec{x},y)\\) successively check \\(R(\\vec{x},0),\\)\n\\(R(\\vec{x},1),\\) …, \\(R(\\vec{x},z),\\)… giving output\n\\(z\\) and halting as soon as \\(R(\\vec{x},z)\\) holds and \\(y+1\\) if no\npositive instance is found before \\(z = y\\). This can be generalized\nto the so-called unbounded search operation. In particular,\ngiven a relation \\(R(\\vec{x},y)\\) we can define the operation\n\\(\\mu_R(\\vec{x},z)\\) which returns the least \\(z\\) such that\n\\(R(\\vec{x},z)\\) if such a \\(z\\) exists and is undefined otherwise.\nNote that if \\(R(\\vec{x},y)\\) is primitive recursive, then it is still\npossible to effectively search for the value of \\(\\mu_R(\\vec{x},y)\\)\nby successively checking \\(R(\\vec{x},0),\\) \\(R(\\vec{x},1),\\)….\nBut since no upper bound is specified in advance, we are not\nguaranteed that this procedure will always terminate. In particular,\nif there is no \\(z \\in \\mathbb{N}\\) such that \\(R(\\vec{x},z)\\) holds,\nthen the procedure will continue indefinitely. In this case, we\nstipulate that \\(\\mu_R(\\vec{x},y)\\) is undefined, from which\nit follows that \\(\\mu_R(\\vec{x},y)\\) will correspond to what is known\nas a partial function—a notion which is made precise by\nthe following sequence of definitions. \nThe class of so-called partial recursive functions is\nobtained from our prior definition of \\(\\mathbf{PR}\\) by closing under an\noperation similar to \\(\\mu_R(\\vec{x},z)\\) which is applied to\nfunctions rather than relations. In order to define this class, we\nfirst introduce the following conventions regarding partial\nfunctions which extends those given at the beginning of\n Section 2: \nA function \\(f:\\mathbb{N}^k \\rightarrow \\mathbb{N}\\) is called\ntotal if \\(f(\\vec{n})\\) is defined for all \\(\\vec{n} \\in\n\\mathbb{N}^k\\). Otherwise \\(f(\\vec{x})\\) is called\npartial. \nWe write \\(f(\\vec{n})\\darrow\\) to express that \\(f(\\vec{x})\\) is\ndefined at \\(\\vec{n}\\) and additionally \\(f(\\vec{n})\\darrow = m\\)\nif \\(f(\\vec{n})\\) is defined at \\(\\vec{n}\\) and equal to \\(m\\).\nOtherwise we write \\(f(\\vec{n})\\uarrow\\) to express that\n\\(f(\\vec{x})\\) is undefined at \\(\\vec{n}.\\) \nThe domain of \\(f(\\vec{n})\\) is the set \\(\\textrm{dom}(f) =\n\\{\\vec{n} \\in \\mathbb{N}^k : f(\\vec{n}) \\darrow\\}\\). \nWe write \\(f(\\vec{x}) \\simeq g(\\vec{x})\\) just in case for all\n\\(\\vec{n} \\in \\mathbb{N}\\), either \\(f(\\vec{n})\\) and \\(g(\\vec{n})\\)\nare both undefined or are both defined and equal. \nSuppose we are given a partial function \\(f(x_0,\\ldots,x_{k-1},y)\\).\nWe now introduce terms of the form \\(\\mu y f(x_0,\\ldots,x_{k-1},y)\\)\ndefined as follows:  \nIn other words, \\(\\mu y f(\\vec{n},y)\\) is equal to the least \\(m\\)\nsuch that \\(f(\\vec{n},m) = 0\\) provided that such an \\(m\\) exists and\nalso that \\(f(\\vec{n},i)\\) is defined but not equal to 0 for all \\(0\n\\leq i < m\\). On the other hand, \\(\\mu y f(\\vec{n},y)\\) is\nundefined just in case either there is no \\(m\\) such that\n\\(f(\\vec{n},m) = 0\\) or there is such a \\(m\\) but \\(f(\\vec{n},i)\\) is\nundefined for some \\(i < m\\). \nSince this definition determines \\(\\mu yf(\\vec{x},y)\\) uniquely,\n(\\ref{murec}) can also be regarded as defining a functional\n\\(\\mathcal{Min}_k\\) which maps \\(k+1\\)-ary partial functions into\n\\(k\\)-ary partial functions. We now define the classes of functions\n\\(\\mathbf{PartREC}\\)  and \\(\\mathbf{REC}\\)  as follow: \nDefinition 2.5: The class of partial recursive\nfunctions \\(\\mathbf{PartREC}\\) (also known as the \\(\\mu\\)-recursive\nfunctions) is the smallest class of partial functions of type\n\\(\\mathbb{N}^k \\rightarrow \\mathbb{N}\\) containing the initial\nfunctions \\(I_{\\mathbf{PR}} = \\{\\mathbf{0},s,\\pi^i_k\\}\\) and closed\nunder the functionals \nWe say that a function \\(f:\\mathbb{N}^k \\rightarrow \\mathbb{N}\\) is\npartial recursive if \\(f \\in \\mathbf{PartREC}\\). Additionally\nwe say that \\(f\\) is recursive if \\(f \\in \\mathbf{PartREC}\\)\nand \\(f\\) is total. The set of recursive functions will be denoted by\n\\(\\mathbf{REC}\\).  \nNote that despite its name, the class of partial recursive\nfunctions contains total functions. In particular, a\nrecursive function is, by definition, one which is\npartial recursive while also being total. We will see in\n Section 3.2,\n there also exist partial recursive functions which are genuinely partial and\ntotal functions which are not recursive. \nNote finally that if \\(f(\\vec{x})\\) is recursive it may be defined via\nsome finite number of applications of composition, primitive\nrecursion, and unbounded minimization in a manner which preserves the\ntotality of intermediate functions in its definition. Thus although\nthe specification of \\(f(\\vec{x})\\) may involve one or more\napplications of unbounded search, each search required to compute its\nvalue is guaranteed to terminate in a finite number of steps. It thus\nfollows that all of functions in \\(\\mathbf{REC}\\) are computable by an\nalgorithm (despite the fact that we will soon see that this class\ncontains functions which are not primitive recursive). This\nconstitutes part of the evidence for Church’s\nThesis—i.e., the claim that \\(\\mathbf{REC}\\) coincides with the\nclass of effectively computable functions—which was surveyed in\n Section 1.6. \nA question which naturally arises at this stage is whether more than\none application of unbounded minimization is required to obtain all\npartial recursive functions. The fact that a single application is\nsufficient is a consequence of the Kleene Normal Form\nTheorem. In order to formulate this result, it is convenient to\nofficially extend the application of the \\(\\mu\\)-operator to relations\nin the manner discussed at the beginning of this section—i.e.,  \nTheorem 2.3: For all \\(k \\in \\mathbb{N}\\) there\nexists a \\(k\\)+2-ary primitive recursive relation\n\\(T_k(e,\\vec{x},s)\\)—the so-called Kleene\n\\(T\\)-predicate—and a primitive recursive function \\(u(x)\\)\n(not depending on \\(k\\)) satisfying the following\ncondition: for all \\(k\\)-ary partial recursive functions\n\\(f(\\vec{x})\\) there exists \\(e \\in \\mathbb{N}\\) such that for all\n\\(\\vec{n} \\in \\mathbb{N}^k\\)  \nSince \\(\\mu y R(\\vec{x},y) \\simeq \\mu y \\chi_{\\neg R}(\\vec{x},y)\\), it\nis easy to see that the class \\(\\mathbf{PartREC}\\) can also be obtained by\nclosing the primitive recursive functions under the operation defined\nby (\\ref{unboundedminrel}). One consequence of\n Theorem 2.3\n is thus that it is indeed possible to define any \\(k\\)-ary partial\nrecursive function \\(f(\\vec{x})\\) by a single application of unbounded\nsearch applied to the relation \\(T_k(e,\\vec{x},s)\\) for an appropriate\nchoice of \\(e\\). More generally, the Normal Form Theorem illustrates\nhow any such function may be defined from a single relation\n\\(T_k(e,\\vec{x},s)\\) wherein the value of \\(e\\) serves as a\ndescription of the manner in which \\(f(\\vec{x})\\) is defined in terms\nof the basis functions \\(I_{\\mathbf{PR}}\\) and the operations\n\\(Op_{\\mathbf{PartRec}}\\). Such an \\(e\\) is known as an index\nfor \\(f(\\vec{x})\\). As we will see in\n Section 3,\n the availability of such indices is one of the central features of\nthe partial recursive functions which allows them to provide the basis\nfor a general theory of computability and non-computability. \nThe complete details of the proof of\n Theorem 2.3\n are involved. But the basic idea may be summarized as follows: \nEvery partial recursive function \\(f(\\vec{x})\\) is defined by a term\n\\(\\tau\\) over the language  \nin the manner which extends the notation scheme for partial recursive\nfunction introduced at the end of\n Section 2.1.1.\n By associating the atomic expressions of this language with natural\nnumbers in the manner of Gödel numbering \\(\\ulcorner \\cdot\n\\urcorner\\) described in\n Section 1.3\n and then employing the coding machinery described at the end of\n Section 2.1.2,\n it is then possible to associate \\(\\tau\\) with a natural number\n\\(\\ulcorner \\tau \\urcorner = e\\) which can serve as an index for\n\\(f(\\vec{x})\\). \nThe definition of \\(T_k(e,\\vec{n},s)\\) can now be constructed by\nformalizing the following decision algorithm:  \nBy performing an unbounded search over codes of computation sequences\nin this manner, we achieve the dual purposes of both determining if\nthe computation described by \\(\\tau\\) on input \\(\\vec{n}\\) halts after\na finite number of steps and, if so, also finding a code \\(s\\) of a\ncomputation sequence which witnesses this fact. The function \\(u(s)\\)\ncan then be defined by formalizing the operation which extracts the\noutput of the computation from the last step\n\\((s)_{\\textit{len}(s)-1}\\) of the sequence encoded by \\(s\\). In the case that\n\\(T_k(e,\\vec{n},s)\\) holds, \\(u(s)\\) will thus correspond to the value\n\\(f(\\vec{n})\\). Since the foregoing steps require only performing\nbounded search and checking the local combinatorial properties of\nfinite sequences, it can additionally be shown that\n\\(T_k(e,\\vec{n},s)\\) and \\(u(x)\\) are primitive recursive. \nThe techniques used in this proof can also be used to show that\n\\(\\alpha(x,y)\\), the universal \\(k\\)-ary primitive recursive\nevaluation function \\(u_k(i,\\vec{x})\\), and the modified diagonal\nfunction \\(\\delta(x)\\) are all recursive (despite the fact that we\nhave seen above that they are not primitive recursive). For\ninstance note that the coding of definitions of \\(k\\)-ary partial recursive\nfunctions described above also allows us to uniformly enumerate all\nprimitive recursive functions \\(g_0(\\vec{x}),g_1(\\vec{x}),\\ldots\\) by\nconsidering the codes of terms not containing \\(\\mathcal{Min}_k\\). We\ncan define in this manner a primitive recursive function \\(r(i)\\)\nenumerating the indices for these functions such that we can obtain\nthe universal function for \\(k\\)-ary primitive recursive function\nas \\(u_k(i,\\vec{x}) = u(\\mu s T_1(r(i),\\vec{x},s)) = g_i(\\vec{x})\\).\nBut note that since \\(g_i(\\vec{x})\\) is always defined,\n\\(u_1(i,\\vec{x})\\) is not only partial recursive but also total, and\nhence recursive. \nTaking into account the equivalences between models of computation\nsummarized in\n Section 1.6,\n it is also possible to formulate a version of\n Theorem 2.3\n for each of the models of computation mentioned there. For instance,\nin the case of the Turing Machine model \\(\\mathbf{T}\\), the analogous\nversion of the Normal Form Theorem can be used to show that there is a\nsingle\n universal Turing machine (see entry on Turing machines)\n \\(U\\) such that every partial recursive function \\(f(\\vec{x})\\)\ncorresponds to that computed by \\(U(e,\\vec{x})\\) for some \\(e \\in\n\\mathbb{N}\\). Complete proofs of this sort were given by Turing (1937, sec.\n6) for \\(\\mathbf{T}\\), by Kleene (1936a, sec. 2) for the general recursive\nfunctions \\(\\mathbf{GR}\\) (see also Kleene 1952, sec. 58), by Shoenfield (1967, ch.\n7.4) for the class \\(\\mathbf{F}_{\\mathsf{PA}}\\) of functions\nrepresentable in Peano Arithmetic, and by Cutland (1980, ch. 5) for the\nUnlimited Register Machine model \\(\\mathbf{U}\\). \nComputability Theory is a subfield of contemporary mathematical logic devoted to\nthe classification of functions and sets of natural numbers in terms\nof their absolute and relative computability and\ndefinability-theoretic properties. This subject is closely related in\nboth origin and content to the study of recursive functions. This is\nreflected by the fact that computability theory was known as\nrecursive function theory (or simply recursion\ntheory) from the time of its inception in the 1930s until the\nlate 1990s. It is also reflected in the formulation and proof of the\nso-called Recursion Theorem which provides a fundamental link\nbetween recursive definability and the sort of self-referential\nconstructions which are at the core of many methods in computability\ntheory (see\n Section 3.4). \nFor reasons discussed in\n Section 1.7,\n contemporary expositions of computability theory are often presented\nin an abstract manner which seeks to minimize reference to the\nspecific features of a model of computation such as the partial\nrecursive functions. It is thus useful to stress the following\nmodifications to the traditional terminology which has been employed\nin\n Sections 1 and 2\n and the more contemporary terminology which will be employed in this\nsection: \nThe expressions computable function and\npartial computable function will be used\ninstead of the traditional terms recursive\nfunction and partial recursive\nfunction as defined in\n Section 2.2.1. \nThe expression computable set will be used\ninstead of the traditional term recursive\nset. Similarly, computably\nenumerable (or c.e.) set will\nbe used instead of the traditional term recursively\nenumerable (or r.e.) set (see\n Section 3.3). \nThe other notational conventions introduced at the beginnings of\n Section 2.1\n and\n Section 2.2\n will be retained in this section. \nThe first significant result in computability theory was\nKleene’s (1936a) proof of the Normal Form Theorem which was\npresented in\n Section 2.2.2.\n As discussed there, the Normal Form Theorem can be understood as\nillustrating how it is possible to associate each \\(k\\)-ary partial\ncomputable function \\(f(\\vec{x})\\) with a natural number \\(e\\) known\nas its index such that \\(f(\\vec{x}) \\simeq \\mu\ns(T_k(e,\\vec{x},s))\\). Such an \\(e\\) can be thought of as a name for a\ncomputer program built up from the basis functions, composition,\nprimitive recursion, and minimization by which the values\n\\(f(\\vec{x})\\) can be computed. This also leads to what is known as an\nindexation of \\(k\\)-ary partial computable functions  \nwhere \\(\\phi^k_i(\\vec{x}) \\simeq \\mu s T_k(i,\\vec{x},s)\\). Such an\nenumeration provides a uniform means of listing off all partial\ncomputable functions in the order of their indices. It should be noted,\nhowever, that each partial computable function has infinitely many\nindices. For instance, given a function \\(f:\\mathbb{N}^k \\rightarrow\n\\mathbb{N}\\) computed by \\(\\phi_e(\\vec{x})\\), it is possible to define\ninfinitely many extensionally coincident functions with distinct\nindices \\(\\phi_{e'}(\\vec{x}), \\phi_{e''}(\\vec{x}),\n\\ldots\\)—e.g., by “padding” the definition encoded\nby \\(e\\) with terms that successively add and then subtract \\(m\\) for\neach \\(m \\in \\mathbb{N}\\). As this yields a definition of an\nextensionally equivalent function, it thus follows that infinitely\nmany of the \\(\\phi^k_i(\\vec{x})\\) will correspond to the same function\nin extension. \nA result closely related to the Normal Form Theorem is the following\nwhich is conventionally known as the s-m-n Theorem: \nTheorem 3.1: For all \\(n,m \\in \\mathbb{N}\\), there is\na primitive recursive function \\(s^m_n(i,x_0,\\ldots,x_{m-1})\\) such\nthat  \nHere the function \\(s^m_n(i,\\vec{x})\\) should be thought of as acting\non an index \\(i\\) for an \\(n+m\\)-ary partial computable function\ntogether with values \\(\\vec{x}\\) for the first \\(m\\) of its arguments.\nThis function returns an index for another partial computable function\nwhich computes the \\(n\\)-ary function determined by carrying out\n\\(\\phi^{n+m}_i\\) with the first \\(m\\) of its arguments \\(\\vec{x}\\)\nfixed but retaining the next \\(n\\) variables \\(\\vec{y}\\) as inputs.\nAlthough the formulation of the s-m-n Theorem may at first\nappear technical, its use will be illustrated in the proof of\n Rice’s Theorem (3.4)\n and the\n Recursion Theorem (3.5)\n below. \nAnother consequence of the Normal Form Theorem is the following: \nTheorem 3.2: For every \\(k \\in \\mathbb{N}\\), there is\na \\(k+1\\)-ary partial computable function \\(\\upsilon^k\\) which is\nuniversal in the sense that for all \\(k\\)-ary partial computable\nfunctions \\(f(\\vec{x})\\), there is an \\(i \\in \\mathbb{N}\\) such that\n\\(\\upsilon_k(i,\\vec{x}) \\simeq f(\\vec{x})\\). \nThis follows immediately from\n Theorem 2.3\n by taking \\(\\upsilon_k(i,\\vec{x}) = u(\\mu s T_k(i,\\vec{x},s))\\) where\n\\(i\\) is such that \\(f(\\vec{x}) \\simeq \\phi^k_i(\\vec{x})\\) in the\nenumeration of \\(k\\)-ary partial computable functions. As\n\\(\\upsilon^k(i,\\vec{x})\\) can be used to compute the values of all\n\\(k\\)-ary partial computable functions uniformly in their index, it\nis conventionally referred to as the \\(k\\)-ary universal\npartial computable function. \nIt is useful to observe that while we have just defined such a\nfunction for each \\(k\\), it is also possible to define a binary function\n\\(\\upsilon(i,x)\\) which treats its second argument as a code for a\nfinite sequence \\(x_0,\\ldots,x_{k-1}\\) and then computes in the same\nmanner as the \\(k\\)-ary universal function so that we have\n\\(\\upsilon(i,\\langle x_0,\\ldots, x_{k-1} \\rangle) \\simeq\n\\upsilon^k(i,x_0,\\ldots,k_{k-1})\\). This provides a means of replacing\nthe prior enumerations of \\(k\\)-ary partial computable functions\nwith a single enumeration of unary functions  \nwhere \\(\\phi_i(\\langle x_0,\\ldots, x_{k-1} \\rangle) \\simeq\n\\upsilon(i,\\langle x_0,\\ldots, x_{k-1} \\rangle) \\simeq\n\\phi^k_i(x_0,\\ldots, x_{k-1})\\). \nTogether with\n Theorem 2.3,\n Theorem 3.1 and\n Theorem 3.2\n codify the basic properties of a model of computation which make it\nsuitable for the development of a general theory of computability. In\n Section 2\n such a model has been defined in the form of the partial recursive\nfunctions. But as was discussed briefly at the end of\n Section 2.2.2,\n versions of these results may also be obtained for the other models\nof computation discussed in\n Section 1.6.\n This licenses the freer usage of computer-based analogies and other\nappeals to Church’s Thesis employed in most contemporary\ntreatments of computability theory which will also be judiciously\nemployed in the remainder of this entry. \nHaving just seen that there is a universal partial computable function\n\\(\\upsilon(i,x)\\), a natural question is whether this function is also\ncomputable (i.e., total). A negative answer is provided\nimmediately by observing that by using \\(\\upsilon(i,x)\\) we may define\nanother modified diagonal function \\(d(x) = \\upsilon(x,x) + 1\\) which\nis partial computable (since \\(\\upsilon(i,x)\\) is). This in turn\nimplies that \\(d(x) \\simeq \\phi_j(x)\\) for some \\(j\\). But now note that if\n\\(\\upsilon(i,x)\\) were total, then \\(d(j)\\) would be defined and we\nwould then have  \na contradiction. Comparing this situation with  that described at the beginning of\n Section 2.2\n we can see that the partial computable functions differ from the\nprimitive recursive functions in admitting a universal function within\nthe same class but at the same time giving up the requirement that the\nfunctions in the class must be total. In other words, while\n\\(\\upsilon(i,x) \\in \\mathbf{PartREC}\\), the discussion in\n Section 2.2.2\n shows that \\(u_1(i,\\vec{x}) \\in \\mathbf{REC} - \\mathbf{PR}\\).\n \nSince it is easy to see how the minimization operation can\nbe used to define partial functions, the foregoing observations is\nexpected. What is more surprising is that there are mathematically\nwell-defined total functions which are not computable. Building on the discussion of the\nEntscheidungsproblem in\n Section 1.7,\n the most famous example of such a function derives from the so-called\n Halting Problem (see entry on Turing machines)\n for the Turing Machine model. This was originally formulated by\nTuring (1937) as follows: \nGiven an indexation of \\(T_0, T_1, \\ldots\\) of Turing machines, does\nmachine \\(T_i\\) halt on the input \\(n\\)? \nAn equivalent question can also be formulated in terms of the partial\nrecursive functions: \nIs the partial computable function \\(\\phi_i(x)\\) defined for input\n\\(n\\)? \nThe pairs of natural numbers \\(\\langle i,n \\rangle\\) corresponding to\npositive answers to this question determine a subset of \\(\\mathbb{N}\n\\times \\mathbb{N}\\) as follows:  \nA set (or problem) is said to be undecidable\njust in case its characteristic function is not computable. For\ninstance let \\(h(x,y) = \\chi_{\\HP}(x,y)\\) and observe that this, by\ndefinition, is a total function. The so-called\nundecidability of the Halting Problem may now be formulated\nas follows: \nTheorem 3.3: \\(h(x,y)\\) is not a computable\nfunction. \nProof: Suppose for a contradiction that \\(h(x,y)\\) were\ncomputable. Consider the function \\(g(x)\\) defined as  \nOn the assumption that \\(h(x,y)\\) is computable, \\(g(x)\\) is partial\ncomputable since, e.g., it may be computed by a program which on input\n\\(x\\) computes \\(h(x,x)\\) and returns 0 just in case \\(h(x,x) = 0\\)\nand otherwise goes into an infinite loop. It hence follows that \\(g(x)\n\\simeq \\phi_j(x)\\) for some \\(j \\in \\mathbb{N}\\). But now observe that one\nof the following two alternatives must hold: i) \\(g(j) \\darrow\\);\nor ii) \\(g(j)\\uarrow\\). We may thus reason by cases as follows: \nSuppose that \\(g(j) \\darrow\\). Then \\(h(j,j) = 0\\) by definition of\n\\(g(x)\\). Since \\(h(i,x)\\) is the characteristic function of\n\\(\\HP\\), this means \\(\\phi_j(j) \\uarrow\\). But then since \\(g(x)\n\\simeq \\phi_j(x)\\), \\(g(j) \\uarrow\\), a contradiction. \nSuppose that \\(g(j) \\uarrow\\). Then \\(h(j,j) \\neq 0\\) by definition\nof \\(g(x)\\). Since \\(h(x,y)\\) is the characteristic function of\n\\(\\HP\\) (and hence total), the only other possibility is that \\(h(j,j)\n= 1\\) which in turn implies that \\(\\phi_j(j) \\darrow\\). But then\nsince \\(g(x) \\simeq \\phi_j(x)\\), \\(g(j) \\darrow\\), a contradiction.\n□  \n\\(h(x,y)\\) thus provides an initial example of a mathematically\nwell-defined total function which is not computable. Other\nnon-computable functions can be defined by considering decision\nproblems similar to \\(\\HP\\). Some well-known examples are as follows:\n \nSuppose we let \\(k(x), z(x), \\textit{tot}(x)\\), and\n\\(\\textit{fin}(x)\\) be the characteristic functions of these sets. By\nmaking suitable modifications to the proof of\n Theorem 3.3\n it is possible to directly show the following: \nProposition 3.1: None of the functions \\(k(x), z(x),\n\\textit{tot}(x)\\), and \\(\\textit{fin}(x)\\) are computable.  \nFor instance in the case of \\(k(x)\\), we may argue as follows: \nAs this is again a contradictory situation, we may conclude that\n\\(k(x)\\) is not computable. \nNote that each of the sets \\(I\\) defined in (\\ref{undecexs}) has\nthe following property: if \\(j \\in I\\) and \\(\\phi_j(x) \\simeq\n\\phi_k(x)\\), then \\(k \\in I\\) as well. Sets with this property are\nknown as index sets as they collect together the indices of\nall partial computable functions which share a common\n“semantic” property—i.e., one which is completely\ndetermined by their graphs such as being coincident with the constant\n0 function in the case of \\(Z\\) or being defined on all inputs in the\ncase of \\(\\TOT\\). An index set \\(I\\) is called non-trivial\nif \\(I \\neq \\emptyset\\) or \\(I \\neq \\mathbb{N}\\)—i.e., it fails\nto either include or exclude all indices. It is easy to see that all\nof the sets defined in (\\ref{undecexs}) are non-trivial index sets.\nThe undecidability of these sets thus follows from the following\nmore general result: \nTheorem 3.4 (Rice 1953): If \\(I\\) is a non-trivial\nindex set, then \\(I\\) is undecidable. \nProof: Let \\(I\\) be a non-trivial index set and suppose\nfor a contradiction that \\(\\chi_I(x)\\) is computable. Consider the\neverywhere undefined unary function \\(u(x)\\)—i.e., \\(u(n)\n\\uarrow\\) for all \\(n \\in \\mathbb{N}\\). Since \\(u(x)\\) is partial\ncomputable, there is an index \\(b\\) such that \\(\\phi_b(x) \\simeq\nu(x)\\). We may suppose without loss of generality that \\(b \\not\\in\nI\\). (If it is the case that \\(b \\in I \\neq \\mathbb{N}\\), then we can\nswitch the role of \\(I\\) with its complement \\(\\overline{I}\\) in\nthe following argument and obtain the same result). Since \\(I \\neq\n\\emptyset\\), we can also choose an index \\(a \\in I\\) and define a\nfunction as follows:  \nNote that \\(f(x,y)\\) is partial computable since it is defined by\ncases in terms of \\(\\phi_a(x)\\) based on the value of \\(\\phi_x(x)\\).\nThere is thus an index \\(c\\) such that \\(f(x,y) \\simeq \\phi_c(x,y)\\).\nBy applying the\n s-m-n Theorem (3.1),\n we thus have that \\(\\phi_c(x,y) \\simeq \\phi_{s^2_1(c,x)}(y)\\). But\nnote that we now have the following sequences of implications: \n(by our choice of \\(a \\in I\\)) \n(by our assumptions that \\(b\\) is an index for \\(u(x)\\)—the\neverywhere undefined function—and that \\(b \\not\\in I\\)).\n \nIt hence follows that the value of \\(k(x)\\) may be computed by\napplying the following algorithm:  \nEither by invoking Church’s Thesis or by formalizing the prior\nalgorithm as a partial recursive definition, it follows that \\(k(x)\\)\nis computable. But this contradicts\n Proposition 3.1\n which shows that \\(k(x)\\) is not computable.\n□ \n\n Rice’s Theorem (3.4)\n provides a means of showing that many decision problems of practical\nimport are undecidable—e.g., of determining whether a program\nalways returns an output or whether it correctly computes a given\nfunction (e.g., addition or multiplication). Its proof also shows that\nif \\(I\\) is a non-trivial index set, the problem of deciding \\(x\n\\in K\\) can be “reduced” to that of deciding \\(x \\in I\\)\nit the following sense: if we could effectively decide the\nlatter, then we could also effectively decide the former by\nfirst calculating \\(s^2_1(c,x)\\) and then checking if this value is in\n\\(I\\). This method of showing undecidability will be formalized by\nthe notion of a many-one reduction described in\n Section 3.5\n below. \nA set \\(A \\subseteq \\mathbb{N}\\) is said to be computable (or\nrecursive according to the older terminology of\n Section 2)\n just in case its characteristic function is. More generally we have\nthe following: \nDefinition 3.1: A relation \\(R \\subseteq\n\\mathbb{N}^k\\) is computable just in case \\(\\chi_R(\\vec{x})\\)\nis computable. \nThis definition extends the definition of a primitive recursive\nrelation given in\n Section 2.1—e.g.,\n since sets like PRIMES and DIV are primitive\nrecursive they are ipso facto computable. Via Church’s\nThesis, the notion of a computable set thus also generalizes the\naccompanying heuristic about effective decidability—i.e., \\(R\\)\nis computable just in case there is an algorithm for deciding if\n\\(R(\\vec{n})\\) holds which always returns an answer after a finite\n(although potentially unbounded) number of steps. On the other hand,\nit follows from the observations recorded in\n Section 3.2\n that none of HP, K, Z, TOT, or\nFIN are computable sets. \nA related definition is that of a computably enumerable (or\nc.e.) set—i.e., one whose members can be\nenumerated by an effective procedure. (In the older terminology of\n Section 2\n such a set is said to be recursively enumerable which is traditionally abbreviated r.e.) Officially we have the\nfollowing: \nDefinition 3.2: \\(A \\subseteq \\mathbb{N}\\) is\ncomputably enumerable (or c.e.) if \\(A = \\emptyset\\) or \\(A\\)\nis the range of a computable function—i.e., \nfor some index \\(e\\) of a total computable function. \nThis definition can be extended to relations by viewing \\(m\\) as a\ncode for a finite sequence in the obvious way—i.e., \\(R\n\\subseteq \\mathbb{N}^k\\) is c.e. just in case there is a\ncomputable function \\(\\phi_e(x)\\) such that \\(R(n_0, \\ldots, n_k)\\) if\nand only if \\(\\phi_e(n) = \\langle n_0, \\ldots, n_k \\rangle\\) for some\n\\(n \\in \\mathbb{N}\\). \nIf \\(A\\) is computably enumerable, its members may thus be listed off\nas  \npossibly with repetitions—e.g., the constant function\n\\(\\const_{17}(x)\\) enumerates the singleton set \\(\\{17\\}\\), which is\nthereby c.e. It is easy to see that a computable set \\(A\\) is\ncomputably enumerable. For if \\(A = \\emptyset\\), then \\(A\\) is\nc.e. by definition. And if \\(A \\neq \\emptyset\\), we may choose\n\\(a \\in A\\) and then define  \nIn this case \\(f(x)\\) is computable and has \\(A\\) as its range. \nIn proving facts about computably enumerable sets, it is often\nconvenient to employ one of several equivalent definitions: \nProposition 3.2: Suppose \\(A \\subseteq \\mathbb{N}\\).\nThen the following are equivalent: \n\\(A\\) is computably enumerable. \n\\(A = \\emptyset\\) or \\(A\\) is the range of a primitive recursive\nfunction. \n\\(A = \\{n \\in \\mathbb{N}: \\exists y R(n,y)\\}\\) for a computable\nrelation \\(R\\). \n\\(A\\) is the domain of a partial computable function. \nThe proof of\n Proposition 3.2\n is largely a matter of unpacking definitions. For instance, to see\nthat iv implies i, suppose that \\(A =\n\\textrm{dom}(\\phi_e)\\)—i.e., \\(A = \\{n \\in \\mathbb{N} :\n\\phi_e(n) \\darrow\\}\\). If \\(A = \\emptyset\\) it is automatically\nc.e. Otherwise, there is an element \\(a \\in A\\). We may now define\n \n\\(f(x)\\) thus treats its input as a pair \\(\\langle n,s \\rangle\\)\nconsisting of an input \\(n\\) to \\(\\phi_e(x)\\) and a computation\nsequence \\(s\\) as defined in the proof of the Normal Form Theorem\n (2.3).\n As \\(x\\) varies over \\(\\mathbb{N}\\), it thus steps through all\npossible inputs \\((x)_0\\) to \\(\\phi_e\\) and also all possible\nwitnesses \\((x)_1\\) to the fact that the computation of \\(\\phi_e\\) on\n\\((x)_0\\) halts. It then returns \\((x)_0\\) if \\((x)_1\\) is such a\nwitness to a halting computation and \\(a\\) otherwise. Thus the range\nof \\(f(x)\\) will correspond to that of \\(\\phi_e(x)\\). And as\n\\(T_1(e,x,s)\\) is computable (and in fact primitive recursive)\nrelation, it is easy to see that \\(f(x)\\) is a computable function\nwith range \\(A\\). This shows that \\(A\\) is c.e. as desired. \nPart iv of\n Proposition 3.2\n also provides a convenient uniform notation for computably enumerable\nsets—i.e., if \\(A = \\textrm{dom}(\\phi_e)\\) we denote \\(A\\) by\n\\(W_e = \\{n : \\phi_e(n) \\darrow\\}\\). The sequence \\(W_0,W_1, W_2,\n\\ldots\\) thus provides a uniform enumeration of c.e. sets\nrelative to our prior enumeration of unary partial computable\nfunctions. This notation also aids the formulation of the\nfollowing: \nProposition 3.3: \nThe computably enumerable sets are effectively closed under union,\nintersection, and cross product—i.e., there are computable\nfunctions \\(\\textit{un}(x,y),\\) \\(\\textit{int}(x,y)\\) and\n\\(\\textit{cr}(x,y)\\) such that if \\(A = W_i\\) and \\(B = W_j\\) then \nand \nThe computable sets are additionally closed under complementation and\nrelative complementation—i.e., if \\(A\\) and \\(B\\) are recursive,\nthen so are \\(\\overline{A}\\) and \\(A - B\\). \nThe proofs of these facts are also straightforward upon appeal to\nChurch’s Thesis. For instance, if \\(\\textrm{dom}(\\phi_i) = A\\)\nand \\(\\textrm{dom}(\\phi_j) = B\\) then \\(\\textit{un}(i,j)\\) can be\ntaken to be an index for a program which simulates the computation of\n\\(\\phi_i(n)\\) and \\(\\phi_j(n)\\) in alternate stages and halts just in\ncase one of these subcomputations halt. Note also that if \\(A = W_i\\)\nis computable, then \\(\\chi_{\\overline{A}}(x) = 1 \\dotminus \\chi_A(x)\\)\nis also computable, from which it follows that \\(\\overline{A}\\) is\n computable.[21] \nA related observation is the following: \nProposition 3.4 (Post 1944): \\(A\\) is computable if\nand only if \\(A\\) and \\(\\overline{A}\\) are both computably\nenumerable. \nThe left-to-right direction is subsumed under\n Proposition 3.3.\n For the right-to-left direction, suppose that \\(A =\n\\textrm{dom}(\\phi_i)\\) and \\(\\overline{A} = \\textrm{dom}(\\phi_j)\\).\nThen to decide \\(n \\in A\\) we can perform an unbounded search for a\ncomputation sequence \\(s\\) such that either \\(T_1(i,n,s)\\) or\n\\(T_1(j,n,s)\\), accepting in the first case and rejecting in the\nsecond. Since \\(A \\cup \\overline{A} = \\mathbb{N}\\), the search must\nalways terminate and since \\(A \\cap \\overline{A} = \\emptyset\\), the\nconditions are exclusive. Thus by again appealing to Church’s\nThesis, \\(A\\) is computable. \nWe have seen that the computable sets are contained in the computably\nenumerable sets. Two questions which arise at this stage are as\nfollows: \nA positive answer to both is provided by the following: \nCorollary 3.1: Recall the set \\(K = \\{i : \\phi_i(i)\n\\darrow\\}\\)—i.e., the so called Diagonal Halting\nProblem. \\(K\\) is computably enumerable but not computable while\n\\(\\overline{K}\\) is not computably enumerable. \n\\(K\\) is clearly c.e. as it is the domain of \\(\\mu s\nT_1(x,x,s)\\). On the other hand, we have seen that the characteristic\nfunction of \\(K\\)—i.e., the function \\(\\chi_K(x) = k(x)\\) as\ndefined in\n Section 3.2—is\n not computable. Thus \\(K\\) is indeed a computably enumerable set\nwhich is not computable. To see that \\(\\overline{K}\\) is not c.e.,\nobserve that if it were, then \\(K\\) would be computable by\n Proposition 3.4.\n This in turn suggests a sense in which it is “harder” to\ndecide membership in \\(K\\) than in any computable set. The\nhierarchies introduced in\n Sections 3.5\n and\n Section 3.6\n will provide a means of making such observations precise. \nThe result which is now most often referred to as Kleene’s\nRecursion Theorem can be used to unify a number of effective\ndiagonal arguments similar to that underlying\n Theorem 3.3\n and has a wide range of applications both in computability theory and\nother areas of mathematical logic and computer\n science.[22]\n Although its statement is straightforward, both its significance and\nthe following proof become clearer upon considering subsequent\napplications. \nTheorem 3.5 (Kleene 1938): Suppose that \\(f(x)\\) is a\ntotal computable function. Then there is a number \\(n \\in \\mathbb{N}\\)\nsuch that \\(\\phi_n(y) \\simeq \\phi_{f(n)}(y)\\). \nProof: Consider the function \\(g(x,y)\\) defined as follows:\n \nAs it is evident that \\(g(x,y)\\) is partial computable, \\(g(x,y)\n\\simeq \\phi_e(x,y)\\) for some \\(e\\). It thus follows by the\n s-m-n Theorem (3.1)\n that \\(\\phi_e(x,y) \\simeq \\phi_{s^2_1(e,x)}(y)\\). Let \\(b(x) =\ns^2_1(e,x)\\) and note that we then have \\(\\phi_{b(x)}(y)\\) is the same\nfunction as \\(\\phi_{\\phi_x(x)}(y)\\) provided that \\(\\phi_x(x)\\) is\ndefined. Note that \\(b(x)\\) is a total computable function and is\ndefined independently of the given function \\(f(x)\\). \nNext let \\(k\\) be an index for the composition of \\(f(x)\\) with\n\\(b(x)\\)—i.e., \\(\\phi_k(x) \\simeq f(b(x))\\). We now claim that\n\\(n = b(k)\\) is the number called for in the statement of the theorem.\nFor first note that since \\(b(x)\\) and \\(f(x)\\) are both total,\n\\(\\phi_k(x)\\) is also total and thus \\(\\phi_k(k)\\) is defined. From\nthis it follows that \\(\\phi_{b(k)}(y) \\simeq \\phi_{\\phi_k(k)}(y)\\). We\nnow have the following sequence of functional identities:  \n□ \nThe Recursion Theorem is sometimes also referred to as the Fixed\nPoint Theorem. Note, however, that\n Theorem 3.5\n does not guarantee the existence of an extensional fixed point for\nthe given function \\(f(x)\\)—i.e., a number \\(n\\) such that\n\\(f(n) = n\\). (In fact it is evident that there are computable\nfunctions for which no such value exists—e.g., \\(f(x) = x+1\\).)\nBut suppose we view \\(f(x)\\) instead as a mapping on indices to\npartial computable functions or, more figuratively, as a means of\ntransforming a program for computing a partial computable\nfunction into another program. On this interpretation, the theorem expresses\nthat for every such computable transformation there is some program\n\\(n\\) such that the function \\(\\phi_n(y)\\) which it computes is the\nsame as the function \\(\\phi_{f(n)}(y)\\) computed by its image \\(f(n)\\)\nunder the transformation. \nAs it may at first appear such an \\(n\\) is defined in a circular\nmanner, it is also prima facie unclear why such a program\nmust exist. Indeed Soare (2016, 28–29) remarks that the\nforegoing proof of the Recursion Theorem is “very short but\nmysterious” and is “best visualized as a diagonal argument\nthat fails”. In order to clarify both this comment and the\nproof, consider the matrix depicted in Figure 1 whose rows \\(R_i\\)\nenumerate not the values of partial computable functions but rather the\nfunctions themselves—i.e., the row \\(R_i\\) will contain the\nfunctions \\(\\phi_{\\phi_i(0)}, \\phi_{\\phi_i(1)}, \\ldots\\) with the\nunderstanding that if \\(\\phi_i(j) \\uarrow\\), then\n\\(\\phi_{\\phi_i(j)}\\) denotes the totally undefined function. (Such a\ndepiction is originally due to Owings 1973.) \nFigure 1: The matrix of partial\ncomputable functions employed in the proof of the\n  Recursion Theorem (3.5)\n  \nWe may think of the function \\(f(x)\\) given in\n Theorem 3.5\n as inducing a transformation on the rows so that \\(R_i\\) is mapped to\n\\(R_{f(i)}\\). To this end, let \\(h_f(x)\\) be an index to the total\ncomputable function which composes \\(f\\) with \\(\\phi_x\\) so that we\nhave  \nNext consider the diagonal of this matrix—i.e., \\(D =\n\\phi_{\\phi_0(0)}, \\phi_{\\phi_1(1)}, \\ldots\\) Since the indices to the\nfunctions which comprise \\(D\\) are given effectively, it must be the\ncase that \\(D\\) itself corresponds to some row \\(R_d\\)—i.e.,\n \nBut now consider the image of \\(R_d\\) under \\(f\\)—i.e., the row\n\\(R_{h_f(d)} = \\phi_{\\phi_{h_f(d)}(0)}, \\phi_{\\phi_{h_f(d)}(1)},\n\\ldots\\) It follows from (\\ref{dr}) that we must have  \nBut note that by the definition of \\(h_f\\), \\(\\phi_{h_f(d)}(h_f(d)) =\nf(\\phi_d(h_f(d))\\) and thus also from (\\ref{lastrecthm1})  \nBut now note that since \\(f,\\phi_d\\) and \\(h_f\\) are all total, the\nvalue \\(\\phi_d(h_f(d))\\) is defined. Thus setting \\(n =\n\\phi_d(h_f(d))\\) it follows from (\\ref{lastrecthm2}) that \\(\\phi_n(y)\n\\simeq \\phi_{f(n)}(y)\\) as desired. \nAs mentioned above, the Recursion Theorem may often be used to present\ncompact proofs of results which would traditionally be described as\ninvolving self-reference. For instance, an immediate\nconsequence is that for every \\(f(x)\\) there is an \\(n\\) such that\n\\(W_n = W_{f(n)}\\). To see this note that\n Theorem 3.5\n entails the existence of such an \\(n\\) such that \\(\\phi_n(x)\n\\simeq \\phi_{f(n)}\\) for every computable \\(f(x)\\). But since the\ndomains of the functions must then coincide, it follows that \\(W_n =\nW_{f(n)}\\). \nIt is useful to record the following alternative form of the Recursion\nTheorem: \nCorollary 3.2: For every partial computable function\n\\(f(x,y)\\), there is an index \\(n\\) such that \\(\\phi_n(y) \\simeq\nf(n,y)\\). \nProof: By the\n s-m-n Theorem (3.1),\n \\(f(x,y) \\simeq \\phi_{s^2_1(i,x)}(y)\\) for some \\(i\\). But then the\nexistence of the required \\(n\\) follows by applying\n Theorem 3.5\n to \\(s^2_1(i,x)\\). □ \nHere are some easy consequences in the spirit described above which\nmake use of this formulation: \nThere is a number \\(n\\) such that \\(\\phi_n(x) = x + n\\). (This\nfollows by taking \\(f(x,y) = x + n\\) in\n Corollary 3.2.\n Analogous observations yield the existence of \\(n\\) such that\n\\(\\phi_n(x) = x \\times n, \\phi_n(x) = x^n\\), etc.) \nThere is a number \\(n\\) such that \\(W_n = \\{n\\}\\). (Take  \nin\n Corollary 3.2.) \nConsider a term \\(\\tau\\) corresponding to a “program”\nwhich determines the partial computable program with index \\(\\ulcorner\n\\tau \\urcorner\\) (as described in\n Section 2.2.2).\n We say that such a program is self-reproducing if for all\ninputs \\(x\\), the computation of \\(\\tau\\) on \\(x\\) outputs \\(\\ulcorner\n\\tau \\urcorner\\). Since in order to construct \\(\\tau\\) it would seem\nthat we need to know \\(\\ulcorner \\tau \\urcorner\\) in advance, it might\nappear that self-reproducing programs need not exist. Note, however,\nthat transposed back into our official terminology, the existence of\nsuch a program is equivalent to the existence of a number \\(n\\) such that\n\\(\\phi_n(x) = n\\). And this is guaranteed by applying\n Corollary 3.2\n to the function \\(f(x,y) = x\\). \nFor further discussions of the Recursion Theorem in regard to\nself-reference and more advanced applications in computability theory\nsee, e.g., Cutland (1980, ch. 11), Rogers (1987, ch. 11), Odifreddi (1989, ch.\nII.2), and Y. Moschovakis (2010). \nBefore leaving the Recursion Theorem, it will finally be useful to reflect on how it bears on the general concept of recursive definability as discussed in Sections 1 and 2.   Consider, for instance, a simple definition such as\n  \nIn the case that \\(f(y)\\) and \\(g(y)\\) are primitive recursive, we\nhave remarked that it is possible to show that there exists a unique\nfunction \\(h(y)\\) satisfying (\\ref{recex}) by an external\nset-theoretic argument. But we may also consider the case in which\n\\(g(y)\\) is assumed to be computable relative to a model of\ncomputation \\(\\mathbf{M}\\) which differs from the partial recursive\nfunctions in that it does not natively support recursion as a mode of\ncomputation—e.g., the Turing Machine model \\(\\mathbf{T}\\) or\nUnlimited Register Machine model \\(\\mathbf{U}\\). If we simply set down\n(\\ref{recex}) as a definition in this case, we would have no a\npriori assurance that \\(h(y)\\) is computable relative to\n\\(\\mathbf{M}\\) even if \\(g(x)\\) is. \nUpon examination, however, it is clear that the only features of a\nmodel of computation on which the proof of\n Theorem 3.5\n relies are the existence of an indexation for which a version of the\n s-m-n Theorem (3.1)\n is available. If \\(\\mathbf{M}\\) satisfies these conditions, the claim\nthat \\(h(y)\\) is computable relative to \\(\\mathbf{M}\\) is equivalent\nto \\(h(y) \\simeq \\phi_n(y)\\) where \\(n\\) is an index drawn from some suitable indexation of\nthe \\(\\mathbf{M}\\)-computable functions. But since the s-m-n\nTheorem for \\(\\mathbf{M}\\) allows us to treat an index as a variable,\nwe can also consider the function defined by  \nNow note that the existence of an \\(n\\) such that \\(f(n,y) \\simeq\n\\phi_n(y)\\) is again guaranteed by\n Corollary 3.2.\n This in turn yields  \nThis illustrates how the existence of a computable function satisfying\na recursive definition such as (\\ref{recex}) follows from the\nRecursion Theorem even if we have not started out by characterizing a\n“computable function” as one defined\n“recursively” in the informal sense discussed in\n Section 1.\n And this in turn helps to explain why\n Theorem 3.5\n has come to be known as the Recursion Theorem. \nA central topic in contemporary computability theory is the study of\nrelative computability—i.e., if we assume that\nwe are able to decide membership in a given set or compute a given\nfunction, which other sets or functions would we be able to decide or\ncompute? This question may be studied using the notion of a\nreduction of one set \\(A\\) to another \\(B\\) which was\nintroduced informally by Kolmogorov (1932) as a means of transforming\na “solution” of \\(A\\) into a “solution” of\n \\(B\\).[23]\n Turing (1939) provided the first formal definition of a computational\nreduction in his study of ordinal logics. However, it was Post who\nfirst proposed to systematically study reducibility notions and their\nassociated degree structures in his highly influential paper\n“Recursively enumerable sets of positive integers and their\ndecision problems” (1944). \nTherein Post explains the basic idea of a reduction and its\nsignificance as follows: \nRelated to the question of solvability or unsolvability of problems is\nthat of the reducibility or non-reducibility of one problem to\nanother. Thus, if problem \\(P_1\\) has been reduced to problem \\(P_2\\),\na solution of \\(P_2\\) immediately yields a solution of \\(P_1\\), while\nif \\(P_1\\) is proved to be unsolvable, \\(P_2\\) must also be\nunsolvable. For unsolvable problems the concept of reducibility leads\nto the concept of degree of unsolvability, two unsolvable problems\nbeing of the same degree of unsolvability if each is\nreducible to the other, one of lower degree of unsolvability than\nanother if it is reducible to the other, but that other is not\nreducible to it, of incomparable degrees of unsolvability if neither\nis reducible to the other. A primary problem in the theory of\nrecursively enumerable sets is the problem of determining the degrees\nof unsolvability of the unsolvable decision problems thereof. We shall\nearly see that for such problems there is certainly a highest degree\nof unsolvability. Our whole development largely centers on the single\nquestion of whether there is, among these problems, a lower degree of\nunsolvability than that, or whether they are all of the same degree of\nunsolvability. (Post 1944, 289) \nIn order to appreciate this passage, it is again useful to think of a\nset \\(A \\subseteq \\mathbb{N}\\) as being associated with the\nproblem of deciding membership in \\(A\\)—e.g., given a\nnatural number \\(n\\), is \\(n\\) prime? (i.e., \\(n \\in\n\\textit{PRIMES}\\)?) or is the \\(n\\)th partial computable function\nwith input \\(n\\) defined? (i.e., \\(n \\in K\\)?). But even given this\ncorrespondence, the assertion that a solution to a problem \\(B\\)\n“immediately yields” a solution to \\(A\\) may still be\nanalyzed in a number of different ways. Two of the most important\npossibilities are as follows: \nAssuming that there is an algorithm for deciding questions of the form\n\\(n \\in B\\), then it is possible to specify an algorithm for deciding\nquestions of the form \\(n \\in A\\). \nAssuming that we had access to an “oracle”\ncapable of answering arbitrary questions of the form \\(n \\in B\\) in a\nsingle step, then it is possible to specify an algorithm employing the\noracle for deciding \\(n \\in A\\). \nThe formalization of these relations between problems leads to the\nnotions of many-one reducibility and Turing\nreducibility which provide distinct but complementary analyses of\nthe notions \\(A\\) is no harder to solve than \\(B\\) and also\nthe degree of unsolvability (or difficulty) of\n\\(A\\) is equal to that of\n \\(B\\).[24]\n The latter notion came first historically and was introduced by\nTuring (1939) and in an equivalent form by Kleene (1943). However it\nwas Post (1944) who both introduced the former notion and also\ninitiated the general study of Turing reducibility. In fact the final\nsentence of the passage quoted above describes an important technical\nquestion about the Turing degrees which would shape the early\ndevelopment of computability theory (i.e., “Post’s\nproblem” given as\n Question 3.1\n below). \nWe have already seen an example of many-one reducibility in the proof\nof\n Rice’s Theorem (3.4).\n In particular, the proof showed that the problem of deciding\nmembership in \\(K\\) can be reduced to that of deciding membership\nin any non-trivial index set \\(I\\) in the following sense: for all\n\\(n\\), if \\(n \\in K\\) then \\(s^2_1(c,n) \\in I\\). Thus if there were\nan algorithm for deciding membership in \\(I\\), we would be able to\ndecide whether \\(n \\in K\\) by using it to test whether \\(s^2_1(c,n)\n\\in I\\). The function \\(s^2_1(c,x)\\) (whose computability is given by\nthe s-m-n Theorem) is thus a so-called many-one\nreduction of \\(K\\) to \\(I\\). \nThe formal definition generalizes this example as follows: \nDefinition 3.3: Given sets \\(A, B \\subseteq\n\\mathbb{N}\\), \\(A\\) is said to be many-one (or \\(m\\)-one)\nreducible to \\(B\\) if there is a computable function \\(f(x)\\)\nsuch that for all \\(n \\in \\mathbb{N}\\),  \nIn this case we write \\(A \\leq_m B\\). \nUsing this notation, the foregoing example thus shows that \\(K \\leq_m\nI\\). These observations can generalized as follows: \nProposition 3.5: Suppose that \\(A \\leq_m B\\). \nIf \\(B\\) is computable, then so is \\(A\\). \nIf \\(B\\) is computably enumerable, then so is \\(A\\). \nBy contraposing\n Proposition 3.5\n it thus follows that in order to show that a set \\(B\\) is\nnon-computable (or non-c.e.) it suffices to show that a known\nnon-computable (or non-c.e.) set can be reduced to it. As an initial\nexample, observe that the Diagonal Halting Problem \\(K = \\{i :\n\\phi_i(i) \\darrow\\}\\) is reducible to the Halting Problem \\(\\HP =\n\\{\\langle i,n \\rangle : \\phi_i(n) \\darrow\\}\\) by the reduction\n\\(f(x) = \\langle x,x \\rangle\\)—i.e., the computable pairing\nfunction of \\(x\\) with itself is a many-one reduction showing \\(K\n\\leq_m \\HP\\). Thus since \\(\\HP\\) is known to be non-computable, this\ngives another proof that \\(K\\) also is not computable. \nReducibility notions also typically come with an associated notion of\nwhat it means for a designated set to be complete relative to\na class of sets—i.e., a set to which every set in the class may\nbe reduced and which is itself a member of the class. As an initial\nexample we have the following: \nDefinition 3.4: A set \\(B\\) is said to be\nmany-one (or \\(m\\)-) complete for the computably\nenumerable sets just in case the following conditions hold: \n\\(B\\) is computable enumerable; \nFor all computably enumerable sets \\(A\\), \\(A \\leq_m B\\). \nAn obvious example of a complete c.e. set is \\(\\HP\\). For since \\(\\HP\n= \\{\\langle i,n \\rangle : \\exists s T_1(i,n,s)\\}\\) and \\(T_1(x,y,z)\\)\nis a computable relation, it follows from\n Proposition 3.2\n that \\(\\HP\\) is c.e. And on the other hand, if \\(A = W_i\\), then \\(n\n\\in A\\) if and only if \\(\\langle i,n \\rangle \\in \\HP\\) thus showing\nthat \\(W_i \\leq_m \\HP\\). \nIt is, nonetheless, standard to take \\(K\\) rather than \\(\\HP\\) as the\ncanonical complete c.e. Although it might at first seem that \\(K\\)\ncontains “less computational information” than \\(\\HP\\), it\nis not hard to see that \\(K\\) is also such that every c.e. set is\n\\(m\\)-reducible to it. For supposing that \\(A = W_i\\), we may define a\nfunction  \nAs \\(f(x,y)\\) is clearly partial computable, the\n s-m-n Theorem (3.1)\n gives a total recursive function \\(s^2_1(i,x)\\) such that \\(f(x,y)\n\\simeq \\phi_{s^2_1(i,x)}(y)\\). We then have  \nThese biconditionals hold because \\(\\phi_i(n) \\darrow\\) just in\ncase \\(\\phi_{s^2_1(i,n)}(y)\\) is \\(\\const_1(x)\\) (i.e., the constant\n1-function) as opposed to the everywhere undefined function just in\ncase \\(\\phi_{s^2_1(i,n)}(s^2_1(i,n)) \\darrow\\). But as the later\ncondition is equivalent to \\(s^2_1(i,n) \\in K\\), \\(s^2_1(i,x)\\) is a\nmany-one reduction showing \\(A \\leq_m K\\). \nThis illustrates a sense in which deciding membership in \\(K\\) can\nalso be understood as universal for computably enumerable sets or,\nalternatively, that there is no c.e. set which is any\n“harder” to solve than \\(K\\). Nonetheless, there are\nproblems that are harder to solve than \\(K\\) in the sense that they\ncould not be solved even if we possessed a decision algorithm for\n\\(K\\). For instance, it will follow from results given below that\nwhile \\(K\\) is \\(m\\)-reducible to \\(\\TOT\\), \\(\\TOT\\) is not \\(m\\)-reducible\nto \\(K\\). This illustrates how \\(m\\)-reducibility can be\nused to study the relative difficulty of solving\ncomputational problems. \nThese considerations lead naturally to the notion of a degree of\ndifficulty—another concept which can be made precise with\nrespect to different reducibility notions. The version for many-one\nreducibility is given by the following definition: \nDefinition 3.5: If \\(A\\) and \\(B\\) are many-one\nreducible to each other—i.e., \\(A \\leq_m B\\) and \\(B \\leq_m\nA\\)—then we say that \\(A\\) and \\(B\\) are many-one\nequivalent and we write \\(A \\equiv_m B\\). \nIt follows immediately from\n Definition 3.3\n that \\(\\leq_m\\) is reflexive. It is also clearly transitive. (For if\n\\(f(x)\\) and \\(g(x)\\) are computable functions which respectively\nserve as many-one reductions showing \\(A \\leq_m B\\) and \\(B \\leq_m\nC\\), then their composition \\(f(g(x))\\) is a many-one reduction\nshowing \\(A \\leq_m C\\).) As it thus follows that \\(\\equiv_m\\) is an\nequivalence relation, it also makes sense to define the following: \nDefinition 3.6: \\(\\textrm{deg}_m(A)\\)—the\nmany-one (or \\(m\\)-) degree of \\(A\\)—is the\nequivalence class of \\(A\\) with respect to \\(\\equiv_m\\)—i.e.,\n\\(\\textrm{deg}_m(A) = \\{B \\subseteq \\mathbb{N} : B \\equiv_m A\\}\\).  We call an \\(m\\)-degree computable if it contains a\ncomputable set and c.e. if it contains a computably enumerable\nset.  \nThe \\(m\\)-degree \\(\\textrm{deg}(A)\\) of \\(A\\) collects together\nall sets which are many-one equivalent to it. It can thus be thought\nof as an abstract representation of the relative difficulty of\ndeciding membership in \\(A\\) when this latter notion is in turn\nexplicated in terms of \\(m\\)-reducibility. For instance, since our\nprior observations show that \\(\\textrm{deg}_m(\\HP) =\n\\textrm{deg}_m(K)\\), they are thus “equally difficult”\nc.e. degrees. \nIt is traditional to use boldface lower case Roman letters\n\\(\\mathbf{a},\\mathbf{b}, \\ldots\\) to denote degrees (although it\nshould be kept in mind that these are sets of sets of natural\nnumbers). We next define an ordering on \\(m\\)-degrees as\nfollows: \nDefinition 3.7: Let \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\)\nbe \\(m\\)-degrees. We then define \n\\(\\mathbf{a} \\leq_m \\mathbf{b}\\) just in case there is a set \\(A \\in\n\\mathbf{a}\\) and a set \\(B \\in \\mathbf{b}\\) such that \\(A \\leq_m\nB\\). \n\\(\\mathbf{a} <_m \\mathbf{b}\\) just in case \\(\\mathbf{a} \\leq_m\n\\mathbf{b}\\) and \\(\\mathbf{a} \\neq \\mathbf{b}\\). \nIt is easy to see that \\(<_m\\) is a partial order on\n\\(m\\)-degrees—i.e., irreflexive, antisymmetric, and transitive.\nWe accordingly introduce the structure \\(\\mathcal{D}_m = \\langle\n\\{\\textrm{deg}_m(A) : A \\subseteq \\mathbb{N}\\}, <_m\\rangle\\) which\nis traditionally known as the many-one (or m-)\ndegrees. \nTogether with the similar study of the Turing degrees (which will be\ndefined in\n Section 3.5.2),\n investigating the structure of \\(\\mathcal{D}_m\\) has been a major\nfocus of research in computability theory since the time of\nPost’s (1944) introduction of the many-one degrees. Some\nproperties of this structure are as follows: \nProposition 3.6: \nThe \\(m\\)-degrees are not closed under complementation—i.e.,\nthere exist sets \\(A\\) such that \\(A \\not\\equiv_m \\overline{A}\\) and\nthus \\(\\overline{A} \\not\\in \\textrm{deg}(A)\\). \n\\(\\mathbf{0} =_{\\textrm{df}} \\textrm{deg}_m(\\emptyset) =\n\\{\\emptyset\\}\\) and \\(\\mathbf{n} =_{\\textrm{df}}\n\\textrm{deg}_m(\\mathbb{N}) = \\{\\mathbb{N}\\}\\) are distinct\n\\(m\\)-degrees both of which are (trivially) computable. \nThere is exactly one computable \\(m\\)-degree \\(\\mathbf{0}_m\\) other\nthan \\(\\mathbf{0}\\) and \\(\\mathbf{n}\\)—i.e., \\(\\mathbf{0}_m =\n\\textrm{deg}(A)\\) for any computable set \\(A \\neq \\emptyset, A\\neq\n\\mathbb{N}\\). Additionally, \\(\\mathbf{0}_m\\) is minimal in\n\\(\\mathcal{D}_m\\) in the sense that \\(\\mathbf{0}_m \\leq_m \\mathbf{a}\\)\nfor all degrees \\(\\mathbf{a}\\) other than \\(\\mathbf{0}\\) and\n\\(\\mathbf{n}\\). \nIf \\(\\mathbf{b}\\) is a c.e. degree and \\(\\mathbf{a} \\leq_m\n\\mathbf{b}\\), then \\(\\mathbf{a}\\) is also a c.e. degree. \nThere is a maximum c.e. \\(m\\)-degree—i.e.,\n\\(\\textrm{deg}_m(K) =_{\\textrm{df}} \\mathbf{0}'_m\\)—in the\nsense that \\(\\mathbf{a} \\leq \\mathbf{0}'_m\\) for all\nc.e. degrees \\(\\mathbf{a}\\). \nAny pair of \\(m\\)-degrees \\(\\mathbf{a},\\mathbf{b}\\) have a least\nupper bound \\(\\mathbf{c}\\)—i.e., \\(\\mathbf{a} \\leq_m\n\\mathbf{c}\\) and \\(\\mathbf{b} \\leq_m \\mathbf{c}\\) and \\(\\mathbf{c}\\)\nis \\(\\leq_m\\)-less than any other upper bound of \\(\\mathbf{a}\\) and\n\\(\\mathbf{b}\\). Since we have seen that \\(\\leq_m\\) is also a partial\norder, this implies that \\(\\mathcal{D}_m\\) is additionally an\nupper semi-lattice. \nThere exists a c.e. degree \\(\\mathbf{a}\\) properly between\n\\(\\mathbf{0}_m\\) and \\(\\mathbf{a} < \\mathbf{0}'_m\\)—i.e.,\n\\(\\mathbf{0}_m < \\mathbf{a} < \\mathbf{0}'_m\\). \nPost (1944) demonstrated part vii by showing that there exist\nso-called simple sets—i.e., sets \\(A\\) which are\nc.e. and such that \\(\\overline{A}\\) is infinite but does not\ncontain an infinite c.e. subset. It is easy to see that a simple\nset cannot be computable. But on the other hand, Post also showed that\na simple set cannot be \\(m\\)-complete. And it thus follows that if\n\\(A\\) is simple \\(\\mathbf{a} =_{\\textrm{df}} \\textrm{deg}_m(A) \\neq\n\\mathbf{0}_m\\) but \\(A \\not\\equiv_m K\\) and thus \\(\\mathbf{a} <\n\\mathbf{0}'_m\\). Suppose we now understand “degrees of\nunsolvability” in the passage quoted at the beginning of this\nsection as corresponding to the c.e. \\(m\\)-degrees. It thus\nfollows from part v of\n Proposition 3.6 that\n\\(\\mathbf{0}'_m\\) is indeed a “highest” such degree\nand also from part vii that there is a lower but still\n“unsolvable” (i.e., non-computable) degree. \nAlthough the other parts of\n Proposition 3.6 have\nstraightforward proofs, they provide some insight into the fact that\n\\(\\mathcal{D}_m\\) is itself a highly complex structure (see, e.g.,\nOdifreddi 1999b, 1). Nonetheless the first two parts of this theorem\nare often taken to illustrate awkward features of the many-one degrees\nas an abstract representation of computational difficulty—i.e.,\nthe exceptional behavior of \\(\\textrm{deg}_m(\\emptyset)\\) and\n\\(\\textrm{deg}_m(\\mathbb{N})\\) and the fact a set and its complement\nmay inhabit different degrees (as is easy to see is exemplified by\n\\(K\\) and \\(\\overline{K}\\)). It is partly in light of these features\nthat the Turing degrees \\(\\mathcal{D}_T\\) are the structure which are\nnow most widely studied in computability theory. But as Post also\nalludes, it is relative to \\(\\mathcal{D}_T\\) for which he was\noriginally unable to demonstrate the existence of a c.e. set of\nan intermediate degree of unsolvability. \nThe notion of relative computability mentioned at the\nbeginning of this section is now standardly analyzed in terms of\ncomputability in a set \\(A \\subseteq \\mathbb{N}\\).\nInformally, we say that a function \\(f(\\vec{x})\\) is computable in\n\\(A\\) just in case there exists an algorithm which is effective in the\ntraditional sense with the exception of the fact its computation may\nrely on computing one or more values \\(\\chi_A(y)\\). These values are\nin turn assumed to be available to the algorithm in a single step even\nthough \\(\\chi_A(y)\\) may not itself be computable—e.g., if \\(A =\nK\\). \nThis notion was originally introduced by Turing (1939) who described\nwhat he referred to as an oracle (or o-)\nmachine variant of the standard Turing Machine model\n\\(\\mathbf{T}\\). An o-machine is otherwise like a normal Turing machine\nbut also possesses a read-only oracle tape (and corresponding\nread-only head) on which the characteristic function of a set \\(A\\) is\nassumed to be written at the beginning of its computation. The\ntransitions of an o-machine are determined by its internal state\ntogether with the currently scanned symbols on both its read-write\ntape and the oracle tape, thus formalizing the idea that the machine\nmay “consult the oracle” about the characteristic function\nof \\(A\\) one or more times during the course of its\n computation.[25] \nKleene (1943) described an analogous idea for the general\nrecursive functions as follows: \nA function \\(\\phi\\) which can be defined from given functions\n\\(\\psi_1, \\ldots, \\psi_k\\) by a series of applications of general\nrecursive schemata we call general recursive in the given\nfunctions; and in particular, a function definable ab initio\nby these means we call general recursive. (Kleene 1943:\n44) \nThe former part of this characterization differs from the definition\nof general recursiveness given in\n Section 1.5\n in allowing that in addition to the initial functions \\(\\mathbf{0}\\)\nand \\(s(x)\\), the functions \\(\\psi_1, \\ldots, \\psi_k\\) can also enter\ninto systems of equations which define the function \\(\\phi\\). This\ncorresponds to the assumption that the values of \\(\\psi_1, \\ldots,\n\\psi_k\\) are available in the course of a computation without the need\nfor further calculation. \nIt is also possible to modify the definition of the partial\nrecursive functions given in\n Section 2.2.1\n to allow such relativization to an additional class of initial\nfunctions. Since relativization to a finite set of functions can be\naccomplished by successive relativization to a single function and the\ngraph of a function can also be coded into a set, this is now\nstandardly achieved as follows: \nDefinition 3.8: Given a set \\(A \\subseteq\n\\mathbb{N}\\), we define the class of \\(A\\)-partial recursive\nfunctions \\(\\mathbf{PartREC}^A\\) to be the smallest class of\npartial functions containing the initial functions \\(I_A =\n\\{\\mathbf{0},s,\\pi^i_k,\\chi_A(x)\\}\\) and closed under the\nfunctionals \nThere are, of course, uncountably many subsets of the natural numbers.\nBut for each such \\(A \\subseteq \\mathbb{N}\\), we may still understand\n\\(\\chi_A(x)\\) as a new primitive functional symbol which can be\nemployed in constructing one of countably many \\(A\\)-partial recursive\ndefinitions in the manner discussed in\n Section 2.1.1.\nIt is thus also possible to list off all of the unary \\(A\\)-partial\nrecursive functions relative to the codes of their definitions to\nobtain a uniform enumeration  \nand similarly for other arities. It is thus not difficult to see that\nwe can thereby also obtain relativized versions of results like the\n s-m-n Theorem (3.1)\n and the Universality Theorem\n (3.2)\n as exemplified by the following: \nTheorem 3.6: For all \\(A \\subseteq \\mathbb{N}\\),\nthere is an \\(A\\)-partial computable function \\(\\upsilon\\) which is\nuniversal in the sense that for all unary \\(A\\)-partial\ncomputable functions \\(f(\\vec{x})\\), there is an \\(i \\in \\mathbb{N}\\)\nsuch that \\(\\upsilon^{A}(i,x) \\simeq f(x)\\). \nThese observations in turn license the use of the expression\ncomputable in \\(A\\) to describe both a function\n\\(f(\\vec{x})\\) which is \\(A\\)-partial recursive and total and also a\nset \\(B\\) such that \\(\\chi_B(x)\\) is computable in \\(A\\). We also use\nthe expression computably enumerable (c.e.) in \\(A\\)\nto describe a set \\(B\\) which is the range of an \\(A\\)-partial\nrecursive function and the notation \\(W^A_e\\) to denote the domain of\n\\(\\phi^{A}_e(x)\\). It is then straightforward to see that many of our\nprior proofs about non-computability also carry over to the\nrelativized setting—e.g., \\(K^A = \\{i : \\phi^{A}_i(i)\\darrow\\}\\) is an example of a set which is computably enumerable in \\(A\\) but not computable in \\(A\\). \nWe may now state the definition of Turing reducibility as\nfollows: \nDefinition 3.9: Given sets \\(A, B \\subseteq\n\\mathbb{N}\\), \\(A\\) is said to be Turing (or \\(T\\)-)\nreducible to \\(B\\) just in case \\(A\\) is computable in \\(B\\).\nIn this case we write \\(A \\leq_T B\\). \nIt is a consequence of this definition that \\(A \\leq_T B\\) just in\ncase \\(\\chi_A(x)\\) coincides with the (total) \\(B\\)-computable\nfunction given by \\(\\phi^{B}_e(x)\\) for some index \\(e\\). For instance\nif we adopt Turing’s characterization of relative computability,\nwe may think of \\(e\\) as describing a program for a machine which can\nconsult \\(B\\) as an oracle. In this case, \\(A \\leq_T B\\) means that it\nis possible to decide if \\(n \\in A\\) by carrying out the program\ndescribed by \\(e\\) on the input \\(n\\) which may in turn require\nperforming queries to the oracle \\(B\\) during the course of its\ncomputation. \nWe may also define a notion of completeness with respect to \\(\\leq_T\\)\nas follows: \nDefinition 3.10: We say that \\(B\\) is Turing\ncomplete if \\(B\\) is c.e. and all c.e. sets \\(A\\) are\nsuch that \\(A \\leq_T B\\). \nIt is easy to see that \\(A \\leq_m B\\) implies \\(A \\leq_T B\\). (For if\n\\(f(x)\\) is a \\(m\\)-reduction of \\(A\\) to \\(B\\), then consider the\nprogram which first computes \\(f(n)\\) and then, using \\(B\\) an as\noracle, checks if \\(f(n) \\in B\\), outputting 1 if so and 0 if not.) It\nthus follows that \\(K\\) is also Turing complete—i.e., it\nembodies the maximum “degree of unsolvability” among the\nthe c.e. sets when this notion is understood in terms of Turing\nreducibility as well as many-one reducibility. \nSuch observations can be made precise by first defining the notion of\nTuring equivalence: \nDefinition 3.11: If \\(A\\) and \\(B\\) are Turing\nreducible to each other—i.e., \\(A \\leq_T B\\) and \\(B \\leq_T\nA\\)—then we say that \\(A\\) and \\(B\\) are Turing\nequivalent and we write \\(A \\equiv_T B\\). \nAs it is again easy to see that \\(\\equiv_T\\) is an equivalence\nrelation, we may also define the notion of Turing degree as\nfollows: \nDefinition 3.12: \\(\\textrm{deg}_T(A)\\)—the\nTuring degree of \\(A\\)—is the equivalence class of\n\\(A\\) with respect to \\(\\equiv_T\\)—i.e., \\(\\textrm{deg}_T(A) =\n\\{B \\subseteq \\mathbb{N} : B \\equiv_T A\\}\\). \nWe can now define an ordering on Turing degrees as follows: \nDefinition 3.13: Let \\(\\mathbf{a}\\) and\n\\(\\mathbf{b}\\) be Turing degrees. We then define \n\\(\\mathbf{a} \\leq_T \\mathbf{b}\\) just in case there is a set \\(A \\in\n\\mathbf{a}\\) and a set \\(B \\in \\mathbf{b}\\) such that \\(A \\leq_T\nB\\). \n\\(\\mathbf{a} <_T \\mathbf{b}\\) just in case \\(\\mathbf{a} \\leq_T\n\\mathbf{b}\\) and \\(\\mathbf{a} \\neq \\mathbf{b}\\). \nAs with the \\(m\\)-degrees, we say that \\(\\mathbf{a}\\) is a\ncomputable Turing degree if it contains a computable set\nand a computably enumerable (c.e.) degree if it\ncontains a c.e. set. If we consider the structure \n—which is known as the Turing\ndegrees—it is again easy to see that \\(\\leq_T\\) is a\npartial order. Some observations which illustrate the relationship\nbetween \\(\\mathcal{D}_T\\) and the many-one degrees \\(\\mathcal{D}_m\\)\nare as follows: \nTheorem 3.7: \nThere is exactly one computable Turing degree denoted by\n\\(\\mathbf{0}_T = \\textrm{deg}_T(\\emptyset)\\) (which is often written\n\\(\\mathbf{0}\\) when there is no possibility of ambiguity with the\n\\(m\\)-degrees). \\(\\mathbf{0}_T\\) consists of all of the computable\nsets and is the unique minimum Turing degree. \nFor all sets \\(A\\), and \\(A \\equiv_T \\overline{A}\\) and thus also\n\\(\\textrm{deg}_T(A) = \\textrm{deg}_T(\\overline{A})\\). \n\\(\\textrm{deg}_T(K)\\) is the maximum amongst all c.e. Turing\ndegrees. \nFor any sets \\(A,B\\), \\(\\textrm{deg}_m(A) \\subseteq\n\\textrm{deg}_T(A)\\) and if  then \nSince \\(\\emptyset\\) and \\(\\mathbb{N}\\) are both (trivially) computable\nsets, by part i) we have \\(\\textrm{deg}_T(\\emptyset) =\n\\textrm{deg}_T(\\mathbb{N}) = \\mathbf{0}_T\\), unlike the \\(m\\)-degrees.\nAnd also unlike the \\(m\\)-degrees we have by part ii that\n\\(\\textrm{deg}_T(A) = \\textrm{deg}_T(\\overline{A})\\). (For if we can\ndecide \\(B\\) via an algorithm which uses \\(A\\) an as oracle, then we\ncan also decide it using \\(\\overline{A}\\) as an oracle by simply\nswapping the responses obtained in our former algorithm.) \nThe structures of both \\(\\mathcal{D}_T\\) and the c.e. degrees \nhave been extensively investigated since the 1950s. One of their most\nbasic properties may be considered by first defining the operation of\nsets  \n\\(A \\oplus B\\) is called the effective join of \\(A\\) and\n\\(B\\) as it encodes the “information” contained in \\(A\\)\non the even members of \\(A \\oplus B\\) and that contained \\(B\\) on its\nodd members. \\(A \\oplus B\\) is c.e. if both \\(A\\) and \\(B\\) are.\nSuppose we also define the operation  \non the degrees \\(\\mathbf{a} = \\textrm{deg}_T(A)\\) and \\(\\mathbf{b} =\n\\textrm{deg}_T(B)\\). Then it is not difficult to see that \\(\\mathbf{a}\n\\vee \\mathbf{b}\\) is the least upper bound of \\(\\mathbf{a}\\)\nand \\(\\mathbf{b}\\) with respect to the structure \\(\\mathcal{D}_T\\).\nLike the \\(m\\)-degrees, \\(\\mathcal{D}_T\\) and \\(\\mathcal{E}_T\\) both\nform an upper semi-lattice—i.e., a partial order in\nwhich least upper bounds always\n exist.[26] \nGiven \\(A \\subseteq \\mathbb{N}\\), we may also consider \\(K^A =\\{n :\n\\phi^{A}_n(n) \\darrow\\}\\)—i.e., the set considered above\nwhich corresponds to the Diagonal Halting Problem relativized to the\noracle \\(A\\). \\(K^A\\) is referred to as the jump of \\(A\\) for\nwhich we also write \\(A'\\). This notation is also used to denote\nan operation on Turing degrees by setting \\(\\mathbf{a}' =\n\\textrm{deg}_T(A')\\) for some representative \\(A \\in \\mathbf{a}\\).\nThe following collects together several facts about the jump operation\non both sets and degrees: \nProposition 3.7: For any set \\(A, B \\subseteq\n\\mathbb{N}\\) with \\(\\textrm{deg}_T(A) = \\mathbf{a}\\) and\n\\(\\textrm{deg}_T(B) = \\mathbf{b}\\): \nIf \\(A\\) is computable, then \\(K^A \\equiv_T K\\). \n\\(A'\\) is c.e. in \\(A\\) but not computable in \\(A\\). \nIf \\(A \\leq_T B\\), then \\(A' \\leq_T B'\\) and if \\(A \\equiv_T\nB\\), then \\(A' \\equiv_T B'\\). \n\\(\\mathbf{a} <_T \\mathbf{a}'\\) \nIf \\(\\mathbf{a} \\leq_T \\mathbf{b}\\), then \\(\\mathbf{a}' \\leq_T\n\\mathbf{b}'\\). \n\\(\\mathbf{0}' \\leq_T \\mathbf{a}'\\) \nIf \\(B\\) is c.e. in \\(A\\), then \\(\\mathbf{b} \\leq_T\n\\mathbf{a}'\\). \nPart ii of\n Proposition 3.7\n records the fact that the basic result that \\(K\\) is c.e. but\nnot computable holds for computability relativized to any set \\(A\\).\nFrom this it follows that \\(A <_T A'\\) and thus also that the\nresult of iterating the jump operation on any set \\(A\\) yields a\nsequence  \nfor which \\(A^{(0)} <_T A^{(1)} <_T A^{(2)} <_T \\ldots\\). As\nbenchmarks in the Turing degrees we also define the sets \nand the degrees \\(\\mathbf{0}^{(n)} =\n\\textrm{deg}_T(\\emptyset^{(n)})\\). Note that the latter correspond to\na linearly ordered sequence  \nFigure 2: The Turing degrees\n\\(\\mathcal{D}_T\\). [A\n extended text-based description of figure 2\n is in the supplement.] \nAs depicted in Figure 2, it is possible to use this sequence to\nclassify many of the problems defined in\n Section 3.2: \n\\(\\mathbf{0} = \\textrm{deg}_T(\\emptyset) = \\{A : A \\text{ is\ncomputable}\\}\\) \n\\(\\mathbf{0}' = \\textrm{deg}_T(K) = \\textrm{deg}_T(\\HP)\\) \n\\(\\mathbf{0}'' = \\textrm{deg}_T(\\TOT) =\n\\textrm{deg}_T(\\textit{FIN})\\) \nSuch classifications illustrate how the position of a set within\n\\(\\mathcal{D}_T\\) can be understood as a measure of how far away it is\nfrom being computable—i.e., of its degree of\nunsolvability or difficulty. However unlike other\nconventional measurement scales, the structure of \\(\\mathcal{D}_T\\) is\nneither simple nor is it always straightforward to discern. Some\nevidence to this effect was provided by the fact that the answer to\nthe following question was posed but left unanswered by Post\n (1944):[27] \nQuestion 3.1 (Post’s Problem): Is\nthere a c.e. degree \\(\\mathbf{a}\\) such that \\(\\mathbf{0} <_T\n\\mathbf{a} <_T \\mathbf{0}'\\)? \nPost’s problem was eventually answered in the positive\nindependently by Friedberg (1957) and Muchnik (1956) who showed the\nfollowing: \nTheorem 3.8: There are c.e. sets \\(A\\) and \\(B\\)\nsuch that \\(A \\nleq_T B\\) and \\(B \\nleq_T A\\). Thus if \\(\\mathbf{a} =\n\\textrm{deg}_T(A)\\) and \\(\\mathbf{b} = \\textrm{deg}_T(B)\\), then\n\\(\\mathbf{a} \\nleq_T \\mathbf{b}\\) and \\(\\mathbf{b} \\nleq_T\n\\mathbf{a}\\) and hence also \\(\\mathbf{0} <_T \\mathbf{a} <_T\n\\mathbf{0}'\\) and \\(\\mathbf{0} <_T \\mathbf{b} <\n_T\\mathbf{0}'\\). \nThe proof of\n Friedberg-Muchnik Theorem (3.8)\n required the development of a new technique known as the priority\nmethod (or also as the injury method) which has become a\ncentral tool in the subsequent development of computability theory.\nThe method provides a means of constructing a c.e. set \\(A\\) with a\ncertain property \\(P\\) which may be described as follows:  \nIn the case of\n Theorem 3.8,\n this technique is used to simultaneously construct the two\nc.e. sets \\(A\\) and \\(B\\) of degree intermediate between\n\\(\\mathbf{0}\\) and \\(\\mathbf{0}'\\) by alternating between the\nrequirements \\(R_{2i}\\) which entail that \\(A \\neq \\{n : \\phi^{B}_i(n)\n\\darrow = 1\\}\\) at even stages to ensure \\(A \\nleq_T B\\) and\nrequirements \\(R_{2i+1}\\) which entail that \\(B \\neq \\{n :\n\\phi^{A}_i(n) \\darrow = 1\\}\\) at odd stages so as to ensure \\(B\n\\nleq_T A\\). \nSophisticated application of the priority method have been employed in\ncomputability theory from the 1960s onward to investigate the\nstructure of \\(\\mathcal{D}_T\\) and\n \\(\\mathcal{E}_T\\).[28]\n Some illustrative results which can be obtained either in this manner\nor more elementary techniques are as follows: \nThere are continuum (i.e., \\(2^{\\aleph_0}\\)) many distinct Turing\ndegrees. In particular, although for a given degree \\(\\mathbf{a}\\) the\nset of \\(\\mathbf{b}\\) such that \\(\\mathbf{b} \\leq_T \\mathbf{a}\\) is\ncountable, the set of \\(\\mathbf{b}\\) such that \\(\\mathbf{a} <_T\n\\mathbf{b}\\) is uncountable (Kleene & Post 1954). \nFor every degree \\(\\mathbf{a} \\not\\equiv_T \\mathbf{0}\\), there exists a\ndegree \\(\\mathbf{b}\\) which is incomparable to\n\\(\\mathbf{a}\\)—i.e., \\(\\mathbf{b} \\nleq_T \\mathbf{a}\\) and\n\\(\\mathbf{a} \\nleq_T \\mathbf{b}\\). Moreover, there is a set of\n\\(2^{\\aleph_0}\\) pairwise incompatible degrees (Kleene & Post\n1954). \nThere are minimal degrees \\(\\mathbf{m}\\)—i.e., degrees\nfor which there is no \\(\\mathbf{a}\\) such that \\(\\mathbf{0} <_T\n\\mathbf{a} <_T \\mathbf{m}\\) (Sacks 1963b). Thus in general\n\\(<_T\\) is not a dense order. (But by fact vii below,\nthere are not minimal c.e. degrees.) \nThere are pairs of degrees \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) which do\nnot possess a greatest lower bound. Thus although \\(\\mathcal{D}_T\\) is\nan upper semi-lattice, it is not a lattice (Kleene & Post 1954).\nThe same is true of \\(\\mathcal{E}_T\\) (Lachlan 1966). \nEvery countable partially ordered set can be embedded into\n\\(\\mathcal{D}_T\\) (Thomason 1971). However this is not true\nof \\(\\mathcal{E}_T\\) into which there are finite non-distributive\nlattices which cannot be embedded (Lachlan & Soare 1980). \nThere is a non-c.e. degree \\(\\mathbf{a} <_T \\mathbf{0}'\\)\n(Shoenfield 1960). \nFor any c.e. degrees \\(\\mathbf{a} <_T \\mathbf{b}\\), there is a\nc.e. degree \\(\\mathbf{c}\\) such that \\(\\mathbf{a} <_T \\mathbf{c}\n<_T \\mathbf{b}\\) (Sacks 1964). Thus unlike the Turing degrees in\ngeneral, the c.e. degrees are densely ordered. \nFor any c.e. degree \\(\\mathbf{a} >_T \\mathbf{0}\\), there are\nincomparable c.e. degrees \\(\\mathbf{b},\\mathbf{c} <_T\n\\mathbf{a}\\) such that \\(\\mathbf{a} = \\mathbf{b} \\cup \\mathbf{c}\\)\n(Sacks 1963b). \nLet \\(\\textrm{Th}({\\mathcal{D}_T})\\) be the first-order theory of the\nstructure \\(\\mathcal{D}_T\\) in the language with the with \\(\\equiv_T\\)\nand \\(\\leq_T\\). Not only is \\(\\textrm{Th}({\\mathcal{D}_T})\\)\nundecidable (Lachlan 1968), it is fact many-one equivalent to true\nsecond-order arithmetic (Simpson 1977). \nAs is easily shown to be true of the join operation \\(\\mathbf{a} \\vee\n\\mathbf{b}\\), the jump operation \\(\\mathbf{a}' = \\mathbf{b}\\) is\ndefinable in \\(\\mathcal{D}_T\\) in the language with \\(\\equiv_T\\) and \\(\\leq_T\\)\n(Shore & Slaman 1999). \nThese properties attest to the complexity of \\(\\mathcal{D}_T\\) as a\nmathematical structure. A related question is whether\n\\(\\mathcal{D}_T\\) is rigid in the following sense: \nQuestion 3.2: Does there exist a non-trivial\nautomorphism of \\(\\mathcal{D}_T\\)—i.e., a mapping \\(\\pi:\n\\mathcal{D}_T \\rightarrow \\mathcal{D}_T\\) which preserves \\(\\leq_T\\)\nand is not the identity? \nA negative answer to this question would show that the relation of\n\\(\\textrm{deg}_T(A)\\) to other degrees uniquely determines the degree\nof unsolvability of \\(A\\) relative to \\(\\mathcal{D}_T\\). Recent work has pointed in this direction (see, e.g., Slaman 2008). Nonetheless, at the time of the\n2020 update to this entry,\n Question 3.2\n remains a significant open problem in computability\ntheory whose origins can be traced back to the original foundational\nwork of Turing, Post, and Kleene surveyed above. \nThe many-one degrees \\(\\mathcal{D}_m\\) and the Turing degrees\n\\(\\mathcal{D}_T\\) are sometimes referred to as hierarchies in\nthe sense that they determine an ordering on\n\\(\\mathcal{P}(\\mathbb{N})\\)—i.e., the set of subsets of the\nnatural numbers—in terms of relative computability. In a series\nof papers from the 1940s and 1950s, Kleene (initiating in 1943) and\nMostowski (initiating in 1947) realized that it was also possible to\nimpose another sort of ordering on \\(\\mathcal{P}(\\mathbb{N})\\) in terms of the\nlogical complexity of the simplest predicate which defines a set \\(A\n\\subseteq \\mathbb{N}\\) in the languages of first- or second-order\narithmetic. This idea leads to what are known as the\narithmetical and analytical hierarchies, both of\nwhich can be understood as classifying sets in terms of their\ndefinitional (or descriptive) complexity. As we will\nsee, the resulting classifications are related to those determined\nrelative to \\(\\mathcal{D}_T\\) in terms of relative computability. They\nare also similar in form to other definability hierarchies studied in\n computational complexity theory\n (e.g., the polynomial hierarchy) and\n descriptive set theory\n (e.g., the Borel and projective hierarchies). \nRecall that according to the definitions given in\n Section 3.3,\n a relation \\(R \\subseteq \\mathbb{N}^k\\) is said to be\ncomputable just in case its characteristic function\n\\(\\chi_R(\\vec{x})\\) is a computable function and computably\nenumerable just in case it is the range of a computable function.\nIn order to introduce the arithmetical hierarchy, it is useful to\nemploy an alternative characterization of computable and computably\nenumerable relations in the form of a semantic analog to the\nproof-theoretic notion of arithmetical representability\ndiscussed in\n Section 1.3. \nRecall that the language of first-order arithmetic\n\\(\\mathcal{L}_a\\) contains the primitive symbols\n\\(\\{<,',+,\\times,0\\}\\) respectively intended to denote the less\nthan relation, successor, addition, and multiplication functions on\nthe natural numbers as well as the first natural number 0. A\nfirst-order arithmetical formula is one built up from these\nexpressions using variables, propositional connectives, and the\nfirst-order quantifiers \\(\\forall x, \\exists x\\) where the variables\nare intended to range over the natural numbers\n\\(\\mathbb{N}\\). Recall also that the standard model of first-order\narithmetic is the structure \\(\\mathfrak{N} = \\langle\n\\mathbb{N},0,<,s,+,\\times \\rangle\\) in which the symbols of\n\\(\\mathcal{L}_a\\) receive their intended interpretations. Finally we\nsay that an \\(\\mathcal{L}_a\\)-formula \\(\\varphi(\\vec{x})\\)\ndefines a relation \\(R \\subseteq \\mathbb{N}^k\\) just in case\n\\(R = \\{\\langle n_1,\\ldots,n_k \\rangle : \\mathfrak{N} \\models\n \\varphi(n_1,\\ldots,n_k)\\}\\).[29]\n For instance \\(x < y \\vee x = y\\) defines the less-than-or-equal\nrelation \\(\\leq\\), \\(\\exists y(y + y = x)\\) defines the even numbers,\nand  \ndefines the prime numbers. \nDefinition 3.14: A formula \\(\\varphi(\\vec{x})\\) of\n\\(\\mathcal{L}_a\\) is said to be in the class \\(\\Delta^0_0\\) if it\ncontains only bounded first-order quantifiers—i.e.,\nthose of the form \\(\\exists x(x < t \\wedge \\ldots)\\) and \\(\\forall\nx(x < t \\rightarrow \\ldots)\\) for \\(t\\) an \\(\\mathcal{L}_a\\)-term\nnot containing \\(x\\). A formula is said to be in the class\n\\(\\Sigma^0_1\\) if it is of the form \\(\\exists \\vec{y}\n\\varphi(\\vec{x},\\vec{y})\\) for \\(\\varphi(\\vec{x},\\vec{y}) \\in\n\\Delta^0_0\\) and to be in the class \\(\\Pi^0_1\\) if it is of the form\n\\(\\forall \\vec{y} \\varphi(\\vec{x},\\vec{y})\\) for\n\\(\\varphi(\\vec{x},\\vec{y}) \\in \\Delta^0_0\\). Finally, a formula\n\\(\\varphi(\\vec{x})\\) is said to be in the class \\(\\Delta^0_1\\) if it\nis semantically equivalent to both a \\(\\Sigma^0_1\\)-formula\n\\(\\psi(\\vec{x})\\) and a \\(\\Pi^0_1\\)-formula\n\\(\\chi(\\vec{x})\\)—i.e., \\(\\mathfrak{N} \\models\n\\varphi(\\vec{n})\\) iff \\(\\mathfrak{N} \\models \\psi(\\vec{n})\\) iff\n\\(\\mathfrak{N} \\models \\chi(\\vec{n})\\) for all \\(\\vec{n} \\in\n\\mathbb{N}^k\\). \nIt is standard to extend this syntactic classification of formulas in\nterms of quantifier complexity to sets and relations on the natural\nnumbers which can be defined by a formula in a given class. Thus, for\ninstance, \\(x < y \\vee x = y\\) is a \\(\\Delta^0_0\\)-formula and the\nrelation \\(\\leq\\) on \\(\\mathbb{N} \\times \\mathbb{N}\\) is accordingly\nsaid to be \\(\\Delta^0_0\\). On the other hand, while \\(\\exists y(y + y\n= x)\\) is a \\(\\Sigma^0_1\\)-formula, the set of even numbers is also\ndefined by \\(\\exists y < x(x = 0 \\vee y + y = x)\\). Thus this set\nis also classified as \\(\\Delta^0_0\\) in virtue of the existence of\nthis latter definition which is simpler in the sense measured by the\narithmetical hierarchy. \nThe first step in relating such classifications to\ncomputability-theoretic notions is provided by the following: \nProposition 3.8: \nA relation \\(R \\subseteq \\mathbb{N}^k\\) is computably enumerable if\nand only if there is a \\(\\Sigma^0_1\\)-formula which defines\n\\(R(\\vec{x})\\). \nA relation \\(R \\subseteq \\mathbb{N}^k\\) is computable if and only if\nthere is a \\(\\Delta^0_1\\)-formula which defines\n\\(R(\\vec{x})\\). \n\n Proposition 3.8\n may be proved by directly showing that for each partial recursive\nfunction \\(\\phi_e(\\vec{x})\\) it is possible to construct a\ncorresponding \\(\\mathcal{L}_a\\)-formula \\(\\varphi(\\vec{x})\\) whose\nlogical structure mimics the steps in the definition of the former.  This can be achieved by\nformalizing primitive recursion using an arithmetically definable\ncoding of finite sequences and expressing minimization using an\nunbounded existential quantifier (see, e.g., Kaye 1991, ch. 3). But it is also\npossible to obtain\n Proposition 3.8\n in a uniform manner by showing that there is a so-called\nuniversal formula for \\(\\Sigma^0_1\\). In order\nspecify such a formula, first note that it is possible to effectively\nenumerate all \\(\\Delta^0_0\\)-formulas with \\(k+1\\) free variables as\n\\(\\psi^{k+1}_0(x,\\vec{y}), \\psi^{k+1}_1(x,\\vec{y}), \\ldots\\) and then define a\ncorresponding enumeration of \\(\\Sigma^0_1\\)-formulas as\n\\(\\varphi^k_0(\\vec{y}) = \\exists x \\psi_0(x,\\vec{y}),\\)\n\\(\\varphi^k_1(\\vec{y}) = \\exists x \\psi_1(x,\\vec{y}),\\)…. We\nthen have the following: \nTheorem 3.9 (Kleene 1943): For all \\(k\\), there\nexists a \\(\\Sigma^0_1\\)-formula \\(\\sigma_{k,1}(x,\\vec{y})\\) such that\nfor all \\(\\Sigma^0_1\\)-formulas with \\(k\\)-free variables\n\\(\\varphi^k_e(\\vec{y})\\), the following biconditional  \nholds in the standard model \\(\\mathfrak{N}\\) for all \\(\\vec{m} \\in\n\\mathbb{N}^k\\). \n\n Theorem 3.9\n can be demonstrated by first observing that the truth of a\n\\(\\Sigma^0_1\\)-formula \\(\\varphi^k_e(\\vec{x})\\) is equivalent to\n\\(\\mathfrak{N} \\models \\psi^k_e(n,\\vec{m})\\) for some \\(n \\in\n\\mathbb{N}\\). Next note that the sequence of observations recorded in\n Section 2.1.2\n suffices to show that all \\(\\Delta^0_0\\)-definable relations are\nprimitive recursive. We may thus consider an algorithm which on input\n\\(e,\\vec{m}\\) uses \\(e\\) to construct \\(\\psi^k_e(x,\\vec{y})\\) and then\nperforms an unbounded search for an \\(n\\) such that\n\\(\\psi^k_e(n,\\vec{m})\\) holds. By an appeal to Church’s Thesis\n(which can, of course, be replaced by an explicit construction) there\nis a computable function \\(f(e)\\) for which we have the following:\n \nIn order to construct the formula \\(\\sigma_{k,1}(e,\\vec{y})\\) promised\nby\n Theorem 3.9,\n observe that standard techniques from the arithmetization of syntax\nallow us to obtain a \\(\\Delta^0_1\\)-formula \\(\\tau_k(x,\\vec{y},z)\\)\nwhich defines the Kleene \\(T\\)-predicate \\(T_k(x,\\vec{y},z)\\)\nintroduced in\n Section 2.2.2.\n We may finally define \\(\\sigma_{k,1}(e,\\vec{y}) = \\exists z\n\\tau_k(f(e),\\vec{y},z)\\). The first part of\n Proposition 3.8\n now follows by letting \\(e\\) be such that\n\\(\\textrm{dom}(\\phi^k_e(\\vec{x})) = R\\) and then taking\n\\(\\sigma_{k,1}(e_0,\\vec{x}) \\in \\Sigma^0_1\\) where \\(e_0\\) is such\nthat \\(f(e_0) = e\\). This is often formulated as what is known as the\nEnumeration Theorem which can be compared to\n Theorem 3.2: \nProposition 3.9: A relation \\(R \\subseteq\n\\mathbb{N}^k\\) is computable enumerable if and only if there is a\nnumber \\(e\\) (known as a c.e. index for \\(R\\)) such that\n\\(R\\) is defined by \\(\\exists z \\tau_k(e,\\vec{y},z)\\). \nThe second part of\n Proposition 3.8\n follows by observing that if \\(R\\) is recursive then both \\(R\\) and\n\\(\\overline{R}\\) are c.e. Thus if \\(e\\) is a c.e. index for\n\\(R\\), then \\(\\overline{R}\\) is defined by \\(\\neg \\exists z\n\\tau_k(e,\\vec{x},z)\\) which is equivalent to a \\(\\Pi^0_1\\)-formula\nsince \\(\\tau_k(x,\\vec{y},z) \\in \\Delta^0_1\\). \nThe formula classes \\(\\Delta^0_1\\) and \\(\\Sigma^0_1\\) thus provide an\nalternative arithmetical characterization of the computable and\ncomputably enumerable sets. These classes also define the lowest\nlevels of the arithmetical hierarchy which in full generality\nis defined as follows: \nDefinition 3.15: In order to simplify notation, the\nclasses \\(\\Sigma^0_0\\) and \\(\\Pi^0_0\\) are both used as alternative\nnames for the class \\(\\Delta^0_0\\). A formula is said to be in\nthe class \\(\\Sigma^0_{n+1}\\) if it is of the form \\(\\exists \\vec{y}\n\\varphi(\\vec{x},\\vec{y})\\) for \\(\\varphi(\\vec{x},\\vec{y}) \\in\n\\Pi^0_n\\) and to be in the class \\(\\Pi_{n+1}\\) if it is of the form\n\\(\\forall \\vec{y} \\varphi(\\vec{x},\\vec{y})\\) for\n\\(\\varphi(\\vec{x},\\vec{y}) \\in \\Sigma^0_n\\). A formula\n\\(\\varphi(\\vec{x})\\) is \\(\\Delta^0_{n+1}\\) if it is semantically\nequivalent to both a \\(\\Sigma^0_{n+1}\\)-formula \\(\\psi(\\vec{x})\\) and\na \\(\\Pi^0_{n+1}\\)-formula \\(\\chi(\\vec{x})\\). \nIt thus follows that a formula is \\(\\Sigma^0_{n}\\) just in case it is\nof the form  \n(where there are \\(n\\) alternations of quantifier types and\n\\(\\mathsf{Q}\\) is \\(\\forall\\) if \\(n\\) is even and \\(\\exists\\) if\n\\(n\\) is odd). Similarly a \\(\\Pi^0_n\\)-formula is of the form  \nThe notations \\(\\Sigma^0_n\\), \\(\\Pi^0_n\\), and \\(\\Delta^0_n\\) are also\nstandardly used to denote the classes of sets and relations which are\ndefinable by a formula in the corresponding syntactic class. For\ninstance it follows from the second part of\n Proposition 3.8\n that \\(\\textit{PRIMES}\\) is \\(\\Delta^0_1\\) (since it is computable)\nand from the first part that \\(\\HP\\) and \\(K\\) are \\(\\Sigma^0_1\\)\n(since they are c.e.). It thus follows that their complements\n\\(\\overline{HP}\\) and \\(\\overline{K}\\) are both \\(\\Pi^0_1\\). It is\nalso not hard to see that \\(\\TOT\\) is \\(\\Pi^0_2\\) as the fact that\n\\(\\phi_x(y)\\) is total may be expressed as \\(\\forall y \\exists z\n\\tau_1(x,y,z)\\) by using the arithmetized formulation of the\n\\(T\\)-predicate introduced above. Similarly, \\(\\textit{FIN}\\) is\n\\(\\Sigma^0_2\\)-definable since the fact that \\(\\phi_x(y)\\) is defined\nfor only finitely many arguments is expressible as \n\\(\\exists u \\forall y\\forall z(u < y \\rightarrow \\neg \\tau_1(x,y,z))\\). \nIt is a consequence of the Prenex Normal Form Theorem for first-order\nlogic that every \\(\\mathcal{L}_a\\)-formula \\(\\varphi(\\vec{y})\\) is\nprovably equivalent to one of the form \\(\\mathsf{Q}_1 x_1 \\mathsf{Q}_2\nx_2 \\ldots \\mathsf{Q}_{n} \\varphi(\\vec{x},\\vec{y})\\) for\n\\(\\mathsf{Q}_i \\equiv \\exists\\) or \\(\\forall\\) (e.g., Boolos, Jeffrey,\n& Burgess 2007, ch. 19.1). It thus follows that up to provable\nequivalence, every such formula is \\(\\Sigma^0_n\\) or \\(\\Pi^0_n\\) for\nsome \\(n \\in \\mathbb{N}\\). Since it is conventional to allow that\nblocks of quantifiers may be empty in the\n Definition 3.15,\n it follows that \nand \nThe fact that these inclusions are strict is a consequence of the\nso-called Hierarchy Theorem, a simple form of which may be\nstated as follows: \nTheorem 3.10 (Kleene 1943): For all \\(n \\geq 1\\),\nthere exists a set \\(A \\subseteq \\mathbb{N}\\) which is\n\\(\\Pi^0_n\\)-definable but not \\(\\Sigma^0_n\\)-definable and hence also\nneither \\(\\Sigma^0_m\\)- nor \\(\\Pi^0_m\\)-definable for any \\(m <\nn\\). It thus follows that \\(\\overline{A}\\) is \\(\\Sigma^0_n\\)-definable\nbut not \\(\\Pi^0_n\\)-definable and hence also neither \\(\\Sigma^0_m\\)-\nnor \\(\\Pi^0_m\\)-definable for any \\(m < n\\). \nIt is again possible to prove\n Theorem 3.10\n by a direct syntactic construction. For instance, building on the\ndefinition of the universal \\(\\Sigma^0_1\\)-predicate\n\\(\\sigma_{k,1}(\\vec{y})\\), it may be shown that for every level\n\\(\\Sigma^0_n\\) of the arithmetical hierarchy, there is a\n\\(\\Sigma^0_n\\)-formula \\(\\sigma_{k,n}(x,\\vec{y})\\) which defines\n\\(\\Sigma^0_n\\)-satisfaction in the standard model in the\nsense that  \nfor all \\(\\varphi(\\vec{x}) \\in \\Sigma^0_n\\) and \\(\\vec{m} \\in\n\\mathbb{N}^k\\) (and where we have also defined our Gödel\nnumbering to agree with the indexation of \\(\\Sigma^0_n\\)-formulas\nintroduced above). Now consider the \\(\\Pi^0_n\\)-formula \\(\\lambda(x) =\n\\neg \\sigma_{2,n}(x,x) \\in \\Pi^0_n\\) and let \\(A\\) be the set defined\nby \\(\\lambda(x)\\). A standard diagonal argument shows that \\(A\\)\ncannot be \\(\\Sigma^0_n\\)-definable and also that if \\(\\ulcorner\n\\sigma_{2,n}(x,x) \\urcorner = l\\) in the enumeration of\n\\(\\Sigma^0_n\\)-formulas then \\(\\neg \\sigma_{2,n}(l,l)\\) is a\n\\(\\Pi^0_n\\)-formula which cannot be provably equivalent to a\n\\(\\Sigma^0_k\\)-formula (see, e.g., Kaye 1991: ch. 9.3). Thus as Kleene\n(1943, 64) observed, part of the significance of the Hierarchy Theorem\nis that it illustrates how the Liar Paradox may be formalized to\nyield a stratified form of Tarski’s Theorem on the undefinability of truth\n (see the entry on self-reference). \nWe may also define a notion of completeness with respect to the levels\nof the arithmetical hierarchy as follows: \\(A\\) is\n\\(\\Sigma^0_n\\)-complete if \\(A\\) is \\(\\Sigma^0_n\\)-definable\nand for all \\(\\Sigma^0_n\\)-definable \\(B\\), we have \\(B \\leq_m A\\)\n(and similarly for \\(\\Pi^0_n\\)-complete). It is not hard to\nshow that in addition to being many-one complete, \\(K\\) is also\n\\(\\Sigma^0_1\\)-complete. Similarly \\(\\overline{K}\\) is\n\\(\\Pi^0_1\\)-complete, \\(INF\\) is \\(\\Sigma^0_2\\)-complete, and \\(TOT\\)\nis \\(\\Pi^0_2\\)-complete. These observations can be subsumed under a\nmore general result which relates the arithmetical hierarchy to the\nTuring degrees and from which\n Theorem 3.10\n can also be obtained as a corollary. \nTheorem 3.11 (Post 1944): \n\\(A\\) is \\(\\Sigma^0_{n+1}\\)-definable iff \\(A\\) is computably\nenumerable in some \\(\\Pi^0_n\\)-definable set iff \\(A\\) is computably\nenumerable in some \\(\\Sigma_n\\)-definable set. \n\\(\\emptyset^{(n)}\\) is \\(\\Sigma^0_n\\)-complete for all \\(n >\n0\\). \n\\(B\\) is \\(\\Sigma^0_{n+1}\\)-definable if and only if \\(B\\) is\ncomputably enumerable in \\(\\emptyset^{(n)}\\). \n\\(B\\) is \\(\\Delta^0_{n+1}\\)-definable if and only if \\(B \\leq_T\n\\emptyset^{(n)}\\). \nThe various parts of\n Theorem 3.11\n follow from prior definitions together with Propositions\n 3.2\n and\n 3.7.\n Note in particular that it follows from parts ii and iv of\n Theorem 3.11\n together with part vii of\n Proposition 3.7\n that \\(\\emptyset^{(n)}\\) is an example of a set in the class\n\\(\\Sigma^0_n - \\Pi^0_n\\) from which it also follows that\n\\(\\overline{\\emptyset^{(n)}} \\in \\Pi^0_n - \\Sigma^0_n\\). This\nobservation in turn strengthens the Hierarchy Theorem\n (3.10)\n by showing that \\(\\Delta^0_n \\subsetneq \\Sigma^0_n\\) and \\(\\Delta^0_n\n\\subsetneq \\Pi^0_n\\) as depicted in Figure 3. \nFigure 3: The Arithmetical Hierarchy.\n[A\n extended text-based description of figure 3\n is in the supplement.] \nPart iv of\n Theorem 3.11\n can also be understood as generalizing\n Proposition 3.4 (i.e.,\nPost’s Theorem). In particular, it characterizes the\n\\(\\Delta^0_{n+1}\\)-definable sets as those sets \\(B\\) such that both\n\\(B\\) and \\(\\overline{B}\\) are computably enumerable in some\n\\(\\Sigma^0_n\\)-complete set such as \\(\\emptyset^{(n)}\\). Restricting\nto the case \\(n = 1\\), this observation can also be used to provide an\nindependent computational characterization of the\n\\(\\Delta^0_2\\)-definable sets, extending those given for the\n\\(\\Sigma^0_1\\)-definable and \\(\\Delta^0_1\\)-definable sets by\n Proposition 3.8. \nDefinition 3.16: A set \\(A\\) is said to be limit\ncomputable if there is a computable sequence of finite sets\n\\(\\{A^s : s \\in \\mathbb{N}\\}\\) such that  \nwhere \\(\\lim_s A^s(n) = 1\\) means that \\(\\lim_s \\chi_{A_s}(n)\\) exists\nand is equal to 1. \nIf \\(A\\) is c.e., then it is clear that \\(A\\) is limit computable. For\nif \\(A\\) is the range of a computable function \\(\\phi_e(x)\\), then we\nmay take \\(A^s\\) to be \\(\\{\\phi_e(0), \\ldots, \\phi_e(s)\\}\\) in which\ncase \\(A^0 \\subseteq A^1 \\subseteq A^2 \\subseteq \\ldots\\) In the\ngeneral case of limit computability, the sequence of sets \\(\\{A^s : s\n\\in \\mathbb{N}\\}\\) may be thought of as an approximation of \\(A\\)\nwhich need not grow monotonically in this way but can rather both grow\nand shrink as long as there is always a stage \\(s\\) such that for all\n\\(s \\leq t\\), \\(n \\in A^t\\) if \\(n \\in A\\) and \\(n \\not\\in A^t\\) if\n\\(n \\not\\in A\\). Following Putnam (1965), a limit computable set can\nalso thus also be described as a so-called trial-and-error\npredicate—i.e., one for which membership can be determined\nby following a guessing procedure which eventually converges to the\ncorrect answer to the questions of the form \\(n \\in A\\)? \nThe following is traditionally referred to as The Limit\nLemma: \nTheorem 3.12 (Shoenfield 1959): The following are\nequivalent: \n\\(A\\) is limit computable. \n\\(A \\leq_T \\emptyset'\\) \nWe have seen that part iv of\n Proposition 3.11\n characterizes the sets Turing reducible to \\(\\emptyset'\\) as the\n\\(\\Delta^0_2\\)-definable sets.\n Theorem 3.12\n thus extends the characterizations of the computable (i.e.,\n\\(\\Delta^0_1\\)-definable) and computably enumerable (i.e.,\n\\(\\Sigma^0_1\\)-definable) sets given in\n Proposition 3.8\n by demonstrating the coincidence of the \\(\\Delta^0_2\\)-definable sets\nand those which are limit computable. \nKleene introduced what is now known as the analytical\nhierarchy in a series of papers (1955a,b,c) which built directly\non his introduction of the arithmetical hierarchy in (1943). His\nproximal motivation was to provide a definability-theoretic\ncharacterization of the so-called hyperarithmetical\nsets—i.e., those which are computable from transfinite\niterates of the Turing jump through the constructive ordinals. On the\nother hand, Mostowski (1947) had already noticed similarities between\nthe arithmetical hierarchy of sets of natural numbers and results\nabout hierarchies of point sets studied in descriptive set\ntheory—i.e., sets of elements of Polish spaces\n(complete, separable metrizable spaces such as the real numbers,\nCantor space, or Baire space)—which have their origins in the\nwork of Borel, Lebesgue, Lusin, and Suslin in the early twentieth\ncentury. Beginning in his PhD thesis under Kleene, Addison (1954)\nrefined Mostowski’s comparisons by showing that Kleene’s\ninitial work could also be used to provide effective versions of\nseveral classical results in this tradition. We present here the\nfundamental definitions regarding the analytical hierarchy\ntogether with some of some results illustrating how it is connected it\nto these other developments. \nDefinition 3.17: The language \\(\\mathcal{L}^2_a\\)\nof second-order arithmetic extends the language \\(\\mathcal{L}_a\\)\nof first-order arithmetic with the binary relation symbol \\(\\in\\),\ntogether with set variables \\(X,Y,Z, \\ldots\\) and set\nquantifiers \\(\\exists X\\) and \\(\\forall Y\\). The standard model of\n\\(\\mathcal{L}^2_a\\) is the structure \\(\\langle\n\\mathbb{N},\\mathcal{P}(\\mathbb{N}),0,<,s,+,\\times,\\in \\rangle\\).\nThe intended range of the set quantifiers is thus\n\\(\\mathcal{P}(\\mathbb{N})\\) (i.e. the power set of\n\\(\\mathbb{N}\\)) while the intended interpretation of \\(x \\in X\\) is\nthat the number \\(x \\in \\mathbb{N}\\) is a member of the set \\(X\\)\nwhere \\(X \\in \\mathcal{P}(\\mathbb{N})\\). \nNote that in the general case a formula\n\\(\\varphi(x_1,\\ldots,x_j,X_1,\\ldots, X_k)\\) of \\(\\mathcal{L}^2_a\\) may\nhave both free number variables \\(x_1,\\ldots, x_j\\) and free set\nvariables \\(X_1,\\ldots,X_k\\). If \\(R \\subseteq \\mathbb{N}^j \\times\n\\mathcal{P}(\\mathbb{N})^k\\) is defined by such a formula, then it is\nsaid to be analytical. Kleene (1955a) proved a normal form\ntheorem for analytical relations which shows that if \\(R\\) is\nanalytical then it is definable by an \\(\\mathcal{L}^2_a\\)-formula of\nthe form  \nor \nwhere \\(\\psi(\\vec{X})\\) contains only number quantifiers and\n\\(\\mathsf{Q}\\) is \\(\\forall\\) or \\(\\exists\\) depending on where\n\\(n\\) is even or odd. It thus possible to classify both\n\\(\\mathcal{L}^2_a\\)-formulas and the sets they define into classes as\nfollows: \nDefinition 3.18: \nWe denote by both \\(\\Sigma^1_0\\) and \\(\\Pi^1_0\\) the class of\n\\(\\mathcal{L}^2_a\\)-formulas containing no set quantifiers (i.e., a\nso-called arithmetical formulas). An \\(\\mathcal{L}^2_a\\)\nformula is in the class \\(\\Sigma^1_{n+1}\\) if it is of the form\n\\(\\exists X \\psi(X)\\) where \\(\\psi \\in \\Pi^1_n\\) and a relation is\n\\(\\Sigma^1_{n+1}\\)-definable if it is defined by a\n\\(\\Sigma^1_{n+1}\\)-formula. Similarly an \\(\\mathcal{L}^2_a\\)-formula\nis in the class \\(\\Pi^1_{n+1}\\) if it is of the form \\(\\forall X\n\\psi(X)\\) where \\(\\psi \\in \\Sigma^1_n\\) and a relation is\n\\(\\Pi^1_{n+1}\\)-definable if is defined by a\n\\(\\Pi^1_{n+1}\\)-formula. A relation is\n\\(\\Delta^1_n\\)-definable just in case it is definable by both\na \\(\\Sigma^1_n\\)- and a \\(\\Pi^1_n\\)-formula. \nIt hence follows that, as in the case of the arithmetical hierarchy,\nwe have \nand \nIn addition, a version of the Enumeration Theorem for arithmetical\nsets can also be proven which can be used to obtain the following\ngeneralization of the Hierarchy Theorem: \nTheorem 3.13 (Kleene 1955a): For all \\(n \\geq 1\\),\nthere exists a set \\(A \\subseteq \\mathbb{N}\\) which is\n\\(\\Pi^1_n\\)-definable but not \\(\\Sigma^1_n\\)-definable and hence also\nneither \\(\\Sigma^1_m\\)- nor \\(\\Pi^1_m\\)-definable for any \\(m <\nn\\). It thus follows that \\(\\overline{A}\\) is \\(\\Sigma^1_n\\)-definable\nbut not \\(\\Pi^1_n\\)-definable and also neither \\(\\Sigma^1_m\\)- nor\n\\(\\Pi^1_m\\)-definable for any \\(m < n\\). \nIn order to provide some illustrations of the levels of the analytical\nhierarchy, it is useful to record the following: \nDefinition 3.19: A set \\(A \\subseteq \\mathbb{N}\\) is\nimplicitly definable in \\(\\mathcal{L}^2_a\\) just in case\nthere is an arithmetical formula \\(\\varphi(X)\\) with \\(X\\) as its sole\nfree set variable and no free number variables such that \\(A\\) is the\nunique set satisfying \\(\\varphi(X)\\) in the standard model of\n\\(\\mathcal{L}^2_a\\). \nTrue Arithmetic (\\(\\textrm{TA}\\)) corresponds to the set of\nGödel numbers of first-order arithmetical sentences true in the\nstandard model of \\(\\mathcal{L}_a\\)—i.e., \\(\\textrm{TA} =\n\\{\\ulcorner \\varphi \\urcorner : \\varphi \\in \\mathcal{L}_a \\ \\wedge \\\n\\mathfrak{N} \\models \\varphi\\}\\). Prior to the definition of the\nanalytical hierarchy itself, Hilbert & Bernays had already showed\nthe following: \nTheorem 3.14 (Hilbert and Bernays 1939, §5.2e):\n\\(\\textrm{TA}\\) is implicitly definable in \\(\\mathcal{L}^2_a\\). \nIt is then not difficult to show the following: \nProposition 3.10 (Spector 1955): If \\(A\\) is\nimplicitly definable, then \\(A\\) is \\(\\Delta^1_1\\)-definable in\n\\(\\mathcal{L}^2_a\\). \nIt thus follows that \\(\\textrm{TA}\\) is \\(\\Delta^1_1\\)-definable. On\nthe other hand, it follows from Tarski’s Theorem on the undefinability of truth\nthat \\(\\textrm{TA}\\) is not arithmetically definable— i.e. \\(\\textrm{TA} \\not\\in \\Sigma^0_n \\cup \\Pi^0_n\\) for any \\(n \\in \\mathbb{N}\\). This in turn shows that the analytical sets\nproperly extend the arithmetical ones. \nThe class of \\(\\Delta^1_1\\)-definable subsets of \\(\\mathbb{N}\\) is\nalso related to Kleene’s original study of the class of\nhyperarithmetical sets, customarily denoted \\(\\textrm{HYP}\\). The\ndefinition of \\(\\textrm{HYP}\\) depends on that of a system of\nconstructive ordinal notations known as \\(\\mathcal{O} = \\langle O,\n<_O \\rangle\\) which Kleene had introduced in (1938). (It was also\nin the context of defining \\(\\mathcal{O}\\) in which he proved the\n Recursion Theorem 3.5—see\n Rogers 1987, ch. 11.7 and Y. Moschovakis 2010.) \\(\\textrm{HYP}\\) can be\ninformally characterized as the class of sets of natural numbers \\(A\\)\nsuch that \\(A \\leq_T \\emptyset^{(\\alpha)}\\) where \\(\\alpha\\) is an\nordinal which receives a notation \\(e \\in O\\)—i.e., \\(A \\in\n\\textrm{HYP}\\) just in case it is computable from a transfinite\niteration the of Turing jump up to the first non-recursive ordinal\n \\(\\omega^{ck}_1\\).[30]\n Kleene’s original result was as\n follows:[31] \nTheorem 3.15 (Kleene 1955b): A set \\(A \\subseteq\n\\mathbb{N}\\) is \\(\\Delta^1_1\\)-definable if and only if \\(A \\in\n\\textrm{HYP}\\). \nThe next step up the analytical hierarchy involves the\ncharacterization of the \\(\\Pi^1_1\\)-definable sets. S. Kleene (1955a)\noriginally established his normal form theorem for\n\\(\\mathcal{L}^2_a\\)-formulas using a variant of the language of\nsecond-order arithmetic which contains function quantifiers\n\\(f,g,h,\\ldots\\) which are intended to range over \\(\\mathbb{N}\n\\rightarrow \\mathbb{N}\\) instead of set quantifiers intended to range\nover \\(\\mathcal{P}(\\mathbb{N})\\) (Rogers 1987, ch. 16.2). In this setting,\nit is possible to show the following: \nProposition 3.11: \\(A \\in \\Pi^1_1\\) if and only if\nthere is a computable (i.e., \\(\\Delta^0_1\\)-definable) relation\n\\(R(x,f)\\) such that  \nwhere \\(\\overline{f}(y)\\) denotes \\(\\langle\nf(0),\\ldots,f(y-1)\\rangle\\). \nFor each such relation, we may also define a computable tree\n\\(\\textit{Tr}_x\\) consisting of the finite sequences \\(\\sigma \\in\n\\mathbb{N}^{< \\mathbb{N}}\\) such that for all proper initial\nsubsequences \\(\\tau \\subset \\sigma\\), \\(\\neg R(x,\\tau)\\) holds. A leaf\nnode in this tree thus corresponds to the first place for which \\(R\\)\nholds. An infinite path in \\(\\textit{Tr}_x\\) thus\ncorresponds to a function \\(f\\) such that \\(\\forall y \\neg\nR(x,\\overline{f}(y))\\), which is in turn a witness to \\(x \\not\\in A\\).\nIt thus follows that \\(x \\in A\\) if and only if \\(\\textit{Tr}_x\\) is\nwell-founded. Since it is straightforward to effectively enumerate\ncomputable trees, it is also not difficult to show the following: \nProposition 3.12: The set \\(T\\) of indices to\nwell-founded computable trees is \\(m\\)-complete for the\n\\(\\Pi^1_1\\)-definable sets—i.e., \\(T \\in \\Pi^1_1\\) and for all\n\\(A \\in \\Pi^1_1\\), \\(A \\leq_m T\\). \nRecalling that \\(O\\) denotes the set of natural numbers which are\nnotations for ordinals in Kleene’s \\(\\mathcal{O}\\), a related\nresult is the following: \nProposition 3.13: \\(O\\) is \\(\\Pi^1_1\\)-complete. \nIt can then be shown using the\n Hierarchy Theorem 3.13\n that neither \\(T\\) nor \\(O\\) is \\(\\Sigma^1_1\\)-definable. These\nresults provide the basis for an inductive analysis of the structure\nof \\(\\Delta^1_1\\)- and \\(\\Pi^1_1\\)-definable sets in terms of\nconstructive ordinals which builds on\n Theorem 3.15\n (see Rogers 1987, ch. 16.4). \nThe foregoing results all pertain to the use of\n\\(\\mathcal{L}^2_a\\)-formulas to describe sets of natural numbers. The\ninitial steps connecting the analytical hierarchy to classical\ndescriptive set theory are mediated by considering formulas\n\\(\\varphi(X)\\) which define subclasses \\(\\mathcal{X} \\subseteq\n\\mathcal{P}(\\mathbb{N})\\). In this case, \\(A \\in \\mathcal{X}\\) may be\nidentified with the graph of its characteristic function\n\\(\\chi_A(x)\\)—i.e., as an infinite sequence whose \\(n\\)th\nelement is 1 if \\(n \\in A\\) and 0 if \\(n \\not\\in A\\). In this way a\nformula \\(\\psi(X)\\) with a single free set variable may be understood\nas defining a subset of the Cantor space \\(\\mathcal{C} =\n2^{\\mathbb{N}}\\) consisting of all infinite 0-1 sequences and a\nformula \\(\\psi(\\vec{X})\\) with \\(X_1,\\ldots,X_k\\) free as defining a\nsubclass of \\(2^{\\mathbb{N}} \\times \\ldots \\times\n2^{\\mathbb{N}}\\). \nIn descriptive set theory, a parallel sequence of topological\ndefinitions of subclasses of \\(\\mathcal{C}\\) is given in the context\nof defining the Borel sets and projective sets. First recall that one\nmeans of defining a topology on \\(\\mathcal{C}\\) is to take as basic\nopen sets all sets of functions \\(f: \\mathbb{N} \\rightarrow \\{0,1\\}\\)\nsuch that \\(\\overline{f}(k) = \\sigma\\) for some \\(\\sigma \\in 2^{<\n\\mathbb{N}}\\) and \\(k \\in \\mathbb{N}\\). The boldface Borel Hierarchy on\n\\(\\mathcal{C}\\) is now given by defining \\(\\mathbf{\\Sigma^0_1}\\) to be\nthe collection of all open sets of \\(\\mathcal{C}\\),\n\\(\\mathbf{\\Pi^0_{n}}\\) (for \\(n \\geq 1\\)) to be the set of all\ncomplements \\(\\overline{A}\\) of sets \\(A \\in \\mathbf{\\Sigma^0_1}\\),\nand \\(\\mathbf{\\Sigma^0_{n+1}}\\) to be the set of all countable unions\n\\(\\bigcup_{i \\in \\mathbb{N}} A_i\\) where \\(A_i \\in \\mathbf{\\Pi^0_n}\\).\n(Thus \\(\\mathbf{\\Pi^0_1}\\) denotes the set of closed sets,\n\\(\\mathbf{\\Sigma^0_2}\\) denotes the so-called \\(F_{\\sigma}\\) sets,\n\\(\\mathbf{\\Pi^0_2}\\) the \\(G_{\\delta}\\) sets, etc.) The union of these\nclasses corresponds to the boldface Borel sets \\(\\mathbf{B}\\)\nwhich may also be characterized as the smallest class of sets\ncontaining the open sets of \\(\\mathcal{C}\\) which is closed under\ncountable unions and complementation. The so-called analytic\nsets are defined to be the continuous images of the Borel sets\nand are denoted by \\(\\mathbf{\\Sigma^1_1}\\) while the\nco-analytic sets are defined to be the complements of\nanalytic sets and are denoted by \\(\\mathbf{\\Pi^1_1}\\). Finally,\n\\(\\mathbf{\\Delta^1_1}\\) is used to denote the intersection of the\nanalytic and co-analytic sets. \nAddison observed (1958, 1959) that these classical definitions can be\neffectivized by restricting to computable unions in the definition of\nthe \\(\\mathbf{\\Sigma^0_n}\\) sets. This leads to the so-called\nlightface version of the Borel hierarchy—customarily\ndenoted using the same notations \\(\\Sigma^0_n\\) and \\(\\Pi^0_n\\) used\nfor the levels of arithmetical hierarchy—and corresponding\ndefinitions of \\(\\Sigma^1_1\\) (i.e., lightface analytic), \\(\\Pi^1_1\\)\n(i.e., lightface co-analytic), and \\(\\Delta^1_1\\) sets. In particular,\nthis sequence of definitions suggests an analogy between\n Theorem 3.15\n and the following classical result of Suslin: \nTheorem 3.16 (Suslin 1917): The class of\n\\(\\mathbf{\\Delta}^1_1\\) sets is equal to the class of Borel sets\n\\(\\mathbf{B}\\). \nAn effective form of\n Theorem 3.16\n relating the \\(\\Delta^1_1\\) subsets of \\(\\mathcal{C}\\) to the\nlightface Borel sets representable by computable codes can be obtained\nfrom Kleene’s original proof of\n Theorem 3.15\n (see, e.g., Y. Moschovakis 2009, ch. 7B). Addison also showed that it is\nsimilarly possible to obtain an effective version of Lusin’s\nTheorem (1927)—i.e., “any two disjoint analytic sets can\nbe separated by a Borel set”—and Kondô’s\ntheorem (1939)—i.e., “every \\(\\mathbf{\\Pi^1_1}\\)-relation can be uniformized by a \\(\\mathbf{\\Pi^1_1}\\)-relation”. See\nY. Moschovakis (2009, ch. 2E,4E) and also Simpson (2009, ch. V.3,VI.2) \nHistorical surveys of the early development of recursive functions and\ncomputability theory are provided by Sieg (2009), Adams (2011), and\nSoare (2016, part V). Many of the original sources discussed in\n §1\n are anthologized in Davis (1965), Heijenoort (1967), and Ewald\n(1996). Textbook presentation of computability theory at an elementary\nand intermediate level include Hopcroft & Ulman (1979), Cutland (1980), Davis,\nSigal, & Weyuker (1994), and Murawski (1999). The original textbook expositions of the\nmaterial presented in\n §2\n and\n §3\n (up to the formulation of Post’s problem) include Kleene\n(1952), Shoenfield (1967), and Rogers (1987; first edition 1967). The\nstructure of the many-one and Turing Degrees is presented in more\nadvanced textbooks such as Sacks (1963a), Shoenfield (1971), Hinman\n(1978), Soare (1987), Cooper (2004), and Soare (2016). In addition to\nShoenfield (1967, ch. 7) and Rogers (1987, ch. 16), the classic treatment of\nthe hyperarithmetical and analytical hierarchies is Sacks (1990).\nClassical and effective descriptive set theory are developed in Y.\nMoschovakis (2009, first edition 1980) and Kechris (1995). Simpson\n(2009) develops connections between computability theory and\nReverse Mathematics—i.e., the axiomatic study of\nsubsystems of second-order arithmetic whose ω-models may often be\ncharacterized using computability theoretic methods. Treatment of\nsub-recursive hierarchies and connections to proof theory and\ntheoretical computer science are provided by Péter (1967), Rose\n(1984), Clote (2002, ch. 6–7), and Schwichtenberg & Wainer\n(2011). Many of the historical and mathematical topics surveyed in\nthis entry are also presented in greater detail in the two volumes of\nOdifreddi’s Classical Recursion Theory (1989, 1999a),\nwhich contain many additional historical references.","contact.mail":"W.H.Dean@warwick.ac.uk","contact.domain":"warwick.ac.uk"}]
