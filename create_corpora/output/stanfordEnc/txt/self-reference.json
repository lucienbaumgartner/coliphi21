[{"date.published":"2008-07-15","date.changed":"2017-08-31","url":"https://plato.stanford.edu/entries/self-reference/","author1":"Thomas Bolander","author1.info":"http://www.imm.dtu.dk/~tb","entry":"self-reference","body.text":"\n\nIn the context of language, self-reference is used to denote\na statement that refers to itself or its own referent. The most famous\nexample of a self-referential sentence is the liar sentence:\n“This sentence is not true.” Self-reference is often used\nin a broader context as well. For instance, a picture could be\nconsidered self-referential if it contains a copy of itself (see the\nanimated image above); and a piece of literature could be considered\nself-referential if it includes a reference to the work itself. In\nphilosophy, self-reference is primarily studied in the context of\nlanguage. Self-reference within language is not only a subject of\nphilosophy, but also a field of individual interest in mathematics and\ncomputer science, in particular in relation to the foundations of\nthese sciences.\n\n\nThe philosophical interest in self-reference is to a large extent\ncentered around the paradoxes. A paradox is a seemingly sound\npiece of reasoning based on apparently true assumptions that leads to\na contradiction. The liar sentence considered above leads to a\ncontradiction when we try to determine whether it is true or not. If\nwe assume the sentence to be true, then what it states must be the\ncase, that is, it cannot be true. If, on the other hand, we assume it\nnot to be true, then what it states is actually the case, and thus it\nmust be true. In either case we are led to a contradiction. Since the\ncontradiction was obtained by a seemingly sound piece of reasoning\nbased on apparently true assumptions, it qualifies as a paradox. It is\nknown as the liar paradox. \n\n\nMost paradoxes of self-reference may be categorised as either\nsemantic, set-theoretic or epistemic. The\nsemantic paradoxes, like the liar paradox, are primarily relevant to\ntheories of truth. The set-theoretic paradoxes are relevant to the\nfoundations of mathematics, and the epistemic paradoxes are relevant\nto epistemology. Even though these paradoxes are different in the\nsubject matter they relate to, they share the same underlying\nstructure, and may often be tackled using the same mathematical means.\n\n\n\nIn the present entry, we will first introduce a number of the most\nwell-known paradoxes of self-reference, and discuss their common\nunderlying structure. Subsequently, we will discuss the profound\nconsequences that these paradoxes have on a number of different areas:\ntheories of truth, set theory, epistemology, foundations of\nmathematics, computability. Finally, we will present the most\nprominent approaches to solving the paradoxes. \n\nParadoxes of self-reference have been known since antiquity. The\ndiscovery of the liar paradox is often credited to Eubulides the\nMegarian who lived in the 4th century BC. The liar paradox belongs to\nthe category of semantic paradoxes, since it is based on the\nsemantic notion of truth. Other well-known semantic paradoxes include\nGrelling’s paradox, Berry’s paradox, and Richard’s\nparadox. \nGrelling’s paradox involves a predicate defined as\nfollows. Say a predicate is heterological if it is not true\nof itself, that is, if it does not itself have the property it\nexpresses. Then the predicate “German” is heterological,\nsince it is not itself a German word, but the predicate\n“deutsch” is not heterological. The question that leads to\nthe paradox is now: \nIs “heterological” heterological?\n \nIt is easy to see that we obtain a contradiction independently of\nwhether we answer “yes” or “no” to this\nquestion (the argument runs more or less like in the liar paradox).\nGrelling’s paradox is self-referential, since the definition of\nthe predicate heterological refers to all predicates,\nincluding the predicate heterological itself. Definitions such as this\nwhich depends on a set of entities, at least one of which is the\nentity being defined, are called impredicative. \nBerry’s paradox is another paradox based on an\nimpredicative definition, or rather, an impredicative description.\nSome phrases of the English language are descriptions of natural\nnumbers, for example, “the sum of five and seven” is a\ndescription of the number 12. Berry’s paradox arises when trying\nto determine the denotation of the following description:  \nthe least number that cannot be referred to by a description\ncontaining less than 100 symbols.\n \nThe contradiction is that this description containing 93 symbols\ndenotes a number which, by definition, cannot be denoted by any\ndescription containing less than 100 symbols. The description is of\ncourse impredicative, since it implicitly refers to all\ndescriptions, including itself. \nRichard’s paradox considers phrases of the English\nlanguage defining real numbers rather than natural numbers. For\nexample, “the ratio between the circumference and diameter of a\ncircle” is a phrase defining the number \\(\\pi\\). Assume an\nenumeration of all such phrases is given (e.g. by putting them into\nlexicographical order). Now consider the phrase: \nthe real number whose \\(n\\)th decimal place is 1 whenever the\n\\(n\\)th decimal place of the number denoted by the \\(n\\)th\nphrase is 0; otherwise 0.\n \nThis phrase defines a real number, so it must be among the enumerated\nphrases, say number \\(k\\) in this enumeration. But, at the same\ntime, by definition, it differs from the number denoted by the\n\\(k\\)th phrase in the \\(k\\)th decimal place. Thus we have a\ncontradiction. The defining phrase is obviously impredicative. The\nparticular construction employed in this paradox is called\ndiagonalisation. Diagonalisation is a general construction\nand proof method originally invented by Georg Cantor (1891) to prove\nthe uncountability of the power set of the natural numbers. It was\nalso used as a basis for Cantor’s paradox, one of the\nset-theoretic paradoxes to be considered next. \nThe best-known set-theoretic paradoxes are Russell’s paradox and\nCantor’s paradox. Russell’s paradox arises from\nconsidering the Russell set \\(R\\) of all sets that are\nnot members of themselves, that is, the set defined defined by\n\\(R = \\{ x \\mid  x \\not\\in x \\}\\). The\ncontradiction is then derived by asking whether \\(R\\) is a member\nof itself, that is, whether \\(R \\in R\\) holds. If\n\\(R \\in R\\) then \\(R\\) is a member of itself,\nand thus \\(R \\not\\in R\\), by definition of \\(R\\).\nIf, on the other hand, \\(R \\not\\in R\\) then \\(R\\)\nis not a member of itself, and thus \\(R \\in R\\),\nagain by definition of \\(R\\). \nCantor’s paradox is based on an application of\nCantor’s theorem. Cantor’s theorem states that\ngiven any finite or infinite set \\(S\\), the power set of\n\\(S\\) has strictly larger cardinality (greater size) than\n\\(S\\). The theorem is proved by a form of diagonalisation, the\nsame idea underlying Richard’s paradox. Cantor’s paradox\nconsiders the set of all sets. Let us call this set the universal\nset and denote it by \\(U\\). The power set of \\(U\\) is\ndenoted \\(\\wp(U)\\). Since \\(U\\) contains all\nsets it will in particular contain all elements of\n\\(\\wp(U)\\). Thus \\(\\wp(U)\\) must be a subset of\n\\(U\\) and must thus have a cardinality (size) which is less than\nor equal to the cardinality of \\(U\\). However, this immediately\ncontradicts Cantor’s theorem.  \nThe Hypergame paradox is a more recent addition to the list\nof set-theoretic paradoxes, invented by Zwicker (1987). Let us call a\ntwo-player game well-founded if it is bound to terminate in a\nfinite number of moves. Tournament chess is an example of a\nwell-founded game. We now define hypergame to be the game in\nwhich player 1 in the first move chooses a well-founded game to be\nplayed, and player 2 subsequently makes the first move in the chosen\ngame. All remaining moves are then moves of the chosen game. Hypergame\nmust be a well-founded game, since any play will last exactly one move\nmore than some given well-founded game. However, if hypergame is\nwell-founded then it must be one of the games that can be chosen in\nthe first move of hypergame, that is, player 1 can choose hypergame in\nthe first move. This allows player 2 to choose hypergame in the\nsubsequent move, and the two players can continue choosing hypergame\nad infinitum. Thus hypergame cannot be well-founded,\ncontradicting our previous conclusion. \nThe most well-know epistemic paradox is the paradox of the\nknower. This paradox has many equivalent formulations, one of\nthem based on the sentence “This sentence is not known by\nanyone.” Let us call this sentence the knower sentence,\nabbreviated \\(KS. KS\\) is obviously quite similar to the\nliar sentence, except the central concept involved is knowledge rather\nthan truth. The reasoning leading to a contradiction from \\(KS\\)\nis a bit more complex than in the liar paradox. First \\(KS\\) is\nshown to be true by the following piece of reasoning: \nAssume to obtain a contradiction that \\(KS\\) is not true. Then\nwhat \\(KS\\) expresses cannot be the case, that is, \\(KS\\)\nmust be known by someone. Since everything known is true (this is part\nof the definition of the concept of knowledge), \\(KS\\) is true,\ncontradicting our assumption. This concludes the proof that\n\\(KS\\) is true.\n \nThe piece of reasoning just carried out to prove the truth of\n\\(KS\\) should be available to any agent (person) with sufficient\nreasoning capabilities. That is, an agent should be able to prove the\ntruth of \\(KS\\), and thus come to know that \\(KS\\) holds.\nHowever, if \\(KS\\) is known by someone, then what it expresses is\nnot the case, and thus it cannot be true. This is a contradiction, and\nthus we have a paradox. The role of self-reference in this paradox is\nobvious, as it is based on a sentence, \\(KS\\), referring directly\nto itself. \nThe paradox of the knower is just one of many epistemic paradoxes\ninvolving self-reference. See the entry on\n epistemic paradoxes\n for further information on the class of epistemic paradoxes. A quite\nrecent epistemic paradox, cast in the setting of beliefs and\nassumptions in a two-player game, is the Brandenburger-Keisler paradox\n(Brandenburger & Keisler, 2006), described in detail in the entry\non\n epistemic foundations of game theory.\n For a detailed discussion and history of the paradoxes of\nself-reference in general, see the entry on\n paradoxes and contemporary logic.\n  \nThe paradoxes above are all quite similar in structure. In the case of\nthe paradoxes of Grelling and Russell, this can be seen as follows.\nDefine the extension of a predicate to be the set of objects\nit is true of. For a predicate \\(P\\) we denote its extension by\next\\((P)\\). Grelling’s paradox involves the predicate\nheterological, which is true of all those predicates that are not true\nof themselves. Thus the extension of the predicate heterological is\nthe set \\(\\{ P \\mid  P \\not\\in\\) ext\\((P) \\}\\). Compare\nthis to the Russell set \\(R\\) given by \\(\\{ x \\mid  x \\not\\in x \\}\\). The only significant difference between these\ntwo sets is that the first is defined on predicates whereas the second\nis defined on sets. The proofs of contradictions based on these two\nsets also share the same structure, as seen below (where\n“het” abbreviates “heterological”): \nWe have here two paradoxes of an almost identical structure belonging\nto two distinct classes of paradoxes: one is semantic and the other\nset-theoretic. What this teaches us is that even if paradoxes seem\ndifferent by involving different subject matters, they might be almost\nidentical in their underlying structure. Thus in many cases it makes\nmost sense to study the paradoxes of self-reference under one, rather\nthan study, say, the semantic and set-theoretic paradoxes separately.\n \nRussell and Cantor’s paradoxes are also more similar than they\nappear at first. Cantor’s paradox is based on an application of\nCantor’s theorem to the universal set \\(U\\) (cf. Section\n1.2 above). Below we give the proof of Cantor’s theorem for an\narbitrary set \\(S\\). \nWe need to prove that \\(\\wp(S)\\) has greater cardinality than\n\\(S\\). Assume to obtain a contradiction that this is not the\ncase. Then there must exist a map \\(f\\) from \\(S\\) onto\n\\(\\wp(S)\\). Now consider the set \\(C = \\{ x \\in S \\mid x \\not\\in f(x)\n\\}\\). Since \\(f\\) is onto \\(\\wp(S)\\), there must exist a set \\(c \\in\nS\\) such that \\(f(c)=C\\). However, we now obtain a contradiction,\nsince the following holds:  \nNote the similarity between this sequence of equivalences and the\ncorresponding sequences of equivalences derived for Russell’s\nand Grelling’s paradoxes above. Now consider the special case of\nCantor’s theorem where \\(S\\) is the universal set. Then we\ncan simply choose \\(f\\) to be the identity function, since\n\\(\\wp(U)\\) must necessarily be a subset of the universal set\n\\(U\\). But then \\(C\\) becomes the Russell set! Thus\nCantor’s paradox is nothing more than a slight variant of\nRussell’s paradox; the core argument leading to the\ncontradiction is the same in both.  \nPriest (1994) gives even firmer evidence to the similarity between the\nparadoxes of self-reference by showing that they all fit into what he\noriginally called the Qualified Russell’s Schema, now\ntermed the Inclosure Schema. The idea behind it goes back to\nRussell himself (1905) who also considered the paradoxes of\nself-reference to have a common underlying structure. Given two\npredicates predicates \\(P\\) and \\(Q\\), and a possibly partial function\n\\(\\delta\\), the Inclosure Schema consists of the following two\nconditions:  If these conditions are satisfied we have the following\ncontradiction: Since \\(w\\) is trivially a subset of \\(w\\) and since\n\\(Q(w)\\) holds by condition 1, we have both \\(\\delta(w) \\not\\in w\\)\nand \\(\\delta(w) \\in w\\), by 2a and 2b, respectively. Thus any triple\n\\((P,Q,\\delta)\\) satisfying the Inclosure Schema will produce a\nparadox. Priest shows how most of the well-known paradoxes of\nself-reference fit into the schema. Below we will consider only a few\nof these paradoxes, starting with Russell’s paradox. In this\ncase we define the triple \\((P,Q,\\delta)\\) as follows: \nThen \\(w\\) in the Inclosure Schema becomes the Russell set and\nthe contradiction obtained from the schema becomes Russell’s\nparadox. \nIn the case of Richard’s paradox we define the triple by: \nHere \\(w = \\{ x \\mid  P(x) \\}\\) becomes the\nset of all reals definable by phrases in English. For any denumerable\nsubset \\(y\\) of \\(w, \\delta(y)\\) is a real that by\nconstruction will differ from all reals in \\(y\\) (it differs from\nthe \\(n\\)th real in \\(y\\) on the \\(n\\)th decimal\nplace). Letting \\(y\\) equal \\(w\\) we thus get\n\\(\\delta(w) \\not\\in w\\). However, at the same time\n\\(\\delta(w)\\) is definable by a phrase in English, so\n\\(\\delta(w) \\in w\\), and we have a contradiction.\nThis contradiction is Richard’s paradox.  \nThe liar paradox also fits Russell’s schema, albeit in a\nslightly less direct way: \nHere \\(w = \\{ x \\mid  P(x) \\}\\) becomes the\nset of true sentences, and \\(\\delta(w)\\) becomes a version of\nthe liar sentence: “this sentence does not belong to the set of\ntrue sentences”.  \nFrom the above it can be concluded that all, or at least most,\nparadoxes of self-reference share a common underlying \nstructure—independent of whether they are semantic, set-theoretic or\nepistemic. Priest (1994) argues that they should then also share a\ncommon solution. Priest calls this the principle of uniform\nsolution: “same kind of paradox, same kind of\nsolution.” Whether the Inclosure Schema can in full generality\ncount as a necessary and sufficient condition for self-referential\nparadoxicality is however disputable (Slater, 2002; Abad, 2008;\nBadici, 2008; Zhong, 2012, and others), hence not all authors agree on\nthe principle of uniform solution either.  \nThe\n Sorites paradox\n is a paradox that on the surface does not involve self-reference at\nall. However, Priest (2010b, 2013) argues that it still fits the\ninclosure schema and can hence be seen as a paradox of self-reference,\nor at least a paradox that should have the same kind of solution as\nthe paradoxes of self-reference. This has led Colyvan (2009), Priest\n(2010) and Weber (2010b) to all advance a dialetheic approach to\nsolving the Sorites paradox. This approach to the Sorites paradox has\nbeen attacked by Beall (2014a, 2014b) and defended by Weber et al.\n(2014). \nMost paradoxes considered so far involve negation in an essential way,\ne.g. sentences saying of themselves that they are not true or\nknowable. The central role of negation will become even clearer when\nwe formalise the paradoxes of self-reference in Section 2 below.\nCurry’s paradox is a similar paradox of self-reference\nthat however does not directly involve negation. A semantic variant of\nCurry’s paradox comes from the following Curry sentence\n\\(C\\): “If this sentence is true then \\(F\\)”,\nwhere \\(F\\) can be any statement, for instance an obviously false\none. Suppose the Curry sentence \\(C\\) is true. Then it expresses\na true fact, that is, if \\(C\\) is true then \\(F\\). However,\nwe already assumed \\(C\\) to be true, so we can infer \\(F\\),\nusing Modus Ponens. We have now proved that if we assume \\(C\\) to\nbe true, then \\(F\\) follows. This is exactly what the Curry\nsentence itself expresses. In other words, we have proved that the\nCurry sentence itself is true! But then we also have that \\(F\\)\nis true, and this is a paradox, since \\(F\\) can be any statement,\nincluding things that are obviously false (Smullyan (2006) let\n\\(F\\) be the sentence “Santa Claus exists”, thereby\nusing Curry’s paradox to prove the existence of Santa Claus). In\na classical logical setting where the implication  \\(C \\rightarrow F\\)\nis equivalent to \\(\\neg C \\vee F\\), Curry’s paradox still\nimplicitly involves negation, but Curry’s paradox is still\nindependently interesting since it goes through with fewer assumptions\nabout the underlying logic than the liar paradox. See the entry on\n Curry’s paradox\n for more details.  \nIn 1985, Yablo succeeded in constructing a semantic paradox that does\nnot involve self-reference in the strict sense. Instead, it consists\nof an infinite chain of sentences, each sentence expressing the\nuntruth of all the subsequent ones. More precisely, for each natural\nnumber \\(i\\) we define \\(S_i\\) to be the\nsentence “for all \\(j\\gt i,\nS_j\\) is not true”. We can then derive\na contradiction as follows: \nFirst we prove that none of the sentences\n\\(S_i\\) can be true. Assume to obtain a\ncontradiction that \\(S_i\\) is true for some\n\\(i\\). Then it is true that “for all\n\\(j\\gt i, S_j\\) is not\ntrue”. Thus none of the sentences\n\\(S_j\\) for \\(j\\gt i\\) are true.\nIn particular, \\(S_{i+1}\\) is not true.\n\\(S_{i+1}\\) is the sentence “for all\n\\(j\\gt i+1, S_j\\) is not\ntrue”. Since this sentence is not true, there must be some\n\\(k\\gt i+1\\) for which \\(S_k\\)\nis true. However, this contradicts that none of the sentences\n\\(S_j\\) with \\(j\\gt i\\) are\ntrue. \nWe have now proved that none of the sentences\n\\(S_i\\) are true. Then, in particular, we have\nthat for all \\(j\\gt 0\\), S\\(_j\\) is not true. This\nis exactly what is expressed by S\\(_0\\), so S\\(_0\\) must\nbe true. This is again a contradiction. \nYablo calls this paradox the \\(\\omega\\)-liar, but others usually\nrefer to it as Yablo’s paradox. Note that none of the\nsentences \\(S_i\\) refer to themselves (not\neven indirectly), but only to the ones that occur later in the\nsequence. Yablo’s paradox is semantic, but as shown by Yablo\n(2006), similar set-theoretic paradoxes involving no self-reference\ncan be formulated in certain set theories.  \nYablo’s paradox demonstrates that we can have logical paradoxes\nwithout self-reference—only a certain kind of\nnon-wellfoundedness is needed to obtain a contradiction. There are\nobviously structural differences between the ordinary paradoxes of\nself-reference and Yablo’s paradox: The ordinary paradoxes of\nself-reference involve a cyclic structure of reference, whereas\nYablo’s paradox involve an acyclic, but non-wellfounded,\nstructure of reference. More precisely, the referential structure in\nself-referential paradoxes such as the liar is a reflexive relation on\na singleton set (a cycle), whereas the referential structure in\nYablo’s paradox is isomorphic to the usual less-than ordering on\nthe natural numbers, which is a strict total order (contains no\ncycles). Even though there is this difference, Yablo’s paradox\nstill share most properties with the ordinary paradoxes of\nself-reference. When solving paradoxes we might thus choose to\nconsider them all under one, and refer to them as paradoxes of\nnon-wellfoundedness. In the following we will however stick to\nthe term paradoxes of self-reference, even though most of\nwhat we say will apply to Yablo’s paradox and related paradoxes\nof non-wellfoundedness as well. \nGiven the insight that not only cyclic structures of reference can\nlead to paradox, but also certain types of non-wellfounded structures,\nit becomes interesting to study further these structures of reference\nand their potential in characterising the necessary and sufficient\nconditions for paradoxicality. This line of work was initiated by\nGaifman (1988, 1992, 2000), and later pursued by Cook (2004), Walicki\n(2009) and others. \nSignificant amounts of newer work on self-reference has gone into\ntrying to make a complete graph-theoretical characterisation of which\nstructures of reference admit paradoxes, including Rabern and Macauley\n(2013), Cook (2014) and Dyrkolbotn and Walicki (2014). A complete\ncharacterisation is still an open problem (Rabern, Rabern and\nMacauley, 2013), but it seems to be a relatively widespread conjecture\nthat all paradoxical graphs of reference are either cyclic or contain\na Yablo-like structure. If this conjecture turns out to be true, it\nwould mean that in terms of structure of reference, all paradoxes of\nreference are either liar-like or Yablo-like. The precise\ncharacterisation of what it means to be a “Yablo-like\nstructure” is still discussed. \nEven though the structure of reference involved in Yablo’s\nparadox does not contain any cycles (each sentence only refers to\nlater sentences in the sequence), it is still being discussed whether\nthe paradox is self-referential or not (Cook, 2014; Halbach and Zhang,\n2017). Yablo (1993) himself argues that it is non-self-referential,\nwhereas Priest (1997) argues that it is self-referential. Butler\n(2017) claims that even if Priest is correct, there will be other\nYablo-like paradoxes that are not self-referential in the sense of\nPriest. In the analysis of Yablo’s paradox, it is essential to\nnote that it involves an infinite sequence of sentences,\nwhere each sentence refers to infinitely many other\nsentences. To formalise it in a setting of propositional logic, it is\nhence necessary to use infinitary propositional logic. Any finitary\nvariant of Yablo’s sequence—where every sentence only\nrefers to finitely many later sentences in the sequence—must\nnecessarily be consistent (non-paradoxical) due to the compactness\ntheorem in propositional logic (every finite subset of sentences in\nthe sequence induces a well-founded reference relation and the\nsentences can hence consistently be assigned truth-values bottom-up).\nIn finitary first- and second-order arithmetic, one can instead\nattempt to formalise Yablo’s paradox by a unary predicate\n\\(S(x)\\) where, for every natural numbers \\(i\\),\n\\(S(\\inumeral)\\) represents the formalisation of the \\(i\\)th\nsentence \\(S_i\\) of the Yablo sequence (where\n\\(\\inumeral\\) is the numeral representing \\(i)\\). How and\nwhether the Yablo paradox can truthfully be represented this way, and\nhow it relates to compactness of the underlying logic, has been\ninvestigated by Picollo (2013).  \nYablo’s paradox has also inspired the creation of similar\nparadoxes involving non-wellfounded, acyclic structures of reference\nin other areas than truth, e.g. the “Yabloesque” variant\nof the Brandenburger-Keisler paradox of epistemic game theory by\nBaşkent (2016), a variant concerning provability by Cieśliński and\nUrbaniak (2013), and a variant in the context of Gödel’s\nincompleteness theorems by Leach-Krouse (2014). \nAfter having presented a number of paradoxes of self-reference and\ndiscussed some of their underlying similarities, we will now turn to a\ndiscussion of their significance. The significance of a\nparadox is its indication of a flaw or deficiency in our understanding\nof the central concepts involved in it. In case of the semantic\nparadoxes, it seems that it is our understanding of fundamental\nsemantic concepts such as truth (in the liar paradox and\nGrelling’s paradox) and definability (in Berry’s\nand Richard’s paradoxes) that are deficient. In case of the\nset-theoretic paradoxes, it is our understanding of the concept of a\nset. If we fully understood these concepts, we should be able\nto deal with them without being led to contradictions.  \nTo illustrate this, consider the case of Zeno’s classical\nparadox on Achilles and the Tortoise (see the entry\n Zeno’s paradoxes\n for details). In this paradox we seem able to prove that the tortoise\ncan win a race against the 10 times faster Achilles if given an\narbitrarily small head start. Zeno used this paradox as an argument\nagainst the possibility of motion. It has later turned out that the\nparadox rests on an inadequate understanding of infinity. More\nprecisely, it rests on an implicit assumption that any infinite series\nof positive reals must have an infinite sum. The later developments of\nthe mathematics of infinite series has shown that this assumption is\ninvalid, and thus the paradox dissolves. The original acceptance of\nZeno’s argument as a paradox was a symptom that the concept of\ninfinity was not sufficiently well understood at the time. In analogy,\nit seems reasonable to expect that the existence of semantic and\nset-theoretic paradoxes is a symptom that the involved semantic and\nset-theoretic concepts are not yet sufficiently well understood.  \nAnother possible answer could be that it is our understanding of the\nvery concept of “contradiction” that is flawed. The\nreasoning involved in the paradoxes of self-reference all end up with\nsome contradiction, a sentence concluded to be both true and false. We\nconsider this an impossibility, hence the paradox, but maybe we\ndon’t have to? Dialetheism is the view that there can\nbe “true contradictions”, meaning that it is not\nimpossible for a sentence to be both true and false. If adopting the\nview of dialetheism, all the paradoxes of self-reference dissolve and\ninstead become existence proofs of certain “dialetheia”:\nsentences being both true and false. Priest (1987) is a strong\nadvocate of dialetheism, and uses his principle of uniform solution\n(see Section 1.4 above) to defend the dialetheist solution. See the\nentries on\n dialetheism\n and\n paraconsistent logic\n for more information. \nCurrently, no commonly agreed upon solution to the paradoxes of\nself-reference exists. They continue to pose foundational problems in\nsemantics and set theory. No claim can be made to a solid foundation\nfor these subjects until a satisfactory solution to the paradoxes has\nbeen provided. Problems surface when it comes to formalising semantics\n(the concept of truth) and set theory. If formalising the intuitive,\n“naive” understanding of these subjects, inconsistent\nsystems linger as the paradoxes will be formalisable in these\nsystems. \nThe liar paradox is a significant barrier to the construction of\nformal theories of truth as it produces inconsistencies in these\npotential theories. A substantial amount of research in self-reference\nconcentrates on formal theories of truth and ways to circumvent the\nliar paradox. There are two articles that have influenced the work on\nformal theories of truth and the liar paradox more than any other:\nAlfred Tarski’s “The Concept of Truth in Formalised\nLanguages” (1935) and Saul Kripke’s “Outline of a\nTheory of Truth” (1975). Below we first introduce some of the\nideas and results of Tarski’s article. Kripke’s article is\ndiscussed in Section 3.2. \nTarski gives a number of conditions that, as he puts it, any\nadequate definition of truth must satisfy. The central of\nthese conditions is what is now most often referred to as Schema\nT (or the T-schema or Convention T or the\nTarski biconditionals): \nHere \\(T\\) is the predicate intended to express truth and\n\\(\\langle \\phi \\rangle\\) is a name for the sentence \\(\\phi\\). Applying the\npredicate \\(T\\) to the name \\(\\langle \\phi \\rangle\\) gives the expression\n\\(T\\langle \\phi \\rangle\\) intended to represent the phrase “\\(\\phi\\)\nis true”. Schema \\(T\\) thus expresses that for every\nsentence \\(\\phi , \\phi\\) holds if and only if the sentence “\\(\\phi\\)\nis true” holds. The \\(T\\)-schema is usually regarded as a\nset of sentences within a formal theory. It is customary to use\nfirst-order arithmetic, that is, first-order predicate logic extended\nwith a set of standard axioms for arithmetic like PA (Peano\nArithmetic) or Robinson’s Q. What is being said in the following\nwill apply to any such first-order formalisation of arithmetic. In\nthis setting, \\(\\langle \\phi \\rangle\\) above denotes the Gödel code\nof \\(\\phi\\), and \\(T\\langle \\phi \\rangle\\) is short for\n\\(T(\\langle \\phi \\rangle)\\). The reader not familiar with Gödel\ncodings (also known as Gödel numberings) can just think of the\nmapping \\(\\langle \\cdot \\rangle\\) as a naming device or quotation mechanism for\nformulae—just like quotation marks in natural language. Often\nused notational variants for \\(\\langle \\phi \\rangle\\) are \\(\\ulcorner \\phi \\urcorner\\)\nand ‘\\(\\phi\\)’. \nTarski showed that the liar paradox is formalisable in any formal\ntheory containing his schema T, and thus any such theory must be\ninconsistent. This result is often referred to as Tarski’s\ntheorem on the undefinability of truth. The result is basically a\nformalisation of the liar paradox within first-order arithmetic\nextended with the \\(T\\)-schema. In order to construct such a\nformalisation it is necessary to be able to formulate self-referential\nsentences (like the liar sentence) within first-order arithmetic. This\nability is provided by the diagonal lemma.  \nDiagonal lemma.\n\nLet \\(S\\) be a theory extending first-order arithmetic. For every\nformula \\(\\phi(x)\\) there is a sentence \\(\\psi\\) such that\n\\(S \\vdash \\psi \\leftrightarrow \\phi \\langle \\psi \\rangle\\).\n \nHere the notation \\(S \\vdash \\alpha\\) means that \\(\\alpha\\) is\nprovable in the theory S, and \\(\\phi \\langle \\psi \\rangle\\) is short for\n\\(\\phi(\\langle \\psi \\rangle)\\). Assume a formula \\(\\phi(x)\\) is given that\nis intended to express some property of sentences – truth, for\ninstance. Then the diagonal lemma gives the existence of a sentence\n\\(\\psi\\) satisfying the biimplication \\(\\psi \\leftrightarrow \\phi \\langle \\psi \\rangle\\).\nThe sentence \\(\\phi \\langle \\psi \\rangle\\) can be thought of as expressing that\nthe sentence \\(\\psi\\) has the property expressed by \\(\\phi(x)\\).\nThe biimplication thus expresses that \\(\\psi\\) is equivalent to the\nsentence expressing that \\(\\psi\\) has property \\(\\phi\\). One can therefore\nthink of \\(\\psi\\) as a sentence expressing of itself that it has\nproperty \\(\\phi\\). In the case of truth, it would be a sentence\nexpressing of itself that it is true. The sentence \\(\\psi\\) is of course\nnot self-referential in a strict sense, but mathematically it behaves\nlike one. It is therefore possible to use sentences generated by the\ndiagonal lemma to formalise paradoxes based on self-referential\nsentences, like the liar. The diagonal lemma is sometimes called the\nfixed-point lemma, since the equivalence \\(\\psi \\leftrightarrow \\phi \\langle \\psi \\rangle\\) can be seen as expressing that \\(\\psi\\) is a\nfixed-point of \\(\\phi(x)\\). \nA theory in first-order predicate logic is called\ninconsistent if a logical contradiction is provable in it.\nTarski’s theorem (on the undefinability of truth) may now be\nstated and proved. \nTarski’s theorem.\n\nAny theory extending first-order arithmetic and containing schema\n\\(T\\) is inconsistent. \nProof. Assume the existence of a consistent formal theory\n\\(S\\) extending first-order arithmetic and containing schema\n\\(T\\). We need to show that this assumption leads to a\ncontradiction. The proof mimics the liar paradox. Apply the diagonal\nlemma to obtain a sentence \\(\\lambda\\) satisfying \\(\\lambda \\leftrightarrow \\neg T \\langle \\lambda \\rangle\\) in S. The sentence \\(\\lambda\\) expresses\nof itself that it is not true, so \\(\\lambda\\) corresponds to the liar\nsentence. Instantiating schema \\(T\\) with the sentence \\(\\lambda\\)\ngives us \\(\\lambda \\leftrightarrow T\\langle \\lambda \\rangle\\). We now have that\nboth \\(\\lambda \\leftrightarrow \\neg T\\langle \\lambda \\rangle\\) and \\(\\lambda \\leftrightarrow T\\langle \\lambda \\rangle\\) hold in \\(S\\) (are provable in\n\\(S)\\), and thus \\(T\\langle \\lambda \\rangle \\leftrightarrow \\neg T\\langle \\lambda \\rangle\\) must hold in \\(S\\). This\ncontradicts \\(S\\) being consistent. \\(\\Box\\) \nNote that the contradiction \\(T\\langle \\lambda \\rangle \\leftrightarrow \\neg T\\langle \\lambda \\rangle\\) above expresses: The liar sentence is true\nif and only if it is not. Compare this to the informal liar presented\nin the beginning of the article. Tarski’s theorem shows that, in\nthe setting of first-order arithmetic, it is not possible to give what\nTarski considers to be an “adequate theory of truth”. The\ncentral question then becomes: How may the formal setting or the\nrequirements for an adequate theory of truth be modified to regain\nconsistency—that is, to prevent the liar paradox from\ntrivialising the system? There are many different answers to this\nquestion, as there are many different ways to regain consistency. In\nSection 3 we will review the most influential approaches. \nThe set-theoretic paradoxes constitute a significant challenge to the\nfoundations of mathematics. They show that it is impossible to have a\nconcept of set satisfying the unrestricted comprehension\nprinciple (also called full comprehension or\nunrestricted abstraction): \nUnrestricted comprehension:\n\n\\(\\forall u (u \\in \\{ x \\mid \\phi(x)\\} \\leftrightarrow \\phi(u))\\), for\nall formulae \\(\\phi(x)\\).\n \nIn an informal setting, the formulae \\(\\phi(x)\\) could be\nallowed to be arbitrary predicates. In a more formal setting they\nwould be formulae of e.g. a suitable first-order language. The\nunrestricted comprehension principle says that for any property\n(expressed by \\(\\phi)\\) there is the set of those entities that\nsatisfy the property. This sounds as a very reasonable principle, and\nit more or less captures the intuitive concept of a set. Indeed, it is\nthe concept of set originally brought forward by the father of set\ntheory, Georg Cantor (1895), himself. Unfortunately, the principle is\nnot sound, as it gives rise to Russell’s paradox. Consider the\nproperty of non-self-membership. This can be expressed by the formula\n\\(x \\not\\in x\\). If we let \\(\\phi(x)\\) be the\nformula \\(x \\not\\in x\\) then the set \\(\\{ x \\mid \n\\phi(x) \\}\\) becomes the Russell set \\(R\\), and we obtain\nthe following instance of the unrestricted comprehension\nprinciple: \nAnalogous to the argument in Russell’s paradox a contradiction\nis now obtained by instantiating \\(u\\) with \\(R\\): \nThis contradiction expresses that the Russell set is a member of\nitself if and only if it is not. What has hereby been proven is the\nfollowing. \nTheorem (Inconsistency of Naive Set Theory).\n\nAny theory containing the unrestricted comprehension principle is\ninconsistent.\n \nCompare this theorem with Tarski’s theorem. Tarski’s\ntheorem expresses that if we formalise the intuitively most obvious\nprinciple concerning truth we end up with an inconsistent theory. The\ntheorem above expresses that the same thing happens when formalising\nthe intuitively most obvious principle concerning set existence and\nmembership. \nGiven the inconsistency of unrestricted comprehension, the objective\nbecomes to find a way to restrict either the comprehension principle\nitself or the underlying logical principles to regain a consistent\ntheory, that is, a set theory that will not be trivialised by\nRussell’s paradox. Many alternative set theories excluding the\nunrestricted comprehension principle have been developed during the\nlast century, among them the type theory of Russell and Whitehead,\nSimple Type theory (ST), Gödel-Bernays set theory (GB),\nZermelo-Fraenkel set theory (ZF), and Quine’s New Foundations\n(NF). These are all believed to be consistent, although no simple\nproofs of their consistency are known. At least they all escape the\nknown paradoxes of self-reference. We will return to a discussion of\nthis in Section 3. \nThe epistemic paradoxes constitute a threat to the construction of\nformal theories of knowledge, as the paradoxes become formalisable in\nmany such theories. Suppose we wish to construct a formal theory of\nknowability within an extension of first-order arithmetic.\nThe reason for choosing to formalise knowability rather than knowledge\nis that knowledge is always relative to a certain agent at a certain\npoint in time, whereas knowability is a universal concept like truth.\nWe could have chosen to work directly with knowledge instead, but it\nwould require more work and make the presentation unnecessarily\ncomplicated. To formalise knowability we introduce a special predicate\n\\(K\\), and use sentences of the form \\(K\\langle \\phi \\rangle\\) to\nexpress that \\(\\phi\\) is knowable. Analogous to the cases of truth and\nset membership, there must be certain logical principles that\n\\(K\\) needs to satisfy in order for our formal theory to qualify\nas an adequate theory of knowability. First of all, all knowable\nsentences must be true. This property can be formalised by the\nfollowing logical principle: \nOf course this principle must itself be knowable, that is, we get the\nfollowing logical principle: \nIn addition, all theorems of first-order arithmetic ought to be\nknowable: \nFurthermore, knowability must be closed under logical\nconsequences: \nNow, the principles A1–A4 is all it takes to formalise the\nparadox of the knower. More precisely, we have the following theorem\ndue to Montague (1963). \nMontague’s theorem.\n\nAny formal theory extending first-order arithmetic and containing\naxiom schemas A1–A4 is inconsistent. \nProof. Assume the existence of a consistent formal theory\n\\(S\\) extending first-order arithmetic and containing axiom\nschemas A1–A4. We need to show that this assumption leads to a\ncontradiction. The proof mimics the paradox of the knower. Apply the\ndiagonal lemma to obtain a sentence \\(\\lambda\\) satisfying \\(\\lambda \\leftrightarrow \\neg K \\langle \\lambda \\rangle\\) in \\(S\\). The sentence\n\\(\\lambda\\) expresses of itself that it is not knowable, so \\(\\lambda\\)\nroughly corresponds to the knower sentence, \\(KS\\). The first\npiece of argumentation used in the paradox of the knower led to the\nconclusion that \\(KS\\) is indeed true. This piece of\nargumentation is mimicked by the following piece of formal reasoning\nwithin \\(S\\): \nThis proof shows that \\(\\lambda\\), our formal version of \\(KS\\), is\nprovable in \\(S\\). The proof corresponds to the informal argument\nthat \\(KS\\) is true. As argued in the paradox of the knower, any\nagent with sufficient reasoning capabilities will be able to prove the\ntruth of \\(KS\\), and thus come to know that \\(KS\\) holds.\nThus \\(KS\\) must be knowable. What this means in the present\nformal framework is that we can also prove the knowability of \\(\\lambda\\)\nin \\(S\\): \nThis completes the proof of the knowability of \\(\\lambda\\), corresponding\nto the informal argument that \\(KS\\) is known by some agent. Note\nthe similarity between the two pieces of proof in lines 1–7 and\n8–14. The only difference is that in the latter all formulae are\npreceded by an extra K. This is because lines 8–14 express the\nsame line of reasoning as lines 1–7 with the only difference\nthat the latter is a proof of the knowability of \\(\\lambda\\)\nrather than the truth of \\(\\lambda\\). Having concluded that\n\\(\\lambda\\) is both true and knowable, we now immediately obtain a\ncontradiction as in the paradox of the knower: \nThis completes the proof of Montague’s theorem. \\(\\Box\\) \nThe proof above is simpler than the original proof of Montague (1963)\nand directly mimicks the reasoning underlying the paradox of the\nknower. Montague’s theorem shows that in the setting of\nfirst-order arithmetic we cannot have a theory of knowledge or\nknowability satisfying even the basic principles A1–A4.\nMontague’s theorem is a generalisation of Tarski’s\ntheorem. If a predicate symbol \\(K\\) satisfies Tarski’s\nschema \\(T\\) then it is easy to see that it will also satisfy\naxiom schemas A1–A4. Thus axiom schemas A1–A4 constitute a\nweakening of the \\(T\\)-schema, and Montague’s theorem shows\nthat even this much weaker version of the \\(T\\)-schema is\nsufficient to produce inconsistency. \nFormalising knowledge as a predicate in a first-order logic is\nreferred to as the syntactic treatment of knowledge.\nAlternatively, one can choose to formalise knowledge as a modal\noperator in a suitable modal logic. This is referred to as the\nsemantic treatment of knowledge. In the semantic treatment of\nknowledge one generally avoids problems of self-reference, and thus\ninconsistency, but it is at the expense of the expressive power of the\nformalism (the problems of self-reference are avoided by propositional\nmodal logic not admitting anything equivalent to the diagonal lemma\nfor constructing self-referential formulas). \nThe central argument given in the proof of Tarski’s theorem is\nclosely related to the central argument in Gödel’s first\nincompleteness theorem (Gödel, 1931). Gödel’s theorem\ncan be given the following formulation. \nGödel’s first incompleteness theorem.\n\nIf first-order arithmetic is \\(\\omega\\)-consistent then it is incomplete.\n \nA theory is called \\(\\omega\\)-consistent if the following holds\nfor every formula \\(\\phi(x)\\) containing \\(x\\) as its only\nfree variable: If \\(\\vdash \\neg \\phi(n)\\) for every natural\nnumber \\(n\\) then \\(\\not\\vdash \\exists x\\phi(x).\n\\omega\\)-consistency is a stronger condition than ordinary consistency,\nso any \\(\\omega\\)-consistent theory will also be consistent. A theory is\nincomplete if it contains a formula which can neither be\nproved nor disproved. \nProof sketch of Gödel’s first incompleteness\ntheorem. Assume first-order arithmetic is both \\(\\omega\\)-consistent\nand complete. We need to show that this leads to a contradiction.\nGödel constructs a formula Bew (for\n“Beweis”) in formal arithmetic satisfying, for all \\(\\phi\\)\nand all \\(n\\), \nAssuming the theory to be \\(\\omega\\)-consistent and complete we can prove\nthat for all sentences \\(\\phi\\), \nThe proof of (2) runs like this. First we prove the implication from\nleft to right. If \\(\\vdash \\exists x\\)Bew\\((x,\n\\langle \\phi \\rangle)\\) then there is some \\(n\\) such that\n\\(\\not\\vdash \\neg\\)Bew\\((n, \\langle \\phi \\rangle)\\), by\n\\(\\omega\\)-consistency. By completeness we get\n\\(\\vdash\\)Bew\\((n, \\langle \\phi \\rangle)\\) for this \\(n\\). By\n(1) above we get that \\(n\\) denotes a proof of \\(\\phi\\). That is,\n\\(\\phi\\) is provable, so we have \\(\\vdash \\phi\\). To prove the implication\nfrom right to left, note that if \\(\\vdash \\phi\\) then there must be an\n\\(n\\) such that \\(\\vdash\\) Bew\\((n, \\langle \\phi \\rangle)\\),\nby (1). From this we get\n\\(\\vdash \\exists x\\)Bew\\((x, \\langle \\phi \\rangle)\\), as\nrequired. This concludes the proof of (2). Now, when in a complete\ntheory we have (2), we must also have: \nIf we let \\(\\exists x\\)Bew\\((x, \\langle \\phi \\rangle)\\) be\nabbreviated \\(T\\langle \\phi \\rangle\\) then (3) becomes: \nThis is the \\(T\\)-schema! Thus if we assume first-order\narithmetic to be \\(\\omega\\)-consistent and complete then schema\n\\(T\\) turns out to be interpretable in it. Now, Tarski’s\ntheorem above shows that there exists no such consistent theory, and\nwe thus have a contradiction. \\(\\Box\\) \nIn the proof above we reduced Gödel’s incompleteness\ntheorem to an application of Tarski’s theorem in order to show\nthe close link between the two (this version of the proof is due to\nBolander, 2002). Gödel was well aware of this link, and indeed it\nseems that Gödel even proved Tarski’s theorem before Tarski\nhimself did (Feferman, 1984). Gödel’s theorem can be\ninterpreted as demonstrating a limitation in what can be achieved by\npurely formal procedures. It says that if first-order arithmetic is\n\\(\\omega\\)-consistent (which it is believed to be), then there must be\narithmetical sentences that can neither be proved nor disproved by the\nformal procedures of first-order arithmetic. One might at first expect\nthis limitation to be resolvable by the inclusion of additional\naxioms, but Gödel showed that the incompleteness result still\nholds when first-order arithmetic is extended with an arbitrary finite\nset of axiom schemas (or, more generally, an arbitrary recursive set\nof axioms). Thus we obtain a general limitation result saying that\nthere cannot exist a formal proof procedure by which any given\narithmetical sentence can be proved to hold or not to hold. For more\ndetails on Gödel’s incompleteness theorem, see the entry on\n Kurt Gödel. \nThe limitation result of Gödel’s theorem is closely related\nto another limitation result known as the undecidability of the\nhalting problem. This is a result stating that there are\nlimitations to what can be computed. We will present this result in\nthe following. The result is based on the notion of a Turing\nmachine, which is a generic model of a computer program running\non a computer having unbounded memory. Thus any program running on any\ncomputer can be thought of as a Turing machine (see the entry on\n Turing machines\n for more details). When running a Turing machine, it will either\nterminate after a finite number of computation steps, or will continue\nrunning forever. In case it terminates after a finite number of\ncomputation steps we say that it halts. The halting\nproblem is the problem of finding a Turing machine that can\ndecide whether other Turing machines halt or not. We say that a Turing\nmachine \\(H\\) decides the halting problem if the\nfollowing holds: \n\\(H\\) takes as input a pair \\((\\langle A\\rangle ,x)\\)\nconsisting of the Gödel code \\(\\langle A\\rangle\\) of a Turing\nmachine \\(A\\) and an arbitrary string \\(x. H\\)\nreturns the answer “yes” if the Turing machine \\(A\\)\nhalts when given input \\(x\\), and “no” otherwise.\n \nThus if a Turing machine \\(H\\) decides the halting problem, we\ncan use it to determine for an arbitrary Turing machine \\(A\\) and\narbitrary input \\(x\\) whether \\(A\\) will halt on input\n\\(x\\) or not. The undecidability of the halting problem\nis the following result, due to Turing (1937), stating that no such\nmachine can exist:  \nTheorem (Undecidability of the Halting Problem).\n\nThere exists no Turing machine deciding the halting problem. \nProof. Assume the existence of a Turing machine \\(H\\)\ndeciding the halting problem. We need to show that this assumption\nleads to a contradiction. The proof mimics Grelling’s paradox.\nWe call a Turing machine \\(A\\) heterological if\n\\(A\\) doesn’t halt on input \\(\\langle A\\rangle\\), that is, if\n\\(A\\) doesn’t halt when given its own Gödel code as\ninput. Using \\(H\\), we can construct a Turing machine \\(G\\)\nthat halts if and only if it is given the Gödel code of a\nheterological Turing machine as input. \\(G\\) works as\nfollows: \n\\(G\\) takes as input the Gödel code of a Turing machine\n\\(A\\). Then it runs \\(H\\) on input\n\\((\\langle A\\rangle ,\\langle A\\rangle)\\). If \\(H\\) on input\n\\((\\langle A\\rangle ,\\langle A\\rangle)\\) returns “no” we\nknow that \\(A\\) is heterological, and \\(G\\) is halted. If,\non the other hand, \\(H\\) on input\n\\((\\langle A\\rangle ,\\langle A\\rangle)\\) returns “yes” then\n\\(G\\) is forced into an infinite loop (that is, is forced to\nnever halt).\n \nIn analogy to Grelling’s paradox we can now ask whether\n\\(G\\) is a heterological Turing machine or not. This leads to the\nfollowing sequence of equivalences:  \nThis gives the required contradiction. \\(\\Box\\) \nFrom the two theorems above we see that in the areas of provability\nand computability the paradoxes of self-reference turn into limitation\nresults: there are limits to what can be proven and what can be\ncomputed. This is actually quite similar to what happened in the areas\nof semantics, set theory and epistemology: The paradoxes of\nself-reference turned into theorems showing that there are limits to\nwhich properties we can consistently assume a truth predicate to have\n(Tarski’s theorem), a set theory to have (inconsistency of naive\nset theory), and a knowledge predicate to have (Montague’s\ntheorem). It is hard to accept these limitation results, because most\nof them conflict with our intuitions and expectations. The central\nrole played by self-reference in all of them makes them even harder to\naccept, and definitely more puzzling. However, we are forced to accept\nthem, and forced to accept the fact that in these areas we cannot have\nall we might (otherwise) reasonably ask for.  \nThe present section takes a look at how to solve—or rather,\ncircumvent—the paradoxes. To solve or circumvent a paradox one\nhas to weaken some of the assumptions leading to the contradiction. It\nis very difficult to choose which assumptions to weaken, since each of\nthe explicitly stated assumptions underlying a paradox appears to be\n“obviously true”—otherwise it would not qualify as\na paradox. Below we will take a look at the most influential\napproaches to solving the paradoxes. \nSo far the presentation has been structured according to type of\nparadox, that is, the semantic, set-theoretic and epistemic paradoxes\nhave been dealt with separately. However, it has also been\ndemonstrated that these three types of paradoxes are similar in\nunderlying structure, and it has been argued that a solution to one\nshould be a solutions to all (the principle of uniform solution).\nTherefore, in the following the presentation will be structured not\naccording to type of paradox but according to type of solution. Each\ntype of solution considered in the following can be applied to any of\nthe paradoxes of self-reference, although in most cases the\nconstructions involved were originally developed with only one type of\nparadox in mind. \nBuilding hierarchies is a method to circumvent both the set-theoretic,\nsemantic and epistemic paradoxes. Russell’s original solution to\nhis paradox—as well as Tarski’s original solution to his\nundefinability of truth problem—was to build\nhierarchies. In Russell’s case, this led to type\ntheory. In Tarski’s case, it led to what is now known as\nTarski’s hierarchy of languages. In both cases, the\nidea is to stratify the universe of discourse (sets, sentences) into\nlevels. In type theory, these levels are called types. The\nfundamental idea of type theory is to introduce the constraint that\nany set of a given type may only contain elements of lower types (that\nis, may only contain sets which are located lower in the\nstratification). This effectively blocks Russell’s paradox,\nsince no set can then be a member of itself. \nIn Tarski’s case, the stratification is obtained in the\nfollowing way. Assume one wants to equip a language \\(L_0\\) with a\ntruth predicate. From Tarski’s theorem (Section 2.1) it is known\nthat this truth predicate cannot be part of the language \\(L_0\\)\nitself—at least not as long as we want the truth predicate to\nsatisfy schema \\(T\\). Instead one builds a hierarchy of languages,\n\\(L_0, L_1, L_2,\\ldots\\), where each language \\(L_{i+1}\\) has a truth\npredicate \\(T_{i+1}\\) that only applies to the sentences of \\(L_j,\nj\\le i\\). In this hierarchy, \\(L_0\\) is called the object\nlanguage and, for all \\(i, L_{i+1}\\) is called the\nmeta-language of \\(L_i\\). This hierarchy effectively blocks\nthe liar paradox, since now a sentence can only express the truth or\nuntruth of sentences at lower levels, and thus a sentence such as the\nliar that expresses its own untruth cannot be formed. \nRussell’s type theory can be regarded as a solution to\nRussell’s paradox, since type theory demonstrates how to\n“repair” set theory such that the paradox disappears.\nSimilarly, Tarski’s hierarchy can be regarded as a solution to\nthe liar paradox. It is the same stratification idea that underlies\nboth of Russell’s and Tarski’s solutions. The point to\nnote is that Russell’s paradox and the liar paradox depend\ncrucially on circular notions (self-membership and\nself-reference). By making a stratification in which an\nobject may only contain or refer to objects at lower levels,\ncircularity disappears. In the case of the epistemic paradoxes, a\nsimilar stratification could be obtained by making an explicit\ndistinction between first-order knowledge (knowledge about the\nexternal world), second-order knowledge (knowledge about first-order\nknowledge), third-order knowledge (knowledge about second-order\nknowledge), and so on. This stratification actually comes for free in\nthe semantic treatment of knowledge, where knowledge is formalised as\na modal operator. \nBuilding explicit hierarchies is sufficient to avoid circularity, and\nthus sufficient to block the standard paradoxes of self-reference.\nHowever, there also exist paradoxes such as Yablo’s that do not\nrely on circularity and self-reference. Such paradoxes can also be\nblocked by a hierarchy approach, but it is necessary to further\nrequire the hierarchy to be well-founded, that is, to have a lowest\nlevel. Otherwise, the paradoxes of non-wellfoundedness can still be\nformulated. For instance, Yablo’s paradox may be formalised in a\ndescending hierarchy of languages. A descending hierarchy of\nlanguages consists of languages \\(L_0, L_{-1}, L_{-2},\\ldots\\) where\neach language \\(L_{-i}\\) has a truth predicate that only applies to\nthe sentences of the languages \\(L_{-j}, j\\gt i\\).  Similarly, a\nset-theoretic paradox of non-wellfoundedness may be formulated in a\ntype theory allowing negative types. The conclusion drawn is that a\nstratification of the universe is not itself sufficient to avoid all\nparadoxes—the stratification also has to be well-founded.  \nBuilding an explicit (well-founded) hierarchy to solve the paradoxes\nis today by most considered an overly drastic and heavy-handed\napproach. The hierarchies introduce a number of complicating\ntechnicalities not present in a “flat universe”, and even\nthough the paradoxes do indeed disappear, so do all non-paradoxical\noccurrences of self-reference. Kripke (1975) gives the following\nillustrative example taken from ordinary discourse. Let \\(N\\) be\nthe following statement, made by Nixon, \nand let \\(J\\) be the following statement, made by Jones, \nIn a Tarskian language hierarchy, the sentence \\(N\\) would have\nto be on a higher level than all of Jones’ utterances, and,\nconversely, the sentence \\(J\\) would have to be on a higher level\nthan all of Nixon’s utterances. Since \\(N\\) is an utterance\nof Nixon, and \\(J\\) is an utterance of Jones, \\(N\\) would\nhave to be on a higher level than \\(J\\), and \\(J\\) on a\nhigher lever than \\(N\\). This is obviously not possible, so in a\nhierarchy like the Tarskian, these sentences cannot even be\nformulated. The sentences \\(N\\) and \\(J\\) are indeed both\nindirectly self-referential, since \\(N\\) makes reference to a\ntotality including \\(J\\), and \\(J\\) makes reference to a\ntotality including \\(N\\). Nevertheless, in most cases \\(N\\)\nand \\(J\\) are harmless, and do not produce a paradox. A paradox\nis only produced in the special case where all of Jones’\nutterances except possibly \\(J\\) are true, and exactly half of\nNixon’s utterances are false, disregarding \\(N\\). Kripke\nuses the fact that \\(N\\) and \\(J\\) are only problematic in a\ncertain special case as an argument against an approach that\naltogether excludes the possibility of formulating \\(N\\) and\n\\(J\\).  \nAnother argument against the hierarchy approach is that explicit\nstratification is not part of ordinary discourse, and thus it might be\nconsidered somewhat ad hoc to introduce it into formal\nsettings with the sole purpose of circumventing the paradoxes. Not\nhaving an explicit stratification in ordinary discourse obviously\ndoesn’t imply the non-existence of an underlying, implicit,\nstratification, but at least it’s not explicitly represented in\nour syntax.  \nThe arguments given above are among the reasons the work of Russell\nand Tarski has not been considered to furnish the final solutions to\nthe paradoxes. Many alternative solutions have been proposed. One\nmight for instance try to look for implicit hierarchies\nrather than explicit hierarchies. An implicit hierarchy is a\nhierarchy not explicitly reflected in the syntax of the language. In\nthe following section we will consider some of the solutions to the\nparadoxes obtained by such implicit stratifications.  \nTarski’s hierarchy approach to the semantic paradoxes dominated\nthe field until 1975, when Kripke published his famous and highly\ninfluential paper, “Outline of a Theory of Truth”. This\npaper has greatly shaped most later approaches to theories of truth\nand the semantic paradoxes. It should be noted, however, that ideas\nquite similar to Kripke’s were developed simultaneously and\nindependently by Martin and Woodruff (1975), and that a parallel\napproach in a set-theoretic setting was developed independently by\nGilmore (1974). \nKripke’s ideas are based on an analysis of the problems involved\nin Tarski’s hierarchy approach. Kripke lists a number of\narguments against having a language hierarchy in which each sentence\nlives at a fixed level, determined by its syntactic form. He proposes\nan alternative solution which still uses the idea of having levels,\nbut where the levels are not becoming an explicit part of the syntax.\nRather, the levels become stages in an iterative construction of a\ntruth predicate. To explain Kripke’s construction, some\nadditional technical machinery is required. \nAt each stage in Kripke’s construction, the truth predicate is\nonly partially defined, that is, it only applies to some of\nthe sentences of the language. To deal with such partially defined\npredicates, a three-valued logic is employed, that is, a\nlogic which operates with a third value, undefined, in\naddition to the truth values true and false. Often\nthe third value is denoted “\\(u\\)” or\n“\\(\\bot\\)” (bottom). A partially defined predicate only\nreceives one of the classical truth values, true or\nfalse, when it is applied to one of the terms for which the\npredicate has been defined, and otherwise it receives the value\nundefined. There are several different three-valued logics\navailable, differing in how they treat the third value. Here only one\nof them is briefly described, called Kleene’s strong\nthree-valued logic. More detailed information on this and related\nlogics can be found in the entry on\n many-valued logic. \nIn Kleene’s strong three-valued logic, the value \\(\\bot\\)\n(undefined) can be interpreted as “not yet\ndefined”. So one could think of formulae with the value \\(\\bot\\)\nas formulae that actually have a classical truth value (true\nor false), but which has just not been determined yet. This\ninterpretation of undefined is reflected in the truth tables\nfor the logic, given below. The upper truth table is for disjunction,\nthe lower for negation: \nThese truth tables define the three-valued logic completely, as \\(\\vee\\)\nand \\(\\neg\\) are taken to form an adequate set of connectives and\nexistential and universal quantification are treated as infinite\ndisjunction and conjunction, respectively.  \nTo handle partially defined truth predicates, it is necessary to\nintroduce the notion of partial models. In a partial model\nfor a first-order language, each \\(n\\)-place predicate symbol\n\\(P\\) is interpreted by a pair \\((U,V)\\) of\ndisjoint \\(n\\)-place relations on the domain of the model.\n\\(U\\) is called the extension of \\(P\\) and\n\\(V\\) its anti-extension. In the model, \\(P\\) is\ntrue of the objects in \\(U\\), false of the objects in \\(V\\),\nand undefined otherwise. In this way, any atomic sentence receives one\nof the truth values true, false or\nundefined in the model. Non-atomic formulae are given truth\nvalues in the model by using Kleene’s strong three-valued logic\nfor evaluating the connectives.  \nGiven the definition of a partial model, a partially interpreted\nlanguage is a pair \\((L,M)\\) where \\(L\\) is a\nfirst-order language and \\(M\\) is a partial model of \\(L\\).\nKripke recursively defines a sequence of partially interpreted\nlanguages \\(L_0, L_1, L_2,\\ldots\\), only differing in their\ninterpretation of the truth predicate \\(T\\). The first language,\n\\(L_0\\), is taken to be an arbitrary language in which\nboth the extension and anti-extension of \\(T\\) are the empty set.\nThus in \\(L_0\\), the truth predicate is completely\nundefined. For any \\(\\alpha\\), the language\n\\(L_{\\alpha +1}\\) is like \\(L_{\\alpha}\\)\nexcept that \\(T\\) is interpreted by the extension/anti-extension\npair \\((U,V)\\) given by: \nThis definition immediately gives that for all \\(\\alpha\\), \nWhat has been constructed is a sequence \\(L_0,\nL_1, L_2,\\ldots\\) of partially\ninterpreted languages such that \\(T\\) is interpreted in\n\\(L_{\\alpha +1}\\) as the truth predicate for\n\\(L_{\\alpha}\\). This is just like Tarski’s\nhierarchy of languages, except that here there is no syntactic\ndistinction between the different languages and their truth\npredicates. \nThe sequence \\(L_0, L_1,\nL_2,\\ldots\\) has an important property: For each\n\\(\\alpha\\), the interpretation of \\(T\\) in\n\\(L_{\\alpha +1}\\) extends the interpretation of\n\\(T\\) in \\(L_{\\alpha}\\), that is, both the\nextension and anti-extension of \\(T\\) increase (or stay the same)\nwhen moving from \\(L_{\\alpha}\\) to\n\\(L_{\\alpha +1}\\). This means that one can define a new\npartially interpreted language \\(L_{\\omega}\\) by letting\nthe extension of \\(T\\) be the union of all the extensions of\n\\(T\\) in \\(L_0, L_1,\nL_2,\\ldots\\); and similarly for the anti-extension.\nThus in \\(L_{\\omega}\\), the interpretation of \\(T\\)\nextends the interpretation that \\(T\\) receives in all previous\nlanguages. This furnishes a strategy for continuing the iterative\nconstruction of a truth predicate into the transfinite: For each\nsuccessor ordinal \\(\\alpha +1\\), define\n\\(L_{\\alpha +1}\\) from \\(L_{\\alpha}\\)\nexactly as in the finite case above; and for each limit ordinal\n\\(\\sigma\\), define \\(L_{\\sigma}\\) from the preceding\nlanguages \\((L_i)_{i\\lt \\sigma}\\) in\nthe same way as \\(L_{\\omega}\\) was defined (for a\ndetailed explanation of the ordinal numbers and their use in this\ncontext, see the entry on\n the revision theory of truth).\n A simple cardinality consideration now shows that this transfinite\nsequence of languages will eventually stabilise: There is an\nordinal \\(\\gamma\\) such that \\(L_{\\gamma} = L_{\\gamma +1}\\). Hence the following instance of (4) is\nobtained: \nThis shows that \\(L_{\\gamma}\\) is actually a language\ncontaining its own truth predicate: Any sentence \\(\\phi\\) is true (false)\nif and only if the sentence expressing its truth,\n\\(T\\langle \\phi \\rangle\\), is true (false). The equivalence (5) is\nnothing more than a semantic analogue of Tarski’s schema\n\\(T\\) in a three-valued setting. The construction of the language\n\\(L_{\\gamma}\\) was one of the major contributions of\nKripke (1975). It shows that in a three-valued logical setting it is\nactually possible for a language to contain its own truth predicate.\nIt is easy to see that the third value, undefined, is\nessential to making things work: If \\(L_{\\gamma}\\) had\nbeen a totally interpreted language (that is, a language with no\nundefined sentences), then \\(L_{\\gamma}\\) would satisfy\nschema T, by (5) above. However, it immediately contradicts\nTarski’s theorem that such a totally interpreted language can\nexist. \nAmong the sentences that receive the value undefined in\n\\(L_{\\gamma}\\) is the liar sentence. The solution to the\nliar paradox implicit in Kripke’s theory is this: Since both\nassuming that the liar sentence is true and that it is false leads to\na contradiction it must be neither, it is undefined. The liar\nsentence is said to suffer from a truth-value gap. The idea\nof avoiding the liar paradox by allowing truth-value gaps did in fact\nappear several times in the literature before Kripke’s paper,\nbut Kripke was among the first to make it an integral part of a\ngenuine theory. \nAs with the hierarchy solution to the liar paradox, the truth-value\ngap solution is by many considered to be problematic. The main\ncriticism is that by using a three-valued semantics, one gets an\ninterpreted language which is expressively weak. One cannot, for\ninstance, in any of Kripke’s languages have a predicate\nexpressing the property of being undefined. This is in fact\nnoted by Kripke himself. If a partially interpreted language contained\nsuch a predicate, the following strengthened liar sentence\nwithin the language could be formulated: “This sentence is\neither false or undefined”. The strengthened liar sentence is\ntrue if and only if false or undefined, so we have a new paradox,\ncalled the strengthened liar paradox. The problem with the\nstrengthened liar paradox is known as a revenge problem:\nGiven any solution to the liar, it seems we can come up with a new\nstrengthened paradox, analogous to the liar, that remains unsolved.\nThe idea is that whatever semantic status the purported solution\nclaims the liar sentence to have, if we are allowed freely to refer to\nthis semantic status in the object language, we can generate a new\nparadox.  \nThe inability of the Kripkean language to express its own\nundefined predicate also means that we cannot in the Kripkean\nobject-language express a statement such as: “The liar sentence\nis undefined”. In fact in Kripke’s language\n\\(L_{\\gamma}\\), the liar sentence \\(is\\) undefined,\nso the previous sentence expresses a truth about\n\\(L_{\\gamma}\\) that cannot be expressed within\n\\(L_{\\gamma}\\) itself (hence the language is\nexpressively incomplete). To express the true statement “The\nliar sentence is undefined”, we are forced to ascend into a\nmeta-language of \\(L_{\\gamma}\\). As Kripke (1975)\nhimself puts it: “The ghost of the Tarski hierarchy is still\nwith us.”  \nSucceeding the work of Kripke, many attempts have been made to\nconstruct languages containing their own truth predicate and not\nsuffering from the revenge problem of strengthened liars. Many of\nthese attempts have focused on modifying or extending the underlying\nstrong three-valued logic, e.g. modifying the semantics of the\nconditional (Field, 2003, 2008) or allowing an unbounded number of\ntruth-values (Cook, 2007; Schlenker, 2010; Tourville and Cook, 2016).\n \nKripke’s theory circumvents the liar paradox by assigning it the\nvalue undefined. An alternative way to circumvent the liar\nparadox would be to assign it the value both true and false\nin a suitable paraconsistent logic. This would be the correct solution\naccording to the dialetheist view, cf. Section 2. One of the simplest\nparaconsistent logics is LP, which is a three-valued logic with the\nsame truth tables as Kleene’s strong three-valued logic\npresented above—the only difference is that the third truth\nvalue is interpreted as both true and false rather than\nundefined. A reason for preferring a paraconsistent logic\nover a partial logic is that paradoxical sentences such as the liar\ncan then be modelled as true contradictions (dialetheia)\nrather than truth-value gaps. We refer again to the entries on\n dialetheism\n and\n paraconsistent logic\n for more information. \nThe choice is between truth-value gaps and truth-value\ngluts: A truth-value gap is a statement with no truth-value,\nneither true or false (like undefined in Kleene’s\nstrong three-valued logic), and a truth-value glut is a statement with\nseveral truth-values, e.g. both true and false (like in the\nparaconsistent logic LP). There are also arguments in favour of\nallowing both gaps and gluts, e.g. by letting the set of truth-values\nform of a bilattice (Fitting, 2006; Odintsov and Wansing, 2015). The\nsimplest non-trivial bilattice has exactly four values, which in the\ncontext of truth-values are interpreted as: true,\nfalse, \\(\\bot\\) (neither true nor false), and \\(\\top\\) (both\ntrue and false).  \nFor a more extensive discussion of Kripke’s theory, its\nsuccessors and rivals, see the entry on\n the liar paradox. \nBuilding implicit rather than explicit hierarchies is also an idea\nthat has been employed in set theory. New Foundations (NF) by Quine\n(1937) is a modification of simple type theory where the\nstratification into syntactic types has been replaced by a\nstratification on the comprehension principle: \nNF comprehension:\n\n\\(\\forall u(u \\in \\{ x \\mid \\phi(x)\\} \\leftrightarrow \\phi(u))\\), for\nall stratified formulae \\(\\phi(x)\\).\n \nA formula \\(\\phi\\) is stratified if there exists a mapping\n\\(\\sigma\\) (a stratification) from the variables of \\(\\phi\\) to the\nnatural numbers such that if \\(u \\in v\\) is a\nsubformula of \\(\\phi\\) then \\(\\sigma(v) = \\sigma(u)+1\\)\nand if \\(u = v\\) is a subformula of \\(\\phi\\) then\n\\(\\sigma(v) = \\sigma(u)\\). Obviously the formula\n\\(x \\not\\in x\\) is not stratified, and thus the NF\ncomprehension principle cannot be used to formulate Russell’s\nparadox in the theory. Quine’s New Foundations is essentially\nobtained from type theory by hiding the types from the syntax. Thus,\nthe theory still makes use of a hierarchy approach to avoid the\nparadoxes, but the hierarchy is made implicit by not representing it\nin the syntax of formulae. Cantini (2015) has investigated the\npossibility of mimicking this implicit hierarchy approach in the\ncontext of theories of truth (achieving an implicitly represented\nTarskian truth hierarchy).  \nZermelo-Fraenkel set theory (ZF) is another theory that builds on the\nidea of an implicit hierarchy to circumvent the paradoxes. However, it\ndoes so in a much less direct way than NF. In ZF, sets are built\nbottom-up, starting with the empty set and iterating a construction of\nbigger and bigger sets using the operations of union and power set.\nThis produces a hierarchy with the empty set on the lowest level,\nlevel 0, and with the power set operation producing a set of level\n\\(\\alpha +1\\) from a set of level \\(\\alpha\\). Analogous to Kripke’s\niterative construction, the procedure is continued into the\ntransfinite using the union operator at the limit ordinal levels. The\nhierarchy obtained is called the cumulative hierarchy. One of\nthe axioms of ZF, the axiom of foundation, states that every set of ZF\nlives on a certain level in this cumulative hierarchy. In other words,\nthe axiom of foundation states that there are no sets in ZF besides\nthe ones that can be constructed bottom-up by the iterative procedure\njust described. Since in a cumulative hierarchy, there can be no sets\ncontaining themselves, no universal set, and no non-wellfounded sets,\nnone of the known paradoxes can immediately be formulated in the\ntheory. This does obviously not in itself ensure the consistency of\nZF, but at least it illustrates how the idea of a set hierarchy plays\na significant role in ZF as well. ZF has a privileged status among set\ntheories, as it is today the most widely acknowledged candidate for a\nformal foundation of mathematics. \nKripke’s iterative construction of a truth predicate presented\nabove may be viewed as an instance of a more general fixed point\napproach towards building formal theories of truth. Fixed point\napproaches have become central to contemporary formal theories of\ntruth. The main idea is to have a truth revision operator and\nthen look for fixed points of this operator. At heart of such fixed\npoint approaches is some suitable fixed point theorem\nguaranteeing the existence of fixed points for certain kinds of\noperators. There are several different fixed point theorems available.\nConsider now one of the simpler ones. \nFixed point theorem.\n\nLet \\(\\tau\\) be a monotone operator on a chain complete partial order\n(henceforth ccpo). Then \\(\\tau\\) has a least fixed point, that is, there\nis a least f such that \\(\\tau(f) = f\\).\n \nA ccpo is a partial order \\((D,\\lt)\\) in which every\ntotally ordered subset of \\(D\\) has a least upper bound. The\ntotally ordered subsets of \\(D\\) are called chains in\n\\(D\\). A monotone operator on \\((D,\\lt)\\) is a\nmapping \\(\\tau : D \\rightarrow D\\) satisfying: \nKripke’s construction fits into the fixed point theorem above in\nthe following way. First note that the set of partially interpreted\nlanguages that only differ on the interpretation of \\(T\\) forms a\nccpo: Simply define the ordering on these languages by\n\\(L_1 \\le L_2\\) iff the\ninterpretation of \\(T\\) in \\(L_2\\) extends the\ninterpretation of \\(T\\) in \\(L_1\\) (that is, the\nextension and anti-extension of \\(T\\) in \\(L_1\\)\nare included in those of \\(L_2)\\). Then define a truth\nrevision operator \\(\\tau\\) on these languages by: \nNote that if \\(L_{\\alpha}\\) is one of the languages in\nKripke’s construction, then \\(L_{\\alpha +1} = \\tau(L_{\\alpha})\\). The idea of this truth revision\noperator \\(\\tau\\) is that if \\(\\tau(L)=L'\\) then\n\\(L'\\) will be a language in which \\(T\\) is\ninterpreted as the truth predicate for \\(L\\). If therefore\n\\(\\tau(L)=L\\) for some \\(L\\), that is, if\n\\(L\\) is a fixed point of \\(\\tau\\), then \\(L\\) will be a\nlanguage containing its own truth predicate. This motivates the search\nfor fixed points of \\(\\tau\\). Since \\(\\tau\\) is easily seen to be monotone,\nby the fixed point theorem it has a least fixed point. It is not hard\nto see that this fixed point is exactly the language\n\\(L_{\\gamma}\\) constructed in Kripke’s theory of\ntruth. Kripke’s construction is thus recaptured in the setting\nof fixed points for monotone operators. \nThe point of introducing the additional machinery was not just to\nrediscover the language \\(L_{\\gamma}\\). The point is\nrather to have provided a much more general and abstract framework\nwhich may lead to new theories of truth and give further insights into\nthe semantic paradoxes. It turns out that the truth revision operator\n\\(\\tau\\) defined above has many interesting fixed-points in addition to\n\\(L_{\\gamma}\\). It is also possible to obtain new\ntheories of truth by considering alternative ways of making the set of\ninterpreted languages into a ccpo. One may for instance add an\nadditional truth value and consider the situation in a four-valued\nlogic, as considered by Fitting (1997); or one may remove the third\ntruth value undefined and construct a ccpo in a completely\nclassical setting. In the classical setting, attention is restricted\nto the totally interpreted languages (languages in which every\nsentence is either true or false), and an ordering on them is defined\nby: \\(L_1 \\le L_2\\) holds iff the\nextension of the truth predicate in \\(L_1\\) is included\nin the extension of the truth predicate in \\(L_2\\),\nthat is, iff \\(L_2\\) points out at least as many\nsentences as true as \\(L_1\\). This gives a ccpo. By\nusing the fixed point theorem in this setting on a suitably defined\nrevision operator, it is fairly easy to prove the existence of a\ntotally interpreted language containing a positive definition of\ntruth. By this is meant that the interpreted language has a\npredicate \\(T\\) satisfying the following restricted version of\nthe \\(T\\)-schema: \nwhere the positive sentences are those built without using negation\n\\((\\neg)\\). Since (7) is satisfiable in a totally interpreted language,\nthe first-order theory containing the sentences of (7) as axioms must\nbe consistent. This should be contrasted with Tarski’s theorem\nstating that the unrestricted \\(T\\)-schema is\ninconsistent. If the unrestricted comprehension principle is similarly\nrestricted to the positive formulae, we also get a consistent theory.\nThis was originally shown by Gilmore (1974). \nThe fixed point approach is also the point of departure of the\nrevision theory of truth developed by Belnap and Gupta\n(1993). The revision theory of truth is the most influential theory of\ntruth and the semantic paradoxes that has been developed since the\ntheory of Kripke. The revision theory considers the standard truth\nrevision operator \\(\\tau\\) defined by (6) as an operator on the\ntotally interpreted languages. On these languages \\(\\tau\\)\ndoesn’t have a fixed point: If it had such a fixed point\n\\(L\\) then \\(L\\) would be a totally interpreted language\nsatisfying the full schema \\(T\\), directly contradicting\nTarski’s theorem. Since \\(\\tau\\) doesn’t have a fixed point\non the totally interpreted languages, the revision theory instead\nconsiders transfinite sequences \\(L_1,\nL_2\\), … ,\n\\(L_{\\omega},\nL_{\\omega +1}\\), … of totally interpreted\nlanguages satisfying: \nIn such a sequence, each sentence \\(\\phi\\) will either eventually\nstabilise on a classical truth value (true or false), or it will never\nstabilise. An example of a sentence that will never stabilise is the\nliar sentence: If the liar sentence is true in one of the languages\n\\(L_{\\alpha}\\) it will be false in\n\\(L_{\\alpha +1}\\), and vice versa. The revision theory\nthus gives an account of truth that correctly models the\nbehaviour of the liar sentence as one that never stabilises on a truth\nvalue. In the revision theory it is argued that this gives a more\ncorrect account of truth and self-reference than Kripke’s theory\nin which the liar sentence is simply assigned the value undefined.\nBoth the revision theory of truth and Kripke-style fixed-point\ntheories are still being actively researched (Gupta and Standefer,\n2017; Hsiung, 2017; Schindler, 2017). A full account of the revision\ntheory can be found in the entry on\n the revision theory of truth.\n  \nStudying self-referential phenomena as fixed-points is not limited to\ntheories of truth. For instance, in the context of epistemic\nparadoxes, the Brandenburger-Keisler paradox has been cast as a\nfixed-point result by Abramsky and Zvesper (2015). \nMurzi and Massimiliano (2015) gives an overview of recent developments\nin approaches to solving the paradoxes: paracompleteness (allowing\ntruth-value gaps), paraconsistency (allowing truth-value gluts),\nsubstructural logics (weakening the logical principles of classical\nlogic), and the revenge problems that these approaches will or could\nlead to. Recent developments in substructural logics as a cure to the\nparadoxes include French (2016) (dropping reflexivity), Caret, Colin\nand Weber (2015), Shapiro and Lionel (2015), Mares and Paoli (2014)\n(dropping contraction), and Cobreros, Égré, Ripley and van Rooij\n(2014) (dropping transitivity). The volume by Achourioti et al. (eds.,\n2015) has several papers on self-reference and how to avoid paradoxes\nin the context of theories of truth.  \nVolker Halbach and Albert Visser (2014a, 2014b) has made a very\ndetailed study of self-reference in arithmetic, studying what it means\nfor a sentence of arithmetic to ascribe itself a property, and how\nthis depends on the chosen encoding, the details of fixed-point\nconstruction etc. ","contact.mail":"tb@imm.dtu.dk","contact.domain":"imm.dtu.dk"}]
