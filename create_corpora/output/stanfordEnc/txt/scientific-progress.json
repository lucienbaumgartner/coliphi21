[{"date.published":"2002-10-01","date.changed":"2019-10-16","url":"https://plato.stanford.edu/entries/scientific-progress/","author1":"Ilkka Niiniluoto","author1.info":"http://www.helsinki.fi/theoreticalphilosophy/staff/Niiniluoto.htm","entry":"scientific-progress","body.text":"\n\n\nScience is often distinguished from other domains of human culture by\nits progressive nature: in contrast to art, religion, philosophy,\nmorality, and politics, there exist clear standards or normative\ncriteria for identifying improvements and advances in science. For\nexample, the historian of science George Sarton argued that “the\nacquisition and systematization of positive knowledge are the only\nhuman activities which are truly cumulative and progressive,”\nand “progress has no definite and unquestionable meaning in\nother fields than the field of science” (Sarton 1936). However,\nthe traditional cumulative view of scientific knowledge was\neffectively challenged by many philosophers of science in the 1960s\nand the 1970s, and thereby the notion of progress was also questioned\nin the field of science. Debates on the normative concept of progress\nare at the same time concerned with axiological questions about the\naims and goals of science. The task of philosophical analysis is to\nconsider alternative answers to the question: What is meant by\nprogress in science? This conceptual question can then be complemented\nby the methodological question: How can we recognize progressive\ndevelopments in science? Relative to a definition of progress and an\naccount of its best indicators, one may then study the factual\nquestion: To what extent, and in which respects, is science\nprogressive? \n\nThe idea that science is a collective enterprise of researchers in\nsuccessive generations is characteristic of the Modern Age (Nisbet\n1980). Classical empiricists (Francis Bacon) and rationalists\n(René Descartes) of the seventeenth century urged that the use\nof proper methods of inquiry guarantees the discovery and\njustification of new truths. This cumulative view of scientific\nprogress was an important ingredient in the optimism of the eighteenth\ncentury Enlightenment, and it was incorporated in the 1830s in Auguste\nComte’s program of positivism: by accumulating empirically\ncertified truths science also promotes progress in society. Other\ninfluential trends in the nineteenth century were the Romantic vision\nof organic growth in culture, Hegel’s dynamic account of\nhistorical change, and the theory of evolution. They all inspired\nepistemological views (e.g., among Marxists and pragmatists) which\nregarded human knowledge as a process. Philosopher-scientists with an\ninterest in the history of science (William Whewell, Charles Peirce,\nErnst Mach, Pierre Duhem) gave interesting analyses of some aspects of\nscientific change. \nIn the early twentieth century, analytic philosophers of science\nstarted to apply modern logic to the study of science. Their main\nfocus was the structure of scientific theories and patterns of\ninference (Suppe 1977). This “synchronic” investigation of\nthe “finished products” of scientific activities was\nquestioned by philosophers who wished to pay serious attention to the\n“diachronic” study of scientific change. Among these\ncontributions one can mention N.R. Hanson’s Patterns of\nDiscovery (1958), Karl Popper’s The Logic of Scientific\nDiscovery (1959) and Conjectures and Refutations (1963),\nThomas Kuhn’s The Structure of Scientific Revolutions\n(1962), Paul Feyerabend’s incommensurability thesis (Feyerabend\n1962), Imre Lakatos’ methodology of scientific research\nprogrammes (Lakatos and Musgrave 1970), and Larry Laudan’s\nProgress and Its Problems (1977). Darwinist models of\nevolutionary epistemology were advocated by Popper’s\nObjective Knowledge: An Evolutionary Approach (1972) and\nStephen Toulmin’s Human Understanding (1972). These\nworks challenged the received view about the development of scientific\nknowledge and rationality. Popper’s falsificationism,\nKuhn’s account of scientific revolutions, and Feyerabend’s\nthesis of meaning variance shared the view that science does not grow\nsimply by accumulating new established truths upon old ones. Except\nperhaps during periods of Kuhnian normal science, theory change is not\ncumulative or continuous: the earlier results of science will be\nrejected, replaced, and reinterpreted by new theories and conceptual\nframeworks. Popper and Kuhn differed, however, in their definitions of\nprogress: the former appealed to the idea that successive theories may\napproach towards the truth, while the latter characterized progress in\nterms of the problem-solving capacity of theories.  \nSince the mid-1970s, a great number of philosophical works have been\npublished on the topics of change, development, and progress in\nscience (Harré 1975; Stegmüller 1976; Howson 1976; Rescher\n1978; Radnitzky and Andersson 1978, 1979; Niiniluoto and Tuomela 1979;\nDilworth 1981; Smith 1981; Hacking 1981; Schäfer 1983; Niiniluoto\n1984; Laudan 1984a; Rescher 1984; Pitt 1985; Radnitzky and Bartley\n1987; Callebaut and Pinxten 1987; Balzer et al. 1987; Hull 1988;\nGavroglu et al. 1989; Kitcher 1993; Pera 1994; Chang 2004; Maxwell\n2017). These studies have also led to many important novelties being\nadded to the toolbox of philosophers of science. One of them is the\nsystematic study of inter-theory relations, such as reduction (Balzer\net al. 1984; Pearce 1987; Balzer 2000; Jonkisz 2000; Hoyningen-Huene\nand Sankey 2001), correspondence (Krajewski 1977; Nowak 1980; Pearce\nand Rantala 1984; Nowakowa and Nowak 2000; Rantala 2002), and belief\nrevision (Gärdenfors, 1988; Aliseda, 2006). Another was the\nrecognition that, besides individual statements and theories, there is\nalso a need to consider temporally developing units of scientific\nactivity and achievement: Kuhn’s paradigm-directed normal\nscience, Lakatos’ research programme, Laudan’s research\ntradition, Wolfgang Stegmüller’s (1976) dynamic theory\nevolution, Philip Kitcher’s (1993) consensus practice. A new\ntool that is employed in many defenses of realist views of scientific\nprogress (Niiniluoto 1980, 2014; Aronson, Harré, and Way 1994;\nKuipers 2000, 2019) is the notion of truthlikeness or verisimilitude\n(Popper 1963, 1970). \nLively interest about the development of science promoted close\nco-operation between historians and philosophers of science. For\nexample, case studies of historical examples (e.g., the replacement of\nNewton’s classical mechanics by quantum theory and theory of\nrelativity) have inspired many philosophical treatments of scientific\nrevolutions. Historical case studies were important for philosophers\nwho started to study scientific discovery (Hanson 1958; Nickles 1980).\nHistorically oriented philosophers have shown how instruments and\nmeasurements have promoted the progress of physics and chemistry\n(Chang 2004). Experimental psychologists have argued that the strive\nfor broad and simple explanations shapes learning and inference\n(Lombrozo 2016). Further interesting material for philosophical\ndiscussions about scientific progress is provided by quantitative\napproaches in the study of the growth of scientific publications (de\nSolla Price 1963; Rescher 1978) and science indicators (Elkana et\nal. 1978). Sociologists of science have studied the dynamic\ninteraction between the scientific community and other social\ninstitutions. With their influence, philosophers have analyzed the\nrole social and cultural values in the development of science (Longino\n2002). One of the favorite topics of sociologists has been the\nemergence of new scientific specialties (Mulkay 1975; Niiniluoto\n1995b). Sociologists are also concerned with the pragmatic problem of\nprogress: what is the best way of organizing research activities in\norder to promote scientific advance. In this way, models of scientific\nchange turn out to be relevant to issues of science policy (Böhme\n1977; Schäfer 1983). \nScience is a multi-layered complex system involving a community of\nscientists engaged in research using scientific methods in order to\nproduce new knowledge. Thus, the notion of science may refer to a\nsocial institution, the researchers, the research process, the method\nof inquiry, and scientific knowledge. The concept of progress can be\ndefined relative to each of these aspects of science. Hence, different\ntypes of progress can be distinguished relative to science:\neconomical (the increased funding of scientific research),\nprofessional (the rising status of the scientists and their\nacademic institutions in the society), educational (the\nincreased skill and expertise of the scientists), methodical\n(the invention of new methods of research, the refinement of\nscientific instruments), and cognitive (increase or\nadvancement of scientific knowledge). These types of progress have to\nbe conceptually distinguished from advances in other human activities,\neven though it may turn out that scientific progress has at least some\nfactual connections with technological progress (increased\neffectiveness of tools and techniques) and social progress\n(economic prosperity, quality of life, justice in society). \nAll of these aspects of scientific progress may involve different\nconsiderations, so that there is no single concept that would cover\nall of them. For our purposes, it is appropriate here to concentrate\nonly on cognitive progress, i.e., to give an account of advances of\nscience in terms of its success in knowledge-seeking or\ntruth-seeking. \n“Progress” is an axiological or a normative concept, which\nshould be distinguished from such neutral descriptive terms as\n“change” and “development” (Niiniluoto 1995a).\nIn general, to say that a step from stage \\(A\\) to stage \\(B\\)\nconstitutes progress means that \\(B\\) is an improvement over\n\\(A\\) in some respect, i.e., \\(B\\) is better than \\(A\\)\nrelative to some standards or criteria. In science, it is a normative\ndemand that all contributions to research should yield some cognitive\nprofit, and their success in this respect can be assessed before\npublication by referees (peer review) and after publication by\ncolleagues. Hence, the theory of scientific progress is not merely a\ndescriptive account of the patterns of developments that science has\nin fact followed. Rather, it should give a specification of the\nvalues or aims that can be used as the constitutive\ncriteria for “good science.”  \nThe “naturalist” program in science studies suggests that\nnormative questions in the philosophy of science can be reduced to\nhistorical and sociological investigations of the actual practice of\nscience. In this spirit, Laudan has defended the project of testing\nphilosophical models of scientific change by the history of science:\nsuch models, which are “often couched in normative\nlanguage,” can be recast “into declarative statements\nabout how science does behave” (Laudan et al. 1986; Donovan et\nal. 1988). It may be the case that most scientific work, at least the\nbest science of each age, is also good science. But it is also evident\nthat scientists often have different opinions about the criteria of\ngood science, and rival researchers and schools make different choices\nin their preference of theories and research programs. Therefore, it\ncan be argued against the naturalists that progress should not be\ndefined by the actual developments of science: the definition\nof progress should give us a normative standard for appraising the\nchoices that the scientific communities have made, could have made,\nare just now making, and will make in the future. The task of finding\nand defending such standards is a genuinely philosophical one which\ncan be enlightened by history and sociology but which cannot be\nreduced to empirical studies of science. For the same reason,\nMizrahi’s (2013) empirical observation that scientists talk\nabout the aim of science in terms of knowledge rather than merely\ntruth cannot settle the philosophical debate about scientific progress\n(cf. Bird, 2007, Niiniluoto, 2014). \nFor many goal-directed activities it is important to distinguish\nbetween quality and progress. Quality is primarily\nan activity-oriented concept, concerning the skill and competence in\nthe performance of some task. Progress is a result-oriented concept,\nconcerning the success of a product relative to some goal. All\nacceptable work in science has to fulfill certain standards of\nquality. But it seems that there are no necessary connections between\nquality and progress in science. Sometimes very well-qualified\nresearch projects fail to produce important new results, while less\ncompetent but more lucky works lead to success. Nevertheless, the\nskillful use of the methods of science will make progress highly\nprobable. Hence, the best practical strategy in promoting scientific\nprogress is to support high-quality research.  \nFollowing the pioneering work of Derek de Solla Price (1963) in\n“scientometrics,” quantitative science indicators\nhave been proposed as measures of scientific activity (Elkana et\nal. 1978). For example, output measures like publication\ncounts are measures of scholarly achievement, but it is\nproblematic whether such a crude measure is sufficient to indicate\nquality (cf. Chotkowski La Follette 1982). The number of articles in\nrefereed journals is an indicator of the quality of their author, but\nit is clear that this indicator cannot yet define what progress means,\nsince publications may contribute different amounts to the advance of\nscientific knowledge. “Rousseau’s Law” proposed by\nNicholas Rescher (1978) marks off a certain part (the square root) of\nthe total number of publications as “important”, but this\nis merely an alleged statistical regularity. \nAnother example of a science indicator, citation index, is an\nindicator for the “impact” of a publication and for the\n“visibility” of its author within the scientific\ncommunity. Martin and Irvine (1983) suggest that the concept of\nscientific progress should be linked to the notion of impact,\ni.e., the actual influence of research to the surrounding scientific\nactivities at a given time. It is no doubt correct that one cannot\nadvance scientific knowledge without influencing the epistemic state\nof the scientific community. But the impact of a publication as such\nonly shows that it has successfully “moved” the scientific\ncommunity in some direction. If science is goal-directed, then we must\nacknowledge that movement in the wrong direction does not\nconstitute progress. \nThe failure of science indicators to function as definitions of\nscientific progress is due to the fact that they do not take into\naccount the semantic content of scientific publications. To\ndetermine whether a work \\(W\\) gives a contribution to scientific\nprogress, we have to specify what \\(W\\) says (alternatively: what\nproblems \\(W\\) solves) and then relate this content of \\(W\\) to the\nknowledge situation of the scientific community at the time of the\npublication of \\(W\\). For the same reason, research assessment\nexercises may use science indicators as tools, but ultimately they\nhave to rely on the judgment of peers who have substantial knowledge\nin the field. \nProgress is a goal-relative concept. But even when we\nconsider science as a knowledge-seeking cognitive enterprise, there is\nno reason to assume that the goal of science is one-dimensional. In\ncontrast, as Isaac Levi’s classic Gambling With Truth\n(1967) argued, the cognitive aim of scientific inquiry has to be\ndefined as a weighted combination of several different, and even\nconflicting, epistemic utilities. As we shall see in Section\n3, alternative theories of scientific progress can be understood as\nspecifications of such epistemic utilities. For example, they might\ninclude truth and information (Levi 1967; see also Popper 1959, 1963)\nor explanatory and predictive power (Hempel 1965). Kuhn’s (1977)\nlist of the values of science includes accuracy, consistency, scope,\nsimplicity, and fruitfulness. \nA goal may be accessible in the sense that it can be reached\nin a finite number of steps in a finite time. A goal is\nutopian if it cannot be reached or even approached. Thus,\nutopian goals cannot be rationally pursued, since no progress can be\nmade in an attempt to reach them. Walking to the moon is a utopian\ntask in this sense. However, not all inaccessible goals are utopian:\nan unreachable goal, such as being morally perfect, can function as a\nregulative principle in Kant’s sense, if it guides our\nbehavior so that we are able to make progress towards it. \nThe classical sceptic argument against science, repeated by Laudan\n(1984a), is that knowing the truth is a utopian task. Kant’s\nanswer to this argument was to regard truth as a regulative principle\nfor science. Charles S. Peirce, the founder of American pragmatism,\nargued that the access to the truth as the ideal limit of scientific\ninquiry is “destined” or guaranteed in an\n“indefinite” community of investigators. Almeder’s\n(1983) interpretation of Peirce’s view of scientific progress is\nthat there is only a finite number of scientific problems and they\nwill all be solved in a finite time. However, there does not seem to\nbe any reason to think that truth is generally accessible in this\nstrong sense. Therefore, the crucial question is whether it is\npossible to make rational appraisals that we have made progress in the\ndirection of the truth (see Section 3.4). \nA goal is effectively recognizable if there are routine or\nmechanical tests for showing that the goal has been reached or\napproached. If the defining criteria of progress are not recognizable\nin this strong sense, we have to distinguish true or real\nprogress from our perceptions or estimations of\nprogress. In other words, claims of the form ‘The step from\nstage \\(A\\) to stage \\(B\\) is progressive’ have to be\ndistinguished from our appraisals of the form ‘The step from\nstage \\(A\\) to stage \\(B\\) seems progressive on the available\nevidence’. The latter appraisals, as our own judgments, are\nrecognizable, but the former claims may be correct without our knowing\nit. Characteristics and measures that help us to make such appraisals\nare then indicators of progress. \nLaudan requires that a rational goal for science should be accessible\nand effectively recognizable (Laudan 1977, 1984a). This requirement,\nwhich he uses to rule out truth as a goal of science, is very strong.\nThe demands of rationality cannot dictate that a goal has to be given\nup, if there are reasonable indicators of progress towards it.  \nA goal may be backward-looking or forward-looking:\nit may refer to the starting point or to the destination point of an\nactivity. If my aim is to travel as far from home as possible, my\nsuccess is measured by my distance from Helsinki. If I wish to become\never better and better piano player, my improvement can be assessed\nrelative to my earlier stages, not to any ideal Perfect Pianist. But\nif I want to travel to San Francisco, my progress is a function of my\ndistance from the destination. Only in the special case, where there\nis only one way from \\(A\\) to \\(B\\), the backward-looking and the\nforward-looking criteria (i.e., distance from \\(A\\) and\ndistance to \\(B)\\) determine each other.  \nKuhn and Stegmüller were advocating backward-looking criteria of\nprogress. In arguing against the view that “the proper measure\nof scientific achievement is the extent to which it brings us closer\nto” the ultimate goal of “one full, objective true account\nof nature,” Kuhn suggested that we should “learn to\nsubstitute evolution-from-what-we-know for\nevolution-toward-what-we-wish-to-know” (Kuhn 1970, p. 171). In\nthe same spirit, Stegmüller (1976) argued that we should reject\nall variants of “a teleological metaphysics” defining\nprogress in terms of “coming closer and closer to the\ntruth.” \nA compromise between forward-looking and backward-looking criteria can\nbe proposed in the following way. If science is viewed as a\nknowledge-seeking activity, it is natural to define real progress in\nforward-looking terms: the cognitive aim of science is to know\nsomething that is still unknown, and our real progress depends on our\ndistance from this destination. But, as this goal is unknown to us,\nour estimates or perceptions of progress have to be based on\nbackward-looking evidential considerations. This kind of view of the\naims of science does not presuppose the existence of one\nunique ultimate goal. To use Levi’s words, our goals may be\n“myopic” rather than “messianic” (Levi 1985):\nthe particular target that we wish to hit in the course of our inquiry\nhas to be redefined “locally,” relative to each cognitive\nproblem situation. Furthermore, in addition to the multiplicity of the\npossible targets, there may be several roads that lead to the same\ndestination. The forward-looking character of the goals of inquiry\ndoes not exclude what Stegmüller calls “progress\nbranching.” This is analogous to the simple fact that we may\napproach San Francisco from New York along two different\nways—via Chicago or St Louis.  \nSome philosophers use the concepts of progress and rationality as\nsynonyms: progressive steps in science are precisely those that are\nbased upon the scientists’ rational choices. One possible\nobjection is that scientific discoveries are progressive when they\nintroduce novel ideas, even though they cannot be fully explained in\nrational terms (Popper 1959; cf. Hanson 1958; Kleiner 1993). However,\nanother problem is more relevant here: By whose lights should such\nsteps be evaluated? This question is urgent especially if we\nacknowledge that standards of good science have changed in history\n(Laudan 1984a).  \nAs we shall see, the main rival philosophical theories of progress\npropose absolute criteria, such as problem-solving capacity\nor increasing truthlikeness, that are applicable to all developments\nof science throughout its history. On the other hand, rationality is a\nmethodological concept which is historically relative: in\nassessing the rationality of the choices made by the past scientists,\nwe have to study the aims, standards, methods, alternative theories\nand available evidence accepted within the scientific community at\nthat time (cf. Doppelt, 1983, Laudan, 1987; Niiniluoto 1999a). If the\nscientific community \\(SC\\) at a given point of time \\(t\\) accepted\nthe standards \\(V\\), then the preference of \\(SC\\) for theory \\(T\\)\nover \\(T'\\) on evidence \\(e\\) was rational just in case the\nepistemic utility of \\(T\\) relative to \\(V\\) was higher than that of\n\\(T'\\). But in a new situation, where the standards were different\nfrom \\(V\\), a different preference might have been rational.  \nA major controversy among philosophers of science is between\ninstrumentalist and realist views of scientific theories (Leplin 1984;\nPsillos 1999; Niiniluoto 1999a; Saatsi 2018). The\ninstrumentalists follow Duhem in thinking that theories are\nmerely conceptual tools for classifying, systematizing and predicting\nobservational statements, so that the genuine content of science is\nnot to be found on the level of theories (Duhem 1954). Scientific\nrealists, by contrast, regard theories as attempts to describe\nreality even beyond the realm of observable things and regularities,\nso that theories can be regarded as statements having a truth value.\nExcluding naive realists, most scientists are fallibilists in\nPeirce’s sense: scientific theories are hypothetical and always\ncorrigible in principle. They may happen to be true, but we cannot\nknow this for certain in any particular case. But even when theories\nare false, they can be cognitively valuable if they are closer to the\ntruth than their rivals (Popper 1963). Theories should be testable by\nobservational evidence, and success in empirical tests gives inductive\nconfirmation (Hintikka 1968; Kuipers 2000) or non-inductive\ncorroboration to the theory (Popper 1959). \nIt might seem natural to expect that the main rival accounts of\nscientific progress would be based upon the positions of\ninstrumentalism and realism. But this is only partly true. To be sure,\nnaive realists as a rule hold the accumulation-of-truths view of\nprogress, and many philosophers combine the realist view of theories\nwith the axiological thesis that truth is an important goal of\nscientific inquiry. A non-cumulative version of the realist view of\nprogress can be formulated by using the notion of truthlikeness. But\nthere are also philosophers who accept the possibility of a realist\ntreatment of theories, but still deny that truth is a relevant value\nof science which could have a function in the characterization of\nscientific progress. Bas van Fraassen’s (1980) constructive\nempiricism takes the desideratum of science to be empirical\nadequacy: what a theory says about the observable should be true.\nThe acceptance of a theory involves only the claim that it is\nempirically adequate, not its truth on the theoretical level. Van\nFraassen has not developed an account of scientific progress in terms\nof his constructive empiricism, but presumably such an account would\nbe close to empiricist notions of reduction and Laudan’s account\nof problem-solving ability (see Section 3.2). \nAn instrumentalist who denies that theories have truth values usually\ndefines scientific progress by referring to other virtues theories may\nhave, such as their increasing empirical success. In 1906 Duhem\nexpressed this idea by a simile: scientific progress is like a\nmounting tide, where waves rise and withdraw, but under this\nto-and-fro motion there is a slow and constant progress. However, he\ngave a realist twist to his view by assuming that theories classify\nexperimental laws, and progress means that the proposed\nclassifications approach a “natural classification” (Duhem\n1954). \nEvolutionary epistemology is open to instrumentalist (Toulmin 1972)\nand realist (Popper 1972) interpretations (Callebaut and Pinxten 1987;\nRadnitzky and Bartley 1987). A biological approach to human knowledge\nnaturally gives emphasis to the pragmatist view that theories function\nas instruments of survival. Darwinist evolution in biology is not\ngoal-directed with a fixed forward-looking goal; rather, species adapt\nthemselves to an ever changing environment. In applying this account\nto the problem of knowledge-seeking, the fitness of a theory can be\ntaken to mean that the theory is accepted by members of the\nscientific community. But a realist can reinterpret the evolutionary\nmodel by taking fitness to mean the truth or truthlikeness of\na theory (Niiniluoto 1984). \nFor a constructive empiricist, it would be natural to think that among\nempirically adequate theories one theory \\(T_{2}\\) is better than\nanother theory \\(T_{1}\\) if \\(T_{2}\\) entails more true observational\nstatements than \\(T_{1}\\). Such a comparison makes sense at least if\nthe observation statements entailed by \\(T_{1}\\) are a proper subset\nof those entailed by \\(T_{2}\\). Kemeny and Oppenheim (1956) gave a\nsimilar condition in their definition of reduction: \\(T_{1}\\) is\nreducible to \\(T_{2}\\) if and only if \\(T_{2}\\) is at least as well\nsystematized as \\(T_{1}\\) and \\(T_{2}\\) is observationally stronger\nthan \\(T_{1}\\), i.e., all observational statements explained by\n\\(T_{1}\\) are also consequences of \\(T_{2}\\). Variants of such an\nempirical reduction relation has been given by the structuralist\nschool in terms of set-theoretical structures (Stegmüller 1976;\nScheibe 1986; Balzer et al. 1987; Moulines 2000). A similar idea, but\napplied to cases where the first theory \\(T_{1}\\) has been falsified\nby some observational evidence, was used by Lakatos in his definition\nof empirically progressive research programmes: the new superseding\ntheory \\(T_{2}\\) should have corroborated excess content relative to\n\\(T_{1}\\) and \\(T_{2}\\) should contain all the unrefuted content of\n\\(T_{1}\\) (Lakatos and Musgrave 1970). The definition of Kuipers\n(2000) allows that even the new theory \\(T_{2}\\) is empirically\nrefuted: \\(T_{2}\\) should have (in the sense of set-theoretical\ninclusion) more empirical successes, but fewer empirical\ncounter-examples than \\(T_{1}\\).  \nAgainst these cumulative definitions it has been argued that\ndefinitions of empirical progress have to take into account an\nimportant complication. A new theory often corrects the\nempirical consequences of the previous one, i.e., \\(T_{2}\\) entails\nobservational statements \\(e_{2}\\) which are in some sense close to\nthe corresponding consequences \\(e_{1}\\) of \\(T_{1}\\). Various models\nof approximate explanation and approximate reduction\nhave been introduced to handle these situations. An important special\ncase is the limiting correspondence relation: theory\n\\(T_{2}\\) approaches theory \\(T_{1}\\) (or the observational\nconsequences of \\(T_{2}\\) approach those of \\(T_{1})\\) when some\nparameter in its laws approaches a limit value (e.g., theory of\nrelativity approaches classical mechanics when the velocity of light c\ngrows without limit). Here \\(T_{2}\\) is said to be a concretization of\nthe idealized theory \\(T_{1}\\) (Nowak 1980; Nowakowa and Nowak 2000).\nHowever, these models do not automatically guarantee that the step\nfrom an old theory to a new one is progressive. For example, classical\nmechanics can be related by the correspondence condition to an\ninfinite number of alternative and mutually incompatible theories, and\nsome additional criteria are needed to pick out the best among\nthem. \nKuhn’s (1962) strategy was to avoid the notion of truth and to\nunderstand science as an activity of making accurate predictions and\nsolving problems or “puzzles”. Paradigm-based normal\nscience is cumulative in terms of the problems solved, and even\nparadigm-changes or revolutions are progressive in the sense that\n“a relatively large part” of the problem-solving capacity\nof the old theory is preserved in the new paradigm. But, as Kuhn\nargued, it may happen that some problems solved by the old theory are\nno longer relevant or meaningful for the new theory. These cases are\ncalled “Kuhn-losses.” A more systematic account of these\nideas is given by Laudan (1977): the problem-solving\neffectiveness of a theory is defined by the number and importance\nof solved empirical problems minus the number and importance of the\nanomalies and conceptual problems that the theory generates. Here the\nconcept of anomaly refers to a problem that a theory fails to solve,\nbut is solved by some of its rivals. For Laudan the solution of a\nproblem by a theory \\(T\\) means that the “statement of the\nproblem” is deduced from \\(T\\). A good theory is thus\nempirically adequate, strong in its empirical content,\nand—Laudan adds—avoids conceptual problems.  \nOne difficulty for the problem-solving account is to find a proper\nframework for identifying and counting problems (Rescher 1984; Kleiner\n1993). When Newton’s mechanics is applied to determine the orbit\nof the planet Mars, this can be counted as one problem. But, given an\ninitial position of Mars, the same theory entails a solution to an\ninfinite number of questions concerning the position of Mars at time\n\\(t\\). Perhaps the most important philosophical issue is whether one\nmay consistently hold that the notion of problem-solving may be\nentirely divorced from truth and falsity: the realist may admit that\nscience is a problem-solving activity, if this means the attempt to\nfind true solutions to predictive and explanatory questions\n(Popper, 1972; Niiniluoto 1984). Bird’s (2007) main criticism\nagainst the “functional account” of Kuhn and Laudan is its\nconsequence that the cumulation of false solutions from an entirely\nfalse theory counts as scientific progress (e.g. Oresme in the\nfourteenth century believed that hot goat’s blood could split\ndiamonds). \nAccording to Shan (2019), “science progresses if more useful\nresearch problems and their corresponding solutions are\nproposed”. This definition involves both problem-defining and\nproblem-solving, as illustrated by the development of early genetics\nfrom Darwin to Bateson. Shan gives up the typical Kuhn-Laudan\nassumption that the scientific community is able to know whether it\nmakes progress or not, and is open to the introduction of the notions\nof know-how and perspectival truth, so that his “new functional\napproach” is a compromise with what Bird (2007) calls the\n“epistemic view” of progress. \nA different view of problem-solving is involved in those theories\nwhich discuss problems of decision and action. A\nradical pragmatist view treats science as a systematic method of\nsolving such decision problems relative to various kinds of practical\nutilities. According to the view called behavioralism by the\nstatistician L J. Savage, science does not produce knowledge, but\nrather recommendations for actions: to accept a hypothesis is always a\ndecision to act as if that hypothesis were true. Progress in science\ncan then be measured by the achievement of the practical utilities of\nthe decision maker. An alternative methodological version of\npragmatism is defended by Rescher (1977) who accepts the realist view\nof theories with some qualifications, but argues that the progress of\nscience has to be understood as “the increasing success of\napplications in problem-solving and control.” Similarly, Douglas\n(2014), after suggesting that the distinction between pure and applied\nscience should be relinquished, defines progress “in terms of\nthe increased capacity to predict, control, manipulate, and intervene\nin various contexts.” In this view, the notion of scientific\nprogress is in effect reduced to science-based technological progress\n(cf. Niiniluoto 1984). \nAlready the ancient philosophers regarded explanation as an important\nfunction of science. The status of explanatory theories was\ninterpreted either in an instrumentalist or realist way: Plato’s\nschool started the tradition of “saving the appearances”\nin astronomy, while Aristotle took theories to be necessary truths.\nBoth parties can take explanatory power to be a criterion of\na good theory, as shown by van Fraassen’s (1980) constructive\nempiricism and Wilfrid Sellars’ scientific realism (Pitt 1981;\nTuomela 1985). When it is added that a good theory should also yield\ntrue empirical predictions, the notions of explanatory and predictive\npower can be combined within the notion of systematic power\n(Hempel 1965). If the demand of systematic power simply means that a\ntheory has many true deductive consequences in the observational\nlanguage, this concept is essentially equivalent to the notion of\nempirical success and empirical problem-solving ability discussed in\nSection 3.2, but normally explanation is taken to include additional\nstructural conditions besides mere deduction (Aliseda 2006). Inductive\nsystematization should also be taken into account (Hempel 1965;\nNiiniluoto and Tuomela 1973). \nOne important idea regarding systematization is that a good theory\nshould unify empirical data and laws from different domains\n(Kitcher 1993; Schurz 2015). For Whewell, the paradigm case of such\n“consilience” was the successful unification of\nKepler’s laws and Galileo’s laws by means of\nNewton’s theory. \nIf theories are underdetermined by observational data, then one is\noften advised to choose the simplest theory compatible with the\nevidence (Foster and Martin 1966). Simplicity may be an\naesthetic criterion of theory choice (Kuipers 2019), but it may also\nhave a cognitive function in helping us in our attempt to understand\nthe world in an “economical” way. Ernst Mach’s\nnotion of the economy of thought is related to the demand of\nmanageability, which is important especially in the\nengineering sciences and other applied sciences: for example, a\nmathematical equation can be made “simpler” by suitable\napproximations, so that it can be solved by a computer. Simplicity has\nalso been related to the notion of systematic or unifying power. This\nis clear in Eino Kaila’s concept of relative\nsimplicity, which he defined in 1939 as the ratio between the\nexplanatory power and the structural complexity of a theory (for a\ntranslation, see Kaila 2014). According to this conception, progress\ncan be achieved by finding structurally simpler explanations of the\nsame data, or by increasing the scope of explanations without making\nthem more complex. Laudan’s formula of solved empirical problems\nminus generated conceptual problems is a variation of the same\nidea. \nAfter Hempel’s pioneering work in 1948, various probabilistic\nmeasures of explanatory power have been proposed (Hempel 1965;\nHintikka 1968). Most of them demand that the explanatory theory \\(h\\)\nshould be positively relevant to the empirical data \\(e\\). This is the\ncase also with the particular proposal \n\n\\[\n\\frac{P(h\\mid e) - P(h\\mid\\neg e)}{P(h\\mid e) + P(h\\mid\\neg e)}\n\\]\n\n defended by\nSchupbach and Sprenger (2011) as the unique measure which satisfies\nseven intuitively plausible adequacy conditions. \nRealist theories of scientific progress take truth to be an important\ngoal of inquiry. This view is built into the classical definition of\nknowledge as justified true belief: if science is a knowledge-seeking\nactivity, then it is also a truth-seeking activity. However, truth\ncannot be the only relevant epistemic utility of inquiry. This is\nshown in a clear way by cognitive decision theory (Levi 1967;\nNiiniluoto 1987). \nLet us denote by \\(B = \\{h_{1}, \\ldots ,h_{n}\\}\\) a set of mutually\nexclusive and jointly exhaustive hypotheses. Here the hypotheses in\n\\(B\\) may be the most informative descriptions of alternative states\nof affairs or possible worlds within a conceptual framework \\(L\\). For\nexample, they may be complete theories expressible in a finite\nfirst-order language. If \\(L\\) is interpreted on a domain \\(U\\), so\nthat each sentence of \\(L\\) has a truth value (true or false), it\nfollows that there is one and only one true hypothesis (say \\(h^*\\))\nin \\(B\\). Our cognitive problem is to identify the target\n\\(h^*\\) in \\(B\\). The elements \\(h_{i}\\) of \\(B\\) are the (potential)\ncomplete answers to the problem. The set \\(D(B)\\) of\npartial answers consists of all non-empty disjunctions of\ncomplete answers. The trivial partial answer in \\(D(B)\\),\ncorresponding to ‘I don’t know’, is represented by a\ntautology, i.e., the disjunction of all complete answers.  \nFor any \\(g\\) in \\(D(B)\\), we let \\(u(g, h_{j})\\) be the epistemic\nutility of accepting \\(g\\) if \\(h_{j}\\) is true. We also assume that a\nrational probability measure \\(P\\) is associated with language \\(L\\),\nso that each \\(h_{j}\\) can be assigned with its epistemic probability\n\\(P(h_{j}\\mid e)\\) given evidence \\(e\\). Then the best hypothesis in\n\\(D(B)\\) is the one \\(g\\) which maximizes the expected epistemic\nutility \nFor comparative purposes, we may say that one hypothesis is better\nthan another if it has a higher expected utility than the other by\nformula (1). \nIf truth is the only relevant epistemic utility, all true answers are\nequally good and all false answers are equally bad. Then we may take\n\\(u(g, h_{j})\\) simply to be the truth value of \\(g\\) relative to\n\\(h_{j}\\): \nHence, \\(u(g, h^*)\\) is the real truth value \\(tv(g)\\) of \\(g\\)\nrelative to the domain \\(U\\). It follows from (1) that the expected\nutility \\(U(g\\mid e)\\) equals the posterior probability \\(P(g\\mid e)\\)\nof \\(g\\) on \\(e\\). In this sense, we may say that posterior\nprobability equals expected truth value. The rule of maximizing\nexpected utility leads now to an extremely conservative policy: the\nbest hypotheses \\(g\\) on \\(e\\) are those that satisfy \\(P(g\\mid e) =\n1\\), i.e., are completely certain on \\(e\\) (e.g. \\(e\\) itself, logical\nconsequences of \\(e\\), and tautologies). On this account, if we are\nnot certain of the truth, then it is always progressive to change an\nuncertain answer to a logically weaker one. \nThe argument against using high probability as a criterion of theory\nchoice was made already by Popper in 1934 (see Popper 1959). He\nproposed that good theories should be bold or improbable. This idea\nhas been made precise in the theory of semantic information.  \nLevi (1967) measures the information content \\(I(g)\\) of a partial\nanswer \\(g\\) in \\(D(B)\\) by the number of complete answers it\nexcludes. With a suitable normalization, \\(I(g) = 1\\) if and only if\n\\(g\\) is one of the complete answers \\(h_{j}\\) in \\(B\\), and \\(I(g) =\n0\\) for a tautology. If we now choose \\(u(g, h_{j}) = I(g)\\), then\n\\(U(g\\mid e) = I(g)\\), so that all the complete answers in B have the\nsame maximal expected utility 1. This measure favors strong\nhypotheses, but it is unable to discriminate between the strongest\nones. For example, the step from a false complete answer to the true\none does not count as progress. Therefore, information cannot be the\nonly relevant epistemic utility. \nAnother measure of information content is \\(cont(g) = 1 - P(g)\\)\n(Hintikka 1968). If we choose \\(u(g, h_{j}) = cont(g)\\), then the\nexpected utility \\(U(g\\mid e) = 1 - P(g)\\) is maximized by a\ncontradiction, as the probability of a contradictory sentence is zero.\nAny false theory can be improved by adding new falsities to it. Again\nwe see that information content alone does not give a good definition\nof scientific progress. The same remark can be made about explanatory\nand systematic power. \nLevi’s (1967) proposal for epistemic utility is the weighted\ncombination of the truth value \\(tv(g)\\) of \\(g\\) and the information\ncontent \\(I(g)\\) of \\(g\\): \nwhere \\(0 \\lt a \\lt \\bfrac{1}{2}\\) is an “index of\nboldness,” indicating how much the scientist is willing to risk\nerror, or to “gamble with truth,” in her attempt to be\nrelieved from agnosticism. The expected epistemic utility of \\(g\\) is\nthen \nA comparative notion of progress ‘\\(g_{1}\\) is better than\n\\(g_{2}\\)’ could be defined by requiring that both \\(I(g_{1})\n\\gt I(g_{2})\\) and \\(P(g_{1}\\mid e) \\gt P(g_{2}\\mid e)\\), but most\nhypotheses would be incomparable by this requirement. By using the\nweight \\(a\\), formula (3) expresses a balance between two mutually\nconflicting goals of inquiry. It has the virtue that all partial\nanswers \\(g\\) in \\(D(B)\\) are comparable with each other: \\(g\\) is\nbetter than \\(g'\\) if and only if the value of (3) is larger for \\(g\\)\nthan for \\(g'\\).  \nIf epistemic utility is defined by information content cont(g) in a\ntruth-dependent way, so that  \n(i,e., in accepting hypothesis \\(g\\), we gain the content of \\(g\\) if\n\\(g\\) is true, but we lose the content of the true hypothesis \\(\\neg\ng\\) if \\(g\\) is false), then the expected utility \\(U(g\\mid e)\\) is\nequal to  \nThis measure combines the criteria of boldness (small prior\nprobability \\(P(g))\\) and high posterior probability \\(P(g\\mid e)\\).\nSimilar results can be obtained if \\(cont(g)\\) is replaced by\nHempel’s (1965) measure of systematic power \\(syst(g, e) =\nP(\\neg g\\mid \\neg e)\\). \nFor Levi, the best hypothesis in \\(D(B)\\) is the complete true answer.\nBut his utility assignment also makes assumptions that may seem\nproblematic: all false hypotheses (even those that make a very small\nerror) are worse than all truths (even the uninformative tautology);\nall false complete answers have the same utility (see, however, the\nmodified definition in Levi, 1980); among false hypotheses utility\ncovaries with logical strength (i.e. if \\(h\\) and \\(h'\\) are false and\n\\(h\\) entails \\(h'\\), then \\(h\\) has greater utility than \\(h')\\).\nThese features are motivated by Levi’s project of using\nepistemic utility as a basis of acceptance rules. But if such\nutilities are used for ordering rival theories, then the theory of\ntruthlikeness suggests other kinds of principles. \nPopper’s notion of truthlikeness is also a combination of truth\nand information (Popper 1963, 1972). For him, verisimilitude\nrepresents the idea of “approaching comprehensive truth.”\nPopper’s explication used the cumulative idea that the more\ntruthlike theory should have (in the sense of set-theoretical\ninclusion) more true consequences and less false consequences, but it\nturned out that this comparison is not applicable to pairs of false\ntheories. An alternative method of defining verisimilitude, initiated\nin 1974 by Pavel Tichy and Risto Hilpinen, relies essentially on the\nconcept of similarity.  \nIn the similarity approach, as developed in Niiniluoto (1987),\ncloseness to the truth is explicated “locally” by means of\nthe distances of partial answers \\(g\\) in \\(D(B)\\) to the target\n\\(h^*\\) in a cognitive problem \\(B\\). For this purpose, we need a\nfunction \\(d\\) which expresses the distance \\(d(h_{i}, h_{j}) =:\nd_{ij}\\) between two arbitrary elements of \\(B\\). By normalization, we\nmay choose \\(0 \\le d_{ij} \\le 1\\). The choice of \\(d\\) depends on the\ncognitive problem \\(B\\), and makes use of the metric structure of\n\\(B\\) (e.g., if \\(B\\) is a subspace of the real numbers \\(\\Re)\\) or\nthe syntactic similarity between the statements in \\(B\\). Then, for a\npartial answer \\(g\\), we let \\(D_{\\min}(h_{i}, g)\\) be the minimum\ndistance of the disjuncts in \\(g\\) from \\(h_{i}\\), and\n\\(D_{\\rmsum}(h_{i}, g)\\) the normalized sum of the distances of the\ndisjuncts of \\(g\\) from \\(h_{i}\\). Then \\(D_{\\min}(h_{i}, g)\\) tells\nhow close to \\(h_{i}\\) hypothesis \\(g\\) is, so that the degree of\napproximate truth of \\(g\\) (relative to the target \\(h^*\\))\nis \\(1 - D_{\\min}(h^*, g)\\). On the other hand, \\(D_{\\rmsum}(h_{i},\ng)\\) includes a penalty for all the mistakes that \\(g\\) allows\nrelative to \\(h_{i}\\). The min-sum measure  \nwhere \\(a \\gt 0\\) and \\(b \\gt 0\\), combines these two aspects. Then\nthe degree of truthlikeness of \\(g\\) is  \nThus, parameter \\(a\\) indicates our cognitive interest in hitting\nclose to the truth, and parameter \\(b\\) indicates our interest in\nexcluding falsities that are distant from the truth. In many\napplications, choosing \\(a\\) to be equal to \\(2b\\) gives intuitively\nreasonable results. \nIf the distance function \\(d\\) on \\(B\\) is trivial, i.e., \\(d_{ij} =\n1\\) if and only if \\(i = j\\), and otherwise 0, then \\(Tr(g, h^*)\\)\nreduces to the variant (2) of Levi’s definition of epistemic\nutility. \nObviously \\(Tr(g, h^*)\\) takes its maximum value 1 if and only if\n\\(g\\) is equivalent to \\(h^*\\). If \\(g\\) is a tautology, i.e., the\ndisjunction of all elements \\(h_{i}\\) of \\(B\\), then \\(Tr(g,h^*) = 1 -\nb\\). If \\(Tr(g, h^*) \\lt 1 - b\\), \\(g\\) is misleading in the strong\nsense that its cognitive value is smaller than that of complete\nignorance. \nOddie (1986) has continued to favor the average function instead of\nthe min-sum measure. An alternative account of truth approximation is\ngiven by Kuipers (2019). \nWhen \\(h^*\\) is unknown, the degree of truthlikeness (6) cannot be\ncalculated. But the expected degree of verisimilitude of a\npartial answer \\(g\\) given evidence \\(e\\) is given by \nIf evidence \\(e\\) entails some \\(h_{j}\\) in \\(B\\), or makes \\(h_{j}\\)\ncompletely certain (i.e., \\(P(h_{j}\\mid e) = 1)\\), then \\(ver(g\\mid\ne)\\) reduces to \\(Tr(g,h_{j})\\). If all the complete answers \\(h_{i}\\)\nin \\(B\\) are equally probable on \\(e\\), then \\(ver(h_{i}\\mid e)\\) is\nalso constant for all \\(h_{i}\\).  \nThe truthlikeness function \\(Tr\\) allows us to define an absolute\nconcept of real progress: \nand the expected truthlikeness function \\(ver\\) gives the relative\nconcept of estimated progress: \n(Cf. Niiniluoto 1980.) According to definition RP, it is meaningful to\nsay that one theory \\(g'\\) satisfies better the cognitive goal of\nanswering problem \\(B\\) than another theory \\(g\\). This is an absolute\nstandard of scientific progress in the sense of Section 2.5.\nDefinition EP shows how claims of progress can be fallibly evaluated\non the basis of evidence: if \\(ver(g\\mid e) \\lt ver(g'\\mid e)\\), it is\nrational to claim on evidence \\(e\\) that the step from \\(g\\) to \\(g'\\)\nin fact is progressive. This claim may of course be mistaken, since\nestimation of progress is relative to two factors: the available\nevidence \\(e\\) and the probability measure \\(P\\) employed in the\ndefinition of \\(ver\\). Both evidence \\(e\\) and the epistemic\nprobabilities \\(P(h_{i}\\mid e)\\) may mislead us. In this sense, the\nproblem of estimating verisimilitude is as difficult as the problem of\ninduction.  \nRowbottom (2015) argues against RP and EP that scientific progress is\npossible in the absence of increasing verisimilitude. He asks us to\nimagine that the scientists in a specific area of physics have found\nthe maximally truthlike theory C*. Yet this general true theory could\nbe used for further predictions and applications. This is indeed the\ncase if we do not make the idealized assumption that the scientists\nknow all the logical consequences of their theories. Then the\nexplanations and predictions from C* constitute new cognitive\nproblems. Moreover, in Rowbottom’s thought experiment further\nprogress is possible by expanding the conceptual framework in order to\nconsider as a target a deeper truth than C* (Niiniluoto 2017).  \nThe measure of expected truthlikeness can be used for retrospective\ncomparisons of past theories \\(g\\), if evidence \\(e\\) is taken to\ninclude our currently accepted theory \\(T\\), i.e., the truthlikeness\nof \\(g\\) is estimated by \\(ver(g\\mid e \\amp T)\\) (Niiniluoto, 1984,\n171). In the same spirit, Barrett (2008) has proposed\nthat—assuming that science makes progress toward the truth\nthrough the elimination of descriptive error—the “probable\napproximate truth” of Newtonian gravitation can be warranted by\nits “nesting relations” to the General Theory of\nRelativity. \nThe definition of progress by RP can be contrasted with the model of\nbelief revision (Gärdenfors, 1988). The simplest case of revision\nis expansion: a theory \\(T\\) is conjoined by an input statement \\(A\\),\nso that the new theory is \\(T \\amp A\\). According to the min-sum\nmeasure, if \\(T\\) and \\(A\\) are true, then the expansion \\(T \\amp A\\)\nis at least as truthlike as \\(T\\). But if \\(T\\) is false and \\(A\\) is\ntrue, then \\(T \\amp A\\) may be less truthlike than \\(T\\). For example,\nlet the false theory \\(T\\) state that the number of planets is 9 or\n20, and let \\(A\\) be the true sentence that this number is 8 or 20.\nThen \\(T \\amp A\\) states that the number of planets is 20, but this is\nclearly less truthlike than \\(T\\) itself. Similar examples show that\nthe AGM revision of a false theory by true input need not increase\ntruthlikeness (Niiniluoto 2011). \nBird (2007) has defended the epistemic definition of progress\n(accumulation of knowledge) against the semantic conception\n(accumulation of true beliefs or succession of theories with\nincreasing verisimilitude). Here knowledge is not defined as justified\ntrue belief, but still it is taken to entail truth and justification,\nso that Bird’s epistemic view in fact returns to the old\ncumulative model of progress. According to Bird, an accidentally true\nor truthlike belief reached by irrational methods without any\njustification does not constitute progress. This kind of thought\nexperiment may seem artificial, since there is always some sort of\njustification for any hypothetical theory which is accepted or at\nleast seriously considered by the scientific community. But\nBird’s argument raises the important question whether\njustification is merely instrumental for progress (Rowbottom, 2008) or\nnecessary for progress (Bird, 2008). Another interesting question is\nwhether the rejection of unfounded but accidentally true beliefs is\nregressive. The truthlikeness approach replies to these problems by\ndistinguishing real progress RP and estimated progress EP:\njustification is not constitutive of progress in the sense of RP, but\nclaims of real progress can be justified by appealing to expected\nverisimilitude (Cevolani and Tambolo, 2013). On the other hand, the\nnotion of progress explicated by EP (or by the combination of RP and\nEP) is relative to evidence and justification but at the same time\nnon-cumulative. \nBird (2015) can reformulate his initial example by assuming that an\naccidentally true or truthlike theory \\(H\\) has been obtained by\nscientific but yet unreliable means, perhaps by derivation from an\naccepted theory which turns out to be false. Does such application of\nmistaken reasoning constitute progress? The interplay of RP and EP\nallows several possibilities here. Later evidence might show that the\ninitial estimate \\(ver(H\\mid e)\\) was too high. Or the Tr-value was in\nfact high but initially the ver-value was low (e.g. Aristarchus on\nheliocentric system, Wegener on continental drift) and only later it\nwas increased by new evidence. \nMost accounts of truthlikeness satisfy the principle that among true\ntheories truthlikeness covaries with logical strength (for an\nexception, see Oddie, 1986). So accumulation of knowledge is a special\ncase of increasing verisimilitude, but it does not cover the case of\nprogress by successive false theories. In his attempt to rehabilitate\nthe cumulative knowledge model of scientific progress, Bird admits\nthat there are historical sequences of theories none of which are\n“fully true” (e.g. Ptolemy—Copernicus—Kepler\nor Galileo—Newton—Einstein). As knowledge entails truth,\nBird tries to save his epistemic account by reformulating past false\ntheories as true ones. He proposes that if \\(g\\) is approximately\ntrue, then the proposition “approximately \\(g\\)” is true,\nso that “the improving precision of approximations can be an\nobject of knowledge”. One problem with this treatment is that\nscientists typically formulate their theories as exact statements, and\nat the time of their proposal it is not known how large margins of\nerrors would be needed to transform them into true theories. With\nreference to Barrett (2008), Saatsi (2019) argues that the approximate\ntruth of Newtonian mechanics can be assessed only from the vantage\npoint of General Theory of Relativity, so that this knowledge was not\nepistemically accessible to Newton at his time. Further, many past\ntheories were radically false rather than approximately true or\ntruthlike, but still they could be improved by more truthlike\nsuccessors. Ptolemy’s geocentric theory was rejected in the\nCopernican revolution, not retained in the form “approximately\nPtolemy”. Indeed, the progressive steps from Ptolemy to\nCopernicus or from Newton to Einstein are not only matters of improved\nprecision but involve changes in theoretical postulates and laws. A\nfurther problem for Bird’s proposal is the question whether his\napproximation propositions are able to distinguish between progress\nand regress in science (Niiniluoto, 2014). \nDellsén (2016, 2018b) has formulated the noetic\naccount of scientific progress as increasing understanding. Using\nobjectual understanding instead of understanding-why, he characterizes\nunderstanding in terms of “grasping how to correctly explain and\npredict aspects of a given target”. Against Bird (2007), who\ntakes understanding to be a species of knowledge of causes,\nDellsén argues that understanding does not require the\nscientists to have justification for, or even belief in, the\nexplanations or predictions they propose. Still, understanding is a\nmatter of degree. Thus, there are increases in scientific\nunderstanding without accumulation of scientific knowledge (e.g.\nEinstein’s explanation of Brownian motion in terms of the\nkinetic theory of heat) and accumulation of scientific knowledge\nwithout increases in understanding (e.g. knowledge about random\nexperimental outcomes or spurious statistical correlations). The\nlatter thesis is easy to accept, especially if explanation needs laws,\nbut on the other hand the epistemic and truthlikeness approaches could\nagree that the collection of new important data may constitute\nscientific progress. The possibility of “quasi-factive”\nunderstanding by means of idealized theories (a common feature with\nthe verisimilitudinarian approach) is taken to be an advantage of the\nnoetic account. Park (2017) has challenged Dellsén’s\nconclusions against the epistemic definition. He argues that\nscientific understanding involves beliefs that the explained phenomena\nare real and the confirmed predictions are true. He also argues that\nWegener’s continental drift theory, which was not supported by\navailable evidence, was progressive, since it paved the way for the\nlater theory of plate tectonics in the 1960s. Dellsén (2018a)\nquestions Park’s arguments by rejecting the “means-end\nthesis”, i.e., one should make the crucial distinction between\ncognitive and non-cognitive scientific progress and likewise\ndistinguish episodes that constitute and promote\nscientific progress. \nIn Section 3.5., we made a distinction between real and estimated\nprogress in terms of the truthlikeness measures. A similar distinction\ncan be made in connection with measures of empirical success. For\nexample, one may distinguish two notions of the problem-solving\nability of a theory: the number of problems solved so far,\nand the number of solvable problems. Real progress could be\ndefined by the latter, while the former gives us an estimate of\nprogress. \nThe scientific realist may continue this line of thought by arguing\nthat all measures of empirical success in fact are at best indicators\nof real cognitive progress, measured in terms of truth or\ntruthlikeness. For example, if \\(T\\) explains \\(e\\), then it can be\nshown that \\(e\\) also confirms \\(T\\), or increases the\nprobability of \\(T\\) (Niiniluoto 1999b). A similar reasoning can be\nemployed to give the so-called “ultimate argument” or\n“no miracle argument”for scientific realism: theoretical\nrealism is the only assumption that does not make the empirical\nsuccess of science a miracle (Putnam, 1978; Psillos 1999; Niiniluoto\n2017; Kuipers 2019; cf. criticism in Laudan 1984b). This means that\nthe best explanation of the empirical progress of science is the\nhypothesis that science is also progressive on the level of\ntheories. \nThe thesis that science is progressive is an overall claim about\nscientific activities. It does not imply that each particular step in\nscience has in fact been progressive: individual scientists make\nmistakes, and even the scientific community is fallible in its\ncollective judgments. For this reason, we should not propose such a\ndefinition that the thesis about the progressive nature of science\nbecomes a tautology or an analytic truth. This undesirable consequence\nfollows if we define truth as the limit of scientific inquiry\n(this is sometimes called the consensus theory of truth), as then it\nis a mere tautology that the limit of scientific research is the truth\n(Laudan 1984a). But this “trivialization of the self-corrective\nthesis” cannot be attributed to Peirce who realized that truth\nand the limit of inquiry coincide at best with probability one\n(Niiniluoto 1980). The notion of truthlikeness allows us to make sense\nof the claim that science converges towards the truth. But the\ncharacterization of progress as increasing truthlikeness, given in\nSection 3.5, does not presuppose “teleological\nmetaphysics” (Stegmüller 1976), “convergent\nrealism” (Laudan 1984), or “scientific eschatology”\n(Moulines 2000), as it does not rely on any assumption about the\nfuture behavior of science. \nThe claim about scientific progress can still be questioned by the\ntheses that observations and ontologies are relative to theories. If\nthis is true, the comparison of rival theories appears to be\nimpossible on cognitive or rational grounds. Kuhn (1962) compared\nparadigm-changes to Gestalt switches (Dilworth 1981). Feyerabend\n(1984) concluded from his methodological anarchism that the\ndevelopment of science and art resemble each other. \nHanson, Popper, Kuhn, and Feyerabend agreed that all observation\nis theory-laden, so that there is no theory-neutral observational\nlanguage. Accounts of reduction and progress, which take for granted\nthe preservation of some observational statements within\ntheory-change, thus run into troubles. Even though Laudan’s\naccount of progress allows Kuhn-losses, it can be argued that the\ncomparison of the problem-solving capacity of two rival theories\npresupposes some kind of correlation or translation between the\nstatements of these theories (Pearce 1987). Various replies have been\nproposed to this issue. One is the movement from language to\nstructures (Stegmüller 1976; Moulines 2000), but it turns out\nthat a reduction on the level structures already guarantees\ncommensurability, since it induces a translation between conceptual\nframeworks (Pearce 1987). Another has been the point that an evidence\nstatement \\(e\\) may happen to be neutral with respect to rival\ntheories \\(T_{1}\\) and \\(T_{2}\\), even though it is laden with some\nother theories. The realist may also point that the theory-ladenness\nof observations concerns at most the estimation of progress (EP), but\nthe definition of real progress (RP) as increasing truthlikeness does\nnot mention the notion of observation at all. \nEven though Popper accepted the theory-ladenness of observations, he\nrejected the more general thesis about incommensurability as\n“the myth of the framework” (Lakatos and Musgrave 1970).\nPopper insisted that the growth of knowledge is always revolutionary\nin the sense that the new theory contradicts the old one by correcting\nit, but there is still continuity in theory-change, as the new theory\nshould explain why the old theory was successful to some extent.\nFeyerabend tried to claim that successive theories are both\ninconsistent and incommensurable with each other, but this combination\nmakes little sense. Kuhn argued against the possibility of finding\ncomplete translations between the languages of rival theories, but in\nhis later work he admitted the possibility that a scientist may learn\ndifferent theoretical languages (Hoyningen-Huene 1993). Kuhn kept\ninsisting that there is “no theory-independent way to\nreconstruct phrases like ‘really there’,” i.e., each\ntheory has its own ontology. Convergence to the truth seems to be\nimpossible, if ontologies change with theories. The same idea has been\nformulated by Putnam (1978) and Laudan (1984a) in the so-called\n“pessimistic meta-induction”: as many past theories in\nscience have turned out to be non-referring, there is all reason to\nexpect that even the future theories fail to refer—and thus also\nfail to be approximately true or truthlike. But the optimistic reply\nby comparative realists points out that for all rejected theories in\nLaudan’s list the scientists have been able to find a better,\nmore truthlike alternative (Niiniluoto 2017; Kuipers 2019). \nThe difficulties for realism seem to be reinforced by the observation\nthat measures of truthlikeness are relative to languages. The choice\nof conceptual frameworks cannot be decided by means of the notion of\ntruthlikeness, but needs additional criteria. In defense of the\ntruthlikeness approach, one may point to the fact that the comparison\nof two theories is relevant only in those cases where they are\nconsidered (perhaps via a suitable translation) as rival answers to\nthe same cognitive problem. It is interesting to compare\nNewton’s and Einstein’s theories for their truthlikeness,\nbut not Newton’s and Darwin’s theories. When definitions\nRP and EP are applied to rival theories in different languages, they\nhave to be translated into a common conceptual framework.  \nAnother line is to appeal to theories of reference in order to show\nthat rival theories can after all be regarded as speaking about the\nsame entities (Psillos 1999). For example, Thompson, Bohr, and later\nphysicists are talking about the same electrons, even though their\ntheories of the electron differ from each other. This is not possible\non the standard descriptive theory of reference: a theory \\(T\\) can\nonly refer to entities about which it gives a true description.\nKuhn’s and Feyerabend’s meaning holism, with devastating\nconsequences for realism, presupposes this account of reference. A\nsimilar argument is used by Moulines (2000), who denies that progress\ncould be understood as “knowing more about the same,” but\nhis own structuralist reconstruction of progress with “partial\nincommensurability” assumes that rival theories share some\nintended applications. Causal theories of reference allow that\nreference is preserved even within changes of theories (Kitcher 1993).\nThe same result is obtained if the descriptive account is modified by\nintroducing a Principle of Charity (Putnam 1975; Smith 1981;\nNiiniluoto 1999a): a theory refers to those entities about which it\ngives the most truthlike description. An alternative account,\nillustrated by the relation of phlogiston theory and oxygen theory, is\ngiven by Schurz (2011) by his notion of structural correspondence.\nThis makes it possible that even false theories are referring.\nMoreover, there can be reference invariance between two successive\ntheories, even though both of them are false; progress means then that\nthe latter theory gives a more truthlike description about their\ncommon domain than the old theory. ","contact.mail":"ilkka.niiniluoto@helsinki.fi","contact.domain":"helsinki.fi"}]
