[{"date.published":"2009-04-01","date.changed":"2017-08-21","url":"https://plato.stanford.edu/entries/modularity-mind/","author1":"Philip Robbins","author1.info":"http://philosophy.missouri.edu/index.php/people/15-/40-philip-robbins","entry":"modularity-mind","body.text":"\n\n\nThe concept of modularity has loomed large in philosophy of psychology\nsince the early 1980s, following the publication of Fodor’s\nlandmark book The Modularity of Mind (1983). In the decades\nsince the term ‘module’ and its cognates first entered the\nlexicon of cognitive science, the conceptual and theoretical landscape\nin this area has changed dramatically. Especially noteworthy in this\nrespect has been the development of evolutionary psychology, whose\nproponents adopt a less stringent conception of modularity than the\none advanced by Fodor, and who argue that the architecture of the mind\nis more pervasively modular than Fodor claimed. Where Fodor (1983,\n2000) draws the line of modularity at the relatively low-level systems\nunderlying perception and language, post-Fodorian theorists such as\nSperber (2002) and Carruthers (2006) contend that the mind is modular\nthrough and through, up to and including the high-level systems\nresponsible for reasoning, planning, decision making, and the like.\nThe concept of modularity has also figured in recent debates in\nphilosophy of science, epistemology, ethics, and philosophy of\nlanguage—further evidence of its utility as a tool for\ntheorizing about mental architecture.\n\nIn his classic introduction to modularity, Fodor (1983) lists nine\nfeatures that collectively characterize the type of system that\ninterests him. In original order of presentation, they are:  \nA cognitive system counts as modular in Fodor’s sense if it is\nmodular “to some interesting extent,” meaning that it has\nmost of these features to an appreciable degree (Fodor, 1983, p. 37).\nThis is a weighted most, since some marks of modularity are more\nimportant than others. Information encapsulation, for example, is more\nor less essential for modularity, as well as explanatorily prior to\nseveral of the other features on the list (Fodor, 1983, 2000).  \nEach of the items on the list calls for explication. To streamline the\nexposition, we will cluster most of the features thematically and\nexamine them on a cluster-by-cluster basis, along the lines of Prinz\n(2006). \nEncapsulation and inaccessibility. Informational\nencapsulation and limited central accessibility are two sides of the\nsame coin. Both features pertain to the character of information flow\nacross computational mechanisms, albeit in opposite directions.\nEncapsulation involves restriction on the flow of information into a\nmechanism, whereas inaccessibility involves restriction on the flow of\ninformation out of it. \nA cognitive system is informationally encapsulated to the extent that\nin the course of processing a given set of inputs it cannot access\ninformation stored elsewhere; all it has to go on is the information\ncontained in those inputs plus whatever information might be stored\nwithin the system itself, for example, in a proprietary database. In\nthe case of language, for example: \nSimilarly, in the case of perception—understood as a kind of\nnon-demonstrative (i.e., defeasible, or non-monotonic) inference from\nsensory ‘premises’ to perceptual\n‘conclusions’—the claim that perceptual systems are\ninformationally encapsulated is equivalent to the claim that\n“the data that can bear on the confirmation of perceptual\nhypotheses includes, in the general case, considerably less than the\norganism may know” (Fodor, 1983, p. 69). The classic\nillustration of this property comes from the study of visual\nillusions, which tend to persist even after the viewer is explicitly\ninformed about the character of the stimulus. In the Müller-Lyer\nillusion, for example, the two lines continue to look as if they were\nof unequal length even after one has convinced oneself otherwise,\ne.g., by measuring them with a ruler (see Figure 1, below).  Figure 1. The Müller-Lyer illusion. \nInformational encapsulation is related to what Pylyshyn (1984, 1999)\ncalls cognitive impenetrability. But the two properties are not the\nsame; instead, they are related as genus to species. Cognitive\nimpenetrability is a matter of encapsulation relative to information\nstored in central memory, paradigmatically in the form of beliefs and\nutilities. But a system could be encapsulated in this respect without\nbeing encapsulated across the board. For example, auditory speech\nperception might be encapsulated relative to beliefs and utilities but\nunencapsulated relative to vision, as suggested by the McGurk effect\n(see below, §2.1). Likewise, a system could be unencapsulated\nrelative to beliefs and utilities yet encapsulated relative to\nperception; it’s plausible that central systems have this\ncharacter, insofar as their operations are sensitive only to\npost-perceptual, propositionally encoded information. Strictly\nspeaking, then, cognitive impenetrability is a specific type of\ninformational encapsulation, albeit a type with special architectural\nsignificance. Lacking this feature means failing the encapsulation\ntest, the litmus test of modularity. But systems with this feature\nmight still fail the test, due to information seepage of a different\n(i.e., non-central) sort. \nThe flip side of informational encapsulation is inaccessibility to\ncentral monitoring. A system is inaccessible in this sense if the\nintermediate-level representations that it computes prior to producing\nits output are inaccessible to consciousness, and hence unavailable\nfor explicit report. In effect, centrally inaccessible systems are\nthose whose internal processing is opaque to introspection. Though the\noutputs of such systems may be phenomenologically salient, their\nprecursor states are not. Speech comprehension, for example, likely\ninvolves the successive elaboration of myriad representations (of\nvarious types: phonological, lexical, syntactic, etc.) of the\nstimulus, but of these only the final product—the representation\nof the meaning of what was said—is consciously available. \nMandatoriness, speed, and superficiality. In addition to\nbeing informationally encapsulated and centrally inaccessible, modular\nsystems and processes are “fast, cheap, and out of\ncontrol” (to borrow a phrase by roboticist Rodney Brooks). These\nfeatures form a natural trio, as we’ll see. \nThe operation of a cognitive system is mandatory just in case it is\nautomatic, that is, not under conscious control (Bargh &\nChartrand, 1999). This means that, like it or not, the system’s\noperations are switched on by presentation of the relevant stimuli and\nthose operations run to completion. For example, native speakers of\nEnglish cannot hear the sounds of English being spoken as mere noise:\nif they hear those sounds at all, they hear them as English. Likewise,\nit’s impossible to see a 3D array of objects in space as 2D\npatches of color, however hard one may try. \nSpeed is arguably the mark of modularity that requires least in the\nway of explication. But speed is relative, so the best way to proceed\nhere is by way of examples. Speech shadowing is generally considered\nto be very fast, with typical lag times on the order of about 250 ms.\nSince the syllabic rate of normal speech is about 4 syllables per\nsecond, this suggests that shadowers are processing the stimulus in\nsyllabus-length bits—probably the smallest bits that can be\nidentified in the speech stream, given that “only at the level\nof the syllable do we begin to find stretches of wave form whose\nacoustic properties are at all reliably related to their linguistic\nvalues” (Fodor, 1983, p. 62). Similarly impressive results are\navailable for vision: in a rapid serial visual presentation task\n(matching picture to description), subjects were 70% accurate at 125\nms. exposure per picture and 96% accurate at 167 ms. (Fodor, 1983, p.\n63). In general, a cognitive process counts as fast in Fodor’s\nbook if it takes place in a half second or less. \nA further feature of modular systems is that their outputs are\nrelatively ‘shallow’. Exactly what this means is unclear.\nBut the depth of an output seems to be a function of at least two\nproperties: first, how much computation is required to produce it\n(i.e., shallow means computationally cheap); second, how constrained\nor specific its informational content is (i.e., shallow means\ninformationally general) (Fodor, 1983, p. 87). These two properties\nare correlated, in that outputs with more specific content tend to be\nmore costly for a system to compute, and vice versa. Some writers have\ninterpreted shallowness to require non-conceptual character (e.g.,\nCarruthers, 2006, p. 4). But this conflicts with Fodor’s own\ngloss on the term, in which he suggests that the output of a plausibly\nmodular system such as visual object recognition might be encoded at\nthe level of ‘basic-level’ concepts, like DOG and CHAIR\n(Rosch et al., 1976). What’s ruled out here is not concepts\nper se, then, but highly theoretical concepts like PROTON,\nwhich are too informationally specific and too computationally\nexpensive to meet the shallowness criterion. \nAll three of the features just discussed—mandatoriness, speed,\nand shallowness—are associated with, and to some extent\nexplicable in terms of, informational encapsulation. In each case,\nless is more, informationally speaking. Mandatoriness flows from the\ninsensitivity of the system to the organism’s utilities, which\nis one dimension of cognitive impenetrability. Speed depends upon the\nefficiency of processing, which positively correlates with\nencapsulation in so far as encapsulation tends to reduce the\nsystem’s informational load. Shallowness is a similar story:\nshallow outputs are computationally cheap, and computational expense\nis negatively correlated with encapsulation. In short, the more\ninformationally encapsulated a system is, the more likely it is to be\nfast, cheap, and out of control. \nDissociability and localizability. To say that a system is\nfunctionally dissociable is to say that it can be selectively\nimpaired, that is, damaged or disabled with little or no effect on the\noperation of other systems. As the neuropsychological record\nindicates, selective impairments of this sort have frequently been\nobserved as a consequence of circumscribed brain lesions. Standard\nexamples from the study of vision include prosopagnosia (impaired face\nrecognition), achromatopsia (total color blindness), and akinetopsia\n(motion blindness); examples from the study of language include\nagrammatism (loss of complex syntax), jargon aphasia (loss of complex\nsemantics), alexia (loss of object words), and dyslexia (impaired\nreading and writing). Each of these disorders have been found in\notherwise cognitively normal individuals, suggesting that the lost\ncapacities are subserved by functionally dissociable mechanisms. \nFunctional dissociability is associated with neural localizability in\na strong sense. A system is strongly localized just in case it is (a)\nimplemented in neural circuitry that is both relatively circumscribed\nin extent (though not necessarily in contiguous areas) and (b)\ndedicated to the realization of that system alone. Localization in\nthis sense goes beyond mere implementation in local neural circuitry,\nsince a given bit of circuitry could subserve more than one cognitive\nfunction (Anderson, 2010). Proposed candidates for strong localization\ninclude systems for color vision (V4), motion detection (MT), face\nrecognition (fusiform gyrus), and spatial scene recognition\n(parahippocampal gyrus). \nDomain specificity. A system is domain specific to the extent\nthat it has a restricted subject matter, that is, the class of objects\nand properties that it processes information about is circumscribed in\na relatively narrow way. As Fodor (1983) puts it, “domain\nspecificity has to do with the range of questions for which a device\nprovides answers (the range of inputs for which it computes\nanalyses)” (p. 103): the narrower the range of inputs a system\ncan compute, the narrower the range of problems the system can\nsolve—and the narrower the range of such problems, the more\ndomain specific the device. Alternatively, the degree of a\nsystem’s domain specificity can be understood as a function of\nthe range of inputs that turn the system on, where the size of that\nrange determines the informational reach of the system (Carruthers,\n2006; Samuels, 2000). \nDomains (and by extension, modules) are typically more fine-grained\nthan sensory modalities like vision and audition. This seems clear\nfrom Fodor’s list of plausibly domain-specific mechanisms, which\nincludes systems for color perception, visual shape analysis, sentence\nparsing, and face and voice recognition (Fodor, 1983, p.\n47)—none of which correspond to perceptual or linguistic\nfaculties in an intuitive sense. It also seems plausible, however,\nthat the traditional sense modalities (vision, audition, olfaction,\netc.), and the language faculty as a whole, are sufficiently domain\nspecific to count as displaying this particular mark of modularity\n(McCauley & Henrich, 2006). \nInnateness. The final feature of modular systems on\nFodor’s roster is innateness, understood as the property of\n“develop[ing] according to specific, endogenously determined\npatterns under the impact of environmental releasers” (Fodor,\n1983, p. 100). On this view, modular systems come on-line chiefly as\nthe result of a brute-causal process like triggering, rather than an\nintentional-causal process like learning. (For more on this\ndistinction, see Cowie, 1999; for an alternative analysis of\ninnateness, based on the notion of canalization, see Ariew, 1999.) The\nmost familiar example here is language, the acquisition of which\noccurs in all normal individuals in all cultures on more or less the\nsame schedule: single words at 12 months, telegraphic speech at 18\nmonths, complex grammar at 24 months, and so on (Stromswold, 1999).\nOther candidates include visual object perception (Spelke, 1994) and\nlow-level mindreading (Scholl & Leslie, 1999). \nThe hypothesis of modest modularity, as we shall call it, has two\nstrands. The first strand of the hypothesis is positive. It says that\ninput systems, such as systems involved in perception and language,\nare modular. The second strand is negative. It says that central\nsystems, such as systems involved in belief fixation and practical\nreasoning, are not modular.  \nIn this section, we assess the case for modest modularity. The next\nsection (§3) will be devoted to discussion of the hypothesis of\nmassive modularity, which retains the positive strand of Fodor’s\nhypothesis while reversing the polarity of the second strand from\nnegative to positive—revising the concept of modularity in the\nprocess. \nThe positive part of the modest modularity hypothesis is that input\nsystems are modular. By ‘input system’ Fodor (1983) means\na computational mechanism that “presents the world to\nthought” (p. 40) by processing the outputs of sensory\ntransducers. A sensory transducer is a device that converts the energy\nimpinging on the body’s sensory surfaces, such as the retina and\ncochlea, into a computationally usable form, without adding or\nsubtracting information. Roughly speaking, the product of sensory\ntransduction is raw sensory data. Input processing involves\nnon-demonstrative inferences from this raw data to hypotheses about\nthe layout of objects in the world. These hypotheses are then passed\non to central systems for the purpose of belief fixation, and those\nsystems in turn pass their outputs to systems responsible for the\nproduction of behavior. \nFodor argues that input systems constitute a natural kind, defined as\n“a class of phenomena that have many scientifically interesting\nproperties over and above whatever properties define the class”\n(Fodor, 1983, p. 46). He argues for this by presenting evidence that\ninput systems are modular, where modularity is marked by a cluster of\npsychologically interesting properties—the most interesting and\nimportant of these being informational encapsulation, as discussed in\n§1. In the course of that discussion, we reviewed a\nrepresentative sample of this evidence, and for present purposes that\nshould suffice. (Readers interested in further details should consult\nFodor, 1983, pp. 47–101.) \nFodor’s claim about the modularity of input systems has been\ndisputed by a number of philosophers and psychologists (Churchland,\n1988; Arbib, 1987; Marslen-Wilson & Tyler, 1987; McCauley &\nHenrich, 2006). The most wide-ranging philosophical critique is due to\nPrinz (2006), who argues that perceptual and linguistic systems rarely\nexhibit the features characteristic of modularity. In particular, he\nargues that such systems are not informationally encapsulated. To this\nend, Prinz adduces two types of evidence. First, there appear to be\ncross-modal effects in perception, which would tell against\nencapsulation at the level of input systems. The classic example of\nthis, also from the speech perception literature, is the McGurk effect\n(McGurk & MacDonald, 1976). Here, subjects watching a video of one\nphoneme being spoken (e.g., /ga/) dubbed with a sound recording of a\ndifferent phoneme (/ba/) hear a third, altogether different phoneme\n(/da/). Second, he points to what look to be top-down effects on\nvisual and linguistic processing, the existence of which would tell\nagainst cognitive impenetrability, i.e., encapsulation relative to\ncentral systems. Some of the most striking examples of such effects\ncome from research on speech perception. Probably the best-known is\nthe phoneme restoration effect, as in the case where listeners\n‘fill in’ a missing phoneme in a spoken sentence (The\nstate governors met with their respective legi*latures convening in\nthe capital city) from which the missing phoneme (the /s/ sound\nin legislatures) has been deleted and replaced with the sound\nof a cough (Warren, 1970). By hypothesis, this filling-in is driven by\nlisteners’ understanding of the linguistic context.  \nHow convincing one finds this part of Prinz’s critique, however,\ndepends on how convincing one finds his explanation of these effects.\nThe McGurk effect, for example, seems consistent with the claim that\nspeech perception is an informationally encapsulated system, albeit a\nsystem that is multi-modal in character (cf. Fodor, 1983, p.132n.13).\nIf speech perception is a multi-modal system, the fact that its\noperations draw on both auditory and visual information need not\nundermine the claim that speech perception is encapsulated. Other\ncross-modal effects, however, resist this type of explanation. In the\ndouble flash illusion, for example, viewers shown a single flash\naccompanied by two beeps report seeing two flashes (Shams et al.,\n2000). The same goes for the rubber hand illusion, in which\nsynchronous brushing of a hand hidden from view and a\nrealistic-looking rubber hand seen at the usual location of the hand\nthat was hidden gives rise to the impression that the fake hand is\nreal (Botvinick & Cohen, 1998). With respect to phenomena of this\nsort, unlike the McGurk effect, there is no plausible candidate for a\nsingle, domain-specific system whose operations draw on multiple\nsources of sensory information. \nRegarding phoneme restoration, it could be that the effect is driven\nby listeners’ drawing on information stored in a\nlanguage-proprietary database (specifically, information about the\nlinguistic types in the lexicon of English), rather than higher-level\ncontextual information. Hence, it’s unclear whether the case of\nphoneme restoration described above counts as a top-down effect. But\nnot all cases of phoneme restoration can be accommodated so readily,\nsince the phenomenon also occurs when there are multiple lexical items\navailable for filling in (Warren & Warren, 1970). For example,\nlisteners fill the gap in the sentences The *eel is on the\naxle and The *eel is on the orange\ndifferently—with a /wh/ sound and a /p/ sound,\nrespectively—suggesting that speech perception is sensitive to\ncontextual information after all. \nA further challenge to modest modularity, not addressed by Prinz\n(2006), comes from evidence that susceptibility to the\nMüller-Lyer illusion varies by both culture and age. For example,\nit appears that adults in Western cultures are more susceptible to the\nillusion than their non-Western counterparts; that adults in some\nnon-Western cultures, such as hunter-gatherers from the Kalahari\nDesert, are nearly immune to the illusion; and that within (but not\nalways across) Western and non-Western cultures, pre-adolescent\nchildren are more susceptible to the illusion than adults are (Segall,\nCampbell, & Herskovits, 1966). McCawley and Henrich (2006) take\nthese findings as showing that the visual system is diachronically (as\nopposed to synchronically) penetrable, in that how one experiences the\nillusion-inducing stimulus changes as a result of one’s wider\nperceptual experience over an extended period of time. They also argue\nthat the aforementioned evidence of cultural and developmental\nvariability in perception militates against the idea that vision is an\ninnate capacity, that is, the idea that vision is among the\n“endogenous features of the human cognitive system that are, if\nnot largely fixed at birth, then, at least, genetically\npre-programmed” and “triggered, rather than shaped, by the\nnewborn’s subsequent experience” (p. 83). However, they\nalso issue the following caveat: \nAs such, the evidence cited can be accommodated by friends of modest\nmodularity, provided that allowance is made for the potential impact\nof environmental, including cultural, variables on\ndevelopment—something that most accounts of innateness make room\nfor. \nA useful way of making this point invokes Segal’s (1996) idea of\ndiachronic modularity (see also Scholl & Leslie, 1999). Diachronic\nmodules are systems that exhibit parametric variation over the course\nof their development. For example, in the case of language, different\nindividuals learn to speak different languages depending on the\nlinguistic environment in which they grew up, but they nonetheless\nshare the same underlying linguistic competence in virtue of their\n(plausibly innate) knowledge of Universal Grammar. Given the observed\nvariation in how people see the Müller-Lyer illusion, it may be\nthat the visual system is modular in much the same way, with its\ndevelopment is constrained by features of the visual environment. Such\na possibility seems consistent with the claim that input systems are\nmodular in Fodor’s sense. \nAnother source of difficulty for proponents of input-level modularity\nis neuroscientific evidence against the claim that perceptual and\nlinguistic systems are strongly localized. Recall that for a system to\nbe strongly localized, it must be realized in dedicated neural\ncircuitry. Strong localization at the level of input systems, then,\nentails the existence of a one-to-one mapping between input systems\nand brain structures. As Anderson (2010, 2014) argues, however, there\nis no such mapping, since most cortical regions of any size are\ndeployed in different tasks across different domains. For instance,\nactivation of the fusiform face area, once thought to be dedicated to\nthe perception of faces, is also recruited for the perception of cars\nand birds (Gauthier et al., 2000). Likewise, Broca’s area, once\nthought to be dedicated to speech production, also plays a role in\naction recognition, action sequencing, and motor imagery (Tettamanti\n& Weniger, 2006). Functional neuroimaging studies generally\nsuggest that cognitive systems are at best weakly localized, that is,\nimplemented in distributed networks of the brain that overlap, rather\nthan discrete and disjoint regions. \nArguably the most serious challenge to modularity at the level of\ninput systems, however, comes from evidence that vision is cognitively\npenetrable, and hence, not informationally encapsulated. The concept\nof cognitive penetrability, originally introduced by Pylyshyn (1984),\nhas been characterized in a variety of non-equivalent ways (Stokes,\n2013), but the core idea is this: A perceptual system is cognitively\npenetrable if and only if its operations are directly causally\nsensitive to the agent’s beliefs, desires, intentions, or other\nnonperceptual states. Behavioral studies purporting to show that\nvision is cognitively penetrable date back to the early days of New\nLook psychology (Bruner and Goodman, 1947) and continue to the present\nday, with renewed interest in the topic emerging in the early 2000s\n(Firestone & Scholl, 2016). It appears, for example, that vision\nis influenced by an agent’s motivational states, with\nexperimental subjects reporting that desirable objects look closer\n(Balcetis & Dunning, 2010) and ambiguous figures look like the\ninterpretation associated with a more rewarding outcome (Balcetis\n& Dunning, 2006). In addition, vision seems to be influenced by\nsubjects’ beliefs, with racial categorization affecting reports\nof the perceived skin tone of faces even when the stimuli are\nequiluminant (Levin & Banaji, 2006), and categorization of objects\naffecting reports of the perceived color of grayscale images of those\nobjects (Hansen et al., 2006).  \nSkeptics of cognitive penetrability point out, however, that\nexperimental evidence for top-down effects on perception can be\nexplained in terms of effects of judgment, memory, and relatively\nperipheral forms of attention (Firestone & Scholl, 2016; Machery,\n2015). Consider, for example, the claim that throwing a heavy ball\n(vs. a light ball) at a target makes the target look farther away,\nevidence for which consists of subjects’ visual estimates of the\ndistance to the target (Witt, Proffitt, & Epstein, 2004). While it\nis possible that the greater effort involved in throwing the heavy\nball caused the target to look farther away, it is also possible that\nthe increased estimate of distance reflected the fact that subjects in\nthe heavy ball condition judged the target to be farther away because\nthey found it harder to hit (Firestone & Scholl, 2016). Indeed,\nreports by subjects in a follow-up study who were explicitly\ninstructed to make their estimates on the basis of visual appearances\nonly did not show the effect of effort, suggesting that the effect was\npost-perceptual (Woods, Philbeck, & Danoff, 2009). Other purported\ntop-down effects on perception, such as the effect of golfing\nperformance on size and distance estimates of golf holes (Witt et al.,\n2008), can be explained as effects of spatial attention, such as the\nfact that visually attended objects tend to appear larger and closer\n(Firestone & Scholl, 2016). These and related considerations\nsuggest that the case for cognitive penetrability—and by\nextension, the case against low-level modularity—is weaker than\nits proponents make it out to be.  \nI turn now to the dark side of Fodor’s hypothesis: the claim\nthat central systems are not modular. \nAmong the principal jobs of central systems is the fixation of belief,\nperceptual belief included, via non-demonstrative inference. Fodor\n(1983) argues that this sort of process cannot be realized in an\ninformationally encapsulated system, and hence that central systems\ncannot be modular. Spelled out a bit further, his reasoning goes like\nthis: Hence: \nThe argument here contains two terms that call for explication, both\nof which relate to the notion of confirmation holism in the philosophy\nof science. The term ‘isotropic’ refers to the epistemic\ninterconnectedness of beliefs in the sense that “everything that\nthe scientist knows is, in principle, relevant to determining what\nelse he ought to believe. In principle, our botany constrains our\nastronomy, if only we could think of ways to make them connect”\n(Fodor, 1983, p. 105). Antony (2003) presents a striking case of this\nsort of long-range interdisciplinary cross-talk in the sciences,\nbetween astronomy and archaeology; Carruthers (2006, pp.\n356–357) furnishes another example, linking solar physics and\nevolutionary theory. On Fodor’s view, since scientific\nconfirmation is akin to belief fixation, the fact that scientific\nconfirmation is isotropic suggests that belief fixation in general has\nthis property.  \nA second dimension of confirmation holism is that confirmation is\n‘Quinean’, meaning that: \nHere again, the analogy between scientific thinking and thinking in\ngeneral underwrites the supposition that belief fixation is Quinean.\n \nBoth isotropy and Quineanness are features that preclude\nencapsulation, since their possession by a system would require\nextensive access to the contents of central memory, and hence a high\ndegree of cognitive penetrability. Put in slightly different terms:\nisotropic and Quinean processes are ‘global’ rather than\n‘local’, and since globality precludes encapsulation,\nisotropy and Quineanness preclude encapsulation as well.  \nBy Fodor’s lights, the upshot of this argument—namely, the\nnonmodular character of central systems—is bad news for the\nscientific study of higher cognitive functions. This is neatly\nexpressed by his “First Law of the Non-Existence of Cognitive\nScience,” according to which “[t]he more global (e.g., the\nmore isotropic) a cognitive process is, the less anybody understands\nit” (Fodor, 1983, p. 107). His grounds for pessimism on this\nscore are twofold. First, global systems are unlikely to be associated\nwith local brain architecture, thereby rendering them unpromising\nobjects of neuroscientific study: \nSecond, and more importantly, global processes are resistant to\ncomputational explanation, making them unpromising objects of\npsychological study: \nBy Fodor’s lights, then, considerations that militate against\nhigh-level modularity also militate against the possibility of a\nrobust science of higher cognition—not a happy result, as far as\nmost cognitive scientists and philosophers of mind are concerned. \nGloomy implications aside, Fodor’s argument against high-level\nmodularity is difficult to resist. The main sticking points are these:\nfirst, the negative correlation between globality and encapsulation;\nsecond, the positive correlation between encapsulation and modularity.\nPutting these points together, we get a negative correlation between\nglobality and modularity: the more global the process, the less\nmodular the system that executes it. As such, there seem to be only\nthree ways to block the conclusion of the argument: \nOf these three options, the second seems least attractive, as it seems\nsomething like a conceptual truth that globality and encapsulation\npull in opposite directions. The first option is slightly more\nappealing, but only slightly. The idea that central processes are\nrelatively global, even if not as global as the process of\nconfirmation in science suggests, is hard to deny. And that is all the\nargument really requires.  \nThat leaves the third option: denying that modularity requires\nencapsulation. This is, in effect, the strategy pursued by Carruthers\n(2006). More specifically, Carruthers draws a distinction between two\nkinds of encapsulation: ‘narrow-scope’ and\n‘wide-scope’. A system is narrow-scope encapsulated if it\ncannot draw on any information held outside of it in the course\nof its processing. This corresponds to encapsulation as Fodor uses the\nterm. By contrast, a system that is wide-scope encapsulated can draw\non exogenous information during the course of its operations—it\njust cannot draw on all of that information. (Compare:\n“No exogenous information is accessible” vs. “Some\nexogenous information is not accessible.”) This is encapsulation\nin a weaker sense of the term than Fodor’s. Indeed,\nCarruthers’s use of the term ‘encapsulation’ in this\ncontext is a bit misleading, insofar as wide-scope encapsulated\nsystems count as unencapsulated in Fodor’s sense (Prinz,\n2006). \nDropping the (narrow-scope) encapsulation requirement on modules\nraises a number of issues, not the least of which being that it\nreduces the power of modularity hypotheses to explain functional\ndissociations at the system level (Stokes & Bergeron, 2015). That\nsaid, if modularity requires only wide-scope encapsulation, then\nFodor’s argument against central modularity no longer goes\nthrough. But given the importance of narrow-scope encapsulation to\nFodorian modularity, all this shows is that central systems might be\nmodular in a non-Fodorian way. The original argument that central\nsystems are not Fodor-modular—and with it, the motivation for\nthe negative strand of the modest modularity\nhypothesis—stands. \nAccording to the massive modularity hypothesis, the mind is modular\nthrough and through, including the parts responsible for high-level\ncognition functions like belief fixation, problem-solving, planning,\nand the like. Originally articulated and advocated by proponents of\nevolutionary psychology (Sperber, 1994, 2002; Cosmides & Tooby,\n1992; Pinker, 1997; Barrett, 2005; Barrett & Kurzban, 2006), the\nhypothesis has received its most comprehensive and sophisticated\ndefense at the hands of Carruthers (2006). Before proceeding to the\ndetails of that defense, however, we need to consider briefly what\nconcept of modularity is in play.  \nThe main thing to note here is that the operative notion of modularity\ndiffers significantly from the traditional Fodorian one. Carruthers is\nexplicit on this point: \nOf the original set of nine features associated with Fodor-modules,\nthen, Carruthers-modules retain at most only five: dissociability,\ndomain specificity, automaticity, neural localizability, and central\ninaccessibility. Conspicuously absent from the list is informational\nencapsulation, the feature most central to modularity in Fodor’s\naccount. What’s more, Carruthers goes on to drop domain\nspecificity, automaticity, and strong localizability (which rules out\nthe sharing of parts between modules) from his initial list of five\nfeatures, making his conception of modularity even more sparse\n(Carruthers, 2006, p. 62). Other proposals in the literature are\nsimilarly permissive in terms of the requirements a system must meet\nin order to count as modular (Coltheart, 1999; Barrett & Kurzban,\n2006).  \nA second point, related to the first, is that defenders of massive\nmodularity have chiefly been concerned to defend the modularity of\ncentral cognition, taking for granted that the mind is modular at the\nlevel of input systems. Thus, the hypothesis at issue for theorists\nlike Carruthers might be best understood as the conjunction of two\nclaims: first, that input systems are modular in a way that requires\nnarrow-scope encapsulation; second, that central systems are modular,\nbut only in a way that does not require this feature. In defending\nmassive modularity, Carruthers focuses on the second of these claims,\nand so will we. \nThe centerpiece of Carruthers (2006) consists of three arguments for\nmassive modularity: the Argument from Design, the Argument from\nAnimals, and the Argument from Computational Tractability. Let’s\nbriefly consider each of them in turn. \nThe Argument from Design is as follows: \nThe crux of this argument is the idea that complex biological systems\ncannot evolve unless they are organized in a modular way, where\nmodular organization entails that each component of the system (that\nis, each module) can be selected for change independently of the\nothers. In other words, the evolvability of the system as a whole\nrequires the independent evolvability of its parts. The problem with\nthis assumption is twofold (Woodward & Cowie, 2004). First, not\nall biological traits are independently modifiable. Having two lungs,\nfor example, is a trait that cannot be changed without changing other\ntraits of an organism, because the genetic and developmental\nmechanisms underlying lung numerosity causally depend on the genetic\nand developmental mechanisms underlying bilateral symmetry. Second,\nthere appear to be developmental constraints on neurogenesis which\nrule out changing the size of one brain area independently of the\nothers. This in turn suggests that natural selection cannot modify\ncognitive traits in isolation from one another, given that evolving\nthe neural circuitry for one cognitive trait is likely to result in\nchanges to the neural circuitry for other traits.  \nA further worry about the Argument from Design concerns the gap\nbetween its conclusion (the claim that the mind is massively modular\nin organization) and the hypothesis at issue (the claim that\nthe mind is massively modular simpliciter). The worry is this.\nAccording to Carruthers, the modularity of a system implies the\npossession of just two properties: functional dissociability and\ninaccessibility of processing to external monitoring. Suppose that a\nsystem is massively modular in organization. It follows from the\ndefinition of modular organization that the components of the system\nare functionally autonomous and separately modifiable. Though\nfunctional autonomy guarantees dissociability, it’s not clear\nwhy separate modifiability guarantees inaccessibility to external\nmonitoring. According to Carruthers, the reason is that “if the\ninternal operations of a system (e.g., the details of the algorithm\nbeing executed) were available elsewhere, then they couldn’t be\naltered without some corresponding alteration being made in the system\nto which they are accessible” (Carruthers, 2006, p. 61). But\nthis is a questionable assumption. On the contrary, it seems plausible\nthat the internal operations of one system could be accessible to a\nsecond system in virtue of a monitoring mechanism that functions the\nsame way regardless of the details of the processing being monitored.\nAt a minimum, the claim that separate modifiability entails\ninaccessibility to external monitoring calls for more justification than\nCarruthers offers.  \nIn short, the Argument from Design is susceptible to a number of\nobjections. Fortunately, there’s a slightly stronger argument in\nthe vicinity of this one, due to Cosmides and Tooby (1992). It goes\nlike this:  \nThe force of this argument depends chiefly on the strength of the\nthird premise. Not everyone is convinced, to put it mildly (Fodor,\n2000; Samuels, 2000; Woodward & Cowie, 2004). First, the premise\nexemplifies adaptationist reasoning, and adaptationism in the\nphilosophy of biology has more than its share of critics. Second, it\nis doubtful whether adaptive problem-solving in general is easier to\naccomplish with a large collection of specialized problem-solving\ndevices than with a smaller collection of general problem-solving\ndevices with access to a library of specialized programs (Samuels,\n2000). Hence, insofar as the massive modularity hypothesis postulates\nan architecture of the first sort—as evolutionary\npsychologists’ ‘Swiss Army knife’ metaphor of the\nmind implies (Cosmides & Tooby, 1992)—the premise seems\nshaky.  \nA related argument is the Argument from Animals. Unlike the Argument\nfrom Design, this argument is never explicitly stated in Carruthers\n(2006). But here is a plausible reconstruction of it, due to Wilson\n(2008): \nUnfortunately for friends of massive modularity, this argument, like\nthe argument from design, is vulnerable to a number of objections\n(Wilson, 2008). We’ll mention two of them here. First,\nit’s not easy to motivate the claim that animal minds are\nmassively modular in the operative sense. Though\nCarruthers (2006) goes to heroic lengths to do so, the evidence he\ncites—e.g., for the domain specificity of animal learning\nmechanisms, à la Gallistel, 1990—adds up to less than\nwhat’s needed. The problem is that domain specificity is not sufficient for Carruthers-style modularity; indeed, it is not even one of the central characteristics of modularity in Carruthers’ account. So the argument falters at the first step. Second, even if animal minds are\nmassively modular, and even if single incremental extensions of the\nanimal mind preserve that feature, it’s quite possible that a\nseries of such extensions of animal minds might have led to its loss.\nIn other words, as Wilson (2008) puts it, it can’t be assumed\nthat the conservation of massive modularity is transitive. And without\nthis assumption, the argument from animals can’t go through. \nFinally, we have the Argument from Computational Tractability\n(Carruthers, 2006, pp. 44–59). For the purposes of this\nargument, we assume that a mental process is computationally tractable\nif it can be specified at the algorithmic level in such a way that the\nexecution of the process is feasible given time, energy, and other\nresource constraints on human cognition (Samuels, 2005). We also\nassume that a system is encapsulated if in the course of its\noperations the system lacks access to at least some information\nexogenous to it. \nThere are two problems with this argument, however. The first problem\nhas to do with the third premise, which states that tractability\nrequires encapsulation, that is, the inaccessibility of at least some\nexogenous information to processing. What tractability actually\nrequires is something weaker, namely, that not all information is\naccessed by the mechanism in the course of its operations (Samuels,\n2005). In other words, it is possible for a system to have unlimited\naccess to a database without actually accessing all of its contents.\nThough tractable computation rules out exhaustive search, for example,\nunencapsulated mechanisms need not engage in exhaustive search, so\ntractability does not require encapsulation. The second problem with\nthe argument concerns the last step. Though one might reasonably\nsuppose that modular systems must be encapsulated, the converse\ndoesn’t follow. Indeed, Carruthers (2006) makes no mention of\nencapsulation in his characterization of modularity, so it’s\nunclear how one is supposed to get from a claim about pervasive\nencapsulation to a claim about pervasive modularity.  \nAll in all, then, compelling general arguments for massive modularity\nare hard to come by. This is not yet to dismiss the possibility of\nmodularity in high-level cognition, but it invites skepticism,\nespecially given the paucity of empirical evidence directly supporting\nthe hypothesis (Robbins, 2013). For example, it has been suggested\nthat the capacity to think about social exchanges is subserved by a\ndomain-specific, functionally dissociable, and innate mechanism (Stone\net al., 2002; Sugiyama et al., 2002). However, it appears that\ndeficits in social exchange reasoning do not occur in isolation, but\nare accompanied by other social-cognitive impairments (Prinz, 2006).\nSkepticism about modularity in other areas of central cognition, such\nas high-level mindreading, also seems to be the order of the day\n(Currie & Sterelny, 2000). The type of mindreading impairments\ncharacteristic of Asperger syndrome and high-functioning autism, for\nexample, co-occur with sensory processing and executive function\ndeficits (Frith, 2003). In general, there is little in the way of\nneuropsychological evidence to support the idea of high-level\nmodularity.  \nJust as there are general theoretical arguments for massive\nmodularity, there are general theoretical arguments against it. One\nargument takes the form of what Fodor (2000) calls the ‘Input\nProblem’. The problem is this. Suppose that the architecture of\nthe mind is modular from top to bottom, and the mind consists entirely\nof domain-specific mechanisms. In that case, the outputs of each\nlow-level (input) system will need to be routed to the appropriately\nspecialized high-level (central) system for processing. But that\nrouting can only be accomplished by a domain-general, non-modular\nmechanism—contradicting the initial supposition. In response to\nthis problem, Barrett (2005) argues that processing in a massively\nmodular architecture does not require a domain-general routing device\nof the sort envisaged by Fodor. An alternative solution, Barrett\nsuggests, involves what he calls ‘enzymatic computation’.\nIn this model, low-level systems pool their outputs together in a\ncentrally accessible workspace where each central system is\nselectively activated by outputs that match its domain, in much the\nsame way that enzymes selectively bind with substrates that match\ntheir specific templates. Like enzymes, specialized computational\ndevices at the central level of the architecture accept a restricted\nrange of inputs (analogous to biochemical substrates), perform\nspecialized operations on that input (analogous to biochemical\nreactions), and produce outputs in a format useable by other\ncomputational devices (analogous to biochemical products). This\nobviates the need for a domain-general (hence,\nnon-modular) mechanism to mediate between low-level and high-level\nsystems.  \nA second challenge to massive modularity is posed by the ‘Domain\nIntegration Problem’ (Carruthers, 2006). The problem here is\nthat reasoning, planning, decision making, and other types of\nhigh-level cognition routinely involve the production of conceptually\nstructured representations whose content crosses domains. This means\nthat there must be some mechanism for integrating representations from\nmultiple domains. But such a mechanism would be domain general rather\nthan domain specific, and hence, non-modular. Like the Input Problem,\nhowever, the Domain Integration Problem is not insurmountable. One\npossible solution is that the language system has the capacity to play\nthe role of content integrator in virtue of its capacity to transform\nconceptual representations that have been linguistically encoded\n(Hermer & Spelke, 1996; Carruthers, 2002, 2006). On this view,\nlanguage is the vehicle of domain-general thought.  \nEmpirical objections to massive modularity take a variety of forms. To\nstart with, there is neurobiological evidence of developmental\nplasticity, a phenomenon that tells against the idea that brain\nstructure is innately specified (Buller, 2005; Buller and Hardcastle,\n2000). However, not all proponents of massive modularity insist that\nmodules are innately specified (Carruthers, 2006; Kurzban, Tooby, and\nCosmides, 2001). Furthermore, it’s unclear to what extent the\nneurobiological record is at odds with nativism, given the evidence\nthat specific genes are linked to the normal development of cortical\nstructures in both humans and animals (Machery & Barrett, 2008;\nRamus, 2006).  \nAnother source of evidence against massive modularity comes from\nresearch on individual differences in high-level cognition (Rabaglia,\nMarcus, & Lane, 2011). Such differences tend to be strongly\npositively correlated across domains—a phenomenon known as the\n‘positive manifold’—suggesting that high-level\ncognitive abilities are subserved by a domain-general mechanism,\nrather than by a suite of specialized modules. There is, however, an\nalternative explanation of the positive manifold. Since post-Fodorian\nmodules are allowed to share parts (Carruthers, 2006), the\ncorrelations observed may stem from individual differences in the\nfunctioning of components spanning multiple domain-specific\nmechanisms.  \nInterest in modularity is not confined to cognitive science and the\nphilosophy of mind; it extends well into a number of allied fields. In\nepistemology, modularity has been invoked to defend the legitimacy of\na theory-neutral type of observation, and hence the possibility of\nsome degree of consensus among scientists with divergent theoretical\ncommitments (Fodor, 1984). The ensuing debate on this issue\n(Churchland, 1988; Fodor, 1988; McCauley & Henrich, 2006) holds\nlasting significance for the general philosophy of science,\nparticularly for controversies regarding the status of scientific\nrealism. Relatedly, evidence of the cognitive penetrability of\nperception has given rise to worries about the justification of\nperceptual beliefs (Siegel, 2012; Stokes, 2012). In ethics, evidence\nof this sort has been used to cast doubt on ethical intuitionism as an\naccount of moral epistemology (Cowan, 2014). In philosophy of\nlanguage, modularity has figured in theorizing about linguistic\ncommunication, for example, in relevance theorists’ suggestion\nthat speech interpretation, pragmatic warts and all, is a modular\nprocess (Sperber & Wilson, 2002). It has also been used demarcate\nthe boundary between semantics and pragmatics, and to defend a notably\naustere version of semantic minimalism (Borg, 2004). Though the\nsuccess of these deployments of modularity theory is subject to\ndispute (e.g., see Robbins, 2007, for doubts about the modularity of\nsemantics), their existence testifies to the relevance of the concept\nof modularity to philosophical inquiry in a variety of domains.","contact.mail":"robbinsp@missouri.edu","contact.domain":"missouri.edu"}]
