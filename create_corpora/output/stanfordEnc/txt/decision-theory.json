[{"date.published":"2015-12-16","date.changed":"2020-10-09","url":"https://plato.stanford.edu/entries/decision-theory/","author1":"Katie Steele","author1.info":"http://philosophy.cass.anu.edu.au/people/katie-steele","author2.info":"http://orristefansson.is/","entry":"decision-theory","body.text":"\n\n\nDecision theory is concerned with the reasoning underlying an\nagent’s choices, whether this is a mundane choice between taking\nthe bus or getting a taxi, or a more far-reaching choice about whether\nto pursue a demanding political career. (Note that “agent”\nhere stands for an entity, usually an individual person, that is\ncapable of deliberation and action.) Standard thinking is that what an\nagent chooses to do on any given occasion is completely determined by\nher beliefs and desires or values, but this is not uncontroversial, as\nwill be noted below. In any case, decision theory is as much a theory\nof beliefs, desires and other relevant attitudes as it is a theory of\nchoice; what matters is how these various attitudes (call them\n“preference attitudes”) cohere together.\n\n\nThe focus of this entry is normative decision theory. That is, the\nmain question of interest is what criteria an agent’s preference\nattitudes should satisfy in any generic\ncircumstances. This amounts to a minimal account of\nrationality, one that sets aside more substantial questions\nabout appropriate desires and reasonable beliefs, given the situation\nat hand. The key issue for a minimal account is the treatment of\nuncertainty. The orthodox normative decision theory, expected\nutility (EU) theory, essentially says that, in situations of\nuncertainty, one should prefer the option with greatest\nexpected desirability or value. (Note that in this context,\n“desirability” and “value” should be\nunderstood as desirability/value according to the agent in\nquestion.) This simple maxim will be the focus of much of our\ndiscussion.\n\n\nThe structure of this entry is as follows: Section 1 discusses the\nbasic notion of “preferences over prospects”, which lies\nat the heart of decision theory. Section 2 describes the development\nof normative decision theory in terms of ever more powerful and\nflexible measures of preferences. Section 3 discusses the two\nbest-known versions of EU theory. Section 4 considers the broader\nsignificance of EU theory for practical action, inference, and\nvaluing. Section 5 turns to prominent challenges to EU theory, while\nSection 6 addresses sequential decisions, and how this richer setting\nbears on debates about rational preferences.\n\nThe two central concepts in decision theory are preferences\nand prospects (or equivalently, options). Roughly\nspeaking, when we (in this entry) say that an agent\n“prefers” the “option” \\(A\\) over \\(B\\) we\nmean that the agent takes \\(A\\) to be more desirable or choice-worthy\nthan \\(B\\). This rough definition makes clear that preference is a\ncomparative attitude. Beyond this, there is room for argument about\nwhat preferences over options actually amount to, or in other words,\nwhat it is about an agent (perhaps oneself) that concerns us when we\ntalk about his/her preferences over options. This section considers\nsome elementary issues of interpretation that set the stage for\nintroducing (in the next section) the decision tables and expected\nutility rule that for many is the familiar subject matter of decision\ntheory. Further interpretive questions regarding preferences and\nprospects will be addressed later, as they arise. \nLet us nonetheless proceed by first introducing basic candidate\nproperties of (rational) preference over options and only afterwards\nturning to questions of interpretation. As noted above, preference\nconcerns the comparison of options; it is a relation between options.\nFor a domain of options we speak of an agent’s preference\nordering, this being the ordering of options that is generated by\nthe agent’s preference between any two options in that\ndomain. \nIn what follows, \\(\\preceq\\) represents a weak preference\nrelation. So \\(A\\preceq B\\) means that the agent we are interested in\nconsiders option \\(B\\) to be at least as preferable as option \\(A\\).\nFrom the weak preference relation we can define the strict\npreference relation, \\(\\prec\\), as follows: \\(A\\prec B\\Leftrightarrow\nA\\preceq B \\ \\& \\ \\neg (B\\preceq A)\\), where \\(\\neg X\\) means\n“it is not the case that \\(X\\)”. The indifference\nrelation, \\(\\sim\\), is defined as: \\(A\\sim B \\Leftrightarrow A\\preceq\nB \\ \\& \\ B\\preceq A\\). This represents that the agent we are\ninterested in considers \\(A\\) and \\(B\\) to be equally preferable. \nWe say that \\(\\preceq\\) weakly orders a set \\(S\\) of options\nwhenever it satisfies the following two conditions: \nAxiom 1 (Completeness)\n\nFor any \\(A, B\\in S\\): either \\(A\\preceq B\\) or \\(B\\preceq A\\). \nAxiom 2 (Transitivity)\n\nFor any \\(A, B, C\\in S\\): if \\(A\\preceq B\\) and \\(B\\preceq C\\) then\n\\(A\\preceq C\\). \nThe above can be taken as a preliminary characterisation of rational\npreference over options. Even this limited characterisation is\ncontentious, however, and points to divergent interpretations of\n“preferences over prospects/options”. \nStart with the Completeness axiom, which says that an agent can\ncompare, in terms of the weak preference relation, all pairs of\noptions in \\(S\\). Whether or not Completeness is a plausible\nrationality constraint depends both on what sort of options are under\nconsideration, and how we interpret preferences over these options. If\nthe option set includes all kinds of states of affairs, then\nCompleteness is not immediately compelling. For instance, it is\nquestionable whether an agent should be able to compare the option\nwhereby two additional people in the world are made literate with the\noption whereby two additional people reach the age of sixty. If, on\nthe other hand, all options in the set are quite similar to each\nother, say, all options are investment portfolios, then Completeness\nis more compelling. But even if we do not restrict the kinds of\noptions under consideration, the question of whether or not\nCompleteness should be satisfied turns on the meaning of preference.\nFor instance, if preferences merely represent choice behaviour or\nchoice dispositions, as they do according to the “revealed\npreference theory” popular amongst economists (see Sen 1973),\nthen Completeness is automatically satisfied, on the assumption that a\nchoice must inevitably be made. By contrast, if preferences are\nunderstood rather as mental attitudes, typically considered judgments\nabout whether an option is better or more desirable than another, then\nthe doubts about Completeness alluded to above are pertinent (for\nfurther discussion, see Mandler 2001). \nMost philosophers and decision theorists subscribe to the latter\ninterpretation of preference as a kind of judgment that explains, as\nopposed to being identical with, choice dispositions and resultant\nchoice behaviour (see, e.g., Hausman 2011a, 2011b; Dietrich and List,\n2016a & 2016b; Bradley 2017; although see also Thoma 2020b and\nVredenburgh 2020 for recent defences of “revealed preference\ntheory”, at least in the context of empirical economics).\nMoreover, many hold that Completeness is not rationally required,\nsince they think that rationality makes demands only on the judgments\nan agent actually holds, but says nothing of whether a judgement must\nbe held in the first place. Nevertheless, following Richard Jeffrey\n(1983), most decision theorists suggest that rationality requires that\npreferences be coherently extendible. This means that even if\nyour preferences are not complete, it should be possible to complete\nthem without violating any of the conditions that are rationally\nrequired, in particular Transitivity. \nThis brings us to the\n Transitivity axiom,\n which says that if an option \\(B\\) is weakly preferred to \\(A\\), and\n\\(C\\) weakly preferred to \\(B\\), then \\(C\\) is weakly preferred to\n\\(A\\). A recent challenge to Transitivity turns on heterogeneous sets\nof options, as per the discussion of Completeness above. But here a\ndifferent interpretation of preference is brought to bear on the\ncomparison of options. The idea is that preferences, or judgments of\ndesirability, may be responsive to a salience condition. For example,\nsuppose that the most salient feature when comparing cars \\(A\\) and\n\\(B\\) is how fast they can be driven, and \\(B\\) is no worse than \\(A\\)\nin this regard, yet the most salient feature when comparing cars \\(B\\)\nand \\(C\\) is how safe they are, and that \\(C\\) is no worse than \\(B\\)\nin this regard. Furthermore, when comparing \\(A\\) and \\(C\\), the most\nsalient feature is their beauty. In such a case, some argue (e.g.,\nTemkin 2012) that there is no reason why Transitivity should be\nsatisfied with respect to the preferences concerning \\(A\\), \\(B\\) and\n\\(C\\). Others (e.g., Broome 1991a) argue that Transitivity is part of\nthe very meaning of the betterness relation (or objective comparative\ndesirability); if rational preference is a judgment of betterness or\ndesirability, then Transitivity is non-negotiable. With respect to the\ncar example, Broome would argue that the desirability of a fully\nspecified option should not vary, simply in virtue of what other\noptions it is compared with. Either the choice context affects how the\nagent perceives the option at hand, in which case the description of\nthe option should reflect this, or else the choice context does not\naffect the option. Either way, Transitivity should be satisfied. \nThere is a more straightforward defence of Transitivity in preference;\na defence that hinges on the sure losses that may befall anyone who\nviolates the axiom. This is the so-called money pump argument\n(see Davidson et. al. 1955 for an early argument of this sort, but for\nrecent discussion and revision of this argument, see Gustafsson 2010\n& 2013). It is based on the assumption that if you find \\(X\\) at\nleast as desirable as \\(Y\\), then you should be happy to trade the\nlatter for the former. Suppose you violate Transitivity; for you:\n\\(A\\preceq B\\), \\(B\\preceq C\\) but \\(C\\prec A\\). Moreover, suppose you\npresently have \\(A\\). Then you should be willing to trade \\(A\\) for\n\\(B\\). The same goes for \\(B\\) and \\(C\\): you should be willing to\ntrade \\(B\\) for \\(C\\). You strictly prefer \\(A\\) to \\(C\\), so you\nshould be willing to trade in \\(C\\) plus some sum \\(\\$x\\) for \\(A\\).\nBut now you are in the same situation as you started, having \\(A\\) and\nneither \\(B\\) nor \\(C\\), except that you have lost \\(\\$x\\)! So in a\nfew steps, each of which was consistent with your preferences, you\nfind yourself in a situation that is clearly worse, by your own\nlights, than your original situation. The picture is made more\ndramatic if we imagine that the process could be repeated, turning you\ninto a “money pump”. Hence, the argument goes, there is\nsomething (instrumentally) irrational about your intransitive\npreferences. If your preferences were transitive, then you would not\nbe vulnerable to choosing a dominated option and serving as a money\npump. Therefore, your preferences should be transitive. \nWhile the aforementioned controversies have not been settled, the\nfollowing assumptions will be made in the remainder of this entry: i)\nthe objects of preference may be heterogeneous prospects,\nincorporating a rich and varied domain of properties, ii) preference\nbetween options is a judgment of comparative desirability or\nchoice-worthiness, and iii) preferences satisfy both Completeness and\nTransitivity (although the former condition will be revisited in\n Section 5).\n The question that now arises is whether there are further general\nconstraints on rational preference over options. \nIn our continuing investigation of rational preferences over\nprospects, the numerical representation (or\nmeasurement) of preference orderings will become important.\nThe numerical measures in question are known as utility\nfunctions. The two main types of utility function that will play\na role are the ordinal utility function and the more\ninformation-rich interval-valued (or cardinal)\nutility function. \nIt turns out that as long as the set of prospects/options, \\(S\\), is\nfinite, any weak order of the options in \\(S\\) can be represented by\nan ordinal utility function. To be precise, let us say that \\(u\\) is a\nutility function with domain \\(S\\). We say that the function\n\\(u\\) represents the preference \\(\\preceq\\) between the\noptions in \\(S\\) just in case: \nAnother way to put this is that, when the above holds, the preference\nrelation can be represented as maximising utility, since it\nalways favours option with higher utility. \nThe only information contained in an ordinal utility representation is\nhow the agent whose preferences are being represented orders options,\nfrom least to most preferable. This means that if \\(u\\) is an ordinal\nutility function that represents the ordering \\(\\preceq\\), then any\nutility function \\(u'\\) that is an ordinal transformation of\n\\(u\\)—that is, any transformation of \\(u\\) that also satisfies\nthe biconditional in (1)—represents \\(\\preceq\\) just as well as\n\\(u\\) does. Hence, we say that an ordinal utility function is\nunique only up to ordinal transformations. \nThe result referred to above can be summarised as follows: \nTheorem 1 (Ordinal representation). Let \\(S\\) be a\nfinite set, and \\(\\preceq\\) a weak preference relation on \\(S\\). Then\nthere is an ordinal utility function that represents \\(\\preceq\\) just\nin case \\(\\preceq\\) is complete and transitive. \nThis theorem should not be too surprising. If \\(\\preceq\\) is complete\nand transitive over \\(S\\), then the options in \\(S\\) can be put in an\norder, from the most to the least preferred, where some options may\nfall in the same position (if they are deemed equally desirable) but\nwhere there are no cycles, loops, or gaps.\n Theorem 1\n just says that we can assign numbers to the options in \\(S\\) in a way\nthat represents this order. (For a simple proof of Theorem 1, except\nfor a strict rather than a weak preference relation, consult Peterson\n2009: 95.) \nNote that ordinal utilities are not very mathematically\n“powerful”, so to speak. It does not make sense, for\ninstance, to compare the probabilistic expectations of different sets\nof ordinal utilities. For example, consider the following two pairs of\nprospects: the elements of the first pair are assigned ordinal\nutilities of 2 and 4, while those in the second pair are assigned\nordinal utilities of 0 and 5. Let us specify a “flat”\nprobability distribution in each case, such that each element in the\ntwo pairs corresponds to a probability of 0.5. Relative to this\nprobability assignment, the expectation of the first pair of ordinal\nutilities is 3, which is larger than 2.5, the expectation of the\nsecond pair. Yet when we transform the ordinal utilities in a\npermissible way—for instance by increasing the highest utility\nin the second pair from 5 to 10—the ordering of expectations\nreverses; now the comparison is between 3 and 5. The significance of\nthis point will become clearer in what follows, when we turn to the\ncomparative evaluation of lotteries and risky choices. An\ninterval-valued or cardinal utility function is necessary for\nevaluating lotteries/risky prospects in a consistent way. By the same\ntoken, in order to construct or conceptualise a cardinal utility\nfunction, one typically appeals to preferences over lotteries.\n(Although see Alt 1936 for a “risk-free” construction of\ncardinal utility, that is, one that does not appeal to lotteries.) \nIn order to get a cardinal (interval-valued) utility representation of\na preference ordering—i.e., a measure that represents not only\nhow an agent orders the options but also says something about the\ndesirabilistic “distance” between options—we need a\nricher setting; the option set and the corresponding preference\nordering will need to have more structure than for an ordinal utility\nmeasure. One such account, owing to John von Neumann and Oskar\nMorgenstern (1944), will be cashed out in detail below. For now, it is\nuseful to focus on the kind of option that is key to understanding and\nconstructing a cardinal utility function:\n lotteries.[1] \nConsider first an ordering over three regular options, e.g., the three\nholiday destinations Amsterdam, Bangkok and Cardiff, denoted \\(A\\),\n\\(B\\) and \\(C\\) respectively. Suppose your preference ordering is\n\\(A\\prec B \\prec C\\). This information suffices to ordinally represent\nyour judgement; recall that any assignment of utilities is then\nacceptable as long as \\(C\\) gets a higher value than \\(B\\) which gets\na higher value than \\(A\\). But perhaps we want to know more than can\nbe inferred from such a utility function—we want to know how\nmuch \\(C\\) is preferred over \\(B\\), compared to how much \\(B\\) is\npreferred over \\(A\\). For instance, it may be that Bangkok is\nconsidered almost as desirable as Cardiff, but Amsterdam is a long way\nbehind Bangkok, relatively speaking. Or else perhaps Bangkok is only\nmarginally better than Amsterdam, compared to the extent to which\nCardiff is better than Bangkok. This kind of information about the\nrelative distance between options, in terms of strength of preference\nor desirability, is precisely what is given by an interval-valued\nutility function. The problem is how to ascertain this\ninformation. \nTo solve this problem, Ramsey (1926) and later von Neumann and\nMorgenstern (hereafter vNM) made the following suggestion: we\nconstruct a new option, a lottery, \\(L\\), that has \\(A\\) and\n\\(C\\) as its possible “prizes”, and we figure out what\nchance the lottery must confer on \\(C\\) for you to be indifferent\nbetween this lottery and a holiday in Bangkok. The basic idea is that\nyour judgment about Bangkok, relative to Cardiff on the one hand and\nAmsterdam on the other, can be measured by the riskiness of the\nlottery \\(L\\) involving Cardiff and Amsterdam that you deem equally\ndesirable as Bangkok. For instance, if you are indifferent between\nBangkok and a lottery that provides a very low chance of winning a\ntrip to Cardiff, then you evidently do not regard Bangkok to be much\nbetter than Amsterdam, vis-à-vis Cardiff; for you, even a small\nimprovement on Amsterdam, i.e., a lottery with a small chance of\nCardiff rather than Amsterdam, is enough to match Bangkok. \nThe above analysis presumes that lotteries are evaluated in terms of\ntheir expected choice-worthiness or desirability. That is,\nthe desirability of a lottery is effectively the sum of the chances of\neach prize multiplied by the desirability of that prize. Consider the\nfollowing example: Suppose you are indifferent between the lottery and\nthe holiday in Bangkok when the chance of the lottery resulting in a\nholiday in Cardiff is \\(3/4\\). Call this particular lottery \\(L'\\).\nThe idea is that Bangkok is therefore three quarters of the way up a\ndesirability scale that has Amsterdam at the bottom and Cardiff at the\ntop. If we stipulate that \\(u(A)=0\\) and \\(u(C)=1\\), then\n\\(u(B)=u(L')=3/4\\). This corresponds to the expected\ndesirability—or, as it is usually called, the expected\nutility—of the lottery, since \\(1/4\\cdot 0 + 3/4\\cdot 1 =\n3/4 = u(L')\\). That is, the desirability of the lottery is a\nprobability weighted sum of the utilities of its prizes, where the\nweight on each prize is determined by the probability that the lottery\nresults in that prize. \nWe thus see that an interval-valued utility measure over options can\nbe constructed by introducing lottery options. As the name suggests,\nthe interval-valued utility measure conveys information about the\nrelative sizes of the intervals between the options according to some\ndesirability scale. That is, the utilities are unique after we have\nfixed the starting point of our measurement and the unit scale of\ndesirability. In the above example, we could have, for instance,\nassigned a utility value of 1 to \\(A\\) and 5 to \\(C\\), in which case\nwe would have had to assign a utility value of 4 to \\(B\\), since 4 is\n3/4 of the way between 1 and 5. In other words, once we have assigned\nutility values to \\(A\\) and \\(C\\), the utility of \\(L'\\) and thus\n\\(B\\) has been determined. Let us call this second utility function\n\\(u'\\). It is related to our original function as follows: \\(u'=4\\cdot\nu +1\\). This relationship always holds between two such functions: If\n\\(u\\) is an interval-valued utility function that represents a\npreference ordering, \\(\\preceq\\), and \\(u'\\) is another utility\nfunction that also represents this same preference ordering, then\nthere are constants \\(a\\) and \\(b\\), where \\(a\\) must be positive,\nsuch that \\(u'=a\\cdot u + b\\). This is to say that interval-valued\nutility functions are unique only up to positive linear\ntransformation. \nBefore concluding this discussion of measuring utility, two related\nlimitations regarding the information such measures convey should be\nmentioned. First, since the utilities of options, whether ordinal or\ninterval-valued, can only be determined relative to the\nutilities of other options, there is no such thing as the\nabsolute utility of an option, at least not without further\n assumptions.[2]\n Second, by the same reasoning, neither interval-valued nor ordinal\nutility measures, as discussed here, are interpersonally\ncommensurable with respect to levels and units of utility. By way\nof a quick illustration, suppose that both you and I have the\npreference ordering described above over the holiday options: \\(A\\prec\nB \\prec C\\). Suppose too that, as per the above, we are both\nindifferent between \\(B\\) and the lottery \\(L'\\) that has a \\(3/4\\)\nchance of yielding \\(C\\) and a \\(1/4\\) chance of yielding \\(A\\). Can\nwe then say that granting me Cardiff and you Bangkok would amount to\nthe same amount of “total desirability” as granting you\nCardiff and me Bangkok? We are not entitled to say this. Our shared\npreference ordering is, for instance, consistent with me finding a\nvacation in Cardiff a dream come true while you just find it the best\nof a bad lot. Moreover, we are not even entitled to say that the\ndifference in desirability between Bangkok and Amsterdam is the same\nfor you as it is for me. According to me, the desirability of the\nthree options might range from living hell to a dream come true, while\naccording to you, from bad to quite bad; both evaluations are\nconsistent with the above preference ordering. In fact, the same might\nhold for our preferences over all possible options, including\nlotteries: even if we shared the same total preference ordering, it\nmight be the case that you are just of a negative\ndisposition—finding no option that great—while I am very\nextreme—finding some options excellent but others a sheer\ntorture. Hence, utility functions, whether interval-valued or ordinal,\ndo not allow for meaningful interpersonal comparisons. (Elster and\nRoemer 1993 contains a number of papers discussing these issues; see\nalso the entry on\n social choice theory.) \nThe last section provided an interval-valued utility representation of\na person’s preferences over lotteries, on the assumption that\nlotteries are evaluated in terms of expected utility. Some might find\nthis a bit quick. Why should we assume that people evaluate lotteries\nin terms of their expected utilities? The vNM theorem effectively\nshores up the gaps in reasoning by shifting attention back to the\npreference relation. In addition to Transitivity and Completeness, vNM\nintroduce further principles governing rational preferences over\nlotteries, and show that an agent’s preferences can be\nrepresented as maximising expected utility whenever her preferences\nsatisfy these principles. \nLet us first define, in formal terms, the expected utility of a\nlottery: Let \\(L_i\\) be a lottery from the set \\(\\bL\\) of lotteries,\nand \\(O_{ik}\\) the outcome, or prize, of lottery \\(L_i\\) that arises\nwith probability \\(p_{ik}\\). The expected utility of \\(L_i\\) is then\ndefined as: \nThe vNM equation. \nThe assumption made earlier can now be formally stated: \nWhen the above holds, we say that there is an expected utility\nfunction that represents the agent’s preferences; in other\nwords, the agent can be represented as maximising expected\nutility. \nThe question that vNM address is: What sort of preferences can be thus\nrepresented? To answer this question, we must return to the underlying\npreference relation \\(\\preceq\\) over the set of options, in this case\ninvolving lotteries. The vNM theorem requires the set \\(\\bL\\) of\nlotteries to be rather extensive: it is closed under\n“probability mixture”, that is, if \\(L_i, L_j\\in \\bL\\),\nthen compound lotteries that have \\(L_i\\) and \\(L_j\\) as possible\nprizes are also in \\(\\bL\\). (Another technical assumption, that will\nnot be discussed in detail, is that compound lotteries can always be\nreduced, in accordance with the laws of probability, to simple\nlotteries that only involve basic prizes.) \nA basic rationality constraint on the preference relation has already\nbeen discussed—that it weakly orders the options (i.e.,\nsatisfies Transitivity and Completeness). The following notation will\nbe used to introduce the two additional vNM axioms of preference:\n\\(\\{pA, (1-p)B\\}\\) denotes a lottery that results either in \\(A\\),\nwith probability \\(p\\), or \\(B\\), with probability \\(1-p\\), where\n\\(A\\) and \\(B\\) can be final outcomes but can also be lotteries. \nAxiom 3 (Continuity)\n\nSuppose \\(A\\preceq B\\preceq C\\). Then there is a \\(p\\in [0,1]\\) such\nthat: \nAxiom 4 (Independence)\n\nSuppose \\(A\\preceq B\\). Then for any \\(C\\), and any \\(p\\in\n[0,1]\\): \nContinuity implies that no outcome \\(A\\) is so bad that you would not\nbe willing to take some gamble that might result in you ending up with\nthat outcome, but might otherwise result in you ending up with an\noutcome (\\(C\\)) that you find to be a marginal improvement on your\nstatus quo (\\(B\\)), provided that the chance of \\(A\\) is small enough.\nIntuitively, Continuity guarantees that an agent’s evaluations\nof lotteries are appropriately sensitive to the probabilities of the\nlotteries’ prizes. \nIndependence implies that when two alternatives have the same\nprobability for some particular outcome, our evaluation of the two\nalternatives should be independent of our opinion of that outcome.\nIntuitively, this means that preferences between lotteries should be\ngoverned only by the features of the lotteries that differ; the\ncommonalities between the lotteries should be effectively ignored.\n \nSome people find the\n Continuity axiom\n an unreasonable constraint on rational preference. Is there any\nprobability \\(p\\) such that you would be willing to accept a gamble\nthat has that probability of you losing your life and probability\n\\((1-p)\\) of you gaining $10? Many people think there is not. However,\nthe very same people would presumably cross the street to pick up a\n$10 bill they had dropped. But that is just taking a gamble that has a\nvery small probability of being killed by a car but a much higher\nprobability of gaining $10! More generally, although people rarely\nthink of it this way, they constantly take gambles that have minuscule\nchances of leading to imminent death, and correspondingly very high\nchances of some modest reward. \nIndependence seems a compelling requirement of rationality, when\nconsidered in the abstract. Nevertheless, there are famous examples\nwhere people often violate Independence without seeming irrational.\nThese examples involve complementarities between the possible\nlottery outcomes. A particularly well-known such example is the\nso-called Allais Paradox, which the French economist Maurice\nAllais (1953) first introduced in the early 1950s. The paradox turns\non comparing people’s preferences over two pairs of lotteries\nsimilar to those given in Table 1. The lotteries are described in\nterms of the prizes that are associated with particular numbered\ntickets, where one ticket will be drawn randomly (for instance,\n\\(L_1\\) results in a prize of $2500 if one of the tickets numbered\n2–34 is drawn). \nTable 1. Allais’ paradox \nIn this situation, many people strictly prefer \\(L_2\\) over \\(L_1\\)\nbut also \\(L_3\\) over \\(L_4\\) (as evidenced by their choice behaviour,\nas well as their testimony), a pair of preferences which will be\nreferred to as Allais’\n preferences.[3]\n A common way to rationalise Allais’ preferences, is that in the\nfirst choice situation, the risk of ending up with nothing when one\ncould have had $2400 for sure does not justify the increased chance of\na higher prize. In the second choice situation, however, the minimum\none stands to gain is $0 no matter which choice one makes. Therefore,\nin that case many people do think that the slight extra risk of $0 is\nworth the chance of a better prize. \nWhile the above reasoning may seem compelling, Allais’\npreferences conflict with the\n Independence axiom.\n The following is true of both choice situations: whatever choice you\nmake, you will get the same prize if one of the tickets in the last\ncolumn is drawn. Therefore, Independence implies that both your\npreference between \\(L_1\\) and \\(L_2\\) and your preference between\n\\(L_3\\) and \\(L_4\\) should be independent of the prizes in that\ncolumn. But when you ignore the last column, \\(L_1\\) becomes identical\nto \\(L_3\\) and \\(L_2\\) to \\(L_4\\). Hence, if you prefer \\(L_2\\) over\n\\(L_1\\) but \\(L_3\\) over \\(L_4\\), there seems to be an inconsistency\nin your preference ordering. And there is definitely a violation of\nIndependence (given how the options have been described; an issue to\nwhich we return in\n Section 5.1).\n As a result, the pair of preferences under discussion cannot be\nrepresented as maximising expected utility. (Thus the\n“paradox”: many people think that Independence is a\nrequirement of rationality, but nevertheless also want to claim that\nthere is nothing irrational about Allais’ preferences.) \nDecision theorists have reacted in different ways to Allais’\nParadox. This issue will be revisited in\n Section 5.1,\n when challenges to EU theory will be discussed. The present goal is\nsimply to show that Continuity and Independence are compelling\nconstraints on rational preference, although not without their\ndetractors. The result vNM proved can be summarised thus: \nTheorem 2 (von Neumann-Morgenstern)\n\nLet \\(\\bO\\) be a finite set of outcomes, \\(\\bL\\) a set of\ncorresponding lotteries that is closed under probability mixture and\n\\(\\preceq\\) a weak preference relation on \\(\\bL\\). Then \\(\\preceq\\)\nsatisfies axioms 1–4 if and only if there exists a function\n\\(u\\), from \\(\\bO\\) into the set of real numbers, that is unique up to\npositive linear transformation, and relative to which \\(\\preceq\\) can\nbe represented as maximising expected utility. \nDavid Kreps (1988) gives an accessible illustration of the proof of\nthis theorem. \nThe vNM theorem is a very important result for measuring the strength\nof a rational agent’s preferences over sure options (the\nlotteries effectively facilitate a cardinal measure over sure\noptions). But this does not get us all the way to making rational\ndecisions in the real world; we do not yet really have a decision\ntheory. The theorem is limited to evaluating options that come with a\nprobability distribution over outcomes—a situation decision\ntheorists and economists often describe as “choice under\nrisk” (Knight 1921). \nIn most ordinary choice situations, the objects of choice, over which\nwe must have or form preferences, are not like this. Rather,\ndecision-makers must consult their own probabilistic beliefs\nabout whether one outcome or another will result from a specified\noption. Decisions in such circumstances are often described as\n“choices under uncertainty” (Knight 1921). For example,\nconsider the predicament of a mountaineer deciding whether or not to\nattempt a dangerous summit ascent, where the key factor for her is the\nweather. If she is lucky, she may have access to comprehensive weather\nstatistics for the region. Nevertheless, the weather statistics differ\nfrom the lottery set-up in that they do not determine the\nprobabilities of the possible outcomes of attempting versus not\nattempting the summit on a particular day. Not least, the mountaineer\nmust consider how confident she is in the data-collection procedure,\nwhether the statistics are applicable to the day in question, and so\non, when assessing her options in light of the weather. \nSome of the most celebrated results in decision theory address, to\nsome extent, these challenges. They consist in showing what conditions\non preferences over “real world options” suffice for the\nexistence of a pair of utility and probability functions\nrelative to which the agent can be represented as maximising expected\nutility. The standard interpretation is that, just as the utility\nfunction represents the agent’s desires, so the probability\nfunction represents her beliefs. The theories are referred to\ncollectively as subjective expected utility (SEU) theory as\nthey concern an agent’s preferences over prospects that are\ncharacterised entirely in terms of her own beliefs and desires (but we\nwill continue to use the simpler label EU theory). In this\nsection, two of these results will be briefly discussed: that of\nLeonard Savage (1954) and Richard Jeffrey (1965). \nNote that these EU decision theories apparently prescribe two things:\n(a) you should have consistent preference attitudes, and (b) you\nshould prefer the means to your ends, or at least you should prefer\nthe means that you assess will on average lead to your ends\n(cf. Buchak 2016). The question arises: What is the relationship\nbetween these prescriptions? The EU representation theorems\nthat will be outlined shortly seem to show that, despite appearances,\nthe two prescriptions are actually just one: anyone who has consistent\nattitudes prefers the means to her ends, and vice versa. But the\npuzzle remains that there are many ways to have consistent preference\nattitudes, and surely not all of these amount to preferring the means\nto one’s own true ends. This puzzle is worth bearing in\nmind when appraising EU theory in its various guises; it will come up\nagain later. \nLeonard Savage’s decision theory, as presented in his (1954)\nThe Foundations of Statistics, is without a doubt the\nbest-known normative theory of choice under uncertainty, in particular\nwithin economics and the decision sciences. In the book Savage\npresents a set of axioms constraining preferences over a set of\noptions that guarantee the existence of a pair of probability and\nutility functions relative to which the preferences can be represented\nas maximising expected utility. Nearly three decades prior to the\npublication of the book, Frank P. Ramsey (1926) had actually proposed\nthat a different set of axioms can generate more or less the same\nresult. Nevertheless, Savage’s theory has been much more\ninfluential than Ramsey’s, perhaps because Ramsey neither gave a\nfull proof of his result nor provided much detail of how it would go\n(Bradley 2004). Savage’s result will not be described here in\nfull detail. However, the ingredients and structure of his theorem\nwill be laid out, highlighting its strengths and weaknesses. \nThe options or prospects in Savage’s theory are similar to\nlotteries, except that the possible outcomes do not come with\nprobabilities but rather depend on whether a particular state of the\nworld is actual. Indeed, the primitives in Savage’s theory are\n outcomes[4]\n and states (of the world). The former are the good or bad\nstates of affairs that ultimately affect and matter to an agent, while\nthe latter are the features of the world that the agent has no control\nover and which are the locus of her uncertainty about the world. Sets\nof states are called events. This distinction between\noutcomes and states serves to neatly separate desire and belief: the\nformer are, according to Savage’s theory, the target of desire,\nwhile the latter are the target of belief. \nThe lottery-like options over which the agent has preferences are a\nrich set of acts that effectively amount to all the possible\nassignments of outcomes to states of the world. That is, acts are\nfunctions from the state space to the outcome space, and the\nagent’s preference ordering is taken to be defined over all such\npossible functions. Some of these acts will look quite sensible:\nconsider the act that assigns to the event “it rains” the\noutcome “miserable wet stroll” and assigns to the event\n“it does not rain” the outcome “very comfortable\nstroll”. This is apparently the act of going for a stroll\nwithout one’s umbrella. Other Savage acts will not look quite so\nsensible, such as the constant act that assigns to both\n“it rains” and “it does not rain” the same\noutcome “miserable wet stroll”. (Note that the constant\nacts provide a way of including sure outcomes within the preference\nordering.) The problem with this act (and many others) is that it does\nnot correspond to anything that an agent could even in principle\nchoose to do or\n perform.[5] \nSavage’s act/state(event)/outcome distinction can be naturally\nrepresented in tabular form, with rows serving as acts that yield a\ngiven outcome for each state/event column. Table 2 depicts the two\nacts mentioned above plus a third one that the decision maker might\ncare about: the acts i) “go for stroll without umbrella”,\nii) “go for stroll with umbrella”, and iii) the bizarre\nconstant act. Of course, the set of acts required for Savage’s\ntheorem involve even more acts that account for all the possible\ncombinations of states and outcomes. \nTable 2. Savage-style decision table \nBefore discussing Savage’s axioms, let us state the result that\nthey give rise to. The following notation will be used: \\(f\\), \\(g\\),\netc, are various acts, i.e., functions from the set \\(\\bS\\) of states\nof the world to the set \\(\\bO\\) of outcomes, with \\(\\bF\\) the set of\nthese functions. \\(f(s_i)\\) denotes the outcome of \\(f\\) when state\n\\(s_i\\in\\bS\\) is actual. The expected utility of \\(f\\), according to\nSavage’s theory, denoted \\(U(f)\\), is given by: \nSavage’s equation\n\n\\(U(f)=\\sum_i u(f(s_i))\\cdot P(s_i)\\)  \nThe result Savage proved can be stated as\n follows:[6] \nThe agent’s confidence in the actuality of the states in \\(\\bS\\)\ncan be represented by a unique (and finitely additive)\nprobability function, \\(P\\); \nthe strength of her desires for the ultimate outcomes in \\(\\bO\\) can\nbe represented by a utility function, \\(u\\), that is unique up to\npositive linear transformation; \nand the pair \\((P, u)\\) gives rise to an expected utility function,\n\\(U\\), that represents her preferences for the alternatives in\n\\(\\bF\\); i.e., for any \\(f, g\\in\\bF\\): \nThe above result may seem remarkable; in particular, the fact that a\nperson’s preferences can determine a unique probability function\nthat represents her beliefs. On a closer look, however, it is evident\nthat some of our beliefs can be determined by examining our\npreferences. Suppose you are offered a choice between two lotteries,\none that results in you winning a nice prize if a coin comes up heads\nbut getting nothing if the coin comes up tails, another that results\nin you winning the same prize if the coin comes up tails but getting\nnothing if the coin comes up heads. Then assuming that the\ndesirability of the prize (and similarly the desirability of no prize)\nis independent of how the coin lands, your preference between the two\nlotteries should be entirely determined by your comparative beliefs\nfor the two ways in which the coin can land. For instance, if you\nstrictly prefer the first lottery to the second, then that suggests\nyou consider heads more likely than tails. \nThe above observation suggests that one can gauge an agent’s\ncomparative beliefs, and perhaps more, from her preferences. Savage\nwent one step further than this, and defined comparative\nbeliefs in terms of preferences. To state Savage’s definition,\nlet \\(\\wcbrel\\) be a weak comparative belief relation, defined on the\nset \\(\\bS\\) of states of the world. (\\(\\cbrel\\) and \\(\\wcbsim\\) are\ndefined in terms of \\(\\wcbrel \\) in the usual way.) \nDefinition 1 (Comparative Belief).\n\nSuppose \\(E\\) and \\(F\\) are two events (i.e., subsets of \\(\\bS\\)).\nSuppose \\(X\\) and \\(Y\\) are two outcomes and \\(f\\) and \\(g\\) two acts,\nwith the following properties: \nThen \\(E \\wcbrel F\\Leftrightarrow f\\preceq g\\). \nDefinition 1 is based on the simple observation that one would\ngenerally prefer to stake a good outcome on a more rather than less\nprobable event. But the idea that this defines comparative\nbeliefs might seem questionable. We could, for instance, imagine\npeople who are instrumentally irrational, and as a result fail to\nprefer \\(g\\) to \\(f\\), even when the above conditions all hold and\nthey find \\(F\\) more likely than \\(E\\). Moreover, this definition\nraises the question of how to define the comparative beliefs of those\nwho are indifferent between all outcomes (Eriksson and\nHájek 2007). Perhaps no such people exist (and Savage’s\n axiom P5\n indeed makes clear that his result does not pertain to such people).\nNevertheless, it seems a definition of comparative beliefs should not\npreclude that such people, if existent, have strict\ncomparative beliefs. Savage suggests that this definition of\ncomparative beliefs is plausible in light of his axiom P4, which will\nbe stated below. In any case, it turns out that when a person’s\npreferences satisfy Savage’s axioms, we can read off her\npreferences a comparative belief relation that can be represented by a\n(unique) probability function. \nWithout further ado, let us state Savage’s axioms in turn. These\nare intended as constraints on an agent’s preference relation,\n\\(\\preceq\\), over a set of acts, \\(\\bF\\), as described above. The\nfirst of Savage’s axioms is the basic ordering axiom. \nP1. (Ordering)\n\nThe relation \\(\\preceq\\) is complete and transitive. \nThe next axiom is reminiscent of vNM’s Independence axiom. We\nsay that alternative \\(f\\) “agrees with” \\(g\\) in event\n\\(E\\) if, for any state in event \\(E\\), \\(f\\) and \\(g\\) yield the same\noutcome. \nP2. (Sure Thing Principle)\n\nIf \\(f\\), \\(g\\), and \\(f'\\), \\(g'\\) are such that: \nthen \\(f'\\preceq g'\\). \nThe idea behind the Sure Thing Principle (STP) is essentially the same\nas that behind Independence: since we should be able to evaluate each\noutcome independently of other possible outcomes, we can safely ignore\nstates of the world where two acts that we are comparing result in the\nsame outcome. Putting the principle in tabular form may make this more\napparent. The setup involves four acts with the following form:  \nThe intuition behind the STP is that if \\(g\\) is weakly preferred to\n\\(f\\), then that must be because the consequence \\(Y\\) is considered\nat least as desirable as \\(X\\), which by the same reasoning implies\nthat \\(g'\\) is weakly preferred to \\(f'\\). \nSavage also requires that the desirability of an outcome be\nindependent of the state in which it occurs, as this is necessary for\nit to be possible to determine a comparative belief relation from an\nagent’s preferences. To formalise this requirement, Savage\nintroduces the notion of a null event, defined as\nfollows: \nDefinition 2 (Null)\n\nEvent E is null just in case for any alternatives\n\\(f,g\\in\\bF\\), \\(f\\sim g\\) given E. \nThe intuition is that null events are those events an agent is certain\nwill not occur. If and only if an agent is certain that \\(E\\) will not\noccur, then it is of indifference to her what the acts before her\nyield under \\(E\\). The following axiom then stipulates that knowing\nwhat state is actual does not affect the preference ordering over\noutcomes: \nP3. (State Neutrality)\n\nIf \\(f(s_i)=X\\) and \\(g(s_i)=Y\\) whenever \\(s_i\\in E\\) and \\(E\\) is\nnot null, then \\(f\\preceq g\\) given \\(E\\) just in case \\(X\\preceq\nY\\). \nThe next axiom is also necessary for it to be possible to determine a\ncomparative belief relation from an agent’s preferences. Above\nit was suggested that by asking you to stake a prize on whether a coin\ncomes up heads or tails, it can be determined which of these events,\nheads or tails, you find more likely. But that suggestion is only\nplausible if the size of the prize does not affect your judgement of\nthe relative likelihood of these two events. That assumption is\ncaptured by the next axioms. Since the axiom is rather complicated it\nwill be stated in tabular form: \nP4. Consider the following acts: \nNow suppose: \nThen \nLess formally (and stated in terms of strict preference), the idea is\nthat if you prefer to stake the prize \\(X\\) on \\(f\\) rather than\n\\(f'\\), you must consider \\(E\\) more probable than \\(F\\). Therefore,\nyou should prefer to stake the prize \\(Y\\) on \\(g\\) rather than \\(g'\\)\nsince the prize itself does not affect the probability of the\nevents. \nThe next axiom is arguably not a rationality requirement, but one of\nSavage’s “structural axioms” (Suppes 2002). An agent\nneeds to have some variation in preference for it to be possible to\nread off her comparative beliefs from her preferences; and, more\ngenerally, for it to be possible to represent her as maximising\nexpected utility. To this end, the next axiom simply requires that\nthere be some alternatives between which the agent is not\nindifferent: \nP5.\n\nThere are some \\(f,g\\in\\bF\\) such that \\(f\\prec g\\). \nWhen these five axioms are satisfied, the agent’s preferences\ngive rise to a comparative belief relation, \\(\\wcbrel \\), which has\nthe property of being a qualitative probability relation,\nwhich is necessary for it to be possible to represent \\(\\wcbrel \\) by\na probability function. In other words, \\(\\wcbrel \\) satisfies the\nfollowing three conditions, for any events \\(E\\), \\(F\\) and \\(G\\): \n\\(\\wcbrel \\) is transitive and complete, \nif \\(E\\cap G=\\emptyset=F\\cap G\\), then \\(E \\wcbrel F\\Leftrightarrow\nE\\cup G \\wcbrel F\\cup G\\), \n\\(\\emptyset \\wcbrel E,\\)   \\(\\emptyset \\cbrel \\bS\\) \nBeing a qualitative probability relation is, however, not sufficient\nto ensure the possibility of probabilistic representation. To ensure\nthis possibility, Savage added the following structural axiom: \nP6. (Non-atomicity)\n\nSuppose \\(f\\prec g\\). Then for any \\(X\\in\\bO\\), there is a\nfinite partition, \\(\\{E_1, E_2, … E_m\\}\\), of \\(\\bS\\) such\nthat: \nLike the Continuity axiom of vNM, Non-Atomicity implies that no matter\nhow bad an outcome \\(X\\) is, if \\(g\\) is already preferred to \\(f\\),\nthen if we add \\(X\\) as one of the possible outcomes of\n\\(f\\)—thereby constructing a new alternative \\(f'\\)—\\(g\\)\nwill still be preferred to the modified alternative as long as the\nprobability of \\(X\\) is sufficiently small. In effect, Non-Atomicity\nimplies that \\(\\bS\\) contains events of arbitrarily small probability.\nIt is not too difficult to imagine how that could be satisfied. For\ninstance, any event \\(F\\) can be partitioned into two equiprobable\nsub-events according to whether some coin would come up heads or tails\nif it were tossed. Each sub-event could be similarly partitioned\naccording to the outcome of the second toss of the same coin, and so\non. \nSavage showed that whenever these six axioms are satisfied, the\ncomparative belief relation can be represented by a unique\nprobability function. Having done so, he could rely on the vNM\nrepresentation theorem to show that an agent who satisfies all six\n axioms[7]\n can be represented as maximising expected utility, relative to a\nunique probability function that plausibly represents the\nagent’s beliefs over the states and a cardinal utility function\nthat plausibly represents the agent’s desires for ultimate\noutcomes (recall the statement of Savage’s theorem\n above).[8]\n Savage’s own proof is rather complicated, but Kreps (1988)\nprovides a useful illustration of it. \nThere is no doubt that Savage’s expected utility\nrepresentation theorem is very powerful. There are, however, two\nimportant questions to ask about whether Savage achieves his aims: 1)\nDoes Savage characterise rational preferences, at least in\nthe generic sense? And 2) Does Savage’s theorem tell us how to\nmake rational decisions in the real world? Savage’s theory has\nproblems meeting these two demands, taken together. Arguably the core\nweakness of the theory is that its various constraints and assumptions\npull in different directions when it comes to constructing realistic\ndecision models, and furthermore, at least one constraint (notably,\nthe Sure Thing Principle) is only plausible under decision modelling\nassumptions that are supposed to be the output, not the input, of the\ntheory. \nOne well recognised decision-modelling requirement for Savage’s\ntheory is that outcomes be maximally specific in every way that\nmatters for their evaluation. If this were not the case, the axiom of\nState Neutrality, for instance, would be a very implausible\nrationality constraint. Suppose we are, for example, wondering whether\nto buy cocoa or lemonade for the weekend, and assume that how good we\nfind each option depends on what the weather will be like. Then we\nneed to describe the outcomes such that they include the state of the\nweather. For if we do not, the desirability of the outcomes will\ndepend on what state is actual. Since lemonade is, let us suppose,\nbetter on hot days than cold, an outcome like “I drink lemonade\nthis weekend” would be more or less desirable depending on\nwhether it occurs in a state where it is hot or cold. This would be\ncontrary to the axiom of State Neutrality. Therefore, the appropriate\noutcomes in this case are those of the form “I drink lemonade\nthis weekend in hot weather”. (Of course, this outcome must be\nsplit into even more fine-grained outcomes if there are yet further\nfeatures that would affect the choice at hand, such as sharing the\ndrink with a friend who loves lemonade versus sharing the drink with a\nfriend who loves hot cocoa, and so on.) \nThe fact that the outcomes in the above case must be specific enough\nto contain the state of the weather may seem rather innocuous.\nHowever, this requirement exacerbates the above-mentioned problem that\nmany of the options/acts that Savage requires for his representation\ntheorem are nonsensical, in that the semantic content of state/outcome\npairs is contradictory. Recall that the domain of the preference\nordering in Savage’s theory amounts to every function\nfrom the set of states to the set of outcomes (what Broome 1991a\nrefers to as the Rectangular Field Assumption). So if\n“I drink lemonade this weekend in hot weather” is one of\nthe outcomes we are working with, and we have partitioned the set of\nstates according to the weather, then there must, for instance, be an\nact that has this outcome in the state where it is cold! The more\ndetailed the outcomes (as required for the plausibility of State\nNeutrality), the less plausible the Rectangular Field Assumption. This\nis an internal tension in Savage’s framework. Indeed, it is\ndifficult to see how/why a rational agent can/should form preferences\nover nonsensical acts (although see Dreier 1996 for an argument that\nthis is not such an important issue). Without this assumption,\nhowever, the agent’s preference ordering will not be adequately\nrich for Savage’s rationality constraints to yield the EU\nrepresentation\n result.[9] \nThe axiom in Savage’s theory that has received most attention is\nthe Sure Thing Principle. It is not hard to see that this principle\nconflicts with Allais’ preferences for the same reason these\npreferences conflict with Independence (recall\n Section 2.3).\n Allais’ challenge will be discussed again later. For now, our\nconcern is rather the Sure Thing Principle vis-à-vis the\ninternal logic of Savage’s theory. To begin with, the Sure Thing\nPrinciple, like State Neutrality, exacerbates concerns about the\nRectangular Field Assumption. This is because the Sure Thing Principle\nis only plausible if outcomes are specific enough to account for any\nsort of dependencies between outcomes in different states of the\nworld. For instance, if the fact that one could have chosen a\nrisk-free alternative—and thereby guaranteed an acceptable\noutcome—makes a difference to the desirability of receiving\nnothing after having taken a risk (as in Allais’ problem), then\nthat has to be accounted for in the description of the outcomes. But\nagain, if we account for such dependencies in the description of the\noutcomes, we run into the problem that there will be acts in the\npreference ordering that are nonsensical (see, e.g., Broome 1991a: ch.\n5). \nThere is a further internal problem with Savage’s theory\nassociated with the Sure Thing Principle: the principle is only\nreasonable when the decision model is constructed such that there is\nprobabilistic independence between the acts an agent is considering\nand the states of the world that determine the outcomes of these acts.\nRecall that the principle states that if we have four options with the\nfollowing form:  \nthen if \\(g\\) is weakly preferred to \\(f\\), \\(g'\\) must be weakly\npreferred to \\(f'\\). Suppose, however, that there is probabilistic\ndependency between the states of the world and the alternatives we are\nconsidering, and that we find \\(Z\\) to be better than both \\(X\\) and\n\\(Y\\), and we also find \\(W\\) to be better than both \\(X\\) and \\(Y\\).\nMoreover, suppose that \\(g\\) makes \\(\\neg E\\) more likely than \\(f\\)\ndoes, and \\(f'\\) makes \\(\\neg E\\) more likely than \\(g'\\) does. Then\nit seems perfectly reasonable to prefer \\(g\\) over \\(f\\) but \\(f'\\)\nover \\(g'\\). \nWhy is the requirement of probabilistic independence problematic? For\none thing, in many real-world decision circumstances, it is hard to\nframe the decision model in such a way that states are intuitively\nprobabilistically independent of acts. For instance, suppose an agent\nenjoys smoking, and is trying to decide whether to quit or not. How\nlong she lives is amongst the contingencies that affect the\ndesirability of smoking. It would be natural to partition the set of\nstates according to how long the agent lives. But then it is obvious\nthat the options she is considering could, and arguably should, affect\nhow likely she finds each state of the world, since it is well\nrecognised that life expectancy is reduced by smoking. Savage would\nthus require an alternative representation of the decision\nproblem—the states do not reference life span directly, but\nrather the agent’s physiological propensity to react in a\ncertain way to smoking. \nPerhaps there is always a way to contrive decision models such that\nacts are intuitively probabilistically independent of states. But\ntherein lies the more serious problem. Recall that Savage was trying\nto formulate a way of determining a rational agent’s beliefs\nfrom her preferences over acts, such that the beliefs can ultimately\nbe represented by a probability function. If we are interested in\nreal-world decisions, then the acts in question ought to be\nrecognisable options for the agent (which we have seen is\nquestionable). Moreover, now we see that one of Savage’s\nrationality constraints on preference—the Sure Thing\nPrinciple—is plausible only if the modelled acts are\nprobabilistically independent of the states. In other words, this\nindependence must be built into the decision model if it is to\nfacilitate appropriate measures of belief and desire. But this is to\nassume that we already have important information about the beliefs of\nthe agent whose attitudes we are trying to represent; namely what\nstate-partitions she considers probabilistically independent of her\nacts. \nThe above problems suggest there is a need for an alternative theory\nof choice under uncertainty. Richard Jeffrey’s theory, which\nwill be discuss next, avoids all of the problems that have been\ndiscussed so far. But as we will see, Jeffrey’s theory has\nwell-known problems of its own, albeit problems that are not\ninsurmountable. \nRichard Jeffrey’s expected utility theory differs from\nSavage’s in terms of both the prospects (i.e., options)\nunder consideration and the rationality constraints on\npreferences over these prospects. The distinct advantage of\nJeffrey’s theory is that real-world decision problems can be\nmodelled just as the agent perceives them; the plausibility of the\nrationality constraints on preference do not depend on decision\nproblems being modelled in a particular way. We first describe the\nprospects or decision set-up and the resultant expected utility rule,\nbefore turning to the pertinent rationality constraints on preferences\nand the corresponding theorem. \nUnlike Savage, Jeffrey does not make a distinction between the objects\nof instrumental and non-instrumental desire (acts and outcomes\nrespectively) and the objects of belief (states of the world). Rather,\nJeffrey assumes that propositions describing states of\naffairs are the objects of both desire and belief. On first sight,\nthis seems unobjectionable: just as we can have views about whether it\nwill in fact rain, we can also have views about how desirable that\nwould be. The uncomfortable part of this setup is that acts, too, are\njust propositions—they are ordinary states of affairs about\nwhich an agent has both beliefs and desires. Just as the agent has a\npreference ordering over, say, possible weather scenarios for the\nweekend, she has a preference ordering over the possible acts that she\nmay perform, and in neither case is the most preferred state of\naffairs necessarily the most likely to be true. In other words, the\nonly thing that picks out acts as special is their substantive\ncontent—these are the propositions that the agent has the power\nto choose/make true in the given situation. It is as if the agent\nassesses her own options for acting from, rather, a third-person\nperspective. If one holds that a decision model should convincingly\nrepresent the subjective perspective of the agent in question, this is\narguably a weakness of Jeffrey’s theory, although it may be one\nwithout\n consequence.[10] \nBefore proceeding, a word about propositions may be helpful: they are\nabstract objects that can be either true or false, and are commonly\nidentified with sets of possible worlds. A possible world can be\nthought of as an abstract representation of how things are or could be\n(Stalnaker 1987; see also entry on\n possible worlds).\n The proposition that it rains at time \\(t\\), for example, is just the\nset of all worlds where it rains at time \\(t\\). And this particular\nproposition is true just in case the actual world happens to be a\nmember of the set of all worlds where it rains at time \\(t\\).  \nThe basic upshot of Jeffrey’s theory is that the desirability of\na proposition, including one representing acts, depends both on the\ndesirabilities of the different ways in which the proposition can be\ntrue, and the relative probability that it is true in these respective\nways. To state this more precisely, \\(p\\), \\(q\\), etc., will denote\npropositional variables. Let \\(\\{p_1, p_2, …, p_n\\}\\) be one\namongst many finite partitions of the proposition \\(p\\); that is, sets\nof mutually incompatible but jointly exhaustive ways in which the\nproposition \\(p\\) can be realised. For instance, if \\(p\\) is the\nproposition that it is raining, then we could partition this\nproposition very coarsely according to whether we go to the beach or\nnot, but we could also partition \\(p\\) much more finely, for instance\naccording to the precise millimetres-per-hour amount of rain. The\ndesirability of \\(p\\) according to Jeffrey, denoted \\(Des(p)\\), is\ngiven by: \nJeffrey’s equation.\n\n\\(Des(p)=\\sum_i Des(p_i)\\cdot P(p_i\\mid p)\\)  \nThis is effectively a conditional expected utility formula\nfor evaluating \\(p\\). As noted, a special case is when the content of\n\\(p\\) is such that it is recognisably something the agent can choose\nto make true, i.e., an act. \nOne important difference between Jeffrey’s desirability formula\nand Savage’s expected utility formula, is that there is no\ndistinction made between desirability and “expected”\ndesirability, unlike what has to be done in Savage’s theory,\nwhere there is a clear distinction between utility, measuring an\nagent’s fundamental desires for ultimate outcomes, and expected\nutility, measuring an agent’s preferences over uncertain\nprospects or acts. This disanalogy is due to the fact that there is no\nsense in which the \\(p_i\\)s that \\(p\\) is evaluated in terms of need\nto be ultimate outcomes; they can themselves be thought of as\nuncertain prospects that are evaluated in terms of their different\npossible realisations. \nAnother important thing to notice about Jeffrey’s way of\ncalculating desirability, is that it does not assume probabilistic\nindependence between the alternative that is being evaluated, \\(p\\),\nand the possible ways, the \\(p_i\\)s, that the alternative may be\nrealised. Indeed, the probability of each \\(p_i\\) is explicitly\nconditional on the \\(p\\) in question. When it comes to evaluating\nacts, this is to say (in Savage’s terminology) that the\nprobabilities for the possible state-outcome pairs for the act are\nconditional on the act in question. Thus we see why the agent can\ndescribe her decision problem just as she sees it; there is no\nrequirement that she identify a set of states (in Jeffrey’s\ncase, this would be a partition of the proposition space that is\northogonal to the act partition) such that the states are\nappropriately fine-grained and probabilistically independent of the\nacts. \nIt should moreover be evident, given the discussion of the Sure Thing\nPrinciple (STP) in\n Section 3.1,\n that Jeffrey’s theory does not have this axiom. Since states\nmay be probabilistically dependent on acts, an agent can be\nrepresented as maximising the value of Jeffrey’s desirability\nfunction while violating the STP. Moreover, unlike Savage’s,\nJeffrey’s representation theorem does not depend on anything\nlike the Rectangular Field Assumption. The agent is not required to\nhave preferences over artificially constructed acts or propositions\nthat turn out to be nonsensical, given the interpretation of\nparticular states and outcomes. In fact, only those propositions the\nagent considers to be possible (in the sense that she assigns them a\nprobability greater than zero) are, according to Jeffrey’s\ntheory, included in her preference ordering. \nOf course, we still need certain structural assumptions in order to\nprove a representation theorem for Jeffrey’s theory. In\nparticular, the set \\(\\Omega\\), on which the preference ordering\n\\(\\preceq\\) is defined, has to be an atomless Boolean algebra\nof propositions, from which the impossible propositions, denoted\n\\(\\bot\\), have been removed. A Boolean algebra is just a set of e.g.\npropositions or sentences that is closed under the classical logical\noperators and negation. An algebra is atomless just in case all of its\nelements can be partitioned into finer elements. The assumption that\n\\(\\Omega\\) is atomless is thus similar to Savage’s\n P6,\n and can be given a similar justification: any way \\(p_i\\) in which\n\\(p\\) can be true can be partitioned into two further propositions\naccording to how some coin would land if tossed. \nSo under what conditions can a preference relation \\(\\preceq\\) on the\nset \\(\\Omega\\) be represented as maximising desirability? Some of the\nrequired conditions on preference should be familiar by now and will\nnot be discussed further. In particular, \\(\\preceq\\) has to be\ntransitive, complete and continuous (recall our discussion in\n Section 2.3\n of vNM’s Continuity preference axiom). \nThe next two conditions are, however, not explicitly part of the two\nrepresentation theorems that have been considered so far: \nAveraging\n\nIf \\(p,\\ q\\in \\Omega\\) are mutually incompatible, then \nImpartiality\n\nSuppose \\(p,\\ q\\in \\Omega\\) are mutually incompatible and \\(p\\sim q\\).\nThen if \\(p\\cup r\\sim q\\cup r\\) for some \\(r\\) that is\nmutually incompatible with both \\(p\\) and \\(q\\) and is such that\n\\(\\neg(r\\sim p)\\), then \\(p\\cup r\\sim q\\cup r\\) for every\nsuch \\(r\\). \nAveraging is the distinguishing rationality condition in\nJeffrey’s theory. It can actually be seen as a weak version of\nIndependence and the Sure Thing Principle, and it plays a similar role\nin Jeffrey’s theory. But it is not directly inconsistent with\nAllais’ preferences, and its plausibility does not depend on the\ntype of probabilistic independence that the STP implies. The postulate\nrequires that no proposition be strictly better or worse than all of\nits possible realisations, which seems to be a reasonable requirement.\nWhen \\(p\\) and \\(q\\) are mutually incompatible, \\(p\\cup q\\) implies\nthat either \\(p\\) or \\(q\\) is true, but not both. Hence, it seems\nreasonable that \\(p\\cup q\\) should be neither strictly more nor less\ndesirable than both \\(p\\) and \\(q\\). Suppose one of \\(p\\) or \\(q\\) is\nmore desirable than the other. Then since \\(p\\cup q\\) is compatible\nwith the truth of either the more or the less desirable of the two,\n\\(p\\cup q\\)’s desirability should fall strictly between that of\n\\(p\\) and that of \\(q\\). However, if \\(p\\) and \\(q\\) are equally\ndesirable, then \\(p\\cup q\\) should be as desirable as each of the\ntwo. \nThe intuitive appeal of Impartiality, which plays a similar role in\nJeffrey’s theory as P4 does in Savage’s, is not as great\nas that of Averaging. Jeffrey himself admitted as much in his comment:\n \nThe axiom is there because we need it, and it is justified by our\nantecedent belief in the plausibility of the result we mean to deduce\nfrom it. (1965: 147)  \nNevertheless, it does seem that an argument can be made that any\nreasonable person will satisfy this axiom. Suppose you are indifferent\nbetween two propositions, \\(p\\) and \\(q\\), that cannot be\nsimultaneously true. And suppose now we find a proposition \\(r\\), that\nis pairwise incompatible with both \\(p\\) and \\(q\\), and which you find\nmore desirable than both \\(p\\) and \\(q\\). Then if it turns out that\nyou are indifferent between \\(p\\) joined with \\(r\\) and \\(q\\) joined\nwith \\(r\\), that must be because you find \\(p\\) and \\(q\\) equally\nprobable. Otherwise, you would prefer the union that contains the one\nof \\(p\\) and \\(q\\) that you find less probable, since that gives you a\nhigher chance of the more desirable proposition \\(r\\). It then follows\nthat for any other proposition \\(s\\) that satisfies the aforementioned\nconditions that \\(r\\) satisfies, you should also be indifferent\nbetween \\(p\\cup s\\) and \\(q\\cup s\\), since, again, the two unions are\nequally likely to result in \\(s\\). \nThe first person to prove a theorem stating sufficient conditions for\na preference relation to be representable as maximising the value of a\nJeffrey-desirability function was actually not Jeffrey himself, but\nthe mathematician Ethan Bolker (1966, 1967). He proved the following\nresult (recall the definition of a “desirability measure”\ngiven\n above):[11] \nTheorem 4 (Bolker)\n\nLet \\(\\Omega\\) be a complete and atomless Boolean algebra of\npropositions, and \\(\\preceq\\) a continuous, transitive and complete\nrelation on \\(\\Omega \\setminus \\bot \\), that satisfies Averaging and\nImpartiality. Then there is a desirability measure on \\(\\Omega\n\\setminus \\bot \\) and a probability measure on \\(\\Omega\\) relative to\nwhich \\(\\preceq\\) can be represented as maximising desirability. \nUnfortunately, Bolker’s representation theorem does not yield a\nresult anywhere near as unique as Savage’s. Even if a\nperson’s preferences satisfy all the conditions in\nBolker’s theorem, then it is neither guaranteed that there will\nbe just one probability function that represents her beliefs nor that\nthe desirability function that represents her desires will be unique\nup to a positive linear transformation (unless her preferences are\nunbounded). Even worse, the same preference ordering satisfying all\nthese axioms could be represented as maximising desirability relative\nto two probability functions that do not even agree on how to order\npropositions according to their\n probability.[12] \nFor those who think that the only way to determine a person’s\ncomparative beliefs is to look at her preferences, the lack of\nuniqueness in Jeffrey’s theory is a big problem. Indeed, this\nmay be one of the main reasons why economists have largely ignored\nJeffrey’s theory. Economists have traditionally been skeptical\nof any talk of a person’s desires and beliefs that goes beyond\nwhat can be established by examining the person’s preferences,\nwhich they take to be the only attitude that is directly revealed by a\nperson’s behaviour. For these economists, it is therefore\nunwelcome news if we cannot even in principle determine the\ncomparative beliefs of a rational person by looking at her\npreferences. \nThose who are less inclined towards behaviourism might, however, not\nfind this lack of uniqueness in Bolker’s theorem to be a\nproblem. James Joyce (1999), for instance, thinks that Jeffrey’s\ntheory gets things exactly right in this regard, since one should not\nexpect that reasonable conditions imposed on a person’s\npreferences would suffice to determine a unique probability function\nrepresenting the person’s beliefs. It is only by imposing overly\nstrong conditions, as Savage does, that we can achieve this. However,\nif uniqueness is what we are after, then we can, as Joyce points out,\nsupplement the Bolker-Jeffrey axioms with certain conditions on the\nagent’s comparative belief relation (e.g. those proposed by\nVillegas 1964) that, together with the Bolker-Jeffrey axioms, ensure\nthat the agent’s preferences can be represented by a unique\nprobability function and a desirability function that is unique up to\na positive linear transformation. \nInstead of adding specific belief-postulates to Jeffrey’s\ntheory, as Joyce suggests, one can get the same uniqueness result by\nenriching the set of prospects. Richard Bradley (1998) has, for\ninstance, shown that if one extends the Boolean algebra in\nJeffrey’s theory to indicative conditionals, then a preference\nrelation on the extended domain that satisfies the Bolker-Jeffrey\naxioms (and some related axioms that specifically apply to\nconditionals) will be representable as maximising desirability, where\nthe probability function is unique and the desirability function is\nunique up to a positive linear transformation. \nIt was noted from the outset that EU theory is as much a theory of\nrational choice, or overall preferences amongst acts, as it is a\ntheory of rational belief and desire. This section expands, in turn,\non the epistemological and evaluative commitments of EU theory. \nSome refer to EU theory as Bayesian decision theory. This\nlabel brings to the forefront the commitment to probabilism,\ni.e., that beliefs may come in degrees which, on pain of\nirrationality, can be represented numerically as probabilities. So\nthere is a strong connection between EU theory and probabilism, or\nmore generally between rational preference and rational belief. (The\nfiner details of rational preference and associated rational belief\nare not the focus here; challenges to EU theory on this front are\naddressed in\n Section 5\n below.) \nSome take the connection between rational preference and rational\nbelief to run very deep indeed. At the far end of the spectrum is the\nposition that the very meaning of belief involves preference. Indeed,\nrecall this manoeuvre in Savage’s theory, discussed earlier in\n Section 3.1.\n Many question the plausibility, however, of equating comparative\nbelief with preferences over specially contrived prospects. A more\nmoderate position is to regard these preferences as entailed by, but\nnot identical with, the relevant comparative beliefs. Whether or not\nbeliefs merely ground or are defined in terms of preference, there is\na further question as to whether the only justification for rational\nbelief having a certain structure (say, conforming to the probability\ncalculus) is a pragmatic one, i.e., an argument resting on the\nagent’s preferences being otherwise inconsistent or\nself-defeating. A recent defender of this kind of pragmatism (albeit\ncast in more general terms) is Rinard (e.g., 2017). Others contend\nthat accounts of rational belief can and should be ultimately\njustified on epistemic grounds; Joyce (1998), for instance, offers a\nnon-pragmatic justification of probabilism that rests on the notion of\noverall “distance from the truth” of one’s beliefs.\n(For further developments of this position, see the entry on\n epistemic utility arguments for probabilism.) \nNotwithstanding these finer disputes, Bayesians agree that pragmatic\nconsiderations play a significant role in managing beliefs. One\nimportant way, at least, in which an agent can interrogate her degrees\nof belief is to reflect on their pragmatic implications. Furthermore,\nwhether or not to seek more evidence is a pragmatic issue; it depends\non the “value of information” one expects to gain with\nrespect to the decision problem at hand. The idea is that seeking more\nevidence is an action that is choice-worthy just in case the expected\nutility of seeking further evidence before making one’s decision\nis greater than the expected utility of making the decision on the\nbasis of existing evidence. This reasoning was made prominent in a\npaper by Good (1967), where he proves that one should always seek\n“free evidence” that may have a bearing on the decision at\nhand. (Precursors of this theorem can be found in Ramsey 1990,\npublished posthumously, and Savage 1954.) Note that the theorem\nassumes the standard Bayesian learning rule known as\n“conditionalisation”, which requires that when one’s\nlearning experience has the form of coming to know some proposition\n(to which one had assigned positive probability) for sure, one’s\nnew degrees of belief should be equal to one’s old degrees of\nbelief conditional on the proposition that now has probability one.\nIndeed, the fact that conditionalisation plays a crucial role in\nGood’s result about the non-negative value of free evidence is\ntaken by some as providing some justification for this learning\nrule. \nSo EU theory or Bayesian decision theory underpins a powerful set of\nepistemic norms. It has been taken as the appropriate account of\nscientific inference, giving rise to a school of statistical inference\nand experimental design and inviting formal interpretations of key\nconcepts like “evidence”, “evidential\nsupport”, “induction” versus\n“abduction”, and the bearing of “coherence”\nand “explanatory power” on truth (see the relevant\n related entries).\n The major competitor to Bayesianism, as regards scientific inference,\nis arguably the collection of approaches known as Classical or Error\nstatistics, which deny the sense of “degrees of support”\n(probabilistic or otherwise) conferred on a hypothesis by evidence.\nThese approaches focus instead on whether a hypothesis has survived\nvarious “severe tests”, and inferences are made with an\neye to the long-run properties of tests as opposed to how they perform\nin any single case, which would require decision-theoretic reasoning\n(see the entry on\n philosophy of statistics). \nEU theory takes a stance on the structure of rational desire too. In\nthis regard, the theory has been criticised on opposing fronts. We\nconsider first the criticism that EU theory is too permissive with\nrespect to what may influence an agent’s desires. We then turn\nto the opposing criticism: that when it comes to desire, EU theory is\nnot permissive enough. \nThe worry that EU theory is too permissive with respect to desire is\nrelated to the worry that the theory is unfalsifiable. The\nworry is that apparently irrational preferences by the lights of EU\ntheory can always be construed as rational, under a suitable\ndescription of the options under consideration. As discussed in\n Section 1\n above, preferences that seem to violate Transitivity can be construed\nas consistent with this axiom so long as the options being compared\nvary in their description depending on, amongst other things, the\nother options under consideration. The same goes for preferences that\nseem to violate Separability or Independence (of the contribution of\neach outcome to the overall value of an option), discussed further in\n Section 5.1\n below. One might argue that this is the right way to describe such\nagents’ preferences. After all, an apt model of preference is\nsupposedly one that captures, in the description of final outcomes and\noptions, everything that matters to an agent. In that case, however,\nEU theory is effectively vacuous or impotent as a standard of\nrationality to which agents can aspire. Moreover, it stretches the\nnotion of what are genuine properties of outcomes that can reasonably\nconfer value or be desirable for an agent. \nThere are two ways one can react to the idea that an agent’s\npreferences are necessarily consistent with EU theory, with the\nabove-mentioned implications for what the agent may desire: \nOne can resist the claim, asserting that there are additional\nconstraints on the content of an agent’s preferences.\nOn the one hand there may be empirical constraints whereby the content\nof preferences is determined by some tradeoff between fit and\nsimplicity in representing the agent’s greater “web”\nof preference attitudes. On the other hand there may be normative\nconstraints with respect to what sorts of outcomes an agent may\nreasonably discriminate (for relevant discussion, see Tversky 1975;\nBroome 1991a & 1993; Pettit 1993; Dreier 1996; Guala 2006;\nVredenburgh 2020). \nOne can alternatively embrace the claim, interpreting EU theory not as\na standard against which an agent may pass or fail, but rather as an\norganising principle that enables the characterisation of an\nagent’s desires as well as her beliefs (see esp. Guala\n2008). \nEither way, it may yet be argued that EU theory does not go far enough\nin structuring an agent’s preference attitudes so that we may\nunderstand the reasons for these preference attitudes.\nDietrich and List (2013 & 2016a) have proposed a more general\nframework that fills this lacuna. In their framework, preferences\nsatisfying some minimal constraints are representable as dependent on\nthe bundle of properties in terms of which each option is perceived by\nthe agent in a given context. Properties can, in turn, be categorised\nas either option properties (which are intrinsic to the\noutcome), relational properties (which concern the outcome in\na particular context), or context properties (which concern\nthe context of choice itself). Such a representation permits more\ndetailed analysis of the reasons for an agent’s preferences and\ncaptures different kinds of context-dependence in an agent’s\nchoices. Furthermore, it permits explicit restrictions on what counts\nas a legitimate reason for preference, or in other words, what\nproperties legitimately feature in an outcome description; such\nrestrictions may help to clarify the normative commitments of EU\ntheory. \nThere are also less general models that offer templates for\nunderstanding the reasons underlying preferences. For instance, the\nmultiple criteria decision framework (see, for instance,\nKeeney and Raiffa 1993) takes an agent’s overall preference\nordering over options to be an aggregate of the set of preference\norderings corresponding to all the pertinent dimensions of value.\nUnder certain assumptions, the overall or aggregate preference\nordering is compatible with EU theory. One might otherwise seek to\nunderstand the role of time, or the temporal position of goods, on\npreferences. To this end, outcomes are described in terms of\ntemporally-indexed bundles of goods, or consumption streams\n(for an early model of this kind see Ramsey 1928; a later influential\ntreatment is Koopmans 1960). There may be systematic structure to an\nagent's preferences over these consumption streams, over and above the\nstructure imposed by the EU axioms of preference. For instance, the\naforementioned authors considered and characterised preferences that\nexhibit exponential time discounting. \nLet’s turn now to the opposing kind of criticism: that the\nlimited constraints that EU theory imposes on rational preference and\ndesire are nonetheless overly restrictive. Here the focus will be on\nthe compatibility of EU theory with prominent ethical positions\nregarding the choice-worthiness of acts, as well as meta-ethical\npositions regarding the nature of value and its relationship to\nbelief. \nOne may well wonder whether EU theory, indeed decision theory more\ngenerally, is neutral with respect to normative ethics, or whether it\nis compatible only with ethical consequentialism, given that\nthe ranking of an act is fully determined by the utility of its\npossible outcomes. Such a model seems at odds with\nnonconsequentialist ethical theories for which the\nchoice-worthiness of acts purportedly depends on more than the moral\nvalue of their consequences. The model does not seem able to\naccommodate basic deontological notions like agent relativity,\nabsolute prohibitions or permissible and yet suboptimal acts. \nAn initial response, however, is that one should not read too much\ninto the formal concepts of decision theory. The utility measure over\nacts and outcomes is simply a convenient way to represent an ordering,\nand leaves much scope for different ways of identifying and evaluating\noutcomes. Just as an agent’s utility function need not be\ninsensitive to ethical considerations in general (a common\nmisconception due to the prevalence of selfish preferences in economic\nmodels; see, for instance, Sen 1977), nor need it be insensitive to\nspecifically nonconsequentialist or deontological ethical\nconsiderations. It all depends on how acts and their outcomes are\ndistinguished and evaluated. For starters, the character of an act may\nfeature as a property of all its possible outcomes. Moreover, whether\nsome event befalls or is perpetrated by the deciding agent or rather\nsomeone else may be relevant. That an act involves lying, say, can be\nreferenced in all possible outcomes of the act, and furthermore this\nlying on the part of the deciding agent can be distinguished from the\nlying of others. In general, acts and their outcomes can be\ndistinguished according to whatever matters morally, be it a complex\nrelational property to do with how and when the act is chosen, by\nwhom, and/or in what way some state of affairs results from the act.\nFor early discussions on how a wide range of ethical properties can be\naccommodated in the description of acts and outcomes, see, for\ninstance, Sen (1982), Vallentyne (1988), Broome (1991b) and Dreier\n(1993). This idea has since been embraced by others associated with\nthe so-called “consequentializing” program, including\nLouise (2004) and Portmore (2007). The idea is that the normative\nadvice of putatively nonconsequentialist ethical theories can be\nrepresented in terms of a ranking of acts/outcomes corresponding to\nsome value function, as per consequentialist ethical theories (see too\nColyvan et al. 2010). \nA sticking point for reconciling decision theory with all forms of\nnonconsequentialism is the difficulty in accommodating absolute\nprohibitions or side constraints (see Oddie and Milne\n1999; Jackson and Smith 2006). For instance, suppose there is a moral\nprohibition against killing an innocent person, whatever else is at\nstake. Perhaps such a constraint is best modelled in terms of a\nlexical ranking and corresponding value function, whereby the\nkilling-innocents status of an act/outcome takes priority in\ndetermining its relative rank/value. But this has counterintuitive\nimplications in the face of risk since very many acts will have some\nchance, however small, of killing an innocent. The lesson here may\nsimply be that the theories in question require development; any\nmature ethical theory owes us an account of how to act under risk or\nuncertainty. What is arguably a more compelling challenge for the\nreconciliation of decision theory and nonconsequentialism is the\naccommodation of “agent-centred options” and associated\n“supererogation”. Portmore (e.g., 2007) and Lazar (e.g.,\n2017) offer proposals to this effect, which appeal (in different ways)\nto the moral ranking of acts/outcomes as distinct from the personal\ncosts to the agent of pursuing these acts/outcomes. \nTo the extent that decision theory can be reconciled with the full\nrange of ethical theories, should we say that there are no meaningful\ndistinctions between these theories? Brown (2011) and Dietrich and\nList (2017) demonstrate that in fact the choice-theoretic\nrepresentation of ethical theories better facilitates distinctions\nbetween them; terms like “(non)consequentialism” can be\nprecisely defined, albeit in debatable ways. More generally, we can\ncatalogue theories in terms of the kinds of properties (whether\nintrinsic or in some sense relational) that distinguish acts/outcomes\nand also in terms of the nature of the ranking of acts/outcomes that\nthey yield (whether transitive, complete, continuous and so on). This\nalso serves to reveal departures from EU theory. \nIndeed, some of the most compelling counterexamples to EU axioms of\npreference rest on ethical considerations. Recall our earlier\ndiscussion of the basic Ordering axioms in\n Section 1.\n The Transitivity axiom has been challenged by appeal to\nethically-motivated examples of preference cycles (see Temkin 2012).\nThe notion of a non-continuous lexical ordering was mentioned above in\nrelation to ethical side constraints. The dispensability of the\nCompleteness axiom, too, is often motivated by appeal to examples\ninvolving competing ethical values that are difficult to tradeoff\nagainst each other, like average versus total welfare. Other\nsuggestive examples against Completeness involve competing notions of\npersonal welfare (see, e.g., Levi 1986; Chang 2002). Must a rational\nagent have a defined preference between, say, two career options that\npull in different directions as regards opportunities for creative\nself-expression versus community service (perhaps a career as a dancer\nversus a career as a doctor in remote regions)? Note that some of\nthese challenges to EU theory are discussed in more depth in\n Section 5\n below. \nFinally, we turn to the potential meta-ethical commitments of EU\ntheory. David Lewis (1988, 1996) famously employed EU theory to argue\nagainst anti-Humeanism, the position that we are sometimes\nmoved entirely by our beliefs about what would be good, rather than by\nour desires as the Humean claims. He formulated the anti-Humean theory\nas postulating a necessary connection between, on the one hand, an\nagent’s desire for any proposition \\(A\\), and, on the other\nhand, her belief in a proposition about \\(A\\)’s goodness; and\nclaimed to prove that when such a connection is formulated in terms of\nEU theory, the agent in question will be dynamically incoherent.\nSeveral people have criticised Lewis’s argument. For instance,\nBroome (1991c), Byrne and Hájek (1997) and Hájek and\nPettit (2004) suggest formulations of anti-Humeanism that are immune\nto Lewis’ criticism, while Stefánsson (2014) and Bradley\nand Stefánsson (2016) argue that Lewis’ proof relies on a\nfalse assumption. Nevertheless, Lewis’ argument no doubt\nprovoked an interesting debate about the sorts of connections between\nbelief and desire that EU theory permits. There are, moreover, further\nquestions of meta-ethical relevance that one might investigate\nregarding the role and structure of desire in EU theory. For instance,\nJeffrey (1974) and Sen (1977) offer some preliminary investigations as\nto whether the theory can accommodate higher-order\ndesires/preferences, and if so, how these relate to first-order\ndesires/preferences. \nThus far the focus has been on prominent versions of the standard\ntheory of rational choice: EU theory. This section picks up on some\nkey criticisms of EU theory that have been developed into alternative\naccounts of rational choice. The proposed innovations to the standard\ntheory are distinct and so are discussed separately, but they are not\nnecessarily mutually exclusive. Note that we do not address all\ncriticisms of EU theory that have inspired alternative accounts of\nrational choice. Two major omissions of this sort (for want of space\nand also because they have been thoroughly addressed in alternative\nentries of this encyclopedia) are i) the problem of causal anomalies\nand the development of causal decision theory (see the entry on\n causal decision theory),\n and ii) the problem of infinite state spaces and the development of\nalternatives like “relative expectation theory” (see the\nentries on\n normative theories of rational choice: expected utility theory\n and\n the St. Petersburg paradox). \nExpected utility theory has been criticised for not allowing for value\ninteractions between outcomes in different, mutually incompatible\nstates of the world. For instance, recall that when deciding between\ntwo risky options you should, according to Savage’s version of\nthe theory, ignore the states of the world where the two options\nresult in the same outcome. That seems very reasonable if we can\nassume separability between outcomes in different states of\nthe world, i.e., if the contribution that an outcome in one state of\nthe world makes towards the overall value of an option is independent\nof what other outcomes the option might result in. For then identical\noutcomes (with equal probabilities) should cancel each other out in a\ncomparison of two options, which would entail that if two options\nshare an outcome in some state of the world, then when comparing the\noptions, it does not matter what that shared outcome is. \nThe Allais paradox, discussed in\n Section 2.3\n above, is a classic example where the aforementioned separability\nseems to fail. For ease of reference, the options that generate the\nparadox are reproduced as Table 3. Recall from\n Section 2.3\n that people tend to prefer \\(L_2\\) over \\(L_1\\) and \\(L_3\\) over\n\\(L_4\\)—an attitude that has been called Allais’\npreferences—in violation of expected utility theory. The\nviolation occurs precisely because the contributions that some of\nthese outcomes make towards the overall value of an option is not\nindependent of the other outcomes that the option can have. Compare\nthe extra chance of outcome $0 that \\(L_1\\) has over \\(L_2\\) with the\nsame extra chance of $0 that \\(L_3\\) has over \\(L_4\\). Many people\nthink that this extra chance counts more heavily in the first\ncomparison than the latter, i.e., that an extra 0.01 chance of $0\ncontributes a greater negative value to \\(L_1\\) than to \\(L_3\\). Some\nexplain this by pointing out that the regret one would\nexperience by winning nothing when one could have had $2400 for\nsure—i.e., when choosing \\(L_1\\) over \\(L_2\\) and the first\nticket is drawn—is much greater than the regret one would\nexperience by winning nothing when the option one turned down also had\na high chance of resulting in $0—such as when choosing \\(L_3\\)\nover \\(L_4\\) (see, e.g., Loomes and Sugden 1982). But whether or not\nthe preference in question should be explained by the potential for\nregret, it would seem that the desirability of the $0-outcome depends\non what could (or would) otherwise have been; in violation of the\naforementioned assumption of separability. (See Thoma 2020a for a\nrecent extensive discussion of this assumption.)  \nTable 3. Allais’ paradox \nVarious attempts have been made to make Allais’ preferences\ncompatible with some version of expected utility theory. A common\nresponse is to suggest that the choice problem has been incorrectly\ndescribed. If it really is rational to evaluate $0 differently\ndepending on which lottery it is part of, then perhaps this should be\naccounted for in the description of the outcomes (Broome 1991a). For\ninstance, we could add a variable to the $0 outcome that \\(L_1\\) might\nresult in to represent the extra regret or risk associate with that\noutcome compared to the $0 outcomes from the other lotteries (as done\nin\n Table 4).\n If we do that, Allais’ preferences are no longer inconsistent\nwith EU theory. The simplest way to see this is to note that when we\nignore the state of the world where the options that are being\ncompared have the same outcome (i.e., when we ignore the last column\nin Table 4), \\(L_1\\) is no longer identical to \\(L_3\\), which means\nthat the Independence axiom of von Neumann and Morgenstern (and\nSavage’s Sure Thing Principle) no longer requires that one\nprefer \\(L_2\\) over \\(L_1\\) only if one prefers \\(L_4\\) over\n\\(L_3\\). \nTable 4. Allais’ paradox\nre-described \nThe above “re-description strategy” could be employed\nwhenever the value and/or contribution of an outcome depends on other\npossible outcomes: just describe the outcomes in a way that accounts\nfor this dependency. But more worryingly, the strategy could be\nemployed whenever one comes across any violation of expected\nutility theory or other theories of rationality (as discussed in\n Section 4.2).\n  \nLara Buchak (2013) has recently developed a decision theory that can\naccommodate Allais’ preferences without re-describing the\noutcomes. On Buchak’s interpretation, the explanation for\nAllais’ preferences is not the different value that the\noutcome $0 has depending on what lottery it is part of. The outcome\nitself has the same value. However, the contribution that $0\nmakes towards the overall value of an option partly depends on what\nother outcomes are possible, she suggests, which reflects the fact\nthat the option-risk that the possibility of $0 generates depends on\nwhat other outcomes the option might result in. To accommodate\nAllais’ preferences (and other intuitively rational attitudes to\nrisk that violate EU theory), Buchak introduces a risk\nfunction that represents people’s willingness to trade\nchances of something good for risks of something bad. And she shows\nthat if an agent satisfies a particular set of axioms, which is\nessentially Savage’s except that the Sure Thing Principle is\nreplaced with a strictly weaker one, then the agent’s\npreferences can be represented as maximising risk weighted\nexpected utility; which is essentially Savage-style expected\nutility weighted by a risk function. \nBradley and Stefánsson (2017) also develop a new decision\ntheory partly in response to the Allais paradox. But unlike Buchak,\nthey suggest that what explains Allais’ preferences is that the\nvalue of wining nothing from a chosen lottery partly depends on what\nwould have happened had one chosen differently. To accommodate this,\nthey extend the Boolean algebra in Jeffrey’s decision theory to\ncounterfactual propositions, and show that Jeffrey’s\nextended theory can represent the value-dependencies one often finds\nbetween counterfactual and actual outcomes. In particular, their\ntheory can capture the intuition that the (un)desirability of winning\nnothing partly depends on whether or not one was guaranteed to win\nsomething had one chosen differently. Therefore, their theory can\nrepresent Allais’ preferences as maximising the value of an\nextended Jeffrey-desirability function. \nStefánsson and Bradley (2019) suggest yet another way of\naccounting for Allais’ preferences in an extension of\nJeffrey’s decision theory; this time extended to chance\npropositions, that is, propositions describing objective\nprobability distributions. The general idea is that the desirability\nof a particular increase or decrease in the chance of some\noutcome—for instance, in the Allais case, a 0.01 increase in the\nchance of the $0-outcome—might depend on what the chances were\nbefore the increase or decrease. Stefánsson and Bradley’s\nextension of Jeffrey’s theory to chance propositions is also\nmotivated by the fact that standard decision theories do not\ndistinguish between risk aversion with respect to some good and\nattitudes to quantities of that good (which is found problematic by,\nfor instance, Hansson 1988, Rabin 2000, and Buchak 2013). \nAs noted in\n Section 4,\n criticisms of the EU requirement of a complete preference ordering\nare motivated by both epistemic and desire/value considerations. On\nthe value side, many contend that a rational agent may simply find two\noptions incomparable due to their incommensurable\nqualities. (Here a prominent usage of these terms will be followed,\nwhereby particular options may be described as incomparable in value,\nwhile general properties or dimensions of value may be described as\nincommensurable.) As in, the agent’s evaluations of the\ndesirability of sure options may not be representable by any precise\nutility function. Likewise, on the belief side, some contend (notably,\nJoyce 2010 and Bradley 2017) that the evidence may be such that it\ndoes not commit a rational agent to precise degrees of belief\nmeasurable by a unique probability function. \nThere are various alternative, “fuzzier” representations\nof desire and belief that might be deemed more suitable. Halpern\n(2003), for instance, investigates different ways of conceptualising\nand representing epistemic uncertainty, once we depart from\nprobabilities. Presumably there are also various ways to represent\nuncertain desire. Here the focus will be on just one proposal that is\npopular amongst philosophers: the use of sets of probability\nand utility functions to represent uncertainty in belief and desire\nrespectively. This is a minimal generalisation of the standard EU\nmodel, in the sense that probability and utility measures still\nfeature. Roughly, the more severe the epistemic uncertainty, the more\nprobability measures over the space of possibilities needed to\nconjointly represent the agent’s beliefs. This notion of\nrational belief is referred to as imprecise probabilism (see\nthe entry on\n imprecise probabilities).\n Likewise, the more severe the evaluative uncertainty, the more\nutility measures over the space of sure options needed to conjointly\nrepresent the agent’s desires. Strictly speaking, we should not\ntreat belief and desire separately, but rather talk of the\nagent’s incomplete preferences being represented by a set of\nprobability and utility pairs. Recall the requirement that incomplete\npreferences be coherently extendible (refer back to\n Section 1);\n on this representation, all the probability-utility pairs amount to\ncandidate extensions of the incomplete preferences. \nThe question then arises: Is there a conservative generalisation of\nthe EU decision rule that can handle sets of probability and utility\npairs? Contender decision rules are standardly framed in terms of\nchoice functions that take as input some set of feasible options and\nreturn as output a non-empty set of admissible choices that is a\nsubset of the feasible options. A basic constraint on these choice\nfunctions is that they respect the agent’s preferences in cases\nwhere options are in fact comparable. That is, if all pairs of\nprobability and utility functions characterising the agent’s\nattitudes agree on the ranking of two options, then these particular\noptions should be ranked accordingly. The relevant constraint on\nchoice functions is that “EU-dominated options” are not\nadmissible choices, i.e., if an option has lower expected utility than\nanother option according to all pairs of probability and utility\nfunctions, then the former dominated option is not an admissible\nchoice. Note that Levi (1986) has a slightly more restrictive\ncondition on admissibility: if an option does not have maximum EU for\nat least one pair of probability and utility functions, then it is not\nadmissible. In ordinary cases where sets of probability and utility\nfunctions are closed convex sets, however, Levi’s condition is\nequivalent to the aforementioned one that rules out EU-dominated\noptions (Schervish et al. 2003). \nThe treatment of genuinely incomparable options (those surviving the\nabove admissibility test and yet are not such that the agent is\nindifferent) is where the real controversies begin. See Bradley (2017)\nfor extensive discussion of the various ways to proceed. A\nconsideration that is often appealed to in order to discriminate\nbetween incomparable options is caution. The Maxmin-EU rule, for\ninstance, recommends picking the action with greatest minimum expected\nutility (see Gilboa and Schmeidler 1989; Walley 1991). The rule is\nsimple to use, but arguably much too cautious, paying no attention at\nall to the full spread of expected utilities. The \\(\\alpha\\)-Maxmin\nrule, by contrast, recommends taking the action with the greatest\n\\(\\alpha\\)-weighted sum of the minimum and maximum expected utilities\nassociated with it. The relative weights for the minimum and maximum\nexpected utilities can be thought of as reflecting either the decision\nmaker’s pessimism in the face of uncertainty or else her degree\nof caution (see Binmore 2009). \nThere are more complicated choice rules that depend on a richer\nrepresentation of uncertainty involving a notion of\nconfidence. For instance, Klibanoff et al. (2005) propose a\nrule whereby choices are made between otherwise incomparable options\non the basis of confidence-weighted expected utility. It presupposes\nthat weights can be assigned to the various expected utilities\nassociated with an act, reflecting the agent’s confidence in the\ncorresponding probability and utility pairs. There are alternative\nrules that appeal to confidence even in the absence of precise\ncardinal weights. Gärdenfors and Sahlin (1982), for instance,\nsuggest simply excluding from consideration any probability (and\nutility) functions that fall below a confidence threshold, and then\napplying the Maxmin-EU rule based on the remainder. Hill’s\n(2013) choice theory is somewhat similar, although confidence\nthresholds for probability and utility pairs are allowed to vary\ndepending on the choice problem (and the term “confidence”\nis itself used differently). There are further proposals whereby acts\nare compared in terms of how much uncertainty they can tolerate (which\nagain depends on levels of confidence) and yet still be a satisfactory\noption (see, e.g., Ben-Haim 2001). These rules are compelling, but\nthey do raise a host of difficult questions regarding how to interpret\nand measure the extra subjective attitudes that play a role, like\n“amount of confidence in a belief/desire” and\n“satisfactory level of desirability”. \nThere has been recent interest in yet a further challenge to expected\nutility theory, namely, the challenge from unawareness. In\nfact, unawareness presents a challenge for all extant normative\ntheories of choice. To keep things simple, we shall however focus on\nSavage’s expected utility theory to illustrate the challenge\nposed by unawareness. \nAs the reader will recall, Savage takes for granted a set of possible\noutcomes \\(\\bO\\), and another set of possible states of the world\n\\(\\bS\\), and defines the set of acts, \\(\\bF\\), as the set of all\nfunctions from \\(\\bS\\) to \\(\\bO\\). Moreover, his representation\ntheorem has been interpreted as justifying the claim that a rational\nperson always performs the act in \\(\\bF\\) that maximises expected\nutility, relative to a probability measure over \\(\\bS\\) and a utility\nmeasure over \\(\\bO\\).  \nNow, Savage’s theory is neutral about how to interpret the\nstates in \\(\\bS\\) and the outcomes in \\(\\bO\\). For instance, the\ntheory is consistent with interpreting \\(\\bS\\) and \\(\\bO\\) as\nrespectively the sets of all logically possible states and\noutcomes, but it is also consistent with interpreting \\(\\bS\\) and\n\\(\\bO\\) as respectively the sets of states and outcomes that some\nmodeller recognises, or the sets of states and outcomes that\nthe decision-maker herself recognises.  \nIf the theory is meant to describe the reasoning of a decision-maker,\nthe first two interpretations would seem inferior to the third. The\nproblem with the first two interpretations is that the decision-maker\nmight be unaware of some of the logically possible states and\noutcomes, as well as some of the states and outcomes that the modeller\nis aware of. (Having said that, one may identify the states and\noutcomes that the agent is unaware of by reference to those of which\nthe modeller is aware.) \nWhen it comes to (partially) unaware decision-makers, an important\ndistinction can be made between on the one hand what we might call\n“unawareness of unawareness”—that is, a situation\nwhere a decision-maker does not realise that there might be some\noutcome or state that they are unaware of—and on the other hand\n“awareness of unawareness”—that is, a situation\nwhere a decision-maker at least suspects that there is some outcome or\nstate of which they are unaware.  \nFrom the perspective of decision-making, unawareness of unawareness is\nnot of much interest. After all, if one is not even aware of the\npossibility that one is unaware of some state or outcome, then that\nunawareness cannot play any role in one’s reasoning about what\nto do. However, decision-theoretic models have been proposed for how a\nrational person responds to growth in awareness (that is\nmeant to apply even to people who previously were unaware of their\nunawareness). In particular, economists Karni and Vierø (2013,\n2015) have recently extended standard Bayesian conditionalisation to\nsuch learning events. Their theory, Reverse Bayesianism,\ninformally says that awareness growth should not affect the ratios of\nprobabilities of the states/outcomes that the agent was aware of\nbefore the growth. Richard Bradley (2017) defends a similar principle\nin the context of the more general Jeffrey-style framework, and so\ndoes Roussos (2020); but the view is criticised by Steele and\nStefánsson (forthcoming-a, forthcoming-b) and by Mahtani\n(forthcoming). \nIn contrast, awareness of unawareness would seem to be of great\ninterest from the perspective of decision-making. If you suspect that\nthere is some possible state, say, that you have not yet entertained,\nand some corresponding outcome, the content of which you are unaware,\nthen you might want to at least come to some view about how likely you\nexpect this state to be, and how good or bad you expect the\ncorresponding outcome to be, before you make a decision. \nA number of people have suggested models to represent agents who are\naware of their unawareness (e.g., Walker & Dietz 2013, Piermont\n2017, Karni & Vierø 2017). Steele and Stefánsson\n(forthcoming-b) argue that there may not be anything especially\ndistinctive about how a decision-maker reasons about states/outcomes\nof which she is aware she is unaware, in terms of the confidence she\nhas in her judgments and how she manages risk. That said, the way she\narrives at such judgments of probability and desirability is worth\nexploring further. Grant and Quiggin (2013a, 2013b), for instance,\nsuggest that these judgments are made based on induction from past\nsituations where one experienced awareness growth. \nIn general, the literature on unawareness has been rapidly growing.\nBradley (2017) and Steele and Stefánsson (forthcoming-b) are\nnew in-depth treatments of this topic within philosophy. Schipper\nmaintains a bibliography on unawareness, mostly with papers in\neconomics and computer science, at\n\\url{http://faculty.econ.ucdavis.edu/faculty/schipper/unaw.htm}.  \nThe decision theories of Savage and Jeffrey, as well as those of their\ncritics, apparently concern a single or “one shot only”\ndecision; at issue is an agent’s preference ordering, and\nultimately her choice of act, at a particular point in time. One may\nrefer to this as a static decision problem. The question\narises as to whether this framework is adequate for handling more\ncomplex scenarios, in particular those involving a series or sequence\nof decisions; these are referred to as sequential decision\nproblems. \nOn paper, at least, static and sequential decision models look very\ndifferent. The static model has familiar tabular or normal\nform, with each row representing an available act/option, and columns\nrepresenting the different possible states of the world that yield a\ngiven outcome for each act. The sequential decision model, on the\nother hand, has tree or extensive form (such as in\n Figure 1).\n It depicts a series of anticipated choice points, where the branches\nextending from a choice point represent the options at that choice\npoint. Some of these branches lead to further choice points, often\nafter the resolution of some uncertainty due to new evidence. \nThese basic differences between static and sequential decision models\nraise questions about how, in fact, they relate to each other: \nDo static and sequential decision models depict the same kind of\ndecision problem? If so, what is the static counterpart of a\nsequential decision model? \nDoes the sequential decision setting reveal any further\n(dis)advantages of EU theory? More generally does this setting shed\nlight on normative theories of choice? \nThese questions turn out to be rather controversial. They will be\naddressed in turn, after the scene has been set with an old story\nabout Ulysses. \nA well-known sequential decision problem is the one facing Ulysses on\nhis journey home to Ithaca in Homer’s great tale from antiquity.\nUlysses must make a choice about the manner in which he will sail past\nan island inhabited by sweet-singing sirens. He can choose to sail\nunrestrained or else tied to the mast. In the former case, Ulysses\nwill later have the choice, upon hearing the sirens, to either\ncontinue sailing home to Ithaca or to stay on the island indefinitely.\nIn the latter case, he will not be free to make further choices and\nthe ship will sail onwards to Ithaca past the sweet-singing sirens.\nThe final outcome depends on what sequence of choices Ulysses makes.\nUlysses’ decision problem is represented in tree (or extensive)\nform in\n Figure 1\n (where the two boxes represent choice points for Ulysses). \nFigure 1. Ulysses’ decision\nproblem \nWe are told that, before embarking, Ulysses would most prefer to\nfreely hear the sirens and return home to Ithaca. The problem is that\nUlysses predicts his future self will not comply: if he sails\nunrestrained, he will later be seduced by the sirens and will not in\nfact continue home to Ithaca but will rather remain on the island\nindefinitely. Ulysses therefore reasons that it would be better to be\ntied to the mast, because he would prefer the shame and discomfort of\nbeing tied to the mast and making it home to remaining on the\nsirens’ island forever. \nIt is hard to deny that Ulysses makes a wise choice in being tied to\nthe mast. Some hold, however, that Ulysses is nevertheless not an\nexemplary agent, since his present self must play against his future\nself who will be unwittingly seduced by the sirens. While Ulysses is\nrational at the first choice node by static decision\nstandards, we might regard him irrational overall by\nsequential decision standards, understood in terms of the relative\nvalue of sequences of choices. The sequence of choices that Ulysses\ninevitably pursues is, after all, suboptimal. It would have been\nbetter were he able to sail unconstrained and continue on home to\nIthaca. This sequence could have been achieved if Ulysses were\ncontinuously rational over the extended time period; say, if\nat all times he were to act as an EU maximiser, and change his beliefs\nand desires only in accordance with Bayesian norms (variants of\nstandard conditionalisation). On this reading, sequential\ndecision models introduce considerations of rationality-over-time. \nWhile rationality-over-time may have import in assessing an\nagent’s preferences and norms for changing these preferences\n(one can read the discussion in\n Section 6.2\n below in this way), there remains the important question of how an\nagent should act in light of her preferences at any given point in\ntime. To this end, the sequential decision model can be\nfruitfully viewed as a tool for helping determine rational choice at a\nparticular time, just like the static decision model. The sequential\ndecision tree is effectively a way of visualising the temporal series\nof choices and learning events that an agent believes she\nwill confront in the future, depending on what part of the decision\ntree she will find herself. The key question, then, is: How should an\nagent choose amongst her initial options in light of her projected\ndecision tree? This question has generated a surprising amount of\ncontroversy. Three major approaches to negotiating sequential decision\ntrees have appeared in the literature. These are the\nnaïve or myopic approach, the\nsophisticated approach and the resolute approach.\nThese will be discussed in turn; it will be suggested that the\ndisputes may not be substantial but rather indicate subtle differences\nin the interpretation of sequential decision models. \nThe so-called naïve approach to negotiating sequential decisions\nserves as a useful contrast to the other two approaches. The\nnaïve agent assumes that any path through the decision tree is\npossible, and so sets off on whichever path is optimal, given his/her\npresent attitudes. For instance, a naïve Ulysses would simply\npresume that he has three overall strategies to choose from: either\nordering the crew to tie him to the mast, or issuing no such order and\nlater stopping at the sirens’ island, or issuing no such order\nand later sticking to his course. Ulysses prefers the outcome\nassociated with the latter combination, and so he initiates this\nstrategy by not ordering the crew to restrain him. Table 5 presents\nthe static counterpart of naïve Ulysses’ decision problem.\nIn effect, this decision model does not take into account\nUlysses’ present knowledge of his future preferences, and hence\nadvises that he pursue an option that is predicted to be\nimpossible. \nTable 5. Naïve Ulysses’\ndecision problem \nThere is no need to labour the point that the naïve approach to\nsequential choice is aptly named. The hallmark of the sophisticated\napproach, by contrast, is its emphasis on backwards planning: the\nsophisticated chooser does not assume that all paths through the\ndecision tree, or in other words, all possible combinations of choices\nat the various choice nodes, will be possible. The agent considers,\nrather, what he/she will be inclined to choose at later choice nodes\nwhen he/she gets to the temporal position in question. Sophisticated\nUlysses would take note of the fact that, if he reaches the island of\nthe sirens unrestrained, he will want to stop there indefinitely, due\nto the transformative effect of the sirens’ song on his\npreferences. This is then reflected in the static representation of\nthe decision problem, as per Table 6. The states here concern\nUlysses’ future preferences, once he reaches the island. Since\nthe second state has (by assumption) probability zero, the acts are\ndecided on the basis of the first state, so Ulysses wisely chooses to\nbe tied to the mast. \nTable 6. Sophisticated Ulysses’\ndecision problem \nResolute choice deviates from sophisticated choice only under certain\nconditions that are not fulfilled by Ulysses, given his inexplicable\nchange in attitudes. Defenders of resolute choice typically defend\ndecision theories and associated preferences that violate the\nIndependence axiom/Sure-Thing Principle (notably McClennen 1990 and\nMachina 1989; see also Rabinowicz 1995 and Buchak 2013 for\ndiscussion), and appeal to resolute choice to make these preferences\nmore palatable in the sequential-decision context (to be discussed\nfurther in\n Section 6.2\n below). According to resolute choice, in appropriate contexts, the\nagent should at all choice points stick to the strategy that was\ninitially deemed best. The question is whether this advice makes\nsense, given the standard interpretation of a sequential decision\nmodel. What would it mean for an agent to choose against her\npreferences in order to fulfill a previously-selected plan? That would\nseem to defy the very notion of preference. Of course, an agent may\nplace considerable importance on honouring previous commitments. Any\nsuch integrity concerns, however, should arguably be reflected in the\nspecification of outcomes and thus in the agent’s preferences at\nthe time in question. This is quite different from choosing out of\nstep with one’s all-things-considered preferences at a time. \nDefenders of resolute choice may have in mind a different\ninterpretation of sequential decision models, whereby future\n“choice points” are not really points at which an agent is\nfree to choose according to her preferences at the time. If so, this\nwould amount to a subtle shift in the question or problem of interest.\nIn what follows, the standard interpretation of sequential decision\nmodels will be assumed, and accordingly, it will be assumed that\nrational agents pursue the sophisticated approach to choice (as per\nLevi 1991, Maher 1992, Seidenfeld 1994, amongst others). \nWe have seen that sequential decision trees can help an agent like\nUlysses take stock of the consequences of his current choice, so that\nhe can better reflect on what to do now. The literature on\nsequential choice is primarily concerned, however, with more ambitious\nquestions. The sequential-decision setting effectively offers new ways\nto “test” theories of rational preference and norms for\npreference (or belief and desire) change. The question is whether an\nagent’s decision theory in this broad sense is shown to be\ndynamically inconsistent or self-defeating. \nSkyrms’ (1993) “diachronic Dutch book” argument for\nconditionalisation can be read in this way. The agent is assumed to\nhave EU preferences and to take a sophisticated (backwards reasoning)\napproach to sequential decision problems. Skyrms shows that any such\nagent who plans to learn in a manner at odds with conditionalisation\nwill make self-defeating choices in some specially contrived\nsequential decision situations. A conditionalising agent, by contrast,\nwill never make choices that are self-defeating in this way. The kind\nof “self-defeating choices” at issue here are ones that\nyield a sure loss. That is, the agent chooses a strategy that is\nsurely worse, by her own lights, than another strategy that she might\notherwise have chosen, if only her learning rule was such that she\nwould choose differently at one or more future decision nodes. \nA similar “dynamic consistency” argument can be used to\ndefend EU preferences in addition to learning in accordance with\nconditionalisation (see Hammond 1976, 1977, 1988b,c). It is assumed,\nas before, that the agent takes a sophisticated approach to sequential\ndecision problems. Hammond shows that only a fully Bayesian agent can\nplan to pursue any path in a sequential decision tree that is deemed\noptimal at the initial choice node. This makes the Bayesian agent\nunique in that she will never make “self-defeating\nchoices” on account of her preferences and norms for preference\nchange. She will never choose a strategy that is worse by her own\nlights than another strategy that she might otherwise have chosen, if\nonly her preferences were such that she would choose differently at\none or more future decision nodes. \nHammond’s argument for EU theory, and the notion of dynamic\nconsistency that it invokes, has been criticised from different\nquarters, both by those who defend theories that violate the\nIndependence axiom but retain the Completeness and Transitivity (i.e.,\nOrdering) axioms of EU theory, and those who defend theories that\nviolate the latter (for discussion, see Steele 2010). The approach\ntaken by some defenders of Independence-violating theories (notably,\nMachina 1989 and McClennen 1990) has already been alluded to: They\nreject the assumption of sophisticated choice underpinning the dynamic\nconsistency arguments. Seidenfeld (1988a,b, 1994, 2000a,b) rather\nrejects Hammond’s notion of dynamic consistency in favour of a\nmore subtle notion that discriminates between theories that violate\nOrdering and those that violate Independence alone; the former, unlike\nthe latter, pass Seidenfeld’s test that turns on future decision\nnodes where the agent is indifferent between the best options. This\nargument too is not without its critics (see McClennen 1988, Hammond\n1988a, Rabinowicz 2000). \nNote that the costs of any departure from EU theory are well\nhighlighted by Al-Najjar and Weinstein (2009), in particular the\npossibility of aversion to free information and aversion to\nopportunities for greater choice in the future. Kadane et al. (2008)\nand Bradley and Steele (2016) focus on the sure loss that is\nassociated with paying to avoid free evidence. But see Buchak (2010,\n2013) for nuanced discussion of this issue in relation to epistemic\nversus instrumental rationality. \nLet us conclude by summarising the main reasons why decision theory,\nas described above, is of philosophical interest. First, normative\ndecision theory is clearly a (minimal) theory of practical\nrationality. The aim is to characterise the attitudes of agents who\nare practically rational, and various (static and sequential)\narguments are typically made to show that certain practical\ncatastrophes befall agents who do not satisfy standard\ndecision-theoretic constraints. Second, many of these constraints\nconcern the agents’ beliefs. In particular, normative\ndecision theory requires that agents’ degrees of beliefs satisfy\nthe probability axioms and that they respond to new information by\nconditionalisation. Therefore, decision theory has great implications\nfor debates in epistemology and philosophy of science; that is, for\ntheories of epistemic rationality. \nFinally, decision theory should be of great interest to philosophers\nof mind and psychology, and others who are interested in how people\ncan understand the behaviour and intentions of others; and, more\ngenerally, how we can interpret what goes on in other people’s\nminds. Decision theorists typically assume that a person’s\nbehaviour can be fully explained in terms of her beliefs and desires.\nBut perhaps more interestingly, some of the most important results of\ndecision theory—the various representation theorems, some of\nwhich have discussed here—suggest that if a person satisfies\ncertain rationality requirements, then we can read her beliefs and\ndesires, and how strong these beliefs and desires are, from her choice\ndispositions (or preferences). How much these theorems really tell us\nis a matter of debate, as discussed above. But on an optimistic\nreading of these results, they assure us that we can meaningfully talk\nabout what goes on in other people’s minds without much evidence\nbeyond information about their dispositions to choose.","contact.mail":"katie.steele@anu.edu.au","contact.domain":"anu.edu.au"},{"date.published":"2015-12-16","date.changed":"2020-10-09","url":"https://plato.stanford.edu/entries/decision-theory/","author1":"Katie Steele","author1.info":"http://philosophy.cass.anu.edu.au/people/katie-steele","author2.info":"http://orristefansson.is/","entry":"decision-theory","body.text":"\n\n\nDecision theory is concerned with the reasoning underlying an\nagent’s choices, whether this is a mundane choice between taking\nthe bus or getting a taxi, or a more far-reaching choice about whether\nto pursue a demanding political career. (Note that “agent”\nhere stands for an entity, usually an individual person, that is\ncapable of deliberation and action.) Standard thinking is that what an\nagent chooses to do on any given occasion is completely determined by\nher beliefs and desires or values, but this is not uncontroversial, as\nwill be noted below. In any case, decision theory is as much a theory\nof beliefs, desires and other relevant attitudes as it is a theory of\nchoice; what matters is how these various attitudes (call them\n“preference attitudes”) cohere together.\n\n\nThe focus of this entry is normative decision theory. That is, the\nmain question of interest is what criteria an agent’s preference\nattitudes should satisfy in any generic\ncircumstances. This amounts to a minimal account of\nrationality, one that sets aside more substantial questions\nabout appropriate desires and reasonable beliefs, given the situation\nat hand. The key issue for a minimal account is the treatment of\nuncertainty. The orthodox normative decision theory, expected\nutility (EU) theory, essentially says that, in situations of\nuncertainty, one should prefer the option with greatest\nexpected desirability or value. (Note that in this context,\n“desirability” and “value” should be\nunderstood as desirability/value according to the agent in\nquestion.) This simple maxim will be the focus of much of our\ndiscussion.\n\n\nThe structure of this entry is as follows: Section 1 discusses the\nbasic notion of “preferences over prospects”, which lies\nat the heart of decision theory. Section 2 describes the development\nof normative decision theory in terms of ever more powerful and\nflexible measures of preferences. Section 3 discusses the two\nbest-known versions of EU theory. Section 4 considers the broader\nsignificance of EU theory for practical action, inference, and\nvaluing. Section 5 turns to prominent challenges to EU theory, while\nSection 6 addresses sequential decisions, and how this richer setting\nbears on debates about rational preferences.\n\nThe two central concepts in decision theory are preferences\nand prospects (or equivalently, options). Roughly\nspeaking, when we (in this entry) say that an agent\n“prefers” the “option” \\(A\\) over \\(B\\) we\nmean that the agent takes \\(A\\) to be more desirable or choice-worthy\nthan \\(B\\). This rough definition makes clear that preference is a\ncomparative attitude. Beyond this, there is room for argument about\nwhat preferences over options actually amount to, or in other words,\nwhat it is about an agent (perhaps oneself) that concerns us when we\ntalk about his/her preferences over options. This section considers\nsome elementary issues of interpretation that set the stage for\nintroducing (in the next section) the decision tables and expected\nutility rule that for many is the familiar subject matter of decision\ntheory. Further interpretive questions regarding preferences and\nprospects will be addressed later, as they arise. \nLet us nonetheless proceed by first introducing basic candidate\nproperties of (rational) preference over options and only afterwards\nturning to questions of interpretation. As noted above, preference\nconcerns the comparison of options; it is a relation between options.\nFor a domain of options we speak of an agent’s preference\nordering, this being the ordering of options that is generated by\nthe agent’s preference between any two options in that\ndomain. \nIn what follows, \\(\\preceq\\) represents a weak preference\nrelation. So \\(A\\preceq B\\) means that the agent we are interested in\nconsiders option \\(B\\) to be at least as preferable as option \\(A\\).\nFrom the weak preference relation we can define the strict\npreference relation, \\(\\prec\\), as follows: \\(A\\prec B\\Leftrightarrow\nA\\preceq B \\ \\& \\ \\neg (B\\preceq A)\\), where \\(\\neg X\\) means\n“it is not the case that \\(X\\)”. The indifference\nrelation, \\(\\sim\\), is defined as: \\(A\\sim B \\Leftrightarrow A\\preceq\nB \\ \\& \\ B\\preceq A\\). This represents that the agent we are\ninterested in considers \\(A\\) and \\(B\\) to be equally preferable. \nWe say that \\(\\preceq\\) weakly orders a set \\(S\\) of options\nwhenever it satisfies the following two conditions: \nAxiom 1 (Completeness)\n\nFor any \\(A, B\\in S\\): either \\(A\\preceq B\\) or \\(B\\preceq A\\). \nAxiom 2 (Transitivity)\n\nFor any \\(A, B, C\\in S\\): if \\(A\\preceq B\\) and \\(B\\preceq C\\) then\n\\(A\\preceq C\\). \nThe above can be taken as a preliminary characterisation of rational\npreference over options. Even this limited characterisation is\ncontentious, however, and points to divergent interpretations of\n“preferences over prospects/options”. \nStart with the Completeness axiom, which says that an agent can\ncompare, in terms of the weak preference relation, all pairs of\noptions in \\(S\\). Whether or not Completeness is a plausible\nrationality constraint depends both on what sort of options are under\nconsideration, and how we interpret preferences over these options. If\nthe option set includes all kinds of states of affairs, then\nCompleteness is not immediately compelling. For instance, it is\nquestionable whether an agent should be able to compare the option\nwhereby two additional people in the world are made literate with the\noption whereby two additional people reach the age of sixty. If, on\nthe other hand, all options in the set are quite similar to each\nother, say, all options are investment portfolios, then Completeness\nis more compelling. But even if we do not restrict the kinds of\noptions under consideration, the question of whether or not\nCompleteness should be satisfied turns on the meaning of preference.\nFor instance, if preferences merely represent choice behaviour or\nchoice dispositions, as they do according to the “revealed\npreference theory” popular amongst economists (see Sen 1973),\nthen Completeness is automatically satisfied, on the assumption that a\nchoice must inevitably be made. By contrast, if preferences are\nunderstood rather as mental attitudes, typically considered judgments\nabout whether an option is better or more desirable than another, then\nthe doubts about Completeness alluded to above are pertinent (for\nfurther discussion, see Mandler 2001). \nMost philosophers and decision theorists subscribe to the latter\ninterpretation of preference as a kind of judgment that explains, as\nopposed to being identical with, choice dispositions and resultant\nchoice behaviour (see, e.g., Hausman 2011a, 2011b; Dietrich and List,\n2016a & 2016b; Bradley 2017; although see also Thoma 2020b and\nVredenburgh 2020 for recent defences of “revealed preference\ntheory”, at least in the context of empirical economics).\nMoreover, many hold that Completeness is not rationally required,\nsince they think that rationality makes demands only on the judgments\nan agent actually holds, but says nothing of whether a judgement must\nbe held in the first place. Nevertheless, following Richard Jeffrey\n(1983), most decision theorists suggest that rationality requires that\npreferences be coherently extendible. This means that even if\nyour preferences are not complete, it should be possible to complete\nthem without violating any of the conditions that are rationally\nrequired, in particular Transitivity. \nThis brings us to the\n Transitivity axiom,\n which says that if an option \\(B\\) is weakly preferred to \\(A\\), and\n\\(C\\) weakly preferred to \\(B\\), then \\(C\\) is weakly preferred to\n\\(A\\). A recent challenge to Transitivity turns on heterogeneous sets\nof options, as per the discussion of Completeness above. But here a\ndifferent interpretation of preference is brought to bear on the\ncomparison of options. The idea is that preferences, or judgments of\ndesirability, may be responsive to a salience condition. For example,\nsuppose that the most salient feature when comparing cars \\(A\\) and\n\\(B\\) is how fast they can be driven, and \\(B\\) is no worse than \\(A\\)\nin this regard, yet the most salient feature when comparing cars \\(B\\)\nand \\(C\\) is how safe they are, and that \\(C\\) is no worse than \\(B\\)\nin this regard. Furthermore, when comparing \\(A\\) and \\(C\\), the most\nsalient feature is their beauty. In such a case, some argue (e.g.,\nTemkin 2012) that there is no reason why Transitivity should be\nsatisfied with respect to the preferences concerning \\(A\\), \\(B\\) and\n\\(C\\). Others (e.g., Broome 1991a) argue that Transitivity is part of\nthe very meaning of the betterness relation (or objective comparative\ndesirability); if rational preference is a judgment of betterness or\ndesirability, then Transitivity is non-negotiable. With respect to the\ncar example, Broome would argue that the desirability of a fully\nspecified option should not vary, simply in virtue of what other\noptions it is compared with. Either the choice context affects how the\nagent perceives the option at hand, in which case the description of\nthe option should reflect this, or else the choice context does not\naffect the option. Either way, Transitivity should be satisfied. \nThere is a more straightforward defence of Transitivity in preference;\na defence that hinges on the sure losses that may befall anyone who\nviolates the axiom. This is the so-called money pump argument\n(see Davidson et. al. 1955 for an early argument of this sort, but for\nrecent discussion and revision of this argument, see Gustafsson 2010\n& 2013). It is based on the assumption that if you find \\(X\\) at\nleast as desirable as \\(Y\\), then you should be happy to trade the\nlatter for the former. Suppose you violate Transitivity; for you:\n\\(A\\preceq B\\), \\(B\\preceq C\\) but \\(C\\prec A\\). Moreover, suppose you\npresently have \\(A\\). Then you should be willing to trade \\(A\\) for\n\\(B\\). The same goes for \\(B\\) and \\(C\\): you should be willing to\ntrade \\(B\\) for \\(C\\). You strictly prefer \\(A\\) to \\(C\\), so you\nshould be willing to trade in \\(C\\) plus some sum \\(\\$x\\) for \\(A\\).\nBut now you are in the same situation as you started, having \\(A\\) and\nneither \\(B\\) nor \\(C\\), except that you have lost \\(\\$x\\)! So in a\nfew steps, each of which was consistent with your preferences, you\nfind yourself in a situation that is clearly worse, by your own\nlights, than your original situation. The picture is made more\ndramatic if we imagine that the process could be repeated, turning you\ninto a “money pump”. Hence, the argument goes, there is\nsomething (instrumentally) irrational about your intransitive\npreferences. If your preferences were transitive, then you would not\nbe vulnerable to choosing a dominated option and serving as a money\npump. Therefore, your preferences should be transitive. \nWhile the aforementioned controversies have not been settled, the\nfollowing assumptions will be made in the remainder of this entry: i)\nthe objects of preference may be heterogeneous prospects,\nincorporating a rich and varied domain of properties, ii) preference\nbetween options is a judgment of comparative desirability or\nchoice-worthiness, and iii) preferences satisfy both Completeness and\nTransitivity (although the former condition will be revisited in\n Section 5).\n The question that now arises is whether there are further general\nconstraints on rational preference over options. \nIn our continuing investigation of rational preferences over\nprospects, the numerical representation (or\nmeasurement) of preference orderings will become important.\nThe numerical measures in question are known as utility\nfunctions. The two main types of utility function that will play\na role are the ordinal utility function and the more\ninformation-rich interval-valued (or cardinal)\nutility function. \nIt turns out that as long as the set of prospects/options, \\(S\\), is\nfinite, any weak order of the options in \\(S\\) can be represented by\nan ordinal utility function. To be precise, let us say that \\(u\\) is a\nutility function with domain \\(S\\). We say that the function\n\\(u\\) represents the preference \\(\\preceq\\) between the\noptions in \\(S\\) just in case: \nAnother way to put this is that, when the above holds, the preference\nrelation can be represented as maximising utility, since it\nalways favours option with higher utility. \nThe only information contained in an ordinal utility representation is\nhow the agent whose preferences are being represented orders options,\nfrom least to most preferable. This means that if \\(u\\) is an ordinal\nutility function that represents the ordering \\(\\preceq\\), then any\nutility function \\(u'\\) that is an ordinal transformation of\n\\(u\\)—that is, any transformation of \\(u\\) that also satisfies\nthe biconditional in (1)—represents \\(\\preceq\\) just as well as\n\\(u\\) does. Hence, we say that an ordinal utility function is\nunique only up to ordinal transformations. \nThe result referred to above can be summarised as follows: \nTheorem 1 (Ordinal representation). Let \\(S\\) be a\nfinite set, and \\(\\preceq\\) a weak preference relation on \\(S\\). Then\nthere is an ordinal utility function that represents \\(\\preceq\\) just\nin case \\(\\preceq\\) is complete and transitive. \nThis theorem should not be too surprising. If \\(\\preceq\\) is complete\nand transitive over \\(S\\), then the options in \\(S\\) can be put in an\norder, from the most to the least preferred, where some options may\nfall in the same position (if they are deemed equally desirable) but\nwhere there are no cycles, loops, or gaps.\n Theorem 1\n just says that we can assign numbers to the options in \\(S\\) in a way\nthat represents this order. (For a simple proof of Theorem 1, except\nfor a strict rather than a weak preference relation, consult Peterson\n2009: 95.) \nNote that ordinal utilities are not very mathematically\n“powerful”, so to speak. It does not make sense, for\ninstance, to compare the probabilistic expectations of different sets\nof ordinal utilities. For example, consider the following two pairs of\nprospects: the elements of the first pair are assigned ordinal\nutilities of 2 and 4, while those in the second pair are assigned\nordinal utilities of 0 and 5. Let us specify a “flat”\nprobability distribution in each case, such that each element in the\ntwo pairs corresponds to a probability of 0.5. Relative to this\nprobability assignment, the expectation of the first pair of ordinal\nutilities is 3, which is larger than 2.5, the expectation of the\nsecond pair. Yet when we transform the ordinal utilities in a\npermissible way—for instance by increasing the highest utility\nin the second pair from 5 to 10—the ordering of expectations\nreverses; now the comparison is between 3 and 5. The significance of\nthis point will become clearer in what follows, when we turn to the\ncomparative evaluation of lotteries and risky choices. An\ninterval-valued or cardinal utility function is necessary for\nevaluating lotteries/risky prospects in a consistent way. By the same\ntoken, in order to construct or conceptualise a cardinal utility\nfunction, one typically appeals to preferences over lotteries.\n(Although see Alt 1936 for a “risk-free” construction of\ncardinal utility, that is, one that does not appeal to lotteries.) \nIn order to get a cardinal (interval-valued) utility representation of\na preference ordering—i.e., a measure that represents not only\nhow an agent orders the options but also says something about the\ndesirabilistic “distance” between options—we need a\nricher setting; the option set and the corresponding preference\nordering will need to have more structure than for an ordinal utility\nmeasure. One such account, owing to John von Neumann and Oskar\nMorgenstern (1944), will be cashed out in detail below. For now, it is\nuseful to focus on the kind of option that is key to understanding and\nconstructing a cardinal utility function:\n lotteries.[1] \nConsider first an ordering over three regular options, e.g., the three\nholiday destinations Amsterdam, Bangkok and Cardiff, denoted \\(A\\),\n\\(B\\) and \\(C\\) respectively. Suppose your preference ordering is\n\\(A\\prec B \\prec C\\). This information suffices to ordinally represent\nyour judgement; recall that any assignment of utilities is then\nacceptable as long as \\(C\\) gets a higher value than \\(B\\) which gets\na higher value than \\(A\\). But perhaps we want to know more than can\nbe inferred from such a utility function—we want to know how\nmuch \\(C\\) is preferred over \\(B\\), compared to how much \\(B\\) is\npreferred over \\(A\\). For instance, it may be that Bangkok is\nconsidered almost as desirable as Cardiff, but Amsterdam is a long way\nbehind Bangkok, relatively speaking. Or else perhaps Bangkok is only\nmarginally better than Amsterdam, compared to the extent to which\nCardiff is better than Bangkok. This kind of information about the\nrelative distance between options, in terms of strength of preference\nor desirability, is precisely what is given by an interval-valued\nutility function. The problem is how to ascertain this\ninformation. \nTo solve this problem, Ramsey (1926) and later von Neumann and\nMorgenstern (hereafter vNM) made the following suggestion: we\nconstruct a new option, a lottery, \\(L\\), that has \\(A\\) and\n\\(C\\) as its possible “prizes”, and we figure out what\nchance the lottery must confer on \\(C\\) for you to be indifferent\nbetween this lottery and a holiday in Bangkok. The basic idea is that\nyour judgment about Bangkok, relative to Cardiff on the one hand and\nAmsterdam on the other, can be measured by the riskiness of the\nlottery \\(L\\) involving Cardiff and Amsterdam that you deem equally\ndesirable as Bangkok. For instance, if you are indifferent between\nBangkok and a lottery that provides a very low chance of winning a\ntrip to Cardiff, then you evidently do not regard Bangkok to be much\nbetter than Amsterdam, vis-à-vis Cardiff; for you, even a small\nimprovement on Amsterdam, i.e., a lottery with a small chance of\nCardiff rather than Amsterdam, is enough to match Bangkok. \nThe above analysis presumes that lotteries are evaluated in terms of\ntheir expected choice-worthiness or desirability. That is,\nthe desirability of a lottery is effectively the sum of the chances of\neach prize multiplied by the desirability of that prize. Consider the\nfollowing example: Suppose you are indifferent between the lottery and\nthe holiday in Bangkok when the chance of the lottery resulting in a\nholiday in Cardiff is \\(3/4\\). Call this particular lottery \\(L'\\).\nThe idea is that Bangkok is therefore three quarters of the way up a\ndesirability scale that has Amsterdam at the bottom and Cardiff at the\ntop. If we stipulate that \\(u(A)=0\\) and \\(u(C)=1\\), then\n\\(u(B)=u(L')=3/4\\). This corresponds to the expected\ndesirability—or, as it is usually called, the expected\nutility—of the lottery, since \\(1/4\\cdot 0 + 3/4\\cdot 1 =\n3/4 = u(L')\\). That is, the desirability of the lottery is a\nprobability weighted sum of the utilities of its prizes, where the\nweight on each prize is determined by the probability that the lottery\nresults in that prize. \nWe thus see that an interval-valued utility measure over options can\nbe constructed by introducing lottery options. As the name suggests,\nthe interval-valued utility measure conveys information about the\nrelative sizes of the intervals between the options according to some\ndesirability scale. That is, the utilities are unique after we have\nfixed the starting point of our measurement and the unit scale of\ndesirability. In the above example, we could have, for instance,\nassigned a utility value of 1 to \\(A\\) and 5 to \\(C\\), in which case\nwe would have had to assign a utility value of 4 to \\(B\\), since 4 is\n3/4 of the way between 1 and 5. In other words, once we have assigned\nutility values to \\(A\\) and \\(C\\), the utility of \\(L'\\) and thus\n\\(B\\) has been determined. Let us call this second utility function\n\\(u'\\). It is related to our original function as follows: \\(u'=4\\cdot\nu +1\\). This relationship always holds between two such functions: If\n\\(u\\) is an interval-valued utility function that represents a\npreference ordering, \\(\\preceq\\), and \\(u'\\) is another utility\nfunction that also represents this same preference ordering, then\nthere are constants \\(a\\) and \\(b\\), where \\(a\\) must be positive,\nsuch that \\(u'=a\\cdot u + b\\). This is to say that interval-valued\nutility functions are unique only up to positive linear\ntransformation. \nBefore concluding this discussion of measuring utility, two related\nlimitations regarding the information such measures convey should be\nmentioned. First, since the utilities of options, whether ordinal or\ninterval-valued, can only be determined relative to the\nutilities of other options, there is no such thing as the\nabsolute utility of an option, at least not without further\n assumptions.[2]\n Second, by the same reasoning, neither interval-valued nor ordinal\nutility measures, as discussed here, are interpersonally\ncommensurable with respect to levels and units of utility. By way\nof a quick illustration, suppose that both you and I have the\npreference ordering described above over the holiday options: \\(A\\prec\nB \\prec C\\). Suppose too that, as per the above, we are both\nindifferent between \\(B\\) and the lottery \\(L'\\) that has a \\(3/4\\)\nchance of yielding \\(C\\) and a \\(1/4\\) chance of yielding \\(A\\). Can\nwe then say that granting me Cardiff and you Bangkok would amount to\nthe same amount of “total desirability” as granting you\nCardiff and me Bangkok? We are not entitled to say this. Our shared\npreference ordering is, for instance, consistent with me finding a\nvacation in Cardiff a dream come true while you just find it the best\nof a bad lot. Moreover, we are not even entitled to say that the\ndifference in desirability between Bangkok and Amsterdam is the same\nfor you as it is for me. According to me, the desirability of the\nthree options might range from living hell to a dream come true, while\naccording to you, from bad to quite bad; both evaluations are\nconsistent with the above preference ordering. In fact, the same might\nhold for our preferences over all possible options, including\nlotteries: even if we shared the same total preference ordering, it\nmight be the case that you are just of a negative\ndisposition—finding no option that great—while I am very\nextreme—finding some options excellent but others a sheer\ntorture. Hence, utility functions, whether interval-valued or ordinal,\ndo not allow for meaningful interpersonal comparisons. (Elster and\nRoemer 1993 contains a number of papers discussing these issues; see\nalso the entry on\n social choice theory.) \nThe last section provided an interval-valued utility representation of\na person’s preferences over lotteries, on the assumption that\nlotteries are evaluated in terms of expected utility. Some might find\nthis a bit quick. Why should we assume that people evaluate lotteries\nin terms of their expected utilities? The vNM theorem effectively\nshores up the gaps in reasoning by shifting attention back to the\npreference relation. In addition to Transitivity and Completeness, vNM\nintroduce further principles governing rational preferences over\nlotteries, and show that an agent’s preferences can be\nrepresented as maximising expected utility whenever her preferences\nsatisfy these principles. \nLet us first define, in formal terms, the expected utility of a\nlottery: Let \\(L_i\\) be a lottery from the set \\(\\bL\\) of lotteries,\nand \\(O_{ik}\\) the outcome, or prize, of lottery \\(L_i\\) that arises\nwith probability \\(p_{ik}\\). The expected utility of \\(L_i\\) is then\ndefined as: \nThe vNM equation. \nThe assumption made earlier can now be formally stated: \nWhen the above holds, we say that there is an expected utility\nfunction that represents the agent’s preferences; in other\nwords, the agent can be represented as maximising expected\nutility. \nThe question that vNM address is: What sort of preferences can be thus\nrepresented? To answer this question, we must return to the underlying\npreference relation \\(\\preceq\\) over the set of options, in this case\ninvolving lotteries. The vNM theorem requires the set \\(\\bL\\) of\nlotteries to be rather extensive: it is closed under\n“probability mixture”, that is, if \\(L_i, L_j\\in \\bL\\),\nthen compound lotteries that have \\(L_i\\) and \\(L_j\\) as possible\nprizes are also in \\(\\bL\\). (Another technical assumption, that will\nnot be discussed in detail, is that compound lotteries can always be\nreduced, in accordance with the laws of probability, to simple\nlotteries that only involve basic prizes.) \nA basic rationality constraint on the preference relation has already\nbeen discussed—that it weakly orders the options (i.e.,\nsatisfies Transitivity and Completeness). The following notation will\nbe used to introduce the two additional vNM axioms of preference:\n\\(\\{pA, (1-p)B\\}\\) denotes a lottery that results either in \\(A\\),\nwith probability \\(p\\), or \\(B\\), with probability \\(1-p\\), where\n\\(A\\) and \\(B\\) can be final outcomes but can also be lotteries. \nAxiom 3 (Continuity)\n\nSuppose \\(A\\preceq B\\preceq C\\). Then there is a \\(p\\in [0,1]\\) such\nthat: \nAxiom 4 (Independence)\n\nSuppose \\(A\\preceq B\\). Then for any \\(C\\), and any \\(p\\in\n[0,1]\\): \nContinuity implies that no outcome \\(A\\) is so bad that you would not\nbe willing to take some gamble that might result in you ending up with\nthat outcome, but might otherwise result in you ending up with an\noutcome (\\(C\\)) that you find to be a marginal improvement on your\nstatus quo (\\(B\\)), provided that the chance of \\(A\\) is small enough.\nIntuitively, Continuity guarantees that an agent’s evaluations\nof lotteries are appropriately sensitive to the probabilities of the\nlotteries’ prizes. \nIndependence implies that when two alternatives have the same\nprobability for some particular outcome, our evaluation of the two\nalternatives should be independent of our opinion of that outcome.\nIntuitively, this means that preferences between lotteries should be\ngoverned only by the features of the lotteries that differ; the\ncommonalities between the lotteries should be effectively ignored.\n \nSome people find the\n Continuity axiom\n an unreasonable constraint on rational preference. Is there any\nprobability \\(p\\) such that you would be willing to accept a gamble\nthat has that probability of you losing your life and probability\n\\((1-p)\\) of you gaining $10? Many people think there is not. However,\nthe very same people would presumably cross the street to pick up a\n$10 bill they had dropped. But that is just taking a gamble that has a\nvery small probability of being killed by a car but a much higher\nprobability of gaining $10! More generally, although people rarely\nthink of it this way, they constantly take gambles that have minuscule\nchances of leading to imminent death, and correspondingly very high\nchances of some modest reward. \nIndependence seems a compelling requirement of rationality, when\nconsidered in the abstract. Nevertheless, there are famous examples\nwhere people often violate Independence without seeming irrational.\nThese examples involve complementarities between the possible\nlottery outcomes. A particularly well-known such example is the\nso-called Allais Paradox, which the French economist Maurice\nAllais (1953) first introduced in the early 1950s. The paradox turns\non comparing people’s preferences over two pairs of lotteries\nsimilar to those given in Table 1. The lotteries are described in\nterms of the prizes that are associated with particular numbered\ntickets, where one ticket will be drawn randomly (for instance,\n\\(L_1\\) results in a prize of $2500 if one of the tickets numbered\n2–34 is drawn). \nTable 1. Allais’ paradox \nIn this situation, many people strictly prefer \\(L_2\\) over \\(L_1\\)\nbut also \\(L_3\\) over \\(L_4\\) (as evidenced by their choice behaviour,\nas well as their testimony), a pair of preferences which will be\nreferred to as Allais’\n preferences.[3]\n A common way to rationalise Allais’ preferences, is that in the\nfirst choice situation, the risk of ending up with nothing when one\ncould have had $2400 for sure does not justify the increased chance of\na higher prize. In the second choice situation, however, the minimum\none stands to gain is $0 no matter which choice one makes. Therefore,\nin that case many people do think that the slight extra risk of $0 is\nworth the chance of a better prize. \nWhile the above reasoning may seem compelling, Allais’\npreferences conflict with the\n Independence axiom.\n The following is true of both choice situations: whatever choice you\nmake, you will get the same prize if one of the tickets in the last\ncolumn is drawn. Therefore, Independence implies that both your\npreference between \\(L_1\\) and \\(L_2\\) and your preference between\n\\(L_3\\) and \\(L_4\\) should be independent of the prizes in that\ncolumn. But when you ignore the last column, \\(L_1\\) becomes identical\nto \\(L_3\\) and \\(L_2\\) to \\(L_4\\). Hence, if you prefer \\(L_2\\) over\n\\(L_1\\) but \\(L_3\\) over \\(L_4\\), there seems to be an inconsistency\nin your preference ordering. And there is definitely a violation of\nIndependence (given how the options have been described; an issue to\nwhich we return in\n Section 5.1).\n As a result, the pair of preferences under discussion cannot be\nrepresented as maximising expected utility. (Thus the\n“paradox”: many people think that Independence is a\nrequirement of rationality, but nevertheless also want to claim that\nthere is nothing irrational about Allais’ preferences.) \nDecision theorists have reacted in different ways to Allais’\nParadox. This issue will be revisited in\n Section 5.1,\n when challenges to EU theory will be discussed. The present goal is\nsimply to show that Continuity and Independence are compelling\nconstraints on rational preference, although not without their\ndetractors. The result vNM proved can be summarised thus: \nTheorem 2 (von Neumann-Morgenstern)\n\nLet \\(\\bO\\) be a finite set of outcomes, \\(\\bL\\) a set of\ncorresponding lotteries that is closed under probability mixture and\n\\(\\preceq\\) a weak preference relation on \\(\\bL\\). Then \\(\\preceq\\)\nsatisfies axioms 1–4 if and only if there exists a function\n\\(u\\), from \\(\\bO\\) into the set of real numbers, that is unique up to\npositive linear transformation, and relative to which \\(\\preceq\\) can\nbe represented as maximising expected utility. \nDavid Kreps (1988) gives an accessible illustration of the proof of\nthis theorem. \nThe vNM theorem is a very important result for measuring the strength\nof a rational agent’s preferences over sure options (the\nlotteries effectively facilitate a cardinal measure over sure\noptions). But this does not get us all the way to making rational\ndecisions in the real world; we do not yet really have a decision\ntheory. The theorem is limited to evaluating options that come with a\nprobability distribution over outcomes—a situation decision\ntheorists and economists often describe as “choice under\nrisk” (Knight 1921). \nIn most ordinary choice situations, the objects of choice, over which\nwe must have or form preferences, are not like this. Rather,\ndecision-makers must consult their own probabilistic beliefs\nabout whether one outcome or another will result from a specified\noption. Decisions in such circumstances are often described as\n“choices under uncertainty” (Knight 1921). For example,\nconsider the predicament of a mountaineer deciding whether or not to\nattempt a dangerous summit ascent, where the key factor for her is the\nweather. If she is lucky, she may have access to comprehensive weather\nstatistics for the region. Nevertheless, the weather statistics differ\nfrom the lottery set-up in that they do not determine the\nprobabilities of the possible outcomes of attempting versus not\nattempting the summit on a particular day. Not least, the mountaineer\nmust consider how confident she is in the data-collection procedure,\nwhether the statistics are applicable to the day in question, and so\non, when assessing her options in light of the weather. \nSome of the most celebrated results in decision theory address, to\nsome extent, these challenges. They consist in showing what conditions\non preferences over “real world options” suffice for the\nexistence of a pair of utility and probability functions\nrelative to which the agent can be represented as maximising expected\nutility. The standard interpretation is that, just as the utility\nfunction represents the agent’s desires, so the probability\nfunction represents her beliefs. The theories are referred to\ncollectively as subjective expected utility (SEU) theory as\nthey concern an agent’s preferences over prospects that are\ncharacterised entirely in terms of her own beliefs and desires (but we\nwill continue to use the simpler label EU theory). In this\nsection, two of these results will be briefly discussed: that of\nLeonard Savage (1954) and Richard Jeffrey (1965). \nNote that these EU decision theories apparently prescribe two things:\n(a) you should have consistent preference attitudes, and (b) you\nshould prefer the means to your ends, or at least you should prefer\nthe means that you assess will on average lead to your ends\n(cf. Buchak 2016). The question arises: What is the relationship\nbetween these prescriptions? The EU representation theorems\nthat will be outlined shortly seem to show that, despite appearances,\nthe two prescriptions are actually just one: anyone who has consistent\nattitudes prefers the means to her ends, and vice versa. But the\npuzzle remains that there are many ways to have consistent preference\nattitudes, and surely not all of these amount to preferring the means\nto one’s own true ends. This puzzle is worth bearing in\nmind when appraising EU theory in its various guises; it will come up\nagain later. \nLeonard Savage’s decision theory, as presented in his (1954)\nThe Foundations of Statistics, is without a doubt the\nbest-known normative theory of choice under uncertainty, in particular\nwithin economics and the decision sciences. In the book Savage\npresents a set of axioms constraining preferences over a set of\noptions that guarantee the existence of a pair of probability and\nutility functions relative to which the preferences can be represented\nas maximising expected utility. Nearly three decades prior to the\npublication of the book, Frank P. Ramsey (1926) had actually proposed\nthat a different set of axioms can generate more or less the same\nresult. Nevertheless, Savage’s theory has been much more\ninfluential than Ramsey’s, perhaps because Ramsey neither gave a\nfull proof of his result nor provided much detail of how it would go\n(Bradley 2004). Savage’s result will not be described here in\nfull detail. However, the ingredients and structure of his theorem\nwill be laid out, highlighting its strengths and weaknesses. \nThe options or prospects in Savage’s theory are similar to\nlotteries, except that the possible outcomes do not come with\nprobabilities but rather depend on whether a particular state of the\nworld is actual. Indeed, the primitives in Savage’s theory are\n outcomes[4]\n and states (of the world). The former are the good or bad\nstates of affairs that ultimately affect and matter to an agent, while\nthe latter are the features of the world that the agent has no control\nover and which are the locus of her uncertainty about the world. Sets\nof states are called events. This distinction between\noutcomes and states serves to neatly separate desire and belief: the\nformer are, according to Savage’s theory, the target of desire,\nwhile the latter are the target of belief. \nThe lottery-like options over which the agent has preferences are a\nrich set of acts that effectively amount to all the possible\nassignments of outcomes to states of the world. That is, acts are\nfunctions from the state space to the outcome space, and the\nagent’s preference ordering is taken to be defined over all such\npossible functions. Some of these acts will look quite sensible:\nconsider the act that assigns to the event “it rains” the\noutcome “miserable wet stroll” and assigns to the event\n“it does not rain” the outcome “very comfortable\nstroll”. This is apparently the act of going for a stroll\nwithout one’s umbrella. Other Savage acts will not look quite so\nsensible, such as the constant act that assigns to both\n“it rains” and “it does not rain” the same\noutcome “miserable wet stroll”. (Note that the constant\nacts provide a way of including sure outcomes within the preference\nordering.) The problem with this act (and many others) is that it does\nnot correspond to anything that an agent could even in principle\nchoose to do or\n perform.[5] \nSavage’s act/state(event)/outcome distinction can be naturally\nrepresented in tabular form, with rows serving as acts that yield a\ngiven outcome for each state/event column. Table 2 depicts the two\nacts mentioned above plus a third one that the decision maker might\ncare about: the acts i) “go for stroll without umbrella”,\nii) “go for stroll with umbrella”, and iii) the bizarre\nconstant act. Of course, the set of acts required for Savage’s\ntheorem involve even more acts that account for all the possible\ncombinations of states and outcomes. \nTable 2. Savage-style decision table \nBefore discussing Savage’s axioms, let us state the result that\nthey give rise to. The following notation will be used: \\(f\\), \\(g\\),\netc, are various acts, i.e., functions from the set \\(\\bS\\) of states\nof the world to the set \\(\\bO\\) of outcomes, with \\(\\bF\\) the set of\nthese functions. \\(f(s_i)\\) denotes the outcome of \\(f\\) when state\n\\(s_i\\in\\bS\\) is actual. The expected utility of \\(f\\), according to\nSavage’s theory, denoted \\(U(f)\\), is given by: \nSavage’s equation\n\n\\(U(f)=\\sum_i u(f(s_i))\\cdot P(s_i)\\)  \nThe result Savage proved can be stated as\n follows:[6] \nThe agent’s confidence in the actuality of the states in \\(\\bS\\)\ncan be represented by a unique (and finitely additive)\nprobability function, \\(P\\); \nthe strength of her desires for the ultimate outcomes in \\(\\bO\\) can\nbe represented by a utility function, \\(u\\), that is unique up to\npositive linear transformation; \nand the pair \\((P, u)\\) gives rise to an expected utility function,\n\\(U\\), that represents her preferences for the alternatives in\n\\(\\bF\\); i.e., for any \\(f, g\\in\\bF\\): \nThe above result may seem remarkable; in particular, the fact that a\nperson’s preferences can determine a unique probability function\nthat represents her beliefs. On a closer look, however, it is evident\nthat some of our beliefs can be determined by examining our\npreferences. Suppose you are offered a choice between two lotteries,\none that results in you winning a nice prize if a coin comes up heads\nbut getting nothing if the coin comes up tails, another that results\nin you winning the same prize if the coin comes up tails but getting\nnothing if the coin comes up heads. Then assuming that the\ndesirability of the prize (and similarly the desirability of no prize)\nis independent of how the coin lands, your preference between the two\nlotteries should be entirely determined by your comparative beliefs\nfor the two ways in which the coin can land. For instance, if you\nstrictly prefer the first lottery to the second, then that suggests\nyou consider heads more likely than tails. \nThe above observation suggests that one can gauge an agent’s\ncomparative beliefs, and perhaps more, from her preferences. Savage\nwent one step further than this, and defined comparative\nbeliefs in terms of preferences. To state Savage’s definition,\nlet \\(\\wcbrel\\) be a weak comparative belief relation, defined on the\nset \\(\\bS\\) of states of the world. (\\(\\cbrel\\) and \\(\\wcbsim\\) are\ndefined in terms of \\(\\wcbrel \\) in the usual way.) \nDefinition 1 (Comparative Belief).\n\nSuppose \\(E\\) and \\(F\\) are two events (i.e., subsets of \\(\\bS\\)).\nSuppose \\(X\\) and \\(Y\\) are two outcomes and \\(f\\) and \\(g\\) two acts,\nwith the following properties: \nThen \\(E \\wcbrel F\\Leftrightarrow f\\preceq g\\). \nDefinition 1 is based on the simple observation that one would\ngenerally prefer to stake a good outcome on a more rather than less\nprobable event. But the idea that this defines comparative\nbeliefs might seem questionable. We could, for instance, imagine\npeople who are instrumentally irrational, and as a result fail to\nprefer \\(g\\) to \\(f\\), even when the above conditions all hold and\nthey find \\(F\\) more likely than \\(E\\). Moreover, this definition\nraises the question of how to define the comparative beliefs of those\nwho are indifferent between all outcomes (Eriksson and\nHájek 2007). Perhaps no such people exist (and Savage’s\n axiom P5\n indeed makes clear that his result does not pertain to such people).\nNevertheless, it seems a definition of comparative beliefs should not\npreclude that such people, if existent, have strict\ncomparative beliefs. Savage suggests that this definition of\ncomparative beliefs is plausible in light of his axiom P4, which will\nbe stated below. In any case, it turns out that when a person’s\npreferences satisfy Savage’s axioms, we can read off her\npreferences a comparative belief relation that can be represented by a\n(unique) probability function. \nWithout further ado, let us state Savage’s axioms in turn. These\nare intended as constraints on an agent’s preference relation,\n\\(\\preceq\\), over a set of acts, \\(\\bF\\), as described above. The\nfirst of Savage’s axioms is the basic ordering axiom. \nP1. (Ordering)\n\nThe relation \\(\\preceq\\) is complete and transitive. \nThe next axiom is reminiscent of vNM’s Independence axiom. We\nsay that alternative \\(f\\) “agrees with” \\(g\\) in event\n\\(E\\) if, for any state in event \\(E\\), \\(f\\) and \\(g\\) yield the same\noutcome. \nP2. (Sure Thing Principle)\n\nIf \\(f\\), \\(g\\), and \\(f'\\), \\(g'\\) are such that: \nthen \\(f'\\preceq g'\\). \nThe idea behind the Sure Thing Principle (STP) is essentially the same\nas that behind Independence: since we should be able to evaluate each\noutcome independently of other possible outcomes, we can safely ignore\nstates of the world where two acts that we are comparing result in the\nsame outcome. Putting the principle in tabular form may make this more\napparent. The setup involves four acts with the following form:  \nThe intuition behind the STP is that if \\(g\\) is weakly preferred to\n\\(f\\), then that must be because the consequence \\(Y\\) is considered\nat least as desirable as \\(X\\), which by the same reasoning implies\nthat \\(g'\\) is weakly preferred to \\(f'\\). \nSavage also requires that the desirability of an outcome be\nindependent of the state in which it occurs, as this is necessary for\nit to be possible to determine a comparative belief relation from an\nagent’s preferences. To formalise this requirement, Savage\nintroduces the notion of a null event, defined as\nfollows: \nDefinition 2 (Null)\n\nEvent E is null just in case for any alternatives\n\\(f,g\\in\\bF\\), \\(f\\sim g\\) given E. \nThe intuition is that null events are those events an agent is certain\nwill not occur. If and only if an agent is certain that \\(E\\) will not\noccur, then it is of indifference to her what the acts before her\nyield under \\(E\\). The following axiom then stipulates that knowing\nwhat state is actual does not affect the preference ordering over\noutcomes: \nP3. (State Neutrality)\n\nIf \\(f(s_i)=X\\) and \\(g(s_i)=Y\\) whenever \\(s_i\\in E\\) and \\(E\\) is\nnot null, then \\(f\\preceq g\\) given \\(E\\) just in case \\(X\\preceq\nY\\). \nThe next axiom is also necessary for it to be possible to determine a\ncomparative belief relation from an agent’s preferences. Above\nit was suggested that by asking you to stake a prize on whether a coin\ncomes up heads or tails, it can be determined which of these events,\nheads or tails, you find more likely. But that suggestion is only\nplausible if the size of the prize does not affect your judgement of\nthe relative likelihood of these two events. That assumption is\ncaptured by the next axioms. Since the axiom is rather complicated it\nwill be stated in tabular form: \nP4. Consider the following acts: \nNow suppose: \nThen \nLess formally (and stated in terms of strict preference), the idea is\nthat if you prefer to stake the prize \\(X\\) on \\(f\\) rather than\n\\(f'\\), you must consider \\(E\\) more probable than \\(F\\). Therefore,\nyou should prefer to stake the prize \\(Y\\) on \\(g\\) rather than \\(g'\\)\nsince the prize itself does not affect the probability of the\nevents. \nThe next axiom is arguably not a rationality requirement, but one of\nSavage’s “structural axioms” (Suppes 2002). An agent\nneeds to have some variation in preference for it to be possible to\nread off her comparative beliefs from her preferences; and, more\ngenerally, for it to be possible to represent her as maximising\nexpected utility. To this end, the next axiom simply requires that\nthere be some alternatives between which the agent is not\nindifferent: \nP5.\n\nThere are some \\(f,g\\in\\bF\\) such that \\(f\\prec g\\). \nWhen these five axioms are satisfied, the agent’s preferences\ngive rise to a comparative belief relation, \\(\\wcbrel \\), which has\nthe property of being a qualitative probability relation,\nwhich is necessary for it to be possible to represent \\(\\wcbrel \\) by\na probability function. In other words, \\(\\wcbrel \\) satisfies the\nfollowing three conditions, for any events \\(E\\), \\(F\\) and \\(G\\): \n\\(\\wcbrel \\) is transitive and complete, \nif \\(E\\cap G=\\emptyset=F\\cap G\\), then \\(E \\wcbrel F\\Leftrightarrow\nE\\cup G \\wcbrel F\\cup G\\), \n\\(\\emptyset \\wcbrel E,\\)   \\(\\emptyset \\cbrel \\bS\\) \nBeing a qualitative probability relation is, however, not sufficient\nto ensure the possibility of probabilistic representation. To ensure\nthis possibility, Savage added the following structural axiom: \nP6. (Non-atomicity)\n\nSuppose \\(f\\prec g\\). Then for any \\(X\\in\\bO\\), there is a\nfinite partition, \\(\\{E_1, E_2, … E_m\\}\\), of \\(\\bS\\) such\nthat: \nLike the Continuity axiom of vNM, Non-Atomicity implies that no matter\nhow bad an outcome \\(X\\) is, if \\(g\\) is already preferred to \\(f\\),\nthen if we add \\(X\\) as one of the possible outcomes of\n\\(f\\)—thereby constructing a new alternative \\(f'\\)—\\(g\\)\nwill still be preferred to the modified alternative as long as the\nprobability of \\(X\\) is sufficiently small. In effect, Non-Atomicity\nimplies that \\(\\bS\\) contains events of arbitrarily small probability.\nIt is not too difficult to imagine how that could be satisfied. For\ninstance, any event \\(F\\) can be partitioned into two equiprobable\nsub-events according to whether some coin would come up heads or tails\nif it were tossed. Each sub-event could be similarly partitioned\naccording to the outcome of the second toss of the same coin, and so\non. \nSavage showed that whenever these six axioms are satisfied, the\ncomparative belief relation can be represented by a unique\nprobability function. Having done so, he could rely on the vNM\nrepresentation theorem to show that an agent who satisfies all six\n axioms[7]\n can be represented as maximising expected utility, relative to a\nunique probability function that plausibly represents the\nagent’s beliefs over the states and a cardinal utility function\nthat plausibly represents the agent’s desires for ultimate\noutcomes (recall the statement of Savage’s theorem\n above).[8]\n Savage’s own proof is rather complicated, but Kreps (1988)\nprovides a useful illustration of it. \nThere is no doubt that Savage’s expected utility\nrepresentation theorem is very powerful. There are, however, two\nimportant questions to ask about whether Savage achieves his aims: 1)\nDoes Savage characterise rational preferences, at least in\nthe generic sense? And 2) Does Savage’s theorem tell us how to\nmake rational decisions in the real world? Savage’s theory has\nproblems meeting these two demands, taken together. Arguably the core\nweakness of the theory is that its various constraints and assumptions\npull in different directions when it comes to constructing realistic\ndecision models, and furthermore, at least one constraint (notably,\nthe Sure Thing Principle) is only plausible under decision modelling\nassumptions that are supposed to be the output, not the input, of the\ntheory. \nOne well recognised decision-modelling requirement for Savage’s\ntheory is that outcomes be maximally specific in every way that\nmatters for their evaluation. If this were not the case, the axiom of\nState Neutrality, for instance, would be a very implausible\nrationality constraint. Suppose we are, for example, wondering whether\nto buy cocoa or lemonade for the weekend, and assume that how good we\nfind each option depends on what the weather will be like. Then we\nneed to describe the outcomes such that they include the state of the\nweather. For if we do not, the desirability of the outcomes will\ndepend on what state is actual. Since lemonade is, let us suppose,\nbetter on hot days than cold, an outcome like “I drink lemonade\nthis weekend” would be more or less desirable depending on\nwhether it occurs in a state where it is hot or cold. This would be\ncontrary to the axiom of State Neutrality. Therefore, the appropriate\noutcomes in this case are those of the form “I drink lemonade\nthis weekend in hot weather”. (Of course, this outcome must be\nsplit into even more fine-grained outcomes if there are yet further\nfeatures that would affect the choice at hand, such as sharing the\ndrink with a friend who loves lemonade versus sharing the drink with a\nfriend who loves hot cocoa, and so on.) \nThe fact that the outcomes in the above case must be specific enough\nto contain the state of the weather may seem rather innocuous.\nHowever, this requirement exacerbates the above-mentioned problem that\nmany of the options/acts that Savage requires for his representation\ntheorem are nonsensical, in that the semantic content of state/outcome\npairs is contradictory. Recall that the domain of the preference\nordering in Savage’s theory amounts to every function\nfrom the set of states to the set of outcomes (what Broome 1991a\nrefers to as the Rectangular Field Assumption). So if\n“I drink lemonade this weekend in hot weather” is one of\nthe outcomes we are working with, and we have partitioned the set of\nstates according to the weather, then there must, for instance, be an\nact that has this outcome in the state where it is cold! The more\ndetailed the outcomes (as required for the plausibility of State\nNeutrality), the less plausible the Rectangular Field Assumption. This\nis an internal tension in Savage’s framework. Indeed, it is\ndifficult to see how/why a rational agent can/should form preferences\nover nonsensical acts (although see Dreier 1996 for an argument that\nthis is not such an important issue). Without this assumption,\nhowever, the agent’s preference ordering will not be adequately\nrich for Savage’s rationality constraints to yield the EU\nrepresentation\n result.[9] \nThe axiom in Savage’s theory that has received most attention is\nthe Sure Thing Principle. It is not hard to see that this principle\nconflicts with Allais’ preferences for the same reason these\npreferences conflict with Independence (recall\n Section 2.3).\n Allais’ challenge will be discussed again later. For now, our\nconcern is rather the Sure Thing Principle vis-à-vis the\ninternal logic of Savage’s theory. To begin with, the Sure Thing\nPrinciple, like State Neutrality, exacerbates concerns about the\nRectangular Field Assumption. This is because the Sure Thing Principle\nis only plausible if outcomes are specific enough to account for any\nsort of dependencies between outcomes in different states of the\nworld. For instance, if the fact that one could have chosen a\nrisk-free alternative—and thereby guaranteed an acceptable\noutcome—makes a difference to the desirability of receiving\nnothing after having taken a risk (as in Allais’ problem), then\nthat has to be accounted for in the description of the outcomes. But\nagain, if we account for such dependencies in the description of the\noutcomes, we run into the problem that there will be acts in the\npreference ordering that are nonsensical (see, e.g., Broome 1991a: ch.\n5). \nThere is a further internal problem with Savage’s theory\nassociated with the Sure Thing Principle: the principle is only\nreasonable when the decision model is constructed such that there is\nprobabilistic independence between the acts an agent is considering\nand the states of the world that determine the outcomes of these acts.\nRecall that the principle states that if we have four options with the\nfollowing form:  \nthen if \\(g\\) is weakly preferred to \\(f\\), \\(g'\\) must be weakly\npreferred to \\(f'\\). Suppose, however, that there is probabilistic\ndependency between the states of the world and the alternatives we are\nconsidering, and that we find \\(Z\\) to be better than both \\(X\\) and\n\\(Y\\), and we also find \\(W\\) to be better than both \\(X\\) and \\(Y\\).\nMoreover, suppose that \\(g\\) makes \\(\\neg E\\) more likely than \\(f\\)\ndoes, and \\(f'\\) makes \\(\\neg E\\) more likely than \\(g'\\) does. Then\nit seems perfectly reasonable to prefer \\(g\\) over \\(f\\) but \\(f'\\)\nover \\(g'\\). \nWhy is the requirement of probabilistic independence problematic? For\none thing, in many real-world decision circumstances, it is hard to\nframe the decision model in such a way that states are intuitively\nprobabilistically independent of acts. For instance, suppose an agent\nenjoys smoking, and is trying to decide whether to quit or not. How\nlong she lives is amongst the contingencies that affect the\ndesirability of smoking. It would be natural to partition the set of\nstates according to how long the agent lives. But then it is obvious\nthat the options she is considering could, and arguably should, affect\nhow likely she finds each state of the world, since it is well\nrecognised that life expectancy is reduced by smoking. Savage would\nthus require an alternative representation of the decision\nproblem—the states do not reference life span directly, but\nrather the agent’s physiological propensity to react in a\ncertain way to smoking. \nPerhaps there is always a way to contrive decision models such that\nacts are intuitively probabilistically independent of states. But\ntherein lies the more serious problem. Recall that Savage was trying\nto formulate a way of determining a rational agent’s beliefs\nfrom her preferences over acts, such that the beliefs can ultimately\nbe represented by a probability function. If we are interested in\nreal-world decisions, then the acts in question ought to be\nrecognisable options for the agent (which we have seen is\nquestionable). Moreover, now we see that one of Savage’s\nrationality constraints on preference—the Sure Thing\nPrinciple—is plausible only if the modelled acts are\nprobabilistically independent of the states. In other words, this\nindependence must be built into the decision model if it is to\nfacilitate appropriate measures of belief and desire. But this is to\nassume that we already have important information about the beliefs of\nthe agent whose attitudes we are trying to represent; namely what\nstate-partitions she considers probabilistically independent of her\nacts. \nThe above problems suggest there is a need for an alternative theory\nof choice under uncertainty. Richard Jeffrey’s theory, which\nwill be discuss next, avoids all of the problems that have been\ndiscussed so far. But as we will see, Jeffrey’s theory has\nwell-known problems of its own, albeit problems that are not\ninsurmountable. \nRichard Jeffrey’s expected utility theory differs from\nSavage’s in terms of both the prospects (i.e., options)\nunder consideration and the rationality constraints on\npreferences over these prospects. The distinct advantage of\nJeffrey’s theory is that real-world decision problems can be\nmodelled just as the agent perceives them; the plausibility of the\nrationality constraints on preference do not depend on decision\nproblems being modelled in a particular way. We first describe the\nprospects or decision set-up and the resultant expected utility rule,\nbefore turning to the pertinent rationality constraints on preferences\nand the corresponding theorem. \nUnlike Savage, Jeffrey does not make a distinction between the objects\nof instrumental and non-instrumental desire (acts and outcomes\nrespectively) and the objects of belief (states of the world). Rather,\nJeffrey assumes that propositions describing states of\naffairs are the objects of both desire and belief. On first sight,\nthis seems unobjectionable: just as we can have views about whether it\nwill in fact rain, we can also have views about how desirable that\nwould be. The uncomfortable part of this setup is that acts, too, are\njust propositions—they are ordinary states of affairs about\nwhich an agent has both beliefs and desires. Just as the agent has a\npreference ordering over, say, possible weather scenarios for the\nweekend, she has a preference ordering over the possible acts that she\nmay perform, and in neither case is the most preferred state of\naffairs necessarily the most likely to be true. In other words, the\nonly thing that picks out acts as special is their substantive\ncontent—these are the propositions that the agent has the power\nto choose/make true in the given situation. It is as if the agent\nassesses her own options for acting from, rather, a third-person\nperspective. If one holds that a decision model should convincingly\nrepresent the subjective perspective of the agent in question, this is\narguably a weakness of Jeffrey’s theory, although it may be one\nwithout\n consequence.[10] \nBefore proceeding, a word about propositions may be helpful: they are\nabstract objects that can be either true or false, and are commonly\nidentified with sets of possible worlds. A possible world can be\nthought of as an abstract representation of how things are or could be\n(Stalnaker 1987; see also entry on\n possible worlds).\n The proposition that it rains at time \\(t\\), for example, is just the\nset of all worlds where it rains at time \\(t\\). And this particular\nproposition is true just in case the actual world happens to be a\nmember of the set of all worlds where it rains at time \\(t\\).  \nThe basic upshot of Jeffrey’s theory is that the desirability of\na proposition, including one representing acts, depends both on the\ndesirabilities of the different ways in which the proposition can be\ntrue, and the relative probability that it is true in these respective\nways. To state this more precisely, \\(p\\), \\(q\\), etc., will denote\npropositional variables. Let \\(\\{p_1, p_2, …, p_n\\}\\) be one\namongst many finite partitions of the proposition \\(p\\); that is, sets\nof mutually incompatible but jointly exhaustive ways in which the\nproposition \\(p\\) can be realised. For instance, if \\(p\\) is the\nproposition that it is raining, then we could partition this\nproposition very coarsely according to whether we go to the beach or\nnot, but we could also partition \\(p\\) much more finely, for instance\naccording to the precise millimetres-per-hour amount of rain. The\ndesirability of \\(p\\) according to Jeffrey, denoted \\(Des(p)\\), is\ngiven by: \nJeffrey’s equation.\n\n\\(Des(p)=\\sum_i Des(p_i)\\cdot P(p_i\\mid p)\\)  \nThis is effectively a conditional expected utility formula\nfor evaluating \\(p\\). As noted, a special case is when the content of\n\\(p\\) is such that it is recognisably something the agent can choose\nto make true, i.e., an act. \nOne important difference between Jeffrey’s desirability formula\nand Savage’s expected utility formula, is that there is no\ndistinction made between desirability and “expected”\ndesirability, unlike what has to be done in Savage’s theory,\nwhere there is a clear distinction between utility, measuring an\nagent’s fundamental desires for ultimate outcomes, and expected\nutility, measuring an agent’s preferences over uncertain\nprospects or acts. This disanalogy is due to the fact that there is no\nsense in which the \\(p_i\\)s that \\(p\\) is evaluated in terms of need\nto be ultimate outcomes; they can themselves be thought of as\nuncertain prospects that are evaluated in terms of their different\npossible realisations. \nAnother important thing to notice about Jeffrey’s way of\ncalculating desirability, is that it does not assume probabilistic\nindependence between the alternative that is being evaluated, \\(p\\),\nand the possible ways, the \\(p_i\\)s, that the alternative may be\nrealised. Indeed, the probability of each \\(p_i\\) is explicitly\nconditional on the \\(p\\) in question. When it comes to evaluating\nacts, this is to say (in Savage’s terminology) that the\nprobabilities for the possible state-outcome pairs for the act are\nconditional on the act in question. Thus we see why the agent can\ndescribe her decision problem just as she sees it; there is no\nrequirement that she identify a set of states (in Jeffrey’s\ncase, this would be a partition of the proposition space that is\northogonal to the act partition) such that the states are\nappropriately fine-grained and probabilistically independent of the\nacts. \nIt should moreover be evident, given the discussion of the Sure Thing\nPrinciple (STP) in\n Section 3.1,\n that Jeffrey’s theory does not have this axiom. Since states\nmay be probabilistically dependent on acts, an agent can be\nrepresented as maximising the value of Jeffrey’s desirability\nfunction while violating the STP. Moreover, unlike Savage’s,\nJeffrey’s representation theorem does not depend on anything\nlike the Rectangular Field Assumption. The agent is not required to\nhave preferences over artificially constructed acts or propositions\nthat turn out to be nonsensical, given the interpretation of\nparticular states and outcomes. In fact, only those propositions the\nagent considers to be possible (in the sense that she assigns them a\nprobability greater than zero) are, according to Jeffrey’s\ntheory, included in her preference ordering. \nOf course, we still need certain structural assumptions in order to\nprove a representation theorem for Jeffrey’s theory. In\nparticular, the set \\(\\Omega\\), on which the preference ordering\n\\(\\preceq\\) is defined, has to be an atomless Boolean algebra\nof propositions, from which the impossible propositions, denoted\n\\(\\bot\\), have been removed. A Boolean algebra is just a set of e.g.\npropositions or sentences that is closed under the classical logical\noperators and negation. An algebra is atomless just in case all of its\nelements can be partitioned into finer elements. The assumption that\n\\(\\Omega\\) is atomless is thus similar to Savage’s\n P6,\n and can be given a similar justification: any way \\(p_i\\) in which\n\\(p\\) can be true can be partitioned into two further propositions\naccording to how some coin would land if tossed. \nSo under what conditions can a preference relation \\(\\preceq\\) on the\nset \\(\\Omega\\) be represented as maximising desirability? Some of the\nrequired conditions on preference should be familiar by now and will\nnot be discussed further. In particular, \\(\\preceq\\) has to be\ntransitive, complete and continuous (recall our discussion in\n Section 2.3\n of vNM’s Continuity preference axiom). \nThe next two conditions are, however, not explicitly part of the two\nrepresentation theorems that have been considered so far: \nAveraging\n\nIf \\(p,\\ q\\in \\Omega\\) are mutually incompatible, then \nImpartiality\n\nSuppose \\(p,\\ q\\in \\Omega\\) are mutually incompatible and \\(p\\sim q\\).\nThen if \\(p\\cup r\\sim q\\cup r\\) for some \\(r\\) that is\nmutually incompatible with both \\(p\\) and \\(q\\) and is such that\n\\(\\neg(r\\sim p)\\), then \\(p\\cup r\\sim q\\cup r\\) for every\nsuch \\(r\\). \nAveraging is the distinguishing rationality condition in\nJeffrey’s theory. It can actually be seen as a weak version of\nIndependence and the Sure Thing Principle, and it plays a similar role\nin Jeffrey’s theory. But it is not directly inconsistent with\nAllais’ preferences, and its plausibility does not depend on the\ntype of probabilistic independence that the STP implies. The postulate\nrequires that no proposition be strictly better or worse than all of\nits possible realisations, which seems to be a reasonable requirement.\nWhen \\(p\\) and \\(q\\) are mutually incompatible, \\(p\\cup q\\) implies\nthat either \\(p\\) or \\(q\\) is true, but not both. Hence, it seems\nreasonable that \\(p\\cup q\\) should be neither strictly more nor less\ndesirable than both \\(p\\) and \\(q\\). Suppose one of \\(p\\) or \\(q\\) is\nmore desirable than the other. Then since \\(p\\cup q\\) is compatible\nwith the truth of either the more or the less desirable of the two,\n\\(p\\cup q\\)’s desirability should fall strictly between that of\n\\(p\\) and that of \\(q\\). However, if \\(p\\) and \\(q\\) are equally\ndesirable, then \\(p\\cup q\\) should be as desirable as each of the\ntwo. \nThe intuitive appeal of Impartiality, which plays a similar role in\nJeffrey’s theory as P4 does in Savage’s, is not as great\nas that of Averaging. Jeffrey himself admitted as much in his comment:\n \nThe axiom is there because we need it, and it is justified by our\nantecedent belief in the plausibility of the result we mean to deduce\nfrom it. (1965: 147)  \nNevertheless, it does seem that an argument can be made that any\nreasonable person will satisfy this axiom. Suppose you are indifferent\nbetween two propositions, \\(p\\) and \\(q\\), that cannot be\nsimultaneously true. And suppose now we find a proposition \\(r\\), that\nis pairwise incompatible with both \\(p\\) and \\(q\\), and which you find\nmore desirable than both \\(p\\) and \\(q\\). Then if it turns out that\nyou are indifferent between \\(p\\) joined with \\(r\\) and \\(q\\) joined\nwith \\(r\\), that must be because you find \\(p\\) and \\(q\\) equally\nprobable. Otherwise, you would prefer the union that contains the one\nof \\(p\\) and \\(q\\) that you find less probable, since that gives you a\nhigher chance of the more desirable proposition \\(r\\). It then follows\nthat for any other proposition \\(s\\) that satisfies the aforementioned\nconditions that \\(r\\) satisfies, you should also be indifferent\nbetween \\(p\\cup s\\) and \\(q\\cup s\\), since, again, the two unions are\nequally likely to result in \\(s\\). \nThe first person to prove a theorem stating sufficient conditions for\na preference relation to be representable as maximising the value of a\nJeffrey-desirability function was actually not Jeffrey himself, but\nthe mathematician Ethan Bolker (1966, 1967). He proved the following\nresult (recall the definition of a “desirability measure”\ngiven\n above):[11] \nTheorem 4 (Bolker)\n\nLet \\(\\Omega\\) be a complete and atomless Boolean algebra of\npropositions, and \\(\\preceq\\) a continuous, transitive and complete\nrelation on \\(\\Omega \\setminus \\bot \\), that satisfies Averaging and\nImpartiality. Then there is a desirability measure on \\(\\Omega\n\\setminus \\bot \\) and a probability measure on \\(\\Omega\\) relative to\nwhich \\(\\preceq\\) can be represented as maximising desirability. \nUnfortunately, Bolker’s representation theorem does not yield a\nresult anywhere near as unique as Savage’s. Even if a\nperson’s preferences satisfy all the conditions in\nBolker’s theorem, then it is neither guaranteed that there will\nbe just one probability function that represents her beliefs nor that\nthe desirability function that represents her desires will be unique\nup to a positive linear transformation (unless her preferences are\nunbounded). Even worse, the same preference ordering satisfying all\nthese axioms could be represented as maximising desirability relative\nto two probability functions that do not even agree on how to order\npropositions according to their\n probability.[12] \nFor those who think that the only way to determine a person’s\ncomparative beliefs is to look at her preferences, the lack of\nuniqueness in Jeffrey’s theory is a big problem. Indeed, this\nmay be one of the main reasons why economists have largely ignored\nJeffrey’s theory. Economists have traditionally been skeptical\nof any talk of a person’s desires and beliefs that goes beyond\nwhat can be established by examining the person’s preferences,\nwhich they take to be the only attitude that is directly revealed by a\nperson’s behaviour. For these economists, it is therefore\nunwelcome news if we cannot even in principle determine the\ncomparative beliefs of a rational person by looking at her\npreferences. \nThose who are less inclined towards behaviourism might, however, not\nfind this lack of uniqueness in Bolker’s theorem to be a\nproblem. James Joyce (1999), for instance, thinks that Jeffrey’s\ntheory gets things exactly right in this regard, since one should not\nexpect that reasonable conditions imposed on a person’s\npreferences would suffice to determine a unique probability function\nrepresenting the person’s beliefs. It is only by imposing overly\nstrong conditions, as Savage does, that we can achieve this. However,\nif uniqueness is what we are after, then we can, as Joyce points out,\nsupplement the Bolker-Jeffrey axioms with certain conditions on the\nagent’s comparative belief relation (e.g. those proposed by\nVillegas 1964) that, together with the Bolker-Jeffrey axioms, ensure\nthat the agent’s preferences can be represented by a unique\nprobability function and a desirability function that is unique up to\na positive linear transformation. \nInstead of adding specific belief-postulates to Jeffrey’s\ntheory, as Joyce suggests, one can get the same uniqueness result by\nenriching the set of prospects. Richard Bradley (1998) has, for\ninstance, shown that if one extends the Boolean algebra in\nJeffrey’s theory to indicative conditionals, then a preference\nrelation on the extended domain that satisfies the Bolker-Jeffrey\naxioms (and some related axioms that specifically apply to\nconditionals) will be representable as maximising desirability, where\nthe probability function is unique and the desirability function is\nunique up to a positive linear transformation. \nIt was noted from the outset that EU theory is as much a theory of\nrational choice, or overall preferences amongst acts, as it is a\ntheory of rational belief and desire. This section expands, in turn,\non the epistemological and evaluative commitments of EU theory. \nSome refer to EU theory as Bayesian decision theory. This\nlabel brings to the forefront the commitment to probabilism,\ni.e., that beliefs may come in degrees which, on pain of\nirrationality, can be represented numerically as probabilities. So\nthere is a strong connection between EU theory and probabilism, or\nmore generally between rational preference and rational belief. (The\nfiner details of rational preference and associated rational belief\nare not the focus here; challenges to EU theory on this front are\naddressed in\n Section 5\n below.) \nSome take the connection between rational preference and rational\nbelief to run very deep indeed. At the far end of the spectrum is the\nposition that the very meaning of belief involves preference. Indeed,\nrecall this manoeuvre in Savage’s theory, discussed earlier in\n Section 3.1.\n Many question the plausibility, however, of equating comparative\nbelief with preferences over specially contrived prospects. A more\nmoderate position is to regard these preferences as entailed by, but\nnot identical with, the relevant comparative beliefs. Whether or not\nbeliefs merely ground or are defined in terms of preference, there is\na further question as to whether the only justification for rational\nbelief having a certain structure (say, conforming to the probability\ncalculus) is a pragmatic one, i.e., an argument resting on the\nagent’s preferences being otherwise inconsistent or\nself-defeating. A recent defender of this kind of pragmatism (albeit\ncast in more general terms) is Rinard (e.g., 2017). Others contend\nthat accounts of rational belief can and should be ultimately\njustified on epistemic grounds; Joyce (1998), for instance, offers a\nnon-pragmatic justification of probabilism that rests on the notion of\noverall “distance from the truth” of one’s beliefs.\n(For further developments of this position, see the entry on\n epistemic utility arguments for probabilism.) \nNotwithstanding these finer disputes, Bayesians agree that pragmatic\nconsiderations play a significant role in managing beliefs. One\nimportant way, at least, in which an agent can interrogate her degrees\nof belief is to reflect on their pragmatic implications. Furthermore,\nwhether or not to seek more evidence is a pragmatic issue; it depends\non the “value of information” one expects to gain with\nrespect to the decision problem at hand. The idea is that seeking more\nevidence is an action that is choice-worthy just in case the expected\nutility of seeking further evidence before making one’s decision\nis greater than the expected utility of making the decision on the\nbasis of existing evidence. This reasoning was made prominent in a\npaper by Good (1967), where he proves that one should always seek\n“free evidence” that may have a bearing on the decision at\nhand. (Precursors of this theorem can be found in Ramsey 1990,\npublished posthumously, and Savage 1954.) Note that the theorem\nassumes the standard Bayesian learning rule known as\n“conditionalisation”, which requires that when one’s\nlearning experience has the form of coming to know some proposition\n(to which one had assigned positive probability) for sure, one’s\nnew degrees of belief should be equal to one’s old degrees of\nbelief conditional on the proposition that now has probability one.\nIndeed, the fact that conditionalisation plays a crucial role in\nGood’s result about the non-negative value of free evidence is\ntaken by some as providing some justification for this learning\nrule. \nSo EU theory or Bayesian decision theory underpins a powerful set of\nepistemic norms. It has been taken as the appropriate account of\nscientific inference, giving rise to a school of statistical inference\nand experimental design and inviting formal interpretations of key\nconcepts like “evidence”, “evidential\nsupport”, “induction” versus\n“abduction”, and the bearing of “coherence”\nand “explanatory power” on truth (see the relevant\n related entries).\n The major competitor to Bayesianism, as regards scientific inference,\nis arguably the collection of approaches known as Classical or Error\nstatistics, which deny the sense of “degrees of support”\n(probabilistic or otherwise) conferred on a hypothesis by evidence.\nThese approaches focus instead on whether a hypothesis has survived\nvarious “severe tests”, and inferences are made with an\neye to the long-run properties of tests as opposed to how they perform\nin any single case, which would require decision-theoretic reasoning\n(see the entry on\n philosophy of statistics). \nEU theory takes a stance on the structure of rational desire too. In\nthis regard, the theory has been criticised on opposing fronts. We\nconsider first the criticism that EU theory is too permissive with\nrespect to what may influence an agent’s desires. We then turn\nto the opposing criticism: that when it comes to desire, EU theory is\nnot permissive enough. \nThe worry that EU theory is too permissive with respect to desire is\nrelated to the worry that the theory is unfalsifiable. The\nworry is that apparently irrational preferences by the lights of EU\ntheory can always be construed as rational, under a suitable\ndescription of the options under consideration. As discussed in\n Section 1\n above, preferences that seem to violate Transitivity can be construed\nas consistent with this axiom so long as the options being compared\nvary in their description depending on, amongst other things, the\nother options under consideration. The same goes for preferences that\nseem to violate Separability or Independence (of the contribution of\neach outcome to the overall value of an option), discussed further in\n Section 5.1\n below. One might argue that this is the right way to describe such\nagents’ preferences. After all, an apt model of preference is\nsupposedly one that captures, in the description of final outcomes and\noptions, everything that matters to an agent. In that case, however,\nEU theory is effectively vacuous or impotent as a standard of\nrationality to which agents can aspire. Moreover, it stretches the\nnotion of what are genuine properties of outcomes that can reasonably\nconfer value or be desirable for an agent. \nThere are two ways one can react to the idea that an agent’s\npreferences are necessarily consistent with EU theory, with the\nabove-mentioned implications for what the agent may desire: \nOne can resist the claim, asserting that there are additional\nconstraints on the content of an agent’s preferences.\nOn the one hand there may be empirical constraints whereby the content\nof preferences is determined by some tradeoff between fit and\nsimplicity in representing the agent’s greater “web”\nof preference attitudes. On the other hand there may be normative\nconstraints with respect to what sorts of outcomes an agent may\nreasonably discriminate (for relevant discussion, see Tversky 1975;\nBroome 1991a & 1993; Pettit 1993; Dreier 1996; Guala 2006;\nVredenburgh 2020). \nOne can alternatively embrace the claim, interpreting EU theory not as\na standard against which an agent may pass or fail, but rather as an\norganising principle that enables the characterisation of an\nagent’s desires as well as her beliefs (see esp. Guala\n2008). \nEither way, it may yet be argued that EU theory does not go far enough\nin structuring an agent’s preference attitudes so that we may\nunderstand the reasons for these preference attitudes.\nDietrich and List (2013 & 2016a) have proposed a more general\nframework that fills this lacuna. In their framework, preferences\nsatisfying some minimal constraints are representable as dependent on\nthe bundle of properties in terms of which each option is perceived by\nthe agent in a given context. Properties can, in turn, be categorised\nas either option properties (which are intrinsic to the\noutcome), relational properties (which concern the outcome in\na particular context), or context properties (which concern\nthe context of choice itself). Such a representation permits more\ndetailed analysis of the reasons for an agent’s preferences and\ncaptures different kinds of context-dependence in an agent’s\nchoices. Furthermore, it permits explicit restrictions on what counts\nas a legitimate reason for preference, or in other words, what\nproperties legitimately feature in an outcome description; such\nrestrictions may help to clarify the normative commitments of EU\ntheory. \nThere are also less general models that offer templates for\nunderstanding the reasons underlying preferences. For instance, the\nmultiple criteria decision framework (see, for instance,\nKeeney and Raiffa 1993) takes an agent’s overall preference\nordering over options to be an aggregate of the set of preference\norderings corresponding to all the pertinent dimensions of value.\nUnder certain assumptions, the overall or aggregate preference\nordering is compatible with EU theory. One might otherwise seek to\nunderstand the role of time, or the temporal position of goods, on\npreferences. To this end, outcomes are described in terms of\ntemporally-indexed bundles of goods, or consumption streams\n(for an early model of this kind see Ramsey 1928; a later influential\ntreatment is Koopmans 1960). There may be systematic structure to an\nagent's preferences over these consumption streams, over and above the\nstructure imposed by the EU axioms of preference. For instance, the\naforementioned authors considered and characterised preferences that\nexhibit exponential time discounting. \nLet’s turn now to the opposing kind of criticism: that the\nlimited constraints that EU theory imposes on rational preference and\ndesire are nonetheless overly restrictive. Here the focus will be on\nthe compatibility of EU theory with prominent ethical positions\nregarding the choice-worthiness of acts, as well as meta-ethical\npositions regarding the nature of value and its relationship to\nbelief. \nOne may well wonder whether EU theory, indeed decision theory more\ngenerally, is neutral with respect to normative ethics, or whether it\nis compatible only with ethical consequentialism, given that\nthe ranking of an act is fully determined by the utility of its\npossible outcomes. Such a model seems at odds with\nnonconsequentialist ethical theories for which the\nchoice-worthiness of acts purportedly depends on more than the moral\nvalue of their consequences. The model does not seem able to\naccommodate basic deontological notions like agent relativity,\nabsolute prohibitions or permissible and yet suboptimal acts. \nAn initial response, however, is that one should not read too much\ninto the formal concepts of decision theory. The utility measure over\nacts and outcomes is simply a convenient way to represent an ordering,\nand leaves much scope for different ways of identifying and evaluating\noutcomes. Just as an agent’s utility function need not be\ninsensitive to ethical considerations in general (a common\nmisconception due to the prevalence of selfish preferences in economic\nmodels; see, for instance, Sen 1977), nor need it be insensitive to\nspecifically nonconsequentialist or deontological ethical\nconsiderations. It all depends on how acts and their outcomes are\ndistinguished and evaluated. For starters, the character of an act may\nfeature as a property of all its possible outcomes. Moreover, whether\nsome event befalls or is perpetrated by the deciding agent or rather\nsomeone else may be relevant. That an act involves lying, say, can be\nreferenced in all possible outcomes of the act, and furthermore this\nlying on the part of the deciding agent can be distinguished from the\nlying of others. In general, acts and their outcomes can be\ndistinguished according to whatever matters morally, be it a complex\nrelational property to do with how and when the act is chosen, by\nwhom, and/or in what way some state of affairs results from the act.\nFor early discussions on how a wide range of ethical properties can be\naccommodated in the description of acts and outcomes, see, for\ninstance, Sen (1982), Vallentyne (1988), Broome (1991b) and Dreier\n(1993). This idea has since been embraced by others associated with\nthe so-called “consequentializing” program, including\nLouise (2004) and Portmore (2007). The idea is that the normative\nadvice of putatively nonconsequentialist ethical theories can be\nrepresented in terms of a ranking of acts/outcomes corresponding to\nsome value function, as per consequentialist ethical theories (see too\nColyvan et al. 2010). \nA sticking point for reconciling decision theory with all forms of\nnonconsequentialism is the difficulty in accommodating absolute\nprohibitions or side constraints (see Oddie and Milne\n1999; Jackson and Smith 2006). For instance, suppose there is a moral\nprohibition against killing an innocent person, whatever else is at\nstake. Perhaps such a constraint is best modelled in terms of a\nlexical ranking and corresponding value function, whereby the\nkilling-innocents status of an act/outcome takes priority in\ndetermining its relative rank/value. But this has counterintuitive\nimplications in the face of risk since very many acts will have some\nchance, however small, of killing an innocent. The lesson here may\nsimply be that the theories in question require development; any\nmature ethical theory owes us an account of how to act under risk or\nuncertainty. What is arguably a more compelling challenge for the\nreconciliation of decision theory and nonconsequentialism is the\naccommodation of “agent-centred options” and associated\n“supererogation”. Portmore (e.g., 2007) and Lazar (e.g.,\n2017) offer proposals to this effect, which appeal (in different ways)\nto the moral ranking of acts/outcomes as distinct from the personal\ncosts to the agent of pursuing these acts/outcomes. \nTo the extent that decision theory can be reconciled with the full\nrange of ethical theories, should we say that there are no meaningful\ndistinctions between these theories? Brown (2011) and Dietrich and\nList (2017) demonstrate that in fact the choice-theoretic\nrepresentation of ethical theories better facilitates distinctions\nbetween them; terms like “(non)consequentialism” can be\nprecisely defined, albeit in debatable ways. More generally, we can\ncatalogue theories in terms of the kinds of properties (whether\nintrinsic or in some sense relational) that distinguish acts/outcomes\nand also in terms of the nature of the ranking of acts/outcomes that\nthey yield (whether transitive, complete, continuous and so on). This\nalso serves to reveal departures from EU theory. \nIndeed, some of the most compelling counterexamples to EU axioms of\npreference rest on ethical considerations. Recall our earlier\ndiscussion of the basic Ordering axioms in\n Section 1.\n The Transitivity axiom has been challenged by appeal to\nethically-motivated examples of preference cycles (see Temkin 2012).\nThe notion of a non-continuous lexical ordering was mentioned above in\nrelation to ethical side constraints. The dispensability of the\nCompleteness axiom, too, is often motivated by appeal to examples\ninvolving competing ethical values that are difficult to tradeoff\nagainst each other, like average versus total welfare. Other\nsuggestive examples against Completeness involve competing notions of\npersonal welfare (see, e.g., Levi 1986; Chang 2002). Must a rational\nagent have a defined preference between, say, two career options that\npull in different directions as regards opportunities for creative\nself-expression versus community service (perhaps a career as a dancer\nversus a career as a doctor in remote regions)? Note that some of\nthese challenges to EU theory are discussed in more depth in\n Section 5\n below. \nFinally, we turn to the potential meta-ethical commitments of EU\ntheory. David Lewis (1988, 1996) famously employed EU theory to argue\nagainst anti-Humeanism, the position that we are sometimes\nmoved entirely by our beliefs about what would be good, rather than by\nour desires as the Humean claims. He formulated the anti-Humean theory\nas postulating a necessary connection between, on the one hand, an\nagent’s desire for any proposition \\(A\\), and, on the other\nhand, her belief in a proposition about \\(A\\)’s goodness; and\nclaimed to prove that when such a connection is formulated in terms of\nEU theory, the agent in question will be dynamically incoherent.\nSeveral people have criticised Lewis’s argument. For instance,\nBroome (1991c), Byrne and Hájek (1997) and Hájek and\nPettit (2004) suggest formulations of anti-Humeanism that are immune\nto Lewis’ criticism, while Stefánsson (2014) and Bradley\nand Stefánsson (2016) argue that Lewis’ proof relies on a\nfalse assumption. Nevertheless, Lewis’ argument no doubt\nprovoked an interesting debate about the sorts of connections between\nbelief and desire that EU theory permits. There are, moreover, further\nquestions of meta-ethical relevance that one might investigate\nregarding the role and structure of desire in EU theory. For instance,\nJeffrey (1974) and Sen (1977) offer some preliminary investigations as\nto whether the theory can accommodate higher-order\ndesires/preferences, and if so, how these relate to first-order\ndesires/preferences. \nThus far the focus has been on prominent versions of the standard\ntheory of rational choice: EU theory. This section picks up on some\nkey criticisms of EU theory that have been developed into alternative\naccounts of rational choice. The proposed innovations to the standard\ntheory are distinct and so are discussed separately, but they are not\nnecessarily mutually exclusive. Note that we do not address all\ncriticisms of EU theory that have inspired alternative accounts of\nrational choice. Two major omissions of this sort (for want of space\nand also because they have been thoroughly addressed in alternative\nentries of this encyclopedia) are i) the problem of causal anomalies\nand the development of causal decision theory (see the entry on\n causal decision theory),\n and ii) the problem of infinite state spaces and the development of\nalternatives like “relative expectation theory” (see the\nentries on\n normative theories of rational choice: expected utility theory\n and\n the St. Petersburg paradox). \nExpected utility theory has been criticised for not allowing for value\ninteractions between outcomes in different, mutually incompatible\nstates of the world. For instance, recall that when deciding between\ntwo risky options you should, according to Savage’s version of\nthe theory, ignore the states of the world where the two options\nresult in the same outcome. That seems very reasonable if we can\nassume separability between outcomes in different states of\nthe world, i.e., if the contribution that an outcome in one state of\nthe world makes towards the overall value of an option is independent\nof what other outcomes the option might result in. For then identical\noutcomes (with equal probabilities) should cancel each other out in a\ncomparison of two options, which would entail that if two options\nshare an outcome in some state of the world, then when comparing the\noptions, it does not matter what that shared outcome is. \nThe Allais paradox, discussed in\n Section 2.3\n above, is a classic example where the aforementioned separability\nseems to fail. For ease of reference, the options that generate the\nparadox are reproduced as Table 3. Recall from\n Section 2.3\n that people tend to prefer \\(L_2\\) over \\(L_1\\) and \\(L_3\\) over\n\\(L_4\\)—an attitude that has been called Allais’\npreferences—in violation of expected utility theory. The\nviolation occurs precisely because the contributions that some of\nthese outcomes make towards the overall value of an option is not\nindependent of the other outcomes that the option can have. Compare\nthe extra chance of outcome $0 that \\(L_1\\) has over \\(L_2\\) with the\nsame extra chance of $0 that \\(L_3\\) has over \\(L_4\\). Many people\nthink that this extra chance counts more heavily in the first\ncomparison than the latter, i.e., that an extra 0.01 chance of $0\ncontributes a greater negative value to \\(L_1\\) than to \\(L_3\\). Some\nexplain this by pointing out that the regret one would\nexperience by winning nothing when one could have had $2400 for\nsure—i.e., when choosing \\(L_1\\) over \\(L_2\\) and the first\nticket is drawn—is much greater than the regret one would\nexperience by winning nothing when the option one turned down also had\na high chance of resulting in $0—such as when choosing \\(L_3\\)\nover \\(L_4\\) (see, e.g., Loomes and Sugden 1982). But whether or not\nthe preference in question should be explained by the potential for\nregret, it would seem that the desirability of the $0-outcome depends\non what could (or would) otherwise have been; in violation of the\naforementioned assumption of separability. (See Thoma 2020a for a\nrecent extensive discussion of this assumption.)  \nTable 3. Allais’ paradox \nVarious attempts have been made to make Allais’ preferences\ncompatible with some version of expected utility theory. A common\nresponse is to suggest that the choice problem has been incorrectly\ndescribed. If it really is rational to evaluate $0 differently\ndepending on which lottery it is part of, then perhaps this should be\naccounted for in the description of the outcomes (Broome 1991a). For\ninstance, we could add a variable to the $0 outcome that \\(L_1\\) might\nresult in to represent the extra regret or risk associate with that\noutcome compared to the $0 outcomes from the other lotteries (as done\nin\n Table 4).\n If we do that, Allais’ preferences are no longer inconsistent\nwith EU theory. The simplest way to see this is to note that when we\nignore the state of the world where the options that are being\ncompared have the same outcome (i.e., when we ignore the last column\nin Table 4), \\(L_1\\) is no longer identical to \\(L_3\\), which means\nthat the Independence axiom of von Neumann and Morgenstern (and\nSavage’s Sure Thing Principle) no longer requires that one\nprefer \\(L_2\\) over \\(L_1\\) only if one prefers \\(L_4\\) over\n\\(L_3\\). \nTable 4. Allais’ paradox\nre-described \nThe above “re-description strategy” could be employed\nwhenever the value and/or contribution of an outcome depends on other\npossible outcomes: just describe the outcomes in a way that accounts\nfor this dependency. But more worryingly, the strategy could be\nemployed whenever one comes across any violation of expected\nutility theory or other theories of rationality (as discussed in\n Section 4.2).\n  \nLara Buchak (2013) has recently developed a decision theory that can\naccommodate Allais’ preferences without re-describing the\noutcomes. On Buchak’s interpretation, the explanation for\nAllais’ preferences is not the different value that the\noutcome $0 has depending on what lottery it is part of. The outcome\nitself has the same value. However, the contribution that $0\nmakes towards the overall value of an option partly depends on what\nother outcomes are possible, she suggests, which reflects the fact\nthat the option-risk that the possibility of $0 generates depends on\nwhat other outcomes the option might result in. To accommodate\nAllais’ preferences (and other intuitively rational attitudes to\nrisk that violate EU theory), Buchak introduces a risk\nfunction that represents people’s willingness to trade\nchances of something good for risks of something bad. And she shows\nthat if an agent satisfies a particular set of axioms, which is\nessentially Savage’s except that the Sure Thing Principle is\nreplaced with a strictly weaker one, then the agent’s\npreferences can be represented as maximising risk weighted\nexpected utility; which is essentially Savage-style expected\nutility weighted by a risk function. \nBradley and Stefánsson (2017) also develop a new decision\ntheory partly in response to the Allais paradox. But unlike Buchak,\nthey suggest that what explains Allais’ preferences is that the\nvalue of wining nothing from a chosen lottery partly depends on what\nwould have happened had one chosen differently. To accommodate this,\nthey extend the Boolean algebra in Jeffrey’s decision theory to\ncounterfactual propositions, and show that Jeffrey’s\nextended theory can represent the value-dependencies one often finds\nbetween counterfactual and actual outcomes. In particular, their\ntheory can capture the intuition that the (un)desirability of winning\nnothing partly depends on whether or not one was guaranteed to win\nsomething had one chosen differently. Therefore, their theory can\nrepresent Allais’ preferences as maximising the value of an\nextended Jeffrey-desirability function. \nStefánsson and Bradley (2019) suggest yet another way of\naccounting for Allais’ preferences in an extension of\nJeffrey’s decision theory; this time extended to chance\npropositions, that is, propositions describing objective\nprobability distributions. The general idea is that the desirability\nof a particular increase or decrease in the chance of some\noutcome—for instance, in the Allais case, a 0.01 increase in the\nchance of the $0-outcome—might depend on what the chances were\nbefore the increase or decrease. Stefánsson and Bradley’s\nextension of Jeffrey’s theory to chance propositions is also\nmotivated by the fact that standard decision theories do not\ndistinguish between risk aversion with respect to some good and\nattitudes to quantities of that good (which is found problematic by,\nfor instance, Hansson 1988, Rabin 2000, and Buchak 2013). \nAs noted in\n Section 4,\n criticisms of the EU requirement of a complete preference ordering\nare motivated by both epistemic and desire/value considerations. On\nthe value side, many contend that a rational agent may simply find two\noptions incomparable due to their incommensurable\nqualities. (Here a prominent usage of these terms will be followed,\nwhereby particular options may be described as incomparable in value,\nwhile general properties or dimensions of value may be described as\nincommensurable.) As in, the agent’s evaluations of the\ndesirability of sure options may not be representable by any precise\nutility function. Likewise, on the belief side, some contend (notably,\nJoyce 2010 and Bradley 2017) that the evidence may be such that it\ndoes not commit a rational agent to precise degrees of belief\nmeasurable by a unique probability function. \nThere are various alternative, “fuzzier” representations\nof desire and belief that might be deemed more suitable. Halpern\n(2003), for instance, investigates different ways of conceptualising\nand representing epistemic uncertainty, once we depart from\nprobabilities. Presumably there are also various ways to represent\nuncertain desire. Here the focus will be on just one proposal that is\npopular amongst philosophers: the use of sets of probability\nand utility functions to represent uncertainty in belief and desire\nrespectively. This is a minimal generalisation of the standard EU\nmodel, in the sense that probability and utility measures still\nfeature. Roughly, the more severe the epistemic uncertainty, the more\nprobability measures over the space of possibilities needed to\nconjointly represent the agent’s beliefs. This notion of\nrational belief is referred to as imprecise probabilism (see\nthe entry on\n imprecise probabilities).\n Likewise, the more severe the evaluative uncertainty, the more\nutility measures over the space of sure options needed to conjointly\nrepresent the agent’s desires. Strictly speaking, we should not\ntreat belief and desire separately, but rather talk of the\nagent’s incomplete preferences being represented by a set of\nprobability and utility pairs. Recall the requirement that incomplete\npreferences be coherently extendible (refer back to\n Section 1);\n on this representation, all the probability-utility pairs amount to\ncandidate extensions of the incomplete preferences. \nThe question then arises: Is there a conservative generalisation of\nthe EU decision rule that can handle sets of probability and utility\npairs? Contender decision rules are standardly framed in terms of\nchoice functions that take as input some set of feasible options and\nreturn as output a non-empty set of admissible choices that is a\nsubset of the feasible options. A basic constraint on these choice\nfunctions is that they respect the agent’s preferences in cases\nwhere options are in fact comparable. That is, if all pairs of\nprobability and utility functions characterising the agent’s\nattitudes agree on the ranking of two options, then these particular\noptions should be ranked accordingly. The relevant constraint on\nchoice functions is that “EU-dominated options” are not\nadmissible choices, i.e., if an option has lower expected utility than\nanother option according to all pairs of probability and utility\nfunctions, then the former dominated option is not an admissible\nchoice. Note that Levi (1986) has a slightly more restrictive\ncondition on admissibility: if an option does not have maximum EU for\nat least one pair of probability and utility functions, then it is not\nadmissible. In ordinary cases where sets of probability and utility\nfunctions are closed convex sets, however, Levi’s condition is\nequivalent to the aforementioned one that rules out EU-dominated\noptions (Schervish et al. 2003). \nThe treatment of genuinely incomparable options (those surviving the\nabove admissibility test and yet are not such that the agent is\nindifferent) is where the real controversies begin. See Bradley (2017)\nfor extensive discussion of the various ways to proceed. A\nconsideration that is often appealed to in order to discriminate\nbetween incomparable options is caution. The Maxmin-EU rule, for\ninstance, recommends picking the action with greatest minimum expected\nutility (see Gilboa and Schmeidler 1989; Walley 1991). The rule is\nsimple to use, but arguably much too cautious, paying no attention at\nall to the full spread of expected utilities. The \\(\\alpha\\)-Maxmin\nrule, by contrast, recommends taking the action with the greatest\n\\(\\alpha\\)-weighted sum of the minimum and maximum expected utilities\nassociated with it. The relative weights for the minimum and maximum\nexpected utilities can be thought of as reflecting either the decision\nmaker’s pessimism in the face of uncertainty or else her degree\nof caution (see Binmore 2009). \nThere are more complicated choice rules that depend on a richer\nrepresentation of uncertainty involving a notion of\nconfidence. For instance, Klibanoff et al. (2005) propose a\nrule whereby choices are made between otherwise incomparable options\non the basis of confidence-weighted expected utility. It presupposes\nthat weights can be assigned to the various expected utilities\nassociated with an act, reflecting the agent’s confidence in the\ncorresponding probability and utility pairs. There are alternative\nrules that appeal to confidence even in the absence of precise\ncardinal weights. Gärdenfors and Sahlin (1982), for instance,\nsuggest simply excluding from consideration any probability (and\nutility) functions that fall below a confidence threshold, and then\napplying the Maxmin-EU rule based on the remainder. Hill’s\n(2013) choice theory is somewhat similar, although confidence\nthresholds for probability and utility pairs are allowed to vary\ndepending on the choice problem (and the term “confidence”\nis itself used differently). There are further proposals whereby acts\nare compared in terms of how much uncertainty they can tolerate (which\nagain depends on levels of confidence) and yet still be a satisfactory\noption (see, e.g., Ben-Haim 2001). These rules are compelling, but\nthey do raise a host of difficult questions regarding how to interpret\nand measure the extra subjective attitudes that play a role, like\n“amount of confidence in a belief/desire” and\n“satisfactory level of desirability”. \nThere has been recent interest in yet a further challenge to expected\nutility theory, namely, the challenge from unawareness. In\nfact, unawareness presents a challenge for all extant normative\ntheories of choice. To keep things simple, we shall however focus on\nSavage’s expected utility theory to illustrate the challenge\nposed by unawareness. \nAs the reader will recall, Savage takes for granted a set of possible\noutcomes \\(\\bO\\), and another set of possible states of the world\n\\(\\bS\\), and defines the set of acts, \\(\\bF\\), as the set of all\nfunctions from \\(\\bS\\) to \\(\\bO\\). Moreover, his representation\ntheorem has been interpreted as justifying the claim that a rational\nperson always performs the act in \\(\\bF\\) that maximises expected\nutility, relative to a probability measure over \\(\\bS\\) and a utility\nmeasure over \\(\\bO\\).  \nNow, Savage’s theory is neutral about how to interpret the\nstates in \\(\\bS\\) and the outcomes in \\(\\bO\\). For instance, the\ntheory is consistent with interpreting \\(\\bS\\) and \\(\\bO\\) as\nrespectively the sets of all logically possible states and\noutcomes, but it is also consistent with interpreting \\(\\bS\\) and\n\\(\\bO\\) as respectively the sets of states and outcomes that some\nmodeller recognises, or the sets of states and outcomes that\nthe decision-maker herself recognises.  \nIf the theory is meant to describe the reasoning of a decision-maker,\nthe first two interpretations would seem inferior to the third. The\nproblem with the first two interpretations is that the decision-maker\nmight be unaware of some of the logically possible states and\noutcomes, as well as some of the states and outcomes that the modeller\nis aware of. (Having said that, one may identify the states and\noutcomes that the agent is unaware of by reference to those of which\nthe modeller is aware.) \nWhen it comes to (partially) unaware decision-makers, an important\ndistinction can be made between on the one hand what we might call\n“unawareness of unawareness”—that is, a situation\nwhere a decision-maker does not realise that there might be some\noutcome or state that they are unaware of—and on the other hand\n“awareness of unawareness”—that is, a situation\nwhere a decision-maker at least suspects that there is some outcome or\nstate of which they are unaware.  \nFrom the perspective of decision-making, unawareness of unawareness is\nnot of much interest. After all, if one is not even aware of the\npossibility that one is unaware of some state or outcome, then that\nunawareness cannot play any role in one’s reasoning about what\nto do. However, decision-theoretic models have been proposed for how a\nrational person responds to growth in awareness (that is\nmeant to apply even to people who previously were unaware of their\nunawareness). In particular, economists Karni and Vierø (2013,\n2015) have recently extended standard Bayesian conditionalisation to\nsuch learning events. Their theory, Reverse Bayesianism,\ninformally says that awareness growth should not affect the ratios of\nprobabilities of the states/outcomes that the agent was aware of\nbefore the growth. Richard Bradley (2017) defends a similar principle\nin the context of the more general Jeffrey-style framework, and so\ndoes Roussos (2020); but the view is criticised by Steele and\nStefánsson (forthcoming-a, forthcoming-b) and by Mahtani\n(forthcoming). \nIn contrast, awareness of unawareness would seem to be of great\ninterest from the perspective of decision-making. If you suspect that\nthere is some possible state, say, that you have not yet entertained,\nand some corresponding outcome, the content of which you are unaware,\nthen you might want to at least come to some view about how likely you\nexpect this state to be, and how good or bad you expect the\ncorresponding outcome to be, before you make a decision. \nA number of people have suggested models to represent agents who are\naware of their unawareness (e.g., Walker & Dietz 2013, Piermont\n2017, Karni & Vierø 2017). Steele and Stefánsson\n(forthcoming-b) argue that there may not be anything especially\ndistinctive about how a decision-maker reasons about states/outcomes\nof which she is aware she is unaware, in terms of the confidence she\nhas in her judgments and how she manages risk. That said, the way she\narrives at such judgments of probability and desirability is worth\nexploring further. Grant and Quiggin (2013a, 2013b), for instance,\nsuggest that these judgments are made based on induction from past\nsituations where one experienced awareness growth. \nIn general, the literature on unawareness has been rapidly growing.\nBradley (2017) and Steele and Stefánsson (forthcoming-b) are\nnew in-depth treatments of this topic within philosophy. Schipper\nmaintains a bibliography on unawareness, mostly with papers in\neconomics and computer science, at\n\\url{http://faculty.econ.ucdavis.edu/faculty/schipper/unaw.htm}.  \nThe decision theories of Savage and Jeffrey, as well as those of their\ncritics, apparently concern a single or “one shot only”\ndecision; at issue is an agent’s preference ordering, and\nultimately her choice of act, at a particular point in time. One may\nrefer to this as a static decision problem. The question\narises as to whether this framework is adequate for handling more\ncomplex scenarios, in particular those involving a series or sequence\nof decisions; these are referred to as sequential decision\nproblems. \nOn paper, at least, static and sequential decision models look very\ndifferent. The static model has familiar tabular or normal\nform, with each row representing an available act/option, and columns\nrepresenting the different possible states of the world that yield a\ngiven outcome for each act. The sequential decision model, on the\nother hand, has tree or extensive form (such as in\n Figure 1).\n It depicts a series of anticipated choice points, where the branches\nextending from a choice point represent the options at that choice\npoint. Some of these branches lead to further choice points, often\nafter the resolution of some uncertainty due to new evidence. \nThese basic differences between static and sequential decision models\nraise questions about how, in fact, they relate to each other: \nDo static and sequential decision models depict the same kind of\ndecision problem? If so, what is the static counterpart of a\nsequential decision model? \nDoes the sequential decision setting reveal any further\n(dis)advantages of EU theory? More generally does this setting shed\nlight on normative theories of choice? \nThese questions turn out to be rather controversial. They will be\naddressed in turn, after the scene has been set with an old story\nabout Ulysses. \nA well-known sequential decision problem is the one facing Ulysses on\nhis journey home to Ithaca in Homer’s great tale from antiquity.\nUlysses must make a choice about the manner in which he will sail past\nan island inhabited by sweet-singing sirens. He can choose to sail\nunrestrained or else tied to the mast. In the former case, Ulysses\nwill later have the choice, upon hearing the sirens, to either\ncontinue sailing home to Ithaca or to stay on the island indefinitely.\nIn the latter case, he will not be free to make further choices and\nthe ship will sail onwards to Ithaca past the sweet-singing sirens.\nThe final outcome depends on what sequence of choices Ulysses makes.\nUlysses’ decision problem is represented in tree (or extensive)\nform in\n Figure 1\n (where the two boxes represent choice points for Ulysses). \nFigure 1. Ulysses’ decision\nproblem \nWe are told that, before embarking, Ulysses would most prefer to\nfreely hear the sirens and return home to Ithaca. The problem is that\nUlysses predicts his future self will not comply: if he sails\nunrestrained, he will later be seduced by the sirens and will not in\nfact continue home to Ithaca but will rather remain on the island\nindefinitely. Ulysses therefore reasons that it would be better to be\ntied to the mast, because he would prefer the shame and discomfort of\nbeing tied to the mast and making it home to remaining on the\nsirens’ island forever. \nIt is hard to deny that Ulysses makes a wise choice in being tied to\nthe mast. Some hold, however, that Ulysses is nevertheless not an\nexemplary agent, since his present self must play against his future\nself who will be unwittingly seduced by the sirens. While Ulysses is\nrational at the first choice node by static decision\nstandards, we might regard him irrational overall by\nsequential decision standards, understood in terms of the relative\nvalue of sequences of choices. The sequence of choices that Ulysses\ninevitably pursues is, after all, suboptimal. It would have been\nbetter were he able to sail unconstrained and continue on home to\nIthaca. This sequence could have been achieved if Ulysses were\ncontinuously rational over the extended time period; say, if\nat all times he were to act as an EU maximiser, and change his beliefs\nand desires only in accordance with Bayesian norms (variants of\nstandard conditionalisation). On this reading, sequential\ndecision models introduce considerations of rationality-over-time. \nWhile rationality-over-time may have import in assessing an\nagent’s preferences and norms for changing these preferences\n(one can read the discussion in\n Section 6.2\n below in this way), there remains the important question of how an\nagent should act in light of her preferences at any given point in\ntime. To this end, the sequential decision model can be\nfruitfully viewed as a tool for helping determine rational choice at a\nparticular time, just like the static decision model. The sequential\ndecision tree is effectively a way of visualising the temporal series\nof choices and learning events that an agent believes she\nwill confront in the future, depending on what part of the decision\ntree she will find herself. The key question, then, is: How should an\nagent choose amongst her initial options in light of her projected\ndecision tree? This question has generated a surprising amount of\ncontroversy. Three major approaches to negotiating sequential decision\ntrees have appeared in the literature. These are the\nnaïve or myopic approach, the\nsophisticated approach and the resolute approach.\nThese will be discussed in turn; it will be suggested that the\ndisputes may not be substantial but rather indicate subtle differences\nin the interpretation of sequential decision models. \nThe so-called naïve approach to negotiating sequential decisions\nserves as a useful contrast to the other two approaches. The\nnaïve agent assumes that any path through the decision tree is\npossible, and so sets off on whichever path is optimal, given his/her\npresent attitudes. For instance, a naïve Ulysses would simply\npresume that he has three overall strategies to choose from: either\nordering the crew to tie him to the mast, or issuing no such order and\nlater stopping at the sirens’ island, or issuing no such order\nand later sticking to his course. Ulysses prefers the outcome\nassociated with the latter combination, and so he initiates this\nstrategy by not ordering the crew to restrain him. Table 5 presents\nthe static counterpart of naïve Ulysses’ decision problem.\nIn effect, this decision model does not take into account\nUlysses’ present knowledge of his future preferences, and hence\nadvises that he pursue an option that is predicted to be\nimpossible. \nTable 5. Naïve Ulysses’\ndecision problem \nThere is no need to labour the point that the naïve approach to\nsequential choice is aptly named. The hallmark of the sophisticated\napproach, by contrast, is its emphasis on backwards planning: the\nsophisticated chooser does not assume that all paths through the\ndecision tree, or in other words, all possible combinations of choices\nat the various choice nodes, will be possible. The agent considers,\nrather, what he/she will be inclined to choose at later choice nodes\nwhen he/she gets to the temporal position in question. Sophisticated\nUlysses would take note of the fact that, if he reaches the island of\nthe sirens unrestrained, he will want to stop there indefinitely, due\nto the transformative effect of the sirens’ song on his\npreferences. This is then reflected in the static representation of\nthe decision problem, as per Table 6. The states here concern\nUlysses’ future preferences, once he reaches the island. Since\nthe second state has (by assumption) probability zero, the acts are\ndecided on the basis of the first state, so Ulysses wisely chooses to\nbe tied to the mast. \nTable 6. Sophisticated Ulysses’\ndecision problem \nResolute choice deviates from sophisticated choice only under certain\nconditions that are not fulfilled by Ulysses, given his inexplicable\nchange in attitudes. Defenders of resolute choice typically defend\ndecision theories and associated preferences that violate the\nIndependence axiom/Sure-Thing Principle (notably McClennen 1990 and\nMachina 1989; see also Rabinowicz 1995 and Buchak 2013 for\ndiscussion), and appeal to resolute choice to make these preferences\nmore palatable in the sequential-decision context (to be discussed\nfurther in\n Section 6.2\n below). According to resolute choice, in appropriate contexts, the\nagent should at all choice points stick to the strategy that was\ninitially deemed best. The question is whether this advice makes\nsense, given the standard interpretation of a sequential decision\nmodel. What would it mean for an agent to choose against her\npreferences in order to fulfill a previously-selected plan? That would\nseem to defy the very notion of preference. Of course, an agent may\nplace considerable importance on honouring previous commitments. Any\nsuch integrity concerns, however, should arguably be reflected in the\nspecification of outcomes and thus in the agent’s preferences at\nthe time in question. This is quite different from choosing out of\nstep with one’s all-things-considered preferences at a time. \nDefenders of resolute choice may have in mind a different\ninterpretation of sequential decision models, whereby future\n“choice points” are not really points at which an agent is\nfree to choose according to her preferences at the time. If so, this\nwould amount to a subtle shift in the question or problem of interest.\nIn what follows, the standard interpretation of sequential decision\nmodels will be assumed, and accordingly, it will be assumed that\nrational agents pursue the sophisticated approach to choice (as per\nLevi 1991, Maher 1992, Seidenfeld 1994, amongst others). \nWe have seen that sequential decision trees can help an agent like\nUlysses take stock of the consequences of his current choice, so that\nhe can better reflect on what to do now. The literature on\nsequential choice is primarily concerned, however, with more ambitious\nquestions. The sequential-decision setting effectively offers new ways\nto “test” theories of rational preference and norms for\npreference (or belief and desire) change. The question is whether an\nagent’s decision theory in this broad sense is shown to be\ndynamically inconsistent or self-defeating. \nSkyrms’ (1993) “diachronic Dutch book” argument for\nconditionalisation can be read in this way. The agent is assumed to\nhave EU preferences and to take a sophisticated (backwards reasoning)\napproach to sequential decision problems. Skyrms shows that any such\nagent who plans to learn in a manner at odds with conditionalisation\nwill make self-defeating choices in some specially contrived\nsequential decision situations. A conditionalising agent, by contrast,\nwill never make choices that are self-defeating in this way. The kind\nof “self-defeating choices” at issue here are ones that\nyield a sure loss. That is, the agent chooses a strategy that is\nsurely worse, by her own lights, than another strategy that she might\notherwise have chosen, if only her learning rule was such that she\nwould choose differently at one or more future decision nodes. \nA similar “dynamic consistency” argument can be used to\ndefend EU preferences in addition to learning in accordance with\nconditionalisation (see Hammond 1976, 1977, 1988b,c). It is assumed,\nas before, that the agent takes a sophisticated approach to sequential\ndecision problems. Hammond shows that only a fully Bayesian agent can\nplan to pursue any path in a sequential decision tree that is deemed\noptimal at the initial choice node. This makes the Bayesian agent\nunique in that she will never make “self-defeating\nchoices” on account of her preferences and norms for preference\nchange. She will never choose a strategy that is worse by her own\nlights than another strategy that she might otherwise have chosen, if\nonly her preferences were such that she would choose differently at\none or more future decision nodes. \nHammond’s argument for EU theory, and the notion of dynamic\nconsistency that it invokes, has been criticised from different\nquarters, both by those who defend theories that violate the\nIndependence axiom but retain the Completeness and Transitivity (i.e.,\nOrdering) axioms of EU theory, and those who defend theories that\nviolate the latter (for discussion, see Steele 2010). The approach\ntaken by some defenders of Independence-violating theories (notably,\nMachina 1989 and McClennen 1990) has already been alluded to: They\nreject the assumption of sophisticated choice underpinning the dynamic\nconsistency arguments. Seidenfeld (1988a,b, 1994, 2000a,b) rather\nrejects Hammond’s notion of dynamic consistency in favour of a\nmore subtle notion that discriminates between theories that violate\nOrdering and those that violate Independence alone; the former, unlike\nthe latter, pass Seidenfeld’s test that turns on future decision\nnodes where the agent is indifferent between the best options. This\nargument too is not without its critics (see McClennen 1988, Hammond\n1988a, Rabinowicz 2000). \nNote that the costs of any departure from EU theory are well\nhighlighted by Al-Najjar and Weinstein (2009), in particular the\npossibility of aversion to free information and aversion to\nopportunities for greater choice in the future. Kadane et al. (2008)\nand Bradley and Steele (2016) focus on the sure loss that is\nassociated with paying to avoid free evidence. But see Buchak (2010,\n2013) for nuanced discussion of this issue in relation to epistemic\nversus instrumental rationality. \nLet us conclude by summarising the main reasons why decision theory,\nas described above, is of philosophical interest. First, normative\ndecision theory is clearly a (minimal) theory of practical\nrationality. The aim is to characterise the attitudes of agents who\nare practically rational, and various (static and sequential)\narguments are typically made to show that certain practical\ncatastrophes befall agents who do not satisfy standard\ndecision-theoretic constraints. Second, many of these constraints\nconcern the agents’ beliefs. In particular, normative\ndecision theory requires that agents’ degrees of beliefs satisfy\nthe probability axioms and that they respond to new information by\nconditionalisation. Therefore, decision theory has great implications\nfor debates in epistemology and philosophy of science; that is, for\ntheories of epistemic rationality. \nFinally, decision theory should be of great interest to philosophers\nof mind and psychology, and others who are interested in how people\ncan understand the behaviour and intentions of others; and, more\ngenerally, how we can interpret what goes on in other people’s\nminds. Decision theorists typically assume that a person’s\nbehaviour can be fully explained in terms of her beliefs and desires.\nBut perhaps more interestingly, some of the most important results of\ndecision theory—the various representation theorems, some of\nwhich have discussed here—suggest that if a person satisfies\ncertain rationality requirements, then we can read her beliefs and\ndesires, and how strong these beliefs and desires are, from her choice\ndispositions (or preferences). How much these theorems really tell us\nis a matter of debate, as discussed above. But on an optimistic\nreading of these results, they assure us that we can meaningfully talk\nabout what goes on in other people’s minds without much evidence\nbeyond information about their dispositions to choose.","contact.mail":"orri.stefansson@philosophy.su.se","contact.domain":"philosophy.su.se"}]
