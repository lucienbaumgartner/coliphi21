[{"date.published":"1995-12-23","date.changed":"2016-10-24","url":"https://plato.stanford.edu/entries/consciousness-animal/","author1":"Colin Allen","author1.info":"http://colinallen.dnsalias.org/","author2.info":"http://indiana.academia.edu/MichaelTrestman","entry":"consciousness-animal","body.text":"\n\n\nQuestions about animal consciousness — in particular, which\nanimals have consciousness and what (if anything) that consciousness\nmight be like — are  both  scientific and\nphilosophical. They are scientific because answering them will require\ngathering information using scientific techniques — no amount of\narm-chair pondering, conceptual analysis, logic, a priori\ntheory-building, transcendental inference or introspection will tell\nus whether a platypus, an iguana, or a squid (to take a few examples)\nenjoy a life of subjective experience — at some point we'll have\nto learn something about the animals. Just what sort(s) of science can\nbear on these questions is a live question, but at the least this will\ninclude investigations of the behavior and neurophysiology of a wide\ntaxonomic range of animals, as well as the phylogenetic relationships\namong taxa. But these questions are deeply philosophical as well, with\nepistemological, metaphysical, and phenomenological\ndimensions. Progress will therefore ultimately require\ninterdisciplinary work by philosophers willing to engage with the\nempirical details of animal biology, as well as scientists who are\nsensitive to the philosophical complexities of the issue.\n\n\n There are many reasons for philosophical interest in nonhuman\nanimal (hereafter “animal”) consciousness:  First, if philosophy often begins with questions about the place\nof humans in nature, one way humans have attempted to locate\nthemselves is by comparison and contrast with those things in nature\nmost similar to themselves, i.e., other animals.  At least in the\nWest, the traditional — and perhaps still intuitive to many\npeople — way of thinking about consciousness is as primarily an\ninnate endowment of humans, which other animals may or may not share\nin virtue of being sufficiently like us. Within the traditional\nBiblical cosmology, while all animals were said to have arisen through\ndivine intentional creation, humans were the only ones created in the\nlikeness of the deity, and thus enjoyed a special, privileged role in\nthe intended workings of the cosmos — including, for example,\naccess to an eternal afterlife not overpopulated with fleas, ants and\nsnails. (See Lewis, 2009 Ch 9 for an in-depth treatment of the problem\nof animal consciousness in relation to Christian theology.) However,\nwithin a modern biological worldview, while humans may be unique in\ncertain (perhaps quite important) respects, we are only one species of\nanimal among many — one tip of one branch of the phylogenetic\ntree of life, and enjoy no particular special status.  From an evolutionary perspective, consciousness is a trait that\nsome animals have (at least humans have it). Salient questions\ninclude: Is it a late evolved, narrowly distributed trait, or an older\nmore broadly shared trait? And, did it evolve only once, or a number\nof times independently? From this view point, the question “Are\n(non-human) animals conscious?” is rather strange, because, for\nexample, it implicitly groups bats together with rabbits (as\n‘nonhuman’ animals) in contrast to humans. In reality,\nrabbits are more closely related to humans than they are to bats\n(Nishihara et al. 2006), so framing the question this way embeds a\nfalse presupposition. Of course, it is consistent with an evolutionary\nperspective that humans are the only conscious animals. This would\nimply that consciousness was acquired through a recent evolutionary\nevent that occurred since the split of our ancestral lineage from that\nof our closest non-human relatives, chimpanzees and bonobos (see\nsection 6 for discussion of such hypotheses). But such a view requires\nsupport; though perhaps intuitive to some, its choice as a default\nposition is arbitrary.  Second, there is a lot at stake morally in the question of whether\nanimals are conscious beings or “mindless automata”. (See\narticle on the Moral Status of Animals.) Many billions of animals are\nslaughtered every year for food, use in research, and other human\npurposes. Moreover, before their deaths, many — perhaps most\n— of these animals are subject to conditions of life that, if\nthey are in fact experienced by the animals in anything like the way a\nhuman would experience them, amount to cruelty. Arguments that\nnon-human animals are not conscious therefore effectively double as\napologetics for our treatment of animals. When the question of animal\nconsciousness is under consideration, our guilt or innocence as a\ncivilization for an enormous body of cruelty may hang in the\nbalance. However, some philosophers have argued that consciousness per\nse does not matter for the treatment of animals, and therefore either\nthat a) even if animals are not conscious, they may deserve moral\nconsideration, or b) even if animals are conscious, they may not\ndeserve moral consideration. (For more discussion of the ethical\nissues, see Singer 1990 [1975]; Regan 1983; Rollin 1989; Varner 1998,\n2012; Steiner 2008.) Third, while theories of consciousness are frequently developed\nwithout special regard to questions about animal consciousness, the\nplausibility of such theories has sometimes been assessed against the\nresults of their application to animal consciousness (and, similarly,\nto human infants). This raises questions about the relative epistemic\nweight of theoretical considerations (e.g. philosophical arguments for\na given theory of consciousness) against particular case judgments or\nintuitions about whether a given creature is conscious. For example,\nSearle (1998) argues that our intuitive, commonsense attributions of\nintentional and emotional states to dogs carries more epistemic weight\nthan philosophically motivated skeptical concerns. In contrast,\nCarruthers (1989) asserts that his own arguments that nonhuman animals\n(even dogs) lack consciousness are sufficiently weighty that we are\nmorally obligated to eradicate or ignore our sympathetic feelings\ntoward such creatures. Should our theories of consciousness be\nconstrained by our intuitive attributions of consciousness to animals\n(or, e.g., babies), or should the former override the latter?\n \n Fourth, the problem of determining whether animals are conscious\n stretches the limits of knowledge and scientific methodology (beyond\n the breaking point, according to some).\n\nThe so-called “cognitive revolution” that took place\nduring the latter half of the 20th century has led to many innovative\nexperiments by comparative psychologists and ethologists probing the\ncognitive capacities of animals.  The philosophical issues surrounding\nthe interpretation of experiments to investigate perception, learning,\ncategorization, memory, spatial cognition, numerosity, communication,\nlanguage, social cognition, theory of mind, causal reasoning, and\nmetacognition in animals are discussed in the entry\non animal cognition. Despite this\nwork on cognition, the topic of consciousness per se in animals has\nremained controversial, even taboo, among many scientists, while other\nscientists from a variety of disciplinary backgrounds\n(e.g. neuroscience, animal behavior, evolutionary biology) have\ndeveloped novel ways of approaching the subject (see Boly et al. 2013 for a review).  The 2012\n Cambridge Declaration on Animal Consciousness \nindicates that many scientists agree that “the weight of evidence\nindicates that humans are not unique in possessing the neurological\nsubstrates that generate consciousness.” However, other scientists,\nincluding Marian Stamp Dawkins, who has been prominent in the science\nof animal welfare (Dawkins 1985, 1993), are not ready to endorse the\nclaim, writing that, “The mystery of consciousness remains. The\nexplanatory gap is as wide as ever and all the wanting in the world\nwill not take us across it” (Dawkins 2012, pp. 171–172).\n \nMany philosophers and scientists have either argued or assumed that\nconsciousness is inherently private, and hence that one's own\nexperience is unknowable to others. While language may allow humans to\ncross this supposed gap by communicating their experience to others,\nthis is allegedly not possible for other animals.  Despite the\ncontroversy in philosophical and scientific circles, it remains a\nmatter of common sense to most people that some animals do have\nconscious experiences. Most people, if asked why they think familiar\nanimals such as their pets are conscious, would point to similarities\nbetween the behavior of those animals and human behavior — for\nexample, animals seem to visibly express pleasure and displeasure and\na variety of emotions, their behavior seems to be motivated by seeking\nfood, comfort, social contact, etc., they seem aware of their\nsurroundings and able to learn from experience. Similarity arguments\nfor animal consciousness thus have roots in common sense\nobservations. But they may also be bolstered by scientific\ninvestigations of behavior and the comparative study of brain anatomy\nand physiology, as well as considerations of evolutionary continuity\nbetween species. Neurological similarities between humans and other\nanimals have been taken to suggest commonality of conscious\nexperience; all mammals share the same basic brain anatomy, and much\nis shared with vertebrates more generally. Even structurally different\nbrains may be neurodynamically similar in ways that enable inferences\nabout animal consciousness to be drawn (Seth et\nal. 2005).   \n\nAs well as generic arguments about the connections among\nconsciousness, neural activity, and behavior, a considerable amount of\nscientific research directed towards understanding particular\nconscious states uses animals as proxies for humans.\nThe reactions of many animals, particularly other mammals, to bodily\nevents that humans would report as painful are easily and\nautomatically recognized by most people as pain\nresponses. High-pitched vocalizations, fear responses, nursing of\ninjuries, and learned avoidance are among the responses to noxious\nstimuli that are all part of the common mammalian heritage, and\nsimilar responses are also observable in organisms from a wide range\nof taxonomic groups (see section 7.1 below). \nMuch of the research that is of direct relevance to the treatment of\nhuman pain, including on the efficacy of analgesics and anesthetics,\nis conducted on rats and other animals. The validity of this research\ndepends on the similar mechanisms\n involved[1]\n and to many it seems arbitrary to deny that injured rats, who respond\nwell to opiates for example, feel\n pain.[2] \nLikewise, much of the basic research that is of direct relevance to\nunderstanding human visual consciousness has been conducted on the\nvery similar visual systems of monkeys.  Monkeys whose primary visual\ncortex is damaged even show impairments analogous to those of human\nblindsight patients (Stoerig & Cowey 1997) suggesting that the\nvisual consciousness of intact monkeys is similar to that of intact\nhumans.  Scientific demonstrations that members of\nother species, even of other phyla, are susceptible to the same visual\nillusions as we are (e.g., Fujita et al. 1991) suggesting\nthat their visual experiences are similar. It is often argued that the use of animals to model\nneuropsychiatric disorders presupposes convergence of emotional and\nother conscious states and further refinements of those models may\nstrengthen the argument for attributing such states to animals. \nAn interesting reversal of the modeling\nrelationship can be found in the work of Temple Grandin, Professor of\nAnimal Science at Colorado State University, who uses her experience\nas a so-called “high-functioning autistic” as the basis\nfor her understanding of the nature of animal experience (Grandin\n1995, 2004). \n\nSuch similarity arguments are, of course, inherently limited in that\nit is always open to critics to exploit some disanalogy\nbetween animals and humans to argue that the similarities don't entail\nthe conclusion that both are sentient. Even when bolstered by\nevolutionary considerations of continuity between the species, the\narguments are vulnerable, for the mere fact that humans have a trait\ndoes not entail that our closest relatives must have that trait too.\nThere is no inconsistency with evolutionary continuity to maintain\nthat only humans have the capacity to learn to play chess. Likewise\nfor consciousness. Povinelli & Giambrone (2000) also argue that\nthe argument from analogy fails because superficial observation of\nquite similar behaviors even in closely related species does not\nguarantee that the underlying cognitive principles are the same, a\npoint that Povinelli believes is demonstrated by his research into how\nchimpanzees use cues to track visual attention (Povinelli 1996).  \n\nPerhaps a combination of behavioral, physiological and morphological\nsimilarities with evolutionary theory amounts to a stronger overall\ncase[3].\n However, a convincing argument will\nlikely also require motivation in terms of a well developed theory of\nthe structure and function of consciousness as a cognitive process\n— a route that many recent participants in the debate on animal\nconsciousness have pursued (see section 6).\n  The term “consciousness” is notoriously ambiguous and\ndifficult to define. Having origins in folk psychology,\n“consciousness” has a multitude of uses that may not be\nresolvable into a single, coherent concept (Wilkes\n1984). Nevertheless, several useful distinctions among different\nnotions of consciousness have been made, and with the help of these\ndistinctions it is possible to gain some clarity on the important\nquestions that remain about animal consciousness. \n\nTwo ordinary senses of consciousness which are not in dispute when\napplied to animals are the sense of consciousness involved when a\ncreature is awake rather than \nasleep[4],\n or in a coma, and the sense of\nconsciousness implicated in the basic ability of organisms to perceive\nand thereby respond to selected features of their environments, thus\nmaking them conscious or aware of those features. Consciousness in\nboth these senses is identifiable in organisms belonging to a wide\nvariety of taxonomic groups (see, e.g., Mather 2008). \n\nA third, more technical notion of consciousness, access consciousness,\nhas been introduced by Block (1995) to capture the sense in which\nmental representations may be poised for use in rational control of\naction or speech.  This “dispositional” account of access\nconsciousness — the idea that the representational content is\navailable for other systems to use — is amended by Block (2005)\nto include an occurrent aspect in which the content is\n“broadcast” in a “global workspace” (Baars\n1997) which is then available for higher cognitive processing tasks\nsuch as categorization, reasoning, planning, and voluntary direction\nof attention.  Block believes that many animals possess access\nconsciousness (speech is not a requirement).  Indeed, some of the\nneurological evidence cited by Block (2005) in support of the global\nworkspace is derived from monkeys. But clearly an author such as\nDescartes, who, we will see, denied speech, language, and\nrationality to animals, would also deny access consciousness to\nthem. Those who follow Davidson (1975) in denying intentional states\nto animals would likely concur. \n\nThere are two remaining senses of consciousness that cause more\ncontroversy when applied to animals: phenomenal consciousness\nand self-consciousness. \n\nPhenomenal consciousness refers to the qualitative,\nsubjective, experiential, or phenomenological aspects of conscious\nexperience, sometimes identified with qualia. (In this article we also\nuse the term “sentience” to refer to phenomenal\nconsciousness.) To contemplate animal consciousness in this sense is\nto consider the possibility that, in Nagel's (1974) phrase, there\nmight be “something it is like” to be a member of another\nspecies. Nagel disputes our capacity to know, imagine, or describe in\nscientific (objective) terms what it is like to be a bat, but\nhe assumes that there is something it is like.   For many authors, Nagel's formulation of phenomenal consciousness\nas “what it's like” serves as a reference point for what's at stake in\nthe debate on animal consciousness — in investigating whether a\ngroup of animals are conscious, the crucial question is whether\nthere is ‘something it is like’ to be those animals,\ni.e. whether there is a subjective experience of life or being for\nthem, a proprietary perspective that individuals have on their own\nperceptual, cognitive and emotive processes.  Though some authors (including Nagel himself) have argued that the\nvery subjectivity of phenomenal consciousness makes it exceedingly\ndifficult or even impossible to investigate scientifically,\nparticularly in other species, others have proceeded by developing\nstructural and/or functional theories of consciousness, and using\nthese to argue for a particular hypothesis about the distribution of\nconsciousness among animals. Such theories will be discussed below, in\nsections 5 and 6. \nSelf-consciousness refers to a subject's awareness of itself,\nbut is also a notoriously ambiguous term — there are importantly\ndistinct senses in which a subject can be self-aware (see for example\nthe SEP article on Phenomenological Approaches to\nSelf-Consciousness). These include: an awareness of one's body as a\nphysical object, or as the medium of one's own perception and action\n(i.e. bodily self-awareness); awareness of one's own mental states\n(i.e. mental or experiential self-awareness); awareness of one-self as\nperceived by others, or as a member of a social group such as a\nfamily, team, or institution (i.e. social self-awareness); awareness\nof one-self as a persistent character in the narratives told by\noneself and others (i.e. narrative self-awareness). This list is far\nfrom exhaustive, and further, each listed notion is subject to\nfurther disambiguation. Hence, although on many theories self-consciousness is\ntightly related to phenomenal consciousness, proposals to this effect\ncan vary greatly in their meaning and their implications for which\nanimals might be conscious. \n\nThe remainder of this article deals primarily with the attribution of\nconsciousness in its phenomenal sense to animals, although there will\nbe some discussion of access consciousness, self-consciousness and\ntheory of mind in animals, especially where these have been related\ntheoretically to phenomenal consciousness — as, for instance, in\nCarruthers' (1998a,b, 2000) argument that a particular sort of mental\nself-representation is required for phenomenal consciousness.  Questions about animal consciousness in the Western tradition have\ntheir roots in ancient discussions about the nature of human beings,\nas filtered through the “modern” philosophy of\nDescartes. It would be anachronistic to read ideas about\nconsciousness from today back into the ancient literature. Nevertheless, because\nconsciousness is sometimes thought to be a uniquely human mental\nphenomenon, it is important to understand the origins of the idea that\nhumans are qualitatively (and “qualia-tatively”) different\nfrom animals. \n\nAristotle asserted that only humans had rational souls, while the\nlocomotive souls shared by all animals, human and nonhuman, endowed\nanimals with instincts suited to their successful reproduction and\nsurvival. Sorabji (1993) argues that the denial of reason to animals\ncreated a crisis for Greek thought, requiring a “wholesale\nreanalysis” (p. 7) of the nature of mental capacities, and a\nrevision in thinking about “man and his place in nature above\nthe animals” (ibid.). The argument about what is reasoning, and\nwhether animals display it, remains with us 25 centuries later, as\nevidenced by the volume Rational Animals? (Hurley & Nudds\n2006). The Great Chain of Being derived from early Christian\ninterpretation of Aristotle's scale of nature (Lovejoy 1936) provides\nanother Aristotelian influence on the debate about animal minds.  Two millennia after Aristotle, Descartes' mechanistic philosophy\nintroduced the idea of a reflex to explain the behavior of nonhuman\nanimals.  Although his conception of animals treated them as\nreflex-driven machines, with no intellectual capacities, it is\nimportant to recognize that he took mechanistic explanation to be\nperfectly adequate for explaining sensation and perception —\naspects of animal behavior that are nowadays often associated with\nconsciousness. He drew the line only at rational thought and\nunderstanding. Given the Aristotelian division between instinct and\nreason and the Cartesian distinction between mechanical reflex and\nrational thought, it's tempting to map the one distinction onto the\nother. Nevertheless, it may be\na mistake to assimilate the two. First, a number of authors before and\nafter Darwin have believed that conscious experience can accompany\ninstinctive and reflexive actions. Second, the dependence of\nphenomenal consciousness on rational, self-reflective thought is a\nparticularly strong and contentious claim (although it has current\ndefenders, discussed below).  Although the roots of careful observation and experimentation of\nthe natural world go back to ancient times, study of animal behavior\nremained largely anecdotal until long after the scientific\nrevolution. Animals were, of course, widely used in pursuit of answers\nto anatomical, physiological, and embryological questions. Vivisection\nwas carried out by such ancient luminaries as Galen and there was a\nresurgence of the practice in early modern times (Bertoloni Meli\n2012). Descartes himself practiced and advocated vivisection\n(Descartes, Letter to Plempius, Feb 15 1638), and wrote in\ncorrespondence that the mechanical understanding of animals absolved\npeople of any guilt for killing and eating animals. Mechanists who\nfollowed him (e.g. Malebranche) used Descartes' denial of reason and a\nsoul to animals as a rationale for their belief that animals were\nincapable of suffering or emotion, and did not deserve moral\nconsideration — justifying vivisection and other brutal\ntreatment (see Olson 1990, p. 39–40, for support of this claim). The\nidea that animal behavior is purely reflexive may also have served to\ndiminish interest in treating behavior as a target of careful study in\nits own right.  A few glimmers of experimental approaches to animal behavior can\nbe seen in the late 18th century (e.g., Barrington 1773; White 1789),\nand soon thereafter Frédéric Cuvier worked from 1804\nuntil his death in 1838 on the development of sexual and social\nbehavior in captive mammals. By the mid 19th century Alfred Russel\nWallace (1867) was arguing explicitly for an experimental approach to\nanimal behavior, and Douglas Spalding's (1872) experiments on\ninstinctual feeding behaviors in chicks were seminal. Still, the\nemergence of experimental approaches had very little to say about\nconsciousness per se, though Spalding's work can be seen as a\ncontribution to the discussion about instinct and reason. \n\nIn the same vein of instinct vs. reason, Darwin in the Origin of\nSpecies wrote, “It is a significant fact, that the more the\nhabits of any particular animal are studied by a naturalist, the more\nhe attributes to reason, and the less to unlearnt instinct”\n(1871, Book I, p.46). He devoted considerable attention in both the\nOrigin and in the Descent of Man to animal behavior,\nwith the obvious goal of demonstrating mental continuity among the\nspecies. To make his case, Darwin relied heavily on anecdotes provided\nby his correspondents — a project infamously pursued after\nDarwin's death by his protégé George Romanes\n(1882). Darwin also carried out experiments and was a keen observer,\nhowever. In his final work he describes experiments on the flexibility\nof earthworm behavior in manipulating leaves, which he took to show\nconsiderable intelligence (Darwin 1881; see also Crist 2002).  The idea of behavioral flexibility is central to discussions of\nanimal mind and consciousness. Descartes' conception of animals as\nautomata seems to make phenomenal consciousness superfluous at best\n— a connection whose philosophical development was traced by\nT.H. Huxley (1874).  Huxley reported a series of experiments on a\nfrog, showing very similar reflexive behavior even when its spinal\ncord had been severed, or large portions of its brain removed. He\nargued that without a brain, the frog could not be conscious, but\nsince it could still do the same sort of things that it could do\nbefore, there is no need to assume consciousness even in the presence\nof the entire brain, going on to argue that consciousness is\nsuperfluous. (The argument is somewhat curious since it seems to show\ntoo much by making the brain itself superfluous to the frog's\nbehavior!) \n\nStill, for those (including Huxley) who became quickly convinced of\nthe correctness of Darwin's theory of evolution, understanding and\ndefending mental continuity between humans and animals loomed\nlarge. In his Principles of Psychology (1890), William James\npromoted the idea of differing intensities of conscious experience\nacross the animal kingdom, an idea that was echoed by the leading\nBritish psychologist of his day, Conwy Lloyd Morgan in his 1894\ntextbook An Introduction to Comparative Psychology. Morgan\nhad been very skeptical and critical of the anecdotal approach favored\nby Darwin and Romanes, but he came around to the Darwinian point of\nview about mental continuity if not about methodology.  To address the\nmethodological deficit he introduced his “double\ninductive” method for understanding the mental states of animals\n(Morgan 1894). The double induction consisted of inductive inferences\nbased on observation of animal behavior combined with introspective\nknowledge of our own minds. At the same time, to counteract the\nanthropomorphic bias in the double inductive method, Lloyd Morgan\nintroduced a principle now known as Morgan's canon: “in no case\nmay we interpret an action as the outcome of the exercise of a higher\npsychical faculty, if it can be interpreted as the outcome of the\nexercise of one which stands lower in the psychological scale”\n(Lloyd Morgan 1894, p.53). \n Lloyd Morgan's Double Induction Method from his 1894 textbook  Even though the double inductive method is now mainly of\nhistorical interest, Morgan's canon lives on.  Questions about quite\nwhat the canon means and how to justify it are active topics of\nhistorical and philosophical investigation (e.g., Burghardt 1985;\nSober 1998, 2005, 2012; Radick 2000; Thomas 2001 (Other Internet\nResources), Fitzpatrick 2008). The questions include what Lloyd Morgan\nmeans by ‘higher’ and ‘lower’, to what extent\nthe principle can or should be justified by evolutionary\nconsiderations, and whether the canon collapses to a principle of\nparsimony, a version of Ockham's razor, or some general principles of\nempirical justification. Despite current uncertainty about what it\nreally means, Morgan's canon, interpreted (or, perhaps,\nmisinterpreted; Thomas 2001, Other Internet Resources) as a strong\nparsimony principle, served a central rhetorical role for\nbehavioristic psychologists, who sought to eliminate any hint of\nCartesian dualism from comparative psychology.  Behaviorism dominated American psychology in the early part of the\n20th century, beginning with Thorndike's (1911) experiments on animals\nlearning by trial and error to escape from the “puzzle\nboxes” that he had constructed. But even Thorndike's famous\n“law of effect” refers to the animal's “satisfaction\nor discomfort” (1911, p.244). It was with the radical\nanti-mentalism of John B. Watson (1928) and B.F. Skinner (1953), both\nof whom strongly rejected any attempts to explain animal behavior in\nterms of unobservable mental states, that American psychology became\nthe science of behavior rather than, as the dictionary would have it,\nthe science of mind and behavior.   At the same time, things were progressing rather differently in\nEurope, where ethological approaches to animal behavior were more\ndominant.  Ethology is part natural history with an emphasis on\nfieldwork and part experimental science conducted on captive animals,\nreflecting the different styles of its two seminal figures, Konrad\nLorenz and Niko Tinbergen (see Burkhardt 2005). Initially,\n“innate” behaviors were the central focus of Lorenz's\nwork. According to Lorenz, it is the investigation of innate behaviors\nin related species that puts the study of animal behavior on a par\nwith other branches of evolutionary biology, and he demonstrated that\nit was possible to derive the phylogenetic relations among species by\ncomparing their instinctive behavioral repertoires (Lorenz 1971a). In\npursuing this direction, Lorenz and Tinbergen explicitly sought to\ndistance ethology from the purposive, mentalistic, animal psychology\nof Bierens de Haan and the lack of biological concern they detected in\nAmerican comparative psychology (see Brigandt 2005).  Like Lloyd\nMorgan, the ethologists rejected Romanes anecdotal approach, but they\nalso criticized Lloyd Morgan's subjectivist approach. \n\nIn the 1970s, Donald Griffin, who made his reputation taking careful\nphysical measurements to prove that bats use echolocation, made a\nconsiderable splash with his plea for a return to questions about\nanimal minds, especially animal consciousness. Griffin (1978) coined\nthe term “cognitive ethology” to describe this research\nprogram, which is based in naturalistic observations of animal\nbehavior and the attempt to understand animal minds in the context of\nevolution.\n\nFierce criticism of Griffin emerged both from psychologists\nand classically trained ethologists. Griffin\nemphasized behavioral flexibility and versatility as the chief source\nof evidence for consciousness, which he defined as “the\nsubjective state of feeling or thinking about objects and\nevents” (Griffin & Speck 2004, p. 6). In seeing\nsubjectivity, at least in simple forms, as a widespread phenomenon in\nthe animal kingdom, Griffin's position also bears considerable\nresemblance to Lloyd Morgan's. Burghardt reports that\n“considerable discomfort with subjectivism” (Burghardt\n1985, p. 907) arose during the Dahlem conference that Griffin convened\nin an early discipline-building exercise (Griffin 1981). Griffin's\nsubjectivist position, and the suggestion that even insects such as\nhoneybees are conscious, seemed to many scientists to represent a\nlamentable return to the anthropomorphic over-interpretation of\nanecdotes seen in Darwin and Romanes. This criticism may be partly\nunfair in that Griffin does not repeat the\n“friend-of-a-farmer” kinds of story collected by Romanes,\nbut bases his interpretations on results from the more sophisticated\nscientific literature that had accumulated more than a century after\nDarwin (e.g., Giurfa et al. 2001). However, the charge of\nover-interpretation of those results may be harder to avoid.  It is\nalso important to note the role played by neurological evidence in his\nargument, when he concludes that the intensive search for neural\ncorrelates of consciousness has not revealed “any structure or\nprocess necessary for consciousness that is found only in human\nbrains” (Griffin & Speck 2004). This view is widely although\nnot universally shared by neuroscientists. \n\nGriffin's behavior-based methodology for studying animal consciousness\nhas also been dismissed as anthropomorphic (see Bekoff & Allen\n1997 for a survey). But such criticisms may have overestimated the\ndangers of anthropomorphism (Fisher 1990) and many of the critics\nthemselves rely on claims for which there are scant scientific data\n(e.g., Kennedy 1992, who claims that the “sin” of\nanthropomorphism may be programmed into humans genetically).  At the\nsame time, other scientists, whether or not they have explicitly\nendorsed Griffin's program, have sought to expand evolutionary\ninvestigation of animal consciousness to include the neurosciences and\na broad range of functional considerations (e.g., Ârhem et\nal. 2002, and see section 6). Whatever the shortfalls of his\nspecific proposals, Griffin played a crucial role in reintroducing\nexplicit discussions of consciousness to the science of animal\nbehavior and cognition, hence paving the way for modern investigations\nof the distribution and evolutionary origins of consciousness.   The topic of consciousness in nonhuman animals has been primarily\nof epistemological interest to philosophers of mind. Two central\nquestions are: \nIn his seminal paper “What is it like to be a bat?” Thomas\nNagel (1974) simply assumes that there is something that it\nis like to be a bat, and focuses his attention on what he argues is\nthe scientifically intractable problem of knowing what it is\nlike. Nagel's confidence in the existence of conscious bat experiences\nwould generally be held to be the commonsense view and, as the\npreceding section illustrates, a view that is increasingly taken for\ngranted by many scientists too. But, as we shall see, it is subject to\nchallenge and there are those who would argue that the Distribution\nQuestion is just as intractable as the Phenomenological Question. The two questions might be seen as special cases — or,\nalternatively, as generalized versions — of the skeptical\n“problem of other minds” — how can one know that\nothers have mental states that are anything like one's own?  Although\nthere is no generally accepted solution to this problem, it is\nnevertheless generally ignored to good effect by psychologists, and\nindeed by most people, who in practice are willing to take for granted\nthat others have mental states similar to theirs. However it is often\nthought that knowledge of animal minds presents special methodological\ndifficulties. First of all, nonhuman animals cannot describe their\nmental states using language. Although there have been attempts to\nteach human-like languages to members of other species, none has\nreached a level of conversational ability that would solve this\nproblem directly (see Anderson 2004 for a review). Furthermore, except\nfor some language-related work with parrots and dolphins, such\napproaches are generally limited to those animals most like ourselves,\nparticularly the great apes. But there is great interest in possible\nforms of consciousness in a much wider variety of species than are\nsuitable for such research.  More generally, the problem of other\nminds is more acute when applied to nonhuman animals because the\nsimilarities between our behavior and bodies, and those of others\nanimals (which form the basis for ‘analogical’ solutions\nto the problem of other minds) are less exact. As well, the perceptual\naccess to other minds that some have argued defuses the problem of\nother minds is arguably weaker regarding the minds of other animals.\n(Sober (2000) discusses of the problem of other minds within an\nevolutionary framework, and Farah 2008 provides a neuroscientist's\nperspective.)  For many people it seems obvious that familiar animals such as\ndogs and cats have conscious mental lives that include perceptual\nstates, motivational and hedonic states, basic emotions and social\nattachments.  David Hume, known for championing skepticism generally,\nwrote that “no truth appears to me more evident, than that beasts are\nendow'd with thought and reason as well as men” (1888 p 176,\nreproduced in Jamieson 1998). Hume did not provide elaborate\nphilosophical or empirical arguments to this effect — he thought\nit was clear from observation.  As Searle (1998) puts it, \nWhat is the epistemic status of such pretheoretical intuitions (if\nthat is indeed a fair way of describing them)?\n  Defenders of theories that deny consciousness to such animals must\ndeny that such intuitions have any epistemic weight. For example\nDennett (who argues that consciousness is unique to humans), claims\nthat intuitive attributions of mental states are “untrustworthy”, and\npoints out that “it is, in fact, ridiculously easy to induce powerful\nintuitions of not just sentience but full-blown consciousness (ripe\nwith malevolence or curiosity) by exposing people to quite simple\nrobots  made to move in familiar mammalian ways at mammalian speeds\n (1995).” (Emphasis from the original.)  Carruthers (1989) acknowledges that intuitive attributions of\nconsciousness to animals are widespread, and go hand in hand with\nsympathetic attitudes toward animals (e.g. wanting to prevent\nsuffering). However, he argues that these attitudes are incorrect, and\nwe have a moral imperative to purge or at least override them: It should be noted that while Carruthers continues to argue that\nonly humans have consciousness, he has more recently amended his\nethical view, holding that animals may deserve some moral concern\ndespite lacking consciousness (1999). \nA crucial point here is how trustworthy these pretheoretic intuitions\nabout the minds of animals are.  Call Perceptualism the view\nthat there is direct perception of (at least some) mental states of\nothers. What this means is that, at least sometimes, when we observe\nanother in a mental state (e.g. in joy, or in pain) their mental state\nis part of the content of our perception — we perceive the\nmental states of others. In contrast, call inferentialism the\nview that we perceive ‘mere behavior’ and must infer or\nreason to conclusions about mental states. An alternative way of\nframing the issues is in terms of whether or not behavior as we\nperceive it is laden with mental properties. According to\nperceptualism, we (at least sometimes) perceive states of mind\nin behavior — an action (e.g. walking across a room) can\nbe perceivably angry or sad, purposeful or eager or hesitant,\netc. Goals, desires, motivations, emotions, pain or pleasure, and many\nother mental states are manifested in modes of action — though\nthey cannot be reduced to patterns of disposition to behave (this\nwould amount to behaviorism), they are tightly linked to behavior by\nconceptual, constitutive or causal connections that ground perceptual\naccess. Jamieson (1998) argues for perceptualism, pointing out that our\neveryday practices of attributing mental states to nonhuman animals\nare deeply ingrained, automatic, conceptually unifying and empirically\npowerful. Strands of the same point of view can also be found in\nscientists writing about cognitive ethology and in\nWittgensteinian attitudes towards questions of animal mind (e.g.,\nGaita 2003). Perceptualism as a theory of social cognition\n(e.g. empathy) in philosophy of psychology has recently been defended\nby Zahavi (2011) and Gallagher (2008).  The Perceptualism/Inferentialism question is critical for the\ndeciding the epistemic value of common sense attributions of mental\nstates to nonhuman animals. If inferentialism is true, then when I\nsee, e.g., a dog bounding around in front of me with a toy in its\nmouth, wagging its tail and looking at me, then I may consider the\npossibility that the dog wants my attention, that it is feeling\nhappy and playful — but this is only a hypothesis,\nfor which I must provide a solid argument from justified premises if I\nam to justifiably believe it. On a perceptualist account, by contrast,\nI literally see (or at least, seem to see) that the dog wants\nmy attention and feels happy and playful.  Perception is usually understood to ground defeasible epistemic\nwarrant for belief — for example, if you look outside and it\nappears to be raining, you have some grounds to believe that it is\nraining. It is difficult to forgo this assumption without succumbing\nto radical global skepticism, since we base so many of our beliefs on\nperception.  If seeming to perceive something to be the case provides\ndefeasible epistemic warrant for believing it to be the case, than the\nfact the I seem to perceive a dog as being happy and playful warrants\nmy belief that the dog is happy and playful, i.e. warrants my\nascription of mental states to the dog. Given the prima facie\nepistemic support of seeming to perceive mental states in familiar\nanimals like dogs, perceptualists would argue that only overwhelming\nevidence should overturn the common-sense, intuitive attribution of\nmental states to those animals. Whereas, as discussed above,\nCarruthers (1989) argues that because his theory denies consciousness\nto animals, we should strive to eradicate our intuitive attributions\nof consciousness, a perceptualist would respond that the evidence\nderived from our perceptual encounters with dogs is more convincing\nthan his arguments (which hang on the plausibility of his higher order\nthought theory of consciousness; see section 6.1).   Nevertheless, even if we have perceptual access to the mental\nstates of other humans and familiar animals like our pet dogs, there\nare sharp limitations to how far this will get us toward solving the\ngeneral problem of animal consciousness. First of all, our perceptual\naccess may be limited to animals that are familiar, comfortable\ninteracting with humans, and biologically very similar to humans\n(i.e. mammals). It may be much harder to ‘see’ what (if\nanything) a spider or a squid is thinking and feeling as she goes\nabout her business — both because these animals may express\ntheir mental states differently, and more radically because they may\nhave a very different repertoire of mental states.  Second, as argued by Dennett, there are examples where our\nperceptions of mental states can be deceived — so Dennett seems\nto embrace perceptualism, but to hold that perceptions of mental\nstates are particularly unreliable. However, Dennett's favored example\nof the robot\n ‘Cog’,\n unlike nonhuman animals, was\nintentionally designed by human engineers to seem life-like, i.e., to\nmimic the dynamical properties of motion that trigger the perception\nof mindedness. Hence, there may be no more reason to fear that our\nseeming perceptions of mind in others are undermined by such examples\nthan to fear that our perception of objects in space is undermined by\nthe existence of photography — in both cases, human engineers\ncan be characterized as having figured out ways of creating perceptual\nillusions. There are deep questions about how perception of bodies in\nmotion might disclose the mental states of others — just as\nthere are deep questions about how visual perception of objects in\nspace is generally possible. But, pace Dennett, there is no\nclear reason why the existence of carefully crafted illusions\nundermines the general epistemic value of perception.\n  Third, even among scientists who are sympathetic to the idea of\nthemselves as sensitive observers of animals with rich mental lives,\nthere is the recognition that the scientific context requires them to\nprovide a particular kind of empirical justification of mental state\nattributions. This demand requires those who would say that a tiger\npacing in the zoo is “bored”, or that the hooked fish is\nin pain to define their terms, state empirical criteria for their\napplication, and provide experimental or observational evidence for\ntheir claims. Even if perceptualism is a viable theory of folk\npractice with respect to attributing animal consciousness, it seems\nunlikely to make inroads against scientific epistemology.  Many scientists and philosophers remain convinced that even if some\nquestions about animal minds are empirically tractable, no amount of\nexperimentation can provide access to  phenomenal consciousness\n per se. This remains true even among those who are willing to\ninvoke cognitive explanations of animal behavior that advert to\ninternal representations. Opposition to dealing with consciousness can\nbe understood in part as a legacy of behavioristic psychology first\nbecause of the behaviorists' rejection of terms for unobservables\nunless they could be formally defined in terms of observables, or\notherwise operationalized experimentally, and second because of the\nstrong association in many behaviorists' minds between the use of\nmentalistic terms and the twin bugaboos of Cartesian dualism and\nintrospectionist psychology. In some cases\nthese scientists are even dualists themselves, but they are strongly\ncommitted to denying the possibility of scientifically investigating\nconsciousness, and remain skeptical of all attempts to bring it into\nthe scientific mainstream. Also important has been a line of argumentation by philosophers\nthat the subjective nature of consciousness makes it inherently\ndifficult to study. Block's (1995) influential distinction between\nphenomenal and access consciousness was framed as part of a critique of\ntreatments of consciousness in the psychological literature: by\nfailing to properly distinguish between consciousness as experience\n(phenomenal consciousness) and consciousness as general availability\nof information (access consciousness), scientists were equivocating\n— drawing conclusions about consciousness in the phenomenal\nsense from premises about consciousness in the access sense. The\nconceptual distinction between access consciousness and phenomenal\nconsciousness, and the difficulty of gaining empirical traction on the\nlatter, has been seen as a major hurdle to empirical consciousness\nstudies. Block himself has recently been more optimistic, even arguing\nthat certain experiments can empirically tease apart phenomenal and\naccess consciousness (Block 2011). But the distinction between access\nand phenomenal consciousness does raise special methodological hurdles\nfor those who want to study the latter empirically. \n\nBecause consciousness is assumed to be private or subjective, it is\noften taken to be beyond the reach of objective scientific methods\n(e.g., Nagel 1974). This claim might be taken in either of two\nways. On the one hand it might be taken to bear on the possibility of\nanswering the Distribution Question, i.e., to reject the possibility\nof knowledge that a member of another taxonomic group (e.g., a bat)\nhas conscious states. On the other hand it might be taken to bear on\nthe possibility of answering the Phenomenological Question, i.e., to\nreject the possibility of knowledge of the phenomenological details of\nthe mental states of a member of another taxonomic group. The\ndifference between believing with justification that a bat is\nconscious and knowing what it is like to be a bat is\nimportant because, at best, the privacy of conscious experience\nsupports a negative conclusion only about the latter. To support a\nnegative conclusion about the former, one must also assume that\nconsciousness has absolutely no measurable effects on behavior, i.e.,\none must accept epiphenomenalism.\nBut if one rejects epiphenomenalism and maintains that consciousness\ndoes have effects on behavior then a strategy of inference to the best\nexplanation may be used to support its attribution. Moreover, if\nparticular conscious states have particular effects on behavior, then\nthis strategy might be pursued to elucidate some specific features of\nthe conscious experience of other animals, even if some aspects must\nremain out of reach because of our inability, as humans, to fully\ngrasp what it would be like to experience them. More will be said\nabout this in the next section. \n\nIf phenomenal consciousness is completely epiphenomenal, as some\nphilosophers believe, then a search for the functions of consciousness\nis doomed to futility. In fact, if consciousness is completely\nepiphenomenal then it cannot have evolved by natural selection. On the\nassumption that phenomenal consciousness is an evolved characteristic\nof human minds, at least, and therefore that epiphenomenalism is\nfalse, then an attempt to understand the biological functions of\nconsciousness may provide the best chance of identifying its\noccurrence in different species. (See Robinson 2007 for more\ndiscussion of this issue.) \n\nWhile epistemological and related methodological issues have been at\nthe forefront of discussions about animal consciousness, philosophical\nattention to consciousness in the analytic tradition over the last\nseveral decades has focused on metaphysical questions about the nature\nof phenomenal consciousness and its fit (or lack thereof) within a\nnaturalistic framework. One might think that the question of what consciousness is\n(metaphysically) should be settled prior to tackling the Distribution\nQuestion — that ontology should drive the epistemology.\nHowever, the metaphysical questions that have occupied analytic\nphilosophers over the last few decades are largely orthogonal to the\ndistribution problem, which depends more on questions about the\nstructure and function of consciousness, discussed\nbelow.  The traditional ‘Mind Body Problem’ concerns the the\nmetaphysical status of mind in relation to the physical world (see SEP\narticle on dualism). Dualists argue that the\nmental and physical are fundamentally distinct, whereas physicalists\nhold that the mind is physical — and therefore not distinct,\ndespite supposed appearances to the contrary. A third alternative is\nidealism, the view that the physical world is actually mental (and\ntherefore that the two are not really distinct). Dualistic theories of consciousness typically deny that it can be\naccounted for in the current terms of the natural\nsciences. Traditional dualists may argue that the reduction of\nconsciousness to physically describable mechanisms is impossible on\nany concept of the physical.  Others may hold that consciousness is an\nas-yet-undescribed fundamental constituent of the physical universe,\nnot reducible to any known physical principles. Such accounts of\nconsciousness (with the possible exception of those based in\nanthropocentric theology) provide no principled reasons, however, for\ndoubting that animals are conscious.  Cartesian dualism is, of course, traditionally associated with the\nview that animals lack minds. Descartes' argument for this view was\nnot based, however, on any ontological principles, but upon what he\ntook to be the failure of animals to use language rationally, or to\nreason generally. On this basis he claimed that nothing in animal\nbehavior requires a non-mechanistic, mental explanation; hence he saw\nno reason to attribute possession of mind to animals.  In a sense,\ntherefore, the Cartesian argument for the human-uniqueness of\nconsciousness rests on the premise that material processes are\ninsufficient to account for human capacities for language,\nrationality, and self-awareness (i.e. the awareness of oneself as,\nputatively, an essentially thinking thing) — and hence a\nnon-material soul was posited to account for these phenomena.  Few\ntoday would hold that material processes are incapable of producing\ncomplex phenomena such as language and rationality, and indeed our\nunderstanding of ‘the material’ has changed dramatically\nsince Descartes' time. However, the subjective nature of consciousness\ncontinues to motivate some authors to argue that mental phenomena\ncannot be reduced to physical phenomena. \nThere is no conceptual reason why animal bodies are any less suitable\nvehicles for embodying a Cartesian soul, or any other of the\nputatively non-physical aspects of mind posited by proponents of\ndualism, than are human bodies. Hence, dualism does not preclude\nanimal minds as a matter of conceptual necessity. The distribution of\nconsciousness is a matter of empirical contingency on dualist theories\nas for physicalist theories. For some dualists, this may come down to\nwhether or not the animals in question possess specific cognitive\ncapacities, although others may argue that the non-physical nature of\nthe mental makes it difficult or impossible to investigate\nempirically.  \n\nEarly physicalist accounts of consciousness explored the philosophical\nconsequences of identifying consciousness with unspecified physical or\nphysiological properties of neurons.  In this generic form, such\ntheories do not provide any particular obstacles to attributing\nconsciousness to animals, given that animals and humans are built upon\nthe same biological, chemical, and physical principles.  If it could\nbe determined that phenomenal consciousness was identical to (or at\nleast perfectly correlated with) some general property such as quantum\ncoherence in the microtubules of neurons, or brain waves of a specific\nfrequency, then settling the Distribution Question would be a\nstraightforward matter of establishing whether or not members of other\nspecies possess the specified properties. Searle (1998) too, although\nhe rejects the physicalist/dualist dialectic, also suggests that\nsettling the Distribution Question for hard cases like insects will\nbecome trivial once neuroscientists have carried out the non-trivial\ntask of determining the physiological basis of consciousness in\nanimals for which no reasonable doubt of their consciousness can be\nentertained (i.e., mammals).  \nSome philosophers have sought more specific grounding in the\nneurosciences for their accounts of consciousness.  Block (2005)\npursues a strategy of using tentative functional characterizations of\nphenomenal and access consciousness to interpret evidence from the\nsearch by neuroscientists for neural correlates of consciousness. He\nargues, on the basis of evidence from both humans and monkeys, that\nrecurrent feedback activity in sensory cortex is the most plausible\ncandidate for being the neural correlate of phenomenal consciousness\nin these species.  Prinz (2005) also pursues a neurofunctional\naccount, but identifies phenomenal consciousness with a different\nfunctional role than Block.  He argues for identifying phenomenal\nconsciousness with brain processes that are involved in attention to\nintermediate-level perceptual representations which feed into working\nmemory via higher level, perspective-invariant representations. Since\nthe evidence for such processes is at least partially derived from\nanimals, including other primates and rats, his view is supportive of\nthe idea that phenomenal consciousness is found in some nonhuman\nspecies (presumably most mammals). Nevertheless, he maintains that it\nmay be impossible ever to answer the Distribution Question for more\ndistantly related species; he mentions octopus, pigeons, bees, and\nslugs in this context. \n\nRepresentational theories of consciousness\n link phenomenal consciousness with the\nrepresentational content of mental states, subject to some further\nfunctional criteria.   \nFirst-order representationalist accounts hold that if a particular\nstate of the visual system of an organism represents some property of\nthe world in a way that is functionally appropriate (e.g., not\nconceptually mediated, and operating as part of a sensory system),\nthen the organism is phenomenally conscious of that\nproperty. First-order accounts are generally quite friendly to\nattributions of consciousness to animals, for it is relatively\nuncontroversial that animals have internal states that have the\nrequisite functional and representational properties (insofar as\nmental representation itself is uncontroversial, that is). Such a view\nunderlies Dretske's (1995) claim that phenomenal consciousness is\ninseparable from a creature's capacity to perceive and respond to\nfeatures of its environment, i.e., one of the uncontroversial senses\nof consciousness identified above. On Dretske's view, phenomenal\nconsciousness is therefore very widespread in the animal kingdom.\nLikewise, Tye (2000) argues, based upon his first-order\nrepresentational account of phenomenal consciousness, that it extends\neven to honeybees.   Driven by a variety of allegedly counter-intuitive consequences of\nfirst-order theories of consciousness, including skepticism about the\nrange of organisms it spans, a number of philosophers have offered a\nvariety of higher-order accounts of phenomenal consciousness. Such\naccounts invoke mental states directed towards other mental states to\nexplain phenomenal consciousness.  Carruthers' “higher order\nthought” (HOT) theory is that a mental state is phenomenally\nconscious for a subject just in case it is available to be thought\nabout directly by that subject (Carruthers 1998a,b, 2000). The term\n“available” here makes this a\n“dispositionalist” account. The contrast is an\n“actualist” account, which requires the actual occurrence\nof the 2nd order thought for subject to be conscious in the relevant\nsense. According to Carruthers, such higher-order thoughts are not\npossible unless a creature has a “theory of mind” to\nprovide it with the concepts necessary for thought about mental\nstates. Carruthers' view is of particular interest in the current\ncontext because he has used it explicitly to deny phenomenal\nconsciousness to (almost) all nonhuman animals.  \nCarruthers argues, there is little, if any, scientific support for\ntheory of mind in nonhuman animals, even among the great apes —\nwith the possible exception of chimpanzees — from which he\nconcludes that there is little support either for the view that any\nanimals possess phenomenological consciousness. Further evaluation of\nthis argument will be taken up further below, but it is worth noting\nhere that if (as experiments on the attribution of false beliefs\nsuggest) young children before the age of four years typically lack a\ntheory of mind, Carruthers' view entails that they are not sentient\neither — fear of needles notwithstanding! This is a bullet\nCarruthers bites, although for many it constitutes a reductio\nof his view (a response Carruthers would certainly regard as\nquestion-begging). \n\nIn contrast to Carruthers' higher-order thought account of\nsentience, other theorists such as Armstrong (1980), and Lycan (1996)\nhave preferred a higher-order experience account, where\nconsciousness is explained in terms of inner perception of mental\nstates, a view that can be traced back to Aristotle, and also to John\nLocke. Because such models do not require the ability to conceptualize\nmental states, proponents of higher-order experience theories have\nbeen slightly more inclined than higher-order theorists to allow that\nsuch abilities may be found in other \nanimals[6].\n Gennaro (2004) argues, however, that a higher order thought theory is\ncompatible with consciousness in nonhuman animals, arguing that\nCarruthers and others have overstated the requirements for the\nnecessary mental concepts and that reentrant pathways in animal brains\nprovide a structure in which higher- and lower-order representations\ncould actually be combined into a unified conscious state.  One metaphysical question that is more directly relevant for the\nquestion of the phylogenetic distribution and evolution of\nconsciousness is whether possessing it (i.e. being conscious) is\nbinary (i.e. on/off, all-or-nothing), or admits of degrees.  Several\nauthors have, for quite different reasons, denied what they take to be\na common but problematic assumption — that “Consciousness is an\non/off switch; a system is either conscious or not,” as Searle —\nwho endorses the thesis puts it (quoted by Lycan 1996, who denies the\nthesis). \n\nLycan argues that consciousness can come in a wide spectrum of degrees\nof richness or fullness of consciousness, and that there is a\nmeaningful sense in which a system with a minimal degree of\nconsciousness is not “really” conscious (1996, p. 8). Admittedly, this\nsounds a bit paradoxical, but the point seems to be that it is\ncounter-intuitive for us to consider very low degrees of\nconsciousness, as it is hard to imagine the contents of very simple\nmental states. One reading of this is that Lycan is arguing that the\npredicate ‘conscious’ is vague, without committing himself\nto the view that consciousness is distributed according to a linear\nscale. \nDennett (1995) also argues that consciousness is not binary. He does\nso in the context of advocating a radically deflationary anti-realism\nabout consciousness overall, on which consciousness is essentially an\nillusion created by language (1991/1995). On his view, “the very idea\nof there being a dividing line between those creatures ‘it is\nlike something to be’ and those that are ‘mere\nautomata’ (is) an artifact of our traditional assumptions.”\n(1995, p. 706)\n  Velmans (2012) distinguishes between ‘discontinuity\ntheories’, which claim that there was a particular point at\nwhich consciousness originated, before which there was no\nconsciousness (this applies both the the universe at large, and also\nto any particular consciousness individual), and ‘continuity\ntheories’, which conceptualize the evolution of consciousness in\nterms of “a gradual transition in consciousness from unrecognizable to\nrecognizable.” He argues that continuity theories are more elegant, as\nany discontinuity is based on arbitrary criteria, and that\ndiscontinuity theories face “the hard problem” in a way that\ncontinuity theories don't. Velmans takes these arguments to weigh in\nfavor of adopting, not just a continuity theory, but a form of\npanpsychism. \nThe three authors described just above deny that consciousness is\nbinary for very different reasons, and each of their views is\ncontroversial. Further, none of them offers much in the way of tools\nor concepts for thinking about the putatively nonbinary nature of\nconsciousness. Following up on Lycan's suggestion of degrees of\nrichness or fullness, one might ask what graded dimensions or\nqualitative thresholds might be available to distinguish different\nkinds of minds? Various authors have distinguished between\n‘primary’ and ‘higher order’ consciousness\n(Seth et al. 2005); ‘primary’, ‘secondary’,\nand ‘tertiary’ consciousness (Panksepp 2005); and\n‘core’ and ‘extended’ consciousness (Damasio\n1999). However, most of these authors seem to correlate phenomenal\nconsciousness, i.e. having any subjective experience at all, with\nprimary or core consciousness. The terms “secondary” and\n“tertiary” are supposed to pick out elaborated forms of\nconsciousness. Hence it is not clear that any of these taxonomies are\nat odds with the idea that phenomenal consciousness itself is binary\n— either wholly present or wholly absent for a given\nsystem. However, the issue deserves more scrutiny, as it bears on the\nproblems of the distribution and evolutionary origins of\nconsciousness. If consciousness is non-binary, then the distribution\nof consciousness will not be sharply bounded, but will include\ngradations — some animals may be partially or incompletely\nconscious.\n \n\nPhenomenal consciousness is just one feature (some would say the\ndefining feature) of mental states or events. Any theory of animal\nconsciousness must be understood, however, in the context of a larger\ninvestigation of animal cognition that (among philosophers) will also\nbe concerned with issues such as intentionality (in the sense\ndescribed by the 19th C. German psychologist Franz Brentano) and\nmental content (Dennett 1983, 1987; Allen 1992a,b). \n\nPhilosophical opinion divides over the relation of consciousness to\nintentionality with some philosophers maintaining that they are\nstrictly independent, others (particularly proponents of the\nfunctionalist theories of consciousness described in this section)\narguing that intentionality is necessary for consciousness, and still\nothers arguing that consciousness is necessary for genuine\nintentionality. Many behavioral\nscientists accept cognitivist explanations of animal behavior that\nattribute representational states to their subjects. Yet they remain\nhesitant to attribute consciousness. If the representations invoked\nwithin cognitive science are intentional in Brentano's sense, then\nthese scientists seem committed to denying that consciousness is\nnecessary for intentionality. \nThere remains great uncertainty about the metaphysics of phenomenal\nconsciousness and its precise relations to intentionality, to the\nbrain, to behavior, etc. It is beyond the scope of this article to\nsurvey the strong attacks that have been mounted against the various\naccounts of consciousness in these terms, but it is safe to say that\nnone of them seems secure enough to hang a decisive endorsement or\ndenial of animal consciousness upon it. Accounts of consciousness in\nterms of basic neurophysiological properties, the quantum-mechanical\nproperties of neurons, or sui generis properties of the\nuniverse are just as insecure as the various functionalist\naccounts. And even those accounts that are compatible with animal in\ntheir general outline, are not specific enough to permit ready answers\nto the Distribution Question in its full generality.  Hence no firm\nconclusions about the distribution of consciousness can be drawn on\nthe basis of the philosophical theories of consciousness that have\nbeen discussed so far.  Where does this leave the epistemological questions about animal\nconsciousness? While it may seem natural to think that we must have a\ntheory of what consciousness is before we try to determine whether\nother animals have it, this may in fact be putting the conceptual cart\nbefore the empirical horse. In the early stages of the scientific\ninvestigation of any phenomenon, putative samples must be identified\nby rough rules of thumb (or working definitions) rather than complete\ntheories. Early scientists identified gold by contingent\ncharacteristics rather than its atomic essence, knowledge of which had\nto await thorough investigation of many putative examples — some\nof which turned out to be gold and some not. Likewise, at this stage\nof the game, perhaps the study of animal consciousness would benefit\nfrom the identification of animal traits worthy of further\ninvestigation, with no firm commitment to idea that all these examples\nwill involve conscious experience.  Recall the Cartesian argument that animals do not use language\nconversationally or reason generally. This argument, based on the\nalleged failure of animals to display certain intellectual capacities,\nis illustrative of a general pattern of using certain\ndissimilarities between animals and humans to argue that\nanimals lack consciousness. \n\nA common refrain in response to such arguments is that, in situations\nof partial information, “absence of evidence is not evidence of\nabsence”. Descartes dismissed parrots vocalizing human words\nbecause he thought it was merely meaningless repetition. This judgment\nmay have been appropriate for the few parrots he encountered, but it\nwas not based on a systematic, scientific investigation of the\ncapacities of parrots. Nowadays many would argue that Pepperberg's\nstudy of the African Grey parrot “Alex” (Pepperberg 1999)\nshould lay the Cartesian prejudice to rest. This study, along with\nseveral on the acquisition of a degree of communicative competence by\nchimpanzees and bonobos (e.g., Gardner et al. 1989;\nSavage-Rumbaugh 1996) would seem to undermine Descartes' assertions\nabout lack of meaningful communication and general reasoning abilities\nin animals. (See, also, contributions to Hurley & Nudds 2006.) \n\nCartesians respond by pointing out the limitations shown by animals in\nsuch studies (they can't play a good game of chess, after all, let\nalone tell us what they are thinking about), and they join linguists\nin protesting that the subjects of animal-language studies have not\nfully mastered the recursive syntax of natural human\nlanguages.[7]\n But this kind of post hoc raising of\nthe bar suggests to many scientists that the Cartesian position is not\nbeing held as a scientific hypothesis, but as a dogma to be defended\nby any means. Convinced by evidence of sophisticated cognitive\nabilities, most philosophers these days agree with Block that\nsomething like access consciousness is properly attributed to many\nanimals.  Nevertheless, when it comes to phenomenal consciousness,\ndissimilarity arguments are not entirely powerless to give some pause\nto defenders of animal sentience, for surely most would agree that, at\nsome point, the dissimilarities between the capacities of humans and\nthe members of another species (the common earthworm Lumbricus\nterrestris, for example) are so great that it is unlikely that\nsuch creatures are sentient. A grey area arises precisely because no\none can say how much dissimilarity is enough to trigger the judgment\nthat sentience is absent. The aim of picking out, in a principled way, behavioral or\nneurophysiological characteristics that could serve as reliable\nindicators for consciousness motivates the structure and function\noriented approach that many authors have pursued since the turn of the\n21st century. Though sometimes pursued along with metaphysical\nquestions about consciousness, this project promises empirical\ntractability even in the face of persistent uncertainty about the\nmetaphysical questions of consciousness. \nOne strategy for bringing consciousness into the scientific fold is to\ntry to articulate a theoretical basis for connecting the observable\ncharacteristics of animals (behavioral or neurological) to\nconsciousness.  What effects should consciousness have on behavior?\nWhat capacities and dispositions should we expect a conscious creature\nto have that might be absent in a nonconscious creature?  What\nneurophysiological structures and processes might realize the dynamics\nor information processing required for consciousness?\n  Such an approach is nascent in Griffin's attempts to force\nethologists to pay attention to questions about animal consciousness,\nin all its senses — including phenomenal consciousness. In a\nseries of books, Griffin (who made his scientific reputation by\ncarefully detailing the physical and physiological characteristics of\necholocation by bats) provides examples of communicative and\nproblem-solving behavior by animals, particularly under natural\nconditions, and argues that these are prime places for ethologists to\nbegin their investigations of animal consciousness (Griffin 1976,\n1984, 1992).  Although he thinks that the intelligence displayed by these\nexamples suggests conscious thought, many critics have been\ndisappointed by the lack of systematic connection between Griffin's\nexamples and the attribution of consciousness (see, e.g., Alcock 1992).\nGriffin's main positive\nproposal in this respect has been the rather implausible suggestion\nthat consciousness might have the function of compensating for limited\nneural machinery.  Thus Griffin is motivated to suggest that\nconsciousness may be more important to honey bees than to humans. \n\nIf compensating for small sets of neurons is not a plausible function\nfor consciousness, what might be? The commonsensical answer would be\nthat consciousness “tells” the organism about events in\nthe environment, or, in the case of pain and other proprioceptive\nsensations, about the state of the body. But this answer begs the\nquestion against opponents of attributing conscious states to animals\nfor it fails to respect the distinction between phenomenal\nconsciousness and mere awareness (in the uncontroversial sense of\ndetection) of environmental or bodily events. Opponents of attributing\nphenomenal consciousness to animals are not committed to denying the\nmore general kind of consciousness of various external and\nbodily events, so there is no logical entailment from awareness of\nthings in the environment or the body to animal sentience. \n\nPerhaps more sophisticated attempts to spell out the functions of\nconsciousness are similarly doomed. But Allen & Bekoff (1997, ch.\n8) suggest that progress might be made by investigating the capacities\nof animals to adjust to their own perceptual errors. Not all\nadjustments to error provide grounds for suspecting that consciousness\nis involved, but in cases where an organism can adjust to a perceptual\nerror while retaining the capacity to exploit the content of the\nerroneous perception, then there may be a robust sense in which the\nanimal internally distinguishes its own appearance states from other\njudgments about the world. (Humans, for instance, have conscious\nvisual experiences that they know are misleading — i.e., visual\nillusions — yet they can exploit the erroneous content of these\nexperiences for various purposes, such as deceiving others or\nanswering questions about how things appear to them.) Given\nthat there are theoretical grounds for identifying conscious\nexperiences with “appearance states”, attempts to discover\nwhether animals have such capacities might be a good place to start\nlooking for animal consciousness. It is important, however, to\nemphasize that such capacities are not themselves intended to be\ndefinitive or in any way criterial for consciousness.\n\nCarruthers (2000) makes a similar suggestion about the function of\nconsciousness, relating it to the general capacity for making an\nappearance-reality distinction; of course, he continues to maintain\nthat this capacity depends upon having conceptual resources that are\nbeyond the grasp of nonhuman animals. \nThe broad issue of function is closely related to questions about just\nwhat sort of mental process consciousness is. As we shall see in the\nnext section, hypotheses in the modern literature on the distribution\nand evolution of consciousness are therefore generally advanced\ntogether with theories of its structure and function in the following\nsenses:\n \nStructure: what are the contents of consciousness (what information,\nrepresentations, intentional contents, properties, processes,\netc. does it include)? What (possibly unconscious or subconscious)\ninformation, representations, or other cognitive or intentional\nprocesses, entities and relations, are required for consciousness?\n \nFunction: how does consciousness relate to other (nonconscious)\nprocesses, in cognition, the body and the environment? How does\npossessing consciousness contribute to an animal's ability to navigate\nand respond adaptively to its environment, to survive and thrive?\n  Different views about what consciousness is, qua cognitive\nprocess, and how it relates to other biological processes such as\nbehavior, development and ecological interaction, largely determine\nbiologically oriented views about which animals have consciousness and\nwhen, how, and why it evolved. To illustrate this, we can start with a\ncrude distinction between views that see consciousness as fundamental\nto the basic perceptual and cognitive processes involved in\ncontrolling an animal body, or as something that can be added on or\nplugged in to a system that is already sufficient for basic control of\nperception-guided action. The more fundamental consciousness is to\nbasic animal functioning, the more widely distributed and ancient\nconsciousness must be; if, however, consciousness is relatively\nmodular, functionally narrow, and conceptually high level, then it\nshould be narrowly distributed among animals and relatively recently\nevolved. The views surveyed in the following section all exploit the\nconnections between function, structure, distribution and evolutionary\norigin.    One further point worth noting is that structural models of\nconsciousness are usually justified in terms of phenomenological or\nintrospective observations — i.e. observations about the nature\nof consciousness as it is experienced by the subject. Though the use\nof such first person methods is now and has been controversial in\npsychology and philosophy throughout the 20th and 21st century, there\nseems to now be a broad acknowledgement that it has an indispensable\nrole in the scientific study of consciousness, as many authors who\nhave published recent scientific theories of consciousness include\nsome appeal to phenomenological premises in justifying their views\n(e.g. Seth, Edelman and Baars 2005; Merker 2005; Tononi 2008; Cabanac\net al. 2009).  A variety of hypotheses have been put forward by scientists and\nphilosophers about which animals are conscious and which are\nnot. These views span a huge range of possibilities, from the\nnarrowest, which is that only humans are conscious, to some authors\narguing that almost all animals, even simple invertebrates, have a\nbasic capacity to experience the world. Some authors have even argued\nthat single-celled organisms (Margulis 2001) or plants (A. Nagel 1997)\nare conscious, and some have given arguments for versions of\npan-psychism, the view that consciousness is a property of fundamental\nphysical entities, much in the same way that mass and charge are\n(Chalmers 2015). It is worth noting that neither the attribution of\nconsciousness to single-celled organisms, nor to fundamental physical\nentities, implies that all animals are conscious. In the former case,\nit may be that the information processing complexity and integration\nof relatively complex single-celled organisms outstrips that of the\nsimplest animals. In the latter case, while the version of panpsychism\ndeveloped by Chalmers attributes ‘microexperience’ to\n‘fundamental physical entities’, this does not imply that\nany particular macroscopic object (like an animal) has\n‘macroexperience’ — i.e. “the sort of conscious\nexperience had by human beings” (Chalmers 2015). This view is\ncompatible with the possibility that a given animal has no conscious\nexperience, although it is composed of microphysical entities which\npossess conscious microexperience.  These issues will not be discussed\nfurther here, as they fall outside the scope of Animal\nConsciousness.  The question of which lineages (species, or more inclusive\ngroupings such as class or phylum) of animals are conscious,\ninevitably goes hand-in-hand with considerations of the evolutionary\norigin of consciousness. This is a logical implication of the broadly\nDarwinian view of life, on which modern organisms have evolved through\ndescent, with modification, from a small number (perhaps one) of very\nancient ancestors.  If a trait is characteristic of a given species,\nit either arose in that species, or is derived from an ancestor\n— in which case, it will be present in other species derived\nfrom that ancestor, unless it has been secondarily lost in those\nspecies. Did consciousness first arise in humans, or in an earlier,\nnonhuman ancestor? If the latter, then what was this ancestor? Another\npossibility is that consciousness may have arisen multiple times, like\nwinged flight, which evolved independently in insects, birds, bats,\nand pterosaurs.   As described above, the view that consciousness is unique to\nhumans has a long history. It coheres with a religious view of\nhumanity as the pinnacle of creation, and it also may be appealing\ninsofar as it absolves us of any guilt for our treatment of\nanimals. Religion aside, it may derive considerable intuitive support\nbecause of the appeal of connecting consciousness to the problem of\nhuman uniquenesss.  If consciousness can be tied together with\nlanguage, abstract reasoning, or some other mental characteristic that\npotentially could explain our apparent seperateness from the natural\nworld, this would solve two outstanding mysteries at once.  \nDennett (1991, 1995) has been an outspoken advocate of the\nhuman-uniqueness of consciousness. Dennett argues for this position in\nconnection with his anti-realist theory of consciousness, the upshot\nof which is that consciousness is a sort of “user\nillusion” (1995) or “fiction” (1991, p. 365, p. 429)\nconstructed through people's narrative descriptions:\n \nOn Dennett's view, because consciousness is a sort of story telling,\nwhich requires language, and only (adult, normally enculturated and\nlanguage-capable) humans have language, only these humans have\nconsciousness. \n\nCarruthers has championed the view that only humans (with the possible\nexception of chimpanzees) are conscious, although for different\nreasons than Dennett. Carruthers (1998a,b, 2000) has argued to this\neffect based on his ‘higher-order thought’ theory,\naccording to which, phenomenal consciousness requires the capacity to\nthink about, and therefore conceptualize, one's own \n thoughts.[8] \n Such conceptualization requires, according to Carruthers, a theory of mind.\nAnd, Carruthers maintains, there is little basis for thinking that any\nnonhuman animals have a theory of mind, with the possible exception of\nchimpanzees (see Lurz 2011 and Andrews 2012 for in depth discussion of\ntheory of mind in nonhuman animals). This argument is, of course, no\nstronger than the higher-order thought account of consciousness upon\nwhich it is based.  But setting that aside for the sake of argument,\nthis challenge by Carruthers deserves further attention as perhaps the\nmost empirically-detailed case against animal consciousness to have\nbeen made in the philosophical literature. \n\nCarruthers neither endorses nor outright rejects the conclusion that\nchimpanzees are sentient. His suspicion that even chimpanzees might\nlack theory of mind, and therefore (on his view) phenomenal\nconsciousness, is based on some ingenious laboratory studies by\nPovinelli (1996) showing that in interactions with human food\nproviders, chimpanzees apparently fail to understand the role of eyes\nin providing visual information to the humans, despite their outwardly\nsimilar behavior to humans in attending to cues such as facial\norientation. The interpretation of Povinelli's work remains\ncontroversial. Hare et al. (2000) conducted experiments in\nwhich dominant and subordinate animals competed with each other for\nfood, and concluded that “at least in some situations\nchimpanzees know what conspecifics do and do not see and, furthermore,\nthat they use this knowledge to formulate their behavioral strategies\nin food competition situations.” They suggest that Povinelli's\nnegative results may be due to the fact that his experiments involve\nless natural chimp-human interactions. Given the uncertainty,\nCarruthers is therefore well-advised in the tentative manner in which\nhe puts forward his claims about chimpanzee sentience. \n\nA full discussion of the controversy over theory of mind (e.g., Heyes\n1998; Lurz 2011; Andrews 2012) deserves an entry of its own, but it is\nworth remarking here that the theory of mind debate has origins in the\nhypothesis that primate intelligence in general, and human\nintelligence in particular, is specially adapted for social cognition\n(see Byrne & Whiten 1988, especially the first two chapters, by\nJolly and Humphrey).  Consequently, it has been argued that evidence\nfor the ability to attribute mental states in a wide range of species\nmight be better sought in natural activities such as social play,\nrather than in laboratory designed experiments which place the animals\nin artificial situations (Allen & Bekoff 1997; see esp. chapter 6;\nsee also Hare et al. 2000, Hare et al. 2001, and\nHare & Wrangham 2002).  Alternative approaches that have attempted\nto provide strong evidence of theory of mind in nonhuman animals under\nnatural conditions have generally failed to produce such evidence\n(see, e.g., the conclusions about theory of mind in vervet monkeys and\nbaboons by Cheney & Seyfarth 1990, 2007), although anecdotal\nevidence tantalizingly suggests that researchers still have not\nmanaged to devise the right experiments. Furthermore, theory of mind\n— and social cognition more broadly — are active areas of\nresearch, and it is quite possible that new research will reveal\nevidence of theory of mind in nonhuman animals.   \n\nOn views such as Carruthers', consciousness is grounded in cognitive\nprocesses that are highly specific and modular — indeed,\nirrelevant for the perceptual, motivational and cognitive processes\ninvolved with all nonhuman animal behavior. Given that most of the\ncognitive processes (and corresponding brain-systems) involved with\nhuman activities are shared with nonhuman animals, this line of\nthinking implies that much of human activity is nonconscious as\nwell. Thus, for example, Carruthers (1989, 1992) argued that\nall animal behavior can be assimilated to the non-conscious\nactivities of humans, such as driving while distracted (“on\nautopilot”), or to the capacities of “blindsight”\npatients whose damage to visual cortex leaves them phenomenologically\nblind in a portion of their visual fields (a “scotoma”)\nbut nonetheless able to identify things presented to the scotoma. (He\nrefers to both of these as examples of “unconscious\nexperiences”.)  This comparison of animal behavior to the unconscious capacities\nof humans can be criticized on the grounds that, like Descartes'\npronouncements on parrots, it is based only on unsystematic\nobservation of animal behavior. There are grounds for thinking that\ncareful investigation would reveal that there is not a very close\nanalogy between animal behavior and human behaviors associated with\nthese putative cases of unconscious experience. For instance, it is\nnotable that the unconscious experiences of automatic driving are not\nremembered by their subjects, whereas there is no evidence that\nanimals are similarly unable to recall their allegedly unconscious\nexperiences.  Likewise, blindsight subjects do not spontaneously\nrespond to things presented to their scotomas, but must be trained to\nmake responses using a forced-response paradigm. There is no evidence\nthat such limitations are normal for animals, or that animals behave\nlike blindsight victims with respect to their visual experiences\n(Jamieson & Bekoff 1992). \n\nNevertheless, there are empirical grounds for concern that behavior\nsuggesting consciousness in animals may be the product of unconscious\nprocesses.  Allen et al. (2009) describe work on learning in\nspinal cords of rats that shows phenomena analogous to latent\ninhibition and overshadowing.  In intact animals, these learning and\nmemory related phenomena have been argued to involve attention.  But\ntheir similarity to mechanisms in the spinal cord, assumed by most not\nto involve consciousness, calls into question their status as evidence\nfor consciousness. There are, of course, differences between the\nlearning capacities of spinal cords and the learning capacities of\nintact organisms, and there are prima facie reasons for thinking that\nsophisticated forms of learning are related to consciousness (Clark\n& Squire 1998; Allen 2004; Ginsburg & Jablonka 2007b). But \nthe current point is similar to that made\nabout blindsight: a more fine-grained analysis of these similarities\nand differences is needed before conclusions about consciousness can\nbe drawn. \n\nGallup (1970) developed an experimental test of mirror\nself-recognition that has become widely used as a test of\nself-awareness, although interpretation of the test remains\ncontroversial (see the section on\n self-consciousness and metacognition\nbelow). Gallup argues that the performance of chimpanzees in this test\nindicates that they are self-aware, and that animals that fail the\ntest lack self-awareness. Further, foreshadowing Carruthers, Gallup\nargues that self-awareness — in the sense of being able to think\nabout one's own mental states — is required for having a mind,\nand therefore that animals that ‘fail’ the mirror test\nhave no minds (1982, 1985). Though there has been controversy over\njust which animals ‘pass’ the validity of versions of the test modified for use with elephants, dolphins,and magpies has been challenged \n— as of 2002, Gallup maintained that there was evidence that\nhumans, common chimpanzees, bonobos and orangutans consistently pass\nthe test, and strong evidence that a wide range of other primates fail\nconsistently fail. He took this to support the claim that\nself-awareness is unique to great apes (Gallup et al. 2002). Combined\nwith his earlier arguments that consciousness requires the sort of\nself-awareness measured by the mirror test, this would imply that\nconsciousness is unique to the great apes.\n  Gallup's interpretation of the mirror results have not been\nuncontroversial (Mitchell 2002). Rochat and Zahavi (2010) challenge\nGallup both on a) the interpretation of chimps' mirror-oriented\nbehavior as indicating a human-like experience of mirror\nself-recognition, and b) the claim that mirror self-recognition is\nimplied by consciousness.  As a side note, there has been a debate, ongoing since the early\n1990s (Cavalieri and Singer 1994) about whether great apes deserve\nspecial legal protection amounting to ‘human rights’. The\ncrux of the debate is not whether the great apes have consciousness\nper se (this seems to be assumed by most participants of the debate,\non both sides), but whether they have personhood. Personhood is\na vexed notion, but is generally thought to be related to certain\nforms of agency and self awareness, and is often thought to be tightly\ncoupled to moral status, as reflected in this debate (DeGrazia 1997;\nSEP article on Moral Status of Animals; Varner 2012). Though not\nessential to phenomenal consciousness, personhood is often thought to\npresuppose consciousness, and so perhaps is best thought of as a level\nof elaboration or complexity of consciousness. A variety of theoretical and empirical arguments have been put\nforward to the effect that consciousness is shared across all\nmammals. Seth, Baars and Edelman (2005) argue that the neural\nprocesses essential to human conscious — widespread reentrant\nactivity in the thalamo-cortical complex — involve anatomical\nsystems that are shared among all mammals (and perhaps more\nwidely). Panksepp (reviewed in 2005) takes a similar approach,\nalthough focusing on the neurophysiological systems involved in the\n‘core emotions’. Although in both of the above proposals,\nthe authors acknowledge that consciousness may be more widespread than\njust mammals, they argue that in the case of mammals, the weight of\nevidence based on homology of relevant neurophysiological systems is\noverwhelming, whereas outside of mammals, the inference is more\ntenuous because of the biological differences in non-mammalian\nanimals. Further, it should be kept in mind that all of the following\nproposals imply that consciousness is widely shared among\nmammals. Hence, the position that all mammals are conscious is widely\nagreed upon among scientists who express views on the distribution of\nconsciousness. \nQuestions about whether reptiles are conscious (and if so what their\nmental lives might be like) are especially interesting because birds\nare more closely related to them than they are to mammals, yet birds\ndisplay a variety of behaviors that tend to intuitively suggest\nintelligence and emotion to human observers much more obviously than\nthe behavior of scaly, so-called ‘cold-blooded’ animals\nlike snakes and turtles. Do birds and mammals share mental features\n(consciousness, intelligence, emotion, social attachment) that are\nabsent in reptiles? If so this would represent independent, convergent\nevolution of these phenomena. Alternatively, are these features common\nto all of these animals, but less obvious in some than others?  Cabanac et al. (2009) argue that consciousness is unique to, and\nshared by all amniotes — the clade that includes all\ndescendants of the common ancestor of living birds and mammals,\nincluding reptiles such as lizards, snakes, turtles and extinct\nanimals such as dinosaurs, pterosaurs and pleseiosaurs (see\nhttp://tolweb.org/Amniota). On this hypothesis, only these animals,\nand not amphibians, fish, or any invertebrates, possess\nconsciousness. Cabanac's argument is based on an explicit structural\nand functional theory of consciousness as a unified representational\nspace, “an abstract private model of reality with four dimensions:\nquality, intensity, hedonicity and duration” (2009, p.268). Possessing\nthis ability to model reality allows animals to simulate possible\ncourses of action, using hedonicity (pleasure or pain) as a\n‘common currency’ to evaluate and choose between actions\nbased on expected consequences (which are based on prior\nexperience).  \nCabanac identifies a set of behavioral markers of consciousness, based\non this model structural and functional theory:  Based on supposed evidence of these phenomena in amniotes but not\nin non-amniotes, Cabanac argues that consciousness originated in the\ncommon ancestor of amniotes, and hence is present in all living\namniotes but in no other animals. Cabanac and Cabanac (2009) also\nargue that a qualitative difference in the role of dopamine in\nmotivational processes in the brains of amniotes compared to\nnon-amniotes supports this distribution/origin hypothesis.   Cabanac and colleagues have documented the presence of some of\nthese phenomena in amniotes, in contrast with their absence in at\nleast a small number of non-amniote species, such as emotional fever\n(Cabanac and Bernieri 2000; Cabanac and Cabanac 2000; Cabanac and\nCabanac 2004) and taste aversion (Paradis and Cabanac 2004).   However, the assertion that these aspects of behavior and\ncognition do not exist outside amniota is largely based on absence of\nevidence (and hence, inherently limited). In particular, they do not\noffer direct support for their claims that non-amniotes are incapable\nof trading off punishments and rewards, play or detouring. Indeed,\nsome of these claims appear to be contradicted by existing studies\n— for example, documentation of detouring in jumping spiders\n(Jackson and Wilcox 2003) and work by Elwood and Appel(2009) that\nshows motivational trade-off behavior in hermit crabs.   Cabanac's structural and functional theory of consciousness can be\nevaluated independently of the evidence that he marshals in support of\nhis view of the distribution and origins of consciousness. Indeed, one\nmight challenge his views on distribution and origins precisely by\naccepting his structural and functional theory, and arguing that the\nlist of proposed indicators can actually by identified with a wider\ndistribution (i.e. if motivational trade-offs, play, and detouring are\npresent outside of amniotes). As we shall see, his structural and\nfunctional views of consciousness have much in common with those of\nother authors who argue for wider distributions of consciousness among\nanimals. 'Fish' is a folk-biological term that does not correspond precisely\nto any monophyletic taxonomic group. This can be appreciated by noted\nthat a coelacanth is more closely related to a human than to a tuna,\nor that a tuna is more closely related to a human than it is to a\nshark. I.e., some things that are intuitively fish are more closely\nrelated to non-fish than to other fish. Basically, the folk term 'fish'\nrefers to all vertebrates other than tetrapods, although it is\nsomewhat ambiguous in regards to animals such as sea-horses, eels,\nhagfish and sting-rays. In any case, there has a lively debate over fish consciousness,\nmostly focusing on the issue of whether fish can experience pain,\nstress and suffering (see below, section 7.1; see also Rose (2002) and\nSneddon et al. (2003) for contrasting views of conscious pain in fish;\nAllen 2013 and Brown 2015 for reviews of fish cognition and\nconsciousness as it may relate to pain; and Braithwaite 2010 for a\nbook-length treatment). This is of special relevance in the context of\nwelfare regulation in commercial aquaculture and recreational angling;\naccordingly, the fish consciousness literature has focused\nexperimentally on salmonids (especially salmon and trout), a group of\nhigh commercial and sport-fishing importance, but only a tiny\nphylogenetic corner of the animals that colloquially count as\nfish.   Merker (2005) has proposed that consciousness originated early in\nvertebrate evolution, and is therefore both ancient and widespread. On\nthis proposal, not only mammals and birds, but amphibians and all\nmarine vertebrates are conscious. Merker begins his argument with the\nphenomenological observation that the contents of conscious experience\nare object- and goal-oriented, but exclude the fine-grained sensory\nand motor details represented in peripheral and low-level neural\nprocessing. Merker argues that consciousness is an integrated\nrepresentational platform — what he refers to a\n‘synthesized reality space’ — that, for animals with\ncomplex bodies with many degrees of freedom of movement and multiple\nsensory modalities, solves a cluster of critical neural logistics\nproblems. This includes:  The neuroanatomical details of Merker's argument (2005) are beyond\nthe scope of this article to review, but his conclusion is that the\nsystems that solve the above problems — giving rise to\nconsciousness — arose in an early vertebrate ancestor. Hence,\nconsciousness is both ancient and widespread among living\nvertebrates. There are additional daunting challenges to addressing questions of\nconsciousness outside the vertebrate lineage, given the radical\ndifferences between vertebrates and invertebrates with respect to\nanatomy and physiology. The strategy of identifying homologous and\nfunctionally analogous structures and processes, which underlies the\nconfidence of researchers such as Cabanac (2009), Seth et al. (2005),\nMerker (2005), and Panksepp (2005) that consciousness is shared with\nother animals is much more difficult to apply (Seth et al. 2005). \nThe vertebrate lineage represents just one of approximately 34 known\nphyla — ancient lineages of animals characterized by differences\nin fundamental anatomical organization and the developmental processes\nthat generate it. Each of these phyla is derived from a relatively\nsimple state (i.e. few tissue types and a minimal central nervous\nsystem with limited sensory capacities). Hence, the invertebrates such\nas cephalopod mollusks (e.g., octopi and squids) and arthropods\n(e.g. crustaceans, insects and spiders), that are complex enough to\nattract the attention of those interested in animal consciousness,\nevolved their complexity independently from vertebrates, and in the\ncase of cephalopods and arthropods, independently from each other.\n \nToday, only three of the phyla (vertebrates, arthropods, and mollusks)\ninclude animals with complex active bodies (Trestman 2013a),\ncharacterized by: Trestman (2013a) argues that the evolution of complex active bodies\nrequires a capacity for integrated, embodied spatial cognition, and\nthat this capacity evolved independently in each of the three phyla in\nwhich it is currently found (vertebrates, arthropods and mollusks). If\nMerker (2005) is right that consciousness represents a solution to the\nneural-logistics problems posed by controlling a complex body in\nspace, it may be a good bet that these three lineages are likely\nsuspects for possessing consciousness. This line of reasoning can be\nbolstered by considering the role of temporal integration of\nperceptual information in consciousness and in action-selection and\nobject-oriented perception (Trestman 2013b). Perhaps each of these\nthree lineages evolved consciousness independently during the\ntransition from a relatively simple worm-like body morphology to\nhaving complex active bodies.  One group of invertebrate animals that has received attention in\nthe context of questions about consciousness is the coleoid\ncephalopods — octopuses, squids and cuttlefish. These are\nlarge-brained, notoriously clever animals, well-known for their\nremarkable abilities to camouflage th emselves, and for their flexible\nhunting strategies. Mather (2008) argues that cephalopods exhibit many\nbehavioral indicators of consciousness, including complex learning and\nspatial memory, as well as apparent play. Both Merker (2005) and Edelman et\nal. (2005, 2009) argue that a strong provisional case can be made for\nconsciousness in cephalopods — although these authors emphasize\nthe limitations on our understanding posed by the differences in\nanatomy and physiology between cephalopods and vertebrates.\n The other phylum that has received particular attention is the\narthropods, which includes insects, crustaceans, spiders, and many\nother less familiar animals. This is an ancient and tremendously\ndiverse group of animals, so any generalizations should be made with\ncaution. Arthropods were among the earliest animals to evolve complex\nactive bodies — and correlatively to evolve brains capable of\nadaptively controlling complex adaptive bodies (Trestman 2013a), and\nso if the function of consciousness is to solve problems raised by the\ncontrol of complex active bodies (cf. Merker 2005), it may have\nevolved early on in the arthropod lineage, in a common ancestor of all\nliving arthropods.\n  Few studies have aimed directly at answering questions about\nconsciousness in arthropods, but relevant empirical work includes: Another possibility is that consciousness evolved even earlier in\nanimal history and is even more widely distributed among animals, and\nhence has a function that is even more fundamental to animal\nlife. Ginsburg & Jablonka (2007a,b) attribute a primitive form of\n“overall sensation” as a by-product of even the simplest\nnerve nets in animals. They argue that as these states became\nharnessed to learning and motivation that they acquired the functional\nproperties of “basic consciousness”.  If this is right,\nthan consciousness may have arisen not independently in arthropods,\nmollusks and vertebrates, but only once in the common ancestor of\nthese ancient groups, very early in animal evolution.\n With the gradual loosening of behaviorist strictures in psychology\nand ethology, and independent advances in neuroscience, there has been\na considerable increase in the number of animal studies that have some\nbearing on animal consciousness.  Some of these studies focus on\nspecific kinds of experience, such as pain, while others focus on\ncognitive abilities such as self-awareness that seem to be strongly\ncorrelated with human consciousness. This section contains brief\nreviews of some of the main areas of investigation.  The aim is to\nprovide some quick entry points into the scientific literature.  Given the centrality of pain to most accounts of our ethical\nobligations towards animals, as well as the importance of animal\nmodels of pain in clinical medical research (see Mogil 2009 for a\nreview), it is hardly surprising that there is a substantial (albeit\ncontroversial) scientific literature bearing on animal pain. Reports\nby the Nuffield Council on Bioethics in the U.K. (Nuffield Council\n2005; see esp. chapter 4) and the U.S. National Academy of the\nSciences Institute for Animal Laboratory Research (ILAR 2009) have\nrecently covered the definition of pain and the physiological,\nneurological, and behavioral evidence for pain in nonhuman\nanimals. These reviews also distinguish pain from distress and\nsuffering (see also Bermond 2001), and the ILAR has divided what used\nto be a single report on recognition and alleviation of pain and\ndistress into two separate reports, although the scientific\ninvestigation of distress is relatively rudimentary (but see Dawkins\n1985; Farah 2008).  A proper understanding of neurological studies of animal pain\nbegins with the distinction between nociception and pain. Nociception\n— the capacity to sense noxious stimuli — is one of the\nmost primitive sensory capacities. Neurons functionally specialized\nfor nociception have been described in invertebrates such as the\nmedical leech and the marine snail Aplysia californica\n(Walters 1996). Because nociceptors are found in a very wide range of\nspecies, and are functionally effective even in decerebrate or\nspinally transected animals, their presence and activity\nin a species provides little or no direct evidence for phenomenally\nconscious pain experiences. The gate control theory of Melzack and\nWall (1965) describes a mechanism by which “top-down”\nsignals from the brain modulate “bottom-up” nociception,\nproviding space for the distinction between felt pain and\nnociception.  Smith & Boyd (1991) assess the evidence for the pain-sensing\ncapabilities of animals in the categories of whether nociceptors are\nconnected to the central nervous system, whether endogenous opioids\nare present, whether analgesics affect responses, and whether the\nensuing behavioral responses are analogous to those of humans (see\ntable 2.3 in Varner 1998, p. 53, which updates the one presented by\nSmith & Boyd).  On the basis of these criteria, Varner follows\nSmith & Boyd in concluding tentatively that the most obvious place\nto draw a line between pain-conscious organisms and those not capable\nof feeling pain consciously is between vertebrates and invertebrates.\nHowever, Elwood & Appel (2009) conducted an experiment on hermit\ncrabs which they interpret as providing evidence that pain is\nexperienced and remembered by these crustaceans. Varner also expressed\nsome hesitation about the evidence for conscious pain in\n“lower” vertebrates: fish, reptiles and amphibians. Allen\n(2004) argues, however, that subsequent research indicates that the\ndirection of discovery seems uniformly towards identifying more\nsimilarities among diverse species belonging to different taxonomic\nclasses, especially in the domains of anatomy and physiology of the\nnociceptive and pain systems. It is generally accepted that the mammalian pain system has both a\nsensory and an affective pathway, and that these can be dissociated to\nsome degree both pharmacologically (with morphine, e.g.) and surgical\nlesions.  The anterior cingulate cortex (ACC) is a particularly\nimportant structure of the mammalian brain in this regard (Price\n2000).  Allen et al. (2005) and Shriver (2006) argue that\nthis dissociability provides a route to empirical assessment of the\naffective component of animal consciousness, and Farah (2008) uses it\nto distinguish suffering from “mere pain”. Detailed analysis of other taxonomic groups may, however, indicate\nimportant anatomical differences. Rose (2002) argues that because fish\nlack an ACC they may not be bothered by pain.  This is in contrast to\nSneddon et al. (2003) who argue that there is adequate\nbehavioral and physiological evidence to support pain attributions to\nfish.  (See, also, Chandroo et al. 2004 for a review.)  While\nthe ACC is important to mammals, there remains the possibility that\nother taxa may have functionally similar structures, such as the\ncorticoidea dorsolateralis in birds (Atoji & Wild 2005;\nDubbeldam 2009). Genetic knockout animals are also providing further\nclues about the affective aspects of pain (see Shriver 2009 for a\nreview and application of these findings to animal welfare.) \n\nFinally, it is worth noting that a major shift in veterinary practice\nin regards to animal pain has occurred in the past decade.  Whereas\nsurgery on animals was once routinely practiced without analgesics or\nanesthetics, the vast majority of veterinary practitioners now accept\nthe basic premise that veterinarians can be trained to recognize\nanimal pain reliably, and that veterinary patients benefit from the\nsame kinds of pain alleviation treatments that are delivered to\nhumans. It has even been argued that animals possess the\nneurobiological mechanisms responsible for phantom limb pain and\nneuropathic pain (pain in the presence of no obvious tissue damage or\ndisease), and that these conditions may therefore be detectable and\ntreatable in nonhuman animals (Mathews 2008).\n \n\nThe idea of animal emotions is, of course, prominent in Darwin's work\nwith his 1872 book The Expression of the Emotions in Man and\nAnimals.  Willingness to see animals as emotional beings (and\nhumans, by contrast, as endowed with rationality that can override the\nemotions) goes back at least to Ancient Greek philosophy. Konrad\nLorenz seems to have held a similar view, echoing Oskar Heinroth's\nstatement that “animals are highly emotional people of very\nlimited intelligence” (Lorenz 1971b, 334). These days it is more\nfashionable to regard emotions as an important component of\nintelligence.  Regardless of the merits of that view, the scientific\nstudy of animal emotions has gained its own momentum.  Early in the\n20th century, although they are not arguing for or about animal\nconsciousness, physiologists recognized that significance of emotion\nin animal behavior. Dror (1999) explains how the emotional state of\nanimals was considered to be a source of noise in physiological\nexperiments at that time, and researchers took steps to ensure that\nanimals were calm before their experiments.  According to Dror,\nalthough physiologists were forced to deal with the problem of\nemotional noise, attempts to treat emotion as a subject of study in\nits own right never crystallized to the extent of generating a journal\nor other institutional features (Dror 1999, 219).  More recently, Jaak Panksepp (2004, 2005) has been conducting a\nresearch program that he calls “affective neuroscience”\nand that encompasses direct study of animal emotions (2004),\nexemplified for example in the experimental investigation of rats\n“laughing” and seeking further contact in response to\ntickling by humans (Panksepp & Burgdorf 2003). Over several\ndecades, his work (reviewed in Panksepp 2005) has elucidated the\nneuro- and molecular-physiological bases of several ‘core\nemotional systems’ including ‘seeking’,\n‘fear’, ‘rage’, ‘lust’,\n‘care’, ‘play’, and\n‘panic’. Panksepp argues that these are shared by all\nmammals, and may be more widely shared among vertebrates.  \nSufka et al. (2009) have proposed that animal models of\nneuropsychiatric disorders may also support the experimental\ninvestigation of animal emotions. Although depending on a more\nanecdotal, non-experimental approach, Smuts (2001) and Bekoff (2007)\neach defend the attribution of conscious emotions to animals from a\nscientist's perspective. Bekoff has made much of play behavior as an\nindicator of animal emotions, an idea that is also taken up by Cabanac\net al. (2009).  \n\nEmpathy in animals is also a topic of current investigation (e.g.,\nPreston & de Waal 2002). Langford et al. (2002) argue for\nempathy in mice based on experiments in mice who observe a cagemate\ngiven a noxious stimulus, or in pain, are more sensitive to painful\nstimuli than control mice who observe an unfamiliar mouse similarly\ntreated. Byrne et al. (2008) argue for empathy in elephants\nas an inference to the best explanation of various capacities, such as\ndiagnosing animacy and goal directedness, and assessing the physical\nabilities and emotional states of other elephants when these different\nfrom their own.  It is worth noting that almost all of the work, both theoretical\nand empirical, on animal emotions has limited its scope to mammals, or\nat least amniotes (For a notable recent exception, see Mendl et\nal. 2011). This work has exploited certain deep homologies of,\ne.g. brain structure and molecular neurophysiology (focusing\nespecially on hormones and neurotransmitters) in making arguments that\nanimals in these taxanomic groups share our emotions because they\nshare the mechanisms of our own emotions (as well as behaviors that\ntend to indicate emotions in us, and bear the same relations to the\nunderlying physiological mechanisms). This approach is not available\nto animals which are very distantly related to us,\ni.e. invertebrates. The ancestors of vertebrates split off from the\nrest of the animal phyla at a time when all animals were still\nrelatively simple, in terms of structure, tissue types, number of\nneurons, bodily capacities for locomotion and other forms of\nbehavior. The elaboration of complex physiological systems occurred\nindependently in the various phyla. Therefore the physiological\nsystems underlying emotions in other phyla — if these exist\n— may be very different, and hence difficult to identify, either\nin terms of direct physiological observations or in terms of\nobservations of behavioral expressions of emotion. It is also possible\nthat the repertoire of emotions in other phyla might be different,\nfurther problematizing the task of individuating non-vertebrate\nemotions. (Further discussion and additional scientific references for\nthe topic of emotions and empathy in animals can be found in the\n section on emotions and empathy in the entry on \n animal cognition.) \n\nThe idea that careful psychophysical work with could help us\nunderstand the nature of their subjective experiences of the world can\nbe traced at least to Donald Griffin's experimental tests of the\nlimits of bat echolocation. It is also behind the idea that knowing\nthat horses have near 360° vision, or that raptors have two fovea\non each retina, may tell us something about the nature of their\nexperiences — how the world appears to them — if it is\ngranted that they have such experiences. Neural investigation adds a\nfurther layer of analysis to scientific understanding of the nature of\nperception. For instance, Leopold & Logothetis (1996) used neural\ndata to support inferences about the percepts of monkeys under\nconditions of binocular rivalry (see also: Myserson et\nal. 1981; Rees et al. 2002). And Leopold et\nal. (2003) argue that neural recordings can be used to\ncorroborate the non-verbal “reports” of monkeys shown\nambiguous visual stimuli.  (Think here of whether it is possible for\nthe monkey to report that it is subject to Gestalt switches like those\narising from ambiguous figures such as the duck-rabbit or figure-vase\nillusions.)  The phenomenon of blindsight, a form of unconscious visual\nperception that arises with damage to specific areas of primary visual\ncortex, has also been investigated in surgically lesioned monkeys\n(Stoerig & Cowey 1997), with a close correspondence between the\nmonkeys' deficits and those of the human patients vis-à-vis\nparts of the visual field that can be processed only unconsciously,\nand those for which the patients retain consciousness. The non-verbal\napproach to assessing visual awareness has been further validated by\nStoerig et al. (2002).  Blindsight subjects, both human and monkey, do\nnot spontaneously respond to things presented to their scotomas (areas\nwhere they are visually unaware), but must be trained to make\nresponses using a forced-response paradigm (Stoerig & Cowey\n1997).  \n\nThe emphasis on visual perception in most of these examples, no doubt\nreflects a primatocentric bias.  We human primates are highly visual\ncreatures, and, as Nagel (1974) argued, we face considerable hurdles\nin imagining (again, a visual metaphor) the subjective experiences of\ncreatures in modalities in which humans are weak or completely\nunendowed. The examples of research also reflect an anthropocentric\nbias in that much of the animal experimentation is explicitly targeted\nat relieving human disorders. Although there is good work by\nneuroethologists on the psychophysics of echolocation by bats and\ndolphins, or on the sensory capacities of weakly electric fish,\nquestions of subjective awareness are generally not broached in that\nliterature. \n\nAs with the investigation of animal pain, fine-grained analysis of the\nneural correlates of consciousness may reveal subtle differences\nbetween different species.  For instance, Rees et al. (2002)\nreport that while the behavior of rhesus monkeys is rather similar to\nhumans under conditions of binocular rivalry, “the firing of\nmost cells in and around V1 primarily reflects stimulus properties\nrather than the conscious percept reported by the animal ... However,\nseveral neuroimaging studies in humans have presented evidence that\nargues for a stronger role of V1 in binocular rivalry and hence, by\nimplication, visual awareness.” Nevertheless, it is noteworthy\nthat they take the behavioral evidence to be unproblematically\ndescribable as report of a conscious percept by the monkey. \nA debate has unfolded in the literature over whether other animals,\nlike humans, are capable of thinking about past and future\nevents. Suddendorf and Corballis (1997, 2007) have argued that\nso-called ‘Mental Time Travel’ is unique to humans, and\nindeed plays a major role in explaining what is cognitively unique\nabout humans, including capacities for language and culture.\n\nMany mammals, birds and fish exhibit behavior such as food caching,\nnest building, tool use, or migration that seems to suggest\nforesight. For example, tayras — a members of the weasel family\nfound in Central and South America — hide bunches of bananas\ninside of bromeliads, recovering them only when the bananas are ripe\n(Soley et al. 2011). Skeptics are quick to point out that many of\nthese examples may be either a) ‘instinctive’ fixed-action\npatterns shaped by natural selection or b) the result of classical or\noperant conditioning, rather than behavior that is mediated by\n‘cognitive’ processes such as episodic memory, insight, or\nunderstanding. However, the novelty, flexibility and ability to make\nsituation-specific adjustments often calls such dismissals into\nquestion. For example, tayras cache several species of bananas, and\naccurately judge for bananas of each species when the banana is mature\nenough to continue ripening once picked. This includes domestic\nbananas, to which tayras have not been exposed over evolutionary\ntime-scales (Soley et al. 2011).   A variety of careful\nexperimental work with animals shows impressive abilities for\nintegrated what-where-when memory — the ability to recall\ndetails of an event together with its location and time. This work was\npioneered by Clayton and colleagues with scrub jays, focusing on their\ncaching behavior — wherein the birds bury food and later recover\nit (Clayton et al. 2003). For example, if scrub jays are prevented\nfrom recovering their caches for long enough, they will recover only\nnonperishable items (peanuts, in the study), ignoring their caches of\notherwise preferred but perishable food (mealworms, in the study)\n(Clayton et al. 2003). Recent work has also documented what is\nreferred to as ‘episodic-like memory’ in rats (Crystal\n2009), and the apparent ability to plan for the future (including in\nnovel ways that are not plausible ruled out as ‘mere\ninstinct’) in several animals, including nonhuman primates,\nbirds, rats and other mammals (Feeney et al. 2011 for an example of\nrecent experimental work; see Roberts 2012 for a review and\ndiscussion).   This debate has been somewhat complicated by the fact that\nproponents of the human-uniqueness of mental time travel tend to rely\non descriptions of the ability that are laden with researchers' and\nsubjects' phenomenological, introspective or intuitive descriptions of\nthe way their own minds work (e.g. Tulving 1985; Suddendorf and\nCorbalis 2007), whereas animal behavior researchers must rely on\nstrict standards of behavioral evidence to support their\nclaims. Animal behavior researchers are typically circumspect in their\ninterpretations, limiting their claims to operationalizable terms such\nas ‘what-where-when’ memory, or\n‘episodic-like’ memory, rather than making claims about\nthe nature of the experience that may be involved in an animal's\nperforming a task.  The situation may therefore represent a double\nstandard in the interpretation of evidence about human and nonhuman\nanimal subjects, with researchers uncritically making liberal\nassumptions about human cognition that would not be allowed for animal\nresearchers — an example of what Buckner (2013) has called\n‘anthropofabulation’. The question of to what extent, and\nin what ways, humans' awareness of time differs from that of other\nanimals remains an open one, and an active line of research.  \n\nSystematic study of self-consciousness and theory of mind in nonhuman\nanimals has roots in an approach to the study of self-consciousness\npioneered by Gallup (1970).  Gallup's rationale for linking\nmirror-self recognition to self-awareness has already been discussed\nabove.  The idea for the experiment came from observations well-known\nto comparative psychologists that chimpanzees would, after a period of\nadjustment, use mirrors to inspect their own images.  Gallup used\nthese observations to develop a widely-replicated protocol that\nappears to allow a scientific determination of whether it is merely\nthe mirror image per se that is the object of interest to the\nanimal inspecting it, or whether it is the image qua proxy for the\nanimal itself that is the object of interest. Taking chimpanzees who\nhad extensive prior familiarity with mirrors, Gallup anesthetized his\nsubjects and marked their foreheads with a distinctive dye, or, in a\ncontrol group, anesthetized them only. Upon waking, marked animals who\nwere allowed to see themselves in a mirror touched their own foreheads\nin the region of the mark significantly more frequently than controls\nwho were either unmarked or not allowed to look into a mirror.  Although it is typically reported that chimpanzees consistently\n“pass” the mirror-mark test, a survey of the scientific\nliterature by Shumaker & Swartz (2002) indicates that of 163\nchimpanzees tested, only 73 showed mark-touching behavior (although\nthere was considerable variation in the age and mirror experience\namong these animals). Shumaker & Swartz also report mark-touching\nbehavior in 5 of 6 tested orang utans and 6 of 23 gorillas. They\nsuggest that the lower incidence of mark touching by gorillas may be\ndue to avoidance of socially-significant direct eye contact. \nFor non-human primates outside the great apes, the evidence for mirror\nself-recognition has been sparse.  Gallup himself regards it as a\nphenomenon restricted to the great apes only, and he was among the\nfirst to challenge Hauser's report that cotton top tamarins engaged in\nmirror-guided self-directed behaviors after their distinctive white\ntufts had been dyed neon colors, a stimulus that Hauser and coauthors\nargued was presumably more salient than the red dot used by Gallup\n(Hauser et al. 1995).  Faced with Gallup's challenge, Hauser\nhimself was unable to replicate his initial results (Hauser et\nal. 2001).  However, the idea that Gallup's protocol uses a\nstimulus that is not particularly salient to monkeys continues to have\nsome currency. For example, Rajala et al. (2010) have\npresented quantitative and videographic evidence that rhesus monkeys\nwith surgical implants in their heads use mirrors to inspect the\nimplants, as well as other parts of their bodies that they cannot\nusually see. \n\nModified versions of Gallup's experiment have also been conducted with\nnon-primate species. Notoriously, Epstein et al. (1981)\ntrained pigeons to peck at a mark on their own bodies that was visible\nonly in a mirror, and they used this to call into question the\nattribution of “self-awareness” on the basis of the\nmirror-mark test, preferring an associative learning\nexplanation. Gallup et al. (2002) reject the claimed\nequivalence, pointing out that chimpanzees were not trained to touch\nmarks before the test was administered. Reiss & Marino (2001) have\noffered evidence of mirror self-recognition in bottlenose\ndolphins. Using a modified version of Gallup's procedure that involved\nno anesthesia, they inferred self-recognition from bodily contortions\nin front of the mirror (self-touching being anatomically impossible\nfor dolphins). This evidence has been disputed (e.g. Wynne 2004). The\nmirror-mark test continues to be an area of active investigation in\nvarious species including elephants (Plotnik et al. 2006) and\nmagpies (Prior et al. 2008).  Various commentators have\npointed out that the mirror test may not be entirely fair for species\nwhich depend more heavily on senses other than vision (Mitchell 2002;\nBekoff and Burghardt 2002).  An intriguing line of research into animals' knowledge of their own\nmental states considers the performance of animals in situations of\ncognitive uncertainty.  When primates and dolphins are given a\n“bailout” response allowing them to avoid making difficult\ndiscriminations, they have been shown to choose the bailout option in\nways that are very similar to humans (Smith et al. 2003). The\nfact that animals who have no bailout option and are thus forced to\nrespond to the difficult comparisons do worse than those who have the\nbailout option but choose to respond to the test has been used to\nargue for some kind of higher-order self understanding. The original\nexperiments have attracted both philosophical criticism of the\nsecond-order interpretation (e.g. Carruthers 2008) and methodological\ncriticism by psychologists (reviewed by Crystal & Foote 2009),\nalthough alternative approaches to establishing metacognition in\nnon-linguistic animals may be capable of avoiding these criticisms\n(Terrace & Son 2009). In the literature on human cognition, awareness of what one knows\nis called “metacognition” and it is associated with a\n“feeling of knowing”.  Smith and colleagues claim that\ninvestigating metacognition in animals could provide information about\nthe relation of self-awareness to other-awareness (theory of mind),\nand that their results already show that “animals have\nfunctional features of or parallels to human conscious\ncognition” (Smith et al. 2003; Smith 2009).  They also\nraise the question of what this might tell us about the phenomenal\nfeatures of that cognition.  Browne (2004) argues that the dolphin\nresearch cannot support the connection to theory of mind, but that it\nnevertheless is relevant to consciousness in dolphins, particularly\nwithin the theoretical framework provided by Lycan, described\nabove. The notion of metacognition also seems relevant to questions\nabout access consciousness. (For additional discussion of self\nawareness and metacognition, readers are referred to the section on\n theory of mind and\nmetacognition in the entry on \n animal cognition.) An article such as this perhaps raises more questions than it\nanswers, but the topic would be of little philosophical interest if it\nwere otherwise.  \nIt is clear that for many philosophers, the topic of animal\nconsciousness is no longer only of peripheral interest. There is\nincreasing interest in animal cognition from a range of philosophical\nperspectives, including ethics, philosophy of mind, and the philosophy\nof science. Philosophers working in all of these areas are\nincreasingly attentive to the particular details of scientific theory,\nmethods, and results. Many scientists and philosophers believe that\nthe groundwork has been laid for addressing at least some of the\nquestions about animal consciousness in a philosophically\nsophisticated yet empirically tractable way. Yet there remain critics\nfrom both sides: on the one hand are those who still think that\nsubjective phenomena are beyond the pale of scientific research, and\non the other are those who think that science and philosophy have not\nmoved far enough or fast enough to recognize animal consciousness.\nThe arguments on both sides are by no means exhausted.","contact.mail":"colin.allen@pitt.edu","contact.domain":"pitt.edu"},{"date.published":"1995-12-23","date.changed":"2016-10-24","url":"https://plato.stanford.edu/entries/consciousness-animal/","author1":"Colin Allen","author1.info":"http://colinallen.dnsalias.org/","author2.info":"http://indiana.academia.edu/MichaelTrestman","entry":"consciousness-animal","body.text":"\n\n\nQuestions about animal consciousness — in particular, which\nanimals have consciousness and what (if anything) that consciousness\nmight be like — are  both  scientific and\nphilosophical. They are scientific because answering them will require\ngathering information using scientific techniques — no amount of\narm-chair pondering, conceptual analysis, logic, a priori\ntheory-building, transcendental inference or introspection will tell\nus whether a platypus, an iguana, or a squid (to take a few examples)\nenjoy a life of subjective experience — at some point we'll have\nto learn something about the animals. Just what sort(s) of science can\nbear on these questions is a live question, but at the least this will\ninclude investigations of the behavior and neurophysiology of a wide\ntaxonomic range of animals, as well as the phylogenetic relationships\namong taxa. But these questions are deeply philosophical as well, with\nepistemological, metaphysical, and phenomenological\ndimensions. Progress will therefore ultimately require\ninterdisciplinary work by philosophers willing to engage with the\nempirical details of animal biology, as well as scientists who are\nsensitive to the philosophical complexities of the issue.\n\n\n There are many reasons for philosophical interest in nonhuman\nanimal (hereafter “animal”) consciousness:  First, if philosophy often begins with questions about the place\nof humans in nature, one way humans have attempted to locate\nthemselves is by comparison and contrast with those things in nature\nmost similar to themselves, i.e., other animals.  At least in the\nWest, the traditional — and perhaps still intuitive to many\npeople — way of thinking about consciousness is as primarily an\ninnate endowment of humans, which other animals may or may not share\nin virtue of being sufficiently like us. Within the traditional\nBiblical cosmology, while all animals were said to have arisen through\ndivine intentional creation, humans were the only ones created in the\nlikeness of the deity, and thus enjoyed a special, privileged role in\nthe intended workings of the cosmos — including, for example,\naccess to an eternal afterlife not overpopulated with fleas, ants and\nsnails. (See Lewis, 2009 Ch 9 for an in-depth treatment of the problem\nof animal consciousness in relation to Christian theology.) However,\nwithin a modern biological worldview, while humans may be unique in\ncertain (perhaps quite important) respects, we are only one species of\nanimal among many — one tip of one branch of the phylogenetic\ntree of life, and enjoy no particular special status.  From an evolutionary perspective, consciousness is a trait that\nsome animals have (at least humans have it). Salient questions\ninclude: Is it a late evolved, narrowly distributed trait, or an older\nmore broadly shared trait? And, did it evolve only once, or a number\nof times independently? From this view point, the question “Are\n(non-human) animals conscious?” is rather strange, because, for\nexample, it implicitly groups bats together with rabbits (as\n‘nonhuman’ animals) in contrast to humans. In reality,\nrabbits are more closely related to humans than they are to bats\n(Nishihara et al. 2006), so framing the question this way embeds a\nfalse presupposition. Of course, it is consistent with an evolutionary\nperspective that humans are the only conscious animals. This would\nimply that consciousness was acquired through a recent evolutionary\nevent that occurred since the split of our ancestral lineage from that\nof our closest non-human relatives, chimpanzees and bonobos (see\nsection 6 for discussion of such hypotheses). But such a view requires\nsupport; though perhaps intuitive to some, its choice as a default\nposition is arbitrary.  Second, there is a lot at stake morally in the question of whether\nanimals are conscious beings or “mindless automata”. (See\narticle on the Moral Status of Animals.) Many billions of animals are\nslaughtered every year for food, use in research, and other human\npurposes. Moreover, before their deaths, many — perhaps most\n— of these animals are subject to conditions of life that, if\nthey are in fact experienced by the animals in anything like the way a\nhuman would experience them, amount to cruelty. Arguments that\nnon-human animals are not conscious therefore effectively double as\napologetics for our treatment of animals. When the question of animal\nconsciousness is under consideration, our guilt or innocence as a\ncivilization for an enormous body of cruelty may hang in the\nbalance. However, some philosophers have argued that consciousness per\nse does not matter for the treatment of animals, and therefore either\nthat a) even if animals are not conscious, they may deserve moral\nconsideration, or b) even if animals are conscious, they may not\ndeserve moral consideration. (For more discussion of the ethical\nissues, see Singer 1990 [1975]; Regan 1983; Rollin 1989; Varner 1998,\n2012; Steiner 2008.) Third, while theories of consciousness are frequently developed\nwithout special regard to questions about animal consciousness, the\nplausibility of such theories has sometimes been assessed against the\nresults of their application to animal consciousness (and, similarly,\nto human infants). This raises questions about the relative epistemic\nweight of theoretical considerations (e.g. philosophical arguments for\na given theory of consciousness) against particular case judgments or\nintuitions about whether a given creature is conscious. For example,\nSearle (1998) argues that our intuitive, commonsense attributions of\nintentional and emotional states to dogs carries more epistemic weight\nthan philosophically motivated skeptical concerns. In contrast,\nCarruthers (1989) asserts that his own arguments that nonhuman animals\n(even dogs) lack consciousness are sufficiently weighty that we are\nmorally obligated to eradicate or ignore our sympathetic feelings\ntoward such creatures. Should our theories of consciousness be\nconstrained by our intuitive attributions of consciousness to animals\n(or, e.g., babies), or should the former override the latter?\n \n Fourth, the problem of determining whether animals are conscious\n stretches the limits of knowledge and scientific methodology (beyond\n the breaking point, according to some).\n\nThe so-called “cognitive revolution” that took place\nduring the latter half of the 20th century has led to many innovative\nexperiments by comparative psychologists and ethologists probing the\ncognitive capacities of animals.  The philosophical issues surrounding\nthe interpretation of experiments to investigate perception, learning,\ncategorization, memory, spatial cognition, numerosity, communication,\nlanguage, social cognition, theory of mind, causal reasoning, and\nmetacognition in animals are discussed in the entry\non animal cognition. Despite this\nwork on cognition, the topic of consciousness per se in animals has\nremained controversial, even taboo, among many scientists, while other\nscientists from a variety of disciplinary backgrounds\n(e.g. neuroscience, animal behavior, evolutionary biology) have\ndeveloped novel ways of approaching the subject (see Boly et al. 2013 for a review).  The 2012\n Cambridge Declaration on Animal Consciousness \nindicates that many scientists agree that “the weight of evidence\nindicates that humans are not unique in possessing the neurological\nsubstrates that generate consciousness.” However, other scientists,\nincluding Marian Stamp Dawkins, who has been prominent in the science\nof animal welfare (Dawkins 1985, 1993), are not ready to endorse the\nclaim, writing that, “The mystery of consciousness remains. The\nexplanatory gap is as wide as ever and all the wanting in the world\nwill not take us across it” (Dawkins 2012, pp. 171–172).\n \nMany philosophers and scientists have either argued or assumed that\nconsciousness is inherently private, and hence that one's own\nexperience is unknowable to others. While language may allow humans to\ncross this supposed gap by communicating their experience to others,\nthis is allegedly not possible for other animals.  Despite the\ncontroversy in philosophical and scientific circles, it remains a\nmatter of common sense to most people that some animals do have\nconscious experiences. Most people, if asked why they think familiar\nanimals such as their pets are conscious, would point to similarities\nbetween the behavior of those animals and human behavior — for\nexample, animals seem to visibly express pleasure and displeasure and\na variety of emotions, their behavior seems to be motivated by seeking\nfood, comfort, social contact, etc., they seem aware of their\nsurroundings and able to learn from experience. Similarity arguments\nfor animal consciousness thus have roots in common sense\nobservations. But they may also be bolstered by scientific\ninvestigations of behavior and the comparative study of brain anatomy\nand physiology, as well as considerations of evolutionary continuity\nbetween species. Neurological similarities between humans and other\nanimals have been taken to suggest commonality of conscious\nexperience; all mammals share the same basic brain anatomy, and much\nis shared with vertebrates more generally. Even structurally different\nbrains may be neurodynamically similar in ways that enable inferences\nabout animal consciousness to be drawn (Seth et\nal. 2005).   \n\nAs well as generic arguments about the connections among\nconsciousness, neural activity, and behavior, a considerable amount of\nscientific research directed towards understanding particular\nconscious states uses animals as proxies for humans.\nThe reactions of many animals, particularly other mammals, to bodily\nevents that humans would report as painful are easily and\nautomatically recognized by most people as pain\nresponses. High-pitched vocalizations, fear responses, nursing of\ninjuries, and learned avoidance are among the responses to noxious\nstimuli that are all part of the common mammalian heritage, and\nsimilar responses are also observable in organisms from a wide range\nof taxonomic groups (see section 7.1 below). \nMuch of the research that is of direct relevance to the treatment of\nhuman pain, including on the efficacy of analgesics and anesthetics,\nis conducted on rats and other animals. The validity of this research\ndepends on the similar mechanisms\n involved[1]\n and to many it seems arbitrary to deny that injured rats, who respond\nwell to opiates for example, feel\n pain.[2] \nLikewise, much of the basic research that is of direct relevance to\nunderstanding human visual consciousness has been conducted on the\nvery similar visual systems of monkeys.  Monkeys whose primary visual\ncortex is damaged even show impairments analogous to those of human\nblindsight patients (Stoerig & Cowey 1997) suggesting that the\nvisual consciousness of intact monkeys is similar to that of intact\nhumans.  Scientific demonstrations that members of\nother species, even of other phyla, are susceptible to the same visual\nillusions as we are (e.g., Fujita et al. 1991) suggesting\nthat their visual experiences are similar. It is often argued that the use of animals to model\nneuropsychiatric disorders presupposes convergence of emotional and\nother conscious states and further refinements of those models may\nstrengthen the argument for attributing such states to animals. \nAn interesting reversal of the modeling\nrelationship can be found in the work of Temple Grandin, Professor of\nAnimal Science at Colorado State University, who uses her experience\nas a so-called “high-functioning autistic” as the basis\nfor her understanding of the nature of animal experience (Grandin\n1995, 2004). \n\nSuch similarity arguments are, of course, inherently limited in that\nit is always open to critics to exploit some disanalogy\nbetween animals and humans to argue that the similarities don't entail\nthe conclusion that both are sentient. Even when bolstered by\nevolutionary considerations of continuity between the species, the\narguments are vulnerable, for the mere fact that humans have a trait\ndoes not entail that our closest relatives must have that trait too.\nThere is no inconsistency with evolutionary continuity to maintain\nthat only humans have the capacity to learn to play chess. Likewise\nfor consciousness. Povinelli & Giambrone (2000) also argue that\nthe argument from analogy fails because superficial observation of\nquite similar behaviors even in closely related species does not\nguarantee that the underlying cognitive principles are the same, a\npoint that Povinelli believes is demonstrated by his research into how\nchimpanzees use cues to track visual attention (Povinelli 1996).  \n\nPerhaps a combination of behavioral, physiological and morphological\nsimilarities with evolutionary theory amounts to a stronger overall\ncase[3].\n However, a convincing argument will\nlikely also require motivation in terms of a well developed theory of\nthe structure and function of consciousness as a cognitive process\n— a route that many recent participants in the debate on animal\nconsciousness have pursued (see section 6).\n  The term “consciousness” is notoriously ambiguous and\ndifficult to define. Having origins in folk psychology,\n“consciousness” has a multitude of uses that may not be\nresolvable into a single, coherent concept (Wilkes\n1984). Nevertheless, several useful distinctions among different\nnotions of consciousness have been made, and with the help of these\ndistinctions it is possible to gain some clarity on the important\nquestions that remain about animal consciousness. \n\nTwo ordinary senses of consciousness which are not in dispute when\napplied to animals are the sense of consciousness involved when a\ncreature is awake rather than \nasleep[4],\n or in a coma, and the sense of\nconsciousness implicated in the basic ability of organisms to perceive\nand thereby respond to selected features of their environments, thus\nmaking them conscious or aware of those features. Consciousness in\nboth these senses is identifiable in organisms belonging to a wide\nvariety of taxonomic groups (see, e.g., Mather 2008). \n\nA third, more technical notion of consciousness, access consciousness,\nhas been introduced by Block (1995) to capture the sense in which\nmental representations may be poised for use in rational control of\naction or speech.  This “dispositional” account of access\nconsciousness — the idea that the representational content is\navailable for other systems to use — is amended by Block (2005)\nto include an occurrent aspect in which the content is\n“broadcast” in a “global workspace” (Baars\n1997) which is then available for higher cognitive processing tasks\nsuch as categorization, reasoning, planning, and voluntary direction\nof attention.  Block believes that many animals possess access\nconsciousness (speech is not a requirement).  Indeed, some of the\nneurological evidence cited by Block (2005) in support of the global\nworkspace is derived from monkeys. But clearly an author such as\nDescartes, who, we will see, denied speech, language, and\nrationality to animals, would also deny access consciousness to\nthem. Those who follow Davidson (1975) in denying intentional states\nto animals would likely concur. \n\nThere are two remaining senses of consciousness that cause more\ncontroversy when applied to animals: phenomenal consciousness\nand self-consciousness. \n\nPhenomenal consciousness refers to the qualitative,\nsubjective, experiential, or phenomenological aspects of conscious\nexperience, sometimes identified with qualia. (In this article we also\nuse the term “sentience” to refer to phenomenal\nconsciousness.) To contemplate animal consciousness in this sense is\nto consider the possibility that, in Nagel's (1974) phrase, there\nmight be “something it is like” to be a member of another\nspecies. Nagel disputes our capacity to know, imagine, or describe in\nscientific (objective) terms what it is like to be a bat, but\nhe assumes that there is something it is like.   For many authors, Nagel's formulation of phenomenal consciousness\nas “what it's like” serves as a reference point for what's at stake in\nthe debate on animal consciousness — in investigating whether a\ngroup of animals are conscious, the crucial question is whether\nthere is ‘something it is like’ to be those animals,\ni.e. whether there is a subjective experience of life or being for\nthem, a proprietary perspective that individuals have on their own\nperceptual, cognitive and emotive processes.  Though some authors (including Nagel himself) have argued that the\nvery subjectivity of phenomenal consciousness makes it exceedingly\ndifficult or even impossible to investigate scientifically,\nparticularly in other species, others have proceeded by developing\nstructural and/or functional theories of consciousness, and using\nthese to argue for a particular hypothesis about the distribution of\nconsciousness among animals. Such theories will be discussed below, in\nsections 5 and 6. \nSelf-consciousness refers to a subject's awareness of itself,\nbut is also a notoriously ambiguous term — there are importantly\ndistinct senses in which a subject can be self-aware (see for example\nthe SEP article on Phenomenological Approaches to\nSelf-Consciousness). These include: an awareness of one's body as a\nphysical object, or as the medium of one's own perception and action\n(i.e. bodily self-awareness); awareness of one's own mental states\n(i.e. mental or experiential self-awareness); awareness of one-self as\nperceived by others, or as a member of a social group such as a\nfamily, team, or institution (i.e. social self-awareness); awareness\nof one-self as a persistent character in the narratives told by\noneself and others (i.e. narrative self-awareness). This list is far\nfrom exhaustive, and further, each listed notion is subject to\nfurther disambiguation. Hence, although on many theories self-consciousness is\ntightly related to phenomenal consciousness, proposals to this effect\ncan vary greatly in their meaning and their implications for which\nanimals might be conscious. \n\nThe remainder of this article deals primarily with the attribution of\nconsciousness in its phenomenal sense to animals, although there will\nbe some discussion of access consciousness, self-consciousness and\ntheory of mind in animals, especially where these have been related\ntheoretically to phenomenal consciousness — as, for instance, in\nCarruthers' (1998a,b, 2000) argument that a particular sort of mental\nself-representation is required for phenomenal consciousness.  Questions about animal consciousness in the Western tradition have\ntheir roots in ancient discussions about the nature of human beings,\nas filtered through the “modern” philosophy of\nDescartes. It would be anachronistic to read ideas about\nconsciousness from today back into the ancient literature. Nevertheless, because\nconsciousness is sometimes thought to be a uniquely human mental\nphenomenon, it is important to understand the origins of the idea that\nhumans are qualitatively (and “qualia-tatively”) different\nfrom animals. \n\nAristotle asserted that only humans had rational souls, while the\nlocomotive souls shared by all animals, human and nonhuman, endowed\nanimals with instincts suited to their successful reproduction and\nsurvival. Sorabji (1993) argues that the denial of reason to animals\ncreated a crisis for Greek thought, requiring a “wholesale\nreanalysis” (p. 7) of the nature of mental capacities, and a\nrevision in thinking about “man and his place in nature above\nthe animals” (ibid.). The argument about what is reasoning, and\nwhether animals display it, remains with us 25 centuries later, as\nevidenced by the volume Rational Animals? (Hurley & Nudds\n2006). The Great Chain of Being derived from early Christian\ninterpretation of Aristotle's scale of nature (Lovejoy 1936) provides\nanother Aristotelian influence on the debate about animal minds.  Two millennia after Aristotle, Descartes' mechanistic philosophy\nintroduced the idea of a reflex to explain the behavior of nonhuman\nanimals.  Although his conception of animals treated them as\nreflex-driven machines, with no intellectual capacities, it is\nimportant to recognize that he took mechanistic explanation to be\nperfectly adequate for explaining sensation and perception —\naspects of animal behavior that are nowadays often associated with\nconsciousness. He drew the line only at rational thought and\nunderstanding. Given the Aristotelian division between instinct and\nreason and the Cartesian distinction between mechanical reflex and\nrational thought, it's tempting to map the one distinction onto the\nother. Nevertheless, it may be\na mistake to assimilate the two. First, a number of authors before and\nafter Darwin have believed that conscious experience can accompany\ninstinctive and reflexive actions. Second, the dependence of\nphenomenal consciousness on rational, self-reflective thought is a\nparticularly strong and contentious claim (although it has current\ndefenders, discussed below).  Although the roots of careful observation and experimentation of\nthe natural world go back to ancient times, study of animal behavior\nremained largely anecdotal until long after the scientific\nrevolution. Animals were, of course, widely used in pursuit of answers\nto anatomical, physiological, and embryological questions. Vivisection\nwas carried out by such ancient luminaries as Galen and there was a\nresurgence of the practice in early modern times (Bertoloni Meli\n2012). Descartes himself practiced and advocated vivisection\n(Descartes, Letter to Plempius, Feb 15 1638), and wrote in\ncorrespondence that the mechanical understanding of animals absolved\npeople of any guilt for killing and eating animals. Mechanists who\nfollowed him (e.g. Malebranche) used Descartes' denial of reason and a\nsoul to animals as a rationale for their belief that animals were\nincapable of suffering or emotion, and did not deserve moral\nconsideration — justifying vivisection and other brutal\ntreatment (see Olson 1990, p. 39–40, for support of this claim). The\nidea that animal behavior is purely reflexive may also have served to\ndiminish interest in treating behavior as a target of careful study in\nits own right.  A few glimmers of experimental approaches to animal behavior can\nbe seen in the late 18th century (e.g., Barrington 1773; White 1789),\nand soon thereafter Frédéric Cuvier worked from 1804\nuntil his death in 1838 on the development of sexual and social\nbehavior in captive mammals. By the mid 19th century Alfred Russel\nWallace (1867) was arguing explicitly for an experimental approach to\nanimal behavior, and Douglas Spalding's (1872) experiments on\ninstinctual feeding behaviors in chicks were seminal. Still, the\nemergence of experimental approaches had very little to say about\nconsciousness per se, though Spalding's work can be seen as a\ncontribution to the discussion about instinct and reason. \n\nIn the same vein of instinct vs. reason, Darwin in the Origin of\nSpecies wrote, “It is a significant fact, that the more the\nhabits of any particular animal are studied by a naturalist, the more\nhe attributes to reason, and the less to unlearnt instinct”\n(1871, Book I, p.46). He devoted considerable attention in both the\nOrigin and in the Descent of Man to animal behavior,\nwith the obvious goal of demonstrating mental continuity among the\nspecies. To make his case, Darwin relied heavily on anecdotes provided\nby his correspondents — a project infamously pursued after\nDarwin's death by his protégé George Romanes\n(1882). Darwin also carried out experiments and was a keen observer,\nhowever. In his final work he describes experiments on the flexibility\nof earthworm behavior in manipulating leaves, which he took to show\nconsiderable intelligence (Darwin 1881; see also Crist 2002).  The idea of behavioral flexibility is central to discussions of\nanimal mind and consciousness. Descartes' conception of animals as\nautomata seems to make phenomenal consciousness superfluous at best\n— a connection whose philosophical development was traced by\nT.H. Huxley (1874).  Huxley reported a series of experiments on a\nfrog, showing very similar reflexive behavior even when its spinal\ncord had been severed, or large portions of its brain removed. He\nargued that without a brain, the frog could not be conscious, but\nsince it could still do the same sort of things that it could do\nbefore, there is no need to assume consciousness even in the presence\nof the entire brain, going on to argue that consciousness is\nsuperfluous. (The argument is somewhat curious since it seems to show\ntoo much by making the brain itself superfluous to the frog's\nbehavior!) \n\nStill, for those (including Huxley) who became quickly convinced of\nthe correctness of Darwin's theory of evolution, understanding and\ndefending mental continuity between humans and animals loomed\nlarge. In his Principles of Psychology (1890), William James\npromoted the idea of differing intensities of conscious experience\nacross the animal kingdom, an idea that was echoed by the leading\nBritish psychologist of his day, Conwy Lloyd Morgan in his 1894\ntextbook An Introduction to Comparative Psychology. Morgan\nhad been very skeptical and critical of the anecdotal approach favored\nby Darwin and Romanes, but he came around to the Darwinian point of\nview about mental continuity if not about methodology.  To address the\nmethodological deficit he introduced his “double\ninductive” method for understanding the mental states of animals\n(Morgan 1894). The double induction consisted of inductive inferences\nbased on observation of animal behavior combined with introspective\nknowledge of our own minds. At the same time, to counteract the\nanthropomorphic bias in the double inductive method, Lloyd Morgan\nintroduced a principle now known as Morgan's canon: “in no case\nmay we interpret an action as the outcome of the exercise of a higher\npsychical faculty, if it can be interpreted as the outcome of the\nexercise of one which stands lower in the psychological scale”\n(Lloyd Morgan 1894, p.53). \n Lloyd Morgan's Double Induction Method from his 1894 textbook  Even though the double inductive method is now mainly of\nhistorical interest, Morgan's canon lives on.  Questions about quite\nwhat the canon means and how to justify it are active topics of\nhistorical and philosophical investigation (e.g., Burghardt 1985;\nSober 1998, 2005, 2012; Radick 2000; Thomas 2001 (Other Internet\nResources), Fitzpatrick 2008). The questions include what Lloyd Morgan\nmeans by ‘higher’ and ‘lower’, to what extent\nthe principle can or should be justified by evolutionary\nconsiderations, and whether the canon collapses to a principle of\nparsimony, a version of Ockham's razor, or some general principles of\nempirical justification. Despite current uncertainty about what it\nreally means, Morgan's canon, interpreted (or, perhaps,\nmisinterpreted; Thomas 2001, Other Internet Resources) as a strong\nparsimony principle, served a central rhetorical role for\nbehavioristic psychologists, who sought to eliminate any hint of\nCartesian dualism from comparative psychology.  Behaviorism dominated American psychology in the early part of the\n20th century, beginning with Thorndike's (1911) experiments on animals\nlearning by trial and error to escape from the “puzzle\nboxes” that he had constructed. But even Thorndike's famous\n“law of effect” refers to the animal's “satisfaction\nor discomfort” (1911, p.244). It was with the radical\nanti-mentalism of John B. Watson (1928) and B.F. Skinner (1953), both\nof whom strongly rejected any attempts to explain animal behavior in\nterms of unobservable mental states, that American psychology became\nthe science of behavior rather than, as the dictionary would have it,\nthe science of mind and behavior.   At the same time, things were progressing rather differently in\nEurope, where ethological approaches to animal behavior were more\ndominant.  Ethology is part natural history with an emphasis on\nfieldwork and part experimental science conducted on captive animals,\nreflecting the different styles of its two seminal figures, Konrad\nLorenz and Niko Tinbergen (see Burkhardt 2005). Initially,\n“innate” behaviors were the central focus of Lorenz's\nwork. According to Lorenz, it is the investigation of innate behaviors\nin related species that puts the study of animal behavior on a par\nwith other branches of evolutionary biology, and he demonstrated that\nit was possible to derive the phylogenetic relations among species by\ncomparing their instinctive behavioral repertoires (Lorenz 1971a). In\npursuing this direction, Lorenz and Tinbergen explicitly sought to\ndistance ethology from the purposive, mentalistic, animal psychology\nof Bierens de Haan and the lack of biological concern they detected in\nAmerican comparative psychology (see Brigandt 2005).  Like Lloyd\nMorgan, the ethologists rejected Romanes anecdotal approach, but they\nalso criticized Lloyd Morgan's subjectivist approach. \n\nIn the 1970s, Donald Griffin, who made his reputation taking careful\nphysical measurements to prove that bats use echolocation, made a\nconsiderable splash with his plea for a return to questions about\nanimal minds, especially animal consciousness. Griffin (1978) coined\nthe term “cognitive ethology” to describe this research\nprogram, which is based in naturalistic observations of animal\nbehavior and the attempt to understand animal minds in the context of\nevolution.\n\nFierce criticism of Griffin emerged both from psychologists\nand classically trained ethologists. Griffin\nemphasized behavioral flexibility and versatility as the chief source\nof evidence for consciousness, which he defined as “the\nsubjective state of feeling or thinking about objects and\nevents” (Griffin & Speck 2004, p. 6). In seeing\nsubjectivity, at least in simple forms, as a widespread phenomenon in\nthe animal kingdom, Griffin's position also bears considerable\nresemblance to Lloyd Morgan's. Burghardt reports that\n“considerable discomfort with subjectivism” (Burghardt\n1985, p. 907) arose during the Dahlem conference that Griffin convened\nin an early discipline-building exercise (Griffin 1981). Griffin's\nsubjectivist position, and the suggestion that even insects such as\nhoneybees are conscious, seemed to many scientists to represent a\nlamentable return to the anthropomorphic over-interpretation of\nanecdotes seen in Darwin and Romanes. This criticism may be partly\nunfair in that Griffin does not repeat the\n“friend-of-a-farmer” kinds of story collected by Romanes,\nbut bases his interpretations on results from the more sophisticated\nscientific literature that had accumulated more than a century after\nDarwin (e.g., Giurfa et al. 2001). However, the charge of\nover-interpretation of those results may be harder to avoid.  It is\nalso important to note the role played by neurological evidence in his\nargument, when he concludes that the intensive search for neural\ncorrelates of consciousness has not revealed “any structure or\nprocess necessary for consciousness that is found only in human\nbrains” (Griffin & Speck 2004). This view is widely although\nnot universally shared by neuroscientists. \n\nGriffin's behavior-based methodology for studying animal consciousness\nhas also been dismissed as anthropomorphic (see Bekoff & Allen\n1997 for a survey). But such criticisms may have overestimated the\ndangers of anthropomorphism (Fisher 1990) and many of the critics\nthemselves rely on claims for which there are scant scientific data\n(e.g., Kennedy 1992, who claims that the “sin” of\nanthropomorphism may be programmed into humans genetically).  At the\nsame time, other scientists, whether or not they have explicitly\nendorsed Griffin's program, have sought to expand evolutionary\ninvestigation of animal consciousness to include the neurosciences and\na broad range of functional considerations (e.g., Ârhem et\nal. 2002, and see section 6). Whatever the shortfalls of his\nspecific proposals, Griffin played a crucial role in reintroducing\nexplicit discussions of consciousness to the science of animal\nbehavior and cognition, hence paving the way for modern investigations\nof the distribution and evolutionary origins of consciousness.   The topic of consciousness in nonhuman animals has been primarily\nof epistemological interest to philosophers of mind. Two central\nquestions are: \nIn his seminal paper “What is it like to be a bat?” Thomas\nNagel (1974) simply assumes that there is something that it\nis like to be a bat, and focuses his attention on what he argues is\nthe scientifically intractable problem of knowing what it is\nlike. Nagel's confidence in the existence of conscious bat experiences\nwould generally be held to be the commonsense view and, as the\npreceding section illustrates, a view that is increasingly taken for\ngranted by many scientists too. But, as we shall see, it is subject to\nchallenge and there are those who would argue that the Distribution\nQuestion is just as intractable as the Phenomenological Question. The two questions might be seen as special cases — or,\nalternatively, as generalized versions — of the skeptical\n“problem of other minds” — how can one know that\nothers have mental states that are anything like one's own?  Although\nthere is no generally accepted solution to this problem, it is\nnevertheless generally ignored to good effect by psychologists, and\nindeed by most people, who in practice are willing to take for granted\nthat others have mental states similar to theirs. However it is often\nthought that knowledge of animal minds presents special methodological\ndifficulties. First of all, nonhuman animals cannot describe their\nmental states using language. Although there have been attempts to\nteach human-like languages to members of other species, none has\nreached a level of conversational ability that would solve this\nproblem directly (see Anderson 2004 for a review). Furthermore, except\nfor some language-related work with parrots and dolphins, such\napproaches are generally limited to those animals most like ourselves,\nparticularly the great apes. But there is great interest in possible\nforms of consciousness in a much wider variety of species than are\nsuitable for such research.  More generally, the problem of other\nminds is more acute when applied to nonhuman animals because the\nsimilarities between our behavior and bodies, and those of others\nanimals (which form the basis for ‘analogical’ solutions\nto the problem of other minds) are less exact. As well, the perceptual\naccess to other minds that some have argued defuses the problem of\nother minds is arguably weaker regarding the minds of other animals.\n(Sober (2000) discusses of the problem of other minds within an\nevolutionary framework, and Farah 2008 provides a neuroscientist's\nperspective.)  For many people it seems obvious that familiar animals such as\ndogs and cats have conscious mental lives that include perceptual\nstates, motivational and hedonic states, basic emotions and social\nattachments.  David Hume, known for championing skepticism generally,\nwrote that “no truth appears to me more evident, than that beasts are\nendow'd with thought and reason as well as men” (1888 p 176,\nreproduced in Jamieson 1998). Hume did not provide elaborate\nphilosophical or empirical arguments to this effect — he thought\nit was clear from observation.  As Searle (1998) puts it, \nWhat is the epistemic status of such pretheoretical intuitions (if\nthat is indeed a fair way of describing them)?\n  Defenders of theories that deny consciousness to such animals must\ndeny that such intuitions have any epistemic weight. For example\nDennett (who argues that consciousness is unique to humans), claims\nthat intuitive attributions of mental states are “untrustworthy”, and\npoints out that “it is, in fact, ridiculously easy to induce powerful\nintuitions of not just sentience but full-blown consciousness (ripe\nwith malevolence or curiosity) by exposing people to quite simple\nrobots  made to move in familiar mammalian ways at mammalian speeds\n (1995).” (Emphasis from the original.)  Carruthers (1989) acknowledges that intuitive attributions of\nconsciousness to animals are widespread, and go hand in hand with\nsympathetic attitudes toward animals (e.g. wanting to prevent\nsuffering). However, he argues that these attitudes are incorrect, and\nwe have a moral imperative to purge or at least override them: It should be noted that while Carruthers continues to argue that\nonly humans have consciousness, he has more recently amended his\nethical view, holding that animals may deserve some moral concern\ndespite lacking consciousness (1999). \nA crucial point here is how trustworthy these pretheoretic intuitions\nabout the minds of animals are.  Call Perceptualism the view\nthat there is direct perception of (at least some) mental states of\nothers. What this means is that, at least sometimes, when we observe\nanother in a mental state (e.g. in joy, or in pain) their mental state\nis part of the content of our perception — we perceive the\nmental states of others. In contrast, call inferentialism the\nview that we perceive ‘mere behavior’ and must infer or\nreason to conclusions about mental states. An alternative way of\nframing the issues is in terms of whether or not behavior as we\nperceive it is laden with mental properties. According to\nperceptualism, we (at least sometimes) perceive states of mind\nin behavior — an action (e.g. walking across a room) can\nbe perceivably angry or sad, purposeful or eager or hesitant,\netc. Goals, desires, motivations, emotions, pain or pleasure, and many\nother mental states are manifested in modes of action — though\nthey cannot be reduced to patterns of disposition to behave (this\nwould amount to behaviorism), they are tightly linked to behavior by\nconceptual, constitutive or causal connections that ground perceptual\naccess. Jamieson (1998) argues for perceptualism, pointing out that our\neveryday practices of attributing mental states to nonhuman animals\nare deeply ingrained, automatic, conceptually unifying and empirically\npowerful. Strands of the same point of view can also be found in\nscientists writing about cognitive ethology and in\nWittgensteinian attitudes towards questions of animal mind (e.g.,\nGaita 2003). Perceptualism as a theory of social cognition\n(e.g. empathy) in philosophy of psychology has recently been defended\nby Zahavi (2011) and Gallagher (2008).  The Perceptualism/Inferentialism question is critical for the\ndeciding the epistemic value of common sense attributions of mental\nstates to nonhuman animals. If inferentialism is true, then when I\nsee, e.g., a dog bounding around in front of me with a toy in its\nmouth, wagging its tail and looking at me, then I may consider the\npossibility that the dog wants my attention, that it is feeling\nhappy and playful — but this is only a hypothesis,\nfor which I must provide a solid argument from justified premises if I\nam to justifiably believe it. On a perceptualist account, by contrast,\nI literally see (or at least, seem to see) that the dog wants\nmy attention and feels happy and playful.  Perception is usually understood to ground defeasible epistemic\nwarrant for belief — for example, if you look outside and it\nappears to be raining, you have some grounds to believe that it is\nraining. It is difficult to forgo this assumption without succumbing\nto radical global skepticism, since we base so many of our beliefs on\nperception.  If seeming to perceive something to be the case provides\ndefeasible epistemic warrant for believing it to be the case, than the\nfact the I seem to perceive a dog as being happy and playful warrants\nmy belief that the dog is happy and playful, i.e. warrants my\nascription of mental states to the dog. Given the prima facie\nepistemic support of seeming to perceive mental states in familiar\nanimals like dogs, perceptualists would argue that only overwhelming\nevidence should overturn the common-sense, intuitive attribution of\nmental states to those animals. Whereas, as discussed above,\nCarruthers (1989) argues that because his theory denies consciousness\nto animals, we should strive to eradicate our intuitive attributions\nof consciousness, a perceptualist would respond that the evidence\nderived from our perceptual encounters with dogs is more convincing\nthan his arguments (which hang on the plausibility of his higher order\nthought theory of consciousness; see section 6.1).   Nevertheless, even if we have perceptual access to the mental\nstates of other humans and familiar animals like our pet dogs, there\nare sharp limitations to how far this will get us toward solving the\ngeneral problem of animal consciousness. First of all, our perceptual\naccess may be limited to animals that are familiar, comfortable\ninteracting with humans, and biologically very similar to humans\n(i.e. mammals). It may be much harder to ‘see’ what (if\nanything) a spider or a squid is thinking and feeling as she goes\nabout her business — both because these animals may express\ntheir mental states differently, and more radically because they may\nhave a very different repertoire of mental states.  Second, as argued by Dennett, there are examples where our\nperceptions of mental states can be deceived — so Dennett seems\nto embrace perceptualism, but to hold that perceptions of mental\nstates are particularly unreliable. However, Dennett's favored example\nof the robot\n ‘Cog’,\n unlike nonhuman animals, was\nintentionally designed by human engineers to seem life-like, i.e., to\nmimic the dynamical properties of motion that trigger the perception\nof mindedness. Hence, there may be no more reason to fear that our\nseeming perceptions of mind in others are undermined by such examples\nthan to fear that our perception of objects in space is undermined by\nthe existence of photography — in both cases, human engineers\ncan be characterized as having figured out ways of creating perceptual\nillusions. There are deep questions about how perception of bodies in\nmotion might disclose the mental states of others — just as\nthere are deep questions about how visual perception of objects in\nspace is generally possible. But, pace Dennett, there is no\nclear reason why the existence of carefully crafted illusions\nundermines the general epistemic value of perception.\n  Third, even among scientists who are sympathetic to the idea of\nthemselves as sensitive observers of animals with rich mental lives,\nthere is the recognition that the scientific context requires them to\nprovide a particular kind of empirical justification of mental state\nattributions. This demand requires those who would say that a tiger\npacing in the zoo is “bored”, or that the hooked fish is\nin pain to define their terms, state empirical criteria for their\napplication, and provide experimental or observational evidence for\ntheir claims. Even if perceptualism is a viable theory of folk\npractice with respect to attributing animal consciousness, it seems\nunlikely to make inroads against scientific epistemology.  Many scientists and philosophers remain convinced that even if some\nquestions about animal minds are empirically tractable, no amount of\nexperimentation can provide access to  phenomenal consciousness\n per se. This remains true even among those who are willing to\ninvoke cognitive explanations of animal behavior that advert to\ninternal representations. Opposition to dealing with consciousness can\nbe understood in part as a legacy of behavioristic psychology first\nbecause of the behaviorists' rejection of terms for unobservables\nunless they could be formally defined in terms of observables, or\notherwise operationalized experimentally, and second because of the\nstrong association in many behaviorists' minds between the use of\nmentalistic terms and the twin bugaboos of Cartesian dualism and\nintrospectionist psychology. In some cases\nthese scientists are even dualists themselves, but they are strongly\ncommitted to denying the possibility of scientifically investigating\nconsciousness, and remain skeptical of all attempts to bring it into\nthe scientific mainstream. Also important has been a line of argumentation by philosophers\nthat the subjective nature of consciousness makes it inherently\ndifficult to study. Block's (1995) influential distinction between\nphenomenal and access consciousness was framed as part of a critique of\ntreatments of consciousness in the psychological literature: by\nfailing to properly distinguish between consciousness as experience\n(phenomenal consciousness) and consciousness as general availability\nof information (access consciousness), scientists were equivocating\n— drawing conclusions about consciousness in the phenomenal\nsense from premises about consciousness in the access sense. The\nconceptual distinction between access consciousness and phenomenal\nconsciousness, and the difficulty of gaining empirical traction on the\nlatter, has been seen as a major hurdle to empirical consciousness\nstudies. Block himself has recently been more optimistic, even arguing\nthat certain experiments can empirically tease apart phenomenal and\naccess consciousness (Block 2011). But the distinction between access\nand phenomenal consciousness does raise special methodological hurdles\nfor those who want to study the latter empirically. \n\nBecause consciousness is assumed to be private or subjective, it is\noften taken to be beyond the reach of objective scientific methods\n(e.g., Nagel 1974). This claim might be taken in either of two\nways. On the one hand it might be taken to bear on the possibility of\nanswering the Distribution Question, i.e., to reject the possibility\nof knowledge that a member of another taxonomic group (e.g., a bat)\nhas conscious states. On the other hand it might be taken to bear on\nthe possibility of answering the Phenomenological Question, i.e., to\nreject the possibility of knowledge of the phenomenological details of\nthe mental states of a member of another taxonomic group. The\ndifference between believing with justification that a bat is\nconscious and knowing what it is like to be a bat is\nimportant because, at best, the privacy of conscious experience\nsupports a negative conclusion only about the latter. To support a\nnegative conclusion about the former, one must also assume that\nconsciousness has absolutely no measurable effects on behavior, i.e.,\none must accept epiphenomenalism.\nBut if one rejects epiphenomenalism and maintains that consciousness\ndoes have effects on behavior then a strategy of inference to the best\nexplanation may be used to support its attribution. Moreover, if\nparticular conscious states have particular effects on behavior, then\nthis strategy might be pursued to elucidate some specific features of\nthe conscious experience of other animals, even if some aspects must\nremain out of reach because of our inability, as humans, to fully\ngrasp what it would be like to experience them. More will be said\nabout this in the next section. \n\nIf phenomenal consciousness is completely epiphenomenal, as some\nphilosophers believe, then a search for the functions of consciousness\nis doomed to futility. In fact, if consciousness is completely\nepiphenomenal then it cannot have evolved by natural selection. On the\nassumption that phenomenal consciousness is an evolved characteristic\nof human minds, at least, and therefore that epiphenomenalism is\nfalse, then an attempt to understand the biological functions of\nconsciousness may provide the best chance of identifying its\noccurrence in different species. (See Robinson 2007 for more\ndiscussion of this issue.) \n\nWhile epistemological and related methodological issues have been at\nthe forefront of discussions about animal consciousness, philosophical\nattention to consciousness in the analytic tradition over the last\nseveral decades has focused on metaphysical questions about the nature\nof phenomenal consciousness and its fit (or lack thereof) within a\nnaturalistic framework. One might think that the question of what consciousness is\n(metaphysically) should be settled prior to tackling the Distribution\nQuestion — that ontology should drive the epistemology.\nHowever, the metaphysical questions that have occupied analytic\nphilosophers over the last few decades are largely orthogonal to the\ndistribution problem, which depends more on questions about the\nstructure and function of consciousness, discussed\nbelow.  The traditional ‘Mind Body Problem’ concerns the the\nmetaphysical status of mind in relation to the physical world (see SEP\narticle on dualism). Dualists argue that the\nmental and physical are fundamentally distinct, whereas physicalists\nhold that the mind is physical — and therefore not distinct,\ndespite supposed appearances to the contrary. A third alternative is\nidealism, the view that the physical world is actually mental (and\ntherefore that the two are not really distinct). Dualistic theories of consciousness typically deny that it can be\naccounted for in the current terms of the natural\nsciences. Traditional dualists may argue that the reduction of\nconsciousness to physically describable mechanisms is impossible on\nany concept of the physical.  Others may hold that consciousness is an\nas-yet-undescribed fundamental constituent of the physical universe,\nnot reducible to any known physical principles. Such accounts of\nconsciousness (with the possible exception of those based in\nanthropocentric theology) provide no principled reasons, however, for\ndoubting that animals are conscious.  Cartesian dualism is, of course, traditionally associated with the\nview that animals lack minds. Descartes' argument for this view was\nnot based, however, on any ontological principles, but upon what he\ntook to be the failure of animals to use language rationally, or to\nreason generally. On this basis he claimed that nothing in animal\nbehavior requires a non-mechanistic, mental explanation; hence he saw\nno reason to attribute possession of mind to animals.  In a sense,\ntherefore, the Cartesian argument for the human-uniqueness of\nconsciousness rests on the premise that material processes are\ninsufficient to account for human capacities for language,\nrationality, and self-awareness (i.e. the awareness of oneself as,\nputatively, an essentially thinking thing) — and hence a\nnon-material soul was posited to account for these phenomena.  Few\ntoday would hold that material processes are incapable of producing\ncomplex phenomena such as language and rationality, and indeed our\nunderstanding of ‘the material’ has changed dramatically\nsince Descartes' time. However, the subjective nature of consciousness\ncontinues to motivate some authors to argue that mental phenomena\ncannot be reduced to physical phenomena. \nThere is no conceptual reason why animal bodies are any less suitable\nvehicles for embodying a Cartesian soul, or any other of the\nputatively non-physical aspects of mind posited by proponents of\ndualism, than are human bodies. Hence, dualism does not preclude\nanimal minds as a matter of conceptual necessity. The distribution of\nconsciousness is a matter of empirical contingency on dualist theories\nas for physicalist theories. For some dualists, this may come down to\nwhether or not the animals in question possess specific cognitive\ncapacities, although others may argue that the non-physical nature of\nthe mental makes it difficult or impossible to investigate\nempirically.  \n\nEarly physicalist accounts of consciousness explored the philosophical\nconsequences of identifying consciousness with unspecified physical or\nphysiological properties of neurons.  In this generic form, such\ntheories do not provide any particular obstacles to attributing\nconsciousness to animals, given that animals and humans are built upon\nthe same biological, chemical, and physical principles.  If it could\nbe determined that phenomenal consciousness was identical to (or at\nleast perfectly correlated with) some general property such as quantum\ncoherence in the microtubules of neurons, or brain waves of a specific\nfrequency, then settling the Distribution Question would be a\nstraightforward matter of establishing whether or not members of other\nspecies possess the specified properties. Searle (1998) too, although\nhe rejects the physicalist/dualist dialectic, also suggests that\nsettling the Distribution Question for hard cases like insects will\nbecome trivial once neuroscientists have carried out the non-trivial\ntask of determining the physiological basis of consciousness in\nanimals for which no reasonable doubt of their consciousness can be\nentertained (i.e., mammals).  \nSome philosophers have sought more specific grounding in the\nneurosciences for their accounts of consciousness.  Block (2005)\npursues a strategy of using tentative functional characterizations of\nphenomenal and access consciousness to interpret evidence from the\nsearch by neuroscientists for neural correlates of consciousness. He\nargues, on the basis of evidence from both humans and monkeys, that\nrecurrent feedback activity in sensory cortex is the most plausible\ncandidate for being the neural correlate of phenomenal consciousness\nin these species.  Prinz (2005) also pursues a neurofunctional\naccount, but identifies phenomenal consciousness with a different\nfunctional role than Block.  He argues for identifying phenomenal\nconsciousness with brain processes that are involved in attention to\nintermediate-level perceptual representations which feed into working\nmemory via higher level, perspective-invariant representations. Since\nthe evidence for such processes is at least partially derived from\nanimals, including other primates and rats, his view is supportive of\nthe idea that phenomenal consciousness is found in some nonhuman\nspecies (presumably most mammals). Nevertheless, he maintains that it\nmay be impossible ever to answer the Distribution Question for more\ndistantly related species; he mentions octopus, pigeons, bees, and\nslugs in this context. \n\nRepresentational theories of consciousness\n link phenomenal consciousness with the\nrepresentational content of mental states, subject to some further\nfunctional criteria.   \nFirst-order representationalist accounts hold that if a particular\nstate of the visual system of an organism represents some property of\nthe world in a way that is functionally appropriate (e.g., not\nconceptually mediated, and operating as part of a sensory system),\nthen the organism is phenomenally conscious of that\nproperty. First-order accounts are generally quite friendly to\nattributions of consciousness to animals, for it is relatively\nuncontroversial that animals have internal states that have the\nrequisite functional and representational properties (insofar as\nmental representation itself is uncontroversial, that is). Such a view\nunderlies Dretske's (1995) claim that phenomenal consciousness is\ninseparable from a creature's capacity to perceive and respond to\nfeatures of its environment, i.e., one of the uncontroversial senses\nof consciousness identified above. On Dretske's view, phenomenal\nconsciousness is therefore very widespread in the animal kingdom.\nLikewise, Tye (2000) argues, based upon his first-order\nrepresentational account of phenomenal consciousness, that it extends\neven to honeybees.   Driven by a variety of allegedly counter-intuitive consequences of\nfirst-order theories of consciousness, including skepticism about the\nrange of organisms it spans, a number of philosophers have offered a\nvariety of higher-order accounts of phenomenal consciousness. Such\naccounts invoke mental states directed towards other mental states to\nexplain phenomenal consciousness.  Carruthers' “higher order\nthought” (HOT) theory is that a mental state is phenomenally\nconscious for a subject just in case it is available to be thought\nabout directly by that subject (Carruthers 1998a,b, 2000). The term\n“available” here makes this a\n“dispositionalist” account. The contrast is an\n“actualist” account, which requires the actual occurrence\nof the 2nd order thought for subject to be conscious in the relevant\nsense. According to Carruthers, such higher-order thoughts are not\npossible unless a creature has a “theory of mind” to\nprovide it with the concepts necessary for thought about mental\nstates. Carruthers' view is of particular interest in the current\ncontext because he has used it explicitly to deny phenomenal\nconsciousness to (almost) all nonhuman animals.  \nCarruthers argues, there is little, if any, scientific support for\ntheory of mind in nonhuman animals, even among the great apes —\nwith the possible exception of chimpanzees — from which he\nconcludes that there is little support either for the view that any\nanimals possess phenomenological consciousness. Further evaluation of\nthis argument will be taken up further below, but it is worth noting\nhere that if (as experiments on the attribution of false beliefs\nsuggest) young children before the age of four years typically lack a\ntheory of mind, Carruthers' view entails that they are not sentient\neither — fear of needles notwithstanding! This is a bullet\nCarruthers bites, although for many it constitutes a reductio\nof his view (a response Carruthers would certainly regard as\nquestion-begging). \n\nIn contrast to Carruthers' higher-order thought account of\nsentience, other theorists such as Armstrong (1980), and Lycan (1996)\nhave preferred a higher-order experience account, where\nconsciousness is explained in terms of inner perception of mental\nstates, a view that can be traced back to Aristotle, and also to John\nLocke. Because such models do not require the ability to conceptualize\nmental states, proponents of higher-order experience theories have\nbeen slightly more inclined than higher-order theorists to allow that\nsuch abilities may be found in other \nanimals[6].\n Gennaro (2004) argues, however, that a higher order thought theory is\ncompatible with consciousness in nonhuman animals, arguing that\nCarruthers and others have overstated the requirements for the\nnecessary mental concepts and that reentrant pathways in animal brains\nprovide a structure in which higher- and lower-order representations\ncould actually be combined into a unified conscious state.  One metaphysical question that is more directly relevant for the\nquestion of the phylogenetic distribution and evolution of\nconsciousness is whether possessing it (i.e. being conscious) is\nbinary (i.e. on/off, all-or-nothing), or admits of degrees.  Several\nauthors have, for quite different reasons, denied what they take to be\na common but problematic assumption — that “Consciousness is an\non/off switch; a system is either conscious or not,” as Searle —\nwho endorses the thesis puts it (quoted by Lycan 1996, who denies the\nthesis). \n\nLycan argues that consciousness can come in a wide spectrum of degrees\nof richness or fullness of consciousness, and that there is a\nmeaningful sense in which a system with a minimal degree of\nconsciousness is not “really” conscious (1996, p. 8). Admittedly, this\nsounds a bit paradoxical, but the point seems to be that it is\ncounter-intuitive for us to consider very low degrees of\nconsciousness, as it is hard to imagine the contents of very simple\nmental states. One reading of this is that Lycan is arguing that the\npredicate ‘conscious’ is vague, without committing himself\nto the view that consciousness is distributed according to a linear\nscale. \nDennett (1995) also argues that consciousness is not binary. He does\nso in the context of advocating a radically deflationary anti-realism\nabout consciousness overall, on which consciousness is essentially an\nillusion created by language (1991/1995). On his view, “the very idea\nof there being a dividing line between those creatures ‘it is\nlike something to be’ and those that are ‘mere\nautomata’ (is) an artifact of our traditional assumptions.”\n(1995, p. 706)\n  Velmans (2012) distinguishes between ‘discontinuity\ntheories’, which claim that there was a particular point at\nwhich consciousness originated, before which there was no\nconsciousness (this applies both the the universe at large, and also\nto any particular consciousness individual), and ‘continuity\ntheories’, which conceptualize the evolution of consciousness in\nterms of “a gradual transition in consciousness from unrecognizable to\nrecognizable.” He argues that continuity theories are more elegant, as\nany discontinuity is based on arbitrary criteria, and that\ndiscontinuity theories face “the hard problem” in a way that\ncontinuity theories don't. Velmans takes these arguments to weigh in\nfavor of adopting, not just a continuity theory, but a form of\npanpsychism. \nThe three authors described just above deny that consciousness is\nbinary for very different reasons, and each of their views is\ncontroversial. Further, none of them offers much in the way of tools\nor concepts for thinking about the putatively nonbinary nature of\nconsciousness. Following up on Lycan's suggestion of degrees of\nrichness or fullness, one might ask what graded dimensions or\nqualitative thresholds might be available to distinguish different\nkinds of minds? Various authors have distinguished between\n‘primary’ and ‘higher order’ consciousness\n(Seth et al. 2005); ‘primary’, ‘secondary’,\nand ‘tertiary’ consciousness (Panksepp 2005); and\n‘core’ and ‘extended’ consciousness (Damasio\n1999). However, most of these authors seem to correlate phenomenal\nconsciousness, i.e. having any subjective experience at all, with\nprimary or core consciousness. The terms “secondary” and\n“tertiary” are supposed to pick out elaborated forms of\nconsciousness. Hence it is not clear that any of these taxonomies are\nat odds with the idea that phenomenal consciousness itself is binary\n— either wholly present or wholly absent for a given\nsystem. However, the issue deserves more scrutiny, as it bears on the\nproblems of the distribution and evolutionary origins of\nconsciousness. If consciousness is non-binary, then the distribution\nof consciousness will not be sharply bounded, but will include\ngradations — some animals may be partially or incompletely\nconscious.\n \n\nPhenomenal consciousness is just one feature (some would say the\ndefining feature) of mental states or events. Any theory of animal\nconsciousness must be understood, however, in the context of a larger\ninvestigation of animal cognition that (among philosophers) will also\nbe concerned with issues such as intentionality (in the sense\ndescribed by the 19th C. German psychologist Franz Brentano) and\nmental content (Dennett 1983, 1987; Allen 1992a,b). \n\nPhilosophical opinion divides over the relation of consciousness to\nintentionality with some philosophers maintaining that they are\nstrictly independent, others (particularly proponents of the\nfunctionalist theories of consciousness described in this section)\narguing that intentionality is necessary for consciousness, and still\nothers arguing that consciousness is necessary for genuine\nintentionality. Many behavioral\nscientists accept cognitivist explanations of animal behavior that\nattribute representational states to their subjects. Yet they remain\nhesitant to attribute consciousness. If the representations invoked\nwithin cognitive science are intentional in Brentano's sense, then\nthese scientists seem committed to denying that consciousness is\nnecessary for intentionality. \nThere remains great uncertainty about the metaphysics of phenomenal\nconsciousness and its precise relations to intentionality, to the\nbrain, to behavior, etc. It is beyond the scope of this article to\nsurvey the strong attacks that have been mounted against the various\naccounts of consciousness in these terms, but it is safe to say that\nnone of them seems secure enough to hang a decisive endorsement or\ndenial of animal consciousness upon it. Accounts of consciousness in\nterms of basic neurophysiological properties, the quantum-mechanical\nproperties of neurons, or sui generis properties of the\nuniverse are just as insecure as the various functionalist\naccounts. And even those accounts that are compatible with animal in\ntheir general outline, are not specific enough to permit ready answers\nto the Distribution Question in its full generality.  Hence no firm\nconclusions about the distribution of consciousness can be drawn on\nthe basis of the philosophical theories of consciousness that have\nbeen discussed so far.  Where does this leave the epistemological questions about animal\nconsciousness? While it may seem natural to think that we must have a\ntheory of what consciousness is before we try to determine whether\nother animals have it, this may in fact be putting the conceptual cart\nbefore the empirical horse. In the early stages of the scientific\ninvestigation of any phenomenon, putative samples must be identified\nby rough rules of thumb (or working definitions) rather than complete\ntheories. Early scientists identified gold by contingent\ncharacteristics rather than its atomic essence, knowledge of which had\nto await thorough investigation of many putative examples — some\nof which turned out to be gold and some not. Likewise, at this stage\nof the game, perhaps the study of animal consciousness would benefit\nfrom the identification of animal traits worthy of further\ninvestigation, with no firm commitment to idea that all these examples\nwill involve conscious experience.  Recall the Cartesian argument that animals do not use language\nconversationally or reason generally. This argument, based on the\nalleged failure of animals to display certain intellectual capacities,\nis illustrative of a general pattern of using certain\ndissimilarities between animals and humans to argue that\nanimals lack consciousness. \n\nA common refrain in response to such arguments is that, in situations\nof partial information, “absence of evidence is not evidence of\nabsence”. Descartes dismissed parrots vocalizing human words\nbecause he thought it was merely meaningless repetition. This judgment\nmay have been appropriate for the few parrots he encountered, but it\nwas not based on a systematic, scientific investigation of the\ncapacities of parrots. Nowadays many would argue that Pepperberg's\nstudy of the African Grey parrot “Alex” (Pepperberg 1999)\nshould lay the Cartesian prejudice to rest. This study, along with\nseveral on the acquisition of a degree of communicative competence by\nchimpanzees and bonobos (e.g., Gardner et al. 1989;\nSavage-Rumbaugh 1996) would seem to undermine Descartes' assertions\nabout lack of meaningful communication and general reasoning abilities\nin animals. (See, also, contributions to Hurley & Nudds 2006.) \n\nCartesians respond by pointing out the limitations shown by animals in\nsuch studies (they can't play a good game of chess, after all, let\nalone tell us what they are thinking about), and they join linguists\nin protesting that the subjects of animal-language studies have not\nfully mastered the recursive syntax of natural human\nlanguages.[7]\n But this kind of post hoc raising of\nthe bar suggests to many scientists that the Cartesian position is not\nbeing held as a scientific hypothesis, but as a dogma to be defended\nby any means. Convinced by evidence of sophisticated cognitive\nabilities, most philosophers these days agree with Block that\nsomething like access consciousness is properly attributed to many\nanimals.  Nevertheless, when it comes to phenomenal consciousness,\ndissimilarity arguments are not entirely powerless to give some pause\nto defenders of animal sentience, for surely most would agree that, at\nsome point, the dissimilarities between the capacities of humans and\nthe members of another species (the common earthworm Lumbricus\nterrestris, for example) are so great that it is unlikely that\nsuch creatures are sentient. A grey area arises precisely because no\none can say how much dissimilarity is enough to trigger the judgment\nthat sentience is absent. The aim of picking out, in a principled way, behavioral or\nneurophysiological characteristics that could serve as reliable\nindicators for consciousness motivates the structure and function\noriented approach that many authors have pursued since the turn of the\n21st century. Though sometimes pursued along with metaphysical\nquestions about consciousness, this project promises empirical\ntractability even in the face of persistent uncertainty about the\nmetaphysical questions of consciousness. \nOne strategy for bringing consciousness into the scientific fold is to\ntry to articulate a theoretical basis for connecting the observable\ncharacteristics of animals (behavioral or neurological) to\nconsciousness.  What effects should consciousness have on behavior?\nWhat capacities and dispositions should we expect a conscious creature\nto have that might be absent in a nonconscious creature?  What\nneurophysiological structures and processes might realize the dynamics\nor information processing required for consciousness?\n  Such an approach is nascent in Griffin's attempts to force\nethologists to pay attention to questions about animal consciousness,\nin all its senses — including phenomenal consciousness. In a\nseries of books, Griffin (who made his scientific reputation by\ncarefully detailing the physical and physiological characteristics of\necholocation by bats) provides examples of communicative and\nproblem-solving behavior by animals, particularly under natural\nconditions, and argues that these are prime places for ethologists to\nbegin their investigations of animal consciousness (Griffin 1976,\n1984, 1992).  Although he thinks that the intelligence displayed by these\nexamples suggests conscious thought, many critics have been\ndisappointed by the lack of systematic connection between Griffin's\nexamples and the attribution of consciousness (see, e.g., Alcock 1992).\nGriffin's main positive\nproposal in this respect has been the rather implausible suggestion\nthat consciousness might have the function of compensating for limited\nneural machinery.  Thus Griffin is motivated to suggest that\nconsciousness may be more important to honey bees than to humans. \n\nIf compensating for small sets of neurons is not a plausible function\nfor consciousness, what might be? The commonsensical answer would be\nthat consciousness “tells” the organism about events in\nthe environment, or, in the case of pain and other proprioceptive\nsensations, about the state of the body. But this answer begs the\nquestion against opponents of attributing conscious states to animals\nfor it fails to respect the distinction between phenomenal\nconsciousness and mere awareness (in the uncontroversial sense of\ndetection) of environmental or bodily events. Opponents of attributing\nphenomenal consciousness to animals are not committed to denying the\nmore general kind of consciousness of various external and\nbodily events, so there is no logical entailment from awareness of\nthings in the environment or the body to animal sentience. \n\nPerhaps more sophisticated attempts to spell out the functions of\nconsciousness are similarly doomed. But Allen & Bekoff (1997, ch.\n8) suggest that progress might be made by investigating the capacities\nof animals to adjust to their own perceptual errors. Not all\nadjustments to error provide grounds for suspecting that consciousness\nis involved, but in cases where an organism can adjust to a perceptual\nerror while retaining the capacity to exploit the content of the\nerroneous perception, then there may be a robust sense in which the\nanimal internally distinguishes its own appearance states from other\njudgments about the world. (Humans, for instance, have conscious\nvisual experiences that they know are misleading — i.e., visual\nillusions — yet they can exploit the erroneous content of these\nexperiences for various purposes, such as deceiving others or\nanswering questions about how things appear to them.) Given\nthat there are theoretical grounds for identifying conscious\nexperiences with “appearance states”, attempts to discover\nwhether animals have such capacities might be a good place to start\nlooking for animal consciousness. It is important, however, to\nemphasize that such capacities are not themselves intended to be\ndefinitive or in any way criterial for consciousness.\n\nCarruthers (2000) makes a similar suggestion about the function of\nconsciousness, relating it to the general capacity for making an\nappearance-reality distinction; of course, he continues to maintain\nthat this capacity depends upon having conceptual resources that are\nbeyond the grasp of nonhuman animals. \nThe broad issue of function is closely related to questions about just\nwhat sort of mental process consciousness is. As we shall see in the\nnext section, hypotheses in the modern literature on the distribution\nand evolution of consciousness are therefore generally advanced\ntogether with theories of its structure and function in the following\nsenses:\n \nStructure: what are the contents of consciousness (what information,\nrepresentations, intentional contents, properties, processes,\netc. does it include)? What (possibly unconscious or subconscious)\ninformation, representations, or other cognitive or intentional\nprocesses, entities and relations, are required for consciousness?\n \nFunction: how does consciousness relate to other (nonconscious)\nprocesses, in cognition, the body and the environment? How does\npossessing consciousness contribute to an animal's ability to navigate\nand respond adaptively to its environment, to survive and thrive?\n  Different views about what consciousness is, qua cognitive\nprocess, and how it relates to other biological processes such as\nbehavior, development and ecological interaction, largely determine\nbiologically oriented views about which animals have consciousness and\nwhen, how, and why it evolved. To illustrate this, we can start with a\ncrude distinction between views that see consciousness as fundamental\nto the basic perceptual and cognitive processes involved in\ncontrolling an animal body, or as something that can be added on or\nplugged in to a system that is already sufficient for basic control of\nperception-guided action. The more fundamental consciousness is to\nbasic animal functioning, the more widely distributed and ancient\nconsciousness must be; if, however, consciousness is relatively\nmodular, functionally narrow, and conceptually high level, then it\nshould be narrowly distributed among animals and relatively recently\nevolved. The views surveyed in the following section all exploit the\nconnections between function, structure, distribution and evolutionary\norigin.    One further point worth noting is that structural models of\nconsciousness are usually justified in terms of phenomenological or\nintrospective observations — i.e. observations about the nature\nof consciousness as it is experienced by the subject. Though the use\nof such first person methods is now and has been controversial in\npsychology and philosophy throughout the 20th and 21st century, there\nseems to now be a broad acknowledgement that it has an indispensable\nrole in the scientific study of consciousness, as many authors who\nhave published recent scientific theories of consciousness include\nsome appeal to phenomenological premises in justifying their views\n(e.g. Seth, Edelman and Baars 2005; Merker 2005; Tononi 2008; Cabanac\net al. 2009).  A variety of hypotheses have been put forward by scientists and\nphilosophers about which animals are conscious and which are\nnot. These views span a huge range of possibilities, from the\nnarrowest, which is that only humans are conscious, to some authors\narguing that almost all animals, even simple invertebrates, have a\nbasic capacity to experience the world. Some authors have even argued\nthat single-celled organisms (Margulis 2001) or plants (A. Nagel 1997)\nare conscious, and some have given arguments for versions of\npan-psychism, the view that consciousness is a property of fundamental\nphysical entities, much in the same way that mass and charge are\n(Chalmers 2015). It is worth noting that neither the attribution of\nconsciousness to single-celled organisms, nor to fundamental physical\nentities, implies that all animals are conscious. In the former case,\nit may be that the information processing complexity and integration\nof relatively complex single-celled organisms outstrips that of the\nsimplest animals. In the latter case, while the version of panpsychism\ndeveloped by Chalmers attributes ‘microexperience’ to\n‘fundamental physical entities’, this does not imply that\nany particular macroscopic object (like an animal) has\n‘macroexperience’ — i.e. “the sort of conscious\nexperience had by human beings” (Chalmers 2015). This view is\ncompatible with the possibility that a given animal has no conscious\nexperience, although it is composed of microphysical entities which\npossess conscious microexperience.  These issues will not be discussed\nfurther here, as they fall outside the scope of Animal\nConsciousness.  The question of which lineages (species, or more inclusive\ngroupings such as class or phylum) of animals are conscious,\ninevitably goes hand-in-hand with considerations of the evolutionary\norigin of consciousness. This is a logical implication of the broadly\nDarwinian view of life, on which modern organisms have evolved through\ndescent, with modification, from a small number (perhaps one) of very\nancient ancestors.  If a trait is characteristic of a given species,\nit either arose in that species, or is derived from an ancestor\n— in which case, it will be present in other species derived\nfrom that ancestor, unless it has been secondarily lost in those\nspecies. Did consciousness first arise in humans, or in an earlier,\nnonhuman ancestor? If the latter, then what was this ancestor? Another\npossibility is that consciousness may have arisen multiple times, like\nwinged flight, which evolved independently in insects, birds, bats,\nand pterosaurs.   As described above, the view that consciousness is unique to\nhumans has a long history. It coheres with a religious view of\nhumanity as the pinnacle of creation, and it also may be appealing\ninsofar as it absolves us of any guilt for our treatment of\nanimals. Religion aside, it may derive considerable intuitive support\nbecause of the appeal of connecting consciousness to the problem of\nhuman uniquenesss.  If consciousness can be tied together with\nlanguage, abstract reasoning, or some other mental characteristic that\npotentially could explain our apparent seperateness from the natural\nworld, this would solve two outstanding mysteries at once.  \nDennett (1991, 1995) has been an outspoken advocate of the\nhuman-uniqueness of consciousness. Dennett argues for this position in\nconnection with his anti-realist theory of consciousness, the upshot\nof which is that consciousness is a sort of “user\nillusion” (1995) or “fiction” (1991, p. 365, p. 429)\nconstructed through people's narrative descriptions:\n \nOn Dennett's view, because consciousness is a sort of story telling,\nwhich requires language, and only (adult, normally enculturated and\nlanguage-capable) humans have language, only these humans have\nconsciousness. \n\nCarruthers has championed the view that only humans (with the possible\nexception of chimpanzees) are conscious, although for different\nreasons than Dennett. Carruthers (1998a,b, 2000) has argued to this\neffect based on his ‘higher-order thought’ theory,\naccording to which, phenomenal consciousness requires the capacity to\nthink about, and therefore conceptualize, one's own \n thoughts.[8] \n Such conceptualization requires, according to Carruthers, a theory of mind.\nAnd, Carruthers maintains, there is little basis for thinking that any\nnonhuman animals have a theory of mind, with the possible exception of\nchimpanzees (see Lurz 2011 and Andrews 2012 for in depth discussion of\ntheory of mind in nonhuman animals). This argument is, of course, no\nstronger than the higher-order thought account of consciousness upon\nwhich it is based.  But setting that aside for the sake of argument,\nthis challenge by Carruthers deserves further attention as perhaps the\nmost empirically-detailed case against animal consciousness to have\nbeen made in the philosophical literature. \n\nCarruthers neither endorses nor outright rejects the conclusion that\nchimpanzees are sentient. His suspicion that even chimpanzees might\nlack theory of mind, and therefore (on his view) phenomenal\nconsciousness, is based on some ingenious laboratory studies by\nPovinelli (1996) showing that in interactions with human food\nproviders, chimpanzees apparently fail to understand the role of eyes\nin providing visual information to the humans, despite their outwardly\nsimilar behavior to humans in attending to cues such as facial\norientation. The interpretation of Povinelli's work remains\ncontroversial. Hare et al. (2000) conducted experiments in\nwhich dominant and subordinate animals competed with each other for\nfood, and concluded that “at least in some situations\nchimpanzees know what conspecifics do and do not see and, furthermore,\nthat they use this knowledge to formulate their behavioral strategies\nin food competition situations.” They suggest that Povinelli's\nnegative results may be due to the fact that his experiments involve\nless natural chimp-human interactions. Given the uncertainty,\nCarruthers is therefore well-advised in the tentative manner in which\nhe puts forward his claims about chimpanzee sentience. \n\nA full discussion of the controversy over theory of mind (e.g., Heyes\n1998; Lurz 2011; Andrews 2012) deserves an entry of its own, but it is\nworth remarking here that the theory of mind debate has origins in the\nhypothesis that primate intelligence in general, and human\nintelligence in particular, is specially adapted for social cognition\n(see Byrne & Whiten 1988, especially the first two chapters, by\nJolly and Humphrey).  Consequently, it has been argued that evidence\nfor the ability to attribute mental states in a wide range of species\nmight be better sought in natural activities such as social play,\nrather than in laboratory designed experiments which place the animals\nin artificial situations (Allen & Bekoff 1997; see esp. chapter 6;\nsee also Hare et al. 2000, Hare et al. 2001, and\nHare & Wrangham 2002).  Alternative approaches that have attempted\nto provide strong evidence of theory of mind in nonhuman animals under\nnatural conditions have generally failed to produce such evidence\n(see, e.g., the conclusions about theory of mind in vervet monkeys and\nbaboons by Cheney & Seyfarth 1990, 2007), although anecdotal\nevidence tantalizingly suggests that researchers still have not\nmanaged to devise the right experiments. Furthermore, theory of mind\n— and social cognition more broadly — are active areas of\nresearch, and it is quite possible that new research will reveal\nevidence of theory of mind in nonhuman animals.   \n\nOn views such as Carruthers', consciousness is grounded in cognitive\nprocesses that are highly specific and modular — indeed,\nirrelevant for the perceptual, motivational and cognitive processes\ninvolved with all nonhuman animal behavior. Given that most of the\ncognitive processes (and corresponding brain-systems) involved with\nhuman activities are shared with nonhuman animals, this line of\nthinking implies that much of human activity is nonconscious as\nwell. Thus, for example, Carruthers (1989, 1992) argued that\nall animal behavior can be assimilated to the non-conscious\nactivities of humans, such as driving while distracted (“on\nautopilot”), or to the capacities of “blindsight”\npatients whose damage to visual cortex leaves them phenomenologically\nblind in a portion of their visual fields (a “scotoma”)\nbut nonetheless able to identify things presented to the scotoma. (He\nrefers to both of these as examples of “unconscious\nexperiences”.)  This comparison of animal behavior to the unconscious capacities\nof humans can be criticized on the grounds that, like Descartes'\npronouncements on parrots, it is based only on unsystematic\nobservation of animal behavior. There are grounds for thinking that\ncareful investigation would reveal that there is not a very close\nanalogy between animal behavior and human behaviors associated with\nthese putative cases of unconscious experience. For instance, it is\nnotable that the unconscious experiences of automatic driving are not\nremembered by their subjects, whereas there is no evidence that\nanimals are similarly unable to recall their allegedly unconscious\nexperiences.  Likewise, blindsight subjects do not spontaneously\nrespond to things presented to their scotomas, but must be trained to\nmake responses using a forced-response paradigm. There is no evidence\nthat such limitations are normal for animals, or that animals behave\nlike blindsight victims with respect to their visual experiences\n(Jamieson & Bekoff 1992). \n\nNevertheless, there are empirical grounds for concern that behavior\nsuggesting consciousness in animals may be the product of unconscious\nprocesses.  Allen et al. (2009) describe work on learning in\nspinal cords of rats that shows phenomena analogous to latent\ninhibition and overshadowing.  In intact animals, these learning and\nmemory related phenomena have been argued to involve attention.  But\ntheir similarity to mechanisms in the spinal cord, assumed by most not\nto involve consciousness, calls into question their status as evidence\nfor consciousness. There are, of course, differences between the\nlearning capacities of spinal cords and the learning capacities of\nintact organisms, and there are prima facie reasons for thinking that\nsophisticated forms of learning are related to consciousness (Clark\n& Squire 1998; Allen 2004; Ginsburg & Jablonka 2007b). But \nthe current point is similar to that made\nabout blindsight: a more fine-grained analysis of these similarities\nand differences is needed before conclusions about consciousness can\nbe drawn. \n\nGallup (1970) developed an experimental test of mirror\nself-recognition that has become widely used as a test of\nself-awareness, although interpretation of the test remains\ncontroversial (see the section on\n self-consciousness and metacognition\nbelow). Gallup argues that the performance of chimpanzees in this test\nindicates that they are self-aware, and that animals that fail the\ntest lack self-awareness. Further, foreshadowing Carruthers, Gallup\nargues that self-awareness — in the sense of being able to think\nabout one's own mental states — is required for having a mind,\nand therefore that animals that ‘fail’ the mirror test\nhave no minds (1982, 1985). Though there has been controversy over\njust which animals ‘pass’ the validity of versions of the test modified for use with elephants, dolphins,and magpies has been challenged \n— as of 2002, Gallup maintained that there was evidence that\nhumans, common chimpanzees, bonobos and orangutans consistently pass\nthe test, and strong evidence that a wide range of other primates fail\nconsistently fail. He took this to support the claim that\nself-awareness is unique to great apes (Gallup et al. 2002). Combined\nwith his earlier arguments that consciousness requires the sort of\nself-awareness measured by the mirror test, this would imply that\nconsciousness is unique to the great apes.\n  Gallup's interpretation of the mirror results have not been\nuncontroversial (Mitchell 2002). Rochat and Zahavi (2010) challenge\nGallup both on a) the interpretation of chimps' mirror-oriented\nbehavior as indicating a human-like experience of mirror\nself-recognition, and b) the claim that mirror self-recognition is\nimplied by consciousness.  As a side note, there has been a debate, ongoing since the early\n1990s (Cavalieri and Singer 1994) about whether great apes deserve\nspecial legal protection amounting to ‘human rights’. The\ncrux of the debate is not whether the great apes have consciousness\nper se (this seems to be assumed by most participants of the debate,\non both sides), but whether they have personhood. Personhood is\na vexed notion, but is generally thought to be related to certain\nforms of agency and self awareness, and is often thought to be tightly\ncoupled to moral status, as reflected in this debate (DeGrazia 1997;\nSEP article on Moral Status of Animals; Varner 2012). Though not\nessential to phenomenal consciousness, personhood is often thought to\npresuppose consciousness, and so perhaps is best thought of as a level\nof elaboration or complexity of consciousness. A variety of theoretical and empirical arguments have been put\nforward to the effect that consciousness is shared across all\nmammals. Seth, Baars and Edelman (2005) argue that the neural\nprocesses essential to human conscious — widespread reentrant\nactivity in the thalamo-cortical complex — involve anatomical\nsystems that are shared among all mammals (and perhaps more\nwidely). Panksepp (reviewed in 2005) takes a similar approach,\nalthough focusing on the neurophysiological systems involved in the\n‘core emotions’. Although in both of the above proposals,\nthe authors acknowledge that consciousness may be more widespread than\njust mammals, they argue that in the case of mammals, the weight of\nevidence based on homology of relevant neurophysiological systems is\noverwhelming, whereas outside of mammals, the inference is more\ntenuous because of the biological differences in non-mammalian\nanimals. Further, it should be kept in mind that all of the following\nproposals imply that consciousness is widely shared among\nmammals. Hence, the position that all mammals are conscious is widely\nagreed upon among scientists who express views on the distribution of\nconsciousness. \nQuestions about whether reptiles are conscious (and if so what their\nmental lives might be like) are especially interesting because birds\nare more closely related to them than they are to mammals, yet birds\ndisplay a variety of behaviors that tend to intuitively suggest\nintelligence and emotion to human observers much more obviously than\nthe behavior of scaly, so-called ‘cold-blooded’ animals\nlike snakes and turtles. Do birds and mammals share mental features\n(consciousness, intelligence, emotion, social attachment) that are\nabsent in reptiles? If so this would represent independent, convergent\nevolution of these phenomena. Alternatively, are these features common\nto all of these animals, but less obvious in some than others?  Cabanac et al. (2009) argue that consciousness is unique to, and\nshared by all amniotes — the clade that includes all\ndescendants of the common ancestor of living birds and mammals,\nincluding reptiles such as lizards, snakes, turtles and extinct\nanimals such as dinosaurs, pterosaurs and pleseiosaurs (see\nhttp://tolweb.org/Amniota). On this hypothesis, only these animals,\nand not amphibians, fish, or any invertebrates, possess\nconsciousness. Cabanac's argument is based on an explicit structural\nand functional theory of consciousness as a unified representational\nspace, “an abstract private model of reality with four dimensions:\nquality, intensity, hedonicity and duration” (2009, p.268). Possessing\nthis ability to model reality allows animals to simulate possible\ncourses of action, using hedonicity (pleasure or pain) as a\n‘common currency’ to evaluate and choose between actions\nbased on expected consequences (which are based on prior\nexperience).  \nCabanac identifies a set of behavioral markers of consciousness, based\non this model structural and functional theory:  Based on supposed evidence of these phenomena in amniotes but not\nin non-amniotes, Cabanac argues that consciousness originated in the\ncommon ancestor of amniotes, and hence is present in all living\namniotes but in no other animals. Cabanac and Cabanac (2009) also\nargue that a qualitative difference in the role of dopamine in\nmotivational processes in the brains of amniotes compared to\nnon-amniotes supports this distribution/origin hypothesis.   Cabanac and colleagues have documented the presence of some of\nthese phenomena in amniotes, in contrast with their absence in at\nleast a small number of non-amniote species, such as emotional fever\n(Cabanac and Bernieri 2000; Cabanac and Cabanac 2000; Cabanac and\nCabanac 2004) and taste aversion (Paradis and Cabanac 2004).   However, the assertion that these aspects of behavior and\ncognition do not exist outside amniota is largely based on absence of\nevidence (and hence, inherently limited). In particular, they do not\noffer direct support for their claims that non-amniotes are incapable\nof trading off punishments and rewards, play or detouring. Indeed,\nsome of these claims appear to be contradicted by existing studies\n— for example, documentation of detouring in jumping spiders\n(Jackson and Wilcox 2003) and work by Elwood and Appel(2009) that\nshows motivational trade-off behavior in hermit crabs.   Cabanac's structural and functional theory of consciousness can be\nevaluated independently of the evidence that he marshals in support of\nhis view of the distribution and origins of consciousness. Indeed, one\nmight challenge his views on distribution and origins precisely by\naccepting his structural and functional theory, and arguing that the\nlist of proposed indicators can actually by identified with a wider\ndistribution (i.e. if motivational trade-offs, play, and detouring are\npresent outside of amniotes). As we shall see, his structural and\nfunctional views of consciousness have much in common with those of\nother authors who argue for wider distributions of consciousness among\nanimals. 'Fish' is a folk-biological term that does not correspond precisely\nto any monophyletic taxonomic group. This can be appreciated by noted\nthat a coelacanth is more closely related to a human than to a tuna,\nor that a tuna is more closely related to a human than it is to a\nshark. I.e., some things that are intuitively fish are more closely\nrelated to non-fish than to other fish. Basically, the folk term 'fish'\nrefers to all vertebrates other than tetrapods, although it is\nsomewhat ambiguous in regards to animals such as sea-horses, eels,\nhagfish and sting-rays. In any case, there has a lively debate over fish consciousness,\nmostly focusing on the issue of whether fish can experience pain,\nstress and suffering (see below, section 7.1; see also Rose (2002) and\nSneddon et al. (2003) for contrasting views of conscious pain in fish;\nAllen 2013 and Brown 2015 for reviews of fish cognition and\nconsciousness as it may relate to pain; and Braithwaite 2010 for a\nbook-length treatment). This is of special relevance in the context of\nwelfare regulation in commercial aquaculture and recreational angling;\naccordingly, the fish consciousness literature has focused\nexperimentally on salmonids (especially salmon and trout), a group of\nhigh commercial and sport-fishing importance, but only a tiny\nphylogenetic corner of the animals that colloquially count as\nfish.   Merker (2005) has proposed that consciousness originated early in\nvertebrate evolution, and is therefore both ancient and widespread. On\nthis proposal, not only mammals and birds, but amphibians and all\nmarine vertebrates are conscious. Merker begins his argument with the\nphenomenological observation that the contents of conscious experience\nare object- and goal-oriented, but exclude the fine-grained sensory\nand motor details represented in peripheral and low-level neural\nprocessing. Merker argues that consciousness is an integrated\nrepresentational platform — what he refers to a\n‘synthesized reality space’ — that, for animals with\ncomplex bodies with many degrees of freedom of movement and multiple\nsensory modalities, solves a cluster of critical neural logistics\nproblems. This includes:  The neuroanatomical details of Merker's argument (2005) are beyond\nthe scope of this article to review, but his conclusion is that the\nsystems that solve the above problems — giving rise to\nconsciousness — arose in an early vertebrate ancestor. Hence,\nconsciousness is both ancient and widespread among living\nvertebrates. There are additional daunting challenges to addressing questions of\nconsciousness outside the vertebrate lineage, given the radical\ndifferences between vertebrates and invertebrates with respect to\nanatomy and physiology. The strategy of identifying homologous and\nfunctionally analogous structures and processes, which underlies the\nconfidence of researchers such as Cabanac (2009), Seth et al. (2005),\nMerker (2005), and Panksepp (2005) that consciousness is shared with\nother animals is much more difficult to apply (Seth et al. 2005). \nThe vertebrate lineage represents just one of approximately 34 known\nphyla — ancient lineages of animals characterized by differences\nin fundamental anatomical organization and the developmental processes\nthat generate it. Each of these phyla is derived from a relatively\nsimple state (i.e. few tissue types and a minimal central nervous\nsystem with limited sensory capacities). Hence, the invertebrates such\nas cephalopod mollusks (e.g., octopi and squids) and arthropods\n(e.g. crustaceans, insects and spiders), that are complex enough to\nattract the attention of those interested in animal consciousness,\nevolved their complexity independently from vertebrates, and in the\ncase of cephalopods and arthropods, independently from each other.\n \nToday, only three of the phyla (vertebrates, arthropods, and mollusks)\ninclude animals with complex active bodies (Trestman 2013a),\ncharacterized by: Trestman (2013a) argues that the evolution of complex active bodies\nrequires a capacity for integrated, embodied spatial cognition, and\nthat this capacity evolved independently in each of the three phyla in\nwhich it is currently found (vertebrates, arthropods and mollusks). If\nMerker (2005) is right that consciousness represents a solution to the\nneural-logistics problems posed by controlling a complex body in\nspace, it may be a good bet that these three lineages are likely\nsuspects for possessing consciousness. This line of reasoning can be\nbolstered by considering the role of temporal integration of\nperceptual information in consciousness and in action-selection and\nobject-oriented perception (Trestman 2013b). Perhaps each of these\nthree lineages evolved consciousness independently during the\ntransition from a relatively simple worm-like body morphology to\nhaving complex active bodies.  One group of invertebrate animals that has received attention in\nthe context of questions about consciousness is the coleoid\ncephalopods — octopuses, squids and cuttlefish. These are\nlarge-brained, notoriously clever animals, well-known for their\nremarkable abilities to camouflage th emselves, and for their flexible\nhunting strategies. Mather (2008) argues that cephalopods exhibit many\nbehavioral indicators of consciousness, including complex learning and\nspatial memory, as well as apparent play. Both Merker (2005) and Edelman et\nal. (2005, 2009) argue that a strong provisional case can be made for\nconsciousness in cephalopods — although these authors emphasize\nthe limitations on our understanding posed by the differences in\nanatomy and physiology between cephalopods and vertebrates.\n The other phylum that has received particular attention is the\narthropods, which includes insects, crustaceans, spiders, and many\nother less familiar animals. This is an ancient and tremendously\ndiverse group of animals, so any generalizations should be made with\ncaution. Arthropods were among the earliest animals to evolve complex\nactive bodies — and correlatively to evolve brains capable of\nadaptively controlling complex adaptive bodies (Trestman 2013a), and\nso if the function of consciousness is to solve problems raised by the\ncontrol of complex active bodies (cf. Merker 2005), it may have\nevolved early on in the arthropod lineage, in a common ancestor of all\nliving arthropods.\n  Few studies have aimed directly at answering questions about\nconsciousness in arthropods, but relevant empirical work includes: Another possibility is that consciousness evolved even earlier in\nanimal history and is even more widely distributed among animals, and\nhence has a function that is even more fundamental to animal\nlife. Ginsburg & Jablonka (2007a,b) attribute a primitive form of\n“overall sensation” as a by-product of even the simplest\nnerve nets in animals. They argue that as these states became\nharnessed to learning and motivation that they acquired the functional\nproperties of “basic consciousness”.  If this is right,\nthan consciousness may have arisen not independently in arthropods,\nmollusks and vertebrates, but only once in the common ancestor of\nthese ancient groups, very early in animal evolution.\n With the gradual loosening of behaviorist strictures in psychology\nand ethology, and independent advances in neuroscience, there has been\na considerable increase in the number of animal studies that have some\nbearing on animal consciousness.  Some of these studies focus on\nspecific kinds of experience, such as pain, while others focus on\ncognitive abilities such as self-awareness that seem to be strongly\ncorrelated with human consciousness. This section contains brief\nreviews of some of the main areas of investigation.  The aim is to\nprovide some quick entry points into the scientific literature.  Given the centrality of pain to most accounts of our ethical\nobligations towards animals, as well as the importance of animal\nmodels of pain in clinical medical research (see Mogil 2009 for a\nreview), it is hardly surprising that there is a substantial (albeit\ncontroversial) scientific literature bearing on animal pain. Reports\nby the Nuffield Council on Bioethics in the U.K. (Nuffield Council\n2005; see esp. chapter 4) and the U.S. National Academy of the\nSciences Institute for Animal Laboratory Research (ILAR 2009) have\nrecently covered the definition of pain and the physiological,\nneurological, and behavioral evidence for pain in nonhuman\nanimals. These reviews also distinguish pain from distress and\nsuffering (see also Bermond 2001), and the ILAR has divided what used\nto be a single report on recognition and alleviation of pain and\ndistress into two separate reports, although the scientific\ninvestigation of distress is relatively rudimentary (but see Dawkins\n1985; Farah 2008).  A proper understanding of neurological studies of animal pain\nbegins with the distinction between nociception and pain. Nociception\n— the capacity to sense noxious stimuli — is one of the\nmost primitive sensory capacities. Neurons functionally specialized\nfor nociception have been described in invertebrates such as the\nmedical leech and the marine snail Aplysia californica\n(Walters 1996). Because nociceptors are found in a very wide range of\nspecies, and are functionally effective even in decerebrate or\nspinally transected animals, their presence and activity\nin a species provides little or no direct evidence for phenomenally\nconscious pain experiences. The gate control theory of Melzack and\nWall (1965) describes a mechanism by which “top-down”\nsignals from the brain modulate “bottom-up” nociception,\nproviding space for the distinction between felt pain and\nnociception.  Smith & Boyd (1991) assess the evidence for the pain-sensing\ncapabilities of animals in the categories of whether nociceptors are\nconnected to the central nervous system, whether endogenous opioids\nare present, whether analgesics affect responses, and whether the\nensuing behavioral responses are analogous to those of humans (see\ntable 2.3 in Varner 1998, p. 53, which updates the one presented by\nSmith & Boyd).  On the basis of these criteria, Varner follows\nSmith & Boyd in concluding tentatively that the most obvious place\nto draw a line between pain-conscious organisms and those not capable\nof feeling pain consciously is between vertebrates and invertebrates.\nHowever, Elwood & Appel (2009) conducted an experiment on hermit\ncrabs which they interpret as providing evidence that pain is\nexperienced and remembered by these crustaceans. Varner also expressed\nsome hesitation about the evidence for conscious pain in\n“lower” vertebrates: fish, reptiles and amphibians. Allen\n(2004) argues, however, that subsequent research indicates that the\ndirection of discovery seems uniformly towards identifying more\nsimilarities among diverse species belonging to different taxonomic\nclasses, especially in the domains of anatomy and physiology of the\nnociceptive and pain systems. It is generally accepted that the mammalian pain system has both a\nsensory and an affective pathway, and that these can be dissociated to\nsome degree both pharmacologically (with morphine, e.g.) and surgical\nlesions.  The anterior cingulate cortex (ACC) is a particularly\nimportant structure of the mammalian brain in this regard (Price\n2000).  Allen et al. (2005) and Shriver (2006) argue that\nthis dissociability provides a route to empirical assessment of the\naffective component of animal consciousness, and Farah (2008) uses it\nto distinguish suffering from “mere pain”. Detailed analysis of other taxonomic groups may, however, indicate\nimportant anatomical differences. Rose (2002) argues that because fish\nlack an ACC they may not be bothered by pain.  This is in contrast to\nSneddon et al. (2003) who argue that there is adequate\nbehavioral and physiological evidence to support pain attributions to\nfish.  (See, also, Chandroo et al. 2004 for a review.)  While\nthe ACC is important to mammals, there remains the possibility that\nother taxa may have functionally similar structures, such as the\ncorticoidea dorsolateralis in birds (Atoji & Wild 2005;\nDubbeldam 2009). Genetic knockout animals are also providing further\nclues about the affective aspects of pain (see Shriver 2009 for a\nreview and application of these findings to animal welfare.) \n\nFinally, it is worth noting that a major shift in veterinary practice\nin regards to animal pain has occurred in the past decade.  Whereas\nsurgery on animals was once routinely practiced without analgesics or\nanesthetics, the vast majority of veterinary practitioners now accept\nthe basic premise that veterinarians can be trained to recognize\nanimal pain reliably, and that veterinary patients benefit from the\nsame kinds of pain alleviation treatments that are delivered to\nhumans. It has even been argued that animals possess the\nneurobiological mechanisms responsible for phantom limb pain and\nneuropathic pain (pain in the presence of no obvious tissue damage or\ndisease), and that these conditions may therefore be detectable and\ntreatable in nonhuman animals (Mathews 2008).\n \n\nThe idea of animal emotions is, of course, prominent in Darwin's work\nwith his 1872 book The Expression of the Emotions in Man and\nAnimals.  Willingness to see animals as emotional beings (and\nhumans, by contrast, as endowed with rationality that can override the\nemotions) goes back at least to Ancient Greek philosophy. Konrad\nLorenz seems to have held a similar view, echoing Oskar Heinroth's\nstatement that “animals are highly emotional people of very\nlimited intelligence” (Lorenz 1971b, 334). These days it is more\nfashionable to regard emotions as an important component of\nintelligence.  Regardless of the merits of that view, the scientific\nstudy of animal emotions has gained its own momentum.  Early in the\n20th century, although they are not arguing for or about animal\nconsciousness, physiologists recognized that significance of emotion\nin animal behavior. Dror (1999) explains how the emotional state of\nanimals was considered to be a source of noise in physiological\nexperiments at that time, and researchers took steps to ensure that\nanimals were calm before their experiments.  According to Dror,\nalthough physiologists were forced to deal with the problem of\nemotional noise, attempts to treat emotion as a subject of study in\nits own right never crystallized to the extent of generating a journal\nor other institutional features (Dror 1999, 219).  More recently, Jaak Panksepp (2004, 2005) has been conducting a\nresearch program that he calls “affective neuroscience”\nand that encompasses direct study of animal emotions (2004),\nexemplified for example in the experimental investigation of rats\n“laughing” and seeking further contact in response to\ntickling by humans (Panksepp & Burgdorf 2003). Over several\ndecades, his work (reviewed in Panksepp 2005) has elucidated the\nneuro- and molecular-physiological bases of several ‘core\nemotional systems’ including ‘seeking’,\n‘fear’, ‘rage’, ‘lust’,\n‘care’, ‘play’, and\n‘panic’. Panksepp argues that these are shared by all\nmammals, and may be more widely shared among vertebrates.  \nSufka et al. (2009) have proposed that animal models of\nneuropsychiatric disorders may also support the experimental\ninvestigation of animal emotions. Although depending on a more\nanecdotal, non-experimental approach, Smuts (2001) and Bekoff (2007)\neach defend the attribution of conscious emotions to animals from a\nscientist's perspective. Bekoff has made much of play behavior as an\nindicator of animal emotions, an idea that is also taken up by Cabanac\net al. (2009).  \n\nEmpathy in animals is also a topic of current investigation (e.g.,\nPreston & de Waal 2002). Langford et al. (2002) argue for\nempathy in mice based on experiments in mice who observe a cagemate\ngiven a noxious stimulus, or in pain, are more sensitive to painful\nstimuli than control mice who observe an unfamiliar mouse similarly\ntreated. Byrne et al. (2008) argue for empathy in elephants\nas an inference to the best explanation of various capacities, such as\ndiagnosing animacy and goal directedness, and assessing the physical\nabilities and emotional states of other elephants when these different\nfrom their own.  It is worth noting that almost all of the work, both theoretical\nand empirical, on animal emotions has limited its scope to mammals, or\nat least amniotes (For a notable recent exception, see Mendl et\nal. 2011). This work has exploited certain deep homologies of,\ne.g. brain structure and molecular neurophysiology (focusing\nespecially on hormones and neurotransmitters) in making arguments that\nanimals in these taxanomic groups share our emotions because they\nshare the mechanisms of our own emotions (as well as behaviors that\ntend to indicate emotions in us, and bear the same relations to the\nunderlying physiological mechanisms). This approach is not available\nto animals which are very distantly related to us,\ni.e. invertebrates. The ancestors of vertebrates split off from the\nrest of the animal phyla at a time when all animals were still\nrelatively simple, in terms of structure, tissue types, number of\nneurons, bodily capacities for locomotion and other forms of\nbehavior. The elaboration of complex physiological systems occurred\nindependently in the various phyla. Therefore the physiological\nsystems underlying emotions in other phyla — if these exist\n— may be very different, and hence difficult to identify, either\nin terms of direct physiological observations or in terms of\nobservations of behavioral expressions of emotion. It is also possible\nthat the repertoire of emotions in other phyla might be different,\nfurther problematizing the task of individuating non-vertebrate\nemotions. (Further discussion and additional scientific references for\nthe topic of emotions and empathy in animals can be found in the\n section on emotions and empathy in the entry on \n animal cognition.) \n\nThe idea that careful psychophysical work with could help us\nunderstand the nature of their subjective experiences of the world can\nbe traced at least to Donald Griffin's experimental tests of the\nlimits of bat echolocation. It is also behind the idea that knowing\nthat horses have near 360° vision, or that raptors have two fovea\non each retina, may tell us something about the nature of their\nexperiences — how the world appears to them — if it is\ngranted that they have such experiences. Neural investigation adds a\nfurther layer of analysis to scientific understanding of the nature of\nperception. For instance, Leopold & Logothetis (1996) used neural\ndata to support inferences about the percepts of monkeys under\nconditions of binocular rivalry (see also: Myserson et\nal. 1981; Rees et al. 2002). And Leopold et\nal. (2003) argue that neural recordings can be used to\ncorroborate the non-verbal “reports” of monkeys shown\nambiguous visual stimuli.  (Think here of whether it is possible for\nthe monkey to report that it is subject to Gestalt switches like those\narising from ambiguous figures such as the duck-rabbit or figure-vase\nillusions.)  The phenomenon of blindsight, a form of unconscious visual\nperception that arises with damage to specific areas of primary visual\ncortex, has also been investigated in surgically lesioned monkeys\n(Stoerig & Cowey 1997), with a close correspondence between the\nmonkeys' deficits and those of the human patients vis-à-vis\nparts of the visual field that can be processed only unconsciously,\nand those for which the patients retain consciousness. The non-verbal\napproach to assessing visual awareness has been further validated by\nStoerig et al. (2002).  Blindsight subjects, both human and monkey, do\nnot spontaneously respond to things presented to their scotomas (areas\nwhere they are visually unaware), but must be trained to make\nresponses using a forced-response paradigm (Stoerig & Cowey\n1997).  \n\nThe emphasis on visual perception in most of these examples, no doubt\nreflects a primatocentric bias.  We human primates are highly visual\ncreatures, and, as Nagel (1974) argued, we face considerable hurdles\nin imagining (again, a visual metaphor) the subjective experiences of\ncreatures in modalities in which humans are weak or completely\nunendowed. The examples of research also reflect an anthropocentric\nbias in that much of the animal experimentation is explicitly targeted\nat relieving human disorders. Although there is good work by\nneuroethologists on the psychophysics of echolocation by bats and\ndolphins, or on the sensory capacities of weakly electric fish,\nquestions of subjective awareness are generally not broached in that\nliterature. \n\nAs with the investigation of animal pain, fine-grained analysis of the\nneural correlates of consciousness may reveal subtle differences\nbetween different species.  For instance, Rees et al. (2002)\nreport that while the behavior of rhesus monkeys is rather similar to\nhumans under conditions of binocular rivalry, “the firing of\nmost cells in and around V1 primarily reflects stimulus properties\nrather than the conscious percept reported by the animal ... However,\nseveral neuroimaging studies in humans have presented evidence that\nargues for a stronger role of V1 in binocular rivalry and hence, by\nimplication, visual awareness.” Nevertheless, it is noteworthy\nthat they take the behavioral evidence to be unproblematically\ndescribable as report of a conscious percept by the monkey. \nA debate has unfolded in the literature over whether other animals,\nlike humans, are capable of thinking about past and future\nevents. Suddendorf and Corballis (1997, 2007) have argued that\nso-called ‘Mental Time Travel’ is unique to humans, and\nindeed plays a major role in explaining what is cognitively unique\nabout humans, including capacities for language and culture.\n\nMany mammals, birds and fish exhibit behavior such as food caching,\nnest building, tool use, or migration that seems to suggest\nforesight. For example, tayras — a members of the weasel family\nfound in Central and South America — hide bunches of bananas\ninside of bromeliads, recovering them only when the bananas are ripe\n(Soley et al. 2011). Skeptics are quick to point out that many of\nthese examples may be either a) ‘instinctive’ fixed-action\npatterns shaped by natural selection or b) the result of classical or\noperant conditioning, rather than behavior that is mediated by\n‘cognitive’ processes such as episodic memory, insight, or\nunderstanding. However, the novelty, flexibility and ability to make\nsituation-specific adjustments often calls such dismissals into\nquestion. For example, tayras cache several species of bananas, and\naccurately judge for bananas of each species when the banana is mature\nenough to continue ripening once picked. This includes domestic\nbananas, to which tayras have not been exposed over evolutionary\ntime-scales (Soley et al. 2011).   A variety of careful\nexperimental work with animals shows impressive abilities for\nintegrated what-where-when memory — the ability to recall\ndetails of an event together with its location and time. This work was\npioneered by Clayton and colleagues with scrub jays, focusing on their\ncaching behavior — wherein the birds bury food and later recover\nit (Clayton et al. 2003). For example, if scrub jays are prevented\nfrom recovering their caches for long enough, they will recover only\nnonperishable items (peanuts, in the study), ignoring their caches of\notherwise preferred but perishable food (mealworms, in the study)\n(Clayton et al. 2003). Recent work has also documented what is\nreferred to as ‘episodic-like memory’ in rats (Crystal\n2009), and the apparent ability to plan for the future (including in\nnovel ways that are not plausible ruled out as ‘mere\ninstinct’) in several animals, including nonhuman primates,\nbirds, rats and other mammals (Feeney et al. 2011 for an example of\nrecent experimental work; see Roberts 2012 for a review and\ndiscussion).   This debate has been somewhat complicated by the fact that\nproponents of the human-uniqueness of mental time travel tend to rely\non descriptions of the ability that are laden with researchers' and\nsubjects' phenomenological, introspective or intuitive descriptions of\nthe way their own minds work (e.g. Tulving 1985; Suddendorf and\nCorbalis 2007), whereas animal behavior researchers must rely on\nstrict standards of behavioral evidence to support their\nclaims. Animal behavior researchers are typically circumspect in their\ninterpretations, limiting their claims to operationalizable terms such\nas ‘what-where-when’ memory, or\n‘episodic-like’ memory, rather than making claims about\nthe nature of the experience that may be involved in an animal's\nperforming a task.  The situation may therefore represent a double\nstandard in the interpretation of evidence about human and nonhuman\nanimal subjects, with researchers uncritically making liberal\nassumptions about human cognition that would not be allowed for animal\nresearchers — an example of what Buckner (2013) has called\n‘anthropofabulation’. The question of to what extent, and\nin what ways, humans' awareness of time differs from that of other\nanimals remains an open one, and an active line of research.  \n\nSystematic study of self-consciousness and theory of mind in nonhuman\nanimals has roots in an approach to the study of self-consciousness\npioneered by Gallup (1970).  Gallup's rationale for linking\nmirror-self recognition to self-awareness has already been discussed\nabove.  The idea for the experiment came from observations well-known\nto comparative psychologists that chimpanzees would, after a period of\nadjustment, use mirrors to inspect their own images.  Gallup used\nthese observations to develop a widely-replicated protocol that\nappears to allow a scientific determination of whether it is merely\nthe mirror image per se that is the object of interest to the\nanimal inspecting it, or whether it is the image qua proxy for the\nanimal itself that is the object of interest. Taking chimpanzees who\nhad extensive prior familiarity with mirrors, Gallup anesthetized his\nsubjects and marked their foreheads with a distinctive dye, or, in a\ncontrol group, anesthetized them only. Upon waking, marked animals who\nwere allowed to see themselves in a mirror touched their own foreheads\nin the region of the mark significantly more frequently than controls\nwho were either unmarked or not allowed to look into a mirror.  Although it is typically reported that chimpanzees consistently\n“pass” the mirror-mark test, a survey of the scientific\nliterature by Shumaker & Swartz (2002) indicates that of 163\nchimpanzees tested, only 73 showed mark-touching behavior (although\nthere was considerable variation in the age and mirror experience\namong these animals). Shumaker & Swartz also report mark-touching\nbehavior in 5 of 6 tested orang utans and 6 of 23 gorillas. They\nsuggest that the lower incidence of mark touching by gorillas may be\ndue to avoidance of socially-significant direct eye contact. \nFor non-human primates outside the great apes, the evidence for mirror\nself-recognition has been sparse.  Gallup himself regards it as a\nphenomenon restricted to the great apes only, and he was among the\nfirst to challenge Hauser's report that cotton top tamarins engaged in\nmirror-guided self-directed behaviors after their distinctive white\ntufts had been dyed neon colors, a stimulus that Hauser and coauthors\nargued was presumably more salient than the red dot used by Gallup\n(Hauser et al. 1995).  Faced with Gallup's challenge, Hauser\nhimself was unable to replicate his initial results (Hauser et\nal. 2001).  However, the idea that Gallup's protocol uses a\nstimulus that is not particularly salient to monkeys continues to have\nsome currency. For example, Rajala et al. (2010) have\npresented quantitative and videographic evidence that rhesus monkeys\nwith surgical implants in their heads use mirrors to inspect the\nimplants, as well as other parts of their bodies that they cannot\nusually see. \n\nModified versions of Gallup's experiment have also been conducted with\nnon-primate species. Notoriously, Epstein et al. (1981)\ntrained pigeons to peck at a mark on their own bodies that was visible\nonly in a mirror, and they used this to call into question the\nattribution of “self-awareness” on the basis of the\nmirror-mark test, preferring an associative learning\nexplanation. Gallup et al. (2002) reject the claimed\nequivalence, pointing out that chimpanzees were not trained to touch\nmarks before the test was administered. Reiss & Marino (2001) have\noffered evidence of mirror self-recognition in bottlenose\ndolphins. Using a modified version of Gallup's procedure that involved\nno anesthesia, they inferred self-recognition from bodily contortions\nin front of the mirror (self-touching being anatomically impossible\nfor dolphins). This evidence has been disputed (e.g. Wynne 2004). The\nmirror-mark test continues to be an area of active investigation in\nvarious species including elephants (Plotnik et al. 2006) and\nmagpies (Prior et al. 2008).  Various commentators have\npointed out that the mirror test may not be entirely fair for species\nwhich depend more heavily on senses other than vision (Mitchell 2002;\nBekoff and Burghardt 2002).  An intriguing line of research into animals' knowledge of their own\nmental states considers the performance of animals in situations of\ncognitive uncertainty.  When primates and dolphins are given a\n“bailout” response allowing them to avoid making difficult\ndiscriminations, they have been shown to choose the bailout option in\nways that are very similar to humans (Smith et al. 2003). The\nfact that animals who have no bailout option and are thus forced to\nrespond to the difficult comparisons do worse than those who have the\nbailout option but choose to respond to the test has been used to\nargue for some kind of higher-order self understanding. The original\nexperiments have attracted both philosophical criticism of the\nsecond-order interpretation (e.g. Carruthers 2008) and methodological\ncriticism by psychologists (reviewed by Crystal & Foote 2009),\nalthough alternative approaches to establishing metacognition in\nnon-linguistic animals may be capable of avoiding these criticisms\n(Terrace & Son 2009). In the literature on human cognition, awareness of what one knows\nis called “metacognition” and it is associated with a\n“feeling of knowing”.  Smith and colleagues claim that\ninvestigating metacognition in animals could provide information about\nthe relation of self-awareness to other-awareness (theory of mind),\nand that their results already show that “animals have\nfunctional features of or parallels to human conscious\ncognition” (Smith et al. 2003; Smith 2009).  They also\nraise the question of what this might tell us about the phenomenal\nfeatures of that cognition.  Browne (2004) argues that the dolphin\nresearch cannot support the connection to theory of mind, but that it\nnevertheless is relevant to consciousness in dolphins, particularly\nwithin the theoretical framework provided by Lycan, described\nabove. The notion of metacognition also seems relevant to questions\nabout access consciousness. (For additional discussion of self\nawareness and metacognition, readers are referred to the section on\n theory of mind and\nmetacognition in the entry on \n animal cognition.) An article such as this perhaps raises more questions than it\nanswers, but the topic would be of little philosophical interest if it\nwere otherwise.  \nIt is clear that for many philosophers, the topic of animal\nconsciousness is no longer only of peripheral interest. There is\nincreasing interest in animal cognition from a range of philosophical\nperspectives, including ethics, philosophy of mind, and the philosophy\nof science. Philosophers working in all of these areas are\nincreasingly attentive to the particular details of scientific theory,\nmethods, and results. Many scientists and philosophers believe that\nthe groundwork has been laid for addressing at least some of the\nquestions about animal consciousness in a philosophically\nsophisticated yet empirically tractable way. Yet there remain critics\nfrom both sides: on the one hand are those who still think that\nsubjective phenomena are beyond the pale of scientific research, and\non the other are those who think that science and philosophy have not\nmoved far enough or fast enough to recognize animal consciousness.\nThe arguments on both sides are by no means exhausted.","contact.mail":"michael.a.trestman@gmail.com","contact.domain":"gmail.com"}]
