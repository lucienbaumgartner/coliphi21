[{"date.published":"2001-11-10","date.changed":"2018-12-10","url":"https://plato.stanford.edu/entries/modeltheory-fo/","author1":"Wilfrid Hodges","author2":"Thomas Scanlon","author1.info":"http://wilfridhodges.co.uk/","entry":"modeltheory-fo","body.text":"\n\n\n\nFirst-order model theory, also known as classical model theory, is a\nbranch of mathematics that deals with the relationships between\ndescriptions in first-order languages and the structures that satisfy\nthese descriptions. From one point of view, this is a vibrant area of\nmathematical research that brings logical methods (in particular the\ntheory of definition) to bear on deep problems of classical\nmathematics. From another point of view, first-order model theory is\nthe paradigm for the rest of\n model theory;\n it is the area in which many of the broader ideas of model\ntheory were first worked out. \n\n\n\n\nMathematical model theory carries a heavy load of notation, and HTML is\nnot the best container for it. In what follows, syntactic objects\n(languages, theories, sentences) are generally written in roman or\ngreek letters (for example L, T, φ), and set-theoretic objects such\nas structures and their elements are written in italic (A,\na). Two exceptions are that variables are italic (x,\ny) and that sequences of elements are written with lower case\nroman letters (a, b).  \n\nWe recall and refine some definitions from the entries on\n classical logic\n and\n model theory.\n A signature is a set\nof individual constants, predicate symbols and function symbols; each\nof the predicate symbols and function symbols has an arity\n(for example it is binary if its arity is 2). Each signature K gives\nrise to a first-order language, by building up formulas from the\nsymbols in the signature together with logical symbols (including =)\nand punctuation. \n\nIf K is a signature, then a structure of signature K, say\nA, consists of the following items: \n\nThe elements of A are the elements of\ndom(A). Likewise the cardinality or power of\nA is the cardinality of its domain. Since we can recover the\nsignature K from the first-order language L that it generates, we can\nand will refer to structures of signature K as L-structures.\nWe think of c as a name for the element\ncA in the structure A, and\nlikewise with the other symbols. \n\nFor example the field of real numbers forms a structure\nR whose elements are the real numbers, with\nsignature consisting of the individual constant 0 to name the number\nzero, a 1-ary function symbol − for minus, and two 2-ary function\nsymbols + and . for plus and times. At first sight we can’t add a\nsymbol to express 1/x, since all the named functions have to\nbe defined on the whole domain of the structure, and there is no such\nreal number as 1/0. But on second thoughts this is not a serious\nproblem; any competent mathematician puts the condition\n‘x is not zero’ before dividing by x, and\nso it never matters what the value of 1/0 is, and we can harmlessly\ntake it to be 42. But most model theorists are uncomfortable with any\nkind of division by zero, so they stick with plus, times and minus. \n\nIf L is the first-order language of signature K, then\n Tarski’s model-theoretic truth\ndefinition tells us when a sentence of L is true in A,\nand when an assignment of elements of A to variables\nsatisfies a formula of L in A. Instead of talking of\nassignments satisfying a formula, model theorists often speak of the\nset of n-tuples of elements of A that\nis defined by a formula\nφ(v1,…,vn);\nthe connection is that an n-tuple\n(a1,…,an) is\nin the defined set if and only if the assignment taking each\nvi to ai\nsatisfies the formula. \n\nIf φ is a sentence, we write \n\nto mean that φ is true in A, or in other words, A\nis a model of φ. If\nφ(v1,…,vn)\nis a formula with free variables as shown, we write  \n\nto mean that the n-tuple a is in the set defined by φ.\n(The entry on\n classical logic\n uses\nthe notation ‘A,s\n ⊨\nφ’,\n where s is any assignment to all the variables\nof L that assigns to each variable vi free\nin φ the i-th element in the n-tuple a.)  \n\nTwo L-structures that are models of exactly the same sentences of L\nare said to be elementarily equivalent. Elementary equivalence\nis an equivalence relation on the class of all L-structures. The set of\nall the sentences of L that are true in the L-structure A is\ncalled the complete theory of A, in symbols\nTh(A). A theory that is Th(A) for some structure\nA is said to be complete. (By the completeness\ntheorem for first-order logic, for which see the entry on\n classical logic,\n a theory is complete if\nand only if it is maximal syntactically consistent.) The two structures\nA and B are elementarily equivalent if and only if\nTh(A) = Th(B). \n\nTo continue the example of the field R of\nreal numbers: It is often not at all obvious whether two given\nstructures are or are not elementarily equivalent. One of the greatest\nachievements of the pre-history of model theory was Tarski’s\ndescription in 1930 of Th(R) (which he\npublished in full only after the war; see his book in the Bibliography\nbelow). This description implied among other things that the structures\nelementarily equivalent to R are exactly the\nreal-closed fields, a class of fields which was already known to the\nalgebraists in its own right. \n\nWhen mathematicians introduce a class of structures, they like to\ndefine what they count as the basic maps between these structures. The\nbasic maps between structures of the same signature K are called\nhomomorphisms, defined as follows. A homomorphism from\nstructure A to structure B is a function f from\ndom(A) to dom(B) with the property that for every\natomic formula\nφ(v1,…,vn)\nand any n-tuple a =\n(a1,…,an) of\nelements of A, \n where b is\n(f(a1),…,f(an)). \nIf we have ‘⇔’ in place of\n‘⇒’ in the quoted condition, we say that f is\nan embedding of A into B. Since the language\nincludes =, an embedding of A into B is always\none-to-one, though it need not be onto the domain of B. If it\nis onto, then the inverse map from dom(B) to dom(A)\nis also a homomorphism, and both the embedding and its inverse are said\nto be isomorphisms. We say that two structures are\nisomorphic if there is an isomorphism from one to the other.\nIsomorphism is an equivalence relation on the class of all structures\nof a fixed signature K. If two structures are isomorphic then they\nshare all model-theoretic properties; in particular they are\nelementarily equivalent.  \n\nIf A and B are structures of signature K with\ndom(A) a subset of dom(B), and the interpretations in\nA of the symbols in K are just the restrictions of their\ninterpretations in B, then we say that A is a\nsubstructure of B and conversely B is an\nextension of A. If moreover B has some\nelements that are not in A, we say that A is a\nproper substructure of B and B is an\nproper extension of A. If B is a structure\nand X is a nonempty subset of dom(B), then there is a\nunique smallest substructure of B whose domain contains all of\nX. It is known as the substructure of B generated by\nX, and we find it by first adding to X all the\nelements cB where c are individual\nconstants of K, and then closing off under the functions\nFB where F are function symbols of K. \n\nFor example the substructure of the field\nR generated by the number 1 consists of 1, 0\n(since it is named by the constant 0), 1+1, 1+1+1 etc., −1,\n−2 etc., in other words the ring of integers. (There is no need\nto close off under multiplication too, since the set of integers is\nalready closed under multiplication.) If we had included a symbol for\n1/x too, the substructure generated by 1 would have been the\nfield of rational numbers. So the notion of substructure is sensitive\nto the choice of signature. \n\nLet L be a first-order language and let A and B be\nL-structures. Suppose e is a function which takes some\nelements of A to elements of B. We say that\ne is an elementary map if whenever a sequence of\nelements a1, …,\nan in the domain of e satisfy a\nformula\nφ(x1,…,xn)\nof L in A, their images under e satisfy the same\nformula in B; in symbols  \n\nWe say that e is an elementary embedding of\nA into B if e is an elementary map and its\ndomain is the whole domain of A. As the name implies,\nelementary embeddings are always embeddings.  \n\nIf there is an elementary embedding from A to B\nthen A and B are elementarily equivalent. On the\nother hand an embedding between elementarily equivalent structures, or\neven between isomorphic structures, need not be elementary. (For\nexample, writing Z for the abelian group of\nthe integers with signature consisting of 0 and +, the embedding from\nZ to Z that takes\neach integer n to 2n is an embedding, and of course\nZ is isomorphic to itself; but this embedding\nis not elementary, since 1 satisfies the formula\n¬∃y(y + y =\nv1), but 2 doesn’t.) \n\nWe say that A is an elementary substructure of\nB, and B is an elementary extension of\nA, if A is a substructure of B and the\ninclusion map is an elementary embedding. It’s immediate from the\ndefinitions that an elementary extension of an elementary extension of\nA is again an elementary extension of A. \n\nElementary embeddings are natural maps to consider within\nfirst-order model theory. Around 1950 Abraham Robinson was impressed\nthat maps between algebraic structures in general seem hardly ever to\nbe elementary, whereas some important maps (such as embeddings between\ntwo algebraically closed fields, or between two real-closed fields)\nturn out to be elementary. He was also surprised to find that this fact\nabout algebraically closed fields is another way of stating a\ncelebrated theorem called the Hilbert Nullstellensatz. These\nobservations of Robinson have had a huge effect on the development of\nmodel theory. In Robinson’s terminology, a first-order theory is\nmodel-complete if every embedding between models of the theory\nis elementary. This notion has found many uses, and it often appears in\napplications of model theory in algebra. \nA notion that is closely related to model-completeness, but should not\nbe confused with it, is elimination of quantifiers.  Suppose L is a\nfirst-order language, T is a theory in L, and Φ is a set of\nformulas of L.  We say that T has elimination of quantifiers down\nto Φ if for every formula\nφ(x1,…,xn)\nof L there is a formula\nψ(x1,…,xn)\nin Φ such that in every model of T, φ and ψ are satisfied\nby exactly the same n-tuples of elements\n(a1,…,an).  (The\n‘method of elimination of quantifiers’ discussed in section 2.2\nof Tarski’s truth definitions) was a\nsyntactic and pre-model-theoretic method for proving elimination of\nquantifiers down to a particular set of formulas.)  A theory is said\nto have quantifier elimination if it has elimination of\nquantifiers down to quantifier-free formulas.  \n\nThe connection between model-completeness and elimination of\nquantifiers is as follows.  Robinson showed that a theory is\nmodel-complete if and only if it has elimination of quantifiers down\nto existential formulas (i.e. formulas that either are quantifier-free\nor consist of one or more existential quantifiers followed by a\nquantifier-free formula).  So theories that have quantifier\nelimination are model-complete, but the converse need not hold.\nStill, showing that a theory is model-complete is sometimes a useful\nfirst step towards showing that it has quantifier elimination. \n\nTo return to elementary embeddings: They have a number of properties\nthat make them useful. We have space for four. \n\nThere is a proof of this in the entry on\n classical logic,\n using Skolem hulls.\nNote that λ must be infinite since every first-order language\nhas infinitely many formulas.  \n\nThe elementary amalgamation theorem:\n\n Suppose L is a first-order language, A is an L-structure and\nB, C are two elementary extensions of A.\nThen there are an elementary extension D of B and an\nelementary embedding e of C into D such that\n(i) for each element a of A, e(a) =\na, and (ii) if c is an element of C but not\nof A, then e(c) is not in B. \n\nThe elementary amalgamation theorem is a consequence of the\ncompactness theorem in the next section.  \n\nThis also follows from the compactness theorem, as shown in the entry on\n classical logic.\n The name of the theorem\nis a little unfortunate, since the theorem was first proved by Tarski,\nand Skolem didn’t even believe it (because he didn’t believe in\nuncountable cardinals).  \n\nThere is another proof using the elementary amalgamation theorem and\nthe elementary chain theorem. One can show that the\nstructure A has a proper elementary\nextension A′.  (There is a proof of this using the\ncompactness theorem and the diagram lemma — see 3.1 and 3.2\nbelow; another proof is by ultrapowers — see 4.1 below.)  Now\nuse A′ and again A′ for the\nstructures B and C in the elementary amalgamation\ntheorem. Then D as in the theorem is an elementary extension\nof A, and by (ii) in the theorem, it must contain elements\nthat are not in A′, so that it is a proper elementary\nextension. Repeat to get a proper elementary extension of D,\nand so on until you have an infinite elementary chain. Use the\nelementary chain theorem to find an elementary extension of A\nthat sits on top of this chain. Keep repeating these moves until you\nhave an elementary extension of\nA that has cardinality at least λ. Then if necessary\nuse the downward Löwenheim-Skolem theorem to pull the cardinality down\nto exactly λ. This kind of argument is very common in\nfirst-order model theory.  By careful choice of the amalgams at the steps in the\nconstruction, we can often ensure that the top structure has further properties\nthat we might want (such as saturation, see 4.2 below). \n\nThe five theorems reported in this section are in some sense the\npillars of classical model theory. All of them are theorems about\nfirst-order model theory. A great deal of the work done in the third\nquarter of the twentieth century was devoted to working out the\nconsequences of these theorems within first-order model theory, and the\nextent to which similar theorems hold for languages that are not\nfirst-order.  \n\nThere is a proof of this theorem in the entry on\n classical logic.\n The theorem has several\nuseful paraphrases. For example it is equivalent to the following\nstatement:  \n\n(See the entry on\n model theory\n for the\nnotion\n ⊨\n of model-theoretic\nconsequence. To derive the second statement from the first, note that\n‘T\n ⊨\n φ’ is true if\nand only if there is no model of the theory T ∪ {¬ φ}.)  \n\nAnatolii Mal’tsev first gave the compactness theorem in 1938 (for\nfirst-order logic of any signature), and used it in 1940/1 to prove\nseveral theorems about groups; this seems to have been the first\napplication of model theory within classical mathematics. Leon Henkin\nand Abraham Robinson independently rediscovered the theorem a few years\nlater and gave some further applications. The theorem fails badly for\nnearly all\n infinitary languages. \n\nIf A is an L-structure, then we form the diagram of\nA as follows. First add to L a supply of new individual\nconstants to serve as names for all the elements of A. (This\nillustrates how in first-order model theory we easily find ourselves\nusing uncountable signatures. The ‘symbols’ in these\nsignatures are abstract set-theoretic objects, not marks on a page.)\nThen using L and these new constants, the diagram of\nA is the set of all the atomic sentences and negations of\natomic sentences that are true in A.  \n\nNamely, if an element of A is named by a new constant\nc, then map that element to the element of B′\nnamed c. A variant of this lemma is used in the proof of the\nelementary amalgamation theorem.  \n\nThis theorem may have the longest pedigree of any theorem of model\ntheory, since it generalises the Laws of Distribution for syllogisms,\nwhich go back at least to the early Renaissance. The theorem is\neasiest to state if we assume that our first-order languages have\nsymbols ∧, ∨ and ¬, but not → or ⇔. Then an\noccurrence of a predicate symbol R in a formula φ is said to\nbe positive (resp. negative) if it lies within the\nscope of an even (resp. odd) number of occurrences of ¬.  \n\nThere are several proofs of this theorem, and not all of them are\nmodel-theoretic. Without the last sentence, the theorem is known as\nCraig’s interpolation theorem, since William Craig proved this version\na few years before Roger Lyndon found the full statement in 1959. As\nCraig noted at the time, his interpolation theorem gives a neat proof\nof Evert Beth’s definability theorem, which runs as follows.  \n\nSuppose that L is a first-order language and M is the first-order\nlanguage got by adding to L a new predicate symbol R. Suppose also that\nT is a theory in M. We say that T implicitly defines R if it\nis false that there are two M-structures which are models of T, have\nthe same elements and interpret all the symbols of L in the same way\nbut interpret the symbol R differently. We say that T defines\nR explicitly if there is a formula\nφ(x1,…,xn)\nof L such that in every model of T, the formulas φ and\nR(x1,…,xn) are\nsatisfied by exactly the same n-tuples\n(a1,…,an) of\nelements. It is easy to see that if T defines R explicitly then it\ndefines R implicitly. (This fact is known as Padoa’s method;\nPadoa used the failure of implicit definability as a way of proving the\nfailure of explicit definability.) Beth’s theorem is the converse: \n\nThe omitting types theorem goes back to the mid 1950s. It very definitely\ndepends on the language being first-order and countable. It has several\nuseful generalisations, for example model-theoretic forcing,\nwhich is an analogue of the forcing construction in\n set theory.\n In fact the games used for\nmodel-theoretic forcing (see the entry on\n logic and games)\n can be adapted to prove the\nomitting types theorem too. There are similar but more complicated\ntheorems for uncountable first-order languages; some of these can be\nparaphrased as omitting types theorems for\n infinitary languages. \n\nA quantifier-free formula is said to be a Horn formula (after\nAlfred Horn) if it has one of the three forms  \n\nwhere the formulas φ1, …,\nφn, ψ are all atomic. A universal Horn\nsentence (also known to the computer scientists as a Horn\nclause) is a sentence that consists of universal quantifiers\nfollowed by a quantifier-free Horn formula; it is said to be\nstrict if no negation sign occurs in it (i.e. if it doesn’t\ncome from a quantifier-free Horn formula of the third kind).  \n\nThis theorem is a generalisation, due to Mal’tsev, of a group-theoretic\nconstruction called construction by generators and relations.\nIt is the main idea behind algebraic specification, which is\none approach to the specification of systems in computer science. The\nrequired behaviour of the system is written down as a set of strict\nuniversal Horn sentences, and then the initial model of these sentences\nis an abstract version of the required system.  \n\nA construction is a procedure for building a structure. We have already\nseen several constructions in the theorems above: for example the\nomitting types construction and the initial model construction. Here\nare three more.  \n\nIf A and B are L-structures, we form their\nproduct C = A × B as\nfollows. The elements of C are the ordered pairs\n(a,b) where a is an element of A\nand b is an element of B. The predicate symbols are\ninterpreted ‘pointwise’, i.e. so that for example  \n\nThe structures A and B are called the\nfactors of A × B. In the same way\nwe can form products of any number of structures. If all the factors of\na product are the same structure A, the product is called a\npower of A. A theorem called the Feferman-Vaught\ntheorem tells us how to work out the complete theory of the\nproduct from the complete theories of its factors.  \n\nThis construction has some variants. We can define an equivalence\nrelation on the domain of a product C, and then take a\nstructure D whose elements are the equivalence classes; the\npredicate symbols are interpreted in D so as to make the\nnatural map from dom(C) to dom(D) a homomorphism. In\nthis case the structure D is called a reduced product\nof the factors of C. It is a reduced power of\nA if all the factors are equal to A; in this case the\ndiagonal map from A to D is the one got by\ntaking each element a to the equivalence class of the element\n(a,a,…). \n\nSuppose we use a set I to index the factors in a product\nC. An ultrafilter over I is a set U\nof subsets of I with the properties \n\nIf we have an ultrafilter U over I, then we can\nconstruct a reduced product from C by making two elements of\nC equivalent if and only if the set of indices at which they\nare equal is a set in the ultrafilter U. This is indeed an\nequivalence relation on the domain of C, and the resulting\nreduced product is called an ultraproduct of the factors of\nC. If C is a power of A then this\nultraproduct is called an ultrapower of A, and it is\nsometimes written U-prod A. A theorem called\nŁoś’s theorem describes what sentences are true in\nan ultraproduct. Its most useful consequence is the following:  \n\nIf the ultrafilter U is nonprincipal, i.e. contains\nno finite sets, then the diagonal map is not onto the domain of\nU-prod A, and in fact U-prod A is\ngenerally much larger than A. So we have a way of constructing\nlarge elementary extensions. The axiom of choice guarantees that every\ninfinite set has many nonprincipal ultrafilters over it. Ultrapowers\nare an essential tool for handling large cardinals in set theory (see\nthe entry on\n set theory). \n\nA remarkable (but in practice not terribly useful) theorem of\nSaharon Shelah tells us that a pair of structures A and\nB are elementarily equivalent if and only if they have\nultrapowers that are isomorphic to each other. \n\nSuppose A is an L-structure, X is a set of elements\nof A, B is an elementary extension of A and\nb, c are two elements of B. Then b\nand c are said to have the same type over X if for\nevery formula\nφ(v1,…,vn+1)\nof L and every n-tuple d of elements of X,  \n\nWe say that A is saturated if whenever X is\na set of elements of A, of cardinality less than that of\nA, and B is any elementary extension of A,\nwe always have that every element of B has the same type over\nX as some element already in A.  \n\nThis rather heavy definition gives little clue how useful saturated\nstructures are. If every structure had a saturated elementary\nextension, many of the results of model theory would be much easier to\nprove. Unfortunately the existence of saturated elementary extensions\ndepends on features of the surrounding universe of sets. There are\ntechnical ways around this obstacle, for example using weakenings of\nthe notion of saturation. We have two main ways of constructing\nelementary extensions with some degree of saturation. One is by\nultrapowers, using cleverly constructed ultrafilters. The other is by\ntaking unions of elementary chains, generalising the proof we gave for\nthe upward Löwenheim-Skolem theorem. \n\nThe existence of partially saturated elementary extensions of the\nfield R of real numbers is the main technical\nfact behind Abraham Robinson’s nonstandard analysis. See\nSection 4 of the entry on\n model theory\nfor more information on this. Though model theory provided the first\nsteps in nonstandard analysis, this branch of analysis rapidly became a\nsubject in its own right, and its links with first-order model theory\ntoday are rather slim. \n\nLet A be an L-structure, X a set of elements of\nA and < a linear ordering of X (not necessarily\ndefinable by a first-order formula). We say that (X,<) is\nan indiscernible sequence in A if for every natural\nnumber n, and all elements\na1,…,an,b\n1,…,b n of A such\nthat a1 < … <\nan and b1 <\n… < bn, the map taking each\nai to the corresponding\nbi is an elementary map. If T is a theory\nwith infinite models, then T has models that are the Skolem hulls (see\nthe entry on\n classical logic)\n of\nindiscernible sequences. These models are known as\nEhrenfeucht-Mostowski models, after the two Polish model\ntheorists who first carried out this construction in the mid 1950s.\nThese models tend to be the opposite of saturated; we can arrange that\nvery few types over sets of elements are represented among their\nelements. Some important distinctions between different models of set\ntheory can be expressed in terms of the indiscernible sequences within\nthese models; see the entry on\n set theory. \n\nEvery healthy branch of mathematics needs a set of problems that form a\nserious challenge for its researchers. We close with a brief\nintroduction to some of the research programmes that drove first-order\nmodel theory forwards in the second half of the twentieth century. The\nbook of Marcja and Toffalori in the bibliography gives further\ninformation about these programmes. There are other current programmes\nbesides these; see for example the handbook edited by Yuri Ershov,\nwhich is about model theory when the structures are built recursively.  \n\nIn 1904 Oswald Veblen described a theory as categorical if it\nhas just one model up to isomorphism, i.e. it has a model and all its\nmodels are isomorphic to each other.  (The name was suggested to him\nby John Dewey, who also suggested the name ‘disjunctive’\nfor other theories.  This pair of terms come from traditional logic as\nnames of types of sentence.) The depressing news is that there are no\ncategorical first-order theories with infinite models; we can see this\nat once from the upward Löwenheim-Skolem theorem. In fact if T is\na first-order theory with infinite models, then the strongest kind of\ncategoricity we can hope for in T is that for certain infinite\ncardinals κ, T has exactly one model of cardinality κ, up\nto isomorphism. This property of T is called\nκ-categoricity.  \n\nNow there is a heuristic principle that many people have used,\nthough it seems to have no simple formulation. We suggest ‘Few is\nbeautiful’. The principle says that if a first-order theory T\nconstrains its models (of a particular cardinality) to be all similar\nto each other, this can only be because the models of T have few\nirregularities and asymmetries. So there should be a good structural\ndescription of these models. One should expect that they are\n‘good structures’ from the point of view of classical\nmathematics. As a first step, one easily sees from the upward and\ndownward Löwenheim-Skolem theorems that if T is κ-categorical\nfor some κ at least as large as the number of formulas in the\nlanguage of T, then T must be a complete theory. From now on, T is a\ncomplete theory with infinite models; and for simplicity we will\nassume that the language of T is countable. \n\nIn 1954 Jerzy Łoś announced that he could only find three\nkinds of example of theories T that are κ-categorical.\nNamely: \n\nŁoś asked whether there are any other possibilities besides\nthese three. (Of course most complete theories are not\nκ-categorical for any κ.)  \n\nThis question of Łoś was a tremendous stimulus to\nresearch, and it led to a classic paper of Michael Morley in 1965 which\nshowed that Łoś’s three possibilities are in fact the only\nones. One central idea of Morley’s analysis was that models of an\nuncountably categorical theory have the smallest possible number of\ntypes of element; this led directly to the branch of model theory\ncalled stability theory, which studies theories that have a\nlimited number of element types. These theories have the remarkable\nproperty that every infinite indiscernible sequence in any of their\nmodels is indiscernible under any linear ordering whatever; so these\nsequences are a kind of generalisation of bases of vector spaces.\nAnother idea implicit in Morley’s work, but much clarified by later\nwork of William Marsh, John Baldwin and Alistair Lachlan, was that in\nany model of an uncountably categorical theory there is a central core\n(called a strongly minimal set) which carries a dependence\nrelation obeying similar laws to linear dependence in vector spaces. In\nterms of this dependence relation one can define a dimension for the\nmodel, and what remains of the model outside the core is so closely\ntied to the core that the dimension determines the model up to\nisomorphism. \n\nSaharon Shelah developed Morley’s ideas with great resourcefulness and\nenergy. His main aim was to stretch the ‘Few is beautiful’\nidea by showing that there are clear dividing lines between kinds of\ntheory T. On one side of a dividing line are theories with some good\nstructural property that forces the number of nonisomorphic models of\na given cardinality to be small. On the other side, every theory has\n(for example) two models of the same cardinality that are not\nisomorphic but are extremely hard to tell apart. Shelah coined the\nname classification theory for this research. The text of\nLascar listed below is an elegant introduction to this whole\nprogramme, from Łoś to Shelah.  Meanwhile Shelah himself has\nextended it far beyond first-order logic.  Even in the first-order\ncase, Shelah had to invent new set-theoretic techniques (such as\nproper forcing) to carry out his constructions.  Classification theory has two related though fundamentally\ndistinct aims: to classify the models of a theory (or to show that\nsuch a classification is impossible) by some relatively simple\ncombinatorial invariants and to classify theories themselves by the\npresence or absence of some fundamental structures within their\nmodels.  With the second edition of Classification Theory, Shelah\ndropped the subtitle “And the number of non-isomorphic\nmodels” in order to emphasize the broader goals of the project.\nIn general, a class of theories may be recognized as classification\ntheoretically robust if it admits characterizations both in terms of\ncardinals and with respect to some absolute condition on formulae\nrelative to the theory.  For example, by definition, a theory T in a\nlanguage L is stable if there is some cardinal κ ≥ |L| so\nthat for every model M of T of cardinality at most κ, the number\nof 1-types over M is at most κ.  Equivalently, a theory T is\nstable if no formula has the order property relative to T.\nThat is, there is no L-formula φ(x;y)\n(where x and y may be tuples of variables) so that for\neach natural number n it is consistent with T that there be\na1,\n…, an; b1, …,\nbn so that\nφ(ai,bj) holds\njust in case i ≤ j.\n \n Geometric model theory grew out of Michael Morley’s 1965 paper, but in\na different direction from Shelah’s work (though today it makes regular\nuse of technical tools developed by Shelah in his classification\nprogramme). Morley had shown that models of an uncountably categorical\ntheory have structural properties that are interesting in their own\nright, regardless of the complete theory of the structure; so it became\nthe custom to talk of uncountably categorical structures,\nmeaning models of uncountably categorical theories. (And likewise\ntotally categorical structures.) Independently Boris Zilber in\nSiberia and Greg Cherlin in the United States noticed that any infinite\ngroup that is definable in an uncountably categorical structure must\nhave many features in common with the algebraic groups studied by\nalgebraic geometers. Zilber in particular showed that many methods from\nalgebraic geometry generalise to the model-theoretic case. His secret\nweapon was Bezout’s Theorem from geometry, which he used to guide him\nto solutions of very difficult model theoretic problems; for example\nhis theorem that no totally categorical theory can be axiomatised by a\nfinite number of axioms. (It was secret in the sense that it guided his\nintuition but never appeared explicitly in his results.) Zilber also\nnoticed an important difference between the first and second of Łoś’s\nexamples above. Namely, in a vector space the subspaces (i.e. the\nsubsets closed under linear dependence) form a modular lattice; but the\nalgebraically closed subsets of an algebraically closed field form a\nlattice that is not modular.  \n\nPartly because of the difficulty of communications between Siberia\nand the West, these results of Zilber took some time to digest, and in\npart they had to be rediscovered in the West. But when the message did\nfinally get through, the result was a new branch of model theory which\nhas come to be known as geometric model theory. The programme\nis broadly to classify structures according to (a) what groups or\nfields are interpretable in them (in the sense sketched in the entry\n on\n model theory)\n and (b) whether or not the\nstructures have ‘modular geometries’; and then to use this\nclassification to solve problems in model theory and geometry. From\nthe mid 1980s the leader of this research was Ehud Hrushovski. In\nthe early 1990s, using joint work with Zilber, Hrushovski gave a\nmodel-theoretic proof (the first complete proof to be found) of the\ngeometric Mordell-Lang conjecture in all characteristics; this was a\nconjecture in classical diophantine geometry. Bouscaren (ed.) 1998\nis devoted to Hrushovski’s proof and\nthe necessary background in model theory. Both (a) and (b) are\nfundamental to Hrushovski’s argument. \n\nOf the three programmes described here, this is the oldest, since it\ngrew out of Tarski’s description of the complete theory of the field of\nreal numbers (which he proved by the method of quantifier elimination).\n In the course of giving this description,\nTarski had shown that every first-order formula φ(x) in\nthe relevant language, possibly with parameters, is satisfied by\nexactly the same assignments as some boolean combination of formulas of\nthe form x < s or t < x where s,\nt are constant terms naming parameters. Another way of saying\nthis is that  \n\nA linearly ordered structure with this property is said to be\no-minimal. (The idea of the name is that o-minimality is an\nanalogue of ‘strong minimality’, in a form that makes sense\nfor structures that carry a linear ordering, whence ‘o-’\nfor ordering.)  \n\nIn 1982 Lou van den Dries showed that the fact that the field of\nreal numbers is o-minimal gives a large amount of useful information\nabout the definable sets of higher dimension, such as the family of\ndefinable subsets of the real plane. Soon after this, Julia Knight,\nAnand Pillay and Charles Steinhorn noticed that if a structure\nA is o-minimal, then so is any structure elementarily\nequivalent to A, and that van den Dries’ analysis of\nhigher-dimensional definable set applies to all these structures. These\nresults led to much activity on the frontier between model theory and\nfunction theory. Several old problems from model theory and function\ntheory were solved. Alex Wilkie showed that the field of real numbers\nwith a symbol for exponentiation is o-minimal and has a model-complete\ncomplete theory, and thereby gave a positive answer to Tarski’s old\nproblem of whether this structure allows a quantifier elimination,\nthough his method was very far from the syntactic analysis that Tarski\nhad in mind.   (This is one case where we need to remember the difference \nbetween being model-complete and having quantifier elimination;  \nsee section 2 above.  The question whether this particular theory \nhas quantifier elimination is much harder and is closely related to \na deep conjecture of number theory called Schanuel’s conjecture;  \nsee the paper of Macintyre and Wilkie.)\nWe now know a wide range of ways of adding interesting\nfeatures to the field of real numbers in such a way that the resulting\nstructure is still o-minimal (and hence in some sense mathematically\ntractable). Van den Dries has urged that o-minimal structures provide a\ngood setting for developing the ‘tame topology’ programme\nof Alexander Grothendieck. \nIn 2006, Jonathan Pila and Alex Wilkie showed that provided one\nremoves the subsets defined using only polynomial inequalities,\nsubsets of Rn definable in an\no-minimal expansion of the real field have few rational points.\nSubsequently, following a strategy first employed by Pila and Umberto\nZannier to reprove the Manin-Mumford conjecture various authors have\nused this o-minimal counting theorem to solve some important open\nproblems in diophantine geometry.\n Kobi Peterzil and Sergei Starchenko have developed a \ntheory of o-minimal complex analysis.   Just as with \nthe classical approach to complex analysis, one may interpret \nthe complex numbers as the set of ordered pairs of real numbers \nwith addition and multiplication defined by the usual rules \ninvolving their real and imaginary parts.  Of their results in this \narea, their algebraicity theorem, which asserts that if a subset of \nCn is complex analytic (meaning that it\nis closed and is locally defined by the vanishing of finitely many \ncomplex analytic functions) and definable in some o-minimal expansion\nof the real field, then it must be algebraic, that is defined by the \nvanishing of polynomial equations, is the most striking result and \nhas been strong consequences in the study of functional transcendence and\nhomogeneous dynamics.  \n\nAll three of these programmes generated new techniques for proof, constructions\nand classifications.  As we should expect, researchers have explored the range of\napplication of each technique.  One result of this has been the emergence of\nseveral useful classes of first-order theories which relate to more than\none of the three programmes.  For example a central tool of\nShelah’s classification theory was his notion of forking, a\nfar-reaching generalisation of earlier algebraic notions of dependence\nrelation.  The class of simple theories is defined by the fact that\nforking has certain nice properties while the class of\nrosy theories is characterised by the existence of a good notion\nof independence coming from a further generalisation of forking called\nþ-forking; several natural examples of simple theories\ncame to light in geometric model theory, and the complete theories of\no-minimal structures are examples of rosy theories.  In parallel with\nthese technical advances, first-order model theory continues to grow\nmore closely involved with problems in number theory, functional\nanalysis and other branches of pure and, and even applied,\nmathematics. In Shelah's programme of classification theory, a central\nrôle is played by\ndividing lines.  That is, the class of all theories should be\ndivided into those having some property and those which do not and\nthis division into these two classes should be authentic in the sense\nthat the classes should admit various definitions of different\ncharacters.  For example, the class of stable theories may be\ndescribed in many facially dissimilar ways as, for example, those\ntheories with respect to which every type is definable, those with\nrespect to which no formula has the order property, or those for which\nthere is some infinite cardinal κ at least as large as\nthat of the language for which over every model of size κ\nthere are no more than κ many 1-types.  Many of\nthese classification theoretic classes are defined by forbidding the\nexistence of certain combinatorial configurations.  For example, the\nclass of dependent or NIP (for \"Not the Independence\nProperty\") theories is defined by saying that for no formula\nφ(x,y) is it possible to find a model\nM and sequences\n(ai)i=0∞ and\n(bS) where the b sequence is indexed by the\nsubsets of the natural numbers so that\nφ(ai,bS) if and only if\ni ∈ S.  Around the same time that Shelah isolated the\nindependence property, Vladimir Vapnik and Alexey Chervonenkis\ndiscovered the same notion in machine learning theory.  Consequences\nof the model theoretic analysis of NIP have since been drawn in theory\nof neural networks, extremal combinatorics, the theory of differential\nprivacy, and machine learning theory more broadly.\n","contact.mail":"scanlon@math.berkeley.edu","contact.domain":"math.berkeley.edu"}]
