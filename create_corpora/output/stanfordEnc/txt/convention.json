[{"date.published":"2007-09-06","date.changed":"2019-06-12","url":"https://plato.stanford.edu/entries/convention/","author1":"Michael Rescorla","entry":"convention","body.text":"\n\n\n\nThe central philosophical task posed by conventions is to analyze what\nthey are and how they differ from mere regularities of action and\ncognition. Subsidiary questions include: How do conventions arise? How\nare they sustained? How do we select between alternative conventions?\nWhy should one conform to convention? What social good, if any, do\nconventions serve? How does convention relate to such notions as rule,\nnorm, custom, practice, institution, and social contract? Apart from\nits intrinsic interest, convention is important because philosophers\nfrequently invoke it when discussing other topics. A favorite\nphilosophical gambit is to argue that, perhaps despite appearances to\nthe contrary, some phenomenon ultimately results from convention.\nNotable candidates include: property, government, justice, law,\nmorality, linguistic meaning, necessity, ontology, mathematics, and\nlogic.\n\n\n\nIn everyday usage, “convention” has various meanings, as\nsuggested by the following list: Republican Party Convention; Geneva\nConvention; terminological conventions; conventional wisdom; flouting\nsocietal convention; conventional medicine; conventional weapons;\nconventions of the horror genre. As Nelson Goodman observes: \n\nAdding to the confusion, “convention” frequently serves\nas jargon within economics, anthropology, and sociology. Even within\nphilosophy, “convention” plays so many roles that we must\nask whether a uniform notion is at work. Generally speaking,\nphilosophical usage emphasizes the second of Goodman’s\ndisambiguations. A common thread linking most treatments is that\nconventions are “up to us,” undetermined by human nature or\nby intrinsic features of the non-human world. We choose our\nconventions, either explicitly or implicitly. \n\nThis concept is the target of David Lewis’s celebrated analysis in\nConvention (1969). A social convention is a regularity widely\nobserved by some group of agents. But not every regularity is a\nconvention. We all eat, sleep, and breathe, yet these are not\nconventions. In contrast, the fact that everyone in the United States\ndrives on the right side of the road rather than the left is a\nconvention. We also abide by conventions of etiquette, dress, eating,\nand so on. \n\nTwo putative social conventions commonly cited by philosophers are\nmoney and language. Aristotle mentions the former\nexample in the Nicomachean Ethics (V.5.II33a): \n\nand the latter example in De Interpretatione (16a.20–28): \n\nDavid Hume mentions both examples in the Treatise of Human\nNature (p. 490): \n\nAlthough Hume analyzed money at some length in the 1752 “Of\nMoney,” it now receives systematic attention mainly from\neconomists rather than\n philosophers.[1]\n In contrast, philosophers still lavish great attention upon the\nextent, if any, to which language rests upon convention. David Lewis\noffers a theory of linguistic conventions, while Noam Chomsky and\nDonald Davidson argue that convention sheds no light upon\nlanguage. See section 7,\n Conventions of language. \n\nFor many philosophers, a central philosophical task is to elucidate how\nwe succeed in “creating facts” through our conventions. For\ninstance, how does convention succeed in conferring value upon money or\nmeaning upon linguistic items? Ideally, a satisfying answer to these\nquestions would include both an analysis of what social conventions\nare and a description of the particular conventions underlying\nsome range of “conventional” facts. Hume’s theory of\nproperty and Lewis’s theory of linguistic meaning serve as\nparadigms here. \n\nWhat are social conventions? A natural first thought is that they are\nexplicit agreements, such as promises or contracts, enacted\neither by parties to the convention or by people suitably related to\nthose parties (such as their ancestors). This conception underwrites at\nleast one famous conventionalist account: Thomas Hobbes’s theory\nof government as resulting from a social contract, into which\nagents enter so as to leave the state of nature. However, it\nseems clear that the vast majority of interesting social phenomena,\nincluding government, involve no explicit historical act of agreement.\nSocial conventions can arise and persist without overt convening. \n\nPartly in response to such worries, John Locke emphasized the notion\nof a tacit agreement. A tacit agreement obtains if there has\nbeen no explicit agreement but matters are otherwise as if an\nexplicit agreement occurred. A principal challenge here is explaining\nthe precise respects in which matters are just as if an explicit\nagreement occurred. Moreover, many philosophers argue that appeal even\nto “as if” agreements cannot explain linguistic meaning.\nWhat language would participants in such an agreement employ when\nconducting their deliberations? Bertrand Russell observes that\n“[w]e can hardly suppose a parliament of hitherto speechless\nelders meeting together and agreeing to call a cow a cow and a wolf a\nwolf” (1921, p. 190). As W. V. Quine asks, then, “What is\nconvention when there can be no thought of convening?” (1969, p.\nxi). Some philosophers take this argument to show that language does\nnot rest upon convention. Others, such as Lewis, take it as impetus to\ndevelop a theory of convention that invokes neither explicit nor tacit\nagreement. \n\nConventionalism about some phenomenon is the doctrine that, perhaps\ndespite appearances to the contrary, the phenomenon arises from or is\ndetermined by convention. Conventionalism surfaces in virtually every\narea of philosophy, with respect to such topics as property (Hume’s\nTreatise of Human Nature), justice (Hume’s Treatise\nagain), morality (Gilbert Harman (1996), Graham Oddie (1999), Bruno Verbeek (2008)),\ngeometry (Henri Poincaré (1902), Hans Reichenbach (1922), Adolf\nGrünbaum (1962)), Lawrence Sklar (1977)), pictorial\nrepresentation (Nelson Goodman (1976)), personal identity (Derek\nParfit (1984)), ontology (Rudolf Carnap (1937), Nelson Goodman (1978),\nHilary Putnam (1987)), arithmetic and mathematical analysis (Rudolf\nCarnap (1937)), necessity (A. J. Ayer (1936)), Alan Sidelle (1989)),\nand almost any other topic one can imagine. Conventionalism arises in\nso many different forms that one can say little of substance about it\nas a general matter. However, a distinctive thesis shared by most\nconventionalist theories is that there exist alternative\nconventions that are in some sense equally good. Our choice of a\nconvention from among alternatives is undetermined by the nature of\nthings, by general rational considerations, or by universal features\nof human physiology, perception, or cognition. This element of free\nchoice distinguishes conventionalism from doctrines such as\nprojectivism, transcendental idealism, and constructivism about\nmathematics, all of which hold that, in one way or another, certain\nphenomena are “due to us.” \n\nA particularly important species of conventionalism, especially within\nmetaphysics and epistemology, holds that some phenomenon is partly due\nto our conventions about the meaning or proper use of words. For\ninstance, Henri Poincaré argues that “the axioms of\ngeometry are merely disguised definitions,” concluding\nthat: \n\nPoincaré holds that, in practice, we will always find it more\nconvenient to choose Euclidean over non-Euclidean geometry. But he\ninsists that, in principle, we could equally well choose non-Euclidean\naxioms. This position greatly influenced the logical positivists,\nincluding Rudolf Carnap, Moritz Schlick, and Hans Reichenbach, who\ngeneralized it to other aspects of science. \n\nBeginning with Logical Syntax of Language (1937/2002), Carnap\ndeveloped a particularly thoroughgoing version of linguistic\nconventionalism. Carnap invites us to propose various linguistic\nframeworks for scientific inquiry. Which framework we choose\ndetermines fundamental aspects of our logic, mathematics, and\nontology. For instance, we might choose a framework yielding either\nclassical or intuitionistic logic; we might choose a framework\nquantifying over numbers or one that eschews numbers; we might choose\na framework that takes sense data as primitive or one that takes\nphysical objects as primitive. Questions about logic, mathematics, and\nontology make no sense outside a linguistic framework, since only by\nchoosing a framework do we settle upon the ground rules through which\nwe can rationally assess such questions. There is no theoretical basis\nfor deciding between any two linguistic frameworks. It is just a\nmatter for conventional stipulation based upon pragmatic factors like\nconvenience. \n\nConventionalist theories differ along several dimensions. The most\nobvious concerns the underlying understanding of conventions\nthemselves. In many cases, such as Hume’s theory of property and\njustice, the conventions are social. In other cases, however,\nconvention lacks any intrinsically social element. For example, both\nPoincaré and Carnap seem to regard conventional stipulation as\nsomething that a lone cognitive agent could in principle achieve. \n\nAnother important difference between conventionalist theories\nconcerns what the “conventional” is contrasted with.\nOptions include: the natural; the mind-independent; the objective; the\nuniversal; the factual; and the truth-evaluable. \n\nPoincaré’s geometric conventionalism contrasts the\nconventional with the truth-evaluable. According to Poincaré,\nthere is no underlying fact of the matter about the geometry of\nphysical space, so geometric axioms are not evaluable as true or false.\nRather, the choice of an axiom system is akin to the choice of a\nmeasuring standard, such as the metric system. In many conventionalist\ntheories, however, the idea is that our conventions somehow\nmake certain facts true. Those facts may be\n“conventional”, “social,” or\n“institutional” rather than “brute” or\n“natural,” but they are full-fledged facts nonetheless. For\ninstance, following Hume, it seems plausible to claim that property\nrights and monetary value are due largely to convention. Yet few\nphilosophers would hold that claims about property rights or monetary\nvalue are\n non-truth-evaluable.[2]\nAs this example illustrates, conventionalism\nneed not reflect an “anti-realist” or\n“deflationary” stance towards some subject matter. \n\nConventionalism often entrains relativism. A particularly\nclear example is Gilbert Harman’s moral philosophy (1996), according\nto which moral truths result from social convention. Conventions vary\namong societies. One society may regard infanticide as horrific, while\nanother may regard it as routine and necessary. Moral statements are\ntrue only relative to a conventional standard. On the other hand, as\nthe example of property rights illustrates, one can accept that some\nfact is due to social convention while denying that it is relative or\nnon-universal. For instance, one might urge, the conventions of my\nsociety make it the case that I own my house, but this fact is then\ntrue simpliciter, without relativization to a particular\nsocietal convention. \n\nA final division among conventionalist theories concerns whether the\nputative conventions inform pre-existing practice. Hume’s theory\nof property purports to unveil actual conventions at work in actual\nhuman societies. But some conventionalists instead urge that we must\nadopt a convention. Carnap’s conventionalist treatment\nof logic, mathematics, and ontology illustrates this approach. Carnap\nexhorts us to replace unformalized natural language with conventionally\nchosen formal languages. Carnap has no interest in describing\npre-existing practice. Instead, he offers a “rational\nreconstruction” of that practice. \n\nCarnap’s conventionalism was the culmination of the logical\npositivists’ efforts to accommodate logic and\nmathematics within an empiricist setting. Rejecting the Kantian\nsynthetic a priori, the positivists held that logic and\nmathematics were analytic. Kant had explained the\n analytic-synthetic distinction\n in terms of concept-containment, which struck the positivists as\npsychologistic and hence “unscientific.” The positivists\ninstead treated analyticity as “truth by virtue of\nmeaning.” Specifically, they treated it as the product of\nlinguistic convention. For instance, we can adopt the stipulative\nconvention that “bachelor” means “unmarried\nman.” “All bachelors are unmarried men” is true by\nvirtue of this convention. The positivists sought to extend this\nanalysis to far less trivial examples, most notably mathematical and\nlogical truth. In this regard, they were heavily influenced by Gottlob\nFrege’s logicism and also by Ludwig Wittgenstein’s conception,\ndeveloped in the Tractatus Logico-Philosophicus, of logical\ntruths as tautologous and contentless (sinnloss). Alberto\nCoffa (1993), Michael Friedman (1999), and Warren Goldfarb (1997)\noffer detailed discussion of the role played by conventionalism in\nlogical positivism. \n\nAlthough initially attracted to Carnap’s conventionalism, W.V.\nQuine eventually launched a sustained attack on it in “Truth by\nConvention” (1935) and “Carnap and Logical Truth”\n(1963). Quine’s anti-conventionalist arguments, in conjunction\nwith his attack upon the analytic-synthetic distinction, profoundly\nimpacted metaphysics and epistemology, casting conventionalist theories\nof logic, mathematics, and ontology into general disrepute. \n\nOne of the Quine’s most widely cited arguments (1936),\ndirected against a crude conventionalism about logic, traces back to\nLewis Carroll. There are infinitely many logical truths. Human beings\nare finite, so we can explicitly stipulate only a finite number of\nstatements. Thus, in generating all the logical truths we must\neventually apply rules of inference to finitely many conventionally\nstipulated statements. But then we are employing logic to derive logic\nfrom convention, generating a vicious regress. Quine’s point here\nis not just that logic did not in fact come into existence\nthrough conventional truth assignment. His point is that it could\nnot have thus come into existence. \n\nTo avoid the Quinean regress, one might propose that we\nconventionally stipulate a finite number of axioms and a\nfinite number of inferences rules, thereby fixing an infinite number of\nlogical truths. The question here is what it means to\n“stipulate” an inference rule. We can conventionally\nstipulate that we will henceforth obey a certain inference rule. But\nthat stipulation does not entail that we are entitled to\nreason in accord with the inference rule. Mere conventional stipulation\nthat we will henceforth obey a inference rule does not ensure that the\nrule carries truths into truths. What if we stipulate that the\ninference rule carries truths into truths? Then our stipulation is\nmerely another axiom. So we require a new inference rule to draw any\nconsequences from it, and the regress continues. \n\nWhile it is doubtful that Carnap or the other positivists held the\ncrude form of conventionalism attacked by Quine’s argument, the\nargument suggests that conventionalism about logic requires an account\nof “tacit” conventions. If logic is indeed “true by\nconvention,” then some of the relevant conventions must\napparently be “implicit” in our practice, rather than the\nresults of explicit stipulation. So we require an account of what an\n“implicit” convention amounts to. Carnap offers no such\naccount. Jared Warren (2017) attempts to meet the challenge by developing an account of “implicit” inference rules. \n\nAnother Quinean argument holds that “truth by\nconvention” offers no explanatory or predictive advantage over\nthe far less exciting thesis that certain statements are true due to\nobvious features of extra-linguistic reality. For instance, we can all\nagree that linguistic convention makes it the case that\n“Everything is identical to itself” means what it does. But\nwhy should we furthermore hold that the truth of this sentence\nis due to linguistic convention, rather than to the fact that\neverything is indeed self-identical? According to Quine, Carnap has\noffered no reason for thinking that such truths are somehow vacuous as\nopposed to merely obvious. \n\nA final notable Quinean argument centers on the role of\n“conventional stipulation” in scientific theorizing.\nConsider a scientist introducing a new theoretical term by\ndefinitional stipulation. The new term is embroiled in an evolving\nbody of scientific doctrine. As this body of doctrine develops, the\noriginal legislated definition occupies no privileged status. We may\nreject it in light of new empirical developments. Thus,\n“conventionality is a passing trait, significant at the moving\nfront of science but useless in classifying the sentences behind the\nlines” (1954, p. 119). Hilary Putnam (1962) further develops\nthis argument, offering the example of “kinetic energy\n\\(= \\bfrac{1}{2} mv^{2}\\)”. Although that identity began\nas a stipulative definition in Newtonian mechanics, Einsteinian\nmechanics deems it false. Inspired by such examples, Quine rejects as\nuntenable any distinction between statements “true by\nconvention” or otherwise. \n\nQuine therefore rejects Carnap’s picture of science as a\ntwo-stage process: the first stage in which we conventionally stipulate\nconstitutive aspects of our scientific language (such as its ontology\nor logic) based solely upon pragmatic, non-rational factors; the second\nin which we deploy our language by subjecting non-conventional theories\nto rational scrutiny. For Quine, this two-stage picture does not\ndescribe even idealized scientific inquiry. There is no clear\nseparation between those aspects of theory choice that are solely\n“pragmatic” and those that are rational. \n\nThese and other Quinean arguments proved extremely influential.\nUltimately, many philosophers became convinced that Carnap’s\nconventionalist program was fundamentally\n flawed.[3]\nThis reaction dovetailed with\nadditional developments inimical to conventionalism. For instance,\nHilary Putnam (1963, 1974) and various later philosophers, such as\nMichael Friedman (1983), vigorously attacked\ngeometric\n conventionalism.[4] \n\nOn the other hand, conventionalism still finds defenders. Lawrence\nSklar (1977) advocates a refurbished version of geometric\nconventionalism. Alan Sidelle (1989) advocates conventionalism about\nnecessary truth. Michael Dummett (1991), Christopher Peacocke (1987),\nand Dag Prawitz (1977) follow Gerhard Gentzen in treating certain\nfundamental inferences as “implicit definitions” of the\nlogical connectives, a theory somewhat reminiscent of Carnap’s\nconventionalism about logic. Jared Warren (2015) invokes implicit definition to elucidate arithmetical vocabulary, defending on that basis a conventionalist treatment of arithmetical truth. Thus, the issues raised by Quine remain\nunresolved. Still, it seems safe to say that philosophers nowadays\nregard conventionalist solutions within metaphysics and epistemology\nmore warily than philosophers from the pre-Quinean\n era.[5] \n\nAlthough philosophers have always been interested in social\nconventions, Hume’s Treatise of Human Nature\noffered the first systematic analysis of what they are. The\ntopic then lay dormant until Lewis revived it in Convention,\nproviding an analysis heavily influenced by Hume’s but far more\ndetailed and rigorous. Lewis’s analysis continues to shape the\ncontemporary discussion. In this section, we briefly discuss Hume and\nthen discuss Lewis in detail. Henceforth, “convention”\nmeans “social convention.” \n\nHume’s analysis of convention, while compressed, has proved\nremarkably fertile. As Hume puts it in the Enquiry\nConcerning Human Understanding, a convention is \n\nOn this definition, a convention prevails in a population when each\nmember of the population plays his part in some system of actions\nbecause he perceives that it is in his interest to do so, given that\nothers perceive it is in their interests to do so. Several features of\nthis definition deserve emphasis. First, a convention contributes to\nthe mutual benefit of its participants. Second, a convention need not\nresult from explicit promise or agreement. Third, each participant\nbelieves that other participants obey the convention. Fourth, given\nthis belief, each participant has reason to obey the convention\nherself. This fourth point emerges even more sharply in the\nTreatise: “the actions of each of us have a reference to\nthose of the other, and are perform’d upon the supposition, that\nsomething is to be perform’d on the other part” (p. 490).\nHume illustrates his approach with the memorable example of two men\nsitting in a row-boat. In order to move at all, they must synchronize\ntheir rowing, which they do without any explicit agreement. \n\nHaving clarified convention, Hume deploys it to illuminate property,\njustice, promising, and government. In each case, Hume offers a\nbroadly conventionalist account (see the entry on Hume’s moral\nphilosophy for details). For instance, property emerges from the state\nof nature through a social convention “to bestow stability on\nthe possession of those external goods, and leave every one in the\npeaceable enjoyment of what he may acquire by his fortune and\nindustry” (Treatise, p. 489). This convention makes it\nthe case that certain goods are “owned” by certain people,\nwho enjoy exclusive rights to their use or dispensation. Similarly,\nHume argues that the obligation to keep one’s promises is intelligible\nonly with reference to convention that, when one employs a certain\n“form of words” (e.g., “I promise to\n\\(j\\)”), one thereby expresses a resolution to \\(j\\)\nand subjects oneself to penalty if one does not \\(j\\). \n\nIn both the Treatise and “Of the Original\nContract,” Hume rejects a Hobbesian conception of government as\narising from the state of nature through a social contract. Hume offers\nvarious criticisms, but a particularly fundamental objection is that\nHobbes adopts a misguided order of explanation. Hobbes explains\ngovernment as the result of phenomena, such as promising or\ncontracting, that themselves rest upon convention and hence\ncould not arise in a pure state of nature. Hume contends that promising\nand government arise independently, albeit in the same basic way and\nfrom the same basic source:\n convention.[6] \n\nPerhaps the most notable feature of Hume’s account is that it\nprovides a detailed model of how social order can arise from rational\ndecisions made by individual agents, without any need for either\nexplicit covenant or supervision by a centralized authority. In this\nrespect, Hume’s discussion prefigures Adam Smith’s\n“invisible hand” analysis of the marketplace. \n\nLewis develops a broadly Humean perspective by employing game\ntheory, the mathematical theory of strategic interaction among\ninstrumentally rational agents. Drawing inspiration from Thomas\nSchelling’s The Strategy of Conflict (1960), Lewis\ncenters his account around the notion of a coordination\nproblem, i.e., a situation in which there are several ways agents\nmay coordinate their actions for mutual benefit. \n\nSuppose \\(A\\) and \\(B\\) want to meet for dinner. They can\nchoose between two restaurants, Luigi’s and\nFabio’s. Each agent is indifferent between the two\nrestaurants, and each agent prefers meeting the other one to not\nmeeting. We represent this situation through a payoff\nmatrix: Restaurant Rendezvous Payoff Matrix \n\nThe rows (respectively, columns) represent \\(A\\)’s\n(respectively, \\(B\\)’s) possible strategies: in\nthis case, their two restaurant options. Each cell contains the\nrespective payoffs for \\(A\\) and \\(B\\) for a given\nstrategy combination. Since there are two incompatible ways that\n\\(A\\) and \\(B\\) might achieve a mutually desirable result,\nthe two “players” must coordinate their actions. \n\nIn several respects, Restaurant Rendezvous is an unrepresentative\ncoordination problem. First, \\(A\\) and \\(B\\) must perform the\nsame action in order to achieve the desired result. Second,\n\\(A\\) and \\(B\\) achieve identical payoffs in each circumstance.\nThe following payoff matrix represents a coordination problem lacking\nthese two properties: Telephone Tag Payoff Matrix \n\nAs an intuitive interpretation, imagine that \\(A\\) and\n\\(B\\) are speaking on the phone but that they are disconnected.\nWho should call back? Each would prefer that the other call back, so as\nto avoid paying for the call. However, each prefers paying for the call\nto not talking at all. If both try to call back, then both will receive\na busy signal. The payoff matrix summarizes this situation. This kind\nof case is sometimes called an impure coordination problem,\nsince it enshrines a partial conflict of interest between players. \n\nCoordination problems pervade social interaction. Drivers must\ncoordinate so as to avoid collisions. Economics agents eliminate the\nneed for barter by coordinating upon a common monetary currency. In\nmany such cases, there is no way to communicate in advance, and there\nis no centralized authority to impose order. For instance, prisoners in\nPOW camps converge without any centralized guidance upon a single\nmedium of exchange, such as cigarettes. \n\nLewis analyzes convention as an arbitrary, self-perpetuating\nsolution to a recurring coordination problem. It is self-perpetuating\nbecause no one has reason to deviate from it, given that others\nconform. For example, if everyone else drives on the right, I have\nreason to as well, since otherwise I will cause a collision.\nLewis’s analysis runs as follows (p. 76): \n\nA regularity \\(R\\) in the behavior of members of a population\n\\(P\\) when they are agents in a recurrent situation \\(S\\) is\na convention if and only if it is true that, and it is common knowledge\nin \\(P\\) that, in any instance of \\(S\\) among members of\n\\(P\\), \n\n(1) everyone conforms to \\(R\\); \n\n(2) everyone expects everyone else to conform to \\(R\\); \n\n(3) everyone has approximately the same preferences regarding all\npossible combinations of actions; \n\n(4) everyone prefers that everyone conform to \\(R\\), on\ncondition that at least all but one conform to \\(R\\); \n\n(5) everyone would prefer that everyone conform to \\(R'\\),\non condition that at least all but one conform to \\(R'\\), \n\nwhere \\(R'\\) is some possible regularity in the behavior\nof members of \\(P\\) in \\(S\\), such that no one in any\ninstance of \\(S\\) among members of \\(P\\) could conform both\nto \\(R'\\) and to \\(R\\). \n\nLewis finally settles upon a modified analysis that allows\noccasional exceptions to conventions. The literature spawned by\nLewis’s discussion tends to focus on the exceptionless\ncharacterization given above. \n\nLewisian convention is a special case of Nash equilibrium, the\ncentral idea behind modern game theory. An assignment of strategies to\nplayers is a Nash equilibrium iff no agent can improve his payoff by\ndeviating unilaterally from it. An equilibrium is strict iff\neach agent decreases his payoff by deviating unilaterally from\nit. Intuitively, a Nash equilibrium is a “steady state”,\nsince each player behaves optimally, given how other players behave. In\nthis sense, Nash equilibrium “solves” the strategic problem\nposed by a game, so it is sometimes called a “solution\nconcept”. However, Lewisian convention goes well beyond Nash\nequilibrium. In a Lewisian convention, everyone prefers that\neveryone else conform if at least all but one conform.\nEquilibria with this property are sometimes called coordination\nequilibria. \n\nBy classifying \\(R\\) as a convention only if there is some\nalternative regularity \\(R'\\) that could serve as a\nconvention, Lewis codifies the intuitive idea that conventions are\narbitrary. This was one of the most widely heralded features\nof Lewis’s definition, emphasized by both Quine (1969) and Putnam\n(1981). \n\nNotably, Lewis introduces the concept of common knowledge.\nRoughly, \\(p\\) is common knowledge iff everyone knows \\(p\\),\neveryone knows that everyone knows \\(p\\), everyone knows that\neveryone knows that everyone knows that \\(p\\), etc. The subsequent\ngame-theoretic and philosophical literature offers several different\nways of formalizing this intuitive idea, due to researchers such as\nRobert Aumann (1976) and Stephen Schiffer (1972). Recently, some\ncontroversy has arisen concerning the precise relation between these\nlater formalizations and Lewis’s own informal remarks. Robin\nCubitt and Robert Sugden (2003) argue that Lewis’s conception of\ncommon knowledge is radically different from the later formalizations,\nwhile Peter Vanderschraaf (1998) and Giacomo Sillari (2005) downplay\nthe differences. \nSee the entry on\n common knowledge\n for discussion of this controversy and of how common knowledge informs both\ngame theory and the philosophical study of convention. \n\nIn the later paper “Languages and Language” (1975/1983), Lewis\nsignificantly altered his analysis of convention. \nSee section 7, \n Conventions of language,\nfor details. \n\nMost subsequent discussions take Lewis’s analysis as a starting point,\nif only as a foil for motivating some alternative. Many philosophers\nsimply help themselves to Lewis’s account without modifying it. On the\nother hand, virtually every element of Lewis’s account has attracted\ncriticism during the past few decades. For instance, Ken Binmore\n(2008) and Richard Moore (2013) attack the “common\nknowledge” condition in Lewis’s analysis. In this section, we\nwill review some prominent criticisms of Lewis’s account. \n\nLewis’s definition of convention demands complete or\nnear-complete conformity. Many commentators object that this is too\nstrict, excluding conventions “more honored in the breach than\nthe observance.” To take Margaret Gilbert’s example (1989),\nthere might be a convention in my social circle of sending thank-you\nnotes after a dinner party, even though few people actually observe\nthis convention anymore. Lewis must deny that sending thank-you notes\nis a convention, a verdict which Gilbert and other commentators find\nunintuitive. Wayne Davis (2003) and Ruth Millikan (2005) develop\nsimilar objections. \n\nThis objection sometimes accompanies another: that Lewis overlooks the\nessentially normative character of conventions. The idea is\nthat conventions concern not just how people actually behave but also\nhow they should behave. In other words, conventions are\nregularities not (merely) de facto, but de jure. For\ninstance, if there is a convention that people stand a certain distance\nfrom one another when conversing, then it seems natural to say that\npeople should stand that distance when conversing. It is not\nobvious that Lewis can honor these intuitions, since his conceptual\nanalysis does not mention normative notions. On this basis, Margaret\nGilbert (1989) and Andrei Marmor (1996) conclude that Lewis has not\nprovided sufficient conditions for a convention to prevail among some\ngroup. \n\nA closely related idea is that violations of convention elicit some\nkind of sanction, such as tangible punishment or, more\ncommonly, negative reactive attitudes. Lewis emphasizes the\nself-perpetuating character of convention: one conforms\nbecause it is in one’s interest to conform, given that others\nconform. But, the argument goes, this emphasis overlooks a distinct\nenforcement mechanism: non-conformity elicits some kind of sanction\nfrom other people. \n\nLewis (1969, pp. 97–100) anticipates such objections and attempts to\nforestall them. He argues that conventions will tend to become norms.\nOnce a convention prevails in some population, any member of the\npopulation will recognize that others expect him to conform to it and\nthat they prefer he do so. He will also recognize that conforming\nanswers to his own preferences. It follow that he ought to\nconform, since, other things being equal, one ought to do what answers\nboth to one’s own preferences and to those of other people.\nMoreover, if people see that he fails to conform, then they will tend\nto sanction him through punishment, reproach, or distrust, since they\nwill see that he acts contrary both to his own preferences and to\ntheirs. To some extent, this argument recalls Hume’s argument in\nthe Treatise that conventions of property generate moral\nnorms. Robert Sugden (1986/2004) develops the line of thought in more\ndetail. \n\nGilbert responds to such arguments by noting that, even if they show\nthat conventions have a tendency to acquire normative force,\nthey do not show that normativity is essential to convention.\nTheoretically, it seems possible for rational agents to instantiate a\nLewisian convention without regarding it as a norm and without making\nany effort to enforce the convention through sanctions. Thus, Gilbert\nconcludes, Lewis’s account does not preserve the intrinsic link\nbetween convention and normativity. \n\nEven if one sympathizes with this objection, how to elucidate more\nsystematically the normativity of convention remains unclear. It does\nnot seem to be the normativity of morality, since someone who violates\nsome convention of, say, etiquette or fashion need not thereby act\nimmorally. Nor is it straightforwardly reducible to the normativity of\ninstrumental rationality: many philosophers want to say that, other\nthings being equal, one should conform to convention quite\nindependently of whatever one’s beliefs and desires happen to be.\n(“You really ought to send a thank-you note.”) What is this\nmysterious brand of normativity, which apparently derives from neither\nmorality nor instrumental rationality? That question is still a focus\nof active philosophical research. \n\nSeumas Miller (2001) deploys an example of Jean-Jacques Rousseau to\nquestion whether a convention must have a conventional alternative. In\nRousseau’s example, agents stationed throughout a forest must\ndecide whether to hunt stag or hunt hares. Hunting stag yields a higher\npay-off for everyone, but only if all other players hunt stag as well.\nWe can represent a two-person stag hunt through the following pay-off\nmatrix: The Stag Hunt Payoff Matrix \n\nMiller argues that, on Lewis’s definition of\n“convention,” hunting hares is not a possible convention, since a\nplayer who chooses to hunt rabbits does not prefer that the other\nplayer do likewise. Miller argues that this result accords with\nintuition. He furthermore argues that hunting stag \\(is\\),\nintuitively speaking, a possible convention. He concludes that Lewis errs by\nrequiring convention to have a conventional alternative. \n\nTyler Burge (1975) develops a related but distinct worry. He agrees\nwith Lewis that convention must have a conventional alternative, but he\ndenies that participants must know of such an alternative.\nBurge offers as an example a primitive, isolated society with a single\nlanguage. Members of this society believe, as a matter of religious\nprinciple, that theirs is the only possible language. Nevertheless,\nBurge argues, their linguistic practice is governed by convention.\nBurge concludes that Lewis adopts an overly\n“intellectualist” conception of convention, one that\ncredits participants in convention with far more rational\nself-understanding than they necessarily possess. While Burge agrees\nwith Lewis that conventions are arbitrary, he thinks that “the\narbitrariness of conventions resides somehow in the ‘logic of the\nsituation’ rather than in the participants’ psychological\nlife” (p. 253). For Burge, the arbitrariness of a convention\nconsists in the following facts: the conventions operative within a\nsociety emerge due to historical accident, not biological,\npsychological or sociological law; and, with effort comparable to that\nexpended in learning the original convention, parties to the convention\ncould have instead learned an incompatible convention that\nwould have served roughly the same social purpose. \n\nThe game-theoretic literature contains numerous solution concepts that\neither generalize or refine Nash equilibrium. Various commentators\nsuggest that a proper analysis of convention requires one of these\nalternate solution concepts. For instance, Robert Sugden (1986/2004)\nanalyzes convention as a system of evolutionarily stable\nstrategies. On this approach, not only are conventions self-enforcing,\nbut they have an additional stability property: once established, they\ncan resist invasion by deviant agents trying to establish a new\nconvention. Sugden argues that this approach illuminates a wide range\nof social phenomena, including familiar examples such as money and\nproperty. \n\nAnother widely discussed solution concept is correlated\nequilibrium, introduced by Robert Aumann (1974, 1987). To\nillustrate this generalized concept, consider a modified version of\nRestaurant Rendezvous. In the new version (sometimes called\n“Battle of the Sexes”), each agent prefers a different\nrestaurant, although both agents prefer meeting to not meeting. We\nrepresent this situation with the following payoff matrix: Battle of the Sexes Payoff Matrix \n\nThis game has two “pure” Nash equilibria: one in which\nboth players go to Luigi’s, the other in which both go to\nFabio’s. Intuitively, neither equilibrium is fair, since one\nplayer achieves a higher payoff than the other. The game also has a\n“mixed-strategy” Nash equilibrium: that is, an equilibrium\nin which each agent chooses his strategy based upon the outcome of a\nrandomizing device. Specifically, the game has a mixed-strategy\nequilibrium in which \\(A\\) goes to Luigi’s with probability\n\\(\\bfrac{2}{3}\\) and \\(B\\) goes to Luigi’s with probability \\(\\bfrac{1}{3}\\).\n\\(A\\)’s expected payoff from this equilibrium is given as\nfollows, where “\\(Prob(x, y)\\)”\ndenotes the probability that \\(A\\) goes to \\(x\\) and\n\\(B\\) goes to \\(y\\): \n\nSimilarly, \\(B\\)’s expected payoff\nis \\(\\bfrac{2}{3}\\). Neither player can improve upon this\npayoff by deviating from the mixed-strategy equilibrium, given that\nthe other player is playing her end of the equilibrium. This\nequilibrium is fair, in that it yields the same expected payoff for\nboth players. But it also yields a lower expected payoff for each\nplayer than either pure equilibrium, since there is a decent chance\nthat the players’ separate randomizing devices will lead to them to\ndifferent restaurants. \n\nIf the players can contrive to correlate their actions with a\ncommon randomizing device, they can achieve a new equilibrium\nthat is fair and that Pareto dominates the old mixed-strategy\nequilibrium. More specifically, suppose that there is a\nsingle coin toss: each player goes to Luigi’s if the toss is\nheads, Fabio’s if the toss is tails. The resulting strategy\ncombination yields an expected payoff of \\(\\bfrac{3}{2}\\) for\neach player. Intuitively, this strategy combination is an\nequilibrium, since no player has reason to deviate unilaterally from\nit. But the strategy combination does not count as a Nash\nequilibrium of the original game, since in mixed Nash equilibria\nplayers’ actions must be probabilistically independent. Aumann calls\nthis strategy combination a correlated equilibrium, since\nplayers’ actions are probabilistically correlated. He develops this\nintuitive idea in great formal detail, without reliance upon explicit\npre-game communication between players. \n\nBuilding upon Aumann’s formal treatment, Brian Skyrms (1996) and\nPeter Vanderschraaf (1998b, 2001) argue that we should treat convention\nas a kind of correlated equilibrium. For example, consider the\nconvention that drivers at traffic intersections correlate their\nactions with the color of the traffic signal. As the restaurant and\ntraffic examples illustrate, correlated equilibria often provide far\nmore satisfactory solutions to coordination problems than one could\notherwise achieve. \n\nWayne Davis (2003), Andrei Marmor (1996, 2009), Seumas Miller (2001), Robert\nSugden (1986/2004), and Peter Vanderschraaf (1998) argue that\nconventions need not be coordination equilibria. For instance, Davis\nclaims that fashion conventions do not solve coordination problems,\nsince we do not usually care how other people dress. \n\nTo develop this objection, Sugden introduces conventions of\nproperty and conventions of reciprocity, neither of which\nsolves coordination problems. He illustrates the former with the\nHawk-Dove game (also sometimes called “Chicken”): Hawk-Dove Payoff Matrix \n\nThe intuitive interpretation here is that two people faced with an\nitem of value 2 must decide whether to fight for it (Hawk) or share it\n(Dove). If both play Dove, then they split it. If one plays Hawk and\nthe other Dove, then the Hawk gets the entire good. If they both play\nHawk, then they again split it, but its value is reduced by half to\nreflect the cost of fighting. This game has no coordination\nequilibrium. However, consider the following strategy for recurring\ninstances of the game: “If you are already in possession of the\nrelevant item, then play Hawk; otherwise, play\nDove.” It is an equilibrium for both players to play\nthis strategy. (More technically, following Skyrms (1996), we might\nregard this strategy combination as a correlated equilibrium.) Sugden\nargues that such an equilibrium might emerge as a convention among\nagents who repeatedly play Hawk-Dove. But the equilibrium is not a\nconvention according to Lewis’s definition. If I play my end of\nit, I do not prefer that other people do likewise. I prefer that others\nplay Dove. Thus, the equilibrium lacks one of the main characteristics\nemphasized by Lewis: a preference for general conformity over\nslight-less-than-general conformity. \n\nSugden illustrates conventions of reciprocity with the Prisoner’s\nDilemma, which has the following payoff matrix: Prisoner’s Dilemma Payoff Matrix \n\nThe original intuitive interpretation of this payoff matrix is that\nthe police are separately interrogating two prisoners, each of whom\nmust decide whether to cooperate with the other prisoner by remaining\nsilent or whether to “defect” by confessing. If both\ncooperate, then both receive very light sentences. If both defect, then\nboth receive very harsh sentences. If one defects and the other\ncooperates, then the defector goes free while the cooperator receives a\nharsh sentence. Although this scenario may seem rather contrived, we\ncan model many common social interactions as instances of\nPrisoner’s Dilemma. Sugden offers as an example two academics who\nexchange houses for their sabbaticals. Each academic must decide\nwhether to maintain the other’s house in good condition, even\nthough leaving it a mess would be easier. \n\nPrisoner’s Dilemma has no coordination equilibrium. Yet Sugden\nargues that the following “tit-for-tat” strategy might\nemerge as a convention when players repeatedly play Prisoner’s\nDilemma over some indefinite period (e.g., two academics with a\nstanding arrangement to exchange houses every summer): co-operate as\nlong as your opponent cooperates; if your opponent defects, then defect\nfor some prescribed number of rounds \\(r\\) as retaliation before\ncooperating again; if your opponent cooperates but you defect by\nmistake, then accept your opponent’s punishment in the next\n\\(r\\) rounds without retaliating. This equilibrium is not a\nconvention in Lewis’s sense, since one always prefers that\none’s opponent cooperate rather than defect. \n\nIn response to such examples, Sugden (1986/2004) and Vanderschraaf\n(1998b) develop generalized game-theoretic analyses that do not require\nconvention to solve a coordination problem. In practice, the necessary\nrevisions to Lewis’s account are not very sweeping, since they\nbasically amount to excising clause (4) from his conceptual analysis.\nVanderschraaf (1998a) argues that these revisions yield a theory closer\nto Hume’s original account. \n\nMarmor (2009) also questions Lewis’s focus on coordination\nproblems. Marmor emphasizes actual games, such as chess, rather than\nthe “games” primarily studied by game theorists, such as Prisoner’s\nDilemma. According to Marmor, the rules of chess are conventions that\ndo not solve a coordination problem. Chess playing activity does not\ninvolve coordinating one’s actions with those of other players, in\nanything like the sense that driving on the right side of the road\n(rather than the left) involves coordination among agents. Drawing on\nJohn Searle’s (1969) discussion of “constitutive rules,” Marmor argues\nthat Lewis has overlooked an important class of conventions, which\nMarmor calls “constitutive conventions,” modeled after the rules of a\ngame. Roughly, a constitutive convention helps “constitute” a social\npractice, in the sense that it helps define what the practice is and\nhow to engage in it correctly. Marmor offers a generalized analysis\ndesigned to accommodate both Lewisian conventions and constitutive\nconventions. The analysis resembles Lewis’s, but it makes no mention\nof coordination problems, and it contains no reference to common\nknowledge. \n\nLewis requires that a convention be one among several possible\nalternatives. Even if one follows Miller in rejecting that requirement,\nit seems clear that there are many cases, such as the choice of\nmonetary currency, where we must select from among numerous candidate\nconventions. This raises the question of how we select a particular\ncandidate. An analogous question arises for game theory more generally,\nsince a game may have many Nash equilibria. It is rational to play my\npart in a Nash equilibrium, if I believe that other agents will\nplay their parts. But why should I believe that others will play\ntheir parts in this particular equilibrium? If we assume that players\ncannot engage in pre-game communication, three basic answers suggest\nthemselves: players converge upon a unique equilibrium through rational\nreflection on the logic of their strategic situation; or they are\nguided by psychological factors outside the ambit of purely rational\nanalysis; or they learn from prior experience which equilibrium to\nchoose. One might also combine these three suggestions with one\nanother. \n\nA venerable game-theoretic tradition embraces the first\nsuggestion. The hope is that, if we assume enough common knowledge\namong players about the game’s payoff structure and their own\nrationality, then, through relatively a priori reasoning,\nthey can successfully predict which equilibrium others will select. An\nearly example of this explanatory tradition is the method of backwards\ninduction, introduced by Ernst Zermelo (1913). The tradition\nculminates in John Harsanyi and Reinhard Selten’s A General Theory\nof Equilibrium Selection (1988). However, few researchers still\nchampion this tradition. Its basic flaw is already apparent from our\nsimplest coordination problem, Restaurant Rendezvous. Nothing\nintrinsic either to rationality or to the logic of the situation\nfavors one equilibrium over the other. Indeed, Harsanyi and Selten’s\ntheory dictates that each player choose a mixed-strategy randomizing\nover Luigi’s and Fabio’s. Clearly, then, Harsanyi and Selten cannot\nexplain how, in a wide variety of cases, people converge upon a\nunique, non-randomized solution. Nor does it seem likely that we can\novercome this difficulty by emending our analysis of rationality or\nrefining our solution concept. Apparently, breaking the tie between\notherwise symmetrical equilibria requires us to supplement the austere\nviewpoint of pure rational analysis with some additional input, either\nfrom human psychology or else from experience. \n\nFollowing Thomas Schelling (1960), who introduced the notion of a\nfocal point, Lewis argues that agents will select the\nsalient convention. A convention is salient (it is a focal\npoint) if it “stands out” from the other choices. A\ncandidate convention might acquire salience through precedent, explicit\nagreement, or its own intrinsic properties. Schelling conducted a\nfamous experiment to illustrate the concept of salience. He asked\nsubjects to choose a time and place to meet a friend on a given day in\nNew York City, without any possibility of prior communication about\nwhere or when to meet. Most respondents chose noon at Grand Central\nStation. Somehow, then, this choice stands out as the most conspicuous.\nAs Schelling’s example illustrates, salience is a\n“subjective” psychological trait that does not follow in\nany obvious way from the rational structure of the strategic situation.\nHume already anticipated a role for subjective psychological traits,\nnoting that our choice of convention often depends upon “the\nimagination, or the more frivolous properties of our thought and\nconception” (Treatise, p. 504, note 1). \n\nSalience plays two distinct roles in Lewis’s account,\ncorresponding to the following two questions: How do conventions\narise? and Why do people conform to convention? The\nformer question concerns dynamics (i.e., the factors governing how\nconventions originate and evolve over time), while the latter concerns\nstatics (specifically, the rational structure that sustains a\nconvention at a given moment). Lewis’s answer to the first\nquestion is that agents initially select some equilibrium either by\nchance, agreement, or intrinsic salience. The equilibrium gradually\nbecomes more salient through precedent, until eventually it becomes a\nconvention. Lewis’s answer to the second question is that a\npre-existing convention is so overwhelmingly salient that agents expect\none another to abide by it, an expectation which furnishes reason to\nconform. \n\nPhilosophers have heavily criticized Lewis’s reliance upon\nsalience, arguing that the notion of salience is obscure, or that there\nis often no salient option among candidate conventions, or that\nprecedence does not confer salience, or that Lewis fails to integrate\nsalience into the formal game-theoretic framework that otherwise shapes\nhis discussion. Margaret Gilbert (1989) argues that salience cannot\nprovide a reason for action: merely observing that some possible\nconvention is salient tells us nothing, because we cannot assume that\nothers will abide by the most salient convention. In a similar vein,\nBrian Skyrms (1996) asks how it comes to be common knowledge that\nothers will choose the salient equilibrium over the alternatives. \n\nDespite these criticisms, many authors over the intervening decades,\nsuch as Robert Sugden (1986/2004, 2011) and Ken Binmore and Larry Samuelson\n(2006), have argued that a satisfactory theory of equilibrium selection\nrequires something like Lewis’s notion of salience. Note also\nthat, even if the foregoing criticisms are legitimate, they do not\nimpugn Lewis’s analysis of what conventions are. They\nonly show that Lewis has not offered a complete theory of how\nconventions are chosen, how they evolve, and how they sustain\nthemselves. \n\nFor the past decade, the most popular approach to equilibrium\nselection has been broadly dynamical. The dynamical approach,\na branch of evolutionary game theory, develops formal models of how\nstrategy choice evolves in a population whose members repeatedly play\nsome game against each another. In contrast with “static”\ngame theory (i.e., the study of equilibria), dynamical models\nincorporate an explicitly temporal parameter. The basic goal is to\nstudy the conditions under which dynamical models with various\nproperties tend to converge to static equilibria with various\nproperties. \n\nDynamical models of equilibrium selection differ along several\ndimensions. Does the model depict learning by individual players or\naggregate trends in the population as a whole? How much rationality\ndoes the model attribute to players? Is the model deterministic or\nstochastic? Do players have limited or unlimited memory of past events?\nHow much common knowledge do players have about the game’s payoff\nstructure? Can players learn about the results of interactions in which\nthey do not participate? Do the same players participate in each round\nof play, or are the players repeatedly drawn anew from a larger\npopulation? Is that larger population modeled as finite or infinite? An\noverview of the burgeoning and forbiddingly technical literature on\nthese questions falls beyond the scope of this article. We confine\nattention here to three developments: replicator dynamics; fictitious\nplay; and sophisticated Bayesian learning. Interested readers should\nconsult the detailed surveys offered by Drew Fudenberg and David Levine\n(1998) and H. Peyton Young (2004). \n\nReplicator dynamics: In this deterministic model,\nintroduced by Peter Taylor and Leo Jonker (1978), the proportion of\nplayers choosing some strategy grows proportionally to the difference\nbetween that strategy’s mean payoff and the mean payoff for the\npopulation as a whole. The model does not describe how the behavior of\nindividual players changes over time. Rather, the model describes\naggregate trends in the population as a whole. \n\nA stable steady state of a dynamical system is a state\n\\(s\\) with the following two features: once the system enters\n\\(s\\), it never leaves it; and once the system approaches\n“close enough” to \\(s\\), then it always remains near\n\\(s\\). The basin of attraction of \\(s\\) is the set\nof states such that, if the dynamical system begins in one of those\nstates, then it will eventually converge towards \\(s\\). In many\ncases, the best way to understand a dynamical system is to construct a\n“phase portrait” diagramming its steady states and their\nbasins of attraction. In the case of interest to us here, the\n“state” of a dynamical system is simply the proportion of\nplayers choosing each strategy. \n\nTwo easy formal results convey the flavor of research on replicator\ndynamics: every stable steady state of replicator dynamics is a Nash\nequilibrium; and every evolutionarily stable equilibrium is a stable\nsteady state of replicator dynamics. \n\nReplicator dynamics originated within evolutionary biology.\nSubsequently, game theorists such as Larry Samuelson (1997) have argued\nthat it illuminates social interaction among humans. Within philosophy,\nBrian Skyrms (1996, 1998) argues that replicator dynamics shows how\nconventions of property and linguistic meaning could evolve without any\nneed for Lewisian “salience.” He places particular emphasis\nupon signaling games, that is, games in which a sender wishes\nto communicate a message to a receiver, a message determining which\naction from among a fixed repertoire the receiver will perform. (See\n section 7.1 \n for more detail on signaling games.) For\ncertain signaling games, replicator dynamics almost always converges to\nan evolutionarily stable signaling convention. Which convention emerges\ndepends solely upon chance facts about players’ initial\npropensities to adopt various strategies (i.e., the basin of attraction\nfrom which the system happens to begin). As Skyrms puts it,\n“[w]hich signaling system is selected is a matter of chance,\nnot of salience” (1996, p. 93). \n\nDespite the popularity of replicator dynamics, critics such as H.\nPeyton Young (1998) remain skeptical. The most natural motivation for\nreplicator dynamics is biological. We conceptualize players as animals\ngenetically programmed to exhibit certain behaviors. Creatures who\nachieve higher payoffs have higher reproductive fitness, and they pass\ntheir strategy choices along to their progeny. Natural selection\ntherefore causes certain behaviors to become more prevalent. Under\nthese assumptions, replicator dynamics seems plausible. But it is not\nclear that a comparable rationale applies to human interaction, since\nhumans generally act not based solely upon their genetic programming\nbut rather upon their beliefs and desires. Why should the choices of\nindividual human agents yield the pattern described by replicator\ndynamics? \n\nIn response to this worry, theorists try to derive replicator dynamics\nfrom models of individual adaptive behavior. Some models posit that\npeople tend to imitate the behavior of others, based either on how\npopular or how successful that behavior seems. Other models posit some\nkind of reinforcement mechanism. Neither approach accords very well\nwith the traditional preference among both philosophers and economists\nfor rational explanations. Samuelson (1997, p. 23) responds\nthat such approaches may nevertheless be appropriate “if we are\ninterested in people, rather than ideally rational agents.” But\nit is hardly obvious that our best cognitive science of actual human\npsychology will eschew rational explanation in favor of the\npsychological mechanisms currently being invoked to underwrite\nreplicator dynamics. \n\nFictitious play: George Brown (1951) introduced fictitious\nplay as “pre-play” reasoning, in which a player mentally\nsimulates repeated trials of a game against an imaginary opponent so\nas to predict her real opponent’s actions. The phrase\n“fictitious play” has become a misnomer, because\nresearchers now typically apply it to models in which players learn\nbased upon their actual experience of repeated play. In paradigmatic\nfictitious play models, each player plays a “best reply”\nto the observed historical frequency of her opponents’ past actions.\nThis policy is rational if: the player assumes that each opponent\nplays some stationary (either pure or mixed) strategy; the player\nemploys Bayesian updating to determine the probability that each\nopponent will perform a given action in the next round; and the player\nseeks to maximize her expected payoff for that round based upon her\ncurrent probability distribution over her opponents’ actions. It is\neasy to show that, if players engaged in fictitious play enter into a\nstrict Nash equilibrium, then they stay in it forever. Moreover, there\nare some circumstances (e.g., zero-sum two-person games) in which\nfictitious play converges to Nash equilibrium behavior. However, as\nLloyd Shapley (1964) first showed, there are games in which fictitious\nplay does not always converge to equilibrium behavior. \n\nThe literature explores many different variations on this theme. One\ncan restrict how many past trials the player remembers or how much\nweight the player places upon older trials. One can embed the player\nin a large population and restrict how much a player knows about\ninteractions within that population. One can introduce a\n“neighborhood structure,” so that players interact only\nwith their neighbors. One can introduce a stochastic element. For\ninstance, building on work of M. I. Friedlin and A. D. Wentzell (1984)\nand Michihiro Kandori, George Mailath, and Rafael Rob (1993),\nH. Peyton Young (1993, 1996, 1998) develops a model of how conventions\nevolve in which each player chooses a “best reply” with\nprobability \\(1-\\varepsilon\\) and some random strategy with\nprobability \\(\\varepsilon\\). One can also generalize the fictitious play\nframework to accommodate correlated equilibrium. Peter Vanderschraaf\n(2001) explores a variant of fictitious play in which a player frames\nhypotheses about correlations between her opponents’ strategies and\nexternal events. Applying this framework to convention, he argues that\nwe can treat the emergence of correlated equilibrium conventions as an\ninstance of rational belief-fixation through inductive\ndeliberation. \n\nFictitious play does not attribute knowledge of other people’s\npayoffs or their rationality. It does not depict players as reasoning\nabout the reasoning of others. Instead, it depicts players as\nperforming a mechanical statistical inference that converts an\naction’s observed historical frequency into a prediction about\nits future probability of recurrence. For this reason, critics such as\nEhud Kalai and Ehud Lehrer (1993) contend that fictitious play\nattributes to players insufficient recognition that they are engaged in\nstrategic interaction. For instance, a player who reasons in\naccord with fictitious play implicitly assumes that each opponent plays\nsome stationary (either pure or mixed) strategy. This assumption\noverlooks that her opponents are themselves updating their beliefs and\nactions based upon prior interaction. It also prevents players from\ndetecting patterns in the data (such as an opponent who plays one\nstrategy in odd-numbered trials and another strategy in even-numbered\ntrials). Moreover, fictitious play instructs a player to maximize her\nexpected payoff for the current round of play. This\n“myopic” approach precludes maximizing one’s future\nexpected payoff at the price of lowering one’s current payoff\n(e.g., playing Hawk rather than Dove even if I expect my opponent to do\nlikewise, since I believe that I can eventually “teach” my\nopponent to back down and play Dove in future rounds). \n\nSophisticated Bayesian learning: This approach, initiated\nby Paul Milgrom and John Robert (1991), replaces the rather crude\nstatistical inference posited by fictitious play with a more refined\nconception of inductive deliberation. Specifically, it abandons the\nquestionable assumption that one faces stationary strategies from\none’s opponents. Ehud Kalai and Ehud Lehrer (1993) offer a widely\ndiscussed model of sophisticated Bayesian learning. Players engaged in\nan infinitely repeated game constantly update probability distributions\ndefined over the set of possible strategies played by their opponents,\nwhere a strategy is a function from the set of possible histories to\nthe set of possible actions. At each stage, a player chooses an action\nthat maximizes the expected value of her payoffs for the\nentire future sequence of trials, not just for the present\ntrial. This approach allows a player to discern patterns in her\nopponents’ behavior, including patterns that depend upon her own\nactions. It also allows her to sacrifice current payoff for a higher\nexpected long-term payoff. Kalai and Lehrer prove that their procedure\nalmost always converges to something approximating Nash equilibrium,\nunder the crucial assumption (the “grain of truth”\nassumption) that each player begins by assigning positive probability\nto all strategies that actually occur. \n\nCritics such as John Nachbar (1997) and Dean Foster and H. Peyton Young\n(2001) argue that there is no reason to accept the “grain of\ntruth” assumption. From this perspective, Kalai and Lehrer merely\npush the problem back to explaining how players converge upon a\nsuitable set of prior probabilities satisfying the “grain of\ntruth” assumption. Although Kalai and Lehrer’s proof\nactually requires only a somewhat weakened version of this assumption,\nthe problem persists: sophisticated Bayesian learning converges to Nash\nequilibrium only under special assumptions about players’ prior\ncoordinated expectations, assumptions that players might well fail to\nsatisfy. \n\nSanjeev Goyal and Maarten Janssen (1996) develop this criticism,\nconnecting it with the philosophical problem of induction, especially\nNelson Goodman’s grue problem. Robert Sugden (1998, 2011) further develops\nthe criticism, targeting not just sophisticated Bayesian learning but\nvirtually every other learning model found in the current\nliterature. As the grue problem highlights, there are many different\nway of extrapolating past observations into predictions about the\nfuture. In philosophy of science, the traditional solution to this\ndifficulty is that only certain predicates are\n“projectible.” But Sugden argues that the difficulty is\nmore acute for strategic interaction, since successful coordination\nrequires shared standards of projectibility. For instance, suppose\nthat I repeatedly play a coordination game with an opponent who has\ntwo different strategy options: \\(s_{1}\\) and\n\\(s_{2}\\). Up until time \\(t\\), my opponent has\nalways played \\(s_{1}\\). I might “project”\nthis pattern into the future, predicting that my opponent will\nhenceforth play \\(s_{1}\\). But I might instead project a\n“grueified” pattern, such as: “play\n\\(s_{1}\\) until time \\(t\\), and then play\n\\(s_{2}\\).” Which inductive inference I make\ndepends upon which predicates I regard as projectible. There is no\nguarantee that my opponent shares my standards of projectibility. In\neffect, then, convergence through inductive deliberation requires me\nand my opponent to solve a new coordination problem: coordinating our\nstandards of projectibility. According to Sugden, existing dynamical models implicitly assume\nthat players have already solved this new coordination problem. Sugden\nconcludes that a full explanation of equilibrium selection requires\nsomething like Lewis’s notion of salience. In particular, it\nrequires shared psychological standards regarding which patterns are\nprojectible and which are not. Sugden urges, contra Skyrms, that\ndynamical models of convention cannot displace salience from its\ncentral role in understanding convention. \n\nAs the foregoing discussion indicates, the dynamical study of\nequilibrium selection is a diverse, fast-growing area of \nresearch.[7]\nMoreover, it raises difficult questions on the boundary between\neconomics and philosophy, such as how to analyze inductive reasoning,\nhow much rationality to attribute to social agents, and so on. It is\nundeniable that, in a wide variety of circumstances, people\nsuccessfully converge upon a single unique convention amidst a range of\nalternatives. It seems equally undeniable that we do not yet fully\nunderstand the social and psychological mechanisms that accomplish this\ndeceptively simple feat. \n\nWe now survey some alternative theories of convention proposed in the\npast few decades. Unlike the rival proposals discussed in section 4,\nwhich accept Lewis’s basic perspective while emending various\ndetails, the theories discussed below reject Lewis’s entire\napproach. \n\nEschewing Lewis’s game-theoretic orientation, Margaret Gilbert\n(1989) instead draws inspiration from sociology, specifically from\nGeorg Simmel’s theory of “social groups” (1908). The\nbasic idea is that individual agents can “join forces” to\nachieve some common end, thereby uniting themselves into a collective\nentity. To develop this idea, Gilbert provides a complex account of how agents\nbind themselves into a “plural subject” of belief and\naction. A plural subject is a set of agents who regard themselves as\njointly committed to promoting some goal, sharing some belief, or\noperating under some principle of action. By virtue of their common\nknowledge of this joint commitment, members of the plural subject\nregard themselves as “we”. They thereby regard one another\nas responsible for promoting the group’s goals and principles.\nFor instance, two traveling companions make manifest their commitment\nto keep track of one another, whereas two people who happen to share a\nseat on a train do not. The traveling companions form a plural subject.\nThe unaffiliated travelers do not. The traveling companions regard each\nother as responsible for helping if one person falls behind, for not\nlosing one another in a crowd, and so on. \n\nGilbert proposes that “our everyday concept of a social\nconvention is that of a jointly accepted principle of action, a group\nfiat with respect to how one is to act in certain situations” (p.\n377). Members of a population jointly accept a fiat when it is\ncommon knowledge that they have made manifest their willingness to\naccept and promote that fiat as a basis for action. By Gilbert’s\ndefinition, participants in a convention constitute a plural subject.\nFor they jointly accept the common goal of promoting some fiat.\nMoreover, members of the social group regard the fiat as exerting\nnormative force simply by virtue of the fact that they jointly accept\nit. Note that not all plural subjects instantiate conventions. For\ninstance, depending on the details of the case, the traveling\ncompanions from the previous paragraph might not. A convention arises\nonly when individual members of a plural subject jointly accept some\nfiat. \n\nGilbert’s account differs from Lewis’s in both\nontology and ideology. Ontologically, Gilbert\nisolates a sui generis entity, the plural subject, that\nLewis’s “individualistic” approach does not\ncountenance. Gilbert argues that a population could instantiate a\nLewisian convention without giving rise to a plural subject.\nParticipants in a Lewisian convention may prefer that other\nparticipants conform to it, given that almost everyone does. But they\nneed not regard themselves as responsible for enforcing it or\nfor helping others conform. They would so regard themselves if they\nviewed themselves as belonging to a plural subject. Thus, a Lewisian\nconvention does not ensure that its adherents constitute a plural\nsubject. \n\nRegarding ideology, Gilbert’s account attributes to\nconvention an intrinsically normative element that Lewis rejects. For\nGilbert, adopting a convention is making manifest a willingness to\npromote a certain fiat. Parties to a convention therefore accept that\nthey ought to act in accord with the fiat. In contrast, as we\nsaw in section 4.2, Lewis’s account does not recognize any\nnormative elements as intrinsic to convention. \n\nThe contrast between Gilbert and Lewis instantiates a more general\ndebate over Homo economicus: a conception of agents as\nself-interested and instrumentally rational. Lewis attempts to analyze\nsocial phenomena reductively within that framework. In contrast,\nGilbert rejects the rational choice conception, opting for a picture,\nHomo sociologicus, according to which an agent acts based on\nher self-identification as a member of a social group constituted by\nvarious norms. Elizabeth Anderson (2000) analyzes how the clash between\nthese two conceptions relates to convention and normativity. \n\nIn her later work, Gilbert (2008) adopts a more concessive stance\ntowards Lewis’s analysis of convention. She maintains that her\nanalysis handles many important social phenomena that Lewis’s account\noverlooks, but she grants that there may be other social phenomena\nthat Lewis’s account handles well. \n\nSeumas Miller (2001) introduces the notion of a “collective\nend.” A collective end is an end that is shared by a group of\nagents and that can be achieved only through action by all of those\nagents; moreover, these facts are mutually believed by the agents. A\nconvention to \\(j\\) in some recurring situation \\(s\\) prevails among\nsome agents iff it is mutually believed by the agents that each one has\na standing intention to \\(j\\) in \\(s\\), as long as others perform \\(j\\) in\n\\(s\\), so as to realize some shared collective end \\(e\\). For\ninstance, the collective end corresponding to the convention of driving\non the right side of the road is avoiding collisions. \n\nIn many respects, Miller’s account is more similar to\nLewis’s than to Gilbert’s. Miller shares Lewis’s\n“reductionist” perspective, analyzing social convention as\na pattern of interaction between rational agents, without any\nirreducibly “social” element. In particular, Miller rejects\nsui generis social entities, such as plural subjects, and he\ndoes not invoke specialized norms of convention beyond those engendered\nby morality and rationality. \n\nOne objection to Miller’s account is that, in many cases, there\nis no clear “collective end” subserved by convention. For\ninstance, what collective end must participants in a monetary practice\nshare? It seems that each agent might care only about his own\nindividual welfare, without concern for some more general social end.\nEven where there is a clear collective end served by some convention,\nshould we really build this fact into the definition of\nconvention? As Burge observes, “parties to a convention are\nfrequently confused about the relevant ends (the social functions of\ntheir practice); they are often brought up achieving them and do not\nknow the origins of their means” (1975, p. 252). Thus, it might\nseem that Miller attributes too much self-understanding to participants\nin a convention. \n\nRuth Millikan (2005) offers a radical alternative to the views surveyed\nso far. She draws inspiration not from economics or sociology but from\nbiology. On her view, a convention is a pattern of behavior\nreproduced within a population due largely to weight of\nprecedent. To say that an instance of some pattern\n“reproduces” previous instances is to say that, if the\nprevious instance had been different, the current instance would be\ncorrespondingly different. Many patterns of behavior are\n“reproduced” in this sense, such as the propensity to greet\none another by shaking hands in a certain way. However, not all\nreproduced patterns are conventions. For instance, we learn from our\nparents to open stuck jars by immersing them in hot water, but our\nreproduction of this pattern is not a convention. To count as a\nconvention, a reproduced pattern must be reproduced, in large part,\nsimply because it is a precedent, not because of its intrinsic merits.\nThus, a convention is unlikely to emerge independently in different\npopulations, in contrast with a pattern such as immersing stuck jars in\nhot water. \n\nThrough what mechanisms does convention spread “by weight of\nprecedent”? Millikan mentions several ideas: lack of imagination,\ndesire to conform, playing it safe by sticking with what has worked.\nThe use of chopsticks in the East and forks in the West illustrates how\nobeying precedent is often the most practical policy, since these\nrespective implements are more readily available in the respective\nlocations. \n\nPerhaps the most striking aspect of Millikan’s discussion is\nthat it assigns no essential role to rationality in sustaining\nconventions. For instance, a society in which people maintain a\nconvention simply from unreflective conformism would satisfy\nMillikan’s definition. The tradition established by Hume and\ncontinued by Lewis seeks to explain how social order emerges from the\nrational decisions of individual agents. Millikan rejects that\ntradition. To some extent, Burge also departs from the tradition,\nwriting that “the stability of conventions is safeguarded not\nonly by enlightened self-interest, but by inertia, superstition, and\nignorance” (p. 253). However, Millikan’s position is more\nextreme than Burge’s, since she assigns reason no role in\nsustaining convention. In other words, whereas Burge apparently thinks\nthat convention rests upon both rational and irrational underpinnings,\nMillikan does not acknowledge any rational underpinnings. \n\nPlato’s Cratylus offers a notable early discussion of\nlinguistic convention. Hermogenes defends a broadly conventionalist\nview of linguistic meaning: \n\nwhile Cratylus advocates a rather obscure anti-conventionalist\nalternative: \n\nNowadays, virtually all philosophers side with Hermogenes. Barring a\nfew possible exceptions such as onomatopoeia, the association between a\nword and its referent is not grounded in the intrinsic nature of either\nthe word or the referent. Rather, the association is\narbitrary. In this weak sense, everyone agrees that language\nis conventional. However, disagreement persists about whether social\nconvention plays a useful role in illuminating the workings of\nlanguage. \n\nDavid Lewis (1969) provides the first systematic theory of how social\nconvention generates linguistic meaning. Subsequent philosophers to\noffer convention-based accounts include Jonathan Bennett (1976), Simon\nBlackburn (1984), Wayne Davis (2003), Ernie Lepore and Matthew Stone\n(2015), Brian Loar (1976), and Stephen Schiffer (1972). \n\nLewis begins by studying signaling problems. A\ncommunicator has privileged information differentiating among\nstates \\(s_{1},\\ldots, s_{m}\\).\nAudience members can choose among responses\n\\(F(s_{1}), \\ldots, F(s_{m})\\). Everyone prefers that audience\nmembers do \\(F(s_{i})\\) if\n\\(s_{i}\\) obtains. There is a set of signals\n\\(x_{1},\\ldots,x_{n}\\), \\(m \\le n\\), that the communicator can pass to the audience. In\nLewis’s example, the sexton knows whether the redcoats are staying\nhome, coming by land, or coming by sea. By placing either zero, one,\nor two lanterns in the belfry, he signals Paul Revere whether to go\nhome, warn people that redcoats are coming by land, or warn people\nthat the redcoats are coming by sea. A signaling problem is a\ncoordination problem, because communicator and audience must\ncoordinate so that the communicator’s signal elicits the mutually\ndesired action. Building on Lewis’s discussion, Skyrms (2010) offers\nan intensive analysis of signaling problems, with applications to\ndiverse biological cases studies ranging from bacteria to apes. \n\nIn comparison with normal linguistic interaction, signaling problems\nare very specialized. A fundamental difference is that people normally\nneed not agree upon which action(s) would be desirable, given some\nstate of affairs. When we search for an audience reaction canonically\nassociated with an assertion that \\(p\\), the most natural\ncandidate is something like believing that \\(p\\) (or\nperhaps believing that the speaker believes \\(p)\\). Yet coming to\nbelieve a proposition is not an action, and Lewis’s definition of\nconvention presupposes that conventions are regularities of action.\nHence, believing what people say cannot be part of a Lewisian\nconvention. \n\nAlthough Lewis explored various ways around this difficulty, he\neventually concluded that we should alter the analysis of convention.\nIn “Languages and Language” (1975/1983), he broadened the\nanalysis so that regularities of action and belief could serve\nas conventions. Clause (4) of Lewis’s definition entails that\neveryone prefers to conform to the convention given that everyone else\ndoes. Preferences regarding one’s own beliefs are dubiously\nrelevant to ordinary conversation. Thus, in his revised analysis, Lewis\nsubstitutes a new clause: \n\nThe “reason” in question might be either a\npractical reason, in the case of action, or an\nepistemic reason, in the case of belief. \n\nLewis defines a language as a function that assigns\ntruth-conditions to sentences. More precisely, and ignoring\ncomplications such as vagueness and indexicality, a language \\(L\\)\nis a mapping that assigns each sentence \\(s\\) a set of possible\nworlds \\(L(s)\\). A sentence \\(s\\) is “true in\n\\(L\\)” iff the actual world belongs to\n\\(L(s)\\). There are infinitely many possible languages.\nWe must explain what it is for a given group of agents to use a given\nlanguage. In other words, what is the “actual language”\nrelation? Lewis proposes: \n\nwhere a speaker is “truthful in \\(L\\)” iff she\ntries to avoid uttering sentences not true in \\(L\\), and a speaker\nis “trusting in \\(L\\)” iff she believes that sentences\nuttered by other speakers are true in \\(L\\). Given that this\nconvention prevails, speakers who want to communicate have reason to\nconform to it, which in turn perpetuates the convention. Note that\nLewis’s account avoids the Russell-Quine regress argument from\n section 1.1, since Lewisian convention does not\npresuppose explicit agreement between participants. \n\nIn many respects, Lewis’s account descends from Grice’s theory of\nspeaker-meaning. A simplified version of Grice’s account runs as\nfollows: a speaker speaker-means that \\(p\\) iff\nshe performs an action with an intention of inducing the belief that\n\\(p\\) in her audience by means of their recognition of that very\nintention. Although Lewis does not explicitly build speaker-meaning\ninto his analysis of the “actual language” relation, a\nbroadly Gricean communicative mechanism informs his discussion. Like\nGrice, Lewis emphasizes how meaning emerges from coordination between\nthe speaker’s communicative intentions and the hearer’s communicative\nexpectations. Grice does not provide a very compelling account of how\nspeakers and hearers coordinate their communicative intentions and\nexpectations by exploiting a pre-existing practice. Lewis\nfills this lacuna by citing a standing convention of truthfulness and\ntrust. \n\nStephen Schiffer (1972) and Jonathan Bennett (1976) offer alternative\n“neo-Gricean” accounts that combine Lewisian convention\nwith more explicit appeal to Gricean speaker-meaning. In effect, both\ntheories are sophisticated variants upon the following: \n\nThus, both accounts analyze sentence meaning as the result of a\nconvention that certain sentences are used to communicate certain\npropositions. \n\n A fundamental question for philosophy of language is how meaning\narises from use. How do we confer significance upon inherently\nmeaningless linguistic expressions by employing them in linguistic\npractice? Neo-Gricean accounts such as Lewis’s, Schiffer’s, and\nBennett’s provide detailed answers to this question. For instance,\nLewis isolates a self-perpetuating communicative mechanism that\nsystematically associates sentences with propositional contents. He\nreduces social convention to the propositional attitudes of individual\nspeakers, and he then uses social convention to explain how meaning\narises from use. He thereby depicts linguistic expressions as\ninheriting content from antecedently contentful propositional\nattitudes. On this approach, thought is the primary locus of\nintentionality, and language enjoys intentional content merely in a\nderivative way, through its employment in communicative\ntransactions. That general view of the relation between language and\nthought goes back at least to Book III of Locke’s Essay on Human\nUnderstanding. It is currently quite popular. Much of its\npopularity stems from the widespread perception that Lewis’s account,\nor some other such account, successfully explains how language\ninherits content from thought. \n\nConventional theories of linguistic meaning attract several different\ntypes of criticism. We may distinguish four especially important\ncriticisms: denial that the putative conventions prevail in actual\npractice; denial that convention can determine linguistic meaning;\ndenial that convention is necessary for linguistic meaning; and denial\nthat convention-based accounts employ the proper order of\nexplanation. \n\nThis criticism surfaces repeatedly throughout the literature. For\ninstance, Grice’s analysis of speaker-meaning generated a\nmini-industry of counter-example and revised analysis. The gist of the\ncounter-examples is that there are many perfectly normal linguistic\ninteractions in which speakers lack the communicative intentions and\nexpectations cited by Grice. Thus, it is difficult to see how our\npractice could instantiate a convention that crucially involves those\nintentions and expectations. One might respond to this argument in\nvarious ways, such as classifying certain linguistic interactions as\n“paradigmatic” and others as “derivative.” But\nat least one prominent Gricean, Stephen Schiffer (1987), eventually\nconcluded, partly from such counter-examples, that the program of\nexplicating linguistic meaning through Lewisian convention and Gricean\nspeaker-meaning was hopeless. \n\nRegarding Lewis’s account, critics such as Wayne Davis (2003),\nMax Kölbel (1998), Stephen Laurence (1996), and Bernard Williams\n(2002) question whether there is a convention of truthfulness and\ntrust. As Davis and Williams urge, it is hardly obvious that speakers\ngenerally speak the truth or generally trust one another, despite\nfrequent claims by diverse philosophers to the contrary. Even if we\ngrant that people generally speak the truth and generally trust one\nanother, does this give me reason to speak truthfully? It does, if\nI want other people to believe the truth. But if I want them to\nbelieve falsehoods, then I have reason to lie rather than speak the\ntruth. Thus, one might object, a regularity of truthfulness and trust\nis not self-perpetuating in the way that Lewisian convention requires.\nExpectation of conformity does not provide reason for conformity. In\ncontrast, consider the convention of driving on the right. That\nconvention likewise provides reason for conformity only given an\nappropriate desire: namely, desire to avoid a collision. The difference\nis that virtually everyone seeks to avoid a collision, while deception\nis a normal feature of ordinary linguistic interaction. \n\nInevitably, such objections focus on details of particular theories.\nThus, they cannot show that conventionalist theories in\ngeneral are mistaken. \n\nThe most serious version of this objection, advanced by Stephen\nSchiffer (1993, 2006), John Hawthorne (1990, 1993), and many other\nphilosophers, focuses on the productivity of language. We can\nunderstand a potential infinity of meaningful sentences. Yet we can\nhardly master infinitely many linguistic conventions, one for each\nmeaningful sentence. How, then, can convention fix the meanings of\nthese infinitely many sentences? \n\nThis general worry arises in a particularly acute way for Lewis’s\ntheory. Consider some sentence \\(S\\) that we would never normally\nuse, perhaps because it is too long or too grammatically\ncomplex. Suppose that some speaker nevertheless utters \\(S\\). As\nLewis acknowledges, we would not normally believe that the speaker was\nthereby attempting to speak truthfully. Instead, we would suspect that\nthe speaker was acting for some deviant reason, such as trying to\nannoy, or settling a bet, and so on. We would not normally trust the\nspeaker. But then Lewis cannot use his convention of truthfulness and\ntrust to underwrite a unique truth-condition for \\(S\\). \n\nThe most natural diagnosis here is that the sentence’s meaning is\ndetermined by the meanings of its parts. We understand it because we\nunderstand its component words and because we understand the\ncompositional mechanisms through which words combine to form meaningful\nsentences. Of course, word meanings may themselves be fixed by\nconvention. But then what the conventionalist should explicate is the\nconventional link between words and their meanings, not just the\nconventional link between sentences and their truth-conditions. Lewis\nexplicates the latter, not the former. Although Lewis (1992) attempts\nto circumvent these worries, Hawthorne (1993) and Schiffer (2006) argue\nthat his response is inadequate. \n\nLewis’s account is not alone in encountering difficulties with\nproductivity. Most contemporary conventionalist theories encounter\nsimilar difficulties, because most such theories, heeding Frege’s\ncontext principle (only the context of a sentence do words have\nmeaning), focus attention upon the link between sentences and\npropositions rather than the link between words and their meanings.\nOne might hope to supplement convention-based accounts with the\nChomsky-inspired thesis, advocated by James Higginbotham (1986) and\nRichard Larson and Gabriel Segal (1995), that speakers have tacit\nknowledge of a compositional semantic theory. However, as Martin\nDavies observes (2003), no one seems to have worked out this\nsupplementary strategy in any detail, and it is not obvious how\nimportant a role the resulting account would assign to convention, let\nalone the Gricean communicative mechanism. \n\nUltimately, the force of these worries remains unclear. For instance,\nWayne Davis (2003) develops a conventionalist account that harkens back\nto the pre-Fregean tradition. In simplified form, Davis’s Lockean\nproposal is that a word is meaningful because we conventionally use it\nto express a certain “idea”. The meaning of a sentence is then determined by the meanings of its component words, along with the (conventionally determined) semantic import of the syntactic structure in which those words are arranged. Evidently, these issues\nconnect with vexed questions about compositionality, linguistic\nunderstanding, the unity of the proposition, and the role played by\nformal semantic theories in the study of natural language. \n\nNoam Chomsky (1980) and Donald Davidson (1984) acknowledge that there\nare linguistic conventions while denying that they are fundamental to\nthe nature of language. \n\nChomsky regards language as a system of grammatical rules\n“tacitly known” by a speaker. Linguistics, which Chomsky\ntreats as a branch of cognitive psychology, studies the grammatical\ncompetence of individual speakers. It should not posit a mysterious and\nunscientific “communal language” shared by speakers, but\nshould instead focus upon “idiolects.” Thus, language has\nno special ties to social interaction or communication. Specifically,\nit has no special ties to convention. Stephen Laurence (1996) and\nStephen Schiffer (2006) develop theories of the “actual\nlanguage” relation informed by a broadly Chomskian perspective.\nThe basic idea behind both accounts is that a linguistic item as used\nby some speaker is associated with certain semantic properties just in\ncase the association between the linguistic item and the semantic\nproperty figures in the psychological processes through which the\nspeaker assigns meanings (or truth-conditions) to sentences. \n\nDavidson elaborates a model of communication that takes as its paradigm\n“radical interpretation.” During radical interpretation,\none tries to assign truth-conditions to utterances in a completely\nunfamiliar tongue. To do so, one detects patterns concerning which\nsentences the speaker “holds true,” and one tries to make\nrational sense of those patterns, guided by general maxims such as the \nprinciple of charity (roughly, maximize true beliefs on the\npart of the speaker). Davidson admits that, in everyday life, we tend\nas a default to interpret one another “homophonically.” But\nthere is no principled reason why we must embrace this homophonic\ndefault, and we readily deviate from it whenever seems appropriate, as\nillustrated by cases of idiosyncratic usage, malapropism, and so on. In\na sense, then, all linguistic understanding rests upon radical\ninterpretation. So shared linguistic conventions are inessential to\nlinguistic communication: \n\nDavidson concludes that theories of meaning and understanding should\nnot assign convention a foundational role. \n\n A\nfinal objection to convention-based theories targets the broader\nLockean strategy of explaining language in terms of thought. According\nto this objection, which is espoused by philosophers such as Robert\nBrandom (1994), Donald Davidson (1984), and Michael Dummett (1993),\nlanguage does not inherit content from thought. Rather, thought and\nlanguage are on a par, acquiring content through their mutual\ninterrelations. (One might also claim that language is the primary\nlocus of intentionality and that thought inherits content from\nlanguage. However, few if any contemporary philosophers espouse this\nviewpoint.) Thus, we should not analyze linguistic meaning as the\nproduct of convention, so long as conventions are understood as\nLewisian systems of intentions, preferences, and expectations. Those\npropositional attitudes are themselves intelligible only through their\nrelations to language. As Davidson puts it, “philosophers who\nmake convention a necessary element in language have the matter\nbackwards. The truth is rather that language is a condition for having\nconventions” (1984, p. 280). \n\nTwo main difficulties face this approach. First, although philosophers\nhave offered various arguments for the thesis that thought is not\nexplanatorily prior to language, none of the arguments commands\nwidespread assent. Christopher Peacocke (1998) forcefully criticizes\nmany of the most well-known arguments. As things stand, the objection\nconstitutes not so much a problem for conventional theories\nas a prospectus for a rival research program. The second and more\nserious difficulty is that, so far, the rival research program has not\nyielded results nearly as precise or systematic as existing\nconventional theories. Perhaps the two most commanding theories within\nthe rival research program are Davidson’s (1984) and Brandom’s\n(1994). Many contemporary philosophers feel that both theories\nenshrine an overly “anti-realist” conception of mental\ncontent. Moreover, neither theory yields detailed necessary and\nsufficient conditions for linguistic meaning analogous to those\nprovided by Lewis.","contact.mail":"rescorla@ucla.edu","contact.domain":"ucla.edu"}]
