[{"date.published":"2007-09-25","date.changed":"2017-09-26","url":"https://plato.stanford.edu/entries/philosophy-mathematics/","author1":"Leon Horsten","author1.info":"http://www.bristol.ac.uk/school-of-arts/people/leon-f-horsten/","entry":"philosophy-mathematics","body.text":"\n\n\nIf mathematics is regarded as a science, then the philosophy of\nmathematics can be regarded as a branch of the philosophy of science,\nnext to disciplines such as the philosophy of physics and the\nphilosophy of biology. However, because of its subject matter, the\nphilosophy of mathematics occupies a special place in the philosophy\nof science. Whereas the natural sciences investigate entities that are\nlocated in space and time, it is not at all obvious that this also the\ncase of the objects that are studied in mathematics. In addition to\nthat, the methods of investigation of mathematics differ markedly from\nthe methods of investigation in the natural sciences. Whereas the\nlatter acquire general knowledge using inductive methods, mathematical\nknowledge appears to be acquired in a different way: by deduction from\nbasic principles. The status of mathematical knowledge also appears to\ndiffer from the status of knowledge in the natural sciences. The\ntheories of the natural sciences appear to be less certain and more\nopen to revision than mathematical theories. For these reasons\nmathematics poses problems of a quite distinctive kind for philosophy.\nTherefore philosophers have accorded special attention to ontological\nand epistemological questions concerning mathematics.\n\nOn the one hand, philosophy of mathematics is concerned with problems\nthat are closely related to central problems of metaphysics and\nepistemology. At first blush, mathematics appears to study abstract\nentities. This makes one wonder what the nature of mathematical\nentities consists in and how we can have knowledge of mathematical\nentities. If these problems are regarded as intractable, then one\nmight try to see if mathematical objects can somehow belong to the\nconcrete world after all. \nOn the other hand, it has turned out that to some extent it is\npossible to bring mathematical methods to bear on philosophical\nquestions concerning mathematics. The setting in which this has been\ndone is that of mathematical logic when it is broadly\nconceived as comprising proof theory, model theory, set theory, and\ncomputability theory as subfields. Thus the twentieth century has\nwitnessed the mathematical investigation of the consequences of what\nare at bottom philosophical theories concerning the nature of\nmathematics. \nWhen professional mathematicians are concerned with the foundations of\ntheir subject, they are said to be engaged in foundational research.\nWhen professional philosophers investigate philosophical questions\nconcerning mathematics, they are said to contribute to the philosophy\nof mathematics. Of course the distinction between the philosophy of\nmathematics and the foundations of mathematics is vague, and the more\ninteraction there is between philosophers and mathematicians working\non questions pertaining to the nature of mathematics, the better. \nThe general philosophical and scientific outlook in the nineteenth\ncentury tended toward the empirical: platonistic aspects of\nrationalistic theories of mathematics were rapidly losing support.\nEspecially the once highly praised faculty of rational intuition of\nideas was regarded with suspicion. Thus it became a challenge to\nformulate a philosophical theory of mathematics that was free of\nplatonistic elements. In the first decades of the twentieth century,\nthree non-platonistic accounts of mathematics were developed:\nlogicism, formalism, and intuitionism. There emerged in the beginning\nof the twentieth century also a fourth program: predicativism. Due to\ncontingent historical circumstances, its true potential was not\nbrought out until the 1960s. However it deserves a place beside the\nthree traditional schools that are discussed in most standard\ncontemporary introductions to philosophy of mathematics, such as\n(Shapiro 2000) and (Linnebo 2017). \nThe logicist project consists in attempting to reduce mathematics to\nlogic. Since logic is supposed to be neutral about matters\nontological, this project seemed to harmonize with the\nanti-platonistic atmosphere of the time. \nThe idea that mathematics is logic in disguise goes back to Leibniz.\nBut an earnest attempt to carry out the logicist program in detail\ncould be made only when in the nineteenth century the basic principles\nof central mathematical theories were articulated (by Dedekind and\nPeano) and the principles of logic were uncovered (by Frege).  \nFrege devoted much of his career to trying to show how mathematics can\nbe reduced to logic (Frege 1884). He managed to derive the principles\nof (second-order) Peano arithmetic from the basic laws of a system of\nsecond-order logic. His derivation was flawless. However, he relied on\none principle which turned out not to be a logical principle after\nall. Even worse, it is untenable. The principle in question is\nFrege’s Basic Law V: \nIn words: the set of the \\(F\\)s is identical with the set of the\n\\(G\\)s iff the \\(F\\)s are precisely the \\(G\\)s. \nIn a famous letter to Frege, Russell showed that Frege’s Basic\nLaw V entails a contradiction (Russell 1902). This argument has come\nto be known as Russell’s paradox (see\n section 2.4). \nRussell himself then tried to reduce mathematics to logic in another\nway. Frege’s Basic Law V entails that corresponding to every\nproperty of mathematical entities, there exists a class of\nmathematical entities having that property. This was evidently too\nstrong, for it was exactly this consequence which led to\nRussell’s paradox. So Russell postulated that only properties of\nmathematical objects that have already been shown to exist, determine\nclasses. Predicates that implicitly refer to the class that they were\nto determine if such a class existed, do not determine a class. Thus a\ntyped structure of properties is obtained: properties of ground\nobjects, properties of ground objects and classes of ground objects,\nand so on. This typed structure of properties determines a layered\nuniverse of mathematical objects, starting from ground objects,\nproceeding to classes of ground objects, then to classes of ground\nobjects and classes of ground objects, and so on. \nUnfortunately, Russell found that the principles of his typed logic\ndid not suffice for deducing even the basic laws of arithmetic. He\nneeded, among other things, to lay down as a basic principle that\nthere exists an infinite collection of ground objects. This could\nhardly be regarded as a logical principle. Thus the second attempt to\nreduce mathematics to logic also faltered. \nAnd there matters stood for more than fifty years. In 1983, Crispin\nWright’s book on Frege’s theory of the natural numbers\nappeared (Wright 1983). In it, Wright breathes new life into the\nlogicist project. He observes that Frege’s derivation of\nsecond-order Peano Arithmetic can be broken down in two stages. In a\nfirst stage, Frege uses the inconsistent Basic Law V to derive what\nhas come to be known as Hume’s Principle: \nThe number of the \\(F\\)s = the number of the \\(G\\)s if and only if\n\\(F\\approx G\\),  \nwhere \\(F \\approx G\\) means that the \\(F\\)s and the \\(G\\)s stand in\none-to-one correspondence with each other. (This relation of\none-to-one correspondence can be expressed in second-order logic.)\nThen, in a second stage, the principles of second-order Peano\nArithmetic are derived from Hume’s Principle and the accepted\nprinciples of second-order logic. In particular, Basic Law V is\nnot needed in the second part of the derivation. Moreover,\nWright conjectured that in contrast to Frege’s Basic Law V,\nHume’s Principle is consistent. George Boolos and others\nobserved that Hume’s Principle is indeed consistent (Boolos\n1987). Wright went on to claim that Hume’s Principle can be\nregarded as a truth of logic. If that is so, then at least\nsecond-order Peano arithmetic is reducible to logic alone. Thus a new\nform of logicism was born; today this view is known as\nneo-logicism (Hale & Wright 2001). \nMost philosophers of mathematics today doubt that Hume’s\nPrinciple is a principle of logic. Indeed, even Wright has in recent\nyears sought to qualify this claim: he now argues that Hume’s\nPrinciple is analytic of our concept of number, and therefore at least\na law of reason. \nWright’s work has drawn the attention of philosophers of\nmathematics to the kind of principles of which Basic Law V and\nHume’s Principle are examples. These principles are called\nabstraction principles. At present, philosophers of\nmathematics attempt to construct general theories of abstraction\nprinciples that explain which abstraction principles are acceptable\nand which are not, and why (Weir 2003; Fine 2002). Also, it has\nemerged that in the context of weakened versions of second-order\nlogic, Frege’s Basic Law V is consistent. But these weak\nbackground theories only allow very weak arithmetical theories to be\nderived from Basic Law V (Burgess 2005). \nIntuitionism originates in the work of the mathematician L.E.J.\nBrouwer (van Atten 2004), and it is inspired by Kantian views of what\nobjects are (Parsons 2008, chapter 1). According to intuitionism,\nmathematics is essentially an activity of construction. The natural\nnumbers are mental constructions, the real numbers are mental\nconstructions, proofs and theorems are mental constructions,\nmathematical meaning is a mental construction… Mathematical\nconstructions are produced by the ideal mathematician, i.e.,\nabstraction is made from contingent, physical limitations of the real\nlife mathematician. But even the ideal mathematician remains a finite\nbeing. She can never complete an infinite construction, even though\nshe can complete arbitrarily large finite initial parts of it. This\nentails that intuitionism resolutely rejects the existence of the\nactual (or completed) infinite; only potentially infinite collections\nare given in the activity of construction. A basic example is the\nsuccessive construction in time of the individual natural numbers. \nFrom these general considerations about the nature of mathematics,\nbased on the condition of the human mind (Moore 2001), intuitionists\ninfer to a revisionist stance in logic and mathematics. They find\nnon-constructive existence proofs unacceptable. Non-constructive\nexistence proofs are proofs that purport to demonstrate the existence\nof a mathematical entity having a certain property without even\nimplicitly containing a method for generating an example of such an\nentity. Intuitionism rejects non-constructive existence proofs as\n‘theological’ and ‘metaphysical’. The\ncharacteristic feature of non-constructive existence proofs is that\nthey make essential use of the principle of excluded\nthird \nor one of its equivalents, such as the principle of double\nnegation \nIn classical logic, these principles are valid. The logic of\nintuitionistic mathematics is obtained by removing the principle of\nexcluded third (and its equivalents) from classical logic. This of\ncourse leads to a revision of mathematical knowledge. For instance,\nthe classical theory of elementary arithmetic, Peano\nArithmetic, can no longer be accepted. Instead, an intuitionistic\ntheory of arithmetic (called Heyting Arithmetic) is proposed\nwhich does not contain the principle of excluded third. Although\nintuitionistic elementary arithmetic is weaker than classical\nelementary arithmetic, the difference is not all that great. There\nexists a simple syntactical translation which translates all classical\ntheorems of arithmetic into theorems which are intuitionistically\nprovable. \nIn the first decades of the twentieth century, parts of the\nmathematical community were sympathetic to the intuitionistic critique\nof classical mathematics and to the alternative that it proposed. This\nsituation changed when it became clear that in higher mathematics, the\nintuitionistic alternative differs rather drastically from the\nclassical theory. For instance, intuitionistic mathematical analysis\nis a fairly complicated theory, and it is very different from\nclassical mathematical analysis. This dampened the enthusiasm of the\nmathematical community for the intuitionistic project. Nevertheless,\nfollowers of Brouwer have continued to develop intuitionistic\nmathematics onto the present day (Troelstra & van Dalen 1988). \nDavid Hilbert agreed with the intuitionists that there is a sense in\nwhich the natural numbers are basic in mathematics. But unlike the\nintuitionists, Hilbert did not take the natural numbers to be mental\nconstructions. Instead, he argued that the natural numbers can be\ntaken to be symbols. Symbols are strictly speaking abstract\nobjects. Nonetheless, it is essential to symbols that they can be\nembodied by concrete objects, so we may call them\nquasi-concrete objects (Parsons 2008, chapter 1). Perhaps\nphysical entities could play the role of the natural numbers. For\ninstance, we may take a concrete ink trace of the form | to be the\nnumber 0, a concretely realized ink trace || to be the number 1, and\nso on. Hilbert thought it doubtful at best that higher mathematics\ncould be directly interpreted in a similarly straightforward and\nperhaps even concrete manner. \nUnlike the intuitionists, Hilbert was not prepared to take a\nrevisionist stance toward the existing body of mathematical knowledge.\nInstead, he adopted an instrumentalist stance with respect to higher\nmathematics. He thought that higher mathematics is no more than a\nformal game. The statements of higher-order mathematics are\nuninterpreted strings of symbols. Proving such statements is no more\nthan a game in which symbols are manipulated according to fixed rules.\nThe point of the ‘game of higher mathematics’ consists, in\nHilbert’s view, in proving statements of elementary arithmetic,\nwhich do have a direct interpretation (Hilbert 1925). \nHilbert thought that there can be no reasonable doubt about the\nsoundness of classical Peano Arithmetic — or at least about the\nsoundness of a subsystem of it that is called Primitive Recursive\nArithmetic (Tait 1981). And he thought that every arithmetical\nstatement that can be proved by making a detour through higher\nmathematics, can also be proved directly in Peano Arithmetic. In fact,\nhe strongly suspected that every problem of elementary\narithmetic can be decided from the axioms of Peano Arithmetic. Of\ncourse solving arithmetical problems in arithmetic is in some cases\npractically impossible. The history of mathematics has shown that\nmaking a “detour” through higher mathematics can sometimes\nlead to a proof of an arithmetical statement that is much shorter and\nthat provides more insight than any purely arithmetical proof of the\nsame statement. \nHilbert realized, albeit somewhat dimly, that some of his convictions\ncan actually be considered to be mathematical conjectures. For a proof\nin a formal system of higher mathematics or of elementary arithmetic\nis a finite combinatorial object which can, modulo coding, be\nconsidered to be a natural number. But in the 1920s the details of\ncoding proofs as natural numbers were not yet completely\nunderstood. \nOn the formalist view, a minimal requirement of formal systems of\nhigher mathematics is that they are at least consistent. Otherwise\nevery statement of elementary arithmetic can be proved in\nthem. Hilbert also saw (again, dimly) that the consistency of a system\nof higher mathematics entails that this system is at least partially\narithmetically sound. So Hilbert and his students set out to prove\nstatements such as the consistency of the standard postulates of\nmathematical analysis. Of course such statements would have to be\nproved in a ‘safe’ part of mathematics, such as elementary\narithmetic. Otherwise the proof does not increase our conviction in\nthe consistency of mathematical analysis. And, fortunately, it seemed\npossible in principle to do this, for in the final analysis\nconsistency statements are, again modulo coding, arithmetical\nstatements. So, to be precise, Hilbert and his students set out to\nprove the consistency of, e.g., the axioms of mathematical analysis in\nclassical Peano arithmetic. This project was known as\nHilbert’s program (Zach 2006). It turned out to be more\ndifficult than they had expected. In fact, they did not even succeed\nin proving the consistency of the axioms of Peano Arithmetic in Peano\nArithmetic. \nThen Kurt Gödel proved that there exist arithmetical statements\nthat are undecidable in Peano Arithmetic (Gödel 1931). This has\nbecome known as his Gödel’s first incompleteness\ntheorem. This did not bode well for Hilbert’s program, but\nit left open the possibility that the consistency of higher\nmathematics is not one of these undecidable statements. Unfortunately,\nGödel then quickly realized that, unless (God forbid!) Peano\nArithmetic is inconsistent, the consistency of Peano Arithmetic is\nindependent of Peano Arithmetic. This is Gödel’s second\nincompleteness theorem. Gödel’s incompleteness\ntheorems turn out to be generally applicable to all sufficiently\nstrong but consistent recursively axiomatizable theories. Together,\nthey entail that Hilbert’s program fails. It turns out that\nhigher mathematics cannot be interpreted in a purely instrumental way.\nHigher mathematics can prove arithmetical sentences, such as\nconsistency statements, that are beyond the reach of Peano\nArithmetic. \nAll this does not spell the end of formalism. Even in the face of the\nincompleteness theorems, it is coherent to maintain that mathematics\nis the science of formal systems. \nOne version of this view was proposed by Curry (Curry 1958). On this\nview, mathematics consists of a collection of formal systems which\nhave no interpretation or subject matter. (Curry here makes an\nexception for metamathematics.) Relative to a formal system, one can\nsay that a statement is true if and only if it is derivable in the\nsystem. But on a fundamental level, all mathematical systems\nare on a par. There can be at most pragmatical reasons for preferring\none system over another. Inconsistent systems can prove all statements\nand therefore are pretty useless. So when a system is found to be\ninconsistent, it must be modified. It is simply a lesson from\nGödel’s incompleteness theorems that a sufficiently strong\nconsistent system cannot prove its own consistency. \nThere is a canonical objection against Curry’s formalist\nposition. Mathematicians do not in fact treat all apparently\nconsistent formal systems as being on a par. Most of them are\nunwilling to admit that the preference of arithmetical systems in\nwhich the arithmetical sentence expressing the consistency of Peano\nArithmetic are derivable over those in which its negation is\nderivable, for instance, can ultimately be explained in purely\npragmatical terms. Many mathematicians want to maintain that the\nperceived correctness (incorrectness) of certain formal systems must\nultimately be explained by the fact that they correctly (incorrectly)\ndescribe certain subject matters. \nDetlefsen has emphasized that the incompleteness theorems do not\npreclude that the consistency of parts of higher mathematics\nthat are in practice used for solving arithmetical problems that\nmathematicians are interested in can be arithmetically established\n(Detlefsen 1986). In this sense, something can perhaps be rescued from\nthe flames even if Hilbert’s instrumentalist stance towards all\nof higher mathematics is ultimately untenable. \nAnother attempt to salvage a part of Hilbert’s program was made\nby Isaacson (Isaacson 1987). He defends the view that in some\nsense, Peano Arithmetic may be complete after all (Isaacson\n1987). He argues that true sentences undecidable in Peano Arithmetic\ncan only be proved by means of higher-order concepts. For\ninstance, the consistency of Peano Arithmetic can be proved by\ninduction up to a transfinite ordinal number (Gentzen 1938). But the\nnotion of an ordinal number is a set-theoretic, and hence\nnon-arithmetical, concept. If the only ways of proving the consistency\nof arithmetic make essential use of notions which arguably belong to\nhigher-order mathematics, then the consistency of arithmetic, even\nthough it can be expressed in the language of Peano Arithmetic, is a\nnon-arithmetical problem. And generalizing from this, one can wonder\nwhether Hilbert’s conjecture that every problem of\narithmetic can be decided from the axioms of Peano Arithmetic might\nnot still be true. \nAs was mentioned earlier, predicativism is not ordinarily described as\none of the schools. But it is only for contingent reasons that before\nthe advent of the second world war predicativism did not rise to the\nlevel of prominence of the other schools. \nThe origin of predicativism lies in the work of Russell. On a cue of\nPoincaré, he arrived at the following diagnosis of the Russell\nparadox. The argument of the Russell paradox defines the collection C\nof all mathematical entities that satisfy \\(\\neg x\\in x\\). The\nargument then proceeds by asking whether C itself meets this\ncondition, and derives a contradiction. \nThe Poincaré-Russell diagnosis of this argument states that\nthis definition does not pick out a collection at all: it is\nimpossible to define a collection S by a condition that implicitly\nrefers to S itself. This is called the vicious circle\nprinciple. Definitions that violate the vicious circle principle\nare called impredicative. A sound definition of a collection\nonly refers to entities that exist independently from the defined\ncollection. Such definitions are called predicative. As\nGödel later pointed out, a platonist would find this line of\nreasoning unconvincing. If mathematical collections exist\nindependently of the act of defining, then it is not immediately clear\nwhy there could not be collections that can only be defined\nimpredicatively (Gödel 1944). \nAll this led Russell to develop the simple and the ramified theory of\ntypes, in which syntactical restrictions were built in that make\nimpredicative definitions ill-formed. In simple type theory, the free\nvariables in defining formulas range over entities to which the\ncollection to be defined do not belong. In ramified type theory, it is\nrequired in addition that the range of the bound variables in defining\nformulas do not include the collection to be defined. It was pointed\nout in\n section 2.1\n that Russell’s type theory cannot be seen as a reduction of\nmathematics to logic. But even aside from that, it was observed early\non that especially in ramified type theory it is too cumbersome to\nformalize ordinary mathematical arguments. \nWhen Russell turned to other areas of analytical philosophy, Hermann\nWeyl took up the predicativist cause (Weyl 1918). Like\nPoincaré, Weyl did not share Russell’s desire to reduce\nmathematics to logic. And right from the start he saw that it would be\nin practice impossible to work in a ramified type theory. Weyl\ndeveloped a philosophical stance that is in a sense intermediate\nbetween intuitionism and platonism. He took the collection of natural\nnumbers as unproblematically given. But the concept of an arbitrary\nsubset of the natural numbers was not taken to be immediately given in\nmathematical intuition. Only those subsets which are determined by\narithmetical (i.e., first-order) predicates are taken to be\npredicatively acceptable. \nOn the one hand, it emerged that many of the standard definitions in\nmathematical analysis are impredicative. For instance, the minimal\nclosure of an operation on a set is ordinarily defined as the\nintersection of all sets that are closed under applications of the\noperation. But the minimal closure itself is one of the sets that are\nclosed under applications of the operation. Thus, the definition is\nimpredicative. In this way, attention gradually shifted away from\nconcern about the set-theoretical paradoxes to the role of\nimpredicativity in mainstream mathematics. On the other hand, Weyl\nshowed that it is often possible to bypass impredicative notions. It\neven emerged that most of mainstream nineteenth century mathematical\nanalysis can be vindicated on a predicative basis (Feferman 1988). \nIn the 1920s, History intervened. Weyl was won over to Brouwer’s\nmore radical intuitionistic project. In the meantime, mathematicians\nbecame convinced that the highly impredicative transfinite set theory\ndeveloped by Cantor and Zermelo was less acutely threatened by\nRussell’s paradox than previously suspected. These factors\ncaused predicativism to lapse into a dormant state for several\ndecades. \nBuilding on work in generalized recursion theory, Solomon Feferman\nextended the predicativist project in the 1960s (Feferman 2005). He\nrealized that Weyl’s strategy could be iterated into the\ntransfinite. Also those sets of numbers that can be defined by using\nquantification over the sets that Weyl regarded as predicatively\njustified, should be counted as predicatively acceptable, and so on.\nThis process can be propagated along an ordinal path. This ordinal\npath stretches as far into the transfinite as the predicative\nordinals reach, where an ordinal is predicative if it measures\nthe length of a provable well-ordering of the natural numbers. This\ncalibration of the strength of predicative mathematics, which is due\nto Feferman and (independently) Schütte, is nowadays fairly\ngenerally accepted. Feferman then investigated how much of standard\nmathematical analysis can be carried out within a predicativist\nframework. The research of Feferman and others (most notably Harvey\nFriedman) shows that most of twentieth century analysis is acceptable\nfrom a predicativist point of view. But it is also clear that not all\nof contemporary mathematics that is generally accepted by the\nmathematical community is acceptable from a predicativist standpoint:\ntransfinite set theory is a case in point. \nIn the years before the second world war it became clear that weighty\nobjections had been raised against each of the three anti-platonist\nprograms in the philosophy of mathematics. Predicativism was perhaps\nan exception, but it was at the time a program without defenders. Thus\nroom was created for a renewed interest in the prospects of\nplatonistic views about the nature of mathematics. On the platonistic\nconception, the subject matter of mathematics consists of abstract\nentities. \nGödel was a platonist with respect to mathematical objects and\nwith respect to mathematical concepts (Gödel 1944; Gödel\n1964). But his platonistic view was more sophisticated than that of\nthe mathematician in the street. \nGödel held that there is a strong parallelism between plausible\ntheories of mathematical objects and concepts on the one hand, and\nplausible theories of physical objects and properties on the other\nhand. Like physical objects and properties, mathematical objects and\nconcepts are not constructed by humans. Like physical objects and\nproperties, mathematical objects and concepts are not reducible to\nmental entities. Mathematical objects and concepts are as objective as\nphysical objects and properties. Mathematical objects and concepts\nare, like physical objects and properties, postulated in order to\nobtain a good satisfactory theory of our experience. Indeed, in a way\nthat is analogous to our perceptual relation to physical objects and\nproperties, through mathematical intuition we stand in a\nquasi-perceptual relation with mathematical objects and concepts. Our\nperception of physical objects and concepts is fallible and can be\ncorrected. In the same way, mathematical intuition is not fool-proof\n— as the history of Frege’s Basic Law V shows— but\nit can be trained and improved. Unlike physical objects and\nproperties, mathematical objects do not exist in space and time, and\nmathematical concepts are not instantiated in space or time. \nOur mathematical intuition provides intrinsic evidence for\nmathematical principles. Virtually all of our mathematical knowledge\ncan be deduced from the axioms of Zermelo-Fraenkel set theory with\nthe Axiom of Choice (ZFC). In Gödel’s view, we have\ncompelling intrinsic evidence for the truth of these axioms. But he\nalso worried that mathematical intuition might not be strong enough to\nprovide compelling evidence for axioms that significantly exceed the\nstrength of ZFC. \nAside from intrinsic evidence, it is in Gödel’s view also\npossible to obtain extrinsic evidence for mathematical\nprinciples. If mathematical principles are successful, then, even if\nwe are unable to obtain intuitive evidence for them, they may be\nregarded as probably true. Gödel says that “success here\nmeans fruitfulness in consequences, particularly in\n“verifiable” consequences, i.e. consequences verifiable\nwithout the new axiom, whose proof with the help of the new axiom,\nhowever, are considerably simpler and easier to discover, and which\nmake it possible to contract into one proof many different proofs\n[…] There might exist axioms so abundant in their verifiable\nconsequences, shedding so much light on a whole field, yielding such\npowerful methods for solving problems […] that, no matter\nwhether or not they are intrinsically necessary, they would have to be\naccepted at least in the same sense as any well-established physical\ntheory” (Gödel 1947, p. 477). This inspired Gödel to\nsearch for new axioms which can be extrinsically motivated and which\ncan decide questions such as the continuum hypothesis which\nare highly independent of ZFC (cf.\n section 5.1). \nGödel shared Hilbert’s conviction that all mathematical\nquestions have definite answers. But platonism in the philosophy of\nmathematics should not be taken to be ipso facto committed to holding\nthat all set-theoretical propositions have determinate truth values.\nThere are versions of platonism that maintain, for instance, that all\ntheorems of ZFC are made true by determinate set-theoretical facts,\nbut that there are no set-theoretical facts that make certain\nstatements that are highly independent of ZFC truth-determinate. It\nseems that the famous set theorist Paul Cohen held some such view\n(Cohen 1971). \nQuine formulated a methodological critique of traditional philosophy.\nHe suggested a different philosophical methodology instead, which has\nbecome known as naturalism (Quine 1969). According to\nnaturalism, our best theories are our best scientific\ntheories. If we want to obtain the best available answer to\nphilosophical questions such as What do we know? and\nWhich kinds of entities exist?, we should not appeal to\ntraditional epistemological and metaphysical theories. We should also\nrefrain from embarking on a fundamental epistemological or\nmetaphysical inquiry starting from first principles. Rather, we should\nconsult and analyze our best scientific theories. They contain, albeit\noften implicitly, our currently best account of what exists, what we\nknow, and how we know it. \nPutnam applied Quine’s naturalistic stance to mathematical\nontology (Putnam 1972). At least since Galilei, our best theories from\nthe natural sciences are mathematically expressed. Newton’s\ntheory of gravitation, for instance, relies heavily on the classical\ntheory of the real numbers. Thus an ontological commitment to\nmathematical entities seems inherent to our best scientific theories.\nThis line of reasoning can be strengthened by appealing to the Quinean\nthesis of confirmational holism. Empirical evidence does not bestow\nits confirmatory power on any one individual hypothesis. Rather,\nexperience globally confirms the theory in which the individual\nhypothesis is embedded. Since mathematical theories are part and\nparcel of scientific theories, they too are confirmed by experience.\nThus, we have empirical confirmation for mathematical theories. Even\nmore appears true. It seems that mathematics is indispensable to our\nbest scientific theories: it is not at all obvious how we\ncould express them without using mathematical vocabulary.\nHence the naturalist stance commands us to accept mathematical\nentities as part of our philosophical ontology. This line of\nargumentation is called an indispensability argument (Colyvan\n2001). \nIf we take the mathematics that is involved in our best scientific\ntheories at face value, then we appear to be committed to a form of\nplatonism. But it is a more modest form of platonism than\nGödel’s platonism. For it appears that the natural sciences\ncan get by with (roughly) function spaces on the real numbers. The\nhigher regions of transfinite set theory appear to be largely\nirrelevant to even our most advanced theories in the natural sciences.\nNevertheless, Quine thought (at some point) that the sets that are\npostulated by ZFC are acceptable from a naturalistic point of view;\nthey can be regarded as a generous rounding off of the mathematics\nthat is involved in our scientific theories. Quine’s judgement\non this matter is not universally accepted. Feferman, for instance,\nargues that all the mathematical theories that are essentially used in\nour currently best scientific theories are predicatively reducible\n(Feferman 2005). Maddy even argues that naturalism in the philosophy\nof mathematics is perfectly compatible with a non-realist view about\nsets (Maddy 2007, part IV).  \nIn Quine’s philosophy, the natural sciences are the ultimate\narbiters concerning mathematical existence and mathematical truth.\nThis has led Charles Parsons to object that this picture makes the\nobviousness of elementary mathematics somewhat mysterious (Parsons\n1980). For instance, the question whether every natural number has a\nsuccessor ultimately depends, in Quine’s view, on our best\nempirical theories; however, somehow this fact appears more immediate\nthan that. In a kindred spirit, Maddy notes that mathematicians do not\ntake themselves to be in any way restricted in their activity by the\nnatural sciences. Indeed, one might wonder whether mathematics should\nnot be regarded as a science in its own right, and whether the\nontological commitments of mathematics should not be judged rather on\nthe basis of the rational methods that are implicit in mathematical\npractice. \nMotivated by these considerations, Maddy set out to inquire into the\nstandards of existence implicit in mathematical practice, and into the\nimplicit ontological commitments of mathematics that follow from these\nstandards (Maddy 1990). She focussed on set theory, and on the\nmethodological considerations that are brought to bear by the\nmathematical community on the question which large cardinal axioms can\nbe taken to be true. Thus her view is closer to that of Gödel\nthan to that of Quine. In more recent work, she isolates two maxims\nthat seem to be guiding set theorists when contemplating the\nacceptability of new set theoretic principles: unify and\nmaximize (Maddy 1997). The maxim “unify” is an\ninstigation for set theory to provide a single system in which all\nmathematical objects and structures of mathematics can be instantiated\nor modelled. The maxim “maximize” means that set theory\nshould adopt set theoretic principles that are as powerful and\nmathematically fruitful as possible. \nBernays observed that when a mathematician is at work she\n“naively” treats the objects she is dealing with in a\nplatonistic way. Every working mathematician, he says, is a platonist\n(Bernays 1935). But when the mathematician is caught off duty by a\nphilosopher who quizzes her about her ontological commitments, she is\napt to shuffle her feet and withdraw to a vaguely non-platonistic\nposition. This has been taken by some to indicate that there is\nsomething wrong with philosophical questions about the nature of\nmathematical objects and of mathematical knowledge. \nCarnap introduced a distinction between questions that are internal to\na framework and questions that are external to a framework (Carnap\n1950). Tait has worked out in detail how something like this\ndistinction can be applied to mathematics (Tait 2005). This has\nresulted in what might be regarded as a deflationary version of\nplatonism. \nAccording to Tait, questions of existence of mathematical entities can\nonly be sensibly asked and reasonably answered from within (axiomatic)\nmathematical frameworks. If one is working in number theory, for\ninstance, then one can ask whether there are prime numbers that have a\ngiven property. Such questions are then to be decided on purely\nmathematical grounds. \nPhilosophers have a tendency to step outside the framework of\nmathematics and ask “from the outside” whether\nmathematical objects really exist and whether mathematical\npropositions are really true. In this question they are\nasking for supra-mathematical or metaphysical grounds for mathematical\ntruth and existence claims. Tait argues that it is hard to see how any\nsense can be made of such external questions. He attempts to deflate\nthem, and bring them back to where they belong: to mathematical\npractice itself. Of course not everyone agrees with Tait on this\npoint. Linsky and Zalta have developed a systematic way of answering\nprecisely the sort of external questions that Tait approaches with\ndisdain (Linsky & Zalta 1995).  \nIt comes as no surprise that Tait has little use for Gödelian\nappeals to mathematical intuition in the philosophy of mathematics, or\nfor the philosophical thesis that mathematical objects exist\n“outside space and time”. More generally, Tait believes\nthat mathematics is not in need of a philosophical foundation; he\nwants to let mathematics speak for itself. In this sense, his position\nis reminiscent of the (in some sense Wittgensteinian) natural\nontological attitude that is advocated by Arthur Fine in the\nrealism debate in the philosophy of science. \nBenacerraf formulated an epistemological problem for a variety of\nplatonistic positions in the philosophy of science (Benacerraf 1973).\nThe argument is specifically directed against accounts of mathematical\nintuition such as that of Gödel. Benacerraf’s argument\nstarts from the premise that our best theory of knowledge is the\ncausal theory of knowledge. It is then noted that according to\nplatonism, abstract objects are not spatially or temporally localized,\nwhereas flesh and blood mathematicians are spatially and temporally\nlocalized. Our best epistemological theory then tells us that\nknowledge of mathematical entities should result from causal\ninteraction with these entities. But it is difficult to imagine how\nthis could be the case. \nToday few epistemologists hold that the causal theory of knowledge is\nour best theory of knowledge. But it turns out that Benacerraf’s\nproblem is remarkably robust under variation of epistemological\ntheory. For instance, let us assume for the sake of argument that\nreliabilism is our best theory of knowledge. Then the problem becomes\nto explain how we succeed in obtaining reliable beliefs about\nmathematical entities. \nHodes has formulated a semantical variant of Benacerraf’s\nepistemological problem (Hodes 1984). According to our currently best\nsemantic theory, causal-historical connections between humans and the\nworld of concreta enable our words to refer to physical entities and\nproperties. According to platonism, mathematics refers to abstract\nentities. The platonist therefore owes us a plausible account of how\nwe (physically embodied humans) are able to refer to them. On the face\nof it, it appears that the causal theory of reference will be unable\nto supply us with the required account of the ‘microstructure of\nreference’ of mathematical discourse. \nA version of platonism has been developed which is intended to provide\na solution to Benacerraf’s epistemological problem (Linsky &\nZalta 1995; Balaguer 1998). This position is known as\nplenitudinous platonism. The central thesis of this theory is\nthat every logically consistent mathematical theory\nnecessarily refers to an abstract entity. Whether the\nmathematician who formulated the theory knows that it refers or does\nnot know this, is largely immaterial. By entertaining a consistent\nmathematical theory, a mathematician automatically acquires knowledge\nabout the subject matter of the theory. So, on this view, there is no\nepistemological problem to solve anymore. \nIn Balaguer’s version, plenitudinous platonism postulates a\nmultiplicity of mathematical universes, each corresponding to a\nconsistent mathematical theory. Thus, in particular a question such as\nthe continuum problem (cf.\n section 5.1)\n does not receive a unique answer: in some set-theoretical universes\nthe continuum hypothesis holds, in others it fails to hold. However,\nnot everyone agrees that this picture can be maintained. Martin has\ndeveloped an argument to show that multiple universes can always to a\nlarge extent be “accumulated” into a single universe\n(Martin 2001). \nIn Linsky and Zalta’s version of plenitudinous platonism, the\nmathematical entity that is postulated by a consistent mathematical\ntheory has exactly the mathematical properties which are attributed to\nit by the theory. The abstract entity corresponding to ZFC, for\ninstance, is partial in the sense that it neither makes the\ncontinuum hypothesis true nor false. The reason is that ZFC neither\nentails the continuum hypothesis nor its negation. This does not\nentail that all ways of consistently extending ZFC are on a par. Some\nways may be fruitful and powerful, others less so. But the view does\ndeny that certain consistent ways of extending ZFC are preferable\nbecause they consist of true principles, whereas others contain false\nprinciples.  \nBenacerraf’s work motivated philosophers to develop both\nstructuralist and nominalist theories in the philosophy of mathematics\n(Reck & Price 2000). And since the late 1980s, combinations of\nstructuralism and nominalism have also been developed. \nAs if saddling platonism with one difficult problem were not enough\n (section 3.4),\n Benacerraf formulated a challenge for set-theoretic platonism\n(Benacerraf 1965). The challenge takes the following form. \nThere exist infinitely many ways of identifying the natural numbers\nwith pure sets. Let us restrict, without essential loss of generality,\nour discussion to two such ways: \nThe simple question that Benacerraf asks is: \nWhich of these consists solely of true identity statements: I or\nII? \nIt seems very difficult to answer this question. It is not hard to see\nhow a successor function and addition and multiplication operations\ncan be defined on the number-candidates of I and on the\nnumber-candidates of II so that all the arithmetical statements that\nwe take to be true come out true. Indeed, if this is done in the\nnatural way, then we arrive at isomorphic structures (in the\nset-theoretic sense of the word), and isomorphic structures make the\nsame sentences true (they are elementarily equivalent). It is\nonly when we ask extra-arithmetical questions, such as ‘\\(1 \\in\n3\\)?’ that the two accounts of the natural numbers yield\ndiverging answers. So it is impossible that both accounts are correct.\nAccording to story I, \\(3 = \\{\\{\\{\\varnothing \\}\\}\\}\\), whereas\naccording to story II, \\(3 = \\{\\varnothing , \\{\\varnothing \\},\n\\{\\varnothing , \\{\\varnothing \\}\\}\\}\\). If both accounts were correct,\nthen the transitivity of identity would yield a purely set theoretic\nfalsehood. \nSumming up, we arrive at the following situation. On the one hand,\nthere appear to be no reasons why one account is superior to the\nother. On the other hand, the accounts cannot both be correct. This\npredicament is sometimes called labelled Benacerraf’s\nidentification problem. \nThe proper conclusion to draw from this conundrum appears to be that\nneither account I nor account II is correct. Since similar\nconsiderations would emerge from comparing other reasonable-looking\nattempts to reduce natural numbers to sets, it appears that natural\nnumbers are not sets after all. It is clear, moreover, that a similar\nargument can be formulated for the rational numbers, the real\nnumbers… Benacerraf concludes that they, too, are not sets at\nall. \nIt is not at all clear whether Gödel, for instance, is committed\nto reducing the natural numbers to pure sets. A platonist can uphold\nthe claim that the natural numbers can be embedded into the\nset-theoretic universe while maintaining that the embedding should not\nbe seen as an ontological reduction. Indeed, on Linsky and\nZalta’s plenitudinous platonist account, the natural numbers\nhave no properties beyond those that are attributed to them by our\ntheory of the natural numbers (Peano Arithmetic). But then it seems\nthat platonists would have to take a similar line with respect to the\nrational numbers, the complex numbers, …. Whereas maintaining\nthat the natural numbers are sui generis admittedly has some appeal,\nit is perhaps less natural to maintain that the complex numbers, for\ninstance, are also sui generis. And, anyway, even if the natural\nnumbers, the complex numbers, … are in some sense not reducible\nto anything else, one may wonder if there may not be another way to\nelucidate their nature. \nShapiro draws a useful distinction between algebraic and\nnon-algebraic mathematical theories (Shapiro 1997). Roughly,\nnon-algebraic theories are theories which appear at first sight to be\nabout a unique model: the intended model of the theory. We\nhave seen examples of such theories: arithmetic, mathematical\nanalysis… Algebraic theories, in contrast, do not carry a prima\nfacie claim to be about a unique model. Examples are group theory,\ntopology, graph theory… \nBenacerraf’s challenge can be mounted for the objects that\nnon-algebraic theories appear to describe. But his challenge does not\napply to algebraic theories. Algebraic theories are not interested in\nmathematical objects per se; they are interested in structural aspects\nof mathematical objects. This led Benacerraf to speculate whether the\nsame could not be true also of non-algebraic theories. Perhaps the\nlesson to be drawn from Benacerraf’s identification problem is\nthat even arithmetic does not describe specific mathematical objects,\nbut instead only describes structural relations? \nShapiro and Resnik hold that all mathematical theories, even\nnon-algebraic ones, describe structures. This position is\nknown as structuralism (Shapiro 1997; Resnik 1997). Structures\nconsists of places that stand in structural relations to each other.\nThus, derivatively, mathematical theories describe places or positions\nin structures. But they do not describe objects. The number three, for\ninstance, will on this view not be an object but a place in the\nstructure of the natural numbers. \nSystems are instantiations of structures. The systems that\ninstantiate the structure that is described by a non-algebraic theory\nare isomorphic with each other, and thus, for the purposes of the\ntheory, equally good. The systems I and II that were described in\n section 4.1\n can be seen as instantiations of the natural number structure.\n\\(\\{\\{\\{\\varnothing \\}\\}\\}\\) and \\(\\{\\varnothing , \\{\\varnothing \\},\n\\{\\varnothing , \\{\\varnothing \\}\\}\\}\\) are equally suitable for\nplaying the role of the number three. But neither are the\nnumber three. For the number three is an open place in the natural\nnumber structure, and this open place does not have any internal\nstructure. Systems typically contain structural properties over and\nabove those that are relevant for the structures that they are taken\nto instantiate. \nSensible identity questions are those that can be asked from within a\nstructure. They are those questions that can be answered on the basis\nof structural aspects of the structure. Identity questions that go\nbeyond a structure do not make sense. One can pose the question\nwhether \\(3 \\in 4\\), but not cogently: this question involves a\ncategory mistake. The question mixes two different structures: \\(\\in\\)\nis a set-theoretical notion, whereas 3 and 4 are places in the\nstructure of the natural numbers. This seems to constitute a\nsatisfactory answer to Benacerraf’s challenge. \nIn Shapiro’s view, structures are not ontologically dependent on\nthe existence of systems that instantiate them. Even if there were no\ninfinite systems to be found in Nature, the structure of the natural\nnumbers would exist. Thus structures as Shapiro understands them are\nabstract, platonic entities. Shapiro’s brand of structuralism is\noften labeled ante rem structuralism. \nIn textbooks on set theory we also find a notion of structure.\nRoughly, the set theoretic definition says that a structure is an\nordered \\(n+1\\)-tuple consisting of a set, a number of relations on\nthis set, and a number of distinguished elements of this set. But this\ncannot be the notion of structure that structuralism in the philosophy\nof mathematics has in mind. For the set theoretic notion of structure\npresupposes the concept of set, which, according to structuralism,\nshould itself be explained in structural terms. Or, to put the point\ndifferently, a set-theoretical structure is merely a system\nthat instantiates a structure that is ontologically prior to it. \nNonetheless, the motivation for extending ante rem structuralism even\nto the most encompassing mathematical discipline (set theory) is not\nentirely evident (Burgess 2015). Recall that the main motivation for\narriving at a structuralist understanding of a mathematical discipline\nlies in Benacerraf’s identification problem. For set theory, it\nseems hard to mount an identification challenge: sets are not usually\ndefined in terms of more primitive concepts. \nIt appears that ante rem structuralism describes the notion\nof a structure in a somewhat circular manner. A structure is described\nas places that stand in relation to each other, but a place cannot be\ndescribed independently of the structure to which it belongs. Yet this\nis not necessarily a problem. For the ante rem structuralist,\nthe notion of structure is a primitive concept, which cannot be\ndefined in other more basic terms. At best, we can construct an\naxiomatic theory of mathematical structures. \nBut Benacerraf’s epistemological problem still appears to be\nurgent. Structures and places in structures may not be objects, but\nthey are abstract. So it is natural to wonder how we succeed in\nobtaining knowledge of them. This problem has been taken by certain\nphilosophers as a reason for developing a nominalist theory of\nmathematics and then to reconcile this theory with basic tenets of\nstructuralism. \nGoodman and Quine tried early on to bite the bullet: they embarked on\na project to reformulate theories from natural science without making\nuse of abstract entities (Goodman & Quine 1947). The nominalistic\nreconstruction of scientific theories proved to be a difficult task.\nQuine, for one, abandoned it after this initial attempt. In the past\ndecades many theories have been proposed that purport to give a\nnominalistic reconstruction of mathematics. (Burgess & Rosen 1997)\ncontains a good critical discussion of such views. \nIn a nominalist reconstruction of mathematics, concrete entities will\nhave to play the role that abstract entities play in platonistic\naccounts of mathematics, and concrete relations (such as the\npart-whole relation) have to be used to simulate mathematical\nrelations between mathematical objects. But here problems arise.\nFirst, already Hilbert observed that, given the discretization of\nnature in quantum mechanics, the natural sciences may in the end claim\nthat there are only finitely many concrete entities (Hilbert 1925).\nYet it seems that we would need infinitely many of them to play the\nrole of the natural numbers — never mind the real numbers. Where\ndoes the nominalist find the required collection of concrete entities?\nSecondly, even if the existence of infinitely many concrete objects is\nassumed, it is not clear that even elementary mathematical theories\nsuch as Primitive Recursive Arithmetic can be “simulated”\nby means of nominalistic relations (Niebergall 2000). \nField made an earnest attempt to carry out a nominalistic\nreconstruction of Newtonian mechanics (Field 1980). The basic idea is\nthis. Field wanted to use concrete surrogates of the real numbers and\nfunctions on them. He adopted a realist stance toward the spatial\ncontinuum, and took regions of space to be as physically real as\nchairs and tables. And he took regions of space to be concrete (after\nall, they are spatially located). If we also count the very\ndisconnected ones, then there are as many regions of Newtonian space\nas there are subsets of the real numbers. And then there are enough\nconcrete entities to play the role of the natural numbers, the real\nnumbers, and functions on the real numbers. And the theory of the real\nnumbers and functions on them is all that is needed to formulate\nNewtonian mechanics. Of course it would be even more interesting to\nhave a nominalistic reconstruction of a truly contemporary scientific\ntheory such as Quantum Mechanics. But given that the project can be\ncarried out for Newtonian mechanics, some degree of initial optimism\nseems justified. \nThis project clearly has its limitations. It may be possible\nnominalistically to interpret theories of function spaces on the real\nnumbers, say. But it seems far-fetched to think that along Fieldian\nlines a nominalistic interpretation of set theory can be found.\nNevertheless, if it is successful within its confines, then\nField’s program has really achieved something. For it would mean\nthat, to some extent at least, mathematical entities appear to be\ndispensable after all. He would thereby have taken an important step\ntowards undermining the indispensability argument for Quinean modest\nplatonism in mathematics, for, to some extent, mathematical entities\nappear to be dispensable after all. \nField’s strategy only has a chance of working if Hilbert’s\nfear that in a very fundamental sense our best scientific theories may\nentail that there are only finitely many concrete entities, is\nill-founded. If one sympathizes with Hilbert’s concern but does\nnot believe in the existence of abstract entities, then one might bite\nthe bullet and claim that there are only finitely many\nmathematical entities, thus contradicting the basic\nprinciples of elementary arithmetic. This leads to a position that has\nbeen called ultra-finitism (Essenin-Volpin 1961). \nOn most accounts, ultra-finitism leads, like intuitionism, to\nrevisionism in mathematics. For it would seem that one would then have\nto say that there is a largest natural number, for instance. From the\noutside, a theory postulating only a finite mathematical universe\nappears proof-theoretically weak, and therefore very likely to be\nconsistent. But Woodin has developed an argument that purports to show\nthat from the ultra-finitist perspective, there are no grounds for\nasserting that the ultra-finitist theory is likely to be consistent\n(Woodin 2011).  \nRegardless of this argument (the details of which are not discussed\nhere), many already find the assertion that there is a largest number\nhard to swallow. But Lavine has articulated a sophisticated form of\nset-theoretical ultra-finitism which is mathematically non-revisionist\n(Lavine 1994). He has developed a detailed account of how the\nprinciples of ZFC can be taken to be principles that describe\ndeterminately finite sets, if these are taken to include indefinitely\nlarge ones. \nField’s physicalist interpretation of arithmetic and analysis\nnot only undermines the Quine-Putnam indispensability argument. It\nalso partially provides an answer to Benacerraf’s\nepistemological challenge. Admittedly it is not a simple task to give\nan account of how humans obtain knowledge of spacetime regions. But at\nleast according to many (but not all) philosophers spacetime regions\nare physically real. So we are no longer required to explicate how\nflesh and blood mathematicians stand in contact with non-physical\nentities. But Benacerraf’s identification problem remains. One\nmay wonder why one spacetime point or region rather than another plays\nthe role of the number \\(\\pi\\), for instance. \nIn response to the identification problem, it seems attractive to\ncombine a structuralist approach with Field’s nominalism. This\nleads to versions of nominalist structuralism, which can be\noutlined as follows. Let us focus on mathematical analysis. The\nnominalist structuralist denies that any concrete physical system is\nthe unique intended interpretation of analysis. All concrete physical\nsystems that satisfy the basic principles of Real Analysis (RA) would\ndo equally well. So the content of a sentence \\(\\phi\\) of the language\nof analysis is (roughly) given by: \nEvery concrete system S that makes RA true, also makes \\(\\phi\\) true.\n \nThis entails that, as with ante rem structuralism, only\nstructural aspects are relevant to the truth or falsehood of\nmathematical statements. But unlike ante rem structuralism,\nno abstract structure is postulated above and beyond concrete\nsystems. \nAccording to in rebus structuralism, no abstract structures\nexist over and above the systems that instantiate them; structures\nexist only in the systems that instantiate them. For this\nreason nominalist in rebus structuralism is sometimes\ndescribed as “structuralism without structures”.\nNominalist structuralism is a form of in rebus structuralism.\nBut in rebus structuralism is not exhausted by nominalist\nstructuralism. Even the version of platonism that takes mathematics to\nbe about structures in the set-theoretic sense of the word can be\nviewed as a form of in rebus structuralism. \nIn mathematical discourse, non-algebraic structures (such as\n‘the’ natural numbers) and mathematical objects (such as\n‘the’ number 1) are referred to by definite descriptions.\nThis strongly suggests that mathematical symbols (N, 1) have a unique\nreference rather than a ‘distributed’ one as in\nrebus structuralism would have it. But in rebus\nstructuralists argue that such mathematical symbols function as\ndedicated variables in much the same way as in ‘Tommy\nneeds his letters from home’, a world war II slogan, the name\n‘Tommy’ is chosen to stand for some arbitrary concrete\nsoldier, and re-used on many occasions without changing its reference\n(Pettigrew 2008).  \nIf Hilbert’s worry is wellfounded in the sense that there are no\nconcrete physical systems that make the postulates of mathematical\nanalysis true, then the above nominalist structuralist rendering of\nthe content of a sentence \\(\\phi\\) of the language of analysis gets\nthe truth conditions of such sentences wrong. For then for\nevery universally quantified sentence \\(\\phi\\), its\nparaphrase will come out vacuously true. So an existential assumption\nto the effect that there exist concrete physical systems that can\nserve as a model for RA is needed to back up the above analysis of the\ncontent of mathematical statements. Perhaps something like\nField’s construction fits the bill. \nPutnam noticed early on that if the above explication of the content\nof mathematical sentences is modified somewhat, a substantially weaker\nbackground assumption is sufficient to obtain the correct truth\nconditions (Putnam 1967). Putnam proposed the following modal\nrendering of the content of a sentence \\(\\phi\\) of the language of\nanalysis: \nNecessarily, every concrete system S that makes RA true, also\nmakes \\(\\phi\\) true.  \nThis is a stronger statement than the nonmodal rendering that was\npresented earlier. But it seems equally plausible. And an advantage of\nthis rendering is that the following modal existential background\nassumption is sufficient to make the truth conditions of mathematical\nstatements come out right: \nIt is possible that there exists a concrete physical system\nthat can serve as a model for RA.  \n(‘It is possible that’ here means ‘It is or might\nhave been the case that’.) Now Hilbert’s concern seems\nadequately addressed. For on Putnam’s account, the truth of\nmathematical sentences no longer depends on physical assumptions about\nthe actual world. \nIt is admittedly not easy to give a satisfying account of how we\nknow that this modal existential assumption is fulfilled. But\nit may be hoped that the task is less daunting than the task of\nexplaining how we succeed in knowing facts about abstract entities.\nAnd it should not be forgotten that the structuralist aspect of this\n(modal) nominalist position keeps Benacerraf’s identification\nchallenge at bay. \nPutnam’s strategy also has its limitations. Chihara sought to\napply Putnam’s strategy not only to arithmetic and analysis but\nalso to set theory (Chihara 1973). Then a crude version of the\nrelevant modal existential assumption becomes: \nIt is possible that there exist concrete physical systems\nthat can serve as a model for ZFC.  \nParsons has noted that when possible worlds are needed which contain\ncollections of physical entities that have large transfinite\ncardinalities or perhaps are even too large to have a cardinal number,\nit becomes hard to see these as possible concrete or physical systems\n(Parsons 1990a). We seem to have no reason to believe that there could\nbe physical worlds that contain highly transfinitely many\nentities. \nAccording to the previous proposals, the statements of ordinary\nmathematics are true when suitably, i.e., nominalistically,\ninterpreted. The nominalistic account of mathematics that will now be\ndiscussed holds that all existential mathematical statements are false\nsimply because there are no mathematical entities. (For the same\nreason all universal mathematical statements will be trivially\ntrue.) \nFictionalism holds that mathematical theories are like fiction stories\nsuch as fairy tales and novels. Mathematical theories describe\nfictional entities, in the same way that literary fiction describes\nfictional characters. This position was first articulated in the\nintroductory chapter of (Field 1989), and has in recent years been\ngaining in popularity. \nThis crude description of the fictionalist position immediately opens\nup the question what sort of entities fictional entities are. This\nappears to be a deep metaphysical ontological problem. One way to\navoid this question altogether is to deny that there exist fictional\nentities. Mathematical theories should be viewed as invitations to\nparticipate in games of pretence, in which we act as if certain\nmathematical entities exist. Pretence or make-believe operators shield\ntheir propositional objects from existential exportation (Leng\n2010). \nAnyway, as said above, on the fictionalist view, a mathematical theory\nisn’t literally true. Nonetheless, mathematics is used to get\ntruths across. So we must subtract something from what is\nliterally said when we assert a physical theory that involves\nmathematics, if we want to get at the truth. But this requires a\ntheory of how this subtraction of content works. Such a\ntheory has been developed in (Yablo, 2014).  \nIf the fictionalist thesis is correct, then one demand that must be\nimposed on mathematical theories is surely consistency. Yet Field adds\nto this a second requirement: mathematics must be\nconservative over natural science. This means, roughly, that\nwhenever a statement of an empirical theory can be derived using\nmathematics, it can in principle also be derived without using any\nmathematical theories. If this were not the case, then an\nindispensability argument could be played out against fictionalism.\nWhether mathematics is in fact conservative over physics, for\ninstance, is currently a matter of controversy. Shapiro has formulated\nan incompleteness argument that intends to refute Field’s claim\n(Shapiro 1983). \nIf there are indeed no mathematical (fictional) entities, as one form\nof fictionalism has it, then Benacerraf’s epistemological\nproblem does not arise. Fictionalism then shares this advantage over\nmost forms of platonism with nominalistic reconstructions of\nmathematics. But the appeal to pretence operators entails that the\nlogical form of mathematical sentences then differs somewhat from\ntheir surface form. If there are fictional objects, then the surface\nform of mathematical sentences can be taken to coincide with their\nlogical form. But if they exist as abstract entities, then\nBenacerraf’s epistemological problem reappears. \nWhether Benacerraf’s identification problem is solved is not\ncompletely clear. In general, fictionalism is a non-reductionist\naccount. Whether an entity in one mathematical theory is identical\nwith an entity that occurs in another theory is usually left\nindeterminate by mathematical “stories”. Yet Burgess has\nrightly emphasized that mathematics differs from literary fiction in\nthe fact that fictional characters are usually confined to one work of\nfiction, whereas the same mathematical entities turn up in diverse\nmathematical theories (Burgess 2004). After all, entities with the\nsame name (such as \\(\\pi)\\) turn up in different theories.\nPerhaps the fictionalist can maintain that when mathematicians develop\na new theory in which an “old” mathematical entity occurs,\nthe entity in question is made more precise. More determinate\nproperties are ascribed to it than before, and this is all right as\nlong as overall consistency is maintained.  \nThe canonical objection to formalism seems also applicable to\nfictionalism. The fictionalists should find some explanation of the\nfact that extending a mathematical theory in one way, is often\nconsidered preferable over continuing it in a another way that is\nincompatible with the first. There is often at least an appearance\nthat there is a right way to extend a mathematical theory. \nIn recent years, subdisciplines of the philosophy of mathematics have\nstarted to arise. They evolve in a way that is not completely\ndetermined by the “big debates” about the nature of\nmathematics. In this section, we look at a few of these\ndisciplines. \nMany regard set theory as in some sense the foundation of mathematics.\nIt seems that just about any piece of mathematics can be carried out\nin set theory, even though it is sometimes an awkward setting for\ndoing so. In recent years, the philosophy of set theory is emerging as\na philosophical discipline of its own. This is not to say that in\nspecific debates in the philosophy of set theory it cannot make an\nenormous difference whether one approaches it from a formalistic point\nof view or from a platonistic point of view, for instance. \nThe thesis that set theory is most suitable for serving as the\nfoundations of mathematics is by no means uncontroversial. Over the\npast decades, category theory has presented itself as a rival\nfor this role. Category theory is a mathematical theory that was\ndeveloped in the middle of the twentieth century. Unlike in set\ntheory, in category theory mathematical objects are only\ndefined up to isomorphism. This means that Benacerraf’s\nidentification problem cannot be raised for category theoretical\nconcepts and ‘objects’. At the same time, (roughly)\neverything that can be done in set theory can be done in category\ntheory (but not always in a natural manner), and vice versa (again not\nalways in a natural manner). This means that for a structuralist\nperspective, category theory is an attractive candidate for providing\nthe foundations of mathematics (McLarty 2004). \nOne question that has been important from the beginning of set theory\nconcerns the difference between sets and proper classes. (This\nquestion has a natural counterpart for category theory: the difference\nbetween small and large categories.) Cantor’s diagonal argument\nforces us to recognize that the set-theoretical universe as a whole\ncannot be regarded as a set. Cantor’s Theorem shows that the\npower set (i.e., the set of all subsets) of any given set has a larger\ncardinality than the given set itself. Now suppose that the\nset-theoretical universe forms a set: the set of all sets. Then the\npower set of the set of all sets would have to be a subset of the set\nof all sets. This would contradict the fact that the power set of the\nset of all sets would have a larger cardinality than the set of all\nsets. So we must conclude that the set-theoretical universe cannot\nform a set. \nCantor called pluralities that are too large to be considered as a set\ninconsistent multiplicities (Cantor 1932). Today,\nCantor’s inconsistent multiplicities are called proper\nclasses. Some philosophers of mathematics hold that proper\nclasses still constitute unities, and hence can be seen as a sort of\ncollection. They are, in a Cantorian spirit, just collections that are\ntoo large to be sets. Nevertheless, there are problems with this view.\nJust as there can be no set of all sets, there can for diagonalization\nreasons also not be a proper class of all proper classes. So the\nproper class view seems compelled to recognize in addition a realm of\nsuper-proper classes, and so on. For this reason, Zermelo claimed that\nproper classes simply do not exist. This position is less strange than\nit looks at first sight. On close inspection, one sees that in ZFC one\nnever needs to quantify over entities that are too large to be sets\n(although there exist systems of set theory that do quantify over\nproper classes). On this view, the set-theoretical universe is\npotentially infinite in an absolute sense of the word. It never exists\nas a completed whole, but is forever growing, and hence forever\nunfinished (Zermelo 1930). This way of speaking indicates that in our\nattempts to understand this notion of potential infinity, we are drawn\nto temporal metaphors. It is not surprising that these temporal\nmetaphors cause some philosophers of mathematics acute discomfort. \nA second subject in the philosophy of set theory concerns the\njustification of the accepted basic principles of mathematics, i.e.,\nthe axioms of ZFC. An important historical case study is the process\nby which the Axiom of Choice came to be accepted by the mathematical\ncommunity in the early decades of the twentieth century (Moore 1982).\nThe importance of this case study is largely due to the fact that an\nopen and explicit discussion of its acceptability was held in the\nmathematical community. In this discussion, general reasons for\naccepting or refusing to accept a principle as a basic axiom came to\nthe surface. On the systematic side, two conceptions of the notion of\nset have been elaborated which aim to justify all axioms of ZFC in one\nfell swoop. On the one hand, there is the iterative\nconception of sets, which describes how the set-theoretical\nuniverse can be thought of as generated from the empty set by means of\nthe power set operation (Boolos 1971, Linnebo 2013). On the other\nhand, there is the limitation of size conception of sets,\nwhich states that every collection which is not too big to be a set,\nis a set (Hallett 1984). The iterative conception motivates some\naxioms of ZFC very well (the power set axiom, for instance), but fares\nless well with respect to other axioms, such as the replacement axiom\n(Potter 2004, Part IV). The limitation of size conception motivates\nother axioms better (such as the restricted comprehension axiom). It\nseems fair to say that there is no uniform conception that\nclearly justifies all axioms of ZFC. \nThe motivation of putative axioms that go beyond ZFC constitutes a\nthird concern of the philosophy of set theory (Maddy 1988; Martin\n1998). One such class of principles is constituted by the large\ncardinal axioms. Nowadays, large cardinal hypotheses are really\ntaken to mean some kind of embedding properties between the set\ntheoretic universe and inner models of set theory. Most of the time,\nlarge cardinal principles entail the existence of sets that are larger\nthan any sets which can be guaranteed by ZFC to exist. \nThe weaker of the large cardinal principles are supported by intrinsic\nevidence (see\n section 3.1).\n They follow from what are called reflection principles.\nThese are principles that state that the set theoretic universe as a\nwhole is so rich that it is very similar to some set-sized initial\nsegment of it. The stronger of the large cardinal principles hitherto\nonly enjoy extrinsic support. Many researchers are skeptical about the\npossibility that reflection principles, for instance, can be found\nthat support them (Koellner 2009); others, however, disagree (Welch\n& Horsten 2016). \nGödel hoped that on the basis of such large cardinal axioms, the\nmost important open question of set theory could eventually be\nsettled. This is the continuum problem. The continuum\nhypothesis was proposed by Cantor in the late nineteenth century.\nIt states that there are no sets S which are too large for there to be\na one-to-one correspondence between S and the natural numbers, but too\nsmall for there to exist a one-to-one correspondence between S and the\nreal numbers. Despite strenuous efforts, all attempts to settle the\ncontinuum problem failed. Gödel came to suspect that the\ncontinuum hypothesis is independent of the accepted principles of set\ntheory (ZFC). Around 1940, he managed to show that the continuum\nhypothesis is consistent with ZFC. A few decades later, Paul Cohen\nproved that the negation of the continuum hypothesis is also\nconsistent with ZFC. Thus Gödel’s conjecture of the\nindependence of the continuum hypothesis was eventually confirmed. \nBut Gödel’s hope that large cardinal axioms could solve the\ncontinuum problem turned out to be unfounded. The continuum hypothesis\nis independent of ZFC even in the context of large cardinal axioms.\nNevertheless, large cardinal principles have manage to settle\nrestricted versions of the continuum hypothesis (in the affirmative).\nThe existence of so-called Woodin cardinals ensures that sets\ndefinable in analysis are either countable or the size of the\ncontinuum. Thus the definable continuum problem is\nsettled. \nIn recent years, attempts have been focused on finding principles of a\ndifferent kind which might be justifiable and which might yet decide\nthe continuum hypothesis (Woodin 2001a, Woodin 2001b). One of the more\ngeneral philosophical questions that have emerged from this research\nis the following: which conditions have to be satisfied in order for a\nprinciple to be a putative basic axiom of mathematics? \nSome of the researchers who seek to decide the continuum hypothesis\nthink that it is true; others think that it is false. But there are\nalso many set theorists and philosophers of mathematics who believe\nthat the continuum hypothesis not just undecidable in ZFC but\nabsolutely undecidable, i.e. that it is neither provable (in\nthe informal sense of the word) nor disprovable (in the informal sense\nof the word) because it is neither true nor false. If the mathematical\nuniverse is a set theoretic multiverse, for instance, then\nthere are equally models that make the continuum hypothesis true and\nequally good models that make it false, and there is no more to be\nsaid (Hamkins, 2015).  \nIn the second half of the nineteenth century Dedekind proved that the\nbasic axioms of arithmetic have, up to isomorphism, exactly one model,\nand that the same holds for the basic axioms of Real Analysis. If a\ntheory has, up to isomorphism, exactly one model, then it is said to\nbe categorical. So modulo isomorphisms, arithmetic and\nanalysis each have exactly one intended model. Half a century later\nZermelo proved that the principles of set theory are\n“almost” categorical or quasi-categorical: for\nany two models \\(M_1\\) and \\(M_2\\) of the principles of set theory,\neither \\(M_1\\) is isomorphic to \\(M_2\\), or \\(M_1\\) is isomorphic to a\nstrongly inaccessible rank of \\(M_2\\), or \\(M_2\\) is isomorphic to a\nstrongly inaccessible rank of \\(M_1\\) (Zermelo 1930). In recent years,\nattempts have been made to develop arguments to the effect that\nZermelo’s conclusion can be strengthened to a full categoricity\nassertion (McGee 1997; Martin 2001), but we will not discuss these\narguments here. \nAt the same time, the Löwenheim-Skolem theorem says that every\nfirst-order formal theory that has at least one model with an infinite\ndomain, must have models with domains of all infinite cardinalities.\nSince the principles of arithmetic, analysis and set theory had better\npossess at least one infinite model, the Löwenheim-Skolem theorem\nappears to apply to them. Is this not in tension with Dedekind’s\ncategoricity theorems? \nThe solution of this conundrum lies in the fact that Dedekind did not\neven implicitly work with first-order formalizations of the basic\nprinciples of arithmetic and analysis. Instead, he informally worked\nwith second-order formalizations. \nLet us focus on arithmetic to see what this amounts to. The basic\npostulates of arithmetic contain the induction axiom. In first-order\nformalizations of arithmetic, this is formulated as a scheme: for each\nfirst-order arithmetical formula of the language of arithmetic with\none free variable, one instance of the induction principle is included\nin the formalization of arithmetic. Elementary cardinality\nconsiderations reveal that there are infinitely many properties of\nnatural numbers that are not expressed by a first-order formula. But\nintuitively, it seems that the induction principle holds for\nall properties of natural numbers. So in a first-order\nlanguage, the full force of the principle of mathematical induction\ncannot be expressed. For this reason, a number of philosophers of\nmathematics insist that the postulates of arithmetic should be\nformulated in a second-order language (Shapiro 1991).\nSecond-order languages contain not just first-order quantifiers that\nrange over elements of the domain, but also second-order quantifiers\nthat range over properties (or subsets) of the domain. In\nfull second-order logic, it is insisted that these\nsecond-order quantifiers range over all subsets of the\ndomain. If the principles of arithmetic are formulated in a\nsecond-order language, then Dedekind’s argument goes through and\nwe have a categorical theory. For similar reasons, we also obtain a\ncategorical theory if we formulate the basic principles of real\nanalysis in a second-order language, and the second-order formulation\nof set theory turns out to be quasi-categorical. \nAnte rem structuralism, as well as the modal nominalist\nstructuralist interpretation of mathematics, could benefit from a\nsecond-order formulation. If the ante rem structuralist wants\nto insists that the natural number structure is fixed up to\nisomorphism by the Peano axioms, then she will want to formulate the\nPeano axioms in second-order logic. And the modal nominalist\nstructuralist will want to insist that the relevant concrete systems\nfor arithmetic are those that make the second-order Peano\naxioms true (Hellman 1989). Similarly for real analysis and set\ntheory. Thus the appeal to second-order logic appears as the final\nstep in the structuralist project of isolating the intended models of\nmathematics. \nYet appeal to second-order logic in the philosophy of mathematics is\nby no means uncontroversial. A first objection is that the ontological\ncommitment of second-order logic is higher than the ontological\ncommitment of first-order logic. After all, use of second-order logic\nseems to commit us to the existence of abstract objects: classes. In\nresponse to this problem, Boolos has articulated an interpretation of\nsecond-order logic which avoids this commitment to abstract entities\n(Boolos 1985). His interpretation spells out the truth clauses for the\nsecond-order quantifiers in terms of plural expressions, without\ninvoking classes. For instance, an second-order expression of the form\n\\(\\exists x F(x)\\) is interpreted as: “there are some\n(first-order objects) \\(x\\) such that they have the property\n\\(F\\)”. This interpretation is called the\nplural interpretation of second-order logic. It is\ncontroversial whether there is a real difference between the\nmathematical use of pluralities and of sets (Linnebo 2003).\nNevertheless it is clear that an appeal to the plural interpretation\nof second-order logic will be tempting for nominalist versions of\nstructuralism. \nA second objection against second-order logic can be traced back to\nQuine (Quine 1970). This objection states that the interpretation of\nfull second-order logic is connected with set-theoretical questions.\nThis is already indicated by the fact that most regimentations of\nsecond-order logic adopt a version of the axiom of choice as one of\nits axioms. But more worrisome is the fact that second-order logic is\ninextricably intertwined with deep problems in set theory, such as the\ncontinuum hypothesis. For theories such as arithmetic that intend to\ndescribe an infinite collection of objects, even a matter as\nelementary as the question of the cardinality of the range of the\nsecond-order quantifiers, is equivalent to the continuum problem.\nAlso, it turns out that there exists a sentence which is a\nsecond-order logical truth if and only if the continuum hypothesis\nholds (Boolos 1975). We have seen that the continuum problem is\nindependent of the currently accepted principles of set theory. And\nmany researchers believe it to be absolutely truth-valueless. If this\nis so, then there is an inherent indeterminacy in the very notion of\nsecond-order infinite model. And many contemporary philosophers of\nmathematics take the latter not to have a determinate truth value.\nThus, it is argued, the very notion of an (infinite) model of full\nsecond-order logic is inherently indeterminate. \nIf one does not want to appeal to full second-order logic, then there\nare other ways to ensure categoricity of mathematical theories. One\nidea would be to make use of quantifiers which are somehow\nintermediate between first-order and second-order quantifiers. For\ninstance, one might treat “there are finitely many \\(x\\)”\nas a primitive quantifier. This will allow one to, for instance,\nconstruct a categorical axiomatization of arithmetic. \nBut ensuring categoricity of mathematical theories does not require\nintroducing stronger quantifiers. Another option would be to take the\ninformal concept of algorithmic computability as a primitive notion\n(Halbach & Horsten 2005; Horsten 2012). A theorem of Tennenbaum\nstates that all first-order models of Peano Arithmetic in which\naddition and multiplication are computable functions, are isomorphic\nto each other. Now our operations of addition and\nmultiplication are computable: otherwise we could never have learned\nthese operations. This, then, is another way in which we may be able\nto isolate the intended models of our principles of arithmetic.\nAgainst this account, however, it may be pointed out that it seems\nthat the categoricity of intended models for real analysis, for\ninstance, cannot be ensured in this manner. For computation on models\nof the principles of real analysis, we do not have a theorem that\nplays the role of Tennenbaum’s theorem. \nIf one accepts a certain open-endedness of the collection of\narithmetical predicates, then a categoricity theorem of sorts for\narithmetic can be obtained without overstepping the bounds of\nfirst-order logic and without appealing to an informal concept of\ncomputability. Suppose that there are two mathematicians, A and B, who\nboth assert the first-order Peano-axioms in their own idiolect.\nSuppose furthermore that A and B regard the collection of predicates\nfor which mathematical induction is permissible as open-ended, and are\nboth willing to accept the other’s induction scheme as true.\nThen A and B have the wherewithal to convince themselves that both\nidiolects describe isomorphic structures (Parsons 1990b).  \nUntil fairly recently, the subject of computation did not receive much\nattention in the philosophy of mathematics. This may be due in part to\nthe fact that in Hilbert-style axiomatizations of number theory,\ncomputation is reduced to proof in Peano Arithmetic. But this\nsituation has changed in recent years. It seems that along with the\nincreased importance of computation in mathematical practice,\nphilosophical reflections on the notion of computation will occupy a\nmore prominent place in the philosophy of mathematics in the years to\ncome. \nChurch’s Thesis occupies a central place in computability\ntheory. It says that every algorithmically computable function on the\nnatural numbers can be computed by a Turing machine. \nAs a principle, Church’s Thesis has a somewhat curious status.\nIt appears to be a basic principle. On the one hand, the\nprinciple is almost universally held to be true. On the other hand, it\nis hard to see how it can be mathematically proved. The reason is that\nits antecedent contains an informal notion (algorithmic computability)\nwhereas its consequent contains a purely mathematical notion (Turing\nmachine computability). Mathematical proofs can only connect purely\nmathematical notions—or so it seems. The received view was that\nour evidence for Church’s Thesis is quasi-empirical. Attempts to\nfind convincing counterexamples to Church’s Thesis have come to\nnaught. Independently, various proposals have been made to\nmathematically capture the algorithmically computable functions on the\nnatural numbers. Instead of Turing machine computability, the notions\nof general recursiveness, Herbrand-Gödel computability,\nlambda-definability… have been proposed. But these mathematical\nnotions all turn out to be equivalent. Thus, to use Gödelian\nterminology, we have accumulated extrinsic evidence for the truth of\nChurch’s Thesis. \nKreisel pointed out long ago that even if a thesis cannot be formally\nproved, it may still be possible to obtain intrinsic evidence for it\nfrom a rigorous but informal analysis of intuitive notions (Kreisel\n1967). Kreisel calls these exercises in informal rigour.\nDetailed scholarship by Sieg revealed that the seminal article (Turing\n1936) constitutes an exquisite example of just this sort of analysis\nof the intuitive concept of algorithmic computability (Sieg 1994). \nCurrently, the most active subjects of investigation in the domain of\nfoundations and philosophy of computation appear to be the following.\nFirst, energy has been invested in developing theories of algorithmic\ncomputation on structures other than the natural numbers. In\nparticular, efforts have been made to obtain analogues of\nChurch’s Thesis for algorithmic computation on various\nstructures. In this context, substantial progress has been made in\nrecent decades in developing a theory of effective computation on the\nreal numbers (Pour-El 1999). Second, attempts have been made to\nexplicate notions of computability other than algorithmic\ncomputability by humans. One area of particular interest here is the\narea of quantum computation (Deutsch et al.\n2000). \nWe know much about the concepts of formal proof and\nformal provability, their connection with algorithmic\ncomputability, and the principles by which these concepts are\ngoverned. We know, for instance, that the proofs of a formal system\nare computably enumerable, and that provability in a sound (strong\nenough) formal system is subject to Gödel’s incompleteness\ntheorems. But a mathematical proof as you find it in a mathematical\njournal is not a formal proof in the sense of the logicians: it is a\n(rigorous) informal proof (Myhill 1960, Detlefsen 1992). We\nknow much less about the concepts of informal proof and informal\nprovability and the laws governing them than we know about formal\nproof and provability. In particular, despite the fact that the\nquestion has been debated since the early 1960s (Lucas 1961), it is\nstill completely unclear whether the extension of informal\nmathematical provability coincides, for some formal theory T, with the\nextension of provability in T, or whether the concept of informal\nmathematical provability is even clear enough for this question to\nhave a definite answer (Horsten & Welch 2016).  \nThe past decades have witnessed the first occurrences of mathematical\nproofs in which computers appear to play an essential role. The\nfour-colour theorem is one example. It says that for every map, only\nfour colours are needed to colour countries in such a way that no two\ncountries that have a common border receive the same color. This\ntheorem was proved in 1976 (Appel et al. 1977). But the proof\ndistinguishes many cases which were verified by a computer. These\ncomputer verifications are too long to be double-checked by humans.\nThe proof of the four colour theorem gave rise to a debate about the\nquestion to what extent computer-assisted proofs count as proofs in\nthe true sense of the word. \nThe received view has it that mathematical proofs yield a priori\nknowledge. Yet when we rely on a computer to generate part of a proof,\nwe appear to rely on the proper functioning of computer hardware and\non the correctness of a computer program. These appear to be empirical\nfactors. Thus one is tempted to conclude that computer proofs yield\nquasi-empirical knowledge (Tymoczko 1979). In other words,\nthrough the advent of computer proofs the notion of proof has lost its\npurely a priori character. Others hold that the empirical factors on\nwhich we rely when we accept computer proofs do not appear as premises\nin the argument. Hence, computer proofs can yield a priori knowledge\nafter all (Burge 1998). \nIn the twentieth century, research in the philosophy of mathematics\nrevolved mostly around the nature of mathematical objects, the\nfundamental laws that govern them, and how we acquire mathematical\nknowledge about them. These are foundational concerns that\nare intimately connected with traditional metaphysical and\nepistemological questions. \nIn the second half of the twentieth century, research in the\nphilosophy of science to a significant extent moved away from\nfoundational concerns. Instead, philosophical questions relating to\nthe growth of scientific knowledge and of scientific understanding\nbecame more central. As early as the 1970s, there were voices that\nargued that a similar shift of attention should take place in the\nphilosophy of mathematics (Lakatos 1976).  \nFor some decades, such sentiments remained restricted to a somewhat\nmarginal school of thought in the philosophy of mathematics. However,\nin recent years the opposition between this new movement and\nmainstream philosophy of mathematics is softening. Philosophical\nquestions relating to mathematical practice, the evolution of\nmathematical theories, and mathematical explanation and understanding\nhave become more prominent, and have been related to more traditional\nquestions from the philosophy of mathematics (Mancosu 2008). This\ntrend will doubtlessly continue in the years to come. \nFor an example, let us briefy return to the subject of computer proofs\n(see\n section 5.3).\n The source of the discomfort that mathematicians experience when\nconfronted with computer proofs appears to be the following. A\n“good” mathematical proof should do more than to convince\nus that a certain statement is true. It should also explain\nwhy the statement in question holds. And this is done by\nreferring to deep relations between deep mathematical concepts that\noften link different mathematical domains (Manders 1989). Until now,\ncomputer proofs typically only employ fairly low level mathematical\nconcepts. They are notoriously weak at developing deep concepts on\ntheir own, and have difficulties with linking concepts in from\ndifferent mathematical fields. All this leads us to a philosophical\nquestion which is just now beginning to receive the attention that it\ndeserves: what is mathematical understanding? ","contact.mail":"Leon.Horsten@bristol.ac.uk","contact.domain":"bristol.ac.uk"}]
