[{"date.published":"2015-07-08","date.changed":"2021-03-01","url":"https://plato.stanford.edu/entries/belief-merging/","author1":"Gabriella Pigozzi","author1.info":"http://www.pigozzi.org/","entry":"belief-merging","body.text":"\n\n\nGroups often need to reach decisions and decisions can be complex,\ninvolving the assessment of several related issues. For example, in a\nuniversity a hiring committee typically decides on a candidate on the\nbasis of her teaching and research qualities. A city council\nconfronted with the decision of building a bridge, may ask its members\nto state whether they are favorable or not and, at the same time, to\nprovide reasons for their position (like economical and environmental\nimpacts, or expenditure considerations). Lastly, jurors are required\nto decide on the liability of a defendant by expressing their\njudgments on the conditions prescribed by the relevant code of law for\nthe case at hand. As pointed out by Kornhauser and Sager (1986)\nreferring to real jury trials, the aggregation of individual opinions\non logically interrelated propositions can lead to a paradoxical\nresult, the so-called doctrinal paradox. Inspired by the\ndoctrinal paradox in jurisprudence, the problem of judgment\naggregation attracted the interest of political scientists,\nphilosophers, logicians, economists and computer scientists. Links to\nsocial choice theory have shown that, similar to the problem of\npreference aggregation (Arrow 1951/1963; Sen 1970), a judgment\naggregation procedure that satisfies a number of desirable properties\ndoes not exist.\n\n\nThe question judgment aggregation addresses is how we can define\naggregation procedures that preserve individual rationality at the\ncollective level. From a philosophical point of view, such question\nconcerns the nature of group attitudes such as group beliefs (Roth\n2011). When the city council decides to build the bridge, the decision\nis taken on the basis of individual beliefs that, for example, the\nbridge will have a positive impact on the development of the economic\nactivities in the area and does not represent an environmental threat.\nThus, the formal approach to judgment aggregation can serve to cast\nlight on the dependence between individual and collective beliefs (if\nthere are any). The questions tackled by judgment aggregation are also\nrelevant for the testimony problem investigated in social epistemology\n(Goldman 1999, 2004, 2010). How shall the diverging opinions of\nexperts in a panel be combined and how should a rational agent respond\nto such disagreement?\n\n\nThe problem of combining potentially conflicting pieces of information\ndoes not arise only when a group of people needs to make a decision.\nArtificial intelligence also explores ways to aggregate conflicting\nsensors’ information, experts’ opinions or databases into\na consistent one (Bloch et al. 2001). The combination of information\ncoming from heterogeneous sensors improves the deficiencies of the\nindividual sensors increasing the performances of a system. Examples\nare sensors of gesture recognition, screen rotation, and accelerometer\nin smart phones. Distributed databases may need to be accessed and\nmanaged at the same time to share data, for example, a hospital may\nneed to access the data collected about patients by different units.\nInternet users can find ratings on products provided by people who\nhave purchased and assessed them on different online platforms. The\ntype of information to be combined can differ, and so its\nrepresentation can be numerical or symbolic: numbers, linguistic\nvalues, statistical probability distributions, binary preferences,\nutility functions etc. Yet all examples mentioned above deal with the\nproblem of merging items coming from heterogeneous sources and with\nthe issue of managing conflicts. At a purely formal level, belief\nmerging studies the fusion of independent and equally reliable sources\nof information expressed in propositional logic. As with judgment\naggregation, belief merging addresses the problem of fusing several\nindividual bases expressed in propositional logic into a consistent\none. Given the structural similarity of the problems investigated by\nthese two disciplines, exploring their connections can reveal how\nsimilar these formalisms really are. On a more practical level, the\napplication of operators defined in belief merging to judgment\naggregation problems lead to the definition of a wider class of\naggregation operators for judgment aggregation, the so-called\ndistance-based procedures.\n\n\nThe focus of this entry is to draw explicit connections between\njudgment aggregation and the belief merging literature. Judgment\naggregation will be briefly introduced in the next section. For a more\ncomprehensive introduction to judgment aggregation the reader is\nreferred to (Grossi and Pigozzi 2014; Endriss 2016).\n\nThe formal work on judgment aggregation stemmed from the\n“doctrinal paradox” in the jurisprudence literature\n(Kornhauser and Sager 1986, 1993, 2004; Kornhauser 1992). The paradox\nshows that judges may face a real danger of falling into collective\nirrationality when trying to reach a common and justified verdict.\nDespite the recent birth of the discipline, structurally similar\nproblems seemed to have been first pointed out by Poisson in 1837 (as\npointed out in Elster 2013), and later noted by the Italian legal\ntheorist Vacca in 1921 (see Spector 2009). \nIn Kornhauser and Sager’s court example (1993), a three-member\ncourt has to reach a verdict in a breach of contract case between a\nplaintiff and a defendant. According to the contract law, the\ndefendant is liable for breach of contract (proposition r) if\nand only if the contract forbid the defendant to do a certain action\nX (proposition p) and the defendant did action X\n(proposition q). Suppose that the three judges express the\njudgments as in\n Table 1. \nTable 1: The doctrinal paradox \nProposition r is the conclusion, whereas p and\nq are the premises. The legal doctrine can thus be\nlogically expressed as \\((p\\land q)\\leftrightarrow r\\), stating that\npremises p and q are both necessary and sufficient for\nthe conclusion r.\n Table 1\n shows that each judge respects the given legal doctrine, by declaring\nthe conclusion to be true if and only if she deems both premises true.\nIf the judges aggregate their individual opinions using majority rule\non the judgments on each proposition, the resulting judgment set is\n{p, q, not r}, which constitutes a violation of\nthe legal doctrine. This is an instance of the doctrinal paradox:\ndespite the individuals being logically consistent, the group’s\njudgment on the propositions is not consistent with the legal\ndoctrine. In the example above, the judges cannot declare the\ndefendant not liable and, at the same time, state that both conditions\nfor her liability apply. Thus, the court faces a dilemma. Either\njudges are asked to express judgments on the premises only, and the\ncourt’s decision on r is logically derived from the\nmajority on the premises (the premise-based or\nissue-by-issue procedure), or the verdict is decided by the\nmajority judgment on r (the conclusion-based or\ncase-by-case procedure) ignoring the opinions on the\npremises. Instances such as that in\n Table 1\n illustrate that the two procedures may give opposite results. In the\ncourt example the issues on which the judges have to express a\nposition are distinguished into premises and conclusion. We should\nnote, however, that the theory of judgment aggregation does not\nrequire such a distinction. The court decision of declaring the\ndefendant not liable (despite a majority in favour of the two criteria\nto declare her liability) would be inconsistent with the decision rule\n\\((p \\land q) \\leftrightarrow r\\) even without a distinction between\npremises and conclusion. \nThis was not the first time that the definition of a collective\noutcome by majority rule resulted in a paradoxical result. Already in\n1785, the Marquis de Condorcet discovered what is now known as the\nCondorcet paradox. Given a set of individual preferences, if\nwe compare each of the alternatives in pairs and apply majority\nvoting, we may obtain an intransitive preference (or cycle) in the\ncollective outcome, of the type that alternative x is preferred\nto y, y is preferred to z, and z to\nx, making it impossible to declare an alternative the winner.\nThe similarities between the Condorcet paradox and the judgment\naggregation paradox were promptly noticed by Kornhauser and Sager\n(1986) and List and Pettit (2004). The study of the aggregation of\nindividual preferences into a social preference ordering is the focus\nof social choice theory (List 2013). The Nobel Prize winner Kenneth\nArrow proved the landmark result by showing that the problem which\nCondorcet stumbled upon is more general and not limited to majority\nrule. Arrow’s impossibility theorem (Arrow 1951/1963; Morreau\n2014) states that, given a finite set of individual preferences over\nthree or more alternatives, there exists no aggregation\nfunction that satisfies a few plausible axioms. There are a number of\nresults similar to Arrow’s theorem that demonstrate the\n“impossibility” of judgment aggregation. The first\nimpossibility theorem of judgment aggregation (List and Pettit 2002)\nwas followed by further generalizations (Pauly and van Hees 2006;\nDietrich 2006; Mongin 2008). \nLet us restrict attention to the aggregation of judgments formulated\nin the language L of propositional logic (the problem of\njudgment aggregation can be generalized to modal and conditional\nlogics as well as predicate logic, see Dietrich 2007; for a more\nin-depth discussion of non-classical logics and judgment aggregation\nsee Grossi 2009, Porello 2017 and Xuefeng 2018). The set of formulas\non which the individuals express judgments is called agenda\n\\((A\\subseteq L\\)). The agenda does not contain double negations\n\\((\\neg \\neg \\varphi\\) is equivalent to \\(\\varphi\\)), is closed with\nrespect to negation (i.e., if \\(\\varphi \\in A\\), then also \\(\\neg\n\\varphi \\in A\\)) and is generally assumed not to contain tautologies\nor contradictions. For example, the agenda of the court case is \\(A =\n\\{p, \\neg p, q, \\neg q, p \\wedge q, \\neg (p \\wedge q)\\}\\). Dietrich\nand List (2007a) showed that, when the agenda is sufficiently rich\n(like, for instance, the agenda of the court decision or \\(\\{p, \\neg\np, q, \\neg q, p \\to q, \\neg (p \\to q)\\}\\)), the only judgment\naggregation rules satisfying the desiderata below are\ndictatorships. An aggregation function is a dictatorship when, for\nany input, the collective outcome is taken to be the\nindividual judgment of one (and the same) individual, i.e., the\ndictator. In a dictatorial aggregation function all individual inputs\nbut the dictator’s are ignored. A judgment set is a\nconsistent and complete set of formulae \\(J \\subseteq A\\). A judgment\nset is complete if, for any element \\(\\varphi\\) of the agenda, either\n\\(\\varphi\\in A\\) or \\(\\neg \\varphi\\in A\\) (that is, any item of the\nagenda has to be accepted of rejected). Given a group of n\nindividuals, a profile is a n-tuple of individual\njudgment sets \\(\\langle J_1, \\ldots, J_n \\rangle\\). Finally, a\njudgment aggregation rule F is a function that assigns to\neach profile \\(\\langle J_1, \\ldots, J_n\\rangle\\) a collective judgment\nset \\(F(J_1, \\ldots, J_{n}) \\subseteq A\\). The conditions imposed on\nF are the following: \nUniversal Domain: All profiles of consistent and\ncomplete (with respect to the agenda) judgment sets are accepted as\ninput of the aggregation function. The profile of the doctrinal\nparadox in\n Table 1\n is a legitimate input because the judges expressed acceptance or\nrejection on each issue in the agenda and their opinions respected the\nrule \\((p \\wedge q) \\leftrightarrow r\\). \nCollective Rationality: Only complete and consistent\ncollective judgments are acceptable as outputs. The collective\njudgment of the example in\n Table 1\n is complete (the group accepts or rejects each agenda’s item)\nbut is not consistent because it violates the rule \\((p \\wedge q)\n\\leftrightarrow r\\). \nIndependence: The collective judgment on each\nproposition depends only on the individual judgments on that\nproposition, and not on other (considered to be independent)\npropositions in the agenda. (This condition reformulates in the\njudgment aggregation framework the independence of the irrelevant\nalternatives condition in Arrow’s theorem for preference\naggregation.) Proposition-wise majority rule (as in the court example\nin\n Table 1)\n satisfies the independence condition because the group\nacceptance/rejection of each agenda’s item depends on whether a\nmajority of the individuals accepted/rejected that proposition. \nUnanimity Preservation: If all individuals submit the\nsame judgment on a proposition p\\(\\in\\) A, this is in\nthe collective judgment set. \nDespite the undemanding conditions, it can be shown that there exists\nno judgment aggregation rule F that jointly satisfies the above\nconditions that is not a dictatorship. This impossibility result is\nparticularly meaningful because, when reformulated for a preference\nframework, it can be shown that Arrow’s theorem (for strict\npreference orderings) is obtained as a corollary (Dietrich and List\n2007a). This led Dietrich and List to say that judgment aggregation\ncan be seen as a more general problem than preference aggregation (see\nGrossi and Pigozzi 2014 for details on such reformulation). \nIn addition to formal connections between the two types of aggregation\nproblems, from a conceptual point of view judgment aggregation extends\nthe problems of preference aggregation to more general decision\nproblems. Although the models provided by social choice have improved\nour understanding of many familiar collective decision problems such\nas elections, referenda and legislative decisions, they focus\nprimarily on collective choices between alternative outcomes such as\ncandidates, policies or actions. They do not capture a whole class of\ndecision problems in which a group has to form collectively endorsed\nbeliefs or judgments on logically interconnected\npropositions. Yet, as the examples given in the introduction also\nshow, such decision problems are common and not limited to court\ndecisions. Pettit (2001) coined the term of discursive\ndilemma to highlight the fact that such problem can arise in all\nsituations in which a group of individuals needs to reach a common\nstance on multiple propositions. \nImpossibility results often bear a negative flavor. However, they also\nindicate possible escape routes. Consistent collective outcomes can be\nobtained when the universal domain condition is relaxed (considering,\nfor example, unidimensionally aligned profiles (List 2002), a\nconditions similar to Black’s single-peakedness in preference\naggregation (Black 1948)) or when the collective rationality condition\nis limited to require consistent (but not complete) collective\njudgments. Possibility results are also obtained when the independence\ncondition is relaxed. The premise-based procedure seen in the\ncourt’s case is an example of an aggregation rule that violates\nindependence. There, the collective position on the conclusion is\nderived by logical implication from the majority judgments on the\npremises. More in general, sequential priority rules violate\nindependence and guarantee consistent group positions: the elements of\nthe agenda are aggregated following a pre-fixed order, and earlier\ndecisions constrain later ones. The reader is referred to (List and\nPuppe 2009; List 2013; Grossi and Pigozzi 2014; Endriss 2016) for\nthorough introductions to judgment aggregation and an overview on more\nimpossibility theorems as well as on escapes routes from such results.\nIn the next section we introduce the problem of combining conflicting\ninformation as it has been addressed in computer science. We will see\nthat some operators introduced in belief merging are instances of\naggregation procedures that violate the independence condition and\nthat such operators can be applied to hold concrete aggregation\nprocedures to judgment aggregation problems. \nComputer scientists have studied the aggregation of several\nindependent and potentially conflicting sources of information into a\nconsistent one. As mentioned in the introduction, examples are the\ncombination of conflicting sensors’ information received by an\nagent, the aggregation of multiple databases to build an expert\nsystem, and multi-agent systems (Borgida and Imielinski 1984; Baral et\nal. 1992; Chawathe et al. 1994; Elmagarmid et al. 1999; Subrahmanian\n1994; Kim 1995). Belief merging (or fusion) studies the\naggregation of symbolic information (expressed in propositional logic)\ninto a consistent base. As we shall see, the process of merging\nseveral bases has tight links with belief change (or\nbelief revision), an active discipline since the 1980s across\nformal philosophy and computer science that models how human and\nartificial agents change their beliefs when they encounter new\ninformation. Revision, expansion and contraction are the three main\ntypes of theory change studied by Alchourrón, Gärdenfors\nand Makinson (the so-called AGM theory) who also provided rationality\npostulates for each of them (Alchourrón et al. 1985;\nGärdenfors 1988). In belief revision, the focus is on how one\nbelief base changes in face of new, completely reliable information\nand this new piece may be conflicting with existing beliefs in the\nbase. When I learn that a new acquaintance Rob has a child, I simply\nadd the piece of information and eventually derive new consequences\n(this is expansion). The most interesting case, though, is when the\nnew information conflicts with previously held beliefs. Suppose that\nfrom a common friend I understood that Rob had no kids. Now I learn\nfrom Rob himself that he has a child. In order to accommodate the new\ninformation, I need to perform a revision, which consists of removing\nthe wrong belief that he had no kids (and all the other beliefs that\nmay depend on that), add the new input that in fact he has a child,\nand derive possibly new consequences (see Hansson 2011 for an overview\nand Fermé and Hansson 2018 for a comprehensive introduction to\nbelief change). As for belief revision, in merging the term\n“knowledge” is used in a broader sense than in the\nepistemological literature, such that “knowledge” refers\nto formulas accepted by an agent (i.e., formulas in her knowledge\nbase), which are not necessarily true. Then, “knowledge\nbase” and “belief base” are used interchangeably.\nFor Grégoire and Konieczny (2006) belief merging operators can\nbe used to aggregate also other types of information than knowledge\nand beliefs, such as goals, observations, and norms. \nIf belief revision focuses on how one base changes following the\naddition of a new piece of information, belief fusion studies how to\naggregate several different and potentially conflicting bases (like,\nfor instance, different experts’ opinions, several databases,\ninformation coming from different sources etc.) to obtain a consistent\nbase. Different approaches have been proposed in the literature. Here\nwe briefly mention combination and arbitration\nbefore moving to the merging operators as defined by Konieczny and\nPino Pérez, which have been applied to judgment aggregation.\nThe first approach to the problem of dealing with aggregating\ndifferent and possibly inconsistent databases (Baral et al. 1991;\nBaral et al. 1992) built on Ginsberg’s idea of considering\nmaximally consistent subsets when facing an inconsistent theory\n(Ginsberg 1986), such as the one that may result from the union of the\ninformation coming from several self-consistent (but conflicting with\none another) agents. Combination operators take the union of the\nknowledge bases (a finite set of logical formulas) and, if the union\nis logically inconsistent, select some maximal consistent subsets. The\nlogical properties of such combination operators have been\ninvestigated in (Konieczny 2000) and compared to merging\noperators as defined in (Konieczny and Pino Pérez 1998, 1999).\nThere are several differences between combining and merging knowledge\nbases. One difference is that the method by Baral et al. (1991, 1992)\nis syntax-dependent while merging operators obey the principle of\nirrelevance of syntax. According to the principle of irrelevance of\nsyntax, an operation on two equivalent knowledge bases should return\ntwo equivalent knowledge bases. For instance, \\(K_1 = \\{a, b\\}\\) and\n\\(K_{2}= \\{a \\wedge b\\}\\) have the same logical consequences. So, if\n\\(K_3 = \\{\\neg b\\}\\), merging \\(K_1\\) with \\(K_3\\) or merging \\(K_2\\)\nwith \\(K_3\\) will give two equivalent knowledge bases. On the other\nhand, the combination of \\(K_1\\) and \\(K_3\\) may not be logically\nequivalent to the combination of \\(K_2\\) and \\(K_3\\). Let \\(E_1 = K_1\n\\bigsqcup K_3\\) (\\(\\bigsqcup\\) is the union on multi-set) and \\(E_2 =\nK_2 \\bigsqcup K_3\\). The maximal consistent subsets of \\(E_1\\) are\n\\(\\{a, b\\}\\) and \\(\\{a, \\neg b\\}\\), and those of \\(E_2\\) are \\(\\{a\n\\wedge b\\}\\) and \\(\\{\\neg b\\}\\). So each maximal consistent subset of\n\\(E_1\\) implies \\(a\\), but this is not the case for all maximal\nconsistent subsets of \\(E_2\\) (example from Konieczny 2000). Another\ndifference is that when combination operators are used, the\ninformation about the source of the knowledge bases is ignored. This\nmeans that, unlike merging, combination operators cannot take into\naccount cardinality considerations. Suppose, for example, that four\nmedical experts advise on the effectiveness of four vaccines for\nadults over 65 years old. Let the propositions \\(a, b, c, d\\) stand\nfor “Vaccine A (respectively, B, C, D) is effective in\nover-65s”. If two experts agree that vaccines A and B are\neffective in over-65s, one expert esteems that vaccine D (but not\nvaccine A) is effective and, finally, the last expert agrees with the\nfirst two that vaccine A is effective and that, if B is effective in\nover-65s, so is vaccine C too, we can represent the four experts\nopinions as four knowledge bases: \\(K_1 = K_{2}= \\{a, b\\}\\), \\(K_{3}=\n\\{\\neg a, d\\}\\) and \\(K_4 = \\{a, b\\rightarrow c\\}\\). The union of\nthese four bases is \\(\\{a,\\neg a, b, b\\rightarrow c, d\\}\\), which is\nclearly logically inconsistent. Considering maximal consistent subsets\nis one way to avoid inconsistency while retaining as much information\nas possible. In this example, the two maximal consistent subsets are:\n\\(\\{a, b,b\\rightarrow c, d\\}\\) and \\(\\{\\neg a, b, b\\rightarrow c,\nd\\}\\). This means that we cannot decide whether to accept a or\n\\(\\neg a\\). However, a majority of knowledge bases contained a,\nand only one base contained \\(\\neg a\\). It seems intuitive that\na should be in the resulting knowledge base as long as all\nknowledge bases are treated equally. If, for whatever reason,\n\\(K_{3}\\) is more trustworthy than the other knowledge bases, then we\nmay prefer a combined base in which \\(\\neg a\\) is accepted. \nArbitration is another operator to fuse knowledge bases that\nhas been introduced in the early Nineties (Revesz 1993, Liberatore and\nSchaerf 1995). In belief revision, it is commonly assumed that the new\ninformation is accepted and must be included in the revised base. By\ncontrast, arbitration addresses situations in which two sources give\ncontradicting information but are equally reliable (examples are two\nequally competent experts, two equally trustworthy witnesses etc.). If\nwe have no reason to dismiss one of the two sources, the solution is\nto fuse the two bases rather than revise one by the other. The\noperation is arbitration in the sense that, since both sources are\nequally reliable, the resulting base should contain as much as\npossible of both sources. Liberatore and Schaerf (1995) proposed\naxioms for arbitration between two belief bases, and the operator\nproposed by Revesz only satisfied some of them. Their proposal\nsuffered from the fact of being limited to the arbitration of only two\nbases. This limitation is overcome in the belief merging approach,\nwhere a finite number of bases can be merged into a consistent\none. \nNone of the above methods could take into account the popularity of a\nspecific information item. This meant that those operators could not\ncapture the view of the majority. The first to introduce a majority\npostulate for the merging of several knowledge bases were Lin and\nMendelzon (1999). The idea was inspired by the majority rule in social\nchoice theory. However, their majority postulate includes a notion of\npartial support that captures the specificity of knowledge\nmerging with respect to voting, and is not limited to count the number\nof bases supporting a proposition a vs. the number of bases\ncontaining \\(\\neg a\\). A knowledge base was defined to partially\nsupport a literal l if there is a proposition a that\ncontains no atoms appearing in l, such that the agent believes\neither l or a is true without knowing which one. A\nmodel-theoretic characterization of the postulates and specific\nmerging operators are given in Lin and Mendelzon (1999). In the belief\nmerging literature, sources of information are generally assumed to be\nequally reliable. One way to help to solve the conflict is to relax\nthis assumption as, for example, in the extension to merging weighted\nknowledge bases given in (Lin 1996) or in prioritized knowledge bases\n(Benferhat et al. 1998; Cholvy 1998; Delgrande et al. 2006). \nA new set of postulates for merging operators and the distinction (in\nterms of axioms they satisfy) between arbitration and majority\noperators were introduced by Konieczny and Pino Pérez (1998).\nIn subsequent works (Konieczny and Pino Pérez 1999, 2002) they\nextended the framework to include merging under integrity\nconstraints, that is, a set of exogenously imposed conditions\nthat have to be satisfied by the merged base (Kowalski 1978; Reiter\n1988). In the next section we present the formal framework introduced\nby Konieczny and Pino Pérez, which is now the standard\nframework for belief merging as it overcomes the limitations of the\nprevious proposals. \nThe formal methods developed in belief merging have been exported and\napplied in areas of social epistemology, like elections and preference\naggregation (Meyer et al. 2001), group consensus (Gauwin et al. 2005),\nand judgment aggregation (Pigozzi 2006) to which we return in\n Section 2.2. \nKonieczny and Pino Pérez consider a propositional language\nL built up from a finite set At of atomic propositions\nand the usual connectives \\((\\neg, \\land, \\lor , \\rightarrow,\n\\leftrightarrow )\\). An interpretation is a total function \\(At\n\\rightarrow \\{0, 1\\}\\) that assigns 0 (false) or 1 (true) to each\natomic proposition. For example, if \\(At =\\{p, q, r\\}\\), then \\((1, 0,\n1)\\) is the interpretation that assigns true to p and r\nand false to\n q.[1]\n Denote the set of all interpretations by \\(W = \\{0, 1\\}^{At}\\). For\nany formula \\(\\varphi \\in L\\), \\(\\mymod(\\varphi) = \\{\\omega \\in W |\n\\omega \\models \\varphi\\}\\) denotes the set of models of \\(\\varphi\\),\ni.e., the set of truth assignments that makes \\(\\varphi\\) true. If we\ntake the formula that expressed the contractual law in the doctrinal\nexample, then \\(\\mymod((p\\land q) \\leftrightarrow r) = \\{(1,1,1), (1,\n0, 0), (0, 1, 0), (0,0,0)\\}.\\) As usual, a formula \\(\\varphi\\) is\nconsistent if it has at least a model, and a formula \\(\\varphi\\)\nfollows from a set of formulae \\(\\Phi\\) if every interpretation that\nmakes all formulae in \\(\\Phi\\) true, makes also \\(\\varphi\\) true. \nA belief base \\(K_i\\) is a finite set of propositional\nformulas representing the explicit beliefs held by individual\ni. Each \\(K_{i}\\) is assumed to be consistent. \\(\\mathcal{K}\\)\ndenotes the set of all consistent belief bases. The postulates for\nmerging consider a multi-set of belief bases (belief\nprofile, or belief set, the terminology used in early\npapers) \\(E = \\{K_1, \\ldots , K_{n}\\}\\). The reason for using\nmulti-sets is that an element can appear more than once, thus allowing\nthe representation of the fact that two or more agents can hold the\nsame beliefs. This is needed to take into account the popularity of a\npiece of information, hence to define majority operators. To mark the\ndistinction with the usual set union \\(\\cup\\), the multi-set union is\ndenoted by \\(\\sqcup\\) and defined as \\(\\{\\varphi\\} \\sqcup \\{\\varphi\\}\n= \\{\\varphi, \\varphi\\}\\). Two belief profiles are equivalent\n\\((E_1\\equiv E_{2})\\) if and only if there exists a bijection f\nfrom \\(E_1\\) to \\(E_{2}\\) such that, for any \\(B\\in E_1\\), we have\nthat \\(\\models\\land f(B)\\leftrightarrow \\land B\\). \nIntegrity constraints represent extra conditions that should follow\nfrom the merged bases. The interest of integrity constraints is to\nensure that the aggregation of individual pieces of information\nsatisfies some problem-specific requirement. For example, suppose that\nmembers of a city council have to decide what to build in a certain\narea. We can have constraints on the available budget (enough to cover\nonly some of the projects) but also constraints on the coexistence of\ndifferent projects (we may not build a parking lot and a playground in\nthat area, but we may build a playground and a public library). If the\n(possibly empty) set of integrity constraints is denoted by the belief\nbase IC, \\(\\Delta_{\\IC}(E)\\) denotes the result of merging\nthe multi-set E of belief bases given IC. Intuitively,\nthe result will be a consistent belief base representing the\ncollective beliefs and implying IC. \nKonieczny and Pino Pérez (1999, 2002) put forward the following\npostulates for IC fusion operators between equally reliable\nsources. Let \\(E\\), \\(E_1\\), \\(E_{2}\\), be belief profiles, \\(K_1\\),\n\\(K_{2}\\) be consistent belief bases, and \\(\\IC\\), \\(\\IC_1\\),\n\\(\\IC_{2}\\), be integrity constraints. \\(\\Delta\\) is an IC\nfusion operator if and only if it satisfies the following rationality\npostulates: \nIn order to illustrate these postulates, we consider the following\nexample, due to (Konieczny and Pino Pérez 1999). A group of\nflats co-owners wish to improve their condominium. At the meeting, the\nchairman proposes to build a tennis court, a swimming pool or a\nprivate parking. He also points out that building two of the three\noptions will lead to a significant increase of the yearly maintenance\nexpenses (this corresponds to the IC).  \n(IC0) ensures that the resulting merged base satisfies the integrity\nconstraints. This is an obvious condition to impose since these are\npostulates for merging under integrity constraints, where the idea is\nto ensure that the result of the merging satisfies the integrity\nconstraints. By employing a merging operator, the chairman knows that\nthe group will agree on the increase of the expenses, if they decide\nto build at least two of the three facilities. (IC1) states that, when\nIC is consistent, then the result of the fusion operator will\nalso be consistent. Again, given that the interpretations of the\nmerged bases are selected among the interpretations of the integrity\nconstraints, if IC is consistent, the result will also be\nconsistent. (IC2) states that the result of the merging operator is\nsimply the conjunction of the belief profile and the IC,\nwhenever such conjunction is consistent. In our running example, if\neach person wishing to build two or more facilities endorses the rise\nof the expenses and the opinions given by the co-owners are\nconsistent, then the merging will just return the conjunction of the\nIC and the individual opinions. (IC3) states that if two\nbelief profiles \\(E_1\\) and \\(E_{2}\\) are logically equivalent and\n\\(\\IC_1\\) and \\(\\IC_{2}\\) are also equivalent, then merging the first\nbelief profile with \\(\\IC_1\\) will be equivalent as merging the second\nbelief profile with \\(\\IC_{2}\\). This postulate expresses a principle\nalready imposed on belief revision operators (of which, as we shall\nsee, merging operators are extensions), that is, the principle of\nirrelevance of syntax, which says that the result of a merging\noperator depends only on the semantical content of the merged bases\nand not on their syntactical expression. (IC4) is known as the\nfairness postulate because it states that when merging two\nbelief bases \\(K_1\\) and \\(K_{2}\\), no priority should be given to one\nof them. The merging is consistent with one of them if and only if it\nis consistent with the other. This postulate expresses a symmetric\ncondition that operators that give priority to one of the two bases\nwill not satisfy. (IC5) and (IC6) were first introduced in (Revesz\n1997) and together they mean that if two groups agree on at least one\nitem, then the result of the fusion will coincide with those items on\nwhich the two groups agreed on. So, if the group of co-owners can be\nsplit in two parties, such that one wants to build the tennis court\nand the swimming pool and the other wants the swimming pool and the\nparking, the building of the swimming pool will be selected as the\nfinal group decision. Finally, (IC7) and (IC8) guarantee that if the\nconjunction between the merging on \\(E\\) under \\(\\IC_1\\) and\n\\(\\IC_{2}\\) is consistent, then \\(\\IC_1\\) will remain satisfied if\n\\(E\\) is merged under a more restrictive condition, that is, the\nconjunction of \\(\\IC_1\\) and \\(\\IC_{2}\\). This is a natural\nrequirement to impose as, less formally, (IC7) and (IC8) together\nstate that if the swimming pool is chosen among the set of three\nalternatives, it will still be selected if we reduce the set of\nalternatives to the tennis court and swimming pool. The last two\npostulates are a generalization of two postulates for revision (R5 and\nR6) in (Katsuno and Mendelzon 1991), who analyzed the revision\noperator from a model-theoretic point of view and gave a\ncharacterization of revision operators satisfying the AGM rationality\npostulates (Alchourrón et al. 1985) in terms of minimal change\nwith respect to an ordering over interpretations. Like Katsuno and\nMendelzon’s postulates, (IC7) and (IC8) ensure that the notion\nof closeness is well behaved, in the sense that if an outcome is\nselected by the merging operator under \\(\\IC_1\\), then that outcome\nwill also be the closest (i.e., it will be selected) to \\(\\IC_{2}\\)\nwithin the more restrictive constraint \\(\\IC_1 \\land \\IC_{2}\\)\n(assuming \\(\\Delta_{\\IC_1}(E) \\land \\IC_{2}\\) to be consistent). In\nKatsuno and Mendelzon model-theoretic approach, revision operators\nchange the initial belief base by choosing the closest interpretation\nin the new information. Similarly, IC merging operators\nselect the closest interpretation in the integrity constraints to the\nset of belief bases. Hence, belief merging can be interpreted as a\ngeneralization of belief revision to multiple belief bases\n(Grégoire and Konieczny 2006).  \nTwo sub-classes of \\(\\IC\\) fusion operators are defined. An IC\nmajority fusion operator minimizes the level of total\ndissatisfaction (as introduced by Lin and Mendelzon 1996), whereas an\nIC arbitration operator aims at equally distributing the\nlevel of individual dissatisfaction among the agents. The majority\noperator is similar in spirit to the utilitarian approach in social\nchoice theory, whereas the arbitration is inspired to\negalitarianism. \nLet, for every integer \\(n\\), \\(E^n\\) denote the multi-set containing\nn times E. An IC majority operator satisfies\nthe following additional postulate: \nThus, (Maj) states that enough repetitions of \\(E_{2}\\) will make\n\\(E_{2}\\) the opinion of the group. The number of repetitions needed\ndepends on the specific instance. \nAn IC arbitration operator is characterized by the following\npostulate, in addition to (IC0)–(IC8): \nIntuitively, this axiom states that the arbitration operator selects\nthe median outcomes that are IC-consistent. The behavior of\nsuch operator will be clearer when expressed in a model-theoretical\nway, as we shall see in the next section. \nAn example can help to appreciate the different behavior of a majority\nand an arbitration operator. Suppose three friends need to decide\nwhether to buy a birthday present for a common acquaintance. Suppose\nnow that two of them want to buy her a book and invite her out for\ndinner, while the third friend does not want to contribute to either\nof those presents. If the group takes its decision by majority, the\nthree friends would resolve to buy a book and to invite her out for\ndinner, making the third friend very unhappy. If, on the other hand,\nthey use an arbitration operator, they would either buy her a book or\ninvite her out to a restaurant, making the three members equally\ndissatisfied. Everyone has exactly one formula in their belief base\nthat is not being satisfied, so the “amount” of\ndissatisfaction for each friend is the same. \nThe fusion operators in the literature can be divided into two\nclasses: syntax-based fusion and model-based fusion.\nThe first type takes the propositional formulas as the information\ninput, and typically considers the maximally consistent subsets of the\nbelief profile. In a model-based operator, on the other hand, it is\nthe interpretations of the formulas that are considered as inputs to\nthe merging process. Hence, each belief base is seen as a set of\nmodels and the syntactic representation of its formulas is irrelevant.\nRecall the example we used at the beginning of\n Section 2\n to illustrate that the combination of belief bases is\nsyntax-dependent. We had \\(K_1 = \\{a, b\\}\\), \\(K_2 = \\{a \\wedge b\\}\\)\nand \\(K_3 = \\{\\neg b\\}\\). A syntax-based fusion would treat \\(a, b, a\n\\wedge b, \\neg b\\) as inputs, whereas a model-based fusion would take\n\\(mod(K_1) = mod(K_2) = \\{(1, 1)\\}\\) and \\(mod(K_3) = \\{(1,0),\n(0,0)\\}\\). Since model-based operators have been applied to the\nproblem of judgment aggregation, we will focus on that class of\nmerging operators and refer to (Baral et al. 1992; Konieczny 2000;\nGrégoire and Konieczny 2006) for more on syntax-based\nfusion. \nAn IC model-based fusion operator selects, among the models\nof the integrity constraints IC, those that are preferred,\nwhere the preference relation depends on the operator that is used.\nThus, the collective belief set \\(\\Delta_{\\IC}(E)\\) is guaranteed to\nbe a set of formulas that are true in all of the selected models and\nto satisfy the IC. In the example of the city council seen\nearlier, this means that building a playground and a parking lot will\nnever be selected as a decision outcome. The preference information\nusually takes the form of a total pre-order (to recall, a pre-order is\na reflexive and transitive relation) \\(\\le\\) on the interpretations\ninduced by a notion of distance d between an interpretation\n\\(\\omega\\) and the profile E, denoted by \\(d(\\omega,E)\\).\nIntuitively, this is to select a collective outcome that is the\nclosest (with respect to some notion of distance to be specified) to\nall individual belief bases while satisfying the integrity\nconstraints. It should be noted that a distance-based fusion operator\ndoes not always guarantee a unique result. We will come back to this\npoint when we look at the application of belief merging to judgment\naggregation. \nWe have seen that majority operators are characterized by trying to\nminimize the total dissatisfaction, whereas the arbitration operators\naim at minimizing the local dissatisfaction. We can thus see the\ndistance as a way to capture the notion of dissatisfaction. Inspired\nby the economy principle employed in belief revision, the\noutcome in merging should keep as much as information as possible from\neach individual belief base \\(K_i\\). In other words, since\nthe sources of information are assumed to be equally reliable, the\nmerge should delete as little as possible from the sources. The idea\nthen is to select the interpretations that minimize the distance\nbetween the models of IC and the models of the belief profile\nE. Formally, this can be expressed as follows: \nA distance d between interpretations is a total function \\(d: W\n\\times W \\rightarrow R^{+}\\) such that for all \\(\\omega, \\omega'\\in\nW\\): \nThe first point states that the distance is symmetric. Suppose there\nare three belief bases: \\(K_1 = K_3 = \\{a, b, \\neg c, d\\}\\) and \\(K_2\n= \\{\\neg a, b, c, d\\}\\). If we denote by \\(\\omega_i\\) the\ninterpretation of \\(K_i\\), we have \\(\\omega_1 = \\omega_3 = (1,1,0,1)\\)\nand \\(\\omega_2 = (0,1,1,1)\\). The first point requires that\n\\(d(\\omega_1 ,\\omega_2) = d(\\omega_2 ,\\omega_1)\\). The second point\nstates that if two interpretations are identical, the distance is 0,\nso \\(d(\\omega_1 ,\\omega_3) =\n 0\\).[2] \nTwo steps are needed to find the models of IC that minimize\nthe distances to the belief profile. In the first step, we calculate\nthe distance between each interpretation satisfying IC (that\nis, each candidate merged base) and each individual belief base. The\nintuition here is to quantify how far each individual opinion is from\neach possible collective outcome (recall that the outcomes will be\nselected among the interpretations satisfying IC). In the\nsecond step, we need to aggregate all those individual distances to\ndefine the collective distance, that is, the distance of the belief\nprofile to each model of IC. This amounts to quantify how far\nthe group is from each possible outcome. Finally, the (possibly more\nthan one) base that minimizes such distance is selected as an\noutcome. \nFor the first step, we need to define the distance between an\ninterpretation \\(\\omega\\) and a belief base K. This is the\nminimal distance between \\(\\omega\\) and the models of K.\nFormally: \\(d(\\omega, K) = \\mymin_{\\omega'\\in \\mymod(K)} d(\\omega,\n\\omega')\\). If K has more than one model (e.g., \\(K_i = \\{a\n\\vee b\\}\\) has three models: \\(\\{(0,1) (1,0), (1,1)\\}\\)), \\(\\omega'\\)\nwill be the closest to \\(\\omega\\). \nWe can now define the distance between an interpretation \\(\\omega\\)\nand a belief profile E, which is needed for the second step. We\nneed an aggregation function \\(D: R^{+n} \\rightarrow R^{+}\\) that\ntakes the distances between the models of IC and the belief\nbases \\(K_i\\) calculated in the first step, and aggregate them into a\ncollective distance. This is: \\(D(\\omega, E) = D(d(\\omega, K_1)\\),\n\\(d(\\omega, K_2)\\), \\(\\ldots\\), \\(d(\\omega, K_n))\\). A total pre-order\nover the set W of all interpretations is thus obtained. The\nmerging operator can now select all interpretations that minimize the\ndistance to the profile E. \nTechnically, an aggregation function \\(D: R^{+n} \\rightarrow R^{+}\\)\nassigns a nonnegative real number to every n-ary tuple of nonnegative\nreal numbers. For any \\(x_1,\\ldots, x_{n}, x, y \\in R^{+}, D\\)\nsatisfies the following properties: \nThe outcome of the merging operator clearly depends on the chosen\ndistance functions d and D. Among the first proposals\n(Lin and Mendelzon 1999; Revesz 1993) it was to adopt the Hamming\ndistance (defined below) for d and the sum or the\nmax for D (denoted respectively \\(D_{\\Sigma}\\) and\n \\(D_{\\mymax}\\)).[3]\n When D is the sum, the global distance is obtained by summing\nthe individual ones. The corresponding merging operator is a majority\noperator and is called minisum as it will select those\ninterpretations that minimize the sum. The merging operator that uses\n\\(D_{\\mymax}\\) is known as minimax and outputs the judgment\nset that minimizes the maximal distance to the individual bases (Brams\net al. 2007b). Intuitively, minimax aims at minimizing the\ndisagreement with the most dissatisfied individual. Two opposite\noutcomes may be selected when \\(D_{\\Sigma}\\) or \\(D_{\\mymax}\\) is used\n(Brams et al. 2007b; Eckert and Klamler 2007). \nThe Hamming distance was a commonly used distance in belief revision.\nThe idea is simple. The Hamming distance counts the number of\npropositional letters on which two interpretations differ. So, for\nexample, if \\(\\omega = (1, 0, 0)\\) and \\(\\omega' = (0, 1, 0)\\), we\nhave that \\(d(\\omega, \\omega') = 2\\) as the two interpretations differ\non the assignment to the first and the second propositions. Also well\nknown is the drastic distance, which assigns distance 0 if\ntwo interpretations are the same and 1 otherwise. But the choice of\nthe distance is not restricted to those options. Other distances can\nbe used, that still satisfy the postulates given above (Konieczny and\nPino Pérez 1999, 2002). The minimization of the sum of the\nindividual distances is an example of an IC majority merging\noperator. In the next section, we will see this operator applied to\nthe discursive dilemma. \nThe distance-based approach can clarify the distinction between\narbitration and majority operators. Leximax is an example of\narbitration operator. A leximax operator may take d as\nthe Hamming distance and, for each interpretation, the distances\nbetween that interpretation and the n bases \\(K_i\\) form a\nlist. A pre-order over interpretations is defined by taking the\nlexicographical order between sequences of distances, fixing an order\nover the set of agents. Finally, \\(D_{\\textit{leximax}}\\) selects the\nminimum. The intuition is that, unlike a majority operator that\nselects the option that minimizes the total disagreement (by\nminimizing the sum of the individual distances, for example), an\narbitration operator looks at the distribution of such\ndisagreement and selects the option that is fairer to all individuals,\nthat is, it aims at equally distributing the individual\ndissatisfaction with the chosen outcome (recall the birthday gift\nexample above). This follows from the definition of the Hamming\ndistance: the larger the Hamming distance, the more disagreement there\nis between two interpretations (here disagreement simply means that\nthe interpretations assign different truth values to the same\nformula). Suppose that a belief profile E has three bases.\nSuppose as well that the distances from the two models of IC\n(\\(\\omega\\) and \\(\\omega'\\)) are \\(D_{\\Sigma} (\\omega, E) = D_{\\Sigma}\n(\\omega', E) = 6\\) when we take the sum of the Hamming distances, and\n\\(D_{\\textit{leximax}}(\\omega, E)= (2,2,2)\\) and\n\\(D_{\\textit{leximax}}(\\omega', E)= (5,1,0)\\) when we take the\nlexicographic order on the distances. In this example, the majority\noperator cannot distinguish between \\(\\omega\\) and \\(\\omega'\\)\n(because in both cases the sum is 6), while the arbitration operator\nwill prefer \\(\\omega\\) to \\(\\omega'\\) as \\(\\omega\\) distributes the\nindividual disagreement in a fairer way than \\(\\omega'\\). \nAs mentioned earlier, Liberatore and Schaerf were among the first to\npropose arbitration operators. However, their approach was limited to\nonly two bases, and the result of the merge was one of the two bases.\nSuch operator would give questionable results in some situations, like\nthe one in (Konieczny and Pino Pérez 2002). Suppose that two\nfinancial experts give you advice regarding four shares a, b,\nc and d. According to the first expert, all four shares\nare going to rise (denoted by \\(\\varphi_1= \\{(1, 1, 1, 1)\\}\\), whereas\nthe second expert deems that all four shares will fall \\((\\varphi_{2}=\n\\{(0, 0, 0, 0)\\})\\). According to Liberatore and Schaerf’s\narbitration operator, the result will be \\(\\{(1, 1, 1, 1), (0, 0, 0,\n0)\\},\\) which means that either the first or the second expert is\ntotally right. If, on the other hand, we apply an arbitration operator\nà la Konieczny and Pino Pérez, we obtain\n\\(\\{(0, 0, 1, 1)\\), \\((0, 1, 0, 1)\\), \\((0, 1, 1, 0)\\), \\((1, 0, 0,\n1)\\), \\((1, 0, 1, 0)\\), \\((1, 1, 0, 0)\\}\\). This result can be\ninterpreted as that—if we assume that all sources are equally\nreliable—we do not have any reason to prefer one or another and,\nso a reasonable position is to conclude that both can be equally\nright. Still, Liberatore and Schaerf’s operator may be used in\nall situations where the result can be only one of the bases submitted\nby the individuals. For example, if two doctors meet in order to\ndecide a patient’s therapy, they likely have to decide in favour\nof one of the two proposals as mixing therapies may not be a feasible\nnor a safe option. \nA representation theorem (Konieczny and Pino Pérez 1999, 2002)\nensures that to each sub-class of IC merging operators\n(majority and arbitration operators) corresponds a family of\npre-orders on interpretations (mirroring a similar representation\ntheorem that Katsuno and Mendelzon (1991) proved for belief revision\n operators).[4] \nLet us now illustrate how belief merging can be applied to judgment\naggregation problems. \nThe merging of individual belief bases into a collective one shares\nsimilarities to the judgment aggregation problem. In both cases, we\nwish to aggregate individual inputs into a group outcome, and both\ndisciplines employ logic to formalize the bases’ contents. As we\nhave seen in\n Section 1,\n no aggregation procedure can ensure a consistent and complete group\njudgment. However, the merging operators introduced in computer\nscience ensure a consistent outcome because such operators do not\nsatisfy independence. The collective judgment on a proposition is not\nonly determined by the individual judgments on that proposition but\nalso by considerations of all other agenda’s items. It\nis natural to apply the results about merging methods to the\naggregation of individual judgments (Pigozzi 2006). \nHow do impossibility results in judgment aggregation conciliate with\nthe fact that IC merging operators can ensure a consistent\ncollective outcome? The reason is that merging operators violate the\nindependence conditions, one of the requirements imposed on\naggregation functions in the impossibility theorems. Independence\nturned out to be an instrumentally attractive condition because it\nprotects an aggregation function from strategic manipulation (Dietrich\n2006; Dietrich and List 2007b). This means that an individual has no\ninterest in submitting an insincere judgment set in order to get a\nbetter outcome for her. However, independence has been criticized in\nthe literature as a not suitable desideratum to aggregate\npropositions that are logically interconnected (Chapman 2002; Mongin\n2008). Clearly, paradoxical results are avoided by resorting to\nIC, which blocks unacceptable outcome. However, it is worth\nnoting that in judgment aggregation the collective rationality\ncondition (that requires logically consistent outputs) plays an\nanalogous role as IC in belief merging, that is, blocks\nunacceptable outcomes like inconsistent majority judgments. Moreover,\njudgment aggregation impossibility results persist even if we\nexplicitly import additional integrity constraints into the judgment\naggregation framework (see Dietrich and List 2008b; Grandi 2012). \nIt has been observed (Brams et al. 2007a) that majority voting\nminimizes the sum of Hamming distances. This means that, whenever\nproposition-wise majority voting selects a consistent judgment set,\nthe same outcome is selected by the minisum rule. Majority\nvoting has credentials for being democratic. Another reason to focus\non majority distance-based procedures is that the aim of the\naggregation of individual judgments should be the right decision\nrather than a fair distribution of individual dissatisfactions. The\nepistemic link between majority voting and right decisions has been\npointed out in the Condorcet Jury Theorem. The theorem shows\nthat, when the voters are independent and have an equal probability of\nbeing right better than random, then majority rule ensures to select\nthe right decision and the probability for doing so approaches 1 as\nthe voters’ group size increases (see List 2013 for this and\nsome more formal arguments for majority rule). \nLet us consider the three judges example and see what we obtain when\napplying the minisum rule. The legal doctrine corresponds to\n\\(\\IC= \\{(p\\land q) \\leftrightarrow r\\}\\). The court is represented by\nthe profile \\(E=\\{K_1 , K_{2} , K_{3}\\}\\), which is the multi-set\ncontaining the judgment sets \\(K_1 , K_{2} , K_3\\) of the three\njudges. The three judgment sets and their corresponding models\nare: \n\n Table 2\n shows the result for the majority operator that minimizes the sum of\nthe Hamming distances. In the first column are all the interpretations\nfor the propositional variables p, q, and r. The\ninterpretations that are not models of the IC have a shaded\nbackground. So, for example, \\((1,0,1)\\) cannot be selected as the\ncollective outcome because it violates the legal doctrine. The numbers\nin the \\(d_H (\\cdot,K_1)\\), \\(d_H(\\cdot,K_{2})\\), and\n\\(d_H(\\cdot,K_{3})\\) columns are the Hamming distances of each \\(K_i\\)\nfrom the corresponding interpretation. In the last column are the sums\nof the Hamming distances. \nTable 2 \nWe see that, without IC, the distance-based majority operator\nwould select the same (inconsistent) outcome as proposition-wise\nmajority voting, that is, \\((1,1,0)\\). This is the outcome that is at\nthe minimum distance from E. However, the merging operator\ncannot select \\((1,1,0)\\) as that outcome violates the IC. Neglecting\nthe shaded rows, only four interpretations are candidates to be\nselected as collective judgment sets, that is, \\((1,1,1)\\),\n\\((1,0,0)\\), \\((0,1,0)\\), and \\((0,0,0)\\). Of those, three are the\nones that minimize the distances. Thus, collective inconsistency is\navoided when a distance-based aggregation is used. However, this\nmethod does not always guarantee a unique outcome. In the court\nexample, this aggregation selects the three models \\((1,1,1)\\),\n\\((1,0,0)\\) and \\((0,1,0)\\) as group positions. Technically, this is\nsaid to be an irresolute procedure, and a tie-breaking rule\nneeds to be combined if we wish to ensure a unique result (as common\nin social choice theory). \nThe applicability of merging techniques developed in computer science\nto judgment aggregation problems does not mean that the two\ndisciplines have the same objectives. As we have seen, the original\nmotivation of belief merging was to define ways to aggregate\ninformation coming from different sources. Since the sources can have\ndifferent access to the information, no externally given agenda is\nassumed. This is a difference with the judgment aggregation framework,\nwhere individuals are required to submit their opinion on a given set\nof items. Belief merging and judgment aggregation do not only differ\nin the type of inputs they aggregate. They also output different\nresults: a collective base satisfying some given integrity constraints\nfor belief merging, and a collective judgment on the given agenda for\njudgment aggregation. \nAnother difference resides in the fact that judgment aggregation\nassumes that all members are rational, and so they all submit\nconsistent judgment sets. In belief merging, this is not required.\nAgents can submit belief bases that are inconsistent with the\nIC (Grégoire 2004). If an individual submits a\njudgment that violates an integrity constraint, that judgment set will\nnot figure among the candidates to represent the group position.\nHowever, his input will not be disregarded and will be taken into\naccount in the merging process. The possibility to abstain from\nexpressing an opinion on a certain item is also easily taken into\naccount in a belief merging setting. If individuals need to have their\nsay on p, q and r and one agent believes q\nand r to be true but does not have a clear opinion on p,\nthis will be represented as \\(\\mymod(K_1)= \\{(1, 1, 1),\\) \\((0, 1,\n1)\\}\\) and the distances calculated accordingly. The completeness\nrequirement on judgment sets has also been weakened in the judgment\naggregation framework. List and Pettit (2002) first discussed the\nweakening of completeness in the context of supermajority and\nunanimity rules. Later, it was shown (Gärdenfors 2006; Dokow and\nHolzman 2010) that, when judgment sets are not assumed to be complete,\nany independent and unanimous aggregation function turns out to be\nweakly oligarchic, that is, a subset of the individuals will decide\nthe collective outcome. Intuitively, this is a less negative result\nthan dictatorship, though it reduces to dictatorship in the case in\nwhich only one individual belongs to that subset. Dietrich and List\n(2008a) independently obtained equivalent results on oligarchic rules\nto those in (Dokow and Holzman 2010). \nFinally, if model-based merging approach is syntax-dependent, judgment\naggregation explicitly permits syntax-dependence. This can give rise\nto decision framing problems (Cariani et al. 2008) or logical agenda\nmanipulation (Dietrich 2006) when a judgment problem can be presented\nusing two logically equivalent but syntactically different\nagendas. \nA formal investigation of the relationships between belief merging and\njudgment aggregation can be found in (Everaere et al. 2015, 2017). As\nwe have seen, belief merging takes a profile of propositional belief\nbases as input, where such bases represent the beliefs of a certain\nindividual, not restraint to a given agenda. Judgment aggregation, on\nthe other hand, asks people to submit their judgments on a specific\nset of issues. The analysis rests on the assumption that an\nindividual’s beliefs allow deriving her opinion on the\nagenda’s items. Thus, in (Everaere et al. 2015) a projection\nfunction p (assumed to be identical for all the individuals) is\ndefined. The role of such projection function is precisely to\ndetermine the judgments of an agent (input of judgment aggregation\noperators) starting from her beliefs (input of belief merging). So,\nfor example, if an individual only believes \\(a\\land b\\) and one of\nthe agenda items is a, then the projection function can derive\nthat the person submits a “yes” as judgment on a.\nHowever, if she believes only a and one of the agenda item is\n\\(a\\land b\\), she will probably be not able to submit a judgment on\nthat item. For this reason, individual judgment sets in (Everaere et\nal. 2015) are not necessarily complete (individuals can abstain on\nsome agenda’s issues). Using the projection p, two paths\nalong which a collective judgment can be derived from a profile of\nbelief bases are considered. Along one path (merge-then-project), the\nindividual belief bases are first merged using a merging operator and\nthen the collective judgment is computed by the projection p.\nAlong the other path (project-then-aggregate), starting from the\nindividual bases, the individual judgment sets are first computed by\np and then aggregated using a judgment aggregation procedure to\ndetermine the collective judgment on the given agenda. Thus, the\nquestion addressed is whether the two collective judgments obtained by\nfollowing the two paths coincide. Two cases are considered: the\ngeneral case (incomplete agendas) and the case in which the agenda is\ncomplete (i.e. it contains all possible interpretations). For example,\nthe agenda \\(A= \\{\\neg a \\land \\neg b, \\neg a \\land b, a \\land \\neg b,\na \\land b\\}\\) is complete whereas the agenda \\(A= \\{\\neg a \\land \\neg\nb, \\neg a \\land b, a \\land \\neg b\\}\\) is not. Hence, if an individual\nbelieves \\(a\\land b\\), her judgment set will be \\((0,0,0,1)\\) in the\nfirst agenda and \\((0,0,0)\\) in the second one, which may lead to\ndifferent collective outcomes depending on whether the\nmerge-then-project or the project-then-merge path is used. The fact\nthat by properly choosing the agenda one may manipulate the result has\nbeen investigated in the judgment aggregation literature (Dietrich\n2016, Lang et al. 2016). In the general case, IC merging methods can\ngive results that are inconsistent with those obtained by using\njudgment aggregation operators satisfying unanimity or majority\n preservation[5].\n On a more positive side, when the agenda is complete, the collective\njudgments obtained by following the two paths coincide for some\njudgment aggregation operators satisfying properties closed to some IC\nmerging postulates.  \nThe minisum rule applied to merge the judgment sets of the\nthree judges in the previous section is based on the same principles\nas the Kemeny rule, a well-known preference aggregation rule\n(Kemeny 1959). Unlike what happened in social choice, at the beginning\nthe literature of judgment aggregation focused on the axiomatic method\nand only few concrete aggregation rules were proposed and studied.\nArguably, the interest of researchers from computer science and\nmulti-agent systems for judgment aggregation lead to the definition of\nmore concrete aggregation rules and to the investigation of their\nrelations. The same idea of minimization that plays such a crucial\nrole in belief merging can be found as a principle in the definition\nof several voting rules in social choice theory. For instance, the\nminisum rule turned out to be equivalent to several other\nrules recently introduced in the judgment aggregation literature (Lang\net al. 2017). \nThe interest of computer scientists for aggregation methods is\nwitnessed by the fact that judgment aggregation is now among the\ntopics of computational social choice, an interdisciplinary discipline\nthat promotes exchanges and interactions between computer science and\nsocial choice theory. Computational issues of aggregation rules are\namong the interests of computational social choice. The intuition\nbehind the application of complexity theory to aggregation rules is to\nassess the acceptability of an aggregation rule on the basis of\npragmatic considerations, that is, the algorithmic feasibility of\napplying that rule. So, an aggregation rule is acceptable when its\noutcome is ‘easy’ to compute, that is, it can be solved by\nan algorithm in time which grows – at worst – polynomially with the\nsize of the input (only in some pathological cases we can imagine\ndesiring a rule that will not be able to return an outcome in a\nforeseeable future). On the other hand, if an aggregation rule is\nmanipulable, then it is acceptable when it is ‘hard’ for\nan individual to manipulate it. Thus, the study of the computational\ncomplexity of aggregation rules may reveal that, even though a rule is\nmanipulable, it is actually hard for an individual to act on that. The\ncomputational complexity of the distance-based procedures has been\nstudied (Endriss et al. 2012; Endriss and de Haan 2015). The high\ncomputational complexity of Hamming rule in judgment aggregation\nmirrors a parallel result that the Kemeny rule in preference\naggregation is also highly computational complex, as first shown in\nBartholdi et al. (1989) and Hudry (1989). A new rule has been proposed\nto overcome the high computational complexity of distance-based\nprocedures. The average-voter rule (Grandi 2012) selects the judgment\nset submitted by the individuals that minimizes the sum of the\ndistances. Hence, the outcome has to be one of the submitted judgment\nsets. This allows reducing the computational complexity and, at the\nsame time, selects the most representative individual. \nA generalization of distance-based methods for judgment aggregation\nhas been given in (Miller and Osherson 2009). Besides generalizing (by\ntaking a general metric) the merging operator we have applied to the\ndoctrinal paradox, they proposed three other distance-based procedures\nfor judgment aggregation. In case proposition-wise majority collapses\ninto an inconsistent collective judgment set, one method\n(Endpoint) selects as group outcome the closest (according to\nsome distance metric) consistent collective judgment set. The other\ntwo methods (Full and Output) look at minimal ways\nto change the profile in order to output a consistent proposition-wise\nmajority collective judgment set. The difference is that\nOutput allows the individual judgment sets in the modified\nprofile to be inconsistent. \nDuddy and Piggins (2012) questioned the use of Hamming distance\nbetween judgment sets. The problem is that, when the agenda contains\npropositions that are logically connected, the Hamming distance may be\nresponsible of double counting because it ignores such\ninterdependencies. Suppose, for example, that two individuals accept\npropositions q but disagree on \\(p\\land q\\) (so, one individual\naccepts the conjunction, while the other rejects it). This can happen\nonly if they disagree on p. The Hamming distance between the\ntwo judgment sets \\(K_1 = \\{\\neg p, q, \\neg(p\\land q)\\}\\) and \\(K_{2}\n= \\{p, q, (p\\land q)\\}\\) is 2. It is the disagreement on p that\nimplies the disagreement over \\(p\\land q\\), so the distance should be\njust 1. The alternative distance proposed in order to address this\nproblem is a distance that takes the smallest number of logically\ncoherent changes needed to convert one judgment set into the\nother. \nBelief merging is an abstract theory that addresses the problem of\naggregating symbolic inputs, without specifying whether such items are\nbeliefs, knowledge, desires, norms etc. It is the choice of the\nmerging operator that should best suit the type of inputs. The\nframework of judgment aggregation has also been extended to include\nthe aggregation of other types of attitudes, as in (Dietrich and List\n2010). \nThe literature on belief merging includes the study of the strategic\nmanipulation problem (Evaraere et al. 2007). When an aggregation\nprocedure is not strategy-proof, an individual who has a preference\nover the possible outcomes can manipulate the result by lying on her\ntrue beliefs and thus obtain an outcome closer to her true\npreferences. In general, merging operators are not strategy-proof when\nHamming distance is used, whereas they are strategy-proof when the\ndrastic distance is employed. For a recent survey of results on\nstrategic behaviour in judgment aggregation, see (Baumeister et al.\n2017). \nIn those situations in which we can assume that there is a fact of the\nmatter (for example, a defendant has—or has not—committed\na murder), which each agent has a (noisy) opinion about, the\ntruth-tracking properties of belief merging operators can be\ninvestigated (Hartmann et al. 2010; Hartmann and Sprenger 2012;\nCevolani 2014). The question is then whether a certain aggregation\nmethod selects the right decision. Williamson (2009) argues that\naggregating the evidence on which the judgments are based is\nbest for judgment aggregation, as it would yield to the right\ndecision. The three-step proposal he advocates distinguishes between\nthree types of propositions: evidence, beliefs and judgments. Evidence\nis the support for an agent’s beliefs and judgments, and it is\nthe right candidate for merging techniques. Judgments, on the other\nhand, are best dealt with decision theory that maps degrees of beliefs\nand utilities to judgments.","contact.mail":"gabriella.pigozzi@lamsade.dauphine.fr","contact.domain":"lamsade.dauphine.fr"}]
