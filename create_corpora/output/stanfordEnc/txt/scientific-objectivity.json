[{"date.published":"2014-08-25","date.changed":"2020-10-30","url":"https://plato.stanford.edu/entries/scientific-objectivity/","author1":"Julian Reiss","author1.info":"http://jreiss.org/","author2.info":"http://www.laeuferpaar.de","entry":"scientific-objectivity","body.text":"\n\n\nScientific objectivity is a property of various aspects of science. It\nexpresses the idea that scientific claims, methods, results—and\nscientists themselves—are not, or should not be, influenced by\nparticular perspectives, value judgments, community bias or personal\ninterests, to name a few relevant factors. Objectivity is often\nconsidered to be an ideal for scientific inquiry, a good reason for\nvaluing scientific knowledge, and the basis of the authority of\nscience in society.\n\n\nMany central debates in the philosophy of science have, in one way or\nanother, to do with objectivity: confirmation and the problem of\ninduction; theory choice and scientific change; realism; scientific\nexplanation; experimentation; measurement and quantification;\nstatistical evidence; reproducibility; evidence-based science;\nfeminism and values in science. Understanding the role of objectivity\nin science is therefore integral to a full appreciation of these\ndebates. As this article testifies, the reverse is true too: it is\nimpossible to fully appreciate the notion of scientific objectivity\nwithout touching upon many of these debates.\n\n\nThe ideal of objectivity has been criticized repeatedly in philosophy\nof science, questioning both its desirability and its attainability.\nThis article focuses on the question of how scientific objectivity\nshould be defined, whether the ideal of objectivity is\ndesirable, and to what extent scientists can achieve\nit.\n\nObjectivity is a value. To call a thing objective implies that it has\na certain importance to us and that we approve of it. Objectivity\ncomes in degrees. Claims, methods, results, and scientists can be more\nor less objective, and, other things being equal, the more objective,\nthe better. Using the term “objective” to describe\nsomething often carries a special rhetorical force with it. The\nadmiration of science among the general public and the authority\nscience enjoys in public life stems to a large extent from the view\nthat science is objective or at least more objective than other modes\nof inquiry. Understanding scientific objectivity is therefore central\nto understanding the nature of science and the role it plays in\nsociety. \nIf what is so great about science is its objectivity, then objectivity\nshould be worth defending. The close examinations of scientific\npractice that philosophers of science have undertaken in the past\nfifty years have shown, however, that several conceptions of the ideal\nof objectivity are either questionable or unattainable. The prospects\nfor a science providing a non-perspectival “view from\nnowhere” or for proceeding in a way uninformed by human goals\nand values are fairly slim, for example. \nThis article discusses several proposals to characterize the idea and\nideal of objectivity in such a way that it is both strong enough to be\nvaluable, and weak enough to be attainable and workable in practice.\nWe begin with a natural conception of objectivity:\nfaithfulness to facts. We motivate the intuitive\nappeal of this conception, discuss its relation to scientific method\nand discuss arguments challenging both its attainability as well as\nits desirability. We then move on to a second conception of\nobjectivity as absence of normative commitments and\nvalue-freedom, and once more we contrast arguments in favor\nof such a conception with the challenges it faces. A third conception\nof objectivity which we discuss at length is the idea of\nabsence of personal bias. \nFinally there is the idea that objectivity is anchored in\nscientific communities and their practices. After\ndiscussing three case studies from economics, social\nscience and medicine, we address the conceptual unity of\nscientific objectivity: Do the various conceptions have a\ncommon valid core, such as promoting trust in science or minimizing\nrelevant epistemic risks? Or are they rivaling and only loosely\nrelated accounts? Finally we present some conjectures about what\naspects of objectivity remain defensible and desirable in the light of\nthe difficulties we have encountered. \nThe basic idea of this first conception of objectivity is that\nscientific claims are objective in so far as they faithfully describe\nfacts about the world. The philosophical rationale underlying this\nconception of objectivity is the view that there are facts “out\nthere” in the world and that it is the task of scientists to\ndiscover, analyze, and systematize these facts.\n“Objective” then becomes a success word: if a claim is\nobjective, it correctly describes some aspect of the world. \nIn this view, science is objective to the degree that it succeeds at\ndiscovering and generalizing facts, abstracting from the perspective\nof the individual scientist. Although few philosophers have fully\nendorsed such a conception of scientific objectivity, the idea figures\nrecurrently in the work of prominent twentieth-century philosophers of\nscience such as Carnap, Hempel, Popper, and Reichenbach. \nHumans experience the world from a perspective. The contents of an\nindividual’s experiences vary greatly with his perspective,\nwhich is affected by his personal situation, and the details of his\nperceptual apparatus, language and culture. While the experiences\nvary, there seems to be something that remains constant. The\nappearance of a tree will change as one approaches it\nbut—according to common sense and most philosophers—the\ntree itself doesn’t. A room may feel hot or cold for different\npersons, but its temperature is independent of their experiences. The\nobject in front of me does not disappear just because the lights are\nturned off. \nThese examples motivate a distinction between qualities that vary with\none’s perspective, and qualities that remain constant through\nchanges of perspective. The latter are the objective qualities. Thomas\nNagel explains that we arrive at the idea of objective qualities in\nthree steps (Nagel 1986: 14). The first step is to realize (or\npostulate) that our perceptions are caused by the actions of things\naround us, through their effects on our bodies. The second step is to\nrealize (or postulate) that since the same qualities that cause\nperceptions in us also have effects on other things and can exist\nwithout causing any perceptions at all, their true nature must be\ndetachable from their perspectival appearance and need not resemble\nit. The final step is to form a conception of that “true\nnature” independently of any perspective. Nagel calls that\nconception the “view from nowhere”, Bernard Williams the\n“absolute conception” (Williams 1985 [2011]). It\nrepresents the world as it is, unmediated by human minds and other\n“distortions”. \nThis absolute conception lies at the basis of scientific realism (for\na detailed discussion, see the entry on\n scientific realism)\n and it is attractive in so far as it provides a basis for arbitrating\nbetween conflicting viewpoints (e.g., two different observations).\nMoreover, the absolute conception provides a simple and unified\naccount of the world. Theories of trees will be very hard to come by\nif they use predicates such as “height as seen by an\nobserver” and a hodgepodge if their predicates track the habits\nof ordinary language users rather than the properties of the world. To\nthe extent, then, that science aims to provide explanations for\nnatural phenomena, casting them in terms of the absolute conception\nwould help to realize this aim. A scientific account cast in the\nlanguage of the absolute conception may not only be able to explain\nwhy a tree is as tall as it is but also why we see it in one way when\nviewed from one standpoint and in a different way when viewed from\nanother. As Williams (1985 [2011: 139]) puts it, \n[the absolute conception] nonvacuously explain[s] how it itself, and\nthe various perspectival views of the world, are possible. \nA third reason to find the view from nowhere attractive is that if the\nworld came in structures as characterized by it and we did have access\nto it, we could use our knowledge of it to ground predictions (which,\nto the extent that our theories do track the absolute structures, will\nbe borne out). A fourth and related reason is that attempts to\nmanipulate and control phenomena can similarly be grounded in our\nknowledge of these structures. To attain any of the four\npurposes—settling disagreements, explaining the world,\npredicting phenomena, and manipulation and control—the absolute\nconception is at best sufficient but not necessary. We can, for\ninstance, settle disagreements by imposing the rule that the person\nwith higher social rank or greater experience is always right. We can\nexplain the world and our image of it by means of theories that do not\nrepresent absolute structures and properties, and there is no need to\nget things (absolutely) right in order to predict successfully.\nNevertheless, there is something appealing in the idea that factual\ndisagreements can be settled by the very facts themselves, that\nexplanations and predictions grounded in what’s really there\nrather than in a distorted image of it. \nNo matter how desirable, our ability to use scientific claims to\nrepresent facts about the world depends on whether these claims can\nunambiguously be established on the basis of evidence, and of evidence\nalone. Alas, the relation between evidence and scientific hypothesis\nis not straightforward.\n Subsection 2.2\n and\n subsection 2.3\n will look at two challenges of the idea that even the best scientific\nmethod will yield claims that describe an aperspectival view from\nnowhere.\n Section 5.2\n will deal with socially motivated criticisms of the view from\nnowhere. \nAccording to a popular picture, all scientific theories are false and\nimperfect. Yet, as we add true and eliminate false beliefs, our best\nscientific theories become more truthlike (e.g., Popper 1963,\n1972). If this picture is correct, then scientific knowledge grows by\ngradually approaching the truth and it will become more objective over\ntime, that is, more faithful to facts. However, scientific theories\noften change, and sometimes several theories compete for the place of\nthe best scientific account of the world. \nIt is inherent in the above picture of scientific objectivity that\nobservations can, at least in principle, decide between competing\ntheories. If they did not, the conception of objectivity as\nfaithfulness would be pointless to have as we would not be in a\nposition to verify it. This position has been adopted by Karl R.\nPopper, Rudolf Carnap and other leading figures in (broadly)\nempiricist philosophy of science. Many philosophers have argued that\nthe relation between observation and theory is way more complex and\nthat influences can actually run both ways (e.g., Duhem 1906 [1954];\nWittgenstein 1953 [2001]). The most lasting criticism, however, was\ndelivered by Thomas S. Kuhn (1962 [1970]) in his book “The\nStructure of Scientific Revolutions”. \nKuhn’s analysis is built on the assumption that scientists\nalways view research problems through the lens of a paradigm, defined\nby set of relevant problems, axioms, methodological presuppositions,\ntechniques, and so forth. Kuhn provided several historical examples in\nfavor of this claim. Scientific progress—and the practice of\nnormal, everyday science—happens within a paradigm that guides\nthe individual scientists’ puzzle-solving work and that sets the\ncommunity standards. \nCan observations undermine such a paradigm, and speak for a different\none? Here, Kuhn famously stresses that observations are\n“theory-laden” (cf. also Hanson 1958): they\ndepend on a body of theoretical assumptions through which they are\nperceived and conceptualized. This hypothesis has two important\naspects. \nFirst, the meaning of observational concepts is influenced by\ntheoretical assumptions and presuppositions. For example, the concepts\n“mass” and “length” have different meanings in\nNewtonian and relativistic mechanics; so does the concept\n“temperature” in thermodynamics and statistical mechanics\n(cf. Feyerabend 1962). In other words, Kuhn denies that there is a\ntheory-independent observation language. The “faithfulness to\nreality” of an observation report is always mediated by a\ntheoretical überbau, disabling the role of observation\nreports as an impartial, merely fact-dependent arbiter between\ndifferent theories. \nSecond, not only the observational concepts, but also the\nperception of a scientist depends on the paradigm she is\nworking in. \nPracticing in different worlds, the two groups of scientists [who work\nin different paradigms, J.R./J.S.] see different things when they look\nfrom the same point in the same direction. (Kuhn 1962 [1970: 150]) \nThat is, our own sense data are shaped and structured by a theoretical\nframework, and may be fundamentally distinct from the sense data of\nscientists working in another one. Where a Ptolemaic astronomer like\nTycho Brahe sees a sun setting behind the horizon, a Copernican\nastronomer like Johannes Kepler sees the horizon moving up to a\nstationary sun. If this picture is correct, then it is hard to assess\nwhich theory or paradigm is more faithful to the facts, that is, more\nobjective. \nThe thesis of the theory-ladenness of observation has also been\nextended to the incommensurability of different paradigms or\nscientific theories, problematized independently by Thomas S.\nKuhn (1962 [1970]) and Paul Feyerabend (1962). Literally, this concept\nmeans “having no measure in common”, and it figures\nprominently in arguments against a linear and standpoint-independent\npicture of scientific progress. For instance, the Special Theory of\nRelativity appears to be more faithful to the facts and therefore more\nobjective than Newtonian mechanics because it reduces, for low speeds,\nto the latter, and it accounts for some additional facts that are not\npredicted correctly by Newtonian mechanics. This picture is\nundermined, however, by two central aspects of incommensurability.\nFirst, not only do the observational concepts in both theories differ,\nbut the principles for specifying their meaning may be inconsistent\nwith each other (Feyerabend 1975: 269–270). Second, scientific\nresearch methods and standards of evaluation change with the theories\nor paradigms. Not all puzzles that could be tackled in the old\nparadigm will be solved by the new one—this is the phenomenon of\n“Kuhn loss”. \nA meaningful use of objectivity presupposes, according to Feyerabend,\nto perceive and to describe the world from a specific perspective,\ne.g., when we try to verify the referential claims of a scientific\ntheory. Only within a peculiar scientific worldview, the\nconcept of objectivity may be applied meaningfully. That is,\nscientific method cannot free itself from the particular scientific\ntheory to which it is applied; the door to standpoint-independence is\nlocked. As Feyerabend puts it: \nour epistemic activities may have a decisive influence even upon the\nmost solid piece of cosmological furniture—they make gods\ndisappear and replace them by heaps of atoms in empty space. (1978:\n70) \nKuhn and Feyerabend’s theses about theory-ladenness of\nobservation, and their implications for the objectivity of scientific\ninquiry have been much debated afterwards, and have often been\nmisunderstood in a social constructivist sense. Therefore Kuhn later\nreturned to the topic of scientific objectivity, of which he gives his\nown characterization in terms of the shared cognitive values of a\nscientific community. We discuss Kuhn’s later view in\n section 3.1.\n For a more thorough coverage, see the entries on\n theory and observation in science,\n the incommensurability of scientific theories and\n Thomas S. Kuhn. \nScientific theories are tested by comparing their implications with\nthe results of observations and experiments. Unfortunately, neither\npositive results (when the theory’s predictions are borne out in\nthe data) nor negative results (when they are not) allow unambiguous\ninferences about the theory. A positive result can obtain even though\nthe theory is false, due to some alternative that makes the same\npredictions. Finding suspect Jones’ fingerprints on the murder\nweapon is consistent with his innocence because he might have used it\nas a kitchen knife. A negative result might be due not to the\nfalsehood of the theory under test but due to the failing of one or\nmore auxiliary assumptions needed to derive a prediction from the\ntheory. Testing, let us say, the implications of Newton’s laws\nfor movements in our planetary system against observations requires\nassumptions about the number of planets, the sun’s and the\nplanets’ masses, the extent to which the earth’s\natmosphere refracts light beams, how telescopes affect the results and\nso on. Any of these may be false, explaining an inconsistency. The\nlocus classicus for these observations is Pierre\nDuhem’s The Aim and Structure of Physical Theory (Duhem\n1906 [1954]). Duhem concluded that there was no “crucial\nexperiment”, an experiment that conclusively decides between two\nalternative theories, in physics (1906 [1954: 188ff.]), and that\nphysicists had to employ their expert judgment or what Duhem called\n“good sense” to determine what an experimental result\nmeans for the truth or falsehood of a theory (1906 [1954:\n216ff.]). \nIn other words, there is a gap between the evidence and the theory\nsupported by it. It is important to note that the alleged gap is more\nprofound than the gap between the premisses of any inductive\nargument and its conclusion, say, the gap between “All hitherto\nobserved ravens have been black” and “All ravens are\nblack”. The latter gap could be bridged by an agreed upon rule\nof inductive reasoning. Alas, all attempts to find an analogous rule\nfor theory choice have failed (e.g., Norton 2003). Various\nphilosophers, historians, and sociologists of science have responded\nthat theory appraisal is “a complex form of value\njudgment” (McMullin 1982: 701; see also Kuhn 1977; Hesse 1980;\nBloor 1982). \nIn\n section 3.1\n below we will discuss the nature of the value judgments in more\ndetail. For now the important lesson is that if these philosophers,\nhistorians, and sociologists are correct, the “faithfulness to\nfacts” ideal is untenable. As the scientific image of the world\nis a joint product of the facts and scientists’ value judgments,\nthat image cannot be said to be aperspectival. Science does not eschew\nthe human perspective. There are of course ways to escape this\nconclusion. If, as John Norton (2003; ms.—see Other Internet\nResources) has argued, it is material facts that power and justify\ninductive inferences, and not value judgments, we can avoid the\nnegative conclusion regarding the view from nowhere. Unsurprisingly,\nNorton is also critical of the idea that evidence generally\nunderdetermines theory (Norton 2008). However, there are good reasons\nto mistrust Norton’s optimism regarding the ineliminability of\nvalues and other non-factual elements in inductive inferences (Reiss\n2020). \nThere is another, closely related concern. Most of the earlier critics\nof “objective” verification or falsification focused on\nthe relation between evidence and scientific theories. There is a\nsense in which the claim that this relation is problematic is not so\nsurprising. Scientific theories contain highly abstract claims that\ndescribe states of affairs far removed from the immediacy of sense\nexperience. This is for a good reason: sense experience is necessarily\nperspectival, so to the extent to which scientific theories are to\ntrack the absolute conception, they must describe a world different\nfrom that of sense experience. But surely, one might think, the\nevidence itself is objective. So even if we do have reasons to doubt\nthat abstract theories faithfully represent the world, we should stand\non firmer grounds when it comes to the evidence against which we test\nabstract theories. \nTheories are seldom tested against brute observations, however. Simple\ngeneralizations such as “all swans are white” are directly\nlearned from observations (say, of the color of swans) but they do not\nrepresent the view from nowhere (for one thing, the view from nowhere\ndoesn’t have colors). Genuine scientific theories are tested\nagainst experimental facts or phenomena, which are themselves\nunobservable to the unaided senses. Experimental facts or phenomena\nare instead established using intricate procedures of measurement and\nexperimentation. \nWe therefore need to ask whether the results of scientific\nmeasurements and experiments can be aperspectival. In an important\ndebate in the 1980s and 1990s some commentators answered that question\nwith a resounding “no”, which was then rebutted by others.\nThe debate concerns the so-called “experimenter’s\nregress” (Collins 1985). Collins, a prominent sociologist of\nscience, claims that in order to know whether an experimental result\nis correct, one first needs to know whether the apparatus producing\nthe result is reliable. But one doesn’t know whether the\napparatus is reliable unless one knows that it produces correct\nresults in the first place and so on and so on ad infinitum.\nCollins’ main case concerns attempts to detect gravitational\nwaves, which were very controversially discussed among physicists in\nthe 1970s. \nCollins argues that the circle is eventually broken not by the\n“facts” themselves but rather by factors having to do with\nthe scientist’s career, the social and cognitive interests of\nhis community, and the expected fruitfulness for future work. It is\nimportant to note that in Collins’s view these factors do not\nnecessarily make scientific results arbitrary. But what he does argue\nis that the experimental results do not represent the world according\nto the absolute conception. Rather, they are produced jointly by the\nworld, scientific apparatuses, and the psychological and sociological\nfactors mentioned above. The facts and phenomena of science are\ntherefore necessarily perspectival. \nIn a series of contributions, Allan Franklin, a\nphysicist-turned-philosopher of science, has tried to show that while\nthere are indeed no algorithmic procedures for establishing\nexperimental facts, disagreements can nevertheless be settled by\nreasoned judgment on the basis of bona fide\nepistemological criteria such as experimental checks and calibration,\nelimination of possible sources of error, using apparatuses based on\nwell-corroborated theory and so on (Franklin 1994, 1997). Collins\nresponds that “reasonableness” is a social category that\nis not drawn from physics (Collins 1994). \nThe main issue for us in this debate is whether there are any reasons\nto believe that experimental results provide an aperspectival view on\nthe world. According to Collins, experimental results are\nco-determined by the facts as well as social and psychological\nfactors. According to Franklin, whatever else influences experimental\nresults other than facts is not arbitrary but instead based on\nreasoned judgment. What he has not shown is that reasoned judgment\nguarantees that experimental results reflect the facts alone and are\ntherefore aperspectival in any interesting sense. Another important\nchallenge for the aperspectival account comes from feminist\nepistemology and other accounts that stress the importance of the\nconstruction of scientific knowledge through epistemic communities.\nThese accounts are reviewed in\n section 5. \nIn the previous section we have presented arguments against the view\nof objectivity as faithfulness to facts and an impersonal “view\nfrom nowhere”. An alternative view is that science is objective\nto the extent that it is value-free. Why would we identify\nobjectivity with value-freedom or regard the latter as a prerequisite\nfor the former? Part of the answer is empiricism. If science is in the\nbusiness of producing empirical knowledge, and if differences about\nvalue judgments cannot be settled by empirical means, values should\nhave no place in science. In the following we will try to make this\nintuition more precise. \nBefore addressing what we will call the “value-free\nideal”, it will be helpful to distinguish four stages at which\nvalues may affect science. They are: (i) the choice of a scientific\nresearch problem; (ii) the gathering of evidence in relation to the\nproblem; (iii) the acceptance of a scientific hypothesis or theory as\nan adequate answer to the problem on the basis of the evidence; (iv)\nthe proliferation and application of scientific research results\n(Weber 1917 [1949]). \nMost philosophers of science would agree that the role of values in\nscience is contentious only with respect to dimensions (ii) and (iii):\nthe gathering of evidence and the acceptance\nof scientific theories. It is almost universally accepted\nthat the choice of a research problem is often influenced by interests\nof individual scientists, funding parties, and society as a whole.\nThis influence may make science more shallow and slow down its\nlong-run progress, but it has benefits, too: scientists will focus on\nproviding solutions to those intellectual problems that are considered\nurgent by society and they may actually improve people’s lives.\nSimilarly, the proliferation and application of scientific research\nresults is evidently affected by the personal values of journal\neditors and end users, and little can be done about this. The real\ndebate is about whether or not the “core” of scientific\nreasoning—the gathering of evidence and the assessment and\nacceptance scientific theories—is, and should be,\nvalue-free. \nWe have introduced the problem of the underdetermination of theory by\nevidence above. The problem does not stop, however, at values being\nrequired for filling the gap between theory and evidence. A further\ncomplication is that these values can conflict with each other.\nConsider the classical problem of fitting a mathematical function to a\ndata set. The researcher often has the choice between using a complex\nfunction, which makes the relationship between the variables less\nsimple but fits the data more accurately, or\npostulating a simpler relationship that is less\naccurate. Simplicity and accuracy are both important\ncognitive values, and trading them off requires a careful value\njudgment. However, philosophers of science tend to regard\nvalue-ladenness in this sense as benign. Cognitive\nvalues (sometimes also called “epistemic” or\n“constitutive” values) such as predictive accuracy, scope,\nunification, explanatory power, simplicity and coherence with other\naccepted theories are taken to be indicative of the truth of a theory\nand therefore provide reasons for preferring one theory over another\n(McMullin 1982, 2009; Laudan 1984; Steel 2010). Kuhn (1977) even\nclaims that cognitive values define the shared commitments of science,\nthat is, the standards of theory assessment that characterize the\nscientific approach as a whole. Note that not every philosopher\nentertains the same list of cognitive values: subjective differences\nin ranking and applying cognitive values do not vanish, a point Kuhn\nmade emphatically. \nIn most views, the objectivity and authority of science is not\nthreatened by cognitive values, but only by\nnon-cognitive or contextual values.\nContextual values are moral, personal, social, political and cultural\nvalues such as pleasure, justice and equality, conservation of the\nnatural environment and diversity. The most notorious cases of\nimproper uses of such values involve travesties of scientific\nreasoning, where the intrusion of contextual values led to an\nintolerant and oppressive scientific agenda with devastating epistemic\nand social consequences. In the Third Reich, a large part of\ncontemporary physics, such as the theory of relativity, was condemned\nbecause its inventors were Jewish; in the Soviet Union, biologist\nNikolai Vavilov was sentenced to death (and died in prison) because\nhis theories of genetic inheritance did not match Marxist-Leninist\nideology. Both states tried to foster a science that was motivated by\npolitical convictions (“Deutsche Physik” in Nazi Germany,\nLysenko’s Lamarckian theory of inheritance and denial of\ngenetics), leading to disastrous epistemic and institutional\neffects. \nLess spectacular, but arguably more frequent are cases where research\nis biased toward the interests of the sponsors, such as tobacco\ncompanies, food manufacturers and large pharmaceutic firms (e.g.,\nResnik 2007; Reiss 2010). This preference bias,\ndefined by Wilholt (2009) as the infringement of conventional\nstandards of the research community with the aim of arriving at a\nparticular result, is clearly epistemically harmful. Especially for\nsensitive high-stakes issues such as the admission of medical drugs or\nthe consequences of anthropogenic global warming, it seems desirable\nthat research scientists assess theories without being influenced by\nsuch considerations. This is the core idea of the \nValue-Free Ideal (VFI): Scientists should strive to\nminimize the influence of contextual values on scientific reasoning,\ne.g., in gathering evidence and assessing/accepting scientific\ntheories. \nAccording to the VFI, scientific objectivity is characterized by\nabsence of contextual values and by exclusive commitment to cognitive\nvalues in stages (ii) and (iii) of the scientific process. See Dorato\n(2004: 53–54), Ruphy (2006: 190) or Biddle (2013: 125) for\nalternative formulations. \nFor value-freedom to be a reasonable ideal, it must not be a goal\nbeyond reach and be attainable at least to some degree. This claim is\nexpressed by the \nValue-Neutrality Thesis (VNT): Scientists\ncan—at least in principle—gather evidence and\nassess/accept theories without making contextual value judgments. \nUnlike the VFI, the VNT is not normative: its subject is whether the\njudgments that scientists make are, or could possibly be, free of\ncontextual values. Similarly, Hugh Lacey (1999) distinguishes three\nprincipal components or aspects of value-free science: impartiality,\nneutrality and autonomy. Impartiality means that\ntheories are solely accepted or appraised in virtue of their\ncontribution to the cognitive values of science, such as truth,\naccuracy or explanatory power. This excludes the influence of\ncontextual values, as stated above. Neutrality means\nthat scientific theories make no value statements about the world:\nthey are concerned with what there is, not with what there should be.\nFinally, scientific autonomy means that the\nscientific agenda is shaped by the desire to increase scientific\nknowledge, and that contextual values have no place in scientific\nmethod. \nThese three interpretations of value-free science can be combined with\neach other, or used individually. All of them, however, are subject to\ncriticisms that we examine below. Denying the VNT, or the\nattainability of Lacey’s three criteria for value-free science,\nposes a challenge for scientific objectivity: one can either conclude\nthat the ideal of objectivity should be rejected, or develop a\nconception of objectivity that differs from the VFI. \nLacey’s characterization of value-free science and the VNT were\nonce mainstream positions in philosophy of science. Their widespread\nacceptance was closely connected to Reichenbach’s famous\ndistinction between context of discovery and\ncontext of justification. Reichenbach first made this\ndistinction with respect to the epistemology of mathematics: \nthe objective relation from the given entities to the solution, and\nthe subjective way of finding it, are clearly separated for problems\nof a deductive character […] we must learn to make the same\ndistinction for the problem of the inductive relation from facts to\ntheories. (Reichenbach 1938: 36–37) \nThe standard interpretation of this statement marks contextual values,\nwhich may have contributed to the discovery of a theory, as irrelevant\nfor justifying the acceptance of a theory, and for assessing\nhow evidence bears on theory—the relation that is crucial for\nthe objectivity of science. Contextual values are restricted to a\nmatter of individual psychology that may influence the discovery,\ndevelopment and proliferation of a scientific theory, but not its\nepistemic status. \nThis distinction played a crucial role in post-World War II philosophy\nof science. It presupposes, however, a clear-cut distinction between\ncognitive values on the one hand and contextual values on the other.\nWhile this may be prima facie plausible for disciplines such\nas physics, there is an abundance of contextual values in the social\nsciences, for instance, in the conceptualization and measurement of a\nnation’s wealth, or in different ways to measure the inflation\nrate (cf. Dupré 2007; Reiss 2008). More generally, three major\nlines of criticism can be identified. \nFirst, Helen Longino (1996) has argued that traditional cognitive\nvalues such as consistency, simplicity, breadth of scope and\nfruitfulness are not purely cognitive or epistemic after all, and that\ntheir use imports political and social values into contexts of\nscientific judgment. According to her, the use of cognitive values in\nscientific judgments is not always, not even normally, politically\nneutral. She proposes to juxtapose these values with feminist values\nsuch as novelty, ontological heterogeneity, mutuality of interaction,\napplicability to human needs and diffusion of power, and argues that\nthe use of the traditional value instead of its alternative (e.g.,\nsimplicity instead of ontological heterogeneity) can lead to biases\nand adverse research results. Longino’s argument here is\ndifferent from the one discussed in\n section 3.1.\n It casts the very distinction between cognitive and contextual values\ninto doubt. \nThe second argument against the possibility of value-free science is\nsemantic and attacks the neutrality of scientific theories: fact and\nvalue are frequently entangled because of the use of so-called\n“thick” ethical concepts in science (Putnam\n2002)—i.e., ethical concepts that have mixed descriptive and\nnormative content. For example, a description such as “dangerous\ntechnology” involves a value judgment about the technology and\nthe risks it implies, but it also has a descriptive content: it is\nuncertain and hard to predict whether using that technology will\nreally trigger those risks. If the use of such terms, where facts and\nvalues are inextricably entangled, is inevitable in scientific\nreasoning, it is impossible to describe hypotheses and results in a\nvalue-free manner, undermining the value-neutrality thesis. \nIndeed, John Dupré has argued that thick ethical terms are\nineliminable from science, at least certain parts of it (Dupré\n2007). Dupré’s point is essentially that scientific\nhypotheses and results concern us because they are relevant to human\ninterests, and thus they will necessarily be couched in a language\nthat uses thick ethical terms. While it will often be possible to\ntranslate ethically thick descriptions into neutral ones, the\ntranslation cannot be made without losses, and these losses obtain\nprecisely because human interests are involved (see\n section 6.2\n for a case study from social science). According to Dupré,\nthen, many scientific statements are value-free only because their\ntruth or falsity does not matter to us: \nWhether electrons have a positive or a negative charge and whether\nthere is a black hole in the middle of our galaxy are questions of\nabsolutely no immediate importance to us. The only human interests\nthey touch (and these they may indeed touch deeply) are cognitive\nones, and so the only values that they implicate are cognitive values.\n(2007: 31) \nA third challenge to the VNT, and perhaps the most influential one,\nwas raised first by Richard Rudner in his influential article\n“The Scientist Qua Scientist Makes Value Judgments”\n(Rudner 1953). Rudner disputes the core of the VNT and the context of\ndiscovery/justification distinction: the idea that the acceptance of a\nscientific theory can in principle be value-free. First, Rudner argues\nthat \nno analysis of what constitutes the method of science would be\nsatisfactory unless it comprised some assertion to the effect that the\nscientist as scientist accepts or rejects hypotheses.\n(1953: 2) \nThis assumption stems from industrial quality control and other\napplication-oriented research. In such contexts, it is often necessary\nto accept or to reject a hypothesis (e.g., the efficacy of a drug) in\norder to make effective decisions. \nSecond, he notes that no scientific hypothesis is ever confirmed\nbeyond reasonable doubt—some probability of error always\nremains. When we accept or reject a hypothesis, there is always a\nchance that our decision is mistaken. Hence, our decision is also\n“a function of the importance, in the typically ethical\nsense, of making a mistake in accepting or rejecting a\nhypothesis” (1953: 2): we are balancing the seriousness of two\npossible errors (erroneous acceptance/rejection of the hypothesis)\nagainst each other. This corresponds to type I and type II error in\nstatistical inference. \nThe decision to accept or reject a hypothesis involves a value\njudgment (at least implicitly) because scientists have to judge which\nof the consequences of an erroneous decision they deem more palatable:\n(1) some individuals die of the side effects of a drug erroneously\njudged to be safe; or (2) other individuals die of a condition because\nthey did not have access to a treatment that was erroneously judged to\nbe unsafe. Hence, ethical judgments and contextual values necessarily\nenter the scientist’s core activity of accepting and rejecting\nhypotheses, and the VNT stands refuted. Closely related arguments can\nbe found in Churchman (1948) and Braithwaite (1953). Hempel (1965:\n91–92) gives a modified account of Rudner’s argument by\ndistinguishing between judgments of confirmation, which are\nfree of contextual values, and judgments of acceptance. Since\neven strongly confirming evidence cannot fully prove a universal\nscientific law, we have to live with a residual “inductive\nrisk” in inferring that law. Contextual values influence\nscientific methods by determining the acceptable amount of inductive\nrisk (see also Douglas 2000). \nBut how general are Rudner’s objections? Apparently, his result\nholds true of applied science, but not necessarily of fundamental\nresearch. For the latter domain, two major lines of rebuttals have\nbeen proposed. First, Richard Jeffrey (1956) notes that lawlike\nhypotheses in theoretical science (e.g., the gravitational law in\nNewtonian mechanics) are characterized by their general scope and not\nconfined to a particular application. Obviously, a scientist cannot\nfine-tune her decisions to their possible consequences in a wide\nvariety of different contexts. So she should just refrain from the\nessentially pragmatic decision to accept or reject hypotheses. By\nrestricting scientific reasoning to gathering and interpreting\nevidence, possibly supplemented by assessing the probability of a\nhypothesis, Jeffrey tries to save the VNT in fundamental scientific\nresearch, and the objectivity of scientific reasoning. \nSecond, Isaac Levi (1960) observes that scientists commit themselves\nto certain standards of inference when they become a member of the\nprofession. This may, for example, lead to the statistical rejection\nof a hypothesis when the observed significance level is smaller than\n5%. These community standards may eliminate any room for contextual\nethical judgment on behalf of the scientist: they determine when she\nshould accept a hypothesis as established. Value judgments may be\nimplicit in how a scientific community sets standards of inference\n(compare\n section 5.1),\n but not in the daily work of an individual scientist (cf.\nWilholt 2013). \nBoth defenses of the VNT focus on the impact of values in theory\nchoice, either by denying that scientists actually choose theories\n(Jeffrey), or by referring to community standards and restricting the\nVNT to the individual scientist (Levi). Douglas (2000: 563–565)\npoints out, however, that the “acceptance” of scientific\ntheories is only one of several places for values to enter scientific\nreasoning, albeit an especially prominent and explicit one. Many\ndecisions in the process of scientific inquiry may conceal implicit\nvalue judgments: the design of an experiment, the methodology for\nconducting it, the characterization of the data, the choice of a\nstatistical method for processing and analyzing data, the\ninterpretational process findings, etc. None of these methodological\ndecisions could be made without consideration of the possible\nconsequences that could occur. Douglas gives, as a case study, a\nseries of experiments where carcinogenic effects of dioxin exposure on\nrats were probed. Contextual values such as safety and risk aversion\naffected the conducted research at various stages: first, in the\nclassification of pathological samples as benign or cancerous (over\nwhich a lot of expert disagreement occurred), second, in the\nextrapolation from the high-dose experimental conditions to the more\nrealistic low-dose conditions. In both cases, the choice of a\nconservative classification or model had to be weighed against the\nadverse consequences for society that could result from\nunderestimating the risks (see also Biddle 2013). \nThese diagnoses cast a gloomy light on attempts to divide scientific\nlabor between gathering evidence and determining the degree of\nconfirmation (value-free) on the one hand and accepting scientific\ntheories (value-laden) on the other. The entire process of\nconceptualizing, gathering and interpreting evidence is so entangled\nwith contextual values that no neat division, as Jeffrey envisions,\nwill work outside the narrow realm of statistical inference—and\neven there, doubts may be raised\n (see section 4.2). \nPhilip Kitcher (2011a: 31–40; see also Kitcher 2011b) gives an\nalternative argument, based on his idea of “significant\ntruths”. There are simply too many truths that are of no\ninterest whatsoever, such as the total number of offside positions in\na low-level football competition. Science, then, doesn’t aim at\ntruth simpliciter but rather at something more narrow: truth\nworth pursuing from the point of view of our cognitive, practical and\nsocial goals. Any truth that is worth pursuing in this sense is what\nhe calls a “significant truth”. Clearly, it is value\njudgments that help us decide whether or not any given truth is\nsignificant. \nKitcher goes on to observing that the process of scientific\ninvestigation cannot neatly be divided into a stage in which the\nresearch question is chosen, one in which the evidence is gathered and\none in which a judgment about the question is made on the basis of the\nevidence. Rather, the sequence is multiply iterated, and at each\nstage, the researcher has to decide whether previous results warrant\npursuit of the current line of research, or whether she should switch\nto another avenue. Such choices are laden with contextual values. \nValues in science also interact, according to Kitcher, in a\nnon-trivial way. Assume we endorse predictive accuracy as an important\ngoal of science. However, there may not be a convincing strategy to\nreach this goal in some domain of science, for instance because that\ndomain is characterized by strong non-linear dependencies. In this\ncase, predictive accuracy might have to yield to achieving other\nvalues, such as consistency with theories in neighbor domains.\nConversely, changing social goals lead to re-evaluations of scientific\nknowledge and research methods. \nScience, then, cannot be value-free because no scientist ever works\nexclusively in the supposedly value-free zone of assessing and\naccepting hypotheses. Evidence is gathered and hypotheses are assessed\nand accepted in the light of their potential for application and\nfruitful research avenues. Both cognitive and contextual value\njudgments guide these choices and are themselves influenced by their\nresults. \nThe discussion so far has focused on the VNT, the practical\nattainability of the VFI, but little has been said about whether a\nvalue-free science is desirable in the first place. This subsection\ndiscusses this topic with special attention to informing and advising\npublic policy from a scientific perspective. While the VFI, and many\narguments for and against it, can be applied to science as a whole,\nthe interface of science and public policy is the place where the\nintrusion of values into science is especially salient, and where it\nis surrounded by the greatest controversy. In the 2009\n“Climategate” affair, leaked emails from climate\nscientists raised suspicions that they were pursuing a particular\nsocio-political agenda that affected their research in an improper\nway. Later inquiries and reports absolved them from charges of\nmisconduct, but the suspicions alone did much to damage the authority\nof science in the public arena. \nIndeed, many debates at the interface of science and public policy are\ncharacterized by disagreements on propositions that combine a factual\nbasis with specific goals and values. Take, for instance, the view\nthat growing transgenic crops carries too much risk in terms of\nbiosecurity, or addressing global warming by phasing out fossil\nenergies immediately. The critical question in such debates is whether\nthere are theses \\(T\\) such that one side in the debate endorses\n\\(T\\), the other side rejects it, the evidence is shared, and both\nsides have good reasons for their respective positions. \nAccording to the VFI, scientists should uncover an epistemic,\nvalue-free basis for resolving such disagreements and restrict the\ndissent to the realm of value judgments. Even if the VNT should turn\nout to be untenable, and a strict separation to be impossible, the VFI\nmay have an important function for guiding scientific\nresearch and for minimizing the impact of values on an objective\nscience. In the philosophy of science, one camp of scholars defends\nthe VFI as a necessary antidote to individual and institutional\ninterests, such as Hugh Lacey (1999, 2002), Ernan McMullin (1982) and\nSandra Mitchell (2004), while others adopt a critical attitude, such\nas Helen Longino (1990, 1996), Philip Kitcher (2011a) and Heather\nDouglas (2009). These criticisms we discuss mainly refer to the\ndesirability or the conceptual (un)clarity of the VFI. \nFirst, it has been argued that the VFI is not desirable at all.\nFeminist philosophers (e.g., Harding 1991; Okruhlik 1994; Lloyd 2005)\nhave argued that science often carries a heavy androcentric values,\nfor instance in biological theories about sex, gender and rape. The\ncharge against these values is not so much that they are contextual\nrather than cognitive, but that they are unjustified. Moreover, if\nscientists did follow the VFI rigidly, policy-makers would pay even\nless attention to them, with a detrimental effect on the decisions\nthey take (Cranor 1993). Given these shortcomings, the VFI has to be\nrethought if it is supposed to play a useful role for guiding\nscientific research and leading to better policy decisions.\n Section 4.3\n and\n section 5.2\n elaborate on this line of criticism in the context of scientific\ncommunity practices, and a science in the service of society. \nSecond, the autonomy of science often fails in practice due to the\npresence of external stakeholders, such as funding agencies and\nindustry lobbies. To save the epistemic authority of science, Douglas\n(2009: 7–8) proposes to detach it from its autonomy by\nreformulating the VFI and distinguishing between direct and\nindirect roles of values in science. Contextual values may\nlegitimately affect the assessment of evidence by indicating the\nappropriate standard of evidence, the representation of complex\nprocesses, the severity of consequences of a decision, the\ninterpretation of noisy datasets, and so on (see also Winsberg 2012).\nThis concerns, above all, policy-related disciplines such as climate\nscience or economics that routinely perform scientific risk analyses\nfor real-world problems (cf. also Shrader-Frechette 1991). Values\nshould, however, not be “reasons in themselves”, that is,\nevidence or defeaters for evidence (direct role, illegitimate) and as\n“helping to decide what should count as a sufficient\nreason for a choice” (indirect role, legitimate). This\nprohibition for values to replace or dismiss scientific evidence is\ncalled detached objectivity by Douglas, but it is\ncomplemented by various other aspects that relate to a reflective\nbalancing of various perspectives and the procedural, social aspects\nof science (2009: ch. 6). \nThat said, Douglas’ proposal is not very concrete when it comes\nto implementation, e.g., regarding the way diverse values should be\nbalanced. Compromising in the middle cannot be the solution (Weber\n1917 [1949]). First, no standpoint is, just in virtue of being in the\nmiddle, evidentially supported vis-à-vis more extreme\npositions. Second, these middle positions are also, from a practical\npoint of view, the least functional when it comes to advising\npolicy-makers. \nMoreover, the distinction between direct and indirect roles of values\nin science may not be sufficiently clear-cut to police the legitimate\nuse of values in science, and to draw the necessary borderlines.\nAssume that a scientist considers, for whatever reason, the\nconsequences of erroneously accepting hypothesis \\(H\\) undesirable.\nTherefore he uses a statistical model whose results are likely to\nfavor ¬\\(H\\) over \\(H\\). Is this a matter of reasonable\nconservativeness? Or doesn’t it amount to reasoning to a\nforegone conclusion, and to treating values as evidence (cf. Elliott\n2011: 320–321)? \nThe most recent literature on values and evidence in science presents\nus with a broad spectrum of opinions. Steele (2012) and Winsberg\n(2012) agree that probabilistic assessments of uncertainty involve\ncontextual value judgments. While Steele defends this point by\nanalyzing the role of scientists as policy advisors, Winsberg points\nto the influence of contextual values in the selection and\nrepresentation of physical processes in climate modeling. Betz (2013)\nargues, by contrast, that scientists can largely avoid making\ncontextual value judgments if they carefully express the uncertainty\ninvolved with their evidential judgments, e.g., by using a scale\nranging from purely qualitative evidence (such as expert judgment) to\nprecise probabilistic assessments. The issue of value judgments at\nearlier stages of inquiry is not addressed by this proposal; however,\ndisentangling evidential judgments and judgments involving contextual\nvalues at the stage of theory assessment may be a good thing in\nitself. \nThus, should we or should we not worried about values in scientific\nreasoning? While the interplay of values and evidential considerations\nneed not be pernicious, it is unclear why it adds to the\nsuccess or the authority of science. How are we going to ensure that\nthe permissive attitude towards values in setting evidential standards\netc. is not abused? In the absence of a general theory about which\ncontextual values are beneficial and which are pernicious, the VFI\nmight as well be as a first-order approximation to a sound,\ntransparent and objective science. \nThis section deals with scientific objectivity as a form of\nintersubjectivity—as freedom from personal biases. According to\nthis view, science is objective to the extent that personal biases are\nabsent from scientific reasoning, or that they can be eliminated in a\nsocial process. Perhaps all science is necessarily perspectival.\nPerhaps we cannot sensibly draw scientific inferences without a host\nof background assumptions, which may include assumptions about values.\nPerhaps all scientists are biased in some way. But objective\nscientific results do not, or so the argument goes, depend on\nresearchers’ personal preferences or experiences—they are\nthe result of a process where individual biases are gradually filtered\nout and replaced by agreed upon evidence. That, among other things, is\nwhat distinguishes science from the arts and other human activities,\nand scientific knowledge from a fact-independent social construction\n(e.g., Haack 2003). \nParadigmatic ways to achieve objectivity in this sense are measurement\nand quantification. What has been measured and quantified has been\nverified relative to a standard. The truth, say, that the Eiffel Tower\nis 324 meters tall is relative to a standard unit and conventions\nabout how to use certain instruments, so it is neither aperspectival\nnor free from assumptions, but it is independent of the person making\nthe measurement. \nWe will begin with a discussion of objectivity, so conceived, in\nmeasurement, discuss the ideal of “mechanical objectivity”\nand then investigate to what extent freedom from personal biases can\nbe implemented in statistical evidence and inductive\ninference—arguably the core of scientific reasoning, especially\nin quantitatively oriented sciences. Finally, we discuss\nFeyerabend’s radical criticism of a rational scientific method\nthat can be mechanically applied, and his defense of the epistemic and\nsocial benefits of personal “bias” and idiosyncrasy. \nMeasurement is often thought to epitomize scientific objectivity, most\nfamously captured in Lord Kelvin’s dictum \nwhen you cannot express it in numbers, your knowledge is of a meagre\nand unsatisfactory kind; it may be the beginning of knowledge, but you\nhave scarcely, in your thoughts, advanced to the stage of\nscience, whatever the matter may be. (Kelvin 1883, 73) \nMeasurement can certainly achieve some independence of perspective.\nYesterday’s weather in Durham UK may have been “really\nhot” to the average North Eastern Brit and “very\ncold” to the average Mexican, but they’ll both accept that\nit was 21°C. Clearly, however, measurement does not result in a\n“view from nowhere”, nor are typical measurement results\nfree from presuppositions. Measurement instruments interact with the\nenvironment, and so results will always be a product of both the\nproperties of the environment we aim to measure as well as the\nproperties of the instrument. Instruments, thus, provide a\nperspectival view on the world (cf. Giere 2006). \nMoreover, making sense of measurement results requires interpretation.\nConsider temperature measurement. Thermometers function by relating an\nunobservable quantity, temperature, to an observable quantity,\nexpansion (or length) of a fluid or gas in a glass tube; that is,\nthermometers measure temperature by assuming that length is a function\nof temperature: length = \\(f\\)(temperature). The function \\(f\\) is not\nknown a priori, and it cannot be tested either (because it\ncould in principle only be tested using a veridical\nthermometer, and the veridicality of the thermometer is just what is\nat stake here). Making a specific assumption, for instance that \\(f\\)\nis linear, solves that problem by fiat. But this\n“solution” does not take us very far because different\nthermometric substances (e.g., mercury, air or water) yield different\nresults for the points intermediate between the two fixed points\n0°C and 100°C, and so they can’t all expand\nlinearly. \nAccording to Hasok Chang’s account of early thermometry (Chang\n2004), the problem was eventually solved by using a “principle\nof minimalist overdetermination”, the goal of which was to find\na reliable thermometer while making as few substantial assumptions\n(e.g., about the form for \\(f\\)) as possible. It was argued that if a\nthermometer was to be reliable, different tokens of the same\nthermometer type should agree with each other, and the results of air\nthermometers agreed the most. “Minimal” doesn’t mean\nzero, however, and indeed this procedure makes an important\npresupposition (in this case a metaphysical assumption about the\none-valuedness of a physical quantity). Moreover, the procedure\nyielded at best a reliable instrument, not necessarily one that was\nbest at tracking the uniquely real temperature (if there is such a\nthing). \nWhat Chang argues about early thermometry is true of measurements more\ngenerally: they are always made against a backdrop of metaphysical\npresuppositions, theoretical expectations and other kinds of belief.\nWhether or not any given procedure is regarded as adequate depends to\na large extent on the purposes pursued by the individual scientist or\ngroup of scientists making the measurements. Especially in the social\nsciences, this often means that measurement procedures are laden with\nnormative assumptions, i.e., values. \nJulian Reiss (2008, 2013) has argued that economic indicators such as\nconsumer price inflation, gross domestic product and the unemployment\nrate are value-laden in this sense. Consumer-price indices, for\ninstance, assume that if a consumer prefers a bundle \\(x\\) over an\nalternative \\(y\\), then \\(x\\) is better for her than \\(y\\), which is\nas ethically charged as it is controversial. National income measures\nassume that nations that exchange a larger share of goods and services\non markets are richer than nations where the same goods and services\nare provided by the government or within households, which too is\nethically charged and controversial. \nWhile not free of assumptions and values, the goal of many measurement\nprocedures remains to reduce the influence of personal biases and\nidiosyncrasies. The Nixon administration, famously, indexed social\nsecurity payments to the consumer-price index in order to eliminate\nthe dependence of security recipients on the flimsiest of party\npolitics: to make increases automatic instead of a result of political\nnegotiations (Nixon 1969). Lorraine Daston and Peter Galison refer to\nthis as mechanical objectivity. They write: \nFinally, we come to the full-fledged establishment of mechanical\nobjectivity as the ideal of scientific representation. What we find is\nthat the image, as standard bearer of is objectivity is tied to a\nrelentless search to replace individual volition and discretion in\ndepiction by the invariable routines of mechanical reproduction.\n(Daston and Galison 1992: 98) \nMechanical objectivity reduces the importance of human contributions\nto scientific results to a minimum, and therefore enables science to\nproceed on a large scale where bonds of trust between individuals can\nno longer hold (Daston 1992). Trust in mechanical procedures thus\nreplaces trust in individual scientists. \nIn his book Trust in Numbers, Theodore Porter pursues this\nline of thought in great detail. In particular, on the basis of case\nstudies involving British actuaries in the mid-nineteenth century, of\nFrench state engineers throughout the century, and of the US Army\nCorps of Engineers from 1920 to 1960, he argues for two causal claims.\nFirst, measurement instruments and quantitative procedures originate\nin commercial and administrative needs and affect the ways in which\nthe natural and social sciences are practiced, not the other way\naround. The mushrooming of instruments such as chemical balances,\nbarometers, chronometers was largely a result of social pressures and\nthe demands of democratic societies. Administering large territories\nor controlling diverse people and processes is not always possible on\nthe basis of personal trust and thus “objective\nprocedures” (which do not require trust in persons) took the\nplace of “subjective judgments” (which do). Second, he\nargues that quantification is a technology of distrust and weakness,\nand not of strength. It is weak administrators who do not have the\nsocial status, political support or professional solidarity to defend\ntheir experts’ judgments. They therefore subject decisions to\npublic scrutiny, which means that they must be made in a publicly\naccessible form. \nThis is the situation in which scientists who work in areas where the\nscience/policy boundary is fluid find themselves: \nThe National Academy of Sciences has accepted the principle that\nscientists should declare their conflicts of interest and financial\nholdings before offering policy advice, or even information to the\ngovernment. And while police inspections of notebooks remain\nexceptional, the personal and financial interests of scientists and\nengineers are often considered material, especially in legal and\nregulatory contexts. \nStrategies of impersonality must be understood partly as defenses\nagainst such suspicions […]. Objectivity means knowledge that\ndoes not depend too much on the particular individuals who author it.\n(Porter 1995: 229) \nMeasurement and quantification help to reduce the influence of\npersonal biases and idiosyncrasies and they reduce the need to trust\nthe scientist or government official, but often at a cost.\nStandardizing scientific procedures becomes difficult when their\nsubject matters are not homogeneous, and few domains outside\nfundamental physics are. Attempts to quantify procedures for treatment\nand policy decisions that we find in evidence-based practices are\ncurrently transferred to a variety of sciences such as medicine,\nnursing, psychology, education and social policy. However, they often\nlack a certain degree of responsiveness to the peculiarities of their\nsubjects and the local conditions to which they are applied (see also\n section 5.3). \nMoreover, the measurement and quantification of characteristics of\nscientific interest is only half of the story. We also want to\ndescribe relations between the quantities and make inferences using\nstatistical analysis. Statistics thus helps to quantify further\naspects of scientific work. We will now examine whether or not\nstatistical analysis can proceed in a way free from personal biases\nand idiosyncrasies—for more detail, see the entry on\n philosophy of statistics. \nThe appraisal of scientific evidence is traditionally regarded as a\ndomain of scientific reasoning where the ideal of scientific\nobjectivity has strong normative force, and where it is also\nwell-entrenched in scientific practice. Episodes such as\nGalilei’s observations of the Jupiter moons, Lavoisier’s\ncalcination experiments, and Eddington’s observation of the 1919\neclipse are found in all philosophy of science textbooks because they\nexemplify how evidence can be persuasive and compelling to scientists\nwith different backgrounds. The crucial question is therefore: can we\nidentify an “objective” concept of scientific evidence\nthat is independent of the personal biases of the experimenter and\ninterpreter? \nInferential statistics—the field that investigates the validity\nof inferences from data to theory—tries to answer this question.\nIt is extremely influential in modern science, pervading experimental\nresearch as well as the assessment and acceptance of our most\nfundamental theories. For instance, a statistical argument helped to\nestablish the recent discovery of the Higgs Boson. We now compare the\nmain theories of statistical evidence with respect to the objectivity\nof the claims they produce. They mainly differ with respect to the\nrole of an explicitly subjective interpretation of probability. \nBayesian inference quantifies scientific evidence by means of\nprobabilities that are interpreted as a scientist’s subjective\ndegrees of belief. The Bayesian thus leaves behind Carnap’s\n(1950) idea that probability is determined by a logical relation\nbetween sentences. For example, the prior degree of belief in\nhypothesis \\(H\\), written \\(p(H)\\), can in principle take any value in\nthe interval \\([0,1]\\). Simultaneously held degrees of belief in\ndifferent hypotheses are, however, constrained by the laws of\nprobability. After learning evidence E, the degree of belief in \\(H\\)\nis changed from its prior probability \\(p(H)\\) to the conditional\ndegree of belief \\(p(H \\mid E)\\), commonly called the posterior\nprobability of \\(H\\). Both quantities can be related to each other by\nmeans of\n Bayes’ Theorem. \nThese days, the Bayesian approach is extremely influential in\nphilosophy and rapidly gaining ground across all scientific\ndisciplines. For quantifying evidence for a hypothesis, Bayesian\nstatisticians almost uniformly use the Bayes factor,\nthat is, the ratio of prior to posterior odds in favor of a\nhypothesis. The Bayes factor in favor of hypothesis \\(H\\) against its\nnegation \\(\\neg\\)\\(H\\) in the light of evidence \\(E\\) can be written\nas \nor in other words, as the likelihood ratio between \\(H\\) and\n\\(\\neg\\)\\(H\\). The Bayes factor reduces to the likelihoodist\nconception of evidence (Royall 1997) for the case of two competing\npoint hypotheses. For further discussion of Bayesian measures of\nevidence, see Good (1950), Sprenger and Hartmann (2019: ch. 1) and the\nentry on\n confirmation and evidential support. \nUnsurprisingly, the idea to measure scientific evidence in terms of\nsubjective probability has met resistance. For example, the\nstatistician Ronald A. Fisher (1935: 6–7) has argued that\nmeasuring psychological tendencies cannot be relevant for scientific\ninquiry and sustain claims to objectivity. Indeed, how should\nscientific objectivity square with subjective degree of belief?\nBayesians have responded to this challenge in various ways: \nHowson (2000) and Howson and Urbach (2006) consider the objection\nmisplaced. In the same way that deductive logic does not judge the\ncorrectness of the premises but just advises you what to infer from\nthem, Bayesian inductive logic provides rational\nrules for representing uncertainty and making inductive inferences.\nChoosing the premises (e.g., the prior distributions)\n“objectively” falls outside the scope of Bayesian\nanalysis. \nConvergence or merging-of-opinion theorems guarantee\nthat under certain circumstances, agents with very different initial\nattitudes who observe the same evidence will obtain similar posterior\ndegrees of belief in the long run. However, they are asymptotic\nresults without direct implications for inference with real-life\ndatasets (see also Earman 1992: ch. 6). In such cases, the choice of\nthe prior matters, and it may be beset with idiosyncratic bias and\nmanifest social values. \nAdopting a more modest stance, Sprenger (2018) accepts that Bayesian\ninference does not achieve the goal of objectivity in the sense of\nintersubjective agreement (concordant objectivity), or being free of\npersonal values, bias and subjective judgment. However, he argues that\ncompeting schools of inference such as frequentist inference face this\nproblem to the same degree, perhaps even worse. Moreover, some\nfeatures of Bayesian inference (e.g., the transparency about prior\nassumptions) fit recent, socially oriented conceptions of objectivity\nthat we discuss in\n section 5. \nA radical Bayesian solution to the problem of personal bias is to\nadopt a principle that radically constrains an agent’s rational\ndegrees of belief, such as the Principle of Maximum\nEntropy (MaxEnt—Jaynes 1968; Williamson 2010).\nAccording to MaxEnt, degrees of belief must be probabilistic and in\nsync with empirical constraints, but conditional on these constraints,\nthey must be equivocal, that is, as middling as possible. This latter\nconstraint amounts to maximizing the entropy of the probability\ndistribution in question. The MaxEnt approach eliminates various\nsources of subjective bias at the expense of narrowing down the range\nof rational degrees of belief. An alternative objective Bayesian\nsolution consists in so-called “objective\npriors”: prior probabilities that do not represent an\nagent’s factual attitudes, but are determined by principles of\nsymmetry, mathematical convenience or maximizing the influence of the\ndata on the posterior (e.g., Jeffreys 1939 [1980]; Bernardo 2012). \nThus, Bayesian inference, which analyzes statistical evidence from the\nvantage point of rational belief, provides only a partial answer to\nsecuring scientific objectivity from personal idiosyncrasy. \nThe frequentist conception of evidence is based on the idea of the\nstatistical test of a hypothesis. Under the influence\nof the statisticians Jerzy Neyman and Egon Pearson, tests were often\nregarded as rational decision procedures that minimize the relative\nfrequency of wrong decisions in a hypothetical series of repetitions\nof a test (hence the name “frequentism”). Rudner’s\nargument in\n section 3.2\n has pointed out the limits of this conception of hypothesis tests:\nthe choice of thresholds for acceptance and rejection (i.e., the\nacceptable type I and II error rates) may reflect contextual value\njudgments and personal bias. Moreover, the losses associated with\nerroneously accepting or rejecting that hypothesis depend on the\ncontext of application which may be unbeknownst to the\nexperimenter. \nAlternatively, scientists can restrict themselves to a purely\nevidential interpretation of hypothesis tests and leave decisions to\npolicy-makers and regulatory agencies. The statistician and biologist\nR.A. Fisher (1935, 1956) proposed what later became the orthodox\nquantification of evidence in frequentist statistics. Suppose a\n“null” or default hypothesis \\(H_0\\) denotes that an\nintervention has zero effect. If the observed data are\n“extreme” under \\(H_0\\)—i.e., if it was highly\nlikely to observe a result that agrees better with \\(H_0\\)—the\ndata provide evidence against the null hypothesis and for the efficacy\nof the intervention. The epistemological rationale is connected to the\nidea of severe testing (Mayo 1996): if the intervention were\nineffective, we would, in all likelihood, have found data that agree\nbetter with the null hypothesis. The strength of evidence against\n\\(H_0\\) is equal to the \\(p\\)-value: the lower it is,\nthe stronger evidence \\(E\\) speaks against the null hypothesis\n\\(H_0\\). \nUnlike Bayes factors, this concept of statistical evidence does not\ndepend on personal degrees of belief. However, this does not\nnecessarily mean that \\(p\\)-values are more objective. First,\n\\(p\\)-values are usually classified as “non-significant”\n(\\(p > .05\\)), “significant” (\\(p < .05\\)),\n“highly significant”, and so on. Not only that these\nthresholds and labels are largely arbitrary, they also promote\npublication bias: non-significant findings are often\nclassified as “failed studies” (i.e., the efficacy of the\nintervention could not be shown), rarely published and end up in the\nproverbial “file drawer”. Much valuable research is\nsuppressed. Conversely, significant findings may often occur when the\nnull hypothesis is actually true, especially when researchers have\nbeen “hunting for significance”. In fact, researchers have\nan incentive to keep their \\(p\\)-values low: the stronger the\nevidence, the more convincing the narrative, the greater the\nimpact—and the higher the chance for a good publication and\ncareer-relevant rewards. Moving the goalpost by\n“p-hacking” outcomes—for example by eliminating\noutliers, selective reporting or restricting the analysis to a\nsubgroup—evidently biases the research results and compromises\nthe objectivity of experimental research. \nIn particular, such questionable research practices\n(QRP) increase the type I error rate, which measures the rate\nat which false hypotheses are accepted, substantially over its nominal\n5% level and contribute to publication bias (Bakker et al. 2012).\nIoannidis (2005) concludes that “most published research\nfindings are false”—they are the combined result of a low\nbase rate of effective causal interventions, the file drawer effect\nand the widespread presence of questionable research practices. The\nfrequentist logic of hypothesis testing aggravates the problem because\nit provides a framework where all these biases can easily enter\n(Ziliak and McCloskey 2008; Sprenger 2016). These radical conclusions\nare also confirmed by empirical findings: in many disciplines\nresearchers fail to replicate findings by other scientific teams. See\n section 5.1\n for more detail. \nSumming up our findings, neither of the two major frameworks of\nstatistical inference manages to eliminate all sources of personal\nbias and idiosyncrasy. The Bayesian considers subjective assumptions\nto be an irreducible part of scientific reasoning and sees no harm in\nmaking them explicit. The frequentist conception of evidence based on\n\\(p\\)-values avoids these explicitly subjective elements, but at the\nprice of a misleading impression of objectivity and frequent abuse in\npractice. A defense of frequentist inference should, in our opinion,\nstress that the relatively rigid rules for interpreting statistical\nevidence facilitate communication and assessment of research results\nin the scientific community—something that is harder to achieve\nfor a Bayesian. We now turn from specific methods for stating and\ninterpreting evidence to a radical criticism of the idea that there is\na rational scientific method. \nIn his writings of the 1970s,\n Paul Feyerabend\n launched a profound attack on the rationality and objectivity of\nscientific method. His position is exceptional in the philosophical\nliterature since traditionally, the threat for objective and\nsuccessful science is located in contextual rather than epistemic\nvalues. Feyerabend turns this view upside down: it is the\n“tyranny” of rational method, and the emphasis on\nepistemic rather than contextual values that prevents us from having a\nscience in the service of society. Moreover, he welcomes a diversity\nof different personal, also idiosyncratic perspectives, thus denying\nthe idea that freedom from personal “bias” is\nepistemically and socially beneficial. \nThe starting point of Feyerabend’s criticism of rational method\nis the thesis that strict epistemic rules such as those expressed by\nthe VFI only suppress an open exchange of ideas, extinguish scientific\ncreativity and prevent a free and truly democratic science. In his\nclassic “Against Method” (1975: chs. 8–13),\nFeyerabend elaborates on this criticism by examining a famous episode\nin the history of science. When the Catholic Church objected to\nGalilean mechanics, it had the better arguments by the standards of\nseventeenth-century science. Their conservatism in their position was\nscientifically backed: Galilei’s telescopes were unreliable for\ncelestial observations, and many well-established phenomena (no fixed\nstar parallax, invariance of laws of motion) could not yet be\nexplained in the heliocentric system. With hindsight, Galilei managed\nto achieve groundbreaking scientific progress just because he\ndeliberately violated rules of scientific reasoning. Hence\nFeyerabend’s dictum “Anything goes”: no methodology\nwhatsoever is able to capture the creative and often irrational ways\nby which science deepens our understanding of the world. Good\nscientific reasoning cannot be captured by rational method, as Carnap,\nHempel and Popper postulated. \nThe drawbacks of an objective, value-free and method-bound view on\nscience and scientific method are not only epistemic. Such a view\nnarrows down our perspective and makes us less free, open-minded,\ncreative, and ultimately, less human in our thinking (Feyerabend 1975:\n154). It is therefore neither possible nor desirable to have an\nobjective, value-free science (cf. Feyerabend 1978: 78–79). As a\nconsequence, Feyerabend sees traditional forms of inquiry about our\nworld (e.g., Chinese medicine) on a par with their Western\ncompetitors. He denounces appeals to “objective” standards\nas rhetorical tools for bolstering the epistemic authority of a small\nintellectual elite (=Western scientists), and as barely disguised\nstatements of preference for one’s own worldview: \nthere is hardly any difference between the members of a\n“primitive” tribe who defend their laws because they are\nthe laws of the gods […] and a rationalist who appeals to\n“objective” standards, except that the former know what\nthey are doing while the latter does not. (1978: 82) \nIn particular, when discussing other traditions, we often project our\nown worldview and value judgments into them instead of making an\nimpartial comparison (1978: 80–83). There is no purely rational\njustification for dismissing other perspectives in favor of the\nWestern scientific worldview—the insistence on our Western\napproach may be as justified as insisting on absolute space and time\nafter the Theory of Relativity. \nThe Galilei example also illustrates that personal perspective and\nidiosyncratic “bias” need not be bad for science.\nFeyerabend argues further that scientific research is accountable to\nsociety and should be kept in check by democratic institutions, and\nlaymen in particular. Their particular perspectives can help to\ndetermine the funding agenda and to set ethical standards for\nscientific inquiry, but also be useful for traditionally value-free\ntasks such as choosing an appropriate research method and assessing\nscientific evidence. Feyerabend’s writings on this issue were\nmuch influenced by witnessing the Civil Rights Movement in the U.S.\nand the increasing emancipation of minorities, such as Blacks, Asians\nand Hispanics. \nAll this is not meant to say that truth loses its function as a\nnormative concept, nor that all scientific claims are equally\nacceptable. Rather, Feyerabend advocates an epistemic\npluralism that accepts diverse approaches to acquiring\nknowledge. Rather than defending a narrow and misleading ideal of\nobjectivity, science should respect the diversity of values and\ntraditions that drive our inquiries about the world (1978:\n106–107). This would put science back into the role it had\nduring the scientific revolution or the Enlightenment: as a liberating\nforce that fought intellectual and political oppression by the\nsovereign, the nobility or the clergy. Objections to this view are\ndiscussed at the end of\n section 5.2. \nThis section addresses various accounts that regard scientific\nobjectivity essentially as a function of social practices in science\nand the social organization of the scientific community. All these\naccounts reject the characterization of scientific objectivity as a\nfunction of correspondence between theories and the world, as a\nfeature of individual reasoning practices, or as pertaining to\nindividual studies and experiments (see also Douglas 2011). Instead,\nthey evaluate the objectivity of a collective of studies, as\nwell as the methods and community practices that structure and guide\nscientific research. More precisely, they adopt a meta-analytic\nperspective for assessing the reliability of scientific results\n(section 5.1), and they construct objectivity from a feminist\nperspective: as an open interchange of mutual criticism, or as being\nanchored in the “situatedness” of our scientific practices\nand the knowledge we gain\n (section 5.2). \nThe collectivist perspective is especially useful when an entire\ndiscipline enters a stage of crisis: its members become convinced that\na significant proportion of findings are not trustworthy. A\ncontemporary example of such a situation is the replication\ncrisis, which was briefly mentioned in the previous section\nand concerns the reproducibility of scientific knowledge\nclaims in a variety of different fields (most prominently: psychology,\nbiology, medicine). Large-scale replication projects have noticed that\nmany findings which we considered as an integral part of scientific\nknowledge failed to replicate in settings that were designed to mimic\nthe original experiment as closely as possible (e.g., Open Science\nCollaboration 2015). Successful attempts at replicating an\nexperimental result have long been argued to provide evidence of\nfreedom from particular kinds of artefacts and thus the\ntrustworthiness of the result. Compare the\n entry on experiment in physics.\n Likewise, failure to replicate indicates that either the original\nfinding, the result of the replication attempt, or both, are\nbiased—though see John Norton’s (ms., ch. 3—see\nOther Internet Resources) arguments that the evidential value of\n(failed) replications crucially depends on researchers’ material\nbackground assumptions. \nWhen replication failures in a discipline are particularly\nsignificant, one may conclude that the published literature lacks\nobjectivity—at a minimum the discipline fails to inspire trust\nthat its findings are more than artefacts of the researchers’\nefforts. Conversely, when observed effects can be replicated in\nfollow-up experiments, a kind of objectivity is reached that goes\nbeyond the ideas of freedom from personal bias, mechanical\nobjectivity, and subject-independent measurement, discussed in\n section 4.1. \nFreese and Peterson (2018) call this idea statistical\nobjectivity. It grounds in the view that even the most\nscrupulous and diligent researchers cannot achieve full objectivity\nall by themselves. The term “objectivity” instead applies\nto a collection or population of studies, with\nmeta-analysis (a formal method for aggregating the\nresults from ranges of studies) as the “apex of\nobjectivity” (Freese and Peterson 2018, 304; see also Stegenga\n2011, 2018). In particular, aggregating studies from different\nresearchers may provide evidence of systematic bias and questionable\nresearch practices (QRP) in the published literature. This diagnostic\nfunction of meta-analysis for detecting violations of objectivity is\nenhanced by statistical techniques such as the funnel plot and the\n\\(p\\)-curve (Simonsohn et al. 2014). \nApart from this epistemic dimension, research on statistical\nobjectivity also has an activist dimension: methodologists urge\nresearchers to make publicly available essential parts of their\nresearch before the data analysis starts, and to make their methods\nand data sources more transparent. For example, it is conjectured that\nthe replicability (and thus objectivity) of science will increase by\nmaking all data available online, by preregistering experiments, and\nby using the registered reports model for journal articles (i.e., the\njournal decides on publication before data collection on the basis of\nthe significance of the proposed research as well as the experimental\ndesign). The idea is that transparency about the data set and the\nexperimental design will make it easier to stage a replication of an\nexperiment and to assess its methodological quality. Moreover,\npublicly committing to a data analysis plan beforehand will lower the\nrate of QRPs and of attempts to accommodate data to\nhypotheses rather than making proper predictions. \nAll in all, statistical objectivity moves the discussion of\nobjectivity to the level of population of studies. There, it takes up\nand modifies several conceptions of objectivity that we have seen\nbefore: most prominently, freedom of subjective bias, which is\nreplaced with collective bias and pernicious conventions, and the\nsubject-independent measurement of a physical quantity, which is\nreplaced by reproducibility of effects. \nTraditional notions of objectivity as faithfulness to facts or freedom\nof contextual values have also been challenged from a feminist\nperspective. These critiques can be grouped in three major research\nprograms: feminist epistemology, feminist standpoint theory and\nfeminist postmodernism (Crasnow 2013). The program of feminist\nepistemology explores the impact of sex and gender on the\nproduction of scientific knowledge. More precisely, feminist\nepistemology highlights the epistemic risks resulting from the\nsystematic exclusion of women from the ranks of scientists, and the\nneglect of women as objects of study. Prominent case studies are the\nneglect of female orgasm in biology, testing medical drugs on male\nparticipants only, focusing on male specimen when studying the social\nbehavior of primates, and explaining human mating patterns by means of\nimaginary neolithic societies (e.g., Hrdy 1977; Lloyd 1993, 2005). See\nalso the\n entry on feminist philosophy of biology. \nOften but not always, feminist epistemologists go beyond pointing out\nwhat they regard as androcentric bias and reject the value-free ideal\naltogether—with an eye on the social and moral responsibility of\nscientific inquiry. They try to show that a value-laden science can\nalso meet important criteria for being epistemically reliable and\nobjective (e.g., Anderson 2004; Kourany 2010). A classical\nrepresentative of such efforts is Longino’s (1990)\ncontextual empiricism. She reinforces Popper’s\ninsistence that “the objectivity of scientific statements lies\nin the fact that they can be inter-subjectively tested” (1934\n[2002]: 22), but unlike Popper, she conceives scientific knowledge\nessentially as a social product. Thus, our conception of scientific\nobjectivity must directly engage with the social process that\ngenerates knowledge. Longino assigns a crucial function to social\nsystems of criticism in securing the epistemic success of science.\nSpecifically, she develops an epistemology which regards a method of\ninquiry as “objective to the degree that it permits\ntransformative criticism” (Longino 1990: 76).\nFor an epistemic community to achieve transformative criticism, there\nmust be: \navenues for criticism: criticism is an essential part\nof scientific institutions (e.g., peer review); \nshared standards: the community must share a set of\ncognitive values for assessing theories (more on this in\n section 3.1); \nuptake of criticism: criticism must be able to\ntransform scientific practice in the long run; \nequality of intellectual authority: intellectual\nauthority must be shared equally among qualified practitioners. \nLongino’s contextual empiricism can be understood as a\ndevelopment of John Stuart Mill’s view that beliefs should never\nbe suppressed, independently of whether they are true or false. Even\nthe most implausible beliefs might be true, and even if they are\nfalse, they might contain a grain of truth which is worth preserving\nor helps to better articulate true beliefs (Mill 1859 [2003: 72]). The\nunderlying intuition is supported by recent empirical research on the\nepistemic benefits of a diversity of opinions and perspectives (Page\n2007). By stressing the social nature of scientific knowledge, and the\nimportance of criticism (e.g., with respect to potential androcentric\nbias and inclusive practice), Longino’s account fits into the\nbroader project of feminist epistemology. \nStandpoint theory undertakes a more radical attack on\ntraditional scientific objectivity. This view develops Marxist ideas\nto the effect that epistemic position is related to, and a product of,\nsocial position. Feminist standpoint theory builds on these ideas but\nfocuses on gender, racial and other social relations. Feminist\nstandpoint theorists and proponents of “situated\nknowledge” such as Donna Haraway (1988), Sandra Harding\n(1991, 2015a, 2015b) and Alison Wylie (2003) deny the internal\ncoherence of a view from nowhere: all human knowledge is at base\nhuman knowledge and therefore necessarily perspectival. But\nthey argue more than that. Not only is perspectivality the human\ncondition, it is also a good thing to have. This is because\nperspectives, especially the perspectives of underprivileged classes\nand groups in society, come along with epistemic benefits. These ideas\nare controversial but they draw attention to the possibility that\nattempts to rid science of perspectives might not only be futile but\nalso costly: they prevent scientists from having the epistemic\nbenefits certain standpoints afford and from developing knowledge\nfor marginalized groups in society. The perspectival stance\ncan also explain why criteria for objectivity often vary with context:\nthe relative importance of epistemic virtues is a matter of goals and\ninterests—in other words, standpoint. \nBy endorsing a perspectival stance, feminist standpoint theory rejects\nclassical elements of scientific objectivity such as neutrality and\nimpartiality (see\n section 3.1\n above). This is a notable difference to feminist epistemology, which\nis in principle (though not always in practice) compatible with\ntraditional views of objectivity. Feminist standpoint theory is also a\npolitical project. For example, Harding (1991, 1993) demands that\nscientists, their communities and their practices—in other\nwords, the ways through which knowledge is gained—be\ninvestigated as rigorously as the object of knowledge itself. This\nidea she refers to as “strong\nobjectivity” replaces the “weak” conception\nof objectivity in the empiricist tradition: value-freedom,\nimpartiality, rigorous adherence to methods of testing and inference.\nLike Feyerabend, Harding integrates a transformation of epistemic\nstandards in science into a broader political project of rendering\nscience more democratic and inclusive. On the other hand, she is\nexposed to similar objections (see also Haack 2003). Isn’t it\ngrossly exaggerated to identify class, race and gender as important\nfactors in the construction of physical theories? Doesn’t the\nfeminist approach—like social constructivist\napproaches—lose sight of the particular epistemic qualities of\nscience? Should non-scientists really have as much authority as\ntrained scientists? To whom does the condition of equally shared\nintellectual authority apply? Nor is it clear—especially in\ntimes of fake news and filter bubbles—whether it is always a\ngood idea to subject scientific results to democratic approval. There\nis no guarantee (arguably there are few good reasons to believe) that\ndemocratized or standpoint-based science leads to more reliable\ntheories, or better decisions for society as a whole. \nSo far everything we discussed was meant to apply across all or at\nleast most of the sciences. In this section we will look at a number\nof specific issues that arise in the social sciences, in economics,\nand in evidence-based medicine. \nThere is a long tradition in the philosophy of social science\nmaintaining that there is a gulf in terms of both goals as well as\nmethods between the natural and the social sciences. This tradition,\nassociated with thinkers such as the neo-Kantians Heinrich Rickert and\nWilhelm Windelband, the hermeneuticist Wilhelm Dilthey, the\nsociologist-economist Max Weber, and the twentieth-century\nhermeneuticists Hans-Georg Gadamer and Michael Oakeshott, holds that\nunlike the natural sciences whose aim it is to establish natural laws\nand which proceed by experimentation and causal analysis, the social\nsciences seek understanding (“Verstehen”) of\nsocial phenomena, the interpretive examination of the meanings\nindividuals attribute to their actions (Weber 1904 [1949]; Weber 1917\n[1949]; Dilthey 1910 [1986]; Windelband 1915; Rickert 1929; Oakeshott\n1933; Gadamer 1960 [1989]). See also the entries on\n hermeneutics\n and\n Max Weber. \nUnderstood this way, social science lacks objectivity in more than one\nsense. One of the more important debates concerning objectivity in the\nsocial sciences concerns the role value judgments play and,\nimportantly, whether value-laden research entails claims about the\ndesirability of actions. Max Weber held that the social sciences are\nnecessarily value laden. However, they can achieve some degree of\nobjectivity by keeping out the social researcher’s views about\nwhether agents’ goals are commendable. In a similar vein,\ncontemporary economics can be said to be value laden because it\npredicts and explains social phenomena on the basis of agents’\npreferences. Nevertheless, economists are adamant that economists are\nnot in the business of telling people what they ought to value. Modern\neconomics is thus said to be objective in the Weberian sense of\n“absence of researchers’\nvalues”—a conception that we discussed in detail\nin\n section 3. \nIn his widely cited essay “‘Objectivity’ in Social\nScience and Social Policy” (Weber 1904 [1949]), Weber argued\nthat the idea of an aperspectival social science was meaningless: \nThere is no absolutely objective scientific analysis of […]\n“social phenomena” independent of special and\n“one-sided” viewpoints according to which expressly or\ntacitly, consciously or unconsciously they are selected, analyzed and\norganized for expository purposes. (1904 [1949: 72]) \nAll knowledge of cultural reality, as may be seen, is always knowledge\nfrom particular points of view. (1904 [1949:. 81]) \nThe reason for this is twofold. First, social reality is too complex\nto admit of full description and explanation. So we have to select.\nBut, perhaps in contraposition to the natural sciences, we cannot just\nselect those aspects of the phenomena that fall under universal\nnatural laws and treat everything else as “unintegrated\nresidues” (1904 [1949: 73]). This is because, second, in the\nsocial sciences we want to understand social phenomena in their\nindividuality, that is, in their unique configurations that have\nsignificance for us. \nValues solve a selection problem. They tell us what research questions\nwe ought to address because they inform us about the cultural\nimportance of social phenomena: \nOnly a small portion of existing concrete reality is colored by our\nvalue-conditioned interest and it alone is significant to us. It is\nsignificant because it reveals relationships which are important to\nuse due to their connection with our values. (1904 [1949: 76]) \nIt is important to note that Weber did not think that social and\nnatural science were different in kind, as Dilthey and others did.\nSocial science too examines the causes of phenomena of interest, and\nnatural science too often seeks to explain natural phenomena in their\nindividual constellations. The role of causal laws is different in the\ntwo fields, however. Whereas establishing a causal law is often an end\nin itself in the natural sciences, in the social sciences laws play an\nattenuated and accompanying role as mere means to explain cultural\nphenomena in their uniqueness. \nNevertheless, for Weber social science remains objective in at least\ntwo ways. First, once research questions of interest have been\nsettled, answers about the causes of culturally significant phenomena\ndo not depend on the idiosyncrasies of an individual researcher: \nBut it obviously does not follow from this that research in the\ncultural sciences can only have results which are\n“subjective” in the sense that they are valid for one\nperson and not for others. […] For scientific truth is\nprecisely what is valid for all who seek the truth. (Weber 1904 [1949:\n84], emphasis original) \nThe claims of social science can therefore be objective in our third\nsense\n (see section 4).\n Moreover, by determining that a given phenomenon is “culturally\nsignificant” a researcher reflects on whether or not a practice\nis “meaningful” or “important”, and not\nwhether or not it is commendable: “Prostitution is a cultural\nphenomenon just as much as religion or money” (1904 [1949: 81]).\nAn important implication of this view came to the fore in the\nso-called “Werturteilsstreit” (quarrel concerning\nvalue judgments) of the early 1900s. In this debate, Weber maintained\nagainst the “socialists of the lectern” around Gustav\nSchmoller the position that social scientists qua scientists should\nnot be directly involved in policy debates because it was not the aim\nof science to examine the appropriateness of ends. Given a policy\ngoal, a social scientist could make recommendations about effective\nstrategies to reach the goal; but social science was to be value-free\nin the sense of not taking a stance on the desirability of the goals\nthemselves. This leads us to our conception of objectivity as freedom\nfrom value judgments. \nContemporary mainstream economists hold a view concerning objectivity\nthat mirrors Max Weber’s (see above). On the one hand, it is\nclear that value judgments are at the heart of economic theorizing.\n“Preferences” are a key concept of rational choice theory,\nthe main theory in contemporary mainstream economics. Preferences are\nevaluations. If an individual prefers \\(A\\) to \\(B\\), she\nvalues \\(A\\) higher than \\(B\\) (Hausman 2012). Thus, to the\nextent that economists predict and explain market behavior in terms of\nrational choice theory, they predict and explain market behavior in a\nway laden with value judgments. \nHowever, economists are not themselves supposed to take a stance about\nwhether or not whatever individuals value is also\n“objectively” good in a stronger sense: \n[…] that an agent is rational from [rational choice\ntheory]’s point of view does not mean that the course of action\nshe will choose is objectively optimal. Desires do not have to align\nwith any objective measure of “goodness”: I may want to\nrisk swimming in a crocodile-infested lake; I may desire to smoke or\ndrink even though I know it harms me. Optimality is determined by the\nagent’s desires, not the converse. (Paternotte 2011:\n307–8) \nIn a similar vein, Gul and Pesendorfer write: \nHowever, standard economics has no therapeutic ambition, i.e., it does\nnot try to evaluate or improve the individual’s objectives.\nEconomics cannot distinguish between choices that maximize happiness,\nchoices that reflect a sense of duty, or choices that are the response\nto some impulse. Moreover, standard economics takes no position on the\nquestion of which of those objectives the agent should pursue. (Gul\nand Pesendorfer 2008: 8) \nAccording to the standard view, all that rational choice theory\ndemands is that people’s preferences are (internally)\nconsistent; it has no business in telling people what they ought to\nprefer, whether their preferences are consistent with external norms\nor values. Economics is thus value-laden, but laden with the values of\nthe agents whose behavior it seeks to predict and explain and not with\nthe values of those who seek to predict and explain this behavior. \nWhether or not social science, and economics in particular, can be\nobjective in this—Weber’s and the contemporary\neconomists’—sense is controversial. On the one hand, there\nare some reasons to believe that rational choice theory (which is at\nwork not only in economics but also in political science and other\nsocial sciences) cannot be applied to empirical phenomena without\nreferring to external norms or values (Sen 1993; Reiss 2013). \nOn the other hand, it is not clear that economists and other social\nscientists qua social scientists shouldn’t participate in a\ndebate about social goals. For one thing, trying to do welfare\nanalysis in the standard Weberian way tends to obscure rather than to\neliminate normative commitments (Putnam and Walsh 2007). Obscuring\nvalue judgments can be detrimental to the social scientist as policy\nadviser because it will hamper rather than promote trust in social\nscience. For another, economists are in a prime position to contribute\nto ethical debates, for a variety of reasons, and should therefore\ntake this responsibility seriously (Atkinson 2001). \nThe same demands calling for “mechanical objectivity” in\nthe natural sciences and quantification in the social and policy\nsciences in the nineteenth century and mid-twentieth century are\nresponsible for a recent movement in biomedical research, which, even\nmore recently, have swept to contemporary social science and policy.\nEarly proponents of so-called “evidence-based medicine”\nmade their pursuit of a downplay of the “human element” in\nmedicine plain: \nEvidence-based medicine de-emphasizes intuition, unsystematic clinical\nexperience, and pathophysiological rationale as sufficient grounds for\nclinical decision making and stresses the examination of evidence from\nclinical research. (Guyatt et al. 1992: 2420) \nTo call the new movement “evidence-based” is a misnomer\nstrictly speaking, as intuition, clinical experience and\npathophysiological rationale can certainly constitute evidence. But\nproponents of evidence-based practices have a much narrower concept of\nevidence in mind: analyses of the results of randomized controlled\ntrials (RCTs). This movement is now very strong in biomedical\nresearch, development economics and a number of areas of social\nscience, especially psychology, education and social policy, and\nespecially in the English speaking world. \nThe goal is to replace subjective (biased, error-prone, idiosyncratic)\njudgments by mechanically objective methods. But, as in other areas,\nattempting to mechanize inquiry can lead to reduced accuracy and\nutility of the results. \nCausal relations in the social and biomedical sciences hold on account\nof highly complex arrangements of factors and conditions. Whether for\ninstance a substance is toxic depends on details of the metabolic\nsystem of the population ingesting it, and whether an educational\npolicy is effective on the constellation of factors that affect the\nstudents’ learning progress. If an RCT was conducted\nsuccessfully, the conclusion about the effectiveness of the treatment\n(or toxicity of a substance) under test is certain for the particular\narrangement of factors and conditions of the trial (Cartwright 2007).\nBut unlike the RCT itself, many of whose aspects can be (relatively)\nmechanically implemented, applying the result to a new setting\n(recommending a treatment to a patient, for instance) always involves\nsubjective judgments of the kind proponents of evidence-based\npractices seek to avoid—such as judgments about the similarity\nof the test to the target or policy population. \nOn the other hand, RCTs can be regarded as “debiasing\nprocedure” because they prevent researchers from allocating\ntreatments to patients according to their personal interests, so that\nthe healthiest (or smartest or…) subjects get the\nresearcher’s favorite therapy. While unbalanced allocations can\ncertainly happen by chance, randomization still provides some warrant\nthat the allocation was not done on purpose with a view to\npromoting somebody’s interests. A priori, the\nexperimental procedure is thus more impartial with respect to the\ninterests at stake. It has thus been argued that RCTs in medicine,\nwhile no guarantor of the best outcomes, were adopted by the U.S. Food\nand Drugs Administration (FDA) to different degrees during the 1960s\nand 1970s in order to regain public trust in its decisions about\ntreatments, which it had lost due to the thalidomide and other\nscandals (Teira and Reiss 2013; Teira 2010). It is important to\nnotice, however, that randomization is at best effective with respect\nto one kind of bias, viz. selection bias. Important other epistemic\nconcerns are not addressed by the procedure but should not be ignored\n(Worrall 2002). \nIn sections 2–5, we have encountered various concepts of\nscientific objectivity and their limitations. This prompts the\nquestion of how unified (or disunified) scientific objectivity is as a\nconcept: Is there something substantive shared by all of these\nanalyses? Or is objectivity, as Heather Douglas (2004) puts it, an\n“irreducibly complex” concept? \nDouglas defends pluralism about scientific\nobjectivity and distinguishes three areas of application of\nthe concept: (1) interaction of humans with the world, (2) individual\nreasoning processes, (3) social processes in science. Within each\narea, there are various distinct senses which are again irreducible to\neach other and do not have a common core meaning. This does not mean\nthat the senses are unrelated; they share a complex web of\nrelationships and can also support each other—for example,\neliminating values from reasoning may help to achieve procedural\nobjectivity. For Douglas, reducing objectivity to a single core\nmeaning would be a simplification without benefits; instead of a\ncomplex web of relations between different senses of objectivity we\nwould obtain an impoverished concept out of touch with scientific\npractice. Similar arguments and pluralist accounts can be found in\nMegill (1994), Janack (2002) and Padovani et al. (2015)—see also\nAxtell (2016). \nIt has been argued, however, that pluralist approaches give up too\nquickly on the idea that the different senses of objectivity share one\nor several important common elements. As we have seen in section\n 4.1\n and\n 5.1,\n scientific objectivity and trust in science are\nclosely connected. Scientific objectivity is desirable because to the\nextent that science is objective we have reasons trust scientists,\ntheir results and recommendations (cf. Fine 1998: 18). Thus, perhaps\nwhat is unifying among the difference senses of objectivity is that\neach sense describes a feature of scientific practice that is able to\ninspire trust in science. \nBuilding on this idea, Inkeri Koskinen has recently argued that it is\nin fact not trust but reliance that we are after (Koskinen\nforthcoming). Trust is something that can be betrayed, but only\nindividuals can betray whereas objectivity pertains to institutions,\npractices, results, etc. We call scientific institutions, practices,\nresults, etc. objective to the extent that we have reasons to rely on\nthem. The analysis does not stop here, however. There is a distinct\nview about objectivity that is behind Daston and Galison’s\nhistorical epistemology of the concept and has been defended by Ian\nHacking: that objectivity is not a—positive—virtue but\nrather the absence of this or that vice (Hacking 2015: 26). Speaking\nof objectivity in imaging, for instance, Daston and Galison write that\nthe goal is to \nlet the specimen appear without that distortion characteristic of the\nobserver’s personal tastes, commitments, or ambitions. (Daston\nand Galison 2007: 121) \nKoskinen picks up this idea of objectivity as absence of\nvice and argues that it is specifically the aversion of\nepistemic risks for which the term is reserved. Epistemic\nrisks comprise “any risk of epistemic error that arises anywhere\nduring knowledge practices’ (Biddle and Kukla 2017: 218) such as\nthe risk of having mistaken beliefs, the risk of errors in reasoning\nand risks related to operationalization, concept formation, and model\nchoice. Koskinen argues that only those epistemic risks that relate to\nfailings of scientists as human beings are relevant to objectivity\n(Koskinen forthcoming: 13): \nFor instance, when the results of an experiment are incorrect because\nof malfunctioning equipment, we do not worry about\nobjectivity—we just say that the results should not be taken\ninto account. [...] So it is only when the epistemic risk is related\nto our own failings, and is hard to avert, that we start talking about\nobjectivity. Illusions, subjectivity, idiosyncrasies, and collective\nbiases are important epistemic risks arising from our imperfections as\nepistemic agents. \nKoskinen understands her account as a response to Hacking’s\n(2015) criticism that we should stop talking about objectivity\naltogether. According to Hacking, “objectivity” is an\n“elevator” or second-level word, similar to\n“true” or “real”—“Instead of\nsaying that the cat is on the mat, we move up one story and and say\nthat it is true that the cat is on the mat” (2015: 20). He\nrecommends to stick to ground-level questions and worry about whether\nspecific sources of error have been controlled. (A similar elimination\nrequest with respect to the labels “objective” and\n“subjective” in statistical inference has been advanced by\nGelman and Hennig (2017).) In focussing on averting specific epistemic\nrisks, Koskinen’s account does precisely that. Koskinen argues\nthat a unified account of objectivity as averting epistemic risks\ntakes into account Hacking’s negative stance and explains at the\nsame time important features of the concept—for example, why\nobjectivity does not imply certainty and why it varies with\ncontext. \nThe strong point of this account is that none of the threats to a\npeculiar analysis puts scientific objectivity at risk. We can (and in\nfact, we do) rely on scientific practices that represent the world\nfrom a perspective and where non-epistemic values affect outcomes and\ndecisions. What is left open by Koskinen’s account is the\nnormative question of what a scientist who cares about her experiments\nand inferences being objective should actually do. That is, the\nphilosophical ideas we have reviewed in this section stay mainly on\nthe descriptive level and do not give an actual guideline for working\nscientists. Connecting the abstract philosophical analysis to\nday-to-day work in science remains an open problem. \nSo is scientific objectivity desirable? Is it attainable? That, as we\nhave seen, depends crucially on how the term is understood. We have\nlooked in detail at four different conceptions of scientific\nobjectivity: faithfulness to facts, value-freedom, freedom from\npersonal biases, and features of community practices. In each case,\nthere are at least some reasons to believe that either science cannot\ndeliver full objectivity in this sense, or that it would not be a good\nthing to try to do so, or both. Does this mean we should give up the\nidea of objectivity in science? \nWe have shown that it is hard to define scientific objectivity in\nterms of a view from nowhere, value freedom, or freedom from personal\nbias. It is a lot harder to say anything positive about the matter.\nPerhaps it is related to a thorough critical attitude concerning\nclaims and findings, as Popper thought. Perhaps it is the fact that\nmany voices are heard, equally respected and subjected to accepted\nstandards, as Longino defends. Perhaps it is something else\naltogether, or a combination of several factors discussed in this\narticle. \nHowever, one should not (as yet) throw out the baby with the\nbathwater. Like those who defend a particular explication of\nscientific objectivity, the critics struggle to explain what makes\nscience objective, trustworthy and special. For instance, our\ndiscussion of the value-free ideal (VFI) revealed that alternatives to\nthe VFI are as least as problematic as the VFI itself, and that the\nVFI may, with all its inadequacies, still be a useful heuristic for\nfostering scientific integrity and objectivity. Similarly, although\nentirely “unbiased” scientific procedures may be\nimpossible, there are many mechanisms scientists can adopt for\nprotecting their reasoning against undesirable forms of bias, e.g.,\nchoosing an appropriate method of statistical inference, being\ntransparent about different stages of the research process and\navoiding certain questionable research practices. \nWhatever it is, it should come as no surprise that finding a positive\ncharacterization of what makes science objective is hard. If we knew\nan answer, we would have done no less than solve the problem of\ninduction (because we would know what procedures or forms of\norganization are responsible for the success of science). Work on this\nproblem is an ongoing project, and so is the quest for understanding\nscientific objectivity.","contact.mail":"julian.reiss@jku.at","contact.domain":"jku.at"},{"date.published":"2014-08-25","date.changed":"2020-10-30","url":"https://plato.stanford.edu/entries/scientific-objectivity/","author1":"Julian Reiss","author1.info":"http://jreiss.org/","author2.info":"http://www.laeuferpaar.de","entry":"scientific-objectivity","body.text":"\n\n\nScientific objectivity is a property of various aspects of science. It\nexpresses the idea that scientific claims, methods, results—and\nscientists themselves—are not, or should not be, influenced by\nparticular perspectives, value judgments, community bias or personal\ninterests, to name a few relevant factors. Objectivity is often\nconsidered to be an ideal for scientific inquiry, a good reason for\nvaluing scientific knowledge, and the basis of the authority of\nscience in society.\n\n\nMany central debates in the philosophy of science have, in one way or\nanother, to do with objectivity: confirmation and the problem of\ninduction; theory choice and scientific change; realism; scientific\nexplanation; experimentation; measurement and quantification;\nstatistical evidence; reproducibility; evidence-based science;\nfeminism and values in science. Understanding the role of objectivity\nin science is therefore integral to a full appreciation of these\ndebates. As this article testifies, the reverse is true too: it is\nimpossible to fully appreciate the notion of scientific objectivity\nwithout touching upon many of these debates.\n\n\nThe ideal of objectivity has been criticized repeatedly in philosophy\nof science, questioning both its desirability and its attainability.\nThis article focuses on the question of how scientific objectivity\nshould be defined, whether the ideal of objectivity is\ndesirable, and to what extent scientists can achieve\nit.\n\nObjectivity is a value. To call a thing objective implies that it has\na certain importance to us and that we approve of it. Objectivity\ncomes in degrees. Claims, methods, results, and scientists can be more\nor less objective, and, other things being equal, the more objective,\nthe better. Using the term “objective” to describe\nsomething often carries a special rhetorical force with it. The\nadmiration of science among the general public and the authority\nscience enjoys in public life stems to a large extent from the view\nthat science is objective or at least more objective than other modes\nof inquiry. Understanding scientific objectivity is therefore central\nto understanding the nature of science and the role it plays in\nsociety. \nIf what is so great about science is its objectivity, then objectivity\nshould be worth defending. The close examinations of scientific\npractice that philosophers of science have undertaken in the past\nfifty years have shown, however, that several conceptions of the ideal\nof objectivity are either questionable or unattainable. The prospects\nfor a science providing a non-perspectival “view from\nnowhere” or for proceeding in a way uninformed by human goals\nand values are fairly slim, for example. \nThis article discusses several proposals to characterize the idea and\nideal of objectivity in such a way that it is both strong enough to be\nvaluable, and weak enough to be attainable and workable in practice.\nWe begin with a natural conception of objectivity:\nfaithfulness to facts. We motivate the intuitive\nappeal of this conception, discuss its relation to scientific method\nand discuss arguments challenging both its attainability as well as\nits desirability. We then move on to a second conception of\nobjectivity as absence of normative commitments and\nvalue-freedom, and once more we contrast arguments in favor\nof such a conception with the challenges it faces. A third conception\nof objectivity which we discuss at length is the idea of\nabsence of personal bias. \nFinally there is the idea that objectivity is anchored in\nscientific communities and their practices. After\ndiscussing three case studies from economics, social\nscience and medicine, we address the conceptual unity of\nscientific objectivity: Do the various conceptions have a\ncommon valid core, such as promoting trust in science or minimizing\nrelevant epistemic risks? Or are they rivaling and only loosely\nrelated accounts? Finally we present some conjectures about what\naspects of objectivity remain defensible and desirable in the light of\nthe difficulties we have encountered. \nThe basic idea of this first conception of objectivity is that\nscientific claims are objective in so far as they faithfully describe\nfacts about the world. The philosophical rationale underlying this\nconception of objectivity is the view that there are facts “out\nthere” in the world and that it is the task of scientists to\ndiscover, analyze, and systematize these facts.\n“Objective” then becomes a success word: if a claim is\nobjective, it correctly describes some aspect of the world. \nIn this view, science is objective to the degree that it succeeds at\ndiscovering and generalizing facts, abstracting from the perspective\nof the individual scientist. Although few philosophers have fully\nendorsed such a conception of scientific objectivity, the idea figures\nrecurrently in the work of prominent twentieth-century philosophers of\nscience such as Carnap, Hempel, Popper, and Reichenbach. \nHumans experience the world from a perspective. The contents of an\nindividual’s experiences vary greatly with his perspective,\nwhich is affected by his personal situation, and the details of his\nperceptual apparatus, language and culture. While the experiences\nvary, there seems to be something that remains constant. The\nappearance of a tree will change as one approaches it\nbut—according to common sense and most philosophers—the\ntree itself doesn’t. A room may feel hot or cold for different\npersons, but its temperature is independent of their experiences. The\nobject in front of me does not disappear just because the lights are\nturned off. \nThese examples motivate a distinction between qualities that vary with\none’s perspective, and qualities that remain constant through\nchanges of perspective. The latter are the objective qualities. Thomas\nNagel explains that we arrive at the idea of objective qualities in\nthree steps (Nagel 1986: 14). The first step is to realize (or\npostulate) that our perceptions are caused by the actions of things\naround us, through their effects on our bodies. The second step is to\nrealize (or postulate) that since the same qualities that cause\nperceptions in us also have effects on other things and can exist\nwithout causing any perceptions at all, their true nature must be\ndetachable from their perspectival appearance and need not resemble\nit. The final step is to form a conception of that “true\nnature” independently of any perspective. Nagel calls that\nconception the “view from nowhere”, Bernard Williams the\n“absolute conception” (Williams 1985 [2011]). It\nrepresents the world as it is, unmediated by human minds and other\n“distortions”. \nThis absolute conception lies at the basis of scientific realism (for\na detailed discussion, see the entry on\n scientific realism)\n and it is attractive in so far as it provides a basis for arbitrating\nbetween conflicting viewpoints (e.g., two different observations).\nMoreover, the absolute conception provides a simple and unified\naccount of the world. Theories of trees will be very hard to come by\nif they use predicates such as “height as seen by an\nobserver” and a hodgepodge if their predicates track the habits\nof ordinary language users rather than the properties of the world. To\nthe extent, then, that science aims to provide explanations for\nnatural phenomena, casting them in terms of the absolute conception\nwould help to realize this aim. A scientific account cast in the\nlanguage of the absolute conception may not only be able to explain\nwhy a tree is as tall as it is but also why we see it in one way when\nviewed from one standpoint and in a different way when viewed from\nanother. As Williams (1985 [2011: 139]) puts it, \n[the absolute conception] nonvacuously explain[s] how it itself, and\nthe various perspectival views of the world, are possible. \nA third reason to find the view from nowhere attractive is that if the\nworld came in structures as characterized by it and we did have access\nto it, we could use our knowledge of it to ground predictions (which,\nto the extent that our theories do track the absolute structures, will\nbe borne out). A fourth and related reason is that attempts to\nmanipulate and control phenomena can similarly be grounded in our\nknowledge of these structures. To attain any of the four\npurposes—settling disagreements, explaining the world,\npredicting phenomena, and manipulation and control—the absolute\nconception is at best sufficient but not necessary. We can, for\ninstance, settle disagreements by imposing the rule that the person\nwith higher social rank or greater experience is always right. We can\nexplain the world and our image of it by means of theories that do not\nrepresent absolute structures and properties, and there is no need to\nget things (absolutely) right in order to predict successfully.\nNevertheless, there is something appealing in the idea that factual\ndisagreements can be settled by the very facts themselves, that\nexplanations and predictions grounded in what’s really there\nrather than in a distorted image of it. \nNo matter how desirable, our ability to use scientific claims to\nrepresent facts about the world depends on whether these claims can\nunambiguously be established on the basis of evidence, and of evidence\nalone. Alas, the relation between evidence and scientific hypothesis\nis not straightforward.\n Subsection 2.2\n and\n subsection 2.3\n will look at two challenges of the idea that even the best scientific\nmethod will yield claims that describe an aperspectival view from\nnowhere.\n Section 5.2\n will deal with socially motivated criticisms of the view from\nnowhere. \nAccording to a popular picture, all scientific theories are false and\nimperfect. Yet, as we add true and eliminate false beliefs, our best\nscientific theories become more truthlike (e.g., Popper 1963,\n1972). If this picture is correct, then scientific knowledge grows by\ngradually approaching the truth and it will become more objective over\ntime, that is, more faithful to facts. However, scientific theories\noften change, and sometimes several theories compete for the place of\nthe best scientific account of the world. \nIt is inherent in the above picture of scientific objectivity that\nobservations can, at least in principle, decide between competing\ntheories. If they did not, the conception of objectivity as\nfaithfulness would be pointless to have as we would not be in a\nposition to verify it. This position has been adopted by Karl R.\nPopper, Rudolf Carnap and other leading figures in (broadly)\nempiricist philosophy of science. Many philosophers have argued that\nthe relation between observation and theory is way more complex and\nthat influences can actually run both ways (e.g., Duhem 1906 [1954];\nWittgenstein 1953 [2001]). The most lasting criticism, however, was\ndelivered by Thomas S. Kuhn (1962 [1970]) in his book “The\nStructure of Scientific Revolutions”. \nKuhn’s analysis is built on the assumption that scientists\nalways view research problems through the lens of a paradigm, defined\nby set of relevant problems, axioms, methodological presuppositions,\ntechniques, and so forth. Kuhn provided several historical examples in\nfavor of this claim. Scientific progress—and the practice of\nnormal, everyday science—happens within a paradigm that guides\nthe individual scientists’ puzzle-solving work and that sets the\ncommunity standards. \nCan observations undermine such a paradigm, and speak for a different\none? Here, Kuhn famously stresses that observations are\n“theory-laden” (cf. also Hanson 1958): they\ndepend on a body of theoretical assumptions through which they are\nperceived and conceptualized. This hypothesis has two important\naspects. \nFirst, the meaning of observational concepts is influenced by\ntheoretical assumptions and presuppositions. For example, the concepts\n“mass” and “length” have different meanings in\nNewtonian and relativistic mechanics; so does the concept\n“temperature” in thermodynamics and statistical mechanics\n(cf. Feyerabend 1962). In other words, Kuhn denies that there is a\ntheory-independent observation language. The “faithfulness to\nreality” of an observation report is always mediated by a\ntheoretical überbau, disabling the role of observation\nreports as an impartial, merely fact-dependent arbiter between\ndifferent theories. \nSecond, not only the observational concepts, but also the\nperception of a scientist depends on the paradigm she is\nworking in. \nPracticing in different worlds, the two groups of scientists [who work\nin different paradigms, J.R./J.S.] see different things when they look\nfrom the same point in the same direction. (Kuhn 1962 [1970: 150]) \nThat is, our own sense data are shaped and structured by a theoretical\nframework, and may be fundamentally distinct from the sense data of\nscientists working in another one. Where a Ptolemaic astronomer like\nTycho Brahe sees a sun setting behind the horizon, a Copernican\nastronomer like Johannes Kepler sees the horizon moving up to a\nstationary sun. If this picture is correct, then it is hard to assess\nwhich theory or paradigm is more faithful to the facts, that is, more\nobjective. \nThe thesis of the theory-ladenness of observation has also been\nextended to the incommensurability of different paradigms or\nscientific theories, problematized independently by Thomas S.\nKuhn (1962 [1970]) and Paul Feyerabend (1962). Literally, this concept\nmeans “having no measure in common”, and it figures\nprominently in arguments against a linear and standpoint-independent\npicture of scientific progress. For instance, the Special Theory of\nRelativity appears to be more faithful to the facts and therefore more\nobjective than Newtonian mechanics because it reduces, for low speeds,\nto the latter, and it accounts for some additional facts that are not\npredicted correctly by Newtonian mechanics. This picture is\nundermined, however, by two central aspects of incommensurability.\nFirst, not only do the observational concepts in both theories differ,\nbut the principles for specifying their meaning may be inconsistent\nwith each other (Feyerabend 1975: 269–270). Second, scientific\nresearch methods and standards of evaluation change with the theories\nor paradigms. Not all puzzles that could be tackled in the old\nparadigm will be solved by the new one—this is the phenomenon of\n“Kuhn loss”. \nA meaningful use of objectivity presupposes, according to Feyerabend,\nto perceive and to describe the world from a specific perspective,\ne.g., when we try to verify the referential claims of a scientific\ntheory. Only within a peculiar scientific worldview, the\nconcept of objectivity may be applied meaningfully. That is,\nscientific method cannot free itself from the particular scientific\ntheory to which it is applied; the door to standpoint-independence is\nlocked. As Feyerabend puts it: \nour epistemic activities may have a decisive influence even upon the\nmost solid piece of cosmological furniture—they make gods\ndisappear and replace them by heaps of atoms in empty space. (1978:\n70) \nKuhn and Feyerabend’s theses about theory-ladenness of\nobservation, and their implications for the objectivity of scientific\ninquiry have been much debated afterwards, and have often been\nmisunderstood in a social constructivist sense. Therefore Kuhn later\nreturned to the topic of scientific objectivity, of which he gives his\nown characterization in terms of the shared cognitive values of a\nscientific community. We discuss Kuhn’s later view in\n section 3.1.\n For a more thorough coverage, see the entries on\n theory and observation in science,\n the incommensurability of scientific theories and\n Thomas S. Kuhn. \nScientific theories are tested by comparing their implications with\nthe results of observations and experiments. Unfortunately, neither\npositive results (when the theory’s predictions are borne out in\nthe data) nor negative results (when they are not) allow unambiguous\ninferences about the theory. A positive result can obtain even though\nthe theory is false, due to some alternative that makes the same\npredictions. Finding suspect Jones’ fingerprints on the murder\nweapon is consistent with his innocence because he might have used it\nas a kitchen knife. A negative result might be due not to the\nfalsehood of the theory under test but due to the failing of one or\nmore auxiliary assumptions needed to derive a prediction from the\ntheory. Testing, let us say, the implications of Newton’s laws\nfor movements in our planetary system against observations requires\nassumptions about the number of planets, the sun’s and the\nplanets’ masses, the extent to which the earth’s\natmosphere refracts light beams, how telescopes affect the results and\nso on. Any of these may be false, explaining an inconsistency. The\nlocus classicus for these observations is Pierre\nDuhem’s The Aim and Structure of Physical Theory (Duhem\n1906 [1954]). Duhem concluded that there was no “crucial\nexperiment”, an experiment that conclusively decides between two\nalternative theories, in physics (1906 [1954: 188ff.]), and that\nphysicists had to employ their expert judgment or what Duhem called\n“good sense” to determine what an experimental result\nmeans for the truth or falsehood of a theory (1906 [1954:\n216ff.]). \nIn other words, there is a gap between the evidence and the theory\nsupported by it. It is important to note that the alleged gap is more\nprofound than the gap between the premisses of any inductive\nargument and its conclusion, say, the gap between “All hitherto\nobserved ravens have been black” and “All ravens are\nblack”. The latter gap could be bridged by an agreed upon rule\nof inductive reasoning. Alas, all attempts to find an analogous rule\nfor theory choice have failed (e.g., Norton 2003). Various\nphilosophers, historians, and sociologists of science have responded\nthat theory appraisal is “a complex form of value\njudgment” (McMullin 1982: 701; see also Kuhn 1977; Hesse 1980;\nBloor 1982). \nIn\n section 3.1\n below we will discuss the nature of the value judgments in more\ndetail. For now the important lesson is that if these philosophers,\nhistorians, and sociologists are correct, the “faithfulness to\nfacts” ideal is untenable. As the scientific image of the world\nis a joint product of the facts and scientists’ value judgments,\nthat image cannot be said to be aperspectival. Science does not eschew\nthe human perspective. There are of course ways to escape this\nconclusion. If, as John Norton (2003; ms.—see Other Internet\nResources) has argued, it is material facts that power and justify\ninductive inferences, and not value judgments, we can avoid the\nnegative conclusion regarding the view from nowhere. Unsurprisingly,\nNorton is also critical of the idea that evidence generally\nunderdetermines theory (Norton 2008). However, there are good reasons\nto mistrust Norton’s optimism regarding the ineliminability of\nvalues and other non-factual elements in inductive inferences (Reiss\n2020). \nThere is another, closely related concern. Most of the earlier critics\nof “objective” verification or falsification focused on\nthe relation between evidence and scientific theories. There is a\nsense in which the claim that this relation is problematic is not so\nsurprising. Scientific theories contain highly abstract claims that\ndescribe states of affairs far removed from the immediacy of sense\nexperience. This is for a good reason: sense experience is necessarily\nperspectival, so to the extent to which scientific theories are to\ntrack the absolute conception, they must describe a world different\nfrom that of sense experience. But surely, one might think, the\nevidence itself is objective. So even if we do have reasons to doubt\nthat abstract theories faithfully represent the world, we should stand\non firmer grounds when it comes to the evidence against which we test\nabstract theories. \nTheories are seldom tested against brute observations, however. Simple\ngeneralizations such as “all swans are white” are directly\nlearned from observations (say, of the color of swans) but they do not\nrepresent the view from nowhere (for one thing, the view from nowhere\ndoesn’t have colors). Genuine scientific theories are tested\nagainst experimental facts or phenomena, which are themselves\nunobservable to the unaided senses. Experimental facts or phenomena\nare instead established using intricate procedures of measurement and\nexperimentation. \nWe therefore need to ask whether the results of scientific\nmeasurements and experiments can be aperspectival. In an important\ndebate in the 1980s and 1990s some commentators answered that question\nwith a resounding “no”, which was then rebutted by others.\nThe debate concerns the so-called “experimenter’s\nregress” (Collins 1985). Collins, a prominent sociologist of\nscience, claims that in order to know whether an experimental result\nis correct, one first needs to know whether the apparatus producing\nthe result is reliable. But one doesn’t know whether the\napparatus is reliable unless one knows that it produces correct\nresults in the first place and so on and so on ad infinitum.\nCollins’ main case concerns attempts to detect gravitational\nwaves, which were very controversially discussed among physicists in\nthe 1970s. \nCollins argues that the circle is eventually broken not by the\n“facts” themselves but rather by factors having to do with\nthe scientist’s career, the social and cognitive interests of\nhis community, and the expected fruitfulness for future work. It is\nimportant to note that in Collins’s view these factors do not\nnecessarily make scientific results arbitrary. But what he does argue\nis that the experimental results do not represent the world according\nto the absolute conception. Rather, they are produced jointly by the\nworld, scientific apparatuses, and the psychological and sociological\nfactors mentioned above. The facts and phenomena of science are\ntherefore necessarily perspectival. \nIn a series of contributions, Allan Franklin, a\nphysicist-turned-philosopher of science, has tried to show that while\nthere are indeed no algorithmic procedures for establishing\nexperimental facts, disagreements can nevertheless be settled by\nreasoned judgment on the basis of bona fide\nepistemological criteria such as experimental checks and calibration,\nelimination of possible sources of error, using apparatuses based on\nwell-corroborated theory and so on (Franklin 1994, 1997). Collins\nresponds that “reasonableness” is a social category that\nis not drawn from physics (Collins 1994). \nThe main issue for us in this debate is whether there are any reasons\nto believe that experimental results provide an aperspectival view on\nthe world. According to Collins, experimental results are\nco-determined by the facts as well as social and psychological\nfactors. According to Franklin, whatever else influences experimental\nresults other than facts is not arbitrary but instead based on\nreasoned judgment. What he has not shown is that reasoned judgment\nguarantees that experimental results reflect the facts alone and are\ntherefore aperspectival in any interesting sense. Another important\nchallenge for the aperspectival account comes from feminist\nepistemology and other accounts that stress the importance of the\nconstruction of scientific knowledge through epistemic communities.\nThese accounts are reviewed in\n section 5. \nIn the previous section we have presented arguments against the view\nof objectivity as faithfulness to facts and an impersonal “view\nfrom nowhere”. An alternative view is that science is objective\nto the extent that it is value-free. Why would we identify\nobjectivity with value-freedom or regard the latter as a prerequisite\nfor the former? Part of the answer is empiricism. If science is in the\nbusiness of producing empirical knowledge, and if differences about\nvalue judgments cannot be settled by empirical means, values should\nhave no place in science. In the following we will try to make this\nintuition more precise. \nBefore addressing what we will call the “value-free\nideal”, it will be helpful to distinguish four stages at which\nvalues may affect science. They are: (i) the choice of a scientific\nresearch problem; (ii) the gathering of evidence in relation to the\nproblem; (iii) the acceptance of a scientific hypothesis or theory as\nan adequate answer to the problem on the basis of the evidence; (iv)\nthe proliferation and application of scientific research results\n(Weber 1917 [1949]). \nMost philosophers of science would agree that the role of values in\nscience is contentious only with respect to dimensions (ii) and (iii):\nthe gathering of evidence and the acceptance\nof scientific theories. It is almost universally accepted\nthat the choice of a research problem is often influenced by interests\nof individual scientists, funding parties, and society as a whole.\nThis influence may make science more shallow and slow down its\nlong-run progress, but it has benefits, too: scientists will focus on\nproviding solutions to those intellectual problems that are considered\nurgent by society and they may actually improve people’s lives.\nSimilarly, the proliferation and application of scientific research\nresults is evidently affected by the personal values of journal\neditors and end users, and little can be done about this. The real\ndebate is about whether or not the “core” of scientific\nreasoning—the gathering of evidence and the assessment and\nacceptance scientific theories—is, and should be,\nvalue-free. \nWe have introduced the problem of the underdetermination of theory by\nevidence above. The problem does not stop, however, at values being\nrequired for filling the gap between theory and evidence. A further\ncomplication is that these values can conflict with each other.\nConsider the classical problem of fitting a mathematical function to a\ndata set. The researcher often has the choice between using a complex\nfunction, which makes the relationship between the variables less\nsimple but fits the data more accurately, or\npostulating a simpler relationship that is less\naccurate. Simplicity and accuracy are both important\ncognitive values, and trading them off requires a careful value\njudgment. However, philosophers of science tend to regard\nvalue-ladenness in this sense as benign. Cognitive\nvalues (sometimes also called “epistemic” or\n“constitutive” values) such as predictive accuracy, scope,\nunification, explanatory power, simplicity and coherence with other\naccepted theories are taken to be indicative of the truth of a theory\nand therefore provide reasons for preferring one theory over another\n(McMullin 1982, 2009; Laudan 1984; Steel 2010). Kuhn (1977) even\nclaims that cognitive values define the shared commitments of science,\nthat is, the standards of theory assessment that characterize the\nscientific approach as a whole. Note that not every philosopher\nentertains the same list of cognitive values: subjective differences\nin ranking and applying cognitive values do not vanish, a point Kuhn\nmade emphatically. \nIn most views, the objectivity and authority of science is not\nthreatened by cognitive values, but only by\nnon-cognitive or contextual values.\nContextual values are moral, personal, social, political and cultural\nvalues such as pleasure, justice and equality, conservation of the\nnatural environment and diversity. The most notorious cases of\nimproper uses of such values involve travesties of scientific\nreasoning, where the intrusion of contextual values led to an\nintolerant and oppressive scientific agenda with devastating epistemic\nand social consequences. In the Third Reich, a large part of\ncontemporary physics, such as the theory of relativity, was condemned\nbecause its inventors were Jewish; in the Soviet Union, biologist\nNikolai Vavilov was sentenced to death (and died in prison) because\nhis theories of genetic inheritance did not match Marxist-Leninist\nideology. Both states tried to foster a science that was motivated by\npolitical convictions (“Deutsche Physik” in Nazi Germany,\nLysenko’s Lamarckian theory of inheritance and denial of\ngenetics), leading to disastrous epistemic and institutional\neffects. \nLess spectacular, but arguably more frequent are cases where research\nis biased toward the interests of the sponsors, such as tobacco\ncompanies, food manufacturers and large pharmaceutic firms (e.g.,\nResnik 2007; Reiss 2010). This preference bias,\ndefined by Wilholt (2009) as the infringement of conventional\nstandards of the research community with the aim of arriving at a\nparticular result, is clearly epistemically harmful. Especially for\nsensitive high-stakes issues such as the admission of medical drugs or\nthe consequences of anthropogenic global warming, it seems desirable\nthat research scientists assess theories without being influenced by\nsuch considerations. This is the core idea of the \nValue-Free Ideal (VFI): Scientists should strive to\nminimize the influence of contextual values on scientific reasoning,\ne.g., in gathering evidence and assessing/accepting scientific\ntheories. \nAccording to the VFI, scientific objectivity is characterized by\nabsence of contextual values and by exclusive commitment to cognitive\nvalues in stages (ii) and (iii) of the scientific process. See Dorato\n(2004: 53–54), Ruphy (2006: 190) or Biddle (2013: 125) for\nalternative formulations. \nFor value-freedom to be a reasonable ideal, it must not be a goal\nbeyond reach and be attainable at least to some degree. This claim is\nexpressed by the \nValue-Neutrality Thesis (VNT): Scientists\ncan—at least in principle—gather evidence and\nassess/accept theories without making contextual value judgments. \nUnlike the VFI, the VNT is not normative: its subject is whether the\njudgments that scientists make are, or could possibly be, free of\ncontextual values. Similarly, Hugh Lacey (1999) distinguishes three\nprincipal components or aspects of value-free science: impartiality,\nneutrality and autonomy. Impartiality means that\ntheories are solely accepted or appraised in virtue of their\ncontribution to the cognitive values of science, such as truth,\naccuracy or explanatory power. This excludes the influence of\ncontextual values, as stated above. Neutrality means\nthat scientific theories make no value statements about the world:\nthey are concerned with what there is, not with what there should be.\nFinally, scientific autonomy means that the\nscientific agenda is shaped by the desire to increase scientific\nknowledge, and that contextual values have no place in scientific\nmethod. \nThese three interpretations of value-free science can be combined with\neach other, or used individually. All of them, however, are subject to\ncriticisms that we examine below. Denying the VNT, or the\nattainability of Lacey’s three criteria for value-free science,\nposes a challenge for scientific objectivity: one can either conclude\nthat the ideal of objectivity should be rejected, or develop a\nconception of objectivity that differs from the VFI. \nLacey’s characterization of value-free science and the VNT were\nonce mainstream positions in philosophy of science. Their widespread\nacceptance was closely connected to Reichenbach’s famous\ndistinction between context of discovery and\ncontext of justification. Reichenbach first made this\ndistinction with respect to the epistemology of mathematics: \nthe objective relation from the given entities to the solution, and\nthe subjective way of finding it, are clearly separated for problems\nof a deductive character […] we must learn to make the same\ndistinction for the problem of the inductive relation from facts to\ntheories. (Reichenbach 1938: 36–37) \nThe standard interpretation of this statement marks contextual values,\nwhich may have contributed to the discovery of a theory, as irrelevant\nfor justifying the acceptance of a theory, and for assessing\nhow evidence bears on theory—the relation that is crucial for\nthe objectivity of science. Contextual values are restricted to a\nmatter of individual psychology that may influence the discovery,\ndevelopment and proliferation of a scientific theory, but not its\nepistemic status. \nThis distinction played a crucial role in post-World War II philosophy\nof science. It presupposes, however, a clear-cut distinction between\ncognitive values on the one hand and contextual values on the other.\nWhile this may be prima facie plausible for disciplines such\nas physics, there is an abundance of contextual values in the social\nsciences, for instance, in the conceptualization and measurement of a\nnation’s wealth, or in different ways to measure the inflation\nrate (cf. Dupré 2007; Reiss 2008). More generally, three major\nlines of criticism can be identified. \nFirst, Helen Longino (1996) has argued that traditional cognitive\nvalues such as consistency, simplicity, breadth of scope and\nfruitfulness are not purely cognitive or epistemic after all, and that\ntheir use imports political and social values into contexts of\nscientific judgment. According to her, the use of cognitive values in\nscientific judgments is not always, not even normally, politically\nneutral. She proposes to juxtapose these values with feminist values\nsuch as novelty, ontological heterogeneity, mutuality of interaction,\napplicability to human needs and diffusion of power, and argues that\nthe use of the traditional value instead of its alternative (e.g.,\nsimplicity instead of ontological heterogeneity) can lead to biases\nand adverse research results. Longino’s argument here is\ndifferent from the one discussed in\n section 3.1.\n It casts the very distinction between cognitive and contextual values\ninto doubt. \nThe second argument against the possibility of value-free science is\nsemantic and attacks the neutrality of scientific theories: fact and\nvalue are frequently entangled because of the use of so-called\n“thick” ethical concepts in science (Putnam\n2002)—i.e., ethical concepts that have mixed descriptive and\nnormative content. For example, a description such as “dangerous\ntechnology” involves a value judgment about the technology and\nthe risks it implies, but it also has a descriptive content: it is\nuncertain and hard to predict whether using that technology will\nreally trigger those risks. If the use of such terms, where facts and\nvalues are inextricably entangled, is inevitable in scientific\nreasoning, it is impossible to describe hypotheses and results in a\nvalue-free manner, undermining the value-neutrality thesis. \nIndeed, John Dupré has argued that thick ethical terms are\nineliminable from science, at least certain parts of it (Dupré\n2007). Dupré’s point is essentially that scientific\nhypotheses and results concern us because they are relevant to human\ninterests, and thus they will necessarily be couched in a language\nthat uses thick ethical terms. While it will often be possible to\ntranslate ethically thick descriptions into neutral ones, the\ntranslation cannot be made without losses, and these losses obtain\nprecisely because human interests are involved (see\n section 6.2\n for a case study from social science). According to Dupré,\nthen, many scientific statements are value-free only because their\ntruth or falsity does not matter to us: \nWhether electrons have a positive or a negative charge and whether\nthere is a black hole in the middle of our galaxy are questions of\nabsolutely no immediate importance to us. The only human interests\nthey touch (and these they may indeed touch deeply) are cognitive\nones, and so the only values that they implicate are cognitive values.\n(2007: 31) \nA third challenge to the VNT, and perhaps the most influential one,\nwas raised first by Richard Rudner in his influential article\n“The Scientist Qua Scientist Makes Value Judgments”\n(Rudner 1953). Rudner disputes the core of the VNT and the context of\ndiscovery/justification distinction: the idea that the acceptance of a\nscientific theory can in principle be value-free. First, Rudner argues\nthat \nno analysis of what constitutes the method of science would be\nsatisfactory unless it comprised some assertion to the effect that the\nscientist as scientist accepts or rejects hypotheses.\n(1953: 2) \nThis assumption stems from industrial quality control and other\napplication-oriented research. In such contexts, it is often necessary\nto accept or to reject a hypothesis (e.g., the efficacy of a drug) in\norder to make effective decisions. \nSecond, he notes that no scientific hypothesis is ever confirmed\nbeyond reasonable doubt—some probability of error always\nremains. When we accept or reject a hypothesis, there is always a\nchance that our decision is mistaken. Hence, our decision is also\n“a function of the importance, in the typically ethical\nsense, of making a mistake in accepting or rejecting a\nhypothesis” (1953: 2): we are balancing the seriousness of two\npossible errors (erroneous acceptance/rejection of the hypothesis)\nagainst each other. This corresponds to type I and type II error in\nstatistical inference. \nThe decision to accept or reject a hypothesis involves a value\njudgment (at least implicitly) because scientists have to judge which\nof the consequences of an erroneous decision they deem more palatable:\n(1) some individuals die of the side effects of a drug erroneously\njudged to be safe; or (2) other individuals die of a condition because\nthey did not have access to a treatment that was erroneously judged to\nbe unsafe. Hence, ethical judgments and contextual values necessarily\nenter the scientist’s core activity of accepting and rejecting\nhypotheses, and the VNT stands refuted. Closely related arguments can\nbe found in Churchman (1948) and Braithwaite (1953). Hempel (1965:\n91–92) gives a modified account of Rudner’s argument by\ndistinguishing between judgments of confirmation, which are\nfree of contextual values, and judgments of acceptance. Since\neven strongly confirming evidence cannot fully prove a universal\nscientific law, we have to live with a residual “inductive\nrisk” in inferring that law. Contextual values influence\nscientific methods by determining the acceptable amount of inductive\nrisk (see also Douglas 2000). \nBut how general are Rudner’s objections? Apparently, his result\nholds true of applied science, but not necessarily of fundamental\nresearch. For the latter domain, two major lines of rebuttals have\nbeen proposed. First, Richard Jeffrey (1956) notes that lawlike\nhypotheses in theoretical science (e.g., the gravitational law in\nNewtonian mechanics) are characterized by their general scope and not\nconfined to a particular application. Obviously, a scientist cannot\nfine-tune her decisions to their possible consequences in a wide\nvariety of different contexts. So she should just refrain from the\nessentially pragmatic decision to accept or reject hypotheses. By\nrestricting scientific reasoning to gathering and interpreting\nevidence, possibly supplemented by assessing the probability of a\nhypothesis, Jeffrey tries to save the VNT in fundamental scientific\nresearch, and the objectivity of scientific reasoning. \nSecond, Isaac Levi (1960) observes that scientists commit themselves\nto certain standards of inference when they become a member of the\nprofession. This may, for example, lead to the statistical rejection\nof a hypothesis when the observed significance level is smaller than\n5%. These community standards may eliminate any room for contextual\nethical judgment on behalf of the scientist: they determine when she\nshould accept a hypothesis as established. Value judgments may be\nimplicit in how a scientific community sets standards of inference\n(compare\n section 5.1),\n but not in the daily work of an individual scientist (cf.\nWilholt 2013). \nBoth defenses of the VNT focus on the impact of values in theory\nchoice, either by denying that scientists actually choose theories\n(Jeffrey), or by referring to community standards and restricting the\nVNT to the individual scientist (Levi). Douglas (2000: 563–565)\npoints out, however, that the “acceptance” of scientific\ntheories is only one of several places for values to enter scientific\nreasoning, albeit an especially prominent and explicit one. Many\ndecisions in the process of scientific inquiry may conceal implicit\nvalue judgments: the design of an experiment, the methodology for\nconducting it, the characterization of the data, the choice of a\nstatistical method for processing and analyzing data, the\ninterpretational process findings, etc. None of these methodological\ndecisions could be made without consideration of the possible\nconsequences that could occur. Douglas gives, as a case study, a\nseries of experiments where carcinogenic effects of dioxin exposure on\nrats were probed. Contextual values such as safety and risk aversion\naffected the conducted research at various stages: first, in the\nclassification of pathological samples as benign or cancerous (over\nwhich a lot of expert disagreement occurred), second, in the\nextrapolation from the high-dose experimental conditions to the more\nrealistic low-dose conditions. In both cases, the choice of a\nconservative classification or model had to be weighed against the\nadverse consequences for society that could result from\nunderestimating the risks (see also Biddle 2013). \nThese diagnoses cast a gloomy light on attempts to divide scientific\nlabor between gathering evidence and determining the degree of\nconfirmation (value-free) on the one hand and accepting scientific\ntheories (value-laden) on the other. The entire process of\nconceptualizing, gathering and interpreting evidence is so entangled\nwith contextual values that no neat division, as Jeffrey envisions,\nwill work outside the narrow realm of statistical inference—and\neven there, doubts may be raised\n (see section 4.2). \nPhilip Kitcher (2011a: 31–40; see also Kitcher 2011b) gives an\nalternative argument, based on his idea of “significant\ntruths”. There are simply too many truths that are of no\ninterest whatsoever, such as the total number of offside positions in\na low-level football competition. Science, then, doesn’t aim at\ntruth simpliciter but rather at something more narrow: truth\nworth pursuing from the point of view of our cognitive, practical and\nsocial goals. Any truth that is worth pursuing in this sense is what\nhe calls a “significant truth”. Clearly, it is value\njudgments that help us decide whether or not any given truth is\nsignificant. \nKitcher goes on to observing that the process of scientific\ninvestigation cannot neatly be divided into a stage in which the\nresearch question is chosen, one in which the evidence is gathered and\none in which a judgment about the question is made on the basis of the\nevidence. Rather, the sequence is multiply iterated, and at each\nstage, the researcher has to decide whether previous results warrant\npursuit of the current line of research, or whether she should switch\nto another avenue. Such choices are laden with contextual values. \nValues in science also interact, according to Kitcher, in a\nnon-trivial way. Assume we endorse predictive accuracy as an important\ngoal of science. However, there may not be a convincing strategy to\nreach this goal in some domain of science, for instance because that\ndomain is characterized by strong non-linear dependencies. In this\ncase, predictive accuracy might have to yield to achieving other\nvalues, such as consistency with theories in neighbor domains.\nConversely, changing social goals lead to re-evaluations of scientific\nknowledge and research methods. \nScience, then, cannot be value-free because no scientist ever works\nexclusively in the supposedly value-free zone of assessing and\naccepting hypotheses. Evidence is gathered and hypotheses are assessed\nand accepted in the light of their potential for application and\nfruitful research avenues. Both cognitive and contextual value\njudgments guide these choices and are themselves influenced by their\nresults. \nThe discussion so far has focused on the VNT, the practical\nattainability of the VFI, but little has been said about whether a\nvalue-free science is desirable in the first place. This subsection\ndiscusses this topic with special attention to informing and advising\npublic policy from a scientific perspective. While the VFI, and many\narguments for and against it, can be applied to science as a whole,\nthe interface of science and public policy is the place where the\nintrusion of values into science is especially salient, and where it\nis surrounded by the greatest controversy. In the 2009\n“Climategate” affair, leaked emails from climate\nscientists raised suspicions that they were pursuing a particular\nsocio-political agenda that affected their research in an improper\nway. Later inquiries and reports absolved them from charges of\nmisconduct, but the suspicions alone did much to damage the authority\nof science in the public arena. \nIndeed, many debates at the interface of science and public policy are\ncharacterized by disagreements on propositions that combine a factual\nbasis with specific goals and values. Take, for instance, the view\nthat growing transgenic crops carries too much risk in terms of\nbiosecurity, or addressing global warming by phasing out fossil\nenergies immediately. The critical question in such debates is whether\nthere are theses \\(T\\) such that one side in the debate endorses\n\\(T\\), the other side rejects it, the evidence is shared, and both\nsides have good reasons for their respective positions. \nAccording to the VFI, scientists should uncover an epistemic,\nvalue-free basis for resolving such disagreements and restrict the\ndissent to the realm of value judgments. Even if the VNT should turn\nout to be untenable, and a strict separation to be impossible, the VFI\nmay have an important function for guiding scientific\nresearch and for minimizing the impact of values on an objective\nscience. In the philosophy of science, one camp of scholars defends\nthe VFI as a necessary antidote to individual and institutional\ninterests, such as Hugh Lacey (1999, 2002), Ernan McMullin (1982) and\nSandra Mitchell (2004), while others adopt a critical attitude, such\nas Helen Longino (1990, 1996), Philip Kitcher (2011a) and Heather\nDouglas (2009). These criticisms we discuss mainly refer to the\ndesirability or the conceptual (un)clarity of the VFI. \nFirst, it has been argued that the VFI is not desirable at all.\nFeminist philosophers (e.g., Harding 1991; Okruhlik 1994; Lloyd 2005)\nhave argued that science often carries a heavy androcentric values,\nfor instance in biological theories about sex, gender and rape. The\ncharge against these values is not so much that they are contextual\nrather than cognitive, but that they are unjustified. Moreover, if\nscientists did follow the VFI rigidly, policy-makers would pay even\nless attention to them, with a detrimental effect on the decisions\nthey take (Cranor 1993). Given these shortcomings, the VFI has to be\nrethought if it is supposed to play a useful role for guiding\nscientific research and leading to better policy decisions.\n Section 4.3\n and\n section 5.2\n elaborate on this line of criticism in the context of scientific\ncommunity practices, and a science in the service of society. \nSecond, the autonomy of science often fails in practice due to the\npresence of external stakeholders, such as funding agencies and\nindustry lobbies. To save the epistemic authority of science, Douglas\n(2009: 7–8) proposes to detach it from its autonomy by\nreformulating the VFI and distinguishing between direct and\nindirect roles of values in science. Contextual values may\nlegitimately affect the assessment of evidence by indicating the\nappropriate standard of evidence, the representation of complex\nprocesses, the severity of consequences of a decision, the\ninterpretation of noisy datasets, and so on (see also Winsberg 2012).\nThis concerns, above all, policy-related disciplines such as climate\nscience or economics that routinely perform scientific risk analyses\nfor real-world problems (cf. also Shrader-Frechette 1991). Values\nshould, however, not be “reasons in themselves”, that is,\nevidence or defeaters for evidence (direct role, illegitimate) and as\n“helping to decide what should count as a sufficient\nreason for a choice” (indirect role, legitimate). This\nprohibition for values to replace or dismiss scientific evidence is\ncalled detached objectivity by Douglas, but it is\ncomplemented by various other aspects that relate to a reflective\nbalancing of various perspectives and the procedural, social aspects\nof science (2009: ch. 6). \nThat said, Douglas’ proposal is not very concrete when it comes\nto implementation, e.g., regarding the way diverse values should be\nbalanced. Compromising in the middle cannot be the solution (Weber\n1917 [1949]). First, no standpoint is, just in virtue of being in the\nmiddle, evidentially supported vis-à-vis more extreme\npositions. Second, these middle positions are also, from a practical\npoint of view, the least functional when it comes to advising\npolicy-makers. \nMoreover, the distinction between direct and indirect roles of values\nin science may not be sufficiently clear-cut to police the legitimate\nuse of values in science, and to draw the necessary borderlines.\nAssume that a scientist considers, for whatever reason, the\nconsequences of erroneously accepting hypothesis \\(H\\) undesirable.\nTherefore he uses a statistical model whose results are likely to\nfavor ¬\\(H\\) over \\(H\\). Is this a matter of reasonable\nconservativeness? Or doesn’t it amount to reasoning to a\nforegone conclusion, and to treating values as evidence (cf. Elliott\n2011: 320–321)? \nThe most recent literature on values and evidence in science presents\nus with a broad spectrum of opinions. Steele (2012) and Winsberg\n(2012) agree that probabilistic assessments of uncertainty involve\ncontextual value judgments. While Steele defends this point by\nanalyzing the role of scientists as policy advisors, Winsberg points\nto the influence of contextual values in the selection and\nrepresentation of physical processes in climate modeling. Betz (2013)\nargues, by contrast, that scientists can largely avoid making\ncontextual value judgments if they carefully express the uncertainty\ninvolved with their evidential judgments, e.g., by using a scale\nranging from purely qualitative evidence (such as expert judgment) to\nprecise probabilistic assessments. The issue of value judgments at\nearlier stages of inquiry is not addressed by this proposal; however,\ndisentangling evidential judgments and judgments involving contextual\nvalues at the stage of theory assessment may be a good thing in\nitself. \nThus, should we or should we not worried about values in scientific\nreasoning? While the interplay of values and evidential considerations\nneed not be pernicious, it is unclear why it adds to the\nsuccess or the authority of science. How are we going to ensure that\nthe permissive attitude towards values in setting evidential standards\netc. is not abused? In the absence of a general theory about which\ncontextual values are beneficial and which are pernicious, the VFI\nmight as well be as a first-order approximation to a sound,\ntransparent and objective science. \nThis section deals with scientific objectivity as a form of\nintersubjectivity—as freedom from personal biases. According to\nthis view, science is objective to the extent that personal biases are\nabsent from scientific reasoning, or that they can be eliminated in a\nsocial process. Perhaps all science is necessarily perspectival.\nPerhaps we cannot sensibly draw scientific inferences without a host\nof background assumptions, which may include assumptions about values.\nPerhaps all scientists are biased in some way. But objective\nscientific results do not, or so the argument goes, depend on\nresearchers’ personal preferences or experiences—they are\nthe result of a process where individual biases are gradually filtered\nout and replaced by agreed upon evidence. That, among other things, is\nwhat distinguishes science from the arts and other human activities,\nand scientific knowledge from a fact-independent social construction\n(e.g., Haack 2003). \nParadigmatic ways to achieve objectivity in this sense are measurement\nand quantification. What has been measured and quantified has been\nverified relative to a standard. The truth, say, that the Eiffel Tower\nis 324 meters tall is relative to a standard unit and conventions\nabout how to use certain instruments, so it is neither aperspectival\nnor free from assumptions, but it is independent of the person making\nthe measurement. \nWe will begin with a discussion of objectivity, so conceived, in\nmeasurement, discuss the ideal of “mechanical objectivity”\nand then investigate to what extent freedom from personal biases can\nbe implemented in statistical evidence and inductive\ninference—arguably the core of scientific reasoning, especially\nin quantitatively oriented sciences. Finally, we discuss\nFeyerabend’s radical criticism of a rational scientific method\nthat can be mechanically applied, and his defense of the epistemic and\nsocial benefits of personal “bias” and idiosyncrasy. \nMeasurement is often thought to epitomize scientific objectivity, most\nfamously captured in Lord Kelvin’s dictum \nwhen you cannot express it in numbers, your knowledge is of a meagre\nand unsatisfactory kind; it may be the beginning of knowledge, but you\nhave scarcely, in your thoughts, advanced to the stage of\nscience, whatever the matter may be. (Kelvin 1883, 73) \nMeasurement can certainly achieve some independence of perspective.\nYesterday’s weather in Durham UK may have been “really\nhot” to the average North Eastern Brit and “very\ncold” to the average Mexican, but they’ll both accept that\nit was 21°C. Clearly, however, measurement does not result in a\n“view from nowhere”, nor are typical measurement results\nfree from presuppositions. Measurement instruments interact with the\nenvironment, and so results will always be a product of both the\nproperties of the environment we aim to measure as well as the\nproperties of the instrument. Instruments, thus, provide a\nperspectival view on the world (cf. Giere 2006). \nMoreover, making sense of measurement results requires interpretation.\nConsider temperature measurement. Thermometers function by relating an\nunobservable quantity, temperature, to an observable quantity,\nexpansion (or length) of a fluid or gas in a glass tube; that is,\nthermometers measure temperature by assuming that length is a function\nof temperature: length = \\(f\\)(temperature). The function \\(f\\) is not\nknown a priori, and it cannot be tested either (because it\ncould in principle only be tested using a veridical\nthermometer, and the veridicality of the thermometer is just what is\nat stake here). Making a specific assumption, for instance that \\(f\\)\nis linear, solves that problem by fiat. But this\n“solution” does not take us very far because different\nthermometric substances (e.g., mercury, air or water) yield different\nresults for the points intermediate between the two fixed points\n0°C and 100°C, and so they can’t all expand\nlinearly. \nAccording to Hasok Chang’s account of early thermometry (Chang\n2004), the problem was eventually solved by using a “principle\nof minimalist overdetermination”, the goal of which was to find\na reliable thermometer while making as few substantial assumptions\n(e.g., about the form for \\(f\\)) as possible. It was argued that if a\nthermometer was to be reliable, different tokens of the same\nthermometer type should agree with each other, and the results of air\nthermometers agreed the most. “Minimal” doesn’t mean\nzero, however, and indeed this procedure makes an important\npresupposition (in this case a metaphysical assumption about the\none-valuedness of a physical quantity). Moreover, the procedure\nyielded at best a reliable instrument, not necessarily one that was\nbest at tracking the uniquely real temperature (if there is such a\nthing). \nWhat Chang argues about early thermometry is true of measurements more\ngenerally: they are always made against a backdrop of metaphysical\npresuppositions, theoretical expectations and other kinds of belief.\nWhether or not any given procedure is regarded as adequate depends to\na large extent on the purposes pursued by the individual scientist or\ngroup of scientists making the measurements. Especially in the social\nsciences, this often means that measurement procedures are laden with\nnormative assumptions, i.e., values. \nJulian Reiss (2008, 2013) has argued that economic indicators such as\nconsumer price inflation, gross domestic product and the unemployment\nrate are value-laden in this sense. Consumer-price indices, for\ninstance, assume that if a consumer prefers a bundle \\(x\\) over an\nalternative \\(y\\), then \\(x\\) is better for her than \\(y\\), which is\nas ethically charged as it is controversial. National income measures\nassume that nations that exchange a larger share of goods and services\non markets are richer than nations where the same goods and services\nare provided by the government or within households, which too is\nethically charged and controversial. \nWhile not free of assumptions and values, the goal of many measurement\nprocedures remains to reduce the influence of personal biases and\nidiosyncrasies. The Nixon administration, famously, indexed social\nsecurity payments to the consumer-price index in order to eliminate\nthe dependence of security recipients on the flimsiest of party\npolitics: to make increases automatic instead of a result of political\nnegotiations (Nixon 1969). Lorraine Daston and Peter Galison refer to\nthis as mechanical objectivity. They write: \nFinally, we come to the full-fledged establishment of mechanical\nobjectivity as the ideal of scientific representation. What we find is\nthat the image, as standard bearer of is objectivity is tied to a\nrelentless search to replace individual volition and discretion in\ndepiction by the invariable routines of mechanical reproduction.\n(Daston and Galison 1992: 98) \nMechanical objectivity reduces the importance of human contributions\nto scientific results to a minimum, and therefore enables science to\nproceed on a large scale where bonds of trust between individuals can\nno longer hold (Daston 1992). Trust in mechanical procedures thus\nreplaces trust in individual scientists. \nIn his book Trust in Numbers, Theodore Porter pursues this\nline of thought in great detail. In particular, on the basis of case\nstudies involving British actuaries in the mid-nineteenth century, of\nFrench state engineers throughout the century, and of the US Army\nCorps of Engineers from 1920 to 1960, he argues for two causal claims.\nFirst, measurement instruments and quantitative procedures originate\nin commercial and administrative needs and affect the ways in which\nthe natural and social sciences are practiced, not the other way\naround. The mushrooming of instruments such as chemical balances,\nbarometers, chronometers was largely a result of social pressures and\nthe demands of democratic societies. Administering large territories\nor controlling diverse people and processes is not always possible on\nthe basis of personal trust and thus “objective\nprocedures” (which do not require trust in persons) took the\nplace of “subjective judgments” (which do). Second, he\nargues that quantification is a technology of distrust and weakness,\nand not of strength. It is weak administrators who do not have the\nsocial status, political support or professional solidarity to defend\ntheir experts’ judgments. They therefore subject decisions to\npublic scrutiny, which means that they must be made in a publicly\naccessible form. \nThis is the situation in which scientists who work in areas where the\nscience/policy boundary is fluid find themselves: \nThe National Academy of Sciences has accepted the principle that\nscientists should declare their conflicts of interest and financial\nholdings before offering policy advice, or even information to the\ngovernment. And while police inspections of notebooks remain\nexceptional, the personal and financial interests of scientists and\nengineers are often considered material, especially in legal and\nregulatory contexts. \nStrategies of impersonality must be understood partly as defenses\nagainst such suspicions […]. Objectivity means knowledge that\ndoes not depend too much on the particular individuals who author it.\n(Porter 1995: 229) \nMeasurement and quantification help to reduce the influence of\npersonal biases and idiosyncrasies and they reduce the need to trust\nthe scientist or government official, but often at a cost.\nStandardizing scientific procedures becomes difficult when their\nsubject matters are not homogeneous, and few domains outside\nfundamental physics are. Attempts to quantify procedures for treatment\nand policy decisions that we find in evidence-based practices are\ncurrently transferred to a variety of sciences such as medicine,\nnursing, psychology, education and social policy. However, they often\nlack a certain degree of responsiveness to the peculiarities of their\nsubjects and the local conditions to which they are applied (see also\n section 5.3). \nMoreover, the measurement and quantification of characteristics of\nscientific interest is only half of the story. We also want to\ndescribe relations between the quantities and make inferences using\nstatistical analysis. Statistics thus helps to quantify further\naspects of scientific work. We will now examine whether or not\nstatistical analysis can proceed in a way free from personal biases\nand idiosyncrasies—for more detail, see the entry on\n philosophy of statistics. \nThe appraisal of scientific evidence is traditionally regarded as a\ndomain of scientific reasoning where the ideal of scientific\nobjectivity has strong normative force, and where it is also\nwell-entrenched in scientific practice. Episodes such as\nGalilei’s observations of the Jupiter moons, Lavoisier’s\ncalcination experiments, and Eddington’s observation of the 1919\neclipse are found in all philosophy of science textbooks because they\nexemplify how evidence can be persuasive and compelling to scientists\nwith different backgrounds. The crucial question is therefore: can we\nidentify an “objective” concept of scientific evidence\nthat is independent of the personal biases of the experimenter and\ninterpreter? \nInferential statistics—the field that investigates the validity\nof inferences from data to theory—tries to answer this question.\nIt is extremely influential in modern science, pervading experimental\nresearch as well as the assessment and acceptance of our most\nfundamental theories. For instance, a statistical argument helped to\nestablish the recent discovery of the Higgs Boson. We now compare the\nmain theories of statistical evidence with respect to the objectivity\nof the claims they produce. They mainly differ with respect to the\nrole of an explicitly subjective interpretation of probability. \nBayesian inference quantifies scientific evidence by means of\nprobabilities that are interpreted as a scientist’s subjective\ndegrees of belief. The Bayesian thus leaves behind Carnap’s\n(1950) idea that probability is determined by a logical relation\nbetween sentences. For example, the prior degree of belief in\nhypothesis \\(H\\), written \\(p(H)\\), can in principle take any value in\nthe interval \\([0,1]\\). Simultaneously held degrees of belief in\ndifferent hypotheses are, however, constrained by the laws of\nprobability. After learning evidence E, the degree of belief in \\(H\\)\nis changed from its prior probability \\(p(H)\\) to the conditional\ndegree of belief \\(p(H \\mid E)\\), commonly called the posterior\nprobability of \\(H\\). Both quantities can be related to each other by\nmeans of\n Bayes’ Theorem. \nThese days, the Bayesian approach is extremely influential in\nphilosophy and rapidly gaining ground across all scientific\ndisciplines. For quantifying evidence for a hypothesis, Bayesian\nstatisticians almost uniformly use the Bayes factor,\nthat is, the ratio of prior to posterior odds in favor of a\nhypothesis. The Bayes factor in favor of hypothesis \\(H\\) against its\nnegation \\(\\neg\\)\\(H\\) in the light of evidence \\(E\\) can be written\nas \nor in other words, as the likelihood ratio between \\(H\\) and\n\\(\\neg\\)\\(H\\). The Bayes factor reduces to the likelihoodist\nconception of evidence (Royall 1997) for the case of two competing\npoint hypotheses. For further discussion of Bayesian measures of\nevidence, see Good (1950), Sprenger and Hartmann (2019: ch. 1) and the\nentry on\n confirmation and evidential support. \nUnsurprisingly, the idea to measure scientific evidence in terms of\nsubjective probability has met resistance. For example, the\nstatistician Ronald A. Fisher (1935: 6–7) has argued that\nmeasuring psychological tendencies cannot be relevant for scientific\ninquiry and sustain claims to objectivity. Indeed, how should\nscientific objectivity square with subjective degree of belief?\nBayesians have responded to this challenge in various ways: \nHowson (2000) and Howson and Urbach (2006) consider the objection\nmisplaced. In the same way that deductive logic does not judge the\ncorrectness of the premises but just advises you what to infer from\nthem, Bayesian inductive logic provides rational\nrules for representing uncertainty and making inductive inferences.\nChoosing the premises (e.g., the prior distributions)\n“objectively” falls outside the scope of Bayesian\nanalysis. \nConvergence or merging-of-opinion theorems guarantee\nthat under certain circumstances, agents with very different initial\nattitudes who observe the same evidence will obtain similar posterior\ndegrees of belief in the long run. However, they are asymptotic\nresults without direct implications for inference with real-life\ndatasets (see also Earman 1992: ch. 6). In such cases, the choice of\nthe prior matters, and it may be beset with idiosyncratic bias and\nmanifest social values. \nAdopting a more modest stance, Sprenger (2018) accepts that Bayesian\ninference does not achieve the goal of objectivity in the sense of\nintersubjective agreement (concordant objectivity), or being free of\npersonal values, bias and subjective judgment. However, he argues that\ncompeting schools of inference such as frequentist inference face this\nproblem to the same degree, perhaps even worse. Moreover, some\nfeatures of Bayesian inference (e.g., the transparency about prior\nassumptions) fit recent, socially oriented conceptions of objectivity\nthat we discuss in\n section 5. \nA radical Bayesian solution to the problem of personal bias is to\nadopt a principle that radically constrains an agent’s rational\ndegrees of belief, such as the Principle of Maximum\nEntropy (MaxEnt—Jaynes 1968; Williamson 2010).\nAccording to MaxEnt, degrees of belief must be probabilistic and in\nsync with empirical constraints, but conditional on these constraints,\nthey must be equivocal, that is, as middling as possible. This latter\nconstraint amounts to maximizing the entropy of the probability\ndistribution in question. The MaxEnt approach eliminates various\nsources of subjective bias at the expense of narrowing down the range\nof rational degrees of belief. An alternative objective Bayesian\nsolution consists in so-called “objective\npriors”: prior probabilities that do not represent an\nagent’s factual attitudes, but are determined by principles of\nsymmetry, mathematical convenience or maximizing the influence of the\ndata on the posterior (e.g., Jeffreys 1939 [1980]; Bernardo 2012). \nThus, Bayesian inference, which analyzes statistical evidence from the\nvantage point of rational belief, provides only a partial answer to\nsecuring scientific objectivity from personal idiosyncrasy. \nThe frequentist conception of evidence is based on the idea of the\nstatistical test of a hypothesis. Under the influence\nof the statisticians Jerzy Neyman and Egon Pearson, tests were often\nregarded as rational decision procedures that minimize the relative\nfrequency of wrong decisions in a hypothetical series of repetitions\nof a test (hence the name “frequentism”). Rudner’s\nargument in\n section 3.2\n has pointed out the limits of this conception of hypothesis tests:\nthe choice of thresholds for acceptance and rejection (i.e., the\nacceptable type I and II error rates) may reflect contextual value\njudgments and personal bias. Moreover, the losses associated with\nerroneously accepting or rejecting that hypothesis depend on the\ncontext of application which may be unbeknownst to the\nexperimenter. \nAlternatively, scientists can restrict themselves to a purely\nevidential interpretation of hypothesis tests and leave decisions to\npolicy-makers and regulatory agencies. The statistician and biologist\nR.A. Fisher (1935, 1956) proposed what later became the orthodox\nquantification of evidence in frequentist statistics. Suppose a\n“null” or default hypothesis \\(H_0\\) denotes that an\nintervention has zero effect. If the observed data are\n“extreme” under \\(H_0\\)—i.e., if it was highly\nlikely to observe a result that agrees better with \\(H_0\\)—the\ndata provide evidence against the null hypothesis and for the efficacy\nof the intervention. The epistemological rationale is connected to the\nidea of severe testing (Mayo 1996): if the intervention were\nineffective, we would, in all likelihood, have found data that agree\nbetter with the null hypothesis. The strength of evidence against\n\\(H_0\\) is equal to the \\(p\\)-value: the lower it is,\nthe stronger evidence \\(E\\) speaks against the null hypothesis\n\\(H_0\\). \nUnlike Bayes factors, this concept of statistical evidence does not\ndepend on personal degrees of belief. However, this does not\nnecessarily mean that \\(p\\)-values are more objective. First,\n\\(p\\)-values are usually classified as “non-significant”\n(\\(p > .05\\)), “significant” (\\(p < .05\\)),\n“highly significant”, and so on. Not only that these\nthresholds and labels are largely arbitrary, they also promote\npublication bias: non-significant findings are often\nclassified as “failed studies” (i.e., the efficacy of the\nintervention could not be shown), rarely published and end up in the\nproverbial “file drawer”. Much valuable research is\nsuppressed. Conversely, significant findings may often occur when the\nnull hypothesis is actually true, especially when researchers have\nbeen “hunting for significance”. In fact, researchers have\nan incentive to keep their \\(p\\)-values low: the stronger the\nevidence, the more convincing the narrative, the greater the\nimpact—and the higher the chance for a good publication and\ncareer-relevant rewards. Moving the goalpost by\n“p-hacking” outcomes—for example by eliminating\noutliers, selective reporting or restricting the analysis to a\nsubgroup—evidently biases the research results and compromises\nthe objectivity of experimental research. \nIn particular, such questionable research practices\n(QRP) increase the type I error rate, which measures the rate\nat which false hypotheses are accepted, substantially over its nominal\n5% level and contribute to publication bias (Bakker et al. 2012).\nIoannidis (2005) concludes that “most published research\nfindings are false”—they are the combined result of a low\nbase rate of effective causal interventions, the file drawer effect\nand the widespread presence of questionable research practices. The\nfrequentist logic of hypothesis testing aggravates the problem because\nit provides a framework where all these biases can easily enter\n(Ziliak and McCloskey 2008; Sprenger 2016). These radical conclusions\nare also confirmed by empirical findings: in many disciplines\nresearchers fail to replicate findings by other scientific teams. See\n section 5.1\n for more detail. \nSumming up our findings, neither of the two major frameworks of\nstatistical inference manages to eliminate all sources of personal\nbias and idiosyncrasy. The Bayesian considers subjective assumptions\nto be an irreducible part of scientific reasoning and sees no harm in\nmaking them explicit. The frequentist conception of evidence based on\n\\(p\\)-values avoids these explicitly subjective elements, but at the\nprice of a misleading impression of objectivity and frequent abuse in\npractice. A defense of frequentist inference should, in our opinion,\nstress that the relatively rigid rules for interpreting statistical\nevidence facilitate communication and assessment of research results\nin the scientific community—something that is harder to achieve\nfor a Bayesian. We now turn from specific methods for stating and\ninterpreting evidence to a radical criticism of the idea that there is\na rational scientific method. \nIn his writings of the 1970s,\n Paul Feyerabend\n launched a profound attack on the rationality and objectivity of\nscientific method. His position is exceptional in the philosophical\nliterature since traditionally, the threat for objective and\nsuccessful science is located in contextual rather than epistemic\nvalues. Feyerabend turns this view upside down: it is the\n“tyranny” of rational method, and the emphasis on\nepistemic rather than contextual values that prevents us from having a\nscience in the service of society. Moreover, he welcomes a diversity\nof different personal, also idiosyncratic perspectives, thus denying\nthe idea that freedom from personal “bias” is\nepistemically and socially beneficial. \nThe starting point of Feyerabend’s criticism of rational method\nis the thesis that strict epistemic rules such as those expressed by\nthe VFI only suppress an open exchange of ideas, extinguish scientific\ncreativity and prevent a free and truly democratic science. In his\nclassic “Against Method” (1975: chs. 8–13),\nFeyerabend elaborates on this criticism by examining a famous episode\nin the history of science. When the Catholic Church objected to\nGalilean mechanics, it had the better arguments by the standards of\nseventeenth-century science. Their conservatism in their position was\nscientifically backed: Galilei’s telescopes were unreliable for\ncelestial observations, and many well-established phenomena (no fixed\nstar parallax, invariance of laws of motion) could not yet be\nexplained in the heliocentric system. With hindsight, Galilei managed\nto achieve groundbreaking scientific progress just because he\ndeliberately violated rules of scientific reasoning. Hence\nFeyerabend’s dictum “Anything goes”: no methodology\nwhatsoever is able to capture the creative and often irrational ways\nby which science deepens our understanding of the world. Good\nscientific reasoning cannot be captured by rational method, as Carnap,\nHempel and Popper postulated. \nThe drawbacks of an objective, value-free and method-bound view on\nscience and scientific method are not only epistemic. Such a view\nnarrows down our perspective and makes us less free, open-minded,\ncreative, and ultimately, less human in our thinking (Feyerabend 1975:\n154). It is therefore neither possible nor desirable to have an\nobjective, value-free science (cf. Feyerabend 1978: 78–79). As a\nconsequence, Feyerabend sees traditional forms of inquiry about our\nworld (e.g., Chinese medicine) on a par with their Western\ncompetitors. He denounces appeals to “objective” standards\nas rhetorical tools for bolstering the epistemic authority of a small\nintellectual elite (=Western scientists), and as barely disguised\nstatements of preference for one’s own worldview: \nthere is hardly any difference between the members of a\n“primitive” tribe who defend their laws because they are\nthe laws of the gods […] and a rationalist who appeals to\n“objective” standards, except that the former know what\nthey are doing while the latter does not. (1978: 82) \nIn particular, when discussing other traditions, we often project our\nown worldview and value judgments into them instead of making an\nimpartial comparison (1978: 80–83). There is no purely rational\njustification for dismissing other perspectives in favor of the\nWestern scientific worldview—the insistence on our Western\napproach may be as justified as insisting on absolute space and time\nafter the Theory of Relativity. \nThe Galilei example also illustrates that personal perspective and\nidiosyncratic “bias” need not be bad for science.\nFeyerabend argues further that scientific research is accountable to\nsociety and should be kept in check by democratic institutions, and\nlaymen in particular. Their particular perspectives can help to\ndetermine the funding agenda and to set ethical standards for\nscientific inquiry, but also be useful for traditionally value-free\ntasks such as choosing an appropriate research method and assessing\nscientific evidence. Feyerabend’s writings on this issue were\nmuch influenced by witnessing the Civil Rights Movement in the U.S.\nand the increasing emancipation of minorities, such as Blacks, Asians\nand Hispanics. \nAll this is not meant to say that truth loses its function as a\nnormative concept, nor that all scientific claims are equally\nacceptable. Rather, Feyerabend advocates an epistemic\npluralism that accepts diverse approaches to acquiring\nknowledge. Rather than defending a narrow and misleading ideal of\nobjectivity, science should respect the diversity of values and\ntraditions that drive our inquiries about the world (1978:\n106–107). This would put science back into the role it had\nduring the scientific revolution or the Enlightenment: as a liberating\nforce that fought intellectual and political oppression by the\nsovereign, the nobility or the clergy. Objections to this view are\ndiscussed at the end of\n section 5.2. \nThis section addresses various accounts that regard scientific\nobjectivity essentially as a function of social practices in science\nand the social organization of the scientific community. All these\naccounts reject the characterization of scientific objectivity as a\nfunction of correspondence between theories and the world, as a\nfeature of individual reasoning practices, or as pertaining to\nindividual studies and experiments (see also Douglas 2011). Instead,\nthey evaluate the objectivity of a collective of studies, as\nwell as the methods and community practices that structure and guide\nscientific research. More precisely, they adopt a meta-analytic\nperspective for assessing the reliability of scientific results\n(section 5.1), and they construct objectivity from a feminist\nperspective: as an open interchange of mutual criticism, or as being\nanchored in the “situatedness” of our scientific practices\nand the knowledge we gain\n (section 5.2). \nThe collectivist perspective is especially useful when an entire\ndiscipline enters a stage of crisis: its members become convinced that\na significant proportion of findings are not trustworthy. A\ncontemporary example of such a situation is the replication\ncrisis, which was briefly mentioned in the previous section\nand concerns the reproducibility of scientific knowledge\nclaims in a variety of different fields (most prominently: psychology,\nbiology, medicine). Large-scale replication projects have noticed that\nmany findings which we considered as an integral part of scientific\nknowledge failed to replicate in settings that were designed to mimic\nthe original experiment as closely as possible (e.g., Open Science\nCollaboration 2015). Successful attempts at replicating an\nexperimental result have long been argued to provide evidence of\nfreedom from particular kinds of artefacts and thus the\ntrustworthiness of the result. Compare the\n entry on experiment in physics.\n Likewise, failure to replicate indicates that either the original\nfinding, the result of the replication attempt, or both, are\nbiased—though see John Norton’s (ms., ch. 3—see\nOther Internet Resources) arguments that the evidential value of\n(failed) replications crucially depends on researchers’ material\nbackground assumptions. \nWhen replication failures in a discipline are particularly\nsignificant, one may conclude that the published literature lacks\nobjectivity—at a minimum the discipline fails to inspire trust\nthat its findings are more than artefacts of the researchers’\nefforts. Conversely, when observed effects can be replicated in\nfollow-up experiments, a kind of objectivity is reached that goes\nbeyond the ideas of freedom from personal bias, mechanical\nobjectivity, and subject-independent measurement, discussed in\n section 4.1. \nFreese and Peterson (2018) call this idea statistical\nobjectivity. It grounds in the view that even the most\nscrupulous and diligent researchers cannot achieve full objectivity\nall by themselves. The term “objectivity” instead applies\nto a collection or population of studies, with\nmeta-analysis (a formal method for aggregating the\nresults from ranges of studies) as the “apex of\nobjectivity” (Freese and Peterson 2018, 304; see also Stegenga\n2011, 2018). In particular, aggregating studies from different\nresearchers may provide evidence of systematic bias and questionable\nresearch practices (QRP) in the published literature. This diagnostic\nfunction of meta-analysis for detecting violations of objectivity is\nenhanced by statistical techniques such as the funnel plot and the\n\\(p\\)-curve (Simonsohn et al. 2014). \nApart from this epistemic dimension, research on statistical\nobjectivity also has an activist dimension: methodologists urge\nresearchers to make publicly available essential parts of their\nresearch before the data analysis starts, and to make their methods\nand data sources more transparent. For example, it is conjectured that\nthe replicability (and thus objectivity) of science will increase by\nmaking all data available online, by preregistering experiments, and\nby using the registered reports model for journal articles (i.e., the\njournal decides on publication before data collection on the basis of\nthe significance of the proposed research as well as the experimental\ndesign). The idea is that transparency about the data set and the\nexperimental design will make it easier to stage a replication of an\nexperiment and to assess its methodological quality. Moreover,\npublicly committing to a data analysis plan beforehand will lower the\nrate of QRPs and of attempts to accommodate data to\nhypotheses rather than making proper predictions. \nAll in all, statistical objectivity moves the discussion of\nobjectivity to the level of population of studies. There, it takes up\nand modifies several conceptions of objectivity that we have seen\nbefore: most prominently, freedom of subjective bias, which is\nreplaced with collective bias and pernicious conventions, and the\nsubject-independent measurement of a physical quantity, which is\nreplaced by reproducibility of effects. \nTraditional notions of objectivity as faithfulness to facts or freedom\nof contextual values have also been challenged from a feminist\nperspective. These critiques can be grouped in three major research\nprograms: feminist epistemology, feminist standpoint theory and\nfeminist postmodernism (Crasnow 2013). The program of feminist\nepistemology explores the impact of sex and gender on the\nproduction of scientific knowledge. More precisely, feminist\nepistemology highlights the epistemic risks resulting from the\nsystematic exclusion of women from the ranks of scientists, and the\nneglect of women as objects of study. Prominent case studies are the\nneglect of female orgasm in biology, testing medical drugs on male\nparticipants only, focusing on male specimen when studying the social\nbehavior of primates, and explaining human mating patterns by means of\nimaginary neolithic societies (e.g., Hrdy 1977; Lloyd 1993, 2005). See\nalso the\n entry on feminist philosophy of biology. \nOften but not always, feminist epistemologists go beyond pointing out\nwhat they regard as androcentric bias and reject the value-free ideal\naltogether—with an eye on the social and moral responsibility of\nscientific inquiry. They try to show that a value-laden science can\nalso meet important criteria for being epistemically reliable and\nobjective (e.g., Anderson 2004; Kourany 2010). A classical\nrepresentative of such efforts is Longino’s (1990)\ncontextual empiricism. She reinforces Popper’s\ninsistence that “the objectivity of scientific statements lies\nin the fact that they can be inter-subjectively tested” (1934\n[2002]: 22), but unlike Popper, she conceives scientific knowledge\nessentially as a social product. Thus, our conception of scientific\nobjectivity must directly engage with the social process that\ngenerates knowledge. Longino assigns a crucial function to social\nsystems of criticism in securing the epistemic success of science.\nSpecifically, she develops an epistemology which regards a method of\ninquiry as “objective to the degree that it permits\ntransformative criticism” (Longino 1990: 76).\nFor an epistemic community to achieve transformative criticism, there\nmust be: \navenues for criticism: criticism is an essential part\nof scientific institutions (e.g., peer review); \nshared standards: the community must share a set of\ncognitive values for assessing theories (more on this in\n section 3.1); \nuptake of criticism: criticism must be able to\ntransform scientific practice in the long run; \nequality of intellectual authority: intellectual\nauthority must be shared equally among qualified practitioners. \nLongino’s contextual empiricism can be understood as a\ndevelopment of John Stuart Mill’s view that beliefs should never\nbe suppressed, independently of whether they are true or false. Even\nthe most implausible beliefs might be true, and even if they are\nfalse, they might contain a grain of truth which is worth preserving\nor helps to better articulate true beliefs (Mill 1859 [2003: 72]). The\nunderlying intuition is supported by recent empirical research on the\nepistemic benefits of a diversity of opinions and perspectives (Page\n2007). By stressing the social nature of scientific knowledge, and the\nimportance of criticism (e.g., with respect to potential androcentric\nbias and inclusive practice), Longino’s account fits into the\nbroader project of feminist epistemology. \nStandpoint theory undertakes a more radical attack on\ntraditional scientific objectivity. This view develops Marxist ideas\nto the effect that epistemic position is related to, and a product of,\nsocial position. Feminist standpoint theory builds on these ideas but\nfocuses on gender, racial and other social relations. Feminist\nstandpoint theorists and proponents of “situated\nknowledge” such as Donna Haraway (1988), Sandra Harding\n(1991, 2015a, 2015b) and Alison Wylie (2003) deny the internal\ncoherence of a view from nowhere: all human knowledge is at base\nhuman knowledge and therefore necessarily perspectival. But\nthey argue more than that. Not only is perspectivality the human\ncondition, it is also a good thing to have. This is because\nperspectives, especially the perspectives of underprivileged classes\nand groups in society, come along with epistemic benefits. These ideas\nare controversial but they draw attention to the possibility that\nattempts to rid science of perspectives might not only be futile but\nalso costly: they prevent scientists from having the epistemic\nbenefits certain standpoints afford and from developing knowledge\nfor marginalized groups in society. The perspectival stance\ncan also explain why criteria for objectivity often vary with context:\nthe relative importance of epistemic virtues is a matter of goals and\ninterests—in other words, standpoint. \nBy endorsing a perspectival stance, feminist standpoint theory rejects\nclassical elements of scientific objectivity such as neutrality and\nimpartiality (see\n section 3.1\n above). This is a notable difference to feminist epistemology, which\nis in principle (though not always in practice) compatible with\ntraditional views of objectivity. Feminist standpoint theory is also a\npolitical project. For example, Harding (1991, 1993) demands that\nscientists, their communities and their practices—in other\nwords, the ways through which knowledge is gained—be\ninvestigated as rigorously as the object of knowledge itself. This\nidea she refers to as “strong\nobjectivity” replaces the “weak” conception\nof objectivity in the empiricist tradition: value-freedom,\nimpartiality, rigorous adherence to methods of testing and inference.\nLike Feyerabend, Harding integrates a transformation of epistemic\nstandards in science into a broader political project of rendering\nscience more democratic and inclusive. On the other hand, she is\nexposed to similar objections (see also Haack 2003). Isn’t it\ngrossly exaggerated to identify class, race and gender as important\nfactors in the construction of physical theories? Doesn’t the\nfeminist approach—like social constructivist\napproaches—lose sight of the particular epistemic qualities of\nscience? Should non-scientists really have as much authority as\ntrained scientists? To whom does the condition of equally shared\nintellectual authority apply? Nor is it clear—especially in\ntimes of fake news and filter bubbles—whether it is always a\ngood idea to subject scientific results to democratic approval. There\nis no guarantee (arguably there are few good reasons to believe) that\ndemocratized or standpoint-based science leads to more reliable\ntheories, or better decisions for society as a whole. \nSo far everything we discussed was meant to apply across all or at\nleast most of the sciences. In this section we will look at a number\nof specific issues that arise in the social sciences, in economics,\nand in evidence-based medicine. \nThere is a long tradition in the philosophy of social science\nmaintaining that there is a gulf in terms of both goals as well as\nmethods between the natural and the social sciences. This tradition,\nassociated with thinkers such as the neo-Kantians Heinrich Rickert and\nWilhelm Windelband, the hermeneuticist Wilhelm Dilthey, the\nsociologist-economist Max Weber, and the twentieth-century\nhermeneuticists Hans-Georg Gadamer and Michael Oakeshott, holds that\nunlike the natural sciences whose aim it is to establish natural laws\nand which proceed by experimentation and causal analysis, the social\nsciences seek understanding (“Verstehen”) of\nsocial phenomena, the interpretive examination of the meanings\nindividuals attribute to their actions (Weber 1904 [1949]; Weber 1917\n[1949]; Dilthey 1910 [1986]; Windelband 1915; Rickert 1929; Oakeshott\n1933; Gadamer 1960 [1989]). See also the entries on\n hermeneutics\n and\n Max Weber. \nUnderstood this way, social science lacks objectivity in more than one\nsense. One of the more important debates concerning objectivity in the\nsocial sciences concerns the role value judgments play and,\nimportantly, whether value-laden research entails claims about the\ndesirability of actions. Max Weber held that the social sciences are\nnecessarily value laden. However, they can achieve some degree of\nobjectivity by keeping out the social researcher’s views about\nwhether agents’ goals are commendable. In a similar vein,\ncontemporary economics can be said to be value laden because it\npredicts and explains social phenomena on the basis of agents’\npreferences. Nevertheless, economists are adamant that economists are\nnot in the business of telling people what they ought to value. Modern\neconomics is thus said to be objective in the Weberian sense of\n“absence of researchers’\nvalues”—a conception that we discussed in detail\nin\n section 3. \nIn his widely cited essay “‘Objectivity’ in Social\nScience and Social Policy” (Weber 1904 [1949]), Weber argued\nthat the idea of an aperspectival social science was meaningless: \nThere is no absolutely objective scientific analysis of […]\n“social phenomena” independent of special and\n“one-sided” viewpoints according to which expressly or\ntacitly, consciously or unconsciously they are selected, analyzed and\norganized for expository purposes. (1904 [1949: 72]) \nAll knowledge of cultural reality, as may be seen, is always knowledge\nfrom particular points of view. (1904 [1949:. 81]) \nThe reason for this is twofold. First, social reality is too complex\nto admit of full description and explanation. So we have to select.\nBut, perhaps in contraposition to the natural sciences, we cannot just\nselect those aspects of the phenomena that fall under universal\nnatural laws and treat everything else as “unintegrated\nresidues” (1904 [1949: 73]). This is because, second, in the\nsocial sciences we want to understand social phenomena in their\nindividuality, that is, in their unique configurations that have\nsignificance for us. \nValues solve a selection problem. They tell us what research questions\nwe ought to address because they inform us about the cultural\nimportance of social phenomena: \nOnly a small portion of existing concrete reality is colored by our\nvalue-conditioned interest and it alone is significant to us. It is\nsignificant because it reveals relationships which are important to\nuse due to their connection with our values. (1904 [1949: 76]) \nIt is important to note that Weber did not think that social and\nnatural science were different in kind, as Dilthey and others did.\nSocial science too examines the causes of phenomena of interest, and\nnatural science too often seeks to explain natural phenomena in their\nindividual constellations. The role of causal laws is different in the\ntwo fields, however. Whereas establishing a causal law is often an end\nin itself in the natural sciences, in the social sciences laws play an\nattenuated and accompanying role as mere means to explain cultural\nphenomena in their uniqueness. \nNevertheless, for Weber social science remains objective in at least\ntwo ways. First, once research questions of interest have been\nsettled, answers about the causes of culturally significant phenomena\ndo not depend on the idiosyncrasies of an individual researcher: \nBut it obviously does not follow from this that research in the\ncultural sciences can only have results which are\n“subjective” in the sense that they are valid for one\nperson and not for others. […] For scientific truth is\nprecisely what is valid for all who seek the truth. (Weber 1904 [1949:\n84], emphasis original) \nThe claims of social science can therefore be objective in our third\nsense\n (see section 4).\n Moreover, by determining that a given phenomenon is “culturally\nsignificant” a researcher reflects on whether or not a practice\nis “meaningful” or “important”, and not\nwhether or not it is commendable: “Prostitution is a cultural\nphenomenon just as much as religion or money” (1904 [1949: 81]).\nAn important implication of this view came to the fore in the\nso-called “Werturteilsstreit” (quarrel concerning\nvalue judgments) of the early 1900s. In this debate, Weber maintained\nagainst the “socialists of the lectern” around Gustav\nSchmoller the position that social scientists qua scientists should\nnot be directly involved in policy debates because it was not the aim\nof science to examine the appropriateness of ends. Given a policy\ngoal, a social scientist could make recommendations about effective\nstrategies to reach the goal; but social science was to be value-free\nin the sense of not taking a stance on the desirability of the goals\nthemselves. This leads us to our conception of objectivity as freedom\nfrom value judgments. \nContemporary mainstream economists hold a view concerning objectivity\nthat mirrors Max Weber’s (see above). On the one hand, it is\nclear that value judgments are at the heart of economic theorizing.\n“Preferences” are a key concept of rational choice theory,\nthe main theory in contemporary mainstream economics. Preferences are\nevaluations. If an individual prefers \\(A\\) to \\(B\\), she\nvalues \\(A\\) higher than \\(B\\) (Hausman 2012). Thus, to the\nextent that economists predict and explain market behavior in terms of\nrational choice theory, they predict and explain market behavior in a\nway laden with value judgments. \nHowever, economists are not themselves supposed to take a stance about\nwhether or not whatever individuals value is also\n“objectively” good in a stronger sense: \n[…] that an agent is rational from [rational choice\ntheory]’s point of view does not mean that the course of action\nshe will choose is objectively optimal. Desires do not have to align\nwith any objective measure of “goodness”: I may want to\nrisk swimming in a crocodile-infested lake; I may desire to smoke or\ndrink even though I know it harms me. Optimality is determined by the\nagent’s desires, not the converse. (Paternotte 2011:\n307–8) \nIn a similar vein, Gul and Pesendorfer write: \nHowever, standard economics has no therapeutic ambition, i.e., it does\nnot try to evaluate or improve the individual’s objectives.\nEconomics cannot distinguish between choices that maximize happiness,\nchoices that reflect a sense of duty, or choices that are the response\nto some impulse. Moreover, standard economics takes no position on the\nquestion of which of those objectives the agent should pursue. (Gul\nand Pesendorfer 2008: 8) \nAccording to the standard view, all that rational choice theory\ndemands is that people’s preferences are (internally)\nconsistent; it has no business in telling people what they ought to\nprefer, whether their preferences are consistent with external norms\nor values. Economics is thus value-laden, but laden with the values of\nthe agents whose behavior it seeks to predict and explain and not with\nthe values of those who seek to predict and explain this behavior. \nWhether or not social science, and economics in particular, can be\nobjective in this—Weber’s and the contemporary\neconomists’—sense is controversial. On the one hand, there\nare some reasons to believe that rational choice theory (which is at\nwork not only in economics but also in political science and other\nsocial sciences) cannot be applied to empirical phenomena without\nreferring to external norms or values (Sen 1993; Reiss 2013). \nOn the other hand, it is not clear that economists and other social\nscientists qua social scientists shouldn’t participate in a\ndebate about social goals. For one thing, trying to do welfare\nanalysis in the standard Weberian way tends to obscure rather than to\neliminate normative commitments (Putnam and Walsh 2007). Obscuring\nvalue judgments can be detrimental to the social scientist as policy\nadviser because it will hamper rather than promote trust in social\nscience. For another, economists are in a prime position to contribute\nto ethical debates, for a variety of reasons, and should therefore\ntake this responsibility seriously (Atkinson 2001). \nThe same demands calling for “mechanical objectivity” in\nthe natural sciences and quantification in the social and policy\nsciences in the nineteenth century and mid-twentieth century are\nresponsible for a recent movement in biomedical research, which, even\nmore recently, have swept to contemporary social science and policy.\nEarly proponents of so-called “evidence-based medicine”\nmade their pursuit of a downplay of the “human element” in\nmedicine plain: \nEvidence-based medicine de-emphasizes intuition, unsystematic clinical\nexperience, and pathophysiological rationale as sufficient grounds for\nclinical decision making and stresses the examination of evidence from\nclinical research. (Guyatt et al. 1992: 2420) \nTo call the new movement “evidence-based” is a misnomer\nstrictly speaking, as intuition, clinical experience and\npathophysiological rationale can certainly constitute evidence. But\nproponents of evidence-based practices have a much narrower concept of\nevidence in mind: analyses of the results of randomized controlled\ntrials (RCTs). This movement is now very strong in biomedical\nresearch, development economics and a number of areas of social\nscience, especially psychology, education and social policy, and\nespecially in the English speaking world. \nThe goal is to replace subjective (biased, error-prone, idiosyncratic)\njudgments by mechanically objective methods. But, as in other areas,\nattempting to mechanize inquiry can lead to reduced accuracy and\nutility of the results. \nCausal relations in the social and biomedical sciences hold on account\nof highly complex arrangements of factors and conditions. Whether for\ninstance a substance is toxic depends on details of the metabolic\nsystem of the population ingesting it, and whether an educational\npolicy is effective on the constellation of factors that affect the\nstudents’ learning progress. If an RCT was conducted\nsuccessfully, the conclusion about the effectiveness of the treatment\n(or toxicity of a substance) under test is certain for the particular\narrangement of factors and conditions of the trial (Cartwright 2007).\nBut unlike the RCT itself, many of whose aspects can be (relatively)\nmechanically implemented, applying the result to a new setting\n(recommending a treatment to a patient, for instance) always involves\nsubjective judgments of the kind proponents of evidence-based\npractices seek to avoid—such as judgments about the similarity\nof the test to the target or policy population. \nOn the other hand, RCTs can be regarded as “debiasing\nprocedure” because they prevent researchers from allocating\ntreatments to patients according to their personal interests, so that\nthe healthiest (or smartest or…) subjects get the\nresearcher’s favorite therapy. While unbalanced allocations can\ncertainly happen by chance, randomization still provides some warrant\nthat the allocation was not done on purpose with a view to\npromoting somebody’s interests. A priori, the\nexperimental procedure is thus more impartial with respect to the\ninterests at stake. It has thus been argued that RCTs in medicine,\nwhile no guarantor of the best outcomes, were adopted by the U.S. Food\nand Drugs Administration (FDA) to different degrees during the 1960s\nand 1970s in order to regain public trust in its decisions about\ntreatments, which it had lost due to the thalidomide and other\nscandals (Teira and Reiss 2013; Teira 2010). It is important to\nnotice, however, that randomization is at best effective with respect\nto one kind of bias, viz. selection bias. Important other epistemic\nconcerns are not addressed by the procedure but should not be ignored\n(Worrall 2002). \nIn sections 2–5, we have encountered various concepts of\nscientific objectivity and their limitations. This prompts the\nquestion of how unified (or disunified) scientific objectivity is as a\nconcept: Is there something substantive shared by all of these\nanalyses? Or is objectivity, as Heather Douglas (2004) puts it, an\n“irreducibly complex” concept? \nDouglas defends pluralism about scientific\nobjectivity and distinguishes three areas of application of\nthe concept: (1) interaction of humans with the world, (2) individual\nreasoning processes, (3) social processes in science. Within each\narea, there are various distinct senses which are again irreducible to\neach other and do not have a common core meaning. This does not mean\nthat the senses are unrelated; they share a complex web of\nrelationships and can also support each other—for example,\neliminating values from reasoning may help to achieve procedural\nobjectivity. For Douglas, reducing objectivity to a single core\nmeaning would be a simplification without benefits; instead of a\ncomplex web of relations between different senses of objectivity we\nwould obtain an impoverished concept out of touch with scientific\npractice. Similar arguments and pluralist accounts can be found in\nMegill (1994), Janack (2002) and Padovani et al. (2015)—see also\nAxtell (2016). \nIt has been argued, however, that pluralist approaches give up too\nquickly on the idea that the different senses of objectivity share one\nor several important common elements. As we have seen in section\n 4.1\n and\n 5.1,\n scientific objectivity and trust in science are\nclosely connected. Scientific objectivity is desirable because to the\nextent that science is objective we have reasons trust scientists,\ntheir results and recommendations (cf. Fine 1998: 18). Thus, perhaps\nwhat is unifying among the difference senses of objectivity is that\neach sense describes a feature of scientific practice that is able to\ninspire trust in science. \nBuilding on this idea, Inkeri Koskinen has recently argued that it is\nin fact not trust but reliance that we are after (Koskinen\nforthcoming). Trust is something that can be betrayed, but only\nindividuals can betray whereas objectivity pertains to institutions,\npractices, results, etc. We call scientific institutions, practices,\nresults, etc. objective to the extent that we have reasons to rely on\nthem. The analysis does not stop here, however. There is a distinct\nview about objectivity that is behind Daston and Galison’s\nhistorical epistemology of the concept and has been defended by Ian\nHacking: that objectivity is not a—positive—virtue but\nrather the absence of this or that vice (Hacking 2015: 26). Speaking\nof objectivity in imaging, for instance, Daston and Galison write that\nthe goal is to \nlet the specimen appear without that distortion characteristic of the\nobserver’s personal tastes, commitments, or ambitions. (Daston\nand Galison 2007: 121) \nKoskinen picks up this idea of objectivity as absence of\nvice and argues that it is specifically the aversion of\nepistemic risks for which the term is reserved. Epistemic\nrisks comprise “any risk of epistemic error that arises anywhere\nduring knowledge practices’ (Biddle and Kukla 2017: 218) such as\nthe risk of having mistaken beliefs, the risk of errors in reasoning\nand risks related to operationalization, concept formation, and model\nchoice. Koskinen argues that only those epistemic risks that relate to\nfailings of scientists as human beings are relevant to objectivity\n(Koskinen forthcoming: 13): \nFor instance, when the results of an experiment are incorrect because\nof malfunctioning equipment, we do not worry about\nobjectivity—we just say that the results should not be taken\ninto account. [...] So it is only when the epistemic risk is related\nto our own failings, and is hard to avert, that we start talking about\nobjectivity. Illusions, subjectivity, idiosyncrasies, and collective\nbiases are important epistemic risks arising from our imperfections as\nepistemic agents. \nKoskinen understands her account as a response to Hacking’s\n(2015) criticism that we should stop talking about objectivity\naltogether. According to Hacking, “objectivity” is an\n“elevator” or second-level word, similar to\n“true” or “real”—“Instead of\nsaying that the cat is on the mat, we move up one story and and say\nthat it is true that the cat is on the mat” (2015: 20). He\nrecommends to stick to ground-level questions and worry about whether\nspecific sources of error have been controlled. (A similar elimination\nrequest with respect to the labels “objective” and\n“subjective” in statistical inference has been advanced by\nGelman and Hennig (2017).) In focussing on averting specific epistemic\nrisks, Koskinen’s account does precisely that. Koskinen argues\nthat a unified account of objectivity as averting epistemic risks\ntakes into account Hacking’s negative stance and explains at the\nsame time important features of the concept—for example, why\nobjectivity does not imply certainty and why it varies with\ncontext. \nThe strong point of this account is that none of the threats to a\npeculiar analysis puts scientific objectivity at risk. We can (and in\nfact, we do) rely on scientific practices that represent the world\nfrom a perspective and where non-epistemic values affect outcomes and\ndecisions. What is left open by Koskinen’s account is the\nnormative question of what a scientist who cares about her experiments\nand inferences being objective should actually do. That is, the\nphilosophical ideas we have reviewed in this section stay mainly on\nthe descriptive level and do not give an actual guideline for working\nscientists. Connecting the abstract philosophical analysis to\nday-to-day work in science remains an open problem. \nSo is scientific objectivity desirable? Is it attainable? That, as we\nhave seen, depends crucially on how the term is understood. We have\nlooked in detail at four different conceptions of scientific\nobjectivity: faithfulness to facts, value-freedom, freedom from\npersonal biases, and features of community practices. In each case,\nthere are at least some reasons to believe that either science cannot\ndeliver full objectivity in this sense, or that it would not be a good\nthing to try to do so, or both. Does this mean we should give up the\nidea of objectivity in science? \nWe have shown that it is hard to define scientific objectivity in\nterms of a view from nowhere, value freedom, or freedom from personal\nbias. It is a lot harder to say anything positive about the matter.\nPerhaps it is related to a thorough critical attitude concerning\nclaims and findings, as Popper thought. Perhaps it is the fact that\nmany voices are heard, equally respected and subjected to accepted\nstandards, as Longino defends. Perhaps it is something else\naltogether, or a combination of several factors discussed in this\narticle. \nHowever, one should not (as yet) throw out the baby with the\nbathwater. Like those who defend a particular explication of\nscientific objectivity, the critics struggle to explain what makes\nscience objective, trustworthy and special. For instance, our\ndiscussion of the value-free ideal (VFI) revealed that alternatives to\nthe VFI are as least as problematic as the VFI itself, and that the\nVFI may, with all its inadequacies, still be a useful heuristic for\nfostering scientific integrity and objectivity. Similarly, although\nentirely “unbiased” scientific procedures may be\nimpossible, there are many mechanisms scientists can adopt for\nprotecting their reasoning against undesirable forms of bias, e.g.,\nchoosing an appropriate method of statistical inference, being\ntransparent about different stages of the research process and\navoiding certain questionable research practices. \nWhatever it is, it should come as no surprise that finding a positive\ncharacterization of what makes science objective is hard. If we knew\nan answer, we would have done no less than solve the problem of\ninduction (because we would know what procedures or forms of\norganization are responsible for the success of science). Work on this\nproblem is an ongoing project, and so is the quest for understanding\nscientific objectivity.","contact.mail":"jan.sprenger@unito.it","contact.domain":"unito.it"}]
