[{"date.published":"2010-04-21","date.changed":"2018-04-18","url":"https://plato.stanford.edu/entries/boole/","author1":"Stanley Burris","author1.info":"http://www.math.uwaterloo.ca/~snburris/","entry":"boole","body.text":"\n\n\n\nGeorge Boole (1815–1864) was an English mathematician and a\nfounder of the algebraic tradition in logic. He worked as a\nschoolmaster in England and from 1849 until his death as professor of\nmathematics at Queen’s University, Cork, Ireland. He revolutionized\nlogic by applying methods from the then-emerging field of symbolic\nalgebra to logic. Where traditional (Aristotelian) logic relied on\ncataloging the valid syllogisms of various simple forms, Boole’s\nmethod provided general algorithms in an algebraic language which\napplied to an infinite variety of arguments of arbitrary\ncomplexity. These results appeared in two major works,\nThe Mathematical Analysis of Logic (1847)\nand\nThe Laws of Thought (1854).\n\n\n\nGeorge Boole was born November 2, 1815 in Lincoln, Lincolnshire,\nEngland, into a family of modest means, with a father who was\nevidently more of a good companion than a good breadwinner. His father\nwas a shoemaker whose real passion was being a devoted dilettante in\nthe realm of science and technology, one who enjoyed participating in\nthe Lincoln Mechanics’ Institution; this was essentially a community\nsocial club promoting reading, discussions, and lectures regarding\nscience. It was founded in 1833, and in 1834 Boole’s father became the\ncurator of its library. This love of learning was clearly inherited by\nBoole. Without the benefit of an elite schooling, but with a\nsupportive family and access to excellent books, in particular from\nSir Edward Bromhead, FRS, who lived only a few miles from Lincoln,\nBoole was able to essentially teach himself foreign languages and\nadvanced mathematics. \n\nStarting at the age of 16 it was necessary for Boole to find gainful\nemployment, since his father was no longer capable of providing for\nthe family. After 3 years working as a teacher in private schools,\nBoole decided, at the age of 19, to open his own small school in\nLincoln. He would be a schoolmaster for the next 15 years, until 1849\nwhen he became a professor at the newly opened Queen’s University in\nCork, Ireland. With heavy responsibilities for his parents and\nsiblings, it is remarkable that he nonetheless found time during the\nyears as a schoolmaster to continue his own education and to start a\nprogram of research, primarily on differential equations and the\ncalculus of variations connected with the works of Laplace and\nLagrange (which he studied in the original French). \n\nThere is a widespread belief that Boole was primarily a\nlogician—in reality he became a recognized mathematician well\nbefore he had penned a single word about logic, all the while running\nhis private school to care for his parents and siblings. Boole’s\nability to read French, German and Italian put him in a good position\nto start serious mathematical studies when, at the age of 16, he read\nLacroix’s Calcul Différentiel, a gift from his friend\nReverend G.S. Dickson of Lincoln. Seven years later, in 1838, he would\nwrite his first mathematical paper (although not the first to be\npublished), “On certain theorems in the calculus of\nvariations,” focusing on improving results he had read in\nLagrange’s Méchanique Analytique. \n\nIn early 1839 Boole travelled to Cambridge to meet with the young\nmathematician Duncan F. Gregory (1813–1844), the editor\nof the Cambridge Mathematical Journal\n(CMJ)—Gregory had founded this journal in 1837 and\nedited it until his health failed in 1843 (he died in early 1844, at\nthe age of 30). Gregory, though only 2 years beyond his degree in\n1839, became an important mentor to Boole. With Gregory’s support,\nwhich included coaching Boole on how to write a mathematical paper,\nBoole entered the public arena of mathematical publication in\n1841. \n\nBoole’s mathematical publications span the 24 years from 1841 to 1864,\nthe year he died from pneumonia. Breaking these 24 years into three\nsegments, the first 6 years (1841–1846), the \nsecond 8 years (1847–1854), and the last 10 years \n(1855–1864), we find that his published work on \nlogic was entirely in the middle 8 years. \n\nIn his first 6 career years, Boole published 15 mathematical papers,\nall but two in the CMJ and its 1846 successor, The\nCambridge and Dublin Mathematical Journal. He wrote on standard\nmathematical topics, mainly differential equations, integration and the\ncalculus of variations. Boole enjoyed early success in using the new\nsymbolical method in analysis, a method which took a differential\nequation, say: \nand wrote it in the form Operator\\((y) =\\) cos\\((x)\\). \nThis was (formally) achieved by letting: \nleading to an expression of the differential equation as: \n\nNow symbolical algebra came into play by simply treating the operator\n\\(D^2 - D - 2\\) as though it were an ordinary polynomial in\nalgebra. Boole’s 1841 paper “On the integration of linear\ndifferential equations with constant coefficients” gave a nice\nimprovement to Gregory’s method for solving such differential\nequations, an improvement based on a standard tool in algebra, the use\nof partial fractions. \n\nIn 1841 Boole also published his first paper on invariants, a paper\nthat would strongly influence Eisenstein, Cayley, and Sylvester to\ndevelop the subject. Arthur Cayley (1821–1895), the future\nSadlerian Professor in Cambridge and one of the most prolific\nmathematicians in history, wrote his first letter to Boole in 1844,\ncomplimenting him on his excellent work on invariants. He became a\nclose personal friend, one who would go to Lincoln to visit and stay\nwith Boole in the years before Boole moved to Cork, Ireland. In 1842\nBoole started a correspondence with Augustus De Morgan\n(1806–1871) that initiated another lifetime friendship. \n\nIn 1843 the schoolmaster Boole finished a lengthy paper on\ndifferential equations, combining an exponential substitution and\nvariation of parameters with the separation of symbols method. The\npaper was too long for the CMJ—Gregory, and later De\nMorgan, encouraged him to submit it to the Royal Society. The first\nreferee rejected Boole’s paper, but the second recommended it for the\nGold Medal for the best mathematical paper written in the years\n1841–1844, and this recommendation was accepted. In 1844 the\nRoyal Society published Boole’s paper and awarded him the Gold \nMedal—the first Gold Medal awarded by the Society to a mathematician.\nThe next year Boole read a paper at the annual meeting of the British\nAssociation for the Advancement of Science at Cambridge in June 1845.\nThis led to new contacts and friends, in particular William Thomson\n(1824–1907), the future Lord Kelvin. \n\nNot long after starting to publish papers, Boole was eager to\nfind a way to become affiliated with an institution of higher learning.\nHe considered attending Cambridge University to obtain a degree, but\nwas counselled that fulfilling the various requirements would likely\nseriously interfere with his research program, not to mention the\nproblems of obtaining financing. Finally, in 1849, he obtained a\nprofessorship in a new university opening in Cork, Ireland. In the\nyears he was a professor in Cork (1849–1864) he would\noccasionally inquire about the possibility of a position back in\nEngland. \n\nThe 8 year stretch from 1847 to 1854 starts and ends with Boole’s\ntwo books on mathematical logic. In addition Boole published 24 more\npapers on traditional mathematics during this period, while only one\npaper was written on logic, that being in 1848. He was awarded an\nhonorary LL.D. degree by the University of Dublin in 1851, and this was\nthe title that he used beside his name in his 1854 book on logic.\nBoole’s 1847 book, Mathematical Analysis of Logic, will be\nreferred to as MAL; the 1854 book, Laws of Thought,\nas LT. \n\nDuring the last 10 years of his career, from 1855 to 1864, Boole\npublished 17 papers on mathematics and two mathematics books, one on\ndifferential equations and one on difference equations. Both books were\nhighly regarded, and used for instruction at Cambridge. Also\nduring this time significant honors came in: \n\nUnfortunately his keen sense of duty led to his walking through a\nrainstorm in late 1864, and then lecturing in wet clothes. Not long\nafterwards, on December 8, 1864 in Ballintemple, County Cork, Ireland,\nhe died of pneumonia, at the age of 49. Another paper on mathematics\nand a revised book on differential equations, giving considerable\nattention to singular solutions, were published post mortem. \n\nThe reader interested in an excellent and thorough account of\nBoole’s personal life is referred to Desmond MacHale’s George\nBoole, His Life and Work, 1985/2014, a source to which this article is\nindebted. \n\nTo understand how Boole developed, in such a short time, his\nimpressive algebra of logic, it is useful to understand the broad\noutlines of the work on the foundations of algebra that had been\nundertaken by mathematicians affiliated with Cambridge University in\nthe 1800s prior to the beginning of Boole’s mathematical publishing\ncareer. An excellent reference for further reading connected to this\nsection is the annotated sourcebook From Kant to Hilbert,\n1996, by William Ewald, which contains a complete copy of Boole’s\nMathematical Analysis of Logic.\n \n\nThe 19th century opened in England with mathematics in the doldrums.\nThe English mathematicians had feuded with the continental\nmathematicians over the issues of priority in the development of the\ncalculus, resulting in the English following Newton’s notation, and\nthose on the continent following that of Leibniz. One of the obstacles\nto overcome in updating English mathematics was the fact that the great\ndevelopments of algebra and analysis had been built on dubious\nfoundations, and there were English mathematicians who were quite vocal\nabout these shortcomings. In ordinary algebra, it was the use of\nnegative numbers and imaginary numbers that caused concern. \n \n\nThe first major attempt among the English to clear up the foundation\nproblems of algebra was the Treatise on Algebra, 1830, by\nGeorge Peacock (1791–1858). A second edition appeared as two\nvolumes, 1842/1845. He divided the subject into two parts, the first\npart being arithmetical algebra, the algebra of the positive\nnumbers (which did not permit operations like subtraction in cases\nwhere the answer would not be a positive number). The second part was\nsymbolical algebra, which was governed not by a specific\ninterpretation, as was the case for arithmetical algebra, but solely\nby laws. In symbolical algebra there were no restrictions on using\nsubtraction, etc. \n\nThe terminology of algebra was somewhat different in the 19th century\nfrom what is used today. In particular they did not use the word\n“variable”; the letter \\(x\\) in an expression like\n\\(2x + 5\\) was called a symbol, hence the name\n“symbolical algebra”. In this article a prefix will\nsometimes be added, as in number symbol or class\nsymbol, to emphasize the intended interpretation of a symbol. \n\nPeacock believed that in order for symbolical algebra to be a useful\nsubject its laws had to be closely related to those of arithmetical\nalgebra. In this connection he introduced his principle of the\npermanence of equivalent forms, a principle connecting results in\narithmetical algebra to those in symbolical algebra. This principle has\ntwo parts: \n\nA fascinating use of algebra was introduced in 1814 by\nFrançois-Joseph Servois (1776–1847) when he tackled\ndifferential equations by separating the differential operator part\nfrom the subject function part, as described in an example given\nabove. This application of algebra captured the interest of Gregory\nwho published a number of papers on the method of the separation\nof symbols, that is, the separation into operators and objects,\nin the CMJ. He also wrote on the foundation of algebra, and\nit was Gregory’s foundation that Boole embraced, almost verbatim.\nGregory had abandoned Peacock’s principle of the permanence of\nequivalent forms in favor of three simple laws, one of which Boole\nregarded as merely a notation convention. Unfortunately these laws\nfell far short of what is required to justify even some of the most\nelementary results in algebra, like those involving subtraction.\n \n\nIn “On the foundation of \nalgebra,” 1839, the first of four papers on this \ntopic by De Morgan that appeared in the Transactions of the Cambridge\nPhilosophical Society, one finds a tribute to the separation of\nsymbols in algebra, and the claim that modern algebraists usually\nregard the symbols as denoting operators (e.g., the derivative\noperation) instead of objects like numbers. The footnote: \nBoole’s path to logic fame started in a curious way. In early 1847 he\nwas stimulated to launch his investigations into logic by a trivial\nbut very public dispute between De Morgan and the Scottish philosopher\nSir William Hamilton (1788–1856)—not to be confused with\nhis contemporary the Irish mathematician Sir William Rowan Hamilton\n(1805–1865). This dispute revolved around who deserved credit\nfor the idea of quantifying the predicate (e.g., “All \\(A\\)\nis all \\(B\\),” “All \\(A\\) is some\n\\(B\\),” etc.). Within a few months Boole had written his\n82 page monograph, Mathematical Analysis of Logic, giving an\nalgebraic approach to Aristotelian logic, then looking briefly at the\ngeneral theory. (Some say that this monograph and De Morgan’s book\nFormal Logic appeared on the same day in November 1847.) \n\nAlthough Boole’s algebra of logic is not the Boolean algebra of power\nsets \\(P(U)\\) with the operations of union, intersection\nand complement, nonetheless the goal of the two algebras is the same,\nnamely to provide an equational logic for the calculus of classes and\npropositional logic. The name “Boolean algebra” was\nintroduced by Charles Sanders Peirce (1839–1914) and adopted by\nhis friend, the Harvard philosopher Josiah Royce (1855–1916)\naround 1900, then by Royce’s students and other Harvard\nmathematicians, and eventually the world. It essentially referred to\nthe modern version of the algebra of logic, introduced in 1864 by\nWilliam Stanley Jevons (1835–1882), a version that Boole had\nrejected in their correspondence—see Section 5.1. For this\nreason the word “Boolean” will not be used in this article\nto describe the algebra of logic that Boole actually created; instead\nthe name Boole’s algebra will be used.\n \n\nIn MAL, and more so in LT, Boole was interested in the insights\nthat his algebra of logic gave to the inner workings of the mind. This pursuit\nhas met with little favor, and will not be discussed in this article.\n \n\nIn pages 15–59, a little more than half of the 82 pages in\nMAL, Boole focused on a slight generalization of Aristotelian\nlogic, namely augmenting its four types of categorical propositions by\npermitting the subject and/or predicate to be of the form\nnot-\\(X\\). In the chapter on conversions, such as Conversion by\nLimitation—All \\(X\\) is \\(Y\\), therefore Some \\(Y\\) is\n\\(X\\)—Boole found the Aristotelian classification defective in\nthat it did not treat contraries, such as not-\\(X\\), on the same\nfooting as the named classes \\(X, Y, Z\\), etc. For example, he wanted\nto be able to convert “No \\(X\\) is \\(Y\\)” into “All\n\\(Y\\) is not-\\(X\\)”. (MAL, p. 28)\n \n\nWith his extended version of Aristotelian logic in mind (where\ncontraries enjoy equal billing), he gave (MAL, p. 30) a set\nof three transformation rules which allowed one to construct all valid\ntwo-line categorical arguments (providing you accepted the unwritten\nconvention that simple names like \\(X\\), and perhaps\nnot-\\(X\\), denoted non-empty classes). \nRegarding syllogisms, Boole did not care for the Aristotelian\nclassification into Figures and Moods as it seemed rather arbitrary\n(and not well-suited to the algebraic setting). In particular he\ndid not like the requirement that the predicate of the conclusion \nhad to be the major term in the premises.  \nIt is somewhat\ncurious that when it came to analyzing categorical syllogisms, it was only\nin the conclusion that he permitted his generalized categorical propositions\nto appear.\nAmong the vast possibilities for hypothetical syllogisms, the ones \n that he discussed were standard, with one new example added. \n\nThe “Introduction” chapter starts with Boole reviewing the\nsymbolical method. The second chapter, “First\nPrinciples”, lets the symbol 1 represent the universe which\n“comprehends every conceivable class of objects, whether\nexisting or not.” Capital letters \\(X, Y,\nZ,\\ldots\\) denoted classes. Then, no doubt heavily\ninfluenced by his very successful work using algebraic techniques on\ndifferential operators, and consistent with De Morgan’s 1839 assertion\nthat algebraists preferred interpreting symbols as operators, Boole\nintroduced the elective symbol \\(x\\) corresponding to the class\n\\(X\\), the elective symbol \\(y\\) corresponding to\n\\(Y\\), etc. The elective symbols denoted elective\noperators—for example the elective operator “red”\nwhen applied to a class would elect (select) the red items in the\nclass. (One can simply replace the elective symbols by their\ncorresponding class symbols and have the interpretation used in\nLT in 1854.) \nThe first operation Boole introduced was the multiplication\n\\(xy\\) of elective symbols. The standard notation\n\\(xy\\) for multiplication also had a standard meaning\nfor operators (for example, differential operators), namely one\napplied \\(y\\) to an object and then \\(x\\) is applied to the\nresult. (In modern terminology, this is the composition of\nthe two operators.) Thus, as pointed out by Theodore Hailperin\n(1916—2014) in his insightful book (1976/1986) on MAL\nand LT, it seems likely that this established notation\nconvention handed Boole his interpretation of the multiplication of\nelective symbols as composition of operators. \n \nWhen one switches to using classes instead of elective operators, as\nin LT, the corresponding multiplication of two classes\nresults in their intersection—that is, one has \\(xy = z\\) if and\nonly if \\(XY = Z\\), where \\(XY\\) is the intersection of \\(X\\) and\n\\(Y\\).  \nThe first law in MAL was the distributive law \n\nwhere Boole said that \\(u+v\\) corresponded to dividing\na class into two parts. This was the first mention of addition in MAL.\nFrom LT one can determine the proper interpretation of the addition of \nelective operators in \nMAL: \n\\((x + y)(Z)\\) is the union of \\(x(Z)\\) and \\(y(Z)\\) provided \\(X\\)\nand \\(Y\\) are disjoint classes; otherwise \\(x + y\\) is not defined.\n \nThus addition is a partial operation on elective operators. \nLikewise one finds that subtraction is defined by: \n\\((x - y)(Z)\\) is \\(x(Z) \\smallsetminus y(Z)\\) provided \\(Y\\) is contained\nin \\(X\\); otherwise \\(x - y\\) is not defined. \nThus subtraction is also a partial operation on elective operators.\n \n\nBoole added (MAL, p. 17) the commutative law \\(xy =\nyx\\) and the index law \\(x^n = x\\)—in LT the\nlatter would be replaced by the law of duality \\(x^2 = x\\)\n(called the idempotent law in 1870 by the Harvard\nmathematician Benjamin Peirce (1809–1880), in another\ncontext). \nAfter stating the above distributive and commutative laws, Boole\nbelieved he was entitled to fully employ the ordinary algebra of his\ntime, saying (MAL, p. 18) that \nand indeed in addition to the usual algebra of polynomials one sees\npower series and Lagrange multipliers in MAL.  Boole went beyond the foundations of symbolical algebra that\nGregory had used in 1840—he added De Morgan’s 1841 single\nrule of inference, that equivalent operations performed upon\nequivalent subjects produce equivalent results.  It is likely more difficult for the modern reader to come to grips\nwith the idea that Boole’s algebra is based on ordinary algebra than\nwould have been the case with Boole’s contemporaries—the modern\nreader has been exposed to modern Boolean algebra (and perhaps Boolean\nrings). In the mid 1800s the word “algebra” meant, for\nmost mathematicians, simply the algebra of numbers. Boole’s algebra\nwas mainly concerned with polynomials with integer coefficients, and\nwith their values when the variables were restricted to taking on only\nthe values 0 and 1. To put the reader in the proper frame of mind,\nsome of the key polynomials in Boole’s work, along with their values\non \\(\\{0,1\\}\\), are presented in the following table: \n\nNote that all of the polynomials \\(p\\)(x,y) in the above\ntable, except for addition and subtraction, take values in \\(\\{0,1\\}\\) when\nthe variables take values in \\(\\{0,1\\}\\). Such polynomials are called\nswitching functions in computer science and electrical\nengineering, and as functions on \\(\\{0,1\\}\\) they are idempotent, that is,\n p\\(^2 =\\) p. The switching functions are exactly\nthe idempotent polynomials in Boole’s algebra. \n\nBoole’s three laws for his algebra of logic are woefully inadequate\nfor what follows in MAL. The reader will, for the most part,\nbe well served by assuming that Boole is doing ordinary polynomial\nalgebra augmented by the assumption that any power\n\\(x^n\\) of an elective symbol \\(x\\) can\nbe replaced by \\(x\\). Indeed one can safely assume that any\npolynomial equation p = q that holds in the integers is valid\nin Boole’s algebra. Also any equational argument \nthat holds in the integers is valid in Boole’s algebra. [A\nnote of caution: the argument “\\(x^2 = x \\therefore x = 1\\) or\n\\(x = 0\\)” is valid in the integers, but it is not an\nequational argument since the conclusion is a disjunction of\nequations, not a single equation.] \n\nIn Boole’s algebra, any polynomial \\(p(x)\\)\nin one variable can be reduced to a linear polynomial \\(ax + b\\)\nsince one has \nLikewise any polynomial \\(p(x, y)\\) can be expressed as \\(axy + bx +\ncy + d\\). Etc. \n\nHowever Boole was much more interested in the fact that \\(ax + b\\)\ncan be written as a linear combination of \\(x\\) and \\(1-x\\), namely \nThis gives his Expansion Theorem in one variable: \nThe Expansion Theorem for polynomials in two variables is For example, \nThe expressions \\(xy, \\ldots, (1 - x)(1 - y)\\), are called\nthe constituents of \\(p(x,y)\\)—it would be better to\ncall them the constituents of the variables \\(x, y\\)—and the\ncoefficients \\(p(1,1), \\ldots, p(0,0)\\) are the modulii of\n\\(p(x,y)\\). \n\nSimilar results hold for polynomials in any number of variables\n(MAL, pp. 62–64). In Boole’s algebra there are three\nimportant facts about the constituents for a given list of\nvariables: \n\nThe index law, \\(x^n = x\\), was different from Boole’s two\nfundamental laws for the common algebra—it only applied to the\nindividual elective symbols, not in general to compound terms that one\ncould build from these symbols.  For example, one does not in general\nhave \\((x + y)^2 = x + y\\) in Boole’s system since, by ordinary\nalgebra with idempotent class symbols, this would imply \\(2xy = 0\\),\nand then \\(xy = 0\\), which would force \\(x\\) and \\(y\\) to represent\ndisjoint classes. But it is not the case that every pair of classes is\ndisjoint.  \n\nKeeping the laws and valid equational arguments from the algebra of\nnumbers, augmented by the index law, forces addition \\(x + y\\) to\nbe undefined unless the classes \\(X\\) and \\(Y\\) are\ndisjoint. The only place where Boole wrote down the argument showing\nthat addition must be a partial operation was in his unpublished\nNachlass—see Boole: Selected Manuscripts …, 1997,\nedited by Ivor Grattan-Guiness and Gérard Bornet, pp. 91,92.\n \n\nIn the chapter “Of Expression and Interpretation”, Boole\nsaid that necessarily the class not-\\(X\\) is expressed by\n\\(1-x\\). This is the first appearance of subtraction\nin MAL. Boole’s initial equational expressions of the\nAristotelian categorical propositions as elective equations\n(MAL, pp. 21,22) will be called his\nprimary expressions. Then in the next several pages he adds\nsupplementary expressions; of these the main ones will be called the\nsecondary expressions. \n\nThe first primary expression given was for “All \\(X\\) is\n\\(Y\\)”, an equation which he then converted into\n\\(x(1-y) = 0\\). This was the first appearance of\n0 in MAL. It was not introduced as the symbol for the empty\nclass—indeed the empty class does not appear in MAL.\nEvidently “\\(= 0\\)” performed the role of a predicate in\nMAL, with an equation \\(E = 0\\) asserting that the class\ndenoted by \\(E\\) simply did not exist. (In LT, the\nempty class was introduced, and denoted by 0.)\n \n\nBoole emphasized that when a premise about \\(X\\) and \\(Y\\)\nis translated into an equation involving \\(x, y\\) and\n\\(v\\), the symbol \\(v\\) expressed “some”, but\nonly in the context in which it appeared in the premise. For example,\n“Some \\(X\\) is \\(Y\\)” has the primary\ntranslation \\(v = xy\\), which implies the\nsecondary translation \\(vx = vy\\). This could also be read as “Some\n\\(X\\) is \\(Y\\)”. Another consequence of \\(v = xy\\) is \\(v(1-x) = v(1-y)\\). However it was not permitted to read\nthis as “Some not-\\(X\\) is not-\\(Y\\)” since\n\\(v\\) did not appear with \\(1-x\\) or\n\\(1-y\\) in the premise. Boole’s use of \\(v\\) in the\nequational expression of propositions has been a long-standing bone of\ncontention.\n \n \nThe simple algebra and considerable detail in this part of\nMAL can be appealing to the new reader, but there are\ncomplications that need to be dealt with. Does “Some\nnot-\\(X\\) is \\(Y\\)” follow from “All\nnot-\\(X\\) is \\(Y\\)”? There is a lack of clarity on\nwhen to use the primary and secondary equations when analyzing\nsyllogisms, and with what one is permitted to do to derive \\(0 = 0\\) as a\nmarker that the premises being considered do not belong to a valid\nsyllogism. \n \nSyllogistic reasoning is just an exercise in elimination,\nnamely the middle term is eliminated from the premises to give the\nconclusion. Elimination was a standard topic in the theory of\nequations, and Boole borrowed a simple elimination result regarding\ntwo equations to use in his algebra of logic—if the premises of\na syllogism involved the classes \\(X, Y\\), and\n\\(Z\\), and one wanted to eliminate the middle term \\(Y\\),\nthen Boole put the equations for the two premises in the form \nwhere \\(y\\) does not appear in the coefficients a,b,c,d.\nThe result of eliminating \\(y\\) in ordinary algebra gives the\nequation \n\nand this is what Boole used in MAL. Unfortunately this is a\nweak elimination result for Boole’s algebra. One finds, using the\nimproved reduction and elimination theorems of LT, that the\nbest possible result of elimination is \n\n(Boole never pointed out this defect in MAL.) \n \nThe primary equational expressions were not sufficient to derive all\nof the desired syllogisms. For example, in the cases where the\npremises had primary expressions \\(ay = 0\\) and \\(cy = 0\\),\nelimination gave \\(0 = 0\\), even though Aristotelian logic might demand a\nnon-trivial conclusion. Boole introduced the alternative equational\nexpressions (see MAL, p. 32) of categorical propositions to\nbe able to derive all of the valid Aristotelian syllogisms. With this\nconvention, of using alternative expressions when needed, it turned\nout that the premises that only led to \\(0 = 0\\) were among\nthose which did not belong to a valid syllogism. Boole did not offer\nan algebraic way to completely determine which premises could be\ncompleted to valid syllogisms. \n\nToward the end of the chapter on categorical syllogisms there is a\nlong footnote (MAL, pp. 42–45) to support a claim\n(MAL, pp. 42, 43) that secondary translations alone are\nsufficient for the analysis of [his generalization of] Aristotelian\ncategorical logic. The footnote loses much of its force because the\nresults it presents depend heavily on the weak elimination theorem\nbeing best possible, which is not the case. In the Postscript he says\nthat using only the secondary translations is altogether superior to\nwhat was presented in the main text. \n\nBoole would use only the secondary translations of MAL in\nLT, but in LT the reader will no longer find a\nleisurely and detailed treatment of Aristotelian logic. Indeed the\ndiscussion of Aristotelian logic is delayed until the last chapter on\nlogic, namely Chapter XV, and in this chapter it is presented in such\na compressed form, using such long equations, that the reader is not\nlikely to want to check that Boole’s analysis is correct.\n \nBoole analyzed the seven hypothetical syllogisms that were\nstandard in Aristotelian logic, from the Constructive and Destructive\nConditionals to the Complex Destructive Dilemma. Letting capital\nletters \\(X, Y, \\ldots\\) represent categorical propositions, the\nhypothetical propositions traditionally involved in\nhypothetical syllogisms were in one of the forms “\\(X\\) is\ntrue”, “\\(X\\) is false”,“If \\(X\\)\nthen \\(Y\\)”, “\\(X\\) or \\(Y\\) or …”,\n“\\(X\\) and \\(Y\\) and …”. At the end of the\nchapter on hypothetical syllogisms he noted that it was easy to create\nnew ones, and one could enrich the collection by using mixed\nhypothetical propositions such as “If \\(X\\) is true, then\neither \\(Y\\) is true, or \\(Z\\) is true.”\n \n\nOne sees that Boole is taking first steps towards the general notion\nof a propositional formula \\(\\Phi(X,Y, \\ldots)\\), \nbut he never reached our modern approach using a recursive definition, \nan approach which is essential to being able to do inductive proofs on \nthe set of propositional formulas.\n \n\nMost important in this chapter was Boole’s claim that his algebra of\nlogic for categorical propositions was equally suited to the study of\nhypothetical syllogisms. This was based on adopting the standard\nreduction of hypothetical propositions to propositions about classes\nby letting the hypothetical universe, also denoted by 1, be\nthe collection of all cases and conjunctures of circumstances\n(which was usually abbreviated to just the word cases).\nEvidently his notion of a “case” was an assignment of\ntruth values to the propositional variables.\n \n\nThis brings up the question of whether or not his hypothetical\nuniverse depended on the variables being considered in an\nargument—if so then for \\(n\\) variables the universe would\nhave \\(2^n\\) cases. However he makes the remark\n(MAL, p. 50) that “the extent of the hypothetical\nUniverse does not at all depend upon the number of circumstances which\nare taken into account”. In this context\n“circumstances” means propositional variables; one still\nhas the question of what he means by cases. A modern solution would be\nto use the collection of all mappings from the set of propositional\nvariables to the set \\(\\{\\rT, \\rF\\}\\).\n \n\nFor \\(X\\) a categorical proposition Boole let \\(x\\) be the elective\noperator that selects the cases for which \\(X\\) is true.  Consider the\nhypothetical proposition “If \\(X\\) then \\(Y\\)”, where \\(X,\nY\\) are categorical propositions. A natural conversion of this\nhypothetical proposition into a categorical proposition would be\n“All \\(Cases(X)\\) are \\(Cases(Y)\\)”, where \\(Cases(X)\\) is\nthe class of all cases for which \\(X\\) is true, etc. The equational\ntranslation would be \\(xy = x\\). \n\nThe hypothetical proposition “\\(X\\) or \\(Y\\)”, with the\n“or” being inclusive, can be expressed by “Every\ncase is in \\(Cases(X)\\) or in \\(Cases(Y)\\) or in both”, but this\nis not in the form of a categorical proposition. Boole says\nthe universe of a categorical proposition has two\ncases, true and false. To find an equational\nexpression for a hypothetical proposition Boole resorts to a near\nrelative of truth tables (MAL, p. 50). To each case, that is,\nassignment of truth values to \\(X\\) and \\(Y\\), he associates an\nelective expression as follows: \n\nThese elective expressions are, of course, the constitutents\nof the elective operators \\(x\\), \\(y\\).\n \n\nBoole translates a propositional formula \\(\\Phi(X,Y, \\ldots)\\) into\nan elective expression \\(\\phi(x,y, \\ldots)\\) by ascertaining all the\ndistinct cases (assignments of truth values) which imply the formula,\nand summing their corresponding elective expressions. The elective\nequation for \\(\\Phi(X,Y, \\ldots)\\) is then \\(\\phi(x,y, \\ldots) = 1\\).\n \nThe elective expression for “\\(X\\) or \\(Y\\)”, with\n“or” inclusive, is the sum of the elective expressions for\nthe truth assignments to \\(X\\) and \\(Y\\) for which “\\(X\\) or\n\\(Y\\)” holds, that is, the sum of the first three elective\nexpressions in the above table, namely \\(xy + x(1 - y) + (1 - x)y\\),\nwhich simplifies to \\(x + y - xy\\). The elective equation of the\nassertion “\\(X\\) or \\(Y\\)” is \\(x + y - xy = 1\\).\n \n\nBoole did not have the modern view that a propositional formula can be\nconsidered a function on \\(\\{\\rT, \\rF\\}\\), taking values in \\(\\{\\rT,\n\\rF\\}\\).\n \nThe function viewpoint gives us an algorithm to determine which\nconstituents are to be summed to give the desired elective expression,\nnamely those constituents associated with the cases for which the\npropositional formula has the value \\(\\rT\\).  Applying this to the\npropositional formula “\\(X\\) implies \\(Y\\)” gives the\nfollowing:\n \n\nThus the elective expression for “\\(X\\) implies \\(Y\\)” is\n\\(xy + (1 - x) y + (1 - x)(1 - y)\\), which simplifies to \\(1 - x +\nxy\\).\n \n\nBy not viewing propositional formulas as functions on \\(\\{\\)T, F\\(\\}\\) Boole\nmissed out on being the inventor of truth tables. His algebraic\nmethod of analyzing hypothetical syllogisms was to transform each of\nthe hypothetical premises into an elective equation, and then apply\nhis algebra of logic (which was developed for categorical\npropositions). For example, the premises “\\(X\\)\nor \\(Y\\)” and “not-\\(X\\)” are expressed by\n“\\(x + y - xy = 1\\)” and\n“\\(x = 0\\)”. From these it immediately follows that\n“\\(y = 1\\)”, giving the conclusion\n“\\(Y\\)”, that is, if “\\(X\\)\nor \\(Y\\)” and “not-\\(X\\)” are true, then\n“\\(Y\\) is true”.\n \n\nBoole’s assumption that \\(x\\) selected the cases for\nwhich \\(X\\) is true leads to some confusion. In the above\nexample, the premise “\\(x = 0\\)” apparently says\nthat \\(X\\) is false in all cases, and the conclusion\n“\\(y = 1\\)” says that \\(Y\\) is true in all\ncases. But the meaning of the argument “\\(X\\)\nor \\(Y\\), not-\\(X \\therefore Y\\)” is that any\ncase which makes the premises true also makes the conclusion true.\n \n\nThe confusion is cleared up by adopting De Morgan’s 1847 concept\nof the universe of discourse (as Boole did in\nin LT).  Namely, given premises \\(\\Phi , \\Psi, \\ldots\\), the\nuniverse of discourse is chosen to be the collection of cases for\nwhich the premises hold.  In LT Boole abandoned the use of\ncases specified by assignments of truth-values to the variables, and\ninstead associated with a proposition the time during which\nit was true, noting that to use “cases” one needed to\ndefine the notion of a case, which he evidently was unable to do in a\nsatisfactory manner.\n \n\nBoole only considered rather simple hypothetical propositions on the\ngrounds these were the only ones encountered in common usage (see\nLT, p. 172). His algebraic approach to propositional logic\nis easily extended to all propositional formulas as follows. For\n\\(\\Phi\\) a propositional formula the associated elective function\n\\(\\Phi^*\\) is defined recursively as follows:\n \nThen one has: \n\nThis looks quite different from modern propositional logic where one\ntakes a few tautologies, such as \\(X \\rightarrow(Y \\rightarrow X)\\), as axioms, and inference rules such as modus ponens to\nform a deductive system.  \nThis translation, from \\(\\Phi\\) to \\(\\Phi^*\\), viewed as mapping\nexpressions in modern Boolean algebra to polynomials, would be\npresented in a 1933 paper of Hassler Whitney (1907–1989), with\nthe objective of showing that one does not need to learn the algebra\nof logic [modern Boolean algebra] to verify the equational laws and\nequational arguments of Boolean algebra—they can be translated\ninto the ordinary algebra with which one is familiar. Howard Aiken\n(1900–1973), Director of the Harvard Computation Laboratory,\nwould use such translations of logical functions into ordinary algebra\nin his 1951 book Synthesis of Electronic Computing and Control\nCircuits, specifically stating that he preferred Boole’s\nnumerical function approach to that of Boolean algebra or\npropositional logic.\n \n\nBeginning with the chapter “Properties of Elective\nFunctions”, Boole developed general theorems for working with\nequations in his algebra of logic—the Expansion Theorem and the\nproperties of constituents are discussed in this chapter. His proof\nof the one-variable case of the Expansion Theorem (MAL,\np. 60) is rather strange—there is no need to take a power series\nexpansion of a polynomial. Otherwise his proof is correct. From the\nExpansion Theorem and the properties of constituents he shows that the\nmodulii of the sum/difference/product of two elective functions are\nthe sums/differences/products of the corresponding modulii of the two\nfunctions. \nThe Expansion Theorem is used (MAL, p. 61) to prove an\nimportant result, that \\(p(x)\\) and \\(q(x)\\) are equivalent in\nBoole’s algebra if and only if corresponding modulii\nare the same, that is, \\(p(1) = q(1)\\) and \\(p(0) = q(0)\\). This\nresult generalizes to functions of several variables. It will not be\nstated as such in LT, but will be absorbed in the much more\ngeneral (if somewhat opaquely stated) result that will be called the\nRule of 0 and 1.\n \nAn elective function \\(p(x, y, \\ldots)\\) is\ninterpretable in Boole’s algebra whenever it is\ndefined. For example \\(1+1 + x\\) is not interpretable (for any class\n\\(X\\)), \\(x + y\\) is only interpretable for \\(X\\) and \\(Y\\) disjoint\nclasses, and \\(xy\\) is totally (always) interpretable. An elective\nequation \\(p = q\\) is interpretable whenever both sides are\ninterpretable. A constituent equation is an elective equation\nof the form \\(r = 0\\), where \\(r\\) is a constituent. Constituent\nequations are totally interpretable. Boole shows (MAL, p. 64)\nthat every elective equation \\(p = 0\\) is equivalent to the collection\nof constituent equations \\(r = 0\\) where the modulus (coefficient) of\n\\(r\\) in the expansion of \\(p\\) is not zero, and thus every\nelective equation is interpretable. Furthermore this leads\n(MAL, p. 65) to the fact that \\(p = 0\\) is equivalent to the\nequation \\(q = 0\\) where \\(q\\) is the sum of the constituents in the\nexpansion of \\(p\\) whose modulus is non-zero.  As examples, consider\nthe equations \\(x + y = 0\\) and \\(x - y = 0\\). The following table\ngives the constituents and modulii of their expansions: \nThus \\(x + y = 0\\) is equivalent to the collection of constituent\nequations  as well as the single equation and \\(x - y = 0\\) is equivalent to the collection of constituent\nequations  as well as the single equation \n\nIt was natural for Boole to want to solve equations in his algebra of\nlogic since this had been a main goal of ordinary algebra, and had led\nto many difficult questions (e.g., how to solve a 5th degree\nequation). Fortunately for Boole, the situation in his algebra of\nlogic was much simpler—he could always solve an equation, and\nfinding the solution was important to applications of his system, to\nderive conclusions in logic. An equation was solved in part by using\n formal expansion after performing formal division, and then decoding the\nfractional coefficients. \nThis Solution Theorem was the result of which he was the most\nproud—it described how to solve an elective equation for one of\nits symbols in terms of the others, often introducing constraint\nequations on the independent variables, and it is this that Boole\nclaimed (in the Introduction chapter of MAL, p. 9) would\noffer “the means of a perfect analysis of any conceivable system\nof propositions, …”. In LT Boole would continue\nto regard this tool as the highlight of his work. \n\nBoole’s final example (MAL, p. 78), solving three equations\nin three unknowns for one of the unknowns in terms of the other two,\nused a well known technique for handling side conditions in analysis\ncalled Lagrange Multipliers—this method (which reduced the three\nequations in the example to a single equation in five unknowns)\nreappears in LT (p. 117), but is only used in a single\nexample. It is superseded by the sum of squares reduction\n(LT, p. 121) which does not introduce new variables. Power\nseries had not been completely abandoned in LT—they\nappeared in LT, but only in a footnote (LT, p. 72).\nUsing the Reduction and Elimination Theorems in LT one\ndiscovers that Boole’s constraint equations (3) (MAL, p. 80)\nfor his three equation example are much too weak—each of the\nproducts should be 0, and there are additional constraint equations.\n \nMAL shows more clearly than LT how closely Boole’s\nalgebra of logic is based on the common algebra plus idempotent class\nsymbols. The Elimination Theorem that he simply borrowed from algebra\nturned out to be weaker than what his algebra offered, and his method\nof reducing equations to a single equation was clumsier than the main\none used in LT, but the Expansion Theorem and Solution\nTheorem were the same. One sees that MAL contained not only\nthe basic outline for LT, but also some parts fully\ndeveloped. Much of LT would be devoted to clarifying and\ncorrecting what was said in MAL, and providing more\nsubstantial applications, the main one being his considerable work in\nprobability theory. \nBoole’s second logic book, An Investigation of The Laws of Thought\non which are founded the Mathematical Theories of Logic and\nProbabilities, published in 1854, was an effort to correct and\nperfect his 1847 book on logic. The second half of this 424 page book\npresented probability theory as an excellent topic to illustrate the\npower of his algebra of logic. Boole discussed the theoretical\npossibility of using probability theory (enhanced by his algebra of\nlogic) to uncover fundamental laws governing society by analyzing large\nquantities of social data by large numbers of (human) computers. \n \n\nBoole said that he would use letters like \\(x\\) to represent classes,\nalthough later he would also use capital letters like\n\\(V\\). The universe was a class, denoted by 1; and there was\na class described as having “no beings”, denoted by 0,\nwhich we call the empty class. The operation of\nmultiplication was defined to be intersection, and this led\nto his first law, \\(xy = yx\\). Next (some pages later) he gave the\nidempotent law \\(x^2 = x\\). Addition was introduced as\naggregation when the classes were disjoint. He stated the commutative\nlaw for addition, \\(x + y = y + x\\), and the distributive law \\(z(x +\ny) = zx + zy\\). Then followed \\(x - y = - y + x\\) and \\(z(x - y) = zx\n- zy\\). The associative laws for addition and multiplication were\nconspicuously absent. A possible reason for this omission was that he\nworked with the standard algebra of\npolynomials, where the parentheses involved in the\nassociative laws are absent, instead of the terms which are\nfundamental to modern logic.\n \n\nBoole seems to justify his choice of laws on the basis that they are\nvalid where defined. This does not guarantee the compatibility of the\naxioms with the algebraic structures since the equation \\((x+y)^2 =\nx+y\\) is certainly valid where defined, namely when \\(xy = 0\\), but\nadding this to Boole’s axioms leads to the theorem \\(xy = 0\\),\nthat is, any two classes are disjoint, which is not the case. Working\nwith partial algebras has its subtleties.  \nOne might expect that Boole was building toward an axiomatic\nfoundation for his algebra of logic, just as in MAL,\nevidently having realized that the three laws in MAL were not\nenough. Indeed he did discuss the rules of inference, that adding or\nsubtracting equals from equals gives equals, and multiplying equals by\nequals gives equals. But then the development of an axiomatic\napproach came to an abrupt halt. There was no discussion as to whether\nthe stated axioms (which he called laws) and rules (which he\ncalled axioms) were sufficient to construct his algebra of\nlogic. (They were not.) Instead he simply and briefly, with\nremarkably little fanfare, presented a radically new foundation for\nhis algebra of logic (LT pp. 37,38). \n\nHe said that since the only idempotent numbers were 0 and 1, this\nsuggested that the correct algebra to use for logic would be the\ncommon algebra of the ordinary numbers modified by restricting the\nsymbols to the values 0 and 1. He stated what, in this article, is\ncalled The Rule of 0 and 1, that a law or argument held in\nlogic iff after being translated into equational form it held in\ncommon algebra with this 0,1-restriction on the possible\ninterpretations (i.e., values) of the symbols. Boole would use this\nRule to justify his main theorems (Expansion, Reduction, Elimination),\nand for no other purpose. The main theorems in turn yielded Boole’s\nGeneral Method for discovering the strongest possible consequences of\npropositional premises under certain desired constraints (such as\neliminating some of the variables). \n\nIn Chapter V he discussed the role of uninterpretables in his\nwork; as a (partial) justification for the use of uninterpretable\nsteps in symbolic algebra he pointed to the well known use of\n\\(\\sqrt{-1}\\). Unfortunately his Principles of Symbolical\nReasoning do not, in general apply to partial algebras, that is,\nwhere some of the operations are only partially defined, such as\naddition and subtraction in Boole’s algebra. Nonetheless it turns out\nthat they do apply to his algebra of logic. In succeeding chapters he\ngave the Expansion Theorem, the new full-strength Elimination Theorem,\nan improved Reduction Theorem, and the use of division to solve an\nequation. \n\nAfter many examples and results for special cases of solving\nequations, Boole turned to the topic of the interpretability of a\nlogical function. Boole had already stated that every equation is\ninterpretable (by converting an equation into a collection of\nconstituent equations). However terms need not be interpretable, e.g.,\n\\(1+1\\) is not interpretable. Working with the modern notion of terms,\none can recursively define the domain of interpretability of a\nterm. For example, \\((x+y) - z\\) has a different domain of\ninterpretability than the equivalent term \\(x + (y -z)\\). The first is\ninterpretable if and only if \\(x\\) and \\(y\\) are disjoint classes, and\n\\(z\\) is contained in the union of \\(x\\) and \\(y\\). The second is\ninterpretable if and only if \\(z\\) is contained in \\(y\\), and \\(x\\)\nand \\(y \\smallsetminus z\\) are disjoint. Both terms are equivalent to the\nsame polynomial \\(x + y - z\\), leaving Boole with the problem of\ndetermining when a polynomial \\(p\\) is interpretable. Eventually he\ncomes to the conclusion that the condition for a polynomial to be\nequivalent to a (totally) interpretable elective function is that it\nsatisfy \\(p^2 = p\\), in which case it is equivalent to a sum of\ndistinct constituents, namely those belonging to the non-vanishing\nmodulii of \\(p\\). Of course a polynomial is idempotent if and only if\nall of its modulii are idempotent, that is, they are in \\(\\{0, 1\\}\\),\nin which case the expansion of the polynomial is a sum of distinct\nconstituents (or it is 0). \nBoole’s chapter on secondary propositions is essentially the same as\nin MAL except that he changed from using “the cases\nwhen \\(X\\) is true” to “the times when \\(X\\) is\ntrue”. In Chapter XIII Boole selected some well-known arguments\nof Clarke and Spinoza, on the nature of an eternal being, to put under\nthe magnifying glass of his algebra of logic, starting with the\ncomment (LT, p. 185): One conclusion was (LT, p. 216): \n\nIn the final chapter on logic, chapter XV, Boole presented his\nanalysis of the conversions and syllogisms of Aristotelian logic. \n\nHe now considered this ancient logic to be a weak, fragmented attempt at a\nlogical system. \n\nThis much neglected chapter is quite interesting\nbecause it is the only chapter where he analyzed particular\npropositions, making essential use of additional letters like\n“\\(v\\)” to encode “some”. \n\nThis is also the chapter\nwhere he detailed (unfortunately incompletely) the rules for working\nwith “some”. \n\nBriefly stated, Boole gave the reader a summary of traditional\nAristotelian categorical logic, and analyzed some simple examples\nusing ad hoc techniques with his algebra of logic. Then he launched\ninto proving a comprehensive result by applying his General Method to\nthe pair of equations: \nnoting that the premises of many categorical syllogisms can be put in\nthis form. His goal was to eliminate \\(y\\) and find expressions for\n\\(x, 1-x\\) and \\(vx\\) in terms of \\(z, v, v', w, w'\\). This led to\nthree equations involving large algebraic expressions. Boole omitted\nalmost all details of his derivation, but summarized the results in\nterms of the established results of Aristotelian logic. Then he noted\nthat the remaining categorical syllogisms are such that their premises\ncan be put in the form: \nand this led to another triple of large equations. \nMany objections to Boole’s system have been published over the years;\nthree among the most important concern: \n\nWe look at a different objection, namely at the Boole/Jevons dispute\nover adding \\(x + x = x\\) as a law. In Laws\nof Thought, p. 66, Boole said: \n[The following details are from “The development of the theories\nof mathematical logic and the principles of mathematics, William\nStanley Jevons,” by Philip Jourdain, 1914.] \n\nIn an 1863 letter to Boole regarding a draft of a commentary on\nBoole’s system that Jevons was considering for his forthcoming book\n(Pure Logic, 1864), Jevons said: It is surely obvious, however, that \\(x+x\\) is equivalent\nonly to \\(x,\\ldots\\) \nProfessor Boole’s notation [process of subtraction] is\ninconsistent with a self-evident law. \nIf my view be right, his system will come to be regarded as a\nmost remarkable combination of truth and error. Boole replied: \nJevons responded by asking if Boole could deny the truth of \\(x + x = x\\). \nBoole, clearly exasperated, replies: \nJevons’s final effort to get Boole to understand the issue was: \nJevons’s new law, \\(x + x = x\\), resulted from\nhis conviction that “+” should denote what we now call\nunion, where the membership of \\(x + y\\) is given by an\ninclusive “or”. Boole simply did not see any way to define\n\\(x + y\\) as a class unless \\(x\\) and \\(y\\)\nwere disjoint, as already noted. \nVarious explanations have been given as to why Boole could not\ncomprehend the possibility of Jevons’s suggestion. Boole clearly had\nthe semantic concept of union—he expressed the union\nof \\(x\\) and \\(y\\) as \\(x + y(1-x)\\), a union of two disjoint classes, and\npointed out that the elements of this class are the ones that belong\nto either \\(x\\) or \\(y\\) or both. So how could he so\ncompletely fail to see the possibility of taking union for his\nfundamental operation + instead of his curious partial union\noperation? \nThe answer is simple: the law \\(x + x = x\\) would have destroyed his\nability to fully use ordinary algebra: from \\(x + x = x\\) one\nhas, by ordinary algebra, \\(x = 0\\). This would force every class\nsymbol to denote the empty class. Jevons’s proposed law \\(x + x\n= x\\) was simply not true if one was committed to constructing the\nalgebra of logic on top of the laws and inference rules of ordinary\nalgebra. (Boolean rings have all the laws of the integers, but not all\nof the inference rules, for example, \\(2x = 0\\) implies \\(x = 0\\) does\nnot hold in Boolean rings. It seems quite possible that Boole found\nthe simplest way to construct an algebra of logic for classes that\nallowed one to use all the equations and equational arguments\nthat were valid for the integers.) \nPerhaps it is interesting to note that the title of Jevon’s 1864 book\nstarted out with the words Pure Logic, referring to the fact\nthat his version of the algebra of logic had been cleansed from\nconnections to the algebra of numbers. The same point would be made in\nthe introduction to Whitehead and Russell’s Principia\nMathematica, that they had adopted the notation of Peano in part\nto free their work from such connections.  \nGiven the enormous degree of sophistication achieved in modern algebra\nin the 20th century, it is rather surprising that a law-preserving\ntotal algebra extension of Boole’s partial algebra of classes did not\nappear until Theodore Hailperin’s book of 1976—the delay was\nlikely caused by readers not believing that Boole was using ordinary\nalgebra. Hailperin’s extension was to look at labelings of the\nuniverse with integers, that is, each element of the universe is\nlabeled with an integer. Each labeling of the universe creates a\nsigned multi-set (perhaps one should say signed\nmulti-class) consisting of those labeled elements where the label\nis non-zero. For multi-sets, whose labels are all\nnon-negative, one can think of the label of an element as describing\nhow many copies of the element are in the multi-set. Boole’s classes\ncorrespond to the signed multi-sets where all the labels are 0 or 1\n(the elements not in the class have the label 0). The uninterpretable\nelements of Boole become interpretable when viewed as signed\nmulti-sets—they are given by labelings of the universe where\nsome label is not 0 or 1.  \n\nTo add two signed multi-sets one simply adds the labels on each\nelement of the universe. Likewise for subtraction and multiplication.\n(For the reader familiar with modern abstract algebra, one can take\nthe extension of Boole’s partial algebra to\nbe \\(Z^U\\) where \\(Z\\) is the ring of\nintegers, and \\(U\\) is the universe of discourse.) The signed\nmulti-sets corresponding to classes are precisely the idempotent\nsigned multi-sets. It turns out that the laws and principles Boole\nwas using in his algebra of logic hold for this system. By this means\nBoole’s methods are proved to be correct for the algebra of logic\nof universal propositions. Hailperin’s analysis did not\napply to particular propositions. Frank W. Brown’s paper “\nGeorge Boole’s deductive system” (2009) proposes that one can\navoid signed multi-sets by working with the ring of polynomials Z[X]\nmodulo a certain ideal.  \n\nBoole could not find a translation that worked as cleanly for the\nparticular propositions as for the universal propositions. In 1847\nBoole used the following two translations, the second one being a\nconsequence of the first: \nHe initially used the symbol \\(v\\) to capture the essence of\n“some”. Later he used other symbols as well, and also he\nused \\(v\\) with other meanings (such as for the coefficients in\nan expansion). One of the problems with his translation scheme with\n\\(v\\) was that at times one needed “margin notes,” to\nkeep track of which class(es) the \\(v\\) was attached to when it\nwas introduced. The rules for translating from equations with\n\\(v\\)’s back to particular statements were never clearly\nformulated. For example in Chapter XV one sees a derivation of\n\\(x = vv'y\\) which is then\ntranslated as Some \\(X\\) is \\(Y\\). But he had no rules for\nwhen a product of \\(v\\)’s carries the import of\n“some”. Such problems detract from Boole’s system; his\nexplanations leave doubts as to which procedures are legitimate in his\nsystem when dealing with particular statements. \n\nThere is one point on which even Hailperin was not faithful to Boole’s\nwork, namely he used modern semantics, where the\nsymbols \\(x, y\\), etc., can refer to the empty class as\nwell as to a non-empty class. With modern semantics one cannot have\nthe Conversion by Limitation which held in Aristotelian logic: from\nAll \\(X\\) is \\(Y\\) follows Some \\(Y\\) is \\(X\\).\nIn his Formal Logic of 1847, De Morgan pointed out that all\nwriters on logic had assumed that the subject in a universal\nproposition was assumed to be non-empty. The simplest way to deal\nwith this in an algebra of logic is to restrict class symbols to\nrepresent non-empty classes; and given the interest in liberating the\nrole of contraries like not-\\(x\\), perhaps class symbols should\nalso be restricted to representing non-universe classes. Such a\nconvention will be called Aristotelian semantics. Boole had\nevidently followed this Aristotelian convention because he derived all\nthe Aristotelian results, including Conversion by Limitation. A\nproper interpretation (faithful to Boole’s work) of Boole’s system\nrequires Aristotelian semantics for the class\nsymbols \\(x, y, z,\\ldots\\) ; unfortunately\nit seems that the published literature on Boole’s system has failed to\nnote this. Authors seem quite satisfied that Boole’s results,\nespecially his general theorems, have been so compatible with the\nmodern semantics of class symbols. \n\nWhile reading through this section, on the technical details of\nBoole’s methods, the reader may find it useful to consult the \nThese examples have been augmented with comments explaining, in each\nstep of a derivation by Boole, which aspect of his methods is being\nemployed.  \nBoole used three methods to analyze arguments in LT: \n\nThe theorems of LT combine to yield the master result, \n\nWhen applying the ad hoc method, he used parts of ordinary algebra\nalong with the idempotent law \\(x^2 = x\\) to\nmanipulate equations. There was no pre-established procedure to\nfollow—success with this method depended on intuitive skills\ndeveloped through experience. \n\nThe second method, the Rule of 0 and 1, is very powerful, but it\ndepends on being given a collection of premise equations and a\nconclusion equation. It is a truth-table like method (but Boole never\ndrew a table when applying the method) to determine if the argument is\ncorrect. Boole only used this method to establish the theorems that\njustified his General Method, even though it is an excellent tool for\nverifying simple arguments like syllogisms. But Boole was more\ninterested in finding the most general conclusion from given premises,\nmodulo certain conditions, and aside from his general theorems, showed\nno interest in simply verifying logical arguments. The Rule of 0 and\n1 is a somewhat shadowy figure in LT—it has no name,\nand is never referred to by section or page number. A precise version\nof Boole’s Rule of 0 and 1 that yields Boole’s results is given in\nBurris and Sankappanavar 2013. \n\nThe third method to analyze arguments was the highlight of Boole’s\nwork in logic, his General Method (discussed immediately after this).\nThis is the one he used for all but the simplest examples in\nLT; for the simplest examples he resorted to the first method\nof ad hoc algebraic techniques because, for one skilled in algebraic\nmanipulations, using them is usually far more efficient than going\nthrough the General Method. \n\nThe final version (from LT) of his General Method for\nanalyzing arguments is, briefly stated, to:  With this method Boole had replaced the art of reasoning from\npremise propositions to conclusion propositions by a routine mechanical\nalgebraic procedure. \n\nIn LT Boole divided propositions into two kinds, primary\nand secondary. These correspond to, but are not exactly the same as,\nthe Aristotelian division into categorical and hypothetical\npropositions. First we discuss his General Method applied to primary\npropositions.  \nBoole recognized three forms of primary propositions: \n\nThese were his version of the Aristotelian categorical propositions,\nwhere \\(X\\) is the subject term and \\(Y\\) the predicate term. The\nterms \\(X\\) and \\(Y\\) could be complex names, for example, \\(X\\) could\nbe \\(X_1\\) or \\(X_2\\). \n\nSTEP 1: Names are converted into algebraic terms as\nfollows: \n\nWe will call the letters \\(x, y,\\ldots\\) class symbols (as\nnoted earlier, the algebra of the 1800s did not use the word\nvariables). \n\nSTEP 2: Having converted names for the terms into algebraic terms,\none then converts the propositions into equations using the\nfollowing: \n\nPrior to chapter XV, the one on Aristotelian logic, Boole’s\nexamples only use universal propositions. (One can speculate that he\nhad encountered difficulties with particular propositions and avoided\nthem.) Those of the form “All X is Y” are first expressed\nas \\(x = vy\\), and then \\(v\\) is promptly eliminated, giving \\(x =\nxy\\). (Similarly if \\(X\\) is replaced by not-\\(X\\), etc.) Boole said\nthis was merely a convenient but unnecessary step. For the examples in\nthe first fourteen chapters he could simply have used the translation\n\\(x = xy\\), skipping the reference to \\(v\\). It seems that to simplify\nnotation he used the same letter \\(v\\) when there were\nseveral universal premises, an incorrect step if one accepts\nBoole’s claim that it is not necessary to eliminate the\n\\(v\\)’s immediately. Distinct universal propositions require\ndifferent \\(v\\)’s in their translation. Else one can run into\nthe following situation. Consider the two premises “All \\(X\\) is\n\\(Z\\)” and “All \\(Y\\) is \\(Z\\)”. Using the same\n\\(v\\) for their equational expressions gives \\(x = vz\\) and \\(y =\nvz\\), leading to the equation \\(x = y\\), and then to the false\nconclusion \\(X\\) equals \\(Y\\). In chapter XV he was careful to use\ndistinct \\(v\\)’s for the expressions of distinct premises.\n \n\nBoole used the four categorical propositions as his primary forms in\n1847, but in 1854 he eliminated the negative propositional forms,\nnoting that one could change “not \\(Y\\)” to\n“not-\\(Y\\)”. Thus in 1854 he would express “No \\(X\\)\nis \\(Y\\)” by “All \\(X\\) is not-\\(Y\\)”, with the\ntranslation \\(x = v(1-y)\\), and then eliminating \\(v\\) to obtain\n which simplifies to \\(xy = 0\\). \nSTEP 3: After converting the premises into algebraic form one has a\ncollection of equations, say \nExpress these as equations with 0 on the right side, that is, as \nwith \nSTEP 4: (REDUCTION) [LT (p. 121) ] \nReduce the system of equations \nto a single equation \\(r = 0\\). Boole had three different\nmethods for doing this—he seemed to have a preference for\nsumming the squares:  \nSteps 1 through 4 are mandatory in Boole’s General Method. After\nexecuting these steps there are various options for continuing,\ndepending on the goal.  \nSTEP 5: (ELIMINATION) [LT (p. 101)] \n\nSuppose one wants the most general equational conclusion derived\nfrom \\(r = 0\\) that involves some, but not all, of the class\nsymbols in \\(r\\). Then one wants to eliminate certain symbols. Suppose \\(r\\)\ninvolves the class symbols \nThen one can write \\(r\\) as \\(r(x_1, \\ldots, x_j, y_1, \\ldots ,y_k)\\). \nBoole’s procedure to eliminate the symbols \\(x_1, \\ldots ,x_j\\)\nfrom to obtain was as follows:  \nFor example, eliminating \\(x_1, x_2\\) from gives where \nSTEP 6: (DEVELOPMENT, or EXPANSION)\n[MAL (p. 60), LT (pp. 72, 73)]. \n\nGiven a term, say \\(r(x_1, \\ldots, x_j, y_1, \\ldots, y_k)\\), one can\nexpand the term with respect to a subset of the class symbols. To\nexpand with respect to \\(x_1, \\ldots, x_j\\) gives \nwhere \\(a_1 , \\ldots ,a_j\\) range over all sequences of 0s and 1s of\nlength \\(j\\), and where the \\(C(a_i, x_i)\\) are defined by: \nBoole said the products: \nwere the constituents of \\(x_1 , \\ldots ,x_j\\). There are \\(2^j\\)\ndifferent constituents for \\(j\\) symbols. The regions of a Venn\ndiagram give a popular way to visualize constituents. \nSTEP 7: (DIVISION: SOLVING FOR A CLASS SYMBOL)\n [MAL (p. 73), LT (pp. 86, 87)] ] \n\nGiven an equation \\(r = 0\\), suppose one wants to solve this equation\nfor one of the class symbols, say \\(x\\), in terms of the other class\nsymbols, say they are \\(y_1 , \\ldots ,y_k\\). To solve: \nfor \\(x\\), first let: \nThen: where \\(s(y_1 ,\\ldots ,y_k)\\) is: the sum of all constituents\n \\(C(a_1, y_1) \\cdots C(a_k,  y_k)\\)\n where \\(a_1 , \\ldots ,a_k\\) range over all sequences of 0s and\n 1s for which: \nplus the sum of all the terms of the form\n \\(V_{a_1 \\ldots a_k} \\cdot C(a_1, y_1) \\cdots C(a_k, y_k)\\)\n for which: \n\nThe \\(V_{a_1 \\ldots a_k}\\) are parameters, denoting\narbitrary classes (similar to what one sees in the study of linear\ndifferential equations, a subject in which Boole was an expert). \n\nTo the equation (*) for \\(x\\) adjoin the side-conditions (that we\nwill call constituent equations) \nwhenever \nNote that one is to evaluate the terms: \nusing ordinary arithmetic. Thus solving an equation \\(r = 0\\) for a\nclass symbol \\(x\\) gives an equation \nperhaps with side-condition constituent equations. \nSTEP 8: (INTERPRETATION) [MAL pp. 64–65, LT\n(Chap. VI, esp. pp. 82–83)] \nSuppose the equation \\(r(y_1 , \\ldots ,y_k) = 0\\) has been obtained by\nBoole’s method from a given collection of premise equations. Then this\nequation is equivalent to the collection of constituent equations \nfor which \\(r(a_1 , \\ldots ,a_k)\\) is not 0. A constituent equation\nmerely asserts that a certain intersection of the original classes and\ntheir complements is empty. For example, \nexpresses the proposition “All \\(Y_1\\) is \\(Y_2\\) or\n\\(Y_3\\),” or equivalently, “All \\(Y_1\\) and not \\(Y_2\\) is\n\\(Y_3\\).” It is routine to convert constituent equations into\npropositions. \n\nSecondary propositions were Boole’s version of the propositions that\none encounters in the study of hypothetical syllogisms in Aristotelian\nlogic, statements like “If \\(X\\) or \\(Y\\) then\n\\(Z\\).” The symbols \\(X, Y, Z\\),\netc. of secondary propositions did not refer to classes, but rather\nthey referred to (primary) propositions. In keeping with the\nincomplete nature of the Aristotelian treatment of hypothetical\npropositions, Boole did not give a precise description of possible\nforms for his secondary propositions. \nThe key (but not original) observation that Boole used was simply that\none can convert secondary propositions into primary propositions. In\nMAL he adopted the convention found in Whately (1826), that\ngiven a propositional symbol \\(X\\), the symbol \\(x\\) will\ndenote “the cases in which \\(X\\) is true”, whereas in\nLT Boole let \\(x\\) denote “the times for which\n\\(X\\) is true”. With this the secondary proposition\n“If \\(X\\) or \\(Y\\) then \\(Z\\)” becomes\nsimply “All \\(x\\) or \\(y\\) is \\(z\\)”. The\nequation \\(x = 1\\) is the equational translation of\n“\\(X\\) is true” (in all cases, or for all times), and\n\\(x = 0\\) says “\\(X\\) is false” (in\nall cases, or for all times). The concepts of all cases and\nall times depend on the choice of the universe of\ndiscourse.  \n\nWith this translation scheme it is clear that Boole’s treatment of\nsecondary propositions can be analyzed by the methods he had developed\nfor primary propositions. This was Boole’s propositional logic. \n\nBoole worked mainly with Aristotelian propositions in MAL,\nusing the traditional division into categoricals and hypotheticals.\nOne does not consider “\\(X\\) and \\(Y\\),”\n“\\(X\\) or \\(Y\\),” etc., in categorial\npropositions, only in hypothetical propositions. In LT this\ndivision was replaced by the similar but more general primary versus\nsecondary classification, where the subject and predicate were allowed\nto become complex names, and the number of propositions in an argument\nbecame unrestricted. With this the parallels between the logic of\nprimary propositions and that of secondary propositions became clear,\nwith one notable difference, namely it seems that the secondary\npropositions that Boole considered always translated into universal\nprimary propositions.","contact.mail":"snburris@math.uwaterloo.ca","contact.domain":"math.uwaterloo.ca"}]
