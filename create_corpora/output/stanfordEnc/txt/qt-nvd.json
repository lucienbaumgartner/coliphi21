[{"date.published":"2004-07-27","date.changed":"2019-07-01","url":"https://plato.stanford.edu/entries/qt-nvd/","author1":"Fred Kronz","author2":"Tracy Lupher","entry":"qt-nvd","body.text":"\n\n\n\nAn ongoing debate in the foundations of quantum physics concerns the role of\nmathematical rigor. The contrasting views of von Neumann\nand Dirac provide interesting and informative insights concerning two\nsides of this debate. Von Neumann’s contributions often emphasize\nmathematical rigor and Dirac’s contributions emphasize pragmatic\nconcerns. The discussion below begins with an assessment of their\ncontributions to the foundations of quantum mechanics. Their\ncontributions to mathematical physics beyond quantum mechanics are\nthen considered, and the focus will be on the influence that these\ncontributions had on subsequent developments in quantum theorizing,\nparticularly with regards to quantum field theory and its\nfoundations. The entry\n quantum field theory\n provides an overview of a variety of approaches to\ndeveloping a quantum theory of fields. The purpose of this article is\nto provide a more detailed discussion of mathematically rigorous\napproaches to quantum field theory, as opposed to conventional\napproaches, such as Lagrangian quantum field theory, which are\ngenerally portrayed as being more heuristic in character. The current\ndebate concerning whether Lagrangian quantum field theory or axiomatic\nquantum field theory should serve as the basis for interpretive\nanalysis is then discussed.\n\n\nThere are two competing mathematical strategies that are used in\nconnection with physical theory, one emphasizes rigor and the other\npragmatics. The pragmatic approach often compromises mathematical\nrigor, but offers instead expediency of calculation and elegance of\nexpression. A case in point is the notion of an infinitesimal, a\nnon-zero quantity that is smaller than any finite\nquantity. Infinitesimals were used by Kepler, Galileo, Newton, Leibniz\nand many others in developing and using their respective physical\ntheories, despite lacking a mathematically rigorous foundation, as\nBerkeley clearly showed in his famous 1734 treatise The\nAnalyst criticizing infinitesimals. Such criticisms did not\nprevent various 18th Century mathematicians, scientists, and engineers\nsuch as Euler and Lagrange from using infinitesimals to get accurate\nanswers from their calculations. Nevertheless, the pull towards rigor\nled to the development in the 19th century of the concept of a limit\nby Cauchy and others, which provided a rigorous mathematical framework\nthat effectively replaced the theory of infinitesimals. A rigorous\nfoundation was eventually provided for infinitesimals by Robinson\nduring the second half of the 20th Century, but infinitesimals are\nrarely used in contemporary physics. For more on the history of\ninfinitesimals, see the entry on \n continuity and infinitesimals.  \n\nThe competing mathematical strategies are manifest in a more recent\ndiscussion concerning the mathematical foundations of quantum\nmechanics. In the preface to von Neumann’s (1955) treatise  on that\ntopic, he notes that Dirac provides a very elegant and powerful formal\nframework for quantum mechanics, but complains about the central role\nin that framework of an “improper function with self-contradictory\nproperties,” which he also characterizes as a “mathematical fiction.”\nHe is referring to the Dirac \\(\\delta\\) function, which has the following\nincompatible properties: it is defined over the real line, is zero\neverywhere except for one point at which it is infinite, and yields\nunity when integrated over the real line. Von Neumann promotes an\nalternative framework, which he characterizes as being “just as clear\nand unified, but without mathematical objections.” He emphasizes that\nhis framework is not merely a refinement of Dirac’s; rather, it is a\nradically different framework that is based on Hilbert’s theory of\noperators. \n\nDirac is of course fully aware that the \\(\\delta\\) function is not a\nwell-defined expression. But he is not troubled by this for two\nreasons. First, as long as one follows the rules governing the \\(\\delta\\)\nfunction (such as using the \\(\\delta\\) function only under an integral\nsign, meaning in part not asking the value of a \\(\\delta\\) function at a\ngiven point), then no inconsistencies will arise. Second, the \\(\\delta\\)\nfunction can be eliminated, meaning that it can be replaced with a\nwell-defined mathematical expression. However, the drawback in that\ncase is, according to Dirac, that the substitution leads to a more\ncumbersome expression that obscures the argument. In short, when\npragmatics and rigor lead to the same conclusion, pragmatics trumps\nrigor due to the resulting simplicity, efficiency, and increase in\nunderstanding.  \n\nAs in the case of the notion of an infinitesimal, the Dirac \\(\\delta\\)\nfunction was eventually given a mathematically rigorous\nfoundation. That was done within Schwartz’s theory of distributions,\nwhich was later used in developing the notion of a rigged Hilbert\nspace. The theory of distributions was used to provide a mathematical\nframework for quantum field theory (Wightman 1964). The rigged Hilbert\nspace was used to do so for quantum mechanics (Böhm 1966) and\nthen for quantum field theory (Bogoluliubov et al. 1975). \n\nThe complementary approaches, rigor and pragmatics, which are\nexhibited in the development of quantum mechanics, later came about in\na more striking way in connection with the development of quantum\nelectrodynamics (QED) and, more generally, quantum field theory\n(QFT). The emphasis on rigor emerges in connection with two\nframeworks, algebraic QFT and Wightman’s axiomatic QFT. Algebraic QFT\nhas its roots in the work of von Neumann on operator algebras, which\nwas developed by him in an attempt to generalize the Hilbert space\nframework. Wightman’s axiomatic QFT has its roots in Schwartz’s theory\nof distributions, and it was later developed in the rigged Hilbert\nspace framework. Roughly, the basic distinction between the two\napproaches is that the algebra of operators is the basic mathematical\nconcept in algebraic QFT, while operator-valued distributions (the\nquantum analogues of field quantities) are fundamental in Wightman’s\naxiomatic QFT. It is worth noting that algebraic QFT is generally\nformulated axiomatically, and that it is just as deserving of the name\n“axiomatic” QFT. However, that term is often taken to refer\nspecifically to the approach based on operator-valued\ndistributions. To avoid any possible confusion, that approach is\nreferred to here as “Wightman’s axiomatic” QFT. The emphasis on\npragmatics arises most notably in Lagrangian QFT, which uses\nperturbation theory, path integrals, and renormalization\ntechniques. Although some elements of the theory were eventually\nplaced on a firmer mathematical foundation, there are still serious\nquestions about its being a fully rigorous approach on a par with\nalgebraic and Wightman’s axiomatic QFT. Nevertheless, it has been\nspectacularly successful in providing numerical results that are\nexceptionally accurate with respect to experimentally determined\nquantities, and in making possible expedient calculations that are\nunrivaled by other approaches. \n\nThe two approaches to QFT continue to develop in parallel. Fleming\n(2002, 135–136) brings this into focus in his discussion of\ndifferences between Haag’s Local Quantum Physics (1996) and\nWeinberg’s Quantum Field Theory (1995); Haag’s book presents\nalgebraic QFT, and Weinberg’s book presents Lagrangian QFT. While both\nbooks are ostensibly about the same subject, Haag gives a precise\nformulation of QFT and its mathematical structure, but does not\nprovide any techniques for connecting with experimentally determined\nquantities, such as scattering cross sections. Weinberg gives a\npragmatic formulation that engages with physical intuition and\nprovides heuristics that are important for performing calculations;\nhowever, it is not as mathematically rigorous. Moreover, there are a\nnumber of important topics that are examined in one book while not\neven mentioned in the other. For example, unitarily inequivalent\nrepresentations are discussed by Haag, but not by Weinberg. By\ncontrast, Weinberg discusses Feynman’s rules for path integrals, which\nare not mentioned at all by Haag. There is also the issue of\ndemographics. Most particle and experimental physicists will read and\nstudy Weinberg’s book, but very few will read Haag’s book. Because of\nthese differences, Fleming (2002, 136) suggests that one might\nquestion whether the two books are really about the same subject. This\ngives rise to the question whether any formulation of QFT is worthy of\nphilosophical attention to its foundations. In particular, there is a\ndebate between Wallace (2006, 2011) and Fraser (2009, 2011) over\nwhether an interpretation of QFT should be based on the standard\ntextbook treatment of QFT or an axiomatic formulation of QFT.  \n\nIn the late 1920s, von Neumann developed the separable Hilbert space\nformulation of quantum mechanics, which later became the definitive\none (from the standpoint of mathematical rigor, at least). In the\nmid-1930s, he worked extensively on lattice theory (see the entry\non\n quantum logic), \n rings of operators, and continuous geometries. Part of his\nexpressed motivation for developing these mathematical theories was to\ndevelop an appropriate framework for QFT and a better foundation for\nquantum mechanics. During this time, he noted two closely related\nstructures, modular lattices and finite type-II factors (a special\ntype of ring of operators), that have what he regarded as desirable\nfeatures for quantum theory. These observations led to his developing\na more general framework, continuous geometries, for quantum\ntheory. Matters did not work out as von Neumann had expected. He soon\nrealized that such geometries must have a transition probability\nfunction, if they are to be used to describe quantum mechanical\nphenomena, and that the resulting structure is not a generalization at\nall beyond the operator rings that were already available. Moreover,\nit was determined much later that the type-III factors are the most\nimportant type of ring of operators for quantum theory. In addition, a\nsimilar verdict was delivered much later with regards to his\nexpectations concerning lattice theory. The lattices that are\nappropriate for quantum theory are orthomodular — a lattice is\northomodular only if it is modular, but the converse is false. Of the\nthree mathematical theories, it is the rings of operators that have\nproven to be the most important framework for quantum theory. It is\npossible to use a ring of operators to model key features of physical\nsystems in a purely abstract, algebraic setting (this is discussed in\nsection 4.1). A related issue concerns whether it is necessary to\nchoose a representation of the ring in a Hilbert space; see Haag and\nKastler (1964), Ruetsche (2003), and Kronz and Lupher (2005) for\nfurther discussion of this issue. In any case, the separable Hilbert\nspace remains a crucial framework for quantum theory. The simplest\nexamples of separable Hilbert spaces are the finite dimensional ones,\nin which case the algebra of operators is a\ntype-I\\(_n\\) factor (n is a positive integer). The\noperators are n-by-n complex matrices, which are typically used to\ndescribe internal degrees of freedom such as spin. Readers wanting to\nfamiliarize themselves with these basic examples should consult the\nentry on\n quantum mechanics. \n\nMatrix mechanics and wave mechanics were formulated roughly around the\nsame time between 1925 and 1926. In July 1925, Heisenberg finished his\nseminal paper “On a Quantum Theoretical Interpretation of\nKinematical and Mechanical Relations”. Two months later, Born\nand Jordan finished their paper, “On Quantum Mechanics”,\nwhich is the first rigorous formulation of matrix mechanics. Two\nmonths after this, Born, Heisenberg, and Jordan finished “On\nQuantum Mechanics II”, which is an elaboration of the earlier\nBorn and Jordan paper; it was published in early 1926. These three\npapers are reprinted in van der Waerden (1967). Meanwhile,\nSchrödinger was working on what eventually became his four famous\npapers on wave mechanics. The first was received by Annalen der\nPhysik in January 1926, the second was received in February, and\nthen the third in May and the fourth in June. All four are reprinted\nin Schrödinger (1928). \n\nSchrödinger was the first to raise the question of the\nrelationship between matrix mechanics and wave mechanics in\nSchrödinger (1926), which was published in Annalen in\nspring 1926 between the publication of his second and third papers of\nthe famous four. This paper is also reprinted in Schrödinger\n(1928). It contains the germ of a mathematical equivalence proof, but\nit does not contain a rigorous proof of equivalency: the mathematical\nframework that Schrödinger associated with wave mechanics is a\nspace of continuous and normalizable functions, which is too small to\nestablish the appropriate relation with matrix mechanics. Shortly\nthereafter, Dirac and Jordan independently provided a unification of\nthe two frameworks. But their respective approaches required essential\nuse of \\(\\delta\\) functions, which were suspect from the standpoint of\nmathematical rigor. In 1927, von Neumann published three papers\nin Göttinger Nachrichten that placed quantum mechanics\non a rigorous mathematical foundation and included a rigorous proof\n(i.e., without the use of \\(\\delta\\) functions) of the equivalence of\nmatrix and wave mechanics. These papers are reprinted in von\nNeumann(1961–1963, Volume I, Numbers 8–10). In the preface\nto his famous 1932 treatise on quantum mechanics (von Neumann 1955),\nwhich is an elegant summary of the separable Hilbert space formulation\nof quantum mechanics that he provided in the earlier papers, he\nacknowledges the simplicity and utility of Dirac’s formulation\nof quantum mechanics, but finds it ultimately unacceptable. He\nindicates that he cannot endure the use of what could then only be\nregarded as mathematical fictions. Examples of these fictions include\nDirac’s assumption that every self-adjoint operator can be put\nin diagonal form and his use of \\(\\delta\\) functions, which von\nNeumann characterizes as “improper functions with\nself-contradictory properties”. His stated purpose is to\nformulate a framework for quantum mechanics that is mathematically\nrigorous. \n\nWhat follows is a brief sketch of von Neumann’s strategy. First, he\nrecognized the mathematical framework of matrix mechanics as what\nwould now be characterized as an infinite dimensional, separable\nHilbert space. Here the term “Hilbert space” denotes\na complete vector space with an inner product; von Neumann imposed the\nadditional requirement of separability (having a countable basis) in\nhis definition of a Hilbert space. He then attempted to specify a set\nof functions that would instantiate an (infinite-dimensional)\nseparable Hilbert space and could be identified with\nSchrödinger’s wave mechanics. He began with the space of\nsquare-integrable functions on the real line. To satisfy the\ncompleteness condition, that all Cauchy sequences of functions\nconverge (in the mean) to some function in that space, he specified\nthat integration must be defined in the manner of Lebesgue. To define\nan inner product operation, he specified that the set of Lebesgue\nsquare-integrable functions must be partitioned into equivalence\nclasses modulo the relation of differing on a set of measure\nzero. That the elements of the space are equivalence classes of\nfunctions rather than functions is sometimes overlooked, and it has\ninteresting ramifications for interpretive investigations. It has been\nargued in Kronz (1999), for example, that separable Hilbert space is\nnot a suitable framework for quantum mechanics under Bohm’s\nontological interpretation (also known as\n Bohmian mechanics). \n\nIn a letter to Birkhoff from 1935, von Neumann says: “I would\nlike to make a confession which may seem immoral: I do not believe in\nHilbert space anymore”; the letter is published in von Neumann\n(2005). The confession is indeed startling since it comes from the\nchampion of the separable Hilbert space formulation of quantum\nmechanics and it is issued just three years after the publication of\nhis famous treatise, the definitive work on the subject. The irony is\ncompounded by the fact that less than two years after his confession\nto Birkhoff, his mathematical theorizing about the abstract\nmathematical structure that was to supersede the separable Hilbert\nspace, continuous geometries with a transition probability, turned out\nnot to provide a generalization of the separable Hilbert space\nframework. It is compounded again with interest in that subsequent\ndevelopments in mathematical physics initiated and developed by von\nNeumann ultimately served to strengthen the entrenchment of the\nseparable Hilbert space framework in mathematical physics (especially\nwith regards to quantum theory). These matters are explained in more\ndetail in Section 4.1. \n\nThree theoretical developments come together for von Neumann in his\ntheory of continuous geometries during the seven years following 1932:\nthe algebraic approach to quantum mechanics, quantum logics, and rings\nof operators. By 1934, von Neumann had already made substantial moves\ntowards an algebraic approach to quantum mechanics with the help of\nJordan and Wigner — their article, “On an Algebraic\nGeneralization of the Quantum Mechanical Formalism”,  is\nreprinted in von Neumann (1961–1963, Vol. II, No. 21). In 1936, he\npublished a second paper on this topic, “On an Algebraic\nGeneralization of the  Quantum Mechanical Formalism (Part\nI)”, which is reprinted in von Neumann (1961–1963, Vol. III,\nNo. 9). Neither work was particularly influential, as it turns out. A\nrelated paper by von Neumann and Birkhoff, “The Logic of Quantum\nMechanics”, was also published in 1936, and it is reprinted in\nvon Neumann (1961–1963, Vol. IV, No. 7). It was seminal to the\ndevelopment of a sizeable body of literature on\n quantum logics.\nIt should be noted, however, that this happens only after modularity,\na key postulate for von Neumann, is replaced with orthomodularity (a\nweaker condition). The nature of the shift is clearly explained in\nHolland (1970): modularity is in effect a weakening of the\ndistributive laws (limiting their validity to certain selected triples\nof lattice elements), and orthomodularity is a weakening of modularity\n(limiting the validity of the distributive laws to an even smaller set\nof triples of lattice elements). The shift from modularity to\northomodularity was first made in (Loomis 1955). Rapid growth of\nliterature on orthomodular lattices and the foundations of quantum\nmechanics soon followed. For example, see Pavi&ccaron;i&cacute; (1992)\nfor a fairly exhaustive bibliography of quantum logic up to 1990,\nwhich has over 1800 entries. \n\nOf substantially greater note for the foundations of quantum theory\nare six papers by von Neumann (three jointly published with Murray) on\nrings of operators, which are reprinted in von Neumann (1961–1963,\nVol. III, Nos 2–7). The first two, “On Rings of Operators”\nand a sequel “On Rings of Operators II”, were published in\n1936 and 1937, and they were seminal to the development of the other\nfour. The third, “On Rings of Operators: Reduction\nTheory”, was written during 1937–1938 but not published until\n1949. The fourth, “On Infinite Direct Products”, was\npublished in 1938. The remaining two, “On Rings of Operators\nIII” and “On Rings of Operators IV” were published\nin 1941 and 1943, respectively. This massive work on rings of\noperators was very influential and continues to have an impact in pure\nmathematics, mathematical physics, and the foundations of\nphysics. Rings of operators are now referred to as “von Neumann\nalgebras” following Dixmier (1981), who first referred to them\nby this name (stating that he did so following a suggestion made to\nhim by Dieudonné) in the introduction to his 1957 treatise on operator\nalgebras (Dixmier 1981). \n\nA von Neumann algebra is a \\(*\\)-subalgebra of the set of bounded\noperators B(H) on a Hilbert space H that is closed in the weak\noperator topology. It is usually assumed that the von Neumann algebra\ncontains the identity operator. A \\(*\\)-subalgebra contains the\nadjoint of every operator in the algebra, where the\n“\\(*\\)” denotes the adjoint. There are special types of\nvon Neumann algebras that are called “factors”. A von\nNeumann algebra is a factor, if its center (which is the set of\nelements that commute with all elements of the algebra) is trivial,\nmeaning that it only contains scalar multiples of the identity\nelement. Moreover, von Neumann showed in his reduction-theory paper\nthat all von Neumann algebras that are not factors can be decomposed\nas a direct sum (or integral) of factors. There are three mutually\nexclusive and exhaustive factor types: type-I, type-II, and\ntype-III. Each type has been classified into (mutually exclusive and\nexhaustive) sub-types: types I\\(_n\\) \\((n = 1,2,\\ldots ,\\infty),\\)\nII\\(_n\\) \\((n = 1,\\infty),\\) III\\(_z\\) \\((0\\le z\\le 1).\\) As mentioned\nabove, type-I\\(_n\\) correspond to finite dimensional Hilbert spaces,\nwhile type-I\\(_{\\infty}\\) corresponds to the infinite dimensional\nseparable Hilbert space that provides the rigorous framework for wave\nand matrix mechanics. Von Neumann and Murray distinguished the\nsubtypes for type-I and type-II, but were not able to do so for the\ntype-III factors. Subtypes were not distinguished for these factors\nuntil the 1960s and 1970s — see Chapter 3 of Sunder (1987) or\nChapter 5 of Connes (1994) for details. \n\nAs a result of his earlier work on the foundations of quantum\nmechanics and his work on quantum logic with Birkhoff, von Neumann\ncame to regard the type-II\\(_1\\) factors as likely to be the\nmost relevant for physics. This is a substantial shift since the most\nimportant class of algebra of observables for quantum mechanics was\nthought at the time to be the set of bounded operators on an\ninfinite-dimensional separable Hilbert space, which is a\ntype-I\\(_{\\infty}\\) factor. A brief explanation for this shift is\nprovided below. See the well-informed and lucid account presented in\n(Rédei 1998) for a much fuller discussion of von Neumann’s\nviews on fundamental connections between quantum logic, rings of\noperators (particularly type-II\\(_1\\) factors), foundations of\nprobability theory, and quantum physics. It is worth noting that von\nNeumann regarded the type-III factors as a catch-all class for the\n“pathological” operator algebras; indeed, it took several\nyears after the classificatory scheme was introduced to demonstrate\nthe existence of such factors. It is ironic that the predominant view\nnow seems to be that the type-III factors are the most relevant class\nfor physics (particularly for QFT and quantum statistical\nmechanics). This point is elaborated further in Section 4.1 after\nexplaining below why von Neumann’s program never came to fruition. \n\nIn the introduction to the first paper in the series of four entitled\n“On Rings of Operators”, Murray and von Neumann list two\nreasons why they are dissatisfied with the separable Hilbert space\nformulation of quantum mechanics. One has to do with a property of the\ntrace operation, which is the operation appearing in the definition of\nthe probabilities for measurement results (the Born rule), and the\nother with domain problems that arise for unbounded observable\noperators. The trace of the identity is infinite when the separable\nHilbert space is infinite-dimensional, which means that it is not\npossible to define a correctly normalized a priori\nprobability for the outcome of an experiment (i.e., a measurement of\nan observable). By definition, the a priori probability for\nan experiment is that in which any two distinct outcomes are equally\nlikely. Thus, the probability must be zero for each distinct outcome\nwhen there is an infinite number of such outcomes, which can occur if\nand only if the space is infinite dimensional. It is not clear why von\nNeumann believed that it is necessary to have an a priori\nprobability for every experiment, especially since von Mises clearly\nbelieved that a priori probabilities (“uniform distributions” in his\nterminology) do not always exist (von Mises 1981, pp. 68 ff.) and von\nNeumann was influenced substantially by von Mises on the foundations\nof probability (von Neumann 1955, p. 198 fn.). Later, von Neumann\nchanged the basis for his expressed reason for dissatisfaction with\ninfinite dimensional Hilbert spaces from probabilistic to algebraic\nconsiderations (Birkhoff and von Neumann 1936, p. 118); namely, that\nit violates Hankel’s principle of the preservation of formal law,\nwhich leads one to try to preserve modularity — a condition that\nholds in finite-dimensional Hilbert spaces but not in\ninfinite-dimensional Hilbert spaces. The problem with unbounded\noperators arises from their only being defined on a merely dense\nsubset of the set elements of the space. This means that algebraic\noperations of unbounded operators (sums and products) cannot be\ngenerally defined; for example, it is possible that two unbounded\noperators \\(A\\), \\(B\\) are such that the range of \\(B\\)\nand the domain of \\(A\\) are disjoint, in which case the\nproduct \\(AB\\) is meaningless. \n\nThe problems mentioned above do not arise for type-I\\(_n\\) factors, if\n\\(n\\lt \\infty\\), nor do they arise for type-II\\(_1\\). That is to say,\nthese factor types have a finite trace operation and are not plagued\nwith the domain problems of unbounded operators. Particularly\nnoteworthy is that the lattice of projections of each of these factor\ntypes (type-I\\(_n\\) for \\(n\\lt \\infty\\) and type-II\\(_1)\\) is\nmodular. By contrast, the set of bounded operators on an\ninfinite-dimensional separable Hilbert space, a type-I\\(_{\\infty}\\)\nfactor, is not modular; rather, it is only orthomodular. These\nconsiderations serve to explain why von Neumann regarded the\ntype-II\\(_1\\) factor as the proper generalization of the type-I\\(_n\\)\n\\((n\\lt \\infty)\\) for quantum physics rather than the\ntype-I\\(_{\\infty}\\) factors. The shift in the literature from modular\nto orthomodular lattices that was characterized above is in effect a\nshift back to von Neumann’s earlier position (prior to his\nconfession). But, as was already mentioned, it now seems that this was\nnot the best move either. \n\nIt was von Neumann’s hope that his program for generalizing quantum\ntheory would emerge from a new mathematical structure known as\n“continuous geometry”. He wanted to use this structure to\nbring together the three key elements that were mentioned above: the\nalgebraic approach to quantum mechanics, quantum logics, and rings of\noperators. He sought to forge a strong conceptual link between these\nelements and thereby provide a proper foundation for generalizing\nquantum mechanics that does not make essential use of Hilbert space\n(unlike rings of operators). Unfortunately, it turns out that the\nclass of continuous geometries is too broad for the purposes of\naxiomatizing quantum mechanics. The class must be suitably restricted\nto those having a transition probability. It turns out that there is\nthen no substantial generalization beyond the separable Hilbert space\nframework. An unpublished manuscript that was finished by von Neumann\nin 1937 was prepared and edited by Israel Halperin, and then published\nas von Neumann (1981). A review of the manuscript by Halperin was\npublished in von Neumann (1961–1963, Vol. IV, No. 16) years before the\nmanuscript itself was published. In that review, Halperin notes the\nfollowing:  \n\nThis unfortunate development does not, however, completely undermine\nvon Neumann’s efforts to generalize quantum mechanics. On the\ncontrary, his work on rings of operators does provide significant\nlight to the way forward. The upshot of subsequent developments is\nthat von Neumann settled on the wrong factor type for the foundations\nof physics. \n\nDirac’s formal framework for quantum mechanics was very useful\nand influential despite its lack of mathematical rigor. It was used\nextensively by physicists and it inspired some powerful mathematical\ndevelopments in functional analysis. Eventually, mathematicians\ndeveloped a suitable framework for placing Dirac’s formal\nframework on a firm mathematical foundation, which is known as\na rigged Hilbert space (and is also referred to as\na Gelfand Triplet). This came about as follows. A rigorous\ndefinition of the \\(\\delta\\) function became possible in distribution\ntheory, which was developed by Schwartz from the mid-1940s to the\nearly 1950s. Distribution theory inspired Gelfand and collaborators\nduring the mid-to-late 1950s to formulate the notion of a rigged\nHilbert space, the firm foundation for Dirac’s formal\nframework. This development was facilitated by Grothendiek’s\nnotion of a nuclear space, which he introduced in the mid-1950s. The\nrigged Hilbert space formulation of quantum mechanics was then\ndeveloped independently by Böhm and by Roberts in 1966. Since\nthen, it has been extended to a variety of different contexts in the\nquantum domain including decay phenomena and the arrow of time. The\nmathematical developments of Schwartz, Gelfand, and others had a\nsubstantial effect on QFT as well. Distribution theory was taken\nforward by Wightman in developing the axiomatic approach to QFT from\nthe mid-1950s to the mid-1960s. In the late 1960s,  the axiomatic\napproach was explicitly put into the rigged Hilbert space framework by\nBogoliubov and co-workers. \n\nAlthough these developments were only indirectly influenced by Dirac,\nby way of the mathematical developments that are associated with his\nformal approach to quantum mechanics, there are other elements of his\nwork that had a more direct and very substantial impact on the\ndevelopment of QFT. In the 1930s, Dirac (1933) developed a Lagrangian\nformulation of quantum mechanics and applied it to quantum fields\n, and the latter inspired Feynman (1948) to develop the\npath-integral approach to QFT. The mathematical\nfoundation for path-integral functionals is still lacking (Rivers\n1987, pp, 109–134), though substantial progress has been made\n(DeWitt-Morette et al. 1979). Despite such shortcomings, it\nremains the most useful and influential approach to QFT to date. In\nthe 1940s, Dirac (1943) developed a form of quantum electrodynamics that\ninvolved an indefinite metric — see also Pauli\n(1943) in that connection. This had a substantial influence on later\ndevelopments, first in quantum electrodynamics in the early 1950s with\nthe Gupta-Bluer formalism, and in a variety of QFT models such as\nvector meson fields and quantum gravity fields by the late 1950s\n— see Chapter 2 of Nagy (1966) for examples and references. \n\nDirac’s attempt to prove the equivalence of matrix mechanics and wave\nmechanics made essential use of the \\(\\delta\\) function, as indicated\nabove. The \\(\\delta\\) function was used by physicists before Dirac, but it\nbecame a standard tool in many areas of physics only after Dirac very\neffectively put it to use in quantum mechanics. It then became widely\nknown by way of his textbook (Dirac 1930), which was based on a series\nof lectures on quantum mechanics given by Dirac at Cambridge\nUniversity. This textbook saw three later editions: the second in\n1935, the third in 1947, and the fourth in 1958. The fourth edition\nhas been reprinted many times. Its staying power is due, in part, to\nanother innovation that was introduced by Dirac in the third edition,\nhis bra-ket formalism. He first published this formalism in (Dirac\n1939), but the formalism did not become widely used until after the\npublication of the third edition of his book. There is no question\nthat these tools, first the \\(\\delta\\) function and then the bra-ket\nnotation, were extremely effective for physicists practicing and\nteaching quantum mechanics both with regards to setting up equations\nand to the performance of calculations. Most quantum mechanics\ntextbooks use \\(\\delta\\) functions and plane waves, which are key elements\nof Dirac’s formal framework, but they are not included in von\nNeumann’s rigorous mathematical framework for quantum\nmechanics. Working physicists as well as teachers and students of\nquantum mechanics often use Dirac’s framework because of its\nsimplicity, elegance, power, and relative ease of use. Thus, from the\nstandpoint of pragmatics, Dirac’s framework is much preferred over von\nNeumann’s. The notion of a rigged Hilbert space placed Dirac’s\nframework on a firm mathematical foundation. \n\nMathematicians worked very hard to provide a rigorous foundation for\nDirac’s formal framework. One key element was Schwartz’s\n(1945; 1950–1951) theory of distributions. Another key element,\nthe notion of a nuclear space, was developed by Grothendieck\n(1955). This notion made possible the generalized-eigenvector\ndecomposition theorem for self-adjoint operators in rigged Hilbert\nspace — for the theorem see Gelfand and Vilenken (1964,\npp. 119–127), and for a brief historical account of the\nconvoluted path leading to it see Berezanskii (1968,\npp. 756–760).  The decomposition principle provides a rigorous\nway to handle observables such as position and momentum in the manner\nin which they are presented in Dirac’s formal framework. These\nmathematical developments culminated in the early 1960s with Gelfand\nand Vilenkin’s characterization of a structure that they\nreferred to as a rigged Hilbert space (Gelfand and Vilenkin\n1964, pp. 103–127). It is unfortunate that their chosen name for\nthis mathematical structure is doubly misleading. First, there is a\nnatural inclination to regard it as denoting a type of Hilbert space,\none that is rigged in some sense, but this inclination must\nbe resisted. Second, the term rigged has an unfortunate\nconnotation of illegitimacy, as in the terms rigged election\nor rigged roulette table, and this connotation must be\ndismissed as prejudicial. There is nothing illegitimate about a rigged\nHilbert space from the standpoint of mathematical rigor (or any other\nrelevant standpoint). A more appropriate analogy may be drawn using\nthe notion of a rigged ship: the term rigged in this context\nmeans fully equipped. But this analogy has its limitations since a\nrigged ship is a fully equipped ship, but (as the first point\nindicates) a rigged Hilbert space is not a Hilbert space, though it is\ngenerated from a Hilbert space in the manner now to be described. \n\nA rigged Hilbert space is a dual pair of spaces\n\\((\\Phi , \\Phi^x)\\) that can generated from a\nseparable Hilbert space \\(\\Eta\\) using a sequence of norms (or\nsemi-norms); the sequence of norms is generated using a nuclear\noperator (a good approximate meaning is an operator of trace-class,\nmeaning that the trace of the modulus of the operator is finite). In\nthe mathematical theory of topological vector spaces, the space \\(\\Phi\\)\nis characterized in technical terms as a nuclear Fréchet\nspace. To say that \\(\\Phi\\) is a Fréchet space means\nthat it is a complete metric space, and to say that it\nis nuclear means that it is the projective limit of a\nsequence of Hilbert spaces in which the associated topologies get\nrapidly finer with increasing n (i.e., the convergence conditions are\nincreasingly strict); the term nuclear is used because the\nHilbert-space topologies are generated using a nuclear operator. In\ndistribution theory, the space \\(\\Phi\\) is characterized as a\ntest-function space, where a test-function is thought of as a very\nwell-behaved function (being continuous, n-times differentiable,\nhaving a bounded domain or at least dropping off exponentially beyond\nsome finite range, etc). \\(\\Phi^x\\) is a space of\ndistributions, and it is the topological dual of \\(\\Phi\\), meaning that\nit corresponds to the complete space of continuous linear functionals\non \\(\\Phi\\). It is also the inductive limit of a sequence of Hilbert\nspaces in which the topologies get rapidly coarser with increasing\nn. Because the elements of \\(\\Phi\\) are so well-behaved,\n\\(\\Phi^x\\) may contain elements that are not so\nwell-behaved, some being singular or improper functions (such as\nDirac’s \\(\\delta\\) function). \\(\\Phi\\) is the topological anti-dual of\n\\(\\Phi^x\\), meaning that it is the complete set of\ncontinuous anti-linear functionals on \\(\\Phi^x\\); it\nis anti-linear rather than linear because multiplication by a scalar\nis defined in terms of the scalar’s complex conjugate. \n\nIt is worth noting that neither \\(\\Phi\\) nor \\(\\Phi^x\\)\nis a Hilbert space in that each lacks an inner product that induces a\nmetric with respect to which the space is complete, though for each\nspace there is a topology with respect to which the space is\ncomplete. Nevertheless, each of them is closely related to the Hilbert\nspace \\(\\Eta\\) from which they are generated: \\(\\Phi\\) is densely embedded\nin \\(\\Eta\\), which in turn is densely embedded in\n\\(\\Phi^x\\). Two other points are worth noting. First,\ndual pairs of this sort can also be generated from a pre-Hilbert\nspace, which is a space that has all the features of a Hilbert space\nexcept that it is not complete, and doing so has the distinct\nadvantage of avoiding the partitioning of functions into equivalence\nclasses (in the case of functions spaces). The term rigged Hilbert\nspace is typically used broadly to include dual pairs generated\nfrom either a Hilbert space or a pre-Hilbert space. Second, the\nterm Gelfand triplet is sometimes used instead of the\nterm rigged Hilbert space, though it refers to the ordered\nset \\((\\Phi , \\Eta , \\Phi^x)\\), where \\(\\Eta\\)\nis the Hilbert space used to generate \\(\\Phi\\) and\n\\(\\Phi^x\\). \n\nThe dual pair \\((\\Phi , \\Phi^x)\\) possesses the means to represent\nimportant operators for quantum mechanics that are problematic in a\nseparable Hilbert space, particularly the unbounded operators that\ncorrespond to the observables position and momentum, and it does so in\na particularly effective and unproblematic manner. As already noted,\nthese operators have no eigenvalues or eigenvectors in a separable\nHilbert space; moreover, they are only defined on a dense subset of\nthe elements of the space and this leads to domain problems. These\nundesirable features also motivated von Neumann to seek an alternative\nto the separable Hilbert space framework for quantum mechanics, as\nnoted above. In a rigged Hilbert space, the\noperators corresponding to position and momentum can have a\ncomplete set of eigenfunctionals (i.e., generalized\neigenfunctions). The key result is known as the nuclear spectral\ntheorem (and it is also known as the Gelfand-Maurin theorem). One\nversion of the theorem says that if A is a symmetric linear operator\ndefined on the space \\(\\Phi\\) and it admits a self-adjoint extension\nto the Hilbert space H, then A possesses a complete system of\neigenfunctionals belonging to the dual space \\(\\Phi^x\\) (Gelfand and\nShilov 1977, chapter 4). That is to say, provided that the stated\ncondition is satisfied, A can be extended by duality to \\(\\Phi^x\\),\nits extension \\(A^x\\) is continuous on \\(\\Phi^x\\) (in the operator\ntopology in \\(\\Phi^x)\\), and \\(A^x\\) satisfies a completeness relation\n(meaning that it can be decomposed in terms of its eigenfunctionals\nand their associated eigenvalues). The duality formula for extending\n\\(A\\) to \\(\\Phi^x\\) is \\(\\braket{\\phi}{A^x\\kappa} =\n\\braket{A\\phi}{\\kappa}\\), for all \\(\\phi \\in \\Phi\\) and for all\n\\(\\kappa \\in \\Phi^x\\). The completeness relation says that for all\n\\(\\phi ,\\theta \\in \\Phi\\): \n\nwhere \\(v(A)\\) is the set of all generalized eigenvalues of \\(A^x\\)\n(i.e., the set of all scalars \\(\\lambda\\) for which there is \\(\\lambda\n\\in \\Phi^x\\) such that \\(\\braket{\\phi}{A^x\\lambda} = \\lambda\n\\braket{\\phi}{\\lambda}\\) for all \\(\\phi \\in \\Phi)\\). \n\nThe rigged Hilbert space representation of these observables is about\nas close as one can get to Dirac’s elegant and extremely useful formal\nrepresentation with the added feature of being placed within a\nmathematically rigorous framework. It should be noted, however, that\nthere is a sense in which it is a proper generalization of Dirac’s\nframework. The rigging (based on the choice of a nuclear operator that\ndetermines the test function space) can result in different sets of\ngeneralized eigenvalues being associated with an operator. For\nexample, the set of (generalized) eigenvalues for the momentum\noperator (in one dimension) corresponds to the real line, if the space\nof test functions is the set \\(S\\) of infinitely differentiable\nfunctions of \\(x\\) which together with all derivatives vanish\nfaster than any inverse power of \\(x\\) as \\(x\\) goes to\ninfinity, whereas its associated set of eigenvalues is the complex\nplane, if the space of test functions is the set \\(D\\) of\ninfinitely differentiable functions with compact support (i.e.,\nvanishing outside of a bounded region of the real line). If complex\neigenvalues are not desired, then \\(S\\) would be a more\nappropriate choice than \\(D\\) — see Nagel (1989) for a\nbrief discussion. But there are situations in which it is desirable\nfor an operator to have complex eigenvalues. This is so, for example,\nwhen a system exhibits resonance scattering (a type of decay\nphenomenon), in which case one would like the Hamiltonian to have\ncomplex eigenvalues — see Böhm & Gadella (1989). (Of\ncourse, it is impossible for a self-adjoint operator to have complex\neigenvalues in a Hilbert space.) \n\nSoon after the development of the theory of rigged Hilbert spaces by\nGelfand and his associates, the theory was used to develop a new\nformulation of quantum mechanics. This was done independently by\nBöhm (1966) and Roberts (1966). It was later demonstrated that\nthe rigged Hilbert space formulation of quantum mechanics can handle a\nbroader range of phenomena than the separable Hilbert space\nformulation. That broader range includes scattering resonances and\ndecay phenomena (Böhm and Gadella 1989), as already\nnoted. Böhm (1997) later extended this range to include a quantum\nmechanical characterization of the arrow of time. The Prigogine school\ndeveloped an alternative characterization of the arrow of time using\nthe rigged Hilbert space formulation of quantum mechanics (Antoniou\nand Prigogine 1993). Kronz (1998, 2000) used this formulation to\ncharacterize quantum chaos in open quantum systems. Castagnino and\nGadella (2003) used it to characterize\n decoherence\nin closed quantum systems. \n\nIn 1943, Gelfand and Neumark published an important paper on an\nimportant class of normed rings, which are now known as abstract\n\\(C^*\\)-algebras. Their paper was influenced by Murray and von\nNeumann’s work on rings of operators, which was discussed in the\nprevious section. In their paper, Gelfand and Neumark focus attention\non abstract normed \\(*\\)-rings. They show that any \\(C^*\\)-algebra can\nbe given a concrete representation in a Hilbert space (which need not\nbe separable). That is to say, there is an isomorphic mapping of the\nelements of a \\(C^*\\)-algebra into the set of bounded operators of the\nHilbert space. Four years later, Segal (1947a) published a paper that\nserved to complete the work of Gelfand and Neumark by specifying the\ndefinitive procedure for constructing concrete (Hilbert space)\nrepresentations of an abstract \\(C^*\\)-algebra. It is called the GNS\nconstruction (after Gelfand, Neumark, and Segal). That same year,\nSegal (1947b) published an algebraic formulation of quantum mechanics,\nwhich was substantially influenced by (though deviating somewhat from)\nvon Neumann’s (1963, Vol. III, No. 9) algebraic formulation of\nquantum mechanics, which is cited in the previous section. It is worth\nnoting that although \\(C^*\\)-algebras satisfy Segal’s\npostulates, the algebra that is specified by his postulates is a more\ngeneral structure known as a Segal algebra. Every \\(C^*\\)-algebra is a\nSegal algebra, but the converse is false since Segal’s\npostulates do not require an adjoint operation to be defined. If a\nSegal algebra is isomorphic to the set of all self-adjoint elements of\na \\(C^*\\)-algebra, then it is a special or exceptional Segal\nalgebra. Although the mathematical theory of Segal algebras has been\nfairly well developed, a \\(C^*\\)-algebra is the most important type of\nalgebra that satisfies Segal’s postulates. \n\nThe algebraic formulations of quantum mechanics that were developed by\nvon Neumann and Segal did not change the way that quantum mechanics\nwas done. Nevertheless, they did have a substantial impact in two\nrelated contexts: QFT and quantum statistical mechanics. The key\ndifference leading to the impact has to do with the domain of\napplicability. The domain of quantum mechanics consists of finite\nquantum systems, meaning quantum systems that have a finite number of\ndegrees of freedom. Whereas in QFT and quantum statistical mechanics,\nthe systems of special interest — i.e., quantum fields and\nparticle systems in the thermodynamic limit, respectively — are\ninfinite quantum systems, meaning quantum systems that have an\ninfinite number of degrees of freedom. Dirac (1927) was the first to\nrecognize the importance of infinite quantum systems for QFT, which is\nreprinted in Schwinger (1958). \n\nSegal (1959, p. 5) was the first to suggest that the beauty and power of the\nalgebraic approach becomes evident when working with an infinite\nquantum system . The key advantage of the algebraic\napproach, according to Segal (1959, pp. 5–6), is that one may work in\nthe abstract algebraic setting where it is possible to obtain\ninteracting fields from free fields by an automorphism on the algebra,\none that need not be unitarily implementable. Segal notes (1959, p. 6)\nthat von Neumann (1937) had a similar idea (that field dynamics are to be\nexpressed as an automorphism on the algebra) in an unpublished\nmanuscript. Segal notes this advantage in response\nto a result obtained by Haag (1955), that field theory representations\nof free fields are unitarily inequivalent to representations of\ninteracting fields. Haag mentions that von Neumann (1938) first discovered\n‘different’ (unitarily inequivalent) representations much\nearlier. A different way of approaching\nunitarily equivalent representations, by contrast with Segal’s\napproach, was later presented by Haag and Kastler (1964), who argued\nthat unitarilty inequivalent representations are physically\nequivalent. Their notion of physical equivalence was based on Fell’s\nmathematical idea of weak equivalence (Fell 1960). \n\nAfter indicating important similarities between his and von Neumann’s\napproaches to infinite quantum systems, Segal draws an important\ncontrast that serves to give the advantage to his approach over von\nNeumann’s. The key mathematical difference, according to Segal, is\nthat von Neumann was working with a weakly closed ring of operators\n(meaning that the ring of operators is closed with respect to the weak\noperator topology), whereas Segal is working with a uniformly closed\nring of operators (closed with respect to the uniform topology). It is\ncrucial because it has the following interpretive significance, which\nrests on operational considerations: \n\nInitially, it appeared that Segal’s assessment of the relative\nmerits of von Neumann algebras and \\(C^*\\)-algebras with respect to\nphysics was substantiated by a seminal paper, (Haag and Kastler\n1964). Among other things, Haag and Kastler introduced the key axioms\nof the algebraic approach to QFT. They also argued that unitarily\ninequivalent representations are “physically equivalent”\nto each other. However, the use of physical equivalence to show that\nunitarily inequivalent representations are not physically significant\nhas been challenged; see Kronz and Lupher (2005), Lupher (2018), and\nRuetsche (2011). The prominent role of type-III factor von Neumann\nalgebras within the algebraic approach to quantum statistical\nmechanics and QFT raises further doubts about Segal’s\nassessment. \n\nThe algebraic approach has proven most effective in quantum\nstatistical mechanics. It is extremely useful for characterizing many\nimportant macroscopic quantum effects including crystallization,\nferromagnetism, superfluidity, structural phase transition,\nBose-Einstein condensation, and superconductivity. A good introductory\npresentation is Sewell (1986), and for a more advanced discussion see\nBratteli and Robinson (1979, 1981). In algebraic quantum statistical\nmechanics, an infinite quantum system is defined by specifying an\nabstract algebra of observables. A particular state may then be used\nto specify a concrete representation of the algebra as a set of\nbounded operators in a Hilbert space. Among the most important types\nof states that are considered in algebraic statistical mechanics are\nthe equilibrium states, which are often referred to as “KMS\nstates” (since they were first introduced by the physicists\nKubo, Martin, and Schwinger). There is a continuum of KMS states since\nthere is at least one KMS state for each possible temperature value\n\\(\\tau\\) of the system, for\n\\(0\\le \\tau \\le +\\infty\\). Given an automorphism\ngroup, each KMS state corresponds to a representation of the algebra\nof observables that defines the system, and each of these\nrepresentations is unitarily inequivalent to any other. It turns out\nthat each representation that corresponds to a KMS state is a factor:\nif \\(\\tau = 0\\) then it is a type-I factor, if\n\\(\\tau = +\\infty\\) then it is a type-II factor, and if\n\\(0\\lt \\tau \\lt +\\infty\\) then it is a type-III\nfactor. Thus, type-III factors play a predominant role in algebraic\nquantum statistical mechanics.  \n\nIn algebraic QFT, an algebra of observables is associated with bounded\nregions of Minkowski spacetime (and unbounded regions including all of\nspacetime by way of certain limiting operations) that are required to\nsatisfy standard axioms of local structure: isotony, locality,\ncovariance, additivity, positive spectrum, and a unique invariant\nvacuum state. The resulting set of algebras on Minkowski spacetime\nthat satisfy these axioms is referred to as the net of local\nalgebras. It has been shown that special subsets of the net of\nlocal algebras — those corresponding to various types of\nunbounded spacetime regions such as tubes, monotones (a tube that\nextends infinitely in one direction only), and wedges — are\ntype-III factors. Of particular interest for the foundations of\nphysics are the algebras that are associated with bounded spacetime\nregions, such as a double cone (the finite region of intersection of a\nforward and a backward light cone). As a result of work done over the\nlast thirty years, local algebras of relativistic QFT appear to be\ntype III von Neuman algebras see Halvorson (2007, pp. 749–752)\nfor more details.  \n\nOne important area for interpretive investigation is the existence of\na continuum of unitarily inequivalent representations of an algebra of\nobservables. Attitudes towards unitarily inequivalent representations\ndiffer drastically in the philosophical literature. In (Wallace 2006)\nunitarily inequivalent representations are not considered a\nfoundational problem for QFT, while in Ruetsche (2011), Lupher (2018) and Kronz and\nLupher (2005) unitarily inequivalent representations are considered\nphysically significant. \n\nIn the early 1950s, theoretical physicists were inspired to axiomatize\nQFT. One motivation for axiomatizing a theory, not the one for the\ncase now under discussion, is to express the theory in a completely\nrigorous form in order to standardize the expression of the theory as\na mature conceptual edifice. Another motivation, more akin to the case\nin point, is to embrace a strategic withdrawal to the foundations to\ndetermine how renovation should proceed on a structure that is\nthreatening to collapse due to internal inconsistencies. One then\nlooks for existing piles (fundamental postulates) that penetrate\nthrough the quagmire to solid rock, and attempts to drive home others\nat advantageous locations. Properly supported elements of the\nsuperstructure (such as the characterization of free fields,\ndispersion relations, etc.) may then be distinguished from those that\nare untrustworthy. The latter need not be razed immediately, and may\nultimately glean supportive rigging from components not yet\nconstructed. In short, the theoretician hopes that the axiomatization\nwill effectively separate sense from nonsense, and that this will\nserve to make possible substantial progress towards the development of\na mature theory. Grounding in a rigorous mathematical framework can be\nan important part of the exercise, and that was a key aspect of the\naxiomatization of QFT by Wightman. \n\nIn the mid-1950s, Schwartz’s theory of distributions was used by\nWightman (1956) to develop an abstract formulation of QFT, which later\ncame to be known known as axiomatic quantum field\ntheory. Mature statements of this formulation are presented in\nWightman and Gårding (1964) and in Streater and Wightman\n(1964). It was further refined in the late 1960s by Bogoliubov, who\nexplicitly placed axiomatic QFT in the rigged Hilbert space framework\n(Bogoliubov et al. 1975, p. 256). It is by now standard\nwithin the axiomatic approach to put forth the following six\npostulates: spectral condition (there are no negative energies or\nimaginary masses), vacuum state (it exists and is unique), domain\naxiom for fields (quantum fields correspond to operator-valued\ndistributions), transformation law (unitary representation in the\nfield-operator (and state) space of the restricted inhomogeneous\nLorentz group — “restricted” means inversions are\nexcluded, and “inhomogeneous” means that translations are\nincluded), local commutativity (field measurements at spacelike\nseparated regions do not disturb one another), asymptotic completeness\n(the scattering matrix is unitary — this assumption is sometimes\nweakened to cyclicity of the vacuum state with respect to the\npolynomial algebra of free fields). Rigged Hilbert space entered the\naxiomatic framework by way of the domain axiom, so this axiom will be\ndiscussed in more detail below. \n\nIn classical physics, a field is is characterized as a scalar- (or\nvector- or tensor-) valued function \\(\\phi(x)\\) on a domain that\ncorresponds to some subset of spacetime points. In QFT, a field is\ncharacterized by means of an operator rather than a\nfunction. A field operator may be obtained from a classical\nfield function by quantizing the function in the canonical manner\n— see Mandl (1959, pp. 1–17). For convenience, the field\noperator associated with \\(\\phi(x)\\) is denoted below by the same\nexpression (since the discussion below only concerns field\noperators). Field operators that are relevant for QFT are too singular\nto be regarded as realistic, so they are smoothed out over their\nrespective domains using elements of a space of well-behaved functions\nknown as test functions. There are many different\ntest-functions spaces (Gelfand and Shilov 1977, Chapter 4). At first,\nthe test-function space of choice for axiomatic QFT was\nthe Schwartz space \\(\\Sigma\\), the space of functions whose\nelements have partial derivatives of all orders at each point and such\nthat each function and its derivatives decreases faster than\n\\(x^{-n}\\) for any \\(n\\in N\\) as \\(x\\rightarrow \\infty\\). It was later\ndetermined that some realistic models require the use of other\ntest-function spaces. The smoothed field operators \\(\\phi[f\\)] for \\(f\n\\in \\Sigma\\) are known as quantum field operators, and they\nare defined as follows  \n\nThe integral (over the domain of the field operator) of the product of\nthe test function \\(f(x)\\) and the field operator \\(\\phi(x)\\) serves\nto “smooth out” the field operator over its domain; a more\ncolloquial description is that the field is “smeared out”\nover space or spacetime. It is postulated within the axiomatic\napproach that a quantum field operator \\(\\phi[f\\)] may be represented\nas an unbounded operator on a separable Hilbert space \\(\\Eta\\), and\nthat \\(\\{\\phi[f]: f\\in \\Sigma \\}\\) (the set of smoothed field\noperators associated with \\(\\phi(x))\\) has a dense domain \\(\\Omega\\)\nin \\(\\Eta\\). The smoothed field operators are often referred to\nas operator-valued distributions, and this means that for\nevery \\(\\Phi,\\Psi \\in \\Omega\\) there is an element of the space of\ndistributions \\(\\Sigma^x\\), the topological dual of \\(\\Sigma\\), that\nmay be equated to the expression \\(\\langle \\Phi {\\mid} \\phi[\\\n]{\\mid}\\Psi\\rangle\\). If \\(\\Omega'\\) denotes the set of functions\nobtained by applying all polynomials of elements of \\(\\{\\phi[f]: f\\in\n\\Sigma \\}\\) onto the unique vacuum state, then the axioms mentioned\nabove entail that \\(\\Omega'\\) is dense in \\(\\Eta\\) (asymptotic\ncompleteness) and that \\(\\Omega'\\subset \\Omega\\) (domain\naxiom). The elements of \\(\\Omega\\) correspond to possible states of\nthe elements of \\(\\{\\phi[f]: f\\in \\Sigma \\}\\). Though only one field\nhas been considered thus far, the formalism is easily generalizable to\na countable number of fields with an associated set of countably\nindexed field operators \\(\\phi_k (x)\\) — cf. (Streater and\nWightman 1964). \n\nAs noted earlier, the appropriateness of the rigged Hilbert space\nframework enters by way of the domain axiom. Concerning that axiom,\nWightman says the following (in the notation introduced above, which\ndiffers slightly from that used by Wightman). \n\nIn Bogoliubov et al. (1975, p. 256), a topology is introduced\nto serve this role, though it is introduced on \\(\\Omega'\\) rather than\non \\(\\Omega\\). Shortly thereafter, they assert that it is not hard to\nshow that \\(\\Omega'\\) is a complete nuclear space with respect to this\ntopology. This serves to justify a claim they make earlier in their\ntreatise: \n\nNote that they refer to the triplet \\(\\Omega \\subset \\Eta \\subset\n\\Omega^*\\) as a rigged Hilbert space. In the terminology introduced\nabove, they refer in effect to the Gelfand triplet \\((\\Omega , \\Eta ,\n\\Omega^x )\\) or (equivalently) the associated rigged Hilbert space\n\\((\\Omega , \\Omega^x)\\) . \n\nFinally, it is worth mentioning that the status of the field in\nalgebraic QFT differs from that in Wightman’s axiomatic QFT. In both\napproaches, a field is an abstract system having an infinite number of\ndegrees of freedom. Sub-atomic quantum particles are field effects\nthat appear in special circumstances. In algebraic QFT, there is a\nfurther abstraction: the most fundamental entities are the elements of\nthe algebra of local (and quasi-local) observables, and the field is a\nderived notion. The term local means bounded within a finite\nspacetime region, and an observable is not regarded as a property\nbelonging to an entity other than the spacetime region itself. The\nterm quasi-local is used to indicate that we take the union\nof all bounded spacetime regions. In short, the algebraic approach\nfocuses on local (or quasi-local) observables and treats the notion of\na field as a derivative notion; whereas the axiomatic approach (as\ncharacterized just above) regards the field concept as the fundamental\nnotion. Indeed, it is common practice for proponents of the algebraic\napproach to distance themselves from the field notion by referring to\ntheir theory as “local quantum physics”. The two\napproaches are mutually complementary — they have developed\nin parallel and have influenced each other by analogy (Wightman\n1976). For a discussion of the close connections between these two\napproaches, see Haag (1996, p. 106). \n\nMost physicists use Lagrangian QFT (LQFT) to make predictions that\nhave been experimentally verified with extraordinary precision in some\ncases. However, LQFT has been described as a “grab bag of conflicting\nmathematical ideas” that has not provided a sharp mathematical\ndescription of what counts as a QFT model (Swanson 2017, pp. 1–2). Those\ncriticisms motivated mathematically inclined physicists to search for\na mathematically rigorous formulation of QFT. Axiomatic versions of\nQFT have been favored by mathematical physicists and most\nphilosophers. With greater mathematical rigor it is possible to prove\nresults about the theoretical structure of QFT independent of any\nparticular Lagrangian. Axiomatic QFT provides clear conceptual\nframeworks within which precise questions and answers to\ninterpretational issues can be formulated. There are three main\naxiomatic frameworks for QFT: Wightman QFT, Osterwalder-Schrader QFT,\nand algebraic QFT. In Wightman QFT, the axioms use functional analysis\nand operator algebras and is closer to LQFT since its axioms describe\ncovariant field operators acting on a fixed Hilbert space. The\nOsterwalder-Schrader axioms use a functional integration approach to\nQFT. The algebraic QFT axioms use \\(C^*\\)-algebras to model local\nobservables. However, axiomatic QFT approaches are sorely lacking with\nregards to building empirically adequate models. Unlike quantum\nmechanics which has a canonical mathematical framework in terms of von\nNeumann’s Hilbert space formulation, QFT has no canonical mathematical\nframework. Even though there is a canonical mathematical framework for\nquantum mechanics, there are many interpretations of that framework,\ne.g., many-worlds, GRW, Copenhagen, Bohmian, etc... QFT has two levels\nthat require interpretation: (1) which QFT framework should be the\nfocus of these foundational efforts, if any, and (2) how that\npreferred framework should be interpreted. Since (1) involves issues\nabout mathematical rigor and pragmatic virtues, it directly bears on\nthe focus of this article. The lack of a canonical formulation of QFT\nthreatens to impede any metaphysical or epistemological lessons that\nmight be learned from QFT. \nOne view is that these two approaches to QFT, the mathematically\nrigorous axiomatic approach and the pragmatic / empirically adequate\nLQFT approach, are rival research programs (see David Wallace (2006,\n2011) and Doreen Fraser (2009, 2011)), though Swanson (2017) argues\nthat they are not rival programs. Fraser (2009, 2011) argues that the\ninterpretation of QFT should be based on the mathematically rigorous\napproach of axiomatic formulations of QFT. By contrast, Wallace (2006,\n2011) argues that an interpretation of QFT should be based on LQFT.\n(Wallace, in 2006, calls his preferred QFT framework conventional QFT\n(CQFT), but changes his terminology to LQFT in Wallace 2011). Swanson\n(2017) and Egg, Lam, and Oldofedi (2017) are good overviews of the\ndebate between Fraser and Wallace (for an extended analysis see James\nFraser 2016). The debate covers many different philosophical topics in\nQFT, which makes it more challenging to pin down exactly what is\nessential to the arguments for both sides (for one view of what is\nessential for the debate, see Egg, Lam, and Oldofedi 2017). One issue\nis the role of internal consistency established by mathematical rigor\nversus empirical adequacy. Wallace argues that LQFT is empirically\nadequate since it can describe the forces of the Standard Model. LQFT\nhas a collection of calculational techniques including perturbation\ntheory, path integrals, and renormalization group methods. One\ncriticism of LQFT is that the calculational techniques it uses are not\nmathematically rigorous. Wallace argues that renormalization group\nmethods puts perturbative QFT, an approach within LQFT, on\nmathematically rigorous ground and removes the main motivation for\naxiomatic QFT. \nWhat follows is a rough overview of perturbative QFT (see James Fraser\n2016 for more details). Since exactly solvable free QFT models are\nmore mathematically tractable than interacting QFT models,\nperturbative QFT treats interactions as perturbations to the free\nLagrangian assuming weak coupling. For strongly coupled theories like\nquantum chromodynamics that idealization fails. Using perturbation\ntheory, approximate solutions for interacting QFT models can be\ncalculated by expanding S-matrix elements in a power series in terms\nof a coupling parameter. However, the higher order terms will often\ncontain divergent integrals. Typically, renormalization of the higher\norder terms is required to get finite predictions. Two sources of\ndivergent integrals are infrared (long distance, low energy) and\nultraviolet (short distance, high energy) divergences. Infrared\ndivergences are often handled by imposing a long distance cutoff or\nputting a small non-zero lower limit for the integral over momentum. A\nsharp cutoff at low momentum is equivalent to putting the theory in a\nfinite volume box. Imposing asymptotic boundary conditions and\nrestricting the observables to long distance “friendly” observables\nalso help with infrared divergences. Ultraviolet divergences are often\nhandled by imposing a momentum cutoff to remove high momentum modes of\na theory. That is equivalent to freezing out variations in the fields\nat arbitrarily short length scales. Putting the system on a lattice\nwith some finite spacing can also help deal with the high\nmomentum. Dimensional regularization, where the integral measure is\nredefined to range over a fractional number of dimensions, can help\nwith both infrared and ultraviolet divergences. The last step in\nrenormalization is to remove the cutoffs by taking the continuum limit\n(i.e., removing the high momentum cutoff) and the infinite volume\nlimit (i.e., removing the low momentum cutoff). The hope is that the\nlimit is well-defined and there are finite expressions of the series\nat each order.  \nJames Fraser (2016) identifies three problems for perturbative\nQFT. (1) The rigor problem: perturbative QFT is not\nmathematically rigorous which makes it difficult to analyze and\ninterpret. (2) The consistency problem: perturbative\ncalculations rest on the interaction picture existing, but Haag’s\ntheorem seems to show that the interaction picture does not\nexist. (3) The justification problem: renormalization lacks\nphysical motivation and appears ad hoc. James Fraser argues that (1)\nand (2) do not pose severe problems for perturbative QFT because it is\nnot attempting to build continuum QFT models. It is building\napproximate physical quantities – not mathematical structures that are\nto be interpreted as physical systems.\n \nBaker (2016) and Swanson (2017) note that LQFT makes false or unproven\nassumptions such as the convergence of certain infinite sums in\nperturbation theory. Dyson (1952) gives a heuristic argument that\nquantum electrodynamic perturbation series do not converge. Baker and\nSwanson also argue that the use of long distance cutoffs is at odds\nwith cosmological theory and astronomical observations which suggest\nthat the universe is spatially infinite. Even in the weak coupling\nlimit where perturbation theory can be formally applied, it is not\nclear when the perturbative QFT gives an accurate approximation of the\nunderlying physics. In the interacting \\(\\phi^4\\) theory, when the\ndimension is less than 4 for Minkowski spacetime, the theory is\nnontrivial, but when the dimension is greater than 4, the renormalized\nperturbation series is asymptotic to a free field theory even though\nit appears to describe nontrivial interactions. When there are 4\ndimensions, the theory is also trivial if additional technical\nassumptions hold (see Swanson 2017 (p. 3) for more details).   Another area where questions of mathematical rigor arise within\nperturbative QFT is the use of path integrals. The S-matrix power\nseries expansion contains integrals over momentum space and this is\nwhere path integrals / Feynman diagrams have been helpful for making\ncalculations. The key concept is the partition function \\(Z\\),\nwhich is defined as a functional integral involving the action, which\nis itself an integral of the Lagrangian. The following details come\nmainly from Hancox-Li (2017). More specifically, the action is a\nfunctional of quantum fields. The functional integral over the action\nranges over all possible combinations of the quantum fields values\nover spacetime. Informally, the sum is being taken over all possible\nfield configurations. As Swanson (2017) notes, the path integral\nrequires choosing a measure over an infinite dimensional path space,\nwhich is only mathematically well-defined in special cases. For\nexample, if the system is formulated on a hypercubic lattice, then the\nmeasure can be defined (see section 1.2 of James Fraser\n2016). Another way of having a well-defined measure is to restrict\nattention to a finite dimensional subspace. But if functions are\nallowed to vary arbitrarily on short length scales, then the integral\nceases to be well-defined (Wallace 2006, p. 42). All of the correlation\nfunctions (i.e., vacuum state expectation values of the fields at\ndifferent spacetime points), can be derived from the partition\nfunction \\(Z\\). So, given \\(Z\\), all empirical quantities\nassociated with the Lagrangian can be calculated, e.g., scattering\ncross-sections. Finding \\(Z\\) amounts to a solution of\nLQFT. \\(Z\\) can be expanded in a Taylor series in the coupling\nconstant. When this is done, two types of divergences can occur: (1)\nindividual terms of the perturbation series can diverge and/or (2) the\nperturbation series itself is divergent, though the series may be an\nasymptotic series. To deal with (1), physicists do the following\nprocedures (Hancox-Li 2017, pp. 344-345): (i) regularization, which involves\nreducing the number of degrees of freedom via dimensional\nregularization, momentum cutoffs, or using a lattice formulation and\n(ii) add counterterms to compensate for the regularization in (i). But\nthis construction is purely formal and not mathematically defined. The\nrules used to manipulate the Lagrangian, and hence the partition\nfunction, are not well-defined.\n  Wallace (2011) argues that renormalization group techniques have\novercome the mathematical deficiencies of older renormalization\ncalculational techniques (for more details on the renormalization\ngroup see Butterfield and Bouatta 2015, Fraser 2016, Hancox-Li (2015a,\n2015b, 2017)). According to Wallace, the renormalization group methods\nput LQFT on the same level of mathematical rigor as other areas of\ntheoretical physics. It provides a solid theoretical framework that is\nexplanatorily rich in particle physics and condensed matter physics,\nso the impetus for axiomatic QFT has been resolved. Renormalization\ngroup techniques presuppose that QFT will fail at some short length\nscale, but the empirical content of LQFT is largely insensitive to the\ndetails at such short length scales. Doreen Fraser (2011) argues that\nrenormalization group methods help articulate the empirical content of\nQFT, but the renormalization group has no significance for the\ntheoretical content of QFT insofar as it does not tell us whether we\nshould focus on LQFT or AQFT. James Fraser (2016) and Hancox-Li\n(2015b) argue that the renormalization group does more than provide\nempirical predictions in QFT. The renormalization group gives us\nmethods for studying the behavior of physical systems at different\nenergy scales, namely how properties of QFT models depend or do not\ndepend on small scale structure. The renormalization group provides a\nnon-perturbative explanation of the success of perturbative\nQFT. Hancox-Li (2015b) discusses how mathematicians working in\nconstructive QFT use non-perturbative approximations with well\ncontrolled error bounds to prove the existence or non-existence of\nultraviolet fixed points. Hancox-Li argues that the renormalization\ngroup explains perturbative renormalization non-perturbatively. The\nrenormalization group can tell us whether certain Lagrangians have an\nultraviolet limit that satisfies the axioms a QFT should\nsatisfy. Thus, the use of the renormalization group in constructive\nQFT can provide additional dynamical information (e.g., whether a\ncertain dynamics can occur in continuous spacetime) that a pure\naxiomatic approach does not.\n  \nEgg, Lam, and Oldofedi (2017) argue that the main disagreement\nbetween Doreen Fraser and David Wallace is over the very definition of\nQFT. Fraser takes QFT to be the union of quantum theory and special\nrelativity. If QFT = QM + SR as Fraser maintains, then LQFT fails to\nsatisfy that criterion since it employs cutoffs which violate Poincaré\ncovariance. For Wallace, the violation of QFT Poincaré\ncovariance is not as worrisome. QFT is not a truly\nfundamental theory since gravity is absent. Wallace is more interested\nin what QFT’s approximate truth tells us about the world. LQFT gives\nus an effective ontology. The renormalization group tell us that QFT\ncannot be trusted in the high energy regimes where quantum gravity can\nbe expected to apply, i.e., the Planckian length scale where\ngravitational effects cannot be ignored. The violation of Poincaré\ncovariance via cutoffs may not amount to much if the fundamental\nquantum theory of gravity imposes some real cutoff, according to\nWallace. There are, however, other options to consider.  \nSome philosophers have rejected the seemingly either-or nature of\nthe debate between Wallace and Fraser to embrace more pluralistic\nviews. On these pluralistic views, different formulations of QFT might\nbe appropriate for different philosophical questions. Baker (2016)\nadvocates that AQFT or LQFT should be trusted in domains of inquiry\nwhere their idealizations are unproblematic. For example, if the\ndomain to be interpreted is the Standard Model, then LQFT is the\nappropriate framework. Swanson (2017) analyzes LQFT, AQFT, and\nWightman QFT and argues that all three approaches are complementary\nand have no deep incompatibilities. LQFT supplies various powerful\npredictive tools and explanatory schemas. It can account for gauge\ntheories, the Standard Model of particle physics, the weak and strong\nnuclear force, and the electromagnetic force. However, the collection\nof calculational techniques are not all mathematically\nwell-defined. LQFT provides QFT theories at only certain length scales\nand cannot make use of unitarily inequivalent representations since\nLQFT uses cutoffs which renders all representations finite dimensional\nand unitarily equivalent by the Stone-von Neumann theorem. Axiomatic\nQFT is supposed to provide a rigorous description of fundamental QFT\nat all length scales, but that conflicts with the effective field\ntheory viewpoint where QFT is only defined for certain lengths. But if\naxiomatic QFT capture what all QFTs have in common, then effective\nfield theories should be captured by it as well. Axiomatic QFT gives a\nprecise regimentation of LQFT, but it is unclear if axiomatic QFT is\nfully faithful to the LQFT picture. Within the axiomatic approach,\nWightman QFT has many sophisticated tools for building concrete models\nof QFT in addition to rigorously proving structural results like the\nPCT theorem and the spin statistics theorem. But Wightman QFT relies\non localized gauge-dependent field operators that do not directly\nrepresent physical properties. AQFT might provide a more physically\ntransparent gauge-free description of QFT. It has topological tools to\ndefine global quantities like temperature, energy, charge, particle\nnumber which use unitarily inequivalent representations. But AQFT has\ndifficulty constructing models. While LQFT is more mathematically\namorphous, there are recent algebraic constructions of low dimensional\ninteracting models with no known Lagrangian, which suggest that AQFT\nis more general than LQFT (Swanson 2017, p. 5). However, LQFT provides\nconstructive QFT with guidance on correctly building models\ncorresponding to Lagrangians particle physicists use with great\nempirical success (Hancox-Li 2017, p. 353).  Constructive QFT is an attempt to mediate between LQFT and\naxiomatic QFT by rigorously constructing specific interacting models\nof QFT. The nontrivial solutions it constructs are supposed to\ncorrespond to Lagrangians that particle physicists use. This ensures\nthat various axiomatic systems have a physical connection to the world\nvia the empirical success of LQFT. While constructive QFT has done\nthis for some models with dimensions less than 4, it has not yet been\naccomplished for a 4 dimensional Lagrangian that particle physicists\nuse. Any model that satisfies the Osterwalder-Schrader axioms will\nautomatically satisfy the Wightman axioms. Constructive QFT tries to\nconstruct the functional integral measures for path integrals by\nshifting from Minkowski spacetime to Euclidean spacetime via a Wick\nrotation (what follows is based on section four of Hancox-Li\n(2017)). In Euclidean field theory, the Schwinger functions, which are\ndefined in terms of \\(Z\\), must satisfy the Osterwalder-Schrader\naxioms. The measure of \\(Z\\) is a Gaussian measure on the Schwartz\nspace of rapidly decreasing functions. The Osterwalder-Schrader axioms\nare related to the Wightman axioms by the Osterwalder-Schrader\nReconstruction Theorem which states that any set of functions\nsatisfying the Osterwalder-Schrader axioms determines a unique\nWightman model whose Schwinger functions form that set. It allows the\nconstructive field theorists to use the advantages of Euclidean space\nfor defining a measure while ensuring that they are constructing\nmodels that exist in Minkowski spacetime. It still has to be verified\nthat the solution corresponds to a renormalized perturbation series\nthat physicists derive for the corresponding Lagrangian in LQFT. The\nchallenge is how to translate something not mathematically\nwell-defined into something that is while showing that the\n“solutions” in LQFT can be reproduced by something that is\nconsistent with a set of axioms. This is crucial since, as Swanson\n(2017) points out, it is unclear whether perturbation theory is an\naccurate guide for the underlying physics described by LQFT. This\nleads Hancox-Li (2017) to argue that mathematically unrigorous LQFT is\nrelevant to the rigorous program of constructive QFT in building\nrigorous interacting models of QFT. Those models correspond to the\nLagrangians of interest to particle physicists. Hence, LQFT can inform\nthe theoretical content of QFT. \nAnother tool of constructive QFT is the use of asymptotic series,\nwhich can tell us which function the perturbative series is asymptotic\nto, which perturbative QFT does not. Constructive QFT tries to\ndetermine some properties of non-perturbative solutions to the\nequations of motion which guarantee that certain methods of summing\nasymptotic expansions will lead to a unique solution (see Hancox-Li\n2017 (pp. 349–350) for more details). Is the rigorously defined\npartition function \\(Z\\) asymptotic to the renormalized perturbative\nseries?  Roughly, a function is asymptotic to a series expansion when\nsuccessive terms of the series provide an increasingly accurate\ndescription of how quickly the function grows. The difference between\nthe function and each order of the perturbation series is\napproximately small. But there are many different functions that have\nthe same asymptotic expansion. Ideally, we want there to be a unique\nfunction because then there is a unique non-perturbative solution. The\nconcept of strong asymptoticity requires that the difference between\nthe function and each order of the series is smaller than what was\nrequired by asymptoticity. A strongly asymptotic series uniquely\ndetermines a function. If there is a strong asymptotic series, then\nthe function can be uniquely reconstructed from the series by Borel\nsummation. The Borel transform of the series is given by dividing the\ncoefficients each term in the series by a factorial of the order of\nthat term and then integrating to recover the exact function. In\nconstructive QFT, the goal is to associate a unique function with a\nrenormalized perturbation series and some kind of Borel summability is\nthe main candidate so far, though the Borel transform cannot remove\nlarge-order divergences. The asymptotic behavior of the renormalized\nperturbation series can be extremely sensitive to the choice of\nregularization and render it asymptotic to a free field theory even if\nit appears to describe nontrivial perturbations (see Swanson 2017\n(p. 11) for more details).\n","contact.mail":"fkronz@nsf.gov","contact.domain":"nsf.gov"},{"date.published":"2004-07-27","date.changed":"2019-07-01","url":"https://plato.stanford.edu/entries/qt-nvd/","author1":"Fred Kronz","author2":"Tracy Lupher","entry":"qt-nvd","body.text":"\n\n\n\nAn ongoing debate in the foundations of quantum physics concerns the role of\nmathematical rigor. The contrasting views of von Neumann\nand Dirac provide interesting and informative insights concerning two\nsides of this debate. Von Neumann’s contributions often emphasize\nmathematical rigor and Dirac’s contributions emphasize pragmatic\nconcerns. The discussion below begins with an assessment of their\ncontributions to the foundations of quantum mechanics. Their\ncontributions to mathematical physics beyond quantum mechanics are\nthen considered, and the focus will be on the influence that these\ncontributions had on subsequent developments in quantum theorizing,\nparticularly with regards to quantum field theory and its\nfoundations. The entry\n quantum field theory\n provides an overview of a variety of approaches to\ndeveloping a quantum theory of fields. The purpose of this article is\nto provide a more detailed discussion of mathematically rigorous\napproaches to quantum field theory, as opposed to conventional\napproaches, such as Lagrangian quantum field theory, which are\ngenerally portrayed as being more heuristic in character. The current\ndebate concerning whether Lagrangian quantum field theory or axiomatic\nquantum field theory should serve as the basis for interpretive\nanalysis is then discussed.\n\n\nThere are two competing mathematical strategies that are used in\nconnection with physical theory, one emphasizes rigor and the other\npragmatics. The pragmatic approach often compromises mathematical\nrigor, but offers instead expediency of calculation and elegance of\nexpression. A case in point is the notion of an infinitesimal, a\nnon-zero quantity that is smaller than any finite\nquantity. Infinitesimals were used by Kepler, Galileo, Newton, Leibniz\nand many others in developing and using their respective physical\ntheories, despite lacking a mathematically rigorous foundation, as\nBerkeley clearly showed in his famous 1734 treatise The\nAnalyst criticizing infinitesimals. Such criticisms did not\nprevent various 18th Century mathematicians, scientists, and engineers\nsuch as Euler and Lagrange from using infinitesimals to get accurate\nanswers from their calculations. Nevertheless, the pull towards rigor\nled to the development in the 19th century of the concept of a limit\nby Cauchy and others, which provided a rigorous mathematical framework\nthat effectively replaced the theory of infinitesimals. A rigorous\nfoundation was eventually provided for infinitesimals by Robinson\nduring the second half of the 20th Century, but infinitesimals are\nrarely used in contemporary physics. For more on the history of\ninfinitesimals, see the entry on \n continuity and infinitesimals.  \n\nThe competing mathematical strategies are manifest in a more recent\ndiscussion concerning the mathematical foundations of quantum\nmechanics. In the preface to von Neumann’s (1955) treatise  on that\ntopic, he notes that Dirac provides a very elegant and powerful formal\nframework for quantum mechanics, but complains about the central role\nin that framework of an “improper function with self-contradictory\nproperties,” which he also characterizes as a “mathematical fiction.”\nHe is referring to the Dirac \\(\\delta\\) function, which has the following\nincompatible properties: it is defined over the real line, is zero\neverywhere except for one point at which it is infinite, and yields\nunity when integrated over the real line. Von Neumann promotes an\nalternative framework, which he characterizes as being “just as clear\nand unified, but without mathematical objections.” He emphasizes that\nhis framework is not merely a refinement of Dirac’s; rather, it is a\nradically different framework that is based on Hilbert’s theory of\noperators. \n\nDirac is of course fully aware that the \\(\\delta\\) function is not a\nwell-defined expression. But he is not troubled by this for two\nreasons. First, as long as one follows the rules governing the \\(\\delta\\)\nfunction (such as using the \\(\\delta\\) function only under an integral\nsign, meaning in part not asking the value of a \\(\\delta\\) function at a\ngiven point), then no inconsistencies will arise. Second, the \\(\\delta\\)\nfunction can be eliminated, meaning that it can be replaced with a\nwell-defined mathematical expression. However, the drawback in that\ncase is, according to Dirac, that the substitution leads to a more\ncumbersome expression that obscures the argument. In short, when\npragmatics and rigor lead to the same conclusion, pragmatics trumps\nrigor due to the resulting simplicity, efficiency, and increase in\nunderstanding.  \n\nAs in the case of the notion of an infinitesimal, the Dirac \\(\\delta\\)\nfunction was eventually given a mathematically rigorous\nfoundation. That was done within Schwartz’s theory of distributions,\nwhich was later used in developing the notion of a rigged Hilbert\nspace. The theory of distributions was used to provide a mathematical\nframework for quantum field theory (Wightman 1964). The rigged Hilbert\nspace was used to do so for quantum mechanics (Böhm 1966) and\nthen for quantum field theory (Bogoluliubov et al. 1975). \n\nThe complementary approaches, rigor and pragmatics, which are\nexhibited in the development of quantum mechanics, later came about in\na more striking way in connection with the development of quantum\nelectrodynamics (QED) and, more generally, quantum field theory\n(QFT). The emphasis on rigor emerges in connection with two\nframeworks, algebraic QFT and Wightman’s axiomatic QFT. Algebraic QFT\nhas its roots in the work of von Neumann on operator algebras, which\nwas developed by him in an attempt to generalize the Hilbert space\nframework. Wightman’s axiomatic QFT has its roots in Schwartz’s theory\nof distributions, and it was later developed in the rigged Hilbert\nspace framework. Roughly, the basic distinction between the two\napproaches is that the algebra of operators is the basic mathematical\nconcept in algebraic QFT, while operator-valued distributions (the\nquantum analogues of field quantities) are fundamental in Wightman’s\naxiomatic QFT. It is worth noting that algebraic QFT is generally\nformulated axiomatically, and that it is just as deserving of the name\n“axiomatic” QFT. However, that term is often taken to refer\nspecifically to the approach based on operator-valued\ndistributions. To avoid any possible confusion, that approach is\nreferred to here as “Wightman’s axiomatic” QFT. The emphasis on\npragmatics arises most notably in Lagrangian QFT, which uses\nperturbation theory, path integrals, and renormalization\ntechniques. Although some elements of the theory were eventually\nplaced on a firmer mathematical foundation, there are still serious\nquestions about its being a fully rigorous approach on a par with\nalgebraic and Wightman’s axiomatic QFT. Nevertheless, it has been\nspectacularly successful in providing numerical results that are\nexceptionally accurate with respect to experimentally determined\nquantities, and in making possible expedient calculations that are\nunrivaled by other approaches. \n\nThe two approaches to QFT continue to develop in parallel. Fleming\n(2002, 135–136) brings this into focus in his discussion of\ndifferences between Haag’s Local Quantum Physics (1996) and\nWeinberg’s Quantum Field Theory (1995); Haag’s book presents\nalgebraic QFT, and Weinberg’s book presents Lagrangian QFT. While both\nbooks are ostensibly about the same subject, Haag gives a precise\nformulation of QFT and its mathematical structure, but does not\nprovide any techniques for connecting with experimentally determined\nquantities, such as scattering cross sections. Weinberg gives a\npragmatic formulation that engages with physical intuition and\nprovides heuristics that are important for performing calculations;\nhowever, it is not as mathematically rigorous. Moreover, there are a\nnumber of important topics that are examined in one book while not\neven mentioned in the other. For example, unitarily inequivalent\nrepresentations are discussed by Haag, but not by Weinberg. By\ncontrast, Weinberg discusses Feynman’s rules for path integrals, which\nare not mentioned at all by Haag. There is also the issue of\ndemographics. Most particle and experimental physicists will read and\nstudy Weinberg’s book, but very few will read Haag’s book. Because of\nthese differences, Fleming (2002, 136) suggests that one might\nquestion whether the two books are really about the same subject. This\ngives rise to the question whether any formulation of QFT is worthy of\nphilosophical attention to its foundations. In particular, there is a\ndebate between Wallace (2006, 2011) and Fraser (2009, 2011) over\nwhether an interpretation of QFT should be based on the standard\ntextbook treatment of QFT or an axiomatic formulation of QFT.  \n\nIn the late 1920s, von Neumann developed the separable Hilbert space\nformulation of quantum mechanics, which later became the definitive\none (from the standpoint of mathematical rigor, at least). In the\nmid-1930s, he worked extensively on lattice theory (see the entry\non\n quantum logic), \n rings of operators, and continuous geometries. Part of his\nexpressed motivation for developing these mathematical theories was to\ndevelop an appropriate framework for QFT and a better foundation for\nquantum mechanics. During this time, he noted two closely related\nstructures, modular lattices and finite type-II factors (a special\ntype of ring of operators), that have what he regarded as desirable\nfeatures for quantum theory. These observations led to his developing\na more general framework, continuous geometries, for quantum\ntheory. Matters did not work out as von Neumann had expected. He soon\nrealized that such geometries must have a transition probability\nfunction, if they are to be used to describe quantum mechanical\nphenomena, and that the resulting structure is not a generalization at\nall beyond the operator rings that were already available. Moreover,\nit was determined much later that the type-III factors are the most\nimportant type of ring of operators for quantum theory. In addition, a\nsimilar verdict was delivered much later with regards to his\nexpectations concerning lattice theory. The lattices that are\nappropriate for quantum theory are orthomodular — a lattice is\northomodular only if it is modular, but the converse is false. Of the\nthree mathematical theories, it is the rings of operators that have\nproven to be the most important framework for quantum theory. It is\npossible to use a ring of operators to model key features of physical\nsystems in a purely abstract, algebraic setting (this is discussed in\nsection 4.1). A related issue concerns whether it is necessary to\nchoose a representation of the ring in a Hilbert space; see Haag and\nKastler (1964), Ruetsche (2003), and Kronz and Lupher (2005) for\nfurther discussion of this issue. In any case, the separable Hilbert\nspace remains a crucial framework for quantum theory. The simplest\nexamples of separable Hilbert spaces are the finite dimensional ones,\nin which case the algebra of operators is a\ntype-I\\(_n\\) factor (n is a positive integer). The\noperators are n-by-n complex matrices, which are typically used to\ndescribe internal degrees of freedom such as spin. Readers wanting to\nfamiliarize themselves with these basic examples should consult the\nentry on\n quantum mechanics. \n\nMatrix mechanics and wave mechanics were formulated roughly around the\nsame time between 1925 and 1926. In July 1925, Heisenberg finished his\nseminal paper “On a Quantum Theoretical Interpretation of\nKinematical and Mechanical Relations”. Two months later, Born\nand Jordan finished their paper, “On Quantum Mechanics”,\nwhich is the first rigorous formulation of matrix mechanics. Two\nmonths after this, Born, Heisenberg, and Jordan finished “On\nQuantum Mechanics II”, which is an elaboration of the earlier\nBorn and Jordan paper; it was published in early 1926. These three\npapers are reprinted in van der Waerden (1967). Meanwhile,\nSchrödinger was working on what eventually became his four famous\npapers on wave mechanics. The first was received by Annalen der\nPhysik in January 1926, the second was received in February, and\nthen the third in May and the fourth in June. All four are reprinted\nin Schrödinger (1928). \n\nSchrödinger was the first to raise the question of the\nrelationship between matrix mechanics and wave mechanics in\nSchrödinger (1926), which was published in Annalen in\nspring 1926 between the publication of his second and third papers of\nthe famous four. This paper is also reprinted in Schrödinger\n(1928). It contains the germ of a mathematical equivalence proof, but\nit does not contain a rigorous proof of equivalency: the mathematical\nframework that Schrödinger associated with wave mechanics is a\nspace of continuous and normalizable functions, which is too small to\nestablish the appropriate relation with matrix mechanics. Shortly\nthereafter, Dirac and Jordan independently provided a unification of\nthe two frameworks. But their respective approaches required essential\nuse of \\(\\delta\\) functions, which were suspect from the standpoint of\nmathematical rigor. In 1927, von Neumann published three papers\nin Göttinger Nachrichten that placed quantum mechanics\non a rigorous mathematical foundation and included a rigorous proof\n(i.e., without the use of \\(\\delta\\) functions) of the equivalence of\nmatrix and wave mechanics. These papers are reprinted in von\nNeumann(1961–1963, Volume I, Numbers 8–10). In the preface\nto his famous 1932 treatise on quantum mechanics (von Neumann 1955),\nwhich is an elegant summary of the separable Hilbert space formulation\nof quantum mechanics that he provided in the earlier papers, he\nacknowledges the simplicity and utility of Dirac’s formulation\nof quantum mechanics, but finds it ultimately unacceptable. He\nindicates that he cannot endure the use of what could then only be\nregarded as mathematical fictions. Examples of these fictions include\nDirac’s assumption that every self-adjoint operator can be put\nin diagonal form and his use of \\(\\delta\\) functions, which von\nNeumann characterizes as “improper functions with\nself-contradictory properties”. His stated purpose is to\nformulate a framework for quantum mechanics that is mathematically\nrigorous. \n\nWhat follows is a brief sketch of von Neumann’s strategy. First, he\nrecognized the mathematical framework of matrix mechanics as what\nwould now be characterized as an infinite dimensional, separable\nHilbert space. Here the term “Hilbert space” denotes\na complete vector space with an inner product; von Neumann imposed the\nadditional requirement of separability (having a countable basis) in\nhis definition of a Hilbert space. He then attempted to specify a set\nof functions that would instantiate an (infinite-dimensional)\nseparable Hilbert space and could be identified with\nSchrödinger’s wave mechanics. He began with the space of\nsquare-integrable functions on the real line. To satisfy the\ncompleteness condition, that all Cauchy sequences of functions\nconverge (in the mean) to some function in that space, he specified\nthat integration must be defined in the manner of Lebesgue. To define\nan inner product operation, he specified that the set of Lebesgue\nsquare-integrable functions must be partitioned into equivalence\nclasses modulo the relation of differing on a set of measure\nzero. That the elements of the space are equivalence classes of\nfunctions rather than functions is sometimes overlooked, and it has\ninteresting ramifications for interpretive investigations. It has been\nargued in Kronz (1999), for example, that separable Hilbert space is\nnot a suitable framework for quantum mechanics under Bohm’s\nontological interpretation (also known as\n Bohmian mechanics). \n\nIn a letter to Birkhoff from 1935, von Neumann says: “I would\nlike to make a confession which may seem immoral: I do not believe in\nHilbert space anymore”; the letter is published in von Neumann\n(2005). The confession is indeed startling since it comes from the\nchampion of the separable Hilbert space formulation of quantum\nmechanics and it is issued just three years after the publication of\nhis famous treatise, the definitive work on the subject. The irony is\ncompounded by the fact that less than two years after his confession\nto Birkhoff, his mathematical theorizing about the abstract\nmathematical structure that was to supersede the separable Hilbert\nspace, continuous geometries with a transition probability, turned out\nnot to provide a generalization of the separable Hilbert space\nframework. It is compounded again with interest in that subsequent\ndevelopments in mathematical physics initiated and developed by von\nNeumann ultimately served to strengthen the entrenchment of the\nseparable Hilbert space framework in mathematical physics (especially\nwith regards to quantum theory). These matters are explained in more\ndetail in Section 4.1. \n\nThree theoretical developments come together for von Neumann in his\ntheory of continuous geometries during the seven years following 1932:\nthe algebraic approach to quantum mechanics, quantum logics, and rings\nof operators. By 1934, von Neumann had already made substantial moves\ntowards an algebraic approach to quantum mechanics with the help of\nJordan and Wigner — their article, “On an Algebraic\nGeneralization of the Quantum Mechanical Formalism”,  is\nreprinted in von Neumann (1961–1963, Vol. II, No. 21). In 1936, he\npublished a second paper on this topic, “On an Algebraic\nGeneralization of the  Quantum Mechanical Formalism (Part\nI)”, which is reprinted in von Neumann (1961–1963, Vol. III,\nNo. 9). Neither work was particularly influential, as it turns out. A\nrelated paper by von Neumann and Birkhoff, “The Logic of Quantum\nMechanics”, was also published in 1936, and it is reprinted in\nvon Neumann (1961–1963, Vol. IV, No. 7). It was seminal to the\ndevelopment of a sizeable body of literature on\n quantum logics.\nIt should be noted, however, that this happens only after modularity,\na key postulate for von Neumann, is replaced with orthomodularity (a\nweaker condition). The nature of the shift is clearly explained in\nHolland (1970): modularity is in effect a weakening of the\ndistributive laws (limiting their validity to certain selected triples\nof lattice elements), and orthomodularity is a weakening of modularity\n(limiting the validity of the distributive laws to an even smaller set\nof triples of lattice elements). The shift from modularity to\northomodularity was first made in (Loomis 1955). Rapid growth of\nliterature on orthomodular lattices and the foundations of quantum\nmechanics soon followed. For example, see Pavi&ccaron;i&cacute; (1992)\nfor a fairly exhaustive bibliography of quantum logic up to 1990,\nwhich has over 1800 entries. \n\nOf substantially greater note for the foundations of quantum theory\nare six papers by von Neumann (three jointly published with Murray) on\nrings of operators, which are reprinted in von Neumann (1961–1963,\nVol. III, Nos 2–7). The first two, “On Rings of Operators”\nand a sequel “On Rings of Operators II”, were published in\n1936 and 1937, and they were seminal to the development of the other\nfour. The third, “On Rings of Operators: Reduction\nTheory”, was written during 1937–1938 but not published until\n1949. The fourth, “On Infinite Direct Products”, was\npublished in 1938. The remaining two, “On Rings of Operators\nIII” and “On Rings of Operators IV” were published\nin 1941 and 1943, respectively. This massive work on rings of\noperators was very influential and continues to have an impact in pure\nmathematics, mathematical physics, and the foundations of\nphysics. Rings of operators are now referred to as “von Neumann\nalgebras” following Dixmier (1981), who first referred to them\nby this name (stating that he did so following a suggestion made to\nhim by Dieudonné) in the introduction to his 1957 treatise on operator\nalgebras (Dixmier 1981). \n\nA von Neumann algebra is a \\(*\\)-subalgebra of the set of bounded\noperators B(H) on a Hilbert space H that is closed in the weak\noperator topology. It is usually assumed that the von Neumann algebra\ncontains the identity operator. A \\(*\\)-subalgebra contains the\nadjoint of every operator in the algebra, where the\n“\\(*\\)” denotes the adjoint. There are special types of\nvon Neumann algebras that are called “factors”. A von\nNeumann algebra is a factor, if its center (which is the set of\nelements that commute with all elements of the algebra) is trivial,\nmeaning that it only contains scalar multiples of the identity\nelement. Moreover, von Neumann showed in his reduction-theory paper\nthat all von Neumann algebras that are not factors can be decomposed\nas a direct sum (or integral) of factors. There are three mutually\nexclusive and exhaustive factor types: type-I, type-II, and\ntype-III. Each type has been classified into (mutually exclusive and\nexhaustive) sub-types: types I\\(_n\\) \\((n = 1,2,\\ldots ,\\infty),\\)\nII\\(_n\\) \\((n = 1,\\infty),\\) III\\(_z\\) \\((0\\le z\\le 1).\\) As mentioned\nabove, type-I\\(_n\\) correspond to finite dimensional Hilbert spaces,\nwhile type-I\\(_{\\infty}\\) corresponds to the infinite dimensional\nseparable Hilbert space that provides the rigorous framework for wave\nand matrix mechanics. Von Neumann and Murray distinguished the\nsubtypes for type-I and type-II, but were not able to do so for the\ntype-III factors. Subtypes were not distinguished for these factors\nuntil the 1960s and 1970s — see Chapter 3 of Sunder (1987) or\nChapter 5 of Connes (1994) for details. \n\nAs a result of his earlier work on the foundations of quantum\nmechanics and his work on quantum logic with Birkhoff, von Neumann\ncame to regard the type-II\\(_1\\) factors as likely to be the\nmost relevant for physics. This is a substantial shift since the most\nimportant class of algebra of observables for quantum mechanics was\nthought at the time to be the set of bounded operators on an\ninfinite-dimensional separable Hilbert space, which is a\ntype-I\\(_{\\infty}\\) factor. A brief explanation for this shift is\nprovided below. See the well-informed and lucid account presented in\n(Rédei 1998) for a much fuller discussion of von Neumann’s\nviews on fundamental connections between quantum logic, rings of\noperators (particularly type-II\\(_1\\) factors), foundations of\nprobability theory, and quantum physics. It is worth noting that von\nNeumann regarded the type-III factors as a catch-all class for the\n“pathological” operator algebras; indeed, it took several\nyears after the classificatory scheme was introduced to demonstrate\nthe existence of such factors. It is ironic that the predominant view\nnow seems to be that the type-III factors are the most relevant class\nfor physics (particularly for QFT and quantum statistical\nmechanics). This point is elaborated further in Section 4.1 after\nexplaining below why von Neumann’s program never came to fruition. \n\nIn the introduction to the first paper in the series of four entitled\n“On Rings of Operators”, Murray and von Neumann list two\nreasons why they are dissatisfied with the separable Hilbert space\nformulation of quantum mechanics. One has to do with a property of the\ntrace operation, which is the operation appearing in the definition of\nthe probabilities for measurement results (the Born rule), and the\nother with domain problems that arise for unbounded observable\noperators. The trace of the identity is infinite when the separable\nHilbert space is infinite-dimensional, which means that it is not\npossible to define a correctly normalized a priori\nprobability for the outcome of an experiment (i.e., a measurement of\nan observable). By definition, the a priori probability for\nan experiment is that in which any two distinct outcomes are equally\nlikely. Thus, the probability must be zero for each distinct outcome\nwhen there is an infinite number of such outcomes, which can occur if\nand only if the space is infinite dimensional. It is not clear why von\nNeumann believed that it is necessary to have an a priori\nprobability for every experiment, especially since von Mises clearly\nbelieved that a priori probabilities (“uniform distributions” in his\nterminology) do not always exist (von Mises 1981, pp. 68 ff.) and von\nNeumann was influenced substantially by von Mises on the foundations\nof probability (von Neumann 1955, p. 198 fn.). Later, von Neumann\nchanged the basis for his expressed reason for dissatisfaction with\ninfinite dimensional Hilbert spaces from probabilistic to algebraic\nconsiderations (Birkhoff and von Neumann 1936, p. 118); namely, that\nit violates Hankel’s principle of the preservation of formal law,\nwhich leads one to try to preserve modularity — a condition that\nholds in finite-dimensional Hilbert spaces but not in\ninfinite-dimensional Hilbert spaces. The problem with unbounded\noperators arises from their only being defined on a merely dense\nsubset of the set elements of the space. This means that algebraic\noperations of unbounded operators (sums and products) cannot be\ngenerally defined; for example, it is possible that two unbounded\noperators \\(A\\), \\(B\\) are such that the range of \\(B\\)\nand the domain of \\(A\\) are disjoint, in which case the\nproduct \\(AB\\) is meaningless. \n\nThe problems mentioned above do not arise for type-I\\(_n\\) factors, if\n\\(n\\lt \\infty\\), nor do they arise for type-II\\(_1\\). That is to say,\nthese factor types have a finite trace operation and are not plagued\nwith the domain problems of unbounded operators. Particularly\nnoteworthy is that the lattice of projections of each of these factor\ntypes (type-I\\(_n\\) for \\(n\\lt \\infty\\) and type-II\\(_1)\\) is\nmodular. By contrast, the set of bounded operators on an\ninfinite-dimensional separable Hilbert space, a type-I\\(_{\\infty}\\)\nfactor, is not modular; rather, it is only orthomodular. These\nconsiderations serve to explain why von Neumann regarded the\ntype-II\\(_1\\) factor as the proper generalization of the type-I\\(_n\\)\n\\((n\\lt \\infty)\\) for quantum physics rather than the\ntype-I\\(_{\\infty}\\) factors. The shift in the literature from modular\nto orthomodular lattices that was characterized above is in effect a\nshift back to von Neumann’s earlier position (prior to his\nconfession). But, as was already mentioned, it now seems that this was\nnot the best move either. \n\nIt was von Neumann’s hope that his program for generalizing quantum\ntheory would emerge from a new mathematical structure known as\n“continuous geometry”. He wanted to use this structure to\nbring together the three key elements that were mentioned above: the\nalgebraic approach to quantum mechanics, quantum logics, and rings of\noperators. He sought to forge a strong conceptual link between these\nelements and thereby provide a proper foundation for generalizing\nquantum mechanics that does not make essential use of Hilbert space\n(unlike rings of operators). Unfortunately, it turns out that the\nclass of continuous geometries is too broad for the purposes of\naxiomatizing quantum mechanics. The class must be suitably restricted\nto those having a transition probability. It turns out that there is\nthen no substantial generalization beyond the separable Hilbert space\nframework. An unpublished manuscript that was finished by von Neumann\nin 1937 was prepared and edited by Israel Halperin, and then published\nas von Neumann (1981). A review of the manuscript by Halperin was\npublished in von Neumann (1961–1963, Vol. IV, No. 16) years before the\nmanuscript itself was published. In that review, Halperin notes the\nfollowing:  \n\nThis unfortunate development does not, however, completely undermine\nvon Neumann’s efforts to generalize quantum mechanics. On the\ncontrary, his work on rings of operators does provide significant\nlight to the way forward. The upshot of subsequent developments is\nthat von Neumann settled on the wrong factor type for the foundations\nof physics. \n\nDirac’s formal framework for quantum mechanics was very useful\nand influential despite its lack of mathematical rigor. It was used\nextensively by physicists and it inspired some powerful mathematical\ndevelopments in functional analysis. Eventually, mathematicians\ndeveloped a suitable framework for placing Dirac’s formal\nframework on a firm mathematical foundation, which is known as\na rigged Hilbert space (and is also referred to as\na Gelfand Triplet). This came about as follows. A rigorous\ndefinition of the \\(\\delta\\) function became possible in distribution\ntheory, which was developed by Schwartz from the mid-1940s to the\nearly 1950s. Distribution theory inspired Gelfand and collaborators\nduring the mid-to-late 1950s to formulate the notion of a rigged\nHilbert space, the firm foundation for Dirac’s formal\nframework. This development was facilitated by Grothendiek’s\nnotion of a nuclear space, which he introduced in the mid-1950s. The\nrigged Hilbert space formulation of quantum mechanics was then\ndeveloped independently by Böhm and by Roberts in 1966. Since\nthen, it has been extended to a variety of different contexts in the\nquantum domain including decay phenomena and the arrow of time. The\nmathematical developments of Schwartz, Gelfand, and others had a\nsubstantial effect on QFT as well. Distribution theory was taken\nforward by Wightman in developing the axiomatic approach to QFT from\nthe mid-1950s to the mid-1960s. In the late 1960s,  the axiomatic\napproach was explicitly put into the rigged Hilbert space framework by\nBogoliubov and co-workers. \n\nAlthough these developments were only indirectly influenced by Dirac,\nby way of the mathematical developments that are associated with his\nformal approach to quantum mechanics, there are other elements of his\nwork that had a more direct and very substantial impact on the\ndevelopment of QFT. In the 1930s, Dirac (1933) developed a Lagrangian\nformulation of quantum mechanics and applied it to quantum fields\n, and the latter inspired Feynman (1948) to develop the\npath-integral approach to QFT. The mathematical\nfoundation for path-integral functionals is still lacking (Rivers\n1987, pp, 109–134), though substantial progress has been made\n(DeWitt-Morette et al. 1979). Despite such shortcomings, it\nremains the most useful and influential approach to QFT to date. In\nthe 1940s, Dirac (1943) developed a form of quantum electrodynamics that\ninvolved an indefinite metric — see also Pauli\n(1943) in that connection. This had a substantial influence on later\ndevelopments, first in quantum electrodynamics in the early 1950s with\nthe Gupta-Bluer formalism, and in a variety of QFT models such as\nvector meson fields and quantum gravity fields by the late 1950s\n— see Chapter 2 of Nagy (1966) for examples and references. \n\nDirac’s attempt to prove the equivalence of matrix mechanics and wave\nmechanics made essential use of the \\(\\delta\\) function, as indicated\nabove. The \\(\\delta\\) function was used by physicists before Dirac, but it\nbecame a standard tool in many areas of physics only after Dirac very\neffectively put it to use in quantum mechanics. It then became widely\nknown by way of his textbook (Dirac 1930), which was based on a series\nof lectures on quantum mechanics given by Dirac at Cambridge\nUniversity. This textbook saw three later editions: the second in\n1935, the third in 1947, and the fourth in 1958. The fourth edition\nhas been reprinted many times. Its staying power is due, in part, to\nanother innovation that was introduced by Dirac in the third edition,\nhis bra-ket formalism. He first published this formalism in (Dirac\n1939), but the formalism did not become widely used until after the\npublication of the third edition of his book. There is no question\nthat these tools, first the \\(\\delta\\) function and then the bra-ket\nnotation, were extremely effective for physicists practicing and\nteaching quantum mechanics both with regards to setting up equations\nand to the performance of calculations. Most quantum mechanics\ntextbooks use \\(\\delta\\) functions and plane waves, which are key elements\nof Dirac’s formal framework, but they are not included in von\nNeumann’s rigorous mathematical framework for quantum\nmechanics. Working physicists as well as teachers and students of\nquantum mechanics often use Dirac’s framework because of its\nsimplicity, elegance, power, and relative ease of use. Thus, from the\nstandpoint of pragmatics, Dirac’s framework is much preferred over von\nNeumann’s. The notion of a rigged Hilbert space placed Dirac’s\nframework on a firm mathematical foundation. \n\nMathematicians worked very hard to provide a rigorous foundation for\nDirac’s formal framework. One key element was Schwartz’s\n(1945; 1950–1951) theory of distributions. Another key element,\nthe notion of a nuclear space, was developed by Grothendieck\n(1955). This notion made possible the generalized-eigenvector\ndecomposition theorem for self-adjoint operators in rigged Hilbert\nspace — for the theorem see Gelfand and Vilenken (1964,\npp. 119–127), and for a brief historical account of the\nconvoluted path leading to it see Berezanskii (1968,\npp. 756–760).  The decomposition principle provides a rigorous\nway to handle observables such as position and momentum in the manner\nin which they are presented in Dirac’s formal framework. These\nmathematical developments culminated in the early 1960s with Gelfand\nand Vilenkin’s characterization of a structure that they\nreferred to as a rigged Hilbert space (Gelfand and Vilenkin\n1964, pp. 103–127). It is unfortunate that their chosen name for\nthis mathematical structure is doubly misleading. First, there is a\nnatural inclination to regard it as denoting a type of Hilbert space,\none that is rigged in some sense, but this inclination must\nbe resisted. Second, the term rigged has an unfortunate\nconnotation of illegitimacy, as in the terms rigged election\nor rigged roulette table, and this connotation must be\ndismissed as prejudicial. There is nothing illegitimate about a rigged\nHilbert space from the standpoint of mathematical rigor (or any other\nrelevant standpoint). A more appropriate analogy may be drawn using\nthe notion of a rigged ship: the term rigged in this context\nmeans fully equipped. But this analogy has its limitations since a\nrigged ship is a fully equipped ship, but (as the first point\nindicates) a rigged Hilbert space is not a Hilbert space, though it is\ngenerated from a Hilbert space in the manner now to be described. \n\nA rigged Hilbert space is a dual pair of spaces\n\\((\\Phi , \\Phi^x)\\) that can generated from a\nseparable Hilbert space \\(\\Eta\\) using a sequence of norms (or\nsemi-norms); the sequence of norms is generated using a nuclear\noperator (a good approximate meaning is an operator of trace-class,\nmeaning that the trace of the modulus of the operator is finite). In\nthe mathematical theory of topological vector spaces, the space \\(\\Phi\\)\nis characterized in technical terms as a nuclear Fréchet\nspace. To say that \\(\\Phi\\) is a Fréchet space means\nthat it is a complete metric space, and to say that it\nis nuclear means that it is the projective limit of a\nsequence of Hilbert spaces in which the associated topologies get\nrapidly finer with increasing n (i.e., the convergence conditions are\nincreasingly strict); the term nuclear is used because the\nHilbert-space topologies are generated using a nuclear operator. In\ndistribution theory, the space \\(\\Phi\\) is characterized as a\ntest-function space, where a test-function is thought of as a very\nwell-behaved function (being continuous, n-times differentiable,\nhaving a bounded domain or at least dropping off exponentially beyond\nsome finite range, etc). \\(\\Phi^x\\) is a space of\ndistributions, and it is the topological dual of \\(\\Phi\\), meaning that\nit corresponds to the complete space of continuous linear functionals\non \\(\\Phi\\). It is also the inductive limit of a sequence of Hilbert\nspaces in which the topologies get rapidly coarser with increasing\nn. Because the elements of \\(\\Phi\\) are so well-behaved,\n\\(\\Phi^x\\) may contain elements that are not so\nwell-behaved, some being singular or improper functions (such as\nDirac’s \\(\\delta\\) function). \\(\\Phi\\) is the topological anti-dual of\n\\(\\Phi^x\\), meaning that it is the complete set of\ncontinuous anti-linear functionals on \\(\\Phi^x\\); it\nis anti-linear rather than linear because multiplication by a scalar\nis defined in terms of the scalar’s complex conjugate. \n\nIt is worth noting that neither \\(\\Phi\\) nor \\(\\Phi^x\\)\nis a Hilbert space in that each lacks an inner product that induces a\nmetric with respect to which the space is complete, though for each\nspace there is a topology with respect to which the space is\ncomplete. Nevertheless, each of them is closely related to the Hilbert\nspace \\(\\Eta\\) from which they are generated: \\(\\Phi\\) is densely embedded\nin \\(\\Eta\\), which in turn is densely embedded in\n\\(\\Phi^x\\). Two other points are worth noting. First,\ndual pairs of this sort can also be generated from a pre-Hilbert\nspace, which is a space that has all the features of a Hilbert space\nexcept that it is not complete, and doing so has the distinct\nadvantage of avoiding the partitioning of functions into equivalence\nclasses (in the case of functions spaces). The term rigged Hilbert\nspace is typically used broadly to include dual pairs generated\nfrom either a Hilbert space or a pre-Hilbert space. Second, the\nterm Gelfand triplet is sometimes used instead of the\nterm rigged Hilbert space, though it refers to the ordered\nset \\((\\Phi , \\Eta , \\Phi^x)\\), where \\(\\Eta\\)\nis the Hilbert space used to generate \\(\\Phi\\) and\n\\(\\Phi^x\\). \n\nThe dual pair \\((\\Phi , \\Phi^x)\\) possesses the means to represent\nimportant operators for quantum mechanics that are problematic in a\nseparable Hilbert space, particularly the unbounded operators that\ncorrespond to the observables position and momentum, and it does so in\na particularly effective and unproblematic manner. As already noted,\nthese operators have no eigenvalues or eigenvectors in a separable\nHilbert space; moreover, they are only defined on a dense subset of\nthe elements of the space and this leads to domain problems. These\nundesirable features also motivated von Neumann to seek an alternative\nto the separable Hilbert space framework for quantum mechanics, as\nnoted above. In a rigged Hilbert space, the\noperators corresponding to position and momentum can have a\ncomplete set of eigenfunctionals (i.e., generalized\neigenfunctions). The key result is known as the nuclear spectral\ntheorem (and it is also known as the Gelfand-Maurin theorem). One\nversion of the theorem says that if A is a symmetric linear operator\ndefined on the space \\(\\Phi\\) and it admits a self-adjoint extension\nto the Hilbert space H, then A possesses a complete system of\neigenfunctionals belonging to the dual space \\(\\Phi^x\\) (Gelfand and\nShilov 1977, chapter 4). That is to say, provided that the stated\ncondition is satisfied, A can be extended by duality to \\(\\Phi^x\\),\nits extension \\(A^x\\) is continuous on \\(\\Phi^x\\) (in the operator\ntopology in \\(\\Phi^x)\\), and \\(A^x\\) satisfies a completeness relation\n(meaning that it can be decomposed in terms of its eigenfunctionals\nand their associated eigenvalues). The duality formula for extending\n\\(A\\) to \\(\\Phi^x\\) is \\(\\braket{\\phi}{A^x\\kappa} =\n\\braket{A\\phi}{\\kappa}\\), for all \\(\\phi \\in \\Phi\\) and for all\n\\(\\kappa \\in \\Phi^x\\). The completeness relation says that for all\n\\(\\phi ,\\theta \\in \\Phi\\): \n\nwhere \\(v(A)\\) is the set of all generalized eigenvalues of \\(A^x\\)\n(i.e., the set of all scalars \\(\\lambda\\) for which there is \\(\\lambda\n\\in \\Phi^x\\) such that \\(\\braket{\\phi}{A^x\\lambda} = \\lambda\n\\braket{\\phi}{\\lambda}\\) for all \\(\\phi \\in \\Phi)\\). \n\nThe rigged Hilbert space representation of these observables is about\nas close as one can get to Dirac’s elegant and extremely useful formal\nrepresentation with the added feature of being placed within a\nmathematically rigorous framework. It should be noted, however, that\nthere is a sense in which it is a proper generalization of Dirac’s\nframework. The rigging (based on the choice of a nuclear operator that\ndetermines the test function space) can result in different sets of\ngeneralized eigenvalues being associated with an operator. For\nexample, the set of (generalized) eigenvalues for the momentum\noperator (in one dimension) corresponds to the real line, if the space\nof test functions is the set \\(S\\) of infinitely differentiable\nfunctions of \\(x\\) which together with all derivatives vanish\nfaster than any inverse power of \\(x\\) as \\(x\\) goes to\ninfinity, whereas its associated set of eigenvalues is the complex\nplane, if the space of test functions is the set \\(D\\) of\ninfinitely differentiable functions with compact support (i.e.,\nvanishing outside of a bounded region of the real line). If complex\neigenvalues are not desired, then \\(S\\) would be a more\nappropriate choice than \\(D\\) — see Nagel (1989) for a\nbrief discussion. But there are situations in which it is desirable\nfor an operator to have complex eigenvalues. This is so, for example,\nwhen a system exhibits resonance scattering (a type of decay\nphenomenon), in which case one would like the Hamiltonian to have\ncomplex eigenvalues — see Böhm & Gadella (1989). (Of\ncourse, it is impossible for a self-adjoint operator to have complex\neigenvalues in a Hilbert space.) \n\nSoon after the development of the theory of rigged Hilbert spaces by\nGelfand and his associates, the theory was used to develop a new\nformulation of quantum mechanics. This was done independently by\nBöhm (1966) and Roberts (1966). It was later demonstrated that\nthe rigged Hilbert space formulation of quantum mechanics can handle a\nbroader range of phenomena than the separable Hilbert space\nformulation. That broader range includes scattering resonances and\ndecay phenomena (Böhm and Gadella 1989), as already\nnoted. Böhm (1997) later extended this range to include a quantum\nmechanical characterization of the arrow of time. The Prigogine school\ndeveloped an alternative characterization of the arrow of time using\nthe rigged Hilbert space formulation of quantum mechanics (Antoniou\nand Prigogine 1993). Kronz (1998, 2000) used this formulation to\ncharacterize quantum chaos in open quantum systems. Castagnino and\nGadella (2003) used it to characterize\n decoherence\nin closed quantum systems. \n\nIn 1943, Gelfand and Neumark published an important paper on an\nimportant class of normed rings, which are now known as abstract\n\\(C^*\\)-algebras. Their paper was influenced by Murray and von\nNeumann’s work on rings of operators, which was discussed in the\nprevious section. In their paper, Gelfand and Neumark focus attention\non abstract normed \\(*\\)-rings. They show that any \\(C^*\\)-algebra can\nbe given a concrete representation in a Hilbert space (which need not\nbe separable). That is to say, there is an isomorphic mapping of the\nelements of a \\(C^*\\)-algebra into the set of bounded operators of the\nHilbert space. Four years later, Segal (1947a) published a paper that\nserved to complete the work of Gelfand and Neumark by specifying the\ndefinitive procedure for constructing concrete (Hilbert space)\nrepresentations of an abstract \\(C^*\\)-algebra. It is called the GNS\nconstruction (after Gelfand, Neumark, and Segal). That same year,\nSegal (1947b) published an algebraic formulation of quantum mechanics,\nwhich was substantially influenced by (though deviating somewhat from)\nvon Neumann’s (1963, Vol. III, No. 9) algebraic formulation of\nquantum mechanics, which is cited in the previous section. It is worth\nnoting that although \\(C^*\\)-algebras satisfy Segal’s\npostulates, the algebra that is specified by his postulates is a more\ngeneral structure known as a Segal algebra. Every \\(C^*\\)-algebra is a\nSegal algebra, but the converse is false since Segal’s\npostulates do not require an adjoint operation to be defined. If a\nSegal algebra is isomorphic to the set of all self-adjoint elements of\na \\(C^*\\)-algebra, then it is a special or exceptional Segal\nalgebra. Although the mathematical theory of Segal algebras has been\nfairly well developed, a \\(C^*\\)-algebra is the most important type of\nalgebra that satisfies Segal’s postulates. \n\nThe algebraic formulations of quantum mechanics that were developed by\nvon Neumann and Segal did not change the way that quantum mechanics\nwas done. Nevertheless, they did have a substantial impact in two\nrelated contexts: QFT and quantum statistical mechanics. The key\ndifference leading to the impact has to do with the domain of\napplicability. The domain of quantum mechanics consists of finite\nquantum systems, meaning quantum systems that have a finite number of\ndegrees of freedom. Whereas in QFT and quantum statistical mechanics,\nthe systems of special interest — i.e., quantum fields and\nparticle systems in the thermodynamic limit, respectively — are\ninfinite quantum systems, meaning quantum systems that have an\ninfinite number of degrees of freedom. Dirac (1927) was the first to\nrecognize the importance of infinite quantum systems for QFT, which is\nreprinted in Schwinger (1958). \n\nSegal (1959, p. 5) was the first to suggest that the beauty and power of the\nalgebraic approach becomes evident when working with an infinite\nquantum system . The key advantage of the algebraic\napproach, according to Segal (1959, pp. 5–6), is that one may work in\nthe abstract algebraic setting where it is possible to obtain\ninteracting fields from free fields by an automorphism on the algebra,\none that need not be unitarily implementable. Segal notes (1959, p. 6)\nthat von Neumann (1937) had a similar idea (that field dynamics are to be\nexpressed as an automorphism on the algebra) in an unpublished\nmanuscript. Segal notes this advantage in response\nto a result obtained by Haag (1955), that field theory representations\nof free fields are unitarily inequivalent to representations of\ninteracting fields. Haag mentions that von Neumann (1938) first discovered\n‘different’ (unitarily inequivalent) representations much\nearlier. A different way of approaching\nunitarily equivalent representations, by contrast with Segal’s\napproach, was later presented by Haag and Kastler (1964), who argued\nthat unitarilty inequivalent representations are physically\nequivalent. Their notion of physical equivalence was based on Fell’s\nmathematical idea of weak equivalence (Fell 1960). \n\nAfter indicating important similarities between his and von Neumann’s\napproaches to infinite quantum systems, Segal draws an important\ncontrast that serves to give the advantage to his approach over von\nNeumann’s. The key mathematical difference, according to Segal, is\nthat von Neumann was working with a weakly closed ring of operators\n(meaning that the ring of operators is closed with respect to the weak\noperator topology), whereas Segal is working with a uniformly closed\nring of operators (closed with respect to the uniform topology). It is\ncrucial because it has the following interpretive significance, which\nrests on operational considerations: \n\nInitially, it appeared that Segal’s assessment of the relative\nmerits of von Neumann algebras and \\(C^*\\)-algebras with respect to\nphysics was substantiated by a seminal paper, (Haag and Kastler\n1964). Among other things, Haag and Kastler introduced the key axioms\nof the algebraic approach to QFT. They also argued that unitarily\ninequivalent representations are “physically equivalent”\nto each other. However, the use of physical equivalence to show that\nunitarily inequivalent representations are not physically significant\nhas been challenged; see Kronz and Lupher (2005), Lupher (2018), and\nRuetsche (2011). The prominent role of type-III factor von Neumann\nalgebras within the algebraic approach to quantum statistical\nmechanics and QFT raises further doubts about Segal’s\nassessment. \n\nThe algebraic approach has proven most effective in quantum\nstatistical mechanics. It is extremely useful for characterizing many\nimportant macroscopic quantum effects including crystallization,\nferromagnetism, superfluidity, structural phase transition,\nBose-Einstein condensation, and superconductivity. A good introductory\npresentation is Sewell (1986), and for a more advanced discussion see\nBratteli and Robinson (1979, 1981). In algebraic quantum statistical\nmechanics, an infinite quantum system is defined by specifying an\nabstract algebra of observables. A particular state may then be used\nto specify a concrete representation of the algebra as a set of\nbounded operators in a Hilbert space. Among the most important types\nof states that are considered in algebraic statistical mechanics are\nthe equilibrium states, which are often referred to as “KMS\nstates” (since they were first introduced by the physicists\nKubo, Martin, and Schwinger). There is a continuum of KMS states since\nthere is at least one KMS state for each possible temperature value\n\\(\\tau\\) of the system, for\n\\(0\\le \\tau \\le +\\infty\\). Given an automorphism\ngroup, each KMS state corresponds to a representation of the algebra\nof observables that defines the system, and each of these\nrepresentations is unitarily inequivalent to any other. It turns out\nthat each representation that corresponds to a KMS state is a factor:\nif \\(\\tau = 0\\) then it is a type-I factor, if\n\\(\\tau = +\\infty\\) then it is a type-II factor, and if\n\\(0\\lt \\tau \\lt +\\infty\\) then it is a type-III\nfactor. Thus, type-III factors play a predominant role in algebraic\nquantum statistical mechanics.  \n\nIn algebraic QFT, an algebra of observables is associated with bounded\nregions of Minkowski spacetime (and unbounded regions including all of\nspacetime by way of certain limiting operations) that are required to\nsatisfy standard axioms of local structure: isotony, locality,\ncovariance, additivity, positive spectrum, and a unique invariant\nvacuum state. The resulting set of algebras on Minkowski spacetime\nthat satisfy these axioms is referred to as the net of local\nalgebras. It has been shown that special subsets of the net of\nlocal algebras — those corresponding to various types of\nunbounded spacetime regions such as tubes, monotones (a tube that\nextends infinitely in one direction only), and wedges — are\ntype-III factors. Of particular interest for the foundations of\nphysics are the algebras that are associated with bounded spacetime\nregions, such as a double cone (the finite region of intersection of a\nforward and a backward light cone). As a result of work done over the\nlast thirty years, local algebras of relativistic QFT appear to be\ntype III von Neuman algebras see Halvorson (2007, pp. 749–752)\nfor more details.  \n\nOne important area for interpretive investigation is the existence of\na continuum of unitarily inequivalent representations of an algebra of\nobservables. Attitudes towards unitarily inequivalent representations\ndiffer drastically in the philosophical literature. In (Wallace 2006)\nunitarily inequivalent representations are not considered a\nfoundational problem for QFT, while in Ruetsche (2011), Lupher (2018) and Kronz and\nLupher (2005) unitarily inequivalent representations are considered\nphysically significant. \n\nIn the early 1950s, theoretical physicists were inspired to axiomatize\nQFT. One motivation for axiomatizing a theory, not the one for the\ncase now under discussion, is to express the theory in a completely\nrigorous form in order to standardize the expression of the theory as\na mature conceptual edifice. Another motivation, more akin to the case\nin point, is to embrace a strategic withdrawal to the foundations to\ndetermine how renovation should proceed on a structure that is\nthreatening to collapse due to internal inconsistencies. One then\nlooks for existing piles (fundamental postulates) that penetrate\nthrough the quagmire to solid rock, and attempts to drive home others\nat advantageous locations. Properly supported elements of the\nsuperstructure (such as the characterization of free fields,\ndispersion relations, etc.) may then be distinguished from those that\nare untrustworthy. The latter need not be razed immediately, and may\nultimately glean supportive rigging from components not yet\nconstructed. In short, the theoretician hopes that the axiomatization\nwill effectively separate sense from nonsense, and that this will\nserve to make possible substantial progress towards the development of\na mature theory. Grounding in a rigorous mathematical framework can be\nan important part of the exercise, and that was a key aspect of the\naxiomatization of QFT by Wightman. \n\nIn the mid-1950s, Schwartz’s theory of distributions was used by\nWightman (1956) to develop an abstract formulation of QFT, which later\ncame to be known known as axiomatic quantum field\ntheory. Mature statements of this formulation are presented in\nWightman and Gårding (1964) and in Streater and Wightman\n(1964). It was further refined in the late 1960s by Bogoliubov, who\nexplicitly placed axiomatic QFT in the rigged Hilbert space framework\n(Bogoliubov et al. 1975, p. 256). It is by now standard\nwithin the axiomatic approach to put forth the following six\npostulates: spectral condition (there are no negative energies or\nimaginary masses), vacuum state (it exists and is unique), domain\naxiom for fields (quantum fields correspond to operator-valued\ndistributions), transformation law (unitary representation in the\nfield-operator (and state) space of the restricted inhomogeneous\nLorentz group — “restricted” means inversions are\nexcluded, and “inhomogeneous” means that translations are\nincluded), local commutativity (field measurements at spacelike\nseparated regions do not disturb one another), asymptotic completeness\n(the scattering matrix is unitary — this assumption is sometimes\nweakened to cyclicity of the vacuum state with respect to the\npolynomial algebra of free fields). Rigged Hilbert space entered the\naxiomatic framework by way of the domain axiom, so this axiom will be\ndiscussed in more detail below. \n\nIn classical physics, a field is is characterized as a scalar- (or\nvector- or tensor-) valued function \\(\\phi(x)\\) on a domain that\ncorresponds to some subset of spacetime points. In QFT, a field is\ncharacterized by means of an operator rather than a\nfunction. A field operator may be obtained from a classical\nfield function by quantizing the function in the canonical manner\n— see Mandl (1959, pp. 1–17). For convenience, the field\noperator associated with \\(\\phi(x)\\) is denoted below by the same\nexpression (since the discussion below only concerns field\noperators). Field operators that are relevant for QFT are too singular\nto be regarded as realistic, so they are smoothed out over their\nrespective domains using elements of a space of well-behaved functions\nknown as test functions. There are many different\ntest-functions spaces (Gelfand and Shilov 1977, Chapter 4). At first,\nthe test-function space of choice for axiomatic QFT was\nthe Schwartz space \\(\\Sigma\\), the space of functions whose\nelements have partial derivatives of all orders at each point and such\nthat each function and its derivatives decreases faster than\n\\(x^{-n}\\) for any \\(n\\in N\\) as \\(x\\rightarrow \\infty\\). It was later\ndetermined that some realistic models require the use of other\ntest-function spaces. The smoothed field operators \\(\\phi[f\\)] for \\(f\n\\in \\Sigma\\) are known as quantum field operators, and they\nare defined as follows  \n\nThe integral (over the domain of the field operator) of the product of\nthe test function \\(f(x)\\) and the field operator \\(\\phi(x)\\) serves\nto “smooth out” the field operator over its domain; a more\ncolloquial description is that the field is “smeared out”\nover space or spacetime. It is postulated within the axiomatic\napproach that a quantum field operator \\(\\phi[f\\)] may be represented\nas an unbounded operator on a separable Hilbert space \\(\\Eta\\), and\nthat \\(\\{\\phi[f]: f\\in \\Sigma \\}\\) (the set of smoothed field\noperators associated with \\(\\phi(x))\\) has a dense domain \\(\\Omega\\)\nin \\(\\Eta\\). The smoothed field operators are often referred to\nas operator-valued distributions, and this means that for\nevery \\(\\Phi,\\Psi \\in \\Omega\\) there is an element of the space of\ndistributions \\(\\Sigma^x\\), the topological dual of \\(\\Sigma\\), that\nmay be equated to the expression \\(\\langle \\Phi {\\mid} \\phi[\\\n]{\\mid}\\Psi\\rangle\\). If \\(\\Omega'\\) denotes the set of functions\nobtained by applying all polynomials of elements of \\(\\{\\phi[f]: f\\in\n\\Sigma \\}\\) onto the unique vacuum state, then the axioms mentioned\nabove entail that \\(\\Omega'\\) is dense in \\(\\Eta\\) (asymptotic\ncompleteness) and that \\(\\Omega'\\subset \\Omega\\) (domain\naxiom). The elements of \\(\\Omega\\) correspond to possible states of\nthe elements of \\(\\{\\phi[f]: f\\in \\Sigma \\}\\). Though only one field\nhas been considered thus far, the formalism is easily generalizable to\na countable number of fields with an associated set of countably\nindexed field operators \\(\\phi_k (x)\\) — cf. (Streater and\nWightman 1964). \n\nAs noted earlier, the appropriateness of the rigged Hilbert space\nframework enters by way of the domain axiom. Concerning that axiom,\nWightman says the following (in the notation introduced above, which\ndiffers slightly from that used by Wightman). \n\nIn Bogoliubov et al. (1975, p. 256), a topology is introduced\nto serve this role, though it is introduced on \\(\\Omega'\\) rather than\non \\(\\Omega\\). Shortly thereafter, they assert that it is not hard to\nshow that \\(\\Omega'\\) is a complete nuclear space with respect to this\ntopology. This serves to justify a claim they make earlier in their\ntreatise: \n\nNote that they refer to the triplet \\(\\Omega \\subset \\Eta \\subset\n\\Omega^*\\) as a rigged Hilbert space. In the terminology introduced\nabove, they refer in effect to the Gelfand triplet \\((\\Omega , \\Eta ,\n\\Omega^x )\\) or (equivalently) the associated rigged Hilbert space\n\\((\\Omega , \\Omega^x)\\) . \n\nFinally, it is worth mentioning that the status of the field in\nalgebraic QFT differs from that in Wightman’s axiomatic QFT. In both\napproaches, a field is an abstract system having an infinite number of\ndegrees of freedom. Sub-atomic quantum particles are field effects\nthat appear in special circumstances. In algebraic QFT, there is a\nfurther abstraction: the most fundamental entities are the elements of\nthe algebra of local (and quasi-local) observables, and the field is a\nderived notion. The term local means bounded within a finite\nspacetime region, and an observable is not regarded as a property\nbelonging to an entity other than the spacetime region itself. The\nterm quasi-local is used to indicate that we take the union\nof all bounded spacetime regions. In short, the algebraic approach\nfocuses on local (or quasi-local) observables and treats the notion of\na field as a derivative notion; whereas the axiomatic approach (as\ncharacterized just above) regards the field concept as the fundamental\nnotion. Indeed, it is common practice for proponents of the algebraic\napproach to distance themselves from the field notion by referring to\ntheir theory as “local quantum physics”. The two\napproaches are mutually complementary — they have developed\nin parallel and have influenced each other by analogy (Wightman\n1976). For a discussion of the close connections between these two\napproaches, see Haag (1996, p. 106). \n\nMost physicists use Lagrangian QFT (LQFT) to make predictions that\nhave been experimentally verified with extraordinary precision in some\ncases. However, LQFT has been described as a “grab bag of conflicting\nmathematical ideas” that has not provided a sharp mathematical\ndescription of what counts as a QFT model (Swanson 2017, pp. 1–2). Those\ncriticisms motivated mathematically inclined physicists to search for\na mathematically rigorous formulation of QFT. Axiomatic versions of\nQFT have been favored by mathematical physicists and most\nphilosophers. With greater mathematical rigor it is possible to prove\nresults about the theoretical structure of QFT independent of any\nparticular Lagrangian. Axiomatic QFT provides clear conceptual\nframeworks within which precise questions and answers to\ninterpretational issues can be formulated. There are three main\naxiomatic frameworks for QFT: Wightman QFT, Osterwalder-Schrader QFT,\nand algebraic QFT. In Wightman QFT, the axioms use functional analysis\nand operator algebras and is closer to LQFT since its axioms describe\ncovariant field operators acting on a fixed Hilbert space. The\nOsterwalder-Schrader axioms use a functional integration approach to\nQFT. The algebraic QFT axioms use \\(C^*\\)-algebras to model local\nobservables. However, axiomatic QFT approaches are sorely lacking with\nregards to building empirically adequate models. Unlike quantum\nmechanics which has a canonical mathematical framework in terms of von\nNeumann’s Hilbert space formulation, QFT has no canonical mathematical\nframework. Even though there is a canonical mathematical framework for\nquantum mechanics, there are many interpretations of that framework,\ne.g., many-worlds, GRW, Copenhagen, Bohmian, etc... QFT has two levels\nthat require interpretation: (1) which QFT framework should be the\nfocus of these foundational efforts, if any, and (2) how that\npreferred framework should be interpreted. Since (1) involves issues\nabout mathematical rigor and pragmatic virtues, it directly bears on\nthe focus of this article. The lack of a canonical formulation of QFT\nthreatens to impede any metaphysical or epistemological lessons that\nmight be learned from QFT. \nOne view is that these two approaches to QFT, the mathematically\nrigorous axiomatic approach and the pragmatic / empirically adequate\nLQFT approach, are rival research programs (see David Wallace (2006,\n2011) and Doreen Fraser (2009, 2011)), though Swanson (2017) argues\nthat they are not rival programs. Fraser (2009, 2011) argues that the\ninterpretation of QFT should be based on the mathematically rigorous\napproach of axiomatic formulations of QFT. By contrast, Wallace (2006,\n2011) argues that an interpretation of QFT should be based on LQFT.\n(Wallace, in 2006, calls his preferred QFT framework conventional QFT\n(CQFT), but changes his terminology to LQFT in Wallace 2011). Swanson\n(2017) and Egg, Lam, and Oldofedi (2017) are good overviews of the\ndebate between Fraser and Wallace (for an extended analysis see James\nFraser 2016). The debate covers many different philosophical topics in\nQFT, which makes it more challenging to pin down exactly what is\nessential to the arguments for both sides (for one view of what is\nessential for the debate, see Egg, Lam, and Oldofedi 2017). One issue\nis the role of internal consistency established by mathematical rigor\nversus empirical adequacy. Wallace argues that LQFT is empirically\nadequate since it can describe the forces of the Standard Model. LQFT\nhas a collection of calculational techniques including perturbation\ntheory, path integrals, and renormalization group methods. One\ncriticism of LQFT is that the calculational techniques it uses are not\nmathematically rigorous. Wallace argues that renormalization group\nmethods puts perturbative QFT, an approach within LQFT, on\nmathematically rigorous ground and removes the main motivation for\naxiomatic QFT. \nWhat follows is a rough overview of perturbative QFT (see James Fraser\n2016 for more details). Since exactly solvable free QFT models are\nmore mathematically tractable than interacting QFT models,\nperturbative QFT treats interactions as perturbations to the free\nLagrangian assuming weak coupling. For strongly coupled theories like\nquantum chromodynamics that idealization fails. Using perturbation\ntheory, approximate solutions for interacting QFT models can be\ncalculated by expanding S-matrix elements in a power series in terms\nof a coupling parameter. However, the higher order terms will often\ncontain divergent integrals. Typically, renormalization of the higher\norder terms is required to get finite predictions. Two sources of\ndivergent integrals are infrared (long distance, low energy) and\nultraviolet (short distance, high energy) divergences. Infrared\ndivergences are often handled by imposing a long distance cutoff or\nputting a small non-zero lower limit for the integral over momentum. A\nsharp cutoff at low momentum is equivalent to putting the theory in a\nfinite volume box. Imposing asymptotic boundary conditions and\nrestricting the observables to long distance “friendly” observables\nalso help with infrared divergences. Ultraviolet divergences are often\nhandled by imposing a momentum cutoff to remove high momentum modes of\na theory. That is equivalent to freezing out variations in the fields\nat arbitrarily short length scales. Putting the system on a lattice\nwith some finite spacing can also help deal with the high\nmomentum. Dimensional regularization, where the integral measure is\nredefined to range over a fractional number of dimensions, can help\nwith both infrared and ultraviolet divergences. The last step in\nrenormalization is to remove the cutoffs by taking the continuum limit\n(i.e., removing the high momentum cutoff) and the infinite volume\nlimit (i.e., removing the low momentum cutoff). The hope is that the\nlimit is well-defined and there are finite expressions of the series\nat each order.  \nJames Fraser (2016) identifies three problems for perturbative\nQFT. (1) The rigor problem: perturbative QFT is not\nmathematically rigorous which makes it difficult to analyze and\ninterpret. (2) The consistency problem: perturbative\ncalculations rest on the interaction picture existing, but Haag’s\ntheorem seems to show that the interaction picture does not\nexist. (3) The justification problem: renormalization lacks\nphysical motivation and appears ad hoc. James Fraser argues that (1)\nand (2) do not pose severe problems for perturbative QFT because it is\nnot attempting to build continuum QFT models. It is building\napproximate physical quantities – not mathematical structures that are\nto be interpreted as physical systems.\n \nBaker (2016) and Swanson (2017) note that LQFT makes false or unproven\nassumptions such as the convergence of certain infinite sums in\nperturbation theory. Dyson (1952) gives a heuristic argument that\nquantum electrodynamic perturbation series do not converge. Baker and\nSwanson also argue that the use of long distance cutoffs is at odds\nwith cosmological theory and astronomical observations which suggest\nthat the universe is spatially infinite. Even in the weak coupling\nlimit where perturbation theory can be formally applied, it is not\nclear when the perturbative QFT gives an accurate approximation of the\nunderlying physics. In the interacting \\(\\phi^4\\) theory, when the\ndimension is less than 4 for Minkowski spacetime, the theory is\nnontrivial, but when the dimension is greater than 4, the renormalized\nperturbation series is asymptotic to a free field theory even though\nit appears to describe nontrivial interactions. When there are 4\ndimensions, the theory is also trivial if additional technical\nassumptions hold (see Swanson 2017 (p. 3) for more details).   Another area where questions of mathematical rigor arise within\nperturbative QFT is the use of path integrals. The S-matrix power\nseries expansion contains integrals over momentum space and this is\nwhere path integrals / Feynman diagrams have been helpful for making\ncalculations. The key concept is the partition function \\(Z\\),\nwhich is defined as a functional integral involving the action, which\nis itself an integral of the Lagrangian. The following details come\nmainly from Hancox-Li (2017). More specifically, the action is a\nfunctional of quantum fields. The functional integral over the action\nranges over all possible combinations of the quantum fields values\nover spacetime. Informally, the sum is being taken over all possible\nfield configurations. As Swanson (2017) notes, the path integral\nrequires choosing a measure over an infinite dimensional path space,\nwhich is only mathematically well-defined in special cases. For\nexample, if the system is formulated on a hypercubic lattice, then the\nmeasure can be defined (see section 1.2 of James Fraser\n2016). Another way of having a well-defined measure is to restrict\nattention to a finite dimensional subspace. But if functions are\nallowed to vary arbitrarily on short length scales, then the integral\nceases to be well-defined (Wallace 2006, p. 42). All of the correlation\nfunctions (i.e., vacuum state expectation values of the fields at\ndifferent spacetime points), can be derived from the partition\nfunction \\(Z\\). So, given \\(Z\\), all empirical quantities\nassociated with the Lagrangian can be calculated, e.g., scattering\ncross-sections. Finding \\(Z\\) amounts to a solution of\nLQFT. \\(Z\\) can be expanded in a Taylor series in the coupling\nconstant. When this is done, two types of divergences can occur: (1)\nindividual terms of the perturbation series can diverge and/or (2) the\nperturbation series itself is divergent, though the series may be an\nasymptotic series. To deal with (1), physicists do the following\nprocedures (Hancox-Li 2017, pp. 344-345): (i) regularization, which involves\nreducing the number of degrees of freedom via dimensional\nregularization, momentum cutoffs, or using a lattice formulation and\n(ii) add counterterms to compensate for the regularization in (i). But\nthis construction is purely formal and not mathematically defined. The\nrules used to manipulate the Lagrangian, and hence the partition\nfunction, are not well-defined.\n  Wallace (2011) argues that renormalization group techniques have\novercome the mathematical deficiencies of older renormalization\ncalculational techniques (for more details on the renormalization\ngroup see Butterfield and Bouatta 2015, Fraser 2016, Hancox-Li (2015a,\n2015b, 2017)). According to Wallace, the renormalization group methods\nput LQFT on the same level of mathematical rigor as other areas of\ntheoretical physics. It provides a solid theoretical framework that is\nexplanatorily rich in particle physics and condensed matter physics,\nso the impetus for axiomatic QFT has been resolved. Renormalization\ngroup techniques presuppose that QFT will fail at some short length\nscale, but the empirical content of LQFT is largely insensitive to the\ndetails at such short length scales. Doreen Fraser (2011) argues that\nrenormalization group methods help articulate the empirical content of\nQFT, but the renormalization group has no significance for the\ntheoretical content of QFT insofar as it does not tell us whether we\nshould focus on LQFT or AQFT. James Fraser (2016) and Hancox-Li\n(2015b) argue that the renormalization group does more than provide\nempirical predictions in QFT. The renormalization group gives us\nmethods for studying the behavior of physical systems at different\nenergy scales, namely how properties of QFT models depend or do not\ndepend on small scale structure. The renormalization group provides a\nnon-perturbative explanation of the success of perturbative\nQFT. Hancox-Li (2015b) discusses how mathematicians working in\nconstructive QFT use non-perturbative approximations with well\ncontrolled error bounds to prove the existence or non-existence of\nultraviolet fixed points. Hancox-Li argues that the renormalization\ngroup explains perturbative renormalization non-perturbatively. The\nrenormalization group can tell us whether certain Lagrangians have an\nultraviolet limit that satisfies the axioms a QFT should\nsatisfy. Thus, the use of the renormalization group in constructive\nQFT can provide additional dynamical information (e.g., whether a\ncertain dynamics can occur in continuous spacetime) that a pure\naxiomatic approach does not.\n  \nEgg, Lam, and Oldofedi (2017) argue that the main disagreement\nbetween Doreen Fraser and David Wallace is over the very definition of\nQFT. Fraser takes QFT to be the union of quantum theory and special\nrelativity. If QFT = QM + SR as Fraser maintains, then LQFT fails to\nsatisfy that criterion since it employs cutoffs which violate Poincaré\ncovariance. For Wallace, the violation of QFT Poincaré\ncovariance is not as worrisome. QFT is not a truly\nfundamental theory since gravity is absent. Wallace is more interested\nin what QFT’s approximate truth tells us about the world. LQFT gives\nus an effective ontology. The renormalization group tell us that QFT\ncannot be trusted in the high energy regimes where quantum gravity can\nbe expected to apply, i.e., the Planckian length scale where\ngravitational effects cannot be ignored. The violation of Poincaré\ncovariance via cutoffs may not amount to much if the fundamental\nquantum theory of gravity imposes some real cutoff, according to\nWallace. There are, however, other options to consider.  \nSome philosophers have rejected the seemingly either-or nature of\nthe debate between Wallace and Fraser to embrace more pluralistic\nviews. On these pluralistic views, different formulations of QFT might\nbe appropriate for different philosophical questions. Baker (2016)\nadvocates that AQFT or LQFT should be trusted in domains of inquiry\nwhere their idealizations are unproblematic. For example, if the\ndomain to be interpreted is the Standard Model, then LQFT is the\nappropriate framework. Swanson (2017) analyzes LQFT, AQFT, and\nWightman QFT and argues that all three approaches are complementary\nand have no deep incompatibilities. LQFT supplies various powerful\npredictive tools and explanatory schemas. It can account for gauge\ntheories, the Standard Model of particle physics, the weak and strong\nnuclear force, and the electromagnetic force. However, the collection\nof calculational techniques are not all mathematically\nwell-defined. LQFT provides QFT theories at only certain length scales\nand cannot make use of unitarily inequivalent representations since\nLQFT uses cutoffs which renders all representations finite dimensional\nand unitarily equivalent by the Stone-von Neumann theorem. Axiomatic\nQFT is supposed to provide a rigorous description of fundamental QFT\nat all length scales, but that conflicts with the effective field\ntheory viewpoint where QFT is only defined for certain lengths. But if\naxiomatic QFT capture what all QFTs have in common, then effective\nfield theories should be captured by it as well. Axiomatic QFT gives a\nprecise regimentation of LQFT, but it is unclear if axiomatic QFT is\nfully faithful to the LQFT picture. Within the axiomatic approach,\nWightman QFT has many sophisticated tools for building concrete models\nof QFT in addition to rigorously proving structural results like the\nPCT theorem and the spin statistics theorem. But Wightman QFT relies\non localized gauge-dependent field operators that do not directly\nrepresent physical properties. AQFT might provide a more physically\ntransparent gauge-free description of QFT. It has topological tools to\ndefine global quantities like temperature, energy, charge, particle\nnumber which use unitarily inequivalent representations. But AQFT has\ndifficulty constructing models. While LQFT is more mathematically\namorphous, there are recent algebraic constructions of low dimensional\ninteracting models with no known Lagrangian, which suggest that AQFT\nis more general than LQFT (Swanson 2017, p. 5). However, LQFT provides\nconstructive QFT with guidance on correctly building models\ncorresponding to Lagrangians particle physicists use with great\nempirical success (Hancox-Li 2017, p. 353).  Constructive QFT is an attempt to mediate between LQFT and\naxiomatic QFT by rigorously constructing specific interacting models\nof QFT. The nontrivial solutions it constructs are supposed to\ncorrespond to Lagrangians that particle physicists use. This ensures\nthat various axiomatic systems have a physical connection to the world\nvia the empirical success of LQFT. While constructive QFT has done\nthis for some models with dimensions less than 4, it has not yet been\naccomplished for a 4 dimensional Lagrangian that particle physicists\nuse. Any model that satisfies the Osterwalder-Schrader axioms will\nautomatically satisfy the Wightman axioms. Constructive QFT tries to\nconstruct the functional integral measures for path integrals by\nshifting from Minkowski spacetime to Euclidean spacetime via a Wick\nrotation (what follows is based on section four of Hancox-Li\n(2017)). In Euclidean field theory, the Schwinger functions, which are\ndefined in terms of \\(Z\\), must satisfy the Osterwalder-Schrader\naxioms. The measure of \\(Z\\) is a Gaussian measure on the Schwartz\nspace of rapidly decreasing functions. The Osterwalder-Schrader axioms\nare related to the Wightman axioms by the Osterwalder-Schrader\nReconstruction Theorem which states that any set of functions\nsatisfying the Osterwalder-Schrader axioms determines a unique\nWightman model whose Schwinger functions form that set. It allows the\nconstructive field theorists to use the advantages of Euclidean space\nfor defining a measure while ensuring that they are constructing\nmodels that exist in Minkowski spacetime. It still has to be verified\nthat the solution corresponds to a renormalized perturbation series\nthat physicists derive for the corresponding Lagrangian in LQFT. The\nchallenge is how to translate something not mathematically\nwell-defined into something that is while showing that the\n“solutions” in LQFT can be reproduced by something that is\nconsistent with a set of axioms. This is crucial since, as Swanson\n(2017) points out, it is unclear whether perturbation theory is an\naccurate guide for the underlying physics described by LQFT. This\nleads Hancox-Li (2017) to argue that mathematically unrigorous LQFT is\nrelevant to the rigorous program of constructive QFT in building\nrigorous interacting models of QFT. Those models correspond to the\nLagrangians of interest to particle physicists. Hence, LQFT can inform\nthe theoretical content of QFT. \nAnother tool of constructive QFT is the use of asymptotic series,\nwhich can tell us which function the perturbative series is asymptotic\nto, which perturbative QFT does not. Constructive QFT tries to\ndetermine some properties of non-perturbative solutions to the\nequations of motion which guarantee that certain methods of summing\nasymptotic expansions will lead to a unique solution (see Hancox-Li\n2017 (pp. 349–350) for more details). Is the rigorously defined\npartition function \\(Z\\) asymptotic to the renormalized perturbative\nseries?  Roughly, a function is asymptotic to a series expansion when\nsuccessive terms of the series provide an increasingly accurate\ndescription of how quickly the function grows. The difference between\nthe function and each order of the perturbation series is\napproximately small. But there are many different functions that have\nthe same asymptotic expansion. Ideally, we want there to be a unique\nfunction because then there is a unique non-perturbative solution. The\nconcept of strong asymptoticity requires that the difference between\nthe function and each order of the series is smaller than what was\nrequired by asymptoticity. A strongly asymptotic series uniquely\ndetermines a function. If there is a strong asymptotic series, then\nthe function can be uniquely reconstructed from the series by Borel\nsummation. The Borel transform of the series is given by dividing the\ncoefficients each term in the series by a factorial of the order of\nthat term and then integrating to recover the exact function. In\nconstructive QFT, the goal is to associate a unique function with a\nrenormalized perturbation series and some kind of Borel summability is\nthe main candidate so far, though the Borel transform cannot remove\nlarge-order divergences. The asymptotic behavior of the renormalized\nperturbation series can be extremely sensitive to the choice of\nregularization and render it asymptotic to a free field theory even if\nit appears to describe nontrivial perturbations (see Swanson 2017\n(p. 11) for more details).\n","contact.mail":"lupherta@jmu.edu","contact.domain":"jmu.edu"}]
