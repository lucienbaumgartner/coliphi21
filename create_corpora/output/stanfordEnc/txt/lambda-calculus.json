[{"date.published":"2012-12-12","date.changed":"2018-03-21","url":"https://plato.stanford.edu/entries/lambda-calculus/","author1":"Jesse Alama","author2":"Johannes Korbmacher","author1.info":"http://mally.stanford.edu/~alama/cv.html","author2.info":"http://jkorbmacher.org/","entry":"lambda-calculus","body.text":"\n\n\nThe \\(\\lambda\\)-calculus is, at heart, a simple notation for functions\nand application. The main ideas are applying a function to an\nargument and forming functions by abstraction. The syntax of\nbasic \\(\\lambda\\)-calculus is quite sparse, making it an elegant, focused\nnotation for representing functions. Functions and arguments are on a\npar with one another. The result is a non-extensional theory of\nfunctions as rules of computation, contrasting with an extensional\ntheory of functions as sets of ordered pairs. Despite its sparse\nsyntax, the expressiveness and flexibility of the \\(\\lambda\\)-calculus\nmake it a cornucopia of logic and mathematics. This entry develops\nsome of the central highlights of the field and prepares the reader\nfor further study of the subject and its applications in philosophy,\nlinguistics, computer science, and logic.\n\nThe \\(\\lambda\\)-calculus is an elegant notation for working with\napplications of functions to arguments. To\ntake a mathematical example, suppose we are given a simple polynomial\nsuch as\n\\(x^2 -2\\cdot x+5\\).\nWhat is the value of this expression when \\(x = 2\\)? We compute\nthis by ‘plugging in’ 2 for \\(x\\) in the expression: we\nget \\(2^2 -2\\cdot 2+5\\),\nwhich we can further reduce to get the answer 5. To use the\n\\(\\lambda\\)-calculus to represent the situation, we start with the\n\\(\\lambda\\)-term \nThe \\(\\lambda\\) operators allows us to abstract over \\(x\\).\nOne can intuitively read\n‘\\(\\lambda x[x^2 -2\\cdot x+5]\\)’\nas an expression that is waiting for a value \\(a\\) for the variable\n\\(x\\). When given such a value \\(a\\) (such as the number 2), the\nvalue of the expression is\n\\(a^2 -2\\cdot a+5\\).\nThe ‘\\(\\lambda\\)’ on its own has no significance; it merely\nbinds the variable \\(x\\), guarding it, as it were, from\noutside interference. The terminology in \\(\\lambda\\)-calculus is that we\nwant to apply this expression to an argument, and\nget a value. We write ‘\\(Ma\\)’ to denote the\napplication of the function \\(M\\) to the argument \\(a\\).\nContinuing with the example, we get: \nThe first step of this calculation, plugging in ‘2’ for\noccurrences of \\(x\\) in the expression ‘\\(x^2 - 2\\cdot x +\n5\\)’, is the passage from an abstraction term\nto another term by the operation of substitution. The remaining\nequalities are justified by computing with natural numbers. \nThis example suggests the central principle of the\n\\(\\lambda\\)-calculus,\ncalled \\(\\beta\\)-reduction, which is also\nsometimes called \\(\\beta\\)-conversion: \nThe understanding is that we can reduce or contract\n\\((\\rhd)\\) an application \\((\\lambda xM)N\\) of an abstraction term\n(the left-hand side, \\(\\lambda xM)\\) to something (the right-hand\nside, \\(N)\\) by simply plugging in \\(N\\) for the occurrences of \\(x\\)\ninside \\(M\\) (that’s what the notation ‘\\(M[x :=\nN]\\)’\nexpresses).  \\(\\beta\\)-reduction,\nor \\(\\beta\\)-conversion, is the heart of the\n\\(\\lambda\\)-calculus.  When one actually applies \\(\\beta\\)-reduction\nto reduce a term, there is an important proviso that has to be\nobserved. But this will be described in Section 2.1, when we discuss\nbound and free variables. \nWhat about functions of multiple arguments? Can the \\(\\lambda\\)-calculus\nrepresent operations such as computing the length of the hypotenuse of\na right triangle: \nHypotenuse of a right triangle with legs of length \\(x\\) and\n\\(y \\Rightarrow \\sqrt{x^2 + y^2}\\). \nThe length-of-hypotenuse operation maps two positive real numbers\n\\(x\\) and \\(y\\) to another positive real number. One can\nrepresent such multiple-arity operations using the apparatus of the\n\\(\\lambda\\)-calculus by viewing the operation as taking one input at a\ntime. Thus, the operation can be seen as taking one input, \\(x\\), a\npositive real number, and producing as its value not a\nnumber, but an operation: namely, the operation that\ntakes a positive real number \\(y\\) as input and produces as output\nthe positive real number \\(\\sqrt{x^2 + y^2}\\). One\ncould summarize the discussion by saying that the operation, \nhypotenuse-length,\nthat computes the length\nof the hypotenuse of a right triangle given the lengths \\(a\\) and\n\\(b\\) of its legs, is: \nhypotenuse-length \\(:= \\lambda a[\\lambda b[\\sqrt{a^2 + b^2}]]\\) \nBy the principle of \\(\\beta\\)-reduction, we have, for example, that \nhypotenuse-length\n3, the application of hypotenuse-length\nto 3, is\n\\(\\lambda b[\\sqrt{3^2 + b^2}]\\), which is a\nfunction of that is ‘waiting’ for another argument. The\n\\(\\lambda\\)-term hypotenuse-length 3 can\nbe viewed as a function that computes the length of the hypotenuse of\na right triangle one of whose legs has length 3. We find,\nfinally, that (hypotenuse-length\n3)4—the application of hypotenuse-length\nto 3 and then to 4—is\n5, as expected. \nAnother way to understand the reduction of many-place functions to\none-place functions is to imagine a machine \\(M\\) that initially\nstarts out by loading the first \\(a\\) of multiple arguments\n\\(a, b,\\ldots\\) into memory. If one then suspends the\nmachine after it has loaded the first argument into memory, one can\nview the result as another machine M\\(_a\\) that is\nawaiting one fewer input; the first argument is now fixed. An important philosophical issue concerning the \\(\\lambda\\)-calculus\nis the question of its underlying concept of functions. In set theory,\na function is standardly understood as a set of argument-value\npairs. More specifically, a function is understood as a\nset \\(f\\) of ordered pairs satisfying the property that\n\\((x,y) \\in f\\) and \\((x,z) \\in f\\)\nimplies \\(y = z\\). If \\(f\\) is a function and\n\\((x,y) \\in f\\), this means that the function f assigns\nthe value \\(y\\) to the argument \\(x\\). This is the concept of\nfunctions-as-sets. Consequently, the notion of\nequality of functions-as-sets is equality qua sets, which,\nunder the standard principle of extensionality, entails that two\nfunctions are equal precisely when they contain the same ordered\npairs. In other words, two functions are identical if and only if they\nassign the same values to the same arguments. In this sense,\nfunctions-as-sets are\nextensional objects. In contrast, the notion of a function at work in \\(\\lambda\\)-calculus\nis one where functions are understood as rules: a function is\ngiven by a rule for how to determine its values from its\narguments. More specifically, we can view a \\(\\lambda\\)-term\n\\(\\lambda x[M]\\) as a description of an operation that,\ngiven \\(x\\), produces \\(M\\); the body \\(M\\) of the\nabstraction term is, essentially, a rule for what to do with\n\\(x\\). This is the conception\nof functions-as-rules. Intuitively, given\nrules \\(M\\) and \\(N\\), we cannot in general decide whether\n\\(\\lambda x[M]\\) is equal to \\(\\lambda x[N]\\). The\ntwo terms might ‘behave’ the same (have the same value\ngiven the same arguments), but it may not be clear what resources are\nneeded for showing the equality of the terms. In this sense,\nfunctions-as-rules are non-extensional objects. To distinguish the extensional concept of functions-as-sets from\nthe non-extensional concept of functions-as-rules, the latter is often\nreferred to as an ‘intensional’ function concept,\nin part because of the ostensibly intensional concept of a rule\ninvolved. This terminology is particularly predominant in the\ncommunity of mathematical logicians and philosophers of mathematics\nworking on the foundations of mathematics. But from the perspective of\nthe philosophy of language, the terminology can be somewhat\nmisleading, since in this context, the extensional-intensional\ndistinction has a slightly different meaning. In the standard possible-worlds framework of philosophical\nsemantics, we would distinguish between an extensional and an\nintensional function concept as follows. Let us say that that two\nfunctions are extensionally equivalent at a world if and only if they\nassign the same values to the same arguments at that world. And\nlet us say that two functions are intensionally equivalent if\nand only if they assign the same values to the same arguments at\nevery possible-world. To illustrate, consider the functions\nhighest-mountain-on-earth and highest-mountain-in-the-Himalayas, where\n highest-mountain-on-earth\n assigns the highest mountain on\nearth as the value to every argument and\n highest-mountain-in-the-Himalayas\n assigns\nthe highest mountain in the Himalayas as the value to every\nargument. The two functions are extensionally equivalent (at the\nactual world), but not intensionally so. At the actual world, the two\nfunctions assign the same value to every argument, namely\nMt. Everest. Now consider a world where Mt. Everest is not the highest\nmountain on earth, but say, Mt. Rushmore is. Suppose further that this\nis so, just because Mt. Rushmore is 30.000 feet/9.100 m higher than it\nis at the actual world, while Mt. Everest, with its roughly 29.000\nfeet/8.800 m, is still the highest mountain in the Himalayas. At that\nworld,\n highest-mountain-on-earth\n now assigns Mt. Rushmore as the value to\nevery argument, while\n highest-mountain-in-the-Himalayas \n still assigns Mt. Everest to\nevery object. In other words, \nhighest-mountain-on-earth and\n highest-mountain-in-the-Himalayas are\nextensionally equivalent (at the actual world) but not intensionally equivalent. A function concept may now be called extensional if and\nonly if it requires functions that are extensionally equivalent at the\nactual world to be identical. And a function concept may be classified\nas intensional if and only if it requires intensionally\nequivalent functions to be identical. Note that these classifications\nare conceptually different from the distinctions commonly used in the\nfoundations of mathematics. On the terminology used in the foundations\nof mathematics, functions-as-sets are classified as extensional since\nthey use the axiom of extensionality as their criterion of identity,\nand functions-as-rules are classified as intensional because they rely\non the ostensibly intensional concept of a rule. In the present\npossible-worlds terminology, function concepts are classified as\nextensional or intensional based of their behavior at\npossible-worlds. \nAn issue from which conceptual confusion might arise is that the two\nterminologies potentially pass different verdicts on the function concept at work\nin the \\(\\lambda\\)-calculus. To see this, consider the following two functions: \nThese two functions are clearly extensionally equivalent: they assign\nthe same value to the same input at the actual world. Moreover, given\nstandard assumptions in possible worlds semantics, the two functions\nare also intensionally equivalent. If we assume that\nmathematical facts, like facts about addition and subtraction, are\nnecessary in the sense that they are the same at every possible world,\nthen we get that the two functions give the same value to the\narguments at every possible world. So, an intensional function\nconcept would require the two functions to be identical. In\nthe \\(\\lambda\\)-calculus, however, it’s not clear at all that we should\nidentify the two functions. Formally speaking, without the help of\nother principle, we cannot show that the two \\(\\lambda\\)-terms denote the\nsame function. Moreover, informally speaking, on the conception of\nfunctions-as-rules, it’s not even clear that we should\nidentify them: the two terms involve genuinely different rules, and so\nwe might be tempted to say that they denote different functions. A function concept that allows for intensionally equivalent\nfunctions to be distinct is called hyperintensional. The point\nis that in possible-worlds terminology, the function concept at work\nin the \\(\\lambda\\)-calculus may be regarded not as intentional but\nhyperintensional—in contrast to what the terminology\ncommon in the foundations of mathematics says. Note that it’s unclear\nhow an intensional semantic framework, like the possible-worlds\nframework, could even in principle account for a non-intensional\nfunction concept. On the semantics of the \\(\\lambda\\)-calculus, see\nsection 7. The point here was simply to clarify\nany conceptual confusions that might arise from different\nterminologies at play in philosophical discourse. \nThe hyperintensionality of the \\(\\lambda\\)-calculus is particularly\nimportant when it comes to its applications as a theory of not only\nfunctions, but more generally \\(n\\)-ary relations. On\nthis, see section\n 9.3.\n It is effectively the hyperintensionality of the \\(\\lambda\\)-calculus\nthat makes it an attractive tool in this context. It should be noted,\nhowever, that the \\(\\lambda\\)-calculus can be made extensional (as well\nas intensional) by postulating additional laws concerning the equality\nof \\(\\lambda\\)-terms. On this, see section\n 5. \nThe official syntax of the \\(\\lambda\\)-calculus is quite simple; it is\ncontained in the next definition. \nDefinition For the alphabet of the language of the\n\\(\\lambda\\)-calculus we take the left and right parentheses, left and\nright square brackets, the symbol ‘\\(\\lambda\\)’, and an\ninfinite set of variables. The class of \\(\\lambda\\)-terms\nis defined inductively as follows: \nBy ‘term’ we always mean ‘\\(\\lambda\\)-term’.\nTerms formed according to rule (2) are called application\nterms. Terms formed according to rule (3) are called\nabstraction terms. \nAs is common when dealing with formal languages that have grouping\nsymbols (the left and right parenthesis, in our case), some\nparentheses will be omitted when it is safe to do so (that is, when\nthey can be reintroduced in only one sensible way). Juxtaposing more\nthan two \\(\\lambda\\)-terms is, strictly speaking, illegal. To avoid the\ntedium of always writing all needed parentheses, we adopt the\nfollowing convention: \nConvention (association to the left): When more than\ntwo terms \\(M_1 M_2 M_3 \\ldots M_n\\) are juxtaposed we can recover the\nmissing parentheses by associating to the\nleft: reading from left to right, group \\(M_1\\) and\n\\(M_2\\) together, yielding \\((M_1 M_2)M_3 \\ldots M_n\\); then group\n\\((M_1 M_2)\\) with \\(M_3\\): \\(((M_1 M_2)M_3)\\ldots M_n\\), and so\nforth. \nThe convention thus gives a unique reading to any sequence of\n\\(\\lambda\\)-terms whose length is greater than 2. \nThe function of \\(\\lambda\\) in an abstraction term\n\\((\\lambda x[M]\\)) is that it binds the\nvariable appearing immediately after it in the term \\(M\\). Thus\n\\(\\lambda\\) is analogous to the universal and existential quantifiers\n\\(\\forall\\) and \\(\\exists\\) of first-order logic. One can define,\nanalogously, the notions of free and bound variable in the expected\nway, as follows. \nDefinition The syntactic functions \\(\\mathbf{FV}\\) and\n\\(\\mathbf{BV}\\) (for ‘free variable’ and ‘bound\nvariable’, respectively) are defined on the set of \\(\\lambda\\)-terms by\nstructural induction thus: For every variable \\(x\\), term \\(M\\), and term \\(N\\): \nIf \\(\\mathbf{FV}(M) = \\varnothing\\) then \\(M\\) is called a\ncombinator. \nClause (3) in the two definitions supports the intention that \\(\\lambda\\)\nbinds variables (ensures that they are not free). Note the difference\nbetween \\(\\mathbf{BV}\\) and \\(\\mathbf{FV}\\) for variables. \nAs is typical in other subjects where the concepts appear, such as\nfirst-order logic, one needs to be careful about the issue; a casual\nattitude about substitution can lead to syntactic\n difficulties.[1]\n We can defend a casual attitude by adopting the convention that we\nare interested not in terms themselves, but in a certain equivalence\nclass of terms. We now define substitution, and then lay down a\nconvention that allows us to avoid such difficulties. \nDefinition (substitution) We write\n‘\\(M[x := N]\\)’ to denote the\nsubstitution of \\(N\\) for the free occurrences of \\(x\\) in\n\\(M\\). A precise\n definition[2]\n by recursion on the set of \\(\\lambda\\)-terms is as follows: for all\nterms \\(A\\), \\(B\\), and \\(M\\), and for all variables \\(x\\)\nand \\(y\\), we define \nClause (1) of the definition simply says that if we are to substitute\n\\(M\\) for \\(x\\) and we are dealing simply with \\(x\\), then\nthe result is just \\(M\\). Clause (2) says that nothing happens when\nwe are dealing (only) with a variable different from \\(x\\) but we\nare to substitute something for \\(x\\). Clause (3) tells us that\nsubstitution unconditionally distributes over applications. Clauses\n(4) and (5) concern abstraction terms and parallel clauses (1) and (2)\n(or rather, clauses (2) and (1), in opposite order): If the bound\nvariable \\(z\\) of the abstraction term \\(\\lambda z[A]\\)\nis identical to the variable \\(x\\) for which we are to do a\nsubstitution, then we do not perform any substitution (that is,\nsubstitution “stops”). This coheres with the intention\nthat \\(M[x := N]\\) is supposed to denote the\nsubstitution of \\(N\\) for the free occurrences of \\(x\\)\nin \\(M\\). If \\(M\\) is an abstraction term\n\\(\\lambda x[A]\\) whose bound variable is \\(x\\), then\n\\(x\\) does not occurr freely in \\(M\\), so there is nothing to\ndo. This explains clause 4. Clause (5), finally, says that if the\nbound variable of an abstraction term differs from \\(x\\), then at\nleast \\(x\\) has the “chance ” to occur freely in the\nabstraction term, and substitution continues into the body of the\nabstraction term. \nDefinition (change of bound variables,\n\\(\\alpha\\)-convertibility).\nThe term \\(N\\) is obtained from the term \\(M\\) by a change\nof bound variables if, roughly, any abstraction term\n\\(\\lambda x[A]\\) inside \\(M\\) has been replaced by\n\\(\\lambda y[A[x := y]]\\). \nLet us say that terms \\(M\\) and \\(N\\) are\n\\(\\alpha\\)-convertible if there is a\nsequence of changes of bound variables starting from \\(M\\) and ending\nat \\(N\\). \nAxiom. \\(\\beta\\)-conversion\n(stated with a a no-capture proviso): \n\\( (\\lambda x[M])N \\rhd M[x := N]\\), provided no variable that\noccurrs free in \\(N\\) becomes bound after its substitution into\n\\(M\\). \nRoughly, we need to adhere to the principle that free variables ought\nto remain free; when an occurrence of a variable is threatened to\nbecome bound by a substitution, simply perform enough\n\\(\\alpha\\)-conversions to sidestep the problem. If we keep this in\nmind, we can work with \\(\\lambda\\)-calculus without worrying about\nthese nettlesome syntactic difficulties.  So, for example, we can't\napply the function \\(\\lambda x[\\lambda y[x(y-5)]]\\) to the argument\n\\(2y\\) because upon substitution of “\\(2y\\)” for\n“\\(x\\)”, the “\\(y\\)” in “\\(2y\\)”\nwould be captured by the variable-binding operator “\\(\\lambda\ny\\)”.  Such a substitution would yield a function different from\nthe one intended. However, we can first transform \\(\\lambda x[\\lambda\ny[x(y-5)]]\\) to \\(\\lambda x[\\lambda z[x(z-5)]]\\) by\n\\(\\alpha\\)-conversion, and then apply this latter function to the\nargument \\(2y\\).  So whereas the following is not a valid use of\n\\(\\beta\\)-conversion:\n\n   \\[ (\\lambda x[\\lambda y[x(y-5)]])2y  \\rhd \\lambda y[2y(y-5)]\\]\n\nwe can validly use \\(\\beta\\)-conversion to conclude:\n\n   \\[ (\\lambda x[\\lambda z[x(z-5)]])2y \\rhd \\lambda z[2y(z-5)]\\]\n\nThis example helps one to see why the proviso to \\(\\beta\\)-conversion\nis so important.  The proviso is really no different from the one used\nin the statement of an axiom of the predicate calculus, namely:\n\\(\\forall x\\phi \\to \\phi^{\\tau}_x\\), provided no variable that is free\nin the term \\(\\tau\\) before the substitution becomes bound after the\nsubstitution. \nThe syntax of \\(\\lambda\\)-calculus is quite flexible. One can form all\nsorts of terms, even self-applications such as \\(xx\\). Such\nterms appear at first blush to be suspicious; one might suspect that\nusing such terms could lead to inconsistency, and in any case one\nmight find oneself reaching for a tool with which to forbid such\nterms. If one were to view functions and sets of ordered pairs of a\ncertain kind, then the \\(x\\) in \\(xx\\) would be a\nfunction (set of ordered pairs) that contains as an element a pair\n\\((x,y)\\) whose first element would be \\(x\\) itself. But\nno set can contain itself in this way, lest the axiom of foundation\n(or regularity) be violated. Thus, from a set theoretical perspective\nsuch terms are clearly dubious. Below one can find a brief sketch of\none such tool, type theory. But in fact such terms do not lead to\ninconsistency and serve a useful purpose in the context of\n\\(\\lambda\\)-calculus. Moreover, forbidding such terms, as in type theory,\ndoes not come for free (e.g., some of the expressiveness of untyped\n\\(\\lambda\\)-calculus is lost). \nAs defined earlier, a combinator is a \\(\\lambda\\)-term with\nno free variables. One can intuitively understand combinators as\n‘completely specified’ operations, since they have no free\nvariables. There are a handful of combinators that have proven useful\nin the history of \\(\\lambda\\)-calculus; the next table highlights some of\nthese special combinators. Many more could be given (and obviously\nthere are infinitely many combinators), but the following have concise\ndefinitions and have proved their utility. Below is a table of some standard\n\\(\\lambda\\)-terms and combinators. Below is a table of notational conventions employed in this entry. \nUsually, parentheses are used to separate the function from the\nargument, like so: ‘\\(M(N)\\)’. However, in\n\\(\\lambda\\)-calculus and kindred subjects the parentheses are used as\ngrouping symbols. Thus, it is safe to write the function and the\nargument adjacent to one other. \nIf we do not use parentheses to separate function and argument, how\nare we to disambiguate expressions that involve three or more terms,\nsuch as ‘\\(PQR\\)’? Recall our convention that we are to\nunderstand such officially illegal expressions by working from left to\nright, always putting parentheses around adjacent terms. Thus,\n‘\\(PQR\\)’ is to be understood as \\((PQ)R\\).\n‘\\(PQRS\\)’ is \\(((PQ)R)S\\). The expression\n‘\\((PQ)R\\)’ is disambiguated; by our convention, it is\nidentical to \\(PQR\\). The expression ‘\\(P(QR)\\)’ is also\nexplicitly disambiguated; it is distinct from \\(PQR\\) because it is\nthe application of \\(P\\) to the argument \\(QR\\) (which is itself the\napplication of the function \\(Q\\) to the argument\n\\(R)\\). \nThe official vocabulary of the \\(\\lambda\\)-calculus consists of the\nsymbol ‘\\(\\lambda\\)’, left ‘(’and right\n‘)’ parentheses, and a set of variables (assumed to be\ndistinct from the three symbols ‘\\(\\lambda\\)’,\n‘(’, and ‘)’ lest we have syntactic\nchaos). \nAlternative notation. It is not necessary to include\ntwo kinds of grouping symbols (parentheses and square brackets) in the\nsyntax. Parentheses or square brackets alone would obviously suffice.\nThe two kinds of brackets are employed in this entry for the sake of\nreadability. Given the two kinds of grouping symbols, we could\neconomize further and omit the parentheses from abstraction terms, so\nthat ‘\\((\\lambda x[M]\\))’ would be written as\n‘\\(\\lambda x[M]\\)’. \nSome authors write ‘\\(\\lambda x.M\\)’ or\n‘\\(\\lambda x\\cdot M\\)’, with a full stop or a\ncentered dot separating the bound variable from the body of the\nabstraction term. As with the square brackets, these devices are\nintended to assist reading \\(\\lambda\\)-terms; they are usually not part\nof the official syntax. (One sees this device used in earlier works of\nlogic, such as Principia Mathematica, where the function of\nthe symbol . in expressions such as\n‘\\(\\forall x\\).\\(\\phi\\)’ is to get us to\nread the whole of the formula \\(\\phi\\) as under the scope of the\n\\(\\forall x\\).) \nSome authors write abstraction terms without any device separating the\nbound variable from the body: such terms are crisply written as, e.g.,\n‘\\(\\lambda xx\\)’,\n‘\\(\\lambda yx\\)’. The practice is not without\nits merits: it is about as concise as one can ask for, and permits an\neven simpler official syntax of the \\(\\lambda\\)-calculus. But this\npractice is not flawless. In\n‘\\(\\lambda xyz\\)’, is the bound variable\n\\(x\\) or is it \\(xy\\)? Usually the names of variables are\nsingle letters, and theoretically this is clearly sufficient. But it\nseems unduly restrictive to forbid the practice of giving longer names\nto variables; indeed, such constructions arise naturally in computer\nprogramming languages. \nFor the sake of uniformity, we will adopt the square bracket notation\nin this entry. (Incidentally, this notation is used in (Turing,\n1937).) \nA bewildering array of notations to represent substitution can be\nfound in the literature on \\(\\lambda\\)-calculus and kindred subjects: \nWhich notation to use for substitution seems to be a personal matter.\nIn this entry we use a linear notation, eschewing superscripts and\nsubscripts. The practice of representing substitution with\n‘:=’ comes from computer science, where ‘:=’\nis read in some programming languages as assigning a value to a\nvariable. \nAs with the square brackets employed to write abstraction terms, the\nsquare brackets employed to write substitution are not officially part\nof the syntax of the \\(\\lambda\\)-calculus. \\(M\\) and A are terms,\n\\(x\\) is a variable; \\(M[x := A]\\) is another\nterm. \nThe syntactic identity relation \\(\\equiv\\) is not part of the official\nsyntax of \\(\\lambda\\)-calculus; this relation between \\(\\lambda\\)-terms\nbelongs to the metatheory of \\(\\lambda\\)-calculus. It is clearly a rather\nstrict notion of equality between \\(\\lambda\\)-terms. Thus, it is not the\ncase (if \\(x\\) and \\(y\\) are distinct variables) that \\(\\lambda x[x]\n\\equiv \\lambda y[y]\\), even though these two terms clearly\n‘behave’ in the same way in the sense that both are\nexpressions of the identity operation \\(x \\Rightarrow x\\). Later\nwe will develop formal theories of equality of \\(\\lambda\\)-terms with the\naim of capturing this intuitive equality of \\(\\lambda x[x]\\)\nand \\(\\lambda y[y]\\). \n\\(\\lambda\\)-calculus arose from the study of functions as rules. Already\nthe essential ingredients of the subject can be found in Frege’s\npioneering work (Frege, 1893). Frege observed, as we did above, that\nin the study of functions it is sufficient to focus on unary functions\n(i.e., functions that take exactly one argument). (The procedure of\nviewing a multiple-arity operation as a sequence of abstractions that\nyield an equivalent unary operation is called currying\nthe operation. Perhaps it would be more historically accurate to call\nthe operation fregeing, but there are often miscarriages\nof justice in the appellation of mathematical ideas.) In the 1920s,\nthe mathematician Moses Schönfinkel took the subject further with\nhis study of so-called combinators. As was common in the\nearly days of the subject, Schönfinkel was interested in the\nkinds of transformations that one sees in formal logic, and his\ncombinators were intended to be a contribution to the foundations of\nformal logic. By analogy with the reduction that one sees in classical\npropositional logic with the Sheffer stroke, Schöfinkel\nestablished the astonishing result that the all functions (in the\nsense of all transformations) could be given in terms of the\ncombinators \\(\\mathbf{K}\\) and \\(\\bS\\); later we will see the definition of\nthese combinators. \nTheorem For every term \\(M\\) made up of \\(\\mathbf{K}\\)\nand \\(\\bS\\) and the variable \\(x\\), there exists a term \\(F\\)\n(built only from \\(\\mathbf{K}\\) and \\(\\bS)\\) such that we can derive\n\\(Fx = M\\). \n(The proof that these two suffice to represent all functions is beyond\nthe scope of this entry. For further discussion, see the entry on\n combinatory logic.)\n One can prove the theorem constructively: there is an algorithm that,\ngiven \\(M\\), produces the required \\(F\\). Church called this\n\\(F\\) ‘\\(\\lambda x[M]\\)’ (Church,\n 1932).[3]\n From this perspective, the \\(\\beta\\)-rule can be justified: if\n‘\\(\\lambda x[M]\\)’ is to be a function \\(F\\)\nsatisfying \\(Fx = M\\), then\n\\(\\lambda x[M]\\)x should transform to \\(M\\). This is just\na special case of the more general principle that for all \\(N,\n(\\lambda x[M])N\\) should transform to\n\\(M[x := N]\\). \nAlthough today we have more clearly delimited systems of abstraction\nand rewriting, in its early days \\(\\lambda\\)-calculus and combinatory\nlogic (à la Schönfinkel) were bound up with investigations\nof foundations of mathematics. In the hands of Curry, Church, Kleene,\nand Rosser (some of the pioneers in the subject) the focus was on\ndefining mathematical objects and carrying out logical reasoning\ninside the these new systems. It turned out that these early attempts\nat so-called illative \\(\\lambda\\)-calculus and combinatory logic were\ninconsistent. Curry isolated and polished the inconsistency; the\nresult is now known as Curry’s paradox. See the entry on\n Curry’s paradox\n and appendix B of (Barendregt, 1985). \nThe \\(\\lambda\\)-calculus earns a special place in the history of logic\nbecause it was the source of the first undecidable problem. The\nproblem is: given \\(\\lambda\\)-terms \\(M\\) and \\(N\\), determine\nwhether \\(M = N\\). (A theory of\nequational reasoning about \\(\\lambda\\)-terms has not yet been defined;\nthe definition will come later.) This problem was shown to be\nundecidable. \nAnother early problem in the \\(\\lambda\\)-calculus was whether it is\nconsistent at all. In this context, inconsistency means that all terms\nare equal: one can reduce any \\(\\lambda\\)-term \\(M\\) to any other\n\\(\\lambda\\)-term \\(N\\). That this is not the case is an early result\nof \\(\\lambda\\)-calculus. Initially one had results showing that certain\nterms were not interconvertible (e.g., \\(\\mathbf{K}\\) and \\(\\bS)\\); later,\na much more powerful result, the so-called Church-Rosser theorem,\nhelped shed more light on \\(\\beta\\)-conversion and could be used to give\nquick proofs of the non-inter-convertibility of whole classes of\n\\(\\lambda\\)-terms. See below for more detailed discussion of\nconsistency. \nThe \\(\\lambda\\)-calculus was a somewhat obscure formalism until the\n1960s, when, at last, a ‘mathematical’ semantics was\nfound. Its relation to programming languages was also clarified. Till\nthen the only models of \\(\\lambda\\)-calculus were\n‘syntactic’, that is, were generated in the style of\nHenkin and consisted of equivalence classes of \\(\\lambda\\)-terms (for\nsuitable notions of equivalence). Applications in the semantics of\nnatural language, thanks to developments by Montague and other\nlinguists, helped to ‘spread the word’ about the subject.\nSince then the \\(\\lambda\\)-calculus enjoys a respectable place in\nmathematical logic, computer science, linguistics (see, e.g., Heim and\nKratzer 1998), and kindred fields. \nVarious notions of reduction for \\(\\lambda\\)-terms are available, but the\nprincipal one is \\(\\beta\\)-reduction, which we have already seen earlier.\nEarlier we used the notation ‘\\(\\rhd\\)’; we can be more\nprecise. In this section we discuss \\(\\beta\\)-reduction and some\nextensions. \nDefinition (one-step \\(\\beta\\)-reduction\n\\(\\rhd_{\\beta ,1})\\) For \\(\\lambda\\)-terms \\(A\\) and \\(B\\),\nwe say that \\(A\\) \\(\\beta\\)-reduces in one step to \\(B\\), written\n\\(A \\rhd_{\\beta ,1} B\\), just in case there\nexists an (occurrence of a) subterm \\(C\\) of \\(A\\), a variable\n\\(x\\), and \\(\\lambda\\)-terms \\(M\\) and \\(N\\) such that \\(C \\equiv(\\lambda x[M])N\\) and \\(B\\) is \\(A\\)\nexcept that the occurrence of \\(C\\) in \\(A\\) is replaced by\n\\(M[x := N]\\). \nHere are some examples of \\(\\beta\\)-reduction: \nThe variable \\(x\\) does not \\(\\beta\\)-reduce to anything. (It does not\nhave the right shape: it is simply a variable, not an application term\nwhose left-hand side is an abstraction term.) \n\\((\\lambda x[x])a \\rhd_{\\beta ,1} a\\). \nIf \\(x\\) and \\(y\\) are distinct variables, then\n\\((\\lambda x[y])a \\rhd_{\\beta ,1} y\\). \nThe \\(\\lambda\\)-term\n\\((\\lambda x[(\\lambda y[xy])a])b]\\) \\(\\beta\\)-reduces in one step to two different \\(\\lambda\\)-terms: \nand \nMoreover, one can check that these two terms \\(\\beta\\)-reduce in one step\nto a common term: \\(ba\\). We thus have: \nAs with any binary relation, one can ask many questions about the\nrelation \\(\\rhd_{\\beta ,1}\\) holding between \\(\\lambda\\)-terms,\nand one can define various derived notions in terms of\n\\(\\rhd_{\\beta ,1}\\). \nDefinition A \\(\\beta\\)-reduction sequence\nfrom a \\(\\lambda\\)-term \\(A\\) to a \\(\\lambda\\)-term \\(B\\) is a finite\nsequence \\(s_1 , \\ldots s_n\\) of\n\\(\\lambda\\)-terms starting with \\(A\\), ending with \\(B\\), and whose\nadjacent terms\n\\((s_k,s_{k+1})\\) satisfy\nthe property that \\(s_k \\rhd_{\\beta ,1} s_{k+1}\\). \nMore generally, any sequence \\(s\\)—finite or\ninfinite—starting with a \\(\\lambda\\)-term \\(A\\) is said to be a\n\\(\\beta\\)-reduction sequence commencing with \\(A\\) provided that the\nadjacent terms \\((s_k,s_{k+1})\\) of \\(s\\) satisfy the property that\n\\(s_k \\rhd_{\\beta ,1} s_{k+1}\\). \nContinuing with \\(\\beta\\)-reduction Example 1, there are no\n\\(\\beta\\)-reduction sequences at all commencing with the variable\n\\(x\\). \nContinuing with \\(\\beta\\)-reduction Example 2, the two-term sequence \nis a \\(\\beta\\)-reduction sequence from\n\\((\\lambda x[x])a\\) to \\(a\\). If \\(a\\) is a\nvariable, then this \\(\\beta\\)-reduction sequence cannot be prolonged, and\nthere are no other \\(\\beta\\)-reduction sequences commencing with\n\\((\\lambda x[x])a\\); thus, the set of\n\\(\\beta\\)-reduction sequences commencing with\n\\((\\lambda x[x])a\\) is finite and contains no\ninfinite sequences. \nConsider the term \\(\\mathbf{K}a\\boldsymbol{\\Omega}\\). There are infinitely many\nreduction sequences commencing with this term: \nIf \\(a\\) is a variable, one can see that all finite reduction\nsequences commencing with \\(\\bK a\\boldsymbol{\\Omega}\\) end at \\(a\\), and there\nis exactly one infinite reduction sequence. \nDefinition A \\(\\beta\\)-redex of a\n\\(\\lambda\\)-term \\(M\\) is (an occurrence of) a subterm of \\(M\\) of\nthe form \\((\\lambda x[P])Q\\). (‘redex’\ncomes from ‘reducible expression.) A \\(\\beta\\)-redex is simply a\ncandidate for an application of \\(\\beta\\)-reduction. Doing so, one\ncontracts the \\(\\beta\\)-redex. A term is said to be in\n\\(\\beta\\)-normal form if it has no \\(\\beta\\)-redexes. \n(Can a term have multiple \\(\\beta\\)-normal forms? The answer is literally\n‘yes’, but substantially the answer is ‘no’:\nIf a \\(M\\) and \\(M'\\) are \\(\\beta\\)-normal forms of some\nterm, then \\(M\\) is \\(\\alpha\\)-convertible to \\(M'\\) Thus,\n\\(\\beta\\)-normal forms are unique up to changes of bound variables.) \nSo far we have focused only on one step of \\(\\beta\\)-reduction. One can\ncombine multiple \\(\\beta\\)-reduction steps into one by taking the\ntransitive closure of the relation \\(\\rhd_{\\beta ,1}\\). \nDefinition For \\(\\lambda\\)-terms \\(A\\) and \\(B\\),\none says that \\(A\\) \\(\\beta\\)-reduces to \\(B\\),\nwritten \\(A \\rhd_{\\beta} B\\), if either \\(A \\equiv B\\) or there exists a finite \\(\\beta\\)-reduction sequence\nfrom \\(A\\) to \\(B\\). \nDefinition A term \\(M\\) has a \\(\\beta\\)-normal\nform if there exists a term \\(N\\) such that \\(N\\) is in\n\\(\\beta\\)-normal form an \\(M \\rhd_{\\beta} N\\). \nReducibility as defined is a one-way relation: it is generally not\ntrue that if \\(A \\rhd_{\\beta} B\\), then \\(B \\rhd_{\\beta} A\\). However, depending on one’s\npurposes, one may wish to treat \\(A\\) and \\(B\\) as equivalent if\neither \\(A\\) reduces to \\(B\\) or \\(B\\) reduces to \\(A\\).\nDoing so amounts to considering the reflexive, symmetric, and\ntransitive closure of the relation \\(\\rhd_{\\beta ,1,}\\). \nDefinition For \\(\\lambda\\)-terms \\(A\\) and \\(B\\),\nwe say that \\(A =_{\\beta} B\\) if either \\(A \\equiv B\\) or there exists a sequence \\(s_1 ,\n\\ldots s_n\\) starting with \\(A\\), ending\nwith \\(B\\), and whose adjacent terms\n\\((s_k,s_{k+1})\\) are such\nthat either \\(s_k \\rhd_{\\beta ,1} s_{k+1}\\) or \\(s_{k+1} \\rhd_{\\beta ,1} s_k\\). \nWe have thus far developed the theory of \\(\\beta\\)-reduction. This is by\nno means the only notion of reduction available in the\n\\(\\lambda\\)-calculus. In addition to \\(\\beta\\)-reduction, a standard\nrelation between \\(\\lambda\\)-terms is that of\n\\(\\eta\\)-reduction: \nDefinition (one-step \\(\\eta\\)-reduction) For\n\\(\\lambda\\)-terms \\(A\\) and \\(B\\), we say that \\(A\\) \\(\\beta\n\\eta\\)-reduces in one step to \\(B\\), written \\(A \\rhd_{\\beta \\eta ,1}\nB\\), just in case there exists an (occurrence of a) subterm \\(C\\) of\n\\(A\\), a variable \\(x\\), and \\(\\lambda\\)-terms \\(M\\) and \\(N\\) such\nthat either \n\\(C \\equiv(\\lambda x[M])N\\) and \\(B\\) is\n\\(A\\) except that the occurrence of \\(C\\) in \\(A\\) is\nreplaced by \\(M[x := N]\\) \nor \n\\(C \\equiv(\\lambda x[Mx]\\)) and \\(B\\) is\n\\(A\\) except that the occurrence of \\(C\\) in \\(A\\) is\nreplaced by \\(M\\). \nThe first clause in the definition of \\(\\rhd_{\\beta \\eta ,1}\\)\nensures that the relation extends the relation of one-step\n\\(\\beta\\)-reduction. As we did for the relation of one-step\n\\(\\beta\\)-reduction, we can replay the development for \\(\\eta\\)-reduction.\nThus, one has the notion of an \\(\\eta\\)-redex, and from\n\\(\\rhd_{\\eta ,1}\\) one can define the relation\n\\(\\rhd_{\\eta}\\) between \\(\\lambda\\)-terms as the symmetric and\ntransitive closure of \\(\\rhd_{\\eta ,1}\\), which captures\nzero-or-more-steps of \\(\\eta\\)-reduction. Then one defines\n\\(=_{\\eta}\\) as the symmetric and transitive closure of\n\\(\\rhd_{\\eta}\\). \nIf \\(A \\rhd_{\\eta ,1} B\\), then the length of\n\\(B\\) is strictly smaller than that of \\(A\\). Thus, there can be\nno infinite \\(\\eta\\)-reductions. This is not the case of\n\\(\\beta\\)-reduction, as we saw above in\n \\(\\beta\\)-reduction sequence examples 3\n and\n 4. \nOne can combine notions of reduction. One useful combination is to\nblend \\(\\beta\\)- and \\(\\eta\\)-reduction. \nDefinition (one-step \\(\\beta \\eta\\)-reduction)\n\\(\\lambda x[Mx] \\rhd_{\\beta \\eta ,1} M\\) and \\((\\lambda x[M]N))\n\\rhd_{\\beta \\eta ,1} M[x := N]\\). A\n\\(\\lambda\\)-term \\(A\\) \\(\\beta \\eta\\)-reduces in one step to a\n\\(\\lambda\\)-term \\(B\\) just in case either \\(A\\) \\(\\beta\\)-reduces to\n\\(B\\) in one step or \\(A\\) \\(\\eta\\)-reduces to \\(B\\) in one\nstep. \nAgain, one can replay the basic concepts of reduction, as we did for\n\\(\\beta\\)-reduction, for this new notion of reduction \\(\\beta \\eta\\). \nRecall that a term is said to be in \\(\\beta\\)-normal form if it has no\n\\(\\beta\\)-redexes, that is, subterms of the shape\n\\((\\lambda x[M]\\))N. A term has a \\(\\beta\\)-normal form if it\ncan be reduced to a term in \\(\\beta\\)-normal form. It should be\nintuitively clear that if a term has a \\(\\beta\\)-normal form, then we can\nfind one by exhaustively contracting all all \\(\\beta\\)-redexes of the\nterm, then exhaustively contracting all \\(\\beta\\)-redexes of all\nresulting terms, and so forth. To say that a term has a \\(\\beta\\)-normal\nform amounts to saying that this blind search for one will eventually\nterminate. \nBlind search for \\(\\beta\\)-normal forms is not satisfactory. In addition\nto be aesthetically unpleasant, it can be quite inefficient: there may\nnot be any need to exhaustively contract all \\(\\beta\\)-redexes. What is\nwanted is a strategy—preferably, a computable\none—for finding a \\(\\beta\\)-normal form. The problem is to\neffectively decide, if there are multiple \\(\\beta\\)-redexes of a term,\nwhich ought to be reduced. \nDefinition A \\(\\beta\\)-reduction strategy\nis a function whose domain is the set of all \\(\\lambda\\)-terms and whose\nvalue on a term \\(M\\) not in \\(\\beta\\)-normal form is a redex subterm\nof \\(M\\), and whose value on all terms M in \\(\\beta\\)-normal form is\nsimply \\(M\\). \nIn other words, a \\(\\beta\\)-reduction strategy selects, whenever a term\nhas multiple \\(\\beta\\)-redexes, which one should be contracted. (If a\nterm is in \\(\\beta\\)-normal form, then nothing is to be done, which is\nwhy we require in the definition of \\(\\beta\\)-reduction strategy that it\ndoes not change any term in \\(\\beta\\)-normal form.) One can represent a\nstrategy \\(S\\) as a relation \\(\\rhd_S\\) on \\(\\lambda\\)-terms,\nwith the understanding that \\(M \\rhd_S N\\)\nprovided that \\(N\\) is obtained from \\(M\\) in one step by\nadhering to the strategy S. When viewed as relations, strategies\nconstitute a subrelation of \\(\\rhd_{\\beta ,1}\\). \nA \\(\\beta\\)-reduction strategy may or may not have the property that\nadhering to the strategy will ensure that we (eventually) reach a\n\\(\\beta\\)-normal form, if one exists. \nDefinition A \\(\\beta\\)-reduction strategy \\(S\\) is\nnormalizing if for all \\(\\lambda\\)-terms \\(M\\), if\n\\(M\\) has a \\(\\beta\\)-normal form \\(N\\), then the sequence\n\\(M, S(M), S(S(M)),\\ldots\\)\nterminates at \\(N\\). \nSome \\(\\beta\\)-reduction strategies are normalizing, but others are\nnot. \nOnce we have defined a reduction strategy, it is natural to ask\nwhether one can improve it. If a term has a \\(\\beta\\)-normal form, then a\nstrategy will discover a normal form; but might there be a shorter\n\\(\\beta\\)-reduction sequence that reaches the same normal form (or a term\nthat is \\(\\alpha\\)-convertible to that normal form)? This is the question\nof optimality. Defining optimal strategies and showing that\nthey are optimal is generally considerably more difficult than simply\ndefining a strategy. For more discussion, see (Barendregt, 1984\nchapter 10). \nFor the sake of concreteness, we have discussed only \\(\\beta\\)-reduction\nstrategies. But in the definitions above the notion of reduction\n\\(\\beta\\) is but one possibility. For any notion \\(R\\) of reduction we\nhave the associated theory of \\(R\\)-reduction strategies, and one\ncan replay the problems of normalizability, optimality, etc., for\n\\(R\\). \nWe discussed earlier how the \\(\\lambda\\)-calculus is a non-extensional\ntheory of functions. If, in the non-extensional spirit, we understand\n\\(\\lambda\\)-terms as descriptions, how should we treat equality of\n\\(\\lambda\\)-terms? Various approaches are available. In this section, let\nus treat the equality relation = as a primitive, undefined relation\nholding between two \\(\\lambda\\)-terms, and try to axiomatize the\nproperties that equality should have. The task is to identity axioms\nand formulate suitable rules of inference concerning the\nequality of \\(\\lambda\\)-terms. \nSome obvious properties of equality, having nothing to do with\n\\(\\lambda\\)-calculus, are as follows: \nAs is standard in proof theory, the way to read these rules of\ninference is that above the horizontal rule \\(\\frac{}{\\phantom{X=X}}\\)\nare the \npremises of the rule (which are equations) and the\nequation below the horizontal rule is the conclusion of\nthe rule of inference. In the case of the reflexivity rule, nothing is\nwritten above the horizontal rule. We understand such a case as saying\nthat, for all terms \\(X\\), we may infer the equation \\(X = X\\) from no premises. \nThe three rules of inference listed in the previous section governing\nequality have nothing to do with the \\(\\lambda\\)-calculus. The following\nlists rules of inference that relate the undefined notion of equality\nand the two term-building operations of the \\(\\lambda\\)-calculus,\napplication and abstraction. \nThese rules of inference say that = is a congruence\nrelation on the set of \\(\\lambda\\)-terms: it\n‘preserves’ both the application and abstraction\nterm-building operations \nThe final rule of inference, \\(\\beta\\)-conversion, is the most\nimportant: \nAs before with the reflexivity rule, the rule \\(\\boldsymbol{\\beta}\\) has no\npremises: for any variable \\(x\\) and any terms \\(M\\) and\n\\(A\\), one can infer the equation\n\\((\\lambda x[M])A = M[x := A]\\)\nat any point in a formal derivation in the theory \\(\\boldsymbol{\\lambda}\\). \nA number of extensions to \\(\\boldsymbol{\\lambda}\\) are available. Consider, for\nexample, the rule (\\(\\boldsymbol{\\eta}\\)), which expresses the principle of\n\\(\\eta\\)-reduction as a rule of inference: \nRule \\(\\boldsymbol{\\eta}\\) tells us that a certain kind of abstraction is\notiose: it is safe to identify \\(M\\) with the function that, given\nan argument \\(x\\), applies \\(M\\) to \\(x\\). Through this rule\nwe can also see that all terms are effectively functions. One can\nintuitively justify this rule using the principle of\n\\(\\beta\\)-reduction. \nOne can view rule \\(\\mathbf{Ext}\\) as a kind of generalization principle. If\nwe have derived that \\(Mx = Nx\\), but \\(x\\)\nfigures in neither \\(M\\) nor \\(N\\), then we have effectively\nshown that \\(M\\) and \\(N\\) are alike. Compare this principle to\nthe principle of universal generalization in first-order logic: if we\nhave derived \\(\\phi(x)\\) from a set \\(\\Gamma\\) of hypotheses in which\n\\(x\\) is not free, then we can conclude that \\(\\Gamma\\) derives\n\\(\\forall x\\phi\\). \nAnother productive principle in the \\(\\lambda\\)-calculus permits us to\nidentify terms that ‘act’ the same: \nThe rule \\(\\boldsymbol{\\omega}\\) has infinitely many hypotheses: on\nthe assumption that \\(Mx = Nx\\), no matter what \\(x\\) may be, then we\ncan conclude that \\(M = N\\). The \\(\\boldsymbol{\\omega}\\) rule is an\nanalogue in the \\(\\lambda\\)-calculus of the rule of inference under\nthe same name in formal number theory, according to which one can\nconclude the universal formula \\(\\forall x\\phi\\) provided one has\nproofs for \\(\\phi(x := \\mathbf{0}), \\phi(x := \\mathbf{1}),\\ldots\\)\n. Note that unlike the rule \\(\\mathbf{Ext}\\), the condition that \\(x\\)\nnot occur freely in \\(M\\) or \\(N\\) does not arise. \nIs the \\(\\lambda\\)-calculus consistent? The question might not be\nwell-posed. The \\(\\lambda\\)-calculus is not a logic for reasoning about\npropositions; there is no apparent notion of contradiction \\((\\bot)\\) or\na method of forming absurd propositions (e.g.,\n\\(p \\wedge \\neg p)\\). Thus\n‘inconsistency’ of the \\(\\lambda\\)-calculus cannot mean that\n\\(\\bot\\), or some formula tantamount to \\(\\bot\\), is derivable. A suitable\nnotion of ‘consistent’ is, however, available.\nIntuitively, a logic is inconsistent if it permits us to derive too\nmuch. The theory \\(\\lambda\\) is a theory of equations. We can thus\ntake inconsistency of \\(\\lambda\\) to mean: all equations are\nderivable. Such a property, if it were true of \\(\\lambda\\),\nwould clearly show that \\(\\lambda\\) is of little use as a formal\ntheory. \nEarly formulations of the idea of \\(\\lambda\\)-calculus by A. Church were\nindeed inconsistent; see (Barendregt, 1985, appendix 2) or (Rosser,\n1985) for a discussion. To take a concrete problem: how do we know\nthat the equation \\(\\bK = \\mathbf{I}\\) is not a theorem of\n\\(\\lambda\\)? The two terms are obviously intuitively distinct.\n\\(\\bK\\) is a function of two arguments, whereas \\(\\mathbf{I}\\) is a\nfunction of one argument. If we could show that\n\\(\\bK = \\mathbf{I}\\), then we could show that \\(\\mathbf{KK} = \\mathbf{IK}\\), whence \\(\\mathbf{KK} = \\bK\\) would be a theorem of\n\\(\\lambda\\), along with many other equations that strike us as\nintuitively unacceptable. But when we’re investigating a formal theory\nsuch as \\(\\lambda\\), intuitive unacceptability by no means implies\nunderivability. What is missing is a deeper understanding of\n\\(\\beta\\)-reduction. \nAn early result that gave such an understanding is known as the\nChurch-Rosser theorem: \nTheorem (Church-Rosser) If \\(P \\rhd_{\\beta} Q\\) and \\(P \\rhd_{\\beta}\\) R, then there exists a term \\(S\\) such\nthat both \\(Q \\rhd_{\\beta} S\\) and \\(R \\rhd_{\\beta} S\\). \n(The proof of this theorem is quite non-trivial and is well-beyond the\nscope of this entry.) The result is a deep fact about\n\\(\\beta\\)-reduction. It says that no matter how we diverge from \\(P\\)\nby \\(\\beta\\)-reductions, we can always converge again to a common\nterm. \nThe Church-Rosser theorem gives us, among other things, that the plain\n\\(\\lambda\\)-calculus—that is, the theory \\(\\lambda\\) of\nequations between \\(\\lambda\\)-terms—is consistent, in the sense\nthat not all equations are derivable. \nAs an illustration, we can use the Church-Rosser theorem to solve the\nearlier problem of showing that the two terms \\(\\bK\\) and \\(\\mathbf{I}\\)\nare not identified by \\(\\lambda\\). The two terms are in\n\\(\\beta\\)-normal form, so from them there are no \\(\\beta\\)-reduction\nsequences at all. If \\(\\bK = \\mathbf{I}\\) were a theorem of\n\\(\\lambda\\), then there would be a term \\(M\\) from which there\nis a \\(\\beta\\)-reduction path to both \\(\\mathbf{I}\\) and \\(\\bK\\). The\nChurch-Rosser theorem then implies the two paths diverging from\n\\(M\\) can be merged. But this is impossible, since \\(\\bK\\) and\n\\(\\mathbf{I}\\) are distinct \\(\\beta\\)-normal forms. \nThe Church-Rosser theorem implies the existence of \\(\\beta\\)-reduction\nsequences commencing from \\(\\bK\\) and from \\(\\mathbf{I}\\) that end at a\ncommon term. But there are no \\(\\beta\\)-reduction sequences at all\ncommencing from \\(\\mathbf{I}\\), because it is in \\(\\beta\\)-normal form, and\nlikewise for \\(\\bK\\). \nTheorem \\(\\lambda\\) is consistent, in the sense\nthat not every equation is a theorem. \nTo prove the theorem, it is sufficient to produce one underivable\nequation. We have already worked through an example: we used the\nChurch-Rosser theorem to show that the equation\n\\(\\bK = \\mathbf{I}\\) is not a theorem of \\(\\lambda\\). Of\ncourse, there’s nothing special about these two terms. A significant\ngeneralization of this result is available: if \\(M\\) and\n\\(N\\) in \\(\\beta\\)-normal form but \\(M\\) is distinct from \\(N\\),\nthen the equation \\(M = N\\) is not a theorem of\n\\(\\lambda\\). (This simple condition for underivability does\nnot generally hold if we add additional rules of inference to\n\\(\\lambda\\).)  \nThe theories \\(\\lambda \\eta\\) and \\(\\lambda \\omega\\) are\nlikewise consistent. One can prove these consistency results along the\nlines of the consistency proof for \\(\\lambda\\) by extending the\nChurch-Rosser theorem to the wider senses of derivability of these\ntheories. \nAlthough the \\(\\lambda\\)-calculus is ‘about’ calculating with\nfunctions by substituting values for arguments, this simple point of\nview cannot support a semantics for the (untyped) \\(\\lambda\\)-calculus if\nby ‘function’ we understand, as is standard in set theory,\na relation \\(R\\) such that for every pair \\((x,y)\\) and\n\\((x,z)\\) in \\(R\\) with the same first component \\(x\\)\nwe have \\(y = z\\). For sets \\(X\\) and \\(Y\\), let\n\\(X^Y\\) denote the set of functions whose domain\nis \\(Y\\) and with values in \\(X\\). Intuitively, if \\(X\\) is\nthe domain of an interpretation of \\(\\lambda\\)-calculus, then \\(X\\)\nshould be, in some sense, isomorphic to \\(X^X\\)\nbecause the domain should be closed under abstraction (as well as\napplication). Taken literally, though, this isomorphism is impossible,\nbecause the cardinality of \\(X\\) always is of strictly smaller than\nthe cardinality of \\(X^X\\). \nIf one is interested in simply the existence of some kind of\nmodel of the \\(\\lambda\\)-calculus—one whose domain not necessarily\nconsist of functions—one can find them by various well-known\n‘syntactic’ constructions involving the theory\n\\(\\lambda\\), not unlike the well-known Henkin constructions .\nThese so-called term models, though, are an unsatisfactory solution to\nthe question of whether there are ‘mathematical’ models of\nthe \\(\\lambda\\)-calculus. \nThe cardinality argument shows that if we are to have a semantics for\n\\(\\lambda\\)-calculus, the interpretation of \\(\\lambda\\)-terms cannot simply\nbe functions in the set-theoretic sense of the term. There are,\nhowever, interpretations of \\(\\lambda\\)-calculus. The first model,\n\\(D_{\\infty}\\), was found by D. Scott; other models\nwere found later. These models solve the cardinality problem by\nrestricting the domain \\(X\\) of interpretation, so that, in them,\n\\(X\\) is in a suitable sense isomorphic to the ‘function\nspace’ \\(X^X\\). \nOne of the advantages of having different interpretations is that one\nsees different aspects of equality: each of these models takes a\ndifferent view on what \\(\\lambda\\)-terms get identified. The definitions\nof \\(D_{\\infty}\\) and other interpretations, the\nverifications that they are indeed models of \\(\\lambda\\)-calculus, and\nthe characterizations of the \\(\\lambda\\)-theories of these models, are\nbeyond the scope of this entry; see (Barendregt, 1985, chapter 18) or\n(Meyer 1982) for details. In recent years, there is a renewed interest\nin the models of \\(\\lambda\\)-calculus from the perspective of category\ntheory and categorical logic, focusing mainly on typed\n\\(\\lambda\\)-calculus (see sections\n 8.2\n and\n 9.1.2\n below) but also dealing with category theoretic models of the untyped\n\\(\\lambda\\)-calculus discussed in this article. See, for example,\n(Hyland, 2017) for details. \nA sister formalism of the \\(\\lambda\\)-calculus, developed slightly\nearlier, deals with variable-free combinations. Combinatory\nlogic is indeed even simpler than the \\(\\lambda\\)-calculus, since\nit lacks a notion of variable binding. \nThe language of combinatory logic is built up from\ncombinators and variables. There is some flexibility in\nprecisely which combinators are chosen as basic, but some standard\nones are \\(\\mathbf{I}, \\bK , \\bS, \\mathbf{B}\\) and \\(\\mathbf{C}\\). (The\nnames are not arbitrary.) \nAs with the \\(\\lambda\\)-calculus, with combinatory logic one is\ninterested in reducibility and provability. The\nprincipal reduction relations are: \nThere is a passage from \\(\\lambda\\)-calculus to combinatory logic via\ntranslation. It turns out that although combinatory logic lacks a\nnotion of abstraction, one can define such a notion and thereby\nsimulate the \\(\\lambda\\)-calculus in combinatory logic. Here is one\ntranslation; it is defined recursively. \nThis translation works inside-out, rather than outside-in. To\nillustrate: \nThe translation of the term \\(\\lambda y[y]\\), a\nrepresentative of the identity function, is mapped by this translation\nto the identity combinator \\(\\bI\\) (because of Rule 4), as\nexpected. \nThe \\(\\lambda\\)-term \\(\\lambda x[\\lambda y[x]]\\) that we\nhave been calling ‘\\(\\bK\\)’is mapped by this translation\nto: \nThe \\(\\lambda\\)-term \\(\\lambda x[\\lambda y[yx]]\\)\nthat switches its two arguments is mapped by this translation to: \nWe can confirm that the \\(\\lambda\\)-term \\(\\lambda x[\\lambda y[yx]]\\)\nand the translated combinatory logic term \\(\\bB(\\bC\\bI)\\bI\\) have\nanalogous applicative behavior: for all \\(\\lambda\\)-terms \\(P\\) and\n\\(Q\\) we have \nlikewise, for all combinatory logic terms \\(P\\) and \\(Q\\) we\nhave \nWe can give but a glimpse of combinatory logic; for more on the\nsubject, consult the entry on\n combinatory logic.\n Many of the issues discussed here for \\(\\lambda\\)-calculus have\nanalogues in combinatory logic, and vice versa. \nIn many contexts of reasoning and computing it is natural to\ndistinguish between different kinds of objects. The way this\ndistinction is introduced is by requiring that certain formulas,\nfunctions, or relations accept arguments or permit substitution only\nof some kinds of objects rather than others. We might require, for\nexample, that addition + take numbers as arguments. The effect of this\nrestriction is to forbid, say, the addition of 5 and the identity\nfunction\n \\(\\lambda x.x\\).(4).\n Regimenting objects into types is also the idea behind the passage\nfrom (unsorted, or one-sorted) first-order logic to\nmany-sorted first-order logic. (See (Enderton, 2001) and\n(Manzano, 2005) for more about many-sorted first-order logic.) As it\nstands, the \\(\\lambda\\)-calculus does not support this kind of\ndiscrimination; any term can be applied to any other term. \nIt is straightforward to extend the untyped \\(\\lambda\\)-calculus so that\nit discriminates between different kinds of objects. This entry limits\nitself to the type-free \\(\\lambda\\)-calculus. See the entries on\n type theory\n and\n Church’s type theory\n for a detailed discussion of the extensions of \\(\\lambda\\)-calculus that\nwe get when we add types, and see (Barendregt, Dekkers, Statman, 2013)\nfor a book length treatment of the subject. \nHere are two senses in which \\(\\lambda\\)-calculus is connected with\nlogic. \nIn the\n table of combinators\n above, we defined combinators \\(\\bT\\) and \\(\\bF\\) and said that\nthey serve as representations in the \\(\\lambda\\)-calculus of the truth\nvalues true and false, respectively. How do these terms function as\ntruth values? \nIt turns out that when one is treating \\(\\lambda\\)-calculus as a kind of\nprogramming language, one can write conditional statements “If\n\\(P\\) then \\(A\\) else \\(B\\)” simply as\n\\(PAB\\), where of course \\(P, A\\), and\n\\(B\\) are understood as \\(\\lambda\\)-terms. If \\(P \\rhd \\bT\\), that is, P is ‘true’, then we have \n(recall that, by definition, \\(\\bT \\equiv \\bK\\)) and if \n\\(P \\rhd \\bF\\), that is, \\(P\\) is ‘false’, then \n(recall that, by definition, \\(\\mathbf{F} \\equiv \\mathbf{KI})\\) which\nis just what we expect from a notion of if-then-else. If \\(P\\) reduces\nneither to \\(\\mathbf{T}\\) nor \\(\\mathbf{F}\\), then we cannot in\ngeneral say what \\(\\text{if-}P\\text{-then-}A\\text{-else-}B\\) is.\n \nThe encoding we’ve just sketched of some of the familiar truth values\nand logical connectives of classical truth-table logic does not show\nthat \\(\\lambda\\)-calculus and classical logic are intimately related. The\nencoding shows little more than embeddibility of the rules of\ncomputation of classical truth-table logic in \\(\\lambda\\)-calculus.\nLogics other than classical truth-table logic can likewise be\nrepresented in the \\(\\lambda\\)-calculus, if one has sufficient computable\ningredients for the logic in question (e.g., if the logical\nconsequence relation is computable, or if a derivability relation is\ncomputable, etc.). For more on computing with \\(\\lambda\\)-calculus, see\nsection\n 9.2\n below. A more intrinsic relationship between logic and\n\\(\\lambda\\)-calculus is discussed in the next section. \nThe correspondence to be descried here between logic and the\n\\(\\lambda\\)-calculus is seen with the help of an apparatus known as\ntypes. This section sketches the beginnings of the\ndevelopment of the subject known as type theory. We are\ninterested in developing type theory only so far as to make the\nso-called Curry-Howard-de Bruijn correspondence visible. A more\ndetailed treatment can be found in the entry on\n type theory;\n see also (Hindley, 1997) and (Barendregt, Dekkers, Statman,\n2013). \nType theory enriches the untyped \\(\\lambda\\)-calculus by requiring that\nterms be given types. In the untyped \\(\\lambda\\)-calculus,\nthe application \\(MN\\) is a legal term regardless of what\n\\(M\\) and \\(N\\) are. Such freedom permits one to form such\nsuspicious terms as \\(xx\\), and thence terms such as the\nparadoxical combinator \\(\\mathbf{Y}\\). One might wish to exclude terms like\n\\(xx\\) on the grounds that \\(x\\) is serving both as a\nfunction (on the left-hand side of the application) and as an argument\n(on the right-hand side of the application). Type theory gives us the\nresources for making this intuitive argument more precise. \n\nAssigning types to terms The language of type theory\nbegins with an (infinite) set of type\nvariables (which is assumed to be disjoint from the set\nof variables of the \\(\\lambda\\)-calculus and from the symbol\n‘\\(\\lambda\\)’ itself).  The set of types is made up of\ntype variables and the operation \\(\\sigma \\rightarrow\n\\tau\\). Variables in type theory now come with a\ntype annotation (unlike the unadorned term\nvariables of untyped \\(\\lambda\\)-calculus). Typed variables are\nrendered ‘\\(x : \\sigma\\)’; the intuitive reading is\n‘the variable \\(x\\) has the type \\(\\sigma\\)’. The\nintuitive reading of the judgment ‘\\(t : \\sigma \\rightarrow\n\\tau\\)’ is that the term \\(t\\) is a function that transforms\narguments of type \\(\\sigma\\) into arguments of type \\(\\tau\\). Given an\nassignment of types to term variables, one has the typing rules: \nand \nThe above two rules define the assignment of types to applications and\nto abstraction terms. The set of terms of type theory is the set of\nterms built up according to these formation rules. \nThe above definition of the set of terms of type theory is sufficient\nto rule out terms such as \\(xx\\). Of course, ‘\\(xx\\)’ is\nnot a typed term at all for the simple reason that no types have been\nassigned to it. What is meant is that there is no type \\(\\sigma\\) that\ncould be assigned to \\(x\\) such that ‘\\(xx\\)’ could be\nannotated in a legal way to make a typed term. We cannot assign to\n\\(x\\) a type variable, because then the type of the left-hand \\(x\\)\nwould fail to be a function type (i.e., a type of the shape\n‘\\(\\sigma \\rightarrow \\tau\\)’). Moreover, we cannot assign\nto \\(x\\) a function type \\(\\sigma \\rightarrow \\tau\\), because then\nthen \\(\\sigma\\) would be equal to \\(\\sigma \\rightarrow \\tau\\), which\nis impossible. \nAs a leading example, consider the types that are assigned to the\ncombinators \\(\\bI\\), \\(\\bK\\), and \\(\\bS\\): \n(See Hindley (1997) Table of principal types for a more\nextensive listing.) If we read ‘\\(\\rightarrow\\)’ as implication and\ntype variables as propositional variables, then we recognize three\nfamiliar tautologies in the right-hand column of the table. The\nlanguage used is meager: there are only propositional variables and\nimplication; there are no other connectives. \nThe table suggests an interesting correspondence between the typed\n\\(\\lambda\\)-calculus and formal logic. Could it really be that the\ntypes assigned to formulas, when understood as logical formulas, are\nvalid? Yes, though ‘validity’ needs to understood not as\nclassical validity: \nTheorem If \\(\\tau\\) is the type of some \\(\\lambda\\)-term,\nthen \\(\\tau\\) is intuitionistically valid. \nThe converse of this theorem holds as well: \nTheorem If \\(\\phi\\) is an intuitionistically valid\nlogical formula whose only connective is implication \\((\\rightarrow)\\), then\n\\(\\phi\\) is the type of some \\(\\lambda\\)-term. \nThe correspondence can be seen when one identifies intuitionistic\nvalidity with derivability in a certain natural deduction formalism.\nFor a proof of these two theorems, see (Hindley, 1997, chapter 6). \nThe correspondence expressed by the previous two theorems between\nintuitionistic validity and typability is known as the\nCurry-Howard-de Bruijn correspondence, after three logicians\nwho noticed it independently. The correspondence, as stated, is\nbetween only propositional intuitionistic logic, restricted to the\nfragment containing only the implication connective \\(\\rightarrow\\). One can\nextend the correspondence to other connectives and to quantifiers,\ntoo, but the most crisp correspondence is at the level of the\nimplication-only fragment. For details, see (Howard, 1980). \nOne can represent natural numbers in a simple way, as follows: \nDefinition (ordered tuples, natural numbers) The\nordered tuple \\(\\langle a_0,\\ldots a_n\\rangle\\) of \\(\\lambda\\)-terms\nis defined as \\(\\lambda x[x a_0\\ldots a_n]\\).  One then defines the\n\\(\\lambda\\)-term \\(\\ulcorner n\\urcorner\\) corresponding to the natural\nnumber \\(n\\) as: \\(\\ulcorner 0\\urcorner = \\mathbf{I}\\) and, for every\n\\(k\\), \\(\\ulcorner k + 1\\urcorner = \\langle \\mathbf{F}, \\ulcorner\nk\\urcorner\\rangle\\). \nThe \\(\\lambda\\)-term corresponding to the number 1, on this\nrepresentation, is: \nThe \\(\\lambda\\)-term corresponding to the number 2, on this\nrepresentation, is: \nSimilarly, \\(\\ulcorner 3\\urcorner\\) is\n\\(\\lambda x[x\\mathbf{F}\\lambda x[x\\mathbf{F}\\lambda x[x\\mathbf{FI}]]]\\). \nVarious representations of natural numbers are available; this\nrepresentation is but\n one.[6] \nUsing the ingredients provided by the \\(\\lambda\\)-calculus, one can\nrepresent all recursive functions. This shows that the model is\nexactly as expressive as other models of computing, such as Turing\nmachines and register machines. Priority goes to Turing’s definition\nof his machine, but Church’s proposal of the \\(\\lambda\\)-calculus was\ndeveloped at almost exactly the same time. \nTheorem For every recursive function \\(f\\) of\narity \\(n\\), there exists a \\(\\lambda\\)-term \\(f^*\\) such\nthat for all natural numbers \\(a_1,\\ldots a_n\\):\n \\(f(a_1,\\ldots a_n) = y\\) iff\n \\(\\boldsymbol{\\lambda} \\vdash f^*\\langle \\bar{a}_1,\\ldots,\\bar{a}_n\\rangle = \\bar{y}\\)\n  \nFor a proof, see\n the appendix. \nSince the class of recursive functions is an adequate representation\nof the class of all computable (number-theoretic) functions, thanks to\nthe work above we find that all computable (number-theoretic)\nfunctions can be faithfully represented in the \\(\\lambda\\)-calculus. \nThe motivation for the \\(\\lambda\\)-calculus given at the beginning of the\nentry was based on reading \\(\\lambda\\)-expressions as descriptions of\nfunctions. Thus, we have understood\n‘\\(\\lambda x[M]\\)’ to be a (or the) function\nthat, given \\(x\\), gives \\(M\\) (which generally, though not\nnecessarily, involves x). But it is not necessary to read\n\\(\\lambda\\)-terms as functions. One could understand \\(\\lambda\\)-terms as\ndenoting relations, and read an abstraction term\n‘\\(\\lambda x[M]\\)’ as the unary relation (or\nproperty) \\(R\\) that holds of an argument \\(x\\) just in case\n\\(M\\) does (see Carnap 1947, p. 3). On the relational reading, we\ncan understand an application term \\(MN\\) as a form of\npredication. One can make sense of these terms using the principle of\n\\(\\beta\\)-conversion: \nwhich says that the abstraction relation \\(\\lambda x[M]\\),\npredicated of A, is the relation obtained by plugging in A for all\nfree occurrences of \\(x\\) inside \\(M\\). \nAs a concrete example of this kind of approach to \\(\\lambda\\)-calculus,\nconsider an extension of first-order logic where one can form new\natomic formulas using \\(\\lambda\\)-terms, in the following way: \nSyntax: For any formula \\(\\phi\\) and any finite sequence\n\\(x_1 , \\ldots ,x_n\\) of\nvariables, the expression\n‘\\(\\lambda x_1 \\ldots x_n [\\phi]\\)’\nis a predicate symbol of arity n. Extend the notion of free and bound\nvariables (using the functions \\(\\mathbf{FV}\\) and \\(\\mathbf{BV})\\) in such a way\nthat \nand \nDeduction Assume as axioms the universal closures of\nall equivalences \nwhere \\(\\phi[x_1 ,\\ldots x_n := t_1,\\ldots t_n]\\) denotes the\nsimultaneous substitution of the terms \\(t_k\\) for\nthe variables \\(x_k\\) \\((1 \\le k \\le n)\\). \nSemantics For a first-order structure \\(A\\) and an\nassignment \\(s\\) of elements of \\(A\\) to variables, define \nAccording to this approach, one can use a \\(\\lambda\\) to treat\nessentially any formula, even complex ones, as if they were atomic. We\nsee the principle of \\(\\beta\\)-reduction in the deductive and semantic\nparts. That this approach adheres to the relational reading of\n\\(\\lambda\\) terms can be seen clearly in the semantics: according to the\nstandard Tarski-style semantics for first-order logic, the\ninterpretation of a formula (possibly with free variables) denotes a\nset of tuples of elements of the structure, as we vary the variable\nassignment that assigns elements of the structure to the\nvariables. \nOne can ‘internalize’ this functional approach. This is\ndone in the case of various property theories, formal\ntheories for reasoning about properties as metaphysical objects\n(Bealer 1982, Zalta 1983, Menzel 1986, 1993, and Turner 1987). This\nkind of theory is employed in certain metaphysical investigations\nwhere properties are metaphysical entities to be investigated. In\nthese theories, metaphysical relations are (or are among) the objects\nof interest; just as we add term-building symbols + and \\(\\times\\) in\nformal theories of arithmetic to build numbers, \\(\\lambda\\) is used in\nproperty theory to build relations. This approach contrasts with the\napproach above. There, \\(\\lambda\\) was added to the grammar of\nfirst-order logic by making it a recipe for building atomic formulas;\nit was a new formula-building operator, like \\(\\vee\\) or \\(\\rightarrow\\) or the\nother connectives. In the case of property theories, the \\(\\lambda\\)\nplays a role more like + and \\(\\times\\) in formal theories of arithmetic:\nit is used to construct relations (which, in this setting, are to be\nunderstood as a kind of metaphysical object). Unlike + and \\(\\times\\),\nthough, the \\(\\lambda\\) binds variables. \nTo give an illustration of how \\(\\lambda\\) is used in this setting,\nlet us inspect the grammar of a typical application (McMichael and\nZalta, 1980). One typically has a predication operator (or,\nmore precisely, a family of predication operators) \\(p_k (k \\ge\n0)\\). In a language where we have terms \\(\\mary\\) and \\(\\john\\) and a\nbinary relation loves, we can formally express: \nWe reason with these \\(\\lambda\\)-terms using a \\(\\beta\\)-conversion\nprinciple such as: \nFormally, the predication operator p\\(_k\\) is a\n\\((k+1)\\)-ary predicate symbol. The first argument is intended to\nbe a \\(\\lambda\\)-term of \\(k\\) arguments, and the rest of the\narguments are intended to be the arguments of the body of the\n\\(\\lambda\\)-term. The \\(\\beta\\)-principle above says that the predication of\nan \\(n\\)-ary \\(\\lambda\\)-term \\(L\\) to \\(n\\) terms holds\nprecisely when the body of \\(L\\) holds of those terms. \nIt turns out that in these theories, we may or may not be able to be\nfully committed to the principle of \\(\\beta\\)-conversion. Indeed, in some\nproperty theories, the full principle of \\(\\beta\\)-conversion leads to\nparadox, because one can replay a Russell-style argument when the full\nprinciple of \\(\\beta\\)-conversion is in place. In such settings, one\nrestricts the formation of \\(\\lambda\\)-formulas by requiring that the\nbody of a \\(\\lambda\\)-term not contain further \\(\\lambda\\)-terms or\nquantifiers. For further discussion, see (Orilia, 2000). \nOne of the reasons why property theories formulated in the\n\\(\\lambda\\)-calculus are of a particular philosophical importance is the\nhyperintensional nature of the calculus (see section\n 1.2).\n A property concept may be called\n‘hyperintensional’ if and only if it does not\nidentify necessarily coextensional properties, i.e. properties that\nare instanciated by exactly the same objects at every possible world.\nThe properties and relations described by the theories of Bealer,\nZalta, Menzel, and Turner have exactly this characteristic. In other\nwords, the theories are hyperintensional property theories. Recent\nyears have seen a significant rise of interest in hyperintensional\nconcepts of properties in metaphysics (Nolan 2014), and\ncorrespondingly property theories formulated in the \\(\\lambda\\)-calculus\nwill likely experience a rise of interest as well. \nIn the context of the foundations of mathematics, Zalta and\nOppenheimer (2011) argue for the conceptual priority of the relational\ninterpretation of \\(\\lambda\\)-terms over the functional one. ","contact.mail":"jkorbmacher@gmail.com","contact.domain":"gmail.com"}]
