[{"date.published":"2010-09-10","date.changed":"2017-09-06","url":"https://plato.stanford.edu/entries/hempel/","author1":"James Fetzer","author1.info":"http://www.d.umn.edu/~jfetzer/","entry":"hempel","body.text":"\n\n\nCarl G. Hempel (1905–1997) was the principal proponent of the\n“covering law” theory of explanation and the paradoxes of\nconfirmation as basic elements of the theory of science. A master of\nphilosophical methodology, Hempel pursued explications of initially\nvague and ambiguous concepts, which were required to satisfy very\nspecific criteria of adequacy. With Rudolf Carnap and Hans\nReichenbach, he was instrumental in the transformation of the dominant\nphilosophical movement of the 1930s and 40s, which was known as\n“logical positivism”, into the more nuanced position known\nas “logical empiricism”. His studies of induction,\nexplanation, and rationality in science exerted a profound influence\nupon more than a generation of philosophers of science, many of whom\nbecame leaders of the discipline in their own right.\n\nCarl G(ustav) Hempel (1905–97), known as “Peter” to\nhis friends, was born near Berlin, Germany, on January 8, 1905. He\nstudied philosophy, physics and mathematics at the Universities of\nGöttingen and Heidelberg before coming to the University of Berlin in\n1925, where he studied with Hans Reichenbach. Impressed by the work of\nDavid Hilbert and Paul Bernays on the foundations of mathematics and\nintroduced to the studies of Rudolf Carnap by Reichenbach, Hempel came\nto believe that the application of symbolic logic held the key to\nresolving a broad range of problems in philosophy, including that of\nseparating genuine problems from merely apparent ones. Hempel’s\ncommitment to rigorous explications of the nature of cognitive\nsignificance, of scientific explanation, and of scientific rationality\nwould become the hallmark of his research, which exerted great\ninfluence on professional philosophers, especially during the middle\ndecades of the 20th Century. \nIn 1929, at Reichenbach’s suggestion, Hempel spent the fall\nsemester at the University of Vienna, where he studied with Carnap,\nMoritz Schlick, and Frederick Waismann, who were advocates of logical\npositivism and members of (what came to be known as) “the Vienna\nCircle”. It would fall to Hempel to become perhaps the most\nastute critic of that movement and to contribute to its refinement as\nlogical empiricism. As Hitler increased his power in Germany, Hempel,\nwho was not Jewish but did not support the Nazi regime, moved to\nBrussels and began collaborating with Paul Oppenheim, which would\nresult in several classic papers, including “Studies in the\nLogic of Explanation”, which appeared in 1948 (Rescher 2005:\nChs. 8 and 9). Hempel would also visit the United States\ntwice—the University of Chicago in 1937–38 and then the\nCity College of New York in 1939–40, where he held his first\nacademic position—and eventually became a naturalized\ncitizen. \nHe was productive throughout his career, publishing such important\npapers as “The Function of General Laws in History” (1942)\nand “Studies in the Logic of Confirmation”,\n“Geometry and Empirical Science”, and “The Nature of\nMathematical Truth” (all in 1945), before leaving City College\nfor Yale. While there, Hempel would publish “Problems and\nChanges in the Empiricist Criterion of Meaning” (1950) and\n“The Concept of Cognitive Significance: A Reconsideration”\n(1951), as well as his first book, a volume in the International\nEncyclopedia of Unified Science, Fundamentals of Concept Formation\nin Empirical Science (1952). Hempel moved to Princeton in 1955,\nwhere his research program flourished and his influence upon\nprofessional philosophers became immense. \nDuring his two decades at Princeton, Hempel’s approach dominated\nthe philosophy of science. His major articles during this interval\nincluded “The Theoretician’s Dilemma” (1958),\n“Inductive Inconsistencies” (1960), “Rational Action” (1961), and\n“Deductive-Nomological vs. Statistical Explanation” and\n“Explanation in Science and in History” and\n (both in 1962). A classic collection of\nhis studies, Aspects of Scientific Explanation (1965c),\nbecame a scholar’s bible for generations of graduate students.\nHis introductory text, Philosophy of Natural Science (1966a),\nwould be translated into ten languages. Other articles he published\nthereafter included “Recent Problems of Induction” (1966b)\nand “Maximal Specificity and Lawlikeness in Probabilistic\nExplanation” (1968) as well as a series of studies that included\n“On the ‘Standard Conception’ of Scientific\nTheories” (1970). \nAt the University of Pittsburgh following his mandatory retirement\nfrom Princeton in 1973, he continued to publish significant articles,\nincluding studies of the nature of scientific rationality,\n“Scientific Rationality: Analytic vs. Pragmatic\nPerspectives” (1979), and “Turns in the Evolution of the\nProblem of Induction” (1981), and on the structure of scientific\ntheories, including, most importantly, “Limits of a Deductive\nConstrual of the Function of Scientific Theories” (1988a) as\nwell as “Provisos: A Problem Concerning the Inferential Function\nof Scientific Theories” (1988b), further enhancing his\nreputation by his willingness to reconsider earlier positions. After\nhis death in 1997, new collections of his papers appeared (Jeffrey\n2000; Fetzer 2001), which complemented studies of his research\n(Rescher 1969; Esler et al. 1985; Kitcher & Salmon 1989; Fetzer\n2000b). \nHowever surprising it may initially seem, contemporary developments in\nthe philosophy of science can only be properly appreciated in relation\nto the historical background of logical positivism. Hempel himself\nattained a certain degree of prominence as a critic of this movement.\nLanguage, Truth and Logic (1936; 2nd edition,\n1946), authored by A.J. Ayer, offers a lucid exposition of the\nmovement, which was—with certain variations—based upon the\nanalytic/synthetic distinction, the observational/theoretical\ndistinction, and the verifiability criterion of meaningfulness. A\nfundamental desideratum motivating its members was to establish\nstandards for separating genuine questions for which answers might be\nfound from pseudo questions for which no answers could be found. \nAccording to the first principle, sentences are analytic\nrelative to a language framework \\(\\mathbf{L}\\) when their truth\nfollows from its grammar and vocabulary alone. In English,\n“Bachelors are unmarried” cannot be false, since\n“bachelor \\(=_{\\df}\\) unmarried, adult male”. Sentences of\nthis kind make no claims about the world, but instead reflect features\nof the linguistic framework as syntactical or semantic truths in\n\\(\\mathbf{L}\\). And sentences are synthetic when they make\nclaims about the world. Their truth in \\(\\mathbf{L}\\) does not follow\nfrom its grammar and vocabulary alone but hinges upon properties of\nthe world and its history. According to logical positivism, all such\nclaims about the world have to be evaluated on the basis of\nexperience, which means the kind of knowledge they display is a\nposteriori. But kinds of knowledge whose truth can be established\nindependently of experience are a priori. \nLogical positivism affirmed that, given a language \\(\\mathbf{L}\\), all\na priori knowledge is analytic and all synthetic knowledge is\na posteriori, thus denying the existence of knowledge that is\nboth synthetic and a priori. Indeed, the denial of the\nexistence of synthetic a priori knowledge is commonly assumed\nto define the position known as “Empiricism”, while the\naffirmation of its existence defines “Rationalism”. Figure\n1 thus reflects the intersection of kinds of sentences and kinds of\nknowledge on the Empiricist approach: \nFigure 1. The Empiricist Position \nThe category for sentences that are analytic and yet represent a\nposteriori knowledge deserves discussion. The empirical study of\nthe use of language within language-using communities by field\nlinguists involves establishing the grammar and the vocabulary\nemployed within each such community. Their empirical research yields\ntheories of the languages, \\(\\mathbf{L}\\), used in those communities\nand affords a basis for distinguishing between which sentences are\nanalytic-in-\\(\\mathbf{L}\\) and which are synthetic-in-\\(\\mathbf{L}\\).\nThe kind of knowledge they acquire about specific sentences based on\nempirical procedures thus assumes the form, “Sentence \\(S\\) is\nanalytic-in-\\(\\mathbf{L}\\)”, when that is true of sentence\n\\(S\\), which is a posteriori. \nOne of Hempel’s early influential articles was a defense of\nlogicism, according to which mathematics—with the notable\nexception of geometry, which he addressed separately—can be\nreduced to logic (for Hempel, including set theory) as its foundation\n(Hempel 1945c). Mathematics thus becomes an exemplar of analytic a\npriori knowledge. Two subtheses should be distinguished: (i) that\nall mathematical concepts can be defined by means of basic\nlogical concepts; and (ii) that all mathematical theorems can\nbe deduced from basic logical truths. In order to distinguish logicism\nfrom formalism, however, the former maintains that there is one\nsystem of logic that is fundamental to all inquiries, where all\nmathematical terms are reducible to logical terms, and all\nmathematical axioms are derivable from logical ones, which formalism\ndenies (Rech 2004). \nThe tenability of logicism has been disputed on multiple grounds, the\nmost prominent of which is that the notion of membership\nfundamental to the theory of sets is not a logical notion but rather a\nsymbol that must be added to first-order logic to formalize what is\nproperly understood as a non-logical theory. Nor would\nphilosophers today accept the conception of the axioms of set theory\nas logical axioms, since there exist alternatives. So even if\nmathematics were reducible to set theory, these considerations\nundermine Hempel’s claim that mathematics is thereby reducible\nto logic (cf. Benacerraf 1981 and Linsky & Zalta 2006, which\nprovides an extensive bibliography). Hempel’s views about\ngeometry, in retrospect, thus appear to have been the better\nfounded. \nThe analytic/synthetic distinction and the observational/theoretical\ndistinction were tied together by the verifiability criterion of\nmeaningfulness, according to which, in relation to a given\nlanguage, \\(\\mathbf{L}\\), a sentence \\(S\\) is meaningful if and only\nif it is either analytic-in-\\(\\mathbf{L}\\) or\nsynthetic-in-\\(\\mathbf{L}\\) as an observation sentence or a sentence\nwhose truth follows from a finite set of observation sentences. By\nthis standard, sentences that are non-analytic but also\nnon-verifiable, including various theological or metaphysical\nassertions concerning God or The Absolute, qualify as cognitively\nmeaningless. This was viewed as a desirable result. But, as Hempel\nwould demonstrate, its scope was far too sweeping, since it also\nrendered meaningless the distinctively scientific assertions made by\nlaws and theories. \nFrom an historical perspective, logical positivism represents a\nlinguistic version of the empiricist epistemology of David Hume\n(1711–76). It refines his crucial distinctions of\n“relations between ideas” and “matters of\nfact” by redefining them relative to a language \\(\\mathbf{L}\\)\nas sentences that are analytic-in-\\(\\mathbf{L}\\) and\nsynthetic-in-\\(\\mathbf{L}\\), respectively. His condition that\nsignificant ideas are those which can be traced back to impressions in\nexperience that gave rise to them now became the claim that synthetic\nsentences have to be justified by derivability from finite classes of\nobservation sentences. Hume applied this criterion to exclude the idea\nof necessary connections, which are not observable, from\nsignificant causal claims, which were thereby reduced to relations of\nregular association, spatial contiguity, and temporal succession. And\nlogical positivism followed Hume’s lead.  \nEmpiricism historically stands in opposition to Rationalism, which is\nrepresented most prominently by Immanuel Kant, who argued that the\nmind, in processing experiences, imposes certain properties on\nwhatever we experience, including what he called Forms of Intuition\nand Categories of Understanding. The Forms of Intuition impose\nEuclidean spatial relations and Newtonian temporal relations; the\nCategories of Understanding require objects to be interpreted as\nsubstances and causes as inherently deterministic. Several\ndevelopments in the history of science, such as the emergence of the\ntheory of relativity and of quantum mechanics, undermine Kant’s\nposition by introducing the role of frames of reference and of\nprobabilistic causation. Newer versions are associated with Noam\nChomsky and with Jerry Fodor, who have championed the ideas of an\ninnate syntax and innate semantics, respectively (Chomsky 1957; Fodor\n1975; Chomsky\n1986) \nIndeed, according to the computational theory of the mind, human\nminds, like computing machines, are special kinds of formal systems.\nSince deviations from formal systems of language in practice can be\nconsiderable, Chomsky introduced a distinction between\ncompetence and performance, where the former models\nthe formal system and various explanations are advanced for deviations\nfrom that model in practice, similar to differences between the fall\nof bodies in a vacuum and in air, which raises questions about\ntestability that parallel those for scientific theories, in general.\nIf languages are not best understood as formal systems, however, or if\nsyntax and semantics are not innate, then Chomsky and Fodor’s\nviews are as vulnerable as those of Kant. If syntax is an emergent\nproperty of semantic complexity, for example, then grammar is not\ninnate; and if mentality has and continues to evolve, Chomsky and\nFodor are wrong (Schoenemann 1999; Fetzer 2005). \nIn his study of formal systems for geometry (Hempel 1945b), Hempel\ndiscusses the existence of alternatives based upon different axioms,\nwhich differentiate Euclidean geometry from its non-Euclidean rivals.\nAccording to Euclid, for example, the sum of the interior angles of a\ntriangle must equal 180° and, in relation to a point separate from\na given line, one and only one parallel line passes through it. The\nalternatives advanced by Lobachevsky (hyperbolic) and by Riemann\n(elliptical), however, which represent the surface of a sphere and of\na saddle, respectively, violate both of those conditions, albeit in\ndifferent ways. Hempel emphasized that all three, as formal systems,\nare on a par, where the most appropriate choice to describe the\ngeometry of space depends on the outcome of empirical studies. As it\nhappened, Einstein would adopt a generalized form of Riemannian\ngeometry in his general theory of relativity. \nHempel accordingly drew a distinction of fundamental importance\nbetween pure and applied mathematics, which he\nemphasized by using a quotation from Einstein, who had observed,\n“As far as the laws of mathematics refer to reality, they are\nnot certain; and as far as they are certain, they do not refer to\nreality” (1921). The existence of alternative and incompatible\nformal systems, moreover, appears to affect Hempel’s defense of\nlogicism from another direction. If mathematics is supposed to be\nreducible to logic and logic is supposed to be consistent, then how\ncan alternative geometries be consistently reducible to logic? No one\nwould dispute that they exist as distinct formal systems with their\nown axioms and primitives, but if these geometries are jointly\nreducible to logic only if logic is inconsistent, their existence\nsuggests that, perhaps, as formalism claims, it is not the case there\nis one system of logic that is fundamental to all inquiries. \nThe analytic/synthetic distinction took a decided hit when the noted\nlogician, Willard van Orman Quine, published “Two Dogmas of\nEmpiricism” (1953), challenging its adequacy. Quine argued that\nthe notion of analyticity presupposes the notion of synonymy-in-use,\nwhich in turn presupposes understanding\ninter-substitutability-while-preserving-truth. He claimed none of the\nnotions can be understood without the other, creating a circular\nrelation between them. Thus, matching up a definiens with a\ndefiniendum could only be done if we already understood that\nthe definiens specifies the meaning of the word that is being\ndefined—a variation of “the paradox of analysis”,\naccording to which we either already know the meaning of words (in\nwhich case analysis is unnecessary) or we do not (in which case it is\nimpossible). The idea of analyticity appeared to have been\ndeposed. \nThe paper created a sensation and has been the most influential\nphilosophical article of the past 100 years. But Quine explicitly\nallowed for the existence of the class of logical truths (such as\n“No unmarried man is married”) as narrowly\nanalytic sentences and their relationship to broadly analytic\nsentences (such as “No bachelor is married”), when the\ndefinitional relationship between them has been suitably stipulated\n(as in “bachelor \\(=_{\\df}\\) unmarried, adult male” in a\nlanguage framework \\(\\mathbf{L})\\). In cases of this kind, he\nconceded, inter-substitutability, synonymy, and analyticity are\nrelated in an unproblematic way. It would have been odd for a logician\nto deny the existence of logical truths or the role of stipulations,\nwhich are basic to the construction of formal systems, which suggests\nthat he may not have actually defeated the idea of analyticity, after\nall (Fetzer 1993). \nIndeed, Carnap (1939) had explained that the process of constructing a\nvocabulary and a grammar for a language-in-use involves several\nstages, including observation of the use of language by members of the\ncommunity, formulating hypotheses regarding the meaning of its phrases\nand expressions, and drawing inferences about the underlying grammar.\nThese are pragmatic, semantic, and syntactical procedures,\nrespectively, and decisions have to be made in arriving at a theory\nabout the language as the outcome of empirical research. The\nconstruction of formal systems thus provides an illustration of the\nelements of artificial languages, where accounts of natural language\ncounterparts can be subject to further testing and refinement. The\nlinguistic practices of a specific community can thus be modeled and\nthereby overcome Quine’s professed objections. \nMoreover, in Fundamentals of Concept Formation in Empirical\nScience (1952), Hempel had endorsed explication as a\nmethod of definition analogous to theory construction by taking words\nand phrases that are somewhat vague and ambiguous and subjecting them\nto a process of clarification and disambiguation. Adequate\nexplications are required to satisfy criteria of syntactical\ndeterminacy, semantic relevance, and pragmatic benefit (by clarifying\nand illuminating the meaning of those words and phrases in specific\ncontexts). The word “probability” is vague and ambiguous,\nfor example, but various contexts of its usage can be distinguished\nand theories of evidential support, relative frequency, and causal\npropensity can be advanced. Hempel, following Carnap (1950), had\naccordingly advanced a methodology that dealt with the paradox of\nanalysis before “Two Dogmas”. \nAbout the same time, however, Hempel found reasons of his own for\ndoubting that the analytic/synthetic distinction was tenable, which\nsurfaced in his study of dispositional predicates, such as\n“malleable”, “soluble” and\n“magnetic”. They designate, not directly observable\nproperties, but (in the case of “magnetic”) tendencies on\nthe part of some kinds of things to display specific reactions (such\nas attracting small iron objects) under suitable conditions (such as\nthe presence of small iron objects in the vicinity). It is very\ntempting to define them using the material conditional,\n“___ \\(\\supset \\ldots\\)” by definitions like, \nwhich could then be formalized by means of the horseshoe and suitable\nabbreviations, \nwhere “\\(t^*\\)” is equal to or later than\n“\\(t\\)” and reflects that effects brought about by causes\nentail changes across time. Since the material “if ___ then\n…” is equivalent to “either not-___ or\n…”, however, the meaning of (D2) turns out to be\nlogically equivalent to, \nwhich means that anything not subject to the test, such as a brown\ncow, is magnetic. Hempel acknowledged that the use of the\nsubjunctive conditional, say, “___ \\(\\rightarrow\n\\ldots\\)”, formalizing what would be the case … if\nsomething ___ were the case, in this case, \n“if, at \\(t\\), as small iron object were close to \\(x\\), then it\nwould move toward \\(x\\) at \\(t^*\\)” (which assumes the\nsatisfaction of the test condition) would avoid the problem, because\nthese conditionals take for granted their antecedents are satisfied\n(that “Sxt” is true). But while acknowledging the\nimportance of subjunctive conditionals for an understanding of both\ncounterfactual conditionals and lawlike sentences, Hempel regarded\ntheir explication as not fully satisfactory and their use as “a\nprogram, rather than a solution” (Hempel 1952: 25). \nHe therefore adopted a method from Carnap to overcome this difficulty,\nwhere, instead of attributing the property in question to anything not\nsubject to the test, the predicate is partially defined by means of a\nreduction sentence, such as “if, at \\(t\\), a small iron\nobject is close to \\(x\\), then \\(x\\) is magnetic at \\(t\\) if and only\nif it moves toward \\(x\\) at \\(t\\)” or symbolically, \nwhere a biconditional, “___ \\(\\equiv \\ldots\\)”, is true\nwhen “___” and “…” have the same truth\nvalue and otherwise is false. This solved one problem by abandoning\nthe goal of defining the predicate for a partial specification of\nmeaning. But it created another, insofar as, if there should be more\nthan one test/response for a property—such as that, “if\n\\(x\\) moves through a closed wire loop at \\(t\\), then \\(x\\) is\nmagnetic at \\(t\\) if and only if an electric current flows in the loop\nat \\(t^*\\)”—in conjunction they jointly imply that any\nobject \\(x\\) that is near small iron objects and moves through a\nclosed wire loop will generate a current in the loop if and only if it\nattracts those iron objects. But this no longer has the character of\neven a partial definition but instead that of an empirical law. The\nprospect that analytic sentences might have synthetic consequences was\nnot a welcome result (Hempel 1952). \nCarnap (1963) was receptive to the adoption of an intensional\nmethodology that went beyond the constraints of extensional logic,\nwhich Hempel (1965b) would consider but leave for others to pursue\n(Fetzer 1981, 1993). The distinction can be elaborated with respect to\nthe difference between the actual world and alternative possible\nworlds as sequences of events that diverge from those that define the\nhistory of the actual world. If specific conditions that obtained at a\nspecific time had been different, for example, the course of ensuing\nevents would have changed. These intensional methods can be applied to\nthe problems of defining dispositions and the nature of laws by\nemploying descriptions of possible worlds as variations on the actual,\nnot as alternatives that are “as real as” the\nactual—as David Lewis (2001a,b) has proposed—but as a\nmeans for formally specifying the semantic content of subjunctives and\ncounterfactuals (where counterfactuals are subjunctives with false\nantecedents), using an alternative calculus. \nThere appear to be two broad kinds of justification for subjunctive\nconditionals, which are logical and ontological, where logical\njustifications are derived from the grammar and vocabulary of a\nspecific language, such as English. The subjunctive, “If John\nwere a bachelor, then John would be unmarried”, for example,\nfollows from the definition of “bachelor” as\n“unmarried, adult male”. Analogously, the subjunctive,\n“If this were gold, then it would be malleable”, could be\njustified on ontological grounds if being malleable were (let us call\nit) a permanent attribute of being gold as a reference\nproperty, where attributes are “permanent” when there is\nno process or procedure, natural or contrived, by means of which\nthings having those reference properties could lose those attributes\nexcept by no longer possessing those reference properties, even though\nthat is not a logical consequence of their respective definitions\n(Fetzer 1977). The approach appeals to necessary connections, which\nare unobservable and therefore unacceptable to Hume. As we shall\ndiscover, that they are unobservable doesn’t mean they are\nempirically untestable. \nThe elaboration of a possible-worlds formal semantics that might be\nsuitable for this purpose, however, requires differentiating between\nfamiliar minimal-change semantics, where the world remains\nthe same except for specified changes, and a maximal-change\nsemantics, in which everything can change except for specified\nproperties, which is the ingredient that seems to be required to\nsatisfy the constraints of scientific inquiries as opposed to\nconversational discourse (Fetzer & Nute 1979, 1980). In the 1950s\nand 60s, however, Nelson Goodman (1955) and Karl Popper (1965) were\nattempting to sort out the linkage between dispositions, subjunctives,\nand laws from distinctive points of view. Hempel’s commitments\nto extensional logic and to Humean constraints would lead him to\nendorse an account of laws that was strongly influenced by Goodman and\nto embrace a pragmatic account that was both epistemically and\ncontextually-dependent. \nWhile the analytic/synthetic distinction appears to be justifiable in\nmodeling important properties of languages, the\nobservational/theoretical distinction does not fare equally well.\nWithin logical positivism, observation language was assumed\nto consist of names and predicates whose applicability or not can be\nascertained, under suitable conditions, by means of direct observation\n(such as using names and predicates for colors, shapes, sounds) or\nrelatively simple measurement (names and predicates for heights,\nweights, and sizes, for example). This was an epistemic position, of\ncourse, since it was sorting them out based upon their accessibility\nby means of experience. Both theoretical and dispositional predicates,\nwhich refer to non-observables, posed serious problems for the\npositivist position, since the verifiability criterion implies they\nmust be reducible to observables or are empirically meaningless. Karl\nPopper (1965, 1968), however, would carry the argument in a different\ndirection by looking at the ontic nature of properties. \nPopper has emphasized that we are theorizing all the time. Consider\nthe observation of a glass full of clear liquid. Suppose it’s\nwater. Then it quenches thirst and extinguishes fires and nourishes\nplants. But what if it’s alcohol instead? Just describing it as\n“water” entails innumerable subjunctives about the kinds\nof responses it would display under a wide variety of test conditions.\nThey are the would be’s of things of that kind.\nConsider the differences between basket balls, billiard balls, and\ntennis balls. Things of different kinds can do different things. Even\nthe seemingly simplest observation of a rabbit in the backyard, for\nexample, implies that it is going to display rabbit-like behavior,\nincluding eating carrots when my wife puts them out. It is going to\nhop around and create more rabbits. If it’s a rabbit, it is\ngoing to have rabbit DNA. It will not turn out to be stuffed. And this\nsuggested that observational properties and predicates are\ndispositional, too. \nFrom the Humean epistemic perspective, observational, dispositional,\nand theoretical predicates are successively more and more\nproblematical in relation to their accessibility via experience. The\nobservational describe observable properties of observable\nentities; the dispositional, unobservable properties of\nobservable entities; and the theoretical, unobservable\nproperties of unobservable entities. Popper suggested that\nobservational and theoretical properties (gravitational strengths\nelectromagnet fields, and such) are ontologically dispositional, too\n(Popper 1965: 425). But if universals as properties that can\nbe attributed to any member of any possible world are dispositions and\nthe kind of property dispositions are does not depend upon the ease\nwith which their presence or absence can be ascertained, then\nnomological subjunctives and counterfactuals—taken as\ninstantiations of lawlike generalizations for specific\nindividuals, places, and times—might be explicable as displays\nof dispositions and of natural necessities (Fetzer 1981). \nHempel (1950, 1951), meanwhile, demonstrated that the verifiability\ncriterion could not be sustained. Since it restricts empirical\nknowledge to observation sentences and their deductive consequences,\nscientific theories are reduced to logical constructions from\nobservables. In a series of studies about cognitive significance and\nempirical testability, he demonstrated that the verifiability\ncriterion implies that existential generalizations are meaningful, but\nthat universal generalizations are not, even though they include\ngeneral laws, the principal objects of scientific discovery.\nHypotheses about relative frequencies in finite sequences are\nmeaningful, but hypotheses concerning limits in infinite sequences are\nnot. The verifiability criterion thus imposed a standard that was too\nstrong to accommodate the characteristic claims of science and was not\njustifiable. \nIndeed, on the assumption that a sentence \\(S\\) is meaningful if and\nonly if its negation is meaningful, Hempel demonstrated that the\ncriterion produced consequences that were counterintuitive if not\nlogically inconsistent. The sentence, “At least one stork is\nred-legged”, for example, is meaningful because it can be\nverified by observing one red-legged stork; yet its negation,\n“It is not the case that even one stork is red-legged”,\ncannot be shown to be true by observing any finite number of\nred-legged storks and is therefore not meaningful. Assertions about\nGod or The Absolute were meaningless by this criterion, since they are\nnot observation statements or deducible from them. They concern\nentities that are non-observable. That was a desirable result. But by\nthe same standard, claims that were made by scientific laws and\ntheories were also meaningless. \nIndeed, scientific theories affirming the existence of gravitational\nattractions and of electromagnetic fields were thus rendered\ncomparable to beliefs about transcendent entities such as an\nomnipotent, omniscient, and omni-benevolent God, for example, because\nno finite sets of observation sentences are sufficient to deduce the\nexistence of entities of those kinds. These considerations suggested\nthat the logical relationship between scientific theories and\nempirical evidence cannot be exhausted by means of observation\nsentences and their deductive consequences alone, but needs\nto include observation sentences and their inductive\nconsequences as well (Hempel 1958). More attention would now be\ndevoted to the notions of testability and of confirmation and\ndisconfirmation as forms of partial verification and partial\nfalsification, where Hempel would recommend an alternative to the\nstandard conception of scientific theories to overcome otherwise\nintractable problems with the observational/theoretical\ndistinction. \nThe need to dismantle the verifiability criterion of meaningfulness\ntogether with the demise of the observational/theoretical distinction\nmeant that logical positivism no longer represented a rationally\ndefensible position. At least two of its defining tenets had been\nshown to be without merit. Since most philosophers believed that Quine\nhad shown the analytic/synthetic distinction was also untenable,\nmoreover, many concluded that the enterprise had been a total failure.\nAmong the important benefits of Hempel’s critique, however, was\nthe production of more general and flexible criteria of cognitive\nsignificance in Hempel (1965b), included in a famous collection of his\nstudies, Aspects of Scientific Explanation (1965d). There he\nproposed that cognitive significance could not be adequately captured\nby means of principles of verification or falsification, whose defects\nwere parallel, but instead required a far more subtle and nuanced\napproach. \nHempel suggested multiple criteria for assessing the cognitive\nsignificance of different theoretical systems, where significance is\nnot categorical but rather a matter of degree: \nThe criteria Hempel offered for evaluating the “degrees of\nsignificance” of theoretical systems (as conjunctions of\nhypotheses, definitions, and auxiliary claims) were (a) the clarity\nand precision with which they are formulated, including explicit\nconnections to observational language; (b) the\nsystematic—explanatory and predictive—power of such a\nsystem, in relation to observable phenomena; (c) the formal simplicity\nof the systems with which a certain degree of systematic power is\nattained; and (d) the extent to which those systems have been\nconfirmed by experimental evidence (Hempel 1965b). The elegance of\nHempel’s study laid to rest any lingering aspirations for simple\ncriteria of cognitive significance and signaled the demise of logical\npositivism as a philosophical movement. \nPrecisely what remained, however, was in doubt. Presumably, anyone who\nrejected one or more of the three principles defining\npositivism—the analytic/synthetic distinction, the\nobservational/theoretical distinction, and the verifiability criterion\nof significance—was not a logical positivist. The precise\noutlines of its philosophical successor, which would be known as\n“logical empiricism”, were not entirely evident. Perhaps\nthis study came the closest to defining its intellectual core. Those\nwho accepted Hempel’s four criteria and viewed cognitive\nsignificance as a matter of degree were members, at least in spirit.\nBut some new problems were beginning to surface with respect to\nHempel’s covering-law explication of explanation and old\nproblems remained from his studies of induction, the most remarkable\nof which was known as “the paradox of confirmation”. \nHempel’s most controversial argument appeared in an article\nabout induction entitled “Studies in the Logic of\nConfirmation” (1945a), where he evaluates the conditions under\nwhich an empirical generalization would be confirmed or disconfirmed\nby instances or non-instances of its antecedent and consequent. He\nfocused on universally quantified material conditionals, exemplified\nby sentences of the form, “\\((x)(Rx \\supset Bx)\\)”. With\n“\\(Rx\\)” interpreted as “\\(x\\) is a raven” and\n“\\(Bx\\)” as “\\(x\\) is black”, this schema\nrepresents, in first-order symbolic logic, the claim, “All\nravens are black”. He also considered sentences of more complex\nlogical structures, but nothing hinges upon their use that cannot be\naddressed relative to an example of the simplest possible kind. And,\nindeed, Hempel took sentences of this kind as exemplars of\n“lawlike sentences”, which combine purely universal\nform with what he called purely qualitative predicates.\nSo lawlike sentences that are true as extensional generalizations are\n“laws” (Hempel & Oppenheim 1948). \nHempel applied “Nicod’s criterion” to this example,\nwhere Nicod had proposed that, in relation to conditional hypotheses,\ninstances of their antecedents that are also instances of their\nconsequents confirm them; instances of their antecedents that are not\ninstances of their consequents disconfirm them; and non-instantiations\nof their antecedents are neutral, neither confirming nor\ndisconfirming. Applied to the raven hypothesis, this means that, given\na thing named “\\(c\\)”, the truth of “\\(Rc\\)”\nand “\\(Bc\\)” confirms it; the truth of\n“\\(Rc\\)” and “\\(\\neg Bc\\)” disconfirms it; and\nthe truth of “\\(\\neg Rc\\)” neither confirms nor\ndisconfirms it, but remains evidentially neutral, regardless of the\ntruth value of “\\(Bc\\)”. To these highly intuitive\nconditions, Hempel added that, since logically equivalent hypotheses\nhave the same empirical content, whatever confirms one member of a set\nof logically equivalent hypotheses must also confirm the others, which\nhe called “the equivalence condition”. \nNo matter how intuitive, Hempel proceeded to demonstrate that this\ncreates a paradox. By Nicod’s criterion, “\\((x)(Rx \\supset\nBx)\\)” is confirmed by ravens that are black. But, by that same\nstandard, “\\((x)(\\neg Bx \\supset \\neg Rx)\\)” is confirmed\nby non-black non-ravens, such as white shoes! Since these are\nlogically equivalent and have the same empirical content, they must be\nconfirmed or disconfirmed by all and only the same instances. This\nmeans that—no matter how counter-intuitive—the lawlike\nhypothesis, “All ravens are black”, is confirmed by\nobservations of white shoes! Since these hypotheses are also\nequivalent to “\\((x)(\\neg Rx \\vee Bx)\\)”, which asserts\nthat everything either is not a raven or is black, it is also the case\nthat observations of non-ravens confirms the hypothesis, regardless of\ntheir color. Observations of non-ravens, however, unlike those of\nblack ravens, confirm alternative hypotheses, like “All ravens\nare blue” and “All ravens are green”. Hempel’s\npoint was that the application of Nicod’s criterion means that,\nsince even observations of non-ravens are confirmatory, the class of\nneutral instances in fact has no members. \nFew papers in the philosophy of science have produced such a\nvoluminous literature. In a “Postscript”, Hempel addressed\na few of the suggestions that have been advanced to analyze the\nparadoxical quality of the argument (Hempel 1965a). Several were\nintent upon explaining them quantitatively on the ground that, for\nexample, there are many more non-black things than black things or\nthat the probability of being non-black is much great than the\nprobability of being a raven, whereas others appealed to Bayesian\nprinciples and suggested that the prior probability for ravens being\nblack makes testing non-ravens of considerably less relative risk.\nHempel replied that even the existence of a quantitative measure of\nevidential support poses no challenge to his conclusion that the\nparadoxical cases—non-black non-ravens, such as white\nshoes—are confirmatory. \nHempel acknowledges that an explanation for why the paradoxical cases\nappear to be non-confirmatory may have something to do with fashioning\nhypotheses about classes that are affected by their relative size.\nSince the class of non-ravens is so much larger than the class of\nravens, where what we are interested in, by hypothesis, is the color\nof ravens, instances of non-black non-ravens might count as\nconfirmatory but to a lesser degree than instances of black ravens. He\nallows the possibility that perhaps the theory of confirmation should\nproceed quantitatively, which might provide a less perplexing basis\nfor assessments of this kind. But he steadfastly maintains that the\nconsequences he identified following from the application of the\nprinciples he employed are logically impeccable, no matter how\npsychologically surprising they may seem (Hempel 1960). \nThe most important claim of Hempel (1965a) is that confirmation cannot\nbe adequately defined by linguistic means alone. Here he cites Goodman\n(1955) to demonstrate that some hypotheses of the form,\n“\\((x)(Fx \\supset Gx)\\)”, are not confirmable even by\ninstances of the kind “\\(Fc\\)” and “\\(Gc\\)”.\nIf “\\(Rx\\)” stands for “\\(x\\) is a raven” and\n“\\(Bx\\)” for “\\(x\\) is blite” (where \\(x\\) is\nblite when it has been examined before time \\(t\\) and is black or has\nnot been examined before \\(t\\) and is white), then any raven observed\nbefore \\(t\\) and found to be black confirms the hypothesis,\n“\\((x)(Rx \\supset Bx)\\)”; yet this hypothesis implies that\nall ravens not examined before \\(t\\) are white, a consequence that, in\nHempel’s language, “must surely count as disconfirmed\nrather than as confirmed”. And he endorses Goodman’s\nsuggestion that whether a universal conditional is capable of being\nconfirmed by its positive instances turns out to depend upon the\ncharacter of its constituent predicates and their past use. \nGoodman (1955) draws a distinction between universal conditional\ngeneralizations that can be confirmed by their instances and those\nthat cannot, where the former are said to be\n“projectible”. Those that can be projected from examined\ncases to unexamined ones are those that have a history of past\nprojections. Thus, the predicate “black” has many past\nprojections, but the predicate “blite” does not. Since a\nhistory of past projections enhances the projectibility of predicates\nonly when they are successful, the measure of a predicate’s\ndegree of projectibility, which Goodman calls its degree of\nentrenchment, is the relative frequency of its successful use in\npast predictions. Hume observed that, no matter how consistently a\nregularity has held in the past, that provides no guarantee it will\ncontinue to hold in the future. Goodman nevertheless adopted the past\nas a guide, which qualifies as his solution to the linguistic version\nof Hume’s problem of induction. \nSince Goodman is offering a pragmatic solution for (what most would\nassume to be) a syntactical and semantical problem, it may be useful\nto consider whether or not there might be a more promising approach.\nIn embracing Goodman’s approach, Hempel was modifying his\nconception of lawlike sentences as extensional\ngeneralizations which are restricted to purely qualitative predicates\nwhich make no mention of specific individuals, specific places or\nspecific times, but which might, in special cases, reference samples\nor exemplars, such as the standard meter or the atomic clock (Hempel\n1965d: 269, where he also mentions Popper’s notion of universal\npredicates). Goodman’s account does not actually capture the\nconcept of laws but the rather restricted notion of hypotheses that\nhave been projected and are supposed to be laws. Laws themselves,\nafter all, exist even when they have not yet been discovered, as in\nthe case of Archimedes’ principle before Archimedes,\nSnell’s law before Snell, and Newton’s before Newton. A\nmore promising approach lay in the direction of universals in\nPopper’s sense, which are dispositions with subjunctive force,\nwhere laws can be characterized as unrestricted intensional\nconditionals. \nPopper (1965, 1968) championed falsifiability as a criterion of\ndemarcation that is more appropriate than verifiability as a criterion\nof meaningfulness, on the ground that what we need is a basis for\ndistinguishing scientific from nonscientific statements, where the\nlatter can still be meaningful, even when they are not scientific. He\nsuggested that laws should be understood as having the force of\nprohibitions, which are empirically testable by attempts to\nfalsify them. And he observed there are no “paradoxes of\nfalsification” to parallel the “paradoxes of\nconfirmation”. Even in the case of material conditionals, the\nonly falsifying instances are those that combine the truth of their\nantecedents with the falsity of their consequents. Relative to\n“\\((x)(Rx \\supset Bx)\\)”, for example, the only potential\nfalsifiers are instances of “\\(Rx\\)” that are instances of\n“\\(\\neg Bx\\)”, and similarly for “\\((x)(\\neg Bx\n\\supset \\neg Rx)\\)” and for “\\((x)(\\neg Rx \\vee\nBx)\\)”, not to mention its subjunctive counterpart,\n“\\((x)(Rx \\rightarrow Bx)\\)”. The absence of paradox\nsuggested that Popper’s approach to problems of demarcation and\nof cognitive significance might possess substantial advantages over\nthe alternatives. \nHempel’s most important contributions to the theory of science\nhave been a series of explications of the structure of scientific\nexplanations. His methodology was such that, following the preliminary\nexamination of the linguistic and physical phenomena under\nconsideration, he would advance a semi-formal characterization, one\nwhich he would subsequently subject to formal characterization using\nthe resources of symbolic logic. The overarching theme of his work was\nthe conception of explanation by subsumption, where specific events\nare subsumed by corresponding laws (of physics, of chemistry, of\nbiology, and so forth). The conception of explanation by subsumption\nis rather ancient in its lineage, but Hempel advanced explicit\nformulations that drew distinctions between explanations of different\nkinds, especially those that invoke universal (or deterministic) laws,\nstatistical (or probabilistic) laws, and the explanation of laws by\nmeans of theories. \nHempel implemented the conception of subsumption by presuming that\nexplanations explain the occurrence of singular events by deriving\ntheir descriptions from premises that include at least one lawlike\nsentence, which thereby displays (what he called) their nomic\nexpectability. In the simplest cases, explanations assume the\nfollowing form: \nFigure 2. An Explanation Schema \nThus, in relation to Figure 2, \\(C_1\\), \\(C_2\\),…, \\(C_r\\)\ndescribe specific conditions (referred to as “initial” or\n“antecedent”) and \\(L_1\\), \\(L_2\\),…, \\(L_k\\)\ngeneral laws, where “\\(E\\)” describes the event to be\nexplained. The explanation takes the form of an inductive or deductive\nargument, where the premises are called the “explanans”\nand the conclusion the “explanandum”. \nRichard Jeffrey (1969) noted that Hempel’s conception harmonizes\nwell with Aristotle’s definition of (what he called)\nunqualified scientific knowledge,  \n[where] the premisses of demonstrated knowledge must be true, primary,\nimmediate, better known than and prior to the conclusion, which is\nfurther related to them as effect to cause. (Posterior\nAnalytics 1.71–2, as quoted in Jeffrey 1969: 104)  \nA potentially even more illuminating comparison emerges from the\nperspective of Aristotle’s theory of the four causes, where the\nlaws are the material cause, the antecedent conditions the efficient\ncause, the logical relation between the explanans and the explanandum\nthe formal cause and the explanandum the final cause (Fetzer 2000a:\n113–114). There were important differences in their conceptions\nof law. Aristotle’s general premises were definitional,\nnecessarily, whereas Hempel’s were not. \nFor Aristotle, the general premises of scientific explanations are\ngeneralizations that describe commensurately universal\nproperties of things of a subject kind, \\(K\\). Merely universal\nproperties are ones that everything of kind \\(K\\) has but could be\nwithout and remain a thing of that kind, just as every Honda might\nhave Michelin tires. Aristotle referred to such properties as\n“accidental”. Commensurately universal properties are ones\nthat belong to everything of the kind as necessary attributes that\nthey cannot be without. A triangle, for example, has three lines and\nangles. Aristotle referred to them as “essential”. Because\ngeneralizations about the essential properties of things of a kind are\n“proper definitions”, they provide the basis for\nexplanations that qualify as analytic. Hempel encompassed analytic\ngeneralizations within the scope of “fundamental laws” as\ndefined in Hempel and Oppenheim (1948), but he focused on those that\nwere synthetic. \nAnalytic explanations are common in the currents of daily life,\nespecially in the context of explaining how you “know\nthat” something is the case. A mother might explain to her\nsingle daughter that she knows that John must be unmarried, because a\nfriend told her that John is a bachelor. Similar cases of analytic\nexplanations can occur in scientific contexts, such as knowing that\nthe element they are dealing with is gold because it has atomic number\n79, when gold is defined by its atomic number. Knowing why John is a\nbachelor, however, is another matter. Indeed, in Hempel (1965c), he\nwould distinguish between reason-seeking why-questions and\nexplanation-seeking why-questions, where the former seek\nreasons that justify believing that something is the case, as opposed\nto the latter, which are usually motivated by knowledge that a\nspecific event has occurred. \nIn his semi-formal explication of the requirements for adequate\nscientific explanations, Hempel specified four conditions of adequacy\n(CA) that have to be satisfied, namely: \nThese conditions are intended to serve as requirements whose\nsatisfaction guarantees that a proposed explanation is adequate.\nHempel drew several distinctions over time between potential\nscientific explanations (which satisfy the first three conditions, but\npossibly not the fourth) and confirmed scientific\nexplanations (which are believed to be true but might turn out to be\nfalse). Hempel recognized that (CA-3) was a redundant condition, since\nit would have to be satisfied by any explanation that satisfied (CA-1)\nand (CA-2). Insofar as the explanandum describes an event that\noccurred during the history of the world, its derivation thereby\nimplies the explanans has empirical content. \nHempel’s conditions had many virtues, not least of which was\nthat they appeared to fit many familiar examples of scientific\nexplanations, such as explaining why a coin expanded when it was\nheated by invoking the law that copper expands when heated and noting\nthat the coin was copper. Hempel doesn’t specify the form laws\nmay take, which could be simple or complex. Most of his examples were\nsimple, such as “All ravens are black”, “All gold is\nmalleable”, and so on. Others were quantitative, such as\nArchimedes’ principle (A body totally immersed in a\nfluid—a liquid or a gas—experiences an apparent loss in\nweight equal to the weight of the fluid it displaces), Snell’s\nlaw (During refraction of light, the ratio of the sines of the angles\nof incidence and of refraction is a constant equal to the refractive\nindex of the medium), and Newton’s law of gravitation (Any two\nbodies attract each other with a force proportional to the product of\ntheir masses and inversely proportional to the square of the distance\nbetween them), which he discussed. \nMore complicated examples can be found in standard sources, such as\nThe Feynman Lectures on Physics (Feynman et al.\n1963–65), the first volume of which is devoted to mechanics,\nradiation, and heat; the second, to electromagnetism and matter; and\nthe third, to quantum mechanics. Hempel explored the implications of\n(CA-4) for laws: \nThe requirement of truth for laws has the consequence that a given\nempirical statement \\(S\\) can never be definitely known to be\na law; for the sentence affirming the truth of \\(S\\) is tantamount to\n\\(S\\) and is therefore capable only of acquiring a more or less high\nprobability, or degree of confirmation, relative to the experimental\nevidence available at any given time (Hempel and Oppenheim 1948: note 22, italics added). \nHempel considered weakening condition (CA-4) to one of high\nconfirmation instead of truth, but concluded that it would be awkward\nto have “adequate explanations” that are later superseded\nby different “adequate explanations” with the\nacquisition of additional evidence and alternative hypotheses across\ntime. He therefore retained the condition of truth. Whether or not the\nconditions of explanatory adequacy should be relative to an epistemic\ncontext of confirmation rather than to an ontic context of truth would\nbecome an important question in coping with the requirements for\nprobabilistic explanations. \nNo aspect of Hempel’s position generated more controversy than\nthe symmetry thesis, which holds that, for any adequate\nexplanation, had its premises—its initial conditions and\ncovering laws—been taken into account at a suitable prior time,\nthen a deductive prediction of the occurrence of the explanandum event\nwould have been possible, and conversely (Hempel & Oppenheim\n1948). Inferences from adequate explanations to potential predictions\nwere generally accepted, but not the converse. Critics, such as\nMichael Scriven (1962), advanced counter-examples that were based on\ncorrelations or “common causes”: the occurrence of a storm\nmight be predicted when cows lie down in their fields, for example,\nyet their behavior does not explain why the storm occurs. Sylvain\nBromberger offered the example of the length of the shadow cast by a\nflagpole, which is sufficient to deduce the height of the flagpole and\nthus satisfies Hempel’s conditions but does not explain why the\nflagpole has that height (Bromberger 1966). Since logical relations\nare non-temporal, Hempel may have taken the symmetry thesis to be a\ntrivial consequence of his account, but deeper issues are involved\nhere. \nHempel observed that universal generalizations of the form,\n“\\((x)(Fx \\supset\\) Gx)”, are true if and only if\nlogically equivalent generalizations of the form, “\\((x)(\\neg Fx\n\\vee Gx)\\)”, are true. But if “\\(Fx\\)” stands for\nan uninstantiated property, such as being a vampire, then,\nsince “\\(\\neg Fx\\)” is satisfied by everything, regardless\nof the attribute “\\(Gx\\)”, “\\(\\neg Gx\\)”,\netc., that hypothesis—and its logical equivalents—are not\nonly universally confirmed but even qualify as “laws”.\nThis is not surprising, from a logical point of view, since\nextensional logic is purely truth functional, where the truth value of\nmolecular sentences is a function of the truth values of its atomic\nconstituents. But it implies that an empirical generalization that\nmight be true of the world’s history may or may not be\n“lawful”, since it could be the case that its truth was\nmerely “accidental”. Hempel’s endorsement of\nGoodman’s approach to select generalizations that support\nsubjunctive conditionals, therefore, was not only consistent with the\ntradition of Hume—who believed that attributions of natural\nnecessity in causal relations are merely “habits of mind”,\npsychologically irresistible, perhaps, but logically\nunwarranted—but circumvented a disconcerting consequence of his\nexplication. \nThere is a fundamental difference between sentences that\n“support subjunctives” and those that “entail\nsubjunctives”, when the selection of those that support\nsubjunctives is made on pragmatic grounds. Popper captured the crucial\ndifference between material (extensional) generalizations and\nsubjunctive (intensional) generalizations as follows: \nA statement may be said to be naturally or physically\nnecessary if, and only if, it is deducible from a statement\nfunction which is satisfied in all worlds that differ from our own, if\nat all, only with respect to initial conditions. (Popper 1965:\n433) \nIndeed, the existence of irreducibly ontic probabilistic phenomena,\nwhere more than one outcome is possible under the same initial\nconditions, would mean that the history of an indeterministic world\nmight be identical with the history of a deterministic one, where\ntheir differences were concealed “by chance”. Even a\ncomplete description of the history of the actual world might not\nsuffice to distinguish between them, where fundamental aspects of\ntheir causal structure would remain beyond empirical detection. \nThe difference between Popper’s universal predicates and\nGoodman’s paradoxical ones may derive from the consideration\nthat incorporating specific times into his definitions entails\nreference to specific moments of time \\(t\\), such as midnight\ntonight, during the history of the actual world, a point to which\nwe are going to return. It follows that they cannot be\n“universal” in Popper’s sense and do not even\nqualify as “purely qualitative” in Hempel’s, either.\nReliance upon material conditionals within first-order symbolic logic,\nmoreover, forfeits the benefits of synthetic subjunctives. If the\nhypothesis, “All ravens are black”, is more adequately\nformalized as a subjunctive of the form, “\\((x)(Rx \\rightarrow\nBx)\\)”, where the truth of a subjunctive hypothetically assumes\nthat its antecedent condition is satisfied, that obviates the paradox:\nwhite shoes are not ravens, and Nicod’s criteria apply Instances\nof “\\(Rx\\)” and “\\(Bx\\)” thereby confirm the\nhypothesis; instances of “\\(Rx\\)” and “\\(\\neg\nBx\\)” disconfirm it; and instances of “\\(\\neg Rx\\)”\nare epistemically neutral, precisely as Nicod said. \nHempel’s critics—both early and late—have not always\nshown an appreciation for the full dimensions of his explication.\nMichael Scriven (1959), for example, once objected to “the\ndeductive model, with its syllogistic form, where no student of\nelementary logic could fail to complete the inference, given the\npremise” (1959: 462), when no restriction is placed on the complexity of\nthe relevant laws or the intricacy of these deductions (Hempel 1965c:\n339). Similar objections have been lodged more recently by William\nBechtel and Adele Abrahamsen (2005), for example, who claim, in\ndefense of “the mechanist alternative”, that, among its many benefits,  \ninvestigators are not limited to linguistic representations and\nlogical inference in presenting explanations but frequently employ\ndiagrams and reasoning about mechanisms by simulating them. (2005:\n421)  \nHempel’s conditions of adequacy, however, are capable of\nsatisfaction without their presentation as formal arguments. \nHempel remarks that his model of explanation does not directly apply\nto the wordless gesticulations of a Yugoslavian automobile mechanic or\nguarantee that explanations that are adequate are invariably\nsubjectively satisfying. His purpose was to formalize the conditions\nthat must be satisfied when an explanation is adequate without denying\nthat background knowledge and prior beliefs frequently make a\ndifference in ordinary conversational contexts. Jan might not know\nsome of the antecedent conditions, Jim might have misunderstood the\ngeneral laws, or features of the explanandum event may have been\nmissed by them both. Even when information is conveyed using diagrams\nand simulations, for example, as long as it satisfies conditions\n(CA-1) through (CA-4)—no matter whether those conditions are\nsatisfied implicitly or explicitly—an adequate scientific\nexplanation is at hand. But it has to satisfy all four of those\nrequirements. \nDemonstrating that an adequate scientific explanation is at hand,\nhowever, imposes demands beyond the acquisition of information about\ninitial conditions and laws. In the examiner’s sense of\nknowledge Ian Hacking identified (Hacking 1967: 319), to prove an\nadequate scientific explanation is available, it would be necessary to\nshow that each of Hempel’s adequacy conditions has been\nsatisfied. It would not be enough to show, say, that one person is\nknowledgeable about the initial conditions, another about the covering\nlaws, and a third about the explanandum. It would be necessary to show\nthat the explanandum can be derived from the explanans, that those\nlaws were required for the derivation, and that the initial conditions\nwere those present on that occasion. (CA-1)–(CA-4) qualifies as\na “check list” to insure that a scientific explanation is\nadequate. \nStudents of Hempel have found it very difficult to avoid the\nimpression that Hempel was not only defending the position that every\nadequate scientific explanation is potentially predictive but also the\nposition that every adequate scientific prediction is potentially\nexplanatory. This impression is powerfully reinforced in “The\nTheoretician’s Dilemma” (Hempel 1958), where, in the\ncourse of demonstrating that the function of theories goes beyond\nmerely establishing connections between observables, he offers this\npassage: \nScientific explanations, predictions, and postdictions all have the\nsame logical character: they show that the fact under consideration\ncan be inferred from certain other facts by means of specified general\nlaws. In the simplest case, the type of argument may be schematized as\na deductive inference of the following form [here substituting the\n“simplest case” for the abstract schemata presented in the\noriginal]: \nFigure 3. A Covering-Law Explanation \n… While explanation, prediction, and postdiction are alike in\ntheir logical structure, they differ in certain other respects. For\nexample, an argument [like Figure 3 above] will qualify as a\nprediction only if [its explanandum] refers to an occurrence at a time\nlater than that at which the argument is offered; in the case of\npostdiction, the event must occur before the presentation of the\nargument. These differences, however, require no further study here,\nfor the purpose of the preceding discussion was simply to point out\nthe role of general laws in scientific explanation, prediction, and\npostdiction (Hempel 1958: 37–38). \nWhat is crucial about this passage is Hempel’s emphasis on the\npragmatic consideration of the time at which the argument is\npresented in relation to the time of occurrence of the\nexplanandum event itself. Let us take this to be the observation\nthat \\(c\\) is black and assume that occurs at a specific time \\(t_1\\).\nIf the argument is presented prior to time \\(t_1\\) (before observing\nthat \\(c\\) is black), then it is a prediction. If the argument is\npresented after time \\(t_1\\) (after observing that \\(c\\) is black),\nthen it is a postdiction. Since explanations are usually advanced\nafter the time of the occurrence of the event to be explained, they\nusually occur as postdictions. But there is nothing about their form\nthat requires that. \nAs Hempel uses the term, reasoning is “scientific” when it\ninvolves inferences with laws. Indeed, this appears to be the\nprincipal ground upon which he wants to maintain that explanations,\npredictions, and postdictions share the same logical form. His\nposition here makes it logically impossible for explanations,\npredictions and postdictions to not have the same logical form. If\nthere are modes of prediction that are non-explanatory, such as might\nbe the case when they are based upon accidental generalizations, then\nthey would not thereby demonstrate that the symmetry thesis does not\nhold for the kinds of distinctively “scientific”\nexplanations that are the focus of his work. Scriven’s cow\nexample, for example, does not show that the symmetry thesis does not\nhold for scientific explanations and scientific\npredictions, even if it shows that some ordinary predictions\nare not also ordinary explanations. But other\ncounter-examples posed greater threats. \nIndeed, in the process of drawing the distinction between\nexplanation-seeking and reason-seeking why-questions, Hempel (1965c)\nproposed a different kind of symmetry thesis, where adequate answers\nto explanation-seeking why-questions also provide adequate answers to\nreason-seeking why-questions, but not conversely. That was very\nappropriate, since the purpose of reason-seeking why-questions is to\nestablish grounds for believing that the event described by the\nexplanandum sentence has taken (or will take) place, while\nexplanation-seeking why-questions typically take for granted that we\nknow their explanandum events have already occurred. It follows that,\nwhile Hempel’s conditions are meant to specify when we know\nwhy, they also entail how we know that. \nInsofar as Hempel focused on logically equivalent formulations of\nlawlike sentences in addressing the paradoxes of confirmation, some\nmay find it remarkable that he does not explore the consequences of\nlogically equivalent formulations in relation to explanations. We tend\nto assume we can explain why a specific thing \\(c\\) is black on the\ngrounds that it is a raven and all ravens are black. Yet we would\nhesitate to explain why a specific thing is not a raven on the ground\nthat it is not black. We may refer to this as the paradox of\ntransposition. Notice, the contention that one member of a class\nof logically equivalent hypotheses is explanatory but others are not\ngenerates “paradoxes of explanation” that parallel the\n“paradoxes of confirmation” (Fetzer 2000a). Figure 4\noffers an illustration: \nFigure 4. The Transposition Paradox \nEven if we accept the transposed form of “\\((x)(Rx \\supset\nBx)\\)” as the basis for an answer to a reason-seeking\nwhy-question—in this case, how we know that\n\\(c\\) is no raven—Figure 4 surely does not explain why that\nis the case, which presumably has to do with the genes of entity\n\\(c\\) and its developmental history as a living thing. If logically\nequivalent forms equally qualify as lawlike—there’s no\nbasis in extensional logic to deny it—then Hempel confronts a\ndilemma. In fact, by his own conditions of adequacy, this argument is\nnot only explanatory but also predictive. It is not a\n“postdiction” as he has defined it above, but it appears\nto qualify as a “retrodiction” that does not explain its\nexplanandum event. \nSuppose Hempel were to resort to Goodman’s approach and deny\nthat the negation of a purely qualitative predicates is also a purely\nqualitative predicate. That would mean that sentences logically\nequivalent to lawlike sentences—which have the same\ncontent—are not therefore also lawlike by invoking pragmatic\ndifferences in their degree of entrenchment and projectibility of\ntheir constituent predicates. An appeal to pragmatic considerations\nwithin this context has a decidedly ad hoc quality about it,\nwhich appears to contravene the spirit of the paradoxes of\nconfirmation, where Hempel insists that the counterintuitive cases are\nconfirmatory and their paradoxical character is merely psychological.\nEven if Hempel were to adopt this position and take for granted that\none member of a class of logically equivalent sentences can be lawlike\nwhile the others are not, another difficulty arises from the use of\nmodus tollens in lieu of modus ponens, as Figure 5\nexemplifies: \nFigure 5. The Modus Tollens Paradox \nHere we have a more threatening problem, since there is no apparent\nbasis for denying that an argument having this form satisfies\nHempel’s criteria and therefore ought to be both explanatory\nand predictive. Similarly for temporally quantified arguments,\nwhere the fact that a match of kind \\(K\\) has not lighted at \\(t^*\\)\nwould certainly not be adequate to explain why it was not struck\nat t, even though every match of kind \\(K\\) will light when it is\nstruck, under suitable conditions! Something serious thus appears to\nbe wrong (Fetzer 2000a). \nThe adoption of an alternative theory of laws that incorporates\nHempel’s commitment to universal generality and to purely\nqualitative predicates, but abandons Goodman’s pragmatic\nentanglements, might offer solutions for these problems. One such\naccount has been advanced by David Armstrong (1983), who embraces\nthree basic assumptions: (a) realism (the thesis that laws\nexist apart from any human minds); (b) actualism (the thesis\nthat laws and properties exist only if they are instantiated); and (c)\nnaturalism (the thesis that nothing exists except “the\nsingle, spatio-temporal, world, the world studied by physics,\nchemistry, cosmology, and so on”, 1983: 76). These theses harbor\nan equivocation, however, since, if there can be uninstantiated laws\nand properties, actualism is false and naturalism might also not be\ntrue—unless “the single, spatio-temporal, world”\nincludes uninstantiated as well as instantiated properties and laws\n(1983: 76). Since Armstrong endorses realism about universals\n(according to which properties are not reducible to their class of\ninstances), there appears to be a certain tension between his realism\nand his actualism. \nArmstrong abandons the Humean account of universal laws as constant\nconjunctions and of statistical laws as relative frequencies, which\nare both extensional in character, for the alternative conception of\nlaws as intensional relations between properties, which are connected\nby (what he characterizes as) primitive relations of\nnecessitation and of probabilification,\nrespectively. When a thing’s being \\(F\\) necessitates its being\n\\(G\\), which he formalizes as “\\(N(F, G)\\)”—where\nbeing gold may be said to necessitate being malleable, for\nexample—then everything that is \\(F\\) will also be \\(G\\), so\nthat a corresponding extensional generalization, “\\((x)(Fx\n\\supset Gx)\\)” must be true, but not conversely. This marks an\nadvance in dealing with accidental generalizations, since, even if\nevery Volkswagen were painted grey, it would not follow that being\ngrey is necessitated by being a Volkswagen, when, for example, there\nare processes and procedures, such as repainting them, that could be\nperformed to violate that generalization, which cannot occur with bona\nfide laws. \nHe argues that his notion of physical necessitation is not the same as\nthe counterpart notion of logical necessitation, where the former,\nunlike the latter, is non-symmetrical and cannot be transposed. The\nadoption of this approach, therefore, would resolve the paradox of\ntransposition, since “\\(N(F, G)\\)” is no longer logically\nequivalent to “\\(N(\\neg G, \\neg F)\\)”. Armstrong attempts\nto assimilate statistical to universal laws by their interpretation as\nnecessitations of less than (let us say) universal strength. On this\nview, the logical form of statistical laws turns out to be\n“\\(N:P(F, G)\\)” and that of universal laws “\\(N:1(F,\nG)\\)”, where the value of “\\(P\\)” equals any\n(possibly infinitesimal) number between 0 and 1. Armstrong appeals to\nthe non-existence of negative properties to support the\nnontranposability of necessitations, but there are hidden dangers\neither way: when “\\(N:1(F, G)\\)”, then “\\(N:0(F,\n\\neg G)\\)”, necessarily; when “\\(N:P(F, G)\\)”,\nnecessarily, “\\(N:1-P(F, \\neg G)\\)”. They seem\nunavoidable. Even more important than preserving the addition and\nsummation of probabilifications, the distinction between permanent and\ntransient properties introduced in Section 2.1 provides an ontological\nbasis for these differences, which Armstrong does not supply. \nThe presence of \\(G\\) is not part of the definition of\n“\\(F\\)”, which requires that “\\([ ](Fx \\supset\nGx)\\)” be false in \\(\\mathbf{L}\\), where “[ ]”\nstands for logical necessity; yet there is no process or procedure,\nnatural or contrived, by means of which a permanent property \\(G\\) can\nbe taken away from something that is \\(F\\) except by making it no\nlonger \\(F\\). The properties that things can have or lose and remain\nthings of that kind are transient (Fetzer 1981, 1993). Being\nyellow, malleable, and a metal are some permanent properties of gold,\nwhile having a particular shape, being owned by a specific person, or\nhaving a certain selling price are not. Lawlike sentences are then\nlogically contingent, subjunctive conditionals that reflect\npermanent property relations. The adoption of a more adequate\ntheory of laws, moreover, would be consistent with Hempel’s\nconditions of adequacy and support his schemata, as Figure 6\ndisplays: \nFigure 6. A D-N Explanation Schema \nThus, when \\(G\\) is a permanent property of \\(F\\), it does not mean\nthat the absence of \\(F\\) is a permanent property of the absence of\n\\(G\\), which conflates logical and physical necessities and\ncontradicts the assumption of contingency (Fetzer 1981: 193–4;\nFetzer 2000a). It follows that “\\((x)(Fxt \\rightarrow\nGx)\\)” is not logically equivalent to “\\((x)(\\neg Gx\n\\rightarrow \\neg Fx)\\)”, even though it entails the\ncorresponding extensional generalization, “\\((x)(Fx \\supset\nGx)\\)”, which can account for differences between explanations\nand predictions based on them. The paradox of transposition is\novercome, because lawlike sentences are not transposable. Subjunctives\ncan be true even when they have no instances; indeed, counterfactuals\nare subjunctives with false antecedents. Actualism thus appears to be\ndispensable. But the modus tollens paradox endures,\nsuggesting something is still not quite right. Even the adoption of a\nbetter theory of laws is not enough to exonerate Hempel’s\nadequacy conditions. \nIn his studies of inductive reasoning, Hempel (1960, 1962a, 1966b)\ndiscusses the ambiguity of induction, which arises because\nincompatible conclusions can appear to be equally-well supported by\ninductive arguments, where all the premises of both arguments are\ntrue. This problem has no analogue for deductive arguments:\ninconsistent conclusions cannot be validly derived from consistent\npremises, even if they are false. Inconsistent conclusions can receive\ninductive support from consistent premises, however, even when they\nare all true. Consider Hempel’s illustration of conflicting\npredictions for a patient’s recovery: \nThis information, taken by itself, would surely lend strong support to\nthe hypothesis, \nBut suppose that we also have the information: \nThis information by itself would lend strong support to the\ncontradictory of (h1): \nThus, Hempel observed, (e1) and (e2) are logically compatible and\ncould all be part of the evidence available when Jones’\nprognosis is being considered. The solution Hempel endorsed was\nthe requirement of total evidence, according to which, in\nreasoning about the world, arguments must be based upon all the\navailable evidence, though he noted that evidence can be omitted when\nit is irrelevant and its omission does not affect the level of\nsupport. Here, when (e1) is combined with (e2), \\((\\neg\\)h1) is better\nsupported than (h1). \nHempel referred to statistical explanations as\n“inductive-statistical” in contrast with his prior\ndiscussion of “deductive-nomological” explanations (Hempel\n1958). Because generalizations of both kinds are supposed to be\nlawlike, however, more appropriate names for them might have been\n“universal-deductive” and\n“statistical-inductive” (or, perhaps,\n“statistical-probabilistic”, respectively (Fetzer 1974).\nIn formalizing these arguments, Hempel symbolized statistical premises\nattributing a certain probability to outcome \\(G\\), under conditions\n\\(F\\), by “\\(P(G, F) = r\\)”, where these explanations then\nassume this form: \nFigure 7. An I-S Explanation Schema \nWhile Hempel initially interpreted the bracketed variable [\\(r\\)] as\nthe measure of inductive support which the explanans confers upon the\nexplanandum, \\(Gi\\), (in conformity with the requirement of total\nevidence)—where the value of [\\(r\\)] equals that of\n\\(r\\)—it occurred to him that, since inductive and deductive\nexplanations are typically offered on the basis of the knowledge that\ntheir explanandum events have already occurred, viewing statistical\nexplanations as inductive arguments whose purpose is to establish how\nwe know that they have occurred (or that they will occur) is not the\ncorrect perspective for understanding them: \nthe point of an explanation is not to provide evidence for the\noccurrence of the explanandum, but to exhibit it as nomically\nexpectable. And the probability attached to an I-S explanation is\nthe probability of the conclusion relative to the explanatory\npremises, not relative to the total class \\(\\mathbf{K}\\) [representing\nour total knowledge at that time]. (Hempel 1968, original\nemphasis) \nIn order to formalize this conception, he advanced the concept of\na maximally specific predicate related to “Gi” in\n\\(\\mathbf{K}\\), where, when “\\(P(G, F) = r\\)”, then,\nif the premises include a predicate stronger than “\\(F\\)”,\nsay, “\\(M\\)”, which implies the presence of more\nproperties than does “\\(F\\)”, then “\\(P(G, M) =\nr\\)”, where, as before, \\(r = P(G, F)\\). Thus additional\npredicates could be included in the explanans of an adequate\nscientific explanation, provided that they made no difference to the\nnomic expectability of the explanandum. Including the position of the\nmoon or the day of the week a match is struck, for example, might be\nirrelevant, but his condition did not exclude them. Wesley C. Salmon\n(1970), however, would pursue this issue by arguing that Hempel had\nembraced the wrong standard upon which to base explanatory relevance\nrelations, where explanations, in Salmon’s view, strictly\nspeaking, do not even qualify as arguments. \nSalmon offered a series of counterexamples to Hempel’s approach.\nIn the case of I-S explanations, Hempel required that the nomic\nexpectability of the explanandum must be equal to or greater than .5,\nwhich preserved the symmetry thesis for explanations of this kind.\nThis implied that events with low probability could not be explained.\nThere were persuasive illustrations, moreover, demonstrating that\nexplanations could satisfy Hempel’s criteria, yet not explain\nwhy their explanandum events occur. For example, \nMost colds clear up within a week, with or without vitamin C, and\nsimilarly for neurotic symptoms. Salmon thought that this problem was\npeculiar to statistical explanations, but was corrected by Henry\nKyburg (1965), who offered examples of the following kind: \nFor Hempel, a property \\(F\\) is explanatorily relevant to the\noccurrence of an outcome \\(G\\) if there is a lawful relationship that\nrelates \\(F\\) to \\(G\\). If table salt dissolves in water, so does\nMorton’s table salt, Morton’s finest table salt,\nMorton’s finest table salt bought on sale, and so on. Salmon\nconcluded that Hempel’s conception of I-S explanation was\nwrong. \nA student of Reichenbach (1938, 1949), Salmon had adopted and defended\nthe limiting frequency interpretation of physical probability, where\n“\\(P(G/F) = r\\)” means that \\(G\\) occurs with a limiting\nfrequency \\(r\\) in a reference class of instances of \\(F\\), which has\nto be infinite for limits to exist (Salmon 1967, 1971). On this\napproach, a property \\(H\\) is explanatorily relevant to the\noccurrence of an attribute \\(G\\) within a reference class \\(F\\) just\nin case (SR): \nthat is, the limiting frequency for \\(G\\) in \\(F\\)-and-\\(H\\) differs\nfrom the limiting frequency for \\(G\\) in \\(F\\)-and-not-\\(H\\).\nProperties whose presence does not make a difference to the limiting\nfrequency for the occurrence of \\(G\\) in \\(F\\) would therefore qualify\nas statistically irrelevant. Relative frequencies were typically\nrelied upon in practice, but in principle they had to be limiting. \nSalmon also rejected Hempel’s requirement that the nomic\nexpectability of a statistical explanation must be equal to or greater\nthan .5, which led him to abandon the notion of explanations as\narguments. Even events of low probability were explainable within the\ncontext of Salmon’s approach, which he compared with\nHempel’s approach as follows: \nI-S model (Hempel): an explanation is an argument that\nrenders the explanandum highly probable; \nS-R model (Salmon): an explanation is an assembly of facts\nstatistically relevant to the explanandum regardless of the\ndegree of probability that results. (Salmon 1971, original\nemphasis) \nSalmon’s work created a sensation, since Hempel’s\ndominance of the philosophy of science, especially in relation to the\ntheory of explanation, now had a significant rival. The students of\nexplanation who recognized that probabilities as properties of\ninfinite classes posed substantial problems were few, and those who\nrealized that Salmon’s position confronted difficulties of its\nown fewer still. \nSalmon was ingenious in devising “screening off” criteria\nto insure that the properties cited in an S-R explanation were\nrestricted to those that were statistically relevant. He may have\nappreciated that the available evidence was restricted to relative\nfrequencies in finite sequences, but that could be discounted as\ntypical of the distinction between a context \\(\\mathbf{K}\\)\nrepresenting our total knowledge at that time and the truth condition,\nsince scientific knowledge is always tentative and fallible. A deeper\nproblem arose from the existence of properties that were statistically\nrelevant but not explanatorily relevant, however. If women whose\nmiddle initials began with vowels, for example, experienced\nmiscarriages with a different frequency than women whose middle\ninitials began with consonants—even after other properties were\ntaken into account—then that property would have to qualify as\nstatistically relevant and therefore explanatorily relevant\n(Fetzer 1974, 1981). This result implied that statistical relevance\ncannot adequately define explanatory relevance, and Salmon would\ngradually move toward the propensity approach in Salmon (1980,\n1989). \nThe advantage of propensities over frequencies are considerable,\nsince, on the propensity account, a probabilistic law no longer simply\naffirms that a certain percentage of the reference class belongs to\nthe attribute class. What it asserts instead is that every member of\nthe reference class possesses a certain disposition, which in the case\nof statistical laws is of probabilistic strength and in the case of\nuniversal laws of universal strength. On its single-case formulation,\nmoreover, short runs and long runs are simply finite and infinite\nsequences of single cases, where each trial has propensities that are\nequal and independent from trial to trial and classic theorems of\nstatistical inference apply.  \nEnvisioning dispositions as single-case causal tendencies brought the\nfurther benefit that the differences between them could be formalized\nusing causal conditionals “__ \\(=n=\\gt \\ldots\\)” of\nvariable strength \\(n\\) in the case of probabilistic laws and of\nuniversal strength \\(u\\) in the case of universal laws “__\n\\(=u=\\gt \\ldots\\)” (Fetzer 1974, 1981). This completes the conception of natural laws\nas subjunctive conditionals attributing permanent properties to\nuniversals as dispositions and thereby justifies two basic models of\nexplanation, the universal-deductive (U-D) model and the\nprobabilistic-inductive (P-I) model, where, for example, why a match\nof kind \\(K\\) lighted when struck could assumes the following form by\nadopting appropriate formulations when temporal constants\n“\\(t\\)” and quantifiers “\\((t)\\)” are included\nand “\\(t^*\\)” occurs some specific interval of time after\n“\\(t\\)”: \nFigure 8. A Universal-Deductive\nExplanation \nExplanations for indeterministic phenomena are equally\nstraightforward. If the half-life of 3.05 minutes is a permanent\nproperty of atoms of polonium-\\(218 (^{218}\\)P), for example, then a\nprobabilistic law could express its meaning as a disposition \\(H\\) of\nstrength .5 to undergo decay \\(D\\) during any 3.05 minute interval\n\\(I\\), which could be formally displayed as follows: \nFigure 9. A Probabilistic-Inductive\nExplanation \nHere the value of [\\(r\\)] can be justified as a degree of nomic\nexpectability that applies to every single case of the reference\nproperty and implies that, for collections of atoms of \\(^{218}\\)P,\napproximately half will undergo decay during any 3.05 minute interval,\nwhich enables lawlike sentences of probabilistic form to be subjected\nto empirical test, on the basis of relative frequencies, especially by\nattempting to refute them. Salmon also expressed enthusiasm for this\napproach, which he regarded as “a straightforward\ngeneralization” of Hempel’s account (Salmon 1989:\n83–89; Fetzer 1992). And it does appear to be a suitable\nsuccessor, not only to Hempel’s I-S but also his D-N\napproach. \nEven this intensional explication would still be vulnerable to the\nproblems of irrelevant properties and the modus tollens\nparadox but for the adoption of a condition to exclude the occurrence\nof predicates that are not nomically relevant to the explanandum event\nfrom the explanans of an adequate scientific explanation. This\ncriterion, known as the requirement of strict maximal\nspecificity, permits the reformulation of Hempel’s four\nconditions of adequacy by replacing the redundant empirical content\ncondition with this new requirement (Fetzer 1981; Salmon 1989).\nExplanations not only display the nomic expectability of\ntheir explanandum events—which, in the case of those that occur\nwith high probability, would enable them to have been predicted, as\nHempel proposed but—more importantly—explain them by\nspecifying all and only those properties nomically\nresponsible for their occurrence, even when they occur with low\nprobability (Fetzer 1992). \nBromberger’s flagpole counterexample provides a severe test of\nthis requirement. The reason why the inference from the length of the\nshadow to the height of the flagpole is non-explanatory is because the\nlength of the shadow is not nomically responsible for the\nflagpole’s height. Hempel’s original conditions could not\ncope with situations of this kind, where inferences using laws support\npredictions and retrodictions that are not also explanations, even\nthough they satisfy all four. This alternative condition thus requires\nthat the properties cited in the antecedent of the lawlike premise(s)\nmust be nomically relevant to the explanandum or may not be included\nthere (Fetzer 1981, 1992). The height of the flagpole, but not the\nlength of the shadow, qualifies as nomically relevant, which resolves\nthe quandary—at the expense of acknowledging classes of\narguments that are predictive or retrodictive but not\nexplanatory, even when they involve inferences from law(s) that\nsatisfy Hempel’s original criteria. The reformulated conditions\nare: \nBy formulating (CA-1*) in this way, the covering law conception of the\nsubsumption of singular events by general laws is preserved; but\nabandonment of the high-probability requirement led both Salmon (1971)\nand Alberto Coffa (1973) to question whether or not explanations still\nproperly qualify as “arguments”. At the least, however,\nthey would appear to be special kinds of “explanatory\narguments”, even when they involve low probabilities. \nThese revised conditions implicitly require abandoning Hempel’s\ncommitment to extensional methodology to capture the notion of nomic\nresponsibility, but the benefits of an intensional approach appear to\nbe profound. As Salmon has observed, \n[on such an explication] the distinction between description and\nprediction, on the one hand, and explanation, on the\nother, is that the former can proceed in an extensional language\nframework, while the latter demands an intensional language framework.\nIt remains to be seen whether the intensional logic can be\nsatisfactorily formulated (Salmon 1989: 172, original emphasis). \nThis approach to explanation incorporates the causal relevance\ncriterion, according to which a property \\(H\\) is causally\nrelevant to the occurrence of an attribute \\(G\\) relative to a\nreference property \\(F\\)—within the context of a causal\nexplanation—just in case (CR): \nthat is, the propensity for \\(G\\), given \\(F \\amp H\\), differs from\nthe propensity for \\(G\\), given \\(F \\amp \\neg H\\), where the presence\nor absence of \\(H\\) affects the single-case causal tendency for \\(G\\).\nThe universal generalization of sentential functions like these thus\nproduces lawlike sentences, while their instantiation to\nindividual constants or to ambiguous names produces (what are known\nas) nomological conditionals (Fetzer 1981: 49–54). The\nintroduction of the probabilistic causal calculus \\(C\\), moreover,\nresponds to Salmon’s concerns by providing a formalization\nwithin intensional logic that resolves them (Fetzer & Nute 1979,\n1980). \nWhat may come as some surprise is that Hempel exposed yet another\nsignificant problem confronting the theory of scientific explanation.\nOne of the most remarkable features of his career is that he continued\nto publish original and innovative studies well into his eightieth\ndecade. Rather surprisingly, he authored a series of articles that\nmoved away from the influential conception of scientific theories as\nformal calculi combined with empirical\ninterpretations that had been characteristic of logical\nempiricism. In Hempel (1966a), at the time, the most widely adopted\nintroduction to the philosophy of science, which has been translated\ninto ten other languages, he advanced the novel explication of\nscientific theories as consisting of internal principles and\nbridge principles, where the lawlike hypotheses that\ndistinguish theories are linked to observation, measurement, and\nexperiment by principles expressed in various mixtures of ordinary and\nof technical language. Now antecedent understanding replaces explicit\ndefinability, which seems to have been, in part, a response to the\ndemise of the observational/theoretical distinction. \nEven more strikingly, Hempel (1988a,b) observed that the application\nof scientific theories presupposes the absence of factors that might\naffect the internal principles of the theory, which goes beyond the\ncontent of the theory itself. Deriving predictions and explanations\nfrom classical mechanics presupposes that bodies are being acted upon\nexclusively by gravitational forces, for example, where the presence\nof electromagnetic forces would invalidate those derivations. This is\nnot simply a matter of conducting tests “under suitable\nconditions”, where the malleability of gold differs when struck\nby a hammer when at extremely cold temperatures (where the\ncombustibility of paper differs when the paper is wet, and so on),\nwhich are familiar examples of the various specific conditions that\nmust be identified in complete definitions of dispositional\npredicates. What Hempel noticed is that these properties may not only\nbe affected by conditions covered by the theory being applied but\ninvolve entirely different theories. He took this to mean that the\napplication of theories has to be accompanied by\n“provisos” affirming that no properties beyond those\nspecified by the theory are present in a specific case. \nThe function of these provisos means that instrumentalist\nconstructions of scientific theories as mere calculating devices and\nprograms for the elimination of theoretical language by reduction to\nobservational language alone are misguided and cannot be sustained.\nAnd this is because, if other theoretical properties make a difference\nto the application of a particular theory, then the observational\nconsequences of that theory cannot be assumed to obtain in any\ninstance without provisos about other theoretical properties beyond\nthose specified by the theory, which requires separate investigation\non the basis of observation, measurement, and experiment. The\nconditions for testing, confirming or falsifying alternative\nhypotheses and theories is thereby rendered vastly more complex than\nhad previously been supposed. Strikingly, as an essential element of\nan adequate explanation, Coffa (1973) had advanced “extremal\nclauses” that assert that no factors other than those specified\nby the initial conditions of the explanans are relevant to the\noccurrence of the explanandum event. Indeed, Salmon points out that,\nsince the application of every law involves a tacit extremal (or\n“ceteris paribus”) clause, any law can be protected from\nrefutation by discounting disconfirming evidence on the expedient of\nclaiming that, because the clause was not satisfied, the law is still\ncorrect, which is another way to accent the source of Hempel’s\nconcern (Salmon 1989: 84–85). \nThese observations are related to the claim that “the laws of\nphysics lie”, which has been suggested by Nancy Cartwright\n(1983). She has claimed that there are theoretical laws, which are\nsupposed to be “simple” but rarely if ever instantiated,\nand phenomenological laws, which are frequently instantiated but\ntypically if not always complex. Armstrong (1983: 137–140) draws a distinction\nbetween laws that are “iron” and have no exceptions and\nthose that are “oaken” and have no exceptions as long\nas no interfering conditions are present. In his language, unless\nCartwright has overlooked the possibility that some laws might be both\ncomplex and true, she seems to be saying that theoretical laws are\n“oaken” laws for which there are no “iron”\ncounterparts. If that is right, then she has failed to appreciate the\ndistinction between counterfactual conditionals (which may be true\nin spite of having no instances) and mere indicative\nconditionals (which may be true because they have no\ninstances). Alternatively, the “provisos” problem implies\nthat satisfying the requirement of maximal specificity may be more\ndemanding than has been generally understood in the past. Either way,\nCartwright’s theses appear to trade on an equivocation between\nthe non-existence of “iron” counterparts and their\nnon-availability: even if the “iron” laws within a domain\nare not yet known, it does not follow that those laws do not exist.\nRecent studies of the problem of provisos include Earman and Roberts\n(1999), Glymour (2002), Kowalenko (2009) and Reutlinger (2014). \nThe publication of Thomas S. Kuhn’s The Structure of\nScientific Revolutions (1962), ironically, was among the\nhistorical developments that contributed to a loss of confidence in\nscience. Kuhn’s work, which turned “paradigm” into a\nhousehold word, was widely regarded as assimilating revolutions in\nscience to revolutions in politics, where one theory succeeds another\nonly upon the death of its adherents. It was interpreted as having\ndestroyed the myth that philosophers possess some special kind of\nwisdom or insight in relation to the nature of science or the thought\nprocesses of scientists with respect to their rationality, almost as\nthough every opinion were on a par with every other. A close reading\nof Kuhn’s work shows that these were not his own conclusions,\nbut they were enormously influential. And among the public at large\nand many social scientists, the tendency to no longer hold science in\nhigh esteem or to be affected by its findings has induced political\nramifications that are inimical to the general good. When our beliefs\nare not well founded, actions we base upon them are unlikely to\nsucceed, often with unforeseen effects that are harmful. Rational\nactions ought to be based upon rational beliefs, where science has\nproven to be the most reliable method for acquiring knowledge about\nourselves and the world around us. \nThis study supports the conclusion that Hempel’s conception of\nscientific explanations as involving the subsumption of singular\nevents by means of covering laws was well-founded, even though his\ncommitment to an extensional methodology inhibited him from embracing\na more adequate account of natural laws. The symmetry thesis turns out\nto require qualification, not only with respect to predictions for\nevents that occur only with low probability, but also for\nretrodictions derived by modus tollens. The link that perhaps\nmost accurately embodies the relationship between Hempel’s work\non explanation and decision-and-inference occurs in the form of\n“the principal principle”, which David Lewis advanced to\nformalize the recognition that personal probabilities as degrees of\nbelief in the occurrence of specific events under specific conditions\nshould have the same values as corresponding objective probabilities,\nwhen they are known (Lewis 1980). The values of propensities as\nproperties of laws, no doubt, should be given precedence over the\nvalues of frequencies, insofar as laws, unlike frequencies, cannot be\nviolated and cannot be changed and provide a more reliable guide. \nA recent trend presumes that the philosophy of science has been\nmisconceived and requires “a naturalistic turn” as a kind\nof science of science more akin to history or to sociology than to\nphilosophy. In studies published in the twilight of his career, Hempel\ndemonstrated that, without standards to separate science from\npseudo-science, it would be impossible to distinguish frauds,\ncharlatans, and quacks from the real thing (Hempel 1979, 1983).\nWithout knowing “the standards of science”, we would not\nknow which of those who call themselves “scientists” are\nscientists and which methods are “scientific”, where the\nplace of explanation remains central within the context of inference\nto the best explanation (Fetzer 2002). The philosophy of science,\ntherefore, cannot be displaced by history or by sociology. Not least\namong the important lessons of Hempel’s enduring legacy is the\nrealization that the standards of science cannot be derived from mere\ndescriptions of its practice alone but require rational justification\nin the form of explications satisfying the highest standards of\nphilosophical rigor.\n\n","contact.mail":"jfetzer@d.umn.edu","contact.domain":"d.umn.edu"}]
