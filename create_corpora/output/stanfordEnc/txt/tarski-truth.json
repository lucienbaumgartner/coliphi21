[{"date.published":"2001-11-10","date.changed":"2018-08-20","url":"https://plato.stanford.edu/entries/tarski-truth/","author1":"Wilfrid Hodges","author1.info":"http://wilfridhodges.co.uk/","entry":"tarski-truth","body.text":"\n\n\nIn 1933 the Polish logician Alfred Tarski published a paper in which\nhe discussed the criteria that a definition of ‘true\nsentence’ should meet, and gave examples of several such\ndefinitions for particular formal languages. In 1956 he and his\ncolleague Robert Vaught published a revision of one of the 1933 truth\ndefinitions, to serve as a truth definition for model-theoretic\nlanguages. This entry will simply review the definitions and make no\nattempt to explore the implications of Tarski’s work for\nsemantics (natural language or programming languages) or for the\nphilosophical study of truth. (For those implications, see the entries\non\n truth\n and\n Alfred Tarski.)\n \nIn the late 1920s Alfred Tarski embarked on a project to give rigorous\ndefinitions for notions useful in scientific methodology. In 1933 he\npublished (in Polish) his analysis of the notion of a true sentence.\nThis long paper undertook two tasks: first to say what should count as\na satisfactory definition of ‘true sentence’ for a given\nformal language, and second to show that there do exist satisfactory\ndefinitions of ‘true sentence’ for a range of formal\nlanguages. We begin with the first task; Section 2 will consider the\nsecond. \nWe say that a language is fully interpreted if all its\nsentences have meanings that make them either true or false. All the\nlanguages that Tarski considered in the 1933 paper were fully\ninterpreted, with one exception described in Section 2.2 below. This\nwas the main difference between the 1933 definition and the later\nmodel-theoretic definition of 1956, which we shall examine in Section\n3. \nTarski described several conditions that a satisfactory definition of\ntruth should meet. \nIf the language under discussion (the object language) is\n\\(L\\), then the definition should be given in another language known\nas the metalanguage, call it \\(M\\). The metalanguage should\ncontain a copy of the object language (so that anything one can say in\n\\(L\\) can be said in \\(M\\) too), and \\(M\\) should also be able to talk\nabout the sentences of \\(L\\) and their syntax. Finally Tarski allowed\n\\(M\\) to contain notions from set theory, and a 1-ary predicate symbol\nTrue with the intended reading ‘is a true sentence of\n\\(L\\)’. The main purpose of the metalanguage was to formalise\nwhat was being said about the object language, and so Tarski also\nrequired that the metalanguage should carry with it a set of axioms\nexpressing everything that one needs to assume for purposes of\ndefining and justifying the truth definition. The truth definition\nitself was to be a definition of True in terms of the other\nexpressions of the metalanguage. So the definition was to be in terms\nof syntax, set theory and the notions expressible in \\(L\\), but not\nsemantic notions like ‘denote’ or ‘mean’\n(unless the object language happened to contain these notions). \nTarski assumed, in the manner of his time, that the object language\n\\(L\\) and the metalanguage \\(M\\) would be languages of some kind of\nhigher order logic. Today it is more usual to take some kind of\ninformal set theory as one’s metalanguage; this would affect a\nfew details of Tarski’s paper but not its main thrust. Also\ntoday it is usual to define syntax in set-theoretic terms, so that for\nexample a string of letters becomes a sequence. In fact one must use a\nset-theoretic syntax if one wants to work with an object language that\nhas uncountably many symbols, as model theorists have done freely for\nover half a century now. \nThe definition of True should be ‘formally\ncorrect’. This means that it should be a sentence of the\nform \nFor all \\(x\\), True\\((x)\\) if and only if \\(\\phi(x)\\),\n \nwhere True never occurs in \\(\\phi\\); or failing this, that\nthe definition should be provably equivalent to a sentence of this\nform. The equivalence must be provable using axioms of the\nmetalanguage that don’t contain True. Definitions of\nthe kind displayed above are usually called explicit, though\nTarski in 1933 called them normal. \nThe definition should be ‘materially adequate’\n(trafny – a better translation would be\n‘accurate’). This means that the objects satisfying\n\\(\\phi\\) should be exactly the objects that we would intuitively count\nas being true sentences of \\(L\\), and that this fact should be\nprovable from the axioms of the metalanguage. At first sight this is a\nparadoxical requirement: if we can prove what Tarski asks for, just\nfrom the axioms of the metalanguage, then we must already have a\nmaterially adequate formalisation of ‘true sentence of\n\\(L\\)’ within the metalanguage, suggesting an infinite regress.\nIn fact Tarski escapes the paradox by using (in general) infinitely\nmany sentences of \\(M\\) to express truth, namely all the sentences of\nthe form \nwhenever \\(s\\) is the name of a sentence \\(S\\) of \\(L\\) and \\(\\psi\\)\nis the copy of \\(S\\) in the metalanguage. So the technical problem is\nto find a single formula \\(\\phi\\) that allows us to deduce all these\nsentences from the axioms of \\(M\\); this formula \\(\\phi\\) will serve\nto give the explicit definition of True. \nTarski’s own name for this criterion of material adequacy was\nConvention T. More generally his name for his approach to\ndefining truth, using this criterion, was the semantic conception\nof truth. \nAs Tarski himself emphasised, Convention \\(T\\) rapidly leads to the\nliar paradox if the language \\(L\\) has enough resources to talk about\nits own semantics. (See the entry on\n the revision theory of truth.)\n Tarski’s own conclusion was that a truth definition for a\nlanguage \\(L\\) has to be given in a metalanguage which is essentially\nstronger than \\(L\\). \nThere is a consequence for the foundations of mathematics. First-order\nZermelo-Fraenkel set theory is widely regarded as the standard of\nmathematical correctness, in the sense that a proof is correct if and\nonly if it can be formalised as a formal proof in set theory. We would\nlike to be able to give a truth definition for set theory; but by\nTarski’s result this truth definition can’t be given in\nset theory itself. The usual solution is to give the truth definition\ninformally in English. But there are a number of ways of giving\nlimited formal truth definitions for set theory. For example Azriel\nLevy showed that for every natural number \\(n\\) there is a\n\\(\\Sigma_n\\) formula that is satisfied by all and only the\nset-theoretic names of true \\(\\Sigma_n\\) sentences of set theory. The\ndefinition of \\(\\Sigma_n\\) is too technical to give here, but three\npoints are worth making. First, every sentence of set theory is\nprovably equivalent to a \\(\\Sigma_n\\) sentence for any large enough\n\\(n\\). Second, the class of \\(\\Sigma_n\\) formulas is closed under\nadding existential quantifiers at the beginning, but not under adding\nuniversal quantifiers. Third, the class is not closed under negation;\nthis is how Levy escapes Tarski’s paradox. (See the entry on\n set theory.)\n Essentially the same devices allow Jaakko Hintikka to give an\ninternal truth definition for his\n independence friendly logic;\n this logic shares the second and third properties of Levy’s\nclasses of formulas. \nIn his 1933 paper Tarski went on to show that many fully interpreted\nformal languages do have a truth definition that satisfies his\nconditions. He gave four examples in that paper. One was a trivial\ndefinition for a finite language; it simply listed the finitely many\ntrue sentences. One was a definition by quantifier elimination; see\nSection 2.2 below. The remaining two, for different classes of\nlanguage, were examples of what people today think of as the standard\nTarski truth definition; they are forerunners of the 1956\nmodel-theoretic definition. \nThe two standard truth definitions are at first glance not definitions\nof truth at all, but definitions of a more complicated relation\ninvolving assignments \\(a\\) of objects to variables: \n(where the symbol ‘\\(F\\)’ is a placeholder for a name of a\nparticular formula of the object language). In fact satisfaction\nreduces to truth in this sense: \\(a\\) satisfies the formula \\(F\\) if\nand only if taking each free variable in \\(F\\) as a name of the object\nassigned to it by \\(a\\) makes the formula \\(F\\) into a true sentence.\nSo it follows that our intuitions about when a sentence is true can\nguide our intuitions about when an assignment satisfies a formula. But\nnone of this can enter into the formal definition of truth, because\n‘taking a variable as a name of an object’ is a semantic\nnotion, and Tarski’s truth definition has to be built only on\nnotions from syntax and set theory (together with those in the object\nlanguage); recall Section 1.1. In fact Tarski’s reduction goes\nin the other direction: if the formula \\(F\\) has no free variables,\nthen to say that \\(F\\) is true is to say that every assignment\nsatisfies it. \nThe reason why Tarski defines satisfaction directly, and then deduces\na definition of truth, is that satisfaction obeys recursive\nconditions in the following sense: if \\(F\\) is a compound\nformula, then to know which assignments satisfy \\(F\\), it’s enough\nto know which assignments satisfy the immediate constituents of \\(F\\).\nHere are two typical examples: \nWe have to use a different approach for atomic formulas. But for\nthese, at least assuming for simplicity that \\(L\\) has no function\nsymbols, we can use the metalanguage copies \\(\\#(R)\\) of the predicate\nsymbols \\(R\\) of the object language. Thus: \n(Warning: the expression \\(\\#\\) is in the metametalanguage, not in the\nmetalanguage \\(M\\). We may or may not be able to find a formula of\n\\(M\\) that expresses \\(\\#\\) for predicate symbols; it depends on exactly\nwhat the language \\(L\\) is.) \nSubject to the mild reservation in the next paragraph, Tarski’s\ndefinition of satisfaction is compositional, meaning that the\nclass of assignments which satisfy a compound formula \\(F\\) is\ndetermined solely by (1) the syntactic rule used to construct \\(F\\)\nfrom its immediate constituents and (2) the classes of assignments\nthat satisfy these immediate constituents. (This is sometimes phrased\nloosely as: satisfaction is defined recursively. But this formulation\nmisses the central point, that (1) and (2) don’t contain any\nsyntactic information about the immediate constituents.)\nCompositionality explains why Tarski switched from truth to\nsatisfaction. You can’t define whether ‘For all\n\\(x, G\\)’ is true in terms of whether \\(G\\) is true, because in\ngeneral \\(G\\) has a free variable \\(x\\) and so it isn’t either\ntrue or false. \nThe reservation is that Tarski’s definition of satisfaction in\nthe 1933 paper doesn’t in fact mention the class of assignments\nthat satisfy a formula \\(F\\). Instead, as we saw, he defines the\nrelation ‘\\(a\\) satisfies \\(F\\)’, which determines what\nthat class is. This is probably the main reason why some people\n(including Tarski himself in conversation, as reported by Barbara\nPartee) have preferred not to describe the 1933 definition as\ncompositional. But the class format, which is compositional on any\nreckoning, does appear in an early variant of the truth definition in\nTarski’s paper of 1931 on definable sets of real numbers. Tarski\nhad a good reason for preferring the format ‘\\(a\\) satisfies\n\\(F\\)’ in his 1933 paper, namely that it allowed him to reduce\nthe set-theoretic requirements of the truth definition. In sections 4\nand 5 of the 1933 paper he spelled out these requirements\ncarefully. \nThe name ‘compositional(ity)’ first appears in papers of\nPutnam in 1960 (published 1975) and Katz and Fodor in 1963 on natural\nlanguage semantics. In talking about compositionality, we have moved\nto thinking of Tarski’s definition as a semantics, i.e. a way of\nassigning ‘meanings’ to formulas. (Here we take the\nmeaning of a sentence to be its truth value.) Compositionality means\nessentially that the meanings assigned to formulas give at\nleast enough information to determine the truth values of\nsentences containing them. One can ask conversely whether\nTarski’s semantics provides only as much information as we\nneed about each formula, in order to reach the truth values of\nsentences. If the answer is yes, we say that the semantics is\nfully abstract (for truth). One can show fairly easily, for\nany of the standard languages of logic, that Tarski’s definition\nof satisfaction is in fact fully abstract. \nAs it stands, Tarski’s definition of satisfaction is not an\nexplicit definition, because satisfaction for one formula is defined\nin terms of satisfaction for other formulas. So to show that it is\nformally correct, we need a way of converting it to an explicit\ndefinition. One way to do this is as follows, using either higher\norder logic or set theory. Suppose we write \\(S\\) for a binary\nrelation between assignments and formulas. We say that \\(S\\) is a\nsatisfaction relation if for every formula \\(G, S\\) meets the\nconditions put for satisfaction of \\(G\\) by Tarski’s definition.\nFor example, if \\(G\\) is ‘\\(G_1\\) and \\(G_2\\)’,\n\\(S\\) should satisfy the following condition for every assignment\n\\(a\\): \nWe can define ‘satisfaction relation’ formally, using the\nrecursive clauses and the conditions for atomic formulas in\nTarski’s recursive definition. Now we prove, by induction on the\ncomplexity of formulas, that there is exactly one satisfaction\nrelation \\(S\\). (There are some technical subtleties, but it can be\ndone.) Finally we define \n\\(a\\) satisfies \\(F\\) if and only if: there is a satisfaction relation\n\\(S\\) such that \\(S(a,F)\\).\n \nIt is then a technical exercise to show that this definition of\nsatisfaction is materially adequate. Actually one must first write out\nthe counterpart of Convention \\(T\\) for satisfaction of formulas, but\nI leave this to the reader. \nThe remaining truth definition in Tarski’s 1933 paper –\nthe third as they appear in the paper – is really a bundle of\nrelated truth definitions, all for the same object language \\(L\\) but\nin different interpretations. The quantifiers of \\(L\\) are assumed to\nrange over a particular class, call it \\(A\\); in fact they are second\norder quantifiers, so that really they range over the collection of\nsubclasses of \\(A\\). The class \\(A\\) is not named explicitly in the\nobject language, and thus one can give separate truth definitions for\ndifferent values of \\(A\\), as Tarski proceeds to do. So for this\nsection of the paper, Tarski allows one and the same sentence to be\ngiven different interpretations; this is the exception to the general\nclaim that his object language sentences are fully interpreted. But\nTarski stays on the straight and narrow: he talks about\n‘truth’ only in the special case where \\(A\\) is the class\nof all individuals. For other values of \\(A\\), he speaks not of\n‘truth’ but of ‘correctness in the domain\n\\(A\\)’. \nThese truth or correctness definitions don’t fall out of a\ndefinition of satisfaction. In fact they go by a much less direct\nroute, which Tarski describes as a ‘purely accidental’\npossibility that relies on the ‘specific peculiarities’ of\nthe particular object language. It may be helpful to give a few more\nof the technical details than Tarski does, in a more familiar notation\nthan Tarski’s, in order to show what is involved. Tarski refers\nhis readers to a paper of Thoralf Skolem in 1919 for the\ntechnicalities. \nOne can think of the language \\(L\\) as the first-order language with\npredicate symbols \\(\\subseteq\\) and =. The language is interpreted as\ntalking about the subclasses of the class \\(A\\). In this language we\ncan define: \nNow we aim to prove:  \nLemma. Every formula \\(F\\) of \\(L\\) is equivalent to (i.e. is\nsatisfied by exactly the same assignments as) some boolean combination\nof sentences of the form ‘There are exactly \\(k\\) elements in\n\\(A\\)’ and formulas of the form ‘There are exactly \\(k\\)\nelements that are in \\(v_1\\), not in \\(v_2\\), not in \\(v_3\\) and in\n\\(v_4\\)’ (or any other combination of this type, using only\nvariables free in \\(F)\\).\n \nThe proof is by induction on the complexity of formulas. For atomic\nformulas it is easy. For boolean combinations of formulas it is easy,\nsince a boolean combination of boolean combinations is again a boolean\ncombination. For formulas beginning with \\(\\forall\\), we take the\nnegation. This leaves just one case that involves any work, namely the\ncase of a formula beginning with an existential quantifier. By\ninduction hypothesis we can replace the part after the quantifier by a\nboolean combination of formulas of the kinds stated. So a typical case\nmight be: \n\\(\\exists z\\) (there are exactly two elements that are in \\(z\\) and\n\\(x\\) and not in \\(y)\\).\n \nThis holds if and only if there are at least two elements that are in\n\\(x\\) and not in \\(y\\). We can write this in turn as: The number of\nelements in \\(x\\) and not in \\(y\\) is not 0 and is not 1; which is a\nboolean combination of allowed formulas. The general proof is very\nsimilar but more complicated. \nWhen the lemma has been proved, we look at what it says about a\nsentence. Since the sentence has no free variables, the lemma tells us\nthat it is equivalent to a boolean combination of statements saying\nthat \\(A\\) has a given finite number of elements. So if we know how\nmany elements \\(A\\) has, we can immediately calculate whether the\nsentence is ‘correct in the domain \\(A\\)’. \nOne more step and we are home. As we prove the lemma, we should gather\nup any facts that can be stated in \\(L\\), are true in every domain,\nand are needed for proving the lemma. For example we shall almost\ncertainly need the sentence saying that \\(\\subseteq\\) is transitive.\nWrite \\(T\\) for the set of all these sentences. (In Tarski’s\npresentation \\(T\\) vanishes, since he is using higher order logic and\nthe required statements about classes become theorems of logic.) Thus\nwe reach, for example: \nTheorem. If the domain \\(A\\) is infinite, then a sentence\n\\(S\\) of the language \\(L\\) is correct in \\(A\\) if and only if \\(S\\)\nis deducible from \\(T\\) and the sentences saying that the number of\nelements of \\(A\\) is not any finite number.\n \nThe class of all individuals is infinite (Tarski asserts), so\nthe theorem applies when \\(A\\) is this class. And in this case Tarski\nhas no inhibitions about saying not just ‘correct in\n\\(A\\)’ but ‘true’; so we have our truth\ndefinition. \nThe method we have described revolves almost entirely around removing\nexistential quantifiers from the beginnings of formulas; so it is\nknown as the method of quantifier elimination. It is not as\nfar as you might think from the two standard definitions. In all cases\nTarski assigns to each formula, by induction on the complexity of\nformulas, a description of the class of assignments that satisfy the\nformula. In the two previous truth definitions this class is described\ndirectly; in the quantifier elimination case it is described in terms\nof a boolean combination of formulas of a simple kind. \nAt around the same time as he was writing the 1933 paper, Tarski gave\na truth definition by quantifier elimination for the first-order\nlanguage of the field of real numbers. In his 1931 paper it appears\nonly as an interesting way of characterising the set of relations\ndefinable by formulas. Later he gave a fuller account, emphasising\nthat his method provided not just a truth definition but an algorithm\nfor determining which sentences about the real numbers are true and\nwhich are false. \nIn 1933 Tarski assumed that the formal languages that he was dealing\nwith had two kinds of symbol (apart from punctuation), namely\nconstants and variables. The constants included logical constants, but\nalso any other terms of fixed meaning. The variables had no\nindependent meaning and were simply part of the apparatus of\nquantification. \n\n Model theory\n by contrast works with three levels of symbol. There are the logical\nconstants \\((=, \\neg\\), & for example), the variables (as before),\nand between these a middle group of symbols which have no fixed\nmeaning but get a meaning through being applied to a particular\nstructure. The symbols of this middle group include the nonlogical\nconstants of the language, such as relation symbols, function symbols\nand constant individual symbols. They also include the quantifier\nsymbols \\(\\forall\\) and \\(\\exists\\), since we need to refer to the\nstructure to see what set they range over. This type of three-level\nlanguage corresponds to mathematical usage; for example we write the\naddition operation of an abelian group as +, and this symbol stands\nfor different functions in different groups. \nSo one has to work a little to apply the 1933 definition to\nmodel-theoretic languages. There are basically two approaches: (1)\nTake one structure \\(A\\) at a time, and regard the nonlogical\nconstants as constants, interpreted in \\(A\\). (2) Regard the\nnonlogical constants as variables, and use the 1933 definition to\ndescribe when a sentence is satisfied by an assignment of the\ningredients of a structure \\(A\\) to these variables. There are\nproblems with both these approaches, as Tarski himself describes in\nseveral places. The chief problem with (1) is that in model theory we\nvery frequently want to use the same language in connection with two\nor more different structures – for example when we are defining\nelementary embeddings between structures (see the entry on\n first-order model theory).\n The problem with (2) is more abstract: it is disruptive and bad\npractice to talk of formulas with free variables being\n‘true’. (We saw in Section 2.2 how Tarski avoided talking\nabout truth in connection with sentences that have varying\ninterpretations.) What Tarski did in practice, from the appearance of\nhis textbook in 1936 to the late 1940s, was to use a version of (2)\nand simply avoid talking about model-theoretic sentences being true in\nstructures; instead he gave an indirect definition of what it is for a\nstructure to be a ‘model of’ a sentence, and apologised\nthat strictly this was an abuse of language. (Chapter VI of Tarski\n1994 still contains relics of this old approach.) \nBy the late 1940s it had become clear that a direct model-theoretic\ntruth definition was needed. Tarski and colleagues experimented with\nseveral ways of casting it. The version we use today is based on that\npublished by Tarski and Robert Vaught in 1956. See the entry on\n classical logic\n for an exposition. \nThe right way to think of the model-theoretic definition is that we\nhave sentences whose truth value varies according to the situation\nwhere they are used. So the nonlogical constants are not variables;\nthey are definite descriptions whose reference depends on the context.\nLikewise the quantifiers have this indexical feature, that the domain\nover which they range depends on the context of use. In this spirit\none can add other kinds of indexing. For example a Kripke structure is\nan indexed family of structures, with a relation on the index set;\nthese structures and their close relatives are fundamental for the\nsemantics of modal,\n temporal\n and\n intuitionist\n logic. \nAlready in the 1950s model theorists were interested in formal\nlanguages that include kinds of expression different from anything in\nTarski’s 1933 paper. Extending the truth definition to\ninfinitary logics was no problem at all. Nor was there any serious\nproblem about most of the generalised quantifiers proposed at the\ntime. For example there is a quantifier \\(Qxy\\) with the intended\nmeaning: \n\\(QxyF(x,y)\\) if and only if there is an infinite set \\(X\\) of\nelements such that for all \\(a\\) and \\(b\\) in \\(X, F(a,b)\\).\n \nThis definition itself shows at once how the required clause in the\ntruth definition should go. \nIn 1961 Leon Henkin pointed out two sorts of model-theoretic language\nthat didn’t immediately have a truth definition of\nTarski’s kind. The first had infinite strings of\nquantifiers: \nThe second had quantifiers that are not linearly ordered. For ease of\nwriting I use Hintikka’s later notation for these: \nHere the slash after \\(\\exists v_4\\) means that this quantifier is\noutside the scope of the earlier quantifier \\(\\forall v_1\\) (and also\noutside that of the earlier existential quantifier). \nHenkin pointed out that in both cases one could give a natural\nsemantics in terms of Skolem functions. For example the second\nsentence can be paraphrased as \nwhich has a straightforward Tarski truth condition in second order\nlogic. Hintikka then observed that one can read the Skolem functions\nas winning strategies in a game, as in the entry on\n logic and games.\n In this way one can build up a compositional semantics, by assigning\nto each formula a game. A sentence is true if and only if the player\nMyself (in Hintikka’s nomenclature) has a winning strategy for\nthe game assigned to the sentence. This game semantics agrees with\nTarski’s on conventional first-order sentences. But it is far\nfrom fully abstract; probably one should think of it as an operational\nsemantics, describing how a sentence is verified rather than whether\nit is true. \nThe problem of giving a Tarski-style semantics for Henkin’s two\nlanguages turned out to be different in the two cases. With the first,\nthe problem is that the syntax of the language is not well-founded:\nthere is an infinite descending sequence of subformulas as one strips\noff the quantifiers one by one. Hence there is no hope of giving a\ndefinition of satisfaction by recursion on the complexity of formulas.\nThe remedy is to note that the explicit form of\nTarski’s truth definition in Section 2.1 above didn’t\nrequire a recursive definition; it needed only that the conditions on\nthe satisfaction relation \\(S\\) pin it down uniquely. For\nHenkin’s first style of language this is still true, though the\nreason is no longer the well-foundedness of the syntax. \nFor Henkin’s second style of language, at least in\nHintikka’s notation (see the entry on\n independence friendly logic),\n the syntax is well-founded, but the displacement of the quantifier\nscopes means that the usual quantifier clauses in the definition of\nsatisfaction no longer work. To get a compositional and fully abstract\nsemantics, one has to ask not what assignments of variables satisfy a\nformula, but what sets of assignments satisfy the formula\n‘uniformly’, where ‘uniformly’ means\n‘independent of assignments to certain variables, as shown by\nthe slashes on quantifiers inside the formula’. (Further details\nof revisions of Tarski’s truth definition along these lines are\nin the entry on\n dependence logic.)\n Henkin’s second example is of more than theoretical interest,\nbecause clashes between the semantic and the syntactic scope of\nquantifiers occur very often in natural languages.","contact.mail":"wilfrid.hodges@btinternet.com","contact.domain":"btinternet.com"}]
