[{"date.published":"2001-07-27","date.changed":"2019-08-16","url":"https://plato.stanford.edu/entries/logic-games/","author1":"Wilfrid Hodges","author2":"Jouko Väänänen","author1.info":"http://wilfridhodges.co.uk/","entry":"logic-games","body.text":"\n\n\nGames between two players, of the kind where one player wins and one\nloses, became a familiar tool in many branches of logic during the\nsecond half of the twentieth century. Important examples are semantic\ngames used to define truth, back-and-forth games used to compare\nstructures, and dialogue games to express (and perhaps explain) formal\nproofs.\n\nThe links between logic and games go back a long way. If one thinks of\na debate as a kind of game, then Aristotle already made the\nconnection; his writings about syllogism are closely intertwined with\nhis study of the aims and rules of debating. Aristotle’s\nviewpoint survived into the common medieval name for logic:\ndialectics. In the mid twentieth century Charles Hamblin\nrevived the link between dialogue and the rules of sound reasoning,\nsoon after Paul Lorenzen had connected dialogue to constructive\nfoundations of logic.  \nThere are close links between games and teaching. Writers throughout\nthe medieval period talk of dialogues as a way of\n‘teaching’ or ‘testing’ the use of sound\nreasoning. We have at least two textbooks of logic from the early\nsixteenth century that present it as a game for an individual student,\nand Lewis Carroll’s The Game of Logic (1887) is another\nexample in the same genre. There are plenty of modern examples too,\nthough probably there has not been enough continuity to justify\ntalking of a tradition of teaching logic by games.  \nMathematical game theory was founded in the early twentieth century.\nAlthough no mathematical links with logic emerged until the 1950s, it\nis striking how many of the early pioneers of game theory are also\nknown for their contributions to logic: John Kemeny, J. C. C.\nMcKinsey, John von Neumann, Willard Quine, Julia Robinson, Ernst\nZermelo and others. In 1953 David Gale and Frank Stewart made fruitful\nconnections between set theory and games. Shortly afterwards Leon\nHenkin suggested a way of using games to give semantics for infinitary\nlanguages. \nThe first half of the twentieth century was an era of increasing\nrigour and professionalism in logic, and to most logicians of that\nperiod the use of games in logic would probably have seemed frivolous.\nThe intuitionist L. E. J. Brouwer expressed this attitude when he\naccused his opponents of causing mathematics ‘to degenerate into\na game’ (as David Hilbert quoted him in 1927, cited in van\nHeijenoort 1967). Hermann Weyl (cited in Mancosu 1998) used the notion\nof games to explain Hilbert’s metamathematics: mathematical\nproofs proceed like plays of a meaningless game, but we can stand\noutside the game and ask meaningful questions about it.\nWittgenstein’s language games provoked little response from the\nlogicians. But in the second half of the century the centre of gravity\nof logical research moved from foundations to techniques, and from\nabout 1960 games were used more and more often in logical papers. \nBy the beginning of the twenty-first century it had become widely\naccepted that games and logic go together. The result was a huge\nproliferation of new combinations of logic and games, particularly in\nareas where logic is applied. Many of these new developments sprang\noriginally from work in pure logic, though today they follow their own\nagendas. One such area is argumentation theory, where games form a\ntool for analysing the structure of debates.  \nBelow we will concentrate on those games that are most closely\nassociated with pure logic. \nFrom the point of view of game theory, the main games that logicians\nstudy are not at all typical. They normally involve just two players,\nthey often have infinite length, the only outcomes are winning and\nlosing, and no probabilities are attached to actions or outcomes. The\nbarest essentials of a logical game are as follows.  \nThere are two players. In general we can call them \\(\\forall\\) and\n\\(\\exists\\). The pronunciations ‘Abelard’ and\n‘Eloise’ go back to the mid 1980s and usefully fix the\nplayers as male and female making reference easier: her move, his\nmove. Other names are in common use for the players in particular\ntypes of logical game. \nThe players play by choosing elements of a set \\(\\Omega\\), called the\ndomain of the game. As they choose, they build up a\nsequence \nof elements of \\(\\Omega\\). Infinite sequences of elements of\n\\(\\Omega\\) are called plays. Finite sequences of elements of\n\\(\\Omega\\) are called positions; they record where a play\nmight have got to by a certain time. A function \\(\\tau\\) (the turn\nfunction or player function) takes each position\n\\(\\mathbf{a}\\) to either \\(\\exists\\) or \\(\\forall\\); if\n\\(\\tau(\\mathbf{a}) = \\exists\\), this means that when the game has\nreached \\(\\mathbf{a}\\), player \\(\\exists\\) makes the next choice (and\nlikewise with \\(\\forall)\\). The game rules define two sets\n\\(\\W_{\\forall}\\) and \\(\\W_{\\exists}\\) consisting of positions and\nplays, with the following properties: if a position \\(\\mathbf{a}\\) is\nin \\(\\W_{\\forall}\\) then so is any play or longer position that starts\nwith \\(\\mathbf{a}\\) (and likewise with \\(\\W_{\\exists})\\); and no play\nis in both \\(\\W_{\\forall}\\) and \\(\\W_{\\exists}\\). We say that player\n\\(\\forall\\) wins a play \\(\\mathbf{b}\\), and that\n\\(\\mathbf{b}\\) is a win for \\(\\forall\\), if \\(\\mathbf{b}\\) is\nin \\(\\W_{\\forall}\\); if some position \\(\\mathbf{a}\\) that is an\ninitial segment of \\(\\mathbf{b}\\) is in \\(\\W_{\\forall}\\), then we say\nthat player \\(\\forall\\) wins already at \\(\\mathbf{a}\\). (And\nlikewise with \\(\\exists\\) and \\(\\W_{\\exists}\\).) So to summarise, a\nlogical game is a 4-tuple \\((\\Omega , \\tau\\), \\(\\W_{\\forall}\\),\n\\(\\W_{\\exists})\\) with the properties just described. \nWe say that a logical game is total if every play is in\neither \\(\\W_{\\forall}\\) or \\(\\W_{\\exists}\\), so that there are no\ndraws. Unless one makes an explicit exception, logical games are\nalways assumed to be total. (Don’t confuse being total with the\nmuch stronger property of being determined—see below.) \nIt is only for mathematical convenience that the definition above\nexpects the game to continue to infinity even when a player has won at\nsome finite position; there is no interest in anything that happens\nafter a player has won. Many logical games have the property that in\nevery play, one of the players has already won at some finite\nposition; games of this sort are said to be well-founded. An\neven stronger condition is that there is some finite number \\(n\\) such\nthat in every play, one of the players has already won by the \\(n\\)-th\nposition; in this case we say that the game has finite\nlength. \nA strategy for a player is a set of rules that describe\nexactly how that player should choose, depending on how the two\nplayers have chosen at earlier moves. Mathematically, a strategy for\n\\(\\forall\\) consists of a function which takes each position\n\\(\\mathbf{a}\\) with \\(\\tau(\\mathbf{a}) = \\forall\\) to an element \\(b\\)\nof \\(\\Omega\\); we think of it as an instruction to \\(\\forall\\) to\nchoose \\(b\\) when the game has reached the position \\(\\mathbf{a}\\).\n(Likewise with a strategy for \\(\\exists\\).) A strategy for a player is\nsaid to be winning if that player wins every play in which he\nor she uses the strategy, regardless of what the other player does. At\nmost one of the players has a winning strategy (since otherwise the\nplayers could play their winning strategies against each other, and\nboth would win, contradicting that \\(\\W_{\\forall}\\) and\n\\(\\W_{\\exists}\\) have no plays in common). Occasionally one meets\nsituations in which it seems that two players have winning strategies\n(for example in the forcing games below), but closer inspection shows\nthat the two players are in fact playing different games. \nA game is said to be determined if one or other of the\nplayers has a winning strategy. There are many examples of games that\nare not determined, as Gale and Stewart showed in 1953 using the axiom\nof choice. This discovery led to important applications of the notion\nof determinacy in the foundations of set theory (see entry on\n large cardinals and determinacy).\n Gale and Stewart also proved an important theorem that bears their\nname: Every well-founded game is determined. It follows that every\ngame of finite length is determined—a fact already known to\nZermelo in 1913. (A more precise statement of the Gale-Stewart theorem\nis this. A game \\(G\\) is said to be closed if \\(\\exists\\)\nwins every play of \\(G\\) in which she hasn’t already lost at any\nfinite position. The theorem states that every closed game is\ndetermined. The proof of the theorem is basically easy: Let us call a\nposition winning for \\(\\forall\\) if he has a winning strategy starting\nfrom this position. Suppose \\(\\forall\\) does not have a winning\nstrategy in the game, that is, in the beginning the position is not\nwinning for \\(\\forall\\). If the first move is a move of \\(\\forall\\),\nafter his move the position is still not winning for him. If the first\nmove is a move of \\(\\exists\\), she must have a move after which the\nposition is still not winning for \\(\\forall\\), for otherwise the\nprevious position would have been winning for \\(\\forall\\). The game\ngoes on in this way infinitely many moves through positions which are\nnot winning for \\(\\forall\\). Because the game is closed, \\(\\exists\\)\nwins.) \nJust as in classical game theory, the definition of logical games\nabove serves as a clothes horse that we can hang other concepts onto.\nFor example it is common to have some laws that describe what elements\nof \\(\\Omega\\) are available for a player to choose at a particular\nmove. Strictly this refinement is unnecessary, because the winning\nstrategies are not affected if we decree instead that a player who\nbreaks the law loses immediately; but for many games this way of\nviewing them seems unnatural. Below we will see some other extra\nfeatures that can be added to games. \nThe definitions of game and strategy above were purely mathematical.\nSo they left out what is probably the single most important feature of\ngames, which is that people play them (at least metaphorically). The\nplayers aim to win, and by studying the strategies open to them we\nstudy what behaviour is rational for a person with a particular aim.\nIn most games there are several players, so we can study what is a\nrational response to somebody else’s behaviour. By restricting\nthe players’ moves and possible strategies, we can study bounded\nrationality, where an agent has to make rational decisions under\nconditions of limited information, memory or time.  \nIn short, games are used for modelling rationality and bounded\nrationality. This is independent of any connection with logic. But\nsome logics were designed for studying aspects of rational behaviour,\nand in recent years it has become increasingly common to link these\nlogics to suitable games. See Section 5 (‘Semantic games for\nother logics’) and its bibliography. \nBut until recently, logical games were connected with rational\nbehaviour in a quite different way. On the surface, the logic in\nquestion had no direct connection with behaviour. But logicians and\nmathematicians noticed that some ideas could be made more intuitive if\nthey were linked to possible aims. For example in many applications of\nlogical games, the central notion is that of a winning strategy for\nthe player \\(\\exists\\). Often these strategies (or their existence)\nturn out to be equivalent to something of logical importance that\ncould have been defined without using games—for example a proof.\nBut games are felt to give a better definition because they quite\nliterally supply some motivation: \\(\\exists\\) is trying to win. \nThis raises a question that is not of much interest mathematically,\nbut it should concern philosophers who use logical games. If we want\n\\(\\exists\\)’s motivation in a game \\(G\\) to have any explanatory\nvalue, then we need to understand what is achieved if \\(\\exists\\) does\nwin. In particular we should be able to tell a realistic story of a\nsituation in which some agent called \\(\\exists\\) is trying to do\nsomething intelligible, and doing it is the same thing as winning in\nthe game. As Richard Dawkins said, raising the corresponding question\nfor the evolutionary games of Maynard Smith, \nFor future reference let us call this the Dawkins question.\nIn many kinds of logical game it turns out to be distinctly harder to\nanswer than the pioneers of these games realised. (Marion 2009\ndiscusses the Dawkins question further.) \nIn the early 1930s Alfred Tarski proposed a definition of truth. His\ndefinition consisted of a necessary and sufficient condition for a\nsentence in the language of a typical formal theory to be true; his\nnecessary and sufficient condition used only notions from syntax and\nset theory, together with the primitive notions of the formal theory\nin question. In fact Tarski defined the more general relation\n‘formula \\(\\phi(x_1 ,\\ldots ,x_n)\\) is true of the elements\n\\(a_1 ,\\ldots ,a_n\\)’; truth of a sentence is the special case\nwhere \\(n = 0\\). For example the question whether  \n‘For all \\(x\\) there is \\(y\\) such that R\\((x, y)\\)’ is\ntrue \nreduces to the question whether the following holds: \nFor every object \\(a\\) the sentence ‘There is \\(y\\) such that\nR\\((a, y)\\)’ is true. \nThis in turn reduces to: \nFor every object \\(a\\) there is an object \\(b\\) such that the sentence\n‘R\\((a, b)\\)’ is true. \nIn this example, that’s as far as Tarski’s truth\ndefinition will take us. \nIn the late 1950s Leon Henkin noticed that we can intuitively\nunderstand some sentences which can’t be handled by\nTarski’s definition. Take for example the infinitely long\nsentence \nFor all \\(x_0\\) there is \\(y_0\\) such that for all \\(x_1\\) there is\n\\(y_1\\) such that … R\\((x_0, y_0, x_1, y_1,\\ldots)\\). \nTarski’s approach fails because the string of quantifiers at the\nbeginning is infinite, and we would never reach an end of stripping\nthem off. Instead, Henkin suggested, we should consider the game where\na person \\(\\forall\\) chooses an object \\(a_0\\) for \\(x_0\\), then a\nsecond person \\(\\exists\\) chooses an object \\(b_0\\) for \\(y_0\\), then\n\\(\\forall\\) chooses \\(a_1\\) for \\(x_1, \\exists\\) chooses \\(b_1\\) for\n\\(y_1\\) and so on. A play of this game is a win for \\(\\exists\\) if and\nonly if the infinite atomic sentence \nis true. The original sentence is true if and only if player\n\\(\\exists\\) has a winning strategy for this game. Strictly Henkin used\nthe game only as a metaphor, and the truth condition that he proposed\nwas that the skolemised version of the sentence is true, i.e. that\nthere are functions \\(f_0, f_1,\\ldots\\) such that for every choice of\n\\(a_0, a_1, a_2\\) etc. we have \nBut this condition translates immediately into the language of games;\nthe Skolem functions \\(f_0\\) etc. define a winning strategy for\n\\(\\exists\\), telling her how to choose in the light of earlier choices\nby \\(\\forall\\). (It came to light sometime later that C. S. Peirce had\nalready suggested explaining the difference between\n‘every’ and ‘some’ in terms of who chooses the\nobject; for example in his second Cambridge Conference lecture of\n1898.) \nSoon after Henkin’s work, Jaakko Hintikka added that the same\nidea applies with conjunctions and disjunctions. We can regard a\nconjunction ‘\\(\\phi \\wedge \\psi\\)’ as a universally\nquantified statement expressing ‘Every one of the sentences\n\\(\\phi , \\psi\\) holds’, so it should be for the player\n\\(\\forall\\) to choose one of the sentences. As Hintikka put it, to\nplay the game \\(G(\\phi \\wedge \\psi), \\forall\\) chooses whether the\ngame should proceed as \\(G(\\phi)\\) or as \\(G(\\psi)\\). Likewise\ndisjunctions become existentially quantified statements about sets of\nsentences, and they mark moves where the player \\(\\exists\\) chooses\nhow the game should proceed. To bring quantifiers into the same style,\nhe proposed that the game \\(G(\\forall x \\phi(x))\\) proceeds thus:\nplayer \\(\\forall\\) chooses an object and provides a name \\(a\\) for it,\nand the game proceeds as \\(G(\\phi(a))\\). (And likewise with\nexistential quantifiers, except that \\(\\exists\\) chooses.) Hintikka\nalso made an ingenious suggestion for introducing negation. Each game\nG has a dual game which is the same as G except that the\nplayers \\(\\forall\\) and \\(\\exists\\) are transposed in both the rules\nfor playing and the rules for winning. The game \\(G(\\neg \\phi)\\) is\nthe dual of \\(G(\\phi)\\). \nOne can prove that for any first-order sentence \\(\\phi\\), interpreted\nin a fixed structure \\(A\\), player \\(\\exists\\) has a winning strategy\nfor Hintikka’s game \\(G(\\phi)\\) if and only if \\(\\phi\\) is true\nin \\(A\\) in the sense of Tarski. Two features of this proof are\ninteresting. First, if \\(\\phi\\) is any first-order sentence then the\ngame \\(G(\\phi)\\) has finite length, and so the Gale-Stewart theorem\ntells us that it is determined. We infer that \\(\\exists\\) has a\nwinning strategy in exactly one of \\(G(\\phi)\\) and its dual; so she\nhas a winning strategy in \\(G(\\neg \\phi)\\) if and only if she\ndoesn’t have one in \\(G(\\phi)\\). This takes care of negation.\nAnd second, if \\(\\exists\\) has a winning strategy for each game\n\\(G(\\phi(a))\\), then after choosing one such strategy \\(f_a\\) for each\n\\(a\\), she can string them together into a single winning strategy for\n\\(G(\\forall x \\phi(x))\\) (namely, ‘Wait and see what element \\(a\n\\forall\\) chooses, then play \\(f_a\\)’). This takes care of the\nclause for universal quantifiers; but the argument uses the axiom of\nchoice, and in fact it is not hard to see that the statement that\nHintikka’s and Tarski’s definitions of truth are\nequivalent is itself equivalent to the axiom of choice (given the\nother axioms of Zermelo-Fraenkel set theory). \nIt’s puzzling that we have here two theories of when a sentence\nis true, and the theories are not equivalent if the axiom of choice\nfails. In fact the reason is not very deep. The axiom of choice is\nneeded not because the Hintikka definition uses games, but because it\nassumes that strategies are deterministic, i.e. that they are\nsingle-valued functions giving the user no choice of options. A more\nnatural way of translating the Tarski definition into game terms is to\nuse nondeterministic strategies, sometimes called quasistrategies (see\nKolaitis 1985 for details). (However, Hintikka 1996 insists that the\ncorrect explication of ‘true’ is the one using\ndeterministic strategies, and that this fact vindicates the axiom of\nchoice.) \nComputer implementations of these games of Hintikka proved to be a\nvery effective way of teaching the meanings of first-order sentences.\nOne such package was designed by Jon Barwise and John Etchemendy at\nStanford, called ‘Tarski’s World’. Independently\nanother team at the University of Omsk constructed a Russian version\nfor use at schools for gifted children. \nIn the published version of his John Locke lectures at Oxford,\nHintikka in 1973 raised the Dawkins question (see above) for these\ngames. His answer was that one should look to Wittgenstein’s\nlanguage games, and the language games for understanding quantifiers\nare those which revolve around seeking and finding. In the\ncorresponding logical games one should think of \\(\\exists\\) as Myself\nand \\(\\forall\\) as a hostile Nature who can never be relied on to\npresent the object I want; so to be sure of finding it, I need a\nwinning strategy. This story was never very convincing; the motivation\nof Nature is irrelevant, and nothing in the logical game corresponds\nto seeking. In retrospect it is a little disappointing that nobody\ntook the trouble to look for a better story. It may be more helpful to\nthink of a winning strategy for \\(\\exists\\) in \\(G(\\phi)\\) as a kind\nof proof (in a suitable infinitary system) that \\(\\phi\\) is true. \nLater Jaakko Hintikka extended the ideas of this section in two\ndirections, namely to natural language semantics and to games of\nimperfect information (see the next section). The name\nGame-Theoretic Semantics, GTS for short, has come to be used\nto cover both of these extensions. \nThe games described in this section adapt almost trivially to\nmany-sorted logic: for example the quantifier \\(\\forall x_{\\sigma}\\),\nwhere \\(x_{\\sigma}\\) is a variable of sort \\(\\sigma\\), is an\ninstruction for player \\(\\forall\\) to choose an element of sort\n\\(\\sigma\\). This immediately gives us the corresponding games for\nsecond-order logic, if we think of the elements of a structure as one\nsort, the sets of elements as a second sort, the binary relations as a\nthird and so on. It follows that we have, quite routinely, game rules\nfor most generalised quantifiers too; we can find them by first\ntranslating the generalised quantifiers into second-order logic. \nIn this and the next section we look at some adaptations of the\nsemantic games of the previous section to other logics. In our first\nexample, the logic (the independence-friendly logic of Hintikka and\nSandu 1997, or more briefly IF logic) was created in order to fit the\ngame. See the entry on\n independence friendly logic\n and Mann, Sandu and Sevenster 2011 for fuller accounts of this\nlogic. \nThe games here are the same as in the previous section, except that we\ndrop the assumption that each player knows the previous history of the\nplay. For example we can require a player to make a choice without\nknowing what choices the other player has made at certain earlier\nmoves. The classical way to handle this within game theory is to make\nrestrictions on the strategies of the players. For example we can\nrequire that the strategy function telling \\(\\exists\\) what to do at a\nparticular step is a function whose domain is the family of possible\nchoices of \\(\\forall\\) at just his first and second moves; this is a\nway of expressing that \\(\\exists\\) doesn’t know how \\(\\forall\\)\nchose at his third and later moves. Games with restrictions of this\nkind on the strategy functions are said to be of imperfect\ninformation, as opposed to the games of perfect\ninformation in the previous section. \nTo make a logic that fits these games, we use the same first-order\nlanguage as in the previous section, except that a notation is added\nto some quantifiers (and possibly also some connectives), to show that\nthe Skolem functions for these quantifiers (or connectives) are\nindependent of certain variables. For example the sentence  \nis read as: “For every \\(x\\) there is \\(y\\), not depending on\n\\(x\\), such that \\(R(x, y)\\)”. \nThere are three important comments to make on the distinction between\nperfect and imperfect information. The first is that the Gale-Stewart\ntheorem holds only for games of perfect information. Suppose for\nexample that \\(\\forall\\) and \\(\\exists\\) play the following game.\nFirst, \\(\\forall\\) chooses one of the numbers 0 and 1. Then\n\\(\\exists\\) chooses one of these two numbers. Player \\(\\exists\\) wins\nif the two numbers chosen are the same, and otherwise player\n\\(\\forall\\) wins. We require that \\(\\exists\\), when she makes her\nchoice, doesn’t know what \\(\\forall\\) chose; so a Skolem\nfunction for her will be a constant. (This game corresponds to the IF\nsentence above with \\(R\\) read as equality, in a structure with a\ndomain consisting of 0 and 1.) It’s clear that player\n\\(\\exists\\) doesn’t have a constant winning strategy, and also\nthat player \\(\\forall\\) doesn’t have a winning strategy at all.\nSo this game is undetermined, although its length is only 2. \nOne corollary is that Hintikka’s justification for reading\nnegation as dualising (‘players swap places’), in his\ngames for first-order logic, doesn’t carry over to IF logic.\nHintikka’s response has been that dualising was the correct\nintuitive meaning of negation even in the first-order case, so no\njustification is needed.  \nThe second comment is that already in games of perfect information, it\ncan happen that winning strategies don’t use all the available\ninformation. For example in a game of perfect information, if player\n\\(\\exists\\) has a winning strategy, then she also has a winning\nstrategy where the strategy functions depend only on the previous\nchoices of \\(\\forall\\). This is because she can reconstruct her own\nprevious moves using her earlier strategy functions. \nWhen Hintikka used Skolem functions as strategies in his games for\nfirst-order logic, he made the strategies for a player depend only on\nthe previous moves of the other player. (A Skolem function for\n\\(\\exists\\) depends only on universally quantified variables.) Because\nthe games were games of perfect information, there was no loss in\nthis, by the second comment above. But when he moved to IF logic, the\nrequirement that strategies depend only on moves of the other player\nreally did make a difference. Hodges 1997 showed this by revising the\nnotation, so that for example \\((\\exists y/x)\\) means: “There is\n\\(y\\) independent of \\(x\\), regardless of which player chose\n\\(x\\)”. \nConsider now the sentence  \nplayed again on a structure with two elements 0 and 1. Player\n\\(\\exists\\) can win as follows. For \\(z\\) she chooses the same as\nplayer \\(\\forall\\) chose for \\(x\\); then for \\(y\\) she chooses the\nsame as she chose for \\(z\\). This winning strategy works only because\nin this game \\(\\exists\\) can refer back to her own previous choices.\nShe would have no winning strategy if the third quantifier was\n\\((\\exists y/xz)\\), again because any Skolem function for this\nquantifier would have to be constant. The way that \\(\\exists\\) passes\ninformation to herself by referring to her previous choice is an\nexample of the phenomenon of signalling. John von Neumann and\nOskar Morgenstern illustrated it with the example of Bridge, where a\nsingle player consists of two partners who have to share information\nby using their public moves to signal to each other. \nThe third comment is that there is a dislocation between the intuitive\nidea of imperfect information and the game-theoretic definition of it\nin terms of strategies. Intuitively, imperfect information is a fact\nabout the circumstances in which the game is played, not about the\nstrategies. This is a very tricky matter, and it continues to lead to\nmisunderstandings about IF and similar logics. Take for example the\nsentence  \nagain played on a structure with elements 0 and 1. Intuitively one\nmight think that if \\(\\exists\\) isn’t allowed to remember at the\nsecond quantifier what she chose at the first, then she can hardly\nhave a winning strategy. But in fact she has a very easy one:\n‘Always choose 0’! \nCompared with first-order logic, IF logic is missing a component that\nthe game semantics won’t supply. The game semantics tells us\nwhen a sentence is true in a structure. But if we take a formula with\n\\(n\\) free variables, what does the formula express about the ordered\n\\(n\\)-tuples of elements of the structure? In first-order logic it\nwould define a set of them, i.e. an \\(n\\)-ary relation on the\nstructure; the Tarski truth definition explains how. Is there a\nsimilar definition for arbitrary formulas of IF logic? It turns out\nthat there is one for the slightly different logic introduced by\nHodges 1997, and it leads to a Tarski-style truth definition for the\nlanguage of that logic. With a little adjustment this truth definition\ncan be made to fit IF logic too. But for both of these new logics\nthere is a catch: instead of saying when an assignment of elements to\nfree variables makes a formula true, we say when a set of\nassignments of elements to free variables makes the formula true.\nVäänänen 2007 made this idea the basis for a range of\nnew logics for studying the notion of dependence (see entry on\n dependence logic).\n In these logics the semantics is defined without games, although the\noriginal inspiration comes from the work of Hintikka and Sandu.  \nIn Väänänen’s logics it is easy to see why one\nneeds sets of assignments. He has an atomic formula expressing\n‘\\(x\\) is dependent on \\(y\\)’. How can we interpret this\nin a structure, for example the structure of natural numbers? It makes\nno sense at all to ask for example whether 8 is dependent on 37. But\nif we have a set X of ordered pairs of natural numbers, it does make\nsense to ask whether in X the first member of each pair is dependent\non the second; the answer Yes would mean that there is a function\n\\(f\\) such that each pair \\((a,b)\\) in X has the form \\((f(b),b)\\).\n \nStructures of the following kind give rise to interesting games. The\nstructure \\(A\\) consists of a set \\(S\\) of elements (which we shall\ncall states, adding that they are often called\nworlds), a binary relation \\(R\\) on \\(S\\) (we shall read\n\\(R\\) as arrow), and a family \\(P_1 ,\\ldots ,P_n\\) of subsets\nof \\(S\\). The two players \\(\\forall\\) and \\(\\exists\\) play a game G on\n\\(A\\), starting at a state \\(s\\) which is given them, by reading a\nsuitable logical formula \\(\\phi\\) as a set of instructions for playing\nand for winning.  \nThus if \\(\\phi\\) is \\(P_i\\), then player \\(\\exists\\) wins at once if\n\\(s\\) is in \\(P_i\\), and otherwise player \\(\\forall\\) wins at once.\nThe formulas \\(\\psi \\wedge \\theta , \\psi \\vee \\theta\\) and \\(\\neg\n\\psi\\) behave as in Hintikka’s games above; for example \\(\\psi\n\\wedge \\theta\\) instructs player \\(\\forall\\) to choose whether the\ngame shall continue as for \\(\\psi\\) or for \\(\\theta\\). If the formula\n\\(\\phi\\) is \\(\\Box \\psi\\), then player \\(\\forall\\) chooses an arrow\nfrom \\(s\\) to a state \\(t\\) (i.e. a state \\(t\\) such that the pair\n\\((s, t)\\) is in the relation \\(R)\\), and the game then proceeds from\nthe state \\(t\\) according to the instructions \\(\\psi\\). The rule for\n\\(\\Diamond \\psi\\) is the same except that player \\(\\exists\\) makes the\nchoice. Finally we say that the formula \\(\\phi\\) is true at s in\nA if player \\(\\exists\\) has a winning strategy for this game\nbased on \\(\\phi\\) and starting at \\(s\\). \nThese games stand to modal logic in very much the same way as\nHintikka’s games stand to first-order logic. In particular they\nare one way of giving a semantics for modal logic, and they agree with\nthe usual Kripke-type semantics. Of course there are many types and\ngeneralisations of modal logic (including closely related logics such\nas temporal, epistemic and dynamic logics), and so the corresponding\ngames come in many different forms. One example of interest is the\ncomputer-theoretic logic of Matthew Hennessy and Robin Milner, used\nfor describing the behaviour of systems; here the arrows come in more\nthan one colour, and moving along an arrow of a particular colour\nrepresents performing a particular ‘action’ to change the\nstate. Another example is the more powerful modal \\(\\mu\\)-calculus of\nDexter Kozen, which has fixed point operators; see Chapter 5 of\nStirling 2001. \nOne interesting feature of these games is that if a player has a\nwinning strategy from some position onwards, then that strategy never\nneeds to refer to anything that happened earlier in the play.\nIt’s irrelevant what choices were made earlier, or even how many\nsteps have been played. So we have what the computer scientists\nsometimes call a ‘memoryless’ winning strategy.  \nIn the related ‘logic of games’, proposed by Rohit Parikh,\ngames that move us between the states are the subject matter rather\nthan a way of giving a truth definition. These games have many\ninteresting aspects. In 2003 the journal Studia Logica ran an\nissue devoted to them, edited by Marc Pauly and Parikh. \nInfluences from economics and computer science have led a number of\nlogicians to use logic for analysing decision making under conditions\nof partial ignorance. (See for example the article on\n epistemic logic.)\n There are several ways to represent states of knowledge. One is to\ntake them as states or worlds in the kind of modal structure that we\nmentioned at the beginning of this section. Another is to use IF logic\nor a variant of it. How are these approaches related? Johan van\nBenthem 2006 presents some thoughts and results on this very natural\nquestion. See also the papers by Johan van Benthem, Krister Segerberg,\nEric Pacuit and K. Venkatesh and their references, in Part IV\n‘Logic, Agency and Games’ of Van Benthem, Gupta and Parikh\n2011 and the entry on\n logics for analyzing games\n for a sample of recent work in this area. \nIn 1930 Alfred Tarski formulated the notion of two structures \\(A\\)\nand \\(B\\) being elementarily equivalent, i.e., that exactly\nthe same first-order sentences are true in \\(A\\) as are true in \\(B\\).\nAt a conference in Princeton in 1946 he described this notion and\nexpressed the hope that it would be possible to develop a theory of it\nthat would be ‘as deep as the notions of isomorphism, etc. now\nin use’ (Tarski 1946).  \nOne natural part of such a theory would be a purely structural\nnecessary and sufficient condition for two structures to be\nelementarily equivalent. Roland Fraïssé, a\nFrench-Algerian, was the first to find a usable necessary and\nsufficient condition. It was rediscovered a few years later by the\nKazakh logician A. D. Taimanov, and it was reformulated in terms of\ngames by the Polish logician Andrzej Ehrenfeucht. The games are now\nknown as Ehrenfeucht-Fraïssé games, or sometimes\nas back-and-forth games. They have turned out to be one of\nthe most versatile ideas in twentieth-century logic. They adapt\nfruitfully to a wide range of logics and structures. \nIn a back-and-forth game there are two structures \\(A\\) and \\(B\\), and\ntwo players who are commonly called Spoiler and Duplicator. (The names\nare due to Joel Spencer in the early 1990s. More recently Neil\nImmerman suggested Samson and Delilah, using the same initials; this\nplaces Spoiler as the male player \\(\\forall\\) and Duplicator as the\nfemale \\(\\exists\\).) Each step in the game consists of a move of\nSpoiler, followed by a move of Duplicator. Spoiler chooses an element\nof one of the two structures, and Duplicator must then choose an\nelement of the other structure. So after \\(n\\) steps, two sequences\nhave been chosen, one from \\(A\\) and one from \\(B\\): \nThis position is a win for Spoiler if and only if some atomic formula\n(of one of the forms ‘\\(\\R(v_0 ,\\ldots ,v_{k-1})\\)’ or\n‘\\(\\mathrm{F}(v_0 ,\\ldots ,v_{k-1}) = v_k\\)’ or\n‘\\(v_0 =v_1\\)’, or one of these with different variables)\nis satisfied by \\((a_0 ,\\ldots ,a_{n-1})\\) in \\(A\\) but not by \\((b_0\n,\\ldots ,b_{n-1})\\) in \\(B\\), or vice versa. The condition for\nDuplicator to win is different in different forms of the game. In the\nsimplest form, \\(\\EF(A, B)\\), a play is a win for Duplicator if and\nonly if no initial part of it is a win for Spoiler (i.e. she wins if\nshe hasn’t lost by any finite stage). For each natural number\n\\(m\\) there is a game \\(\\EF_m (A, B)\\); in this game Duplicator wins\nafter \\(m\\) steps provided she has not yet lost. All these games are\ndetermined, by the Gale-Stewart Theorem. The two structures \\(A\\) and\n\\(B\\) are said to be back-and-forth equivalent if Duplicator\nhas a winning strategy for \\(\\EF(A, B)\\), and m-equivalent if\nshe has a winning strategy for \\(\\EF_m (A, B)\\). \nOne can prove that if \\(A\\) and \\(B\\) are \\(m\\)-equivalent for every\nnatural number \\(m\\), then they are elementarily equivalent. In fact,\nif Eloise has a winning strategy \\(\\tau\\) in the Hintikka game\nG\\((\\phi)\\) on \\(A\\), where the nesting of quantifier scopes of\n\\(\\phi\\) has at most m levels and Duplicator has a winning strategy\n\\(\\varrho\\) in the game \\(\\EF_m (A, B)\\), the two strategies \\(\\tau\\)\nand \\(\\varrho\\) can be composed into a winning strategy of Eloise in\nG\\((\\phi)\\) on \\(B\\). On the other hand a winning strategy for Spoiler\nin \\(\\EF_m (A, B)\\) can be converted into a first-order sentence that\nis true in exactly one of \\(A\\) and \\(B\\), and in which the nesting of\nquantifier scopes has at most \\(m\\) levels. So we have our necessary\nand sufficient condition for elementary equivalence, and a bit more\nbesides. \nIf \\(A\\) and \\(B\\) are back-and-forth equivalent, then certainly they\nare elementarily equivalent; but in fact back-and-forth equivalence\nturns out to be the same as elementary equivalence in an\n infinitary logic\n which is much more expressive than first-order logic. There are many\nadjustments of the game that give other kinds of equivalence. For\nexample Barwise, Immerman and Bruno Poizat independently described a\ngame in which the two players have exactly \\(p\\) numbered pebbles\neach; each player has to label his or her choices with a pebble, and\nthe two choices in the same step must be labelled with pebbles\ncarrying the same number. As the game proceeds, the players will run\nout of pebbles and so they will have to re-use pebbles that were\nalready used. The condition for Spoiler to win at a position (and all\nsubsequent positions) is the same as before, except that only the\nelements carrying labels at that position count. The existence of a\nwinning strategy for Duplicator in this game means that the two\nstructures agree for sentences which use at most \\(p\\) variables\n(allowing these variables to occur any number of times). \nThe theory behind back-and-forth games uses very few assumptions about\nthe logic in question. As a result, these games are one of the few\nmodel-theoretic techniques that apply as well to finite structures as\nthey do to infinite ones, and this makes them one of the cornerstones\nof theoretical computer science. One can use them to measure the\nexpressive strength of formal languages, for example database query\nlanguages. A typical result might say, for example, that a certain\nlanguage can’t distinguish between ‘even’ and\n‘odd’; we would prove this by finding, for each level\n\\(n\\) of complexity of formulas of the language, a pair of finite\nstructures for which Duplicator has a winning strategy in the\nback-and-forth game of level \\(n\\), but one of the structures has an\neven number of elements and the other has an odd number. Semanticists\nof natural languages have found back-and-forth games useful for\ncomparing the expressive powers of\n generalised quantifiers.\n (See for example Peters and Westerståhl 2006 Section IV.) \nThere is also a kind of back-and-forth game that corresponds to our\nmodal semantics above in the same way as\nEhrenfeucht-Fraïssé games correspond to Hintikka’s\ngame semantics for first-order logic. The players start with a state\n\\(s\\) in the structure \\(A\\) and a state \\(t\\) in the structure \\(B\\).\nSpoiler and Duplicator move alternately, as before. Each time he\nmoves, Spoiler chooses whether to move in \\(A\\) or in \\(B\\), and then\nDuplicator must move in the other structure. A move is always made by\ngoing forwards along an arrow from the current state. If between them\nthe two players have just moved to a state \\(s\\)´ in \\(A\\) and a\nstate \\(t\\)´ in \\(B\\), and some predicate \\(P_i\\) holds at just\none of \\(s\\)´ and \\(t\\)´, then Duplicator loses at once.\nAlso she loses if there are no available arrows for her to move along;\nbut if Spoiler finds there are no available arrows for him to move\nalong in either structure, then Duplicator wins. If the two players\nplay this game with given starting states \\(s\\) in \\(A\\) and \\(t\\) in\n\\(B\\), and both structures have just finitely many states, then one\ncan show that Duplicator has a winning strategy if and only if the\nsame modal sentences are true at \\(s\\) in \\(A\\) as are true at \\(t\\)\nin \\(B\\). \nThere are many generalisations of this result, some of them involving\nthe following notion. Let \\(Z\\) be a binary relation which relates\nstates of \\(A\\) to states of \\(B\\). Then we call \\(Z\\) a\nbisimulation between \\(A\\) and \\(B\\) if Duplicator can use\n\\(Z\\) as a nondeterministic winning strategy in the back-and-forth\ngame between \\(A\\) and \\(B\\) where the first pair of moves of the two\nplayers is to choose their starting states. In computer science the\nnotion of a bisimulation is crucial for the understanding of \\(A\\) and\n\\(B\\) as systems; it expresses that the two systems interact with\ntheir environment in the same way as each other, step for step. But a\nlittle before the computer scientists introduced the notion,\nessentially the same concept appeared in Johan van Benthem’s PhD\nthesis on the semantics of modal logic (1976). \nThe logical games in this section are mathematicians’ tools, but\nthey have some conceptually interesting features.  \nForcing games are also known to descriptive set theorists as\nBanach-Mazur games; see the references by Kechris or Oxtoby\nbelow for more details of the mathematical background. Model theorists\nuse them as a way of building infinite structures with controlled\nproperties. In the simplest case \\(\\forall\\) and \\(\\exists\\) play a\nso-called Model Existence Game, where \\(\\exists\\) claims that a fixed\nsentence \\(\\phi\\) has a model while \\(\\forall\\) claims that he can\nderive a contradiction from \\(\\phi\\). In the beginning a countably\ninfinite set \\(C\\) of new constant symbols \\(a_0, a_1, a_2\\) etc is\nfixed. \\(\\exists\\) defends a disjunction by choosing one disjunct, and\nan existential statement by choosing a constant from \\(C\\) as a\nwitness. \\(\\forall\\) can challenge a conjunction by choosing either\nconjunct, and a universal statement by choosing an arbitrary witness\nfrom \\(C\\). \\(\\exists\\) wins if no contradicting atomic sentences are\nplayed. \\(\\exists\\) has a winning strategy (a Consistency Property is\none way of describing a winning strategy) if and only if \\(\\phi\\) has\na model. On the other hand, if \\(\\forall\\) has a winning strategy, the\ntree (which can be made finite) of all plays against his winning\nstrategy is related to a Gentzen style proof of the negation of\n\\(\\phi\\). This method of analysing sentences is closely related to\nBeth’s method of semantic tableaux and the Dialogical Game (see\nSection 8). \nTo sketch the idea of the general Forcing Game, imagine that a\ncountably infinite team of builders are building a house \\(A\\). Each\nbuilder has his or her own task to carry out: for example to install a\nbath or to wallpaper the entrance hall. Each builder has infinitely\nmany chances to enter the site and add some finite amount of material\nto the house; these slots for the builders are interleaved so that the\nwhole process takes place in a sequence of steps counted by the\nnatural numbers.  \nTo show that the house can be built to order, we need to show that\neach builder separately can carry out his or her appointed task,\nregardless of what the other builders do. So we imagine each builder\nas player \\(\\exists\\) in a game where all the other players are lumped\ntogether as \\(\\forall\\), and we aim to prove that \\(\\exists\\) has a\nwinning strategy for this game. When we have proved this for each\nbuilder separately, we can imagine them going to work, each with their\nown winning strategy. They all win their respective games and the\nresult is one beautiful house. \nMore technically, the elements of the structure \\(A\\) are fixed in\nadvance, say as \\(a_0, a_1, a_2\\) etc., but the properties of these\nelements have to be settled by the play. Each player moves by throwing\nin a set of atomic or negated atomic statements about the elements,\nsubject only to the condition that the set consisting of all the\nstatements thrown in so far must be consistent with a fixed set of\naxioms written down before the game. (So throwing in a negated atomic\nsentence \\(\\neg \\phi\\) has the effect of preventing any player from\nadding \\(\\phi\\) at a later stage.) At the end of the joint play, the\nset of atomic sentences thrown in has a canonical model, and this is\nthe structure \\(A\\); there are ways of ensuring that it is a model of\nthe fixed set of axioms. A possible property P of \\(A\\) is said to be\nenforceable if a builder who is given the task of making P\ntrue of \\(A\\) has a winning strategy. A central point (due essentially\nto Ehrenfeucht) is that the conjunction of a countably infinite set of\nenforceable properties is again enforceable. \nVarious Löwenheim-Skolem Theorems of model theory can be proved\nusing variants of the Forcing Game. In these variants we do not\nconstruct a model but a submodel of a given model. We start with a big\nmodel \\(M\\) for a sentence (or a countable set of sentences) \\(\\phi\\).\nThen we list the subformulas of \\(\\phi\\) and each player has a\nsubformula with a free variable to attend to. The player’s task\nis to make sure that as soon as the parameters of the subformula occur\nin the game, and there is a witness to the truth of the formula in the\nbig model, one such a witness is played. When the game is over, a\ncountable submodel of \\(M\\) has been built in such a way that it\nsatisfies \\(\\phi\\). \nThe name ‘forcing’ comes from an application of related\nideas by Paul Cohen to construct models of set theory in the early\n1960s. Abraham Robinson adapted it to make a general method for\nbuilding countable structures, and Martin Ziegler introduced the game\nsetting. Later Robin Hirsch and Ian Hodkinson used related games to\nsettle some old questions about relation algebras. \nForcing games are a healthy example to bear in mind when thinking\nabout the Dawkins question. They remind us that in logical games it\nneed not be helpful to think of the players as opposing each\nother. \nIn the traditional cut-and-choose game you take a piece of cake and\ncut it into two smaller pieces; then I choose one of the pieces and\neat it, leaving the other one for you. This procedure is supposed to\nput pressure on you to cut the cake fairly. Mathematicians, not quite\nunderstanding the purpose of the exercise, insist on iterating it.\nThus I make you cut the piece I chose into two, then I choose one of\nthose two; then you cut this piece again, and so on indefinitely. Some\neven more unworldly mathematicians make you cut the cake into\ncountably many pieces instead of two.  \nThese games are important in the theory of definitions. Suppose we\nhave a collection \\(A\\) of objects and a family \\(S\\) of properties;\neach property cuts \\(A\\) into the set of those objects that have the\nproperty and the set of those that don’t. Let \\(\\exists\\) cut,\nstarting with the whole set \\(A\\) and using a property in \\(S\\) as a\nknife; let \\(\\forall\\) choose one of the pieces (which are subsets of\n\\(A)\\) and give it back to \\(\\exists\\) to cut again, once more using a\nproperty in \\(S\\); and so on. Let \\(\\exists\\) lose as soon as\n\\(\\forall\\) chooses an empty piece. We say that \\((A, S)\\) has\nrank at most \\(m\\) if \\(\\forall\\) has a strategy which\nensures that \\(\\exists\\) will lose before her \\(m\\)-th move. The rank\nof \\((A, S)\\) gives valuable information about the family of subsets\nof \\(A\\) definable by properties in \\(S\\). \nVariations of this game, allowing a piece to be cut into infinitely\nmany smaller pieces, are fundamental in the branch of model theory\ncalled stability theory. Broadly speaking, a theory is\n‘good’ in the sense of stability theory if, whenever we\ntake a model \\(A\\) of the theory and \\(S\\) the set of first-order\nformulas in one free variable with parameters from \\(A\\), the\nstructure \\((A, S)\\) has ‘small’ rank. A different\nvariation is to require that at each step, \\(\\exists\\) divides into\ntwo each of the pieces that have survived from earlier steps, and\nagain she loses as soon as one of the cut fragments is empty. (In this\nversion \\(\\forall\\) is redundant.) With this variation, the rank of\n\\((A\\),S) is called its Vapnik-Chervonenkis dimension; this\nnotion is used in computational learning theory. \nImagine a tree that has been built up in levels. At the bottom level\nthere is a single root node, but a left branch and a right branch come\nup from it. At the next level up there are two nodes, one on each\nbranch, and from each of these nodes a left branch and a right branch\ngrow up. So on the next level up there are four nodes, and again the\ntree branches into left and right at each of these nodes. Continued to\ninfinity, this tree is called the tree of two successor\nfunctions (namely left successor and right successor). Taking the\nnodes as elements and introducing two function symbols for left and\nright successor, we have a structure. A powerful theorem of Michael\nRabin states that there is an algorithm which will tell us, for every\nmonadic second-order sentence \\(\\phi\\) in the language appropriate for\nthis structure, whether or not \\(\\phi\\) is true in the structure.\n(’Monadic second-order’ means that the logic is like\nfirst-order, except that we can also quantify over sets of\nelements—but not over binary relations on elements, for\nexample.) \nRabin’s theorem has any number of useful consequences. For\nexample Dov Gabbay used it to prove the decidability of some modal\nlogics. But Rabin’s proof, using automata, was notoriously\ndifficult to follow. Yuri Gurevich and Leo Harrington, and\nindependently Andrei Muchnik, found much simpler proofs in which the\nautomaton is a player in a game. \nThis result of Rabin is one of several influential resuls that connect\ngames with automata. Another example is the parity games\nwhich are used for verifying properties of modal systems. See for\nexample Stirling (2001) Chapter 6; Bradfield and Stirling (2006)\ndiscuss parity games for the modal \\(\\mu\\)-calculus.  \nSeveral medieval texts describe a form of debate called\nobligationes. There were two disputants, Opponens and\nRespondens. At the beginning of a session, the disputants would agree\non a ‘positum’, typically a false statement. The job of\nRespondens was to give rational answers to questions from Opponens,\nassuming the truth of the positum; above all he had to avoid\ncontradicting himself unnecessarily. The job of Opponens was to try to\nforce Respondens into contradictions. So we broadly know the answer to\nthe Dawkins question, but we don’t know the game rules! The\nmedieval textbooks do describe several rules that the disputants\nshould follow. But these rules are not stipulated rules of the game;\nthey are guidelines which the textbooks derive from principles of\nsound reasoning with the aid of examples. (Paul of Venice justifies\none rule by the practice of ‘great logicians, philosophers,\ngeometers and theologians’.) In particular it was open to a\nteacher of obligationes to discover new rules. This open-endedness\nimplies that obligationes are not logical games in our sense. \nNot everybody agrees with the previous sentence. For example Catarina\nDutilh Novaes (2007, 6) makes a detailed defence of the view that\nobligationes present “a remarkable case of conceptual similarity\nbetween a medieval and a modern theoretical framework”. But\nwhatever view we take on this question, these debates have inspired\none important line of modern research in logical games. \nImagine \\(\\exists\\) taking an oral examination in proof theory. The\nexaminer gives her a sentence and invites her to start proving it. If\nthe sentence has the form \nthen she is entitled to choose one of the sentences and say ‘OK,\nI’ll prove this one’. (In fact if the examiner is an\nintuitionist, he may insist that she choose one of the sentences to\nprove.) On the other hand if the sentence is \nthen the examiner, being an examiner, might well choose one of the\nconjuncts himself and invite her to prove that one. If she knows how\nto prove the conjunction then she certainly knows how to prove the\nconjunct. \nThe case of \\(\\phi \\rightarrow \\psi\\) is a little subtler. She will\nprobably want to start by assuming \\(\\phi\\) in order to deduce\n\\(\\psi\\); but there is some risk of confusion because the sentences\nthat she has written down so far are all of them things to be proved,\nand \\(\\phi\\) is not a thing to be proved. The examiner can help her by\nsaying ‘I’ll assume \\(\\phi\\), and let’s see if you\ncan get to \\(\\psi\\) from there’. At this point there is a chance\nthat she sees a way of getting to \\(\\psi\\) by deducing a contradiction\nfrom \\(\\phi\\); so she may turn the tables on the examiner and invite\nhim to show that his assumption is consistent, with a view to proving\nthat it isn’t. The symmetry is not perfect: he was asking her to\nshow that a sentence is true everywhere, while she is inviting him to\nshow that a sentence is true somewhere. Nevertheless we can see a sort\nof duality. \nIdeas of this kind lie behind the dialectical games of Paul Lorenzen.\nHe showed that with a certain amount of pushing and shoving, one can\nwrite rules for the game which have the property that \\(\\exists\\) has\na winning strategy if and only if the sentence that she is presented\nwith at the beginning is a theorem of intuitionistic logic. In a\ngesture towards medieval debates, he called \\(\\exists\\) the Proponent\nand the other player the Opponent. Almost as in the medieval\nobligationes, the Opponent wins by driving the Proponent to a point\nwhere the only moves available to her are blatant\nself-contradictions. \nLorenzen claimed that his games provided justifications for both\nintuitionist and classical logic (or in his words, made them\n‘gerechtfertigt’, Lorenzen (1961,196)). Unfortunately any\n‘justification’ involves a convincing answer to the\nDawkins question, and this Lorenzen never provided. For example he\nspoke of moves as ‘attacks’, even when (like the\nexaminer’s choice at \\(\\phi \\wedge \\psi\\) above) they look more\nlike help than hostility.  \nThe entry\n dialogical logic\n gives a fuller account of Lorenzen’s games and a number of more\nrecent variants. In its present form (January 2013) it sidesteps\nLorenzen’s claims about justifying logics. Instead it describes\nthe games as providing semantics for the logics (a point that Lorenzen\nwould surely have agreed with), and adds that for understanding the\ndifferences between logics it can be helpful to compare their\nsemantics.  \nFrom this point of view, Lorenzen’s games stand as an important\nparadigm of what recent proof theorists have called semantics of\nproofs. A semantics of proofs gives a ‘meaning’ not\njust to the notion of being provable, but to each separate step in a\nproof. It answers the question ‘What do we achieve by making\nthis particular move in the proof?’ During the 1990s a number of\nworkers at the logical end of computer science looked for games that\nwould stand to\n linear logic\n and some other proof systems in the same way as Lorenzen’s\ngames stood to intuitionist logic. Andreas Blass, and then later\nSamson Abramsky and colleagues, gave games that corresponded to parts\nof linear logic, but at the time of writing we don’t yet have a\nperfect correspondence between game and logic. This example is\nparticularly interesting because the answer to the Dawkins question\nshould give an intuitive interpretation of the laws of linear logic, a\nthing that this logic has badly needed. The games of Abramsky et al.\ntell a story about two interacting systems. But while he began with\ngames in which the players politely take turns, Abramsky later allowed\nthe players to act ‘in a distributed, asynchronous\nfashion’, taking notice of each other only when they choose to.\nThese games are no longer in the normal format of logical games, and\ntheir real-life interpretation raises a host of new questions. \nGiorgi Japaridze has proposed a ‘computability logic’ for\nstudying computation. Its syntax is first-order logic with some extra\nitems reminiscent of linear logic. Its semantics is in terms of\nsemantic games with some unusual features. For example it is not\nalways determined which player makes the next move. The notion of\nstrategy functions is no longer adequate for describing the players;\ninstead Japaridze describes ways of reading the second player (player\n\\(\\exists\\) in our notation) as a kind of computing machine. Further\ninformation is on his website. \nAnother group of games of the same general family as Lorenzen’s\nare the proof games of Pavel Pudlak 2000. Here the Opponent (called\nProver) is in the role of an attorney in a court of law, who knows\nthat the Proponent (called Adversary) is guilty of some offence.\nProponent will insist he is innocent, and is prepared to tell lies to\ndefend himself. Opponent’s aim is to force Proponent to\ncontradict something that Proponent is on record as having said\nearlier; but Opponent keeps the record and (as in the pebble games\nabove) he sometimes has to drop items from the record for lack of\nspace or memory. The important question is not whether Opponent has a\nwinning strategy (it’s assumed from the outset that he has one),\nbut how much memory he needs for his record. These games are a useful\ndevice for showing upper and lower bounds on the lengths of proofs in\nvarious proof systems. \nAnother kind of logical game that allows lies is Ulam’s Game\nwith Lies. Here one player thinks of a number in some given range. The\nsecond player’s aim is to find out what that number is, by\nasking the first player yes/no questions; but the first player is\nallowed to tell some fixed number of lies in his answers. As in\nPudlak’s games, there is certainly a winning strategy for the\nsecond player, but the question is how hard this player has to work in\norder to win. The measure this time is not space or memory but time:\nhow many questions does he have to ask? Cignoli et al. 2000 Chapter 5\nrelate this game to many-valued logic. \nTo return for a moment to Lorenzen: he failed to distinguish between\ndifferent stances that a person might take in an argument: stating,\nassuming, conceding, querying, attacking, committing oneself. Whether\nit is really possible to define all these notions without presupposing\nsome logic is a moot point. But never mind that; a refinement of\nLorenzen’s games along these lines could serve as an approach to\ninformal logic, and especially to the research that aims to\nsystematise the possible structures of sound informal argument. On\nthis front see Walton and Krabbe 1995. The papers in Bench-Capon and\nDunne 2007 are also relevant. ","contact.mail":"jouko.vaananen@helsinki.fi","contact.domain":"helsinki.fi"}]
