[{"date.published":"2011-06-22","date.changed":"2020-04-20","url":"https://plato.stanford.edu/entries/logic-justification/","author1":"Sergei Artemov","author1.info":"http://web.cs.gc.cuny.edu/~sartemov/","author2.info":"http://comet.lehman.cuny.edu/fitting","entry":"logic-justification","body.text":"\n\n\n\nYou may say, “I know that Abraham Lincoln was a tall man. \n” In turn you may be asked how you know. You would almost \ncertainly not reply semantically, Hintikka-style, that Abraham \nLincoln was tall in all situations compatible with your knowledge. \nInstead you would more likely say, “I read about Abraham \nLincoln’s height in several books, and I have seen photographs of him\nnext to other people. ” One certifies knowledge by providing a \nreason, a justification. Hintikka semantics captures knowledge as \ntrue belief. Justification logics supply the missing third component \nof Plato’s characterization of knowledge as justified true \nbelief.\n\n\n\nJustification logics are epistemic logics which allow knowledge and \nbelief modalities to be ‘unfolded’ into justification\nterms: instead of \\(\\Box X\\) one writes \n\\(t : X\\), and reads it as “\\(X\\) is justified\nby reason \\(t\\)”. One may think of traditional modal \noperators as implicit modalities, and justification terms as\ntheir explicit elaborations which supplement modal logics \nwith finer-grained epistemic machinery. The family of justification \nterms has structure and operations. Choice of operations gives rise \nto different justification logics. For all common epistemic logics \ntheir modalities can be completely unfolded into explicit \njustification form. In this respect Justification Logic reveals and \nuses the explicit, but hidden, content of traditional Epistemic Modal\nLogic. \n\nJustification logic originated as part of a successful project to \nprovide a constructive semantics for intuitionistic \nlogic—justification terms abstracted away all but the most \nbasic features of mathematical proofs. Proofs are justifications in \nperhaps their purest form. Subsequently justification logics were \nintroduced into formal epistemology.\nThis article presents the general range of justification logics as \ncurrently understood. It discusses their relationships with \nconventional modal logics. In addition to technical machinery, the \narticle examines in what way the use of explicit justification terms \nsheds light on a number of traditional philosophical problems. The \nsubject as a whole is still under active development. \n\nThe roots of justification logic can be traced back to many different\nsources, two of which are discussed in detail: epistemology and \nmathematical logic. \n\nThe properties of knowledge and belief have been a subject for formal\nlogic at least since von Wright and Hintikka, (Hintikka 1962, von \nWright 1951). Knowledge and belief are both treated as modalities in \na way that is now very familiar—Epistemic Logic. But \nof Plato’s three criteria for knowledge, justified, true, \nbelief, (Gettier 1963, Hendricks 2005), epistemic logic really \nworks with only two of them. Possible worlds and indistinguishability\nmodel belief—one believes what is so under all circumstances \nthought possible. Factivity brings a trueness component into \nplay—if something is not so in the actual world it cannot be \nknown, only believed. But there is no representation for the \njustification condition. Nonetheless, the modal approach has been \nremarkably successful in permitting the development of a rich \nmathematical theory and applications, (Fagin, Halpern, Moses, and \nVardi 1995, van Ditmarsch, van der Hoek, and Kooi 2007). Still, it is\nnot the whole picture. \n\nThe modal approach to the logic of knowledge is, in a sense, built \naround the universal quantifier: \\(X\\) is known in a situation \nif \\(X\\) is true in all situations indistinguishable \nfrom that one. Justifications, on the other hand, bring an \nexistential quantifier into the picture: \\(X\\) is known in a \nsituation if there exists a justification for \\(X\\) in \nthat situation. This universal/existential dichotomy is a familiar \none to logicians—in formal logics there exists a proof for a \nformula \\(X\\) if and only if \\(X\\) is true in all models \nfor the logic. One thinks of models as inherently non-constructive, \nand proofs as constructive things. One will not go far wrong in \nthinking of justifications in general as much like mathematical \nproofs. Indeed, the first justification logic was explicitly designed\nto capture mathematical proofs in arithmetic, something which will be\ndiscussed further in Section 1.2. \n\nIn Justification Logic, in addition to the category of formulas, \nthere is a second category of justifications. Justifications\nare formal terms, built up from constants and variables using various\noperation symbols. Constants represent justifications for commonly \naccepted truths—typically axioms. Variables denote unspecified \njustifications. Different justification logics differ on which \noperations are allowed (and also in other ways too). If \\(t\\) is\na justification term and \\(X\\) is a formula, \n\\(t : X\\) is a formula, and is intended to be read: \n  \\(t\\) is a justification for X.\n \n\nOne operation, common to all justification logics, is \napplication, written like multiplication. The idea is, if \n\\(s\\) is a justification for \\(A \\rightarrow B\\) and \n\\(t\\) is a justification for \\(A\\), then \n[\\(s\\cdot t\\)] is a justification for \n \\(B\\)[1].\n That is, the validity of the following is generally assumed: \n\nThis is the explicit version of the usual distributivity of knowledge\noperators, and modal operators generally, across implication: \n\nIn fact, formula (2) is behind many of the problems of logical \nomniscience. It asserts that an agent knows everything that is \nimplied by the agent’s knowledge—knowledge is closed under \nconsequence. While knowable-in-principle, knowability, is closed \nunder consequence, the same cannot be said for any plausible version \nof actual knowledge. The distinction between (1) and (2) can be \nexploited in a discussion of the paradigmatic Red Barn Example of \nGoldman and Kripke; here is a simplified version of the story taken \nfrom (Dretske 2005). \n\nIn the first formalization of the Red Barn Example, logical \nderivation will be performed in a basic modal logic in which \\(\\Box\\)  \nis interpreted as the ‘belief’ modality. Then some of the\noccurrences of \\(\\Box\\)  will be externally interpreted as \n‘knowledge’ according to the problem’s description. Let \n\\(B\\) be the sentence ‘the object in front of me is a \nbarn’, and let \\(R\\) be the sentence ‘the object in \nfront of me is red’. \n\nAt the metalevel, 2 is actually knowledge, whereas by the problem \ndescription, 1 is not knowledge. \n\nWithin this formalization, it appears that epistemic closure in its\nmodal form (2) is violated: line 2, \\(\\Box ( B \\wedge R )\\), and line\n3, \\(\\Box ( B \\wedge R \\rightarrow B)\\) are cases of knowledge whereas\n\\(\\Box B\\) (line 1) is not knowledge. The modal language here does not\nseem to help resolving this issue. \n\nNext consider the Red Barn Example in Justification Logic where \n\\(t : F\\) is interpreted as ‘I \nbelieve \\(F\\) for reason \\(t\\)’. Let \\(u\\) be a\nspecific individual justification for belief that \\(B\\), and \\(v\\),\nfor belief that \\(B \\wedge R\\). In addition, let \\(a\\) be a\njustification for the logical truth \\(B \\wedge R \\rightarrow B\\). Then\nthe list of assumptions is: \n\nOn the metalevel, the problem description states that 2 and 3 are \ncases of knowledge, and not merely belief, whereas 1 is belief which \nis not knowledge. Here is how the formal reasoning goes: \n\nNotice that conclusion 6 is [\\(a\\cdot v ]: B\\), \nand not \\(u : B\\) ; epistemic closure holds. By reasoning\nin justification logic it was concluded that \n[\\(a\\cdot v ]: B\\) is a case of knowledge, i.e.,\n‘I know \\(B\\) for reason \n\\(a\\cdot v\\)’. The fact that \n\\(u : B\\) is not a case of knowledge does not spoil the \nclosure principle, since the latter claims knowledge specifically for\n[\\(a\\cdot v ]: B\\). Hence after observing a red \nfaçade, I indeed know \\(B\\), but this knowledge has \nnothing to do with 1, which remains a case of belief rather than of \nknowledge. The justification logic formalization represents the \nsituation fairly. \n\nTracking justifications represents the structure of the Red Barn \nExample in a way that is not captured by traditional epistemic modal \ntools. The Justification Logic formalization models what seems to be \nhappening in such a case; closure of knowledge under logical \nentailment is maintained even though ‘barn’ is not \nperceptually \n known.[2] \n\nAccording to Brouwer, truth in constructive (intuitionistic) \nmathematics means the existence of a proof, cf. (Troelstra and van \nDalen 1988). In 1931–34, Heyting and Kolmogorov gave an \ninformal description of the intended proof-based semantics for \nintuitionistic logic (Kolmogorov 1932, Heyting 1934), which is now \nreferred to as the Brouwer-Heyting-Kolmogorov (BHK) \nsemantics. According to the BHK conditions, a formula is \n‘true’ if it has a proof. Furthermore, a proof of a \ncompound statement is connected to proofs of its components in the \nfollowing way: \n\nKolmogorov explicitly suggested that the proof-like objects in his \ninterpretation (“problem solutions”) came from classical \nmathematics (Kolmogorov 1932). Indeed, from a foundational point of \nview it does not make much sense to understand the \n‘proofs’ above as proofs in an intuitionistic system \nwhich these conditions are supposed to be specifying. \n\nThe fundamental value of the BHK semantics is that informally but \nunambiguously it suggests treating justifications, here mathematical \nproofs, as objects with operations. \n\nIn (Gödel 1933), Gödel took the first step towards \ndeveloping a rigorous proof-based semantics for intuitionism. \nGödel considered the classical modal logic\n \\(\\mathsf{S4}\\)\n to be a calculus describing \nproperties of provability: \n\nBased on Brouwer’s understanding of logical truth as provability, \nGödel defined a translation tr\\((F)\\) of the propositional \nformula \\(F\\) in the intuitionistic language into the language \nof classical modal logic: tr\\((F)\\) is obtained by prefixing \nevery subformula of \\(F\\) with the provability modality \\(\\Box\\).\nInformally speaking, when the usual procedure of determining \nclassical truth of a formula is applied to tr\\((F)\\), it will \ntest the provability (not the truth) of each of \\(F\\)’s \nsubformulas, in agreement with Brouwer’s ideas. From Gödel’s \nresults and the McKinsey-Tarski work on topological semantics for \nmodal logic, it follows that the translation tr\\((F)\\) provides \na proper embedding of the Intuitionistic Propositional Calculus, \n\\(\\mathsf{IPC}\\), into\n \\(\\mathsf{S4}\\), i.e., an embedding of \nintuitionistic logic into classical logic extended by the provability\noperator. \n\nStill, Gödel’s original goal of defining intuitionistic\nlogic in terms of classical provability was not reached, since the\nconnection of \\(\\mathsf{S4}\\) to the usual mathematical notion of\nprovability was not established. Moreover, Gödel noted that the\nstraightforward idea of interpreting modality \\(\\Box F\\) as F is\nprovable in a given formal system T contradicted\nGödel’s second incompleteness theorem. Indeed, \\(\\Box (\n\\Box F \\rightarrow F)\\) can be derived in \\(\\mathsf{S4}\\) by the rule\nof necessitation from the axiom \\(\\Box F \\rightarrow F\\). On the other\nhand, interpreting modality \\(\\Box\\) as the predicate of formal\nprovability in theory \\(T\\) and \\(F\\) as contradiction, converts this\nformula into a false statement that the consistency of \\(T\\) is\ninternally provable in \\(T\\). \n\nThe situation after (Gödel 1933) can be described by the \nfollowing figure where ‘\\(X \\hookrightarrow Y\\)’\n should be read as ‘\\(X\\) is interpreted in \n\\(Y\\)’ \n\nIn a public lecture in Vienna in 1938, Gödel observed that using\nthe format of explicit proofs: \n\ncan help in interpreting his provability calculus\n \\(\\mathsf{S4}\\) (Gödel 1938). Unfortunately, \nGödel’s work (Gödel 1938) remained unpublished until 1995, \nby which time the Gödelian logic of explicit proofs had already \nbeen rediscovered, and axiomatized as the Logic of Proofs\n \\(\\mathsf{LP}\\) and supplied with \ncompleteness theorems connecting it to both\n \\(\\mathsf{S4}\\)\n and classical proofs (Artemov 1995). \n\nThe Logic of Proofs\n \\(\\mathsf{LP}\\)\n became the first in the Justification Logic \nfamily. Proof terms in\n \\(\\mathsf{LP}\\)\n are nothing but BHK terms understood as \nclassical proofs. With\n \\(\\mathsf{LP}\\),\n propositional intuitionistic logic received \nthe desired rigorous BHK semantics: \n\nFor further discussion of the mathematical logic tradition, see the \n Section 1 of the supplementary document \n  Some More Technical Matters. The hyperintensional paradox was formulated by Cresswell in 1975. It is well known that it seems possible to have a situation in\nwhich there are two propositions \\(p\\) and \\(q\\) which are logically\nequivalent and yet are such that a person may believe the one but not\nthe other. If we regard a proposition as a set of possible worlds then\ntwo logically equivalent propositions will be identical, and so if\n‘\\(x\\) believes that’ is a genuine sentential functor, the\nsituation described in the opening sentence could not arise. I call\nthis the paradox of hyperintensional contexts. Hyperintensional\ncontexts are simply contexts which do not respect logical\nequivalence. Starting with Cresswell himself, several ways of dealing with this\nhave been proposed. Generally these involve adding more layers to\nfamiliar possible world approaches so that some way of distinguishing\nbetween logically equivalent sentences is available. Cresswell\nsuggested that the syntactic form of sentences be taken into\naccount. Justification Logic, in effect, takes sentence form into\naccount through its mechanism for handling justifications for\nsentences. Thus Justification Logic addresses some of the central\nissues of hyperintensionality and, as a bonus, we automatically have\nan appropriate proof theory, model theory, complexity estimates and a\nbroad variety of applications. A good example of a hyperintensional context is the informal\nlanguage used by mathematicians conversing with each other. Typically\nwhen a mathematician says he or she knows something, the understanding\nis that a proof is at hand. But as the following illustrates, this\nkind of knowledge is essentially hyperintensional. Fermat’s Last Theorem, FLT, is logically equivalent to\n\\(0=0\\) since both are provable, and hence denote the same\nproposition. However, the context of proofs distinguishes them\nimmediately: a proof \\(t\\) of \\(0=0\\) is not necessarily a proof of\nFLT, and vice versa. To formalize mathematical speech the justification logic\n\\({\\textsf{LP}}\\) is a natural choice since \\(t{:}X\\) was designed to\nhave characteristics of “\\(t\\) is a proof of\n\\(X\\).” The fact that propositions \\(X\\) and \\(Y\\) are equivalent in\n\\({\\textsf{LP}}\\), \\(X\\leftrightarrow Y\\), does not warrant the\nequivalence of the corresponding justification assertions and\ntypically \\(t{:}X\\) and \\(t{:}Y\\) are not equivalent,\n\\(t{:}X\\not\\leftrightarrow t{:}Y\\). Going further \\({\\textsf{LP}}\\), and Justification Logic in\ngeneral, is not only sufficiently refined to distinguish justification\nassertions for logically equivalent sentences, it provides a flexible\nmachinery to connect justifications of equivalent sentences and hence\nto maintain constructive closure properties necessary for a quality\nlogic system. For example, let \\(X\\) and \\(Y\\) be provably equivalent,\ni.e., there is a proof \\(u\\) of \\(X\\leftrightarrow Y\\), and so\n\\(u{:}(X\\leftrightarrow Y)\\) is provable in \\({\\textsf{LP}}\\). Suppose\nalso that \\(v\\) is a proof of \\(X\\), and so \\(v{:}X\\). It has already\nbeen mentioned that this does not mean \\(v\\) is a proof of\n\\(Y\\)—this is a hyperintensional context. However within the\nframework of Justification Logic, building on the proofs of \\(X\\) and\nof \\(X\\leftrightarrow Y\\), we can construct a proof term\n\\(f(u,v)\\) which represents the proof of \\(Y\\) and so \\(f(u,v){:}Y\\)\nis provable. In this respect, Justification Logic goes beyond\nCresswell’s expectations: logically equivalent sentences display\ndifferent but constructively controlled epistemic behavior. \n\nIn this section the syntax and axiomatics of the most common systems \nof justification logic are presented. \n\nIn order to build a formal account of justification logics one must \nmake a basic structural assumption: justifications are abstract \nobjects which have structure and operations on them. A good \nexample of justifications is provided by formal proofs, which have \nlong been objects of study in mathematical logic and computer science\n(cf. Section 1.2). \n\nJustification Logic is a formal logical framework which incorporates \nepistemic assertions \\(t : F\\), standing for \n‘\\(t\\) is a justification for \\(F\\)’. \nJustification Logic does not directly analyze what it means for \n\\(t\\) to justify \\(F\\) beyond the format \n\\(t : F\\), but rather attempts to characterize this \nrelation axiomatically. This is similar to the way Boolean logic \ntreats its connectives, say, disjunction: it does not analyze the \nformula \\(p \\vee q\\) but rather assumes certain logical\naxioms and truth tables about this formula. \n\nThere are several design decisions made. Justification Logic starts \nwith the simplest base: classical Boolean logic, and for good\nreasons. Justifications provide a sufficiently serious challenge on \neven the simplest level. The paradigmatic examples by Russell, \nGoldman-Kripke, Gettier and others, can be handled with Boolean \nJustification Logic. The core of Epistemic Logic consists of modal \nsystems with a classical Boolean base\n (K, T, K4, S4, K45, KD45, S5,\n etc.), and each of \nthem has been provided with a corresponding Justification Logic \ncompanion based on Boolean logic. Finally, factivity of \njustifications is not always assumed. This makes it possible to \ncapture the essence of discussions in epistemology involving matters \nof belief and not knowledge. \n\nThe basic operation on justifications\nis application. The application operation takes\njustifications \\(s\\) and \\(t\\) and produces a justification \\(s\\cdot\nt\\) such that if \\(s :( F \\rightarrow G)\\) and \\(t : F\\), then\n[\\(s\\cdot t ]: G\\). Symbolically, \n\nThis is a basic property of justifications assumed in combinatory \nlogic and \\(\\lambda\\)  -calculi (Troelstra and Schwichtenberg \n1996), Brouwer-Heyting-Kolmogorov semantics (Troelstra and van Dalen \n1988), Kleene realizability (Kleene 1945), the Logic of Proofs\n \\(\\mathsf{LP}\\),\n etc. \n\nAnother common operation on justifications is sum: it has been introduced to\nmake explicit the modal logic reasoning (Artemov 1995).  However, some meaningful\njustification logics like \\({\\mathsf{J}}^{-}\\) (Artemov and Fitting 2019)\ndo not use the operation sum.  With sum, any two justifications can safely be combined\ninto something with broader scope.  If \\(s : F\\), \nthen whatever evidence \\(t\\) may be, the combined evidence \n\\(s\\) + \\(t\\) remains a justification for \\(F\\). More \nproperly, the operation ‘+’ takes justifications \n\\(s\\) and \\(t\\) and produces \\(s\\) + \\(t\\), which\nis a justification for everything justified by \\(s\\) or by \n\\(t\\). \n\nAs motivation, one might think of \\(s\\) and \\(t\\) as two \nvolumes of an encyclopedia, and \\(s\\) + \\(t\\) as the set of\nthose two volumes. Imagine that one of the volumes, say \\(s\\), \ncontains a sufficient justification for a proposition \\(F\\), \ni.e., \\(s : F\\) is the case. Then the larger set \n\\(s\\) + \\(t\\) also contains a sufficient justification for \n\\(F\\), [\\(s\\) + \\(t ]: F\\). In the Logic of \nProofs \\(\\mathsf{LP}\\), Section \n1.2, ‘\\(s\\) + \\(t\\)’ can be interpreted as a \nconcatenation of proofs \\(s\\) and \\(t\\). \n\nJustification terms are built from justification variables \n\\(x , y , z\\), … and justification \nconstants \\(a , b , c\\), … (with indices \n\\(i\\) = 1, 2, 3, … which are omitted whenever it is safe)\nby means of the operations ‘\\(\\cdot\\) ’ and ‘+’. \nMore elaborate logics considered below also allow additional \noperations on justifications. Constants denote atomic justifications \nwhich the system does not analyze; variables denote unspecified \njustifications. The Basic Logic of Justifications,\n \\(\\mathsf{J}_{0}\\) is axiomatized by the \nfollowing. \n\n\\(\\mathsf{J}_{0}\\) is the\nlogic of general (not necessarily factive) justifications for an \nabsolutely skeptical agent for whom no formula is provably justified,\ni.e., \\(\\mathsf{J}_{0}\\) \ndoes not derive \\(t : F\\) for any \\(t\\) and \n\\(F\\). Such an agent is, however, capable of drawing \nrelative justification conclusions of the form \n\nWith this capacity\n \\(\\mathsf{J}_{0}\\)\n is able to adequately emulate many other \nJustification Logic systems in its language. \n\nThe Logical Awareness principle states that logical axioms \nare justified ex officio: an agent accepts logical axioms as\njustified (including the ones concerning justifications). As just \nstated, Logical Awareness may be too strong in some epistemic \nsituations. However Justification Logic offers the flexible mechanism\nof Constant Specifications to represent varying shades of Logical \nAwareness. \n\nOf course one distinguishes between an assumption and a justified \nassumption. In Justification Logic constants are used to represent \njustifications of assumptions in situations where they are not \nanalyzed any further. Suppose it is desired to postulate that an \naxiom \\(A\\) is justified for the knower. One simply postulates \n\\(e_{1} : A\\) for some evidence constant \n\\(e_{1}\\) (with index 1). If, furthermore, it is desired\nto postulate that this new principle \n\\(e_{1} : A\\) is also justified, one can \npostulate \\(e_{2} :( e_{1} : A)\\) \nfor a constant \\(e_{2}\\) (with index 2). And so on. \nKeeping track of indices is not necessary, but it is easy and helps \nin decision procedures (Kuznets 2008). The set of all assumptions of \nthis kind for a given logic is called a Constant \nSpecification. Here is the formal definition: \n\nA Constant Specification \\(CS\\) for a given \njustification logic \\(\\mathcal{L}\\) is a set of \nformulas of the form \n\nwhere \\(A\\) is an axiom of \\(\\mathcal{L}\\), and \n\\(e_{1} , e_{2}, \\ldots, e_{n}\\) are similar constants with indices 1,\n2, …, \\(n\\). It is assumed that \\(CS\\) contains all \nintermediate specifications, i.e., whenever \n\\(e_{n} : e_{n- 1}:\\ldots:e_{1} : A\\)\nis in \\(CS\\), then \n\\(e_{n- 1}:\\ldots:e_{1} : A\\)\nis in \\(CS\\) too. \n\nThere are a number of special conditions that have been placed on \nconstant specifications in the literature. The following are the most\ncommon. We may now specify: \n  Logic of Justifications:\n  \\(\\mathsf{J}\\)\n is the logic\n \\(\\mathsf{J}_{0}\\) + \nAxiom Internalization Rule. The new rule states: \n      For each axiom \\(A\\) and any\n      constants \\(e_{1} , e_{2}, \\ldots, e_{n}\\)\n      infer \\(e_{n} : e_{n- 1} : \\ldots : e_{1} : A\\).\n     The latter embodies the idea of unrestricted Logical Awareness for\n\\(\\mathsf{J}\\). A similar rule appeared in the Logic of Proofs\n\\(\\mathsf{LP}\\), and has also been anticipated in Goldman’s\n(Goldman 1967). Logical Awareness, as expressed by axiomatically\nappropriate Constant Specifications, is an explicit incarnation of the\nNecessitation Rule in Modal Logic: \\(\\vdash F \\Rightarrow\\, \\vdash \\Box\nF\\), but restricted to axioms. Note that \\(\\mathsf{J}\\) coincides with\n\\(\\mathsf{J}_{TCS}\\). \n\nThe key feature of Justification Logic systems is their ability to \ninternalize their own derivations as provable justification \nassertions within their languages. This property was anticipated in \n(Gödel 1938). \n\nTheorem 1: For each axiomatically appropriate \nconstant specification \\(CS\\), J\\(_{CS}\\) enjoys \nInternalization: \nIf \\(\\vdash F\\), then \\(\\vdash p : F\\) for some justification term \\(p\\).\n   \n\nProof. Induction on derivation length. Suppose\n\\(\\vdash\\)  \\(F\\). If \\(F\\) is a member of \\(\\mathsf{J}_{0}\\),\nor a member of \\(CS\\), there is a constant \\(e_{n}\\) (where \\(n\\)\nmight be 1) such that \\(e_{n} : F\\) is in \\(CS\\), since \\(CS\\) is\naxiomatically appropriate. Then \\(e_{n} : F\\) is derivable. If \\(F\\)\nis obtained by Modus Ponens from \\(X \\rightarrow F\\) and\n\\(X\\), then, by the Induction Hypothesis, \\(\\vdash s :( X \\rightarrow\nF)\\) and \\(\\vdash t : X\\) for some \\(s , t\\). Using the Application\nAxiom, \\(\\vdash [ s\\cdot t ]: F\\). \n\nSee Section 2 of the supplementary document\n Some More Technical Matters\n for examples of concrete syntactic derivations in\n justification logic. The basic justification logic \\({\\textsf{J}}_0\\), and its extension\nwith a constant specification \\({\\textsf{J}}_{CS}\\), is an explicit\ncounterpart of the smallest normal modal logic \\({\\textsf{K}}\\). A\nproper definition of counterpart will be given in Section 4\nbecause the notion of realization is central, but some hints\nare already apparent at this stage of our presentation. For instance,\nit was noted in Section 1.1 that (1), \\(s{:}(A\\rightarrow\nB)\\rightarrow(t{:}A\\rightarrow [s\\cdot t]{:}B)\\), is an explicit\nversion of the familiar modal principle (2), \\({\\square}(A\\rightarrow\nB) \\rightarrow ({\\square}A\\rightarrow {\\square}B)\\). In a similar way\nthe first justification logic \\(\\textsf{LP}\\) is an explicit\ncounterpart of modal \\({\\textsf{S4}}\\). It turns out that many modal\nlogics have justification logic counterparts—indeed, generally\nmore than one. In what follows we begin by discussing some very\nfamiliar logics, leading up to \\({\\textsf{S4}}\\) and\n\\(\\textsf{LP}\\). Up to this point much of our original motivation\napplies—we have justification logics that are interpretable in\narithmetic. Then we move on to a broader family of modal logics, and\nthe arithmetic motivation is no longer applicable. The phenomenon of\nhaving a modal logic with a justification logic counterpart has turned\nout to be unexpectedly broad. In almost all cases, one must add operations to the \\(+\\) and\n\\(\\cdot\\) of \\({\\textsf{J}}_0\\), along with axioms capturing their\nintended behavior. The exception is factivity, discussed next, for\nwhich no additional operations are required, though additional axioms\nare. It is always understood that constant specifications cover axioms\nfrom the enlarged set. We continue using the terminology of Section\n2.3; for instance a constant specification is axiomatically\nappropriate if it meets the condition as stated there, for all\naxioms including any that have been added to the original set.\nTheorem 1 from Section 2.3 continues to apply to our new justification\nlogics, and with the same proof: if we have a justification logic\n\\(\\textsf{JL}_{CS}\\) with an axiomatically appropriate constant\nspecification, Internalization holds. \n\nFactivity states that justifications are sufficient for an agent to \nconclude truth. This is embodied in the following. \n  Factivity Axiom \\(t : F \\rightarrow F\\).\n \n\nThe Factivity Axiom has a similar motivation to the Truth Axiom of \nEpistemic Logic, \\(\\Box F \\rightarrow F\\), which is widely\naccepted as a basic property of knowledge. \n\nFactivity of justifications is not required in basic Justification Logic \nsystems, which makes them capable of representing both partial and\nfactive justifications.\nThe Factivity Axiom appeared in the Logic of Proofs \n\\(\\mathsf{LP}\\), Section 1.2, as \na principal feature of mathematical proofs. Indeed, in this setting \nFactivity is clearly valid: if there is a mathematical proof \n\\(t\\) of \\(F\\), then \\(F\\) must be true. \n\nThe Factivity Axiom is adopted for justifications that lead to \nknowledge. However, factivity alone does not warrant knowledge, as \nhas been demonstrated by the Gettier examples (Gettier 1963). \n\nLogic of Factive Justifications: \n\nSystems \\(\\mathsf{JT}_{CS}\\) corresponding to Constant\nSpecifications \\(CS\\) are defined as in Section 2.3. \n\nOne of the common principles of knowledge is identifying \nknowing and knowing that one knows. In a modal\nsetting, this corresponds to \\(\\Box F \\rightarrow \\Box \\Box F\\). This\nprinciple has an adequate explicit counterpart: the fact that an agent\naccepts \\(t\\) as sufficient evidence for \\(F\\) serves as sufficient\nevidence for \\(t : F\\). Often such ‘meta-evidence’ has a\nphysical form: a referee report certifying that a proof in a paper is\ncorrect; a computer verification output given a formal proof \\(t\\) of\n\\(F\\) as an input; a formal proof that \\(t\\) is a proof of \\(F\\),\netc. A Positive Introspection operation ‘!’ may\nbe added to the language for this purpose; one then assumes that given\n\\(t\\), the agent produces a justification !\\(t\\) of \\(t : F\\) such\nthat \\(t : F \\rightarrow ! t :( t : F)\\).  Positive Introspection in\nthis operational form first appeared in the Logic of Proofs\n\\(\\mathsf{LP}\\). \n  Positive Introspection Axiom: \\(t : F \\rightarrow ! t :( t : F)\\).\n \n\nWe then define: \n\nLogics \\(\\mathsf{J4}_{0} , \\mathsf{J4}_{CS} , \\mathsf{LP}_{0}\\), and\n \\(\\mathsf{LP}_{CS}\\) are defined in\nthe natural way (cf. Section 2.3). \n\nIn the presence of the Positive Introspection Axiom, one can limit \nthe scope of the Axiom Internalization Rule to internalizing axioms \nwhich are not of the form \\(e : A\\). This is how it was \ndone in \\(\\mathsf{LP}\\): Axiom \nInternalization can then be emulated by using \n!!\\(e :(! e :( e : A))\\) instead of \n\\(e_{3} :( e_{2} :( e_{1} : A))\\), etc.\nThe notion of Constant Specification can also be simplified \naccordingly. Such modifications are minor and they do not affect the \nmain theorems and applications of Justification Logic. \n\n(Pacuit 2006, Rubtsova 2006) considered the Negative\nIntrospection operation ‘?’ which verifies that a\ngiven justification assertion is false. A possible motivation for\nconsidering such an operation is that the positive introspection\noperation ‘!’ may well be regarded as capable of\nproviding conclusive verification judgments about the\nvalidity of justification assertions \\(t : F\\), so when \\(t\\) is not a\njustification for \\(F\\), such a ‘!’ should conclude that\n\\(\\neg t : F\\). This is normally the case for computer proof\nverifiers, proof checkers in formal theories, etc. This motivation is,\nhowever, nuanced: the examples of proof verifiers and proof checkers\nwork with both \\(t\\) and \\(F\\) as inputs, whereas the Pacuit-Rubtsova\nformat ?\\(t\\) suggests that the only input for ‘?’ is a\njustification \\(t\\), and the result ?\\(t\\) is supposed to justify\npropositions \\(\\neg t : F\\) uniformly for all \\(F\\)s for which \\(t :\nF\\) does not hold. Such an operation ‘?’ does not exist\nfor formal mathematical proofs since ?\\(t\\) should then be a single\nproof of infinitely many propositions \\(\\neg t : F\\), which is\nimpossible.  The operation ‘?’ was, historically, the\nfirst example that did not fit into the original framework in which\njustifications were abstract versions of formal proofs.\n \n  Negative Introspection Axiom\n  \\(\\neg t : F \\rightarrow ? t :( \\neg t : F)\\)\n \n\nWe define the systems: \n\nand naturally extend these definitions to\n \\(\\mathsf{J}45_{CS} , \\mathsf{JD}45_{CS}\\), and\n \\(\\mathsf{JT}45_{CS}\\). Justification logics involving \\(?\\) were the first examples that\nwent beyond sublogics of \\({\\textsf{LP}}\\). More recently it has been\ndiscovered that there is an infinite family of modal logics\nthat have justification counterparts, but for which the connection\nwith arithmetic proofs is weak or missing. We discuss a single case in\nsome detail, and sketch others. Peter Geach proposed the axiom scheme\n\\({\\lozenge}{\\square}X{\\rightarrow}{\\square}{\\lozenge}X\\). When added\nto axiomatic \\({\\textsf{S4}}\\) it yields an interesting logic known as\n\\(\\textsf{S4.2}\\). Semantically, Geach’s scheme\nimposes confluence on frames. That is, if two possible\nworlds, \\(w_1\\) and \\(w_2\\) are accessible from the same world\n\\(w_0\\), there is a common world \\(w_4\\) accessible from both \\(w_1\\)\nand \\(w_2\\). Geach’s scheme was generalized\nin Lemmon and Scott (1977) and a\ncorresponding notation was introduced: \\({\\textsf{G}}^{k,l,m,n}\\) is\nthe scheme \\({\\lozenge}^k{\\square}^l X\n{\\rightarrow}{\\square}^m{\\lozenge}^n X\\), where \\(k, l, m, n\\geq\n0\\). Semantically these schemes correspond to generalized versions of\nconfluence. Some people have begun referring to the schemes\nas Geach schemes, and we will follow this practice. More\ngenerally, we will call a modal logic a Geach logic if it can\nbe axiomatized by adding a finite set of Geach schemes to\n\\({\\textsf{K}}\\). The original Geach scheme is\n\\({\\textsf{G}}^{1,1,1,1}\\), but also note that\n\\({\\square}X{\\rightarrow}X\\) is \\({\\textsf{G}}^{0,1,0,0}\\),\n\\({\\square}X{\\rightarrow}{\\square}{\\square}X\\) is\n\\({\\textsf{G}}^{0,1,2,0}\\),\n\\({\\lozenge}X{\\rightarrow}{\\square}{\\lozenge}X\\) is\n\\({\\textsf{G}}^{1,0,1,1}\\), and \\(X{\\rightarrow}{\\square}{\\lozenge}X\\)\nis \\({\\textsf{G}}^{0,0,1,1}\\), so Geach logics include the most common\nof the modal logics. Geach logics constitute an infinite family. Every Geach logic has a justification counterpart. Consider the\noriginal Geach logic, with axiom scheme \\(\\textsf{G}^{1,1,1,1}\\),\n\\({\\lozenge}{\\square}X{\\rightarrow}{\\square}{\\lozenge}X\\) added to a\nsystem for \\(\\textsf{S4}\\)—the system \\(\\textsf{S4.2}\\)\nmentioned above. We build a justification counterpart for\n\\(\\textsf{S4.2}\\) axiomatically by starting with\n\\({\\textsf{LP}}\\). Then we add two function symbols, \\(f\\) and \\(g\\),\neach two-place, and adopt the following axiom scheme, calling the\nresulting justification logic \\(\\textsf{J4.2}\\).  \nThere\nis some informal motivation for this scheme. In \\({\\textsf{LP}}\\),\nbecause of the axiom scheme \\(t{:}X{\\rightarrow}X\\), we have\nprovability of \\((t{:}X\\land u{:}\\lnot X){\\rightarrow}\\bot\\) for any\n\\(t\\) and \\(u\\), and thus provability of \\(\\lnot t{:}X \\lor\\lnot\nu{:}\\lnot X\\). In any context one of the disjuncts must hold. The\nscheme above is equivalent to \\(f(t,u){:}\\lnot t{:}X \\lor\ng(t,u){:}\\lnot u{:}\\lnot X\\), which informally says that in any\ncontext we have means for computing a justification for the disjunct\nthat holds. It is a strong assumption, but not implausible at least in\nsome circumstances. A realization theorem connects \\(\\textsf{S4.2}\\) and\n\\(\\textsf{J4.2}\\), though it is not known if this has a constructive\nproof. As another example, consider \\({\\textsf{G}}^{1,2,2,1}\\),\n\\({\\lozenge}{\\square}{\\square}X{\\rightarrow}{\\square}{\\square}{\\lozenge}X\\),\nor equivalently \\({\\square}\\lnot{\\square}{\\square}X \\lor\n{\\square}{\\square}\\lnot{\\square}X\\). It has as a corresponding\njustification axiom scheme the following, where \\(f\\), \\(g\\), and\n\\(h\\) are three-place function symbols. \nAn intuitive\ninterpretation for \\(f\\), \\(g\\), and \\(h\\) is not as clear as it is\nfor \\(\\textsf{G}^{1,1,1,1}\\), but formally things behave quite\nwell. Even though the Geach family is infinite, these logics do not cover\nthe full range of logics with justification counterparts. For\ninstance, the normal modal logic using the axiom scheme\n\\({\\square}({\\square}X{\\rightarrow}X)\\), sometimes called shift\nreflexivity, is not a Geach logic, but it does have a\njustification counterpart. Add a one-place function symbol \\(k\\) to\nthe machinery building up justification terms, and adopt the\njustification axiom scheme \\(k(t){:}(t{:}X{\\rightarrow}X)\\). A\nRealization Theorem holds; this is shown\nin Fitting (2014b). We speculate that\nall logics axiomatized with Sahlquist formulas will have justification\ncounterparts, but this remains a conjecture at this point. \n\nThe now-standard semantics for justification logic originates in\n(Fitting 2005)—the models used are generally called Fitting\nmodels in the literature, but will be called possible world\njustification models here. Possible world justification models\nare an amalgam of the familiar possible world semantics for logics of\nknowledge and belief, due to Hintikka and Kripke, with machinery\nspecific to justification terms, introduced by Mkrtychev in (Mkrtychev\n1997), (cf. Section 3.4). \n\nTo be precise, a semantics for \\(\\mathsf{J}_{CS}\\), where \\(CS\\) is\nany constant specification, is to be defined. Formally, a possible\nworld justification logic model for \\(\\mathsf{J}_{CS}\\) is a\nstructure \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R} ,\n\\mathcal{E} , \\mathcal{V}\\rangle\\) . Of this, \\(\\langle \\mathcal{G} ,\n\\mathcal{R}\\rangle\\) is a standard \\(\\mathsf{K}\\) frame, where\n\\(\\mathcal{G}\\) is a set of possible worlds and \\(\\mathcal{R}\\) is a\nbinary relation on it.  \\(\\mathcal{V}\\) is a mapping from\npropositional variables to subsets of \\(\\mathcal{G}\\), specifying\natomic truth at possible worlds. \n\nThe new item is \\(\\mathcal{E}\\), an evidence \nfunction, which originated in (Mkrtychev 1997). This maps \njustification terms and formulas to sets of worlds. The intuitive \nidea is, if the possible world \\(\\Gamma\\)  is in\n \\(\\mathcal{E} ( t , X)\\), then \\(t\\) is \nrelevant or admissible evidence for \\(X\\) at \nworld \\(\\Gamma\\) . One should not think of relevant evidence as \nconclusive. Rather, think of it as more like evidence that can be \nadmitted in a court of law: this testimony, this document is \nsomething a jury should examine, something that is pertinent, but \nsomething whose truth-determining status is yet to be considered. \nEvidence functions must meet certain conditions, but these are \ndiscussed a bit later. \n\nGiven a \\(\\mathsf{J}_{CS}\\) possible world justification model\n\\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R} , \\mathcal{E} ,\n\\mathcal{V}\\rangle\\) , truth of formula \\(X\\) at possible world\n\\(\\Gamma\\) is denoted by \\(\\mathcal{M} , \\Gamma \\Vdash X\\), and is\nrequired to meet the following standard conditions: \n\nFor each \\(\\Gamma \\in \\mathcal{G}\\): \n\nThese just say that atomic truth is specified arbitrarily, and \npropositional connectives behave truth-functionally at each world. \nThe key item is the next one. \n\nThis condition breaks into two parts. The clause requiring that\n \\(\\mathcal{M} , \\Delta \\Vdash X\\) for every \\(\\Delta \\in\n \\mathcal{G}\\) such that \\(\\Gamma \\mathcal{R} \\Delta\\) is the familiar\n Hintikka/Kripke condition for \\(X\\) to be believed, or be believable,\n at \\(\\Gamma\\) . The clause requiring that \\(\\Gamma \\in \\mathcal{E} (\n t , X)\\) adds that \\(t\\) should be relevant evidence for \\(X\\) at\n \\(\\Gamma\\) . Then, informally, \\(t : X\\) is true at a possible world\n if \\(X\\) is believable at that world in the usual sense of epistemic\n logic, and \\(t\\) is relevant evidence for \\(X\\) at that world. \n\nIt is important to realize that, in this semantics, one might not \nbelieve something for a particular reason at a world either because \nit is simply not believable, or because it is but the reason is not \nappropriate. \n\nSome conditions must still be placed on evidence functions, and the \nconstant specification must also be brought into the picture. Suppose\none is given \\(s\\) and \\(t\\) as justifications. One can \ncombine these in two different ways: simultaneously use the \ninformation from both; or use the information from just one of them, \nbut first choose which one. Each gives rise to a basic operation on \njustification terms, \\(\\cdot\\)  and +, introduced axiomatically in \nSection 2.2. \n\nSuppose \\(s\\) is relevant evidence for an implication and \n\\(t\\) is relevant evidence for the antecedent. Then \\(s\\) \nand \\(t\\) together provides relevant evidence for the \nconsequent. The following condition on evidence functions is assumed: \n\nWith this condition added, the validity of \n\nis secured. \n\nIf \\(s\\) and \\(t\\) are items of evidence, one might say \nthat something is justified by one of \\(s\\) or \\(t\\), \nwithout bothering to specify which, and this will still be evidence. \nThe following requirement is imposed on evidence functions. \n\nNot surprisingly, both \n\nand \n\nnow hold. \n\nFinally, the Constant Specification \\(CS\\) should be taken into \naccount. Recall that constants are intended to represent reasons for \nbasic assumptions that are accepted outright. A model\n \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R} , \\mathcal{E} , \\mathcal{V}\\rangle\\)  \nmeets Constant Specification \\(CS\\) provided: if \n\\(c : X \\in CS\\) then\n \\(\\mathcal{E}\\)(c,X) = \\(\\mathcal{G}\\). \nPossible World Justification Model A possible world\n justification model for \\(\\mathsf{J}_{CS}\\) is a structure\n \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R} , \\mathcal{E} ,\n \\mathcal{V}\\rangle\\) satisfying all the conditions listed above, and\n meeting Constant Specification \\(CS\\).\n \n\nDespite their similarities, possible world justification models allow\na fine-grained analysis that is not possible with Kripke models. See\nSection 3 of the supplementary document\n Some More Technical Matters\nfor more details. \n\nA formula \\(X\\) is valid in a particular model for \n\\(\\mathsf{J}_{CS}\\) if it is true at all \npossible worlds of the model. Axiomatics for\n \\(\\mathsf{J}_{CS}\\) was given in \nSections 2.2 and 2.3. A completeness theorem now takes the expected \nform. \n Theorem 2: A formula \\(X\\) is provable\n in \\(\\mathsf{J}_{CS}\\)\n if and only if \\(X\\) is valid\n in all \\(\\mathsf{J}_{CS}\\) models.\n \n\nThe completeness theorem as just stated is sometimes referred to as \nweak completeness. It maybe a bit surprising that it is \nsignificantly easier to prove than completeness for the modal logic \n\\(\\mathsf{K}\\). Comments on this \npoint follow. On the other hand it is very general, working for all \nConstant Specifications. \n\nIn (Fitting 2005) a stronger version of the semantics was also\nintroduced. A model \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R}\n, \\mathcal{E} , \\mathcal{V}\\rangle\\) is called fully\nexplanatory if it meets the following condition. For each\n\\(\\Gamma \\in \\mathcal{G}\\), if \\(\\mathcal{M} , \\Delta \\Vdash X\\) for\nall \\(\\Delta \\in \\mathcal{G}\\) such that \\(\\Gamma \\mathcal{R} \\Delta\\)\n, then \\(\\mathcal{M} , \\Gamma \\Vdash t : X\\) for some justification\nterm \\(t\\). Note that the condition, \\(\\mathcal{M} , \\Delta \\Vdash X\\)\nfor all \\(\\Delta \\in \\mathcal{G}\\) such that \\(\\Gamma \\mathcal{R}\n\\Delta\\) , is the usual condition for \\(X\\) being believable at\n\\(\\Gamma\\) in the Hintikka/Kripke sense.  So, fully explanatory really\nsays that if a formula is believable at a possible world, there is a\njustification for it. \n\nNot all weak models meet the fully explanatory condition. Models that\ndo are called strong models. If constant specification \n\\(CS\\) is rich enough so that an Internalization theorem holds, \nthen one has completeness with respect to strong models meeting \n\\(CS\\). Indeed, in an appropriate sense completeness with \nrespect to strong models is equivalent to being able to prove \nInternalization. \n\nThe proof of completeness with respect to strong models bears a close\nsimilarity to the proof of completeness using canonical models for \nthe modal logic \\(\\mathsf{K}\\). \nIn turn, strong models can be used to give a semantic proof of the \nRealization Theorem (cf. Section 4). \n\nSo far a possible world semantics for one justification logic has been \ndiscussed, for \\(\\mathsf{J}\\), \nthe counterpart of\n \\(\\mathsf{K}\\). Now things are broadened to encompass \njustification analogs of other familiar modal logics. Simply by adding reflexivity of the accessibility relation\n\\(\\mathcal{R}\\) to the conditions for a model in Section 3.1, one\ngains the validity of \\(t{:}X \\rightarrow X\\) for every \\(t\\) and\n\\(X\\), and obtains a semantics for \\(\\mathsf{JT}\\), the justification logic analog of\nthe modal logic \\({\\textsf{T}}\\), the weakest logic of\nknowledge. Indeed, if \\({\\mathcal{M},\\Gamma{\\Vdash}t{:}X}\\) then, in particular,\n\\(X\\) is true at every state accessible from \\(\\Gamma\\). Since the\naccessibility relation is required to be reflexive,\n\\({\\mathcal{M},\\Gamma{\\Vdash}X}\\). Weak and strong completeness theorems are\nprovable using the same machinery that applied in the case of \\(\\textsf{J}\\), and a\nsemantic proof of a Realization Theorem connecting  \\(\\mathsf{JT}\\) and\n\\({\\textsf{T}}\\) is also available. The same applies to the logics\ndiscussed below. For a justification analog of \\({\\textsf{K4}}\\) an additional unary\noperator ‘!’ is added to the term language, see Section\n2.5. Recall this operator maps justifications to justifications, where\nthe idea is that if \\(t\\) is a justification for \\(X\\), then \\(!t\\)\nshould be a justification for \\(t{:}X\\). Semantically this adds\nconditions to a model \\(\\mathcal{M} = \\langle\n\\mathcal{G},\\mathcal{R},\\mathcal{E},\\mathcal{V}\\rangle\\), as\nfollows. First, of course, \\(\\mathcal{R}\\) should be transitive, but not\nnecessarily reflexive. Second, a monotonicity condition on evidence\nfunctions is required: \\[\\mbox{If } \\Gamma \\mathcal{R} \\Delta \\mbox{ and } \\Gamma\\in\n\\mathcal{E}(t,X) \\mbox{ then } \\Delta \\in \\mathcal{E}(t,X)\\] And\nfinally, one more evidence function condition is needed. \\[\\mathcal{E}(t,X) \\subseteq \\mathcal{E}(!t,t{:}X)\\] These\nconditions together entail the validity of \\(t{:}X \\rightarrow\n!t{:}t{:}X\\) and produce a semantics for \\(\\mathsf{J4}\\), a\njustification analog of \\(\\mathsf{K4}\\), with a Realization Theorem\nconnecting them. Adding reflexivity leads to a logic that is called\n\\({\\textsf{LP}}\\) for historical reasons. We have discussed justification logics that are sublogics of\n\\({\\textsf{LP}}\\), corresponding to sublogics of the modal logic\n\\(\\textsf{S4}\\). The first examples that went beyond \\({\\textsf{LP}}\\)\nwere those discussed in Section 2.7, involving a negative\nintrospection operator, ‘?’. Models for justification\nlogics that include this operator add three conditions. First R is\nsymmetric. Second, one adds a condition that has come to be known\nas strong evidence: \\({\\mathcal{M},\\Gamma{\\Vdash}t{:}X}\\) for\nall \\(\\Gamma\\in \\mathcal{E}(t, X)\\). Finally, there is a condition on\nthe evidence function: If this machinery is added to that for \\(\\mathsf{J4}\\) we get the\nlogic \\(\\mathsf{J45}\\), a justification counterpart of\n\\(\\mathsf{K45}\\). Axiomatic soundness and completeness can be\nproved. In a similar way, related logics \\(\\mathsf{JD45}\\) and\n\\(\\mathsf{JT45}\\) can be formulated semantically. A Realization\nTheorem taking the operator \\(?\\) into account was shown in (Rubtsova\n2006). Moving to Geach logics as introduced in Section 2.8, a semantic\nmodel for \\(\\textsf{J4.2}\\) can also be specified. Suppose \\(G =\n\\langle \\mathcal{G}, \\mathcal{R}, \\mathcal{E}, \\mathcal{V}\\rangle\\) is\nan \\({\\textsf{LP}}\\) model. We add the following requirements. First,\nthe frame must be convergent, as with \\(\\textsf{S4.2}\\). Second, as\nwith \\(?\\), \\(\\mathcal{E}\\) must be a strong evidence\nfunction. And third, \\(\\mathcal{E}(f(t,u), \\lnot t{:}X)\\cup\n\\mathcal{E}(g(t,u), \\lnot u{:}\\lnot X) = \\mathcal{G}\\). Completeness\nand soundness results follow in the usual way. In a similar way every modal logic axiomatized by Geach schemes in\nthis family has a justification counterpart, with a Fitting semantics\nand a realization theorem connecting the justification counterpart\nwith the corresponding modal logic. In particular, this tells us that\nthe justification logic family is infinite, and certainly much broader\nthan it was originally thought to be. It is also the case that some\nmodal logics not previously considered, and not in this family, have\njustification counterparts as well. Investigating the consequences of\nall this is still work in progress. \n\nSingle world justification models were developed considerably before\nthe more general possible world justification models we have been\ndiscussing, (Mkrtychev 1997). Today they can most simply be thought of\nas possible world justification models that happen to have a single\nworld. The completeness proof for \\(\\mathsf{J}\\) and the other\njustification logics mentioned above can easily be modified to\nestablish completeness with respect to single world justification\nmodels, though of course this was not the original argument. What\ncompleteness with respect to single world justification models tells\nus is that information about the possible world structure of\njustification models can be completely encoded by the admissible\nevidence function, at least for the logics discussed so far. Mkrtychev\nused single world justification models to establish decidability of\n\\(\\mathsf{LP}\\), and others have made fundamental use of them in\nsetting complexity bounds for justification logics, as well as for\nshowing conservativity results for justification logics of belief\n(Kuznets 2000, Kuznets 2008, Milnikel 2007, Milnikel 2009). Complexity\nresults have further been used to address the problem of logical\nomniscience. The formal semantics for Justification Logic described above in\n3.1–3.4 defines truth value at a given world \\(\\Gamma\\) the same\nway it is done in Awareness Models: \\(t{:}F\\) holds at \\(\\Gamma\\)\niff \\(F\\) holds at all worlds accessible from \\(\\Gamma\\) and \\(t\\) is admissible evidence for \\(F\\) according to the given\nevidence function. In addition, there is a different kind of semantics, so-called\nmodular semantics, which focuses on making more transparent the\nontological status of justifications. Within modular semantics\npropositions receive the usual classical truth values and\njustifications are interpreted syntactically as sets of formulas. We\nretain a classical interpretation \\(\\ast\\) of the propositional\nformulas \\(Fm\\), which, in the case of a single world, reduces to\n\\[\\ast: Fm \\mapsto\\ \\ \\{0,1\\}\\] i.e., each formula gets a truth value\n0 (false) or 1 (true), with the usual Boolean conditions:\n\\({\\Vdash}A\\rightarrow B\\) iff \\(\\not\\Vdash A\\) or \\({\\Vdash}B\\),\netc. The principal issue is how to interpret justification\nterms. For sets of formulas \\(X\\) and \\(Y\\), we define\n\\[X\\cdot Y = \\{ F \\mid G{\\rightarrow}F \\in X\\ \\mbox{and} \\ G \\in Y\\\n\\mbox{for some}\\ G\\}.\\] Informally, \\(X\\cdot Y\\) is the result of\napplying Modus Ponens once between all members of \\(X\\) and\nof \\(Y\\) (in that order). Justification terms Tm are\ninterpreted as subsets of the set of formulas: \\[\\ast: Tm \\mapsto\\ \\\n2^{Fm}\\] such that \\[(s\\cdot t)^\\ast\\supseteq s^\\ast\\cdot t^\\ast \\ \\\n\\mbox{and}\\ \\ \\ (s+t)^\\ast\\supseteq s^\\ast\\cup t^\\ast .\\] These\nconditions correspond to the basic justification logic \\(\\textsf{J}\\);\nother systems require additional closure properties of \\(\\ast\\). Note\nthat whereas propositions in modular models are interpreted\nsemantically, as truth values, justifications are interpreted\nsyntactically, as sets of formulas. This is a principal hyperintensional feature: a\nmodular model may treat distinct formulas \\(F\\) and \\(G\\) as equal in\nthe sense that \\(F^\\ast = G^\\ast\\), but still be able to distinguish\njustification assertions \\(t{:}F\\) and \\(t{:}G\\), for example when \\(F\n\\in t^\\ast\\) but \\(G\\not\\in t^\\ast\\) yielding \\({\\Vdash}t{:}F\\) but\n\\(\\not\\Vdash t{:}G\\). In the general possible world setting, formulas\nare interpreted classically as subsets of the set \\(W\\) of possible\nworlds, \\[\\ast: Fm \\mapsto\\ \\ 2^W ,\\] and justification terms are\ninterpreted syntactically as sets of formulas at each world \\[\\ast:\nW\\times Tm \\mapsto\\ \\ 2^{Fm}.\\] Soundness and completeness of\nJustification Logic systems with respect to modular models have been\ndemonstrated in Artemov (2012; Kuznets and\nStuder 2012). The logical omniscence problem is that in epistemic logics all\ntautologies are known and knowledge is closed under consequence, which\nis unreasonable. In Fagin and Halpern\n(1988) a simple mechanism for avoiding the problems was\nintroduced. One adds to the usual Kripke model structure an awareness\nfunction \\(\\cal A\\) indicating for each world which formulas the agent\nis aware of at this world. Then a formula is taken to be known at a\npossible world \\(\\Gamma\\) if 1) the formula is true at all worlds\naccessible from \\(\\Gamma\\) (the Kripkean condition for knowledge) and\n2) the agent is aware of the formula at \\(\\Gamma\\). Awareness\nfunctions can serve as a practical tool for blocking knowledge of an\narbitrary set of formulas. However as logical structures, awareness\nmodels can exhibit unusual behavior due to the lack of natural closure\nproperties. For example, the agent can know \\(A\\wedge B\\) but be aware\nof nether \\(A\\) nor \\(B\\) and hence not know either. Possible world justification logic models use a forcing definition\nreminiscent of the one from the awareness models: for any given\njustification \\(t\\) the justification assertion \\(t{:}F\\) holds at\nworld \\(\\Gamma\\) iff 1) \\(F\\) holds at all worlds \\(\\Delta\\)\naccessible from \\(\\Gamma\\) and 2) \\(t\\) is admissible evidence for\n\\(F\\) at \\(\\Gamma\\), \\(\\Gamma\\in{\\cal E}(t,F)\\). The principal\ndifference is in the operations on justifications and corresponding\nclosure conditions on admissible evidence function \\(\\cal E\\) in\nJustification Logic models, which may hence be regarded as a dynamic\nversion of awareness models which necessary closure properties\nspecified. This idea has been explored\nin Sedlár (2013) which worked\nwith the language of \\(\\textsf{LP}\\), thinking of it as a multi-agent\nmodal logic, and taking justification terms as agents (more properly,\nactions of agents). This shows that Justification Logic models absorb\nthe usual epistemic themes of awareness, group agency and dynamics in\na natural way. \n\nThe natural modal epistemic counterpart of the evidence assertion \n\\(t : F\\) is \\(\\Box F\\), read for some x, \nx:\\(F\\). This observation leads to the notion of \nforgetful projection which replaces each occurrence of \n\\(t : F\\) by \\(\\Box F\\) and hence converts a \nJustification Logic sentence \\(S\\) to a corresponding Modal \nLogic sentence \\(S^{o}\\). The forgetful \nprojection extends in the natural way from sentences to logics. \n\nObviously, different Justification Logic sentences may have the same \nforgetful projection, hence \\(S^{o}\\) loses \ncertain information that was contained in \\(S\\). However, it is \neasily observed that the forgetful projection always maps valid \nformulas of Justification Logic (e.g., axioms of\n \\(\\mathsf{J})\\)\n to valid formulas of a corresponding\nEpistemic Logic \\((\\mathsf{K}\\) \nin this case). The converse also holds: any valid formula of \nEpistemic Logic is the forgetful projection of some valid formula of \nJustification Logic. This follows from the Correspondence Theorem 3. \n  Theorem 3:\n \\(\\mathsf{J}^{o} = \\mathsf{K}\\).\n \n\nThis correspondence holds for other pairs of Justification and \nEpistemic systems, for instance\n \\(\\mathsf{J4}\\) and\n \\(\\mathsf{K4}\\), or\n \\(\\mathsf{LP}\\) and\n \\(\\mathsf{S4}\\),\n and many others. In such extended form, the \nCorrespondence Theorem shows that major modal logics such as\n \\(\\mathsf{K} , \\mathsf{T} , \\mathsf{K4} , \\mathsf{S4} , \\mathsf{K45} , \\mathsf{S5}\\)\n and some others have exact Justification Logic \ncounterparts. \n\nAt the core of the Correspondence Theorem is the following \nRealization Theorem. \nTheorem 4: There is an algorithm which, for each\nmodal formula \\(F\\) derivable in\n \\(\\mathsf{K}\\), assigns evidence terms to each occurrence of\nmodality in \\(F\\) in such a way that the resulting formula\n\\(F^{r}\\) is derivable in\n \\(\\mathsf{J}\\). Moreover, the realization assigns evidence\nvariables to the negative occurrences of modal operators in \\(F\\), thus\nrespecting the existential reading of epistemic modality.\n \n\nKnown realization algorithms which recover evidence terms in modal \ntheorems use cut-free derivations in the corresponding modal logics. \nAlternatively, the Realization Theorem can be established \nsemantically by Fitting’s method or its proper modifications. \nIn principle, these semantic arguments also produce \nrealization procedures which are based on exhaustive search. \n\nIt would be a mistake to draw the conclusion that \nany modal logic has a reasonable Justification Logic\ncounterpart. For example the logic of formal provability,\n \\(\\mathsf{GL}\\), (Boolos 1993) contains\nthe Löb Principle: \n\nwhich does not seem to have an epistemically acceptable explicit \nversion. Consider, for example, the case where \\(F\\) is the \npropositional constant \\(\\bot\\)  for false. If an analogue of \nTheorem 4 would cover the Löb Principle there would be \njustification terms \\(s\\) and \\(t\\) such that \n\\(x :( s : \\bot \\rightarrow \\bot ) \\rightarrow t : \\bot\\) . \nBut this is intuitively false for factive justification. Indeed, \n\\(s : \\bot \\rightarrow \\bot\\)  is an instance of the Factivity Axiom.\nApply Axiom Internalization to obtain \n\\(c :( s : \\bot \\rightarrow \\bot )\\) for some constant \n\\(c\\). This choice of \\(c\\) makes the antecedent of \n\\(c :( s : \\bot \\rightarrow \\bot ) \\rightarrow t : \\bot\\)  \nintuitively true and the conclusion \n false[4].\n In particular, the Löb Principle (5) is not valid for the proof \ninterpretation (cf. (Goris 2007) for a full account of which \nprinciples of \\(\\mathsf{GL}\\) are\nrealizable). \n\nThe Correspondence Theorem gives fresh insight into epistemic modal \nlogics. Most notably, it provides a new semantics for the major modal\nlogics. In addition to the traditional Kripke-style \n‘universal’ reading of \\(\\Box F\\) as F holds \nin all possible situations, there is now a rigorous \n‘existential’ semantics for \\(\\Box F\\) that can be\nread as there is a witness (proof, justification) for F. \n\nJustification semantics plays a similar role in Modal Logic to that \nplayed by Kleene realizability in Intuitionistic Logic. In both \ncases, the intended semantics is existential: the \nBrouwer-Heyting-Kolmogorov interpretation of Intuitionistic Logic \n(Heyting 1934, Troelstra and van Dalen 1988, van Dalen 1986) and \nGödel’s provability reading of\n \\(\\mathsf{S4}\\) (Gödel 1933, Gödel 1938). In both \ncases there is a possible-world semantics of \nuniversal character which is a highly potent and \ndominant technical tool. It does not, however, address the \nexistential character of the intended semantics. It took Kleene \nrealizability (Kleene 1945, Troelstra 1998) to reveal the \ncomputational semantics of Intuitionistic Logic and the Logic of \nProofs to provide exact BHK semantics of\nproofs for Intuitionistic and Modal Logic. \n\nIn the epistemic context, Justification Logic and the Correspondence \nTheorem add a new ‘justification’ component to modal \nlogics of knowledge and belief. Again, this new component was, in \nfact, an old and central notion which has been widely discussed by \nmainstream epistemologists but which remained out of the scope of \nclassical epistemic logic. The Correspondence Theorem tells us that \njustifications are compatible with Hintikka-style systems and hence \ncan be safely incorporated into the foundation for Epistemic Modal \nLogic. \nSee Section 4 of the supplementary document\n Some More Technical Matters\nfor more on Realization Theorems. \n\nSo far in this article only single-agent justification logics, \nanalogous to single-agent logics of knowledge, have been considered. \nJustification Logic can be thought of as logic of explicit \nknowledge, related to more conventional logics of implicit \nknowledge. A number of systems beyond those discussed above have been\ninvestigated in the literature, involving multiple agents, or having \nboth implicit and explicit operators, or some combination of these. \n\nSince justification logics provide explicit justifications, while\nconventional logics of knowledge provide an implicit knowledge\noperator, it is natural to consider combining the two in a single\nsystem. The most common joint logic of explicit and implicit knowledge\nis \\(\\mathsf{S4LP}\\) (Artemov and Nogina 2005). The language of\n\\(\\mathsf{S4LP}\\) is like that of \\(\\mathsf{LP}\\), but with an\nimplicit knowledge operator added, written either \\(\\mathbf{K}\\) or\n\\(\\Box\\) . The axiomatics is like that of \\(\\mathsf{LP}\\), combined\nwith that of \\(\\mathsf{S4}\\) for the implicit operator, together with\na connecting axiom, \\(t : X \\rightarrow \\Box X\\), anything that has an\nexplicit justification is knowable. \n\nSemantically, possible world justification models for\n \\(\\mathsf{LP}\\) need no modification, since they already have \nall the machinery of Hintikka/Kripke models. One models the \\(\\Box\\)  \noperator in the usual way, making use of just the accessibility \nrelation, and one models the justification terms as described in \nSection 3.1 using both accessibility and the evidence function. Since \nthe usual condition for \\(\\Box X\\) being true at a world is \none of the two clauses of the condition for \\(t : X\\) \nbeing true, this immediately yields the validity of \n\\(t : X \\rightarrow \\Box X\\), and soundness follows\neasily. Axiomatic completeness is also rather straightforward. \n\nIn \\(\\mathsf{S4LP}\\) both implicit and explicit knowledge is\nrepresented, but in possible world justification model semantics a\nsingle accessibility relation serves for both. This is not the only\nway of doing it. More generally, an explicit knowledge accessibility\nrelation could be a proper extension of that for implicit\nknowledge. This represents the vision of explicit knowledge as having\nstricter standards for what counts as known than that of implicit\nknowledge. Using different accessibility relations for explicit and\nimplicit knowledge becomes necessary when these epistemic notions obey\ndifferent logical laws, e.g., \\(\\mathsf{S5}\\) for implicit knowledge\nand \\(\\mathsf{LP}\\) for explicit.  The case of multiple accessibility\nrelations is commonly known in the literature as Artemov-Fitting\nmodels, but will be called multi-agent possible world models\nhere. (cf. Section 5.2). \n\nCuriously, while the logic\n \\(\\mathsf{S4LP}\\) seems quite natural, a Realization Theorem \nhas been problematic for it: no such theorem can be proved if one \ninsists on what are called normal realizations (Kuznets \n2010). Realization of implicit knowledge modalities in\n \\(\\mathsf{S4LP}\\) by explicit \njustifications which would respect the epistemic structure remains a \nmajor challenge in this area. \n\nInteractions between implicit and explicit knowledge can sometimes be\nrather delicate. As an example, consider the following mixed \nprinciple of negative introspection (again \\(\\Box\\)  should be read as \nan implicit epistemic operator), \n\nFrom the provability perspective, it is the right form of negative \nintrospection. Indeed, let \\(\\Box F\\) be interpreted as F \nis provable and \\(t : F\\) as t is a proof of \nF in a given formal theory \\(T\\), e.g., in Peano Arithmetic\n\\(\\mathsf{PA}\\). Then (6) states \na provable principle. Indeed, if \\(t\\) is not a proof of \n\\(F\\) then, since this statement is decidable, it can be \nestablished inside \\(T\\), hence in \\(T\\) this sentence is \nprovable. On the other hand, the proof \\(p\\) of \n‘\\(t\\) is not a proof of \\(F\\)’ depends on both\n\\(t\\) and \\(F , p = p ( t , F)\\) and \ncannot be computed given \\(t\\) only. In this respect, \\(\\Box\\)  \ncannot be replaced by any specific proof term depending on \\(t\\)\nonly and (6) cannot be presented in an entirely explicit \njustification-style format. \n\nThe first examples of explicit/implicit knowledge systems appeared in\nthe area of provability logic. In (Sidon 1997, Yavorskaya (Sidon) \n2001), a logic \\(\\mathsf{LPP}\\) \nwas introduced which combined the logic of provability\n \\(\\mathsf{GL}\\) with the logic of \nproofs \\(\\mathsf{LP}\\), but to \nensure that the resulting system had desirable logical properties \nsome additional operations from outside the original \nlanguages of \\(\\mathsf{GL}\\) and \n\\(\\mathsf{LP}\\) were added. In \n(Nogina 2006, Nogina 2007) a complete logical system,\n \\(\\mathsf{GLA}\\), for proofs and \nprovability was offered, in the sum of the original \nlanguages of \\(\\mathsf{GL}\\)\nand\n \\(\\mathsf{LP}\\). Both\n \\(\\mathsf{LPP}\\) and\n \\(\\mathsf{GLA}\\)\n enjoy completeness relative to the \nclass of arithmetical models, and also relative to the class of \npossible world justification models. \n\nAnother example of a provability principle that cannot be made \ncompletely explicit is the Löb Principle (5). For each of\n \\(\\mathsf{LPP}\\) and\n \\(\\mathsf{GLA}\\),\n it is easy to find a proof term \n\\(l ( x)\\) such that \n\nholds. However, there is no realization which makes all \nthree \\(\\Box\\) s in (5) explicit. In fact, the set of \nrealizable provability principles is the intersection of\n \\(\\mathsf{GL}\\) and\n \\(\\mathsf{S4}\\) (Goris 2007). \n\nIn Multi-Agent possible world justification models multiple\naccessibility relations are employed, with connections between them,\n(Artemov 2006). The idea is, there are multiple agents, each with an\nimplicit knowledge operator, and there are justification terms, which\neach agent understands. Loosely, everybody understands explicit\nreasons; these amount to evidence-based common knowledge. \n\nAn \\(n\\)-agent possible world justification model is a structure\n \\(\\langle \\mathcal{G} , \\mathcal{R}_{1}\\), …,\\(\\mathcal{R}_{n}\n , \\mathcal{R} , \\mathcal{E} , \\mathcal{V}\\rangle\\) meeting the\n following conditions.  \\(\\mathcal{G}\\) is a set of possible\n worlds. Each of \\(\\mathcal{R}_{1}\\),…,\\(\\mathcal{R}_{n}\\) is\n an accessibility relation, one for each agent. These may be assumed\n to be reflexive, transitive, or symmetric, as desired. They are used\n to model implicit agent knowledge for the family of agents. The\n accessibility relation \\(\\mathcal{R}\\) meets the \\(\\mathsf{LP}\\)\n conditions, reflexivity and transitivity. It is used in the modeling\n of explicit knowledge.  \\(\\mathcal{E}\\) is an evidence function,\n meeting the same conditions as those for \\(\\mathsf{LP}\\) in Section\n 3.3. \\(\\mathcal{V}\\) maps propositional letters to sets of worlds, as\n usual. There is a special condition imposed: for each \\(i\\) = 1,\n …,\\(n , \\mathcal{R}_{i} \\subseteq \\mathcal{R}\\). \n\nIf \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R}_{1}\\),\n …,\\(\\mathcal{R}_{n} , \\mathcal{R} , \\mathcal{E} ,\n \\mathcal{V}\\rangle\\) is a multi-agent possible world justification\n model a truth-at-a-world relation, \\(\\mathcal{M} , \\Gamma \\Vdash X\\),\n is defined with most of the usual clauses. The ones of particular\n interest are these: \n\nThe condition \\(\\mathcal{R}_{i} \\subseteq \\mathcal{R}\\) entails the validity of \n\\(t : X \\rightarrow K_{i}X\\), for each agent \\(i\\).\nIf there is only a single agent, and the accessibility relation for \nthat agent is reflexive and transitive, this provides another \nsemantics for \\(\\mathsf{S4LP}\\). \nWhatever the number of agents, each agent accepts explicit reasons as\nestablishing knowledge. \n\nA version of \\(\\mathsf{LP}\\) with\ntwo agents was introduced and studied in (Yavorskaya (Sidon) \n2008), though it can be generalized to any finite number of agents. In\nthis, each agent has its own set of justification operators, \nvariables, and constants, rather than having a single set for \neverybody, as above. In addition some limited communication between \nagents may be permitted, using a new operator that allows one agent \nto verify the correctness of the other agent’s justifications. \nVersions of both single world and more general possible world\njustification semantics were created for the two-agent logics. This\ninvolves a straightforward extension of the notion of an evidence\nfunction, and for possible world justification models, using two\naccessibility relations. Realization theorems have been proved\nsyntactically, though presumably a semantic proof would also work. \n\nThere has been some recent exploration of the role of public \nannouncements in multi-agent justification logics (Renne 2008, Renne \n2009). \n\nThere is more on the notion of evidence-based common knowledge in\nSection 5 of the supplementary document\n Some More Technical Matters. \n\nThere is a technique for using Justification Logic to analyze \ndifferent justifications for the same fact, in particular when some \nof the justifications are factive and some are not. To demonstrate \nthe technique consider a well-known example: \n\nAs in the Red Barn Example, discussed in Section 1.1, here one has to\ndeal with two justifications for a true statement, one of which is \ncorrect and one of which is not. Let \\(B\\) be a sentence \n(propositional atom), \\(w\\) be a designated justification \nvariable for the wrong reason for \\(B\\) and \\(r\\) a \ndesignated justification variable for the right (hence factive) \nreason for \\(B\\). Then, Russell’s example prompts the following \nset of \n assumptions[7]:\n  \n\nSomewhat counter to intuition, one can logically deduce factivity of \n\\(w\\) from \\(\\mathcal{R}\\): \n\nHowever, this derivation utilizes the fact that \\(r\\) is a \nfactive justification for \\(B\\) to conclude \n\\(w : B \\rightarrow B\\), which constitutes a case of \n‘induced factivity’ for \\(w : B\\). The \nquestion is, how can one distinguish the ‘real’ factivity\nof \\(r : B\\) from the ‘induced factivity’ of \n\\(w : B\\) ? Some sort of evidence-tracking is needed here, \nand Justification Logic is an appropriate tool. The natural approach \nis to consider the set of assumptions without \n\\(r : B\\), i.e., \n\nand establish that factivity of \\(w\\), i.e., \n\\(w : B \\rightarrow B\\) is not derivable from\n \\(\\mathcal{S}\\). Here is a possible world justification model\n \\(\\mathcal{M}\\) =\n \\((\\mathcal{G} , \\mathcal{R} , \\mathcal{E} , \\mathcal{V})\\) in which\n \\(\\mathcal{S}\\) \nholds but \\(w : B \\rightarrow B\\) does not: \n\nIt is easy to see that the closure conditions Application \nand Sum on \\(\\mathcal{E}\\) are fulfilled. At\n\\(\\mathbf{1} , w : B\\) holds, i.e., \n\nsince \\(w\\) is admissible evidence for \\(B\\) at \n\\(\\mathbf{1}\\) and there are no possible worlds accessible from \n\\(\\mathbf{1}\\). Furthermore, \n\nsince, according to \\(\\mathcal{E} , r\\) is \nnot admissible evidence for \\(B\\) at \\(\\mathbf{1}\\). Hence: \n\nOn the other hand, \n\nsince \\(B\\) does not hold at \\(\\mathbf{1}\\). \n\nThe Realization algorithms sometimes produce Constant Specifications \ncontaining self-referential justification assertions \n\\(c : A ( c)\\), that is, assertions in which the \njustification (here \\(c)\\) occurs in the asserted proposition \n(here \\(A ( c))\\). \n\nSelf-referentiality of justifications is a new phenomenon which is \nnot present in the conventional modal language. In addition to being \nintriguing epistemic objects, such self-referential assertions \nprovide a special challenge from the semantical viewpoint because of \nthe built-in vicious circle. Indeed, to evaluate \\(c\\) one would\nexpect first to evaluate \\(A\\) and then assign a justification \nobject for \\(A\\) to \\(c\\). However, this cannot be done \nsince \\(A\\) contains \\(c\\) which is yet to be evaluated. \nThe question of whether or not modal logics can be realized without \nusing self-referential justifications was a major open question in \nthis area. \n\nThe principal result by Kuznets in (Brezhnev and Kuznets 2006) states\nthat self-referentiality of justifications is unavoidable in \nrealization of \\(\\mathsf{S4}\\) in\n\\(\\mathsf{LP}\\). The current \nstate of things is given by the following theorem due to Kuznets: \nTheorem 5: Self-referentiality can be avoided in\nrealizations of modal logics\n \\(\\mathsf{K}\\) and\n \\(\\mathsf{D}\\).\n Self-referentiality cannot be avoided in\nrealizations of modal logics\n \\(\\mathsf{T} , \\mathsf{K4} , \\mathsf{D4}\\)\n and\n \\(\\mathsf{S4}\\).\n \n\nThis theorem establishes that a system of justification terms for \n\\(\\mathsf{S4}\\) will necessarily \nbe self-referential. This creates a serious, though not directly \nvisible, constraint on provability semantics. In the Gödelian \ncontext of arithmetical proofs, the problem was coped with by a \ngeneral method of assigning arithmetical semantics to \nself-referential assertions \\(c : A ( c)\\) stating\nthat \\(c\\) is a proof of \\(A ( c)\\). In the Logic of\nProofs \\(\\mathsf{LP}\\) it was \ndealt with by a non-trivial fixed-point construction. \n\nSelf-referentiality gives an interesting perspective on Moore’s \nParadox. See Section 6 of the\nsupplementary document\n Some More Technical Matters\n for details. \nThe question of the self-referentiality of BHK-semantics for\nintuitionistic logic \\(\\mathsf{IPC}\\) has been answered by Junhua Yu\n(Yu 2014).  Extending Kuznets’ method, he established \nTheorem 6: Each \\(\\mathsf{LP}\\) realization of the\nintuitionistic law of double negation \\(\\neg\\neg(\\neg\\neg p\n\\rightarrow p)\\) requires self referential constant\nspecifications. \n\nWhile the investigation of propositional Justification Logic is far \nfrom complete, there has also been some work on first-order \nversions. Quantified versions of Modal Logic already offer \ncomplexities beyond standard first-order logic. Quantification has an\neven broader field to play when Justification Logics are involved. \nClassically one quantifies over ‘objects,’ and models are\nequipped with a domain over which quantifiers range. Modally one \nmight have a single domain common to all possible worlds, or one \nmight have separate domains for each world. The role of the Barcan \nformula is well-known here. Both constant and varying domain options \nare available for Justification Logic as well. In addition there is a\npossibility that has no analog for Modal Logic: one might quantify \nover justifications themselves. \n\nInitial results concerning the possibility of Quantified \nJustification Logic were notably unfavorable. The arithmetical \nprovability semantics for the Logic of Proofs\n \\(\\mathsf{LP}\\), naturally generalizes to a \nfirst-order version with conventional quantifiers, and to a version \nwith quantifiers over proofs. In both cases, axiomatizability \nquestions were answered negatively. \nTheorem 7: The first-order logic of proofs is not\nrecursively enumerable (Artemov and Yavorskaya (Sidon) 2001). The\nlogic of proofs with quantifiers over proofs is not recursively\nenumerable (Yavorsky 2001).\n \n\nAlthough an arithmetic semantics is not possible, in (Fitting 2008) a\npossible world semantics, and an axiomatic proof theory, was given for \na version of \\(\\mathsf{LP}\\) with\nquantifiers ranging over justifications. Soundness and completeness \nwere proved. At this point possible world semantics separates from \narithmetic semantics, which may or may not be a cause for alarm. It \nwas also shown that\n \\(\\mathsf{S4}\\)\n embeds into the quantified logic by translating\n\\(\\Box Z\\) as “there exists a justification \\(x\\) \nsuch that \\(x : Z^{*}\\),” where \n\\(Z^{*}\\) is the translation of \\(Z\\). While this \nlogic is somewhat complicated, it has found applications, e.g., in \n(Dean and Kurokawa 2009b) it is used to analyze the Knower Paradox, \nthough objections have been raised to this analysis in (Arlo-Costa \nand Kishida 2009). A First-Order Logic of Proofs, \\(\\textsf{FOLP}\\), with quantifiers\nover individual variables, has been presented\nin Artemov and Yavorskaya (Sidon)\n(2011). In \\(\\textsf{FOLP}\\) proof assertions are represented\nby formulas of the form \\(t{:}_X A\\) where \\(X\\) is a finite set of\nindividual variables that are considered global parameters open for\nsubstitution. All occurrences of variables from \\(X\\) that are free in\n\\(A\\) are also free in \\(t{:}_X A\\). All other free variables of \\(A\\)\nare considered local and hence bound in \\(t{:}_X A\\). For example, if\n\\(A(x,y)\\) is an atomic formula, then in \\(p{:}_{\\{x\\}} A(x,y)\\)\nvariable \\(x\\) is free and variable \\(y\\) is bound. Likewise, in\n\\(p{:}_{\\{x,y\\}} A(x,y)\\) both variables are free, and in\n\\(p{:}_{\\emptyset} A(x,y)\\) neither \\(x\\) nor \\(y\\) is free. Proofs (justifications) are represented by proof terms which do not\ncontain individual variables. In addition to \\(\\textsf{LP}\\)\noperations there is one more series of operations on proof terms,\n\\({\\sf gen}_x(t)\\), corresponding to generalization over individual\nvariable \\(x\\). The new axiom that governs this operation is \\(t{:}_X\nA {\\rightarrow}{\\sf gen{:}_x(t)}_X\\forall x A\\), with \\(x\\not\\in\nX\\). The complete list of \\(\\textsf{FOLP}\\) principles along with\nrealization of First-Order \\(\\textsf{S4}\\) can be found\nin Artemov and Yavorskaya (Sidon)\n(2011). A semantics for \\(\\textsf{FOLP}\\) has been developed\nin Fitting (2014a). \n\nThe initial Justification Logic system, the Logic of Proofs\n \\(\\mathsf{LP}\\),\n was introduced in 1995 in (Artemov 1995) (cf. \nalso (Artemov 2001)) where such basic properties as Internalization, \nRealization, arithmetical completeness, were first established.\n\\(\\mathsf{LP}\\) offered an intended\nprovability semantics for Gödel’s provability logic\n \\(\\mathsf{S4}\\),\n thus providing a formalization of Brouwer-Heyting-Kolmogorov\nsemantics for intuitionistic propositional logic. \nEpistemic semantics and completeness (Fitting 2005) were first \nestablished for \\(\\mathsf{LP}\\). \nSymbolic models and decidability for\n \\(\\mathsf{LP}\\)\n are due to Mkrtychev (Mkrtychev 1997). \nComplexity estimates first appeared in (Brezhnev and Kuznets 2006, \nKuznets 2000, Milnikel 2007). A comprehensive overview of all \ndecidability and complexity results can be found in (Kuznets 2008). \nSystems \\(\\mathsf{J} , \\mathsf{J4}\\), and\n \\(\\mathsf{JT}\\)\n were first considered in (Brezhnev \n2001) under different names and in a slightly different setting. \n\\(\\mathsf{JT45}\\) appeared \nindependently in (Pacuit 2006) and (Rubtsova 2006), and\n \\(\\mathsf{JD45}\\) in (Pacuit 2006). The\nlogic of uni-conclusion proofs has been found in (Krupski 1997). \nA more general approach to common knowledge based on justified\nknowledge was offered in (Artemov 2006).  Game\nsemantics of Justification Logic and Dynamic Epistemic Logic with \njustifications were studied in (Renne 2008, Renne 2009). Connections \nbetween Justification Logic and the problem of logical omniscience \nwere examined in (Artemov and Kuznets 2009, Wang 2009).\nThe name Justification Logic was introduced in\n(Artemov 2008), in which Kripke, Russell, and Gettier examples were\nformalized; this formalization has been used for the resolution of\nparadoxes, verification, hidden assumption analysis, and eliminating\nredundancies.  In (Dean and Kurokawa 2009a), Justification Logic was\nused for the analysis of Knower and Knowability paradoxes.\n \nThe first two monographs on Justification Logic were published in 2019\n(Artemov and Fitting 2019, Kuznets and Studer 2019).","contact.mail":"sartemov@gc.cuny.edu","contact.domain":"gc.cuny.edu"},{"date.published":"2011-06-22","date.changed":"2020-04-20","url":"https://plato.stanford.edu/entries/logic-justification/","author1":"Sergei Artemov","author1.info":"http://web.cs.gc.cuny.edu/~sartemov/","author2.info":"http://comet.lehman.cuny.edu/fitting","entry":"logic-justification","body.text":"\n\n\n\nYou may say, “I know that Abraham Lincoln was a tall man. \n” In turn you may be asked how you know. You would almost \ncertainly not reply semantically, Hintikka-style, that Abraham \nLincoln was tall in all situations compatible with your knowledge. \nInstead you would more likely say, “I read about Abraham \nLincoln’s height in several books, and I have seen photographs of him\nnext to other people. ” One certifies knowledge by providing a \nreason, a justification. Hintikka semantics captures knowledge as \ntrue belief. Justification logics supply the missing third component \nof Plato’s characterization of knowledge as justified true \nbelief.\n\n\n\nJustification logics are epistemic logics which allow knowledge and \nbelief modalities to be ‘unfolded’ into justification\nterms: instead of \\(\\Box X\\) one writes \n\\(t : X\\), and reads it as “\\(X\\) is justified\nby reason \\(t\\)”. One may think of traditional modal \noperators as implicit modalities, and justification terms as\ntheir explicit elaborations which supplement modal logics \nwith finer-grained epistemic machinery. The family of justification \nterms has structure and operations. Choice of operations gives rise \nto different justification logics. For all common epistemic logics \ntheir modalities can be completely unfolded into explicit \njustification form. In this respect Justification Logic reveals and \nuses the explicit, but hidden, content of traditional Epistemic Modal\nLogic. \n\nJustification logic originated as part of a successful project to \nprovide a constructive semantics for intuitionistic \nlogic—justification terms abstracted away all but the most \nbasic features of mathematical proofs. Proofs are justifications in \nperhaps their purest form. Subsequently justification logics were \nintroduced into formal epistemology.\nThis article presents the general range of justification logics as \ncurrently understood. It discusses their relationships with \nconventional modal logics. In addition to technical machinery, the \narticle examines in what way the use of explicit justification terms \nsheds light on a number of traditional philosophical problems. The \nsubject as a whole is still under active development. \n\nThe roots of justification logic can be traced back to many different\nsources, two of which are discussed in detail: epistemology and \nmathematical logic. \n\nThe properties of knowledge and belief have been a subject for formal\nlogic at least since von Wright and Hintikka, (Hintikka 1962, von \nWright 1951). Knowledge and belief are both treated as modalities in \na way that is now very familiar—Epistemic Logic. But \nof Plato’s three criteria for knowledge, justified, true, \nbelief, (Gettier 1963, Hendricks 2005), epistemic logic really \nworks with only two of them. Possible worlds and indistinguishability\nmodel belief—one believes what is so under all circumstances \nthought possible. Factivity brings a trueness component into \nplay—if something is not so in the actual world it cannot be \nknown, only believed. But there is no representation for the \njustification condition. Nonetheless, the modal approach has been \nremarkably successful in permitting the development of a rich \nmathematical theory and applications, (Fagin, Halpern, Moses, and \nVardi 1995, van Ditmarsch, van der Hoek, and Kooi 2007). Still, it is\nnot the whole picture. \n\nThe modal approach to the logic of knowledge is, in a sense, built \naround the universal quantifier: \\(X\\) is known in a situation \nif \\(X\\) is true in all situations indistinguishable \nfrom that one. Justifications, on the other hand, bring an \nexistential quantifier into the picture: \\(X\\) is known in a \nsituation if there exists a justification for \\(X\\) in \nthat situation. This universal/existential dichotomy is a familiar \none to logicians—in formal logics there exists a proof for a \nformula \\(X\\) if and only if \\(X\\) is true in all models \nfor the logic. One thinks of models as inherently non-constructive, \nand proofs as constructive things. One will not go far wrong in \nthinking of justifications in general as much like mathematical \nproofs. Indeed, the first justification logic was explicitly designed\nto capture mathematical proofs in arithmetic, something which will be\ndiscussed further in Section 1.2. \n\nIn Justification Logic, in addition to the category of formulas, \nthere is a second category of justifications. Justifications\nare formal terms, built up from constants and variables using various\noperation symbols. Constants represent justifications for commonly \naccepted truths—typically axioms. Variables denote unspecified \njustifications. Different justification logics differ on which \noperations are allowed (and also in other ways too). If \\(t\\) is\na justification term and \\(X\\) is a formula, \n\\(t : X\\) is a formula, and is intended to be read: \n  \\(t\\) is a justification for X.\n \n\nOne operation, common to all justification logics, is \napplication, written like multiplication. The idea is, if \n\\(s\\) is a justification for \\(A \\rightarrow B\\) and \n\\(t\\) is a justification for \\(A\\), then \n[\\(s\\cdot t\\)] is a justification for \n \\(B\\)[1].\n That is, the validity of the following is generally assumed: \n\nThis is the explicit version of the usual distributivity of knowledge\noperators, and modal operators generally, across implication: \n\nIn fact, formula (2) is behind many of the problems of logical \nomniscience. It asserts that an agent knows everything that is \nimplied by the agent’s knowledge—knowledge is closed under \nconsequence. While knowable-in-principle, knowability, is closed \nunder consequence, the same cannot be said for any plausible version \nof actual knowledge. The distinction between (1) and (2) can be \nexploited in a discussion of the paradigmatic Red Barn Example of \nGoldman and Kripke; here is a simplified version of the story taken \nfrom (Dretske 2005). \n\nIn the first formalization of the Red Barn Example, logical \nderivation will be performed in a basic modal logic in which \\(\\Box\\)  \nis interpreted as the ‘belief’ modality. Then some of the\noccurrences of \\(\\Box\\)  will be externally interpreted as \n‘knowledge’ according to the problem’s description. Let \n\\(B\\) be the sentence ‘the object in front of me is a \nbarn’, and let \\(R\\) be the sentence ‘the object in \nfront of me is red’. \n\nAt the metalevel, 2 is actually knowledge, whereas by the problem \ndescription, 1 is not knowledge. \n\nWithin this formalization, it appears that epistemic closure in its\nmodal form (2) is violated: line 2, \\(\\Box ( B \\wedge R )\\), and line\n3, \\(\\Box ( B \\wedge R \\rightarrow B)\\) are cases of knowledge whereas\n\\(\\Box B\\) (line 1) is not knowledge. The modal language here does not\nseem to help resolving this issue. \n\nNext consider the Red Barn Example in Justification Logic where \n\\(t : F\\) is interpreted as ‘I \nbelieve \\(F\\) for reason \\(t\\)’. Let \\(u\\) be a\nspecific individual justification for belief that \\(B\\), and \\(v\\),\nfor belief that \\(B \\wedge R\\). In addition, let \\(a\\) be a\njustification for the logical truth \\(B \\wedge R \\rightarrow B\\). Then\nthe list of assumptions is: \n\nOn the metalevel, the problem description states that 2 and 3 are \ncases of knowledge, and not merely belief, whereas 1 is belief which \nis not knowledge. Here is how the formal reasoning goes: \n\nNotice that conclusion 6 is [\\(a\\cdot v ]: B\\), \nand not \\(u : B\\) ; epistemic closure holds. By reasoning\nin justification logic it was concluded that \n[\\(a\\cdot v ]: B\\) is a case of knowledge, i.e.,\n‘I know \\(B\\) for reason \n\\(a\\cdot v\\)’. The fact that \n\\(u : B\\) is not a case of knowledge does not spoil the \nclosure principle, since the latter claims knowledge specifically for\n[\\(a\\cdot v ]: B\\). Hence after observing a red \nfaçade, I indeed know \\(B\\), but this knowledge has \nnothing to do with 1, which remains a case of belief rather than of \nknowledge. The justification logic formalization represents the \nsituation fairly. \n\nTracking justifications represents the structure of the Red Barn \nExample in a way that is not captured by traditional epistemic modal \ntools. The Justification Logic formalization models what seems to be \nhappening in such a case; closure of knowledge under logical \nentailment is maintained even though ‘barn’ is not \nperceptually \n known.[2] \n\nAccording to Brouwer, truth in constructive (intuitionistic) \nmathematics means the existence of a proof, cf. (Troelstra and van \nDalen 1988). In 1931–34, Heyting and Kolmogorov gave an \ninformal description of the intended proof-based semantics for \nintuitionistic logic (Kolmogorov 1932, Heyting 1934), which is now \nreferred to as the Brouwer-Heyting-Kolmogorov (BHK) \nsemantics. According to the BHK conditions, a formula is \n‘true’ if it has a proof. Furthermore, a proof of a \ncompound statement is connected to proofs of its components in the \nfollowing way: \n\nKolmogorov explicitly suggested that the proof-like objects in his \ninterpretation (“problem solutions”) came from classical \nmathematics (Kolmogorov 1932). Indeed, from a foundational point of \nview it does not make much sense to understand the \n‘proofs’ above as proofs in an intuitionistic system \nwhich these conditions are supposed to be specifying. \n\nThe fundamental value of the BHK semantics is that informally but \nunambiguously it suggests treating justifications, here mathematical \nproofs, as objects with operations. \n\nIn (Gödel 1933), Gödel took the first step towards \ndeveloping a rigorous proof-based semantics for intuitionism. \nGödel considered the classical modal logic\n \\(\\mathsf{S4}\\)\n to be a calculus describing \nproperties of provability: \n\nBased on Brouwer’s understanding of logical truth as provability, \nGödel defined a translation tr\\((F)\\) of the propositional \nformula \\(F\\) in the intuitionistic language into the language \nof classical modal logic: tr\\((F)\\) is obtained by prefixing \nevery subformula of \\(F\\) with the provability modality \\(\\Box\\).\nInformally speaking, when the usual procedure of determining \nclassical truth of a formula is applied to tr\\((F)\\), it will \ntest the provability (not the truth) of each of \\(F\\)’s \nsubformulas, in agreement with Brouwer’s ideas. From Gödel’s \nresults and the McKinsey-Tarski work on topological semantics for \nmodal logic, it follows that the translation tr\\((F)\\) provides \na proper embedding of the Intuitionistic Propositional Calculus, \n\\(\\mathsf{IPC}\\), into\n \\(\\mathsf{S4}\\), i.e., an embedding of \nintuitionistic logic into classical logic extended by the provability\noperator. \n\nStill, Gödel’s original goal of defining intuitionistic\nlogic in terms of classical provability was not reached, since the\nconnection of \\(\\mathsf{S4}\\) to the usual mathematical notion of\nprovability was not established. Moreover, Gödel noted that the\nstraightforward idea of interpreting modality \\(\\Box F\\) as F is\nprovable in a given formal system T contradicted\nGödel’s second incompleteness theorem. Indeed, \\(\\Box (\n\\Box F \\rightarrow F)\\) can be derived in \\(\\mathsf{S4}\\) by the rule\nof necessitation from the axiom \\(\\Box F \\rightarrow F\\). On the other\nhand, interpreting modality \\(\\Box\\) as the predicate of formal\nprovability in theory \\(T\\) and \\(F\\) as contradiction, converts this\nformula into a false statement that the consistency of \\(T\\) is\ninternally provable in \\(T\\). \n\nThe situation after (Gödel 1933) can be described by the \nfollowing figure where ‘\\(X \\hookrightarrow Y\\)’\n should be read as ‘\\(X\\) is interpreted in \n\\(Y\\)’ \n\nIn a public lecture in Vienna in 1938, Gödel observed that using\nthe format of explicit proofs: \n\ncan help in interpreting his provability calculus\n \\(\\mathsf{S4}\\) (Gödel 1938). Unfortunately, \nGödel’s work (Gödel 1938) remained unpublished until 1995, \nby which time the Gödelian logic of explicit proofs had already \nbeen rediscovered, and axiomatized as the Logic of Proofs\n \\(\\mathsf{LP}\\) and supplied with \ncompleteness theorems connecting it to both\n \\(\\mathsf{S4}\\)\n and classical proofs (Artemov 1995). \n\nThe Logic of Proofs\n \\(\\mathsf{LP}\\)\n became the first in the Justification Logic \nfamily. Proof terms in\n \\(\\mathsf{LP}\\)\n are nothing but BHK terms understood as \nclassical proofs. With\n \\(\\mathsf{LP}\\),\n propositional intuitionistic logic received \nthe desired rigorous BHK semantics: \n\nFor further discussion of the mathematical logic tradition, see the \n Section 1 of the supplementary document \n  Some More Technical Matters. The hyperintensional paradox was formulated by Cresswell in 1975. It is well known that it seems possible to have a situation in\nwhich there are two propositions \\(p\\) and \\(q\\) which are logically\nequivalent and yet are such that a person may believe the one but not\nthe other. If we regard a proposition as a set of possible worlds then\ntwo logically equivalent propositions will be identical, and so if\n‘\\(x\\) believes that’ is a genuine sentential functor, the\nsituation described in the opening sentence could not arise. I call\nthis the paradox of hyperintensional contexts. Hyperintensional\ncontexts are simply contexts which do not respect logical\nequivalence. Starting with Cresswell himself, several ways of dealing with this\nhave been proposed. Generally these involve adding more layers to\nfamiliar possible world approaches so that some way of distinguishing\nbetween logically equivalent sentences is available. Cresswell\nsuggested that the syntactic form of sentences be taken into\naccount. Justification Logic, in effect, takes sentence form into\naccount through its mechanism for handling justifications for\nsentences. Thus Justification Logic addresses some of the central\nissues of hyperintensionality and, as a bonus, we automatically have\nan appropriate proof theory, model theory, complexity estimates and a\nbroad variety of applications. A good example of a hyperintensional context is the informal\nlanguage used by mathematicians conversing with each other. Typically\nwhen a mathematician says he or she knows something, the understanding\nis that a proof is at hand. But as the following illustrates, this\nkind of knowledge is essentially hyperintensional. Fermat’s Last Theorem, FLT, is logically equivalent to\n\\(0=0\\) since both are provable, and hence denote the same\nproposition. However, the context of proofs distinguishes them\nimmediately: a proof \\(t\\) of \\(0=0\\) is not necessarily a proof of\nFLT, and vice versa. To formalize mathematical speech the justification logic\n\\({\\textsf{LP}}\\) is a natural choice since \\(t{:}X\\) was designed to\nhave characteristics of “\\(t\\) is a proof of\n\\(X\\).” The fact that propositions \\(X\\) and \\(Y\\) are equivalent in\n\\({\\textsf{LP}}\\), \\(X\\leftrightarrow Y\\), does not warrant the\nequivalence of the corresponding justification assertions and\ntypically \\(t{:}X\\) and \\(t{:}Y\\) are not equivalent,\n\\(t{:}X\\not\\leftrightarrow t{:}Y\\). Going further \\({\\textsf{LP}}\\), and Justification Logic in\ngeneral, is not only sufficiently refined to distinguish justification\nassertions for logically equivalent sentences, it provides a flexible\nmachinery to connect justifications of equivalent sentences and hence\nto maintain constructive closure properties necessary for a quality\nlogic system. For example, let \\(X\\) and \\(Y\\) be provably equivalent,\ni.e., there is a proof \\(u\\) of \\(X\\leftrightarrow Y\\), and so\n\\(u{:}(X\\leftrightarrow Y)\\) is provable in \\({\\textsf{LP}}\\). Suppose\nalso that \\(v\\) is a proof of \\(X\\), and so \\(v{:}X\\). It has already\nbeen mentioned that this does not mean \\(v\\) is a proof of\n\\(Y\\)—this is a hyperintensional context. However within the\nframework of Justification Logic, building on the proofs of \\(X\\) and\nof \\(X\\leftrightarrow Y\\), we can construct a proof term\n\\(f(u,v)\\) which represents the proof of \\(Y\\) and so \\(f(u,v){:}Y\\)\nis provable. In this respect, Justification Logic goes beyond\nCresswell’s expectations: logically equivalent sentences display\ndifferent but constructively controlled epistemic behavior. \n\nIn this section the syntax and axiomatics of the most common systems \nof justification logic are presented. \n\nIn order to build a formal account of justification logics one must \nmake a basic structural assumption: justifications are abstract \nobjects which have structure and operations on them. A good \nexample of justifications is provided by formal proofs, which have \nlong been objects of study in mathematical logic and computer science\n(cf. Section 1.2). \n\nJustification Logic is a formal logical framework which incorporates \nepistemic assertions \\(t : F\\), standing for \n‘\\(t\\) is a justification for \\(F\\)’. \nJustification Logic does not directly analyze what it means for \n\\(t\\) to justify \\(F\\) beyond the format \n\\(t : F\\), but rather attempts to characterize this \nrelation axiomatically. This is similar to the way Boolean logic \ntreats its connectives, say, disjunction: it does not analyze the \nformula \\(p \\vee q\\) but rather assumes certain logical\naxioms and truth tables about this formula. \n\nThere are several design decisions made. Justification Logic starts \nwith the simplest base: classical Boolean logic, and for good\nreasons. Justifications provide a sufficiently serious challenge on \neven the simplest level. The paradigmatic examples by Russell, \nGoldman-Kripke, Gettier and others, can be handled with Boolean \nJustification Logic. The core of Epistemic Logic consists of modal \nsystems with a classical Boolean base\n (K, T, K4, S4, K45, KD45, S5,\n etc.), and each of \nthem has been provided with a corresponding Justification Logic \ncompanion based on Boolean logic. Finally, factivity of \njustifications is not always assumed. This makes it possible to \ncapture the essence of discussions in epistemology involving matters \nof belief and not knowledge. \n\nThe basic operation on justifications\nis application. The application operation takes\njustifications \\(s\\) and \\(t\\) and produces a justification \\(s\\cdot\nt\\) such that if \\(s :( F \\rightarrow G)\\) and \\(t : F\\), then\n[\\(s\\cdot t ]: G\\). Symbolically, \n\nThis is a basic property of justifications assumed in combinatory \nlogic and \\(\\lambda\\)  -calculi (Troelstra and Schwichtenberg \n1996), Brouwer-Heyting-Kolmogorov semantics (Troelstra and van Dalen \n1988), Kleene realizability (Kleene 1945), the Logic of Proofs\n \\(\\mathsf{LP}\\),\n etc. \n\nAnother common operation on justifications is sum: it has been introduced to\nmake explicit the modal logic reasoning (Artemov 1995).  However, some meaningful\njustification logics like \\({\\mathsf{J}}^{-}\\) (Artemov and Fitting 2019)\ndo not use the operation sum.  With sum, any two justifications can safely be combined\ninto something with broader scope.  If \\(s : F\\), \nthen whatever evidence \\(t\\) may be, the combined evidence \n\\(s\\) + \\(t\\) remains a justification for \\(F\\). More \nproperly, the operation ‘+’ takes justifications \n\\(s\\) and \\(t\\) and produces \\(s\\) + \\(t\\), which\nis a justification for everything justified by \\(s\\) or by \n\\(t\\). \n\nAs motivation, one might think of \\(s\\) and \\(t\\) as two \nvolumes of an encyclopedia, and \\(s\\) + \\(t\\) as the set of\nthose two volumes. Imagine that one of the volumes, say \\(s\\), \ncontains a sufficient justification for a proposition \\(F\\), \ni.e., \\(s : F\\) is the case. Then the larger set \n\\(s\\) + \\(t\\) also contains a sufficient justification for \n\\(F\\), [\\(s\\) + \\(t ]: F\\). In the Logic of \nProofs \\(\\mathsf{LP}\\), Section \n1.2, ‘\\(s\\) + \\(t\\)’ can be interpreted as a \nconcatenation of proofs \\(s\\) and \\(t\\). \n\nJustification terms are built from justification variables \n\\(x , y , z\\), … and justification \nconstants \\(a , b , c\\), … (with indices \n\\(i\\) = 1, 2, 3, … which are omitted whenever it is safe)\nby means of the operations ‘\\(\\cdot\\) ’ and ‘+’. \nMore elaborate logics considered below also allow additional \noperations on justifications. Constants denote atomic justifications \nwhich the system does not analyze; variables denote unspecified \njustifications. The Basic Logic of Justifications,\n \\(\\mathsf{J}_{0}\\) is axiomatized by the \nfollowing. \n\n\\(\\mathsf{J}_{0}\\) is the\nlogic of general (not necessarily factive) justifications for an \nabsolutely skeptical agent for whom no formula is provably justified,\ni.e., \\(\\mathsf{J}_{0}\\) \ndoes not derive \\(t : F\\) for any \\(t\\) and \n\\(F\\). Such an agent is, however, capable of drawing \nrelative justification conclusions of the form \n\nWith this capacity\n \\(\\mathsf{J}_{0}\\)\n is able to adequately emulate many other \nJustification Logic systems in its language. \n\nThe Logical Awareness principle states that logical axioms \nare justified ex officio: an agent accepts logical axioms as\njustified (including the ones concerning justifications). As just \nstated, Logical Awareness may be too strong in some epistemic \nsituations. However Justification Logic offers the flexible mechanism\nof Constant Specifications to represent varying shades of Logical \nAwareness. \n\nOf course one distinguishes between an assumption and a justified \nassumption. In Justification Logic constants are used to represent \njustifications of assumptions in situations where they are not \nanalyzed any further. Suppose it is desired to postulate that an \naxiom \\(A\\) is justified for the knower. One simply postulates \n\\(e_{1} : A\\) for some evidence constant \n\\(e_{1}\\) (with index 1). If, furthermore, it is desired\nto postulate that this new principle \n\\(e_{1} : A\\) is also justified, one can \npostulate \\(e_{2} :( e_{1} : A)\\) \nfor a constant \\(e_{2}\\) (with index 2). And so on. \nKeeping track of indices is not necessary, but it is easy and helps \nin decision procedures (Kuznets 2008). The set of all assumptions of \nthis kind for a given logic is called a Constant \nSpecification. Here is the formal definition: \n\nA Constant Specification \\(CS\\) for a given \njustification logic \\(\\mathcal{L}\\) is a set of \nformulas of the form \n\nwhere \\(A\\) is an axiom of \\(\\mathcal{L}\\), and \n\\(e_{1} , e_{2}, \\ldots, e_{n}\\) are similar constants with indices 1,\n2, …, \\(n\\). It is assumed that \\(CS\\) contains all \nintermediate specifications, i.e., whenever \n\\(e_{n} : e_{n- 1}:\\ldots:e_{1} : A\\)\nis in \\(CS\\), then \n\\(e_{n- 1}:\\ldots:e_{1} : A\\)\nis in \\(CS\\) too. \n\nThere are a number of special conditions that have been placed on \nconstant specifications in the literature. The following are the most\ncommon. We may now specify: \n  Logic of Justifications:\n  \\(\\mathsf{J}\\)\n is the logic\n \\(\\mathsf{J}_{0}\\) + \nAxiom Internalization Rule. The new rule states: \n      For each axiom \\(A\\) and any\n      constants \\(e_{1} , e_{2}, \\ldots, e_{n}\\)\n      infer \\(e_{n} : e_{n- 1} : \\ldots : e_{1} : A\\).\n     The latter embodies the idea of unrestricted Logical Awareness for\n\\(\\mathsf{J}\\). A similar rule appeared in the Logic of Proofs\n\\(\\mathsf{LP}\\), and has also been anticipated in Goldman’s\n(Goldman 1967). Logical Awareness, as expressed by axiomatically\nappropriate Constant Specifications, is an explicit incarnation of the\nNecessitation Rule in Modal Logic: \\(\\vdash F \\Rightarrow\\, \\vdash \\Box\nF\\), but restricted to axioms. Note that \\(\\mathsf{J}\\) coincides with\n\\(\\mathsf{J}_{TCS}\\). \n\nThe key feature of Justification Logic systems is their ability to \ninternalize their own derivations as provable justification \nassertions within their languages. This property was anticipated in \n(Gödel 1938). \n\nTheorem 1: For each axiomatically appropriate \nconstant specification \\(CS\\), J\\(_{CS}\\) enjoys \nInternalization: \nIf \\(\\vdash F\\), then \\(\\vdash p : F\\) for some justification term \\(p\\).\n   \n\nProof. Induction on derivation length. Suppose\n\\(\\vdash\\)  \\(F\\). If \\(F\\) is a member of \\(\\mathsf{J}_{0}\\),\nor a member of \\(CS\\), there is a constant \\(e_{n}\\) (where \\(n\\)\nmight be 1) such that \\(e_{n} : F\\) is in \\(CS\\), since \\(CS\\) is\naxiomatically appropriate. Then \\(e_{n} : F\\) is derivable. If \\(F\\)\nis obtained by Modus Ponens from \\(X \\rightarrow F\\) and\n\\(X\\), then, by the Induction Hypothesis, \\(\\vdash s :( X \\rightarrow\nF)\\) and \\(\\vdash t : X\\) for some \\(s , t\\). Using the Application\nAxiom, \\(\\vdash [ s\\cdot t ]: F\\). \n\nSee Section 2 of the supplementary document\n Some More Technical Matters\n for examples of concrete syntactic derivations in\n justification logic. The basic justification logic \\({\\textsf{J}}_0\\), and its extension\nwith a constant specification \\({\\textsf{J}}_{CS}\\), is an explicit\ncounterpart of the smallest normal modal logic \\({\\textsf{K}}\\). A\nproper definition of counterpart will be given in Section 4\nbecause the notion of realization is central, but some hints\nare already apparent at this stage of our presentation. For instance,\nit was noted in Section 1.1 that (1), \\(s{:}(A\\rightarrow\nB)\\rightarrow(t{:}A\\rightarrow [s\\cdot t]{:}B)\\), is an explicit\nversion of the familiar modal principle (2), \\({\\square}(A\\rightarrow\nB) \\rightarrow ({\\square}A\\rightarrow {\\square}B)\\). In a similar way\nthe first justification logic \\(\\textsf{LP}\\) is an explicit\ncounterpart of modal \\({\\textsf{S4}}\\). It turns out that many modal\nlogics have justification logic counterparts—indeed, generally\nmore than one. In what follows we begin by discussing some very\nfamiliar logics, leading up to \\({\\textsf{S4}}\\) and\n\\(\\textsf{LP}\\). Up to this point much of our original motivation\napplies—we have justification logics that are interpretable in\narithmetic. Then we move on to a broader family of modal logics, and\nthe arithmetic motivation is no longer applicable. The phenomenon of\nhaving a modal logic with a justification logic counterpart has turned\nout to be unexpectedly broad. In almost all cases, one must add operations to the \\(+\\) and\n\\(\\cdot\\) of \\({\\textsf{J}}_0\\), along with axioms capturing their\nintended behavior. The exception is factivity, discussed next, for\nwhich no additional operations are required, though additional axioms\nare. It is always understood that constant specifications cover axioms\nfrom the enlarged set. We continue using the terminology of Section\n2.3; for instance a constant specification is axiomatically\nappropriate if it meets the condition as stated there, for all\naxioms including any that have been added to the original set.\nTheorem 1 from Section 2.3 continues to apply to our new justification\nlogics, and with the same proof: if we have a justification logic\n\\(\\textsf{JL}_{CS}\\) with an axiomatically appropriate constant\nspecification, Internalization holds. \n\nFactivity states that justifications are sufficient for an agent to \nconclude truth. This is embodied in the following. \n  Factivity Axiom \\(t : F \\rightarrow F\\).\n \n\nThe Factivity Axiom has a similar motivation to the Truth Axiom of \nEpistemic Logic, \\(\\Box F \\rightarrow F\\), which is widely\naccepted as a basic property of knowledge. \n\nFactivity of justifications is not required in basic Justification Logic \nsystems, which makes them capable of representing both partial and\nfactive justifications.\nThe Factivity Axiom appeared in the Logic of Proofs \n\\(\\mathsf{LP}\\), Section 1.2, as \na principal feature of mathematical proofs. Indeed, in this setting \nFactivity is clearly valid: if there is a mathematical proof \n\\(t\\) of \\(F\\), then \\(F\\) must be true. \n\nThe Factivity Axiom is adopted for justifications that lead to \nknowledge. However, factivity alone does not warrant knowledge, as \nhas been demonstrated by the Gettier examples (Gettier 1963). \n\nLogic of Factive Justifications: \n\nSystems \\(\\mathsf{JT}_{CS}\\) corresponding to Constant\nSpecifications \\(CS\\) are defined as in Section 2.3. \n\nOne of the common principles of knowledge is identifying \nknowing and knowing that one knows. In a modal\nsetting, this corresponds to \\(\\Box F \\rightarrow \\Box \\Box F\\). This\nprinciple has an adequate explicit counterpart: the fact that an agent\naccepts \\(t\\) as sufficient evidence for \\(F\\) serves as sufficient\nevidence for \\(t : F\\). Often such ‘meta-evidence’ has a\nphysical form: a referee report certifying that a proof in a paper is\ncorrect; a computer verification output given a formal proof \\(t\\) of\n\\(F\\) as an input; a formal proof that \\(t\\) is a proof of \\(F\\),\netc. A Positive Introspection operation ‘!’ may\nbe added to the language for this purpose; one then assumes that given\n\\(t\\), the agent produces a justification !\\(t\\) of \\(t : F\\) such\nthat \\(t : F \\rightarrow ! t :( t : F)\\).  Positive Introspection in\nthis operational form first appeared in the Logic of Proofs\n\\(\\mathsf{LP}\\). \n  Positive Introspection Axiom: \\(t : F \\rightarrow ! t :( t : F)\\).\n \n\nWe then define: \n\nLogics \\(\\mathsf{J4}_{0} , \\mathsf{J4}_{CS} , \\mathsf{LP}_{0}\\), and\n \\(\\mathsf{LP}_{CS}\\) are defined in\nthe natural way (cf. Section 2.3). \n\nIn the presence of the Positive Introspection Axiom, one can limit \nthe scope of the Axiom Internalization Rule to internalizing axioms \nwhich are not of the form \\(e : A\\). This is how it was \ndone in \\(\\mathsf{LP}\\): Axiom \nInternalization can then be emulated by using \n!!\\(e :(! e :( e : A))\\) instead of \n\\(e_{3} :( e_{2} :( e_{1} : A))\\), etc.\nThe notion of Constant Specification can also be simplified \naccordingly. Such modifications are minor and they do not affect the \nmain theorems and applications of Justification Logic. \n\n(Pacuit 2006, Rubtsova 2006) considered the Negative\nIntrospection operation ‘?’ which verifies that a\ngiven justification assertion is false. A possible motivation for\nconsidering such an operation is that the positive introspection\noperation ‘!’ may well be regarded as capable of\nproviding conclusive verification judgments about the\nvalidity of justification assertions \\(t : F\\), so when \\(t\\) is not a\njustification for \\(F\\), such a ‘!’ should conclude that\n\\(\\neg t : F\\). This is normally the case for computer proof\nverifiers, proof checkers in formal theories, etc. This motivation is,\nhowever, nuanced: the examples of proof verifiers and proof checkers\nwork with both \\(t\\) and \\(F\\) as inputs, whereas the Pacuit-Rubtsova\nformat ?\\(t\\) suggests that the only input for ‘?’ is a\njustification \\(t\\), and the result ?\\(t\\) is supposed to justify\npropositions \\(\\neg t : F\\) uniformly for all \\(F\\)s for which \\(t :\nF\\) does not hold. Such an operation ‘?’ does not exist\nfor formal mathematical proofs since ?\\(t\\) should then be a single\nproof of infinitely many propositions \\(\\neg t : F\\), which is\nimpossible.  The operation ‘?’ was, historically, the\nfirst example that did not fit into the original framework in which\njustifications were abstract versions of formal proofs.\n \n  Negative Introspection Axiom\n  \\(\\neg t : F \\rightarrow ? t :( \\neg t : F)\\)\n \n\nWe define the systems: \n\nand naturally extend these definitions to\n \\(\\mathsf{J}45_{CS} , \\mathsf{JD}45_{CS}\\), and\n \\(\\mathsf{JT}45_{CS}\\). Justification logics involving \\(?\\) were the first examples that\nwent beyond sublogics of \\({\\textsf{LP}}\\). More recently it has been\ndiscovered that there is an infinite family of modal logics\nthat have justification counterparts, but for which the connection\nwith arithmetic proofs is weak or missing. We discuss a single case in\nsome detail, and sketch others. Peter Geach proposed the axiom scheme\n\\({\\lozenge}{\\square}X{\\rightarrow}{\\square}{\\lozenge}X\\). When added\nto axiomatic \\({\\textsf{S4}}\\) it yields an interesting logic known as\n\\(\\textsf{S4.2}\\). Semantically, Geach’s scheme\nimposes confluence on frames. That is, if two possible\nworlds, \\(w_1\\) and \\(w_2\\) are accessible from the same world\n\\(w_0\\), there is a common world \\(w_4\\) accessible from both \\(w_1\\)\nand \\(w_2\\). Geach’s scheme was generalized\nin Lemmon and Scott (1977) and a\ncorresponding notation was introduced: \\({\\textsf{G}}^{k,l,m,n}\\) is\nthe scheme \\({\\lozenge}^k{\\square}^l X\n{\\rightarrow}{\\square}^m{\\lozenge}^n X\\), where \\(k, l, m, n\\geq\n0\\). Semantically these schemes correspond to generalized versions of\nconfluence. Some people have begun referring to the schemes\nas Geach schemes, and we will follow this practice. More\ngenerally, we will call a modal logic a Geach logic if it can\nbe axiomatized by adding a finite set of Geach schemes to\n\\({\\textsf{K}}\\). The original Geach scheme is\n\\({\\textsf{G}}^{1,1,1,1}\\), but also note that\n\\({\\square}X{\\rightarrow}X\\) is \\({\\textsf{G}}^{0,1,0,0}\\),\n\\({\\square}X{\\rightarrow}{\\square}{\\square}X\\) is\n\\({\\textsf{G}}^{0,1,2,0}\\),\n\\({\\lozenge}X{\\rightarrow}{\\square}{\\lozenge}X\\) is\n\\({\\textsf{G}}^{1,0,1,1}\\), and \\(X{\\rightarrow}{\\square}{\\lozenge}X\\)\nis \\({\\textsf{G}}^{0,0,1,1}\\), so Geach logics include the most common\nof the modal logics. Geach logics constitute an infinite family. Every Geach logic has a justification counterpart. Consider the\noriginal Geach logic, with axiom scheme \\(\\textsf{G}^{1,1,1,1}\\),\n\\({\\lozenge}{\\square}X{\\rightarrow}{\\square}{\\lozenge}X\\) added to a\nsystem for \\(\\textsf{S4}\\)—the system \\(\\textsf{S4.2}\\)\nmentioned above. We build a justification counterpart for\n\\(\\textsf{S4.2}\\) axiomatically by starting with\n\\({\\textsf{LP}}\\). Then we add two function symbols, \\(f\\) and \\(g\\),\neach two-place, and adopt the following axiom scheme, calling the\nresulting justification logic \\(\\textsf{J4.2}\\).  \nThere\nis some informal motivation for this scheme. In \\({\\textsf{LP}}\\),\nbecause of the axiom scheme \\(t{:}X{\\rightarrow}X\\), we have\nprovability of \\((t{:}X\\land u{:}\\lnot X){\\rightarrow}\\bot\\) for any\n\\(t\\) and \\(u\\), and thus provability of \\(\\lnot t{:}X \\lor\\lnot\nu{:}\\lnot X\\). In any context one of the disjuncts must hold. The\nscheme above is equivalent to \\(f(t,u){:}\\lnot t{:}X \\lor\ng(t,u){:}\\lnot u{:}\\lnot X\\), which informally says that in any\ncontext we have means for computing a justification for the disjunct\nthat holds. It is a strong assumption, but not implausible at least in\nsome circumstances. A realization theorem connects \\(\\textsf{S4.2}\\) and\n\\(\\textsf{J4.2}\\), though it is not known if this has a constructive\nproof. As another example, consider \\({\\textsf{G}}^{1,2,2,1}\\),\n\\({\\lozenge}{\\square}{\\square}X{\\rightarrow}{\\square}{\\square}{\\lozenge}X\\),\nor equivalently \\({\\square}\\lnot{\\square}{\\square}X \\lor\n{\\square}{\\square}\\lnot{\\square}X\\). It has as a corresponding\njustification axiom scheme the following, where \\(f\\), \\(g\\), and\n\\(h\\) are three-place function symbols. \nAn intuitive\ninterpretation for \\(f\\), \\(g\\), and \\(h\\) is not as clear as it is\nfor \\(\\textsf{G}^{1,1,1,1}\\), but formally things behave quite\nwell. Even though the Geach family is infinite, these logics do not cover\nthe full range of logics with justification counterparts. For\ninstance, the normal modal logic using the axiom scheme\n\\({\\square}({\\square}X{\\rightarrow}X)\\), sometimes called shift\nreflexivity, is not a Geach logic, but it does have a\njustification counterpart. Add a one-place function symbol \\(k\\) to\nthe machinery building up justification terms, and adopt the\njustification axiom scheme \\(k(t){:}(t{:}X{\\rightarrow}X)\\). A\nRealization Theorem holds; this is shown\nin Fitting (2014b). We speculate that\nall logics axiomatized with Sahlquist formulas will have justification\ncounterparts, but this remains a conjecture at this point. \n\nThe now-standard semantics for justification logic originates in\n(Fitting 2005)—the models used are generally called Fitting\nmodels in the literature, but will be called possible world\njustification models here. Possible world justification models\nare an amalgam of the familiar possible world semantics for logics of\nknowledge and belief, due to Hintikka and Kripke, with machinery\nspecific to justification terms, introduced by Mkrtychev in (Mkrtychev\n1997), (cf. Section 3.4). \n\nTo be precise, a semantics for \\(\\mathsf{J}_{CS}\\), where \\(CS\\) is\nany constant specification, is to be defined. Formally, a possible\nworld justification logic model for \\(\\mathsf{J}_{CS}\\) is a\nstructure \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R} ,\n\\mathcal{E} , \\mathcal{V}\\rangle\\) . Of this, \\(\\langle \\mathcal{G} ,\n\\mathcal{R}\\rangle\\) is a standard \\(\\mathsf{K}\\) frame, where\n\\(\\mathcal{G}\\) is a set of possible worlds and \\(\\mathcal{R}\\) is a\nbinary relation on it.  \\(\\mathcal{V}\\) is a mapping from\npropositional variables to subsets of \\(\\mathcal{G}\\), specifying\natomic truth at possible worlds. \n\nThe new item is \\(\\mathcal{E}\\), an evidence \nfunction, which originated in (Mkrtychev 1997). This maps \njustification terms and formulas to sets of worlds. The intuitive \nidea is, if the possible world \\(\\Gamma\\)  is in\n \\(\\mathcal{E} ( t , X)\\), then \\(t\\) is \nrelevant or admissible evidence for \\(X\\) at \nworld \\(\\Gamma\\) . One should not think of relevant evidence as \nconclusive. Rather, think of it as more like evidence that can be \nadmitted in a court of law: this testimony, this document is \nsomething a jury should examine, something that is pertinent, but \nsomething whose truth-determining status is yet to be considered. \nEvidence functions must meet certain conditions, but these are \ndiscussed a bit later. \n\nGiven a \\(\\mathsf{J}_{CS}\\) possible world justification model\n\\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R} , \\mathcal{E} ,\n\\mathcal{V}\\rangle\\) , truth of formula \\(X\\) at possible world\n\\(\\Gamma\\) is denoted by \\(\\mathcal{M} , \\Gamma \\Vdash X\\), and is\nrequired to meet the following standard conditions: \n\nFor each \\(\\Gamma \\in \\mathcal{G}\\): \n\nThese just say that atomic truth is specified arbitrarily, and \npropositional connectives behave truth-functionally at each world. \nThe key item is the next one. \n\nThis condition breaks into two parts. The clause requiring that\n \\(\\mathcal{M} , \\Delta \\Vdash X\\) for every \\(\\Delta \\in\n \\mathcal{G}\\) such that \\(\\Gamma \\mathcal{R} \\Delta\\) is the familiar\n Hintikka/Kripke condition for \\(X\\) to be believed, or be believable,\n at \\(\\Gamma\\) . The clause requiring that \\(\\Gamma \\in \\mathcal{E} (\n t , X)\\) adds that \\(t\\) should be relevant evidence for \\(X\\) at\n \\(\\Gamma\\) . Then, informally, \\(t : X\\) is true at a possible world\n if \\(X\\) is believable at that world in the usual sense of epistemic\n logic, and \\(t\\) is relevant evidence for \\(X\\) at that world. \n\nIt is important to realize that, in this semantics, one might not \nbelieve something for a particular reason at a world either because \nit is simply not believable, or because it is but the reason is not \nappropriate. \n\nSome conditions must still be placed on evidence functions, and the \nconstant specification must also be brought into the picture. Suppose\none is given \\(s\\) and \\(t\\) as justifications. One can \ncombine these in two different ways: simultaneously use the \ninformation from both; or use the information from just one of them, \nbut first choose which one. Each gives rise to a basic operation on \njustification terms, \\(\\cdot\\)  and +, introduced axiomatically in \nSection 2.2. \n\nSuppose \\(s\\) is relevant evidence for an implication and \n\\(t\\) is relevant evidence for the antecedent. Then \\(s\\) \nand \\(t\\) together provides relevant evidence for the \nconsequent. The following condition on evidence functions is assumed: \n\nWith this condition added, the validity of \n\nis secured. \n\nIf \\(s\\) and \\(t\\) are items of evidence, one might say \nthat something is justified by one of \\(s\\) or \\(t\\), \nwithout bothering to specify which, and this will still be evidence. \nThe following requirement is imposed on evidence functions. \n\nNot surprisingly, both \n\nand \n\nnow hold. \n\nFinally, the Constant Specification \\(CS\\) should be taken into \naccount. Recall that constants are intended to represent reasons for \nbasic assumptions that are accepted outright. A model\n \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R} , \\mathcal{E} , \\mathcal{V}\\rangle\\)  \nmeets Constant Specification \\(CS\\) provided: if \n\\(c : X \\in CS\\) then\n \\(\\mathcal{E}\\)(c,X) = \\(\\mathcal{G}\\). \nPossible World Justification Model A possible world\n justification model for \\(\\mathsf{J}_{CS}\\) is a structure\n \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R} , \\mathcal{E} ,\n \\mathcal{V}\\rangle\\) satisfying all the conditions listed above, and\n meeting Constant Specification \\(CS\\).\n \n\nDespite their similarities, possible world justification models allow\na fine-grained analysis that is not possible with Kripke models. See\nSection 3 of the supplementary document\n Some More Technical Matters\nfor more details. \n\nA formula \\(X\\) is valid in a particular model for \n\\(\\mathsf{J}_{CS}\\) if it is true at all \npossible worlds of the model. Axiomatics for\n \\(\\mathsf{J}_{CS}\\) was given in \nSections 2.2 and 2.3. A completeness theorem now takes the expected \nform. \n Theorem 2: A formula \\(X\\) is provable\n in \\(\\mathsf{J}_{CS}\\)\n if and only if \\(X\\) is valid\n in all \\(\\mathsf{J}_{CS}\\) models.\n \n\nThe completeness theorem as just stated is sometimes referred to as \nweak completeness. It maybe a bit surprising that it is \nsignificantly easier to prove than completeness for the modal logic \n\\(\\mathsf{K}\\). Comments on this \npoint follow. On the other hand it is very general, working for all \nConstant Specifications. \n\nIn (Fitting 2005) a stronger version of the semantics was also\nintroduced. A model \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R}\n, \\mathcal{E} , \\mathcal{V}\\rangle\\) is called fully\nexplanatory if it meets the following condition. For each\n\\(\\Gamma \\in \\mathcal{G}\\), if \\(\\mathcal{M} , \\Delta \\Vdash X\\) for\nall \\(\\Delta \\in \\mathcal{G}\\) such that \\(\\Gamma \\mathcal{R} \\Delta\\)\n, then \\(\\mathcal{M} , \\Gamma \\Vdash t : X\\) for some justification\nterm \\(t\\). Note that the condition, \\(\\mathcal{M} , \\Delta \\Vdash X\\)\nfor all \\(\\Delta \\in \\mathcal{G}\\) such that \\(\\Gamma \\mathcal{R}\n\\Delta\\) , is the usual condition for \\(X\\) being believable at\n\\(\\Gamma\\) in the Hintikka/Kripke sense.  So, fully explanatory really\nsays that if a formula is believable at a possible world, there is a\njustification for it. \n\nNot all weak models meet the fully explanatory condition. Models that\ndo are called strong models. If constant specification \n\\(CS\\) is rich enough so that an Internalization theorem holds, \nthen one has completeness with respect to strong models meeting \n\\(CS\\). Indeed, in an appropriate sense completeness with \nrespect to strong models is equivalent to being able to prove \nInternalization. \n\nThe proof of completeness with respect to strong models bears a close\nsimilarity to the proof of completeness using canonical models for \nthe modal logic \\(\\mathsf{K}\\). \nIn turn, strong models can be used to give a semantic proof of the \nRealization Theorem (cf. Section 4). \n\nSo far a possible world semantics for one justification logic has been \ndiscussed, for \\(\\mathsf{J}\\), \nthe counterpart of\n \\(\\mathsf{K}\\). Now things are broadened to encompass \njustification analogs of other familiar modal logics. Simply by adding reflexivity of the accessibility relation\n\\(\\mathcal{R}\\) to the conditions for a model in Section 3.1, one\ngains the validity of \\(t{:}X \\rightarrow X\\) for every \\(t\\) and\n\\(X\\), and obtains a semantics for \\(\\mathsf{JT}\\), the justification logic analog of\nthe modal logic \\({\\textsf{T}}\\), the weakest logic of\nknowledge. Indeed, if \\({\\mathcal{M},\\Gamma{\\Vdash}t{:}X}\\) then, in particular,\n\\(X\\) is true at every state accessible from \\(\\Gamma\\). Since the\naccessibility relation is required to be reflexive,\n\\({\\mathcal{M},\\Gamma{\\Vdash}X}\\). Weak and strong completeness theorems are\nprovable using the same machinery that applied in the case of \\(\\textsf{J}\\), and a\nsemantic proof of a Realization Theorem connecting  \\(\\mathsf{JT}\\) and\n\\({\\textsf{T}}\\) is also available. The same applies to the logics\ndiscussed below. For a justification analog of \\({\\textsf{K4}}\\) an additional unary\noperator ‘!’ is added to the term language, see Section\n2.5. Recall this operator maps justifications to justifications, where\nthe idea is that if \\(t\\) is a justification for \\(X\\), then \\(!t\\)\nshould be a justification for \\(t{:}X\\). Semantically this adds\nconditions to a model \\(\\mathcal{M} = \\langle\n\\mathcal{G},\\mathcal{R},\\mathcal{E},\\mathcal{V}\\rangle\\), as\nfollows. First, of course, \\(\\mathcal{R}\\) should be transitive, but not\nnecessarily reflexive. Second, a monotonicity condition on evidence\nfunctions is required: \\[\\mbox{If } \\Gamma \\mathcal{R} \\Delta \\mbox{ and } \\Gamma\\in\n\\mathcal{E}(t,X) \\mbox{ then } \\Delta \\in \\mathcal{E}(t,X)\\] And\nfinally, one more evidence function condition is needed. \\[\\mathcal{E}(t,X) \\subseteq \\mathcal{E}(!t,t{:}X)\\] These\nconditions together entail the validity of \\(t{:}X \\rightarrow\n!t{:}t{:}X\\) and produce a semantics for \\(\\mathsf{J4}\\), a\njustification analog of \\(\\mathsf{K4}\\), with a Realization Theorem\nconnecting them. Adding reflexivity leads to a logic that is called\n\\({\\textsf{LP}}\\) for historical reasons. We have discussed justification logics that are sublogics of\n\\({\\textsf{LP}}\\), corresponding to sublogics of the modal logic\n\\(\\textsf{S4}\\). The first examples that went beyond \\({\\textsf{LP}}\\)\nwere those discussed in Section 2.7, involving a negative\nintrospection operator, ‘?’. Models for justification\nlogics that include this operator add three conditions. First R is\nsymmetric. Second, one adds a condition that has come to be known\nas strong evidence: \\({\\mathcal{M},\\Gamma{\\Vdash}t{:}X}\\) for\nall \\(\\Gamma\\in \\mathcal{E}(t, X)\\). Finally, there is a condition on\nthe evidence function: If this machinery is added to that for \\(\\mathsf{J4}\\) we get the\nlogic \\(\\mathsf{J45}\\), a justification counterpart of\n\\(\\mathsf{K45}\\). Axiomatic soundness and completeness can be\nproved. In a similar way, related logics \\(\\mathsf{JD45}\\) and\n\\(\\mathsf{JT45}\\) can be formulated semantically. A Realization\nTheorem taking the operator \\(?\\) into account was shown in (Rubtsova\n2006). Moving to Geach logics as introduced in Section 2.8, a semantic\nmodel for \\(\\textsf{J4.2}\\) can also be specified. Suppose \\(G =\n\\langle \\mathcal{G}, \\mathcal{R}, \\mathcal{E}, \\mathcal{V}\\rangle\\) is\nan \\({\\textsf{LP}}\\) model. We add the following requirements. First,\nthe frame must be convergent, as with \\(\\textsf{S4.2}\\). Second, as\nwith \\(?\\), \\(\\mathcal{E}\\) must be a strong evidence\nfunction. And third, \\(\\mathcal{E}(f(t,u), \\lnot t{:}X)\\cup\n\\mathcal{E}(g(t,u), \\lnot u{:}\\lnot X) = \\mathcal{G}\\). Completeness\nand soundness results follow in the usual way. In a similar way every modal logic axiomatized by Geach schemes in\nthis family has a justification counterpart, with a Fitting semantics\nand a realization theorem connecting the justification counterpart\nwith the corresponding modal logic. In particular, this tells us that\nthe justification logic family is infinite, and certainly much broader\nthan it was originally thought to be. It is also the case that some\nmodal logics not previously considered, and not in this family, have\njustification counterparts as well. Investigating the consequences of\nall this is still work in progress. \n\nSingle world justification models were developed considerably before\nthe more general possible world justification models we have been\ndiscussing, (Mkrtychev 1997). Today they can most simply be thought of\nas possible world justification models that happen to have a single\nworld. The completeness proof for \\(\\mathsf{J}\\) and the other\njustification logics mentioned above can easily be modified to\nestablish completeness with respect to single world justification\nmodels, though of course this was not the original argument. What\ncompleteness with respect to single world justification models tells\nus is that information about the possible world structure of\njustification models can be completely encoded by the admissible\nevidence function, at least for the logics discussed so far. Mkrtychev\nused single world justification models to establish decidability of\n\\(\\mathsf{LP}\\), and others have made fundamental use of them in\nsetting complexity bounds for justification logics, as well as for\nshowing conservativity results for justification logics of belief\n(Kuznets 2000, Kuznets 2008, Milnikel 2007, Milnikel 2009). Complexity\nresults have further been used to address the problem of logical\nomniscience. The formal semantics for Justification Logic described above in\n3.1–3.4 defines truth value at a given world \\(\\Gamma\\) the same\nway it is done in Awareness Models: \\(t{:}F\\) holds at \\(\\Gamma\\)\niff \\(F\\) holds at all worlds accessible from \\(\\Gamma\\) and \\(t\\) is admissible evidence for \\(F\\) according to the given\nevidence function. In addition, there is a different kind of semantics, so-called\nmodular semantics, which focuses on making more transparent the\nontological status of justifications. Within modular semantics\npropositions receive the usual classical truth values and\njustifications are interpreted syntactically as sets of formulas. We\nretain a classical interpretation \\(\\ast\\) of the propositional\nformulas \\(Fm\\), which, in the case of a single world, reduces to\n\\[\\ast: Fm \\mapsto\\ \\ \\{0,1\\}\\] i.e., each formula gets a truth value\n0 (false) or 1 (true), with the usual Boolean conditions:\n\\({\\Vdash}A\\rightarrow B\\) iff \\(\\not\\Vdash A\\) or \\({\\Vdash}B\\),\netc. The principal issue is how to interpret justification\nterms. For sets of formulas \\(X\\) and \\(Y\\), we define\n\\[X\\cdot Y = \\{ F \\mid G{\\rightarrow}F \\in X\\ \\mbox{and} \\ G \\in Y\\\n\\mbox{for some}\\ G\\}.\\] Informally, \\(X\\cdot Y\\) is the result of\napplying Modus Ponens once between all members of \\(X\\) and\nof \\(Y\\) (in that order). Justification terms Tm are\ninterpreted as subsets of the set of formulas: \\[\\ast: Tm \\mapsto\\ \\\n2^{Fm}\\] such that \\[(s\\cdot t)^\\ast\\supseteq s^\\ast\\cdot t^\\ast \\ \\\n\\mbox{and}\\ \\ \\ (s+t)^\\ast\\supseteq s^\\ast\\cup t^\\ast .\\] These\nconditions correspond to the basic justification logic \\(\\textsf{J}\\);\nother systems require additional closure properties of \\(\\ast\\). Note\nthat whereas propositions in modular models are interpreted\nsemantically, as truth values, justifications are interpreted\nsyntactically, as sets of formulas. This is a principal hyperintensional feature: a\nmodular model may treat distinct formulas \\(F\\) and \\(G\\) as equal in\nthe sense that \\(F^\\ast = G^\\ast\\), but still be able to distinguish\njustification assertions \\(t{:}F\\) and \\(t{:}G\\), for example when \\(F\n\\in t^\\ast\\) but \\(G\\not\\in t^\\ast\\) yielding \\({\\Vdash}t{:}F\\) but\n\\(\\not\\Vdash t{:}G\\). In the general possible world setting, formulas\nare interpreted classically as subsets of the set \\(W\\) of possible\nworlds, \\[\\ast: Fm \\mapsto\\ \\ 2^W ,\\] and justification terms are\ninterpreted syntactically as sets of formulas at each world \\[\\ast:\nW\\times Tm \\mapsto\\ \\ 2^{Fm}.\\] Soundness and completeness of\nJustification Logic systems with respect to modular models have been\ndemonstrated in Artemov (2012; Kuznets and\nStuder 2012). The logical omniscence problem is that in epistemic logics all\ntautologies are known and knowledge is closed under consequence, which\nis unreasonable. In Fagin and Halpern\n(1988) a simple mechanism for avoiding the problems was\nintroduced. One adds to the usual Kripke model structure an awareness\nfunction \\(\\cal A\\) indicating for each world which formulas the agent\nis aware of at this world. Then a formula is taken to be known at a\npossible world \\(\\Gamma\\) if 1) the formula is true at all worlds\naccessible from \\(\\Gamma\\) (the Kripkean condition for knowledge) and\n2) the agent is aware of the formula at \\(\\Gamma\\). Awareness\nfunctions can serve as a practical tool for blocking knowledge of an\narbitrary set of formulas. However as logical structures, awareness\nmodels can exhibit unusual behavior due to the lack of natural closure\nproperties. For example, the agent can know \\(A\\wedge B\\) but be aware\nof nether \\(A\\) nor \\(B\\) and hence not know either. Possible world justification logic models use a forcing definition\nreminiscent of the one from the awareness models: for any given\njustification \\(t\\) the justification assertion \\(t{:}F\\) holds at\nworld \\(\\Gamma\\) iff 1) \\(F\\) holds at all worlds \\(\\Delta\\)\naccessible from \\(\\Gamma\\) and 2) \\(t\\) is admissible evidence for\n\\(F\\) at \\(\\Gamma\\), \\(\\Gamma\\in{\\cal E}(t,F)\\). The principal\ndifference is in the operations on justifications and corresponding\nclosure conditions on admissible evidence function \\(\\cal E\\) in\nJustification Logic models, which may hence be regarded as a dynamic\nversion of awareness models which necessary closure properties\nspecified. This idea has been explored\nin Sedlár (2013) which worked\nwith the language of \\(\\textsf{LP}\\), thinking of it as a multi-agent\nmodal logic, and taking justification terms as agents (more properly,\nactions of agents). This shows that Justification Logic models absorb\nthe usual epistemic themes of awareness, group agency and dynamics in\na natural way. \n\nThe natural modal epistemic counterpart of the evidence assertion \n\\(t : F\\) is \\(\\Box F\\), read for some x, \nx:\\(F\\). This observation leads to the notion of \nforgetful projection which replaces each occurrence of \n\\(t : F\\) by \\(\\Box F\\) and hence converts a \nJustification Logic sentence \\(S\\) to a corresponding Modal \nLogic sentence \\(S^{o}\\). The forgetful \nprojection extends in the natural way from sentences to logics. \n\nObviously, different Justification Logic sentences may have the same \nforgetful projection, hence \\(S^{o}\\) loses \ncertain information that was contained in \\(S\\). However, it is \neasily observed that the forgetful projection always maps valid \nformulas of Justification Logic (e.g., axioms of\n \\(\\mathsf{J})\\)\n to valid formulas of a corresponding\nEpistemic Logic \\((\\mathsf{K}\\) \nin this case). The converse also holds: any valid formula of \nEpistemic Logic is the forgetful projection of some valid formula of \nJustification Logic. This follows from the Correspondence Theorem 3. \n  Theorem 3:\n \\(\\mathsf{J}^{o} = \\mathsf{K}\\).\n \n\nThis correspondence holds for other pairs of Justification and \nEpistemic systems, for instance\n \\(\\mathsf{J4}\\) and\n \\(\\mathsf{K4}\\), or\n \\(\\mathsf{LP}\\) and\n \\(\\mathsf{S4}\\),\n and many others. In such extended form, the \nCorrespondence Theorem shows that major modal logics such as\n \\(\\mathsf{K} , \\mathsf{T} , \\mathsf{K4} , \\mathsf{S4} , \\mathsf{K45} , \\mathsf{S5}\\)\n and some others have exact Justification Logic \ncounterparts. \n\nAt the core of the Correspondence Theorem is the following \nRealization Theorem. \nTheorem 4: There is an algorithm which, for each\nmodal formula \\(F\\) derivable in\n \\(\\mathsf{K}\\), assigns evidence terms to each occurrence of\nmodality in \\(F\\) in such a way that the resulting formula\n\\(F^{r}\\) is derivable in\n \\(\\mathsf{J}\\). Moreover, the realization assigns evidence\nvariables to the negative occurrences of modal operators in \\(F\\), thus\nrespecting the existential reading of epistemic modality.\n \n\nKnown realization algorithms which recover evidence terms in modal \ntheorems use cut-free derivations in the corresponding modal logics. \nAlternatively, the Realization Theorem can be established \nsemantically by Fitting’s method or its proper modifications. \nIn principle, these semantic arguments also produce \nrealization procedures which are based on exhaustive search. \n\nIt would be a mistake to draw the conclusion that \nany modal logic has a reasonable Justification Logic\ncounterpart. For example the logic of formal provability,\n \\(\\mathsf{GL}\\), (Boolos 1993) contains\nthe Löb Principle: \n\nwhich does not seem to have an epistemically acceptable explicit \nversion. Consider, for example, the case where \\(F\\) is the \npropositional constant \\(\\bot\\)  for false. If an analogue of \nTheorem 4 would cover the Löb Principle there would be \njustification terms \\(s\\) and \\(t\\) such that \n\\(x :( s : \\bot \\rightarrow \\bot ) \\rightarrow t : \\bot\\) . \nBut this is intuitively false for factive justification. Indeed, \n\\(s : \\bot \\rightarrow \\bot\\)  is an instance of the Factivity Axiom.\nApply Axiom Internalization to obtain \n\\(c :( s : \\bot \\rightarrow \\bot )\\) for some constant \n\\(c\\). This choice of \\(c\\) makes the antecedent of \n\\(c :( s : \\bot \\rightarrow \\bot ) \\rightarrow t : \\bot\\)  \nintuitively true and the conclusion \n false[4].\n In particular, the Löb Principle (5) is not valid for the proof \ninterpretation (cf. (Goris 2007) for a full account of which \nprinciples of \\(\\mathsf{GL}\\) are\nrealizable). \n\nThe Correspondence Theorem gives fresh insight into epistemic modal \nlogics. Most notably, it provides a new semantics for the major modal\nlogics. In addition to the traditional Kripke-style \n‘universal’ reading of \\(\\Box F\\) as F holds \nin all possible situations, there is now a rigorous \n‘existential’ semantics for \\(\\Box F\\) that can be\nread as there is a witness (proof, justification) for F. \n\nJustification semantics plays a similar role in Modal Logic to that \nplayed by Kleene realizability in Intuitionistic Logic. In both \ncases, the intended semantics is existential: the \nBrouwer-Heyting-Kolmogorov interpretation of Intuitionistic Logic \n(Heyting 1934, Troelstra and van Dalen 1988, van Dalen 1986) and \nGödel’s provability reading of\n \\(\\mathsf{S4}\\) (Gödel 1933, Gödel 1938). In both \ncases there is a possible-world semantics of \nuniversal character which is a highly potent and \ndominant technical tool. It does not, however, address the \nexistential character of the intended semantics. It took Kleene \nrealizability (Kleene 1945, Troelstra 1998) to reveal the \ncomputational semantics of Intuitionistic Logic and the Logic of \nProofs to provide exact BHK semantics of\nproofs for Intuitionistic and Modal Logic. \n\nIn the epistemic context, Justification Logic and the Correspondence \nTheorem add a new ‘justification’ component to modal \nlogics of knowledge and belief. Again, this new component was, in \nfact, an old and central notion which has been widely discussed by \nmainstream epistemologists but which remained out of the scope of \nclassical epistemic logic. The Correspondence Theorem tells us that \njustifications are compatible with Hintikka-style systems and hence \ncan be safely incorporated into the foundation for Epistemic Modal \nLogic. \nSee Section 4 of the supplementary document\n Some More Technical Matters\nfor more on Realization Theorems. \n\nSo far in this article only single-agent justification logics, \nanalogous to single-agent logics of knowledge, have been considered. \nJustification Logic can be thought of as logic of explicit \nknowledge, related to more conventional logics of implicit \nknowledge. A number of systems beyond those discussed above have been\ninvestigated in the literature, involving multiple agents, or having \nboth implicit and explicit operators, or some combination of these. \n\nSince justification logics provide explicit justifications, while\nconventional logics of knowledge provide an implicit knowledge\noperator, it is natural to consider combining the two in a single\nsystem. The most common joint logic of explicit and implicit knowledge\nis \\(\\mathsf{S4LP}\\) (Artemov and Nogina 2005). The language of\n\\(\\mathsf{S4LP}\\) is like that of \\(\\mathsf{LP}\\), but with an\nimplicit knowledge operator added, written either \\(\\mathbf{K}\\) or\n\\(\\Box\\) . The axiomatics is like that of \\(\\mathsf{LP}\\), combined\nwith that of \\(\\mathsf{S4}\\) for the implicit operator, together with\na connecting axiom, \\(t : X \\rightarrow \\Box X\\), anything that has an\nexplicit justification is knowable. \n\nSemantically, possible world justification models for\n \\(\\mathsf{LP}\\) need no modification, since they already have \nall the machinery of Hintikka/Kripke models. One models the \\(\\Box\\)  \noperator in the usual way, making use of just the accessibility \nrelation, and one models the justification terms as described in \nSection 3.1 using both accessibility and the evidence function. Since \nthe usual condition for \\(\\Box X\\) being true at a world is \none of the two clauses of the condition for \\(t : X\\) \nbeing true, this immediately yields the validity of \n\\(t : X \\rightarrow \\Box X\\), and soundness follows\neasily. Axiomatic completeness is also rather straightforward. \n\nIn \\(\\mathsf{S4LP}\\) both implicit and explicit knowledge is\nrepresented, but in possible world justification model semantics a\nsingle accessibility relation serves for both. This is not the only\nway of doing it. More generally, an explicit knowledge accessibility\nrelation could be a proper extension of that for implicit\nknowledge. This represents the vision of explicit knowledge as having\nstricter standards for what counts as known than that of implicit\nknowledge. Using different accessibility relations for explicit and\nimplicit knowledge becomes necessary when these epistemic notions obey\ndifferent logical laws, e.g., \\(\\mathsf{S5}\\) for implicit knowledge\nand \\(\\mathsf{LP}\\) for explicit.  The case of multiple accessibility\nrelations is commonly known in the literature as Artemov-Fitting\nmodels, but will be called multi-agent possible world models\nhere. (cf. Section 5.2). \n\nCuriously, while the logic\n \\(\\mathsf{S4LP}\\) seems quite natural, a Realization Theorem \nhas been problematic for it: no such theorem can be proved if one \ninsists on what are called normal realizations (Kuznets \n2010). Realization of implicit knowledge modalities in\n \\(\\mathsf{S4LP}\\) by explicit \njustifications which would respect the epistemic structure remains a \nmajor challenge in this area. \n\nInteractions between implicit and explicit knowledge can sometimes be\nrather delicate. As an example, consider the following mixed \nprinciple of negative introspection (again \\(\\Box\\)  should be read as \nan implicit epistemic operator), \n\nFrom the provability perspective, it is the right form of negative \nintrospection. Indeed, let \\(\\Box F\\) be interpreted as F \nis provable and \\(t : F\\) as t is a proof of \nF in a given formal theory \\(T\\), e.g., in Peano Arithmetic\n\\(\\mathsf{PA}\\). Then (6) states \na provable principle. Indeed, if \\(t\\) is not a proof of \n\\(F\\) then, since this statement is decidable, it can be \nestablished inside \\(T\\), hence in \\(T\\) this sentence is \nprovable. On the other hand, the proof \\(p\\) of \n‘\\(t\\) is not a proof of \\(F\\)’ depends on both\n\\(t\\) and \\(F , p = p ( t , F)\\) and \ncannot be computed given \\(t\\) only. In this respect, \\(\\Box\\)  \ncannot be replaced by any specific proof term depending on \\(t\\)\nonly and (6) cannot be presented in an entirely explicit \njustification-style format. \n\nThe first examples of explicit/implicit knowledge systems appeared in\nthe area of provability logic. In (Sidon 1997, Yavorskaya (Sidon) \n2001), a logic \\(\\mathsf{LPP}\\) \nwas introduced which combined the logic of provability\n \\(\\mathsf{GL}\\) with the logic of \nproofs \\(\\mathsf{LP}\\), but to \nensure that the resulting system had desirable logical properties \nsome additional operations from outside the original \nlanguages of \\(\\mathsf{GL}\\) and \n\\(\\mathsf{LP}\\) were added. In \n(Nogina 2006, Nogina 2007) a complete logical system,\n \\(\\mathsf{GLA}\\), for proofs and \nprovability was offered, in the sum of the original \nlanguages of \\(\\mathsf{GL}\\)\nand\n \\(\\mathsf{LP}\\). Both\n \\(\\mathsf{LPP}\\) and\n \\(\\mathsf{GLA}\\)\n enjoy completeness relative to the \nclass of arithmetical models, and also relative to the class of \npossible world justification models. \n\nAnother example of a provability principle that cannot be made \ncompletely explicit is the Löb Principle (5). For each of\n \\(\\mathsf{LPP}\\) and\n \\(\\mathsf{GLA}\\),\n it is easy to find a proof term \n\\(l ( x)\\) such that \n\nholds. However, there is no realization which makes all \nthree \\(\\Box\\) s in (5) explicit. In fact, the set of \nrealizable provability principles is the intersection of\n \\(\\mathsf{GL}\\) and\n \\(\\mathsf{S4}\\) (Goris 2007). \n\nIn Multi-Agent possible world justification models multiple\naccessibility relations are employed, with connections between them,\n(Artemov 2006). The idea is, there are multiple agents, each with an\nimplicit knowledge operator, and there are justification terms, which\neach agent understands. Loosely, everybody understands explicit\nreasons; these amount to evidence-based common knowledge. \n\nAn \\(n\\)-agent possible world justification model is a structure\n \\(\\langle \\mathcal{G} , \\mathcal{R}_{1}\\), …,\\(\\mathcal{R}_{n}\n , \\mathcal{R} , \\mathcal{E} , \\mathcal{V}\\rangle\\) meeting the\n following conditions.  \\(\\mathcal{G}\\) is a set of possible\n worlds. Each of \\(\\mathcal{R}_{1}\\),…,\\(\\mathcal{R}_{n}\\) is\n an accessibility relation, one for each agent. These may be assumed\n to be reflexive, transitive, or symmetric, as desired. They are used\n to model implicit agent knowledge for the family of agents. The\n accessibility relation \\(\\mathcal{R}\\) meets the \\(\\mathsf{LP}\\)\n conditions, reflexivity and transitivity. It is used in the modeling\n of explicit knowledge.  \\(\\mathcal{E}\\) is an evidence function,\n meeting the same conditions as those for \\(\\mathsf{LP}\\) in Section\n 3.3. \\(\\mathcal{V}\\) maps propositional letters to sets of worlds, as\n usual. There is a special condition imposed: for each \\(i\\) = 1,\n …,\\(n , \\mathcal{R}_{i} \\subseteq \\mathcal{R}\\). \n\nIf \\(\\mathcal{M} = \\langle \\mathcal{G} , \\mathcal{R}_{1}\\),\n …,\\(\\mathcal{R}_{n} , \\mathcal{R} , \\mathcal{E} ,\n \\mathcal{V}\\rangle\\) is a multi-agent possible world justification\n model a truth-at-a-world relation, \\(\\mathcal{M} , \\Gamma \\Vdash X\\),\n is defined with most of the usual clauses. The ones of particular\n interest are these: \n\nThe condition \\(\\mathcal{R}_{i} \\subseteq \\mathcal{R}\\) entails the validity of \n\\(t : X \\rightarrow K_{i}X\\), for each agent \\(i\\).\nIf there is only a single agent, and the accessibility relation for \nthat agent is reflexive and transitive, this provides another \nsemantics for \\(\\mathsf{S4LP}\\). \nWhatever the number of agents, each agent accepts explicit reasons as\nestablishing knowledge. \n\nA version of \\(\\mathsf{LP}\\) with\ntwo agents was introduced and studied in (Yavorskaya (Sidon) \n2008), though it can be generalized to any finite number of agents. In\nthis, each agent has its own set of justification operators, \nvariables, and constants, rather than having a single set for \neverybody, as above. In addition some limited communication between \nagents may be permitted, using a new operator that allows one agent \nto verify the correctness of the other agent’s justifications. \nVersions of both single world and more general possible world\njustification semantics were created for the two-agent logics. This\ninvolves a straightforward extension of the notion of an evidence\nfunction, and for possible world justification models, using two\naccessibility relations. Realization theorems have been proved\nsyntactically, though presumably a semantic proof would also work. \n\nThere has been some recent exploration of the role of public \nannouncements in multi-agent justification logics (Renne 2008, Renne \n2009). \n\nThere is more on the notion of evidence-based common knowledge in\nSection 5 of the supplementary document\n Some More Technical Matters. \n\nThere is a technique for using Justification Logic to analyze \ndifferent justifications for the same fact, in particular when some \nof the justifications are factive and some are not. To demonstrate \nthe technique consider a well-known example: \n\nAs in the Red Barn Example, discussed in Section 1.1, here one has to\ndeal with two justifications for a true statement, one of which is \ncorrect and one of which is not. Let \\(B\\) be a sentence \n(propositional atom), \\(w\\) be a designated justification \nvariable for the wrong reason for \\(B\\) and \\(r\\) a \ndesignated justification variable for the right (hence factive) \nreason for \\(B\\). Then, Russell’s example prompts the following \nset of \n assumptions[7]:\n  \n\nSomewhat counter to intuition, one can logically deduce factivity of \n\\(w\\) from \\(\\mathcal{R}\\): \n\nHowever, this derivation utilizes the fact that \\(r\\) is a \nfactive justification for \\(B\\) to conclude \n\\(w : B \\rightarrow B\\), which constitutes a case of \n‘induced factivity’ for \\(w : B\\). The \nquestion is, how can one distinguish the ‘real’ factivity\nof \\(r : B\\) from the ‘induced factivity’ of \n\\(w : B\\) ? Some sort of evidence-tracking is needed here, \nand Justification Logic is an appropriate tool. The natural approach \nis to consider the set of assumptions without \n\\(r : B\\), i.e., \n\nand establish that factivity of \\(w\\), i.e., \n\\(w : B \\rightarrow B\\) is not derivable from\n \\(\\mathcal{S}\\). Here is a possible world justification model\n \\(\\mathcal{M}\\) =\n \\((\\mathcal{G} , \\mathcal{R} , \\mathcal{E} , \\mathcal{V})\\) in which\n \\(\\mathcal{S}\\) \nholds but \\(w : B \\rightarrow B\\) does not: \n\nIt is easy to see that the closure conditions Application \nand Sum on \\(\\mathcal{E}\\) are fulfilled. At\n\\(\\mathbf{1} , w : B\\) holds, i.e., \n\nsince \\(w\\) is admissible evidence for \\(B\\) at \n\\(\\mathbf{1}\\) and there are no possible worlds accessible from \n\\(\\mathbf{1}\\). Furthermore, \n\nsince, according to \\(\\mathcal{E} , r\\) is \nnot admissible evidence for \\(B\\) at \\(\\mathbf{1}\\). Hence: \n\nOn the other hand, \n\nsince \\(B\\) does not hold at \\(\\mathbf{1}\\). \n\nThe Realization algorithms sometimes produce Constant Specifications \ncontaining self-referential justification assertions \n\\(c : A ( c)\\), that is, assertions in which the \njustification (here \\(c)\\) occurs in the asserted proposition \n(here \\(A ( c))\\). \n\nSelf-referentiality of justifications is a new phenomenon which is \nnot present in the conventional modal language. In addition to being \nintriguing epistemic objects, such self-referential assertions \nprovide a special challenge from the semantical viewpoint because of \nthe built-in vicious circle. Indeed, to evaluate \\(c\\) one would\nexpect first to evaluate \\(A\\) and then assign a justification \nobject for \\(A\\) to \\(c\\). However, this cannot be done \nsince \\(A\\) contains \\(c\\) which is yet to be evaluated. \nThe question of whether or not modal logics can be realized without \nusing self-referential justifications was a major open question in \nthis area. \n\nThe principal result by Kuznets in (Brezhnev and Kuznets 2006) states\nthat self-referentiality of justifications is unavoidable in \nrealization of \\(\\mathsf{S4}\\) in\n\\(\\mathsf{LP}\\). The current \nstate of things is given by the following theorem due to Kuznets: \nTheorem 5: Self-referentiality can be avoided in\nrealizations of modal logics\n \\(\\mathsf{K}\\) and\n \\(\\mathsf{D}\\).\n Self-referentiality cannot be avoided in\nrealizations of modal logics\n \\(\\mathsf{T} , \\mathsf{K4} , \\mathsf{D4}\\)\n and\n \\(\\mathsf{S4}\\).\n \n\nThis theorem establishes that a system of justification terms for \n\\(\\mathsf{S4}\\) will necessarily \nbe self-referential. This creates a serious, though not directly \nvisible, constraint on provability semantics. In the Gödelian \ncontext of arithmetical proofs, the problem was coped with by a \ngeneral method of assigning arithmetical semantics to \nself-referential assertions \\(c : A ( c)\\) stating\nthat \\(c\\) is a proof of \\(A ( c)\\). In the Logic of\nProofs \\(\\mathsf{LP}\\) it was \ndealt with by a non-trivial fixed-point construction. \n\nSelf-referentiality gives an interesting perspective on Moore’s \nParadox. See Section 6 of the\nsupplementary document\n Some More Technical Matters\n for details. \nThe question of the self-referentiality of BHK-semantics for\nintuitionistic logic \\(\\mathsf{IPC}\\) has been answered by Junhua Yu\n(Yu 2014).  Extending Kuznets’ method, he established \nTheorem 6: Each \\(\\mathsf{LP}\\) realization of the\nintuitionistic law of double negation \\(\\neg\\neg(\\neg\\neg p\n\\rightarrow p)\\) requires self referential constant\nspecifications. \n\nWhile the investigation of propositional Justification Logic is far \nfrom complete, there has also been some work on first-order \nversions. Quantified versions of Modal Logic already offer \ncomplexities beyond standard first-order logic. Quantification has an\neven broader field to play when Justification Logics are involved. \nClassically one quantifies over ‘objects,’ and models are\nequipped with a domain over which quantifiers range. Modally one \nmight have a single domain common to all possible worlds, or one \nmight have separate domains for each world. The role of the Barcan \nformula is well-known here. Both constant and varying domain options \nare available for Justification Logic as well. In addition there is a\npossibility that has no analog for Modal Logic: one might quantify \nover justifications themselves. \n\nInitial results concerning the possibility of Quantified \nJustification Logic were notably unfavorable. The arithmetical \nprovability semantics for the Logic of Proofs\n \\(\\mathsf{LP}\\), naturally generalizes to a \nfirst-order version with conventional quantifiers, and to a version \nwith quantifiers over proofs. In both cases, axiomatizability \nquestions were answered negatively. \nTheorem 7: The first-order logic of proofs is not\nrecursively enumerable (Artemov and Yavorskaya (Sidon) 2001). The\nlogic of proofs with quantifiers over proofs is not recursively\nenumerable (Yavorsky 2001).\n \n\nAlthough an arithmetic semantics is not possible, in (Fitting 2008) a\npossible world semantics, and an axiomatic proof theory, was given for \na version of \\(\\mathsf{LP}\\) with\nquantifiers ranging over justifications. Soundness and completeness \nwere proved. At this point possible world semantics separates from \narithmetic semantics, which may or may not be a cause for alarm. It \nwas also shown that\n \\(\\mathsf{S4}\\)\n embeds into the quantified logic by translating\n\\(\\Box Z\\) as “there exists a justification \\(x\\) \nsuch that \\(x : Z^{*}\\),” where \n\\(Z^{*}\\) is the translation of \\(Z\\). While this \nlogic is somewhat complicated, it has found applications, e.g., in \n(Dean and Kurokawa 2009b) it is used to analyze the Knower Paradox, \nthough objections have been raised to this analysis in (Arlo-Costa \nand Kishida 2009). A First-Order Logic of Proofs, \\(\\textsf{FOLP}\\), with quantifiers\nover individual variables, has been presented\nin Artemov and Yavorskaya (Sidon)\n(2011). In \\(\\textsf{FOLP}\\) proof assertions are represented\nby formulas of the form \\(t{:}_X A\\) where \\(X\\) is a finite set of\nindividual variables that are considered global parameters open for\nsubstitution. All occurrences of variables from \\(X\\) that are free in\n\\(A\\) are also free in \\(t{:}_X A\\). All other free variables of \\(A\\)\nare considered local and hence bound in \\(t{:}_X A\\). For example, if\n\\(A(x,y)\\) is an atomic formula, then in \\(p{:}_{\\{x\\}} A(x,y)\\)\nvariable \\(x\\) is free and variable \\(y\\) is bound. Likewise, in\n\\(p{:}_{\\{x,y\\}} A(x,y)\\) both variables are free, and in\n\\(p{:}_{\\emptyset} A(x,y)\\) neither \\(x\\) nor \\(y\\) is free. Proofs (justifications) are represented by proof terms which do not\ncontain individual variables. In addition to \\(\\textsf{LP}\\)\noperations there is one more series of operations on proof terms,\n\\({\\sf gen}_x(t)\\), corresponding to generalization over individual\nvariable \\(x\\). The new axiom that governs this operation is \\(t{:}_X\nA {\\rightarrow}{\\sf gen{:}_x(t)}_X\\forall x A\\), with \\(x\\not\\in\nX\\). The complete list of \\(\\textsf{FOLP}\\) principles along with\nrealization of First-Order \\(\\textsf{S4}\\) can be found\nin Artemov and Yavorskaya (Sidon)\n(2011). A semantics for \\(\\textsf{FOLP}\\) has been developed\nin Fitting (2014a). \n\nThe initial Justification Logic system, the Logic of Proofs\n \\(\\mathsf{LP}\\),\n was introduced in 1995 in (Artemov 1995) (cf. \nalso (Artemov 2001)) where such basic properties as Internalization, \nRealization, arithmetical completeness, were first established.\n\\(\\mathsf{LP}\\) offered an intended\nprovability semantics for Gödel’s provability logic\n \\(\\mathsf{S4}\\),\n thus providing a formalization of Brouwer-Heyting-Kolmogorov\nsemantics for intuitionistic propositional logic. \nEpistemic semantics and completeness (Fitting 2005) were first \nestablished for \\(\\mathsf{LP}\\). \nSymbolic models and decidability for\n \\(\\mathsf{LP}\\)\n are due to Mkrtychev (Mkrtychev 1997). \nComplexity estimates first appeared in (Brezhnev and Kuznets 2006, \nKuznets 2000, Milnikel 2007). A comprehensive overview of all \ndecidability and complexity results can be found in (Kuznets 2008). \nSystems \\(\\mathsf{J} , \\mathsf{J4}\\), and\n \\(\\mathsf{JT}\\)\n were first considered in (Brezhnev \n2001) under different names and in a slightly different setting. \n\\(\\mathsf{JT45}\\) appeared \nindependently in (Pacuit 2006) and (Rubtsova 2006), and\n \\(\\mathsf{JD45}\\) in (Pacuit 2006). The\nlogic of uni-conclusion proofs has been found in (Krupski 1997). \nA more general approach to common knowledge based on justified\nknowledge was offered in (Artemov 2006).  Game\nsemantics of Justification Logic and Dynamic Epistemic Logic with \njustifications were studied in (Renne 2008, Renne 2009). Connections \nbetween Justification Logic and the problem of logical omniscience \nwere examined in (Artemov and Kuznets 2009, Wang 2009).\nThe name Justification Logic was introduced in\n(Artemov 2008), in which Kripke, Russell, and Gettier examples were\nformalized; this formalization has been used for the resolution of\nparadoxes, verification, hidden assumption analysis, and eliminating\nredundancies.  In (Dean and Kurokawa 2009a), Justification Logic was\nused for the analysis of Knower and Knowability paradoxes.\n \nThe first two monographs on Justification Logic were published in 2019\n(Artemov and Fitting 2019, Kuznets and Studer 2019).","contact.mail":"melvin.fitting@lehman.cuny.edu","contact.domain":"lehman.cuny.edu"}]
