[{"date.published":"2010-08-23","date.changed":"2016-07-12","url":"https://plato.stanford.edu/entries/dynamic-semantics/","author1":"Rick Nouwen","author2":"Adrian Brasoveanu","author1.info":"http://ricknouwen.org","author2.info":"http://www.cwi.nl/~jve","entry":"dynamic-semantics","body.text":"\n\n\nDynamic semantics is a perspective on natural language semantics that\nemphasizes the growth of information in time. It is an approach to\nmeaning representation where pieces of text or discourse are viewed as\ninstructions to update an existing context with new information, the\nresult of which is an updated context. In a slogan: meaning is context\nchange potential. \n\n\nIt is important to be aware of the abstractness of this perspective so\nas to guard against various non sequiturs. For one thing, one could\neasily think that dynamic semantics or update semantics is committed\nat least in part to an internalist idea of semantics since the\ninformation states are “internal”—in the sense that\nthey are wholly contained in the individual mind/brain. In other\nwords, one might think that the information states of dynamic\nsemantics are what Putnam (1975) calls “states in the sense of\nmethodological solipsism”. See the entries on\n scientific realism,\n computational theory of mind,\n externalism about mental content,\n and\n narrow mental content.\n However, the general framework says nothing about what the states\nare. The state could very well include the environment in which the\ninterpreter is embedded and thus contain an “external”\ncomponent.\n\n\nA second possible misunderstanding is that dynamic semantics or update\nsemantics is in complete opposition to classical truth conditional\nsemantics (compare the entries on\n classical logic\n and\n first-order model theory).\n In fact, as this entry will soon make clear, what dynamic semantics\nprovides is a generalization of truth conditional semantics rather\nthan a radically different alternative. The classical meanings become\nthe preconditions for success of the discourse actions.\nDynamic semanticists claim that compositional meanings have\nthe nature of functions or relations and the classical meanings are\nrecoverable from the relational dynamic meanings as\nprojections onto their “input” coordinate.\n\n\nThe point of the use of an abstract framework is not to give empirical\npredictions. This is the task of specific realizations inside the\nframework. The framework of dynamic semantics (i) provides a direction\nof thinking and (ii) allows us to import methods from the mathematical\nstudy of the framework. It follows that the question whether natural\nlanguage meaning is intrinsically dynamic does not have an empirical\nanswer. Still, what can be said is that the study of interpretation as\na linearly-ordered process has proven quite fruitful and\nrewarding.\n\n\nSince dynamic semantics focuses on the discourse actions of sender and\nreceiver, it is in a sense close to use-oriented approaches to meaning\nin philosophy such as the work of Wittgenstein and Dummett. However,\neasy identifications between dynamic semantics and these approaches\nare to be avoided. Dynamic semantics as an abstract framework is\ncompatible with many philosophical ways of viewing meaning and\ninterpretation. Dynamic semantics aims to model meaning and\ninterpretation. You can do that without answering broader\nphilosophical questions such as the question of what it is that makes\nit possible for the subject to be related to these meanings at all.\nFor example, in dynamic predicate logic we take the meaning of\nhorse as given without making any substantial claim about\nwhat it means for a subject to have the concept of horse; we\njust stipulate the subject has it. This is not to say such\nquestions—which are at the center of the work of Wittgenstein\nand Dummett—should not ultimately be answered: it’s just\nthat a model can be of interest even if it does not answer them. (Note\nthat dynamic semantics tries to give a systematic and compositional\naccount of meaning, which makes it markedly different in spirit from\nWittgenstein’s later philosophy.)\n\n\nOne approach to dynamic semantics is\n discourse representation theory\n (DRT, Kamp 1981). (Closely related to Kamp’s approach is Irene\nHeim’s file change semantics (FCS, Heim 1983a) and the\ndiscourse semantics of Seuren 1985). Meanings in DRT are so-called\ndiscourse representation structures (DRSs). These structures\nare a type of database that contains specific pieces of information.\nIn and of itself a DRS is a static object, but DRT can be said to be a\ndynamic semantic framework because it allows us to understand the\nprocess of composing meanings as a process of merging\ndiscourse representation structures. In this way, information change\nbecomes an integral part of the interpretation process.\n\n\nOur main focus in this entry is a second approach to dynamic\nsemantics, although we will compare things to DRT along the way. In\nthis second approach, dynamic meanings are types of actions, things\nthat are individuated by the changes they effect. This is the approach\nassociated with dynamic predicate logic (DPL, Groenendijk and\nStokhof 1991a). According to this dynamic semantic tradition, a\nmeaning is a specification of how a receiver’s information state\nwould be modified. It could for instance be a function that maps an\nold information state to one which has been updated with the\ninformation that the meaning embodies. Alternatively, it could be a\nrelation that expresses the kind of information change that the\nmeaning brings about. (For early work in this tradition, see\nGroenendijk and Stokhof 1991a,b; Muskens 1991; Dekker 1993; Vermeulen\n1993; van Eijck 1994; Vermeulen 1994; Krahmer 1995; van den Berg 1996;\nGroenendijk et al. 1996; Aloni 1997; Muskens et al. 1997).\n\nInterpretation of declarative sentences can be viewed as a product or\nas a process. In the product perspective, one focuses on the notion of\ntruth in a given situation. In the process perspective, interpretation\nof a proposition is viewed as an information updating step that allows\nus to replace a given state of knowledge by a new, more accurate\nknowledge state. Dynamic semantics focuses on interpretation as a\nprocess. \nUpdate semantics is a particular way in which the\ninterpretation-as-process idea can be implemented. The central idea\nbehind update semantics is very simple. We start with a simple model\nof a hearer/receiver who receives items of information sequentially.\nAt every moment the hearer is in a certain state: she possesses\ncertain information. This state is modified by the incoming\ninformation in a systematic way. We now analyze the meaning of the\nincoming items as their contribution to the change of the information\nstate of the receiver. Thus, meanings are seen as actions, or, more\nprecisely, as action types: They are not the concrete changes\nof some given state into another, but what such concrete changes have\nin common. \nPropositional logic (the logic of negation, disjunction and\nconjunction) can be viewed as an update logic as follows. Consider the\ncase where we have three basic propositions \\(p, q\\) and \\(r\\), and\nwe know nothing about their truth. Then there are eight possibilities:\n\\(\\{ \\bar{p} \\bar{q} \\bar{r}, p \\bar{q} \\bar{r}, \\bar{p} q \\bar{r},\n\\bar{p} \\bar{q} r, pq \\bar{r}, p \\bar{q} r, \\bar{p} qr, pqr \\}\\) Here\n\\(\\bar{p} \\bar{q} \\bar{r}\\) should be read as: none of \\(p, q, r\\) is\ntrue, \\(p \\bar{q} \\bar{r}\\) as: \\(p\\) is true but \\(q\\) and\n\\(r\\) are false, and so on. If now \\(\\neg p\\) (“not\n\\(p\\)”) is announced, four of these disappear, and we are\nleft with \\(\\{\\bar{p} \\bar{q} \\bar{r}, \\bar{p} q \\bar{r}, \\bar{p}\n\\bar{q} r, \\bar{p} qr\\}\\). If next \\(q \\vee \\neg r\\) (“\\(q\\)\nor not \\(r\\)”) is announced, the possibility \\(\\bar{p}\n\\bar{q} r\\) gets ruled out, and we are left with \\(\\{ \\bar{p} \\bar{q}\n\\bar{r}, \\bar{p} q \\bar{r}, \\bar{p} qr \\}\\). And so on. We can view\nthe meaning of propositions like \\(\\neg p\\) and \\(q \\vee \\neg r\\) as\nmappings from sets of possibilities to subsets thereof. \nSets of possibilities represent states of knowledge. In the example,\n\\(\\{ \\bar{p} \\bar{q} \\bar{r}, p \\bar{q} \\bar{r}, \\bar{p} q \\bar{r},\n\\bar{p} \\bar{q} r, pq \\bar{r}, p \\bar{q} r, \\bar{p} qr, pqr \\}\\)\nrepresents the state of complete ignorance about propositions \\(p, q,\nr\\). Singleton sets like \\(\\{ pq \\bar{r} \\}\\) represent states of\nfull knowledge about these propositions, and the empty set\n\\(\\varnothing\\) represents the inconsistent state that results from\nprocessing incompatible statements about \\(p, q\\) and \\(r\\). Here\nwe spell out the dynamic meanings of the statements of our\npropositional language:  \nThis gives the meanings of the propositional connectives as operations\nfrom an old context representing a state of knowledge to a new context\nrepresenting the state of knowledge that results from processing the\npropositional information. \nIt is instructive to compare the actions of update semantics to\nprogramming statements and their execution. Such a comparison provides\na first glimpse into how quantification works within a dynamic\nsetting. Programming statements of imperative languages are\ninterpreted (or “executed”) in the context of a machine\nstate, where machine states can be viewed as allocations of values to\nregisters. Assume the registers are named by variables \\(x, y, z\\),\nand that the contents of the registers are natural numbers. Then the\nfollowing is a machine state: \nIf the statement \\(z := x\\) is executed, i.e.,\n“interpreted”, in this state (in C syntax, this statement\nwould have the simpler form \\(z = x)\\), the result is a new machine\nstate: \nIf the sequence of statements \\(x := y\\); \\(y := z\\) is executed in\nthis state, the result is: \nThis illustrates that the result of the sequence \\(z := x\\); \\(x :=\ny\\); \\(y := z\\) is that the values of \\(x\\) and \\(y\\) are\nswapped, with the side effect that the old value of \\(z\\) gets\nlost. In other words, the meaning of the program \\(z := x\\); \\(x :=\ny\\); \\(y := z\\) can be viewed as a mapping from an input machine state\n\\(s\\) to an output machine state \\(s'\\) that differs from \\(s\\)\nin several respects: \\(s'(x) = s(y)\\) and \\(s'(y) = s(x)\\) (that is,\nthe input values of \\(x\\) and \\(y\\) are swapped in the\noutput state), and \\(s'(z) = s'(y)\\). \nNow consider the existential quantifier “there exists an\n\\(x\\) such that \\(A\\)”. Suppose we add this quantifier to\nan imperative programming language. What would be its meaning? It\nwould be an instruction to replace the old value of \\(x\\) by a new\nvalue, where the new value has property \\(A\\). We can decompose\nthis into a part “there exists \\(x\\)” and a test\n“\\(A\\)”. A formula/instruction is a test if\nthe update contributed by it takes the states in the input context one\nat a time and tests that they satisfy a particular condition. If they\ndo, they are included in the output context; if they don’t, they\nare discarded. That is, a test is an update that takes an input\ncontext and outputs a context that is a subset of the input context.\nAll the formulas of propositional logic in the\n Propositional logic as an update logic\n section above are tests. \nThe two parts “there exists \\(x\\)” and the test\n“\\(A\\)” are glued together by sequential composition:\n“\\(\\exists x\\); \\(A\\)”. Focusing on the part\n“\\(\\exists x\\)”, what would be its natural meaning? An\ninstruction to replace the old value of \\(x\\) by some arbitrary new\nvalue. This is again a relation between input states and output\nstates, but the difference with definite assignments like \\(x := y\\)\nis that now the relation is not a function. In fact, this relational\nmeaning of quantifiers shows up in the well known Tarski-style truth\ndefinition for first order logic (compare the entry on\n Tarski’s truth definitions): \n\\(\\exists x\\phi\\) is true in a model \\(M\\) relative to a variable\nassignment \\(\\alpha\\) iff (if and only if) there is some variable\nassignment \\(\\beta\\) such that \\(\\beta\\) differs from \\(\\alpha\\) at\nmost with respect to the value it assigns to \\(x\\) and such that\n\\(\\phi\\) is true in \\(M\\) relative to assignment \\(\\beta\\).  \nImplicit in the Tarskian definition is a relation that holds between\nassignment \\(\\alpha\\) and assignment \\(\\beta\\) iff for all variables\n\\(y\\) that are different from \\(x\\), it is the case that\n\\(\\alpha(y) = \\beta(y)\\). This relation is often called a random\nreset of x and is written as [\\(x\\)]. For any variable\n\\(x\\), the binary relation between total assignments [\\(x\\)] is\nan equivalence relation between assignments, i.e., it is a reflexive,\nsymmetric and transitive binary relation. Below, we see how such\nrelations are put to work in a dynamicised version of first order\npredicate logic.  \nAdopting [\\(x\\)] as the meaning of “\\(\\exists x\\)”,\nnote that its meaning is quite different in nature from that of a test\nin that it creates new values in the output context. In contrast, the\noutput context resulting from an update with a test is always a subset\nof the input context and can therefore never contain anything new\nrelative to the input context. \nInformation states are often called contexts, since the state\nis a precondition for the “interpretation”, i.e., semantic\nevaluation, of expressions in a formal or natural language. The use of\nthe word “context” also makes it clear that we are not\ninterested in the total state of the receiver but only in aspects of\nit relevant to the interpretation of the expressions/informational\nitems we are focusing on. Thus, meanings are often called context\nchange potentials in the dynamic tradition. \nAlthough it is broadly speaking true that the changes brought about by\nmeanings in dynamic semantics concern aspects of context, it\nis important to note that semanticists may mean various things when\nthey talk about context (compare the entries on\n epistemic contextualism\n and\n indexicals),\n and these different views engender varieties of dynamic semantics\nthat deal with a variety of issues. Some of these issues are:\nconstructing an appropriate mechanism for pronominal reference\n(compare the entries on\n anaphora\n and\n reference),\n explaining the semantics of conditionals (compare the entries on\n conditionals\n and\n the logic of conditionals),\n giving a semantic treatment of the distinction between assertion and\npresupposition (compare the entries on\n assertion,\n speech acts,\n implicature,\n pragmatics) and developing a theory of “presupposition\nprojection”, explaining how the interpretation of discourse is\ninfluenced and guided by the common ground that exists between speaker\nand hearer, and developing a theory of how this common ground develops\nas the discourse proceeds (compare the entries on\n pragmatics\n and\n implicature). \nContext plays a role in two separate distinctions. The first\ndistinction is between context and that which modifies the context.\nHere the context is the information state or a suitable abstraction\nthereof (compare the entry on\n semantic conceptions of information).\n The context modifier is (the meaning of) the received informational\nitem. The information cannot be received without the correct kind of\npresupposed information state. The proper analogues in classical\nstatic predicate logic (compare the entries on\n classical logic\n and\n first-order model theory)\n are as follows: the information state is an assignment (environment)\nor a set of assignments, and the received information is a set of\nassignments. The second distinction is between context and content.\nHere the context is something like the storage capacity of the\nreceiver and various other features that could influence how new\nexpressions/informational items are interpreted. The content is the\n(factual, truth conditional) information that is stored. Thus, e.g.,\nthe context in this sense could be a set of registers/variables or in\nDRT/FCS terms, discourse referents or files. The content would then be\nsome set of assignments or, perhaps, world/assignment pairs\nconstraining the values of these discourse referents and the set of\nworlds that are live candidates for the actual world. \nHere is an example to illustrate the distinctions. Suppose we view an\ninformation state as a pair of a finite set of discourse referents and\na set of world/assignment pairs, where the assignments have as domain\nthe given finite set of discourse referents. Such a state would be a\ncontext-in-the-first-sense and the set of discourse referents would be\na context-in-the-second-sense. One basic kind of update would be\nupdate of content: here we constrain the set of world/assignment\npairs, and leave the set of referents constant. A second basic kind of\nupdate would be extension of the set of referents: we extend our\nallocated storage capacity. We modify the given world/assignments\npairs to pairs of worlds and extended assignments, where our extended\nassignments are constrained by the old ones, but take all possible\nvalues on the new referents. Thus, the update process in our example\nis two-dimensional: we have both update of content and update of\ncontext-in-the-second-sense. \nThe motivation for a dynamic semantic framework for natural language\ncomes first and foremost from potential dependencies between the\nreference of a personal pronoun and that of an indefinite noun phrase.\nThe simplest example of such a dependency is that of coreferential\ndiscourse anaphora, as in: \nThe observation is that this sequence of sentences has the same\nmeaning as the single sentence: \nIf we assume that indefinites are existential quantifiers, then the\nanalysis of\n (2)\n is easy. It simply says that there exists an \\(x\\) that is a\nstudent, that met Mary yesterday and that needed her help then. In\npredicate logic: \nHowever, a similar analysis is unavailable for the equivalent\ntwo-sentence example in\n (1).\n This is because interpretation is compositional (see the\nentry on\n compositionality\n for discussion) and in our compositional analysis, we will first come\nto an analysis of Mary met a student yesterday, which will\nhave the form \\(\\exists\nx(\\texttt{student}(x)\\wedge\\texttt{met}(m,x))\\). Likewise, the second\nsentence will correspond to \\(\\texttt{need-help}(x)\\). Assuming that\nthe default mode of combining multiple sentences is to conjoin them,\nwe now arrive at: \nThe final occurrence of \\(x\\) is not bound and so in classical\npredicate logic, we have not arrived at an equivalent translation for\n (1)\n and\n (2).\n The upshot is that if we want to account for the equivalence between\n (1)\n and\n (2)\n within a static semantic framework, we will not be able to maintain a\ncompositional interpretation for individual sentences. We will have to\nassume that the discourse in\n (1)\n is interpreted as a whole. \nThis is counter-intuitive. We know what the individual sentences in\n (1)\n mean and we would like to capture the potential these meanings have\nin combining with other meanings to form a meaningful whole, one which\ncorresponds to a sequence of sentences. Dynamic semantics allows us to\ndeliver a fully compositional analysis of meaning at the sentential\nand supra-sentential level. It does so by guaranteeing that in\ncontrast to classical predicate logic,\n (3)\n and\n (4)\n are equivalent in a dynamic interpretation of\nclassical predicate logic syntax. In particular, the following is\nvalid in dynamic predicate logic: \nIn this kind of dynamic semantics for natural language, the meaning of\na sentence does not correspond to a set of truth-conditions, but\nrather to an action performed on a context. There are two kinds of\nactions. Predications like \\(\\texttt{need-help}(x)\\) or\n\\(\\texttt{met}(m,x)\\) are tests. They merely check if every\nstate/assignment in the current context assigns a value to \\(x\\)\nthat satisfies the relevant predicate; if (and only if) this is the\ncase, the test passes the unaltered assignment on to the output\ncontext. In contrast, the existential quantifier is not a test. It has\nthe potential to alter the context by randomly resetting the value of\nits associated variable. So, \\(\\exists x(\\psi)\\) takes a context,\nrandomly changes the value of \\(x\\) in each assignment in the\ncontext and passes these changed assignments on to the output context\nif they also satisfy the condition contributed by the test\n\\(\\psi\\). \nOne of the main consequences of this semantics is that the scope of\nthe existential quantifier is in principle limitless. It changes the\nvalue of some variable and until a further change to that variable\noccurs, any subsequent test accesses the particular value that was\nset. This also means that the semantics of existential quantification\ncan be given without reference to any scope: the meaning of \\(\\exists\nx\\) is the action that takes a context and returns the same context\nwith at most the value of \\(x\\) randomly replaced by another value.\n(We will work this out in detail below.) \nRight now, two senses of the term dynamic semantics (as applied to\nnatural language) emerge. First and foremost, dynamic semantics is the\ngeneral idea that logical statements do not express truth-conditions\nbut rather actions on contexts (where contexts can be conceptualized\nin various ways). A second understanding of the term dynamic semantics\nis a set of theoretical positions taken within debates concerning the\nsemantics of certain natural language phenomena, most notably\npronominal anaphora. (See below for a similar take on dynamic\nsemantics with respect to presupposition). For the case of\nanaphora, this theoretical understanding embodies the combination of\ntwo hypotheses: (i) pronouns correspond to variables; (ii) indefinites\nare non-quantificational, they simply contribute a dynamic variable\nassignment update. As is clear from the second hypothesis, this\ntheoretical use of the term dynamic semantics presupposes the more\ngeneral view that meanings are actions on contexts.  \nBefore we turn to defining dynamic predicate logic, we should note\nthat the route dynamic semantics takes to account for anaphora is by\nno means the only one to be found in the literature. We could also\nchoose to give up the idea that pronouns are correspond to variables\nand instead assign them a more intricate meaning, one akin to that of\ndefinite descriptions. In the contemporary tradition, such ideas\nemerge as early as Quine 1960 and Geach 1962, before being brought to\nmaturity by (especially) Evans (1977, 1980), Parsons (1978, Other\nInternet Resources), Heim (1990), and Elbourne (2001, 2005). See\nNouwen (forthcoming) for discussion. \nThe previous subsection gave a first glimpse into the basic aim of a\ndynamic semantic framework, which is to define a logical semantics in\nwhich statements express actions and specifically, in which\nexistential quantification has the potential to reset variables, thus\nchanging the context. We get our clue about how to do this by\nexamining the definition of existential quantification in ordinary\npredicate logic. Suppose we work with total assignments on a fixed set\nof variables \\(\\textsf{VAR}\\) over a fixed domain \\(D\\). The set of\ntotal assignments \\(\\textsf{ASSIGN}\\) is therefore the set of all\n(total) functions from \\(\\textsf{VAR}\\) to \\(D\\). \nLet the meaning of atomic formulas like \\(P(x)\\) be the set \\(F\\)\nof all assignments \\(\\alpha\\) such that \\(\\alpha(x)\\) is an object\nsatisfying \\(P\\). \nNow define: \n\n\\[\n\\alpha[x]\\beta := \\forall v \\in \\textsf{VAR}\\setminus\\{x\\}\\ (\\alpha(v) = \\beta(v)).\n\\]\n\n So [\\(x\\)] is the binary relation\n“assignment \\(\\beta\\) is a result of (at most) resetting the\nvalue of the variable \\(x\\) in assignment \\(\\alpha\\)”. As\nalready mentioned, this is an equivalence relation over variable\nassignments. Now the meaning \\(G\\) of \\(\\exists x P(x)\\), will be:\n\n\\[\nG := \\{\\alpha \\in \\textsf{ASSIGN } \\mid \\exists \\beta \\in F \\alpha[x]\\beta \\}.\n\\]\n\n Thus, \\(G\\) is the set of assignments that can be\nsuccessfully reset with respect to \\(x\\) and obtain an assignment\nin \\(F\\) as a result of this resetting. Viewed differently,\n\\(G\\) is the domain of the relation \\(R\\) given by\n\n\\[\\alpha R\\beta := \\alpha[x]\\beta \\textrm{ and } \\beta \\in F.\n\\]\n\n  \nWe could say that \\(G\\) is the precondition for the resetting\naction \\(R\\). Now the idea of \\(\\textsf{DPL}\\) is to take the\nmeaning of \\(\\exists x P(x)\\) to be not the precondition \\(G\\) (as\nin classical static first order logic) but the resetting action\n\\(R\\). In this way we do not lose information since \\(G\\) can\nalways be obtained from \\(R\\). Moreover, the range of the relation\n\\(R\\) consists of assignments \\(\\beta\\) that differ from\nassignments in the precondition \\(G\\) at most with respect to the\nvalue of \\(x\\) and that are also in \\(F\\) (i.e., \\(\\beta(x)\\) is\nin the interpretation of \\(P)\\). The \\(x\\) values stored in the\nrange of the binary relation \\(R\\) are precisely the \\(x\\)\nvalues that satisfy \\(P\\), i.e., the values we were looking\nfor. \nMore generally, we take as \\(\\textsf{DPL}\\)-meanings binary\nrelations between assignments. Such relations can be seen as\n(modeling) resetting actions. This is an instance of an\nadmittedly simplistic but well-known and useful way of modeling\nactions: an action is viewed as a relation between the states of the\nworld before the action and the corresponding states after the\naction. \nHere is the full definition. Assume a non-empty domain \\(D\\), a set\nof variables \\(\\textsf{VAR}\\) and a model \\(\\mathcal{M}=\\langle D,\nI\\rangle\\) of signature \\(\\Sigma\\). Atomic conditions \\(\\pi\\) are of\nthe form \\(P(x_0 , \\ldots ,x_{n-1})\\), where \\(P\\in \\Sigma\\) is of\narity \\(n\\). Atomic resets \\(\\varepsilon\\) are of the form\n\\(\\exists v\\), where \\(v\\) is a variable. The language of predicate\nlogic for \\(\\Sigma\\) is given below (\\(\\cdot\\) is conjunction and\n\\({\\sim}\\) is negation):  \nAssignments are elements \\(\\alpha , \\beta ,\\ldots\\), of\n\\(\\textsf{ASSIGN} := D^{\\textsf{VAR}}\\). We define the\ndynamic/relational semantics for this language as follows:  \nNote that conjunction \\(\\cdot\\) is interpreted as relation\ncomposition, and negation \\({\\sim}\\) is basically interpreted as\ncomplementation with respect to the domain of the relation denoted by\nthe negated formula. \nTruth is defined in terms of relational meanings; we basically project\nthe binary relations between assignments onto their first\ncoordinate: \nWe can define implication \\(\\phi \\rightarrow \\psi\\) as \\({\\sim}(\\phi\n\\cdot {\\sim}\\psi)\\). Applying the truth definition to this gives: \n\\(\\alpha \\vDash \\phi \\rightarrow \\psi \\textrm{ iff } \\forall\n\\beta(\\alpha[\\phi]\\beta \\Rightarrow \\beta \\vDash \\psi)\\), i.e., any\nassignment \\(\\beta\\) that results from updating \\(\\alpha\\) with the\nantecedent \\(\\phi\\) satisfies the consequent \\(\\psi\\).  \nRelational meanings also yield the following beautiful definition of\ndynamic entailment: \nThis definition was first introduced by Hans Kamp in his pioneering\npaper Kamp 1981. Informally, it says that any assignment \\(\\beta\\)\nthat has incorporated the update contributed by \\(\\phi\\) is guaranteed\nto support/satisfy \\(\\psi\\). \nNote that \\({\\sim}\\phi\\) is equivalent to \\((\\phi \\rightarrow \\bot)\\),\nand that \\((\\phi \\rightarrow \\psi)\\) is true iff \\(\\phi \\vDash \\psi\\).\nEqually importantly, we can define \\(\\forall x (\\phi)\\) as \\((\\exists\nx \\rightarrow \\phi)\\). \nA possible alternative notation for \\(\\exists v\\) would be [\\(v := ?\\)] \n(random reset). This emphasizes the connection with random\nassignment in programming languages. \nThe interpretations of predicate symbols are conditions. They\nare subsets of the diagonal \\(\\{\\langle \\alpha , \\alpha \\rangle \\mid\n\\alpha \\in \\textsf{ASSIGN}\\}\\) (which is the meaning of \\(\\top)\\).\nSubsets of the diagonal are tests: they modify nothing and simply pass\non what is OK (satisfies the condition) and throw away what is not.\nThe mapping \\(\\textsf{diag}\\) that sends a set \\(F\\) of assignments\nto a condition \\(\\{\\langle \\alpha , \\alpha \\rangle \\mid \\alpha \\in\nF\\}\\) is the link between the classical static and the dynamic world.\nFor example, the relational composition of \\(\\textsf{diag}(F)\\) and\n\\(\\textsf{diag}(G)\\) is \\(\\textsf{diag}(F\\cap G)\\). \nClassical first-order logic (FOL) can be interpreted in\n\\(\\textsf{DPL}\\) as follows. We assume that the FOL language has the\nfollowing connectives and quantifiers: \\(\\top , \\bot , \\wedge ,\n\\rightarrow , \\exists x\\). We translate as follows: \nWe get that \\([\\phi^*]\\) is the diagonal of the classical\ninterpretation of \\(\\phi\\). Our translation is compositional. It shows\nthat FOL can be taken as a fragment of \\(\\textsf{DPL}\\). \nIt is, conversely, possible to translate any \\(\\textsf{DPL}\\)-formula\n\\(\\phi\\) to a predicate logical formula \\(\\phi\\)°, such that the\ndomain of \\([\\phi]\\) is the classical interpretation of \\(\\phi\\)°.\nOne of the ways to define this translation is by means of a\nprecondition calculus, with Floyd-Hoare rules (Eijck and de Vries\n1992). The following is a variation on this. Take the language of\nstandard predicate logic, with diamond modalities \\(\\langle \\psi\n\\rangle \\phi\\) added, where \\(\\psi\\) ranges over DPL formulas and\n\\(\\alpha \\vDash \\langle \\psi \\rangle \\phi\\) iff there is an assignment\n\\(\\beta\\) with \\(\\alpha[\\psi]\\beta\\), and \\(\\beta \\vDash \\phi\\). Then\nthe following equivalences show that this extension does not increase\nexpressive power. \nAn example of the merits of dynamic predicate logic is that it allows\nfor a straightforward compositional analysis of donkey sentences\n(Geach 1962; see the entry on anaphora). \nThere is obviously a dependency between the pronouns \\(he\\) and \\(it\\)\nand the indefinites a farmer and a donkey,\nrespectively. In a nutshell, the problem for\n (5)\n in a classical analysis is that such an analysis gives us two\nchoices, which taken together do not cover the possible meanings of\n (5).\n If we treat the indefinites as referring to a particular farmer and a\nparticular donkey and the pronouns as simply picking up that same\nentities, then we get a possible yet not very salient reading for\n (5).\n The most prominent reading describes a co-variation between the\nowning relation and the beating relation: any farmer-donkey pair that\nstands in the own relation also stands in the beat\nrelation. Clearly, we will need to interpret the indefinites as\nquantifiers. Yet if we do so, they won’t be able to bind the\nvariables in the consequent of the conditional since a compositional\nanalysis will place the variables contributed by the pronouns outside\nthe classical scope of the existential quantifiers in the antecedent\nof the conditional. That is,\n (6)\n does not yield the correct truth-conditions for\n (5). \nThe dynamic version of\n (6)\n is\n (7),\n which yields the correct truth conditions: any random reset of\n\\(x\\) and \\(y\\) such that \\(x\\) is a farmer and \\(y\\) is a\ndonkey owned by \\(x\\) is also such that \\(x\\) beats\n\\(y\\). \nInterestingly, the translation ( )° of\n (7)\n into predicate logic is not\n (6)\n but\n (8).\n So the problem is not that predicate logic cannot express the\ntruth-conditions of donkey conditionals but that sentences like\n (8)\n are unlikely to be the end product of a compositional interpretation\nprocess (but see Barker and Shan 2008).  \nThis is how\n (8)\n is derived from\n (6): \nThe successful application of dynamic predicate logic to the\ninteraction of quantification and anaphora in natural languages hinges\non the fact that in DPL, existential quantification is dynamic whereas\nuniversal quantification is not. What would happen if universal\nquantification were dynamic too? Note first of all, that it makes no\nsense to define a universal quantification action \\(\\forall x\\) in\nparallel to the random reset action \\(\\exists x\\). This is because\nuniversal quantification only makes sense on a given domain (the\nrestrictor) and with respect to some given property (the\nscope). Second, if we give \\(\\forall x(\\phi)(\\psi)\\) a\ndynamic interpretation, it predicts that universal quantifiers can\nstand in anaphoric relations to singular pronouns across clausal\nboundaries, just as existential quantifiers can. For cases like\n (9),\n this is clearly undesirable. \nHowever, as soon as one looks at plural anaphora it becomes\napparent that the static nature of universal quantification (and, in\nfact, that of other non-indefinite generalized quantifiers) should not\nbe taken for granted. For example,\n (10)\n allows a reading in which they is anaphorically linked to\nevery boy. \nOn the assumption that examples like\n (10)\n should receive a dynamic treatment (see the earlier remark on\nalternative explanations and Nouwen, forthcoming, for discussion), the\nconclusion can only be that universal quantifiers should not be given\na static interpretation. The next question is then what kind of\ninterpretation is appropriate, and how this interpretation can\ndistinguish the infelicitous case of anaphora in\n (9)\n from the case in\n (10).\n One option would be to distinguish between the values assigned to the\nvariables that are bound by the quantifier in its scope and the value\nassigned to that variable outside the scope of the quantifier. (See,\nfor instance, Kamp and Reyle 1993 for such a strategy and Nouwen 2007\nfor discussion.) In order to account for\n (10),\n one would have the variable occurrences bound by the quantifier in\nthe first sentence of\n (10)\n range over individual boys, while that variable gets assigned the\nplurality of all boys outside the quantifier’s scope (i.e. in\nthe second sentence). As van den Berg (1996) was the first to show,\nhowever, such a solution only gets there half-way. In discourse,\npronouns do not just have access to pluralities associated to\nquantifiers, but also to the relations such quantifiers are engaged\nin. For instance, in the second sentence of\n (11)\n the pronoun \\(it\\) covaries with the quantification over the boys in\nthe subject in such a way that the second sentence is understood to\nmean that each boy submitted the paper that \\(he\\) wrote (cf. van den\nBerg 1996; Krifka 1996; Nouwen 2003; Brasoveanu 2007, 2008). \nThe leading idea in dynamic treatments of generalized quantification\nand plural anaphora is to represent plural values not by assigning\npluralities to variables, but rather to adopt a notion of context that\nallows for pluralities (e.g., sets) of assignment functions. Say that\nthe first sentence in\n (11)\n is translated into dynamic predicate logic with dynamic quantifiers\nas follows: \\(\\forall x(\\textrm{boy}(x))(\\exists y\\cdot\n\\textrm{essay}(y)\\cdot \\textrm{wrote}(x,y))\\). The interpretation of\nsuch formulas requires collecting assignment functions in which the\nvalue of \\(x\\) is a boy and the value of \\(y\\) is an essay\nwritten by this boy. The universal quantifier requires such\ncollections to include all possible values for the predicate\nboy. In the subsequent discourse, we now have access to the\nset of all \\(x\\) values, i.e., the set of all boys, the set of all\n\\(y\\) values, i.e., the set of essays written by the boys, as well\nas the individual boy-essay pairs: each atomic assignment \\(f\\) in\nthe set of contextual assignments following the first sentence of\n (11)\n is such that \\(f(y)\\) is an essay written by boy \\(f(x)\\). All that\nis now needed to account for the case of anaphora in\n (11) is the assumption that the universal\n quantification there involves universal quantification over\n assignment functions, rather than just quantification over\n values. See van den Berg (1996), Nouwen (2007,\n forthcoming), Brasoveanu (2007, 2008, 2013) for various ways of\n implementing this idea. \nThe upshot is that given a suitably structured notion of context,\nquantifiers can be given dynamic interpretations generally. An\nimportant consequence is that this kind of analysis extends to\nnon-nominal quantifiers (Brasoveanu 2007). Cases like\n (11)\n could be described as cases of quantificational subordination, and\nthe structured context approach can be seen as designed to offer a\nwindow into the mechanism behind subordination. Cases of modal\nsubordination (Roberts 1987, 1989), like the famous\n (12),\n can receive a parallel treatment. \nThe modal might introduces a quantifier over possible worlds\nthat takes scope over the indefinite a wolf, in the same way\nthat every boy takes scope over an essay in\n (11)\n above. The set of assignment functions that is the output of the\nupdate contributed by the first sentence in\n (12)\n will therefore store a set of possible worlds contributed by\nmight that are epistemically possible relative to the actual\nworld, and a set of wolves that come in in these epistemically\naccessible worlds. The second sentence in\n (12)\n can then further elaborate on the dependency between worlds and\nwolves requiring at least some of the epistemic possibilities to be\nsuch that the corresponding wolf not only comes in but also eats\nyou. \nAlthough anaphora and presuppositions (see below) are the central\nlinguistic phenomena that may be thought to require a dynamic semantic\nanalysis, in principle any aspect of the context could be the target\nof a phenomenon that warrants a dynamic analysis of interpretation.\nBarker’s 2002\ntreatment of the information provided by vague statements is\nillustrative. Barker assumes that contexts contain precise standards\nfor vague adjectives like tall. A sentence like\n (19)\n can then be used in two distinct ways.\n (19)\n John is tall. If the information state contains precise (enough)\ninformation about what counts as tall, then an utterance of\n (19)\n may be used to provide information about John’s height. If,\nhowever, the hearer has no idea about the appropriate precisification\nof an expression like tall (say, s/he is an alien or a\nforeigner), but s/he does have information about John’s height,\nthen\n (19)\n can be used to provide information about the standard. \nContext plays an important role in presupposition. A sentence like\n (13)\n presupposes that John is late. But put this sentence in a context\nproviding this very information, as in\n (14),\n and the presupposition disappears. That John is late is\nasserted in\n (14),\n not presupposed. \nStalnaker 1973 takes\npresupposition to be based on presumed common knowledge. Uttering a\nsentence like\n (13)\n takes for granted that it is common knowledge that John is\nlate. In this sense,\n (13)\n requires the context of utterance to be such that this common\nknowledge is in place. In contrast,\n (14)\n lacks such a requirement simply because the first conjunct in\n (14)\n asserts what the second conjunct takes for granted. The crucial\nassumption made by Stalnaker is that interpretation is incremental in\nthe following sense: for a sentence of the form [\\(S\\)1 and\n\\(S\\)2], the interpretation of \\(S\\)2 occurs in a context which\nis already updated with \\(S\\)1. Schematically: \nStalnaker’s interpretation of the scheme in\n (15)\n is pragmatic: when we encounter a series of clauses in discourse, we\ninterpret these clauses in light of a context that is already\ninformed by the interpretation of previous clauses. This idea of\nincremental interpretation is simple yet powerful and it makes perfect\nsense for complex discourses with conjunctive interpretations (for\ninstance, coordinations with and and simple sequences of\ndeclarative sentences). Since the conjuncts in a conjunction have\nassertoric force, they can be used to update the context in order to\ncreate a new local context. The problem is though that presuppositions\ndo not just disappear in conjunctive environments. Just like\n (14),\n (16) also lacks the requirement that it should be common\nknowledge that John is late. But here the first disjunct does not have\nassertoric force (see, for instance, Schlenker 2009 for discussion).\nIt is not obvious what kind of pragmatic rule could account for the\nlack of a presupposition in\n (16). \nExamples like\n (16)\n call into question the value of an incremental interpretation schema\nlike\n (15).\n On top of that,\n (15)\n is rather presumptuous in its assumptions of how interpretation\nproceeds. Asserting a clause with propositional content \\(p\\) does\nnot automatically make it common knowledge that \\(p\\). Rather, such\nan assertion should be regarded as a proposal to make\n\\(p\\) common knowledge. Whether or not \\(p\\) becomes common\nground is dependent on the willingness of the other interlocutors to\naccept the proposition (for instance, by not objecting against the\nassertion). In other words,\n (15)\n seems ill-suited for capturing the pragmatics of (the dynamics of)\ninformation flow. \nA possible way out is to regard\n (15)\n not as a pragmatic rule, but rather as a semantic rule, couched in a\ndynamic notion of interpretation. This was most prominently proposed\nin Heim 1983b, following Karttunen 1973. Karttunen distinguishes\nglobal contexts, which are contexts relative to which the\ncurrent sentence is evaluated, from local contexts, which are\ncontexts relative to which the current clause (or potentially some\nsub-clausal entity) is interpreted. The idea now is that a rule like\n (15)\n can express the semantics of and. In\n (15),\n \\(C\\) is the global context. A crucial part of the semantics of\nconjunction is that the local context for \\(S\\)2 is the update of\nthe global context with \\(S\\)1. Thus, there is no presupposition in\n (14)\n simply because of the dynamic semantics of and. All\nwe need to account for the lack of presupposition in\n (16)\n is to come up with a semantics for disjunction in which the local\ncontext for the second disjunct has already been updated with the\nnegation of the first disjunct; see Krahmer and Muskens 1996 for such\nan account that also captures interactions between (double) negation\nand anaphora. \nTo make things more concrete let us assume that contexts are sets of\npossible worlds and that an update \\(C[S]\\) of \\(C\\) with a simple\nclause \\(S\\) is \\(C\\cap p\\), where \\(p\\) is the propositional\ncontent of \\(S\\): updating \\(C\\) with a clause outputs the\n\\(C\\) worlds in which the clause is true. The rules in\n (18)\n show a Heimian fragment of a dynamic interpretation of the main\npropositional operators in English. \nSome question the explanatory value of such a dynamic interpretation\nin the sense that the framework fails to account for why there appear\nto be no natural language expressions that encode a minimal variation\nof\n (17),\n where the local context of the second disjunct \\(S\\)2 is \\(C[S1]\\)\ninstead of \\(C[\\textrm{not }S1]\\), or where the local context of\n\\(S\\)1 is based on an update with \\(S\\)2, or where there are no\nlocal contexts at all as in\n (18)\n (see, for instance, Soames 1989). \nIn light of such criticisms, there has been a recent resurgence of\nstatic approaches to presupposition projection, such as the pragmatic\napproaches of Schlenker (2008, 2009), Chemla (2008, Other Internet\nResources) and the semantic (trivalent) approaches of George (2008)\nand Fox (2008). As Rothschild points out though, there is a route to\nmaking a semantics along the lines of\n (17)\n explanatory. To do so, one has to show that permissible dynamic\ninterpretations of connectives share certain properties. As Rothschild\n(2011) shows, an\nexplanatory and empirically adequate dynamic treatment of\npresupposition is possible if we assume that context change potentials\nadhere to certain principles of definedness. Let us assume that\n\\(C[S]\\) (for a simple clause \\(S\\)) is only defined if and only if\nany presupposition of \\(S\\) is true in all the worlds in \\(C\\).\nThe rules in\n (17)\n determine the definedness conditions for complex statements. For\ninstance, according to\n (17)\n [not S] is only undefined in \\(C\\) if \\(S\\) is undefined in\n\\(C\\). Rothschild’s insight is that we can constrain dynamic\ninterpretation by constraining the resulting definedness\nconditions. \nEpistemic logic, the logic of knowledge, is a branch of modal logic\nwhere the modality “\\(i\\) knows that” is studied\n(compare the entries:\n epistemic logic,\n logic of belief revision). The dynamic turn in epistemic logic, which took place\naround 2000, introduced a focus on change of state, but now with\nstates taken to be representations of the knowledge of a set of\nagents. \nIf we fix a set of basic propositions \\(P\\) and a set of agents\n\\(I\\), then a knowledge state for \\(P\\) and \\(I\\) consists of\na set \\(W\\) of possible worlds, together with a valuation function\n\\(V\\) that assigns a subset of \\(P\\) to each \\(w\\) in\n\\(W\\) (if \\(w \\in W\\), then \\(V(w)\\) lists the basic propositions\nthat are true in \\(w)\\) and for each agent \\(i \\in I\\), a relation\n\\(R_i\\) stating the epistemic similarities for \\(i\\) (if \\(wR_i\nw'\\), this means that agent \\(i\\) cannot distinguish world \\(w\\)\nfrom world w\\('\\)). Epistemic models \\(M = (W, V, \\{R_i \\mid\ni \\in I\\})\\) are known as multimodal Kripke models. Pointed epistemic\nmodels are epistemic models with a designated world \\(w_0\\)\nrepresenting the actual world. \nWhat happens to a given epistemic state \\((M, w_0) = ((W, V, \\{ R_i\n\\mid i \\in I\\}), w_0)\\) if a public announcement \\(\\phi\\) is made?\nIntuitively, the world set \\(W\\) of \\(M\\) is restricted to those\nworlds \\(w \\in W\\) where \\(\\phi\\) holds, and the valuation function\n\\(V\\) and epistemic relations \\(R_i\\) are restricted accordingly.\nCall the new model \\(M\\mid\\phi\\). In case \\(\\phi\\) is true in \\(w_0\\),\nthe meaning of the public announcement \\(\\phi\\) can be viewed as a map\nfrom \\((M, w_0)\\) to \\((M\\mid\\phi , w_0)\\). In case \\(\\phi\\) is false\nin \\(w_0\\), no update is possible. \nVeltman’s update logic can be accommodated in public\nannouncement logic (compare the entry on\n common knowledge)\n by allowing public announcements of the form \\(\\Diamond \\phi\\), where\nthe modality is read as reachability under common knowledge. If an\n\\(S\\)5 knowledge state for a set of agents (compare the entry on\n epistemic logic)\n is updated with the public announcement \\(\\Diamond \\phi\\), then in\ncase \\(\\phi\\) is true somewhere in the model, the update changes\nnothing (for in this case \\(M\\mid\\Diamond \\phi\\) equals \\(M)\\), and\notherwise the update yields inconsistency (since public announcements\nare assumed to be true). This is in accordance with the update logic\ndefinition. \nThe logical toolbox for epistemic logic with communicative updates is\ncalled dynamic epistemic logic or DEL. DEL started out from the\nanalysis of the epistemic and doxastic effects of public announcements\n(Plaza 1989; Gerbrandy 1999). Public announcement is interesting\nbecause it creates common knowledge. There is a variety of other kinds\nof announcements—private announcements, group announcements,\nsecret sharing, lies, and so on—that also have well-defined\nepistemic effects. A general framework for a wide class of update\nactions was proposed in Baltag et al. 1999 and Baltag and Moss 2004. A\nfurther generalization to a complete logic of communication and\nchange, with enriched actions that allow changing the facts of the\nworld, is provided in Benthem et al. 2006. A textbook treatment of\ndynamic epistemic logic is given in Ditmarsch et al. 2006. \nWithin an epistemic logic setting, one may represent the communicative\nsituation of an utterance with presuppositions as follows. First, we\nneed to represent what a speaker assumes about what her audience knows\nor believes in a multi-agent belief (or knowledge) state, then we need\nto model the effect of the communicative action on the belief state. A\nsimple way to handle presupposing utterances in dynamic epistemic\nlogic is by modeling a presupposition \\(P\\) as a public\nannouncement “it is common knowledge that \\(P\\)”. In\ncases where it is indeed common knowledge that \\(P\\), an update\nwith this information changes nothing. In cases where \\(P\\) is not\ncommon knowledge, however, the utterance is false, and public\nannouncements of falsehoods yield an inconsistent knowledge state. \nDynamic semantics is particularly suitable to describe how different\ntypes of linguistic material affect different aspects of the\ninformation state. In particular, dynamic semantics allows one to\nefficiently model the difference between at-issue content,\ne.g., the content that is asserted by the utterance of a declarative\nsentence and non-at issue content, content that plays some\nsecondary role. For instance, the at-issue content of\n (19)\n is that John’s neighbor was arrested yesterday: it is the\nmessage the speaker intends to assert. The appositive who I have\nnever met is not at issue. One way to see this is that an\ninterlocutor can only respond to\n (19)\n with No! That’s not true! if s/he intends to challenge\nthe fact that the neighbor was arrested, not if s/he merely wishes to\nexpress their disbelief in the speaker’s claim of never having\nmet the neighbor. \nDynamic semantics is a suitable framework for analyzing what goes on\nwhen such sentences are interpreted, since it naturally allows the\nmodeling of separate streams of information. For instance, AnderBois\net al. 2015 provide an account of sentences like\n (19)\n where the matrix sentence updates a local set of possible worlds. The\nupdated set can be seen as a potential candidate for updating the\ncommon ground with. In contrast, the appositive directly updates the\ncommon ground. Rather than a proposed common ground update,\nit can be seen as an imposed update (see Nouwen 2007 for an\nalternative dynamic logic). The ideas of AnderBois et al. 2015 are\npartly inspired by similar ideas that were successfully applied in the\nrealm of evidentials; see in particular Murray 2014. \nCompositionality has always been an important concern in the use of\nlogical systems in natural language semantics (see the entry on\n compositionality).\n Through the use of higher order logics (see the entries on\n second-order and higher-order logics\n and\n Church’s type theory),\n a thoroughly compositional account of, e.g., the quantificational\nsystem of natural language can be achieved, as is demonstrated in\nclassical Montague grammar (Montague 1974a,b, 1973; compare the entry\non\n logical form).\n We will review how the dynamic approach can be extended to higher\norder systems. The link between dynamic semantics and type theory is\nmore like a liaison than a stable marriage: there is no intrinsic need\nfor the connection. The connection is treated here to explain the\nhistorical influence of Montague grammar on dynamic semantics. \nMost proposals for dynamic versions of Montague grammar develop what\nare in fact higher order versions of dynamic predicate logic (DPL).\nThis holds for Groenendijk and Stokhof 1990; Chierchia 1992, 1995;\nMuskens 1994, 1995, 1996; Eijck 1997; Eijck and Kamp 1997; Kohlhase et\nal. 1996; and Kuschert 2000. These systems all inherit a feature (or\nbug) from the DPL approach: they make re-assignment destructive. DRT\ndoes not suffer from this problem: the discourse representation\nconstruction algorithms of Kamp 1981 and Kamp and Reyle 1993 are\nstated in terms of functions with finite domains, and carefully talk\nabout “taking a fresh discourse referent” to extend the\ndomain of a verifying function, for each new noun phrase to be\nprocessed. \nIn extensional Montague grammar “a man” translates as:\n \nHere \\(P\\), of type \\(e \\rightarrow t\\), is the variable for the VP\nslot: it is assumed that VPs denote sets of entities.  \nIn Dynamic Montague Grammar (DMG) of Groenendijk and Stokhof 1990, the\ntranslation of an indefinite NP introduces an anaphoric index. The\ntranslation of “a man” is  \nInstead of the basic types e and t of classical extensional Montague\ngrammar, DMG has basic types \\(e, t\\) and \\(m (m\\) for marker). States\npick out entities for markers, so they can be viewed as objects of\ntype \\(m \\rightarrow e\\). Abbreviating \\(m \\rightarrow e\\) as \\(s\\)\n(for “state”), we call objects of type \\(s \\rightarrow s\n\\rightarrow t\\) state transitions. The variable \\(P\\) in the DMG\ntranslation of “a man” has type \\(m \\rightarrow s\n\\rightarrow s \\rightarrow t\\), so VP meanings have been lifted from\ntype \\(e \\rightarrow t\\) to this type. Note that \\(\\rightarrow\\)\nassociates to the right, so \\(m \\rightarrow s \\rightarrow s\n\\rightarrow t\\) is shorthand for \\(m \\rightarrow(s \\rightarrow(s\n\\rightarrow t))\\). Indeed, DMG can be viewed as the result of\nsystematic replacement of entities by markers and of truth values by\nstate transitions. A VP meaning for “is happy” is a\nfunction that maps a marker to a state transition. The state\ntransition for marker \\(u_i\\) will check whether the input state maps\n\\(u_i\\) to a happy entity, and whether the output context equals the\ninput context. The variables \\(a\\), a\\('\\) range over\nstates, and the expression \\((u_i \\mid x)a\\) denotes the result of\nresetting the value of \\(u_i\\) in \\(a\\) to \\(x\\), so the old\nvalue of \\(u_i\\) gets destroyed (destructive assignment). The\nanaphoric index \\(i\\) on reference marker \\(u_i\\) is introduced by\nthe translation. In fact, the translation starts from the indexed\nindefinite noun phrase “a man\\(_i\\)”. The connection\nbetween Montagovian compositionality and dynamic semantics as well as\nthe basic Montagovian and dynamic ingredients are much more\ntransparent and streamlined in the typed Logic of Change proposed in\nMuskens 1991, 1995, 1996. Because of this, Muskens’s\nCompositional DRT is probably the de facto standard and\nstarting point for current research in compositional dynamic\nsemantics. An alternative treatment is given in Incremental Typed\nLogic (ITL), an extension to typed logic of a “stack\nsemantics” that is based on variable free indexing and that\navoids the destructive assignment problem. The basic idea of the stack\nsemantics for DPL, developed in Vermeulen 1993, is to replace the\ndestructive assignment of ordinary DPL, which throws away old values\nwhen resetting, by a stack-valued one that allows old values to be\nreused. Stack-valued assignments assign to each variable a stack of\nvalues, the top of the stack being the current value. Existential\nquantification pushes a new value on the stack, but there is also the\npossibility of popping the stack to reuse a previously assigned value.\nEijck’s 2000 ITL is in fact a typed version of stack semantics,\nusing a single stack. \nAssuming a domain of entities, contexts are finite lists of entities.\nIf \\(c\\) is a context of length \\(n\\), then we refer to its\nelements as \\(c[0]\\), \\(\\ldots ,c[n-1]\\), and to its length as\n\\(\\lvert c\\rvert\\). We will refer to the type of contexts of length\n\\(i\\) as \\([e]^i\\). If \\(c\\) is a context in \\([e]^i\\), then\nobjects of type \\(\\{0, \\ldots ,i-1\\}\\) can serve as indices into\n\\(c\\). If \\(c \\in[e]^i\\) and \\(j \\in \\{0, \\ldots ,i-1\\}\\), then\n\\(c[j]\\) is the object of type e that occurs at position \\(j\\) in\nthe context. A key operation on contexts is extension with an element.\nIf \\(c :: [e]^i\\) and \\(x :: e\\) (\\(c\\) is a context of length\n\\(i\\) and \\(x\\) is an entity) then \\(c\\mcaret x\\) is the context\nof length \\(i+1\\) that has elements \\(c\\)[0], \\(\\ldots ,c[i-1],\nx\\). Thus \\(\\mcaret\\) is an operator of type \\([e]^i \\rightarrow e\n\\rightarrow[e]^{i+1}\\). Also note that types like \\([e]^i\\) are in\nfact polymorphic types, with \\(i\\) acting as a type variable. See\nMilner 1978. \nIn ITL there is no destructive assignment, and indefinite noun phrases\ndo not carry indexes in the syntax. The ITL translation of “a\nman” picks up an index from context, as follows:  \nHere \\(P\\) is a variable of type \\(\\{0, \\ldots ,i\\}\n\\rightarrow[e]^{i+1} \\rightarrow [e]^j \\rightarrow t\\), while \\(c\\)\nis a variable of type [\\(e]^i\\) representing the input context of\nlength \\(i\\), and \\(c'\\) is a variable of type [\\(e]^j\\)\nrepresenting the output context. Note that the type \\(\\{0, \\ldots ,i\\}\n\\rightarrow [e]^{i+1} \\rightarrow [e]^j \\rightarrow t\\) for \\(P\\)\nindicates that \\(P\\) first takes an index in the range \\(\\{0,\n\\ldots ,i\\}\\), next a context fitting this range (a context of length\n\\(i+1)\\), next a context of a yet unknown length, and then gives a\ntruth value. \\(P\\) is the type of unary predicates, lifted to the\nlevel of context changers, as follows. Instead of using a variable to\nrange over objects to form an expression of type \\(e\\), a lifted\npredicate uses a variable ranging over the size of an input context to\nform an expression that denotes a changer for that context.  \nThe ITL translation of “a man” has type \n\n\\[(\\{0, \\ldots ,i\\} \\rightarrow[e]^{i+1} \\rightarrow [e]^j \\rightarrow t) \\rightarrow [e]^i \\rightarrow [e]^j \\rightarrow t.\\] \n\n In\n\\(P\\lvert c\\rvert (c\\mcaret x)c'\\), the \\(P\\) variable marks the\nslot for the VP interpretation; \\(\\lvert c\\rvert\\) gives the length of\nthe input context to \\(P\\); it picks up the value \\(i\\), which\nis the position of the next available slot when the context is\nextended. This slot is filled by an object \\(x\\) denoting a man.\nNote that \\(c\\mcaret x[\\lvert c\\rvert ] = c\\mcaret x[i] = x\\), so the\nindex \\(i\\) serves to pick out that man from the context. \nTo see that a dynamic higher order system is expressible in ITL, it is\nenough to show how to define the appropriate dynamic operations.\nAssume \\(\\phi\\) and \\(\\psi\\) have the type of context transitions,\ni.e. type [\\(e] \\rightarrow[e] \\rightarrow t\\) (using [\\(e\\)] for\narbitrary contexts), and that \\(c, c', c''\\) have type [\\(e\\)].\nThen we can define the dynamic existential quantifier, dynamic\nnegation and dynamic composition as follows:  \nDynamic implication \\(\\Rightarrow\\) is defined in the usual way by\nmeans of \\({\\sim}(\\phi; {\\sim}\\psi)\\). \nITL and Muskens style Compositional DRT are not incompatible; see\nBittner 2014 for example. We will end this section by noting that the\nrange of systems integrating Montagovian compositionality and dynamic\nsemantics is far from being completely charted. A recent series of\ncontributions integrating continuation-based and dynamic semantics is\nexploring new ways of integrating and generalizing them; see de Groote\n2006, Bumford and Barker 2013, Charlow 2014, Bumford 2015, and Martin\n2016. \nHopefully, the above has given the reader a sense of Dynamic Semantics\nas a fruitful and flexible approach to meaning and information\nprocessing. Dynamic semantics comes with a set of flexible tools, and\nwith a collection of “killer applications”, such as the\ncompositional treatment of donkey sentences, the account of anaphoric\nlinking, the account of presupposition projection, the account of\nepistemic updating and fine-grained distinctions between different\nkinds of (non-at-issue) updates. Dynamic semantics is a very lively\nsubfield of formal semantics and the cross-linguistic range of\nphenomena for which dynamic approaches are being pursued is expanding\nat an increasing pace.","contact.mail":"rnouwen@gmail.com","contact.domain":"gmail.com"},{"date.published":"2010-08-23","date.changed":"2016-07-12","url":"https://plato.stanford.edu/entries/dynamic-semantics/","author1":"Rick Nouwen","author2":"Adrian Brasoveanu","author1.info":"http://ricknouwen.org","author2.info":"http://www.cwi.nl/~jve","entry":"dynamic-semantics","body.text":"\n\n\nDynamic semantics is a perspective on natural language semantics that\nemphasizes the growth of information in time. It is an approach to\nmeaning representation where pieces of text or discourse are viewed as\ninstructions to update an existing context with new information, the\nresult of which is an updated context. In a slogan: meaning is context\nchange potential. \n\n\nIt is important to be aware of the abstractness of this perspective so\nas to guard against various non sequiturs. For one thing, one could\neasily think that dynamic semantics or update semantics is committed\nat least in part to an internalist idea of semantics since the\ninformation states are “internal”—in the sense that\nthey are wholly contained in the individual mind/brain. In other\nwords, one might think that the information states of dynamic\nsemantics are what Putnam (1975) calls “states in the sense of\nmethodological solipsism”. See the entries on\n scientific realism,\n computational theory of mind,\n externalism about mental content,\n and\n narrow mental content.\n However, the general framework says nothing about what the states\nare. The state could very well include the environment in which the\ninterpreter is embedded and thus contain an “external”\ncomponent.\n\n\nA second possible misunderstanding is that dynamic semantics or update\nsemantics is in complete opposition to classical truth conditional\nsemantics (compare the entries on\n classical logic\n and\n first-order model theory).\n In fact, as this entry will soon make clear, what dynamic semantics\nprovides is a generalization of truth conditional semantics rather\nthan a radically different alternative. The classical meanings become\nthe preconditions for success of the discourse actions.\nDynamic semanticists claim that compositional meanings have\nthe nature of functions or relations and the classical meanings are\nrecoverable from the relational dynamic meanings as\nprojections onto their “input” coordinate.\n\n\nThe point of the use of an abstract framework is not to give empirical\npredictions. This is the task of specific realizations inside the\nframework. The framework of dynamic semantics (i) provides a direction\nof thinking and (ii) allows us to import methods from the mathematical\nstudy of the framework. It follows that the question whether natural\nlanguage meaning is intrinsically dynamic does not have an empirical\nanswer. Still, what can be said is that the study of interpretation as\na linearly-ordered process has proven quite fruitful and\nrewarding.\n\n\nSince dynamic semantics focuses on the discourse actions of sender and\nreceiver, it is in a sense close to use-oriented approaches to meaning\nin philosophy such as the work of Wittgenstein and Dummett. However,\neasy identifications between dynamic semantics and these approaches\nare to be avoided. Dynamic semantics as an abstract framework is\ncompatible with many philosophical ways of viewing meaning and\ninterpretation. Dynamic semantics aims to model meaning and\ninterpretation. You can do that without answering broader\nphilosophical questions such as the question of what it is that makes\nit possible for the subject to be related to these meanings at all.\nFor example, in dynamic predicate logic we take the meaning of\nhorse as given without making any substantial claim about\nwhat it means for a subject to have the concept of horse; we\njust stipulate the subject has it. This is not to say such\nquestions—which are at the center of the work of Wittgenstein\nand Dummett—should not ultimately be answered: it’s just\nthat a model can be of interest even if it does not answer them. (Note\nthat dynamic semantics tries to give a systematic and compositional\naccount of meaning, which makes it markedly different in spirit from\nWittgenstein’s later philosophy.)\n\n\nOne approach to dynamic semantics is\n discourse representation theory\n (DRT, Kamp 1981). (Closely related to Kamp’s approach is Irene\nHeim’s file change semantics (FCS, Heim 1983a) and the\ndiscourse semantics of Seuren 1985). Meanings in DRT are so-called\ndiscourse representation structures (DRSs). These structures\nare a type of database that contains specific pieces of information.\nIn and of itself a DRS is a static object, but DRT can be said to be a\ndynamic semantic framework because it allows us to understand the\nprocess of composing meanings as a process of merging\ndiscourse representation structures. In this way, information change\nbecomes an integral part of the interpretation process.\n\n\nOur main focus in this entry is a second approach to dynamic\nsemantics, although we will compare things to DRT along the way. In\nthis second approach, dynamic meanings are types of actions, things\nthat are individuated by the changes they effect. This is the approach\nassociated with dynamic predicate logic (DPL, Groenendijk and\nStokhof 1991a). According to this dynamic semantic tradition, a\nmeaning is a specification of how a receiver’s information state\nwould be modified. It could for instance be a function that maps an\nold information state to one which has been updated with the\ninformation that the meaning embodies. Alternatively, it could be a\nrelation that expresses the kind of information change that the\nmeaning brings about. (For early work in this tradition, see\nGroenendijk and Stokhof 1991a,b; Muskens 1991; Dekker 1993; Vermeulen\n1993; van Eijck 1994; Vermeulen 1994; Krahmer 1995; van den Berg 1996;\nGroenendijk et al. 1996; Aloni 1997; Muskens et al. 1997).\n\nInterpretation of declarative sentences can be viewed as a product or\nas a process. In the product perspective, one focuses on the notion of\ntruth in a given situation. In the process perspective, interpretation\nof a proposition is viewed as an information updating step that allows\nus to replace a given state of knowledge by a new, more accurate\nknowledge state. Dynamic semantics focuses on interpretation as a\nprocess. \nUpdate semantics is a particular way in which the\ninterpretation-as-process idea can be implemented. The central idea\nbehind update semantics is very simple. We start with a simple model\nof a hearer/receiver who receives items of information sequentially.\nAt every moment the hearer is in a certain state: she possesses\ncertain information. This state is modified by the incoming\ninformation in a systematic way. We now analyze the meaning of the\nincoming items as their contribution to the change of the information\nstate of the receiver. Thus, meanings are seen as actions, or, more\nprecisely, as action types: They are not the concrete changes\nof some given state into another, but what such concrete changes have\nin common. \nPropositional logic (the logic of negation, disjunction and\nconjunction) can be viewed as an update logic as follows. Consider the\ncase where we have three basic propositions \\(p, q\\) and \\(r\\), and\nwe know nothing about their truth. Then there are eight possibilities:\n\\(\\{ \\bar{p} \\bar{q} \\bar{r}, p \\bar{q} \\bar{r}, \\bar{p} q \\bar{r},\n\\bar{p} \\bar{q} r, pq \\bar{r}, p \\bar{q} r, \\bar{p} qr, pqr \\}\\) Here\n\\(\\bar{p} \\bar{q} \\bar{r}\\) should be read as: none of \\(p, q, r\\) is\ntrue, \\(p \\bar{q} \\bar{r}\\) as: \\(p\\) is true but \\(q\\) and\n\\(r\\) are false, and so on. If now \\(\\neg p\\) (“not\n\\(p\\)”) is announced, four of these disappear, and we are\nleft with \\(\\{\\bar{p} \\bar{q} \\bar{r}, \\bar{p} q \\bar{r}, \\bar{p}\n\\bar{q} r, \\bar{p} qr\\}\\). If next \\(q \\vee \\neg r\\) (“\\(q\\)\nor not \\(r\\)”) is announced, the possibility \\(\\bar{p}\n\\bar{q} r\\) gets ruled out, and we are left with \\(\\{ \\bar{p} \\bar{q}\n\\bar{r}, \\bar{p} q \\bar{r}, \\bar{p} qr \\}\\). And so on. We can view\nthe meaning of propositions like \\(\\neg p\\) and \\(q \\vee \\neg r\\) as\nmappings from sets of possibilities to subsets thereof. \nSets of possibilities represent states of knowledge. In the example,\n\\(\\{ \\bar{p} \\bar{q} \\bar{r}, p \\bar{q} \\bar{r}, \\bar{p} q \\bar{r},\n\\bar{p} \\bar{q} r, pq \\bar{r}, p \\bar{q} r, \\bar{p} qr, pqr \\}\\)\nrepresents the state of complete ignorance about propositions \\(p, q,\nr\\). Singleton sets like \\(\\{ pq \\bar{r} \\}\\) represent states of\nfull knowledge about these propositions, and the empty set\n\\(\\varnothing\\) represents the inconsistent state that results from\nprocessing incompatible statements about \\(p, q\\) and \\(r\\). Here\nwe spell out the dynamic meanings of the statements of our\npropositional language:  \nThis gives the meanings of the propositional connectives as operations\nfrom an old context representing a state of knowledge to a new context\nrepresenting the state of knowledge that results from processing the\npropositional information. \nIt is instructive to compare the actions of update semantics to\nprogramming statements and their execution. Such a comparison provides\na first glimpse into how quantification works within a dynamic\nsetting. Programming statements of imperative languages are\ninterpreted (or “executed”) in the context of a machine\nstate, where machine states can be viewed as allocations of values to\nregisters. Assume the registers are named by variables \\(x, y, z\\),\nand that the contents of the registers are natural numbers. Then the\nfollowing is a machine state: \nIf the statement \\(z := x\\) is executed, i.e.,\n“interpreted”, in this state (in C syntax, this statement\nwould have the simpler form \\(z = x)\\), the result is a new machine\nstate: \nIf the sequence of statements \\(x := y\\); \\(y := z\\) is executed in\nthis state, the result is: \nThis illustrates that the result of the sequence \\(z := x\\); \\(x :=\ny\\); \\(y := z\\) is that the values of \\(x\\) and \\(y\\) are\nswapped, with the side effect that the old value of \\(z\\) gets\nlost. In other words, the meaning of the program \\(z := x\\); \\(x :=\ny\\); \\(y := z\\) can be viewed as a mapping from an input machine state\n\\(s\\) to an output machine state \\(s'\\) that differs from \\(s\\)\nin several respects: \\(s'(x) = s(y)\\) and \\(s'(y) = s(x)\\) (that is,\nthe input values of \\(x\\) and \\(y\\) are swapped in the\noutput state), and \\(s'(z) = s'(y)\\). \nNow consider the existential quantifier “there exists an\n\\(x\\) such that \\(A\\)”. Suppose we add this quantifier to\nan imperative programming language. What would be its meaning? It\nwould be an instruction to replace the old value of \\(x\\) by a new\nvalue, where the new value has property \\(A\\). We can decompose\nthis into a part “there exists \\(x\\)” and a test\n“\\(A\\)”. A formula/instruction is a test if\nthe update contributed by it takes the states in the input context one\nat a time and tests that they satisfy a particular condition. If they\ndo, they are included in the output context; if they don’t, they\nare discarded. That is, a test is an update that takes an input\ncontext and outputs a context that is a subset of the input context.\nAll the formulas of propositional logic in the\n Propositional logic as an update logic\n section above are tests. \nThe two parts “there exists \\(x\\)” and the test\n“\\(A\\)” are glued together by sequential composition:\n“\\(\\exists x\\); \\(A\\)”. Focusing on the part\n“\\(\\exists x\\)”, what would be its natural meaning? An\ninstruction to replace the old value of \\(x\\) by some arbitrary new\nvalue. This is again a relation between input states and output\nstates, but the difference with definite assignments like \\(x := y\\)\nis that now the relation is not a function. In fact, this relational\nmeaning of quantifiers shows up in the well known Tarski-style truth\ndefinition for first order logic (compare the entry on\n Tarski’s truth definitions): \n\\(\\exists x\\phi\\) is true in a model \\(M\\) relative to a variable\nassignment \\(\\alpha\\) iff (if and only if) there is some variable\nassignment \\(\\beta\\) such that \\(\\beta\\) differs from \\(\\alpha\\) at\nmost with respect to the value it assigns to \\(x\\) and such that\n\\(\\phi\\) is true in \\(M\\) relative to assignment \\(\\beta\\).  \nImplicit in the Tarskian definition is a relation that holds between\nassignment \\(\\alpha\\) and assignment \\(\\beta\\) iff for all variables\n\\(y\\) that are different from \\(x\\), it is the case that\n\\(\\alpha(y) = \\beta(y)\\). This relation is often called a random\nreset of x and is written as [\\(x\\)]. For any variable\n\\(x\\), the binary relation between total assignments [\\(x\\)] is\nan equivalence relation between assignments, i.e., it is a reflexive,\nsymmetric and transitive binary relation. Below, we see how such\nrelations are put to work in a dynamicised version of first order\npredicate logic.  \nAdopting [\\(x\\)] as the meaning of “\\(\\exists x\\)”,\nnote that its meaning is quite different in nature from that of a test\nin that it creates new values in the output context. In contrast, the\noutput context resulting from an update with a test is always a subset\nof the input context and can therefore never contain anything new\nrelative to the input context. \nInformation states are often called contexts, since the state\nis a precondition for the “interpretation”, i.e., semantic\nevaluation, of expressions in a formal or natural language. The use of\nthe word “context” also makes it clear that we are not\ninterested in the total state of the receiver but only in aspects of\nit relevant to the interpretation of the expressions/informational\nitems we are focusing on. Thus, meanings are often called context\nchange potentials in the dynamic tradition. \nAlthough it is broadly speaking true that the changes brought about by\nmeanings in dynamic semantics concern aspects of context, it\nis important to note that semanticists may mean various things when\nthey talk about context (compare the entries on\n epistemic contextualism\n and\n indexicals),\n and these different views engender varieties of dynamic semantics\nthat deal with a variety of issues. Some of these issues are:\nconstructing an appropriate mechanism for pronominal reference\n(compare the entries on\n anaphora\n and\n reference),\n explaining the semantics of conditionals (compare the entries on\n conditionals\n and\n the logic of conditionals),\n giving a semantic treatment of the distinction between assertion and\npresupposition (compare the entries on\n assertion,\n speech acts,\n implicature,\n pragmatics) and developing a theory of “presupposition\nprojection”, explaining how the interpretation of discourse is\ninfluenced and guided by the common ground that exists between speaker\nand hearer, and developing a theory of how this common ground develops\nas the discourse proceeds (compare the entries on\n pragmatics\n and\n implicature). \nContext plays a role in two separate distinctions. The first\ndistinction is between context and that which modifies the context.\nHere the context is the information state or a suitable abstraction\nthereof (compare the entry on\n semantic conceptions of information).\n The context modifier is (the meaning of) the received informational\nitem. The information cannot be received without the correct kind of\npresupposed information state. The proper analogues in classical\nstatic predicate logic (compare the entries on\n classical logic\n and\n first-order model theory)\n are as follows: the information state is an assignment (environment)\nor a set of assignments, and the received information is a set of\nassignments. The second distinction is between context and content.\nHere the context is something like the storage capacity of the\nreceiver and various other features that could influence how new\nexpressions/informational items are interpreted. The content is the\n(factual, truth conditional) information that is stored. Thus, e.g.,\nthe context in this sense could be a set of registers/variables or in\nDRT/FCS terms, discourse referents or files. The content would then be\nsome set of assignments or, perhaps, world/assignment pairs\nconstraining the values of these discourse referents and the set of\nworlds that are live candidates for the actual world. \nHere is an example to illustrate the distinctions. Suppose we view an\ninformation state as a pair of a finite set of discourse referents and\na set of world/assignment pairs, where the assignments have as domain\nthe given finite set of discourse referents. Such a state would be a\ncontext-in-the-first-sense and the set of discourse referents would be\na context-in-the-second-sense. One basic kind of update would be\nupdate of content: here we constrain the set of world/assignment\npairs, and leave the set of referents constant. A second basic kind of\nupdate would be extension of the set of referents: we extend our\nallocated storage capacity. We modify the given world/assignments\npairs to pairs of worlds and extended assignments, where our extended\nassignments are constrained by the old ones, but take all possible\nvalues on the new referents. Thus, the update process in our example\nis two-dimensional: we have both update of content and update of\ncontext-in-the-second-sense. \nThe motivation for a dynamic semantic framework for natural language\ncomes first and foremost from potential dependencies between the\nreference of a personal pronoun and that of an indefinite noun phrase.\nThe simplest example of such a dependency is that of coreferential\ndiscourse anaphora, as in: \nThe observation is that this sequence of sentences has the same\nmeaning as the single sentence: \nIf we assume that indefinites are existential quantifiers, then the\nanalysis of\n (2)\n is easy. It simply says that there exists an \\(x\\) that is a\nstudent, that met Mary yesterday and that needed her help then. In\npredicate logic: \nHowever, a similar analysis is unavailable for the equivalent\ntwo-sentence example in\n (1).\n This is because interpretation is compositional (see the\nentry on\n compositionality\n for discussion) and in our compositional analysis, we will first come\nto an analysis of Mary met a student yesterday, which will\nhave the form \\(\\exists\nx(\\texttt{student}(x)\\wedge\\texttt{met}(m,x))\\). Likewise, the second\nsentence will correspond to \\(\\texttt{need-help}(x)\\). Assuming that\nthe default mode of combining multiple sentences is to conjoin them,\nwe now arrive at: \nThe final occurrence of \\(x\\) is not bound and so in classical\npredicate logic, we have not arrived at an equivalent translation for\n (1)\n and\n (2).\n The upshot is that if we want to account for the equivalence between\n (1)\n and\n (2)\n within a static semantic framework, we will not be able to maintain a\ncompositional interpretation for individual sentences. We will have to\nassume that the discourse in\n (1)\n is interpreted as a whole. \nThis is counter-intuitive. We know what the individual sentences in\n (1)\n mean and we would like to capture the potential these meanings have\nin combining with other meanings to form a meaningful whole, one which\ncorresponds to a sequence of sentences. Dynamic semantics allows us to\ndeliver a fully compositional analysis of meaning at the sentential\nand supra-sentential level. It does so by guaranteeing that in\ncontrast to classical predicate logic,\n (3)\n and\n (4)\n are equivalent in a dynamic interpretation of\nclassical predicate logic syntax. In particular, the following is\nvalid in dynamic predicate logic: \nIn this kind of dynamic semantics for natural language, the meaning of\na sentence does not correspond to a set of truth-conditions, but\nrather to an action performed on a context. There are two kinds of\nactions. Predications like \\(\\texttt{need-help}(x)\\) or\n\\(\\texttt{met}(m,x)\\) are tests. They merely check if every\nstate/assignment in the current context assigns a value to \\(x\\)\nthat satisfies the relevant predicate; if (and only if) this is the\ncase, the test passes the unaltered assignment on to the output\ncontext. In contrast, the existential quantifier is not a test. It has\nthe potential to alter the context by randomly resetting the value of\nits associated variable. So, \\(\\exists x(\\psi)\\) takes a context,\nrandomly changes the value of \\(x\\) in each assignment in the\ncontext and passes these changed assignments on to the output context\nif they also satisfy the condition contributed by the test\n\\(\\psi\\). \nOne of the main consequences of this semantics is that the scope of\nthe existential quantifier is in principle limitless. It changes the\nvalue of some variable and until a further change to that variable\noccurs, any subsequent test accesses the particular value that was\nset. This also means that the semantics of existential quantification\ncan be given without reference to any scope: the meaning of \\(\\exists\nx\\) is the action that takes a context and returns the same context\nwith at most the value of \\(x\\) randomly replaced by another value.\n(We will work this out in detail below.) \nRight now, two senses of the term dynamic semantics (as applied to\nnatural language) emerge. First and foremost, dynamic semantics is the\ngeneral idea that logical statements do not express truth-conditions\nbut rather actions on contexts (where contexts can be conceptualized\nin various ways). A second understanding of the term dynamic semantics\nis a set of theoretical positions taken within debates concerning the\nsemantics of certain natural language phenomena, most notably\npronominal anaphora. (See below for a similar take on dynamic\nsemantics with respect to presupposition). For the case of\nanaphora, this theoretical understanding embodies the combination of\ntwo hypotheses: (i) pronouns correspond to variables; (ii) indefinites\nare non-quantificational, they simply contribute a dynamic variable\nassignment update. As is clear from the second hypothesis, this\ntheoretical use of the term dynamic semantics presupposes the more\ngeneral view that meanings are actions on contexts.  \nBefore we turn to defining dynamic predicate logic, we should note\nthat the route dynamic semantics takes to account for anaphora is by\nno means the only one to be found in the literature. We could also\nchoose to give up the idea that pronouns are correspond to variables\nand instead assign them a more intricate meaning, one akin to that of\ndefinite descriptions. In the contemporary tradition, such ideas\nemerge as early as Quine 1960 and Geach 1962, before being brought to\nmaturity by (especially) Evans (1977, 1980), Parsons (1978, Other\nInternet Resources), Heim (1990), and Elbourne (2001, 2005). See\nNouwen (forthcoming) for discussion. \nThe previous subsection gave a first glimpse into the basic aim of a\ndynamic semantic framework, which is to define a logical semantics in\nwhich statements express actions and specifically, in which\nexistential quantification has the potential to reset variables, thus\nchanging the context. We get our clue about how to do this by\nexamining the definition of existential quantification in ordinary\npredicate logic. Suppose we work with total assignments on a fixed set\nof variables \\(\\textsf{VAR}\\) over a fixed domain \\(D\\). The set of\ntotal assignments \\(\\textsf{ASSIGN}\\) is therefore the set of all\n(total) functions from \\(\\textsf{VAR}\\) to \\(D\\). \nLet the meaning of atomic formulas like \\(P(x)\\) be the set \\(F\\)\nof all assignments \\(\\alpha\\) such that \\(\\alpha(x)\\) is an object\nsatisfying \\(P\\). \nNow define: \n\n\\[\n\\alpha[x]\\beta := \\forall v \\in \\textsf{VAR}\\setminus\\{x\\}\\ (\\alpha(v) = \\beta(v)).\n\\]\n\n So [\\(x\\)] is the binary relation\n“assignment \\(\\beta\\) is a result of (at most) resetting the\nvalue of the variable \\(x\\) in assignment \\(\\alpha\\)”. As\nalready mentioned, this is an equivalence relation over variable\nassignments. Now the meaning \\(G\\) of \\(\\exists x P(x)\\), will be:\n\n\\[\nG := \\{\\alpha \\in \\textsf{ASSIGN } \\mid \\exists \\beta \\in F \\alpha[x]\\beta \\}.\n\\]\n\n Thus, \\(G\\) is the set of assignments that can be\nsuccessfully reset with respect to \\(x\\) and obtain an assignment\nin \\(F\\) as a result of this resetting. Viewed differently,\n\\(G\\) is the domain of the relation \\(R\\) given by\n\n\\[\\alpha R\\beta := \\alpha[x]\\beta \\textrm{ and } \\beta \\in F.\n\\]\n\n  \nWe could say that \\(G\\) is the precondition for the resetting\naction \\(R\\). Now the idea of \\(\\textsf{DPL}\\) is to take the\nmeaning of \\(\\exists x P(x)\\) to be not the precondition \\(G\\) (as\nin classical static first order logic) but the resetting action\n\\(R\\). In this way we do not lose information since \\(G\\) can\nalways be obtained from \\(R\\). Moreover, the range of the relation\n\\(R\\) consists of assignments \\(\\beta\\) that differ from\nassignments in the precondition \\(G\\) at most with respect to the\nvalue of \\(x\\) and that are also in \\(F\\) (i.e., \\(\\beta(x)\\) is\nin the interpretation of \\(P)\\). The \\(x\\) values stored in the\nrange of the binary relation \\(R\\) are precisely the \\(x\\)\nvalues that satisfy \\(P\\), i.e., the values we were looking\nfor. \nMore generally, we take as \\(\\textsf{DPL}\\)-meanings binary\nrelations between assignments. Such relations can be seen as\n(modeling) resetting actions. This is an instance of an\nadmittedly simplistic but well-known and useful way of modeling\nactions: an action is viewed as a relation between the states of the\nworld before the action and the corresponding states after the\naction. \nHere is the full definition. Assume a non-empty domain \\(D\\), a set\nof variables \\(\\textsf{VAR}\\) and a model \\(\\mathcal{M}=\\langle D,\nI\\rangle\\) of signature \\(\\Sigma\\). Atomic conditions \\(\\pi\\) are of\nthe form \\(P(x_0 , \\ldots ,x_{n-1})\\), where \\(P\\in \\Sigma\\) is of\narity \\(n\\). Atomic resets \\(\\varepsilon\\) are of the form\n\\(\\exists v\\), where \\(v\\) is a variable. The language of predicate\nlogic for \\(\\Sigma\\) is given below (\\(\\cdot\\) is conjunction and\n\\({\\sim}\\) is negation):  \nAssignments are elements \\(\\alpha , \\beta ,\\ldots\\), of\n\\(\\textsf{ASSIGN} := D^{\\textsf{VAR}}\\). We define the\ndynamic/relational semantics for this language as follows:  \nNote that conjunction \\(\\cdot\\) is interpreted as relation\ncomposition, and negation \\({\\sim}\\) is basically interpreted as\ncomplementation with respect to the domain of the relation denoted by\nthe negated formula. \nTruth is defined in terms of relational meanings; we basically project\nthe binary relations between assignments onto their first\ncoordinate: \nWe can define implication \\(\\phi \\rightarrow \\psi\\) as \\({\\sim}(\\phi\n\\cdot {\\sim}\\psi)\\). Applying the truth definition to this gives: \n\\(\\alpha \\vDash \\phi \\rightarrow \\psi \\textrm{ iff } \\forall\n\\beta(\\alpha[\\phi]\\beta \\Rightarrow \\beta \\vDash \\psi)\\), i.e., any\nassignment \\(\\beta\\) that results from updating \\(\\alpha\\) with the\nantecedent \\(\\phi\\) satisfies the consequent \\(\\psi\\).  \nRelational meanings also yield the following beautiful definition of\ndynamic entailment: \nThis definition was first introduced by Hans Kamp in his pioneering\npaper Kamp 1981. Informally, it says that any assignment \\(\\beta\\)\nthat has incorporated the update contributed by \\(\\phi\\) is guaranteed\nto support/satisfy \\(\\psi\\). \nNote that \\({\\sim}\\phi\\) is equivalent to \\((\\phi \\rightarrow \\bot)\\),\nand that \\((\\phi \\rightarrow \\psi)\\) is true iff \\(\\phi \\vDash \\psi\\).\nEqually importantly, we can define \\(\\forall x (\\phi)\\) as \\((\\exists\nx \\rightarrow \\phi)\\). \nA possible alternative notation for \\(\\exists v\\) would be [\\(v := ?\\)] \n(random reset). This emphasizes the connection with random\nassignment in programming languages. \nThe interpretations of predicate symbols are conditions. They\nare subsets of the diagonal \\(\\{\\langle \\alpha , \\alpha \\rangle \\mid\n\\alpha \\in \\textsf{ASSIGN}\\}\\) (which is the meaning of \\(\\top)\\).\nSubsets of the diagonal are tests: they modify nothing and simply pass\non what is OK (satisfies the condition) and throw away what is not.\nThe mapping \\(\\textsf{diag}\\) that sends a set \\(F\\) of assignments\nto a condition \\(\\{\\langle \\alpha , \\alpha \\rangle \\mid \\alpha \\in\nF\\}\\) is the link between the classical static and the dynamic world.\nFor example, the relational composition of \\(\\textsf{diag}(F)\\) and\n\\(\\textsf{diag}(G)\\) is \\(\\textsf{diag}(F\\cap G)\\). \nClassical first-order logic (FOL) can be interpreted in\n\\(\\textsf{DPL}\\) as follows. We assume that the FOL language has the\nfollowing connectives and quantifiers: \\(\\top , \\bot , \\wedge ,\n\\rightarrow , \\exists x\\). We translate as follows: \nWe get that \\([\\phi^*]\\) is the diagonal of the classical\ninterpretation of \\(\\phi\\). Our translation is compositional. It shows\nthat FOL can be taken as a fragment of \\(\\textsf{DPL}\\). \nIt is, conversely, possible to translate any \\(\\textsf{DPL}\\)-formula\n\\(\\phi\\) to a predicate logical formula \\(\\phi\\)°, such that the\ndomain of \\([\\phi]\\) is the classical interpretation of \\(\\phi\\)°.\nOne of the ways to define this translation is by means of a\nprecondition calculus, with Floyd-Hoare rules (Eijck and de Vries\n1992). The following is a variation on this. Take the language of\nstandard predicate logic, with diamond modalities \\(\\langle \\psi\n\\rangle \\phi\\) added, where \\(\\psi\\) ranges over DPL formulas and\n\\(\\alpha \\vDash \\langle \\psi \\rangle \\phi\\) iff there is an assignment\n\\(\\beta\\) with \\(\\alpha[\\psi]\\beta\\), and \\(\\beta \\vDash \\phi\\). Then\nthe following equivalences show that this extension does not increase\nexpressive power. \nAn example of the merits of dynamic predicate logic is that it allows\nfor a straightforward compositional analysis of donkey sentences\n(Geach 1962; see the entry on anaphora). \nThere is obviously a dependency between the pronouns \\(he\\) and \\(it\\)\nand the indefinites a farmer and a donkey,\nrespectively. In a nutshell, the problem for\n (5)\n in a classical analysis is that such an analysis gives us two\nchoices, which taken together do not cover the possible meanings of\n (5).\n If we treat the indefinites as referring to a particular farmer and a\nparticular donkey and the pronouns as simply picking up that same\nentities, then we get a possible yet not very salient reading for\n (5).\n The most prominent reading describes a co-variation between the\nowning relation and the beating relation: any farmer-donkey pair that\nstands in the own relation also stands in the beat\nrelation. Clearly, we will need to interpret the indefinites as\nquantifiers. Yet if we do so, they won’t be able to bind the\nvariables in the consequent of the conditional since a compositional\nanalysis will place the variables contributed by the pronouns outside\nthe classical scope of the existential quantifiers in the antecedent\nof the conditional. That is,\n (6)\n does not yield the correct truth-conditions for\n (5). \nThe dynamic version of\n (6)\n is\n (7),\n which yields the correct truth conditions: any random reset of\n\\(x\\) and \\(y\\) such that \\(x\\) is a farmer and \\(y\\) is a\ndonkey owned by \\(x\\) is also such that \\(x\\) beats\n\\(y\\). \nInterestingly, the translation ( )° of\n (7)\n into predicate logic is not\n (6)\n but\n (8).\n So the problem is not that predicate logic cannot express the\ntruth-conditions of donkey conditionals but that sentences like\n (8)\n are unlikely to be the end product of a compositional interpretation\nprocess (but see Barker and Shan 2008).  \nThis is how\n (8)\n is derived from\n (6): \nThe successful application of dynamic predicate logic to the\ninteraction of quantification and anaphora in natural languages hinges\non the fact that in DPL, existential quantification is dynamic whereas\nuniversal quantification is not. What would happen if universal\nquantification were dynamic too? Note first of all, that it makes no\nsense to define a universal quantification action \\(\\forall x\\) in\nparallel to the random reset action \\(\\exists x\\). This is because\nuniversal quantification only makes sense on a given domain (the\nrestrictor) and with respect to some given property (the\nscope). Second, if we give \\(\\forall x(\\phi)(\\psi)\\) a\ndynamic interpretation, it predicts that universal quantifiers can\nstand in anaphoric relations to singular pronouns across clausal\nboundaries, just as existential quantifiers can. For cases like\n (9),\n this is clearly undesirable. \nHowever, as soon as one looks at plural anaphora it becomes\napparent that the static nature of universal quantification (and, in\nfact, that of other non-indefinite generalized quantifiers) should not\nbe taken for granted. For example,\n (10)\n allows a reading in which they is anaphorically linked to\nevery boy. \nOn the assumption that examples like\n (10)\n should receive a dynamic treatment (see the earlier remark on\nalternative explanations and Nouwen, forthcoming, for discussion), the\nconclusion can only be that universal quantifiers should not be given\na static interpretation. The next question is then what kind of\ninterpretation is appropriate, and how this interpretation can\ndistinguish the infelicitous case of anaphora in\n (9)\n from the case in\n (10).\n One option would be to distinguish between the values assigned to the\nvariables that are bound by the quantifier in its scope and the value\nassigned to that variable outside the scope of the quantifier. (See,\nfor instance, Kamp and Reyle 1993 for such a strategy and Nouwen 2007\nfor discussion.) In order to account for\n (10),\n one would have the variable occurrences bound by the quantifier in\nthe first sentence of\n (10)\n range over individual boys, while that variable gets assigned the\nplurality of all boys outside the quantifier’s scope (i.e. in\nthe second sentence). As van den Berg (1996) was the first to show,\nhowever, such a solution only gets there half-way. In discourse,\npronouns do not just have access to pluralities associated to\nquantifiers, but also to the relations such quantifiers are engaged\nin. For instance, in the second sentence of\n (11)\n the pronoun \\(it\\) covaries with the quantification over the boys in\nthe subject in such a way that the second sentence is understood to\nmean that each boy submitted the paper that \\(he\\) wrote (cf. van den\nBerg 1996; Krifka 1996; Nouwen 2003; Brasoveanu 2007, 2008). \nThe leading idea in dynamic treatments of generalized quantification\nand plural anaphora is to represent plural values not by assigning\npluralities to variables, but rather to adopt a notion of context that\nallows for pluralities (e.g., sets) of assignment functions. Say that\nthe first sentence in\n (11)\n is translated into dynamic predicate logic with dynamic quantifiers\nas follows: \\(\\forall x(\\textrm{boy}(x))(\\exists y\\cdot\n\\textrm{essay}(y)\\cdot \\textrm{wrote}(x,y))\\). The interpretation of\nsuch formulas requires collecting assignment functions in which the\nvalue of \\(x\\) is a boy and the value of \\(y\\) is an essay\nwritten by this boy. The universal quantifier requires such\ncollections to include all possible values for the predicate\nboy. In the subsequent discourse, we now have access to the\nset of all \\(x\\) values, i.e., the set of all boys, the set of all\n\\(y\\) values, i.e., the set of essays written by the boys, as well\nas the individual boy-essay pairs: each atomic assignment \\(f\\) in\nthe set of contextual assignments following the first sentence of\n (11)\n is such that \\(f(y)\\) is an essay written by boy \\(f(x)\\). All that\nis now needed to account for the case of anaphora in\n (11) is the assumption that the universal\n quantification there involves universal quantification over\n assignment functions, rather than just quantification over\n values. See van den Berg (1996), Nouwen (2007,\n forthcoming), Brasoveanu (2007, 2008, 2013) for various ways of\n implementing this idea. \nThe upshot is that given a suitably structured notion of context,\nquantifiers can be given dynamic interpretations generally. An\nimportant consequence is that this kind of analysis extends to\nnon-nominal quantifiers (Brasoveanu 2007). Cases like\n (11)\n could be described as cases of quantificational subordination, and\nthe structured context approach can be seen as designed to offer a\nwindow into the mechanism behind subordination. Cases of modal\nsubordination (Roberts 1987, 1989), like the famous\n (12),\n can receive a parallel treatment. \nThe modal might introduces a quantifier over possible worlds\nthat takes scope over the indefinite a wolf, in the same way\nthat every boy takes scope over an essay in\n (11)\n above. The set of assignment functions that is the output of the\nupdate contributed by the first sentence in\n (12)\n will therefore store a set of possible worlds contributed by\nmight that are epistemically possible relative to the actual\nworld, and a set of wolves that come in in these epistemically\naccessible worlds. The second sentence in\n (12)\n can then further elaborate on the dependency between worlds and\nwolves requiring at least some of the epistemic possibilities to be\nsuch that the corresponding wolf not only comes in but also eats\nyou. \nAlthough anaphora and presuppositions (see below) are the central\nlinguistic phenomena that may be thought to require a dynamic semantic\nanalysis, in principle any aspect of the context could be the target\nof a phenomenon that warrants a dynamic analysis of interpretation.\nBarker’s 2002\ntreatment of the information provided by vague statements is\nillustrative. Barker assumes that contexts contain precise standards\nfor vague adjectives like tall. A sentence like\n (19)\n can then be used in two distinct ways.\n (19)\n John is tall. If the information state contains precise (enough)\ninformation about what counts as tall, then an utterance of\n (19)\n may be used to provide information about John’s height. If,\nhowever, the hearer has no idea about the appropriate precisification\nof an expression like tall (say, s/he is an alien or a\nforeigner), but s/he does have information about John’s height,\nthen\n (19)\n can be used to provide information about the standard. \nContext plays an important role in presupposition. A sentence like\n (13)\n presupposes that John is late. But put this sentence in a context\nproviding this very information, as in\n (14),\n and the presupposition disappears. That John is late is\nasserted in\n (14),\n not presupposed. \nStalnaker 1973 takes\npresupposition to be based on presumed common knowledge. Uttering a\nsentence like\n (13)\n takes for granted that it is common knowledge that John is\nlate. In this sense,\n (13)\n requires the context of utterance to be such that this common\nknowledge is in place. In contrast,\n (14)\n lacks such a requirement simply because the first conjunct in\n (14)\n asserts what the second conjunct takes for granted. The crucial\nassumption made by Stalnaker is that interpretation is incremental in\nthe following sense: for a sentence of the form [\\(S\\)1 and\n\\(S\\)2], the interpretation of \\(S\\)2 occurs in a context which\nis already updated with \\(S\\)1. Schematically: \nStalnaker’s interpretation of the scheme in\n (15)\n is pragmatic: when we encounter a series of clauses in discourse, we\ninterpret these clauses in light of a context that is already\ninformed by the interpretation of previous clauses. This idea of\nincremental interpretation is simple yet powerful and it makes perfect\nsense for complex discourses with conjunctive interpretations (for\ninstance, coordinations with and and simple sequences of\ndeclarative sentences). Since the conjuncts in a conjunction have\nassertoric force, they can be used to update the context in order to\ncreate a new local context. The problem is though that presuppositions\ndo not just disappear in conjunctive environments. Just like\n (14),\n (16) also lacks the requirement that it should be common\nknowledge that John is late. But here the first disjunct does not have\nassertoric force (see, for instance, Schlenker 2009 for discussion).\nIt is not obvious what kind of pragmatic rule could account for the\nlack of a presupposition in\n (16). \nExamples like\n (16)\n call into question the value of an incremental interpretation schema\nlike\n (15).\n On top of that,\n (15)\n is rather presumptuous in its assumptions of how interpretation\nproceeds. Asserting a clause with propositional content \\(p\\) does\nnot automatically make it common knowledge that \\(p\\). Rather, such\nan assertion should be regarded as a proposal to make\n\\(p\\) common knowledge. Whether or not \\(p\\) becomes common\nground is dependent on the willingness of the other interlocutors to\naccept the proposition (for instance, by not objecting against the\nassertion). In other words,\n (15)\n seems ill-suited for capturing the pragmatics of (the dynamics of)\ninformation flow. \nA possible way out is to regard\n (15)\n not as a pragmatic rule, but rather as a semantic rule, couched in a\ndynamic notion of interpretation. This was most prominently proposed\nin Heim 1983b, following Karttunen 1973. Karttunen distinguishes\nglobal contexts, which are contexts relative to which the\ncurrent sentence is evaluated, from local contexts, which are\ncontexts relative to which the current clause (or potentially some\nsub-clausal entity) is interpreted. The idea now is that a rule like\n (15)\n can express the semantics of and. In\n (15),\n \\(C\\) is the global context. A crucial part of the semantics of\nconjunction is that the local context for \\(S\\)2 is the update of\nthe global context with \\(S\\)1. Thus, there is no presupposition in\n (14)\n simply because of the dynamic semantics of and. All\nwe need to account for the lack of presupposition in\n (16)\n is to come up with a semantics for disjunction in which the local\ncontext for the second disjunct has already been updated with the\nnegation of the first disjunct; see Krahmer and Muskens 1996 for such\nan account that also captures interactions between (double) negation\nand anaphora. \nTo make things more concrete let us assume that contexts are sets of\npossible worlds and that an update \\(C[S]\\) of \\(C\\) with a simple\nclause \\(S\\) is \\(C\\cap p\\), where \\(p\\) is the propositional\ncontent of \\(S\\): updating \\(C\\) with a clause outputs the\n\\(C\\) worlds in which the clause is true. The rules in\n (18)\n show a Heimian fragment of a dynamic interpretation of the main\npropositional operators in English. \nSome question the explanatory value of such a dynamic interpretation\nin the sense that the framework fails to account for why there appear\nto be no natural language expressions that encode a minimal variation\nof\n (17),\n where the local context of the second disjunct \\(S\\)2 is \\(C[S1]\\)\ninstead of \\(C[\\textrm{not }S1]\\), or where the local context of\n\\(S\\)1 is based on an update with \\(S\\)2, or where there are no\nlocal contexts at all as in\n (18)\n (see, for instance, Soames 1989). \nIn light of such criticisms, there has been a recent resurgence of\nstatic approaches to presupposition projection, such as the pragmatic\napproaches of Schlenker (2008, 2009), Chemla (2008, Other Internet\nResources) and the semantic (trivalent) approaches of George (2008)\nand Fox (2008). As Rothschild points out though, there is a route to\nmaking a semantics along the lines of\n (17)\n explanatory. To do so, one has to show that permissible dynamic\ninterpretations of connectives share certain properties. As Rothschild\n(2011) shows, an\nexplanatory and empirically adequate dynamic treatment of\npresupposition is possible if we assume that context change potentials\nadhere to certain principles of definedness. Let us assume that\n\\(C[S]\\) (for a simple clause \\(S\\)) is only defined if and only if\nany presupposition of \\(S\\) is true in all the worlds in \\(C\\).\nThe rules in\n (17)\n determine the definedness conditions for complex statements. For\ninstance, according to\n (17)\n [not S] is only undefined in \\(C\\) if \\(S\\) is undefined in\n\\(C\\). Rothschild’s insight is that we can constrain dynamic\ninterpretation by constraining the resulting definedness\nconditions. \nEpistemic logic, the logic of knowledge, is a branch of modal logic\nwhere the modality “\\(i\\) knows that” is studied\n(compare the entries:\n epistemic logic,\n logic of belief revision). The dynamic turn in epistemic logic, which took place\naround 2000, introduced a focus on change of state, but now with\nstates taken to be representations of the knowledge of a set of\nagents. \nIf we fix a set of basic propositions \\(P\\) and a set of agents\n\\(I\\), then a knowledge state for \\(P\\) and \\(I\\) consists of\na set \\(W\\) of possible worlds, together with a valuation function\n\\(V\\) that assigns a subset of \\(P\\) to each \\(w\\) in\n\\(W\\) (if \\(w \\in W\\), then \\(V(w)\\) lists the basic propositions\nthat are true in \\(w)\\) and for each agent \\(i \\in I\\), a relation\n\\(R_i\\) stating the epistemic similarities for \\(i\\) (if \\(wR_i\nw'\\), this means that agent \\(i\\) cannot distinguish world \\(w\\)\nfrom world w\\('\\)). Epistemic models \\(M = (W, V, \\{R_i \\mid\ni \\in I\\})\\) are known as multimodal Kripke models. Pointed epistemic\nmodels are epistemic models with a designated world \\(w_0\\)\nrepresenting the actual world. \nWhat happens to a given epistemic state \\((M, w_0) = ((W, V, \\{ R_i\n\\mid i \\in I\\}), w_0)\\) if a public announcement \\(\\phi\\) is made?\nIntuitively, the world set \\(W\\) of \\(M\\) is restricted to those\nworlds \\(w \\in W\\) where \\(\\phi\\) holds, and the valuation function\n\\(V\\) and epistemic relations \\(R_i\\) are restricted accordingly.\nCall the new model \\(M\\mid\\phi\\). In case \\(\\phi\\) is true in \\(w_0\\),\nthe meaning of the public announcement \\(\\phi\\) can be viewed as a map\nfrom \\((M, w_0)\\) to \\((M\\mid\\phi , w_0)\\). In case \\(\\phi\\) is false\nin \\(w_0\\), no update is possible. \nVeltman’s update logic can be accommodated in public\nannouncement logic (compare the entry on\n common knowledge)\n by allowing public announcements of the form \\(\\Diamond \\phi\\), where\nthe modality is read as reachability under common knowledge. If an\n\\(S\\)5 knowledge state for a set of agents (compare the entry on\n epistemic logic)\n is updated with the public announcement \\(\\Diamond \\phi\\), then in\ncase \\(\\phi\\) is true somewhere in the model, the update changes\nnothing (for in this case \\(M\\mid\\Diamond \\phi\\) equals \\(M)\\), and\notherwise the update yields inconsistency (since public announcements\nare assumed to be true). This is in accordance with the update logic\ndefinition. \nThe logical toolbox for epistemic logic with communicative updates is\ncalled dynamic epistemic logic or DEL. DEL started out from the\nanalysis of the epistemic and doxastic effects of public announcements\n(Plaza 1989; Gerbrandy 1999). Public announcement is interesting\nbecause it creates common knowledge. There is a variety of other kinds\nof announcements—private announcements, group announcements,\nsecret sharing, lies, and so on—that also have well-defined\nepistemic effects. A general framework for a wide class of update\nactions was proposed in Baltag et al. 1999 and Baltag and Moss 2004. A\nfurther generalization to a complete logic of communication and\nchange, with enriched actions that allow changing the facts of the\nworld, is provided in Benthem et al. 2006. A textbook treatment of\ndynamic epistemic logic is given in Ditmarsch et al. 2006. \nWithin an epistemic logic setting, one may represent the communicative\nsituation of an utterance with presuppositions as follows. First, we\nneed to represent what a speaker assumes about what her audience knows\nor believes in a multi-agent belief (or knowledge) state, then we need\nto model the effect of the communicative action on the belief state. A\nsimple way to handle presupposing utterances in dynamic epistemic\nlogic is by modeling a presupposition \\(P\\) as a public\nannouncement “it is common knowledge that \\(P\\)”. In\ncases where it is indeed common knowledge that \\(P\\), an update\nwith this information changes nothing. In cases where \\(P\\) is not\ncommon knowledge, however, the utterance is false, and public\nannouncements of falsehoods yield an inconsistent knowledge state. \nDynamic semantics is particularly suitable to describe how different\ntypes of linguistic material affect different aspects of the\ninformation state. In particular, dynamic semantics allows one to\nefficiently model the difference between at-issue content,\ne.g., the content that is asserted by the utterance of a declarative\nsentence and non-at issue content, content that plays some\nsecondary role. For instance, the at-issue content of\n (19)\n is that John’s neighbor was arrested yesterday: it is the\nmessage the speaker intends to assert. The appositive who I have\nnever met is not at issue. One way to see this is that an\ninterlocutor can only respond to\n (19)\n with No! That’s not true! if s/he intends to challenge\nthe fact that the neighbor was arrested, not if s/he merely wishes to\nexpress their disbelief in the speaker’s claim of never having\nmet the neighbor. \nDynamic semantics is a suitable framework for analyzing what goes on\nwhen such sentences are interpreted, since it naturally allows the\nmodeling of separate streams of information. For instance, AnderBois\net al. 2015 provide an account of sentences like\n (19)\n where the matrix sentence updates a local set of possible worlds. The\nupdated set can be seen as a potential candidate for updating the\ncommon ground with. In contrast, the appositive directly updates the\ncommon ground. Rather than a proposed common ground update,\nit can be seen as an imposed update (see Nouwen 2007 for an\nalternative dynamic logic). The ideas of AnderBois et al. 2015 are\npartly inspired by similar ideas that were successfully applied in the\nrealm of evidentials; see in particular Murray 2014. \nCompositionality has always been an important concern in the use of\nlogical systems in natural language semantics (see the entry on\n compositionality).\n Through the use of higher order logics (see the entries on\n second-order and higher-order logics\n and\n Church’s type theory),\n a thoroughly compositional account of, e.g., the quantificational\nsystem of natural language can be achieved, as is demonstrated in\nclassical Montague grammar (Montague 1974a,b, 1973; compare the entry\non\n logical form).\n We will review how the dynamic approach can be extended to higher\norder systems. The link between dynamic semantics and type theory is\nmore like a liaison than a stable marriage: there is no intrinsic need\nfor the connection. The connection is treated here to explain the\nhistorical influence of Montague grammar on dynamic semantics. \nMost proposals for dynamic versions of Montague grammar develop what\nare in fact higher order versions of dynamic predicate logic (DPL).\nThis holds for Groenendijk and Stokhof 1990; Chierchia 1992, 1995;\nMuskens 1994, 1995, 1996; Eijck 1997; Eijck and Kamp 1997; Kohlhase et\nal. 1996; and Kuschert 2000. These systems all inherit a feature (or\nbug) from the DPL approach: they make re-assignment destructive. DRT\ndoes not suffer from this problem: the discourse representation\nconstruction algorithms of Kamp 1981 and Kamp and Reyle 1993 are\nstated in terms of functions with finite domains, and carefully talk\nabout “taking a fresh discourse referent” to extend the\ndomain of a verifying function, for each new noun phrase to be\nprocessed. \nIn extensional Montague grammar “a man” translates as:\n \nHere \\(P\\), of type \\(e \\rightarrow t\\), is the variable for the VP\nslot: it is assumed that VPs denote sets of entities.  \nIn Dynamic Montague Grammar (DMG) of Groenendijk and Stokhof 1990, the\ntranslation of an indefinite NP introduces an anaphoric index. The\ntranslation of “a man” is  \nInstead of the basic types e and t of classical extensional Montague\ngrammar, DMG has basic types \\(e, t\\) and \\(m (m\\) for marker). States\npick out entities for markers, so they can be viewed as objects of\ntype \\(m \\rightarrow e\\). Abbreviating \\(m \\rightarrow e\\) as \\(s\\)\n(for “state”), we call objects of type \\(s \\rightarrow s\n\\rightarrow t\\) state transitions. The variable \\(P\\) in the DMG\ntranslation of “a man” has type \\(m \\rightarrow s\n\\rightarrow s \\rightarrow t\\), so VP meanings have been lifted from\ntype \\(e \\rightarrow t\\) to this type. Note that \\(\\rightarrow\\)\nassociates to the right, so \\(m \\rightarrow s \\rightarrow s\n\\rightarrow t\\) is shorthand for \\(m \\rightarrow(s \\rightarrow(s\n\\rightarrow t))\\). Indeed, DMG can be viewed as the result of\nsystematic replacement of entities by markers and of truth values by\nstate transitions. A VP meaning for “is happy” is a\nfunction that maps a marker to a state transition. The state\ntransition for marker \\(u_i\\) will check whether the input state maps\n\\(u_i\\) to a happy entity, and whether the output context equals the\ninput context. The variables \\(a\\), a\\('\\) range over\nstates, and the expression \\((u_i \\mid x)a\\) denotes the result of\nresetting the value of \\(u_i\\) in \\(a\\) to \\(x\\), so the old\nvalue of \\(u_i\\) gets destroyed (destructive assignment). The\nanaphoric index \\(i\\) on reference marker \\(u_i\\) is introduced by\nthe translation. In fact, the translation starts from the indexed\nindefinite noun phrase “a man\\(_i\\)”. The connection\nbetween Montagovian compositionality and dynamic semantics as well as\nthe basic Montagovian and dynamic ingredients are much more\ntransparent and streamlined in the typed Logic of Change proposed in\nMuskens 1991, 1995, 1996. Because of this, Muskens’s\nCompositional DRT is probably the de facto standard and\nstarting point for current research in compositional dynamic\nsemantics. An alternative treatment is given in Incremental Typed\nLogic (ITL), an extension to typed logic of a “stack\nsemantics” that is based on variable free indexing and that\navoids the destructive assignment problem. The basic idea of the stack\nsemantics for DPL, developed in Vermeulen 1993, is to replace the\ndestructive assignment of ordinary DPL, which throws away old values\nwhen resetting, by a stack-valued one that allows old values to be\nreused. Stack-valued assignments assign to each variable a stack of\nvalues, the top of the stack being the current value. Existential\nquantification pushes a new value on the stack, but there is also the\npossibility of popping the stack to reuse a previously assigned value.\nEijck’s 2000 ITL is in fact a typed version of stack semantics,\nusing a single stack. \nAssuming a domain of entities, contexts are finite lists of entities.\nIf \\(c\\) is a context of length \\(n\\), then we refer to its\nelements as \\(c[0]\\), \\(\\ldots ,c[n-1]\\), and to its length as\n\\(\\lvert c\\rvert\\). We will refer to the type of contexts of length\n\\(i\\) as \\([e]^i\\). If \\(c\\) is a context in \\([e]^i\\), then\nobjects of type \\(\\{0, \\ldots ,i-1\\}\\) can serve as indices into\n\\(c\\). If \\(c \\in[e]^i\\) and \\(j \\in \\{0, \\ldots ,i-1\\}\\), then\n\\(c[j]\\) is the object of type e that occurs at position \\(j\\) in\nthe context. A key operation on contexts is extension with an element.\nIf \\(c :: [e]^i\\) and \\(x :: e\\) (\\(c\\) is a context of length\n\\(i\\) and \\(x\\) is an entity) then \\(c\\mcaret x\\) is the context\nof length \\(i+1\\) that has elements \\(c\\)[0], \\(\\ldots ,c[i-1],\nx\\). Thus \\(\\mcaret\\) is an operator of type \\([e]^i \\rightarrow e\n\\rightarrow[e]^{i+1}\\). Also note that types like \\([e]^i\\) are in\nfact polymorphic types, with \\(i\\) acting as a type variable. See\nMilner 1978. \nIn ITL there is no destructive assignment, and indefinite noun phrases\ndo not carry indexes in the syntax. The ITL translation of “a\nman” picks up an index from context, as follows:  \nHere \\(P\\) is a variable of type \\(\\{0, \\ldots ,i\\}\n\\rightarrow[e]^{i+1} \\rightarrow [e]^j \\rightarrow t\\), while \\(c\\)\nis a variable of type [\\(e]^i\\) representing the input context of\nlength \\(i\\), and \\(c'\\) is a variable of type [\\(e]^j\\)\nrepresenting the output context. Note that the type \\(\\{0, \\ldots ,i\\}\n\\rightarrow [e]^{i+1} \\rightarrow [e]^j \\rightarrow t\\) for \\(P\\)\nindicates that \\(P\\) first takes an index in the range \\(\\{0,\n\\ldots ,i\\}\\), next a context fitting this range (a context of length\n\\(i+1)\\), next a context of a yet unknown length, and then gives a\ntruth value. \\(P\\) is the type of unary predicates, lifted to the\nlevel of context changers, as follows. Instead of using a variable to\nrange over objects to form an expression of type \\(e\\), a lifted\npredicate uses a variable ranging over the size of an input context to\nform an expression that denotes a changer for that context.  \nThe ITL translation of “a man” has type \n\n\\[(\\{0, \\ldots ,i\\} \\rightarrow[e]^{i+1} \\rightarrow [e]^j \\rightarrow t) \\rightarrow [e]^i \\rightarrow [e]^j \\rightarrow t.\\] \n\n In\n\\(P\\lvert c\\rvert (c\\mcaret x)c'\\), the \\(P\\) variable marks the\nslot for the VP interpretation; \\(\\lvert c\\rvert\\) gives the length of\nthe input context to \\(P\\); it picks up the value \\(i\\), which\nis the position of the next available slot when the context is\nextended. This slot is filled by an object \\(x\\) denoting a man.\nNote that \\(c\\mcaret x[\\lvert c\\rvert ] = c\\mcaret x[i] = x\\), so the\nindex \\(i\\) serves to pick out that man from the context. \nTo see that a dynamic higher order system is expressible in ITL, it is\nenough to show how to define the appropriate dynamic operations.\nAssume \\(\\phi\\) and \\(\\psi\\) have the type of context transitions,\ni.e. type [\\(e] \\rightarrow[e] \\rightarrow t\\) (using [\\(e\\)] for\narbitrary contexts), and that \\(c, c', c''\\) have type [\\(e\\)].\nThen we can define the dynamic existential quantifier, dynamic\nnegation and dynamic composition as follows:  \nDynamic implication \\(\\Rightarrow\\) is defined in the usual way by\nmeans of \\({\\sim}(\\phi; {\\sim}\\psi)\\). \nITL and Muskens style Compositional DRT are not incompatible; see\nBittner 2014 for example. We will end this section by noting that the\nrange of systems integrating Montagovian compositionality and dynamic\nsemantics is far from being completely charted. A recent series of\ncontributions integrating continuation-based and dynamic semantics is\nexploring new ways of integrating and generalizing them; see de Groote\n2006, Bumford and Barker 2013, Charlow 2014, Bumford 2015, and Martin\n2016. \nHopefully, the above has given the reader a sense of Dynamic Semantics\nas a fruitful and flexible approach to meaning and information\nprocessing. Dynamic semantics comes with a set of flexible tools, and\nwith a collection of “killer applications”, such as the\ncompositional treatment of donkey sentences, the account of anaphoric\nlinking, the account of presupposition projection, the account of\nepistemic updating and fine-grained distinctions between different\nkinds of (non-at-issue) updates. Dynamic semantics is a very lively\nsubfield of formal semantics and the cross-linguistic range of\nphenomena for which dynamic approaches are being pursued is expanding\nat an increasing pace.","contact.mail":"abrsvn@gmail.com","contact.domain":"gmail.com"},{"date.published":"2010-08-23","date.changed":"2016-07-12","url":"https://plato.stanford.edu/entries/dynamic-semantics/","author1":"Rick Nouwen","author2":"Adrian Brasoveanu","author1.info":"http://ricknouwen.org","author2.info":"http://www.cwi.nl/~jve","entry":"dynamic-semantics","body.text":"\n\n\nDynamic semantics is a perspective on natural language semantics that\nemphasizes the growth of information in time. It is an approach to\nmeaning representation where pieces of text or discourse are viewed as\ninstructions to update an existing context with new information, the\nresult of which is an updated context. In a slogan: meaning is context\nchange potential. \n\n\nIt is important to be aware of the abstractness of this perspective so\nas to guard against various non sequiturs. For one thing, one could\neasily think that dynamic semantics or update semantics is committed\nat least in part to an internalist idea of semantics since the\ninformation states are “internal”—in the sense that\nthey are wholly contained in the individual mind/brain. In other\nwords, one might think that the information states of dynamic\nsemantics are what Putnam (1975) calls “states in the sense of\nmethodological solipsism”. See the entries on\n scientific realism,\n computational theory of mind,\n externalism about mental content,\n and\n narrow mental content.\n However, the general framework says nothing about what the states\nare. The state could very well include the environment in which the\ninterpreter is embedded and thus contain an “external”\ncomponent.\n\n\nA second possible misunderstanding is that dynamic semantics or update\nsemantics is in complete opposition to classical truth conditional\nsemantics (compare the entries on\n classical logic\n and\n first-order model theory).\n In fact, as this entry will soon make clear, what dynamic semantics\nprovides is a generalization of truth conditional semantics rather\nthan a radically different alternative. The classical meanings become\nthe preconditions for success of the discourse actions.\nDynamic semanticists claim that compositional meanings have\nthe nature of functions or relations and the classical meanings are\nrecoverable from the relational dynamic meanings as\nprojections onto their “input” coordinate.\n\n\nThe point of the use of an abstract framework is not to give empirical\npredictions. This is the task of specific realizations inside the\nframework. The framework of dynamic semantics (i) provides a direction\nof thinking and (ii) allows us to import methods from the mathematical\nstudy of the framework. It follows that the question whether natural\nlanguage meaning is intrinsically dynamic does not have an empirical\nanswer. Still, what can be said is that the study of interpretation as\na linearly-ordered process has proven quite fruitful and\nrewarding.\n\n\nSince dynamic semantics focuses on the discourse actions of sender and\nreceiver, it is in a sense close to use-oriented approaches to meaning\nin philosophy such as the work of Wittgenstein and Dummett. However,\neasy identifications between dynamic semantics and these approaches\nare to be avoided. Dynamic semantics as an abstract framework is\ncompatible with many philosophical ways of viewing meaning and\ninterpretation. Dynamic semantics aims to model meaning and\ninterpretation. You can do that without answering broader\nphilosophical questions such as the question of what it is that makes\nit possible for the subject to be related to these meanings at all.\nFor example, in dynamic predicate logic we take the meaning of\nhorse as given without making any substantial claim about\nwhat it means for a subject to have the concept of horse; we\njust stipulate the subject has it. This is not to say such\nquestions—which are at the center of the work of Wittgenstein\nand Dummett—should not ultimately be answered: it’s just\nthat a model can be of interest even if it does not answer them. (Note\nthat dynamic semantics tries to give a systematic and compositional\naccount of meaning, which makes it markedly different in spirit from\nWittgenstein’s later philosophy.)\n\n\nOne approach to dynamic semantics is\n discourse representation theory\n (DRT, Kamp 1981). (Closely related to Kamp’s approach is Irene\nHeim’s file change semantics (FCS, Heim 1983a) and the\ndiscourse semantics of Seuren 1985). Meanings in DRT are so-called\ndiscourse representation structures (DRSs). These structures\nare a type of database that contains specific pieces of information.\nIn and of itself a DRS is a static object, but DRT can be said to be a\ndynamic semantic framework because it allows us to understand the\nprocess of composing meanings as a process of merging\ndiscourse representation structures. In this way, information change\nbecomes an integral part of the interpretation process.\n\n\nOur main focus in this entry is a second approach to dynamic\nsemantics, although we will compare things to DRT along the way. In\nthis second approach, dynamic meanings are types of actions, things\nthat are individuated by the changes they effect. This is the approach\nassociated with dynamic predicate logic (DPL, Groenendijk and\nStokhof 1991a). According to this dynamic semantic tradition, a\nmeaning is a specification of how a receiver’s information state\nwould be modified. It could for instance be a function that maps an\nold information state to one which has been updated with the\ninformation that the meaning embodies. Alternatively, it could be a\nrelation that expresses the kind of information change that the\nmeaning brings about. (For early work in this tradition, see\nGroenendijk and Stokhof 1991a,b; Muskens 1991; Dekker 1993; Vermeulen\n1993; van Eijck 1994; Vermeulen 1994; Krahmer 1995; van den Berg 1996;\nGroenendijk et al. 1996; Aloni 1997; Muskens et al. 1997).\n\nInterpretation of declarative sentences can be viewed as a product or\nas a process. In the product perspective, one focuses on the notion of\ntruth in a given situation. In the process perspective, interpretation\nof a proposition is viewed as an information updating step that allows\nus to replace a given state of knowledge by a new, more accurate\nknowledge state. Dynamic semantics focuses on interpretation as a\nprocess. \nUpdate semantics is a particular way in which the\ninterpretation-as-process idea can be implemented. The central idea\nbehind update semantics is very simple. We start with a simple model\nof a hearer/receiver who receives items of information sequentially.\nAt every moment the hearer is in a certain state: she possesses\ncertain information. This state is modified by the incoming\ninformation in a systematic way. We now analyze the meaning of the\nincoming items as their contribution to the change of the information\nstate of the receiver. Thus, meanings are seen as actions, or, more\nprecisely, as action types: They are not the concrete changes\nof some given state into another, but what such concrete changes have\nin common. \nPropositional logic (the logic of negation, disjunction and\nconjunction) can be viewed as an update logic as follows. Consider the\ncase where we have three basic propositions \\(p, q\\) and \\(r\\), and\nwe know nothing about their truth. Then there are eight possibilities:\n\\(\\{ \\bar{p} \\bar{q} \\bar{r}, p \\bar{q} \\bar{r}, \\bar{p} q \\bar{r},\n\\bar{p} \\bar{q} r, pq \\bar{r}, p \\bar{q} r, \\bar{p} qr, pqr \\}\\) Here\n\\(\\bar{p} \\bar{q} \\bar{r}\\) should be read as: none of \\(p, q, r\\) is\ntrue, \\(p \\bar{q} \\bar{r}\\) as: \\(p\\) is true but \\(q\\) and\n\\(r\\) are false, and so on. If now \\(\\neg p\\) (“not\n\\(p\\)”) is announced, four of these disappear, and we are\nleft with \\(\\{\\bar{p} \\bar{q} \\bar{r}, \\bar{p} q \\bar{r}, \\bar{p}\n\\bar{q} r, \\bar{p} qr\\}\\). If next \\(q \\vee \\neg r\\) (“\\(q\\)\nor not \\(r\\)”) is announced, the possibility \\(\\bar{p}\n\\bar{q} r\\) gets ruled out, and we are left with \\(\\{ \\bar{p} \\bar{q}\n\\bar{r}, \\bar{p} q \\bar{r}, \\bar{p} qr \\}\\). And so on. We can view\nthe meaning of propositions like \\(\\neg p\\) and \\(q \\vee \\neg r\\) as\nmappings from sets of possibilities to subsets thereof. \nSets of possibilities represent states of knowledge. In the example,\n\\(\\{ \\bar{p} \\bar{q} \\bar{r}, p \\bar{q} \\bar{r}, \\bar{p} q \\bar{r},\n\\bar{p} \\bar{q} r, pq \\bar{r}, p \\bar{q} r, \\bar{p} qr, pqr \\}\\)\nrepresents the state of complete ignorance about propositions \\(p, q,\nr\\). Singleton sets like \\(\\{ pq \\bar{r} \\}\\) represent states of\nfull knowledge about these propositions, and the empty set\n\\(\\varnothing\\) represents the inconsistent state that results from\nprocessing incompatible statements about \\(p, q\\) and \\(r\\). Here\nwe spell out the dynamic meanings of the statements of our\npropositional language:  \nThis gives the meanings of the propositional connectives as operations\nfrom an old context representing a state of knowledge to a new context\nrepresenting the state of knowledge that results from processing the\npropositional information. \nIt is instructive to compare the actions of update semantics to\nprogramming statements and their execution. Such a comparison provides\na first glimpse into how quantification works within a dynamic\nsetting. Programming statements of imperative languages are\ninterpreted (or “executed”) in the context of a machine\nstate, where machine states can be viewed as allocations of values to\nregisters. Assume the registers are named by variables \\(x, y, z\\),\nand that the contents of the registers are natural numbers. Then the\nfollowing is a machine state: \nIf the statement \\(z := x\\) is executed, i.e.,\n“interpreted”, in this state (in C syntax, this statement\nwould have the simpler form \\(z = x)\\), the result is a new machine\nstate: \nIf the sequence of statements \\(x := y\\); \\(y := z\\) is executed in\nthis state, the result is: \nThis illustrates that the result of the sequence \\(z := x\\); \\(x :=\ny\\); \\(y := z\\) is that the values of \\(x\\) and \\(y\\) are\nswapped, with the side effect that the old value of \\(z\\) gets\nlost. In other words, the meaning of the program \\(z := x\\); \\(x :=\ny\\); \\(y := z\\) can be viewed as a mapping from an input machine state\n\\(s\\) to an output machine state \\(s'\\) that differs from \\(s\\)\nin several respects: \\(s'(x) = s(y)\\) and \\(s'(y) = s(x)\\) (that is,\nthe input values of \\(x\\) and \\(y\\) are swapped in the\noutput state), and \\(s'(z) = s'(y)\\). \nNow consider the existential quantifier “there exists an\n\\(x\\) such that \\(A\\)”. Suppose we add this quantifier to\nan imperative programming language. What would be its meaning? It\nwould be an instruction to replace the old value of \\(x\\) by a new\nvalue, where the new value has property \\(A\\). We can decompose\nthis into a part “there exists \\(x\\)” and a test\n“\\(A\\)”. A formula/instruction is a test if\nthe update contributed by it takes the states in the input context one\nat a time and tests that they satisfy a particular condition. If they\ndo, they are included in the output context; if they don’t, they\nare discarded. That is, a test is an update that takes an input\ncontext and outputs a context that is a subset of the input context.\nAll the formulas of propositional logic in the\n Propositional logic as an update logic\n section above are tests. \nThe two parts “there exists \\(x\\)” and the test\n“\\(A\\)” are glued together by sequential composition:\n“\\(\\exists x\\); \\(A\\)”. Focusing on the part\n“\\(\\exists x\\)”, what would be its natural meaning? An\ninstruction to replace the old value of \\(x\\) by some arbitrary new\nvalue. This is again a relation between input states and output\nstates, but the difference with definite assignments like \\(x := y\\)\nis that now the relation is not a function. In fact, this relational\nmeaning of quantifiers shows up in the well known Tarski-style truth\ndefinition for first order logic (compare the entry on\n Tarski’s truth definitions): \n\\(\\exists x\\phi\\) is true in a model \\(M\\) relative to a variable\nassignment \\(\\alpha\\) iff (if and only if) there is some variable\nassignment \\(\\beta\\) such that \\(\\beta\\) differs from \\(\\alpha\\) at\nmost with respect to the value it assigns to \\(x\\) and such that\n\\(\\phi\\) is true in \\(M\\) relative to assignment \\(\\beta\\).  \nImplicit in the Tarskian definition is a relation that holds between\nassignment \\(\\alpha\\) and assignment \\(\\beta\\) iff for all variables\n\\(y\\) that are different from \\(x\\), it is the case that\n\\(\\alpha(y) = \\beta(y)\\). This relation is often called a random\nreset of x and is written as [\\(x\\)]. For any variable\n\\(x\\), the binary relation between total assignments [\\(x\\)] is\nan equivalence relation between assignments, i.e., it is a reflexive,\nsymmetric and transitive binary relation. Below, we see how such\nrelations are put to work in a dynamicised version of first order\npredicate logic.  \nAdopting [\\(x\\)] as the meaning of “\\(\\exists x\\)”,\nnote that its meaning is quite different in nature from that of a test\nin that it creates new values in the output context. In contrast, the\noutput context resulting from an update with a test is always a subset\nof the input context and can therefore never contain anything new\nrelative to the input context. \nInformation states are often called contexts, since the state\nis a precondition for the “interpretation”, i.e., semantic\nevaluation, of expressions in a formal or natural language. The use of\nthe word “context” also makes it clear that we are not\ninterested in the total state of the receiver but only in aspects of\nit relevant to the interpretation of the expressions/informational\nitems we are focusing on. Thus, meanings are often called context\nchange potentials in the dynamic tradition. \nAlthough it is broadly speaking true that the changes brought about by\nmeanings in dynamic semantics concern aspects of context, it\nis important to note that semanticists may mean various things when\nthey talk about context (compare the entries on\n epistemic contextualism\n and\n indexicals),\n and these different views engender varieties of dynamic semantics\nthat deal with a variety of issues. Some of these issues are:\nconstructing an appropriate mechanism for pronominal reference\n(compare the entries on\n anaphora\n and\n reference),\n explaining the semantics of conditionals (compare the entries on\n conditionals\n and\n the logic of conditionals),\n giving a semantic treatment of the distinction between assertion and\npresupposition (compare the entries on\n assertion,\n speech acts,\n implicature,\n pragmatics) and developing a theory of “presupposition\nprojection”, explaining how the interpretation of discourse is\ninfluenced and guided by the common ground that exists between speaker\nand hearer, and developing a theory of how this common ground develops\nas the discourse proceeds (compare the entries on\n pragmatics\n and\n implicature). \nContext plays a role in two separate distinctions. The first\ndistinction is between context and that which modifies the context.\nHere the context is the information state or a suitable abstraction\nthereof (compare the entry on\n semantic conceptions of information).\n The context modifier is (the meaning of) the received informational\nitem. The information cannot be received without the correct kind of\npresupposed information state. The proper analogues in classical\nstatic predicate logic (compare the entries on\n classical logic\n and\n first-order model theory)\n are as follows: the information state is an assignment (environment)\nor a set of assignments, and the received information is a set of\nassignments. The second distinction is between context and content.\nHere the context is something like the storage capacity of the\nreceiver and various other features that could influence how new\nexpressions/informational items are interpreted. The content is the\n(factual, truth conditional) information that is stored. Thus, e.g.,\nthe context in this sense could be a set of registers/variables or in\nDRT/FCS terms, discourse referents or files. The content would then be\nsome set of assignments or, perhaps, world/assignment pairs\nconstraining the values of these discourse referents and the set of\nworlds that are live candidates for the actual world. \nHere is an example to illustrate the distinctions. Suppose we view an\ninformation state as a pair of a finite set of discourse referents and\na set of world/assignment pairs, where the assignments have as domain\nthe given finite set of discourse referents. Such a state would be a\ncontext-in-the-first-sense and the set of discourse referents would be\na context-in-the-second-sense. One basic kind of update would be\nupdate of content: here we constrain the set of world/assignment\npairs, and leave the set of referents constant. A second basic kind of\nupdate would be extension of the set of referents: we extend our\nallocated storage capacity. We modify the given world/assignments\npairs to pairs of worlds and extended assignments, where our extended\nassignments are constrained by the old ones, but take all possible\nvalues on the new referents. Thus, the update process in our example\nis two-dimensional: we have both update of content and update of\ncontext-in-the-second-sense. \nThe motivation for a dynamic semantic framework for natural language\ncomes first and foremost from potential dependencies between the\nreference of a personal pronoun and that of an indefinite noun phrase.\nThe simplest example of such a dependency is that of coreferential\ndiscourse anaphora, as in: \nThe observation is that this sequence of sentences has the same\nmeaning as the single sentence: \nIf we assume that indefinites are existential quantifiers, then the\nanalysis of\n (2)\n is easy. It simply says that there exists an \\(x\\) that is a\nstudent, that met Mary yesterday and that needed her help then. In\npredicate logic: \nHowever, a similar analysis is unavailable for the equivalent\ntwo-sentence example in\n (1).\n This is because interpretation is compositional (see the\nentry on\n compositionality\n for discussion) and in our compositional analysis, we will first come\nto an analysis of Mary met a student yesterday, which will\nhave the form \\(\\exists\nx(\\texttt{student}(x)\\wedge\\texttt{met}(m,x))\\). Likewise, the second\nsentence will correspond to \\(\\texttt{need-help}(x)\\). Assuming that\nthe default mode of combining multiple sentences is to conjoin them,\nwe now arrive at: \nThe final occurrence of \\(x\\) is not bound and so in classical\npredicate logic, we have not arrived at an equivalent translation for\n (1)\n and\n (2).\n The upshot is that if we want to account for the equivalence between\n (1)\n and\n (2)\n within a static semantic framework, we will not be able to maintain a\ncompositional interpretation for individual sentences. We will have to\nassume that the discourse in\n (1)\n is interpreted as a whole. \nThis is counter-intuitive. We know what the individual sentences in\n (1)\n mean and we would like to capture the potential these meanings have\nin combining with other meanings to form a meaningful whole, one which\ncorresponds to a sequence of sentences. Dynamic semantics allows us to\ndeliver a fully compositional analysis of meaning at the sentential\nand supra-sentential level. It does so by guaranteeing that in\ncontrast to classical predicate logic,\n (3)\n and\n (4)\n are equivalent in a dynamic interpretation of\nclassical predicate logic syntax. In particular, the following is\nvalid in dynamic predicate logic: \nIn this kind of dynamic semantics for natural language, the meaning of\na sentence does not correspond to a set of truth-conditions, but\nrather to an action performed on a context. There are two kinds of\nactions. Predications like \\(\\texttt{need-help}(x)\\) or\n\\(\\texttt{met}(m,x)\\) are tests. They merely check if every\nstate/assignment in the current context assigns a value to \\(x\\)\nthat satisfies the relevant predicate; if (and only if) this is the\ncase, the test passes the unaltered assignment on to the output\ncontext. In contrast, the existential quantifier is not a test. It has\nthe potential to alter the context by randomly resetting the value of\nits associated variable. So, \\(\\exists x(\\psi)\\) takes a context,\nrandomly changes the value of \\(x\\) in each assignment in the\ncontext and passes these changed assignments on to the output context\nif they also satisfy the condition contributed by the test\n\\(\\psi\\). \nOne of the main consequences of this semantics is that the scope of\nthe existential quantifier is in principle limitless. It changes the\nvalue of some variable and until a further change to that variable\noccurs, any subsequent test accesses the particular value that was\nset. This also means that the semantics of existential quantification\ncan be given without reference to any scope: the meaning of \\(\\exists\nx\\) is the action that takes a context and returns the same context\nwith at most the value of \\(x\\) randomly replaced by another value.\n(We will work this out in detail below.) \nRight now, two senses of the term dynamic semantics (as applied to\nnatural language) emerge. First and foremost, dynamic semantics is the\ngeneral idea that logical statements do not express truth-conditions\nbut rather actions on contexts (where contexts can be conceptualized\nin various ways). A second understanding of the term dynamic semantics\nis a set of theoretical positions taken within debates concerning the\nsemantics of certain natural language phenomena, most notably\npronominal anaphora. (See below for a similar take on dynamic\nsemantics with respect to presupposition). For the case of\nanaphora, this theoretical understanding embodies the combination of\ntwo hypotheses: (i) pronouns correspond to variables; (ii) indefinites\nare non-quantificational, they simply contribute a dynamic variable\nassignment update. As is clear from the second hypothesis, this\ntheoretical use of the term dynamic semantics presupposes the more\ngeneral view that meanings are actions on contexts.  \nBefore we turn to defining dynamic predicate logic, we should note\nthat the route dynamic semantics takes to account for anaphora is by\nno means the only one to be found in the literature. We could also\nchoose to give up the idea that pronouns are correspond to variables\nand instead assign them a more intricate meaning, one akin to that of\ndefinite descriptions. In the contemporary tradition, such ideas\nemerge as early as Quine 1960 and Geach 1962, before being brought to\nmaturity by (especially) Evans (1977, 1980), Parsons (1978, Other\nInternet Resources), Heim (1990), and Elbourne (2001, 2005). See\nNouwen (forthcoming) for discussion. \nThe previous subsection gave a first glimpse into the basic aim of a\ndynamic semantic framework, which is to define a logical semantics in\nwhich statements express actions and specifically, in which\nexistential quantification has the potential to reset variables, thus\nchanging the context. We get our clue about how to do this by\nexamining the definition of existential quantification in ordinary\npredicate logic. Suppose we work with total assignments on a fixed set\nof variables \\(\\textsf{VAR}\\) over a fixed domain \\(D\\). The set of\ntotal assignments \\(\\textsf{ASSIGN}\\) is therefore the set of all\n(total) functions from \\(\\textsf{VAR}\\) to \\(D\\). \nLet the meaning of atomic formulas like \\(P(x)\\) be the set \\(F\\)\nof all assignments \\(\\alpha\\) such that \\(\\alpha(x)\\) is an object\nsatisfying \\(P\\). \nNow define: \n\n\\[\n\\alpha[x]\\beta := \\forall v \\in \\textsf{VAR}\\setminus\\{x\\}\\ (\\alpha(v) = \\beta(v)).\n\\]\n\n So [\\(x\\)] is the binary relation\n“assignment \\(\\beta\\) is a result of (at most) resetting the\nvalue of the variable \\(x\\) in assignment \\(\\alpha\\)”. As\nalready mentioned, this is an equivalence relation over variable\nassignments. Now the meaning \\(G\\) of \\(\\exists x P(x)\\), will be:\n\n\\[\nG := \\{\\alpha \\in \\textsf{ASSIGN } \\mid \\exists \\beta \\in F \\alpha[x]\\beta \\}.\n\\]\n\n Thus, \\(G\\) is the set of assignments that can be\nsuccessfully reset with respect to \\(x\\) and obtain an assignment\nin \\(F\\) as a result of this resetting. Viewed differently,\n\\(G\\) is the domain of the relation \\(R\\) given by\n\n\\[\\alpha R\\beta := \\alpha[x]\\beta \\textrm{ and } \\beta \\in F.\n\\]\n\n  \nWe could say that \\(G\\) is the precondition for the resetting\naction \\(R\\). Now the idea of \\(\\textsf{DPL}\\) is to take the\nmeaning of \\(\\exists x P(x)\\) to be not the precondition \\(G\\) (as\nin classical static first order logic) but the resetting action\n\\(R\\). In this way we do not lose information since \\(G\\) can\nalways be obtained from \\(R\\). Moreover, the range of the relation\n\\(R\\) consists of assignments \\(\\beta\\) that differ from\nassignments in the precondition \\(G\\) at most with respect to the\nvalue of \\(x\\) and that are also in \\(F\\) (i.e., \\(\\beta(x)\\) is\nin the interpretation of \\(P)\\). The \\(x\\) values stored in the\nrange of the binary relation \\(R\\) are precisely the \\(x\\)\nvalues that satisfy \\(P\\), i.e., the values we were looking\nfor. \nMore generally, we take as \\(\\textsf{DPL}\\)-meanings binary\nrelations between assignments. Such relations can be seen as\n(modeling) resetting actions. This is an instance of an\nadmittedly simplistic but well-known and useful way of modeling\nactions: an action is viewed as a relation between the states of the\nworld before the action and the corresponding states after the\naction. \nHere is the full definition. Assume a non-empty domain \\(D\\), a set\nof variables \\(\\textsf{VAR}\\) and a model \\(\\mathcal{M}=\\langle D,\nI\\rangle\\) of signature \\(\\Sigma\\). Atomic conditions \\(\\pi\\) are of\nthe form \\(P(x_0 , \\ldots ,x_{n-1})\\), where \\(P\\in \\Sigma\\) is of\narity \\(n\\). Atomic resets \\(\\varepsilon\\) are of the form\n\\(\\exists v\\), where \\(v\\) is a variable. The language of predicate\nlogic for \\(\\Sigma\\) is given below (\\(\\cdot\\) is conjunction and\n\\({\\sim}\\) is negation):  \nAssignments are elements \\(\\alpha , \\beta ,\\ldots\\), of\n\\(\\textsf{ASSIGN} := D^{\\textsf{VAR}}\\). We define the\ndynamic/relational semantics for this language as follows:  \nNote that conjunction \\(\\cdot\\) is interpreted as relation\ncomposition, and negation \\({\\sim}\\) is basically interpreted as\ncomplementation with respect to the domain of the relation denoted by\nthe negated formula. \nTruth is defined in terms of relational meanings; we basically project\nthe binary relations between assignments onto their first\ncoordinate: \nWe can define implication \\(\\phi \\rightarrow \\psi\\) as \\({\\sim}(\\phi\n\\cdot {\\sim}\\psi)\\). Applying the truth definition to this gives: \n\\(\\alpha \\vDash \\phi \\rightarrow \\psi \\textrm{ iff } \\forall\n\\beta(\\alpha[\\phi]\\beta \\Rightarrow \\beta \\vDash \\psi)\\), i.e., any\nassignment \\(\\beta\\) that results from updating \\(\\alpha\\) with the\nantecedent \\(\\phi\\) satisfies the consequent \\(\\psi\\).  \nRelational meanings also yield the following beautiful definition of\ndynamic entailment: \nThis definition was first introduced by Hans Kamp in his pioneering\npaper Kamp 1981. Informally, it says that any assignment \\(\\beta\\)\nthat has incorporated the update contributed by \\(\\phi\\) is guaranteed\nto support/satisfy \\(\\psi\\). \nNote that \\({\\sim}\\phi\\) is equivalent to \\((\\phi \\rightarrow \\bot)\\),\nand that \\((\\phi \\rightarrow \\psi)\\) is true iff \\(\\phi \\vDash \\psi\\).\nEqually importantly, we can define \\(\\forall x (\\phi)\\) as \\((\\exists\nx \\rightarrow \\phi)\\). \nA possible alternative notation for \\(\\exists v\\) would be [\\(v := ?\\)] \n(random reset). This emphasizes the connection with random\nassignment in programming languages. \nThe interpretations of predicate symbols are conditions. They\nare subsets of the diagonal \\(\\{\\langle \\alpha , \\alpha \\rangle \\mid\n\\alpha \\in \\textsf{ASSIGN}\\}\\) (which is the meaning of \\(\\top)\\).\nSubsets of the diagonal are tests: they modify nothing and simply pass\non what is OK (satisfies the condition) and throw away what is not.\nThe mapping \\(\\textsf{diag}\\) that sends a set \\(F\\) of assignments\nto a condition \\(\\{\\langle \\alpha , \\alpha \\rangle \\mid \\alpha \\in\nF\\}\\) is the link between the classical static and the dynamic world.\nFor example, the relational composition of \\(\\textsf{diag}(F)\\) and\n\\(\\textsf{diag}(G)\\) is \\(\\textsf{diag}(F\\cap G)\\). \nClassical first-order logic (FOL) can be interpreted in\n\\(\\textsf{DPL}\\) as follows. We assume that the FOL language has the\nfollowing connectives and quantifiers: \\(\\top , \\bot , \\wedge ,\n\\rightarrow , \\exists x\\). We translate as follows: \nWe get that \\([\\phi^*]\\) is the diagonal of the classical\ninterpretation of \\(\\phi\\). Our translation is compositional. It shows\nthat FOL can be taken as a fragment of \\(\\textsf{DPL}\\). \nIt is, conversely, possible to translate any \\(\\textsf{DPL}\\)-formula\n\\(\\phi\\) to a predicate logical formula \\(\\phi\\)°, such that the\ndomain of \\([\\phi]\\) is the classical interpretation of \\(\\phi\\)°.\nOne of the ways to define this translation is by means of a\nprecondition calculus, with Floyd-Hoare rules (Eijck and de Vries\n1992). The following is a variation on this. Take the language of\nstandard predicate logic, with diamond modalities \\(\\langle \\psi\n\\rangle \\phi\\) added, where \\(\\psi\\) ranges over DPL formulas and\n\\(\\alpha \\vDash \\langle \\psi \\rangle \\phi\\) iff there is an assignment\n\\(\\beta\\) with \\(\\alpha[\\psi]\\beta\\), and \\(\\beta \\vDash \\phi\\). Then\nthe following equivalences show that this extension does not increase\nexpressive power. \nAn example of the merits of dynamic predicate logic is that it allows\nfor a straightforward compositional analysis of donkey sentences\n(Geach 1962; see the entry on anaphora). \nThere is obviously a dependency between the pronouns \\(he\\) and \\(it\\)\nand the indefinites a farmer and a donkey,\nrespectively. In a nutshell, the problem for\n (5)\n in a classical analysis is that such an analysis gives us two\nchoices, which taken together do not cover the possible meanings of\n (5).\n If we treat the indefinites as referring to a particular farmer and a\nparticular donkey and the pronouns as simply picking up that same\nentities, then we get a possible yet not very salient reading for\n (5).\n The most prominent reading describes a co-variation between the\nowning relation and the beating relation: any farmer-donkey pair that\nstands in the own relation also stands in the beat\nrelation. Clearly, we will need to interpret the indefinites as\nquantifiers. Yet if we do so, they won’t be able to bind the\nvariables in the consequent of the conditional since a compositional\nanalysis will place the variables contributed by the pronouns outside\nthe classical scope of the existential quantifiers in the antecedent\nof the conditional. That is,\n (6)\n does not yield the correct truth-conditions for\n (5). \nThe dynamic version of\n (6)\n is\n (7),\n which yields the correct truth conditions: any random reset of\n\\(x\\) and \\(y\\) such that \\(x\\) is a farmer and \\(y\\) is a\ndonkey owned by \\(x\\) is also such that \\(x\\) beats\n\\(y\\). \nInterestingly, the translation ( )° of\n (7)\n into predicate logic is not\n (6)\n but\n (8).\n So the problem is not that predicate logic cannot express the\ntruth-conditions of donkey conditionals but that sentences like\n (8)\n are unlikely to be the end product of a compositional interpretation\nprocess (but see Barker and Shan 2008).  \nThis is how\n (8)\n is derived from\n (6): \nThe successful application of dynamic predicate logic to the\ninteraction of quantification and anaphora in natural languages hinges\non the fact that in DPL, existential quantification is dynamic whereas\nuniversal quantification is not. What would happen if universal\nquantification were dynamic too? Note first of all, that it makes no\nsense to define a universal quantification action \\(\\forall x\\) in\nparallel to the random reset action \\(\\exists x\\). This is because\nuniversal quantification only makes sense on a given domain (the\nrestrictor) and with respect to some given property (the\nscope). Second, if we give \\(\\forall x(\\phi)(\\psi)\\) a\ndynamic interpretation, it predicts that universal quantifiers can\nstand in anaphoric relations to singular pronouns across clausal\nboundaries, just as existential quantifiers can. For cases like\n (9),\n this is clearly undesirable. \nHowever, as soon as one looks at plural anaphora it becomes\napparent that the static nature of universal quantification (and, in\nfact, that of other non-indefinite generalized quantifiers) should not\nbe taken for granted. For example,\n (10)\n allows a reading in which they is anaphorically linked to\nevery boy. \nOn the assumption that examples like\n (10)\n should receive a dynamic treatment (see the earlier remark on\nalternative explanations and Nouwen, forthcoming, for discussion), the\nconclusion can only be that universal quantifiers should not be given\na static interpretation. The next question is then what kind of\ninterpretation is appropriate, and how this interpretation can\ndistinguish the infelicitous case of anaphora in\n (9)\n from the case in\n (10).\n One option would be to distinguish between the values assigned to the\nvariables that are bound by the quantifier in its scope and the value\nassigned to that variable outside the scope of the quantifier. (See,\nfor instance, Kamp and Reyle 1993 for such a strategy and Nouwen 2007\nfor discussion.) In order to account for\n (10),\n one would have the variable occurrences bound by the quantifier in\nthe first sentence of\n (10)\n range over individual boys, while that variable gets assigned the\nplurality of all boys outside the quantifier’s scope (i.e. in\nthe second sentence). As van den Berg (1996) was the first to show,\nhowever, such a solution only gets there half-way. In discourse,\npronouns do not just have access to pluralities associated to\nquantifiers, but also to the relations such quantifiers are engaged\nin. For instance, in the second sentence of\n (11)\n the pronoun \\(it\\) covaries with the quantification over the boys in\nthe subject in such a way that the second sentence is understood to\nmean that each boy submitted the paper that \\(he\\) wrote (cf. van den\nBerg 1996; Krifka 1996; Nouwen 2003; Brasoveanu 2007, 2008). \nThe leading idea in dynamic treatments of generalized quantification\nand plural anaphora is to represent plural values not by assigning\npluralities to variables, but rather to adopt a notion of context that\nallows for pluralities (e.g., sets) of assignment functions. Say that\nthe first sentence in\n (11)\n is translated into dynamic predicate logic with dynamic quantifiers\nas follows: \\(\\forall x(\\textrm{boy}(x))(\\exists y\\cdot\n\\textrm{essay}(y)\\cdot \\textrm{wrote}(x,y))\\). The interpretation of\nsuch formulas requires collecting assignment functions in which the\nvalue of \\(x\\) is a boy and the value of \\(y\\) is an essay\nwritten by this boy. The universal quantifier requires such\ncollections to include all possible values for the predicate\nboy. In the subsequent discourse, we now have access to the\nset of all \\(x\\) values, i.e., the set of all boys, the set of all\n\\(y\\) values, i.e., the set of essays written by the boys, as well\nas the individual boy-essay pairs: each atomic assignment \\(f\\) in\nthe set of contextual assignments following the first sentence of\n (11)\n is such that \\(f(y)\\) is an essay written by boy \\(f(x)\\). All that\nis now needed to account for the case of anaphora in\n (11) is the assumption that the universal\n quantification there involves universal quantification over\n assignment functions, rather than just quantification over\n values. See van den Berg (1996), Nouwen (2007,\n forthcoming), Brasoveanu (2007, 2008, 2013) for various ways of\n implementing this idea. \nThe upshot is that given a suitably structured notion of context,\nquantifiers can be given dynamic interpretations generally. An\nimportant consequence is that this kind of analysis extends to\nnon-nominal quantifiers (Brasoveanu 2007). Cases like\n (11)\n could be described as cases of quantificational subordination, and\nthe structured context approach can be seen as designed to offer a\nwindow into the mechanism behind subordination. Cases of modal\nsubordination (Roberts 1987, 1989), like the famous\n (12),\n can receive a parallel treatment. \nThe modal might introduces a quantifier over possible worlds\nthat takes scope over the indefinite a wolf, in the same way\nthat every boy takes scope over an essay in\n (11)\n above. The set of assignment functions that is the output of the\nupdate contributed by the first sentence in\n (12)\n will therefore store a set of possible worlds contributed by\nmight that are epistemically possible relative to the actual\nworld, and a set of wolves that come in in these epistemically\naccessible worlds. The second sentence in\n (12)\n can then further elaborate on the dependency between worlds and\nwolves requiring at least some of the epistemic possibilities to be\nsuch that the corresponding wolf not only comes in but also eats\nyou. \nAlthough anaphora and presuppositions (see below) are the central\nlinguistic phenomena that may be thought to require a dynamic semantic\nanalysis, in principle any aspect of the context could be the target\nof a phenomenon that warrants a dynamic analysis of interpretation.\nBarker’s 2002\ntreatment of the information provided by vague statements is\nillustrative. Barker assumes that contexts contain precise standards\nfor vague adjectives like tall. A sentence like\n (19)\n can then be used in two distinct ways.\n (19)\n John is tall. If the information state contains precise (enough)\ninformation about what counts as tall, then an utterance of\n (19)\n may be used to provide information about John’s height. If,\nhowever, the hearer has no idea about the appropriate precisification\nof an expression like tall (say, s/he is an alien or a\nforeigner), but s/he does have information about John’s height,\nthen\n (19)\n can be used to provide information about the standard. \nContext plays an important role in presupposition. A sentence like\n (13)\n presupposes that John is late. But put this sentence in a context\nproviding this very information, as in\n (14),\n and the presupposition disappears. That John is late is\nasserted in\n (14),\n not presupposed. \nStalnaker 1973 takes\npresupposition to be based on presumed common knowledge. Uttering a\nsentence like\n (13)\n takes for granted that it is common knowledge that John is\nlate. In this sense,\n (13)\n requires the context of utterance to be such that this common\nknowledge is in place. In contrast,\n (14)\n lacks such a requirement simply because the first conjunct in\n (14)\n asserts what the second conjunct takes for granted. The crucial\nassumption made by Stalnaker is that interpretation is incremental in\nthe following sense: for a sentence of the form [\\(S\\)1 and\n\\(S\\)2], the interpretation of \\(S\\)2 occurs in a context which\nis already updated with \\(S\\)1. Schematically: \nStalnaker’s interpretation of the scheme in\n (15)\n is pragmatic: when we encounter a series of clauses in discourse, we\ninterpret these clauses in light of a context that is already\ninformed by the interpretation of previous clauses. This idea of\nincremental interpretation is simple yet powerful and it makes perfect\nsense for complex discourses with conjunctive interpretations (for\ninstance, coordinations with and and simple sequences of\ndeclarative sentences). Since the conjuncts in a conjunction have\nassertoric force, they can be used to update the context in order to\ncreate a new local context. The problem is though that presuppositions\ndo not just disappear in conjunctive environments. Just like\n (14),\n (16) also lacks the requirement that it should be common\nknowledge that John is late. But here the first disjunct does not have\nassertoric force (see, for instance, Schlenker 2009 for discussion).\nIt is not obvious what kind of pragmatic rule could account for the\nlack of a presupposition in\n (16). \nExamples like\n (16)\n call into question the value of an incremental interpretation schema\nlike\n (15).\n On top of that,\n (15)\n is rather presumptuous in its assumptions of how interpretation\nproceeds. Asserting a clause with propositional content \\(p\\) does\nnot automatically make it common knowledge that \\(p\\). Rather, such\nan assertion should be regarded as a proposal to make\n\\(p\\) common knowledge. Whether or not \\(p\\) becomes common\nground is dependent on the willingness of the other interlocutors to\naccept the proposition (for instance, by not objecting against the\nassertion). In other words,\n (15)\n seems ill-suited for capturing the pragmatics of (the dynamics of)\ninformation flow. \nA possible way out is to regard\n (15)\n not as a pragmatic rule, but rather as a semantic rule, couched in a\ndynamic notion of interpretation. This was most prominently proposed\nin Heim 1983b, following Karttunen 1973. Karttunen distinguishes\nglobal contexts, which are contexts relative to which the\ncurrent sentence is evaluated, from local contexts, which are\ncontexts relative to which the current clause (or potentially some\nsub-clausal entity) is interpreted. The idea now is that a rule like\n (15)\n can express the semantics of and. In\n (15),\n \\(C\\) is the global context. A crucial part of the semantics of\nconjunction is that the local context for \\(S\\)2 is the update of\nthe global context with \\(S\\)1. Thus, there is no presupposition in\n (14)\n simply because of the dynamic semantics of and. All\nwe need to account for the lack of presupposition in\n (16)\n is to come up with a semantics for disjunction in which the local\ncontext for the second disjunct has already been updated with the\nnegation of the first disjunct; see Krahmer and Muskens 1996 for such\nan account that also captures interactions between (double) negation\nand anaphora. \nTo make things more concrete let us assume that contexts are sets of\npossible worlds and that an update \\(C[S]\\) of \\(C\\) with a simple\nclause \\(S\\) is \\(C\\cap p\\), where \\(p\\) is the propositional\ncontent of \\(S\\): updating \\(C\\) with a clause outputs the\n\\(C\\) worlds in which the clause is true. The rules in\n (18)\n show a Heimian fragment of a dynamic interpretation of the main\npropositional operators in English. \nSome question the explanatory value of such a dynamic interpretation\nin the sense that the framework fails to account for why there appear\nto be no natural language expressions that encode a minimal variation\nof\n (17),\n where the local context of the second disjunct \\(S\\)2 is \\(C[S1]\\)\ninstead of \\(C[\\textrm{not }S1]\\), or where the local context of\n\\(S\\)1 is based on an update with \\(S\\)2, or where there are no\nlocal contexts at all as in\n (18)\n (see, for instance, Soames 1989). \nIn light of such criticisms, there has been a recent resurgence of\nstatic approaches to presupposition projection, such as the pragmatic\napproaches of Schlenker (2008, 2009), Chemla (2008, Other Internet\nResources) and the semantic (trivalent) approaches of George (2008)\nand Fox (2008). As Rothschild points out though, there is a route to\nmaking a semantics along the lines of\n (17)\n explanatory. To do so, one has to show that permissible dynamic\ninterpretations of connectives share certain properties. As Rothschild\n(2011) shows, an\nexplanatory and empirically adequate dynamic treatment of\npresupposition is possible if we assume that context change potentials\nadhere to certain principles of definedness. Let us assume that\n\\(C[S]\\) (for a simple clause \\(S\\)) is only defined if and only if\nany presupposition of \\(S\\) is true in all the worlds in \\(C\\).\nThe rules in\n (17)\n determine the definedness conditions for complex statements. For\ninstance, according to\n (17)\n [not S] is only undefined in \\(C\\) if \\(S\\) is undefined in\n\\(C\\). Rothschild’s insight is that we can constrain dynamic\ninterpretation by constraining the resulting definedness\nconditions. \nEpistemic logic, the logic of knowledge, is a branch of modal logic\nwhere the modality “\\(i\\) knows that” is studied\n(compare the entries:\n epistemic logic,\n logic of belief revision). The dynamic turn in epistemic logic, which took place\naround 2000, introduced a focus on change of state, but now with\nstates taken to be representations of the knowledge of a set of\nagents. \nIf we fix a set of basic propositions \\(P\\) and a set of agents\n\\(I\\), then a knowledge state for \\(P\\) and \\(I\\) consists of\na set \\(W\\) of possible worlds, together with a valuation function\n\\(V\\) that assigns a subset of \\(P\\) to each \\(w\\) in\n\\(W\\) (if \\(w \\in W\\), then \\(V(w)\\) lists the basic propositions\nthat are true in \\(w)\\) and for each agent \\(i \\in I\\), a relation\n\\(R_i\\) stating the epistemic similarities for \\(i\\) (if \\(wR_i\nw'\\), this means that agent \\(i\\) cannot distinguish world \\(w\\)\nfrom world w\\('\\)). Epistemic models \\(M = (W, V, \\{R_i \\mid\ni \\in I\\})\\) are known as multimodal Kripke models. Pointed epistemic\nmodels are epistemic models with a designated world \\(w_0\\)\nrepresenting the actual world. \nWhat happens to a given epistemic state \\((M, w_0) = ((W, V, \\{ R_i\n\\mid i \\in I\\}), w_0)\\) if a public announcement \\(\\phi\\) is made?\nIntuitively, the world set \\(W\\) of \\(M\\) is restricted to those\nworlds \\(w \\in W\\) where \\(\\phi\\) holds, and the valuation function\n\\(V\\) and epistemic relations \\(R_i\\) are restricted accordingly.\nCall the new model \\(M\\mid\\phi\\). In case \\(\\phi\\) is true in \\(w_0\\),\nthe meaning of the public announcement \\(\\phi\\) can be viewed as a map\nfrom \\((M, w_0)\\) to \\((M\\mid\\phi , w_0)\\). In case \\(\\phi\\) is false\nin \\(w_0\\), no update is possible. \nVeltman’s update logic can be accommodated in public\nannouncement logic (compare the entry on\n common knowledge)\n by allowing public announcements of the form \\(\\Diamond \\phi\\), where\nthe modality is read as reachability under common knowledge. If an\n\\(S\\)5 knowledge state for a set of agents (compare the entry on\n epistemic logic)\n is updated with the public announcement \\(\\Diamond \\phi\\), then in\ncase \\(\\phi\\) is true somewhere in the model, the update changes\nnothing (for in this case \\(M\\mid\\Diamond \\phi\\) equals \\(M)\\), and\notherwise the update yields inconsistency (since public announcements\nare assumed to be true). This is in accordance with the update logic\ndefinition. \nThe logical toolbox for epistemic logic with communicative updates is\ncalled dynamic epistemic logic or DEL. DEL started out from the\nanalysis of the epistemic and doxastic effects of public announcements\n(Plaza 1989; Gerbrandy 1999). Public announcement is interesting\nbecause it creates common knowledge. There is a variety of other kinds\nof announcements—private announcements, group announcements,\nsecret sharing, lies, and so on—that also have well-defined\nepistemic effects. A general framework for a wide class of update\nactions was proposed in Baltag et al. 1999 and Baltag and Moss 2004. A\nfurther generalization to a complete logic of communication and\nchange, with enriched actions that allow changing the facts of the\nworld, is provided in Benthem et al. 2006. A textbook treatment of\ndynamic epistemic logic is given in Ditmarsch et al. 2006. \nWithin an epistemic logic setting, one may represent the communicative\nsituation of an utterance with presuppositions as follows. First, we\nneed to represent what a speaker assumes about what her audience knows\nor believes in a multi-agent belief (or knowledge) state, then we need\nto model the effect of the communicative action on the belief state. A\nsimple way to handle presupposing utterances in dynamic epistemic\nlogic is by modeling a presupposition \\(P\\) as a public\nannouncement “it is common knowledge that \\(P\\)”. In\ncases where it is indeed common knowledge that \\(P\\), an update\nwith this information changes nothing. In cases where \\(P\\) is not\ncommon knowledge, however, the utterance is false, and public\nannouncements of falsehoods yield an inconsistent knowledge state. \nDynamic semantics is particularly suitable to describe how different\ntypes of linguistic material affect different aspects of the\ninformation state. In particular, dynamic semantics allows one to\nefficiently model the difference between at-issue content,\ne.g., the content that is asserted by the utterance of a declarative\nsentence and non-at issue content, content that plays some\nsecondary role. For instance, the at-issue content of\n (19)\n is that John’s neighbor was arrested yesterday: it is the\nmessage the speaker intends to assert. The appositive who I have\nnever met is not at issue. One way to see this is that an\ninterlocutor can only respond to\n (19)\n with No! That’s not true! if s/he intends to challenge\nthe fact that the neighbor was arrested, not if s/he merely wishes to\nexpress their disbelief in the speaker’s claim of never having\nmet the neighbor. \nDynamic semantics is a suitable framework for analyzing what goes on\nwhen such sentences are interpreted, since it naturally allows the\nmodeling of separate streams of information. For instance, AnderBois\net al. 2015 provide an account of sentences like\n (19)\n where the matrix sentence updates a local set of possible worlds. The\nupdated set can be seen as a potential candidate for updating the\ncommon ground with. In contrast, the appositive directly updates the\ncommon ground. Rather than a proposed common ground update,\nit can be seen as an imposed update (see Nouwen 2007 for an\nalternative dynamic logic). The ideas of AnderBois et al. 2015 are\npartly inspired by similar ideas that were successfully applied in the\nrealm of evidentials; see in particular Murray 2014. \nCompositionality has always been an important concern in the use of\nlogical systems in natural language semantics (see the entry on\n compositionality).\n Through the use of higher order logics (see the entries on\n second-order and higher-order logics\n and\n Church’s type theory),\n a thoroughly compositional account of, e.g., the quantificational\nsystem of natural language can be achieved, as is demonstrated in\nclassical Montague grammar (Montague 1974a,b, 1973; compare the entry\non\n logical form).\n We will review how the dynamic approach can be extended to higher\norder systems. The link between dynamic semantics and type theory is\nmore like a liaison than a stable marriage: there is no intrinsic need\nfor the connection. The connection is treated here to explain the\nhistorical influence of Montague grammar on dynamic semantics. \nMost proposals for dynamic versions of Montague grammar develop what\nare in fact higher order versions of dynamic predicate logic (DPL).\nThis holds for Groenendijk and Stokhof 1990; Chierchia 1992, 1995;\nMuskens 1994, 1995, 1996; Eijck 1997; Eijck and Kamp 1997; Kohlhase et\nal. 1996; and Kuschert 2000. These systems all inherit a feature (or\nbug) from the DPL approach: they make re-assignment destructive. DRT\ndoes not suffer from this problem: the discourse representation\nconstruction algorithms of Kamp 1981 and Kamp and Reyle 1993 are\nstated in terms of functions with finite domains, and carefully talk\nabout “taking a fresh discourse referent” to extend the\ndomain of a verifying function, for each new noun phrase to be\nprocessed. \nIn extensional Montague grammar “a man” translates as:\n \nHere \\(P\\), of type \\(e \\rightarrow t\\), is the variable for the VP\nslot: it is assumed that VPs denote sets of entities.  \nIn Dynamic Montague Grammar (DMG) of Groenendijk and Stokhof 1990, the\ntranslation of an indefinite NP introduces an anaphoric index. The\ntranslation of “a man” is  \nInstead of the basic types e and t of classical extensional Montague\ngrammar, DMG has basic types \\(e, t\\) and \\(m (m\\) for marker). States\npick out entities for markers, so they can be viewed as objects of\ntype \\(m \\rightarrow e\\). Abbreviating \\(m \\rightarrow e\\) as \\(s\\)\n(for “state”), we call objects of type \\(s \\rightarrow s\n\\rightarrow t\\) state transitions. The variable \\(P\\) in the DMG\ntranslation of “a man” has type \\(m \\rightarrow s\n\\rightarrow s \\rightarrow t\\), so VP meanings have been lifted from\ntype \\(e \\rightarrow t\\) to this type. Note that \\(\\rightarrow\\)\nassociates to the right, so \\(m \\rightarrow s \\rightarrow s\n\\rightarrow t\\) is shorthand for \\(m \\rightarrow(s \\rightarrow(s\n\\rightarrow t))\\). Indeed, DMG can be viewed as the result of\nsystematic replacement of entities by markers and of truth values by\nstate transitions. A VP meaning for “is happy” is a\nfunction that maps a marker to a state transition. The state\ntransition for marker \\(u_i\\) will check whether the input state maps\n\\(u_i\\) to a happy entity, and whether the output context equals the\ninput context. The variables \\(a\\), a\\('\\) range over\nstates, and the expression \\((u_i \\mid x)a\\) denotes the result of\nresetting the value of \\(u_i\\) in \\(a\\) to \\(x\\), so the old\nvalue of \\(u_i\\) gets destroyed (destructive assignment). The\nanaphoric index \\(i\\) on reference marker \\(u_i\\) is introduced by\nthe translation. In fact, the translation starts from the indexed\nindefinite noun phrase “a man\\(_i\\)”. The connection\nbetween Montagovian compositionality and dynamic semantics as well as\nthe basic Montagovian and dynamic ingredients are much more\ntransparent and streamlined in the typed Logic of Change proposed in\nMuskens 1991, 1995, 1996. Because of this, Muskens’s\nCompositional DRT is probably the de facto standard and\nstarting point for current research in compositional dynamic\nsemantics. An alternative treatment is given in Incremental Typed\nLogic (ITL), an extension to typed logic of a “stack\nsemantics” that is based on variable free indexing and that\navoids the destructive assignment problem. The basic idea of the stack\nsemantics for DPL, developed in Vermeulen 1993, is to replace the\ndestructive assignment of ordinary DPL, which throws away old values\nwhen resetting, by a stack-valued one that allows old values to be\nreused. Stack-valued assignments assign to each variable a stack of\nvalues, the top of the stack being the current value. Existential\nquantification pushes a new value on the stack, but there is also the\npossibility of popping the stack to reuse a previously assigned value.\nEijck’s 2000 ITL is in fact a typed version of stack semantics,\nusing a single stack. \nAssuming a domain of entities, contexts are finite lists of entities.\nIf \\(c\\) is a context of length \\(n\\), then we refer to its\nelements as \\(c[0]\\), \\(\\ldots ,c[n-1]\\), and to its length as\n\\(\\lvert c\\rvert\\). We will refer to the type of contexts of length\n\\(i\\) as \\([e]^i\\). If \\(c\\) is a context in \\([e]^i\\), then\nobjects of type \\(\\{0, \\ldots ,i-1\\}\\) can serve as indices into\n\\(c\\). If \\(c \\in[e]^i\\) and \\(j \\in \\{0, \\ldots ,i-1\\}\\), then\n\\(c[j]\\) is the object of type e that occurs at position \\(j\\) in\nthe context. A key operation on contexts is extension with an element.\nIf \\(c :: [e]^i\\) and \\(x :: e\\) (\\(c\\) is a context of length\n\\(i\\) and \\(x\\) is an entity) then \\(c\\mcaret x\\) is the context\nof length \\(i+1\\) that has elements \\(c\\)[0], \\(\\ldots ,c[i-1],\nx\\). Thus \\(\\mcaret\\) is an operator of type \\([e]^i \\rightarrow e\n\\rightarrow[e]^{i+1}\\). Also note that types like \\([e]^i\\) are in\nfact polymorphic types, with \\(i\\) acting as a type variable. See\nMilner 1978. \nIn ITL there is no destructive assignment, and indefinite noun phrases\ndo not carry indexes in the syntax. The ITL translation of “a\nman” picks up an index from context, as follows:  \nHere \\(P\\) is a variable of type \\(\\{0, \\ldots ,i\\}\n\\rightarrow[e]^{i+1} \\rightarrow [e]^j \\rightarrow t\\), while \\(c\\)\nis a variable of type [\\(e]^i\\) representing the input context of\nlength \\(i\\), and \\(c'\\) is a variable of type [\\(e]^j\\)\nrepresenting the output context. Note that the type \\(\\{0, \\ldots ,i\\}\n\\rightarrow [e]^{i+1} \\rightarrow [e]^j \\rightarrow t\\) for \\(P\\)\nindicates that \\(P\\) first takes an index in the range \\(\\{0,\n\\ldots ,i\\}\\), next a context fitting this range (a context of length\n\\(i+1)\\), next a context of a yet unknown length, and then gives a\ntruth value. \\(P\\) is the type of unary predicates, lifted to the\nlevel of context changers, as follows. Instead of using a variable to\nrange over objects to form an expression of type \\(e\\), a lifted\npredicate uses a variable ranging over the size of an input context to\nform an expression that denotes a changer for that context.  \nThe ITL translation of “a man” has type \n\n\\[(\\{0, \\ldots ,i\\} \\rightarrow[e]^{i+1} \\rightarrow [e]^j \\rightarrow t) \\rightarrow [e]^i \\rightarrow [e]^j \\rightarrow t.\\] \n\n In\n\\(P\\lvert c\\rvert (c\\mcaret x)c'\\), the \\(P\\) variable marks the\nslot for the VP interpretation; \\(\\lvert c\\rvert\\) gives the length of\nthe input context to \\(P\\); it picks up the value \\(i\\), which\nis the position of the next available slot when the context is\nextended. This slot is filled by an object \\(x\\) denoting a man.\nNote that \\(c\\mcaret x[\\lvert c\\rvert ] = c\\mcaret x[i] = x\\), so the\nindex \\(i\\) serves to pick out that man from the context. \nTo see that a dynamic higher order system is expressible in ITL, it is\nenough to show how to define the appropriate dynamic operations.\nAssume \\(\\phi\\) and \\(\\psi\\) have the type of context transitions,\ni.e. type [\\(e] \\rightarrow[e] \\rightarrow t\\) (using [\\(e\\)] for\narbitrary contexts), and that \\(c, c', c''\\) have type [\\(e\\)].\nThen we can define the dynamic existential quantifier, dynamic\nnegation and dynamic composition as follows:  \nDynamic implication \\(\\Rightarrow\\) is defined in the usual way by\nmeans of \\({\\sim}(\\phi; {\\sim}\\psi)\\). \nITL and Muskens style Compositional DRT are not incompatible; see\nBittner 2014 for example. We will end this section by noting that the\nrange of systems integrating Montagovian compositionality and dynamic\nsemantics is far from being completely charted. A recent series of\ncontributions integrating continuation-based and dynamic semantics is\nexploring new ways of integrating and generalizing them; see de Groote\n2006, Bumford and Barker 2013, Charlow 2014, Bumford 2015, and Martin\n2016. \nHopefully, the above has given the reader a sense of Dynamic Semantics\nas a fruitful and flexible approach to meaning and information\nprocessing. Dynamic semantics comes with a set of flexible tools, and\nwith a collection of “killer applications”, such as the\ncompositional treatment of donkey sentences, the account of anaphoric\nlinking, the account of presupposition projection, the account of\nepistemic updating and fine-grained distinctions between different\nkinds of (non-at-issue) updates. Dynamic semantics is a very lively\nsubfield of formal semantics and the cross-linguistic range of\nphenomena for which dynamic approaches are being pursued is expanding\nat an increasing pace.","contact.mail":"Albert.Visser@phil.uu.nl","contact.domain":"phil.uu.nl"}]
