[{"date.published":"2001-08-17","date.changed":"2016-10-14","url":"https://plato.stanford.edu/entries/causation-mani/","author1":"James Woodward","author1.info":"https://www.hps.pitt.edu/people/james-woodward","entry":"causation-mani","body.text":"\n\n\nManipulability theories of causation, according to which causes are to\nbe regarded as handles or devices for manipulating effects, have\nconsiderable intuitive appeal and are popular among social scientists\nand statisticians. This article surveys several prominent versions of\nsuch theories advocated by philosophers, and the many difficulties\nthey face. Philosophical statements of the manipulationist approach\nare generally reductionist in aspiration and assign a central role to\nhuman action. These contrast with recent discussions employing a\nbroadly manipulationist framework for understanding causation, such as\nthose due to the computer scientist Judea Pearl and others, which are\nnon-reductionist and rely instead on the notion of an intervention.\nThis is simply an appropriately exogenous causal process; it has no\nessential connection with human action. This interventionist framework\nmanages to avoid at least some of these difficulties faced by\ntraditional philosophical versions of the manipulability theory and\nhelps to clarify the content of causal claims.\n\n\n\n\nA commonsensical idea about causation is that causal relationships are\nrelationships that are potentially exploitable for purposes of\nmanipulation and control: very roughly, if \\(C\\) is genuinely a cause\nof \\(E\\), then if I can manipulate \\(C\\) in the right way, this should\nbe a way of manipulating or changing \\(E\\). This idea is the\ncornerstone of manipulability theories of causation developed by\nphilosophers such as Gasking (1955), Collingwood (1940), von Wright\n(1971), Menzies and Price (1993), and Woodward (2003). It is also an\nidea that is advocated by many non-philosophers. For example, in their\nextremely influential text on experimental design (1979) Cook and\nCampbell write: \nThe paradigmatic assertion in causal relationships is that\nmanipulation of a cause will result in the manipulation of an\neffect. … Causation implies that by varying one factor I\ncan make another vary. (Cook & Campbell 1979: 36, emphasis in\noriginal) \nSimilar ideas are commonplace in econometrics and in the so-called\nstructural equations or causal modeling literature, and very recently\nhave been forcefully reiterated by the computer scientist Judea Pearl\nin very influential book length treatment of causality (Pearl\n2009). \nAt least until recently philosophical discussion has been\nunsympathetic to manipulability theories: two standard complaints have\nbeen that manipulability theories are unilluminatingly circular and\nthat they lead to a conception of causation that is unacceptably\nanthropocentric or at least insufficiently general in the sense that\nit is linked much too closely to the practical possibility of human\nmanipulation (see, e.g., Hausman 1986, 1998). Both objections seem\nprima facie plausible. Suppose that \\(X\\) is a variable that\ntakes one of two different values, 0 and 1, depending on whether some\nevent of interest occurs. Then for an event or process \\(M\\) to\nqualify as a manipulation of \\(X\\), it would appear that there must be\na causal connection between \\(M\\) and \\(X\\): to manipulate \\(X\\), one\nmust cause it to change in value. How then can we use the\nnotion of manipulation to provide an account of causation? Moreover,\nit is uncontroversial that causal relationships can obtain in\ncircumstances in which manipulation of the cause by human beings is\nnot practically possible—think of the causal relationship\nbetween the gravitational attraction of the moon and the motion of the\ntides or causal relationships in the very early universe. How can a\nmanipulability theory avoid generating a notion of causation that is\nso closely tied to what humans can do that it is inapplicable to such\ncases? \nThese philosophical criticisms of manipulability theories contrasts\nwith the widespread view among statisticians, theorists of\nexperimental design, and many social and natural scientists that an\nappreciation of the connection between causation and manipulation can\nplay an important role in clarifying the meaning of causal claims and\nunderstanding their distinctive features. This in turn generates a\npuzzle. Are non-philosophers simply mistaken in thinking that focusing\non the connection between causation and manipulation can tell us\nsomething valuable about causation? Does the widespread invocation of\nsomething like a manipulability conception among practicing scientists\nshow that the usual philosophical criticisms of manipulability\ntheories of causation are misguided? \nThe ensuing discussion is organized as follows.\n Section 2\n describes a well-known version of an manipulability theory due to\nMenzies and Price (1993) which assigns a central role to the notion of\nagency or free action.\n Section 3\n describes reasons why the notion of a free action seems an inadequate\nbasis for the formulation of a manipulability theory.\n Section 4\n introduces the notion of an intervention which allows for a more\nadequate statement of the manipulability approach to causation and\nwhich has figured prominently in recent discussion.\n Section 5\n considers Pearl’s “interventionist” formulation of\na manipulability theory and an alternative to it, due to Woodward\n(2003).\n Section 6\n takes up the charge that manipulability theories are circular.\n Section 7\n explores how interventionist ideas can be used to explicate a variety\nof different causal concepts.\n Section 8\n returns to the relationship between interventions and human actions,\nwhile\n §9\n discusses the role of counterfactuals in interventionist theories.\nSections\n 10,\n 11 and\n 12\n consider the scope of manipulability accounts, while\n §13\n considers some objections to such accounts and\n §14\n some recent positive developments. \nAs we shall see, the somewhat different assessments of manipulability\naccounts of causation within and outside of philosophy derive in part\nfrom the different goals or aspirations that underlie the versions of\nthe theory developed by these two groups. Early philosophical\ndefenders of the manipulability conception such as von Wright and\nMenzies and Price attempted to turn the connection between causation\nand manipulability into a reductive analysis: their strategy was to\ntake as primitive the notion of manipulation (or some related notion\nlike agency or bringing about an outcome as a result of a free\naction), to argue that this notion is not itself causal (or at least\ndoes not presuppose all of the features of causality the investigator\nis trying to analyze), and to then attempt to use this notion to\nconstruct a non-circular reductive definition of what it is for a\nrelationship to be causal. Philosophical critics have (quite\nreasonably) assessed such approaches in terms of this aspiration\n(i.e., they have tended to think that manipulability accounts are of\ninterest only insofar as they lead to a non-circular analysis of\ncausal claims) and have found the claim of a successful reduction\nunconvincing. By contrast, statisticians and other non-philosophers\nwho have explored the link between causation and manipulation\ngenerally have not had reductionist aspirations—instead their\ninterest has been in unpacking what causal claims mean and in showing\nhow they figure in inference by tracing their interconnections with\nother related concepts (such as manipulation) but without suggesting\nthat the notion of manipulation is itself a causally innocent\nnotion. \nThe impulse toward reduction contributes to the other features that\ncritics have found objectionable in standard formulations of the\nmanipulability theory. To carry through the reduction, one needs to\nshow that the notion of agency is independent of or prior to the\nnotion of causality and this in turn requires that human actions or\nmanipulations be given a special status—they can’t be\nordinary causal transactions, but must instead be an independent\nfundamental feature of the world in their own right. This both seems\nproblematic on its own terms (it is prima facie inconsistent\nwith various naturalizing programs) and leads directly to the problem\nof anthropocentricity: if the only way in which we understand\ncausation is by means of our prior grasp of an independent notion of\nagency, then it is hard to see what could justify us in extending the\nnotion of causation to circumstances in which manipulation by human\nbeings is not possible and the relevant experience of agency\nunavailable. Both von Wright and Menzies and Price struggle, not\nentirely successfully, with this difficulty. \nThe way out of these problems is to follow Pearl and others in\nreformulating the manipulability approach in terms of the notion of an\nintervention, where this is characterized in purely causal terms that\nmake no essential reference to human action. Some human actions will\nqualify as interventions but they will do so in virtue of their causal\ncharacteristics, not because they are free or carried out by humans.\nThis “interventionist” reformulation allows the\nmanipulability theory to avoid a number of counterexamples to more\ntraditional versions of the theory. Moreover, when so reformulated, it\nis arguable that the theory may be extended readily to capture causal\nclaims in contexts in which human manipulation is impossible. However,\nthe price of such a reformulation is that we lose the possibility of a\nreduction of causal claims to claims that are non-causal. Fortunately\n(or so\n §§7 and\n 8 argue) an interventionist formulation of a manipulability\ntheory may be non-trivial and illuminating even if it fails to be\nreductive. \nA comparatively early and influential statement of a manipulability\ntheory which assigns a central role to human agency is due to von\nWright (1971; see\n An Early Version of an Agency Theory\n for further discussion). However, this entry will focus on the more\nrecent version of an agency theory developed by Peter Menzies and Huw\nPrice (1993) (also discussed in a series of papers written by Price\nalone [1991, 1992).\nMenzies’ and Price’s basic thesis is that: \n… an event \\(A\\) is a cause of a distinct event \\(B\\) just in\ncase bringing about the occurrence of \\(A\\) would be an effective\nmeans by which a free agent could bring about the occurrence of \\(B\\).\n(1993: 187) \nThey take this connection between free agency and causation to support\na probabilistic analysis of causation (according to which “\\(A\\)\ncauses \\(B\\)” can be plausibly identified with “\\(A\\)\nraises the probability of \\(B\\)”) provided that the\nprobabilities appealed to are what they call “agent\nprobabilities,” where \n[a]gent probabilities are to be thought of as conditional\nprobabilities, assessed from the agent’s perspective under the\nsupposition that antecedent condition is realized ab initio,\nas a free act of the agent concerned. Thus the agent probability that\none should ascribe to \\(B\\) conditional on \\(A\\) is the probability\nthat \\(B\\) would hold were one to choose to realize \\(A\\). (1993:\n190) \nThe idea is thus that the agent probability of \\(B\\) conditional on\n\\(A\\) is the probability that \\(B\\) would have conditional on the\nassumption that \\(A\\) has a special sort of status or history—in\nparticular, on the assumption that A is realized by a free act. \\(A\\)\nwill be a cause of \\(B\\) just in case the probability of \\(B\\)\nconditional on the assumption that \\(A\\) is realized by a free act is\ngreater than the unconditional probability of \\(B\\); \\(A\\) will be a\nspurious cause of \\(B\\) just in case these two probabilities are\nequal. As an illustration, consider a stock example of\nphilosophers—a structure in which atmospheric pressure,\nrepresented by a variable \\(Z\\), is a common cause of the reading\n\\(X\\) of a barometer and the occurrence of a storm \\(Y\\), with no\ncausal relationship between \\(X\\) and \\(Y. X\\) and \\(Y\\) will be\ncorrelated, but Price’s and Menzies’ intuitive idea is\nthat conditional on the realization of \\(X\\) by a free act, this\ncorrelation will disappear, indicating that the correlation between\n\\(X\\) and \\(Y\\) is spurious and does not reflect a causal connection\nfrom \\(X\\) to \\(Y\\). If, by contrast, this correlation were to\npersist, this would be an indication that \\(X\\) was after all a cause\nof \\(Y\\). (What “free act” might mean in this context will\nbe explored below, but I take it that what is\nintended—as opposed to what Price and Menzies actually\nsay—is that the manipulation of \\(X\\) should satisfy the\nconditions we would associate with an ideal experiment designed to\ndetermine whether \\(X\\) causes \\(Y\\)—thus, for example, the\nexperimenter should manipulate the position of the barometer dial in a\nway that is independent of the atmospheric pressure \\(Z\\), perhaps by\nsetting its value after consulting the output of some randomizing\ndevice.) \nMenzies and Price claim that they can appeal to this notion of agency\nto provide a non-circular, reductive analysis of causation. They claim\nthat circularity is avoided because we have a grasp of the\nexperience of agency that is independent of our grasp of the\ngeneral notion of causation. \nThe basic premise is that from an early age, we all have direct\nexperience of acting as agents. That is, we have direct experience not\nmerely of the Humean succession of events in the external world, but\nof a very special class of such successions: those in which the\nearlier event is an action of our own, performed in circumstances in\nwhich we both desire the later event, and believe that it is more\nprobable given the act in question than it would be otherwise. To put\nit more simply, we all have direct personal experience of doing one\nthing and thence achieving another. … It is this common and\ncommonplace experience that licenses what amounts to an ostensive\ndefinition of the notion of ‘bringing about’. In other\nwords, these cases provide direct non-linguistic acquaintance with the\nconcept of bringing about an event; acquaintance which does not depend\non prior acquisition of any causal notion. An agency theory thus\nescapes the threat of circularity. (1993: 194–5) \nMenzies and Price recognize that, once the notion of causation has\nbeen tied in this way to our “personal experience of doing one\nthing and hence achieving another” (1993: 194), a problem arises\nconcerning unmanipulable causes. To use their own example, what can it\nmean to say that “the 1989 San Francisco earthquake was caused\nby friction between continental plates” (1993: 195) if no one\nhas (or given the present state of human capabilities could have) the\ndirect personal experience of bringing about an earthquake by\nmanipulating these plates? Their response to this difficulty is\ncomplex, but the central idea is captured in the following\npassages \n… we would argue that when an agent can bring about one event\nas a means to bringing about another, this is true in virtue of\ncertain basic intrinsic features of the situation involved, these\nfeatures being essentially non-causal though not necessarily physical\nin character. Accordingly, when we are presented with another\nsituation involving a pair of events which resembles the given\nsituation with respect to its intrinsic features, we infer that the\npair of events are causally related even though they may not be\nmanipulable. (1993: 197) \nClearly, the agency account, so weakened, allows us to make causal\nclaims about unmanipulable events such as the claim that the 1989 San\nFrancisco earthquake was caused by friction between continental\nplates. We can make such causal claims because we believe that there\nis another situation that models the circumstances surrounding the\nearthquake in the essential respects and does support a means-end\nrelation between an appropriate pair of events. The paradigm example\nof such a situation would be that created by seismologists in their\nartificial simulations of the movement of continental plates. (1993:\n197) \nOne problem with this suggestion has to do with how we are to\nunderstand the “intrinsic” but (allegedly)\n“non-causal” features in virtue of which the movements of\nthe continental plates “resemble” the artificial models\nwhich the seismologists are able to manipulate. It is well-known that\nsmall scale models and simulations of naturally occurring phenomena\nthat superficially resemble or mimic those phenomena may nonetheless\nfail to capture their causally relevant features because, for example,\nthe models fail to “scale up”—because causal\nprocesses that are not represented in the model become quite important\nat the length scales that characterize the naturally occurring\nphenomena. Thus, when we ask what it is for a model or simulation\nwhich contains manipulable causes to “resemble” phenomena\ninvolving unmanipulable causes, the relevant notion of resemblance\nseems to require that the same causal processes are operative\nin both. Menzies and Price do not provide any reason to think that\nthis notion of resemblance can be characterized in non-causal terms.\nBut if the extension of their account to unmanipulable causes requires\na notion of resemblance that is already causal in character and which,\nex hypothesi cannot be explained in terms of our experience\nof agency, then their reduction fails. \nIt might be thought the difficulty under discussion can be avoided by\nthe simple expedient of adhering to a counterfactual formulation of\nthe manipulability theory. Indeed, it is clear that some\ncounterfactual formulation is required if the theory is to be even\nremotely plausible: after all, no one supposes that \\(A\\) can only be\na cause of \\(B\\) if \\(A\\) is in fact manipulated. One thus might\nconsider a formulation along the lines of: \nThe suggestion under consideration attempts to avoid the difficulties\nposed by causes that are not manipulable by human beings by contending\nthat for\n (CF)\n to be true, it is not required that the manipulation in question be\npractically possible for human beings to carry out or even that human\nbeings exist. Instead all that is required is that \\(if\\) human beings\nwere to carry out the requisite manipulation of \\(A\\) (e.g., the\ncontinental plates), \\(B\\) (whether or not an earthquake occurs) would\nchange. (The possibility of adopting such a counterfactual formulation\nis sympathetically explored, but not fully endorsed by Ernest Sosa and\nMichael Tooley in the introduction to their 1993.) \nOne fundamental problem with this suggestion is that, independently of\nwhether a counterfactual formulation is adopted, the notion of a free\naction or human manipulation cannot by itself, for reasons to be\ndescribed in\n §3,\n do the work (that of distinguishing between genuine and spurious\ncausal relationships) that Menzies and Price wish it to do. But in\naddition to this, a counterfactual formulation along the lines of\n (CF)\n seems completely unilluminating unless accompanied by some sort of\naccount of how we are to understand and assess such counterfactuals\nand, more specifically, what sort of situation or possibility we are\nsupposed to envision when we imagine that the antecedent of\n (CF)\n is true. Consider, for example, a causal claim about the very early\nuniverse during which temperatures are so high that atoms and\nmolecules and presumably anything we can recognize as an agent cannot\nexist. What counterfactual scenario or possible world are we supposed\nto envision when we ask, along the lines of\n (CF),\n what would happen if human beings were to exist and were able to\ncarry out certain manipulations in this situation? A satisfying\nversion of an agency theory should give us an account of how our\nexperience of agency in ordinary contexts gives us a purchase on how\nto understand and evaluate such counterfactuals. To their credit,\nMenzies and Price attempt to do this, but in my view they are\nunsuccessful. \nAs we have seen, Menzies and Price assign a central role to\n“free action” in the elucidation of causation. They do not\nfurther explain what they mean by this phrase, preferring instead, as\nthe passage quoted above indicates, to point to a characteristic\nexperience we have as agents. It seems clear, however, that whether\n(as soft determinists would have it) a free action is understood as an\naction that is uncoerced or unconstrained or due to voluntary choices\nof the agent, or whether, as libertarians would have it, a free action\nis an action that is uncaused or not deterministically caused, the\npersistence of a correlation between \\(A\\) and \\(B\\) when \\(A\\) is\nrealized as a “free act” is not sufficient for\n\\(A\\) to cause \\(B\\). Suppose that, in the example described above,\nthe position of the barometer dial \\(X\\) is set by a free act (in\neither of the above senses) of the experimenter but that this free act\n(and hence \\(X)\\) is correlated with \\(Z\\), the variable measuring\natmospheric pressure, perhaps because the experimenter observes the\natmospheric pressure and freely chooses to set \\(X\\) in a way that is\ncorrelated with \\(Z\\). (This possibility is compatible with the\nexperimenter’s act of setting \\(X\\) being free in either of the\nabove two senses.) In this case, \\(X\\) will remain correlated with\n\\(Y\\) when produced by a free act, even though \\(X\\) does not cause\n\\(Y\\). Suppose, then, that we respond to this difficulty by adding to\nour characterization of \\(A\\)’s being realized by a free act the\nidea that this act must not itself be correlated with any other cause\nof \\(A\\). (Passages in Price 1991 suggest such an additional proviso,\nalthough the condition in question seems to have nothing to do with\nthe usual understanding of free action.) Even with this proviso, it\nneed not be the case that \\(A\\) causes \\(B\\) if \\(A\\) remains\ncorrelated with \\(B\\) when \\(A\\) is produced by an act that is free in\nthis sense, since it still remains possible that the free act that\nproduces \\(A\\) also causes \\(B\\) via a route that does not go through\n\\(A\\). As an illustration, consider a case in which an\nexperimenter’s administration of a drug to a treatment group (by\ninducing patients to ingest it) has a placebo effect that enhances\nrecovery, even though the drug itself has no effect on recovery. There\nis a correlation between ingestion of the drug and recovery that\npersists under the experimenter’s free act of administering the\ndrug even though ingestion of the drug does not cause recovery. \nExamples like those just described show that if we wish to follow\nMenzies and Price in defending the claim that if an association\nbetween \\(A\\) and \\(B\\) persists when \\(A\\) is given the right sort of\n“independent causal history” or is\n“manipulated” in the right way, then \\(A\\) causes \\(B\\),\nwe need to be much more precise by what we mean by the quoted phases.\nThere have been a number of attempts to do this in the recent\nliterature on causation. The basic idea that all of these discussions\nattempt to capture is that of a “surgical” change in \\(A\\)\nwhich is of such a character that if any change occurs in \\(B\\), it\noccurs only as a result of its causal connection, if any, to \\(A\\) and\nnot in any other way. In other words, the change in \\(B\\), if any,\nthat is produced by the manipulation of \\(A\\) should be produced only\nvia a causal route that goes through \\(A\\). Manipulations or changes\nin the value of a variable that have the right sort of surgical\nfeatures have come to be called interventions in the recent\nliterature (e.g., Spirtes, Glymour, and Scheines 2000; Meek and\nGlymour 1994; Hausman 1998; Pearl 2009; Woodward 1997, 2000, 2003;\nWoodward and Hitchcock 2003; Cartwright 2003) and I will follow this\npractice. The characterization of the notion of an intervention is\nrightly seen by many writers as central to the development of a\nplausible version of a manipulability theory. One of the most detailed\nattempts to think systematically about interventions and their\nsignificance for understanding causation is due to Pearl 2009 and I\nturn now to a discussion of his views. \nA great deal of recent work on causation has used systems of equations\nand directed graphs to represent causal relationships. Judea Pearl\n(e.g., Pearl 2009) is an influential example of this approach. His\nwork provides a striking illustration of the heuristic usefulness of a\nmanipulationist framework in specifying what it is to give such\nsystems a causal\n interpretation.[1]\n Pearl characterizes the notion of an intervention by reference to a\nprimitive notion of a causal mechanism. A functional causal model is a\nsystem of equations \\(X_i = F(Pa_i, U_i)\\) where \\(Pa_i\\) represents\nthe parents or direct causes of \\(X_i\\) that are explicitly included\nin the model and \\(U_i\\) represents an error variable that summarizes\nthe impact of all excluded variables. Each equation represents a\ndistinct causal mechanism which is understood to be\n“autonomous” in the sense in which that notion is used in\neconometrics; this means roughly that it is possible to interfere with\nor disrupt each mechanism (and the corresponding equation) without\ndisrupting any of the others. The simplest sort of intervention in\nwhich some variable \\(X_i\\) is set to some particular value \\(x_i\\)\namounts, in Pearl’s words, to  \nlifting \\(X_i\\) from the influence of the old functional mechanism\n\\(X_i = F_i(Pa_i, U_i)\\) and placing it under the influence of a new\nmechanism that sets the value \\(x_i\\) while keeping all other\nmechanisms undisturbed. (Pearl 2009: 70; I have altered the notation\nslightly)  \nIn other words, the intervention disrupts completely the relationship\nbetween \\(X_i\\) and its parents so that the value of \\(X_i\\) is\ndetermined entirely by the intervention. Furthermore, the intervention\nis surgical in the sense that no other causal relationships in the\nsystem are changed. Formally, this amounts to replacing the equation\ngoverning \\(X_i\\) with a new equation \\(X_i = x_i\\), substituting for\nthis new value of \\(X_i\\) in all the equations in which \\(X_i\\) occurs\nbut leaving the other equations themselves unaltered. In a graphical\nrepresentation of causal relationships (see below), an intervention of\nthis sort on a variable \\(X_i\\) breaks or removes all other arrows\ndirected into \\(X_i\\), so that the value of \\(X_i\\) is now completely\nfixed by the intervention. Pearl’s assumption is that the other\nvariables that change in value under this intervention will do so only\nif they are effects of \\(X_i\\). \nAgain, if we want to use this notion of an intervention to elucidate\nwhat it is for \\(X\\) to cause \\(Y\\) it is natural to move to a\ncounterfactual formulation in the sense that what matters for whether\n\\(X\\) causes \\(Y\\) is what would happen to \\(Y\\) if an intervention on\n\\(X\\) of the sort described above were to occur. Following what has\nbecome an established usage I will call such counterfactuals, the\nantecedents of which correspond to claims about interventions (If\n\\(X\\) were set to value \\(x\\) under an intervention, then…)\ninterventionist counterfactuals. These are the\ncounterfactuals that (under some interpretation, perhaps not\nnecessarily involving Pearl’s particular notion of an\nintervention) seem most suitable for formulating a manipulability\ntheory of causation. \nThe need for such a counterfactual formulation raises several\nquestions that will be explored in more detail below. First, how\nshould one understand (what is the appropriate interpretation of or\nsemantics for) the counterfactuals in question? Without attempting to\nanswer this question in detail, it seems plausible that if\ninterventionist counterfactuals are to be useful in elucidating causal\nclaims, their semantics must be different from the familiar\nLewis/Stalnaker possible world semantics in some respects, as is\nargued by Woodward (2003), Briggs (2012), Fine (2012). For example, on\nthe Lewis/Stalnaker semantics, counterfactuals with logically or\nmetaphysically impossible antecedents are always vacuously true, but\npresumably we don’t want the causal claims that might be\nassociated with such counterfactuals to be automatically true (cf.\n §12).\n  \nA second difference is that an interventionist counterfactual of form\n“If an intervention were to set \\(X=x\\), then \\(Y= y\\)”\nrequires for its truth that all such interventions (or at\nleast all such interventions within the background circumstances in\nwhich the causal model of interest is taken to hold) would be followed\nby \\(Y= y\\). This has the consequence that, for example, “strong\ncentering” which holds for the Lewis/Stalnaker semantics, does\nnot hold for interventionist counterfactuals. According to\nstrong centering the actual world is more similar to itself than any\nother possible world. Thus if both \\(p\\) and \\(q\\) hold in the actual\nworld, then the “counterfactual” (that is, subjunctive\nconditional) “if \\(p\\) were the case, \\(q\\) would be the\ncase”, is automatically true, As an illustration of the\ndifference this makes, suppose that \\(X\\) and \\(Y\\) obey the following\nintervention–supporting functional relation: If and only if \\(X=\n1\\).5, then \\(Y= 3\\). Suppose that in the actual world, \\(X= 1.5\\),\n\\(Y= 3\\). Now consider the counterfactual \\(C\\) : If \\(1\\lt X \\lt 3\\),\nthen \\(Y=3\\). Assuming strong centering, the closest world to the\nactual world in which the antecedent of \\(C\\) is true is the actual\nworld in which \\(X=1.5\\). In this world, \\(Y=3\\), so \\(C\\) is true. By\ncontrast, \\(C\\) is false under an interventionist interpretation,\nsince values of \\(X\\) between 1 and 3 other than 1.5 are not followed\nby 3. Arguably the interventionist verdict that \\(C\\) (and the\nassociated causal claim that “\\(X\\) being between 1 and 3 causes\n\\(Y=3)\\)” are false is the correct view. Several other\ndifferences between interventionist counterfactuals and the\nLewis/Stalnaker semantics will be noted below. \nA second general issue, related to the one just described, concerns\nthe sense, if any, in which interventions must be\n“possible” and the bearing of this on the truth of the\nassociated causal claims. Returning to the notion of intervention\nassociated with Pearl above, note that this notion says nothing about\nwhether there is an actual or even possible causal factor that might\naccomplish the kind of surgical modification Pearl describes. We may\nif we wish represent such an intervention \\(I\\) by means of arrow\ndirected into the variable \\(X_i\\) that is intervened on which breaks\nall other arrows directed into \\(X_i\\) (and Pearl sometimes uses this\nrepresentation) but both the \\(I\\) variable and this arrow seem\ndispensable. We could instead just think of \\(X_i\\) as set to some new\nvalue in the arrow-breaking or equation replacement manner described\nabove, with no further restrictions on when such a setting operation\nis possible (or when it is permissible or legitimate to invoke it). I\nwill call this a setting intervention. This contrasts with an\nalternative conception of interventions and their connection to causal\nclaims according to which the truth of a claim like “\\(X\\)\ncauses \\(Y\\)” requires that interventions on \\(X\\) must be\n“possible” in some non-trivial sense of this notion, which\nthen must be specified. (In other words, the truth of “\\(X\\)\ncauses \\(Y\\)” requires both that \\(Y\\) changes under an\nintervention on \\(X\\) and that this intervention be\npossible.) When a possibility condition of this sort is imposed, I\nwill say we are making use of a possibility constrained\nnotion of intervention. Use of this notion raises the difficult\nquestion of how the relevant notion of possibility should be\nunderstood. I will suggest below that the best way of making sense of\nthis notion is in terms of some notion of conceptual or mathematical\n(or if you like, “metaphysical”) coherence—roughly\nspeaking, the issue is whether there is an appropriately empirically\ngrounded theoretical/mathematical apparatus that allows for a coherent\ndescription of the possible intervention in question and allows us to\ndetermine what would happen if the intervention were realized. In some\ncases (see below) such a description may be available even though the\nintervention in question may not be physically\n possible.[2]\n Recognizing obvious worries about the clarity of this notion of\npossibility (which in my view should be acknowledged by defenders of\nthis notion), one might think that it is preferable to always employ\nthe setting notion in formulating an interventionist account. However,\nas we shall see, formulations in terms of the “possibility\nconstrained” notion have appealing features (they seem to do a\nbetter job of capturing the truth conditions for some causal claims)\nand a number of writers seem to rely on such a conception.  \nReturning to Pearl, and following his framework, let us represent the\nproposition that the value of \\(X\\) has been set by an intervention to\nsome particular value, \\(x_0\\), by means of a “\\(\\do\\)”\noperator \\((\\do(X=x_0)\\), or more simply, \\(\\do x_0)\\). It is\nimportant to understand that conditioning on the information that the\nvalue of \\(X\\) has been set to \\(x_0\\) will in general be\nquite different from conditioning on the information that the value of\n\\(X\\) has been observed to be \\(x_0\\) (see Meek and Glymour\n1994; Pearl 2009). For example, in the case in which \\(X\\) and \\(Y\\)\nare joint effects of the common cause \\(Z\\), and \\(X\\) does not cause\n\\(Y\\), \\(P(Y/X=x_0) \\ne P(Y)\\); that is, \\(Y\\) and \\(X\\) are not\nindependent. However, \\(P(Y/\\do(X=x_0) = P(Y)\\); that is, \\(Y\\) will\nbe independent of \\(X\\), if the value of \\(X\\) is set by an\nintervention. This is because the intervention on \\(X\\) will break the\ncausal connection from \\(Z\\) to \\(X\\), so that the probabilistic\ndependence between \\(Y\\) and \\(X\\) that is produced by \\(Z\\) in the\nundisturbed system will no longer hold once the intervention occurs.\nIn this way, we may capture Menzies’ and Price’s idea that\n\\(X\\) causes \\(Y\\) if and only if the correlation between \\(X\\) and\n\\(Y\\) would persist under the right sort of manipulation of \\(X\\). \nThis framework allows for a simple definitions of various causal\nnotions. For example, Pearl defines the “causal effect” of\n\\(X\\) on \\(Y\\) associated with the “realization” of a\nparticular value \\(x\\) of \\(X\\) as: \nthat is, as the distribution that \\(Y\\) would assume under an\nintervention that sets the value of \\(X\\) to the value \\(x\\). Again,\nit is obvious that this is a version of a counterfactual account of\ncausation.  \nOne of the many attractions of this approach is that it yields a very\nnatural account of what it is to give a causal interpretation to a\nsystem of equations of the sort employed in the so-called causal\nmodeling literature. For example, if a linear regression equation \\(Y\n= aX + U\\) makes a causal claim, it is to be understood as claiming\nthat if an intervention were to occur that sets the value of \\(X=x_0\\)\nin circumstances \\(U=u_0\\), the value of \\(Y\\) would be \\(y = ax_0 +\nu_0\\), or alternatively that an intervention that changes \\(X\\) by\namount \\(dx\\) will change \\(Y\\) by amount \\(a\\; dx\\). As another\nillustration consider the system of equations \nWe may rewrite these as follows: \nwhere \\(d = b + ac\\) and \\(W = cU + V\\). Since (3) has been obtained\nby substituting (1) into (2), the system (1)–(2) has exactly the\nsame solutions in \\(X, Y\\), and \\(Z\\) as the system (1)–(3).\nSince \\(X, Y\\) and \\(Z\\) are the only measured variables,\n(1)–(2) and (1)–(3) are “observationally\nequivalent” in the sense that they imply or represent exactly\nthe same facts about the patterns of correlations that obtain among\nthe measured variables. Nonetheless, the two systems correspond to\ndifferent causal structures. (1)–(2) says that \\(X\\) is a direct\ncause of \\(Y\\) and that \\(X\\) and \\(Y\\) are direct causes of \\(Z\\). By\ncontrast, (1)–(3) says that \\(X\\) is a direct cause of \\(Y\\) and\nthat \\(X\\) is a direct cause of \\(Z\\) but says nothing about a causal\nrelation between \\(Y\\) and \\(Z\\). We can cash this difference out\nwithin the interventionist/manipulationist framework described\nabove—(2) claims that an intervention on \\(Y\\) will change \\(Z\\)\nwhile (1)–(3) denies this. (Recall that an intervention on \\(Y\\)\nwith respect to \\(Z\\) must not be correlated with any other cause of\n\\(Z\\) such as \\(X\\), and will break any causal connection between\n\\(X\\) and \\(Y\\).) Thus while the two systems of equations agree about\nthe correlations so far observed, they disagree about what would\nhappen under an intervention on \\(Y\\). According to an\ninterventionist/manipulationist account of causation, it is the system\nthat gets such counterfactuals right that correctly represents the\ncausal facts. \nOne possible limitation of the notion of a setting intervention (or at\nleast Pearl’s characterization of it) concerns the scope of the\nrequirement that an intervention on \\(X_i\\) leave intact all\nother mechanisms besides the mechanism that previously determined the\nvalue of \\(X_i^.\\) If, as Pearl apparently intends, we understand this\nto include the requirement that an intervention on \\(X_i\\) must leave\nintact the causal mechanism if any, that connects \\(X\\)i to its\npossible effects \\(Y\\), then an obvious worry about circularity\narises, at least if we want to use the notion of an intervention to\ncharacterize what it is for \\(X_i\\) to cause \\(Y\\). A closely related\nproblem is that given the way Pearl characterizes the notion of an\nintervention, his definition\n (C)\nof the causal effect of \\(X\\) on \\(Y\\), seems to give us not the\ncausal contribution made by \\(X = x\\) alone to \\(Y\\) but rather the\ncombined impact on \\(Y\\) of this contribution and whatever\ncontribution is made to the value of \\(Y\\) by other causes of \\(Y\\)\nbesides \\(X\\). For example, in the case of the regression equation \\(Y\n= aX+U\\), the causal effect in Pearl’s sense of \\(X=x\n\\textrm{on} Y\\) is apparently \\(P(Y) = ax + U\\), rather than, as one\nmight expect, just \\(ax\\). In part for these reasons (and for other\nreasons, described below), Woodward (2003) and Woodward and Hitchcock\n(2003) explore a different way of characterizing the notion of an\nintervention which does not make reference to the relationship between\nthe variable intervened on and its effects. For Woodward and\nHitchcock, in contrast to Pearl, an intervention \\(I\\) on a variable\n\\(X\\) is always defined with respect to a second variable \\(Y\\) (the\nintent being to use the notion of an intervention on \\(X\\) with\nrespect to \\(Y\\) to characterize what it is for \\(X\\) to cause \\(Y)\\).\nSuch an intervention \\(I\\) must meet the following requirements\n(M1–M4): \nThis characterization makes explicit reference to conditions that must\nbe satisfied by the intervention variable \\(I.\\) Although perhaps not\nmandatory, questions about what it means for such an \\(I\\) to be\npossible and how we are to understand the antecedents of the\nassociated interventionist counterfactuals (“If an intervention\nsatisfying\n (M1)–(M4)\n on \\(X\\) were to occur,…”) thus arise in a natural way\non this characterization—or at so I will assume in what follows.\n \nPutting aside these issues about possibility for the present, the most\nnatural way of defining the notion of causal effect in the framework\nassociated with\n (M1)–(M4)\n is in terms of the difference made to the value of \\(Y\\) by\na change or difference in the value of \\(X\\). (This is also\neffectively the definition of causal effect adopted in Rubin 1974. Focusing on differences in\nthis way allows us to isolate the contribution made to \\(Y\\) by \\(X\\)\nalone from the contribution made to \\(Y\\) by its other causes.\nMoreover, since in the non-linear case, the change in the value of\n\\(Y\\) caused by a given change in the value of \\(X\\) will depend on\nthe values of the other causes of \\(Y\\), it seems to follow that the\nnotion of causal effect must be relativized to a background context\n\\(B_i\\) which incorporates information about these other values. In\ndeterministic contexts, we might thus define the causal effect on\n\\(Y\\) of a change in the value of \\(X\\) from \\(X=x\\) to \\(X=x'\\) in\ncircumstances \\(B_i\\) as: \nthat is, as the difference between the value that \\(Y\\) would take\nunder an intervention that sets \\(X=x\\) in circumstances \\(B_i\\) and\nthe value that \\(Y\\) would take under an intervention that sets\n\\(X=x'\\) in \\(B_i\\), where the notion of an intervention is now\nunderstood in terms of\n (M1)–(M4) rather than in the way\n recommended by Pearl. In non-deterministic contexts, the\n characterization of causal effect is less straightforward, but one\n natural proposal is to define this notion in terms of expectations:\n If we let  \\(E P_{\\do x, B_{i}}(Y)\\) be the expectation of \\(Y\\) with\n respect to the probability distribution \\(P\\) if \\(X\\) is set to\n \\(X=x\\) by means of an intervention, then the causal effect on \\(Y\\)\n of a change in \\(X\\) from \\(X=x''\\) to \\(X=x\\) might be defined as:\n \\(E P_{\\do x, B_{i}}(Y) - E P_{\\do x', B_{i}}\n (Y)\\).  \nI will not attempt to adjudicate here among these and various other\nproposals concerning the best way to characterize the notions of\nintervention and causal effect. Instead, I want to comment on the\ngeneral strategy they embody and to compare it with the approach to\ncausation associated with theorists like Menzies and Price. Note first\nthat the notion of an intervention, when understood along either of\nthe lines described above, is an unambiguously causal notion in the\nsense that causal notions are required for its\ncharacterization—thus the proposals variously speak of an\nintervention on \\(X\\) as breaking the causal connection between \\(X\\)\nand its causes while leaving other causal mechanisms intact or as not\naffecting \\(Y\\) via a causal route that does not go through \\(X\\).\nThis has the immediate consequence that one cannot use the notion of\nan intervention to provide a reduction of causal claims to non-causal\nclaims. Moreover, to the extent that reliance on some notion like that\nof an intervention is unavoidable in any satisfactory version of a\nmanipulability theory (as I believe that it is), any such theory must\nbe non-reductionist. Indeed, we can now see that critics who have\ncharged manipulability theories with circularity have in one important\nsense understated their case: manipulability theories turn out to be\n“circular” not just in the obvious sense that for an\naction or event \\(I\\) to constitute an intervention on a variable\n\\(X\\), there must be a causal relationship between \\(I\\) and \\(X\\),\nbut in the sense that \\(I\\) must meet a number of other causal\nconditions as well. \nSuppose that we agree that any plausible version of a manipulability\ntheory must make use of the notion of an intervention and that this\nmust be characterized in causal terms. Does this sort of\n“circularity” make any such theory trivial and\nunilluminating? It is arguable that it does not, for at least two\nreasons. First, it may be, as writers like Woodward (2003) contend,\nthat in characterizing what it is for a process \\(I\\) to qualify as an\nintervention on \\(X\\) for the purposes of characterizing what it is\nfor \\(X\\) to cause \\(Y\\), we need not make use of information about\nthe causal relationship, if any, between \\(X\\) and \\(Y\\). Instead, it\nmay be that we need only to make use of other sorts of causal\ninformation, e.g., about the causal relationship between \\(I\\) and\n\\(Y\\) or about whether \\(I\\) is caused by causes that cause \\(Y\\)\nwithout causing \\(X\\), as in\n (M1)–(M4)\n above. To the extent that this is so, we may use one set of claims\nabout causal relationships (e.g., that \\(X\\) has been changed in a way\nthat meets the conditions for an intervention) together with\ncorrelational information (that \\(X\\) and \\(Y\\) remain correlated\nunder this change) to characterize what it is for a different\nrelationship (the relationship between \\(X\\) and \\(Y)\\) to be causal.\nThis does not yield a reduction of causal talk to non-causal talk, but\nit is also not viciously circular in the sense that it presupposes\nthat we already have causal information about the very relationship\nthat we are trying to characterize. One reason for thinking that there\nmust be some way of characterizing the notion of an\nintervention along the lines just described is that we do sometimes\nlearn about causal relationships by performing experiments—and\nit is not easy to see how this is possible if to characterize the\nnotion of an intervention on \\(X\\) we had to make reference to the\ncausal relationship between \\(X\\) and its effects. \nA related point is that even if manipulability accounts of causation\nare non-reductive, they can conflict with other accounts of\ncausation, leading to different causal judgments in particular cases.\nAs an illustration consider a simple version of manipulability account\nalong the lines of\n (CD),\n according to which a sufficient condition for \\(X\\) to cause (have a\ncausal effect on \\(Y)\\) is that some change in the value of \\(X\\)\nproduced by an intervention is associated with a change in the value\nof \\(Y\\) (in the background circumstances of interest). Such an\naccount implies that omissions (e.g., the failure of a gardener to\nwater a plant) can be causes (e.g., of the plant’s death) since\na change under an intervention in whether the gardener waters is\nassociated with a change in the value of the variable measuring\nwhether the plant dies. For a similar reason relationships involving\n“double prevention” (Hall 2000) or “causation by\ndisconnection” (Schaffer 2000) count as genuine causal\nrelationships on interventionist accounts. Consider, by contrast, the\nverdicts about these cases reached by a simple version of a causal\nprocess theory (in the sense of Salmon 1984, Dowe 2000) according\nto which a necessary condition for a particular instantiation \\(x\\) of\na value \\(X\\) to cause a particular instantiation \\(y\\) of a value\n\\(Y\\) is that there be a spatio-temporally continuous process\nconnecting \\(x\\) to \\(y\\) involving the transfer of energy, momentum\nor perhaps some other conserved quantity. According to such a theory,\n“causation” by omission or by double prevention does not\nqualify as genuine causation. Similarly, if an “action at a\ndistance” version of Newtonian gravitational theory had turned\nout to be correct, this would be a theory that described genuine\ncausal relationships according to interventionist accounts of\ncausation, but not according to causal process accounts. Whether one\nregards the verdicts about these cases reached by causal process\naccounts or by interventionist accounts as more defensible, the very\nfact that the accounts lead to inconsistent judgments shows that\ninterventionist approaches are not trivial or vacuous, despite their\n“circular”, non-reductive character. \nA second respect in which reliance on the notion of an intervention\nneed not be thought of as introducing a vicious circularity is this:\nSo far, I have been following Menzies and Price in assuming that there\nis just one causal notion or locution \\((A\\) causes \\(B\\), where \\(A\\)\nand \\(B\\) are types of events) that we are trying to analyze. But in\nfact there are many such notions. For example, among causal notions\nbelonging to the family of so-called type causal notions (i.e., causal\nclaims that relate types of events or variables) there is a\ndistinction to be drawn between what we might call claims about total\nor net causes and claims about direct causes. Even if the notion of an\nintervention presupposes some causal notion such as some notion of\ntype causation, it may be that we can use it to characterize other\ncausal notions. \nAs an illustration consider the causal structure represented by the\nfollowing equations and associated directed graph \nIn this structure, there are two different causal routes from \\(X\\) to\n\\(Y\\)—a direct causal relationship and an indirect relationship\nwith \\(Z\\) as an intermediate variable. If \\(a = {-bc}\\), there is\ncancellation along these two routes. This means that no intervention\non \\(X\\) will change the value of \\(Y\\). In one natural sense, this\nseems to mean that \\(X\\) does not cause \\(Y\\), assuming that (C*) a\nnecessary condition for \\(X\\) to cause \\(Y\\) is that some\ninterventions on \\(X\\) are associated with changes in the value of\n\\(Y,\\) as an obvious extension of CD seems to suggest. In another\nnatural sense, however, \\(X\\) does seem to be a cause—indeed a\ndirect cause—of \\(Y\\). We can resolve this apparent\ninconsistency by distinguishing between two kinds of causal claims\n(for a related distinction, see Hitchcock 2001b )—the claim \\(X\\) is a total\nor net cause of \\(Y\\), where this is captured by (C*) and the claim\nthat \\(X\\) is a direct cause of \\(Y\\), where this is understood along\nthe following lines: \\(X\\) is a direct cause of \\(Y\\) if and only if\nunder some intervention that changes the value of \\(X\\), the value of\n\\(Y\\) changes when all other variables in the system of interest\ndistinct from \\(X\\) and \\(Y\\) including those that are on some causal\nroute from \\(X\\) to \\(Y\\), are held fixed at some value, also by\ninterventions. (For related, but different, characterizations of\ndirect causation along these lines, see Pearl 2009 and Woodward 2003.)\nFixing the other values of other variables means that each of these\nvalues is determined by separate processes, each meeting the\nconditions for an intervention, that are appropriately independent of\neach other and of the intervention that changes the value of \\(X\\).\nThe effect of intervening to fix the values of these variables is thus\nthat each variable intervened on is disconnected from its causes,\nincluding \\(X\\). In the example under discussion, \\(X\\) qualifies as a\ndirect cause of \\(Y\\) because if we were to fix the value of \\(Z\\) in\na way that disconnects it from the value of \\(X\\), and then intervene\nto change the value of \\(X\\), the value of \\(Y\\) would change. This\nidea can then be generalized to provide a characterization of\n“contributing” causation along a causal route, i.e., to\ncapture the sense in which \\(X\\) is an indirect cause of \\(Y\\) along\nthe route that goes through \\(Z\\) (Woodward 2003). \nSo far our focus has been on type causal claims of various kinds.\nThere are also a number of proposals in the literature that provide\ninterventionist treatments of token or actual cause claims (these have\nto do with the event of \\(X\\)’s taking on a particular value\nbeing an actual cause of \\(Y\\)’s taking on a particular value,\nas when it is claimed that Jones’ smoking caused his lung\ncancer), including those that involve various forms of pre-emption and\nover-determination (e.g., Halpern and Pearl 2005 a, b; ; Hitchcock\n2001a; Woodward 2003; Hitchcock 2007a; Hall 2007; Glymour and Wimberly\n2007; Halpern and Hitchcock 2015; Halpern 2016; Weslake\nforthcoming). Considerations of space preclude detailed description,\nbut one strategy that has been explored is to appeal to what will\nhappen to the effect under combinations of interventions that\nboth affect the cause and that fix certain other variables to specific\nvalues. As an illustration, consider a standard case of causal\npre-emption: Gunman one shoots \\((s_1)\\) victim, causing his death\n\\(d\\), while gunman two does not shoot but would have shot \\((s_2)\\)\nalso causing \\(d\\), if \\(s_1\\) had not occurred.  If we fix (via an\nintervention) the behavior of the gunman two at its actual value (he\ndoes not shoot), then an independent intervention that alters whether\ngunman one shoots will alter whether victim dies, thus identifying\n\\(s_1\\) as the actual cause of \\(d\\), despite the absence of\ncounterfactual dependence (of the usual sort) between \\(d\\) and\n\\(s_1\\). Accounts along these lines are able to deal with a number\n(although admittedly not all; see Hitchcock 2007a for details) of the\nstandard counterexamples to other counterfactual treatments of token\ncausation. \nIt is worth adding that although this appeal to combinations of\ninterventions may seem artificial, it maps on to standard experimental\nprocedures in an intuitive way. Consider a case of genetic\nredundancy—gene complex \\(G_1\\) is involved in causing\nphenotypic trait \\(P\\) but if \\(G_1\\) is inactivated another gene\ncomplex \\(G_2\\) (which is inactive when \\(G_1\\) is active) will become\nactive and will cause \\(P\\). The geneticist may test for this\npossibility by, first, intervening on \\(G_2\\) so that it is fixed at\nthe value = inactive, then intervening to vary \\(G_1\\) and observing\nwhether there is a corresponding change in \\(P\\). Second, the\ninvestigator may intervene to render \\(G_1\\) inactive and then,\nindependently of this intervening to change \\(G_2\\) and observing\nwhether there is a change in \\(P\\). As this example illustrates, we\nmay think of different complex causal structures in which there are\nmultiple pathways, redundancy, cancellation and so on, as encoding\ndifferent sets of claims about what will happen under various possible\ncombinations of interventions. \nThus even if a “manipulationist” or\n“interventionist” framework does not yield a reduction of\ncausal talk to non-causal talk, it provides a natural way of marking\nthe distinctions among a number of different causal notions and\nexhibiting their interrelations. More generally, even if a\nmanipulationist account of causation does not yield a reduction but\ninstead simply connects “causation” (or better, various\nmore specific causal concepts) with other concepts within the same\ncircle, we still face many non-trivial choices about how the concepts\non this circle are to be elucidated and connected up with one another.\nFor example, it is far from obvious how to characterize the notion of\nan intervention so as to avoid the various counterexamples to standard\nstatements of the manipulability theory such as the theory of Menzies\nand Price. It is in part because the notion of\nmanipulation/intervention has an interesting and complex fine\nstructure—a structure that is left largely unexplored in\ntraditional manipulability theories-- that working out the connection\nbetween causation and manipulation turns out to be interesting and\nnon-trivial rather than banal and obvious. \nWe noted above that a free action need not meet the conditions for an\nintervention, on any of the conceptions of intervention described in\n §5.\n It is also true that a process or event can qualify as an\nintervention even if it does not involve human action or intention at\nany point. This should be apparent from the way in which the notion of\nan intervention has been characterized, for this is entirely in terms\nof causal and correlational concepts and makes no reference to human\nbeings or their activities. In other words, a purely\n“natural” process involving no animate beings at all can\nqualify as an intervention as long as it has the right sort of causal\nhistory—indeed, this sort of possibility is often described by\nscientists as a “natural experiment”. Moreover, even when\nmanipulations are carried out by human beings, it is the causal\nfeatures of those manipulations and not the fact that they are carried\nout by human beings or are free or are attended by a special\nexperience of agency that matters for recognizing and characterizing\ncausal relationships. Thus, by giving up any attempt at reduction and\ncharacterizing the notion of an intervention in causal terms, an\n“interventionist” approach of the sort described under\n §§4–5\n and\n 7\n avoids the second classical problem besetting manipulability\ntheories—that of anthropocentrism and commitment to a privileged\nstatus for human action. For example, under this approach \\(X\\) will\nqualify as a (total) cause of \\(Y\\) as long as it is true that for\nsome value of \\(X\\) that if \\(X\\) were to be changed to that value by\na process having the right sort of causal characteristics, the value\nof \\(Y\\) would change. Obviously, this claim can be true even if human\nbeings lack the power to manipulate \\(X\\) or even in a world in which\nhuman beings do not or could not exist. There is nothing in the\ninterventionist version of a manipulability theory that commits us to\nthe view that all causal claims are in some way dependent for their\ntruth on the existence of human beings or involve a\n“projection” on to the world of our experience of\nagency. \nWe noted above that interventionist versions of manipulability\ntheories are counterfactual theories. What is the relationship between\nsuch theories and more familiar versions of counterfactual theories\nsuch as the theory of David Lewis? Lewis’ theory is an account\nof what it is for one individual token event to cause another while,\nas explained above, versions of interventionist treatments are\navailable for different sorts of type causal claims as well as token\ncausal claims. But if we abstract away from this, there are both\nimportant similarities and important differences between the two\napproaches. As readers of Lewis will be aware, any counterfactual\ntheory must explain what we should envision as changed and what should\nbe held fixed when we evaluate a counterfactual the antecedent of\nwhich is not true of the actual world—within Lewis’\nframework, this is the issue of which worlds in which the antecedent\nof the counterfactual holds are “closest” or “most\nsimilar” to the actual world. Lewis’ answer to this\nquestion invokes a “similarity” ordering that ranks the\nimportance of various respects of resemblance between worlds in\nassessing overall similarity. (Lewis 1979). For example, avoiding\ndiverse, widespread violations of law is said to be the most important\nconsideration, preserving perfect match of particular fact over the\nlargest possible spatio-temporal region is next in importance and more\nimportant than avoiding small localized violations of law, and so on.\nAs is well-known the effect of this similarity ordering is, at least\nin most situations, to rule out so-called “back-tracking”\ncounterfactuals (e.g., the sort of counterfactual that is involved in\nreasoning that if the effect of some cause had not occurred, then the\ncause would not have occurred). When the antecedent of a\ncounterfactual is not true of the actual world, Lewis’\nsimilarity metric commonly leads us (at least in deterministic\ncontexts) to think of that antecedent as made true by a\n“small” miracle. \nThe notion of an intervention plays a somewhat (but only somewhat)\nsimilar role within manipulability theories of causation to\nLewis’ similarity ordering. Like Lewis’ ordering, the\ncharacterization of an intervention tells us what should be envisioned\nas changed and what should be held fixed when we evaluate the sorts of\ncounterfactuals that are relevant to elucidating causal claims. For\nexample, on Pearl’s understanding of an intervention, in\nevaluating an interventionist counterfactual like “If \\(X\\) were\nto be changed by an intervention to such and such a value, the value\nof \\(Y\\) would change”, we are to consider a situation in which\nthe previously existing causal relationship between \\(X\\) and its\ncauses is disrupted, but all other causal relationships in the system\nof interest are left unchanged. A moment’s thought will also\nshow that, as in Lewis’ account, both Pearl’s (in its\nsetting version) and the characterization of interventions in terms of\n M1–M4\n rule out backtracking counterfactuals—for example, in\nevaluating a counterfactual of the form “if an intervention were\nto occur that changes \\(E\\), (where \\(E\\) is an effect of \\(C)\\), then\n\\(C\\) would change”, Pearl holds that we should consider a\nsituation in which the relationship between \\(E\\) and its causes (in\nthis case, \\(C)\\) is disrupted, but all other causal relationships are\nleft unchanged, so that \\(C\\) still occurs, and the above\ncounterfactual is false, as it should be. Moreover, there is a clear\nsimilarity between Lewis’ idea that the appropriate\ncounterfactuals for analyzing causation are often counterfactuals the\nantecedents of which are made true by “miracles”, and the\nidea of an intervention as an exogenous change that disrupts the\nmechanism that was previously responsible for the cause event\nC—both of these notions function so as to provide \\(C\\)\nwith the kind of “independent causal history” that allows\nus to distinguish the effects (if any) of \\(C\\) on \\(E\\) from the\neffects of other “confounding” variables on \\(E\\). From\nthis perspective, one might think of an interventionist treatment of\ncausation as explaining why Lewis’ account, with its somewhat\nad hoc looking similarity ordering, works as well as it\ndoes—Lewis’ account works because his similarity ordering\npicks out roughly those relationships that are stable under\ninterventions and hence exploitable for purposes of manipulation and\ncontrol and, as a manipulability theory claims, it is just these\nrelationships that are causal. \nAs noted above, however, this is not to say that the two\napproaches are identical or always yield identical assessments of\nparticular causal and counterfactual claims. One central difference is\nthat Lewis’ account is reductionist in aspiration—the\nelements that go into his similarity metric (avoidance of big\nmiracles, perfect match of particular facts etc.) are (at least\nofficially) characterized in non-causal, non-modal terms. By contrast,\nas explained above, the notion of an intervention and the standards\nfor evaluating counterfactuals to which it gives rise are\ncharacterized in causal terms, so that the resulting account is\nnon-reductionist. \nThere are other differences as well, a number of which are explored in\nan important paper by Briggs (2012). We have already noted that strong\ncentering holds in Lewis’ semantics but not for counterfactuals\nwith an interventionist interpretation. In addition, the inference\nfrom (i) “if \\(p\\) or \\(q\\) were the case, \\(r\\) would be the\ncase” to (ii) “if \\(p\\) were the case, \\(r\\) would be the\ncase” is invalid within Lewis’ semantics but valid if\nthese counterfactuals are given an interventionist interpretation\n(Briggs 2012; Fine 2012). It is arguable that in each of these cases,\nthe assessments provided by the interventionist interpretation are\ncorrect, assuming that what we want to capture are those\ncounterfactuals that behave in a way that is appropriate for causal\ninterpretation. In addition, Woodward 2003 describes several specific\nexamples in which the two approaches diverge in their judgments about\nwhich causal relations are present and in which the interventionist\napproach seems more\n satisfactory.[3] \nIn the versions of a manipulability theory considered under\n §5ff\n above, causal claims are elucidated in terms of counterfactuals about\nwhat would happen under interventions. As we have seen, the notion of\nan intervention should be understood without reference to human\naction, and this permits formulation of a manipulability theory that\napplies to causal claims in situations in which manipulation by human\nbeings is not a practical possibility.  \nHowever, as already intimated, interesting questions arise about how\nfar this framework may be extended to other sorts of cases in which\ninterventions are not “possible”. These also illustrate\nsome additional differences between thinking of interventions as\nsetting or, alternatively, in terms of\n M1–M4\n and as possibility constrained. Consider the (presumably true) causal\nclaim\n (G): \nWithin Pearl’s framework and using the notion of a setting\nintervention, it might be argued that there is no problem with\ncapturing claims like (G), at least if we assume (as we did above)\nthat the relevant setting operation is always “possible”\nor legitimate: we just imagine the gravitational attraction of the\nmoon set to some different value via a setting intervention (we\ndon’t need to specify how this comes about—whether the\nmass of the moon or its distance from the earth etc. is different) and\nthen note (by applying Newtonian gravitational theory) that the motion\nof the tides would be\n different.[4] \nSuppose, by contrast, we require that interventions be\n“possible” in some more demanding sense (that is, we adopt\na notion of possibility constrained intervention) and we consider\ncounterfactuals of the form: “if an intervention meeting\n M1–M4\n were to occur that sets the gravitational attraction of the moon to a\ndifferent value, then…”. It may well be that there is no\nphysically possible process that will meet the conditions\n M1–M4\n for intervention on the moon’s position with respect to the\ntides—all possible processes that would alter the gravitational\nforce exerted by the moon may be insufficiently\n“surgical”. For example, it may very well be that any\npossible process that alters the position of the moon by altering the\nposition of some other massive object will have an independent impact\non the tides in violation of condition\n (M2)\n for an intervention. Woodward (2003) argues that nonetheless we have\na principled basis in Newtonian mechanics and gravitational theory\nthemselves for answering questions about what would happen if such a\nsurgical intervention were to occur and that this is enough to\nvindicate the causal claim\n (G).\n On this view of the matter, what is crucial is not whether the\nantecedent of the relevant counterfactual is nomologically or\nphysically possible but rather whether we are in possession of\nwell-grounded scientific theories and accompanying mathematics that\nallow us to reliably answer questions about what would happen under\nthe supposition of such antecedents. We count interventions as\n“possible” as long as this is the case. Such interventions\nshould be distinguished from interventions that are logically,\nconceptually or mathematically inconsistent or incoherent (see below\nfor additional illustrations).  \nOne context in which issues about the range of cases in which\ninterventionist account may be legitimately or fruitfully applied\nconcerns “cosmological” claims in which fundamental\nphysical theories are understood as applying to the whole universe.\nConsider the following claim \nOn an interventionist construal,\n (4)\n is unpacked as a claim to the effect that under some possible\nintervention that changes \\(S_t\\), there would be an associated change\nin \\(S_{t+d}\\). This raises the worry that it is unclear what would be\ninvolved in such an intervention (given that there is nothing in\naddition to \\(S_t\\) that might realize the intervention) and unclear\nhow to assess what would happen if it were to occur, given the\nstipulation that \\(S_t\\) is a specification of the entire state of the\nuniverse.  \nCommenting on an example like this, Pearl writes: \nIf you wish to include the whole universe in the model, causality\ndisappears because interventions disappear—the manipulator and\nthe manipulated lose their distinction. (2009: 419-20)   \nNote that here Pearl seems to invoke a notion of intervention that is\ndifferent from (and stronger than) a pure setting conception. After\nall, as Reutlinger (2012) notes, it is arguable that there is no\nproblem about imagining the state of the universe at \\(S_t\\) set to\nsome different value and then determining by reference to the laws\ngoverning its evolution what its state will be at \\(S_{t\n +1}\\).[5]\n Pearl’s remark seems to assume that the imagined intervention\nhas to meet some additional constraint beyond this (having to do in\nsome way with the possibility of realizing the intervention).\nPearl’s claim is controversial—it is discussed\nsympathetically by Hitchcock 2007b and Woodward 2007 and criticized by\nother writers such as Reutlinger 2012. \nWe will not try to resolve the issues surrounding this particular\nclaim of Pearl’s here, but there is a related and more general\nissue concerning the implications of interventionism for the status of\ncausal claims in physics, even outside of cosmological contexts, that\ndeserves discussion. Return to the contrast between explicating causal\nclaims by appealing to a pure setting notion of intervention and,\nalternatively, explicating them by reference to interventions that\nmeet some further non-trivial constraints regarding possibility, as\ndiscussed above. Consider cases in which there is a physical law\naccording to which there is counterfactual dependence between \\(Y\\)\nand \\(X\\) but interventions on \\(X\\) are in some appropriately\nrelevant sense impossible. A pure setting treatment may conclude that\nsuch relationships are causal while an account relying on a\npossibility constrained notion of intervention will not. \nTwo possible illustrations are discussed in Woodward (2016). The field\nequations of General Relativity describe a lawful or nomological\nrelationship between the stress energy tensor and the spacetime\nmetric. “Setting” the former to different values (by\nspecifying initial and boundary conditions) one may calculate the\nassociated different values of the latter. One may doubt, however,\nthat it is appropriate to think of the field equations as describing a\ncausal relationship between the stress-energy tensor and the\nmetric. It is arguable that a possibility constrained interventionist\naccount supports this judgment: specification of the stress energy\n\ntensor requires reference to the metric in such a way that\ninterventions on the former with respect to the latter will violate\nthe conditions\n M1–M4\n for an intervention. One might conclude on these grounds that\nalthough there is a relation of nomic dependence between the state of\nthe stress energy tensor and the metric, this relation is not causal.\nEmployment of a setting conception of intervention seems to realize\nthe opposite conclusion. \nAs a second example, the spins of the entangled particles in an\nEPR–type experiment are lawfully related by a conservation law.\nIt is arguable (cf. Skyrms 1984; Butterfield 1992) that many standard\nphilosophical theories, including regularity and Lewis-style\ncounterfactual theories treat this relationship as causal, and a\nsetting version of an interventionist theory seems to suggest a\nsimilar conclusion. By contrast, various no signaling theorems are\ncommonly interpreted as implying that it is impossible both to\nintervene on one of the separated spin settings and to use the\nrelationship between the two settings to manipulate the other setting.\nIn this case a possibility constrained version of interventionism can\njudge that no causal relationship is present. Although the matter is\ncontroversial among philosophers, most physicists agree with this\njudgment of non-causality. \nBoth of these examples illustrate different implications of setting\nand possibility constrained versions of interventionism in physics\ncontexts and how the latter framework requires more than just the\npresence of a nomically sufficient condition or law-based\ncounterfactual dependence for causation. More generally, if one\nthinks, as many philosophers of physics and some physicists do, that\ncausal concepts do not apply, at least in any straightforward way, to\nsome or many fundamental physics contexts, then it is arguably a\nconsideration in favor of a version of interventionism that imposes a\nnon-trivial possibility constraint that it might be used to support\nthis judgment. By contrast, a setting version of interventionism will\ntend to find causation in physics whenever there is nomic\ndependence. \nThere has been considerable discussion recently both about the extent\nto which fundamental physics is causal and about what interventionist\nframeworks imply about the status of causal claims in physics. A\nnumber of the essays in Price and Corry 2007 (Price 2007; Hitchcock\n2007b; Woodward 2007) express varying degrees of skepticism about the\napplicability of causal notions in portions of physics, in part on the\nbasis of interventionist considerations. By contrast, Frisch (2014)\nargues vigorously that many physical theories, at least in classical\nphysics, such as classical electromagnetism, make extensive use of\ncausal concepts and that the relevant notion of cause is captured by\nthe interventionist framework and associated technical ideas (such as\nstructural equations and directed graphs). He suggests that writers\nlike Price, Hitchcock, and Woodward underestimate the degree to which\ninterventionist ideas of causation are applicable to such contexts. Of\ncourse it is also possible, consistently, with the views of both\nFrisch and these other writers, that causal notions, understood along\npossibility constrained interventionist lines, are important in many\nareas of physics but that there are other physical theories that are\nnot fruitfully interpreted as making causal claims, whether understood\nalong interventionist or other lines. In any case, the question of the\nscope of interventionist theories and their implications for causal\nclaims in fundamental physics is an important and at present\nunresolved\n issue.[6] \nSeveral statisticians (e.g., Holland 1986; Rubin 1986), as well as\nsimilarly minded epidemiologists (e.g., Hernan and Taubman 2008) who advocate treatments of\ncausation in terms of manipulation-based ideas (in this case in terms\nof “potential outcome” theory) have held that causal\nclaims involving causes that are unmanipulable in principle are\ndefective or lack a clear meaning—they think of this conclusion\nas following directly from a manipulationist approach to causation.\nWhat is meant by an unmanipulable cause is not made very clear, but\nwhat these authors have in mind are not candidate causes that cannot\nbe manipulated as a practical matter, but rather candidates that are\nsuch that we lack any clear conception of what would be involved in\nmanipulating them or any basis for assessing what would happen under\nsuch manipulations—cases in which manipulation seems\n“impossible” for conceptual or (if you like)\n“metaphysical” reasons. Proposed examples include such\ncandidate causes as race, membership in a particular species, and\ngender. Other examples discussed in this connection involve cases in\nwhich there are many different things one might have in mind by\n“manipulation” of the candidate causes with different\nresults flowing from such manipulations so that the claims in question\nare taken, from a manipulationist or interventionist standpoint, to be\nunclear or ambiguous. All such cases contrast with the case involving\n (G)\n above, where the notion of manipulating the moon’s orbit seems\nperfectly clear and well-defined, and the problem is simply that the\nworld happens to be arranged in such a way that an intervention that\nproduces such a change is not physically possible. \nA sympathetic reconstruction of the position under discussion might go\nas follows. On an interventionist account of causation, causes\n(whether we think of them as events, types of events, properties,\nfacts, or what have you) must be representable by means of\nvariables—where this means, at a minimum, that it must\nbe possible for the cause to change or to assume different values, for\nwhatever object, unit or system those values are assigned to, as when\nit is possible for the same particle to be either at position \\(p_1\\)\nspecified by a position variable \\(P\\) or at some alternative position\n\\(p_2\\). This is required if we are to have a well-defined notion of\nmanipulating a candidate cause and well-defined answers to\ncounterfactual queries about what would happen if the cause were to be\nmanipulated in some way—matters which are central to what causal\nclaims mean on any version of a manipulability theory worthy of the\nname. However, for some putative causes, there may be no well-defined\nnotion of change or variation in value and if so, a manipulability\ntheory will not count these as genuine causes. Suppose, for example,\nwe lack any coherent conception of what it is for something to exist\nbut to be non-physical. Then there will be no well-defined notion of\nintervening to change whether something is or is not a physical object\nand being a physical object will not be a factor or property that can\nserve as a cause. (Of course it is consistent with this that there are\ntrue and perhaps even lawful generalizations about all physical\nobjects.). For example, although to the best of our knowledge, it is a\nlaw of nature that  \n(L) is not, according to this version of a manipulability theory, a\ncausal generalization: being a physical object is not a cause\nof the incapacity in question. \nMoreover, even with respect to variables that can take more than one\nvalue, the notion of an intervention or manipulation will not be\nwell-defined if there is no well-defined notion of changing\nthe values of that variable. Suppose that we introduce a variable\n“animal” which takes the values \\(\\{\\)lizard, kitten,\nraven\\(\\}\\). By construction, this variable has more than one value,\nbut if, as seems plausible, we have no coherent idea of what it is to\nchange a raven into lizard or kitten, there will be no well-defined\nnotion of an intervention for this variable and being an animal (or\nbeing a raven) will not be the sort of thing that can count as a\nbona fide cause on a manipulability theory. The notion of\nchanging the value of a variable seems to involve the idea of an\nalteration from one value of the variable to another in circumstances\nin which the very same system or entity can possess both values and\nthis notion seems inapplicable to the case under discussion. \nNote that, just as with some of the examples considered in\n §12,\n this conclusion does not seem to follow on the pure setting\ninterpretation of the interventionist account. One can, after all, set\nup an equation \\(Y = X\\) with a candidate variable \\(X\\), taking the\nvalues 0 and 1, according to whether some object is a kitten or lizard\nand a candidate effect variable \\(Y\\), taking the values 0 and 1\naccording to whether that object is warm-blooded or cold-blooded. Then\nsetting \\(X\\) to 0 rather than 1 changes whether \\(Y= 0\\) or 1, and if\nthis is sufficient for causation, being a kitten rather than a lizard\ncauses warmbloodiness rather than coldbloodiness. If one thinks, that\nthere is something defective or problematic about these causal claims,\nthis requires, within an interventionist framework, a richer\nconception of what is required for causation than what is suggested by\nthe setting conception of intervention. A similar point applies to the\nother examples described in this section.  \nSome readers will take it to be intuitively obvious that, e.g., being\na raven can be a cause of some particular organism’s being\nblack, that being a kitten can be a cause of warm-bloodiness and so\non. If causal claims like  \nare true, it will be an important advantage of a setting version of\ninterventionism over a formulation in terms of a possibility\nconstrained notion of intervention that the former but not the latter\nis able to capture claims like (R). By contrast, others will think\nthat claims like (R) are, if not false, at least unclear and\nunperspicuous, and that it is a point in favor of a possibility\nconstrained version of the interventionist account that it can capture\nthis. Those who take this second view will think that claims like (R)\nshould be replaced by claims that involve causes that are\nstraightforwardly manipulable. For example, (R) might be replaced by a\nclaim that identified the genetic factors and biochemical pathways\nthat are responsible for raven pigmentation—factors and pathways\nfor which there is a well-defined notion of manipulation and which are\nsuch that if they were appropriately manipulated, this would lead to\nchanges in pigmentation. Theorists like Rubin and Holland will think\nthat such a replacement would be clearer and more perspicuous than the\noriginal claim (R) Another illustration of this general idea that\nreplacing claims involving non-manipulable candidate causes with\nclaims involving candidate manipulable causes clarifies their meaning\nis discussed in\n The Role of the Manipulability Theory in Clarifying Causal Claims.\n  \nA number of other criticisms besides the classic charges of\nanthropomorphism and circularity have been advanced against\ninterventionist accounts. One complaint is that interventionist\naccounts (at least as I have formulated them) appeal to\ncounterfactuals and that counterfactuals cannot be (as it is often\nput) “barely true”: if a counterfactual is true, this must\nbe so in virtue of some “truth maker” which is not itself\nmodal or counterfactual. Standard candidates for such truth makers are\nfundamental laws of nature or perhaps fundamental physical/chemical\nprocesses or mechanisms. Often the further suggestion is made that we\ncan then explain the notion of causation in terms of such truth makers\nrather than along interventionist lines—for example, the notion\nof causation (as well as the truth conditions for counterfactuals)\nmight be explained in terms of laws (Hiddleston 2005). Thus appealing\nto interventionist counterfactuals is not necessary, once we take\naccount of the truth conditions of such counterfactuals. \nThese claims raise a number of issues that can be explored only\nbriefly. First, let us distinguish between providing an ordinary\nscientific explanation for why some counterfactual claim is true and\nproviding truth conditions (or identifying a truth maker) in the sense\ndescribed above, where these truth conditions are specified in\nnon-modal, non-counterfactual terms. The expectation that (i) whenever\nsome macro-level interventionist counterfactual is true, there will be\nsome more fundamental scientific explanation of why it is true seems\nplausible and well grounded in scientific practice. By contrast, the\nexpectation that (ii) for every true counterfactual there must be a\ntruth maker that can be characterized in non-modal, non-counterfactual\nterms is a metaphysical doctrine that requires some independent\nargument; it does not follow just from (i). Suppose that it is true\nthat  \nThen it is very plausible that there will be some explanation, which\nmay or may not be known at present, that explains why\n (5)\n is true in terms of more fundamental biochemical mechanisms or\nphysical/chemical laws and various initial and boundary conditions.\nWhat is less obviously correct is the further idea that we can\nelucidate these underlying mechanisms/laws without appealing to\ncounterfactuals. It is this further idea that is appealed to when it\nis claimed that it must be possible to describe a truth maker for a\ncounterfactual like\n (5)\n that does not itself appeal to counterfactual or modal claims. The\ncorrectness of this idea is not guaranteed merely by the existence of\nan explanation in the ordinary sense for why\n (5)\n is true; instead it seems to depend on whether a reductivist account\nof laws, mechanisms, etc. in terms of non-modal primitives can be\ngiven—a matter on which the jury is still\n out.[7] \nA different line of criticism has been advanced against\ninterventionist accounts in several recent papers by Nancy Cartwright\n(e.g., 2001, 2002). According to Cartwright such accounts are\n“operationalist”. Classical operationalism is often\ncriticized as singling out just one possible procedure for testing\nsome claim of interest and contending that the claim only makes sense\nor only has a truth value when that procedure can actually be carried\nout. Similarly, Cartwright complains that the interventionist account\n“overlooks the possibility of devising other methods for\nmeasuring” causal relationships and also suggests that the\naccount leads us to  \nwithhold the concept [of cause] from situations that seem the same in\nall other aspects relevant to its application just because our test\ncannot be applied in those situations. (2002: 422) \nIf interventionism is formulated as above, this criticism seems\nmisplaced. The interventionist account does not hold that causal\nconcepts apply or make sense only when the appropriate interventions\ncan actually be carried out. Nor does it deny that there are other\nways of testing causal claims besides carrying out interventions.\nInstead, interventionism holds that causal claims apply or have truth\nvalues whenever the appropriate counterfactuals concerning what would\nhappen if interventions were to be performed have truth values. As\nexplained above, interventionists think that sometimes such\ncounterfactuals are true even if the interventions in question cannot\nactually be performed. Similarly, interventionists can readily agree\nthat causal claims may be tested and confirmed by, for example, purely\nobservational data, not involving interventions or\nmanipulations—their view, though, is that what is confirmed in\nthis way is a claim about what would happen if certain interventions\nwere to be performed. In fact, thinking of causal claims in this way\nhelps to clarify why certain strategies for causal inference with\nobservational data, such as the use of instrumental variables, are\nmore likely to lead to reliable conclusions than alternatives\n(Woodward 2015).  \nIn a related criticism, Cartwright contends that the interventionist\naccount is “monolithic”: it takes just one of the criteria\ncommonly thought to be relevant to whether a relationship is\ncausal—whether it is potentially exploitable for purposes of\nmanipulation—and gives it a privileged or pre-eminent place,\nallowing it to trump other criteria (like spatio-temporal contiguity\nor transmission of energy-momentum), when it comes into conflict with\nthem. By contrast, Cartwright favors a “pluralistic”\naccount, according to which a variety of diverse criteria are relevant\nto whether a relationship is causal and which of these are most\nappropriate or important will depend on the causal claim at issue. \nThe interventionist account is indeed mono-criterial. Whether this\nfeature is objectionable depends on whether there are realistic cases\nin which (i) intervention-based criteria and criteria based on other\nconsiderations come into conflict and (ii) it is clear that\nthe causal judgments supported by these other criteria are more\ndefensible than those supported by interventionist criteria.\nCartwright does not present any uncontroversial cases of this kind. We\nhave seen that interventionist accounts and accounts that take, e.g.,\nspatio-temporal continuity to be crucial for causation do yield\nconflicting judgments in some realistic cases (e.g., those involving\ndouble prevention), but it is far from clear that the interventionist\naccount is mistaken in the judgments that it recommends about such\ncases. \nTwo still more recent criticisms directed against\n M1–M4\n and possibility constrained notions of interventionism are Reutlinger\n2012 and Glynn 2013. These are discussed in the supplementary document\n Additional Recent Criticisms of the Interventionist Account.\n  \nThe material above has largely focused on the use of interventionist\nor manipulability based ideas to provide an interpretation of causal\nclaims, with little attention paid to the use of these ideas in causal\ninference—that is, inference to causal relationships from\nexperimental and non-experimental data. The latter is an important\nsubject in its own right. Roughly speaking, if one thinks of causal\nclaims as claims about the outcomes of possible manipulations or\nexperiments, then this suggests distinctive ways of conceptualizing\nproblems of causal inference from non-experimental data: these may be\nconceptualized as problems of inferring from such data (and other\nassumptions) what the outcome of a possible experiment would be\nwithout doing the experiment in question. This point of view can used\nto motivate or rationalize the use of such procedures as instrumental\nvariables or regression discontinuity designs—see, e.g., Angrist\nand Pischke 2009 for econometric applications of these ideas.  \nAnother important extension of interventionist ideas, also with a\nfocus on inference but containing conceptual innovations as well is\ndue to Eberhardt (Eberhardt 2007, Eberhardt and Scheines 2007). \nThese authors generalize the notion of intervention in two ways.\nFirst, they consider interventions that do not deterministically fix\nthe value of variable(s) intervened on but rather merely impose a\nprobability distribution on those variables. Second, they explore the\nuse of what have come to be called “soft” interventions.\nThese are interventions that unlike the fully surgical\n(“hard”) interventions considered above (both\nPearl’s setting interventions and the notion associated with\n M1–M4),\n do not completely break the previously existing relationships between\nthe variable \\(X\\) intervened on and its causes \\(C\\) but rather\nsupply an exogenous source \\(I\\) of variation to \\(X\\) that leaves its\nrelations to \\(C\\) intact but where \\(I\\) is uncorrelated with \\(C\\).\nCertain experiments are naturally modeled in this way. For example, in\nan experiment in which subjects are randomly given various amounts of\nadditional income (besides whatever income they have from other\nsources) this additional income functions as a soft, rather than a\nhard intervention. Soft interventions may be possible in practice or\nin principle in certain situations in which hard interventions are\nnot. Eberhardt 2007 and Eberhardt and Scheines 2007 explore what can\nbe learned from various combinations of soft and hard, indeterministic\nand deterministic interventions together with non-experimental data in\nvarious contexts. Unsurprisingly each kind of intervention and\nassociated data have both advantages and limitations from the point of\nview of inference.","contact.mail":"jfw@pitt.edu","contact.domain":"pitt.edu"}]
