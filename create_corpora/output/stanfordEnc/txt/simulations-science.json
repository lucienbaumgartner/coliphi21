[{"date.published":"2013-05-06","date.changed":"2019-09-26","url":"https://plato.stanford.edu/entries/simulations-science/","author1":"Eric Winsberg","author1.info":"http://www.cas.usf.edu/~ewinsb/","entry":"simulations-science","body.text":"\n\n\n\nComputer simulation was pioneered as a scientific tool in meteorology\nand nuclear physics in the period directly following World War II, and\nsince then has become indispensable in a growing number of\ndisciplines. The list of sciences that make extensive use of computer\nsimulation has grown to include astrophysics, particle physics,\nmaterials science, engineering, fluid mechanics, climate science,\nevolutionary biology, ecology, economics, decision theory, medicine,\nsociology, epidemiology, and many others. There are even a few\ndisciplines, such as chaos theory and complexity theory, whose very\nexistence has emerged alongside the development of the computational\nmodels they study.\n\n\n\nAfter a slow start, philosophers of science have begun to devote\nmore attention to the role of computer simulation in\nscience. Several areas of philosophical interest in\ncomputer simulation have emerged: What is the structure of the\nepistemology of computer simulation? What is the relationship\nbetween computer simulation and experiment? Does computer\nsimulation raise issues for the philosophy of science that are not\nfully covered by recent work on models more generally? What does\ncomputer simulation teach us about emergence? About the structure\nof scientific theories? About the role (if any) of fictions in\nscientific modeling? \nNo single definition of computer simulation is appropriate. In the\nfirst place, the term is used in both a narrow and a broad sense. In\nthe second place, one might want to understand the term from more than\none point of view.  \n\nIn its narrowest sense, a computer simulation is a program that is\nrun on a computer and that uses step-by-step methods to explore\nthe approximate behavior of a mathematical model. Usually this is\na model of a real-world system (although the system in question might\nbe an imaginary or hypothetical one). Such a computer program is\na computer simulation model. One run of the\nprogram on the computer is a computer simulation of the system. The\nalgorithm takes as its input a specification of the system’s\nstate (the value of all of its variables) at some time t. \nIt then calculates the system’s state at time t+1. \nFrom the values characterizing that second state, it then calculates\nthe system’s state at time t+2, and so on. When\nrun on a computer, the algorithm thus produces a numerical picture of\nthe evolution of the system’s state, as it is conceptualized in\nthe model.  \n\nThis sequence of values for the model variables can be saved as a\nlarge collection of “data” and is often viewed on a\ncomputer screen using methods of visualization. Often, but\ncertainly not always, the methods of visualization are designed to\nmimic the output of some scientific instrument—so that the\nsimulation appears to be measuring a system of interest. \n\nSometimes the step-by-step methods of computer simulation are used\nbecause the model of interest contains continuous (differential)\nequations (which specify continuous rates of change in time) that\ncannot be solved analytically—either in principle or perhaps only in\npractice. This underwrites the spirit of the following\ndefinition given by Paul Humphreys: “any computer-implemented method\nfor exploring the properties of mathematical models where analytic\nmethods are not available” (1991, 500). But even as a narrow\ndefinition, this one should be read carefully, and not be taken to\nsuggest that simulations are only used when there are analytically\nunsolvable equations in the model. Computer simulations are often\nused either because the original model itself contains discrete\nequations—which can be directly implemented in an algorithm suitable\nfor simulation—or because the original model consists of something\nbetter described as rules of evolution than as\nequations. \n\nIn the former case, when equations are being\n“discretized” (the turning of equations that describe\ncontinuous rates of change into discrete equations), it should be\nemphasized that, although it is common to speak of simulations\n“solving” those equations, a discretization can at best\nonly find something which approximates the solution of continuous\nequations, to some desired degree of accuracy. Finally,\nwhen speaking of “a computer simulation” in the narrowest\nsense, we should be speaking of a particular implementation of the\nalgorithm on a particular digital computer, written in a particular\nlanguage, using a particular compiler, etc. There are cases in\nwhich different results can be obtained as a result of variations in\nany of these particulars. \n\nMore broadly, we can think of computer simulation as a comprehensive\nmethod for studying systems. In this broader sense of the term, it\nrefers to an entire process. This process includes choosing\na model; finding a way of implementing that model in a form that can be\nrun on a computer; calculating the output of the algorithm; and\nvisualizing and studying the resultant data. The method includes\nthis entire process—used to make inferences about the target\nsystem that one tries to model—as well as the procedures used to\nsanction those inferences. This is more or less the definition of\ncomputer simulation studies in Winsberg 2003 (111).\n“Successful simulation studies do more than compute numbers. They\nmake use of a variety of techniques to draw inferences from these\nnumbers. Simulations make creative use of calculational\ntechniques that can only be motivated extra-mathematically and\nextra-theoretically. As such, unlike simple computations that can be\ncarried out on a computer, the results of simulations are not\nautomatically reliable. Much effort and expertise goes into deciding\nwhich simulation results are reliable and which are not.” \nWhen philosophers of science write about computer simulation, and make\nclaims about what epistemological or methodological properties\n“computer simulations” have, they usually mean the term to\nbe understood in this broad sense of a computer simulation\nstudy.  \n\nBoth of the above definitions take computer simulation to be\nfundamentally about using a computer to solve, or to approximately\nsolve, the mathematical equations of a model that is meant to represent\nsome system—either real or hypothetical. Another approach\nis to try to define “simulation” independently of the\nnotion of computer simulation, and then to define “computer\nsimulation” compositionally: as a simulation that is carried out\nby a programmed digital computer. On this approach, a simulation is any\nsystem that is believed, or hoped, to have dynamical behavior that is\nsimilar enough to some other system such that the former can be studied\nto learn about the latter.   \n\nFor example, if we study some object because we believe it is\nsufficiently dynamically similar to a basin of fluid for us to learn\nabout basins of fluid by studying the it, then it provides a\nsimulation of basins of fluid. This is in line with the definition of\nsimulation we find in Hartmann: it is something that “imitates\none process by another process. In this definition the term\n‘process’ refers solely to some object or system whose\nstate changes in time” (1996, 83).  Hughes (1999) objected that\nHartmann’s definition ruled out simulations that imitate a system’s\nstructure rather than its dynamics. Humphreys revised his definition\nof simulation to accord with the remarks of Hartmann and Hughes as\nfollows: \n\n(Note that Humphreys is here defining computer simulation, not\nsimulation generally, but he is doing it in the spirit of defining a\ncompositional term.) It should be noted that Humphreys’ definitions\nmake simulation out to be a success term, and that seems\nunfortunate. A better definition would be one that, like the one in\nthe last section, included a word like “believed” or\n“hoped” to address this issue. \n\nIn most philosophical discussions of computer simulation, the more\nuseful concept is the one defined in 1.2. The exception is when it is\nexplicitly the goal of the discussion to understand computer\nsimulation as an example of simulation more generally (see section\n5). Examples of simulations that are not computer simulations include\nthe famous physical model of the San Francisco Bay (Huggins &\nSchultz 1973).  This is a working hydraulic scale model of the San\nFrancisco Bay and Sacramento-San Joaquin River Delta System built in\nthe 1950s by the Army Corps of engineers to study possible engineering\ninterventions in the Bay. Another nice example, which is discussed\nextensively in (Dardashti et al., 2015, 2019) is the use of acoustic\n“dumb holes” made out of Bose-Einstein condensates to\nstudy the behavior of Black Holes. Physicist Bill Unruh noted that in\ncertain fluids, something akin to a black hole would arise if there\nwere regions of the fluid that were moving so fast that waves would\nhave to move faster than the speed of sound (something they cannot do)\nin order to escape from them (Unruh 1981). Such regions would in\neffect have sonic event horizons. Unruh called such a physical setup a\n“dumb hole” (“dumb” as in “mute”)\nand proposed that it could be studied in order to learn things we do\nnot know about black holes. For some time, this proposal was viewed as\nnothing more than a clever idea, but physicists have recently come to\nrealize that, using Bose-Einstein condensates, they can actually build\nand study dumb holes in the laboratory. It is clear why we should\nthink of such a setup as a simulation: the dumb hole simulates the\nblack hole. Instead of finding a computer program to simulate the\nblack holes, physicists find a fluid dynamical setup for which they\nbelieve they have a good model and for which that model has\nfundamental mathematical similarities to the model of the systems of\ninterest. They observe the behavior of the fluid setup in the\nlaboratory in order to make inferences about the black holes. The\npoint, then, of the definitions of simulation in this section is to\ntry to understand in what sense computer simulation and these sorts of\nactivities are species of the same genus. We might then be in a better\nsituation to understand why a simulation in the sense of 1.3 which\nhappens to be run on a computer overlaps with a simulation in the\nsense of 1.2. We will come back to this in section 5. \n\nBarberousse et al. (2009), however, have been critical of this\nanalogy. They point out that computer simulations do not\nwork the way Unruh’s simulation works. It is not the case that the\ncomputer as a material object and the target system follow the same\ndifferential equations. A  good reference about\nsimulations that are not computer simulations is Trenholme 1994. Two types of computer simulation are often\ndistinguished: equation-based simulations\nand agent-based (or\nindividual-based) simulations. Computer\nSimulations of both types are used for three different general sorts of\npurposes: prediction (both pointwise and global/qualitative),\nunderstanding, and exploratory or heuristic purposes. \n\nEquation-based simulations are most commonly used in the physical\nsciences and other sciences where there is governing theory that can\nguide the construction of mathematical models based on differential\nequations. I use the term “equation based” here\nto refer to simulations based on the kinds of global equations we\nassociate with physical theories—as opposed to “rules of\nevolution” (which are discussed in the next section.) Equation\nbased simulations can either be particle-based, where there are n many\ndiscrete bodies and a set of differential equations governing their\ninteraction, or they can be field-based, where there is a set of\nequations governing the time evolution of a continuous medium or\nfield. An example of the former is a simulation of galaxy\nformation, in which the gravitational interaction between a finite\ncollection of discrete bodies is discretized in time and space. \nAn example of the latter is the simulation of a fluid, such as a\nmeteorological system like a severe storm. Here the system is\ntreated as a continuous medium—a fluid—and a field representing its\ndistribution of the relevant variables in space is discretized in space\nand then updated in discrete intervals of time. \n\nAgent-based simulations are most common in the social and behavioral\nsciences, though we also find them in such disciplines as artificial\nlife, epidemiology, ecology, and any discipline in which the networked\ninteraction of many individuals is being studied. \nAgent-based simulations are similar to particle-based simulations in\nthat they represent the behavior of n-many discrete individuals. \nBut unlike equation-particle-based simulations, there are no global\ndifferential equations that govern the motions of the\nindividuals. Rather, in agent-based simulations, the behavior of\nthe individuals is dictated by their own local rules \n\nTo give one example: a famous and groundbreaking agent-based\nsimulation was Thomas Schelling’s (1971) model of\n“segregation.” The agents in his simulation\nwere individuals who “lived” on a chessboard. \nThe individuals were divided into two groups in the society (e.g. two\ndifferent races, boys and girls, smokers and non-smokers, etc.) \nEach square on the board represented a house, with at most one person\nper house. An individual is happy if he/she has a certain percent\nof neighbors of his/her own group. Happy agents stay where they are,\nunhappy agents move to free locations. Schelling found that the board\nquickly evolved into a strongly segregated location pattern if the\nagents’ “happiness rules” were specified so that\nsegregation was heavily favored. Surprisingly, however, he also found\nthat initially integrated boards tipped into full segregation even if\nthe agents’ happiness rules expressed only a mild preference for having\nneighbors of their own type. \n\nIn section 2.1 we discussed equation-based models that are based on\nparticle methods and those that are based on field methods. \nBut some simulation models are hybrids of different kinds of modeling\nmethods. Multiscale simulation models, in particular,\ncouple together modeling elements from different scales of\ndescription. A good example of this would be a model that\nsimulates the dynamics of bulk matter by treating the material as a\nfield undergoing stress and strain at a relatively coarse level of\ndescription, but which zooms into particular regions of the material\nwhere important small scale effects are taking place, and models those\nsmaller regions with relatively more fine-grained modeling methods.\nSuch methods might rely on molecular dynamics, or quantum mechanics, or\nboth—each of which is a more fine-grained description of matter\nthan is offered by treating the material as a field. Multiscale\nsimulation methods can be further broken down into serial multiscale\nand parallel multiscale methods. The more traditional\nmethod is serial multi-scale modeling. The idea here is to\nchoose a region, simulate it at the lower level of description,\nsummarize the results into a set of parameters digestible by the higher\nlevel model, and pass them up to into the part of the algorithm\ncalculating at the higher level. \n\nSerial multiscale methods are not effective when the different scales\nare strongly coupled together. When the different scales interact\nstrongly to produce the observed behavior, what is required is an\napproach that simulates each region simultaneously. This is called\nparallel multiscale modeling. Parallel multiscale modeling is the\nfoundation of a nearly ubiquitous simulation method: so called\n“sub-grid” modeling. Sub-grid modeling refers to the\nrepresentation of important small-scale physical processes that occur\nat length-scales that cannot be adequately resolved on the grid size\nof a particular simulation. (Remember that many simulations discretize\ncontinuous equations, so they have a relatively arbitrary finite\n“grid size.”) In the study of turbulence in fluids, for\nexample, a common practical strategy for calculation is to account for\nthe missing small-scale vortices (or eddies) that\nfall inside the grid cells. This is done by adding to the large-scale\nmotion an eddy viscosity that characterizes the transport and\ndissipation of energy in the smaller-scale flow—or any such\nfeature that occurs at too small a scale to be captured by the\ngrid. \n\nIn climate science and kindred disciplines, sub-grid modeling is\ncalled “parameterization.” This, again, refers to the\nmethod of replacing processes—ones that are too small-scale or\ncomplex to be physically represented in the model— by a more\nsimple mathematical description. This is as opposed to other\nprocesses—e.g., large-scale flow of the atmosphere—that are\ncalculated at the grid level in accordance with the basic theory. It is\ncalled “parameterization” because various non-physical\nparameters are needed to drive the highly approximative\nalgorithms that compute the sub-grid values. Examples of\nparameterization in climate simulations include the descent rate of\nraindrops, the rate of atmospheric radiative transfer, and the rate of\ncloud formation. For example, the average cloudiness over a 100\nkm2 grid box is not cleanly related to the average humidity\nover the box. Nonetheless, as the average humidity increases, average\ncloudiness will also increase—hence there could be a parameter linking\naverage cloudiness to average humidity inside a grid box. Even\nthough modern-day parameterizations of cloud formation are more\nsophisticated than this, the basic idea is well illustrated by the\nexample. The use of\nsub-grid modeling methods in simulation has important consequences for\nunderstanding the structure of the epistemology of\nsimulation. This will be discussed in greater detail in\nsection 4. \n\nSub-grid modelling methods can be contrasted with another kind of\nparallel multiscale model where the sub-grid algorithms are more\ntheoretically principled, but are motivated by a theory at a different\nlevel of description. In the example of the simulation of bulk matter\nmentioned above, for example, the algorithm driving the smaller level\nof description is not built by the seat-of-the-pants. The algorithm\ndriving the smaller level is actually more theoretically principled\nthan the higher level in the sense that the physics is more\nfundamental: quantum mechanics or molecular dynamics vs. continuum\nmechanics. These kinds of multiscale models, in other words, cobble\ntogether the resources of theories at different levels of\ndescription. So they provide for interesting examples that\nprovoke our thinking about intertheoretic relationships, and that\nchallenge the widely-held view that an inconsistent set of laws can\nhave no models.  \n\nIn the scientific literature, there is another large class of\ncomputer simulations called Monte Carlo (MC) Simulations. MC\nsimulations are computer algorithms that use randomness to calculate\nthe properties of a mathematical model and where the randomness of the\nalgorithm is not a feature of the target model. A nice\nexample is the use of a random algorithm to calculate the value\nof π.  If you draw a unit square on a piece of\npaper and inscribe a circle in it, and then randomly drop a collection\nof objects inside the square, the proportion of objects that land in\nthe circle would be roughly equal to π/4. A\ncomputer simulation that simulated a procedure like that would be\ncalled a MC simulation for calculating π.  \n\nMany philosophers of science have deviated from ordinary scientific\nlanguage here and have shied away from thinking of MC simulations as\ngenuine simulations. Grüne-Yanoff and Weirich (2010) offer the\nfollowing reasoning: “The Monte Carlo approach does not have a\nmimetic purpose: It imitates the deterministic system not in order to\nserve as a surrogate that is investigated in its stead but only in\norder to offer an alternative computation of the deterministic\nsystem’s properties” (p.30). This shows that MC\nsimulations do not fit any of the above definitions aptly. On the\nother hand, the divide between philosophers and ordinary language can\nperhaps be squared by noting that MC simulations simulate an imaginary\nprocess that might be used for calculating something relevant to\nstudying some other process. Suppose I am modeling a planetary orbit\nand for my calculation I need to know the value of π. If I do the\nMC simulation mentioned in the last paragraph, I am simulating the\nprocess of randomly dropping objects into a square, but what I am\nmodeling is a planetary orbit. This is the sense in which MC\nsimulations are simulations, but they are not\nsimulations of the systems they are being used to study.\nHowever, as Beisbart and Norton (2012) point\nout, some MC simulations (viz. those that use MC techniques to solve\nstochastic dynamical equations referring to a physical system) are in\nfact simulations of the systems they study.  \n\nThere are three general categories of purposes to which computer\nsimulations can be put. Simulations can be used for\nheuristic purposes, for the purpose of predicting data that we do not\nhave, and for generating understanding of data that we do already\nhave. \n\nUnder the category of heuristic models, simulations can be further\nsubdivided into those used to communicate knowledge to others, and\nthose used to represent information to ourselves. When Watson and Crick\nplayed with tin plates and wire, they were doing the latter at first,\nand the former when they showed the results to others. When the army\ncorps built the model of the San Francisco Bay to convince the voting\npopulation that a particular intervention was dangerous, they were\nusing it for this kind of heuristic purpose. Computer simulations can\nbe used for both of these kinds of purposes—to explore features of\npossible representational structures; or to communicate knowledge to\nothers. For example: computer simulations of natural processes, such as\nbacterial reproduction, tectonic shifting, chemical reactions, and\nevolution have all been used in classroom settings to help students\nvisualize hidden structure in phenomena and processes that are\nimpractical, impossible, or costly to illustrate in a “wet”\nlaboratory setting. \n\nAnother broad class of purposes to which computer simulations can be\nput is in telling us about how we should expect some system in the\nreal world to behave under a particular set of circumstances. Loosely\nspeaking: computer simulation can be used for prediction. We can use\nmodels to predict the future, or to retrodict the past; we can use\nthem to make precise predictions or loose and general ones. With\nregard to the relative precision of the predictions we make with\nsimulations, we can be slightly more fine-grained in our\ntaxonomy. There are a) Point predictions: Where will the planet Mars\nbe on October 21st, 2300? b) “Qualitative” or global or\nsystemic predictions: Is the orbit of this planet stable? What scaling\nlaw emerges in these kinds of systems? What is the fractal dimension\nof the attractor for systems of this kind? and c) Range predictions:\nIt is 66% likely that the global mean surface temperature will\nincrease by between 2–5 degrees C by the year 2100; it is\n“highly likely” that sea level will rise by at least two\nfeet; it is “implausible” that the thermohaline will shut\ndown in the next 50 years. \n\nFinally, simulations can be used to understand systems and their\nbehavior. If we already have data telling us how some system\nbehaves, we can use computer simulation to answer questions about how\nthese events could possibly have occurred; or about how those events\nactually did occur. \n\nWhen thinking about the topic of the next section, the epistemology\nof computer simulations, we should also keep in mind that the\nprocedures needed to sanction the results of simulations will often\ndepend, in large part, on which of the above kind of purpose or\npurposes the simulation will be put to. \n\nAs computer simulation methods have gained importance in more and\nmore disciplines, the issue of their trustworthiness for generating new\nknowledge has grown, especially when simulations are expected to be\ncounted as epistemic peers with experiments and traditional analytic\ntheoretical methods. The relevant question is always whether or not the\nresults of a particular computer simulation are accurate enough for\ntheir intended purpose. If a simulation is being used to\nforecast weather, does it predict the variables we are\ninterested in to a degree of accuracy that is sufficient to meet the\nneeds of its consumers? If a simulation of the atmosphere above a\nMidwestern plain is being used to understand the structure of\na severe thunderstorm, do we have confidence that the structures in the\nflow—the ones that will play an explanatory role in our account of why\nthe storm sometimes splits in two, or why it sometimes forms\ntornados—are being depicted accurately enough to support our\nconfidence in the explanation? If a simulation is being used in\nengineering and design, are the predictions made by the simulation\nreliable enough to sanction a particular choice of design parameters,\nor to sanction our belief that a particular design of airplane wing\nwill function? Assuming that the answer to these questions is sometimes\n“yes”, i.e. that these kinds of inferences are at least\nsometimes justified, the central philosophical question is: what\njustifies them? More generally, how can the claim that a simulation is\ngood enough for its intended purpose be evaluated? These are the\ncentral questions of the epistemology of computer simulation\n(EOCS). \n\nGiven that confirmation theory is one of the traditional\ntopics in philosophy of science, it might seem obvious that the\nlatter would have the resources to begin to approach these questions.\nWinsberg (1999), however, argued that when it comes to topics related\nto the credentialing of knowledge claims, philosophy of science has\ntraditionally concerned itself with the justification of theories, not\ntheir application. Most simulation, on the other hand, to the extent\nthat it makes use of the theory, tends to make use of the\nwell-established theory. EOCS, in other words, is rarely about testing\nthe basic theories that may go into the simulation, and most often\nabout establishing the credibility of the hypotheses that are, in part,\nthe result of applications of those theories. \n\nWinsberg (2001) argued that, unlike the epistemological issues that\ntake center stage in traditional confirmation theory, an adequate EOCS\nmust meet three conditions. In particular it must take account of\nthe fact that the knowledge produced by computer simulations is the\nresult of inferences that are downward, motley, and\nautonomous. Downward. EOCS must reflect the fact that in a large\nnumber of cases, accepted scientific theories are the starting point\nfor the construction of computer simulation models and play an\nimportant role in the justification of inferences from simulation\nresults to conclusions about real-world target systems. The\nword “downward” was meant to signal the fact that, unlike\nmost scientific inferences that have traditionally interested\nphilosophers, which move up from observation instances to\ntheories, here we have inferences that are drawn (in part) from\nhigh theory, down to particular features of phenomena. \nMotley. EOCS must take into account that simulation results\nnevertheless typically depend not just on theory but on many other\nmodel ingredients and resources as well, including parameterizations\n(discussed above), numerical solution methods, mathematical tricks,\napproximations and idealizations, outright fictions, ad hoc\nassumptions, function libraries, compilers and computer hardware, and\nperhaps most importantly, the blood, sweat, and tears of much trial and\nerror. \nAutonomous. EOCS must take into account the autonomy\nof the knowledge produced by simulation in the sense that the knowledge\nproduced by simulation cannot be sanctioned entirely by comparison with\nobservation. Simulations are usually employed to study phenomena where\ndata are sparse. In these circumstances, simulations are meant to\nreplace experiments and observations as sources of data about the world\nbecause the relevant experiments or observations are out of reach,\nfor principled, practical, or ethical reasons. \n\nParker (2013) has made the point that the usefulness of\nthese conditions is somewhat compromised by the fact that it is overly\nfocused on simulation in the physical sciences, and other disciplines\nwhere simulation is theory-driven and equation-based. This seems\ncorrect. In the social and behavioral sciences, and other\ndisciplines where agent-based simulation (see 2.2) are more the\nnorm, and where models are built in the absence of established and\nquantitative theories, EOCS probably ought to be characterized in other\nterms. \n\nFor instance, some social scientists who use agent-based simulation\npursue a methodology in which social phenomena (for example an\nobserved pattern like segregation) are explained, or accounted for, by\ngenerating similar looking phenomena in their simulations (Epstein and\nAxtell 1996; Epstein 1999). But this raises its own sorts of\nepistemological questions. What exactly has been accomplished, what\nkind of knowledge has been acquired, when an observed social\nphenomenon is more or less reproduced by an agent-based simulation?\nDoes this count as an explanation of the phenomenon?  A possible\nexplanation? (see e.g., Grüne-Yanoff 2007).  Giuseppe Primiero\n(2019) argues that there is a whole domain of “artificial\nsciences” built around agent-based and multi-agent system based\nsimulations, and that it requires its own epistemology--one where\nvalidation cannot be defined by comparison with an existing real-world\nsystem, but must be defined vis a vis an intended system. \n\nIt is also fair to say, as Parker does (2013), that the\nconditions outlined above pay insufficient attention to the various and\ndiffering purposes for which simulations are used (as discussed in\n2.4). If we are using a simulation to make detailed\nquantitative predictions about the future behavior of a target system,\nthe epistemology of such inferences might require more stringent\nstandards than those that are involved when the inferences being made\nare about the general, qualitative behavior of a whole class of\nsystems. Indeed, it is also fair to say that much more work could\nbe done in classifying the kinds of purposes to which computer\nsimulations are put and the constraints those purposes place on the\nstructure of their epistemology. \n\nFrigg and Reiss (2009) argued that none of these three conditions\nare new to computer simulation. They argued that ordinary\n‘paper and pencil’ modeling incorporate these\nfeatures. Indeed, they argued that computer simulation could not\npossibly raise new epistemological issues because the epistemological\nissues could be cleanly divided into the question of the\nappropriateness of the model underlying the simulation, which is an\nissue that is identical to the epistemological issues that arise in\nordinary modeling, and the question of the correctness of the solution\nto the model equations delivered by the simulation, which is a\nmathematical question, and not one related to the epistemology of\nscience. On the first point, Winsberg (2009b) replied that\nit was the simultaneous confluence of all three features that was new\nto simulation. We will return to the second point in section\n4.3 \n\nSome of the work on the EOCS has developed analogies between\ncomputer simulation in order to draw on recent work in the epistemology\nof experiment, particularly the work of Allan Franklin;\nsee the entry on \n experiments in physics. \n\nIn his work on the epistemology of experiment, Franklin (1986,\n1989) identified a number of strategies that experimenters use to\nincrease rational confidence in their results. Weissart (1997) \nand Parker (2008a) argued for various forms of analogy between these\nstrategies and a number of strategies available to simulationists to\nsanction their results. The most detailed analysis of these\nrelationships is to be found in Parker 2008a, where she also uses\nthese analogies to highlight weaknesses in current approaches to\nsimulation model evaluation. \n\nWinsberg (2003) also makes use of Ian Hacking’s (1983, 1988,\n1992) work on the philosophy of experiment. One of Hacking’s\ncentral insights about experiment is captured in his slogan that\nexperiments have a life of their own’ (1992: 306). Hacking\nintended to convey two things with this slogan. The first was a\nreaction against the unstable picture of science that comes, for\nexample, from Kuhn. Hacking (1992) suggests that experimental results\ncan remain stable even in the face of dramatic changes in the other\nparts of sciences. The second, related, point he intended to\nconvey was that ‘experiments are organic, develop, change, and\nyet retain a certain long-term development which makes us talk about\nrepeating and replicating experiments’ (1992: 307). Some of the\ntechniques that simulationists use to construct their models get\ncredentialed in much the same way that Hacking says that instruments\nand experimental procedures and methods do; the credentials develop\nover an extended period of time and become deeply tradition-bound. In\nHacking’s language, the techniques and sets of assumptions that\nsimulationists use become ‘self-vindicating’. Perhaps a\nbetter expression would be that they carry their own credentials. This\nprovides a response to the problem posed in 4.1, of understanding how\nsimulation could have a viable epistemology despite the motley and\nautonomous nature of its inferences. \n\nDrawing inspiration from another philosopher of experiment (Mayo\n1996), Parker (2008b) suggests a remedy to some of the shortcomings in\ncurrent approaches to simulation model evaluation. In this work,\nParker suggests that Mayo’s error-statistical approach for\nunderstanding the traditional experiment—which makes use of the\nnotion of a “severe test”—could shed light on the\nepistemology of simulation. The central question of the epistemology\nof simulation from an error-statistical perspective becomes,\n‘What warrants our taking a computer simulation to be a severe\ntest of some hypothesis about the natural world? That is, what\nwarrants our concluding that the simulation would be unlikely to give\nthe results that it in fact gave, if the hypothesis of interest were\nfalse (2008b, 380)?  Parker believes that too much of what passes for\nsimulation model evaluation lacks rigor and structure because it: \n\nDrawing explicitly upon Mayo’s (1996) work, she argues that\nwhat the epistemology of simulation ought to be doing, instead, is\noffering some account of the ‘canonical errors’ that can\narise, as well as strategies for probing for their presence. \n\nPractitioners of simulation, particularly in engineering contexts,\nin weapons testing, and in climate science, tend to conceptualize\nthe EOCS in terms of verification and validation. \nVerification is said to be the process of determining whether\nthe output of the simulation approximates the true solutions to the\ndifferential equations of the original model. Validation, on\nthe other hand, is said to be the process of determining whether the\nchosen model is a good enough representation of the real-world system\nfor the purpose of the simulation. The literature on verification and\nvalidation from engineers and scientists is enormous and it is\nbeginning to receive some attention from philosophers. \n\nVerification can be divided into solution verification and code\nverification. The former verifies that the output of the intended\nalgorithm approximates the true solutions to the differential\nequations of the original model. The latter verifies that the\ncode, as written, carries out the intended algorithm. Code\nverification has been mostly ignored by philosophers of science;\nprobably because it has been seen as more of a problem in computer\nscience than in empirical science—perhaps a mistake. Part of solution\nverification consists in comparing computed output with analytic\nsolutions (so called “benchmark solutions”). \nThough this method can of course help to make case for the results of a\ncomputer simulation, it is by itself inadequate, since\nsimulations are often used precisely because analytic solution is\nunavailable for regions of solution space that are of interest. Other\nindirect techniques are available: the most important of which is\nprobably checking to see whether and at what rate computed output\nconverges to a stable solution as the time and spatial resolution of\nthe discretization grid gets finer. \n\nThe principal strategy of validation involves comparing model output\nwith observable data. Again, of course, this strategy is\nlimited in most cases, where simulations are being run because\nobservable data are sparse. But complex strategies can be\nemployed, including comparing the output of subsystems of a simulation\nto relevant experiments (Parker, 2013; Oberkampf and Roy\n2010). \n\nThe concepts of verification and validation has drawn some criticism\nfrom philosophers. Oreskes et al. 1994, a very widely-cited article,\nwas mostly critical of the terminology, arguing that\n“validity,” in particular, is a property that only applies\nto logical arguments, and that hence the term, when applied to models,\nmight lead to overconfidence. \n\nWinsberg (2010, 2018, p.155) has argued that the conceptual division\nbetween verification and validation can be misleading, if it is taken\nto suggest that there is one set of methods which can, by itself, show\nthat we have solved the equations right, and that there is another set\nof methods, which can, by itself, show that we’ve got the right\nequations. He also argued that it is misleading to think that the\nepistemology of simulation is cleanly divided into an empirical part\n(verification) and a mathematical (and computer science) part\n(validation.) But this misleading idea often follows discussion of\nverification and validation. We find this both in the work of\npractitioners and philosophers. \n\nHere is the standard line from a practitioner, Roy:\n“Verification deals with mathematics and addresses the\ncorrectness of the numerical solution to a given model. Validation, on\nthe other hand, deals with physics and addresses the appropriateness\nof the model in reproducing experimental data. Verification can be\nthought of as solving the chosen equations correctly, while validation\nis choosing the correct equations in the first place” (Roy\n2005). \n\nSome philosophers have put this distinction to work in arguments\nabout the philosophical novelty of simulation. We first\nraised this issue in section 4.1, where Frigg and Reiss argued that\nsimulation could have no epistemologically novel features, since it\ncontained two distinct components: a component that is identical\nto the epistemology of ordinary modeling, and a component that is\nentirely mathematical. “We should distinguish two\ndifferent notions of reliability here, answering two different\nquestions. First, are the solutions that the computer provides close\nenough to the actual (but unavailable) solutions to be\nuseful?…this is a purely mathematical question and falls within\nthe class of problems we have just mentioned. So, there is nothing new\nhere from a philosophical point of view and the question is indeed one\nof number crunching. Second, do the computational models that are the\nbasis of the simulations represent the target system correctly? That\nis, are the simulation results externally valid? This is a serious\nquestion, but one that is independent of the ﬁrst problem, and\none that equally arises in connection with models that do not involve\nintractable mathematics and ordinary experiments” (Frigg\nand Reiss 2009). \n\nBut verification and validation are not, strictly speaking, so cleanly\nseparable. That is because most methods of validation, by themselves,\nare much too weak to establish the validity of a simulation. And most\nmodel equations chosen for simulation are not in any straightforward\nsense “the right equations”; they are not the model\nequations we would choose in an ideal world. We have good reason to\nthink, in other words, that there are model equations out there that\nenjoy better empirical support, in the abstract. The equations we\nchoose often reflect a compromise between what we think best describes\nthe phenomena and computational tractability. So the equations that\nare chosen are rarely well “validated” on their own. If we\nwant to understand why simulation results are taken to be credible, we\nhave to look at the epistemology of simulation as an integrated whole,\nnot as cleanly divided into verification and validation—each of\nwhich, on its own, would look inadequate to the task. \n\nSo one point is that verification and validation are not\nindependently-successful and separable activities. But the other point\nis that there are not two independent entities onto which these\nactivities can be directed: a model chosen to discretized, and a method\nfor discretizing it. Once one recognizes that the equations to be\n“solved” are sometimes chosen so as to cancel out\ndiscretization errors, etc. (Lenhard 2007 has a very nice example of\nthis involving the Arakawa operator), this later distinction gets harder\nto maintain. So success is achieved in simulation with a kind of\nback-and-forth, trial-and-error, piecemeal adjustment between model and\nmethod of calculation. And when this is the case, it is hard even to\nknow what it means to say that a simulation is separately verified and\nvalidated. \n\nNo one has argued that V&V isn’t a useful distinction, but\nrather that scientists shouldn’t overinflate a pragmatically\nuseful distinction into a clean methodological dictate that\nmisrepresents the messiness of their own practice. Collaterally, Frigg\nand Reiss’s argument for the absence of epistemological novelty\nin simulation fails for just this reason.  It is not “a purely\nmathematical question” whether the solutions that the computer\nprovides close enough to the actual (but unavailable) solutions to be\nuseful. At least not in this respect: it is not a question that can be\nanswered, as a pragmatic matter, entirely using mathematical\nmethods. And hence it is an empirical/epistemological issue that does\nnot arise in ordinary modeling. \n\nA major strand of ordinary (outside of the philosophy of science)\nepistemology is to emphasize the degree to which it is a condition for\nthe possibility of knowledge that we rely on our senses and the\ntestimony of other people in a way that we cannot ourselves justify.\n According to Tyler Burge (1993,1998), belief in the results of\nthese two processes are warranted but not justified. Rather,\naccording to Burge, we are entitled to these beliefs. \n“[w]e are entitled to rely, other things equal, on perception,\nmemory, deductive and inductive reasoning, and on…the word of\nothers” (1993, p. 458). Beliefs in which a believer is\nentitled are those that are unsupported by evidence available to the\nbeliever, but which the believer is nevertheless warranted in\nbelieving. \n\nSome work in EOCS has developed analogies between computer\nsimulation and the kinds of knowledge producing practices Burge\nassociates with entitlement. (See especially Barberousse\nand Vorms, 2014, and Beisbart, 2017.) This is, in some ways, a\nnatural outgrowth of Burge’s arguments that we view computer\nassisted proofs in this way (1998). Computer simulations\nare extremely complex, often the result of the epistemic labor of a\ndiverse set of scientists and other experts, and perhaps most\nimportantly, epistemically opaque (Humphreys, 2004).  Because of\nthese features, Beisbart argues that it is reasonable to treat computer\nsimulations in the same way that we treat our senses and the testimony\nof others: simply as things that can be trusted on the assumption\nthat everything is working smoothly. (Beisbart,\n2017).  \n\nSymons and Alvarado (2019) argue that there is a fundamental problem\nwith this approach to EOCS and it has to do with a feature of\ncomputer-aided proof that was crucial to Burge’s original\naccount: that of a being a ‘transparent conveyor’.\n“It is very important to note, for example, that Burge’s\naccount of content preservation and transparent conveying requires\nthat the recipient already has reason not to doubt the source”\n(p. 13). But Symons and Alvarado point to many of the properties of\ncomputer simulations (drawing from Winsberg 2010 and Ruphy 2015) in\nvirtue of which they fail to have these properties. Lenhard and\nKüster 2019 is also relevant here, as they argue that there are\nmany features of computer simulation that make them difficult to\nreproduce and that therefore undermine some of the stability that\nwould be required for them to be transparent conveyors. For these\nreasons and others having to do with many of the features discussed in\n4.2 and 4.3, Symons and Alvarado argue that it is implausible that we\nshould view computer simulation as a basic epistemic practice on a par\nwith sense perception, memory, testimony, or the like. \n\nAnother approach to EOCS is to ground it in the practical aspects of\nthe craft of modeling and simulation. According to this view, in\nother words, the best account we can give of the reasons we have for\nbelieving the results of computer simulation studies is to have trust\nin the practical skills and craft of the modelers that use them. \nA good example of this kind of account is (Hubig and Kaminski,\n2017). The epistemological goal of this kind of work is to\nidentify the locus of our trust in simulations in practical aspects of\nthe craft of modeling and simulation, rather than in any\nfeatures of the models themselves. (Resch et al, 2017) argue that\na good part of the reason we should trust simulations is not because of\nthe simulations themselves, but because of the interpretive artistry of\nthose who employ their art and skill to interpret simulation\noutputs. Symons and Alvarado (2019) are also critical of this\napproach, arguing that “Part of the task of the epistemology of\ncomputer simulation is to explain the difference between the\ncontemporary scientist’s position in relation to epistemically\nopaque computer simulations..” (p.7) and the believers in a\nmechanical oracle’s relation to their oracles.  Pragmatic\nand epistemic considerations, according to Symons and Alvarado,\nco-exist, and they are not possible competitors for the correct\nexplanation of our trust in simulations--the epistemic reasons are\nultimate what explain and ground the pragmatic ones.  \n\nWorking scientists sometimes describe simulation studies in\nexperimental terms. The connection between simulation and\nexperiment probably goes back as far as von Neumann, who, when\nadvocating very early on for the use of computers in physics, noted\nthat many difficult experiments had to be conducted merely to determine\nfacts that ought, in principle, to be derivable from theory. Once\nvon Neumann’s vision became a reality, and some of these\nexperiments began to be replaced by simulations, it became somewhat\nnatural to view them as versions of experiment. A\nrepresentative passage can be found in a popular book on\nsimulation: \n\nThe idea of “in silico” experiments becomes even more\nplausible when a simulation study is designed to learn what happens to\na system as a result of various possible interventions: What would\nhappen to the global climate if x amount of carbon were added\nto the atmosphere? What will happen to this airplane wing if it is\nsubjected to such-and-such strain? How would traffic patterns change\nif an onramp is added at this location? \n\nPhilosophers, consequently, have begun to consider in what sense, if\nany, computer simulations are like experiments and in what sense they\ndiffer.  A related issue is the question of when a process that\nfundamentally involves computer simulation can counts as measurement\n(Parker, 2017) A number of views have emerged in the literature\ncentered around defending and criticizing two theses: The identity thesis. Computer simulation studies are\nliterally instances of experiments. The epistemological dependence thesis. The identity\nthesis would (if it were true) be a good reason (weak version), or the\nbest reason (stronger version), or the only reason (strongest version;\nit is a necessary condition) to believe that simulations can provide\nwarrants for belief in the hypotheses that they support. A\nconsequence of the strongest version is that only if the identity\nthesis is true is there reason to believe that simulations can confer\nwarrant for believing in hypotheses. \n\nThe central idea behind the epistemological dependence thesis is\nthat experiments are the canonical entities that play a central role in\nwarranting our belief in scientific hypotheses, and that therefore the\ndegree to which we ought to think that simulations can also play a role\nin warranting such beliefs depends on the extent to which they can be\nidentified as a kind of experiment. \n\nOne can find philosophers arguing for the identity thesis as early as\nHumphreys 1995 and Hughes 1999. And there is at least implicit support\nfor (the stronger) version of the epistemological dependence thesis in\nHughes. The earliest explicit argument in favor of the epistemological\ndependence thesis, however, is in Norton and Suppe 2001. According to\nNorton and Suppe, simulations can warrant belief precisely because\nthey literally are experiments. They have a detailed story to tell\nabout in what sense they are experiments, and how this is all supposed\nto work.  According to Norton and Suppe, a valid simulation is one in\nwhich certain formal relations (what they call\n‘realization’) hold between a base model, the modeled\nphysical system itself, and the computer running the algorithm. When\nthe proper conditions are met, ‘a simulation can be used as an\ninstrument for probing or detecting real world phenomena. Empirical\ndata about real phenomena are produced under conditions of\nexperimental control’ (p. 73). \n\nOne problem with this story is that the formal conditions that they\nset out are much too strict. It is unlikely that there are very many\nreal examples of computer simulations that meet their strict standards.\nSimulation is almost always a far more idealizing and approximating\nenterprise. So, if simulations are experiments, it is probably\nnot in the way that Norton and Suppe imagined. \n\nMore generally, the identity thesis has drawn fire from other\nquarters. \n\nGilbert and Troitzsch argued that “[t]he major difference is\nthat while in an experiment, one is controlling the actual object of\ninterest (for example, in a chemistry experiment, the chemicals under\ninvestigation), in a simulation one is experimenting with a model\nrather than the phenomenon itself.” (Gilbert and Troitzsch 1999,\n13). But this doesn’t seem right. Many (Guala 2002, 2008, Morgan 2003,\nParker 2009a, Winsberg 2009a) have pointed to problems with the\nclaim. If Gilbert and Troitzsch mean that simulationists manipulate\nmodels in the sense of abstract objects, then the claim is difficult\nto understand—how do we manipulate an abstract entity? If, on\nthe other hand, they simply mean to point to the fact that the\nphysical object that simulationists manipulate—a digital\ncomputer—is not the actual object of interest, then it is not\nclear why this differs from ordinary experiments.  \n\nIt is false that real experiments always manipulate exactly their\ntargets of interest. In fact, in both real experiments and\nsimulations, there is a complex relationship between what is\nmanipulated in the investigation on the one hand, and the real-world\nsystems that are the targets of the investigation on the other. In\ncases of both experiment and simulation, therefore, it takes an\nargument of some substance to establish the ‘external\nvalidity’ of the investigation – to establish that what is\nlearned about the system being manipulated is applicable to the system\nof interest. Mendel, for example, manipulated pea plants, but he was\ninterested in learning about the phenomenon of heritability\ngenerally. The idea of a model organism in biology makes this\nidea perspicuous. We experiment on Caenorhabditis elegans\nbecause we are interested in understanding how organism in general use\ngenes to control development and genealogy. We experiment\non Drosophila melanogaster, because it provides a\nuseful model of mutations and genetic inheritance. But the idea is not\nlimited to biology.  Galileo experimented with inclined planes because\nhe was interested in how objects fall and how they would behave in the\nabsence of interfering forces—phenomena that the inclined plane\nexperiments did not even actually instantiate. \n\nOf course, this view about experiments is not uncontested. It is\ntrue that, quite often, experimentalists infer something about a system\ndistinct from the system they interfere with. However, it is not clear\nwhether this inference is proper part of the original experiment.\nPeschard (2010) mounts a criticism along these lines, and hence can be\nseen as a defender of Gilbert and Troitzsch. Peschard argues that the\nfundamental assumption of their critics—that in experimentation,\njust as in simulation, what is manipulated is a system standing in for\na target system—is confused. It confuses, Peschard argues, the\nepistemic target of an experiment with its epistemic\nmotivation. She argues that while the epistemic motivation for\ndoing experiments on C. elegans might be quite far-reaching,\nthe proper epistemic target for any such experiment is the worm\nitself.  In a simulation, according to Peschard, however, the\nepistemic target is never the digital computer itself. Thus,\nsimulation is distinct from experiment, according to her, in that its\nepistemic target (as opposed to merely its epistemic motivation) is\ndistinct from the object being manipulated. Roush (2017) can also be\nseen as a defender of the Gilbert and Troitzsch line, but Roush\nappeals to sameness of natural kinds as the crucial feature that\nseparates experiments and simulations. Other opponents of the identity\nthesis include Giere (2009) and Beisbart and Norton (2012, Other\nInternet Resources). \n\nIt is not clear how to adjudicate this dispute, and it seems to\nrevolve primarily around a difference of emphasis. One can\nemphasize the difference between experiment and simulation,\nfollowing Gilbert and Troitzsch and Peschard, by insisting that\nexperiments teach us first about their epistemic targets and only\nsecondarily allow inferences to the behavior of other systems. \n(I.e., experiments on worms teach us, in the first instance, about\nworms, and only secondarily allow us to make inferences about genetic\ncontrol more generally.) This would make them conceptually\ndifferent from computer simulations, which are not thought to teach us,\nin the first instance, about the behavior of computers, and only in the\nsecond instance about storms, or galaxies, or whatever. \n\nOr one can emphasize similarity in the opposite way. One can\nemphasize the degree to which experimental targets are always chosen\nas surrogates for what’s really of interest.  Morrison, 2009 is\nprobably the most forceful defender of emphasizing this aspect of the\nsimilarity of experiment and simulation.  She argues that most\nexperimental practice, and indeed most measurement practice, involve\nthe same kinds of modeling practices as simulations.  In any case,\npace Peschard, nothing but a debate about nomenclature—and maybe\nan appeal to the ordinary language use of scientists; not always the\nmost compelling kind of argument—would prevent us from saying\nthat the epistemic target of a storm simulation is the computer, and\nthat the storm is merely the epistemic motivation for studying the\ncomputer. \n\nBe that as it may, many philosophers of simulation, including those\ndiscussed in this section, have chosen the latter path—partly as\na way of drawing attention to ways in which the message lurking behind\nGilbert and Troitzsch’s quoted claim paints an overly simplistic\npicture of experiment. It does seem overly simplistic to paint a\npicture according to which experiment gets a direct grip on\nthe world, whereas simulation’s situation is exactly\nopposite. And this is the picture one seems to get from the\nGilber and Troitzsch quotation. Peschard’s more sophisticated picture\ninvolving a distinction between epistemic targets and epistemic\nmotivations goes a long way towards smoothing over those concerns\nwithout pushing us into the territory of thinking that simulation and\nexperiment are exactly the same, in this regard. \n\nStill, despite rejecting Gilbert and Troitzsch’s\ncharacterization of the difference between simulation and experiment,\nGuala and Morgan both reject the identity thesis. Drawing on the\nwork of Simon (1969), Guala argues that simulations differ\nfundamentally from experiments in that the object of manipulation in an\nexperiment bears a material similarity to the target of interest, but\nin a simulation, the similarity between object and target is merely\nformal. Interestingly, while Morgan accepts this argument against the\nidentity thesis, she seems to hold to a version of the\nepistemological dependency thesis. She argues, in other words,\nthat the difference between experiments and simulations identified by\nGuala implies that simulations are epistemologically inferior to real\nexperiments – that they have intrinsically less power to warrant\nbelief in hypotheses about the real world because they are not\nexperiments. \n\nA defense of the epistemic power of simulations against Morgan’s\n(2002) argument could come in the form of a defense of the identity\nthesis, or in the form of a rejection of the epistemological\ndependency thesis. On the former front, there seem to be two problems\nwith Guala’s (2002) argument against the identity thesis. The\nfirst is that the notion of material similarity here is too weak, and\nthe second is that the notion of mere formal similarity is too vague,\nto do the required work. Consider, for example, the fact that it is\nnot uncommon, in the engineering sciences, to use simulation methods\nto study the behavior of systems fabricated out of silicon. The\nengineer wants to learn about the properties of different design\npossibilities for a silicon device, so she develops a computational\nmodel of the device and runs a simulation of its behavior on a digital\ncomputer. There are deep material similarities between, and some of\nthe same material causes are at work in, the central processor of the\ncomputer and the silicon device being studied. On Guala’s line\nof reasoning, this should mark this as an example of a real\nexperiment, but that seems wrong. The peculiarities of this example\nillustrate the problem rather starkly, but the problem is in fact\nquite general: any two systems bear some material similarities to each\nother and some differences. Parke (2014) argues against the\nepistemological dependency thesis by undermining two premises that she\nbelieves support it: fist, that experiments generate greater\ninferential power than simulations, and second, that simulations\ncannot surprise us in the same way that experiments can. \n\nOn the flip side, the idea that the existence of a formal similarity\nbetween two material entities could mark anything interesting is\nconceptually confused. Given any two sufficiently complex entities,\nthere are many ways in which they are formally identical, not to\nmention similar. There are also ways in which they are formally\ncompletely different. Now, we can speak loosely, and say that two\nthings bear a formal similarity, but what we really mean is that our\nbest formal representations of the two entities have formal\nsimilarities. In any case, there appear to be good grounds for rejecting both\nthe Gilbert and Troitzsch and the Morgan and Guala grounds for\ndistinguishing experiments and simulations.  \n\nReturning to the defense of the epistemic power of simulations, there\nare also grounds for rejecting the epistemological dependence thesis.\nAs Parker (2009a) points out, in both experiment and simulation, we\ncan have relevant similarities between computer simulations and target\nsystems, and that’s what matters. When the relevant background\nknowledge is in place, a simulation can provide more reliable\nknowledge of a system than an experiment. A computer simulation of the\nsolar system, based on our most sophisticated models of celestial\ndynamics, will produce better representations of the planets’\norbits than any experiment.   \nParke (2014) argues against the epistemological dependency thesis by\nundermining two premises that she believes support it: fist, that\nexperiments generate greater inferential power than simulations, and\nsecond, that simulations cannot surprise us in the same way that\nexperiments can.  The argument that simulations cannot surprise us\ncomes from Morgan (2005).  Pace Morgan, Parke argues that\nsimulationists are often surprised by their simulations, both because\nthey are not computationally omniscient, and because they are not\nalways the sole creators of the models and code they use.  She argues,\nmoreover, that ‘[d]ifferences in researcher’s epistemic states, alone,\nseem like the wrong grounds for tracking a distinction between\nexperiment and simulation’ (258).  Adrian Curry (2017) defends\nMorgan’s original intuition by making two friendly amendments.  He\nargues that the distinction Morgan was really after was between two\ndifferent kinds of surprise, and in particular to what the source of\nsurprise is: surprise due to bringing out theoretical knowledge into\ncontact with the world are distinctive of experiment.  He also more\ncarefully defines surprise in a non-psychological way such that it is\na “quality the attainment of which constitutes genuine epistemic\nprogress” (p. 640). \n\nPaul Humphreys (2004) has argued that computer simulations\nhave profound implications for our understanding of the structure of\ntheories; he argues that they reveal inadequacies with both the\nsemantic and syntactic views of scientific theories. This claim has\ndrawn sharp fire from Roman Frigg and Julian Reiss (2009). Frigg and\nReiss argue that whether a model admits of analytic solution or not has\nno bearing on how it relates to the world. They use the example of the\ndouble pendulum to show this. Whether or not the pendulum’s inner\nfulcrum is held fixed (a fact which will determine whether the relevant\nmodel is analytically solvable) has no bearing on the semantics of the\nelements of the model. From this, they conclude that the semantics of a\nmodel, or how it relates to the world, is unaffected by whether or not\nthe model is analytically solvable. \n\n This was not responsive, however,\nto the most charitable reading of what Humphreys was pointing at. The\nsyntactic and semantic views of theories, after all, were not just\naccounts of how our abstract scientific representations relate to the\nworld. More particularly, they were not stories about the\nrelation between particular models and the world, but rather about the\nrelation between theories and the world, and the role, if any,\nthat models played in that relation. \n\nThey were also stories that had a lot to say about where the\nphilosophically interesting action is when it comes to scientific\ntheorizing. The syntactic view suggested that scientific practice could\nbe adequately rationally reconstructed by thinking of theories as\naxiomatic systems, and, more importantly, that logical deduction was a\nuseful regulative ideal for thinking about how inferences from theory\nto the world are drawn. The syntactic view also, by omission, made if\nfairly clear that modeling played, if anything, only a\nheuristic role in science. (This was a feature of the\nsyntactic view of theories that Frederick Suppe, one of its most ardent\ncritics, often railed against.) Theories themselves had nothing\nto do with models, and theories could be compared directly to\nthe world, without any important role for modeling to play. \n\nThe semantic view of theories, on the other hand, did emphasize an\nimportant role for models, but it also urged that theories were\nnon-linguistic entities. It urged philosophers not to be distracted by\nthe contingencies of the particular form of linguistic expression a\ntheory might be found in, say, a particular textbook. \n\nComputer simulations, however, do seem to illustrate that both of\nthese themes were misguided. It was profoundly wrong to think that\nlogical deduction was the right tool for rationally reconstructing the\nprocess of theory application. Computer simulations show that there are\nmethods of theory application that vastly outstrip the inferential\npower of logical deduction. The space of solutions, for example, that\nis available via logical deduction from the theory of fluids is\nmicroscopic compared with the space of applications that can be\nexplored via computer simulation. On the flip side, computer\nsimulations seem to reveal that, as Humphreys (2004) has urged, syntax\nmatters. It was wrong, it turns out, to suggest, as the semantic\nview did, that the particular linguistic form in which a scientific\ntheory is expressed is philosophically uninteresting. The syntax of the\ntheory’s expression will have a deep effect on what inferences\ncan be drawn from it, what kinds of idealizations will work well with\nit, etc. Humphreys put the point as follows: “the\nspecific syntactic representation used is often crucial to the\nsolvability of the theory’s equations” (Humphreys 2009,\np.620). The theory of fluids can be used to\nemphasize this point: whether we express that theory in Eulerian or\nLagrangian form will deeply affect what, in practice, we can calculate\nand how; it will affect what idealizations, approximations, and\ncalculational techniques will be effective and reliable in which\ncircumstances. So the epistemology of computer simulation needs\nto be sensitive to the particular syntactic formulation of a theory,\nand how well that particular formulation has been credentialed. \nHence, it does seem right to emphasize, as Humphreys (2004) did, that\ncomputer simulations have revealed inadequacies with both the syntactic\nand semantic theories. \n\nPaul Humphreys (2004) and Mark Bedau (1997, 2011) have argued that\nphilosophers interested in the topic of emergence can learn a great\ndeal by looking at computer simulation. Philosophers\ninterested in this topic should consult the entry on \n emergent properties,\nwhere the contributions of all these philosophers have been\ndiscussed.  \n\nThe connection between emergence and simulation was perhaps best\narticulated by Bedau in his (2011). Bedau argued that any\nconception of emergence must meet the twin hallmarks of explaining how\nthe whole depends on its parts and how the whole is independent of its\nparts. He argues that philosophers often focus on what he calls\n“strong” emergence, which posits brute downward causation that is\nirreducible in principle. But he argues that this is a\nmistake. He focuses instead  on what he calls “weak”\nemergence, which allows for reducibility of wholes to parts\nin principle but not in practice. Systems that\nproduce emergent properties are mere mechanisms, but the mechanisms are\nvery complex (they have very many independently interacting parts). As\na result, there is no way to figure out exactly what will happen given\na specific set of initial and boundary conditions, except to “crawl the\ncausal web”. It is here that the connection to computer\nsimulation arises. Weakly emergent properties are characteristic\nof complex systems in nature. And it is also characteristic of\ncomplex computer simulations that there is no way to predict what they\nwill do except to let them run. Weak emergence explains, according to\nBedau, why computer simulations play a central role in the\nscience of complex systems. The best way to understand and predict how\nreal complex systems behave is to simulate them by crawling the\nmicro-causal web, and see what happens.  Models of course involve idealizations. But it has been argued\nthat some kinds of idealization, which play an especially prominent\nrole in the kinds of modeling involved in computer simulation, are\nspecial—to the point that they deserve the title of\n“fiction.” This section will discuss attempts to define\nfictions and explore their role in computer simulation. \n\nThere are two different lines of thinking about the role of fictions\nin science. According to one, all models are fictions. This line of\nthinking is motivated by considering the role, for example, of\n“the ideal pendulum” in science. Scientists, it is argued,\noften make claims about these sorts of entities (e.g., “the\nideal pendulum has a period proportional to the square-root of its\nlength”) but they are nowhere to be found in the real world;\nhence they must be fictional entities. This line of argument about\nfictional entities in science does not connect up in any special way\nwith computer simulation—readers interested in this topic should\nconsult the entry on\n scientific representation\n [forthcoming]. \n\nAnother line of thinking about fictions is concerned with the question\nof what sorts of representations in science ought to be regarded as\nfictional. Here, the concern is not so much about the ontology of\nscientific model entities, but about the representational character of\nvarious postulated model entities. Here, Winsberg (2009c) has argued\nthat fictions do have a special connection to computer simulations. Or\nrather, that some computer simulations contain elements that best\ntypify what we might call fictional representations in science, even\nif those representations are not uniquely present in simulations.  \n\nHe notes that the first conception of a fiction—mentioned\nabove—which makes “any representation that contradicts\nreality a fiction” (p. 179), doesn’t correspond to our ordinary\nuse of the term: a rough map is not fiction. He then proposes an\nalternative definition: nonfiction is offered as a “good\nenough” guide to some part of the world (p. 181); fiction is\nnot. But the definition needs to be refined.  Take the fable of the\ngrasshopper and the ant. Although the fable offers lessons about how\nthe world is, it is still fiction because it is “a useful guide\nto the way the world is in some general sense” rather than a\nspecific guide to the way a part of the world is, its “prima\nfacie representational target”, a singing grasshopper and\ntoiling ant. Nonfictions, on the other hand, “point to a certain\npart of the world” and are a guide to that part of the world\n(p. 181). \n\nThese kinds of fictional components of models are\nparadigmatically exemplified in certain computer simulations. Two of\nhis examples are the “silogen atom” and “artificial\nviscosity.” Silogen atoms appear in certain nanomechanical models\nof cracks in silicon—a species of the kind of multiscale models\nthat blend quantum mechanics and molecular mechanics mentioned in\nsection 2.3. The silogen containing models of crack propagation in\nsilicon work by describing the crack itself using quantum mechanics and\nthe region immediately surrounding the crack using classical molecular\ndynamics. To bring together the modeling frameworks in the two regions,\nthe boundary gets treated as if it contains ‘silogen’\natoms, which have a mixture of the properties of silicon and those of\nhydrogen. Silogen atoms are fictions. They are not offered as even a\n‘good enough’ description of the atoms at the\nboundary—their prima facie representational targets. But they are\nused so that the overall model can be hoped to get things right. Thus\nthe overall model is not a fiction, but one of its components is.\nArtificial viscosity is a similar sort of example. Fluids with abrupt\nshocks are difficult to model on a computational grid because the\nabrupt shock hides inside a single grid cell, and cannot be resolved by\nsuch an algorithm. Artificial viscosity is a technique that pretends\nthat the fluid is highly viscous—a fiction—right were the\nshock is, so that he shock becomes less abrupt, and blurs over several\ngrid cells. Getting the viscosity, and hence the thickness of the\nshock, wrong, helps to get the overall model to work “well\nenough.” Again, the overall model of the fluid is not a fiction,\nit is a reliable enough guide to the behavior of the fluid. But the\ncomponent called artificial viscosity is a fiction—it is not\nbeing used to reliably model the shock. It is being incorporated into a\nlarger modeling framework so as to make that larger framework,\n“reliable enough.” \n\nThis account has drawn two sorts of criticisms. Toon (2010) has\nargued that this definition of a fiction is too narrow. He gives\nexamples of historical fictions like I, Claudius, and\nSchindler’s Ark, which he argues are fictions, despite\nthe fact that “they are offered as ‘good enough’\nguides to those people, places and events in certain respects and we\nare entitled to take them as such.” (p. 286–7). Toon, presumably,\nsupports a broader conception of the role of fictions in science, then,\naccording to which they do not play a particularly prominent or\nheightened role in computer simulation. \n\nGordon Purves (forthcoming) argues that there are examples of\nfictions in computational models (his example is so-called\n“imaginary cracks”), and elsewhere, that do not meet the\nstrict requirements discussed above. Unlike Toon, however, he also\nwants to delineate fictional modeling elements from the non-fictional\nones. His principal criticism is of the criterion of fictionhood in\nterms of social norms of use—and Purves argues that we ought to\nbe able to settle whether or not some piece of modeling is a fiction in\nthe absence of such norms. Thus, he wants to find an intrinsic\ncharacterization of a scientific fiction. His proposal takes as\nconstitutive of model fictions that they fail to have the\ncharacteristic that Laymon (1985) called “piecewise\nimprovability” (PI). PI is a characteristic of many models that\nare idealizations; it says that as you de-idealize, your model becomes\nmore and more accurate. But as you de-idealize a silogen atom, you do\nnot get a more and more accurate simulation of a silicon crack. But\nPurves takes this failure of PI to be constitutive of a fiction, rather\nthan merely symptomatic of them.","contact.mail":"winsberg@usf.edu","contact.domain":"usf.edu"}]
