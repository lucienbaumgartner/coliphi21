[{"date.published":"2018-07-13","url":"https://plato.stanford.edu/entries/wesley-salmon/","author1":"Maria Carla Galavotti","entry":"wesley-salmon","body.text":"\n\n\nWesley Charles Salmon (1925–2001) was a central figure in\ntwentieth century philosophy of science. Working in the tradition of\nHume, Salmon developed a sophisticated version of empiricism combining\na genuinely probabilistic approach with realism about theoretical\nentities. Salmon’s writings, characterized by a systematic and\ncrystal-clear style, cover a wide range of topics including logic, the\nphilosophy of space and time, the foundations of probability and\nscientific inference, rationality, realism, and scientific\nexplanation, a major focus of his production for more than thirty\nyears. Unlike the Hempelian “received view”, Salmon\ndeveloped a concept of explanation according to which to explain means\nto exhibit the causal mechanisms responsible for the occurrence of\nphenomena. Convinced that our knowledge is uncertain and that\ncausality ought to be defined in probabilistic terms, he pursued a\nprobabilistic version of mechanicism, opening a new trend of research\nin the literature on explanation, known as\n“neo-mechanicism”. Salmon’s views on all the topics\nhe addressed continue to nurture fresh reflection and ongoing\ndebate.\n\n\nAfter a biographical note (section 1), this entry surveys\nSalmon’s views on probability (section 2), confirmation (section\n3), space and time (section 4), explanation and causality (section 5),\nrationality and realism (section 6). Albeit necessary in this kind of\nessay, such partitioning is somewhat artificial, because\nSalmon’s ideas are strictly interconnected: his conception of\ncausal explanation relies on his frequency view of probability and\nsubstantiates a concept of rationality that regards causal knowledge\nof phenomena as crucial for our understanding of both the world and\nhuman action. \n\n\n\n\nWesley Charles Salmon was born in Detroit on 9 August 1925, to Wallis,\na mechanical and electrical engineer, and Ruth Springer Salmon, a\nschoolteacher. After completing primary and secondary school in\nDetroit, and studying at Wayne University (now Wayne State University)\nfrom 1943–44, in 1944 Salmon moved to the University of Chicago.\nTaken with admiration for the charismatic minister of his\nfamily’s Methodist church, Salmon entered the University of\nChicago Divinity School with the intention to become a minister\nhimself. However, as he writes in the autobiographical note published\nin What? Where? When? Why? (1982), once in Chicago he left\nhis “belief in virtually every tenet of Christianity, as well as\nall confidence in the social value of religion” (Salmon 1982c:\n281). He then decided to turn to philosophy and in 1947 obtained his\nMA in Philosophy with a thesis on Whitehead’s conception of\nfreedom. \nIn Chicago, Salmon was quite unhappy with the Thomistic focus of the\nPhilosophy department, where the scientifically oriented philosophy he\nfavored was somewhat disregarded, in spite of the presence there of\nRudolf Carnap, with whom at that time he did not have much\ninterchange. Closer interaction between them took place in 1963, while\nSalmon was visiting the University of Minnesota Center for Philosophy\nof Science for the Winter and Spring terms, and was given the\nopportunity to pay a one week visit to Carnap in Los Angeles, together\nwith Herbert Feigl, and Grover Maxwell. That visit was the occasion\nfor daily discussions on the nature of confirmation and inductive\nlogic. Such a stimulating exchange fueled many writings, including the\nmasterpiece The Foundations of Scientific Inference (1967a),\nwhose fiftieth anniversary edition was re-published in 2017 with an\nintroduction by Christopher Hitchcock. \nAfter receiving his MA, Salmon decided to move to UCLA. Although he\nclaimed to have taken that decision attracted by the warm Californian\nclimate, his choice proved decisive, because there he encountered Hans\nReichenbach, who supervised his Ph.D. dissertation on John Venn, and\nwho exercised a dominant influence on all of his subsequent work.\nAfter obtaining his Ph.D. in 1950, Salmon held teaching positions at\nWashington State College; UCLA; Northwestern University, and Brown\nUniversity. \nIn 1963 Salmon moved to the recently founded (1960) department of\nHistory and Philosophy of Science of Indiana University, where his\nphilosophical attitude underwent an important turn, that he so\ndescribes: \nAt Indiana, for the first time, I found myself dealing with graduate\nstudents and colleagues who had strong scientific backgrounds and a\nfair degree of scientific sophistication. It became essential for me\nto treat philosophy of science, not as a discipline looking inward\nupon other branches of philosophy, but as one which looks outward\ntoward the various scientific disciplines. […] I came to the\nconviction, which I still hold, that philosophy which remains out of\ncontact with other disciplines runs the great risk of becoming quite\nsterile. (Salmon 1982c: 282) \nAs a result of such developments, besides continuing to work on the\nissues which had always been on his mind, namely induction,\nconfirmation, probability and the nature of scientific inference,\nSalmon became deeply interested in the philosophy of space and time,\npublishing the introductory book Space, Time, and Motion\n(1975a), which can be considered a pearl of clarity; the collection\nZeno’s Paradoxes (1970a); and a number of subsequent\npapers. During his years at Indiana University Salmon started working\nalso on explanation, a subject that remained at the heart of his\nproduction for the rest of his life. \nAfter his first marriage ended in divorce, in 1971 Salmon married\nMerrilee Ashby, herself a philosopher of science. In 1973 Salmon and\nhis wife left Indiana and took positions at the University of Arizona,\nto stay there until 1981 when they both moved to the University of\nPittsburgh. There, in 1983 Salmon was appointed University Professor\nat the Philosophy department as a successor of Carl Gustav Hempel, a\nposition he held until his retirement in 1999. In Pittsburgh\nphilosophy of science was flourishing, thanks to a large community\nbelonging not only to the department of Philosophy, but also the\ndepartment of History and Philosophy of Science, the Center for\nPhilosophy of Science, and the Philosophy department of Carnegie\nMellon University. As a member of such a lively philosophical\ncommunity Salmon enjoyed a most congenial atmosphere for twenty\nextremely productive years, leading to the publication of the book\nScientific Explanation and the Causal Structure of the World\n(1984), a milestone of the literature on scientific explanation and\nthe apex of Salmon’s work on the topic, the collection, edited\nwith Philip Kitcher, Scientific Explanation (1989), which\nincluded as a chapter the essay “Four Decades of Scientific\nExplanation”, to be published one year later as a book (1990a),\nand a long series of articles which later merged into the two\ncollections Causality and Explanation (1998) and Reality\nand Rationality, edited by P. Dowe and M.H. Salmon, which\nappeared posthumously in 2005. \nAlong the years Salmon gave lectures and courses as a visiting\nprofessor in many universities and other prestigious institutions\naround the world, including the university of Bologna, where in 1988\nhe delivered a lecture course on “Forty years of scientific\nexplanation”; the university of Melbourne (1978), and Kyoto\nUniversity, where in the Spring 2000 he last taught for one term.\nSalmon was also very active in promoting philosophy of science, and\nserved as President of the Logic, Methodology and Philosophy of\nScience division of the International Union of History and Philosophy\nof Science (now IUHPST: International Union of History and Philosophy\nof Science and Technology) from 1996 to 2000. \nOn 22 April 2001 Salmon died in a car accident on his way home from a\nfamily visit in Indiana.  \nFrom his first book Logic (1963a), which was translated into\nSpanish, Japanese, Italian, Portuguese, and German, to his last\npublication, the article “The Causal Structure of the\nWorld” (2010), Salmon published fifteen authored and edited\nbooks, and over two hundred articles, reviews and comments of other\nauthors. All of his publications, written in a crystal clear style,\nare characterized by rigorous argumentation and original thought.\nIntroductory books like Logic, Space, Time and\nMotion, and Foundations of Scientific Inference are\nmasterpieces which have served as reference books for generations of\nstudents and researchers operating in various fields, while\nStatistical Explanation and Statistical Relevance,\nScientific Explanation and the Causal Structure of the World,\nExplanation and Causality, and Reality and\nRationality are unparalleled sources of inspiration for\nphilosophers of science working on explanation, causality, and\nscientific rationality. \nSalmon regarded probability as an essential component of science and\nhuman knowledge at large, and induction as the fundamental ingredient\nof scientific method. In so doing, he followed in the steps of his\nmentor Reichenbach, of whom he said:  \nJust as Hume was the great empiricist of the eighteenth century, so it\nmay be, will Reichenbach be remembered as the great empiricist of the\ntwentieth century. (Salmon 1979b: 2–3)  \nDavid Hume is undoubtedly a major source of inspiration for both\nReichenbach and Salmon, who placed themselves in the empiricist\ntradition, and shared Hume’s conviction that prediction is the\nmain task of science, to be fulfilled using induction. By embracing a\nprobabilistic version of inductivism Reichenbach and Salmon intended\nto make a step forward in the direction indicated by Hume.  \nReichenbach was one of the first to criticize the verifiability theory\nof meaning embraced by the Viennese school on account that  \nit would be illusory to imagine that the terms ‘true’ or\n‘false’ ever express anything else than high or low\nprobability values. (Reichenbach 1936: 156)  \nThis brought probability to the foreground. Reichenbach embraced an\nempirical approach to probability and maintained that probability\nvalues must be determined on the basis of experience alone. What can\nbe extracted from experience are frequencies, and it is on their basis\nthat probability must be fixed. Reichenbach called the method for\nobtaining probability values induction by enumeration. This\nconsists in counting the relative frequency of a given attribute in\nthe initial section of a sequence of observations and inferring that\nsuch frequency will persist approximately for the rest of the sequence\nwhen this is indefinitely prolonged. This procedure forms the content\nof the canon according to which the frequency interpretation\nprescribes fixing prior probabilities, a tenet Reichenbach called\nRule of induction: \nif the sequence has a limit of the frequency, there must exist an\nn such that from there on the frequency \\(f^{i} (i \\gt n)\\)\nwill remain within the interval \\(f^{n} \\pm \\delta\\), where \\(\\delta\\)\nis a quantity that we can choose as small as we like, but that, once\nchosen, is kept constant. Now if we posit that the frequency \\(f^{i}\\)\nwill remain within the interval \\(f^{n} \\pm \\delta\\), and we correct\nthis posit for greater n by the same rule, we must finally come\nto the correct result. (Reichenbach 1935 [1949: 445]) \nEvery probability statement obtained by means of this method is a\nwager, or a posit, namely a statement allowing us to infer\nunknown from known frequencies in such a way that, if the sequence of\nobservations has a limit, the method will assure convergence to a\nunique result. \nSalmon wholeheartedly embraced the frequency interpretation, and in\nparticular Reichenbach’s version of it, which embodies a way of\nmaking single case probability assignments. The key notion in this\nregard is that of weight, taken to represent the predictive\nvalue of sentences referring to single events. The idea is that the\nweight assigned to such sentences derives from the probabilities\nattached to the reference class to which the event in\nquestion belongs. The reference class should obey a criterion of\nhomogeneity, namely it should be chosen so as to include as\nmany cases as possible similar to the one under consideration,\nexcluding dissimilar ones. While Reichenbach recommended choosing\n“the narrowest class for which we have reliable\nstatistics” (Reichenbach 1938: 316) Salmon opted for “the\nbroadest homogeneous reference class”, because  \nwe do not want to try to refer single cases to classes that are too\nnarrow, for if we do we will not have enough evidence upon which to\nbase our inference […] at the same time, we want our reference\nclass to contain other relevant cases, not irrelevant ones.\nStatistical relevance is the key concept here. (Salmon 1967a:\n91)  \nThe reference class containing all and only the relevant properties is\nobjectively homogeneous. Salmon is well aware that \nit would be most unrealistic to suppose that we can fulfill the\nrequirement of selecting the broadest homogeneous reference class in\nall cases in which we have to make practical decisions about single\nevents. We may suspect that a given reference class is inhomogeneous,\nbut not know of any way to make a relevant partition of it. Under\nthese circumstances let us say that the class is epistemically\nhomogeneous. […] Sometimes we know that a reference class\nis inhomogeneous, but it would simply be impractical to carry out a\nrelevant subdivision. […] Under these circumstances, let us say\nthe reference class is practically homogeneous. (Salmon\n1967a: 92) \nAs we shall see\n (§ 5.2),\n in addition to playing a crucial role in scientific inference by\nproviding the key to singular prediction, statistical relevance is no\nless essential for Salmon’s conception of explanation, and the\nsame holds for reference class homogeneity. \nDeeply convinced of the indispensability of induction, Salmon\nmaintained that  \nthere is a crucial sense in which the logic of science is inescapably\ninductive, and that a justification of induction is essential to a\nfull understanding of the logic of science. (Salmon 1968a: 24)  \nTo Popper’s uncompromising deductivism he opposed the claim that\ncorroboration, the core of Popper’s falsificationist\nmethodology, is a non-demonstrative kind of inference:\n“Modus tollens without corroboration is empty;\nmodus tollens with corroboration is induction” (Salmon\n1968a: 28; see also Salmon 1981 [1988a]). A number of Salmon’s\npapers published in the Fifties and Sixties argued against various\nattempts to deny or dissolve the problem of justifying induction,\nincluding those of A.J. Ayer, M. Black and P. Strawson (Salmon 1957,\n1963b, 1965, 1978b). By contrast, he took seriously Hume’s\nargument showing the impossibility of giving a logical solution to the\nproblem of the justification of induction. Adopting Herbert\nFeigl’s distinction between validation and vindication (Feigl\n1950), Salmon embraced a pragmatic approach according to which\ninduction is justified in terms of the knowledge-extending function to\nwhich it happens to be necessary. \nIn a similar vein, Reichenbach (1935 [1949] and 1938) had set himself\nthe task of justifying induction as the best possible method for\nprediction and action. Given his commitment to frequentism, he meant\nto show that the rule of induction satisfies the “principle of\nthe greatest number of successes”, namely that it leads us to\nact in the most successful way possible. Accordingly, the rule of\ninduction is justified on account that if successful\npredictions are attainable at all, its application will assure the\nattainment of that goal. Reichenbach’s justification relies on\nthe self-correcting character of the method, whose repeated\napplication guarantees convergence to a unique value in the long run\nwhenever there exists a limit of the relative frequency. However, his\nargument applies to a whole class of asymptotic rules, all of which\nsatisfy the convergence property. The thing is that one can add to the\nrelative frequency a corrective term which modifies the observed\nfrequency to obtain a slightly different posit. The particularity of\nthe rule of induction is that it makes no use of the corrective term.\nWell aware of the fact that his argument applied to an infinite class\nof asymptotic rules, Reichenbach privileged the rule of induction on\nthe grounds of its descriptive simplicity. This applies to\ndescriptions (statements) which are semantically equivalent, as\nopposed to inductive simplicity which applies when one of two\nor more descriptions, or hypotheses, which are not semantically\nequivalent, is believed to be more likely to be true.  \nSalmon praised Reichenbach’s approach for not assuming that\nthere exists an order in nature:  \nthe whole force of the justification is that the use of induction is\nreasonable whether or not nature is uniform, whatever may be meant by\nthe assertion “Nature is uniform”. (Salmon 1953: 48)  \nNevertheless, he found fault with Reichenbach’s argument for the\njustification of the rule of induction. Both descriptive and inductive\nsimplicity apply to statements, not to rules, and even if one wanted\nto apply them to rules, one would have to consider that asymptotic\nrules do not converge uniformly, which means that they “are not\nin any sense empirically equivalent” (Salmon 1963c: 28).\nSimplicity would be a sufficient criterion for justifying the choice\nof a particular rule from the class of asymptotic rules only if such\nrules were empirically equivalent, but they are not. Salmon set\nhimself the task of spelling out the conditions under which all\nasymptotic rules could be rejected except the rule of induction.  \nHis first move was to fix two regularity, or\nnormalizing, conditions imposing that no relative frequency\n\\(m/n\\) observed in any initial section of a sequence can be negative,\nand that for every possible n so obtained all the corresponding\nvalues of \\(m_i\\) must add up to one. He then added a requirement of\nlinguistic invariance stating that the inferences made by\nmeans of a given rule must be invariant with respect to the language\nin which the evidence taken into consideration is expressed. In other\nwords, what matters to inductive inferences is the content of evidence\nstatements, not their linguistic form. For a while Salmon thought that\nthese requirements could fulfill the purpose for which they had been\nproposed. He was able to demonstrate that the normalizing conditions\ncould eliminate a large subclass of Reichenbach’s asymptotic\nrules (Salmon 1956), and that the criterion of linguistic invariance\ncould do the same with all the methods belonging to Carnap’s\ncontinuum, except the one Carnap called the straight\nrule—alias the rule of induction (Salmon 1961). Among other\nthings, the criterion of linguistic invariance allowed Salmon to\nsuggest an original solution to Goodman’s paradox (Salmon\n1963c). \nSalmon’s hope to have solved the problem left open by\nReichenbach’s argument for the justification of inductive\nmethods was soon disappointed, especially after the criticism raised\nby Ian Hacking (1965 and 1968). Hacking showed that the three\nconditions of consistency, symmetry and\ninvariance taken together are necessary and sufficient to\nselect the rule of induction among the class of asymptotic rules.\nHacking’s consistency and invariant conditions are stronger\nversions of Salmon’s requirements of regularity and linguistic\ninvariance, while the symmetry condition (corresponding to the\nproperty usually called exchangeability) requires that for\nany given value of the relative frequency observed in a sample, the\nposited value of the limiting frequency must be insensitive to the\norder in which the items of the sample were observed to occur. This\nrequirement is commonly accepted by the upholders of the subjective\ninterpretation of probability, but for a frequentist like Salmon, who\nheld that the evaluation of probability must be entirely based on\nempirical data, symmetry (exchangeability) can only mean a factual\nassumption on the nature of the population under study. This clashes\nwith a justification in tune with Reichenbach’s perspective. As\nSalmon observed, Reichenbach’s rule of induction  \nis a method for primitive knowledge, and this is what he was\nattempting to justify. Thus, he would argue, since we have no results\nof previous inductions to establish these factual assumptions, we are\nnot entitled to make them. (Salmon 1991: 117) \nIn order to overcome this difficulty Salmon put forward a new argument\nbased on Reichenbach’s distinction between a context of\ndiscovery and a context of justification. The decision\nto examine a certain sequence to calculate the relative frequency of\nits attributes, Salmon claimed, belongs in the context of discovery,\nand in addition  \nthe use of the rule of induction to arrive at a value to\nposit is also part of the context of discovery; at the same time, it\nlooks like part of the context of justification as well, for the posit\nis justified by virtue of the rule of induction. (Salmon 1991:\n117–118)  \nThe interplay between the two contexts offers the key to attempt a\nsolution, because assumptions introduced as hypotheses at the\ndiscovery level are to be confirmed or rejected at the justification\nlevel. The symmetry condition would then represent a wager in the\ncontext of discovery, to be tested in the context of justification.\nThe conclusion Salmon reached is that: \nReichenbach sought to solve Hume’s problem of the justification\nof induction by means of a pragmatic vindication that relies heavily\non the convergence properties of his rule of induction. His attempt to\nrule out all other asymptotic methods by an appeal to descriptive\nsimplicity was unavailing. We found that important progress in that\ndirection could be made by invoking normalizing conditions\n(consistency) and methodological simplicity (as a basis for\ninvariance), but that they did not do the whole job. I am proposing\nthat, in the end, Reichenbach’s own distinction between\ndiscovery and justification holds the key to the solution. (Salmon\n1991: 119) \nThe methodological simplicity mentioned in this passage was\nsuggested to Salmon by John Clendinnen. It is a version of simplicity\nthat applies to rules instead of statements, and requires the adoption\nof “the simplest system of predicting rules which are compatible\nwith, and exemplified in, the set of known facts” (Clendinnen\n1982: 20). Salmon accepted Clendinnen’s suggestion as a\nsignificant, if not decisive, contribution to the justification of\ninduction (Salmon 1982c and 1991). \nIn The Foundations of Scientific Inference Salmon compared\nthe major interpretations of probability against three criteria:\nadmissibility, ascertainability, and applicability.\nAdmissibility requires satisfaction of the formal properties\nof probability spelled out by the probability calculus;\nascertainability demands that there must exist a method of\nascertaining the values of probability; applicability\nstipulates that the concept of probability must have a practical\npredictive import. \nLaplace’s classical interpretation was deemed defective\nwith respect to admissibility, because it suffers from the difficulty\nknown as “Bertrand’s paradox”, which applies to\nproblems involving an infinite range of possibilities, in which case\nthe classical definition can lead to conflicting probability values.\nSalmon also considered the subjective interpretation,\naccording to which probability “is simply a measure of degree of\nbelief”, to be inadmissible (Salmon 1967a: 68). Salmon dealt\nseparately with the interpretation he called personalistic,\nwhich he attributed to Savage. The distinctive feature of this\napproach—matching what is meant by the subjective interpretation\ntoday – is that it appeals to the betting scheme in order to\ndetermine probability values, and imposes coherence on systems of\nbets. Salmon claimed that the personalistic outlook satisfies the\ncriteria of admissibility and ascertainability, but does not comply\nwith applicability because it  \nleaves entirely unanswered our questions about inductive inference. It\ntolerates any kind of inference from the observed to the\nunobserved. (Salmon 1967a: 82)  \nApplicability also represented an obstacle for the logical\ninterpretation, which was reputed “to provide no basis for\nexpecting the probable in preference to the improbable” (Salmon\n1967a: 79). In Salmon 1967a and elsewhere, notably Salmon 1967b, 1969\n[2005], and 1975b [2005], Salmon discussed in great detail\nCarnap’s inductive logic, which he rated highly for shedding\nlight on a number of important aspects of confirmation and induction.\nAt the same time, he deemed that  \nthe conception of inductive logic as based upon a logical relation is\nfundamentally misconceived […] although deductive logic\nrequires and exploits logical relevance relations, induction is\ninvolved with factual relevance relations instead. (Salmon 1969 [2005:\n202])  \nMoreover, Salmon disagreed with Carnap’s justification of\ninduction in terms of inductive intuition (Carnap 1968). Salmon held\nthe frequency interpretation to come closest to satisfying\nall of the adequacy requirements, although it faced serious\ndifficulties with ascertainability, especially in connection with\nsingle case probability attributions. However, Salmon deemed the\nsolution promising in terms of weight referred to homogeneous\nreference classes\n (§ 2.1).\n In addition, he regarded the frequency theory as the only\ninterpretation offering a viable approach to the justification of\ninduction.  \nIn 1979d Salmon discussed the propensity interpretation put\nforward by Popper to solve the single case problem arising within\nquantum mechanics. The idea is that probability should be taken as a\ndispositional property of the experimental set-up, or the generating\nconditions of experiments, liable to be reproduced over and over again\nto form a sequence (Popper 1959). Salmon argued that Popper’s\nproposal fares no better than the frequentist way of attaching\nprobability values to single occurrences of events. In fact, the\ndifficulties faced by frequentists in connection with identifying\nhomogeneous reference classes are displaced rather than solved by the\npropensity account, which requires completeness of information in\norder to describe the chance set-up generating propensities. \nIn addition, Salmon endorsed Paul Humphreys’ objection that\npropensities cannot qualify as probabilities because their\ndispositional character ascribes them a peculiar asymmetry that goes\nin the opposite direction from that characterizing inverse\nprobability, making the propensity theory inapplicable to Bayes’\nrule (Humphreys 1985). To take Salmon’s example,  \nsuppose we are given a set of probabilities from which we can deduce\nthat the probability that a certain person died as a result of being\nshot through the head is ¾. It would be strange, under these\ncircumstances, to say that this corpse has a propensity (tendency?) of\n¾ to have had its skull perforated by a bullet. (Salmon 1979d:\n213)  \nWhile clashing with the symmetrical character of probabilities, the\nasymmetry of propensities matches that of the causal relation. In view\nof this, Salmon preferred to take propensities to be probabilistic\ncausal tendencies rather than probabilities (see\n § 5.6). \nFurther reading: On\nReichenbach see Salmon 1979a; Glymour & Eberhardt 2008 [2016]; and\nthe 2011 special issue of the journal Synthese 181(1). On the\ninterpretation of probability see Gillies 2000; Galavotti 2005; and\nHájek 2002 [2012]. The debate on context of discovery vs.\ncontext of justification is surveyed in Schickore 2014. \nSalmon tackled the issue of confirmation of scientific hypotheses in\nChapter VII of The Foundations of Scientific Inference and in\na number of papers including 1973 and 1975b [2005]. He called\nattention to the difference between absolute confirmation,\ntaken to mean making highly probable, and incremental, or\nrelevance confirmation, taken to mean increasing the\nprobability of some hypothesis. According to Salmon, the distinction,\nalready made by Carnap in Logical Foundations of Probability,\nwas largely overlooked by subsequent literature, although failure to\nappreciate it can yield puzzling results. For instance, Carnap showed\nthat it can be the case that two pieces of evidence incrementally\nconfirm a given hypothesis, while their conjunction may disconfirm it.\nIn addition, Salmon pointed out that a piece of evidence that\nlogically entails the falsity of the conjunction of two hypotheses\ncould incrementally confirm each of them. In view of this and other\npuzzles, Salmon emphasized that “we have said very little when\nwe have stated merely that a hypothesis h has been confirmed by\nevidence i” (Salmon 1975b [2005: 229]). Conversely, by\nappealing to Bayes’ rule “we can aspire to a much fuller\nunderstanding of relations of confirmation (in both the absolute and\nthe relevance senses)” (Salmon 1975b [2005: 236]). \nLike Reichenbach, Salmon assigned Bayes’ rule a crucial role in\nthe confirmation of scientific hypotheses, convinced that the\nhypothetico-deductive (H-D) method dear to logical empiricism\n“is a gross oversimplification” (1968b [2005: 72]) unable\nto capture essential aspects of confirmation. His main reason for\nrejecting the H-D method was its inability to accommodate\nplausibility judgments, even though many examples from the\nhistory of science show that they have entered the choice between\nalternative hypotheses. It is precisely for that reason, Salmon\nargued, that many philosophers have denied that plausibility\nconsiderations belong to the logic of science, or claimed that they\nare part of the context of discovery rather than the context of\njustification. On the contrary, for Salmon plausibility considerations\n“are pervasive in the sciences; they play a\nsignificant—indeed, indispensable—role”\n(Salmon 1990d [2005: 98]). In particular, they can contribute to\nfixing the prior probability of hypotheses and hence fit very well in\nthe Bayesian scheme and as such belong in the context of\njustification. Incidentally, Salmon considered Reichenbach’s\ndistinction between a context of discovery and a context of\njustification, which a number of authors deem debatable, not only\nfruitful, but even essential for a proper understanding of the nature\nof scientific knowledge. \nSalmon followed Reichenbach in embracing an objective version of\nBayesianism according to which prior probabilities should be\ndetermined on the basis of objective and empirical criteria. Prior\nprobabilities represent the “best estimates of the frequencies\nwith which certain kinds of hypotheses succeed” (Salmon 1990d\n[2005: 102]), and must be fixed by means of (objective) criteria such\nas simplicity, symmetry and analogy. Analogy, in particular, is apt to\nsuggest comparisons with other similar theories, whose rate of success\nin the past can be assessed. Salmon conceded that priors are sometimes\nthe expression of rough estimates, and can be stated in terms of\ninterval probabilities. In any case, he regarded prior probabilities\nas an essential component of hypothesis confirmation, as testified by\nmany cases offered by the history of science. The fruitfulness of\nassuming a Bayesian perspective in studying the history of science is\nstrongly emphasized: \nWithout the Bayesian analysis, one could say that the study of the\nhistory of science might have some (at least marginal) heuristic value\nfor the scientist and philosopher of science; but with the Bayesian\nanalysis, the data provided by the history of science constitute,\nin addition, an essential segment of the evidence relevant to\nthe confirmation or disconfirmation of hypotheses. Philosophers of\nscience and creative scientists ignore this fact at their peril.\n(Salmon 1970c [2005: 92]) \nSalmon identified the decisive advantage of the Bayesian method over\nthe H-D with its being a tool for theory comparison, for which reason\nhe recommended adopting its formulation in terms of ratios: \nwhere \\(T_1\\) and \\(T_2\\) are two alternative hypotheses, and E is a\npiece of evidence. Given the pivotal importance Kuhn ascribed to\ntheory comparison, Salmon regarded the Bayesian method as a way of\nbridging the gap between the vision of science as an objective and\nrational enterprise, embraced by logical empiricists, and Kuhn’s\ncritique of such view (Salmon 1990d [2005]).  \nFurther reading: On\nconfirmation see Crupi 2013 [2016] and Talbott 2001 [2016].\nHájek & Hitchcock (eds.) 2016 contains a number of essays on\nprobability, confirmation, probabilistic causation, and related\nissues. \nSalmon took an interest in the philosophy of space and time while\nattending Reichenbach’s courses as a graduate student at UCLA,\nand continued working on the topic for many years. His first\npublication in the field was the collection of essays Zeno’s\nParadoxes (1970a), including contributions by Abner Shimony,\nBertrand Russell, Henri Bergson, Max Black, J.O. Wisdom, James\nThomson, Paul Benacerraf, G.E.L. Owen, and Adolf Grünbaum, plus a\nlong introduction and an appendix on “Sets and Infinity”\nby Salmon himself. As stated at the beginning of the introduction,\nSalmon’s goal in bringing together the essays forming the\ncollection was systematic rather than historical. His motivation lay\nin the conviction that after a long period in which Zeno’s\nparadoxes had been regarded as mere sophisms, from the middle of the\nNineteenth and even more in the Twentieth century they had become the\nfocus of sophisticated philosophical discussion. The articles included\nin the book tackle five of Zeno’s arguments, namely four\nparadoxes of motion and the paradox of plurality. At the heart of the\nparadoxes lies the problem of defining the notions of continuum and\ninfinity. According to Salmon, such paradoxes cannot be solved in\npurely logical or mathematical terms because “it is also\nnecessary to show how the abstract mathematical system can be used for\nthe description of concrete physical reality” (Salmon 1970a:\n16). It is worth noting that one of the chapters consists of a few\npages taken from Russell’s Our Knowledge of the External\nWorld (1929) outlining his at-at theory of motion, which later\nplayed a key role within Salmon’s theory of causal processes\n(see\n § 5.5.2). \nIn 1975 Salmon published a second book called Space, Time and\nMotion: A Philosophical Introduction (1975a) which contains a\nmasterly introduction to the topic. The four chapters of the book lead\nthe non-specialist reader through the essentials of the philosophy of\nspace and time from non-Euclidean geometries and Zeno’s\nparadoxes to special relativity and simultaneity. The book, which\npresupposes only an elementary background knowledge of geometry and\nmathematics on the part of the reader, is meant as an invitation to\npursue the topics addressed in a more systematic and specialized way.\nSalmon fully achieved this purpose, whose treatment of thorny subjects\nsucceeded in being both “scientifically sound” and\n“intuitive and easy” (Salmon 1988c: 276). \nSalmon addressed simultaneity in other writings, including the article\n“The Philosophical Significance of the One-Way Speed of\nLight” (1977c) which contains a defense of simultaneity’s\nconventionality, dating back to Einstein and argued for in detail by\nReichenbach (1928 [1957]). After surveying a number of experimental\nmethods devised for the measurement of the speed of light, from\nGalileo to J. Bradley, H.L. Fizeau, and J.L. Foucault, Salmon went on\nto discuss synchrony, arguing that a conventional element is involved\nin all of such accounts. Since simultaneity rests on synchrony and\nultimately on the one way speed of light, by showing that the latter\ncannot be ascertained experimentally Salmon intended to “give\nsubstance to the abstract conventionality issue” (Salmon 1977c:\n255), namely to Einstein’s claim that the relation between the\nspeed of light in two different directions is not a matter that can be\nestablished empirically, but only by convention. \nFurther reading: For a\nclassical introduction to the philosophy of space and time see\nGrünbaum 1973. A more recent account is to be found in Malament\n2012. A collection of essays on the key problems of the philosophy of\nphysics is contained in Batterman (ed.) 2013. \nSalmon tackled explanation in a highly original manner which left a\nmost remarkable legacy. He worked intensively on the topic for the\nlast thirty years of his life, refining his approach in response to\ncomments and critiques raised by a number of authors, and shedding new\nlight on various details. At the turn of the Seventies, when Salmon\npublished his groundbreaking paper “Statistical\nExplanation” (Salmon 1970b [1971]) the literature was dominated\nby Hempel’s “covering law” model of explanation,\nwhich held sway since the Forties, and is often referred to as the\nreceived view. Salmon’s motivation for developing an\nalternative view of explanation stemmed from his dissatisfaction with\ncertain aspects of Hempel’s account. In Four Decades of\nScientific Explanation (Salmon 1990a) Salmon discussed a number\nof counterexamples showing that the requirements Hempel imposed on\nexplanation, and more in particular the requirement of maximal\nspecificity and the requirement of high inductive\nprobability of the explanandum, are neither necessary nor\nsufficient to identify a tenable account of scientific explanation. In\nshort, Salmon’s discontents focused on the impossibility of\nexplaining low probability events, the secondary role assigned to\ncausality, the thesis of the symmetry between explanation and\nprediction, the epistemic relativization of statistical explanation,\nand the insufficient importance ascribed to the notion of relevance.\n \nUnlike Hempel, Salmon did not regard statistical explanation as\nsomewhat incomplete compared to deductive explanation, taken as the\noptimum. By contrast, his approach to explanation takes statistical\ngeneralizations to be the general case, with explanations making use\nof universal generalizations as a special case. A pivotal role is\nassigned to the notion of relevance, more particularly statistical\nrelevance, placed at the core of the Statistical-Relevance\n(or S-R) model. Equal importance is assigned to causality\ninterpreted in a probabilistic fashion. By the Seventies,\nprobabilistic causality had already attracted the attention of a\nnumber of authors including Hans Reichenbach (see Reichenbach 1956);\nbuilding on this work Salmon intended to revive the mechanistic ideal\nof explanation, convinced that the time had come to put the\n“cause” back into “because”. \nThe notions of statistical relevance and probabilistic\ncausality inform the two components of Salmon’s theory,\nnamely the S-R model, aimed at identifying the network of statistical\nrelations holding between the properties relevant to the events to be\nexplained, and causal explanation, aimed at locating such\nevents within the mechanisms responsible for their occurrence (Salmon\n1984). \nAccording to the S-R model, in order to explain an event one must\nexhibit all the factors that are statistically relevant to its\nhappening, without mentioning irrelevant elements, so that an\nexplanatory account should include only information that is genuinely\nexplanatory. In order to accomplish this task, the event explanandum\nmust be referred to a homogeneous reference class, namely to\nthe class containing all and only the relevant properties. Homogeneity\nis obtained through statistically relevant partitions of\nnon-homogeneous reference classes into mutually exclusive and\nexhaustive sub-classes. Statistical relevance, providing the tool to\nattain homogeneity, is defined as follows. Let A stand for the\nreference class including some event of which one wants to establish\nthe probability of possessing the property B; \\(p (B \\mid A)\\)\nbe the probability of B within the reference class A,\nand C be another property by which the class A can be\ndivided into two sub-classes \\((A \\amp C)\\) and \\((A \\amp \\msim C)\\);\nthe property C is statistically relevant with respect to\nB in A if and only if \\(p (B \\amp C \\mid A) ≠ p (B\n\\mid A)\\). A homogeneous partition of a reference class does not admit\nfurther relevant partitions, and the resulting sub-classes must be\nmaximal, in the sense that no irrelevant properties are retained.  \nIn some cases partitioning a reference class A can result in\ntwo sub-classes \\((A \\amp C)\\) and \\((A \\amp \\msim C)\\) both\nhomogeneous with respect to a given property B. This means that\nproperty B is held by all elements belonging to class \\((A \\amp\nC)\\), but none of the elements belonging to \\((A \\amp \\msim C)\\). In\nall other cases the class A will be partitioned into k\nhomogeneous sub-classes \\((A \\amp C_{k})\\) such that \nfor \\(i ≠ j\\). Such a procedure is the content of a rule of\nmultiple homogeneity which “expresses the fundamental\ncondition for adequate explanation of particular events” (Salmon\n1970b [1971: 59]). Fulfillment of this rule guarantees against the\ninclusion of irrelevant information in the explanatory account. Once\nthe process leading to the specification of a homogeneous reference\nclass is completed, the event to be explained is associated with a\nprobability distribution. The shift from a non-homogeneous to a\nhomogeneous reference class embodies the explanatory power of the S-R\nmodel, according to which  \nan explanation is an assemblage of factors that are statistically\nrelevant to the occurrence of the event to be explained, accompanied\nby an associated probability distribution. (Salmon 1979c: 68)  \nThe shift in question involves an increase in information, although\nnot necessarily an increase in probability. Given that Salmon does not\nrequire relevance to be positive, the procedure described can result\nin a higher as well as a lower probability of the explanandum. In this\nperspective what counts for the sake of explanation is not high\nprobability, as required by Hempel, but being in a position to assert\nthat the probability distribution associated with the explanandum\nreflects the most complete and detailed information attainable. This\ninformation is conveyed by a homogeneous partition of the reference\nclass, together with a statement specifying to which cell of that\npartition the explanandum event belongs. \nAs observed\n (§ 2.1),\n the objective homogeneity of the reference class is an ideal not free\nfrom difficulties, because one can hardly ever be sure to have taken\ninto account all relevant information. Well aware of this, Salmon\nadmits that in practice  \nwe often lack full knowledge of the properties relevant to a given\nattribute, so we do not know whether our reference class is\nhomogeneous or not. (Salmon 1970b [1971: 44])  \nTherefore, in most cases use is made of epistemically\nhomogeneous reference classes, namely those relative to a given\nknowledge situation. \nSalmon rejected Hempel’s tenet that an explanation is an\nargument, which he deemed the “third dogma of empiricism”\n(Salmon 1977a [1998]). His main objection was that although\nirrelevancies are harmless to arguments, they are fatal to\nexplanations. In Salmon’s words: \nInference, whether deductive or inductive, demands a requirement of\ntotal evidence—a requirement that all relevant evidence\nbe mentioned in the premises. This requirement, which has substantive\nimportance for inductive inferences, is automatically satisfied for\ndeductive inferences. Explanation, in contrast, seems to demand a\nfurther requirement—namely, that only considerations\nrelevant to the explanandum be contained in the explanans. (Salmon\n1977a [1998: 104]) \nFurthermore, arguments are not well suited to account for explanatory\nasymmetry, for there is a disparity of temporal asymmetry in\nexplanations and in arguments that makes the latter fit for prediction\nand retrodiction, but unfit for explanation. Take for instance a lunar\neclipse, which can be predicted on the basis of the laws of motion and\na suitable set of initial conditions holding prior to it. The same\neclipse can also be retrodicted making use of posterior conditions and\nthe same laws. However, explanations are temporally asymmetric in a\nvery specific sense: they go from antecedent conditions to subsequent\nevents. Such asymmetry is not embodied by arguments, which often move\nin the opposite direction. There emerges a divergence between\nprediction, which is an inferential activity, and explanation, which\nis not.  \nThe asymmetry of explanation reflects that of causation, which for\nSalmon is the key to a satisfactory explanatory account. While\nknowledge of correlations is usually sufficient to bolster prediction,\nexplanation requires more, namely establishing causal relations\nbetween events. A favorite example mentioned by Salmon is that of\n“the barometer and the storm”. Based on the correlation\nbetween the behavior of the barometer and the occurrence of storms,\none can predict a storm after having observed a sudden drop in the\nbarometer, but nobody would say that the drop in the barometer\nexplains the storm. In similar situations one would look for causal\ninformation, such as the sudden drop in atmospheric pressure in the\narea surrounding the occurrence of the storm. On the one hand, not all\nstatistically relevant properties convey causal information; on the\nother, statistical correlations themselves invoke an explanation. In\nview of this, in the course of the Seventies Salmon gradually came to\nthe conclusion that the S-R model cannot substantiate a satisfactory\naccount of explanation. In a paper entitled “Why Ask\n‘Why?’?” he maintained: \nI no longer believe that the assemblage of relevant factors provides a\ncomplete explanation—or much of anything in the way of an\nexplanation. We do, I believe, have a bona fide explanation of an\nevent if we have a complete set of statistically relevant factors, the\npertinent probability values, and causal explanations of the relevance\nrelations (1978a [1998: 137]).  \nFirst of all, a theory of probabilistic causal explanation requires\nthat a distinction can be made between statistical and causal\nrelevance. The tool for that purpose is the screening off\nrelation, defined as follows. Going back to the example of the\nbarometer and the storm, let B stand for the barometer drop,\nS for the storm, and P for the drop in atmospheric\npressure. There is a correlation between B and S, so\nthat \\(p (S \\mid B) \\gt p (S)\\)—namely B is statistically\nrelevant to S. But if we take into account P, we see\nthat \\(p (S \\mid P \\amp B) = p (S \\mid P)\\), namely B becomes\nirrelevant to S in the presence of P. This means that\nP screens off B from S. It should not pass\nunnoticed that the screening off relation is asymmetrical; in our\nexample B does not screen off P from S, for \\(p\n(S \\mid P \\amp B) ≠ p (S \\mid B)\\). Salmon formulates a\nscreening off rule requiring that those properties which are\nscreened off by other properties are removed from the reference class.\nThis makes screening off the canon guiding the search for homogeneous\nreference classes. Moreover, by virtue of its asymmetric character the\nscreening off relation forges a bridge between statistical and causal\nrelevance, obviously taken in a probabilistic sense. \nEmbedded in the Principle of the common cause, that Salmon\nborrowed from Reichenbach, screening off has the capacity to discern\ngenuine from spurious causal links. In Reichenbach’s\nformulation, such principle states that “if an improbable\ncoincidence has occurred, there must exist a common cause”\n(Reichenbach 1956: 157). Reichenbach named the structure underlying\nthe principle of the common cause conjunctive fork, to be\ndefined as follows. Take two events A and B which happen\nsimultaneously more frequently than would be expected on the basis of\npure chance. Then we have that \\(p (A \\amp B) \\gt p (A) \\times p\n(B)\\), namely the two events are not independent. If in the presence\nof a third event C the correlation between A and\nB is absorbed, so that the two events become reciprocally\nindependent if taken relative to C and \\(\\msim C\\), we have a\nconjunctive fork. For a conjunctive fork the following relations\nhold: \nIn other words, the common cause C screens off irrelevant\nproperties from their effects. Salmon offers many examples of\nconjunctive forks. Here is one:  \nSuppose that two siblings contract mumps at the same time, and assume\nthat neither caught the disease from the other. The coincidence is\nexplained by the fact that they attended a birthday party and, by\nvirtue of being in the same locale, both were exposed to another child\nwho had the disease. This would constitute a typical example of a\nconjunctive fork. (Salmon 1984: 164)  \nConjunctive forks possess a peculiar asymmetry, namely they are open\nto the future, never to the past. In Salmon’s words:  \nSince the statistical relations found in conjunctive forks are said to\nexplain otherwise improbable coincidences, it follows that such\ncoincidences are explained only in terms of common causes, never\ncommon effects. (Salmon 1984: 163)  \nConjunctive forks provide the connection between the S-R model and\ncausal explanation. \nFor several years Salmon thought that the combination of screening off\nand the common cause principle offered a solid basis on which causal\nexplanation could be made to rest, but he later revised his position,\nafter criticism from a number of authors including Bas van Fraassen\n(1977 and 1982). In order to cope with the difficulties besetting\nconjunctive forks Salmon formulated another type of fork, called\ninteractive. Interactive forks depict causal interactions\nwhose effects remain correlated even in the presence of the common\ncause; in other words the common cause does not screen off one effect\nfrom the other. The structure of interactive forks is analogous to\nthat of conjunctive forks, with the difference that in this case the\nequality  \ndoes not hold, and in its place we have the inequality \nTo exemplify interactive forks Salmon mentions Compton scattering: \nIf, for example, an energetic photon collides with an electron in a\nCompton scattering experiment, there is a certain probability that a\nphoton with a given smaller energy will emerge, and there is a certain\nprobability that the electron will be kicked out with a given kinetic\nenergy. […] However, because of the law of conservation of\nenergy, there is a strong correspondence between the two energies:\ntheir sum must be close to the energy of the incident photon. Thus,\nthe probability of getting a photon with energy \\(E_1\\) and an\nelectron with energy \\(E_2\\), where \\(E_1 + E_2\\) is approximately\nequal to \\(E\\) (the energy of the incident photon), is much greater\nthan the product of the probabilities of each energy occurring\nseparately. (Salmon 1978a [1998: 133]) \nAlthough, in the absence of screening off, in interactive forks the\ncommon cause does not absorb the dependency between the effects, they\nplay a crucial role within Salmon’s approach. Before this can be\nclarified some more notions must be introduced. \nThe cornerstone of Salmon’s theory of probabilistic causality is\nthe notion of a causal process, defined as a spatio-temporal\ncontinuous entity having the capacity to transmit “information,\nstructure and causal influence” (Salmon 1994b [1998: 253]; see\nalso Salmon 1984: 154–157). Processes are responsible for causal\npropagation, and provide the links connecting causes to\neffects. By opting for continuous processes, instead of causal chains\nconceived as collections of events, Salmon diverged from other\ntheories of probabilistic causality, such as those put forward by\nPatrick Suppes, Irving John Good and Hans Reichenbach. Salmon was\ndeeply convinced that the notion of a causal process can account for\nmany puzzling cases, which other theories find difficult to handle\n(see Salmon 1980 [1998]). Furthermore, he regarded causal processes as\n“the kinds of causal connections Hume sought but was unable to\nfind”, holding that “such connections do not violate\nHume’s strictures against mysterious powers” (Salmon 1990b\n[1998: 71]). In order to characterize causal propagation, or\ntransmission, Salmon borrowed from Reichenbach the concept of mark\ntransmission, and from Bertrand Russell the at-at theory\nof causal propagation. \nReichenbach introduced the mark method in The Philosophy\nof Space and Time (1928 [1957]) to distinguish causal processes\nfrom pseudo-processes. Unlike the latter, causal processes have the\ncapacity to transmit marks, namely various sorts of signals or\ninformation. Salmon’s favorite example is that of a rotating\nspotlight placed at the center of a circular room, which casts a spot\nof light on the wall. The light beam that travels from the source to\nthe wall is a causal process, whereas the light spot that moves around\nthe wall is a pseudo-process. In order to convince us that the light\nray is a genuine process, Salmon invites us to consider what happens\nif a red filter is placed near the source of the beam: the color of\nthe beam will turn red, and so will the spot on the wall. By\ninterposing a red filter between the source and the beam a mark has\nbeen introduced, which is then transmitted along the beam. By\ncontrast, the moving spot on the wall is not a causal process, because\nit lacks the capacity to transmit information; if for instance someone\nwere to place a piece of red cellophane on the wall at some point, the\nlight would turn red when the beam hit the cellophane, but the color\nwould not be retained as the spot moves on.  \nAs Salmon emphasized, it is the ability to transmit marks\nthat characterizes processes, not the fact that they actually do\nso: \na process is causal if it is capable of transmitting a mark,\nwhether or not it is actually transmitting one. The fact that\nit has the capacity to transmit a mark is merely a symptom of the fact\nthat it is actually transmitting something else. That other something\nI described as information, structure, and causal influence. (Salmon\n1994b [1998: 253]) \nIn order to account for mark transmission without violating the\nstrictures of Hume’s critique and being exposed to the suspicion\nof introducing some occult causal power, Salmon drew inspiration from\nthe theory of causal lines put forward by Russell in\nHuman Knowledge: Its Scope and Limits (1948). According to\nSalmon, Russell came very close to conceiving a notion of a causal\nprocess similar to his own, when he stated that \na causal line may always be regarded as the persistence of\nsomething—a person, table, a photon, or what not. Throughout a\ngiven causal line, there may be constancy of quality, constancy of\nstructure. […] That there are such more or less self-determined\ncausal processes is in no degree logically necessary, but is, I think,\none of the fundamental postulates of science. (Russell 1948: 459,\nquoted from Salmon 1984: 144) \nAlthough not completely satisfied with some aspects of Russell’s\naccount, Salmon retained his at-at theory of motion, which he\nsummarized as follows:  \nto move from A to B is simply to occupy the intervening\npoints at the intervening instants. It consists in being at\nparticular points of space at corresponding moments. (Salmon\n1984: 153)  \nApplying the at-at theory to causal processes having the capacity to\ntransmit marks results in stipulating that the transmission of a mark\nfrom a given point A in a process to some point B in the\nsame process simply consists in the fact that it appears at each point\nbetween A and B. Incidentally, as observed earlier\n (§ 4)\n Salmon found Russell’s at-at theory of motion a satisfactory\nsolution to Zeno’s arrow paradox (Salmon 1984: 151–153).\n \nTo the definition of processes in terms of the capacity to transmit a\nmark, Salmon added a counterfactual clause, to the effect that:  \nA mark that has been introduced into a process by means of a\nsingle intervention at point A is transmitted to point B\nif and only if it occurs at B and at all stages of the process\nbetween A and B without additional interventions.\n(Salmon 1977b [1998: 197], italics original; see also Salmon 1984:\n148)  \nThis move was made necessary to obviate a problem connected with a\ncounterexample suggested by Nancy Cartwright. This can be summarized\nas follows: back to the example of the rotating spotlight, suppose\nthat a few nanoseconds before a piece of red cellophane is placed on\nthe wall and turns the moving spot red someone places a red lens on\nthe rotating beacon, so that the beam remains red, not because of the\ncellophane placed on the wall, but because of the lens placed near the\nlight source. In Salmon’s words:  \nin such a case the spot turns red owing to a local\ninteraction and remains red without any additional local\ninteraction. With or without the intervention on the wall, the\nspot of light moving around the wall would have been red from that\npoint on. Considerations of such cases required a counterfactual\nformulation of the principle of mark transmission. (Salmon 1994b\n[1998: 252])  \nNotably, Salmon did not associate counterfactuals with the semantic\nview in terms of possible words, adopting instead an experimental\ninterpretation according to which counterfactual statements make\nreference to observed statistical relations which can be tested by\ncontrolled experiments (Salmon 1984: 149–150).  \nSalmon’s view of processes has been criticized in various ways.\nIn particular, Philip Kitcher (1989) found the experimental view of\ncounterfactuals no more satisfactory than the attempts made by various\nauthors to justify counterfactuals on semantic grounds. Phil Dowe also\nexpressed dissatisfaction with Salmon’s account of causal\nprocesses, and suggested mark transmission to be abandoned in favor of\nan alternative definition in terms of conserved quantities,\nlater adopted by Salmon. \nThe process theory of causality in terms of conserved quantities\nproposed by Dowe is based on the following: \nA world line is “the collection of points on a\nspace-time (Minkowski) diagram which represents the history of an\nobject”, and a conserved quantity “is any\nquantity universally conserved according to current scientific\ntheories” (Dowe 1992: 210; see also Dowe 1995 and 2000).\nExamples of conserved quantities mentioned by Dowe are mass-energy,\nlinear momentum, angular momentum, and charge. Salmon regarded with\nfavor Dowe’s proposal and accepted a slightly modified version\nof it, according to which \nA process transmits a conserved quantity between A and\nB \\((A ≠ B)\\) if and only if it possesses [a fixed\namount of] this quantity at A and at B and at every\nstage of the process between A and B without any\ninteractions in the open interval (A,B) that involve an exchange of\nthat particular conserved quantity. (Salmon 1997: 462, italics\noriginal) \nSalmon deemed a decisive advantage of conserved quantities over mark\ntransmission the fact that causal processes are defined in terms of\ncharacteristics they actually possess, rather than of their\ncapacity to transmit marks. This makes it unnecessary to\nappeal to counterfactuals. Moreover, the conserved quantities approach\nallows one to handle intersections that are untreatable by the mark\nmethod, such as those of Y and \\(\\lambda\\) types. These obtain whenever two\nprocesses merge into one—for instance, when a snake swallows a\nmouse—or two processes emerge from one—for instance, when\na single-celled organism splits into two cells. A major difference\nwith Dowe’s approach is Salmon’s insistence upon\ncausal transmission, as opposed to the mere possession of\nconserved quantities, so that “a process is causal if and only\nif it transmits a conserved quantity” (Salmon 2010: 10; see also\nSalmon 1997). The capacity to transmit conserved quantities provides\nan easy way to distinguish causal from pseudo processes, which do not\nhave that capacity. The at-at theory of transmission is retained, to\nmean that a conserved quantity “is at the appropriate\nplace at the appropriate stage in the process” (Salmon\n2010: 10). The mark method keeps an important role as a tool for\ndetecting causal relationships.  \nAnother fundamental ingredient of Salmon’s theory of causality\nis the notion of production. Causal production takes place\nwhenever two processes intersect each other in such a way that their\nstructure is modified, and the modification will be propagated by\nprocesses until another interaction takes place. The kind of\nintersection between processes that gives rise to causal production is\ndescribed by interactive forks.  \nProcesses and conjunctive and interactive forks are the ingredients of\nthe mechanistic picture of the world that Salmon had in mind.\nConjunctive and interactive forks represent two different ways in\nwhich processes can intersect one another, and fulfill different tasks\nwithin Salmon’s perspective. Thanks to their screening off\ncapacity, conjunctive forks detect order and asymmetries among the\ncausal connections forming mechanisms, whereas interactive forks are\nthe sites of causal production. The temporal asymmetry characterizing\nconjunctive forks is absent from interactive forks, which describe\nphysical interactions taking place at a certain moment in a certain\nplace. Interactive forks are more basic than conjunctive forks,\nbecause they express a causal concept which can be “explicated\nwithout recourse to other causal concepts” (Salmon 1994b [1998:\n249]). Salmon called attention to the fact that \nthere is a striking difference between conjunctive common causes on\nthe one hand and causal processes and interactions on the other.\nCausal processes and causal interactions seem to be governed by basic\nlaws of nature in ways that do not apply to conjunctive forks.\n[…] Although I am not prepared to argue the case in detail, it\nseems plausible to suppose that all fundamental physical\ninteractions can be regarded as exemplifications of the\ninteractive fork. Conjunctive common causes are not nearly as closely\ntied to the laws of nature. […] in contrast to causal processes\nand causal interactions, conjunctive forks depend crucially on de\nfacto background conditions. (Salmon 1982a [1998: 299]) \nUnlike conjunctive forks, causal processes and interactions cannot be\ndefined in purely statistical terms. To stress this crucial\ndifference, Salmon referred to statistical causality in terms\nof screening off and conjunctive forks, and aleatory\ncausality in terms of processes and interactive forks. Aleatory\ncausality “places primary emphasis on the mechanisms of\ncausality” (Salmon 1990c [1998: 207]) and informs us about how\nphenomena fit within the mechanisms responsible for their occurrence.\nStatistical regularities are all that is needed by statistical\ncausality, whereas aleatory causality requires more, namely the\npossibility to speak of tendencies that are both causal and\nprobabilistic. Salmon thought that propensities, taken as causal\nprobabilistic tendencies\n (§ 2.3),\n prove fruitful in that connection, and held that:  \nif we think of propensities as probabilistic causes, we can use the\nconcepts of causal processes and causal mechanisms in order to explain\nthe mechanisms of probabilistic causality. (Salmon 1990c [1998: 205])\n \nTo the two kinds of causality described by Salmon there correspond two\ndifferent levels of explanation: (1) the S-R model, which concerns\nconnections between kinds of events, and (2) causal mechanical\nexplanation, which bears upon single events. It should not pass\nunnoticed that while explanation of the first level, based on\nstatistical correlations, provides a good basis for prediction,\nexplanation in terms of aleatory causality traces back the history of\nevents after their occurrence. In the Eighties, Salmon thought that\nonly aleatory causality could offer an adequate understanding of\ncausality and regarded the causal mechanical level as genuine\nexplanation, assigning an ancillary role to the S-R level.  \nIn a penetrating discussion Christopher Hitchcock observed that\nSalmon’s causal mechanical explanation was too weak, because it\nenvisaged a geometrical network of processes and interactions but did\nnot convey any hint as to what properties should be taken as\nexplanatory. In agreement with Woodward (1984), Hitchcock held that\nexplanation should answer\n“what-if-things-had-been-different” questions, and claimed\nthat  \na successful account of explanation had better make the relation of\nexplanatory relevance look roughly like that of counterfactual\ndependence. (Hitchcock 1995: 311)  \nAccording to Hitchcock  \nour demand that explanations provide relevant information\nrequires something stronger—that we be told which\nearlier properties the properties specified in the explanandum depend\nupon. (Hitchcock 1995: 311)  \na requisite Salmon’s definition of processes and causal\ntransmission does not meet. By way of a counterexample, Hitchcock\nobserved that based on Salmon’s theory a blue spot impressed on\na billiard ball by a stick on which a player had put blue chalk would\ncount as a mark transmitted by a causal process, and furthermore one\nwould be unable to tell why the linear momentum of the\nbilliard ball should be included in the explanation of its movement,\nwhereas the blue mark should not.  \nIn reply to Hitchcock, Salmon revised his position by ascribing equal\nsignificance to the two levels of explanation. In “A Reply to\nTwo Critiques” he wrote:  \nI would now say (1) that statistical relevance relations, in the\nabsence of connecting causal processes, lack explanatory import and\n(2) that connecting causal processes, in the absence of statistical\nrelevance relations, also lack explanatory import. […] Both are\nindispensable. (Salmon 1997: 476)  \nThe causal model in terms of processes was compared to a telephone\nnetwork which exhibits the lines of communications and the\nconnections, but does not convey any information about the messages\nthat are sent. In order to identify the properties pertinent to given\noutcomes one needs information on statistical relevance relations; the\nprocedure of singling out such properties results from an interplay\nbetween causal and statistical relevance information. On the one hand,\na network of causal processes and interactions serves to exclude\nirrelevant factors which are not there at the considered place and\ntime; on the other, the network has to be filled with statistical\nrelevance relations linking the properties present.  \nContextually, Salmon admitted that counterfactual considerations play\na role within explanation, and reaffirmed a close connection between\nstatistical relevance relations and counterfactuals. To take\nSalmon’s example,  \nwhen asserting that a window was shattered because it was struck by a\nbaseball traveling at a considerable velocity, we presumably have in\nmind that the window would not have broken if the intersection with\nthe baseball had not occurred. (Salmon 1997: 475)  \nSuch a counterfactual is deemed unproblematic because it is supported\nby well-established assertions of statistical relevance, which are\nnothing other than reports of observed relative frequencies. \nSalmon termed his conception of explanation ontic, as opposed\nto the epistemic conception heralded by Hempel, and the erotetic\napproach defended by van Fraassen (Salmon 1985a [1998] and 1982b\n[1998]). According to the ontic viewpoint events are explained by\nshowing how they fit into the mechanisms operating in the world, and\nthe causal processes and interactions of which mechanisms are\ncompounded are physical entities. In Salmon’s words: \nTo understand the world and what goes on in it, we must expose its\ninner workings. To the extent that causal mechanisms operate, they\nexplain how the world works. […] A detailed knowledge of the\nmechanisms may not be required for successful prediction; it is\nindispensable to the attainment of genuine scientific understanding.\n(Salmon 1984: 133) \nAlbeit he never gave up the task of developing an objective and\nrealistic concept of explanation, in the Nineties Salmon granted the\nimportance of pragmatic considerations in connection with causal\nexplanation. In this vein, he admitted that causal analysis can be\nperformed at different levels of detail, depending on the\ncircumstances. In some cases, phenomena can be analyzed in great\ndetail, based on scientific theories, but more often they can be\nexamined at varying degrees of abstraction, determined by the context.\nIn “A Realistic Account of Causation”, published\nposthumously in 2002, Salmon argued that  \nthe major obstacle to the creation of a fully objective and realistic\ntheory of cause-effect relations is the fact that the instances we\ntend to select are highly context dependent. (Salmon 2002: 123)  \nAfter examining a number of examples he concluded that\n“cause-effect statements are almost always—if not\nalways—context dependent” (Salmon 2002: 125).  \nThat said, Salmon retained the idea of a complete causal\nstructure including all the processes and interactions operating\nin a certain space-time region. Such a concept bears some resemblance\nto Peter Railton’s “ideal explanatory text” (Railton\n1981), the difference being that Railton has a text in mind, while\nSalmon’s complete causal structure is a physical entity. The\nmost important feature characterizing the complete causal structure is\nits objectivity: “the complete causal structure is a fact of\nnature that exists quite independently of our knowledge or\ninterests” (Salmon 2002: 126).  \nThe role played by scientific theories within Salmon’s\nmechanistic view should not pass unnoticed. Both causal production and\nprocesses defined in terms of conserved quantities include an appeal\nto theories and laws of nature, because only “our current\ntheories tell us what quantities to think of as conserved”\n(Salmon 1994b [1998: 258]). Similarly, to describe causal interactions\none must appeal to laws such as the conservation of energy and\nmomentum. This led Salmon to conclude:  \nI realize that the theory I am proposing has a highly reductionistic\nflavor. It seems to me that my account should hold in the natural\nsciences—including biology, but not quantum mechanics—I am\nnot confident that it is suitable for psychology and the social\nsciences. (Salmon 2002: 131)  \nA similar conclusion, which further clarifies Salmon’s attitude\ntowards reductionism, is to be found in “The Causal Structure of\nthe World”: \nFinally, although my tone in this talk has been rather reductionistic,\nI do not hold a reductionist point of view. It is quite possible that\nother kinds of causation are present in such areas as psychology and\nsociology, where human intentions and interrelations are involved.\nPhysical causation must apply at the basic level of perception and\ncommunication, but there may be more. I would not commit myself to a\nreductionist—or antireductionist—viewpoint unless I\nhad at least an acceptable solution to the mind-body problem, and that\nis something I don’t have at present, and I doubt that\nI’ll ever find one in my lifetime. (Salmon 2010: 12) \nFurther reading: On\nHempel’s theory of explanation see Hempel 1965 and Fetzer 2010\n[2017]. On the notion of probabilistic causality and the relative\ndebate see Hitchcock 1997 [2016] and Beebe, Hitchcock & Menzies\n(eds.) 2009. Salmon’s view of a causal process and Dowe’s\nconserved quantities theory are discussed in Dowe 2000. The debate on\nexplanation is surveyed in Woodward 2003 [2017]. \nCausal explanation, probability, and the Bayesian method are the key\ningredients of Salmon’s view of rationality, which is strictly\nentrenched with his version of realism. A further ingredient is the\nnotion of propensity taken as causal tendency (see\n § 2.3).\n Salmon’s “Rationality and Objectivity in Science”\n(1990d [2005]) defines three grades of rationality standing in\ndifferent relationships with objectivity. The first kind of\nrationality has no connection with objectivity and is identified with\nthe coherence of degrees of conviction, a key requirement of the\nBayesian method. This is called static rationality. Bayesian\nconditionalization, offering a tool to update one’s degree of\nconviction, shapes a stronger type of rationality called\nkinematic. The highest grade of rationality is called\ndynamic, and involves a closer connection with\nobjectivity. \nDynamic rationality is dealt with in some detail in “Dynamic\nRationality: Propensity, Probability, and Credence” (1988b\n[2005]). This kind of rationality revolves around the tenet that\nrational action must obey the maxim: Respect the frequencies.\nFor it to be accomplished, credence, or the degree of conviction\nleading to action, must be empirically informed, namely it should take\ninto account objective facts. Salmon holds that explanation has a\ncrucial role in that connection because causal knowledge of phenomena\nprovides the optimal basis for action. The notion of propensity is\ndeemed no less fundamental and is assigned the purpose of bridging the\ngap between objective probabilities, namely frequencies, and personal\nprobabilities on whose basis people act. Personal probabilities should\nnot be construed in a subjective sense, not only because for Salmon\nsubjectivism is not an admissible interpretation of probability\n (§ 2.3),\n but more generally because subjective opinions cannot be taken to\noffer good grounds for rational action. Rational action can only be\nbased on rational degrees of conviction, the emphasis being on\nrational as opposed to merely subjective. \nAs Salmon observed,  \nit is the operations of physical devices having […]\npropensities—chance setups, including our own actions—that\nproduce the actual short-run frequencies, on which our fortunes\ndepend, as well as the long-run frequencies which I am calling\nprobabilities. (Salmon 1988b [2005: 148])  \nAssigning a propensity to a chance setup amounts to making a causal\nhypothesis, which can be evaluated by means of Bayes’ rule.\nSince Salmon’s objective Bayesianism\n (§ 3.2)\n holds that prior probabilities are determined on the basis of\nobserved frequencies, the latter are the cornerstone on which the\nwhole procedure of confirming the hypotheses about propensities rests.\nTo sum up, dynamic rationality \nconsists in the attempt to use propensities—i.e., probabilistic\ncauses—as the weighting factors that occur in the formula for\nexpected utility. Since we cannot be sure that our choices and\ndecisions will be fully efficacious in bringing about desired results,\nit is reasonable to rely on the strengths of probabilistic causes.\nThis line of thought treats our voluntary choices, decisions, and\nactions as probabilistic causes of what happens as a result of our\ndeliberations. Dynamic rationality involves a\npropensity-driven view of objective probabilities and\nshort-run frequencies. (Salmon 1988b [2005: 150]) \nDeeply convinced of the tenability of scientific realism, Salmon\nargued in favor of its compatibility with empiricism. His argument\nrevolves around what he calls the key question, phrased as\nfollows:  \nDo we have empirical evidence that gives us just about as much reason\nto believe in the existence of such entities as molecules, atoms,\nions, and subatomic particles as we have for our belief in\nmiddle-sized material objects? (Salmon 2005: 32)  \nThe possibility of combining empiricism and realism is made to depend\non an affirmative answer to this question, which Salmon claimed had\nnot been given serious consideration by most philosophers of science,\nincluding van Fraassen, whose constructive empiricism implies a\nnegative answer to the key question, and therefore the incompatibility\nbetween empiricism and realism. \nIn order to provide an affirmative answer to the key question, Salmon\nonce again drew inspiration from Reichenbach’s work. In\nExperience and Prediction Reichenbach tackled the issue of\nour knowledge of the external world by means of a fictional example.\nHe imagined a “cubical world” whose inhabitants cannot\npenetrate either the walls or the ceiling, made of a translucent\nsubstance. In Salmon’s words: \nAs a result of a complicated arrangement of lights and mirrors,\nshadows of the birds outside of the cube are projected onto the\nceiling and the left-hand wall. The inhabitants of the cubical world\ncan see the shadows cast by the external birds, but they cannot see\nthe actual birds, mirrors, or lighting system. For beings in the\ncubical world, the birds are truly unobserved entities. (Salmon 1999:\n303) \nAfter careful observations, a scientist in the cubical world notices\nthere are correlations between the shadows on the ceiling and those on\nthe wall. After having repeatedly observed such correlations, the\nscientist infers the probabilistic hypothesis that there must exist\nsomething responsible for the shadows seen on the walls and ceiling.\nThe reasoning leading to that conclusion is nothing other than an\ninference to a common cause. Although the principle of the\ncommon cause (see\n § 5.4.1)\n was introduced by Reichenbach in The Direction of Time,\npublished posthumously in 1956, and does not appear at all in\nExperience and Prediction (1938), Salmon conjectured that the\nidea was already there, as testified by Reichenbach’s tenet that\nany physicist who happens to repeatedly observe some coincidences\n“will not believe in a matter of chance but will look for a\ncausal connection” (Reichenbach 1938: 121). \nFor Salmon, the fundamental role played by the principle of the common\ncause in connection with realism was testified by a great many\nexamples in the history of science, his favorite being Perrin’s\nascertainment of Avogadro’s number around 1912. As recounted by\nMary Jo Nye in Molecular Reality (1972), after Perrin showed\nthat Avogadro’s number could be determined by means of thirteen\ndifferent methods, all producing results in close agreement, the\ncommunity of physicists was convinced of the reality of atoms and\nmolecules. According to Salmon, Perrin’s conclusion was reached\nby means of an inductive reasoning which “can appropriately be\nschematized as a type of common cause argument” (Salmon 1985b\n[2005: 17]). From this and other examples Salmon concluded that a\npowerful method for inferring hypotheses from empirical evidence of\nregularities, the principle of the common cause provides a tool for\ninferring unobservables from observables. \nThis, however, is only part of the story. Salmon believed that the\nanswer to the key question “lies in connecting the common cause\nprinciple and Bayes’s theorem” (Salmon 1994a [2005: 25]).\nAlthough crediting him for having grasped the same idea, Salmon found\nReichenbach’s treatment incomplete, because it contains only\nsketchy remarks in that regard. He therefore set himself the task of\nworking out a detailed argument, spelled out in “Ornithology in\na Cubical World” (1999) and “An Empiricist Argument for\nRealism” published as Chapter 3 of Reality and\nRationality. In Salmon’s own words, his purpose was:  \nto show how the considerations that convinced serious physical\nscientists of the reality of atoms and molecules in the early years of\nthe twentieth century provide a philosophically sound argument for\nrealism that does not exceed the bounds of empiricism. (2005: x)  \nIn a nutshell, the fruitfulness of combining Bayes’ rule with\nthe principle of the common cause amounts to the fact that those\nhypotheses which embody information on common causes are apt to be\nassigned higher prior probabilities than hypotheses which involve mere\ncoincidences. \nSalmon reached this conclusion by scrutinizing the way scientists\nachieved a number of important findings, such as the existence of\natoms and molecules. His in-depth analysis of case studies belonging\nto the history of science, carried out with respect to both\nmicroscopic objects and the submicroscopic domain, confers on\nSalmon’s argument for realism a peculiar significance and\noriginality. \nFurther reading: The volume\nReality and Rationality (Salmon 2005) contains many articles\non Salmon’s views on rationality and realism.","contact.mail":"mariacarla.galavotti@unibo.it","contact.domain":"unibo.it"}]
