[{"date.published":"2020-01-13","url":"https://plato.stanford.edu/entries/physics-Rpcc/","author1":"Christopher Hitchcock","author2":"Miklós Rédei","author1.info":"http://hss.divisions.caltech.edu/people/christopher-r-hitchcock","entry":"physics-Rpcc","body.text":"\n\n\nThe Common Cause Principle was introduced by Hans\nReichenbach, in The Direction of Time, which was published\nposthumously in 1956. Suppose that two events A and B\nare positively correlated: \\(p(A\\cap B)>p(A)p(B)\\). Suppose,\nmoreover, that neither event is a cause of the other. Then,\nReichenbach’s Common Cause Principle (RCCP) states that A\nand B will have a common cause that renders them conditionally\nindependent. Reichenbach incorporated his RCCP into a new probablistic\ntheory of causation, and used it to describe a (purported)\nmacrostatistical temporal asymmetry in analogy with the second law of\nthermodynamics. The principle is significant because it posits a\nconnection between causal structure and probabilistic correlations,\nthus facilitating causal inference from observed correlations.\nHowever, RCCP has been controversial, and a number of counterexamples\nhave been proposed. RCCP is often seen as an antecedent of the\nCausal Markov Condition, which plays a central role in causal\nmodeling and causal inference. RCCP has also been taken to capture\nassumptions about the behavior of classical systems that appear to be\nviolated in quantum mechanics.\n\nThe Common Cause Principle (RCCP) was introduced by Hans\nReichenbach, in The Direction of Time, which was published\nposthumously in 1956. The principle posits a connection between causal\nstructure and probabilistic correlations between events. After\npresenting the principle in\n Section 2,\n we will provide some historical background in\n Section 3.\n The following two sections present some illustrations and alleged\ncounterexamples to RCCP.\n Section 6\n discusses Reichenbach’s fork asymmetry, a (putative)\ntemporal asymmetry in macrostatistical patterns that he associated\nwith RCCP.\n Section 7\n presents the Causal Markov Condition, which plays a central\nrole in causal modeling methods. The Causal Markov Condition is often\nseen as a modern successor of RCCP, and its relationship to RCCP will\nbe examined.\n Section 8\n will develop RCCP in a formal setting that is suitable for examining\nthe status of RCCP in quantum mechanics.\n Section 9\n and\n Section 10\n will then consider whether RCCP is compatible with quantum\nphysics. \nLet A and B be events. A storm, a person getting sick, a\nsoccer player scoring a goal, and a scientific measurement yielding a\nspecific result are all examples of events. Assume we can meaningfully\nassign probabilities to these events occurring. Reichenbach himself\ndeveloped a sophisticated frequency interpretation of probability\n(Reichenbach 1949), but we will assume only that some kind of\nobjective probability can be meaningfully applied. Suppose that events\nA and B are positively probabilistically correlated:\n \nThat is, the probability that both A and B\noccur is greater than the product of the individual probabilities.\nReichenbach’s Common Cause Principle says that when such a\nprobabilistic correlation between A and B exists, this\nis because one of the following causal relations exists: A is a\ncause of B; B is a cause of A; or A and\nB are both caused by a third factor, C. In the last\ncase, the common cause C occurs prior to A and B,\nand must satisfy the following four independent conditions:  \nwhere  \ndenotes the conditional probability of X on condition Y,\n\\(\\overline{C}\\) denotes the absence of event C (the negation\nof the proposition that C happens) and it is assumed that\nneither C nor \\(\\overline{C}\\) has probability zero. Line (2)\nsays that A and B are conditionally\nindependent, given C. In Reichenbach’s terminology,\nC screens A off from B. Line (3) says that\n\\(\\overline{C}\\) also screens A off from B. Lines (4)\nand (5) say that A and B are more probable, conditional\non C, than conditional on the absence of C. These\ninequalities are natural consequences of C being a cause of\nA and of B. Together, conditions (2) through (5)\nmathematically entail\n (1).\n The common cause can thus be understood to explain the correlation in\n(1). The probability relations described in lines (1) through (3)\nexhibit a version of Simpson’s Paradox. For more about\nthis probabilistic phenomenon, see the entry on\n Simpson’s Paradox. \nIt will often be helpful to represent such a common cause structure\ndiagrammatically, as in\n Figure 1.\n Arrows indicate causal relationships, and the vertical dimension\nrepresents time (with later times appearing higher up). \nFigure 1: A common cause structure.\nC occurs earlier than A and B, and C is a\ncause of A and B. \nRCCP says that probabilistic correlations are ultimately derived from\ncausal relationships. That is, if \\(p(A\\cap B)>p(A)p(B)\\), that is\neither because one of these events causes the other, or else the\ninequality can be derived from other inequalities \\(p(A|C) >\np(A|\\overline{C})\\) and \\(p(B|C) > p(B|\\overline{C})\\) where\nC is a cause of A and B. The principle is\nsignificant because it posits a connection between causal structure\nand probabilistic correlations that licenses inferences to causal\nrelationships from empirically observable correlations. \nAs formulated above, RCCP assumes that there are only two possible\nstates of the common cause: C and \\(\\overline{C}\\). That is,\nC is a binary event that is either present or absent. A natural\nextension of RCCP would be to allow the common cause to be a random\nvariable Z with many possible values \\(z_1,\\dots,z_n\\). In this\ncase we would expect that \\(Z = z_i\\) screens off A from\nB for \\(i=1,\\dots,n\\). However, this does not imply that we can\ndivide the values of Z into two sets \\(\\mathbf{S}\\) and\n\\(\\mathbf{S^\\prime}\\) such that \\(Z\\in \\mathbf{S}\\) (corresponding to\nC) and \\(Z \\in \\mathbf{S^\\prime}\\) (corresponding to\n\\(\\overline{C}\\)) each screen off A and B. More\ngenerally, we would not expect coarsenings of Z to yield events\nthat screen off A and B. \nOne corollary of this generalization is that if A and B\nhave two distinct binary common causes C and D, we would\nexpect each of \\(CD, C\\overline{D}, \\overline{C}D, \\overline{CD}\\) to\nscreen off A and B, but would not expect C and\nD to screen off A and B. For example, even if we\ncondition on the common cause C, we would expect A and\nB to be correlated because of the further common cause\nD. \nWe can further generalize to allow the correlated effects to be\nrandom variables instead of binary events. The fully general version\nof RCCP then reads as follows: \nSuppose X and Y are random variables that are\ncorrelated; i.e., there exist values \\(x_i\\) and \\(y_j\\) such that\n \nThen there exists a set of variables \\(Z_1,\\dots,Z_m\\), such that each\nvariable is a cause of X and Y, and \nfor all \\(i,j,k_1,\\dots,k_m\\) \nWith this generalization of RCCP, it is trickier to formulate analogs\nfor conditions 4 and 5 that capture in probabilistic terms the idea\nthat each variable \\(Z_k\\) is a cause of both X and Y.\nIn addition, this set of conditions will not strictly imply that\nX and Y are probabilistically correlated. We will return\nto these issues in\n Section 7. \nThe Direction of Time (Reichenbach 1956) was unfinished at\nthe time of Reichenbach’s death in 1953. The manuscript was\nedited by his wife Maria Reichenbach, and published posthumously in\n1956. The book was concerned with temporally asymmetric\nphenomena—phenomena that we associate with the distinction\nbetween the past and the future. It included major sections on the\nrole of time in classical physics, thermodynamics, statistical\nmechanics, and quantum mechanics. It also included a section on\ntemporal asymmetries in macrostatistics. Reichenbach had plans to\ninclude a final section on the subjective experience of time. \nThe book makes a number of important and original contributions. It\ncontains a detailed investigation into the philosophical foundations\nof statistical mechanics, especially examining the status of the\nsecond law of thermodynamics, which states that the entropy of a\nclosed system can increase, but never decrease. Reichenbach explored\nconnections between statistical mechanics and the new field of\ninformation theory—Shannon and Weaver’s classic book\n(1949) on the topic had been published just a few years earlier. In\naddition to the asymmetry of entropy increase described by the second\nlaw of thermodynamics, the book examined other temporally asymmetric\nphenomena. One of these was the asymmetry of records: We have detailed\nrecords of past events, including human memories and human made\ndocuments such as records and history books, but also including\nnatural phenomena such as fossils, tree rings, and geological strata.\nThese records provide us with a rich source of information about the\npast. We have no comparable source of information about the future,\nalthough we can reliably predict certain events, such as solar\neclipses. \nA third important temporal asymmetry is the asymmetry of cause and\neffect. Causes invariably precede their effects in time. Reichenbach\nattempted to analyze causal direction in terms of macrostatistics or\nprobability. He appealed to his notion of screening-off to define a\nrelation of causal betweenness, and also to define causal direction.\nIt is in this latter context that the RCCP was introduced. The\nconnection between RCCP and causal direction will be discussed in\n Section 6\n below. Reichenbach also formulated a probabilistic theory of\ncausation, and explored the connections between these new ideas and\nthe mark method for distinguishing causal direction, which he\nhad proposed much earlier (Reichenbach 1958). \nRCCP connects with a number of threads in Reichenbach’s thought.\nReichenbach had developed and defended a frequency interpretation of\nprobability (Reichenbach 1949), as well as a thoroughgoing\nprobabilistic epistemology (Reichenbach 1938) He had also explored the\nconnection between probability and causation in earlier works\n(Reichenbach 1925 [1978], 1930 [1978]). The Direction of Time\ntakes the project further in developing a probabilistic metaphysics.\nReichenbach had also explored the connection between causation and the\ndirection of time in Reichenbach (1925 [1978]) and Reichenbach (1958).\nThe latter work developed a causal theory of time in the context of\nrelativity theory. \nExample 1. The barometer and the storm (Jeffrey\n1969). \nFigure 2: The barometer and the storm.\n\\(A =\\) drop in atmospheric pressure; \\(B =\\) drop in mercury level in\nbarometer; \\(S =\\) storm. \nA drop in the level of mercury in a barometer is frequently followed\nby a storm. Call these events B and S, respectively.\nSince storms in general are not so frequent, these events are\nprobabilistically correlated: \\(p(B \\cap S) > p(B)p(S)\\). The\nbehavior of one barometer doesn’t affect the weather, so\nB is not a cause of S; rather, B and S\nhave a common cause: a drop in atmospheric pressure A (see\n Figure 2).\n A increases the probability of both B and S:\n \nMoreover, A will screen off B from S: \nand  \nFor example, if the atmospheric pressure drops, but the column of\nmercury in the barometer does not drop because the barometer is\nmalfunctioning, the probability of a storm is the same as it would be\nif the barometer were functioning properly. \nExample 2. The theatre troupe (Reichenbach\n1956). \nA small theatre troupe travels around the country putting on\nperformances. Occasionally, the leading man becomes seriously\nill—call this event M—and an understudy must take\nhis place. The same thing sometimes happens to the leading\nlady—L. Although both events are rare, they tend to occur\ntogether: \\(p(L \\cap M) > p(L)p(M)\\). The reason is that the actors\nusually eat together at the same restaurants, where they occasionally\nshare tainted food—T. See\n Figure 3. \nFigure 3: The theatre troupe. \\(T =\\)\nfood tainted at restaurant patronized by actors; \\(L =\\) leading lady\ngets sick; \\(M =\\) leading man gets sick. \nSuppose the probabilities are as follows: \nThen we can compute: \nThese calculations make use of the fact that T and\n\\(\\overline{T}\\) screen L off from M. We can also\ncompute: \nThus \nL and M are probabilistically correlated. \nSuppose that, on a given night, both the leading man and the leading\nlady are seriously ill. Can we infer that they ate tainted food? From\nthe probabilities above, we can compute \nWhile it is probable that they ate tainted food, it is by no means a\ncertainty. This example shows that the Common Cause Principle, by\nitself, does not license token-level causal inferences. That\nis, it does not tell us that when two effects A and\nB occur on a particular occasion, then their common cause\nC also occurred on this occasion. Instead, the Common Cause\nPrinciple licenses the inference from a probabilistic correlation to\nthe existence of a type-level common cause. \nExample 3. Language descent. \nCommon words in English that start with the letter ‘F’\noften have counterparts in Spanish that start with the letter\n‘P’: ‘foot’/‘pie’,\n‘fish’/‘pez’,\n‘father’/‘padre’, etc. One could quantify this\nby looking at canonical wordlists from both languages, and seeing how\noften words begin with ‘F’ in English and with\n‘P’ in Spanish. By treating the relative frequencies in\nthis list as probabilities, one would discover that there is indeed a\nprobabilistic correlation between the English word-initial\n‘F’ and Spanish word-initial ‘P’. \nThe explanation for this correlation is that English and Spanish are\ndescended from a common language, called Proto-Indo-European.\nSome, but not all, words in Proto-Indo-European began with a consonant\nwe can label [P/F], which evolved into ‘P’ in Romance\nlanguages (including Spanish), and ‘F’ in Germanic\nlanguages (including English). (Note that it is the phonetic\npronunciation, rather than the spelling that is of interest here; for\nexample, many German words whose spelling begins with ‘V’\nare counted for this purpose.) In the separate lineages leading from\nProto-Indo-European to English and to Spanish, Proto-Indo-European\nroots were retained for some words, but replaced for others. The roots\nwere retained often enough that the correlation can still be detected.\nMoreover, the two lineages evolved more or less independently after\nsplitting from Proto-Indo-European. Note that the common cause is not\nthe Proto-Indo-European language as a whole, and the effects are not\nEnglish and Spanish. It would make little sense to assign\nprobabilities to these languages (let alone a joint probability to\nEnglish and Spanish). Rather, the common cause is an initial consonant\n[P/F] in Proto-Indo-European; the effects are initial ‘F’\nin English and initial ‘P’ in Spanish. It makes sense to\nassign probabilities to these sounds, since we can count the frequency\nwith which words in these languages start with these sounds. See\n Figure 4. \nFigure 4: The descent of words with\ninitial consonant ‘F’ in English and initial consonant\n‘P’ in Spanish, from words with initial consonant [P/F] in\nProto-Indo-European. \nNote that the evidence of common descent between the two languages is\nthe correlation between the two sounds, rather than any\nphonetic similarity between them. For example, there is a recognized\ncorrelation between the Latin ‘du’ and Armenian\n‘erk’, as in ‘duo’/‘erku’\n(‘two’). Despite the differences in these sounds, the\ncorrelation is evidence of common descent (both are also Indo-European\nlanguages). \nFor further discussion of this example, see Hitchcock (1998). \nExample 4. Fried fish. \nBoth the British and the Japanese eat battered seafood that has been\ndeep-fried in oil: the British in the form of fish and chips, and the\nJapanese in the form of tempura. The technique of battering and\ndeep-frying seafood seems to have originated with Moors in the Iberian\nPeninsula in the thirteenth century, where the dish was called\nmu’affar. It spread to the Jewish and Christian\ninhabitants of Spain and Portugal. In the sixteenth century, Sephardic\nJews fleeing persecution took the recipe to Britain, and Portuguese\ntraders carried it to Japan. \nWhile it might be reasonable to call mu’affar the\ncommon cause of fish and chips and tempura, this is not an instance of\nthe Common Cause Principle. There are no probabilities involved in\nthis example, and there is no clear sense in which the British and\nJapanese both eating fried seafood is a probabilistic correlation.\nPerhaps one could construct a probabilistic model of global food\ndistribution that would supply such probabilities, but in the absence\nof such a model, we do not have an instance of RCCP. \nA number of authors have proposed counterexamples to the Common Cause\nPrinciple. A counterexample would involve two events A and\nB such that \nA and B are probabilistically correlated, \nneither event is a cause of the other, and \nthe correlation between A and B cannot be explained by a\ncommon cause, either because they have no common cause, or because\ntheir common cause does not screen them off from one another. \nOne type of case that is often said to violate the Common Cause\nPrinciple involves entangled states in quantum mechanics, such as\nthose found in Einstein-Podolski-Rosen (EPR) thought experiment. We\nwill discuss this case in detail in\n Section 10\n below. The present section will consider several other examples. As\nwe shall see, these examples typically raise questions about the\nproper scope and interpretation of the Common Cause Principle, rather\nthan refuting the principle outright. \nExample 5. Cartwright’s factory. \nCartwright (1999: 108–109) asks us to imagine a factory that\nproduces a chemical, C, that is used in sewage treatment. The\nfactory employs a genuinely indeterministic process, so that when the\nprocess is initiated, I, there is a probability of .8 that the\nchemical is produced. However, whenever the chemical is produced, the\nfactory also releases a pollutant, P as a by-product. Thus \nNeither C nor P cause the other. \nGlymour (1999) objects that such a factory is nowhere to be found.\nThis raises a question about the status of the Common Cause Principle.\nIf the principle is intended to be a conceptual truth about the\nrelationship between causation and probability, then we could\nundermine the principle by showing that a causal structure that\nviolates it can be clearly conceived. On the other hand, if the\nprinciple is intended to be an empirical generalization about the\nrelationship between causation and probability in the actual world,\nthen Glymour is right to demand more than a hypothetical example. \nExample 6. Random darts. \nSuppose that darts are shot at a dart board using an indeterministic\nprocess that can hit any part of the board. (If the reader is not\ncomfortable with indeterministic darts, she may imagine photons\nhitting a scintillation screen after passing through a narrow slit.)\nSuppose that A and B\nare two regions of the dart board such that\nA is fully contained within B,\nand B does\nnot fill the entire board (see\n Figure 5(a)).\n Let A be the event corresponding to the dart landing in region\nA, and analogously for B. Then\nwe will have: \nThis follows because \\(A \\cap B = A\\) and \\(p(B) < 1\\). While the\nthrow of the dart (or whatever process launches the dart) is a common\ncause of A and B, this will not screen them off. And if\nthe process is genuinely indeterministic, there will be no cause that\nscreens them off. \nFigure 5: The large circle represents\nthe dart board. Circles A and B\nare regions of the dartboard. In (a) the\nregion A is entirely contained in the\nregion B. In (b) the regions almost\n(but not quite) completely overlap.  \nDavid Lewis famously tried to analyze causation in terms of\ncounterfactuals (Lewis 1973). He recognized that in order for his\ntheory to succeed, he needed to restrict the analysis to\ncounterfactual relations among distinct events (see\nespecially Lewis 1986). For instance, we typed the word “Lewis”\nnear the beginning of this paragraph. If we had not typed the letters\nL-e-w, then we would not have typed the word “Lewis”. But typing\nthe letters L-e-w did not cause us to type “Lewis”.\nTyping L-e-w was part of the act of typing “Lewis”. The\nevents typing L-e-w and typing “Lewis” are not\ndistinct from one another in the right kind of way to stand\nin causal relations to each other. Lewis’s account of\ndistinctness is somewhat involved, but it specifically excludes\nrelations of logical entailment and spatiotemporal inclusion. \nIt appears that the Common Cause Principle requires a similar\nrestriction to distinct events. In our example of the dart board, the\nregion A is spatially included within\nthe region B; hence, the events\nA and B will not be distinct, in Lewis’s sense.\nThis means that there may be correlations between these events that\nare entirely due to their spatiotemporal relationship, and don’t\nhave any distinctively causal basis. \nNow suppose that the regions A and\nB almost completely overlap, but\nneither is contained within the other (see\n Figure 5(b)).\n Again, the corresponding events A and B will be\ncorrelated, and the earlier common cause may not screen them off.\n(Arntzenius (1999 [2010: section 2.4]) has an example that has\nessentially this structure.) It seems that this case, too, is one in\nwhich the events A and B are insufficiently distinct.\nBut now it becomes difficult to formulate a notion of distinctness\nthat is sufficiently general, without ruling out too much. To see the\nproblem, imagine that instead of a literal dartboard, we have a Venn\ndiagram representing the possible states of a system that evolves\nindeterministically. The spatial regions A\nand B now\nrepresent sets of possible states, corresponding to the states in\nwhich events A and B occur. And the area corresponds to\nprobability. Thus the set of states in which A occurs almost\ncompletely overlaps with the set of states in which B occurs,\nas measured by the probability distribution over states. Is this a\nreason to think that A and B are not distinct? It had\nbetter not be, because this is just a representation of the generic\ncase where events A and B are probabilistically\ncorrelated. Thus spelling out the precise notion of\ndistinctness at work remains a challenge. \nExample 7. Conserved quantities. \nSalmon (1984) and Schurz (2017) argue that systems governed by\nprobabilistic dynamics together with conservation laws will give rise\nto violations of RCCP. Suppose that a brick weighing 2 kg falls onto a\nhard, peaked surface. The brick cracks and breaks into two pieces,\nA and B.\nSuppose that this process is genuinely chancy. Perhaps the precise\npoint at which the brick strikes the surface, or the precise process\nof crack formation in the brick, is not determined by earlier states\nof the system. Let A be the event corresponding to piece A\nweighing some specific amount, say 1.2 kg,\nand let B be the event corresponding to piece B\nweighing the complementary amount, say 0.8\nkg. Since the combined mass must be 2 kg, A will occur if and\nonly if B occurs. Since the process is chancy, \\(p(A) = p(B) =\nr < 1\\). However,  \nso A and B are correlated. No earlier event can screen\noff this correlation unless it determines that A and B\nwill occur. Since the process is genuinely chancy, there is no such\nevent. Hence RCCP is violated. \nWhether there are any actual violations of RCCP having this form\ndepends on whether there are actual processes governed by\nprobabilistic dynamics and conservation laws. We don’t find such\nprocesses described by classical physics. We do encounter this\ncombination already in quantum mechanics, at least on some\ninterpretations (so-called collapse interpretations). However, these\ncases are further complicated by the role of quantum\nentanglement. We discuss the status of the Common Cause\nPrinciple in quantum mechanics in greater detail in sections 9 and 10\nbelow. \nExample 8. Time series. \nSober (2001) notes that sea levels in Venice and bread prices in\nLondon have both been rising over the past few centuries. Let V\nrepresent Venetian sea levels higher than some specified level, and\nL London bread prices higher than a given mark. If we sample\nVenetian sea levels and London bread prices over time, we will find\nthat V and L are correlated: In years where V\nobtains, L tends to obtain as well (since these will tend to be\nmore recent years). However, we have no reason to think that these\nphenomena share a common cause. They appear to be causally\nindependent. \nTo understand what is going on in this example, we need to look more\nclosely at the relationship between sample statistics and underlying\nprobability distributions. We frequently think about this in terms of\na classic urn model. An urn contains a certain proportion of black and\nwhite balls. We draw balls from the urn, and use the frequency of\nblack balls drawn to estimate the proportion of black balls in the\nurn. Using statistical frequencies to estimate probabilities in this\nway typically requires an assumption that the samples are\nprobabilistically independent: drawing a black ball does not affect\nthe probability that the next ball drawn will be black. Sober’s\nexample involves what statisticians call a time series. When\nwe sample Venetian sea levels over the course of years, we are not\ndrawing probabilistically independent samples from a stable\nprobability distribution. If the sea level is high in a particular\nyear, we can predict that the sea level will be similarly high the\nfollowing year (they tend not to change dramatically from one year to\nthe next). For this reason, we cannot interpret the relative\nfrequencies that we obtain as estimates of an underlying probability\ndistribution. Thus, even though there is a correlation between\nV and L in our samples, it is impossible to interpret\nthis as a probabilistic correlation with  \\(p(V \\cap L) > p(V)p(L)\\). Not all correlations in\nstatistical samples bespeak probabilistic correlations. (See\nalso Hoover 2003 and Steel 2003 for further discussion of\nSober’s example.) \nThis defense of the Common Cause Principle raises a worry, however.\nMany cases where we would like to apply the Common Cause Principle may\nalso turn out to behave like time series. For example, consider\nReichenbach’s example of the traveling theatre troupe\n (Example 2\n above). It is reasonable to expect that if the leading man is sick on\na particular day, then he will be more likely to be sick on the\nfollowing day—some illnesses last more than a day. And if he is\nexposed to a particular pathogen at one time, he may gain immunity\nagainst that pathogen in the future. If we exclude all such examples,\nthen we run the risk of excluding many of the standard examples that\nare supposed to lend support to the principle. \nReichenbach’s Direction of Time (1956) was centrally\nconcerned with temporally asymmetric phenomena. Much of the work is\ndevoted to the status of the Second Law of Thermodynamics, which says\nthat in a closed system, entropy can increase but will never decrease.\nBut Reichenbach also tried to define a macroscopic statistical\nasymmetry using the Common Cause Principle. Suppose that events\nA and B are correlated, i.e., that \\(p(A \\cap B) >\np(A)p(B)\\). If there is an event C that satisfies conditions\n (2)–(5)\n above, Reichenbach called the trio ACB a conjunctive\nfork. If C occurs earlier than A and B, and\nthere is no event satisfying (2)–(5) that occurs later than\nA and B, then ACB is said to form a conjunctive\nfork open to the future (see\n Figure 6(a)).\n \nFigure 6: (a) Conjunctive fork open to\nthe future. (b) Conjunctive fork open to the past. (c) Closed fork.\n[An\n extended description of figure 6\n is in the supplement.]  \n Analogously, if there is a later event satisfying (2)–(5), but\nno earlier event, we have a conjunctive fork open to the past\n (Figure 6(b)).\n If an earlier event C and a later event D both satisfy\n(2)–(5), then ACBD forms a closed fork\n (Figure 6(c)).\n Reichenbach claimed that in our world, there are a great many forks\nopen to the future, but few or none open to the past. Moreover, he\nproposed that the direction from cause to effect could be grounded in\nthis statistical asymmetry. \nReichenbach saw his fork asymmetry as a macro-statistical analog of\nthe second law of thermodynamics. Suppose we have a system such as a\ngas that is made up of a large number of particles. Each particle can\nbe in one of many possible states \\(s_1,\\dots,s_n\\). Let \\(p_i\\) be\nproportion of the particles that are in state \\(s_i\\). Then one\nexpression for the entropy of the system is \\(S = {-}\\sum_i\np_i log(p_i)\\). This sum will reach a maximum when the particles are\nevenly distributed among the n states (or distributed as evenly\nas possible given constraints on the system). The second law of\nthermodynamics states that the entropy of a closed system can increase\nbut never decrease; hence it will evolve toward a state of maximum\nentropy. Reichenbach claims that if we find a closed system in a state\nof low entropy, we can infer that it was recently prepared in that\nstate, before being closed off from the rest of the environment. \nNow suppose that we have two events A and B, and a\nprobability distribution p over the four states \\(AB\\),\n\\(A\\overline{B}\\), \\(\\overline{A}B\\), \\(\\overline{A} \\overline{B}\\).\nWe can apply the formula for entropy to this probability distribution;\nholding the probability of A and B fixed, the entropy\nwill be highest when A and B are probabilistically\nindependent. Thus, when we find a correlation between A and\nB, this is like finding a system in a state of low entropy, and\nwe should look for some event in the past of A and B to\nexplain this correlation. This is only a formal analogy, but\nReichenbach attempted to show that the same basic principles that give\nrise to the second law of thermodynamics would also give rise to the\nCommon Cause Principle. For more discussion, see the entry on\n thermodynamic asymmetry in time. \nReichenbach’s fork asymmetry has been subjected to numerous\ncriticisms. Horwich (1987) argues that our willingness to infer a past\ninteraction often has little to do with entropy. We may infer from a\npile of rubble that a city has been bombed. A pile of rubble\ncorresponds to higher entropy than intact buildings; but it is the\nformer, rather than the latter, that leads us to infer that a certain\nkind of interaction with the city has taken place. \nFigure 7:  \\(\\mathcal{S}\\) is the entire\nstate space. Three copies of \\(\\mathcal{S}\\) are shown, corresponding\nto times 0, t, and \\(t^\\prime > t\\). If the system is in state\ns at time 0, it will be in state \\(U_t(s)\\) at time t,\nand state \\(U_{t^\\prime}(s)\\) at time \\(t^\\prime\\). The set of states\ncorresponding to event C will evolve into \\(U_t(C)\\) and\n\\(U_{t^\\prime}(C)\\). [An\n extended description of figure 7\n is in the supplement.] \nArntzenius (1990) points out that the fork asymmetry is highly\nproblematic in the context of classical statistical mechanics within\nwhich Reichenbach was working. Let \\(\\mathcal{S}\\) be a state-space\ncontaining all possible states of a physical system (see\n Figure 7).\n The state of a system s at a particular time t will\ninvolve the specification of parameters, such as the positions and\nmomenta of all the particles in the system. The system evolves\ndeterministically, so that for every time time t, if the system\nwas in state s at time 0, it will be in state \\(U_t(s)\\) at\ntime t, where each \\(U_t\\) is a one-one function from\n\\(\\mathcal{S}\\) into itself. An event such as C corresponds to\na subset of \\(\\mathcal{S}\\): the set of states in which C\noccurs. We can then define \\(U_t(C)\\) to be the set of states of the\nform \\(U_t(s)\\), where \\(s \\in C\\). \nA probability function p on \\(\\mathcal{S}\\) at time 0 can then\nbe extended to a probability distribution over trajectories through\n\\(\\mathcal{S}\\), yielding probabilities for events at later times. \nSuppose that C occurs at time 0, and A and B\noccur at later time t. Suppose, moreover, that ACB forms\na conjunctive fork. Then we can evolve the set of microstates in\nC forward to time \\(t^\\prime > t\\). Then \\(D =\nU_{t^\\prime}(C)\\) will occur after A and B, but stand in\nthe same probabilistic relationship to A and B that\nC does (see\n Figure 8).\n Thus ACBD will form a closed fork. Since this recipe is\nperfectly general, it seems that every conjunctive fork ACB\nwith C earlier than A and B must belong to a\nclosed fork ABCD. \nFigure 8: Event D at time\n\\(t^\\prime\\) results from evolving C forward from time 0 to\n\\(t^\\prime\\). It will stand in the same probabilistic relationship to\nevents A and B at time t that C did at\ntime 0. [An\n extended description of figure 8\n is in the supplement.]  \nA natural response to this worry is to propose that the earlier set of\nstates C will be sufficiently coherent to form a natural event,\nwhile the later set of states D will be a heterogeneous\ncollection, having nothing in common except for the fact that they all\nevolved states in C. Such a heterogeneous collection of states\nwould not qualify as an event—see, e.g., Lewis (1986)\nfor discussion of what qualifies as a genuine event. Hence, there is\nan earlier event that screens off A and B, but no later\nevent that does so. However, the framework of statistical mechanics\ngives us no principled reason for thinking that in all such cases, the\nearlier screening off event will be coherent enough to be a proper\nevent, while the later screener will not be. Moreover, Arntzenius\n(1990) offers a counterexample to one way of making this proposal\nprecise. \nWe will also see in Section 7 that the modern theory of causal\nmodeling does not use conjunctive forks to determine the direction of\ncausation, but rather uses a probabilistic pattern that is essentially\nthe exact opposite of a conjunctive fork. \nReichenbach’s Common Cause Principle is closely related to the\nCausal Markov Condition that is commonly employed in causal\nmodeling. A version of the Causal Markov Condition was first\nproposed by Kiiveri, Speed, and Carlin (1984). Detailed programs in\ncausal modeling featuring the Causal Markov Condition have been\ndeveloped by Pearl (2009) and Spirtes, Glymour and Scheines\n(2000). \nWe will describe here just one kind of causal model, the causal\nBayes net. A causal Bayes net uses a directed acyclic\ngraph (DAG) to represent causal relations among a set of\nvariables, and pairs it with a probability distribution over the set\nof variables. More precisely, a causal Bayes net is a triple\n\\((\\mathbf{V}, \\mathcal{G}, p)\\), where \\(\\mathbf{V}\\) is a set of\nvariables, \\(\\mathcal{G}\\) is a directed acyclic graph over\n\\(\\mathbf{V}\\), and p is a probability distribution over the\nfield of events generated by \\(\\mathbf{V}\\). The variables in\n\\(\\mathbf{V}\\) correspond to the properties of individuals in some\npopulation. For example, in a population of American adults, we might\nhave variables representing an individual’s education level,\nwork experience, and present income. A variable can be binary,\nrepresenting the presence or absence of some property, but it can also\nbe multiple-valued or continuous. \n\\(\\mathcal{G}\\) is a set of ordered pairs of variables in\n\\(\\mathbf{V}\\). If \\((X, Y) \\in \\mathcal{G}\\), we represent this\ngraphically by drawing an arrow from X to Y, and we say\nthat X is a parent of Y. If there are arrows\nfrom \\(X_{1}\\) to \\(X_{2}\\), \\(X_{2}\\) to \\(X_{3}\\),… and\n\\(X_{n-1}\\) to \\(X_{n}\\), then there is a directed path from\n\\(X_{1}\\) to \\(X_{n}\\). In this case, we say that \\(X_{n}\\) is a\ndescendant of \\(X_{1}\\). \\(\\mathcal{G}\\) is acyclic if there\nis no directed path from any variable to itself.\n Figure 9\n shows a DAG on the variable set \\(\\{U, V, W, X, Y, Z\\}\\). In this\nDAG, there is a directed path from U to Z, and Z\nis a descendant of U. \\(\\PA(X)\\) is the set of all parents of\nX and \\(\\ND(X)\\) is the set of all variables in \\(\\mathbf{V}\\)\nother than X and its descendants. In\n Figure 9,\n \\(\\PA(W) = \\{U, V\\}\\) and \\(\\ND(W) = \\{U, V, X\\}\\). \nA DAG represents the qualitative causal structure among the set of\nvariables in an individual from the relevant population. In\nparticular, an arrow from X to Y indicates that X\nhas a causal influence on Y that is not mediated by any other\nvariables in the set. In this case, we say that X is a direct\ncause of Y. \nFigure 9: A DAG on the variable set\n\\(\\{U, V, W, X, Y, Z\\}\\). \\(\\PA(W) = \\{U, V\\}\\) is the set of parents\nof W and \\(\\ND(W) = \\{U, V, X\\}\\) is the set of non-descendants\nof W. [An\n extended description of figure 9\n is in the supplement.]  \nThe Causal Markov Condition connects the graph \\(\\mathcal{G}\\) with\nthe probability distribution p over the algebra generated by\nthe variables. It says that p must exhibit specific relations\nof conditional probabilistic independence that are implied by the\ngraph. In the special case where \\(\\mathcal{G}\\) is a DAG, the\nfollowing three formulations of the Causal Markov Condition are\nequivalent: \nCausal Markov Condition: Screening off version. \nFor every variable X in \\(\\mathbf{V}\\), and every set of\nvariables \\(\\mathbf{Y} \\subseteq \\ND(X):\\) \nWe employ a notational convention where statements involving variables\nare understood to involve universal quantification over values of\nthose variables (or over measurable sets of values). This version of\nthe Causal Markov Condition says that the parents of variable X\nscreen X off from all other variables, except for X\nitself and the descendants of X. Given the values of the\nvariables that are parents of X, the values of the variables in\n\\(\\mathbf{Y}\\) make no further difference to the probability that\nX will take on any given value. This version of the Causal\nMarkov Condition is closest in form to Reichenbach’s Common\nCause Principle, although it is formulated in terms of the parents of\nX, rather than the common cause(s) of X and\nY. \nCausal Markov Condition: Factorization version. \nLet \\(\\mathbf{V} = \\{X_{1}, X_{2}, \\dots, X_{n}\\}\\). Then: \nThis version tells us that once we know the conditional probability\ndistribution of each variable given its parents,\n\\(p(X_{i}|\\PA(X_{i}))\\), we can compute the complete joint\ndistribution over all of the variables. This captures\nReichenbach’s idea that probabilistic correlations between\nevents can ultimately be derived from probabilistic correlations\nresulting from cause and effect relationships. \nCausal Markov Condition: d-separation\nversion. \nLet \\(\\mathbf{X}, \\mathbf{Y},\\) and \\(\\mathbf{Z}\\) be disjoint subsets\nof \\(\\mathbf{V}\\). Then: \nif \\(\\mathbf{Z}\\) d-separates \\(\\mathbf{X}\\) and\n\\(\\mathbf{Y}\\) in \\(\\mathcal{G}.\\) \nThis version introduces the graphical notion of d-separation.\nA path from X to Y is a sequence of variables \\((X =\nX_{1},\\dots, X_{k} = Y)\\) such that for each \\(X_{i}\\), \\(X_{i+1},\\) there\nis either an arrow from \\(X_{i}\\) to \\(X_{i+1}\\) or an arrow from\n\\(X_{i+1}\\) to \\(X_{i}\\) in \\(\\mathcal{G}\\). For example, in\n Figure 9,\n \\(\\{U, Y, W, V, X\\}\\) forms a path. A variable \\(X_{i}\\), \\(1 < i <\nk\\) is a collider on the path just in case there is an arrow\nfrom \\(X_{i-1}\\) to \\(X_{i}\\) and from \\(X_{i+1}\\) to \\(X_{i}\\). In\nother words, \\(X_{i}\\) is a collider just in case the arrows converge\non \\(X_{i}\\) in the path:  in\n Figure 9,\n Y is a collider on the path \\(\\{U, Y, W, V, X\\}.\\) Let\n\\(\\mathbf{X}, \\mathbf{Y}\\), and \\(\\mathbf{Z}\\) be disjoint subsets of\n\\(\\mathbf{V}\\). \\(\\mathbf{Z}\\) d-separates \\(\\mathbf{X}\\) and\n\\(\\mathbf{Y}\\) just in case every path \\((X_{1}, \\dots, X_{k})\\) from\na variable in \\(\\mathbf{X}\\) to a variable in \\(\\mathbf{Y}\\) contains\nat least one variable \\(X_{i}\\) such that either: (i) \\(X_{i}\\) is a\ncollider, and neither \\(X_{i}\\) nor any descendant of \\(X_{i}\\) is in\n\\(\\mathbf{Z}\\); or (ii) \\(X_{i}\\) is not a collider, and \\(X_{i}\\) is\nin \\(\\mathbf{Z}\\). In\n Figure 9,\n \\(\\{U, V\\}\\) d-separates \\(\\{Y\\}\\) and \\(\\{X\\}\\). The path\n\\(\\{Y, W, Z, X\\}\\) contains a collider at Z, and all other\npaths from Y to X include U or V as a\nnon-collider. \nThe Causal Markov Condition implies the generalized version of RCCP\npresented in\n Section 2.\n This is most easily seen using the d-separation version. If\nvariables X and Y are correlated, then \\(\\{X\\}\\) and\n\\(\\{Y\\}\\) are not d-separated by the empty set. This means\nthat at least one path between X and Y must be without a\ncollider. If we further assume that neither variable is a cause of the\nother, then there is no directed path between them. It then follows\nthat the collider-free path must contain a common cause: a variable\nZ that has both X and Y as descendants.\nFurthermore, the set of all such common causes d-separates\n\\(\\{X\\}\\) and \\(\\{Y\\}\\). (The proof is a bit fussy, since a common\ncause on one path can be a collider on another path.) Hence the set of\ncommon causes of X and Y will screen them off from one\nanother. \nNote that the Causal Markov Condition tells us that certain causal\nstructures give rise to relations of conditional probabilistic\nindependence. The Causal Markov Condition never entails\nprobabilistic dependence. For purposes of causal inference,\nthe Causal Markov Condition is often supplemented by a further\nprinciple governing when probabilistic dependence is to be expected.\nOne such principle is the Faithfulness Condition (Spirtes et\nal. 2000) which says that only the probabilistic\nindependencies entailed by the Causal Markov Condition are present.\nLooked at another way, the Faithfulness Condition says that when we\nfind a relation of conditional probabilistic independence, we should\ninfer a causal structure that entails that independence relation\nrather than one that doesn’t. \nOne justification for assuming the Causal Markov Condition is a\ntheorem due to Pearl and Verma (1991). Suppose that we have a variable\nset \\(\\mathbf{V}\\), and DAG \\(\\mathcal{G}\\) representing the causal\nrelations among the variables in \\(\\mathbf{V}\\). Suppose, in addition,\nthat the value of each variable X in \\(\\mathbf{V}\\) is a\ndeterministic function of its parents in \\(\\mathbf{V}\\), together with\nan error variable \\(U_{X}\\), which represents the influence\nof any variables that are not included in \\(\\mathbf{V}\\). In other\nwords, \\(X = f_{X}(\\PA(X), U_{X})\\). Then the values of all of the\nerror variables will uniquely determine the value of all of the\nvariables in \\(\\mathbf{V}\\), and a probability distribution \\(p^{*}\\)\nover the error variables will induce a probability distribution\np over the variables in \\(\\mathbf{V}\\). If the error variables\nare independent in \\(p^{*}\\), then the induced probability\ndistribution p will satisfy the Causal Markov Condition with\nrespect to \\(\\mathcal{G}\\). The idea is that if we include enough\nvariables in \\(\\mathbf{V}\\) so that any remaining causal influences\nare probabilistically independent of one another, then the probability\ndistribution over \\(\\mathbf{V}\\) will satisfy the Causal Markov\nCondition. \nA set of variables \\(\\mathbf{V}\\) is causally sufficient if\nthere is no variable W omitted from \\(\\mathbf{V}\\), such that\nif it were added to \\(\\mathbf{V}\\), it would be a direct cause of two\nvariables in \\(\\mathbf{V}\\). In\n Figure 9,\n \\(\\{U, W, Y\\}\\) is causally sufficient (assuming the original DAG\nis), but \\(\\{U, W, Y, Z\\}\\) is not, since W and Z have a\ncommon cause, V, that is left out of this set. \nIt is usually assumed that if a variable set is causally sufficient,\nthen the error variables will be probabilistically independent, and\nthe probability distribution over \\(\\mathbf{V}\\) will satisfy the\nCausal Markov Condition with respect to the true causal graph. Note\nthat this assumption is very similar to the Common Cause Principle\nitself. If X and Y are variables included in a causally\nsufficient DAG, and \\(U_X\\) and \\(U_Y\\) are their corresponding error\nvariables, then neither \\(U_X\\) nor \\(U_Y\\) is a cause of the other,\nand they do not have a common cause. If they had a common cause, this\nwould be a common cause of X and Y; if \\(U_X\\) is a\ncause of \\(U_Y\\), then \\(U_X\\) is a common cause of X and\nY. So the causal sufficiency of the variable set implies that\n\\(U_X\\) and \\(U_Y\\) are causally unrelated. The Common Cause Principle\nwould then imply that they are probabilistically independent. Thus it\nwould be inaccurate to say that the Causal Markov Condition can be\nused to justify the Common Cause Principle: both involve\ncomparable assumptions about the relationship between causation and\nprobability. \nExamining the d-separation version of the Causal Markov\nCondition, we see that it is not common causes but rather colliders\nthat give rise to distinctive probabilistic relationships. Suppose\nthat we have a variable set with three variables \\(\\{X, Y, Z\\}\\), and\nthat the probability distribution p satisfies the Causal Markov\nCondition with respect to the true causal graph. Finally, suppose that\nX and Z are correlated, but screened off by Y.\nThen there are three different causal graphs that all imply just this\nset of probabilistic independence relations: \nThe last of these, of course, is the Common Cause Structure\ncharacterized by Reichenbach. (However, Reichenbach also postulated\nthat intermediate causes would screen off distal causes from their\neffects, as indicated in the first two diagrams.) On the other hand,\nsuppose the relations of probabilistic (in)dependence are exactly the\nopposite. That is: X and Z are probabilistically\nindependent, but dependent conditional on Y. In this case,\nthere is only one causal structure that implies just this set of\nprobabilistic independence relations: \nIndeed, algorithms for inferring causal structure from relations of\nconditional probabilistic dependence and independence, such as the\nPC algorithm of Spirtes et al. (2000), proceed by searching\nfor this type of probabilistic signature. Thus Reichenbach was\nmistaken in looking to conjunctive forks to define the direction of\ncausation (see\n Section 6\n above). He would have done better to look to colliders. \nA classical probability measure space is a triplet \\((X,{\\cal S},p)\\),\nwhere X is the set of elementary random events, \\({\\cal S}\\) is\na Boolean algebra of some subsets of X and p is the\nadditive probability measure from \\({\\cal S}\\) into the unit interval\n\\([0,1]\\). The probability measure space \\((X,{\\cal S},p)\\) is called\ncommon cause complete if there exists a common cause C\nin \\({\\cal S}\\) of every correlated pair \\((A,B)\\) of elements \\(A,B\\)\nin \\({\\cal S}\\), common cause incomplete otherwise. One can\nshow that common cause (in)completeness can be characterized in terms\nof the measure theoretic (non)atomicity of probability measure spaces:\n\\((X,{\\cal S},p)\\) is common cause complete if and only if \\((X,{\\cal\nS},p)\\) contains at most one measure theoretic atom (Gyenis &\nRédei 2011). A measure theoretic atom is an element \\(A_0\\) in\n\\({\\cal S}\\) such that \\(p(A_0)\\not=0\\), and, if \\(B\\subset A_0\\),\nthen \\(p(B)=0\\). In particular measure theoretically purely non-atomic\nprobability measure spaces (i.e., probability spaces that do not\ncontain any measure theoretic atom) are common cause complete (Gyenis\n& Rédei 2011; Hofer-Szabó et al. 2013; Marczyk &\nWroński 2015). An example of a measure theoretically purely\nnon-atomic probability measure space is the unit interval \\([0,1]\\)\nwith the uniform probability (Lebesgue measure) on the Lebesgue\nmeasurable subsets of \\([0,1]\\); a class of examples are probability\nmeasures on the (Lebesgue measurable subsets of the) real line where\nthe probability is given by a density function with respect to the\nLebesgue measure on the real line. \nA common cause incomplete probability space \\((X,{\\cal S},p)\\) is\ncalled common cause completable if it can be embedded into a\nlarger probability space \\((X',{\\cal S}',p')\\) that is\ncommon cause complete. An embedding of \\((X,{\\cal S},p)\\) into\n\\((X',{\\cal S}',p')\\) is an injective Boolean algebra\nhomomorphism h from \\({\\cal S}\\) into \\({\\cal S}'\\) such\nthat \\(p'(h(A))=p(A)\\) for all A in \\({\\cal S}\\). One can\nshow that every probability space \\((X,{\\cal S},p)\\) can be embedded\ninto a purely nonatomic probability space. This entails that every\ncommon cause incomplete probability space is common cause completable\n(Gyenis & Rédei 2011; Hofer-Szabó et al. 2013;\nMarczyk & Wroński 2015). \nIn quantum theory one uses non-classical (quantum) probability spaces\nto describe quantum physical systems. A general quantum probability\nspace is a pair \\(({\\cal P} ({\\cal N}),\\phi)\\), where \\({\\cal P}\n({\\cal N})\\) is the orthocomplemented, orthomodular lattice of\nprojections of a non-commutative von Neumann algebra \\({\\cal N}\\) and\n\\(\\phi\\) is a countably additive probability measure on \\({\\cal P}\n({\\cal N})\\), which is the restriction to \\({\\cal P} ({\\cal N})\\) of a\nnormal state on \\({\\cal N}\\). Rédei & Summers (2007a)\nprovides a brief description of non-commutative probability theory in\nterms of von Neumann algebras; Landsman (2017) contains an\nencyclopedic treatment of the algebraic structures relevant for\nquantum theory; the SEP entry on\n quantum theory and mathematical rigor\n gives a very brief informal introduction to some basic facts on von\nNeumann algebras, including their Murray-von Neumann classification,\nwhich is relevant from the perspective of the Common Cause\nPrinciple—see below). A special example of a quantum probability\nspace is obtained by taking the set of all bounded operators \\({\\cal\nB} ({\\cal H} )\\) on a (possibly infinite dimensional) Hilbert space\n\\({\\cal H}\\) as the von Neumann algebra and \\(\\phi\\) a quantum state\ngiven by a density matrix. The resulting specific quantum probability\nspace \\(({\\cal P}({\\cal B}({\\cal H})),\\phi)\\) is known as the\n“Hilbert space formalism” of quantum mechanics; this space\ndescribes quantum systems of finite degrees of freedom. The\northomodular lattice \\({\\cal P}({\\cal B}({\\cal H}))\\), frequently\ndenoted as \\({\\cal P} ({\\cal H})\\), is the set of all projections on\n\\({\\cal H}\\), this lattice is also called “Hilbert\nlattice”. \nThe concept of correlation between commuting projections \\(A,B\\) in\n\\({\\cal P} ({\\cal N})\\) and the notion of common cause of such\ncorrelations as a projection C commuting with both A and\nB and satisfying the (analogues) of the\n four Reichenbachian conditions (2)–(5)\n make perfect sense in quantum probability spaces. So do the concepts\nof common cause (in)completeness, common cause completability (with a\nsuitably defined embedding of orthomodular lattices), measure\ntheoretic atoms and measure theoretic non-atomicity. \nOne can show that common cause completeness of such quantum\nprobability spaces can be characterized in terms of measure theoretic\natomicity of \\(({\\cal P} ({\\cal N}),\\phi)\\) in complete analogy with\nthe classical case: \\(({\\cal P} ({\\cal N}),\\phi)\\) is common cause\ncomplete if it contains at most one measure theoretic atom (Kitajima\n2008; Gyenis & Rédei 2014; Kitajima & Rédei\n2015). This entails that measure theoretically purely non-atomic\nquantum probability spaces are common cause complete. Specifically,\nquantum probability spaces \\(({\\cal P} ({\\cal N}),\\phi)\\) with a type\nIII or type II von Neumann algebra \\({\\cal N}\\) are common cause\ncomplete because the quantum probability spaces defined by these types\nof von Neumann algebras are purely measure theoretically non-atomic.\nThe quantum probability space \\(({\\cal P} ({\\cal H}),\\phi)\\) is not\npurely nonatomic, it contains a lot of measure theoretic atoms: all\nthe rank-one projections (equivalently: one dimensional linear spaces\nspanned by vectors in \\({\\cal H}\\)) are atoms of the Hilbert lattice\n\\({\\cal P} ({\\cal H})\\), hence all rank-one projections that are\nassigned non-zero probability by state \\(\\phi\\) are also measure\ntheoretic atoms in \\(({\\cal P} ({\\cal N}),\\phi)\\). Thus \\(({\\cal P}\n({\\cal H}),\\phi)\\) is not common cause complete. Whether common cause\nincomplete quantum probability spaces are common cause completable, is\nnot known; results are available on common cause\nextendability of quantum probability spaces only: Every\nquantum probability space \\(({\\cal P} ({\\cal N}),\\phi)\\) is embeddable\ninto a larger quantum probability space \\(({\\cal P}({\\cal\nN}'),\\phi')\\) in such a way that every correlation in \\(({\\cal\nP} ({\\cal N}),\\phi)\\) has a common cause in \\(({\\cal P}({\\cal\nN}'),\\phi')\\) (Hofer-Szabó, Rédei, &\nSzabó 1999; 2013: 62, Proposition 6.3). \nThe philosophical significance of common cause completability and\ncommon cause extendability of (classical and quantum) probability\nspaces is that they show that it is always possible in principle to\nexplain any correlation, hence also any correlation between causally\nindependent events, in terms of (possibly hidden) common\ncauses—hidden in the sense that the common causes need not be in\nthe probability space that contains the correlation: the common causes\ncan be “hiding” in a larger probability space. Thus these\ncommon cause completability and common cause extendability results\nconstrain the possible ways of attempts to falsify the Common Cause\nPrinciple: Any attempt at falsification should impose some further\nconditions on the common causes in addition to the four defining\n conditions (2)–(5),\n otherwise falsification can be evaded by referring to hidden common\ncauses. Formulated differently: The Common Cause Principle, as\nformulated exclusively in terms of the notion of a Reichenbachian\ncommon cause, either in a classical or in a quantum probability\ntheory, is not falsifiable. This does not mean that the common cause\nextendability results can be regarded as proof that the Common Cause\nPrinciple is true: Even the weaker question of whether a common cause\nextendability result can be taken as confirming evidence for the\nCommon Cause Principle depends on whether the extended probability\nmeasure space, existence of which is warranted by the mathematical\ncommon cause extendability results, is (part of) an empirically\nconfirmed scientific theory. \nThe significance of common cause complete spaces is that they display\na very strong compliance with the Common Cause Principle: An\nequivalent formulation of the Common Cause Principle is that\nprobability theories describing the world are causally closed in the\nfollowing sense: if A and B are correlated and are\ncausally independent, \\(R_{ind}(A,B)\\) in notation, then the\ncorrelation has to have a common cause that explains the correlation.\nCommon cause complete spaces are causally closed in the extremely\nstrong sense that the causal independence relation \\(R_{ind}(A,B)\\)\ncan be taken to be the strongest one, containing all correlated\nevents. Thus, if a scientific theory describing some aspect of reality\nuses a measure theoretically purely non-atomic probability space, such\na theory can be regarded as evidence in favor of the Common Cause\nPrinciple because that theory contains common causes of all\ncorrelations, including correlations that are between events that the\ntheory might regard as causally unrelated (independent). In view of\nthe interpretation of common cause completeness, common cause\ncompletability and common cause extendability, it is a relevant\nquestion whether our well-confirmed scientific theories are causally\nclosed or common cause extendable. Quantum field theory and standard\nnon-relativistic quantum mechanics are two theories for which this\nquestions has been analyzed extensively. \nRelativistic quantum field theory (see entry on\n quantum field theory)\n predicts an abundance of correlations between observables that are\nlocalized in spacelike separated (hence causally independent)\nspacetime regions. This is a consequence of prevalence of entanglement\nand of violation of Bell’s inequality in quantum field theory,\nwhich is even more striking than violation of Bell’s inequality\nby standard, non-relativistic quantum mechanics (Summers 1997; Clifton\n& Halvorson 2001; Halvorson & Clifton 2000; entry on\n Bell’s theorem).\n If relativistic quantum field theory is causally closed in the sense\nof providing common causes of these correlations, then this theory is\nconfirming evidence for the truth of the Common Cause Principle. \nThe quantum probability spaces describing relativistic quantum field\ntheory are based on type III von Neumann algebras (Haag 1992; Horuzhy\n1986 [1990]; Araki 1993 [1999]; entry on\n quantum field theory;\n consequently, these quantum probability spaces are measure\ntheoretically purely non-atomic. It follows then from the common cause\ncompleteness of such quantum probability spaces that there exists\ncommon causes of the correlations between spacelike separated\nobservables. Yet, one cannot conclude from this that quantum field\ntheory satisfies the Common Cause Principle, for the following reason:\nobservables in quantum field theory are explicitly associated with\nspecific spacetime regions. So the common causes also should be\nrequired to belong to specific spacetime regions. Given a correlation\nbetween observable A localized in spacetime region \\(V_1\\) and\nobservable B localized in spacetime region \\(V_2\\) spacelike\nseparated from \\(V_1\\), the common cause for this correlation should\nbe localized in a region V that is in the intersection of the\nbackward light cones of the spacelike separated spacetime regions\n\\(V_1\\) and \\(V_2\\). But the mere pure non-atomicity of the quantum\nprobability space of quantum field theory does not entail any such\nlocality of the common causes that exist as a consequence of the\nnon-atomicity of the quantum probability space describing quantum\nfields. When one imposes this additional localizability constraint on\nthe common causes in quantum field theory, the question of whether\nsuch properly localized common causes exist according to the\ntheory, becomes a highly non-trivial problem (Rédei 1997). So\nnon-trivial that the answer to it is still not known—the problem\nof status of causal completeness of quantum field theory is an open\nquestion. \nIt is known however that quantum field theory is causally complete in\nthe weaker sense of containing common causes localized in the\nunion (as opposed to the intersection) of the\nbackward light cones of the spacelike separated spacetime regions\n\\(V_1\\) and \\(V_2\\) that contain the correlated observables\n(Rédei & Summers 2002, 2007b; Hofer-Szabó et al.\n2013). It also is possible logically that the status of the Common\nCause Principle in relativistic quantum field theory cannot be\ndecided: The quantum field theory in which the abundance of\ncorrelations between spacelike separated observables has been proven\nis defined by axioms (Haag-Kastler axiomatization). The axioms might\njust be too weak to give an answer to the question whether all\ncorrelations between spacelike separated observables have properly\nlocalized common causes. Proving such an independence result would be\nvery interesting. Given how difficult it is to create any model of the\nHaag-Kastler axioms, attempting such a proof also appears to be\nextremely difficult because it requires displaying two models, one in\nwhich the Common Cause Principle holds (with properly localized common\ncauses), one in which it does not. \nOne also can consider the problem of the status of the Common Cause\nPrinciple in discrete (lattice) quantum field theory. This is a\nsimplified model of quantum field theory in which calculations are\nfrequently easier to carry out. One of the simplifications of this\ntheory is that the algebras of local observables are finite\ndimensional. The quantum probability spaces determined by such\nobservables are not purely non-atomic and this prevents common\ncauses—localized or not—to exist in these theories\n(Hofer-Szabó & Vecsernyés 2012a). If, in the quantum\ncontext, one allows common causes not to commute with the correlated\nobservables, then “non-commutative” common causes can be\nshown to exist in lattice quantum field theory (Hofer-Szabó\n& Vecsernyés 2012b, 2013, 2018). One also can raise the\nproblem of the status of the Common Cause Principle in categorial\nquantum field theory (Brunetti, Fredenhagen, & Verch 2003;\nRédei 2014a). This requires a reformulation of the concept of\ncommon cause in terms of the notions of the categories used in\ncategorial quantum field theory, which is done in Rédei\n(2014a). This then leads to a number of specific questions about the\nstatus of the suitable reformulated Common Cause Principle. Most of\nthese questions are open—this is an active area of research. \nStandard non-relativistic quantum mechanics of finite degrees of\nfreedom predicts the famous EPR correlations (see entry on\n the Einstein-Podolsky-Rosen argument in quantum theory),\n which have been observed in sophisticated physical measurements (see\nentry on\n Bell’s theorem).\n These correlations are between events that are spacelike separated\n(hence causally independent according the special theory of\nrelativity). Thus, they can serve as evidence to assess the status of\nthe Common Cause Principle: These EPR correlations should have common\ncauses if the Common Cause Principle describes the physical world\ncorrectly. \nThe quantum probability space that predicts the EPR correlations does\nnot contain common causes for these correlations because this quantum\nprobability space is defined on a finite dimensional Hilbert space and\nsuch a quantum probability space is not purely non-atomic hence not\ncommon cause complete. The question of whether “hidden”\ncommon causes for such correlations can in principle exist has been\nextensively discussed in a large literature. The first informal\ndiscussion seems to be von Neumann’s letter to Schrödinger\nin 1935 (Von Neumann 2005: 211–213). In this letter von Neumann\ntakes the position that no correlation, including EPR-type quantum\ncorrelations, is problematic as long as one can find a common cause\nfor it—although von Neumann does not use the term “common\ncause”, nor does he define any notion of common cause explicitly\n(Rédei 2006). The first technically explicit no-go theorem on\ncommon causes of EPR correlations is due to van Fraassen (1982). In\nthis paper it is assumed however that a single common cause explains\ndifferent correlations—i.e., that common causes are\ncommon common causes. It turns out however that, given a set\n\\((A_i,B_i)\\) (\\(i=1,2,\\ldots\\)) of pairs of correlated events in a\nclassical probability measure space, requiring the existence of a\ncommon cause \\(C_i\\) for each correlated pair \\((A_i,B_i)\\) is a much\nweaker assumption than requiring the existence of a single C\nthat is the common cause of all correlated pairs \\((A_i,B_i)\\)\n(\\(i=1,2,\\ldots\\)): one can give examples of different correlations in\na classical probability measure space that cannot have the same common\ncause (Hofer-Szabó, Rédei, & Szabó 2002).\nThus if one aims at deriving no-go propositions on the existence of\ncommon causes of EPR correlations then one has to either argue that\nthe different correlations in the EPR-situation should have the same\ncommon cause or one should impose further conditions on the common\ncauses in addition to those in\n Reichenbach’s definition (2)–(5). \nThere are two types of such additional conditions, both motivated by\nthe specific features of the EPR-scenario: “Locality\nconditions” and requirements expressing what is called\n“no-conspiracy”. Furthermore, both locality and\nno-conspiracy come in two varieties: surface and\nhidden locality conditions on one hand and weak and\nstrong no-conspiracy conditions on the other. The content of\nthe surface locality condition is that “… the probability\nof the outcome in one wing of the EPR correlation experiment is the\nsame no matter in which direction the measurement is carried out in\nthe other wing of the EPR experiment.” (Hofer-Szabó et\nal. 2013: 143).  The hidden locality conditions require that  \n... given a pair of correlated outcomes of an EPR\ncorrelation experiment, the probability of the outcome in one wing of\nthe EPR correlation experiment be the same no matter in which\ndirection the measurement is carried out in the other wing of the EPR\nexperiment if the hypothetical common cause of this\ncorrelation also has happened. (Hofer-Szabó et al. 2013:\n144).  \nThe weak no-conspiracy condition requires that any choice of\nthe direction in which a measurement is decided to be carried out in\nany wing of the EPR experimental setup is probabilistically\nindependent of the hypothetical common cause explaining the\ncorrelation in the chosen direction. The strong no-conspiracy\ncondition requires that any Boolean combination of choices of\nmeasurement directions in the two wings of the EPR experiment are\nprobabilistically independent of any Boolean combination of\nthe hypothetical common causes. (Hofer-Szabó et al. 2013:\n178).  \nThe differences between the different versions of the locality and\nno-nonspiracy conditions are conceptually significant and they are\nalso crucial from the perspective of whether hypothetical common\ncauses of EPR correlations can be ruled out by no-go theorems: The\nsurface locality conditions are empirically testable due to the fact\nthat all the events involved in it are observable. The hidden locality\nconditions involve the unobserved, hypothetical common cause events\nand, as a consequence, these locality conditions are not testable\nindependently of the observation of the common causes. The\ninterpretation of the no-conspiracy conditions is somewhat\ncontroversial: it declares as an implausible conspiracy on the part of\nnature if common causes influenced not only the outcomes of the EPR\ncorrelation experiments but also the choices of measuring in\nparticular directions in the wings of the EPR experiment. These\nchoices, we feel, are free, depending on the experimenter’s\ndecision. \nOne can show that weakly non-conspiratorial common cause\nexplanations of EPR correlations satisfying surface locality are\npossible. But strongly non-conspiratorial, hidden\nlocal common cause explanations of EPR correlations are ruled out\n(Hofer-Szabó et al. 2013: 152, 163). These results show\nthat the EPR correlations cannot be regarded as strictly empirical\nevidence against the Common Cause Principle because the type of common\ncauses that can be ruled out have features by assumption that are not\nempirically testable (hidden locality and no-conspiracy)—they\nare metaphysical in character. \nOther accessible overviews of Reichenbach’s Common Cause\nPrinciple include Chapter 6 of Salmon (1984) and Arntzenius\n(1999 [2010]), which is a previous version of the present\nentry. The entry on\n Hans Reichenbach\n provides an overview of Reichenbach’s philosophy.\nReichenbach’s probabilistic theory of causation is discussed in\nthe entry on\n causation, probabilistic.\n Issues related to temporal asymmetry in thermodynamics are discussed\nin the entry on\n thermodynamic asymmetry in time.\n The Causal Markov Condition is discussed at greater length in the\nentry on\n causal models.\n This encyclopedia contains numerous entries on philosophical issues\nrelated to quantum mechanics. Of particular relevance are\n the Einstein-Podolski-Rosen argument in quantum theory,\n philosophical issues in quantum theory,\n quantum logic and probability theory,\n and\n Quantum Mechanics. \nTwo recent book-length treatments of RCCP are Hofer-Szabó et\nal. (2013) and Wroński (2014). Further good discussions of the\nCommon Cause Principle include Arntzenius (1990, 1992); Cartwright\n(1988); Van Fraassen (1982b); Gyenis and Redei (2011, 2014); Henson\n(2005); Hofer-Szabó et al. (1999, 2002); Marczyk and\nWroński (2015); Mazzola (2012, 2013); Mazzola and Evans (2017);\nRédei (2014b); San Pedro (2008); Sober (1984, 1988 1989,\n2008); Spohn (1994); Suppes (1970, 1984); Uffink (1999); and\nWroński (2010). \nDiscussion of counterexamples to RCCP are found in Cartwright (1994,\n2007); Hoover (2003); Sober (2001); and Steel (2003).  \nDiscussions of RCCP in the context of quantum theory include\nButterfield (1989, 2007); Chang and Cartwright (1992) Kowalski and\nPlacek (1999); Penrose and Percival (1962); Placek (2000a,b); van\nFraassen (1982a, 1991); Wüthrich (2004); and Wiseman and\nCavalcanti (2017).","contact.mail":"cricky@caltech.edu","contact.domain":"caltech.edu"},{"date.published":"2020-01-13","url":"https://plato.stanford.edu/entries/physics-Rpcc/","author1":"Christopher Hitchcock","author2":"Miklós Rédei","author1.info":"http://hss.divisions.caltech.edu/people/christopher-r-hitchcock","entry":"physics-Rpcc","body.text":"\n\n\nThe Common Cause Principle was introduced by Hans\nReichenbach, in The Direction of Time, which was published\nposthumously in 1956. Suppose that two events A and B\nare positively correlated: \\(p(A\\cap B)>p(A)p(B)\\). Suppose,\nmoreover, that neither event is a cause of the other. Then,\nReichenbach’s Common Cause Principle (RCCP) states that A\nand B will have a common cause that renders them conditionally\nindependent. Reichenbach incorporated his RCCP into a new probablistic\ntheory of causation, and used it to describe a (purported)\nmacrostatistical temporal asymmetry in analogy with the second law of\nthermodynamics. The principle is significant because it posits a\nconnection between causal structure and probabilistic correlations,\nthus facilitating causal inference from observed correlations.\nHowever, RCCP has been controversial, and a number of counterexamples\nhave been proposed. RCCP is often seen as an antecedent of the\nCausal Markov Condition, which plays a central role in causal\nmodeling and causal inference. RCCP has also been taken to capture\nassumptions about the behavior of classical systems that appear to be\nviolated in quantum mechanics.\n\nThe Common Cause Principle (RCCP) was introduced by Hans\nReichenbach, in The Direction of Time, which was published\nposthumously in 1956. The principle posits a connection between causal\nstructure and probabilistic correlations between events. After\npresenting the principle in\n Section 2,\n we will provide some historical background in\n Section 3.\n The following two sections present some illustrations and alleged\ncounterexamples to RCCP.\n Section 6\n discusses Reichenbach’s fork asymmetry, a (putative)\ntemporal asymmetry in macrostatistical patterns that he associated\nwith RCCP.\n Section 7\n presents the Causal Markov Condition, which plays a central\nrole in causal modeling methods. The Causal Markov Condition is often\nseen as a modern successor of RCCP, and its relationship to RCCP will\nbe examined.\n Section 8\n will develop RCCP in a formal setting that is suitable for examining\nthe status of RCCP in quantum mechanics.\n Section 9\n and\n Section 10\n will then consider whether RCCP is compatible with quantum\nphysics. \nLet A and B be events. A storm, a person getting sick, a\nsoccer player scoring a goal, and a scientific measurement yielding a\nspecific result are all examples of events. Assume we can meaningfully\nassign probabilities to these events occurring. Reichenbach himself\ndeveloped a sophisticated frequency interpretation of probability\n(Reichenbach 1949), but we will assume only that some kind of\nobjective probability can be meaningfully applied. Suppose that events\nA and B are positively probabilistically correlated:\n \nThat is, the probability that both A and B\noccur is greater than the product of the individual probabilities.\nReichenbach’s Common Cause Principle says that when such a\nprobabilistic correlation between A and B exists, this\nis because one of the following causal relations exists: A is a\ncause of B; B is a cause of A; or A and\nB are both caused by a third factor, C. In the last\ncase, the common cause C occurs prior to A and B,\nand must satisfy the following four independent conditions:  \nwhere  \ndenotes the conditional probability of X on condition Y,\n\\(\\overline{C}\\) denotes the absence of event C (the negation\nof the proposition that C happens) and it is assumed that\nneither C nor \\(\\overline{C}\\) has probability zero. Line (2)\nsays that A and B are conditionally\nindependent, given C. In Reichenbach’s terminology,\nC screens A off from B. Line (3) says that\n\\(\\overline{C}\\) also screens A off from B. Lines (4)\nand (5) say that A and B are more probable, conditional\non C, than conditional on the absence of C. These\ninequalities are natural consequences of C being a cause of\nA and of B. Together, conditions (2) through (5)\nmathematically entail\n (1).\n The common cause can thus be understood to explain the correlation in\n(1). The probability relations described in lines (1) through (3)\nexhibit a version of Simpson’s Paradox. For more about\nthis probabilistic phenomenon, see the entry on\n Simpson’s Paradox. \nIt will often be helpful to represent such a common cause structure\ndiagrammatically, as in\n Figure 1.\n Arrows indicate causal relationships, and the vertical dimension\nrepresents time (with later times appearing higher up). \nFigure 1: A common cause structure.\nC occurs earlier than A and B, and C is a\ncause of A and B. \nRCCP says that probabilistic correlations are ultimately derived from\ncausal relationships. That is, if \\(p(A\\cap B)>p(A)p(B)\\), that is\neither because one of these events causes the other, or else the\ninequality can be derived from other inequalities \\(p(A|C) >\np(A|\\overline{C})\\) and \\(p(B|C) > p(B|\\overline{C})\\) where\nC is a cause of A and B. The principle is\nsignificant because it posits a connection between causal structure\nand probabilistic correlations that licenses inferences to causal\nrelationships from empirically observable correlations. \nAs formulated above, RCCP assumes that there are only two possible\nstates of the common cause: C and \\(\\overline{C}\\). That is,\nC is a binary event that is either present or absent. A natural\nextension of RCCP would be to allow the common cause to be a random\nvariable Z with many possible values \\(z_1,\\dots,z_n\\). In this\ncase we would expect that \\(Z = z_i\\) screens off A from\nB for \\(i=1,\\dots,n\\). However, this does not imply that we can\ndivide the values of Z into two sets \\(\\mathbf{S}\\) and\n\\(\\mathbf{S^\\prime}\\) such that \\(Z\\in \\mathbf{S}\\) (corresponding to\nC) and \\(Z \\in \\mathbf{S^\\prime}\\) (corresponding to\n\\(\\overline{C}\\)) each screen off A and B. More\ngenerally, we would not expect coarsenings of Z to yield events\nthat screen off A and B. \nOne corollary of this generalization is that if A and B\nhave two distinct binary common causes C and D, we would\nexpect each of \\(CD, C\\overline{D}, \\overline{C}D, \\overline{CD}\\) to\nscreen off A and B, but would not expect C and\nD to screen off A and B. For example, even if we\ncondition on the common cause C, we would expect A and\nB to be correlated because of the further common cause\nD. \nWe can further generalize to allow the correlated effects to be\nrandom variables instead of binary events. The fully general version\nof RCCP then reads as follows: \nSuppose X and Y are random variables that are\ncorrelated; i.e., there exist values \\(x_i\\) and \\(y_j\\) such that\n \nThen there exists a set of variables \\(Z_1,\\dots,Z_m\\), such that each\nvariable is a cause of X and Y, and \nfor all \\(i,j,k_1,\\dots,k_m\\) \nWith this generalization of RCCP, it is trickier to formulate analogs\nfor conditions 4 and 5 that capture in probabilistic terms the idea\nthat each variable \\(Z_k\\) is a cause of both X and Y.\nIn addition, this set of conditions will not strictly imply that\nX and Y are probabilistically correlated. We will return\nto these issues in\n Section 7. \nThe Direction of Time (Reichenbach 1956) was unfinished at\nthe time of Reichenbach’s death in 1953. The manuscript was\nedited by his wife Maria Reichenbach, and published posthumously in\n1956. The book was concerned with temporally asymmetric\nphenomena—phenomena that we associate with the distinction\nbetween the past and the future. It included major sections on the\nrole of time in classical physics, thermodynamics, statistical\nmechanics, and quantum mechanics. It also included a section on\ntemporal asymmetries in macrostatistics. Reichenbach had plans to\ninclude a final section on the subjective experience of time. \nThe book makes a number of important and original contributions. It\ncontains a detailed investigation into the philosophical foundations\nof statistical mechanics, especially examining the status of the\nsecond law of thermodynamics, which states that the entropy of a\nclosed system can increase, but never decrease. Reichenbach explored\nconnections between statistical mechanics and the new field of\ninformation theory—Shannon and Weaver’s classic book\n(1949) on the topic had been published just a few years earlier. In\naddition to the asymmetry of entropy increase described by the second\nlaw of thermodynamics, the book examined other temporally asymmetric\nphenomena. One of these was the asymmetry of records: We have detailed\nrecords of past events, including human memories and human made\ndocuments such as records and history books, but also including\nnatural phenomena such as fossils, tree rings, and geological strata.\nThese records provide us with a rich source of information about the\npast. We have no comparable source of information about the future,\nalthough we can reliably predict certain events, such as solar\neclipses. \nA third important temporal asymmetry is the asymmetry of cause and\neffect. Causes invariably precede their effects in time. Reichenbach\nattempted to analyze causal direction in terms of macrostatistics or\nprobability. He appealed to his notion of screening-off to define a\nrelation of causal betweenness, and also to define causal direction.\nIt is in this latter context that the RCCP was introduced. The\nconnection between RCCP and causal direction will be discussed in\n Section 6\n below. Reichenbach also formulated a probabilistic theory of\ncausation, and explored the connections between these new ideas and\nthe mark method for distinguishing causal direction, which he\nhad proposed much earlier (Reichenbach 1958). \nRCCP connects with a number of threads in Reichenbach’s thought.\nReichenbach had developed and defended a frequency interpretation of\nprobability (Reichenbach 1949), as well as a thoroughgoing\nprobabilistic epistemology (Reichenbach 1938) He had also explored the\nconnection between probability and causation in earlier works\n(Reichenbach 1925 [1978], 1930 [1978]). The Direction of Time\ntakes the project further in developing a probabilistic metaphysics.\nReichenbach had also explored the connection between causation and the\ndirection of time in Reichenbach (1925 [1978]) and Reichenbach (1958).\nThe latter work developed a causal theory of time in the context of\nrelativity theory. \nExample 1. The barometer and the storm (Jeffrey\n1969). \nFigure 2: The barometer and the storm.\n\\(A =\\) drop in atmospheric pressure; \\(B =\\) drop in mercury level in\nbarometer; \\(S =\\) storm. \nA drop in the level of mercury in a barometer is frequently followed\nby a storm. Call these events B and S, respectively.\nSince storms in general are not so frequent, these events are\nprobabilistically correlated: \\(p(B \\cap S) > p(B)p(S)\\). The\nbehavior of one barometer doesn’t affect the weather, so\nB is not a cause of S; rather, B and S\nhave a common cause: a drop in atmospheric pressure A (see\n Figure 2).\n A increases the probability of both B and S:\n \nMoreover, A will screen off B from S: \nand  \nFor example, if the atmospheric pressure drops, but the column of\nmercury in the barometer does not drop because the barometer is\nmalfunctioning, the probability of a storm is the same as it would be\nif the barometer were functioning properly. \nExample 2. The theatre troupe (Reichenbach\n1956). \nA small theatre troupe travels around the country putting on\nperformances. Occasionally, the leading man becomes seriously\nill—call this event M—and an understudy must take\nhis place. The same thing sometimes happens to the leading\nlady—L. Although both events are rare, they tend to occur\ntogether: \\(p(L \\cap M) > p(L)p(M)\\). The reason is that the actors\nusually eat together at the same restaurants, where they occasionally\nshare tainted food—T. See\n Figure 3. \nFigure 3: The theatre troupe. \\(T =\\)\nfood tainted at restaurant patronized by actors; \\(L =\\) leading lady\ngets sick; \\(M =\\) leading man gets sick. \nSuppose the probabilities are as follows: \nThen we can compute: \nThese calculations make use of the fact that T and\n\\(\\overline{T}\\) screen L off from M. We can also\ncompute: \nThus \nL and M are probabilistically correlated. \nSuppose that, on a given night, both the leading man and the leading\nlady are seriously ill. Can we infer that they ate tainted food? From\nthe probabilities above, we can compute \nWhile it is probable that they ate tainted food, it is by no means a\ncertainty. This example shows that the Common Cause Principle, by\nitself, does not license token-level causal inferences. That\nis, it does not tell us that when two effects A and\nB occur on a particular occasion, then their common cause\nC also occurred on this occasion. Instead, the Common Cause\nPrinciple licenses the inference from a probabilistic correlation to\nthe existence of a type-level common cause. \nExample 3. Language descent. \nCommon words in English that start with the letter ‘F’\noften have counterparts in Spanish that start with the letter\n‘P’: ‘foot’/‘pie’,\n‘fish’/‘pez’,\n‘father’/‘padre’, etc. One could quantify this\nby looking at canonical wordlists from both languages, and seeing how\noften words begin with ‘F’ in English and with\n‘P’ in Spanish. By treating the relative frequencies in\nthis list as probabilities, one would discover that there is indeed a\nprobabilistic correlation between the English word-initial\n‘F’ and Spanish word-initial ‘P’. \nThe explanation for this correlation is that English and Spanish are\ndescended from a common language, called Proto-Indo-European.\nSome, but not all, words in Proto-Indo-European began with a consonant\nwe can label [P/F], which evolved into ‘P’ in Romance\nlanguages (including Spanish), and ‘F’ in Germanic\nlanguages (including English). (Note that it is the phonetic\npronunciation, rather than the spelling that is of interest here; for\nexample, many German words whose spelling begins with ‘V’\nare counted for this purpose.) In the separate lineages leading from\nProto-Indo-European to English and to Spanish, Proto-Indo-European\nroots were retained for some words, but replaced for others. The roots\nwere retained often enough that the correlation can still be detected.\nMoreover, the two lineages evolved more or less independently after\nsplitting from Proto-Indo-European. Note that the common cause is not\nthe Proto-Indo-European language as a whole, and the effects are not\nEnglish and Spanish. It would make little sense to assign\nprobabilities to these languages (let alone a joint probability to\nEnglish and Spanish). Rather, the common cause is an initial consonant\n[P/F] in Proto-Indo-European; the effects are initial ‘F’\nin English and initial ‘P’ in Spanish. It makes sense to\nassign probabilities to these sounds, since we can count the frequency\nwith which words in these languages start with these sounds. See\n Figure 4. \nFigure 4: The descent of words with\ninitial consonant ‘F’ in English and initial consonant\n‘P’ in Spanish, from words with initial consonant [P/F] in\nProto-Indo-European. \nNote that the evidence of common descent between the two languages is\nthe correlation between the two sounds, rather than any\nphonetic similarity between them. For example, there is a recognized\ncorrelation between the Latin ‘du’ and Armenian\n‘erk’, as in ‘duo’/‘erku’\n(‘two’). Despite the differences in these sounds, the\ncorrelation is evidence of common descent (both are also Indo-European\nlanguages). \nFor further discussion of this example, see Hitchcock (1998). \nExample 4. Fried fish. \nBoth the British and the Japanese eat battered seafood that has been\ndeep-fried in oil: the British in the form of fish and chips, and the\nJapanese in the form of tempura. The technique of battering and\ndeep-frying seafood seems to have originated with Moors in the Iberian\nPeninsula in the thirteenth century, where the dish was called\nmu’affar. It spread to the Jewish and Christian\ninhabitants of Spain and Portugal. In the sixteenth century, Sephardic\nJews fleeing persecution took the recipe to Britain, and Portuguese\ntraders carried it to Japan. \nWhile it might be reasonable to call mu’affar the\ncommon cause of fish and chips and tempura, this is not an instance of\nthe Common Cause Principle. There are no probabilities involved in\nthis example, and there is no clear sense in which the British and\nJapanese both eating fried seafood is a probabilistic correlation.\nPerhaps one could construct a probabilistic model of global food\ndistribution that would supply such probabilities, but in the absence\nof such a model, we do not have an instance of RCCP. \nA number of authors have proposed counterexamples to the Common Cause\nPrinciple. A counterexample would involve two events A and\nB such that \nA and B are probabilistically correlated, \nneither event is a cause of the other, and \nthe correlation between A and B cannot be explained by a\ncommon cause, either because they have no common cause, or because\ntheir common cause does not screen them off from one another. \nOne type of case that is often said to violate the Common Cause\nPrinciple involves entangled states in quantum mechanics, such as\nthose found in Einstein-Podolski-Rosen (EPR) thought experiment. We\nwill discuss this case in detail in\n Section 10\n below. The present section will consider several other examples. As\nwe shall see, these examples typically raise questions about the\nproper scope and interpretation of the Common Cause Principle, rather\nthan refuting the principle outright. \nExample 5. Cartwright’s factory. \nCartwright (1999: 108–109) asks us to imagine a factory that\nproduces a chemical, C, that is used in sewage treatment. The\nfactory employs a genuinely indeterministic process, so that when the\nprocess is initiated, I, there is a probability of .8 that the\nchemical is produced. However, whenever the chemical is produced, the\nfactory also releases a pollutant, P as a by-product. Thus \nNeither C nor P cause the other. \nGlymour (1999) objects that such a factory is nowhere to be found.\nThis raises a question about the status of the Common Cause Principle.\nIf the principle is intended to be a conceptual truth about the\nrelationship between causation and probability, then we could\nundermine the principle by showing that a causal structure that\nviolates it can be clearly conceived. On the other hand, if the\nprinciple is intended to be an empirical generalization about the\nrelationship between causation and probability in the actual world,\nthen Glymour is right to demand more than a hypothetical example. \nExample 6. Random darts. \nSuppose that darts are shot at a dart board using an indeterministic\nprocess that can hit any part of the board. (If the reader is not\ncomfortable with indeterministic darts, she may imagine photons\nhitting a scintillation screen after passing through a narrow slit.)\nSuppose that A and B\nare two regions of the dart board such that\nA is fully contained within B,\nand B does\nnot fill the entire board (see\n Figure 5(a)).\n Let A be the event corresponding to the dart landing in region\nA, and analogously for B. Then\nwe will have: \nThis follows because \\(A \\cap B = A\\) and \\(p(B) < 1\\). While the\nthrow of the dart (or whatever process launches the dart) is a common\ncause of A and B, this will not screen them off. And if\nthe process is genuinely indeterministic, there will be no cause that\nscreens them off. \nFigure 5: The large circle represents\nthe dart board. Circles A and B\nare regions of the dartboard. In (a) the\nregion A is entirely contained in the\nregion B. In (b) the regions almost\n(but not quite) completely overlap.  \nDavid Lewis famously tried to analyze causation in terms of\ncounterfactuals (Lewis 1973). He recognized that in order for his\ntheory to succeed, he needed to restrict the analysis to\ncounterfactual relations among distinct events (see\nespecially Lewis 1986). For instance, we typed the word “Lewis”\nnear the beginning of this paragraph. If we had not typed the letters\nL-e-w, then we would not have typed the word “Lewis”. But typing\nthe letters L-e-w did not cause us to type “Lewis”.\nTyping L-e-w was part of the act of typing “Lewis”. The\nevents typing L-e-w and typing “Lewis” are not\ndistinct from one another in the right kind of way to stand\nin causal relations to each other. Lewis’s account of\ndistinctness is somewhat involved, but it specifically excludes\nrelations of logical entailment and spatiotemporal inclusion. \nIt appears that the Common Cause Principle requires a similar\nrestriction to distinct events. In our example of the dart board, the\nregion A is spatially included within\nthe region B; hence, the events\nA and B will not be distinct, in Lewis’s sense.\nThis means that there may be correlations between these events that\nare entirely due to their spatiotemporal relationship, and don’t\nhave any distinctively causal basis. \nNow suppose that the regions A and\nB almost completely overlap, but\nneither is contained within the other (see\n Figure 5(b)).\n Again, the corresponding events A and B will be\ncorrelated, and the earlier common cause may not screen them off.\n(Arntzenius (1999 [2010: section 2.4]) has an example that has\nessentially this structure.) It seems that this case, too, is one in\nwhich the events A and B are insufficiently distinct.\nBut now it becomes difficult to formulate a notion of distinctness\nthat is sufficiently general, without ruling out too much. To see the\nproblem, imagine that instead of a literal dartboard, we have a Venn\ndiagram representing the possible states of a system that evolves\nindeterministically. The spatial regions A\nand B now\nrepresent sets of possible states, corresponding to the states in\nwhich events A and B occur. And the area corresponds to\nprobability. Thus the set of states in which A occurs almost\ncompletely overlaps with the set of states in which B occurs,\nas measured by the probability distribution over states. Is this a\nreason to think that A and B are not distinct? It had\nbetter not be, because this is just a representation of the generic\ncase where events A and B are probabilistically\ncorrelated. Thus spelling out the precise notion of\ndistinctness at work remains a challenge. \nExample 7. Conserved quantities. \nSalmon (1984) and Schurz (2017) argue that systems governed by\nprobabilistic dynamics together with conservation laws will give rise\nto violations of RCCP. Suppose that a brick weighing 2 kg falls onto a\nhard, peaked surface. The brick cracks and breaks into two pieces,\nA and B.\nSuppose that this process is genuinely chancy. Perhaps the precise\npoint at which the brick strikes the surface, or the precise process\nof crack formation in the brick, is not determined by earlier states\nof the system. Let A be the event corresponding to piece A\nweighing some specific amount, say 1.2 kg,\nand let B be the event corresponding to piece B\nweighing the complementary amount, say 0.8\nkg. Since the combined mass must be 2 kg, A will occur if and\nonly if B occurs. Since the process is chancy, \\(p(A) = p(B) =\nr < 1\\). However,  \nso A and B are correlated. No earlier event can screen\noff this correlation unless it determines that A and B\nwill occur. Since the process is genuinely chancy, there is no such\nevent. Hence RCCP is violated. \nWhether there are any actual violations of RCCP having this form\ndepends on whether there are actual processes governed by\nprobabilistic dynamics and conservation laws. We don’t find such\nprocesses described by classical physics. We do encounter this\ncombination already in quantum mechanics, at least on some\ninterpretations (so-called collapse interpretations). However, these\ncases are further complicated by the role of quantum\nentanglement. We discuss the status of the Common Cause\nPrinciple in quantum mechanics in greater detail in sections 9 and 10\nbelow. \nExample 8. Time series. \nSober (2001) notes that sea levels in Venice and bread prices in\nLondon have both been rising over the past few centuries. Let V\nrepresent Venetian sea levels higher than some specified level, and\nL London bread prices higher than a given mark. If we sample\nVenetian sea levels and London bread prices over time, we will find\nthat V and L are correlated: In years where V\nobtains, L tends to obtain as well (since these will tend to be\nmore recent years). However, we have no reason to think that these\nphenomena share a common cause. They appear to be causally\nindependent. \nTo understand what is going on in this example, we need to look more\nclosely at the relationship between sample statistics and underlying\nprobability distributions. We frequently think about this in terms of\na classic urn model. An urn contains a certain proportion of black and\nwhite balls. We draw balls from the urn, and use the frequency of\nblack balls drawn to estimate the proportion of black balls in the\nurn. Using statistical frequencies to estimate probabilities in this\nway typically requires an assumption that the samples are\nprobabilistically independent: drawing a black ball does not affect\nthe probability that the next ball drawn will be black. Sober’s\nexample involves what statisticians call a time series. When\nwe sample Venetian sea levels over the course of years, we are not\ndrawing probabilistically independent samples from a stable\nprobability distribution. If the sea level is high in a particular\nyear, we can predict that the sea level will be similarly high the\nfollowing year (they tend not to change dramatically from one year to\nthe next). For this reason, we cannot interpret the relative\nfrequencies that we obtain as estimates of an underlying probability\ndistribution. Thus, even though there is a correlation between\nV and L in our samples, it is impossible to interpret\nthis as a probabilistic correlation with  \\(p(V \\cap L) > p(V)p(L)\\). Not all correlations in\nstatistical samples bespeak probabilistic correlations. (See\nalso Hoover 2003 and Steel 2003 for further discussion of\nSober’s example.) \nThis defense of the Common Cause Principle raises a worry, however.\nMany cases where we would like to apply the Common Cause Principle may\nalso turn out to behave like time series. For example, consider\nReichenbach’s example of the traveling theatre troupe\n (Example 2\n above). It is reasonable to expect that if the leading man is sick on\na particular day, then he will be more likely to be sick on the\nfollowing day—some illnesses last more than a day. And if he is\nexposed to a particular pathogen at one time, he may gain immunity\nagainst that pathogen in the future. If we exclude all such examples,\nthen we run the risk of excluding many of the standard examples that\nare supposed to lend support to the principle. \nReichenbach’s Direction of Time (1956) was centrally\nconcerned with temporally asymmetric phenomena. Much of the work is\ndevoted to the status of the Second Law of Thermodynamics, which says\nthat in a closed system, entropy can increase but will never decrease.\nBut Reichenbach also tried to define a macroscopic statistical\nasymmetry using the Common Cause Principle. Suppose that events\nA and B are correlated, i.e., that \\(p(A \\cap B) >\np(A)p(B)\\). If there is an event C that satisfies conditions\n (2)–(5)\n above, Reichenbach called the trio ACB a conjunctive\nfork. If C occurs earlier than A and B, and\nthere is no event satisfying (2)–(5) that occurs later than\nA and B, then ACB is said to form a conjunctive\nfork open to the future (see\n Figure 6(a)).\n \nFigure 6: (a) Conjunctive fork open to\nthe future. (b) Conjunctive fork open to the past. (c) Closed fork.\n[An\n extended description of figure 6\n is in the supplement.]  \n Analogously, if there is a later event satisfying (2)–(5), but\nno earlier event, we have a conjunctive fork open to the past\n (Figure 6(b)).\n If an earlier event C and a later event D both satisfy\n(2)–(5), then ACBD forms a closed fork\n (Figure 6(c)).\n Reichenbach claimed that in our world, there are a great many forks\nopen to the future, but few or none open to the past. Moreover, he\nproposed that the direction from cause to effect could be grounded in\nthis statistical asymmetry. \nReichenbach saw his fork asymmetry as a macro-statistical analog of\nthe second law of thermodynamics. Suppose we have a system such as a\ngas that is made up of a large number of particles. Each particle can\nbe in one of many possible states \\(s_1,\\dots,s_n\\). Let \\(p_i\\) be\nproportion of the particles that are in state \\(s_i\\). Then one\nexpression for the entropy of the system is \\(S = {-}\\sum_i\np_i log(p_i)\\). This sum will reach a maximum when the particles are\nevenly distributed among the n states (or distributed as evenly\nas possible given constraints on the system). The second law of\nthermodynamics states that the entropy of a closed system can increase\nbut never decrease; hence it will evolve toward a state of maximum\nentropy. Reichenbach claims that if we find a closed system in a state\nof low entropy, we can infer that it was recently prepared in that\nstate, before being closed off from the rest of the environment. \nNow suppose that we have two events A and B, and a\nprobability distribution p over the four states \\(AB\\),\n\\(A\\overline{B}\\), \\(\\overline{A}B\\), \\(\\overline{A} \\overline{B}\\).\nWe can apply the formula for entropy to this probability distribution;\nholding the probability of A and B fixed, the entropy\nwill be highest when A and B are probabilistically\nindependent. Thus, when we find a correlation between A and\nB, this is like finding a system in a state of low entropy, and\nwe should look for some event in the past of A and B to\nexplain this correlation. This is only a formal analogy, but\nReichenbach attempted to show that the same basic principles that give\nrise to the second law of thermodynamics would also give rise to the\nCommon Cause Principle. For more discussion, see the entry on\n thermodynamic asymmetry in time. \nReichenbach’s fork asymmetry has been subjected to numerous\ncriticisms. Horwich (1987) argues that our willingness to infer a past\ninteraction often has little to do with entropy. We may infer from a\npile of rubble that a city has been bombed. A pile of rubble\ncorresponds to higher entropy than intact buildings; but it is the\nformer, rather than the latter, that leads us to infer that a certain\nkind of interaction with the city has taken place. \nFigure 7:  \\(\\mathcal{S}\\) is the entire\nstate space. Three copies of \\(\\mathcal{S}\\) are shown, corresponding\nto times 0, t, and \\(t^\\prime > t\\). If the system is in state\ns at time 0, it will be in state \\(U_t(s)\\) at time t,\nand state \\(U_{t^\\prime}(s)\\) at time \\(t^\\prime\\). The set of states\ncorresponding to event C will evolve into \\(U_t(C)\\) and\n\\(U_{t^\\prime}(C)\\). [An\n extended description of figure 7\n is in the supplement.] \nArntzenius (1990) points out that the fork asymmetry is highly\nproblematic in the context of classical statistical mechanics within\nwhich Reichenbach was working. Let \\(\\mathcal{S}\\) be a state-space\ncontaining all possible states of a physical system (see\n Figure 7).\n The state of a system s at a particular time t will\ninvolve the specification of parameters, such as the positions and\nmomenta of all the particles in the system. The system evolves\ndeterministically, so that for every time time t, if the system\nwas in state s at time 0, it will be in state \\(U_t(s)\\) at\ntime t, where each \\(U_t\\) is a one-one function from\n\\(\\mathcal{S}\\) into itself. An event such as C corresponds to\na subset of \\(\\mathcal{S}\\): the set of states in which C\noccurs. We can then define \\(U_t(C)\\) to be the set of states of the\nform \\(U_t(s)\\), where \\(s \\in C\\). \nA probability function p on \\(\\mathcal{S}\\) at time 0 can then\nbe extended to a probability distribution over trajectories through\n\\(\\mathcal{S}\\), yielding probabilities for events at later times. \nSuppose that C occurs at time 0, and A and B\noccur at later time t. Suppose, moreover, that ACB forms\na conjunctive fork. Then we can evolve the set of microstates in\nC forward to time \\(t^\\prime > t\\). Then \\(D =\nU_{t^\\prime}(C)\\) will occur after A and B, but stand in\nthe same probabilistic relationship to A and B that\nC does (see\n Figure 8).\n Thus ACBD will form a closed fork. Since this recipe is\nperfectly general, it seems that every conjunctive fork ACB\nwith C earlier than A and B must belong to a\nclosed fork ABCD. \nFigure 8: Event D at time\n\\(t^\\prime\\) results from evolving C forward from time 0 to\n\\(t^\\prime\\). It will stand in the same probabilistic relationship to\nevents A and B at time t that C did at\ntime 0. [An\n extended description of figure 8\n is in the supplement.]  \nA natural response to this worry is to propose that the earlier set of\nstates C will be sufficiently coherent to form a natural event,\nwhile the later set of states D will be a heterogeneous\ncollection, having nothing in common except for the fact that they all\nevolved states in C. Such a heterogeneous collection of states\nwould not qualify as an event—see, e.g., Lewis (1986)\nfor discussion of what qualifies as a genuine event. Hence, there is\nan earlier event that screens off A and B, but no later\nevent that does so. However, the framework of statistical mechanics\ngives us no principled reason for thinking that in all such cases, the\nearlier screening off event will be coherent enough to be a proper\nevent, while the later screener will not be. Moreover, Arntzenius\n(1990) offers a counterexample to one way of making this proposal\nprecise. \nWe will also see in Section 7 that the modern theory of causal\nmodeling does not use conjunctive forks to determine the direction of\ncausation, but rather uses a probabilistic pattern that is essentially\nthe exact opposite of a conjunctive fork. \nReichenbach’s Common Cause Principle is closely related to the\nCausal Markov Condition that is commonly employed in causal\nmodeling. A version of the Causal Markov Condition was first\nproposed by Kiiveri, Speed, and Carlin (1984). Detailed programs in\ncausal modeling featuring the Causal Markov Condition have been\ndeveloped by Pearl (2009) and Spirtes, Glymour and Scheines\n(2000). \nWe will describe here just one kind of causal model, the causal\nBayes net. A causal Bayes net uses a directed acyclic\ngraph (DAG) to represent causal relations among a set of\nvariables, and pairs it with a probability distribution over the set\nof variables. More precisely, a causal Bayes net is a triple\n\\((\\mathbf{V}, \\mathcal{G}, p)\\), where \\(\\mathbf{V}\\) is a set of\nvariables, \\(\\mathcal{G}\\) is a directed acyclic graph over\n\\(\\mathbf{V}\\), and p is a probability distribution over the\nfield of events generated by \\(\\mathbf{V}\\). The variables in\n\\(\\mathbf{V}\\) correspond to the properties of individuals in some\npopulation. For example, in a population of American adults, we might\nhave variables representing an individual’s education level,\nwork experience, and present income. A variable can be binary,\nrepresenting the presence or absence of some property, but it can also\nbe multiple-valued or continuous. \n\\(\\mathcal{G}\\) is a set of ordered pairs of variables in\n\\(\\mathbf{V}\\). If \\((X, Y) \\in \\mathcal{G}\\), we represent this\ngraphically by drawing an arrow from X to Y, and we say\nthat X is a parent of Y. If there are arrows\nfrom \\(X_{1}\\) to \\(X_{2}\\), \\(X_{2}\\) to \\(X_{3}\\),… and\n\\(X_{n-1}\\) to \\(X_{n}\\), then there is a directed path from\n\\(X_{1}\\) to \\(X_{n}\\). In this case, we say that \\(X_{n}\\) is a\ndescendant of \\(X_{1}\\). \\(\\mathcal{G}\\) is acyclic if there\nis no directed path from any variable to itself.\n Figure 9\n shows a DAG on the variable set \\(\\{U, V, W, X, Y, Z\\}\\). In this\nDAG, there is a directed path from U to Z, and Z\nis a descendant of U. \\(\\PA(X)\\) is the set of all parents of\nX and \\(\\ND(X)\\) is the set of all variables in \\(\\mathbf{V}\\)\nother than X and its descendants. In\n Figure 9,\n \\(\\PA(W) = \\{U, V\\}\\) and \\(\\ND(W) = \\{U, V, X\\}\\). \nA DAG represents the qualitative causal structure among the set of\nvariables in an individual from the relevant population. In\nparticular, an arrow from X to Y indicates that X\nhas a causal influence on Y that is not mediated by any other\nvariables in the set. In this case, we say that X is a direct\ncause of Y. \nFigure 9: A DAG on the variable set\n\\(\\{U, V, W, X, Y, Z\\}\\). \\(\\PA(W) = \\{U, V\\}\\) is the set of parents\nof W and \\(\\ND(W) = \\{U, V, X\\}\\) is the set of non-descendants\nof W. [An\n extended description of figure 9\n is in the supplement.]  \nThe Causal Markov Condition connects the graph \\(\\mathcal{G}\\) with\nthe probability distribution p over the algebra generated by\nthe variables. It says that p must exhibit specific relations\nof conditional probabilistic independence that are implied by the\ngraph. In the special case where \\(\\mathcal{G}\\) is a DAG, the\nfollowing three formulations of the Causal Markov Condition are\nequivalent: \nCausal Markov Condition: Screening off version. \nFor every variable X in \\(\\mathbf{V}\\), and every set of\nvariables \\(\\mathbf{Y} \\subseteq \\ND(X):\\) \nWe employ a notational convention where statements involving variables\nare understood to involve universal quantification over values of\nthose variables (or over measurable sets of values). This version of\nthe Causal Markov Condition says that the parents of variable X\nscreen X off from all other variables, except for X\nitself and the descendants of X. Given the values of the\nvariables that are parents of X, the values of the variables in\n\\(\\mathbf{Y}\\) make no further difference to the probability that\nX will take on any given value. This version of the Causal\nMarkov Condition is closest in form to Reichenbach’s Common\nCause Principle, although it is formulated in terms of the parents of\nX, rather than the common cause(s) of X and\nY. \nCausal Markov Condition: Factorization version. \nLet \\(\\mathbf{V} = \\{X_{1}, X_{2}, \\dots, X_{n}\\}\\). Then: \nThis version tells us that once we know the conditional probability\ndistribution of each variable given its parents,\n\\(p(X_{i}|\\PA(X_{i}))\\), we can compute the complete joint\ndistribution over all of the variables. This captures\nReichenbach’s idea that probabilistic correlations between\nevents can ultimately be derived from probabilistic correlations\nresulting from cause and effect relationships. \nCausal Markov Condition: d-separation\nversion. \nLet \\(\\mathbf{X}, \\mathbf{Y},\\) and \\(\\mathbf{Z}\\) be disjoint subsets\nof \\(\\mathbf{V}\\). Then: \nif \\(\\mathbf{Z}\\) d-separates \\(\\mathbf{X}\\) and\n\\(\\mathbf{Y}\\) in \\(\\mathcal{G}.\\) \nThis version introduces the graphical notion of d-separation.\nA path from X to Y is a sequence of variables \\((X =\nX_{1},\\dots, X_{k} = Y)\\) such that for each \\(X_{i}\\), \\(X_{i+1},\\) there\nis either an arrow from \\(X_{i}\\) to \\(X_{i+1}\\) or an arrow from\n\\(X_{i+1}\\) to \\(X_{i}\\) in \\(\\mathcal{G}\\). For example, in\n Figure 9,\n \\(\\{U, Y, W, V, X\\}\\) forms a path. A variable \\(X_{i}\\), \\(1 < i <\nk\\) is a collider on the path just in case there is an arrow\nfrom \\(X_{i-1}\\) to \\(X_{i}\\) and from \\(X_{i+1}\\) to \\(X_{i}\\). In\nother words, \\(X_{i}\\) is a collider just in case the arrows converge\non \\(X_{i}\\) in the path:  in\n Figure 9,\n Y is a collider on the path \\(\\{U, Y, W, V, X\\}.\\) Let\n\\(\\mathbf{X}, \\mathbf{Y}\\), and \\(\\mathbf{Z}\\) be disjoint subsets of\n\\(\\mathbf{V}\\). \\(\\mathbf{Z}\\) d-separates \\(\\mathbf{X}\\) and\n\\(\\mathbf{Y}\\) just in case every path \\((X_{1}, \\dots, X_{k})\\) from\na variable in \\(\\mathbf{X}\\) to a variable in \\(\\mathbf{Y}\\) contains\nat least one variable \\(X_{i}\\) such that either: (i) \\(X_{i}\\) is a\ncollider, and neither \\(X_{i}\\) nor any descendant of \\(X_{i}\\) is in\n\\(\\mathbf{Z}\\); or (ii) \\(X_{i}\\) is not a collider, and \\(X_{i}\\) is\nin \\(\\mathbf{Z}\\). In\n Figure 9,\n \\(\\{U, V\\}\\) d-separates \\(\\{Y\\}\\) and \\(\\{X\\}\\). The path\n\\(\\{Y, W, Z, X\\}\\) contains a collider at Z, and all other\npaths from Y to X include U or V as a\nnon-collider. \nThe Causal Markov Condition implies the generalized version of RCCP\npresented in\n Section 2.\n This is most easily seen using the d-separation version. If\nvariables X and Y are correlated, then \\(\\{X\\}\\) and\n\\(\\{Y\\}\\) are not d-separated by the empty set. This means\nthat at least one path between X and Y must be without a\ncollider. If we further assume that neither variable is a cause of the\nother, then there is no directed path between them. It then follows\nthat the collider-free path must contain a common cause: a variable\nZ that has both X and Y as descendants.\nFurthermore, the set of all such common causes d-separates\n\\(\\{X\\}\\) and \\(\\{Y\\}\\). (The proof is a bit fussy, since a common\ncause on one path can be a collider on another path.) Hence the set of\ncommon causes of X and Y will screen them off from one\nanother. \nNote that the Causal Markov Condition tells us that certain causal\nstructures give rise to relations of conditional probabilistic\nindependence. The Causal Markov Condition never entails\nprobabilistic dependence. For purposes of causal inference,\nthe Causal Markov Condition is often supplemented by a further\nprinciple governing when probabilistic dependence is to be expected.\nOne such principle is the Faithfulness Condition (Spirtes et\nal. 2000) which says that only the probabilistic\nindependencies entailed by the Causal Markov Condition are present.\nLooked at another way, the Faithfulness Condition says that when we\nfind a relation of conditional probabilistic independence, we should\ninfer a causal structure that entails that independence relation\nrather than one that doesn’t. \nOne justification for assuming the Causal Markov Condition is a\ntheorem due to Pearl and Verma (1991). Suppose that we have a variable\nset \\(\\mathbf{V}\\), and DAG \\(\\mathcal{G}\\) representing the causal\nrelations among the variables in \\(\\mathbf{V}\\). Suppose, in addition,\nthat the value of each variable X in \\(\\mathbf{V}\\) is a\ndeterministic function of its parents in \\(\\mathbf{V}\\), together with\nan error variable \\(U_{X}\\), which represents the influence\nof any variables that are not included in \\(\\mathbf{V}\\). In other\nwords, \\(X = f_{X}(\\PA(X), U_{X})\\). Then the values of all of the\nerror variables will uniquely determine the value of all of the\nvariables in \\(\\mathbf{V}\\), and a probability distribution \\(p^{*}\\)\nover the error variables will induce a probability distribution\np over the variables in \\(\\mathbf{V}\\). If the error variables\nare independent in \\(p^{*}\\), then the induced probability\ndistribution p will satisfy the Causal Markov Condition with\nrespect to \\(\\mathcal{G}\\). The idea is that if we include enough\nvariables in \\(\\mathbf{V}\\) so that any remaining causal influences\nare probabilistically independent of one another, then the probability\ndistribution over \\(\\mathbf{V}\\) will satisfy the Causal Markov\nCondition. \nA set of variables \\(\\mathbf{V}\\) is causally sufficient if\nthere is no variable W omitted from \\(\\mathbf{V}\\), such that\nif it were added to \\(\\mathbf{V}\\), it would be a direct cause of two\nvariables in \\(\\mathbf{V}\\). In\n Figure 9,\n \\(\\{U, W, Y\\}\\) is causally sufficient (assuming the original DAG\nis), but \\(\\{U, W, Y, Z\\}\\) is not, since W and Z have a\ncommon cause, V, that is left out of this set. \nIt is usually assumed that if a variable set is causally sufficient,\nthen the error variables will be probabilistically independent, and\nthe probability distribution over \\(\\mathbf{V}\\) will satisfy the\nCausal Markov Condition with respect to the true causal graph. Note\nthat this assumption is very similar to the Common Cause Principle\nitself. If X and Y are variables included in a causally\nsufficient DAG, and \\(U_X\\) and \\(U_Y\\) are their corresponding error\nvariables, then neither \\(U_X\\) nor \\(U_Y\\) is a cause of the other,\nand they do not have a common cause. If they had a common cause, this\nwould be a common cause of X and Y; if \\(U_X\\) is a\ncause of \\(U_Y\\), then \\(U_X\\) is a common cause of X and\nY. So the causal sufficiency of the variable set implies that\n\\(U_X\\) and \\(U_Y\\) are causally unrelated. The Common Cause Principle\nwould then imply that they are probabilistically independent. Thus it\nwould be inaccurate to say that the Causal Markov Condition can be\nused to justify the Common Cause Principle: both involve\ncomparable assumptions about the relationship between causation and\nprobability. \nExamining the d-separation version of the Causal Markov\nCondition, we see that it is not common causes but rather colliders\nthat give rise to distinctive probabilistic relationships. Suppose\nthat we have a variable set with three variables \\(\\{X, Y, Z\\}\\), and\nthat the probability distribution p satisfies the Causal Markov\nCondition with respect to the true causal graph. Finally, suppose that\nX and Z are correlated, but screened off by Y.\nThen there are three different causal graphs that all imply just this\nset of probabilistic independence relations: \nThe last of these, of course, is the Common Cause Structure\ncharacterized by Reichenbach. (However, Reichenbach also postulated\nthat intermediate causes would screen off distal causes from their\neffects, as indicated in the first two diagrams.) On the other hand,\nsuppose the relations of probabilistic (in)dependence are exactly the\nopposite. That is: X and Z are probabilistically\nindependent, but dependent conditional on Y. In this case,\nthere is only one causal structure that implies just this set of\nprobabilistic independence relations: \nIndeed, algorithms for inferring causal structure from relations of\nconditional probabilistic dependence and independence, such as the\nPC algorithm of Spirtes et al. (2000), proceed by searching\nfor this type of probabilistic signature. Thus Reichenbach was\nmistaken in looking to conjunctive forks to define the direction of\ncausation (see\n Section 6\n above). He would have done better to look to colliders. \nA classical probability measure space is a triplet \\((X,{\\cal S},p)\\),\nwhere X is the set of elementary random events, \\({\\cal S}\\) is\na Boolean algebra of some subsets of X and p is the\nadditive probability measure from \\({\\cal S}\\) into the unit interval\n\\([0,1]\\). The probability measure space \\((X,{\\cal S},p)\\) is called\ncommon cause complete if there exists a common cause C\nin \\({\\cal S}\\) of every correlated pair \\((A,B)\\) of elements \\(A,B\\)\nin \\({\\cal S}\\), common cause incomplete otherwise. One can\nshow that common cause (in)completeness can be characterized in terms\nof the measure theoretic (non)atomicity of probability measure spaces:\n\\((X,{\\cal S},p)\\) is common cause complete if and only if \\((X,{\\cal\nS},p)\\) contains at most one measure theoretic atom (Gyenis &\nRédei 2011). A measure theoretic atom is an element \\(A_0\\) in\n\\({\\cal S}\\) such that \\(p(A_0)\\not=0\\), and, if \\(B\\subset A_0\\),\nthen \\(p(B)=0\\). In particular measure theoretically purely non-atomic\nprobability measure spaces (i.e., probability spaces that do not\ncontain any measure theoretic atom) are common cause complete (Gyenis\n& Rédei 2011; Hofer-Szabó et al. 2013; Marczyk &\nWroński 2015). An example of a measure theoretically purely\nnon-atomic probability measure space is the unit interval \\([0,1]\\)\nwith the uniform probability (Lebesgue measure) on the Lebesgue\nmeasurable subsets of \\([0,1]\\); a class of examples are probability\nmeasures on the (Lebesgue measurable subsets of the) real line where\nthe probability is given by a density function with respect to the\nLebesgue measure on the real line. \nA common cause incomplete probability space \\((X,{\\cal S},p)\\) is\ncalled common cause completable if it can be embedded into a\nlarger probability space \\((X',{\\cal S}',p')\\) that is\ncommon cause complete. An embedding of \\((X,{\\cal S},p)\\) into\n\\((X',{\\cal S}',p')\\) is an injective Boolean algebra\nhomomorphism h from \\({\\cal S}\\) into \\({\\cal S}'\\) such\nthat \\(p'(h(A))=p(A)\\) for all A in \\({\\cal S}\\). One can\nshow that every probability space \\((X,{\\cal S},p)\\) can be embedded\ninto a purely nonatomic probability space. This entails that every\ncommon cause incomplete probability space is common cause completable\n(Gyenis & Rédei 2011; Hofer-Szabó et al. 2013;\nMarczyk & Wroński 2015). \nIn quantum theory one uses non-classical (quantum) probability spaces\nto describe quantum physical systems. A general quantum probability\nspace is a pair \\(({\\cal P} ({\\cal N}),\\phi)\\), where \\({\\cal P}\n({\\cal N})\\) is the orthocomplemented, orthomodular lattice of\nprojections of a non-commutative von Neumann algebra \\({\\cal N}\\) and\n\\(\\phi\\) is a countably additive probability measure on \\({\\cal P}\n({\\cal N})\\), which is the restriction to \\({\\cal P} ({\\cal N})\\) of a\nnormal state on \\({\\cal N}\\). Rédei & Summers (2007a)\nprovides a brief description of non-commutative probability theory in\nterms of von Neumann algebras; Landsman (2017) contains an\nencyclopedic treatment of the algebraic structures relevant for\nquantum theory; the SEP entry on\n quantum theory and mathematical rigor\n gives a very brief informal introduction to some basic facts on von\nNeumann algebras, including their Murray-von Neumann classification,\nwhich is relevant from the perspective of the Common Cause\nPrinciple—see below). A special example of a quantum probability\nspace is obtained by taking the set of all bounded operators \\({\\cal\nB} ({\\cal H} )\\) on a (possibly infinite dimensional) Hilbert space\n\\({\\cal H}\\) as the von Neumann algebra and \\(\\phi\\) a quantum state\ngiven by a density matrix. The resulting specific quantum probability\nspace \\(({\\cal P}({\\cal B}({\\cal H})),\\phi)\\) is known as the\n“Hilbert space formalism” of quantum mechanics; this space\ndescribes quantum systems of finite degrees of freedom. The\northomodular lattice \\({\\cal P}({\\cal B}({\\cal H}))\\), frequently\ndenoted as \\({\\cal P} ({\\cal H})\\), is the set of all projections on\n\\({\\cal H}\\), this lattice is also called “Hilbert\nlattice”. \nThe concept of correlation between commuting projections \\(A,B\\) in\n\\({\\cal P} ({\\cal N})\\) and the notion of common cause of such\ncorrelations as a projection C commuting with both A and\nB and satisfying the (analogues) of the\n four Reichenbachian conditions (2)–(5)\n make perfect sense in quantum probability spaces. So do the concepts\nof common cause (in)completeness, common cause completability (with a\nsuitably defined embedding of orthomodular lattices), measure\ntheoretic atoms and measure theoretic non-atomicity. \nOne can show that common cause completeness of such quantum\nprobability spaces can be characterized in terms of measure theoretic\natomicity of \\(({\\cal P} ({\\cal N}),\\phi)\\) in complete analogy with\nthe classical case: \\(({\\cal P} ({\\cal N}),\\phi)\\) is common cause\ncomplete if it contains at most one measure theoretic atom (Kitajima\n2008; Gyenis & Rédei 2014; Kitajima & Rédei\n2015). This entails that measure theoretically purely non-atomic\nquantum probability spaces are common cause complete. Specifically,\nquantum probability spaces \\(({\\cal P} ({\\cal N}),\\phi)\\) with a type\nIII or type II von Neumann algebra \\({\\cal N}\\) are common cause\ncomplete because the quantum probability spaces defined by these types\nof von Neumann algebras are purely measure theoretically non-atomic.\nThe quantum probability space \\(({\\cal P} ({\\cal H}),\\phi)\\) is not\npurely nonatomic, it contains a lot of measure theoretic atoms: all\nthe rank-one projections (equivalently: one dimensional linear spaces\nspanned by vectors in \\({\\cal H}\\)) are atoms of the Hilbert lattice\n\\({\\cal P} ({\\cal H})\\), hence all rank-one projections that are\nassigned non-zero probability by state \\(\\phi\\) are also measure\ntheoretic atoms in \\(({\\cal P} ({\\cal N}),\\phi)\\). Thus \\(({\\cal P}\n({\\cal H}),\\phi)\\) is not common cause complete. Whether common cause\nincomplete quantum probability spaces are common cause completable, is\nnot known; results are available on common cause\nextendability of quantum probability spaces only: Every\nquantum probability space \\(({\\cal P} ({\\cal N}),\\phi)\\) is embeddable\ninto a larger quantum probability space \\(({\\cal P}({\\cal\nN}'),\\phi')\\) in such a way that every correlation in \\(({\\cal\nP} ({\\cal N}),\\phi)\\) has a common cause in \\(({\\cal P}({\\cal\nN}'),\\phi')\\) (Hofer-Szabó, Rédei, &\nSzabó 1999; 2013: 62, Proposition 6.3). \nThe philosophical significance of common cause completability and\ncommon cause extendability of (classical and quantum) probability\nspaces is that they show that it is always possible in principle to\nexplain any correlation, hence also any correlation between causally\nindependent events, in terms of (possibly hidden) common\ncauses—hidden in the sense that the common causes need not be in\nthe probability space that contains the correlation: the common causes\ncan be “hiding” in a larger probability space. Thus these\ncommon cause completability and common cause extendability results\nconstrain the possible ways of attempts to falsify the Common Cause\nPrinciple: Any attempt at falsification should impose some further\nconditions on the common causes in addition to the four defining\n conditions (2)–(5),\n otherwise falsification can be evaded by referring to hidden common\ncauses. Formulated differently: The Common Cause Principle, as\nformulated exclusively in terms of the notion of a Reichenbachian\ncommon cause, either in a classical or in a quantum probability\ntheory, is not falsifiable. This does not mean that the common cause\nextendability results can be regarded as proof that the Common Cause\nPrinciple is true: Even the weaker question of whether a common cause\nextendability result can be taken as confirming evidence for the\nCommon Cause Principle depends on whether the extended probability\nmeasure space, existence of which is warranted by the mathematical\ncommon cause extendability results, is (part of) an empirically\nconfirmed scientific theory. \nThe significance of common cause complete spaces is that they display\na very strong compliance with the Common Cause Principle: An\nequivalent formulation of the Common Cause Principle is that\nprobability theories describing the world are causally closed in the\nfollowing sense: if A and B are correlated and are\ncausally independent, \\(R_{ind}(A,B)\\) in notation, then the\ncorrelation has to have a common cause that explains the correlation.\nCommon cause complete spaces are causally closed in the extremely\nstrong sense that the causal independence relation \\(R_{ind}(A,B)\\)\ncan be taken to be the strongest one, containing all correlated\nevents. Thus, if a scientific theory describing some aspect of reality\nuses a measure theoretically purely non-atomic probability space, such\na theory can be regarded as evidence in favor of the Common Cause\nPrinciple because that theory contains common causes of all\ncorrelations, including correlations that are between events that the\ntheory might regard as causally unrelated (independent). In view of\nthe interpretation of common cause completeness, common cause\ncompletability and common cause extendability, it is a relevant\nquestion whether our well-confirmed scientific theories are causally\nclosed or common cause extendable. Quantum field theory and standard\nnon-relativistic quantum mechanics are two theories for which this\nquestions has been analyzed extensively. \nRelativistic quantum field theory (see entry on\n quantum field theory)\n predicts an abundance of correlations between observables that are\nlocalized in spacelike separated (hence causally independent)\nspacetime regions. This is a consequence of prevalence of entanglement\nand of violation of Bell’s inequality in quantum field theory,\nwhich is even more striking than violation of Bell’s inequality\nby standard, non-relativistic quantum mechanics (Summers 1997; Clifton\n& Halvorson 2001; Halvorson & Clifton 2000; entry on\n Bell’s theorem).\n If relativistic quantum field theory is causally closed in the sense\nof providing common causes of these correlations, then this theory is\nconfirming evidence for the truth of the Common Cause Principle. \nThe quantum probability spaces describing relativistic quantum field\ntheory are based on type III von Neumann algebras (Haag 1992; Horuzhy\n1986 [1990]; Araki 1993 [1999]; entry on\n quantum field theory;\n consequently, these quantum probability spaces are measure\ntheoretically purely non-atomic. It follows then from the common cause\ncompleteness of such quantum probability spaces that there exists\ncommon causes of the correlations between spacelike separated\nobservables. Yet, one cannot conclude from this that quantum field\ntheory satisfies the Common Cause Principle, for the following reason:\nobservables in quantum field theory are explicitly associated with\nspecific spacetime regions. So the common causes also should be\nrequired to belong to specific spacetime regions. Given a correlation\nbetween observable A localized in spacetime region \\(V_1\\) and\nobservable B localized in spacetime region \\(V_2\\) spacelike\nseparated from \\(V_1\\), the common cause for this correlation should\nbe localized in a region V that is in the intersection of the\nbackward light cones of the spacelike separated spacetime regions\n\\(V_1\\) and \\(V_2\\). But the mere pure non-atomicity of the quantum\nprobability space of quantum field theory does not entail any such\nlocality of the common causes that exist as a consequence of the\nnon-atomicity of the quantum probability space describing quantum\nfields. When one imposes this additional localizability constraint on\nthe common causes in quantum field theory, the question of whether\nsuch properly localized common causes exist according to the\ntheory, becomes a highly non-trivial problem (Rédei 1997). So\nnon-trivial that the answer to it is still not known—the problem\nof status of causal completeness of quantum field theory is an open\nquestion. \nIt is known however that quantum field theory is causally complete in\nthe weaker sense of containing common causes localized in the\nunion (as opposed to the intersection) of the\nbackward light cones of the spacelike separated spacetime regions\n\\(V_1\\) and \\(V_2\\) that contain the correlated observables\n(Rédei & Summers 2002, 2007b; Hofer-Szabó et al.\n2013). It also is possible logically that the status of the Common\nCause Principle in relativistic quantum field theory cannot be\ndecided: The quantum field theory in which the abundance of\ncorrelations between spacelike separated observables has been proven\nis defined by axioms (Haag-Kastler axiomatization). The axioms might\njust be too weak to give an answer to the question whether all\ncorrelations between spacelike separated observables have properly\nlocalized common causes. Proving such an independence result would be\nvery interesting. Given how difficult it is to create any model of the\nHaag-Kastler axioms, attempting such a proof also appears to be\nextremely difficult because it requires displaying two models, one in\nwhich the Common Cause Principle holds (with properly localized common\ncauses), one in which it does not. \nOne also can consider the problem of the status of the Common Cause\nPrinciple in discrete (lattice) quantum field theory. This is a\nsimplified model of quantum field theory in which calculations are\nfrequently easier to carry out. One of the simplifications of this\ntheory is that the algebras of local observables are finite\ndimensional. The quantum probability spaces determined by such\nobservables are not purely non-atomic and this prevents common\ncauses—localized or not—to exist in these theories\n(Hofer-Szabó & Vecsernyés 2012a). If, in the quantum\ncontext, one allows common causes not to commute with the correlated\nobservables, then “non-commutative” common causes can be\nshown to exist in lattice quantum field theory (Hofer-Szabó\n& Vecsernyés 2012b, 2013, 2018). One also can raise the\nproblem of the status of the Common Cause Principle in categorial\nquantum field theory (Brunetti, Fredenhagen, & Verch 2003;\nRédei 2014a). This requires a reformulation of the concept of\ncommon cause in terms of the notions of the categories used in\ncategorial quantum field theory, which is done in Rédei\n(2014a). This then leads to a number of specific questions about the\nstatus of the suitable reformulated Common Cause Principle. Most of\nthese questions are open—this is an active area of research. \nStandard non-relativistic quantum mechanics of finite degrees of\nfreedom predicts the famous EPR correlations (see entry on\n the Einstein-Podolsky-Rosen argument in quantum theory),\n which have been observed in sophisticated physical measurements (see\nentry on\n Bell’s theorem).\n These correlations are between events that are spacelike separated\n(hence causally independent according the special theory of\nrelativity). Thus, they can serve as evidence to assess the status of\nthe Common Cause Principle: These EPR correlations should have common\ncauses if the Common Cause Principle describes the physical world\ncorrectly. \nThe quantum probability space that predicts the EPR correlations does\nnot contain common causes for these correlations because this quantum\nprobability space is defined on a finite dimensional Hilbert space and\nsuch a quantum probability space is not purely non-atomic hence not\ncommon cause complete. The question of whether “hidden”\ncommon causes for such correlations can in principle exist has been\nextensively discussed in a large literature. The first informal\ndiscussion seems to be von Neumann’s letter to Schrödinger\nin 1935 (Von Neumann 2005: 211–213). In this letter von Neumann\ntakes the position that no correlation, including EPR-type quantum\ncorrelations, is problematic as long as one can find a common cause\nfor it—although von Neumann does not use the term “common\ncause”, nor does he define any notion of common cause explicitly\n(Rédei 2006). The first technically explicit no-go theorem on\ncommon causes of EPR correlations is due to van Fraassen (1982). In\nthis paper it is assumed however that a single common cause explains\ndifferent correlations—i.e., that common causes are\ncommon common causes. It turns out however that, given a set\n\\((A_i,B_i)\\) (\\(i=1,2,\\ldots\\)) of pairs of correlated events in a\nclassical probability measure space, requiring the existence of a\ncommon cause \\(C_i\\) for each correlated pair \\((A_i,B_i)\\) is a much\nweaker assumption than requiring the existence of a single C\nthat is the common cause of all correlated pairs \\((A_i,B_i)\\)\n(\\(i=1,2,\\ldots\\)): one can give examples of different correlations in\na classical probability measure space that cannot have the same common\ncause (Hofer-Szabó, Rédei, & Szabó 2002).\nThus if one aims at deriving no-go propositions on the existence of\ncommon causes of EPR correlations then one has to either argue that\nthe different correlations in the EPR-situation should have the same\ncommon cause or one should impose further conditions on the common\ncauses in addition to those in\n Reichenbach’s definition (2)–(5). \nThere are two types of such additional conditions, both motivated by\nthe specific features of the EPR-scenario: “Locality\nconditions” and requirements expressing what is called\n“no-conspiracy”. Furthermore, both locality and\nno-conspiracy come in two varieties: surface and\nhidden locality conditions on one hand and weak and\nstrong no-conspiracy conditions on the other. The content of\nthe surface locality condition is that “… the probability\nof the outcome in one wing of the EPR correlation experiment is the\nsame no matter in which direction the measurement is carried out in\nthe other wing of the EPR experiment.” (Hofer-Szabó et\nal. 2013: 143).  The hidden locality conditions require that  \n... given a pair of correlated outcomes of an EPR\ncorrelation experiment, the probability of the outcome in one wing of\nthe EPR correlation experiment be the same no matter in which\ndirection the measurement is carried out in the other wing of the EPR\nexperiment if the hypothetical common cause of this\ncorrelation also has happened. (Hofer-Szabó et al. 2013:\n144).  \nThe weak no-conspiracy condition requires that any choice of\nthe direction in which a measurement is decided to be carried out in\nany wing of the EPR experimental setup is probabilistically\nindependent of the hypothetical common cause explaining the\ncorrelation in the chosen direction. The strong no-conspiracy\ncondition requires that any Boolean combination of choices of\nmeasurement directions in the two wings of the EPR experiment are\nprobabilistically independent of any Boolean combination of\nthe hypothetical common causes. (Hofer-Szabó et al. 2013:\n178).  \nThe differences between the different versions of the locality and\nno-nonspiracy conditions are conceptually significant and they are\nalso crucial from the perspective of whether hypothetical common\ncauses of EPR correlations can be ruled out by no-go theorems: The\nsurface locality conditions are empirically testable due to the fact\nthat all the events involved in it are observable. The hidden locality\nconditions involve the unobserved, hypothetical common cause events\nand, as a consequence, these locality conditions are not testable\nindependently of the observation of the common causes. The\ninterpretation of the no-conspiracy conditions is somewhat\ncontroversial: it declares as an implausible conspiracy on the part of\nnature if common causes influenced not only the outcomes of the EPR\ncorrelation experiments but also the choices of measuring in\nparticular directions in the wings of the EPR experiment. These\nchoices, we feel, are free, depending on the experimenter’s\ndecision. \nOne can show that weakly non-conspiratorial common cause\nexplanations of EPR correlations satisfying surface locality are\npossible. But strongly non-conspiratorial, hidden\nlocal common cause explanations of EPR correlations are ruled out\n(Hofer-Szabó et al. 2013: 152, 163). These results show\nthat the EPR correlations cannot be regarded as strictly empirical\nevidence against the Common Cause Principle because the type of common\ncauses that can be ruled out have features by assumption that are not\nempirically testable (hidden locality and no-conspiracy)—they\nare metaphysical in character. \nOther accessible overviews of Reichenbach’s Common Cause\nPrinciple include Chapter 6 of Salmon (1984) and Arntzenius\n(1999 [2010]), which is a previous version of the present\nentry. The entry on\n Hans Reichenbach\n provides an overview of Reichenbach’s philosophy.\nReichenbach’s probabilistic theory of causation is discussed in\nthe entry on\n causation, probabilistic.\n Issues related to temporal asymmetry in thermodynamics are discussed\nin the entry on\n thermodynamic asymmetry in time.\n The Causal Markov Condition is discussed at greater length in the\nentry on\n causal models.\n This encyclopedia contains numerous entries on philosophical issues\nrelated to quantum mechanics. Of particular relevance are\n the Einstein-Podolski-Rosen argument in quantum theory,\n philosophical issues in quantum theory,\n quantum logic and probability theory,\n and\n Quantum Mechanics. \nTwo recent book-length treatments of RCCP are Hofer-Szabó et\nal. (2013) and Wroński (2014). Further good discussions of the\nCommon Cause Principle include Arntzenius (1990, 1992); Cartwright\n(1988); Van Fraassen (1982b); Gyenis and Redei (2011, 2014); Henson\n(2005); Hofer-Szabó et al. (1999, 2002); Marczyk and\nWroński (2015); Mazzola (2012, 2013); Mazzola and Evans (2017);\nRédei (2014b); San Pedro (2008); Sober (1984, 1988 1989,\n2008); Spohn (1994); Suppes (1970, 1984); Uffink (1999); and\nWroński (2010). \nDiscussion of counterexamples to RCCP are found in Cartwright (1994,\n2007); Hoover (2003); Sober (2001); and Steel (2003).  \nDiscussions of RCCP in the context of quantum theory include\nButterfield (1989, 2007); Chang and Cartwright (1992) Kowalski and\nPlacek (1999); Penrose and Percival (1962); Placek (2000a,b); van\nFraassen (1982a, 1991); Wüthrich (2004); and Wiseman and\nCavalcanti (2017).","contact.mail":"M.Redei@lse.ac.uk","contact.domain":"lse.ac.uk"}]
