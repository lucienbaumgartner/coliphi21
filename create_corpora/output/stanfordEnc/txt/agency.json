[{"date.published":"2015-08-10","date.changed":"2019-10-28","url":"https://plato.stanford.edu/entries/agency/","author1":"Markus Schlosser","entry":"agency","body.text":"\n\nIn very general terms, an agent is a being with the capacity to\nact, and ‘agency’ denotes the exercise or manifestation of\nthis capacity. The philosophy of action provides us with a standard\nconception and a standard theory of action. The former construes\naction in terms of intentionality, the latter explains the\nintentionality of action in terms of causation by the agent’s\nmental states and events. From this, we obtain a standard conception\nand a standard theory of agency. There are alternative conceptions of\nagency, and it has been argued that the standard theory fails to\ncapture agency (or distinctively human agency). Further, it seems that\ngenuine agency can be exhibited by beings that are not capable of\nintentional action, and it has been argued that agency can and should\nbe explained without reference to causally efficacious mental states\nand events.\n\nDebates about the nature of agency have flourished over the past\nfew decades in philosophy and in other areas of research (including\npsychology, cognitive neuroscience, social science, and\nanthropology). In philosophy, the nature of agency is an important\nissue in the philosophy of mind, the philosophy of psychology, the\ndebates on free will and moral responsibility, in ethics, meta-ethics,\nand in the debates on the nature of reasons and practical\nrationality. For the most part, this entry focuses on conceptual and\nmetaphysical questions concerning the nature of agency. In the final\nsections, it provides an overview of empirically informed accounts of\nthe sense of agency and of various empirical challenges to the\ncommonsense assumption that our reasons and our conscious intentions\nmake a real difference to how we act.\n\nIn a very broad sense, agency is virtually everywhere. Whenever\nentities enter into causal relationships, they can be said to act on\neach other and interact with each other, bringing about changes in\neach other. In this very broad sense, it is possible to identify\nagents and agency, and patients and patiency, virtually \neverywhere.[1]\nUsually, though, the term ‘agency’ is used in a much narrower sense to denote the performance of intentional actions. This\nway of thinking about agency has a long history in philosophy and it\ncan be traced back to Hume and Aristotle, among other historical\nfigures. In contemporary analytic philosophy, it is most commonly\nassociated with the influential work of Anscombe (1957) and Davidson\n(1963). Anscombe’s and Davidson’s views differ\nsignificantly in many respects, but they share the central doctrine\nthat action is to be explained in terms of the intentionality of intentional action. In the debates that followed, the philosophy of\naction revolved largely around the notion of intentional action. For\nsome time, the term ‘agency’ was rarely used, and if it was, it was usually taken to refer to the exercise of the capacity to perform intentional actions.[2] This has changed in the more recent\ndebate, where talk about agency has become more and more common in\nmany areas of philosophy (and in other areas of\nresearch).[3] To\nsome extent, this focus on the notion of agency has been fuelled by a\nresistance to the assimilation of agency to intentional action. As we\nwill see in the following section, this resistance amounts in some\ncases to the rejection of the standard conception of action,\nin some cases it amounts to the rejection of the\nstandard theory of action, and in some it amounts to the\nmore modest claim that there are different kinds of\nagency. The contributions of Anscombe and Davidson have established a\nstandard conception of action, and Davidson’s work has provided\nthe groundwork for a standard theory of action. At the core of the\nstandard conception are the following two claims. First, the notion of\nintentional action is more fundamental than the notion of action. In\nparticular, action is to be explained in terms of the intentionality\nof intentional action. Second, there is a close connection between\nintentional action and acting for a reason. There are two ways of spelling out the first claim (which\ncorrespond to two different views on the individuation of actions; see\nsection 3.4). According to the first, one\nand the same event can be more than one action under different\ndescriptions, and an event is an action just in case it is an\nintentional action under some description. An action, that\nis, may be intentional under some description and unintentional under\nothers (Anscombe 1957; Davidson 1963). Suppose that you alert the\nburglar by turning on the light, and suppose that this is one event\nthat is intentional under the description ‘turning on the\nlight’, but not under ‘alerting the burglar’. On this view, alerting the burglar is nevertheless something that you do,\ngiven that the event is an intentional action under some description.\nAccording to a second way of spelling out the first claim, something\nis an action either if it is identical with or “generated\nby” an intentional action (Goldman 1970; see also Ginet\n1990).[4] On this view, alerting the burglar is an action of yours either if it\nis an intentional action or if it is generated by an intentional\naction (your turning on the light, in this case). If it is merely\ngenerated by an intentional action, it is an unintentional action of\nyours. On both views, intentional action is more fundamental than\naction itself: action derives from and is dependent on intentional\naction.[5] According to the second claim of the standard conception, there is\na close connection between acting intentionally and acting for a\nreason. According to Anscombe and Davidson’s early view, this\nclose connection is identity. Following Aristotle, they both held the\nview that to act intentionally is to act for a reason, and that to\nact for a reason is to act in a way that can be rationalized by the\npremises of a sound practical syllogism, which consists, typically,\nof a major premise that corresponds to the agent’s goal and a\nminor premise that corresponds to the agent’s take on how to\nattain the goal. Furthermore, Davidson held the view that having an\nintention consists in having a desire and a belief that correspond to\nthe major and the minor premise of the relevant syllogism (Davidson\n1963, 1970; see also Goldman 1970; Audi\n1986).[6] One can still find a fairly widespread commitment to this\ndesire-belief version of the standard conception (in the philosophy of\nmind, the philosophy of psychology, ethics, meta-ethics, and in other\nareas of research). In the philosophy of action, however, it is now\nwidely thought that intentions cannot be reduced to desires and\nbeliefs (and combinations thereof). On this view, intentions play a\ncrucial and irreducible role in practical reasoning, long-term\nplanning, and in the initiation and guidance of action (see,\nespecially, Bratman 1987; see also Harman 1976; Brand 1984; Bishop\n1989; Mele 1992, 2003; Enç 2003). It is nevertheless still\nwidely accepted that there is a close connection between intentional\naction and acting for reasons and that intentional actions are\ntypically performed for reasons (Mele and Moser 1994; Mele 2003;\nEnç 2003; Clarke 2010b, for instance). The standard conception is not committed to a particular\naccount of what it is to act intentionally and for reasons, and it is\nnot committed to a particular account of the nature of reason\nexplanations. It is important to distinguish the standard conception\nfrom the standard theory, which provides a causal account of\nintentional action and reason explanation. This theory says, very\nroughly, that something is an intentional action and done for reasons\njust in case it is caused by the right mental states and events in the\nright way. The right mental states and events are states and events\nthat rationalize the action from the agent’s point of view (such\nas desires, beliefs, and intentions). The right way of causation is\nnon-deviant causation (see\nsection 3.2). On this view, a reason explanation is an explanation in terms of\nmental states and events that cause the action and that rationalize it\nfrom the agent’s point of view (typically by providing a\nmeans-end rationale). This theory is often called “the causal\ntheory of action”. Strictly speaking, it is an event-causal\ntheory and it consists of an event-causal theory of reason explanation\nand an event-causal theory of intentional action. In conjunction with\nthe standard conception, this causal theory provides us with a theory\nof action, which has been the standard theory in the contemporary\nphilosophy of mind and action (see also the entry on\naction). As indicated, the standard conception is compatible with non-causal\ntheories of intentional action and reason explanation. It is generally\nagreed that a reason explanation of an action usually renders the\naction intelligible by revealing the agent’s goal or intention.\nAccording to non-causal theories, having the relevant goals or\nintentions does not consist in the possession of causally\nefficacious mental states or events (Melden 1961; Ginet 1990;\nO’Connor 2000; Sehon 2005). Non-causal theories are, however,\nwidely rejected (the most influential critique is due to Davidson\n1963; see also Goldman 1970: 76–85; Mele 2003: 38–51;\nClarke 2003: 21–24). The standard conception is compatible,\nfurthermore, with dual standpoint theories. We will turn to this view\nin\nsection 3.3. The standard conception of action provides us with a conception of\nagency. According to this view, a being has the capacity to exercise agency just\nin case it has the capacity to act intentionally, and the exercise of\nagency consists in the performance of intentional actions and, in many\ncases, in the performance of unintentional actions (that derive from\nthe performance of intentional actions; see\nsection 2). Call this the standard conception of agency. The standard theory of action provides us with a theory of agency, according to which a being\nhas the capacity to act intentionally just in case it has the right\nfunctional organization: just in case the instantiation of certain\nmental states and events (such as desires, beliefs, and intentions)\nwould cause the right events (such as certain movements) in the right\nway. According to this standard theory of agency, the exercise of\nagency consists in the instantiation of the right causal relations\nbetween agent-involving states and events. (Proponents include\nDavidson 1963, 1971; Goldman 1970; Brand 1984; Bratman 1987; Dretske\n1988; Bishop 1989; Mele 1992, 2003; Enç 2003.) The most serious problem for this standard theory has been the\nproblem of deviant causal chains. Further, some have argued that this\nview altogether fails to capture agency, because it reduces actions to\nmere happenings. We will turn to those issues in\nsection 3. Recently, it has been argued that reasons for actions cannot be the\ncauses of actions, because reasons are facts or states of affairs, not\nmental states or events (Dancy 2000; Alvarez 2010). But the standard\ntheory is not committed to the claim that reasons are identical with\nmental entities. It is, in particular, compatible with the view that\nreasons are the things that are represented by the contents of the\nrelevant mental states and events (see Scanlon 1998: 56–64; Mele\n2003: 82–84; Setiya 2007: 28–31). It has often been claimed, and it is widely agreed, that agency\ninvolves the initiation of action by the\nagent.[7] But it\nhas been controversial what this consists in. The standard conception\nis compatible with the claim that intentional actions are initiated\nby the agent, and proponents of the standard theory have argued that\ninitiation can be explained in terms of causation by the\nagent’s mental states and events. According to desire-belief\nversions of the view, initiation by the agent consists in causation\nby the relevant desire-belief pairs (Goldman 1970; Davidson 1971;\nDretske 1988). According to more recent versions, initiation consists\nin causation by the relevant intentions (Brand 1984; Bratman 1987;\nBishop 1989; Mele 1992, 2003; Enç 2003). Opponents of the\nstandard conception argue, however, that an agent’s power to\ninitiate action cannot be reduced to the capacity to act\nintentionally and for reasons. They argue that the exercise of agency\nmay be entirely spontaneous, in the sense that an agent may initiate\nan action for no reason and without prior intent. On this view,\nreasons and intentions may have a strong and even a decisive\ninfluence on how an agent acts. But agency has its source in the\npower to initiate, and the exercise of this power cannot be reduced\nto the agent’s being moved by reasons or intentions. This is an\nalternative conception of agency (Ginet 1990; O’Connor\n2000; Lowe 2008; see also McCann 1998; for critical discussion see\nMele 2003: 38–51, 71–76; Clarke 2003:\n17–24). Proponents of this alternative conception reject the\nstandard theory and they reject, more generally, any account of\nagency in terms of causal relations between agent-involving states\nand events. According to some, the initiation of action consists in\nirreducible agent-causation, others appeal to uncaused mental acts of\nthe will. The main positions on this issue correspond to the main\npositions in the metaphysics of agency, to which we turn in\nsection 3.1. In an influential article, Frankfurt (1971) argued that the\ndifference between persons and other agents consists in the structure\nof their will. Only persons reflect on and care about their\nmotivations. According to Frankfurt, this reflective evaluation of our\nmotives usually results in the formation of second-order desires:\ndesires that are directed at first-order desires (which are directed\nat goals and actions). When a person wants to have a certain desire\nand wants to be moved by it, then he or she is said to\n“identify” with the desire and its motivational efficacy.\nOn this hierarchical account of agency, the role of higher-order\nattitudes is essential to the kind of agency that distinguishes\npersons from other agents. Taylor (1977) took this as a starting point\nfor an account of distinctively human agency, under the\nassumption that the distinction between persons and non-persons is,\nessentially, the distinction between human and non-human agents. It is\nnot entirely clear whether Frankfurt and Taylor meant to provide an\nalternative to the standard theory of agency or an extension\nof it.[8] On one\nreading, they accepted the account of intentional agency provided by\nthe standard theory, and they proposed a hierarchical extension of the\nstandard theory that captures the kind of agency that is distinctive\nof persons or human agents. (For an influential critique of such\nhierarchical accounts see Watson 1975.) According to Velleman (1992), Frankfurt’s observation that an\nagent may fail to identify with a particular motive points to a\nfundamental flaw in the standard theory. As it seems always possible\nthat an agent “disowns” the mental attitudes that cause an\naction, those attitudes do not “add up to the agent’s\nbeing involved” (1992: 463). This shows, according to Velleman,\nthat the standard theory captures, at best, actions that are\ndefective. It fails, in particular, to capture “human\naction par excellence”, because it fails to account for\nthe agent’s participation. Velleman rejects the appeal to\nirreducible agent-causation (see\nsection 3.1), and he argues that this leaves only one strategy for solving the\nproblem: we must find a mental attitude that the agent cannot disown\nand that is, therefore, fit to play the role of the agent. We must,\nthat is, find a mental attitude that is the agent,\nfunctionally speaking. According to Velleman, the desire to act in\naccordance with reasons is fit to play this role. Bratman (2000, 2001) agrees with Velleman that the standard theory\ndoes not explain genuine self-governance. On his view, though, an\naccount of “full-blown agency”, as he calls it, does not\nrequire reference to a mental attitude that the agent cannot disown.\nBuilding on his work on temporally extended planning agency (Bratman\n1987), he argues that an agent’s “self-governing\npolicies” have the “authority to speak for the\nagent”, because they help to establish and support the\nagent’s identity across time, and because they specify which\ndesires are to be treated as providing justifying reasons in practical\ndeliberation. According to Bratman, these self-governing policies\nexplain what it is for an agent “to take a stand in favor of or\nagainst certain motivations, a stand that can itself be subject to\nreexamination and revision” (2000: 50–51). (For a critical\ndiscussion of Bratman’s account see Hornsby 2004 and Franklin 2017.) In defense of the standard theory, Mele (2003: Ch. 10) has argued\nthat the search for a mental attitude that plays the role of the agent\nis misguided and that Velleman’s critique of the view is off\ntarget. As Mele points out, it seems clear that a desire cannot\npossibly be the agent, because agents deliberate, decide, and act.\nDesires do none of these things. He suggests that any talk of a mental\nattitude as playing the role of the agent can at best be metaphorical.\nFurther, there is no obvious reason why an agent’s failure to\nidentify with a motive should be diagnosed in terms of the\nagent’s failure to participate. It seems more plausible to\nsuggest that the agent does participate in such cases, but in a\ndefective manner. Once defective participation is distinguished from a\nfailure to participate, it is easy to avoid Velleman’s\nconclusion that the standard theory “leaves out the\nagent”. Moreover, one can then separate the question of whether\nthe standard theory accounts for the agent’s participation from\nthe question of whether it captures human action par\nexcellence. According to Mele, the human agent is simply a human\nbeing who acts. On this view, the agent does play some role in all\ninstances of agency, no matter how deficient. The standard theory\nprovides, first and foremost, an account of what it is for an agent to\nperform intentional actions. It does not claim that the capacity to\nperform intentional actions is the capacity that separates human from\nnon-human agency, and it does not claim to give an account of more\nrefined or excellent kinds of human agency, such as self-controlled,\nautonomous, wholehearted, or free agency. It is an interesting and\nimportant task to investigate whether or not the standard theory can\nbe extended so as to account for the more refined or excellent kinds\nof human agency (Mele 1995; Bratman 2007, for instance). But to reject\nthe view because it fails to do so is to misconstrue its aim and scope\n(see also\nsection 3.3). Arguments for the claim that the standard theory does not account\nfor important aspects of agency are usually driven by a focus on\ndistinctively human agency. Once we shift our focus to non-human\nagents, and simpler organisms, a very different challenge\nemerges. When we turn to such agents, it seems that the standard\ntheory is clearly too demanding. The view explains agency in terms of\nthe agent’s desires, beliefs, and intentions. Usually, it is\nassumed that this is an explanation in terms of mental\nrepresentations: in terms of intentional mental states and events that\nhave representational contents (typically, propositional contents). It\nseems, however, that there are beings that are capable of genuine\nagency and that do not possess representational mental states. We can\ndistinguish here between three claims (and three\nchallenges). According to the first, there are non-human beings that\nare capable of agency and that do not possess representational mental\nstates. Second, there are many instances of human agency that can and\nshould be explained without the ascription of representational mental\nstates. Third, all instances of agency can and should be explained\nwithout the ascription of representational mental states. We turn to\neach claim in turn. We have a pervasive tendency to interpret and explain behavior in\nterms of intentional mental states. We tend, even, to interpret the\ninteraction between animated objects in terms of desires, beliefs, and\nintentions (Heider and Simmel 1944). This raises the question of when\nit is appropriate to attribute mental states in the explanation of\nbehavior. According to an instrumentalist stance (Dennett 1987:\nCh. 2), the question of when it is appropriate to ascribe mental\nstates cannot be separated from the question of when it is appropriate\nto ascribe agency, and both questions are to be answered in terms of\npredictive success: it is appropriate to attribute mental states in\nthe explanation of agency when doing so supports successful\npredictions of behavior. However, most proponents of the standard\ntheory presume some form of realism, according to which the ascription\nof mental states is appropriate only if the agent in question\npossesses the right internal states with the right representational\ncontents. The question of what the possession of representational\nmental states consists in is one of the most controversial questions\nin the philosophy of mind and cognitive science, and it is clearly\nbeyond the scope of this entry (see the entries on\nmental representation\nand\ncognitive science). Consider, though, the following remarks. Davidson (1982) held the view\nthat only human agents have the relevant mental attitudes, because he\nthought that having such attitudes requires linguistic\ncompetence. Others have argued that we are justified in ascribing\nrepresentational mental states to non-human agents if doing so\nprovides the best explanation of their behavior (Allen and Bekoff\n1997, for instance). Sometimes it is rather difficult to decide\nwhether or not the best explanation of an agent’s behavior\nrequires the ascription of representational mental states. Sterelny\n(2001: Ch. 11, 12), for instance, has argued that plausible\nexplanations in terms of desires can sometimes be replaced by equally\ngood explanations in terms of drives. The ascription of a desire is\nusually construed as the ascription of a representational mental\nstate, whereas a drive can be construed in terms of more basic\nmechanisms (and without the ascription of representational\ncontent). What is important to bear in mind, here, is that the issue\nconcerns not only the possession of the relevant mental states and\nevents. It concerns, moreover, the capacity to combine or process the\ncontents of such attitudes in rational inferences: the capacity to\ntreat the relevant contents as premises in practical reasoning (as\nemphasized by Anscombe 1957 and Davidson 1970). Suppose, for the sake of argument, that it is appropriate to\nascribe representational mental states to non-human beings of various\nkinds. It may still be the case that there are other kinds of\nnon-human beings that are capable of agency and that do not possess\nrepresentational mental states. Would this show that the standard\ntheory is too demanding? Only if the standard theory is construed as\nproviding an account of agency as such. According to a less\ndemanding view, the standard theory provides an account of one\nparticularly interesting and central kind of agency:\nintentional agency (and the kind of unintentional agency that derives\nfrom it; see\nsection 2).[9] On this construal, the standard theory is perfectly compatible with\nthe claim that there are more basic kinds of agency, including kinds\nof agency that do not require the possession of representational\nmental states. It is, for instance, compatible with what Barandiaran\net al. (2009) call “minimal agency”. On their view, an\nagent is a unified entity that is distinguishable from its environment\nand that is doing something by itself in accord with a certain goal\n(or norm). This view departs from the standard conception and theory\nin its characterization of action (“doing something”) in\nterms of the “adaptive regulation” of the agent’s\n“coupling with the environment” and in terms of metabolic\nself-maintenance (inspired by Varela et al. 1974). They suggest that\norganisms as simple as bacteria exhibit this minimal kind of\nagency. The crucial point is that this provides an account of\ngoal-directed behavior that does not appeal to the mental\nrepresentation of goals. Barandiaran et al. suggest, rather, that\neven very simple organisms can be said to have the intrinsic\ngoal to be: to bring about the continuation of their\nexistence. We turn now to the second claim, which says that many instances of\nhuman agency can and should be explained without the ascription of\nrepresentational mental states. This view is usually based on and\nmotivated by embodied and enactive approaches in the philosophy of\nmind and cognitive science. Some versions of this approach are\ninspired by the works Husserl, Heidegger, and Merleau-Ponty (Dreyfus\n1991, 2002), others are based on more recent developments in robotics\nand dynamical systems theory (Brooks 1991; Beer 1995). Common to such\nviews is the focus on skillful and “online” engagement with the world:\nthe ability to engage with others and with one’s circumstances\nby responding to the demands of the situation in a skillful and often\neffortless manner, without conscious deliberation, reasoning, or\nplanning (often called “skilled coping”). Examples of\nhuman agency include instances of habitual action, such as the actions\nthat one performs while driving a car, and cases where the agent is\nengaged in a responsive flow of interaction, such as in jazz\nimprovisation or in verbal exchanges. Examples from robotics include\nskills like the coordination of limb movements and the ability to\nnavigate through novel environments. The challenge to the standard\ntheory often involves the following three points. First, it is argued\nthat the explanation of such skills and abilities in terms of mental\nrepresentations is both costly and clumsy: it imposes very high\ndemands on the agent’s information-processing resources and it\nleads to an inelegant and implausible overpopulation of highly\nspecific mental representations. Second, it is pointed out that\ncurrent accounts of mental representation are untenable or, at least,\ncontroversial and that there is no obvious reason to think that there\nwill ever be a generally accepted account of mental\nrepresentation. Third, it is argued that the explanation of skilled\ncoping does not require the ascription of representational mental\nstates, because it can be explained in terms of behavioral\ndispositions and direct guidance by the relevant features of the\nsituation. The proposed conclusion is that we should, therefore,\nexplain instances of skilled coping without reference to\nrepresentational mental states and events. In response, proponents of the standard theory (and of\nrepresentational theories of mind) usually argue as follows. First, it\nis pointed out that the standard theory does not require that the\nagent considers the relevant mental contents in conscious deliberation\nor reasoning. This reduces the information-processing demands to a\nsignificant degree. Second, it is argued that the standard theory is\ncompatible with explanations of habitual actions in terms of motor\nschemata (or motor intentions). Motor schemata are not represented in\nthe contents of personal-level mental states, and they are usually\nrecruited automatically in the service of personal-level goals and\nintentions. The utilization of motor schemata further reduces the\nrequired processing load. Third, it is pointed out that most instances\nof skilled coping do not occur in an intentional vacuum, as it were.\nThey are, rather, usually constrained by and often integrated with the\nagent’s long-term goals and intentions. Given this, it seems\nthat a full explanation of skilled coping must, at some point or\nlevel, make reference to representational mental states after\nall. (For more on this see Clark and Toribio 1994; Antony 2002; Rey\n2002; Adams 2010; Clarke 2010b; Schlosser 2018.) According to the third claim, all instances of agency, including\nall instances of human agency, can and should be explained without the\nascription of representational mental states. This position is usually\nmotivated by radical versions of the embodied and enactive approach to\nthe mind (Chemero 2009; Silberstein and Chemero 2011; Hutto and Myin\n2014). The main strategy here is usually to generalize the argument\noutlined above: explanations in terms of representational mental\nstates are costly and clumsy; there is no generally accepted account\nof mental representation; and there is reason to think that we will,\neventually, be able to explain all kinds of agency without the\nascription of representational mental states. This radical view raises\nsome obvious and difficult questions. How can one explain our ability\nto deliberate about the future without assuming mental\nrepresentations? How can one explain reasoning about abstract\nconcepts, counterfactuals, and theoretical generalizations? And how\ncan one explain that our agency is to a significant extent motivated,\nguided, and constrained by our long-terms plans and commitments?\nTemporally extended planning agency (Bratman 1987, 2000) is clearly a\n“representation-hungry” phenomenon: it is difficult to see\nhow it can be explained without the ascription of representational\nmental states (Clark and Toribio 1994; Schlosser 2018; see also the entry on\nembodied cognition). There is, as we have seen, good reason to distinguish between\ndifferent kinds of agency. The standard theory offers an account of\nwhat is, arguably, the most central kind of agency: intentional agency\n(and the kind of unintentional agency that derives from it; see\nsection 2). This can be distinguished from higher or more refined kinds of agency,\nsuch as self-controlled, autonomous, and free agency, and it can be\ndistinguished from more basic kinds of agency that do not require the\nascription of representational mental states. Apart from that, there are\nseveral candidates for further kinds of agency. They include mental\nagency, shared agency, collective agency, relational agency, and\nartificial agency. In each case, we can ask whether the agency in\nquestion can be explained in terms of the standard conception and\ntheory, or whether it is indeed a different kind of agency. The main\nfocus in this section will be on mental agency, and we will address the\nother candidates only very briefly. It may seem obvious that our mental lives are filled with mental\naction. We attend, consider, judge, reason, deliberate, accept,\nendorse, decide, try, and so on. It may seem that these are all things\nthat we do. If we consider such cases through the standard theory of\nagency, we encounter immediately two difficulties. First, it seems\nthat such mental occurrences are hardly ever, if ever, intentional\nactions. According to the standard theory, an event is an intentional\naction of the type A only if the agent has an intention that\nincludes A in its content. In the basic case, this would be\nan intention to A. In an instrumental case, this would be an\nintention to perform some other action B in order\nto A. Now, thoughts are individuated in part by their\ncontents. Take the thought that p. According to the standard\ntheory, thinking that p is an intentional action only if the\nagent has an intention that includes “think\nthat p” in its content. This is rather odd and\nproblematic, because we would have to have the intention to think a\ncertain thought before we think it. Second, there are problems with\nthe central case of decision-making. According to the standard\ntheory, deciding to A would be an intentional action only if\none already had the intention to make a decision that includes\n“deciding to A” in its content. This seems,\nagain, rather odd and problematic. Further, our reasons for making a\ndecision to A are usually our reasons\nto A—they are reasons for performing\nthe action. According to the standard theory, something is\nan action only if it has a reason explanation (in terms of the\nagent’s desires, beliefs, and intentions). As reasons are\nusually reasons for action, it is again difficult to see how making a\ndecision can ever be an action. Considerations of this kind may lead\none to conclude that thoughts are hardly ever, if ever, mental actions\n(see Strawson 2003). It is not difficult to avoid this conclusion, as Mele\n(1997, 2003: Ch. 9, 2009b) has shown. Consider again the central case\nof decision-making, and assume that making a decision consists in the\nformation of an intention. According to the standard theory, the\nformation of an intention is an action if it is an intentional action\nunder some description (or if it is either identical with or generated\nby an intentional action; see\nsection 2). What could plausibly be the\nagent’s intention in making a decision? Mele suggests that\nprocesses of decision-making are usually motivated by the intention to\nsettle the practical question at hand. This proposal avoids the\nproblem outlined above. Suppose the agent decides to A. For\nthis to be an action, it is not required that the agent has the\nintention to decide to A. For if the agent has the intention\nto settle the question by making a decision, making the decision is\nintentional under a description. In particular, making a\ndecision is then an intentional action and making the\ndecision to A is then an unintentional action (that is either\nidentical with or generated by the intentional action of\nmaking a\ndecision).[10]\nSimilar considerations apply to the mentioned issue concerning reason\nexplanation and to other cases, such as remembering. Mele (2009b)\nargues that remembering something is never an intentional action,\nbecause no one has ever the intention to remember the particular\ncontent in question. But there is nevertheless a closely associated\nintentional mental action that one might perform: intentionally trying\nto bring it about that one remembers the particular content in\nquestion. See Shepherd (2015) for a defense of the view that decisions are intentional actions by construing them as extensions and conclusions of deliberative activity. Hieronymi (2009) takes a very different line. She thinks that we\nengage in mental agency whenever we settle the question of whether to\ndo or whether to believe something, and she argues that this kind of\nmental agency differs from ordinary intentional agency, primarily due\nto a difference in control. According to Hieronymi, we have\n“evaluative control” over our mental attitudes. This\nconsists in the ability to form and revise “our take on\nthings”, and it is to be distinguished from the kind of\nvoluntary control that we have over our overt bodily\nactions. According to volitionist theories of agency, mental acts of\nwilling (choosing or trying) are also different in kind from overt\nbodily actions. On such views, mental acts of willing are furthermore\nfundamental, in the sense that they are the source of overt\nagency (Ginet 1990; McCann 1998; Lowe 2008; more on this in\nsection 3.1). \nEpistemic agency concerns the control that agents may\nexercise over their beliefs (and other doxastic states). It is common\nto distinguish between two main positions: indirect doxastic\nvoluntarism and direct doxastic voluntarism. The former concerns the\nways in which we may acquire or revise beliefs by doing research,\nevaluating the evidence, considering opposing opinions, and so on. It\nis fairly uncontroversial that we can exercise control over our\nbeliefs in such indirect ways. In contrast, direct doxastic\nvoluntarism is very controversial. It says that we have direct\nvoluntary control over some of our beliefs, where voluntary control is\nusually understood as the kind of control that agents exercise in the\nperformance of intentional actions. A main issue here is that direct\ndoxastic voluntarism appears to be incompatible with the nature of\nbeliefs. Beliefs are supposed to represent the world (or “aim at\ntruth”). One may argue that there is no fundamental difference in the\ncontrol over action and belief-formation, because in both cases the\ncontrol consists basically in reason-responsiveness. But this proposal\noverlooks the central role of intentions. According to the standard\ntheory, actions must be initiated and guided by intentions, in\naddition to being responsive to reasons. The challenge is to find\nbeliefs-formations that are initiated and guided by intentions in the\nsame or similar way as intentional actions. (For a more extensive\noverview and references see Vitz 2019.) Shared agency occurs when two or more individuals do\nsomething together (such as carry a piece of furniture or sing a\nsong). Collective agency occurs when two or more individuals\nact as a group (in accordance with certain principles or procedures\nthat constitute and organize the group). Research on shared and\ncollective agency has flourished over the past two decades or so. One\ncentral question has been whether shared and collective agency can be\nreduced to the agency of the individuals involved, or whether they are\nconstitutive of different kinds of agency—whether they are, in\nsome sense, something over and above individual agency. An account of\ncollective agency in terms of the standard theory raises the question\nof whether it makes sense to attribute mental states and events (such\nas desires, beliefs, and intentions) to groups of individuals. (For\nreferences and discussion see the entries on\nshared agency\nand\ncollective intentionality.) The notion of relational agency derives from relational\naccounts of autonomy. According to feminist critiques, traditional\naccounts of autonomy are overly individualistic, insofar as they\noverlook or neglect the importance of interpersonal relationships in\nthe development and sustenance of an autonomous individual. As\nWestlund (2009) points out, however, most traditional accounts are\ncompatible with the feminist emphasis on interpersonal relationships\nas long as relationships and dependence on others are construed as\nbeing causally necessary for the development and sustenance\nof an individual agent. Autonomy is genuinely relational only if\ninterpersonal relationships and dependence are constitutive\nof autonomy. On Westlund’s own view, autonomous agency requires\nan “irreducibly dialogical form of reflectiveness and\nresponsiveness to others” (2009: 28). On this account, autonomy\nis an irreducibly relational kind of agency. (For more on this see the\nentry on\nfeminist perspectives on autonomy.) Finally, we turn briefly to the question of whether robots and\nother systems of artificial intelligence are capable of agency. If one\npresumes the standard theory, one faces the question of whether it is\nappropriate to attribute mental states to artificial\nsystems (see\nsection 2.4). If one takes an instrumentalist stance (Dennett 1987: Ch. 2), there is\nno obvious obstacle to the attribution of mental states\nand intentional agency to artificial systems. According to realist\npositions, however, it is far from obvious whether or not this is\njustified, because it is far from obvious whether or not artificial\nsystems have internal states that ground the ascription of\nrepresentational mental states. If artificial systems are not capable\nof intentional agency, as construed by the standard theory, they may\nstill be capable of some more basic kind of agency. According to\nBarandiaran et al. (2009), minimal agency does not require the\npossession of mental states. It requires, rather, the adaptive\nregulation of the agent’s coupling with the environment and\nmetabolic self-maintenance. This means, though, that on this view\nartificial systems are not even capable of minimal agency: “being specific about the requirements for agency\nhas told us a lot about how much is still needed for the development\nof artificial forms of agency” (Barandiaran et al. 2009:\n382).  What is the nature of agency? How should we construe the relation\nbetween agents and actions? How can agency be part of the event-causal\norder? In this section, we will first turn to the three main\napproaches in the metaphysics of agency that provide three different\nframeworks for how to think about such metaphysical questions (the\nevent-causal, the agent-causal, and the volitionist framework). After\nconsidering some problems and objections, we turn to an alternative\napproach that rejects the project of providing a metaphysics of agency\n(dual standpoint theory). Finally, we briefly consider the\nindividuation of actions and some further issues in the metaphysics of\nagency. According to an event-causal approach, agency is to be\nexplained in terms of event-causal relations between agent-involving\nstates and events.[11]\nOn this view, actions are events, and an\nevent is an action just in case it has the right event-causal\nhistory.[12] We\nmay call this a reductive approach to agency, as it reduces\nthe agent’s role in the exercise of agency to the causal roles\nof agent-involving states and events. Obviously, the standard theory\nbelongs to this reductive event-causal framework, because it explains\nagency in terms of causation by the agent’s mental states and\nevents.[13]\n(Proponents include Davidson 1963, 1971; Goldman 1970; Brand 1984;\nBratman 1987; Dretske 1988; Bishop 1989; Mele 1992, 2003; Enç\n2003.) According to an agent-causal approach, agency is to be\nexplained in terms of a kind of substance-causation: causation by the\nagent, construed as a persisting substance. On this view, actions are\nevents, and an event is an action just in case it has the right\nagent-causal history.[14]\nThis framework provides\na non-reductive account of agency insofar as it holds that an\nagent’s role in the exercise of agency is to be construed in\nterms of the exercise of an irreducible agent-causal power (Chisholm\n1964; Taylor 1966; O’Connor 2000; see also Clarke 2003; Lowe\n2008). According to a volitionist approach, agency is to be\nexplained in terms of acts of the will, usually called\n“volitions”. On this view, volitions are the source of\nagency: an overt movement is an action just in case it is caused, in\nthe right way, by a volition. Volitions themselves are entirely\nuncaused and they are sui generis acts: they are acts in\nvirtue of their intrinsic properties, not in virtue of some extrinsic\nor relational property (such as having the right causal\nhistory). This is also a non-reductive approach to agency, but it\ndiffers sharply from both the event-causal and the agent-causal\nframework in the important respect that it rejects the suggestion\nthat all actions are events with a certain causal history (Ginet\n1990; McCann 1998; see also Lowe 2008).[15] The event-causal framework is by far the most widely accepted view\nin the contemporary philosophy of mind and action. One reason for this\nis that the commitment to the event-causal framework is tantamount to\na commitment to a very minimal and widely endorsed kind of naturalism,\naccording to which any appeal to irreducible substance-causation or\nteleology is to be avoided. Further, this commitment to the\nevent-causal framework is sustained by a widespread dissatisfaction\nwith alternative agent-causal and volitionist theories of agency. Some\nobjections to agent-causal theories derive from more general\nobjections to the notion of substance-causation, others address more\ndirectly the agent-causal account of agency. It has been argued, for\ninstance, that appeal to substances leaves both the timing and the\nmanner of causation mysterious (Broad 1952). Further, it has been\nargued that substance-causation collapses into event-causation, once\nit is acknowledged that a substance has its causal powers in virtue of\nits properties (Clarke 2003: Ch. 10). Others have argued that an\nappeal to the agent as a cause is vacuous, because it has no\nexplanatory import (Davidson 1971), and because it cannot explain what\nan agent’s exercise of control consists in (Schlosser 2010). A\ncommon objection to volitionist accounts is that they generate a\nregress of mental acts (Ryle 1949). Arguably, though, this objection\nbegs the question. The view holds that overt actions are to be\nexplained in terms of volitions. There is no need to appeal to further\nmental acts of the will in order to explain why volitions are actions,\nbecause volitions are actions sui generis (see Enç\n2003 for discussion). This, however, points also to the reason why\nthe view is widely rejected. Volitionist theories stipulate as\nprimitive what appears to be in need of explanation. In particular,\nthey do not explain what an agent’s exercise of control consists\nin, as the agent is merely the subject or the bearer of volitions\n(O’Connor 2000: 25–26; Clarke 2003:\n17–24). Moreover, if, as most contemporary philosophers would\nassume, volitions are realized by events in the brain, the view\nappears to be in tension with the fact that there are no events in the\nbrain that are entirely uncaused. In the 1950s and 60s, several philosophers argued that the\nevent-causal framework is incoherent. Their main argument was the so\ncalled “logical connection argument”, which says, very\nroughly, that the relation between mental attitudes and actions\ncannot be causal, because the connection between them is logical,\nconceptual, or in some sense non-contingent (Hampshire 1959; Melden\n1961; Kenny 1963, for instance). It is widely agreed now that this\nattack was unsuccessful (the most influential reply is due to\nDavidson 1963; see also Goldman 1970:\n109–116).[16]\nShortly after that another challenge\nemerged, which turned out to be the most serious and most persistent\nproblem for the standard theory and the event-causal framework: the\nproblem of deviant causal chains. In general, the problem is that it seems always possible that the\nrelevant mental states and events cause the relevant event (a certain\nmovement, for instance) in a deviant way: so that this event is\nclearly not an intentional action or not an action at all. It is\ncommon to distinguish between cases of basic deviance\nand consequential deviance (also called primary and\nsecondary deviance). A murderous nephew intends to kill his uncle in\norder to inherit his fortune. He drives to his uncle’s house\nand on the way he kills a pedestrian by accident. As it turns out,\nthis pedestrian is his uncle. This is a case of consequential\ndeviance (Chisholm 1966). In a standard case of basic deviance\n(Davidson 1973), a climber intends to rid himself of the weight and\ndanger of holding another man on a rope by loosening his grip. This\nintention unnerves him so that it causes him to loosen his hold on\nthe rope. The difference between the cases is best explained in terms\nof the distinction between basic and non-basic\nactions. Very roughly, basic actions are the things that one can do\nwithout doing something else (such as raising one’s hand),\nwhereas the performance of non-basic actions requires that one does\nsomething else (such as giving someone a signal by raising\none’s hand).[17] In the consequential case, the nephew\nhas an intention to perform a non-basic action (to kill his\nuncle). He successfully performs several basic actions, but it is a\nsheer coincidence that he brings about the intended end. The climber,\nin contrast, does not perform any action at all. The mental\nantecedent causes a movement that would have been a basic\naction, had the causal chain not been deviant. Any event-causal theory of agency must require that the relevant\nmental attitudes cause the action in the right way. The right way of\ncausation is non-deviant causation. The challenge is to spell out\nwhat non-deviant causation consists in within the event-causal\nframework; without, in particular, any appeal to some unanalyzed\nnotion of agent-causation or control. Davidson (1974) was pessimistic\nabout the prospects for finding an event-causal account of\nnon-deviant causation, and he suggested that the standard theory is\nbest understood as providing only necessary conditions for\nagency. Goldman (1970) suggested that giving an account of\nnon-deviant causation is an empirical rather than a philosophical\ntask. Since then, however, most proponents of the event-causal\napproach have acknowledged that the problem of deviant causal chains\nis a serious philosophical problem, and various solutions have been\nproposed (see Peacocke 1979; Brand 1984; Bishop 1989; Mele 2003;\nSchlosser 2007, 2011; Wu 2016).[18] Sometimes it is suggested that the problem of deviant causal chains\nis merely a symptom of the deeper problem that event-causal theories\naltogether fail to capture agency, because they reduce actions to\nthings that merely happen to us (Lowe 2008: 9, for instance). Put\ndifferently, this challenge says that the event-causal framework is\ndeficient because it leaves out agents: all there is, on this view, is\na nexus of causal pushes and pulls in which no one does\nanything (Melden 1961; Nagel 1986; see also Velleman 1992). This\nhas been called the problem of the “disappearing agent”\n(Mele 2003: Ch. 10; Lowe 2008: 159–161; Steward 2013). According to Mele (2003: Ch. 10), some formulations of this\ndisappearing agent objection are easily dismissed. Some proponents of\nthis challenge use the terms ‘event-causal order’ and\n‘natural order’ interchangeably. This would seem to\nsuggest that, on their view, agency is a supernatural\nphenomenon­—a view that most contemporary philosophers find\nhard to take seriously. However, sometimes the challenge is raised in\norder to motivate alternative agent-causal or volitionist theories of\nagency, and the main proponents of agent-causal and volitionist\ntheories maintain that their views are compatible with\nnaturalism. They would argue that it is a mistake to presume that the\nevent-causal order exhausts the natural order of things. Further, the disappearing agent objection is not always put forward\nas a general objection to the event-causal framework. As we have seen\n(section 2.3), Velleman (1992) argued\nthat the standard theory leaves out the agent, or the agent’s\nparticipation, and he proposed a solution to this\nproblem within the event-causal framework. In his reply,\nMele (2003: Ch. 10) suggested that it would be more appropriate to\ncall this the problem of the “shrinking agent”. According to\nVelleman, the standard theory captures only deficient instances of\nagency, in which the agent’s participation is\n“unwitting” or “halfhearted”. Instances of\ndeficient agency can be explained in terms of various capacities or\nproperties that the agent does not possess, exercise, or instantiate;\ncapacities and properties such as conscious awareness, reflective\nawareness, reason-responsiveness, self-control, self-governance, and\nso on. Given this, there is no need to conceptualize instances of\ndeficient agency in terms of the agent’s absence. Further,\ndoing so creates a rather implausible dichotomy between a kind of\nagency in which the agent does participate and a kind of agency in\nwhich the agent does not participate (Schlosser 2010). Others, yet, press the disappearing agent objection in order to\nmotivate a dual standpoint theory. According to dual standpoint\ntheories, agency cannot be explained from any theoretical standpoint\nor metaphysical framework. Agency can only be understood from a\npractical and normative standpoint (Nagel 1986; Korsgaard 1996;\nBilgrami 2006, for instance). Arguably, this view has its roots in\nKant’s account of practical reason (see the entry on\nKant and Hume on morality). Usually, dual standpoint theories do not reject metaphysics as such,\nand they often provide a metaphysical framework of their own. But they\nreject both reductive and non-reductive theories of agency, and they\nreject, in general, the notion that we can have a metaphysical account\nof what the exercise of agency consists in. They align themselves\nnaturally with non-causal theories of reason explanation (see\nsection 2).\nBoth views tend to emphasize the normative and irreducibly\nteleological nature of reason explanation and, hence, agency. Dual\nstandpoint theories have received relatively little attention in the\nphilosophy of action. To many, it seems that such views are deeply\nunsatisfactory precisely because they refuse to face a central\nquestion in the metaphysics of agency: how can agents exercise control\nover their actions in a world in which all movements can be explained\nin terms of event-causation? It seems that this is in need of\nexplanation, and it seems that this requires a metaphysics of agency\n(see Bishop 1989; Schlosser 2010). Nelkin (2000) has questioned the\ncoherence of dual standpoint theories on the basis of an argument for\nthe claim that they entail commitments to contradictory beliefs about\nfree will. We now turn, in brief, to some further issues in the metaphysics of\nagency. The first concerns the individuation of actions. You flick the\nswitch, turn on the light, illuminate the room, and you thereby also\nalert the burglar. How many actions do you perform? According\nto coarse-grained (or minimizing) views on the individuation\nof actions, you perform one action under different descriptions\n(Anscombe 1957; Davidson 1963). According to fine-grained (or\nmaximizing) views, how many actions you perform depends on how many\nact-properties are instantiated. If you instantiate four\nact-properties, then you perform four distinct actions (Goldman 1970;\nsee also Ginet 1990). According to a third alternative, actions can\nhave other actions as their components or parts (Thalberg 1977; Ginet\n1990). According to all three views, actions are events, and the\nindividuation of actions derives from different views on the\nindividuation of events (see the entry on\nevents). Not much work has been done on this recently (see, however, Enç\n2003: Ch. 3). This is partly because it is now widely agreed that the\nindividuation of actions has little or no bearing on other issues. To\nillustrate, the question of whether agency is to be explained within\nan event-causal or an agent-causal framework bears directly on various\nissues in the debate on free will and moral responsibility (see the\nentry on\nfree will). But event-causal and agent-causal theories are both compatible with\ncoarse-grained and fine-grained views on the individuation of actions.\nSimilarly, it seems that the views on the individuation of actions\nhave no substantial bearing on the question of whether or not reason\nexplanations are causal explanations. A related issue is whether actions are to be identified with\nthe outcomes of causal processes or with\nthe processes themselves. According to most versions of\nevent-causal and agent-causal theories, an action is an event that is\ncaused in the right way: the action is identical with or constituted\nby the outcome of that process.[19] According to process views, the action\nis either identical with or constituted by that process (Searle 1983;\nDretske 1988; Wu 2011; see also Thompson 2008). This issue has also not\nreceived much attention. Again, this is mainly because it is widely\nassumed that this issue has little or no substantial bearing on more\nfundamental issues in the metaphysics of agency and on debates\noutside the philosophy of\naction.[20] Another issue in the metaphysics of agency that has received more\nattention in the recent debate is the nature of omissions (in\nparticular, intentional omissions). According to Sartorio (2009), an\nintentional omission is the absence of an action that is caused by the\nabsence of an intention. She argues, on the basis of this account,\nthat intentional omissions cannot be accommodated easily by the\nstandard theory. In reply, Clarke (2010a) has argued that in cases of\nintentional omission the agent usually does have an intention not to\nact that plays an important causal role, and he has identified various\nparallels between intentional actions and intentional omissions. On\nhis view, there are no major obstacles to an account of intentional\nomissions that is compatible and continuous with the standard theory\nof intentional action. Further, he argues that a failure to account\nfor intentional omissions would not obviously be a shortcoming of a\ntheory of intentional action. There are, after all, significant\ndifferences between actions and omissions, and so we should not expect\nthat a theory of action provides all the resources that are required\nfor an account of omissions. (For more on this see Clarke 2014.) According to our commonsense conception of agency, our reasons and\nconscious intentions tend to make a real difference to how we act\n(D’Andrade 1987; Malle 2004, for instance). This assumption is\npart and parcel of the standard theory and of numerous psychological\ntheories of intentional action and motivation (Fishbein and Ajzen\n1975; Locke and Latham 1990; Heckhausen 1991; Gollwitzer 1993; Austin\nand Vancouver 1996, for instance). There are, however, various\nempirical findings from psychology and cognitive neuroscience that\nhave been taken to show that this commonsense assumption is\nunwarranted, and that have raised interesting and challenging\nquestions concerning the role of consciousness in the initiation and\nguidance of agency. This section provides an overview of the most\nrelevant research. An early and highly influential source of the skepticism concerning\nthe causal relevance of our reasons is a theoretical review by Nisbett\nand Wilson (1977). This article reports numerous experiments and\nstudies in which participants appear to construct or confabulate\nrationalizing explanations by giving reasons that could not possibly\nhave been the reasons they acted for. Despite some rather serious\nmethodological problems (White 1988), this research has achieved and\nretained the status of textbook knowledge within psychology and\ncognitive science. Moreover, it has been taken to show that ordinary\nreason explanations are not causal explanations, even though the\nauthors themselves rejected this conclusion. On their view, the\nevidence shows, first and foremost, that verbal reports of mental\nstates are based on self-interpretation (theorizing or\nrationalization), rather than on direct or introspective access. They\nnoted that this epistemic view is perfectly compatible with the\nassumption that we can and often do give the actual causes of our\nactions when we give an ordinary reason explanation. The upshot is\nthat, even if the proposed epistemic view is correct, there is nothing\nin the evidence which shows that reason explanations cannot be causal\nexplanations, and there is nothing in the evidence which shows that\nreason explanations are usually not causal explanations. It seems that the empirical evidence in support of\nsituationism raises a challenge for our commonsense conception of\nagency. According to situationism, empirical research shows that\ncommonsense explanations of actions in terms of character traits (such\nas honesty, kindness, or courage) are systematically mistaken or\ninaccurate, because this research shows that the actions in question\nare better explained in terms of situational features (Ross and\nNisbett 1991; Harman 1999; Doris 2002). But none of the common\nphilosophical theories of agency say that actions are to be explained\nin terms of the agent’s character traits, and so it seems that\nsituationism does not raise a problem for the standard theory and\nother philosophical accounts of agency. Moreover, the interpretation\nof the empirical evidence in question and the argument for\nsituationism have been controversial (Sreenivasan 2002, for\ninstance). It has been argued, however, that this evidence raises the\nfurther question of whether we are genuinely reason-responsive. The\nevidence suggests that our actions are, under certain conditions,\ndriven by situational and morally irrelevant factors even when there\nare salient moral reasons to act otherwise. This suggests that we (or\nmost of us) are not as reason-responsive as we would like to\nthink. But it is controversial whether or not the evidence supports\nany stronger claims than that (for more on this see Nelkin 2005;\nSchlosser 2013; Vargas 2013). The most influential empirical challenge concerning the role of\nconscious intentions stems from Libet’s seminal neuroscientific\nwork on the initiation of movements. In the Libet experiment (Libet\n1985), participants were instructed to initiate a simple and\npredefined movement when the wish or urge to do so arises. During\nthis, EEG measurements were taken to record the readiness potential, a\nbrain potential that was known to precede intentional movements. The\nmain finding was that the readiness potential precedes the occurrence\nof the conscious wish or urge to move by about 350ms. According to\nLibet, this shows that movements are not consciously initiated and\nthat we do not have free will in the sense we commonly think we do\n(Libet 1999). The methodology of this experiment has been scrutinized\nextensively and criticized on a number of points. Some of those\nmethodological issues have been addressed in follow-up experiments\n(Soon et al. 2008; Fried et al. 2011). Most philosophers who have addressed Libet’s work have argued\nthat the conclusions about the role of conscious intentions and about\nfree will do not follow, even if it is granted that the experimental\nmethods and results are sound. They have argued that there are\nalternative interpretations of the evidence that preserve a causal\nrole for conscious intentions and that are as plausible and probable\nas Libet’s own interpretation of the evidence (Flanagan 1992:\n136–138; Zhu 2003; Mele 2009a; Schlosser 2012b). Further, it has\nbeen argued that the experiment creates a very unusual and artificial\ncontext in which participants are instructed to\ndecide spontaneously. Due to this, it is questionable that\nthe results of the experiment can be generalized (Keller and\nHeckhausen 1990; Roskies 2011; Waller 2012; Schlosser 2014). Schurger\net al. (2012) have proposed and tested a model that addresses this\nissue. According to this model, the timing of the movement in the\nLibet experiment is determined by random threshold crossings in\nspontaneous fluctuations in neural activity. In particular, the model\nsays that a decision when to move is determined by random threshold\ncrossings only when it is not constrained by any evidence or\nreasons for action. The fact that this model has been tested\nsuccessfully supports the claim that the results from the Libet\nexperiment and from similar follow-up studies do not generalize,\nbecause most of our everyday decisions clearly are constrained by\nevidence and by reasons for action. A related challenge concerning the role of conscious intentions\nstems from Wegner’s model of apparent mental\ncausation. According to this view, conscious intentions provide mere\n“previews” of our actions: they precede our actions, but\nthey do not cause them (Wegner and Wheatley 1999; Wegner\n2002). Wegner provided evidence of dissociations between the sense of\nagency and the actual exercise of agency, and he argued that the\nmodel of apparent mental causation provides the best explanation of\nthe data. This view has been strongly criticized for conceptual ambiguities and\nargumentative flaws (see also section 4.5). One common objection is that the fact that the sense of agency can come apart from the exercise of agency is\nperfectly compatible with the assumption that conscious intentions\ntend to cause the intended actions. (See Bayne 2006; Mele 2009a; for\na reply to Wegner’s inference to the best explanation see\nSchlosser 2012a.) The work of Libet and Wegner has nevertheless raised interesting\nand challenging questions concerning the role of consciousness in\nagency. Proponents of the standard theory often qualify the view\nwith the claim that the relevant mental attitudes need not be\nconsciously accessed in order to play the right role in the exercise\nof agency. When, for instance, Davidson (1978: 85–86)\nconsidered the example of an agent who adds some spice to a stew with\nthe intention of improving the taste, he claimed that intentional\nagency requires only that the agent would have reasoned on\nthe basis of the relevant attitudes that the action is to be\nperformed, had he been aware of those attitudes at the\ntime. Few, though, would be prepared to accept the view that all of\nour actions might be like this: initiated and guided by attitudes\nthat are not consciously accessed at the time. This raises various\nquestions that are rarely addressed. How often, or in what kinds of\ncases, should actions be preceded by conscious intentions or\nconscious reasoning? What kind of consciousness is required? In cases\nwhere the relevant attitudes are not consciously accessed, must they\nbe accessible? And so forth.[21] One strand of empirical research that is relevant to questions\nconcerning the role of consciousness in agency is the work on\nautomaticity; in particular, the research on automatic goal\npursuit. It has been shown, for instance, that the goal to perform a\ncertain task accurately can be primed, so that the agent pursues the\ngoal without any awareness of doing so (Bargh et al. 2001). There is\na large body of research on this, and it has been suggested that this\nresearch shows that most of our actions are executed\nautomatically and without conscious control (Bargh and Chartrand\n1999, Custers and Aarts 2010).[22] This claim is less radical than the\nclaims put forward by Libet (1999) and Wegner (2002), as it concerns\nonly the extent or scope of conscious control. Further, this appears\nto be much less challenging once it is noted that the great majority\nof automatic actions are sub-routines that are in the service of\nhigher goals and long-term intentions. Consider, for instance, all\nthe sub-routines that one performs while driving a car. The claim\nthat such actions are performed automatically and without conscious\ncontrol can be reconciled with our commonsense conception of agency\nand it can be accommodated by the standard theory, provided that\nconscious intentions and plans can recruit the relevant routines\nautomatically, either by generating the relevant motor intentions, or\nby activating the relevant motor schemata. (For more on this see\nPacherie 2008; Adams 2010; Clarke 2010b.) Another relevant strand of research is the work on dual-process (or\ndual-system) theories of decision-making. According to such models,\nthere are two distinct types of mental processes (or systems) that\nunderlie decision-making and agency: one is typically characterized as\nautomatic, effortless, and heuristics-based, and the other as\nconscious, deliberate, and rule-based. Dual-process models have been\ndeployed widely and successfully in many areas of research (for\noverviews see Sloman 1996; Evans 2008; for critical reviews see Osman\n2004; Keren and Schul 2009). In philosophy, it is commonly assumed,\nexplicitly or implicitly, that there is one mechanism (or\nfaculty) of practical reason that underlies practical reasoning and\nreason-based agency. This appears to be incompatible with the\ndual-process framework. What complicates this issue, though, is that\nthere is no consensus on the details of the dual-process model. There\nis, for instance, no commonly accepted view on how the two processes\n(or systems) interact. Conscious and deliberate processes may have a\ntop-down influence on automatic processes; the two processes may\ninteract with each other; they may interfere with each other in some\ncases; there may be cases in which processing switches from one to the\nother; and so on. Not all of those possibilities are obviously\nincompatible with the assumption that there is one mechanism (or\nfaculty) of practical reason. Further research is needed in order to\ninvestigate whether the two types of processes are in the relevant\nrespects independent or whether they can be construed as interacting\nparts of one mechanism of decision-making. For a discussion of whether\nthe dual-system framework is compatible with the philosophical\nstandard theory of action see Schlosser\n2019.[23] There has been some debate concerning the kind of knowledge we have\nof our own actions. Most prominently, Anscombe (1957) argued that the\nknowledge of our actions is direct, in the sense that it is not based\non observation or inference (see the entry on\naction). \nThis section provides an overview of the closely related debate on the\nso called “sense of agency”. It seems that when we act, we\nhave a sense of doing something: a sense of control and of being the\nagent or owner of the action. The debate about this has been driven\nlargely by empirical findings from psychology and cognitive science,\nand it has become common to distinguish between the following three\nmain positions. \nThe first is largely due to Wegner’s work on the “model of\napparent mental causation” (Wegner and Wheatley 1999; Wegner\n2002). According to this view, the sense of agency (or the\n“experience of conscious will”, as Wegner called it)\narises when we interpret a conscious intention to perform a\ncertain action as its cause. It says, in particular, that an agent\ninterprets an intention as the cause of an action when the following\nconditions obtain: the intention proximately precedes the action, the\naction is consistent with the intention, and the agent is not aware of\nany factors that could provide an alternative\nexplanation. Wegner’s argument for the model of apparent mental\ncausation is based on various experiments, studies, and observations\nconcerning illusions of control and failures in the ascription of\nagency. This work initiated the empirical study of the sense of\nagency, but Wegner’s model is now widely rejected. Philosophers\nhave criticized the view for various conceptual ambiguities and flaws\nin the interpretation and use of the evidence (Nahmias 2002; Bayne\n2006; Dennett 2008; and Mele 2009a, for instance). Moreover, there is\nnow plenty of empirical evidence to suggest that the sense of agency\nis not merely a matter of self-interpretation (Haggard 2005; Bayne and\nPacherie 2007; Gallagher 2007; and Synofzik et al. 2008). \nThe second account of the sense of agency is based on a\nfeedback-comparator model of motor control. According to this model,\nthe motor control system uses copies of motor commands in order to\ngenerate predictions of the ensuing bodily movements. Those\npredictions (so called “forward models”) are then used for\ncomparisons between the predicted and the intended trajectories of\nmovements, and for comparisons between the predicted and actual\ntrajectories (based on information from sensory feedback). The model\nholds that a sub-personal system of motor control uses those\npredictions and comparisons in order to adjust and fine-tune the\nexecution of bodily movements (Wolpert and Kawato 1998; Frith et\nal. 2000; Haggard 2005). It has been suggested that this system may\nalso play a crucial role in the generation of the sense of agency. On\nthis view, positive matches in the comparator system generate a sense\nof agency, whereas mismatches generate error signals that disrupt the\nsense of agency. This model can explain a wide range of phenomena\nconcerning the sense and control of agency (Frith et al. 2000;\nBlakemore et al. 2002). More recently it has been argued, however,\nthat this comparator model provides at best a partial explanation of\nthe sense of agency (Haggard 2005; Bayne and Pacherie 2007; Gallagher\n2007; Synofzik et al. 2008). \nThe third account of the sense of agency is a hybrid of the first\ntwo. Proponents of this approach usually distinguish between a basic\nsense of agency and post-act judgments concerning one’s agency.\nThe basic sense of agency is construed as an online and\nphenomenologically rather thin experience that accompanies the\nperformance of actions, and that does not necessarily require the\npresence of a conscious intention. Judgments about one’s agency,\nin contrast, are offline and usually post-act, and they are, thereby,\nsubject to various biases that may distort the interpretation of\none’s own agency. The feedback-comparator model is well suited\nto explain the basic sense of agency, whereas a self-interpretation\ntheory, akin to Wegner’s, can explain why judgments about\none’s own agency tend to be distorted or illusory under certain\nconditions (Bayne and Pacherie 2007; Gallagher 2007; Synofzik et\nal. 2008). \nPacherie (2008) develops the feedback-comparator model into an account\nof the phenomenology of agency that postulates three integrated\nfeedback loops at three different levels of intention: the level of\ndistal (or future-directed) intention, proximal (or present-directed)\nintention, and motor intention. These are levels of action\nspecification in which progressively more detailed representations of\nthe action are generated, at the later stages in response to\nperceptual and proprioceptive feedback. Pacherie’s main thesis\nis that the component representations of the stages in the process of\naction specification are strongly interconnected with the components\nand contents of the phenomenology of agency. At the level of proximal\nintentions, for instance, the model explains how the conceptual\ninformation that is inherited from the distal intention is integrated\nwith perceptual input and situational constraints. Concerning the\nsense of agency, the model distinguishes between the awareness of what\n(the goal), awareness of how (the means), the sense of intentionality,\nthe sense of initiation, the sense of situational control, and the\nsense of motor control. Shepherd (2017) argues that the components in\nthe phenomenology of agency are so richly integrated that they can be\nregarded as fused in the total experience. \nThe analytical philosophy of action neglected the role of perception\nand attention in the guidance of agency for a long time. Concerning\nperception it was common to assume, often without any elaboration,\nthat the reference to the guiding role of beliefs takes care of the\nrole of perception. The standard theory does not limit the causal role\nof beliefs to those that the agent considers or possesses prior to the\nexecution of the action, and so we may assume that the beliefs that\nare supposed to play a causal guidance role include perceptual beliefs\nthat the agent acquires during the performance of the action. More\nrecent work (Mele 2003; Pacherie 2008; Schlosser 2012a) has shown that\nthe standard theory is compatible with the feedback-comparator model\nof movement control outlined above (see section\n4.5). This model accounts not only for the role of perceptual and\nproprioceptive input, but also for the guidance provided by internal\npredictions in the fine-tuning and execution of motor control. \nThe role of attention, however, was almost entirely unacknowledged, as\npointed out by Wu (2011, 2016). Whenever we pursue a goal, we must not\nonly select appropriate means. We must also select which features of\nthe situation to attend to in the guidance of action. Wu\nconceptualizes this in terms of a “many-many problem”: in the pursuit\nof a goal we face typically too many perceptual inputs and too many\npossible behavioral outputs. The formation of an intention provides\nonly a partial solution. The content of an intention usually includes\nthe selection of the appropriate means. One intends, for instance, to\nopen the window in order to let in some fresh air. This constrains the\nrange of behavioral outputs and the range of perceptual inputs that\none needs to attend to. But it does not determine a specific enough\ninput-output mapping. Generally, the content of intentions is not\nfine-grained enough in order to properly guide the execution of\nmovements and the direction of attention. Wu suggests that the\nmany-many problems at those finer-grained levels are solved by\nattention. Following William James, Wu proposes that\nattention is the missing selection for action: the selection\nof perceptual inputs for the implementation of motor control. On this\nview, intention-mediated attention is an essential component\nof embodied agency. This raises the question of whether the selection\nof attention can itself be a genuine exercise of agency, and whether\nthe proposed account can be extended so as to account for the\nintentional direction and control of attention.","contact.mail":"markus.schlosser@ucd.ie","contact.domain":"ucd.ie"}]
