[{"date.published":"2001-08-08","date.changed":"2020-08-29","url":"https://plato.stanford.edu/entries/conditionals/","author1":"Dorothy Edgington","entry":"conditionals","body.text":"\n\n\nTake a sentence in the indicative mood, suitable for making a\nstatement: “We’ll be home by ten”, “Tom cooked\nthe dinner”. Attach a conditional clause to it, and you have a\nsentence which makes a conditional statement: “We’ll be\nhome by ten if the train is on time”, “If Mary\ndidn’t cook the dinner, Tom cooked it”. A conditional\nsentence “If \\(A, C\\)” or “\\(C\\) if \\(A\\)”\nthus has two contained sentences or sentence-like clauses. \\(A\\) is\ncalled the antecedent, \\(C\\) the consequent. If you understand \\(A\\)\nand \\(C\\), and you have mastered the conditional construction (as we\nall do at an early age), you understand “If \\(A, C\\)”.\nWhat does “if” mean? Consulting the dictionary yields\n“on condition that; provided that; supposing that”. These\nare adequate synonyms. But we want more than synonyms. A theory of\nconditionals aims to give an account of the conditional construction\nwhich explains when conditional judgements are acceptable, which\ninferences involving conditionals are good inferences, and why this\nlinguistic construction is so important. Despite intensive work of\ngreat ingenuity, this remains a highly controversial subject. \n\nFirst let us delimit our field. The examples with which we began are\ntraditionally called “indicative conditionals”. There are\nalso “subjunctive” or “counterfactual”\nconditionals like “Tom would have cooked the dinner if Mary had\nnot done so”, “We would have been home by ten if the train\nhad been on time”. Counterfactuals will be the subject of a\nseparate entry, and theories addressing them will not be discussed\nhere. That there is some difference between indicatives and\ncounterfactuals is shown by pairs of examples like “If Oswald\ndidn’t kill Kennedy, someone else did” and “If\nOswald hadn’t killed Kennedy, someone else would have”:\nyou can accept the first yet reject the second (Adams (1970)). That\nthere is not a huge difference between them is shown by examples like\nthe following: “Don’t go in there”, I say, “If\nyou go in you will get hurt”. You look sceptical but stay\noutside, when there is large crash as the roof collapses. “You\nsee”, I say, “if you had gone in you would have got hurt.\nI told you so.”  \nIt is controversial how best to classify conditionals. According to\nsome theorists, the forward-looking “indicatives” (those\nwith a “will” in the main clause) belong with the\n“subjunctives” (those with a “would” in the\nmain clause), and not with the other “indicatives”. (See\nGibbard (1981, pp. 222–6), Dudman (1984, 1988), Bennett (1988).\nBennett (1995) changed his mind. Jackson (1990) defends the\ntraditional view.) The easy transition from typical\n“wills” to “woulds” is indeed a datum to be\nexplained. Still, straightforward statements about the past, present\nor future, to which a conditional clause is attached — the\ntraditional class of indicative conditionals — do (in my view)\nconstitute a single semantic kind. The theories to be discussed do not\nfare better or worse when restricted to a particular subspecies. \nAs well as conditional statements, there are conditional commands,\npromises, offers, questions, etc.. As well as conditional beliefs,\nthere are conditional desires, hopes, fears, etc.. Our focus will be\non conditional statements and what they express — conditional\nbeliefs; but we will consider which of the theories we have examined\nextends most naturally to these other kinds of conditional. \nThree kinds of theory will be discussed. In §2 we compare\ntruth-functional and non-truth-functional accounts of the truth\nconditions of conditionals. In §3 we examine what is called the\nsuppositional theory: that conditional judgements essentially involve\nsuppositions. On development, it appears to be incompatible with\nconstruing conditionals as statements with truth conditions. §4\nlooks at some responses from advocates of truth conditions. In §5\nwe consider the problem for the suppositional theory of complex\nsentences with conditional parts. In §6 we consider a wider\nvariety of conditional speech acts and propositional attitudes. \nWhere we need to distinguish between different interpretations, we\nwrite “\\(A \\supset B\\)” for the truth-functional\nconditional, “\\(A \\rightarrow B\\)” for a\nnon-truth-functional conditional and “\\(A \\Rightarrow B\\)”\nfor the conditional as interpreted by the suppositional theory; and\nfor brevity we call protagonists of the three theories Hook, Arrow and\nSupp, respectively. We use “\\({\\sim}\\)” for negation. \nThe generally most fruitful, and time-honoured, approach to specifying\nthe meaning of a complex sentence in terms of the meanings of its\nparts, is to specify the truth conditions of the complex sentence, in\nterms of the truth conditions of its parts. A semantics of this kind\nyields an account of the validity of arguments involving the complex\nsentence, given the conception of validity as necessary preservation\nof truth. Throughout this section we assume that this approach to\nconditionals is correct. Let \\(A\\) and \\(B\\) be two sentences such as\n“Ann is in Paris” and “Bob is in Paris”. Our\nquestion will be: are the truth conditions of “If \\(A,\nB\\)” of the simple, extensional, truth-functional kind, like\nthose of “\\(A\\) and \\(B\\)”, “\\(A \\text{ or }\nB\\)” and “It is not the case that \\(A\\)”? That is,\ndo the truth values of \\(A\\) and of \\(B\\) determine the truth value of\n“If \\(A, B\\)”? Or are they non-truth-functional, like\nthose of “\\(A\\) because \\(B\\)”, “\\(A\\) before\n\\(B\\)”, “It is possible that \\(A\\)”? That is, are\nthey such that the truth values of \\(A\\) and \\(B\\) may, in some cases,\nleave open the truth value of “If \\(A, B\\)”?  \nThe truth-functional theory of the conditional was integral to\nFrege’s new logic (1879). It was taken up enthusiastically by\nRussell (who called it “material implication”),\nWittgenstein in the Tractatus, and the logical positivists,\nand it is now found in every logic text. It is the first theory of\nconditionals which students encounter. Typically, it does not strike\nstudents as obviously correct. It is logic’s first\nsurprise. Yet, as the textbooks testify, it does a creditable job in\nmany circumstances. And it has many defenders. It is a strikingly\nsimple theory: “If \\(A, B\\)” is false when \\(A\\) is true\nand \\(B\\) is false. In all other cases, “If \\(A, B\\)” is\ntrue. It is thus equivalent to “\\({\\sim}(A \\amp{\\sim}B)\\)”\nand to “\\({\\sim}A\\) or \\(B\\)”. “\\(A \\supset\nB\\)” has, by stipulation, these truth conditions. \nIf “if” is truth-functional, this is the right\ntruth function to assign to it: of the sixteen possible\ntruth-functions of \\(A\\) and \\(B\\), it is the only serious candidate.\nFirst, it is uncontroversial that when \\(A\\) is true and \\(B\\) is\nfalse, “If \\(A, B\\)” is false. A basic rule of inference\nis modus ponens: from “If \\(A, B\\)” and \\(A\\), we can\ninfer \\(B\\). If it were possible to have \\(A\\) true, \\(B\\) false and\n“If \\(A, B\\)” true, this inference would be invalid.\nSecond, it is uncontroversial that “If \\(A, B\\)” is\nsometimes true when \\(A\\) and \\(B\\) are respectively (true,\ntrue), or (false, true), or (false, false). “If it’s a\nsquare, it has four sides”, said of an unseen geometric figure,\nis true, whether the figure is a square, a rectangle or a triangle.\nAssuming truth-functionality — that the truth value of the\nconditional is determined by the truth values of its parts\n— it follows that a conditional is always true when its\ncomponents have these combinations of truth values. \nNon-truth-functional accounts agree that “If \\(A, B\\)” is\nfalse when \\(A\\) is true and \\(B\\) is false; and they agree that the\nconditional is sometimes true for the other three combinations of\ntruth-values for the components; but they deny that the conditional is\nalways true in each of these three cases. Some agree with the\ntruth-functionalist that when \\(A\\) and \\(B\\) are both true, “If\n\\(A, B\\)” must be true. Some do not, demanding a further\nrelation between the facts that \\(A\\) and that \\(B\\) (see Read\n(1995)). This dispute need not concern us, as the arguments which\nfollow depend only on the feature on which non-truth-functionalists\nagree: that when \\(A\\) is false, “If \\(A, B\\)” may be\neither true or false. For instance, I say (*) “If you touch that\nwire, you will get an electric shock”. You don’t touch it.\nWas my remark true or false? According to the non-truth-functionalist,\nit depends on whether the wire is live or dead, on whether you are\ninsulated, and so forth. Robert Stalnaker’s (1968) account is of\nthis type: consider a possible situation in which you touch the wire,\nand which otherwise differs minimally from the actual situation. (*)\nis true (false) according to whether or not you get a shock in that\npossible situation. \nLet \\(A\\) and \\(B\\) be two logically independent propositions. The\nfour lines below represent the four incompatible logical possibilities\nfor the truth values of \\(A\\) and \\(B\\). “If \\(A, B\\)”,\n“If \\({\\sim}A, B\\)” and “If \\(A, {\\sim}B\\)”\nare interpreted truth-functionally in columns (i)–(iii), and\nnon-truth-functionally (when their antecedents are false) in columns\n(iv)–(vi). The non-truth-functional interpretation we write\n“\\(A \\rightarrow B\\)”. “T/F” means both truth\nvalues are possible for the corresponding assignment of truth values\nto \\(A\\) and \\(B\\). For instance, line 4, column (iv), represents two\npossibilities for \\(A, B\\), If \\(A, B\\), (F, F, T) and (F, F, F). \nThe main argument points to the fact that minimal knowledge that the\ntruth-functional truth condition is satisfied is enough for knowledge\nthat if \\(A, B\\). Suppose there are two balls in a bag, labelled \\(x\\)\nand \\(y\\). All you know about their colour is that at least one of\nthem is red. That’s enough to know that if \\(x\\) isn’t\nred, \\(y\\) is red. Or: all you know is that they are not both red.\nThat’s enough to know that if \\(x\\) is red, \\(y\\) is not red.\n \nSuppose you start off with no information about which of the four\npossible combinations of truth values for \\(A\\) and \\(B\\) obtains. You\nthen acquire compelling reason to think that either \\(A\\) or \\(B\\) is\ntrue. You don’t have any stronger belief about the matter. In\nparticular, you have no firm belief as to whether \\(A\\) is true or\nnot. You have ruled out line 4. The other possibilities remain open.\nThen, intuitively, you are justified in inferring that if \\({\\sim}A,\nB\\). Look at the possibilities for \\(A\\) and \\(B\\) on the left. You\nhave eliminated the possibility that both \\(A\\) and \\(B\\) are false.\nSo if \\(A\\) is false, only one possibility remains: \\(B\\) is true. \nThe truth-functionalist (call him Hook) gets this right. Look at\ncolumn (ii). Eliminate line 4 and line 4 only, and you have eliminated\nthe only possibility in which “\\({\\sim}A \\supset B\\)” is\nfalse. You know enough to conclude that “\\({\\sim}A \\supset\nB\\)” is true. \nThe non-truth-functionalist (call her Arrow) gets this wrong. Look at\ncolumn (v). Eliminate line 4 and line 4 only, and some possibility of\nfalsity remains in other cases which have not been ruled out. By\neliminating just line 4, you do not thereby eliminate these further\npossibilities, incompatible with line 4, in which “\\({\\sim}A\n\\rightarrow B\\)” is false. \nThe same point can be made with negated conjunctions. You discover for\nsure that \\({\\sim}(A \\amp B)\\), but nothing stronger than that. In\nparticular, you don’t know whether \\(A\\). You rule out line 1,\nnothing more. You may justifiably infer that if \\(A, {\\sim}B\\). Hook\ngets this right. In column (iii), if we eliminate line 1, we are left\nonly with cases in which “\\(A \\supset{\\sim}B\\)” is true.\nArrow gets this wrong. In column (vi), eliminating line 1 leaves open\nthe possibility that “\\(A \\rightarrow{\\sim}B\\)” is\nfalse. \nThe same argument renders compelling the thought that if we eliminate\njust \\(A \\amp{\\sim}B\\), nothing stronger, i.e., we\ndon’t eliminate \\(A\\), then we have sufficient reason to\nconclude that if \\(A, B\\). \nHere is a second argument in favour of Hook, in the style of Natural\nDeduction. The rule of Conditional Proof (CP) says that if \\(Z\\)\nfollows from premises \\(X\\) and \\(Y\\), then “If \\(Y, Z\\)”\nfollows from premise \\(X\\). Now the three premises \\({\\sim}(A \\amp B),\nA\\) and \\(B\\) entail a contradiction. So, by Reductio Ad Absurdum,\nfrom \\({\\sim}(A \\amp B)\\) and \\(A\\), we can conclude \\({\\sim}B\\). So\nby CP, \\({\\sim}(A \\amp B)\\) entails “If \\(A, {\\sim}B\\)”.\nSubstitute “\\({\\sim}C\\)” for \\(B\\), and we have a proof of\n“If \\(A\\), then \\({\\sim}{\\sim}C\\)” from “\\({\\sim}(A\n\\amp{\\sim}C)\\)”. And provided we also accept Double Negation\nElimination, we can derive “If \\(A\\), then \\(C\\)” from\n“\\({\\sim}(A \\amp{\\sim}C)\\)”. \nConditional Proof seems sound: “From \\(X\\) and \\(Y\\), it follows\nthat \\(Z\\). So from \\(X\\) it follows that if \\(Y, Z\\)”. Yet\nfor no reading of “if” which is stronger than the\ntruth-functional reading is CP valid — at least this is so\nif we treat “&” and “\\({\\sim}\\)” in the\nclassical way and accept the validity of the inference: (I) \\({\\sim}(A\n\\amp{\\sim}B)\\); \\(A\\); therefore \\(B\\). Suppose CP is valid for some\ninterpretation of “If \\(A, B\\)”. Apply CP to (I), and we\nget \\({\\sim}(A \\amp{\\sim}B)\\); therefore if \\(A, B\\), i.e., \\(A\n\\supset B\\) entails if \\(A, B\\). \nThe best-known objection to the truth-functional account, one of the\n“paradoxes of material implication”, is that according to\nHook, the falsity of \\(A\\) is sufficient for the truth of “If\n\\(A, B\\)”. Look at the last two lines of column (i). In every\npossible situation in which \\(A\\) is false, “\\(A \\supset\nB\\)” is true. Can it be right that the falsity of “She\ntouched the wire” entails the truth of “If she touched the\nwire she got a shock”?  \nHook might respond as follows. How do we test our intuitions about the\nvalidity of an inference? The direct way is to imagine that we know\nfor sure that the premise is true, and to consider what we would then\nthink about the conclusion. Now when we know for sure that\n\\({\\sim}A\\), we have no use for thoughts beginning “If \\(A\\),\n…”. When you know for sure that Harry didn’t do it,\nyou don’t go in for “If Harry did it …”\nthoughts or remarks. In this circumstance conditionals have no role to\nplay, and we have no practice in assessing them. The direct intuitive\ntest is, therefore, silent on whether “If \\(A, B\\)”\nfollows from \\({\\sim}A\\). If our smoothest, simplest, generally\nsatisfactory theory has the consequence that it does follow, perhaps\nwe should learn to live with that consequence. \nThere may, of course, be further consequences of this feature of\nHook’s theory which jar with intuition. That needs\ninvestigating. But, Hook may add, even if we come to the conclusion\nthat “\\(\\supset\\)” does not match perfectly our\nnatural-language “if”, it comes close, and it has the\nvirtues of simplicity and clarity. We have seen that rival theories\nalso have counterintuitive consequences. Natural language is a fluid\naffair, and we cannot expect our theories to achieve better than\napproximate fit. Perhaps, in the interests of precision and clarity,\nin serious reasoning we should replace the elusive “if”\nwith its neat, close relative, \\(\\supset\\) . \nThis was no doubt Frege’s attitude. Frege’s primary\nconcern was to construct a system of logic, formulated in an idealized\nlanguage, which was adequate for mathematical reasoning. If “\\(A\n\\supset B\\)” doesn’t translate perfectly our\nnatural-language “If \\(A, B\\)”, but plays its intended\nrole, so much the worse for natural language. \nFor the purpose of doing mathematics, Frege’s judgement was\nprobably correct. The main defects of \\(\\supset\\) don’t show up\nin mathematics. There are some peculiarities, but as long as we are\naware of them, they can be lived with. And arguably, the gain in\nsimplicity and clarity more than offsets the oddities. \nThe oddities are harder to tolerate when we consider conditional\njudgements about empirical matters. The difference is this: in\nthinking about the empirical world, we often accept and reject\npropositions with degrees of confidence less than certainty. “I\nthink, but am not sure, that \\(A\\)” plays no central role in\nmathematical thinking. We can, perhaps, ignore as unimportant the use\nof indicative conditionals in circumstances in which we are\ncertain that the antecedent is false. But we cannot ignore\nour use of conditionals whose antecedent we think is likely to be\nfalse. We use them often, accepting some, rejecting others. “I\nthink I won’t need to get in touch, but if I do, I shall need a\nphone number”, you say as your partner is about to go away; not\n“If I do I’ll manage by telepathy”. “I think\nJohn spoke to Mary; if he didn’t he wrote to her”; not\n“If he didn’t he shot her”. Hook’s theory has\nthe unhappy consequence that all conditionals with unlikely\nantecedents are likely to be true. To think it likely that \\({\\sim}A\\)\nis to think it likely that a sufficient condition for the truth of\n“\\(A \\supset B\\)” obtains. Take someone who thinks that\nthe Republicans won’t win the election \\(({\\sim}R)\\), and who\nrejects the thought that if they do win, they will double income tax\n\\((D)\\). According to Hook, this person has grossly inconsistent\nopinions. For if she thinks it’s likely that \\({\\sim}R\\), she\nmust think it likely that at least one of the propositions,\n\\(\\{{\\sim}R, D\\}\\) is true. But that is just to think it likely that\n\\(R \\supset D\\). (Put the other way round, to reject \\(R \\supset D\\)\nis to accept \\(R \\amp{\\sim}D\\); for this is the only case in which \\(R\n\\supset D\\) is false. How can someone accept \\(R \\amp{\\sim}D\\) yet\nreject \\(R\\)?) Not only does Hook’s theory fit badly the\npatterns of thought of competent, intelligent people. It cannot be\nclaimed that we would be better off with \\(\\supset\\). On the contrary,\nwe would be intellectually disabled: we would not have the power to\ndiscriminate between believable and unbelievable conditionals whose\nantecedent we think is likely to be false. \nArrow does not have this problem. Her theory is designed to avoid it,\nby allowing that “\\(A \\rightarrow B\\)” may be false when\n\\(A\\) is false. \nThe other paradox of material implication is that according to Hook\nall conditionals with true consequents are true: from \\(B\\) it follows\nthat \\(A \\supset B\\). This is perhaps less obviously unacceptable: if\nI’m sure that \\(B\\), and treat \\(A\\) as an epistemic\npossibility, I must be sure that if \\(A, B\\). Again the problem\nbecomes vivid when we consider the case when I’m only nearly\nsure, but not quite sure, that \\(B\\). I think \\(B\\) may be\nfalse, and will be false if certain, in my view unlikely,\ncircumstances obtain. For example, I think Sue is giving a lecture\nright now. I don’t think that if she was seriously injured on\nher way to work, she is giving a lecture right now. I reject that\nconditional. But on Hook’s account, the conditional is false\nonly if the consequent is false. I think the consequent is true: I\nthink a sufficient condition for the truth of the conditional\nobtains. \nH. P. Grice famously defended the truth-functional account, in his\nWilliam James lectures, “Logic and Conversation”,\ndelivered in 1967 (see Grice (1989); see also Thomson (1990)). There\nare many ways of speaking the truth yet misleading your audience,\ngiven the standard to which you are expected to conform in\nconversational exchange. One way is to say something weaker than some\nother relevant thing you are in a position to say. Consider\ndisjunctions. I am asked where John is. I am sure that he is in the\npub, and know that he never goes near libraries. Inclined to be\nunhelpful but not wishing to lie, I say “He is either in the pub\nor in the library”. My hearer naturally assumes that this is the\nmost precise information I am in a position to give, and also\nconcludes from the truth (let us assume) that I told him “If\nhe’s not in the pub he’s in the library”. The\nconditional, like the disjunction, according to Grice, is true if\nhe’s in the pub, but misleadingly asserted on that ground.  \nAnother example, from David Lewis (1976, p. 143): “You\nwon’t eat those and live”, I say of some wholesome and\ndelicious mushrooms—knowing that you will now leave them alone,\ndeferring to my expertise. I told no lie—for indeed you\ndon’t eat them—but of course I misled you. \nGrice drew attention, then, to situations in which a person is\njustified in believing a proposition, which would\nnevertheless be an unreasonable thing for the person to say,\nin normal circumstances. His lesson was salutary and important. He is\nright, I think, about disjunctions and negated conjunctions. Believing\nthat John is in the pub, I can’t consistently\ndisbelieve “He’s either in the pub or the\nlibrary”; if I have any epistemic attitude to this proposition,\nit should be one of belief, however inappropriate for me to assert it.\nSimilarly for “You won’t eat those and live” when I\nknow you won’t eat them. But it is implausible that the\ndifficulties with the truth-functional conditional can be explained\naway in terms of what is an inappropriate conversational remark. They\narise at the level of belief. Thinking that John is in the pub, I may\nwithout irrationality disbelieve “If he’s not in the pub\nhe’s in the library”. Thinking you won’t eat the\nmushrooms, I may without irrationality reject “If you eat them\nyou will die”. As facts about the norms to which people defer,\nthese claims can be tested. A good enough test is to take a\nco-operative person, who understands that you are merely interested in\nher opinions about the propositions you put to her, as opposed to what\nwould be a reasonable remark to make, and note which conditionals she\nassents to. Are we really to brand as illogical someone who dissents\nfrom both “The Republicans will win” and “If the\nRepublicans win, income tax will double”? \nThe Gricean phenomenon is a real one. On anyone’s account of\nconditionals, there will be circumstances when a conditional is\njustifiably believed, but is liable to mislead if stated. For\ninstance, I believe that the match will be cancelled, because all the\nplayers have ’flu. I believe that whether or not it rains, the\nmatch will be cancelled: if it rains, the match will be cancelled, and\nif it doesn’t rain, the match will be cancelled. Someone asks me\nwhether the match will go ahead. I say, “If it rains, the match\nwill be cancelled”. I say something I believe, but I mislead my\naudience — why should I say that, when I think it will be\ncancelled whether or not it rains? This does not demonstrate that Hook\nis correct. Although I believe that the match will be cancelled, I\ndon’t believe that if all the players make a very speedy\nrecovery, the match will be cancelled. \n\\({\\sim}(A \\supset B)\\) is equivalent to \\(A \\amp{\\sim}B\\).\nIntuitively, you may safely say, of an unseen geometric figure,\n“It’s not the case that if it’s a pentagon, it has\nsix sides”. But by Hook’s lights, you may well be wrong;\nfor it may not be a pentagon, and in that case it is true that if\nit’s a pentagon, it has six sides.  \nAnother example, due to Gibbard (1981, pp. 235–6): of a glass\nthat had been held a foot above the floor, you say (having left the\nscene) “If it broke if it was dropped, it was fragile”.\nIntuitively this seems reasonable. But by Hook’s lights, if the\nglass was not dropped, and was not fragile, the conditional has a true\n(conditional) antecedent and false consequent, and is hence false. \nGrice’s strategy was to explain why we don’t assert\ncertain conditionals which (by Hook’s lights) we have reason to\nbelieve true. In the above two cases, the problem is reversed: there\nare compounds of conditionals which we confidently assert and accept\nwhich, by Hook’s lights, we do not have reason to believe\ntrue. \nAnother bad result is that according to Hook, the following is a valid\nargument: \nIf \\(A \\amp B, C\\); therefore, either, if \\(A, C\\), or, if \\(B, C\\).\n \nEven in mathematics, this looks wrong. Said of an unseen plane figure:\n“If it’s a triangle and it’s equiangular, it’s\nequilateral; therefore, either, if it’s a triangle it’s\nequilateral, or, if it’s equiangular it’s\nequilateral”. (I owe this example to Alberto Mura.) \nThe above examples are not a problem for Arrow. But other cases of\nembedded conditionals count in the opposite direction. Here are two\nsentence forms which are, intuitively, equivalent: \n(Following Vann McGee (1989) I’ll call the principle that (i)\nand (ii) are equivalent the Import-Export Principle, or\n“Import-Export” for short.) Try any example: “If\nMary comes then if John doesn’t have to leave early we will play\nBridge”; “If Mary comes and John doesn’t have to\nleave early we will play Bridge”. “If they were outside\nand it rained, they got wet”; “If they were outside, then\nif it rained, they got wet”. For Hook, Import-Export holds.\n(Exercise: do a truth table, or construct a proof.) Gibbard (1981, pp.\n234–5) has proved that for no conditional with truth conditions\nstronger than \\(\\supset\\) does Import-Export hold. Assume\nImport-Export holds for some reading of “if”. The key to\nthe proof is to consider the formula \nBy Import-Export, (1) is equivalent to  \nThe antecedent of (2) entails its consequent. So (2) is a logical\ntruth. So by Import-Export, (1) is a logical truth. On any reading of\n“if”, “if \\(A, B\\)” entails \\((A \\supset B)\\).\nSo (1) entails  \nSo (3) is a logical truth. That is, there is no possible situation in\nwhich its antecedent \\((A \\supset B)\\) is true and its consequent (if\n\\(A, B)\\) is false. That is, \\((A \\supset B)\\) entails “If \\(A,\nB\\)”. \nNeither kind of truth condition has proved entirely satisfactory. We\nstill have to consider Jackson’s defence of Hook, and\nStalnaker’s response to the problem about non-truth-functional\ntruth conditions raised in §2.2. These are deferred to §4,\nbecause they depend on the considerations developed in §3. \nLet us put truth conditions aside for a while, and ask what it is to\nbelieve, or to be more or less certain, that \\(B\\) if \\(A\\) —\nthat John cooked the dinner if Mary didn’t, that you will\nrecover if you have the operation, and so forth. How do you make such\na judgement? You suppose (assume, hypothesise) that \\(A\\), and make a\nhypothetical judgement about \\(B\\), under the supposition that \\(A\\),\nin the light of your other beliefs. Frank Ramsey put it like this:\n \nA suppositional theory was advanced by J. L. Mackie (1973, chapter 4).\nSee also David Barnett (2006). Peter Gärdenfors’s work\n(1986, 1988) could also come under this heading. But the most fruitful\ndevelopment of the idea (in my view) takes seriously the last part of\nthe above quote from Ramsey, and emphasises the fact that conditionals\ncan be accepted with different degrees of closeness to certainty.\nErnest Adams (1965, 1966, 1975) has developed such a theory.  \nWhen we are neither certain that \\(B\\) nor certain that \\({\\sim}B\\),\nthere remains a range of epistemic attitudes we may have to \\(B\\): we\nmay be nearly certain that \\(B\\), think \\(B\\) more likely than not,\netc.. Similarly, we may be certain, nearly certain, etc. that \\(B\\)\ngiven the supposition that \\(A\\). Make the idealizing assumption that\ndegrees of closeness to certainty can be quantified: 100% certain, 90%\ncertain, etc.; and we can turn to probability theory for what Ramsey\ncalled the “logic of partial belief”. There we find a\nwell-established, indispensable concept, “the conditional\nprobability of \\(B\\) given \\(A\\)”. It is to this notion that\nRamsey refers by the phrase “degrees of belief in \\(q\\) given\n\\(p\\)”. \nIt is, at first sight, rather curious that the best-developed and most\nilluminating suppositional theory should place emphasis on uncertain\nconditional judgements. If we knew the truth conditions of\nconditionals, we would handle uncertainty about conditionals in terms\nof a general theory of what it is to be uncertain of the truth of a\nproposition. But there is no consensus about the truth conditions of\nconditionals. It happens that when we turn to the theory of uncertain\njudgements, we find a concept of conditionality in use. It is worth\nseeing what we can learn from it. \nThe notion of conditional probability entered probability theory at an\nearly stage because it was needed to compute the probability of a\nconjunction. Thomas Bayes (1763) wrote: \nA simple example: a ball is picked at random. 70% of the balls are red\n(so the probability that a red ball is picked is 70%). 60% of the red\nballs have a black spot (so the probability that a ball with a black\nspot is picked, on the supposition that a red ball is picked, is 60%).\nThe probability that a red ball with a black spot is picked is 60% of\n70%, i.e. 42%.  \nRamsey, arguing that “degrees of belief” should conform to\nprobability theory, stated the same “fundamental law of partial\nbelief”: \nFor example, you are about 50% certain that the test will be on\nconditionals, and about 80% certain that you will pass, on the\nsupposition that it is on conditionals. So you are about 40% certain\nthat the test will be on conditionals and you will pass.  \nAccepting Ramsey’s suggestion that “if”,\n“given that”, “on the supposition that” come\nto the same thing, writing “\\(\\mathbf{p}(B)\\)” for\n“degree of belief in \\(B\\)”, and “\\(\\mathbf{p}_A\n(B)\\)” for “degree of belief in \\(B\\) given \\(A\\)”,\nand rearranging the basic law, we have: \nCall a set of mutually exclusive and jointly exhaustive propositions a\npartition. The lines of a truth table constitute a partition.\nOne’s degrees of belief in the members of a partition, idealized\nas precise, should sum to 100%. That is all there is to the claim that\ndegrees of belief should have the structure of probabilities. Consider\na partition of the form \\(\\{A \\amp B, A \\amp{\\sim}B, {\\sim}A\\}\\).\nSuppose someone X thinks it 50% likely that \\({\\sim}A\\) (hence 50%\nlikely that \\(A), 40\\)% likely that \\(A \\amp B\\), and 10% likely that\n\\(A \\amp{\\sim}B\\). Think of this distribution as displayed\ngeometrically, as follows. Draw a long narrow horizontal rectangle.\nDivide it in half by a vertical line. Write “\\({\\sim}A\\)”\nin the right-hand half. Divide the left-hand half with another\nvertical line, in the ratio 4:1, with the larger part on the left.\nWrite “\\(A \\amp B\\)” and “\\(A \\amp{\\sim}B\\)”\nin the larger and smaller cells respectively. \n(Note that as \\(\\{A \\amp B, A \\amp{\\sim}B, {\\sim}A\\}\\) and \\(\\{A,\n{\\sim}A\\}\\) are both partitions, it follows that \\(\\mathbf{p}(A) =\n\\mathbf{p}(A \\amp B) + \\mathbf{p}(A \\amp{\\sim}B)\\).) \nHow does X evaluate “If \\(A, B\\)”? She assumes that \\(A\\),\nthat is, hypothetically eliminates \\({\\sim}A\\). In the part of the\npartition that remains, in which \\(A\\) is true, \\(B\\) is four times as\nlikely as \\({\\sim}B\\); that is, on the assumption that \\(A\\), it is\nfour to one that \\(B: \\mathbf{p}(B\\) if \\(A)\\) is 80%,\n\\(\\mathbf{p}({\\sim}B\\) if \\(A)\\) is 20%. Equivalently, as \\(A \\amp B\\)\nis four times as likely as \\(A \\amp{\\sim}B, \\mathbf{p}(B\\) if \\(A)\\)\nis 4/5, or 80%. Equivalently, \\(\\mathbf{p}(A \\amp B)\\) is 4/5 of\n\\(\\mathbf{p}(A)\\). In non-numerical terms: you believe that if \\(A,\nB\\) to the extent that you think that \\(A \\amp B\\) is nearly as likely\nas \\(A\\); or, to the extent that you think \\(A \\amp B\\) is much more\nlikely than \\(A \\amp{\\sim}B\\). If you think \\(A \\amp B\\) is as likely\nas \\(A\\), you are certain that if \\(A, B\\). In this case, your\n\\(\\mathbf{p}(A \\amp{\\sim}B) = 0\\). \nGo back to the truth table. You are wondering whether if \\(A, B\\).\nAssume \\(A\\). That is, ignore lines 3 and 4 in which \\(A\\) is false.\nAsk yourself about the relative probabilities of lines 1 and 2.\nSuppose you think line 1 is about 100 times more likely than line 2.\nThen you think it is about 100 to 1 that \\(B\\) if \\(A\\). \nNote: these thought-experiments can only be performed when\n\\(\\mathbf{p}(A)\\) is not 0. On this approach, indicative conditionals\nonly have a role when the thinker takes \\(A\\) to be an epistemic\npossibility. If you take yourself to know for sure that Ann is in\nParis, you don’t go in for “If Ann is not in Paris\n…” thoughts (though of course you can think “If Ann\nhad not been in Paris …”). In conversation, you can\npretend to take something as an epistemic possibility, temporarily, to\ncomply with the epistemic state of the hearer. When playing the\nsceptic, there are not many limits on what you can, at a\npinch, take as an epistemic possibility – as not already ruled\nout. But there are some limits, as Descartes found. Is there a\nconditional thought that begins “If I don’t exist now\n…”? \nOn Hook’s account, to be close to certain that if \\(A, B\\) is to\ngive a high value to \\(\\mathbf{p}(A \\supset B)\\). How does\n\\(\\mathbf{p}(A \\supset B)\\) compare with \\(\\mathbf{p}_A (B)\\)? In two\nspecial cases, they are equal: first, if \\(\\mathbf{p}(A \\amp{\\sim}B) =\n0\\) (and \\(\\mathbf{p}(A)\\) is not 0), \\(\\mathbf{p}(A \\supset B) =\n\\mathbf{p}_A (B) = 1\\) (i.e. 100%). Second, if \\(\\mathbf{p}(A) =\n100\\)%, \\(\\mathbf{p}(A \\supset B) = \\mathbf{p}_A (B) =\n\\mathbf{p}(B)\\). In all other cases, \\(\\mathbf{p}(A \\supset B)\\) is\ngreater than \\(\\mathbf{p}_A (B)\\). To see this we need to compare\n\\(\\mathbf{p}(A \\amp{\\sim}B)\\) and \\(\\mathbf{p}(A\n\\amp{\\sim}B)/\\mathbf{p}(A)\\). Consider again the partition \\(\\{A \\amp\nB, A \\amp{\\sim}B, {\\sim}A\\}. \\mathbf{p}(A \\amp{\\sim}B)\\) is a smaller\nproportion of the whole space than it is of the \\(A\\)-part — the\npart of the space in which \\(A\\) is true — except in the special\ncases in which \\(\\mathbf{p}(A \\amp{\\sim}B) = 0\\), or\n\\(\\mathbf{p}({\\sim}A) = 0\\). So, except in these special cases,\n\\(\\mathbf{p}_A ({\\sim}B)\\) is greater than \\(\\mathbf{p}(A\n\\amp{\\sim}B)\\). Now \\(\\mathbf{p}(A \\supset B) = \\mathbf{p}({\\sim}(A\n\\amp{\\sim}B))\\); and \\(\\mathbf{p}(A \\amp{\\sim}B) + \\mathbf{p}({\\sim}(A\n\\amp{\\sim}B)) = 1\\). Also \\(\\mathbf{p}_A (B) + \\mathbf{p}_A ({\\sim}B)\n= 1\\). So from \\(\\mathbf{p}_A ({\\sim}B) \\gt \\mathbf{p}(A\n\\amp{\\sim}B)\\) it follows that \\(\\mathbf{p}(A \\supset B) \\gt\n\\mathbf{p}_A (B)\\). \nHook and the suppositional theorist (call her Supp) come spectacularly\napart when \\(\\mathbf{p}({\\sim}A)\\) is high and \\(\\mathbf{p}(A \\amp\nB)\\) is much smaller than \\(\\mathbf{p}(A \\amp{\\sim}B)\\). Let\n\\(\\mathbf{p}({\\sim}A) = 90\\)%, \\(\\mathbf{p}(A \\amp B) = 1\\)%,\n\\(\\mathbf{p}(A \\amp{\\sim}B) = 9\\)%. \\(\\mathbf{p}_A (B) = 10\\)%.\n\\(\\mathbf{p}(A \\supset B) = 91\\)%. For instance, I am 90% certain that\nSue won’t be offered the job \\(({\\sim}O)\\), and think it only\n10% likely that she will decline the offer \\((D)\\) if it is made, that\nis \\(\\mathbf{p}_O (D) = 10\\)%. \\(\\mathbf{p}(O \\supset D) =\n\\mathbf{p}({\\sim}O \\text{ or } (O \\amp D)) = 91\\)%. \nNow let us compare Hook, Arrow, and Supp with respect to two questions\nraised in §2. \nHook: yes. Because “\\(A \\supset B\\)” is true whenever \\(A\n\\amp{\\sim}B\\) is false. \nSupp: yes. Because \\(A \\amp B\\) is as likely as \\(A. \\mathbf{p}_A (B)\n= 1\\). \nArrow: no, not necessarily. For “\\(A \\rightarrow B\\)” may\nbe false when \\(A \\amp{\\sim}B\\) is false. With just the information\nthat \\(A \\amp{\\sim}B\\) is false, I should not be certain that if \\(A,\nB\\). \nHook: no. “\\(A \\supset B\\)” is true in all the possible\nsituations in which \\({\\sim}A\\) is true. If I think it likely that\n\\({\\sim}A\\), I think it likely that a sufficient condition for the\ntruth of “\\(A \\supset B\\)” obtains. I must, therefore,\nthink it likely that if \\(A, B\\). \nSupp: yes. We had an example above. That most of my probability goes\nto \\({\\sim}A\\) leaves open the question whether or not \\(A \\amp B\\) is\nmore probable than \\(A \\amp{\\sim}B\\). If \\(\\mathbf{p}(A \\amp{\\sim}B)\\)\nis greater than \\(\\mathbf{p}(A \\amp B)\\), I think it’s unlikely\nthat if \\(A, B\\). That’s compatible with thinking it likely that\n\\({\\sim}A\\). \nArrow: yes. “If \\(A, B\\)” may be false when \\(A\\) is\nfalse. And I might well think it likely that that possibility obtains,\ni.e. unlikely that “If \\(A, B\\)” is true. \nSupp has squared the circle: she gets the intuitively right answer to\nboth questions. In this she differs from both Hook and Arrow.\nSupp’s way of assessing conditionals is incompatible with the\ntruth-functional way (they answer Question 2 differently); and\nincompatible with stronger-than-truth-functional truth conditions\n(they answer Question 1 differently). It follows that Supp’s way\nof assessing conditionals is incompatible with the claim that\nconditionals have truth conditions of any kind. \\(\\mathbf{p}_A (B)\\)\ndoes not measure the probability of the truth of any proposition.\nSuppose it did measure the probability of the truth of some\nproposition \\(A*B\\). Either \\(A*B\\) is entailed by “\\(A \\supset\nB\\)”, or it is not. If it is, it is true whenever \\({\\sim}A\\) is\ntrue, and hence cannot be improbable when \\({\\sim}A\\) is probable.\nThat is, it cannot agree with Supp in its answer to Question 2. If\n\\(A*B\\) is not entailed by “\\(A \\supset B\\)”, it may be\nfalse when \\({\\sim}(A \\amp{\\sim}B)\\) is true, and hence certainty that\n\\({\\sim}(A \\amp{\\sim}B)\\) (in the absence of certainty that\n\\({\\sim}A)\\) is insufficient for certainty that \\(A*B\\); it cannot\nagree with Supp in its answer to Question 1.  \nTo make the point in a slightly different way, let me adopt the\nfollowing as an expository, heuristic device, a harmless fiction.\nImagine a partition as carved into a large finite number of\nequally-probable chunks, such that the propositions with which we are\nconcerned are true in an exact number of them. The probability of any\nproposition is the proportion of chunks in which it is true. The\nprobability of \\(B\\) on the supposition that \\(A\\) is the proportion\nof the \\(A\\)-chunks (the chunks in which \\(A\\) is\ntrue) which are \\(B\\)-chunks. With some misgivings, I succumb to the\ntemptation to call these chunks “worlds”: they are equally\nprobable, mutually incompatible and jointly exhaustive epistemic\npossibilities, enough of them for the propositions with which we are\nconcerned to be true, or false, at each world. The heuristic value is\nthat judgements of probability and conditional probability then\ntranslate into statements about proportions. \nAlthough Supp and Hook give the same answer to Question 1, their\nreasons are different. Supp answers “yes” not\nbecause a proposition, \\(A*B\\), is true whenever \\(A \\amp{\\sim}B\\) is\nfalse; but because \\(B\\) is true in all the “worlds” which\nmatter for the assessment of “If \\(A, B\\)”: the\n\\(A\\)-worlds. Although Supp and Arrow give the same answer to Question\n2, their reasons are different. Supp answers “yes”, not\nbecause a proposition \\(A*B\\) may be false when \\(A\\) is false; but\nbecause the fact that most worlds are \\({\\sim}A\\)-worlds is irrelevant\nto whether most of the \\(A\\)-worlds are\n\\(B\\)-worlds. To judge that \\(B\\) is true on the supposition\nthat \\(A\\) is true, it turns out, is not to judge that\nsomething-or-other, \\(A*B\\), is true. \nBy a different argument, David Lewis (1976) was the first to prove\nthis remarkable result: there is no proposition \\(A*B\\) such that, in\nall probability distributions, \\(\\mathbf{p}(A*B) = \\mathbf{p}_A (B)\\).\nConditional probability does not measure the probability of the truth\nof any proposition. If a conditional has truth conditions, one should\nbelieve it to the extent that one thinks it is probably true. If Supp\nis correct, that one believes “If \\(A, B\\)” to the extent\nthat one thinks it probable that \\(B\\) on the supposition that \\(A\\),\nthen this is not equivalent to believing some proposition to be\nprobably true. Hence, it appears, if Supp is right, conditionals\nshouldn’t be construed as having truth conditions at all. A\nconditional judgement involves two propositions, which play different\nroles. One is the content of a supposition. The other is the content\nof a judgement made under that supposition. They do not combine to\nyield a single proposition which is judged to be likely to be true\njust when the second is judged likely to be true on the supposition of\nthe first. \n(Lewis called his proofs “triviality results”, because the\nconclusions are avoided only in a trivial probability space which is\nincapable of giving positive probability to more than two incompatible\npropositions—for instance, is incapable of giving positive\nprobability to \\(A \\amp B, A \\amp{\\sim}B\\), and \\({\\sim}A\\). The name\nis widely used in the literature. For recent examples see Khoo and\nMandelkern (2019) and Charlow (2019).) \nNote: ways of restoring truth conditions, compatible with Supp’s\nthesis, are considered in §5. \nErnest Adams, in two articles (1965, 1966) and a subsequent book\n(1975), gave a theory of the validity of arguments involving\nconditionals as construed by Supp. He taught us something important\nabout classically valid arguments as well: that they are, in a special\nsense to be made precise, probability-preserving. This property can be\ngeneralized to apply to arguments with conditionals. The valid ones\nare those which, in the special sense, preserve probability or\nconditional probability.  \nFirst consider classically valid (that is, necessarily\ntruth-preserving) arguments which don’t involve conditionals. We\nuse them in arguing from contingent premises about which we are often\nless than completely certain. The question arises: how certain can we\nbe of the conclusion of the argument, given that we think, but are not\nsure, that the premises are true? Call the improbability of a\nstatement one minus its probability. Adams showed this: if (and only\nif) an argument is valid, then in no probability distribution does the\nimprobability of its conclusion exceed the sum of the improbabilities\nof its premises. Call this the Probability Preservation Principle\n(PPP). \nThe proof of PPP rests on the Partition Principle — that the\nprobabilities of the members of a partition sum to 100% —\nnothing else, beyond the fact that if \\(A\\) entails \\(B, \\mathbf{p}(A\n\\amp{\\sim}B) = 0\\). Here are three consequences: \nSuppose \\(A_1, \\ldots, A_n\\) entail \\(B\\). Then \\({\\sim}B\\) entails\n\\({\\sim}A_1\\) or … or \\({\\sim}A_n\\). Therefore\n\\(\\mathbf{p}({\\sim}B) \\le \\mathbf{p}({\\sim}A_1) + \\cdots +\n\\mathbf{p}({\\sim}A_n)\\): the improbability of the conclusion of a\nvalid argument cannot exceed the sum of the improbabilities of the\npremises.  \nThe result is useful to know: if you have two premises of which you\nare at least 99% certain, they entitle you to be at least 98% certain\nof a conclusion validly drawn from them. Of course, if you have 100\npremises each at least 99% certain, your conclusion may have zero\nprobability. That is the lesson of the “Lottery Paradox”.\nStill, Adams’s result vindicates deductive reasoning from\nuncertain premises, provided that they are not too uncertain, and\nthere are not too many of them. \nSo far, we have a very useful consequence of the classical notion of\nvalidity. Now Adams extends this consequence to arguments involving\nconditionals. Take a language with “and”,\n“or”, “not” and “if” — but\nwith “if” occurring only as the main connective in a\nsentence. (We put aside compounds of conditionals.) Take any argument\nformulated in this language. Consider any probability function over\nthe sentences of this argument which assigns non-zero probability to\nthe antecedents of all conditionals — that is, any assignment of\nnumbers to the non-conditional sentences which conforms to the\nPartition Principle, and to the conditional sentences which conforms\nto Supp’s thesis: \\(\\mathbf{p}(B\\) if \\(A) = \\mathbf{p}_A (B) =\n\\mathbf{p}(A \\amp B)/\\mathbf{p}(A)\\). Let the improbability of the\nconditional “If \\(A, B\\)” be \\(1 - \\mathbf{p}_A (B)\\).\nDefine a valid argument as one such that there is no\nprobability function in which the improbability of the conclusion\nexceeds the sum of the improbabilities of the premises. And a nice\nlogic emerges, which is now well known. It is the same as\nStalnaker’s logic over this domain (see §4.1). There are\nrules of proof, a decision procedure, consistency and completeness can\nbe proved. See Adams (1998 and 1975). \nI shall write the conditional which satisfies Adams’s criterion\nof validity “\\(A \\Rightarrow B\\)”.\nWe have already seen that in all distributions, \\(\\mathbf{p}_A (B) \\le\n\\mathbf{p}(A \\supset B)\\). Therefore, \\(A \\Rightarrow B\\) entails \\(A\n\\supset B\\): it cannot be the case that the former is more probable\nthan the latter. Call a non-conditional sentence a factual sentence.\nIf an argument has a factual conclusion, and is classically valid with\nthe conditional interpreted as \\(\\supset\\), it is valid with the\nconditional interpreted as the stronger \\(\\Rightarrow\\). The following\npatterns of inference are therefore valid: \nWe cannot consistently have their premises highly probable and their\nconclusion highly improbable.  \nArguments with conditional conclusions, however, may be valid when the\nconditional is interpreted as the weaker \\(A \\supset B\\), but invalid\nwhen it is interpreted as the stronger \\(A \\Rightarrow B\\). Here are\nsome examples. \nI can consistently be close to certain that Sue is lecturing right\nnow, while thinking it highly unlikely that if she had a heart attack\non her way to work, she is lecturing just now. \nYou can consistently be close to certain that the Republicans\nwon’t win, while thinking it highly unlikely that if they win\nthey will double income tax. \nI can consistently be close to certain that it’s not the case\nthat I will be hit by a bomb and injured today, while thinking it\nhighly unlikely that if I am hit by a bomb, I won’t be\ninjured. \nAs I think it is very likely to rain tomorrow, I think it’s very\nlikely to be true that it will rain or snow tomorrow. But I think\nit’s very unlikely that if it doesn’t rain, it will\nsnow. \nI can think it’s highly likely that if you strike the match, it\nwill light; but highly unlikely that if you dip it in water and strike\nit, it will light.  \nStrengthening is a special case of transitivity, in which the missing\npremise is a tautology: if \\(C \\amp A\\) then \\(A\\); if \\(A, B\\); so if\n\\(C \\amp A, B\\). So transitivity also fails: \nAdams gave this example (1966): I can think it highly likely that if\nJones is elected, Brown will resign immediately afterwards; I can also\nthink it highly likely that if Brown dies before the election, Jones\nwill be elected; but I do not think it at all likely that if Brown\ndies before the election, Brown will resign immediately after the\nelection!  \nWe saw in §2.2 that Conditional Proof (CP) is invalid for any\nconditional stronger than \\(\\supset\\). It is invalid in Adams’s\nlogic. For instance, “\\({\\sim}(A \\amp B)\\); \\(A\\); so\n\\({\\sim}B\\)” is valid. It contains no conditionals. Any\nnecessarily truth-preserving argument satisfies PPP. If I’m\nclose to certain that I won’t be hit by a bomb and injured,\nand close to certain that I will be hit by a bomb, then I\nmust be close to certain that I won’t be injured. But, as we\nsaw, “\\({\\sim}(A \\amp B)\\); so \\(A \\Rightarrow{\\sim}B\\)”\nis invalid. Yet we can get the latter from the former by CP. \nWhy does CP fail on this conception of conditionals? After all,\nSupp’s idea is to treat the antecedent of a conditional as an\nassumption. What is the difference between the roles of a\npremise, and of the antecedent of a conditional in the conclusion? \nThe antecedent of the conditional is indeed treated as an assumption.\nOn this conception of validity, the premises are not, primarily,\ntreated as assumptions. We also make inferences from beliefs,\nincluding beliefs which are less than certain. Indeed, it is not\nimmediately clear what it would be to treat a conditional, construed\naccording to Supp, as an assumption: to assume something, as\nordinarily understood, is to assume that it is true; and conditionals\nare not being construed as ordinary statement of fact. But we could\napproximate the idea of taking the premises as assumptions, by\ntreating them, hypothetically, as certainties. Treating the premises\nthus would be to require of a valid argument that it preserve\ncertainty: that there must be no probability distributions in which\nall the premises (conditional or otherwise) are assigned probability 1\nand the conclusion is assigned probability less than 1. Call this the\ncertainty-preservation principle (CPP). \nThe conception of validity we have been using (PPP) takes as central\nthe fact that premises may be accepted with degrees of confidence less\nthan certainty. Now, anything which satisfies PPP satisfies CPP. And\nfor argument involving only factual propositions, the converse is also\ntrue: the same class of arguments necessarily preserves truth,\nnecessarily preserves certainty and necessarily preserves probability\nin the sense of PPP. But arguments involving conditionals can satisfy\nCPP without satisfying PPP. The invalid argument forms above do\npreserve certainty: if you assign probability 1 to the premises, then\nyou are constrained to assign probability 1 to the conclusion (in all\nprobability distributions in which the antecedent of any conditional\ngets non-zero probability). But they do not preserve high probability.\nThey do not satisfy PPP. If at least one premise falls short of\ncertainty by however small an amount, the conclusion can plummet to\nzero. \nThe logico-mathematical fact behind this is the difference in logical\npowers between “All” and “Almost all”. If all\n\\(A\\)-worlds are \\(B\\)-worlds (and there are some \\(C \\amp A\\)-worlds)\nthen all \\(C \\amp A\\)-worlds are \\(B\\)-worlds. But we can have: almost\nall \\(A\\)-worlds are \\(B\\)-worlds but no \\(C \\amp A\\)-world is a\n\\(B\\)-world. If all \\(A\\)-worlds are \\(B\\)-worlds and all \\(B\\)-worlds\nare \\(C\\)-worlds, then all \\(A\\)-worlds are \\(C\\)-worlds. But we can\nhave: all \\(A\\)-worlds are \\(B\\)-worlds, almost all \\(B\\)-worlds are\n\\(C\\)-worlds, yet no \\(A\\)-world is a \\(C\\)-world; just as we can\nhave, all kiwis are birds, almost all birds fly, but no kiwi\nflies. \nSomeone might react as follows: “All I want of a valid argument\nis that it preserve certainty. I’m not bothered if an argument\ncan have premises close to certain and a conclusion far from certain,\nas long as the conclusion is certain when the premises are\ncertain”. \nWe could use the word “valid” in such a way that\nan argument is valid provided it preserves certainty. If our interest\nin logic is confined to its application to mathematics or other a\npriori matters, that is fine. Further, when our arguments do not\ncontain conditionals, if we have certainty-preservation,\nprobability-preservation comes free. But if we use conditionals when\narguing about contingent matters, then great caution will be required.\nUnless we are 100% certain of the premises, the arguments above which\nare invalid on Adams’s criterion guarantee nothing about what\nyou are entitled to think about the conclusion. The line between 100%\ncertainty and something very close is hard to make out: it’s not\nclear how you tell which side of it you are on. The epistemically\ncautious might admit that they are never, or only very rarely, 100%\ncertain of contingent conditionals. So it would be useful to have\nanother category of argument, the “super-valid”, which\npreserves high probability as well as certainty. Adams has shown us\nwhich arguments (on Supp’s reading of “if”) are\nsuper-valid. \nContinuing to restrict our attention to the case where the antecedent\nhas non-zero probability, this argument-form preserves certainty:\nA\\(\\supset\\)B; so A\\(\\Rightarrow\\)B. The\nconverse inference is uncontroversial. So if we were just concerned\nwith certainty preservation, Hook and Supp would be equivalent. But\nthey are far from equivalent for uncertain beliefs: the former can be\narbitrarily close to 1 while the latter is 0. \nAdams’s theory of validity emerged in the mid-1960s.\n“Nearest possible worlds” theories were not yet in\nevidence. Nor was Lewis’s result that conditional probabilities\nare not probabilities of the truth of a proposition. (Adams expressed\nscepticism about truth conditions for conditionals, but the question\nwas still open.) Stalnaker’s (1968) semantics for conditionals\nwas an attempt to provide truth conditions which were compatible with\nRamsey’s and Adams’s thesis about conditional belief. (See\nalso Stalnaker (1970), where the probabilistic aspects of his proposal\nare developed.) That is, he sought truth conditions for a proposition\n\\(A\\gt B\\) (his notation) such that \\(\\mathbf{p}(A\\gt B)\\) must equal\n\\(\\mathbf{p}_A (B)\\):  \nIf an argument is necessarily truth-preserving, the improbability of\nits conclusion cannot exceed the sum of the improbabilities of the\npremises. The latter was the criterion Adams used in constructing his\nlogic. So Stalnaker’s logic for conditionals must agree with\nAdams’s over their common domain. And it does. The argument\nforms we showed to be invalid in Adams’s logic (§3.2) are\ninvalid on Stalnaker’s semantics. For instance, the following is\npossible: in the nearest possible world in which you strike the match,\nit lights; in the nearest world in which you dip the match in water\nand strike it, it doesn’t light. So Strengthening fails. (By\n“nearest world in which …” I mean the possible\nworld which is minimally different from the actual world in which\n… .)  \nConditional Proof fails for Stalnaker’s semantics. “\\(A\\)\nor \\(B\\); \\({\\sim}A\\); so \\(B\\)” is of course valid. But (*)\n“\\(A\\) or \\(B\\), therefore \\({\\sim}A\\gt B\\)” is not: it\ncan be true that Ann or Mary cooked the dinner (for Ann cooked it);\nyet false that in the nearest world to the actual world in which Ann\ndid not cook it, Mary cooked it. \nStalnaker (1975) argued that although (*) is invalid, it is\nnevertheless a “reasonable inference” when “\\(A\\) or\n\\(B\\)” is assertable, that is, in a context in which \\({\\sim}A\n\\amp{\\sim}B\\) has been ruled out but \\({\\sim}A \\amp B\\) and \\(A\n\\amp{\\sim}B\\) remain open possibilities. \nStalnaker’s semantics uses a “selection function”,\nF, which selects, for any proposition \\(A\\) and any world \\(w\\), a\nworld, \\(w'\\), the nearest (most similar) world to \\(w\\) at which\n\\(A\\) is true. “If \\(A, B\\)” is true at \\(w\\) iff \\(B\\) is\ntrue at F\\((A, w)\\), i.e. at \\(w'\\). “If \\(A, B\\)” is true\nsimpliciter iff \\(B\\) is true at the nearest \\(A\\)-world to the actual\nworld. (However, we do not know which world is the actual\nworld—there are many candidates compatible with our knowledge.\nTo be sure that if \\(A, B\\), we need to be sure that whichever world\n\\(w\\) is a candidate for actuality, \\(B\\) is true at the nearest\n\\(A\\)-world to \\(w\\).) If \\(A\\) is true, the nearest \\(A\\)-world to\nthe actual world is the actual world itself, so in this case “If\n\\(A, B\\)” is true iff \\(B\\) is also true. The selection function\ndoes substantive work only when \\(A\\) is false. \nStalnaker’s theory is intended to apply to counterfactuals and\nindicative conditionals alike, but in the case of indicative\nconditionals, he claims, the selection function is subject to a\npragmatic constraint, set in the framework of the dynamics of\nconversation. At any stage in a conversation, many things are taken\nfor granted by speaker and hearer, i.e. many possibilities are taken\nas already ruled out. The remaining possibilities are live. He calls\nthe set of worlds which are not ruled out — the live\npossibilities — the context set. For indicative conditionals,\nantecedents are typically live possibilities, and we focus on that\ncase. The pragmatic constraint for indicative conditionals says that\nif the antecedent \\(A\\) is compatible with the context set (i.e. true\nat some worlds in the context set) then for any world \\(w\\) in the\ncontext set, the nearest \\(A\\)-world to \\(w\\) — i.e. the world\npicked out by the selection function — is also a member of the\ncontext set. Roughly, if \\(A\\) is a live possibility (i.e. not already\nruled out), then for any world \\(w\\) which is a live possibility, the\nnearest \\(A\\)-world to \\(w\\) is also a live possibility. Or: things\nwhich are taken to be epistemically possible count as closer to\nactuality than things which are not. \nThe proposition expressed by “If \\(A, B\\)” is the set of\nworlds \\(w\\) such that the nearest \\(A\\)-world to \\(w\\) is a\n\\(B\\)-world. The ordering of worlds, by the pragmatic constraint,\ndepends on the conversational setting. As different possibilities are\nlive in different conversational settings, a different proposition may\nbe expressed by “If \\(A, B\\)” in different conversational\nsettings. Thus, the truth-conditions of conditionals are\ncontext-dependent, depending on which possibilities the speaker and\nhearer have ruled out. \nLet us transpose this to the one-person case: I am talking to myself,\ni.e. thinking — considering whether if \\(A, B\\). The context set\nis the set of worlds compatible with what I take for granted, i.e. the\nset of worlds not ruled out, i.e. the set of worlds which are\nepistemically possible for me. Let \\(A\\) be epistemically possible for\nme. Then the pragmatic constraint requires that for any world in the\ncontext set, the nearest \\(A\\)-world to it is also in the context set.\nProvided you and I have different bodies of information, the\nproposition I am considering when I consider whether if \\(A, B\\) may\nwell differ from the proposition you would express in the same words:\nthe constraints on nearness differ; worlds which are near for me may\nnot be near for you. \nThis enables Stalnaker to avoid the argument against\nnon-truth-functional truth conditions given in §2.2. The argument\nwas as follows. There are six incompatible logically possible\ncombinations of truth values for \\(A, B\\) and \\({\\sim}A\\gt B\\). We\nstart off with no firm beliefs about which obtains. Now we eliminate\njust \\({\\sim}A \\amp{\\sim}B\\), i.e. establish \\(A\\) or \\(B\\). That\nleaves five remaining possibilities, including two in which\n“\\({\\sim}A\\gt B\\)” is false. So we can’t be certain\nthat \\({\\sim}A\\gt B\\) (whereas, intuitively, one can be certain of the\nconditional in these circumstances). Stalnaker replies: we\ncan’t, indeed, be certain that the proposition we were wondering\nabout earlier is true. But we are now in a new context: \\({\\sim}A\n\\amp{\\sim}B\\)-worlds have been ruled out (but \\({\\sim}A \\amp\nB\\)-worlds remain). We now express a different proposition by\n“\\({\\sim}A\\gt B\\)”, with different truth conditions,\ngoverned by a new nearness relation. As all our live\n\\({\\sim}A\\)-worlds are \\(B\\)-worlds (none are \\({\\sim}B\\)-worlds), we\nknow that the new proposition is true. \nThis sensitivity of the proposition expressed by “If \\(A,\nB\\)” to what is taken for granted by speaker and hearer, or to\nthe epistemic state of the thinker, is somewhat unnatural. One usually\ndistinguishes between the content of what is said and the different\nepistemic attitudes one may take to that same content. Someone\nconjectures that if Ann isn’t home, Bob is. We are entirely\nagnostic about this. Then we discover that at least one of them is at\nhome (nothing stronger). We now accept the conditional. It seems more\nnatural to say that we now have a different attitude to the same\nconditional thought, that \\(B\\) on the supposition that \\({\\sim}A\\).\nIt does not seem that the content of our conditional thought has\nchanged. And if there are conditional propositions, it seems more\nnatural to say that we now take to be true what we were previously\nwondering about. There does not seem to be independent motivation for\nthinking the content of the proposition has changed. \nAlso, Stalnaker’s argument is restricted to the special case\nwhere we take the \\({\\sim}A \\amp{\\sim}B\\)-possibilities to be ruled\nout. Consider a case when, starting out agnostic, we become close to\ncertain, but not quite certain, that \\(A\\) or \\(B\\) — say we\nbecome about 95% certain that \\(A\\) or \\(B\\), and are about 50%\ncertain that \\(A\\). According to Supp, we are entitled to be quite\nclose to certain that if \\({\\sim}A, B\\) — 90% certain in fact.\n(If \\(\\mathbf{p}(A \\text{ or } B) = 95\\)% and \\(\\mathbf{p}(A) = 50\\)%,\nthen \\(\\mathbf{p}({\\sim}A \\amp B) = 45\\)%. Now \\(\\mathbf{p}({\\sim}A\n\\amp{\\sim}B) = 5\\)%. So, on the assumption that \\({\\sim}A\\),\nit’s 45:5, or 9:1, that \\(B\\).) In this case, no additional\npossibilities have been ruled out. There are \\({\\sim}A\n\\amp{\\sim}B\\)-worlds as well as \\({\\sim}A \\amp B\\)-worlds which are\npermissible candidates for being nearest. Stalnaker has not told us\nwhy we should think it likely, in this case, that the nearest\n\\({\\sim}A\\)-world is a \\(B\\)-world. \nUncertain conditional judgements create difficulties for all\npropositional theories. As we have seen, it is easy to construct\nprobabilistic counterexamples to Hook’s theory; and it is easy\nto do so for the variant of Stalnaker’s theory according to\nwhich “If \\(A, B\\)” is true iff \\(B\\) is true at\nall nearest \\(A\\)-worlds (as Lewis (1973) holds for\ncounterfactuals). (It is very close to certain that if you toss the\ncoin ten times, you will get at least one head; but it is certainly\nfalse that the consequent is true at all nearest\nantecedent-worlds.) It is rather harder for Stalnaker’s theory,\nbecause nearness is so volatile, and also because it is not fully\nspecified. But here is a putative counterexample: the short straws.\n(An example of this type I learned from James Studd.) \nYou are to pick a straw from a collection of 100 straws. From the\nangle you see them—end on—they all look the same; and they\nare the same, except for length. 90 are of length 10 cm, 1 is\n11 cm, and 9 are 20 cm. Consider this conditional, about the\nstraw that will be picked: \n(*) If it’s over 10 cm, it’s less than 15 cm.\n \nIntuitively, (*) is 10% likely: of those over 10 cm, one is under\n15 cm and nine are not. But on Stalnaker’s theory, (*)\nappears to be 91% likely: it’s 90% likely that it is not over\n10 cm, in which case, in the world most similar to the actual\nworld in which it is over 10 cm, it is 11 cm, i.e. less than\n15 cm. And we add another 1% for the case in which it is\n11 cm, hence under 15 cm. \n(The point is simpler for the counterfactual: “If it had been\nover 10 cm, it would have been less than 15 cm”:\njudging by similarity to the actual world, this seems true; but\nintuitively it is only 10% likely.) \nThe example casts doubt on whether any notion of similarity, or\nminimal difference from the actual world, is the right notion for\nunderstanding conditionals, as opposed to taking a probability\ndistribution over the various possible antecedent worlds. \nThere is also the question, for Stalnaker, of the uniqueness\nassumption—that there is a unique closest antecedent-world.\nStalnaker (1981, pp. 87–91) discusses this, and proposes to use\nthe machinery of supervaluations when there is no unique nearest\nworld: the conditional is true iff true whichever of the candidates\nfor nearest the selection function selects, false iff false for all\nsuch selections, otherwise it is indeterminate—neither true nor\nfalse. As the uniqueness assumption often fails, a great many\nconditionals will just get the verdict indeterminate. For instance, I\nam considering whether, (*) if I pick a red ball, it will have a black\nspot. 90% of the red balls have black spots. Merely to be told that\n(*) is indeterminate, is less helpful than being told it is 90%\nlikely. \nDoes making the proposition expressed by the conditional\ncontext-dependent escape Lewis’s result that a conditional\nprobability is not the probability of the truth of any proposition?\nLewis showed that there is no proposition \\(A*B\\) such that in every\nbelief state \\(\\mathbf{p}(A*B) = \\mathbf{p}_A (B)\\). He did not rule\nout that in every belief state there is some proposition or other,\n\\(A*B\\), such that \\(\\mathbf{p}(A*B) = \\mathbf{p}_A (B)\\). However, in\nthe wake of Lewis, Stalnaker himself proved a stronger result, for his\nconditional connective: the equation \\(\\mathbf{p}(A\\gt B) =\n\\mathbf{p}_A (B)\\) cannot hold for all propositions \\(A, B\\) in a\nsingle belief state. If it holds for \\(A\\) and \\(B\\), we can find two\nother propositions, \\(C\\) and D (truth-functional compounds of \\(A,\nB\\) and \\(A\\gt B)\\) for which, demonstrably, it does not hold. (See\nStalnaker’s letter to van Fraassen published in van Fraassen\n(1976, pp. 303–4), Gibbard (1981, pp. 219–20), and\nEdgington (1995, pp. 276–8). \nIt was Gibbard (1981, pp. 231–4) who showed just how sensitive\nto epistemic situations Stalnaker’s truth conditions would be.\nLater (1984, ch. 6), reacting to Gibbard, Stalnaker seemed more\nambivalent about whether conditional judgements express propositions.\nBut he still takes his original theory to be a serious candidate\n(Stalnaker 2005, 2019), and this remains an influential theory. His\nwork has inspired others to develop related theories:\ncontext-dependent theories are currently popular (see below,\n§4.3); the fact that Stalnaker kept the probabilistic\nconsiderations aside in his 1968 paper led others to develop the\nRamsey test for all-or-nothing beliefs—see e.g. Gärdenfors\n(1986); and another close relative of Stalnaker’s semantics, due\nto Richard Bradley (2012), is discussed below in §5. \nFrank Jackson holds that “If \\(A, B\\)” has the truth\nconditions of “\\(A \\supset B\\)”, i.e. “\\({\\sim}A\\)\nor \\(B\\)”; but it is part of its meaning that it is governed by\na special rule of assertability. “If” is assimilated to\nwords like “but”, “nevertheless” and\n“even”. “\\(A\\) but \\(B\\)” has the same truth\nconditions as “\\(A\\) and \\(B\\)”, yet they differ in\nmeaning: “but” is used to signal a contrast between \\(A\\)\nand \\(B\\). When \\(A\\) and \\(B\\) are true and the contrast is lacking,\n“\\(A\\) but \\(B\\)” is true but inappropriate. Likewise,\n“Even John can understand this proof” is true when John\ncan understand this proof, but inappropriate when John is a\nworld-class logician.  \nAccording to Jackson, in asserting “If \\(A, B\\)” the\nspeaker expresses his belief that \\(A \\supset B\\), and also indicates\nthat this belief is “robust” with respect to the\nantecedent \\(A\\). In Jackson’s early work (1979, 1980)\n“robustness” was explained thus: the speaker would not\nabandon his belief that \\(A \\supset B\\) if he were to learn that\n\\(A\\). This, it was claimed, amounted to the speaker’s having a\nhigh probability for \\(A \\supset B\\) given \\(A\\), i.e. for\n\\(({\\sim}A\\) or \\(B)\\) given \\(A\\), which is just to have a high\nprobability for \\(B\\) given \\(A\\). Thus, assertability goes by\nconditional probability. Robustness was meant to ensure that an\nassertable conditional is fit for modus ponens. Robustness is not\nsatisfied if you believe \\(A \\supset B\\) solely on the grounds that\n\\({\\sim}A\\). Then, if you discover that \\(A\\), you will abandon your\nbelief in \\(A \\supset B\\) rather than conclude that \\(B\\). \nJackson came to realise, however, that there are assertable\nconditionals which one would not continue to believe if one learned\nthe antecedent. I say “If Reagan worked for the KGB, I’ll\nnever find out” (Lewis’s example (1986, p. 155)). My\nconditional probability for consequent given antecedent is high. But\nif I were to discover that the antecedent is true, I would abandon the\nconditional belief, rather than conclude that I will never find out\nthat the antecedent is true. So, in Jackson’s later work (1987),\nrobustness with respect to \\(A\\) is simply defined as \\(\\mathbf{p}_A\n(A \\supset B)\\) being high, which is trivially equivalent to\n\\(\\mathbf{p}_A (B)\\) being high. In most cases, though, the earlier\nexplanation will hold good. \nWhat do we need the truth-functional truth conditions for? Do they\nexplain the meaning of compounds of conditionals? According to\nJackson, they do not (1987, p. 129). We know what “\\(A \\supset\nB\\)” means, as a constituent in complex sentences. But\n“\\(A \\supset B\\)” does not mean the same as “If \\(A,\nB\\)”. The latter has a special assertability condition. And his\ntheory has no implications about what, if anything, “if \\(A,\nB\\)” means when it occurs, unasserted, as a constituent in a\nlonger sentence. \n(Here his analogy with “but” etc. fails. “But”\ncan occur in unasserted clauses: “Either he arrived on time but\ndidn’t wait for us, or he never arrived at all” (see Woods\n(1997, p. 61)). It also occurs in questions and commands: “Shut\nthe door but leave the window open”. “Does anyone want\neggs but no ham?”. “But” means “and in\ncontrast”. Its meaning is not given by an “assertability\ncondition”.) \nDo the truth-functional truth conditions explain the validity of\narguments involving conditionals? Not in a way that accords well with\nintuition, we have seen. Jackson claims that our intuitions are at\nfault here: we confuse preservation of truth and preservation of\nassertability (1987, pp. 50–1). \nNor is there any direct evidence for Jackson’s theory. Nobody\nwho thinks the Republicans won’t win treats “If the\nRepublicans win, they will double income tax” as inappropriate\nbut probably true, in the same category as “Even Gödel\nunderstood truth-functional logic”. Jackson is aware of this. He\nseems to advocate an error theory of conditionals: ordinary linguistic\nbehaviour fits the false theory that there is a proposition \\(A*B\\)\nsuch that \\(\\mathbf{p}(A*B) = \\mathbf{p}_A (B)\\) (1987, pp.\n39–40). If this is his view, he cannot hold that his own theory\nis a psychologically accurate account of what people do when they use\nconditionals. Perhaps it is an account of how we should use\nconditionals, and would if we were free from error: we should\naccept that “If the Republicans win they will double income\ntax” is probably true when it is probable that the Republicans\nwon’t win. Would we gain anything from following this\nprescription? It is hard to see that we would: we would deprive\nourselves of the ability to discriminate between believable and\nunbelievable conditionals whose antecedents we think false. \nFor Jackson’s more recent thoughts on conditionals see his\npostscript (1998, pp. 51–54). See also Edgington (2009) and\nJackson’s reply (2009, pp. 463–6).  \nAngelika Kratzer’s work on conditionals has been very\ninfluential in linguistics, and also in philosophy. Her articles have\nappeared, reworked, as a book, Modals and Conditionals\n(2012). Kratzer’s inspiration comes from a paper by David Lewis,\n“Adverbs of Quantification” (1975). Lewis’s paper is\nabout the analysis of sentences containing adverbs such as\nalways, never, usually, often,\nseldom …, sentences such as “The fog usually\nlifts before noon here” and “Caesar seldom awoke before\ndawn”. After considering and rejecting some alternatives, Lewis\nintroduces “restriction by if-clauses”: he proposes that\nthere is a use of if-clauses whose function is to restrict the range\nof cases to which the operator or quantifier applies. First paraphrase\nthe sentences: “Usually if there is fog here, it lifts before\nnoon.” “Seldom if Caesar awoke, it was before dawn.”\n(Lewis’s target sentences do not have “if” in their\nsurface structure, but they could have had: the theory also applies to\nsentences like “Usually, if Mary visits, she brings her\ndog”.) The “if” restricts the “usually”\nto the occurrences of fog here, or of Mary’s visits, and the\n“seldom” to Caesar’s awakenings. These sentences are\nnot to be construed as applying an adverb to a conditional\nproposition. The adverb applies to the main clause, its scope\nrestricted by the if-clause. Thus Lewis:  \nLewis’s final example is particularly interesting, especially\nbecause this paper was written at much the same time as his proof that\nconditional probabilities are not to be construed as probabilities of\nconditional propositions.  \nLewis has three different accounts of “if”: he follows\nJackson in claiming that the “if” of indicative\nconditionals is the truth-functional “if”, with a special\nrule of assertability (see Lewis 1986 pp. 152–6); there is his\nfamous account of the “if” of counterfactual conditionals\n(Lewis 1973); and there is this use of “if” as a\nrestrictor.  \nKratzer’s idea is that this last account of “if” as\na restrictor should be applied to all conditionals. Consider first\nconditionals which contain a modal term: “If it’s not in\nthe kitchen it must be in the bathroom/might be in the bathroom/is\nprobably in the bathroom”. By analogy with Lewis, she argues\nthat these are not to be construed as attaching a modal term to a\nconditional proposition; rather, they are to be construed as attaching\na modal term to the main clause, the scope of the modal term being\nrestricted by the conditional clause.  \nBut what of a simple conditional which does not contain a modal\noperator, such as “If it’s not in the kitchen it is in the\nbathroom” — what Kratzer calls the “bare\nconditional”? Here is her famous remark:  \nThere is much in common between the restrictor-view of conditionals\nand the suppositional view. A supposition also restricts one’s\nclaim to the case in which the antecedent is true. The strength of\nyour conditional belief is measured by how probable you judge the\nconsequent, on the assumption that the antecedent is satisfied; and\nthis is not the same as thinking a conditional proposition is probably\ntrue. Recall Lewis’s remark about “the probability that\n… if”. Kratzer’s treatment of modal conditionals\nmay be seen as a generalization to other modalities of this treatment\nof “Probably, if \\(A, C\\)”.  \nHowever, Kratzer’s treatment of the “bare\nconditional” is controversial: at the level of semantic\nstructure, there really are no such things — apparent bare\nconditionals contain an “unpronounced modal operator”. If\nthe modal operator is an epistemic “must”, as she\nsuggests, bare conditionals are a species of strict conditional\n— something like “all live \\(A\\)-possibilities are\n\\(C\\)-possibilities”.  \nThis proposal has difficulty handling the fact that one may adopt\nepistemic attitudes to a conditional of varying degrees of closeness\nto certainty. I may be close to certain, but not completely certain,\nthat Jane will accept if she is offered the job, that if I have the\noperation I will be cured, etc. Not all the relevant\n\\(A\\)-possibilities are \\(C\\)-possibilities. On this proposal, in\nthese circumstances the conditionals are clearly, definitely false,\nand should be completely rejected, and hence not something one should\nbe close to certain of. This point holds for any kind of strict\nconditional — any kind of “must”. Stalnaker (1981 p.\n100) made essentially the same point, about counterfactuals, comparing\nhis view with Lewis’s. On a strict-conditional account, the\nfollowing exchange should be in order:  \nB’s remark sounds contradictory. \nStalnaker (ibid.) attributes to Thomasson the closely related point:\n \nAlthough B’s reply seems sensible, it is defective on the\nstrict-conditional proposal: not all offer-possibilities are\naccept-possibilities. The conditional is clearly false. One should not\nbelieve something which one judges to be clearly false.  \nKratzer will reply that “I believe Jane will accept if she\noffers the job” introduces a different modality: restricting\nattention to the offer-possibilities, I believe (but am not certain)\nthat she accepts. Nevertheless, she cannot allow that one can take\ndifferent epistemic attitudes to the same conditional thought. In this\nrespect her view differs from the Ramsey–Adams approach, as well\nas the propositional view. \nNor would it do to make the unpronounced modal operator in bare\nconditionals “probably”; for one can be certain that it is\nprobable that if \\(A, C\\), without being certain that if \\(A, C\\).\nThis point is made in more detail by Edgington (1995, pp.\n292–3). Thus, while the restrictor view has some plausibility,\nits treatment of the “bare conditional” as a modalised\nproposition is problematic.  \nOther philosophers have also defended the view that indicative\nconditionals are context-dependent strict conditionals, without\nadopting Kratzer’s restrictor view. According to Anthony Gillies\n(2009), a context determines a set of possibilities compatible with\nthe relevant information in the context. “If \\(A, C\\)” is\ntrue at a context iff all relevant \\(A\\)-possibilities are\n\\(C\\)-possibilities, false otherwise. William Lycan (2001), similarly,\nclaims that “If \\(A, C\\)” is true iff all real and\nrelevant \\(A\\)-events are \\(C\\)-events. Context-dependent strict\nconditionals are also defended by Daniel Rothschild (2013, 2015). The\ndifficulty mentioned above remains: on these accounts, a conditional\nmay be certainly false, yet probable.  \nI shall discuss only briefly a recently published book by Timothy\nWilliamson, Suppose and Tell (2020). Williamson accepts that\nthe suppositional procedure—suppose the antecedent, and on that\nbasis come to a judgement about the consequent—is our\nfundamental, primary method of conditional judgement, an essential\npart of our cognitive equipment. As uncertainty is often involved, he\naccepts that it is appropriate to theorize about this process in terms\nof conditional probabilities. This is what he calls the\nheuristics of conditionals (not to be confused with\nsemantics). Heuristics are part of our cognitive and psychological\napparatus, “fast and frugal”, immensely useful and\nvaluable, but typically imperfect. In this case, they lead to subtle\nlogical problems, he argues (ch. 3), broadly of the same kind as\nLewis’s triviality results—indeed, to inconsistencies. An\nassessment of these arguments will have to wait for another occasion.\nNevertheless, he claims, they are useful and valuable for our everyday\nconditional thinking.  \nAlso, he argues, this primary heuristic is sometimes at odds with a\nsecondary heuristic—acquiring conditional beliefs by testimony.\nOften this is unproblematic, but, as Gibbard (1981) showed, two people\nwith different background knowledge can flawlessly come to opposite\njudgements about whether if \\(A, B\\). They then convey their\njudgements to a third person, who trusts them, but who cannot accept\nboth judgements, using the suppositional procedure.  \nHere is Gibbard’s example: two henchmen, Zack and Jack, observe\na poker game, between Sly Pete and Mr Stone. Zack sees Stone’s\nhand, and signals its contents to Pete. He knows that Pete won’t\ncall unless he has the winning hand. Jack sees both hands, and sees\nthat Pete does not have the winning hand. The room is cleared.\nOutside, Zack hands a note to the boss which says “If Pete\ncalled, he won”. Jack hands a note to the boss which says\n“If Pete called, he lost”. Boss trusts them both, and\nconcludes that Pete did not call. But Boss cannot simply take over\nboth conditionals as suppositional judgements on the supposition that\nPete called: if one gets a high value, the other gets a low value.\n(Nor can Boss think that in the nearest world in which Pete called, he\nlost and he won.) Williamson has several variants of examples of this\nstructure. (As some have pointed out, Gibbard’s example is\nperhaps not perfectly symmetric, as Jack’s judgement might seem\nthe most securely based; but plenty of perfectly symmetric examples\nhave since been given.)  \nThe truth-functional, material conditional turns out to be useful\nhere. The suppositional conditional entails the truth-functional\nconditional. Zack is committed to “Pete called \\(\\supset\\) Pete\nwon”, i.e., either Pete didn’t call, or he won. Jack is\ncommitted to “Pete called \\(\\supset\\) Pete lost”, i.e.,\neither Pete didn’t call, or he lost. From both, it\nstraightforwardly follows that Pete didn’t call. The\ntruth-functional conditional is the strongest proposition\nwhich gets transmitted by conditional testimony. Testimony, at its\nbest, concerns the transmission of facts; and we can always resort to\nthe truth-functional conditional as a fact that gets transmitted by a\nreliable conditional statement, when problems arise from the differing\nbackground knowledge of our informants (as suppositionalists can\nagree).  \nThis is one of the reasons why Williamson argues that the\nsemantics of the conditional is best treated as the truth\nfunction. The semantics is not something which every speaker knows, or\nis readily available to them. We do not learn to use “if”\nvia the truth table. And we know that no semantic theory of the\nconditional is obviously correct! The probabilities generated\nby the semantics are typically higher, and never lower than the\nprobabilities generated by our basic suppositional procedure for\nassessing conditionals. Nevertheless, he argues, the truth-functional\nsemantics does the best job of rationalizing our overall practice.\n \nWilliamson gives other examples of useful but imperfect heuristics.\nOne concerns vagueness, and the so-called “tolerance\nprinciples”, such as “If \\(n\\) seconds after noon is\nnoonish, \\(n+1\\) seconds after noon is noonish”. That is a\nuseful rule of thumb, though not all of its instances can be true. For\nthe epistemicist, one instance is false, but we don’t know\nwhich. On other views, all are at least very close to clearly true,\nbut not all are clearly true. Another example is the problem the Liar\nParadox presents for the principle that it is true that \\(P\\) if and\nonly if \\(P\\). In both cases, the exceptions are rare and can normally\nbe overlooked. He also mentions the heuristics involved in perceptual\njudgements, normally very reliable, which sometimes lead us astray.\n“Humans predictably resort to fast and frugal heuristics,\nreliable enough under normal conditions, but not perfectly\nreliable” he says, (p. 265).  \nHowever, in the case of uncertain conditionals, it is hard to accept\nthat the heuristics are “reliable enough under normal\nconditions”, when combined with the truth-functional semantics.\nWhen the conditional is certain, the suppositional procedure and the\ntruth function agree. They also agree in the relatively uninteresting\ncase in which the antecedent is certain. In all other cases, the\ntruth-functional conditional gets a higher value than the\nsuppositional conditional, and the difference between them can be\narbitrarily large. Many examples have already been given (see\n§§2.3, 2.5, 3.1, 3.2). Another simple example: how likely is\nit that if the die lands an even number, it lands 6? Most people,\nrightly in my view, will answer 1/3. If the conditional is a material\nimplication, the answer is 2/3: if it lands 1, 3, 5 or 6, the\nconditional is true. As already mentioned, all conditionals whose\nantecedents are improbable, are probable as judged by the truth\nfunction.  \nAnother example: we are planning a trip in a couple of days, and\nwondering whether  \n(*) if it snows the night before, the road will be impassable.  \nThe probability of snow is around 0.5; and we reckon (on the\nsuppositional procedure), it’s around 0.2 that the road will be\nimpassable if it snows. According to the truth function, the\nconditional gets 0.6. Then, as forecasts are updated, the probability\nof snow decreases. Nothing else changes. On the truth-functional\nsemantics, the probability of our conditional goes up as the\nprobability of snow goes down: when the probability of snow goes down\nto 0.25, the probability of (*) is 0.8 on the truth-functional\nreading, although it remains at 0.2 on the suppositional approach.\nWilliamson says that our suppositional procedure errs “on the\nside of caution” (p. 104) by generating lower probability values\nthan the truth-functional conditional. It is hard to see why, as the\nprobability of snow decreases, we become more risk-averse, and make\nlarger errors on the side of caution.  \nA common complaint against Supp’s theory is that if conditionals\ndo not express propositions with truth conditions, we have no account\nof the behaviour of compound sentences with conditionals as parts (see\ne.g. Lewis (1976, p. 142)). Probability theory is no help: conditional\nprobabilities never occur inside wider constructions. However, no\ntheory has an intuitively adequate account of compounds of\nconditionals: we saw in §2.4 that there are compounds which Hook\ngets wrong; and compounds which Arrow gets wrong. Grice’s and\nJackson’s defences of Hook focus on what more is needed to\njustify the assertion of a conditional, beyond belief that it\nis true. This is no help when it occurs, unasserted, as a constituent\nof a longer sentence, as Jackson accepts. And with negations of\nconditionals and conditionals in antecedents, we saw, the problem is\nreversed: we assert conditionals which we would not believe if we\nconstrued them truth-functionally. \nSome followers of Adams have tried to show that when a sentence with a\nconditional subsentence is intelligible, it can be paraphrased, at\nleast in context, by a sentence without a conditional subsentence. For\ninstance, they read “It’s not the case that if \\(A,\nB\\)” as “If \\(A\\), it’s not the case that\n\\(B\\)”, and “If \\(A\\), then if \\(B, C\\)” as\n“If \\(A \\amp B, C\\)”. They also point out that some\nconstructions are rarer, and harder to understand, and more peculiar,\nthan would be expected if conditionals had truth conditions and\nembedded in a standard way. See Appiah (1985, pp. 205–10),\nGibbard (1981, pp. 234–8), Edgington (1995, pp. 280–4),\nWoods (1997, pp. 58–68 and 120–4); see also Jackson (1987,\npp. 127–37). (Note that the Lewis-Kratzer strategy (§4.3)\nalso involves paraphrase, so that conditional propositions are not\nembedded in adverbs and operators.) But it would be better to have a\nsystematic solution to this problem, and there have several\nattempts. \nThe first attempt to construct a theory of compounds of conditionals,\ncompatible with Supp’s thesis, is due to Bruno de Finetti\n(1936), who, shortly after Ramsey, independently developed a theory of\nprobability as degree of belief, and like Ramsey, saw that conditional\nprobability seemed a good measure of one’s degree of belief in a\nconditional. To deal with compounds of conditionals, he proposed a\nthree-valued semantics for the conditional—true, false,\nundefined. “If \\(A, B\\)” is true if \\(A \\amp B\\), false if\n\\(A \\amp{\\sim}B\\), and lacks a truth value—is undefined—if\n\\({\\sim}A\\). He called these semantic entities “conditional\nevents” or “tri-events”. The probability of a\nconditional is not the probability of its truth (which is just the\nprobability of \\(A \\amp B)\\), but the probability of its truth given\nthat it is either true or false, which is just the conditional\nprobability of \\(B\\) given \\(A\\). Then de Finetti gave truth tables,\nwhich accommodate compounds of conditionals. A conjunction is true iff\nboth conjuncts are true, false iff at least one conjunct is false,\notherwise undefined. A disjunction is true iff at least one disjunct\nis true, false if both disjuncts are false, otherwise undefined.\nNegation takes true to false, false to true, undefined to undefined. A\nconditional with a false or undefined antecedent is undefined. And the\nprobability of a compound is also the probability that it is true,\ngiven that it is either true or false. For work in this tradition see\nMilne (1997). See also Belnap (1970) and McDermott (1996). \nThe idea has a certain appeal. A conditional, if \\(A, B\\), involves\nthe supposition that \\(A\\). It tells us nothing about what happens if\n\\(A\\) is false. But there are costs. On this account, to\nbelieve/assert a conditional is not to believe/assert that it is true.\nIt is no fault in a conditional that it is not true, for it is no\nfault in a conditional that it has a false antecedent. I say “If\nyou press that button there will be an explosion”. A disaster is\navoided, because, fortunately, my remark was not true. One might say\nthe normative dimension of truth has been lost. We have to give up the\nequivalence between “If \\(A, B\\)” and “It is true\nthat if \\(A, B\\)”. Even a necessary conditional such as\n“If \\(A \\amp B\\), then \\(A\\)” can fail to be true.\nValidity cannot be preservation of truth, for if it were, “If\n\\(A, B\\); so \\(A \\amp B\\)” would be a valid argument. \nFurther, some of the results this theory delivers for embedded\nconditionals are not plausible. Mother says “If it doesn’t\nrain tomorrow we’ll go to the beach, and if it rains we’ll\ngo to the cinema”. This rightly inspires confident expectations.\nBut on the present theory, as one or the other conditional has a false\nantecedent, the conjunction cannot be true. Yet one or the other\nconditional might be false, due to some unlikely contretemps, such as\nillness, in which case the conjunction is false. So the probability\nthat it is true, given that it is either true or false, is 0. The\nchildren are 99% confident that if \\({\\sim}R, B\\), and 99% confident\nthat if \\(R, C\\), but, on this account, they should be 0% confident\nthat (if \\({\\sim}R, B)\\) & (if \\(R, C)\\). (McGee (1989) raises\nthis objection to the account.) \nA second approach gives “semantic values” to conditionals\nas follows: \\(1 (=\\) true) if \\(A \\amp B\\); \\(0 (=\\) false) if \\(A\n\\amp{\\sim}B\\); \\(\\mathbf{p}_A (B)\\) if \\({\\sim}A\\). See van Fraassen\n(1976), McGee (1989), Jeffrey (1991), Stalnaker and Jeffrey (1994),\nSanfilippo et al. (2020). Thus we have a belief-relative three-valued\nentity. Its probability is its “expected value”. For\ninstance, I’m to pick a ball from a bag. 50% of the balls are\nred. 80% of the red balls have black spots. Consider “If I pick\na red ball \\((R)\\) it will have a black spot \\((B)\\)”.\n\\(\\mathbf{p}_R (B) = 80\\)%. If \\(R \\amp B\\), the conditional gets\nsemantic value 1, if \\(R \\amp{\\sim}B\\), it gets semantic value 0. What\ndoes it get if \\({\\sim}R\\)? One way of motivating this approach is to\ntreat it as a refinement of Stalnaker’s truth conditions. Is the\nnearest \\(R\\)-world a \\(B\\)-world or not? Well, if I actually\ndon’t pick a red ball, there isn’t any difference, in\nnearness to the actual world, between the worlds in which I do; but\n80% of them are \\(B\\)-worlds. Select an \\(R\\)-world at random; then\nit’s 80% likely that it is a \\(B\\)-world. So “If \\(R,\nB\\)” gets 80% if \\({\\sim}R\\). You don’t divide the\n\\({\\sim}R\\)-worlds into those in which “If \\(R, B\\)” is\ntrue and those in which it is false. Instead the conditional gets\nvalue 80% in all of them. The expected value of “If \\(R,\nB\\)” is \nWays of handling compounds of conditionals have been proposed on the\nbasis of these semantic values. \nSome of the difficulties of the former account are avoided. Necessary\nconditionals like “If \\(A \\amp B\\), then \\(A\\)” are\ntrue—get value 1. Conjunctions of the form (if \\(A, B)\\) &\n(if \\({\\sim}A, C)\\) do not all get 0. Indeed, conditionals this form\nalways get the value \\(\\mathbf{p}_A (B).\\mathbf{p}_{{\\sim}A}(C)\\).\n(The expected value of the conjunction if \\(\\mathbf{p}(A \\amp\nB).\\mathbf{p}_{{\\sim}A}(C) + \\mathbf{p}({\\sim}A \\amp C).\\mathbf{p}_A\n(B)\\), which simplifies to \\(\\mathbf{p}_A\n(B).\\mathbf{p}_{{\\sim}A}(C)\\).) Indeed, the stronger result holds,\nthat if the two antecedents are incompatible, the value of the\nconjunction is the product of the two conditional probabilities. So\nour above example about rain, beach and cinema indeed gets a high\nvalue. \nHowever, this result for conjunctions of conditionals gives some\nimplausible results. An example due to Mark Lance (1991) concerns a\nwerewolf, such that it’s 50% likely that it is our area tonight.\nIf it is, it will kill everyone outside. “If John went out, he\nwas killed” gets 0.5. But “If John went out the back door,\nhe was killed, and if John went out the front door, he was\nkilled” gets 0.25 on this proposal, whereas it should still get\n0.5. Another example, due to Richard Bradley: I must pick one of two\nurns, only one of which contains the prize. “If I pick the left\nurn, I’ll win” gets 0.5. “If I pick the right urn,\nI’ll win” gets 0.5. On this proposal, “If I pick the\nleft urn I’ll win, and if I pick the right urn, I’ll\nwin” gets 0.25, whereas it surely deserves to get 0. \nThe flaw in this proposal is that the conditional gets the same value\nin every possible situation in which the antecedent is false. In our\nsecond example, in the “pick left and win” situation,\n“If pick right, win” deserves 0, not 0.5, despite its\nfalse antecedent, and in the “pick left and lose”\nsituation, “If pick right, win” deserves 1, not 0.5. In\nthe werewolf example, in the “goes out front door and is\nkilled” situation, “If back door, killed” deserves\n1, not 0.5, despite its false antecedent. This point is made by\nBradley (2012), who has a different approach. \nBradley’s account can be seen as a modification of\nStalnaker’s (1968) theory discussed in §4.1: consider a\npossible world in which \\(A\\) is true, and otherwise differs minimally\nfrom the actual world; “If \\(A\\), then \\(B\\)” is true just\nin case \\(B\\) is true in that possible world. First modification:\nBradley abandons the notion of similarity, or of minimal difference,\nin favour of a probability distribution over the candidate A-worlds.\nThe example of the short straws in §4.1 shows that this is a good\nidea. Second modification: conditionals are not propositions. This is\na suppositional theory. Conditionals involve two propositions which\nplay different roles, one a supposition, one a judgement within its\nscope. They cannot be represented by the set of worlds in which they\nare true. Indeed, conditionals are not ingredients of\nworlds—they are cross-world entities. Bradley proposes that the\nconditional “if \\(A, B\\)” can be represented by the set of\npairs of worlds, \\(\\langle w_i, w_j\\rangle\\) such that, if\n\\(w_i\\) is actual, and \\(w_j\\) is the “nearest”\n\\(A\\)-world, i.e. the world that would be actual if \\(A\\) were true,\nthe conditional would be true (because \\(B\\) is true at \\(w_j)\\).\nNote: “nearest” does not mean “most similar”.\nThere is no ordering of worlds for similarity. It means the world that\nwould be actual if \\(A\\) were true. Often, we do not know which world\nthat is—hence the probability distribution over candidates.\nSometimes it might even be indeterminate which world that is, but\nreflection again on the “short straws” example in\n§4.1 shows that the probabilities are still in order. \nTwo types of uncertainty, Bradley notes, are involved in assessing a\nconditional—uncertainty about the facts—about which world\nis actual; and uncertainty about what would be the case if some\nsupposition, which may be false, were true. These combine in a joint\nprobability distribution over the set of ordered pairs. \nHe accepts centering: if \\(A\\) is true, the “nearest”\n\\(A\\)-world is the actual world, and the conditional is true iff \\(B\\)\nis true. \nHere is a simple model. There are just three possible worlds: at\n\\(w_1, A\\) and \\(B\\) are true; at \\(w_2, A\\) is true and \\(B\\) is\nfalse; at \\(w_3, A\\) is false. These generate the following\npossibilities for the conditional if \\(A, B\\). \nThe probabilities of these four lines sum to 1. \nThe first two lines are the cases in which the antecedent is true, so\nin those the “nearest” world is the actual world. If on\nthe other hand \\(w_3\\) is actual, that does not tell us whether the\nnearest \\(A\\)-world is \\(w_1\\), in which case the conditional is true,\nor \\(w_2\\), in which case the conditional is false. \nThe crucial rule governing this non-propositional entity is this: the\nprobability of “if \\(A, B\\)” given \\(A\\), is the same as\nthe probability of “if \\(A, B\\)” given \\({\\sim}A\\); the\nprobability of the conditional is independent of its antecedent. This\nguarantees that \\(\\mathbf{p}\\)(if \\(A, B) = \\mathbf{p}_A (B)\\). \nThe non-propositional nature of the conditional is essential here.\nSuppose we just redescribe the four lines above as four possible\nworlds, four ways the world might be, in two of which the conditional\nis true—as Stalnaker did. And suppose we start off thinking each\nof the four is equally likely. Then we learn \\({\\sim}(A \\amp B)\\): the\nfirst line goes out. We learn nothing other than that. \\(\\mathbf{p}_A\n(B)\\) is now 0. But \\(\\mathbf{p}\\)(if \\(A, B)\\) is not 0: the third\nline remains a possibility, and we haven’t eliminated that.\n(Indeed, if probabilities change by conditionalization, the third line\nnow has probability 1/3.) In short, no two contingent propositions are\nprobabilistically independent in all probability distributions. But\nthe conditional—not a proposition—is stipulated to be\nindependent of \\(A\\). On Bradley’s theory, having learned that\n\\({\\sim}(A \\amp B), \\mathbf{p}_A (B) = \\mathbf{p}\\)(if \\(A, B) = 0\\);\nthe third line gets 0; should \\(A\\) turn out to be false, it’s\nfalse that if \\(A, B\\). \nWith this machinery, the contents of conjunctions, disjunctions and\nnegations of conditionals are given in the usual way by intersection,\nunion and complements of the contents of the component sentences. When\na sentence has two conditionals, with two antecedents, such as those\nof the form \\((A\\Rightarrow B) \\amp({\\sim}A\\Rightarrow C)\\), their\nsemantics requires not ordered pairs but ordered triples, \\(\\langle\nw_i, w_j, w_k\\rangle\\), such that, if \\(w_i\\) is actual and \\(w_j\\) is\nthe nearest \\(A\\)-world, and wk is the nearest \\({\\sim}A\\)-world, the\nconditional is true. As it is perfectly proper to give probabiity 0 to\nthe possibility: “I pick right and win, and in the nearest world\nin which I pick left, I win”, the problem for the previous\nproposal is avoided. \nThis is a remarkable achievement. Probability is probability of truth.\nValidity is necessary preservation of truth, and so Adams’s\nprobabilistic criterion of validity is demonstrable. If B is\ntrue/false at all \\(A\\)-worlds, \\(A\\Rightarrow B\\) is\nstraightforwardly true/false. Plenty of others may be\nstraightforwardly true/false, whether or not we know this. The many\nuncertain conditionals come out with the right probability—the\nconditional probability of \\(B\\) given \\(A\\). The construction is not\neasy to work with, but it is a sort of possibility proof—that\nthe embeddings objection can be met. (Bradley also has a suggested\napproach to conditionals within conditionals, but this has not been\nworked out in detail.) \nIt is not ad hoc or unheard-of to claim that some kinds of content\ncannot be represented by a set of worlds—the set of worlds in\nwhich they are true. Some examples: to capture the content of\nindexical thoughts using “I” and “now”, we\nneed the richer notion of a “centred world”—an\nordered triple of a world, and individual and a time (see Lewis 1979).\nGibbard (1990) proposes that the content of a normative judgement can\nbe represented by a set of ordered pairs \\(\\langle w, n\\rangle\\) where\nw is a world and n is a set of norms. Moss (2018) argues that the\ncontents of probability judgements are not propositions but sets of\nprobability spaces. And Bacon (2018) argues that the contents of vague\nthoughts cannot be represented by a set of worlds. (He calls them\npropositions nevertheless—that is a verbal issue—but they\nare not propositions in the sense that is relevant here.) \nI shall end this section by discussing a notorious example of Vann\nMcGee’s (1985)—a counterexample to modus ponens. Before\nReagan’s first election, Reagan was hot favourite, a second\nRepublican, Anderson, was a complete outsider, and Carter was lagging\nwell behind Reagan. Consider first \nAs these are the only two Republicans in the race, (1) is\nunassailable. Now consider  \nWe read (2) as equivalent to (1), hence also unassailable.  \nSuppose I’m close to certain (say, 90% certain) that Reagan will\nwin. Hence I am close to certain that \nBut I don’t believe  \nI’m less than 1% certain that (4). On the contrary, I believe\nthat if Reagan doesn’t win, Carter will win. As these opinions\nseem sensible, we have a prima facie counterexample to modus ponens: I\naccept (2) and (3), but reject (4). Truth conditions or not, valid\narguments obey the probability-preservation principle. I’m 100%\ncertain that (2), 90% certain that (3), but less than 1% certain that\n(4). \nHook saves modus ponens by claiming that I must accept (4). For Hook,\n(4) is equivalent to “Either Reagan will win or Anderson will\nwin”. As I’m 90% certain that Reagan will win, I must\naccept this disjunction, and hence accept (4). Hook’s reading of\n(4) is, of course, implausible. \nArrow saves modus ponens by claiming that, although (1) is certain,\n(2) is not equivalent to (1), and (2) is almost certainly false. For\nStalnaker, \nis true. To assess (5), we need to consider the nearest world in which\na Republican wins (call it \\(w)\\), and ask whether the conditional\nconsequent is true at \\(w\\). At \\(w\\), almost certainly, it is Reagan\nwho wins. We need now to consider the nearest world to \\(w\\) in which\nReagan does not win. Call it \\(w'\\). In \\(w'\\), almost certainly,\nCarter wins. \nStalnaker’s reading of (2) is implausible; intuitively, we\naccept (2) as equivalent to (1), and do not accept (5). \nSupp can save modus ponens by denying that the argument is really of\nthat form. “\\(A\\Rightarrow B\\); \\(A\\); so \\(B\\)” is\ndemonstrably valid when \\(A\\) and \\(B\\) are propositions. For\ninstance, if \\(\\mathbf{p}(A) = 90\\)% and \\(\\mathbf{p}_A (B) = 90\\)%\nthe lowest possible value for \\(\\mathbf{p}(B)\\) is 81%. The\n“consequent” of (2), “If Reagan doesn’t win,\nAnderson will win”, is not a proposition. The argument is really\nof the form “If \\(A \\amp B\\), then \\(C\\); \\(A\\); so if \\(B\\)\nthen \\(C\\)”. This argument form is invalid (Supp and Stalnaker\nagree). It is one of the many argument forms which do preserve\ncertainty, but do not preserve high probability. Take the case where\n\\(C = A\\), and we have “If \\(A \\amp B\\) then \\(A\\); \\(A\\); so if\n\\(B\\) then \\(A\\)”. The first premise is a tautology and falls\nout as redundant; and we are left with “\\(A\\); so if \\(B\\) then\n\\(A\\)”. We have already seen that this is invalid: I can think\nit very likely that Sue is lecturing right now, without thinking that\nif she was seriously injured on her way to work, she is lecturing\nright now. \nI have put this in the terms of the kind of suppositionalist who\neliminates the embedded conditional by paraphrase. If we do develop a\nsystematic account of the embedded conditional, it is surely a\ndesideratum that (1) and (2) are equivalent. In that case, modus\nponens is fine for propositions, but not when applied to a consequent\nwhich is not a proposition. \nCompounds of conditionals are a hard problem for everyone. It is\ndifficult to see why this should be so if conditionals are\npropositions with truth conditions.  \nAs well as conditional beliefs, there are conditional desires, hopes,\nfears, etc.. As well as conditional statements, there are conditional\ncommands, questions, offers, promises, bets, etc.. “If he\ncalls” plays the same role in “If he calls, what shall I\nsay?”, “If he calls, tell him I’m out” and\n“If he calls, Mary will be pleased”. Which of our theories\nextends to these other kinds of conditional?  \nOne believes that \\(B\\) to the extent that one thinks \\(B\\) more\nlikely than not \\(B\\); according to Supp, one believes that \\(B\\) if\n\\(A\\) to the extent that one believes that \\(B\\) under the supposition\nthat \\(A\\), i.e. to the extent that one thinks \\(A \\amp B\\) more\nlikely than \\(A \\amp{\\sim}B\\); and there is no proposition \\(X\\) such\nthat one must believe \\(X\\) more likely than \\({\\sim}X\\), just to the\nextent that one believes \\(A \\amp B\\) more likely than \\(A\n\\amp{\\sim}B\\). Conditional desires appear to be like conditional\nbeliefs: to desire that \\(B\\) is to prefer \\(B\\) to \\({\\sim}B\\); to\ndesire that \\(B\\) if \\(A\\) is to prefer \\(A \\amp B\\) to \\(A\n\\amp{\\sim}B\\); there is no proposition \\(X\\) such that one prefers\n\\(X\\) to \\({\\sim}X\\) just to the extent that one prefers \\(A \\amp B\\)\nto \\(A \\amp{\\sim}B\\). I have entered a competition and have a very\nsmall chance of winning. I express the desire that if I win the prize\n\\((W)\\), you tell Fred straight away \\((T)\\). I prefer \\(W \\amp T\\) to\n\\(W \\amp{\\sim}T\\). I do not necessarily prefer \\((W \\supset T)\\) to\n\\({\\sim}(W \\supset T)\\), i.e. \\(({\\sim}W\\) or \\(W \\amp T)\\) to \\(W\n\\amp{\\sim}T\\). For I also want to win the prize, and much the most\nlikely way for \\(({\\sim}W\\) or \\(W \\amp T)\\) to be true is that I\ndon’t win the prize. Nor is my conditional desire satisfied if I\ndon’t win but in the nearest possible world in which I win, you\ntell Fred straight away. \nIf I believe that \\(B\\) if \\(A\\), i.e. (according to Supp) think \\(A\n\\amp B\\) much more likely than \\(A \\amp{\\sim}B\\), this puts me in a\nposition to make a conditional commitment to \\(B\\): to assert that\n\\(B\\), conditionally upon \\(A\\). If \\(A\\) is found to be true, my\nconditional assertion has the force of an assertion of \\(B\\). If \\(A\\)\nis false, there is no proposition that I asserted. I did, however,\nexpress my conditional belief — it is not as though I said\nnothing. Suppose I say “If you press that switch, there will be\nan explosion”, and my hearer takes me to have made a conditional\nassertion of the consequent, one which will have the force of an\nassertion of the consequent if she presses the button. Provided she\ntakes me to be trustworthy and reliable, she thinks that if she\npresses the switch, the consequent is likely to be true. That is, she\nacquires a reason to think that if she presses it, there will be an\nexplosion; and hence a reason not to press it. \nConditional commands can, likewise, be construed as having the force\nof a command of the consequent, conditional upon the\nantecedent’s being true. The doctor says to the nurse in the\nemergency ward, “If the patient is still alive in the morning,\nchange the dressing”. Considered as a command to make\nHook’s conditional true, this is equivalent to “Make it\nthe case that either the patient is not alive in the morning, or you\nchange the dressing”. The nurse puts a pillow over the\npatient’s face and kills her. On the truth-functional\ninterpretation, the nurse can claim that he was carrying out the\ndoctor’s order. Extending Jackson’s account to conditional\ncommands, the doctor said “Make it the case that either the\npatient is not alive in the morning, or you change the\ndressing”, and indicated that she would still command this if\nshe knew that the patient would be alive. This doesn’t help. The\nnurse who kills the patient still carried out an order. Why should the\nnurse be concerned with what the doctor would command in a\ncounterfactual situation? \nHook will reply to the above argument about conditional commands that\nwe need to appeal to pragmatics. Typically, for any command,\nconditional or not, there are tacitly understood reasonable and\nunreasonable ways of obeying it; and killing the patient is to be\ntacitly understood as a totally unreasonable way of making the\ntruth-functional conditional true — as, indeed, would be\nchanging the dressing in such an incompetent way that you almost\nstrangle the patient in the process. The latter clearly is obeying the\ncommand, but not in the intended manner. But it is stretching\npragmatics rather far to say the same of the former. To take a less\ndramatic example, at Fred’s request, the Head of Department\nagrees to bring it about that he gives the Kant lectures if his\nappointment is extended. She then puts every effort into making sure\nthat his appointment is not extended. Is it plausible to say that this\nis doing what she was asked to do, albeit not in the intended way? \nExtending Stalnaker’s account to conditional commands, “If\nit rains, take your umbrella” becomes “In the nearest\npossible world in which it rains, take your umbrella”. Suppose I\nhave forgotten your command or alternatively am inclined to disregard\nit. However, it doesn’t rain. In the nearest world in which it\nrains, I don’t take my umbrella. On Stalnaker’s account, I\ndisobeyed you. Similarly for conditional promises: on this analysis I\ncould break my promise to go to the doctor if the pain gets worse,\neven if the pain gets better. This is wrong: conditional commands and\npromises are not requirements on my behaviour in other possible\nworlds. \nAmong conditional questions we can distinguish those in which the\naddressee is presumed to know whether the antecedent is true, and\nthose in which he is not. In the latter case, the addressee is being\nasked to suppose that the antecedent is true, and give his opinion\nabout the consequent: “If it rains, will the match be\ncancelled?”. In the former case — “If you have been\nto London, did you like it?” — he is expected to answer\nthe consequent-question if the antecedent is true. If the antecedent\nis false, the question lapses: there is no conditional belief for him\nto express. “Not applicable” as the childless might write\non a form which asks “If you have children, how many children do\nyou have?”. You are not being asked how many children you have\nin the nearest possible world in which you have children. Nor is it\npermissible to answer “17” on the grounds that “I\nhave children \\(\\supset\\) I have 17 children” is true. Nor are\nyou being asked what you would believe about the consequent if you\ncame to believe that you did have children. \nWidening our perspective to include these other conditionals tends to\nconfirm Supp’s view. Any propositional attitude can be held\ncategorically, or under a supposition. Any speech act can be performed\nunconditionally, or conditionally upon something else. Our uses of\n“if”, on the whole, seem to be better and more uniformly\nexplained without invoking conditional propositions.","contact.mail":"d.edgington@bbk.ac.uk","contact.domain":"bbk.ac.uk"}]
