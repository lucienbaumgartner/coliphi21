[{"date.published":"2005-06-30","date.changed":"2014-10-09","url":"https://plato.stanford.edu/entries/atomism-modern/","author1":"Alan Chalmers","entry":"atomism-modern","body.text":"\n\n\n\nAtomism in the form in which it first emerged in Ancient Greece was a\nmetaphysical thesis, purporting to establish claims about the ultimate\nnature of material reality by philosophical argument. Versions of\natomism developed by mechanical philosophers in the seventeenth\ncentury shared that characteristic. By contrast, the knowledge of\natoms that is now taken for granted in modern science is not\nestablished by a priori philosophical argument but by appeal\nto quite specific experimental results interpreted and guided by a\nquite specific theory, quantum mechanics. If metaphysics involves an\nattempt to give an account of the basic nature of material reality\nthen it is an issue about which science rather than philosophy has\nmost to say. A study of the path from philosophical atomism to\ncontemporary scientific atomism helps to shed light on the nature of\nphilosophy and science and the relationship between the two.\n\n\n\nFrom the nineteenth century onwards, when serious versions of\nscientific atomism first emerged, the philosophical relevance of a\nhistory of atomism becomes epistemological rather than metaphysical.\nSince atoms lie far beyond the domain of observation, should\nhypotheses concerning them form part of empirical science? There were\ncertainly philosophers and scientists of the nineteenth century who\nanswered that question in the negative. Contemporary philosophers\ndiffer over the question of whether the debate was essentially a\nscientific one or a philosophical one. Was there a case to oppose\natomism on the grounds that it was unfruitful or lacking in adequate\nexperimental support, or did such a case stem from some general\nepistemological thesis, perhaps some brand of positivism, that ruled\nout of court any attempt to explain observable phenomena by invoking\nunobservable atoms? Many contemporary philosophers see the ultimate\ntriumph of atomism as a victory for realism over positivism. Such\nclaims are historical as well as philosophical, so it is important to\nget the history straight when evaluating them. In this respect the\nphilosophical literature has yet to catch up with recent advances in\nthe history of nineteenth-century chemistry. This entry gives an\naccount of the key developments in atomism from the seventeenth\ncentury until the time, early in the twentieth century, when the\nexistence of atoms ceased to be a contentious issue. The focus is on\nthe epistemological status of the various versions, and on the\nrelationship between science and philosophy.\n\n\n\nVersions of atomism developed by seventeenth-century mechanical\nphilosophers, referred to hereafter as mechanical atomism, were\nrevivals of Ancient Greek atomism, with the important difference that\nthey were presumed to apply only to the material world, and not to the\nspiritual world of the mind, the soul, angels and so on. Mechanical\natomism was a totally general theory, insofar as it offered an account\nof the material world in general as made up of nothing other than\natoms in the void. The atoms themselves were characterised in terms of\njust a few basic properties, their shape, size and motion. Atoms were\nchangeless and ultimate, in the sense that they could not be broken\ndown into anything smaller and had no inner structure on which their\nproperties depended. The case made for mechanical atomism was largely\nprior to and independent of empirical investigation. \n\nThere were plenty of seventeenth-century versions of atomism that were\nnot mechanical. These tended to be less ambitious in their scope than\nmechanical atomism, and properties were attributed to atoms with an\neye to the explanatory role they were to play. For instance, chemicals\nwere assumed by many to have least parts, natural minima, with those\nminima possessing the capability of combining with the minima of other\nchemicals to form compounds. \n\nThe flexibility and explanatory potential of mechanical atomism was\nincreased once Newton had made it possible to include forces in the\nlist of their properties. However, there was no way of specifying\nthose forces by recourse to general philosophical argument and they\nwere remote from what could be established empirically also. Newtonian\natomism was not fruitful as far as eighteenth-century experimental\nscience is concerned. \n\nIt was only in the nineteenth century that atomism began to bear\nsignificant fruit in science, with the emergence of atomic chemistry\nand the kinetic theory of gases. The way in which and the point at\nwhich atomic speculations were substantiated or were fruitful is\ncontroversial but by the end of the century the fact that the\nproperties of chemical compounds are due to an atomic structure that\ncan be represented by a structural formulae was beyond dispute. The\nkinetic theory of gases met with impressive empirical success from\n1860 until 1885 at least. However, it also faced\ndifficulties. Further, there was the emergence and success of\nphenomenological thermodynamics, which made it possible to deal with a\nrange of thermal and chemical phenomena without resort to an\nunderlying structure of matter. Atomism was rejected by leading\nscientists and philosophers such as Wilhelm Ostwald, Pierre Duhem and\nErnst Mach up to the end of the nineteenth century and beyond. By that\ntime atomism had been extended from chemistry and the kinetic theory\nto offer explanations in stereochemistry, electro-chemistry,\nspectroscopy and so on. Any opposition from scientists that remained\nwas removed by Jean Perrin's experimental investigations of Brownian\nmotion. However, the task of explaining chemical properties in terms\nof atoms and their structure still remained as a task for twentieth\ncentury science. \n\nTwentieth-century atomism in a sense represents the achievement of the\nAncient Greek ideal insofar as it is a theory of the properties of\nmatter in general in terms of basic particles, electrons, protons and\nneutrons, characterised in terms of a few basic properties. The major\ndifference is that the nature of the particles and the laws governing\nthem were arrived at empirically rather than by a priori philosophical\nargument. \n\nSuggested Reading: Melson (1952) is a somewhat dated but\nstill interesting and useful overview of the history of atomism from a\nphilosophical point of view.Chalmers (2009) is a history of atomism\nthat focuses on the relationship between philosophical and scientific\ntheories about atoms.  Influential versions of Greek atomism were formulated by a range\nof philosophers in the seventeenth century, notably Pierre Gassendi\n(Clericuzio, 2000, 63–74) and Robert Boyle (Stewart, 1979 and\nNewman 2006). Neither the content of nor the mode of argument for\nthese various versions were identical. Here the focus is on the\nversion articulated and defended by Robert Boyle. Not only was Boyle\none of the clearest and ablest defenders of the mechanical philosophy\nbut he was also a leading pioneer of the new experimental science, so\nhis work proves to be particularly illuminating as far as\ndistinguishing philosophical and empirical aspects of atomism are\nconcerned. \n\nThe mechanical philosophy differed from the atomism of the Greeks\ninsofar as it was intended to apply to the material world only and not\nto the spiritual world. Apart from that major difference, the\nworld-views are alike. Fundamentally there is just one kind of matter\ncharacterised by a property that serves to capture the tangibility of\nmatter and distinguish it from void. Boyle chose absolute\nimpenetrability as that property. There are insensibly small portions\nof matter that, whilst they are divisible in thought or by God, are\nindivisible as far as natural processes are concerned. Boyle,\nmisleadingly drawing on another tradition that will be discussed in a\nlater section, referred to these particles as minima\nnaturalia or prima naturalia. Here they are referred to\nas atoms, a terminology only very rarely adopted by Boyle\nhimself. Each atom has an unchanging shape and size and a changeable\ndegree of motion or rest.  All properties of the material world are\nreducible to and arise as a consequence of the arrangements and\nmotions of the underlying atoms. In particular, properties possessed\nby macroscopic objects, both those detectable directly by the senses,\nsuch as colour and taste, and those involved in the interaction of\nbodies with each other, such as elasticity and degree of heat, are to\nbe explained in terms of the properties of atoms. Those properties of\natoms, their shape, size and motion, together with the impenetrability\npossessed by them all, are the primary ones in terms of which the\nproperties of the complex bodies that they compose, the secondary\nones, are to be explained. Such explanations involve the fundamental\nlaws of nature that govern the motions of atoms. \n\nNot all of the mechanical philosophers were mechanical atomists.\nDescartes provides a ready example of a mechanical philosopher who was\nnot an atomist insofar as he rejected the void and held that particles\nof matter could be broken down into smaller particles. The mechanical\nphilosophers were divided on the question of the existence of the\nvoid, some sharing the opinion of the Greek atomists that void was a\npre-requisite for motion but others, like Descartes, rejecting the\nvoid as unintelligible and hence regarding all motion as involving the\nsimultaneous displacement of closed loops of matter whether that\nmatter be continuous or particulate. Arguments at the most general\nlevel for the intelligibility of the void and its relation to the\npossibility of motion were inconclusive. In addition to the question\nof the void, there is the question of whether matter is particulate\nand whether there are indivisible particles called atoms. Once again,\ngeneral a priori philosophical arguments were hardly able to settle\nthe question. \n\nBoyle, along with his fellow mechanical philosophers, argued for his\nposition on the grounds that it was clear and intelligible compared to\nrival systems such as Aristotelianism and those developed in chemical\nand related contexts by the likes of Paracelsus. The argument operated\nat the level of the fundamental ontology of the rival philosophies.\nBoyle insisted that it is perfectly clear what is intended when shape,\nsize and degree of motion are ascribed to an impenetrable atom and\nwhen arrangements are ascribed to groups of such atoms. That much can\nsurely be granted. But Boyle went further to insist that it is\nunintelligible to ascribe to atoms properties other than these primary\nones, that is, properties other than those that atoms must necessarily\npossess by virtue of being portions of matter, such as the forms and\nqualities of the Aristotelians or the principles of the\nchemists. ‘Nor could I ever find it intelligibly made\nout’, wrote Boyle, ‘what these real qualities may be, that\nthey [the scholastics] deny to be either matter, or modes of matter,\nor immaterial substances’ (Stewart, 1979, 22). If an atom is\nsaid to possess elasticity, for example, then Boyle is saying that the\nontological status of whatever it is that is added to matter to render\nit elastic is mysterious, given that it cannot be material. This is\nnot to claim that attributing elasticity and other secondary\nproperties to gross matter is unintelligible. For such properties can\nbe rendered intelligible by regarding them as arising from the primary\nproperties and arrangements of underlying atoms. Secondary properties\ncan be ascribed to the world derivatively but not primitively. So the\nstark ontology of the mechanical philosopher is established a priori\nby appealing to a notion of intelligibility. \n\nExplaining complex properties by reducing them to more elementary ones\nwas not an enterprise unique to the mechanical philosophers. After\nall, it was a central Aristotelian thesis that the behaviour of\nmaterials was due to the proportions of the four elements in them,\nwhilst the elements themselves owed their properties to the\ninteraction of the hot and the cold and the wet and the dry, the\nfundamental active principles in nature. What a mechanical atomist\nlike Boyle needed, and attempted, to do was establish that they could\nprovide examples of successful mechanical reductions that were clear\nand intelligible. It was to this end that Boyle stressed how the\nworkings of a key could be explained in terms of nothing other than\nits shape and size relative to the lock and the workings of a clock\ncan be explained by appeal to nothing other than the properties of its\nparts. \n\nThere is a basic problem with this type of illustration of and support\nfor the mechanical philosophy. Firstly, whilst the examples may indeed\nbe examples of successful reductions, they are not strict mechanical\nreductions, and they are certainly not reductions to the mechanical\nproperties of atoms. The functioning of a key depends on its rigidity\nwhilst that of clocks and watches depend crucially on the weight of\npendulum bobs or the elasticity of springs. On a number of occasions\nBoyle himself observed that explanations that appealed to such things\nas elasticity, gravity, acidity and the like fall short of the kind of\nexplanations sought by a mechanical atomist (Chalmers, 1993).  To attempt to produce examples of reduction that conform to the\nideal of the mechanical atomists is, in effect, to attempt to bolster\nthe arguments from intelligibility with empirical arguments. The issue\nof empirical support for mechanical atomism, or any other version of\natomism, raises a fundamental problem, a problem that Maurice\nMandelbaum (1964, 88–112) has called ‘the problem of\ntransdiction’. How are we to reach knowledge of unobservable\natoms from knowledge of the bulk matter to which we have observational\nand experimental access? Mandelbaum credits Boyle with proposing a\nsolution to the problem and he is endorsed by Newman (2006). Roughly\nspeaking, the solution is that knowledge that is confirmed at the\nlevel of observation, that is found to apply to all matter whatsoever,\nand is scale invariant can be assumed to apply to atoms also. There is\nno doubt that an argument of this kind is to be found in Boyle, but it\nis highly problematic and can hardly be regarded as the solution to\nthe epistemological problems faced by a seventeenth-century\natomist. \n\nThere is something to be said for an appeal to scale invariance along\nthe lines that laws that are shown to hold at the level of observation\nin a way that is independent of size should be held to hold generally,\nand in particular, on a scale so minute that it is beyond what can be\nobserved. Boyle draws attention to the fact that the law of fall is\nobeyed by objects independently of their size and that the same appeal\nto mechanism can be applied alike to explain the workings of a large\ntown clock and a tiny wristwatch (Stewart, 1979, 143). The question is\nto what extent recognition of scale invariance of this kind can aid\nthe atomist. There is a range of reasons for concluding that it\ncannot. \n\nA key problem is that laws established at the level of observation and\nexperiment involve or imply properties other than the primary ones of\nthe mechanical atomist. As mentioned above, the mechanisms of clocks\ninvolve the elasticity of springs, the weight of pendulum bobs and the\nrigidity of gear wheels and the law of fall presupposes a tendency for\nheavy objects to fall ‘downwards’. So the mechanical\natomist cannot apply knowledge of this kind, scale invariant or\notherwise, to atoms that are presumed to lack such properties. If we\nare looking for an empirical case for the list of properties that can\nbe applied to atoms then it would appear that we need some criteria\nfor picking out that subset of properties possessed by observable\nobjects that can be applied to atoms also. Boyle offered a solution to\nthis problem. He suggested that only those properties that occur in\nall observable objects whatsoever should be transferred to\natoms. Since all observable objects have some definitive shape and\nsize then atoms do also. By contrast, whilst some observable objects\nare magnetic, many are not, and so atoms are not magnetic. This\nstrategy does not give an atomist what is needed. All observable\nobjects are elastic to some degree and are even divisible to some\ndegree and yet mechanical atoms are denied such\nproperties. Conversely, no observable macroscopic object is absolutely\nimpenetrable whereas Boyle assumes that atoms posses precisely that\nproperty. Perhaps it should not be surprising that the mechanical\natomists of the seventeenth century lacked the resources to forge\nlinks between their conjectured atoms and experimental findings. \n\nMany speculations about atoms in the seventeenth century came from a\nsource quite distinct from mechanical atomism. That source was the\ntheory of natural minima which had its roots in Aristotle and that was\ntransformed into a detailed atomic theory mainly applicable to\nchemical change. \n\nAristotle (On Generation and Corruption, Bk 1, Ch 10) clearly\nidentified what we would refer to as chemical change as a special\ncategory presenting problems peculiar to it. It differs from mere\nalteration, such as the browning of an autumn leaf, where an\nidentifiable material substratum persists, and from generation and\ncorruption, such as the transformation of an olive seed into a tree or\nthe decay of a rose into a heap of dust, where no identifiable\nmaterial substratum persists. The transformation of a mixture of\ncopper and tin into bronze, an example of what Aristotle called\ncombination, is intermediate between alteration and generation and\ncorruption. Copper and tin do not persist as such in the bronze and to\nassume so would fail to make the appropriate distinction between a\ncombination and a mixture. Nevertheless, there is some important sense\nin which the copper and tin are in the bronze because they are\nrecoverable from it.  Aristotle had put his finger on a central\nproblem in chemistry, the sense in which elements combine to form\ncompounds and yet remain in the compounds as components of\nthem. Aristotle did not use this terminology, of course, and it should\nbe recognised that he and the scholastics that followed him had few\nexamples of combination, as opposed to alteration and generation and\ncorruption, to draw on.  Alloys, which provided them with their stock\nand just about only example, are not even compounds from a modern\npoint of view. The importance of combination for Aristotelians lay in\nthe philosophical challenge it posed. \n\nMany scholastics came to understand combination as the coming together\nof the least parts of the combining substances to form least parts of\nthe compound. These least parts were referred to as natural\nminima. Substances cannot be divided indefinitely, it was claimed,\nbecause division will eventually result in natural minima which are\neither indivisible or are such that, if divided, no longer constitute\na portion of the divided substance. But the theory of natural minima\nwas developed to a stage where it involved more than that. The minima\nwere presumed to exist as parts of a substance quite independent of\nany process of division. What is more, chemical combination was\nunderstood as coming about via the combination of minima of the\ncombining substances forming minima of the compound. Talk of chemical\ncombination taking place ‘per minima’ became common. \n\nNatural minima were presumed by the scholastics to owe their being\nboth to matter and form in standard Aristotelian fashion. A key\nproblem they struggled with concerned the relation of the form\ncharacteristic of the minima of combining substances and the form of\nthe minima of the resulting compound. Natural minima of copper and tin\ncannot remain as such in the minima of bronze otherwise the properties\nof copper and tin would persist in bronze. On the other hand, the form\nof copper and tin must persist in some way to account for the fact\nthat those metals can be recovered. A common scholastic response was\nto presume that the forms of the combining minima persist in the\nminima of the resulting compound but in a way that is subservient to\nthe form of those latter minima. Elements persist in the compound\nsomewhat as individual notes persist in a chord. \n\nWhilst Aristotle and the scholastics can be given the credit for\npinpointing a fundamental problem associated with chemical change they\ncan hardly be credited with providing a definitive solution. It should\nbe recognised that adding the assumption of natural minima does not\ncontribute in any way to a solution to the problem posed by chemical\nchange. The problem of understanding how components persist in\ncompounds simply becomes transferred to the problem of how minima of\ncomponents persist in minima of compounds. So the extent to which\nacceptance of natural minima became widespread cannot be explained in\nterms of their contribution to a solution to the fundamental problem\nof chemical change. There were a number of motivations for assuming\nminima, all having at least their germs in Aristotle. One idea was\nthat a portion of a substance can resist the corrupting influence of\nthe surrounding medium only if there is a sufficient amount of\nit. Another stemmed from the common recognition that substances must\ncome into contact if they are to combine. The particulate nature of\nsubstances facilitates such contact, as Aristotle hinted (On\nGeneration and Corruption, 1, 10, 328a, 34). A third motivation\nconcerned the logical problems, dating back to Zeno, that were\nunderstood to flow from assuming infinite divisibility. \n\nRecognising the need to avoid problems perceived to be associated with\ninfinite divisibility was a point shared by proponents of natural\nminima and mechanical atomists. But this one point of contact must not\nblind us to the crucial differences between the two traditions.\nMechanical atoms were proposed as components of matter in\ngeneral. They were unchangeable and possessed a minimum of properties,\nshape, size and a degree of motion or rest together with the\nimpenetrability of their component matter. The motivation for\nascribing just those properties to atoms was to provide an\nintelligible account of being and change in general. By contrast,\nnatural minima possess properties characteristic of the substances of\nwhich they are the minima. The minima are not unchangeable because\nthey are transformed into more complicated minima via chemical\ncombination. The minima were not basic building blocks for the\nscholastics that developed this theory because their properties needed\nto be traced back to their composition from the four Aristotelian\nelements. Finally, the minima theory was developed as an attempt to\naccommodate chemical change. It was not intended as a theory of\neverything in the way that mechanical atomism was.  Atomic theories became common in the seventeenth century. The\nemerging emphasis on experiment led the proponents of those theories\nto become less concerned with philosophical systems and more concerned\nwith the explanation of specific phenomena such as condensation and\nrarefaction, evaporation, the strength of materials and chemical\nchange. There was an increasing tendency for atomists to borrow in an\nopportunist way from both the mechanical and natural minima traditions\nas well as from the alchemical tradition which employed atomistic\ntheories of its own as Newman (1991, 143–190 and 1994,\n92–114) has documented. Thus an Aristotelian proponent of the\nnatural minima tradition, Daniel Sennert, whose main interest was in\nchemistry in medical contexts, drew on the work of the alchemists as\nwell as that of the minima theorists, employed minima in physical as\nwell as chemical contexts, and insisted that his atomism had much in\ncommon with that of Democritus (Clericuzio, 2000, 23–29 and\nMelsen, 1952, 81–89). Boyle referred to his mechanical atoms as\nnatural minima and his first account of atomism involved attributing\nto an atom properties distinctive of the substance it was a least part\nof (Newman, 2006, 162ff, Clericuzio, 2000, 166ff) and in fact borrowed\nheavily from Sennert (Newman, 1996). In subsequent writings he made it\nclear that in his view least parts of substances are composed of more\nelementary particles possessing only shape, size and a degree of\nmotion. Whether, according to Boyle, properties other than primary\nmechanical ones emerge at the level of least parts or at the\nmacroscopic level is an issue on which contemporary commentators\ndisagree (Chalmers, 2009, 155–161), Chalmers, 2010, 8–9,\nClericuzio, 2000, 103–148, Newman, 2006, 179–189). The\ntheories of a number of atomists, such as Sebastien Basso, Etienne de\nClave and Thomas Digges, were an eclectic mixture of ingredients drawn\nfrom mechanical atomism, minima theory and alchemy. (Clericuzio, 2000,\nMelsen, 1952, Newman, 2006) \n\nThe seventeenth-century certainly witnessed the growth of a range of\nexperimental sciences, an occurrence of considerable epistemological\nsignificance. However, the experimental basis for seventeenth-century\natomism remained extremely weak and none of the various versions of it\ncan be said to have productively informed experiment or to have been\nconfirmed by it, a claim that has been documented by Meinel (1988) in\nhis survey of the experimental basis for atomism in the seventeenth\ncentury and is argued in detail in Chalmers (2009). Appeal to atoms to\nexplain the gradual wearing away of a stone, the evaporation of a\nliquid, the passage of a solution through a filter paper folded\nmultiple times and so on dated back at least as far as Lucretius and\nwere hardly sufficiently powerful to convince anyone disinclined to\naccept the reality of atoms. Experimental knowledge of the combination\nand recovery of reacting chemicals, which certainly experienced marked\ngrowth in the course of the seventeenth century, did not of itself\nwarrant the assumption that atoms were involved. Evidence revealed by\nthe microscope was new to the seventeenth century, of course, and did\nreveal a microscopic world previously unknown. But the properties of\nmicroscopic systems were not qualitatively distinct from macroscopic\nones in a way that aided the demonstration of the emergence of the\nproperties of observable systems, whether microscopic or macroscopic,\nfrom the properties of atoms. \n\nSuggested Readings: Clericuzio (2000) is a detailed survey of\nseventeenth-century atomic theories. Stewart (1979) is a collection of\nBoyle's philosophical papers related to his mechanical\natomism. Boyle's atomism is detailed in Newman(2006) and Chalmers\n(2009). Debates concerning the nature and status of it are in\nChalmers(1993), Chalmers (2002), Chalmers (2009), Chalmers (2010),\nNewman (2006), Newman (2010), Anstey (2002) and Pyle (2002). \n\nThe key sources of Newton's stance on atomism in his published work\nare Querie 31 of his Opticks, and a short piece on acids\n(Cohen, 1958, 257–8). Atomistic views also make their appearance in\nthe Principia, where Newton claimed “the least parts of\nbodies to be—all extended, and hard and impenetrable, and\nmoveable, and endowed with their proper inertia” (Cajori, 1962,\n399). If we temporarily set aside Newton's introduction of his concept\nof force, then Newton's basic matter theory can be seen as a version\nof mechanical atomism improved by drawing on the mechanics of the\nPrincipia. Whereas mechanical atomists prior to Newton had\nbeen unclear about the nature and status of the laws governing atoms,\nNewton was able to presume that his precisely formulated three laws of\nmotion, shown to apply in a wide variety of astronomical and\nterrestrial settings, applied to atoms also. Those laws provided the\nlaw of inertia governing motion of atoms in between collisions and\nlaws of impact governing collisions. Newton also added his precise and\ntechnical notion of inertia or mass, another fruit of his new\nmechanics, to the list of primary properties of atoms. These moves\ncertainly helped to give precise content to the fundamental tenets of\nmechanical atomism that they had previously lacked. \n\nThere is no doubt that Newton shared the assumption of the Ancient and\nmechanical atomists that there is just one kind of homogeneous matter\nof which all atoms are composed. This is clear from the way in which\nNewton explained differing densities of observable matter in terms of\nthe amount of space intervening between the component atoms.  Newton\nargued, for instance that the ratio of space to volume occupied by\natoms was seventeen times greater in water than in gold on the grounds\nthat gold is seventeen times more dense. The fact that thin gold films\ntransmit light convinced Newton that the atoms of gold already\ncontains enough space to permit the transmission of light\nparticles. The preponderance of space between the atoms of matter,\nhowever bulky or solid they might appear at the observational and\nexperimental level, became a characteristic feature of Newtonian\natomism, as Thackray (1968) has stressed. \n\nThe picture of Newton's atomism as an elaboration and improvement of\nmechanical atomism becomes untenable once the role of force in\nNewton's theorising is taken into account. There is no doubting that\nNewton's introduction of forces, especially the gravitational force,\ninto his mechanics was a major scientific success borne out by\nobservational and experimental evidence. Newton famously speculated in\nthe Preface to the Principia (Cajori, 1958, xviii), that if\nall forces operative in nature, including those acting between the\nsmallest, unobservable, particles, were known, then the whole course\nof nature could be encompassed within his mechanics.  However, the\nfulfilment of such a dream would not constitute the fruition of the\nmechanical philosophy because of the ontological problems posed by the\nconcept of force. \n\nNewton explicitly rejected the idea that gravitation, or any other\nforce, be essential to matter. But the major point of mechanical\natomism had been to admit as properties of atoms only those that they\nmust, essentially, have as pieces of matter. It was in this way that\nthey had endeavoured to avoid introducing Aristotelian forms and\nqualities, which they regarded as incomprehensible from an ontological\npoint of view. The introduction of forces as irreducible entities flew\nin the face of the major aim of the mechanical philosophers for\nclarity and intelligibility on ontological matters. Newton was unable\nto fashion an unambiguous view on the ontological status of gravity, a\nforce manifest at the level of observation and experiment, let alone\nforces operative at the atomic level. It is true that, in the case of\ngravity, Newton had a plausible pragmatic response. He argued that,\nwhatever the underlying status of the force of gravity might be, he\nhad given a precise specification of that force with his law of\ngravitation and had employed the force to explain a range of phenomena\nat the astronomical and terrestrial level, explanations that had been\nconfirmed by observation and experiment. But not even a pragmatic\njustification such as this could be offered for forces at the atomic\nlevel. \n\nMechanical atomism had faced the problem of how to introduce the\nappropriate kinds of activity into the world relying solely on the\nshapes, sizes and motions of atoms. They had struggled unsuccessfully\nto explain elasticity and gravity along such lines and chemistry posed\nproblems of its own. Newtonian forces could readily be deployed to\nremove these problems. Newton presumed that forces of characteristic\nstrengths (affinities) operated between the least parts of chemicals.\nWhat displaces what in a chemical reaction is to be explained simply\nin terms of the relative strengths of the affinities\ninvolved. Elasticity was attributed to attractive and repulsive forces\nacting between particles of an elastic substance and so on. \n\nNewton developed theories of optics and chemistry that were atomistic\nin the weak sense that they sought to explain optical and chemical\nproperties by invoking interacting particles lying beyond the range of\nobservation. However, the particles were not ultimate.  Newton's\nposition on the least parts of chemical substances was similar to that\nof Boyle and other mechanical philosophers. They were regarded as made\nup of a hierarchy of yet smaller particles. So long as the smallest\nparticles were held together by forces, the problem of the ontological\nstatus of the forces remained. The least parts of chemicals in\nNewton's theory were akin to natural minima with the added detail that\ntheir action was due to attractive and repulsive forces. As far as the\nparticles of light in Newton's optics are concerned, whether they were\nultimate or not, they too acted by way of forces and also suffered\nfits of easy reflection and easy refraction, the latter being used to\nexplain interference phenomena such as Newton’s rings and why a\nray incident on a boundary between two refracting media can be\npartially reflected and partially transmitted. \n\nHowever attractive the reduction of the material world to particles\ninteracting by way of forces may have appeared, it must be recognised\nthat there was scant empirical support for the idea. This point is\nclearest in the context of chemistry. The affinities presumed to act\nbetween chemical ‘atoms’ were postulated solely on the\nbasis of the observed chemical behaviour of bulk substances\nmanipulated in the laboratory. The assumption that the chemical\nbehaviour of bulk substances were due to combining atoms added nothing\nthat made a difference to what was testable by experiment. Observed\nproperties of chemical substances were simply projected onto\natoms. Newtonians had not formulated a chemical atomic theory that\ncould be used as a basis for the prediction of chemical phenomena at\nthe experimental level.  Newton's optics was in an analogous\nsituation. However, here it can be said that that optical theory was\nable to accommodate a range of optical phenomena in a coherent way\nthat rendered it superior to any rival. The result was the widespread\nacceptance of the theory in the eighteenth century. \n\nWhen Newton took for granted that there is just one kind of universal\nmatter and refused to include gravity as a primary property of matter\nbecause of worries about the ontological status of force, he was\nplaying the role of a natural philosopher in the tradition of the\nmechanical philosophy. When he offered a pragmatic justification of\nhis specification of the force of gravity independently of how that\nforce might be explained he was acting as one who sought to develop an\nexperimentally confirmed science independent of the kinds of ultimate\nexplanation sought by the mechanical philosophers. His atomism\ncontained elements of both of these tendencies. A sympathiser could\nsay that whatever the philosophical problems posed by forces,\nNewtonian atomism was a speculation that at least held the promise of\nexplaining material phenomena in a way that mechanical atomism did not\nand so experimental support in the future was a possibility. A critic,\non the other hand, could argue that, from the philosophical\nperspective, the introduction of force undermined the case for the\nclarity and intelligibility of mechanical atomism on which its\noriginators had based their case. From a scientific point of view,\nthere was no significant empirical support for atomism and it was\nunable to offer useful guidance to the experimental sciences that grew\nand prospered in the seventeenth century and beyond. \n\nForce was to prove a productive addition to experimental science in no\nuncertain manner in the eighteenth century. Force laws in addition to\nthe law of gravitation, involving elasticity, surface tension,\nelectric and magnetic attractions and so on were experimentally\nidentified and put to productive use. In the domain of science,\nscruples about the ontological status of forces were forgotten and\nthis attitude spread to philosophy. Eighteenth-century updates of\nmechanical atomism typically included gravity and other forces amongst\nthe primary properties of atoms. Acceptance of force as an ontological\nprimitive is evident in an extreme form in the 1763 reformulation of\nNewtonian atomism by R. Boscovich (1966). In his philosophy of matter\natoms became mere points (albeit possessing mass) acting as centres of\nforce, the forces varying with the distance from the centre and\noscillating between repulsive and attractive several times before\nbecoming the inverse square law of gravitation at sensible\ndistances. The various short-range attractive and repulsive forces\nwere appealed to as explanations of the cohesion of atoms in bulk\nmaterials, chemical combination and also elasticity. Short-range\nrepulsive forces varying with distance enabled Boscovich to remove the\ninstantaneous rebounds of atoms that had been identified as an\nincoherency in Newton's own atomism stemming from their absolute\nhardness and inelasticity. \n\nWhile most atomists were able to rid themselves of scruples about\naccepting forces as ontologically primitive, the issue of the empirical\nfoundation for the various unobservable forces hypothesised remained.\nThe best arguments that could be mounted were hypothetical-deductive.\nForces postulated at the atomic level were credited with some empirical\nsupport if they could serve to explain observable phenomena. The form\nof such arguments, as well as their inconclusiveness, can be\nillustrated by Newton's demonstration in the Principia\n(Bk. 2, Prop. 23) that a gas consisting of a static array of atoms\nrepelling each other with a force inversely proportional to their\nseparation would obey Boyle's law. The fact that some of these\ntheories did indeed reproduce the experimentally established facts was\ncertainly a point in their favour, but hardly served to establish them.\nWhewell brought the point home by identifying competing theories of\ncapillarity, due to Poisson and Laplace, that were equally able to\nreproduce the phenomena but which were based on incompatible atomic\nforce laws, as Gardner (1979, 20) has pointed out. \n\nThe problem besetting those seeking experimental support for atomic\ntheories is most evident in chemistry. Although many eighteenth-century\nchemists espoused versions of Newtonian chemistry their chemical\npractice owed nothing to it (Thackray, 1970). As philosophers they\npayed lip-service to atomism but as experimental chemists they worked\nindependently of it. As early as 1718 Ettienne Geoffroy spelt out how\nthe blossoming experimental science of chemical combination, involving\nextensive use of mineral acids to form an array of salts, could be\nunderstood in terms of what substances combined with what and could be\nrecovered from what and to what degree. His table of the degrees of\n‘rapport’ of chemical substances for each other summarised\nexperimental data acquired by manipulating substances in the laboratory\nand became an efficient device for ordering chemical experience and for\nguiding the search for novel reactions. Klein (1995) has highlighted\nthis aspect of Geoffroy's work and how his 1718 paper in effect\nshows how a large section of the experimental chemistry of the time\ncould be construed as a practical tradition divorced from a speculative\nmetaphysics, atomistic or otherwise. Eighteenth-century tables of\naffinity, modelled on Geoffroy's version, became increasingly\ndetailed as the century proceeded. Many of the chemists who employed\nthem interpreted the affinities featuring in them as representing\nattractions between chemical atoms, but such an assumption added\nnothing that could not be fully represented in terms of combinations of\nchemical substances in the laboratory. \n\nThe fact that Newtonian atomism offered little that was of practical\nutility to chemistry became increasingly recognised by chemists as the\neighteenth century progressed. The culmination of the experimental\nprogram involving the investigation of the combination and analysis of\nchemical substances was, of course, Lavoisier's system involving\nchemical elements. But whatever sympathy Lavoisier may have had for\nNewtonian atomism of the kind championed by Laplace, he was at pains to\ndistance his new chemistry from it. Substances provisionally classified\nas elements were those that could not be broken down into something\nsimpler in the laboratory. Progress in eighteenth-century chemistry led\naway from rather than towards atomism. It was not until Dalton that the\nsituation changed early in the nineteenth century. \n\nThe assessment that eighteenth-century atomism was ill-confirmed by\nexperiment and failed to give useful guidance to experimentalists is a\njudgement that is fairly insensitive to what theory of confirmation one\nadopts or what one might require of an adequate scientific explanation.\nThis situation was transformed by the emergence of Daltonian atomism, a\nstrong candidate for the first atomic theory that had a productive link\nwith experiment. \n\nSuggested Reading: Thackray (1970) is an authoritative and\ndetailed account of Newton's atomism and its development in the\neighteenth century. The relation between Newton's atomism and his\nmechanics is discussed in Chalmers (2009, Chapter 7). \n\nThe status of atomism underwent a transformation when John Dalton\nformulated his version of chemical atomism early in the nineteenth\ncentury. His atomic theory had implications for the way chemicals\ncombine by weight and, for the first time, it would seem, a direct\npath was uncovered that took scientists from experimental measurement\nto a property of atoms, namely, their relative weight. An assessment\nof the fruitfulness and epistemological status of Dalton's atomism can\neasily be distorted if we are uncritically influenced by the\nrecognition that Dalton's basic assumptions are in fact correct from a\nmodern point of view. This section will involve a summary of the basic\nfeatures of Dalton's chemistry as he published it in 1808 together\nwith the way in which its content can be usefully expressed using\nchemical formulae introduced by Berzelius five years later. The\nfollowing sections will explore, first the issue of the\nepistemological status of this early version and then the nature and\nstatus of subsequent elaborations of chemical atomism during the first\nhalf century of its life. These latter issues very much involve\ndevelopments in organic chemistry, issues that have been highlighted\nby historians of chemistry only in the last few decades. \n\nDalton was able to take for granted assumptions that had become\ncentral to chemistry since the work of Lavoisier. Chemical compounds\nwere understood as arising through the combination of chemical\nelements, substances that cannot be broken down into something simpler\nby chemical means. The weight of each element was understood to be\npreserved in chemical reactions. By the time Dalton (1808) made his\nfirst contributions to chemistry the law of constant composition of\ncompounds could be added to this. Proust had done much to substantiate\nexperimentally the claim that the relative weights of elements making\nup a chemical compound remain constant independent of its mode of\npreparation, its temperature and its state. \n\nThe key assumption of Dalton's chemical atomism is that chemical\nelements are composed of ‘ultimate particles’ or\natoms. The least part of a chemical compound is assumed to be made up\nof characteristic combinations of atoms of the component elements.\nDalton called these ‘compound atoms’. According to Dalton,\nall atoms of a given substance whether simple or compound, are alike\nin shape, weight and any other particular. This much already entails\nthe law of constant proportions. Although Dalton himself resisted the\nmove, Berzelius was able to show how Dalton's theory can be\nconveniently portrayed by representing the composition of compounds in\nterms of elements by chemical formulae in the way that has since\nbecome commonplace. Hereafter this device is employed using modern\nconventions rather than any of the various ones used by Berzelius and\nhis contemporaries, \n\nAs Dalton stressed, once the chemical atomic theory is accepted, the\npromise is opened up of determining the relative weights of atoms by\nmeasuring the relative weights of elements in compounds. If an atom of\nelement A combines with an atom of element B to form\na compound atom of compound AB, then the relative weights of\nA and B in the compound as measured in the\nlaboratory will be equal to the relative weights of atoms of\nA and B. However, there is a serious\nunder-determination of relative atomic weights by measurements of\ncombining weights in the laboratory. If the compound atom in our\nexample were A2B rather than AB\nthen the relative atomic weight of B would be twice what it\nwould be if the formula were AB. Dalton himself attempted to\nresolve this problem with a simplicity assumption. Formulae were\nalways to take the simplest form compatible with the empirical\ndata. If there was only one compound of A and B\nknown then it was assumed to be AB, whilst if there were two\nthen a more complicated compound, A2B or\nAB2 became necessary. As is illustrated by the\nlatter example, as well as the problem of the truth of the simplicity\nassumption there was the problem of its ambiguity. Chemical atomists\nwere to struggle for several decades with various solutions to the\nproblem of arriving at definitive formulae and relative atomic\nweights, as we shall see. \n\nThis deficiency of Dalton's atomism aside, links were forged between\nit and experimentally determined combining weights that went beyond\nthe law of constant proportions to include the laws of multiple and\nreciprocal proportions. If two elements combine together in more than\none way to form compounds, as is the case with the various oxides of\nnitrogen and carbon, for example, then Daltonian atomism predicts that\nthe weights of one of the elements in each compound, relative to a\nfixed weight of the second, will bear simple integral ratios to each\nother. This is the law of multiple proportions, predicted by Dalton\nand soon confirmed by a range of experiments. Daltonian atomism also\npredicts that if the weights of elements A and B\nthat combine with a fixed weight of element C are x\nand y respectively, then if A and B combine\nto form a compound then the relative weights of A and\nB in the compound will be in the ration x:y\nor some simple multiple of it. This law was also confirmed by\nexperiment. \n\nThere is a further component that needs to be added to the content of\nearly atomic chemistry, although it did not originate with Dalton, who\nin fact did not fully embrace it. Gay Lussac discovered experimentally\nthat when gases combine chemically they do so in volumes that bear an\nintegral ratio to each other and to the volume of the resulting\ncompound if gaseous, provided that all volumes are estimated at the\nsame temperature and pressure. For instance, one volume of oxygen\ncombines with two volumes of hydrogen to form two volumes of steam. If\none accepts atomism, this implies that there are some whole-number\nratios between the numbers per unit volume of atoms of various gaseous\nelements at the same temperature. Following suggestions made by\nAvogadro and Ampere early in the second decade of the nineteenth\ncentury, many chemists assumed that equal volumes of gases contain\nequal numbers of ‘atoms’, with the important implication\nthat relative weights of atoms could be established by comparing\nvapour densities. As Dalton clearly saw, this can only be maintained\nat the expense of admitting that ‘atoms’ can be split. The\nmeasured volumes involved in the formation of water, for example,\nentail that, if equal volumes contain equal numbers of atoms then a\nwater ‘atom’ must contain half of an oxygen\n‘atom’. The resolution of these problems required a clear\ndistinction between atoms of a chemical substance and molecules of a\ngas, the grounds for which became available only later in the century.\nThis problem aside, the empirical fact that gases combine in volumes\nthat are in simple ratios to each other became a central component of\nchemistry, although it should be noted that at the time Gay Lussac\nproposed his law, only a small number of gases were known to chemists.\nThe situation was to change with the development of organic chemistry\nin the next few decades. \n\nIf Dalton's atomism was viewed as a contribution to natural philosophy\nin the tradition of mechanical atomism, designed to give a simple and\nintelligible account of the ultimate nature of the material world,\nthen it did not have a lot going for it. It marked a decisive break\nwith the idea that there is just one kind of matter, an assumption\nthat extended from Democritus to Newton and beyond. If Dalton's atoms\nwere regarded as ontologically basic, then there needed to be as many\nkinds of matter as there are chemical elements.  Further, atoms of\neach element needed to posses a range of characteristic properties to\naccount for chemical combination as well as physical aggregation and\nother physical properties. As a philosophical theory of the ultimate\nnature of material reality, Daltonian atomism was not a serious\ncontender and was not treated as such. A more significant issue is the\nstatus of Daltonian chemistry as an experimental science. To what\nextent was Daltonian chemistry borne out by and able to fruitfully\nguide experiment? \n\nA basic issue concerning the empirical statues of Daltonian atomism\nwas already pinpointed in an early exchange between Dalton (1814) and\nBerzelius (1815). Dalton was keen to present himself as the Newton of\nchemistry. In his view, just as Newton had explained Kepler’s\nlaws with his new mechanics, so he, Dalton, had explained the laws of\nproportion with his atomism. Without atomism the joint truth of the\nthree laws of proportion is a mystery. Berzelius questioned the\nexperimental grounds for assuming anything stronger than the laws of\nproportion, since, he argued, all of the chemistry could be\naccommodated by the latter. That is, nothing testable by the chemistry\nof the time follows from Dalton's atomic theory that does not follow\nfrom the laws of proportion plus the experimental law of combining\nvolumes for gases. \n\nBerzelius (1814) expressed his version of Daltonian chemistry using\nformulae. Dalton had pictured atoms as spheres and compound atoms as\ncharacteristic arrangements of spheres. Berzelius claimed that the two\nmethods were equivalent but that his method was superior because it\nwas less hypothetical. It is clear that Berzelius's version cannot be\nboth less speculative and equivalent to Dalton's theory at the same\ntime. But it is also clear what Berzelius intended. His point was that\nthe testable empirical content of the two theories were equivalent as\nfar as the chemistry of the time was concerned, but that his version\nwas less speculative because it did not require a commitment to atoms.\nThe symbols in Berzelian formulae can be interpreted as representing\ncombing weights or volumes without a commitment to atoms. A Daltonian\natomist will typically take the hydrogen atom as a standard of weight\nand the atomic weight of any other element will represent the weight\nof an atom of that element relative to the weight of the hydrogen\natom. On such an interpretation the formula H2O represents\ntwo atoms of hydrogen combined with one of oxygen. But, more in\nkeeping with the weight determinations that are carried out in the\nlaboratory, it is possible to interpret atomic weights and formulae in\na more empirical way. Any sample of hydrogen whatever can be taken as\nthe standard, and the atomic weight of a second element will be\ndetermined by the weight of that element which combines with it. The\nformula H2O then represents the fact that water contains\ntwo atomic weights of hydrogen for every one of oxygen. Of course,\ndetermining atomic weights and formulae requires some decision to\nsolve the under-determination problem, but that is the case whether\none commits to atoms or not. \n\nBerzelius was right to point out that as far as being supported by\nand serving to guide the chemistry of the time was concerned, his\nformulation using formulae served as well as Dalton's formulation\nwithout committing to atomism. What follows from this will depend on\none's stand on confirmation and explanation in science. A\nstrong-minded empiricist might conclude from Berzelius’s\nobservation that Dalton's atomism had no place in the chemistry\nof the time. Others might agree with Dalton that the mere fact that\nDalton's theory could explain the laws of proportion in a way\nthat no available rival theory could constituted a legitimate argument\nfor it in spite of the lack of evidence independent of combining\nweights and volumes. Atomism could be defended on the grounds that\nattempts to articulate and improve it might well fruitfully guide\nexperiment in the future and lead to evidence for it that went beyond\ncombining weights and volumes. But such articulations would clearly\nrequire properties to be ascribed to atoms in addition to their\nweight. \n\nBerzelius himself took this latter option. He developed an atomic\ntheory that attributed the combination of atoms in compounds to\nelectrostatic attractions. He developed a ‘dualist’ theory\nto bring order to compounds involving several types of molecules. For\ninstance, he represented copper sulphate as (CuO + SO3).\nHere electropositive copper combines with electronegative oxygen but in\na way that leaves the combination slightly electropositive, whereas\nelectropositive sulphur combines with oxygen in a way that leaves the\ncombination slightly electronegative. The residual charges of the\n‘radicals’ as they became known could then account for\ntheir combination to form copper sulphate. \n\nBerzelius's conjectures about the electrical nature of\nchemical combination owed their plausibility to the phenomenon of\nelectrolysis, and especially the laws governing it discovered by\nFaraday, which linked the weights of chemicals deposited in\nelectrolysis to chemical equivalents. But evidence for the details of\nhis atomistic theory independent of the evidence for the experimental\nlaws that the theory was designed to support was still lacking.\nContemporaries of Berzelius proposed other atomic theories to explain\nelectrical properties of matter. Ampère proposed electrical\ncurrents in atoms to explain magnetism and Poisson showed how\nelectrostatic induction could be explained by assuming atomic dipoles.\nIn each of these cases some new hypothesis was added to atomism for\nwhich there was no evidence independent of the phenomenon explained.\nNevertheless, the fact that there existed this range of possible\nexplanations all assuming the existence of atoms can be seen as\nconstituting evidence for atoms by those favouring inferences to the\nbest explanation. \n\nIn the early decades of the life of Dalton's atomic chemistry various\nattempts were made to solve the problem of the under-determination of\natomic weights and formulae. We have already mentioned the appeal to\nthe equal numbers hypothesis and vapour densities. The fact that\nchemists of the time did not have the resources to make this solution\nwork has been explored in detail by Brooke (1981) and Fisher (1982). A\nsecond method was to employ an empirical rule, proposed by Dulong and\nPetit, according to which the product of the specific heats and the\natomic weights of solids is a constant. The problem with this at the\ntime was, firstly, that some atomic weights needed to be known\nindependently to establish the truth of the rule, and, secondly, there\nwere known counter-instances. A third method for determining atomic\nweights employed Mitscherlich’s proposal (Rocke, 1984, 154–6)\nthat substances with similar formulae should have similar crystal\nstructure. This method had limited application and, again, there were\ncounter-examples. \n\nOur considerations so far of the status of Daltonian atomism have not\nyet taken account of the area in which chemistry was to be making\nspectacular progress by the middle of the nineteenth century, namely,\norganic chemistry. This is the topic of the next section. \n\nThe period from the third to the sixth decades of the nineteenth\ncentury witnessed spectacular advances in the area of organic\nchemistry and it is uncontroversial to observe that these advances\nwere facilitated by the use of chemical formulae. Inorganic chemistry\ndiffers from organic chemistry insofar as the former involves simple\narrangements of a large number of elements whereas organic chemistry\ninvolves complicated arrangements of just a few elements, mainly\ncarbon, hydrogen, oxygen and to a lesser extent, nitrogen. \n\nIt was soon to become apparent that the specification of the\nproportions of the elements in an organic compound was not sufficient\nto identify it or to give an adequate reflection of its properties.\nProgress became possible when the arrangements of the symbols\nrepresenting the elements in formulae were deployed to reflect\nchemical properties. The historical details of the various ways in\nwhich chemical properties were represented by arrangements of symbols\nare complex. (For details see Rocke (1984) and Klein (2003)). Here we\nabstract from those details to illustrate the kinds of moves that were\nmade. \n\nThe simplest formula representing the composition of acetic acid is\nCH2O using modern atomic weights. This formula cannot\naccommodate the fact that, in the laboratory, the hydrogen in acetic\nacid can be replaced by chlorine in four distinct ways yielding four\ndistinct chemical compounds. Three of those compounds are acids that\nhave properties very similar to acetic acid, and in which the relative\nweights of chlorine vary as 1:2:3. The fourth compound has the\nproperties of a salt rather than an acid. These experimental facts can\nbe captured in a formula by doubling the numbers and rearranging the\nsymbols, so that we have C2H4O2,\nrearranged to read C2H3O2H. The\nexperimental facts can now readily be understood in terms of the\nsubstitution of one or more of the hydrogens by chlorine, with the\nthree chloro-acetic acids represented as\nC2H2ClO2,\nC2HCl2O2H and\nC2Cl3O2H and the salt, acetyl\nchloride, as C2H3O2Cl. Such formulae\ncame to be known as ‘rational formulae’ as distinct from\nthe ‘empirical formula’ CH2O. Representing the\nreplacement of one element in a compound by another in the laboratory\nby the replacement of one symbol by another in a chemical formula\nbecame a standard and productive device that was to eventually yield\nthe concept of valency in the 1860s. (Oxygen has a valency of two\nbecause two hydrogens need to be substituted for each oxygen.) \n\nOther devices employed to fashion rational formulae involved the\nnotion of a radical, a grouping of elements that persisted through a\nrange of chemical changes so that they play a role in organic\nchemistry akin to that of elements in inorganic chemistry. Series of\ncompounds could be understood in terms of additions, for example to\nthe methyl radical, CH3, or to the ethyl radical,\nC2H5, and so on. ‘Homologous series’\nof compounds could be formed by repeatedly adding CH2 to\nthe formulae for such radicals so that the properties, and indeed the\nexistence, of complex compounds could be predicted by analogy with\nsimpler ones. Another productive move involved the increasing\nrecognition that the action of acids needed to be understood in terms\nof the replacement of hydrogen. Polybasic acids were recognised as\nproducing two or more series of salts depending on whether one, two or\nmore hydrogens are replaced. Yet another important move involved the\ndemand that rational formulae capture certain asymmetric compounds,\nsuch as methyl ethyl ether, CH3C2H5O,\nas distinct from methyl ether, (CH3)2O, and\nethyl ether, (C2H5)2O. By 1860, the\nidea of tetravalent carbon atoms that could combine together in chains\nwas added. By that stage, the demand that rational formulae reflect a\nwide range of chemical properties had resulted in a set of formulae\nthat was more or less unique. The under-determination problem that had\nblocked the way to the establishment of unique formulae and atomic\nweights had been solved by chemical means. \n\nThe previous section was deliberately written in a way that does not\ninvolve a commitment to atomism. It is possible to understand the\nproject of adapting rational formulae so that they adequately reflect\nchemical properties by interpreting the symbols as representing\ncombining weights or volumes as Berzelius had already observed in his\nearly debates with Dalton. Philosophers and historians of science have\nresponded in a variety of ways to this situation. \n\nPierre Duhem (2002), in his classic analysis of the logic of\nnineteenth-century chemistry at the end of that century, construed it\nas being independent of, and offering no support for, atomism. Paul\nNeedham (2004a, 2004b) has recently supported his case. Klein (2003,\n18–20) notes that many of the pioneers of the developments in organic\nchemistry referred to combining volumes or portions or proportions\nrather than atoms. She attributes the productivity of the use of\nformulae to the fact that they ‘conveyed a building-block image\nof chemical proportions without simultaneously requiring an investment\nin atomic theories, together with the simplicity of their\nmaneuverability on paper’ (2003, 35). \n\nA number of chemists involved in the early advances of organic\nchemistry who did adopt atomism expressed their ontological commitment\nto ‘chemical atoms’. In doing so they distinguished their\ntheories from those brands of physical atomism that were in the\ntradition of mechanical or Newtonian atomism and which sought to\nexplain phenomena in general, and chemistry in particular, by\nreference to a few physical properties of atoms. Chemical atoms had\nmore in common with natural minima insofar as they were presupposed to\nhave properties characteristic of the substances they were atoms of.\nChemical atomism lent itself to the idea that it was developments in\nchemistry that were to indicate which properties were to be attributed\nto chemical atoms, as exemplified in the path that led to the property\n‘valency’. Alan Rocke (1984, 10–15 and 2013) interprets the use of\nformulae in organic chemistry as involving a chemical atomism that is\nweaker than physical atomism but stronger than a commitment only to\nlaws of proportion. \n\nDalton's atomism had given a line on just one property of atoms, their\nrelative weight. But it is quite clear that they needed far richer\nproperties to play there presumed role in chemistry. It was to be\ndevelopments in chemistry, and later physics, that were to give\nfurther clues about what properties to ascribe to atoms. (We have seen\nhow chemists came to ascribe the property of valency to them.) There\nwas no viable atomistic theory of chemistry in the nineteenth century\nthat was such that chemical properties could be deduced from it. The\nphenomenon of isomerism is often regarded as a success for\natomism. (See Bird, (1998, p. 152) for a recent example.) There are\nreasons to doubt this. The fact that there are chemical substances\nwith the same proportional weights of the elements but with widely\ndifferent chemical properties was a chemical discovery. It could not\nbe predicted by any atomic theory of the nineteenth-century because no\ntheory contained within its premises a connection between the physical\narrangement of atoms and chemical properties.Isomerism could be\naccommodated to atomism but could not, and did not, predict it. \n\nThe emergence of unique atomic weights and the structural formulae\nthat organic chemistry had yielded by the 1860s were to prove vital\ningredients for the case for atomism that could eventually be\nmade. But there are reasons to be wary of the claim that atomism was\nresponsible for the rise of organic chemistry and the extent to which\nthe achievement improved the case for atomism needs to be elaborated\nwith more caution that is typically the case. Glymour (1980, 226–263)\noffers an account of how Dalton's atomism was increasingly confirmed\nand relative atomic weights established by 1860 that conforms to his\n‘bootstrapping’ account of confirmation, an account that\nis adopted and built on by Gardner (1979). These accounts do not take\norganic chemistry into account. In one sense, doing so could in fact\nhelp to improve Glymour's account by offering a further element to the\ninterlocking and mutually supporting hypotheses and pieces of evidence\nthat are involved in his case. But in another sense, the fact that\norganic chemistry led to unique formulae by chemical means casts doubt\non Glymour's focus on the establishment of definitive atomic weights\nas the problem for chemistry. There is a case for claiming\nthat correct atomic weights were the outcome of, rather than a\nprecondition for, progress in organic chemistry prior to 1860. After\nall, the majority of the formulae productively involved in that\ndramatic progress were the wrong formulae from a modern point of view!\nFor instance, use of homologous series to project properties of lower\nhydrocarbons on to higher ones are not affected if the number of\ncarbon atoms in the correct formulae are doubled, which results from\ntaking 6 as the relative atomic weight of carbon, as many of the\ncontemporary organic chemists did. \n\nSuggested Readings: Rocke (1984) is a detailed study of the\nrelevant theories in eighteenth-century chemistry whilst Klein (2003)\nis a historical and philosophical analysis of the introduction of\nformulae into organic chemistry. The empirical status of atomism in\nnineteenth-century chemistry is discussed in Chalmers (2009, Chapters\n9 and 10) \n\nThe first atomic theory that had empirical support independent of the\nphenomena it was designed to explain was the kinetic theory of\ngases. This discussion will pass over the historical detail of the\nemergence of the theory and consider the mature statistical theory as\ndeveloped by Maxwell from 1859 (Niven, (1965, Vol. 1, 377–409, Vol. 2,\n26–78) and developed further by Boltzmann (1872). \n\nThe theory attributed the behaviour of gases to the motions and\nelastic collisions of a large number of molecules. The motions were\nconsidered to be randomly distributed in the gas, while the motion of\neach molecule was governed by the laws of mechanics both during and in\nbetween collisions. It was necessary to assume that molecules acted on\neach other only during collision, that their volume was small compared\nwith the total volume of the gas and that the time spent in collision\nis small compared to the time that elapses between collisions. While\nthe molecules needed to be assumed to be small, they needed to be\nsufficiently large that they could not move uninterrupted through the\ngas. The irregular path of a molecule through the body of a gas from\ncollision to collision was necessary to explain rates of\ndiffusion. \n\nThe kinetic theory was able to explain the gas laws connecting volume,\ntemperature and pressure. It also predicted Avogadro’s law that\nequal volumes of gases contain equal numbers of molecules and so\nexplained Gay Lussac's law also. This legitimated the use of vapour\ndensities for the determination of relative molecular weights.  This\nin turn led to definitive atomic weights and formulae that coincided\nwith those that organic chemistry had yielded by the 1860’s. The\nkinetic theory of gases also explained the laws of diffusion and even\npredicted a novel phenomena that was quite counter-intuitive, namely,\nthat the viscosity of a gas, the property that determines its ease of\nflow and the ease with which objects flow through it, is independent\nof its density. Counter-intuitive or not, the prediction was confirmed\nby experiment. \n\nIt was known from experiment that the behaviour of gases diverges from\nthe gas laws as pressure is increased and they approach\nliquefaction. The gas laws were presumed to apply to ‘ideal\ngases’ as opposed to real gases. The behaviour of real gases\napproaches that of ideal gases as their pressure is reduced. The\nkinetic theory had an explanation for this distinction, for at high\npressure the assumptions of the kinetic theory, that the volume of\nmolecules is small compared with the total volume of the gas they form\npart of and that the time spent in collision is small compared to the\ntime between collisions, become increasingly inaccurate. The theory\nwas able to predict various ways in which a real gas will diverge from\nthe ideal gas laws at high pressures (Van der Waals equation) and\nthese were confirmed by experiments on gases approaching\nliquefaction. \n\nThe kinetic theory of gases explained a range of experimental laws and\nsuccessfully predicted new ones. However, there were some key\ndifficulties. One of them was the departure of experimentally measured\nvalues of the ratio of the two specific heats of a gas, measured at\nconstant pressure and at constant volume, from what the theory\npredicted. This prediction followed from a central tenet of the theory\nthat energy is distributed equally amongst the degrees of freedom of a\nmolecule. The difficulty could be mitigated by assuming that molecules\nof monatomic gases were perfectly smooth spheres that could not be set\nrotating and that diatomic molecules were also smooth to the extent\nthat they could not be set rotating about the axis joining the two\natoms in the molecule. But, as Maxwell made clear, (Niven, 1965, Vol.\n2, 433) it must be possible for molecules to vibrate in a number of\nmodes in order to give rise to the spectra of radiation that they emit\nand absorb, and once this is admitted the predictions of the theory\nclash unavoidably with the measured specific heats. \n\nThe second major difficulty stemmed from the time reversibility of the\nkinetic theory. The time inverse of any process is as allowable as the\noriginal within the kinetic theory. This clashes with the time\nasymmetry of the second law of thermodynamics and the\ntime-directedness of the observed behaviour of gases. Heat flows\nspontaneously from hot regions to cold regions and gases in contact\nspontaneously mix rather than separate. It is true that defenders of\nthe kinetic theory such as Maxwell and Boltzmann were able to\naccommodate the difficulty by stressing the statistical nature of the\ntheory and attributing time asymmetries to asymmetries in initial\nconditions. But this meant that a fundamental tenet of thermodynamics,\nthe second law, was in fact only statistically true. Violations were\nimprobable rather than impossible.  Defenders of the kinetic theory\nhad no direct experimental evidence for deviations from the second\nlaw. \n\nThe kinetic theory explained known experimental laws and predicted new\nones. That empirical success could not be accommodated by some\ntruncated version of the theory that avoided a commitment to atomism\nin the way that use of chemical formulae could for chemistry. Insofar\nas the kinetic theory explained anything at all, it did so by\nattributing the behaviour of gases to the motions and collisions of\nmolecules. On the other hand, it did face apparent empirical\nrefutations as we have seen. Those wishing to assert the truth of the\nkinetic theory, and hence of an atomic theory, had a case but also\nfaced problems. \n\nFor those inclined to judge theories by the extent to which they\nfruitfully guide experiment and lead to the discovery of experimental\nlaws, we get a more qualified appraisal. For two decades or more the\nmature kinetic theory proved to be a fruitful guide as far as the\nexplanation and prediction of experimental laws is concerned. But, in\nthe view of a number of scientists involved at the time, the kinetic\ntheory had ceased to bear fruit for the remainder of the century, as\nClarke (1976, 88–9) has stressed.  It might appear that the success of the kinetic theory marked a\nsuccessful instantiation of the kind of atomism aspired to by the\nmechanical or Newtonian atomists, since macroscopic phenomena are\nexplained in terms of atoms with just a few specified mechanical\nproperties. There are reasons to resist such a view. Firstly, neither\nthe molecules of the kinetic theory nor the atoms composing them were\nultimate particles. As we have noted, it was well appreciated that\nthey needed an inner structure to accommodate spectra. Secondly, it\nwas well apparent that the mechanical properties attributed to\nmolecules by the kinetic theory could not constitute an exhaustive\nlist of those properties. Further properties were required to explain\ncohesion and chemical interaction for instance. Thirdly, and perhaps\nmost fundamentally, the kinetic theory was not an attempt to give an\natomic account of the ultimate structure of matter. Maxwell, for one,\nwas quite clear of the distinction between an atomism that made claims\nabout the ultimate structure of matter for some very general\nmetaphysical reasons, on the one hand, and a specific scientific\ntheory postulating atoms on the other (Niven, 1965, Vol. 2,\n361–4). The kinetic theory was an example of the latter insofar\nas it was proposed, not as an ultimate theory, nor as a theory of\nmatter in general, but as a theory designed to explain a specified\nrange of phenomena, in this case the macroscopic behaviour of gases\nand, to a less detailed extent, of liquids and gases too. As such, it\nwas to be judged by the extent it was able to fulfil that task and\nrejected or modified to the extent that it could not. A case for the\nexistence of atoms or molecules and for the properties to be\nattributed to them was to be sought in experimental science rather\nthan philosophy. \n\nDuring the half-century that followed the emergence of unique chemical\nformulae and viable versions of the kinetic theory around 1860 the\ncontent of atomism was clarified and extended and the case for it\nimproved by the development of atomic explanations of experimental\neffects that involved connections between phenomena of a variety of\nkinds, the behaviour of gases, the effect of solutes on solutions,\nosmotic pressure, crystallography and optical rotation, properties of\nthin films, spectra and so on. In several of these cases atomic\nexplanations were offered of experimental connections for which there\nwere no available alternative explanations so that the case for\natomism understood as an inference to the best explanation was\nstrengthened. \n\nStereo-chemistry emerged as a result of taking the structures depicted\nin chemical formulae of substances to be indicative of actual\nstructures in the molecules of those substances. Pairs of substances\nthat had crystal structures that were mirror images of each other but\nwhich were otherwise chemically identical were represented by formulae\nthat were themselves mirror images of each other. Optical rotation\ngave independent evidence for the reality of these underlying\nstructures.  Some chemists were reluctant to assert that the\nstructures were in fact depictions of the physical arrangements of\natoms in space, a stand supported by the fact that there was still no\ntheory that connected physical arrangements of atoms with physical and\nchemical properties.  There were eminent scientists, notably Ostwald\n(1904) and Duhem (2002), who, whilst accepting that the phenomena were\nindicative of some underlying structure, refused to make the further\nassumption that the formulae with their structures referred to\narrangements of atoms at all. Two factors provide a rationale for\ntheir stance. Firstly, the use of formulae in chemistry could be\naccepted without committing to atomism, as we have discussed above,\nand as both Ostwald and Duhem stressed. Secondly, an analogy with\nelectromagnetism indicates that structural features need not be\nindicative of underlying physical arrangements accounting for those\nstructures. The electric field has the symmetry of an arrow and the\nmagnetic field the symmetry of a spinning disc, but there is no known\nunderlying physical mechanism that accounts for these\nsymmetries. Stereo-chemistry may not have provided a case for atomism\nthat was logically compelling, but it certainly enabled that case to\nbe strengthened. \n\nAnother set of phenomena providing opportunities to develop atomism\ninvolved the effects of solutes on solutions. It was discovered that\neffects such as the depression of freezing point and vapour pressure\nand the elevation of boiling point of a solvent brought about by\ndissolving a non-electrolytic solute in it are proportional to the\nweight of dissolved substance and, what is more, that the relative\neffects of differing solutes in a given solvent were determined by the\nmolecular weight of the solute. More specifically, the magnitude of\nthe various physical effects of a solute was dependent on the number\nof gram molecules of the dissolved solute, independent of the chemical\nnature of the solute. This provided a way of measuring the molecular\nweight of soluble substances that complimented the method involving\nthe measurement of the vapour pressure of volatile ones. The strong\nsuggestion that these effects depended on the number of molecules per\nunit volume was strengthened when it was discovered that the osmotic\npressure of a solute in a solvent obeys the gas laws. That is, the\nosmotic pressure exerted by a solute in a definite volume of solvent,\nmeasurable as the pressure exerted on a membrane permeable to the\nsolvent but not the solute, was exactly the same as if that same\namount of solute were to fill that same volume as a gas. \n\nWhile the above could readily be explained by atomism, an anti-atomist\ncould still accept the experimental correlations by interpreting\nmolecular weights as those yielded by chemical formulae independently\nof an atomic interpretation. Ostwald took that course.  The move\nbecame less plausible once the phenomena were extended to include\nsolutions of non-electrolytes. For electrolytes, physical phenomena\nsuch as modification of boiling and freezing points and osmotic\npressure could be explained in terms of the concentration of ions\nrather than molecules, where the ions were the charged atoms or\ncomplexes of atoms employed by the atomists to explain electrolysis.\nThis enabled new experimental connections to be forged between, for\nexample, osmotic pressure, and the conductivity of electrolytes. What\nis more, the charges that needed to be attributed to ions to explain\nelectrolysis were themselves linked to the valencies of the chemists.\nThe atomic interpretation of electrolysis required a corresponding\natomistic interpretation of electric charge, with each monovalent ion\ncarrying a single unit of charge, a bi-valent ion carrying two such\nunits and so on. \n\nYet another breeding ground for atomism came in the wake of the\nelectromagnetic theory of light (1865) and the experimental production\nof electromagnetic radiation by an electric oscillator (1888).\nHelmholtz (1881) observed that optical dispersion could be readily\nexplained if it were assumed that the transmission of light through a\nmedium involved the oscillation of particles that were both massive\nand charged. The adsorption and emission of spectra characteristic of\natoms also suggested that they were due to the oscillations of charged\nparticles on the atomic or sub-atomic scale. These assumptions in\nconjunction with the kinetic theory of gases led to an explanation of\nthe width of spectral lines as a Doppler shift due to the velocity of\nradiating molecule, making possible estimates of the velocities of\nmolecules that were in agreement with those deduced from the diffusion\nrate of gases. \n\nStrong evidence for the charged and massive particles assumed in an\natomic explanation of electrolysis and radiation was provided by the\nexperiments on cathode rays performed by J. J. Thomson (1897). The\nexperimental facts involving cathode rays could be explained on the\nassumption that they were beams of charged particles each with the same\nvalue for the ratio of their charge to their mass. Thomson’s\nexperiments enabled that ratio to be measured. A range of other\nexperiments in the ensuing few years, especially by Milliken, enabled\nthe charge on the cathode particles, electrons, to be estimated, and\nthis led to a mass of the electron very much smaller than that of\natoms. The fact that identical electrons were emitted from cathodes of\na range of materials under a range of conditions strongly suggested\nthat the electron is a fundamental constituent of all atoms. \n\nAs the considerations of the previous section indicate, there is no\ndoubt that those wishing to make a case for atoms were able to\nsteadily strengthen their case during the closing decades of the\nnineteenth century. However, it is important to put this in perspective\nby taking account of spectacular developments in thermodynamics which\nwere achieved independently of atomism, and which could be, and were,\nused to question atomism, branding it as unacceptably\nhypothetical. \n\nPhenomenological thermodynamics, based on the law of conservation of\nenergy and the law ruling out spontaneous decreases in entropy,\nsupported an experimental programme that could be pursued\nindependently of any assumptions about a micro-structure of matter\nunderlying properties that were experimentally measurable. The\nprogramme was developed with impressive success in the second half of\nthe nineteenth century. Especially relevant for the comparison with\natomism is the extension of thermodynamics, from the late 1870s, to\ninclude chemistry.  Two of the striking accomplishments of the\nprogramme were in areas that had proved a stumbling block for atomism,\nnamely, thermal dissociation and chemical affinity. \n\nGibbs (1876–8) developed a theory to account for what, from the point\nof view of the atomic theory, had been regarded as\n‘anomalous’ vapour densities by regarding them as\nconsisting of a mixture of vapours of different chemical constitution\nin thermal equilibrium. The theory was able to predict relative\ndensities of the component vapours as a function of temperature in a\nway that was supported by experiment. It is true that atomists could\nnot only accommodate this result by interpreting it in atomic terms\nbut also welcomed it as a way of removing the problems the phenomena\nhad caused for the determination of molecular weights from vapour\ndensities. But it remains the fact that the thermodynamic predictions\nare independent of atomic considerations once it is recognised that\nthe chemical formulae needed for them can be, and were, obtained and\ninterpreted in a way independent of atomism. As a matter of historical\nfact, Deville, the major participant in the experimental confirmation,\nwas opposed to atomism, as Duhem (2002, 96–7) stressed. \n\nFrom the time Newton introduced the notion of forces of affinity\nacting between atoms and responsible for their chemical behaviour\nthere had been a problem forging a link between those forces and\nexperimentally measurable effects. Daltonian atomists simply assumed\nthat atoms combine in the way required to account for the measurable\nproportions of elements in compounds. The theory gave no account of\nthe relative strengths of chemical bonding or hints of what would\nreplace what in a chemical reaction. Chemical thermodynamics was able\nto make headway with this problem. Considerations based on entropy\nchanges and heats of reaction made it possible to predict in which\ndirection a particular chemical reaction will proceed and to provide\nan experimental measure of the affinities involved, where the\naffinities are not forces between atoms but provide a measure of the\nfacility with which one macroscopic chemical substance combines with\nanother. In the late nineteenth century leading scientists such as\nOstwald, Duhem and Planck were inclined to take thermodynamics as\nthe model of how science should proceed, maintaining a secure\nand productive relationship with experiment whilst avoiding hypotheses\nof the kind involved in atomism. \n\nThe factor that is usually considered as turning the tables decisively\nin favour of the atomists is Jean Perrin's experiments on Brownian\nmotion. Nye (1972, 145–52) has documented how Ostwald and\nothers conceded that the experiments settled the case in favour of\natoms. \n\nSuggested Readings: Clarke (1976) is a detailed investigation\nof the relationship between thermodynamics and the kinetic theory\nwhich contains good summaries of both theories.  Clarke's case that\nobjections to the kinetic theory were based largely on scientific\ngrounds is contested in Nyoff (1988) which contains a good treatment\nof the specific heats problem, and is further discussed in de Regt (1996). \n\nBrownian motion is the fluctuating motion of particles of an emulsion\nvisible through a microscope. Two features of it led physicists in the\nlate nineteenth century to suspect that it was caused by the molecular\nmotions assumed in the kinetic theory. Those two features were its\npermanence and its random character. Perrin’s experiments of\n1908 were able to give precision to those suspicions. He was able to\nshow that the motions of the particles are indeed random, in a\ntechnical sense, and he showed that the general features of the motion\nare permanent, once equilibrium has been reached. The density\ndistribution and mean free path of the particles remain constant at\nconstant temperature. The kinetic theory had a ready explanation of\nthese features, attributing the randomness to the randomness of the\nmotions of the molecules making up the liquid in which the emulsion\nwas suspended, and the equilibrium conditions as a dynamic equilibrium\ncorresponding to the distribution of velocities formalised by Maxwell.\nThose wishing to resist the conclusion that Brownian motion\nconstituted strong evidence for the kinetic theory needed to offer\nsome alternative explanation for the two features. \n\nThe randomness of the motion rules out causes, such as convection\ncurrents in the liquid, which operate on a scale larger than the\ndimensions of the particles. Causes of that kind would lead to\ncorrelations between the motions of neighbouring particles and that is\nprecisely what is ruled out by a truly random motion of particles. The\npermanence of the motion is a puzzle because the particles, moving\nthrough a viscous liquid, will be slowed down, losing heat to the\nliquid, suggesting that the whole motion should come to a halt just as\na sizeable object such as a cricket ball, projected into a liquid,\nwill be brought to rest. General, quantitative features of\nPerrin’s results made life difficult for the anti-atomists, but\nthere was yet more to his case. \n\nAs was observed in \n Section 5.3, \n it had been experimentally established that the osmotic pressure of a\nsolute in small concentrations obeys the gas laws. A natural step from\nthe point of view of the kinetic theory is to assume that the\ndifference between the molecules of a solute distributed through the\nliquid in which it is dissolved and Brownian particles all of like\nsize suspended in a liquid is simply one of scale. Einstein (1905,\n1906,1907) was the first to stress this point and to give a detailed\naccount of Brownian motion as a thermal agitation. Perrin's initial\nwork on the density distribution of Brownian particles seems to have\nbeen carried out in ignorance of Einstein's paper. But it was soon\nbrought to his attention and influenced his subsequent work with full\nacknowledgment given to Einstein. \n\nPerrin's observations revealed that the density distribution of\nBrownian particles decreased exponentially with height. He was able to\nexplain this quantitatively by appeal to Newtonian mechanics and\nstatistics. Because of the decrease in their density with height, more\nparticles per second strike a unit area of the lower surface of a thin\nhorizontal layer in the liquid than will strike a unit area of the\nupper surface. As a result there will be a net pressure directed\nupwards. Perrin was able to derive a value for the pressure in terms of\nthe number of particles per unit volume, their mass and the mean of\nthe squares of their velocities. Equilibrium is reached when the\nupwards force due to the pressure is equal to the weight of the\nparticles arising from the excess of the density of the material of\nthe particles over that of the suspending liquid. The resulting\nequation, when integrated, showed the density of the particle\ndistribution to vary exponentially with height and also enabled Perrin\nto calculate a value for the mean kinetic energy of the Brownian\nparticles from the measured variation in density of the particle\ndistribution. It transpired that the mean kinetic energy depended only\non temperature and was independent of the material of the particles,\ntheir size and the density of the liquid in which the particles were\nsuspended. \n\nOnce Perrin was able to calculate the mean kinetic energy of the\nBrownian particles he could support the most basic assumptions of\nkinetic theory without a need to complicate matters by adding\nadditional hypotheses. From the point of view of the kinetic theory,\nsystems are in equilibrium when the mean kinetic energy of the\nmolecules in those systems are equal, with particle collisions being\nthe mechanism by means of which equilibrium is reached. Brownian\nparticles constitute a system that differs from the molecules\nconstituting a gas only quantitatively, not qualitatively. If a system\nof Brownian particles is in thermal equilibrium with a gas at some\ntemperature, T, then, from the point of view of the kinetic\ntheory, the mean kinetic energy of the particles must be equal to\nthat of the molecules of the gas. By measuring the mean kinetic energy\nof Brownian particles from the observable density distribution at\ntemperature, Tr, Perrin had in effect measured the mean\nkinetic energy of the molecules of a gas at that temperature. That\nknowledge enabled him to calculate Avogadro's number. As Perrin (1990,\n104) remarked, it was with ‘the liveliest emotion’ that he\nfound that number to be in accord with previous, more indirect,\nestimates of Avogadro's number. \n\nPerrin stressed the extent to which the value for Avogadro’s\nnumber yielded by his experiments on density distribution formed the\nbasis of a strong argument from coincidence for the kinetic theory.\nPerrin posed the question of what density distribution of Brownian\nparticles might have been suspected prior to his experiments if the\nkinetic theory is ignored. Since the particles were denser than the\nliquid in which they were suspended, a reasonable assumption might be\nthat the particles fall to the bottom so that the density distribution\nis zero. This experimental result, substituted into Perrin’s\nformula, would have led to an infinitely large value for\nN. Another plausible assumption might have attributed an even\ndistribution to the suspended particles. Such an outcome would have\nled to a value of zero for N. A decrease in density with\nheight yields some value in between these two extremes. Prior to the\nexperiment, then, the range of plausible results to be expected from\nfeeding the measured distribution into Perrin's equation, derived on\nthe basis of the kinetic theory, is immense. And yet the outcome was a\nnumber very close to that predicted by the kinetic theory. \n\nThere were yet further dimensions to Perrin's experiments. In his 1905\npaper, Einstein had derived expressions for the mean displacement and\nrotation of Brownian particles as a function of time on the basis of\nthe kinetic theory. Perrin was able to show how these predictions were\nborne out by his observations of the particles. He, in effect, showed\nthat propositions basic to the kinetic theory, such as the\nindependence of orthogonal components of the velocity of particles and\nthe equi-partition of energy amongst their degrees of freedom, were\nsatisfied by the Brownian particles. What is more, it was again\npossible to calculate values for N from the experimentally\ndetermined mean displacements and rotations, and in both cases the\nmeasured values were within a few percent of 68 ×\n1022. \n\nIt was not long before Avogadro's number could be calculated by\nmethods not closely tied to the kinetic theory of gases. Rayleigh\nspeculated that the brightness of the sky is due to the scattering of\nlight from the sun by molecules in the atmosphere. The theory\npredicted that light of shorter wavelength is scattered more\neffectively than that of longer wavelength, a prediction borne out by\nthe blueness of the sky and the redness of sunsets. It also predicted\nthat the scattered light be polarised, also in conformity with\nobservation. It was possible to calculate Avogadro's number from the\nratio of the intensity of skylight to that of light coming direct from\nthe sun. Once the charge on the electron had been measured it was also\npossible to calculate Avogadro's number from the relation between\ncurrent passed and weight of substance deposited in\nelectrolysis. Radioactivity was to provide further access to the\nnumber. In all cases, the values for Avogadro's number agreed to a\ndegree that could be reconciled with the accuracy of the experiments\nand the degree of approximation involved in the calculations. \n\nThere is a further important aspect of the extent to which Perrin's\nexperiments supported the kinetic theory. One of the major objections\nraised by opponents of that theory was the fact that it implied that\nthe second law of thermodynamics is only statistically true. Perpetual\nmotion machines of the second kind become improbable rather than\nimpossible. It is difficult to resist the conclusion that the constant\nlifting of Brownian particles against gravity refutes the unqualified\nversion of the second law. When a Brownian particle moves upwards then\nthe first law of thermodynamics, the conservation of energy, requires\nthat the potential energy gained by the particle must come from\nsomewhere. If it comes from the heat of the suspending liquid then\nthis is in contradiction to the second law. An opponent of the kinetic\ntheory and a defender of the literal truth of the second law is\nrequired to supply some alternative source of the energy. Needless to\nsay, no suitable alternative was forthcoming. Once the kinetic theory\nis assumed, the rising of a Brownian particle is understood as a\nthe result of a statistical fluctuation. What is more, the randomness and the\nsmallness of the scale on which the violations of the second law take\nplace ensures that it is not possible to employ the phenomenon to\nextract useful work.  The force of Perrin's argument for the kinetic theory, and hence\nfor the reality of molecules, stems from the fact that his argument\nrequires only the central assumptions of the theory, the equipartition\nof energy and the randomness of molecular agitation, without requiring\nthe addition of auxiliary or simplifying assumptions. It is this fact\nthat made his calculations of Avogadro's number qualitatively distinct\nfrom, and more telling than, other estimates. Ostwald cited this as\nthe reason for his conversion to belief in molecules (Nye, 1972,\n151–152). Interestingly, the derivation of the ratio of the\nprinciple specific heats of a gas similarly requires only the basic\nassumptions of the kinetic theory cited above. That is why the clash\nof the prediction with measured values spelt serious trouble for the\nclassical kinetic theory. Equipartition of energy breaks down for the\nvibrational modes of a molecule and for rotational modes also at\ntemperatures sufficiently low, as Perrin (1990, 73) noted. \n\nSuggested Readings: Perrin (1990) is an English\ntranslation of his classic defence of atomism written in 1913. Nye\n(1972) is a useful historical survey of Perrin's work on Brownian\nmotion. A recent philosophical analysis of the significance of\nPerrin's experiments, which contains references to earlier analyses by\nother philosophers, is Achinstein (2001), 243–265. Mayo (1996,\n214–250) is an attempt to construe Perrin's argument as\ninvolving bottom-up rather than top-down reasoning. Doubts about the\nuse of Perrin's experiments by philosophers are raised by van Fraassen\n(2009), to which Chalmers (2011) is a response. \n\nIf we take atomism to involve the claim that the properties of\nmacroscopic matter arise as a result of the combinations and motions\nof tiny particles, then it is a position confirmed by the time of the\nSolvay Conference in 1911 in a way that left little room for sensible\ndoubt. But if we take atomism in a stronger sense, to mean a theory\nthat explains all of the properties of macroscopic matter in terms of\nunderlying particles with specified properties and governed by\nspecified laws, then it must be denied that atomism had reached its\nobjective in 1911. There were identifiable inadequacies and gaps in\nthe specification of the properties of atoms and the electrons and\nprotons that compose them and there were to an increasing extent\nproblematic experimental results that were eventually to lead to a\nradical change in the laws that were presumed to govern the behaviour\nof atomic and sub-atomic particles. \n\nAcceptance of the kinetic theory implied acceptance of the existence\nof atoms and molecules with a well-defined mass. However, it was\nperfectly clear that they must have further properties. For example,\nthey needed properties that would explain chemical combination, and,\nspecifically, the notion of valency. They also needed properties that\nwould account for spectra. Answers to these challenges were\nforthcoming in the form of the electron structure of the atom and the\nquantum mechanics that governs it. There is a sense in which\ncontemporary physics, with its account of the properties of atoms and\nmolecules in terms of their electron structure and the explanation of\nmany macroscopic phenomena in terms of the atomic and molecular\nstructures underlying them, comes close to the ideal of Democritus. A\ngeneral account of the properties of the material world is offered in\nterms of underlying particles with a few well-defined properties\ngoverned by well-defined laws. The difference between the contemporary\nsituation and the ideals of Democritus or the mechanical philosophers\nlies in the epistemological access to the general atomistic\ntheory. The contemporary theory became possible only as a result of\ncenturies of scientific development. The quantum mechanical laws\ngoverning the atomic world were responses to quite specific problems\nrevealed by experiment in areas such as black-body radiation, emission\nand absorption spectra, the specific heats of gases and\nradioactivity. The properties ascribed to electrons, for instance,\nsuch as their charge and half-integral spin, were themselves responses\nto quite specific experimental findings involving discharge tube\nphenomena and spectra.  Atomism, which began its life as speculative\nmetaphysics, has become a securely established part of experimental\nscience."}]
