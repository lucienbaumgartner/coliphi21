[{"date.published":"2014-09-08","date.changed":"2019-11-07","url":"https://plato.stanford.edu/entries/social-procedures/","author1":"Jan van Eijck","author2":"Rineke (L.C.) Verbrugge","author1.info":"http://www.cwi.nl/~jve","author2.info":"http://www.rinekeverbrugge.nl","entry":"social-procedures","body.text":"\n\n\nSocial procedures that have algorithmic aspects can often be improved\nby redesign. This holds for voting and other peaceful decision making\nprocedures, for match-making, for auctioning, for fair division of\nestates, and for many procedures of distributive justice. The\nalgorithmic aspects can be analyzed with formal methods. The term\n“social software” was coined by Rohit Parikh (2002)\nfor the emerging interdisciplinary\nenterprise that is concerned with the design and analysis of\nalgorithms that regulate social processes. Such analysis and\n(re-)design uses methods from logic, game theory and theoretical\ncomputer\n science.[1]\n The goals of research in formal approaches to social procedures are\nmodeling social situations, developing theories of correctness, and\n(re-)designing social procedures, ideally leading to new social\nbehavior.\n\n\nLogic, game theory and computer science are not the only disciplines\nthat have something to say about social mechanisms. Such mechanisms\nare also an object of study in voting theory, in auction theory, in\nsocial choice theory, in social epistemology, in mechanism design\ntheory, and in algorithmic game theory. Multi-agent interaction at a\nmore abstract level is studied in artificial intelligence and\ndistributed computing, so all these disciplines have something to say\nabout the formal analysis of social interaction.\n\nSocial software cannot be seen as a clearly defined research field on\nits own, but rather an umbrella for certain types of research in\ncomputer science, logic, and game theory. Nevertheless, the social\nsoftware perspective on social procedures and intelligent interaction,\nemphasizing algorithms and information, has already produced a wide\nvariety of important insights. In this article, a number of examples\nwill be discussed and pointers will be given to related discussions in\nphilosophy. \nThe prototypical example of an algorithm in\nmathematics (see also entry on\n computability and complexity)\n is Euclid’s recipe for finding the greatest common divisor\n(GCD) of two positive whole numbers \\(A\\) and \\(B\\). The GCD of two\nnumbers is the greatest number that divides both numbers without\nresidue. \nIf \\(A\\) is larger than \\(B\\), then replace \\(A\\) by \\(A - B\\),\notherwise, if \\(B\\) is larger than \\(A\\), replace \\(B\\) by \\(B - A\\).\nContinue like this until \\(A\\) equals \\(B\\). \nThe final \\(A = B\\) yields the greatest common divisor of the numbers\n\\(A\\) and \\(B\\) that you started with. For instance, suppose you start\nthe algorithm with \\(A = 20\\), \\(B = 12\\). Then in the first step,\n\\(A\\) gets replaced by \\(20 - 12 = 8\\), so \\(8\\) becomes the new\n\\(A\\). In the second step, \\(B\\) gets replaced by \\(12 - 8 = 4\\), so\n\\(4\\) becomes the new \\(B\\). In the third step, \\(A\\) gets replaced by\n\\(8 - 4 = 4\\), so \\(4\\) becomes the new \\(A\\) and the two numbers\n\\(A\\) and \\(B\\) have become equal. The algorithm yields \\(4\\) as the\nGCD of \\(20\\) and \\(12\\). \nEuclid’s recipe is formal, and we can\nanalyze it with formal means. The correctness of Euclid’s\nalgorithm follows from the insight that if you have two numbers \\(A\\)\nand \\(B\\) with \\(A\\) larger than \\(B\\), and you replace \\(A\\) by \\(A -\nB\\), then the set of common divisors of the number pair does not\nchange. \nAlgorithms come in many forms and flavors, for example, sequential and\nparallel ones. For interesting introductions to algorithms in computer\nscience, see Harel & Feldman (2004) and Miller & Boxer (2012).\nIn a similar manner as these algorithms, social procedures can be\nanalyzed with the formal tools of logic and theoretical computer\n science.[2] \nIt appears that most amenable to a formal approach are those social\nprocedures for which one wants to guarantee that given certain\nstarting conditions, the procedure preserves or creates specific\ndesired properties. Examples are social procedures for fair division\n(Section\n 2),\n matching (Section\n 3),\n communication (Section\n 4).\n Finally, the formal perspective is useful for situations requiring\nparticipants’ strategic reasoning (Section\n 5).\n A common element is that in all these situations, agents’\nknowledge and lack of knowledge of other agents’ mental states\nplay an important role. As a counterpart to the examples in the\ncurrent article, Van Benthem (2018) provides an intriguing overview\nabout the current roles of social perspectives in computer science\nitself, highlighting social agency and information.  \nFormal methods by themselves do not solve philosophical issues, as the\nfollowing tale from Padma (2007)\nillustrates. \nTwo farmers, Ram and Shyam were eating chapatis. Ram had 3 pieces of\nthe flat, round bread and Shyam had 5. A traveller who looked hungry\nand tired rode up to the two men. Ram and Shyam decided to share their\nchapatis with him. The 3 men stacked the 8 chapatis (like pancakes)\nand cut the stack into 3 equal parts. They shared the pieces equally\nand ate until nothing was left. The traveller, who was a nobleman, was\nso grateful that he gave the two farmers 8 gold coins for his share of\nthe food. \nAfter the traveller left, Ram and Shyam wondered how they should share\nthe 8 gold coins. Ram said that there were 8 coins and only 2 people,\nso each person should get an equal share of 4 coins. “But\nthat’s not fair,” said Shyam, “since I had 5\nchapatis to begin with.” Ram could see his point, but he\ndidn’t really want to give 5 of the coins to Shyam. So he\nsuggested they go see Maulvi, who was very wise. Shyam agreed. \nRam and Shyam told the whole story to Maulvi. After thinking for a\nlong time, he said that the fairest way to share the coins was to give\nShyam 7 coins and Ram only 1 coin. Both men were surprised. But when\nthey asked Maulvi to explain his reasoning, they were satisfied that\nit was a fair division of the 8 coins. \nHere are reasons the participants could have given to explain each\nmentioned division as being fair: \nRam: “If the traveller hadn’t arrived, we would have\nshared the chapatis equally. So it is only fair\nif we now share the eight coins equally as well.” \nShyam: “If the traveller hadn’t arrived, you would have\nbought one chapati from me at the going rate for chapatis. Now that\nthe traveller was so generous, the going rate suddenly went up to one\ngold coin for a chapati. So your chapatis turned out to be worth three\ngold coins and mine five gold coins.” \nMaulvi: “The traveller has eaten one third of eight chapatis.\nRam had only three chapatis to start with, and therefore he has eaten\n\\(1/3\\) chapati from Ram and \\(7/3\\) chapatis from Shyam. So it is\nonly fair if Ram gets one coin and Shyam gets seven.” \nA moral of this could be that there is no obviously correct notion of\nfairness, in this case, and in many cases. Formal analysis always\nstarts from an intuition and can help to turn that intuition into a\nmore precise definition. Then one can check if a given procedure fits\nthe definition; however, if it fits, that does not show that the\ndefinition is right. \nSocial procedures are as old as the world. Divide and\nchoose (also known as “I cut, you choose”) is\na procedure for two-person fair division of some desirable or\nundesirable heterogeneous good. One person divides the good into what\nshe believes to be equal shares, and the other person chooses. If the\ntwo participants have different value judgements on parts of the\ngoods, it is possible that both participants feel that they received\nmore than 50 percent of the goods. Indeed, let \\(X\\) be a set\nrepresenting the good to be divided. A valuation function \\(V\\) for\n\\(X\\) is a function from \\({{\\cal P}}(X)\\) to \\([0,1]\\) with the\nproperties that \\(V(\\emptyset) = 0\\), \\(V(X) = 1\\), and for all\nsubsets \\(A\\), \\(B\\), it holds that \\(A \\subseteq B \\subseteq X\\)\nimplies \\(V(A) \\leq V(B)\\) (for explanation of notation, see\nsupplement on\n basic set theory).\n Suppose \\(V_m\\) and \\(V_y\\) are functions for my and your valuation\nof the contents of \\(X\\). If \\(V_m\\) and \\(V_y\\) are different, this\nmeans that you and I value some items in \\(X\\) differently. It\nfollows, as was already observed by Steinhaus in 1948, that there\nexists a division that gives both parties more than their due part;\n“this fact disproves the common opinion that differences in\nestimation make fair division difficult” (Steinhaus\n1948). \nIt matters whether the valuations are known to the other party. Such\nknowledge can be used to advantage by the one who cuts. First consider\nthe case that your valuation is unknown to me, and vice versa. Then if\nI cut, the best I can do is pick sets \\(A, B \\subseteq X\\) with \\(A\n\\cap B = \\emptyset\\), \\(A \\cup B = X\\), and \\(V_m(A) = V_m(B)\\). If\nyou choose, you will use \\(V_y\\) to pick the maximum of \\(\\{ V_y(A),\nV_y(B) \\}\\). It follows immediately that cutting guarantees a fair\nshare, but no more than that, while choosing holds a promise for a\nbetter deal. So if you ever get the choice between cutting and\nchoosing in a situation where both parties only know their own\nvaluation, then it is to your advantage to leave the cutting to the\nother person. \nHowever, if the valuations are common knowledge (see entry on\n common knowledge),\n the situation is reversed, for then it is more advantageous to take\nthe role of cutter. As cutter, you can attempt to make a division intp\nsets \\(A\\) and \\(B\\) with \\(A\\) slightly more valuable than \\(B\\)\naccording to the valuation of the other party, while \\(B\\) is much\nmore valuable than \\(A\\) according to your own valuation. \nThe example shows that issues of knowledge and ignorance, are crucial\nfor analysis of fair division protocols. Epistemic logic (see entry on\n epistemic logic)\n can shed much light on many subtle aspects of knowledge and ignorance\nin social interactions, and in particular in fair division problems;\nfor an interesting cake-cutting experiment showing the importance of\nknowledge and ignorance, see Kyropoulou et al.\n2019. Still, in traditional studies of fair division the role\nof knowledge is not taken into account, as is witnessed by the\ncomprehensive study of “cake cutting algorithms” in Robertson\n& Webb (1998). \nIn the social choice literature (Brams 2005;\nBrams & Taylor 1996) it is common practice to use cake\ncutting as a metaphor for a division of a single\nheterogeneous good. Dividing a piece of land at\ninheritance would be an example. The cake has different toppings that\ncannot all be cut into pieces with the same composition: it may have\ncandied cherries on top that someone likes but another person abhors,\nand so on. A cake division is simply fair if\neach of \\(n\\) players feels she received at least \\(1/n\\) of the cake,\naccording to her individual valuation of its parts. A procedure may be\nsimply fair without ruling out the possibility of hard feelings. A\ncake division is called envy-free if each person\nfeels that nobody else received a larger piece. A sure sign of a\ndivision being envy-free is that nobody wishes to trade pieces with\nanyone else. It turns out to be very hard to design cake cutting\nprocedures that are both fair and envy-free. The I cut, you\nchoose procedure is fair, and it is envy-free simply\nbecause the rest of the cake is a single piece, so there is no\npossibility for envy. See the entry on\n economics and economic justice\n for philosophical discussions of envy-freeness. \nR. Parikh (2002) analyzes the so-called\nBanach-Knaster algorithm for cake cutting when the cake has to be\ndivided fairly among at least three persons, which goes like this: \nI cut a piece intended for myself. All others consider it. If nobody\nobjects, I get my piece. If someone raises an objection, she has the\nright to cut off a slice and put that back with the rest of the cake.\nShe then asks if she can have the reduced piece. If nobody objects,\nshe gets it, otherwise someone else takes the knife and reduces the\npiece a bit further, and so on, until someone gets the trimmed piece.\nThen on to the next round, with \\(n-1\\) players. When two players are\nleft, they use the Divide and choose\nalgorithm. \nParikh’s discussion shows how the methods of theoretical\ncomputer science can be used to argue that the procedure is fair. The\nkey ingredient of the procedure is a loop operation: \nContinue to trim the piece until there are no further objections about\nthe size. \nSuppose \\(r\\) stands for the action of trimming a piece of cake and\nputting it back with the main part of the cake, according to the\nBanach-Knaster algorithm, and suppose \\(F(m,k)\\) is the proposition\nthat the main part of the cake is large enough for \\(k\\) people. Then\nsurely \\(F(m,n)\\) holds at the beginning: the whole cake is large\nenough for the whole group to begin with. Moreover, Parikh (1983,\n2002) uses his game logic to prove that\n\\(F(m,k)\\) is invariant under the action \\(r\\): If \\(F(m,k)\\) is true\nbefore \\(r\\), then it will still be true after \\(r\\) has occurred.\nClearly, if one can show that \\(F(m,k)\\) continues to hold through the\nalgorithm, for \\(k\\) running through \\(n, \\ldots, 1\\), then this\nestablishes that the division is\n fair.[3] \nA variation on Divide and choose was played by\nKing Solomon in the famous Judgement of Solomon, in a dispute among\ntwo women who both claimed to be the mother of a child. The full story\nis in 1 Kings 3:16–28. Two women who lived in the same house\nboth had an infant son. One of the women claimed that the other woman\nhad stolen her child, after accidentally smothering her own son during\nsleep. The other woman denied this and reversed the charge. After\nhearing their stories, King Solomon called for a sword and declared\nthat there was only one fair solution: cut the living child in two and\ngive both women half of it. Upon hearing this, the true mother cried\nout that she was willing to give up the child if it could be spared,\nwhile the fake mother agreed with the judgement. This behaviour\nrevealed to Solomon who was the real mother, and her child was given\nback to her. \nThis procedure is not repeatable. As the Bible story puts it: \nAnd all Israel heard of the judgment which the king had judged; and\nthey feared the king; for they saw that the wisdom of God was in him,\nto do justice. \nObviously, in a second similar dispute, both women would exclaim\n“Give it to her, but let it live!” \nSolomon’s handling of the situation can be turned into a social\nprocedure that is repeatable, as follows. Solomon does not call for a\nsword, but instead explains to the two women the following procedure.\nFirst he is going to ask the first woman if she is willing to give up\nthe child. If the answer is “yes”, the dispute is\nresolved, with no further questions asked. Otherwise he will ask the\nother woman if she is willing to give up the child. Again, if the\nanswer is “yes” the dispute is resolved. If they both\nrefuse, then the child is his, and then he will allow one of the women\nto buy it back, at a price that is to be determined as follows. They\nwill both write an amount of money on a sheet of paper, without their\nnames. If the two bids are \\(A\\) and \\(B\\), then the price of the\nchild is set at \\(\\frac{A + B}{2}\\), and fate will determine which\nwoman is going to get the child at that price, where the other woman\nhas to pay a small fine. If the two women are rational, one of them\nwill give up the child when being first asked (see Moore\n1992 and Pauly 2005; for philosophical\ndiscussions of rationality, see the entries on\n practical reason\n &\n game theory and ethics). \nBoth Moore (1992) and Pauly (2005)\ndiscuss the importance of reasoning\nabout common knowledge and ignorance in the King Solomon cases. For\nexample, King Solomon is ignorant of who is the real mother, but both\nwomen commonly know from the start who is the true mother, and that\nthe true mother will therefore bid much higher than the other one.\nThis makes the procedure safe. Again, epistemic logic and in\nparticular common knowledge help to shed light on a tricky social\nprocedure. For a more traditionally philosophical introduction to the\nfair division problem, including more extensive explanations of\nfairness, manipulability and envy-freeness, see the entry on\n economics and economic justice. \nThe next section shows that the perspective of social software can\nalso shed light on social matching problems. These range from\nmarriages to the assignment of resident doctors to hospitals, college\nadmission procedures, and the assignment of students to housing. \nSuppose equal sets of men and women are given, all of them seeking to\nmarry someone of the opposite gender, and each man has listed his\npreferences for the women by means of a strict ordering, and similarly\nfor each woman. A stable marriage match is a\none-to-one mapping between the men and women with the property that if\na man prefers another woman over his own wife, then that woman does\nnot prefer him to her own husband, and if a\nwoman prefers another man over her own husband, then that man does\nnot prefer her to his own wife. \nThe computer scientists Gale and Shapley proved that stable matchings\nalways exist, and gave an algorithm for finding such matchings, the\nso-called Gale-Shapley algorithm (Gale &\nShapley 1962): \nInitially, all men and all women are free (unengaged). \nNext, in a number of rounds, each free man proposes to the\nmost-preferred woman to whom he has not yet proposed and ticks her off\nfrom his list. If the woman is free, she accepts, and they become\nengaged. If the woman is not free, she compares the proponent to her\ncurrent fiancé. If she likes him better, she dumps the\nfiancé who becomes free again, and the proponent and his woman\nof choice become engaged. \nThis goes on until all men and women are engaged. \nAs an example, suppose that there are three men \\(a, b, c\\) and three\nwomen \\(d, e, f\\), and the lists of preferences are as follows (with\nthe most preferred one first in the list): \\(a: edf\\), \\(b: {\\it\nfed}\\), \\(c: {\\it dfe}\\), \\(d: {\\it abc}\\), \\(e: {\\it cda}\\), \\(g:\n{\\it acb}\\). So \\(a: {\\it edf}\\) means that \\(a\\) prefers \\(e\\) to\n\\(d\\) and \\(d\\) to \\(f\\). It is assumed that preferences are\ntransitive, so \\(a\\) also prefers \\(e\\) to \\(f\\). \nAn example of a stable match for this situation is represented as\nthree pairs \\((a,e)\\), \\((b,f)\\), \\((c,d)\\). Note that woman \\(d\\)\nends up with the man that is at the bottom of her list. But this match\nis still stable, for although \\(c\\) is willing to swap her husband for\nany of the other two men, these two candidates will not agree, for\nthey both happen to be married to the woman who is on the top of their\nown list. \nTo check that the Gale-Shapley algorithm always produces stable\nmatchings, we can proceed as follows. Obviously, the situation where\nno-one is engaged is stable. \nWhat does it mean for \\(E\\), an “engagement” mapping, to\nbe stable on the set of women \\(W\\) and the set of men \\(M\\)? Let us\nuse \\(m >_w m'\\) for “\\(w\\) prefers \\(m\\) over \\(m'\\)”\n(so bigger is better). \nWhat does it mean for a man to be free? \nNext, inspect what happens in a single step in the algorithm. The\nprecondition for the step is that there is at least one free man \\(m\\)\nleft. Such a free man \\(m\\) proposes to the highest woman \\(w\\) on his\nlist to whom he has not yet proposed. \nThere are two cases. If \\(w\\) is free, \\(w\\) accepts the proposal, and\nthey become engaged. Is the new set of engaged pairs stable? We only\nhave to check for the new pair \\((w,m)\\). \nSuppose that there is a free \\(w'\\) with \\(w' >_m w\\). This cannot\nbe, for \\(w\\) is at the top of \\(m\\)'s list. \nSuppose there is \\(m'\\) with \\(m' >_w m\\). Then if \\(m'\\) is\nengaged, let us say to \\(w'\\), this must mean that not \\(w >_{m'}\nw'\\). For otherwise \\(m'\\) would have proposed to \\(w\\) instead of to\n\\(w'\\). \nThe new list of free men equals the old list, minus \\(m\\). This is\ncorrect, for \\(m\\) just got engaged. \nNow the other case: suppose that \\(w\\) is already engaged. There are\ntwo subcases. In case \\(w\\) prefers her own current fiancé,\nnothing happens. The resulting list of engaged pairs is still stable.\nThe list of free men remains the same, for \\(m\\) proposed and got\nrejected. \nIn case \\(w\\) prefers \\(m\\) to her own fiancé \\(m'\\), she\nswaps: \\((m,w)\\) replaces \\((m',w)\\) in the set of engaged pairs.\nAgain, it is easy to see that the resulting list of engaged pairs is\nstable. Man \\(m\\) gets replaced by \\(m'\\) in the set of free men. This\nis also correct. \nNote that the Gale-Shapley matching algorithm is hugely favourable to\nthe party that is doing the proposing. The proposing party gets a\nchance to make proposals to any candidate, in order of preference. But\nat the start of the procedure the receiving party has to say\n“yes” to any proposal! The result of swapping the roles of\nthe men and the women in the algorithm will also compute a stable\nmatch, but one that is more advantageous to the women.  \nThe Gale-Shapley procedure runs in time quadratic in the number of men\nand women (see, e.g., Cechlérová et al. 2005). Pini et\nal. (2011) show how participants can easily manipulate the outcome of\nthe procedure by misrepresenting their true preferences. Fortunately,\nPini et al. also present an alternative procedure for which\nmanipulation is hard, in that coming up with an individually\nprofitable misrepresentation of one’s preferences is a\ncomputationally complex task. \nThe Gale-Shapley algorithm has many important applications, also\noutside of the area of marriage brokering; Gale and Shapley themselves\ndiscuss college admission procedures (1962).\nThe next subsection presents another\napplication. \nUsing the perspective of social software, Parikh and Pauly (2012)\ninvestigate a variant of the\nGale-Shapley algorithm that is used in the Stanford Housing Draw to\nassign students to rooms. The situation is more complex than in the\nmarriage setting, because students do not give a complete order on all\nhouses, but only on 8 of them; moreover, they may choose to enter the\nDraw in groups. In the housing context, the students turn out to have\nan incentive to honestly submit their true preferences: the draw is\nnon-manipulable for them. However, in theory\nthey could still strategize about choosing the subset of 8 houses on\nwhich they submit their preferences. \nThe issue of knowledge is interesting in this case. Even though the\nalgorithm can be found on the Stanford webpages, most students and\nadministrators do not fully understand how it works. Therefore, the\nStanford Housing Draw cannot be assumed as common knowledge among the\nstudents. An interesting phenomenon seems to occur: even while\nadmitting not to understand the algorithm, most students would say\nthat they believe it to be fair (Parikh &\nPauly 2012). \nCommunication protocols are important in distributed computing:\ncomputing with distributed systems, where a distributed system is a\nset of computers that are connected through a communication network.\nCommunication protocols are also interesting from a philosophical\nperspective, especially in the context of discussions of the value of\nprivacy (see entries on\n privacy\n and\n computing and moral responsibility).\n The formal approach can help in answering philosophical questions\nsuch as “Does more security automatically lead to less\nprivacy?”. \nIn the following example, the inspiration does not only flow from\nsocial problems to formal solutions, but also the other way, from\nsuccessful social practices to formal procedures. Many algorithms for\ndistributed computing are related to social protocols for\ncommunication in everyday life. An example is the use of a\n“talking stick” to regulate discussion and decision making\nin a group of peers, with the rules that the talking stick gets passed\naround and only the person who is holding the stick is allowed to talk\n(Nerburn 1999). \nA computer communication protocol based on this social procedure is\nthe token ring protocol. A token ring in\ndistributed computing is a network where each computer is connected to\nexactly two other computers in such a way that each computer is\nreachable in the network, and where a single “token”\ncirculates around the ring-shaped network. Communication can only be\ninitiated by the current owner of the token. \nSometimes the token gets lost through computer or network failure. In\nsuch cases the token has to be regenerated, with a guarantee that only\none computer has the token. This problem of regenerating the token in\na token ring is called the leader election\nproblem. Here is an algorithm for it: \nAssume that communication takes place clockwise, and each computer can\ndistinguish its clockwise neighbour from its counterclockwise\nneighbour. Assume that all computers have different identifiers\n(positive whole numbers) and each computer knows its identifier. \nEach computer sends its identifier around the ring. When a computer\n\\(c\\) receives an identifier, \\(c\\) compares it to its own. If the\nidentifier is greater than its own, \\(c\\) passes it on. If it is less\nthan its own, \\(c\\) discards it. If it is equal to its own, \\(c\\)\ndeclares itself to be the leader. \nIt is not hard to see that this guarantees the computer with the\nhighest identifier \\(i_{\\text{max}}\\) to become the leader (see Lynch\n1996). No assumptions need to be made\nabout the number of computers in the ring, nor about any computer\nknowing anything about the size of the ring or the identifiers of the\nother computers. A next stage of the protocol could be for the leader\nto send around a request to register as non-leader and halt. \nOne further level of abstraction is from distributed computers or\nprocesses to interacting intelligent agents, or multi-agent systems.\nThese agents can be computers, robots, humans, teams of humans, or\nsome mix of these. It is commonly assumed that the agents have a\ndegree of autonomy, that the agents have a restricted local view of\nthe system as a whole, and that there is no designated controller of\nthe whole system (see Wooldridge 2002 [2009]). \nMany social procedures are designed to create common knowledge (Lewis\n1969; van Ditmarsch et al. 2009; and entry on\n common knowledge).\n The old-fashioned ritual that takes place when you withdraw a large\namount of money from your bank account and have it paid out to you in\ncash by the cashier is an example. \nHow and whether common knowledge can be achieved depends on available\ncommunication facilities. Public announcement or publicly observable\nritual (the cashier ritual mentioned above) can create common\nknowledge. But, as Halpern and Moses (1984)\nproved, message exchange in a\ndistributed environment, where there is no guarantee that messages get\ndelivered, cannot. Halpern and Moses use the example of two generals\nwho are planning a coordinated attack on a city. The generals are on\ntwo hills on opposite sides of the city, each with their own army, and\nthey know that they can only succeed in capturing the city if their\ntwo armies attack at the same time. But the valley that separates the\ntwo hills is in enemy hands, and any messengers that are sent from one\narmy base to the other run a severe risk to get captured. The generals\nhave agreed on a joint attack, but still have to settle the time. So\nthe generals start sending messages, for example, “Let’s\nattack at 9:00 AM”. But they cannot be sure that the messengers\nsucceed in delivering their message. And if they get through, there is\nno guarantee that the message of acknowledgement will get delivered.\nAnd so on. \nEven if common knowledge is sometimes hard to achieve in practice, it\nserves as necessary presumption in regulating society. Roman lawgivers\nfound out long ago that if citizens within their jurisdiction could\nplead innocence because of being unaware of the law, no offender could\never get convicted. So they invented principles like\nIgnorantia legis neminem excusat,\n“ignorance of the law excuses no one”. Societies that\nabide by the rule of law have to be organized in such a way that\ncitizens in principle are in a position to know\nthe law. The laws have to be properly published and distributed, for\nexample, by being printed in a government gazette to which every\ncitizen has access. \nIn his book “Rational Ritual” (2001),\nMichael Suk-Young Chwe points out the\nimportance of the size of groups for which\ncommon knowledge gets established. A brand name that is common\nknowledge in a large group is worth a lot of money. Chwe analyzes the\nexample of advertisements broadcasted during the American football\nSuper Bowl. He compares the enormous cost of making something common\nknowledge by means of such advertisements to the obvious benefits.\nPart of the benefit is in the fact that the advertisements create\ncommon knowledge. An important consideration when deciding to buy a\nsmartphone of a particular brand, for example, is the knowledge that\nothers are going to buy the same model too. \nOf course in many social situations, you may want to prevent\ncommon knowledge from arising, for example, if you want to keep a\nsecret from certain others. There are also more interesting cases\nwhere everybody knows some fact, for example that a particular country\npossesses nuclear weapons, but where it would lead to political\nproblems to make this fact common knowledge by making a public\nannouncement. For a number of such social situations where maintaining\nprivacy and ignorance are crucial, see van Eijck and Verbrugge (2009).\nAn interesting recent development is the study of dynamic-epistemic\nlogic-based epistemic planning, which enables us to\nsynthesize communication protocols in order to create certain exact\nconfigurations of levels of higher-order knowledge within a group\n(Bolander and Andersen 2011, Löwe, Pacuit, and Witzel 2011). \nThe large field of game theory is extensively explained in other\nlemmas in this encyclopedia (see among others the entry on\n game theory).\n This field of research has been very active since the appearance of\nthe seminal book (Von Neumann and Morgenstern 1944). Similarly, social\nchoice theory and in particular voting theory (see entries on\n social choice theory\n and\n voting methods)\n were already thriving fields of research long before the term social\nsoftware came along. \nIt is useful to investigate how formal methods and an algorithmic\nperspective can help solve societal problems. For example, in the case\nof the famous prisoner’s dilemma (see entry on\n prisoner’s dilemma)\n it is interesting to try to design policies that make cheating the\nother agent less profitable by penalizing it. Notice that this\n“social software engineering” takes place at the\nmeta-level, on top of the level of the prisoners choosing their\nstrategies (van Eijck 2015). \nA related recent trend in game theory that is relevant for social\nsoftware, is to step away from solution concepts such as the Nash\nequilibrium and instead to focus on the process of rational\ndeliberation: the “theory of play” (see van Benthem,\nPacuit and Roy, 2011, as well as the entry\n logics for analyzing games).\n This type of research delineates both the normative principles\nguiding the players’ strategic reasoning, and the psychological\nphenomena explaining the differences between predicted and observed\nbehavior in games (Camerer 2003; Ghosh and Verbrugge 2018; Pacuit\n2015; Meijering et al. 2012, 2014; Top et al. 2018). \nIn Section 4.2 we briefly discussed the role of the study of knowledge\nand belief when analyzing social procedures. In this vein, the field\nof epistemic game theory focuses on agents’ beliefs about other\nagents’ strategies and those agents’ beliefs about other\nagents’ strategies, and so on, up to the idealized case of\ncommon knowledge among a group of agents that they are all rational\n(see the entry on\n epistemic foundations of game theory;\n Perea 2012; Brandenburger 2014). \nIt turns out that in voting theory in particular, it is useful to\ndesign a logic to explicitly model the knowledge that agents bring to\nbear when they are voting. It is especially interesting to model what\nhappens in a group when agents vote strategically by misrepresenting\ntheir own preferences in order to manipulate the outcome (van Eijck\n2015; van Ditmarsch et al. 2012). \nIn recent years in the research area of multi-agent systems, formal\napproaches to social procedures have also been used to help design\nactual software, for example for cooperative problem solving in teams,\ncoalition formation, knowledge fusion, auctions, and negotiations\namong software agents (Bulling et al. 2015; Chalkiadakis et al. 2011;\nDunin-Kęplicz and Verbrugge 2010; Pauly 2002; Shoham and\nLeyton-Brown 2009; Vazirani et al. 2007). This literature is mostly\nnormative in nature. \nIn contrast, another fascinating area of research, evolutionary game\ntheory (see entry on\n evolutionary game theory),\n investigates how features like altruism, social norms, moral behavior\nand cooperation could actually have evolved. This area combines both\nnormative and descriptive work (Axelrod 1984; Bowles and Gintis 2011;\nSigmund 2010). As a particular social software contribution to this\narea, Gärdenfors (2012) characterized how much cognition and\ncommunication are required for several kinds of cooperation, from\nsimple flocking behavior, through reciprocal altruism\n(“I’ll scratch your back if you scratch mine”), up\nto fully fledged teamwork. \nIn conclusion, the formal perspective on social procedures and\nintelligent interaction, which emphasizes algorithms and information,\nhas produced a wide variety of important insights. It has also led to\ninteresting philosophical discussions. The main challenge for the\nfuture appears to be to unify this currently relatively scattered\nfield, in which many contributors do not seem to be aware of relevant\nwork in other subfields.","contact.mail":"L.C.Verbrugge@rug.nl","contact.domain":"rug.nl"}]
