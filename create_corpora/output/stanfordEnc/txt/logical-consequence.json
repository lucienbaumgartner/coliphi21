[{"date.published":"2005-01-07","date.changed":"2019-02-21","url":"https://plato.stanford.edu/entries/logical-consequence/","author1":"Jc Beall","author2":"Greg Restall","author1.info":"http://entailments.net","author2.info":"http://consequently.org/","entry":"logical-consequence","body.text":"\n\n\nA good argument is one whose conclusions follow from its premises; its\nconclusions are consequences of its premises. But in what\nsense do conclusions follow from premises? What is it for a\nconclusion to be a consequence of premises? Those questions,\nin many respects, are at the heart of logic (as a philosophical\ndiscipline). Consider the following argument:\n\nIf we charge high fees for university, only the rich will enroll.\n\nWe charge high fees for university.\n\nTherefore, only the rich will enroll.\n\nThere are many different things one can say about this argument, but\nmany agree that if we do not equivocate (if the terms mean the same\nthing in the premises and the conclusion) then the argument is\nvalid, that is, the conclusion follows deductively from the\npremises. This does not mean that the conclusion is true. Perhaps the\npremises are not true. However, if the premises are true, then the\nconclusion is also true, as a matter of logic. This entry is about the\nrelation between premises and conclusions in valid arguments.\n\n\nContemporary analyses of the concept of consequence—of the\nfollows from relation—take it to be both\nnecessary and formal, with such answers often being\nexplicated via proofs or models (or, in some cases,\nboth). Our aim in this article is to provide a brief characterisation\nof some of the notions that play a central role in contemporary\naccounts of logical consequence.\n\n\nWe should note that we only highlight a few of the\nphilosophical aspects of logical consequence, leaving out\nalmost all technical details, and also leaving out a large number of\nphilosophical debates about the topic. Our rationale for doing as much\nis that one will get the technical details, and the particular\nphilosophical issues that motivated them, from looking at specific\nlogics—specific theories of logical consequence (e.g.,\nrelevant logics, substructural logics, non-monotonic logics, dynamic\nlogics, modal logics, theories of quantification, and so on).\n(Moreover, debates about almost any feature of\nlanguage—structure versus form of sentences, propositions,\ncontext sensitivity, meaning, even truth—are relevant to debates\nabout logical consequence, making an exhaustive discussion practically\nimpossible.) Our aim here is simply to touch on a few of the very\nbasic issues that are central to logical consequence.\n\nSome arguments are such that the (joint) truth of the premises is\nnecessarily sufficient for the truth of the conclusions. In\nthe sense of logical consequence central to the current\ntradition, such “necessary sufficiency” distinguishes\ndeductive validity from inductive validity. In inductively\nvalid arguments, the (joint) truth of the premises is very likely\n(but not necessarily) sufficient for the truth of the conclusion.\nAn inductively valid argument is such that, as it is often put, its\npremises make its conclusion more likely or more reasonable (even\nthough the conclusion may well be untrue given the joint truth of the\npremises). The argument \nis not deductively valid because the premises are not necessarily\nsufficient for the conclusion. Smoothy may well be a black swan. \nDistinctions can be drawn between different inductive arguments. Some\ninductive arguments seem quite reasonable, and others are less so.\nThere are many different ways to attempt to analyse inductive\nconsequence. We might consider the degree to which the premises make\nthe conclusion more likely (a probabilistic reading), or we\nmight check whether the most normal circumstances in which\nthe premises are true render the conclusion true as well. (This leads\nto some kinds of default or non-monotonic inference.) The field of\ninductive consequence is difficult and important, but we shall leave\nthat topic here and focus on deductive validity. \n(See the entries on\n inductive logic\n and\n non-monotonic logic\n for more information on these topics.) \nThe constraint of necessity is not sufficient to settle the\nnotion of deductive validity, for the notion of necessity may\nalso be fleshed out in a number of ways. To say that a conclusion\nnecessarily follows from the premises is to say that the argument is\nsomehow exceptionless, but there are many different ways to\nmake that idea precise. \nA first stab at the notion might use what we now call metaphysical\nnecessity. Perhaps an argument is valid if it is (metaphysically)\nimpossible for the premises to be true and the conclusion to be\nuntrue, valid if—holding fixed the interpretations of premises\nand conclusion—in every possible world in which the premises\nhold, so does the conclusion. This constraint is plausibly thought to\nbe a necessary condition for logical consequence (if it could\nbe that the premises are true and the conclusion isn’t,\nthen there is no doubt that the conclusion does not follow from the\npremises); however, on most accounts of logical consequence, it is not\na sufficient condition for validity. Many admit the existence of a\nposteriori necessities, such as the claim that water is\nH\\(_2\\)O. If that claim is necessary, then the argument: \nis necessarily truth preserving, but it seems a long way from being\ndeductively valid. It was a genuine discovery that water is\nH\\(_2\\)O, one that required significant empirical investigation.\nWhile there may be genuine discoveries of valid arguments that we had\nnot previously recognised as such, it is another thing entirely to\nthink that these discoveries require empirical investigation. \nAn alternative line on the requisite sort of necessity turns\nto conceptual necessity. On this line, the conclusion of (3)\nis not a consequence of its premise given that it is not a conceptual\ntruth that water is H\\(_2\\)O. The concept water and the\nconcept \\(H_2O\\) happen to pick out the same property,\nbut this agreement is determined partially by the world. \nA similar picture of logic takes consequence to be a matter of what is\nanalytically true, and it is not an analytic truth that water\nis H\\(_2\\)O. The word “water” and the formula\n“H\\(_2\\)O” agree in extension (and necessarily so)\nbut they do not agree in meaning. \nIf metaphysical necessity is too coarse a notion to determine logical\nconsequence (since it may be taken to render too many arguments\ndeductively valid), an appeal to conceptual or analytic necessity\nmight seem to be a better route. The trouble, as Quine argued, is that\nthe distinction between analytic and synthetic (and similarly,\nconceptual and non-conceptual) truths is not as straightforward as we\nmight have thought in the beginning of the 20th Century. (See the\nentry on the\n analytic/synthetic distinction.)\n Furthermore many arguments seem to be truth-preserving on the basis\nof analysis alone: \nOne can understand that the conclusion follows from the premises, on\nthe basis of one’s understanding of the concepts involved. One\nneed not know anything about the identity of Peter, Greg’s\ncousin. Still, many have thought that (4) is not deductively valid,\ndespite its credentials as truth-preserving on analytic or conceptual\ngrounds. It is not quite as general as it could be because it is not\nas formal as it could be. The argument succeeds only because\nof the particular details of family concepts involved. \nA further possibility for carving out the distinctive notion of\nnecessity grounding logical consequence is the notion of\napriority. Deductively valid arguments, whatever they are,\ncan be known to be so without recourse to experience, so they must be\nknowable a priori. A constraint of apriority certainly seems\nto rule argument (3) out as deductively valid, and rightly so.\nHowever, it will not do to rule out argument (4). If we take arguments\nlike (4) to turn not on matters of deductive validity but something\nelse, such as an a priori knowable definition, then we must\nlook elsewhere for a characterisation of logical consequence. \nThe strongest and most widespread proposal for finding a narrower\ncriterion for logical consequence is the appeal to formality.\nThe step in (4) from “Peter is Greg’s mother’s\nbrother’s son” to “Peter is my cousin” is a\nmaterial consequence and not a formal one, because to make\nthe step from the premise to the conclusion we need more than the\nstructure or form of the claims involved: we need to\nunderstand their contents too. \nWhat could the distinction between form and content\nmean? We mean to say that consequence is formal if it depends on the\nform and not the substance of the claims involved.\nBut how is that to be understood? We will give at most a sketch,\nwhich, again, can be filled out in a number of ways. \nThe obvious first step is to notice that all presentations of the\nrules of logical consequence rely on\n schemes.\n Aristotle’s syllogistic is a proud example. \nFerio: No \\(F\\) is \\(G\\). Some \\(H\\) is \\(G\\). Therefore\nsome \\(H\\) is not \\(F\\).\n \nInference schemes, like the one above, display the structure of valid\narguments. Perhaps to say that an argument is formally valid is to say\nthat it falls under some general scheme of which every instance is\nvalid, such as Ferio. \nThat, too, is an incomplete specification of formality. The material\nargument (4) is an instance of: \nevery instance of which is valid. We must say more to explain why some\nschemes count as properly formal (and hence a sufficient ground for\nlogical consequence) and others do not. A general answer will\narticulate the notion of\n logical form,\n which is an important issue in its own right (involving the notion of\n logical constants,\n among other things). Instead of exploring the details of different\ncandidates for logical form, we will mention different proposals about\nthe point of the exercise. \nWhat is the point in demanding that validity be underwritten by a\nnotion of logical form? There are at least three distinct proposals\nfor the required notion of formality, and each provides a different\nkind of answer to that question. \nWe might take the formal rules of logic to be totally neutral\nwith respect to particular features of objects. Laws of\nlogic, on this view, must abstract away from particular features of\nobjects. Logic is formal in that it is totally general. One\nway to characterise what counts as a totally general notion\nis by way of permutations. Tarski proposed (1986) that an operation or\npredicate on a domain counted as general (or logical) if it was\ninvariant under permutations of objects. (A permutation of a\ncollection of objects assigns for each object a unique object in that\ncollection, such that no object is assigned more than once. A\npermutation of \\(\\{a, b, c, d\\}\\) might, for example, assign \\(b\\) to\n\\(a, d\\) to \\(b, c\\) to \\(c\\) and \\(a\\) to \\(d\\).) A \\(2\\)-place\npredicate \\(R\\) is invariant under permutation if for any permutation\n\\(p\\), whenever \\(Rxy\\) holds, \\(Rp(x)p(y)\\) holds too. You can\nsee that the identity relation is permutation\ninvariant—if \\(x = y\\) then \\(p(x) = p(y)\\)—but\nthe mother-of relation is not. We may have permutations \\(p\\)\nsuch that even though \\(x\\) is the mother of \\(y\\), \\(p(x)\\) is not the\nmother of \\(p(y)\\). We may use permutation to characterise logicality\nfor more than predicates too: we may say that a one-place sentential\nconnective ‘\\(\\bullet\\)’ is permutation invariant if and\nonly if, for all \\(A\\), \\(p(\\bullet A)\\) is true if and only if \\(\\bullet\np(A)\\) is true. Defining this rigorously requires establishing how\npermutations operate on sentences, and this takes us beyond the scope\nof this article. Suffice to say, an operation such as negation passes\nthe test of invariance, but an operation such as ‘JC believes\nthat’ fails. \nA closely related analysis for formality is that formal rules are\ntotally abstract. They abstract away from the semantic\ncontent of thoughts or claims, to leave only semantic\nstructure. The terms ‘mother’ and ‘cousin’\nenter essentially into argument (5). On this view, expressions such as\npropositional connectives and quantifiers do not add new semantic\ncontent to expressions, but instead add only ways to combine and\nstructure semantic content. Expressions like ‘mother’ and\n‘cousin’, by contrast, add new semantic content. \nAnother way to draw the distinction (or to perhaps to draw a different\ndistinction) is to take the formal rules of logic to be\nconstitutitive norms for thought, regardless of its subject\nmatter. It is plausible to hold that no matter what we think about, it\nmakes sense to conjoin, disjoin and negate our thoughts to make new\nthoughts. It might also make sense to quantify. The behaviour, then,\nof logical vocabulary may be used to structure and regulate\nany kind of theory, and the norms governing logical\nvocabulary apply totally universally. The norms of valid argument, on\nthis picture, are those norms that apply to thought irrespective of\nthe particular content of that\n thought.[1] \nTwentieth Century technical work on the notion of logical\nconsequence has centered on two different mathematical tools, proof\ntheory and model theory. Each of these can be seen as explicating\ndifferent aspects of the concept of logical consequence, backed by\ndifferent philosophical perspectives. \nWe have characterized logical consequence as necessary truth\npreservation in virtue of form. This idea can be explicated\nformally. One can use mathematical structures to account for the range\nof possibilities over which truth needs to be preserved. The formality\nof logical consequence can be explicated formally by giving a special\nrole to the logical vocabulary, taken as constituting the forms of\nsentences. Let us see how model theory attends to both these\ntasks. \nThe model-centered approach to logical consequence takes the\nvalidity of an argument to be absence of counterexample. A\ncounterexample to an argument is, in general, some way of\nmanifesting the manner in which the premises of the argument\nfail to lead to a conclusion. One way to do this is to\nprovide an argument of the same form for which the premises are\nclearly true and the conclusion is clearly false. Another way to do\nthis is to provide a circumstance in which the premises are\ntrue and the conclusion is false. In the contemporary literature, the\nintuitive idea of a counterexample is developed into a theory of\nmodels. \nThe exact structure of a model will depend on the kind of language at\nhand (extensional/intensional, first/higher-order, etc.). A model for\nan extensional first order language consists of a non-empty set which\nconstitutes the domain, and an interpretation\nfunction, which assigns to each nonlogical term an extension over\nthe domain—any extension agreeing with its semantic type\n(individual constants are assigned elements of the domain, function\nsymbols are assigned functions from the domain to itself, one-place\nfirst-order predicates are assigned subsets of the domain, etc.). \nThe contemporary model-theoretic definition of logical consequence\ntraces back to Tarski (1936). It builds on the definition of truth\nin a model given by Tarski in (1935). Tarski defines a true\nsentence in a model recursively, by giving truth (or\nsatisfaction) conditions on the logical vocabulary. A conjunction, for\nexample, is true in a model if and only if both conjuncts are true in\nthat model. A universally quantified sentence \\(\\forall xFx\\) is\ntrue in a model if and only if each instance is true in the model.\n(Or, on the Tarskian account of satisfaction, if and only if the open\nsentence \\(Fx\\) is satisfied by every object in the domain of the\nmodel. For detail on how this is accomplished, see the entry on\n Tarski’s truth definitions.)\n Now we can define logical consequence as preservation of truth over\nmodels: an argument is valid if in any model in which the\npremises are true (or in any interpretation of the premises\naccording to which they are true), the conclusion is true too. \nThe model-theoretic definition is one of the most successful\nmathematical explications of a philosophical concept to date. It\npromises to capture both the necessity of logical consequence—by\nlooking at truth over all models, and the formality of logical\nconsequence—by varying the interpretations of the nonlogical\nvocabulary across models: an argument is valid no matter what the\nnonlogical vocabulary means. Yet, models are just sets, which are\nmerely mathematical objects. How do they account for the range of\npossibilities, or circumstances required? John Etchemendy (1990)\noffers two perspectives for understanding models. On the\nrepresentational approach, each model is taken to represent a\npossible world. If an argument preserves truth over models, we are\nthen guaranteed that it preserves truth over possible worlds, and if\nwe accept the identification of necessity with truth in all possible\nworlds, we have the necessary truth preservation of logical\nconsequence. The problem with this approach is that it identifies\nlogical consequence with metaphysical consequence, and it gives no\naccount of the formality of logical consequence. On the\nrepresentational approach, there is no basis for a distinction between\nthe logical and the nonlogical vocabulary, and there is no explanation\nof why the interpretations of the nonlogical vocabulary are maximally\nvaried. The second perspective on models is afforded by the\ninterpretational approach, by which each model assigns\nextensions to the nonlogical vocabulary from the actual world: what\nvaries between models is not the world depicted but the meaning of the\nterms. Here, the worry is that necessity isn’t captured. For\ninstance, on the usual division of the vocabulary into logical and\nnonlogical, identity is considered a logical term, and can be used to\nform statements about the cardinality of the domain (e.g.,\n‘‘there are at least two things’’) which are\ntrue under every reinterpretation, but perhaps are not necessarily\ntrue. On this approach, there is no basis for considering models with\ndomains other than the universe of what actually exists, and\nspecifically, there is no explanation of model theory’s use of\ndomains of different sizes. Each approach, as described here, is\nflawed with respect to our analysis of logical consequence as\nnecessary and formal. The interpretational approach, by looking only\nat the actual world fails to account for necessity, and the\nrepresentational approach fails to account for formality (for details,\nsee Etchemendy 1990, Sher 1996, and Shapiro 1998, and for refinements\nsee Etchemendy 2008). A possible response to Etchemendy would be to\nblend the representational and the interpretational perspectives,\nviewing each model as representing a possible world under a\nre-interpretation of the nonlogical vocabulary (Shapiro 1998, see also\nSher 1996 and Hanson 1997 for alternative responses). \nOne of the main challenges set by the model-theoretic definition of\nlogical consequence is to distinguish between the logical and the\nnonlogical vocabulary. The logical vocabulary is defined in all models\nby the recursive clauses (such as those mentioned above for\nconjunction and the universal quantifier), and in that sense its\nmeaning is fixed. The choice of the logical vocabulary determines the\nclass of models considered when evaluating validity, and thus it\ndetermines the class of the logically valid arguments. Now, while each\nformal language is typically defined with a choice of a logical\nvocabulary, one can ask for a more principled characterization of\nlogical vocabulary. Tarski left the question of a principled\ndistinction open in his 1936, and only gave the lines of a\nrelativistic stance, by which different choices of the logical\nvocabulary may be admissible. Others have proposed criteria for\nlogicality, demanding that logical constants be appropriately formal,\ngeneral or topic neutral (for references and details, see the entry on\n logical constants).\n Note that a choice of the logical vocabulary is a special case of\nsetting constraints on the class of models to be used. It has been\nsuggested that the focus on criteria for the logical vocabulary misses\nthis point, and that more generally the question is which semantic\nconstraints should be adopted, limiting the admissible\nmodels for a language (Sagi 2014a, Zinke 2017).  \nAnother challenge faced by the model-theoretic account is due to the\nlimitations of its set-theoretic basis. Recall that models are sets.\nThe worry is that truth-preservation over models might not guarantee\nnecessary truth preservation—moreover, it might not even\nguarantee material truth preservation (truth preservation in the\nactual world). The reason is that each model domain is a set, but the\nactual world presumably contains all sets, and as a collection which\nincludes all sets is too ‘‘large’’ to be a set\n(it constitutes a proper class), the actual world is not\naccounted for by any model (see Shapiro 1987). \nOne way of dealing with this worry is to employ external means, such\nas proof theory, in support of the model-theoretic definition. This is\ndone by Georg Kreisel in his “squeezing argument”, which\nwe present in section 3.3. Kreisel’s argument crucially depends\non the language in question having a sound and complete proof system.\nAnother option is to use set-theoretic reflection principles.\nGenerally speaking, reflection principles state that whatever is true\nof the universe of sets, is already true in an initial segment thereof\n(which is always a set). If reflection principles are accepted, then\nat least as concerns the relevant language, one can argue that an\nargument is valid if and only if there is no counter set-model (see\nKreisel 1967, Shapiro 1987, Kennedy & Väänänen\n2017). \nFinally, the explanation of logical consequence in terms of truth in\nmodels is typically preferred by “Realists”, who take\ntruth of sentences to be independent of what can be known. Explaining\nlogical consequence in terms of truth in models is rather close to\nexplaining logical consequence in terms of truth, and the\nanalysis of truth-in-a-model is sometimes taken to be an explication\nof truth in terms of correspondence, a typically Realist notion. Some,\nhowever, view logical consequence as having an indispensable epistemic\ncomponent, having to do with the way we establish the conclusion on\nthe basis of the premises. “Anti-realists”, who eschew\ntaking truth (or at least, correspondence-truth) as an explanatory\nnotion, will typically prefer explaining logical consequence in terms\nof proof—to which we turn next. \nOn the proof-centered approach to logical consequence, the\nvalidity of an argument amounts to there being a proof of the\nconclusions from the premises. Exactly what proofs are is a\nbig issue but the idea is fairly plain (at least if you have been\nexposed to some proof system or other). Proofs are made up of small\nsteps, the primitive inference principles of the proof system. The\n20th Century has seen very many different kinds of proof systems, from\nso-called Hilbert proofs, with simple rules and complex axioms, to\nnatural deduction systems, with few (or even no) axioms and very many\nrules. \nThe proof-centered approach highlights epistemic aspects of logical\nconsequence. A proof does not merely attest to the validity of the\nargument: it provides the steps by which we can establish this\nvalidity. And so, if a reasoner has grounds for the premises of an\nargument, and they infer the conclusion via a series of applications\nof valid inference rules, they thereby obtain grounds for the\nconclusion (see Prawitz 2012). One can go further and subscribe to\ninferentialism, the view by which the meaning of expressions\nis determined by their role in inference. The idea is that our use of\na linguistic expression is regulated by rules, and mastering the rules\nsuffices for understanding the expression. This gives us a preliminary\nrestriction on what semantic values of expressions can be: they cannot\nmake any distinctions not accounted for by the rules. One can then go\neven further, and reject any kind of meaning that goes beyond the\nrules—adopting the later Wittgensteinian slogan “meaning\nis use”. This view is favored by anti-realists about meaning,\nsince meaning on this view is fully explained by what is knowable.\n \nThe condition of necessity on logical consequence obtains a new\ninterpretation in the proof-centered approach. The condition can be\nreformulated thus: in a valid argument, the truth of the conclusion\nfollows from the truth of the premises by necessity of thought\n(Prawitz 2005). Let us parse this formulation. Truth is\nunderstood constructively: sentences are true in virtue of\npotential evidence for them, and the facts described by true\nsentences are thus conceived as constructed in terms of potential\nevidence. (Note that one can completely forgo reference to truth, and\ninstead speak of assertibility or acceptance of sentences.) Now, the\nnecessity of thought by which an argument is valid is explained by the\nmeaning of the terms involved, which compels us to accept the truth of\nthe conclusion given the truth of the premises. Meanings of\nexpressions, in turn, are understood through the rules governing their\nuse: the usual truth conditions give their way to proof\nconditions of formulas containing an expression. \nOne can thus provide a proof-theoretic semantics for a\nlanguage (Schroeder-Heister 1991). When presenting his system of\nnatural deduction, Gentzen remarked that the introduction rules for\nthe logical expressions represent their “definitions,” and\nthe elimination rules are consequences of those definitions (Gentzen\n1933). For example, the introduction rule for conjunction dictates\nthat a conjunction \\(A \\amp B\\) may be inferred from both\nconjuncts \\(A\\) and \\(B\\), and this rule captures the\nmeaning of the connective. Conversely, the elimination rule for\nconjunction says that from \\(A \\amp B\\) one may infer both\n\\(A\\) and \\(B\\). The universal quantifier rules tell us that\nfrom the universally quantified claim \\(\\forall xFx\\) we can\ninfer any instance \\(Fa\\), and we can infer \\(\\forall xFx\\)\nfrom the instance \\(Fa\\), provided that no other assumption has\nbeen made involving the name \\(a\\). Under certain requirements,\none can show that the elimination rule is validated by the\nintroduction rule. \nOne of the main challenges for the proof-centered approach is that of\ndistinguishing between rules that are genuinely meaning-determining\nand those that are not. Some rules for connectives, if added to a\nsystem, would lead to triviality. Prior (1960) offered the following\nrules for a connective “\\(\\tonk\\)”. Its introduction rule says\nthat from \\(A\\) one can infer \\(A \\tonk B\\), and its\nelimination rule says that from \\(A \\tonk B\\) one can infer\n\\(B\\). With the introduction of these rules, the system becomes\ntrivial so long as at least one thing is provable, since from any\nassumption \\(A\\) one can derive any conclusion \\(B\\). Some\nconstraints have to posed on inference rules, and much of subsequent\nliterature has been concerned with these constraints (Belnap 1962,\nDummett 1991, Prawitz 1974). \nTo render the notions of proof and validity more systematized, Prawitz\nhas introduced the notion of a canonical proof. A sentence\nmight be proved in several different ways, but it is the direct, or\ncanonical proof that is constitutive of its meaning. A canonical proof\nis a proof whose last step is an application of an introduction rule,\nand its immediate subproofs are canonical (unless they have free\nvariables or undischarged assumptions—for details see Prawitz\n2005). A canonical proof is conceived as giving direct evidence for\nthe sentence proved, as it establishes the truth of the sentence by\nthe rule constitutive of the meaning of its connectives. For more on\ncanonical proofs and the ways other proofs can be reduced to them, see\nthe entry on\n proof-theoretic semantics. \nWe have indicated how the condition of necessity can be interpreted in\nthe proof-centered approach. The condition of formality can be\naccounted for as well. Note that on the present perspective as well,\nthere is a division of the vocabulary into logical and nonlogical.\nThis division can be used to define substitutions of an\nargument. A substitution of an argument is an argument obtained from\nthe original one by replacing the nonlogical terms with terms of the\nsame syntactic category in a uniform manner. A definition of validity\nthat respects the condition of formality will entail that an argument\nis valid if and only if all its substitutions are valid, and in the\npresent context, this is a requirement that there is a proof of all\nits substitutions. This condition is satisfied in any proof system\nwhere rules are given only for the logical vocabulary. Of course, in\nthe proof-centered approach as well, there is a question of\ndistinguishing the logical vocabulary (see the entry on\n logical constants). \nFinally, it should be noted that a proof theoretic semantics can be\ngiven for classical logic as well as a variety of non-classical\nlogics. However, due to the epistemic anti-realist attitude that lies\nat the basis of the proof-centered approach, its proponents have\ntypically advocated\n intuitionistic logic\n (see Dummett 1991). \nFor more on the proof-centered perspective and on proof-theoretic\nsemantics, see the entry on\n proof-theoretic semantics. \nThe proof-theoretic and model-theoretic perspectives have been\nconsidered as providing rival accounts of logical consequence.\nHowever, one can also view “logical consequence” and\n“validity” as expressing cluster concepts:\n“A number of different, closely related notions go by those\nnames. They invoke matters of modality, meaning, effectiveness,\njustification, rationality, and form” (Shapiro 2014). One can\nalso note that the division between the model-theoretic and the\nproof-theoretic perspectives is a modern one, and it was only made\npossible when tools for metamathematical investigations were\ndeveloped. Frege’s Begriffsschrift, for instance, which\npredates the development of those tools, is formulated as an axiomatic\nproof system, but the meanings of the connectives are given via truth\nconditions. \nOnce there are two different analyses of a relation of logical\nconsequence, one can ask about possible interactions, and we’ll\ndo that next. One can also ask what general features such a relation\nhas independently of its analysis as proof-theoretic or\nmodel-theoretic. One way of answering this question goes back to\n Tarski,\n who introduced the notion of consequence operations. For our\npurposes, we note only some features of such operations. Let\n\\(Cn(X)\\) be the consequences of \\(X\\). (One can think of\nthe operator \\(Cn\\) as deriving from a prior consequence relation\nwhich, when taking \\(X\\) as ‘input (or premise)’ set,\ntells you what follows from \\(X\\). But one can also see the\n‘process’ in reverse, and a key insight is that\nconsequence relations and corresponding operations are, in effect,\ninterdefinable. See the entry on\n algebraic propositional logic\n for details.) Among some of the minimal conditions one might impose\non a consequence relation are the following two (from Tarski): \nIf you think of \\(X\\) as a set of claims, then the first\ncondition tells you that the consequences of a set of claims includes\nthe claims themselves. The second condition demands that the\nconsequences of \\(X\\) just are the consequences of the\nconsequences of \\(X\\). Both of these conditions can be motivated\nfrom reflection on the model-theoretic and proof-theoretic approaches;\nand there are other such conditions too. (For a general discussion,\nsee the entry on\n algebraic propositional logic.)\n But as with many foundation issues (e.g., ‘what are the\nessential features of consequence relations in general?’), even\nsuch minimal conditions are contentious in philosophical logic and the\nphilosophy of logic. For example, some might take condition (2) to be\nobjectionable on the grounds that, for reasons of vagueness (or more),\nimportant consequence relations over natural languages (however\nformalized) are not generally transitive in ways reflected in (2).\n(See Tennant 1994, Cobreros et al 2012, and Ripley 2013, for\nphilosophical motivations against transitive consequence.) But we\nleave these issues for more advanced discussion. \nWhile the philosophical divide between Realists and Anti-realists\nremains vast, proof-centered and model-centered accounts of\nconsequence have been united (at least with respect to extension) in\nmany cases. The great soundness and completeness theorems for\ndifferent proof systems (or, from the other angle, for different\nmodel-theoretic semantics) show that, in an important sense, the two\napproaches often coincide, at least in extension. A proof system is\nsound with respect to a model-theoretic semantics if every\nargument that has a proof in the system is model-theoretically valid.\nA proof system is complete with respect to a model-theoretic\nsemantics if every model-theoretically valid argument has a proof in\nthe system. While soundness is a principal condition on any proof\nsystem worth its name, completeness cannot always be expected.\nAdmittedly, these definitions are biased towards the model-theoretic\nperspective: the model-theoretic semantic sets the standard to what is\n“sound” and “complete”. Leaving terminological\nissues aside, if a proof system is both sound and complete with\nrespect to a model-theoretic semantics (as, significantly, in the case\nof first order predicate logic), then the proof system and the\nmodel-theoretic semantics agree on which arguments are valid. \nCompleteness results can also support the adequacy of the\nmodel-theoretic account, as in Kreisel’s “squeezing\nargument”. We have noted a weakness of the model-theoretic\naccount: all models are sets, and so it might be that no model\nrepresents the actual world. Kreisel has shown that if we have a proof\nsystem that is “intuitively sound” and is complete with\nrespect to the model-theoretic semantics, we won’t be missing\nany models: every intuitively valid argument will have a\ncounter-model. Let \\(L\\) be a first order language. Let \\(Val\\) denote\nthe set of intuitively valid arguments in \\(L\\). Kreisel takes\nintuitive validity to be preservation of truth across all structures\n(whether sets or not). His analysis privileges the modal analysis of\nlogical consequence—but note that the weakness we are addressing\nis that considering set-theoretic structures might not be enough. Let\n\\(V\\) denote the set of model-theoretic validities in \\(L\\): arguments\nthat preserve truth over models. Let \\(D\\) be the set of deductively\nvalid arguments, by some accepted proof system for first order\nlogic. Now, any such proof system is “intuitively sound”,\nmeaning that what is deductively valid by the system is intuitively\nvalid. This gives us \\(D \\subseteq Val\\). And obviously, by the\ndefinitions we’ve given, \\(Val \\subseteq V\\), since an\nargument that preserves truth over all structures will preserve truth\nover set-structures. \nBy the completeness result for first order logic, we have: \\(V\\)\n&subseteq; \\(D\\). Putting the three inclusions together (the\n“squeeze”), we get that all three sets must be equal, and\nin particular: \\(V = Val\\). In this way, we’ve proven\nthat if there is some structure that is a counterexample to a first\norder argument, then there is a set-theoretic one. \nAnother arena for the interaction between the proof-theoretic and the\nmodel-theoretic perspectives has to do with the definition of the\nlogical vocabulary. For example, one can hold a “moderate”\ninferentialist view which defines the meanings of logical connectives\nthrough their semantics (i.e. truth conditions) but demands that the\nmeaning of a connective be determined by inference rules. Carnap has\nfamously shown that the classical inference rules allow non-standard\ninterpretations of the logical expressions (Carnap 1943). Much recent\nwork in the field has been devoted to the exact nature and extent of\nCarnap’s categoricity problem (Raatikainen 2008, Murzi and\nHjortland 2009, Woods 2012, Garson 2013, Peregrin 2014, Bonnay and\nWesterståhl 2016. See also the entry on\n sentence connectives in formal logic). \nFinally, we should note that while model theory and proof theory are\nthe most prominent contenders for the explication of logical\nconsequence, there are alternative frameworks for formal semantics\nsuch as\n algebraic semantics,\n game-theoretic semantics and\n dynamic semantics\n (see Wansig 2000). \nThere has also been dissent, even in Aristotle’s day, as to the\n“shape” of logical consequence. In particular, there is no\nsettled consensus on the number of premises or conclusions appropriate\nto “tie together” the consequence relation. \nIn Aristotle’s syllogistic, a syllogism relates two or more\npremises and a single conclusion. In fact, Aristotle focuses on\narguments with exactly two premises (the major premise and the minor\npremise), but nothing in his definition forbids arguments with three\nor more premises. Surely, such arguments should be permitted: if, for\nexample, we have one syllogism from two premises \\(A\\) and\n\\(B\\) to a conclusion \\(C\\), and we have another from the\npremises \\(C\\) and \\(D\\) to the conclusion \\(E\\), then\nin some sense, the longer argument from premises \\(A,\nB\\) and \\(D\\) to conclusion \\(E\\) is a good one. It\nis found by chaining together the two smaller arguments. If the two\noriginal arguments are formally valid, then so too is the longer\nargument from three premises. On the other hand, on a common reading\nof Aristotle’s definition of syllogism, one-premise\narguments are ruled out—but this seems arbitrary, as even\nAristotle’s own “conversion” inferences are thus\nexcluded.  \nFor such reasons, many have taken the relation of logical consequence\nto pair an arbitrary (possibly infinite) collection of\npremises with a single conclusion. This account has the added virtue\nof having the special case of an empty collection of premises.\nArguments to a conclusion from no premises whatsoever are those in\nwhich the conclusion is true by logic alone. Such\n“conclusions” are logical truths (sometimes\ntautologies) or, on the proof-centered approach,\ntheorems. \nPerhaps there is a reason to allow the notion of logical consequence\nto apply even more broadly. In Gentzen’s proof theory for\nclassical logic, a notion of consequence is defined to hold between\nmultiple premises and multiple conclusions. The argument from a set\n\\(X\\) of premises to a set \\(Y\\) of conclusions is valid if\nthe truth of every member of \\(X\\) guarantees (in the relevant\nsense) the truth of some member of \\(Y\\). There is no doubt that\nthis is formally perspicuous, but the philosophical applicability of\nthe multiple premise—multiple conclusion sense of logical\nconsequence remains an open philosophical issue. In particular, those\nanti-Realists who take logical consequence to be defined in terms of\nproof (such as Michael Dummett) reject a multiple conclusion\nanalysis of logical consequence. For an Anti-realist, who takes good\ninference to be characterised by the way warrant is\ntransmitted from premise to conclusion, it seems that a multiple\nconclusion analysis of logical consequence is out of the question. In\na multiple conclusion argument from \\(A\\) to \\(B,\nC\\), any warrant we have for \\(A\\) does not necessarily\ntransmit to \\(B\\) or \\(C\\): the only conclusion we are\nwarranted to draw is the disjunction \\(B\\) or \\(C\\), so it seems for\nan analysis of consequence in terms of warrant we need to understand\nsome logical vocabulary (in this case, disjunction) in order to\nunderstand the consequence relation. This is unacceptable if we hope\nto use logical consequence as a tool to define that logical\nvocabulary. No such problems appear to arise in a single conclusion\nsetting. (However, see Restall (2005) for a defence of multiple\nconclusion consequence for Anti-realists; and see Beall (2011) for a\ndefence of certain sub-classical multiple-conclusion logics in the\nservice of non-classical solutions to paradox.) \nAnother line along which the notion has been broadened (or along which\nsome have sought to broaden it) involves recent work on\n substructural logic.\n The proposal here is that we may consider doing without some of the\nstandard rules governing the way that premises (or conclusions) of an\nargument may be combined. Structural rules deal with the\nshape or structure of an argument in the sense of\nthe way that the premises and conclusions are collected together, and\nnot the way that those statements are constructed. The structural rule\nof weakening for example, states that if an argument from\nsome collection of premises \\(X\\) to a conclusion \\(C\\) is\nvalid, then the argument from \\(X\\) together with another premise\n\\(A\\) to the conclusion \\(C\\) is also valid. This rule has\nseemed problematic to some (chiefly on the grounds that the extra\npremise \\(A\\) need not be used in the derivation of the\nconclusion \\(C\\) and hence, that \\(C\\) does not follow\nfrom the premises \\(X,A\\) in the appropriate sense).\n Relevant logics\n are designed to respect this thought, and do without the structural\nrule of weakening. (For the proof-theoretic picture, see Negri and von\nPlato (2001).)  \nOther structural rules are also a called into question. Another\npossible application of substructural logic is found in the analysis\nof paradoxes such as\n Curry’s paradox.\n A crucial move in the reasoning in Curry’s paradox and other\nparadoxes like it seems to require the step reducing two applications\nof an assumption to a single one (which is then discharged). According\nto some, this step is problematic, and so, they must distinguish an\nargument from \\(A\\) to \\(B\\) and an argument from\n\\(A, A\\) to \\(B\\). The rule of contraction\nis rejected. \nIn yet other examples, the order in which premises are used\nis important and an argument from \\(A, B\\) to \\(C\\)\nis to be distinguished from an argument from \\(B, A\\) to\n\\(C\\). (For more details, consult the entry on\n substructural logics.)\n There is no doubt that the formal systems of substructural logics are\nelegant and interesting, but the case for the philosophical importance\nand applicability of substructural logics is not closed. \nWe have touched only on a few central aspects of the notion of logical\nconsequence, leaving further issues, debates and, in particular,\ndetails to emerge from particular accounts (accounts that are\nwell-represented in this encyclopedia). But even a quick glance at the\nrelated links section (below) will attest to a fairly large\nnumber of different logical theories, different accounts of what\n(logically) follows from what. And that observation raises a question\nwith which we will close: Is there one notion of logical consequence\nthat is the target of all such theories, or are there many? \nWe all agree that there are many different formal techniques for\nstudying logical consequence, and very many different formal systems\nthat each propose different relations of logical consequence. But\ngiven a particular argument, is the question as to whether it is\ndeductively valid an all-or-nothing affair? The orthodoxy, logical\nmonism, answers affirmatively. There is one relation of\ndeductive consequence, and different formal systems do a better or\nworse job of modelling that relation. (See, for example, Priest 1999\nfor a defence of monism.) The logical contextualist or\nrelativist says that the validity of an argument depends on\nthe subject matter or the frame of reference or some other context of\nevaluation. (For example, a use of the law of the excluded middle\nmight be valid in a classical mathematics textbook, but not in an\nintuitionistic mathematics textbook, or in a context where we reason\nabout fiction or vague matters.) The logical pluralist, on\nthe other hand, says that of one and the same argument, in one and the\nsame context, there are sometimes different things one should say with\nrespect to its validity. For example, perhaps one ought say that the\nargument from a contradictory collection of premises to an unrelated\nconclusion is valid in the sense that in virtue of its form\nit is not the case that the premises are true an the conclusion untrue\n(so it is valid in one precise sense) but that nonetheless, in another\nsense the form of the argument does not ensure that the truth of the\npremises leads to the truth of the conclusion. The monist or\nthe contextualist holds that in the case of the one argument a single\nanswer must be found for the question of its validity. The pluralist\ndenies this. The pluralist holds that the notion of logical\nconsequence itself may be made more precise in more than one way, just\nas the original idea of a “good argument” bifurcates into\ndeductive and inductive validity (see Beall and Restall 2000 for a\ndefence of pluralism).","contact.mail":"gilisagi@gmail.com","contact.domain":"gmail.com"}]
