[{"date.published":"2007-02-12","date.changed":"2019-02-06","url":"https://plato.stanford.edu/entries/situations-semantics/","author1":"Angelika Kratzer","author1.info":"http://people.umass.edu/kratzer/","entry":"situations-semantics","body.text":"\n\n\n\nSituation semantics was developed as an alternative to possible worlds\nsemantics. In situation semantics, linguistic expressions are\nevaluated with respect to partial, rather than complete, worlds. There\nis no consensus about what situations are, just as there is no\nconsensus about what possible worlds or events are. According to some,\nsituations are structured entities consisting of relations and\nindividuals standing in those relations. According to others,\nsituations are particulars. In spite of unresolved foundational\nissues, the partiality provided by situation semantics has led to some\ngenuinely new approaches to a variety of phenomena in natural language\nsemantics. In the way of illustration, this article includes\nrelatively detailed overviews of a few selected areas where situation\nsemantics has been successful: implicit quantifier domain\nrestrictions, donkey pronouns, and exhaustive interpretations. It\nmoreover addresses the question of how Davidsonian event semantics can\nbe embedded in a semantics based on situations. Other areas where a\nsituation semantics perspective has led to progress include attitude\nascriptions, questions, tense, aspect, nominalizations, implicit\narguments, point of view, counterfactual conditionals, and discourse\nrelations.\n\n\n\nSituations entered natural language semantics with Jon Barwise’s paper\nScenes and Other Situations (Barwise 1981), followed by\nBarwise and Perry’s Situations and Attitudes (Barwise &\nPerry 1983). Scenes and Other Situations is about the meaning\nof direct (or epistemically neutral) perception reports, a\nconstruction illustrated in (1): \n\nDirect perception reports contrast with indirect (or epistemically\npositive) perception reports, which typically have finite embedded\nclauses, as in (2): \n\nBoth (1) and (2) presuppose that Meryl fed the animals. But (1) and\n(2) still differ with respect to the interpretation of their embedded\ncomplements: the embedded complement in (1) can only be interpreted as\ntransparent, and this is not so for the embedded complement in\n(2). The transparency of the embedded complement in (1) is shown by\nthe validity of inferences like that in (3), for example: \n\nIn contrast to (3), the first sentence in (4) has an interpretation\nthat renders the inference in (4) invalid. \n\nA semantic analysis of direct perception reports has to explain what\nit is that forces their complements to be transparent. Barwise 1981\nproposes to analyze direct perception reports like (1) along the lines\nof (5): \n\nThe virtues of Barwise’s analysis can be appreciated even without\nseeing the exact details of how situations might support the truth of\nsentences. In (5) the verb see semantically selects\nsituations rather than propositions as its first argument, and this\nhas the desirable effect that the truth value of those sentences does\nnot change when the description of the perceived situation is replaced\nby an extensionally equivalent one. If Meryl fed the animals just once\nin the actual world, and she fed them hay, then the set of actual\nsituations that support the truth of Meryl feed the animals\nis expected to be the same as the set of actual situations that\nsupport the truth of Meryl feed the animals hay. But then (5)\nand (6) must have the same actual truth-value, and Barwise’s analysis\npredicts correctly that (1) and (7) must, too. \n\nThe publication of Barwise 1981 in the Journal of Philosophy\nwas followed by two papers providing commentary: Higginbotham 1983 in\nthe same journal, and Vlach 1983 in Synthese. The peer\nverdict on situations was that they were not needed for the semantics\nof direct perception reports: the facts could just as well be\nexplained by Davidsonian event semantics. (Davidson 1967a, 1980. See\nthe entries\n Donald Davidson\n and\n events.)\n In fact, Barwise’s argument showing that direct perception\nsee selects a situation is very much like Davidson’s argument\nshowing that the verb cause expresses a relation between\nevents (Davidson 1967b, 1980). Comparison with Davidsonian event\nsemantics has been an issue for situation semantics throughout its\nhistory. The relation between situation semantics and Davidsonian\nevent semantics will be taken up in section 9. \n\nLater developments in situation semantics emphasized its role as a\ngeneral theory of information content. The key concept is the notion\nof a state-of-affair or “infon” (see the entry\n states of affairs).\n State-of-affairs are non-linguistic formal objects that come in\nvarious stages of complexity (see Gawron & Peters 1990 for a brief\noverview, Devlin 1991, 2006 for a more detailed exposition, and\nGinzburg & Sag 2000 for a system based on a richer ontology). The\nsimplest kinds of state-of-affairs consist of a relation, individuals\nrelated by the relation, and a polarity, and might be represented as\nin (8): \n\nArguments of a relation may be parameterized, as in (9): \n\nParameterized roles can be anchored to individuals. In (9), the\nparameterized botherer role may be anchored to Nina, for example, and\nin that case, the result is the unparameterized state-of-affairs in\n8(a). Parameterized states-of-affairs can be restricted by other\nparameterized state-of-affairs, as in (10), where the subject role for\nthe property of taking a shower is restricted to individuals who are\nsinging: \n\nProperties and relations can be produced from parameterized\nstates-of-affairs by absorbing parameters: \n\nParameter absorption is the situation theory analogue of\nλ-abstraction. (11) corresponds to the property of not\nbothering Stella. There are additional operations that build complex\nstates-of-affairs from simpler ones, including analogues of\nconjunction, disjunction, and existential and universal quantification\n(see Devlin 1991, 2006, and Ginzburg & Sag 2000). The ultimate\ngoal is to provide the necessary tools for a theory of information\ncontent (see the entry\n semantic conceptions of information).\n Barwise 1988 mentions a wide range of applications, including\n“a theory of information to account for the role information\npickup plays in the life of the frog, how the information it detects\nis related to the actions it takes, actions like flicking its tongue\nand hopping about” (Barwise 1988, 257). Other applications\nmentioned are theories of vision, databases, robot design,\nmathematical proofs, information exchange between speakers of\nparticular language, and cognitive science as a whole. Finally, the\ntheory should be able “to be turned on itself, and provide an\naccount of its own information content, or rather, of the statements\nmade by the theorist using the theory” (Barwise 1988, 258). \n\nWhen Barwise and Perry started their joint work, a new, more\nfine-grained, notion of information content seemed to be urgently\nneeded in natural language semantics, because of a known challenge\nfacing possible worlds semantics, which, under the influence of Lewis\n1972 and Montague 1974, was the framework of choice for most formal\nsemanticists at the time (see the entry on\n possible worlds).\n In possible worlds semantics, propositions are identified with the\nset of possible worlds where they are true (see the entry\n propositions).\n Consequently, propositions that are true in the same possible worlds\nare identical, and we seem to predict wrongly that a person who\nbelieves a proposition p should also believe any proposition\nthat is true in the same worlds as p (see the entry\n propositional attitude reports).\n To distinguish logically equivalent propositions, we seem to need a\nmore fine-grained notion of what the information content of a sentence\nis, and the state-of-affairs or infons of situation semantics were\nmarketed to provide just that. \n\nThe solution that situation semantics offered for the puzzle of\nlogically equivalents in attitude ascriptions encountered competition\nfrom the very start: state-of-affairs and infons looked suspiciously\nlike structured propositions (see the entry\n structured propositions).\nIntensional versions of structured propositions had already been\noffered as remedies for the attitude ascription problem by Carnap\n1947, Lewis 1972, Cresswell & von Stechow 1982, and were also\nappealed to for the analysis of information structure and intonational\nmeaning. The structured meanings of Carnap, Lewis, and Cresswell &\nvon Stechow are tree structures whose end nodes are intensions, rather\nthan lexical items. They are thus objects that are independent of the\nvocabularies of particular languages, but are nevertheless\nhierarchically structured in the way sentences are. Differences\nbetween structured propositions in various frameworks and the\nstate-of-affairs or infons of situation theory seem to largely boil\ndown to foundational matters regarding the status of possibilia\n(see the entries on\n possible objects\n and\n possible worlds)\n and the nature of properties and relations (see\n properties). \n\nThere is currently no consensus about the semantics of attitude\nascriptions, and it is not clear whether situation semantics has a\nprivileged place in the family of accounts that have been proposed.\nPerhaps more importantly, for most empirical generalizations in\nlinguistic semantics, propositions construed as sets of possible\nworlds or situations provide the right level of abstraction. There\nseems to be no need to posit unwieldy information contents in areas\nwhere simpler notions provide more elegant accounts. Since this\narticle is not about theories of information, the concern to provide a\ngeneral theory of information content will now have to be set aside,\neven though it is central to some areas in situation semantics and\nsituation theory (Devlin 1991, 2006; Ginzburg and Sag 2000; see also\nBarwise & Seligman 1997). The remainder of this article will\nreview situation-based accounts of selected topics that are currently\nunder active investigation in linguistics and philosophy: Austinian\ntopic situations, domain restrictions, donkey sentences, exhaustive\ninterpretations, and Davidsonian event predication. None of those\nphenomena requires a more fine-grained notion of information content.\nThe discussion will thus be cast within a possibilistic framework\n(Kratzer 1989, 2002, 2012; Elbourne 2005, 2013).  Possibilistic\nversions of situation semantics are conservative extensions of\npossible worlds semantics that construe propositions as sets of world\nparts, rather than complete possible worlds (see Barwise 1988, chapter\n11, for an overview of the major branch points in situation\nsemantics). There are many areas that situation semantics has\ncontributed to that could not be reviewed here for reasons of space,\nincluding knowledge ascriptions, questions, discourse relations,\ncounterfactuals, viewpoint aspect, gerunds, and implicit\narguments. Stojanovich 2012 and Zucchi 2015 are recent general\noverviews of situation semantics. Additional references to work on\nvarious phenomena within a situation-based semantics are given below\nunder the heading references not mentioned in the text. \n\nA core feature of many actual analyses of natural language phenomena\nwithin situation semantics is the idea attributed to John L. Austin\n1950 that utterances are about particular situations, with the actual\nworld being the limiting case (see the entry on\n John Langshaw Austin.)\n Barwise & Etchemendy 1987 illustrate the idea with an imagined\nutterance of sentence (12): \n\nWhether an utterance of (12) is true or false depends, among other\nthings, on what situation the utterance is about. \n\nIf assertions are about particular situations, reports of assertions\nmight not be accurate unless they take into account the situations the\nassertions were about. And there are more repercussions of Austinian\nreasoning: if assertions are about particular situations, beliefs\nshould be, too, and this means that our belief ascriptions might not\nbe accurate unless they take into account the situations the beliefs\nare about. That those situations do indeed matter for belief\nascriptions is illustrated by the story of the Butler and the Judge\nfrom Kratzer 1998 (see Ogihara 1996, Kratzer 1990 (Other Internet\nResources), 2002, 2012; Portner 1992, Récanati 2000, for relevant\nwork on the role of topic situations in attitude ascriptions and other\nembedded constructions): \n\nThe judge was in financial trouble. He told his butler that he had\nbeen ready to commit suicide, when a wealthy man, who chose to remain\nanonymous, offered to pay off his debts. The butler suspected that\nMilford was the man who saved his master’s life by protecting him from\nfinancial ruin and suicide. While the butler was away on a short\nvacation, the judge fell into a ditch, drunk. Unconscious and close to\ndeath, he was pulled out by a stranger and taken to the local\nhospital, where he recovered. When the butler returned to the village,\nhe ran into a group of women who were speculating about the identity\nof the stranger who saved the judge’s life by taking him to the\nhospital. One of the women said she thought that Milford saved the\njudge’s life. The butler, who hadn’t yet heard about the accident and\nthought the women were talking about the judge’s financial traumas,\nreacted with (13): \n\nThe next day, when discussion of the judge’s accident continued,\nsomebody said: \n\nGiven that the butler’s suspicion is not about the accident, there is\na sense in which this belief attribution is not true. It seems\ninfelicitous, if not outright false. This suggests that our imagined\nassertion of (14) makes a claim about a particular situation that the\nsuspicion is about. In the context of the story, that situation is the\none everyone was talking about, and where the judge was rescued from\nthe ditch. Since the butler has no suspicion about such a situation,\nthe person who uttered (14) said something infelicitous or false. If\n(14) simply said that the butler suspected that there was a situation\nwhere Milford saved the judge’s life, the assertion would be\ntrue. There is support for the Austinian perspective on assertions and\nattitude ascriptions, then. \n\nAustinian topic situations (also referred to as “focus\nsituations”, “described situations”, or\n“reference situations” in the literature) are often\nnon-overt, but the tense of a sentence might give them away. A close\nlook at tenses tells us that topic situations do not always coincide\nwith the situations described by the main predication of a sentence.\nKlein (1994, 4) imagines a witness who is asked by a judge what she\nnoticed when she looked into the room. The witness answered with\n(15): \n\nIt is surprising that there is a past tense in the second sentence, even\nthough the book must have still been in Russian when the witness was\ncalled for testimony. Even more surprising is the fact that the\nwitness could not have said (16) instead of (15). \n\nTranslated into a situation semantics (Klein himself talks about topic\ntimes, rather than topic situations), Klein’s explanation is that\ntense relates utterance situations to topic situations, which do not\nnecessarily coincide with the situations described by the main\npredication of a sentence. In Klein’s scenario, the topic situation\nfor the second part of the witness’s answer was the past situation\nthat she saw when she looked into the room. Since the topic situation\nwas past, tense marking in the second sentence of (16) has to be past,\ntoo. Via their temporal locations, topic situations play an important\nrole in the semantics of both tense and aspect (see the entry on\n tense and aspect;\n also Smith 1991, Kamp & Reyle 1993, and Cipria & Roberts\n2000). \nIf Austinian topic situations play a role in the grammars of natural languages, there should be grammatical devices in at least some languages that track them. Recent work by Andrew McKenzie (McKenzie 2012, 2015) has suggested that certain Switch Reference systems in a number of genetically unrelated languages seem to track Austinian topic situations. For example, the North American language Kiowa (Tanoan, spoken in Oklahoma) uses different forms for certain sentential connectives (including conjunction), depending on whether the topic situations of the conjoined conjuncts changes or stays the same. \n\nAmong the most innovative ideas in Barwise & Perry 1983 is the\nproposal to exploit the Austinian perspective on utterances to account\nfor implicit quantifier restrictions and so-called\n“incomplete” definite descriptions (see the entry\n descriptions): \n\nA similar example discusses incomplete definite descriptions: \n\nThe answer is, “It depends on which situation I am\ndescribing.” First, suppose someone comes up to me and says,\n“The food at this party is delicious! Who is the cook?” If\nI say “I am the cook,” I have clearly not described things\naccurately. I have claimed to be the person who did the\ncooking for the party. But suppose instead someone comes up to me\neating a piece of my famous cheesecake pastry and says, “Who\nmade this?” Then I may truly say that I am the cook.  (Barwise\n& Perry 1983, 159)\n  \n\nOn the Austinian perspective, at least certain kinds of implicit\nrestrictions for quantification domains are a direct consequence of\nthe fact that assertions are about particular actual situations, and\nthat those situations can be smaller or bigger parts of the actual\nworld. \n\nThe Austinian answer to implicit domain restrictions was endorsed and\ndeveloped in Récanati (1986/87, 1996, 2004a) and Cooper\n1996. An influential attack on the situation semantics approach to\n“incomplete” definite descriptions came from Soames 1986,\nwho concluded that “the analysis of definite descriptions is not\nfacilitated by the kind of partiality that situation semantics\nprovides” (Soames 1986, 368). Soames’ reservations against the\nAustinian approach to domain restrictions come from two major\npotential counterarguments, both of which are directed against\nparticular implementations of the approach. One of the potential\nproblems discussed by Soames concerns attributive readings of definite\ndescriptions. However, as Soames is careful to note (Soames 1986,\n359), this problem does not necessarily affect possibilistic versions\nof situation semantics. Since Soames’ qualification is not elaborated\nin his article, it might be useful to look at a concrete example\nillustrating his point. Suppose the two of us observe a bear crossing\nthe road one night in Glacier National Park. Since it is dark, we\ncan’t see the bear very well, and I say to you: \n\nI am aware that the bear we see is not the only bear in the world, so\nmy assertion relies on an implicit domain restriction. On the\nAustinian view, my assertion is about a particular situation located\nsomewhere in Glacier National Park at a particular time in August\n2006.  Call that situation “Bear Sighting”. Bear Sighting\nhas a particular bear in it, the bear we see. Call that bear\n“Bruno”. On the intended attributive reading, what I want\nto get across to you is not that Bruno may be a grizzly, but that our\nevidence about Bear Sighting is compatible with the assumption that\nthe bear there—whoever he is—is a grizzly. There is a\nlegitimate question whether we can get that reading on the Austinian\napproach to domain restrictions. If Bear Sighting has to give us the\nrestriction for bear, it seems that all it can do is restrict\nthe bears we are talking about to Bruno. But that wouldn’t produce the\nattributive reading we are after. For that reading, so it might seem,\ndomain restrictions must be properties. \n\nThe above conclusion might look inevitable, but it is not. It is true\nthat on the Austinian view, my utterance of (17) is interpreted as a\nclaim about Bear Sighting. To see that we can nevertheless get the\ndesired interpretation, we need to look at technical details. 18(a)\ngives a plausible interpretation of the possibility modal in (17)\nwithin a possibilistic situation semantics. 18(b) is the\ninterpretation of the whole sentence (17) before the Austinian\ncomponent comes into play: \n\n(18) assumes an intensional semantics that is based on possible\nsituations. In possible situation semantics, propositions are sets of\npossible situations, or characteristic functions of such sets, and all\npredicates are evaluated with respect to a possible situation. 18(b)\nis the proposition expressed by (17) in context c. That\nproposition is a property that is true of a situation s iff\nthere is a situation s′ that is accessible from\ns and the unique bear in s′ is a grizzly in\ns′. The modal might introduces existential\nquantification over possible situations that are accessible from the\nevaluation situation s (see the entry\n modal logic).\n The kind of accessibility relation is determined by the lexical\nmeaning of the modal in interaction with properties of the utterance\ncontext c (see the entry\n indexicals).\n In our example, the modality is a particular kind of epistemic\nmodality that relates two situations s and s′\nin a context c just in case s and s′\nare equivalent with respect to the information available in\nc, that is, whatever evidence about s is available\nin c isn’t specific enough to distinguish between s\nand s′ (epistemic contextualism).  Evidence\nthat counts as available for epistemic modals might include the\ndistributed knowledge of the discourse participants (see von Fintel\n& Gillies 2011), other\navailable sources of information like ship’s logs or computer\nprintouts (Hacking 1967, von Fintel & Gillies 2011), but,\ninterestingly, not necessarily information that happens to be hidden\nfrom sight like test results in sealed envelopes (de Rose 1991),\nbabies in wombs (Teller 1972), weather conditions behind drawn\ncurtains (Gillies 2001), or details of animals obscured by\ndarkness. Suppose the actual bear in Bear Sighting is in fact a black\nbear, and not a grizzly. Since it is night and we can’t see the bear\nvery well, the evidence we have about Bear Sighting when I utter (17)\ncannot distinguish the real situation from many merely possible ones,\nincluding some where the bear is a grizzly and not a black bear.  This\nis what makes my utterance of (17) true. \n\nWhen I uttered (17), I claimed that the proposition in 18(b) was true\nof Bear Sighting. Applying 18(b) to Bear Sighting yields the desired\nattributive interpretation. Bear Sighting is exploited to provide\nimplicit domain restrictions, but it doesn’t do so directly. We are\nconsidering epistemic alternatives of Bear Sighting.  The epistemic\nalternatives are alternatives of Bear Sighting, hence are partial,\njust as Bear Sighting itself is. They have no more than a single bear\nin them. This suggests that the analysis of definite descriptions\nis facilitated by the kind of partiality that situation\nsemantics provides. Austinian topic situations can give us domain\nrestrictions for attributive definite descriptions. \n\nSoames’ second major objection against the Austinian approach to\ndomain restrictions relates to the fact that there are instances of\ndomain restrictions that can’t seem to come from Austinian topic\nsituations (see also Westerståhl 1985). One of Soames’ examples\nis (19) below (Soames 1986, 357), which is a variation of Barwise and\nPerry’s sleep lab example quoted above. \n\nIf all quantifier domains were provided by Austinian topic situations,\n(19) would seem to make contradictory demands on such a\nsituation. Assuming that there is just a single topic situation for\nutterances of (19), we seem to predict that those utterances imply\nthat the research assistants are among those who are asleep. But there\nis no such implication. Soames is aware that proponents of the\nAustinian approach are not committed to the assumption that\nall domain restrictions are directly provided by Austinian\ntopic situations (Soames 1986, footnote 17, 371), and he therefore\nemphasizes that he is only commenting on the particular account of\ndomain restrictions offered in Barwise and Perry (1983, 1985). Soames’\nobjection does not apply to Cooper 1996, for example, who allows\nquantifier domains to be determined by different resource situations,\nwhich he distinguishes from the Austinian topic situation (his\n“described situation”). The objection also does not apply\nto possibilistic versions of situation semantics, where every\npredicate is necessarily evaluated with respect to an actual or\npossible situation. Different predicates in one and the same sentence\ncan then be evaluated with respect to different situations (Heim 1990,\nPercus 2000, Elbourne 2002, 2005, 2013). A possible interpretation for (19)\nmight be (20): \n\nWhen the doctor of the sleep lab utters (19), she claims that the\nproposition in (20) is true of a particular situation, call it\n“Sleep Lab”. Sleep Lab is the Austinian topic situation,\nbut it is not the situation that picks out the sleepers. The sleepers\nmight be recruited from a contextually salient (possibly scattered)\nsituation s′ that is related to Sleep Lab via the part\nrelation ≤p and functions as a resource\nsituation for the evaluation of the predicate person\nintroduced by the quantifier phrase everyone. This situation\ncould be the sum of the patients in the lab, for example. \n\nNeither topic nor resource situations have to be posited for the\nexclusive need of domain restriction. In a possibilistic situation\nsemantics resource situations are the kind of entities that the\nevaluation of any predicate routinely depends on. Topic situations,\ntoo, are independently needed: they are the situations that assertions\nand beliefs are about, and they are key players in the semantics of\ntense and aspect. This means that the contribution of topic and\nresource situations to domain restriction comes entirely for\nfree. Many instances of domain restrictions can thus be explained\nwithout positing any special devices. Some of the remaining cases\nmight also be accounted for by independently attested mechanisms\nincluding syntactic ellipsis, presupposition projection and\nconversational implicatures. But there is also exaggeration, taboo\nrelated omissions, and some such. The implicit domain restriction in\nthe following sentence, which appeared on a note posted in a bathroom\nin York (England), might very well fall in the last-mentioned\ncategory: \n\nIt is hard to see how any theory would want to literally prevent any\nkind of pragmatic enrichment processes (Récanati 1993, 2002,\n2004) from contributing to implicit quantifier restrictions, given\nthat humans are able to “interpret utterances replete with\nirony, metaphor, elision, anacoluthon, aposiopesis, and on top of all\nof this …identify what a speaker is implying as well\nas saying” (Neale 2004, 123). Implicit domain restrictions are\nlikely to be the byproducts of a number of independently attested\nmechanisms, then. \n\nAn important question in situation semantics is how exactly situations\nenter the semantic interpretation process. Are they articulated via\nsyntactically represented variables, or are they “unarticulated\nconstituents” (Perry 1986, Récanati 2002), possibly mere\nindices of evaluation? The issue is well explored for times and\npossible worlds (entry ontology and ontological\ncommitment). Kripke’s semantics for modal logic allows\nquantification over possible worlds only in the metalanguage (see the\nentry\n modal logic),\n for example.\nLikewise, in Prior’s tense logic (see the entry\n Arthur Prior),\n quantification over times is\nconfined to the metalanguage (see the entry\n time). \n\nMontague’s language of intensional logic (Montague 1974) was developed\nin the tradition of Kripke and Prior, and does not have variables\nranging over times or worlds: tense and modal operators shift\nevaluation indices, as illustrated in (22), but do not bind variables\nin the object language. Quantification over worlds and times is\ntreated differently from quantification over individuals, then. The\ndistinction was made deliberately because it predicts differences that\nwere thought correct at the time. Once an evaluation index is shifted,\nit is gone for good, and can no longer be used for the evaluation of\nother expressions. This constrains temporal and modal anaphora. Until\nthe early seventies anaphoric reference to times and worlds in natural\nlanguages was believed to be constrained in precisely the way\npredicted by the evaluation index approach. The belief was challenged\nby work on temporal anaphora (Kamp 1971, Partee 1973, Vlach 1973, van\nBenthem 1977), however. Cresswell 1990 presented parallel arguments\nfor modal anaphora, and showed more generally that natural languages\nhave the full expressive power of object language quantification over\nworlds and times. Quantification over worlds or times is thus no\ndifferent from quantification over individuals, and should be\naccounted for in the same way. \n\nExact analogues of Cresswell’s examples can be constructed to show\nthat natural languages have the full expressive power of object\nlanguage quantification over situations. Here is a first taste of the\nkind of example we have to look at. \n\nSuppose (23) is uttered to make a claim about the town of Amherst\nduring the last 20 years. We are looking at the snowfalls during the\nrelevant period. For each of those actual snowfalls s, we are\nconsidering counterfactual situations r where it snowed much\nmore than it did in s. The claim is that each of those\ncounterfactual situations is part of a situation where the town plow\nremoved the snow for us. To formalize what was said, we have to be\nable to consider for each actual snowfall s a set of\ncounterfactual alternatives and compare the amount of snow in each of\nthem to the actual amount of snow in s. This means that we\nhave to be able to “go back” to the actual snowfall\nsituations after considering corresponding counterfactual situations.\nTo do so we have to keep track of the original situations. The\navailable bookkeeping tools are either evaluation indices, or else\nsituation variables and binding relations in the object language. If\nwe want to avoid possibly unpronounced situation variables, we need\ntwo shiftable evaluation indices for (23). In the long run, even two\nindices wouldn’t be enough, though. Here is an example that requires\nthree: \n\nIt is not hard to see that we can complicate such examples\nindefinitely, and that there would be no end to the number of\nevaluation indices needed. But that suggests that natural languages\nhave the full power of object language quantification over situations.\nQuantification over situations is no different from quantification\nover individuals, then, as far as expressive power is concerned. Since\nnatural languages have syntactically represented individual variables\nand it would be surprising if they used two different equally powerful\nquantification mechanisms, it seems to be at least a good bet that\nthere are syntactically represented situation variables in natural\nlanguages (but see Cresswell 1990 and Jacobson 1999 for dissenting\nopinions). But then the situations quantified over or referred to in\n(23), (24) and their kin do not necessarily correspond to\n“unarticulated constituents”. They are syntactically\nrepresented, even though they might happen to be unpronounced. The\nsyntactic representation of situation variables is investigated in Percus 2000, Keshet (2008, 2010), and F. Schwarz (2008, 2012). \n\nOne of the most frequent uses of situation-based frameworks is in the\nanalysis of “donkey” pronouns, that is, anaphoric pronouns\nthat are interpreted as definite descriptions (see descriptive\ntheories of anaphora under the entry\n descriptions\n and the entry \n anaphora). \n\nThe pronoun it in 25(a) is an instance of a descriptive\npronoun that is interpreted like the corresponding definite\ndescription in 25(b). Suppose I use 25(a) or (b) to talk about a\nparticular situation, call it “Donkey Parade”. The\nsituations that whenever quantifies over are then all part of\nDonkey Parade.  They are precisely those subsituations of Donkey\nParade that are minimal situations in which a donkey appeared. Those\nmust then be situations with a single donkey in them. The claim is\nthat all those situations are part of situations where the donkey was\ngreeted enthusiastically. More formally, my claim about Donkey Parade\nis (26): \n\n(26) reflects the standard analysis of adverbs of quantification and\ndescriptive pronouns in a possibilistic situation semantics (Berman\n1987; Heim 1990; Portner 1992; von Fintel 1994, 2004b; Elbourne 2002,\n2005, 2013, 2016). All resource situations that are introduced in (26) are\ndirectly or indirectly related to the topic situation via the part\nrelation ≤p. The topic situation is the\nultimate anchor for all resource situations. It indirectly restricts\nthe donkeys being talked about to those that are present in Donkey\nParade. The antecedent of the conditional introduces a further\nrestriction: we are considering only those subsituations of Donkey\nParade that are minimal situations in which a donkey appeared. Those\nsituations have just one donkey in them, and they can thus be used as\nresource situations for the definite description the donkey\nor a corresponding descriptive pronoun. \n\nThe crucial feature of any analysis of donkey sentences within a\nsituation semantics is that quantification is over minimal situations\nsatisfying conditions imposed by the antecedent of the\nconditional. The minimality condition is crucial for the analysis of\ndescriptive pronouns. Without it, we wouldn’t be able to analyze those\npronouns as definite descriptions: \n\nWe have to make sure that the situations or events quantified over\nhave just one man and just one donkey in them, because definite\ndescriptions have to be unique with respect to their resource\nsituations. The minimality condition is a source of potential trouble,\nhowever (Reinhart 1986, Dekker 2004; von Fintel 2004a,b). When the\nantecedent of a conditional contains a mass noun, negative\nquantifiers, or certain kinds of modified quantifier phrases,\nquantification over minimal situations or events seems to yield\nunwelcome results or isn’t possible at all: \n\n28(a) raises the question whether there ever are minimal situations or\nevents in which snow falls. But even if there are, we do not quantify\nover them in this case. We also do not seem to rely on discrete scales\nfor measuring portions of Super Supper. But even if we did, this would\nnot help with 28(b). This sentence does not necessarily quantify over\nsituations in which a cat eats just a little more than a can of Super\nSupper. Minimality also doesn’t seem to play a role for 28(c). If\n28(c) quantified over minimal situations that have between 20 and 2000\nwedding guests, it would quantify over situations or events with\nexactly 20 wedding guests, and might very well be true.  28(d) is even\nmore dramatic. What would a minimal situation or event look like in\nwhich nobody showed up? If any event- or situation-based analysis of\ndonkey sentences is to succeed, then, it must keep the events or\nsituations that are quantified over small enough to contain just one\nman and one donkey in cases like (27), but it has to accomplish this\nwithout minimizing the amount of snow, Super Supper, or wedding guests\nin cases like 28(a) to (c). And it should not mess with negative\nconstructions at all. When we are quantifying over situations in\ndonkey sentences, then, we need to relate possibly very complex\nsentences to exemplifying situations in a way that is responsive to\nthe different behavior of different kinds of antecedents illustrated\nby (27) and 28(a) to (d). \n\nThere are several proposals in the literature that elucidate the\nrelation between a sentence and the situations or events that\nexemplify it by positing a special recursive mechanism that relates\nsentences to the set of exemplifying events or situations (see Schein\n1993, chapters 9 and 10 for discussion of this issue). Possibilistic\nversions of situation semantics typically start out with a recursive\ntruth definition that relates utterances of sentences to the sets of\npossible situations in which the utterances are true, the propositions\nexpressed. The situations or events that exemplify a proposition can\nthen be defined as the “minimal” situations in which the\nproposition is true (see the entries on\n events,\n facts,\n states of affairs,\n and\n truthmakers).\n The challenge presented by sentences (27) and 28(a) to (d) is that\nthey suggest that a naïve notion of minimality won’t do. A more\nflexible notion of minimality seems to be needed. The following\nsection will document in some detail how the desired notion of\nminimality might emerge from a simple definition of exemplification in\ninteraction with independently justified sentence denotations. The\nissue is under active investigation, however, and cannot be considered\nsettled before a wide range of different constructions has been looked\nat. Whatever the ultimate outcome may be, the following discussion\nwill provide the opportunity to illustrate how the shift from possible\nworlds to situations affects the denotations we might want to posit\nfor an expression. In a situation semantics, there are often several\nways of assigning denotations to an expression that are hard to\ndistinguish on truth-conditional grounds. Looking at the situations\nthat exemplify a sentence as well as its truth-conditions helps with\nthe choice. \n\nIn possibilistic versions of situation semantics, possible situations\nare parts of possible worlds. Some authors also assume that the parts of a\npossible world w form a join semi-lattice with maximal\nelement w (Bach 1986; Lasersohn 1988, 1990; Portner 1992; see\nalso the entry\n mereology).\n The part relation ≤p and the sum operation +\nare then related as usual: s ≤ps′ iff s + s′ =\ns′. Propositions are sets of possible situations or\ntheir characteristic functions (see the entry\n propositions).\n The notion of a situation that exemplifies a proposition might be\ndefined as in (29), which is a variation of a definition that appears\nin Kratzer 1990 (Other Internet Resources), 1998, 2002: \n\nIntuitively, a situation that exemplifies a proposition p is\none that does not contain anything that does not contribute to the\ntruth of p. The first part of (29) allows two possibilities for a situation\ns to exemplify p.  Either p is true in all\nsubsituations of s or s is a minimal situation in\nwhich p is true. The notion of minimality appealed to in (29)\nis the standard one: A situation is a minimal situation in which a\nproposition p is true iff it has no proper parts in which\np is true. The situation Mud (Case One below) gives a first\nillustration of what (29) does. \n Case One: Mud\n  \n\nAssuming that Mud and all of its parts are mud, Mud and all of its\nparts exemplify the proposition in 30(b), since there are no parts of\nMud where there is no mud. \n\n30(b) is not exemplified by Mud & Moss (Case Two below),\nhowever: \n Case Two: Mud & Moss\n  \n\nMud & Moss has parts where 30(b) is not true: the parts where\nthere is only moss. But Mud & Moss is not a minimal situation in\nwhich 30(b) is true. \n\nNext, consider (31): \n\n31(b) describes situations s that have at least three teapots\n(individuals that are teapots in the world of s) in them. The\nproposition in 31(b) seems to be exemplified by the situation Teapots\n(Case Three below). \n Case Three: Teapots\n  \n\nThere is no proper subsituation of Teapots in which 31(b) is true.\nSince Teapots has nothing but three teapots in it, any proper\nsubsituation of Teapots would have to be one where a part of at least\none of the three teapots is missing. But 31(b) is true in Teapots\nitself, and Teapots is thus a minimal situation in which 31(b) is\ntrue. \n\nThere is a potential glitch in the above piece of reasoning. It\nassumes that when an individual is a teapot in a world, no proper part\nof that individual is also a teapot in that world. This assumption can\nbe questioned, however. Following Geach 1980 (p. 215; see entries\n identity,\n problem of many),\n we might reason as follows: My teapot would remain a teapot if we\nchipped off a tiny piece. Chipping off pieces from teapots doesn’t\ncreate new teapots, so there must have been smaller teapots all\nalong. We might feel that there is just a single teapot sitting on the\ntable, but upon reflection we might have to acknowledge that there are\nin fact many overlapping entities that all have legitimate claims to\nteapothood. The unexpected multitude of teapots is a source of\nheadaches when it comes to counting. A fundamental principle of\ncounting says that a domain for counting cannot contain non-identical\noverlapping individuals (Casati & Varzi 1999, 112): \n\n(32) implies that just one of the many overlapping teapots on the\ntable over there can be counted, and the question is which one. If we\nare that liberal with teapothood, we need a counting criterion that\ntells us which of the many teapots in our overpopulated inventory of\nteapots we are allowed to count. \n\nWith spatiotemporal objects like teapots, humans seem to rely on\ncounting criteria that privilege maximal self-connected entities\n(Spelke 1990, Casati & Varzi 1999). A self-connected teapot is one\nthat cannot be split into two parts that are not connected. In\ncontrast to parthood, which is a mereological concept, connectedness\nis a topological notion (see Casati and Varzi 1999 for discussion of\nvarious postulates for a “mereotopology”, a theory that\ncombines mereology and topology). The maximality requirement prevents\ncounting teapots that are proper parts of other teapots, and the\nself-connectedness requirement disqualifies sums of parts from\ndifferent teapots. Casati and Varzi point out that not all kinds of\nentities, not even all kinds of spatiotemporal entities, come with\ncounting criteria that involve topological self-connectedness. Obvious\ncounterexamples include bikinis, three-piece suits, and broken glasses\nthat are shattered all over the floor. We have to recognize a wider\nrange of counting criteria, then, that guarantee compliance with (32)\nin one way or other. \n\nAssuming counting criteria, the proposition expressed by 31(a) would\nstill be exemplified by Teapots, even if we grant that teapots can\nhave proper parts that are also teapots. The specification of\ndenotations for sentences with numerals would now have to make\nreference to teapots that can be counted, call them “numerical\nteapots”.  Representations like 31(b) and its kin should then be\nunderstood along the lines of 33(b): \n\nIf Teapots contains nothing but three individuals that are numerical\nteapots in the actual world, 33(b) is true in Teapots. But then none\nof the proper subsituations of Teapots can contain three individuals\nthat are numerical teapots in the actual world. Any such situation\ncontains at least one teapot that is a proper part of one of the\nteapots in Teapots, hence can no longer contain three numerical\nteapots. \n\nIn contrast to Teapots, Teapots & Scissors (Case Four below) does\nnot exemplify 31(b). Teapots & Scissors has parts where 31(b) is\nnot true: take any part that has just the scissors or just a part of\nthe scissors in it, for example. But Teapots & Scissors is not a\nminimal situation in which 31(b) is true. \n Case Four: Teapots and Scissors\n  \n\nDefinition (29) has the consequence that Teapots does not exemplify\nthe proposition 34(b) below, even though 34(b) is true in Teapots. \n\n34(b) is true in Teapots, since Teapots contains a plural individual\nthat contains exactly two teapots. However, 34(b) is not exemplified\nby Teapots. Teapots has parts in which 34(b) is not true without being\na minimal situation in which 34(b) is true. More generally, if\nsentences of the form there are n teapots denote propositions\nof the kind illustrated by 34(b), then those propositions can only be\nexemplified by situations that have exactly n\nteapots. Likewise, if there is a teapot is interpreted as in\n35(b) below, the proposition it expresses can only be exemplified by\nsituations with exactly one teapot, even though it can be true in\nsituations with more teapots. \n\nThe predicted exemplification properties of sentences with numerals\nare welcome, since they suggest that (29) might indeed capture the\nrelation between propositions and situations that we are after: The\nsituations exemplifying the proposition expressed by there is a\nteapot are all situations that have a single teapot in them,\nhence are literally minimal situations containing a teapot. In\ncontrast, the situations exemplifying the proposition expressed by\nthere is mud are all situations that contain mud and nothing\nelse, hence do not have to be minimal situations containing mud. \n\nThe major consequence of (29) is that if a proposition has\nexemplifying situations at all, the set of its exemplifying situations\nmust be either homogeneous or quantized in the sense of Krifka 1992. A\nset of situations is quantized iff it doesn’t contain both a situation\ns and a proper part of s. A set of situations is\nhomogeneous iff it is closed under the parthood relation, that is,\nwhenever it contains a situation s, it also contains all\nparts of s. As argued in Krifka’s work, algebraic notions\nlike homogeneity and quantization might capture linguistically\nimportant aspectual distinctions like that illustrated in (36) (see\nthe entry on\n tense and aspect). \n\nThe proposition expressed by 36(a) seems to be exemplified by minimal\npast situations in which Josephine built an airplane, and this set of\nsituations is quantized. On the other hand, the proposition expressed\nby 36(b) seems to be exemplified by all past situations that contain\nairplane flying by Josephine and nothing else, and this set of\nsituations is homogeneous. Homogeneous sets cannot be used as counting\ndomains, however, and this requires adjustments with examples like\n37(b). \n\n37(b) cannot quantify over all situations that exemplify the\nproposition Josephine flew an airplane, since this would give\nus a quantification domain that violates the Counting Principle (32).\nWe have to impose a counting criterion, then, and the topological\nnotion of self-connectedness seems to be relevant here, too (see von\nFintel 2004a,b). As a result, 37(b) might quantify over maximal\nself-connected situations exemplifying the proposition expressed by\nJosephine flew an airplane. \n\nWe are now in a position to see how exemplification can be used for\nthe analysis of donkey sentences. Look again at (38) and (39): \n\n(38) and (39) quantify over parts of a contextually salient topic\nsituation. The antecedents of the conditionals tell us more about what\nthose parts are. In (38) quantification is over situations\nexemplifying the proposition expressed by a man saw a donkey,\nwhich are all situations that contain a single man and a single\ndonkey. Those situations can then be taken to be resource situations\nfor the definite descriptions the man and the donkey\nin the consequent of (38). (39) also quantifies over parts of the\ntopic situation that exemplify the antecedent proposition, but as in\nthe case of 37(b), considering all exemplifying situations would\nviolate the Counting Principle, and we therefore need a counting\ncriterion. (39) might then quantify over maximal self-connected\nsituations exemplifying the proposition expressed by snow falls\naround here. Those situations include complete snowfalls, then,\nand if it does indeed snow a lot around here whenever it snows, (39)\nmight very well wind up true. \n\nNot all propositions that look like perfectly acceptable candidates\nfor sentence denotations have exemplifying situations. Consider 40(b),\nfor example: \n\nWhenever there is a situation that has more than five tons of mud in\nit, there are parts that have just five tons or less. But none of\nthose parts can be part of any minimal situation with more than five\ntons of mud, since there are no such situations. \n\nIn a situation semantics, it often happens that there are several\noptions for assigning subtly different propositions to sentences, and\nsometimes the options are hard to distinguish on truth-conditional\ngrounds. Insisting on both adequate truth-conditions and adequate\nexemplification conditions might help narrow down the field of\ncandidates. 40(a) can also be paraphrased as saying that the total\namount of mud in some contextually salient resource situation weighs\nmore than five tons. The denotation of 40(a) could be (41), then,\nwhich includes a contextualized maximalization condition: \n\n(41) is true in a situation s if it contains all the mud of\nsome salient resource situation s′ (possibly the actual\nworld as a whole), and that mud weighs more than 5 tons. (41) is\nexemplified by the mud in s′, provided it weighs more\nthan five tons. Sentences may contain noun phrases that provide\nanchors for the maximalization condition. (42) is a case in\nquestion: \n\n42(b) is exemplified by the mud in this ditch, as long as it weighs more than five tons. \n\nMaximalized interpretations for more than n and similar kinds\nof indefinites like at least n are discussed in Reinhart\n1986, Kadmon  (1987, 1990, 2001), Schein 1993, and Landman (2000,\n2004). Some of the original observations go back to Evans 1977. As\nnoted by Reinhart and Kadmon, more than n noun phrases\nproduce maximality effects of the kind illustrated in (43): \n\n(43) would be considered false in a situation where there was in fact\n7 tons of mud in this ditch, but only six tons were removed. This\njudgment can be accounted for by assuming that utterances of the\nsecond sentence in (43) are about a particular past situation that\nexemplifies the first sentence. This situation can then serve as a\nresource situation for the interpretation of the definite description\nthe mud. If sentences like 42(a) have maximalized\ninterpretations, it follows that the mud that was removed was all the\nmud in the ditch. \n\nThere are other numeral expressions that trigger maximalization.  (44)\nis an example: \n\n44(c), too, would be considered false in situations where only some of\nthe teapots on the shelf are defective. Even simple numeral phrases\nlike four teapots can have maximalized interpretations. \n\nIntuitions for (45) are not so clear, but (46) brings out a sharp\ndifference between simple and complex numeral phrases. \n\nImagine that I sold exactly four teapots yesterday. 46(a) has an\ninterpretation where I am entitled to a $10 bonus. On this reading,\nour quantification domain is some set of non-overlapping situations\nthat are minimal situations in which I sold two teapots on the same\nday.  Regardless of how we pair up yesterday’s four teapot sales to\nconstruct an acceptable counting domain, we always end up with exactly\ntwo bonus-qualifying situations. This shows that numeral expressions\nlike two teapots do not obligatorily have maximalized\ninterpretations. 46(a) contrasts with 46(b) and (c). 46(c) has no\ninterpretation where I qualify for a $10 bonus if I sold four teapots\nyesterday. And 46(b) has no interpretation where I get $10 dollars if\nI sold six, for example. We can conclude, then, that numeral\nexpressions of the form more than n NP or between n and m\nNP trigger denotations that are obligatorily maximalized, but\nthis is not the case for simple numerals of the form n\nNP. \n\nReturning to the donkey sentences we looked at earlier, we now\nunderstand why 47(a) and (b) (repeated from above) do not simply\nquantify over minimal situations in a naïve sense: \n\nThe antecedents of 47(a) and (b) involve maximalization. For 47(a),\nfor example, the proposition expressed by the antecedent could be\n48(b): \n\n48(b) restricts the situations quantified over to those whose temporal\nextension is a day, which could be a calendar day, or, more plausibly,\na 24-hour period. The maximality condition can then pick out all the\nfood eaten during such a period by the relevant cats, regardless of\nwhether they ate just a little more than what comes in a can or much\nmore than that. There is no pressure to keep the portions\nsmall. However, Fox & Hackl (2006) have drawn attention to a\nclass of cases where there is pressure to keep amounts small\nin sentences with more than n noun phrases. (49) below would\nbe such a case: \n\n(49) suggests that candidates appeared on TV five minutes after it\nbecame clear that they had won the majority of votes. If 500 votes\nwere cast in all, for example, and the ballot count showed at 8:00 pm\nthat one of the candidates had won 251 votes, the winning candidate is\nclaimed to have appeared on TV at 8:05 pm. This judgment is expected\nif (49) quantifies over situations that exemplify the proposition\nexpressed by its antecedent. Factoring in maximalization triggered by\nmore than 50% of all votes, the antecedent can be paraphrased\nas (50): \n\nThe exemplifying situations for the proposition expressed by (50) are\nminimal ballot count situations that establish that one of the\ncandidates has carried the majority of votes. If there are 500 ballots\nin all, the exemplifying situations are all situations where 251\nballots have been counted. \n\nThe last case to discuss concerns negative quantifiers. \n\n51(b) is exemplified by the situations in which it is true. This makes\nthe situations exemplifying negative sentences a rather disparate\nbatch that do not resemble each other in any intuitive sense. If we\nwant to quantify over situations exemplifying the propositions\nexpressed by negative sentences, as we do in (52) below (repeated from\nabove), contextual restrictions for the topic situation must play a\nmajor role, including those contributed by the topic-focus\narticulation and presuppositions (Kratzer 1989, 2012; von Fintel 1994,\n2004a).  Exemplification is not expected to make any contribution\nhere, which is the result we want to derive. \n\nThis section discussed and tested a particular possibilistic account\nof the relation between a proposition and its exemplifying situations.\nThe test cases were conditionals that quantify over situations that\nare “minimal” in a way that is responsive to specific\nproperties of their antecedents: the presence of count nouns versus\nmass nouns, telic versus atelic verb phrases, modified versus\nunmodified numerals, negative versus positive quantifiers. The account\nshowed the right responsiveness in interaction with independently\nmotivated interpretations for the sentences involved. Interestingly,\nonce possible maximalizations are factored into sentence denotations,\nthe exemplification account spelled out in definition (29) coincides\nwith the naïve minimalization account in most cases. The only\nsystematic exceptions seem to be atelic antecedents, including those\ninvolving negation. Contrary to initial appearance, then, the\nnaïve minimalization accounts found in most existing analyses of\ndonkey sentences within a possibilistic situation semantics are close\nto correct (but see section 9 for discussion of another potentially\nproblematic case, example (61)). \n\nMinimal interpretations of sentences are a common phenomenon and are\nnot only found in the antecedents of donkey sentences. Among the most\nwidely discussed cases are exhaustive answers to questions, or more\ngenerally, exhaustive interpretations (Groenendijk & Stokhof 1984,\nBonomi & Casalegno 1993, Sevi 2005, Schulz and van Rooij 2006,\nSpector 2006, Fox (to appear), Fox & Hackl (to appear); see also\nthe entry\n implicature).\n Here is an illustration. \n\nWe tend to understand Beatrice’s answer as suggesting that Jason and\nWillie were the only ones who caught something. This is the exhaustive\ninterpretation of Beatrice’s answer. Non-exhaustive or “mention\nsome” answers are often marked with special intonation or\nparticles, as in (54), for example: \n\nIn this case, Beatrice indicates that she does not mean her answer to\nbe understood exhaustively. In combination with Groenendijk and\nStokhof’s 1984 analysis of questions, the exemplification relation\nallows a strikingly simple characterization of exhaustive and\nnon-exhaustive answers. If we import Groenendijk and Stokhof’s\nanalysis into a situation semantics, the extension of Josephine’s\nquestion in (54) is the proposition in (55): \n\n(55) describes possible situations in which the set of those who\ncaught something is the same as the set of those who caught something\nin the actual world. Since question extensions are propositions, they\ncan be exemplified. Suppose Jason, Willie, and Joseph are the only\nones who caught anything in the actual world. Then (55) is exemplified\nby all minimal situations in which Jason, Willie, and Joseph caught\nsomething. If nobody caught anything in the actual world, then any\nactual situation exemplifies (55). Bringing in the Austinian\nperspective, we can now say that answers to questions are always\nunderstood as claims about the actual situations that exemplify the\nquestion extension. Via their exemplifying situations, then, question\nextensions determine possibly multiple topic situations that answers\nare understood to make claims about. When an answer is interpreted as\nexhaustive, the proposition it expresses is understood as\nexemplified by the topic situations. When an answer is\ninterpreted as non-exhaustive, the proposition it expresses is\nunderstood as being merely true in the topic situations. We\nhave, then: \n\nThe proposition expressed by Beatrice’s exhaustive answer in (53) is\nunderstood as exemplified by the topic situations determined by\nJosephine’s question, and that implies that Jason and Willie were the\nonly ones who caught anything. In contrast, Beatrice’s non-exhaustive\nanswer in (54) is understood as being true in the topic situations,\nand that allows for the possibility that there were others who caught\nsomething. \n\nIt might be useful to consider a few more possible answers that\nBeatrice might have given in response to Josephine’s question and find\nout what the exemplification approach would predict if the answers are\nunderstood exhaustively: \n\nThe proposition expressed by 57(a) is exemplified by minimal\nsituations in which two cats caught something. If the topic situations\nare of this kind, they, too, are minimal situations in which two cats\ncaught something. But then the only ones who caught anything in the\nactual world are two cats. Building in maximalization, the proposition\nexpressed by 57(b) is exemplified by minimal situations in which a\nbunch of two to five cats that consisted of all the cats that caught\nsomething in some salient resource situation caught something. If the\ntopic situations are of this kind, then only cats caught something,\nand there were between two and five of them. For 57(c), the set of\nsituations that exemplify the proposition it expresses coincides with\nthe set of situations in which it is true. Consequently, there is no\ndifference between an exhaustive and a non-exhaustive interpretation.\nThe topic situations include the actual world, and what is being\nclaimed about them is that nobody caught anything. \n\nThe examples discussed suggest that the notion of minimality that is\nneeded for the analysis of donkey conditionals also accounts for\nexhaustive interpretations of answers. A third area where what looks\nlike the same notion of minimality shows up is Davidsonian event\npredication. \n\nSituations and events seem to be the same kinds of things. If\nsituations are particulars, so are events. If situations are built\nfrom relations and individuals standing in those relations, so are\nevents.  We don’t seem to need both of those things. We don’t seem to\nneed both situation semantics and Davidsonian event semantics (see\nentries\n Donald Davidson\n and\n events). \n\nThe core of a Davidsonian event semantics are predications like the\nfollowing: \n\n(58) is the classical Davidsonian formalization of the tenseless\nsentence Ewan swim. The predication in (58) is standardly\nread as “e is a swim by Ewan”. Crucially, this\nformula is not understood as ‘e is an event that\ncontains a swim by Ewan’ or as “e is an event\nin which Ewan is swimming”.  In other words, unlike the\nbasic predications in situation semantics, Davidsonian basic\npredications have a built-in minimality condition.  This is a major\ndifference between situation semantics and Davidsonian event\nsemantics, maybe the difference. Without the minimality\ncondition, we couldn’t do many things we want to do with a Davidsonian\nsemantics. As an illustration, consider the following example: \n\nIf the simple predication swim(Ewan)(e) in 59(b) could be\nunderstood as “e is an event in which Ewan\nswims”, then 59(b) could describe an event where Ewan swam for\njust five minutes, but a lot of other things went on as well in that\nevent: He rode his bike, his sister slept, his mother harvested\nshallots, his father irrigated fields, and taken together, those\nactivities took a total of 10 hours. 59(a) doesn’t describe events of\nthis kind, hence 59(b) couldn’t be a formalization of 59(a). The\nstandard way of understanding 59(b) is as saying that there was a swim\nby Ewan that took 10 hours. \n\nBut what is a swim by Ewan? A swim is typically a self-connected\nsituation in which someone is swimming, and which is\n“minimal” in a sense that it excludes other activities\nlike riding a bike, sleeping or farm work. It doesn’t exclude parts of\nthe actual swimming, like movement of arms and legs. Most importantly,\na swim by Ewan doesn’t literally have to be a minimal\nsituation in which Ewan is swimming, which would be a very short swim,\nif there are minimal swimming situations at all. The relevant notion\nof minimality is by now familiar: a swim by Ewan is a situation that\nexemplifies the proposition “Ewan is swimming”. This\nsuggests that the exemplification relation can be used to actually\ndefine basic Davidsonian event predications within a situation\nsemantics. The exemplification relation relates possibly very complex\nsentences to their exemplifying situations. Davidsonian event\npredications emerge as those special cases where the sentences that\nare related to exemplifying situations are atomic. \n\nIf verbs have an event argument, as Davidson proposed, then simple\nsentences consisting of a verb and its arguments always involve\nDavidsonian event predication, and hence exemplification. Importing\nDavidsonian event semantics into situation semantics, the proposition\nexpressed by 59(a), for example, might be formalized as follows: \n\nThe formula in (60) incorporates the usual notation for Davidsonian\nevent predication. Within a situation semantics, this notation is just\na convenient way to convey that swim(Ewan)(e) is to be\ninterpreted in terms of exemplification: we are not talking about\nsituations in which Ewan swims, but about situations that exemplify\nthe proposition “Ewan swims”. \n\nIf Davidsonian event predication is part of the antecedent of a\nconditional, exemplification may come in more than once when\ndetermining the situations the conditional quantifies over. This is\ncrucial for examples like (61): \n\n(61) quantifies over situations that contain just one man and just one\ndonkey, but it does not seem to quantify over minimal donkey rides.\nThere is no pressure to keep the rides short and multiply the treats\naccordingly. A single shift from descriptions of merely verifying to\nexemplifying situations would not yield the correct quantification\ndomain for (61). If we tried to keep the situations small enough so as\nto contain no more than a single man and a single donkey we would have\nto keep the rides short as well. However, if the antecedent of (61)\ncontains Davidsonian event quantification, we can keep the situations\nquantified over small enough to prevent the presence of more than one\nman or donkey, but still big enough to contain complete donkey rides.\nThe proposition expressed by the antecedent of (61) would be (62): \n\nIf the domain for the event quantifier in (62) is established on the\nbasis of some suitable counting criterion, it could quantify over\nmaximal spatiotemporally connected donkey rides. The proposition in\n(62) can then be exemplified by minimal situations that contain a\nsingle man x and a single donkey y and a maximal\nspatiotemporally connected event of riding y by\nx. \n\nThe goal of bringing together situation semantics and Davidsonian\nevent semantics, at least in certain areas, is pursued in a number of\nworks, including Lasersohn (1988, 1990), Zucchi (1988), Portner\n(1992), Cooper (1997), and Kratzer (1998).","contact.mail":"kratzer@linguist.umass.edu","contact.domain":"linguist.umass.edu"}]
