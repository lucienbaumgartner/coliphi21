[{"date.published":"2012-10-01","date.changed":"2017-09-13","url":"https://plato.stanford.edu/entries/innateness-cognition/","author1":"Jerry Samet","author2":"Deborah Zaitchik","entry":"innateness-cognition","body.text":"\n\n\nNativism and Empiricism are rival approaches to questions about the\norigins of knowledge.  Roughly speaking, Nativists hold that important\nelements of our understanding of the world are innate, that they are\npart of our initial condition, and thus do not have to be learned from\nexperience.  Empiricists deny this, claiming that all knowledge is\nbased in experience.  Different Nativist and Empiricist views spell\nout the details in different ways, depending on which elements of our\nknowledge are at issue, what counts as understanding, what is meant by\nthe initial condition, how learning is to be understood, what it is\nfor knowledge to be based in experience, and so on.  There continues\nto be lively philosophical debate about whether there is any\nsatisfactory general account of what it is for something to be innate\n(for a review of some recent work see Gross & Rey 2012).  The\nNativist views discussed here differ in many respects, but all share\nthe broad commitments of the approach.  It should be noted that the\ncommonplace opposition of Empiricism to Rationalism reflects back on\n17th and 18th century philosophical debates in which Nativism was a\ncentral plank in the Rationalist position.  The contemporary Nativist\nviews we consider here are independent of most of the broader Rationalist\ncommitments (see the entry on \n rationalism vs. empiricism), but we note some important and often-ignored connections in section 3.3 of this entry. \n Although it is misleading, it is not uncommon for the\nterms ‘Nativism’ and ‘Rationalism’ to be used\ninterchangeably (see the entry on the\n  historical controversies surrounding innateness).\n \n\nUp until the 1950s, there were no active research programs that were\nlooking for the innate factors in knowledge and cognition that had\nbeen hypothesized and argued for by Nativist thinkers since Plato. It\nwas widely agreed that the centuries-old battles between Empiricists\nand Nativists were over, and that the Empiricists had decisively won.\nThe Nativist situation was actually worse than that: innateness claims\nwere seen as not only wrong, but as ultimately unscientific approaches\nto mind and perhaps incoherent as well.  The prevailing research\nagenda for scientists and philosophers interested in how the mind\nworks was to show how our knowledge and abilities could be fully\naccounted for on the basis of our sensory experiences and the general\nlearning mechanisms that operate on them. \n\n\nBut a number of developments have led to a resurgence of Nativism,\nbeginning with Chomsky’s revolutionary work in linguistics in the\n1950s and 1960s.  This entry places this resurgence in its scientific\nand philosophical context, and will discuss a few important areas of\nresearch to give a taste of the kinds of experimental approaches,\nhypotheses, and theories that have been advanced. A word about the\nfocus of this entry. Most philosophical discussions about innateness\nbegin with careful analyses of the variety of meanings innateness\nclaims can have, consider the sorts of entities that might be at issue\nin such claims (beliefs, ideas, concepts, knowledge, etc.), discuss\nthe epistemological standing of these innate elements, and so\non. These questions are no doubt interesting—and sometimes the\nanswers are interesting too—and such work has its place. But the\nreal action for philosophers is more in the details of the current\nempirical research, and less in the philosophical bookkeeping.\nCognitive scientists are beginning to reveal some of the basic, or one\nmight say ‘primal’, patterns of human cognition. They are\nusing experimental evidence to paint a detailed picture of how we\nhuman beings understand the world—both the physical world around\nus, and ourselves and other selves that are parts of that\nworld. Developmental scientists are trying to figure out to what\nextent and in what ways we are built by nature to arrive at these\nunderstandings. Those we identify as Nativists accord a significant\nrole to our natures, and lean towards the view that we are not built\nto be initially neutral about the world we encounter, in the way that\nclassical Empiricism would lead us to expect. This growing body of\nscientific thinking is of general interest, as evidenced by the\nattention of science magazines and newspapers like the NY Times. But\nthe character of our primal understandings and their innate bases are\nintimately connected to the central concepts and questions that\nphilosophers have always been most interested in. Getting clear on how\nwe naturally think and how we come to think that way is, arguably, a\ncritical element in our understanding of human beings.\n\n\n\nThe entry has three main sections. In the first section,\ncurrent Nativist developments are put in recent historical context,\nespecially the connections between Chomsky’s linguistic\ninnovations and current cognitive science research. The second,\nand longest section, takes up three areas of current research on\nchildren’s early concepts and understanding—of physical\nobjects, number, and mind/agency—to give a sense of the type of\nempirical work being conducted and to highlight some of the promising\nresults that are\n emerging.[1]\nA third section reviews some recent work in\nthe study of development that is close to the Empiricist side of the\ntraditional divide.\n\n\n\nThe reigning experimental paradigms in mid-20th century\nAmerican psychology were for the most part variants of\nBehaviorism. B.F. Skinner’s behaviorist account of language\nacquisition and use (Skinner 1957) in many ways marks the end of this\ndominance—or at least the beginning of the end—because it\nwas the target of a very influential attack by Chomsky (1959). This\nattack convinced many of the inherent limits of behaviorist theorizing\n(see Cowie 2010 for details). \n\nThe defining feature of Behaviorism is its\nanti-mentalism—the methodological claim that one can\n(must) provide a psychological account of human beings without\nreferencing internal mental states. Chomsky’s attack on\nSkinner zeroes in on this\n anti-mentalism.[2]\nThe connection between Behaviorism and\nNativism, on the other hand, is typically given less\nprominence. Although Behaviorism is closely tied to Empiricist\nassociationism and is therefore ‘officially’ anti-Nativist,\ntheories like Skinner’s do incorporate significant Nativist\nelements. Specifically, Skinner took it for granted that every\nanimal has a range of naturally emitted behaviors. Some of these\nbehaviors are responses to stimuli (Skinner’s\nrespondents—e.g., the baby’s suckling response),\nwhile others are just emitted (Skinner’s\noperants—e.g., the baby’s babbling). These\nbehaviors are the raw materials that can be shaped by\nexperience—Skinner’s conditioning and the law\nof effect. So the notion of an innate behavioral repertoire,\nand of innately specified links between environmental stimuli and\nelements of that repertoire, are very much part of the Behaviorist\npicture. This innate repertoire was, as any good Darwinian would\nexpect, highly information rich, because it was shaped by the history\nof problem solving by the animal’s forebears. All parties\ntake it for granted that babies babble, and suckle in the presence of\nthe right stimuli, because such behaviors are part of their biological\nheritage. There might be disagreements about the underlying mechanisms\nand epistemological standing of that heritage, but it is hard to deny\nthat humans are in some sense pre-informed that they need to\nsuck to get milk from the breast. This is a ‘factory\nsettings’ for babies. So if we set aside the controversy\nover the subject matter of psychology (behavior or the\ninternal mind?), and the controversy over the right explanatory\nconstructs (schedules of reinforcement or cognitive\nprocesses?), we find that Behaviorism is actually\ncommitted to innateness claims, and doctrinally\nopposed to any kind of ‘blank-slate-ism’.\nBut this isn’t how things actually played out. Behaviorism\nwas for the most part truer to its affiliations with philosophical\nEmpiricism and Associationism, and its Nativist commitments were\nobscured. One important lesson is that in the Nativism-Empiricism\ndebate we are often dealing with ideology, not theory (Pinker\n2002). \n\nThe impact of Chomsky on linguistics and cognitive science has been\nmuch discussed. Here we briefly review some of the elements\ncritical to the resurgence of\n Nativism.[3]\nChomsky focused attention on two facts about\nhuman languages: (1) that they are very complex, and (2) that children\ncome to master them without much systematic training. The second\nfact is fairly obvious, but the first is not. A very important\nstep, as far as Nativism is concerned, was Chomsky’s notion of a\ngenerative grammar as a framework for articulating the\ncomplexity of a language. A generative grammar of a particular\nlanguage is a system of rules that generates all (and only) the\nsentences of that language, along with a characterization of how each\nsentence sounds and what it means. Chomskyan linguistics is the\nproject of discovering the elements and structure of such rule\nsystems. \n\nThe link between linguistics and innateness comes in a second\nimportant move: the psychologization of grammars. Chomsky argued\nthat every speaker of a language has a mental representation of its\ngrammar. This sets up a natural question—how did the\ngrammar get into the speaker’s head?—and two\ntraditional answers immediately present themselves. The\nEmpiricist would aim to show that the grammar (if it indeed is\nin the head) could be learned from experience in much the way one\nlearns other facts about the world. The Nativist, in contrast, is ready to\nconsider that learning a language—now reconceived as a matter of\ngrammar acquisition—depends in some way on a language-specific\ninnate endowment. This brings us to the third important\nstep. Chomsky argued that a comparison of (i) the grammar that\nhas to be acquired, and (ii) the idiosyncrasies of the acquisition\nprocess and the data presented to the language-learner, favors the\nNativist approach. \n\nSo Chomsky did more than simply point to language learning as an\narea in which the Nativist case might be\n built.[4]\nHis framework for\nspecifying the grammatical rules that the child has to master\nsharpened the debate between Empiricism and Nativism in something like\nthe way that the mathematicization of physics in the 17th\ncentury revolutionized the empirical sciences. \n\nPart of this sharpening is the result of Chomsky’s important\nmethodological distinction between competence and\nperformance. Chomsky argued that a scientific approach\nto language needed to focus on the specific mental representations that\nunderlie linguistic behavior (‘linguistic\ncompetence’), and not on the behavior itself\n(‘linguistic performance’). Linguistic\nperformance, he argued, is scientifically intractable, because it is\nthe result of too many idiosyncratic interacting factors. We\nwould do better to take on the much more circumscribed question: what\nis the system of rules (the grammar) that generates all the allowable\nsentences? It soon became clear that even if we set aside the\nperformance systems involved in real linguistic behavior, the rules of\nthe grammar were themselves very complicated, often unintuitive, and\nabstract, in that they involved categories and constructs that\nwere at a significant remove from the data. The idea that children\ncould simply ‘pick up’ these rules by attending to what is\nassociated with what in their language environment was just not\nplausible (but we will see in section 3 that this claim continues to be challenged). Yet every normal child does in fact learn a language,\nand so does somehow master these rules. So either the general\nlearning system that the child wields is somehow more powerful than the\nAssociationist-Empiricist had assumed, or the Nativist is right and\nthere is some innate language-specific information that ‘greases\nthe wheels’ of language acquisition. To resist the Nativist\nconclusion, the Empiricist has to return to the drawing board to\ndevelop a more powerful general learning theory. Chomsky\ndeveloped the Nativist position and termed the innate information\n‘universal grammar’ or ‘linguistic\ntheory’. This is the essence of Chomsky’s famous\nPoverty of the Stimulus argument, which in an important way\nprovided a measure of the challenge that Empiricism faces.\nThe Empiricist-Nativist debate was no longer\n‘you-say-experience-I-say-innate’ affair; it looked to many\nto be a matter of ‘put up or shut up’, and the burden was\non the Empiricist to do the putting up. \n\nThere was significant controversy about all the elements of this\nparadigm shift: philosophical tangles about the notion of\nrepresentation (in what sense is the grammar ‘in the\nhead’?), technical linguistic debates about the structure and\ncharacter of grammars for specific languages and about the nature of\nuniversal grammar, controversies in psychology about the relevance of\nChomskyan formalisms to experimental studies of child learners and\nadult speakers of a language, and on and on. But the shift\nheld. Linguistics went from a backwater to a central player (as a\nmodel and as an integrator) in the development of cognitive science as\na multi-disciplinary approach to aspects of cognition and mind.\nDevelopmental psycholinguistics, a field more or less born out of these\nupheavals, set out to investigate experimentally whether the details\nabout language acquisition actually supported the Chomskyan Nativist\nhypotheses, and in time, many developmental psychologists broke from\nthe reigning Empiricist paradigm and began to deploy Poverty of the\nStimulus arguments in other areas of cognitive development. \n\nBefore Chomsky, Nativism suffered from two disabilities. The\nolder charge, which we alluded to briefly at the start, was that the\ndoctrine was in some way incompatible with a naturalistic or scientific\napproach to the world. It is true that the Nativist view, as\ndefended by many early modern Rationalists including Descartes\n(1996/1641 and 1911/1647) and Leibniz (1981/1764), did contain (what we\nnow regard as) a supernaturalist element: what was innate was\npresumed to have been placed in us by God. But beside this taint\nof anti-naturalism, there seemed to be another problem, highlighted by\nLocke: simplicity. Locke (1979/1690) argued that, all things being\nequal, we ought to prefer the simpler Empiricist doctrine, which posits\nonly sense experience and general associationist learning, to the\nNativist view, which adds inborn materials. It is this\npresumption in favor of Empiricism that was inherited by modern\nversions of Associationist psychology; it was taken for granted that if\nthere were equally good Empiricist and Nativist accounts, the\nEmpiricist account would be methodologically preferable on the grounds\nof simplicity. \n\nIn light of all this, it is important to recognize that\nChomsky’s advances undercut both these supposed shortcomings of\nNativism. On the first point, Chomsky repeatedly stressed that\nclaims about internalized grammars and universal grammar were\nunexceptional empirical hypotheses about the internal causes\nof the observational evidence. The question of what is built in\nand what needs to be learned is a straightforward scientific\nquestion. It goes without saying that there is no hint of the\nsupernatural in Chomsky’s linguistics: we have the innate\nstructures we do because we are evolved biological organisms. \n\nThis Nativist connection to evolution raises a natural question: why\ndid the resurgence of Nativism have to wait for Chomskyan linguistics;\nwhy didn’t the theory of evolution, developed more than a\nhalf-century earlier, undermine Empiricism and resurrect\nNativism? The Empiricist paradigm, after all, has always promoted\nitself in terms of its very austere view of human knowers: we perceive\nthe world, and learn all we know on the basis of our perceptual\nexperience of it. But as we noted earlier, the Darwinian\nRevolution made it plain that as a general rule, evolutionary\nforces shape organisms to fit into their niche. Such\nshaping, at least in the animal kingdom, was obviously a matter of\npre-organizing the animal’s behavior-producing\nmachinery—the processing that goes on in its brain—so that,\nfor example, birds know that they should eat worms and build nests out\nof twigs and not vice versa. No one tries to explain the\nbird’s competences (and birds’ natural competences extend\nfar beyond this trivial example) purely in terms of the bird’s\nperceptual experience. Birds are not blank slates at birth.\nBut we humans grow from the same evolutionary branches as the animals\naround us. This line of thought leaves us with a few\npossibilities. One is that all the innate preparedness\npainstakingly established in our evolutionary ancestors was somehow\ndiscarded, and we humans were redesigned—from scratch, as it\nwere—as blank slates with a uniquely powerful learning capability\nto make up for our meager initial holdings. This is, arguably,\nthe traditional Empiricist approach. Another is that we inherited\na good deal of what evolution had established in the cognitive systems\nof the organisms from which we evolved, but that our further advance\nwas, to a first approximation, based not on innate factors but on\nlearning. A third view—the Nativist position—is that\nmore was added in the course of our own evolution, and that we too are\nin some way pre-informed about at least some matters most critical for\nour survival. These possibilities are too vague to be taken as\nhypotheses, but the Nativist view seems at least as initially plausible\nas the Empiricist approach. The important point is that it\nshould have been that plausible a century ago. Somehow the\nNativist implications of evolutionary theorizing were\nalso\n obscured.[5]\nEmpiricists\nmight argue that these implications are not relevant to the Nativist\ntradition that they oppose, but the point is that the issue was hardly\nraised. One suspects that a deep cultural and intellectual bias\nwas at work.[6] \n\nThe upshot of this last point is that the presumed advantage of\nsimplicity that Empiricism claimed for itself was illusory. Once\nwe include in our measurement of simplicity how well a hypothesis fits\nwith other established theories, the simpler hypothesis is that human\nbeings are part of the natural biological order, and that like all\nother organisms they are to some degree pre-shaped by evolution to fit\ninto their distinctive ecological niche. The naturalistic view of\nhuman beings ushered in by Darwin should have, all by itself,\nrevived\n Nativism.[7]\nWe might go a step further and ask whether Empiricism itself missed a\ngolden opportunity to deploy evolutionary theory as a vindication\nof Empiricism. A more enterprising Empiricism might\nhave noted that evolutionary theory commits us to the idea that\nwhatever is innate in us was, at least in one sense, shaped by\nexperience. Experience here would be ancestral\nexperience, not the experience of the individual subject, but such a\nview would still ground knowledge in experience. In other words,\nthe range of ‘learning from experience’, the\nEmpiricist’s core commitment, would simply be extended to cover\nnot only individual learning but species-based learning as well.\nBut this opportunity was for the most part missed. \n\nAlthough Chomskyan linguistics set the stage for a general Nativist\nrevival, it took a while for this train to leave the station, and it\nwill help to understand why. Part of the problem was that the\noriginal case for linguistic Nativism had been made, at least in part,\nby focusing on what looked to be unique features of language.\nLanguage has long been seen as exceptional; as the\ndistinguishing feature of human cognition. Chomsky championed\nthis view, and argued that language is central to a special kind of\nhuman creativity (Chomsky 1966). \n\nWe have already noted one facet of this exceptionalism: the fact\nthat grammars are very complex. But there are also unexpected\nsingularities in how children learn; in the learning process\nitself. Each child is exposed to an idiosyncratic sample of the\nlanguage (their primary linguistic data). Each sample is\ncompatible with any number of non-equivalent grammars that all generate\nthe pld sample so far, but give different verdicts about new\ncases not in the pld. We might therefore expect (i) that\nthe grammar a child acquires reflects the idiosyncrasies of the\npld the child was exposed to, (ii) that, as a consequence,\nchildren will disagree about what is and what is not grammatical, and\n(iii) that adults will therefore have to correct them to smooth out\nerrors that reflect those idiosyncrasies. But this, Chomsky\nargued, is not what we find (Chomsky 1965). Children learning a\nlanguage somehow converge on the same grammar, as evidenced by\ntheir agreement about well-formedness, and by the distinctive types of\nerrors they make and don’t make in the course of\nlearning. If this is right, it suggests that the child must have\nprior information that somehow constrains or orders the hypothesis\nspace that steers the child to the right grammar, and it is hard to see\nhow this information can be acquired through experience.\nFurthermore, the pld contain ungrammatical and incomplete\nsentences, but children somehow filter out this noise, and do so\nwithout explicit instructions or feedback. There are a\nnumber of other striking features about language learning that Chomsky\ndrew attention to: (1) it is acquired rapidly, (2) the speed of\nacquisition does not correlate with intelligence, (3) it does not\nrequire reinforcement or extensive explicit training, and (4) it is\nacquired in a critical period—a relatively fixed window\nin the maturation process—during which other less complex systems\n(counting, for instance—see below section 2.3) cannot be\nmastered. Each of these claims has prompted a long trail of\nexperimentation and theory construction, and all remain controversial\n(see, for example, the discussion in Menn et al. 2003). But\ntheir overall effect was to single out language learning as\nexceptional, and perhaps unique. Chomsky himself marked this\ndifference by speaking of language acquisition and contrasting\nit with learning, a term he reserved for induction-based\nprocesses. \n\nSo on Chomsky’s view, language is doubly exceptional. It\nis the distinctive human cognitive trait, and is essentially\ndifferent from all known animal communication systems. The fact\nthat we have it makes us exceptional as a\n species.[8]\nIt is also exceptional in that\nthe pattern of its acquisition suggests that it stands apart from all\nthat we learn about the world; it simply grows in us. Taken\ntogether, these considerations supported a Nativist account of language\nlearning, but tended to discourage the idea of\nexporting the Nativist revolution beyond language. After\nall, how much of the rest of the child’s untutored knowledge of\nthe world is as complex as grammars reveal human languages to be?\nAnd how much of that knowledge comes to the child as effortlessly and\nwithout explicit instruction? \n\nIn time, the arguments for linguistic exceptionalism gave way to a\nbroader view of the Nativist project. Chomsky (1975) set out a\nfully general schema for Poverty of the Stimulus arguments that did\nnot depend on the distinctive features of grammars and\nlanguage acquisition, which had been featured in making the original\nNativist case. Chomsky began to speak of language as one of\npossibly many mental organs that grow in the\nindividual. This naturalistic biological model embeds Nativism\nabout mental organs into a wider and uncontroversial biological\nNativism. It is uncontroversial that kidneys do not develop as a\nresponse to the environment, and they certainly do not copy the\nenvironment. The human body is organized in such a way that in\nnormal (fetal) environments, kidneys will form. This point could\nnow be deployed against the Empiricist. To presume that the basic\nfeatures of our physical-biological nature are\ninternally pre-determined, but that our\nmental-psychological nature is not, but is wholly\nexternally determined, is to introduce a dualism that requires\na special defense. But Empiricism seems to make just this\npresumption, and offers no credible defense. So the tables are\nturned. The Nativist has been freed from the earlier\nsupernaturalism charge, the simplicity-card of Empiricist models turns\nout to be spurious, and now the Empiricist seems to be the one carrying\nan unmotivated dualism as excess\n baggage.[9] \n\nThe mental organs approach has proven to be extremely influential in\nboth philosophy and the cognitive sciences. In its most general\nform, it has displaced the idea of information in the mind as (for the\nmost part) a single uniform set of sentences or data points, and put in\nits place an alternative architecture of systems and subsystems of\nknowledge and information, each, possibly, having its own design,\npattern of representations, specialized function, pattern of\nactivation, level of integration with other systems, (sometimes)\nspecific locus in the brain, and so on. We mention here a number\nof developments significant to the Nativist side that that have grown\nout of this central theme. \n\nThe modularity of mind hypothesis. Fodor (1983) proposed a\nview of our overall cognitive architecture that rested on a rough\ndistinction between input systems, or relatively rigid computational\n“modules” that are designed to pick up specific types of\ninformation, and more flexible central processors that integrate that\ninformation in various ways. Each of these modules has a specific\ntask-orientation, and does its work independently of much of what is\ngoing on in the rest of the system. So, for instance, we more-or-less\nautomatically hear sound patterns as sentences of our native language,\nperceive patterns of light and shadow as configurations of objects in\nspace, and so on. In these terms, the language organ is just one\nof a set of freestanding mental modules. Fodor suggested a\nchecklist of properties that such modules could be expected to have,\nand among them is that they are innately\n determined.[10]\nThe architectural claim about modular\norganization does not in itself imply an innate basis, but the\nhypothesis that the sorts of response patterns to linguistic and visual\ninput (like those just mentioned) have a strong innate basis is\nplausible and has been experimentally pursued. Fodor’s\nversion of the view is now termed a moderate modularity\nthesis, because he holds that much of the business of cognition\ninvolves ‘central’ processing that is decidedly\nnon-modular. Modules do the work of ‘presenting the\nworld’ to highly integrated non-modular global psychological\nprocesses. But others, like Carruthers (2006), have argued that\nwith some adjustment to Fodor’s original characterization of\nmodules, we can argue for massive modularity. \n\nEvolutionary Psychology. One of the controversial\narguments used to defend massive modularity claims is that evolution\nfavors this sort of architecture. This brings us to the central\ndoctrine of Evolutionary Psychology—i.e., that cognition is best\nunderstood as a ‘Swiss army knife’ of special purpose\npsychological-computational mechanisms that evolved to enhance the\nsurvival of our\n ancestors.[11]\nOne much-discussed example of such a\nmechanism is a ‘cheater detection’ module. Our\nancestors needed to distinguish fair-traders from freeloaders.\nThose who could be consistently taken advantage of in exchanges were at\na significant disadvantage in terms of survival. At some point, a\nmechanism evolved—a computational program in the brain, a mental\norgan (or mini-organ?)—that made such vigilance and\nrecord-keeping second nature, and we now all have this module as part\nof our innate endowment. It’s been argued—but the\nclaim continues to be controversial—that the operation of this\nmodule explains the (purported) fact that although we fall prey to a\nclass of reasoning mistakes, we do not make as many of these errors\nwhen our reasoning is related to cheater-detection. For\nEvolutionary Psychologists, the mind is a collection of evolved\nsub-systems adapted to the environments of our Pleistocene ancestors,\nnot to our own\n environment.[12]\nEvolutionary Psychology is arguably the most\nradical Nativist-inspired paradigm, because it looks to make the range\nof the Empiricist’s general purpose learning mechanism smaller\nand smaller. \n\nTo keep the players straight, we must note that Chomsky himself has\nhad a very complicated relationship with evolutionary explanations of\nmind and\n cognition.[13]\nHe\nis certainly not a friend of Evolutionary Psychology, and has joined\nwith its critics in questioning its adaptationist\n perspective.[14] \n\nCognitive Ethology. The modularist position, and the\nNativism that fits it so well, have been supported by recent work on\nanimal cognition, especially the discovery of very sophisticated\ninformation-rich sub-systems in the animal brain (see Andrews 2010 for\na philosophy-oriented review). Early discoveries about complex\nanimal behavior—like Von Frisch’s work on the dance of the\nbees (Frisch 1971)—remained in the shadows during the heyday of\nBehaviorism, but more and more such systems have come to light since\nthen. Just to take navigation as an example, desert ants have an\ninnate dead reckoning module for navigation, and various birds species\nhave intricate innately-based systems based on the fixed stars,\nmagnetic fields, the azimuth angle of the Sun, and so\n on.[15]\nAll these cognitive\nmodules/mechanisms are innately specified subsystems, and add\nplausibility to the Nativist theme that nature has built human beings\nin the same way. \n\nWe have explained the ways in which Chomsky’s work in\nlinguistics inspired subsequent Nativist thinking in the cognitive\nsciences. But there is an irony here in that, except for the very\ngeneral Poverty of the Stimulus schema (which can be traced back to\nPlato), linguistics and language acquisition have not served as\neasy-to-use templates or paradigms for developing Nativist hypotheses\nin other domains. We so far have no reason to think that there is\nany domain outside language that requires anything as complex as a\ngrammar of a natural language to represent it. So linguistic\ncompetence remains an exceptional element in our\ncognitive\n make-up.[16]\nAnd even\nthough some of the distinctive features of language acquisition have\ncounterparts in other domains—sensitive and critical periods in\nthe development of visual perception, for example—there does seem\nto be something exceptional about the way virtually every normal child\ncomes to master a language. We might say that for Nativists,\nlanguage has been more an inspiration than a working model. But\nat the same time, as Nativists move beyond language, they may avoid\nmany of the methodological challenges to the Chomskyan approach\n(including: is a grammar a theory of competence, in what sense are\ngrammars ‘mentally represented’, is the pld all\nthat’s relevant to acquisition, etc). \n\nA full account—even a comprehensive survey—of Nativism\nin the cognitive sciences is beyond the scope of this entry. But there are a number of\nconceptual domains that have been especially well investigated by\ncognitive scientists in the last decades, and this section will\nhighlight a few areas that are the subject of lively and theoretically\ninteresting work, and that are connected to traditional and\ncontemporary philosophical concerns. \n\nThe research we will discuss in this section is inspired by the\nChomskyan paradigm, but there is an important difference between the\nlanguage case and this developmental work. Chomsky’s\nLinguistic Nativism used Skinner’s Behaviorism as a foil, but the\nBehaviorist paradigm was not the reigning scientific paradigm\nin the area of child development. In this field, the Swiss\npsychologist Jean Piaget was the dominant figure, and his research has\nserved as the backdrop for most developmental work over the last 40 or\n50\n years.[17] \n\nPiaget generally ignored Behaviorism, and conducted experimental\nstudies on the child’s evolving conception of the world.\nHis extensive research agenda included the child’s understanding\nof space, time, God, objects, causality, morality, dreams, number,\nbeing alive, and more. Piaget’s specific questions and\nexperimental results—which were reciprocally (mostly) ignored by\nBehaviorists—have served as a jumping off point for many\nNativist-oriented theorists. But Piaget was not a Nativist.\nThe heart of the Piagetian paradigm is his stage\ntheory. On this view, children start with a very different\nconception of the world than adults have—in fact, Piaget thought\nthat they start without a conception of an external world at\nall—and they go through a series of identifiable stages that\nculminate in adult understanding. The powerful unifying idea here\nis that there is something about the general character of these stages\nthat is the same across all domains of understanding, and that the\ndynamics of stage transition is also uniform. To a first\napproximation, for Piagetians there are no significant distinctions\nbetween the developmental patterns in different domains of\nunderstanding. If we consider any domain, the stage theory\nimposes a uniform grid of steps in the development of that domain\nknowledge. The dynamic picture, again very roughly, is that a\nchild at a stage proceeds until she faces an insurmountable obstacle;\nher present grasp of things makes it impossible for her to deal with a\nrecalcitrant problem. This disequilibrium propels her to the next\n(pre-plotted) stage, in which new internal resources become\navailable—an enriched conception of the world or a new\nflexibility in physical interaction—and the earlier problem can\nbe resolved. The child recovers equilibrium until coping with\nproblems again causes a crisis that leads to the availability of more\nnew resources, and so on. The articulation of the Piagetian\nparadigm involved understanding the general nature of these\nstage-transitions better, exploring how the stage theory operates in\nspecific domains, and understanding the new cognitive and behavioral\nresources that make these transitions possible. \n\nPhilosophers will recognize the theory as in some ways analogous to\nthe theories of scientific development proposed by Thomas Kuhn\n(1962/1996) and others. Two important differences are worth\nmentioning, because they highlight what is distinctive about\nPiaget’s approach. First, although science develops\norganically, there is, for Kuhn, no one specific resource that\napplies across all fields. What explains the shift from\none dominant paradigm to another in economics will typically not\nexplain the shift from the Ptolemaic to the Copernican paradigm in\nastronomy. But Piaget held that what makes it possible for the\nchild to advance in her understanding of space is in one sense the\nsame thing as what facilitates the stage transitions in the\nchild’s developing understanding of God or morality.\nSecond, science depends on the contingent, uniquely fruitful\ninnovations that overthrow older understandings and set the stage for\nnew ones. But in children, Piaget’s developmental stages\nare posited as mandatory; we might say they are innately prescribed\nsteps in normal development. The child’s forward motion is\nregularized as the world presents its predictable problems, and the new\nresources become available to solve them and advance the child’s\nunderstanding. The upshot is that although Piagetians produced\nprobing and highly detailed studies of various domains of the\nchild’s understanding, they shared the Empiricist preference for\nan across-the-board domain-general mechanism that could explain the\ndevelopmental facts in every domain. Although there are\ninteresting ideas inherent in the Piagetian paradigm about the innate\nendowment that makes adult cognition possible, it is not easy to place\nPiagetian Constructivism on the Nativist-Empiricist\n spectrum.[18] \n\nPiaget’s theories provided the scientific received view\nagainst which developmentalists inspired by Chomsky’s linguistics\nreacted. These researchers set aside Piaget’s assumption\nthat development is uniform across domains, and instead—in part\ninspired by Chomsky’s organology and modularity\nclaims—considered each domain independently. The overall\nstrategy was to discover the cognitive capacities of the youngest\nchildren, and to develop and test hypotheses about (i) the initial\nstate, and (ii) the transitions that move the child from the initial\nstate to the normal adult repertoire. \n\nThe ‘Core Cognition’ hypothesis. Many\ndevelopmentalists in this camp share a commitment to the ‘Core\nCognition’ (sometimes called ‘Core Knowledge’)\nhypothesis (Carey 2009; Carey\n& Spelke 1996; Spelke et al. 1992; Spelke 1998, 2000, 2003). According to this hypothesis,\nevolution has equipped our species (and other species too) with an\ninnate repertoire of conceptual representation types, that is,\nrepresentations that cannot be reduced to the perceptual primitives\nfavored by the Empiricists or the sensory-motor primitives favored by\nPiagetians. Rather, evolution has shaped our perceptual input\nanalyzers to detect certain types of entities in the world, and has provided us with principles—embodied in our cognitive machinery—that determine how we (at least initially) think about such entities. These different types of\nentities are few in number. To date, there is a consensus among proponents of this\nhypothesis that the innately specified core domains\ninclude physical objects, number, and minds.[19] Proponents of the\nCore Cognition view defend a moderate Nativism; they leave work for learning mechanisms, which, together with\nmaturation, take the infant from limited ‘core’\nconceptual systems to the broad and highly elaborated knowledge of\nthe world that adults have. In some cases, adult knowledge\nextends the core; in others it ‘over-writes’ it. The conceptual machinery that embodies a core domain is often referred to as an ‘intuitive theory’—for instance, a folk physics or folk psychology (sometimes theory of mind)—to highlight the fact that each supports patterns of conceptualization of input and inference.  There is intense ongoing work on core domains, and research paradigms are being extended to non-human animals and across cultures.  In\nthe sections that follow, we review select findings on three\ndomains: physical objects, number, and intentional agents.[20]\nWe concentrate on very early\ndevelopment. While it is often difficult to say what\nexactly the research reveals about the young child’s\nknowledge (for methodological as well as philosophical\nreasons), the earlier some distinctive elements of a competence are\npresent, the less likely that it was learned solely on the\nbasis of experience. \n\nMethodological innovation: the\n‘violation-of-expectancy’ looking time. The work\nwe discuss depended on solving a knotty methodological problem: how to\ndiscover what is going on in the minds of preverbal infants and very\nyoung children? Though infants cannot report on what they are\nperceiving or thinking, one can make inferences from their reactions to\nobjects and events. Long before they utter their first words,\nthey suck, grasp, creep, crawl, and—most importantly—they\nlook. Since infants, like adults and other animals, look longer\nat an unexpected stimulus, where they look and for how long they look\ncan reveal a good deal about their expectations about the\nworld. While measures of grasping, crawling, and sucking have all\nbeen successfully used to reveal some of what is going on in the baby’s\nmind, the measure that has been used most extensively is the\nviolation-of-expectancy looking time (sometimes called\npreferential looking time). Experiments using this measure\ntend to have a similar structure: during an initial phase, the child\nis presented with display \\(X\\), over and over, until the child’s\ninterest wanes and looking time drops down to some criterion\n(the habituation phase). In the test phase, the\nchild is presented with two displays: \\(Y\\) and \\(Z\\). If\nthe child reliably looks longer at \\(Y\\) than at \\(Z\\), this\nprovides evidence that \\(Z\\) is as expected, but that \\(Y\\)\nis unexpected. \n\nAs adults, we recognize physical objects as bounded entities that\npersist through space and time; they ‘hold together’ as\nunits, and their paths, when they move, are continuous. In addition, objects causally interact upon contact\nwith each other. Do we learn these properties of objects by\nexperience, and if so, by what sort of\nexperience? Empiricist thinkers have argued that these properties\nare learned, and have proposed several different types of experience as\nrequisite input to such learning. Helmholtz (1867/1962) suggested\nthat moving around objects and manipulating them were necessary for\nbuilding a concept of an object. Quine (1960) looked to language\nas the relevant source of information, and Piaget (1954)\nproposed that sensorimotor coordinations led to construction of the\nconcept of a physical object. Indeed, Piaget famously argued that\ninfants altogether lack object permanence (1977), the\nunderstanding that objects persist in time and space, until the latter\nhalf of the second year of life. \n\nObject permanence. In the last 35 years,\nthe baby’s representation of objects has been re-explored with\nstriking results. A landmark study (Baillargeon et al. 1985) used\nthe violation-of-expectancy paradigm to test the Piagetian claim that\ninfants lack object permanence. Five-month-old infants were shown\na screen that rotated 180 degrees up from the surface of a table and\nback again to its initial position. In the habituation phase, the babies\ngot used to the screen motion and their looking time decreased,\nevidence that they no longer found the screen’s movement to be\nnovel. In the test phase, an object was placed in the path of the\nscreen as the screen moved downward to the table’s surface.\nIn one outcome, the screen rotated down until it touched the object and\nthen rotated back up to its initial position, an event that adults\nrecognize as possible. In the other outcome, the screen continued\nits downward trajectory to the table, at first hiding the object and\nthen apparently moving right through the space occupied by the object,\nan event that adults recognize as physically impossible. The\nlogic here is straightforward: babies will see the second outcome as\nsurprising only if (i) they represent the object as continuing to exist\neven when it can no longer be seen behind the screen, and (ii) they\nassume that two objects cannot occupy the same space at the same\ntime. Only then should they look longer at what adults recognize\nas an impossible event. If, however, young infants lack object\npermanence or have no constraints about two physical objects occupying\nthe same space, the impossible event will not constitute a\nviolation of any expectation. The results were clear; babies\nlooked longer at the impossible event, indicating that it violated\ntheir expectation of objects. The same finding was later\ndemonstrated with 4-month-olds (Baillargeon 1987). These findings\noffer evidence that very young infants represent objects as persisting\neven when they are no longer in view, an understanding of object\npermanence thoroughly at odds with the claims of Piaget and\nQuine. One may still ask what exactly the child\nknows or represents (Burge 2010 is especially\npertinent here), but the point is that there is something in\nthe child’s cognitive apparatus that is sufficient to generate\nthis expectation, and the burden of explanation is on the view that\nthis is learned from experience. Moreover, these infants also\nexpect that two objects will not occupy the same space at the same\ntime. \n\nSpatiotemporal continuity of objects. As adults, we know that\nobjects are spatiotemporally continuous; an object that appears at\npoint \\(A\\) and then at point \\(B\\) must have traversed a\ncontinuous path between these points. Here too the violation of\nexpectancy looking time paradigm has been used to test the Empiricist\nclaim that such knowledge requires an extended learning period. In one\nstudy (Spelke et al. 1995), 4.5-month-olds were shown a stage with 2 screens on it, with a\nvisible gap between the screens. In the discontinuous motion\ncondition, each screen has an object hidden behind\nit. First, the object behind the left screen is moved further\nleft so that the baby sees it, then it is moved back behind that same\nscreen. The object behind the right screen is shown in the same\nway, so that during these displays only one object has been visible at\na time and no object has ever been shown to cross the gap between the\ntwo screens. Adults seeing this display infer that there are 2\nobjects involved. To find out if babies make the same inference,\nthe screens are removed and the infant is shown either one object or\ntwo objects. The result is that infants look longer at the\none-object display, presumably expecting, like adults, that there had\nto be two objects; otherwise, the object would have been visible\ncrossing the gap. In a follow-up study, a continuous motion\ncondition was used. This condition is identical to the previous\ncondition except that, between the alternating trials, an object\nis seen crossing the gap. In this condition babies\nlooked longer at the display of two objects. Like\nadults, they presumably assumed there was a single object moving back\nand forth (Aguiar & Baillargeon 1999 report similar findings\nwith 2-month-olds).  Generally, by 2-months, and perhaps earlier, infants expect that objects persist through time, move continuously, have parts that cohere, and are solid (Spelke 1990).  Recent work (Rips & Hespos 2015) shows that by 6-months, babies already have different expectations for rigid bodies, soft objects, and liquids. \n\nIf the representation of spatiotemporally continuous objects is part\nof our evolutionary endowment, we might expect to find such\nrepresentation in the newborn of other species, and indeed we\ndo. Newborn chicks, for example, display a striking ability to\nrepresent spatiotemporally continuous objects (see Spelke 1998 for\nreview). In one study, newborn chicks spent their first day of\nlife in a homogeneous environment containing only one inanimate object.\nOn their second day, the object was moved fully out of view\nbehind one of two screens. Though they had never before seen an\nobject hidden behind another, they reliably searched behind the correct\nscreen where the object was hidden. Indeed they even did so when\nthey had to turn away from the object in order to reach it (Regolin et\nal. 1995; Regolin et al. 2000). Chicks, it seems, have object\npermanence from birth. Although this does not show that\nobject permanence is innate in humans, it does show that in at least\none animal, evolution has succeeded in building it in.\nSo Nativists can claim an existence proof of an innately endowed\nrepresentation of objects as permanent. \n\nWynn (1992) showed that young babies represent objects as not only\npersisting in time and space, but also as subject to addition and\nsubtraction. In that study, babies were habituated to a display\nof a single object on a stage. Then a screen came up and hid the\nobject completely. Now a hand was seen to bring in another\n(identical) object and move behind the screen, from which the hand then\nwithdrew empty. The question was: do the babies now represent 2\nobjects behind the screen? Test displays consisted of 1 object, 2\nobjects, and 3 objects. Again, in line with Nativist claims,\nbabies showed longer looking times to all displays except the\n2-object display. In this respect, babies showed the same\nexpectations that adults do. Further testing showed that babies\nare not only capable of ‘adding up’ the number of hidden\nobjects (at least to 3), but are also capable of\n‘subtraction’ of the same number of hidden objects as well.\nThis finding has been replicated in 4- and 5-month-olds as well\n(Simon et al. 1995; Koechlin et al. 1998). \n\nIt may be tempting to see the infant’s ability to add and\nsubtract the number of objects in a display as evidence that infants\nalready have something close to the adult concept of number, but a\nseries of studies suggests that this is not the case. Most\ntelling is the extremely limited set size (about 3 objects) over which\nthe baby can add or subtract. To illustrate this set size limit,\nwhich has emerged in a variety of experiments, consider the following\nstudy that used crawling, rather than violation-of-expectancy, as an\nindicator of the baby’s representation (Feigenson & Carey\n2005). In this study, babies watched as graham crackers were\nplaced, one at time, into 2 separate boxes. The babies were then\nallowed to crawl to the box of their choice and retrieve the\ncrackers. When one box had 1 cracker and the other box had 2,\nbabies crawled to the box with 2. Similarly, when one box had 3\ncrackers and the other had 2 or had 1, they crawled to the box with\n3. The surprising finding, however, is that babies failed with 4\nversus 3, 4 versus 2, and even 4 versus 1. Apparently, the\nability to represent and keep track of exactly 4 objects is beyond the\nbaby’s capability. Given the set size limit of 3 objects,\nit is arguable that the baby’s competence should be understood as\nan ability to track 3 different objects in working memory. One\nmight argue that the baby can succeed in adding and subtracting very\nsmall numbers of objects without having a general concept of number\nor any general numerical competence. We return to this issue\nin section 2.3. \n\nAs mentioned above, Piaget (1954) proposed that sensorimotor\ncoordinations gradually lead to construction of the object\nconcept. Establishing these coordinations between different modes\nof perceptual experience—vision and touch, for\nexample—would take time, and Piaget proposes that it is not until\nthe child is 18–24 months that these coordinations have been\nconstructed. Meltzoff\n& Moore 1977 provide counter-evidence to this claim. This study shows that newborn infants\ncan imitate the facial movements of an experimenter, clearly revealing\nthe coordination of their own movements (along with the attendant\nfeelings of their muscles) and their visual perception of the\nexperimenter’s facial movements. The following video links\n(Ferrari et al. 2006,  videos S1 and S2)\nprovide some evidence\nthat newborn rhesus macaques have this ability as well. Insofar\nas these coordinations of different modes of perceptual experience are\npresent at birth in humans and in monkeys, they simply could not be the\nproducts of learning.  \n\nThere is currently a great deal of empirical research—and\nphilosophically sophisticated\n debate[21]—on\nthe underpinnings of numerical knowledge\nin adults and children. There is strong evidence for the view\nthat in addition to an exact number system that underlies\nformal mathematical thinking, adults also have an analog magnitude\nsystem for representing approximate number (see Dehaene\n1997). For example, if we are very briefly shown 2 bowls of rice,\none with 20 grains and one with 50, we can tell immediately which has\nmore, even though we couldn’t say exactly how many grains of rice\nwere in either. Similarly, shown a book with 70 pages and a book\nwith 100 pages, we can see instantly which has more pages—though\nagain without knowing the exact number of pages in either book.\nControlled tests show that such judgments are independent of variables\nthat correlate with magnitude, such as the extent of space occupied or\nthe size of the individual stimuli. The ‘signature’\nof this analog magnitude system is its ratio dependence: that\nis, the difficulty in comparing two analog magnitudes decreases as the\nratio difference between them grows. Recent studies indicate that\nthe smallest ratio difference needed for adults to successfully\ndiscriminate 2 different analog magnitudes is 8:7. If the ratio\nis smaller, error rates in comparing magnitudes spike up. \n\nAnalog magnitude representations in\ninfants. Recent studies have shown have\nshown that 6-month-olds use this same analog system to discriminate\nnumerical arrays (McCrink & Wynn 2004b; Xu\n& Spelke 2000). In one study (Xu & Spelke 2000),\ninfants were habituated to displays of either 8 dots or 16 dots.\nWhen shown novel dot displays, babies who had originally seen 16 dots\ndishabituated to displays of 8, but remained habituated to the new\ndisplays of 16. Similarly, babies who had been habituated to 8\ndots dishabituated to novel displays of 16, but not novel displays of 8\ndots. (Again, researchers controlled for the cumulative amount of\nspace occupied by the dots, the density of the dots, and the size of\nthe dots.) A series of studies have now shown that 6-month-old\nbabies can use the analog magnitude system successfully so long as the\nmagnitudes differ by a 2:1 ratio. When presented with dots\ndisplays that have a 3:2 ratio, such as 24 to 16, babies this age do\nnot show discrimination. Note that the necessary ratio for\ndiscrimination gets smaller with age, so that 9-month-olds succeed when\nthe magnitudes differ by 3 to 2. One might have thought that this\nability to discriminate approximate quantities is somehow implemented\nin the visual system, but the analog number system has been shown to\noperate at a more abstract level (or perhaps to be implemented in a\nnumber of perceptual modalities). At any given age, the same\nratio applies no matter whether the stimulus is a number of dots in a\nspatial array or the number of tones in an auditory sequence (Lipton\n& Spelke, 2003)—or even a number of events (jumps) in a\nvisual display (Wood & Spelke, 2005). \n\nNot only do these representations support comparisons of magnitude,\nthey have also been shown to support approximate addition and\nsubtraction in babies as young as 9-months-old. In one study,\nbabies were presented with a set of 5 objects that moved behind a\nscreen so they were no longer visible. Then another set of 5\nobjects was presented and they too moved behind the screen. When\nthe screen was removed, babies looked longer if there were only 5 objects\nthan if there were 10. In a parallel subtraction condition, where\nbabies first saw 10 objects move behind the screen, and then saw\n5 objects taken away, they stared longer when the screen was removed to\nshow a display of 10 objects (McCrink & Wynn, 2004a). \n\nThe approximative analog system we have been discussing is different\nfrom the object-tracking system mentioned earlier (for instance, in the graham cracker\nstudy). The infant’s object-tracking system has a severely\nlimited set size, and this is true of the adult’s tracking system\nas well. The analog magnitude system does not. It has also\nbeen found that infants’ success shows the ratio-dependence\nprofile of the analog magnitude system. The fact that 6-month-old\nbabies appear to use the same system of analog representation that\nadults do—although, again, their discriminations are less\nfine—strongly suggests that humans come equipped with an innate\nsystem that makes it possible for them to make relative size\ndistinctions across modalities. Very recently this hypothesis has\nbeen given strong confirmation by a study showing that the analog\nmagnitude system operates in newborn babies (Izard et al. 2009).\nIn this study, newborns were familiarized with auditory sequences\ncontaining a fixed number of syllables and were then tested with\nvisual-spatial images of the same or a different number of\nobjects. Infants spontaneously associated stationary,\nvisual-spatial arrays of 4–18 objects with auditory sequences\n(spoken syllables) on the basis of approximate number, providing\nevidence for abstract numerical representations at the very\nbeginning of postnatal\n experience.[22] \n\nIs the analog system species universal? If this\nanalog numerical system is innate, it should be found in all human\nsocieties, no matter how urban or rural, educated or unschooled,\nwhether in technologically advanced societies or remote and isolated\ntribal villages in other parts of the\n world.[23]\nIf it is the same system evident in the\nyoungest infants, it should not require exposure to any symbolic\nrepresentations of number, such as Arabic numerals or a number\nlexicon. To test this hypothesis, investigators explored the\nanalog number system in the Amazonian Munduruku people, an isolated\ntribe whose language has no words for numbers greater than 5. As\npredicted, the Munduruku compared and added large approximate numbers\nfar beyond their naming range. Moreover, performance decreased as\nthe ratios decreased, just as it did in a group of French control\nsubjects (Dehaene et al. 2008). \n\nAnimal representation of approximate quantities. If this\nnumerical system (what Dehaene has called our number sense) is\npart of our innate endowment, might it be evident in other primate\nspecies? Hauser and his colleagues (Hauser et al. 2003)\npresented cotton-top tamarins with auditory sequences of syllables of\ndifferent numerosities. Like humans, monkeys orient their\nattention to unexpected stimuli. When they hear a sequence of\nsyllables of an unexpected numerosity, they turn their heads toward the\naudio speaker from which the sounds are emanating, providing a reliable\nindicator of their discrimination of the novel number. The\nresults are similar to those of the infant studies: cotton-top tamarins\ndiscriminated between sequences of syllables based on approximate\nnumerosity alone. Moreover, discriminability depended on the\nratio of the numbers, just as it does in humans. Indeed, adult\ntamarins showed comparable discrimination abilities to nine-month-old\nhuman babies. \n\nThere is now a sizeable literature showing the presence of analog\nmagnitude representations in many different kinds of animals, including\nrats, crows, pigeons, a parrot, rhesus macaques, apes, and dolphins\n(see Carey 2009 for review). In short, there appears to be\nexcellent evidence from studies of human adults, human babies, and\nanimals, all suggesting the presence of an ancient evolutionary system\nof approximate number representation. \n\nIf one steps back from the theoretical heat of the\nEmpiricist-Nativist debates, it should not be surprising that we have\nan innate system for discriminating sets by their approximate size, and\nthat this system is found in other animals too. Animals typically\nneed to take some measure, for example, of the relative size of food\nsources, of the relative number of predators on their left and right\nflanks, and so on. In some animals, these abilities may be part\nof an encapsulated system devoted to a specific task. The\nbee’s awareness of the relative size of a discovered food\nsource—information communicated in the scout’s\ndance—is a popular example of this sort of ability (Frisch\n1953). In other animals, the system operates more broadly, and\ndifferent sorts of inputs can be measured in this way (heard sounds,\nperceived jumps, and so on). It is as if the brain has an\n‘accumulator’; a bar graph system of some kind that maps\ninput arrays into some neutral format and appends the elements together\ninto a stack, and a scanner that judges relative stack size.\nGelman and Gallistel and others have explored such systems extensively\n(starting with Gelman & Gallistel 1978). \n\nEqually unremarkable is the fact that crawling infants distinguish 1\ncracker from 2 and 2 from 3. This discrimination is beyond the\nabilities of the posited analog approximative systems. But it\nsuggests that there is another system in the child that is in a limited\nway sensitive to number. This system—which seems more tied\nto attention—is the subject of current research (see, for\ninstance, Pylyshyn 2007). Animals need to keep track of changing\nelements in their immediate environment. One idea under investigation is that there\nis a psychological subsystem system that ‘tags’ elements in\na perceptual array and keeps track of them by assigning properties to\nthe tag. Without such a system, we would lack the ability to\nre-identify changing elements from one moment to the next. Such a\nsystem therefore seems to be a prerequisite for any perception of a\nworld/scene, as involving things that are moving and changing. It\nis difficult to see how an animal that does not track in this way could\nlearn to do so (although the ability might grow). \n\nIf current thinking about these systems is on the right track, we\nhave two innate systems, each of which deals with number in some\nsense. The analog system takes a range of perceptual\npresentations and assigns an ordering by relative magnitude. The\nsecond system identifies and tracks (a limited number of) discrete\nelements in an environment. A current research question that is\nof particular interest to philosophers is this: what is the relation of\nthese innate systems to the adult concept of number.\nNotice that the analog system does not get us to the concept of an\nexact number. Only ranges are detected—the system can judge\nthat two sets are in the same range (below the ratio-threshold for\ndiscrimination), but two arrays that are “the same” in this\nway need not have the same number of elements. The\nsecond system is not approximative. If the subject has\ntracked 2 objects and 1 is added, as in Wynn’s studies, the\ndifference is noted and the subject’s expectations change\naccordingly. So this object-tracking system is sensitive to\nthe number of units in play, and in this respect is closer to\nthe adult notion of number. But it has an extremely constricted\nrange, and is useless when it comes to problems that extend\nbeyond its range. The crawling infant in the study cited earlier\ndoesn’t represent an added 4th cracker as one more\nthan the 3 previously tracked. The infant doesn’t even\ntrack the 4th element: the system seems to\n(eccentrically) shut down completely when its range is exceeded.\nSo the concept of number—the successor function and all that it\nbrings in its wake—is not implemented in this system. \n\nFor these reasons, some have argued that aside from these\nwell-evidenced systems, there must be a third element in the human\nmind—viz., an innate concept of number, which must involve the\ngrasp of a fully-general successor function—that grounds adult\nmathematical competence (see Leslie, Gallistel & Gelman 2007,\nfor example). Others, like Carey (2009) have argued that the\nconcept of exact number is not innate, but is constructed by\nthe kind of language-based bootstrapping sketched out by Quine (1960).\nThe debate here is especially interesting because although both sides\nare Nativist—in that both accept innate ‘numerical’\nsystems—there are still learning elements in play in the search\nfor an adequate psychological account of our distinctive arithmetic\ncompetence. \n\nThe simple question: “Is number innate?” turns out to be\ntoo simple. However the current debates play out, we can expect\nthat the achievement of adult number competence is quite complex and\ninvolves significant innate and learned elements. We should be\nprepared to find that things are no less complicated on other\nEmpiricist-Nativist battlegrounds. \n\nIn a seminal paper of 1978, Premack and Woodruff posed the question\nof whether chimpanzees have a ‘theory of mind’; that is, do\nthey attribute mental states to others, and do they, like adult humans,\npredict and explain action on the basis of hypotheses about these\nstates. It was a mark of Piaget’s influence that no one had\nas yet asked this question in regard to human infants; Piaget thought that they did not yet have a robust notion of an external world at all, let alone of a world containing minds.  The chimp\nstudies led to an explosion of research into the development of a\ntheory of mind in human beings. In responses to Premack and\nWoodruff’s paper, Dennett and others commented that the\nsuccessful prediction of another’s action does not yet constitute\nevidence for a theory of mind. Consider the following: a child\nparticipant in a study is told a story about a boy named Max who has a\npiece of candy. Max puts it into the red cabinet and goes out to\nplay in the yard. The child participant is asked, “When Max\nreturns and wants to get his candy, where will he look for\nit?” The child might answer correctly because he\nor she understands that Max will think that the candy is where\nhe left it or last saw it (i.e., the red cabinet). This involves\nattributing mental states to Max. But the child might also answer\ncorrectly because that’s where the candy actually is. That\nis, the child with no theory of mind might still answer correctly\nsimply by reasoning that people go to get things where they\nare. The way to resolve this uncertainty, Dennett proposed,\nwas the false belief task. In this task, which quickly\nbecame the litmus test of a theory of mind, the story includes a second\ncharacter who enters the scene while Max is still outside in the\nyard. This second character finds the candy in the red cabinet\nand puts it into the yellow cabinet. Once again, the child\nparticipant—who has seen the transfer—is asked where Max will look for his candy when he returns\nto the kitchen. Only if the child is successful now, responding\nthat Max will look in the red cabinet—even though the\nchild knows that the candy is really in the yellow cabinet—can we\nlegitimately attribute to the child a theory of mind. There is\nnow a very large literature involving the false belief task and the\nbottom line appears to be that most young 3-year-olds incorrectly\npredict that Max will look in the yellow cabinet (or, in some studies,\nsay that Max thinks it’s in the yellow cabinet)\nbecause that’s where it is, while somewhere between the\nages of 3.5 and 4, children begin to succeed on the\n task.[24] \n\nFor two decades, success on the false belief task was considered the\nonly really hard evidence for a claim that one had a theory of mind.\nWhatever social competence children showed before passing the\nfalse belief test was widely considered a precursor to having\na theory of mind. More recently, however, cognitive\ndevelopmentalists have argued that success on the false belief task is\nneither necessary nor sufficient for the attribution of a theory of\nmind, and that focusing nearly exclusively on it has led to an overly\nnarrow view of the conceptual domain (Bloom & German\n2000). The last several years have seen a plethora of studies\ninvestigating the attribution of mental states, and social cognition\nmore broadly, in infants. The next section focuses on a group of\nkey concepts involved in understanding minds including\ngoals, agency, and rationality. \n\nWoodward’s 1998 study on goal understanding in 6-month-olds is\na good example of the pattern of recent work in this area.\nInfants watched a hand move across a stage and repeatedly grasp one of\nthe two objects on opposite sides of the stage. The hand always\nmoved along the same path to the same side of the stage and then always\ngrasped the same object. After the infants habituated to this\ndisplay, Woodward switched the location of the two objects. Now\none of two events occurred: either the hand took a different\npath to grasp the same object it had always grasped (that object now being on the other side of the stage) or it took the\nsame path as before, but now grasped the other\nobject. Looking time showed that infants were more surprised when\nthe hand followed the same path and grasped the other object than when\nit followed a new path and grasped the originally grasped object.\nThis would make sense if the infants understood in some sense that the\npreviously grasped object was the hand’s preferred\ngoal. To see if this was really the basis of the\nbabies’ looking responses, control conditions were included to\nrule out a variety of other possibilities. \n\nIn a control condition, the hand was replaced with a rod that had a\nmulti-fingered sponge at the end. When the rod/sponge followed\nits old path and touched the new object, babies did not dishabituate;\nthey dishabituated only when the rod/sponge followed a new path to the\nold object. The suggestion is that the babies did not see the\naction of the rod/sponge (whose shape was similar to the shape of the\nhand) as a goal-directed action. What is it about the\npresence of the human arm that signals a goal? Would any movement\ninvolving repeated contact between a human hand and one of the toys\ntrigger goal attribution? Woodward (1999) shows that this is not the\ncase. In this study, a human arm was used again, but this time\nthe arm merely dropped onto the display, and contact was between the\nback of the hand and the toy. In this case, there was contact,\nbut not grasping. In this condition, adults would be less likely\nto interpret the action as purposeful, and the same was true of the\nbabies. When the hand/arm followed its earlier path (touching the\nnew object), babies did not dishabituate; they did however dishabituate\nwhen it followed the new path, even though it made contact with the\nsame object as before. This suggests that 5-month old babies,\nlike adults, attribute goal-directedness (again: ‘in some\nsense’) to human arms and hands that reach and grasp,\nbut not to arms that only drop and make passive contact with the\nobject. \n\nWhat clues do babies use to determine if a perceived motion is\ngoal-directed? The previous study suggests that they are finely tuned to complex patterns of self-directed bodily activity.  One might hypothesize that babies first\nrestrict their attributions of goals to humans only and then, with\nexperience, extend the range to include non-humans as well (Woodward\n2005; Meltzoff 2005). But a recent study, however, suggests that this\nmay not be so. In this study (Luo & Baillargeon 2005),\nbabies reliably attributed goals to a moving box, which they were\npreviously shown could move on its own. The key difference\nbetween the rod/sponge in Woodward’s study and the moving box in\nthis study appears to be information about autonomous\nmotion. The rod/sponge never showed such capacity; the\nmoving box did. Autonomous motion, the authors argue, signals an\nobject’s status as an agent, and agents, for the baby,\nhave goals. These results have recently been extended to\n3-month-olds (Luo 2011). \n\nA very recent study has shown that infants are sensitive not only to\nclues indicating an agent’s capacity for autonomous motion, but\nto the perceptual information available to the agent as well and to the agent’s preferences.\nRemarkably, this is true even when this information differs from\ntheir own. In Luo and Johnson (2009), 6-month-old babies saw another person look at 2 different objects and repeatedly reach for the same one. As indicated by their looking times, babies in this condition attributed to the other person a preference for the chosen object.  In contrast, in a condition where the baby saw 2\nobjects, but also saw that the other person could see only one, no preference was attributed. In this case, it seems, the baby\nappreciates that the other person cannot see the second object and that\ntherefore the repeated grasping of the first object does not indicate a\npreference. This suggests that babies at this age can already\nattribute different perceptual information to different perceivers\n(what I see vs. what she sees). Nativists expect to find\nsimilar sorts of perceptual preparedness for other systems of knowledge\nand action (for instance, a system of face recognition as preparedness\nfor social and family life). \n\nThe cognitive resources we bring to bear on the problem of\nresponding to and carrying out goal-directed behavior is complicated;\nthese studies provide evidence that some of these resources are in\nplace very early in life. They do not show that the\ninfant’s goal-directedness abilities are innate; they might\nsomehow be learned on the basis of early experience. But again,\nsuch findings shift the burden. The earlier that resources\ninvolving notions like intention, goal,\npreference, and so on appear, the greater the challenge to\nEmpiricist claims that the categories are learned solely on the basis\nof prior experience. \n\nAnother set of studies (Kuhlmeier et al. 2003; Hamlin et al. 2007)\nprovide evidence that infants are not only sensitive to displays of\nagency, but also have a sense of (something like)\ncooperative behavior: they readily distinguish between\nhelpers and hinderers. In the 2007 study,\nbabies were shown animated displays that adults interpret as a red\ncircle trying to climb a hill but having trouble making it all the way\nup \n(Hamlin et al. 2007 video display on line).\nIn half the trials, the babies see a yellow triangle gently\n‘helping’ the circle up the hill; in the other half, they\nsee a blue square gently pushing the triangle down to the bottom.\nAdults plainly see the yellow triangle as a helper, an agent\nwhose goal is to assist the circle in getting up the hill; they see the\nblue square as a hinderer, an agent whose goal is to stop the\ntriangle from getting up the hill. Babies make such a distinction\nas well. Six-months-olds showed surprise in test trials that came\nafter the hindering and helping scenarios, in which the red circle is\nseen approaching its hinderer rather than its helper.\nFurthermore, in a live action version of the task, the 3-month-old babies\nthemselves chose to touch the helper more than the hinderer when they\nwere given both to\n choose.[25] \n\nIt would seem, then, that sometime between 3 and 9 months, babies are\narguably already on their way to a concept of desert.  Much\nremains to be discovered about the contours of their concept and its\nsubsequent development.  As Hamlin points out, apart from the\nhelper-hinderer contrast, we don’t know how they determine who\ndeserves what.  Relevant here is the finding that babies prefer not\nonly helpers, but also those who are relevantly similar, who like the\nsame toy or candy, for example (Mahajan and Wynn 2012).  How much of\ntheir apportionment of desert is dependent on such factors as opposed\nto factors that adults might consider morally relevant, like fairness,\nresponding to need, and so on. How, if at all, does their early\nconcept connect to egalitarian notion of fairness?   \n\nIf we consider morality as a system that evolved to enhance cooperation within large groups of unrelated individuals (Bloom 2013, Joyce 2006), we see that infants have some of the key prerequisites in place for such a system:  (1) they have a positive attitude towards cooperation, (2) they have some grasp of other actors’ preferences and their informational point of view, (3) they are sensitive to actors’ intentions as embodied in their actions, and (4) they are ready to enforce rules by punishing violators and rewarding adherers, and they approve others who do likewise.   \n\nWe are moving towards a better understanding of the early cognitive and motivational underpinnings of moral norms, understood as social rules or expectations that all are expected to obey and enforce.  As we noted, there is still much to learn here about both the early state and what is likely to be a very complicated developmental story about maturation and the influence of the child’s social environment. (Bloom and Wynn 2016 provides a useful and philosophically informed summary of the sate of research on which features of our moral cognition are, or are not, part of an early core.)  But there is mounting evidence that from early in their first year infants are social cognizers with (at least) a hold on the moral realm.  It is hard to see any way that all of this can be learned from experience (Hamlin 2015). \n\nOur understanding of goal-directed behavior is characterized by a\nprinciple of rationality; that is, that all things being equal, agents\ntake the easiest, most direct, and most efficient means available to\nachieve their goal. In a series of studies, Csibra, Gergely and\ntheir colleagues provide evidence that infants use this principle\n(Csibra et al. 1999 and 2003). In Csibra et al. 2003,\n12-month-old babies were habituated to a ball rolling along a path,\napparently jumping while its path is hidden by a screen, and then\ncontinuing rolling along its path once it has emerged from behind the\nscreen. In the test trials, the screen was removed and babies\nwere shown one of two displays: one with an obstacle on the path, one\nwith no obstacle. Longer looking times at the display with no\nobstacle indicate that jumping for no apparent reason is unexpected for\nthe infant. In contrast, when there is an obstacle on the path,\njumping over it is a direct and efficient means to achieving\none’s goal and is therefore not a violation of expectation. \n\nAnother study by Gergely and his colleagues (2002) followed up on a\nfinding of Meltzoff (1988) showing that 14-month-olds imitate the means\nan agent employs to attain a goal, even if those means are not the most\ndirect or efficient. Meltzoff showed infants that tapping a panel\nlight with his head made it light up. When babies returned to the\nlab the following week, they too used their heads to turn on the light,\nrather than simply pressing it with their hands. Gergely\nsuggested that this seeming violation of rationality was not in fact\nirrational. He suggested that the baby might reason that\nif the light could be turned on with one’s hand, the\nadult they were imitating would have used his hand. The fact that\nthe adult used his head to turn on the light suggests to the child that\nthis must be a necessary means to achieve the goal. To test this\nhypothesis, the researchers added a condition in which the adult actor\ncould not use his hands because they were otherwise engaged: the actor\npretended to be very cold and used his hands to hold a blanket wrapped\naround him. With hands thus busy, the adult actor used his head\nto tap the panel light. They then compared the babies’\nresponses to the panel light in this hands-busy condition with the\nresponses in the original Meltzoff condition where the actor’s\nhands were simply resting on the table. In the original Meltzoff\ncondition, babies used their heads to turn on the light, but in the\nactor’s-hands-busy condition, the babies did not imitate the\nactor but instead used their hands. This supports the view that\nthese babies already are acting on the basis of some principle\nconnecting efficiency and goal-directedness, and that this principle is\nstronger than their tendency to imitate. \n\nLet us return to the False Belief Task. It was noted earlier\nthat children younger than 3-1/2 do not succeed in the classic\nparadigm. But in a recent study, Onishi and Baillargeon (2005)\nshowed that infants as young as 13- to 15-months could succeed on a\nfalse belief task. In this study, babies were familiarized to a\ndisplay of an adult placing a toy (a plastic watermelon slice) into one\nof two boxes and then reaching into the box as if to grasp it.\nThe point of these familiarization trials was to indicate to the baby\nthat reaching the toy was the adult’s goal. The toy was\nthen moved from the box in which the adult had placed it to the other\nbox. Although the baby always saw the toy move, and thus\nunderstood its new location, the adult did not always see the toy move;\nhalf the time, the adult’s view was blocked. The question is this: on the\ntrials where the adult did not see the toy move to the new\nbox—that is, when the adult had a false belief about the\ntoy’s location—where do babies expect the adult to look for\nthe toy? Looking time measures indicated that babies were\nsurprised when the adult looked in the new box, even though babies knew\nit was the correct location. In contrast, on the trials in which\nadults saw the toy move to the new box, babies were surprised if adults\ndid not look in the new location. At present there is no\nsatisfactory account of why 3-year-olds fail the standard false belief\ntask, given that 15-month-old babies seem to be able to attribute false beliefs to\nothers. What else does the 3-year-old need, beyond what the\n15-month-old already has, to succeed on the classic task? There\nare many candidate answers, but the Onishi and Baillargeon results have\nconsiderably changed the debate. \n\nAs noted above, questions about the development of a theory of mind\nwere first posed with respect to chimpanzees, and it is to chimpanzees\n(and other nonhuman primates) that we now return. Until recently,\nmost researchers agreed that there was little evidence to support the\nclaim that nonhuman primates represented agency, goals, attention or\nthe like (Povinelli 2000; Tomasello & Call 1997).\nHowever, chimpanzees, macaques, and other primates do follow eye\ngaze. Researchers have probed whether they appreciate the\nrelationship between the direction of gaze and attention, or\nbetween seeing something and acquiring\ninformation. A number of recent studies have shown that\nchimps prefer to steal food from a person (or, in some conditions, a\nmore dominant chimp) who cannot see them as opposed to a person (or\nmore dominant chimp) who can (see Flombaum & Santos 2005; Hare\net al. 2000; and Carey 2009 for review). If dedicated\nmechanisms to identify agents and to support our reasoning about them\nis part of our evolutionary heritage, as seems increasingly plausible,\nit should not surprise us to find them in some of our distant\nrelatives—and in the very young. \n\nOnce again, the studies of newborn chicks are particularly\nilluminating. Regolin and colleagues (2000) habituated newborn\nchicks to a video display involving 2 balls, one red and one\nblue. At first the balls are presented as static. The red\nball then moves, bumps into the blue ball, and then the blue ball\nmoves. After habituation the chicks were presented with a fuzzy\noval-shaped red ball and a fuzzy oval-shaped blue ball. The\nchicks imprinted to the red ball, not the blue one. It seems that\nthey are sensitive to agency—that they see the red ball\nas an agent, while the blue ball may be a passive object. To make\nsure it was the red ball’s autonomous movement that was critical,\nexperimenters partly occluded the red ball as it began its movement so\nthat it wasn’t clear whether the movement was autonomous or set\nin motion by someone or something else. In this condition, the\nimprinting preference for the red ball disappeared. These chicks\nwere newly hatched, so an explanation for these data that appeals to\nlearning from sensory experience is unavailable. Once again, the\nchick studies provide an existence proof of an innately specified\ndetection mechanism closely related to agency. Note that the\nquestion of what precisely the chick is detecting or representing is\nstill open—is it autonomous motion or agency or some other\nproperty. \n\nThe studies summarized in section 2 are representative of the\nNativist resurgence. Not surprisingly, cognitive scientists with\nEmpiricist sympathies continue to push back: to search for\ncountervailing evidence, to question the methodologies involved in\nthese studies, to develop alternative interpretations of the data, and\nso on. Moreover, as we mentioned at the outset, it is not only\nNativism that has experienced a resurgence; there are important\nresearch directions in the cognitive sciences that seem inherently more\nfriendly to the Empiricist position. In this section we briefly\ndescribe and contextualize some of these developments. \n\nOne important trend has been the development of Connectionism as an\nalternative to the ‘Classical’ conception of the mind\n(Newell & Simon 1976; see Garson 2010 for an overview).\nOn the Classical view, the cognitive mind is best understood on\nthe model of a digital computer that (i) uses symbolic representations\nthat have a combinatorial syntax and semantics, and (ii) manipulates\nthese representations following structure-sensitive processing rules.\nConnectionists replace the Classical view with a model of\npsychological processes as involving networks of simple units with\nweighted connections among the units that control the spread of\nactivation through the network, and ‘learning’ algorithms\nfor resetting the weights of the connections on the basis of earlier\nbehavior of the network in response to some task. There is\ncontinuing debate about whether the Classical and Connectionist models\nare really incompatible, and some have argued that Connectionist\nsystems are best viewed as implementations of classical symbol-based\nsystems (see Pinker & Prince 1988 for discussion). But\nthe research on psychological processing within the Connectionist\nframework is very different from what one finds in the Classical\ntradition. \n\nConnectionism is relevant to the Nativism-Empiricism in two related\nways. In the first place, Connectionism provides a natural format\nfor the Empiricist idea that perception provides the basic elements of\nthe mental system (ideas/network-nodes) and experienced regularities\namong ideas strengthens their connection (associations/weightings) and\nin this way accounts for learning. But a more important idea is\nthat if Connectionism could be established as a real\nalternative to the Classical symbol manipulation approach (and\nnot simply as providing implementations of Classical systems), it could\nhelp undercut a key argument of Chomsky-style Nativism. Here is a\nsimplified version of the target\n argument.[26]\nChomskyans, as we noted (section 1.1.2),\nargued that grammars—and by extension, the rules governing other\ndomains of knowledge—are ‘psychologically\nreal’. If they are, and the Classical view is correct, then\nit would seem that such rules are present in the mind as symbolic\nconstructions. But these rules, as linguistic grammars make\nplain, involve abstract concepts that are not perceptually available in\nthe data. So if the rules are symbolically represented, then\nthese abstract concepts, which are the constituent elements of the\nrules, are also internally represented. But if the relevant\nconcepts are not perceptually available, how could they be learned by\nEmpiricist-style mechanisms that only track regularities in the stream\nof experience? This sort of Nativist argument was developed in\nFodor 1981. Connectionism rejects the view of mental\nrepresentation on which this argument depends. For the\nConnectionist, information is not in the mind as the semantics of\nmental symbols; as the meanings of terms in the language of\nthought. For the Connectionist, information is distributed as a\npattern of weightings in a network in which none of the nodes\nrepresents anything. So: if this sort of anti-Classical\nConnectionist approach is successful, this particular version of the\nPoverty of the Stimulus argument for Nativism is blocked.  \n\nThere is continuing controversy about whether Connectionism has\nin-principle limitations that disqualify it as a general model of\ncognitive processing (see Fodor & Pylyshyn 1988 and the\nliterature this critique spawned, which is reviewed in Garson\n2010). But there is a practical problem that is less\ncontroversial, and to understand it, we need to consider more closely\nhow Connectionist nets learn. Imagine that one wants the net to\nlearn the difference between (photos of) male and female faces. A\nset of input nodes will code the photo, activation will pass through a\nset of intermediate nodes, and an answer will appear on the output\nnodes. If the output on a particular input is incorrect (a male\nis misidentified as a female for example), the algorithm that governs\nthe dynamics of the network automatically adjusts the weights of the\nconnections between the various intermediate-layer nodes ‘in the right\ndirection’ and more inputs are cycled through the system.\nWhen the output is correct over some range of inputs, the net has been\n‘trained up’; it has successfully learned to tell male from\nfemale faces in photos. The art in Connectionist modeling is to\ndiscover the best network structure and the right algorithm for\nadjusting the weightings. The problem is that such networks learn\nvery slowly; they often need hundreds of thousands of cycles of inputs,\noutputs, and weight adjustments. But humans and animals learn\nmany things very quickly, sometimes even from one instance and often\nfrom a small set of instances (Garcia et al. 1955; Markman 1989). \n\nOne way to approach this discrepancy is to see it as due to the fact\nthat in the typical Connectionist set up, the weights between nodes are\ninitially set to random values, and are (very) slowly reset on the\nbasis of small adjustments. But the fact that the initial\nweightings provide no prior information is arguably an artifact of the\nmodeler’s Empiricist commitment to have all the learning\n‘come from experience’. There is nothing in the\ngeneral structure of Connectionist models that would prevent the\nmodeler from starting with a highly constrained set of\nweightings—in this case one that already holistically contains\ninformation of the general features of human faces, and perhaps\ninformation about differences between male and female faces. The\nupshot, then, is that although most actual Connectionist models are\nEmpiricist-friendly in their format and in their representational\ncommitments, they can also be implemented in a way that is congenial to\nNativist ideas. The prior information that the Nativist claims is\npart of the initial state of the organism can be realized by setting\nthe initial patterns of weightings between the nodes in the network in\nsuch a way that learning will happen much more quickly. So while\nConnectionism may avoid the very general commitment to Nativism that\nsome have argued is built into the Classical conception, it is neutral\non the question of whether learning in a particular domain is wholly\nbased on experience or uses innate information (suitably distributed\nacross networks). \n\nThis last point applies to Dynamic Systems Theory approaches to\ncognition as well (Thelen & Smith 1994; Port & van\nGelder 1995). Dynamicists hold that human behavior should be\nexplained in terms of sets of differential equations that represent a\nsubject’s trajectory in real time through a space of possible\ntotal cognitive-behavioral states. Because they, like\nanti-Classical Connectionists, reject the Classical paradigm’s\ncommitment to symbol manipulation and computation, they also avoid the\nNativist consequences of that view. But neither Connectionists\nnor Dynamicists are in principle anti-Nativist. However\nwe model an organisms cognitive processes—as executing a\nClassical Von Neumann style program, as reassigning weights to nodes in\nline with a Connectionist back-propagation algorithm, or as moving\nthrough a Dynamicist state space as described by a set of differential\nequations—the question remains: what are the built in initial\nbiases of the system and what role do they play in determining the\nsteady state. One can construct a Connectionist system that is\nantecedently tuned to converge on a specific steady-state, and as such\nwill have a significant Nativist element (Hummel & Biederman\n1992 presents such a system for shape recognition). The same\nseems true of Dynamic Systems models. The oft-used Dynamicist\nexample of a pendulum is ‘innately specified’ to reach a\nspecific steady state (its point attractor) despite wide\nvariability in its inputs. If very young children do indeed\ndistinguish helpers from hinderers, for example, then this capacity\nwill need to figure in the Dynamicist model. It will be\nappropriate to then ask about the role that the child’s initial\nstructure or configuration played in its coming to have this\ncapacity. \n\nEven at the height of Chomsky’s influence, it was clear that\nthe strength of the Nativist position rested, to a great extent, on the\nweakness of the Empiricist alternative. The central argument from\nthe Poverty of the Stimulus was that Empiricism had failed to make\nits case, and that the Nativist hypothesis was therefore more\nplausible. But it was implicit in this dialectic that if\na more powerful Empiricist learning theory were developed, it could\nchange the terms of the debate. Furthermore, Empiricists argued\nthat there had to be a stronger general learning theory\nbecause learning theory as developed up until that time did not have\nthe resources to account for much learning that was plainly\nbased on experience (Harman 1967; Putnam 1967). Some would argue that these Empiricist\nhopes for a more powerful learning theory have been realized. Learning theory has advanced\nsignificantly, especially in the last decade, and Empiricism can now\ndraw upon new resources; specifically, learning algorithms based on\nBayes’ Theorem. The power of Bayesianism raises the\npossibility that the earlier Poverty of the Stimulus arguments\nunderestimated what could be learned from experience by general\nlearning mechanisms. \n\n‘Bayesianism’ is a general term for a range of\nsophisticated statistical methods, algorithms, and tools that draw upon Bayes’\nTheorem/Rule, which tells us how to revise our beliefs given new\ninformation; that is, how to choose the best of a set of alternative\nhypotheses given new data. The calculation requires (i) the prior\nprobability of the data, (ii) the probability of the data given the\nhypothesis, and (iii) the prior probability of the\n hypothesis.[27] \n\nThe relevance of Bayes’ Theorem to Cognitive\nScience. Bayesianism is in its origins a normative theory of\nwhat one ought to believe under specific epistemic\ncircumstances, and as such it has been applied extensively in\nunderstanding theory confirmation in the sciences. It first came\nto the fore in the cognitive sciences as an ideal against which one\ncould measure human irrationality. Kahneman and Tversky\n(1972) famously showed that ordinary reasoners typically fall short of\nBayesian standards when they are asked to decide the bearing of\nevidence on hypotheses, in part because they misjudge the relevance of\nthe prior probability of the hypotheses. But in recent years, Bayesian methodologies have become a unifying framework for analyzing all aspects of cognition that can be represented as inference under uncertainty.  For example, \nBayesian ideas have been successfully applied to the processing\nunderlying perception—especially the visual system (Knill\n& Richards 1996; Rao et al. 2002). In visual perception,\na pattern of light hits the eye (the proximal stimulus), and the visual\nsystem needs to determine the nature of the visual scene in the\nenvironment (the distal stimulus) that caused that pattern. The\nproximal stimulus is compatible with a number of different distal\nstimuli. So the system faces something like the\nunder-determination problem that a scientist faces. Both must\nselect one view about what the world is like on the basis of\ninformation that still leaves other possibilities open. It turns\nout that Bayesian methods have been very successful at modeling how the\nvisual system resolves these uncertainties. \n\nThe visual system gets an image on the retina (D), and must\ndetermine what the real-world scene is like (H). The\nimage is compatible with many different possible scenes, but the visual\nsystem is very good at overcoming this uncertainty and reliably settles\non the most likely scene. In Bayesian terms, the visual system\nmust do this calculation: \n\nConsider this (again simplified) example, drawn from Scholl\n2005. In Figure 1, the circles are ambiguous; they can be either\nconvex bumps or concave depressions. Viewers normally see (a) as\nconvex and (b) as concave, (but if the display is turned upside down, the\nproperties are reversed). Figure 1 \n\nThe fact that we see these as we do can be explained in Bayesian\nterms. To figure out the most likely scene/source of (a), the visual\nsystem must assign a probability to the hypotheses \\(H_2\\) (that the circle\nin a is convex) and to \\(H_2\\) (that it is concave). One key assumption\nthe visual system makes is that the scene in both (a) and (b) is\nilluminated by a single light source coming from overhead. So if\nthe bottom of the circle is in shadow, we tend to see it as convex; if\nthe top, we tend to see it as concave. When we look at\n(a), this assumption about the light source translates into the\nprior probability of \\(H_1\\) being higher than the prior probability of\n\\(H_2\\). So the priors in this case give us an antecedent ordering of\nthe hypothesis space (here we ignore other hypotheses that could\naccount for the image), and the visual system settles on (a) as\nconvex. \n\nBayesian approaches are appealing because they provide a natural way\nto solve the problem that troubles theories, like Connectionism, that\nare built on associationist lines. Associationist learning is\nbottom-up. It depends on keeping track of correlations in the\nstream of experience and slowly modulating expectations on the basis of\nthese correlations. But as we noted earlier, humans and animals\nlearn about the world very quickly, and on the basis of a very small\nnumber of exposures and interventions. A child hears the word\n‘horse’ applied to a few instances (and probably\nhears stray utterances of the word too) and reliably learns the\nextension of the term (Markman 1989). A rat made sick by a food\none time, will not eat food with that smell again (Garcia et\nal 1955). These ‘fast-mappings’ are a problem\nfor Associationist models. But they are more easily accommodated\nin Bayesian models, which essentially quantify the role of background\nknowledge—the top-down contribution—in the fixation of\nbelief. If the rat already knows, as part of its background\nknowledge—its ‘factory settings’, so to\nspeak—that when it comes to foods, smell is an indicator of\nedibility, then single-case learning is less mysterious. The\nprior probability of hypotheses linking edibility to smell may be\nantecedently set as very high, and hypotheses linking edibility to\norientation may be set as very low. So one association between\nsick-making food \\(f\\) and smell \\(s\\) will be enough for the rat to\n‘adopt the hypothesis’ that \\(f\\) and \\(s\\) are regularly\nlinked. In contrast, if sick-making food \\(f\\) is always in a\nparticular orientation \\(o\\), the rat may have a hard time making the\nconnection even if it may be sensitive to orientations in other\ncontexts. Similarly, if the child comes to the word-learning task\nwith the assumption that new words most likely pick out unfamiliar\nextensions—again, with this assumption implemented in the\npriors—then her job is made easier. Bayes’ Theorem\ngives us a way to factor in this top-down background\n knowledge.[28] \n\nThe key issue in considering the bearing of Bayesianism on the\nNativist-Empiricist controversy is the\n priors.[29]\nWhere do they come from? If we are talking about simple, repeatable events like coin flips, the priors are a\nmatter of well-defined relative frequencies given by probability\ntheory. But the prior in the concave-convex case (which was\nchosen to highlight this point) seems to involve domain-specific facts\nabout light and shadow, and their relation to the shape of objects.\nScholl 2005 argues that the priors here are innate, and many\nscientists studying visual perception would agree. We don’t\nlearn from experience that the objects in our perceptual world\nwill typically have overhead illumination. Rather, this is one of\nthe ‘factory settings’ of the visual system. As\nKersten (2004) puts it (speaking more generally): ‘the priors are\nin the genes’. Ullman (1979) argues that the same may well\nhold for the general constraints relating the rigidity of objects to\nfacts about motion. The view that the illumination constraint is\ninnate is also supported by the fact that chickens reared in an\nabnormal illuminated-from-below environment still react as we do to\nstimuli (a) and (b) (Hershberger 1970). So we have evidence that this\nprior can be innate. \n\nLet us assume that there are significant innate priors that operate\nin perceptual processing. Does this score points for the Nativist\nposition in general? In one way it does, because it is in line\nwith the basic Nativist theme that humans are tailored for their\nnatural environment. But in another sense, the Empiricist might\ndownplay the importance of this kind of Perceptual Nativism for the\nlarger debate. Empiricists have always taken it for granted that\nwe perceive as we do, in large part, because of our\nbiological-psychological nature. The traditional Empiricist focus\nhas usually been on that part of our understanding that goes beyond\nwhat we actually perceive. Its main claim is that anything that\ngoes beyond what we perceive is constructed out of what\nwe’ve perceived by domain-general\nprinciples. So even if (some of) the priors involved in Bayesian\nmodels of perceptual processing are innate, the more critical arena for\nthe Nativist is domain-specific cognitive processing,\nto which we now turn. Nativists would expect that the best\nBayesian models of cognitive processing would have to incorporate\ninnate priors that reflect domain-specific knowledge.\nEmpiricists would expect that domain-specific priors are themselves\nlearnable by Bayesian methods from experience plus domain-general\nconstraints on learning. \n\nWe do not yet know enough to settle these questions, but they are\nnow beginning to be addressed. Most recently, a number of\ntheorists have used Bayesian techniques to model not just low-level\nperceptual processing but also aspects of higher-order cognitive\nprocesses. Areas of current research include concept learning\n(Tenenbaum 1999), word learning (Xu 2007), and causal reasoning\n(Griffiths & Tenenbaum 2005; Griffiths et al. 2011), and the\nlist is\n growing.[30]\nContemporary research on the application of Bayesian techniques\nto higher-level cognition has generally ignored the battle lines of the\nNativist-Empiricist debate. The real interest is in the\npossibility of developing statistical techniques that, as Tenenbaum et al 2006 puts it, “integrate bottom-up and top-down\ninfluences.” (For a very useful state of the art in Statistical learning along with concrete suggestions about deploying top-down information in such models, see Lake et al, forthcoming.)  We already have sophisticated statistical\nanalyses of the bottom-up part; the perceptual phenomena. The\nchallenge is to develop quantitative representations and analyses of\nthe levels of top-down background knowledge that operate in particular\ndomains. In section 2, for instance, we considered as part of the\nchild’s background information his theory of mind.\nIt was on the basis of this theory that the child could develop a\nstructural analysis of a situation in terms of agents, beliefs, goals,\nhelp/hindrance, and so on. But the information contained in such\na theory and the structural analyses of particular situations that this\ntheory makes available, cannot yet be integrated into Bayesian\nstatistical analyses. The challenge for Bayesians is to develop\nways to recast the top-down elements and the analyses they make\navailable in quantitative terms. Only then will we be in a position to address\nwhether and to what extent top-down information is learned or\ninnate. \n\nWe can use the case of language understanding, a well-studied area\nand arguably a Nativist stronghold, to illustrate how these Bayesian\ngoals might be achieved. The phenomenon is familiar: you hear a\nsentence \\(S_1\\) as having a specific meaning. The theoretical\napproach mirrors the vision case: \\(S_1\\) (as auditorily processed) is\ncompatible with a number of competing structural representations, but your parser\nsomehow chooses the best one: \\(\\mathrm{sr}(S_1)'\\). The Bayesian says\nthat the parser is able to do this because it can do a statistical analysis\nthat integrates bottom-up and top-down information. In this case,\nthe bottom-up element is \\(S_1\\). But the range of possible\nstructured representations the parser can select from is top-down\ninformation, as is the algorithm that chooses \\(\\mathrm{sr}(S_1)'\\)\nover other candidates. The problem: how to assign a prior\nprobability to a complex structured representation like \\(\\mathrm{sr}(S_1)'\\)\n(for instance, a syntactic tree)—a probability that depends on the probability\nassigned to the sub-elements. We know how to assign the prior\nprobability of a series of heads for a fair coin. But the question comes up again: how do we\nassign a prior probability to a linguistic representation, or to a\ncomplex visual scene, or to a complicated representation of the goals,\nroles, and perceptual beliefs of a player in one of the Theory of Mind\nscenarios? The events are more complex, the\nrepresentations of the events are therefore more complex, and the\nhypothesis space is more complex (Chater et al. 2006). \n\nIn the language case, the Bayesian can hope to draw on a good deal\nof what contemporary linguists have already achieved in understanding\nthe structures underlying sentence comprehension, and some\ncomputational linguists are beginning to merge such analyses with\nprobability theory (for instance, Chater & Manning 2006).\nBut even here, the problem of finding the best structure to assign to\nan input is daunting. As Chater et al. 2006 puts it: \n“More challenging is inferring representational structures over\nwhich parameters are optimized. One problem is that the space of\npossible structures is often large and discontinuous; a second is that\na direct application of probabilistic methods would involve assessing\neach structure by integrating a prior over its parameters, which seems\ncomputationally prohibitive; a third is that structures appear to be\nconstrained in potentially highly abstract ways.” \n \nIn the case of theory of mind, on the other hand, we don’t yet have\ndeveloped theories about the relevant structures (but see the related\nwork on causality collected in Gopnik & Schulz 2007). So it is\nonly if Bayesians can get a handle on these representational and\nstatistical problems, that they will be able to attack our\nquestion: how is the space of such structures generated in the first\nplace? Is there innate domain-specific information at work or is there\na Bayesian hierarchy, a two-level-up Bayesian account that explains\nhow this one-level-up information is acquired (that is, a Bayesian\nlearning-theoretic account that explains why the child represents\nlinguistic input, for example, using tree structures, but integers in\nterms of a very different linear structure; for further discussion see\nTenenbaum et al. 2011). \n\nSo, for example, children might know that animals are arranged in a\ntaxonomy of a specific sort, and this prior background knowledge helps\nthem learn about animals. But how do they get this prior? It might be\nthat they have a prior higher-order principle \\(P\\) that provides a\nprobabilistic ordering on different graph structures, and that the\ntaxonomy they use has a higher prior probability than other ways to\nstructure the animal world (say, a ring structure). But how do they\nget \\(P\\)? Do they learn it or is it simply there innately? To tackle\nthese questions, all sorts of objects—structured representations\none finds in a grammar, graph-structures one might find in a taxonomic\nrepresentation of causal or kin relations, schemas applied to scene or\nevent analysis, etc.—will need to be formalized and assigned\nprobabilities. So there is much to be done. There is no a priori\nanswer about how far up the Bayesian can go, and we do well to keep an\nopen mind about the nature of the unlearned priors. But we should also\nnot overlook findings like the chick’s stubborn presumption of\nillumination from above, which suggest that nature can build\nin unlearned priors, and that they can be domain specific. It would\nbe, at the very least, extremely surprising if nothing like this\noperates in human psychology. \n\nBayesianism, then, focuses the Nativist-Empiricist question on the\npriors. First, we need to find out where the background\nknowledge brought to bear in any particular task comes from. Is\nsome part of it innate, or can its presence be accounted for in terms\nof higher-order Bayesian learning? At some point, the Bayesian\nwill come up against what is not learned by Bayesian methods (at the\nvery least, the Bayesian machinery\n itself[31]),\nand we will want to understand its specific\ncharacter. Will it be information implemented in our perceptual\nsystems or domain-general information that applies no matter what is\nbeing learned, supporting the Empiricist view, or will some of it be\ntailored to specific ranges and domains of knowledge, vindicating the\nNativist? We are still at the beginning of the road to the\nanswers to these questions. \n\nIt is important not to underestimate the challenge that Empiricists face.  The Bayesian formalism might make it seem that all that needs to be explained is why the hypotheses compatible with the data are ordered in the way they are.  So, for example, if it could be shown that the bias for a light from above explanation of the retinal image (in section 3.2) could, in principle, have been learned from experience, then it might appear that the Empiricist wins the round.  It is plausible that some of the priors relevant to scene recognition will be learnable in this way, so this may be right as far as it goes.  But it does not get to the heart of the challenge. \n\nOnce we shift our attention away from the Bayesian formalism and focus\non the fact that we are looking for an account of the\ncognitive/computational machinery that processes inputs and generates\ncomplex structural analyses of the world—think here of the\nsubsystem that generates theory of mind representations of interacting\nagents in terms of goals, rationality, cooperation, desert, and so\non—then it becomes clearer that the burden on the Empiricist is\nmuch greater.  She must not only explain where the representation\ntypes come from, she must also account for the cognitive\nprocessing over these representation types. So even if there were a\nsatisfactory Empiricist account of how the infant sorts inputs into\nthe categories agent, hinderer, and so on, we still need a separate\naccount of where the cognitive machinery that operates over these\ntypes comes from.  Without that, the infant will have a static\ntypology with no way to anticipate the dynamics of the situation.\nHere, then, the Empiricist seems to have two choices.  She must make\nthe case that the machinery involved is either (i) generic and\ndomain-independent, or (ii) domain-specific, but itself the product of\nhigher-order learning. The point is that the Empiricist must account for the repertoire of\nrepresentation types that figure in the processing and for\nthe machinery that does the processing.  The ultimate outcome of this\ndebate will depend in part on how distinctive and complex the\ncomputational machinery turns out to be.  If the engine for theory of\nmind dynamics only needs to do tree search or production rule\napplication (for example), then the case for Empiricism is\nstrengthened, because these are very general computational capacities.\nOnly the content of the specific rules or the content at the nodes\nwill be domain-specific.  But the more idiosyncratic the computational\nmachinery in a specific subsystem—for example, a simulator that\nanticipated motions and locations in a dynamic physical\nscene—the greater the challenge for the Empiricist to explain\nhow such an internal computational device is acquired from experience\nalone.\n As we noted, although Bayesianism has had a special appeal for Empiricists, one can use Bayesian methodologies and remain open to Nativist possibilities.  There is nothing to prevent a Bayesian from starting with an innate system of representations and computational machinery and then using Bayesian algorithms to figure out how learning from experience might work for such a system.  This approach is very much in line with the Core Nativist theorizing discussed in section 2.  (For a detailed defense of this methodology, see Lake et. al. forthcoming). \n\nIn summary, then, Bayesianism appeals to Empiricists for at least two\nimportant reasons. First, because it reinstates\nlearning from experience as a central process in cognitive\ndevelopment and change. This focus on learning contrasts sharply with\nthe first wave of Nativist cognitive research, which, inspired by\nChomsky’s work in linguistics, tended to assign a diminished\nrole to learning from experience. Experience was thought to act as a\ntrigger/releaser of innate information, or, as in some linguistic\ntheorizing, as setting values to parameters that were left unspecified\nby our innate endowment. The lead role, again following Chomsky, was\nassigned to growth, understood simply as biological maturation. The\nsecond reason is that the current Bayesian mindset tends in\nsome ways towards Empiricism.  This is primarily because Bayesian\nlearning can, at least in principle, be extended hierarchically, in\nthe ways we’ve discussed. But Bayesianism also has some appeal\nto Nativists, because it focuses attention on the role of background\nknowledge in learning, and this is a theme that Nativists have pressed\nagainst bottom-up Associationist forms of Empiricism from the\noutset. Nativists can welcome a renewed focus on learning, and join in\nthe development of Bayesian theories of cognitive development. So in\nthe end, Bayesianism—as an approach to cognitive\ndevelopment—is, like Connectionism, compatible with\nNativism. (For recent discussion of this last point, see Colombo 2017;\nfor a more pessimistic assessment of the potential contribution of\nBayesian approaches to psychology see Jones and Love 2011.) \n\nNativism, as we have seen, is a vigorous program in contemporary cognitive science.  But there is very little talk of Rationalism.   The term is sometimes repurposed as another name for Nativism, and in some cases it is explicitly disowned, with Nativism taken to be the only plank in the original Rationalist platform worth saving.  But following up on our previous discussion, there is a case to be made that this common attitude misses an important and distinctly Rationalist feature of current Core Nativist research.  Here we briefly sketch the key ideas behind this claim. \n\nThe Classical Nativist-Empiricist debate is an expression of a\ndisagreement about a bigger question: what is the (cognitive)\nmind and what is it for?  For the Empiricist (Hume 1975/1738\nbeing an especially clear example), the mind is first and foremost\na pattern detector, and it is for prediction.  For\nthe Humean, all we have to work with is one experience and then\nanother.  Cognitive processing is at bottom experience mining:\ndeploying our domain general cognitive machinery like statistical\nlearning routines, memory retrieval, attentional mechanisms,\nassociative connectivity, and so on, to detect patterns in the\nsequences of traces (Hume’s ideas) that experience\nleaves behind in memory. \n\nFor the Rationalist, mind is for understanding.\nUnderstanding is of course connected to pattern detection and\nprediction, but it also involves making sense of the patterns\nat some deeper level.  The Classical Rationalist view is that Reason\n(with a capital ‘R’), in part embodied in our innate endowment,\nsomehow makes this sort of deeper understanding possible.  Descartes’\nfamous wax example (Descartes 1996/1641) is aimed at making clear the\ndifference between detecting patterns in the flow of perceptual ideas\nthat are prompted by a piece of wax and having a real understanding of\nwhat a piece of wax is.  The Humean Empiricist rejects this search for\ndepth as illusory; pattern detection is all understanding is or can\nbe. \n\nOur point is that the Core Cognition approach retains this\ndistinctively Rationalist emphasis on understanding.  Core\nsystems like our intuitive physics and theory of mind help us\nconstruct models of the world based on innate abstract\nframeworks.  By deploying these theories we can go beyond the input\npatterns and come to understand not just how things look, but\nalso what they are, why they are as they are, why\nthey change in the ways they do, how things might be\nif relevant parameters were different, and so on.  When the baby sees\ntriangles pushing a square up a hill, she constructs a rich\nconceptualization of the scene that breaks things up into different\nkinds of elements, and assigns properties to the elements; properties\ninvolving agency, physical object, goals, private intentions,\ninformation states, rationality, number, shape, etc..  She can use\nthis conceptualization—her intuitive theory—to understand\nthe dynamics of what she sees and in that way make sense of\nthe situation. \n\nDespite this commonality, Core Nativists are not one with Classical\nRationalists.  Descartes took our innate Rational notion of the\nphysical to be at the heart of the true physics.  Newton showed that\nthis was wrong, and that we needed to go beyond our intuitive physics\nif we wanted to get a deeper understanding of the world.  Core\nKnowledge theorists reject the Classical assumption that our innate\nsense-making frameworks are necessarily true.  But true or\nnot, what is innate provides a framework that we use to make\nsense of the world.  To this extent, the Core Knowledge program\nrevitalizes this key Rationalist idea.  It remains an open question\nhow we are to understand this notion of (deep) understanding.  This\nsearch goes back at least as far as Plato.  But our point here has not\nbeen to defend the revival of this Rationalist theme; only to note the\ncommonality. \n\nIn conclusion, the studies that we surveyed\nin section 2 provide compelling evidence that\nwe have been underestimating how much infants and young children\nunderstand about the world. At the same time, it is clear that adult\ncompetence goes far beyond the child’s in virtually every\ndomain. The Bayesian framework we discussed\nin section 3 has the potential to address both\nissues at once. It provides a systematic and quantifiable approach to\ndevelopment, and is at the same time open to incorporating innate\nelements. Whether it will succeed in unifying a learning-theoretic\napproach to cognitive development with the built-in representations\nfavored by Nativists remains to be seen.","contact.mail":"samet@brandeis.edu","contact.domain":"brandeis.edu"},{"date.published":"2012-10-01","date.changed":"2017-09-13","url":"https://plato.stanford.edu/entries/innateness-cognition/","author1":"Jerry Samet","author2":"Deborah Zaitchik","entry":"innateness-cognition","body.text":"\n\n\nNativism and Empiricism are rival approaches to questions about the\norigins of knowledge.  Roughly speaking, Nativists hold that important\nelements of our understanding of the world are innate, that they are\npart of our initial condition, and thus do not have to be learned from\nexperience.  Empiricists deny this, claiming that all knowledge is\nbased in experience.  Different Nativist and Empiricist views spell\nout the details in different ways, depending on which elements of our\nknowledge are at issue, what counts as understanding, what is meant by\nthe initial condition, how learning is to be understood, what it is\nfor knowledge to be based in experience, and so on.  There continues\nto be lively philosophical debate about whether there is any\nsatisfactory general account of what it is for something to be innate\n(for a review of some recent work see Gross & Rey 2012).  The\nNativist views discussed here differ in many respects, but all share\nthe broad commitments of the approach.  It should be noted that the\ncommonplace opposition of Empiricism to Rationalism reflects back on\n17th and 18th century philosophical debates in which Nativism was a\ncentral plank in the Rationalist position.  The contemporary Nativist\nviews we consider here are independent of most of the broader Rationalist\ncommitments (see the entry on \n rationalism vs. empiricism), but we note some important and often-ignored connections in section 3.3 of this entry. \n Although it is misleading, it is not uncommon for the\nterms ‘Nativism’ and ‘Rationalism’ to be used\ninterchangeably (see the entry on the\n  historical controversies surrounding innateness).\n \n\nUp until the 1950s, there were no active research programs that were\nlooking for the innate factors in knowledge and cognition that had\nbeen hypothesized and argued for by Nativist thinkers since Plato. It\nwas widely agreed that the centuries-old battles between Empiricists\nand Nativists were over, and that the Empiricists had decisively won.\nThe Nativist situation was actually worse than that: innateness claims\nwere seen as not only wrong, but as ultimately unscientific approaches\nto mind and perhaps incoherent as well.  The prevailing research\nagenda for scientists and philosophers interested in how the mind\nworks was to show how our knowledge and abilities could be fully\naccounted for on the basis of our sensory experiences and the general\nlearning mechanisms that operate on them. \n\n\nBut a number of developments have led to a resurgence of Nativism,\nbeginning with Chomsky’s revolutionary work in linguistics in the\n1950s and 1960s.  This entry places this resurgence in its scientific\nand philosophical context, and will discuss a few important areas of\nresearch to give a taste of the kinds of experimental approaches,\nhypotheses, and theories that have been advanced. A word about the\nfocus of this entry. Most philosophical discussions about innateness\nbegin with careful analyses of the variety of meanings innateness\nclaims can have, consider the sorts of entities that might be at issue\nin such claims (beliefs, ideas, concepts, knowledge, etc.), discuss\nthe epistemological standing of these innate elements, and so\non. These questions are no doubt interesting—and sometimes the\nanswers are interesting too—and such work has its place. But the\nreal action for philosophers is more in the details of the current\nempirical research, and less in the philosophical bookkeeping.\nCognitive scientists are beginning to reveal some of the basic, or one\nmight say ‘primal’, patterns of human cognition. They are\nusing experimental evidence to paint a detailed picture of how we\nhuman beings understand the world—both the physical world around\nus, and ourselves and other selves that are parts of that\nworld. Developmental scientists are trying to figure out to what\nextent and in what ways we are built by nature to arrive at these\nunderstandings. Those we identify as Nativists accord a significant\nrole to our natures, and lean towards the view that we are not built\nto be initially neutral about the world we encounter, in the way that\nclassical Empiricism would lead us to expect. This growing body of\nscientific thinking is of general interest, as evidenced by the\nattention of science magazines and newspapers like the NY Times. But\nthe character of our primal understandings and their innate bases are\nintimately connected to the central concepts and questions that\nphilosophers have always been most interested in. Getting clear on how\nwe naturally think and how we come to think that way is, arguably, a\ncritical element in our understanding of human beings.\n\n\n\nThe entry has three main sections. In the first section,\ncurrent Nativist developments are put in recent historical context,\nespecially the connections between Chomsky’s linguistic\ninnovations and current cognitive science research. The second,\nand longest section, takes up three areas of current research on\nchildren’s early concepts and understanding—of physical\nobjects, number, and mind/agency—to give a sense of the type of\nempirical work being conducted and to highlight some of the promising\nresults that are\n emerging.[1]\nA third section reviews some recent work in\nthe study of development that is close to the Empiricist side of the\ntraditional divide.\n\n\n\nThe reigning experimental paradigms in mid-20th century\nAmerican psychology were for the most part variants of\nBehaviorism. B.F. Skinner’s behaviorist account of language\nacquisition and use (Skinner 1957) in many ways marks the end of this\ndominance—or at least the beginning of the end—because it\nwas the target of a very influential attack by Chomsky (1959). This\nattack convinced many of the inherent limits of behaviorist theorizing\n(see Cowie 2010 for details). \n\nThe defining feature of Behaviorism is its\nanti-mentalism—the methodological claim that one can\n(must) provide a psychological account of human beings without\nreferencing internal mental states. Chomsky’s attack on\nSkinner zeroes in on this\n anti-mentalism.[2]\nThe connection between Behaviorism and\nNativism, on the other hand, is typically given less\nprominence. Although Behaviorism is closely tied to Empiricist\nassociationism and is therefore ‘officially’ anti-Nativist,\ntheories like Skinner’s do incorporate significant Nativist\nelements. Specifically, Skinner took it for granted that every\nanimal has a range of naturally emitted behaviors. Some of these\nbehaviors are responses to stimuli (Skinner’s\nrespondents—e.g., the baby’s suckling response),\nwhile others are just emitted (Skinner’s\noperants—e.g., the baby’s babbling). These\nbehaviors are the raw materials that can be shaped by\nexperience—Skinner’s conditioning and the law\nof effect. So the notion of an innate behavioral repertoire,\nand of innately specified links between environmental stimuli and\nelements of that repertoire, are very much part of the Behaviorist\npicture. This innate repertoire was, as any good Darwinian would\nexpect, highly information rich, because it was shaped by the history\nof problem solving by the animal’s forebears. All parties\ntake it for granted that babies babble, and suckle in the presence of\nthe right stimuli, because such behaviors are part of their biological\nheritage. There might be disagreements about the underlying mechanisms\nand epistemological standing of that heritage, but it is hard to deny\nthat humans are in some sense pre-informed that they need to\nsuck to get milk from the breast. This is a ‘factory\nsettings’ for babies. So if we set aside the controversy\nover the subject matter of psychology (behavior or the\ninternal mind?), and the controversy over the right explanatory\nconstructs (schedules of reinforcement or cognitive\nprocesses?), we find that Behaviorism is actually\ncommitted to innateness claims, and doctrinally\nopposed to any kind of ‘blank-slate-ism’.\nBut this isn’t how things actually played out. Behaviorism\nwas for the most part truer to its affiliations with philosophical\nEmpiricism and Associationism, and its Nativist commitments were\nobscured. One important lesson is that in the Nativism-Empiricism\ndebate we are often dealing with ideology, not theory (Pinker\n2002). \n\nThe impact of Chomsky on linguistics and cognitive science has been\nmuch discussed. Here we briefly review some of the elements\ncritical to the resurgence of\n Nativism.[3]\nChomsky focused attention on two facts about\nhuman languages: (1) that they are very complex, and (2) that children\ncome to master them without much systematic training. The second\nfact is fairly obvious, but the first is not. A very important\nstep, as far as Nativism is concerned, was Chomsky’s notion of a\ngenerative grammar as a framework for articulating the\ncomplexity of a language. A generative grammar of a particular\nlanguage is a system of rules that generates all (and only) the\nsentences of that language, along with a characterization of how each\nsentence sounds and what it means. Chomskyan linguistics is the\nproject of discovering the elements and structure of such rule\nsystems. \n\nThe link between linguistics and innateness comes in a second\nimportant move: the psychologization of grammars. Chomsky argued\nthat every speaker of a language has a mental representation of its\ngrammar. This sets up a natural question—how did the\ngrammar get into the speaker’s head?—and two\ntraditional answers immediately present themselves. The\nEmpiricist would aim to show that the grammar (if it indeed is\nin the head) could be learned from experience in much the way one\nlearns other facts about the world. The Nativist, in contrast, is ready to\nconsider that learning a language—now reconceived as a matter of\ngrammar acquisition—depends in some way on a language-specific\ninnate endowment. This brings us to the third important\nstep. Chomsky argued that a comparison of (i) the grammar that\nhas to be acquired, and (ii) the idiosyncrasies of the acquisition\nprocess and the data presented to the language-learner, favors the\nNativist approach. \n\nSo Chomsky did more than simply point to language learning as an\narea in which the Nativist case might be\n built.[4]\nHis framework for\nspecifying the grammatical rules that the child has to master\nsharpened the debate between Empiricism and Nativism in something like\nthe way that the mathematicization of physics in the 17th\ncentury revolutionized the empirical sciences. \n\nPart of this sharpening is the result of Chomsky’s important\nmethodological distinction between competence and\nperformance. Chomsky argued that a scientific approach\nto language needed to focus on the specific mental representations that\nunderlie linguistic behavior (‘linguistic\ncompetence’), and not on the behavior itself\n(‘linguistic performance’). Linguistic\nperformance, he argued, is scientifically intractable, because it is\nthe result of too many idiosyncratic interacting factors. We\nwould do better to take on the much more circumscribed question: what\nis the system of rules (the grammar) that generates all the allowable\nsentences? It soon became clear that even if we set aside the\nperformance systems involved in real linguistic behavior, the rules of\nthe grammar were themselves very complicated, often unintuitive, and\nabstract, in that they involved categories and constructs that\nwere at a significant remove from the data. The idea that children\ncould simply ‘pick up’ these rules by attending to what is\nassociated with what in their language environment was just not\nplausible (but we will see in section 3 that this claim continues to be challenged). Yet every normal child does in fact learn a language,\nand so does somehow master these rules. So either the general\nlearning system that the child wields is somehow more powerful than the\nAssociationist-Empiricist had assumed, or the Nativist is right and\nthere is some innate language-specific information that ‘greases\nthe wheels’ of language acquisition. To resist the Nativist\nconclusion, the Empiricist has to return to the drawing board to\ndevelop a more powerful general learning theory. Chomsky\ndeveloped the Nativist position and termed the innate information\n‘universal grammar’ or ‘linguistic\ntheory’. This is the essence of Chomsky’s famous\nPoverty of the Stimulus argument, which in an important way\nprovided a measure of the challenge that Empiricism faces.\nThe Empiricist-Nativist debate was no longer\n‘you-say-experience-I-say-innate’ affair; it looked to many\nto be a matter of ‘put up or shut up’, and the burden was\non the Empiricist to do the putting up. \n\nThere was significant controversy about all the elements of this\nparadigm shift: philosophical tangles about the notion of\nrepresentation (in what sense is the grammar ‘in the\nhead’?), technical linguistic debates about the structure and\ncharacter of grammars for specific languages and about the nature of\nuniversal grammar, controversies in psychology about the relevance of\nChomskyan formalisms to experimental studies of child learners and\nadult speakers of a language, and on and on. But the shift\nheld. Linguistics went from a backwater to a central player (as a\nmodel and as an integrator) in the development of cognitive science as\na multi-disciplinary approach to aspects of cognition and mind.\nDevelopmental psycholinguistics, a field more or less born out of these\nupheavals, set out to investigate experimentally whether the details\nabout language acquisition actually supported the Chomskyan Nativist\nhypotheses, and in time, many developmental psychologists broke from\nthe reigning Empiricist paradigm and began to deploy Poverty of the\nStimulus arguments in other areas of cognitive development. \n\nBefore Chomsky, Nativism suffered from two disabilities. The\nolder charge, which we alluded to briefly at the start, was that the\ndoctrine was in some way incompatible with a naturalistic or scientific\napproach to the world. It is true that the Nativist view, as\ndefended by many early modern Rationalists including Descartes\n(1996/1641 and 1911/1647) and Leibniz (1981/1764), did contain (what we\nnow regard as) a supernaturalist element: what was innate was\npresumed to have been placed in us by God. But beside this taint\nof anti-naturalism, there seemed to be another problem, highlighted by\nLocke: simplicity. Locke (1979/1690) argued that, all things being\nequal, we ought to prefer the simpler Empiricist doctrine, which posits\nonly sense experience and general associationist learning, to the\nNativist view, which adds inborn materials. It is this\npresumption in favor of Empiricism that was inherited by modern\nversions of Associationist psychology; it was taken for granted that if\nthere were equally good Empiricist and Nativist accounts, the\nEmpiricist account would be methodologically preferable on the grounds\nof simplicity. \n\nIn light of all this, it is important to recognize that\nChomsky’s advances undercut both these supposed shortcomings of\nNativism. On the first point, Chomsky repeatedly stressed that\nclaims about internalized grammars and universal grammar were\nunexceptional empirical hypotheses about the internal causes\nof the observational evidence. The question of what is built in\nand what needs to be learned is a straightforward scientific\nquestion. It goes without saying that there is no hint of the\nsupernatural in Chomsky’s linguistics: we have the innate\nstructures we do because we are evolved biological organisms. \n\nThis Nativist connection to evolution raises a natural question: why\ndid the resurgence of Nativism have to wait for Chomskyan linguistics;\nwhy didn’t the theory of evolution, developed more than a\nhalf-century earlier, undermine Empiricism and resurrect\nNativism? The Empiricist paradigm, after all, has always promoted\nitself in terms of its very austere view of human knowers: we perceive\nthe world, and learn all we know on the basis of our perceptual\nexperience of it. But as we noted earlier, the Darwinian\nRevolution made it plain that as a general rule, evolutionary\nforces shape organisms to fit into their niche. Such\nshaping, at least in the animal kingdom, was obviously a matter of\npre-organizing the animal’s behavior-producing\nmachinery—the processing that goes on in its brain—so that,\nfor example, birds know that they should eat worms and build nests out\nof twigs and not vice versa. No one tries to explain the\nbird’s competences (and birds’ natural competences extend\nfar beyond this trivial example) purely in terms of the bird’s\nperceptual experience. Birds are not blank slates at birth.\nBut we humans grow from the same evolutionary branches as the animals\naround us. This line of thought leaves us with a few\npossibilities. One is that all the innate preparedness\npainstakingly established in our evolutionary ancestors was somehow\ndiscarded, and we humans were redesigned—from scratch, as it\nwere—as blank slates with a uniquely powerful learning capability\nto make up for our meager initial holdings. This is, arguably,\nthe traditional Empiricist approach. Another is that we inherited\na good deal of what evolution had established in the cognitive systems\nof the organisms from which we evolved, but that our further advance\nwas, to a first approximation, based not on innate factors but on\nlearning. A third view—the Nativist position—is that\nmore was added in the course of our own evolution, and that we too are\nin some way pre-informed about at least some matters most critical for\nour survival. These possibilities are too vague to be taken as\nhypotheses, but the Nativist view seems at least as initially plausible\nas the Empiricist approach. The important point is that it\nshould have been that plausible a century ago. Somehow the\nNativist implications of evolutionary theorizing were\nalso\n obscured.[5]\nEmpiricists\nmight argue that these implications are not relevant to the Nativist\ntradition that they oppose, but the point is that the issue was hardly\nraised. One suspects that a deep cultural and intellectual bias\nwas at work.[6] \n\nThe upshot of this last point is that the presumed advantage of\nsimplicity that Empiricism claimed for itself was illusory. Once\nwe include in our measurement of simplicity how well a hypothesis fits\nwith other established theories, the simpler hypothesis is that human\nbeings are part of the natural biological order, and that like all\nother organisms they are to some degree pre-shaped by evolution to fit\ninto their distinctive ecological niche. The naturalistic view of\nhuman beings ushered in by Darwin should have, all by itself,\nrevived\n Nativism.[7]\nWe might go a step further and ask whether Empiricism itself missed a\ngolden opportunity to deploy evolutionary theory as a vindication\nof Empiricism. A more enterprising Empiricism might\nhave noted that evolutionary theory commits us to the idea that\nwhatever is innate in us was, at least in one sense, shaped by\nexperience. Experience here would be ancestral\nexperience, not the experience of the individual subject, but such a\nview would still ground knowledge in experience. In other words,\nthe range of ‘learning from experience’, the\nEmpiricist’s core commitment, would simply be extended to cover\nnot only individual learning but species-based learning as well.\nBut this opportunity was for the most part missed. \n\nAlthough Chomskyan linguistics set the stage for a general Nativist\nrevival, it took a while for this train to leave the station, and it\nwill help to understand why. Part of the problem was that the\noriginal case for linguistic Nativism had been made, at least in part,\nby focusing on what looked to be unique features of language.\nLanguage has long been seen as exceptional; as the\ndistinguishing feature of human cognition. Chomsky championed\nthis view, and argued that language is central to a special kind of\nhuman creativity (Chomsky 1966). \n\nWe have already noted one facet of this exceptionalism: the fact\nthat grammars are very complex. But there are also unexpected\nsingularities in how children learn; in the learning process\nitself. Each child is exposed to an idiosyncratic sample of the\nlanguage (their primary linguistic data). Each sample is\ncompatible with any number of non-equivalent grammars that all generate\nthe pld sample so far, but give different verdicts about new\ncases not in the pld. We might therefore expect (i) that\nthe grammar a child acquires reflects the idiosyncrasies of the\npld the child was exposed to, (ii) that, as a consequence,\nchildren will disagree about what is and what is not grammatical, and\n(iii) that adults will therefore have to correct them to smooth out\nerrors that reflect those idiosyncrasies. But this, Chomsky\nargued, is not what we find (Chomsky 1965). Children learning a\nlanguage somehow converge on the same grammar, as evidenced by\ntheir agreement about well-formedness, and by the distinctive types of\nerrors they make and don’t make in the course of\nlearning. If this is right, it suggests that the child must have\nprior information that somehow constrains or orders the hypothesis\nspace that steers the child to the right grammar, and it is hard to see\nhow this information can be acquired through experience.\nFurthermore, the pld contain ungrammatical and incomplete\nsentences, but children somehow filter out this noise, and do so\nwithout explicit instructions or feedback. There are a\nnumber of other striking features about language learning that Chomsky\ndrew attention to: (1) it is acquired rapidly, (2) the speed of\nacquisition does not correlate with intelligence, (3) it does not\nrequire reinforcement or extensive explicit training, and (4) it is\nacquired in a critical period—a relatively fixed window\nin the maturation process—during which other less complex systems\n(counting, for instance—see below section 2.3) cannot be\nmastered. Each of these claims has prompted a long trail of\nexperimentation and theory construction, and all remain controversial\n(see, for example, the discussion in Menn et al. 2003). But\ntheir overall effect was to single out language learning as\nexceptional, and perhaps unique. Chomsky himself marked this\ndifference by speaking of language acquisition and contrasting\nit with learning, a term he reserved for induction-based\nprocesses. \n\nSo on Chomsky’s view, language is doubly exceptional. It\nis the distinctive human cognitive trait, and is essentially\ndifferent from all known animal communication systems. The fact\nthat we have it makes us exceptional as a\n species.[8]\nIt is also exceptional in that\nthe pattern of its acquisition suggests that it stands apart from all\nthat we learn about the world; it simply grows in us. Taken\ntogether, these considerations supported a Nativist account of language\nlearning, but tended to discourage the idea of\nexporting the Nativist revolution beyond language. After\nall, how much of the rest of the child’s untutored knowledge of\nthe world is as complex as grammars reveal human languages to be?\nAnd how much of that knowledge comes to the child as effortlessly and\nwithout explicit instruction? \n\nIn time, the arguments for linguistic exceptionalism gave way to a\nbroader view of the Nativist project. Chomsky (1975) set out a\nfully general schema for Poverty of the Stimulus arguments that did\nnot depend on the distinctive features of grammars and\nlanguage acquisition, which had been featured in making the original\nNativist case. Chomsky began to speak of language as one of\npossibly many mental organs that grow in the\nindividual. This naturalistic biological model embeds Nativism\nabout mental organs into a wider and uncontroversial biological\nNativism. It is uncontroversial that kidneys do not develop as a\nresponse to the environment, and they certainly do not copy the\nenvironment. The human body is organized in such a way that in\nnormal (fetal) environments, kidneys will form. This point could\nnow be deployed against the Empiricist. To presume that the basic\nfeatures of our physical-biological nature are\ninternally pre-determined, but that our\nmental-psychological nature is not, but is wholly\nexternally determined, is to introduce a dualism that requires\na special defense. But Empiricism seems to make just this\npresumption, and offers no credible defense. So the tables are\nturned. The Nativist has been freed from the earlier\nsupernaturalism charge, the simplicity-card of Empiricist models turns\nout to be spurious, and now the Empiricist seems to be the one carrying\nan unmotivated dualism as excess\n baggage.[9] \n\nThe mental organs approach has proven to be extremely influential in\nboth philosophy and the cognitive sciences. In its most general\nform, it has displaced the idea of information in the mind as (for the\nmost part) a single uniform set of sentences or data points, and put in\nits place an alternative architecture of systems and subsystems of\nknowledge and information, each, possibly, having its own design,\npattern of representations, specialized function, pattern of\nactivation, level of integration with other systems, (sometimes)\nspecific locus in the brain, and so on. We mention here a number\nof developments significant to the Nativist side that that have grown\nout of this central theme. \n\nThe modularity of mind hypothesis. Fodor (1983) proposed a\nview of our overall cognitive architecture that rested on a rough\ndistinction between input systems, or relatively rigid computational\n“modules” that are designed to pick up specific types of\ninformation, and more flexible central processors that integrate that\ninformation in various ways. Each of these modules has a specific\ntask-orientation, and does its work independently of much of what is\ngoing on in the rest of the system. So, for instance, we more-or-less\nautomatically hear sound patterns as sentences of our native language,\nperceive patterns of light and shadow as configurations of objects in\nspace, and so on. In these terms, the language organ is just one\nof a set of freestanding mental modules. Fodor suggested a\nchecklist of properties that such modules could be expected to have,\nand among them is that they are innately\n determined.[10]\nThe architectural claim about modular\norganization does not in itself imply an innate basis, but the\nhypothesis that the sorts of response patterns to linguistic and visual\ninput (like those just mentioned) have a strong innate basis is\nplausible and has been experimentally pursued. Fodor’s\nversion of the view is now termed a moderate modularity\nthesis, because he holds that much of the business of cognition\ninvolves ‘central’ processing that is decidedly\nnon-modular. Modules do the work of ‘presenting the\nworld’ to highly integrated non-modular global psychological\nprocesses. But others, like Carruthers (2006), have argued that\nwith some adjustment to Fodor’s original characterization of\nmodules, we can argue for massive modularity. \n\nEvolutionary Psychology. One of the controversial\narguments used to defend massive modularity claims is that evolution\nfavors this sort of architecture. This brings us to the central\ndoctrine of Evolutionary Psychology—i.e., that cognition is best\nunderstood as a ‘Swiss army knife’ of special purpose\npsychological-computational mechanisms that evolved to enhance the\nsurvival of our\n ancestors.[11]\nOne much-discussed example of such a\nmechanism is a ‘cheater detection’ module. Our\nancestors needed to distinguish fair-traders from freeloaders.\nThose who could be consistently taken advantage of in exchanges were at\na significant disadvantage in terms of survival. At some point, a\nmechanism evolved—a computational program in the brain, a mental\norgan (or mini-organ?)—that made such vigilance and\nrecord-keeping second nature, and we now all have this module as part\nof our innate endowment. It’s been argued—but the\nclaim continues to be controversial—that the operation of this\nmodule explains the (purported) fact that although we fall prey to a\nclass of reasoning mistakes, we do not make as many of these errors\nwhen our reasoning is related to cheater-detection. For\nEvolutionary Psychologists, the mind is a collection of evolved\nsub-systems adapted to the environments of our Pleistocene ancestors,\nnot to our own\n environment.[12]\nEvolutionary Psychology is arguably the most\nradical Nativist-inspired paradigm, because it looks to make the range\nof the Empiricist’s general purpose learning mechanism smaller\nand smaller. \n\nTo keep the players straight, we must note that Chomsky himself has\nhad a very complicated relationship with evolutionary explanations of\nmind and\n cognition.[13]\nHe\nis certainly not a friend of Evolutionary Psychology, and has joined\nwith its critics in questioning its adaptationist\n perspective.[14] \n\nCognitive Ethology. The modularist position, and the\nNativism that fits it so well, have been supported by recent work on\nanimal cognition, especially the discovery of very sophisticated\ninformation-rich sub-systems in the animal brain (see Andrews 2010 for\na philosophy-oriented review). Early discoveries about complex\nanimal behavior—like Von Frisch’s work on the dance of the\nbees (Frisch 1971)—remained in the shadows during the heyday of\nBehaviorism, but more and more such systems have come to light since\nthen. Just to take navigation as an example, desert ants have an\ninnate dead reckoning module for navigation, and various birds species\nhave intricate innately-based systems based on the fixed stars,\nmagnetic fields, the azimuth angle of the Sun, and so\n on.[15]\nAll these cognitive\nmodules/mechanisms are innately specified subsystems, and add\nplausibility to the Nativist theme that nature has built human beings\nin the same way. \n\nWe have explained the ways in which Chomsky’s work in\nlinguistics inspired subsequent Nativist thinking in the cognitive\nsciences. But there is an irony here in that, except for the very\ngeneral Poverty of the Stimulus schema (which can be traced back to\nPlato), linguistics and language acquisition have not served as\neasy-to-use templates or paradigms for developing Nativist hypotheses\nin other domains. We so far have no reason to think that there is\nany domain outside language that requires anything as complex as a\ngrammar of a natural language to represent it. So linguistic\ncompetence remains an exceptional element in our\ncognitive\n make-up.[16]\nAnd even\nthough some of the distinctive features of language acquisition have\ncounterparts in other domains—sensitive and critical periods in\nthe development of visual perception, for example—there does seem\nto be something exceptional about the way virtually every normal child\ncomes to master a language. We might say that for Nativists,\nlanguage has been more an inspiration than a working model. But\nat the same time, as Nativists move beyond language, they may avoid\nmany of the methodological challenges to the Chomskyan approach\n(including: is a grammar a theory of competence, in what sense are\ngrammars ‘mentally represented’, is the pld all\nthat’s relevant to acquisition, etc). \n\nA full account—even a comprehensive survey—of Nativism\nin the cognitive sciences is beyond the scope of this entry. But there are a number of\nconceptual domains that have been especially well investigated by\ncognitive scientists in the last decades, and this section will\nhighlight a few areas that are the subject of lively and theoretically\ninteresting work, and that are connected to traditional and\ncontemporary philosophical concerns. \n\nThe research we will discuss in this section is inspired by the\nChomskyan paradigm, but there is an important difference between the\nlanguage case and this developmental work. Chomsky’s\nLinguistic Nativism used Skinner’s Behaviorism as a foil, but the\nBehaviorist paradigm was not the reigning scientific paradigm\nin the area of child development. In this field, the Swiss\npsychologist Jean Piaget was the dominant figure, and his research has\nserved as the backdrop for most developmental work over the last 40 or\n50\n years.[17] \n\nPiaget generally ignored Behaviorism, and conducted experimental\nstudies on the child’s evolving conception of the world.\nHis extensive research agenda included the child’s understanding\nof space, time, God, objects, causality, morality, dreams, number,\nbeing alive, and more. Piaget’s specific questions and\nexperimental results—which were reciprocally (mostly) ignored by\nBehaviorists—have served as a jumping off point for many\nNativist-oriented theorists. But Piaget was not a Nativist.\nThe heart of the Piagetian paradigm is his stage\ntheory. On this view, children start with a very different\nconception of the world than adults have—in fact, Piaget thought\nthat they start without a conception of an external world at\nall—and they go through a series of identifiable stages that\nculminate in adult understanding. The powerful unifying idea here\nis that there is something about the general character of these stages\nthat is the same across all domains of understanding, and that the\ndynamics of stage transition is also uniform. To a first\napproximation, for Piagetians there are no significant distinctions\nbetween the developmental patterns in different domains of\nunderstanding. If we consider any domain, the stage theory\nimposes a uniform grid of steps in the development of that domain\nknowledge. The dynamic picture, again very roughly, is that a\nchild at a stage proceeds until she faces an insurmountable obstacle;\nher present grasp of things makes it impossible for her to deal with a\nrecalcitrant problem. This disequilibrium propels her to the next\n(pre-plotted) stage, in which new internal resources become\navailable—an enriched conception of the world or a new\nflexibility in physical interaction—and the earlier problem can\nbe resolved. The child recovers equilibrium until coping with\nproblems again causes a crisis that leads to the availability of more\nnew resources, and so on. The articulation of the Piagetian\nparadigm involved understanding the general nature of these\nstage-transitions better, exploring how the stage theory operates in\nspecific domains, and understanding the new cognitive and behavioral\nresources that make these transitions possible. \n\nPhilosophers will recognize the theory as in some ways analogous to\nthe theories of scientific development proposed by Thomas Kuhn\n(1962/1996) and others. Two important differences are worth\nmentioning, because they highlight what is distinctive about\nPiaget’s approach. First, although science develops\norganically, there is, for Kuhn, no one specific resource that\napplies across all fields. What explains the shift from\none dominant paradigm to another in economics will typically not\nexplain the shift from the Ptolemaic to the Copernican paradigm in\nastronomy. But Piaget held that what makes it possible for the\nchild to advance in her understanding of space is in one sense the\nsame thing as what facilitates the stage transitions in the\nchild’s developing understanding of God or morality.\nSecond, science depends on the contingent, uniquely fruitful\ninnovations that overthrow older understandings and set the stage for\nnew ones. But in children, Piaget’s developmental stages\nare posited as mandatory; we might say they are innately prescribed\nsteps in normal development. The child’s forward motion is\nregularized as the world presents its predictable problems, and the new\nresources become available to solve them and advance the child’s\nunderstanding. The upshot is that although Piagetians produced\nprobing and highly detailed studies of various domains of the\nchild’s understanding, they shared the Empiricist preference for\nan across-the-board domain-general mechanism that could explain the\ndevelopmental facts in every domain. Although there are\ninteresting ideas inherent in the Piagetian paradigm about the innate\nendowment that makes adult cognition possible, it is not easy to place\nPiagetian Constructivism on the Nativist-Empiricist\n spectrum.[18] \n\nPiaget’s theories provided the scientific received view\nagainst which developmentalists inspired by Chomsky’s linguistics\nreacted. These researchers set aside Piaget’s assumption\nthat development is uniform across domains, and instead—in part\ninspired by Chomsky’s organology and modularity\nclaims—considered each domain independently. The overall\nstrategy was to discover the cognitive capacities of the youngest\nchildren, and to develop and test hypotheses about (i) the initial\nstate, and (ii) the transitions that move the child from the initial\nstate to the normal adult repertoire. \n\nThe ‘Core Cognition’ hypothesis. Many\ndevelopmentalists in this camp share a commitment to the ‘Core\nCognition’ (sometimes called ‘Core Knowledge’)\nhypothesis (Carey 2009; Carey\n& Spelke 1996; Spelke et al. 1992; Spelke 1998, 2000, 2003). According to this hypothesis,\nevolution has equipped our species (and other species too) with an\ninnate repertoire of conceptual representation types, that is,\nrepresentations that cannot be reduced to the perceptual primitives\nfavored by the Empiricists or the sensory-motor primitives favored by\nPiagetians. Rather, evolution has shaped our perceptual input\nanalyzers to detect certain types of entities in the world, and has provided us with principles—embodied in our cognitive machinery—that determine how we (at least initially) think about such entities. These different types of\nentities are few in number. To date, there is a consensus among proponents of this\nhypothesis that the innately specified core domains\ninclude physical objects, number, and minds.[19] Proponents of the\nCore Cognition view defend a moderate Nativism; they leave work for learning mechanisms, which, together with\nmaturation, take the infant from limited ‘core’\nconceptual systems to the broad and highly elaborated knowledge of\nthe world that adults have. In some cases, adult knowledge\nextends the core; in others it ‘over-writes’ it. The conceptual machinery that embodies a core domain is often referred to as an ‘intuitive theory’—for instance, a folk physics or folk psychology (sometimes theory of mind)—to highlight the fact that each supports patterns of conceptualization of input and inference.  There is intense ongoing work on core domains, and research paradigms are being extended to non-human animals and across cultures.  In\nthe sections that follow, we review select findings on three\ndomains: physical objects, number, and intentional agents.[20]\nWe concentrate on very early\ndevelopment. While it is often difficult to say what\nexactly the research reveals about the young child’s\nknowledge (for methodological as well as philosophical\nreasons), the earlier some distinctive elements of a competence are\npresent, the less likely that it was learned solely on the\nbasis of experience. \n\nMethodological innovation: the\n‘violation-of-expectancy’ looking time. The work\nwe discuss depended on solving a knotty methodological problem: how to\ndiscover what is going on in the minds of preverbal infants and very\nyoung children? Though infants cannot report on what they are\nperceiving or thinking, one can make inferences from their reactions to\nobjects and events. Long before they utter their first words,\nthey suck, grasp, creep, crawl, and—most importantly—they\nlook. Since infants, like adults and other animals, look longer\nat an unexpected stimulus, where they look and for how long they look\ncan reveal a good deal about their expectations about the\nworld. While measures of grasping, crawling, and sucking have all\nbeen successfully used to reveal some of what is going on in the baby’s\nmind, the measure that has been used most extensively is the\nviolation-of-expectancy looking time (sometimes called\npreferential looking time). Experiments using this measure\ntend to have a similar structure: during an initial phase, the child\nis presented with display \\(X\\), over and over, until the child’s\ninterest wanes and looking time drops down to some criterion\n(the habituation phase). In the test phase, the\nchild is presented with two displays: \\(Y\\) and \\(Z\\). If\nthe child reliably looks longer at \\(Y\\) than at \\(Z\\), this\nprovides evidence that \\(Z\\) is as expected, but that \\(Y\\)\nis unexpected. \n\nAs adults, we recognize physical objects as bounded entities that\npersist through space and time; they ‘hold together’ as\nunits, and their paths, when they move, are continuous. In addition, objects causally interact upon contact\nwith each other. Do we learn these properties of objects by\nexperience, and if so, by what sort of\nexperience? Empiricist thinkers have argued that these properties\nare learned, and have proposed several different types of experience as\nrequisite input to such learning. Helmholtz (1867/1962) suggested\nthat moving around objects and manipulating them were necessary for\nbuilding a concept of an object. Quine (1960) looked to language\nas the relevant source of information, and Piaget (1954)\nproposed that sensorimotor coordinations led to construction of the\nconcept of a physical object. Indeed, Piaget famously argued that\ninfants altogether lack object permanence (1977), the\nunderstanding that objects persist in time and space, until the latter\nhalf of the second year of life. \n\nObject permanence. In the last 35 years,\nthe baby’s representation of objects has been re-explored with\nstriking results. A landmark study (Baillargeon et al. 1985) used\nthe violation-of-expectancy paradigm to test the Piagetian claim that\ninfants lack object permanence. Five-month-old infants were shown\na screen that rotated 180 degrees up from the surface of a table and\nback again to its initial position. In the habituation phase, the babies\ngot used to the screen motion and their looking time decreased,\nevidence that they no longer found the screen’s movement to be\nnovel. In the test phase, an object was placed in the path of the\nscreen as the screen moved downward to the table’s surface.\nIn one outcome, the screen rotated down until it touched the object and\nthen rotated back up to its initial position, an event that adults\nrecognize as possible. In the other outcome, the screen continued\nits downward trajectory to the table, at first hiding the object and\nthen apparently moving right through the space occupied by the object,\nan event that adults recognize as physically impossible. The\nlogic here is straightforward: babies will see the second outcome as\nsurprising only if (i) they represent the object as continuing to exist\neven when it can no longer be seen behind the screen, and (ii) they\nassume that two objects cannot occupy the same space at the same\ntime. Only then should they look longer at what adults recognize\nas an impossible event. If, however, young infants lack object\npermanence or have no constraints about two physical objects occupying\nthe same space, the impossible event will not constitute a\nviolation of any expectation. The results were clear; babies\nlooked longer at the impossible event, indicating that it violated\ntheir expectation of objects. The same finding was later\ndemonstrated with 4-month-olds (Baillargeon 1987). These findings\noffer evidence that very young infants represent objects as persisting\neven when they are no longer in view, an understanding of object\npermanence thoroughly at odds with the claims of Piaget and\nQuine. One may still ask what exactly the child\nknows or represents (Burge 2010 is especially\npertinent here), but the point is that there is something in\nthe child’s cognitive apparatus that is sufficient to generate\nthis expectation, and the burden of explanation is on the view that\nthis is learned from experience. Moreover, these infants also\nexpect that two objects will not occupy the same space at the same\ntime. \n\nSpatiotemporal continuity of objects. As adults, we know that\nobjects are spatiotemporally continuous; an object that appears at\npoint \\(A\\) and then at point \\(B\\) must have traversed a\ncontinuous path between these points. Here too the violation of\nexpectancy looking time paradigm has been used to test the Empiricist\nclaim that such knowledge requires an extended learning period. In one\nstudy (Spelke et al. 1995), 4.5-month-olds were shown a stage with 2 screens on it, with a\nvisible gap between the screens. In the discontinuous motion\ncondition, each screen has an object hidden behind\nit. First, the object behind the left screen is moved further\nleft so that the baby sees it, then it is moved back behind that same\nscreen. The object behind the right screen is shown in the same\nway, so that during these displays only one object has been visible at\na time and no object has ever been shown to cross the gap between the\ntwo screens. Adults seeing this display infer that there are 2\nobjects involved. To find out if babies make the same inference,\nthe screens are removed and the infant is shown either one object or\ntwo objects. The result is that infants look longer at the\none-object display, presumably expecting, like adults, that there had\nto be two objects; otherwise, the object would have been visible\ncrossing the gap. In a follow-up study, a continuous motion\ncondition was used. This condition is identical to the previous\ncondition except that, between the alternating trials, an object\nis seen crossing the gap. In this condition babies\nlooked longer at the display of two objects. Like\nadults, they presumably assumed there was a single object moving back\nand forth (Aguiar & Baillargeon 1999 report similar findings\nwith 2-month-olds).  Generally, by 2-months, and perhaps earlier, infants expect that objects persist through time, move continuously, have parts that cohere, and are solid (Spelke 1990).  Recent work (Rips & Hespos 2015) shows that by 6-months, babies already have different expectations for rigid bodies, soft objects, and liquids. \n\nIf the representation of spatiotemporally continuous objects is part\nof our evolutionary endowment, we might expect to find such\nrepresentation in the newborn of other species, and indeed we\ndo. Newborn chicks, for example, display a striking ability to\nrepresent spatiotemporally continuous objects (see Spelke 1998 for\nreview). In one study, newborn chicks spent their first day of\nlife in a homogeneous environment containing only one inanimate object.\nOn their second day, the object was moved fully out of view\nbehind one of two screens. Though they had never before seen an\nobject hidden behind another, they reliably searched behind the correct\nscreen where the object was hidden. Indeed they even did so when\nthey had to turn away from the object in order to reach it (Regolin et\nal. 1995; Regolin et al. 2000). Chicks, it seems, have object\npermanence from birth. Although this does not show that\nobject permanence is innate in humans, it does show that in at least\none animal, evolution has succeeded in building it in.\nSo Nativists can claim an existence proof of an innately endowed\nrepresentation of objects as permanent. \n\nWynn (1992) showed that young babies represent objects as not only\npersisting in time and space, but also as subject to addition and\nsubtraction. In that study, babies were habituated to a display\nof a single object on a stage. Then a screen came up and hid the\nobject completely. Now a hand was seen to bring in another\n(identical) object and move behind the screen, from which the hand then\nwithdrew empty. The question was: do the babies now represent 2\nobjects behind the screen? Test displays consisted of 1 object, 2\nobjects, and 3 objects. Again, in line with Nativist claims,\nbabies showed longer looking times to all displays except the\n2-object display. In this respect, babies showed the same\nexpectations that adults do. Further testing showed that babies\nare not only capable of ‘adding up’ the number of hidden\nobjects (at least to 3), but are also capable of\n‘subtraction’ of the same number of hidden objects as well.\nThis finding has been replicated in 4- and 5-month-olds as well\n(Simon et al. 1995; Koechlin et al. 1998). \n\nIt may be tempting to see the infant’s ability to add and\nsubtract the number of objects in a display as evidence that infants\nalready have something close to the adult concept of number, but a\nseries of studies suggests that this is not the case. Most\ntelling is the extremely limited set size (about 3 objects) over which\nthe baby can add or subtract. To illustrate this set size limit,\nwhich has emerged in a variety of experiments, consider the following\nstudy that used crawling, rather than violation-of-expectancy, as an\nindicator of the baby’s representation (Feigenson & Carey\n2005). In this study, babies watched as graham crackers were\nplaced, one at time, into 2 separate boxes. The babies were then\nallowed to crawl to the box of their choice and retrieve the\ncrackers. When one box had 1 cracker and the other box had 2,\nbabies crawled to the box with 2. Similarly, when one box had 3\ncrackers and the other had 2 or had 1, they crawled to the box with\n3. The surprising finding, however, is that babies failed with 4\nversus 3, 4 versus 2, and even 4 versus 1. Apparently, the\nability to represent and keep track of exactly 4 objects is beyond the\nbaby’s capability. Given the set size limit of 3 objects,\nit is arguable that the baby’s competence should be understood as\nan ability to track 3 different objects in working memory. One\nmight argue that the baby can succeed in adding and subtracting very\nsmall numbers of objects without having a general concept of number\nor any general numerical competence. We return to this issue\nin section 2.3. \n\nAs mentioned above, Piaget (1954) proposed that sensorimotor\ncoordinations gradually lead to construction of the object\nconcept. Establishing these coordinations between different modes\nof perceptual experience—vision and touch, for\nexample—would take time, and Piaget proposes that it is not until\nthe child is 18–24 months that these coordinations have been\nconstructed. Meltzoff\n& Moore 1977 provide counter-evidence to this claim. This study shows that newborn infants\ncan imitate the facial movements of an experimenter, clearly revealing\nthe coordination of their own movements (along with the attendant\nfeelings of their muscles) and their visual perception of the\nexperimenter’s facial movements. The following video links\n(Ferrari et al. 2006,  videos S1 and S2)\nprovide some evidence\nthat newborn rhesus macaques have this ability as well. Insofar\nas these coordinations of different modes of perceptual experience are\npresent at birth in humans and in monkeys, they simply could not be the\nproducts of learning.  \n\nThere is currently a great deal of empirical research—and\nphilosophically sophisticated\n debate[21]—on\nthe underpinnings of numerical knowledge\nin adults and children. There is strong evidence for the view\nthat in addition to an exact number system that underlies\nformal mathematical thinking, adults also have an analog magnitude\nsystem for representing approximate number (see Dehaene\n1997). For example, if we are very briefly shown 2 bowls of rice,\none with 20 grains and one with 50, we can tell immediately which has\nmore, even though we couldn’t say exactly how many grains of rice\nwere in either. Similarly, shown a book with 70 pages and a book\nwith 100 pages, we can see instantly which has more pages—though\nagain without knowing the exact number of pages in either book.\nControlled tests show that such judgments are independent of variables\nthat correlate with magnitude, such as the extent of space occupied or\nthe size of the individual stimuli. The ‘signature’\nof this analog magnitude system is its ratio dependence: that\nis, the difficulty in comparing two analog magnitudes decreases as the\nratio difference between them grows. Recent studies indicate that\nthe smallest ratio difference needed for adults to successfully\ndiscriminate 2 different analog magnitudes is 8:7. If the ratio\nis smaller, error rates in comparing magnitudes spike up. \n\nAnalog magnitude representations in\ninfants. Recent studies have shown have\nshown that 6-month-olds use this same analog system to discriminate\nnumerical arrays (McCrink & Wynn 2004b; Xu\n& Spelke 2000). In one study (Xu & Spelke 2000),\ninfants were habituated to displays of either 8 dots or 16 dots.\nWhen shown novel dot displays, babies who had originally seen 16 dots\ndishabituated to displays of 8, but remained habituated to the new\ndisplays of 16. Similarly, babies who had been habituated to 8\ndots dishabituated to novel displays of 16, but not novel displays of 8\ndots. (Again, researchers controlled for the cumulative amount of\nspace occupied by the dots, the density of the dots, and the size of\nthe dots.) A series of studies have now shown that 6-month-old\nbabies can use the analog magnitude system successfully so long as the\nmagnitudes differ by a 2:1 ratio. When presented with dots\ndisplays that have a 3:2 ratio, such as 24 to 16, babies this age do\nnot show discrimination. Note that the necessary ratio for\ndiscrimination gets smaller with age, so that 9-month-olds succeed when\nthe magnitudes differ by 3 to 2. One might have thought that this\nability to discriminate approximate quantities is somehow implemented\nin the visual system, but the analog number system has been shown to\noperate at a more abstract level (or perhaps to be implemented in a\nnumber of perceptual modalities). At any given age, the same\nratio applies no matter whether the stimulus is a number of dots in a\nspatial array or the number of tones in an auditory sequence (Lipton\n& Spelke, 2003)—or even a number of events (jumps) in a\nvisual display (Wood & Spelke, 2005). \n\nNot only do these representations support comparisons of magnitude,\nthey have also been shown to support approximate addition and\nsubtraction in babies as young as 9-months-old. In one study,\nbabies were presented with a set of 5 objects that moved behind a\nscreen so they were no longer visible. Then another set of 5\nobjects was presented and they too moved behind the screen. When\nthe screen was removed, babies looked longer if there were only 5 objects\nthan if there were 10. In a parallel subtraction condition, where\nbabies first saw 10 objects move behind the screen, and then saw\n5 objects taken away, they stared longer when the screen was removed to\nshow a display of 10 objects (McCrink & Wynn, 2004a). \n\nThe approximative analog system we have been discussing is different\nfrom the object-tracking system mentioned earlier (for instance, in the graham cracker\nstudy). The infant’s object-tracking system has a severely\nlimited set size, and this is true of the adult’s tracking system\nas well. The analog magnitude system does not. It has also\nbeen found that infants’ success shows the ratio-dependence\nprofile of the analog magnitude system. The fact that 6-month-old\nbabies appear to use the same system of analog representation that\nadults do—although, again, their discriminations are less\nfine—strongly suggests that humans come equipped with an innate\nsystem that makes it possible for them to make relative size\ndistinctions across modalities. Very recently this hypothesis has\nbeen given strong confirmation by a study showing that the analog\nmagnitude system operates in newborn babies (Izard et al. 2009).\nIn this study, newborns were familiarized with auditory sequences\ncontaining a fixed number of syllables and were then tested with\nvisual-spatial images of the same or a different number of\nobjects. Infants spontaneously associated stationary,\nvisual-spatial arrays of 4–18 objects with auditory sequences\n(spoken syllables) on the basis of approximate number, providing\nevidence for abstract numerical representations at the very\nbeginning of postnatal\n experience.[22] \n\nIs the analog system species universal? If this\nanalog numerical system is innate, it should be found in all human\nsocieties, no matter how urban or rural, educated or unschooled,\nwhether in technologically advanced societies or remote and isolated\ntribal villages in other parts of the\n world.[23]\nIf it is the same system evident in the\nyoungest infants, it should not require exposure to any symbolic\nrepresentations of number, such as Arabic numerals or a number\nlexicon. To test this hypothesis, investigators explored the\nanalog number system in the Amazonian Munduruku people, an isolated\ntribe whose language has no words for numbers greater than 5. As\npredicted, the Munduruku compared and added large approximate numbers\nfar beyond their naming range. Moreover, performance decreased as\nthe ratios decreased, just as it did in a group of French control\nsubjects (Dehaene et al. 2008). \n\nAnimal representation of approximate quantities. If this\nnumerical system (what Dehaene has called our number sense) is\npart of our innate endowment, might it be evident in other primate\nspecies? Hauser and his colleagues (Hauser et al. 2003)\npresented cotton-top tamarins with auditory sequences of syllables of\ndifferent numerosities. Like humans, monkeys orient their\nattention to unexpected stimuli. When they hear a sequence of\nsyllables of an unexpected numerosity, they turn their heads toward the\naudio speaker from which the sounds are emanating, providing a reliable\nindicator of their discrimination of the novel number. The\nresults are similar to those of the infant studies: cotton-top tamarins\ndiscriminated between sequences of syllables based on approximate\nnumerosity alone. Moreover, discriminability depended on the\nratio of the numbers, just as it does in humans. Indeed, adult\ntamarins showed comparable discrimination abilities to nine-month-old\nhuman babies. \n\nThere is now a sizeable literature showing the presence of analog\nmagnitude representations in many different kinds of animals, including\nrats, crows, pigeons, a parrot, rhesus macaques, apes, and dolphins\n(see Carey 2009 for review). In short, there appears to be\nexcellent evidence from studies of human adults, human babies, and\nanimals, all suggesting the presence of an ancient evolutionary system\nof approximate number representation. \n\nIf one steps back from the theoretical heat of the\nEmpiricist-Nativist debates, it should not be surprising that we have\nan innate system for discriminating sets by their approximate size, and\nthat this system is found in other animals too. Animals typically\nneed to take some measure, for example, of the relative size of food\nsources, of the relative number of predators on their left and right\nflanks, and so on. In some animals, these abilities may be part\nof an encapsulated system devoted to a specific task. The\nbee’s awareness of the relative size of a discovered food\nsource—information communicated in the scout’s\ndance—is a popular example of this sort of ability (Frisch\n1953). In other animals, the system operates more broadly, and\ndifferent sorts of inputs can be measured in this way (heard sounds,\nperceived jumps, and so on). It is as if the brain has an\n‘accumulator’; a bar graph system of some kind that maps\ninput arrays into some neutral format and appends the elements together\ninto a stack, and a scanner that judges relative stack size.\nGelman and Gallistel and others have explored such systems extensively\n(starting with Gelman & Gallistel 1978). \n\nEqually unremarkable is the fact that crawling infants distinguish 1\ncracker from 2 and 2 from 3. This discrimination is beyond the\nabilities of the posited analog approximative systems. But it\nsuggests that there is another system in the child that is in a limited\nway sensitive to number. This system—which seems more tied\nto attention—is the subject of current research (see, for\ninstance, Pylyshyn 2007). Animals need to keep track of changing\nelements in their immediate environment. One idea under investigation is that there\nis a psychological subsystem system that ‘tags’ elements in\na perceptual array and keeps track of them by assigning properties to\nthe tag. Without such a system, we would lack the ability to\nre-identify changing elements from one moment to the next. Such a\nsystem therefore seems to be a prerequisite for any perception of a\nworld/scene, as involving things that are moving and changing. It\nis difficult to see how an animal that does not track in this way could\nlearn to do so (although the ability might grow). \n\nIf current thinking about these systems is on the right track, we\nhave two innate systems, each of which deals with number in some\nsense. The analog system takes a range of perceptual\npresentations and assigns an ordering by relative magnitude. The\nsecond system identifies and tracks (a limited number of) discrete\nelements in an environment. A current research question that is\nof particular interest to philosophers is this: what is the relation of\nthese innate systems to the adult concept of number.\nNotice that the analog system does not get us to the concept of an\nexact number. Only ranges are detected—the system can judge\nthat two sets are in the same range (below the ratio-threshold for\ndiscrimination), but two arrays that are “the same” in this\nway need not have the same number of elements. The\nsecond system is not approximative. If the subject has\ntracked 2 objects and 1 is added, as in Wynn’s studies, the\ndifference is noted and the subject’s expectations change\naccordingly. So this object-tracking system is sensitive to\nthe number of units in play, and in this respect is closer to\nthe adult notion of number. But it has an extremely constricted\nrange, and is useless when it comes to problems that extend\nbeyond its range. The crawling infant in the study cited earlier\ndoesn’t represent an added 4th cracker as one more\nthan the 3 previously tracked. The infant doesn’t even\ntrack the 4th element: the system seems to\n(eccentrically) shut down completely when its range is exceeded.\nSo the concept of number—the successor function and all that it\nbrings in its wake—is not implemented in this system. \n\nFor these reasons, some have argued that aside from these\nwell-evidenced systems, there must be a third element in the human\nmind—viz., an innate concept of number, which must involve the\ngrasp of a fully-general successor function—that grounds adult\nmathematical competence (see Leslie, Gallistel & Gelman 2007,\nfor example). Others, like Carey (2009) have argued that the\nconcept of exact number is not innate, but is constructed by\nthe kind of language-based bootstrapping sketched out by Quine (1960).\nThe debate here is especially interesting because although both sides\nare Nativist—in that both accept innate ‘numerical’\nsystems—there are still learning elements in play in the search\nfor an adequate psychological account of our distinctive arithmetic\ncompetence. \n\nThe simple question: “Is number innate?” turns out to be\ntoo simple. However the current debates play out, we can expect\nthat the achievement of adult number competence is quite complex and\ninvolves significant innate and learned elements. We should be\nprepared to find that things are no less complicated on other\nEmpiricist-Nativist battlegrounds. \n\nIn a seminal paper of 1978, Premack and Woodruff posed the question\nof whether chimpanzees have a ‘theory of mind’; that is, do\nthey attribute mental states to others, and do they, like adult humans,\npredict and explain action on the basis of hypotheses about these\nstates. It was a mark of Piaget’s influence that no one had\nas yet asked this question in regard to human infants; Piaget thought that they did not yet have a robust notion of an external world at all, let alone of a world containing minds.  The chimp\nstudies led to an explosion of research into the development of a\ntheory of mind in human beings. In responses to Premack and\nWoodruff’s paper, Dennett and others commented that the\nsuccessful prediction of another’s action does not yet constitute\nevidence for a theory of mind. Consider the following: a child\nparticipant in a study is told a story about a boy named Max who has a\npiece of candy. Max puts it into the red cabinet and goes out to\nplay in the yard. The child participant is asked, “When Max\nreturns and wants to get his candy, where will he look for\nit?” The child might answer correctly because he\nor she understands that Max will think that the candy is where\nhe left it or last saw it (i.e., the red cabinet). This involves\nattributing mental states to Max. But the child might also answer\ncorrectly because that’s where the candy actually is. That\nis, the child with no theory of mind might still answer correctly\nsimply by reasoning that people go to get things where they\nare. The way to resolve this uncertainty, Dennett proposed,\nwas the false belief task. In this task, which quickly\nbecame the litmus test of a theory of mind, the story includes a second\ncharacter who enters the scene while Max is still outside in the\nyard. This second character finds the candy in the red cabinet\nand puts it into the yellow cabinet. Once again, the child\nparticipant—who has seen the transfer—is asked where Max will look for his candy when he returns\nto the kitchen. Only if the child is successful now, responding\nthat Max will look in the red cabinet—even though the\nchild knows that the candy is really in the yellow cabinet—can we\nlegitimately attribute to the child a theory of mind. There is\nnow a very large literature involving the false belief task and the\nbottom line appears to be that most young 3-year-olds incorrectly\npredict that Max will look in the yellow cabinet (or, in some studies,\nsay that Max thinks it’s in the yellow cabinet)\nbecause that’s where it is, while somewhere between the\nages of 3.5 and 4, children begin to succeed on the\n task.[24] \n\nFor two decades, success on the false belief task was considered the\nonly really hard evidence for a claim that one had a theory of mind.\nWhatever social competence children showed before passing the\nfalse belief test was widely considered a precursor to having\na theory of mind. More recently, however, cognitive\ndevelopmentalists have argued that success on the false belief task is\nneither necessary nor sufficient for the attribution of a theory of\nmind, and that focusing nearly exclusively on it has led to an overly\nnarrow view of the conceptual domain (Bloom & German\n2000). The last several years have seen a plethora of studies\ninvestigating the attribution of mental states, and social cognition\nmore broadly, in infants. The next section focuses on a group of\nkey concepts involved in understanding minds including\ngoals, agency, and rationality. \n\nWoodward’s 1998 study on goal understanding in 6-month-olds is\na good example of the pattern of recent work in this area.\nInfants watched a hand move across a stage and repeatedly grasp one of\nthe two objects on opposite sides of the stage. The hand always\nmoved along the same path to the same side of the stage and then always\ngrasped the same object. After the infants habituated to this\ndisplay, Woodward switched the location of the two objects. Now\none of two events occurred: either the hand took a different\npath to grasp the same object it had always grasped (that object now being on the other side of the stage) or it took the\nsame path as before, but now grasped the other\nobject. Looking time showed that infants were more surprised when\nthe hand followed the same path and grasped the other object than when\nit followed a new path and grasped the originally grasped object.\nThis would make sense if the infants understood in some sense that the\npreviously grasped object was the hand’s preferred\ngoal. To see if this was really the basis of the\nbabies’ looking responses, control conditions were included to\nrule out a variety of other possibilities. \n\nIn a control condition, the hand was replaced with a rod that had a\nmulti-fingered sponge at the end. When the rod/sponge followed\nits old path and touched the new object, babies did not dishabituate;\nthey dishabituated only when the rod/sponge followed a new path to the\nold object. The suggestion is that the babies did not see the\naction of the rod/sponge (whose shape was similar to the shape of the\nhand) as a goal-directed action. What is it about the\npresence of the human arm that signals a goal? Would any movement\ninvolving repeated contact between a human hand and one of the toys\ntrigger goal attribution? Woodward (1999) shows that this is not the\ncase. In this study, a human arm was used again, but this time\nthe arm merely dropped onto the display, and contact was between the\nback of the hand and the toy. In this case, there was contact,\nbut not grasping. In this condition, adults would be less likely\nto interpret the action as purposeful, and the same was true of the\nbabies. When the hand/arm followed its earlier path (touching the\nnew object), babies did not dishabituate; they did however dishabituate\nwhen it followed the new path, even though it made contact with the\nsame object as before. This suggests that 5-month old babies,\nlike adults, attribute goal-directedness (again: ‘in some\nsense’) to human arms and hands that reach and grasp,\nbut not to arms that only drop and make passive contact with the\nobject. \n\nWhat clues do babies use to determine if a perceived motion is\ngoal-directed? The previous study suggests that they are finely tuned to complex patterns of self-directed bodily activity.  One might hypothesize that babies first\nrestrict their attributions of goals to humans only and then, with\nexperience, extend the range to include non-humans as well (Woodward\n2005; Meltzoff 2005). But a recent study, however, suggests that this\nmay not be so. In this study (Luo & Baillargeon 2005),\nbabies reliably attributed goals to a moving box, which they were\npreviously shown could move on its own. The key difference\nbetween the rod/sponge in Woodward’s study and the moving box in\nthis study appears to be information about autonomous\nmotion. The rod/sponge never showed such capacity; the\nmoving box did. Autonomous motion, the authors argue, signals an\nobject’s status as an agent, and agents, for the baby,\nhave goals. These results have recently been extended to\n3-month-olds (Luo 2011). \n\nA very recent study has shown that infants are sensitive not only to\nclues indicating an agent’s capacity for autonomous motion, but\nto the perceptual information available to the agent as well and to the agent’s preferences.\nRemarkably, this is true even when this information differs from\ntheir own. In Luo and Johnson (2009), 6-month-old babies saw another person look at 2 different objects and repeatedly reach for the same one. As indicated by their looking times, babies in this condition attributed to the other person a preference for the chosen object.  In contrast, in a condition where the baby saw 2\nobjects, but also saw that the other person could see only one, no preference was attributed. In this case, it seems, the baby\nappreciates that the other person cannot see the second object and that\ntherefore the repeated grasping of the first object does not indicate a\npreference. This suggests that babies at this age can already\nattribute different perceptual information to different perceivers\n(what I see vs. what she sees). Nativists expect to find\nsimilar sorts of perceptual preparedness for other systems of knowledge\nand action (for instance, a system of face recognition as preparedness\nfor social and family life). \n\nThe cognitive resources we bring to bear on the problem of\nresponding to and carrying out goal-directed behavior is complicated;\nthese studies provide evidence that some of these resources are in\nplace very early in life. They do not show that the\ninfant’s goal-directedness abilities are innate; they might\nsomehow be learned on the basis of early experience. But again,\nsuch findings shift the burden. The earlier that resources\ninvolving notions like intention, goal,\npreference, and so on appear, the greater the challenge to\nEmpiricist claims that the categories are learned solely on the basis\nof prior experience. \n\nAnother set of studies (Kuhlmeier et al. 2003; Hamlin et al. 2007)\nprovide evidence that infants are not only sensitive to displays of\nagency, but also have a sense of (something like)\ncooperative behavior: they readily distinguish between\nhelpers and hinderers. In the 2007 study,\nbabies were shown animated displays that adults interpret as a red\ncircle trying to climb a hill but having trouble making it all the way\nup \n(Hamlin et al. 2007 video display on line).\nIn half the trials, the babies see a yellow triangle gently\n‘helping’ the circle up the hill; in the other half, they\nsee a blue square gently pushing the triangle down to the bottom.\nAdults plainly see the yellow triangle as a helper, an agent\nwhose goal is to assist the circle in getting up the hill; they see the\nblue square as a hinderer, an agent whose goal is to stop the\ntriangle from getting up the hill. Babies make such a distinction\nas well. Six-months-olds showed surprise in test trials that came\nafter the hindering and helping scenarios, in which the red circle is\nseen approaching its hinderer rather than its helper.\nFurthermore, in a live action version of the task, the 3-month-old babies\nthemselves chose to touch the helper more than the hinderer when they\nwere given both to\n choose.[25] \n\nIt would seem, then, that sometime between 3 and 9 months, babies are\narguably already on their way to a concept of desert.  Much\nremains to be discovered about the contours of their concept and its\nsubsequent development.  As Hamlin points out, apart from the\nhelper-hinderer contrast, we don’t know how they determine who\ndeserves what.  Relevant here is the finding that babies prefer not\nonly helpers, but also those who are relevantly similar, who like the\nsame toy or candy, for example (Mahajan and Wynn 2012).  How much of\ntheir apportionment of desert is dependent on such factors as opposed\nto factors that adults might consider morally relevant, like fairness,\nresponding to need, and so on. How, if at all, does their early\nconcept connect to egalitarian notion of fairness?   \n\nIf we consider morality as a system that evolved to enhance cooperation within large groups of unrelated individuals (Bloom 2013, Joyce 2006), we see that infants have some of the key prerequisites in place for such a system:  (1) they have a positive attitude towards cooperation, (2) they have some grasp of other actors’ preferences and their informational point of view, (3) they are sensitive to actors’ intentions as embodied in their actions, and (4) they are ready to enforce rules by punishing violators and rewarding adherers, and they approve others who do likewise.   \n\nWe are moving towards a better understanding of the early cognitive and motivational underpinnings of moral norms, understood as social rules or expectations that all are expected to obey and enforce.  As we noted, there is still much to learn here about both the early state and what is likely to be a very complicated developmental story about maturation and the influence of the child’s social environment. (Bloom and Wynn 2016 provides a useful and philosophically informed summary of the sate of research on which features of our moral cognition are, or are not, part of an early core.)  But there is mounting evidence that from early in their first year infants are social cognizers with (at least) a hold on the moral realm.  It is hard to see any way that all of this can be learned from experience (Hamlin 2015). \n\nOur understanding of goal-directed behavior is characterized by a\nprinciple of rationality; that is, that all things being equal, agents\ntake the easiest, most direct, and most efficient means available to\nachieve their goal. In a series of studies, Csibra, Gergely and\ntheir colleagues provide evidence that infants use this principle\n(Csibra et al. 1999 and 2003). In Csibra et al. 2003,\n12-month-old babies were habituated to a ball rolling along a path,\napparently jumping while its path is hidden by a screen, and then\ncontinuing rolling along its path once it has emerged from behind the\nscreen. In the test trials, the screen was removed and babies\nwere shown one of two displays: one with an obstacle on the path, one\nwith no obstacle. Longer looking times at the display with no\nobstacle indicate that jumping for no apparent reason is unexpected for\nthe infant. In contrast, when there is an obstacle on the path,\njumping over it is a direct and efficient means to achieving\none’s goal and is therefore not a violation of expectation. \n\nAnother study by Gergely and his colleagues (2002) followed up on a\nfinding of Meltzoff (1988) showing that 14-month-olds imitate the means\nan agent employs to attain a goal, even if those means are not the most\ndirect or efficient. Meltzoff showed infants that tapping a panel\nlight with his head made it light up. When babies returned to the\nlab the following week, they too used their heads to turn on the light,\nrather than simply pressing it with their hands. Gergely\nsuggested that this seeming violation of rationality was not in fact\nirrational. He suggested that the baby might reason that\nif the light could be turned on with one’s hand, the\nadult they were imitating would have used his hand. The fact that\nthe adult used his head to turn on the light suggests to the child that\nthis must be a necessary means to achieve the goal. To test this\nhypothesis, the researchers added a condition in which the adult actor\ncould not use his hands because they were otherwise engaged: the actor\npretended to be very cold and used his hands to hold a blanket wrapped\naround him. With hands thus busy, the adult actor used his head\nto tap the panel light. They then compared the babies’\nresponses to the panel light in this hands-busy condition with the\nresponses in the original Meltzoff condition where the actor’s\nhands were simply resting on the table. In the original Meltzoff\ncondition, babies used their heads to turn on the light, but in the\nactor’s-hands-busy condition, the babies did not imitate the\nactor but instead used their hands. This supports the view that\nthese babies already are acting on the basis of some principle\nconnecting efficiency and goal-directedness, and that this principle is\nstronger than their tendency to imitate. \n\nLet us return to the False Belief Task. It was noted earlier\nthat children younger than 3-1/2 do not succeed in the classic\nparadigm. But in a recent study, Onishi and Baillargeon (2005)\nshowed that infants as young as 13- to 15-months could succeed on a\nfalse belief task. In this study, babies were familiarized to a\ndisplay of an adult placing a toy (a plastic watermelon slice) into one\nof two boxes and then reaching into the box as if to grasp it.\nThe point of these familiarization trials was to indicate to the baby\nthat reaching the toy was the adult’s goal. The toy was\nthen moved from the box in which the adult had placed it to the other\nbox. Although the baby always saw the toy move, and thus\nunderstood its new location, the adult did not always see the toy move;\nhalf the time, the adult’s view was blocked. The question is this: on the\ntrials where the adult did not see the toy move to the new\nbox—that is, when the adult had a false belief about the\ntoy’s location—where do babies expect the adult to look for\nthe toy? Looking time measures indicated that babies were\nsurprised when the adult looked in the new box, even though babies knew\nit was the correct location. In contrast, on the trials in which\nadults saw the toy move to the new box, babies were surprised if adults\ndid not look in the new location. At present there is no\nsatisfactory account of why 3-year-olds fail the standard false belief\ntask, given that 15-month-old babies seem to be able to attribute false beliefs to\nothers. What else does the 3-year-old need, beyond what the\n15-month-old already has, to succeed on the classic task? There\nare many candidate answers, but the Onishi and Baillargeon results have\nconsiderably changed the debate. \n\nAs noted above, questions about the development of a theory of mind\nwere first posed with respect to chimpanzees, and it is to chimpanzees\n(and other nonhuman primates) that we now return. Until recently,\nmost researchers agreed that there was little evidence to support the\nclaim that nonhuman primates represented agency, goals, attention or\nthe like (Povinelli 2000; Tomasello & Call 1997).\nHowever, chimpanzees, macaques, and other primates do follow eye\ngaze. Researchers have probed whether they appreciate the\nrelationship between the direction of gaze and attention, or\nbetween seeing something and acquiring\ninformation. A number of recent studies have shown that\nchimps prefer to steal food from a person (or, in some conditions, a\nmore dominant chimp) who cannot see them as opposed to a person (or\nmore dominant chimp) who can (see Flombaum & Santos 2005; Hare\net al. 2000; and Carey 2009 for review). If dedicated\nmechanisms to identify agents and to support our reasoning about them\nis part of our evolutionary heritage, as seems increasingly plausible,\nit should not surprise us to find them in some of our distant\nrelatives—and in the very young. \n\nOnce again, the studies of newborn chicks are particularly\nilluminating. Regolin and colleagues (2000) habituated newborn\nchicks to a video display involving 2 balls, one red and one\nblue. At first the balls are presented as static. The red\nball then moves, bumps into the blue ball, and then the blue ball\nmoves. After habituation the chicks were presented with a fuzzy\noval-shaped red ball and a fuzzy oval-shaped blue ball. The\nchicks imprinted to the red ball, not the blue one. It seems that\nthey are sensitive to agency—that they see the red ball\nas an agent, while the blue ball may be a passive object. To make\nsure it was the red ball’s autonomous movement that was critical,\nexperimenters partly occluded the red ball as it began its movement so\nthat it wasn’t clear whether the movement was autonomous or set\nin motion by someone or something else. In this condition, the\nimprinting preference for the red ball disappeared. These chicks\nwere newly hatched, so an explanation for these data that appeals to\nlearning from sensory experience is unavailable. Once again, the\nchick studies provide an existence proof of an innately specified\ndetection mechanism closely related to agency. Note that the\nquestion of what precisely the chick is detecting or representing is\nstill open—is it autonomous motion or agency or some other\nproperty. \n\nThe studies summarized in section 2 are representative of the\nNativist resurgence. Not surprisingly, cognitive scientists with\nEmpiricist sympathies continue to push back: to search for\ncountervailing evidence, to question the methodologies involved in\nthese studies, to develop alternative interpretations of the data, and\nso on. Moreover, as we mentioned at the outset, it is not only\nNativism that has experienced a resurgence; there are important\nresearch directions in the cognitive sciences that seem inherently more\nfriendly to the Empiricist position. In this section we briefly\ndescribe and contextualize some of these developments. \n\nOne important trend has been the development of Connectionism as an\nalternative to the ‘Classical’ conception of the mind\n(Newell & Simon 1976; see Garson 2010 for an overview).\nOn the Classical view, the cognitive mind is best understood on\nthe model of a digital computer that (i) uses symbolic representations\nthat have a combinatorial syntax and semantics, and (ii) manipulates\nthese representations following structure-sensitive processing rules.\nConnectionists replace the Classical view with a model of\npsychological processes as involving networks of simple units with\nweighted connections among the units that control the spread of\nactivation through the network, and ‘learning’ algorithms\nfor resetting the weights of the connections on the basis of earlier\nbehavior of the network in response to some task. There is\ncontinuing debate about whether the Classical and Connectionist models\nare really incompatible, and some have argued that Connectionist\nsystems are best viewed as implementations of classical symbol-based\nsystems (see Pinker & Prince 1988 for discussion). But\nthe research on psychological processing within the Connectionist\nframework is very different from what one finds in the Classical\ntradition. \n\nConnectionism is relevant to the Nativism-Empiricism in two related\nways. In the first place, Connectionism provides a natural format\nfor the Empiricist idea that perception provides the basic elements of\nthe mental system (ideas/network-nodes) and experienced regularities\namong ideas strengthens their connection (associations/weightings) and\nin this way accounts for learning. But a more important idea is\nthat if Connectionism could be established as a real\nalternative to the Classical symbol manipulation approach (and\nnot simply as providing implementations of Classical systems), it could\nhelp undercut a key argument of Chomsky-style Nativism. Here is a\nsimplified version of the target\n argument.[26]\nChomskyans, as we noted (section 1.1.2),\nargued that grammars—and by extension, the rules governing other\ndomains of knowledge—are ‘psychologically\nreal’. If they are, and the Classical view is correct, then\nit would seem that such rules are present in the mind as symbolic\nconstructions. But these rules, as linguistic grammars make\nplain, involve abstract concepts that are not perceptually available in\nthe data. So if the rules are symbolically represented, then\nthese abstract concepts, which are the constituent elements of the\nrules, are also internally represented. But if the relevant\nconcepts are not perceptually available, how could they be learned by\nEmpiricist-style mechanisms that only track regularities in the stream\nof experience? This sort of Nativist argument was developed in\nFodor 1981. Connectionism rejects the view of mental\nrepresentation on which this argument depends. For the\nConnectionist, information is not in the mind as the semantics of\nmental symbols; as the meanings of terms in the language of\nthought. For the Connectionist, information is distributed as a\npattern of weightings in a network in which none of the nodes\nrepresents anything. So: if this sort of anti-Classical\nConnectionist approach is successful, this particular version of the\nPoverty of the Stimulus argument for Nativism is blocked.  \n\nThere is continuing controversy about whether Connectionism has\nin-principle limitations that disqualify it as a general model of\ncognitive processing (see Fodor & Pylyshyn 1988 and the\nliterature this critique spawned, which is reviewed in Garson\n2010). But there is a practical problem that is less\ncontroversial, and to understand it, we need to consider more closely\nhow Connectionist nets learn. Imagine that one wants the net to\nlearn the difference between (photos of) male and female faces. A\nset of input nodes will code the photo, activation will pass through a\nset of intermediate nodes, and an answer will appear on the output\nnodes. If the output on a particular input is incorrect (a male\nis misidentified as a female for example), the algorithm that governs\nthe dynamics of the network automatically adjusts the weights of the\nconnections between the various intermediate-layer nodes ‘in the right\ndirection’ and more inputs are cycled through the system.\nWhen the output is correct over some range of inputs, the net has been\n‘trained up’; it has successfully learned to tell male from\nfemale faces in photos. The art in Connectionist modeling is to\ndiscover the best network structure and the right algorithm for\nadjusting the weightings. The problem is that such networks learn\nvery slowly; they often need hundreds of thousands of cycles of inputs,\noutputs, and weight adjustments. But humans and animals learn\nmany things very quickly, sometimes even from one instance and often\nfrom a small set of instances (Garcia et al. 1955; Markman 1989). \n\nOne way to approach this discrepancy is to see it as due to the fact\nthat in the typical Connectionist set up, the weights between nodes are\ninitially set to random values, and are (very) slowly reset on the\nbasis of small adjustments. But the fact that the initial\nweightings provide no prior information is arguably an artifact of the\nmodeler’s Empiricist commitment to have all the learning\n‘come from experience’. There is nothing in the\ngeneral structure of Connectionist models that would prevent the\nmodeler from starting with a highly constrained set of\nweightings—in this case one that already holistically contains\ninformation of the general features of human faces, and perhaps\ninformation about differences between male and female faces. The\nupshot, then, is that although most actual Connectionist models are\nEmpiricist-friendly in their format and in their representational\ncommitments, they can also be implemented in a way that is congenial to\nNativist ideas. The prior information that the Nativist claims is\npart of the initial state of the organism can be realized by setting\nthe initial patterns of weightings between the nodes in the network in\nsuch a way that learning will happen much more quickly. So while\nConnectionism may avoid the very general commitment to Nativism that\nsome have argued is built into the Classical conception, it is neutral\non the question of whether learning in a particular domain is wholly\nbased on experience or uses innate information (suitably distributed\nacross networks). \n\nThis last point applies to Dynamic Systems Theory approaches to\ncognition as well (Thelen & Smith 1994; Port & van\nGelder 1995). Dynamicists hold that human behavior should be\nexplained in terms of sets of differential equations that represent a\nsubject’s trajectory in real time through a space of possible\ntotal cognitive-behavioral states. Because they, like\nanti-Classical Connectionists, reject the Classical paradigm’s\ncommitment to symbol manipulation and computation, they also avoid the\nNativist consequences of that view. But neither Connectionists\nnor Dynamicists are in principle anti-Nativist. However\nwe model an organisms cognitive processes—as executing a\nClassical Von Neumann style program, as reassigning weights to nodes in\nline with a Connectionist back-propagation algorithm, or as moving\nthrough a Dynamicist state space as described by a set of differential\nequations—the question remains: what are the built in initial\nbiases of the system and what role do they play in determining the\nsteady state. One can construct a Connectionist system that is\nantecedently tuned to converge on a specific steady-state, and as such\nwill have a significant Nativist element (Hummel & Biederman\n1992 presents such a system for shape recognition). The same\nseems true of Dynamic Systems models. The oft-used Dynamicist\nexample of a pendulum is ‘innately specified’ to reach a\nspecific steady state (its point attractor) despite wide\nvariability in its inputs. If very young children do indeed\ndistinguish helpers from hinderers, for example, then this capacity\nwill need to figure in the Dynamicist model. It will be\nappropriate to then ask about the role that the child’s initial\nstructure or configuration played in its coming to have this\ncapacity. \n\nEven at the height of Chomsky’s influence, it was clear that\nthe strength of the Nativist position rested, to a great extent, on the\nweakness of the Empiricist alternative. The central argument from\nthe Poverty of the Stimulus was that Empiricism had failed to make\nits case, and that the Nativist hypothesis was therefore more\nplausible. But it was implicit in this dialectic that if\na more powerful Empiricist learning theory were developed, it could\nchange the terms of the debate. Furthermore, Empiricists argued\nthat there had to be a stronger general learning theory\nbecause learning theory as developed up until that time did not have\nthe resources to account for much learning that was plainly\nbased on experience (Harman 1967; Putnam 1967). Some would argue that these Empiricist\nhopes for a more powerful learning theory have been realized. Learning theory has advanced\nsignificantly, especially in the last decade, and Empiricism can now\ndraw upon new resources; specifically, learning algorithms based on\nBayes’ Theorem. The power of Bayesianism raises the\npossibility that the earlier Poverty of the Stimulus arguments\nunderestimated what could be learned from experience by general\nlearning mechanisms. \n\n‘Bayesianism’ is a general term for a range of\nsophisticated statistical methods, algorithms, and tools that draw upon Bayes’\nTheorem/Rule, which tells us how to revise our beliefs given new\ninformation; that is, how to choose the best of a set of alternative\nhypotheses given new data. The calculation requires (i) the prior\nprobability of the data, (ii) the probability of the data given the\nhypothesis, and (iii) the prior probability of the\n hypothesis.[27] \n\nThe relevance of Bayes’ Theorem to Cognitive\nScience. Bayesianism is in its origins a normative theory of\nwhat one ought to believe under specific epistemic\ncircumstances, and as such it has been applied extensively in\nunderstanding theory confirmation in the sciences. It first came\nto the fore in the cognitive sciences as an ideal against which one\ncould measure human irrationality. Kahneman and Tversky\n(1972) famously showed that ordinary reasoners typically fall short of\nBayesian standards when they are asked to decide the bearing of\nevidence on hypotheses, in part because they misjudge the relevance of\nthe prior probability of the hypotheses. But in recent years, Bayesian methodologies have become a unifying framework for analyzing all aspects of cognition that can be represented as inference under uncertainty.  For example, \nBayesian ideas have been successfully applied to the processing\nunderlying perception—especially the visual system (Knill\n& Richards 1996; Rao et al. 2002). In visual perception,\na pattern of light hits the eye (the proximal stimulus), and the visual\nsystem needs to determine the nature of the visual scene in the\nenvironment (the distal stimulus) that caused that pattern. The\nproximal stimulus is compatible with a number of different distal\nstimuli. So the system faces something like the\nunder-determination problem that a scientist faces. Both must\nselect one view about what the world is like on the basis of\ninformation that still leaves other possibilities open. It turns\nout that Bayesian methods have been very successful at modeling how the\nvisual system resolves these uncertainties. \n\nThe visual system gets an image on the retina (D), and must\ndetermine what the real-world scene is like (H). The\nimage is compatible with many different possible scenes, but the visual\nsystem is very good at overcoming this uncertainty and reliably settles\non the most likely scene. In Bayesian terms, the visual system\nmust do this calculation: \n\nConsider this (again simplified) example, drawn from Scholl\n2005. In Figure 1, the circles are ambiguous; they can be either\nconvex bumps or concave depressions. Viewers normally see (a) as\nconvex and (b) as concave, (but if the display is turned upside down, the\nproperties are reversed). Figure 1 \n\nThe fact that we see these as we do can be explained in Bayesian\nterms. To figure out the most likely scene/source of (a), the visual\nsystem must assign a probability to the hypotheses \\(H_2\\) (that the circle\nin a is convex) and to \\(H_2\\) (that it is concave). One key assumption\nthe visual system makes is that the scene in both (a) and (b) is\nilluminated by a single light source coming from overhead. So if\nthe bottom of the circle is in shadow, we tend to see it as convex; if\nthe top, we tend to see it as concave. When we look at\n(a), this assumption about the light source translates into the\nprior probability of \\(H_1\\) being higher than the prior probability of\n\\(H_2\\). So the priors in this case give us an antecedent ordering of\nthe hypothesis space (here we ignore other hypotheses that could\naccount for the image), and the visual system settles on (a) as\nconvex. \n\nBayesian approaches are appealing because they provide a natural way\nto solve the problem that troubles theories, like Connectionism, that\nare built on associationist lines. Associationist learning is\nbottom-up. It depends on keeping track of correlations in the\nstream of experience and slowly modulating expectations on the basis of\nthese correlations. But as we noted earlier, humans and animals\nlearn about the world very quickly, and on the basis of a very small\nnumber of exposures and interventions. A child hears the word\n‘horse’ applied to a few instances (and probably\nhears stray utterances of the word too) and reliably learns the\nextension of the term (Markman 1989). A rat made sick by a food\none time, will not eat food with that smell again (Garcia et\nal 1955). These ‘fast-mappings’ are a problem\nfor Associationist models. But they are more easily accommodated\nin Bayesian models, which essentially quantify the role of background\nknowledge—the top-down contribution—in the fixation of\nbelief. If the rat already knows, as part of its background\nknowledge—its ‘factory settings’, so to\nspeak—that when it comes to foods, smell is an indicator of\nedibility, then single-case learning is less mysterious. The\nprior probability of hypotheses linking edibility to smell may be\nantecedently set as very high, and hypotheses linking edibility to\norientation may be set as very low. So one association between\nsick-making food \\(f\\) and smell \\(s\\) will be enough for the rat to\n‘adopt the hypothesis’ that \\(f\\) and \\(s\\) are regularly\nlinked. In contrast, if sick-making food \\(f\\) is always in a\nparticular orientation \\(o\\), the rat may have a hard time making the\nconnection even if it may be sensitive to orientations in other\ncontexts. Similarly, if the child comes to the word-learning task\nwith the assumption that new words most likely pick out unfamiliar\nextensions—again, with this assumption implemented in the\npriors—then her job is made easier. Bayes’ Theorem\ngives us a way to factor in this top-down background\n knowledge.[28] \n\nThe key issue in considering the bearing of Bayesianism on the\nNativist-Empiricist controversy is the\n priors.[29]\nWhere do they come from? If we are talking about simple, repeatable events like coin flips, the priors are a\nmatter of well-defined relative frequencies given by probability\ntheory. But the prior in the concave-convex case (which was\nchosen to highlight this point) seems to involve domain-specific facts\nabout light and shadow, and their relation to the shape of objects.\nScholl 2005 argues that the priors here are innate, and many\nscientists studying visual perception would agree. We don’t\nlearn from experience that the objects in our perceptual world\nwill typically have overhead illumination. Rather, this is one of\nthe ‘factory settings’ of the visual system. As\nKersten (2004) puts it (speaking more generally): ‘the priors are\nin the genes’. Ullman (1979) argues that the same may well\nhold for the general constraints relating the rigidity of objects to\nfacts about motion. The view that the illumination constraint is\ninnate is also supported by the fact that chickens reared in an\nabnormal illuminated-from-below environment still react as we do to\nstimuli (a) and (b) (Hershberger 1970). So we have evidence that this\nprior can be innate. \n\nLet us assume that there are significant innate priors that operate\nin perceptual processing. Does this score points for the Nativist\nposition in general? In one way it does, because it is in line\nwith the basic Nativist theme that humans are tailored for their\nnatural environment. But in another sense, the Empiricist might\ndownplay the importance of this kind of Perceptual Nativism for the\nlarger debate. Empiricists have always taken it for granted that\nwe perceive as we do, in large part, because of our\nbiological-psychological nature. The traditional Empiricist focus\nhas usually been on that part of our understanding that goes beyond\nwhat we actually perceive. Its main claim is that anything that\ngoes beyond what we perceive is constructed out of what\nwe’ve perceived by domain-general\nprinciples. So even if (some of) the priors involved in Bayesian\nmodels of perceptual processing are innate, the more critical arena for\nthe Nativist is domain-specific cognitive processing,\nto which we now turn. Nativists would expect that the best\nBayesian models of cognitive processing would have to incorporate\ninnate priors that reflect domain-specific knowledge.\nEmpiricists would expect that domain-specific priors are themselves\nlearnable by Bayesian methods from experience plus domain-general\nconstraints on learning. \n\nWe do not yet know enough to settle these questions, but they are\nnow beginning to be addressed. Most recently, a number of\ntheorists have used Bayesian techniques to model not just low-level\nperceptual processing but also aspects of higher-order cognitive\nprocesses. Areas of current research include concept learning\n(Tenenbaum 1999), word learning (Xu 2007), and causal reasoning\n(Griffiths & Tenenbaum 2005; Griffiths et al. 2011), and the\nlist is\n growing.[30]\nContemporary research on the application of Bayesian techniques\nto higher-level cognition has generally ignored the battle lines of the\nNativist-Empiricist debate. The real interest is in the\npossibility of developing statistical techniques that, as Tenenbaum et al 2006 puts it, “integrate bottom-up and top-down\ninfluences.” (For a very useful state of the art in Statistical learning along with concrete suggestions about deploying top-down information in such models, see Lake et al, forthcoming.)  We already have sophisticated statistical\nanalyses of the bottom-up part; the perceptual phenomena. The\nchallenge is to develop quantitative representations and analyses of\nthe levels of top-down background knowledge that operate in particular\ndomains. In section 2, for instance, we considered as part of the\nchild’s background information his theory of mind.\nIt was on the basis of this theory that the child could develop a\nstructural analysis of a situation in terms of agents, beliefs, goals,\nhelp/hindrance, and so on. But the information contained in such\na theory and the structural analyses of particular situations that this\ntheory makes available, cannot yet be integrated into Bayesian\nstatistical analyses. The challenge for Bayesians is to develop\nways to recast the top-down elements and the analyses they make\navailable in quantitative terms. Only then will we be in a position to address\nwhether and to what extent top-down information is learned or\ninnate. \n\nWe can use the case of language understanding, a well-studied area\nand arguably a Nativist stronghold, to illustrate how these Bayesian\ngoals might be achieved. The phenomenon is familiar: you hear a\nsentence \\(S_1\\) as having a specific meaning. The theoretical\napproach mirrors the vision case: \\(S_1\\) (as auditorily processed) is\ncompatible with a number of competing structural representations, but your parser\nsomehow chooses the best one: \\(\\mathrm{sr}(S_1)'\\). The Bayesian says\nthat the parser is able to do this because it can do a statistical analysis\nthat integrates bottom-up and top-down information. In this case,\nthe bottom-up element is \\(S_1\\). But the range of possible\nstructured representations the parser can select from is top-down\ninformation, as is the algorithm that chooses \\(\\mathrm{sr}(S_1)'\\)\nover other candidates. The problem: how to assign a prior\nprobability to a complex structured representation like \\(\\mathrm{sr}(S_1)'\\)\n(for instance, a syntactic tree)—a probability that depends on the probability\nassigned to the sub-elements. We know how to assign the prior\nprobability of a series of heads for a fair coin. But the question comes up again: how do we\nassign a prior probability to a linguistic representation, or to a\ncomplex visual scene, or to a complicated representation of the goals,\nroles, and perceptual beliefs of a player in one of the Theory of Mind\nscenarios? The events are more complex, the\nrepresentations of the events are therefore more complex, and the\nhypothesis space is more complex (Chater et al. 2006). \n\nIn the language case, the Bayesian can hope to draw on a good deal\nof what contemporary linguists have already achieved in understanding\nthe structures underlying sentence comprehension, and some\ncomputational linguists are beginning to merge such analyses with\nprobability theory (for instance, Chater & Manning 2006).\nBut even here, the problem of finding the best structure to assign to\nan input is daunting. As Chater et al. 2006 puts it: \n“More challenging is inferring representational structures over\nwhich parameters are optimized. One problem is that the space of\npossible structures is often large and discontinuous; a second is that\na direct application of probabilistic methods would involve assessing\neach structure by integrating a prior over its parameters, which seems\ncomputationally prohibitive; a third is that structures appear to be\nconstrained in potentially highly abstract ways.” \n \nIn the case of theory of mind, on the other hand, we don’t yet have\ndeveloped theories about the relevant structures (but see the related\nwork on causality collected in Gopnik & Schulz 2007). So it is\nonly if Bayesians can get a handle on these representational and\nstatistical problems, that they will be able to attack our\nquestion: how is the space of such structures generated in the first\nplace? Is there innate domain-specific information at work or is there\na Bayesian hierarchy, a two-level-up Bayesian account that explains\nhow this one-level-up information is acquired (that is, a Bayesian\nlearning-theoretic account that explains why the child represents\nlinguistic input, for example, using tree structures, but integers in\nterms of a very different linear structure; for further discussion see\nTenenbaum et al. 2011). \n\nSo, for example, children might know that animals are arranged in a\ntaxonomy of a specific sort, and this prior background knowledge helps\nthem learn about animals. But how do they get this prior? It might be\nthat they have a prior higher-order principle \\(P\\) that provides a\nprobabilistic ordering on different graph structures, and that the\ntaxonomy they use has a higher prior probability than other ways to\nstructure the animal world (say, a ring structure). But how do they\nget \\(P\\)? Do they learn it or is it simply there innately? To tackle\nthese questions, all sorts of objects—structured representations\none finds in a grammar, graph-structures one might find in a taxonomic\nrepresentation of causal or kin relations, schemas applied to scene or\nevent analysis, etc.—will need to be formalized and assigned\nprobabilities. So there is much to be done. There is no a priori\nanswer about how far up the Bayesian can go, and we do well to keep an\nopen mind about the nature of the unlearned priors. But we should also\nnot overlook findings like the chick’s stubborn presumption of\nillumination from above, which suggest that nature can build\nin unlearned priors, and that they can be domain specific. It would\nbe, at the very least, extremely surprising if nothing like this\noperates in human psychology. \n\nBayesianism, then, focuses the Nativist-Empiricist question on the\npriors. First, we need to find out where the background\nknowledge brought to bear in any particular task comes from. Is\nsome part of it innate, or can its presence be accounted for in terms\nof higher-order Bayesian learning? At some point, the Bayesian\nwill come up against what is not learned by Bayesian methods (at the\nvery least, the Bayesian machinery\n itself[31]),\nand we will want to understand its specific\ncharacter. Will it be information implemented in our perceptual\nsystems or domain-general information that applies no matter what is\nbeing learned, supporting the Empiricist view, or will some of it be\ntailored to specific ranges and domains of knowledge, vindicating the\nNativist? We are still at the beginning of the road to the\nanswers to these questions. \n\nIt is important not to underestimate the challenge that Empiricists face.  The Bayesian formalism might make it seem that all that needs to be explained is why the hypotheses compatible with the data are ordered in the way they are.  So, for example, if it could be shown that the bias for a light from above explanation of the retinal image (in section 3.2) could, in principle, have been learned from experience, then it might appear that the Empiricist wins the round.  It is plausible that some of the priors relevant to scene recognition will be learnable in this way, so this may be right as far as it goes.  But it does not get to the heart of the challenge. \n\nOnce we shift our attention away from the Bayesian formalism and focus\non the fact that we are looking for an account of the\ncognitive/computational machinery that processes inputs and generates\ncomplex structural analyses of the world—think here of the\nsubsystem that generates theory of mind representations of interacting\nagents in terms of goals, rationality, cooperation, desert, and so\non—then it becomes clearer that the burden on the Empiricist is\nmuch greater.  She must not only explain where the representation\ntypes come from, she must also account for the cognitive\nprocessing over these representation types. So even if there were a\nsatisfactory Empiricist account of how the infant sorts inputs into\nthe categories agent, hinderer, and so on, we still need a separate\naccount of where the cognitive machinery that operates over these\ntypes comes from.  Without that, the infant will have a static\ntypology with no way to anticipate the dynamics of the situation.\nHere, then, the Empiricist seems to have two choices.  She must make\nthe case that the machinery involved is either (i) generic and\ndomain-independent, or (ii) domain-specific, but itself the product of\nhigher-order learning. The point is that the Empiricist must account for the repertoire of\nrepresentation types that figure in the processing and for\nthe machinery that does the processing.  The ultimate outcome of this\ndebate will depend in part on how distinctive and complex the\ncomputational machinery turns out to be.  If the engine for theory of\nmind dynamics only needs to do tree search or production rule\napplication (for example), then the case for Empiricism is\nstrengthened, because these are very general computational capacities.\nOnly the content of the specific rules or the content at the nodes\nwill be domain-specific.  But the more idiosyncratic the computational\nmachinery in a specific subsystem—for example, a simulator that\nanticipated motions and locations in a dynamic physical\nscene—the greater the challenge for the Empiricist to explain\nhow such an internal computational device is acquired from experience\nalone.\n As we noted, although Bayesianism has had a special appeal for Empiricists, one can use Bayesian methodologies and remain open to Nativist possibilities.  There is nothing to prevent a Bayesian from starting with an innate system of representations and computational machinery and then using Bayesian algorithms to figure out how learning from experience might work for such a system.  This approach is very much in line with the Core Nativist theorizing discussed in section 2.  (For a detailed defense of this methodology, see Lake et. al. forthcoming). \n\nIn summary, then, Bayesianism appeals to Empiricists for at least two\nimportant reasons. First, because it reinstates\nlearning from experience as a central process in cognitive\ndevelopment and change. This focus on learning contrasts sharply with\nthe first wave of Nativist cognitive research, which, inspired by\nChomsky’s work in linguistics, tended to assign a diminished\nrole to learning from experience. Experience was thought to act as a\ntrigger/releaser of innate information, or, as in some linguistic\ntheorizing, as setting values to parameters that were left unspecified\nby our innate endowment. The lead role, again following Chomsky, was\nassigned to growth, understood simply as biological maturation. The\nsecond reason is that the current Bayesian mindset tends in\nsome ways towards Empiricism.  This is primarily because Bayesian\nlearning can, at least in principle, be extended hierarchically, in\nthe ways we’ve discussed. But Bayesianism also has some appeal\nto Nativists, because it focuses attention on the role of background\nknowledge in learning, and this is a theme that Nativists have pressed\nagainst bottom-up Associationist forms of Empiricism from the\noutset. Nativists can welcome a renewed focus on learning, and join in\nthe development of Bayesian theories of cognitive development. So in\nthe end, Bayesianism—as an approach to cognitive\ndevelopment—is, like Connectionism, compatible with\nNativism. (For recent discussion of this last point, see Colombo 2017;\nfor a more pessimistic assessment of the potential contribution of\nBayesian approaches to psychology see Jones and Love 2011.) \n\nNativism, as we have seen, is a vigorous program in contemporary cognitive science.  But there is very little talk of Rationalism.   The term is sometimes repurposed as another name for Nativism, and in some cases it is explicitly disowned, with Nativism taken to be the only plank in the original Rationalist platform worth saving.  But following up on our previous discussion, there is a case to be made that this common attitude misses an important and distinctly Rationalist feature of current Core Nativist research.  Here we briefly sketch the key ideas behind this claim. \n\nThe Classical Nativist-Empiricist debate is an expression of a\ndisagreement about a bigger question: what is the (cognitive)\nmind and what is it for?  For the Empiricist (Hume 1975/1738\nbeing an especially clear example), the mind is first and foremost\na pattern detector, and it is for prediction.  For\nthe Humean, all we have to work with is one experience and then\nanother.  Cognitive processing is at bottom experience mining:\ndeploying our domain general cognitive machinery like statistical\nlearning routines, memory retrieval, attentional mechanisms,\nassociative connectivity, and so on, to detect patterns in the\nsequences of traces (Hume’s ideas) that experience\nleaves behind in memory. \n\nFor the Rationalist, mind is for understanding.\nUnderstanding is of course connected to pattern detection and\nprediction, but it also involves making sense of the patterns\nat some deeper level.  The Classical Rationalist view is that Reason\n(with a capital ‘R’), in part embodied in our innate endowment,\nsomehow makes this sort of deeper understanding possible.  Descartes’\nfamous wax example (Descartes 1996/1641) is aimed at making clear the\ndifference between detecting patterns in the flow of perceptual ideas\nthat are prompted by a piece of wax and having a real understanding of\nwhat a piece of wax is.  The Humean Empiricist rejects this search for\ndepth as illusory; pattern detection is all understanding is or can\nbe. \n\nOur point is that the Core Cognition approach retains this\ndistinctively Rationalist emphasis on understanding.  Core\nsystems like our intuitive physics and theory of mind help us\nconstruct models of the world based on innate abstract\nframeworks.  By deploying these theories we can go beyond the input\npatterns and come to understand not just how things look, but\nalso what they are, why they are as they are, why\nthey change in the ways they do, how things might be\nif relevant parameters were different, and so on.  When the baby sees\ntriangles pushing a square up a hill, she constructs a rich\nconceptualization of the scene that breaks things up into different\nkinds of elements, and assigns properties to the elements; properties\ninvolving agency, physical object, goals, private intentions,\ninformation states, rationality, number, shape, etc..  She can use\nthis conceptualization—her intuitive theory—to understand\nthe dynamics of what she sees and in that way make sense of\nthe situation. \n\nDespite this commonality, Core Nativists are not one with Classical\nRationalists.  Descartes took our innate Rational notion of the\nphysical to be at the heart of the true physics.  Newton showed that\nthis was wrong, and that we needed to go beyond our intuitive physics\nif we wanted to get a deeper understanding of the world.  Core\nKnowledge theorists reject the Classical assumption that our innate\nsense-making frameworks are necessarily true.  But true or\nnot, what is innate provides a framework that we use to make\nsense of the world.  To this extent, the Core Knowledge program\nrevitalizes this key Rationalist idea.  It remains an open question\nhow we are to understand this notion of (deep) understanding.  This\nsearch goes back at least as far as Plato.  But our point here has not\nbeen to defend the revival of this Rationalist theme; only to note the\ncommonality. \n\nIn conclusion, the studies that we surveyed\nin section 2 provide compelling evidence that\nwe have been underestimating how much infants and young children\nunderstand about the world. At the same time, it is clear that adult\ncompetence goes far beyond the child’s in virtually every\ndomain. The Bayesian framework we discussed\nin section 3 has the potential to address both\nissues at once. It provides a systematic and quantifiable approach to\ndevelopment, and is at the same time open to incorporating innate\nelements. Whether it will succeed in unifying a learning-theoretic\napproach to cognitive development with the built-in representations\nfavored by Nativists remains to be seen.","contact.mail":"dzaitchiksamet@partners.org","contact.domain":"partners.org"}]
