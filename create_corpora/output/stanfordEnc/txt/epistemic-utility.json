[{"date.published":"2011-09-23","date.changed":"2019-11-06","url":"https://plato.stanford.edu/entries/epistemic-utility/","author1":"Richard Pettigrew","author1.info":"http://eis.bris.ac.uk/~rp3959/","entry":"epistemic-utility","body.text":"\n\n\nOur beliefs come in degrees; we believe some things more strongly than\nothers. For instance, I believe that the sun will rise tomorrow very\nslightly more strongly than I believe that it will rise every morning\nfor the coming week; and I believe both of these propositions much\nmore strongly than I believe that there will be an earthquake tomorrow\nin Bristol. We call the strength or the degree of our belief in a\nproposition our credence in that proposition. Suppose I know\nthat a die is to be rolled, and I believe that it will land on six\nmore strongly than I believe that it will land on an even number. In\nthis case, we would say that there is something wrong with my\ncredences, for if it lands on six, it lands on an even number, and I\nought not to believe a proposition more strongly than I believe a\nlogical consequence of it. This follows from a popular doctrine in the\nepistemology of credences called Probabilism, which\nsays that our credences at a given time ought to satisfy the axioms of\nthe probability calculus (given in detail below). Since this says\nsomething about how our credences ought to be rather than how\nthey in fact are, we call this an epistemic norm.\n\n\nIn this entry, we explore a particular strategy that we might deploy\nwhen we wish to establish an epistemic norm such as\nProbabilism. It is called epistemic utility\ntheory or accuracy-first epistemology, or sometimes\ncognitive or epistemic decision theory. In this\nentry, we will use the former. Epistemic utility theory is inspired by\ntraditional utility theory, so let’s begin with a quick summary\nof that.\n\n\nTraditional utility theory (also known as decision theory, see entry\non\n normative theories of rational choice: expected utility)\n explores a particular strategy for establishing the norms that govern\nwhich actions it is rational for us to perform in a given situation.\nGiven a particular situation, the framework for the theory includes\nstates of the world that are relevant to the situation,\nactions that are available to the agent in the situation, and\nthe agent’s utility function, which takes a state of\nthe world and an action and returns a measure of the extent to which\nshe values the outcome of performing that action at that world. We\ncall this measure the utility of the outcome at the world.\nFor example, there might be just two relevant states of the world: one\nin which it rains and one in which it does not. And there might be\njust two relevant actions from which to choose: take an umbrella when\nyou leave the house or don’t. Then your utility function will\nmeasure how much you value the outcomes of each action at each state\nof the world: that is, it will give the value of being in the rain\nwithout an umbrella, being in the rain with an umbrella, being with an\numbrella when there is no rain, and being without an umbrella when\nthere is no rain. With this framework in hand, we can state certain\nvery general norms of action in terms of it. For instance, we might\nsay that an agent ought not to perform an action if there is some\nother action that has greater utility than it at every possible state\nof the world. This norm is called Naive Dominance. We\nwill have a lot to say about it in\n section 5.1\n below.\n\n\nIn epistemic utility theory, the states of the world remain the same,\nbut the possible actions an agent might perform are replaced by the\npossible epistemic states she might adopt, and the utility\nfunction is replaced, for each agent, by an epistemic utility\nfunction, which takes a state of the world and a possible\nepistemic state and returns a measure of the purely epistemic value\nthat the agent attaches to being in that epistemic state at that state\nof the world. So, in epistemic utility theory, we appeal to epistemic\nutility to ask which of a range of possible epistemic states it is\nrational to adopt, just as in traditional utility theory we appeal to\nnon-epistemic, pragmatic utility to ask which of a range of possible\nactions it is rational to perform. In fact, we will often talk of\nepistemic disutility rather than epistemic utility in this\nentry. But it is easy to translate between them. If \\(\\mathfrak{EU}\\)\nis an epistemic utility function, then \\(-\\mathfrak{EU}\\) is an\nepistemic disutility function, and vice versa.\n\n\nAgain, certain very general norms may be stated, such as the obvious\nanalogue of Naive Dominance from above. Thus, before\nthe die is rolled, we might ask whether I should adopt an epistemic\nstate in which I believe that the die will land on six more strongly\nthan I believe that it will land on an even number. And we might be\nable to show that I shouldn’t because there is some other\nepistemic state I could adopt instead that will have greater epistemic\nutility however the world turns out. In this case, we appeal to the\nepistemic version of Naive Dominance to show that my\ncredences are irrational. This is an example of how epistemic utility\ntheory might come to justify Probabilism. As we will\nsee, arguments just like this have indeed been given. In this entry,\nwe explore these arguments.\n\nIn formal epistemology, epistemic states are modelled in many\ndifferent ways (see entry on\n formal representations of belief).\n Given an epistemic agent and a time \\(t\\), we might model her\nepistemic state at \\(t\\) using any of the following: \nEpistemic utility theory may be applied to any one of these ways of\nmodelling epistemic states. Whichever we choose, we define an\nepistemic disutility function to be a function that takes an epistemic\nstate modelled in this way, together with a state of the world, to a\nnon-negative real number or the number \\(\\infty\\), and we take this\nnumber to measure the epistemic disutility of having that epistemic\nstate at that world. \nThe vast majority of work carried out so far in epistemic utility\ntheory has taken an agent’s epistemic state at time \\(t\\) to be\nmodelled by her credence function at \\(t\\). And, in any case, the\nepistemic norm of Probabilism that interests us here\ngoverns agents modelled in this way. Thus, we focus on this case. In\n section 7,\n we will consider how the argument strategy employed here to justify\nProbabilism for agents with precise credences might\nbe employed to establish other norms either for agents also\nrepresented as having precise credences or for agents represented in\nother ways. \nSo, henceforth, we model an agent’s epistemic state at \\(t\\) by\nher credence function at \\(t\\). We now make more precise what this\nmeans. We assume that the set of propositions about which an agent has\nan opinion is finite and forms an algebra \\(\\mathcal{F}\\). That\nis: \nWe then assume that our agent’s credence in a proposition in\n\\(\\mathcal{F}\\) can be measured by a real number between 0 and 1\ninclusive, where 0 represents minimal credence, and 1 represents\nmaximal credence. Then her credence function at \\(t\\) is a function\nc from \\(\\mathcal{F}\\) to the closed unit interval \\([0,\n1]\\). If \\(A\\) is in \\(\\mathcal{F}\\), then \\(c(A)\\) is our\nagent’s credence in \\(A\\) at \\(t\\). Throughout, we denote by\n\\(\\mathcal{C_F}\\) the set of possible credence functions defined on\n\\(\\mathcal{F}\\). There is no principled reason for restricting to the\ncase in which \\(\\mathcal{F}\\) is finite. We do it here only because\nthe majority of work on this problem has been carried out under this\nassumption. It is an interesting question how the results here might\nbe extended to the case in which \\(\\mathcal{F}\\) is infinite, but we\nwill not explore it here (again, see\n section 7). \nSo, an epistemic utility function for credences takes a credence\nfunction, together with a way the world might be, and returns a\nmeasure of the epistemic utility of having that credence function if\nthe world were that way. \nIn epistemic utility theory, we attempt to justify an epistemic norm\nN using the following two ingredients: \nTypically, the inference from Q and\nE to N appeals to a mathematical\ntheorem, which shows that, applied to any epistemic utility function\nthat satisfies the conditions E, the norm\nQ entails the norm N. \nGiven that the existing arguments of epistemic utility theory share\nthis common form, we might organize these arguments by the norms they\nattempt to justify, or by the norms of standard utility theory they\nemploy, or by the set of constraints on epistemic utility functions\nthey impose. We will take the latter course in this survey. \nIn sections\n 4\n and\n 5,\n we identify a specific epistemic goal and treat epistemic\ndisutility functions as measures of the distance of an\nepistemic state from that goal in a given situation; we lay down\nconditions that it is claimed all such measures must satisfy. In\n section 6,\n we take an alternative route: we lay down putative general conditions\non any epistemic disutility function, which it is claimed\nsuch a function must satisfy regardless of whether or not it is a\nmeasure of distance from a specified epistemic goal. In the next\nsection, we state Probabilism precisely, so that we\ncan refer back to it later. \nProbabilism is often said to be a coherence\nconstraint on credence functions, which would mean that it governs how\nan agent’s credences in some propositions should relate to her\ncredences in other, related propositions. It is often likened to the\nconsistency constraint on sets of full beliefs. In fact, this\nisn’t quite right. Condition (ii) below is certainly a coherence\nconstraint, but condition (i) is not. \nProbabilism A rational agent’s credence\nfunction \\(c\\) at a given time is a probability function. That is: \nNote that any agent who satisfies Probabilism must be\nlogically omniscient: that is, she must be certain of every\ntautology. Some other consequences of\nProbabilism: \nProbabilism is one of a handful of norms that\ncharacterise the Bayesian view in credal epistemology. \nIn this section, we consider the conditions imposed on an epistemic\ndisutility function when we treat it as a measure of the distance of\nan epistemic state from the goal of being actually or\nhypothetically calibrated (van Fraassen 1983; Lange 1999;\nShimony 1988). We say that a credence function is actually calibrated\nat a particular possible world if the credence it assigns to a\nproposition matches the relative frequency with which propositions of\nthat kind are true at that world. Thus, credence 0.2 in proposition\n\\(A\\) is actually calibrated if one-fifth of propositions like \\(A\\)\nare actually true. And we say that a credence function is\nhypothetically calibrated if the credence it assigns to a proposition\nmatches the limiting relative frequency with which propositions of\nthat kind would be true were there more propositions\nof that kind. Thus, credence 0.2 in proposition \\(A\\) is\nhypothetically calibrated if, as we move to worlds with more and more\npropositions like \\(A\\), the proportion of such propositions that are\ntrue approaches one-fifth in the limit. According to the calibration\narguments, matching these relative frequencies or limiting relative\nfrequencies is an epistemic goal. And they attempt to justify\nProbabilism by appealing to this goal and measures of\ndistance from it. \nFirst, we must make precise what we mean by actual and hypothetical\ncalibration; then we can say which functions will count as measuring\ndistance from these putative goals. We treat actual calibration first.\nSince we are talking of relative frequencies, we will need to assign\nto each proposition in \\(\\mathcal{F}\\) its reference class:\nthat is, the set of propositions that are relevantly similar to it.\nThus, we require an equivalence relation \\(\\sim\\) on \\(\\mathcal{F}\\),\nwhere \\(A \\sim B\\) iff \\(A\\) and \\(B\\) are relevantly similar. For\ninstance, if our algebra of propositions contains Heads on first\ntoss of coin, Heads on second toss of coin, and Six\non first roll of die, we might plausibly say that the first two\nare relevantly similar, but neither first nor second is relevantly\nsimilar to the third. Proponents of calibration arguments do not claim\nto give an account of how the equivalence relation is determined. Nor\ndo they claim that there is a single, objectively correct equivalence\nrelation on a given algebra of propositions: this is the notorious\nproblem of the reference class that haunts frequentist\ninterpretations of objective probability. Rather they treat the\nequivalence relation as a component of the agent’s epistemic\nstate, along with her credence function. Indeed, for van Fraassen, it\nis determined entirely by the credence function together with the form\nof the propositions in \\(\\mathcal{F}\\) (van Fraassen 1983: 299).\nHowever, they do impose some rational constraints on \\(\\sim\\) in order\nto establish their conclusion. We will not discuss these conditions in\nany detail. Rather we denote them \\(C(\\sim)\\), and keep in mind that\nthis is a placeholder for a full account of conditions on \\(\\sim\\).\nDetailed accounts of these conditions have been given by van Fraassen\n(1983) and Shimony (1988). We say that a credence function \\(c\\),\ntogether with an equivalence relation \\(\\sim\\), is perfectly\ncalibrated or not relative to a way the world might be. We are now\nready to give our first definitions; but we preface these with an\nexample. \nSuppose a coin is to be flipped 1000 times. And suppose that \\(A\\) is\nthe proposition Heads on toss 1. And suppose that the\npropositions that are relevantly similar to \\(A\\) in algebra\n\\(\\mathcal{F}\\) are: Heads on toss 1, …Heads on\ntoss 1000. Finally, suppose that \\(w\\) is a possible world; a way\nthat the world might be. In fact, throughout this article, we need not\nquantify over genuine possible worlds, which are maximally specific\nways the world might be; we need only quantify over ways the world\nmight be that are specific enough to assign truth values to each of\nthe propositions in the algebra \\(\\mathcal{F}\\). Let’s call\nthese possible worlds relative to \\(\\mathcal{F}\\) and let\n\\(\\mathcal{W_F}\\) be the set of them for a given algebra\n\\(\\mathcal{F}\\). Then the relative frequency of \\(A\\) at\n\\(w\\) (written \\(\\mathrm{Freq}(\\mathcal{F}, A, \\sim, w)\\)) is the\nproportion of the propositions relevantly similar to \\(A\\) that are\ntrue at \\(w\\): that is, the frequency of heads amongst the 1000 coin\ntosses at that world. For instance, if every second toss lands heads\nat \\(w\\), or if the first five hundred land heads and the rest land\ntails at \\(w\\), then \\(\\mathrm{Freq}(\\mathcal{F}, A, \\sim, w) =\n\\frac{1}{2}\\). If every third toss lands heads at \\(w\\), then\n\\(\\mathrm{Freq}(\\mathcal{F}, A, \\sim, w) = \\frac{1}{3}\\). And so\non. \nNow we give the definition in full generality. Suppose \\(\\sim\\) is an\nequivalence relation on \\(\\mathcal{F}\\), and \\(w\\) is a possible world\nrelative to \\(\\mathcal{F}\\). Then: \nThe idea is that, if \\(\\sim\\) satisfies constraints \\(C(\\sim)\\), then\nthe function \\(\\mathrm{Freq}(\\mathcal{F}, \\cdot, \\sim, w)\\) is always\na probability function on \\(\\mathcal{F}\\). \nNext, we treat hypothetical calibration. For this, we need the notion\nof the limiting relative frequency of truths amongst propositions of a\ncertain sort. The idea is that, for each proposition \\(A\\) in\n\\(\\mathcal{F}\\), there is not just a fact of the matter about what the\nfrequency of truths amongst propositions like \\(A\\) actually is; there\nis also a fact of the matter about what the frequency of truths\namongst propositions like \\(A\\) would be if there were more\npropositions like \\(A\\). For instance, there is not just a fact of the\nmatter about how many actual tosses of a given coin will land heads;\nthere is also a fact of the matter about the frequency of heads\namongst hypothetical further tosses of the same coin. In general,\nsuppose we have a possible world \\(w\\), an extension \\(\\mathcal{F}'\\)\nof \\(\\mathcal{F}\\) (containing new propositions like \\(A\\)), and an\nextension \\(\\sim'\\) of \\(\\sim\\) to cover the new propositions in\n\\(\\mathcal{F}'\\). Then there is a single unique number\n\\(\\mathrm{Freq}(\\mathcal{F}', A, \\sim', w)\\) that gives what the\nrelative frequency of truths amongst propositions like \\(A\\) would be\nwere there all the propositions in \\(\\mathcal{F}'\\) and where the\nrelation of similarity amongst them is given by \\(\\sim'\\), where this\ncounterfactual is evaluated at the world \\(w\\). Again, let us\nillustrate this using our example of the coin toss from above. \nSuppose again that \\(A\\) is the proposition Heads on toss 1\nand that the propositions in \\(\\mathcal{F}\\) that are relevantly\nsimilar to \\(A\\) according to \\(\\sim\\) are Heads on toss 1,\n…, Heads on toss 1000. Now suppose that\n\\(\\mathcal{F}_1\\) extends \\(\\mathcal{F}\\) by introducing a new\nproposition about a further hypothetical toss of the coin (as well as\nperhaps other propositions). That is, it introduces Heads on toss\n1001 (and closes out under negation, disjunction, and\nconjunction). And suppose that \\(\\sim_1\\) extends \\(\\sim\\), so that\nthe new proposition Heads on toss 1001 is considered\nrelevantly similar to each Heads on toss 1, …,\nHeads on toss 1000. Then those who appeal to hypothetical\nlimiting frequencies must claim that there is a unique number that\ngives what the frequency of heads would be, were the coin tossed 1001\ntimes. They denote this number \\(\\mathrm{Freq}(\\mathcal{F}_1, A,\n\\sim_1, w)\\). Now suppose that \\(\\mathcal{F}_2\\) extends\n\\(\\mathcal{F}_1\\) by adding the new proposition Heads on toss\n1002 and \\(\\sim_2\\) extends \\(\\sim_1\\), so that the new\nproposition Heads on toss 1002 is considered relevantly\nsimilar to each Heads on toss 1, …, Heads on toss\n1001. And so on. Then the limiting relative frequency of \\(A\\) at\n\\(w\\) (written \\(\\mathrm{LimFreq}(\\mathcal{F}, A, \\sim, w)\\)) is the\nnumber towards which the following sequence tends: \n\n\\[\\mathrm{Freq}(\\mathcal{F}, A, \\sim, w), \\mathrm{Freq}(\\mathcal{F}_1,\nA, \\sim_1, w), \\mathrm{Freq}(\\mathcal{F}_2, A, \\sim_2, w),\n\\ldots\\] \nIn general, for each algebra \\(\\mathcal{F}\\) and equivalence relation\n\\(\\sim\\), there is an infinite sequence \n\n\\[(\\mathcal{F}, \\sim) = (\\mathcal{F}_0, \\sim_0), (\\mathcal{F}_1,\n\\sim_1), (\\mathcal{F}_2, \\sim_2), \\ldots\\]\n\n of pairs of\nalgebras \\(\\mathcal{F}_i\\) and equivalence relations \\(\\sim_i\\) such\nthat each \\(\\mathcal{F}_{i+1}\\) is an extension of \\(\\mathcal{F}_i\\)\nand each \\(\\sim_{i+1}\\) is an extension of \\(\\sim_i\\) and, for each\n\\(i\\), \\(C(\\sim_i)\\). Using this, we can define the notion of limiting\nrelative frequency and the associated notion of hypothetical\ncalibration in full generality. Suppose \\(\\sim\\) is an equivalence\nrelation on \\(\\mathcal{F}\\) and \\(w\\) is a possible world. And suppose\n\n\\[(\\mathcal{F}_0, \\sim_0), (\\mathcal{F}_1, \\sim_1), (\\mathcal{F}_2,\n\\sim_2), \\ldots\\]\n\n is the sequence just mentioned. Then: \nAccording to some calibration arguments, actual calibration is an\nepistemic goal; according to others, hypothetical calibration is the\ngoal. Whichever it is, the epistemic disutility of a credence ought to\nbe given by its distance from this epistemic goal. We say that an\nepistemic disutility function is local if it measures only\nthe epistemic disutility of an individual credence at a world; we say\nthat it is global if it measures the epistemic disutility of\nan entire credence function at a world. In this section, we will be\nconcerned only with local epistemic disutility functions. In sections\n 5\n and\n 6,\n we will be concerned instead with global epistemic disutility\nfunctions. \nThe goals of actual calibration and hypothetical calibration give rise\nto the following definitions of two sorts of local epistemic\ndisutility function: \nOur next task is to identify the norms of standard decision\ntheory/utility theory that are deployed in conjunction with this\ncharacterization to derive Probabilism. \nIn this section, we consider the two accounts of epistemic disutility\nfor credences given in the previous section and we combine them with\ndecision-theoretic norms to derive epistemic norms. When we state the\ndecision-theoretic norms in question, we state them in full\ngenerality. In practical decision theory, we evaluate acts: it is acts\nthat have practical disutilities at worlds. In epistemic decision\ntheory, on the other hand, we evaluate credence functions: it is\ncredence functions that have epistemic disutilities at worlds. And in\nanother context still, we might wish to use decision theory to\nevaluate some other sort of thing, such as a scientific theory (Maher\n1993). So we want to state the decision-theoretic norms in a way that\nis neutral between these. We will talk of options as the\nthings that are being evaluated and that have utilities at worlds.\nOptions can thus be acts or credence functions or scientific theories\nor some other sort of thing. \nHere’s our first putative norm of standard decision theory (van\nFraassen 1983: 297): \nPossibility of Vindication A rational agent will not\nadopt an option that has no possibility of attaining minimal\ndisutility, when such a minimum exists. \nHere it is a little more formally: Suppose \\(\\mathcal{O}\\) is a set of\noptions, \\(\\mathcal{W}\\) is the set of possible worlds, and\n\\(\\mathfrak{U}\\) is a disutility function. Then, if \\(o^*\\) is an\noption, and there is no \\(w^*\\) in \\(\\mathcal{W}\\) such \n\n\\[\\mathfrak{U}(o^*, w^*) = \\min \\{\\mathfrak{U}(o, w) : o \\in\n\\mathcal{O}\\ \\&\\ w \\in \\mathcal{W}\\}\\] (when this minimum exists),\n\nthen \\(o^*\\) is irrational. \nIt can be shown that, together with Actual\nCalibration from the previous section and suitable\nconstraints \\(C(\\sim)\\) on the equivalence relation \\(\\sim\\), this\nnorm entails something stronger than Probabilism. It\nentails: \nRational-valued Probabilism At any time \\(t\\), a\nrational agent’s credence function \\(c\\) is a probability\nfunction that takes only values in \\(\\mathbb{Q}\\) (where\n\\(\\mathbb{Q}\\) is the set of rational numbers). \nThis is a consequence of the following theorem: \nTheorem 1 Suppose \\(\\mathfrak{c}\\) is a calibration\nmeasure and suppose \\(C(\\sim)\\). Then the following are\nequivalent: \nDifferent versions of this theorem result from different constraints\n\\(C(\\sim)\\) on the equivalence relation \\(\\sim\\) (van Fraassen 1983;\nShimony 1988), but the result is not surprising. An agent will satisfy\nPossibility of Vindication just in case her credences\nmatch the relative frequencies at some world. And those relative\nfrequencies will satisfy the probability axioms if \\(C(\\sim)\\) and if\nwe have specified that condition correctly. That they will be rational\nnumbers follows from the definition of the relative frequency of a\nproposition at a world. \nThus, we have the following argument: \nActual Calibration argument for Rational-valued\nProbabilism \nMost proponents of the calibration argument are reluctant to accept a\nnorm that rules out every credence given by an irrational number. To\nestablish the weaker norm of Probabilism, there are\ntwo strategies they might adopt. The first is to appeal to the\nepistemic goal of hypothetical calibration instead of actual\ncalibration. This, together with\n Possibility of Vindication\n gives us Probabilism via the following theorem: \nTheorem 2 Suppose \\(C(\\sim)\\). Then the following are\nequivalent: \nThe reason is that, while relative frequencies are always rational\nnumbers, the limit of an infinite sequence of rational numbers may be\nan irrational number. And, in fact, for any irrational number, there\nis a sequence of rational numbers that approaches it in the limit\n(indeed, there are infinitely many such sequences). \nThus, we have the following argument: \nHypothetical Calibration argument for Probabilism \nAn alternative route to Probabilism changes the\ndecision-theoretic norm to which we appeal, rather than the sort of\ncalibration from which we wish our epistemic disutility function to\nmeasure distance. The alternative norm is: \nPossibility of Arbitrary Closeness to Vindication. An\nagent ought not to adopt an option unless there are worlds at which it\nis arbitrarily close to achieving minimal disutility. \nThat is: Suppose \\(\\mathcal{O}\\) is a set of options, \\(\\mathcal{W}\\)\nis the set of possible worlds, and \\(\\mathfrak{U}\\) is a disutility\nfunction. Then, if \\(o^*\\) is an option, and if it is not the case\nthat, for any \\(\\varepsilon > 0\\), there is a possible \n\nworld \\(w^*_\\varepsilon\\) in \\(\\mathcal{W}\\) such \\[|\n\\mathfrak{U}(o^*, w^*_\\varepsilon) - \\min \\{\\mathfrak{U}(o, w) : o \\in\n\\mathcal{O}\\ \\&\\ w \\in \\mathcal{W}\\}| < \\varepsilon\\] (when\n\nthese minima exist), then \\(o^*\\) is irrational. \nTogether with the characterization of calibration measures given\nabove, suitable constraints \\(C(\\sim)\\) on the equivalence relation\n\\(\\sim\\), and two extra assumptions, this norm does establish\nProbabilism. The extra assumptions are these: First,\nif our agent has a credence function \\(c\\) in \\(\\mathcal{C_F}\\), the\npossible worlds that we are considering include not only all\n(consistent) truth assignments to \\(\\mathcal{F}\\), but also any\n(consistent) truth assignments to any (finite) algebra\n\\(\\mathcal{F}'\\) that extends \\(\\mathcal{F}\\). And, second, given any\nsuch \\(\\mathcal{F}'\\), the equivalence relation \\(\\sim\\) can be\nextended in any possible way, providing the extension \\(\\sim'\\) of\n\\(\\sim\\) satisfies \\(C(\\sim')\\). \nTheorem 3 Suppose \\(C(\\sim)\\). Then the following are\nequivalent: \nThus, if our agent satisfies Probabilism, then\nhowever close she would like to be to actual calibration, there is\nsome possible world at which she is that close. And conversely. \nThus, we have the following argument: \nActual Calibration argument for Probabilism \nThese are the calibration arguments for Probabilism.\nIn the next section, we consider objections that may be raised against\nthem. \nObjection 1: Calibration is not an epistemic goal. It may be\nobjected that neither actual nor hypothetical calibration measures are\ntruth-directed epistemic disutility functions, where this is\ntaken to be a necessary condition on such a function (Joyce 1998: 595;\nSeidenfeld 1985). We say that a local epistemic disutility\nfunction—that is, recall, an epistemic disutility function\ndefined for individual credences—is truth-directed if the\ndisutility that it assigns to a credence in a true proposition\nincreases as the credence decreases, and the disutility it assigns to\na credence in a false proposition increases as the credence increases.\nCalibration measures do not have this property. To see this, let us\nreturn to our toy example: the propositions Heads on toss 1,\n…, Heads on toss 1000 are in \\(\\mathcal{F}\\) and they\nare all relevantly similar according to \\(\\sim\\). Now suppose that the\nfirst coin toss lands heads, but all the others land tails. Then\ncredence 0.001 in Heads on toss 1 is actually calibrated,\nsince exactly one out of one-thousand relevantly similar propositions\nare true; so it has epistemic disutility 0. Credence 0.993, on the\nother hand, is not, and thus receives a positive epistemic disutility.\nHowever, it is a higher credence in a true proposition, and thus\nshould be assigned a lower epistemic disutility, according to the\nrequirement of truth-directedness. One natural response to this\nobjection is that it is question-begging. Proponents of the\ncalibration argument will simply reject the claim that an epistemic\ndisutility function must be truth-directed. Credences, unlike beliefs,\nthey might say, are not in the business of getting close to the truth;\nthey are in the business of getting close to being calibrated. \nObjection 2: Limiting relative frequencies are not\nwell-defined. To define the limiting relative frequency of \\(A\\)\nat a world \\(w\\), we require that there is a unique sequence of\nextensions of the algebra each of which contains more propositions\nthat are relevantly similar to \\(A\\) than the previous extension, and\na corresponding sequence of relative frequencies of truths amongst the\npropositions like \\(A\\) in the corresponding algebra. But the\nassumption of such a unique sequence is extremely controversial and\nthe problems to which it gives rise have haunted hypothetical\nfrequentism about objective probability (Hájek 2009). \nObjection 3: Neither\n Possibility of Vindication\n nor\n Possibility of Arbitrary Closeness to Vindication\n is a norm. It might be that the only actions that give rise to\nthe possibility of vindication or of arbitrary closeness to\nvindication also give rise to the possibility of maximal distance from\nvindication. And it might be that there are actions that do not give\nrise to the possibility of vindication or of arbitrary closeness to\nvindication, but do limit the distance from vindication that is risked\nby choosing that action. In such cases, it is not at all clear that it\nis rationally required of an agent that she ought to risk maximal\ndistance from vindication in order to leave open the possibility of\nvindication or of arbitrary closeness to vindication. Compare: I have\ntwo options—if I choose option 1, I will receive £0 or\n£100, but I don’t know which; if I choose option 2, I will\nreceive £99 for sure. Even before they know the objective\nchances of the two possibilities that the first option creates, many\npeople will opt for the second. However, by doing so, they rule out\nthe possibility that they will receive the maximum possible utility,\nwhich is obtained by option 1 if I receive £100. It seems that\nruling out such a possibility is not irrational. To put it another\nway:\n Possibility of Vindication\n and\n Possibility of Arbitrary Closeness to Vindication\n are extreme risk-seeking norms. That is, they suggest that we make\nour decisions by trying to maximise the utility we obtain in our\nbest-case scenario. But while it might be rationally permissible to be\nso risk-seeking, it is certainly not mandatory (Easwaran &\nFitelson 2015: Section 8). \nObjection 4: The constraints on \\(\\sim\\) are ill-motivated.\nThis objection will vary with the constraints \\(C(\\sim)\\) that are\nimposed on \\(\\sim\\). One uncontroversial constraint is this: If \\(A\n\\sim B\\), then \\(c(A) = c(B)\\). The further constraints imposed by\nShimony (1988) and van Fraassen (1983) are more controversial (Joyce\n1998: 594–6). Moreover, they limit the application of the\nresult, since they involve assumptions about the form of the\npropositions in \\(\\mathcal{F}\\). Thus, the calibration arguments do\nnot show in general, of any finite algebra \\(\\mathcal{F}\\), that a\ncredence function on \\(\\mathcal{F}\\) ought to be a probability\nfunction, since not every such algebra will contain propositions with\nthe form required by the constraints \\(C(\\sim)\\). \nIn this section, we move from calibration arguments to accuracy\narguments for Probabilism. These arguments have the\nsame structure as the calibration arguments. They consist of a\nmathematically-precise account of epistemic disutility and a\ndecision-theoretic norm. And they derive, from that norm together with\nthat account of disutility, an epistemic norm. In particular, they\nderive Probabilism. And that derivation goes via a\nmathematical theorem. However, they will use different accounts of\nepistemic disutility and different decision-theoretic norms. \nIn this section, we will begin with the original accuracy-based\nargument for Probabilism due to James M. Joyce (1998;\nsee also Rosenkrantz 1981; both versions, as well as subsequent\nversions, build on mathematical results due to de Finetti (1974)).\nThen we’ll consider its various components in turn, and explore\nthe objections they have elicited and the adjustments that have been\nmade to them. \nJoyce’s argument consists of an account of the epistemic\ndisutility of credences and a decision-theoretic norm. Let’s\nconsider each in turn. \nJoyce’s account of the epistemic disutility of credences itself\nconsists of two components. The first identifies epistemic disutility\nwith gradational inaccuracy; the second gives a mathematically-precise\naccount of gradational inaccuracy. \nIn more detail: The first component of Joyce’s account of\nepistemic disutility for credences is the claim—which we will\ncall Credal Veritism, partly following Goldman (2002:\n58)—that the only source of value for credences that is relevant\nto their epistemic status is their gradational accuracy,\nwhere the gradational accuracy of a credence in a true proposition is\nhigher when the credence is closer to 1, which we might think of as\nthe ideal or vindicated credence in a true proposition, while the\ngradational accuracy of a false proposition is higher when the\ncredence is closer to 0, which we might think of as the ideal or\nvindicated credence in a false proposition. Thus, the only source of\ndisvalue for credences is their gradational\ninaccuracy. \nThe second component of Joyce’s account of epistemic disutility\nfor credences is a set of mathematically-precise conditions that a\nmeasure of the gradational inaccuracy of a credence function at a\ngiven possible world must satisfy. A putative inaccuracy measure for\ncredence functions over an algebra \\(\\mathcal{F}\\) is a mathematical\nfunction \\(\\mathfrak{I}\\) that takes a credence function \\(c\\) in\n\\(\\mathcal{C_F}\\) and a possible world \\(w\\) in \\(\\mathcal{W_F}\\) and\nreturns a number \\(\\mathfrak{I}(c, w)\\) in \\([0, \\infty]\\) that\nmeasures the inaccuracy of \\(c\\) at \\(w\\). (The set \\([0, \\infty]\\)\ncontains all non-negative real numbers together with \\(\\infty\\).) Here\nis an example, called the Brier score: \n\n\\[\\mathfrak{B}(c, w) := \\sum_{X \\in \\mathcal{F}} |v_w(X) - c(w)|^2\\]\n\n Thus, the\nBrier score measures the inaccuracy of a credence function at a world\nas follows: it takes each proposition to which the credence function\nassigns credences; it takes the difference between the credence that\nthe credence function assigns to that proposition and the ideal or\nvindicated credence in that proposition at that world; it squares this\ndifference; and it sums up the results. We shall not give all of\nJoyce’s conditions here, but just note that the Brier score just\ndefined satisfies them all. Let us say that any putative inaccuracy\nmeasure \\(\\mathfrak{I}\\) that satisfies these conditions is a\nJoycean inaccuracy measure. And let Joycean\nInaccuracy be the claim that all legitimate inaccuracy\nmeasures are Joycean inaccuracy measures. \nCombining Credal Veritism and Joycean\nInaccuracy, we have the claim that the epistemic disutility\nof a credence function at a world is given by its inaccuracy at that\nworld as measured by a Joycean inaccuracy measure. \nLet us turn now to the decision-theoretic norm to which Joyce appeals.\nWe have met it already above in the introduction to this article: it\nis the norm of Naive Dominance. We will state it here\nprecisely: \nNaive Dominance A rational agent will not adopt an\noption when there is another option that has lower disutility at all\nworlds. \nThat is: Suppose \\(\\mathcal{O}\\) is a set of options, \\(\\mathcal{W}\\)\nis the set of possible worlds, and \\(\\mathfrak{U}\\) is a disutility\nfunction. Then, if \\(o^*\\) is an option, and if there is another\noption \\(o'\\) such that \\(\\mathfrak{U}(o', w) < \\mathfrak{U}(o^*,\nw)\\) for all worlds \\(w\\) in \\(\\mathcal{W}\\), then \\(o^*\\) is\nirrational. (In this situation, we say that \\(o^*\\)\n\\(\\mathfrak{U}\\)-dominates \\(o'\\).) \nThe idea behind Naive Dominance is this: If there is\none option that is guaranteed to have lower disutility than another\noption, then the latter is guaranteed to be worse than the former; so\nthe agent can know a priori that the latter is worse than the\nformer. And surely it is irrational to adopt an option if there is\nanother that you know a priori to be better. \nThus, we have the substantial components of Joyce’s argument:\nCredal Veritism, Joycean Inaccuracy,\nand Naive Dominance. From these, we can derive\nProbabilism via the following mathematical theorem\nJoyce (1998: 597–600): \nTheorem 4 (Joyce’s Main Theorem) Suppose\n\\(\\mathcal{F}\\) is an algebra and \\(\\mathfrak{I} : \\mathcal{C_F}\n\\times \\mathcal{W_F} \\rightarrow [0, \\infty]\\) is a Joycean inaccuracy\nmeasure for the credence functions on \\(\\mathcal{F}\\). Now suppose\nthat \\(c^*\\) is a credence function in \\(\\mathcal{C_F}\\) that violates\nProbabilism. Then there is a credence function \\(c'\\)\nin \\(\\mathcal{C_F}\\) such that \\(\\mathfrak{I}(c', w) <\n\\mathfrak{I}(c^*, w)\\) for all \\(w\\) in \\(\\mathcal{W_F}\\). (In this\nsituation, we say that \\(c'\\) accuracy dominates \\(c^*\\) relative\nto \\(\\mathfrak{I}\\).) \n\n Figure 1\n illustrates this result in the particular very simple case in which\n\\(\\mathcal{F}\\) contains just a proposition, Heads, and its\nnegation, Tails, and inaccuracy is measured using the Brier\nscore. \nThus, we have the following argument: \nJoyce’s accuracy argument for Probabilism \nFigure 1: In this figure, we plot the\nvarious possible credence functions defined on a proposition\nHeads and its negation Tails in the unit square.\nThus, we plot the credence in Heads along the horizontal axis\nand the credence in Tails up the vertical axis. We also plot\nthe vindicated credence functions \\(v_{w_1}\\) and \\(v_{w_2}\\) for the\ntwo worlds \\(w_1\\) (at which Tails is true and Heads\nis false) and \\(w_2\\) (at which Heads is true and\nTails is false). The diagonal line between them contains all\nand only the credence functions on these two propositions that are\nprobability functions and thus satisfy Probabilism.\n\\(c^*\\) (which assigns 0.7 to Heads and 0.6 to\nTails) violates Probabilism. The lower\nright-hand arc contains all the credence functions that are exactly as\ninaccurate as \\(c\\) at world \\(w_2\\), where that inaccuracy is\nmeasured using the Brier score. To see this, note that the Brier score\nof \\(c^*\\) at \\(w_2\\) is the square of the Euclidean distance of the\npoint \\(c^*\\) from the point \\(v_{w_2}\\). Thus, the credence functions\nthat have exactly the same Brier score as \\(c^*\\) at \\(w_2\\) are those\nthat lie equally far from \\(v_{w_2}\\). For the same reason, the upper\nleft-hand arc contains all the credence functions that are exactly as\ninaccuracy as \\(c\\) at world \\(w_1\\). Every credence function that\nlies between the two arcs is more accurate than \\(c^*\\) at both\nworlds. These are the ones whose squared Euclidean distance from\n\\(v_{w_2}\\) is less than the squared Euclidean distance of \\(c^*\\)\nfrom \\(v_{w_2}\\), and similarly for \\(v_{w_1}\\). It assigns 0.55 to\nHeads and 0.45 to Tails. \\(c'\\) is such a credence\nfunction. \\(c'\\) also satisfies Probabilism.  \nLet us start by considering the first of the two components that\ncomprise Joyce’s account of epistemic disutility for credences,\nnamely,\n Credal Veritism.\n This says that the sole fundamental source of epistemic disutility\nfor a credence is its gradational inaccuracy. That is, any other vice\nthat the credence has must derive from this vice (Goldman 2002:\n52). \nFirst, let’s note why it is important to make this assumption.\nWould it not be sufficient to say merely that one of the sources of\ndisutility for a credence is its inaccuracy, and then to point out\nthat any credence function that isn’t a probability function is\naccuracy dominated? If it could always be guaranteed that, for any\nnon-probabilistic credence function, none of its accuracy dominators\nhas any epistemic vice to a greater degree than does the credence\nfunction it dominates, then this would be sufficient. But, if it were\npossible that every accuracy dominator is guaranteed to be better\nalong the dimension of inaccuracy but worse along some other dimension\nof epistemic disutility, then being accuracy dominated would not rule\nout a credence function as irrational. Thus, if the accuracy dominance\nargument for Probabilism is to work, we must claim,\nwith\n Credal Veritism,\n that inaccuracy is the only source of epistemic disutility for\ncredences. \nHow are we to establish this? How can we be sure there aren’t\nother sources of disutility. For instance, perhaps it is a virtue of a\ncredence function if the credences it assigns cohere with one another\nin a particular way, and a vice if they do not. This is a\ncoherentist claim of the sort endorsed for full beliefs,\nrather than credences, by the likes of BonJour (1985) and Harman\n(1973). Or perhaps it is a virtue of a credence in a particular\nproposition if it matches the degree of support given to that\nproposition by the agent’s current total evidence. This claim is\ndubbed evidential proportionalism by Goldman (2002:\n55–7). Recent proponents might include Williamson (2000) and\nWhite (2009). Another possibility: perhaps the verisimilitude\nor truthlikeness of your credences is a source of their\nepistemic utility over and above their gradational accuracy (see entry\non\n truthlikeness).\n Graham Oddie (2019) argues in favour of this. Each of these seem\nplausible. How is the credal veritist to answer the objection that\nthere are sources of epistemic disutility, such as these three, that\ngo beyond gradational inaccuracy? Of course, it is notoriously\ndifficult to prove a negative existential claim, such as the credal\nveritist claim that there are no other epistemic vices beyond\ninaccuracy. But here is a natural strategy: for each proposed\ncandidate epistemic vice besides accuracy, the credal veritist should\nprovide an account of how its badness derives from the badness of\ninaccuracy. \nIn the case of the coherentist described above, who proposes that it\nis a vice to have credences that fail to cohere in a particular way,\nthere is a very natural instance of this strategy. The coherence that\nwe demand of credences is precisely that they relate to one another in\nthe way that Probabilism demands, so that, for\ninstance, no disjunction is assigned lower credence than is assigned\nto either of the disjuncts, no proposition is assigned very high\ncredence at the same time that its negation is also assigned very high\ncredence, and so on. If that is correct, then of course Joyce’s\naccuracy argument for Probabilism detailed above\nprovides an argument that this vice derives its badness from the\nbadness of inaccuracy: after all, if a credence function lacks the\ncoherence that the coherentist considers virtuous, they will be\naccuracy dominated. \nWhat of the evidential proportionalist? Here it is a little more\ndifficult. There are principles that the evidential proportionalist\nwill take to govern evidential support that go beyond merely\nProbabilism, which is a relatively weak and\nundemanding principle. So it is not sufficient to point to the\naccuracy argument for that principle in the way we did in response to\nthe coherentist. However, here is an attempt at an answer. It comes\nfrom collecting together a series of accuracy arguments for other\nprinciples of rationality that we take to govern our credences. For\ninstance, Greaves & Wallace (2006) and Briggs & Pettigrew\n(2018) give an accuracy argument for the principle of\nconditionalization, which says that, if an agent is rational, her\ncredence function at a later time will be obtained from her credence\nfunction at an earlier time by conditionalizing on the total evidence\nshe obtains between those two times; Easwaran (2013) and Huttegger\n(2013) extend the argument, and Schoenfield (2016) and Carr (2019)\nclarify the norm that it establishes. Moreover, Pettigrew (2013a)\ngives an accuracy argument for the Principal Principle, which says\nthat, if an agent is rational, her credences in propositions\nconcerning the objective chances will relate to propositions to which\nthose chances attach in a particular way. Pettigrew (2014b) and Konek\n(2016) give rather different accuracy-based arguments for the\nPrinciple of Indifference, which says how a rational agent with no\nevidence will distribute their credences. Moss (2011), Lam (2013), and\nLevinstein (2015) describe principles that rational agents will obey\nin the presence of peer disagreement and provide accuracy-based\narguments in their favour. And finally Horowitz (2014) uses\naccuracy-based arguments to evaluate various species of permissivism.\nThe point is that, piece by piece, the principles that are taken to\ngovern the degree of support provided to a proposition by a body of\nevidence are being shown to follow from accuracy considerations alone.\nThis, it seems, constitutes a response to the concerns of the\nevidential proportionalist. \nChristopher Meacham (2018) objects to this response in two ways:\nfirst, he argues that the different decision-theoretic norms that are\nused in the justifications of the various credal norms listed above\nmight be incompatible with one another; and, second, he worries that\nsome of the decision-theoretic norms that are used in those\njustifications are not themselves purely alethic and therefore fail to\nprovide purely veritistic justifications of the norms in question. \nBoth the response to the coherentist and the response to the\nevidential proportionalist leave the accuracy argument for\nProbabilism in a strange position. The argument for,\nor defence of, one component of its first premise, namely,\n Credal Veritism\n appeals to an argument of which it is a premise! In fact, this\nisn’t problematic. The credal veritist and her opponent might\nagree that the argument at least establishes a conditional:\nif credal veritism is true, then probabilism is\ntrue. You need not accept credal veritism to accept that conditional.\nAnd it is that conditional to which the credal veritist appeals in\ndefending her position against the coherentist and the evidential\nproportionalist. Having successfully defended credal veritism in this\nway, she can then appeal to its truth to derive\nProbabilism. \nBefore we consider how to measure inaccuracy in the next section,\nlet’s consider the claim that verisimilitude or truthlikeness is\na further source of epistemic utility. It is most easily introduced by\nan example. Suppose I am interested in how many stars there are on the\nflag of Suriname. I have credences in three propositions: 1\n(which says there’s one star), 2 (which says there are\ntwo), and 3 (which says three). In fact, there is one star on\nthe flag. That is, 1 is true at the actual world, while\n2 and 3 are false. Now consider two different\ncredence functions on these three propositions: \nThat is, \\(c\\) and \\(c'\\) both assign credence 0 to the true\nproposition, 1; they are certain that there are either 2 or 3\nstars on the flag, but while \\(c\\) spreads its credence equally over\nthese two false options, \\(c'\\) is certain of the first. According to\nOddie (2019), \\(c'\\) has greater truthlikeness than \\(c\\) at the\nactual world because it assigns a higher credence to a proposition\nthat, while false, is more truthlike, namely, 2, and it\nassigns a lower credence to a proposition that is, while also false,\nless truthlike, namely, 3. On this basis, he argues that any\nmeasure of epistemic disutility must judge \\(c\\) to be worse than\n\\(c'\\). However, he notes, nearly all measures of gradational accuracy\nthat are used in accuracy dominance arguments for\nProbabilism will not judge in that way: they will\njudge \\(c'\\) worse than \\(c\\). And indeed those that do so judge will\nfail to respect truthlikeness in other ways. Jeffrey Dunn (2018) and\nMiriam Schoenfield (2019) respond to Oddie’s arguments. \nSo much, then, for the first component of the first premise of the\naccuracy argument for Probabilism, namely,\n Credal Veritism.\n In this section, we turn to the second component, namely,\n Joycean Inaccuracy.\n Let’s focus on a particular condition that Joyce places on\nmeasures of inaccuracy, namely, Strong Convexity\n(Joyce calls it Weak Convexity, but we change the name in this\npresentation because, as Patrick Maher (2002) points out, it is\nconsiderably stronger than Joyce imagines.) \nStrong Convexity Suppose \\(\\mathfrak{I}\\) is a\nlegitimate inaccuracy measure. Then if \\(c \\neq c'\\) and\n\\(\\mathfrak{I}(c, w) = \\mathfrak{I}(c', w)\\), then \n\n\\[\\mathfrak{I}\\left(\\frac{1}{2}c + \\frac{1}{2}c', w\\right) <\n\\mathfrak{I}(c, w) = \\mathfrak{I}(c', w)\\] (Given two credence\n\nfunctions, \\(c\\) and \\(c'\\), we define a third credence function\n\\(\\frac{1}{2}c + \\frac{1}{2} c'\\) as follows: the credence that\n\\(\\frac{1}{2}c + \\frac{1}{2}c'\\) assigns to a proposition is the\nstraight average of the credences that \\(c\\) and \\(c'\\) assign to it.\nThus, \\((\\frac{1}{2}c + \\frac{1}{2}c')(X) = \\frac{1}{2}c(X) +\n\\frac{1}{2}c'(X).\\) We call this the equal mixture of \\(c\\) and\n\\(c'\\).) \nThis says that, for any two distinct credence functions that are\nequally inaccurate at a given world, the third credence function\nobtained by “splitting the difference” between them and\ntaking an equal mixture of the two is less inaccurate than either of\nthem. Here is Joyce’s justification of this condition: \n[Strong] Convexity is motivated by the intuition that extremism in the\npursuit of accuracy is no virtue. It says that if a certain change in\na person’s degrees of belief does not improve accuracy then a\nmore radical change in the same direction and of the same magnitude\nshould not improve accuracy either. Indeed, this is just what the\nprinciple says. (Joyce 1998: 596) \nJoyce’s point is this: Suppose we have three credence functions,\n\\(c\\), \\(m\\), and \\(c'\\). And suppose that, to move from \\(m\\) to\n\\(c'\\) is just to move in the same direction and by the same amount as\nto move from \\(c\\) to \\(m\\), which is exactly what will be true if\n\\(m\\) is the equal mixture of \\(c\\) and \\(c'\\). Now suppose that \\(m\\)\nis at least as inaccurate as \\(c\\)—that is, the change from\n\\(c\\) to \\(m\\) does not “improve accuracy”. Then, Joyce\nclaims, \\(c'\\) must be at least as inaccurate as \\(m\\)—that is,\nthe change from \\(m\\) to \\(c'\\) also does not “improve\naccuracy”. \nObjection: The justification given doesn’t justify\nStrong Convexity. The problem with this\njustification is that it establishes a weaker principle than\nStrong Convexity. This was first pointed out by\nPatrick Maher (2002), who noted that Joyce’s justification in\nfact motivates the following weaker principle: \nWeak Convexity Suppose \\(\\mathfrak{I}\\) is a\nlegitimate inaccuracy measure. Then if \\(c \\neq c'\\) and\n\\(\\mathfrak{I}(c, w) = \\mathfrak{I}(c', w)\\), then \n\n\\[\\mathfrak{I}\\left(\\frac{1}{2}c + \\frac{1}{2}c', w\\right) \\leq\n\\mathfrak{I}(c, w) = \\mathfrak{I}(c', w)\\] \nThat is, Joyce’s motivation rules out situations in which\ninaccuracy increases from \\(c\\) to \\(m\\) and then\ndecreases from \\(m\\) to \\(c'\\). And this is what Weak\nConvexity also rules out. But Strong\nConvexity furthermore rules out situations in which\ninaccuracy remains the same from \\(c\\) to \\(m\\) and then from\n\\(m\\) to \\(c'\\). And Joyce has given no reason to think that such\nchanges are problematic. What’s more, as Maher proves, the\nstronger convexity condition is crucial for Joyce’s proof. With\nonly the weaker condition, the theorem is false. \nIn this section, we consider alternative sets of conditions on\ninaccuracy measures that are presented by Leitgeb & Pettigrew\n(2010a). These propose that we replace the claim\n Joycean Inaccuracy\n in Joyce’s accuracy argument for Probabilism\nwith an alternative claim that says that the legitimate inaccuracy\nmeasures are (amongst) those that satisfy Leitgeb and\nPettigrew’s alternative conditions. Unlike Joyce’s\nconditions, these are sufficient to narrow the field of legitimate\ninaccuracy measures to just a single one, namely, the Brier score\n\\(\\mathfrak{B}\\) that we met in\n section 5.1\n above. Let us say that Brier Inaccuracy is the claim\nthat the Brier score is the only legitimate measure of inaccuracy. And\nnote that, if we replace\n Joycean Inaccuracy\n with Brier Inaccuracy in Joyce’s argument for\nProbabilism, we retain our argument for that\nepistemic norm: \nBrier accuracy-based argument for Probabilism: I \nSo far, in this section, we have been concerned only with what we\nmight call global measures of inaccuracy—that is,\nmeasures of the inaccuracy of entire credence functions. Leitgeb and\nPettigrew are certainly interested in those. But they are also\ninterested in what we might call local measures of\ninaccuracy—that is, measures of the inaccuracy of individual\ncredences. Indeed, they are interested in how these two sorts of\ninaccuracy measure interact. They lay down constraints on each of the\ninaccuracy measures individually, and then they lay down constraints\non how they combine. The guiding idea in each case is that any feature\nof the inaccuracy of credences that is determined from the point of\nview of local inaccuracy measures—such as their total\ninaccuracy, or the urgency with which an agent with inaccurate\ncredences should change them—should match that same feature when\nit is determined from the point of view of global inaccuracy measures.\nIf this doesn’t happen, then the agent will face a rational\ndilemma when choosing which of the two ways she should use to\ndetermine that feature. Here, we shall focus only on one of the most\npowerful of Leitgeb and Pettigrew’s conditions, which also turns\nout to be the most problematic. Here it is: \nGlobal Normality and Dominance If \\(\\mathfrak{I}\\) is\na legitimate global inaccuracy measure, there is a strictly increasing\n\\(f:[0, \\infty) \\rightarrow [0, \\infty)\\) such \n\n\\[\\mathfrak{I}(c, w) = f(||v_w - c||_2).\\] where, for any two credence\n\n functions\n\\(c\\), \\(c'\\) defined on \\(\\mathcal{F}\\), \n\n\\[||c - c'||_2 := \\sqrt{\\sum_{X \\in \\mathcal{F}} |c(X) - c'(X)|^2}\\]\n\n and we call\n\\(||c - c'||_2\\) the Euclidean distance between \\(c\\) and\n\\(c'\\); and, recall, \\(v_w\\) is the omniscient credence function\nat \\(w\\), so that \\(v_w(X) = 1\\) if \\(X\\) is true at \\(w\\) and\n\\(v_w(X) = 0\\) if \\(X\\) is false at \\(w\\). \nThus, Global Normality and Dominance says that the\ninaccuracy of a credence function at a world should supervene in a\ncertain way upon the Euclidean distance between that credence function\nand the omniscient credence function at that world. Indeed, it should\nbe a strictly increasing function of that distance between them. \nObjection 1: There is no motivation for the appeal to Euclidean\ndistance. Leitgeb and Pettigrew show that the only inaccuracy\nmeasure that satisfies\n Global Normality and Dominance,\n together with their other conditions on inaccuracy measures, is the\nBrier score, which we defined above. That is, imposing these\nconditions entails\n Brier Inaccuracy.\n The problem with this characterization, however, is that it depends\ncrucially on the appeal to the Euclidean distance made in\n Global Normality and Dominance,\n and no reason is given for appealing to the Euclidean distance\nmeasure in particular, rather than some other measure of distance\nbetween credence functions. Suppose we replace that condition with one\nthat says that a legitimate global inaccuracy measure must be a\nstrictly increasing function of the so-called Manhattan or\ncity block distance measure, where the distance between two\ncredence functions measured in this way is defined as follows:\n\n\\[||c - c'||_1 := \\sum_{X \\in \\mathcal{F}} |c(X) - c'(X)|\\] That is,\n\n the Manhattan distance between two credence functions is\nobtained by summing the differences between the credences they each\nassign to the various propositions on which they are defined. Together\nwith the other constraints that Leitgeb and Pettigrew place on\ninaccuracy measures, this alternative constraint entails that the only\nlegitimate inaccuracy measure is the so-called absolute value\nscore, which is defined as follows: \n\n\\[\\mathfrak{A}(c, w) := \\sum_{X \\in \\mathcal{F}} |v_w(X) - c(X)|\\] \nNow, it turns out that the absolute value score cannot ground an\naccuracy argument for Probabilism. In fact, there are\nsituations in which non-probabilistic credence functions accuracy\ndominate probabilistic credence functions when inaccuracy is measured\nusing the absolute value score. Let \\(\\mathcal{F} = \\{X_1, X_2,\nX_3\\}\\), where \\(X_1\\), \\(X_2\\), and \\(X_3\\) are mutually exclusive\nand exhaustive propositions. And consider the following two credence\nfunctions: \\(c(X_i) = \\frac{1}{3}\\) for each \\(i = 1, 2, 3\\);\n\\(c'(X_i) = 0\\) for each \\(i = 1, 2, 3\\). The former, \\(c\\), is\nprobabilistic; the latter, \\(c'\\), is not. But, if we measure\ninaccuracy using the absolute score, the inaccuracy of \\(c\\) at each\nof the three possible worlds is \\(\\frac{4}{3}\\), whereas the\ninaccuracy of \\(c'\\) at each of the three possible worlds is \\(1\\).\nThe upshot of this observation is that it is crucial, if our accuracy\nargument for Probabilism is to succeed, to rule out\nthe absolute value score. The problem with the Leitgeb and Pettigrew\ncharacterization is that it rules out this measure essentially by\nfiat. It rules it out by demanding that the inaccuracy of a credence\nfunction at a world supervenes on the Euclidean distance between the\ncredence function and the omniscient credence function at that world.\nBut it gives no reason for favouring this measure of distance over\nanother, such as Manhattan distance. \nObjection 2: Using the Brier score to measure inaccuracy has\nunintuitive consequences. A further objection to Leitgeb and\nPettigrew’s characterization of inaccuracy measures is given by\nLevinstein (2012). In the sequel to the paper in which they give this\ncharacterization, Leitgeb and Pettigrew use it to argue in favour of\nan updating rule for credences that applies in the same situations as\nso-called Jeffrey Conditionalization (or Probability Kinematics) but\noffers different advice (Jeffrey 1965; Leitgeb & Pettigrew 2010b).\nLevinstein objects to the use of the Brier score to measure inaccuracy\non the grounds that this alternative updating rule gives deeply\nunintuitive results. \nThe final characterization of inaccuracy measures that we consider\nhere is due to Pettigrew (2016). Again, we won’t enumerate all\nof the conditions here. Instead, we’ll describe the most\ncontentious and mathematically powerful of the conditions—the\none that in some sense does the main mathematical\n“heavylifting” when it comes to showing what putative\ninaccuracy measures these conditions permit. \nSo far in this entry, we have presented calibration accounts of\nepistemic utility and accuracy accounts as separate and incompatible.\nThe condition on inaccuracy measures that Pettigrew proposes and that\nwe consider in this section denies that. Rather, it claims that\ncloseness to calibration in fact plays a role in determining the\naccuracy of a credence function; the difference between this approach\nand the calibration arguments of section\n 4\n is that Pettigrew does not think that closeness to calibration is the\nwhole story. Let \\(\\mathfrak{D}\\) be a putative measure of the\ndistance between two credence functions. That is, \\(\\mathfrak{D} :\n\\mathcal{C_F} \\times \\mathcal{C_F} \\rightarrow [0, \\infty]\\), and\nwe’ll assume that \\(\\mathfrak{D}(c, c') = 0\\) iff \\(c = c'\\).\nNow first we use this measure of distance to define a measure of the\ndistance that a credence function lies from being perfectly calibrated\nat a world. Then, following a point already made above in our\ntreatment of calibration arguments for Probabilism,\nwe note that this, on its own, cannot define a measure of inaccuracy\nbecause it lacks a crucial feature that we demand of any such measure:\nit is not truth-directed. However, we then note how to supplement the\nmeasure of distance from calibration in order to give an inaccuracy\nmeasure that does have the crucial feature. And we claim that all\ninaccuracy measures are produced by supplementing a measure of\ndistance from calibration in this way. \nAs in\n section 4.1,\n we let \\(\\sim\\) be an equivalence relation on the set \\(\\mathcal{F}\\)\nof propositions to which our agent assigns opinions. It is the\nrelation of relevant similarity between two propositions. In\n section 4.1,\n we said that we would impose conditions \\(C(\\sim)\\) on this\nequivalence relation, but we said no more to identify those\nconditions. In this section, we in fact define this equivalence\nrelation. We take it to be relative to a credence function \\(c\\), so\nwe write it \\(\\sim_c\\), and we define it as follows: \\(A \\sim_c B\\)\niff \\(c(A) = c(B)\\). That is, two propositions are relevantly similar\nfor our agent with credence function \\(c\\) if \\(c\\) assigns them the\nsame credence. Thus, given a possible world \\(w\\), we say that a\ncredence function \\(c\\) is perfectly calibrated at \\(w\\) if,\nfor each \\(A\\) in \\(\\mathcal{F}\\), \n\n\\[c(A) = \\mathrm{Freq}(\\mathcal{F}, A, \\sim_c, w)\\] \nNext, given a credence function \\(c\\) and a world \\(w\\), the\nperfectly calibrated counterpart of \\(c\\) at \\(w\\) is a\ncredence function also defined on \\(\\mathcal{F}\\) that is defined as\nfollows: for each \\(A\\) in \\(\\mathcal{F}\\) \n\n\\[c^w(A) = \\mathrm{Freq}(\\mathcal{F}, A, \\sim_c, w)\\]\n\n That is, the\nperfectly calibrated counterpart of \\(c\\) at \\(w\\) assigns to each\nproposition \\(A\\) the frequency of truths at \\(w\\) amongst all\npropositions to which \\(c\\) assigns the same credence that it assigns\nto \\(A\\). Note that \\(c^w\\) is perfectly calibrated at \\(w\\). And if\n\\(c\\) is perfectly calibrated at \\(w\\), then \\(c^w = c\\). Now, we\ndefine the distance that a credence function \\(c\\) lies from\ncalibration at a world \\(w\\) to be the distance, \\(\\mathfrak{D}(c^w,\nc)\\), from \\(c^w\\) to \\(c\\). Now, as we saw in Objection 1 from\n section 4.3\n above, this measure does not itself give a measure of epistemic\ndisutility. The problem is that an agent can move closer to\ncalibration at a world \\(w\\) while moving uniformly further from the\nomniscient credence function at that world: that is, the measure of\nepistemic disutility provided by the distance of the credence function\nfrom its perfectly calibrated counterpart is not truth-directed. Thus,\nif an agent’s distance from her perfectly calibrated counterpart\nis to contribute to a measure of her inaccuracy, it must be\nsupplemented by something that ensures that the resulting measure\navoids this consequence. The idea that Pettigrew proposes is this: the\ninaccuracy of \\(c\\) at \\(w\\) is given by the distance of \\(c\\) from\nthe omniscient credence function \\(v_w\\) at \\(w\\); and that is given\nby adding the distance of \\(c\\) from its perfectly calibrated\ncounterpart \\(c^w\\) to the distance of \\(c^w\\) from \\(v_w\\). Thus,\nwhile moving to a credence function that is closer to its perfectly\ncalibrated counterpart may move you further from the omniscient\ncredence function, this can only be because the perfectly calibrated\ncounterpart of your new credence function is further from the\nomniscient credence function than the perfectly calibrated counterpart\nof your current credence function. If their perfectly calibrated\ncounterparts are the same, or if they are different but equally close\nto the omniscient credence function, then moving closer to them will\nmove you closer to the omniscient credence function. Thus, Pettigrew\nimposes the following constraint: \nDecomposition Suppose \\(\\mathfrak{I}\\) is a\nlegitimate inaccuracy measure and \\(\\mathfrak{D}\\) is a distance\nmeasure such that \\(\\mathfrak{I}(c, w) = \\mathfrak{D}(v_w, c)\\). Then\n\n\\[\\mathfrak{I}(c, w) = \\mathfrak{D}(v_w, c) = \\mathfrak{D}(c^w, c) + \\mathfrak{D}(v_w, c^w)\\] \nTogether with the other conditions that Pettigrew imposes,\nDecomposition narrows down the class of legitimate\ninaccuracy measures to a single one, namely, the Brier score. That is,\nimposing these conditions entails\n Brier Inaccuracy. \nObjection 1: Appeal to summation is arbitrary. One concern\nabout Decomposition is this: it is crucial for the\nproof that the Brier score and only the Brier score satisfies all of\nPettigrew’s conditions that in Decomposition we\ncombine the distance between \\(c\\) and \\(c^w\\) with the distance\nbetween \\(c^w\\) and \\(v_w\\) by summing them together. But we could\nhave combined those quantities in other ways: we might have multiplied\nthem together, for instance; or, we might have summed them and then\ntaken a strictly increasing function of that sum. It might be\nmathematically natural simply to add them together: but that\ndoesn’t privilege that means of combining them for philosophical\npurposes. However, if we combine them in any of these alternative\nways, Pettigrew’s conditions will no longer hold of the Brier\nscore. \nObjection 2: Proximity to calibration is not a good. Another\nconcern is that, while proximity to being perfectly calibrated seems\nepistemically good in the standard cases that are used to motivate\ncalibrationist accounts, it seems less compelling in other cases. For\ninstance, suppose you have opinions only about three propositions:\nFirst coin toss lands heads, Second coin toss lands\nheads, Third coin toss lands heads. And suppose you\nassign to each of them the same credence, \\(\\frac{1}{3}\\). Then, in\nthat situation, it seems plausible that you are doing better if one\nout of the three tosses comes up heads. Now suppose that I have\nopinions only about three propositions: Djibouti is the capital of\nGhana, Serena Williams is a badminton player, Doris\nLessing wrote The Golden Notebook. And suppose I assign\nto each of them the same credence, \\(\\frac{1}{3}\\). Then, in that\nsituation, do we really retain the intuition that I do best if one out\nof the three turns out true? \nIn many of the accounts of inaccuracy measures that we’ve\nconsidered, such as those that propose the Brier score, the inaccuracy\nof a whole credence function is given by the sum of the inaccuracies\nof the individual credences it comprises; and the inaccuracy of every\nindividual credence is measured using the same local inaccuracy\nmeasure. You might object, however, that not all credences should be\ncontribute equally to the overall inaccuracy of a credence function of\nwhich they are a part. The accuracy of my credence that general\nrelativity is correct is surely more important and contributes more to\nthe overall epistemic utility of my credence function than the\naccuracy of my credence that there are 1,239,382 blades of grass on my\nfront lawn. Now, we might accommodate this intuition by taking the\ninaccuracy of the whole credence function to be not the straight sum\nof the local inaccuracies of the credences it assigns, but rather the\nweighted sum, where a credence gets greater weight the more important\nthe proposition to which it is assigned is. Now, as Predd, et al.\n(2009) show, if we define global inaccuracy like this, and if the\nimportance of a proposition is the same at every world, then an\nanalogue of Theorem 4 still holds and we can still establish\nProbabilism. However, Ben Levinstein (2018) shows\nthat, if the importance of a proposition changes from world to world,\nthe analogue of Theorem 4 will fail and with it the accuracy dominance\nargument for Probabilism. And, he argues, the\nimportance of a proposition does often change from world to world. In\nworlds where I have a brother, propositions that concern his\nwell-being have great importance to me, and the accuracy of my\ncredences in them should contribute greatly to the epistemic utility\nof my whole credence function; in worlds where I am an only child, on\nthe other hand, the importance of these propositions is much\ndiminished, as is the contribution of the accuracy of my credences in\nthem to my total epistemic utility. \nSo far, we have considered the two components of the first premise of\nJoyce’s accuracy argument for Probabilism:\n Credal Veritism\n and\n Joycean Inaccuracy.\n We have left the former intact, but we have seen concerns with the\nlatter, and we have considered arguments for a stronger claim,\n Brier Inaccuracy,\n though these also face difficulties. In this section, we move from\nthe account of epistemic disutility on which the argument is based to\nthe decision-theoretic principle to which we appeal in order to derive\nProbabilism from this account. Let’s recall the\nversion of the principle to which Joyce appeals in his original\npaper: \n Naive Dominance\n A rational agent will not adopt an option when there is another\noption that has lower disutility at all worlds. \nThat is: Suppose \\(\\mathcal{O}\\) is a set of options, \\(\\mathcal{W}\\)\nis the set of possible worlds, and \\(\\mathfrak{U}\\) is a disutility\nfunction. Then, if \\(o^*\\) is an option, and if there is another\noption \\(o'\\) such that \\(\\mathfrak{U}(o', w) < \\mathfrak{U}(o^*,\nw)\\) for all worlds \\(w\\) in \\(\\mathcal{W}\\), then \\(o^*\\) is\nirrational. \nThus, according to Joyce, a credence function is irrational if it is\naccuracy dominated. \nIn this section, we’ll consider four objections that have been\nraised against\n Naive Dominance\n in the context of the accuracy argument for\nProbabilism. \nThe first objection to the application of\n Naive Dominance\n in the context of the accuracy argument for\nProbabilism was first stated in an unpublished\nmanuscript by Aaron Bronfman entitled “A Gap in Joyce’s\nProof of Probabilism”; it has been discussed by Hájek\n(2008) and Pettigrew (2010, 2013b). The starting point for the\nobjection is the observation that\n Credal Veritism\n and\n Joycean Inaccuracy\n do not together narrow down the class of legitimate measures of\nepistemic disutility to a single function; they characterize a family\nof such measures. But, for all that\n Theorem 4\n (Joyce’s Main Theorem) tells us, it may well be that, for a\ngiven non-probabilistic credence function \\(c^*\\), different measures\nin this family of legitimate inaccuracy measures give different sets\nof credence functions that accuracy dominate \\(c^*\\). Thus, an agent\nwith a non-probabilistic credence function \\(c^*\\) might be faced with\na range of credence functions, each of which accuracy dominates\n\\(c^*\\) relative to a different legitimate inaccuracy measure.\nMoreover, it may be that any credence function that accuracy dominates\n\\(c^*\\) relative to Joycean inaccuracy measure \\(\\mathfrak{I}\\) does\nnot accuracy dominate \\(c^*\\) relative to the alternative Joycean\nmeasure \\(\\mathfrak{I}'\\); indeed, it may be that any credence\nfunction that dominates \\(c^*\\) relative to \\(\\mathfrak{I}\\) risks\nvery high inaccuracy at some world relative to \\(\\mathfrak{I}'\\), and\nvice versa. In this situation, it is plausible that the agent\nis rationally permitted to stick with her non-probabilistic credence\nfunction \\(c^*\\). \nThere are two replies to this objection. According to the first, the\nobjection relies on a false meta-normative claim; according to the\nsecond, it misunderstands the purpose of Joyce’s conditions. \nReply 1: No requirement to give advice. The meta-normative\nclaim on which the objection seems to rely is the following: For a\nnorm to hold, there must be specific advice available to those who\nviolate that norm concerning how to improve their behaviour.\nBronfman’s objection begins with the observation that, for any\nspecific advice that one might give to a non-probabilistic agent\nconcerning which credence function she should adopt in favour of her\nown, there will be inaccuracy measures that satisfy Joyce’s\nconditions, but don’t sanction this advice; indeed, there will\nbe inaccuracy measures relative to which that advice is very bad.\nThus, Joyce’s accuracy argument violates the meta-normative\nconstraint. But, the reply submits, the meta-normative claim is false:\nfor a norm to hold, it is sufficient that there is a serious defect\nsuffered by those who violate the norm that is not shared by those who\nsatisfy the norm; it is not also required that there should be advice\non which specific action an agent should perform to improve her\nbehaviour. And Joyce’s argument satisfies this sufficient\ncondition. An agent ought to satisfy Probabilism\nbecause non-probabilistic credence functions suffer from a serious\nepistemic defect (namely, being accuracy dominated) that does not\nbeset probabilistic ones. And this fact is “supertrue”, so\nto speak: that is, it is true on any precisification of the notion of\naccuracy that obeys Joyce’s conditions on an inaccuracy\nmeasure. \nReply 2: Each agent uses a single inaccuracy measure. The\nsecond reply to this objection does not take issue with the\nmeta-normative claim mentioned above; indeed, on the understanding of\nthe accuracy argument for Probabilism that it\nproposes, the argument satisfies the necessary condition imposed by\nthat claim. That is, according to this reply, the accuracy argument,\nproperly understood, does in fact provide specific advice to\nnon-probabilistic agents. The idea is this: There are (at least) three\nways to understand the purpose of Joyce’s conditions on\ninaccuracy measures. First, we might think that the notion of\ninaccuracy is vague; and we might say that any inaccuracy measure that\nsatisfies the conditions is a legitimate precisification of it. This\nis a supervaluationist approach. On this approach, there is\nno specific advice available to non-probabilistic agents that is\nsanctioned by all precisifications. Second, we might think that the\nnotion of inaccuracy is precise, but that we have only limited\nknowledge about it, and that the sum total of our knowledge is\nembodied in the conditions. This is an epistemicist approach.\nOn this approach, there is specific advice, but it is not available to\nus. Third, we might think that there is no objectively correct\ninaccuracy measure; rather, any inaccuracy measure that satisfies the\nconditions is rationally permissible. But nonetheless, any particular\nagent has exactly one such measure. This is a subjectivist\napproach. On this understanding, there is specific advice for any\nnon-probabilistic agent. Any such agent uses an inaccuracy measure\nthat satisfies Joyce’s conditions. And this gives, for any\nnon-probabilistic credence function, a probabilistic credence function\nthat strongly dominates it. So the specific advice is this: adopt one\nof the probabilistic credence functions that strongly dominates your\nnon-probabilistic credence function relative to your favoured measure\nof inaccuracy. This gives us Probabilism and does so\nwithout violating the meta-normative claim on which Bronfman’s\nobjection relies. \nHowever, this response isn’t without its own problems. For\ninstance, it assumes that each agent values inaccuracy in a\nsufficiently specific way that they narrow down the class of\ninaccuracy measures to a single measure that they can then use to\nobtain this advice. But, at least for those who think that\n Joycean Inaccuracy\n is the strongest condition we can place on the inaccuracy measures,\nthis seems too strong. How can we assume that each rational agent will\nhave a unique inaccuracy measure in mind when we don’t think\nthat there are conditions that demand that we narrow down the class of\nlegitimate inaccuracy measures this far? \nThe second objection to\n Naive Dominance\n comes from Pettigrew (2014a). Here, Pettigrew observes that there are\ndecisions in which\n Naive Dominance\n does not seem to hold because the irrationality of being dominated\ndepends on the status of the dominating options in some way.\nHere’s Pettigrew’s central example: \nName Your Fortune\\(^*\\) You have a choice: play a\ngame with God or don’t. If you don’t, you receive 2 utiles\nfor sure. If you do, you then pick an integer. If you pick \\(k\\), God\nwill then do one of two things: (i) give you \\(2^{k-1}\\) utiles; or\n(ii) give you \\(2 - \\frac{1}{2^{k-1}}\\) utiles. (Pettigrew 2014a:\n587) \nIn this example, the only option that isn’t dominated is the\noption in which you do not play the game with God. If you choose that\noption, you get 2 utiles for sure. If, on the other hand, you choose\nto play the game and pick integer \\(k\\), then choosing integer \\(k+1\\)\nwill be guaranteed to get you more utility: either \\(2^{k+1}\\) utiles\ncompared with \\(2^k\\) or \\(2 - \\frac{1}{2^k}\\) utiles compared with\n\\(2 - \\frac{1}{2^{k-1}}\\). However, the option in which you get 2\nutiles for sure seems a lousy option given the other possibilities\navailable. One way to see this is as follows: Take a probability\ndistribution over the two possibilities (i) and (ii) between which God\nwill choose if you choose to play; then, providing it doesn’t\nassign all probability to God choosing (i), there will be some option\nyou can take if you play the game that has greater expected utility\nthan the option of not playing the game. If\n Naive Dominance\n is correct, however, not playing the game is the only rational\noption. This seems to tell against\n Naive Dominance. \nThe moral that Pettigrew draws from this example is the following. Not\nall dominated options are irrational. Whether or not a dominated\noption is irrational depends on the status of the options that\ndominate it. If all of the options that dominate a given option are\nthemselves dominated, then being dominated does not rule out the given\noption as irrational. Thus, in\n Name Your Fortune\\(^*\\),\n none of the options are ruled irrational because they are dominated;\nafter all, all of the dominated options are only dominated by other\noptions that are also themselves dominated. Thus, Pettigrew instead\nsuggests a decision-theoretic principle to replace\n Naive Dominance.\n To state it, we must distinguish between two notions of dominance: a\nstrong notion and a weak notion. Suppose \\(o^*\\) and \\(o'\\) are\noptions. We say that \\(o^*\\) strongly dominates \\(o'\\) if\n\\(o^*\\) has greater utility than \\(o'\\) at all worlds. We say that\n\\(o^*\\) weakly dominates \\(o'\\) if \\(o^*\\) has at least as\ngreat utility as \\(o'\\) at all worlds and greater utility at some\nworld. \nUndominated Dominance A rational agent will not adopt\nan option that is strongly dominated by an option that is not itself\neven weakly dominated. \nNow, it turns out that, if we accept\n Brier Inaccuracy,\n we can still derive Probabilism using only\nUndominated Dominance. This is a consequence of the\nfollowing theorem: \nTheorem 5 (de Finetti) Suppose that \\(c^*\\) is a\ncredence function in \\(\\mathcal{C_F}\\) that violates\nProbabilism. Then  \nThus, we have the following argument: \nBrier-based accuracy argument for Probabilism: II \nThe next objection to\n Naive Dominance\n is similar to the objection raised in the previous section. In the\nprevious section, the moral we drew from\n Name Your Fortune\\(^*\\)\n is that a dominated option is only ruled irrational in virtue of\nbeing dominated if at least one of the options that dominate it is not\nitself dominated. But there may be other features that a credence\nfunction might have besides itself being dominated such that being\ndominated by that credence function does not entail irrationality.\nEaswaran & Fitelson (2012) suggest the following feature. Suppose\nthat your credence function is non-probabilistic, but it matches the\nevidence that you have: that is, the credence it assigns to a\nproposition matches the extent to which your evidence supports that\nproposition. And suppose that none of the credence functions that\naccuracy dominate your credence function have that feature. Then, we\nmight say, the fact that your credence function is accuracy dominated\ndoes not rule it irrational. After all, it is dominated only by\ncredence functions that violate the constraints that your evidence\nimposes on your credences. Thus, Easwaran and Fitelson suggest the\nfollowing decision-theoretic principle, which applies only when the\noptions in question are credence functions: \nEvidential Dominance A rational agent will not adopt\na credence function that is strongly dominated by an alternative\ncredence function that is not itself even weakly dominated and which\nmatches the agent’s evidence if the dominated credence function\ndoes. \nEaswaran and Fitelson then object that there are situations in which\nEvidential Dominance does not entail\nProbabilism. For instance, suppose that a trick coin\nis about to be tossed. Your evidence tells you that the chance of it\nlanding heads is 0.7. Your credence that it will lands heads is 0.7\nand your credence that it will land tails is 0.6. Then you might think\nthat your credences match your evidence, because you have evidence\nonly about it landing heads and your credence that it will land heads\nequals the known chance that it will land heads. However, it turns out\nthat all of the credence functions that accuracy dominate your\ncredence function (when accuracy is measured by the Brier score) fail\nto match this evidence: that is, they assign credence other than 0.7\nto Heads. Thus, Evidential Dominance does\nnot entail that your credence function is irrational.\n Figure 2\n illustrates this result. Pettigrew (2014a) responds to this objection\non behalf of the accuracy argument for\nProbabilism. \nFigure 2: In this figure, as in\n Figure 1,\n we plot the various possible credence functions defined on a\nproposition Heads and its negation Tails in the unit\nsquare. The diagonal line contains all and only the probability\nfunctions. Let \\(c^*\\) be your credence function: that is, it assigns\n0.7 to Heads and 0.6 to Tails. So it violates\nProbabilism. The credence functions that lie between\nthe two arcs are all and only the credence functions that accuracy\ndominate \\(c^*\\). The credence functions on the dashed line are all\nand only the credence functions that match your evidence that the\nchance of Heads is 0.7. Notice that the dashed line does not\noverlap with the set of credence functions that accuracy dominate\nyours at any point. This is the crucial fact on which Easwaran and\nFitelson’s objection rests.  \nThe final objection to\n Naive Dominance\n comes from Hilary Greaves (2013) and Michael Caie (2013), who point\nout that, in practical decision theory, only a restricted version of\nthat principle is accepted (see also Jenkins 2007; Berker 2013a,b;\nCarr 2017). To see why such a restriction is needed, consider the\nfollowing case: \nDriving Test My driving test is in a week’s\ntime. I can choose now whether or not I will practise for it. Other\nthings being equal, I prefer not to practise. But I also want to pass\nthe test, and I know that I won’t pass if I don’t\npractise, and I will pass if I do. Here is my decision table: \nAccording to\n Naive Dominance,\n it is irrational to practise. After all, whether or not I pass or\nfail, I obtain higher utility if I don’t practise, so not\npractising strongly dominates practising. But this is clearly the\nwrong result. The reason is that I should not compare practising at\nthe world at which I pass with not practising at that world, and\npractising at the world at which I fail with not practising at that\nworld. For if I practise, I will pass; and if I don’t, I will\nfail. Moreover, I know all this. So I should compare practising at the\nworld at which I pass with not practising at the world at which I\nfail. And then my utility is higher if I practise. \nThe moral of this example is that\n Naive Dominance\n should be restricted so that it applies only in situations in which\nthe options between which the agent is choosing will not influence the\nway the world is if they are adopted. Such situations are sometimes\ncalled situations of act-state independence. In situations in\nwhich the acts (options) influence the states (of the world),\n Naive Dominance\n does not apply. To see how this affects the accuracy argument for\nProbabilism, consider the following example, which\nborrows from Caie’s and Greaves’ examples: \nThwarted Accuracy Suppose I can read your mind. You\nhave opinions only about two propositions, \\(A\\) and \\(\\neg A\\). And\nsuppose that I have control over the truth of \\(A\\) and \\(\\neg A\\). I\ndecide to do the following. First, define the non-probabilistic\ncredence function \\(c^\\dag(A) = 0.99\\) and \\(c^\\dag(\\neg A) = 0.005\\).\nThen: \nIn this case, since the credence function \\(c^\\dag\\) is not a\nprobability function, it is accuracy dominated by Joyce’s\ntheorem and thus it is ruled out as irrational by\n Naive Dominance,\n just as the option of practising is ruled out as irrational in\nDriving Test. However, this is a situation in which adopting an option\ninfluences the way the world is in such a way that it affects the\nutility of the option, just as choosing whether or not to practise\ndoes in Driving Test. If I were to have credence function \\(c^\\dag\\),\nI would be more accurate than I would be were I to have any other\ncredence function. Thus, it seems that, just as we said that\npractising is in fact the only option that shouldn’t be ruled\nirrational in Driving Test, so now we must say that credence function\n\\(c^\\dag\\) is the only option that shouldn’t be ruled irrational\nin Thwarted Accuracy. But of course, it then follows that\nProbabilism is false, for there are situations such\nas this one in which it is irrational to do anything other than have a\nnon-probabilistic credence function. \nThere are three responses available here: the first is to bite the\nbullet, accept the restriction to\n Naive Dominance,\n and therefore accept a restriction on the cases in which\nProbabilism holds; the second is to argue that the\npractical case and the epistemic case are different, with different\ndecision-theoretic principles applying to each; the third, of course,\nis to abandon the accuracy argument for Probabilism.\nJoyce (2018) and Pettigrew (2018a) argue for the first response. They\nadvocate different decision-theoretic principles to replace\n Naive Dominance\n in the epistemic case: Joyce advocates standard causal decision\ntheory together with a Ratifiability condition (Jeffrey 1983);\nPettigrew omits the ratifiability condition. But they both agree that\nthese principles will agree with\n Naive Dominance\n in cases of act-state independence; and they agree with the verdict\nthat \\(c^\\dag\\) is the only credence function that isn’t ruled\nout as irrational in Thwarted Accuracy. Konek & Levinstein (2019)\nargue for the second response, claiming that, since doxastic states\nand actions have different directions of fit, different\ndecision-theoretic principles will govern them. They hold that\n Naive Dominance\n (or, perhaps, Undominated Dominance) is the correct\nprinciple when the options are credence functions, even though it is\nnot the correct principle when the options are actions. Caie (2013)\nand Berker (2013b), on the other hand, argue for the third option. \nIn\n section 5.4.2,\n we introduced Undominated Dominance and we stated Theorem 5, which\nsays that every non-probabilistic credence function \\(c^*\\) defined on\n\\(\\mathcal{F}\\) is accuracy dominated by a credence function \\(c'\\)\ndefined on \\(\\mathcal{F}\\) that is itself not accuracy dominated by a\ncredence function \\(c\\) defined on \\(\\mathcal{F}\\). But you might\nthink that this is still not sufficient to establish\nProbabilism. After all, while \\(c'\\) is not itself\ndominated by a credence function defined on \\(\\mathcal{F}\\), it might\nbe accuracy dominated by a credence function \\(c^\\dag\\) defined on\nsome other set of propositions \\(\\mathcal{F}^\\dag\\). For instance,\ntake the non-probabilistic credence function \\(c^*\\) defined on\n\\(\\mathcal{F} = \\{X, \\neg X\\}\\), where \\(c^*(X) = 0.6 = c^*(\\neg X)\\).\nIt is Brier dominated by \\(c'(X) = 0.5 = c'(\\neg X)\\), since \\(c^*\\)\nhas Brier score \\(|1-0.6|^2 + |0-0.6|^2 = 0.52\\) at both worlds in\n\\(\\mathcal{W_F}\\) while \\(c'\\) has \\(|1-0.5|^2 + |0-0.5|^2 = 0.5\\) at\nboth worlds. But \\(c'\\) is Brier dominated by \\(c^\\dag\\) defined on\n\\(\\mathcal{F}^\\dag = \\{X\\}\\), where \\(c^\\dag(X) = 0.5\\), since this\nhas Brier score \\(|1-0.5|^2 = |0-0.5|^2 = 0.25\\) at both worlds. A\nnatural reaction to this is to define the epistemic disutility\nfunction to be the average Brier score rather than the\ntotal Brier score: \nNow, relative to \\(\\mathfrak{B}'\\), \\(c^*\\) is indeed accuracy\ndominated by \\(c'\\) and \\(c'\\) is not accuracy dominated by\n\\(c^\\dag\\). But \\(c'\\) is accuracy dominated by \\(c^+\\) defined on\n\\(\\mathcal{F}^+ = \\{\\top\\}\\), where \\(c^+(\\top) = 1\\), since the\naverage Brier score of \\(c^+\\) is \\(\\frac{1}{1}|1-1|^2 = 0\\) at all\nworlds, while the average Brier score of \\(c'\\) is\n\\(\\frac{1}{2}(|1-0.5|^2 + |0-0.5|^2) = 0.25\\) at all worlds. Jennifer\nCarr (2015) initiated the investigation into how epistemic utility\narguments for Probabilism might work when we start to\ncompare credence functions defined on different sets of propositions.\nShe notes the analogy with population axiology in ethics (see entry on\n the repugnant conclusion).\n Pettigrew (2018b) takes this analogy further, proving an\nimpossibility result analogous to those prevalent in that part of\nethics. \nSo far, we have considered calibration arguments and accuracy\narguments for Probabilism. In each of these cases, we\nidentify a particular feature of a credence function—the\nproximity of its credences to being calibrated, or their proximity to\nthe omniscience credences—we claim that it is the source of all\nepistemic utility, and we attempt to characterize the mathematical\nfunctions that legitimately measure the extent to which the credence\nfunction has that feature. In this section, we consider an argument\ndue to Joyce (2009) that attempts to characterize epistemic disutility\nfunctions directly. \nJoyce’s central condition is Coherent\nAdmissibility, which says that a measure of epistemic\ndisutility should never render a probabilistic credence function\nweakly dominated. More precisely: \nCoherent Admissibility Suppose \\(\\mathcal{F}\\) is a\nset of propositions and \\(\\mathfrak{D}: \\mathcal{C_F} \\times\n\\mathcal{W_F} \\rightarrow [0, \\infty]\\) is a measure of epistemic\ndisutility. Then, if \\(c^*\\) is a probabilistic credence function,\nthen \\(c^*\\) is not weakly dominated relative to \\(\\mathfrak{D}\\).\nThat is, for any probabilistic credence function \\(c^*\\), there is no\ncredence function \\(c'\\) such that  \nWe then have two results concerning coherent admissible epistemic\ndisutility functions. On the first, we restrict attention to the case\nin which \\(\\mathcal{F}\\) is a partition, and we prove that, together\nwith Undominated Dominance, we can establish\nProbabilism; on the second, we focus on the case in\nwhich \\(\\mathcal{F}\\) is an algebra, and we prove that, together with\nNaive Dominance, we can establish\nProbabilism. \nTheorem 5 (Joyce 2009) Suppose \\(\\mathcal{F}\\) is a\nset of propositions and \\(\\mathfrak{D}\\) is a Joycean epistemic\ndisutility function for the credence functions in \\(\\mathcal{C_F}\\).\n \nLet’s say that Joycean Disutility is the claim\nthat all legitimate measures of epistemic disutility satisfy\nCoherent Admissibility along with the other new\nconditions that Joyce imposes. Then we have the following\nargument: \nJoycean epistemic disutility argument for\nProbabilism \nJoyce argues for Coherent Admissibility as\nfollows. \nLet’s consider two objections to this argument. \nObjection 1: Not all probabilistic credence functions could be\nchance functions. The first objection denies (1). It’s due\nto Alan Hájek (2008). As Hájek notes, if a credence\nfunction \\(c\\) is defined on propositions about the chances\nthemselves, it’s not obvious that any chance function will be\ndefined on that proposition. If that’s right \\(c\\) is not a\npossible chance function. And his argument might be extended. We can\nassign a credence function on propositions concerning ethical matters,\nor mathematical matters, or aesthetic matters, or facts about the\ncurrent time or the agent’s current location. But it is not\nclear that such a credence function could possibly be the chance\nfunction of any world, since it seems natural to think that chances\ncannot attach to these sorts of proposition. Pettigrew (2014b: 5.2.1)\nreplies on Joyce’s behalf. \nObjection 2: The argument over-generates. The second\nobjection claims that, in the absence of Probabilism,\nwhich is supposed to be the conclusion of the argument for which\nCoherent Admissibility is a crucial part, this\nargument overgenerates. Consider, for instance, the following\nclaim: \nNow, suppose \\(c^\\dag\\) is a non-probabilistic credence function and\napply the version of Joyce’s argument that results from\nreplacing (2) with (2’). That is, we assume that it is possible\nthat the agent learn with certainty that \\(c^\\dag\\) is the unique\nrational response to her evidence, even if in fact it is not. We might\nassume, for instance, that a mischievous God whispers in the\nagent’s ear that this is the case. Then we must conclude that\n\\(c^\\dag\\) is not weakly dominated relative to any legitimate measure\nof epistemic disutility. But now we have that no credence function is\nweakly dominated, whether it is probabilistic or not. And, combined\nwith Joyce’s other considerations, this is impossible. If no\nprobabilistic credence functions are weakly dominated relative to an\nepistemic disutility function, then all of the non-probabilistic\ncredence functions are: that’s the lesson of\n Theorem 5\n above. Of course, the natural response to this objection is to note\nthat (2’) only holds when \\(c\\) is a probabilistic credence\nfunction. But such a restriction is unmotivated until we have\nestablished Probabilism. \nWe have considered a number of different characterizations of the\nlegitimate ways of measuring (in)accuracy and epistemic (dis)utility.\nEach has assumed that the measures of these quantities are numerically\nrepresentable; that is, each assumes it makes sense to use real\nnumbers to measure these quantities. Conor Mayo-Wilson and Greg\nWheeler call this assumption into question (Mayo-Wilson & Wheeler,\nms.). They argue that, in order to represent a quantity numerically,\nyou need to prove a representation theorem for it in measurement\ntheory. And, if you wish to use that quantity as a measure of utility,\nor as a component of a measure of utility, you need to prove a\nrepresentation theorem not only for the quantity itself, but for its\nuse in expected utility calculations. They note that this was the\npurpose of the representation theorems of von Neumann &\nMorgenstern as well as Savage and Jeffrey (see entry on\n normative theories of rational choice: expected utility).\n And they argue that the methods that these authors use are not\navailable to the proponent of epistemic utility arguments.  \nThat completes our survey of the existing literature on the epistemic\nutility arguments for Probabilism. We have considered three families\nof argument: calibration arguments, accuracy arguments, and epistemic\ndisutility arguments. In this final section, we briefly consider ways\nin which the argument strategy employed here (and described in\n section 2)\n might be generalised. \nWe have assumed throughout that the set of propositions on which an\nagent’s credence function is defined is finite. What happens\nwhen we lift this restriction? The first problem is that we need to\nsay how to measure the inaccuracy of a credence function defined over\nan infinite set of propositions. Then, having done that, we need to\nsay which such credence functions are accuracy dominated relative to\nthese measures, and which aren’t. \nSean Walsh has described an extension of the Brier score to the\ncase in which the set of propositions to which we assign credences is\ncountably infinite; and he has shown that non-probabilistic credence\nfunctions on such sets are accuracy dominated relative to that\ninaccuracy measure, while probabilistic ones aren’t. (For a description of Walsh's unpublished work, see Kelley 2019). Mikayla\nKelley (2019) has then gone considerably further and generalized\nWalsh’s results significantly by describing a wide range of\npossible inaccuracy measures and characterizing the undominated\ncredence functions defined on sets of propositions of different\nvarieties. One interesting consequence is that an accuracy dominance\nargument for the norm of Countable Additivity does not seem to be\nforthcoming. \nWe have focussed here on the synchronic coherence principle of\nProbabilism. But there are many other principles that\nare thought to govern rational credence. It is natural to ask whether\nwe can give similar arguments for those. As we saw above in\n section 5.2,\n a number of epistemic norms have been explored in this framework, but\nof course there are many more still to consider. \nIn this entry, we have considered agents represented as having precise\ncredence functions. But there are, of course, many other models of\ndoxastic states that are considered in current epistemology. As\nmentioned at the outset, we might represent an agent by the set of\npropositions that they believe (their full beliefs); or we might\nrepresent them using a set of precise credence functions (their\nimprecise credences); or a comparative confidence ordering; or a\nprecise primitive conditional probability function. And, when modelled\nin this way, there are principles of rationality that apply to these\nagents. Are there accuracy arguments in their favour? \nIn the case of full beliefs, it is reasonably straightforward to\ndefine the measures of accuracy: a belief in a proposition receives\nsome positive epistemic utility \\(R\\) when the proposition is true and\nsome negative epistemic utility \\(-W\\) when it is false; and if you\nsuspend judgment on a proposition, you receive epistemic utility 0\nwhether it is true or false. Kenny Easwaran (2015) and Kevin Dorst\n(2017) explore the consequences of this account and show that it\nnaturally gives rise to what is known as the Lockean account of the\nrelationship between credences and full beliefs. Relative to a\nprobability function \\(c\\), you maximise your expected epistemic\nutility by believing a proposition \\(A\\) iff \\(c(A) >\n\\frac{W}{R+W}\\). \nIn the case of imprecise credences, it is much less straightforward to\ndefine the measures of accuracy. Indeed, there are a number of\npowerful results that seem to show that there can be no measures that\nsatisfy some basic plausible conditions (Seidenfeld, Schervish, &\nKadane 2012, Schoenfield 2015, Mayo-Wilson & Wheeler 2016). To see\nhow these work, note that one of the central motivations for\nrepresenting an agent’s credences using imprecise credences is\nthat there are often situations in which our evidence seems to demand\nthat our credences are not captured by a single precise credence\nfunction. When our evidence is complex, mixed, and ambiguous, we might\nwell think only an imprecise credal state is an appropriate response.\nHowever, as these various results show, if your accuracy measure\nsatisfies certain plausible conditions, then for any imprecise credal\nstate, there is a precise one that is at least as accurate as the\nimprecise one at all worlds. But if that’s the case, Veritism\nsays that it would be just as good to have the precise state as the\nimprecise one. But that goes against the requirements of our evidence.\nJason Konek (2019, section 3) offers a response to these impossibility\nresults on behalf of the epistemic utility theorist who wishes to use\nimprecise credences to represent agents.  \nIn all of the arguments we’ve surveyed above, we have assumed\nthat classical logic governs the propositions to which our agent\nassigns credences. This secures Probabilism, which demands, among\nother things, that an agent assign maximal credence to every classical\ntautology. But what happens if we drop this assumption? What if,\ninstead, the propositions are governed by a three-valued logic, such\nas strong Kleene logic or the Logic of Paradox (see entry on\n many-valued logic)?\n In a series of papers, Robbie Williams has built on mathematical\nresults by Jeff Paris and Jean-Yves Jaffray to understand what norms\nof credence the accuracy arguments establish in this case (Williams\n2012a,b, 2018, Paris 2001, Jaffray 1989). I’ll give a single\nexample here to illustrate. Strong Kleene logic has three truth\nvalues: true, false, and neither. Our first\nquestion is this: what is the omniscient credence in a proposition\nthat is neither true nor false? Williams argues that it should be\nzero. And then he shows that, if we measure the inaccuracy of a\ncredence function at a world as its distance from the omniscient\ncredence function at that world in the usual way, then the credence\nfunctions that are not accuracy dominated are precisely those that\nsatisfy the norm of Generalized Probabilism: \nGeneralized Probabilism Suppose \\(\\models\\) is the\nlogical consequence relation of the correct logic. A rational\nagent’s credence function \\(c\\) at a given time is a generalized\nprobability function for that logic. That is: \nNote that, if \\(\\models\\) is classical, then Generalized Probabilism\nis equivalent to Probabilism. ","contact.mail":"richard.pettigrew@bris.ac.uk","contact.domain":"bris.ac.uk"}]
