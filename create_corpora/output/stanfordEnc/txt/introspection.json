[{"date.published":"2010-02-02","date.changed":"2019-10-18","url":"https://plato.stanford.edu/entries/introspection/","author1":"Eric Schwitzgebel","author1.info":"http://www.faculty.ucr.edu/~eschwitz/","entry":"introspection","body.text":"\n\n\nIntrospection, as the term is used in contemporary philosophy of mind,\nis a means of learning about one’s own currently ongoing, or\nperhaps very recently past, mental states or processes. You can, of\ncourse, learn about your own mind in the same way you learn about\nothers’ minds—by reading psychology texts, by observing\nfacial expressions (in a mirror), by examining readouts of brain\nactivity, by noting patterns of past behavior—but it’s\ngenerally thought that you can also learn about your mind\nintrospectively, in a way that no one else can. But what\nexactly is introspection? No simple characterization is widely\naccepted.\n\n\nIntrospection is a key concept in epistemology, since introspective\nknowledge is often thought to be particularly secure, maybe even\nimmune to skeptical doubt. Introspective knowledge is also often held\nto be more immediate or direct than sensory knowledge. Both of these\nputative features of introspection have been cited in support of the\nidea that introspective knowledge can serve as a ground or foundation\nfor other sorts of knowledge.\n\n\nIntrospection is also central to philosophy of mind, both as a process\nworth study in its own right and as a court of appeal for other claims\nabout the mind. Philosophers of mind offer a variety of theories of\nthe nature of introspection; and philosophical claims about\nconsciousness, emotion, free will, personal identity, thought, belief,\nimagery, perception, and other mental phenomena are often thought to\nhave introspective consequences or to be susceptible to introspective\nverification. For similar reasons, empirical psychologists too have\ndiscussed the accuracy of introspective judgments and the role of\nintrospection in the science of the mind.\n\nIntrospection is generally regarded as a process by means of which we\nlearn about our own currently ongoing, or very recently past, mental\nstates or processes. Not all such processes are introspective,\nhowever: Few would say that you have introspected if you learn that\nyou’re angry by seeing your facial expression in the mirror.\nHowever, it’s unclear and contentious exactly what more is\nrequired for a process to qualify as introspective. A relatively\nrestrictive account of introspection might require introspection to\ninvolve attention to and direct detection of one’s ongoing\nmental states; but many philosophers think attention to or direct\ndetection of mental states is impossible or at least not present in\nmany paradigmatic instances of introspection. \nFor a process to qualify as “introspective” as the term is\nordinarily used in contemporary philosophy of mind, it must minimally\nmeet the following three conditions: \nThe mentality condition: Introspection is a process that\ngenerates, or is aimed at generating, knowledge, judgments, or beliefs\nabout mental events, states, or processes, and not about\naffairs outside one’s mind, at least not directly. In this\nrespect, it is different from sensory processes that normally deliver\ninformation about outward events or about the non-mental aspects of\nthe individual’s body. The border between introspective and\nnon-introspective knowledge can begin to seem blurry with respect to\nbodily self-knowledge such as proprioceptive knowledge about the\nposition of one’s limbs or nociceptive knowledge about\none’s pains. But in principle the introspective part of such\nprocesses, pertaining to judgments about one’s mind—e.g.,\nthat one has the feeling as though one’s arms were crossed or of\ntoe-ishly located pain—can be distinguished from the\nnon-introspective judgment that one’s arms are in fact crossed\nor one’s toe is being pinched. \nThe first-person condition: Introspection is a process that\ngenerates, or is aimed at generating, knowledge, judgments, or beliefs\nabout one’s own mind only and no one else’s, at\nleast not directly. Any process that in a similar manner generates\nknowledge of one’s own and others’ minds is by that token\nnot an introspective process. (Some philosophers have contemplated\npeculiar or science fiction cases in which we might introspect the\ncontents of others’ minds directly—for example in\ntelepathy or when two people’s brains are directly wired\ntogether—but the proper interpretation of such cases is\ndisputable see, e.g., Gertler 2000.) \nThe temporal proximity condition: Introspection is a process\nthat generates knowledge, beliefs, or judgments about one’s\ncurrently ongoing mental life only; or, alternatively (or\nperhaps in addition) immediately past (or even future) mental\nlife, within a certain narrow temporal window (sometimes called the\nspecious present; see the entry on the\n experience and perception of time).\n You may know that you were thinking about Montaigne yesterday during\nyour morning walk, but you cannot know that fact by current\nintrospection alone—though perhaps you can know introspectively\nthat you currently have a vivid memory of having thought about\nMontaigne. Likewise, you cannot know by introspection alone that you\nwill feel depressed if your favored candidate loses the election in\nNovember—though perhaps you can know introspectively what your\ncurrent attitude is toward the election or what emotion starts to rise\nin you when you consider the possible outcomes. Whether the target of\nintrospection is best thought of as one’s current mental life or\none’s immediately past mental life may depend on one’s\nmodel of introspection: On self-detection models of introspection,\naccording to which introspection is a causal process involving the\ndetection of a mental state (see Section 2.2 below), it’s\nnatural to suppose that a brief lapse of time will transpire between\nthe occurrence of the mental state that is the introspective target\nand the final introspective judgment about that state, which invites\n(but does not strictly imply) the idea that introspective judgments\ngenerally pertain to immediately past states. On self-shaping and\nself-fulfillment models of introspection, according to which\nintrospective judgments create or embed the very state introspected\n(see Sections 2.3.1 and 2.3.2 below), it seems more natural to think\nthat the target of introspection is one’s current mental life or\nperhaps even the immediate future. \nFew contemporary philosophers of mind would call a process\n“introspective” if it does not meet some version of the\nthree conditions above, though in ordinary language the temporal\nproximity condition may sometimes be violated. (For example, in\nordinary speech we might describe as “introspective” a\nprocess of thinking about why you abandoned a relationship last month\nor whether you’re really as kind to your children as you think\nyou are.) However, many philosophers of mind will resist calling a\nprocess that meets these three conditions “introspective”\nunless it also meets some or all of the following three\nconditions: \nThe directness condition: Introspection yields judgments or\nknowledge about one’s own current mental processes relatively\ndirectly or immediately. It’s difficult to\narticulate exactly what directness or immediacy involves in the\npresent context, but some examples should make the import of this\ncondition relatively clear. Gathering sensory information about the\nworld and then drawing theoretical conclusions based on that\ninformation should not, according to this condition, count as\nintrospective, even if the process meets the three conditions above.\nSeeing that a car is twenty feet in front of you and then inferring\nfrom that fact about the external world that you are having a visual\nexperience of a certain sort does not, by this condition, count as\nintrospective. However, as we will see in Section 2.3.4 below, those\nwho embrace transparency theories of introspection may reject at least\nstrong formulations of this condition. \nThe detection condition: Introspection involves some sort of\nattunement to or detection of a\npre-existing mental state or event, where the introspective\njudgment or knowledge is (when all goes well) causally but\nnot ontologically dependent on the target mental state. For\nexample, a process that involved creating the state of mind that one\nattributes to oneself would not be introspective, according to this\ncondition. Suppose I say to myself in silent inner speech, “I am\nsaying to myself in silent inner speech, ‘haecceities of\napplesauce’”, without any idea ahead of time how I plan to\ncomplete the embedded quotation. Now, what I say may be true, and I\nmay know it to be true, and I may know its truth (in some sense)\ndirectly, by a means by which I could not know the truth of anyone\nelse’s mind. That is, it may meet all the four conditions above\nand yet we may resist calling such a self-attribution introspective.\nSelf-shaping (Section 2.3.2 below), expressivist (Section 2.3.3\nbelow), and transparency (Section 2.3.4 below) accounts of\nself-knowledge emphasize the extent to which our self-knowledge often\ndoes not involve the detection of pre-existing mental states; and\nbecause something like the detection condition is implicitly or\nexplicitly accepted by many philosophers, some philosophers (including\nsome but not all of those who endorse self-shaping, expressivist,\nand/or transparency views) would regard it as inappropriate to regard\nsuch accounts of self-knowledge as accounts of introspection\nproper. \nThe effort condition: Introspection is not constant,\neffortless, and automatic. We are not every minute of the day\nintrospecting. Introspection involves some sort of special reflection\non one’s own mental life that differs from the ordinary\nun-self-reflective flow of thought and action. The mind may monitor\nitself regularly and constantly without requiring any special act of\nreflection by the thinker—for example, at a non-conscious level\ncertain parts of the brain or certain functional systems may monitor\nthe goings-on of other parts of the brain and other functional\nsystems, and this monitoring may meet all five conditions\nabove—but this sort of thing is not what philosophers generally\nhave in mind when they talk of introspection. However, this condition,\nlike the directness and detection conditions, is not universally\naccepted. For example, philosophers who think that conscious\nexperience requires some sort of introspective monitoring of the mind\nand who think of conscious experience as a more or less constant\nfeature of our lives may reject the effort condition (Armstrong 1968,\n1999; Lycan 1996). \nThough not all philosophical accounts that are put forward by their\nauthors as accounts of “introspection” meet all of\nconditions 4–6, most meet at least two of those. Because of\ndifferences in the importance accorded to conditions 4–6, it is\nnot unusual for authors with otherwise similar accounts of\nself-knowledge to differ in their willingness to describe their\naccounts as accounts of “introspection”. \nAccounts of introspection differ in what they treat as the proper\ntargets of the introspective process. No major contemporary\nphilosopher believes that all of mentality is available to be\ndiscovered by introspection. For example, the cognitive processes\ninvolved in early visual processing and in the detection of phonemes\nare generally held to be introspectively impenetrable and nonetheless\n(in some important sense) mental (Marr 1983; Fodor 1983). Many\nphilosophers also accept the existence of unconscious beliefs or\ndesires, in roughly the Freudian sense, that are not introspectively\navailable (e.g., Gardner 1993; Velleman 2000; Moran 2001; Wollheim\n2003; though see Lear 1998). Although in ordinary English usage we\nsometimes say we are “introspecting” when we reflect on\nour character traits, contemporary philosophers of mind generally do\nnot believe that we can directly introspect character traits in the\nsame sense in which we can introspect some of our other mental states\n(especially in light of research suggesting that we sometimes have\npoor knowledge of our traits, reviewed in Taylor and Brown 1988;\nPaulhus and John 1998; Vazire 2010). \nThe two most commonly cited classes of introspectible mental states\nare attitudes, such as beliefs, desires, evaluations, and\nintentions, and conscious experiences, such as emotions,\nimages, and sensory experiences. (These two groups may not be wholly,\nor even partially, disjoint: Depending on other aspects of her view, a\nphilosopher may regard some or all conscious experiences as involving\nattitudes, and/or she may regard attitudes as things that are or can\nbe consciously experienced.) It of course does not follow from the\nfact (if it is a fact) that some attitudes are introspectible that all\nattitudes are, or from the fact that some conscious experiences are\nintrospectible that all conscious experiences are. Some accounts of\nintrospection focus on attitudes (e.g., Nichols and Stich 2003), while\nothers focus on conscious experiences (e.g., Hill 1991; Goldman 2006;\nSchwitzgebel 2012); and it is sometimes unclear to what extent\nphilosophers intend their remarks about the introspection of one type\nof target to apply to the other type. There is no guarantee that the\nsame mechanism or process is involved in introspecting all the\ndifferent potential targets. \nGenerically, this article will describe the targets of introspection\nas mental states, though in some cases it may be more apt to\nthink of the targets as processes rather than states. Also, in\nspeaking of the targets of introspection as targets, no\npresupposition is intended of a self-detection view of introspection\nas opposed to a self-shaping or containment or expressivist view (see\nSection 2 below). The targets are simply the states self-ascribed as a\nconsequence of the introspective process if the process works\ncorrectly, or if the introspective process fails, the states that\nwould have been self-ascribed. \nThough philosophers have not explored the issue very thoroughly,\naccounts also differ regarding the products of introspection.\nMost philosophers hold that introspection yields something like\nbeliefs or judgments about one’s own mind, but others prefer to\ncharacterize the products of introspection as “thoughts”,\n“representations”, “awareness”, or the like.\nFor ease of exposition, this article will describe the products of the\nintrospective process as judgments, without meaning to beg the\nquestion against competing views. \nThis section will outline several approaches to self-knowledge. Not\nall deserve to be called introspective, but an understanding of\nintrospection requires an appreciation of this diversity of\napproaches—some for the sake of the contrast they provide to\nintrospection proper and some because it’s disputable whether\nthey should be classified as introspective. These approaches are not\nexclusive. Surely there is more than one process by means of which we\ncan obtain self-knowledge. Unavoidably, some of the same territory\ncovered here is also covered, rather differently, in the entry on\n self-knowledge. \nSymmetrical or self/other parity accounts of self-knowledge\ntreat the processes by which we acquire knowledge of our own minds as\nessentially the same as the processes by which we acquire knowledge of\nother people’s minds. A simplistic version of this view is that\nwe know both our own minds and the minds of others only by observing\noutward behavior. On such a view, introspection strictly speaking is\nimpossible, since the first-person condition on introspection\n(condition 2 in Section 1.1) cannot be met: There is no distinctive\nprocess that generates knowledge of one’s own mind only.\nTwentieth-century\n behaviorist\n principles tended to encourage this view, but no prominent treatment\nof self-knowledge accepts this view in its most extreme and simple\nform. Advocates of parity accounts sometimes characterize our\nknowledge of our own minds as arising from “theories” that\nwe apply equally to ourselves and others (as in Nisbett and Ross 1980;\nGopnik 1993a, 1993b). Consequently, this approach to self-knowledge is\nsometimes called the theory theory. \nAmong leading researchers, Bem’s (1972) view, though now dated,\nperhaps comes closest to a simple self/other parity view, arguing on\nthe basis of psychological research that our knowledge of the\n“internal states” of both self and other derives largely\nfrom the same types of behavioral evidence and employs the same\nprinciples of inference. We notice how we behave, and then we infer\nthe attitudes evidenced by those behaviors—and we do so even\nwhen we actually lack the ascribed attitude. For example, Bem cites\nclassic research in social psychology suggesting that when induced to\nperform an action for a small reward, people will attribute to\nthemselves a more positive attitude toward that action than when they\nare induced by a large reward (Festinger and Carlsmith 1959; see also\nSection 4.2.2 below). When we notice ourselves doing something with\nminimal compensation, we infer a positive attitude toward that\nactivity, just as we would if we saw someone else perform the same\nactivity with minimal compensation. Likewise, we might know we like\nThai food because we’ve noticed that we sometimes drive all the\nway across town to get it; we might know that we’re happy\nbecause we see or feel ourselves smiling. Bem argued that social\npsychology had consistently failed to show that we have any\nappreciable access to private information that might tell against such\nexternally-driven self-attributions. On Bem’s view, if we are\nbetter at discerning our own motives and attitudes, it’s\nprimarily because we have observed more of our own behavior than of\nanyone else’s. \nNisbett, Wilson, and their co-authors (Nisbett and Bellows 1977;\nNisbett and Wilson 1977; Nisbett and Ross 1980; Wilson 2002) similarly\nargue for self/other parity in our knowledge of the bases or causes of\nour own and others’ attitudes and behavior, describing cases in\nwhich people seem to show poor knowledge of these bases or causes. For\nexample, people queried in a suburban shopping center about why they\nchose a particular pair of stockings appeared to be ignorant of the\ninfluence of position on that choice, including explicitly denying\nthat influence when it was suggested to them. People asked to rate\nvarious traits of supposed job applicants were unaware that their\njudgments of the applicant’s flexibility were greatly influenced\nby having been told that the applicant had spilled coffee during the\njob interview (see also Section 4.2.2 below). In such cases, Nisbett\nand his co-investigators found that participants’ descriptions\nof the causal influences on their own behavior closely mirrored the\ninfluences hypothesized by outside observers. From this finding, they\ninfer that the same mechanism drives the first-person and third-person\nattributions, a mechanism that that does not involve any special\nprivate access to the real causes of one’s attitudes and\nbehavior and instead relies heavily on intuitive psychological\ntheories. \nGopnik (1993a, 1993b; Gopnik and Meltzoff 1994) deploys developmental\npsychological evidence to support a parity theory of self-knowledge.\nShe points to evidence that for a wide variety of mental states,\nincluding believing, desiring, and pretending, children develop the\ncapacity to ascribe those states to themselves at the same age they\ndevelop the capacity to ascribe those states to others. For example,\nchildren do not seem to be able to ascribe to themselves past false\nbeliefs (after having been tricked by the experimenter) any earlier\nthan they can ascribe false beliefs to other people. This appears to\nbe so even when that false belief is in the very recent past, having\nonly just been revealed to be false. According to Gopnik, this\npervasive parallelism shows that we are not given direct introspective\naccess to our beliefs, desires, pretenses, and the like. Rather, we\nmust develop a “theory of mind” in light of which we\ninterpret evidence underwriting our self-attributions. The appearance\nof the immediate givenness of one’s mental states is, Gopnik\nsuggests, merely an “illusion of expertise”: Experts\nengage in all sorts of tacit theorizing that they don’t\nrecognize as such—the expert chess player for whom the strength\nof a move seems simply visually given, the doctor who immediately\nintuits cancer in a patient. Since we are all experts at mental state\nattribution, we don’t recognize the layers of theory\nunderwriting the process. \nThe empirical evidence behind self/other parity views remains\ncontentious (White 1988; Nichols and Stich 2003; Carruthers 2011).\nFurthermore, though Bem, Nisbett, Wilson, and Gopnik all stress the\nparallelism between mental state attribution to oneself and others and\nthe inferential and theoretical nature of such attributions, they all\nalso leave some room for a kind of self-awareness different in kind\nfrom the awareness one has of others’ mental lives. Thus, none\nendorses a purely symmetrical or self/other parity view. Bem\nacknowledges that the parallelism only holds “to the extent that\ninternal cues are weak, ambiguous, or uninterpretable” (1972,\n5). With this caveat in mind, he states that our self-knowledge is\n“partially” based on external cues. Nisbett and Wilson\nstress that we lack access only to the “processes” or\ncauses underlying our behavior and attitudes. Our attitudes\nthemselves and our current sensations, they say, can be known with\n“near certainty” (1977, 255; though contrast Nisbett and\nRoss 1980, 200–202, which seems sympathetic to Bem’s\nskepticism about special access even to our attitudes). Gopnik allows\nthat we “may be well equipped to detect certain kinds of\ninternal cognitive activity in a vague and unspecified way”, and\nthat we have “genuinely direct and special access to certain\nkinds of first-person evidence [which] might account for the fact that\nwe can draw some conclusions about our own psychological states when\nwe are perfectly still and silent”, though we can\n“override that evidence with great ease” (1993a,\n11–12). Ryle (1949) similarly stresses the importance of outward\nbehavior in the self-attribution of mental states while acknowledging\nthe presence of “twinges”, “thrills”,\n“tickles”, and even “silent soliloquies”,\nwhich we know of in our own case and that do not appear to be\ndetectable by observing outward behavior. However, none of these\nauthors develops an account of this apparently more direct\nself-knowledge. Their theories are consequently incomplete. Regardless\nof the importance of behavioral evidence and general theories in\ndriving our self-attributions, in light of the considerations that\ndrive Bem, Nisbett, Wilson, Gopnik, and Ryle to these caveats, it is\nprobably impossible to sustain a view on which there is complete\nparity between first- and third-person mental state attributions.\nThere must be some sort of introspective, or at least uniquely\nfirst-person, process. \nSelf/other parity views can also be restricted to particular\nsubclasses of mental states: Any mental state that can only be known\nby cognitive processes identical to the processes by which we know\nabout the same sorts of states in other people is a state to which we\nhave no distinctively introspective access. States for which parity is\noften asserted include personality traits, unconscious motives, early\nperceptual processes, and the bases of our decisions (see Section\n4.2.1 below for more on this). We learn about these states in\nourselves, perhaps, in much the same way we learn about such states in\nother people. Carruthers (2011; see also Section 4.2.2 below) presents\na case for parity of access to\n propositional attitudes\n like belief and desire (in contrast to inner speech, visual imagery,\nand the like, which he holds to be introspectible). \nEtymologically, the term “introspection”—from the\nLatin “looking into”—suggests a perceptual or\nquasi-perceptual process. Locke writes that we have a faculty of\n“Perception of the Operation of our own Mind” which,\n“though it be not Sense, as having nothing to do with external\nObjects; yet it is very like it, and might properly enough be\ncall’d internal Sense” (1690 [1975, 105], italics\nsuppressed). Kant (1781/1997) says we have an “inner\nsense” by which we learn about mental aspects of ourselves that\nis in important ways parallel to the “outer sense” by\nwhich we learn about outer objects. \nBut what does it mean to say that introspection is like perception? In\nwhat respects? As Shoemaker (1994a, 1994b, 1994c) points out, in a\nnumber of respects introspection is plausibly unlike\nperception. For example, introspection does not involve a dedicated\norgan like the eye or ear (though as Armstrong 1968 notes, neither\ndoes bodily proprioception). Both friends and foes of self-detection\naccounts have tended to agree that introspection does not involve a\ndistinctive phenomenology of “introspective appearances”\n(Shoemaker 1994a, 1994b, 1994c; Lycan 1996; Rosenthal 2001; Siewert\n2012): The visual experience of redness has a distinctive sensory\nquality or phenomenology that would be difficult or impossible to\nconvey to a blind person; analogously for the olfactory experience of\nsmelling a banana, the auditory experience of hearing a pipe organ,\nthe experience of touching something painfully hot. To be analogous to\nsensory experience in this respect, introspection would have to\ngenerate an analogously distinctive phenomenology—some\nquasi-sensory phenomenology in addition to, say, the visual\nphenomenology of seeing red that is the phenomenology of the\nintrospective appearance of the visual phenomenology of\nseeing red. This would seem to require two layers of appearance in\nintrospectively attended sensory perception: a visual appearance of\nthe outward object and an introspective appearance of that visual\nappearance. (This isn’t to say, however, that introspection, or\nat least conscious introspection, doesn’t involve some sort of\n“cognitive phenomenology”—if there is such a\nthing—of the sort that accompanies conscious thoughts in\ngeneral: See Bayne and Montague, eds., 2011.) \nContemporary proponents of quasi-perceptual models of introspection\nconcede the existence of such disanalogies (e.g., Lycan 1996). We\nmight consider an account of introspection to be quasi-perceptual, or\nless contentiously to be a “self-detection” account, if it\nmeets the first five conditions described in Section 1.1—that\nis, the mentality condition, the first-person condition, the temporal\nproximity condition, the directness condition, and the detection\ncondition. One aspect of the detection condition deserves special\nemphasis here: that detection requires the ontological independence of\nthe target mental state and the introspective judgment—the two\nstates will be causally connected (assuming that all has gone well)\nbut not constitutively connected. (Shoemaker (1994a, 1994b,\n1994c) calls models of self-knowledge that meet this aspect of the\ndetection condition “broad perceptual” models.) Maybe on a\nliberal understanding of “detection” that does not require\nontological independence, containment or other accounts of\nintrospection (see Section 2.3.1 below) might qualify as involving\n“detection”. However, that is not how\n“detection” is being used in the present taxonomy. \nSelf-detection accounts of self-knowledge seem to put introspection\nepistemically on a par with sense perception. To many philosophers,\nthis has seemed a deficiency in these accounts. A long and widespread\nphilosophical tradition holds that self-knowledge is epistemically\nspecial, that we have specially “privileged access”\nto—perhaps even infallible or indubitable knowledge of—at\nleast some portion of our mentality, in a way that is importantly\ndifferent in kind from our knowledge of the world outside us (see\nSection 4 below). Both self/other parity accounts (Section 2.1 above)\nand self-detection accounts (this section) of self-knowledge either\ndeny any special epistemic privilege or characterize that privilege as\nsimilar to the privilege of being the only person to have an extended\nview of an object or a certain sort of sensory access to that object.\nOther accounts of self-knowledge to be discussed later in Section 2.3\nare more readily compatible with, and often to some extent driven by,\nmore robust notions of the epistemic differences between\nself-knowledge and knowledge of environmental objects. \nArmstrong (1968, 1981, 1999) is perhaps the leading defender of a\nsimple, quasi-perceptual, self-detection account of introspection. He\ndescribes introspection as a “self-scanning process in the\nbrain” (1968, 324), and he stresses what he sees as the\nimportant ontological distinction between the state of awareness\nproduced by the self-scanning procedure and the target mental state of\nwhich one is aware by means of that scanning—the distinction,\nfor example, between one’s pain and one’s introspective\nawareness of that pain. \nArmstrong also appears to hold that the quasi-perceptual introspective\nprocess proceeds at a fairly low level cognitively—quick and\nsimple, typically without much interference by or influence from other\ncognitive or sensory processes. He describes introspection as\n“completely non-inferential”, similar to the simple\ndetection of pressure on one’s back (1968, 97), and he says it\ncan be (and presumably typically is) continuous and\n“reflex”, involving no more than keeping “a watching\nbrief on our own current mental contents, but without making much of a\ndeal of it” (1999, 115). Since Armstrong allows that inferences\nare often non-conscious, based on sensory or other cues that the\ninferring person cannot herself discern, his claim that the\nintrospective process is non-inferential is a substantial commitment\nto the simplicity of the process. He contrasts this reflexive\nself-monitoring with more sophisticated acts of deliberate\nintrospection which he thinks are also possible (1999, 114). Note that\nin calling reflexive self-monitoring “introspection”,\nArmstrong violates the effort condition from Section 1.1, which\nrequires that introspection not be constant and automatic. Lycan\n(1996) endorses a similar view, though unlike Armstrong, Lycan\ncharacterizes introspection as involving attentional\nmechanisms, thus presumably treating introspection as more demanding\nof cognitive resources (though still perhaps nearly constant). \nNichols and Stich (2003) employ a model of the mind on which having a\npropositional attitude such as a belief or desire is a matter of\nhaving a representation stored in a functionally-defined (and\nmetaphorical) “belief box” or “desire box”\n(see also the entries on\n belief\n and\n functionalism).\n On their account, self-awareness of these attitudes typically\ninvolves the operation of a simple “Monitoring Mechanism”\nthat merely takes the representations from these boxes, appends an\n“I believe that …”, “I desire that\n…”, or whatever (as appropriate) to that representation,\nand adds it back into the belief box. For example, if I desire that my\nfather flies to Hong Kong on Sunday, the Monitoring Mechanism can copy\nthe representation in my desire box with the content “my father\nflies to Hong Kong on Sunday” and produce a new representation\nin my belief box—that is, create a new belief—with the\ncontent “I desire that my father flies to Hong Kong on\nSunday”. Nichols and Stich also propose an analogous but\nsomewhat more complicated mechanism (they leave the details\nunspecified) that takes percepts as its input and produces beliefs\nabout those percepts as its output. \nNichols and Stich emphasize that this Monitoring Mechanism does not\noperate in isolation, but often co-operates or competes with a second\nmeans of acquiring self-knowledge, which involves deploying theories\nalong the lines suggested by Gopnik (see Section 2.1.2 above). They\noffer a “double dissociation” argument for this view. That\nis, they present, on the one hand, cases which they interpret as cases\nshowing a breakdown in the Monitoring Mechanism, while the capacity\nfor theoretical inference about the mind remains intact and, on the\nother hand, cases in which the capacity for theoretical inference\nabout the mind is impaired but the Monitoring Mechanism continues to\nfunction normally, suggesting that theoretical inference and\nself-monitoring are distinct and separable processes. Nichols and\nStich argue that autistic people have very poor theoretical knowledge\nof the mind, as suggested by their very poor performance in\n“theory of mind” tasks (tasks like assessing when someone\nwill have a false belief), and yet they succeed in monitoring their\nmental states as shown by their ability to describe their mental\nstates in autobiographies and other forms of self-report. Conversely,\nNichols and Stich argue that schizophrenic people remain excellent\ntheorizers about mental states but monitor their own mental states\nvery poorly—for example, when they fail to recognize certain\nactions as their own and struggle to report, or deny the existence of,\nongoing thoughts. \nGoldman (2006) criticizes the account of Nichols and Stich (see\nSection 2.2.1 above) for not describing how the Monitoring Mechanism\ndetects the attitude type of the representation (belief, desire,\netc.). If talk of “belief boxes” and the like is shorthand\nfor talk of functional role (as Nichols and Stich say), then the\nMonitoring Mechanism must somehow detect the functional role of the\ndetected representation. But functional role is a matter of what is\napt to cause a particular mental state and what that mental state is\napt to cause (see the entry on\n functionalism),\n and Goldman argues that a simple mechanism could not discern such\ndispositional and relational facts (though Nichols and Stich might be\nable to avoid this concern by describing introspection as involving\nnot just one but rather a cluster of similar mechanisms: 2003, 162).\nGoldman also argues that the Nichols and Stich account leaves unclear\nhow we can discern the strength or intensity of our beliefs, desires,\nand other propositional attitudes. \nGoldman’s positive account starts with the idea that\nintrospection is a quasi-perceptual process that involves attention:\n“Attention seems to act like an orienting organ in\nintrospection, analogous to the shift of eye gaze or the sniffing of\nthe nose” (2006, 244). Individual attended mental states are\nthen classified into broad categories (similarly, in visual perception\nwe can classify seen objects into broad categories). However, on\nGoldman’s view this process can only generate introspective\nknowledge of the general types of mental states (such as\nbelief, happiness, bodily sensation) and some properties of those\nmental states (such as degree of confidence for belief, and “a\nmultitude of finely delineated categories” for bodily\nsensation). Specific contents, especially of attitudes like belief,\nare too manifold, Goldman suggests, for pre-existing classificational\ncategories to exist for each one. Rather, we represent the specific\ncontent of such mental states by “redeploying” the\nrepresentational content of the mental state, that is, simply copying\nthe content of the introspected mental state into the content of the\nintrospective belief or judgment (somewhat like in the Nichols and\nStich account). Finally, Goldman argues that some mental states\nrequire “translation” into the mental code appropriate to\nbelief if they are to be introspected. Visual representations, he\nsuggests, have a different format or mental code than beliefs, and\ntherefore cognitive work will be necessary to translate the\nfine-grained detail of visual experience into mental contents that can\nbe believed introspectively. \nHill (1991, 2009) also offers a multi-process self-detection account\nof introspection. Like Goldman, Hill sees attention (in some broad,\nnon-sensory sense) as central to introspection, though he also allows\nfor introspective awareness without attention (1991, 117–118).\nHill emphasizes dissimilarities between introspection and perception,\nwhile retaining a broadly self-detection account. Hill (2009) argues\nthat introspection is a process that produces judgments\nabout, rather than perceptual awareness of, the target states,\nand suggests that the processes that generate these judgments vary\nconsiderably, depending on the target state, and are often complex.\nFor example, judgments about enduring beliefs and desires must, he\nsays, involve complex procedures for searching “vast and\nheterogeneous” long-term memory stores. Central to Hill’s\n(1991) account is an emphasis on the capacity of introspective\nattention to transform—especially to amplify and enrich, even to\ncreate—the target experience. In this respect Hill argues that\nthe introspective act differs from the paradigmatic observational act\nwhich does not transform the object perceived (though of course both\nscientific and ordinary—especially gustatory—observation\ncan affect what is perceived); and thus Hill’s account contains\na “self-fulfillment” or “self-shaping” aspect\nin the sense of Section 2.3.1 and Section 2.3.2 below, and only\nqualifiedly and conditionally meets the detection condition on\naccounts of introspection as described in Section 1.1 above—the\ncondition that introspection involves attunement to or detection of a\npre-existing mental state or event. \nLike Hill, Prinz (2004) argues that introspection must involve\nmultiple mechanisms, depending both on the target states (e.g.,\nattitudes vs. perceptual experiences) and the particular mode of\naccess to those states. Access might involve controlled attention or\nit might be more of a passive noticing; it might involve the verbal\n“captioning” or labeling of experiences or it might\ninvolve the kind of non-verbal access that even monkeys have to their\nmental states. Prinz (2007) sharply distinguishes between the\nconceptual classification of our conscious experiences into\nvarious types that can be recognized and re-identified over\ntime—classifications which he thinks must necessarily be\nsomewhat crude—and non-conceptual knowledge of ongoing conscious\nexperiences attained by “pointing” at them with attention.\nThe latter type of knowledge, Prinz argues, is much more detailed and\nfinely structured than the former but cannot be expressed or retained\nover time. Prinz also follows Hill in emphasizing that introspection\noften intensifies or otherwise modifies the target experience. In such\ncases, Prinz argues, introspective “access” is only access\nin an attenuated sense. \nThere are several ways to generate judgments, or at least statements,\nabout one’s own current mental life—self-ascriptions,\nlet’s call them—that are reliably true though they do not\ninvolve the detection of a pre-existing state. Consider the following\nfour types of case: \nAutomatically self-fulfilling self-ascriptions: I think to\nmyself, “I am thinking”. Or: I judge that I am making a\njudgment about my own mental life. Or: I say to myself in inner speech\n“I am saying to myself in inner speech:\n‘blu-bob’”. Such self-ascriptions are automatically\nself-fulfilling. Their existence conditions are a subset of their\ntruth conditions. \nSelf-ascriptions that prompt self-shaping: I declare that I\nhave a mental image of a pink elephant. At the same time I make this\ndeclaration, I deliberately cause myself to form the mental image of a\npink elephant. Or: A man uninitiated in romantic love declares to a\nprospective lover that he is the kind of person who sends flowers to\nhis lovers. At the same time he says this, he successfully resolves to\nbe the kind of person who sends flowers to his lovers. The\nself-ascription either precipitates a change or buttresses what\nalready exists in such a way as to make the self-ascription accurate.\nIn these cases, unlike the cases described in (A), some change or\nself-maintenance is necessary to render the self-ascription true,\nbeyond the self-ascriptional event itself. \nAccurate self-ascription through self-expression: I learn to\nsay “I’m in pain!” instead of “ow!” as\nan automatic, unreflective response to painful stimuli. Or: I use the\nself-attributive sentence “I believe Russell changed his mind\nabout pacifism” simply as a cautious way of expressing the\nbelief that Russell changed his mind about pacifism, this expression\nbeing the product of reflecting upon Russell rather than a product of\nreflection upon my own mind. Self-expressions of this sort are assumed\nhere to flow naturally from the states expressed in roughly the same\nway that facial expressions and non-self-attributive verbal\nexpressions flow naturally from those same states—that is,\nwithout being preceded by any attempt to detect the state\nself-ascribed. \nSelf-ascriptions derived from judgments about the outside\nworld: From the non-self-attributive fact that Stanford is south\nof Berkeley I derive the self-attributive conclusion that I believe\nthat Stanford is south of Berkeley. Or: From the non-self-attributive\nfact that it would be good to go to home now, I derive the\nself-attributive judgment that I want to go home now. These\nderivations may be inferences, but if so, such inferences require no\nspecific premises about ongoing mental states. Perhaps one embraces a\ngeneral inference principle like “from P, it is\npermissible to derive I believe that P”, or\n“normally, if something is good, I want it”. \nThe following accounts of self-knowledge all take advantage of one or\nmore of these facts about self-ascription. Because these ways of\nobtaining self-knowledge all violate the detection condition on\nintrospection (condition 5 in Section 1.1 above), and because\nphilosophers are divided about whether methods of obtaining\nself-knowledge that violate that condition count as\nintrospective methods strictly speaking, philosophers are\ndivided about whether accounts of self-knowledge of the sort described\nin this section should be regarded as accounts of introspection. \nAn emphasis on infallible knowledge through self-fulfilling\nself-ascriptions goes back at least to Augustine (c. 420 C.E./1998)\nand is most famously deployed by Descartes in his Discourse on\nMethod (1637/1985) and Meditations (1641/1984), where he\ntakes the self-fulfilling thought that he is thinking as indubitably\ntrue, immune to even the most radical skepticism, and a secure ground\non which to build further knowledge (at least under certain\nconditions; see Paul 2018). \nContemporary self-fulfillment accounts tend to exploit the idea of\ncontainment. In a 1988 essay, Burge writes: \nThis is the case, Burge argues, because “by its reflexive,\nself-referential character, the content of the second-order\n[self-attributive] judgment is locked (self-referentially) onto the\nfirst-order content which it both contains and takes as its subject\nmatter” (1988, 659–660; cf. Heil 1988; Gertler 2000, 2001;\nHeil and Gertler describe such thoughts as introspective while Burge\nappears not to think of self-knowledge so structured as introspective:\n1998, 244; see also 1988, 652). In judging that I am thinking of a\nbanana, I thereby necessarily think of a banana: The self-attributive\njudgment contains, as a part, the very thought self-ascribed, and thus\ncannot be false. In a 1996 essay, Burge extends his remarks to include\nnot just self-attributive “thoughts” as targets but also\n(certain types of) “judgments” (e.g., “I judge,\nherewith, that there are physical entities” and other judgments\nwith “herewith”-like reflexivity, 92) \nShoemaker (1994a, 1994b, 1994c) deploys the containment idea very\ndifferently, and over a much wider array of introspective targets,\nincluding conscious states like pains and propositional attitudes like\nbelief. Shoemaker speculates that the relevant containment relation\nholds not between the contents or concepts employed\nin the target state and in the self-ascriptive state but rather\nbetween their neural realizations in the brain. To develop this point,\nShoemaker distinguishes between a mental state’s “core\nrealization” and its “total realization”. One might\nthink of mental processes as transpiring in fairly narrow regions of\nthe brain (their core realization), and yet, Shoemaker suggests,\nit’s not as though we could simply carve off those regions from\nall others and still have the mental state in question. To be the\nmental state it is, the process must be embedded in a larger causal\nnetwork involving more of the brain (the total realization).\nRelationships of containment or overlap between core realization and\ntotal realization between the target state and the self-ascriptive\njudgment might then underwrite introspective accuracy. For example,\nthe total brain-state realization of the state of pain may simply be a\nsubset of the total brain-state realization of the state of believing\nthat one is in pain. Introspective accuracy might then be explained by\nthe fact that the introspective judgment is not an independently\nexisting state. \nMore recently, philosophers have applied Burge-like\ncontent-containment models (as opposed to Shoemaker-like\nrealization-containment models) to self-knowledge of conscious states,\nor “phenomenology”, in particular—for example,\nGertler (2001), Papineau (2002), Chalmers (2003), Horgan and Kriegel\n(2007), and Balog (2012). Husserl (1913/1982) offers an early\nphenomenal containment approach, arguing that we can at any time put\nour “cogitatio”—our conscious\nexperiences—consciously before us through a kind of mental\nglancing, with the self-perception that arises containing as a part\nthe conscious experience toward which it is directed, and incapable of\nexisting without it. Papineau offers a “quotational”\naccount on which in introspection we self-attribute “the\nexperience: ___”, where the blank is completed by the experience\nitself. Chalmers writes that “direct phenomenal beliefs”\nabout our experiences are “partly constituted by an\nunderlying phenomenal quality”, in that the two will be tightly\ncoupled across “a wide range of nearby conceptually possible\ncases” (2003, 235). \nOne possible difficulty with such accounts is that while it seems\nplausible to suppose that an introspective thought or judgment might\ncontain another thought or judgment as a part, it’s less clear\nhow a self-attributive judgment or belief might contain a piece of\nconscious experience as a part. Beliefs, and other belief-like mental\nstates like judgments, one might think, contain concepts, not\nconscious experiences, as their constituents (Fodor 1998); or,\nalternatively, one might think that beliefs are functional or\ndispositional patterns of response to input (Dennett 1987;\nSchwitzgebel 2002), again rendering it unclear how a piece of\nphenomenology could be part of belief. Perhaps with this concern in\nmind, advocates of containment accounts often appeal to\n“phenomenal concepts” that are, like the introspective\njudgments to which they contribute, partly constituted by the the\nconscious experiences that are the contents of those concepts. Such\nconcepts are often thought to be obtained by demonstrative attention\nto our conscious experiences as they are ongoing. \nIt would seem, at least, that beliefs, concepts, or judgments\ncontaining pieces of phenomenology would have to expire once the\nphenomenology has passed and thus that the introspective judgments\ncould not be used in later inferences without recreating the state in\nquestion. Chalmers (2003) concedes the temporal locality of such\nphenomenology-containing introspective judgments and consequently\ntheir limited use in speech and in making generalizations. Papineau\n(2002), in contrast, embraces a theory in which the imaginative\nrecreation of phenomenology in thinking about past experience is\ncommonplace. \nAlthough we can seemingly at least sometimes arrive at true self\nascriptions through the self-shaping and the self-expression\nprocedures (B and C) described at the beginning of Section 2.3, and\nalthough such procedures may meet the first three conditions on an\naccount of introspection as described in Section 1.1—that is,\nthey may (depending on how they are described and developed) be\nprocedures that can yield only knowledge or judgments (or at least\nself-ascriptions) about one’s own currently ongoing or very\nrecently past mental states—few philosophers would describe such\nprocedures as “introspective”. Nonetheless, they warrant\nbrief treatment here, partly for the same reason self/other parity\naccounts warranted treatment in Section 2.1 above—that is, as\nskeptical accounts suggesting that the scope of introspection may be\nconsiderably narrower than is generally thought—and partly as\nbackground for the “transparency” accounts to be discussed\nin Section 2.3.4 below, with which they are often married. \nIt is difficult to find accounts of self-knowledge that stress the\nself-shaping technique in its purest, forward-looking, causal\nform—perhaps because it’s clear that self-knowledge must\ninvolve considerably more than this (Gertler 2011). However, McGeer\n(1996, 2008; McGeer and Pettit 2002) puts considerable emphasis on\nself-shaping, writing that “we learn to use our intentional\nself-ascriptions to instill or reinforce tendencies and inclinations\nthat fit with these ascriptions, even though such tendencies and\ninclinations may at best have been only nascent at the time we first\nmade the judgments” (1996, 510). If I describe myself as brave\nin battle, or as a committed vegetarian—especially if I do so\npublicly—I create commitments and expectations for myself that\nhelp to make those self-ascriptions true. McGeer compares\nself-knowledge to the knowledge a driver has, as opposed to a\npassenger, of where the car is going: The driver, unlike the\npassenger, can make it the case that the car goes where she says it is\ngoing (505). \nThere are also strains in Dennett (though Dennett may not have an\nentirely consistent view on these matters; see Schwitzgebel 2007) that\nsuggest either a self-fulfillment or a self-shaping view. In some\nplaces, Dennett compares “introspective” self-reports\nabout consciousness to works of fiction, immune to refutation in the\nsame way that fictional claims are—one could no more go wrong\nabout one’s consciousness, Dennett says, than Doyle could go\nwrong about the color of Holmes’s easy chair (e.g., 1991, 81,\n94). Such remarks are consistent with either an anti-realist view of\nfiction (there are no facts about the easy chair or about\nconsciousness; see 366–367) or a self-fulfillment or\nself-shaping realist view (Doyle creates facts about Holmes\nas he thinks or writes about him; we create facts about what\nit’s like to be us in thinking or making claims about our\nconsciousness, as perhaps on 81 and 94). More moderately, in\ndiscussing attitudes, Dennett emphasizes how the act of formulating an\nattitude in language—for example, when ordering a menu\nitem—can involve self-attributing a degree of specification in\none’s attitudes that was not present before, thereby committing\none to, and partially or wholly creating, the specific attitude\nself-ascribed (1987, 20). \nCommissive accounts of self-knowledge also involve\nself-shaping, but not a form of self-shaping in which the\nintrospective judgment brings into existence an ontologically distinct\ntarget state, but rather a kind of self-shaping involving a\nself-fulfillment or containment component similar to that discussed in\nSection 2.3.1 above. Moran (2001), for example, argues that normally\nwhen we are prompted to think about what we believe, desire, or intend\n(and he limits his account primarily to these three mental states), we\nreflect on the (outward) phenomena in question and make up our minds\nabout what to believe, desire, or do. Rather than attempting\nto detect a pre-existing state, we open or re-open the matter and come\nto a resolution. Since we normally do believe, desire, and intend what\nwe resolve to believe, desire, and do, we can therefore accurately\nself-ascribe those attitudes. Coliva (2016) argues that the\nself-ascription “I believe that P” is like a performative\nstatement in that it constitutes a comment to the belief that P. (See\nalso Wright 1989; Falvey 2000; Heal 2002; Boyle 2009,\nforthcoming.) \nWittgenstein writes: \nAnd  \nOn Wittgenstein’s view, it is both true that I am in pain and\nthat I say of myself that I am in pain, but the utterance in no way\nemerges from a process of detecting one’s pain. \nA simple expressivist view—sometimes attributed to Wittgenstein\non the basis of these and related passages—denies that the\nexpressive utterances (e.g., “that hurts!”) genuinely\nascribe mental states to the individuals uttering them. Such a view\nfaces serious difficulties accommodating the evident semantics of\nself-ascriptive utterances, including their use in inference and the\napparent symmetries between present-tense and past-tense uses and\nbetween first-person and third-person uses (Wright 1998; Bar-On 2004).\nConsequently, Bar-On advocates, instead, what she calls a\nneo-expressivist view according to which expressive utterances can\nshare logical and semantic structure with non-expressive utterances,\ndespite the epistemic differences between them. \nExpressivists have not always been clear about exactly the range of\ntarget mental states expressible in this way, but it seems plausible\nthat at least in principle some true (or apt) self-ascriptions could\narise in this manner, with no intervening introspective\nself-detection. The question would then be whether this is how we\ngenerally arrive at true self-ascriptions, for some\nparticular class of mental states, or whether some more archetypically\nintrospective process is also available. (For a more detailed\ntreatment of expressivism, consult the section about the expressivist\nmodel of self-knowledge in the entry\n self-knowledge.) \nEvans writes: \nTransparency approaches to self-knowledge, like Evans’,\nemphasize cases in which it seems that one arrives at an accurate\nself-ascription not by means of attending to, or thinking about,\none’s own mental states, but rather by means of attending to or\nthinking about the external states of the world that the target mental\nstates are about. Note that this claim has both a negative and a\npositive aspect: We do not learn about our minds by as it\nwere gazing inward; and we do learn about our minds by\nreflecting on the aspects of the world that our mental states are\nabout. The positive and negative theses are separable: A pluralist\nmight accept the positive thesis without the negative one; an advocate\nof a self/other parity theory or an expressivist account of\nself-knowledge (with respect to a certain class of target states)\nmight accept the negative thesis without the positive. (N.B.: In the\nphilosophical literature on self-knowledge “transparency”\nis also sometimes used to mean something like self-intimation in the\nsense of Section 4.1.1 below, for example in Wright 1998; Bilgrami\n2006. This is a completely different usage, not to be confused with\nthe present usage.) Because transparency accounts stress the outward\nfocus of our thought in arriving at self-ascriptions, calling such\naccounts accounts of “introspection” strains against the\netymology of the term. Nonetheless, some prominent advocates of\ntransparency accounts, such as Dretske (1995) and Tye (2000), offer\nthem explicitly as accounts of introspection. \nThe range of target states to which transparency applies is a matter\nof some dispute. Among philosophers who accept something like\ntransparency, belief is generally regarded as transparent (Gordon\n1995, 2007; Gallois 1996; Moran 2001; Fernández 2003; Byrne\n2018). Perceptual states or perceptual experiences are also often\nregarded as transparent in the relevant sense. Harman’s example\nis the most cited: \nHarman’s emphasis here is on the negative thesis, which goes\nback at least to Moore (1903; though Moore does not unambiguously\nendorse it). The view that it is impossible to attend directly to\nperceptual experience has been especially stressed by Tye (1995, 2000,\n2002; see also Evans 1982; Van Gulick 1993; Shoemaker 1994a; Dretske\n1995; Martin 2002; Stoljar 2004), and directly conflicts with accounts\naccording to which we learn about our sensory experience primarily by\ndirecting introspective attention to it (e.g., Goldman 2006;\nPetitmengin 2006; Hill 2009; Siewert 2012; and back at least to Wundt\n1888 and Titchener 1908 [1973]). \nGordon (2007) argues (contra Nichols and Stich 2003 and Goldman 2006)\nthat Evans-like ascent routines (ascending from\n“p” to “I believe that p”)\ncan drive the accurate self-ascription of all the attitudes, not just\nbelief. He makes his case by wedding the transparency thesis to\nsomething like an expressive account of self-ascription: To answer a\nquestion about what I want—for example, which flavor ice cream\ndo I want?—I think not about my desires but rather about the\ndifferent flavors available, and then I express the resulting\nattitude self-ascriptively. Similarly for hopes, fears, wishes,\nintentions, regrets, etc. Gordon points out that from a very early\nage, before they likely have any self-ascriptive intent, children\nlearn to express their attitudes self-ascriptively, for example with\nsimple phrases like “[I] want banana!” (see also Bar-On\n2004). \nCommissive accounts of self-knowledge (see Section 2.3.2 above) also\ngenerally affirm transparency: Reflecting on the world generates\ncommitment to a belief, desire, or intention, which one thereby also\nknows or self-ascribes (Falvey 2000; Moran 2001; Coliva 2016; Boyle\nforthcoming).  \nThe transparency thesis is in fact consistent, not just with\nexpressivism and commissive accounts, but with any of the four\nnon-detection-based self-ascription procedures described at the\nbeginning of this section (and indeed Aydede and Güzeldere 2005\nattempt to reconcile aspects of the transparency view with a broadly\ndetection-like approach to introspection). This manifold compatibility\nflows from the fact that by itself the transparency thesis does not go\nfar toward a positive view of the mechanisms of self-knowledge. \nByrne (2018) and Dretske (1995) bring together transparency and\nsomething like a derivational model of self-knowledge—a model on\nwhich I derive the conclusion that I believe that P directly\nfrom P itself, or the conclusion that I am representing\nx as F from the fact that x is\nF—a fact which must of course, to serve as a premise in\nthe derivation, be represented (or believed) by me. Byrne argues that\njust as one might abide by the following epistemic rule: \nso also might someone abide by the rule: \nTo determine whether you believe that P, first determine\nwhether P is the case, then follow the rule BEL. Byrne (2018)\noffers similar accounts of self-knowledge of intention, thinking,\nseeing, and desire. \nDretske analogizes introspection to ordinary cases of “displaced\nperception”—cases in which one perceives that something is\nthe case by way of directly perceiving some other thing (e.g., hearing\nthat the mail carrier has arrived by hearing the dog’s barking;\nseeing that you weigh 110 pounds by seeing the dial on the bathroom\nscale): One perceives that one represents x as F by\nway of perceiving the F-ness of x. Dretske notes,\nhowever, two points of disanalogy between the cases. In the case of\nhearing that the mail carrier has arrived by hearing the dog’s\nbark, the conclusion (that the mail carrier has arrived) is only\nestablished if the premise about the dog’s barking is true, and\nfurthermore it depends on a defeasible connecting belief, that the\ndog’s barking is a reliable indicator of the mail’s\narrival. In the introspective case, however, the inference, if it is\nan inference, does not require the truth of the premise about\nx’s being F. Even if x is not\nF, the conclusion that I’m representing x as\nF is supported. Nor does there seem to be any sort of\ndefeasible connecting belief. \nTye also emphasizes transparency in his account of introspection,\nthough he limits his remarks to the introspection of conscious\nexperience or “phenomenal character”. In his 2000 book,\nTye develops a view like Dretske’s, analogizing introspection to\ndisplaced perception, though Tye unlike Dretske explicitly denies that\ninference is involved, instead proposing a mechanism similar to the\nsort of mechanism envisioned by simple monitoring accounts like those\nof Nichols and Stich (2003; see Section 2.2.1 above), a reliable\nprocess that, in the case of perceptual self-awareness, takes\nawareness of external things as its input and yields as its output\nawareness of phenomenal character. (The key difference between\nTye’s 2000 account on the one hand and the Nichols and Stich\naccount on the other that warrants the classification of Tye’s\nview here rather than in the section on self-detection models is this:\nTye rejects the idea that the process is one of internal detection,\nwhile Nichols and Stich stress that idea. To adjudicate the dispute\nbetween those two positions, and to determine whether it might, in\nfact, be merely nominal, it would be helpful to have a clearer sense\nthan has so far been given of what it means to say that one\nsubpersonal system detects, or “monitors” or\n“scans”, the states or contents of another.) However, in\nhis 2009 book, Tye rejects the displaced perception model in favor of\na version of the transparency view that identifies phenomenal\ncharacter with external qualities in the world, so that perceiving\nfeatures of the world just is perceiving phenomenal character—a\nview that he recognizes is then charged with the difficult task of\nexplaining how phenomenal character is a property (or\n“quality”) of external objects rather than, as is\ngenerally assumed, a property only of experiences of those\nobjects. \nSeveral authors have challenged the idea that sensory experience\nnecessarily eludes attention—that is, they have denied the\ncentral claim of transparency theories about sensory experience. Block\n(1996), Kind (2003), and Smith (2008) have argued that\nphosphenes—those little lights you see when you press on your\neyes—and visual blurriness are aspects of sensory experiences\nthat can be directly attended. Siewert (2004) has argued that\nwhat’s intuitively appealing in the transparency view is\nprimarily the observation that in reflecting on sensory experience one\ndoes not withdraw attention from the objects sensed; but, he\nargues, this is compatible with also devoting a certain sort of\nattention to the sensory experience itself. In early discussions of\nattention, perceptual attention was sometimes distinguished from\n“intellectual attention” (James 1890 [1981]; Baldwin\n1901–1905; see also Peacocke 1998; Mole 2011), that is, from the\nkind of attention we can devote to purely imagined word puzzles or to\nphilosophical issues. If non-sensory forms of attention are possible,\nthen the transparency thesis for sensory experience will require\nrestatement: Is it only sensory attention to sensory experience that\nis impossible? Or is it any kind of attention whatsoever? Simply to\nsay we don’t attend sensorily to our mental states is to make\nonly a modest claim, akin to the claim that we see objects rather than\nseeing our visual experiences of objects; but to say that we cannot\nattend to our mental states even intellectually appears extreme. In\nlight of this, it remains unclear how to cast the transparency\nintuition to better bring out the core idea that is meant to be\nconveyed by the slogan that introspecting sensory experience is not a\nmatter of attending to one’s own mind. \nPhilosophers discussing self-knowledge often write as if approaches\nhighlighting one of these non-self-detection methods of generating\nself-ascriptions conflict with approaches that highlight other of\nthese non-self-detection methods, and also as if approaches of this\ngeneral sort conflict with self-detection approaches (Section 2.2\nabove). While conflicts will certainly exist between different\naccounts intended to serve as exhaustive approaches to\nself-knowledge, it is implausible that any one or even any few of\nthese approaches to self-knowledge is exhaustive. Plausibly, all of\nthe non-self-detection approaches described above can lead, at least\noccasionally, to accurate self-ascriptions. Enthusiasts for another of\nthe models, or for a self-detection model, needn’t deny this. It\nalso seems hard to deny that we at least sometimes reach\nconclusions about our mental lives based on the kind of theoretical\ninference or self-interpretation emphasized by advocates of self/other\nparity accounts (Section 2.1 above). Finally, even philosophers\nconcerned about strong or oversimple self-scanning views might wish to\ngrant that the mind can do some sort of tracking of its own\npresent or recently past states—for example, when we trace back\na stream of recently past thoughts that presumably can’t\n(because past) be self-ascribed by self-fulfillment, self-shaping,\nself-expression, or transparency methods. \nSchwitzgebel (2012) elevates this pluralism into a kind of negative\naccount of introspection. Introspective judgments, he says, arise from\na shifting confluence of many processes, recruited opportunistically,\nnone of which can be called introspection proper. Just as there is no\nsingle, unified faculty of poster-taking-in that one employs when\ntrying to take in a poster at a psychological conference or science\nfair, there is, on Schwitzgebel’s view, no single, unified\nfaculty of introspection or one underlying core process, nor even a\nfew dedicated mechanisms or processes. Instead, the introspector, like\nthe poster-viewer, brings to bear a diverse range of cognitive\nresources as suits the occasion. Although, he says, a process\nwouldn’t be worth calling “introspective” unless the\nintrospector aimed to reach a judgment about their current or very\nrecently past conscious experience, using at least some resources\nspecific to the first-person case and that exhibit some relatively\ndirect sensitivity to the target state, this limitation does not imply\nthe existence of any dedicated introspective processes. Defenders of\nless extreme versions of pluralism that are compatible with the\nexistence of several dedicated introspective processes include Prinz\n(2004), Hill (2009), Coliva (2016), and Samoilova (2016). \nPhilosophers have long made introspective claims about the human\nmind—or, to speak more cautiously, they’ve made claims\nseemingly at least in part introspectively grounded. Aristotle (3rd c.\nBCE/1961) asserts that thought does not occur without imagery. Mengzi\n(3rd c. BCE/2008) argues that our hearts are pleased by moral goodness\nand revolted by evil, even if the pleasure and revulsion are not\nevident in our outward behavior. Berkeley finds in himself no\n“abstract ideas” like that of a triangle that is, in\nLocke’s terms “neither oblique, nor rectangle, neither\nequilateral, equicrural, nor scalenon, but all and none of these at\nonce” (Berkeley 1710/1965, 12; Locke 1689/1975, 596). James Mill\n(1829 [1878]) attempts a catalog of the varieties of sense\nexperience. \nAlthough a number of early modern philosophers had aimed to initiate\nthe scientific study of the mind, it wasn’t until the middle of\nthe 19th century—with the appearance of quantitative\nintrospective methods, especially regarding sensory\nconsciousness—that the study of the mind took shape as a\nprogressive, mathematical, laboratory-based science. Early\nquantitative psychologists such as Helmholtz (1856/1962), Fechner\n(1860 [1964]), and Wundt (1896 [1902]) sought quantitative answers to\nquestions like: By how much must two physical stimuli differ for the\nexperiences of them to differ noticeably? How weak a stimulus can\nstill be consciously perceived? What is the mathematical relationship\nbetween stimulus intensity and the intensity of the resulting\nsensation? (The Weber-Fechner law holds that the relationship is\nlogarithmic.) Along what dimensions, exactly, can sense experience\nvary? (The “color solid” [see the link to the Munsell\nsolid in Other Internet Resources, below], for example, characterizes\ncolor experience by appeal to just three dimensions of variation: hue,\nsaturation, and lightness or brightness.) Although from very early on,\npsychologists also employed non-introspective methods (e.g.,\nperformance on memory tests, reaction times), most early\ncharacterizations of the field stood introspection at the center.\nJames, for example, wrote that “introspective observation is\nwhat we have to rely on first and foremost and always” (1890\n[1981, 185]). \nIn contrast with the dominant philosophical tradition that has, since\nDescartes, stressed the special privilege or at least high accuracy of\nintrospective judgments about consciousness (see Section 4.1 below)\nmany early introspective psychologists held that the introspection of\ncurrently ongoing or recently past conscious experience is difficult\nand prone to error if the introspective observer is insufficiently\ntrained. Wundt, for example, reportedly did not credit the\nintrospective reports of people with fewer than 50,000 trials of\npractice in observing their conscious experience (Boring 1953).\nTitchener, a leading American introspective psychologist, wrote a\n1600-page introspective training manual for students, arguing that\nintrospective observation is at least as difficult as observation in\nthe physical sciences (Titchener 1901–1905; see also Wundt 1874\n[1908]; Müller 1904; for contemporary discussions of\nintrospective training see Varela 1996; Nahmias 2002; Schwitzgebel\n2011b). This difference in optimism about untrained introspection may\npartly reflect differences in the types of judgments foregrounded in\nthe two disciplines. Philosophers stressing privilege tend to focus on\ncoarse and (seemingly) simple judgments such as “I’m\nhaving a visual experience of redness” or “I believe\nit’s raining”. The projects of interest to introspective\npsychologists often required much finer judgments—such as\ndetermining with mathematical precision whether one visual sensation\nhas twice the “intensity” of another or determining along\nwhat dimensions emotional experience can vary. \nEarly introspective psychologists’ theoretical discussions of\nthe nature of introspection were often framed in reaction to\nskepticism about the scientific viability of introspection, especially\nthe concern that the introspective act interferes with or destroys the\nmental state or process that is its\n target.[1])\n The most influential formulation of this concern was\nComte’s: \nIntrospective psychologists tended to react to this concern in one of\nthree ways. The most concessive approach—recommended, for\nexample, by James (1890 [1981]; see also Mill 1865 [1961]; Lyons\n1986)—was to grant Comte’s point for concurrent\nintrospection, that is, introspection simultaneous with the target\nstate or process, and to emphasize in contrast immediate\nretrospection, that is, reflecting on or attending to the target\nprocess (usually a conscious experience) very shortly after\nit occurs. Since the scientific observation occurs only after the\ntarget process is complete, it does not interfere with that process;\nbut of course the delay between the process and the observation must\nbe as brief as possible to ensure that the process is accurately\nremembered. \nBrentano (1874 [1973]) responded to Comte’s concern by\ndistinguishing between “inner observation”\n[innere Beobachtung] and “inner\nperception” [innere Wahrnehmung]. Observation,\nas Brentano characterizes it, involves dedicating full attention to a\nphenomenon, with the aim of apprehending it accurately. This\ndedication of attention necessarily interferes with the process to be\nobserved if the process is a mental one; therefore, he says, inner\nobservation is problematic as a scientific psychological method. Inner\nperception, in contrast, according to Brentano, does not\ninvolve attention to our mental lives and thus does not objectionably\ndisturb them. While our “attention is turned toward a different\nobject … we are able to perceive, incidentally, the mental\nprocesses which are directed toward that object” (1874 [1973,\n30]). Brentano concedes that inner perception necessarily lacks the\nadvantages of attentive observation, so he recommends conjoining it\nwith retrospective methods. \nWundt (1888) agrees with Comte and Brentano that observation\nnecessarily involves attention and so often interferes with the\nprocess to be observed, if that process is an inner, psychological\none. To a much greater extent than Brentano, however, Wundt emphasizes\nthe importance to scientific psychology of direct attention to\nexperience, including planful and controlled variation. The\npsychological method of “inner perception” is, for Wundt,\nthe method of holding and attentively manipulating a memory image or\nreproduction of a past psychological process. Although Wundt sees some\nvalue in this retrospective method, he thinks it has two crucial\nshortcomings: First, one can only work with what one remembers of the\nprocess in question—the manipulation of a memory-image cannot\ndiscover new elements. And second, foreign elements may be\nunintentionally introduced through association—one might confuse\none’s memory of a process with one’s memory of another\nassociated process or object. \nTherefore, Wundt suggests, the science of psychology must depend upon\nthe attentive observation of mental processes as they occur. He argues\nthat those who think attention necessarily distorts the target mental\nprocess are too pessimistic. A subclass of mental processes\nremains relatively unperturbed by attentive observation—the\n“simpler” mental processes, especially of perception\n(1896/1902, 27–28). The experience of seeing red, Wundt claims,\nis more or less the same whether or not one is attending to the\npsychological fact that one is experiencing redness. Wundt also\nsuggests that the basic processes of memory, feeling, and volition can\nbe observed systematically and without excessive disruption. These\nalone, he thinks, can be studied by introspective psychology\n(see also Wundt 1874 [1904]; 1896 [1902]; 1907). Other aspects of our\npsychology must be approached through non-introspective methods such\nas the observation of language, mythology, culture, and human and\nanimal development. \nAlthough introspective psychologists were able to build scientific\nconsensus on some issues concerning sense experience—issues such\nas the limits of sensory perception in various modalities and some of\nthe contours of variation in sensory experience—by the early\n20th century it was becoming clear that on many issues consensus was\nelusive. The most famous dispute concerned the existence of\n“imageless thought” (see the discussion of the imageless\nthought controversy in the entry\n mental imagery;\n see also Humphrey 1951; Kusch 1999); but other topics proved\nsimilarly resistant such as the structure of emotion or\n“feeling” (James 1890 [1981]; Külpe 1893 [1895];\nWundt 1896 [1902]; Titchener 1908 [1973]) and the experiential changes\nbrought about by shifts in attention (Wundt 1896 [1902]; Pillsbury\n1908; Titchener 1908 [1973]; Chapman 1933). \nBy the 1910s,\n behaviorism\n (which focused simply on the relationship between outward stimuli and\nbehavioral response) had declared war on introspective psychology,\nportraying it as bogged down in irresolvable disputes between\ndiffering introspective “experts”, and also rebuking the\nintrospectivists’ passive taxonomizing of experience,\nrecommending that psychology focus instead on socially useful\nparadigms for modifying behavior (e.g., Watson 1913). In the 1920s and\n1930s, introspective studies were increasingly marginalized. Although\nstrict behaviorism declined in the 1960s and 1970s, its main\nreplacement, cognitivist\n functionalism\n (which treats functionally defined internal cognitive processes as\ncentral to psychological inquiry), generally continued to share\nbehaviorism’s disdain of introspective methods. \nPsychophysics (the study of the relationship between physical sensory\ninput and consequent psychological state or response), where the\nintrospective psychologists had found their greatest success,\nunderwent a subtle shift in this period from a focus on\nsubjective methods—methods that involve asking subjects\nto report on their experiences or percepts—to a focus on\nobjective methods such as asking participants to report on\nstates of the outside world, including insisting that participants\nguess even when they feel they don’t know or have no relevant\nconscious experience (especially with the rise of “signal\ndetection theory” in psychophysics: Green and Swets 1966;\nCheesman and Merikle 1986; Macmillan and Creelman 1991; Merikle,\nSmilek, and Eastwood 2001). Perhaps in accord with transparency views\nof introspection (Section 2.3.4 above), the two types of instruction\nseem very similar (compare the subjective “tell me if you\nvisually experience a flash of light” with the objective\n“tell me if the light flashes”). On the other hand,\nperhaps in tension with transparency views, subjective and objective\ninstructions seem sometimes to differ importantly, especially in cases\nof known illusion, Gestalt effects such as perceived grouping, stimuli\nnear the limits of perceivability, and the experience of ambiguous\nfigures (Boring 1921; Merikle, Smilek, and Eastwood 2001; Siewert\n2004). \nIn no period, however, were introspective methods entirely\nabandoned by psychologists, and in the last few decades, they have\nmade something of a comeback, especially with the rise of the\ninterdisciplinary field of “consciousness studies” (see,\ne.g., Jack and Roepstorff, eds., 2003, 2004). Ericsson and Simon\n(1984/1993; to be discussed further in Section 4.2.3 below) have\nadvocated the use of “think-aloud protocols” and\nimmediately retrospective reports in the study of problem solving.\nOther researchers have emphasized introspective methods in the study\nof imagery (Marks 1985; Kosslyn, Reisbert, and Behrmann 2006) and\nemotion (Lambie and Marcel 2002; Barrett et al. 2007). \nBeeper methodologies have been developed to facilitate immediate\nretrospection, especially by Hurlburt (1990, 2011; Hurlburt and Heavey\n2006; Hurlburt and Schwitzgebel 2007) and Csikszentmihalyi (Larson and\nCsikszentmihalyi 1983; Csikszentmihalyi 2014). Traditional immediately\nretrospective methods required the introspective observer in the\nlaboratory somehow to intentionally refrain from introspecting the\ntarget experience as it occurs, arguably a difficult task. Hurlburt\nand Csikszentmihalyi, in contrast, give participants beepers to wear\nduring ordinary, everyday activity. The beepers are timed to sound\nonly at long intervals, surprising participants and triggering an\nimmediately retrospective assessment of their “inner\nexperience”, emotion, or thoughts in the moment before the\nbeep. \nIntrospective or subjective reports of conscious experience have also\nplayed an important role in the search for the “neural\ncorrelates of consciousness” (as reviewed in Rees and Frith\n2007; Prinz 2012; Koch et al. 2016; see also Varela 1996). One\nparadigm is for researchers to present ambiguous sensory stimuli,\nholding them constant over an extended period, noting what neural\nchanges correlate with changes in subjective reports of experience.\nFor example, in “binocular rivalry” methods, two different\nimages (e.g., a face and a house) are presented, one to each eye.\nParticipants typically say that only one image is visible at a time,\nwith the visible image switching every few seconds. Researchers have\nsometimes reported finding evidence that activity in\n“early” visual areas (such as V1) is not temporally\ncoupled with reported changes in visual experience, while changes in\nconscious percept are better temporally coupled with activity in\nparietal and maybe also frontal areas further downstream and to\nlarge-scale changes in neural synchronization or oscillation; however,\nthe evidence is disputed (Lumer, Friston, and Rees 1998; Tong et al.\n1998; Tononi et al. 1998; Polonsky et al. 2000; Tong, Meng, and Blake\n2006; Kamphuisen, Bauer, and van Ee 2008; Sandberg et al. 2013;\nFrässle et al. 2014; Ishiku and Zeki 2014; Tsuchiya et al. 2015).\nAnother version of the ambiguous sensory stimuli paradigm involves\npresenting the participant with an ambiguous figure such as the Rubin\nfaces-vase figure: \nUsing this paradigm, researchers have found neuronal changes both in\nearly visual areas and in later areas, as well as changes in\nwidespread neuronal synchrony, that correspond temporally with\nsubjective reports of flipping between one way and another of seeing\nthe ambiguous figure (Kleinschmidt et al. 1998; Rodriguez et al. 1999;\nIlg et al. 2008; Parkkonen et al. 2008; de Graaf et al. 2011; Megumi,\nBahrami, Kanai, and Rees 2015; Brascamp, Sterzer, Blake, and Knapen\n2017). In masking paradigms, stimuli are briefly presented then\nfollowed by a “mask”. On some trials, participants report\nseeing the stimuli, while on others they don’t. In trials in\nwhich the participant reports that stimulus was visually experienced,\nresearchers have tended to find higher levels of activity through at\nleast some of the downstream visual pathways as well as spontaneous\nelectrical oscillations near 40 Hz (Dehaene et al. 2001; Summerfield,\nJack, and Burgess 2002; Del Cul, Baillet, and Dehaene 2007; Quiroga et\nal. 2008; Salti et al. 2015). However, it remains contentious how\nproperly to interpret such attempts to find neural correlates of\nconsciousness (Noë and Thompson 2004; Overgaard, Sandberg, and\nJensen 2008; Dehaene and Changeux 2011; Aru, Bachmann, Singer, and\nMelloni 2012; de Graaf, Hsieh, and Sack 2012; Koch et al. 2016;\nPhillips 2018). \nIf we report our attitudes by introspecting upon them, then much of\nsurvey research is also introspective, though psychologists have not\ngenerally explicitly described it as such. As with subjective vs.\nobjective methods in psychophysics, there appears to be only a slight\ndifference between subjectively phrased questions (“Do you\napprove of the President’s handling of the war?”,\n“Do you think marijuana should be legalized?”) and\nobjectively phrased questions (“Has the President handled the\nwar well?”, “Should marijuana be legalized?”). This\nwould seem to support the observation at the core of transparency\ntheory (discussed in Section 2.3.4 above) that questions about the\nmind and questions about the outside world often call for the same\ntype of reflection. \nIt’s plausible to suppose that people have some sort of\nprivileged access to at least some of their own mental states\nor processes: You know about your own mind, or at least some aspects\nof it, in a different way and better than you know about other\npeople’s minds, and maybe also in a different way and better\nthan you know about the outside world. Consider pain. It seems you\nknow your own pains differently and better than you know mine,\ndifferently and (perhaps) better than you know about the coffee cup in\nyour hand. If so, perhaps that special “first-person”\nprivileged knowledge arises through something like introspection, in\none or more of the senses described in Section 2 above. \nJust as there is a diversity of methods for acquiring knowledge of or\nreaching judgments about one’s own mental states and processes,\nto which the label “introspection” applies with more or\nless or disputable accuracy, so also is there a diversity of forms of\n“privileged access”, with different kinds of privilege and\nto which the idea of access applies with more or less or disputable\naccuracy. And as one might expect, the different introspective methods\ndo not all align equally well with the different varieties of\nprivilege. \nA substantial philosophical tradition, going back at least to\nDescartes (1637/1985; 1641/1984; also Augustine c. 420 C.E./1998),\nascribes a kind of epistemic perfection to at least some of our\njudgments (or thoughts or beliefs or knowledge) about our own\nminds—infallibility, indubitability, incorrigibility, or\nself-intimation. Consider the judgment (thought, belief, etc.) that\nP, where P is a proposition self-ascribing a mental\nstate or process (for example P might be I am in\npain, or I believe that it is snowing, or I am\nthinking of a dachshund). The judgment that P is\ninfallible just in case, if I make that judgment, it is not\npossible that P is false. It is indubitable just in\ncase, if I make the judgment, it is not possible for me to doubt the\ntruth of P. It is incorrigible just in case, if I\nmake the judgment, it is not possible for anyone else to show that\nP is false. And it is self-intimating if it is not\npossible for P to be true without my reaching the judgment\n(thought, belief, etc.) that it is true. Note that the direction of\nimplication for the last of these is the reverse of the first three.\nInfallibility, indubitability, and incorrigibility all have the form:\n“If I judge (think, believe, etc.) that P, then\n…”, while self-intimation has the form “If\nP, then I judge (think, believe, etc.) that\nP”. All four theses also admit of weakening by adding\nconditions to the antecedent “if” clause (e.g., “If\nI judge that P as a result of normal introspective processes,\nthen …”). (See Alston 1971 for a helpful dissection of\nthese distinctions; all admit of variations and nuance. Also note that\nsome philosophers [e.g. Ayer 1936/1946; Armstrong 1963; Chalmers 2003;\nTye 2009] use “incorrigibility” to mean infallibility as\ndefined here, while others [e.g., Ayer 1963; Alston 1971; Rorty 1970;\nDennett 2000] use it with the more etymologically specific meaning of\n[something like] “incapable of correction”.) \nDescartes (1641/1984) famously endorsed the indubitability of “I\nthink”, which he extends also to such mental states as doubting,\nunderstanding, affirming, and seeming to have sensory perceptions. He\nalso appears to claim that the thought or affirmation that I am in\nsuch states is infallibly true, at least if that thought is clear and\ndistinct. He was followed in this—especially in his\ninfallibilism—by Locke (1690 [1975]), Hume (1739 [1978]),\ntwentieth-century thinkers such as Husserl (1913 [1982]), Ayer (1936\n[1946], 1963), Lewis (1946), and the early Shoemaker (1963), and many\nothers. Historical arguments for indubitability and infallibility have\ntended to center on intuitive appeals to the apparent impossibility of\ndoubting or going wrong about such matters as whether one is having a\nthought with a certain content or is experiencing pain or having a\nvisual experience as of seeing red. \nRecent infallibilists have added to this intuitive appeal structural\narguments based on self-fulfillment accounts of introspection or\nself-knowledge (see Section 2.3.1 above)—generally while also\nnarrowing the scope of infallibility, for example to thoughts about\nthoughts (Burge 1988, 1996), or to “pure” phenomenal\njudgments about consciousness (Chalmers 2003; see also Wright 1998;\nGertler 2001; Horgan, Tienson, and Graham 2006; Horgan and Kriegel\n2007; Tye 2009; with important predecessors in Brentano 1874 [1973];\nHusserl 1913 [1982]), or to beliefs as “commitments”\n(Coliva 2016). The intuitive idea behind most of these structural\narguments is that somehow the self-ascriptive thought or judgment\ncontains the mental state or process self-ascribed: the\nthought that I am thinking of a pink elephant contains the thought of\na pink elephant; the judgment that I am having a visual experience of\nredness contains the red experience itself. \nIn contrast, self/other parity (Section 2.1) and self-detection\n(Section 2.2) accounts of introspection or self-knowledge appear to\nstand in tension with infallibilism. If introspection or\nself-knowledge involves a causal process from a mental state to an\nontologically distinct self-ascription of that state, it appears that,\nhowever reliable such a process may generally be, there is inevitably\nroom in principle for interference and error. Minimally, it seems,\nstroke, quantum accident, or clever neurosurgery could break otherwise\ngenerally reliable relationships between target mental states and the\nself-ascriptions of those states. Similar considerations apply to\nself-shaping (Section 2.3.2) and expressivist (Section 2.3.3)\naccounts, to the extent that these are interpreted causally rather\nthan constitutively. \nIntrospective incorrigibility, as opposed to either infallibility or\nindubitability, was held by Rorty (1970) to be “the mark of the\nmental”—and thus as applying to a wide range of mental\nstates—. Dennett (2000, 2002) defends a similar view, for\nconscious experiences. The idea behind incorrigibility, recall, is\nthat no one else could show your self-ascriptions to be false; or we\nmight say, more qualifiedly and a bit differently, that if you arrive\nat the right kind of self-ascriptive judgment (perhaps an\nintrospectively based judgment about a currently ongoing conscious\nprocess that survives critical reflection), then no one else, perhaps\nnot even you in the future, aware of this, can rationally hold that\njudgment to be mistaken. If I judge that right now I am in severe\npain, and I do so as a result of considering introspectively whether I\nam indeed in such pain (as opposed to, say, merely inferring that I am\nin pain based on outward behavior), and if I pause to think carefully\nabout whether I really am in pain and conclude that I indeed am, then\nno one else who is aware of this can rationally believe that I’m\nnot in pain, regardless of what my outward behavior might be (say,\ncalm and relaxed) or what shows up in the course of brain imaging\n(say, no activation in brain centers normally associated with pain).\n \nIncorrigibility does not imply infallibility: I may not actually be in\npain, even if no one could show that I’m not.\nConsequently, incorrigibility is compatible with a broader array of\nsources of self-knowledge than is infallibility. Neither Rorty nor\nDennett, for example, appear to defend incorrigibility by appeal to\nself-fulfillment accounts of introspection (though in both cases,\ninterpreting their positive accounts is difficult). Causal accounts of\nself-knowledge may be compatible with incorrigibility if the causal\nconnections underwriting the incorrigible judgments are vastly more\ntrustworthy than judgments obtained without the benefit of this sort\nof privileged access. Of course, unless one embraces a strict\nself-fulfillment account, with its attendant infallibilism, one will\nwant to rule out abnormal cases such as quantum accident; hence the\nneed for qualifications. \nSelf-intimating mental states are those such that, if a person (or at\nleast a person with the right background capacities) has them, she\nnecessarily believes or judges or knows that she does. Conscious\nstates are often held to be in some sense self-intimating, in that the\nmere having of them involves, requires, or implies some sort of\nrepresentation or awareness of those states. Brentano argues that\nconsciousness, for example, of an outward stimulus like a sound,\n“clearly occurs together with consciousness of this\nconsciousness”, that is, the consciousness is “of the\nwhole mental act in which the sound is presented and in which the\nconsciousness itself exists concomitantly” (1874 [1995, 129];\nsee also\n phenomenological approaches to self-consciousness).\n “Higher order” and “same order” theories of\nconsciousness (Armstrong 1968; Rosenthal 1990, 2005; Gennaro 1996;\nLycan 1996; Carruthers 2005; Kriegel 2009; see also\n higher-order theories of consciousness)\n explain consciousness in terms of some thought, perception, or\nrepresentation of the mental state that is conscious—the\npresence of that thought, perception, or representation being what\nmakes the target state conscious. (On same order theories, the target\nmental state, or an aspect of it, represents itself, with no need for\na distinct higher order state.) Thus, Horgan, Kriegel, and others have\ndescribed consciousness as “self-presenting” (Horgan,\nTienson, and Graham 2005; Horgan and Kriegel 2007; the usage appears\nto follow Chisholm 1981, but Chisholm actually has an indubitability\nrather than a self-intimation thesis in mind). Shoemaker (1995, 2012)\nargues that beliefs—as long as they are “available”\n(i.e., readily deployed in inference, assent, practical reasoning,\netc.), which needn’t require that they are occurrently\nconscious—are self-intimating for individuals with sufficient\ncognitive capacity. Shoemaker’s idea is that if the belief that\nP is available in the relevant sense, then one is disposed to\ndo things like say “I believe P”, and such\ndispositions are themselves constitutive of believing that one\nbelieves that P. \nSelf-intimation claims (unlike infallibility, indubitability, and\nincorrigibility claims) are not usually cast as claims about\n“introspection”. This may be because knowledge acquired\nthrough self-intimation would appear to be constant and automatic,\nthus violating the effort condition on introspection (condition 6 in\nSection 1.1 above). \nA number of philosophers have argued for forms of first-person\nprivilege involving some sort of epistemic guarantee—not just\nconditional accuracy as a matter of empirical fact, but something more\nrobust than that—without embracing infallibility,\nindubitability, incorrigibility, or self-intimation in the senses\ndescribed in Section 4.1.1 above. \nShoemaker (1968), for example, argues that self-knowledge of certain\npsychological facts such as “I am waving my arm” or\n“I see a canary”, when arrived at “in the ordinary\nway (without the aid of mirrors, etc.)”, is immune to error\nthrough misidentification relative to the first-person pronoun\n(see also Campbell 1999; Pryor 1999; Bar-On 2004; Hamilton 2008). That\nis, although one may be wrong about waving one’s arm (perhaps\nthe nerves to your arm were recently severed unbeknownst to you) or\nabout seeing a canary (perhaps it’s a goldfinch), one cannot be\nwrong due to mistakenly identifying the person waving the arm or\nseeing the canary as you, when in fact it is someone else.\nThis immunity arises, Shoemaker argues, because there is no need for\nidentification in the first place, and thus no opportunity for\nmis-identification. In this respect, Shoemaker argues,\nknowledge that a particular arm that is moving is your arm (not immune\nto misidentification since maybe it’s someone else’s arm,\nmisidentified in the mirror) is different from the knowledge that\nyou are moving your arm—knowledge, that is, of what\nSearle (1983) calls an “intention in action”. \nShoemaker has also argued for the conceptual impossibility of\nintrospective self-blindness with respect to one’s\nbeliefs, desires, and intentions, and for somewhat different reasons\none’s pains (1988, 1994b). A self-blind creature, by\nShoemaker’s definition, would be a rational creature with a\nconception of the relevant mental states, and who can entertain the\nthought that she has this or that belief, desire, intention, or pain,\nbut who nonetheless utterly lacks introspective access to the type of\nmental state in question. A self-blind creature could still gain\n“third person” knowledge of the mental states in question,\nthrough observing her own behavior, reading textbooks, and the like.\n(Thus, strict self/other parity accounts of self-knowledge of the sort\ndescribed in Section 2.1 are accounts according to which one is\nself-blind in Shoemaker’s sense.) Shoemaker’s case against\nself-blindness with respect to belief turns on the dilemma of whether\nthe self-blind creature can avoid “Moore-paradoxical”\nsentences (see Moore 1942, 1944 [1993]; Shoemaker 1995) like\n“it’s raining but I don’t believe that it’s\nraining” in which the subject asserts both P and that\nshe doesn’t believe that P. If the subject is truly\nself-blind, Shoemaker suggests, there should be cases in which her\nbest evidence is both that P and that she doesn’t\nbelieve that P (the latter, perhaps, based on misleading\nfacts about her behavior). But if the subject asserts\n“P but I don’t believe that P” in\nsuch cases, she does not (contra the initial supposition) really have\na rational command of the nature of belief and assertion; and thus\nit’s not a genuine case of self-blindness as originally\nintended. Alternatively, perhaps the creature can reliably avoid such\nMoore-paradoxical sentences, self-attributing belief in an apparently\nnormal way. But then, Shoemaker suggests, it seems that she is\nindistinguishable from normal people in thought and behavior and hence\nnot self-blind. For desire, intention, and pain, too, Shoemaker aims\nto reveal incoherences between having a rational command of the\nconcepts in question and behaving as though one were systematically\nignorant of or mistaken about those states. Shoemaker uses his case\nagainst self-blindness as part of his argument against self-detection\naccounts of introspection (described in Section 2.2 above): If\nintrospection were a matter of detecting the presence of states that\nexist independently of the introspective judgment or belief, then it\nought to be possible for the faculty enabling the detection to break\ndown entirely, as in the case of blindness, deafness, etc., in outward\nperception (see also Nichols and Stich 2003, who argue that\nschizophrenia provides such a case). \nBurge has influentially asserted that brute errors about\n“present, ordinary, accessible propositional attitudes [such as\nbelief and desire]” are impossible or at least subject to\n“severe limits”—where a “brute error” is\nan error that “indicates no rational failure and no malfunction\nin the mistaken individual” such as commonly occur in ordinary\nperception due to “misleading natural conditions or look-alike\nsubstitutes” (1988, 657–658; 1996, 103–104).\nHowever, Burge offers little argument for this claim, apart from the\nargument mentioned in Sections 2.3.1 and 4.1.1 above that for certain\nsorts of self-ascriptions error in general (and not just “brute\nerror”) is impossible, due to the “self-verifying”\nnature of such self-ascriptions. \nDretske (1995, 2004) argues that we have infallible knowledge of the\ncontent of our attitudes without necessarily knowing (or even\nhaving a very good idea about) the attitude we take toward\nthose contents. For example, if I believe that it will rain\ntomorrow, I have infallibly accurate information, which I may\nthen access introspectively, regarding the presence of a mental state\nwith a certain content—the content “it will rain\ntomorrow”—but I may often have little or no information\nabout the fact that my attitude toward that content is the particular\nattitude it is—belief, in this case (as opposed to supposition\nor hope). This view follows from Dretske’s accepting something\nlike a containment account of the introspection of the content of the\nattitude (the introspective judgment employing the same content as the\ntarget attitude; see Section 2.3.1 above, especially the discussion of\nBurge), while he sees knowledge of the attitude one has toward that\ncontent as requiring complex information about the causal role and\nhistory of that mental state. \nTranscendental arguments for the accuracy of certain sorts of\nself-knowledge offer a different sort of epistemic\nguarantee—“transcendental arguments” being arguments\nthat assume the existence of some sort of experience or capacity, then\ndevelop insights about the background conditions necessary for that\nexperience or capacity, and finally conclude that those background\nconditions must in fact be met. Burge (1996; see also Shoemaker 1988)\nargues that to be capable of “critical reasoning” one must\nbe able to recognize one’s own attitudes, knowledgeably\nevaluating, identifying, and reviewing one’s beliefs, desires,\ncommitments, suppositions, etc., where these mental states are known\nto be the states they are. Since we are (by assumption, for the sake\nof transcendental argument) capable of critical reasoning, we must\nhave some knowledge of our attitudes. Bilgrami (2006) argues that we\ncan only be held responsible for actions if we know the beliefs and\ndesires that “rationalize” our actions; since we can (by\nassumption) sometimes be held responsible, we must sometimes know our\nbeliefs and desires. Wright (1989) argues that the “language\ngame” of ascribing “intentional states” such as\nbelief and desire to oneself and others requires as a background\ncondition that self-ascriptions have special authority within that\ngame. Given that we successfully play this language game, we must\nindeed have the special authority that we assume and others grant us\nin the context of the game. \nDeveloping an analogy from Wright (1998), if it’s your turn with\nthe kaleidoscope, you have a type of privileged perspective on the\nshapes and colors it presents. If someone else in the room wants to\nknow what color dominates, for example, the most straightforward\ncourse would be to ask you. But this type of privileged access comes\nwith no guarantee. At least in principle, you might be quite wrong\nabout the tumbling shapes. You might be dazzled by afterimages, or\nmomentarily confused, or hallucinating, or (unbeknownst to you)\ncolorblind. (Yes, people often don’t know they are colorblind, a\npoint stressed by Kornblith 1998.) It is also at least in principle\npossible that others may know better than you, perhaps even\nsystematically so, what is transpiring in the kaleidoscope. You might\nthink the figure shows octagonal symmetry, but the rest of us,\nfamiliar with the kaleidoscope’s design, might know that the\nsymmetry is hexagonal. A brilliant engineer may invent a kaleidoscope\nstate detector that can dependably reveal from outside the shape,\ncolor, and position of the tumbling chunks. \nWright raises this analogy to suggest that people’s privilege\nwith respect to certain aspects of their mental lives must be\ndifferent from that of the person with the kaleidoscope; but other\nphilosophers, especially those who embrace self-detection accounts of\nintrospection, should find the analogy at least somewhat apt:\nIntrospective privilege is akin to the privilege of having a unique\nand advantageous sensory perspective on something. Metaphorically\nspeaking, we are the only ones who can gaze directly at our attitudes\nor our stream of experience, while others must rely on us or on\noutward signs. Less metaphorically, in generating introspective\njudgments (or beliefs or knowledge) about one’s own mentality\none employs a detection process available to no one else. It is then\nan empirical question how accurate the deliverances of this process\nare; but on the assumption that the deliverances are in a broad range\nof conditions at least somewhat accurate and more accurate than the\ntypical judgments other people make about those same aspects of your\nmind, you have a “privileged” perspective. Typically,\nadvocates of self-detection models of introspection regard the\nmechanism or cognitive process generating introspective judgments or\nbeliefs as highly reliable in roughly this way, but not infallible,\nand not immune to correction by other people (Armstrong 1968;\nChurchland 1988; Hill 1981, 2009; Lycan 1996; Nichols and Stich 2003;\nGoldman 2000, 2006). \nThe arguments of the previous section are a priori in at least the\nbroad sense of that term (the psychologists’ sense): They depend\non general conceptual considerations and armchair folk psychology\nrather than on empirical research. To these might be added the\nargument, due to Boghossian (1989) that “externalism”\nabout the content of our attitudes (the view that our attitudes depend\nconstitutively not just on what is going on internally but also on\nfacts about our environment; Putnam 1975; Burge 1979) seems to\nproblematize introspective self-knowledge of those attitudes. This\nissue will not be treated here, since it is amply covered in the\nentries on\n externalism about mental content\n and\n externalism and self-knowledge. \nNow we turn to empirical research on our self-knowledge of those\naspects of our minds often thought to be accessible to introspection.\nSince character traits are not generally regarded as introspectible\naspects of our mentality, we’ll skip the large literature on the\naccuracy or inaccuracy of our judgments about them (e.g., Taylor and\nBrown 1988; Paulhus and John 1998; Funder 1999; Vazire 2010; see also\nHaybron’s 2008 skeptical perspective on our knowledge of how\nhappy we are); nor will we discuss self-knowledge of subpersonal,\nnonconscious mental processes, such as the processes underlying visual\nrecognition of color and shape. \nAs a general matter, while a priori accounts of the epistemology of\nintrospection have tended to stress its privilege and accuracy,\nempirical accounts have tended to stress its failures. \nPerhaps the most famous argument in the psychological literature on\nintrospection and self-knowledge is Nisbett and Wilson’s\nargument that we have remarkably poor knowledge of the causes of, and\nprocesses underlying, our behavior and attitudes (Nisbett and Wilson\n1977; Nisbett and Ross 1980; Wilson 2002). Section 2.1 above briefly\nmentioned their emblematic finding that people in a shopping mall were\noften ignorant of a major factor—position—influencing\ntheir judgments about the quality of pairs of stockings. In Nisbett\nand Bellows (1977), also briefly mentioned above, participants were\nasked to assess the influence of various factors on their judgments\nabout features of a supposed job applicant. As in Nisbett and\nWilson’s stocking study, participants denied the influence of\nsome factors that were in fact influential; for example, they denied\nthat the information that they would meet the applicant influenced\ntheir judgments about the applicant’s flexibility. (It actually\nhad a major influence, as assessed by comparing the judgments of\nparticipants who were told and not told that they would meet the\napplicant.) Participants also attributed influence to factors that\nwere not in fact influential; for example, they falsely reported that\nthe information that the applicant accidentally knocked over a cup of\ncoffee during the interview influenced “how sympathetic the\nperson seems” to them. Nisbett and Bellows found that ordinary\nobservers’ hypothetical ratings of the influence of the various\nfactors on the various judgments closely paralleled the\nparticipants’ own ratings of the factors influencing\nthem—a finding used by Nisbett to argue that people have no\nspecial access to causal influences on their judgments and instead\nrely on the same sorts of theoretical considerations outside observers\nrely on (the self/other parity view described in Section 2.1). Despite\nsome objections (such as White 1988), both psychologists and\nphilosophers now tend to accept Nisbett’s and Wilson’s\nview that there is at best only a modest first-person advantage in\nassessing the factors influencing our judgments and behavior. \nIn series of experiments, Gazzaniga (1995) presented commissurotomy\npatients (people with severed corpus callosum) with different visual\nstimuli to each hemisphere of the brain. With cross-hemispheric\ncommunication severely impaired due to the commissurotomy, the left\nhemisphere, controlling speech, had information about one part of the\nvisual stimulus, while the right hemisphere, controlling some aspects\nof movement (especially the left hand) had information about a\ndifferent part. Gazzaniga reported finding that when these\n“split brain” patients were asked to explain why they did\nsomething, when that action was clearly caused by input to the right,\nnon-verbal hemisphere, the left hemisphere would sometimes fluently\nconfabulate an explanation. For example, Gazzaniga reports presenting\nan instruction like “laugh” to the right hemisphere,\nmaking the patient laugh. When asked why he laughed, the patient would\nsay something like “You guys come up and test us every month.\nWhat a way to make a living!” (1393). When a chicken claw was\nshown to the left hemisphere and snow scene to the right, and the\npatient was asked to select an appropriate picture from an array, the\nright hand would point to a chicken and the left hand to a snow\nshovel, and when asked why they selected those two things, the patient\nwould say something like “Oh, that’s simple. The chicken\nclaw goes with the chicken and you need a shovel to clean out the\nchicken shed” (ibid.). Similar confabulation about motives is\nsometimes (but not always) seen in people whose behavior is,\nunbeknownst to them, driven by post-hypnotic suggestion (Richet 1884;\nMoll 1889 [1911]), and in disorders such as hemineglect (anosognosia),\nblindness denial (Anton’s syndrome), and Korsakoff’s\nsyndrome (Hirstein 2005). \nIn a normal population, Johansson and collaborators (Johansson et al.\n2005; Johansson et al. 2006) manually displayed to participants pairs\nof pictures of women’s faces. On each trial, the participant was\nto point to the face he found more attractive. The picture of that\nface was then centered before the participant while the other face was\nhidden. On some trials, participants were asked to explain the reasons\nfor their choices while continuing to look at the selected face. On a\nfew key trials, the experimenters used sleight-of-hand to present to\nthe participant the face that was not selected as though it\nhad been the face selected. Strikingly, the switch was noticed only\n28% of the time. What’s more, when the change was not detected\nparticipants actually gave explanations for their choice that appealed\nto specific features of the unselected face that were not possessed by\nthe selected face 13% of the time. For example, one participant\nclaimed to have chosen the face before him “because I love\nblondes” when in fact he had chosen a dark-haired face\n(Johansson et al. 2006, 690). Johansson and colleagues failed to find\nany systematic differences in the explanations of choice between the\nmanipulated and non-manipulated trials, using a wide variety of\nmeasures. They found, for example, no difference in linguistic markers\nof confidence (including pauses in speech), emotionality, specificity\nof detail, complexity or length of description, or general position in\nsemantic space. These results, like Nisbett’s and\nWilson’s, suggest that at least some of the time when people\nthink they are explaining the bases of their decisions, they are\ninstead merely theorizing or confabulating. \nWegner has found that people can often be manipulated into believing\nthat they willed or intended behavior that is in fact caused by\nanother person’s manipulation and, conversely, that they exerted\nno control over movements that were in fact their own—as with\nOuija boards, with or without a cheating, intentionally directive\nconfederate (Wegner and Wheatley 1999; Wegner 2002). The literature on\n“cognitive dissonance” is replete with cases in which\nparticipants’ attitudes appear to change for reasons they do, or\nwould, deny. According to cognitive dissonance theory, when people\nbehave or appear to behave counternormatively (e.g., incompetently,\nfoolishly, immorally), they will tend to adjust their attitudes so as\nto make the behavior seem less counternormative or\n“dissonant” (Festinger 1957; Aronson 1968; Cooper and\nFazio 1984; Stone and Cooper 2001). For example, people induced to\nfalsely describe as enjoyable a monotonous task they’ve just\ncompleted will tend, later, to report having a more positive attitude\ntoward the task then those not induced to lie (though much less so if\nthey were handsomely paid to lie in which case the behavior is not\nclearly counternormative; Festinger and Carlsmith 1959; but see Bem\n1967, 1972 for an argument that the attitude doesn’t change but\nonly the report of it). Presumably, if such attitude changes were\nknown to the person they would generally fail to have their\ndissonance-reducing effect. Research psychologists have also confirmed\nsuch familiar phenomena as “sour grapes” (Elster\n1983/2016; Lyubomirsky and Ross 1999; Kay, Jiminez, and Jost 2002) and\n“self-deception” (Mele 2001) which presumably also involve\nignorance of the factors driving the relevant judgments and actions.\nAnd of course the Freudian psychoanalytic tradition has also long held\nthat people often have only poor knowledge of their motives and the\ninfluences on their attitudes (Wollheim 1981; Cavell 2006). \nIn light of this empirical research, no major philosopher now holds\n(perhaps no major philosopher ever held) that we have infallible,\nindubitable, incorrigible, or self-intimating knowledge of the causes\nof our judgments, decisions, and behavior. Perhaps weaker forms of\nprivilege also come under threat. But the question arises: Whatever\nfailures there may be in assessing the causes of our attitudes and\nbehavior, are those failures failures of introspection,\nproperly construed? Psychologists tend to cast these results as\nfailures of “introspection”, but if it turns out that a\nvery different and more trustworthy process underwrites our knowledge\nof some other aspects of our minds—such as what our present\nattitudes are (however caused) or our currently ongoing or recently\npast conscious experience—then perhaps we can call only\nthat process introspection, thereby retaining some robust\nform of introspective privilege while acceding to the psychological\nconsensus regarding (what we would now call non-introspective)\nfirst-person knowledge of causes. Indeed, few contemporary\nphilosophical accounts of introspection or privileged self-knowledge\nhighlight, as the primary locus of privilege, the causes of our\nattitudes and behavior (though Bilgrami 2006 is a notable exception).\nThus, the literature reviewed in this section can be interpreted as\nsuggesting that the causes of our behavior are not, after all, the\nsorts of things to which we have introspective access. \nResearch psychologists have generally not been as skeptical of our\nknowledge of our attitudes as they have been of our knowledge of the\ncauses of our attitudes (Section 4.2.1 above). In fact, many of the\nsame experiments that purport to show inaccurate knowledge of the\ncauses of our attitudes nonetheless rely unguardedly on self-report\nfor assessment of the attitudes themselves—a feature of those\nexperiments criticized by Bem (1967). Attitudinal surveys in\npsychology and social science generally rely on participants’\nself-report as the principal source of evidence about attitudes (de\nVaus 1985/2002; Sirken et al. (eds.) 1999). However, as in the case of\nmotives and causes, there’s a long tradition in clinical\npsychology skeptical of our self-knowledge of our attitudes, giving a\nlarge role to “unconscious” motives and attitudes. \nA key challenge in assessing the accuracy of people’s beliefs or\njudgments about their attitudes is the difficulty of accurately\nmeasuring attitudes independently of self-report. There is at present\nno tractable measure of attitude that is generally seen by\nphilosophers as overriding individuals’ own reports about their\nattitudes. However, in the psychological literature,\n“implicit” measures of attitudes—measures of\nattitudes that do not reply on self-report—have recently been\ngaining considerable attention (see Wittenbrink and Schwarz, eds.,\n2007; Petty, Fazio, and Briñol, eds., 2009). Such measures are\nsometimes thought capable of revealing unconscious attitudes or\nimplicit attitudes either unavailable to introspection or erroneously\nintrospected (Wilson, Lindsey, and Schooler 2000; Kihlstrom 2004; Lane\net al. 2007; though see Hahn et al. 2014). \nMuch of the leading research on implicit attitude measures has\nconcerned racism, in accord with the view that racist attitudes,\nthough common, are considered socially undesirable and therefore often\nnot self-ascribed even when present. For example, Campbell, Kruskal,\nand Wallace (1966) explored the use of seating distance as an index of\nracial attitudes, noting that racially Black and White students tended\nto aggregate in classroom seating arrangements. Using facial\nelectromyography (EMG), Vanman et al. (1997) found (racially) White\nparticipants to display facial responses indicative of negative affect\nmore frequently when asked to imagine co-operative activity with Black\nthan with White partners—results interpreted as indicative of\nracist attitudes. Cunningham et al. (2004) showed White and Black\nfaces to White participants while participants were undergoing fMRI\nbrain imaging. They found less amygdala activation when participants\nlooked at faces from their own group than when participants looked at\nother faces; and since amygdala activation is generally associated\nwith negative emotion, they interpreted this tendency suggesting a\nnegative attitude toward outgroup members (see also Hart et al 1990;\nand for discussion Ito and Cacioppo 2007). \nMuch of the recent implicit attitude research has focused on response\npriming and interference in speeded tasks. In priming research, a\nstimulus (the “prime”) is briefly displayed, followed by a\nmask that hides it, and then a second stimulus (the\n“target”) is displayed. The participant’s task is to\nrespond as swiftly as possible to the target, typically with a\nclassification judgment. In evaluative priming, for example,\nthe participant is primed with a positively or negatively valenced\nword or picture (e.g., snake), then asked to make a swift judgment\nabout whether the subsequently presented target word (e.g.,\n“disgusting”) is good or bad, or has some other feature\n(e.g., belongs to a particular category). Generally, negative primes\nwill speed response for negative targets while delaying response for\npositive targets, and positive primes will do the reverse. Researchers\nhave found that photographs of Black faces, whether presented visibly\nor whether presented so quickly as to be subliminal, tend to\nfacilitate the categorization of negative targets and delay the\ncategorization of positive targets for White participants—a\nresult widely interpreted as revealing racist attitudes (Fazio et al.\n1995; Dovidio et al. 1997; Wittenbrink, Judd, and Park 1997). In the\nImplicit Association Test, respondents are asked to respond\ndisjunctively to combined categories, giving for example one response\nif they see either a dark-skinned face or a positively valenced word\nand a different response if they see either a light-skinned face or a\nnegatively valenced word. As in evaluative priming tasks, White\nrespondents tend to respond more slowly when asked to pair\ndark-skinned faces with positively valenced words than with negatively\nvalenced words, which is interpreted as revealing a negative attitude\nor association (Greenwald, McGhee, and Schwartz 1998; Lane et al.\n2007). However, it should be noted that despite its prominence, the\nImplicit Association Task has recently been criticized as having poor\ntest-retest reliability and weak correlations with other measures of\nracism (Oswald, Mitchell, Blanton, Jaccard, and Tetlock 2013;\nGawronski, Morrison, Phills, and Galdi 2017; Payne, Vuletich, and\nLundberg 2017; Singal 2017). \nAs mentioned above, such implicit measures are often interpreted as\nrevealing attitudes to which people have poor or no introspective\naccess. The evidence that people lack introspective knowledge of such\nattitudes generally turns on the low correlations between such\nimplicit measures of racism and more explicit measures such as\nself-report—though due to the recognized social undesirability\nof racial prejudice, it is difficult to disentangle\nself-presentational from self-knowledge factors in self-reports (Fazio\net al. 1995; Greenwald, McGhee, and Schwartz 1998; Wilson, Lindsey,\nand Schooler 2000; Greenwald and Nosek 2009). People who appear racist\nby implicit measures might disavow racism and inhibit racist patterns\nof response on explicit measures (such as when asked to rate the\nattractiveness of faces of different races) because they don’t\nwant to be seen as racist—a motivation that might drive\nthem whether or not they have accurate self-knowledge of their racist\nattitudes. Still, it seems prima facie plausible that people have at\nbest limited knowledge of the patterns of association that drive their\nresponses on priming and other implicit measures. \nBut what do such tests really measure? In philosophy, Zimmerman (2018)\nand Gendler (2008a, 2008b) have argued that measures like the Implicit\nAssociation Test do not measure actual racist beliefs but rather\nsomething else, something under less rational control (Gendler calls\nthem “aliefs”). Schwitzgebel (2010) argues that people who\nare implicitly prejudiced but explicitly egalitarian are “in\nbetween” believing and failing to believe the egalitarian\npropositions that they sincerely accept (see also Levy 2015). Machery\n(2016) argues that implicit measures reveal multi-track dispositions,\nrather than attitudes. Gawronski and Bodenhausen (2006) advance a\nmodel according to which there is a substantial difference between\nimplicit attitudes, defined in terms of associative processes, and\nexplicit attitudes which have a propositional structure and are guided\nby standards of truth and consistency (see also Wilson, Lindsey, and\nSchooler 2000; Greenwald and Nosek 2009). Mandelbaum (2016) and\nBorgoni (2016) also endorse views on which people who are implicitly\nprejudiced but explicitly egalitarian have contradictory attitudes,\nthough they argue that both the implicit and the explicit attitudes\nare propositionally structured and to some extent subject to norms of\nrationality. Payne, Vuletich and Lundberg (2017) argue that implicit\nmeasures capture the situationally-variable accessibility of\nculturally given concepts. \nHow one answers this question about the relation between implicit bias\nand belief or other attitudes bears on the question of the accuracy of\nintrospection of the belief or other attitude in question. On the\nassumption that people are unaware of the extent of their bias, or at\nleast have no direct introspective access to their bias, that failure\nof introspection of bias constitutes a failure of introspection with\nrespect to the attitude in question. On the other hand, if what is at\nstake is merely an association or trait-like disposition, rather than\nan attitude, failure of introspectibility is unsurprising and does not\nbear on the general question of the introspection of attitudes. \nThe issue generalizes beyond implicit bias. To the extent attitudes\nare held to be reflected in, or even defined by, our explicit\njudgments about the matter in question and also, differently but\nperhaps not wholly separably (see Section 2.3.4 above), our explicit\njudgments about our attitudes toward the matter in question,\nour self-knowledge would seem to be correspondingly secure and\nimplicit measures beside the point. To the extent attitudes are held\nto crucially involve swift and automatic, or unreflective, patterns of\nreaction and association, our self-knowledge of them would appear to\nbe correspondingly problematic, corrigible by data from implicit\nmeasures (Bohner and Dickel 2011; Schwitzgebel 2011a,\nforthcoming). \nSimilarly, Carruthers (2011; see also Bem 1967, 1972; Rosenthal 2001;\nCassam 2014) argues that the evidence of Nisbett, Gazzaniga, Wegner,\nand others (reviewed in Section 4.2.1 above) shows that people\nconfabulate not just in reporting the causes of their\nattitudes but also in reporting the attitudes themselves. For example,\nCarruthers suggests that if someone in Nisbett and Wilson’s\nfamous 1977 study confabulates “I thought this pair was\nsoftest” as an explanation of their choice of the rightmost pair\nof stockings, they err not only about the cause of their choice but\nalso in self-ascribing the judgment that the pair was softest. On this\nbasis, Carruthers adopts a self/other parity view (see Section 2.1\nabove) of our self-knowledge of our attitudes, holding that we can\nonly introspect, in the strict sense, conscious experiences like those\nthat arise in perception and imagery. \nCurrently ongoing conscious experience—or maybe immediately past\nconscious experience (if we hold that introspective judgment must\ntemporally follow the state or process introspected, or if emphasize\nthe concerns raised in Section 3.2 about the self-undermining of the\nintrospective process)—is both the most universally acknowledged\ntarget of the introspective process and the target most commonly\nthought to be known with a high degree of privilege. Infallibility,\nindubitability, incorrigibility, and self-intimation claims (see\nSection 4.1.1) are most commonly made for self-knowledge of states\nsuch as being in pain or having a visual experience as of the color\nred, where these states are construed as qualitative states, or\nsubjective experiences, or aspects of our phenomenology or\nconsciousness. (All these terms are intended interchangeably to refer\nto what Block [1995], Chalmers [1996], and other contemporary\nphilosophers call “phenomenal consciousness”.) If\nattitudes are sometimes conscious, then we might also be capable of\nintrospecting those attitudes as part of our capacity to introspect\nconscious experience generally (Goldman 2006; Hill 2009). \nIt’s difficult to study the accuracy of self-ascriptions of\nconscious experience for the same reasons it’s difficult to\nstudy the accuracy of our self-ascriptions of attitudes (Section\n4.2.2): There’s no widely accepted measure to trump or confirm\nself-report. In the medical literature on pain, for example, no\nbehavioral or physiological measure of pain is generally thought\ncapable of overriding self-report of current pain, despite the fact\nthat scaling issues remain a problem within and especially between\nsubjects (Williams, Davies, and Chadury 2000) as does retrospective\nassessment (Redelmeier and Kahneman 1996). When physiological markers\nof pain and self-report dissociate, it’s by no means clear that\nthe physiological marker should be taken as the more accurate index\n(for methodological recommendations see Price and Aydede 2005).\nCorresponding remarks apply to the case of pleasure (Haybron\n2008). \nAs mentioned in Section 3.3 above, early introspective psychologists\nboth asserted the difficulty of accurately introspecting conscious\nexperience and achieved only mixed success in their attempts to obtain\nscientifically replicable (and thus presumably accurate) data through\nthe use of trained introspectors. In some domains they achieved\nconsiderable success and replicability, such as in the construction of\nthe “color solid” (a representation of the three primary\ndimensions of variation in color experience: hue, saturation, and\nlightness or brightness), the mapping of the size of “just\nnoticeable differences” between sensations and the\n“liminal” threshold below which a stimulus is too faint to\nbe experienced, and the (at least roughly) logarithmic relationship\nbetween the intensity of a sensory stimulus and the intensity of the\nresulting experience (the “Weber-Fechner law”).\nContemporary psychophysics—the study of the relation between\nphysical stimuli and the resulting sense experiences or\npercepts—is rooted in these early introspective studies.\nHowever, other sorts of phenomena proved resistant to cross-laboratory\nintrospective consensus—such as the possibility or not of\nimageless thought (see the entry on\n “mental imagery”),\n the structure of emotion, and the experiential aspects of of\nattention. Perhaps these facts about the range of early introspective\nagreement and apparently intractable disagreement cast light on the\nrange over which careful and well-trained introspection is and is not\nreliable. \nEricsson and Simon (1984/1993; Ericsson 2003) discuss and review\nrelationships between the participant’s performance on various\nproblem-solving tasks, their concurrent verbalizations of conscious\nthoughts (“think aloud protocols”), and their immediately\nretrospective verbalizations. The existence of good relationships in\nthe predicted directions in many problem-solving tasks lends empirical\nsupport to the view that people’s reports about their stream of\nthoughts often accurately reflect those thoughts. For example,\nEricsson and Simon find that think-aloud and retrospective reports of\nthought processes correlate with predicted patterns of eye movement\nand response latency. Ericsson and Simon also cite studies like that\nof Hamilton and Sanford (1978), who asked participants to make yes or\nno judgments about whether pairs of letters were in alphabetical order\n(like MO) or not (like RP) and then to describe retrospectively their\nmethod for arriving at the judgments. When participants\nretrospectively reported knowing the answer\n“automatically” without an intervening conscious process,\nreaction times were swift and did not depend on the distance between\nthe letters. When participants retrospectively reported “running\nthrough” a sequential series of letters (such as\n“LMNO” when prompted with “MO”) reaction times\ncorrelated nicely with reported length of run-through. On the other\nhand, Flavell, Green, and Flavell (1995) report gross and widespread\nintrospective error about recently past and even current (conscious)\nthought in young children; and Smallwood and Schooler (2006) review\nliterature that suggests that people are not especially good at\ndetecting when their mind is wandering. \nIn the 20th century, philosophers arguing against infallibilism often\ndevised hypothetical examples in which they suggested it was plausible\nto attribute introspective error; but even if such examples succeed,\nthey are generally confined to far-fetched scenarios, pathological\ncases, or very minor or very brief mistakes (e.g., Armstrong 1963;\nChurchland 1988; Kornblith 1998, with an eye to the distinction\nbetween mistakes about current conscious experience and other sorts of\nmistakes). In the 21st century, philosophical critics of the accuracy\nof introspective judgments about consciousness shifted their focus to\ncases of widespread disagreement or (putative) error, either among\nordinary people or among research specialists. Dennett (1991),\nBlackmore (2002), and Schwitzgebel (2011b), for example, argue that\nmost people are badly mistaken about the nature of the experience of\nperipheral vision. These authors argue that people experience visual\nclarity only in a small and rapidly moving region of about 1–2\ndegrees of visual arc, contrary to the (they say) widespread\nimpression most people have that they experience a substantially\nbroader range of stable clarity in the visual field. Other recent\narguments against the accuracy of introspective judgments about\nconscious experience turn on citing the widespread disagreement about\nwhether there is a “phenomenology of thinking” beyond that\nof imagery and emotion, about whether sensory experience as a whole is\n“rich” (including for example constant tactile experience\nof one’s feet in one’s shoes) or “thin”\n(limited mostly just to what is in attention at any one time), and\nabout the nature of visual imagery experience (Hurlburt and\nSchwitzgebel 2007; Bayne and Spener 2010; Schwitzgebel 2011b; though\nsee Hohwy 2011). \nIrvine (2013, forthcoming) has argued that the methodological problems\nin this area are so severe that the term “consciousness”\nshould be eliminated from scientific discourse as impossible to\neffectively operationalize or measure. Feest (2014) and Timmermans and\nCleeremans (2015) similarly highlight the substantial methodological\nchallenges using introspective reports in the science of\nconsciousness, though without being quite as pessimistic as\nIrvine.","contact.mail":"eschwitz@citrus.ucr.edu","contact.domain":"citrus.ucr.edu"}]
