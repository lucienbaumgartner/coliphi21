[{"date.published":"2006-04-19","date.changed":"2020-01-06","url":"https://plato.stanford.edu/entries/moral-psych-emp/","author1":"John Doris","author2":"Lachlan Walmsley","author1.info":"https://philosophy.cornell.edu/john-m-doris","author2.info":"https://philosophy.rutgers.edu/people/faculty/details/182-faculty1/faculty-profiles/635-stich-stephen","entry":"moral-psych-emp","body.text":"\n\n\nMoral psychology investigates human functioning in moral contexts, and\nasks how these results may impact debate in ethical theory. This work\nis necessarily interdisciplinary, drawing on both the empirical\nresources of the human sciences and the conceptual resources of\nphilosophical ethics. The present article discusses several topics\nthat illustrate this type of inquiry: thought experiments,\nresponsibility, character, egoism v. altruism, and moral\ndisagreement.\n\nContemporary moral psychology—the study of human thought and\nbehavior in ethical contexts—is resolutely interdisciplinary:\npsychologists freely draw on philosophical theories to help structure\ntheir empirical research, while philosophers freely draw on empirical\nfindings from psychology to help structure their\n theories.[1] \nWhile this extensive interdisciplinarity is a fairly recent\ndevelopment (with few exceptions, most of the relevant work dates from\nthe past quarter century), it should not be a surprising development.\nFrom antiquity to the present, philosophers have not been bashful\nabout making empirical claims, and many of these empirical claims have\nbeen claims about human psychology (Doris & Stich 2005). It is\ntherefore unremarkable that, with the emergence of scientific\npsychology over the past century and a half, some of these\nphilosophers would think to check their work against the systematic\nfindings of psychologists (hopefully, while taking special care to\navoid being misled by scientific controversy; see Doris 2015, Chapter\n3; Machery & Doris forthcoming).  \nSimilarly, at least since the demise of behaviorism, psychologists\nhave been keenly interested in normative phenomena in general and\nethical phenomena in particular. It is therefore unremarkable that\nsome of these psychologists would seek to enrich their theoretical\nframeworks with the conceptual resources of a field intensively\nfocused on normative phenomena: philosophical ethics. As a result, the\nfield demarcated by “moral psychology”, routinely involves\nan admixture of empirical and normative inquiry, pursued by both\nphilosophers and psychologists—increasingly, in the form of\ncollaborative efforts involving practitioners from both fields.  \nFor philosophers, the special interest of this interdisciplinary\ninquiry lies in the ways moral psychology may help adjudicate between\ncompeting ethical theories. The plausibility of its associated moral\npsychology is not, of course, the only dimension on which an ethical\ntheory may be evaluated; equally important are normative\nquestions having to do with how well a theory fares when compared to\nimportant convictions about such things as justice, fairness, and the\ngood life. Such questions have been, and will continue to be, of\ncentral importance for philosophical ethics. Nonetheless, it is\ncommonly supposed that an ethical theory committed to an impoverished\nor inaccurate conception of moral psychology is at a serious\ncompetitive disadvantage. As Bernard Williams (1973, 1985; cf.\nFlanagan 1991) forcefully argued, an ethical conception that commends\nrelationships, commitments, or life projects that are at odds with the\nsorts of attachments that can be reasonably expected to take root in\nand vivify actual human lives is an ethical conception with—at\nbest—a very tenuous claim to our assent. \nWith this in mind, problems in ethical theory choice making reference\nto moral psychology can be framed by two related inquiries: \nThe first question is one of philosophical scholarship: what are the\npsychological commitments of various positions in philosophical\nethics? The second question takes us beyond the corridors of\nphilosophy departments and to the sorts of questions asked, and\nsometimes answered, by the human sciences, including psychology,\nanthropology, sociology, history, cognitive science, linguistics and\nneuroscience. Thus, contemporary moral psychology is\nmethodologically pluralistic: it aims to answer philosophical\nquestions, but in an empirically responsible way. \nHowever, it will sometimes be difficult to tell which claims in\nphilosophical ethics require empirical substantiation. Partly, this is\nbecause it is sometimes unclear whether, and to what extent, a\ncontention counts as empirically assessable. Consider questions\nregarding “normal functioning” in mental health care: are\nthe answers to these questions statistical, or evaluative (Boorse\n1975; Fulford 1989; Murphy 2006)? For example, is “normal”\nmental health simply the psychological condition of most people, or is\nit good mental health? If the former, the issue is, at least\nin principle, empirically decidable. If the latter, the issues must be\ndecided, if they can be decided, by arguments about value. \nAdditionally, philosophers have not always been explicit about\nwhether, and to what extent, they are making empirical claims. For\nexample, are their depictions of moral character meant to identify\npsychological features of actual persons, or to articulate ideals that\nneed not be instantiated in actual human psychologies? Such questions\nwill of course be complicated by the inevitable diversity of\nphilosophical opinion. \nIn every instance, therefore, the first task is to carefully document\na theory’s empirically assessable claims, whether they are\nexplicit or, as may often be the case, tacit. Once claims apt for\nempirical assessment have been located, the question becomes one of\nidentifying any relevant empirical literatures. The next job is to\nassess those literatures, in an attempt to determine what conclusions\ncan be responsibly drawn from them. Science, particularly social\nscience, being what it is, many conclusions will be provisional; the\nphilosophical moral psychologist must be prepared to adjudicate\ncontroversies in other fields, or offer informed conjecture regarding\nfuture findings. Often, the empirical record will be crucially\nincomplete. In such cases, philosophers may be forced to engage in\nempirically disciplined conjecture, or even to engage in their own\nempirical work, as some philosophers are beginning to\n do.[2] \nWhen the philosophical positions have been isolated, and putatively\nrelevant empirical literatures assessed, we can begin to evaluate the\nplausibility of the philosophical moral psychology: Is the speculative\npicture of psychological functioning that informs some region of\nethical theory compatible with the empirical picture that emerges from\nsystematic observation? In short, is the philosophical picture\nempirically adequate? If it is determined that the\nphilosophical conception is empirically adequate, the result is\nvindicatory. Conversely, if the philosophical moral\npsychology in question is found to be empirically inadequate,\nthe result is revisionary, compelling alteration, or even\nrejection, of those elements of the philosophical theory presupposing\nthe problematic moral psychology. The process will often be\ncomparative. Theory choice in moral psychology, like other\ntheory choice, involves tradeoffs, and while an empirically\nundersupported approach may not be decisively eliminated from\ncontention on empirical grounds alone, it may come to be seen as less\nattractive than theoretical options with firmer empirical\nfoundations. \nThe winds driving the sort of disciplinary cross-pollination we\ndescribe do not blow in one direction. As philosophers writing for an\nencyclopedia of philosophy, we are naturally concerned with the ways\nempirical research might shape, or re-shape, philosophical ethics. But\nphilosophical reflection may likewise influence empirical research,\nsince such research is often driven by philosophical suppositions that\nmay be more or less philosophically sound. The best interdisciplinary\nconversations, then, should benefit both parties. To illustrate the\ndialectical process we have described, we will consider a variety of\ntopics in moral psychology. Our primary concerns will be\nphilosophical: What are some of the most central problems in\nphilosophical moral psychology, and how might they be resolved?\nHowever, as the hybrid nature of our topic invites us to do, we will\npursue these questions in an interdisciplinary spirit, and are hopeful\nthat our remarks will also engage interested scientists. Hopefully,\nthe result will be a broad sense of the problems and methods that will\nstructure research on moral psychology during the 21st\ncentury. \n“Intuition pumps” or “thought experiments”\nhave long been well-used items in the philosopher’s toolbox\n(Dennett 1984: 17–18; Stuart et al. 2018). Typically, a thought\nexperiment presents an example, often a hypothetical example, in order\nto elicit some philosophically telling response. If a thought\nexperiment is successful, it may be concluded that competing theories\nmust account for the resulting response. These responses are supposed\nto serve an evidential role in philosophical theory choice;\nif you like, they can be understood as data competing\ntheories must\n accommodate.[3]\n If an appropriate audience’s ethical responses to a thought\nexperiment conflict with the response a theory prescribes for the\ncase, the theory has suffered a counterexample. \nThe question of whose responses “count” philosophically\n(or, who is the “appropriate” audience) has been answered\nin a variety of ways, but for many philosophers, the intended audience\nfor thought experiments seems to be some species of “ordinary\nfolk” (see Jackson 1998: 118, 129; Jackson & Pettit 1995:\n22–9; Lewis 1989: 126–9). Of course, the relevant folk\nmust possess such cognitive attainments as are required to understand\nthe case at issue; very young children are probably not an ideal\naudience for thought experiments. Accordingly, some philosophers may\ninsist that the relevant responses are the considered judgments of\npeople with the training required to see “what is at stake\nphilosophically”. But if the responses are to help adjudicate\nbetween competing theories, the responders must be more or less\ntheoretically neutral, and this sort of neutrality is\nrather likely to be vitiated by philosophical education. A dilemma\nemerges. On the one hand, philosophically naïve subjects may be\nthought to lack the erudition required to grasp the philosophical\nstakes. On the other, with increasing philosophical sophistication\ncomes, very likely, philosophical partiality; one audience is\nnaïve, and the other\n prejudiced.[4] \nHowever exactly the philosophically relevant audience is specified,\nthere are empirical questions that must be addressed in determining\nthe philosophical potency of a thought experiment. In particular, when\ndeciding what philosophical weight to give a response, philosophers\nneed to determine its origins. What features of the\nexample are implicated in a given judgment—are people\nreacting to the substance of the case, or the style of exposition?\nWhat features of the audience are implicated in their\nreaction—do different demographic groups respond to the example\ndifferently? Are there factors in the environment that are affecting\npeople’s intuitive judgments? Does the order in which people\nconsider examples affect their judgments? Such questions raise the\nfollowing concern: judgments about thought experiments dealing with\nmoral issues might be strongly influenced by ethically\nirrelevant characteristics of the example or the audience or the\nenvironment or the order of presentation. Whether a characteristic is\nethically relevant is a matter for philosophical discussion, but\ndetermining the status of a particular thought experiment also\nrequires empirical investigation of its causally relevant\ncharacteristics. We’ll now describe some examples of such\ninvestigation. \nAs part of their famous research on the “heuristics and\nbiases” that underlie human reasoning, Tversky and Kahneman\n(1981) presented subjects with the following problem: \nImagine that the U.S. is preparing for the outbreak of an unusual\nAsian disease, which is expected to kill 600 people. Two alternative\nprograms to combat the disease have been proposed. Assume that the\nexact scientific estimate of the consequences of the programs are as\nfollows: \nA second group of subjects was given an identical problem, except that\nthe programs were described as follows: \nOn the first version of the problem, most subjects thought that\nProgram A should be adopted. But on the second version, most chose\nProgram D, despite the fact that the outcome described in A is\nidentical to the one described in C. The disconcerting implication of\nthis study is that ethical responses may be strongly influenced by the\nmanner in which cases are described or framed. It seems that\nsuch framing sensitivities constitute ethically irrelevant influences\non ethical responses. Unless this sort of possibility can be\nconfidently eliminated, one should hesitate to rely on responses to a\nthought experiment for adjudicating theoretical controversies. Such\npossibilities can only be eliminated through systematic empirical\n work.[5] \nWhile a relatively small percentage of empirical work on\n“heuristics and biases” directly addresses moral\nreasoning, numerous philosophers who have addressed the issue\n(Horowitz 1998; Doris & Stich 2005; Sinnott-Armstrong 2005;\nSunstein 2005) agree that phenomena like framing effects are likely to\nbe pervasively implicated in responses to ethically freighted\nexamples, and argue that this state of affairs should cause\nphilosophers to view the thought-experimental method with considerable\nconcern. \nWe turn now to order effects. In a pioneering study, Petrinovich and\nO’Neill (1996) found that participants’ moral intuitions\nvaried with the order in which the thought experiments were presented.\nSimilar findings have been reported by Liao et al. (2012), Wiegman et\nal. (2012), and Schwitzgebel & Cushman (2011, 2015). The\nSchwitzgebel and Cushman studies are particularly striking, since they\nset out to explore whether order effects in moral intuitions were\nsmaller or non-existent in professional philosophers. Surprisingly,\nthey found that professional philosophers were also subject to order\neffects, even though the thought experiments used are well known in\nthe field. Schwitzgebel and Cushman also report that in some cases\nphilosophers intuitions show substantial order effects when the\nintuitions of non-philosophers don’t. \nAudience characteristics may also affect the outcome of thought\nexperiments. Haidt and associates (1993: 613) presented stories about\n“harmless yet offensive violations of strong social norms”\nto men and women of high and low socioeconomic status (SES) in\nPhiladelphia (USA), Porto Alegre, and Recife (both in Brazil). For\nexample: \nA man goes to the supermarket once a week and buys a dead chicken. But\nbefore cooking the chicken, he has sexual intercourse with it. Then he\ncooks it and eats it. (Haidt et al. 1993: 617) \nLower SES subjects tended to “moralize” harmless and\noffensive behaviors like that in the chicken story. These subjects\nwere more inclined than their high SES counterparts to say that the\nactor should be “stopped or punished”, and more inclined\nto deny that such behaviors would be “OK” if customary in\na given country (Haidt et al. 1993: 618–19). The point is not\nthat lower SES subjects are mistaken in their moralization of such\nbehaviors while the urbanity of higher SES subjects represents a more\nrationally defensible response. The difficulty is deciding\nwhich—if any—of the conflicting responses is fit to serve\nas a constraint on ethical theory, when both may equally be the result\nof more or less arbitrary cultural factors. \nPhilosophical audiences typically decline to\nmoralize the offensive behaviors, and we ourselves share their\ntolerant attitude. But of course these audiences—by virtue of\neducational attainments, if not stock portfolios—are\noverwhelmingly high SES. Haidt’s work suggests that it is a\nmistake for a philosopher to say, as Jackson (1998: 32n4; cf. 37)\ndoes, that “my intuitions reveal the folk conception in as much\nas I am reasonably entitled, as I usually am, to regard myself as\ntypical”. The question is: typical of what demographic? Are\nphilosophers’ ethical responses determined by the philosophical\nsubstance of the examples, or by cultural idiosyncrasies that are very\nplausibly thought to be ethically irrelevant? Once again, until such\npossibilities are ruled out by systematic empirical investigation, the\nphilosophical heft of a thought experiment is open to question. \nIn recent years there has been a growing body of research reporting\nthat judgments evoked by moral thought experiments are affected by\nenvironmental factors that look to be completely irrelevant to the\nmoral issue at hand. The presence of dirty pizza boxes and a whiff of\nfart spray (Schnall et al. 2008a), the use of soap (Schnall et al.\n2008b) or an antiseptic handwipe (Zhong et al. 2010), or even the\nproximity of a hand sanitizer dispenser (Helzer & Pizarro 2011)\nhave all been reported to influence moral intuitions. Tobia et al.\n(2013) found that the moral intuitions of both students and\nprofessional philosophers are affected by spraying the questionnaire\nwith a disinfectant spray. Valdesolo and DeSteno (2006) reported that\nviewing a humorous video clip can have a substantial impact on\nparticipant’s moral intuitions. And Strohminger et al. (2011)\nhave shown that hearing different kinds of audio clips (stand-up\ncomedy or inspirational stories from a volume called Chicken Soup\nfor the Soul) has divergent effects on moral intuitions. \nHow should moral theorists react to findings like these? One might, of\ncourse, eschew thought experiments in ethical theorizing. While this\nmethodological austerity is not without appeal, it comes at a cost.\nDespite the difficulties, thought experiments are a window, in some\ncases the only accessible window, into important regions of ethical\nexperience. In so far as it is disconnected from the thoughts and\nfeels of the lived ethical life, ethical theory risks being\n“motivationally inaccessible”, or incapable of engaging\nthe ethical concern of agents who are supposed to live in accordance\nwith the normative standards of the\n theory.[6]\n Fortunately, there is another possibility: continue pursuing the\nresearch program that systematically investigates responses to\nintuition pumps. In effect, the idea is to subject philosophical\nthought experiments to the critical methods of experimental social\npsychology. If investigations employing different experimental\nscenarios and subject populations reveal a clear trend in responses,\nwe can begin to have some confidence that we are identifying a deeply\nand widely shared moral conviction. Philosophical discussion may\nestablish that convictions of this sort should serve as a constraint\non moral theory, while responses to thought experiments that empirical\nresearch determines to lack such solidity, such as those susceptible\nto order, framing or environmental effects, or those admitting of\nstrong cultural variation, may be ones that ethical theorists can\nsafely disregard.  \nA philosophically informed empirical research program akin to the one\njust described is more than a methodological fantasy. This approach\naccurately describes a number of research programs aimed at informing\nphilosophical debates through interdisciplinary research. \nOne of the earliest examples of this kind of work was inspired in\nlarge part by the work of Knobe (2003a,b, 2006) and addressed\nquestions surrounding “folk morality” on issues ranging\nfrom intentional action to causal responsibility (see Knobe 2010 for\nreview and discussion). This early work helped to spur the development\nof a truly interdisciplinary research program with both philosophers\nand psychologists investigating the folk morality of everyday life.\n(See the Stanford Encyclopedia of Philosophy article on\nExperimental Moral Philosophy for a more complete treatment of this\nresearch.) \nAnother related philosophical debate concerns the compatibility of\nfree will and moral responsibility with determinism. On the one hand,\nincompatibilists insist that determinism (the view that all events are\njointly determined by antecedent events as governed by laws of\nnature), is incompatible with moral responsibility.\nTypically, these accounts also go on to specify what particular\ncapacity is required to be responsible for one’s own behavior\n(e.g., that agents have alternate possibilities for behavior, or are\nthe “ultimate” source of their behavior, or both (Kane\n2002: 5; Haji 2002:\n 202–3).[7]\n On the other hand, compatibilists argue that determinism and\nresponsibility are compatible, often by denying that\nresponsible agency requires that the actor have genuinely open\nalternatives, or rejecting the ultimacy condition that requires\nindeterminism (or impossible demands for self-creation). In short,\ncompatibilists hold that people may legitimately be held responsible\neven though there is some sense in which they “could not have\ndone otherwise” or are not the “ultimate source” of\ntheir behavior. Incompatibilists deny that this is the case.\nProponents of these two opposing positions have remained relatively\nentrenched, and some participants have raised fears of a\n“dialectical stalemate” (Fischer 1994: 83–5). \nA critical issue in these debates has been the claim that the\nincompatibilist position better captures folk moral judgments about\nagents whose actions have been completely determined (e.g., G.\nStrawson 1986: 88; Smilansky 2003: 259; Pereboom 2001: xvi;\nO’Connor 2000: 4; Nagel 1986: 113, 125; Campbell 1951: 451; Pink\n2004: 12). For example, Robert Kane (1999: 218; cf. 1996: 83–5),\na leading incompatibilist, reports that in his experience “most\nordinary persons start out as natural incompatibilists”, and\n“have to be talked out of this natural incompatibilism by the\nclever arguments of philosophers”. \nUnsurprisingly, some compatibilists have been quick to assert the\ncontrary. For example, Peter Strawson (1982) famously argued that in\nthe context of “ordinary interpersonal relationships”,\npeople are not haunted by the specter of determinism; such\nmetaphysical concerns are irrelevant to their experience and\nexpression of the “reactive attitudes”—anger,\nresentment, gratitude, forgiveness, and the like—associated with\nresponsibility assessment. Any anxiety about determinism, Strawson\ninsisted, is due to the “panicky metaphysics” of\nphilosophers, not incompatibilist convictions on the part of ordinary\npeople. However, incompatibilists have historically been thought to\nhave ordinary intuitions on their side; even some philosophers with\ncompatibilist leanings are prepared to concede the incompatibilist\npoint about “typical” response tendencies (e.g., Vargas\n2005a,b). \nNeither side, so far as we are aware, has offered much in the way of\nsystematic evidence of actual patterns of folk moral judgments.\nRecently however, a now substantial research program has begun to\noffer empirical evidence on the relationship between determinism and\nmoral responsibility in folk moral judgments. \nInspired by the work of Frankfurt (1988) and others, Woolfolk, Doris,\nand Darley (2006) hypothesized that observers may hold actors\nresponsible even when the observers judge that the actors could not\nhave done otherwise, if the actors appear to “identify”\nwith their behavior. Roughly, the idea is that the actor identifies\nwith a behavior—and is therefore responsible for it—to the\nextent that she “embraces” the behavior, or performs it\n“wholeheartedly” regardless of whether genuine\nalternatives for behavior are\n possible.[8]\n Woolfolk et al.’s suspicion was, in effect, that people’s\n(presumably tacit) theory of responsibility is compatibilist. \nTo test this, subjects were asked to read a story about an agent who\nwas forced by a group of armed hijackers to kill a man who had been\nhaving an affair with his wife. In the “low\nidentification” condition, the man was described as being\nhorrified at being forced to kill his wife’s lover, and as not\nwanting to do so. In the “high identification” condition,\nthe man is instead described as welcoming the opportunity and wanting\nto kill his wife’s lover. In both cases, the man is not given a\nchoice, and does kill his wife’s lover. \nConsistent with Woolfolk and colleagues’ hypothesis, subjects\njudged that the highly identifying actor was more responsible, more\nappropriately blamed, and more properly subject to guilt than the low\nidentification\n actor.[9]\n This pattern in folk moral judgments seems to suggest that\nparticipants were not consistently incompatibilist in their\nresponsibility attributions, because the lack of alternatives\navailable to the actor was not alone sufficient to rule out such\nattributions. \nIn response to these results, those who believe that folk morality is\nincompatibilist may be quick to object that the study merely suggests\nthat responsibility attributions are influenced by identification, but\nsays nothing about incompatibilist commitments or the lack thereof.\nSubjects still may have believed that the actor could have done\notherwise. To address this concern, Woolfolk and colleagues also\nconducted a version of the study in which the man acted under the\ninfluence of a “compliance drug”. In this case,\nparticipants were markedly less likely to agree that the man\n“was free to behave other than he did” and yet they still\nheld the agent who identified with the action as more responsible than\nthe agent who did not. These results look to pose a clear challenge to\nthe view that ordinary folk are typically incompatibilists. \nA related pattern of responses was obtained by Nahmias, Morris,\nNadelhoffer and Turner (2009) who instead described agents preforming\nimmoral behaviors in a “deterministic world” of the sort\noften described in philosophy classrooms. One variation read as\nfollows: \nImagine that in the next century we discover all the laws of nature,\nand we build a supercomputer which can deduce from these laws of\nnature and from the current state of everything in the world exactly\nwhat will be happening in the world at any future time. It can look at\neverything about the way the world is and predict everything about how\nit will be with 100% accuracy. Suppose that such a supercomputer\nexisted, and it looks at the state of the universe at a certain time\non March 25th, 2150 C.E., twenty years before Jeremy Hall is born. The\ncomputer then deduces from this information and the laws of nature\nthat Jeremy will definitely rob Fidelity Bank at 6:00 PM on January\n26th, 2195. As always, the supercomputer’s prediction is\ncorrect; Jeremy robs Fidelity Bank at 6:00 PM on January 26th,\n2195. \nSubjects were then asked whether Jeremy was morally blameworthy. Most\nsaid yes, indicating that they thought an agent could be morally\nblameworthy even if his behaviors were entirely determined by natural\nlaws. Consistent with the Woolfolk et al. results, it appears that the\nsubjects’ judgments, at least those having to do with moral\nblameworthiness, were not governed by a commitment to\nincompatibilism. \nThis emerging picture was complicated, however, by Nichols and Knobe\n(2007), which argued that the ostensibly compatibilist responses were\nperformance errors driven by an affective response to the\nagents’ immoral actions. To demonstrate this, all subjects were\nasked to imagine two universes—a universe completely governed by\ndeterministic laws (Universe A) and a universe (Universe B) in which\neverything is determined except for human decisions which are not\ncompletely determined by deterministic laws and what has happened in\nthe past. In Universe B, but not Universe A, “each human\ndecision does not have to happen the way it does”. Some\nsubjects were assigned to a concrete condition, and asked to make a\njudgment about a specific individual in specific circumstances, while\nothers were assigned to an abstract condition, and asked to make a\nmore general judgment, divorced from any particular individual. The\nhypothesis was that the difference between these two conditions would\ngenerate different responses regarding the relationship between\ndeterminism and moral responsibility. Subjects in the concrete\ncondition read a story about a man, “Bill”, in the\ndeterministic universe who murders his wife and children in a\nparticularly ghastly manner, and were asked whether Bill was morally\nresponsible for what he had done. By contrast, subjects in the\nabstract condition were asked “In Universe A, is it possible for\na person to be fully morally responsible for their actions?”\nSeventy-two percent of subjects in the concrete condition gave a\ncompatibilist response, holding Bill responsible in Universe A,\nwhereas less than fifteen percent of subjects in the abstract\ncondition gave a compatibilist response, allowing that people could be\nfully morally responsible in the deterministic Universe A. \nIn line with previous experimental work demonstrating that increased\naffective arousal amplified punitive responses to wrongdoing (Lerner,\nGoldberg, & Tetlock 1998), Nichols and Knobe hypothesized that\npreviously observed compatibilist responses were the result of the\naffectively laden nature of the stimulus materials. When this\naffective element was eliminated from the materials (as in the\nabstract condition), participants instead exhibited an incompatibilist\npattern of responses. \nMore recently, Nichols and Knobe’s line of reasoning has come\nunder fire from two directions. First, a number of studies have now\ntried to systematically manipulate how affectively arousing the\nimmoral behavior performed is, but have not found that these changes\nsignificantly alter participants’ judgments of moral\nresponsibility in deterministic scenarios. Rather, the differences\nseem to be best explained simply by whether the case was described\nabstractly or concretely (see Cova et al. 2012 for work with patients\nwho have frontotemporal dementia, and see Feltz & Cova 2014 for a\nmeta-analysis). Second, a separate line of studies from Murray and\nNahmias (2014) argued that participants who exhibited the apparently\nincompatibilist pattern of responses were making a critical error in\nhow they understood the deterministic scenario. In particular, they\nargued these participants mistakenly took the agents, or their mental\nstates, in these deterministic scenarios to be “bypassed”\nin the causal chain leading up to their behavior. In support of their\nargument, Murray and Nahmias (2014) demonstrated that when analyses\nwere restricted to the participants who clearly did not take the agent\nto be bypassed, these participants judged the agent to be morally\nresponsible (blameworthy, etc.) despite being in a deterministic\nuniverse. Unsurprisingly, this line of argument has, in turn, inspired\na number of further counter-responses, both empirical (Rose &\nNichols 2013) and theoretical (Björnsson & Pereboom 2016),\nwhich caution against the conclusions of Murray and Nahmias. \nWhile the debate continues over whether the compatibilist or\nincompatibilist position better captures folk moral judgments of\nagents in deterministic universes, a related line of research has\nsprung up around what is widely taken to be the most convincing\ncontemporary form of argument for incompatibilism: manipulation\narguments (e.g., Mele 2006, 2013, Pereboom 2001, 2014).\nPereboom’s Four-Case version, for example, begins with the case\nof an agent named Plum who is manipulated by neuroscientists who use a\nradio-like technology to change Plum’s neural states, which\nresults in him wanting and then deciding to kill a man named White. In\nthis case, it seems clear that Plum did not freely decide to kill\nWhite. Compare this case to a second one, in which the team of\nneuroscientists programmed Plum at the beginning of his life in a way\nthat resulted in him developing the desire (and making the decision)\nto kill White. The incompatibilist argues that these two cases do not\ndiffer in a way that is relevant for whether Plum acted freely, and\nso, once again, it seems that Plum did not freely decide to kill\nWhite. Now compare this to a third case, in which Plum’s desire\nand decision to kill White were instead determined by his cultural and\nsocial milieu, rather than by a team of neuroscientists. Since the\nonly difference between the second and third case is the particular\ntechnological process through which Plum’s mental states were\ndetermined, he would again seem to not have freely decided to kill\nWhite. Finally, in a fourth and final case, Plum’s desire and\ndecision to kill White was determined jointly by the past states and\nthe laws of nature in our own deterministic universe. Regarding these\nfour cases, Pereboom argues that, since there is no difference between\nany of the four cases that is relevant to free will, if Plum was not\nmorally responsible in the first case, then he was not morally\nresponsible in the fourth. \nIn response to this kind of manipulation-based argument for\nincompatibilism, a number of researchers have taken aim at painting a\nbetter empirical picture of ordinary moral judgments concerning\nmanipulated agents. This line of inquiry has been productive on two\nlevels. First, a growing number of empirical studies have investigated\nmoral responsibility judgments about cases of manipulation, and now\nprovide a clearer psychological picture for why manipulated agents are\njudged to lack free will and moral responsibility. Second, continuing\ntheoretical work, informed by this empirical picture, has provided new\nreasons for doubting that manipulation based arguments actually\nprovide evidence against compatibilism. \nOne line of empirical research, led by Chandra Sripada (2012) has\nasked whether manipulated agents are perceived to be unfree because\n(a) they lack ultimate control over their actions (a capacity\nincompatibilists take to be essential for moral responsibility) or\ninstead because (b) their psychological or volitional capacities (the\ncapacities focused on by compatibilists) have been damaged. Using a\nstatistical approach called Structural Equation Modeling (or SEM),\nSripada found that participants’ moral responsibility judgments\nwere best explained by whether they believed the psychological and\nvolitional capacities of the agent were damaged by manipulation and\nnot whether the agent lacked control over her actions. This finding\nsuggests that patterns of judgment in cases of manipulation are more\nconsistent with the predictions of compatibilism than with\nincompatibilism. \nTaking a different approach, Phillips and Shaw (2014) demonstrated\nthat the reduction of moral responsibility that is typically observed\nin cases of manipulation depends critically on the role of an\nintentional manipulator. In particular, ordinary people were\nshown to distinguish between (1) the moral responsibility of agents\nwho are made to do a particular act by features of the situation they\nare in (i.e., situational determinism), and (2) the moral\nresponsibility of agents who are made to do that same act by another\nintentional agent (i.e., manipulation). This work suggests that the\nordinary practice of assessing freedom and responsibility is likely to\nclearly distinguish between cases that do and do not involve a\nmanipulator who intervenes with the intention of causing the\nmanipulated agent to do the immoral action. A series of studies by\nMurray and Lombrozo (2016) further elaborates these findings by\nproviding evidence that the specific reduction of moral responsibility\nthat results from being manipulated arises from the perception that\nthe agent’s mental states are bypassed. \nCollectively, two lessons have come out of this work on the ordinary\npractice of assessing the moral responsibility of manipulated agents:\n(1) folk morality provides a natural way of distinguishing between the\ndifferent cases used in manipulation-based arguments (those that do\ninvolve the intentional intervention of a manipulator vs. those that\ndon’t) and (2) folk morality draws an intimate link between the\nmoral responsibility of an agent and that agent’s mental and\nvolitional capacities. Building on this increasingly clear empirical\npicture, Deery and Nahmias (2017) formalized these basic principles in\ntheoretical work that argues for a principled way of distinguishing\nbetween the moral responsibility of determined and manipulated\nagents. \nWhile the majority of evidence may currently be in favor of the view\nthat folk morality adheres to a kind of “natural\ncompatibilism” (Cova & Kitano 2013), this remains a\ncontentious topic, and new work is continually emerging on both sides\nof the debate (Andow & Cova 2016; Bear & Knobe 2016;\nBjörnsson 2014; Feltz & Millan 2013; Figdor & Phelan\n2015; Knobe 2014). One thing that has now been agreed on by parties on\nboth sides of this debate, however, is a critical role for careful\nempirical studies (Björnsson & Pereboom 2016; Knobe 2014;\nNahmias 2011). \nTo date, empirically informed approaches to moral psychology have been\nmost prominent in discussions of moral character and virtue. The focus\nis decades of experimentation in “situationist” social\npsychology: unobtrusive features of situations have repeatedly been\nshown to impact behavior in seemingly arbitrary, and sometimes\nalarming, ways. Among the findings that have most interested\nphilosophers: \nThese experiments are part of an extensive empirical literature,\nwhere social psychologists have time and again found that\ndisappointing omissions and appalling actions are readily induced by\napparently minor situational\n features.[10]\n The striking fact is not that people fail standards for good conduct,\nbut that they can be so easily induced to do so. \nExploiting this observation, “character skeptics” contend\nthat if moral conduct varies so sharply, often for the worse, with\nminor perturbations in circumstance, ostensibly good character\nprovides very limited assurance of good conduct. In addition to this\nclaim in descriptive psychology, concerning the fragility of\nmoral character, some character skeptics also forward a thesis in\nnormative ethics, to the effect that character merits less\nattention in ethical thought than it traditionally\n gets.[11] \nCharacter skepticism contravenes the influential program of\ncontemporary virtue ethics, which maintains that advancing\nethical theory requires more attention to character, and\nvirtue ethicists offer vigorous\n resistance.[12]\n Discussion has sometimes been overheated, but it has resulted in a\nlarge literature in a vibrantly interdisciplinary field of\n“character studies” (e.g., Miller et al.\n 2015).[13]\n The literature is too extensive for the confines of this entry, but\nwe will endeavor to outline some of the main issues.  \nThe first thing to observe is that the science which inspires the\ncharacter skeptics may itself be subject to skepticism. Given the\nuneven history of the human sciences, it might be argued that the\nrelevant findings are too uncertain to stand as a constraint on\nphilosophical theorizing. This contention is potentially buttressed by\nrecent prominent replication failures in social psychology.  \nThe psychology at issue is, like much of science, unfinished business.\nBut the replication controversy, and the attendant suspicion of\nscience, is insufficient grounds for dismissing the psychology out of\nhand. Philosophical conclusions should not be based on a few studies;\nthe task of the philosophical consumer of science is to identify\ntrends in convergent strands of evidence (Doris\n2015: 49, 56; Machery & Doris forthcoming). The observation that\nmotivates character skepticism—the surprising situational\nsensitivity of behavior—is supported by a wide range of\nscientific findings, as well as by recurring themes in history and\nbiography (Doris 2002, 2005). The strong situational\ndiscriminativeness of behavior is accepted as fact by high proportion\nof involved scientists; accordingly, it is not much contested in\ndebates about character skepticism. \nBut the philosophical implications of this fact remain, after\nconsiderable debate, a contentious issue. The various responses to\ncharacter skepticism need not be forwarded in isolation, and some of\nthem may be combined as part of a multi-pronged defense. Different\nrejoinders have differing strengths and weaknesses, particularly with\nrespect to the differing pieces of evidence on which character\nskeptics rely; the phenomena are not unitary, and accommodating them\nall may preclude a unitary response.  \nOne way of defusing empirically motivated skepticism—dubbed by\nAlfano (2013) “the dodge”—is simply to deny that\nvirtue ethics makes empirical claims. On this understanding, virtue\nethics is cast as a “purely normative” endeavor aiming at\nerecting ethical ideals in complete absence of empirical commitments\nregarding actual human psychologies. This sort of purity is perhaps\nless honored than honored in the breach: historically, virtue ethics\nhas been typified by an interest in how actual people become\ngood. Aristotle (Nicomachean Ethics, 1099b18–19)\nthought that anyone not “maimed” with regard to the\ncapacity for virtue may acquire it “by a certain kind of study\nand care”, and contemporary Aristotelians have emphasized the\nimportance of moral education and development (e.g., Annas 2011). More\ngenerally, virtue-based approaches have been claimed to have an\nadvantage over major Kantian and consequentialist competitors with\nrespect to “psychological realism”—the advantage of\na more lifelike moral psychology (see Anscombe 1958: 1, 15; Williams\n1985; Flanagan 1991: 182; Hursthouse 1999: 19–20).  \nTo be sure, eschewing empirical commitment allows virtue ethics to\nescape empirical threat: obviously, empirical evidence cannot be used\nto undermine a theory that makes no empirical claims.\nHowever, it is not clear such theories could claim advantages\ntraditionally claimed for virtue theories with regard to moral\ndevelopment and psychological realism. In any event, they are not\ncontributions to empirical moral psychology, and needn’t be\nfurther discussed here. \nBefore seeing how the debate in moral psychology might be advanced, it\nis necessary to correct a mischaracterization that serves to arrest\nprogress. It is too often said, particularly in reference to Doris\n(1998, 2002) and Harman (1999, 2000), that character skepticism comes\nto the view that character traits “do not exist” (e.g.,\nFlanagan 2009: 55). Frequently, this attribution is made without\ndocumentation, but when documentation is provided, it is typically in\nreference to some early, characteristically pointed, remarks of Harman\n(e.g., 1999). Yet in his most recent contribution, Harman (2009: 241)\nsays, “I do not think that social psychology demonstrates there\nare no character traits”. For his part, Doris has repeatedly\nasserted that traits exist, and has repeatedly drawn attention to such\nassertions (Doris 1998: 507–509; 2002: 62–6; 2005: 667;\n2010: 138–141; Doris & Stich 2005: 119–20; Doris &\nPrinz 2009).  \nWith good reason, to say “traits do not exist” is\ntantamount to denying that there are individual dispositional\ndifferences, an unlikely view that character skeptics and antiskeptics\nare united in rejecting. Quite unsurprisingly, this unlikely view is\nseriously undersubscribed in both philosophy and psychology. It is\nendorsed by neither the most aggressive critics of personality,\nsituationists in social psychology such as Ross and Nisbett (1991),\nnor by the patron saint of situationism in personality psychology:\nMischel (1999: 45). Mischel disavows a trait-based approach, but his\nskepticism concerns a particular approach to traits, not\nindividual dispositional differences more generally.  \nThen the question of whether or not traits exist is emphatically\nnot the issue dividing more and less skeptical approaches to\ncharacter. Today, all mainstream parties to the debate are\n“interactionist”, treating behavioral outcomes as the\nfunction of a (complex) person by situation interaction (Mehl et al.\n2015)—and it’s likely most participants have always been\nso (Doris 2002: 25–6). Contemporary research programs in\npersonality and social psychology freely deploy both personal\nand situational variables (e.g., Cameron, Payne, & Doris 2013;\nLeikas, Lönnqvist, & Verkasalo 2012; Sherman, Nave, &\nFunder 2010). The issue worth discussing is not whether individual\ndispositional differences exist, but how these differences should\nbe characterized, and how (or whether) these individual\ndifferences, when appropriately characterized, should inform\nethical thought.  \nAn important feature of early forays into character skepticism was\nthat skeptics tended to focus on behavioral implications of\ntraits rather than the psychological antecedents of behavior\n(Doris 2015: 15). Defenders of virtue ethics observe that character\nskeptics have had much to say about situational variation in behavior\nand little to say about the psychological processes underlying it,\nwith the result that they overlook the rational order in\npeople’s lives (Adams 2006: 115–232). These virtue\nethicists maintain that the behavioral variation provoking character\nskepticism evinces not unreliability, but rationally appropriate\nsensitivity to differing situations (Adams 2006; Kamtekar 2004). The\nvirtuous person, such as Aristotle’s exemplary\nphronimos (“man of practical wisdom”) may\nsometimes come clean, and sometimes dissemble, or sometimes fight, and\nsometimes flee, depending on the particular ethical demands of his\ncircumstances. \nFor example, in the Good Samaritan Study, the hurried passersby was on\nthe way to an appointment where they had agreed to give a\npresentation; perhaps these people made a rational\ndetermination—perhaps even an ethically defensible\ndetermination—to weigh the demands of punctuality and\nprofessionalism over ethical requirement to check on the welfare of a\nstranger in apparent distress. However attractive one finds such\naccounting for this case (note that some of Darley and Batson’s\n[1973] hurried passersby failed to notice the victim, which strains\nexplanations in terms of their rational discriminations), there are\nother cases where the “rationality response” seems plainly\nunattractive. These are cases of ethically irrelevant influences\n (Sec. 2 above;\n Doris & Stich 2005), where it seems unlikely the influence could\nbe cited as part of a rationalizing explanation of the behavior:\nit’s odd to cite failing to find a dime as\njustification for failing to help—or for that matter,\nfinding a dime as justification for doing so. \nIt is certainly appropriate for virtue ethicists to emphasize\npractical rationality in their accounts of character. This is a\ncentral theme in the tradition going back to Aristotle himself, who is\nprobably the most oft-cited canonical philosopher in contemporary\nvirtue ethics. But while the rationality response may initially\naccommodate some of the troubling behavioral evidence, it encounters\nfurther empirical difficulty. There is an extensive empirical\nliterature problematizing familiar conceptions of rationality:\npsychologists have endlessly documented a dispiriting range of\nreasoning errors (Baron 1994, 2001; Gilovich et al. 2002; Kahneman et\nal. 1982; Tversky & Kahneman 1973; Kruger & Dunning 1999;\nNisbett & Borgida 1975; Nisbett & Ross 1980; Stich 1990;\nTversky & Kahneman 1981). In light of this evidence, character\nskeptics claim that the vagaries afflicting behavior also afflict\nreasoning (Alfano 2013; Olin & Doris 2014).  \nResearch supporting this discouraging assessment of human rationality\nis controversial, and not all psychologists think things are so bleak\n(Gigerenzer 2000; Gigerenzer et al. 1999; for philosophical commentary\nsee Samuels & Stich 2002). Nevertheless, if virtue ethics is to\nhave an empirically credible moral psychology, it needs to account for\nthe empirical challenges to practical reasoning: how can the relevant\nexcellence in practical reasoning be developed?  \nFaced with the challenge to practical rationality, virtue ethicists\nmay respond that their theories concern excellent reasoning,\nnot the ordinary reasoning studied in psychology. Practical\nwisdom, and the ethical virtue it supports, are expected to be\nrare, and not widely instantiated. This state of affairs, it\nis said, is quite compatible with the disturbing, but not\nexceptionlessly disturbing, behavior in experiments like\nMilgram’s (see Athanassoulis 1999: 217–219; DePaul 1999;\nKupperman 2001: 242–3). If this account is supposed to be part\nof an empirically contentful moral psychology, rather than unverified\nspeculation, we require a detailed and empirically substantiated\naccount of how the virtuous few get that way—remember that an\nemphasis on moral development is central to the virtue ethics\ntradition. Moreover, if virtue ethics is supposed to have widespread\npractical implications—as opposed to being merely a celebration\nof a tiny “virtue elite”—it should have an account\nof how the less-than-virtuous-many may at least tolerably\napproximate virtue.  \nThis point is underscored by the fact that for some of the troubling\nevidence, as in the Stanford Prison Study, the worry is not so much\nthat people fail standards of virtue, but that they fail standards of\nminimal decency. Surely an approach to ethics that celebrates\nmoral development, even one that acknowledges (or rather, insists)\nthat most people will not attain its ideal, might be expected to have\nan account of how people can become minimally decent. \nRecently, proponents of virtue ethics have been increasingly proposing\na suggestive solution to this problem: virtue is a skill acquired\nthrough effortful practice, so virtue is a kind of expertise (Annas\n2011; Bloomfield 2000, 2001, 2014; Jacobson 2005; Russell 2015; Snow\n2010; Sosa 2009; Stichter 2007, 2011; for reservations, see Doris, in\npreparation). The virtuous are expert at morality and—given the\nAristotelian association of virtue and happiness—expert at life.\n \nAn extensive scientific literature indicates that developing expert\nskill requires extensive preparation, whether the practitioner is a\nnovelist, doctor, or chess master—around 10,000 hours of\n“deliberate practice”, according to a popular\ngeneralization (Ericsson 2014; Ericsson et al. 1993). The\n“10,000–hour rule” is likely an oversimplification,\nbut there is no doubt that attaining expertise requires intensive\ntraining. Because of this, people rarely achieve eminence in more than\none area; for instance, “baseball trivia” experts display\nsuperior recall for baseball-related material, but not for\nnon-baseball material (Chiesi et al. 1979). Conversely, becoming\nexpert at morality, or (even more ambitiously) expert at the whole of\nlife, would apparently require a highly generalized form of\nexpertise: to be good, there’s a lot to be good at.\nMoreover, it’s quite unclear what deliberate practice at life\ninvolves; how exactly does one get better at being good?  \nOne obvious problem concerns specifying the “good” in\nquestion. Expertises like chess have been effectively studied in part\nbecause there are accepted standards of excellence (the\n“ELO” score used for ranking chess players; Glickman\n1995). To put it blithely, there aren’t any chess skeptics. But\nthere have, historically, been lots of moral skeptics. And if\nthere’s not moral knowledge, how could there be moral experts?\nAnd even if there are moral experts, there’s the problem of how\nare they to be identified, since it is not clear we are possessed of\nstandard independent of expert opinion itself (like winning chess\nmatches) for doing so (for the “metaethics of expertise”,\nsee McGrath 2008, 2011). \nEven if these notorious philosophical difficulties can be\nresolved—as defenders of expertise approaches to virtue must\nthink they can—matters remain complicated, because if moral\nexpertise is like other expertises, practice alone—assuming we\nhave a clear notion of what “moral practice”\nentails—will be insufficient. While practice matters in\nattaining expertise, other factors, such as talent, also matter\n(Hambrick et al. 2014; Macnamara et al. 2014). And some of the\nrequired endowments may be quite unequally distributed across\npopulations: practice cannot make a jockey into an NFL lineman, or an\nNFL lineman into a jockey.  \nWhat are the natural endowments required for moral expertise, and how\nwidely are they distributed in the population? If they are rare, like\nthe skill of a chess master or the strength of an NFL lineman, virtue\nwill also be rare. Some virtue ethicists believe virtue should be\nwidely attainable, and they will resist this result (Adams 2006:\n119–123, and arguably Aristotle Nicomachean Ethics\n1099b15–20). But even virtue ethicists who embrace the rarity of\nvirtue require an account of what the necessary natural endowments\nare, and if they wish to also have an account of how the less\nwell-endowed may achieve at least minimal decency, they should have\nsomething to say about how moral development will proceed across a\npopulation with widely varying endowments. \nWhat is needed, for the study of moral character research to advance,\nis an account of the biological, psychological, and social factors\nrequisite for successful moral development—on the expertise\nmodel, the conditions conducive to developing “moral\nskill”. This, quite obviously, is a tall order, and the research\nneeded to systematically address these issue is in comparative\ninfancy. Yet the expertise model, in exploiting connections with areas\nin which skill acquisition has been well studied, such as music and\nsport, provides a framework for moving discussion of character beyond\nthe empirically under-informed conjectures and assumptions about\n“habituation” that have been too frequent in previous\nliterature (Doris 2015: 128). \nPeople often behave in ways that benefit others, and they sometimes do\nthis knowing that it will be costly, unpleasant or dangerous. But at\nleast since Plato’s classic discussion in the second Book of the\nRepublic, debate has raged over why people behave in\nthis way. Are their motives altruistic, or is their behavior\nultimately motivated by self-interest? Famously, Hobbes gave this\nanswer: \nNo man giveth but with intention of good to himself, because gift is\nvoluntary; and of all voluntary acts, the object is to every man his\nown good; of which, if men see they shall be frustrated, there will be\nno beginning of benevolence or trust, nor consequently of mutual help.\n(1651 [1981: Ch. 15]) \nViews like Hobbes’ have come to be called\n egoism,[14]\n and this rather depressing conception of human motivation has any\nnumber of eminent philosophical advocates, including Bentham, J.S.\nMill and\n Nietzsche.[15]\n Dissenting voices, though perhaps fewer in number, have been no less\neminent. Butler, Hume, Rousseau and Adam Smith have all argued that,\nsometimes at least, human motivation is genuinely altruistic. \nThough the issue that divides egoistic and altruistic accounts of\nhuman motivation is largely empirical, it is easy to see why\nphilosophers have thought that the competing answers will have\nimportant consequences for moral theory. For example, Kant famously\nargued that a person should act “not from inclination but from\nduty, and by this would his conduct first acquire true moral\nworth” (1785 [1949: Sec. 1, parag. 12]). But egoism maintains\nthat all human motivation is ultimately self-interested, and\nthus people can’t act “from duty” in the\nway that Kant urged. Thus if egoism is true, Kant’s account\nwould entail that no conduct has “true moral worth”.\nAdditionally, if egoism is true, it would appear to impose a strong\nconstraint on how a moral theory can answer the venerable question\n“Why should I be moral?” since, as Hobbes clearly saw, the\nanswer will have to ground the motivation to be moral in the\nagent’s\n self-interest.[16] \nWhile the egoism vs. altruism debate has historically been of great\nphilosophical interest, the issue centrally concerns psychological\nquestions about the nature of human motivation, so it’s not\nsurprise that psychologists have done a great deal of empirical\nresearch aimed at determining which view is correct. Some of the most\ninfluential and philosophically sophisticated empirical work on this\nissue has been done by Daniel Batson and his associates. The\nconclusion Batson draws from this work is that people do\nsometimes behave altruistically, and that the emotion of empathy plays\nan important role in generating altruistic motivation.\n [17]\n Others are not convinced. For a discussion of Batson’s\nexperiments, the conclusion he draws from them, and some reasons for\nskepticism about that conclusion, see sections 5 and 6 of the entry\n“Empirical Approaches to Altruism” in this encyclopedia.\nIn this section, we’ll focus on some of the philosophical\nspadework that is necessary before plunging into the empirical\nliterature. \nA crucial question that needs to be addressed is: What, exactly, is\nthe debate about; what is altruism? Unfortunately, there is\nno uncontroversial answer to this question, since researchers in many\ndisciplines, including philosophy, biology, psychology, sociology,\neconomics, anthropology and primatology, have written about altruism,\nand authors in different disciplines tend to use the term\n“altruism” in quite different ways. Even among\nphilosophers the term has been used with importantly different\nmeanings. There is, however, one account of altruism—actually a\ncluster closely related accounts—that plays a central role both\nin philosophy and in a great deal of psychology, including\nBatson’s work. We’ll call it “the standard\naccount”. That will be our focus in the remainder of this\n section.[18] \nAccording to the standard account, an action is altruistic if it is\nmotivated by an ultimate desire for the well-being of another person.\nThis formulation invites questions about (1) what it is for a behavior\nto be motivated by an ultimate desire, and (2) the\ndistinction between desires that are self-interested and\ndesires that are for the well-being of others. \nAlthough the second question will need careful consideration in any\ncomprehensive treatment, a few rough and ready examples of the\ndistinction will suffice\n here.[19]\n Desires to save someone else’s life, to alleviate someone\nelse’s suffering, or to make someone else happy are paradigm\ncases of desires for the well-being of others, while desires to\nexperience pleasure, get rich, and become famous are typical examples\nof self-interested desires. The self-interested desires to experience\npleasure and to avoid pain have played an especially prominent role in\nthe debate, since one version of egoism, often called\nhedonism, maintains that these are our only ultimate\ndesires. \nThe first question, regarding ultimate desires, requires a fuller\nexposition; it can be usefully explicated with the help of a familiar\naccount of practical\n reasoning.[20]\n On this account, practical reasoning is a causal process via which a\ndesire and a belief give rise to or sustain another desire. For\nexample, a desire to drink an espresso and a belief that the best\nplace to get an espresso is at the espresso bar on Main Street may\ncause a desire to go to the espresso bar on Main Street. This desire\ncan then join forces with another belief to generate a third desire,\nand so on. Sometimes this process will lead to a desire to perform a\nrelatively simple or “basic” action, and that desire, in\nturn, will cause the agent to perform the basic action without the\nintervention of any further desires. Desires produced or sustained by\nthis process of practical reasoning are instrumental\ndesires—the agent has them because she thinks that satisfying\nthem will lead to something else that she desires. But not\nall desires can be instrumental desires. If we are to avoid\ncircularity or an infinite regress there must be some desires that are\nnot produced because the agent thinks that satisfying them\nwill facilitate satisfying some other desire. These desires that are\nnot produced or sustained by practical reasoning are the agent’s\nultimate desires, and the objects of ultimate desires, the\nstates of affairs desired, are desired for their own sake. A behavior\nis motivated by a specific ultimate desire when that desire\nis part of the practical reasoning process that leads to the\nbehavior. \nIf people do sometimes have ultimate desires for the well-being of\nothers, and these desires motivate behavior, then altruism is the\ncorrect view, and egoism is false. However, if all ultimate\ndesires are self-interested, then egoism is the correct view, and\naltruism is false. The effort to establish one or the other of these\noptions has given rise to a vast and enormously sophisticated\nempirical literature. For an overview of that literature, see the\n empirical approaches to altruism entry. \nGiven that moral disagreement—about abortion, say, or capital\npunishment—so often seems intractable, is there any reason to\nthink that moral problems admit objective resolutions? While this\ndifficulty is of ancient coinage, contemporary philosophical\ndiscussion was spurred by Mackie’s (1977: 36–8)\n“argument from relativity” or, as it is called by later\nwriters, the “argument from disagreement” (Brink 1989:\n197; Loeb 1998). Such “radical” differences in moral\njudgment as are frequently observed, Mackie (1977: 36) argued,\n“make it difficult to treat those judgments as apprehensions of\nobjective truths”. \nMackie supposed that his argument undermines moral realism,\nthe view that, as Smith (1994: 9, cf. 13) puts it,  \nmoral questions have correct answers, that the correct answers are\nmade correct by objective moral facts … and … by\nengaging in moral argument, we can discover what these objective moral\nfacts\n are.[21] \nThis notion of objectivity, as Smith recognizes, requires\nconvergence in moral views—the right sort of argument,\nreflection and discussion is expected to result in very substantial\nmoral agreement (Smith 1994:\n 6).[22] \nWhile moral realists have often taken pretty optimistic positions on\nthe extent of actual moral agreement (e.g., Sturgeon 1988: 229; Smith\n1994: 188), there is no denying that there is an abundance of\npersistent moral disagreement; on many moral issues there is a\nstriking failure of convergence even after protracted\nargument. Anti-realists like Mackie have a ready explanation for this\nphenomenon: Moral judgment is not objective in Smith’s sense,\nand moral argument cannot be expected to accomplish what Smith and\nother realists think it\n can.[23]\n Conversely, the realist’s task is to explain away\nfailures of convergence; she must provide an explanation of the\nphenomena consistent with it being the case that moral judgment is\nobjective and moral argument is rationally resolvable. Doris and\nPlakias (2008) call these “defusing explanations”. The\nrealist’s strategy is to insist that the preponderance of actual\nmoral disagreement is due to limitations of disputants or their\ncircumstances, and insist that (very substantial, if not\n unanimous)[24]\n moral agreement would emerge in ideal conditions,\nwhen, for example, disputants are fully rational and fully informed of\nthe relevant non-moral facts. \nIt is immediately evident that the relative merits of these competing\nexplanations cannot be fairly determined without close discussion of\nthe factors implicated in actual moral disagreements. Indeed, as acute\ncommentators with both realist (Sturgeon 1988: 230) and anti-realist\n(Loeb 1998: 284) sympathies have noted, the argument from disagreement\ncannot be evaluated by a priori philosophical means alone;\nwhat’s needed, as Loeb observes, is “a great deal of\nfurther empirical research into the circumstances and beliefs of\nvarious cultures”. This research is required not only to\naccurately assess the extent of actual disagreement, but also to\ndetermine why disagreement persists or dissolves. Only then\ncan realists’ attempts to “explain away” moral\ndisagreement be fairly assessed. \nRichard Brandt, who was a pioneer in the effort to integrate ethical\ntheory and the social sciences, looked primarily to anthropology to\nhelp determine whether moral attitudes can be expected to converge\nunder idealized circumstances. It is of course well known that\nanthropology includes a substantial body of work, such as the classic\nstudies of Westermarck (1906) and Sumner (1908 [1934]), detailing the\nradically divergent moral outlooks found in cultures around the world.\nBut as Brandt (1959: 283–4) recognized, typical ethnographies do\nnot support confident inferences about the convergence of attitudes\nunder ideal conditions, in large measure because they often give\nlimited guidance regarding how much of the moral disagreement can be\ntraced to disagreement about factual matters that are not moral in\nnature, such as those having to do with religious or cosmological\nviews. \nWith this sort of difficulty in mind, Brandt (1954) undertook his own\nanthropological study of Hopi people in the American southwest, and\nfound issues for which there appeared to be serious moral disagreement\nbetween typical Hopi and white American attitudes that could not\nplausibly be attributed to differences in belief about nonmoral\n facts.[25]\n A notable example is the Hopi attitude toward animal suffering, an\nattitude that might be expected to disturb many non-Hopis: \n[Hopi children] sometimes catch birds and make “pets” of\nthem. They may be tied to a string, to be taken out and\n“played” with. This play is rough, and birds seldom\nsurvive long. [According to one informant:] “Sometimes they get\ntired and die. Nobody objects to this”. (Brandt 1954: 213) \nBrandt (1959: 103) made a concerted effort to determine whether this\ndifference in moral outlook could be traced to disagreement about\nnonmoral facts, but he could find no plausible explanation of this\nkind; his Hopi informants didn’t believe that animals lack the\ncapacity to feel pain, for example, nor did they have cosmological\nbeliefs that would explain away the apparent cruelty of the practice,\nsuch as beliefs to the effect that animals are rewarded for martyrdom\nin the afterlife. The best explanation of the divergent moral\njudgments, Brandt (1954: 245, 284) concluded, is a “basic\ndifference of attitude”, since “groups do sometimes make\ndivergent appraisals when they have identical beliefs about the\nobjects”. \nMoody-Adams argues that little of philosophical import can be\nconcluded from Brandt’s—and indeed from\nmuch—ethnographic work. Deploying Gestalt psychology’s\ndoctrine of “situational meaning” (e.g., Dunker 1939),\nMoody-Adams (1997: 34–43) contends that all institutions,\nutterances, and behaviors have meanings that are peculiar to their\ncultural milieu, so that we cannot be certain that participants in\ncross-cultural disagreements are talking about the same\n thing.[26]\n The problem of situational meaning, she thinks, threatens\n“insuperable” methodological difficulty for those\nasserting the existence of intractable intercultural disagreement\n(1997: 36). Advocates of ethnographic projects will likely\nrespond—not unreasonably, we think—that judicious\nobservation and interview, such as that to which Brandt aspired,\ncan motivate confident assessments of evaluative diversity.\nSuppose, however, that Moody-Adams is right, and the methodological\ndifficulties are insurmountable. Now, there’s an equitable\ndistribution of the difficulty: if observation and interview are\nreally as problematic as Moody-Adams suggests, neither the\nrealists’ nor the anti-realists’ take on\ndisagreement can be supported by appeal to empirical evidence. We do\nnot think that such a stalemate obtains, because we think the\nimplicated methodological pessimism excessive. Serious empirical work\ncan, we think, tell us a lot about cultures and the differences\nbetween them. The appropriate way of proceeding is with close\nattention to particular studies, and what they show and fail to\n show.[27] \nAs Brandt (1959: 101–2) acknowledged, the anthropological\nliterature of his day did not always provide as much information on\nthe exact contours and origins of moral attitudes and beliefs as\nphilosophers wondering about the prospects for convergence might like.\nHowever, social psychology and cognitive science have recently\nproduced research which promises to further discussion; during the\nlast 35 years, there has been an explosion of “cultural\npsychology” investigating the cognitive and emotional processes\nof different cultures (Shweder & Bourne 1982; Markus &\nKitayama 1991; Ellsworth 1994; Nisbett & Cohen 1996; Nisbett 1998,\n2003; Kitayama & Markus 1999; Heine 2008; Kitayama & Cohen\n2010; Henrich 2015). Here we will focus on some cultural differences\nfound close to (our) home, differences discovered by Nisbett and his\ncolleagues while investigating regional patterns of violence in the\nAmerican North and South. We argue that these findings support\nBrandt’s pessimistic conclusions regarding the likelihood of\nconvergence in moral judgment. \nThe Nisbett group’s research can be seen as applying the tools\nof cognitive social psychology to the “culture of honor”,\na phenomenon that anthropologists have documented in a variety of\ngroups around the world. Although these groups differ in many\nrespects, they manifest important commonalities: \nA key aspect of the culture of honor is the importance placed on the\ninsult and the necessity to respond to it. An insult implies that the\ntarget is weak enough to be bullied. Since a reputation for strength\nis of the essence in the culture of honor, the individual who insults\nsomeone must be forced to retract; if the instigator refuses, he must\nbe punished—with violence or even death. (Nisbett & Cohen\n1996: 5) \nAccording to Nisbett and Cohen (1996: 5–9), an important factor\nin the genesis of southern honor culture was the presence of a herding\neconomy. Honor cultures are particularly likely to develop where\nresources are liable to theft, and where the state’s coercive\napparatus cannot be relied upon to prevent or punish thievery. These\nconditions often occur in relatively remote areas where herding is a\nmain form of subsistence; the “portability” of herd\nanimals makes them prone to theft. In areas where farming rather than\nherding dominates, cooperation among neighbors is more important,\nstronger government infrastructures are more common, and\nresources—like decidedly unportable farmland—are harder to\nsteal. In such agrarian social economies, cultures of honor tend not\nto develop. The American South was originally settled primarily by\npeoples from remote areas of Britain. Since their homelands were\ngenerally unsuitable for farming, these peoples have historically been\nherders; when they emigrated from Britain to the American South, they\ninitially sought out remote regions suitable for herding, and in such\nregions, the culture of honor flourished. \nIn the contemporary South, police and other government services are\nwidely available and herding has all but disappeared as a way of life,\nbut certain sorts of violence continue to be more common than they are\nin the North. Nisbett and Cohen (1996) maintain that patterns of\nviolence in the South, as well as attitudes toward violence, insults,\nand affronts to honor, are best explained by the hypothesis that a\nculture of honor persists among contemporary white non-Hispanic\nsoutherners. In support of this hypothesis, they offer a compelling\narray of evidence, including: \nTwo experimental studies—one in the field, the other in the\nlaboratory—are especially striking. \nIn the field study (Nisbett & Cohen 1996: 73–5), letters of\ninquiry were sent to hundreds of employers around the United States.\nThe letters purported to be from a hardworking 27-year-old Michigan\nman who had a single blemish on his otherwise solid record. In one\nversion, the “applicant” revealed that he had been\nconvicted for manslaughter. The applicant explained that he had been\nin a fight with a man who confronted him in a bar and told onlookers\nthat “he and my fiancée were sleeping together. He\nlaughed at me to my face and asked me to step outside if I was man\nenough”. According to the letter, the applicant’s nemesis\nwas killed in the ensuing fray. In the other version of the letter,\nthe applicant revealed that he had been convicted of motor vehicle\ntheft, perpetrated at a time when he needed money for his family.\nNisbett and his colleagues assessed 112 letters of response, and found\nthat southern employers were significantly more likely to be\ncooperative and sympathetic in response to the manslaughter letter\nthan were northern employers, while no regional differences were found\nin responses to the theft letter. One southern employer responded to\nthe manslaughter letter as follows: \nAs for your problems of the past, anyone could probably be in the\nsituation you were in. It was just an unfortunate incident that\nshouldn’t be held against you. Your honesty shows that you are\nsincere…. I wish you the best of luck for your future. You have\na positive attitude and a willingness to work. These are qualities\nthat businesses look for in employees. Once you are settled, if you\nare near here, please stop in and see us. (Nisbett & Cohen 1996:\n75) \nNo letters from northern employers were comparably sympathetic. \nIn the laboratory study (Nisbett & Cohen 1996: 45–8)\nsubjects—white males from both northern and southern states\nattending the University of Michigan—were told that saliva\nsamples would be collected to measure blood sugar as they performed\nvarious tasks. After an initial sample was collected, the unsuspecting\nsubject walked down a narrow corridor where an experimental\nconfederate was pretending to work on some filing. The confederate\nbumped the subject and, feigning annoyance, called him an\n“asshole”. A few minutes after the incident, saliva\nsamples were collected and analyzed to determine the level of\ncortisol—a hormone associated with high levels of stress,\nanxiety and arousal, and testosterone—a hormone associated with\naggression and dominance behavior. As Figure 1 indicates, southern\nsubjects showed dramatic increases in cortisol and testosterone\nlevels, while northerners exhibited much smaller changes. \nFigure 1 \nThe two studies just described suggest that southerners respond more\nstrongly to insult than northerners, and take a more sympathetic view\nof others who do so, manifesting just the sort of attitudes that are\nsupposed to typify honor cultures. We think that the data assembled by\nNisbett and his colleagues make a persuasive case that a culture of\nhonor persists in the American South. Apparently, this culture affects\npeople’s judgments, attitudes, emotion, behavior, and even their\nphysiological responses. Additionally, there is evidence that child\nrearing practices play a significant role in passing the culture of\nhonor on from one generation to the next, and also that relatively\npermissive laws regarding gun ownership, self-defense, and corporal\npunishment in the schools both reflect and reinforce southern honor\nculture (Nisbett & Cohen 1996: 60–63, 67–9). In short,\nit seems to us that the culture of honor is deeply entrenched in\ncontemporary southern culture, despite the fact that many of the\nmaterial and economic conditions giving rise to it no longer widely\n obtain.[28] \nWe believe that the North/South cultural differences adduced by\nNisbett and colleagues support Brandt’s conclusion that moral\nattitudes will often fail to converge, even under ideal conditions.\nThe data should be especially troubling for the realist, for despite\nthe differences that we have been recounting, contemporary northern\nand southern Americans might be expected to have rather more in\ncommon—from circumstance to language to belief to\nideology—than do, say, Yanomamö and Parisians. So if there\nis little ground for expecting convergence in the case at hand, there\nis probably little ground in a good many others. \nFraser and Hauser (2010) are not convinced by our interpretation of\nNisbett and Cohen’s data. They maintain that while those data do\nindicate that northerners and southerners differ in the strength of\ntheir disapproval of insult-provoked violence, they do not show that\nnortherners and southerners have a real moral disagreement. They go on\nto argue that the work of Abarbanell and Hauser (2010) provides a much\nmore persuasive example of a systematic moral disagreement between\npeople in different cultural groups. Abarbanell and Hauser focused on\nthe moral judgments of rural Mayan people in the Mexican state of\nChiapas. They found that people in that community do not judge\nactions causing harms to be worse than omissions\n(failures to act) which cause identical harms, while nearby urban\nMayan people and Western internet users judge actions to be\nsubstantially worse than omissions.  \nThough we are not convinced by Fraser and Hauser’s\ninterpretation of the Nisbett and Cohen data, we agree that the\nAbarbanell and Hauser study provides a compelling example of a\nsystematic cultural difference in moral judgement. Barrett et al.\n(2016) provides another example. That study looked at the extent to\nwhich an agent’s intention affected the moral judgments of\npeople in eight traditional small-scale societies and two Western\nsocieties, one urban, one rural. They found that in some of these\nsocieties, notably including both Western groups, the agent’s\nintention had a major effect, while in other societies agent intention\nhad little or no effect.  \nAs we said at the outset, realists defending conjectures about\nconvergence may attempt to explain away evaluative diversity\nby arguing that the diversity is to be attributed to shortcomings of\ndiscussants or their circumstances. If this strategy can be made good,\nmoral realism may survive an empirically informed argument from\ndisagreement: so much the worse for the instance of moral reflection\nand discussion in question, not so much the worse for the objectivity\nof morality. While we cannot here canvass all the varieties of this\nsuggestion, we will briefly remark on some of the more common forms.\nFor concreteness, we will focus on Nisbett and Cohen’s\nstudy. \nImpartiality. One strategy favored by moral realists\nconcerned to explain away moral disagreement is to say that such\ndisagreement stems from the distorting effects of individual interest\n(see Sturgeon 1988: 229–230; Enoch 2009: 24–29); perhaps\npersistent disagreement doesn’t so much betray deep features of\nmoral argument and judgment as it does the doggedness with which\nindividuals pursue their perceived advantage. For instance, seemingly\nmoral disputes over the distribution of wealth may be due to\nperceptions—perhaps mostly inchoate—of individual and\nclass interests rather than to principled disagreement about justice;\npersisting moral disagreement in such circumstances fails the\nimpartiality condition, and is therefore untroubling to the moral\nrealist. But it is rather implausible to suggest that North/South\ndisagreements as to when violence is justified will fail the\nimpartiality condition. There is no reason to think that southerners\nwould be unwilling to universalize their judgments across relevantly\nsimilar individuals in relevantly similar circumstances, as indeed\nNisbett and Cohen’s “letter study” suggests. One can\nadvocate a violent honor code without going in for special\n pleading.[29]\n We do not intend to denigrate southern values; our point is that\nwhile there may be good reasons for criticizing the honor-bound\nsoutherner, it is not obvious that the reason can be failure of\nimpartiality, if impartiality is (roughly) to be understood along the\nlines of a willingness to universalize one’s moral\njudgments. \nFull and vivid awareness of relevant nonmoral facts. Moral\nrealists have argued that moral disagreements very often derive from\ndisagreement about nonmoral issues. According to Boyd (1988: 213; cf.\nBrink 1989: 202–3; Sturgeon 1988: 229),  \ncareful philosophical examination will reveal … that agreement\non nonmoral issues would eliminate almost all disagreement\nabout the sorts of moral issues which arise in ordinary moral\npractice.  \nIs this a plausible conjecture for the data we have just considered?\nWe find it hard to imagine what agreement on nonmoral facts could do\nthe trick, for we can readily imagine that northerners and southerners\nmight be in full agreement on the relevant nonmoral facts in the cases\ndescribed. Members of both groups would presumably agree that the job\napplicant was cuckolded, for example, or that calling someone an\n“asshole” is an insult. We think it much more plausible to\nsuppose that the disagreement resides in differing and deeply\nentrenched evaluative attitudes regarding appropriate responses to\ncuckolding, challenge, and insult. \nSavvy philosophical readers will be quick to observe that terms like\n“challenge” and “insult” look like\n“thick” ethical terms, where the evaluative and\ndescriptive are commingled (see Williams 1985: 128–30);\ntherefore, it is very difficult to say what the extent of the factual\ndisagreement is. But this is of little help for the expedient under\nconsideration, since the disagreement-in-nonmoral-fact response\napparently requires that one can disentangle factual\nand moral disagreement. \nIt is of course possible that full and vivid awareness of the nonmoral\nfacts might motivate the sort of change in southern attitudes\nenvisaged by the (at least the northern) moral realist. Were\nsoutherners to become vividly aware that their culture of honor was\nimplicated in violence, they might be moved to change their moral\noutlook. (We take this way of putting the example to be the most\nnatural one, but nothing philosophical turns on it. If you like,\nsubstitute the possibility of northerners endorsing honor values after\nexposure to the facts.) On the other hand, southerners might insist\nthat the values of honor should be nurtured even at the cost of\npromoting violence; the motto “death before dishonor”,\nafter all, has a long and honorable history. The burden of argument,\nwe think, lies with the realist who asserts—culture and\nhistory notwithstanding—that southerners would change their\nmind if vividly aware of the pertinent facts. \nFreedom from “Abnormality”. Realists may contend\nthat much moral disagreement may result from failures of rationality\non the part of discussants (Brink 1989: 199–200). Obviously,\ndisagreement stemming from cognitive impairments is no embarrassment\nfor moral realism; at the limit, that a disagreement persists when\nsome or all disputing parties are quite insane shows nothing deep\nabout morality. But it doesn’t seem plausible that\nsoutherners’ more lenient attitudes towards certain forms of\nviolence are readily attributed to widespread cognitive disability. Of\ncourse, this is an empirical issue, but we don’t know of any\nevidence suggesting that southerners suffer some cognitive impairment\nthat prevents them from understanding demographic and attitudinal\nfactors in the genesis of violence, or any other matter of fact. What\nis needed to press home a charge of irrationality is evidence of\ncognitive impairment independent of the attitudinal\ndifferences, and further evidence that this impairment is implicated\nin adherence to the disputed values. In this instance, as in many\nothers, we have difficulty seeing how charges of abnormality or\nirrationality can be made without one side begging the question\nagainst the other. \nNisbett and colleagues’ work may represent a potent\ncounterexample to any theory maintaining that rational argument tends\nto convergence on important moral issues; the evidence suggests that\nthe North/South differences in attitudes towards violence and honor\nmight well persist even under the sort of ideal conditions under\nconsideration. Admittedly, such conclusions must be tentative. On the\nphilosophical side, not every plausible strategy for “explaining\naway” moral disagreement and grounding expectations of\nconvergence has been\n considered.[30]\n On the empirical side, this entry has reported on but a few studies, and\nthose considered, like any empirical work, might be\ncriticized on either conceptual or methodological\n grounds.[31]\n Finally, it should be clear what this entry is not claiming:\nany conclusions here—even if fairly earned—are not a\n“refutation” of all versions of moral realism, since there\nare versions of moral realism that do not require convergence\n(Bloomfield 2001; Shafer-Landau 2003). \nRather, this discussion should give an idea of the empirical work\nphilosophers must encounter, if they are to make defensible\nconjectures regarding moral disagreement. \nProgress in ethical theorizing often requires progress on difficult\npsychological questions about how human beings can be expected to\nfunction in moral contexts. It is no surprise, then, that moral\npsychology is a central area of inquiry in philosophical ethics. It\nshould also come as no surprise that empirical research, such as that\nconducted in psychology departments, may substantially abet such\ninquiry. Nor then, should it surprise that research in moral\npsychology has become methodologically pluralistic,\nexploiting the resources of, and endeavoring to contribute to, various\ndisciplines. Here, we have illustrated how such interdisciplinary\ninquiry may proceed with regard to central problems in philosophical\nethics.","contact.mail":"jmd378@cornell.edu","contact.domain":"cornell.edu"},{"date.published":"2006-04-19","date.changed":"2020-01-06","url":"https://plato.stanford.edu/entries/moral-psych-emp/","author1":"John Doris","author2":"Lachlan Walmsley","author1.info":"https://philosophy.cornell.edu/john-m-doris","author2.info":"https://philosophy.rutgers.edu/people/faculty/details/182-faculty1/faculty-profiles/635-stich-stephen","entry":"moral-psych-emp","body.text":"\n\n\nMoral psychology investigates human functioning in moral contexts, and\nasks how these results may impact debate in ethical theory. This work\nis necessarily interdisciplinary, drawing on both the empirical\nresources of the human sciences and the conceptual resources of\nphilosophical ethics. The present article discusses several topics\nthat illustrate this type of inquiry: thought experiments,\nresponsibility, character, egoism v. altruism, and moral\ndisagreement.\n\nContemporary moral psychology—the study of human thought and\nbehavior in ethical contexts—is resolutely interdisciplinary:\npsychologists freely draw on philosophical theories to help structure\ntheir empirical research, while philosophers freely draw on empirical\nfindings from psychology to help structure their\n theories.[1] \nWhile this extensive interdisciplinarity is a fairly recent\ndevelopment (with few exceptions, most of the relevant work dates from\nthe past quarter century), it should not be a surprising development.\nFrom antiquity to the present, philosophers have not been bashful\nabout making empirical claims, and many of these empirical claims have\nbeen claims about human psychology (Doris & Stich 2005). It is\ntherefore unremarkable that, with the emergence of scientific\npsychology over the past century and a half, some of these\nphilosophers would think to check their work against the systematic\nfindings of psychologists (hopefully, while taking special care to\navoid being misled by scientific controversy; see Doris 2015, Chapter\n3; Machery & Doris forthcoming).  \nSimilarly, at least since the demise of behaviorism, psychologists\nhave been keenly interested in normative phenomena in general and\nethical phenomena in particular. It is therefore unremarkable that\nsome of these psychologists would seek to enrich their theoretical\nframeworks with the conceptual resources of a field intensively\nfocused on normative phenomena: philosophical ethics. As a result, the\nfield demarcated by “moral psychology”, routinely involves\nan admixture of empirical and normative inquiry, pursued by both\nphilosophers and psychologists—increasingly, in the form of\ncollaborative efforts involving practitioners from both fields.  \nFor philosophers, the special interest of this interdisciplinary\ninquiry lies in the ways moral psychology may help adjudicate between\ncompeting ethical theories. The plausibility of its associated moral\npsychology is not, of course, the only dimension on which an ethical\ntheory may be evaluated; equally important are normative\nquestions having to do with how well a theory fares when compared to\nimportant convictions about such things as justice, fairness, and the\ngood life. Such questions have been, and will continue to be, of\ncentral importance for philosophical ethics. Nonetheless, it is\ncommonly supposed that an ethical theory committed to an impoverished\nor inaccurate conception of moral psychology is at a serious\ncompetitive disadvantage. As Bernard Williams (1973, 1985; cf.\nFlanagan 1991) forcefully argued, an ethical conception that commends\nrelationships, commitments, or life projects that are at odds with the\nsorts of attachments that can be reasonably expected to take root in\nand vivify actual human lives is an ethical conception with—at\nbest—a very tenuous claim to our assent. \nWith this in mind, problems in ethical theory choice making reference\nto moral psychology can be framed by two related inquiries: \nThe first question is one of philosophical scholarship: what are the\npsychological commitments of various positions in philosophical\nethics? The second question takes us beyond the corridors of\nphilosophy departments and to the sorts of questions asked, and\nsometimes answered, by the human sciences, including psychology,\nanthropology, sociology, history, cognitive science, linguistics and\nneuroscience. Thus, contemporary moral psychology is\nmethodologically pluralistic: it aims to answer philosophical\nquestions, but in an empirically responsible way. \nHowever, it will sometimes be difficult to tell which claims in\nphilosophical ethics require empirical substantiation. Partly, this is\nbecause it is sometimes unclear whether, and to what extent, a\ncontention counts as empirically assessable. Consider questions\nregarding “normal functioning” in mental health care: are\nthe answers to these questions statistical, or evaluative (Boorse\n1975; Fulford 1989; Murphy 2006)? For example, is “normal”\nmental health simply the psychological condition of most people, or is\nit good mental health? If the former, the issue is, at least\nin principle, empirically decidable. If the latter, the issues must be\ndecided, if they can be decided, by arguments about value. \nAdditionally, philosophers have not always been explicit about\nwhether, and to what extent, they are making empirical claims. For\nexample, are their depictions of moral character meant to identify\npsychological features of actual persons, or to articulate ideals that\nneed not be instantiated in actual human psychologies? Such questions\nwill of course be complicated by the inevitable diversity of\nphilosophical opinion. \nIn every instance, therefore, the first task is to carefully document\na theory’s empirically assessable claims, whether they are\nexplicit or, as may often be the case, tacit. Once claims apt for\nempirical assessment have been located, the question becomes one of\nidentifying any relevant empirical literatures. The next job is to\nassess those literatures, in an attempt to determine what conclusions\ncan be responsibly drawn from them. Science, particularly social\nscience, being what it is, many conclusions will be provisional; the\nphilosophical moral psychologist must be prepared to adjudicate\ncontroversies in other fields, or offer informed conjecture regarding\nfuture findings. Often, the empirical record will be crucially\nincomplete. In such cases, philosophers may be forced to engage in\nempirically disciplined conjecture, or even to engage in their own\nempirical work, as some philosophers are beginning to\n do.[2] \nWhen the philosophical positions have been isolated, and putatively\nrelevant empirical literatures assessed, we can begin to evaluate the\nplausibility of the philosophical moral psychology: Is the speculative\npicture of psychological functioning that informs some region of\nethical theory compatible with the empirical picture that emerges from\nsystematic observation? In short, is the philosophical picture\nempirically adequate? If it is determined that the\nphilosophical conception is empirically adequate, the result is\nvindicatory. Conversely, if the philosophical moral\npsychology in question is found to be empirically inadequate,\nthe result is revisionary, compelling alteration, or even\nrejection, of those elements of the philosophical theory presupposing\nthe problematic moral psychology. The process will often be\ncomparative. Theory choice in moral psychology, like other\ntheory choice, involves tradeoffs, and while an empirically\nundersupported approach may not be decisively eliminated from\ncontention on empirical grounds alone, it may come to be seen as less\nattractive than theoretical options with firmer empirical\nfoundations. \nThe winds driving the sort of disciplinary cross-pollination we\ndescribe do not blow in one direction. As philosophers writing for an\nencyclopedia of philosophy, we are naturally concerned with the ways\nempirical research might shape, or re-shape, philosophical ethics. But\nphilosophical reflection may likewise influence empirical research,\nsince such research is often driven by philosophical suppositions that\nmay be more or less philosophically sound. The best interdisciplinary\nconversations, then, should benefit both parties. To illustrate the\ndialectical process we have described, we will consider a variety of\ntopics in moral psychology. Our primary concerns will be\nphilosophical: What are some of the most central problems in\nphilosophical moral psychology, and how might they be resolved?\nHowever, as the hybrid nature of our topic invites us to do, we will\npursue these questions in an interdisciplinary spirit, and are hopeful\nthat our remarks will also engage interested scientists. Hopefully,\nthe result will be a broad sense of the problems and methods that will\nstructure research on moral psychology during the 21st\ncentury. \n“Intuition pumps” or “thought experiments”\nhave long been well-used items in the philosopher’s toolbox\n(Dennett 1984: 17–18; Stuart et al. 2018). Typically, a thought\nexperiment presents an example, often a hypothetical example, in order\nto elicit some philosophically telling response. If a thought\nexperiment is successful, it may be concluded that competing theories\nmust account for the resulting response. These responses are supposed\nto serve an evidential role in philosophical theory choice;\nif you like, they can be understood as data competing\ntheories must\n accommodate.[3]\n If an appropriate audience’s ethical responses to a thought\nexperiment conflict with the response a theory prescribes for the\ncase, the theory has suffered a counterexample. \nThe question of whose responses “count” philosophically\n(or, who is the “appropriate” audience) has been answered\nin a variety of ways, but for many philosophers, the intended audience\nfor thought experiments seems to be some species of “ordinary\nfolk” (see Jackson 1998: 118, 129; Jackson & Pettit 1995:\n22–9; Lewis 1989: 126–9). Of course, the relevant folk\nmust possess such cognitive attainments as are required to understand\nthe case at issue; very young children are probably not an ideal\naudience for thought experiments. Accordingly, some philosophers may\ninsist that the relevant responses are the considered judgments of\npeople with the training required to see “what is at stake\nphilosophically”. But if the responses are to help adjudicate\nbetween competing theories, the responders must be more or less\ntheoretically neutral, and this sort of neutrality is\nrather likely to be vitiated by philosophical education. A dilemma\nemerges. On the one hand, philosophically naïve subjects may be\nthought to lack the erudition required to grasp the philosophical\nstakes. On the other, with increasing philosophical sophistication\ncomes, very likely, philosophical partiality; one audience is\nnaïve, and the other\n prejudiced.[4] \nHowever exactly the philosophically relevant audience is specified,\nthere are empirical questions that must be addressed in determining\nthe philosophical potency of a thought experiment. In particular, when\ndeciding what philosophical weight to give a response, philosophers\nneed to determine its origins. What features of the\nexample are implicated in a given judgment—are people\nreacting to the substance of the case, or the style of exposition?\nWhat features of the audience are implicated in their\nreaction—do different demographic groups respond to the example\ndifferently? Are there factors in the environment that are affecting\npeople’s intuitive judgments? Does the order in which people\nconsider examples affect their judgments? Such questions raise the\nfollowing concern: judgments about thought experiments dealing with\nmoral issues might be strongly influenced by ethically\nirrelevant characteristics of the example or the audience or the\nenvironment or the order of presentation. Whether a characteristic is\nethically relevant is a matter for philosophical discussion, but\ndetermining the status of a particular thought experiment also\nrequires empirical investigation of its causally relevant\ncharacteristics. We’ll now describe some examples of such\ninvestigation. \nAs part of their famous research on the “heuristics and\nbiases” that underlie human reasoning, Tversky and Kahneman\n(1981) presented subjects with the following problem: \nImagine that the U.S. is preparing for the outbreak of an unusual\nAsian disease, which is expected to kill 600 people. Two alternative\nprograms to combat the disease have been proposed. Assume that the\nexact scientific estimate of the consequences of the programs are as\nfollows: \nA second group of subjects was given an identical problem, except that\nthe programs were described as follows: \nOn the first version of the problem, most subjects thought that\nProgram A should be adopted. But on the second version, most chose\nProgram D, despite the fact that the outcome described in A is\nidentical to the one described in C. The disconcerting implication of\nthis study is that ethical responses may be strongly influenced by the\nmanner in which cases are described or framed. It seems that\nsuch framing sensitivities constitute ethically irrelevant influences\non ethical responses. Unless this sort of possibility can be\nconfidently eliminated, one should hesitate to rely on responses to a\nthought experiment for adjudicating theoretical controversies. Such\npossibilities can only be eliminated through systematic empirical\n work.[5] \nWhile a relatively small percentage of empirical work on\n“heuristics and biases” directly addresses moral\nreasoning, numerous philosophers who have addressed the issue\n(Horowitz 1998; Doris & Stich 2005; Sinnott-Armstrong 2005;\nSunstein 2005) agree that phenomena like framing effects are likely to\nbe pervasively implicated in responses to ethically freighted\nexamples, and argue that this state of affairs should cause\nphilosophers to view the thought-experimental method with considerable\nconcern. \nWe turn now to order effects. In a pioneering study, Petrinovich and\nO’Neill (1996) found that participants’ moral intuitions\nvaried with the order in which the thought experiments were presented.\nSimilar findings have been reported by Liao et al. (2012), Wiegman et\nal. (2012), and Schwitzgebel & Cushman (2011, 2015). The\nSchwitzgebel and Cushman studies are particularly striking, since they\nset out to explore whether order effects in moral intuitions were\nsmaller or non-existent in professional philosophers. Surprisingly,\nthey found that professional philosophers were also subject to order\neffects, even though the thought experiments used are well known in\nthe field. Schwitzgebel and Cushman also report that in some cases\nphilosophers intuitions show substantial order effects when the\nintuitions of non-philosophers don’t. \nAudience characteristics may also affect the outcome of thought\nexperiments. Haidt and associates (1993: 613) presented stories about\n“harmless yet offensive violations of strong social norms”\nto men and women of high and low socioeconomic status (SES) in\nPhiladelphia (USA), Porto Alegre, and Recife (both in Brazil). For\nexample: \nA man goes to the supermarket once a week and buys a dead chicken. But\nbefore cooking the chicken, he has sexual intercourse with it. Then he\ncooks it and eats it. (Haidt et al. 1993: 617) \nLower SES subjects tended to “moralize” harmless and\noffensive behaviors like that in the chicken story. These subjects\nwere more inclined than their high SES counterparts to say that the\nactor should be “stopped or punished”, and more inclined\nto deny that such behaviors would be “OK” if customary in\na given country (Haidt et al. 1993: 618–19). The point is not\nthat lower SES subjects are mistaken in their moralization of such\nbehaviors while the urbanity of higher SES subjects represents a more\nrationally defensible response. The difficulty is deciding\nwhich—if any—of the conflicting responses is fit to serve\nas a constraint on ethical theory, when both may equally be the result\nof more or less arbitrary cultural factors. \nPhilosophical audiences typically decline to\nmoralize the offensive behaviors, and we ourselves share their\ntolerant attitude. But of course these audiences—by virtue of\neducational attainments, if not stock portfolios—are\noverwhelmingly high SES. Haidt’s work suggests that it is a\nmistake for a philosopher to say, as Jackson (1998: 32n4; cf. 37)\ndoes, that “my intuitions reveal the folk conception in as much\nas I am reasonably entitled, as I usually am, to regard myself as\ntypical”. The question is: typical of what demographic? Are\nphilosophers’ ethical responses determined by the philosophical\nsubstance of the examples, or by cultural idiosyncrasies that are very\nplausibly thought to be ethically irrelevant? Once again, until such\npossibilities are ruled out by systematic empirical investigation, the\nphilosophical heft of a thought experiment is open to question. \nIn recent years there has been a growing body of research reporting\nthat judgments evoked by moral thought experiments are affected by\nenvironmental factors that look to be completely irrelevant to the\nmoral issue at hand. The presence of dirty pizza boxes and a whiff of\nfart spray (Schnall et al. 2008a), the use of soap (Schnall et al.\n2008b) or an antiseptic handwipe (Zhong et al. 2010), or even the\nproximity of a hand sanitizer dispenser (Helzer & Pizarro 2011)\nhave all been reported to influence moral intuitions. Tobia et al.\n(2013) found that the moral intuitions of both students and\nprofessional philosophers are affected by spraying the questionnaire\nwith a disinfectant spray. Valdesolo and DeSteno (2006) reported that\nviewing a humorous video clip can have a substantial impact on\nparticipant’s moral intuitions. And Strohminger et al. (2011)\nhave shown that hearing different kinds of audio clips (stand-up\ncomedy or inspirational stories from a volume called Chicken Soup\nfor the Soul) has divergent effects on moral intuitions. \nHow should moral theorists react to findings like these? One might, of\ncourse, eschew thought experiments in ethical theorizing. While this\nmethodological austerity is not without appeal, it comes at a cost.\nDespite the difficulties, thought experiments are a window, in some\ncases the only accessible window, into important regions of ethical\nexperience. In so far as it is disconnected from the thoughts and\nfeels of the lived ethical life, ethical theory risks being\n“motivationally inaccessible”, or incapable of engaging\nthe ethical concern of agents who are supposed to live in accordance\nwith the normative standards of the\n theory.[6]\n Fortunately, there is another possibility: continue pursuing the\nresearch program that systematically investigates responses to\nintuition pumps. In effect, the idea is to subject philosophical\nthought experiments to the critical methods of experimental social\npsychology. If investigations employing different experimental\nscenarios and subject populations reveal a clear trend in responses,\nwe can begin to have some confidence that we are identifying a deeply\nand widely shared moral conviction. Philosophical discussion may\nestablish that convictions of this sort should serve as a constraint\non moral theory, while responses to thought experiments that empirical\nresearch determines to lack such solidity, such as those susceptible\nto order, framing or environmental effects, or those admitting of\nstrong cultural variation, may be ones that ethical theorists can\nsafely disregard.  \nA philosophically informed empirical research program akin to the one\njust described is more than a methodological fantasy. This approach\naccurately describes a number of research programs aimed at informing\nphilosophical debates through interdisciplinary research. \nOne of the earliest examples of this kind of work was inspired in\nlarge part by the work of Knobe (2003a,b, 2006) and addressed\nquestions surrounding “folk morality” on issues ranging\nfrom intentional action to causal responsibility (see Knobe 2010 for\nreview and discussion). This early work helped to spur the development\nof a truly interdisciplinary research program with both philosophers\nand psychologists investigating the folk morality of everyday life.\n(See the Stanford Encyclopedia of Philosophy article on\nExperimental Moral Philosophy for a more complete treatment of this\nresearch.) \nAnother related philosophical debate concerns the compatibility of\nfree will and moral responsibility with determinism. On the one hand,\nincompatibilists insist that determinism (the view that all events are\njointly determined by antecedent events as governed by laws of\nnature), is incompatible with moral responsibility.\nTypically, these accounts also go on to specify what particular\ncapacity is required to be responsible for one’s own behavior\n(e.g., that agents have alternate possibilities for behavior, or are\nthe “ultimate” source of their behavior, or both (Kane\n2002: 5; Haji 2002:\n 202–3).[7]\n On the other hand, compatibilists argue that determinism and\nresponsibility are compatible, often by denying that\nresponsible agency requires that the actor have genuinely open\nalternatives, or rejecting the ultimacy condition that requires\nindeterminism (or impossible demands for self-creation). In short,\ncompatibilists hold that people may legitimately be held responsible\neven though there is some sense in which they “could not have\ndone otherwise” or are not the “ultimate source” of\ntheir behavior. Incompatibilists deny that this is the case.\nProponents of these two opposing positions have remained relatively\nentrenched, and some participants have raised fears of a\n“dialectical stalemate” (Fischer 1994: 83–5). \nA critical issue in these debates has been the claim that the\nincompatibilist position better captures folk moral judgments about\nagents whose actions have been completely determined (e.g., G.\nStrawson 1986: 88; Smilansky 2003: 259; Pereboom 2001: xvi;\nO’Connor 2000: 4; Nagel 1986: 113, 125; Campbell 1951: 451; Pink\n2004: 12). For example, Robert Kane (1999: 218; cf. 1996: 83–5),\na leading incompatibilist, reports that in his experience “most\nordinary persons start out as natural incompatibilists”, and\n“have to be talked out of this natural incompatibilism by the\nclever arguments of philosophers”. \nUnsurprisingly, some compatibilists have been quick to assert the\ncontrary. For example, Peter Strawson (1982) famously argued that in\nthe context of “ordinary interpersonal relationships”,\npeople are not haunted by the specter of determinism; such\nmetaphysical concerns are irrelevant to their experience and\nexpression of the “reactive attitudes”—anger,\nresentment, gratitude, forgiveness, and the like—associated with\nresponsibility assessment. Any anxiety about determinism, Strawson\ninsisted, is due to the “panicky metaphysics” of\nphilosophers, not incompatibilist convictions on the part of ordinary\npeople. However, incompatibilists have historically been thought to\nhave ordinary intuitions on their side; even some philosophers with\ncompatibilist leanings are prepared to concede the incompatibilist\npoint about “typical” response tendencies (e.g., Vargas\n2005a,b). \nNeither side, so far as we are aware, has offered much in the way of\nsystematic evidence of actual patterns of folk moral judgments.\nRecently however, a now substantial research program has begun to\noffer empirical evidence on the relationship between determinism and\nmoral responsibility in folk moral judgments. \nInspired by the work of Frankfurt (1988) and others, Woolfolk, Doris,\nand Darley (2006) hypothesized that observers may hold actors\nresponsible even when the observers judge that the actors could not\nhave done otherwise, if the actors appear to “identify”\nwith their behavior. Roughly, the idea is that the actor identifies\nwith a behavior—and is therefore responsible for it—to the\nextent that she “embraces” the behavior, or performs it\n“wholeheartedly” regardless of whether genuine\nalternatives for behavior are\n possible.[8]\n Woolfolk et al.’s suspicion was, in effect, that people’s\n(presumably tacit) theory of responsibility is compatibilist. \nTo test this, subjects were asked to read a story about an agent who\nwas forced by a group of armed hijackers to kill a man who had been\nhaving an affair with his wife. In the “low\nidentification” condition, the man was described as being\nhorrified at being forced to kill his wife’s lover, and as not\nwanting to do so. In the “high identification” condition,\nthe man is instead described as welcoming the opportunity and wanting\nto kill his wife’s lover. In both cases, the man is not given a\nchoice, and does kill his wife’s lover. \nConsistent with Woolfolk and colleagues’ hypothesis, subjects\njudged that the highly identifying actor was more responsible, more\nappropriately blamed, and more properly subject to guilt than the low\nidentification\n actor.[9]\n This pattern in folk moral judgments seems to suggest that\nparticipants were not consistently incompatibilist in their\nresponsibility attributions, because the lack of alternatives\navailable to the actor was not alone sufficient to rule out such\nattributions. \nIn response to these results, those who believe that folk morality is\nincompatibilist may be quick to object that the study merely suggests\nthat responsibility attributions are influenced by identification, but\nsays nothing about incompatibilist commitments or the lack thereof.\nSubjects still may have believed that the actor could have done\notherwise. To address this concern, Woolfolk and colleagues also\nconducted a version of the study in which the man acted under the\ninfluence of a “compliance drug”. In this case,\nparticipants were markedly less likely to agree that the man\n“was free to behave other than he did” and yet they still\nheld the agent who identified with the action as more responsible than\nthe agent who did not. These results look to pose a clear challenge to\nthe view that ordinary folk are typically incompatibilists. \nA related pattern of responses was obtained by Nahmias, Morris,\nNadelhoffer and Turner (2009) who instead described agents preforming\nimmoral behaviors in a “deterministic world” of the sort\noften described in philosophy classrooms. One variation read as\nfollows: \nImagine that in the next century we discover all the laws of nature,\nand we build a supercomputer which can deduce from these laws of\nnature and from the current state of everything in the world exactly\nwhat will be happening in the world at any future time. It can look at\neverything about the way the world is and predict everything about how\nit will be with 100% accuracy. Suppose that such a supercomputer\nexisted, and it looks at the state of the universe at a certain time\non March 25th, 2150 C.E., twenty years before Jeremy Hall is born. The\ncomputer then deduces from this information and the laws of nature\nthat Jeremy will definitely rob Fidelity Bank at 6:00 PM on January\n26th, 2195. As always, the supercomputer’s prediction is\ncorrect; Jeremy robs Fidelity Bank at 6:00 PM on January 26th,\n2195. \nSubjects were then asked whether Jeremy was morally blameworthy. Most\nsaid yes, indicating that they thought an agent could be morally\nblameworthy even if his behaviors were entirely determined by natural\nlaws. Consistent with the Woolfolk et al. results, it appears that the\nsubjects’ judgments, at least those having to do with moral\nblameworthiness, were not governed by a commitment to\nincompatibilism. \nThis emerging picture was complicated, however, by Nichols and Knobe\n(2007), which argued that the ostensibly compatibilist responses were\nperformance errors driven by an affective response to the\nagents’ immoral actions. To demonstrate this, all subjects were\nasked to imagine two universes—a universe completely governed by\ndeterministic laws (Universe A) and a universe (Universe B) in which\neverything is determined except for human decisions which are not\ncompletely determined by deterministic laws and what has happened in\nthe past. In Universe B, but not Universe A, “each human\ndecision does not have to happen the way it does”. Some\nsubjects were assigned to a concrete condition, and asked to make a\njudgment about a specific individual in specific circumstances, while\nothers were assigned to an abstract condition, and asked to make a\nmore general judgment, divorced from any particular individual. The\nhypothesis was that the difference between these two conditions would\ngenerate different responses regarding the relationship between\ndeterminism and moral responsibility. Subjects in the concrete\ncondition read a story about a man, “Bill”, in the\ndeterministic universe who murders his wife and children in a\nparticularly ghastly manner, and were asked whether Bill was morally\nresponsible for what he had done. By contrast, subjects in the\nabstract condition were asked “In Universe A, is it possible for\na person to be fully morally responsible for their actions?”\nSeventy-two percent of subjects in the concrete condition gave a\ncompatibilist response, holding Bill responsible in Universe A,\nwhereas less than fifteen percent of subjects in the abstract\ncondition gave a compatibilist response, allowing that people could be\nfully morally responsible in the deterministic Universe A. \nIn line with previous experimental work demonstrating that increased\naffective arousal amplified punitive responses to wrongdoing (Lerner,\nGoldberg, & Tetlock 1998), Nichols and Knobe hypothesized that\npreviously observed compatibilist responses were the result of the\naffectively laden nature of the stimulus materials. When this\naffective element was eliminated from the materials (as in the\nabstract condition), participants instead exhibited an incompatibilist\npattern of responses. \nMore recently, Nichols and Knobe’s line of reasoning has come\nunder fire from two directions. First, a number of studies have now\ntried to systematically manipulate how affectively arousing the\nimmoral behavior performed is, but have not found that these changes\nsignificantly alter participants’ judgments of moral\nresponsibility in deterministic scenarios. Rather, the differences\nseem to be best explained simply by whether the case was described\nabstractly or concretely (see Cova et al. 2012 for work with patients\nwho have frontotemporal dementia, and see Feltz & Cova 2014 for a\nmeta-analysis). Second, a separate line of studies from Murray and\nNahmias (2014) argued that participants who exhibited the apparently\nincompatibilist pattern of responses were making a critical error in\nhow they understood the deterministic scenario. In particular, they\nargued these participants mistakenly took the agents, or their mental\nstates, in these deterministic scenarios to be “bypassed”\nin the causal chain leading up to their behavior. In support of their\nargument, Murray and Nahmias (2014) demonstrated that when analyses\nwere restricted to the participants who clearly did not take the agent\nto be bypassed, these participants judged the agent to be morally\nresponsible (blameworthy, etc.) despite being in a deterministic\nuniverse. Unsurprisingly, this line of argument has, in turn, inspired\na number of further counter-responses, both empirical (Rose &\nNichols 2013) and theoretical (Björnsson & Pereboom 2016),\nwhich caution against the conclusions of Murray and Nahmias. \nWhile the debate continues over whether the compatibilist or\nincompatibilist position better captures folk moral judgments of\nagents in deterministic universes, a related line of research has\nsprung up around what is widely taken to be the most convincing\ncontemporary form of argument for incompatibilism: manipulation\narguments (e.g., Mele 2006, 2013, Pereboom 2001, 2014).\nPereboom’s Four-Case version, for example, begins with the case\nof an agent named Plum who is manipulated by neuroscientists who use a\nradio-like technology to change Plum’s neural states, which\nresults in him wanting and then deciding to kill a man named White. In\nthis case, it seems clear that Plum did not freely decide to kill\nWhite. Compare this case to a second one, in which the team of\nneuroscientists programmed Plum at the beginning of his life in a way\nthat resulted in him developing the desire (and making the decision)\nto kill White. The incompatibilist argues that these two cases do not\ndiffer in a way that is relevant for whether Plum acted freely, and\nso, once again, it seems that Plum did not freely decide to kill\nWhite. Now compare this to a third case, in which Plum’s desire\nand decision to kill White were instead determined by his cultural and\nsocial milieu, rather than by a team of neuroscientists. Since the\nonly difference between the second and third case is the particular\ntechnological process through which Plum’s mental states were\ndetermined, he would again seem to not have freely decided to kill\nWhite. Finally, in a fourth and final case, Plum’s desire and\ndecision to kill White was determined jointly by the past states and\nthe laws of nature in our own deterministic universe. Regarding these\nfour cases, Pereboom argues that, since there is no difference between\nany of the four cases that is relevant to free will, if Plum was not\nmorally responsible in the first case, then he was not morally\nresponsible in the fourth. \nIn response to this kind of manipulation-based argument for\nincompatibilism, a number of researchers have taken aim at painting a\nbetter empirical picture of ordinary moral judgments concerning\nmanipulated agents. This line of inquiry has been productive on two\nlevels. First, a growing number of empirical studies have investigated\nmoral responsibility judgments about cases of manipulation, and now\nprovide a clearer psychological picture for why manipulated agents are\njudged to lack free will and moral responsibility. Second, continuing\ntheoretical work, informed by this empirical picture, has provided new\nreasons for doubting that manipulation based arguments actually\nprovide evidence against compatibilism. \nOne line of empirical research, led by Chandra Sripada (2012) has\nasked whether manipulated agents are perceived to be unfree because\n(a) they lack ultimate control over their actions (a capacity\nincompatibilists take to be essential for moral responsibility) or\ninstead because (b) their psychological or volitional capacities (the\ncapacities focused on by compatibilists) have been damaged. Using a\nstatistical approach called Structural Equation Modeling (or SEM),\nSripada found that participants’ moral responsibility judgments\nwere best explained by whether they believed the psychological and\nvolitional capacities of the agent were damaged by manipulation and\nnot whether the agent lacked control over her actions. This finding\nsuggests that patterns of judgment in cases of manipulation are more\nconsistent with the predictions of compatibilism than with\nincompatibilism. \nTaking a different approach, Phillips and Shaw (2014) demonstrated\nthat the reduction of moral responsibility that is typically observed\nin cases of manipulation depends critically on the role of an\nintentional manipulator. In particular, ordinary people were\nshown to distinguish between (1) the moral responsibility of agents\nwho are made to do a particular act by features of the situation they\nare in (i.e., situational determinism), and (2) the moral\nresponsibility of agents who are made to do that same act by another\nintentional agent (i.e., manipulation). This work suggests that the\nordinary practice of assessing freedom and responsibility is likely to\nclearly distinguish between cases that do and do not involve a\nmanipulator who intervenes with the intention of causing the\nmanipulated agent to do the immoral action. A series of studies by\nMurray and Lombrozo (2016) further elaborates these findings by\nproviding evidence that the specific reduction of moral responsibility\nthat results from being manipulated arises from the perception that\nthe agent’s mental states are bypassed. \nCollectively, two lessons have come out of this work on the ordinary\npractice of assessing the moral responsibility of manipulated agents:\n(1) folk morality provides a natural way of distinguishing between the\ndifferent cases used in manipulation-based arguments (those that do\ninvolve the intentional intervention of a manipulator vs. those that\ndon’t) and (2) folk morality draws an intimate link between the\nmoral responsibility of an agent and that agent’s mental and\nvolitional capacities. Building on this increasingly clear empirical\npicture, Deery and Nahmias (2017) formalized these basic principles in\ntheoretical work that argues for a principled way of distinguishing\nbetween the moral responsibility of determined and manipulated\nagents. \nWhile the majority of evidence may currently be in favor of the view\nthat folk morality adheres to a kind of “natural\ncompatibilism” (Cova & Kitano 2013), this remains a\ncontentious topic, and new work is continually emerging on both sides\nof the debate (Andow & Cova 2016; Bear & Knobe 2016;\nBjörnsson 2014; Feltz & Millan 2013; Figdor & Phelan\n2015; Knobe 2014). One thing that has now been agreed on by parties on\nboth sides of this debate, however, is a critical role for careful\nempirical studies (Björnsson & Pereboom 2016; Knobe 2014;\nNahmias 2011). \nTo date, empirically informed approaches to moral psychology have been\nmost prominent in discussions of moral character and virtue. The focus\nis decades of experimentation in “situationist” social\npsychology: unobtrusive features of situations have repeatedly been\nshown to impact behavior in seemingly arbitrary, and sometimes\nalarming, ways. Among the findings that have most interested\nphilosophers: \nThese experiments are part of an extensive empirical literature,\nwhere social psychologists have time and again found that\ndisappointing omissions and appalling actions are readily induced by\napparently minor situational\n features.[10]\n The striking fact is not that people fail standards for good conduct,\nbut that they can be so easily induced to do so. \nExploiting this observation, “character skeptics” contend\nthat if moral conduct varies so sharply, often for the worse, with\nminor perturbations in circumstance, ostensibly good character\nprovides very limited assurance of good conduct. In addition to this\nclaim in descriptive psychology, concerning the fragility of\nmoral character, some character skeptics also forward a thesis in\nnormative ethics, to the effect that character merits less\nattention in ethical thought than it traditionally\n gets.[11] \nCharacter skepticism contravenes the influential program of\ncontemporary virtue ethics, which maintains that advancing\nethical theory requires more attention to character, and\nvirtue ethicists offer vigorous\n resistance.[12]\n Discussion has sometimes been overheated, but it has resulted in a\nlarge literature in a vibrantly interdisciplinary field of\n“character studies” (e.g., Miller et al.\n 2015).[13]\n The literature is too extensive for the confines of this entry, but\nwe will endeavor to outline some of the main issues.  \nThe first thing to observe is that the science which inspires the\ncharacter skeptics may itself be subject to skepticism. Given the\nuneven history of the human sciences, it might be argued that the\nrelevant findings are too uncertain to stand as a constraint on\nphilosophical theorizing. This contention is potentially buttressed by\nrecent prominent replication failures in social psychology.  \nThe psychology at issue is, like much of science, unfinished business.\nBut the replication controversy, and the attendant suspicion of\nscience, is insufficient grounds for dismissing the psychology out of\nhand. Philosophical conclusions should not be based on a few studies;\nthe task of the philosophical consumer of science is to identify\ntrends in convergent strands of evidence (Doris\n2015: 49, 56; Machery & Doris forthcoming). The observation that\nmotivates character skepticism—the surprising situational\nsensitivity of behavior—is supported by a wide range of\nscientific findings, as well as by recurring themes in history and\nbiography (Doris 2002, 2005). The strong situational\ndiscriminativeness of behavior is accepted as fact by high proportion\nof involved scientists; accordingly, it is not much contested in\ndebates about character skepticism. \nBut the philosophical implications of this fact remain, after\nconsiderable debate, a contentious issue. The various responses to\ncharacter skepticism need not be forwarded in isolation, and some of\nthem may be combined as part of a multi-pronged defense. Different\nrejoinders have differing strengths and weaknesses, particularly with\nrespect to the differing pieces of evidence on which character\nskeptics rely; the phenomena are not unitary, and accommodating them\nall may preclude a unitary response.  \nOne way of defusing empirically motivated skepticism—dubbed by\nAlfano (2013) “the dodge”—is simply to deny that\nvirtue ethics makes empirical claims. On this understanding, virtue\nethics is cast as a “purely normative” endeavor aiming at\nerecting ethical ideals in complete absence of empirical commitments\nregarding actual human psychologies. This sort of purity is perhaps\nless honored than honored in the breach: historically, virtue ethics\nhas been typified by an interest in how actual people become\ngood. Aristotle (Nicomachean Ethics, 1099b18–19)\nthought that anyone not “maimed” with regard to the\ncapacity for virtue may acquire it “by a certain kind of study\nand care”, and contemporary Aristotelians have emphasized the\nimportance of moral education and development (e.g., Annas 2011). More\ngenerally, virtue-based approaches have been claimed to have an\nadvantage over major Kantian and consequentialist competitors with\nrespect to “psychological realism”—the advantage of\na more lifelike moral psychology (see Anscombe 1958: 1, 15; Williams\n1985; Flanagan 1991: 182; Hursthouse 1999: 19–20).  \nTo be sure, eschewing empirical commitment allows virtue ethics to\nescape empirical threat: obviously, empirical evidence cannot be used\nto undermine a theory that makes no empirical claims.\nHowever, it is not clear such theories could claim advantages\ntraditionally claimed for virtue theories with regard to moral\ndevelopment and psychological realism. In any event, they are not\ncontributions to empirical moral psychology, and needn’t be\nfurther discussed here. \nBefore seeing how the debate in moral psychology might be advanced, it\nis necessary to correct a mischaracterization that serves to arrest\nprogress. It is too often said, particularly in reference to Doris\n(1998, 2002) and Harman (1999, 2000), that character skepticism comes\nto the view that character traits “do not exist” (e.g.,\nFlanagan 2009: 55). Frequently, this attribution is made without\ndocumentation, but when documentation is provided, it is typically in\nreference to some early, characteristically pointed, remarks of Harman\n(e.g., 1999). Yet in his most recent contribution, Harman (2009: 241)\nsays, “I do not think that social psychology demonstrates there\nare no character traits”. For his part, Doris has repeatedly\nasserted that traits exist, and has repeatedly drawn attention to such\nassertions (Doris 1998: 507–509; 2002: 62–6; 2005: 667;\n2010: 138–141; Doris & Stich 2005: 119–20; Doris &\nPrinz 2009).  \nWith good reason, to say “traits do not exist” is\ntantamount to denying that there are individual dispositional\ndifferences, an unlikely view that character skeptics and antiskeptics\nare united in rejecting. Quite unsurprisingly, this unlikely view is\nseriously undersubscribed in both philosophy and psychology. It is\nendorsed by neither the most aggressive critics of personality,\nsituationists in social psychology such as Ross and Nisbett (1991),\nnor by the patron saint of situationism in personality psychology:\nMischel (1999: 45). Mischel disavows a trait-based approach, but his\nskepticism concerns a particular approach to traits, not\nindividual dispositional differences more generally.  \nThen the question of whether or not traits exist is emphatically\nnot the issue dividing more and less skeptical approaches to\ncharacter. Today, all mainstream parties to the debate are\n“interactionist”, treating behavioral outcomes as the\nfunction of a (complex) person by situation interaction (Mehl et al.\n2015)—and it’s likely most participants have always been\nso (Doris 2002: 25–6). Contemporary research programs in\npersonality and social psychology freely deploy both personal\nand situational variables (e.g., Cameron, Payne, & Doris 2013;\nLeikas, Lönnqvist, & Verkasalo 2012; Sherman, Nave, &\nFunder 2010). The issue worth discussing is not whether individual\ndispositional differences exist, but how these differences should\nbe characterized, and how (or whether) these individual\ndifferences, when appropriately characterized, should inform\nethical thought.  \nAn important feature of early forays into character skepticism was\nthat skeptics tended to focus on behavioral implications of\ntraits rather than the psychological antecedents of behavior\n(Doris 2015: 15). Defenders of virtue ethics observe that character\nskeptics have had much to say about situational variation in behavior\nand little to say about the psychological processes underlying it,\nwith the result that they overlook the rational order in\npeople’s lives (Adams 2006: 115–232). These virtue\nethicists maintain that the behavioral variation provoking character\nskepticism evinces not unreliability, but rationally appropriate\nsensitivity to differing situations (Adams 2006; Kamtekar 2004). The\nvirtuous person, such as Aristotle’s exemplary\nphronimos (“man of practical wisdom”) may\nsometimes come clean, and sometimes dissemble, or sometimes fight, and\nsometimes flee, depending on the particular ethical demands of his\ncircumstances. \nFor example, in the Good Samaritan Study, the hurried passersby was on\nthe way to an appointment where they had agreed to give a\npresentation; perhaps these people made a rational\ndetermination—perhaps even an ethically defensible\ndetermination—to weigh the demands of punctuality and\nprofessionalism over ethical requirement to check on the welfare of a\nstranger in apparent distress. However attractive one finds such\naccounting for this case (note that some of Darley and Batson’s\n[1973] hurried passersby failed to notice the victim, which strains\nexplanations in terms of their rational discriminations), there are\nother cases where the “rationality response” seems plainly\nunattractive. These are cases of ethically irrelevant influences\n (Sec. 2 above;\n Doris & Stich 2005), where it seems unlikely the influence could\nbe cited as part of a rationalizing explanation of the behavior:\nit’s odd to cite failing to find a dime as\njustification for failing to help—or for that matter,\nfinding a dime as justification for doing so. \nIt is certainly appropriate for virtue ethicists to emphasize\npractical rationality in their accounts of character. This is a\ncentral theme in the tradition going back to Aristotle himself, who is\nprobably the most oft-cited canonical philosopher in contemporary\nvirtue ethics. But while the rationality response may initially\naccommodate some of the troubling behavioral evidence, it encounters\nfurther empirical difficulty. There is an extensive empirical\nliterature problematizing familiar conceptions of rationality:\npsychologists have endlessly documented a dispiriting range of\nreasoning errors (Baron 1994, 2001; Gilovich et al. 2002; Kahneman et\nal. 1982; Tversky & Kahneman 1973; Kruger & Dunning 1999;\nNisbett & Borgida 1975; Nisbett & Ross 1980; Stich 1990;\nTversky & Kahneman 1981). In light of this evidence, character\nskeptics claim that the vagaries afflicting behavior also afflict\nreasoning (Alfano 2013; Olin & Doris 2014).  \nResearch supporting this discouraging assessment of human rationality\nis controversial, and not all psychologists think things are so bleak\n(Gigerenzer 2000; Gigerenzer et al. 1999; for philosophical commentary\nsee Samuels & Stich 2002). Nevertheless, if virtue ethics is to\nhave an empirically credible moral psychology, it needs to account for\nthe empirical challenges to practical reasoning: how can the relevant\nexcellence in practical reasoning be developed?  \nFaced with the challenge to practical rationality, virtue ethicists\nmay respond that their theories concern excellent reasoning,\nnot the ordinary reasoning studied in psychology. Practical\nwisdom, and the ethical virtue it supports, are expected to be\nrare, and not widely instantiated. This state of affairs, it\nis said, is quite compatible with the disturbing, but not\nexceptionlessly disturbing, behavior in experiments like\nMilgram’s (see Athanassoulis 1999: 217–219; DePaul 1999;\nKupperman 2001: 242–3). If this account is supposed to be part\nof an empirically contentful moral psychology, rather than unverified\nspeculation, we require a detailed and empirically substantiated\naccount of how the virtuous few get that way—remember that an\nemphasis on moral development is central to the virtue ethics\ntradition. Moreover, if virtue ethics is supposed to have widespread\npractical implications—as opposed to being merely a celebration\nof a tiny “virtue elite”—it should have an account\nof how the less-than-virtuous-many may at least tolerably\napproximate virtue.  \nThis point is underscored by the fact that for some of the troubling\nevidence, as in the Stanford Prison Study, the worry is not so much\nthat people fail standards of virtue, but that they fail standards of\nminimal decency. Surely an approach to ethics that celebrates\nmoral development, even one that acknowledges (or rather, insists)\nthat most people will not attain its ideal, might be expected to have\nan account of how people can become minimally decent. \nRecently, proponents of virtue ethics have been increasingly proposing\na suggestive solution to this problem: virtue is a skill acquired\nthrough effortful practice, so virtue is a kind of expertise (Annas\n2011; Bloomfield 2000, 2001, 2014; Jacobson 2005; Russell 2015; Snow\n2010; Sosa 2009; Stichter 2007, 2011; for reservations, see Doris, in\npreparation). The virtuous are expert at morality and—given the\nAristotelian association of virtue and happiness—expert at life.\n \nAn extensive scientific literature indicates that developing expert\nskill requires extensive preparation, whether the practitioner is a\nnovelist, doctor, or chess master—around 10,000 hours of\n“deliberate practice”, according to a popular\ngeneralization (Ericsson 2014; Ericsson et al. 1993). The\n“10,000–hour rule” is likely an oversimplification,\nbut there is no doubt that attaining expertise requires intensive\ntraining. Because of this, people rarely achieve eminence in more than\none area; for instance, “baseball trivia” experts display\nsuperior recall for baseball-related material, but not for\nnon-baseball material (Chiesi et al. 1979). Conversely, becoming\nexpert at morality, or (even more ambitiously) expert at the whole of\nlife, would apparently require a highly generalized form of\nexpertise: to be good, there’s a lot to be good at.\nMoreover, it’s quite unclear what deliberate practice at life\ninvolves; how exactly does one get better at being good?  \nOne obvious problem concerns specifying the “good” in\nquestion. Expertises like chess have been effectively studied in part\nbecause there are accepted standards of excellence (the\n“ELO” score used for ranking chess players; Glickman\n1995). To put it blithely, there aren’t any chess skeptics. But\nthere have, historically, been lots of moral skeptics. And if\nthere’s not moral knowledge, how could there be moral experts?\nAnd even if there are moral experts, there’s the problem of how\nare they to be identified, since it is not clear we are possessed of\nstandard independent of expert opinion itself (like winning chess\nmatches) for doing so (for the “metaethics of expertise”,\nsee McGrath 2008, 2011). \nEven if these notorious philosophical difficulties can be\nresolved—as defenders of expertise approaches to virtue must\nthink they can—matters remain complicated, because if moral\nexpertise is like other expertises, practice alone—assuming we\nhave a clear notion of what “moral practice”\nentails—will be insufficient. While practice matters in\nattaining expertise, other factors, such as talent, also matter\n(Hambrick et al. 2014; Macnamara et al. 2014). And some of the\nrequired endowments may be quite unequally distributed across\npopulations: practice cannot make a jockey into an NFL lineman, or an\nNFL lineman into a jockey.  \nWhat are the natural endowments required for moral expertise, and how\nwidely are they distributed in the population? If they are rare, like\nthe skill of a chess master or the strength of an NFL lineman, virtue\nwill also be rare. Some virtue ethicists believe virtue should be\nwidely attainable, and they will resist this result (Adams 2006:\n119–123, and arguably Aristotle Nicomachean Ethics\n1099b15–20). But even virtue ethicists who embrace the rarity of\nvirtue require an account of what the necessary natural endowments\nare, and if they wish to also have an account of how the less\nwell-endowed may achieve at least minimal decency, they should have\nsomething to say about how moral development will proceed across a\npopulation with widely varying endowments. \nWhat is needed, for the study of moral character research to advance,\nis an account of the biological, psychological, and social factors\nrequisite for successful moral development—on the expertise\nmodel, the conditions conducive to developing “moral\nskill”. This, quite obviously, is a tall order, and the research\nneeded to systematically address these issue is in comparative\ninfancy. Yet the expertise model, in exploiting connections with areas\nin which skill acquisition has been well studied, such as music and\nsport, provides a framework for moving discussion of character beyond\nthe empirically under-informed conjectures and assumptions about\n“habituation” that have been too frequent in previous\nliterature (Doris 2015: 128). \nPeople often behave in ways that benefit others, and they sometimes do\nthis knowing that it will be costly, unpleasant or dangerous. But at\nleast since Plato’s classic discussion in the second Book of the\nRepublic, debate has raged over why people behave in\nthis way. Are their motives altruistic, or is their behavior\nultimately motivated by self-interest? Famously, Hobbes gave this\nanswer: \nNo man giveth but with intention of good to himself, because gift is\nvoluntary; and of all voluntary acts, the object is to every man his\nown good; of which, if men see they shall be frustrated, there will be\nno beginning of benevolence or trust, nor consequently of mutual help.\n(1651 [1981: Ch. 15]) \nViews like Hobbes’ have come to be called\n egoism,[14]\n and this rather depressing conception of human motivation has any\nnumber of eminent philosophical advocates, including Bentham, J.S.\nMill and\n Nietzsche.[15]\n Dissenting voices, though perhaps fewer in number, have been no less\neminent. Butler, Hume, Rousseau and Adam Smith have all argued that,\nsometimes at least, human motivation is genuinely altruistic. \nThough the issue that divides egoistic and altruistic accounts of\nhuman motivation is largely empirical, it is easy to see why\nphilosophers have thought that the competing answers will have\nimportant consequences for moral theory. For example, Kant famously\nargued that a person should act “not from inclination but from\nduty, and by this would his conduct first acquire true moral\nworth” (1785 [1949: Sec. 1, parag. 12]). But egoism maintains\nthat all human motivation is ultimately self-interested, and\nthus people can’t act “from duty” in the\nway that Kant urged. Thus if egoism is true, Kant’s account\nwould entail that no conduct has “true moral worth”.\nAdditionally, if egoism is true, it would appear to impose a strong\nconstraint on how a moral theory can answer the venerable question\n“Why should I be moral?” since, as Hobbes clearly saw, the\nanswer will have to ground the motivation to be moral in the\nagent’s\n self-interest.[16] \nWhile the egoism vs. altruism debate has historically been of great\nphilosophical interest, the issue centrally concerns psychological\nquestions about the nature of human motivation, so it’s not\nsurprise that psychologists have done a great deal of empirical\nresearch aimed at determining which view is correct. Some of the most\ninfluential and philosophically sophisticated empirical work on this\nissue has been done by Daniel Batson and his associates. The\nconclusion Batson draws from this work is that people do\nsometimes behave altruistically, and that the emotion of empathy plays\nan important role in generating altruistic motivation.\n [17]\n Others are not convinced. For a discussion of Batson’s\nexperiments, the conclusion he draws from them, and some reasons for\nskepticism about that conclusion, see sections 5 and 6 of the entry\n“Empirical Approaches to Altruism” in this encyclopedia.\nIn this section, we’ll focus on some of the philosophical\nspadework that is necessary before plunging into the empirical\nliterature. \nA crucial question that needs to be addressed is: What, exactly, is\nthe debate about; what is altruism? Unfortunately, there is\nno uncontroversial answer to this question, since researchers in many\ndisciplines, including philosophy, biology, psychology, sociology,\neconomics, anthropology and primatology, have written about altruism,\nand authors in different disciplines tend to use the term\n“altruism” in quite different ways. Even among\nphilosophers the term has been used with importantly different\nmeanings. There is, however, one account of altruism—actually a\ncluster closely related accounts—that plays a central role both\nin philosophy and in a great deal of psychology, including\nBatson’s work. We’ll call it “the standard\naccount”. That will be our focus in the remainder of this\n section.[18] \nAccording to the standard account, an action is altruistic if it is\nmotivated by an ultimate desire for the well-being of another person.\nThis formulation invites questions about (1) what it is for a behavior\nto be motivated by an ultimate desire, and (2) the\ndistinction between desires that are self-interested and\ndesires that are for the well-being of others. \nAlthough the second question will need careful consideration in any\ncomprehensive treatment, a few rough and ready examples of the\ndistinction will suffice\n here.[19]\n Desires to save someone else’s life, to alleviate someone\nelse’s suffering, or to make someone else happy are paradigm\ncases of desires for the well-being of others, while desires to\nexperience pleasure, get rich, and become famous are typical examples\nof self-interested desires. The self-interested desires to experience\npleasure and to avoid pain have played an especially prominent role in\nthe debate, since one version of egoism, often called\nhedonism, maintains that these are our only ultimate\ndesires. \nThe first question, regarding ultimate desires, requires a fuller\nexposition; it can be usefully explicated with the help of a familiar\naccount of practical\n reasoning.[20]\n On this account, practical reasoning is a causal process via which a\ndesire and a belief give rise to or sustain another desire. For\nexample, a desire to drink an espresso and a belief that the best\nplace to get an espresso is at the espresso bar on Main Street may\ncause a desire to go to the espresso bar on Main Street. This desire\ncan then join forces with another belief to generate a third desire,\nand so on. Sometimes this process will lead to a desire to perform a\nrelatively simple or “basic” action, and that desire, in\nturn, will cause the agent to perform the basic action without the\nintervention of any further desires. Desires produced or sustained by\nthis process of practical reasoning are instrumental\ndesires—the agent has them because she thinks that satisfying\nthem will lead to something else that she desires. But not\nall desires can be instrumental desires. If we are to avoid\ncircularity or an infinite regress there must be some desires that are\nnot produced because the agent thinks that satisfying them\nwill facilitate satisfying some other desire. These desires that are\nnot produced or sustained by practical reasoning are the agent’s\nultimate desires, and the objects of ultimate desires, the\nstates of affairs desired, are desired for their own sake. A behavior\nis motivated by a specific ultimate desire when that desire\nis part of the practical reasoning process that leads to the\nbehavior. \nIf people do sometimes have ultimate desires for the well-being of\nothers, and these desires motivate behavior, then altruism is the\ncorrect view, and egoism is false. However, if all ultimate\ndesires are self-interested, then egoism is the correct view, and\naltruism is false. The effort to establish one or the other of these\noptions has given rise to a vast and enormously sophisticated\nempirical literature. For an overview of that literature, see the\n empirical approaches to altruism entry. \nGiven that moral disagreement—about abortion, say, or capital\npunishment—so often seems intractable, is there any reason to\nthink that moral problems admit objective resolutions? While this\ndifficulty is of ancient coinage, contemporary philosophical\ndiscussion was spurred by Mackie’s (1977: 36–8)\n“argument from relativity” or, as it is called by later\nwriters, the “argument from disagreement” (Brink 1989:\n197; Loeb 1998). Such “radical” differences in moral\njudgment as are frequently observed, Mackie (1977: 36) argued,\n“make it difficult to treat those judgments as apprehensions of\nobjective truths”. \nMackie supposed that his argument undermines moral realism,\nthe view that, as Smith (1994: 9, cf. 13) puts it,  \nmoral questions have correct answers, that the correct answers are\nmade correct by objective moral facts … and … by\nengaging in moral argument, we can discover what these objective moral\nfacts\n are.[21] \nThis notion of objectivity, as Smith recognizes, requires\nconvergence in moral views—the right sort of argument,\nreflection and discussion is expected to result in very substantial\nmoral agreement (Smith 1994:\n 6).[22] \nWhile moral realists have often taken pretty optimistic positions on\nthe extent of actual moral agreement (e.g., Sturgeon 1988: 229; Smith\n1994: 188), there is no denying that there is an abundance of\npersistent moral disagreement; on many moral issues there is a\nstriking failure of convergence even after protracted\nargument. Anti-realists like Mackie have a ready explanation for this\nphenomenon: Moral judgment is not objective in Smith’s sense,\nand moral argument cannot be expected to accomplish what Smith and\nother realists think it\n can.[23]\n Conversely, the realist’s task is to explain away\nfailures of convergence; she must provide an explanation of the\nphenomena consistent with it being the case that moral judgment is\nobjective and moral argument is rationally resolvable. Doris and\nPlakias (2008) call these “defusing explanations”. The\nrealist’s strategy is to insist that the preponderance of actual\nmoral disagreement is due to limitations of disputants or their\ncircumstances, and insist that (very substantial, if not\n unanimous)[24]\n moral agreement would emerge in ideal conditions,\nwhen, for example, disputants are fully rational and fully informed of\nthe relevant non-moral facts. \nIt is immediately evident that the relative merits of these competing\nexplanations cannot be fairly determined without close discussion of\nthe factors implicated in actual moral disagreements. Indeed, as acute\ncommentators with both realist (Sturgeon 1988: 230) and anti-realist\n(Loeb 1998: 284) sympathies have noted, the argument from disagreement\ncannot be evaluated by a priori philosophical means alone;\nwhat’s needed, as Loeb observes, is “a great deal of\nfurther empirical research into the circumstances and beliefs of\nvarious cultures”. This research is required not only to\naccurately assess the extent of actual disagreement, but also to\ndetermine why disagreement persists or dissolves. Only then\ncan realists’ attempts to “explain away” moral\ndisagreement be fairly assessed. \nRichard Brandt, who was a pioneer in the effort to integrate ethical\ntheory and the social sciences, looked primarily to anthropology to\nhelp determine whether moral attitudes can be expected to converge\nunder idealized circumstances. It is of course well known that\nanthropology includes a substantial body of work, such as the classic\nstudies of Westermarck (1906) and Sumner (1908 [1934]), detailing the\nradically divergent moral outlooks found in cultures around the world.\nBut as Brandt (1959: 283–4) recognized, typical ethnographies do\nnot support confident inferences about the convergence of attitudes\nunder ideal conditions, in large measure because they often give\nlimited guidance regarding how much of the moral disagreement can be\ntraced to disagreement about factual matters that are not moral in\nnature, such as those having to do with religious or cosmological\nviews. \nWith this sort of difficulty in mind, Brandt (1954) undertook his own\nanthropological study of Hopi people in the American southwest, and\nfound issues for which there appeared to be serious moral disagreement\nbetween typical Hopi and white American attitudes that could not\nplausibly be attributed to differences in belief about nonmoral\n facts.[25]\n A notable example is the Hopi attitude toward animal suffering, an\nattitude that might be expected to disturb many non-Hopis: \n[Hopi children] sometimes catch birds and make “pets” of\nthem. They may be tied to a string, to be taken out and\n“played” with. This play is rough, and birds seldom\nsurvive long. [According to one informant:] “Sometimes they get\ntired and die. Nobody objects to this”. (Brandt 1954: 213) \nBrandt (1959: 103) made a concerted effort to determine whether this\ndifference in moral outlook could be traced to disagreement about\nnonmoral facts, but he could find no plausible explanation of this\nkind; his Hopi informants didn’t believe that animals lack the\ncapacity to feel pain, for example, nor did they have cosmological\nbeliefs that would explain away the apparent cruelty of the practice,\nsuch as beliefs to the effect that animals are rewarded for martyrdom\nin the afterlife. The best explanation of the divergent moral\njudgments, Brandt (1954: 245, 284) concluded, is a “basic\ndifference of attitude”, since “groups do sometimes make\ndivergent appraisals when they have identical beliefs about the\nobjects”. \nMoody-Adams argues that little of philosophical import can be\nconcluded from Brandt’s—and indeed from\nmuch—ethnographic work. Deploying Gestalt psychology’s\ndoctrine of “situational meaning” (e.g., Dunker 1939),\nMoody-Adams (1997: 34–43) contends that all institutions,\nutterances, and behaviors have meanings that are peculiar to their\ncultural milieu, so that we cannot be certain that participants in\ncross-cultural disagreements are talking about the same\n thing.[26]\n The problem of situational meaning, she thinks, threatens\n“insuperable” methodological difficulty for those\nasserting the existence of intractable intercultural disagreement\n(1997: 36). Advocates of ethnographic projects will likely\nrespond—not unreasonably, we think—that judicious\nobservation and interview, such as that to which Brandt aspired,\ncan motivate confident assessments of evaluative diversity.\nSuppose, however, that Moody-Adams is right, and the methodological\ndifficulties are insurmountable. Now, there’s an equitable\ndistribution of the difficulty: if observation and interview are\nreally as problematic as Moody-Adams suggests, neither the\nrealists’ nor the anti-realists’ take on\ndisagreement can be supported by appeal to empirical evidence. We do\nnot think that such a stalemate obtains, because we think the\nimplicated methodological pessimism excessive. Serious empirical work\ncan, we think, tell us a lot about cultures and the differences\nbetween them. The appropriate way of proceeding is with close\nattention to particular studies, and what they show and fail to\n show.[27] \nAs Brandt (1959: 101–2) acknowledged, the anthropological\nliterature of his day did not always provide as much information on\nthe exact contours and origins of moral attitudes and beliefs as\nphilosophers wondering about the prospects for convergence might like.\nHowever, social psychology and cognitive science have recently\nproduced research which promises to further discussion; during the\nlast 35 years, there has been an explosion of “cultural\npsychology” investigating the cognitive and emotional processes\nof different cultures (Shweder & Bourne 1982; Markus &\nKitayama 1991; Ellsworth 1994; Nisbett & Cohen 1996; Nisbett 1998,\n2003; Kitayama & Markus 1999; Heine 2008; Kitayama & Cohen\n2010; Henrich 2015). Here we will focus on some cultural differences\nfound close to (our) home, differences discovered by Nisbett and his\ncolleagues while investigating regional patterns of violence in the\nAmerican North and South. We argue that these findings support\nBrandt’s pessimistic conclusions regarding the likelihood of\nconvergence in moral judgment. \nThe Nisbett group’s research can be seen as applying the tools\nof cognitive social psychology to the “culture of honor”,\na phenomenon that anthropologists have documented in a variety of\ngroups around the world. Although these groups differ in many\nrespects, they manifest important commonalities: \nA key aspect of the culture of honor is the importance placed on the\ninsult and the necessity to respond to it. An insult implies that the\ntarget is weak enough to be bullied. Since a reputation for strength\nis of the essence in the culture of honor, the individual who insults\nsomeone must be forced to retract; if the instigator refuses, he must\nbe punished—with violence or even death. (Nisbett & Cohen\n1996: 5) \nAccording to Nisbett and Cohen (1996: 5–9), an important factor\nin the genesis of southern honor culture was the presence of a herding\neconomy. Honor cultures are particularly likely to develop where\nresources are liable to theft, and where the state’s coercive\napparatus cannot be relied upon to prevent or punish thievery. These\nconditions often occur in relatively remote areas where herding is a\nmain form of subsistence; the “portability” of herd\nanimals makes them prone to theft. In areas where farming rather than\nherding dominates, cooperation among neighbors is more important,\nstronger government infrastructures are more common, and\nresources—like decidedly unportable farmland—are harder to\nsteal. In such agrarian social economies, cultures of honor tend not\nto develop. The American South was originally settled primarily by\npeoples from remote areas of Britain. Since their homelands were\ngenerally unsuitable for farming, these peoples have historically been\nherders; when they emigrated from Britain to the American South, they\ninitially sought out remote regions suitable for herding, and in such\nregions, the culture of honor flourished. \nIn the contemporary South, police and other government services are\nwidely available and herding has all but disappeared as a way of life,\nbut certain sorts of violence continue to be more common than they are\nin the North. Nisbett and Cohen (1996) maintain that patterns of\nviolence in the South, as well as attitudes toward violence, insults,\nand affronts to honor, are best explained by the hypothesis that a\nculture of honor persists among contemporary white non-Hispanic\nsoutherners. In support of this hypothesis, they offer a compelling\narray of evidence, including: \nTwo experimental studies—one in the field, the other in the\nlaboratory—are especially striking. \nIn the field study (Nisbett & Cohen 1996: 73–5), letters of\ninquiry were sent to hundreds of employers around the United States.\nThe letters purported to be from a hardworking 27-year-old Michigan\nman who had a single blemish on his otherwise solid record. In one\nversion, the “applicant” revealed that he had been\nconvicted for manslaughter. The applicant explained that he had been\nin a fight with a man who confronted him in a bar and told onlookers\nthat “he and my fiancée were sleeping together. He\nlaughed at me to my face and asked me to step outside if I was man\nenough”. According to the letter, the applicant’s nemesis\nwas killed in the ensuing fray. In the other version of the letter,\nthe applicant revealed that he had been convicted of motor vehicle\ntheft, perpetrated at a time when he needed money for his family.\nNisbett and his colleagues assessed 112 letters of response, and found\nthat southern employers were significantly more likely to be\ncooperative and sympathetic in response to the manslaughter letter\nthan were northern employers, while no regional differences were found\nin responses to the theft letter. One southern employer responded to\nthe manslaughter letter as follows: \nAs for your problems of the past, anyone could probably be in the\nsituation you were in. It was just an unfortunate incident that\nshouldn’t be held against you. Your honesty shows that you are\nsincere…. I wish you the best of luck for your future. You have\na positive attitude and a willingness to work. These are qualities\nthat businesses look for in employees. Once you are settled, if you\nare near here, please stop in and see us. (Nisbett & Cohen 1996:\n75) \nNo letters from northern employers were comparably sympathetic. \nIn the laboratory study (Nisbett & Cohen 1996: 45–8)\nsubjects—white males from both northern and southern states\nattending the University of Michigan—were told that saliva\nsamples would be collected to measure blood sugar as they performed\nvarious tasks. After an initial sample was collected, the unsuspecting\nsubject walked down a narrow corridor where an experimental\nconfederate was pretending to work on some filing. The confederate\nbumped the subject and, feigning annoyance, called him an\n“asshole”. A few minutes after the incident, saliva\nsamples were collected and analyzed to determine the level of\ncortisol—a hormone associated with high levels of stress,\nanxiety and arousal, and testosterone—a hormone associated with\naggression and dominance behavior. As Figure 1 indicates, southern\nsubjects showed dramatic increases in cortisol and testosterone\nlevels, while northerners exhibited much smaller changes. \nFigure 1 \nThe two studies just described suggest that southerners respond more\nstrongly to insult than northerners, and take a more sympathetic view\nof others who do so, manifesting just the sort of attitudes that are\nsupposed to typify honor cultures. We think that the data assembled by\nNisbett and his colleagues make a persuasive case that a culture of\nhonor persists in the American South. Apparently, this culture affects\npeople’s judgments, attitudes, emotion, behavior, and even their\nphysiological responses. Additionally, there is evidence that child\nrearing practices play a significant role in passing the culture of\nhonor on from one generation to the next, and also that relatively\npermissive laws regarding gun ownership, self-defense, and corporal\npunishment in the schools both reflect and reinforce southern honor\nculture (Nisbett & Cohen 1996: 60–63, 67–9). In short,\nit seems to us that the culture of honor is deeply entrenched in\ncontemporary southern culture, despite the fact that many of the\nmaterial and economic conditions giving rise to it no longer widely\n obtain.[28] \nWe believe that the North/South cultural differences adduced by\nNisbett and colleagues support Brandt’s conclusion that moral\nattitudes will often fail to converge, even under ideal conditions.\nThe data should be especially troubling for the realist, for despite\nthe differences that we have been recounting, contemporary northern\nand southern Americans might be expected to have rather more in\ncommon—from circumstance to language to belief to\nideology—than do, say, Yanomamö and Parisians. So if there\nis little ground for expecting convergence in the case at hand, there\nis probably little ground in a good many others. \nFraser and Hauser (2010) are not convinced by our interpretation of\nNisbett and Cohen’s data. They maintain that while those data do\nindicate that northerners and southerners differ in the strength of\ntheir disapproval of insult-provoked violence, they do not show that\nnortherners and southerners have a real moral disagreement. They go on\nto argue that the work of Abarbanell and Hauser (2010) provides a much\nmore persuasive example of a systematic moral disagreement between\npeople in different cultural groups. Abarbanell and Hauser focused on\nthe moral judgments of rural Mayan people in the Mexican state of\nChiapas. They found that people in that community do not judge\nactions causing harms to be worse than omissions\n(failures to act) which cause identical harms, while nearby urban\nMayan people and Western internet users judge actions to be\nsubstantially worse than omissions.  \nThough we are not convinced by Fraser and Hauser’s\ninterpretation of the Nisbett and Cohen data, we agree that the\nAbarbanell and Hauser study provides a compelling example of a\nsystematic cultural difference in moral judgement. Barrett et al.\n(2016) provides another example. That study looked at the extent to\nwhich an agent’s intention affected the moral judgments of\npeople in eight traditional small-scale societies and two Western\nsocieties, one urban, one rural. They found that in some of these\nsocieties, notably including both Western groups, the agent’s\nintention had a major effect, while in other societies agent intention\nhad little or no effect.  \nAs we said at the outset, realists defending conjectures about\nconvergence may attempt to explain away evaluative diversity\nby arguing that the diversity is to be attributed to shortcomings of\ndiscussants or their circumstances. If this strategy can be made good,\nmoral realism may survive an empirically informed argument from\ndisagreement: so much the worse for the instance of moral reflection\nand discussion in question, not so much the worse for the objectivity\nof morality. While we cannot here canvass all the varieties of this\nsuggestion, we will briefly remark on some of the more common forms.\nFor concreteness, we will focus on Nisbett and Cohen’s\nstudy. \nImpartiality. One strategy favored by moral realists\nconcerned to explain away moral disagreement is to say that such\ndisagreement stems from the distorting effects of individual interest\n(see Sturgeon 1988: 229–230; Enoch 2009: 24–29); perhaps\npersistent disagreement doesn’t so much betray deep features of\nmoral argument and judgment as it does the doggedness with which\nindividuals pursue their perceived advantage. For instance, seemingly\nmoral disputes over the distribution of wealth may be due to\nperceptions—perhaps mostly inchoate—of individual and\nclass interests rather than to principled disagreement about justice;\npersisting moral disagreement in such circumstances fails the\nimpartiality condition, and is therefore untroubling to the moral\nrealist. But it is rather implausible to suggest that North/South\ndisagreements as to when violence is justified will fail the\nimpartiality condition. There is no reason to think that southerners\nwould be unwilling to universalize their judgments across relevantly\nsimilar individuals in relevantly similar circumstances, as indeed\nNisbett and Cohen’s “letter study” suggests. One can\nadvocate a violent honor code without going in for special\n pleading.[29]\n We do not intend to denigrate southern values; our point is that\nwhile there may be good reasons for criticizing the honor-bound\nsoutherner, it is not obvious that the reason can be failure of\nimpartiality, if impartiality is (roughly) to be understood along the\nlines of a willingness to universalize one’s moral\njudgments. \nFull and vivid awareness of relevant nonmoral facts. Moral\nrealists have argued that moral disagreements very often derive from\ndisagreement about nonmoral issues. According to Boyd (1988: 213; cf.\nBrink 1989: 202–3; Sturgeon 1988: 229),  \ncareful philosophical examination will reveal … that agreement\non nonmoral issues would eliminate almost all disagreement\nabout the sorts of moral issues which arise in ordinary moral\npractice.  \nIs this a plausible conjecture for the data we have just considered?\nWe find it hard to imagine what agreement on nonmoral facts could do\nthe trick, for we can readily imagine that northerners and southerners\nmight be in full agreement on the relevant nonmoral facts in the cases\ndescribed. Members of both groups would presumably agree that the job\napplicant was cuckolded, for example, or that calling someone an\n“asshole” is an insult. We think it much more plausible to\nsuppose that the disagreement resides in differing and deeply\nentrenched evaluative attitudes regarding appropriate responses to\ncuckolding, challenge, and insult. \nSavvy philosophical readers will be quick to observe that terms like\n“challenge” and “insult” look like\n“thick” ethical terms, where the evaluative and\ndescriptive are commingled (see Williams 1985: 128–30);\ntherefore, it is very difficult to say what the extent of the factual\ndisagreement is. But this is of little help for the expedient under\nconsideration, since the disagreement-in-nonmoral-fact response\napparently requires that one can disentangle factual\nand moral disagreement. \nIt is of course possible that full and vivid awareness of the nonmoral\nfacts might motivate the sort of change in southern attitudes\nenvisaged by the (at least the northern) moral realist. Were\nsoutherners to become vividly aware that their culture of honor was\nimplicated in violence, they might be moved to change their moral\noutlook. (We take this way of putting the example to be the most\nnatural one, but nothing philosophical turns on it. If you like,\nsubstitute the possibility of northerners endorsing honor values after\nexposure to the facts.) On the other hand, southerners might insist\nthat the values of honor should be nurtured even at the cost of\npromoting violence; the motto “death before dishonor”,\nafter all, has a long and honorable history. The burden of argument,\nwe think, lies with the realist who asserts—culture and\nhistory notwithstanding—that southerners would change their\nmind if vividly aware of the pertinent facts. \nFreedom from “Abnormality”. Realists may contend\nthat much moral disagreement may result from failures of rationality\non the part of discussants (Brink 1989: 199–200). Obviously,\ndisagreement stemming from cognitive impairments is no embarrassment\nfor moral realism; at the limit, that a disagreement persists when\nsome or all disputing parties are quite insane shows nothing deep\nabout morality. But it doesn’t seem plausible that\nsoutherners’ more lenient attitudes towards certain forms of\nviolence are readily attributed to widespread cognitive disability. Of\ncourse, this is an empirical issue, but we don’t know of any\nevidence suggesting that southerners suffer some cognitive impairment\nthat prevents them from understanding demographic and attitudinal\nfactors in the genesis of violence, or any other matter of fact. What\nis needed to press home a charge of irrationality is evidence of\ncognitive impairment independent of the attitudinal\ndifferences, and further evidence that this impairment is implicated\nin adherence to the disputed values. In this instance, as in many\nothers, we have difficulty seeing how charges of abnormality or\nirrationality can be made without one side begging the question\nagainst the other. \nNisbett and colleagues’ work may represent a potent\ncounterexample to any theory maintaining that rational argument tends\nto convergence on important moral issues; the evidence suggests that\nthe North/South differences in attitudes towards violence and honor\nmight well persist even under the sort of ideal conditions under\nconsideration. Admittedly, such conclusions must be tentative. On the\nphilosophical side, not every plausible strategy for “explaining\naway” moral disagreement and grounding expectations of\nconvergence has been\n considered.[30]\n On the empirical side, this entry has reported on but a few studies, and\nthose considered, like any empirical work, might be\ncriticized on either conceptual or methodological\n grounds.[31]\n Finally, it should be clear what this entry is not claiming:\nany conclusions here—even if fairly earned—are not a\n“refutation” of all versions of moral realism, since there\nare versions of moral realism that do not require convergence\n(Bloomfield 2001; Shafer-Landau 2003). \nRather, this discussion should give an idea of the empirical work\nphilosophers must encounter, if they are to make defensible\nconjectures regarding moral disagreement. \nProgress in ethical theorizing often requires progress on difficult\npsychological questions about how human beings can be expected to\nfunction in moral contexts. It is no surprise, then, that moral\npsychology is a central area of inquiry in philosophical ethics. It\nshould also come as no surprise that empirical research, such as that\nconducted in psychology departments, may substantially abet such\ninquiry. Nor then, should it surprise that research in moral\npsychology has become methodologically pluralistic,\nexploiting the resources of, and endeavoring to contribute to, various\ndisciplines. Here, we have illustrated how such interdisciplinary\ninquiry may proceed with regard to central problems in philosophical\nethics.","contact.mail":"stich.steve@gmail.com","contact.domain":"gmail.com"},{"date.published":"2006-04-19","date.changed":"2020-01-06","url":"https://plato.stanford.edu/entries/moral-psych-emp/","author1":"John Doris","author2":"Lachlan Walmsley","author1.info":"https://philosophy.cornell.edu/john-m-doris","author2.info":"https://philosophy.rutgers.edu/people/faculty/details/182-faculty1/faculty-profiles/635-stich-stephen","entry":"moral-psych-emp","body.text":"\n\n\nMoral psychology investigates human functioning in moral contexts, and\nasks how these results may impact debate in ethical theory. This work\nis necessarily interdisciplinary, drawing on both the empirical\nresources of the human sciences and the conceptual resources of\nphilosophical ethics. The present article discusses several topics\nthat illustrate this type of inquiry: thought experiments,\nresponsibility, character, egoism v. altruism, and moral\ndisagreement.\n\nContemporary moral psychology—the study of human thought and\nbehavior in ethical contexts—is resolutely interdisciplinary:\npsychologists freely draw on philosophical theories to help structure\ntheir empirical research, while philosophers freely draw on empirical\nfindings from psychology to help structure their\n theories.[1] \nWhile this extensive interdisciplinarity is a fairly recent\ndevelopment (with few exceptions, most of the relevant work dates from\nthe past quarter century), it should not be a surprising development.\nFrom antiquity to the present, philosophers have not been bashful\nabout making empirical claims, and many of these empirical claims have\nbeen claims about human psychology (Doris & Stich 2005). It is\ntherefore unremarkable that, with the emergence of scientific\npsychology over the past century and a half, some of these\nphilosophers would think to check their work against the systematic\nfindings of psychologists (hopefully, while taking special care to\navoid being misled by scientific controversy; see Doris 2015, Chapter\n3; Machery & Doris forthcoming).  \nSimilarly, at least since the demise of behaviorism, psychologists\nhave been keenly interested in normative phenomena in general and\nethical phenomena in particular. It is therefore unremarkable that\nsome of these psychologists would seek to enrich their theoretical\nframeworks with the conceptual resources of a field intensively\nfocused on normative phenomena: philosophical ethics. As a result, the\nfield demarcated by “moral psychology”, routinely involves\nan admixture of empirical and normative inquiry, pursued by both\nphilosophers and psychologists—increasingly, in the form of\ncollaborative efforts involving practitioners from both fields.  \nFor philosophers, the special interest of this interdisciplinary\ninquiry lies in the ways moral psychology may help adjudicate between\ncompeting ethical theories. The plausibility of its associated moral\npsychology is not, of course, the only dimension on which an ethical\ntheory may be evaluated; equally important are normative\nquestions having to do with how well a theory fares when compared to\nimportant convictions about such things as justice, fairness, and the\ngood life. Such questions have been, and will continue to be, of\ncentral importance for philosophical ethics. Nonetheless, it is\ncommonly supposed that an ethical theory committed to an impoverished\nor inaccurate conception of moral psychology is at a serious\ncompetitive disadvantage. As Bernard Williams (1973, 1985; cf.\nFlanagan 1991) forcefully argued, an ethical conception that commends\nrelationships, commitments, or life projects that are at odds with the\nsorts of attachments that can be reasonably expected to take root in\nand vivify actual human lives is an ethical conception with—at\nbest—a very tenuous claim to our assent. \nWith this in mind, problems in ethical theory choice making reference\nto moral psychology can be framed by two related inquiries: \nThe first question is one of philosophical scholarship: what are the\npsychological commitments of various positions in philosophical\nethics? The second question takes us beyond the corridors of\nphilosophy departments and to the sorts of questions asked, and\nsometimes answered, by the human sciences, including psychology,\nanthropology, sociology, history, cognitive science, linguistics and\nneuroscience. Thus, contemporary moral psychology is\nmethodologically pluralistic: it aims to answer philosophical\nquestions, but in an empirically responsible way. \nHowever, it will sometimes be difficult to tell which claims in\nphilosophical ethics require empirical substantiation. Partly, this is\nbecause it is sometimes unclear whether, and to what extent, a\ncontention counts as empirically assessable. Consider questions\nregarding “normal functioning” in mental health care: are\nthe answers to these questions statistical, or evaluative (Boorse\n1975; Fulford 1989; Murphy 2006)? For example, is “normal”\nmental health simply the psychological condition of most people, or is\nit good mental health? If the former, the issue is, at least\nin principle, empirically decidable. If the latter, the issues must be\ndecided, if they can be decided, by arguments about value. \nAdditionally, philosophers have not always been explicit about\nwhether, and to what extent, they are making empirical claims. For\nexample, are their depictions of moral character meant to identify\npsychological features of actual persons, or to articulate ideals that\nneed not be instantiated in actual human psychologies? Such questions\nwill of course be complicated by the inevitable diversity of\nphilosophical opinion. \nIn every instance, therefore, the first task is to carefully document\na theory’s empirically assessable claims, whether they are\nexplicit or, as may often be the case, tacit. Once claims apt for\nempirical assessment have been located, the question becomes one of\nidentifying any relevant empirical literatures. The next job is to\nassess those literatures, in an attempt to determine what conclusions\ncan be responsibly drawn from them. Science, particularly social\nscience, being what it is, many conclusions will be provisional; the\nphilosophical moral psychologist must be prepared to adjudicate\ncontroversies in other fields, or offer informed conjecture regarding\nfuture findings. Often, the empirical record will be crucially\nincomplete. In such cases, philosophers may be forced to engage in\nempirically disciplined conjecture, or even to engage in their own\nempirical work, as some philosophers are beginning to\n do.[2] \nWhen the philosophical positions have been isolated, and putatively\nrelevant empirical literatures assessed, we can begin to evaluate the\nplausibility of the philosophical moral psychology: Is the speculative\npicture of psychological functioning that informs some region of\nethical theory compatible with the empirical picture that emerges from\nsystematic observation? In short, is the philosophical picture\nempirically adequate? If it is determined that the\nphilosophical conception is empirically adequate, the result is\nvindicatory. Conversely, if the philosophical moral\npsychology in question is found to be empirically inadequate,\nthe result is revisionary, compelling alteration, or even\nrejection, of those elements of the philosophical theory presupposing\nthe problematic moral psychology. The process will often be\ncomparative. Theory choice in moral psychology, like other\ntheory choice, involves tradeoffs, and while an empirically\nundersupported approach may not be decisively eliminated from\ncontention on empirical grounds alone, it may come to be seen as less\nattractive than theoretical options with firmer empirical\nfoundations. \nThe winds driving the sort of disciplinary cross-pollination we\ndescribe do not blow in one direction. As philosophers writing for an\nencyclopedia of philosophy, we are naturally concerned with the ways\nempirical research might shape, or re-shape, philosophical ethics. But\nphilosophical reflection may likewise influence empirical research,\nsince such research is often driven by philosophical suppositions that\nmay be more or less philosophically sound. The best interdisciplinary\nconversations, then, should benefit both parties. To illustrate the\ndialectical process we have described, we will consider a variety of\ntopics in moral psychology. Our primary concerns will be\nphilosophical: What are some of the most central problems in\nphilosophical moral psychology, and how might they be resolved?\nHowever, as the hybrid nature of our topic invites us to do, we will\npursue these questions in an interdisciplinary spirit, and are hopeful\nthat our remarks will also engage interested scientists. Hopefully,\nthe result will be a broad sense of the problems and methods that will\nstructure research on moral psychology during the 21st\ncentury. \n“Intuition pumps” or “thought experiments”\nhave long been well-used items in the philosopher’s toolbox\n(Dennett 1984: 17–18; Stuart et al. 2018). Typically, a thought\nexperiment presents an example, often a hypothetical example, in order\nto elicit some philosophically telling response. If a thought\nexperiment is successful, it may be concluded that competing theories\nmust account for the resulting response. These responses are supposed\nto serve an evidential role in philosophical theory choice;\nif you like, they can be understood as data competing\ntheories must\n accommodate.[3]\n If an appropriate audience’s ethical responses to a thought\nexperiment conflict with the response a theory prescribes for the\ncase, the theory has suffered a counterexample. \nThe question of whose responses “count” philosophically\n(or, who is the “appropriate” audience) has been answered\nin a variety of ways, but for many philosophers, the intended audience\nfor thought experiments seems to be some species of “ordinary\nfolk” (see Jackson 1998: 118, 129; Jackson & Pettit 1995:\n22–9; Lewis 1989: 126–9). Of course, the relevant folk\nmust possess such cognitive attainments as are required to understand\nthe case at issue; very young children are probably not an ideal\naudience for thought experiments. Accordingly, some philosophers may\ninsist that the relevant responses are the considered judgments of\npeople with the training required to see “what is at stake\nphilosophically”. But if the responses are to help adjudicate\nbetween competing theories, the responders must be more or less\ntheoretically neutral, and this sort of neutrality is\nrather likely to be vitiated by philosophical education. A dilemma\nemerges. On the one hand, philosophically naïve subjects may be\nthought to lack the erudition required to grasp the philosophical\nstakes. On the other, with increasing philosophical sophistication\ncomes, very likely, philosophical partiality; one audience is\nnaïve, and the other\n prejudiced.[4] \nHowever exactly the philosophically relevant audience is specified,\nthere are empirical questions that must be addressed in determining\nthe philosophical potency of a thought experiment. In particular, when\ndeciding what philosophical weight to give a response, philosophers\nneed to determine its origins. What features of the\nexample are implicated in a given judgment—are people\nreacting to the substance of the case, or the style of exposition?\nWhat features of the audience are implicated in their\nreaction—do different demographic groups respond to the example\ndifferently? Are there factors in the environment that are affecting\npeople’s intuitive judgments? Does the order in which people\nconsider examples affect their judgments? Such questions raise the\nfollowing concern: judgments about thought experiments dealing with\nmoral issues might be strongly influenced by ethically\nirrelevant characteristics of the example or the audience or the\nenvironment or the order of presentation. Whether a characteristic is\nethically relevant is a matter for philosophical discussion, but\ndetermining the status of a particular thought experiment also\nrequires empirical investigation of its causally relevant\ncharacteristics. We’ll now describe some examples of such\ninvestigation. \nAs part of their famous research on the “heuristics and\nbiases” that underlie human reasoning, Tversky and Kahneman\n(1981) presented subjects with the following problem: \nImagine that the U.S. is preparing for the outbreak of an unusual\nAsian disease, which is expected to kill 600 people. Two alternative\nprograms to combat the disease have been proposed. Assume that the\nexact scientific estimate of the consequences of the programs are as\nfollows: \nA second group of subjects was given an identical problem, except that\nthe programs were described as follows: \nOn the first version of the problem, most subjects thought that\nProgram A should be adopted. But on the second version, most chose\nProgram D, despite the fact that the outcome described in A is\nidentical to the one described in C. The disconcerting implication of\nthis study is that ethical responses may be strongly influenced by the\nmanner in which cases are described or framed. It seems that\nsuch framing sensitivities constitute ethically irrelevant influences\non ethical responses. Unless this sort of possibility can be\nconfidently eliminated, one should hesitate to rely on responses to a\nthought experiment for adjudicating theoretical controversies. Such\npossibilities can only be eliminated through systematic empirical\n work.[5] \nWhile a relatively small percentage of empirical work on\n“heuristics and biases” directly addresses moral\nreasoning, numerous philosophers who have addressed the issue\n(Horowitz 1998; Doris & Stich 2005; Sinnott-Armstrong 2005;\nSunstein 2005) agree that phenomena like framing effects are likely to\nbe pervasively implicated in responses to ethically freighted\nexamples, and argue that this state of affairs should cause\nphilosophers to view the thought-experimental method with considerable\nconcern. \nWe turn now to order effects. In a pioneering study, Petrinovich and\nO’Neill (1996) found that participants’ moral intuitions\nvaried with the order in which the thought experiments were presented.\nSimilar findings have been reported by Liao et al. (2012), Wiegman et\nal. (2012), and Schwitzgebel & Cushman (2011, 2015). The\nSchwitzgebel and Cushman studies are particularly striking, since they\nset out to explore whether order effects in moral intuitions were\nsmaller or non-existent in professional philosophers. Surprisingly,\nthey found that professional philosophers were also subject to order\neffects, even though the thought experiments used are well known in\nthe field. Schwitzgebel and Cushman also report that in some cases\nphilosophers intuitions show substantial order effects when the\nintuitions of non-philosophers don’t. \nAudience characteristics may also affect the outcome of thought\nexperiments. Haidt and associates (1993: 613) presented stories about\n“harmless yet offensive violations of strong social norms”\nto men and women of high and low socioeconomic status (SES) in\nPhiladelphia (USA), Porto Alegre, and Recife (both in Brazil). For\nexample: \nA man goes to the supermarket once a week and buys a dead chicken. But\nbefore cooking the chicken, he has sexual intercourse with it. Then he\ncooks it and eats it. (Haidt et al. 1993: 617) \nLower SES subjects tended to “moralize” harmless and\noffensive behaviors like that in the chicken story. These subjects\nwere more inclined than their high SES counterparts to say that the\nactor should be “stopped or punished”, and more inclined\nto deny that such behaviors would be “OK” if customary in\na given country (Haidt et al. 1993: 618–19). The point is not\nthat lower SES subjects are mistaken in their moralization of such\nbehaviors while the urbanity of higher SES subjects represents a more\nrationally defensible response. The difficulty is deciding\nwhich—if any—of the conflicting responses is fit to serve\nas a constraint on ethical theory, when both may equally be the result\nof more or less arbitrary cultural factors. \nPhilosophical audiences typically decline to\nmoralize the offensive behaviors, and we ourselves share their\ntolerant attitude. But of course these audiences—by virtue of\neducational attainments, if not stock portfolios—are\noverwhelmingly high SES. Haidt’s work suggests that it is a\nmistake for a philosopher to say, as Jackson (1998: 32n4; cf. 37)\ndoes, that “my intuitions reveal the folk conception in as much\nas I am reasonably entitled, as I usually am, to regard myself as\ntypical”. The question is: typical of what demographic? Are\nphilosophers’ ethical responses determined by the philosophical\nsubstance of the examples, or by cultural idiosyncrasies that are very\nplausibly thought to be ethically irrelevant? Once again, until such\npossibilities are ruled out by systematic empirical investigation, the\nphilosophical heft of a thought experiment is open to question. \nIn recent years there has been a growing body of research reporting\nthat judgments evoked by moral thought experiments are affected by\nenvironmental factors that look to be completely irrelevant to the\nmoral issue at hand. The presence of dirty pizza boxes and a whiff of\nfart spray (Schnall et al. 2008a), the use of soap (Schnall et al.\n2008b) or an antiseptic handwipe (Zhong et al. 2010), or even the\nproximity of a hand sanitizer dispenser (Helzer & Pizarro 2011)\nhave all been reported to influence moral intuitions. Tobia et al.\n(2013) found that the moral intuitions of both students and\nprofessional philosophers are affected by spraying the questionnaire\nwith a disinfectant spray. Valdesolo and DeSteno (2006) reported that\nviewing a humorous video clip can have a substantial impact on\nparticipant’s moral intuitions. And Strohminger et al. (2011)\nhave shown that hearing different kinds of audio clips (stand-up\ncomedy or inspirational stories from a volume called Chicken Soup\nfor the Soul) has divergent effects on moral intuitions. \nHow should moral theorists react to findings like these? One might, of\ncourse, eschew thought experiments in ethical theorizing. While this\nmethodological austerity is not without appeal, it comes at a cost.\nDespite the difficulties, thought experiments are a window, in some\ncases the only accessible window, into important regions of ethical\nexperience. In so far as it is disconnected from the thoughts and\nfeels of the lived ethical life, ethical theory risks being\n“motivationally inaccessible”, or incapable of engaging\nthe ethical concern of agents who are supposed to live in accordance\nwith the normative standards of the\n theory.[6]\n Fortunately, there is another possibility: continue pursuing the\nresearch program that systematically investigates responses to\nintuition pumps. In effect, the idea is to subject philosophical\nthought experiments to the critical methods of experimental social\npsychology. If investigations employing different experimental\nscenarios and subject populations reveal a clear trend in responses,\nwe can begin to have some confidence that we are identifying a deeply\nand widely shared moral conviction. Philosophical discussion may\nestablish that convictions of this sort should serve as a constraint\non moral theory, while responses to thought experiments that empirical\nresearch determines to lack such solidity, such as those susceptible\nto order, framing or environmental effects, or those admitting of\nstrong cultural variation, may be ones that ethical theorists can\nsafely disregard.  \nA philosophically informed empirical research program akin to the one\njust described is more than a methodological fantasy. This approach\naccurately describes a number of research programs aimed at informing\nphilosophical debates through interdisciplinary research. \nOne of the earliest examples of this kind of work was inspired in\nlarge part by the work of Knobe (2003a,b, 2006) and addressed\nquestions surrounding “folk morality” on issues ranging\nfrom intentional action to causal responsibility (see Knobe 2010 for\nreview and discussion). This early work helped to spur the development\nof a truly interdisciplinary research program with both philosophers\nand psychologists investigating the folk morality of everyday life.\n(See the Stanford Encyclopedia of Philosophy article on\nExperimental Moral Philosophy for a more complete treatment of this\nresearch.) \nAnother related philosophical debate concerns the compatibility of\nfree will and moral responsibility with determinism. On the one hand,\nincompatibilists insist that determinism (the view that all events are\njointly determined by antecedent events as governed by laws of\nnature), is incompatible with moral responsibility.\nTypically, these accounts also go on to specify what particular\ncapacity is required to be responsible for one’s own behavior\n(e.g., that agents have alternate possibilities for behavior, or are\nthe “ultimate” source of their behavior, or both (Kane\n2002: 5; Haji 2002:\n 202–3).[7]\n On the other hand, compatibilists argue that determinism and\nresponsibility are compatible, often by denying that\nresponsible agency requires that the actor have genuinely open\nalternatives, or rejecting the ultimacy condition that requires\nindeterminism (or impossible demands for self-creation). In short,\ncompatibilists hold that people may legitimately be held responsible\neven though there is some sense in which they “could not have\ndone otherwise” or are not the “ultimate source” of\ntheir behavior. Incompatibilists deny that this is the case.\nProponents of these two opposing positions have remained relatively\nentrenched, and some participants have raised fears of a\n“dialectical stalemate” (Fischer 1994: 83–5). \nA critical issue in these debates has been the claim that the\nincompatibilist position better captures folk moral judgments about\nagents whose actions have been completely determined (e.g., G.\nStrawson 1986: 88; Smilansky 2003: 259; Pereboom 2001: xvi;\nO’Connor 2000: 4; Nagel 1986: 113, 125; Campbell 1951: 451; Pink\n2004: 12). For example, Robert Kane (1999: 218; cf. 1996: 83–5),\na leading incompatibilist, reports that in his experience “most\nordinary persons start out as natural incompatibilists”, and\n“have to be talked out of this natural incompatibilism by the\nclever arguments of philosophers”. \nUnsurprisingly, some compatibilists have been quick to assert the\ncontrary. For example, Peter Strawson (1982) famously argued that in\nthe context of “ordinary interpersonal relationships”,\npeople are not haunted by the specter of determinism; such\nmetaphysical concerns are irrelevant to their experience and\nexpression of the “reactive attitudes”—anger,\nresentment, gratitude, forgiveness, and the like—associated with\nresponsibility assessment. Any anxiety about determinism, Strawson\ninsisted, is due to the “panicky metaphysics” of\nphilosophers, not incompatibilist convictions on the part of ordinary\npeople. However, incompatibilists have historically been thought to\nhave ordinary intuitions on their side; even some philosophers with\ncompatibilist leanings are prepared to concede the incompatibilist\npoint about “typical” response tendencies (e.g., Vargas\n2005a,b). \nNeither side, so far as we are aware, has offered much in the way of\nsystematic evidence of actual patterns of folk moral judgments.\nRecently however, a now substantial research program has begun to\noffer empirical evidence on the relationship between determinism and\nmoral responsibility in folk moral judgments. \nInspired by the work of Frankfurt (1988) and others, Woolfolk, Doris,\nand Darley (2006) hypothesized that observers may hold actors\nresponsible even when the observers judge that the actors could not\nhave done otherwise, if the actors appear to “identify”\nwith their behavior. Roughly, the idea is that the actor identifies\nwith a behavior—and is therefore responsible for it—to the\nextent that she “embraces” the behavior, or performs it\n“wholeheartedly” regardless of whether genuine\nalternatives for behavior are\n possible.[8]\n Woolfolk et al.’s suspicion was, in effect, that people’s\n(presumably tacit) theory of responsibility is compatibilist. \nTo test this, subjects were asked to read a story about an agent who\nwas forced by a group of armed hijackers to kill a man who had been\nhaving an affair with his wife. In the “low\nidentification” condition, the man was described as being\nhorrified at being forced to kill his wife’s lover, and as not\nwanting to do so. In the “high identification” condition,\nthe man is instead described as welcoming the opportunity and wanting\nto kill his wife’s lover. In both cases, the man is not given a\nchoice, and does kill his wife’s lover. \nConsistent with Woolfolk and colleagues’ hypothesis, subjects\njudged that the highly identifying actor was more responsible, more\nappropriately blamed, and more properly subject to guilt than the low\nidentification\n actor.[9]\n This pattern in folk moral judgments seems to suggest that\nparticipants were not consistently incompatibilist in their\nresponsibility attributions, because the lack of alternatives\navailable to the actor was not alone sufficient to rule out such\nattributions. \nIn response to these results, those who believe that folk morality is\nincompatibilist may be quick to object that the study merely suggests\nthat responsibility attributions are influenced by identification, but\nsays nothing about incompatibilist commitments or the lack thereof.\nSubjects still may have believed that the actor could have done\notherwise. To address this concern, Woolfolk and colleagues also\nconducted a version of the study in which the man acted under the\ninfluence of a “compliance drug”. In this case,\nparticipants were markedly less likely to agree that the man\n“was free to behave other than he did” and yet they still\nheld the agent who identified with the action as more responsible than\nthe agent who did not. These results look to pose a clear challenge to\nthe view that ordinary folk are typically incompatibilists. \nA related pattern of responses was obtained by Nahmias, Morris,\nNadelhoffer and Turner (2009) who instead described agents preforming\nimmoral behaviors in a “deterministic world” of the sort\noften described in philosophy classrooms. One variation read as\nfollows: \nImagine that in the next century we discover all the laws of nature,\nand we build a supercomputer which can deduce from these laws of\nnature and from the current state of everything in the world exactly\nwhat will be happening in the world at any future time. It can look at\neverything about the way the world is and predict everything about how\nit will be with 100% accuracy. Suppose that such a supercomputer\nexisted, and it looks at the state of the universe at a certain time\non March 25th, 2150 C.E., twenty years before Jeremy Hall is born. The\ncomputer then deduces from this information and the laws of nature\nthat Jeremy will definitely rob Fidelity Bank at 6:00 PM on January\n26th, 2195. As always, the supercomputer’s prediction is\ncorrect; Jeremy robs Fidelity Bank at 6:00 PM on January 26th,\n2195. \nSubjects were then asked whether Jeremy was morally blameworthy. Most\nsaid yes, indicating that they thought an agent could be morally\nblameworthy even if his behaviors were entirely determined by natural\nlaws. Consistent with the Woolfolk et al. results, it appears that the\nsubjects’ judgments, at least those having to do with moral\nblameworthiness, were not governed by a commitment to\nincompatibilism. \nThis emerging picture was complicated, however, by Nichols and Knobe\n(2007), which argued that the ostensibly compatibilist responses were\nperformance errors driven by an affective response to the\nagents’ immoral actions. To demonstrate this, all subjects were\nasked to imagine two universes—a universe completely governed by\ndeterministic laws (Universe A) and a universe (Universe B) in which\neverything is determined except for human decisions which are not\ncompletely determined by deterministic laws and what has happened in\nthe past. In Universe B, but not Universe A, “each human\ndecision does not have to happen the way it does”. Some\nsubjects were assigned to a concrete condition, and asked to make a\njudgment about a specific individual in specific circumstances, while\nothers were assigned to an abstract condition, and asked to make a\nmore general judgment, divorced from any particular individual. The\nhypothesis was that the difference between these two conditions would\ngenerate different responses regarding the relationship between\ndeterminism and moral responsibility. Subjects in the concrete\ncondition read a story about a man, “Bill”, in the\ndeterministic universe who murders his wife and children in a\nparticularly ghastly manner, and were asked whether Bill was morally\nresponsible for what he had done. By contrast, subjects in the\nabstract condition were asked “In Universe A, is it possible for\na person to be fully morally responsible for their actions?”\nSeventy-two percent of subjects in the concrete condition gave a\ncompatibilist response, holding Bill responsible in Universe A,\nwhereas less than fifteen percent of subjects in the abstract\ncondition gave a compatibilist response, allowing that people could be\nfully morally responsible in the deterministic Universe A. \nIn line with previous experimental work demonstrating that increased\naffective arousal amplified punitive responses to wrongdoing (Lerner,\nGoldberg, & Tetlock 1998), Nichols and Knobe hypothesized that\npreviously observed compatibilist responses were the result of the\naffectively laden nature of the stimulus materials. When this\naffective element was eliminated from the materials (as in the\nabstract condition), participants instead exhibited an incompatibilist\npattern of responses. \nMore recently, Nichols and Knobe’s line of reasoning has come\nunder fire from two directions. First, a number of studies have now\ntried to systematically manipulate how affectively arousing the\nimmoral behavior performed is, but have not found that these changes\nsignificantly alter participants’ judgments of moral\nresponsibility in deterministic scenarios. Rather, the differences\nseem to be best explained simply by whether the case was described\nabstractly or concretely (see Cova et al. 2012 for work with patients\nwho have frontotemporal dementia, and see Feltz & Cova 2014 for a\nmeta-analysis). Second, a separate line of studies from Murray and\nNahmias (2014) argued that participants who exhibited the apparently\nincompatibilist pattern of responses were making a critical error in\nhow they understood the deterministic scenario. In particular, they\nargued these participants mistakenly took the agents, or their mental\nstates, in these deterministic scenarios to be “bypassed”\nin the causal chain leading up to their behavior. In support of their\nargument, Murray and Nahmias (2014) demonstrated that when analyses\nwere restricted to the participants who clearly did not take the agent\nto be bypassed, these participants judged the agent to be morally\nresponsible (blameworthy, etc.) despite being in a deterministic\nuniverse. Unsurprisingly, this line of argument has, in turn, inspired\na number of further counter-responses, both empirical (Rose &\nNichols 2013) and theoretical (Björnsson & Pereboom 2016),\nwhich caution against the conclusions of Murray and Nahmias. \nWhile the debate continues over whether the compatibilist or\nincompatibilist position better captures folk moral judgments of\nagents in deterministic universes, a related line of research has\nsprung up around what is widely taken to be the most convincing\ncontemporary form of argument for incompatibilism: manipulation\narguments (e.g., Mele 2006, 2013, Pereboom 2001, 2014).\nPereboom’s Four-Case version, for example, begins with the case\nof an agent named Plum who is manipulated by neuroscientists who use a\nradio-like technology to change Plum’s neural states, which\nresults in him wanting and then deciding to kill a man named White. In\nthis case, it seems clear that Plum did not freely decide to kill\nWhite. Compare this case to a second one, in which the team of\nneuroscientists programmed Plum at the beginning of his life in a way\nthat resulted in him developing the desire (and making the decision)\nto kill White. The incompatibilist argues that these two cases do not\ndiffer in a way that is relevant for whether Plum acted freely, and\nso, once again, it seems that Plum did not freely decide to kill\nWhite. Now compare this to a third case, in which Plum’s desire\nand decision to kill White were instead determined by his cultural and\nsocial milieu, rather than by a team of neuroscientists. Since the\nonly difference between the second and third case is the particular\ntechnological process through which Plum’s mental states were\ndetermined, he would again seem to not have freely decided to kill\nWhite. Finally, in a fourth and final case, Plum’s desire and\ndecision to kill White was determined jointly by the past states and\nthe laws of nature in our own deterministic universe. Regarding these\nfour cases, Pereboom argues that, since there is no difference between\nany of the four cases that is relevant to free will, if Plum was not\nmorally responsible in the first case, then he was not morally\nresponsible in the fourth. \nIn response to this kind of manipulation-based argument for\nincompatibilism, a number of researchers have taken aim at painting a\nbetter empirical picture of ordinary moral judgments concerning\nmanipulated agents. This line of inquiry has been productive on two\nlevels. First, a growing number of empirical studies have investigated\nmoral responsibility judgments about cases of manipulation, and now\nprovide a clearer psychological picture for why manipulated agents are\njudged to lack free will and moral responsibility. Second, continuing\ntheoretical work, informed by this empirical picture, has provided new\nreasons for doubting that manipulation based arguments actually\nprovide evidence against compatibilism. \nOne line of empirical research, led by Chandra Sripada (2012) has\nasked whether manipulated agents are perceived to be unfree because\n(a) they lack ultimate control over their actions (a capacity\nincompatibilists take to be essential for moral responsibility) or\ninstead because (b) their psychological or volitional capacities (the\ncapacities focused on by compatibilists) have been damaged. Using a\nstatistical approach called Structural Equation Modeling (or SEM),\nSripada found that participants’ moral responsibility judgments\nwere best explained by whether they believed the psychological and\nvolitional capacities of the agent were damaged by manipulation and\nnot whether the agent lacked control over her actions. This finding\nsuggests that patterns of judgment in cases of manipulation are more\nconsistent with the predictions of compatibilism than with\nincompatibilism. \nTaking a different approach, Phillips and Shaw (2014) demonstrated\nthat the reduction of moral responsibility that is typically observed\nin cases of manipulation depends critically on the role of an\nintentional manipulator. In particular, ordinary people were\nshown to distinguish between (1) the moral responsibility of agents\nwho are made to do a particular act by features of the situation they\nare in (i.e., situational determinism), and (2) the moral\nresponsibility of agents who are made to do that same act by another\nintentional agent (i.e., manipulation). This work suggests that the\nordinary practice of assessing freedom and responsibility is likely to\nclearly distinguish between cases that do and do not involve a\nmanipulator who intervenes with the intention of causing the\nmanipulated agent to do the immoral action. A series of studies by\nMurray and Lombrozo (2016) further elaborates these findings by\nproviding evidence that the specific reduction of moral responsibility\nthat results from being manipulated arises from the perception that\nthe agent’s mental states are bypassed. \nCollectively, two lessons have come out of this work on the ordinary\npractice of assessing the moral responsibility of manipulated agents:\n(1) folk morality provides a natural way of distinguishing between the\ndifferent cases used in manipulation-based arguments (those that do\ninvolve the intentional intervention of a manipulator vs. those that\ndon’t) and (2) folk morality draws an intimate link between the\nmoral responsibility of an agent and that agent’s mental and\nvolitional capacities. Building on this increasingly clear empirical\npicture, Deery and Nahmias (2017) formalized these basic principles in\ntheoretical work that argues for a principled way of distinguishing\nbetween the moral responsibility of determined and manipulated\nagents. \nWhile the majority of evidence may currently be in favor of the view\nthat folk morality adheres to a kind of “natural\ncompatibilism” (Cova & Kitano 2013), this remains a\ncontentious topic, and new work is continually emerging on both sides\nof the debate (Andow & Cova 2016; Bear & Knobe 2016;\nBjörnsson 2014; Feltz & Millan 2013; Figdor & Phelan\n2015; Knobe 2014). One thing that has now been agreed on by parties on\nboth sides of this debate, however, is a critical role for careful\nempirical studies (Björnsson & Pereboom 2016; Knobe 2014;\nNahmias 2011). \nTo date, empirically informed approaches to moral psychology have been\nmost prominent in discussions of moral character and virtue. The focus\nis decades of experimentation in “situationist” social\npsychology: unobtrusive features of situations have repeatedly been\nshown to impact behavior in seemingly arbitrary, and sometimes\nalarming, ways. Among the findings that have most interested\nphilosophers: \nThese experiments are part of an extensive empirical literature,\nwhere social psychologists have time and again found that\ndisappointing omissions and appalling actions are readily induced by\napparently minor situational\n features.[10]\n The striking fact is not that people fail standards for good conduct,\nbut that they can be so easily induced to do so. \nExploiting this observation, “character skeptics” contend\nthat if moral conduct varies so sharply, often for the worse, with\nminor perturbations in circumstance, ostensibly good character\nprovides very limited assurance of good conduct. In addition to this\nclaim in descriptive psychology, concerning the fragility of\nmoral character, some character skeptics also forward a thesis in\nnormative ethics, to the effect that character merits less\nattention in ethical thought than it traditionally\n gets.[11] \nCharacter skepticism contravenes the influential program of\ncontemporary virtue ethics, which maintains that advancing\nethical theory requires more attention to character, and\nvirtue ethicists offer vigorous\n resistance.[12]\n Discussion has sometimes been overheated, but it has resulted in a\nlarge literature in a vibrantly interdisciplinary field of\n“character studies” (e.g., Miller et al.\n 2015).[13]\n The literature is too extensive for the confines of this entry, but\nwe will endeavor to outline some of the main issues.  \nThe first thing to observe is that the science which inspires the\ncharacter skeptics may itself be subject to skepticism. Given the\nuneven history of the human sciences, it might be argued that the\nrelevant findings are too uncertain to stand as a constraint on\nphilosophical theorizing. This contention is potentially buttressed by\nrecent prominent replication failures in social psychology.  \nThe psychology at issue is, like much of science, unfinished business.\nBut the replication controversy, and the attendant suspicion of\nscience, is insufficient grounds for dismissing the psychology out of\nhand. Philosophical conclusions should not be based on a few studies;\nthe task of the philosophical consumer of science is to identify\ntrends in convergent strands of evidence (Doris\n2015: 49, 56; Machery & Doris forthcoming). The observation that\nmotivates character skepticism—the surprising situational\nsensitivity of behavior—is supported by a wide range of\nscientific findings, as well as by recurring themes in history and\nbiography (Doris 2002, 2005). The strong situational\ndiscriminativeness of behavior is accepted as fact by high proportion\nof involved scientists; accordingly, it is not much contested in\ndebates about character skepticism. \nBut the philosophical implications of this fact remain, after\nconsiderable debate, a contentious issue. The various responses to\ncharacter skepticism need not be forwarded in isolation, and some of\nthem may be combined as part of a multi-pronged defense. Different\nrejoinders have differing strengths and weaknesses, particularly with\nrespect to the differing pieces of evidence on which character\nskeptics rely; the phenomena are not unitary, and accommodating them\nall may preclude a unitary response.  \nOne way of defusing empirically motivated skepticism—dubbed by\nAlfano (2013) “the dodge”—is simply to deny that\nvirtue ethics makes empirical claims. On this understanding, virtue\nethics is cast as a “purely normative” endeavor aiming at\nerecting ethical ideals in complete absence of empirical commitments\nregarding actual human psychologies. This sort of purity is perhaps\nless honored than honored in the breach: historically, virtue ethics\nhas been typified by an interest in how actual people become\ngood. Aristotle (Nicomachean Ethics, 1099b18–19)\nthought that anyone not “maimed” with regard to the\ncapacity for virtue may acquire it “by a certain kind of study\nand care”, and contemporary Aristotelians have emphasized the\nimportance of moral education and development (e.g., Annas 2011). More\ngenerally, virtue-based approaches have been claimed to have an\nadvantage over major Kantian and consequentialist competitors with\nrespect to “psychological realism”—the advantage of\na more lifelike moral psychology (see Anscombe 1958: 1, 15; Williams\n1985; Flanagan 1991: 182; Hursthouse 1999: 19–20).  \nTo be sure, eschewing empirical commitment allows virtue ethics to\nescape empirical threat: obviously, empirical evidence cannot be used\nto undermine a theory that makes no empirical claims.\nHowever, it is not clear such theories could claim advantages\ntraditionally claimed for virtue theories with regard to moral\ndevelopment and psychological realism. In any event, they are not\ncontributions to empirical moral psychology, and needn’t be\nfurther discussed here. \nBefore seeing how the debate in moral psychology might be advanced, it\nis necessary to correct a mischaracterization that serves to arrest\nprogress. It is too often said, particularly in reference to Doris\n(1998, 2002) and Harman (1999, 2000), that character skepticism comes\nto the view that character traits “do not exist” (e.g.,\nFlanagan 2009: 55). Frequently, this attribution is made without\ndocumentation, but when documentation is provided, it is typically in\nreference to some early, characteristically pointed, remarks of Harman\n(e.g., 1999). Yet in his most recent contribution, Harman (2009: 241)\nsays, “I do not think that social psychology demonstrates there\nare no character traits”. For his part, Doris has repeatedly\nasserted that traits exist, and has repeatedly drawn attention to such\nassertions (Doris 1998: 507–509; 2002: 62–6; 2005: 667;\n2010: 138–141; Doris & Stich 2005: 119–20; Doris &\nPrinz 2009).  \nWith good reason, to say “traits do not exist” is\ntantamount to denying that there are individual dispositional\ndifferences, an unlikely view that character skeptics and antiskeptics\nare united in rejecting. Quite unsurprisingly, this unlikely view is\nseriously undersubscribed in both philosophy and psychology. It is\nendorsed by neither the most aggressive critics of personality,\nsituationists in social psychology such as Ross and Nisbett (1991),\nnor by the patron saint of situationism in personality psychology:\nMischel (1999: 45). Mischel disavows a trait-based approach, but his\nskepticism concerns a particular approach to traits, not\nindividual dispositional differences more generally.  \nThen the question of whether or not traits exist is emphatically\nnot the issue dividing more and less skeptical approaches to\ncharacter. Today, all mainstream parties to the debate are\n“interactionist”, treating behavioral outcomes as the\nfunction of a (complex) person by situation interaction (Mehl et al.\n2015)—and it’s likely most participants have always been\nso (Doris 2002: 25–6). Contemporary research programs in\npersonality and social psychology freely deploy both personal\nand situational variables (e.g., Cameron, Payne, & Doris 2013;\nLeikas, Lönnqvist, & Verkasalo 2012; Sherman, Nave, &\nFunder 2010). The issue worth discussing is not whether individual\ndispositional differences exist, but how these differences should\nbe characterized, and how (or whether) these individual\ndifferences, when appropriately characterized, should inform\nethical thought.  \nAn important feature of early forays into character skepticism was\nthat skeptics tended to focus on behavioral implications of\ntraits rather than the psychological antecedents of behavior\n(Doris 2015: 15). Defenders of virtue ethics observe that character\nskeptics have had much to say about situational variation in behavior\nand little to say about the psychological processes underlying it,\nwith the result that they overlook the rational order in\npeople’s lives (Adams 2006: 115–232). These virtue\nethicists maintain that the behavioral variation provoking character\nskepticism evinces not unreliability, but rationally appropriate\nsensitivity to differing situations (Adams 2006; Kamtekar 2004). The\nvirtuous person, such as Aristotle’s exemplary\nphronimos (“man of practical wisdom”) may\nsometimes come clean, and sometimes dissemble, or sometimes fight, and\nsometimes flee, depending on the particular ethical demands of his\ncircumstances. \nFor example, in the Good Samaritan Study, the hurried passersby was on\nthe way to an appointment where they had agreed to give a\npresentation; perhaps these people made a rational\ndetermination—perhaps even an ethically defensible\ndetermination—to weigh the demands of punctuality and\nprofessionalism over ethical requirement to check on the welfare of a\nstranger in apparent distress. However attractive one finds such\naccounting for this case (note that some of Darley and Batson’s\n[1973] hurried passersby failed to notice the victim, which strains\nexplanations in terms of their rational discriminations), there are\nother cases where the “rationality response” seems plainly\nunattractive. These are cases of ethically irrelevant influences\n (Sec. 2 above;\n Doris & Stich 2005), where it seems unlikely the influence could\nbe cited as part of a rationalizing explanation of the behavior:\nit’s odd to cite failing to find a dime as\njustification for failing to help—or for that matter,\nfinding a dime as justification for doing so. \nIt is certainly appropriate for virtue ethicists to emphasize\npractical rationality in their accounts of character. This is a\ncentral theme in the tradition going back to Aristotle himself, who is\nprobably the most oft-cited canonical philosopher in contemporary\nvirtue ethics. But while the rationality response may initially\naccommodate some of the troubling behavioral evidence, it encounters\nfurther empirical difficulty. There is an extensive empirical\nliterature problematizing familiar conceptions of rationality:\npsychologists have endlessly documented a dispiriting range of\nreasoning errors (Baron 1994, 2001; Gilovich et al. 2002; Kahneman et\nal. 1982; Tversky & Kahneman 1973; Kruger & Dunning 1999;\nNisbett & Borgida 1975; Nisbett & Ross 1980; Stich 1990;\nTversky & Kahneman 1981). In light of this evidence, character\nskeptics claim that the vagaries afflicting behavior also afflict\nreasoning (Alfano 2013; Olin & Doris 2014).  \nResearch supporting this discouraging assessment of human rationality\nis controversial, and not all psychologists think things are so bleak\n(Gigerenzer 2000; Gigerenzer et al. 1999; for philosophical commentary\nsee Samuels & Stich 2002). Nevertheless, if virtue ethics is to\nhave an empirically credible moral psychology, it needs to account for\nthe empirical challenges to practical reasoning: how can the relevant\nexcellence in practical reasoning be developed?  \nFaced with the challenge to practical rationality, virtue ethicists\nmay respond that their theories concern excellent reasoning,\nnot the ordinary reasoning studied in psychology. Practical\nwisdom, and the ethical virtue it supports, are expected to be\nrare, and not widely instantiated. This state of affairs, it\nis said, is quite compatible with the disturbing, but not\nexceptionlessly disturbing, behavior in experiments like\nMilgram’s (see Athanassoulis 1999: 217–219; DePaul 1999;\nKupperman 2001: 242–3). If this account is supposed to be part\nof an empirically contentful moral psychology, rather than unverified\nspeculation, we require a detailed and empirically substantiated\naccount of how the virtuous few get that way—remember that an\nemphasis on moral development is central to the virtue ethics\ntradition. Moreover, if virtue ethics is supposed to have widespread\npractical implications—as opposed to being merely a celebration\nof a tiny “virtue elite”—it should have an account\nof how the less-than-virtuous-many may at least tolerably\napproximate virtue.  \nThis point is underscored by the fact that for some of the troubling\nevidence, as in the Stanford Prison Study, the worry is not so much\nthat people fail standards of virtue, but that they fail standards of\nminimal decency. Surely an approach to ethics that celebrates\nmoral development, even one that acknowledges (or rather, insists)\nthat most people will not attain its ideal, might be expected to have\nan account of how people can become minimally decent. \nRecently, proponents of virtue ethics have been increasingly proposing\na suggestive solution to this problem: virtue is a skill acquired\nthrough effortful practice, so virtue is a kind of expertise (Annas\n2011; Bloomfield 2000, 2001, 2014; Jacobson 2005; Russell 2015; Snow\n2010; Sosa 2009; Stichter 2007, 2011; for reservations, see Doris, in\npreparation). The virtuous are expert at morality and—given the\nAristotelian association of virtue and happiness—expert at life.\n \nAn extensive scientific literature indicates that developing expert\nskill requires extensive preparation, whether the practitioner is a\nnovelist, doctor, or chess master—around 10,000 hours of\n“deliberate practice”, according to a popular\ngeneralization (Ericsson 2014; Ericsson et al. 1993). The\n“10,000–hour rule” is likely an oversimplification,\nbut there is no doubt that attaining expertise requires intensive\ntraining. Because of this, people rarely achieve eminence in more than\none area; for instance, “baseball trivia” experts display\nsuperior recall for baseball-related material, but not for\nnon-baseball material (Chiesi et al. 1979). Conversely, becoming\nexpert at morality, or (even more ambitiously) expert at the whole of\nlife, would apparently require a highly generalized form of\nexpertise: to be good, there’s a lot to be good at.\nMoreover, it’s quite unclear what deliberate practice at life\ninvolves; how exactly does one get better at being good?  \nOne obvious problem concerns specifying the “good” in\nquestion. Expertises like chess have been effectively studied in part\nbecause there are accepted standards of excellence (the\n“ELO” score used for ranking chess players; Glickman\n1995). To put it blithely, there aren’t any chess skeptics. But\nthere have, historically, been lots of moral skeptics. And if\nthere’s not moral knowledge, how could there be moral experts?\nAnd even if there are moral experts, there’s the problem of how\nare they to be identified, since it is not clear we are possessed of\nstandard independent of expert opinion itself (like winning chess\nmatches) for doing so (for the “metaethics of expertise”,\nsee McGrath 2008, 2011). \nEven if these notorious philosophical difficulties can be\nresolved—as defenders of expertise approaches to virtue must\nthink they can—matters remain complicated, because if moral\nexpertise is like other expertises, practice alone—assuming we\nhave a clear notion of what “moral practice”\nentails—will be insufficient. While practice matters in\nattaining expertise, other factors, such as talent, also matter\n(Hambrick et al. 2014; Macnamara et al. 2014). And some of the\nrequired endowments may be quite unequally distributed across\npopulations: practice cannot make a jockey into an NFL lineman, or an\nNFL lineman into a jockey.  \nWhat are the natural endowments required for moral expertise, and how\nwidely are they distributed in the population? If they are rare, like\nthe skill of a chess master or the strength of an NFL lineman, virtue\nwill also be rare. Some virtue ethicists believe virtue should be\nwidely attainable, and they will resist this result (Adams 2006:\n119–123, and arguably Aristotle Nicomachean Ethics\n1099b15–20). But even virtue ethicists who embrace the rarity of\nvirtue require an account of what the necessary natural endowments\nare, and if they wish to also have an account of how the less\nwell-endowed may achieve at least minimal decency, they should have\nsomething to say about how moral development will proceed across a\npopulation with widely varying endowments. \nWhat is needed, for the study of moral character research to advance,\nis an account of the biological, psychological, and social factors\nrequisite for successful moral development—on the expertise\nmodel, the conditions conducive to developing “moral\nskill”. This, quite obviously, is a tall order, and the research\nneeded to systematically address these issue is in comparative\ninfancy. Yet the expertise model, in exploiting connections with areas\nin which skill acquisition has been well studied, such as music and\nsport, provides a framework for moving discussion of character beyond\nthe empirically under-informed conjectures and assumptions about\n“habituation” that have been too frequent in previous\nliterature (Doris 2015: 128). \nPeople often behave in ways that benefit others, and they sometimes do\nthis knowing that it will be costly, unpleasant or dangerous. But at\nleast since Plato’s classic discussion in the second Book of the\nRepublic, debate has raged over why people behave in\nthis way. Are their motives altruistic, or is their behavior\nultimately motivated by self-interest? Famously, Hobbes gave this\nanswer: \nNo man giveth but with intention of good to himself, because gift is\nvoluntary; and of all voluntary acts, the object is to every man his\nown good; of which, if men see they shall be frustrated, there will be\nno beginning of benevolence or trust, nor consequently of mutual help.\n(1651 [1981: Ch. 15]) \nViews like Hobbes’ have come to be called\n egoism,[14]\n and this rather depressing conception of human motivation has any\nnumber of eminent philosophical advocates, including Bentham, J.S.\nMill and\n Nietzsche.[15]\n Dissenting voices, though perhaps fewer in number, have been no less\neminent. Butler, Hume, Rousseau and Adam Smith have all argued that,\nsometimes at least, human motivation is genuinely altruistic. \nThough the issue that divides egoistic and altruistic accounts of\nhuman motivation is largely empirical, it is easy to see why\nphilosophers have thought that the competing answers will have\nimportant consequences for moral theory. For example, Kant famously\nargued that a person should act “not from inclination but from\nduty, and by this would his conduct first acquire true moral\nworth” (1785 [1949: Sec. 1, parag. 12]). But egoism maintains\nthat all human motivation is ultimately self-interested, and\nthus people can’t act “from duty” in the\nway that Kant urged. Thus if egoism is true, Kant’s account\nwould entail that no conduct has “true moral worth”.\nAdditionally, if egoism is true, it would appear to impose a strong\nconstraint on how a moral theory can answer the venerable question\n“Why should I be moral?” since, as Hobbes clearly saw, the\nanswer will have to ground the motivation to be moral in the\nagent’s\n self-interest.[16] \nWhile the egoism vs. altruism debate has historically been of great\nphilosophical interest, the issue centrally concerns psychological\nquestions about the nature of human motivation, so it’s not\nsurprise that psychologists have done a great deal of empirical\nresearch aimed at determining which view is correct. Some of the most\ninfluential and philosophically sophisticated empirical work on this\nissue has been done by Daniel Batson and his associates. The\nconclusion Batson draws from this work is that people do\nsometimes behave altruistically, and that the emotion of empathy plays\nan important role in generating altruistic motivation.\n [17]\n Others are not convinced. For a discussion of Batson’s\nexperiments, the conclusion he draws from them, and some reasons for\nskepticism about that conclusion, see sections 5 and 6 of the entry\n“Empirical Approaches to Altruism” in this encyclopedia.\nIn this section, we’ll focus on some of the philosophical\nspadework that is necessary before plunging into the empirical\nliterature. \nA crucial question that needs to be addressed is: What, exactly, is\nthe debate about; what is altruism? Unfortunately, there is\nno uncontroversial answer to this question, since researchers in many\ndisciplines, including philosophy, biology, psychology, sociology,\neconomics, anthropology and primatology, have written about altruism,\nand authors in different disciplines tend to use the term\n“altruism” in quite different ways. Even among\nphilosophers the term has been used with importantly different\nmeanings. There is, however, one account of altruism—actually a\ncluster closely related accounts—that plays a central role both\nin philosophy and in a great deal of psychology, including\nBatson’s work. We’ll call it “the standard\naccount”. That will be our focus in the remainder of this\n section.[18] \nAccording to the standard account, an action is altruistic if it is\nmotivated by an ultimate desire for the well-being of another person.\nThis formulation invites questions about (1) what it is for a behavior\nto be motivated by an ultimate desire, and (2) the\ndistinction between desires that are self-interested and\ndesires that are for the well-being of others. \nAlthough the second question will need careful consideration in any\ncomprehensive treatment, a few rough and ready examples of the\ndistinction will suffice\n here.[19]\n Desires to save someone else’s life, to alleviate someone\nelse’s suffering, or to make someone else happy are paradigm\ncases of desires for the well-being of others, while desires to\nexperience pleasure, get rich, and become famous are typical examples\nof self-interested desires. The self-interested desires to experience\npleasure and to avoid pain have played an especially prominent role in\nthe debate, since one version of egoism, often called\nhedonism, maintains that these are our only ultimate\ndesires. \nThe first question, regarding ultimate desires, requires a fuller\nexposition; it can be usefully explicated with the help of a familiar\naccount of practical\n reasoning.[20]\n On this account, practical reasoning is a causal process via which a\ndesire and a belief give rise to or sustain another desire. For\nexample, a desire to drink an espresso and a belief that the best\nplace to get an espresso is at the espresso bar on Main Street may\ncause a desire to go to the espresso bar on Main Street. This desire\ncan then join forces with another belief to generate a third desire,\nand so on. Sometimes this process will lead to a desire to perform a\nrelatively simple or “basic” action, and that desire, in\nturn, will cause the agent to perform the basic action without the\nintervention of any further desires. Desires produced or sustained by\nthis process of practical reasoning are instrumental\ndesires—the agent has them because she thinks that satisfying\nthem will lead to something else that she desires. But not\nall desires can be instrumental desires. If we are to avoid\ncircularity or an infinite regress there must be some desires that are\nnot produced because the agent thinks that satisfying them\nwill facilitate satisfying some other desire. These desires that are\nnot produced or sustained by practical reasoning are the agent’s\nultimate desires, and the objects of ultimate desires, the\nstates of affairs desired, are desired for their own sake. A behavior\nis motivated by a specific ultimate desire when that desire\nis part of the practical reasoning process that leads to the\nbehavior. \nIf people do sometimes have ultimate desires for the well-being of\nothers, and these desires motivate behavior, then altruism is the\ncorrect view, and egoism is false. However, if all ultimate\ndesires are self-interested, then egoism is the correct view, and\naltruism is false. The effort to establish one or the other of these\noptions has given rise to a vast and enormously sophisticated\nempirical literature. For an overview of that literature, see the\n empirical approaches to altruism entry. \nGiven that moral disagreement—about abortion, say, or capital\npunishment—so often seems intractable, is there any reason to\nthink that moral problems admit objective resolutions? While this\ndifficulty is of ancient coinage, contemporary philosophical\ndiscussion was spurred by Mackie’s (1977: 36–8)\n“argument from relativity” or, as it is called by later\nwriters, the “argument from disagreement” (Brink 1989:\n197; Loeb 1998). Such “radical” differences in moral\njudgment as are frequently observed, Mackie (1977: 36) argued,\n“make it difficult to treat those judgments as apprehensions of\nobjective truths”. \nMackie supposed that his argument undermines moral realism,\nthe view that, as Smith (1994: 9, cf. 13) puts it,  \nmoral questions have correct answers, that the correct answers are\nmade correct by objective moral facts … and … by\nengaging in moral argument, we can discover what these objective moral\nfacts\n are.[21] \nThis notion of objectivity, as Smith recognizes, requires\nconvergence in moral views—the right sort of argument,\nreflection and discussion is expected to result in very substantial\nmoral agreement (Smith 1994:\n 6).[22] \nWhile moral realists have often taken pretty optimistic positions on\nthe extent of actual moral agreement (e.g., Sturgeon 1988: 229; Smith\n1994: 188), there is no denying that there is an abundance of\npersistent moral disagreement; on many moral issues there is a\nstriking failure of convergence even after protracted\nargument. Anti-realists like Mackie have a ready explanation for this\nphenomenon: Moral judgment is not objective in Smith’s sense,\nand moral argument cannot be expected to accomplish what Smith and\nother realists think it\n can.[23]\n Conversely, the realist’s task is to explain away\nfailures of convergence; she must provide an explanation of the\nphenomena consistent with it being the case that moral judgment is\nobjective and moral argument is rationally resolvable. Doris and\nPlakias (2008) call these “defusing explanations”. The\nrealist’s strategy is to insist that the preponderance of actual\nmoral disagreement is due to limitations of disputants or their\ncircumstances, and insist that (very substantial, if not\n unanimous)[24]\n moral agreement would emerge in ideal conditions,\nwhen, for example, disputants are fully rational and fully informed of\nthe relevant non-moral facts. \nIt is immediately evident that the relative merits of these competing\nexplanations cannot be fairly determined without close discussion of\nthe factors implicated in actual moral disagreements. Indeed, as acute\ncommentators with both realist (Sturgeon 1988: 230) and anti-realist\n(Loeb 1998: 284) sympathies have noted, the argument from disagreement\ncannot be evaluated by a priori philosophical means alone;\nwhat’s needed, as Loeb observes, is “a great deal of\nfurther empirical research into the circumstances and beliefs of\nvarious cultures”. This research is required not only to\naccurately assess the extent of actual disagreement, but also to\ndetermine why disagreement persists or dissolves. Only then\ncan realists’ attempts to “explain away” moral\ndisagreement be fairly assessed. \nRichard Brandt, who was a pioneer in the effort to integrate ethical\ntheory and the social sciences, looked primarily to anthropology to\nhelp determine whether moral attitudes can be expected to converge\nunder idealized circumstances. It is of course well known that\nanthropology includes a substantial body of work, such as the classic\nstudies of Westermarck (1906) and Sumner (1908 [1934]), detailing the\nradically divergent moral outlooks found in cultures around the world.\nBut as Brandt (1959: 283–4) recognized, typical ethnographies do\nnot support confident inferences about the convergence of attitudes\nunder ideal conditions, in large measure because they often give\nlimited guidance regarding how much of the moral disagreement can be\ntraced to disagreement about factual matters that are not moral in\nnature, such as those having to do with religious or cosmological\nviews. \nWith this sort of difficulty in mind, Brandt (1954) undertook his own\nanthropological study of Hopi people in the American southwest, and\nfound issues for which there appeared to be serious moral disagreement\nbetween typical Hopi and white American attitudes that could not\nplausibly be attributed to differences in belief about nonmoral\n facts.[25]\n A notable example is the Hopi attitude toward animal suffering, an\nattitude that might be expected to disturb many non-Hopis: \n[Hopi children] sometimes catch birds and make “pets” of\nthem. They may be tied to a string, to be taken out and\n“played” with. This play is rough, and birds seldom\nsurvive long. [According to one informant:] “Sometimes they get\ntired and die. Nobody objects to this”. (Brandt 1954: 213) \nBrandt (1959: 103) made a concerted effort to determine whether this\ndifference in moral outlook could be traced to disagreement about\nnonmoral facts, but he could find no plausible explanation of this\nkind; his Hopi informants didn’t believe that animals lack the\ncapacity to feel pain, for example, nor did they have cosmological\nbeliefs that would explain away the apparent cruelty of the practice,\nsuch as beliefs to the effect that animals are rewarded for martyrdom\nin the afterlife. The best explanation of the divergent moral\njudgments, Brandt (1954: 245, 284) concluded, is a “basic\ndifference of attitude”, since “groups do sometimes make\ndivergent appraisals when they have identical beliefs about the\nobjects”. \nMoody-Adams argues that little of philosophical import can be\nconcluded from Brandt’s—and indeed from\nmuch—ethnographic work. Deploying Gestalt psychology’s\ndoctrine of “situational meaning” (e.g., Dunker 1939),\nMoody-Adams (1997: 34–43) contends that all institutions,\nutterances, and behaviors have meanings that are peculiar to their\ncultural milieu, so that we cannot be certain that participants in\ncross-cultural disagreements are talking about the same\n thing.[26]\n The problem of situational meaning, she thinks, threatens\n“insuperable” methodological difficulty for those\nasserting the existence of intractable intercultural disagreement\n(1997: 36). Advocates of ethnographic projects will likely\nrespond—not unreasonably, we think—that judicious\nobservation and interview, such as that to which Brandt aspired,\ncan motivate confident assessments of evaluative diversity.\nSuppose, however, that Moody-Adams is right, and the methodological\ndifficulties are insurmountable. Now, there’s an equitable\ndistribution of the difficulty: if observation and interview are\nreally as problematic as Moody-Adams suggests, neither the\nrealists’ nor the anti-realists’ take on\ndisagreement can be supported by appeal to empirical evidence. We do\nnot think that such a stalemate obtains, because we think the\nimplicated methodological pessimism excessive. Serious empirical work\ncan, we think, tell us a lot about cultures and the differences\nbetween them. The appropriate way of proceeding is with close\nattention to particular studies, and what they show and fail to\n show.[27] \nAs Brandt (1959: 101–2) acknowledged, the anthropological\nliterature of his day did not always provide as much information on\nthe exact contours and origins of moral attitudes and beliefs as\nphilosophers wondering about the prospects for convergence might like.\nHowever, social psychology and cognitive science have recently\nproduced research which promises to further discussion; during the\nlast 35 years, there has been an explosion of “cultural\npsychology” investigating the cognitive and emotional processes\nof different cultures (Shweder & Bourne 1982; Markus &\nKitayama 1991; Ellsworth 1994; Nisbett & Cohen 1996; Nisbett 1998,\n2003; Kitayama & Markus 1999; Heine 2008; Kitayama & Cohen\n2010; Henrich 2015). Here we will focus on some cultural differences\nfound close to (our) home, differences discovered by Nisbett and his\ncolleagues while investigating regional patterns of violence in the\nAmerican North and South. We argue that these findings support\nBrandt’s pessimistic conclusions regarding the likelihood of\nconvergence in moral judgment. \nThe Nisbett group’s research can be seen as applying the tools\nof cognitive social psychology to the “culture of honor”,\na phenomenon that anthropologists have documented in a variety of\ngroups around the world. Although these groups differ in many\nrespects, they manifest important commonalities: \nA key aspect of the culture of honor is the importance placed on the\ninsult and the necessity to respond to it. An insult implies that the\ntarget is weak enough to be bullied. Since a reputation for strength\nis of the essence in the culture of honor, the individual who insults\nsomeone must be forced to retract; if the instigator refuses, he must\nbe punished—with violence or even death. (Nisbett & Cohen\n1996: 5) \nAccording to Nisbett and Cohen (1996: 5–9), an important factor\nin the genesis of southern honor culture was the presence of a herding\neconomy. Honor cultures are particularly likely to develop where\nresources are liable to theft, and where the state’s coercive\napparatus cannot be relied upon to prevent or punish thievery. These\nconditions often occur in relatively remote areas where herding is a\nmain form of subsistence; the “portability” of herd\nanimals makes them prone to theft. In areas where farming rather than\nherding dominates, cooperation among neighbors is more important,\nstronger government infrastructures are more common, and\nresources—like decidedly unportable farmland—are harder to\nsteal. In such agrarian social economies, cultures of honor tend not\nto develop. The American South was originally settled primarily by\npeoples from remote areas of Britain. Since their homelands were\ngenerally unsuitable for farming, these peoples have historically been\nherders; when they emigrated from Britain to the American South, they\ninitially sought out remote regions suitable for herding, and in such\nregions, the culture of honor flourished. \nIn the contemporary South, police and other government services are\nwidely available and herding has all but disappeared as a way of life,\nbut certain sorts of violence continue to be more common than they are\nin the North. Nisbett and Cohen (1996) maintain that patterns of\nviolence in the South, as well as attitudes toward violence, insults,\nand affronts to honor, are best explained by the hypothesis that a\nculture of honor persists among contemporary white non-Hispanic\nsoutherners. In support of this hypothesis, they offer a compelling\narray of evidence, including: \nTwo experimental studies—one in the field, the other in the\nlaboratory—are especially striking. \nIn the field study (Nisbett & Cohen 1996: 73–5), letters of\ninquiry were sent to hundreds of employers around the United States.\nThe letters purported to be from a hardworking 27-year-old Michigan\nman who had a single blemish on his otherwise solid record. In one\nversion, the “applicant” revealed that he had been\nconvicted for manslaughter. The applicant explained that he had been\nin a fight with a man who confronted him in a bar and told onlookers\nthat “he and my fiancée were sleeping together. He\nlaughed at me to my face and asked me to step outside if I was man\nenough”. According to the letter, the applicant’s nemesis\nwas killed in the ensuing fray. In the other version of the letter,\nthe applicant revealed that he had been convicted of motor vehicle\ntheft, perpetrated at a time when he needed money for his family.\nNisbett and his colleagues assessed 112 letters of response, and found\nthat southern employers were significantly more likely to be\ncooperative and sympathetic in response to the manslaughter letter\nthan were northern employers, while no regional differences were found\nin responses to the theft letter. One southern employer responded to\nthe manslaughter letter as follows: \nAs for your problems of the past, anyone could probably be in the\nsituation you were in. It was just an unfortunate incident that\nshouldn’t be held against you. Your honesty shows that you are\nsincere…. I wish you the best of luck for your future. You have\na positive attitude and a willingness to work. These are qualities\nthat businesses look for in employees. Once you are settled, if you\nare near here, please stop in and see us. (Nisbett & Cohen 1996:\n75) \nNo letters from northern employers were comparably sympathetic. \nIn the laboratory study (Nisbett & Cohen 1996: 45–8)\nsubjects—white males from both northern and southern states\nattending the University of Michigan—were told that saliva\nsamples would be collected to measure blood sugar as they performed\nvarious tasks. After an initial sample was collected, the unsuspecting\nsubject walked down a narrow corridor where an experimental\nconfederate was pretending to work on some filing. The confederate\nbumped the subject and, feigning annoyance, called him an\n“asshole”. A few minutes after the incident, saliva\nsamples were collected and analyzed to determine the level of\ncortisol—a hormone associated with high levels of stress,\nanxiety and arousal, and testosterone—a hormone associated with\naggression and dominance behavior. As Figure 1 indicates, southern\nsubjects showed dramatic increases in cortisol and testosterone\nlevels, while northerners exhibited much smaller changes. \nFigure 1 \nThe two studies just described suggest that southerners respond more\nstrongly to insult than northerners, and take a more sympathetic view\nof others who do so, manifesting just the sort of attitudes that are\nsupposed to typify honor cultures. We think that the data assembled by\nNisbett and his colleagues make a persuasive case that a culture of\nhonor persists in the American South. Apparently, this culture affects\npeople’s judgments, attitudes, emotion, behavior, and even their\nphysiological responses. Additionally, there is evidence that child\nrearing practices play a significant role in passing the culture of\nhonor on from one generation to the next, and also that relatively\npermissive laws regarding gun ownership, self-defense, and corporal\npunishment in the schools both reflect and reinforce southern honor\nculture (Nisbett & Cohen 1996: 60–63, 67–9). In short,\nit seems to us that the culture of honor is deeply entrenched in\ncontemporary southern culture, despite the fact that many of the\nmaterial and economic conditions giving rise to it no longer widely\n obtain.[28] \nWe believe that the North/South cultural differences adduced by\nNisbett and colleagues support Brandt’s conclusion that moral\nattitudes will often fail to converge, even under ideal conditions.\nThe data should be especially troubling for the realist, for despite\nthe differences that we have been recounting, contemporary northern\nand southern Americans might be expected to have rather more in\ncommon—from circumstance to language to belief to\nideology—than do, say, Yanomamö and Parisians. So if there\nis little ground for expecting convergence in the case at hand, there\nis probably little ground in a good many others. \nFraser and Hauser (2010) are not convinced by our interpretation of\nNisbett and Cohen’s data. They maintain that while those data do\nindicate that northerners and southerners differ in the strength of\ntheir disapproval of insult-provoked violence, they do not show that\nnortherners and southerners have a real moral disagreement. They go on\nto argue that the work of Abarbanell and Hauser (2010) provides a much\nmore persuasive example of a systematic moral disagreement between\npeople in different cultural groups. Abarbanell and Hauser focused on\nthe moral judgments of rural Mayan people in the Mexican state of\nChiapas. They found that people in that community do not judge\nactions causing harms to be worse than omissions\n(failures to act) which cause identical harms, while nearby urban\nMayan people and Western internet users judge actions to be\nsubstantially worse than omissions.  \nThough we are not convinced by Fraser and Hauser’s\ninterpretation of the Nisbett and Cohen data, we agree that the\nAbarbanell and Hauser study provides a compelling example of a\nsystematic cultural difference in moral judgement. Barrett et al.\n(2016) provides another example. That study looked at the extent to\nwhich an agent’s intention affected the moral judgments of\npeople in eight traditional small-scale societies and two Western\nsocieties, one urban, one rural. They found that in some of these\nsocieties, notably including both Western groups, the agent’s\nintention had a major effect, while in other societies agent intention\nhad little or no effect.  \nAs we said at the outset, realists defending conjectures about\nconvergence may attempt to explain away evaluative diversity\nby arguing that the diversity is to be attributed to shortcomings of\ndiscussants or their circumstances. If this strategy can be made good,\nmoral realism may survive an empirically informed argument from\ndisagreement: so much the worse for the instance of moral reflection\nand discussion in question, not so much the worse for the objectivity\nof morality. While we cannot here canvass all the varieties of this\nsuggestion, we will briefly remark on some of the more common forms.\nFor concreteness, we will focus on Nisbett and Cohen’s\nstudy. \nImpartiality. One strategy favored by moral realists\nconcerned to explain away moral disagreement is to say that such\ndisagreement stems from the distorting effects of individual interest\n(see Sturgeon 1988: 229–230; Enoch 2009: 24–29); perhaps\npersistent disagreement doesn’t so much betray deep features of\nmoral argument and judgment as it does the doggedness with which\nindividuals pursue their perceived advantage. For instance, seemingly\nmoral disputes over the distribution of wealth may be due to\nperceptions—perhaps mostly inchoate—of individual and\nclass interests rather than to principled disagreement about justice;\npersisting moral disagreement in such circumstances fails the\nimpartiality condition, and is therefore untroubling to the moral\nrealist. But it is rather implausible to suggest that North/South\ndisagreements as to when violence is justified will fail the\nimpartiality condition. There is no reason to think that southerners\nwould be unwilling to universalize their judgments across relevantly\nsimilar individuals in relevantly similar circumstances, as indeed\nNisbett and Cohen’s “letter study” suggests. One can\nadvocate a violent honor code without going in for special\n pleading.[29]\n We do not intend to denigrate southern values; our point is that\nwhile there may be good reasons for criticizing the honor-bound\nsoutherner, it is not obvious that the reason can be failure of\nimpartiality, if impartiality is (roughly) to be understood along the\nlines of a willingness to universalize one’s moral\njudgments. \nFull and vivid awareness of relevant nonmoral facts. Moral\nrealists have argued that moral disagreements very often derive from\ndisagreement about nonmoral issues. According to Boyd (1988: 213; cf.\nBrink 1989: 202–3; Sturgeon 1988: 229),  \ncareful philosophical examination will reveal … that agreement\non nonmoral issues would eliminate almost all disagreement\nabout the sorts of moral issues which arise in ordinary moral\npractice.  \nIs this a plausible conjecture for the data we have just considered?\nWe find it hard to imagine what agreement on nonmoral facts could do\nthe trick, for we can readily imagine that northerners and southerners\nmight be in full agreement on the relevant nonmoral facts in the cases\ndescribed. Members of both groups would presumably agree that the job\napplicant was cuckolded, for example, or that calling someone an\n“asshole” is an insult. We think it much more plausible to\nsuppose that the disagreement resides in differing and deeply\nentrenched evaluative attitudes regarding appropriate responses to\ncuckolding, challenge, and insult. \nSavvy philosophical readers will be quick to observe that terms like\n“challenge” and “insult” look like\n“thick” ethical terms, where the evaluative and\ndescriptive are commingled (see Williams 1985: 128–30);\ntherefore, it is very difficult to say what the extent of the factual\ndisagreement is. But this is of little help for the expedient under\nconsideration, since the disagreement-in-nonmoral-fact response\napparently requires that one can disentangle factual\nand moral disagreement. \nIt is of course possible that full and vivid awareness of the nonmoral\nfacts might motivate the sort of change in southern attitudes\nenvisaged by the (at least the northern) moral realist. Were\nsoutherners to become vividly aware that their culture of honor was\nimplicated in violence, they might be moved to change their moral\noutlook. (We take this way of putting the example to be the most\nnatural one, but nothing philosophical turns on it. If you like,\nsubstitute the possibility of northerners endorsing honor values after\nexposure to the facts.) On the other hand, southerners might insist\nthat the values of honor should be nurtured even at the cost of\npromoting violence; the motto “death before dishonor”,\nafter all, has a long and honorable history. The burden of argument,\nwe think, lies with the realist who asserts—culture and\nhistory notwithstanding—that southerners would change their\nmind if vividly aware of the pertinent facts. \nFreedom from “Abnormality”. Realists may contend\nthat much moral disagreement may result from failures of rationality\non the part of discussants (Brink 1989: 199–200). Obviously,\ndisagreement stemming from cognitive impairments is no embarrassment\nfor moral realism; at the limit, that a disagreement persists when\nsome or all disputing parties are quite insane shows nothing deep\nabout morality. But it doesn’t seem plausible that\nsoutherners’ more lenient attitudes towards certain forms of\nviolence are readily attributed to widespread cognitive disability. Of\ncourse, this is an empirical issue, but we don’t know of any\nevidence suggesting that southerners suffer some cognitive impairment\nthat prevents them from understanding demographic and attitudinal\nfactors in the genesis of violence, or any other matter of fact. What\nis needed to press home a charge of irrationality is evidence of\ncognitive impairment independent of the attitudinal\ndifferences, and further evidence that this impairment is implicated\nin adherence to the disputed values. In this instance, as in many\nothers, we have difficulty seeing how charges of abnormality or\nirrationality can be made without one side begging the question\nagainst the other. \nNisbett and colleagues’ work may represent a potent\ncounterexample to any theory maintaining that rational argument tends\nto convergence on important moral issues; the evidence suggests that\nthe North/South differences in attitudes towards violence and honor\nmight well persist even under the sort of ideal conditions under\nconsideration. Admittedly, such conclusions must be tentative. On the\nphilosophical side, not every plausible strategy for “explaining\naway” moral disagreement and grounding expectations of\nconvergence has been\n considered.[30]\n On the empirical side, this entry has reported on but a few studies, and\nthose considered, like any empirical work, might be\ncriticized on either conceptual or methodological\n grounds.[31]\n Finally, it should be clear what this entry is not claiming:\nany conclusions here—even if fairly earned—are not a\n“refutation” of all versions of moral realism, since there\nare versions of moral realism that do not require convergence\n(Bloomfield 2001; Shafer-Landau 2003). \nRather, this discussion should give an idea of the empirical work\nphilosophers must encounter, if they are to make defensible\nconjectures regarding moral disagreement. \nProgress in ethical theorizing often requires progress on difficult\npsychological questions about how human beings can be expected to\nfunction in moral contexts. It is no surprise, then, that moral\npsychology is a central area of inquiry in philosophical ethics. It\nshould also come as no surprise that empirical research, such as that\nconducted in psychology departments, may substantially abet such\ninquiry. Nor then, should it surprise that research in moral\npsychology has become methodologically pluralistic,\nexploiting the resources of, and endeavoring to contribute to, various\ndisciplines. Here, we have illustrated how such interdisciplinary\ninquiry may proceed with regard to central problems in philosophical\nethics.","contact.mail":"jonathan.s.phillips@dartmouth.edu","contact.domain":"dartmouth.edu"},{"date.published":"2006-04-19","date.changed":"2020-01-06","url":"https://plato.stanford.edu/entries/moral-psych-emp/","author1":"John Doris","author2":"Lachlan Walmsley","author1.info":"https://philosophy.cornell.edu/john-m-doris","author2.info":"https://philosophy.rutgers.edu/people/faculty/details/182-faculty1/faculty-profiles/635-stich-stephen","entry":"moral-psych-emp","body.text":"\n\n\nMoral psychology investigates human functioning in moral contexts, and\nasks how these results may impact debate in ethical theory. This work\nis necessarily interdisciplinary, drawing on both the empirical\nresources of the human sciences and the conceptual resources of\nphilosophical ethics. The present article discusses several topics\nthat illustrate this type of inquiry: thought experiments,\nresponsibility, character, egoism v. altruism, and moral\ndisagreement.\n\nContemporary moral psychology—the study of human thought and\nbehavior in ethical contexts—is resolutely interdisciplinary:\npsychologists freely draw on philosophical theories to help structure\ntheir empirical research, while philosophers freely draw on empirical\nfindings from psychology to help structure their\n theories.[1] \nWhile this extensive interdisciplinarity is a fairly recent\ndevelopment (with few exceptions, most of the relevant work dates from\nthe past quarter century), it should not be a surprising development.\nFrom antiquity to the present, philosophers have not been bashful\nabout making empirical claims, and many of these empirical claims have\nbeen claims about human psychology (Doris & Stich 2005). It is\ntherefore unremarkable that, with the emergence of scientific\npsychology over the past century and a half, some of these\nphilosophers would think to check their work against the systematic\nfindings of psychologists (hopefully, while taking special care to\navoid being misled by scientific controversy; see Doris 2015, Chapter\n3; Machery & Doris forthcoming).  \nSimilarly, at least since the demise of behaviorism, psychologists\nhave been keenly interested in normative phenomena in general and\nethical phenomena in particular. It is therefore unremarkable that\nsome of these psychologists would seek to enrich their theoretical\nframeworks with the conceptual resources of a field intensively\nfocused on normative phenomena: philosophical ethics. As a result, the\nfield demarcated by “moral psychology”, routinely involves\nan admixture of empirical and normative inquiry, pursued by both\nphilosophers and psychologists—increasingly, in the form of\ncollaborative efforts involving practitioners from both fields.  \nFor philosophers, the special interest of this interdisciplinary\ninquiry lies in the ways moral psychology may help adjudicate between\ncompeting ethical theories. The plausibility of its associated moral\npsychology is not, of course, the only dimension on which an ethical\ntheory may be evaluated; equally important are normative\nquestions having to do with how well a theory fares when compared to\nimportant convictions about such things as justice, fairness, and the\ngood life. Such questions have been, and will continue to be, of\ncentral importance for philosophical ethics. Nonetheless, it is\ncommonly supposed that an ethical theory committed to an impoverished\nor inaccurate conception of moral psychology is at a serious\ncompetitive disadvantage. As Bernard Williams (1973, 1985; cf.\nFlanagan 1991) forcefully argued, an ethical conception that commends\nrelationships, commitments, or life projects that are at odds with the\nsorts of attachments that can be reasonably expected to take root in\nand vivify actual human lives is an ethical conception with—at\nbest—a very tenuous claim to our assent. \nWith this in mind, problems in ethical theory choice making reference\nto moral psychology can be framed by two related inquiries: \nThe first question is one of philosophical scholarship: what are the\npsychological commitments of various positions in philosophical\nethics? The second question takes us beyond the corridors of\nphilosophy departments and to the sorts of questions asked, and\nsometimes answered, by the human sciences, including psychology,\nanthropology, sociology, history, cognitive science, linguistics and\nneuroscience. Thus, contemporary moral psychology is\nmethodologically pluralistic: it aims to answer philosophical\nquestions, but in an empirically responsible way. \nHowever, it will sometimes be difficult to tell which claims in\nphilosophical ethics require empirical substantiation. Partly, this is\nbecause it is sometimes unclear whether, and to what extent, a\ncontention counts as empirically assessable. Consider questions\nregarding “normal functioning” in mental health care: are\nthe answers to these questions statistical, or evaluative (Boorse\n1975; Fulford 1989; Murphy 2006)? For example, is “normal”\nmental health simply the psychological condition of most people, or is\nit good mental health? If the former, the issue is, at least\nin principle, empirically decidable. If the latter, the issues must be\ndecided, if they can be decided, by arguments about value. \nAdditionally, philosophers have not always been explicit about\nwhether, and to what extent, they are making empirical claims. For\nexample, are their depictions of moral character meant to identify\npsychological features of actual persons, or to articulate ideals that\nneed not be instantiated in actual human psychologies? Such questions\nwill of course be complicated by the inevitable diversity of\nphilosophical opinion. \nIn every instance, therefore, the first task is to carefully document\na theory’s empirically assessable claims, whether they are\nexplicit or, as may often be the case, tacit. Once claims apt for\nempirical assessment have been located, the question becomes one of\nidentifying any relevant empirical literatures. The next job is to\nassess those literatures, in an attempt to determine what conclusions\ncan be responsibly drawn from them. Science, particularly social\nscience, being what it is, many conclusions will be provisional; the\nphilosophical moral psychologist must be prepared to adjudicate\ncontroversies in other fields, or offer informed conjecture regarding\nfuture findings. Often, the empirical record will be crucially\nincomplete. In such cases, philosophers may be forced to engage in\nempirically disciplined conjecture, or even to engage in their own\nempirical work, as some philosophers are beginning to\n do.[2] \nWhen the philosophical positions have been isolated, and putatively\nrelevant empirical literatures assessed, we can begin to evaluate the\nplausibility of the philosophical moral psychology: Is the speculative\npicture of psychological functioning that informs some region of\nethical theory compatible with the empirical picture that emerges from\nsystematic observation? In short, is the philosophical picture\nempirically adequate? If it is determined that the\nphilosophical conception is empirically adequate, the result is\nvindicatory. Conversely, if the philosophical moral\npsychology in question is found to be empirically inadequate,\nthe result is revisionary, compelling alteration, or even\nrejection, of those elements of the philosophical theory presupposing\nthe problematic moral psychology. The process will often be\ncomparative. Theory choice in moral psychology, like other\ntheory choice, involves tradeoffs, and while an empirically\nundersupported approach may not be decisively eliminated from\ncontention on empirical grounds alone, it may come to be seen as less\nattractive than theoretical options with firmer empirical\nfoundations. \nThe winds driving the sort of disciplinary cross-pollination we\ndescribe do not blow in one direction. As philosophers writing for an\nencyclopedia of philosophy, we are naturally concerned with the ways\nempirical research might shape, or re-shape, philosophical ethics. But\nphilosophical reflection may likewise influence empirical research,\nsince such research is often driven by philosophical suppositions that\nmay be more or less philosophically sound. The best interdisciplinary\nconversations, then, should benefit both parties. To illustrate the\ndialectical process we have described, we will consider a variety of\ntopics in moral psychology. Our primary concerns will be\nphilosophical: What are some of the most central problems in\nphilosophical moral psychology, and how might they be resolved?\nHowever, as the hybrid nature of our topic invites us to do, we will\npursue these questions in an interdisciplinary spirit, and are hopeful\nthat our remarks will also engage interested scientists. Hopefully,\nthe result will be a broad sense of the problems and methods that will\nstructure research on moral psychology during the 21st\ncentury. \n“Intuition pumps” or “thought experiments”\nhave long been well-used items in the philosopher’s toolbox\n(Dennett 1984: 17–18; Stuart et al. 2018). Typically, a thought\nexperiment presents an example, often a hypothetical example, in order\nto elicit some philosophically telling response. If a thought\nexperiment is successful, it may be concluded that competing theories\nmust account for the resulting response. These responses are supposed\nto serve an evidential role in philosophical theory choice;\nif you like, they can be understood as data competing\ntheories must\n accommodate.[3]\n If an appropriate audience’s ethical responses to a thought\nexperiment conflict with the response a theory prescribes for the\ncase, the theory has suffered a counterexample. \nThe question of whose responses “count” philosophically\n(or, who is the “appropriate” audience) has been answered\nin a variety of ways, but for many philosophers, the intended audience\nfor thought experiments seems to be some species of “ordinary\nfolk” (see Jackson 1998: 118, 129; Jackson & Pettit 1995:\n22–9; Lewis 1989: 126–9). Of course, the relevant folk\nmust possess such cognitive attainments as are required to understand\nthe case at issue; very young children are probably not an ideal\naudience for thought experiments. Accordingly, some philosophers may\ninsist that the relevant responses are the considered judgments of\npeople with the training required to see “what is at stake\nphilosophically”. But if the responses are to help adjudicate\nbetween competing theories, the responders must be more or less\ntheoretically neutral, and this sort of neutrality is\nrather likely to be vitiated by philosophical education. A dilemma\nemerges. On the one hand, philosophically naïve subjects may be\nthought to lack the erudition required to grasp the philosophical\nstakes. On the other, with increasing philosophical sophistication\ncomes, very likely, philosophical partiality; one audience is\nnaïve, and the other\n prejudiced.[4] \nHowever exactly the philosophically relevant audience is specified,\nthere are empirical questions that must be addressed in determining\nthe philosophical potency of a thought experiment. In particular, when\ndeciding what philosophical weight to give a response, philosophers\nneed to determine its origins. What features of the\nexample are implicated in a given judgment—are people\nreacting to the substance of the case, or the style of exposition?\nWhat features of the audience are implicated in their\nreaction—do different demographic groups respond to the example\ndifferently? Are there factors in the environment that are affecting\npeople’s intuitive judgments? Does the order in which people\nconsider examples affect their judgments? Such questions raise the\nfollowing concern: judgments about thought experiments dealing with\nmoral issues might be strongly influenced by ethically\nirrelevant characteristics of the example or the audience or the\nenvironment or the order of presentation. Whether a characteristic is\nethically relevant is a matter for philosophical discussion, but\ndetermining the status of a particular thought experiment also\nrequires empirical investigation of its causally relevant\ncharacteristics. We’ll now describe some examples of such\ninvestigation. \nAs part of their famous research on the “heuristics and\nbiases” that underlie human reasoning, Tversky and Kahneman\n(1981) presented subjects with the following problem: \nImagine that the U.S. is preparing for the outbreak of an unusual\nAsian disease, which is expected to kill 600 people. Two alternative\nprograms to combat the disease have been proposed. Assume that the\nexact scientific estimate of the consequences of the programs are as\nfollows: \nA second group of subjects was given an identical problem, except that\nthe programs were described as follows: \nOn the first version of the problem, most subjects thought that\nProgram A should be adopted. But on the second version, most chose\nProgram D, despite the fact that the outcome described in A is\nidentical to the one described in C. The disconcerting implication of\nthis study is that ethical responses may be strongly influenced by the\nmanner in which cases are described or framed. It seems that\nsuch framing sensitivities constitute ethically irrelevant influences\non ethical responses. Unless this sort of possibility can be\nconfidently eliminated, one should hesitate to rely on responses to a\nthought experiment for adjudicating theoretical controversies. Such\npossibilities can only be eliminated through systematic empirical\n work.[5] \nWhile a relatively small percentage of empirical work on\n“heuristics and biases” directly addresses moral\nreasoning, numerous philosophers who have addressed the issue\n(Horowitz 1998; Doris & Stich 2005; Sinnott-Armstrong 2005;\nSunstein 2005) agree that phenomena like framing effects are likely to\nbe pervasively implicated in responses to ethically freighted\nexamples, and argue that this state of affairs should cause\nphilosophers to view the thought-experimental method with considerable\nconcern. \nWe turn now to order effects. In a pioneering study, Petrinovich and\nO’Neill (1996) found that participants’ moral intuitions\nvaried with the order in which the thought experiments were presented.\nSimilar findings have been reported by Liao et al. (2012), Wiegman et\nal. (2012), and Schwitzgebel & Cushman (2011, 2015). The\nSchwitzgebel and Cushman studies are particularly striking, since they\nset out to explore whether order effects in moral intuitions were\nsmaller or non-existent in professional philosophers. Surprisingly,\nthey found that professional philosophers were also subject to order\neffects, even though the thought experiments used are well known in\nthe field. Schwitzgebel and Cushman also report that in some cases\nphilosophers intuitions show substantial order effects when the\nintuitions of non-philosophers don’t. \nAudience characteristics may also affect the outcome of thought\nexperiments. Haidt and associates (1993: 613) presented stories about\n“harmless yet offensive violations of strong social norms”\nto men and women of high and low socioeconomic status (SES) in\nPhiladelphia (USA), Porto Alegre, and Recife (both in Brazil). For\nexample: \nA man goes to the supermarket once a week and buys a dead chicken. But\nbefore cooking the chicken, he has sexual intercourse with it. Then he\ncooks it and eats it. (Haidt et al. 1993: 617) \nLower SES subjects tended to “moralize” harmless and\noffensive behaviors like that in the chicken story. These subjects\nwere more inclined than their high SES counterparts to say that the\nactor should be “stopped or punished”, and more inclined\nto deny that such behaviors would be “OK” if customary in\na given country (Haidt et al. 1993: 618–19). The point is not\nthat lower SES subjects are mistaken in their moralization of such\nbehaviors while the urbanity of higher SES subjects represents a more\nrationally defensible response. The difficulty is deciding\nwhich—if any—of the conflicting responses is fit to serve\nas a constraint on ethical theory, when both may equally be the result\nof more or less arbitrary cultural factors. \nPhilosophical audiences typically decline to\nmoralize the offensive behaviors, and we ourselves share their\ntolerant attitude. But of course these audiences—by virtue of\neducational attainments, if not stock portfolios—are\noverwhelmingly high SES. Haidt’s work suggests that it is a\nmistake for a philosopher to say, as Jackson (1998: 32n4; cf. 37)\ndoes, that “my intuitions reveal the folk conception in as much\nas I am reasonably entitled, as I usually am, to regard myself as\ntypical”. The question is: typical of what demographic? Are\nphilosophers’ ethical responses determined by the philosophical\nsubstance of the examples, or by cultural idiosyncrasies that are very\nplausibly thought to be ethically irrelevant? Once again, until such\npossibilities are ruled out by systematic empirical investigation, the\nphilosophical heft of a thought experiment is open to question. \nIn recent years there has been a growing body of research reporting\nthat judgments evoked by moral thought experiments are affected by\nenvironmental factors that look to be completely irrelevant to the\nmoral issue at hand. The presence of dirty pizza boxes and a whiff of\nfart spray (Schnall et al. 2008a), the use of soap (Schnall et al.\n2008b) or an antiseptic handwipe (Zhong et al. 2010), or even the\nproximity of a hand sanitizer dispenser (Helzer & Pizarro 2011)\nhave all been reported to influence moral intuitions. Tobia et al.\n(2013) found that the moral intuitions of both students and\nprofessional philosophers are affected by spraying the questionnaire\nwith a disinfectant spray. Valdesolo and DeSteno (2006) reported that\nviewing a humorous video clip can have a substantial impact on\nparticipant’s moral intuitions. And Strohminger et al. (2011)\nhave shown that hearing different kinds of audio clips (stand-up\ncomedy or inspirational stories from a volume called Chicken Soup\nfor the Soul) has divergent effects on moral intuitions. \nHow should moral theorists react to findings like these? One might, of\ncourse, eschew thought experiments in ethical theorizing. While this\nmethodological austerity is not without appeal, it comes at a cost.\nDespite the difficulties, thought experiments are a window, in some\ncases the only accessible window, into important regions of ethical\nexperience. In so far as it is disconnected from the thoughts and\nfeels of the lived ethical life, ethical theory risks being\n“motivationally inaccessible”, or incapable of engaging\nthe ethical concern of agents who are supposed to live in accordance\nwith the normative standards of the\n theory.[6]\n Fortunately, there is another possibility: continue pursuing the\nresearch program that systematically investigates responses to\nintuition pumps. In effect, the idea is to subject philosophical\nthought experiments to the critical methods of experimental social\npsychology. If investigations employing different experimental\nscenarios and subject populations reveal a clear trend in responses,\nwe can begin to have some confidence that we are identifying a deeply\nand widely shared moral conviction. Philosophical discussion may\nestablish that convictions of this sort should serve as a constraint\non moral theory, while responses to thought experiments that empirical\nresearch determines to lack such solidity, such as those susceptible\nto order, framing or environmental effects, or those admitting of\nstrong cultural variation, may be ones that ethical theorists can\nsafely disregard.  \nA philosophically informed empirical research program akin to the one\njust described is more than a methodological fantasy. This approach\naccurately describes a number of research programs aimed at informing\nphilosophical debates through interdisciplinary research. \nOne of the earliest examples of this kind of work was inspired in\nlarge part by the work of Knobe (2003a,b, 2006) and addressed\nquestions surrounding “folk morality” on issues ranging\nfrom intentional action to causal responsibility (see Knobe 2010 for\nreview and discussion). This early work helped to spur the development\nof a truly interdisciplinary research program with both philosophers\nand psychologists investigating the folk morality of everyday life.\n(See the Stanford Encyclopedia of Philosophy article on\nExperimental Moral Philosophy for a more complete treatment of this\nresearch.) \nAnother related philosophical debate concerns the compatibility of\nfree will and moral responsibility with determinism. On the one hand,\nincompatibilists insist that determinism (the view that all events are\njointly determined by antecedent events as governed by laws of\nnature), is incompatible with moral responsibility.\nTypically, these accounts also go on to specify what particular\ncapacity is required to be responsible for one’s own behavior\n(e.g., that agents have alternate possibilities for behavior, or are\nthe “ultimate” source of their behavior, or both (Kane\n2002: 5; Haji 2002:\n 202–3).[7]\n On the other hand, compatibilists argue that determinism and\nresponsibility are compatible, often by denying that\nresponsible agency requires that the actor have genuinely open\nalternatives, or rejecting the ultimacy condition that requires\nindeterminism (or impossible demands for self-creation). In short,\ncompatibilists hold that people may legitimately be held responsible\neven though there is some sense in which they “could not have\ndone otherwise” or are not the “ultimate source” of\ntheir behavior. Incompatibilists deny that this is the case.\nProponents of these two opposing positions have remained relatively\nentrenched, and some participants have raised fears of a\n“dialectical stalemate” (Fischer 1994: 83–5). \nA critical issue in these debates has been the claim that the\nincompatibilist position better captures folk moral judgments about\nagents whose actions have been completely determined (e.g., G.\nStrawson 1986: 88; Smilansky 2003: 259; Pereboom 2001: xvi;\nO’Connor 2000: 4; Nagel 1986: 113, 125; Campbell 1951: 451; Pink\n2004: 12). For example, Robert Kane (1999: 218; cf. 1996: 83–5),\na leading incompatibilist, reports that in his experience “most\nordinary persons start out as natural incompatibilists”, and\n“have to be talked out of this natural incompatibilism by the\nclever arguments of philosophers”. \nUnsurprisingly, some compatibilists have been quick to assert the\ncontrary. For example, Peter Strawson (1982) famously argued that in\nthe context of “ordinary interpersonal relationships”,\npeople are not haunted by the specter of determinism; such\nmetaphysical concerns are irrelevant to their experience and\nexpression of the “reactive attitudes”—anger,\nresentment, gratitude, forgiveness, and the like—associated with\nresponsibility assessment. Any anxiety about determinism, Strawson\ninsisted, is due to the “panicky metaphysics” of\nphilosophers, not incompatibilist convictions on the part of ordinary\npeople. However, incompatibilists have historically been thought to\nhave ordinary intuitions on their side; even some philosophers with\ncompatibilist leanings are prepared to concede the incompatibilist\npoint about “typical” response tendencies (e.g., Vargas\n2005a,b). \nNeither side, so far as we are aware, has offered much in the way of\nsystematic evidence of actual patterns of folk moral judgments.\nRecently however, a now substantial research program has begun to\noffer empirical evidence on the relationship between determinism and\nmoral responsibility in folk moral judgments. \nInspired by the work of Frankfurt (1988) and others, Woolfolk, Doris,\nand Darley (2006) hypothesized that observers may hold actors\nresponsible even when the observers judge that the actors could not\nhave done otherwise, if the actors appear to “identify”\nwith their behavior. Roughly, the idea is that the actor identifies\nwith a behavior—and is therefore responsible for it—to the\nextent that she “embraces” the behavior, or performs it\n“wholeheartedly” regardless of whether genuine\nalternatives for behavior are\n possible.[8]\n Woolfolk et al.’s suspicion was, in effect, that people’s\n(presumably tacit) theory of responsibility is compatibilist. \nTo test this, subjects were asked to read a story about an agent who\nwas forced by a group of armed hijackers to kill a man who had been\nhaving an affair with his wife. In the “low\nidentification” condition, the man was described as being\nhorrified at being forced to kill his wife’s lover, and as not\nwanting to do so. In the “high identification” condition,\nthe man is instead described as welcoming the opportunity and wanting\nto kill his wife’s lover. In both cases, the man is not given a\nchoice, and does kill his wife’s lover. \nConsistent with Woolfolk and colleagues’ hypothesis, subjects\njudged that the highly identifying actor was more responsible, more\nappropriately blamed, and more properly subject to guilt than the low\nidentification\n actor.[9]\n This pattern in folk moral judgments seems to suggest that\nparticipants were not consistently incompatibilist in their\nresponsibility attributions, because the lack of alternatives\navailable to the actor was not alone sufficient to rule out such\nattributions. \nIn response to these results, those who believe that folk morality is\nincompatibilist may be quick to object that the study merely suggests\nthat responsibility attributions are influenced by identification, but\nsays nothing about incompatibilist commitments or the lack thereof.\nSubjects still may have believed that the actor could have done\notherwise. To address this concern, Woolfolk and colleagues also\nconducted a version of the study in which the man acted under the\ninfluence of a “compliance drug”. In this case,\nparticipants were markedly less likely to agree that the man\n“was free to behave other than he did” and yet they still\nheld the agent who identified with the action as more responsible than\nthe agent who did not. These results look to pose a clear challenge to\nthe view that ordinary folk are typically incompatibilists. \nA related pattern of responses was obtained by Nahmias, Morris,\nNadelhoffer and Turner (2009) who instead described agents preforming\nimmoral behaviors in a “deterministic world” of the sort\noften described in philosophy classrooms. One variation read as\nfollows: \nImagine that in the next century we discover all the laws of nature,\nand we build a supercomputer which can deduce from these laws of\nnature and from the current state of everything in the world exactly\nwhat will be happening in the world at any future time. It can look at\neverything about the way the world is and predict everything about how\nit will be with 100% accuracy. Suppose that such a supercomputer\nexisted, and it looks at the state of the universe at a certain time\non March 25th, 2150 C.E., twenty years before Jeremy Hall is born. The\ncomputer then deduces from this information and the laws of nature\nthat Jeremy will definitely rob Fidelity Bank at 6:00 PM on January\n26th, 2195. As always, the supercomputer’s prediction is\ncorrect; Jeremy robs Fidelity Bank at 6:00 PM on January 26th,\n2195. \nSubjects were then asked whether Jeremy was morally blameworthy. Most\nsaid yes, indicating that they thought an agent could be morally\nblameworthy even if his behaviors were entirely determined by natural\nlaws. Consistent with the Woolfolk et al. results, it appears that the\nsubjects’ judgments, at least those having to do with moral\nblameworthiness, were not governed by a commitment to\nincompatibilism. \nThis emerging picture was complicated, however, by Nichols and Knobe\n(2007), which argued that the ostensibly compatibilist responses were\nperformance errors driven by an affective response to the\nagents’ immoral actions. To demonstrate this, all subjects were\nasked to imagine two universes—a universe completely governed by\ndeterministic laws (Universe A) and a universe (Universe B) in which\neverything is determined except for human decisions which are not\ncompletely determined by deterministic laws and what has happened in\nthe past. In Universe B, but not Universe A, “each human\ndecision does not have to happen the way it does”. Some\nsubjects were assigned to a concrete condition, and asked to make a\njudgment about a specific individual in specific circumstances, while\nothers were assigned to an abstract condition, and asked to make a\nmore general judgment, divorced from any particular individual. The\nhypothesis was that the difference between these two conditions would\ngenerate different responses regarding the relationship between\ndeterminism and moral responsibility. Subjects in the concrete\ncondition read a story about a man, “Bill”, in the\ndeterministic universe who murders his wife and children in a\nparticularly ghastly manner, and were asked whether Bill was morally\nresponsible for what he had done. By contrast, subjects in the\nabstract condition were asked “In Universe A, is it possible for\na person to be fully morally responsible for their actions?”\nSeventy-two percent of subjects in the concrete condition gave a\ncompatibilist response, holding Bill responsible in Universe A,\nwhereas less than fifteen percent of subjects in the abstract\ncondition gave a compatibilist response, allowing that people could be\nfully morally responsible in the deterministic Universe A. \nIn line with previous experimental work demonstrating that increased\naffective arousal amplified punitive responses to wrongdoing (Lerner,\nGoldberg, & Tetlock 1998), Nichols and Knobe hypothesized that\npreviously observed compatibilist responses were the result of the\naffectively laden nature of the stimulus materials. When this\naffective element was eliminated from the materials (as in the\nabstract condition), participants instead exhibited an incompatibilist\npattern of responses. \nMore recently, Nichols and Knobe’s line of reasoning has come\nunder fire from two directions. First, a number of studies have now\ntried to systematically manipulate how affectively arousing the\nimmoral behavior performed is, but have not found that these changes\nsignificantly alter participants’ judgments of moral\nresponsibility in deterministic scenarios. Rather, the differences\nseem to be best explained simply by whether the case was described\nabstractly or concretely (see Cova et al. 2012 for work with patients\nwho have frontotemporal dementia, and see Feltz & Cova 2014 for a\nmeta-analysis). Second, a separate line of studies from Murray and\nNahmias (2014) argued that participants who exhibited the apparently\nincompatibilist pattern of responses were making a critical error in\nhow they understood the deterministic scenario. In particular, they\nargued these participants mistakenly took the agents, or their mental\nstates, in these deterministic scenarios to be “bypassed”\nin the causal chain leading up to their behavior. In support of their\nargument, Murray and Nahmias (2014) demonstrated that when analyses\nwere restricted to the participants who clearly did not take the agent\nto be bypassed, these participants judged the agent to be morally\nresponsible (blameworthy, etc.) despite being in a deterministic\nuniverse. Unsurprisingly, this line of argument has, in turn, inspired\na number of further counter-responses, both empirical (Rose &\nNichols 2013) and theoretical (Björnsson & Pereboom 2016),\nwhich caution against the conclusions of Murray and Nahmias. \nWhile the debate continues over whether the compatibilist or\nincompatibilist position better captures folk moral judgments of\nagents in deterministic universes, a related line of research has\nsprung up around what is widely taken to be the most convincing\ncontemporary form of argument for incompatibilism: manipulation\narguments (e.g., Mele 2006, 2013, Pereboom 2001, 2014).\nPereboom’s Four-Case version, for example, begins with the case\nof an agent named Plum who is manipulated by neuroscientists who use a\nradio-like technology to change Plum’s neural states, which\nresults in him wanting and then deciding to kill a man named White. In\nthis case, it seems clear that Plum did not freely decide to kill\nWhite. Compare this case to a second one, in which the team of\nneuroscientists programmed Plum at the beginning of his life in a way\nthat resulted in him developing the desire (and making the decision)\nto kill White. The incompatibilist argues that these two cases do not\ndiffer in a way that is relevant for whether Plum acted freely, and\nso, once again, it seems that Plum did not freely decide to kill\nWhite. Now compare this to a third case, in which Plum’s desire\nand decision to kill White were instead determined by his cultural and\nsocial milieu, rather than by a team of neuroscientists. Since the\nonly difference between the second and third case is the particular\ntechnological process through which Plum’s mental states were\ndetermined, he would again seem to not have freely decided to kill\nWhite. Finally, in a fourth and final case, Plum’s desire and\ndecision to kill White was determined jointly by the past states and\nthe laws of nature in our own deterministic universe. Regarding these\nfour cases, Pereboom argues that, since there is no difference between\nany of the four cases that is relevant to free will, if Plum was not\nmorally responsible in the first case, then he was not morally\nresponsible in the fourth. \nIn response to this kind of manipulation-based argument for\nincompatibilism, a number of researchers have taken aim at painting a\nbetter empirical picture of ordinary moral judgments concerning\nmanipulated agents. This line of inquiry has been productive on two\nlevels. First, a growing number of empirical studies have investigated\nmoral responsibility judgments about cases of manipulation, and now\nprovide a clearer psychological picture for why manipulated agents are\njudged to lack free will and moral responsibility. Second, continuing\ntheoretical work, informed by this empirical picture, has provided new\nreasons for doubting that manipulation based arguments actually\nprovide evidence against compatibilism. \nOne line of empirical research, led by Chandra Sripada (2012) has\nasked whether manipulated agents are perceived to be unfree because\n(a) they lack ultimate control over their actions (a capacity\nincompatibilists take to be essential for moral responsibility) or\ninstead because (b) their psychological or volitional capacities (the\ncapacities focused on by compatibilists) have been damaged. Using a\nstatistical approach called Structural Equation Modeling (or SEM),\nSripada found that participants’ moral responsibility judgments\nwere best explained by whether they believed the psychological and\nvolitional capacities of the agent were damaged by manipulation and\nnot whether the agent lacked control over her actions. This finding\nsuggests that patterns of judgment in cases of manipulation are more\nconsistent with the predictions of compatibilism than with\nincompatibilism. \nTaking a different approach, Phillips and Shaw (2014) demonstrated\nthat the reduction of moral responsibility that is typically observed\nin cases of manipulation depends critically on the role of an\nintentional manipulator. In particular, ordinary people were\nshown to distinguish between (1) the moral responsibility of agents\nwho are made to do a particular act by features of the situation they\nare in (i.e., situational determinism), and (2) the moral\nresponsibility of agents who are made to do that same act by another\nintentional agent (i.e., manipulation). This work suggests that the\nordinary practice of assessing freedom and responsibility is likely to\nclearly distinguish between cases that do and do not involve a\nmanipulator who intervenes with the intention of causing the\nmanipulated agent to do the immoral action. A series of studies by\nMurray and Lombrozo (2016) further elaborates these findings by\nproviding evidence that the specific reduction of moral responsibility\nthat results from being manipulated arises from the perception that\nthe agent’s mental states are bypassed. \nCollectively, two lessons have come out of this work on the ordinary\npractice of assessing the moral responsibility of manipulated agents:\n(1) folk morality provides a natural way of distinguishing between the\ndifferent cases used in manipulation-based arguments (those that do\ninvolve the intentional intervention of a manipulator vs. those that\ndon’t) and (2) folk morality draws an intimate link between the\nmoral responsibility of an agent and that agent’s mental and\nvolitional capacities. Building on this increasingly clear empirical\npicture, Deery and Nahmias (2017) formalized these basic principles in\ntheoretical work that argues for a principled way of distinguishing\nbetween the moral responsibility of determined and manipulated\nagents. \nWhile the majority of evidence may currently be in favor of the view\nthat folk morality adheres to a kind of “natural\ncompatibilism” (Cova & Kitano 2013), this remains a\ncontentious topic, and new work is continually emerging on both sides\nof the debate (Andow & Cova 2016; Bear & Knobe 2016;\nBjörnsson 2014; Feltz & Millan 2013; Figdor & Phelan\n2015; Knobe 2014). One thing that has now been agreed on by parties on\nboth sides of this debate, however, is a critical role for careful\nempirical studies (Björnsson & Pereboom 2016; Knobe 2014;\nNahmias 2011). \nTo date, empirically informed approaches to moral psychology have been\nmost prominent in discussions of moral character and virtue. The focus\nis decades of experimentation in “situationist” social\npsychology: unobtrusive features of situations have repeatedly been\nshown to impact behavior in seemingly arbitrary, and sometimes\nalarming, ways. Among the findings that have most interested\nphilosophers: \nThese experiments are part of an extensive empirical literature,\nwhere social psychologists have time and again found that\ndisappointing omissions and appalling actions are readily induced by\napparently minor situational\n features.[10]\n The striking fact is not that people fail standards for good conduct,\nbut that they can be so easily induced to do so. \nExploiting this observation, “character skeptics” contend\nthat if moral conduct varies so sharply, often for the worse, with\nminor perturbations in circumstance, ostensibly good character\nprovides very limited assurance of good conduct. In addition to this\nclaim in descriptive psychology, concerning the fragility of\nmoral character, some character skeptics also forward a thesis in\nnormative ethics, to the effect that character merits less\nattention in ethical thought than it traditionally\n gets.[11] \nCharacter skepticism contravenes the influential program of\ncontemporary virtue ethics, which maintains that advancing\nethical theory requires more attention to character, and\nvirtue ethicists offer vigorous\n resistance.[12]\n Discussion has sometimes been overheated, but it has resulted in a\nlarge literature in a vibrantly interdisciplinary field of\n“character studies” (e.g., Miller et al.\n 2015).[13]\n The literature is too extensive for the confines of this entry, but\nwe will endeavor to outline some of the main issues.  \nThe first thing to observe is that the science which inspires the\ncharacter skeptics may itself be subject to skepticism. Given the\nuneven history of the human sciences, it might be argued that the\nrelevant findings are too uncertain to stand as a constraint on\nphilosophical theorizing. This contention is potentially buttressed by\nrecent prominent replication failures in social psychology.  \nThe psychology at issue is, like much of science, unfinished business.\nBut the replication controversy, and the attendant suspicion of\nscience, is insufficient grounds for dismissing the psychology out of\nhand. Philosophical conclusions should not be based on a few studies;\nthe task of the philosophical consumer of science is to identify\ntrends in convergent strands of evidence (Doris\n2015: 49, 56; Machery & Doris forthcoming). The observation that\nmotivates character skepticism—the surprising situational\nsensitivity of behavior—is supported by a wide range of\nscientific findings, as well as by recurring themes in history and\nbiography (Doris 2002, 2005). The strong situational\ndiscriminativeness of behavior is accepted as fact by high proportion\nof involved scientists; accordingly, it is not much contested in\ndebates about character skepticism. \nBut the philosophical implications of this fact remain, after\nconsiderable debate, a contentious issue. The various responses to\ncharacter skepticism need not be forwarded in isolation, and some of\nthem may be combined as part of a multi-pronged defense. Different\nrejoinders have differing strengths and weaknesses, particularly with\nrespect to the differing pieces of evidence on which character\nskeptics rely; the phenomena are not unitary, and accommodating them\nall may preclude a unitary response.  \nOne way of defusing empirically motivated skepticism—dubbed by\nAlfano (2013) “the dodge”—is simply to deny that\nvirtue ethics makes empirical claims. On this understanding, virtue\nethics is cast as a “purely normative” endeavor aiming at\nerecting ethical ideals in complete absence of empirical commitments\nregarding actual human psychologies. This sort of purity is perhaps\nless honored than honored in the breach: historically, virtue ethics\nhas been typified by an interest in how actual people become\ngood. Aristotle (Nicomachean Ethics, 1099b18–19)\nthought that anyone not “maimed” with regard to the\ncapacity for virtue may acquire it “by a certain kind of study\nand care”, and contemporary Aristotelians have emphasized the\nimportance of moral education and development (e.g., Annas 2011). More\ngenerally, virtue-based approaches have been claimed to have an\nadvantage over major Kantian and consequentialist competitors with\nrespect to “psychological realism”—the advantage of\na more lifelike moral psychology (see Anscombe 1958: 1, 15; Williams\n1985; Flanagan 1991: 182; Hursthouse 1999: 19–20).  \nTo be sure, eschewing empirical commitment allows virtue ethics to\nescape empirical threat: obviously, empirical evidence cannot be used\nto undermine a theory that makes no empirical claims.\nHowever, it is not clear such theories could claim advantages\ntraditionally claimed for virtue theories with regard to moral\ndevelopment and psychological realism. In any event, they are not\ncontributions to empirical moral psychology, and needn’t be\nfurther discussed here. \nBefore seeing how the debate in moral psychology might be advanced, it\nis necessary to correct a mischaracterization that serves to arrest\nprogress. It is too often said, particularly in reference to Doris\n(1998, 2002) and Harman (1999, 2000), that character skepticism comes\nto the view that character traits “do not exist” (e.g.,\nFlanagan 2009: 55). Frequently, this attribution is made without\ndocumentation, but when documentation is provided, it is typically in\nreference to some early, characteristically pointed, remarks of Harman\n(e.g., 1999). Yet in his most recent contribution, Harman (2009: 241)\nsays, “I do not think that social psychology demonstrates there\nare no character traits”. For his part, Doris has repeatedly\nasserted that traits exist, and has repeatedly drawn attention to such\nassertions (Doris 1998: 507–509; 2002: 62–6; 2005: 667;\n2010: 138–141; Doris & Stich 2005: 119–20; Doris &\nPrinz 2009).  \nWith good reason, to say “traits do not exist” is\ntantamount to denying that there are individual dispositional\ndifferences, an unlikely view that character skeptics and antiskeptics\nare united in rejecting. Quite unsurprisingly, this unlikely view is\nseriously undersubscribed in both philosophy and psychology. It is\nendorsed by neither the most aggressive critics of personality,\nsituationists in social psychology such as Ross and Nisbett (1991),\nnor by the patron saint of situationism in personality psychology:\nMischel (1999: 45). Mischel disavows a trait-based approach, but his\nskepticism concerns a particular approach to traits, not\nindividual dispositional differences more generally.  \nThen the question of whether or not traits exist is emphatically\nnot the issue dividing more and less skeptical approaches to\ncharacter. Today, all mainstream parties to the debate are\n“interactionist”, treating behavioral outcomes as the\nfunction of a (complex) person by situation interaction (Mehl et al.\n2015)—and it’s likely most participants have always been\nso (Doris 2002: 25–6). Contemporary research programs in\npersonality and social psychology freely deploy both personal\nand situational variables (e.g., Cameron, Payne, & Doris 2013;\nLeikas, Lönnqvist, & Verkasalo 2012; Sherman, Nave, &\nFunder 2010). The issue worth discussing is not whether individual\ndispositional differences exist, but how these differences should\nbe characterized, and how (or whether) these individual\ndifferences, when appropriately characterized, should inform\nethical thought.  \nAn important feature of early forays into character skepticism was\nthat skeptics tended to focus on behavioral implications of\ntraits rather than the psychological antecedents of behavior\n(Doris 2015: 15). Defenders of virtue ethics observe that character\nskeptics have had much to say about situational variation in behavior\nand little to say about the psychological processes underlying it,\nwith the result that they overlook the rational order in\npeople’s lives (Adams 2006: 115–232). These virtue\nethicists maintain that the behavioral variation provoking character\nskepticism evinces not unreliability, but rationally appropriate\nsensitivity to differing situations (Adams 2006; Kamtekar 2004). The\nvirtuous person, such as Aristotle’s exemplary\nphronimos (“man of practical wisdom”) may\nsometimes come clean, and sometimes dissemble, or sometimes fight, and\nsometimes flee, depending on the particular ethical demands of his\ncircumstances. \nFor example, in the Good Samaritan Study, the hurried passersby was on\nthe way to an appointment where they had agreed to give a\npresentation; perhaps these people made a rational\ndetermination—perhaps even an ethically defensible\ndetermination—to weigh the demands of punctuality and\nprofessionalism over ethical requirement to check on the welfare of a\nstranger in apparent distress. However attractive one finds such\naccounting for this case (note that some of Darley and Batson’s\n[1973] hurried passersby failed to notice the victim, which strains\nexplanations in terms of their rational discriminations), there are\nother cases where the “rationality response” seems plainly\nunattractive. These are cases of ethically irrelevant influences\n (Sec. 2 above;\n Doris & Stich 2005), where it seems unlikely the influence could\nbe cited as part of a rationalizing explanation of the behavior:\nit’s odd to cite failing to find a dime as\njustification for failing to help—or for that matter,\nfinding a dime as justification for doing so. \nIt is certainly appropriate for virtue ethicists to emphasize\npractical rationality in their accounts of character. This is a\ncentral theme in the tradition going back to Aristotle himself, who is\nprobably the most oft-cited canonical philosopher in contemporary\nvirtue ethics. But while the rationality response may initially\naccommodate some of the troubling behavioral evidence, it encounters\nfurther empirical difficulty. There is an extensive empirical\nliterature problematizing familiar conceptions of rationality:\npsychologists have endlessly documented a dispiriting range of\nreasoning errors (Baron 1994, 2001; Gilovich et al. 2002; Kahneman et\nal. 1982; Tversky & Kahneman 1973; Kruger & Dunning 1999;\nNisbett & Borgida 1975; Nisbett & Ross 1980; Stich 1990;\nTversky & Kahneman 1981). In light of this evidence, character\nskeptics claim that the vagaries afflicting behavior also afflict\nreasoning (Alfano 2013; Olin & Doris 2014).  \nResearch supporting this discouraging assessment of human rationality\nis controversial, and not all psychologists think things are so bleak\n(Gigerenzer 2000; Gigerenzer et al. 1999; for philosophical commentary\nsee Samuels & Stich 2002). Nevertheless, if virtue ethics is to\nhave an empirically credible moral psychology, it needs to account for\nthe empirical challenges to practical reasoning: how can the relevant\nexcellence in practical reasoning be developed?  \nFaced with the challenge to practical rationality, virtue ethicists\nmay respond that their theories concern excellent reasoning,\nnot the ordinary reasoning studied in psychology. Practical\nwisdom, and the ethical virtue it supports, are expected to be\nrare, and not widely instantiated. This state of affairs, it\nis said, is quite compatible with the disturbing, but not\nexceptionlessly disturbing, behavior in experiments like\nMilgram’s (see Athanassoulis 1999: 217–219; DePaul 1999;\nKupperman 2001: 242–3). If this account is supposed to be part\nof an empirically contentful moral psychology, rather than unverified\nspeculation, we require a detailed and empirically substantiated\naccount of how the virtuous few get that way—remember that an\nemphasis on moral development is central to the virtue ethics\ntradition. Moreover, if virtue ethics is supposed to have widespread\npractical implications—as opposed to being merely a celebration\nof a tiny “virtue elite”—it should have an account\nof how the less-than-virtuous-many may at least tolerably\napproximate virtue.  \nThis point is underscored by the fact that for some of the troubling\nevidence, as in the Stanford Prison Study, the worry is not so much\nthat people fail standards of virtue, but that they fail standards of\nminimal decency. Surely an approach to ethics that celebrates\nmoral development, even one that acknowledges (or rather, insists)\nthat most people will not attain its ideal, might be expected to have\nan account of how people can become minimally decent. \nRecently, proponents of virtue ethics have been increasingly proposing\na suggestive solution to this problem: virtue is a skill acquired\nthrough effortful practice, so virtue is a kind of expertise (Annas\n2011; Bloomfield 2000, 2001, 2014; Jacobson 2005; Russell 2015; Snow\n2010; Sosa 2009; Stichter 2007, 2011; for reservations, see Doris, in\npreparation). The virtuous are expert at morality and—given the\nAristotelian association of virtue and happiness—expert at life.\n \nAn extensive scientific literature indicates that developing expert\nskill requires extensive preparation, whether the practitioner is a\nnovelist, doctor, or chess master—around 10,000 hours of\n“deliberate practice”, according to a popular\ngeneralization (Ericsson 2014; Ericsson et al. 1993). The\n“10,000–hour rule” is likely an oversimplification,\nbut there is no doubt that attaining expertise requires intensive\ntraining. Because of this, people rarely achieve eminence in more than\none area; for instance, “baseball trivia” experts display\nsuperior recall for baseball-related material, but not for\nnon-baseball material (Chiesi et al. 1979). Conversely, becoming\nexpert at morality, or (even more ambitiously) expert at the whole of\nlife, would apparently require a highly generalized form of\nexpertise: to be good, there’s a lot to be good at.\nMoreover, it’s quite unclear what deliberate practice at life\ninvolves; how exactly does one get better at being good?  \nOne obvious problem concerns specifying the “good” in\nquestion. Expertises like chess have been effectively studied in part\nbecause there are accepted standards of excellence (the\n“ELO” score used for ranking chess players; Glickman\n1995). To put it blithely, there aren’t any chess skeptics. But\nthere have, historically, been lots of moral skeptics. And if\nthere’s not moral knowledge, how could there be moral experts?\nAnd even if there are moral experts, there’s the problem of how\nare they to be identified, since it is not clear we are possessed of\nstandard independent of expert opinion itself (like winning chess\nmatches) for doing so (for the “metaethics of expertise”,\nsee McGrath 2008, 2011). \nEven if these notorious philosophical difficulties can be\nresolved—as defenders of expertise approaches to virtue must\nthink they can—matters remain complicated, because if moral\nexpertise is like other expertises, practice alone—assuming we\nhave a clear notion of what “moral practice”\nentails—will be insufficient. While practice matters in\nattaining expertise, other factors, such as talent, also matter\n(Hambrick et al. 2014; Macnamara et al. 2014). And some of the\nrequired endowments may be quite unequally distributed across\npopulations: practice cannot make a jockey into an NFL lineman, or an\nNFL lineman into a jockey.  \nWhat are the natural endowments required for moral expertise, and how\nwidely are they distributed in the population? If they are rare, like\nthe skill of a chess master or the strength of an NFL lineman, virtue\nwill also be rare. Some virtue ethicists believe virtue should be\nwidely attainable, and they will resist this result (Adams 2006:\n119–123, and arguably Aristotle Nicomachean Ethics\n1099b15–20). But even virtue ethicists who embrace the rarity of\nvirtue require an account of what the necessary natural endowments\nare, and if they wish to also have an account of how the less\nwell-endowed may achieve at least minimal decency, they should have\nsomething to say about how moral development will proceed across a\npopulation with widely varying endowments. \nWhat is needed, for the study of moral character research to advance,\nis an account of the biological, psychological, and social factors\nrequisite for successful moral development—on the expertise\nmodel, the conditions conducive to developing “moral\nskill”. This, quite obviously, is a tall order, and the research\nneeded to systematically address these issue is in comparative\ninfancy. Yet the expertise model, in exploiting connections with areas\nin which skill acquisition has been well studied, such as music and\nsport, provides a framework for moving discussion of character beyond\nthe empirically under-informed conjectures and assumptions about\n“habituation” that have been too frequent in previous\nliterature (Doris 2015: 128). \nPeople often behave in ways that benefit others, and they sometimes do\nthis knowing that it will be costly, unpleasant or dangerous. But at\nleast since Plato’s classic discussion in the second Book of the\nRepublic, debate has raged over why people behave in\nthis way. Are their motives altruistic, or is their behavior\nultimately motivated by self-interest? Famously, Hobbes gave this\nanswer: \nNo man giveth but with intention of good to himself, because gift is\nvoluntary; and of all voluntary acts, the object is to every man his\nown good; of which, if men see they shall be frustrated, there will be\nno beginning of benevolence or trust, nor consequently of mutual help.\n(1651 [1981: Ch. 15]) \nViews like Hobbes’ have come to be called\n egoism,[14]\n and this rather depressing conception of human motivation has any\nnumber of eminent philosophical advocates, including Bentham, J.S.\nMill and\n Nietzsche.[15]\n Dissenting voices, though perhaps fewer in number, have been no less\neminent. Butler, Hume, Rousseau and Adam Smith have all argued that,\nsometimes at least, human motivation is genuinely altruistic. \nThough the issue that divides egoistic and altruistic accounts of\nhuman motivation is largely empirical, it is easy to see why\nphilosophers have thought that the competing answers will have\nimportant consequences for moral theory. For example, Kant famously\nargued that a person should act “not from inclination but from\nduty, and by this would his conduct first acquire true moral\nworth” (1785 [1949: Sec. 1, parag. 12]). But egoism maintains\nthat all human motivation is ultimately self-interested, and\nthus people can’t act “from duty” in the\nway that Kant urged. Thus if egoism is true, Kant’s account\nwould entail that no conduct has “true moral worth”.\nAdditionally, if egoism is true, it would appear to impose a strong\nconstraint on how a moral theory can answer the venerable question\n“Why should I be moral?” since, as Hobbes clearly saw, the\nanswer will have to ground the motivation to be moral in the\nagent’s\n self-interest.[16] \nWhile the egoism vs. altruism debate has historically been of great\nphilosophical interest, the issue centrally concerns psychological\nquestions about the nature of human motivation, so it’s not\nsurprise that psychologists have done a great deal of empirical\nresearch aimed at determining which view is correct. Some of the most\ninfluential and philosophically sophisticated empirical work on this\nissue has been done by Daniel Batson and his associates. The\nconclusion Batson draws from this work is that people do\nsometimes behave altruistically, and that the emotion of empathy plays\nan important role in generating altruistic motivation.\n [17]\n Others are not convinced. For a discussion of Batson’s\nexperiments, the conclusion he draws from them, and some reasons for\nskepticism about that conclusion, see sections 5 and 6 of the entry\n“Empirical Approaches to Altruism” in this encyclopedia.\nIn this section, we’ll focus on some of the philosophical\nspadework that is necessary before plunging into the empirical\nliterature. \nA crucial question that needs to be addressed is: What, exactly, is\nthe debate about; what is altruism? Unfortunately, there is\nno uncontroversial answer to this question, since researchers in many\ndisciplines, including philosophy, biology, psychology, sociology,\neconomics, anthropology and primatology, have written about altruism,\nand authors in different disciplines tend to use the term\n“altruism” in quite different ways. Even among\nphilosophers the term has been used with importantly different\nmeanings. There is, however, one account of altruism—actually a\ncluster closely related accounts—that plays a central role both\nin philosophy and in a great deal of psychology, including\nBatson’s work. We’ll call it “the standard\naccount”. That will be our focus in the remainder of this\n section.[18] \nAccording to the standard account, an action is altruistic if it is\nmotivated by an ultimate desire for the well-being of another person.\nThis formulation invites questions about (1) what it is for a behavior\nto be motivated by an ultimate desire, and (2) the\ndistinction between desires that are self-interested and\ndesires that are for the well-being of others. \nAlthough the second question will need careful consideration in any\ncomprehensive treatment, a few rough and ready examples of the\ndistinction will suffice\n here.[19]\n Desires to save someone else’s life, to alleviate someone\nelse’s suffering, or to make someone else happy are paradigm\ncases of desires for the well-being of others, while desires to\nexperience pleasure, get rich, and become famous are typical examples\nof self-interested desires. The self-interested desires to experience\npleasure and to avoid pain have played an especially prominent role in\nthe debate, since one version of egoism, often called\nhedonism, maintains that these are our only ultimate\ndesires. \nThe first question, regarding ultimate desires, requires a fuller\nexposition; it can be usefully explicated with the help of a familiar\naccount of practical\n reasoning.[20]\n On this account, practical reasoning is a causal process via which a\ndesire and a belief give rise to or sustain another desire. For\nexample, a desire to drink an espresso and a belief that the best\nplace to get an espresso is at the espresso bar on Main Street may\ncause a desire to go to the espresso bar on Main Street. This desire\ncan then join forces with another belief to generate a third desire,\nand so on. Sometimes this process will lead to a desire to perform a\nrelatively simple or “basic” action, and that desire, in\nturn, will cause the agent to perform the basic action without the\nintervention of any further desires. Desires produced or sustained by\nthis process of practical reasoning are instrumental\ndesires—the agent has them because she thinks that satisfying\nthem will lead to something else that she desires. But not\nall desires can be instrumental desires. If we are to avoid\ncircularity or an infinite regress there must be some desires that are\nnot produced because the agent thinks that satisfying them\nwill facilitate satisfying some other desire. These desires that are\nnot produced or sustained by practical reasoning are the agent’s\nultimate desires, and the objects of ultimate desires, the\nstates of affairs desired, are desired for their own sake. A behavior\nis motivated by a specific ultimate desire when that desire\nis part of the practical reasoning process that leads to the\nbehavior. \nIf people do sometimes have ultimate desires for the well-being of\nothers, and these desires motivate behavior, then altruism is the\ncorrect view, and egoism is false. However, if all ultimate\ndesires are self-interested, then egoism is the correct view, and\naltruism is false. The effort to establish one or the other of these\noptions has given rise to a vast and enormously sophisticated\nempirical literature. For an overview of that literature, see the\n empirical approaches to altruism entry. \nGiven that moral disagreement—about abortion, say, or capital\npunishment—so often seems intractable, is there any reason to\nthink that moral problems admit objective resolutions? While this\ndifficulty is of ancient coinage, contemporary philosophical\ndiscussion was spurred by Mackie’s (1977: 36–8)\n“argument from relativity” or, as it is called by later\nwriters, the “argument from disagreement” (Brink 1989:\n197; Loeb 1998). Such “radical” differences in moral\njudgment as are frequently observed, Mackie (1977: 36) argued,\n“make it difficult to treat those judgments as apprehensions of\nobjective truths”. \nMackie supposed that his argument undermines moral realism,\nthe view that, as Smith (1994: 9, cf. 13) puts it,  \nmoral questions have correct answers, that the correct answers are\nmade correct by objective moral facts … and … by\nengaging in moral argument, we can discover what these objective moral\nfacts\n are.[21] \nThis notion of objectivity, as Smith recognizes, requires\nconvergence in moral views—the right sort of argument,\nreflection and discussion is expected to result in very substantial\nmoral agreement (Smith 1994:\n 6).[22] \nWhile moral realists have often taken pretty optimistic positions on\nthe extent of actual moral agreement (e.g., Sturgeon 1988: 229; Smith\n1994: 188), there is no denying that there is an abundance of\npersistent moral disagreement; on many moral issues there is a\nstriking failure of convergence even after protracted\nargument. Anti-realists like Mackie have a ready explanation for this\nphenomenon: Moral judgment is not objective in Smith’s sense,\nand moral argument cannot be expected to accomplish what Smith and\nother realists think it\n can.[23]\n Conversely, the realist’s task is to explain away\nfailures of convergence; she must provide an explanation of the\nphenomena consistent with it being the case that moral judgment is\nobjective and moral argument is rationally resolvable. Doris and\nPlakias (2008) call these “defusing explanations”. The\nrealist’s strategy is to insist that the preponderance of actual\nmoral disagreement is due to limitations of disputants or their\ncircumstances, and insist that (very substantial, if not\n unanimous)[24]\n moral agreement would emerge in ideal conditions,\nwhen, for example, disputants are fully rational and fully informed of\nthe relevant non-moral facts. \nIt is immediately evident that the relative merits of these competing\nexplanations cannot be fairly determined without close discussion of\nthe factors implicated in actual moral disagreements. Indeed, as acute\ncommentators with both realist (Sturgeon 1988: 230) and anti-realist\n(Loeb 1998: 284) sympathies have noted, the argument from disagreement\ncannot be evaluated by a priori philosophical means alone;\nwhat’s needed, as Loeb observes, is “a great deal of\nfurther empirical research into the circumstances and beliefs of\nvarious cultures”. This research is required not only to\naccurately assess the extent of actual disagreement, but also to\ndetermine why disagreement persists or dissolves. Only then\ncan realists’ attempts to “explain away” moral\ndisagreement be fairly assessed. \nRichard Brandt, who was a pioneer in the effort to integrate ethical\ntheory and the social sciences, looked primarily to anthropology to\nhelp determine whether moral attitudes can be expected to converge\nunder idealized circumstances. It is of course well known that\nanthropology includes a substantial body of work, such as the classic\nstudies of Westermarck (1906) and Sumner (1908 [1934]), detailing the\nradically divergent moral outlooks found in cultures around the world.\nBut as Brandt (1959: 283–4) recognized, typical ethnographies do\nnot support confident inferences about the convergence of attitudes\nunder ideal conditions, in large measure because they often give\nlimited guidance regarding how much of the moral disagreement can be\ntraced to disagreement about factual matters that are not moral in\nnature, such as those having to do with religious or cosmological\nviews. \nWith this sort of difficulty in mind, Brandt (1954) undertook his own\nanthropological study of Hopi people in the American southwest, and\nfound issues for which there appeared to be serious moral disagreement\nbetween typical Hopi and white American attitudes that could not\nplausibly be attributed to differences in belief about nonmoral\n facts.[25]\n A notable example is the Hopi attitude toward animal suffering, an\nattitude that might be expected to disturb many non-Hopis: \n[Hopi children] sometimes catch birds and make “pets” of\nthem. They may be tied to a string, to be taken out and\n“played” with. This play is rough, and birds seldom\nsurvive long. [According to one informant:] “Sometimes they get\ntired and die. Nobody objects to this”. (Brandt 1954: 213) \nBrandt (1959: 103) made a concerted effort to determine whether this\ndifference in moral outlook could be traced to disagreement about\nnonmoral facts, but he could find no plausible explanation of this\nkind; his Hopi informants didn’t believe that animals lack the\ncapacity to feel pain, for example, nor did they have cosmological\nbeliefs that would explain away the apparent cruelty of the practice,\nsuch as beliefs to the effect that animals are rewarded for martyrdom\nin the afterlife. The best explanation of the divergent moral\njudgments, Brandt (1954: 245, 284) concluded, is a “basic\ndifference of attitude”, since “groups do sometimes make\ndivergent appraisals when they have identical beliefs about the\nobjects”. \nMoody-Adams argues that little of philosophical import can be\nconcluded from Brandt’s—and indeed from\nmuch—ethnographic work. Deploying Gestalt psychology’s\ndoctrine of “situational meaning” (e.g., Dunker 1939),\nMoody-Adams (1997: 34–43) contends that all institutions,\nutterances, and behaviors have meanings that are peculiar to their\ncultural milieu, so that we cannot be certain that participants in\ncross-cultural disagreements are talking about the same\n thing.[26]\n The problem of situational meaning, she thinks, threatens\n“insuperable” methodological difficulty for those\nasserting the existence of intractable intercultural disagreement\n(1997: 36). Advocates of ethnographic projects will likely\nrespond—not unreasonably, we think—that judicious\nobservation and interview, such as that to which Brandt aspired,\ncan motivate confident assessments of evaluative diversity.\nSuppose, however, that Moody-Adams is right, and the methodological\ndifficulties are insurmountable. Now, there’s an equitable\ndistribution of the difficulty: if observation and interview are\nreally as problematic as Moody-Adams suggests, neither the\nrealists’ nor the anti-realists’ take on\ndisagreement can be supported by appeal to empirical evidence. We do\nnot think that such a stalemate obtains, because we think the\nimplicated methodological pessimism excessive. Serious empirical work\ncan, we think, tell us a lot about cultures and the differences\nbetween them. The appropriate way of proceeding is with close\nattention to particular studies, and what they show and fail to\n show.[27] \nAs Brandt (1959: 101–2) acknowledged, the anthropological\nliterature of his day did not always provide as much information on\nthe exact contours and origins of moral attitudes and beliefs as\nphilosophers wondering about the prospects for convergence might like.\nHowever, social psychology and cognitive science have recently\nproduced research which promises to further discussion; during the\nlast 35 years, there has been an explosion of “cultural\npsychology” investigating the cognitive and emotional processes\nof different cultures (Shweder & Bourne 1982; Markus &\nKitayama 1991; Ellsworth 1994; Nisbett & Cohen 1996; Nisbett 1998,\n2003; Kitayama & Markus 1999; Heine 2008; Kitayama & Cohen\n2010; Henrich 2015). Here we will focus on some cultural differences\nfound close to (our) home, differences discovered by Nisbett and his\ncolleagues while investigating regional patterns of violence in the\nAmerican North and South. We argue that these findings support\nBrandt’s pessimistic conclusions regarding the likelihood of\nconvergence in moral judgment. \nThe Nisbett group’s research can be seen as applying the tools\nof cognitive social psychology to the “culture of honor”,\na phenomenon that anthropologists have documented in a variety of\ngroups around the world. Although these groups differ in many\nrespects, they manifest important commonalities: \nA key aspect of the culture of honor is the importance placed on the\ninsult and the necessity to respond to it. An insult implies that the\ntarget is weak enough to be bullied. Since a reputation for strength\nis of the essence in the culture of honor, the individual who insults\nsomeone must be forced to retract; if the instigator refuses, he must\nbe punished—with violence or even death. (Nisbett & Cohen\n1996: 5) \nAccording to Nisbett and Cohen (1996: 5–9), an important factor\nin the genesis of southern honor culture was the presence of a herding\neconomy. Honor cultures are particularly likely to develop where\nresources are liable to theft, and where the state’s coercive\napparatus cannot be relied upon to prevent or punish thievery. These\nconditions often occur in relatively remote areas where herding is a\nmain form of subsistence; the “portability” of herd\nanimals makes them prone to theft. In areas where farming rather than\nherding dominates, cooperation among neighbors is more important,\nstronger government infrastructures are more common, and\nresources—like decidedly unportable farmland—are harder to\nsteal. In such agrarian social economies, cultures of honor tend not\nto develop. The American South was originally settled primarily by\npeoples from remote areas of Britain. Since their homelands were\ngenerally unsuitable for farming, these peoples have historically been\nherders; when they emigrated from Britain to the American South, they\ninitially sought out remote regions suitable for herding, and in such\nregions, the culture of honor flourished. \nIn the contemporary South, police and other government services are\nwidely available and herding has all but disappeared as a way of life,\nbut certain sorts of violence continue to be more common than they are\nin the North. Nisbett and Cohen (1996) maintain that patterns of\nviolence in the South, as well as attitudes toward violence, insults,\nand affronts to honor, are best explained by the hypothesis that a\nculture of honor persists among contemporary white non-Hispanic\nsoutherners. In support of this hypothesis, they offer a compelling\narray of evidence, including: \nTwo experimental studies—one in the field, the other in the\nlaboratory—are especially striking. \nIn the field study (Nisbett & Cohen 1996: 73–5), letters of\ninquiry were sent to hundreds of employers around the United States.\nThe letters purported to be from a hardworking 27-year-old Michigan\nman who had a single blemish on his otherwise solid record. In one\nversion, the “applicant” revealed that he had been\nconvicted for manslaughter. The applicant explained that he had been\nin a fight with a man who confronted him in a bar and told onlookers\nthat “he and my fiancée were sleeping together. He\nlaughed at me to my face and asked me to step outside if I was man\nenough”. According to the letter, the applicant’s nemesis\nwas killed in the ensuing fray. In the other version of the letter,\nthe applicant revealed that he had been convicted of motor vehicle\ntheft, perpetrated at a time when he needed money for his family.\nNisbett and his colleagues assessed 112 letters of response, and found\nthat southern employers were significantly more likely to be\ncooperative and sympathetic in response to the manslaughter letter\nthan were northern employers, while no regional differences were found\nin responses to the theft letter. One southern employer responded to\nthe manslaughter letter as follows: \nAs for your problems of the past, anyone could probably be in the\nsituation you were in. It was just an unfortunate incident that\nshouldn’t be held against you. Your honesty shows that you are\nsincere…. I wish you the best of luck for your future. You have\na positive attitude and a willingness to work. These are qualities\nthat businesses look for in employees. Once you are settled, if you\nare near here, please stop in and see us. (Nisbett & Cohen 1996:\n75) \nNo letters from northern employers were comparably sympathetic. \nIn the laboratory study (Nisbett & Cohen 1996: 45–8)\nsubjects—white males from both northern and southern states\nattending the University of Michigan—were told that saliva\nsamples would be collected to measure blood sugar as they performed\nvarious tasks. After an initial sample was collected, the unsuspecting\nsubject walked down a narrow corridor where an experimental\nconfederate was pretending to work on some filing. The confederate\nbumped the subject and, feigning annoyance, called him an\n“asshole”. A few minutes after the incident, saliva\nsamples were collected and analyzed to determine the level of\ncortisol—a hormone associated with high levels of stress,\nanxiety and arousal, and testosterone—a hormone associated with\naggression and dominance behavior. As Figure 1 indicates, southern\nsubjects showed dramatic increases in cortisol and testosterone\nlevels, while northerners exhibited much smaller changes. \nFigure 1 \nThe two studies just described suggest that southerners respond more\nstrongly to insult than northerners, and take a more sympathetic view\nof others who do so, manifesting just the sort of attitudes that are\nsupposed to typify honor cultures. We think that the data assembled by\nNisbett and his colleagues make a persuasive case that a culture of\nhonor persists in the American South. Apparently, this culture affects\npeople’s judgments, attitudes, emotion, behavior, and even their\nphysiological responses. Additionally, there is evidence that child\nrearing practices play a significant role in passing the culture of\nhonor on from one generation to the next, and also that relatively\npermissive laws regarding gun ownership, self-defense, and corporal\npunishment in the schools both reflect and reinforce southern honor\nculture (Nisbett & Cohen 1996: 60–63, 67–9). In short,\nit seems to us that the culture of honor is deeply entrenched in\ncontemporary southern culture, despite the fact that many of the\nmaterial and economic conditions giving rise to it no longer widely\n obtain.[28] \nWe believe that the North/South cultural differences adduced by\nNisbett and colleagues support Brandt’s conclusion that moral\nattitudes will often fail to converge, even under ideal conditions.\nThe data should be especially troubling for the realist, for despite\nthe differences that we have been recounting, contemporary northern\nand southern Americans might be expected to have rather more in\ncommon—from circumstance to language to belief to\nideology—than do, say, Yanomamö and Parisians. So if there\nis little ground for expecting convergence in the case at hand, there\nis probably little ground in a good many others. \nFraser and Hauser (2010) are not convinced by our interpretation of\nNisbett and Cohen’s data. They maintain that while those data do\nindicate that northerners and southerners differ in the strength of\ntheir disapproval of insult-provoked violence, they do not show that\nnortherners and southerners have a real moral disagreement. They go on\nto argue that the work of Abarbanell and Hauser (2010) provides a much\nmore persuasive example of a systematic moral disagreement between\npeople in different cultural groups. Abarbanell and Hauser focused on\nthe moral judgments of rural Mayan people in the Mexican state of\nChiapas. They found that people in that community do not judge\nactions causing harms to be worse than omissions\n(failures to act) which cause identical harms, while nearby urban\nMayan people and Western internet users judge actions to be\nsubstantially worse than omissions.  \nThough we are not convinced by Fraser and Hauser’s\ninterpretation of the Nisbett and Cohen data, we agree that the\nAbarbanell and Hauser study provides a compelling example of a\nsystematic cultural difference in moral judgement. Barrett et al.\n(2016) provides another example. That study looked at the extent to\nwhich an agent’s intention affected the moral judgments of\npeople in eight traditional small-scale societies and two Western\nsocieties, one urban, one rural. They found that in some of these\nsocieties, notably including both Western groups, the agent’s\nintention had a major effect, while in other societies agent intention\nhad little or no effect.  \nAs we said at the outset, realists defending conjectures about\nconvergence may attempt to explain away evaluative diversity\nby arguing that the diversity is to be attributed to shortcomings of\ndiscussants or their circumstances. If this strategy can be made good,\nmoral realism may survive an empirically informed argument from\ndisagreement: so much the worse for the instance of moral reflection\nand discussion in question, not so much the worse for the objectivity\nof morality. While we cannot here canvass all the varieties of this\nsuggestion, we will briefly remark on some of the more common forms.\nFor concreteness, we will focus on Nisbett and Cohen’s\nstudy. \nImpartiality. One strategy favored by moral realists\nconcerned to explain away moral disagreement is to say that such\ndisagreement stems from the distorting effects of individual interest\n(see Sturgeon 1988: 229–230; Enoch 2009: 24–29); perhaps\npersistent disagreement doesn’t so much betray deep features of\nmoral argument and judgment as it does the doggedness with which\nindividuals pursue their perceived advantage. For instance, seemingly\nmoral disputes over the distribution of wealth may be due to\nperceptions—perhaps mostly inchoate—of individual and\nclass interests rather than to principled disagreement about justice;\npersisting moral disagreement in such circumstances fails the\nimpartiality condition, and is therefore untroubling to the moral\nrealist. But it is rather implausible to suggest that North/South\ndisagreements as to when violence is justified will fail the\nimpartiality condition. There is no reason to think that southerners\nwould be unwilling to universalize their judgments across relevantly\nsimilar individuals in relevantly similar circumstances, as indeed\nNisbett and Cohen’s “letter study” suggests. One can\nadvocate a violent honor code without going in for special\n pleading.[29]\n We do not intend to denigrate southern values; our point is that\nwhile there may be good reasons for criticizing the honor-bound\nsoutherner, it is not obvious that the reason can be failure of\nimpartiality, if impartiality is (roughly) to be understood along the\nlines of a willingness to universalize one’s moral\njudgments. \nFull and vivid awareness of relevant nonmoral facts. Moral\nrealists have argued that moral disagreements very often derive from\ndisagreement about nonmoral issues. According to Boyd (1988: 213; cf.\nBrink 1989: 202–3; Sturgeon 1988: 229),  \ncareful philosophical examination will reveal … that agreement\non nonmoral issues would eliminate almost all disagreement\nabout the sorts of moral issues which arise in ordinary moral\npractice.  \nIs this a plausible conjecture for the data we have just considered?\nWe find it hard to imagine what agreement on nonmoral facts could do\nthe trick, for we can readily imagine that northerners and southerners\nmight be in full agreement on the relevant nonmoral facts in the cases\ndescribed. Members of both groups would presumably agree that the job\napplicant was cuckolded, for example, or that calling someone an\n“asshole” is an insult. We think it much more plausible to\nsuppose that the disagreement resides in differing and deeply\nentrenched evaluative attitudes regarding appropriate responses to\ncuckolding, challenge, and insult. \nSavvy philosophical readers will be quick to observe that terms like\n“challenge” and “insult” look like\n“thick” ethical terms, where the evaluative and\ndescriptive are commingled (see Williams 1985: 128–30);\ntherefore, it is very difficult to say what the extent of the factual\ndisagreement is. But this is of little help for the expedient under\nconsideration, since the disagreement-in-nonmoral-fact response\napparently requires that one can disentangle factual\nand moral disagreement. \nIt is of course possible that full and vivid awareness of the nonmoral\nfacts might motivate the sort of change in southern attitudes\nenvisaged by the (at least the northern) moral realist. Were\nsoutherners to become vividly aware that their culture of honor was\nimplicated in violence, they might be moved to change their moral\noutlook. (We take this way of putting the example to be the most\nnatural one, but nothing philosophical turns on it. If you like,\nsubstitute the possibility of northerners endorsing honor values after\nexposure to the facts.) On the other hand, southerners might insist\nthat the values of honor should be nurtured even at the cost of\npromoting violence; the motto “death before dishonor”,\nafter all, has a long and honorable history. The burden of argument,\nwe think, lies with the realist who asserts—culture and\nhistory notwithstanding—that southerners would change their\nmind if vividly aware of the pertinent facts. \nFreedom from “Abnormality”. Realists may contend\nthat much moral disagreement may result from failures of rationality\non the part of discussants (Brink 1989: 199–200). Obviously,\ndisagreement stemming from cognitive impairments is no embarrassment\nfor moral realism; at the limit, that a disagreement persists when\nsome or all disputing parties are quite insane shows nothing deep\nabout morality. But it doesn’t seem plausible that\nsoutherners’ more lenient attitudes towards certain forms of\nviolence are readily attributed to widespread cognitive disability. Of\ncourse, this is an empirical issue, but we don’t know of any\nevidence suggesting that southerners suffer some cognitive impairment\nthat prevents them from understanding demographic and attitudinal\nfactors in the genesis of violence, or any other matter of fact. What\nis needed to press home a charge of irrationality is evidence of\ncognitive impairment independent of the attitudinal\ndifferences, and further evidence that this impairment is implicated\nin adherence to the disputed values. In this instance, as in many\nothers, we have difficulty seeing how charges of abnormality or\nirrationality can be made without one side begging the question\nagainst the other. \nNisbett and colleagues’ work may represent a potent\ncounterexample to any theory maintaining that rational argument tends\nto convergence on important moral issues; the evidence suggests that\nthe North/South differences in attitudes towards violence and honor\nmight well persist even under the sort of ideal conditions under\nconsideration. Admittedly, such conclusions must be tentative. On the\nphilosophical side, not every plausible strategy for “explaining\naway” moral disagreement and grounding expectations of\nconvergence has been\n considered.[30]\n On the empirical side, this entry has reported on but a few studies, and\nthose considered, like any empirical work, might be\ncriticized on either conceptual or methodological\n grounds.[31]\n Finally, it should be clear what this entry is not claiming:\nany conclusions here—even if fairly earned—are not a\n“refutation” of all versions of moral realism, since there\nare versions of moral realism that do not require convergence\n(Bloomfield 2001; Shafer-Landau 2003). \nRather, this discussion should give an idea of the empirical work\nphilosophers must encounter, if they are to make defensible\nconjectures regarding moral disagreement. \nProgress in ethical theorizing often requires progress on difficult\npsychological questions about how human beings can be expected to\nfunction in moral contexts. It is no surprise, then, that moral\npsychology is a central area of inquiry in philosophical ethics. It\nshould also come as no surprise that empirical research, such as that\nconducted in psychology departments, may substantially abet such\ninquiry. Nor then, should it surprise that research in moral\npsychology has become methodologically pluralistic,\nexploiting the resources of, and endeavoring to contribute to, various\ndisciplines. Here, we have illustrated how such interdisciplinary\ninquiry may proceed with regard to central problems in philosophical\nethics.","contact.mail":"lachlan.walmsley@anu.edu.au","contact.domain":"anu.edu.au"}]
