[{"date.published":"2016-08-29","date.changed":"2019-01-29","url":"https://plato.stanford.edu/entries/phenomenal-intentionality/","author1":"David Bourget","author1.info":"http://www.dbourget.com/","author2.info":"http://publish.uwo.ca/~amendel5","entry":"phenomenal-intentionality","body.text":"\n\n\nPhenomenal intentionality is a kind of intentionality, or\naboutness, that is grounded in phenomenal consciousness, the\nsubjective, experiential feature of certain mental states. The\nphenomenal intentionality theory is a theory of\nintentionality according to which there is phenomenal intentionality,\nand all other kinds of intentionality at least partly derive from it.\nIn recent years, the phenomenal intentionality theory has increasingly been seen as one of the main\napproaches to intentionality.\nThe phenomenal intentionality theory is a theory of\nintentionality, the “aboutness” of mental states, on which phenomenal consciousness plays a central role in accounting for intentional states. Unlike many other contemporary theories of intentionality, which aim to account for intentionality in terms of causal relations, information, functional roles, or other “naturalistic” ingredients, the phenomenal intentionality theory’s main ingredient is phenomenal consciousness, the felt, subjective, or “what it’s like” (Nagel 1974) aspect\nof mental life. Accordingly, Pautz (2013) describes the general approach as taking a\n“consciousness first” approach to intentionality, since it claims that consciousness either grounds or is explanatorily prior to intentionality, and Kriegel (2011a, 2013a) describes the approach as one\non which consciousness is the “source” of intentionality. (These ways of characterizing the phenomenal intentionality theory suggest a reductive picture, on which intentionality is reduced to or explained in terms of consciousness,\nbut in section 2.3 we will see that some versions of the phenomenal intentionality theory are not reductive.)\n \nBy explaining intentionality in terms of phenomenal consciousness, the phenomenal intentionality theory challenges the received view of the past few decades that the mind divides into two\nmutually exclusive and independent types of states: intentional states\nand phenomenal states (see Kim 1998 for a clear articulation of the\nreceived view). According to the phenomenal intentionality theory, intentional states and phenomenal\nstates are intimately related. Some intentional states are constituted by phenomenal states, and the rest are in some way importantly related to phenomenal states. \nPhenomenal intentionality has been discussed under that label only\nrecently (see, e.g., Horgan and Tienson 2002 and Loar 2003, and related\ninfluential work by Searle, Siewert, and others), but many modern\nphilosophers have suggested a close relation between thought, which is\ncharacteristically intentional, and perception, which is\ncharacteristically phenomenal, or consciousness itself. For example, rationalists\nsuch as Descartes held that all cognition is conscious, while empiricists such as Hume and Locke held that all cognition is grounded in perceptual experience. Later, Brentano, Husserl and the phenomenologists that they influenced conceived of intentionality\nprimarily as a conscious phenomenon. Like the phenomenal intentionality theory, the views of these figures can\nbe understood as taking a “consciousness first” approach. For more on the history of the phenomenal intentionality theory, see Kriegel (2013a) and the entry Consciousness and Intentionality.\n  \nIn this article we describe various versions of the phenomenal intentionality theory, their\nmotivations, the challenges they face, and their relations to other views. \nIntentionality is the “aboutness” or “directedness”of mental\nstates. For example, a thought that snow is white “says” or represents that snow is white. Similarly, your\ncurrent visual experience might represent a blue cup or that there is\na blue cup in front of you. When a state exhibits intentionality, it involves the instantiation of an intentional\nproperty, a property of representing something. What the state\nrepresents is its (intentional) content. In this article, we\nuse the term “state” for instantantiations of properties,\nwhich are sometimes called token states. (See the entries \n Intentionality\n and\n Mental Representation.)\n  \nPhenomenal consciousness is the felt, subjective, or\n“what it’s like” aspect of mental states (see Nagel\n1974). Paradigmatic examples of phenomenal states include perceptual\nexperiences, pains, emotional feelings, episodes of mental imagery,\nand cognitive experiences such as the experience of déjà\nvu. Each of these states has a characteristic phenomenal character—there is something that it’s like to be in it. When there is\nsomething that it is like for a subject, we can say that she\ninstantiates a phenomenal property, or that she has a\nphenomenal state. (See the entry\n Consciousness.)\n  \nPhenomenal intentionality is intentionality that is\nconstituted by phenomenal consciousness. A phenomenal intentional\nstate is an intentional state that is constituted by a subject’s phenomenal states. For example, someone who accepts phenomenal intentionality might say that a perceptual intentional state representing a red cube is constituted by a reddish-cube-ish phenomenal state—the reddish-cube-ish phenomenal experience automatically and necessarily results in the representation of a red cube. We will call intentional states that are not phenomenal intentional states non-phenomenal intentional state. PIT takes phenomenal intentionality to play a central role in accounting for intentional phenomena. The next subsections discuss ways that this initial gloss on PIT can be precisified.  A central idea common to phenomenal intentionality theories is that phenomenal intentionality plays an important role in the mind. The next subsections discuss ways that this idea can be precisified.  The following three theses about the relationship between phenomenal\nintentional states and intentional states are ways of precisifying the idea that phenomenal intentionality plays an important role in the mind: \nThe “all” in the above theses should be\nunderstood as quantifying over all actual intentional states, not all\nmetaphysically possible intentional states. In the same way that some\nphysicalist theories of intentionality allow that there are merely\npossible forms of intentionality that are independent of physical\nproperties, PIT can allow that there are non-actual intentional states\nthat have nothing to do with phenomenal consciousness. Of course, more\nspecific versions of PIT might make stronger claims.  Of the three views mentioned above, Strong PIT asserts the strongest\npossible relationship between phenomenal intentionality and\nintentionality: it claims that phenomenal intentionality is the only\nkind of intentionality there is. Relatively few hold this view, but\nversions of it have been defended by Pitt (2004), Farkas (2008a), and\nMendelovici (2010, 2018). The difficulty with this view, as we will see\nbelow, is that it is not clear that there are enough phenomenal states\nor phenomenal states of the right kind to constitute all intentional\nstates. For example, it is not easy to see how standing beliefs like\nyour belief that grass is green could be constituted by phenomenal\nstates. Moderate PIT is significantly weaker than Strong PIT. It is compatible with the\nexistence of non-phenomenal intentional states but claims that any\nsuch non-phenomenal intentional states are at least partly grounded in\nphenomenal intentional states.  \nThere are different ways of explicating the intuitive notion of\ngrounding used in the definition of Moderate PIT. For our purposes\nhere, we can say that A grounds B when B obtains\nin virtue of A. This gloss is itself in need of further\nanalysis, but for now it is enough to know that grounding is an\nasymmetric relation of metaphysical determination (see Trogdon 2013\nfor an introduction to grounding). An example of grounding that is\nsimilar to the grounding relation posited by some proponents of\nModerate PIT is the (alleged) grounding of linguistic meaning in\nspeaker intentions: on many views of language, words have their\nmeanings in virtue of speakers’ intentions toward them. To say\nthat A is partly grounded in B is to that say\nthat A is grounded in the combination of B and other\nfactors. \nThere are different views of how phenomenal intentionality might\npartly ground non-phenomenal intentionality: \nOne view is that non-phenomenal intentional states are simply\ndispositions to have phenomenal intentional states and that these\ndispositions get their contents from the phenomenal intentional states\nthat they are dispositions to bring about (Searle 1983, 1990, 1991,\n1992). On this view, standing beliefs about grass that are not\nphenomenal intentional states are dispositions to have phenomenal intentional states with the same or related contents. \nAnother view is that non-phenomenal intentional states get their\nintentionality from functional relations they bear to phenomenal\nintentional states (Loar 2003a, Horgan & Tienson 2002, Graham,\nHorgan, & Tienson 2007). On this view, a standing belief that\ngrass is green might have its content in virtue of being suitably\nconnected to a host of phenomenal intentional states. \nA third view is that non-phenomenal intentionality is a matter of\nideal rational interpretation (Kriegel 2011a,b, Pautz 2013). On Kriegel’s view, for example, the relevant phenomenal intentional states are in the mind of a possible ideal\nrational interpreter. \nMore versions of Moderate PIT will be discussed below. Proponents of\nModerate PIT (or something close to it) include Loar (1987, 1988,\n1995, 2003a, 2003b), Searle (1983, 1990, 1991, 1992), Goldman\n(1993a,b), Siewert (1998), McGinn (1988), Kriegel (2003, 2011a,b),\nHorgan, Tienson & Graham (2003, 2004, 2006, 2007), Georgalis\n(2006), Pitt (2004, 2009, 2011), Farkas (2008a,b, 2013), Mendola\n(2008), Chalmers (2010: xxiv), Bourget (2010), Pautz (2010, 2013),\nSmithies (2012, 2013a, 2013b, 2014), and Montague (2016). \nWeak PIT merely claims that there is phenomenal intentionality. It\nallows that there are non-phenomenal intentional states that have\nnothing to do with phenomenal consciousness. The proponents of Weak\nPIT are too many to list. As we will see below, Weak PIT is entailed\nby some widely accepted views in philosophy of mind, including many\nforms of representationalism about phenomenal consciousness, the view\nthat phenomenal states are identical to intentional states (perhaps that meet certain further conditions). \nSince Moderate PIT is the strongest view that is endorsed by most\nproponents of the general approach, it is the view that\nhas the best claim to being the phenomenal intentionality\ntheory. For this reason, this article will focus mainly on Moderate\nPIT. Unless otherwise indicated, we will use “PIT” to\nrefer to Moderate PIT. (Note that Strong PIT is a version of Moderate PIT, while Weak PIT is not a version of PIT at all, but rather a weakening of the view.) \nOur definition of phenomenal intentional states is neutral between two\ntypes of views regarding how phenomenal states constitute intentional\nstates. On grounding views, phenomenal intentional states are\ngrounded in phenomenal states (either in individual states or in sets\nof such states). Since grounding is asymmetric, this view implies that\nphenomenal intentional states are distinct from the phenomenal states\nthat ground them. In contrast, identity views take the\nrelation that obtains between phenomenal intentional states and\nphenomenal states (in virtue of which the former are constituted by\nthe latter) to be that of identity: certain instantiations of\nintentional properties are identical to instantiations of phenomenal\nproperties. On this view, phenomenal intentional states are identical\nto individual phenomenal states or sets of phenomenal states.  \nFarkas (2008a,b), Pitt (2004) (though not in Pitt 2009), and Woodward (2016, forthcoming-a) defend a\ngrounding version of PIT. It is also possible to read Horgan and\nTienson (2002) as holding a grounding version of PIT, since they take\nthe relevant relation between phenomenal intentionality and phenomenal\nconsciousness to be that of “constitutive determination”,\nwhich might be understood as a kind of grounding relation. Other\nproponents of PIT, such as Mendelovici (2018), favor an identity view.  \nWe can also distinguish between versions of PIT that are reductive and\nversions that are not. To a first approximation, a theory of\nintentionality is reductive if it specifies the nature of\nintentionality in terms that are supposed to be more basic or\nfundamental. A theory that is not reductive\nmight either be neutral on the question of reduction or incompatible with\nreduction.  \nAll grounding versions of (Moderate or Strong) PIT are reductive. Such\nviews entail that all intentionality is ultimately grounded in\nphenomenal states. Since grounding is asymmetric, the grounding\nphenomenal states cannot themselves be intentional and are more\nfundamental than intentional states.  An identity version of (Moderate\nor Strong) PIT will be reductive if it holds or entails that\nphenomenal intentional states are identical to phenomenal states and\nthat phenomenal descriptions are more fundamental than intentional\ndescriptions (just as “H2O” descriptions are\nmore fundamental than “water” descriptions). If such views\nare correct, it should be possible to understand phenomenal states\nindependently of intentionality. \nVersions of (Moderate or Strong) PIT that identify phenomenal intentional\nstates with phenomenal states can also be nonreductive. On such\nnonreductive views, phenomenal descriptions of intentional states are\nnot more fundamental then intentional descriptions. Exactly which\nversions of PIT that identify phenomenal intentional states with\nphenomenal states are reductive or nonreductive is an open\nquestion. \nRegardless of whether PIT provides a reductive account of\nintentionality in general, versions of Moderate PIT that allow for\nnon-phenomenal intentional states aim to reduce such states to\nphenomenal intentionality and other ingredients, so they provide a\nreductive account of at least some intentional states. We will discuss\nsome of these views below. \nAn important dimension of variation between versions of PIT\nconcerns the extent of phenomenal intentionality. The disagreement here\ncuts across the disagreement between Moderate and Strong PIT.\nFor example, Loar (2003a), who falls in the Moderate PIT camp, mostly\nlimits phenomenal intentionality to perceptual and other sensory\nstates. In contrast, other advocates of Moderate PIT (for example,\nStrawson (1994) and Pitt (2004)) claim that many thoughts have phenomenal\nintentionality. Most theorists maintain that unconscious subpersonal\nstates, such as states in early visual processing or unconscious\nlinguistic processing, lack phenomenal intentionality, though Bourget\n(2010, forthcoming-b), Pitt (2009,\n Other Internet Resources), and Mendelovici (2018)\n claim that some such states might have phenomenal intentionality that\nwe are unaware of.  \nPhenomenal intentionality theorists also disagree on which mental\nstates, if any, have non-phenomenal intentionality. Horgan &\nTienson (2002) and Kriegel (2011a) claim that at least some\nunconscious subpersonal states have non-phenomenal intentionality,\nwhile Searle (1990, 1991, 1992) and Mendelovici (2018) deny this.\nSearle (1990, 1991, 1992) takes at least some standing states, such as\nnon-occurrent beliefs and desires, to have non-phenomenal\nintentionality, which Strawson (2008) and Mendelovici (2018) deny.\n Another important question concerns the structure of phenomenal intentionality. Some proponents of phenomenal intentionality hold that it has a relational structure (Pautz 2010, 2013; Speaks 2015; Bourget forthcoming-a, forthcoming-c), while others (Farkas 2008a,b; Kriegel 2011a,b, 2013; Mendelovici 2018; Pitt 2009) deny this. We briefly discuss this question in Section 4.6. \nThis section outlines some important relations between PIT and other\nviews. \nReductive PIT stands in contrast with two well-known classes of\nreductive theories of intentionality: tracking theories\n(Stampe 1977, Dretske 1988, 1995, Millikan 1984, Fodor 1987), which\ntake the content of mental states to be a matter of\ncausal-informational-historical links between them and things in the\nenvironment (see the entries on\n causal theories of mental content\n and\n teleological theories of mental content),\n and conceptual role theories, which take the content of\nmental states to be a matter of their relations to other mental states\nand sometimes to the external world (Block 1986, Harman 1987,\nGreenberg & Harman 2007). (See the section\n Conceptual role\n in the entry on\n narrow mental content.)\n Reductive PIT also contrasts with primitivism, the view that\nintentionality cannot be reduced. Reductive PIT is a competitor to\ntracking, conceptual role, and primitivist theories in that it is an\nalternative account of the grounds of intentionality.\nVersions of PIT that are not reductive are also competitors to these\ntheories, but to a more limited extent: they only offer an alternative\nexplanation of the grounds of non-phenomenal intentional states. Such\nviews are compatible with reducing phenomenal intentional states to\ntracking states and similar states.  \nWhile PIT offers a different account of the grounds of intentionality\nthan conceptual role and tracking theories, it is noteworthy that all\nversions of PIT are, strictly speaking, compatible with these theories.\nIt could turn out that PIT is true but phenomenal consciousness\nreduces to conceptual role or tracking, making both PIT and the tracking\nor conceptual role theory true.  \nRepresentationalism (or intentionalism) is the view\nthat phenomenal states are intentional states that meet certain\nfurther conditions (Harman 1990, Dretske 1995, Lycan 1996, Tye 2000,\nByrne 2001, Chalmers 2004; see also the entry\n Representational Theories of Consciousness).\n As in the case of PIT, some versions of representationalism are\nreductive while others are not. When one says that phenomenal states\nare intentional states that meet certain conditions, one might intend\nthis as a reduction of phenomenal consciousness or one might merely\nintend to point out a true identity. As in the case of PIT, many\nproponents of representationalism take the view to be reductive.  \nThe reductive versions of representationalism and PIT are\nincompatible: if consciousness reduces to intentionality, then\nintentionality does not reduce to consciousness, and vice-versa.\nHowever, versions of PIT and representationalism that are not\nreductive are compatible. It is common for the two views to be\ncombined: many advocates of PIT also endorse a version of\nrepresentationalism, claiming that all phenomenal states are also\nrepresentational states (Horgan and Tienson 2002, Graham, Horgan, and\nTienson 2007, Pautz 2010, Mendelovici 2013, 2018, Bourget 2010). In the\nother direction, representationalism, as we are understanding the\nview, is committed to Weak PIT, because it entails that some\nintentional states are phenomenal states. \nAnother view of the relationship between intentionality and\nconsciousness is what Horgan & Tienson dub\n“separatism”, the view that consciousness and\nintentionality are wholly distinct mental phenomena (see e.g., Kim\n1998). On this view, consciousness and intentionality do not bear\ninteresting metaphysical relations to each other. For example, there\nis no identity or grounding relation between them (separatists reject\nboth PIT and representationalism). Separatism is typically associated\nwith the view that consciousness is limited to perceptual and sensory\nstates, and intentionality is limited to beliefs, desires, and other\npropositional attitudes.  \nThis section overviews the main arguments and motivations for PIT. \nHorgan and Tienson (2002) argue for the claim that “[t]here is a\nkind of intentionality, pervasive in human mental life, that is\nconstitutively determined by phenomenology alone” (2002: 520).\nThis is a (fairly strong) version of Weak PIT. They do so by arguing\nfor the following two principles: \nWe take IOP to say that each paradigmatic phenomenal property has an\nassociated intentional content such that, necessarily, all instances\nof the property have this associated content. We take POI to say that each\nparadigmatic intentional property has some associated phenomenal character such\nthat, necessarily, all instances of the property have this associated phenomenal\ncharacter. \nHorgan and Tienson defend IOP by appealing to broadly phenomenological\nconsiderations: \nYou might see, say, a red pen on a nearby table, and a chair with red\narms and back a bit behind the table. There is certainly something\nthat the red you see is like to you. But the red that you see is seen,\nfirst, as a property of objects. These objects are seen as located in\nspace relative to your center of visual awareness. And they are\nexperienced as part of a complete three-dimensional scene—not\njust a pen with table and chair, but a pen, table, and chair in a room\nwith floor, walls, ceiling, and windows. This spatial character is\nbuilt into the phenomenology of the experience. (Horgan & Tienson\n2002: 521, footnote suppressed)  The basic idea is that introspective consideration of paradigmatic phenomenal states suggests that they are intentional. This argument echoes the transparency\nconsiderations for representationalism (see the entry Representational Theories of Consciousness). \nHorgan and Tienson’s case for POI (the phenomenology of\nintentionality) rests primarily on detailed phenomenological\nobservations purporting to show that there are phenomenological\nfeatures corresponding to most contents of propositional attitudes as\nwell as the attitudes of belief and desires. We discuss these arguments\nin\n section 5. \nWith IOP and POI in hand, Horgan and Tienson proceed to argue for the\nwidespread existence of phenomenal intentionality. The following is a reconstruction of the key steps of their argument:  \nThe general idea is that phenomenal states, with their phenomenally\ndetermined intentionality, bring in their train much of the rest of\nthe “web of belief”. \nHorgan and Tienson argue for the transition from\n (1)\n to\n (2)\n by articulating in some detail how the contents of perceptual\nexperiences, either individually or in groups, bring in their train\nperceptual beliefs. A key idea, supported by POI, is that perceptual\nbeliefs and other attitudes towards perceptible contents have\nphenomenal characters closely associated with them. For example, there\nis a phenomenology of accepting various contents as true. The\nsuggestion is that once one has a vast number of perceptual\nexperiences with their associated perceptual contents and feelings of\naccepting and rejecting some of these, one qualifies as having a number of perceptual beliefs. \nRegarding the transition from\n (2)\n to\n (3),\n a key idea, again derived from POI, is that non-perceptual beliefs\nhave extensive phenomenology. For example, according to Horgan and\nTienson, there is something that it’s like to wonder whether to\ncook meatloaf for dinner. The phenomenology of such non-perceptual\nthoughts, together with one’s vast collection of perceptual\nbeliefs and perceptual experiences, fixes a large number of\nnon-perceptual beliefs and other non-perceptual propositional\nattitudes.\n (4)\n combines conclusions\n (1)–(3). \nThe following considerations, while not exactly Horgan and\nTienson’s, seem to go in the same direction as their line of\nargument: If all beliefs and desires have phenomenal characters unique\nto them, as Horgan and Tienson take themselves to have established,\nthen phenomenal duplicates will share these phenomenal characters. By\nIOP, these phenomenal characters must determine contents. Plausibly,\nthey determine the contents of the beliefs and desires that they\ncharacterize. So if an individual has a given belief with content C,\nthen his or her phenomenal duplicate has this content as the content\nof a phenomenal experience. Moreover, the duplicate has a feeling of accepting\nC. It is then quite plausible that the duplicate believes\nC. \nHorgan and Tienson’s argument establishes Weak PIT, but it does\nnot yet establish any version of Moderate PIT. It could be that many\nintentional states are phenomenal intentional states but some\nintentional states are neither phenomenal intentional states nor\ngrounded in phenomenal intentionality (Bailey and Richards (2014)\npoint out related limitations of the argument). However, when combined\nwith Horgan and Tienson’s arguments for the claim that many\nnon-phenomenal intentional states are grounded in phenomenal\nintentionality (more on this view below), we have some support for\nModerate PIT.  Mendelovici (2018) also argues for Moderate PIT on the grounds of metaphysical sufficiency: The ingredients invoked by alternative theories of intentionality, such as tracking and functional role theories, are not metaphysically sufficient for intentionality. For instance, it is unclear why having internal states\nplaying certain functional roles should result in those internal states representing a particular content, or any content at all. Likewise, while tracking relations relate us to items that may seem to be well-suited to playing the role of content, such as objects, properties, and states of affairs, it is mysterious how tracking such items could make them psychologically relevant to us. For instance, it is unclear how merely tracking such items can make them introspectively accessible, available to reason with, or in any sense “entertained”. (See also BonJour 1998 for similar worries with tracking and functional role theories.) In contrast, PIT’s central ingredient, phenomenal consciousness, is arguably metaphysically sufficient for intentionality. For instance, it is arguably inconceivable for there to be someone with a reddish phenomenal experience who does not thereby represent redness. If all this is right, then there is reason to think that phenomenal consciousness alone is metaphysically sufficient for intentionality, which supports Moderate PIT. \nSiewert (1998) argues for Weak PIT by arguing that phenomenal states are\nautomatically assessable for accuracy. A key element of\nSiewert’s argument is his assumption that phenomenal characters\ncan be identified with “how it seems for it to look some way to\nsomeone”. We take this to mean that phenomenal states are states\nof things seeming a certain way, where the relevant kind of seeming is\nthe kind we are familiar with from cases where things look a certain\nway in perception (perhaps there are other kinds of seemings that are\nnot phenomenal states). Siewert’s argument is contained in the\nfollowing passage, in which we have added numbers corresponding to the\npremises: \nFirst, consider some instance of its seeming to you as it does for it\nto look as if something is shaped and situated in a certain way, such\nas its seeming to you just as it does on a given occasion for it to\nlook as if there is something X-shaped in a certain position. (1) If\nit seems this way to you, then it appears to follow that it does look\nto you as if there is something X-shaped in a certain position. (3) If\nthis is right, then its seeming this way to you is a feature in virtue\nof which you are assessable for accuracy—(5) that is to say, it\nis an intentional feature. For, from what we have said, (2) if it\nseems to you as it does for it to look this way, then, if it is also\nthe case that there is something X-shaped in a certain position, it\nfollows that the way it looks to you is accurate. (Siewert 1998: 221)\n \nSiewert suggests that this argument straightforwardly generalizes to a\nlarge number of perceptual experiences.  \nLet S be the phenomenal state in which it seems to you just as\nit does on a given occasion for it to look as if there is something\nX-shaped in a certain position. The argument in the above quotation can be\nbroken down as follows:  \nSiewert does not explicitly defend premises\n (1)\n and\n (2).\n (4) is defended in section 6.2 of the book. \nOne might object that\n (3)\n does not follow from\n (1)\n and\n (2).\n Perhaps S is such that, necessarily, things being a certain\nway (or not) would make the bearer of S accurate (or not), but\nit is not in virtue of being in S that its bearer is\nassessable for accuracy. The assessability might come from the\ninevitable addition of an interpretation to S in all\ncircumstances. Siewert argues against this possibility extensively\nbetween pages 222 and 245, ruling out various sources of\ninterpretation.  \nGertler (2001) objects that there is an alternative explanation of\nSiewert’s observations about the co-occurrence of phenomenal and\nintentional properties: intentional properties automatically give rise\nto phenomenal properties. Gertler argues that Siewert has not ruled\nout this alternative, and so fails to establish PIT. See Siewert 2004 for a response. \nIt is possible to argue for PIT on the basis of internalism\nabout mental content, the view that what a subject’s mental\nstates represent is fully determined by her intrinsic properties. (The\nalternative to internalism is externalism. Intentional\ncontent that is determined by a subject’s intrinsic properties\nis said to be narrow as opposed to wide. See the\nentries on\n narrow mental content\n and\n externalism about mental content.) \nLoar (2003a) argues from internalism to PIT.\nFirst, Loar proposes the following two desiderata for a theory of\nintentionality: (1) The theory should be a non-referential theory,\nwhere a non-referential theory is a theory that does not take\nintentionality to be a matter of reference to external entities, for\nexample, concrete or abstract objects. This desideratum is motivated\nby internalism. (Note that, for Loar, intentionality is not the same\nthing as reference, and so a non-referential theory of intentionality\ndoes not commit one to denying that there is such a thing as\nreference.) (2) The theory should accommodate externalism about\nreference and truth-conditions (see, e.g., Putnam 1975, Burge 1979,\nKripke 1980).  \nLoar then argues that internalist views that do not appeal to phenomenal consciousness fail to meet\ndesiderata (1) and (2). The first view he considers is short-arm\nfunctionalism, the view that causal interactions between brain states\ngive rise to intentionality. The second view is a version of\n the descriptivist theory of reference\n combined with short-arm functionalism about its primitive\nrepresentations. Having excluded these views, he argues that a version\nof PIT can meet his two desiderata. Phenomenal properties are\ninherently intentional in that they exhibit directedness, or purport\nto refer. Since purporting to refer is not the same thing as\nreferring, the result is non-referential mental content. This\nsatisfies the first desideratum.  \nLoar argues that his view satisfies the second desideratum by arguing\nthat phenomenal properties do not by themselves secure reference or\ntruth-conditions. Instead, reference and truth-conditions are a matter\nof externally-determined relations, as externalists such as Putnam\n(1975), Burge (1979), and Kripke (1980) claim. However, which\nexternally-determined relations matter for reference depends on a\nsubject’s non-referential internalist content. Horgan, Tienson,\n& Graham (2004) also suggest that PIT is the best available theory\nof narrow content and suggest that phenomenal intentionality can provide a basis for externalist content. \nAnother argument for PIT involves appeal to brain in a vat scenarios (see Loar 2003a and Horgan, Tienson & Graham 2004). A brain in a\nvat duplicate is an exact physical duplicate of a normally\nembodied human brain that is kept in a vat of life-sustaining liquids\nand is hooked up to a computer that delivers to it the same kinds of\nstimulation its embodied twin receives. It intuitively seems that a\nbrain in a vat would have a mental life “matching” that of\nits embodied twin. The brain in a vat and its twin would have matching\nperceptual experiences, perceptual judgments, and beliefs. For\nexample, when the embodied twin believes that she is lying on the\nbeach sipping a frappé, the brain in a vat twin believes that\nthey are lying on the beach sipping a frappé. However, while\nthe normal subject’s belief might be true, the envatted\nsubject’s beliefs, and many other of their mental states, would\nbe false or non-veridical. \nFarkas (2008a) agrees with Loar and Horgan et al. (2004) that PIT is\nthe best available theory of narrow content but criticizes Loar\n(2003a) and Horgan et al. (2004) for making a concession to\nexternalism by allowing for externally-determined\nreference, truth-conditions, or broad content. Instead,\nFarkas argues that internalist, phenomenally-constituted\nintentionality is all that a theory of intentionality needs. \nWilson (2003) objects to Loar’s appeal to brains in vats,\nclaiming that intuitions concerning them are theoretical intuitions\nand are likely to be rejected by many of PIT’s opponents.  \nIn an early defense of PIT, Searle (1990, 1991, 1992) puts forth an\nargument based on the “aspectual shapes” of intentional\nstates. The argument is rather complex and open to several\ninterpretations, but here is one simplified way of understanding it:\nSearle begins by noting that all intentional states have an aspectual\nshape, where an aspectual shape is a matter of how something\nis represented. For example, there is a difference between\nrepresenting Hesperus and representing Phosphorus, or representing\nSuperman and representing Clark Kent. The differences lie not in\nwhich objects are represented, but in how they are\nrepresented—these are differences in their aspectual shapes.  \nSearle then argues that no internal or external unconscious physical\nor functional facts can determine aspectual shapes. The only thing\nthat can determine aspectual shape is consciousness. If that is so,\nthen it looks like unconscious states can only have their aspectual\nshapes in virtue of their connections to conscious states. Searle\nconcludes, more specifically, that unconscious intentional states\ninvolve dispositions to have conscious states, a thesis that he calls\nthe connection principle. (Sometimes he says that unconscious\nstates are potentially accessible to consciousness,\napparently meaning that they can be introspected consciously\n(1992, p. 156), but other times he says what we say here: that\nunconscious states involve dispositions to have conscious states\n(1992, p. 159, 161–162). The latter is what Searle says as part\nof his argument for the connection principle, and this interpretation\nis more in line with the argument he deploys.)  \nIn sum, the argument seems to go as follows: \nAccording to the argument’s conclusion, all intentional states\nare either phenomenal intentional states or involve dispositions to\nhave such states. This is a version of Moderate PIT. \nSearle’s arguments have elicited a large number of responses.\nFodor and Lepore (1994) argue that there is no suitable way of cashing\nout what it would take for a state to be potentially\nconscious such that Searle’s claims are both plausible and\ntendentious (i.e., that they entail, as Searle claims, that much of\ncognitive science’s appeal to non-conscious intentional states\nis misguided). For a response, see Searle 1994. Davies\n(1995) argues that Searle might be right about a kind of\nintentionality but that there are other kinds of intentionality\ninvoked in cognitive science that are not dependent on consciousness.\nVan Gulick (1995) argues that Searle’s notion of aspectual shape\nsmuggles in the notion of consciousness, and that on a less\ncontentious understanding of aspectual shape, his argument that\nconsciousness is the only way of accounting for aspectual shape does\nnot succeed. Baaren (1999) also takes issue with the notion of\naspectual shape. See also the commentaries accompanying Searle 1990.\n \nAnother line of argument for PIT similar to Searle’s aspectual shape argument is an argument from content determinacy. Graham, Horgan & Tienson (2007) and\nHorgan & Graham (2012) argue that it is difficult to see how\nunconscious neural activity, functional role, dispositions to\nbehavior, and other possible physical bases of intentionality can\nyield the sorts of determinate contents we manifestly represent (see\nalso Dennett 1987, Quine 1960: ch. 2, and Kripke 1982). For example,\nno causal, functional, or purely physical features of one’s\nbrain or environment seem to make it the case that one is thinking\nabout rabbits rather than undetached-rabbit-parts. A\nMartian looking down on Earth with complete knowledge of all\nEarthly physical facts could not tell whether we are representing\nrabbits or undetached rabbit parts. Thus, it appears that a\nphysical-functional theory of intentionality will predict that\none’s concept RABBIT is indeterminate between the two contents.\n \nSimilarly, nothing about our brains, their finite dispositions, or\ntheir environments indicates that our word “plus” means\nthe plus operator rather than a Kripkean quus\noperator, an operator that works just like plus when the operands are\nless than 57 and returns 5 when either operand is 57 or greater (see\nKripke 1982). If we do determinately represent plus and\nrabbits, something other than tracking relations,\ndispositions towards behaviors, internal functional roles, or brain\nstates has to determine this. Along similar lines, Strawson (2008)\nargues that phenomenal intentional facts about what we take an\nintentional state to refer to play a key role in determining what an\nintentional state refers to.  \nSome argue that phenomenal consciousness is capable of explaining\ncontent determinacy. According to Graham, Horgan and Tienson, there is\na phenomenal difference between representing rabbits and representing\nundetached-rabbit-parts. Since PIT claims that phenomenal intentional\ncontent is determined by phenomenal character, it allows that the two\nstates have distinct contents. The supposition that there is\nhigh-level cognitive phenomenology corresponding to such\nabstract contents as rabbits and\nundetached-rabbit-parts is key to this argument. This is a\ncontroversial claim, but one that is quite central to many versions of\nPIT. We discuss this claim in\n section 5.\n  \nArguments for PIT from content determinacy rely on the strong claim\nthat the totality of physical facts do not fix content determinately\nand that content is fixed determinately. While PIT does not entail\ndualism about consciousness, PIT combined with this claim does (see Pautz 2013, who objects to arguments for PIT from content determinacy for related reasons). This claim will be resisted by anyone who thinks that physicalism about the mind is\nwell-motivated. One might say that the intuition that physical facts\ncannot fix determinate contents arises from the fact that we do not\nhave a suitably good understanding of how intentionality arises from\nphysical facts; had we such an understanding, the intuition would\ndisappear.  \nRelationalism about intentionality is the view that\nintentionality is a relation to distinctly existing entities that\nserve as contents. Non-relationalism about intentionality\nis the view that\nintentionality is not a relation to distinctly existing entities that\nserve as contents.  \nKriegel (2007, 2011a) argues that a non-relational view of intentionality\nprovides the best explanation of how we can represent things that\ndon’t exist, such as Bigfoot, and that PIT is the best candidate\nnon-relational view of intentionality. Kriegel first argues that the\nfollowing three intuitively appealing claims are inconsistent: \nOne of these claims needs to be rejected. Kriegel argues that it is\n (c),\n the claim that asserts relationalism. His’s argument\nproceeds by a process of elimination. \nKriegel considers rejecting\n (a).\n On this proposal, when we seem to represent dragons, Bigfoot, or\nSanta Claus, we either fail to have an intentional state or we\nrepresent something else. One reason Kriegel rejects the first option\nis that it implies that there is a gap between trying to represent and\nrepresenting, which he takes to be implausible. On the second option,\nwhen we seem to represent non-existent concrete entities, we are\nreally just representing something else, such as existent abstract\nentities (e.g., universals or propositions), existent mental entities\n(e.g., sense data or ideas), or existent possible but non-actual\nentities. But Kriegel takes this option to be highly counterintuitive.\nWhen we seem to be thinking about concrete flesh-and-blood Bigfoot, we\nare in fact thinking about an abstract or mental entity. (See, however, Mendelovici 2018, section 9.3.1 for a response to this line of argument.)\nAnother worry\nis that accounting for the representation of non-existents seems like\nthe wrong kind of reason to accept the existence of these abstract,\nmental, or merely possible entities. \nAnother option is to reject\n (b).\n Kriegel argues that just as a monadic property cannot be instantiated\nwithout an existing particular that instantiates it, so too a relation\ncannot be instantiated without existing particulars that instantiate\nit. In short, it is a general rule that relations require relata.\nRejecting\n (b)\n is tantamount to claiming that the intentionality relation is an\nexception to this general rule, which is implausible. \nKriegel concludes that we should reject\n (c).\n He calls his non-relational view “adverbialism”, since it\ndraws its inspiration from the adverbialist views of perception of\nDucasse (1942) and Chisholm (1957). According to Kriegel’s\nadverbialism, representing Bigfoot is not standing in a relation to an\nentity, but rather instantiating a non-relational intentional\nproperty, which we might describe as the property of representing\nBigfoot-wise. \nSo far, this only motivates adverbialism. The final step of the\nargument motivates PIT: One objection to adverbialism is that it is\nmysterious what non-relational intentional properties are. What is it\nto represent Bigfoot-wise? Kriegel suggests that a plausible account\nof these properties is that they are phenomenal properties. Phenomenal\nproperties are usually taken to be non-relational and there is\nindependent reason to think they give rise to intentionality (see the\nother arguments in this section). The resulting picture is one on\nwhich phenomenal intentionality is non-relational. Kriegel suggests\nthat this view can be combined with the view that non-phenomenal\nintentionality is derived from phenomenal intentionality and is\nrelational.  \nIn short, Kriegel’s argument attempts to show that PIT is the\nbest way to account for the representation of non-existents. \nThis argument motivates non-relational versions of PIT. However, it\ndoes not motivate relational versions of PIT, on which intentionality\nis relational. Loar (2003a), Pitt (2009), Kriegel (2007, 2011a), and\nMendelovici (2010, 2018) hold non-relational versions of PIT, while Pautz\n(2013) and Bourget (forthcoming-a, forthcoming-c) defend a relational version of PIT, on which both phenomenal properties and intentional properties are relational. Speaks (2015) also defends a relational view of phenomenal representation (without endorsing PIT).\n Arguing in the direction opposite the preceding considerations, some have challenged PIT on the grounds that intentionality is relational. Ott (2016) raises worries for PIT along such lines, arguing that most versions of PIT fail to adequately explain how phenomenal consciousness can give rise to intentionality, which he takes to necessarily involve a relation to extra-mental reality. There are two lines of response open to phenomenal intentionalists: One is to maintain that phenomenal consciousness is itself relational in the relevant way. Pautz (2010) and Bourget (forthcoming-a, forthcoming-c) argue that consciousness is a relation to items in extra-mental reality, such as clusters of abstract properties or abstract propositions. Of course, this response gives up on the benefits of non-relational PIT alleged by Kriegel. (Bourget (forthcoming-c) responds to some of Kriegel’s arguments against relationalism.) Another response is to deny that intentionality secures the required relation to extra-mental reality. Along such lines, Mendelovici (2018, sections 1.3.4 and 9.3.4) argues that it is a substantive question whether intentionality on its own or with the help of additional ingredients secures such a relation. Of course, whether this is so depends on what exactly we mean by “intentionality”. If intentionality involves such a relation by definition, then there is no further substantive question to be asked. But if, as Mendelovici (2010, 2018) and Kriegel (2010) suggest, the core notion of intentionality leaves open this aspect of its nature, it might very well turn out that intentionality does not involve such relations.  Even if intentionality does not involve a relation to extra-mental reality, one might worry that it should at least play a role in facilitating such a relation and that PIT cannot allow for this. But Ott (2016) suggests that PIT can in fact connect us to extra-mental reality through relations of resemblance. Similarly, Mendelovici (2018, chapter 9) argues that intentionality does not involve a connection to extra-mental reality but that truth and reference do and that truth and reference are a matter of a special kind of superficial resemblance called “matching”. Woodward (forthcoming-b) and Bourget (forthcoming-b) challenge Mendelovici’s account of truth and reference for non-relational versions of PIT.  Another line of argument for PIT begins by noting that theories of intentionality, combined with certain facts about the world, often make predictions as to what particular intentional states represent. For example, a causal theory of intentionality combined with the fact that cows often cause tokens of the concept COW might predict that COW represents the content cow, which might be the property of being a cow.  One line of argument for PIT is based on the claim that PIT makes correct predictions in certain paradigm cases of intentionality that other theories fail to accommodate. One such case is that of color experience: It is plausible (though not undisputed) that color experiences represent what Chalmers (2006) calls “Edenic colors”—primitive, non-physical, qualitative properties (see also Pautz 2006a, 2009). This might be supported by introspection, epistemic considerations, and considerations of psychological role. But since Edenic colors are arguably not instantiated, it is difficult for causal, informational, teleological, and other “tracking” theories of intentionality to allow us to represent them. Instead, such theories predict that perceptual color representations represent the likes of particular dispositions to reflect, emit, or transfer light of particular wavelengths. In contrast, since Edenic colors “match” the phenomenal characters of color experience, PIT has the resources to make the correct predictions in the case of color experiences. Mendelovici (2018) refers to this as the argument from matching for PIT. Pautz (2006b) makes a related argument against tracking representationalism and for primitivist representationalism based on a structural mismatch between the contents represented by color experience and the properties color experiences track. See also Causal Theories of Mental Content. \nThe argument from predictive accuracy purports to show that PIT is the only theory of intentionality that stands a chance of being empirically adequate (whether it can indeed handle all the cases depends on whether it can deal with challenging cases, such as those discussed in section 6). It does not make a complete case for PIT, but it is an important consideration as part of the overall case for PIT. \n We will briefly mention a few other lines of argument for PIT. One revolves around the idea that norms of rationality are\nconstitutive of (non-phenomenal) intentional states. Pautz writes: \nConsciousness grounds rationality because it is implicated in basic\nepistemic norms. … In turn, the facts about rationality help to\nconstitutively determine belief and desire (Davidson, Lewis). So\nconsciousness also ultimately grounds belief and desire. (Pautz 2014:\n176)  \nThis line of argument combines two claims that have been defended\nindependently. The first is a view of non-phenomenal states (chiefly,\npropositional attitudes) on which they derive their contents from\nnorms of rationality (Davidson 2001, Lewis 1983, Chalmers 2012). The\nsecond is the view that consciousness plays a role in determining\nrational norms (Siewert 1998, Campbell 2002, Smithies 2012, 2014). In\naddition to the above passage from Pautz, this argument for PIT is\nalso made in Chalmers 2012: 467 and Pautz 2013: 226. \nAnother line of argument for PIT is that there is nothing to determine\nwho a given non-conscious state of mind belongs to unless that state\nconsists in a disposition to produce a conscious mental state of the\nright sort (Ludwig 1996). Kriegel (2003) similarly argues that only\nPIT can account for the fact that intentional states have a subjective\nor “for-me” character.  \nMany defenses and elaborations of PIT maintain that occurrent thoughts\nhave a rich and varied phenomenology. Such a view of thought is\nrequired by versions of PIT that claim that the contents we normally\nattribute to thoughts are phenomenal contents (see\n section 6.2).\n Cognitive phenomenology is also a widely debated topic independently\nof any connection to PIT (see, e.g., Cognitive Phenomenology,\nedited by Bayne and Montague 2011). \nAdvocates of PIT that take thought content to be phenomenal content\nmainly focus on arguing for the following two claims:  \nThe term “proprietary” is due to David Pitt (2004).\nThought has a proprietary phenomenal character just in case\nthe phenomenal characters of thoughts are special or unique to\nthought, i.e., they are not perceptual, verbal, bodily, or affective\nphenomenal characters, or other phenomenal characters that are present\nin mental states other than thoughts. Following current usage, we call\nall of the aforementioned kinds of phenomenology sensory\nphenomenology and the putative proprietary phenomenology of\nthought cognitive phenomenology. The claim that thought has a\nproprietary phenomenology is then just the claim that it has a\nnon-sensory phenomenology. \nThoughts have individuative phenomenal characters just in\ncase thoughts with different intentional contents have different\nphenomenal characters and thoughts with different phenomenal\ncharacters have different intentional contents. (We use\n“individuative” in the way Bayne and Montague (2011: ch.\n1) use it. Pitt (2004) uses the term “distinctive” for a\nsimilar notion and the term “individuative” to mean\nsomething else.)  \nWhile most advocates of PIT take thoughts to have individuative\nphenomenal characters, this isn’t required by PIT. Grounding PIT can allow\nthat there is a one-many grounding relation between contents and\nphenomenal characters. For example, phenomenal properties r1\nand r2 might both ground the intentional property of\nrepresenting red421. If all intentional properties\nwere grounded in this way, PIT would be true, but (Individuative)\nmight not be. \nIt is possible for thoughts to have proprietary but not individuative\nphenomenal characters. For example, suppose every thought came with\neither a generic feeling of understanding or a generic feeling of\nconfusion. These phenomenal characters might be proprietary in that\nthey do not occur outside of thoughts, but they are not individuative,\nsince thoughts with different intentional contents might have the same\nphenomenal characters. \nIt is also possible for thoughts to have individuative but not\nproprietary phenomenal characters. For example, suppose every thought\ncame with a different kind of perceptual imagery. Then thoughts with\ndifferent contents would have different phenomenal characters, but\nthese phenomenal characters would not be special to thoughts, since\nperceptual states could have them too. \nIn addition to the claims that there is a proprietary and an\nindividuative phenomenology of thought, advocates of PIT usually aim\nto establish that thought’s content is phenomenal intentional\ncontent and thus that thought’s intentional properties are\nobtained in the requisite way from phenomenal properties.  \nWhile much of the discussion of the phenomenology of thought involves\ncareful argumentation and consideration of cases, it is worth\nmentioning that many advocates of a proprietary phenomenology of\nthought find the view obvious and the negation of the view clearly\nfalse or even absurd. Strawson writes: \nTo deny this [cognitive phenomenology], one must hold that the total\nlifelong character of our lived experience—everything that life\nis to us experientially—consists entirely of bare or pure\nsensation or feeling of one kind or another. It must, for example, be\nfalse to say that anguish at someone’s death includes\nconscious comprehending believing entertaining of the\nproposition that he is dead. (Strawson 2011a: 295, italics in\noriginal)  \nIn a similar vein, Kriegel writes: \nFor my part, I am persuaded of the existence of cognitive experience\n[…] most vividly by something like everyday experiential\noverwhelm: it simply seems that my inner life is much more interesting\nto me than it would be if my conscious experience consisted merely in\nperceptual experiences. (Kriegel 2011a: 50)  \nIn what follows we discuss the main arguments that have been offered\nto supplement such appeals to the alleged obviousness of cognitive\nphenomenology. \nPhenomenal contrast cases are cases of two thoughts that are\nalike in sensory phenomenal character but differ in thought content.\n \nSiewert (1998) asks his readers to compare an experience of hearing or\nreading a sentence without understanding, as when one reads a\ndifficult passage without paying attention to it, and an experience of\nhearing or reading a sentence with understanding. There is\nclearly a phenomenal difference between these cases. Siewert argues\nthat the difference is not a difference in verbal or perceptual\nimagery, since the verbal and perceptual imagery might be the same in\nboth cases. The best explanation of the phenomenal contrast is that\nthought involves proprietary cognitive phenomenology.  \nStrawson (1994) argues for a kind of “understanding\nexperience” by contrasting the cases of a monolingual English\nspeaker and a monolingual French speaker listening to the news in\nFrench. The experiences of the two subjects differ in a way that is\nnot fully explained by a difference in sensory phenomenology. The best\nexplanation involves a difference in cognitive phenomenology. Siewert\n(1998) also employs examples involving the comparison of hearing\nsentences in familiar versus unfamiliar languages.  \nAs it stands, Strawson’s argument can only establish that\nthought has a proprietary phenomenology, but Kriegel (2011a: 49)\nextends it to argue that thought has an individuative phenomenology.\nHe asks us to imagine a case of two languages involving graphically\nand phonetically identical words such that the same report can be\ninterpreted in one language as describing a faraway war and in the\nother language a children’s bedtime story. Monolingual speakers\nof each language will experience different phenomenal characters upon\nreading or hearing this report. The best explanation of this involves\na difference in cognitive phenomenology. This supports the claim that\ncognitive phenomenology is individuative.  \nOther arguments from phenomenal contrast cases aim to create the\ncontrasting experiences in the reader herself. Horgan and Tienson\n(2002) present the reader with sentences that are likely to give rise\nto two different interpretations, such as the following:  \nOn one reading, the sentence is about the act of visiting relatives.\nOn another reading, the sentence is about relatives that visit. Both\nreadings are likely to generate the same verbal imagery, but they\ndiffer in content. Horgan and Tienson encourage the reader to notice\nthat they also differ in phenomenal character. If this is right, then\nthis suggests that thought has a proprietary and individuative\nphenomenology.  \nThe following sentences are also used to generate phenomenal contrast\ncases: \n\n (Dogs)\n might at first be read without understanding, but might\nsubsequently be read with understanding, giving rise to a phenomenal\ncontrast case.\n (Time)\n can be read as a cliché or as a command at the insect races.\n (Bar)\n can be read as being about an aborted legal career or a trip around\ntown. Again, the claim is that these different readings of the\nsentences give rise to different phenomenal experiences and that the\nbest explanation of this is that thought has a proprietary and\nindividuative phenomenology.  \nThough instances of pairs of thoughts differing in intentional content\nand differing in phenomenal character provide some evidence for the\nexistence of individuative cognitive phenomenology, in order for the\nthesis that thought has a individuative phenomenology to be true,\nthere have to be no cases of thoughts that are alike in content but\nthat differ in phenomenal character. This latter kind of case would be a counterexample to (Individuative). Wilson (2003) responds to Horgan\nand Tienson by accepting their observations in their phenomenal\ncontrast cases but attempting to provide such a counterexample:  \nIn the spirit of Horgan and Tienson’s appeal for a reader to\n“pay attention to your own experience” ([2002] p. 521), I\nhave just done the decisive experiment: I thought first that George\nBush is President of the United States, and had CNN-mediated auditory\nand visual phenomenology that focussed on one of his speeches. I then\ntook a short break, doodled a little, wandered around the room, and\nthen had a thought with that very same content and … nothing.\nOr at least nothing distinctly Bush-like, as in the first case.\n(Wilson 2003: 417)  \nIf Wilson is right, this not only shows that arguments based on\nphenomenal contrast ultimately fail, but also provides positive\nconsiderations against (Individuative), since it shows that there can\nbe thoughts with the same contents that fail to have the same\nphenomenal character.  \nVersions of PIT that\n require only a one-many relation\n between phenomenal intentional content and phenomenal character, and\nhence that do not need to endorse (Individuative), can accommodate\nobservations such as Wilson’s putative observation, since they\nallow that multiple phenomenal characters can ground or constitute the\nsame phenomenal intentional content.  \nAnother kind of objection to arguments from phenomenal contrast involves agreeing\nthat there is a phenomenal difference between the relevant cases but\nclaiming that this difference is exhausted by sensory phenomenology,\nwhere this might include the phenomenology of perceptual imagery,\naffective experience, or verbal imagery (see, e.g., Lormand 1996, Tye\nand Wright 2011, Levine 2011, Robinson 2011, Carruthers and Veillet\n2011). What makes the phenomenal contrast cases described above\nvulnerable to this kind of objection is that they do not control for\nall potential accompanying perceptual imagery. This leaves open the\npossibility that the observed phenomenal differences are fully\naccounted for by such imagery.  \nChudnoff (2013) provides a phenomenal contrast case that he claims\navoids this reply. He asks his readers to compare the experience of an\narray of dots to an experience of the same array of dots experienced\nas part of a proof for a mathematical theorem. In the second\nexperience, but not in the first, the perceptual experience involves\ncognitive phenomenology. The array of dots is in some sense\nexperienced as part of a larger whole, representative of something, or\nin some sense meaningful. (Chudnoff 2015a,b also contain extensive\ncritical discussions of phenomenal contrast cases.) \nOne might worry that, like the original phenomenal contrast cases,\nChudnoff’s case does not control for certain forms of\naccompanying imagery, in this case, verbal imagery. The adamant\nopponent of cognitive phenomenology might insist that just as the\nphenomenal differences in the phenomenal contrast cases involving\nsentences might be explained by perceptual imagery, the differences in\nChudnoff’s cases can be accounted for by differences in verbal\nphenomenology.  \nIt might seem that what is needed is a phenomenal contrast case that\nplausibly controls for both verbal and perceptual phenomenology, as\nwell other kinds of sensory phenomenology. Mendelovici (2010: 107)\nargues that thoughts about chiliagons (one-thousand sided figures) and\nmegagons (one-million sided figures) might involve the same mental\nimagery (both shapes effectively look like circles) and so might\nprovide the basis for such cases. Imagine a person who mistakenly uses\nthe word “megagon” to mean chilliagon. Compare\nher experience of viewing a chilliagon and thinking that it is a\nchilliagon with your experience of viewing a megagon and thinking that\nit is a megagon. Since you both use the word “megagon” to\ndescribe the shape you are thinking about, and since the two\nshapes are perceptually similar, you will likely have the same\nperceptual and verbal imagery. If there is a phenomenal difference\nbetween the two cases, it is plausibly attributed to a difference in\nthought content. \nSiewert (1998, 2011) claims that sudden realizations are cases in\nwhich cognitive phenomenology is particularly noticeable.  \n[Y]ou are standing at the door to your house, reaching in your pants\npocket for the door key, and find it empty. You feel a sudden panic;\nyou think perhaps you have locked yourself out; you try to remember\nwhere you put the keys, then recall switching them to your coat pocket\nearlier; you reach and find them there—relief. (Siewert 1998:\n277)  \nI meet a friend, and she asks me, “Did you bring the\nbook?” For a moment I am at a loss as to what book she’s\ntalking about—and then I realize in an instant what book it is.\n(Siewert 2011: 258)  \nSiewert claims that such realizations needn’t involve any verbal\nor perceptual imagery. In the case of the first example, you\ndon’t think the words “I have locked myself out” or\nvisualize your keys. Siewert takes these and other similar examples to\nshow that thought has a proprietary phenomenology.  \nSimilarly, in order to argue that the phenomenal properties of thought\nare not merely associated with verbal imagery, Horgan and Tienson\n(2002) point to examples of spontaneous thoughts we have when engaging\nin activities such as cooking or working in a garage or woodshop: \nThere is something that it is like to think that a certain tool is\njust there—in that cabinet, say—but such beliefs are\ntypically not verbalized either vocally or subvocally or by way of\nverbal imagery. (Horgan and Tienson 2002: 523)  \nLike Siewert’s examples, this example helps motivate the claim\nthat thought has a proprietary phenomenology.  \nThis line of argument relies heavily on introspection. Unfortunately, detractors of\ncognitive phenomenology (for example, Robinson 2011 and Tye &\nWright 2011) claim that their own observations of sudden realization\nreveal less phenomenology, resulting in an apparent stalemate.  \nSome experiences with a cognitive character seem to make a fairly good\ncase for a minimal amount of proprietary phenomenology of thought. For\nexample, Goldman (1993a) invokes the tip-of-the-tongue phenomenon to\nargue that thought has a proprietary phenomenology, an argument he\nattributes to Jackendoff (1987).  \nWhen one tries to say something but can’t think of the word, one\nis phenomenologically aware of having requisite conceptual structure,\nthat is, of having a determinate thought-content one seeks to\narticulate. What is missing is the phonological form: the sound of the\nsought-for word. The absence of this sensory quality, however, does\nnot imply that nothing (relevant) is in awareness. Entertaining the\nconceptual unit has a phenomenology, just not a sensory phenomenology.\n(Goldman 1993a: 24)  \nThe tip-of-the-tongue phenomenon occurs when one cannot think of a\nword, so it involves the absence of verbal phenomenology\ncorresponding to that word. But instances of this phenomenon do\ninvolve some phenomenology. Goldman proposes that this\nphenomenology is non-sensory.  \nLormand (1996) responds to this suggestion by providing an alternative\naccount of the relevant phenomenology on which it is sensory, which he\nalso takes to be supported by Jackendoff 1987. According to Lormand,\nthe relevant phenomenology involves a sensory phenomenal experience of\na void, which is akin to hearing silence, along with an experience of\neffort, whose phenomenology is also sensory.  \nPhenomenal consciousness has various epistemic markers: It gives rise\nto (at least the appearance of) an explanatory gap (see Levine 1983\nand the entry on\n consciousness),\n it is susceptible to zombie thought experiments (see Chalmers 1996\nand the entry on\n zombies),\n and it is susceptible to the knowledge argument (see Jackson 1982 and\nthe entry Qualia: The Knowledge Argument).\n These arguments usually focus on sensory phenomenal consciousness.\nFor example, Levine’s central example is that of pain and\nJackson’s is that of experiencing red.  \nThe initial plausibility of these kinds of arguments might be taken to\nserve as an indicator of phenomenal consciousness: plausibly, if these\narguments have some traction with some mental state, then that mental\nstate is likely to have phenomenal properties. Some have used the\npresence or absence of such markers to argue for or against cognitive\nphenomenology. \nGoldman (1993b) argues that a version of Jackson’s (1982)\nthought experiment can be run with propositional attitudes, such as\ndoubt and disappointment:  \nJackson’s example is intended to dramatize the claim that there\nare subjective aspects of sensations that resist capture in\nfunctionalist terms. I suggest a parallel style of argument for\nattitude types. Just as someone deprived of any experience of colors\nwould learn new things upon being exposed to them, viz., what it feels\nlike to see red, green, and so forth, so (I submit) someone who had\nnever experienced certain propositional attitudes, e.g., doubt or\ndisappointment, would learn new things on first undergoing these\nexperiences. There is “something it is like” to have these\nattitudes, just as much as there is “something it is like”\nto see red. (Goldman 1993b: 365)  \nIn other words, Goldman argues that Jackson’s thought experiment\nis compelling in the case of propositional attitudes and that this\nsupports the claim that propositional attitudes have proprietary\nphenomenal properties above and beyond functional properties.\n(Presumably, Goldman intends his argument to apply only to occurrent\npropositional attitudes, since he takes standing states to be purely\ndispositional (1993b: 366).) Goff (2012) makes similar observations.\n \nHorgan (2011a) also uses epistemic indicators of phenomenal\nconsciousness to argue for cognitive phenomenology. He argues that\nsince partial zombies lacking cognitive phenomenology are conceivable\nand phenomenally different from us, we have cognitive phenomenology.\n \nInterestingly, Carruthers and Veillet (2011) use epistemic indicators\nto argue against cognitive phenomenology. They claim that thought is\nnot susceptible to the explanatory gap, and thus that there is no\ncognitive phenomenology.  \nPitt (2004) argues that there is a kind of self-knowledge that can\nonly be explained by cognitive phenomenology. Pitt’s argument\nnot only aims to establish that there is a proprietary and\nindividuative cognitive phenomenology but also that this\nphenomenology is constitutive of thought’s content,\ni.e., that thought’s content is phenomenal intentional content.\n \nPitt’s argument runs as follows: Normally, we can consciously,\nintrospectively, and non-inferentially (1) distinguish an occurrent\nthought from other mental states, (2) distinguish an occurrent thought\nfrom other occurrent thoughts, and (3) identify which occurrent\nthoughts we are thinking. Pitt considers various explanations of these\nabilities, and argues that the only plausible explanation is that\nthought has a proprietary, individuative, and constitutive\nphenomenology. Thought’s proprietary phenomenology explains how\nwe can tell the difference between thoughts and other kinds of mental\nstates, thought’s individuative phenomenology explains how we\ncan tell the difference between one thought and another, and\nthought’s phenomenology being constitutive of its content\nexplains how we can identify which thoughts we are thinking.  \nLevine (2011) argues that Pitt (2004) fails to rule out an alternative\nexplanation of the relevant kind of self-knowledge: immediate\nself-knowledge is a matter of non-inferentially coming to have an\nintentional state that represents that one is thinking what one is in\nfact thinking. In having such a state, one is automatically aware of\nits content. Pitt (2011) responds that, when properly understood,\nLevine’s proposal can’t work unless there is the contested\nkind of cognitive phenomenology.  \nGoldman (1993a,b) also uses considerations from self-knowledge to\nargue for a phenomenology of thought. He argues that the way we can\ntell what mental states we are in is not through their functional\nroles or neural properties, but through their phenomenal properties.\nIn the case of cognitive states, the best explanation for how we can\ndiscriminate between different strengths of desires or degrees of\nbelief is that thoughts have an accompanying phenomenology.  PIT faces both in-principle challenges and empirical challenges. We\nhave already discussed the in-principle worry that phenomenal\nconsciousness is not metaphysically sufficient for intentionality\n(see section 4.1). Here, we\nfocus on the empirical challenges PIT faces in accommodating specific\nkinds of mental states.  The problematic mental states are those that might reasonably be taken to have intentionality without having phenomenal intentionality. Here we will discuss four types of mental\nstate that give rise to challenges of this kind: thoughts, standing\npropositional attitudes, wide intentional states, and occurrent\nunconscious states. These states don’t seem to be phenomenal\nintentional states, so it is not immediately clear how PIT can accommodate\nthem. \nThere are three general strategies for handling a problematic state:\neliminativism, inflationism, and derivativism. Eliminativism\nconsists in denying the existence of the putative intentional state\n(or denying that it is an intentional state).\nInflationism consists in claiming that the state in question\nis a phenomenal intentional state. In the case of thought, this\nstrategy often involves arguing for rich cognitive phenomenology (see\n section 5).\n Derivativism agrees that the problematic state is not a\nphenomenal intentional state, but maintains that it nonetheless\nderives its content in part from phenomenal intentional states and so is at least partly grounded in such states. We will now discuss these\nstrategies in more detail in relation to the four problematic kinds of\nstates.  \nThoughts are occurrent conceptual states, the kinds of states we have when we think, reflect, or muse over something. Examples of thoughts include\njudgments, occurrent beliefs, and occurrent desires. Thoughts, especially thoughts\nabout abstract ideas such as democracy and the square root function,\nmight seem to lack phenomenal properties. Even if thoughts have\nphenomenal properties, it does not seem that these phenomenal\nproperties are rich or determinate enough to fully account for their\nintentional properties. For example, these phenomenal properties might seem to be\nlimited to verbal and visual imagery.  \nInflationism is the most widely endorsed strategy for dealing with\noccurrent thoughts, at least in cases of thoughts that do not seem to\nhave wide contents (see\n 6.3 below\n for the latter). Strawson (1994, 2008), Siewert (1998), Horgan &\nTienson (2002), Horgan, Tienson & Graham (2004), and Pitt (2009)\nall hold that occurrent thought has a phenomenology that is rich and\ndeterminate enough to fix its intentional contents. Horgan &\nTienson (2002), Horgan, Tienson & Graham (2004), and Pitt (2009)\nalso argue that the difference between beliefs, desires, and other\nkinds of attitudes is phenomenally constituted. The case for this\napproach rests on the\n arguments for cognitive phenomenology\n we discuss above.  \nIn contrast, Loar (2003a,b), Bourget (2010, 2015), and Mendelovici (2010, 2018) maintain\nthat thoughts have a fairly impoverished phenomenology that cannot\nfully constitute all the contents we might want to attribute to them.\nLoar (2003a,b) endorses a derived content strategy on which much of\nthought’s content is determined by the “lateral\nconnections” between thoughts and other mental states. The\nnetwork of interconnected states eventually derives its content from\nphenomenal intentional states. Bourget (2010) adopts a derived content\nstrategy on which thoughts derive their contents from phenomenal\nintentional states through a variety of derivation mechanisms. \nMendelovici (2010, 2018) has a largely eliminativist take on the\nintentionality of thought. Like Pitt (2004, 2009), she holds that all\nintentional states are phenomenal intentional states, but unlike Pitt, she\nmaintains that the phenomenology of thought is too impoverished to\ncapture all the contents we might pre-theoretically want to attribute\nto thoughts. However, she recognizes the existence of derived\nrepresentational contents, which capture the rich contents we tend to\nattribute to thoughts. Derived representational states are not strictly\nspeaking intentional states, but they fill the role that intentional\nstates with rich contents have been thought to play. \nStanding propositional attitudes are states one is in independently of\nwhat one is thinking about or experiencing at the time (i.e., independently\nof one’s occurrent states). For example, five minutes ago you\nhad the standing belief that monkeys like bananas even though you\nweren’t occurrently thinking that content. Standing\npropositional attitudes do not seem to have phenomenal properties, and\nso, it seems their intentionality is not phenomenal\nintentionality. \nAs far as we can tell, no one has applied the inflationist strategy to\nstanding propositional attitudes—no one claims that they are\nphenomenal intentional states.  \nStrawson (2008) and Mendelovici (2010, 2018) adopt the eliminativist\nstrategy as part of their defenses of PIT: they deny that standing\nbeliefs and other standing propositional attitudes are intentional\nstates. As Strawson puts it, “To have a belief is not to be in\nany contentful mental state.” (p. 271) Rather, it is to be\ndisposed to be in such a state. Horgan & Tienson (2002)\nare not eliminativists about the intentionality of standing states,\nbut they do not consider them part of the scope of their version of\nPIT.  \nSearle (1990, 1991, 1992), Bourget (2010), and Kriegel (2011a,b) favor\nderivativism about standing states. Searle holds that non-phenomenal\nintentional states have their intentionality in virtue of\nsubjects’ dispositions to have conscious states. This account\napplies most naturally to standing propositional attitudes. Bourget\n(2010) holds a similar but more nuanced view according to which\nstanding propositional attitudes derive from connections to occurrent\nthoughts, which themselves either are phenomenal intentional states or\nderive their contents from distinct phenomenal intentional states (see\nthe next section on the derivativist strategy for thoughts). \nThe simple derived content approach defended by Searle and Bourget is\nopen to well-known objections. One of these objections, discussed by\nPeacocke (1998), is that a state that causes occurrent thoughts to the\neffect that P is not a belief that P unless it is\naccompanied by the right behavior. Imagine someone who claims not to\nbe sexist and tends to form occurrent non-sexist thoughts but who\nbehaves in demonstrably sexist ways. Such an individual is naturally\nsaid to have unconscious sexist beliefs. \nKriegel’s (2011a,b) account aims to explain standing states and\nunconscious occurrent states in a unified way. On his account, which\nhe calls interpretivism, a non-phenomenal state s has\na certain derived intentional content C just in case an ideal\ninterpreter is disposed to ascribe C to s. An ideal\ninterpreter is a being that is perfectly rational and knows all the\nphenomenal and non-phenomenal (but not derivatively intentional) facts\nabout the world. On the resulting derivativist view, non-phenomenal\nintentional states derive from an ideal interpreter’s phenomenal\nintentional states. \nThe disagreement between eliminativism and derivativism about standing\nstates might be partly terminological. Most of the above-mentioned\ntheorists agree that standing states are a matter of a certain kind of\ndisposition to have phenomenal states. What they disagree on is\nwhether the potentially conscious or dispositional states count as\nintentional states.  \nWide intentional states are intentional states that depend on\nrelations to items in our environments. They are states for which externalism is true\n(see\n section 4.3). Prime candidates of wide\nintentional states are thoughts about natural kinds (e.g.,\nH2O) and thoughts about individual objects (e.g., Bill Gates).\nArguably, subjects that are phenomenally alike and have all the\nsame phenomenal intentional states can nonetheless differ in their\nwide intentional states. So, it seems that wide intentional states are\nnot phenomenal intentional states.  \nA Twin Earth case helps illustrate the options available in the case\nof wide intentional states (see Putnam 1975). Consider two\nindividuals, Alice and Twin Alice. Alice lives on Earth, while Twin\nAlice lives on a copy of Earth located far away from us in this world.\nLet us suppose that Alice and Twin Alice are phenomenal\nduplicates: they instantiate all the same phenomenal properties throughout their existences. \nAlice and Twin Alice each have a brother called “Bob”. When\nAlice thinks a thought that she would express by making the sounds\n“Bob is happy”, it seems that her thought is true at just\nthe worlds where Bob is happy. By contrast, it seems that the thought\nthat Twin Alice expresses with “Bob is happy” in her\nidiolect is one that is true at just the worlds where Twin\nBob is happy. So it looks like the Alices’ thoughts have\ndifferent truth conditions. This suggests that the Alices’\nthoughts have different contents. Alice’s thought represents\nthat Bob is happy, while Twin Alice’s thought represents that\nTwin Bob is happy. The Alices’ “Bob”-thoughts are\nparadigmatic examples of putatively broad intentional states.  \nFew advocates of PIT seem to endorse an inflationist strategy for\nbroad intentional states. Even advocates of PIT who take consciousness\nto be relational seem to agree that what a subject gets\nrelated to in consciousness depends solely on her intrinsic properties\n(Pautz 2010). However, Campbell (2002) holds that perceptual\nexperience is broad and intentional, and his view might be counted as\na type of phenomenal intentionality theory.  \nSiewert (1998), Kriegel (2007), and Farkas (2008a) adopt an\neliminativist strategy with respect to broad intentional states. Their\nviews are the same in broad outline. On their views, the two\nAlices’ thoughts have the same content, and that content is\nnarrow. We can account for the fact that the two Alices’\nthoughts are made true by different Bobs by adding contextual\nparameters to their shared content: their shared content is not a\nfunction from possible worlds to truth values but a function from\npossible worlds and relevant elements of context to truth values. The\nintroduction of contexts enables us to account for the fact that the\nAlices’ thoughts are true at different worlds. For example, one\n(over-simplistic) view along these lines could state that the shared\ncontent of the two Alices’ thoughts can be modeled as a function\nfrom worlds W and contexts of use C that returns true\njust in case the person that bears the name “Bob” in\nC is happy in W. Given that different contexts are\nrelevant to Alice and Twin Alice, different worlds can satisfy the\ncommon thought they express as “Bob is happy”. If this is\nthe right way to think about content, the Bobs’ case and other\ncases motivating broad content do not force us to recognize broad\ncontents.  \nPitt (1999, 2011) also endorses an eliminativist strategy, arguing\nagainst externalist intuitions. Mendelovici (2010, 2018) also endorses\neliminativism but claims that she can capture many externalist\nintuitions through the notion of derived mental representation (see\nthe previous section).  \nDerivativist strategies have also been applied to broad\ncontents (Loar 2003a,b, Horgan and Tienson 2002, Horgan, Tienson &\nGraham 2004, Bourget 2010, Chalmers 2010). The idea here is that broad\nintentional states have two contents: a phenomenally constituted\nnarrow content, and a broad content that is determined by the narrow\ncontent together with relevant factors in the environment. So\nAlice’s thought has two contents: one narrow and one broad. The\nbroad content of her thought is true at just the worlds where Bob is\nhappy. The narrow content is true at the worlds where a person bearing\ncertain Bob-like characteristics is happy. The relevant Bob-like\ncharacteristics might, for example, centrally involve being called\n“Bob” by people of a certain community.  \nOf course, such a derivativist approach is compatible with other accounts of the narrow content of Alice’s\nthought. The options available to proponents of PIT are the\nsame as for theories of narrow content in general. For instance, this\nderivativist approach can draw on all the resources of\ntwo-dimensional theories of narrow content (see Chalmers 2002a and the\nentries on\n two-dimensional semantics\n and\n narrow mental content).\n  \nPautz (2008, 2013, 2017) offers a related derivativist approach that he dubs\nconsciousness-based best systems theory. On this view, facts about (sensory)\nphenomenal states and their internal causal roles fix the facts about\nwhat is rational for an agent to believe. These facts about\nrationality in turn fix the narrow contents of an individual’s\nbeliefs. Wide contents are fixed by causal relations between beliefs\nand the environment. \nCognitive science posits various kinds of occurrent unconscious\nrepresentation, e.g., dorsal stream states and internal\nrepresentations of syntactic structures. It seems that such states\nhave intentional properties but lack phenomenal properties, so their\nintentionality cannot be phenomenal intentionality.  \nSome supporters of PIT adopt an eliminativist strategy towards such\nunconscious states. Searle (1990, 1991, 1992) argues, roughly, for the\nclaim that only conscious or potentially conscious states exhibit\nintentionality. Since most unconscious states posited by cognitive\nscience are not potentially conscious, they are not intentional.\nSearle presents this view of unconscious states as being in conflict\nwith cognitive science. In contrast, Graham, Horgan, and Tienson\n(2007) and Mendelovici (2018) highlight the agreement between the\nassumptions of cognitive science and eliminativism about unconscious\nstates: everyone agrees that unconscious states play functional roles,\nbear tracking relations to things in the environment, and have no\nphenomenal properties. Everyone also agrees that it can be fruitful to\ntreat unconscious states as if they represented certain contents. The\nmain disagreement is over whether unconscious states really do qualify\nas intentional.  \nBourget (2010, 2015) and Pitt (2009,\n Other Internet Resources)\n suggest that an inflationist strategy may be acceptable in case of at\nleast some unconscious occurrent states. On their views, we can have\nphenomenal states that we are not aware of. Unconscious occurrent\nstates could be such states. \nA derived content strategy is also an option in the case of some\nunconscious occurrent states. Bourget (2010) argues for this strategy\nby arguing for the claim that the low-level systems that allegedly support\nunconscious occurrent intentional states don’t seem intentional\nwhen they are taken out of the organisms in which they belong.\nKriegel’s interpretivism (2011a,b) is also meant to apply to\nunconscious occurrent states (see\n section 6.2).","contact.mail":"david.bourget@gmail.com","contact.domain":"gmail.com"},{"date.published":"2016-08-29","date.changed":"2019-01-29","url":"https://plato.stanford.edu/entries/phenomenal-intentionality/","author1":"David Bourget","author1.info":"http://www.dbourget.com/","author2.info":"http://publish.uwo.ca/~amendel5","entry":"phenomenal-intentionality","body.text":"\n\n\nPhenomenal intentionality is a kind of intentionality, or\naboutness, that is grounded in phenomenal consciousness, the\nsubjective, experiential feature of certain mental states. The\nphenomenal intentionality theory is a theory of\nintentionality according to which there is phenomenal intentionality,\nand all other kinds of intentionality at least partly derive from it.\nIn recent years, the phenomenal intentionality theory has increasingly been seen as one of the main\napproaches to intentionality.\nThe phenomenal intentionality theory is a theory of\nintentionality, the “aboutness” of mental states, on which phenomenal consciousness plays a central role in accounting for intentional states. Unlike many other contemporary theories of intentionality, which aim to account for intentionality in terms of causal relations, information, functional roles, or other “naturalistic” ingredients, the phenomenal intentionality theory’s main ingredient is phenomenal consciousness, the felt, subjective, or “what it’s like” (Nagel 1974) aspect\nof mental life. Accordingly, Pautz (2013) describes the general approach as taking a\n“consciousness first” approach to intentionality, since it claims that consciousness either grounds or is explanatorily prior to intentionality, and Kriegel (2011a, 2013a) describes the approach as one\non which consciousness is the “source” of intentionality. (These ways of characterizing the phenomenal intentionality theory suggest a reductive picture, on which intentionality is reduced to or explained in terms of consciousness,\nbut in section 2.3 we will see that some versions of the phenomenal intentionality theory are not reductive.)\n \nBy explaining intentionality in terms of phenomenal consciousness, the phenomenal intentionality theory challenges the received view of the past few decades that the mind divides into two\nmutually exclusive and independent types of states: intentional states\nand phenomenal states (see Kim 1998 for a clear articulation of the\nreceived view). According to the phenomenal intentionality theory, intentional states and phenomenal\nstates are intimately related. Some intentional states are constituted by phenomenal states, and the rest are in some way importantly related to phenomenal states. \nPhenomenal intentionality has been discussed under that label only\nrecently (see, e.g., Horgan and Tienson 2002 and Loar 2003, and related\ninfluential work by Searle, Siewert, and others), but many modern\nphilosophers have suggested a close relation between thought, which is\ncharacteristically intentional, and perception, which is\ncharacteristically phenomenal, or consciousness itself. For example, rationalists\nsuch as Descartes held that all cognition is conscious, while empiricists such as Hume and Locke held that all cognition is grounded in perceptual experience. Later, Brentano, Husserl and the phenomenologists that they influenced conceived of intentionality\nprimarily as a conscious phenomenon. Like the phenomenal intentionality theory, the views of these figures can\nbe understood as taking a “consciousness first” approach. For more on the history of the phenomenal intentionality theory, see Kriegel (2013a) and the entry Consciousness and Intentionality.\n  \nIn this article we describe various versions of the phenomenal intentionality theory, their\nmotivations, the challenges they face, and their relations to other views. \nIntentionality is the “aboutness” or “directedness”of mental\nstates. For example, a thought that snow is white “says” or represents that snow is white. Similarly, your\ncurrent visual experience might represent a blue cup or that there is\na blue cup in front of you. When a state exhibits intentionality, it involves the instantiation of an intentional\nproperty, a property of representing something. What the state\nrepresents is its (intentional) content. In this article, we\nuse the term “state” for instantantiations of properties,\nwhich are sometimes called token states. (See the entries \n Intentionality\n and\n Mental Representation.)\n  \nPhenomenal consciousness is the felt, subjective, or\n“what it’s like” aspect of mental states (see Nagel\n1974). Paradigmatic examples of phenomenal states include perceptual\nexperiences, pains, emotional feelings, episodes of mental imagery,\nand cognitive experiences such as the experience of déjà\nvu. Each of these states has a characteristic phenomenal character—there is something that it’s like to be in it. When there is\nsomething that it is like for a subject, we can say that she\ninstantiates a phenomenal property, or that she has a\nphenomenal state. (See the entry\n Consciousness.)\n  \nPhenomenal intentionality is intentionality that is\nconstituted by phenomenal consciousness. A phenomenal intentional\nstate is an intentional state that is constituted by a subject’s phenomenal states. For example, someone who accepts phenomenal intentionality might say that a perceptual intentional state representing a red cube is constituted by a reddish-cube-ish phenomenal state—the reddish-cube-ish phenomenal experience automatically and necessarily results in the representation of a red cube. We will call intentional states that are not phenomenal intentional states non-phenomenal intentional state. PIT takes phenomenal intentionality to play a central role in accounting for intentional phenomena. The next subsections discuss ways that this initial gloss on PIT can be precisified.  A central idea common to phenomenal intentionality theories is that phenomenal intentionality plays an important role in the mind. The next subsections discuss ways that this idea can be precisified.  The following three theses about the relationship between phenomenal\nintentional states and intentional states are ways of precisifying the idea that phenomenal intentionality plays an important role in the mind: \nThe “all” in the above theses should be\nunderstood as quantifying over all actual intentional states, not all\nmetaphysically possible intentional states. In the same way that some\nphysicalist theories of intentionality allow that there are merely\npossible forms of intentionality that are independent of physical\nproperties, PIT can allow that there are non-actual intentional states\nthat have nothing to do with phenomenal consciousness. Of course, more\nspecific versions of PIT might make stronger claims.  Of the three views mentioned above, Strong PIT asserts the strongest\npossible relationship between phenomenal intentionality and\nintentionality: it claims that phenomenal intentionality is the only\nkind of intentionality there is. Relatively few hold this view, but\nversions of it have been defended by Pitt (2004), Farkas (2008a), and\nMendelovici (2010, 2018). The difficulty with this view, as we will see\nbelow, is that it is not clear that there are enough phenomenal states\nor phenomenal states of the right kind to constitute all intentional\nstates. For example, it is not easy to see how standing beliefs like\nyour belief that grass is green could be constituted by phenomenal\nstates. Moderate PIT is significantly weaker than Strong PIT. It is compatible with the\nexistence of non-phenomenal intentional states but claims that any\nsuch non-phenomenal intentional states are at least partly grounded in\nphenomenal intentional states.  \nThere are different ways of explicating the intuitive notion of\ngrounding used in the definition of Moderate PIT. For our purposes\nhere, we can say that A grounds B when B obtains\nin virtue of A. This gloss is itself in need of further\nanalysis, but for now it is enough to know that grounding is an\nasymmetric relation of metaphysical determination (see Trogdon 2013\nfor an introduction to grounding). An example of grounding that is\nsimilar to the grounding relation posited by some proponents of\nModerate PIT is the (alleged) grounding of linguistic meaning in\nspeaker intentions: on many views of language, words have their\nmeanings in virtue of speakers’ intentions toward them. To say\nthat A is partly grounded in B is to that say\nthat A is grounded in the combination of B and other\nfactors. \nThere are different views of how phenomenal intentionality might\npartly ground non-phenomenal intentionality: \nOne view is that non-phenomenal intentional states are simply\ndispositions to have phenomenal intentional states and that these\ndispositions get their contents from the phenomenal intentional states\nthat they are dispositions to bring about (Searle 1983, 1990, 1991,\n1992). On this view, standing beliefs about grass that are not\nphenomenal intentional states are dispositions to have phenomenal intentional states with the same or related contents. \nAnother view is that non-phenomenal intentional states get their\nintentionality from functional relations they bear to phenomenal\nintentional states (Loar 2003a, Horgan & Tienson 2002, Graham,\nHorgan, & Tienson 2007). On this view, a standing belief that\ngrass is green might have its content in virtue of being suitably\nconnected to a host of phenomenal intentional states. \nA third view is that non-phenomenal intentionality is a matter of\nideal rational interpretation (Kriegel 2011a,b, Pautz 2013). On Kriegel’s view, for example, the relevant phenomenal intentional states are in the mind of a possible ideal\nrational interpreter. \nMore versions of Moderate PIT will be discussed below. Proponents of\nModerate PIT (or something close to it) include Loar (1987, 1988,\n1995, 2003a, 2003b), Searle (1983, 1990, 1991, 1992), Goldman\n(1993a,b), Siewert (1998), McGinn (1988), Kriegel (2003, 2011a,b),\nHorgan, Tienson & Graham (2003, 2004, 2006, 2007), Georgalis\n(2006), Pitt (2004, 2009, 2011), Farkas (2008a,b, 2013), Mendola\n(2008), Chalmers (2010: xxiv), Bourget (2010), Pautz (2010, 2013),\nSmithies (2012, 2013a, 2013b, 2014), and Montague (2016). \nWeak PIT merely claims that there is phenomenal intentionality. It\nallows that there are non-phenomenal intentional states that have\nnothing to do with phenomenal consciousness. The proponents of Weak\nPIT are too many to list. As we will see below, Weak PIT is entailed\nby some widely accepted views in philosophy of mind, including many\nforms of representationalism about phenomenal consciousness, the view\nthat phenomenal states are identical to intentional states (perhaps that meet certain further conditions). \nSince Moderate PIT is the strongest view that is endorsed by most\nproponents of the general approach, it is the view that\nhas the best claim to being the phenomenal intentionality\ntheory. For this reason, this article will focus mainly on Moderate\nPIT. Unless otherwise indicated, we will use “PIT” to\nrefer to Moderate PIT. (Note that Strong PIT is a version of Moderate PIT, while Weak PIT is not a version of PIT at all, but rather a weakening of the view.) \nOur definition of phenomenal intentional states is neutral between two\ntypes of views regarding how phenomenal states constitute intentional\nstates. On grounding views, phenomenal intentional states are\ngrounded in phenomenal states (either in individual states or in sets\nof such states). Since grounding is asymmetric, this view implies that\nphenomenal intentional states are distinct from the phenomenal states\nthat ground them. In contrast, identity views take the\nrelation that obtains between phenomenal intentional states and\nphenomenal states (in virtue of which the former are constituted by\nthe latter) to be that of identity: certain instantiations of\nintentional properties are identical to instantiations of phenomenal\nproperties. On this view, phenomenal intentional states are identical\nto individual phenomenal states or sets of phenomenal states.  \nFarkas (2008a,b), Pitt (2004) (though not in Pitt 2009), and Woodward (2016, forthcoming-a) defend a\ngrounding version of PIT. It is also possible to read Horgan and\nTienson (2002) as holding a grounding version of PIT, since they take\nthe relevant relation between phenomenal intentionality and phenomenal\nconsciousness to be that of “constitutive determination”,\nwhich might be understood as a kind of grounding relation. Other\nproponents of PIT, such as Mendelovici (2018), favor an identity view.  \nWe can also distinguish between versions of PIT that are reductive and\nversions that are not. To a first approximation, a theory of\nintentionality is reductive if it specifies the nature of\nintentionality in terms that are supposed to be more basic or\nfundamental. A theory that is not reductive\nmight either be neutral on the question of reduction or incompatible with\nreduction.  \nAll grounding versions of (Moderate or Strong) PIT are reductive. Such\nviews entail that all intentionality is ultimately grounded in\nphenomenal states. Since grounding is asymmetric, the grounding\nphenomenal states cannot themselves be intentional and are more\nfundamental than intentional states.  An identity version of (Moderate\nor Strong) PIT will be reductive if it holds or entails that\nphenomenal intentional states are identical to phenomenal states and\nthat phenomenal descriptions are more fundamental than intentional\ndescriptions (just as “H2O” descriptions are\nmore fundamental than “water” descriptions). If such views\nare correct, it should be possible to understand phenomenal states\nindependently of intentionality. \nVersions of (Moderate or Strong) PIT that identify phenomenal intentional\nstates with phenomenal states can also be nonreductive. On such\nnonreductive views, phenomenal descriptions of intentional states are\nnot more fundamental then intentional descriptions. Exactly which\nversions of PIT that identify phenomenal intentional states with\nphenomenal states are reductive or nonreductive is an open\nquestion. \nRegardless of whether PIT provides a reductive account of\nintentionality in general, versions of Moderate PIT that allow for\nnon-phenomenal intentional states aim to reduce such states to\nphenomenal intentionality and other ingredients, so they provide a\nreductive account of at least some intentional states. We will discuss\nsome of these views below. \nAn important dimension of variation between versions of PIT\nconcerns the extent of phenomenal intentionality. The disagreement here\ncuts across the disagreement between Moderate and Strong PIT.\nFor example, Loar (2003a), who falls in the Moderate PIT camp, mostly\nlimits phenomenal intentionality to perceptual and other sensory\nstates. In contrast, other advocates of Moderate PIT (for example,\nStrawson (1994) and Pitt (2004)) claim that many thoughts have phenomenal\nintentionality. Most theorists maintain that unconscious subpersonal\nstates, such as states in early visual processing or unconscious\nlinguistic processing, lack phenomenal intentionality, though Bourget\n(2010, forthcoming-b), Pitt (2009,\n Other Internet Resources), and Mendelovici (2018)\n claim that some such states might have phenomenal intentionality that\nwe are unaware of.  \nPhenomenal intentionality theorists also disagree on which mental\nstates, if any, have non-phenomenal intentionality. Horgan &\nTienson (2002) and Kriegel (2011a) claim that at least some\nunconscious subpersonal states have non-phenomenal intentionality,\nwhile Searle (1990, 1991, 1992) and Mendelovici (2018) deny this.\nSearle (1990, 1991, 1992) takes at least some standing states, such as\nnon-occurrent beliefs and desires, to have non-phenomenal\nintentionality, which Strawson (2008) and Mendelovici (2018) deny.\n Another important question concerns the structure of phenomenal intentionality. Some proponents of phenomenal intentionality hold that it has a relational structure (Pautz 2010, 2013; Speaks 2015; Bourget forthcoming-a, forthcoming-c), while others (Farkas 2008a,b; Kriegel 2011a,b, 2013; Mendelovici 2018; Pitt 2009) deny this. We briefly discuss this question in Section 4.6. \nThis section outlines some important relations between PIT and other\nviews. \nReductive PIT stands in contrast with two well-known classes of\nreductive theories of intentionality: tracking theories\n(Stampe 1977, Dretske 1988, 1995, Millikan 1984, Fodor 1987), which\ntake the content of mental states to be a matter of\ncausal-informational-historical links between them and things in the\nenvironment (see the entries on\n causal theories of mental content\n and\n teleological theories of mental content),\n and conceptual role theories, which take the content of\nmental states to be a matter of their relations to other mental states\nand sometimes to the external world (Block 1986, Harman 1987,\nGreenberg & Harman 2007). (See the section\n Conceptual role\n in the entry on\n narrow mental content.)\n Reductive PIT also contrasts with primitivism, the view that\nintentionality cannot be reduced. Reductive PIT is a competitor to\ntracking, conceptual role, and primitivist theories in that it is an\nalternative account of the grounds of intentionality.\nVersions of PIT that are not reductive are also competitors to these\ntheories, but to a more limited extent: they only offer an alternative\nexplanation of the grounds of non-phenomenal intentional states. Such\nviews are compatible with reducing phenomenal intentional states to\ntracking states and similar states.  \nWhile PIT offers a different account of the grounds of intentionality\nthan conceptual role and tracking theories, it is noteworthy that all\nversions of PIT are, strictly speaking, compatible with these theories.\nIt could turn out that PIT is true but phenomenal consciousness\nreduces to conceptual role or tracking, making both PIT and the tracking\nor conceptual role theory true.  \nRepresentationalism (or intentionalism) is the view\nthat phenomenal states are intentional states that meet certain\nfurther conditions (Harman 1990, Dretske 1995, Lycan 1996, Tye 2000,\nByrne 2001, Chalmers 2004; see also the entry\n Representational Theories of Consciousness).\n As in the case of PIT, some versions of representationalism are\nreductive while others are not. When one says that phenomenal states\nare intentional states that meet certain conditions, one might intend\nthis as a reduction of phenomenal consciousness or one might merely\nintend to point out a true identity. As in the case of PIT, many\nproponents of representationalism take the view to be reductive.  \nThe reductive versions of representationalism and PIT are\nincompatible: if consciousness reduces to intentionality, then\nintentionality does not reduce to consciousness, and vice-versa.\nHowever, versions of PIT and representationalism that are not\nreductive are compatible. It is common for the two views to be\ncombined: many advocates of PIT also endorse a version of\nrepresentationalism, claiming that all phenomenal states are also\nrepresentational states (Horgan and Tienson 2002, Graham, Horgan, and\nTienson 2007, Pautz 2010, Mendelovici 2013, 2018, Bourget 2010). In the\nother direction, representationalism, as we are understanding the\nview, is committed to Weak PIT, because it entails that some\nintentional states are phenomenal states. \nAnother view of the relationship between intentionality and\nconsciousness is what Horgan & Tienson dub\n“separatism”, the view that consciousness and\nintentionality are wholly distinct mental phenomena (see e.g., Kim\n1998). On this view, consciousness and intentionality do not bear\ninteresting metaphysical relations to each other. For example, there\nis no identity or grounding relation between them (separatists reject\nboth PIT and representationalism). Separatism is typically associated\nwith the view that consciousness is limited to perceptual and sensory\nstates, and intentionality is limited to beliefs, desires, and other\npropositional attitudes.  \nThis section overviews the main arguments and motivations for PIT. \nHorgan and Tienson (2002) argue for the claim that “[t]here is a\nkind of intentionality, pervasive in human mental life, that is\nconstitutively determined by phenomenology alone” (2002: 520).\nThis is a (fairly strong) version of Weak PIT. They do so by arguing\nfor the following two principles: \nWe take IOP to say that each paradigmatic phenomenal property has an\nassociated intentional content such that, necessarily, all instances\nof the property have this associated content. We take POI to say that each\nparadigmatic intentional property has some associated phenomenal character such\nthat, necessarily, all instances of the property have this associated phenomenal\ncharacter. \nHorgan and Tienson defend IOP by appealing to broadly phenomenological\nconsiderations: \nYou might see, say, a red pen on a nearby table, and a chair with red\narms and back a bit behind the table. There is certainly something\nthat the red you see is like to you. But the red that you see is seen,\nfirst, as a property of objects. These objects are seen as located in\nspace relative to your center of visual awareness. And they are\nexperienced as part of a complete three-dimensional scene—not\njust a pen with table and chair, but a pen, table, and chair in a room\nwith floor, walls, ceiling, and windows. This spatial character is\nbuilt into the phenomenology of the experience. (Horgan & Tienson\n2002: 521, footnote suppressed)  The basic idea is that introspective consideration of paradigmatic phenomenal states suggests that they are intentional. This argument echoes the transparency\nconsiderations for representationalism (see the entry Representational Theories of Consciousness). \nHorgan and Tienson’s case for POI (the phenomenology of\nintentionality) rests primarily on detailed phenomenological\nobservations purporting to show that there are phenomenological\nfeatures corresponding to most contents of propositional attitudes as\nwell as the attitudes of belief and desires. We discuss these arguments\nin\n section 5. \nWith IOP and POI in hand, Horgan and Tienson proceed to argue for the\nwidespread existence of phenomenal intentionality. The following is a reconstruction of the key steps of their argument:  \nThe general idea is that phenomenal states, with their phenomenally\ndetermined intentionality, bring in their train much of the rest of\nthe “web of belief”. \nHorgan and Tienson argue for the transition from\n (1)\n to\n (2)\n by articulating in some detail how the contents of perceptual\nexperiences, either individually or in groups, bring in their train\nperceptual beliefs. A key idea, supported by POI, is that perceptual\nbeliefs and other attitudes towards perceptible contents have\nphenomenal characters closely associated with them. For example, there\nis a phenomenology of accepting various contents as true. The\nsuggestion is that once one has a vast number of perceptual\nexperiences with their associated perceptual contents and feelings of\naccepting and rejecting some of these, one qualifies as having a number of perceptual beliefs. \nRegarding the transition from\n (2)\n to\n (3),\n a key idea, again derived from POI, is that non-perceptual beliefs\nhave extensive phenomenology. For example, according to Horgan and\nTienson, there is something that it’s like to wonder whether to\ncook meatloaf for dinner. The phenomenology of such non-perceptual\nthoughts, together with one’s vast collection of perceptual\nbeliefs and perceptual experiences, fixes a large number of\nnon-perceptual beliefs and other non-perceptual propositional\nattitudes.\n (4)\n combines conclusions\n (1)–(3). \nThe following considerations, while not exactly Horgan and\nTienson’s, seem to go in the same direction as their line of\nargument: If all beliefs and desires have phenomenal characters unique\nto them, as Horgan and Tienson take themselves to have established,\nthen phenomenal duplicates will share these phenomenal characters. By\nIOP, these phenomenal characters must determine contents. Plausibly,\nthey determine the contents of the beliefs and desires that they\ncharacterize. So if an individual has a given belief with content C,\nthen his or her phenomenal duplicate has this content as the content\nof a phenomenal experience. Moreover, the duplicate has a feeling of accepting\nC. It is then quite plausible that the duplicate believes\nC. \nHorgan and Tienson’s argument establishes Weak PIT, but it does\nnot yet establish any version of Moderate PIT. It could be that many\nintentional states are phenomenal intentional states but some\nintentional states are neither phenomenal intentional states nor\ngrounded in phenomenal intentionality (Bailey and Richards (2014)\npoint out related limitations of the argument). However, when combined\nwith Horgan and Tienson’s arguments for the claim that many\nnon-phenomenal intentional states are grounded in phenomenal\nintentionality (more on this view below), we have some support for\nModerate PIT.  Mendelovici (2018) also argues for Moderate PIT on the grounds of metaphysical sufficiency: The ingredients invoked by alternative theories of intentionality, such as tracking and functional role theories, are not metaphysically sufficient for intentionality. For instance, it is unclear why having internal states\nplaying certain functional roles should result in those internal states representing a particular content, or any content at all. Likewise, while tracking relations relate us to items that may seem to be well-suited to playing the role of content, such as objects, properties, and states of affairs, it is mysterious how tracking such items could make them psychologically relevant to us. For instance, it is unclear how merely tracking such items can make them introspectively accessible, available to reason with, or in any sense “entertained”. (See also BonJour 1998 for similar worries with tracking and functional role theories.) In contrast, PIT’s central ingredient, phenomenal consciousness, is arguably metaphysically sufficient for intentionality. For instance, it is arguably inconceivable for there to be someone with a reddish phenomenal experience who does not thereby represent redness. If all this is right, then there is reason to think that phenomenal consciousness alone is metaphysically sufficient for intentionality, which supports Moderate PIT. \nSiewert (1998) argues for Weak PIT by arguing that phenomenal states are\nautomatically assessable for accuracy. A key element of\nSiewert’s argument is his assumption that phenomenal characters\ncan be identified with “how it seems for it to look some way to\nsomeone”. We take this to mean that phenomenal states are states\nof things seeming a certain way, where the relevant kind of seeming is\nthe kind we are familiar with from cases where things look a certain\nway in perception (perhaps there are other kinds of seemings that are\nnot phenomenal states). Siewert’s argument is contained in the\nfollowing passage, in which we have added numbers corresponding to the\npremises: \nFirst, consider some instance of its seeming to you as it does for it\nto look as if something is shaped and situated in a certain way, such\nas its seeming to you just as it does on a given occasion for it to\nlook as if there is something X-shaped in a certain position. (1) If\nit seems this way to you, then it appears to follow that it does look\nto you as if there is something X-shaped in a certain position. (3) If\nthis is right, then its seeming this way to you is a feature in virtue\nof which you are assessable for accuracy—(5) that is to say, it\nis an intentional feature. For, from what we have said, (2) if it\nseems to you as it does for it to look this way, then, if it is also\nthe case that there is something X-shaped in a certain position, it\nfollows that the way it looks to you is accurate. (Siewert 1998: 221)\n \nSiewert suggests that this argument straightforwardly generalizes to a\nlarge number of perceptual experiences.  \nLet S be the phenomenal state in which it seems to you just as\nit does on a given occasion for it to look as if there is something\nX-shaped in a certain position. The argument in the above quotation can be\nbroken down as follows:  \nSiewert does not explicitly defend premises\n (1)\n and\n (2).\n (4) is defended in section 6.2 of the book. \nOne might object that\n (3)\n does not follow from\n (1)\n and\n (2).\n Perhaps S is such that, necessarily, things being a certain\nway (or not) would make the bearer of S accurate (or not), but\nit is not in virtue of being in S that its bearer is\nassessable for accuracy. The assessability might come from the\ninevitable addition of an interpretation to S in all\ncircumstances. Siewert argues against this possibility extensively\nbetween pages 222 and 245, ruling out various sources of\ninterpretation.  \nGertler (2001) objects that there is an alternative explanation of\nSiewert’s observations about the co-occurrence of phenomenal and\nintentional properties: intentional properties automatically give rise\nto phenomenal properties. Gertler argues that Siewert has not ruled\nout this alternative, and so fails to establish PIT. See Siewert 2004 for a response. \nIt is possible to argue for PIT on the basis of internalism\nabout mental content, the view that what a subject’s mental\nstates represent is fully determined by her intrinsic properties. (The\nalternative to internalism is externalism. Intentional\ncontent that is determined by a subject’s intrinsic properties\nis said to be narrow as opposed to wide. See the\nentries on\n narrow mental content\n and\n externalism about mental content.) \nLoar (2003a) argues from internalism to PIT.\nFirst, Loar proposes the following two desiderata for a theory of\nintentionality: (1) The theory should be a non-referential theory,\nwhere a non-referential theory is a theory that does not take\nintentionality to be a matter of reference to external entities, for\nexample, concrete or abstract objects. This desideratum is motivated\nby internalism. (Note that, for Loar, intentionality is not the same\nthing as reference, and so a non-referential theory of intentionality\ndoes not commit one to denying that there is such a thing as\nreference.) (2) The theory should accommodate externalism about\nreference and truth-conditions (see, e.g., Putnam 1975, Burge 1979,\nKripke 1980).  \nLoar then argues that internalist views that do not appeal to phenomenal consciousness fail to meet\ndesiderata (1) and (2). The first view he considers is short-arm\nfunctionalism, the view that causal interactions between brain states\ngive rise to intentionality. The second view is a version of\n the descriptivist theory of reference\n combined with short-arm functionalism about its primitive\nrepresentations. Having excluded these views, he argues that a version\nof PIT can meet his two desiderata. Phenomenal properties are\ninherently intentional in that they exhibit directedness, or purport\nto refer. Since purporting to refer is not the same thing as\nreferring, the result is non-referential mental content. This\nsatisfies the first desideratum.  \nLoar argues that his view satisfies the second desideratum by arguing\nthat phenomenal properties do not by themselves secure reference or\ntruth-conditions. Instead, reference and truth-conditions are a matter\nof externally-determined relations, as externalists such as Putnam\n(1975), Burge (1979), and Kripke (1980) claim. However, which\nexternally-determined relations matter for reference depends on a\nsubject’s non-referential internalist content. Horgan, Tienson,\n& Graham (2004) also suggest that PIT is the best available theory\nof narrow content and suggest that phenomenal intentionality can provide a basis for externalist content. \nAnother argument for PIT involves appeal to brain in a vat scenarios (see Loar 2003a and Horgan, Tienson & Graham 2004). A brain in a\nvat duplicate is an exact physical duplicate of a normally\nembodied human brain that is kept in a vat of life-sustaining liquids\nand is hooked up to a computer that delivers to it the same kinds of\nstimulation its embodied twin receives. It intuitively seems that a\nbrain in a vat would have a mental life “matching” that of\nits embodied twin. The brain in a vat and its twin would have matching\nperceptual experiences, perceptual judgments, and beliefs. For\nexample, when the embodied twin believes that she is lying on the\nbeach sipping a frappé, the brain in a vat twin believes that\nthey are lying on the beach sipping a frappé. However, while\nthe normal subject’s belief might be true, the envatted\nsubject’s beliefs, and many other of their mental states, would\nbe false or non-veridical. \nFarkas (2008a) agrees with Loar and Horgan et al. (2004) that PIT is\nthe best available theory of narrow content but criticizes Loar\n(2003a) and Horgan et al. (2004) for making a concession to\nexternalism by allowing for externally-determined\nreference, truth-conditions, or broad content. Instead,\nFarkas argues that internalist, phenomenally-constituted\nintentionality is all that a theory of intentionality needs. \nWilson (2003) objects to Loar’s appeal to brains in vats,\nclaiming that intuitions concerning them are theoretical intuitions\nand are likely to be rejected by many of PIT’s opponents.  \nIn an early defense of PIT, Searle (1990, 1991, 1992) puts forth an\nargument based on the “aspectual shapes” of intentional\nstates. The argument is rather complex and open to several\ninterpretations, but here is one simplified way of understanding it:\nSearle begins by noting that all intentional states have an aspectual\nshape, where an aspectual shape is a matter of how something\nis represented. For example, there is a difference between\nrepresenting Hesperus and representing Phosphorus, or representing\nSuperman and representing Clark Kent. The differences lie not in\nwhich objects are represented, but in how they are\nrepresented—these are differences in their aspectual shapes.  \nSearle then argues that no internal or external unconscious physical\nor functional facts can determine aspectual shapes. The only thing\nthat can determine aspectual shape is consciousness. If that is so,\nthen it looks like unconscious states can only have their aspectual\nshapes in virtue of their connections to conscious states. Searle\nconcludes, more specifically, that unconscious intentional states\ninvolve dispositions to have conscious states, a thesis that he calls\nthe connection principle. (Sometimes he says that unconscious\nstates are potentially accessible to consciousness,\napparently meaning that they can be introspected consciously\n(1992, p. 156), but other times he says what we say here: that\nunconscious states involve dispositions to have conscious states\n(1992, p. 159, 161–162). The latter is what Searle says as part\nof his argument for the connection principle, and this interpretation\nis more in line with the argument he deploys.)  \nIn sum, the argument seems to go as follows: \nAccording to the argument’s conclusion, all intentional states\nare either phenomenal intentional states or involve dispositions to\nhave such states. This is a version of Moderate PIT. \nSearle’s arguments have elicited a large number of responses.\nFodor and Lepore (1994) argue that there is no suitable way of cashing\nout what it would take for a state to be potentially\nconscious such that Searle’s claims are both plausible and\ntendentious (i.e., that they entail, as Searle claims, that much of\ncognitive science’s appeal to non-conscious intentional states\nis misguided). For a response, see Searle 1994. Davies\n(1995) argues that Searle might be right about a kind of\nintentionality but that there are other kinds of intentionality\ninvoked in cognitive science that are not dependent on consciousness.\nVan Gulick (1995) argues that Searle’s notion of aspectual shape\nsmuggles in the notion of consciousness, and that on a less\ncontentious understanding of aspectual shape, his argument that\nconsciousness is the only way of accounting for aspectual shape does\nnot succeed. Baaren (1999) also takes issue with the notion of\naspectual shape. See also the commentaries accompanying Searle 1990.\n \nAnother line of argument for PIT similar to Searle’s aspectual shape argument is an argument from content determinacy. Graham, Horgan & Tienson (2007) and\nHorgan & Graham (2012) argue that it is difficult to see how\nunconscious neural activity, functional role, dispositions to\nbehavior, and other possible physical bases of intentionality can\nyield the sorts of determinate contents we manifestly represent (see\nalso Dennett 1987, Quine 1960: ch. 2, and Kripke 1982). For example,\nno causal, functional, or purely physical features of one’s\nbrain or environment seem to make it the case that one is thinking\nabout rabbits rather than undetached-rabbit-parts. A\nMartian looking down on Earth with complete knowledge of all\nEarthly physical facts could not tell whether we are representing\nrabbits or undetached rabbit parts. Thus, it appears that a\nphysical-functional theory of intentionality will predict that\none’s concept RABBIT is indeterminate between the two contents.\n \nSimilarly, nothing about our brains, their finite dispositions, or\ntheir environments indicates that our word “plus” means\nthe plus operator rather than a Kripkean quus\noperator, an operator that works just like plus when the operands are\nless than 57 and returns 5 when either operand is 57 or greater (see\nKripke 1982). If we do determinately represent plus and\nrabbits, something other than tracking relations,\ndispositions towards behaviors, internal functional roles, or brain\nstates has to determine this. Along similar lines, Strawson (2008)\nargues that phenomenal intentional facts about what we take an\nintentional state to refer to play a key role in determining what an\nintentional state refers to.  \nSome argue that phenomenal consciousness is capable of explaining\ncontent determinacy. According to Graham, Horgan and Tienson, there is\na phenomenal difference between representing rabbits and representing\nundetached-rabbit-parts. Since PIT claims that phenomenal intentional\ncontent is determined by phenomenal character, it allows that the two\nstates have distinct contents. The supposition that there is\nhigh-level cognitive phenomenology corresponding to such\nabstract contents as rabbits and\nundetached-rabbit-parts is key to this argument. This is a\ncontroversial claim, but one that is quite central to many versions of\nPIT. We discuss this claim in\n section 5.\n  \nArguments for PIT from content determinacy rely on the strong claim\nthat the totality of physical facts do not fix content determinately\nand that content is fixed determinately. While PIT does not entail\ndualism about consciousness, PIT combined with this claim does (see Pautz 2013, who objects to arguments for PIT from content determinacy for related reasons). This claim will be resisted by anyone who thinks that physicalism about the mind is\nwell-motivated. One might say that the intuition that physical facts\ncannot fix determinate contents arises from the fact that we do not\nhave a suitably good understanding of how intentionality arises from\nphysical facts; had we such an understanding, the intuition would\ndisappear.  \nRelationalism about intentionality is the view that\nintentionality is a relation to distinctly existing entities that\nserve as contents. Non-relationalism about intentionality\nis the view that\nintentionality is not a relation to distinctly existing entities that\nserve as contents.  \nKriegel (2007, 2011a) argues that a non-relational view of intentionality\nprovides the best explanation of how we can represent things that\ndon’t exist, such as Bigfoot, and that PIT is the best candidate\nnon-relational view of intentionality. Kriegel first argues that the\nfollowing three intuitively appealing claims are inconsistent: \nOne of these claims needs to be rejected. Kriegel argues that it is\n (c),\n the claim that asserts relationalism. His’s argument\nproceeds by a process of elimination. \nKriegel considers rejecting\n (a).\n On this proposal, when we seem to represent dragons, Bigfoot, or\nSanta Claus, we either fail to have an intentional state or we\nrepresent something else. One reason Kriegel rejects the first option\nis that it implies that there is a gap between trying to represent and\nrepresenting, which he takes to be implausible. On the second option,\nwhen we seem to represent non-existent concrete entities, we are\nreally just representing something else, such as existent abstract\nentities (e.g., universals or propositions), existent mental entities\n(e.g., sense data or ideas), or existent possible but non-actual\nentities. But Kriegel takes this option to be highly counterintuitive.\nWhen we seem to be thinking about concrete flesh-and-blood Bigfoot, we\nare in fact thinking about an abstract or mental entity. (See, however, Mendelovici 2018, section 9.3.1 for a response to this line of argument.)\nAnother worry\nis that accounting for the representation of non-existents seems like\nthe wrong kind of reason to accept the existence of these abstract,\nmental, or merely possible entities. \nAnother option is to reject\n (b).\n Kriegel argues that just as a monadic property cannot be instantiated\nwithout an existing particular that instantiates it, so too a relation\ncannot be instantiated without existing particulars that instantiate\nit. In short, it is a general rule that relations require relata.\nRejecting\n (b)\n is tantamount to claiming that the intentionality relation is an\nexception to this general rule, which is implausible. \nKriegel concludes that we should reject\n (c).\n He calls his non-relational view “adverbialism”, since it\ndraws its inspiration from the adverbialist views of perception of\nDucasse (1942) and Chisholm (1957). According to Kriegel’s\nadverbialism, representing Bigfoot is not standing in a relation to an\nentity, but rather instantiating a non-relational intentional\nproperty, which we might describe as the property of representing\nBigfoot-wise. \nSo far, this only motivates adverbialism. The final step of the\nargument motivates PIT: One objection to adverbialism is that it is\nmysterious what non-relational intentional properties are. What is it\nto represent Bigfoot-wise? Kriegel suggests that a plausible account\nof these properties is that they are phenomenal properties. Phenomenal\nproperties are usually taken to be non-relational and there is\nindependent reason to think they give rise to intentionality (see the\nother arguments in this section). The resulting picture is one on\nwhich phenomenal intentionality is non-relational. Kriegel suggests\nthat this view can be combined with the view that non-phenomenal\nintentionality is derived from phenomenal intentionality and is\nrelational.  \nIn short, Kriegel’s argument attempts to show that PIT is the\nbest way to account for the representation of non-existents. \nThis argument motivates non-relational versions of PIT. However, it\ndoes not motivate relational versions of PIT, on which intentionality\nis relational. Loar (2003a), Pitt (2009), Kriegel (2007, 2011a), and\nMendelovici (2010, 2018) hold non-relational versions of PIT, while Pautz\n(2013) and Bourget (forthcoming-a, forthcoming-c) defend a relational version of PIT, on which both phenomenal properties and intentional properties are relational. Speaks (2015) also defends a relational view of phenomenal representation (without endorsing PIT).\n Arguing in the direction opposite the preceding considerations, some have challenged PIT on the grounds that intentionality is relational. Ott (2016) raises worries for PIT along such lines, arguing that most versions of PIT fail to adequately explain how phenomenal consciousness can give rise to intentionality, which he takes to necessarily involve a relation to extra-mental reality. There are two lines of response open to phenomenal intentionalists: One is to maintain that phenomenal consciousness is itself relational in the relevant way. Pautz (2010) and Bourget (forthcoming-a, forthcoming-c) argue that consciousness is a relation to items in extra-mental reality, such as clusters of abstract properties or abstract propositions. Of course, this response gives up on the benefits of non-relational PIT alleged by Kriegel. (Bourget (forthcoming-c) responds to some of Kriegel’s arguments against relationalism.) Another response is to deny that intentionality secures the required relation to extra-mental reality. Along such lines, Mendelovici (2018, sections 1.3.4 and 9.3.4) argues that it is a substantive question whether intentionality on its own or with the help of additional ingredients secures such a relation. Of course, whether this is so depends on what exactly we mean by “intentionality”. If intentionality involves such a relation by definition, then there is no further substantive question to be asked. But if, as Mendelovici (2010, 2018) and Kriegel (2010) suggest, the core notion of intentionality leaves open this aspect of its nature, it might very well turn out that intentionality does not involve such relations.  Even if intentionality does not involve a relation to extra-mental reality, one might worry that it should at least play a role in facilitating such a relation and that PIT cannot allow for this. But Ott (2016) suggests that PIT can in fact connect us to extra-mental reality through relations of resemblance. Similarly, Mendelovici (2018, chapter 9) argues that intentionality does not involve a connection to extra-mental reality but that truth and reference do and that truth and reference are a matter of a special kind of superficial resemblance called “matching”. Woodward (forthcoming-b) and Bourget (forthcoming-b) challenge Mendelovici’s account of truth and reference for non-relational versions of PIT.  Another line of argument for PIT begins by noting that theories of intentionality, combined with certain facts about the world, often make predictions as to what particular intentional states represent. For example, a causal theory of intentionality combined with the fact that cows often cause tokens of the concept COW might predict that COW represents the content cow, which might be the property of being a cow.  One line of argument for PIT is based on the claim that PIT makes correct predictions in certain paradigm cases of intentionality that other theories fail to accommodate. One such case is that of color experience: It is plausible (though not undisputed) that color experiences represent what Chalmers (2006) calls “Edenic colors”—primitive, non-physical, qualitative properties (see also Pautz 2006a, 2009). This might be supported by introspection, epistemic considerations, and considerations of psychological role. But since Edenic colors are arguably not instantiated, it is difficult for causal, informational, teleological, and other “tracking” theories of intentionality to allow us to represent them. Instead, such theories predict that perceptual color representations represent the likes of particular dispositions to reflect, emit, or transfer light of particular wavelengths. In contrast, since Edenic colors “match” the phenomenal characters of color experience, PIT has the resources to make the correct predictions in the case of color experiences. Mendelovici (2018) refers to this as the argument from matching for PIT. Pautz (2006b) makes a related argument against tracking representationalism and for primitivist representationalism based on a structural mismatch between the contents represented by color experience and the properties color experiences track. See also Causal Theories of Mental Content. \nThe argument from predictive accuracy purports to show that PIT is the only theory of intentionality that stands a chance of being empirically adequate (whether it can indeed handle all the cases depends on whether it can deal with challenging cases, such as those discussed in section 6). It does not make a complete case for PIT, but it is an important consideration as part of the overall case for PIT. \n We will briefly mention a few other lines of argument for PIT. One revolves around the idea that norms of rationality are\nconstitutive of (non-phenomenal) intentional states. Pautz writes: \nConsciousness grounds rationality because it is implicated in basic\nepistemic norms. … In turn, the facts about rationality help to\nconstitutively determine belief and desire (Davidson, Lewis). So\nconsciousness also ultimately grounds belief and desire. (Pautz 2014:\n176)  \nThis line of argument combines two claims that have been defended\nindependently. The first is a view of non-phenomenal states (chiefly,\npropositional attitudes) on which they derive their contents from\nnorms of rationality (Davidson 2001, Lewis 1983, Chalmers 2012). The\nsecond is the view that consciousness plays a role in determining\nrational norms (Siewert 1998, Campbell 2002, Smithies 2012, 2014). In\naddition to the above passage from Pautz, this argument for PIT is\nalso made in Chalmers 2012: 467 and Pautz 2013: 226. \nAnother line of argument for PIT is that there is nothing to determine\nwho a given non-conscious state of mind belongs to unless that state\nconsists in a disposition to produce a conscious mental state of the\nright sort (Ludwig 1996). Kriegel (2003) similarly argues that only\nPIT can account for the fact that intentional states have a subjective\nor “for-me” character.  \nMany defenses and elaborations of PIT maintain that occurrent thoughts\nhave a rich and varied phenomenology. Such a view of thought is\nrequired by versions of PIT that claim that the contents we normally\nattribute to thoughts are phenomenal contents (see\n section 6.2).\n Cognitive phenomenology is also a widely debated topic independently\nof any connection to PIT (see, e.g., Cognitive Phenomenology,\nedited by Bayne and Montague 2011). \nAdvocates of PIT that take thought content to be phenomenal content\nmainly focus on arguing for the following two claims:  \nThe term “proprietary” is due to David Pitt (2004).\nThought has a proprietary phenomenal character just in case\nthe phenomenal characters of thoughts are special or unique to\nthought, i.e., they are not perceptual, verbal, bodily, or affective\nphenomenal characters, or other phenomenal characters that are present\nin mental states other than thoughts. Following current usage, we call\nall of the aforementioned kinds of phenomenology sensory\nphenomenology and the putative proprietary phenomenology of\nthought cognitive phenomenology. The claim that thought has a\nproprietary phenomenology is then just the claim that it has a\nnon-sensory phenomenology. \nThoughts have individuative phenomenal characters just in\ncase thoughts with different intentional contents have different\nphenomenal characters and thoughts with different phenomenal\ncharacters have different intentional contents. (We use\n“individuative” in the way Bayne and Montague (2011: ch.\n1) use it. Pitt (2004) uses the term “distinctive” for a\nsimilar notion and the term “individuative” to mean\nsomething else.)  \nWhile most advocates of PIT take thoughts to have individuative\nphenomenal characters, this isn’t required by PIT. Grounding PIT can allow\nthat there is a one-many grounding relation between contents and\nphenomenal characters. For example, phenomenal properties r1\nand r2 might both ground the intentional property of\nrepresenting red421. If all intentional properties\nwere grounded in this way, PIT would be true, but (Individuative)\nmight not be. \nIt is possible for thoughts to have proprietary but not individuative\nphenomenal characters. For example, suppose every thought came with\neither a generic feeling of understanding or a generic feeling of\nconfusion. These phenomenal characters might be proprietary in that\nthey do not occur outside of thoughts, but they are not individuative,\nsince thoughts with different intentional contents might have the same\nphenomenal characters. \nIt is also possible for thoughts to have individuative but not\nproprietary phenomenal characters. For example, suppose every thought\ncame with a different kind of perceptual imagery. Then thoughts with\ndifferent contents would have different phenomenal characters, but\nthese phenomenal characters would not be special to thoughts, since\nperceptual states could have them too. \nIn addition to the claims that there is a proprietary and an\nindividuative phenomenology of thought, advocates of PIT usually aim\nto establish that thought’s content is phenomenal intentional\ncontent and thus that thought’s intentional properties are\nobtained in the requisite way from phenomenal properties.  \nWhile much of the discussion of the phenomenology of thought involves\ncareful argumentation and consideration of cases, it is worth\nmentioning that many advocates of a proprietary phenomenology of\nthought find the view obvious and the negation of the view clearly\nfalse or even absurd. Strawson writes: \nTo deny this [cognitive phenomenology], one must hold that the total\nlifelong character of our lived experience—everything that life\nis to us experientially—consists entirely of bare or pure\nsensation or feeling of one kind or another. It must, for example, be\nfalse to say that anguish at someone’s death includes\nconscious comprehending believing entertaining of the\nproposition that he is dead. (Strawson 2011a: 295, italics in\noriginal)  \nIn a similar vein, Kriegel writes: \nFor my part, I am persuaded of the existence of cognitive experience\n[…] most vividly by something like everyday experiential\noverwhelm: it simply seems that my inner life is much more interesting\nto me than it would be if my conscious experience consisted merely in\nperceptual experiences. (Kriegel 2011a: 50)  \nIn what follows we discuss the main arguments that have been offered\nto supplement such appeals to the alleged obviousness of cognitive\nphenomenology. \nPhenomenal contrast cases are cases of two thoughts that are\nalike in sensory phenomenal character but differ in thought content.\n \nSiewert (1998) asks his readers to compare an experience of hearing or\nreading a sentence without understanding, as when one reads a\ndifficult passage without paying attention to it, and an experience of\nhearing or reading a sentence with understanding. There is\nclearly a phenomenal difference between these cases. Siewert argues\nthat the difference is not a difference in verbal or perceptual\nimagery, since the verbal and perceptual imagery might be the same in\nboth cases. The best explanation of the phenomenal contrast is that\nthought involves proprietary cognitive phenomenology.  \nStrawson (1994) argues for a kind of “understanding\nexperience” by contrasting the cases of a monolingual English\nspeaker and a monolingual French speaker listening to the news in\nFrench. The experiences of the two subjects differ in a way that is\nnot fully explained by a difference in sensory phenomenology. The best\nexplanation involves a difference in cognitive phenomenology. Siewert\n(1998) also employs examples involving the comparison of hearing\nsentences in familiar versus unfamiliar languages.  \nAs it stands, Strawson’s argument can only establish that\nthought has a proprietary phenomenology, but Kriegel (2011a: 49)\nextends it to argue that thought has an individuative phenomenology.\nHe asks us to imagine a case of two languages involving graphically\nand phonetically identical words such that the same report can be\ninterpreted in one language as describing a faraway war and in the\nother language a children’s bedtime story. Monolingual speakers\nof each language will experience different phenomenal characters upon\nreading or hearing this report. The best explanation of this involves\na difference in cognitive phenomenology. This supports the claim that\ncognitive phenomenology is individuative.  \nOther arguments from phenomenal contrast cases aim to create the\ncontrasting experiences in the reader herself. Horgan and Tienson\n(2002) present the reader with sentences that are likely to give rise\nto two different interpretations, such as the following:  \nOn one reading, the sentence is about the act of visiting relatives.\nOn another reading, the sentence is about relatives that visit. Both\nreadings are likely to generate the same verbal imagery, but they\ndiffer in content. Horgan and Tienson encourage the reader to notice\nthat they also differ in phenomenal character. If this is right, then\nthis suggests that thought has a proprietary and individuative\nphenomenology.  \nThe following sentences are also used to generate phenomenal contrast\ncases: \n\n (Dogs)\n might at first be read without understanding, but might\nsubsequently be read with understanding, giving rise to a phenomenal\ncontrast case.\n (Time)\n can be read as a cliché or as a command at the insect races.\n (Bar)\n can be read as being about an aborted legal career or a trip around\ntown. Again, the claim is that these different readings of the\nsentences give rise to different phenomenal experiences and that the\nbest explanation of this is that thought has a proprietary and\nindividuative phenomenology.  \nThough instances of pairs of thoughts differing in intentional content\nand differing in phenomenal character provide some evidence for the\nexistence of individuative cognitive phenomenology, in order for the\nthesis that thought has a individuative phenomenology to be true,\nthere have to be no cases of thoughts that are alike in content but\nthat differ in phenomenal character. This latter kind of case would be a counterexample to (Individuative). Wilson (2003) responds to Horgan\nand Tienson by accepting their observations in their phenomenal\ncontrast cases but attempting to provide such a counterexample:  \nIn the spirit of Horgan and Tienson’s appeal for a reader to\n“pay attention to your own experience” ([2002] p. 521), I\nhave just done the decisive experiment: I thought first that George\nBush is President of the United States, and had CNN-mediated auditory\nand visual phenomenology that focussed on one of his speeches. I then\ntook a short break, doodled a little, wandered around the room, and\nthen had a thought with that very same content and … nothing.\nOr at least nothing distinctly Bush-like, as in the first case.\n(Wilson 2003: 417)  \nIf Wilson is right, this not only shows that arguments based on\nphenomenal contrast ultimately fail, but also provides positive\nconsiderations against (Individuative), since it shows that there can\nbe thoughts with the same contents that fail to have the same\nphenomenal character.  \nVersions of PIT that\n require only a one-many relation\n between phenomenal intentional content and phenomenal character, and\nhence that do not need to endorse (Individuative), can accommodate\nobservations such as Wilson’s putative observation, since they\nallow that multiple phenomenal characters can ground or constitute the\nsame phenomenal intentional content.  \nAnother kind of objection to arguments from phenomenal contrast involves agreeing\nthat there is a phenomenal difference between the relevant cases but\nclaiming that this difference is exhausted by sensory phenomenology,\nwhere this might include the phenomenology of perceptual imagery,\naffective experience, or verbal imagery (see, e.g., Lormand 1996, Tye\nand Wright 2011, Levine 2011, Robinson 2011, Carruthers and Veillet\n2011). What makes the phenomenal contrast cases described above\nvulnerable to this kind of objection is that they do not control for\nall potential accompanying perceptual imagery. This leaves open the\npossibility that the observed phenomenal differences are fully\naccounted for by such imagery.  \nChudnoff (2013) provides a phenomenal contrast case that he claims\navoids this reply. He asks his readers to compare the experience of an\narray of dots to an experience of the same array of dots experienced\nas part of a proof for a mathematical theorem. In the second\nexperience, but not in the first, the perceptual experience involves\ncognitive phenomenology. The array of dots is in some sense\nexperienced as part of a larger whole, representative of something, or\nin some sense meaningful. (Chudnoff 2015a,b also contain extensive\ncritical discussions of phenomenal contrast cases.) \nOne might worry that, like the original phenomenal contrast cases,\nChudnoff’s case does not control for certain forms of\naccompanying imagery, in this case, verbal imagery. The adamant\nopponent of cognitive phenomenology might insist that just as the\nphenomenal differences in the phenomenal contrast cases involving\nsentences might be explained by perceptual imagery, the differences in\nChudnoff’s cases can be accounted for by differences in verbal\nphenomenology.  \nIt might seem that what is needed is a phenomenal contrast case that\nplausibly controls for both verbal and perceptual phenomenology, as\nwell other kinds of sensory phenomenology. Mendelovici (2010: 107)\nargues that thoughts about chiliagons (one-thousand sided figures) and\nmegagons (one-million sided figures) might involve the same mental\nimagery (both shapes effectively look like circles) and so might\nprovide the basis for such cases. Imagine a person who mistakenly uses\nthe word “megagon” to mean chilliagon. Compare\nher experience of viewing a chilliagon and thinking that it is a\nchilliagon with your experience of viewing a megagon and thinking that\nit is a megagon. Since you both use the word “megagon” to\ndescribe the shape you are thinking about, and since the two\nshapes are perceptually similar, you will likely have the same\nperceptual and verbal imagery. If there is a phenomenal difference\nbetween the two cases, it is plausibly attributed to a difference in\nthought content. \nSiewert (1998, 2011) claims that sudden realizations are cases in\nwhich cognitive phenomenology is particularly noticeable.  \n[Y]ou are standing at the door to your house, reaching in your pants\npocket for the door key, and find it empty. You feel a sudden panic;\nyou think perhaps you have locked yourself out; you try to remember\nwhere you put the keys, then recall switching them to your coat pocket\nearlier; you reach and find them there—relief. (Siewert 1998:\n277)  \nI meet a friend, and she asks me, “Did you bring the\nbook?” For a moment I am at a loss as to what book she’s\ntalking about—and then I realize in an instant what book it is.\n(Siewert 2011: 258)  \nSiewert claims that such realizations needn’t involve any verbal\nor perceptual imagery. In the case of the first example, you\ndon’t think the words “I have locked myself out” or\nvisualize your keys. Siewert takes these and other similar examples to\nshow that thought has a proprietary phenomenology.  \nSimilarly, in order to argue that the phenomenal properties of thought\nare not merely associated with verbal imagery, Horgan and Tienson\n(2002) point to examples of spontaneous thoughts we have when engaging\nin activities such as cooking or working in a garage or woodshop: \nThere is something that it is like to think that a certain tool is\njust there—in that cabinet, say—but such beliefs are\ntypically not verbalized either vocally or subvocally or by way of\nverbal imagery. (Horgan and Tienson 2002: 523)  \nLike Siewert’s examples, this example helps motivate the claim\nthat thought has a proprietary phenomenology.  \nThis line of argument relies heavily on introspection. Unfortunately, detractors of\ncognitive phenomenology (for example, Robinson 2011 and Tye &\nWright 2011) claim that their own observations of sudden realization\nreveal less phenomenology, resulting in an apparent stalemate.  \nSome experiences with a cognitive character seem to make a fairly good\ncase for a minimal amount of proprietary phenomenology of thought. For\nexample, Goldman (1993a) invokes the tip-of-the-tongue phenomenon to\nargue that thought has a proprietary phenomenology, an argument he\nattributes to Jackendoff (1987).  \nWhen one tries to say something but can’t think of the word, one\nis phenomenologically aware of having requisite conceptual structure,\nthat is, of having a determinate thought-content one seeks to\narticulate. What is missing is the phonological form: the sound of the\nsought-for word. The absence of this sensory quality, however, does\nnot imply that nothing (relevant) is in awareness. Entertaining the\nconceptual unit has a phenomenology, just not a sensory phenomenology.\n(Goldman 1993a: 24)  \nThe tip-of-the-tongue phenomenon occurs when one cannot think of a\nword, so it involves the absence of verbal phenomenology\ncorresponding to that word. But instances of this phenomenon do\ninvolve some phenomenology. Goldman proposes that this\nphenomenology is non-sensory.  \nLormand (1996) responds to this suggestion by providing an alternative\naccount of the relevant phenomenology on which it is sensory, which he\nalso takes to be supported by Jackendoff 1987. According to Lormand,\nthe relevant phenomenology involves a sensory phenomenal experience of\na void, which is akin to hearing silence, along with an experience of\neffort, whose phenomenology is also sensory.  \nPhenomenal consciousness has various epistemic markers: It gives rise\nto (at least the appearance of) an explanatory gap (see Levine 1983\nand the entry on\n consciousness),\n it is susceptible to zombie thought experiments (see Chalmers 1996\nand the entry on\n zombies),\n and it is susceptible to the knowledge argument (see Jackson 1982 and\nthe entry Qualia: The Knowledge Argument).\n These arguments usually focus on sensory phenomenal consciousness.\nFor example, Levine’s central example is that of pain and\nJackson’s is that of experiencing red.  \nThe initial plausibility of these kinds of arguments might be taken to\nserve as an indicator of phenomenal consciousness: plausibly, if these\narguments have some traction with some mental state, then that mental\nstate is likely to have phenomenal properties. Some have used the\npresence or absence of such markers to argue for or against cognitive\nphenomenology. \nGoldman (1993b) argues that a version of Jackson’s (1982)\nthought experiment can be run with propositional attitudes, such as\ndoubt and disappointment:  \nJackson’s example is intended to dramatize the claim that there\nare subjective aspects of sensations that resist capture in\nfunctionalist terms. I suggest a parallel style of argument for\nattitude types. Just as someone deprived of any experience of colors\nwould learn new things upon being exposed to them, viz., what it feels\nlike to see red, green, and so forth, so (I submit) someone who had\nnever experienced certain propositional attitudes, e.g., doubt or\ndisappointment, would learn new things on first undergoing these\nexperiences. There is “something it is like” to have these\nattitudes, just as much as there is “something it is like”\nto see red. (Goldman 1993b: 365)  \nIn other words, Goldman argues that Jackson’s thought experiment\nis compelling in the case of propositional attitudes and that this\nsupports the claim that propositional attitudes have proprietary\nphenomenal properties above and beyond functional properties.\n(Presumably, Goldman intends his argument to apply only to occurrent\npropositional attitudes, since he takes standing states to be purely\ndispositional (1993b: 366).) Goff (2012) makes similar observations.\n \nHorgan (2011a) also uses epistemic indicators of phenomenal\nconsciousness to argue for cognitive phenomenology. He argues that\nsince partial zombies lacking cognitive phenomenology are conceivable\nand phenomenally different from us, we have cognitive phenomenology.\n \nInterestingly, Carruthers and Veillet (2011) use epistemic indicators\nto argue against cognitive phenomenology. They claim that thought is\nnot susceptible to the explanatory gap, and thus that there is no\ncognitive phenomenology.  \nPitt (2004) argues that there is a kind of self-knowledge that can\nonly be explained by cognitive phenomenology. Pitt’s argument\nnot only aims to establish that there is a proprietary and\nindividuative cognitive phenomenology but also that this\nphenomenology is constitutive of thought’s content,\ni.e., that thought’s content is phenomenal intentional content.\n \nPitt’s argument runs as follows: Normally, we can consciously,\nintrospectively, and non-inferentially (1) distinguish an occurrent\nthought from other mental states, (2) distinguish an occurrent thought\nfrom other occurrent thoughts, and (3) identify which occurrent\nthoughts we are thinking. Pitt considers various explanations of these\nabilities, and argues that the only plausible explanation is that\nthought has a proprietary, individuative, and constitutive\nphenomenology. Thought’s proprietary phenomenology explains how\nwe can tell the difference between thoughts and other kinds of mental\nstates, thought’s individuative phenomenology explains how we\ncan tell the difference between one thought and another, and\nthought’s phenomenology being constitutive of its content\nexplains how we can identify which thoughts we are thinking.  \nLevine (2011) argues that Pitt (2004) fails to rule out an alternative\nexplanation of the relevant kind of self-knowledge: immediate\nself-knowledge is a matter of non-inferentially coming to have an\nintentional state that represents that one is thinking what one is in\nfact thinking. In having such a state, one is automatically aware of\nits content. Pitt (2011) responds that, when properly understood,\nLevine’s proposal can’t work unless there is the contested\nkind of cognitive phenomenology.  \nGoldman (1993a,b) also uses considerations from self-knowledge to\nargue for a phenomenology of thought. He argues that the way we can\ntell what mental states we are in is not through their functional\nroles or neural properties, but through their phenomenal properties.\nIn the case of cognitive states, the best explanation for how we can\ndiscriminate between different strengths of desires or degrees of\nbelief is that thoughts have an accompanying phenomenology.  PIT faces both in-principle challenges and empirical challenges. We\nhave already discussed the in-principle worry that phenomenal\nconsciousness is not metaphysically sufficient for intentionality\n(see section 4.1). Here, we\nfocus on the empirical challenges PIT faces in accommodating specific\nkinds of mental states.  The problematic mental states are those that might reasonably be taken to have intentionality without having phenomenal intentionality. Here we will discuss four types of mental\nstate that give rise to challenges of this kind: thoughts, standing\npropositional attitudes, wide intentional states, and occurrent\nunconscious states. These states don’t seem to be phenomenal\nintentional states, so it is not immediately clear how PIT can accommodate\nthem. \nThere are three general strategies for handling a problematic state:\neliminativism, inflationism, and derivativism. Eliminativism\nconsists in denying the existence of the putative intentional state\n(or denying that it is an intentional state).\nInflationism consists in claiming that the state in question\nis a phenomenal intentional state. In the case of thought, this\nstrategy often involves arguing for rich cognitive phenomenology (see\n section 5).\n Derivativism agrees that the problematic state is not a\nphenomenal intentional state, but maintains that it nonetheless\nderives its content in part from phenomenal intentional states and so is at least partly grounded in such states. We will now discuss these\nstrategies in more detail in relation to the four problematic kinds of\nstates.  \nThoughts are occurrent conceptual states, the kinds of states we have when we think, reflect, or muse over something. Examples of thoughts include\njudgments, occurrent beliefs, and occurrent desires. Thoughts, especially thoughts\nabout abstract ideas such as democracy and the square root function,\nmight seem to lack phenomenal properties. Even if thoughts have\nphenomenal properties, it does not seem that these phenomenal\nproperties are rich or determinate enough to fully account for their\nintentional properties. For example, these phenomenal properties might seem to be\nlimited to verbal and visual imagery.  \nInflationism is the most widely endorsed strategy for dealing with\noccurrent thoughts, at least in cases of thoughts that do not seem to\nhave wide contents (see\n 6.3 below\n for the latter). Strawson (1994, 2008), Siewert (1998), Horgan &\nTienson (2002), Horgan, Tienson & Graham (2004), and Pitt (2009)\nall hold that occurrent thought has a phenomenology that is rich and\ndeterminate enough to fix its intentional contents. Horgan &\nTienson (2002), Horgan, Tienson & Graham (2004), and Pitt (2009)\nalso argue that the difference between beliefs, desires, and other\nkinds of attitudes is phenomenally constituted. The case for this\napproach rests on the\n arguments for cognitive phenomenology\n we discuss above.  \nIn contrast, Loar (2003a,b), Bourget (2010, 2015), and Mendelovici (2010, 2018) maintain\nthat thoughts have a fairly impoverished phenomenology that cannot\nfully constitute all the contents we might want to attribute to them.\nLoar (2003a,b) endorses a derived content strategy on which much of\nthought’s content is determined by the “lateral\nconnections” between thoughts and other mental states. The\nnetwork of interconnected states eventually derives its content from\nphenomenal intentional states. Bourget (2010) adopts a derived content\nstrategy on which thoughts derive their contents from phenomenal\nintentional states through a variety of derivation mechanisms. \nMendelovici (2010, 2018) has a largely eliminativist take on the\nintentionality of thought. Like Pitt (2004, 2009), she holds that all\nintentional states are phenomenal intentional states, but unlike Pitt, she\nmaintains that the phenomenology of thought is too impoverished to\ncapture all the contents we might pre-theoretically want to attribute\nto thoughts. However, she recognizes the existence of derived\nrepresentational contents, which capture the rich contents we tend to\nattribute to thoughts. Derived representational states are not strictly\nspeaking intentional states, but they fill the role that intentional\nstates with rich contents have been thought to play. \nStanding propositional attitudes are states one is in independently of\nwhat one is thinking about or experiencing at the time (i.e., independently\nof one’s occurrent states). For example, five minutes ago you\nhad the standing belief that monkeys like bananas even though you\nweren’t occurrently thinking that content. Standing\npropositional attitudes do not seem to have phenomenal properties, and\nso, it seems their intentionality is not phenomenal\nintentionality. \nAs far as we can tell, no one has applied the inflationist strategy to\nstanding propositional attitudes—no one claims that they are\nphenomenal intentional states.  \nStrawson (2008) and Mendelovici (2010, 2018) adopt the eliminativist\nstrategy as part of their defenses of PIT: they deny that standing\nbeliefs and other standing propositional attitudes are intentional\nstates. As Strawson puts it, “To have a belief is not to be in\nany contentful mental state.” (p. 271) Rather, it is to be\ndisposed to be in such a state. Horgan & Tienson (2002)\nare not eliminativists about the intentionality of standing states,\nbut they do not consider them part of the scope of their version of\nPIT.  \nSearle (1990, 1991, 1992), Bourget (2010), and Kriegel (2011a,b) favor\nderivativism about standing states. Searle holds that non-phenomenal\nintentional states have their intentionality in virtue of\nsubjects’ dispositions to have conscious states. This account\napplies most naturally to standing propositional attitudes. Bourget\n(2010) holds a similar but more nuanced view according to which\nstanding propositional attitudes derive from connections to occurrent\nthoughts, which themselves either are phenomenal intentional states or\nderive their contents from distinct phenomenal intentional states (see\nthe next section on the derivativist strategy for thoughts). \nThe simple derived content approach defended by Searle and Bourget is\nopen to well-known objections. One of these objections, discussed by\nPeacocke (1998), is that a state that causes occurrent thoughts to the\neffect that P is not a belief that P unless it is\naccompanied by the right behavior. Imagine someone who claims not to\nbe sexist and tends to form occurrent non-sexist thoughts but who\nbehaves in demonstrably sexist ways. Such an individual is naturally\nsaid to have unconscious sexist beliefs. \nKriegel’s (2011a,b) account aims to explain standing states and\nunconscious occurrent states in a unified way. On his account, which\nhe calls interpretivism, a non-phenomenal state s has\na certain derived intentional content C just in case an ideal\ninterpreter is disposed to ascribe C to s. An ideal\ninterpreter is a being that is perfectly rational and knows all the\nphenomenal and non-phenomenal (but not derivatively intentional) facts\nabout the world. On the resulting derivativist view, non-phenomenal\nintentional states derive from an ideal interpreter’s phenomenal\nintentional states. \nThe disagreement between eliminativism and derivativism about standing\nstates might be partly terminological. Most of the above-mentioned\ntheorists agree that standing states are a matter of a certain kind of\ndisposition to have phenomenal states. What they disagree on is\nwhether the potentially conscious or dispositional states count as\nintentional states.  \nWide intentional states are intentional states that depend on\nrelations to items in our environments. They are states for which externalism is true\n(see\n section 4.3). Prime candidates of wide\nintentional states are thoughts about natural kinds (e.g.,\nH2O) and thoughts about individual objects (e.g., Bill Gates).\nArguably, subjects that are phenomenally alike and have all the\nsame phenomenal intentional states can nonetheless differ in their\nwide intentional states. So, it seems that wide intentional states are\nnot phenomenal intentional states.  \nA Twin Earth case helps illustrate the options available in the case\nof wide intentional states (see Putnam 1975). Consider two\nindividuals, Alice and Twin Alice. Alice lives on Earth, while Twin\nAlice lives on a copy of Earth located far away from us in this world.\nLet us suppose that Alice and Twin Alice are phenomenal\nduplicates: they instantiate all the same phenomenal properties throughout their existences. \nAlice and Twin Alice each have a brother called “Bob”. When\nAlice thinks a thought that she would express by making the sounds\n“Bob is happy”, it seems that her thought is true at just\nthe worlds where Bob is happy. By contrast, it seems that the thought\nthat Twin Alice expresses with “Bob is happy” in her\nidiolect is one that is true at just the worlds where Twin\nBob is happy. So it looks like the Alices’ thoughts have\ndifferent truth conditions. This suggests that the Alices’\nthoughts have different contents. Alice’s thought represents\nthat Bob is happy, while Twin Alice’s thought represents that\nTwin Bob is happy. The Alices’ “Bob”-thoughts are\nparadigmatic examples of putatively broad intentional states.  \nFew advocates of PIT seem to endorse an inflationist strategy for\nbroad intentional states. Even advocates of PIT who take consciousness\nto be relational seem to agree that what a subject gets\nrelated to in consciousness depends solely on her intrinsic properties\n(Pautz 2010). However, Campbell (2002) holds that perceptual\nexperience is broad and intentional, and his view might be counted as\na type of phenomenal intentionality theory.  \nSiewert (1998), Kriegel (2007), and Farkas (2008a) adopt an\neliminativist strategy with respect to broad intentional states. Their\nviews are the same in broad outline. On their views, the two\nAlices’ thoughts have the same content, and that content is\nnarrow. We can account for the fact that the two Alices’\nthoughts are made true by different Bobs by adding contextual\nparameters to their shared content: their shared content is not a\nfunction from possible worlds to truth values but a function from\npossible worlds and relevant elements of context to truth values. The\nintroduction of contexts enables us to account for the fact that the\nAlices’ thoughts are true at different worlds. For example, one\n(over-simplistic) view along these lines could state that the shared\ncontent of the two Alices’ thoughts can be modeled as a function\nfrom worlds W and contexts of use C that returns true\njust in case the person that bears the name “Bob” in\nC is happy in W. Given that different contexts are\nrelevant to Alice and Twin Alice, different worlds can satisfy the\ncommon thought they express as “Bob is happy”. If this is\nthe right way to think about content, the Bobs’ case and other\ncases motivating broad content do not force us to recognize broad\ncontents.  \nPitt (1999, 2011) also endorses an eliminativist strategy, arguing\nagainst externalist intuitions. Mendelovici (2010, 2018) also endorses\neliminativism but claims that she can capture many externalist\nintuitions through the notion of derived mental representation (see\nthe previous section).  \nDerivativist strategies have also been applied to broad\ncontents (Loar 2003a,b, Horgan and Tienson 2002, Horgan, Tienson &\nGraham 2004, Bourget 2010, Chalmers 2010). The idea here is that broad\nintentional states have two contents: a phenomenally constituted\nnarrow content, and a broad content that is determined by the narrow\ncontent together with relevant factors in the environment. So\nAlice’s thought has two contents: one narrow and one broad. The\nbroad content of her thought is true at just the worlds where Bob is\nhappy. The narrow content is true at the worlds where a person bearing\ncertain Bob-like characteristics is happy. The relevant Bob-like\ncharacteristics might, for example, centrally involve being called\n“Bob” by people of a certain community.  \nOf course, such a derivativist approach is compatible with other accounts of the narrow content of Alice’s\nthought. The options available to proponents of PIT are the\nsame as for theories of narrow content in general. For instance, this\nderivativist approach can draw on all the resources of\ntwo-dimensional theories of narrow content (see Chalmers 2002a and the\nentries on\n two-dimensional semantics\n and\n narrow mental content).\n  \nPautz (2008, 2013, 2017) offers a related derivativist approach that he dubs\nconsciousness-based best systems theory. On this view, facts about (sensory)\nphenomenal states and their internal causal roles fix the facts about\nwhat is rational for an agent to believe. These facts about\nrationality in turn fix the narrow contents of an individual’s\nbeliefs. Wide contents are fixed by causal relations between beliefs\nand the environment. \nCognitive science posits various kinds of occurrent unconscious\nrepresentation, e.g., dorsal stream states and internal\nrepresentations of syntactic structures. It seems that such states\nhave intentional properties but lack phenomenal properties, so their\nintentionality cannot be phenomenal intentionality.  \nSome supporters of PIT adopt an eliminativist strategy towards such\nunconscious states. Searle (1990, 1991, 1992) argues, roughly, for the\nclaim that only conscious or potentially conscious states exhibit\nintentionality. Since most unconscious states posited by cognitive\nscience are not potentially conscious, they are not intentional.\nSearle presents this view of unconscious states as being in conflict\nwith cognitive science. In contrast, Graham, Horgan, and Tienson\n(2007) and Mendelovici (2018) highlight the agreement between the\nassumptions of cognitive science and eliminativism about unconscious\nstates: everyone agrees that unconscious states play functional roles,\nbear tracking relations to things in the environment, and have no\nphenomenal properties. Everyone also agrees that it can be fruitful to\ntreat unconscious states as if they represented certain contents. The\nmain disagreement is over whether unconscious states really do qualify\nas intentional.  \nBourget (2010, 2015) and Pitt (2009,\n Other Internet Resources)\n suggest that an inflationist strategy may be acceptable in case of at\nleast some unconscious occurrent states. On their views, we can have\nphenomenal states that we are not aware of. Unconscious occurrent\nstates could be such states. \nA derived content strategy is also an option in the case of some\nunconscious occurrent states. Bourget (2010) argues for this strategy\nby arguing for the claim that the low-level systems that allegedly support\nunconscious occurrent intentional states don’t seem intentional\nwhen they are taken out of the organisms in which they belong.\nKriegel’s interpretivism (2011a,b) is also meant to apply to\nunconscious occurrent states (see\n section 6.2).","contact.mail":"amendel5@uwo.ca","contact.domain":"uwo.ca"}]
