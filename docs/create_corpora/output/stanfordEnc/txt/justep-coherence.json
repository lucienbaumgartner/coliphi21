[{"date.published":"2003-11-11","date.changed":"2021-03-09","url":"https://plato.stanford.edu/entries/justep-coherence/","author1":"Erik Olsson","entry":"justep-coherence","body.text":"\n\n\nAccording to the coherence theory of justification, also known as\ncoherentism, a belief or set of beliefs is justified, or justifiably\nheld, just in case the belief coheres with a set of beliefs, the set\nforms a coherent system or some variation on these themes. The\ncoherence theory of justification should be distinguished from the\ncoherence theory of truth. The former is a theory of what it\nmeans for a belief or a set of beliefs to be justified, or for a\nsubject to be justified in holding the belief or set of beliefs. The\nlatter is a theory of what it means for a belief or proposition to be\ntrue. Modern coherence theorists, in contrast to some earlier writers\nin the British idealist tradition, typically subscribe to a coherence\ntheory of justification without advocating a coherence theory of\ntruth. Rather, they either favor a correspondence theory of truth or\ntake the notion of truth for granted, at least for the purposes of\ntheir epistemological investigations. This does not prevent many\nauthors from claiming that coherence justification is an indication or\ncriterion of truth.\n\nA central problem in epistemology is to explain when we are justified in holding\na proposition to be true. It is not at all evident what epistemic\njustification is, and classical accounts of that notion have turned\nout to be severely problematic. A tradition inspired by Descartes holds that justified beliefs are those that are either self-evidently true or deduced from self-evident truths.  But, as is often argued, little of what we\ntake ourselves to justifiably believe satisfies these austere\nconditions: many of our apparently justified beliefs, it is commonly\nthought, are neither based on self-evident truths nor derivable in a\nstrict logical sense from other things we believe in. Thus, the\nCartesian rationalist picture of justification seems far too\nrestrictive. Similar problems hound empiricist attempts to ground all\nour knowledge in the allegedly indubitable data of the senses.\nDepending on how they are understood, sense data are either not\nindubitable or else not informative enough to justify a sufficient\nportion of our purported knowledge. The exact characterization of\nfoundationalism is a somewhat contentious issue. There is another form\nof foundationalism according to which some beliefs have some\nnon-doxastic source of epistemic support that requires no support of\nits own. This support can be defeasible and it can require\nsupplementation to be strong enough for knowledge. This sort of\nnon-doxastic support would terminate the regress of justification. To\ndo so it may not have to appeal to self-evidence, indubitability or\ncertainty. Such foundationalist views vary on the source of the\nnon-doxastic support, how strong the support is on its own, and what\nrole in justification coherence plays, if any. Some critics of this\nposition have questioned the intelligibility of the non-doxastic\nsupport relation. Thus, Davidson (1986) complains that advocates have\nbeen unable to explain the relation between experience and belief that\nallows the first to justify the second. \nThe difficulties pertaining to both rationalism and empiricism about\njustification have led many epistemologists to think that there must\nbe something fundamentally wrong with the way in which the debate has\nbeen framed, prompting their rejection of the foundationalist\njustificatory structure underlying rationalism and empiricism alike.\nRather than conceiving the structure of our knowledge on the model of\nEuclidean geometry, with its basic axioms and derived theorems, these\nepistemologists favor a holistic picture of justification which does\nnot distinguish between basic or foundational and non-basic or derived\nbeliefs, treating rather all our beliefs as equal members of a\n“web of belief” (Quine and Ullian 1970, cf. Neurath\n1983/1932 and Sosa 1980). \nThe mere rejection of foundationalism is not itself an alternative\ntheory because it leaves us with no positive account of justification,\nsave a suggestive metaphore about webs of belief. A more substantial\ncontrasting proposal is that what justifies our beliefs is ultimately\nthe way in which they hang together or dovetail so as to produce a\ncoherent set. As Davidson puts it, “[w]hat distinguishes a\ncoherence theory is simply the claim that nothing can count as a\nreason for a belief except another belief” (Davidson, 1986). The\nfact that our beliefs cohere can establish their truth, even though\neach individual belief may lack justification entirely if considered\nin splendid isolation, or so it is thought. Following C. I. Lewis\n(1946), some proponents think of this situation as analogous to how\nagreeing testimonies in court can lead to a verdict although each\ntestimony by itself would be insufficient for that purpose. \nThere is a serious objection that any coherence theory of\njustification or knowledge must immediately face. It is called the\nisolation objection: how can the mere fact that a system is\ncoherent, if the latter is understood as a purely system-internal\nmatter, provide any guidance whatsoever to truth and reality? Since\na coherence theory, in its basic form, does not assign any essential role to experience, there is\nlittle reason to think that a coherent system of belief will\naccurately reflect the external world. A variation on this theme is\npresented by the equally notorious alternative systems\nobjection. For each coherent system of beliefs there exist,\nconceivably, other systems that are equally coherent yet incompatible\nwith the first system. If coherence is sufficient for justification,\nthen all these incompatible systems would be justifiably held. But this\nobservation, of course, thoroughly undermines any claim suggesting\nthat coherence is indicative of truth. \nAs we shall see, most, if not all, influential coherence theorists try\nto avoid these traditional objections by assigning some beliefs that\nare close to experience a special role, whether they are called\n“supposed facts asserted” (Lewis, 1946),\n“truth-candidates” (Rescher, 1973), “cognitively\nspontaneous beliefs” (BonJour, 1985) or something else.\nDepending on how this special role is construed, these theories are often\nclassified as versions of weak\nfoundationalism. An advocate of\nweak foundationalism typically holds that while coherence is incapable\nof justifying beliefs from scratch, it can provide justification for\nbeliefs that already have some initial, perhaps miniscule, degree of\nwarrant, e.g., for observational beliefs. \nA fair number of distinguished contemporary philosophers have declared\nthat they advocate a coherence theory of justification. Apart from\nthis superficial fact, these theories often address some rather\ndiverse issues loosely united by the fact that they in one way or the\nother take a holistic approach to the justification of beliefs. Here\nare some of the problems and questions that have attracted the\nattention of coherence theorists (cf. Bender, 1989): \nThe fact that these separate, though related, issues are not always\nclearly distinguished presents a challenge to the reader of the\nrelevant literature. \nAlthough the regress problem is not a central contemporary issue, it\nis helpful to explain coherence theories as responses to the problem.\nThis will also serve to illustrate some challenges that a coherence\ntheory faces. We will then turn to the concept of coherence itself as\nthat concept is traditionally conceived. Unfortunately, not all\nprominent authors associated with the coherence theory use the term\ncoherence in this traditional sense, and the section that follows is\ndevoted to such non-standard coherence theories. The arguably most\nsystematic and prolific discussion of the coherence theory of\njustification has focused on the relationship between coherence and\nprobability. The rest of this entry will be devoted to this\ndevelopment, which took off in the mid-1990s inspired by seminal work\nby C. I. Lewis (1946). The development has given us precise and\nsophisticated definitions of coherence as well as detailed studies of\nthe relationship between coherence and truth (probability),\nculminating in some potentially disturbing impossibility results that\nshed doubt on the possibility of defining coherence in a way that\nmakes it indicative of truth. More precise descriptions of key\nentailments of these results, and ways to address the worries that\nthey raise, will be discussed in later sections of this entry. \nOn the traditional justified true belief account of knowledge, a\nperson cannot be said to know that a proposition \\(p\\) is true\nwithout having good reasons for believing that \\(p\\) is true. If\nLucy knows that she will pass tomorrow’s exam, she must have good\nreasons for thinking that this is so. Consider now Lucy’s reasons.\nThey will presumably consist of other beliefs she has, e.g., beliefs\nabout how well she did earlier, about how well she has prepared, and\nso on. For Lucy to know that she will pass the exam, these other\nbeliefs, upon which the first belief rests, must also be things that\nLucy knows. Knowledge, after all, cannot be based on something less\nthan knowledge, i.e., on ignorance (cf. Rescher 1979, 76). Since the\nreasons are themselves things that Lucy knows, those reasons must in\nturn be based on reasons, and so on. Thus, any knowledge claim\nrequires a never-ending chain, or “regress”, of reasons\nfor reasons. This seems strange, or even impossible, because it\ninvolves reference to an infinite number of beliefs. But most of us\nthink that knowledge is possible. \nWhat is the coherentist’s response to the regress? The coherentist can\nbe understood as proposing that nothing prevents the regress from\nproceeding in a circle. Thus, \\(A\\) can be a reason for \\(B\\)\nwhich is a reason for \\(C\\) which is a reason for \\(A\\). If this\nis acceptable, then what we have is a chain of reasons that is\nnever-ending but which does not involve an infinite number of beliefs.\nIt is never-ending in the sense that for each belief in the chain\nthere is a reason for that belief also in the chain. Yet there is an\nimmediate problem with this response due to the fact that\njustificatory circles are usually thought to be vicious ones. If\nsomeone claims \\(C\\) and is asked why she believes it, she may\nreply that her reason is \\(B\\). If asked why she believes \\(B\\),\nshe may assert \\(A\\). But if prompted to justify her belief in\n\\(A\\), she is not allowed to refer back to \\(C\\) which in the\npresent justificatory context is still in doubt. If she did justify\n\\(A\\) in terms of \\(C\\) nonetheless, her move would lack any\njustificatory force whatsoever. \nThe coherentist may respond by denying that she ever intended to\nsuggest that circular reasoning is a legitimate dialectical strategy.\nWhat she objects to is rather the assumption that justification should\nat all proceed in a linear fashion whereby reasons are given for\nreasons, and so on. This assumption of linearity presupposes that what\nis, in a primary sense, justified are individual beliefs. This, says\nthe coherentist, is simply wrong: it is not individual beliefs that\nare primarily justified, but entire belief systems. Particular beliefs\ncan also be justified but only in a secondary or derived sense, if\nthey form part of a justified belief system. This is a coherence\napproach because what makes a belief system justified, on this view,\nis precisely its coherence. A belief system is justified if it is\ncoherent to a sufficiently high degree. This, in essence, is Laurence\nBonJour’s 1985 solution to the regress problem. \nThis looks much more promising than the circularity theory. If\nepistemic justification is holistic in this sense, then a central\nassumption behind the regress is indeed false, and so the regress\nnever gets started. Even so, this holistic approach raises many new\nquestions to which the coherentist will need to respond. First of all,\nwe need to get clearer on what the concept of coherence involves as\nthat concept is applied to a belief system. This is the topic of the\nnext section. Second, the proposal that a singular belief is justified\nmerely in virtue of being a member of a justified totality can be\nquestioned because, plausibly, a belief can be a member of a\nsufficiently coherent system without in any way adding to the\ncoherence of that system, e.g., if the belief is the only member which\ndoes not quite fit in an otherwise strikingly coherent system. Surely,\na belief will have to contribute to the coherence of the\nsystem in order to become justified by that system. A particular\nbelief needs, in other words, to cohere with the system of\nwhich it is a member if that belief is to be considered justified. We\nwill turn to this issue in section 4, in connection with Keith\nLehrer’s epistemological work. Finally, we have seen that most\ncoherence theories assign a special role to some beliefs that are\nclose to experience in order to avoid the isolation and alternative\nsystems objections. This fact raises the question of what status those\nspecial beliefs have. Do they have to have some credibility in\nthemselves or can they be totally lacking therein? A particularly\nclear debate on this topic is the Lewis-BonJour controversy over the\npossibility of justification by coherence from scratch, which we will\nexamine more closely in section 5. \nBy a traditional account of coherence we will mean one which construes\ncoherence as a relation of mutual support or agreement among given\ndata (propositions, beliefs, memories, testimonies etc.). Early\ncharacterizations were given by, among others, Brand Blanshard (1939)\nand A. C. Ewing (1934). According to Ewing, a coherent set is\ncharacterized partly by consistency and partly by the property that\nevery belief in the set follows logically from the others taken\ntogether. Thus, a set such as \\(\\{A_1,\nA_2, A_1 \\amp A_2\\}\\),\nif consistent, is highly coherent on this view because each element\nfollows by logical deduction from the rest in concert. \nWhile Ewing’s definition is admirably precise, it defines coherence\ntoo narrowly. Few belief sets that occur naturally in everyday life\nsatisfy the austere second part of his definition: the requirement\nthat each element follow logically from the rest when combined.\nConsider, for instance, the set consisting of propositions \\(A,\nB\\) and \\(C\\), where \nThis set is intuitively coherent, and yet it fails to satisfy Ewing’s\nsecond condition. The proposition \\(A\\), for instance, does not\nfollow logically from \\(B\\) and \\(C\\) taken together: that John\nowns a gun of the relevant type and deposited money in his bank the\nday after does not logically imply him being at the crime scene at the\ntime of the crime. Similarly, neither \\(B\\) nor \\(C\\) follows\nfrom the rests of the propositions in the set by logic alone. \nC. I. Lewis’s definition of coherence, or “congruence” to\nuse his term, can be seen as a refinement and improvement of Ewing’s\nbasic idea. As Lewis defines the term, a set of “supposed facts\nasserted” is coherent (congruent) just in case every element in\nthe set is supported by all the other elements taken together, whereby\n“support” is understood not in logical terms but in a\nprobabilistic sense. In other words, \\(P\\) supports \\(Q\\) if and\nonly if the probability of \\(Q\\) is raised on the assumption that\n\\(P\\) is true. As is readily appreciated, Lewis’s definition is\nless restrictive than Ewing’s: more sets will turn out to be coherent\non the former than on the latter. (There are some uninteresting\nlimiting cases for which this is not true. For instance, a set of\ntautologies will be coherent in Ewing’s but not in Lewis’s sense.\nThere cases are not interesting because they are not significant parts\nof anyone’s actual body of beliefs.) \nLet us return to the example with John. The proposition \\(A\\),\nwhile not logically entailed by \\(B\\) and \\(C\\), is under normal\ncircumstances nevertheless supported by those propositions taken\ntogether. If we assume that John owns the relevant type of gun and\ndeposited a large sum the next day, then this should raise the\nprobability that John did it and thereby also raise the probability\nthat he was at the crime scene when the robbery took place. Similarly,\none could hold that each of \\(B\\) and \\(C\\) is supported, in the\nprobabilistic sense, by the other elements of the set. If so, this set\nis not only coherent in an intuitive sense but also coherent according\nto Lewis’s definition. Against Lewis’s proposal one could hold that it\nseems arbitrary to focus merely on the support single elements of a\nset receive from the rest of the set (cf. Bovens and Olsson 2000). Why\nnot consider the support any subset, not just singletons, receives\nfrom the rest? \nAnother influential proposal concerning how to define coherence\noriginates from Laurence BonJour (1985), whose account is considerably\nmore complex than earlier suggestions. Where Ewing and Lewis proposed\nto define coherence in terms of one single concept—logical\nconsequence and probability, respectively—BonJour thinks that\ncoherence is a concept with a multitude of different aspects\ncorresponding to the following “coherence criteria”\n(97–99): \nA difficulty pertaining to theories of coherence that construe\ncoherence as a multidimensional concept is to specify how the\ndifferent dimensions are to be amalgamated so as to produce an overall\ncoherence judgment. It could well happen that one system \\(S\\) is\nmore coherent than another system \\(T\\) in one respect, whereas\n\\(T\\) is more coherent than \\(S\\) in another. Perhaps \\(S\\)\ncontains more inferential connections than \\(T\\), but \\(T\\) is\nless anomalous than \\(S\\). If so, which system is more coherent in\nan overall sense? Bonjour’s theory is largely silent on this\npoint. \nBonJour’s account also raises another general issue. The third\ncriterion stipulates that the degree of coherence increases with the\nnumber of inferential connections between different parts of the\nsystem. Now as a system grows larger the probability that there will\nbe relatively many inferentially connected beliefs is increased simply\nbecause there are more possible connections to be made. Hence, one\ncould expect there to be a positive correlation between the size of a\nsystem and the number of inferential connection between the beliefs\ncontained in the system. BonJour’s third criterion, taken at face\nvalue, entails therefore that a bigger system will generally have a\nhigher degree of coherence due to its sheer size. But this is at least\nnot obviously correct. A possible modified coherence criterion could\nstate that what is correlated with higher coherence is not the number\nof inferential connections but rather the inferential density\nof the system, where the latter is obtained by dividing the number of\ninferential connections by the number of beliefs in the system. \nWe will return, in section 6, to the problem of defining the\ntraditional concept of coherence while addressing some of the concerns\nthat we have raised, e.g., concerning the relationship between\ncoherence and system size. The point of departure for the present\ndiscussion, however, is the observation that several prominent\nself-proclaimed coherentists construe the central concept, and to some\nextent also its role in philosophical inquiry, in ways that depart\nsomewhat from the traditional view. Among them we find Nicolas\nRescher, Keith Lehrer and Paul Thagard. \nCentral in Rescher’s account, as laid out in Rescher (1973), his most\ninfluential book on the subject, is the notion of a truth-candidate. A\nproposition is a truth-candidate if there is something that speaks in\nits favor. Rescher’s truth-candidates are related to Lewis’s\n“supposed facts asserted”. In both cases, the propositions\nof interest are prima facie rather than bona fide\ntruths. Although Rescher’s 1973 book is entitled A Coherence\nTheory of Truth, the purpose of Rescher’s investigation is not to\ninvestigate the possibility of defining truth in terms of\ncoherence but to find a truth criterion, which he understands\nto be a systematic procedure for selecting from a set of conflicting\nand even contradictory truth-candidates those elements which it is\nrational to accept as bona fide truths. His solution amounts\nto first identifying the maximal consistent subsets of the original\nset, i.e., the subsets that are consistent but would become\ninconsistent if extended by further elements of the original set, and\nthen choosing the most “plausible” among these subsets.\nPlausibility is characterized in way that reveals no obvious relation\nto the traditional concept of coherence. While the traditional concept\nof coherence plays a role in the philosophical underpinning of\nRescher’s theory, it does not figure essentially in the final product.\nIn a later book, Rescher develops a more traditional\n“system-theoretic” view on coherence (Rescher 1979). \nKeith Lehrer employs the concept of coherence in his definition of\njustification, which in turn is a chief ingredient in his complex\ndefinition of knowledge. According to Lehrer, a person is justified in\naccepting a proposition just in case that proposition coheres with the\nrelevant part of her cognitive system. This is the relational concept\nof coherence alluded to earlier. In Lehrer (1990), the relevant part\nis the “acceptance system” of the person, consisting of\npropositions to the effect that the subject accepts this and that.\nThus, “\\(S\\) accepts that \\(A\\)” would initially be\nin \\(S\\)’s acceptance system, but not \\(A\\) itself. In later\nworks, Lehrer has emphasized the importance of coherence with a more\ncomplex cognitive entity which he calls the “evaluation\nsystem” (e.g., Lehrer 2000 and 2003). \nThe starting point of Lehrer’s account of coherence is the fact that\nwe can think of all sorts of objections an imaginative critic may\nraise to what a person accepts. These objections might be directly\nincompatible with what that person accepts or they might threaten to\nundermine her reliability in making assessments of the kind in\nquestion. For instance, a critic might object to her claim that she\nsees a tree by suggesting that she is merely hallucinating. That would\nbe an example of the first sort of objection. An example of the second\nsort would be a case in which the critic replies that the person\ncannot tell whether she is hallucinating or not. Coherence, and\n(personal) justification, results when all objections have been\nmet. \nLehrer’s concept of coherence does not seem to have much in common\nwith the traditional concept of mutual support. If one takes it as\nessential that such a theory make use of a concept of systematic or\nglobal coherence, then Lehrer’s theory is not a coherence theory in\nthe traditional sense because, in Lehrer’s view, “[c]oherence\n… is not a global feature of the system” (1997, 31), nor\ndoes it depend on global features of the system (31). A critic may\nwonder what reasons there are for calling the relation of meeting\nobjections to a given claim relative to an evaluation system a\nrelation of coherence. Lehrer’s answer seems to be that it is\na relation of “fitting together with”, rather than, say, a\nrelation of “being inferable from”: “[i]f it is more\nreasonable for me to accept one of [several] conflicting claims than\nthe other on the basis of my acceptance system, then that claim fits\nbetter or coheres better with my acceptance system” (116), and\nso “[a] belief may be completely justified for a person because\nof some relation of the belief to a system to which it belongs, the\nway it coheres with the system, just as a nose may be beautiful\nbecause of some relation of the nose to a face, the way it fits with\nthe face” (88). Olsson (1999) has objected to this view by\npointing out that it is difficult to understand what it means for a\nbelief to fit into a system unless the former does so in virtue of\nadding to the global coherence of the latter. \nPaul Thagard’s theory is clearly influenced by the traditional concept\nof coherence but the specific way in which the theory is developed\ngives it a somewhat non-traditional flavor, in particular considering\nits strong emphasis on explanatory relations between beliefs. Like\nRescher, Thagard takes the fundamental problem to be which elements of\na given set of typically conflicting claims that have the status of\nprima facie truths to single out as acceptable. However,\nwhere Rescher proposes to base the choice of acceptable truths on\nconsiderations of plausibility, Thagard suggests the use of\nexplanatory coherence for that purpose. \nAccording to Thagard, prima facie truths can cohere (fit\ntogether) or “incohere” (resist fitting together). The\nfirst type of relation includes relations of explanation and\ndeduction, whereas the second type includes various types of\nincompatibility, such as logical inconsistency. If two propositions\ncohere, this gives rise to a positive constraint. If they incohere,\nthe result is a negative constraint. A positive constraint between two\npropositions can be satisfied either by accepting both or by rejecting\nboth. By contrast, satisfying a negative constraint means accepting\none proposition while rejecting the other. A “coherence\nproblem”, as Thagard sees it, is one of dividing the initial set\nof propositions into those that are accepted and those that are\nrejected in such a way that most constraints are satisfied. Thagard\npresents several different computational models for solving coherence\nproblems, including a model based on neural networks. \nHow acceptability depends on coherence, more precisely, is codified in\nThagard’s “principles of explanatory coherence” (Thagard,\n2000): \nPrinciple E4 (Data Priority) reveals that Thagard’s theory is not a\npure coherence theory, as it gives some epistemic priority to\nobservational beliefs, making it rather a form of weak\nfoundationalism, i.e., the view that some propositions have some\ninitial epistemic support apart from coherence. Moreover, Thagard’s\ntheory is based on binary coherence/incoherence relations, i.e.,\nrelations holding between two propositions. His basic theory does not\nhandle incompatibilities that involve, in an essential way, more than\ntwo propositions. But incompatibilities of that sort may very well\narise, as exemplified by the three propositions “Jane is taller\nthan Martha”, “Martha is taller than Karen” and\n“Karen is taller than Jane”. Nevertheless, Thagard reports\nthe existence of computational methods for converting constraint\nsatisfaction problems whose constraints involve more than two elements\ninto problems that involve only binary constraints, concluding that\nhis characterization of coherence “suffices in principle for\ndealing with more complex coherence problems with nonbinary\nconstraints” (Thagard 2000, 19). Thagard (2009) argues that\nthere is a connection between explanatory coherence and (approximate)\ntruth, where explaining consists in describing causal mechanisms.\nSeveral other authors have advocated coherence theories that emphasize\nthe importance of explanatory relations. See, for example, Lycan\n(1988, 2012) and, for a book-length defense of explanatory\ncoherentism, Poston (2014). Also related to Thagard’s work is Susan Haack’s so-called foundherentist theory, which draws on a proposed analogy between coherence justification (with foundationalist ingredients) and crossword puzzle-solving (Haack, 2009). \nThe arguably most significant development of the coherence theory in\nrecent years has been the revival of C. I. Lewis’s work and the\nresearch program he inspired by translating parts of the coherence\ntheory into the language of probability. The kind of coherence in\nquestion should be distinguished from a probability function being\ncoherent in the sense of conforming to the axioms of the probability\ncalculus. The theory of coherence that we are concerned with here is\nan application of such coherent probability functions to model\ncoherence as mutual support, agreement etc. Thus “probabilistic\ncoherence” means something else than it does in standard\nBayesian theories. The probabilistic translations of coherence theory\nhas made it possible to define concepts and prove results with\nmathematical precision. It has also led to increased transferability\nof concepts and results across fields, e.g., between coherence theory\nand confirmation theory as it is studied in philosophy of science. As\na result, the study of coherence has developed into an\ninterdisciplinary research program with connections to philosophy of\nscience, cognitive psychology, artificial intelligence and philosophy\nof law. The rest of this article will be devoted to this recent\ntransformation of the subject. \nTo introduce Lewis’s view on the role of coherence, consider the\nfollowing famous passage on “relatively unreliable witnesses who\nindependently tell the same story” from his 1946 book: \nWhile Lewis allows that individual reports need not be very credible\nconsidered in isolation for coherence to have a positive effect, he is\nfirmly committed to the view that their credibility must not be nil.\nHe writes, in his discussion of reports from memory, that “[i]f\n… there were no initial presumption attaching to the mnemically\npresented … then no extent of congruity with other such items\nwould give rise to any eventual credibility” (357). In other\nwords, if the beliefs in a set have no initial credibility, then no\njustification will ensue from observing the coherence of that set.\nThus, Lewis is advocating weak foundationalism rather than a pure\ncoherence theory. \nIn apparent agreement with Lewis, Laurence BonJour (1985, 148) writes:\n“[a]s long as we are confident that the reports of the various\nwitnesses are genuinely independent of each other, a high enough\ndegree of coherence among them will eventually dictate the hypothesis\nof truth telling as the only available explanation of their\nagreement.” However, BonJour proceeds to reject Lewis’s point\nabout the need for positive antecedent credibility: “[w]hat\nLewis does not see, however, is that his own [witness] example shows\nquite convincingly that no antecedent degree of warrant or credibility\nis required” (148). BonJour is here apparently denouncing\nLewis’s claim that coherence will not have any confidence boosting\npower unless the sources are initially somewhat credible. BonJour is\nproposing that coherence can play this role even if there is no\nantecedent degree of warrant, so long as the witnesses are delivering\ntheir reports independently. \nSeveral authors have objected to this claim of BonJour’s, arguing that\ncoherence does not have any effect on the probability of the report\ncontents if the independent reports lack individual credibility. The\nfirst argument to that effect was given by Michael Huemer (1997). A\nmore general proof in the same vein is presented in Olsson (2002).\nWhat follows is a sketch of the latter argument for the special case\nof two testimonies, couched essentially in the terminology of Huemer\n(2011). In the following, all probabilities are assumed to lie\nstrictly between 0 and 1. \nLet \\(E_1\\) be the proposition that the first witness\nreports that \\(A\\), and let \\(E_2\\) be the proposition\nthat the second witness reports that \\(A\\). Consider the following\nconditions: \nConditional Independence\n\\(P(E_2 \\mid E_1, A) = P(E_2 \\mid A)\\)\n\n\\(P(E_2 \\mid E_1,\\neg A) = P(E_2 \\mid \\neg A)\\)\n \nNonfoundationalism\n\\(P(A \\mid E_1) = P(A)\\)\n\n\\(P(A \\mid E_2) = P(A)\\)\n \nCoherence Justification\n\\(P(A \\mid E_1, E_2) \\gt P(A)\\)\n \nConditional independence is intended to capture the idea that the\ntestimonies are independent in the sense that there is no direct\ninfluence between the testimonies. The probability of a testimony is\ninfluenced only by the fact it reports on, meaning that once that fact\nis given, this “screens off” any probabilistic influence\nbetween the individual testimonies making them irrelevant to each\nother. Nonfoundationalism states that neither testimony confers any\njustification upon \\(A\\) by itself: assuming merely that one single\nwitness has testified that \\(A\\) has no effect on the probability\nof \\(A\\). Finally, Coherence Justification states that testimonies,\nwhen combined, do provide justification for \\(A\\). \nThe debate between Lewis and BonJour can be reconstructed as a debate\nover the joint consistency of these three conditions. BonJour is\nclaiming that the conditions are jointly consistent, and that\nCoherence Justification follows from Conditional Independence even in\nthe context of Nonfoundationalism, whereas Lewis is rejecting these\nclaims. Olsson (2002) established that if the dispute is couched in\nthese terms, then Lewis was provably right. From Conditional\nIndependence and Nonfoundationalism it follows, via Bayes’s theorem,\nthat \nso that combining collectively independent but individually useless\ntestimonies, however coherent, fails to give rise to anything useful.\n(As noted in Olsson, 2005, section 3.5, the matter is somewhat\ncomplicated by the fact that Lewis adopted a notion of independence\nthat is weaker than Conditional Independence. Ironically, Lewis’s\nweaker notion turns out to be compatible with the combination of\nNonfoundationalism and Coherence Justification.) \nNonfoundationalism should be contrasted with the following\ncondition: \nWeak Foundationalism\n\\(P(A \\mid E_1) \\gt P(A)\\)\n\n\\(P(A \\mid E_2) \\gt P(A)\\)\n \nWeak Foundationalism does not by itself entail Coherence\nJustification: it is common knowledge in probability theory that even\nif two pieces of evidence each support a given conclusion, that\nsupport may disappear, or even turn into disconfirmation, if they are\ncombined. However, in the context of Conditional Independence, Weak\nFoundationalism does imply Coherence Justification. Indeed, the\ncombined testimonies will, in this case, confer more support upon the\nconclusion than the testimonies did individually. As confirmed by\nJames Van Cleve (2011), the conclusions supported by these\nconsiderations are that coherence can boost justification or\ncredibility that is already there without being able to create such\njustification or credibility from scratch. \nThere are various ways to save the coherence theory from this\nprobabilistic attack. The most radical strategy would be to dismiss\nthe probabilistic framework as altogether unsuitable for coherentism.\nIndependent reasons for this response can be found in Thagard’s work\n(e.g., Thagard 2000 and 2005). A less radical approach would be to\nrefrain from any blanket dismissal of probability theory in this\ncontext but reject one of the premises of the troublesome proof. This\nis the strategy recently taken by Huemer, who now considers his 1997\nprobabilistic refutation of coherentism to be mistaken (Huemer 2011,\n39, footnote 6). While he thinks that Coherentist Justification\ncorrectly captures a minimal sense of coherentism, he reports\ndissatisfaction with both Conditional Independence and\nNonfoundationalism (his term for the latter is “Strong\nNonfoundationalism”). Huemer now thinks independence, in the\nintuitive sense, is better captured by the condition\n\\(P(E_2 \\mid E_1, A) \\gt P(E_2 \\mid E_1, \\neg A)\\).\nMoreover, he takes the condition \\(P(A \\mid E_1, \\neg E_2) = P(A)\\),\nor “Weak Nonfoundationalism” in his terminology, to be a\nmore suitable explication of nonfoundationalist intuitions than the\ncondition \\(P(A \\mid E_1) = P(A)\\). He goes on to show that they are jointly\nconsistent with Coherentist Justification: there are probability\ndistributions satisfying all three conditions. Thus the immediate\nthreat to coherentism presented by the observed inconsistency of the\nthree original conditions has been neutralized, even though a critic\nmight point out that the defense is weak since it has not been shown\nthat Coherence Justification follows from the two new conditions. \nWhatever merits Huemer’s new conditions might have, their standing in\nthe literature is hardly comparable to that of the original\nconditions. Conditional Independence, for instance, is an extremely\npowerful and intuitive concept which has been put to fruitful use in\nmany areas in philosophy and computer science, the most spectacular\nexample being the theory of Bayesian networks (Pearl, 1985).\nSimilarly, the Nonfoundationalist condition is still the most widely\nused—and many would say most natural—way of stating, in\nthe language of probability theory, that a testimony fails to support\nthat which is testified. Thus, it would seem that coherentism is saved\nat the price of disconnecting it from the way in which probability\ntheory is standardly applied. Roche (2010) criticizes\nNonfoundationalism from another perspective. In his view, a close\nreading of BonJour reveals that the latter requires only that the\nwitness reports lack individual credibility in the sense that\n\\(P(A \\mid E_i) = 0.5\\) and not in the\nsense of \\(P(A \\mid E_i) = P(A)\\), which is the condition we called\nNonfoundationalism. Since the former does not entail the latter,\ncoherentists, to the extent that they follow BonJour, need not worry\nabout the joint inconsistency of Conditional Independence,\nNonfoundationalism and Coherence Justification. Still, this account of\nwhat it means to lack initial credibility is non-standard if taken as\na general characterization, and it may in the end be more charitable\nto interpret BonJour as not having subscribed to it. For an\nelaboration of this point the reader is referred to Olsson (2005, 65),\nfootnote 4. In later works, BonJour has gradually retracted from his\noriginal coherentist position (e.g., BonJour 1989 and 1999). \nWe recall that Lewis’s defined coherence, or congruence, not for any\nold set of proposition but rather for a set of supposed facts\nasserted. One way to capture this idea is in terms of the notion of a\ntestimonial system introduced in Olsson (2005). A testimonial system\n\\(S\\) is a set\n\\(\\{\\langle E_1,A_1\\rangle ,\\ldots ,\\langle E_n,A_n\\rangle \\}\\)\nwhere \\(E_i\\) is a report to the effect that\n\\(A_i\\) is true. We will say that\n\\(A_i\\) is the content of report\n\\(E_i\\). The content of a testimonial system\n\\(S = \\{\\langle E_1,A_1\\rangle ,\n\\ldots ,\\langle E_n,A_n\\rangle \\}\\)\nis the ordered set of report contents\n\\(\\langle A_1 ,\\ldots ,A_n\\rangle\\).\nBy the degree of coherence \\(C(S)\\) of such a testimonial\nsystem we will mean the degree of coherence of its content.\nBovens and Hartmann (2003) proposed a similar representation of\nsupposed facts asserted in terms of ordered sets. \nTo illustrate these concepts, consider a case in which all witnesses\nreport exactly the same thing, e.g., that John was at the crime scene.\nThat would be a paradigm case of a (highly) coherent set of reports.\nNow contrast this situation with one in which only one witness reports\nthis. That would be a situation which would intuitively not qualify as\ncoherent. Indeed, it does not even seem meaningful to apply the\nconcept of coherence to a case of just one report (except in the\ntrivial sense in which everything coheres with itself). Letting\n\\(A\\) be the proposition “John was at the crime scene”,\nand \\(E_1 ,\\ldots ,E_n\\) the\ncorresponding reports, this intuitive difference can be represented as\nthe difference between two testimonial systems: \\(S = \\{\\langle E_1,A\\rangle ,\\ldots ,\\langle E_n ,A\\rangle \\}\\) and\n\\(S' = \\{\\langle E_1,A\\rangle \\}\\). If, by\ncontrast, the entities to which coherence applies are represented as\nsimple unstructured sets, the sets of testimonies in question would be\ngiven the same formal representation in terms of the set having\n\\(A\\) as its sole member. \nBy a (probabilistic) coherence measure, as defined for ordered sets of\npropositions, we shall mean any numerical measure\n\\(C(A_1 ,\\ldots ,A_n)\\)\ndefined solely in terms of the probability of\n\\(A_1 ,\\ldots ,A_n\\) (and their\nBoolean combinations) and standard arithmetical operations (Olsson,\n2002). This definition makes the degree of coherence of a set of\nwitness reports a function of the probability of the report contents\n(and their Boolean combinations). Huemer (2011, 45) refers to this\nconsequence as the Content Determination Thesis. We will return to the\nstatus of this thesis in section 8, in connection with the recent\nimpossibility results for coherence. A reasonable constraint on any\ncoherence measure is that the degree of coherence of an ordered set\nshould be independent of the particular way in which the content\npropositions are listed. Thus,\n\\(C(\\langle A_1,A_2 , \\ldots ,A_n\\rangle) = C(\\langle B_1,B_2 , \\ldots ,B_n\\rangle)\\) whenever\n\\(\\langle B_1,B_2 , \\ldots ,B_n\\rangle\\) is a permutation of\n\\(\\langle A_1,A_2 , \\ldots ,A_n\\rangle\\). This is a formal way of stating\nthat all propositions in the relevant set should be treated as\nepistemic equals. All measures that will be discussed below satisfy\nthis condition. \nOur starting point will be an attempt to identify the degree of\ncoherence of a set with its joint probability: \nHowever, it is easily seen that this is not a plausible proposal.\nConsider the following two cases. Case 1: Two witnesses point out the\nsame person as the perpetrator, John, say. Case 2: One witness states\nthat John or James did it, and the other witness that John or Mary did\nit. Since the joint probability is the same in both cases, equaling\nthe probability that John did it, they yield the same degree of\ncoherence as measured by \\(C_0\\). And yet, the reports in\nthe first case are more coherent from a presystematic standpoint\nbecause the witnesses are in complete agreement. \nOne way of handling this example would be to define coherence as relative overlap, in the following sense (Glass 2002, Olsson 2002): \n\\(C_1 (A,B)\\), which also takes on values\nbetween 0 and 1, measures how much of the total probability mass\nassigned to either \\(A\\) or \\(B\\) falls into their intersection.\nThe degree of coherence is 0 if and only if\n\\(P(A\\wedge B) = 0\\), i.e., just in case \\(A\\) and\n\\(B\\) do not overlap at all, and it is 1 if and only if\n\\(P(A\\wedge B) = P(A\\vee B)\\), i.e., just in case\n\\(A\\) and \\(B\\) coincide. The measure is straightforwardly\ngeneralizable: \nThis measure assigns the same coherence value, namely 1, to all cases\nof total agreement, regardless of the number of witnesses that are\ninvolved. Against this it may be objected that agreement among the\nmany is more coherent than agreement among the few, an intuition that\ncan be accounted for by the following alternative measure introduced\nby Shogenji (1999): \nor, as Shogenji proposes to generalize it, \nIt is easy to see that this measure is sensitive, in the way we\nsuggested, to the number of reports in cases of total agreement:\n\\(n\\) agreeing reports correspond to a coherence value of\n\\(\\bfrac{1}{P(A)^{n-1}}\\), meaning that as\n\\(n\\) approaches infinity, so does the degree of coherence. Like\nthe other measures, \\(C_2 (A,B)\\) equals 0\nif and only if \\(A\\) and \\(B\\) do not overlap. An alternative\ngeneralization of the Shogenji measure is presented in Shupbach\n(2011). However, whatever its philosophical merits, Schupbach’s\nproposal is considerably more complex than Shogenji’s original\nsuggestion. Akiba (2000) and Moretti and Akiba (2007) raise a number\nof worries for the Shogenji measure and for probabilistic measures of\ncoherence generally but they seem to be predicated on the assumption\nthat the concept of coherence is interestingly applicable to unordered\nsets of propositions, an assumption that we found reason to question\nabove. \n\\(C_1\\) and \\(C_2\\) can also be contrasted\nwith regard to their sensitivity to the specificity of the\npropositions involved. Consider two cases. The first case involves two\nwitnesses both claiming that John committed the crime. The second case\ninvolves two witnesses both making the weaker disjunctive claim that\nJohn, Paul or Mary committed the crime. Which pair of witnesses are\ndelivering the more coherent set? One way to reason is as follows.\nSince both cases involve fully agreeing testimonies, the degree of\ncoherence should be the same. This is also the result we get if we\napply \\(C_1\\). But one could maintain instead that since\nthe first two witnesses agree on something more specific—a\nparticular individual’s guilt—the degree of coherence should be\nhigher. This is what we get if we apply \\(C_2\\). In an\nattempt at reconciliation, Olsson (2002) suggested that\n\\(C_1\\) and \\(C_2\\) may capture two\ndifferent concepts of coherence. While \\(C_1\\) measures\nthe degree of agreement of a set, \\(C_2\\) is more\nplausible as a measure of how striking the agreement is. \nRecently, however, Koscholke and Schippers (2015) have noted a\ncounterintuitive feature of \\(C_1\\): that it is impossible to increase\na set’s degree of coherence by adding further propositions to\nthe set. They also show that according to a more sophisticated\nrelative overlap measure which avoids this issue no set’s degree\nof coherence exceeds the degree of coherence of its maximally coherent\nsubset. On the other hand, they also prove in a later article, in\ncollaboration with Stegman, that there is a further relative overlap\nmeasure which avoids both these problems and which therefore in their\nview re-establishes relative overlap as a candidate for a proper\nformalization of coherence (Koscholke, Schippers and Stegman,\n2019). \nA further much discussed measure is that proposed in Fitelson (2003).\nIt is based on the intuition that the degree of coherence of a set\n\\(E\\) should be “a quantitative, probabilistic generalization\nof the (deductive) logical coherence of \\(E\\)” (ibid., 194).\nFitelson takes it to be a consequence of this idea that a maximum\n(constant) degree of coherence is attained if the propositions in\n\\(E\\) are all logically equivalent (and consistent). This is in\naccordance with \\(C_1\\) but not with\n\\(C_2\\), which as we saw is sensitive to the specificity\n(prior probability) of the propositions involved. Fitelson, who\napproached the subject from the standpoint of confirmation theory,\nproposed a complex coherence measure based on Kemeny and Oppenheim’s\n(1952) measure of factual support. A further innovative idea is that\nFitelson extends this measure to take into account support relations\nholding between all subsets in the set \\(E\\), whereas\nLewis, we recall, only considered the support relation holding between\none element and the rest. The degree of coherence of a set, finally,\nis defined as the mean support among the subsets of \\(E\\). An\nalleged counterexample to this measure can be found in Siebel (2004)\nand criticisms and proposed amendments in Meijs (2006). The reader may\nwish to consult Bovens and Hartmann (2003), Douven and Meijs (2007),\nRoche (2013a) and Shippers (2014a) for further coherence measures and\nhow they fare in relation to test cases in the literature, and\nKoscholke and Jekel (2017) for an empirical study of coherence\nassessments drawing on similar examples. The latter study indicates\nthat the measures by Douven and Meijs and by Roche are more in line\nwith intuitive judgement than other established measures. Some recent\nworks have focused on applying coherence measures to inconsistent\nsets, e.g., Schippers (2014b) and Schippers and Siebel (2015). \nIt is fair to say that coherence theorists have yet to reach anything\nlike consensus on how best to define coherence in probabilistic terms.\nNevertheless, the debate so far has given rise to a much more\nfine-grained understanding of what the options are and what\nconsequences they have. What is more, some quite surprising\nconclusions can be drawn even with this issue largely unresolved: all\nwe need to assume in order to prove that no coherence measure can be\ntruth conducive, in a sense to be explained, is that those measures\nrespect the Content Determination Thesis. \nPeter Klein and Ted Warfield’s 1994 paper in Analysis\ninitiated a lively and instructive debate on the relationship between\ncoherence and probability (e.g., Klein and Warfield 1994 and 1996,\nMerricks 1995, Shogenji 1999, Cross 1999, Akiba 2000, Olsson 2001,\nFitelson 2003 and Siebel 2004). According to Klein and Warfield, just\nbecause one set of beliefs is more coherent than another set, this\ndoes not mean that the first set is more likely to be true. On the\ncontrary, a higher degree of coherence can, so they claimed, be\nassociated with a lower probability of the whole set. The idea behind\ntheir reasoning is simple: We can often raise the coherence of an\ninformational set by adding more information that explains the\ninformation already in the set. But as more genuinely new information\nis added, the probability that all the elements of the set are true is\ncorrespondingly diminished. This, Klein and Warfield wrote, follows\nfrom the well-known inverse relationship between probability and\ninformational content. They concluded that coherence is not truth\nconducive. \nMuch in the spirit of C. I. Lewis, Klein and Warfield illustrated\ntheir argument referring to a detective story (the so-called\n“Dunnit example”). It turns out that this example is\nunnecessarily complex and that the main point can be illustrated by\nreference to a simpler case (borrowed from computer science where it\nis used to exemplify the concept of non-monotonic inference). Suppose\nthat you are told by one source, Jane, that Tweety is a bird and by\nanother source, Carl, that Tweety cannot fly. The resulting\ninformation set \\(S = \\langle\\)“Tweety is a bird”,\n“Tweety cannot fly”\\(\\rangle\\) is not particularly coherent\nfrom an intuitive standpoint. Nor is it coherent from the point of\nview of Lewis’s definition: assuming one of the items true decreases\nthe probability of the other. At this point, it would be reasonable to\nconjecture that either Jane or Carl is not telling the truth. However,\nupon consulting a further source, Rick, we receive the information\nthat Tweety is a penguin. The new set \\(S' = \\langle\\)“Tweety is a bird”, “Tweety cannot fly”,\n“Tweety is a penguin”\\(\\rangle\\) is surely more coherent than\n\\(S\\). In explaining the previous anomaly, the information supplied\nby Rick contributes to the explanatory coherence of the set. \nThe new enlarged set \\(S'\\) is more coherent than the\noriginal smaller set \\(S\\). And yet \\(S\\), being less\ninformative, is more probable than \\(S'\\): the conjunction of\nall the propositions in \\(S\\) is more probable than the conjunction\nof all the propositions in \\(S'\\). Hence, more coherence does\nnot necessarily imply higher likelihood of truth in the sense of\nhigher joint probability. Klein and Warfield seem to be right:\ncoherence is not truth conducive. \nBut, as will soon be clear, this conclusion is premature. As a\npreliminary, let us state Klein and Warfield’s argument more formally\nusing the following abbreviations: \nThe first information set \\(S\\) consists of \\(A_1\\)\nand \\(A_2\\). The second, more coherent set\n\\(S'\\) contains, in addition, \\(A_3\\). We let\n\\(C\\) denote the degree of coherence, intuitively understood. What\nwe have then is: \nAs we saw, due to the greater informational content of the larger set,\nits probability is lower than that of the smaller set: \nYet behind this seemingly impeccable piece of reasoning lurks a\nserious difficulty. As we saw, it is part of the example that we are\nsupposed to know also that Jane reports that Tweety is a\nbird, that Carl reports that Tweety cannot fly and that\nRick reports that Tweety is a penguin. Let: \nThe well-known principle of total evidence now dictates that all\nrelevant evidence should be taken into consideration when computing\nprobabilities. Since it cannot be excluded at the outset that the\nevidence represented by\n\\(E_1\\)–\\(E_3\\) may be relevant to the\nprobability of the information sets \\(S\\) and \\(S'\\), the\nprobability of the smaller set is not\n\\(P(A_1,A_2)\\) but rather\n\\(P(A_1,A_2 \\mid E_1,E_2)\\). Similarly, the probability\nof the larger set is not\n\\(P(A_1,A_2,A_3)\\)\nbut rather\n\\(P(A_1,A_2,A_3 \n\\mid E_1, E_2,\nE_3)\\). \nBovens and Olsson (2002) raised the question whether, given this\nrevised understanding of the probability of a set of reported\npropositions, it would still follow that extended sets are no more\nprobable than the sets they extend. Referring to our Tweety example,\nwould it still hold that \nBovens and Olsson demonstrated that the answer to the general question\nis in the negative by giving an example of a more coherent extended\nset that is also more probable, on the revised understanding of what\nthis means, than the original smaller set. Klein and Warfield’s\nreasoning is based on an problematic understanding of the joint\nprobability of a set of reported propositions. In the end, they have\nnot shown that coherence is not truth conducive.  \nLet us say that a measure \\(C\\) of coherence is propositionally\ntruth conducive if and only if the following holds:  \nif \n \\(C(A_1 ,\\ldots ,A_n) \\gt C(B_1 ,\\ldots ,B_m)\\), then\n\n \\(P(A_1\\wedge \\ldots \\wedge A_n) \\gt P(B_1\\wedge \\ldots \\wedge B_m)\\).\n \n\nOne lesson emerging from the Analysis debate is\nthat this way of construing truth conduciveness should be replaced by\na notion of truth conduciveness where the relevant probabilities take\nall relevant evidence into account, whatever that evidence may be\n(beliefs, testimonies etc.). For example, a coherence measure \\(C\\)\nis doxastically truth conducive (for a subject \\(S)\\) if\nand only if: \nif \\(C(A_1 ,\\ldots ,A_n) \\gt C(B_1 ,\\ldots ,B_m)\\), then \n\\(P(A_1\\wedge \\ldots \\wedge A_n \\mid \\mathrm{Bel}_S A_1,\\ldots,\\mathrm{Bel}_{S}A_n)\n\\gt\\) \\(P(B_1\\wedge \\ldots \\wedge B_m \\mid \\mathrm{Bel}_S B_1,\\ldots,\\mathrm{Bel}_{S}B_m)\\),\n \nwhere \\(\\mathrm{Bel}_S A\\) abbreviates “\\(S\\) believes\nthat \\(A\\)”. In other words, a measure of coherence is\ndoxastically truth conducive just in case a more coherent set of\nbelieved propositions is jointly more probable than a less\ncoherent set of believed propositions. This the how we will\nunderstand the probability (likelihood of truth) of a set in the\nfollowing. \nThe impossibility results for coherence draw on all three\ndebates summarized above: the Lewis-BonJour controversy, the debate\nover probabilistic measures of coherence and also the dispute in\nAnalysis regarding truth conduciveness. Before we can discuss\nthe results we need to make one further observation. Given the\nconclusion of the Lewis-BonJour dispute, it is a reasonable\nexpectation that no coherence measure is truth conducive, in the\nrelevant conditional sense, unless the reports (beliefs, memories\netc.) in question are individually credible and collectively\nindependent. But assuming this is not sufficient for coherence to\nstand a reasonable chance of being truth conducive. We must also\nrequire that when we compare two different sets of reports, we do so\nwhile keeping the degree of individual credibility fixed. Otherwise we\ncould have a situation in which one set of report contents is more\ncoherent than another set but still fails to give rise to a higher\nlikelihood of truth simply because the reporters delivering the\npropositions in the less coherent set are individually more reliable.\nThus, truth conduciveness must be understood in a ceteris\nparibus sense. The question of interest, then, is whether more\ncoherence implies a higher probability (given independence and\nindividual credibility) everything else being equal. We are\nnow finally in a position to state the impossibility theorems. What\nthey show is that no measure of coherence is truth conducive even in a\nweak ceteris paribus sense, under the favorable conditions of\n(conditional) independence and individual credibility. \nThe first result of this nature was presented by Bovens and Hartmann\n(2003). Their definition of truth conduciveness deviates slightly from\nthe standard account given above. As they define it, a measure\n\\(C\\) is truth conducive if and only if, for all sets \\(S\\) and\n\\(S'\\), if \\(S\\) is at least as coherent as\n\\(S'\\) according to \\(C\\), then \\(S\\) is at least as\nlikely to be true as \\(S'\\) ceteris paribus and\ngiven independence and individual credibility. Very roughly, their\nproof has the following structure: They show that there are sets\n\\(S\\) and \\(S'\\), each containing three\npropositions, such that which set is more likely to be true will\ndepend on the level at which the individual credibility (reliability)\nis held fixed. Thus for lower degrees of reliability, one set, say\n\\(S\\), will be more probable than the other set, \\(S'\\);\nfor higher degrees of reliability, the situation will be reversed. One\ncan now find a counterexample to the truth conduciveness of any\nmeasure \\(C\\) through a strategic choice of the level at which the\nreliability is held fixed. Suppose for instance that, according to\n\\(C\\), the set \\(S\\) is more coherent than the set\n\\(S'\\). In order to construct a counterexample to \\(C\\)’s\ntruth conduciveness, we set the reliability to a value for which\n\\(S'\\) will be more probable than \\(S\\). If, on the other\nhand, \\(C\\) makes \\(S'\\) more coherent than \\(S\\), we\nfix the reliability to a level at which \\(S\\) will be the more\nprobable set. For the details, see Bovens and Hartmann (2003, section\n1.4). \nOlsson defines truth conduciveness in the standard fashion. His\nimpossibility theorem is based on the following alternative proof\nstrategy (Olsson 2005, appendix B): Consider a situation of two\nwitnesses both reporting that \\(A\\), represented by\n\\(S = \\langle A, A\\rangle\\). Take a measure\n\\(C\\) of coherence that is informative with respect to \\(S\\), in\nthe sense that it does not assign the same degree of coherence to\n\\(S\\) regardless of which probability assignment is used. This\nmeans that the measure is non-trivial in the situation in question.\nTake two assignments \\(P\\) and \\(P'\\) of probabilities to\nthe propositions in \\(S\\) that give rise to different coherence\nvalues. Olsson shows that a counter example to the truth conduciveness\nof \\(C\\) can be constructed through a strategic choice of the\nprobability of reliability. If \\(P\\) makes \\(S\\) more coherent\nthan does \\(P'\\) according to \\(C\\), we fix the\nprobability of reliability in such a way that \\(S\\) comes out as\nmore probable on \\(P'\\) than on \\(P\\). If, on the other\nhand, \\(P'\\) makes \\(S\\) more coherent, then we choose a\nvalue for the probability of reliability so that \\(P\\) makes\n\\(S\\) more probable. It follows that no coherence measure is both\ntruth conducive and informative. \nThere are some further subtle differences between the two results.\nFirst, Olsson’s theorem is proved against the backdrop of a\ndynamic (or, in the language of Bovens and Hartmann, 2003,\nendogenous) model of reliability: the assessment of witness\nreliability, which in this model is represented as a probability of\nreliability, may change as we obtain more reports. Bovens and\nHartmann’s detailed proof assumes a non-dynamic (exogenous) model of\nreliability, although they indicate that the result carries over to\nthe dynamic (endogenous) case. Second, there is a difference in the\nway the ceteris paribus condition is understood. Olsson fixes\nthe initial probability of reliability, but allows the prior\nprobability of the report contents to vary. Bovens and Hartmann fix\nnot only the reliability but also the prior probability of the report\ncontents. \nThese impossibility results give rise to a thought-provoking paradox.\nIt can hardly be doubted that we trust and rely on coherence reasoning\nwhen judging the believability of information, in everyday life and in\nscience (see Harris and Hahn, 2009, for an experimental study in a\nBayesian setting). But how can this be when in fact coherence is not\ntruth conducive? Since the impossibility results were published a\nnumber of studies have been dedicated to the resolution of this\nparadox (see Meijs and Douven, 2007, for an overview of some possible\nmoves). These studies can be divided into two camps. Researchers in\nthe first camp accept the conclusion that the impossibility results\nshow that coherence is not truth conducive. They add, however, that\nthis does not prevent coherence from being valuable and important in\nother ways. Researchers in the other camp do not accept the conclusion\nthat the impossibility results show that coherence is not truth\nconducive because they think that at least one premise used in proving\nthe results is doubtful. \nLet us start with responses from the first camp. Dietrich and Moretti\n(2005) show that coherence in the sense of the Olsson measure is\nlinked to the practice of indirect confirmation of scientific\nhypotheses. That measure turns out to be, in the terminology of\nMoretti (2007), “confirmation conducive”. Glass (2007)\nargues, similarly, that coherence can provide the key to a precise\naccount of inference to the best explanation, the main idea being to\nuse a coherence measure for ranking competing hypotheses in terms of\ntheir coherence with a given piece of evidence. Furthermore, Olsson\nand Schubert (2007) observe that, while coherence falls short of being\ntruth conducive, it can still be “reliability conducive”,\ni.e., more coherence, according to some measures, entails a higher\nprobability that the sources are reliable, at least in a paradigmatic\ncase (cf. Schubert 2012a, 2011). Nevertheless, Schubert has proved an impossibility theorem to the effect that no coherence\nmeasure is reliability conducive in general (Schubert 2012b). For yet\nanother example, Angere (2007, 2008) argues, based on computer\nsimulations, that the fact that coherence fails to be truth conducive,\nin the above sense, does not prevent it from being connected with\ntruth in a weaker, defeasible sense. In fact, almost all coherence\nmeasures that have an independent standing in the literature satisfy\nthe condition that most cases of higher coherence are also\ncases of higher probability, although they do so to different degrees. Moreover, Roche (2013b) has demonstrated that assuming a set to\nbe coherent implies an increase in the probability of truth of any of\nits elements. This is a weak form of truth-conduciveness, and Roche is\nright to point out that it should not give the coherentist much\ncomfort. It has also been noted that coherence plays an important\nnegative role in our thinking. If our beliefs show signs of\nincoherence, this is often a good reason for contemplating a revision.\nSee chapter 10 in Olsson (2005) for an elaboration of this point. \nAs for the other approach to the impossibility results (questioning\nthe premises used in their derivation), we have already seen that\nHuemer (2007, 2011), in connection with the Lewis-BonJour dispute, has\nexpressed doubts regarding the standard way of formalizing\nindependence in terms of conditional probability. It should come as no\nsurprise that he objects to the impossibility results (ibid.) on the\nsame grounds. In his 2011 article, Huemer even questions the Content\nDetermination Thesis, which plays a pivotal role in the derivation of\nthe results, for reasons that we have to leave aside here. \nAll these things can be consistently questioned. But the question is:\nat what cost? We have already seen that there are strong systematic\nreasons for explicating independence in terms of conditional\nindependence in the standard way. Furthermore, the Content\nDetermination Thesis is deeply entrenched in just about all work on\ncoherence that takes agreeing witnesses to be the prototypical case.\nGiving up Content Determination would mean purging the coherence\ntheory of one of its clearest and most distinctive pre-systematic\nintuitions: that coherence is a property at the level of report\ncontents. The worry is that coherentism is saved at the cost\nof robbing it of almost all its significance, as Ewing put it almost a\ncentury ago in response to a similar worry (Ewing 1934, 246). \nThese concerns do not obviously carry over to another dialectical\nmove: questioning the ceteris paribus conditions employed in\nthe impossibility results, i.e., the conditions that determine what to\nhold fixed as the degree of coherence is varied. This line of\ncriticism has been taken up by several authors, including Douven and\nMeijs (2007), Schupbach (2008) and Huemer (2011), and it may well be\nthe internally least problematic strategy to explore for those who are\ninclined to challenge the premises upon which the impossibility\nresults are based. It should be borne in mind, though, that the\ntendency to offer ever stronger ceteris paribus conditions\nmay in the end be self-defeating. As more things are held fixed, it\nbecomes easier for a coherence measure to be truth conducive. Hence,\nresearchers pursuing this line of defense ultimately run the risk of\ntrivializing the debate by making coherence truth conducive by\ndefinition (cf. Schubert 2012b). \nThere are some attempts to explain or come to grips with the\nimpossibility results that do not easily fit into the two camps\nidentified above or represent a combination of ideas from both. For an\nexample of the latter, Wheeler (2012; see also Wheeler and Scheines,\n2013) both suggest focusing on reliability conduciveness as opposed to\ntruth conduciveness (camp 1) and question the assumptions, primarily\nindependence but also the Content Determination Thesis, used in the\nderivation of the impossibility results (camp 2). Shogenji (2007,\n2013) and McGraw (2016) are other complex and insightful attempts to\ndeepen the Bayesian analysis and diagnose of those results. Specifically, Lydia McGrew argues for a shift in focus from the coherence of contents of reports to coherence of the evidence with an hypothesis \\(H\\) (which need not coincide with the conjunction of the report contents). If the conjunction of the members of a set of evidence supports some hypothesis \\(H\\), and if all members of that set are playing a role in that epistemic effect, then that set of evidence is, McGrew shows, indeed confirmatory of \\(H\\) and in that sense truth-conducive for \\(H\\) (McGrew, 2016). McGrew offers several proposals for how to spell out “coherence with \\(H\\)”. \nThe coherence theory of justification represents an initially\nsuggestive solution to some deeply rooted problems of epistemology.\nPerhaps most significantly, it suggests a way of thinking about\nepistemic justification as arising in a “web of belief”.\nAs such, it competes with, and could potentially replace, the\nhistorically dominating, but increasingly disreputable,\nfoundationalist picture of knowledge as resting on a secure base of\nindubitable fact. Coherentism may also be more promising than\nalternative foundationalist views with their reliance on non-doxastic\nsupport. Unfortunately, coherence theorists have generally struggled\nto provide the details necessary for their theory to advance beyond\nthe metaphorical stage, something which has not gone unnoticed by\ntheir critics. Following the seminal work of C. I. Lewis, contemporary\nscholars have taken on that challenge with considerable success in\nterms of clarity and established results, although a fair number of\nthe latter are to the coherentist’s disadvantage. Some results support\na weak foundationalist theory according to which coherence can boost\ncredibility that is already there, without creating it from scratch.\nHowever, on the face of it, the impossibility results negatively\naffect this less radical form of coherence theory as well. It is often\nobserved that while it is relatively easy to put forward a convincing\ntheory in the outline, the ultimate test for any philosophical\nendeavor is whether the product will survive detailed specification\n(the devil is in the details, and so on). What the recent developments\nin this area have shown, if nothing else, is that this is very much\ntrue for the coherence theory of epistemic justification.","contact.mail":"Erik_J.Olsson@fil.lu.se","contact.domain":"fil.lu.se"}]
