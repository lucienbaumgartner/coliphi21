[{"date.published":"2003-12-31","date.changed":"2015-11-18","url":"https://plato.stanford.edu/entries/consequentialism-rule/","author1":"Brad Hooker","entry":"consequentialism-rule","body.text":"\n\nThe theory of morality we can call full rule-consequentialism\nselects rules solely in terms of the goodness of their consequences\nand then claims that these rules determine which kinds of acts are\nmorally wrong. George Berkeley was arguably the first\nrule-consequentialist. He wrote, “In framing the general laws of\nnature, it is granted we must be entirely guided by the public good of\nmankind, but not in the ordinary moral actions of our lives. …\nThe rule is framed with respect to the good of mankind; but our\npractice must be always shaped immediately by the rule.”\n(Berkeley 1712: section 31) Writers often classified as\nrule-consequentialists include Austin 1832; Harrod 1936; Toulmin 1950;\nUrmson 1953; Harrison 1953; Mabbott 1953; M. Singer 1955, 1961; and\nmost influentially Brandt 1959, 1963, 1967, 1979, 1989, 1996; and\nHarsanyi 1977, 1982, 1993. See also Rawls 1955; Ezorsky 1968; Ihara\n1981; Haslett 1987, 1994: ch. 1, 2000; Attfield 1987: 103–12;\nBarrow 1991: ch. 6; 2015; Johnson 1991; Riley 2000; Shaw 1999; Hooker\n2000, 2005; Mulgan, 2006, 2009; Ridge 2006; R.B. Miller 2009; Parfit\n2011; Cowen 2011; Kahn 2012, 2013; Levy 2013; Tobia 2013; and\nD.E. Miller 2014. Whether J.S. Mill’s ethics was rule-consequentialist\nis controversial (Urmson 1953; Lyons 1994: 47–65; Crisp 1997:\n102–33; D.E. Miller 2010: 79–110).\n\nA moral theory is a form of consequentialism if and only if it\nassesses acts and/or character traits, practices, and institutions\nsolely in terms of the goodness of the consequences. Historically,\nutilitarianism has been the best-known form of consequentialism.\nUtilitarianism assesses acts and/or character traits, practices, and\ninstitutions solely in terms of overall net benefit. Overall net\nbenefit is often referred to as aggregate well-being or\nwelfare. Aggregate welfare is calculated by counting a benefit or harm\nto any one individual the same as the same size benefit or harm to any\nother individual, and then adding all the benefits and harms together\nto reach an aggregate sum. There is considerable dispute among\nconsequentialists about what the best account of welfare is. Classical utitilitarians (i.e., Jeremy Bentham, J.S. Mill, and\nHenry Sidgwick) took benefit and harm to be purely a matter of\npleasure and pain. The view that welfare is a matter of pleasure minus\npain has generally been called hedonism. It has grown in\nsophistication (Parfit 1984: Appendix I; Sumner 1996; Crisp 2006; de\nLazari-Radek and Singer 2014: ch. 9) but remains committed to the\nthesis that how well someone’s life goes depends entirely on\nhis or her pleasure minus pain, albeit with pleasure and pain being\nconstrued very broadly. Even if pleasures and pains are construed very broadly, hedonism\nencounters difficulties. The main one is that many (if not all) people\ncare very strongly about things other than their own pleasures and\npains. Of course these other things can be important as means to\npleasures and to the avoidance of pain. But many people care very\nstrongly about things over and beyond their hedonistic instrumental\nvalue. For example, many people want to know the truth about various\nmatters even if this won’t increase their (or anyone else’s) pleasure.\nAnother example is that many people care about achieving things over\nand beyond the pleasure such achievements might produce. Again, many\npeople care about the welfare of their family and friends in a\nnon-instrumental way. A rival account of these points, especially the\nlast, is that people care about many things other than their own\nwelfare. On any plausible view of welfare, the satisfaction people can feel\nwhen their desires are fulfilled constitutes an addition to their\nwelfare. Likewise, on any plausible view, frustration felt as a result\nof unfulfilled desires constitutes a reduction in welfare. What is\ncontroversial is whether the fulfilment of someone’s desire\nconstitutes a benefit to that person apart from any effect that the\nfulfilment of the desire has on that person’s felt satisfaction or\nfrustration.  Hedonism answers No, claiming that only effects on felt\nsatisfaction or felt frustration matter. A different theory of welfare answers Yes. This theory holds that\nthe fulfilment of any desire of the agent’s constitutes a benefit to\nthe agent, even if the agent never knows that desire has been\nfulfilled and even if the agent derives no pleasure from its\nfulfilment. This theory of human welfare is often referred to as the\ndesire-fulfillment theory of welfare.  Clearly, the desire-fulfillment theory of welfare is broader than\nhedonism, in that the desire-fulfillment theory accepts that what can\nconstitute a benefit is wider than merely pleasure. But there are\nreasons for thinking that this broader theory is too broad. For one\nthing, people can have sensible desires that are simply too\ndisconnected from their own lives to be relevant to their own welfare\n(Williams 1973: 262; Overvold 1980, 1982; Parfit 1984: 494). I desire\nthat the starving in far-away countries get food. But the fulfilment\nof this desire of mine does not benefit me. For another thing, people can have desires for absurd things for\nthemselves. Suppose I desire to count all the blades of grass in the\nlawns on this road. If I get satisfaction out of doing this, the felt\nsatisfaction constitutes a benefit to me. But the bare fulfilment of\nmy desire to count all the blades of grass in the lawns on this road\ndoes not (Rawls 1971: 432; Parfit 1984: 500; Crisp 1997: 56). On careful reflection, we might think that the fulfilment of\nsomeone’s desire constitutes an addition to that person’s welfare\nonly if that desire has one of a certain set of contents. We\nmight think, for example, that the fulfilment of someone’s desire for\npleasure, friendship, knowledge, achievement, or autonomy for herself\ndoes constitute an addition to her welfare, and that the\nfulfilment of any desires she might have for others things do not\ndirectly benefit her (though, again, the pleasure she derives from\ntheir satisfaction does). If we think this, it seems we think there is\na list of things that constitute anyone’s welfare (Parfit 1984:\nAppendix I; Brink 1989: 221–36; Griffin 1996: ch. 2; Crisp 1997: ch. 3;\nGert 1998: 92–4; Arneson 1999a). Insofar as the goods to be promoted are parts of welfare, the\ntheory remains utilitarian. There is a lot to be said for\nutilitarianism.  Obviously, how lives go is important. And there is\nsomething deeply attractive (if not downright irresistible) in the\nidea that morality is fundamentally impartial, i.e., the idea that, at\nthe most fundamental level of morality, everyone is equally important\n— women and men, strong and weak, rich and poor, Blacks, Whites,\nHispanics, Asians, etc.  And utilitarianism plausibly interprets this\nequal importance as dictating that in the calculation of overall\nwelfare a benefit or harm to any one individual counts neither more\nnor less that the same size benefit or harm to any other\nindividual. The nonutilitarian members of the consequentialist family are\ntheories that assess acts and/or character traits, practices, and\ninstitutions solely in terms of resulting good, where good is not\nrestricted to welfare. “Nonutilitarian” here means\n“not purely utilitarian”, rather than “completely\nunutilitarian”. When writers describe themselves as\nconsequentialists rather than as utilitarians, they are normally\nsignalling that their fundamental evaluations will be in terms of not\nonly welfare but also some other goods. What are these other goods? The most common answers have been\njustice, fairness, and equality. Justice, according to Plato, is “rendering to each his\ndue” (Republic, Bk. 1). We might suppose that what\npeople are due is a matter of what people are owed, either because\nthey deserve it or because they have a moral right to it. Suppose we\nplug these ideas into consequentialism. Then we get the theory that\nthings should be assessed in terms of not only how much welfare\nresults but also the extent to which people get what they deserve and\nthe extent to which moral rights are respected. For consequentialism to take this line, however, is for it to\nrestrict its explanatory ambitions. What a theory simply presupposes,\nit does not explain. A consequentialist theory that presupposes both\nthat justice is constituted by such-and-such and that justice is one\nof the things to be promoted does not explain why the components of\njustice are important. It does not explain what desert is. It does not\nexplain the importance of moral rights, much less try to determine\nwhat the contents of these moral rights are. These are matters too\nimportant and contentious for a consequentialist theory to leave\nunexplained or open. If consequentialism is going to refer to justice,\ndesert, and moral rights, it needs to analyze these concepts and\njustify the role it gives them. Similar things can be said about fairness. If a consequentialist\ntheory presupposes an account of fairness, and simply stipulates that\nfairness is to be promoted, then this consequentialist theory is not\nexplaining fairness. But fairness (like justice, desert, and moral\nrights) is a concept too important for consequentialism not to try to\nexplain. One way for consequentialists to deal with justice and fairness is\nto contend that justice and fairness are constituted by conformity\nwith a certain set of justified social practices, and that what\njustifies these practices is that they generally promote overall\nwelfare and equality. Indeed, the contention might be that what people\nare due, what people have a moral right to, what justice and fairness\nrequire, is conformity to whatever practices promote overall welfare\nand equality. Whether equality needs to be included in the formula, however, is\nvery controversial. Many think that a purely utilitarian formula has\nsufficiently egalitarian implications. They think that, even if the\ngoal is promotion of welfare, not the promotion of\nwelfare-plus-equality, there are some contingent but pervasive facts\nabout human beings that push in the direction of equal distribution of\nmaterial resources (Brandt 1979). According to the “law of diminishing marginal utility of\nmaterial resources”, the amount of benefit a person gets out of\na certain unit of material resources is less the more units of that\nmaterial good the person already has. Suppose I go from having no way\nof getting around except by foot to having a bicycle, or, though I\nlive in a place where one can get very cold, I go from having no warm\ncoat to having one. I will benefit more from getting that first\nbicycle or coat than I would if I go from having nine bicycles or\ncoats to having ten. There are exceptions to the law of diminishing marginal utility.\nIn most of these exceptions, an additional unit of material resource\npushes someone over some important threshold. For example, consider\nthe meal or pill or gulp of air that saves someone’s life, or the car\nwhose acquisition pushes the competitive collector into first\nplace. In such cases, the unit that puts the person over the threshold\nmight well be as beneficial to that person as any prior unit\nwas. Still, as a general rule, material resources do have diminishing\nmarginal utility. To the assumption that material resources have diminishing marginal\nutility, let us add the assumption that different people generally get\nroughly the same benefits from the same material resources.\nAgain, there are exceptions. If you live in a freezing climate and I\nlive in a hot climate, then you would benefit much more from a warm\ncoat than I would. But suppose we live in the same place, which has freezing winters,\ngood paths for riding bicycles, and no public transportation. And\nsuppose you have ten bicycles and ten coats (though you are not vying\nfor some bicycle- or coat-collector prize). Meanwhile, I am so poor\nthat I have none. Then, redistributing one of your bicycles and one of\nyour coats to me will probably harm you less than it will benefit me.\nThis sort of phenomenon pervades societies where resources are\nunequally distributed. Wherever the phenomenon occurs, a fundamentally\nimpartial morality is under pressure to redistribute resources from\nthe richer to the poorer. However, there are also contingent but pervasive facts about human\nbeings that pull in favor of practices that have the foreseen\nconsequence of material inequality. First of all, higher levels of\noverall welfare can require higher levels of productivity (think of\nthe welfare gains resulting from improvements in agricultural\nproductivity). In many areas of the economy, the provision of material\nrewards for greater productivity seems the most efficient acceptable\nway of eliciting higher productivity. Some individuals and groups will\nbe more productive than others (especially if there are incentive\nschemes). So the practice of providing material rewards for greater\nproductivity will result in material inequality. Thus, on the one hand, the diminishing marginal utility of material\nresources exerts pressure in favor of more equal distributions of\nresources. On the other hand, the need to promote productivity exerts\npressure in favor of incentive schemes that have the foreseen\nconsequence of material inequality. Utilitarians and most other\nconsequentialists find themselves balancing these opposed\npressures. Note that those pressures concern the distribution of resources.\nThere is a further question about how equally welfare itself should be\ndistributed. Many recent writers have taken utilitarianism to be\nindifferent about the distribution of welfare. Imagine a choice\nbetween an outcome where overall welfare is large but distributed\nunequally and an outcome where overall welfare is smaller but\ndistributed equally.  Utilitarians are taken to favor outcomes with\ngreater overall welfare even if it is also less equally\ndistributed. To illustrate this, let us take an artificially simple population,\ndivided into just two groups. Many people would think Alternative 2 above better than Alternative\n1, and might think that the comparison between these alternatives\nshows that there is always pressure in favor of greater equality of\nwelfare. As Derek Parfit (1997) in particular has argued, however, we must\nnot be too hasty. Consider the following choice: Is equality of welfare so important that Alternative 3 is superior\nto Alternative 1? To take an example of Parfit’s, suppose the only way\nto make everyone equal with respect to sight is to make everyone\ntotally blind. Is such “levelling down” required by\nmorality? Indeed, is it in any way at all morally desirable? If we think the answer is No, then we might think that equality of\nwelfare as such is not really an ideal (cf. Temkin 1993). Losses to\nthe better off are justified only where this benefits the worse\noff. What we had thought of as pressure in favor of equality of\nwelfare was instead pressure in favor of levelling up. We might say\nthat additions to welfare matter more the worse off the person is\nwhose welfare is affected. This view has come to be called\nprioritarianism (Parfit 1997; Arneson 1999b). It has\ntremendous intuitive appeal. For a simplistic example of how prioritarianism might work, suppose\nthe welfare of the worst off counts five times as much as the welfare\nof the better off. Then Alternative 1 from the tables above comes out\nat \\((1 \\times 5 \\times 10,000) + (10 \\times 100,000)\\), which comes\nto 1,050,000 total units of welfare. Again with the welfare of the\nworst off counting five times as much, Alternative 2 comes out at \\((8\n\\times 5 \\times 10,000) + (9 \\times 100,000)\\), which comes to\n1,300,000 total units of welfare. This accords with the common\nreaction that Alternative 2 is morally superior to Alternative 1. Of course in real examples there is never only one division in\nsociety. Rather there is a scale from the worst off, to the not quite\nso badly off, and so on up to the best off. Prioritarianism is\ncommitted to variable levels of importance of the welfare of people at\ndifferent places on this scale: the worse off a person is, the greater\nthe importance attached to that person’s level of welfare. This raises two serious worries about prioritarianism. The first\nconcerns prioritarianism’s difficulty in nonarbitrarily\ndetermining how much more importance to give to the welfare of the\nworse off. For example, should a unit of benefit to the worst off\ncount 10 times the same size benefit to the best off and 5 times the\nsame size benefit to the averagely well off? Or should the multipliers\nbe 20 and 10, or 4 and 2? The second worry about prioritarianism is\nwhether attaching greater importance to increases in welfare for some\nthan to the same size increases in welfare for others contradicts\nfundamental impartiality (Hooker 2000: 60–2). This is not the place to go further into debates between\nprioritarianism and its critics. So the rest of this article sets\naside those debates. Consequentialists have distinguished three components of their\ntheory: (1) their thesis about what makes acts morally wrong, (2)\ntheir thesis about the procedure agents should use to make their moral\ndecisions, and (3) their thesis about the conditions under which moral\nsanctions such as blame, guilt, and praise are appropriate. What we might call full rule-consequentialism consists of\nrule-consequentialist criteria for all three. Thus, full\nrule-consequentialism claims that an act is morally wrong if and only\nif it is forbidden by rules justified by their consequences. It also\nclaims that agents should do their moral decision-making in terms of\nrules justified by their consequences. And it claims that the\nconditions under which moral sanctions should be applied are\ndetermined by rules justified by their consequences. Full rule-consequentialists may think that there is really only one\nset of rules about these three different subject matters. Or they may\nthink that there are different sets that in some sense correspond to\nor complement one another. Much more important than the distinction between different kinds of\nfull rule-consequentialism is the distinction between full\nrule-consequentialism and partial rule-consequentialism.\nPartial rule-consequentialism might take many forms. Let us focus on\nthe most common form. The most common form of partial\nrule-consequentialism claims that agents should make their moral\ndecisions about what to do by reference to rules justified by their\nconsequences, but does not claim that moral wrongness is determined by\nrules justified by their consequences. Partial rule-consequentialists\ntypically subscribe to the theory that moral wrongness is determined\ndirectly in terms of the consequences of the act. This theory of\nwrongness is called act-consequentialism. Distinguishing between full and partial rule-consequentialism\nclarifies the contrast between act-consequentialism and\nrule-consequentialism. Act-consequentialism is best conceived of as\nmaintaining merely the following: When confronted with that criterion of moral wrongness, many people\nnaturally assume that the way to decide what to do is to apply the\ncriterion, i.e., However, consequentialists nearly never defend this\nact-consequentialist decision procedure as a general and typical way\nof making moral decisions (Mill 1861: ch 2; Sidgwick 1907:\n405–6, 413, 489–90; Moore 1903: 162–4; Smart 1956:\n346; 1973: 43, 71; Bales 1971: 257–65; Hare 1981; Parfit 1984:\n24–9, 31–43; Railton 1984: 140–6, 152–3; Brink\n1989: 216–7, 256–62, 274–6; Pettit and Brennan 1986;\nPettit 1991, 1994, 1997: 156–61; de Lazari-Radek and Singer\n2014: ch. 10). There are a number of compelling consequentialist\nreasons why the act-consequentialist decision procedure would be\ncounter-productive. First, very often the agent does not have detailed information\nabout what the consequences would be of various acts. Second, obtaining such information would often involve greater\ncosts than are at stake in the decision to be made. Third, even if the agent had the information needed to make\ncalculations, the agent might make mistakes in the calculations. (This\nis especially likely when the agent’s natural biases intrude, or when\nthe calculations are complex, or when they have to be made in a\nhurry.) Fourth, there are what we might call expectation effects. Imagine a\nsociety in which people know that others are naturally biased towards\nthemselves and towards their loved ones but are trying to make their\nevery moral decision by calculating overall good. In such a society,\neach person might well fear that others will go around breaking\npromises, stealing, lying, and even assaulting whenever they convinced\nthemselves that such acts would produce the greatest overall good. In\nsuch a society, people would not feel they could trust one\nanother. This fourth consideration is more controversial than the first\nthree. For example, Hodgson 1967, Hospers 1972, and Harsanyi 1982\nargue that trust would break down. Singer 1972 and Lewis 1972 argue\nthat it would not. Nevertheless, most philosophers accept that, for all four of the\nreasons above, using an act-consequentialist decision procedure would\nnot maximize the good. Hence even philosophers who espouse the\nact-consequentialist criterion of moral wrongness reject the\nact-consequentialist moral decision procedure. In its place, they\ntypically advocate the following: Since act-consequentialists about the criterion of wrongness\ntypically accept this decision procedure, act-consequentialists are in\nfact partial rule-consequentialists. Often, what writers refer to as\nindirect consequentialism is this combination of act-consequentialism\nabout wrongness and rule-consequentialism about the appropriate\ndecision procedure. Standardly, the decision procedure that full rule-consequentialism\nendorses is the one that it would be best for society to\naccept. The qualification “standardly” is needed because\nthere are versions of rule-consequentialism that let the rules be\nrelativised to small groups or even individuals (D.E. Miller 2010;\nKahn 2012).  And act-consequentialism insists upon the decision\nprocedure it would be best for the individual to accept. So,\naccording to act-consequentialism, since Jack’s and Jill’s capacities\nand situations may be very different, the best decision procedures for\nJack to accept may be different from the best decision procedure for\nJill to accept.  However, in practice act-consequentialists typically\nignore for the most part such differences and endorse the above\nrule-consequentialist decision procedure (Hare 1981, chs. 2, 3, 8, 9,\n11; Levy 2000). When act-consequentialists endorse the above rule-consequentialist\ndecision procedure, they acknowledge that following this decision\nprocedure does not guarantee that we will do the act with the best\nconsequences. Sometimes, for example, our following a decision\nprocedure that rules out harming an innocent person will prevent us\nfrom doing that act that would produce the best consequences.\nSimilarly, there will be some circumstances in which stealing,\nbreaking our promises, etc., would produce the best\nconsequences. Still, our following a decision procedure that generally\nrules out such acts will in the long run and on the whole probably\nproduce far better consequences than our trying to run\nconsequentialist calculations on an act-by-act basis. Because act-consequentialists typically agree with a\nrule-consequentialist decision procedure, whether to classify some\nphilosopher as an act-consequentialist or as a rule-consequentialist\ncan be problematic.  For example, G.E. Moore (1903, 1912) is sometimes\nclassified as an act-consequentialist and sometimes as a\nrule-consequentialist. Like so many others, including his teacher\nHenry Sidgwick, Moore combined an act-consequentialist criterion of\nmoral wrongness with a rule-consequentialist procedure for deciding\nwhat to do. Moore simply went further than most in stressing the\ndanger of departing from the rule-consequentialist decision procedure\n(see Shaw 2000). Some writers propose that the purest and most consistent form of\nconsequentialism is the view that absolutely everything should be\nassessed by its consequences, including not only acts but also rules,\nmotives, the imposition of sanctions, etc. Let us follow Pettit and\nSmith (2000) in referring to this view as global\nconsequentialism. Kagan (2000) pictures it as multi-dimensional direct\nconsequentialism, in that each thing is assessed directly in terms of\nwhether its own consequences are as good as the consequences of\nalternatives. How does this global consequentialism differ from what we have been\ncalling partial rule-consequentialism? What we have been calling\npartial rule-consequentialism is nothing but the combination of the\nact-consequentialist criterion of moral wrongness with the\nrule-consequentialist decision procedure. So defined, partial\nrule-consequentialism leaves open the question of when moral sanctions\nare appropriate. Some partial rule-consequentialists say that agents should be\nblamed and feel guilty whenever they fail to choose an act that would\nresult in the best consequences. A much more reasonable position for a\npartial rule-consequentialist to take is that agents should be blamed\nand feel guilty whenever they choose an act that is forbidden by the\nrule-consequentialist decision procedure, whether or not that\nindividual act fails to result in the best consequences. Finally,\npartial rule-consequentialism, as we have defined it, is compatible\nwith the claim that whether agents should be blamed or feel guilty\ndepends not on the wrongness of what they did, nor on whether the\nrecommended procedure for making moral decisions would have led them\nto choose the act they choose, but instead solely on whether this\nblame or guilt will do any good. This is precisely the view of\nsanctions that global consequentialism takes. One devastating objection to global consequentialism is that\nsimultaneously applying a consequentialist criterion to acts, decision\nprocedures, and the imposition of sanctions leads to apparent\nparadoxes (Crisp 1992; Streumer 2003; Lang 2004). Suppose, on the whole and in the long run, the best decision\nprocedure for you to accept is one that leads you to do act x\nnow. But suppose also that in fact the act with the best consequences\nin this situation is not x but y. So global\nconsequentialism tells you to use the best possible decision procedure\nbut also not to do the act picked out by this decision procedure. That\nseems paradoxical. Things get worse when we consider blame and guilt. Suppose you\nfollow the best possible decision procedure but fail to do the act\nwith the best consequences. Are you to be blamed? Should you feel\nguilty?  Global consequentialism claims that you should be blamed if\nand only if blaming you will produce the best consequences, and that\nyou should feel guilty if and only if this will produce the best\nconsequences.  Suppose that for some reason the best consequences\nwould result from blaming you for following the prescribed decision\nprocedure (and thus doing x). But surely it is paradoxical\nfor a moral theory to call for you to be blamed although you followed\nthe moral decision procedure mandated by the theory. Or suppose that\nfor some reason the best consequences would result from blaming you\nfor intentionally choosing the act with the best consequences\n(y). Again, surely it is paradoxical for a moral theory to\ncall for you to be blamed although you intentionally chose the very\nact required by the theory. So one problem with global consequentialism is that it creates\npotential gaps between what acts it claims to be required and what\ndecision procedures it tells agents to use, and between each of these\nand blamelessness. (For explicit replies to this line of attack, see\nDriver 2014: 175 and de\nLazari-Radek and Singer 2014: 315–16.) That is not the most familiar problem with global consequentialism.\nThe most familiar problem with it is instead its maximising\nact-consequentialist criterion of wrongness. According to this\nmaximising criterion, an act is wrong if and only if it fails to\nresult in the greatest good. This criterion judges some acts to be not\nwrong which certainly seem to be wrong. It also judges some acts that\nseem not wrong to be wrong. For example, consider an act of murder that results in slightly\nmore good than any other act would have produced. According to the\nmost familiar, maximising act-consequentialist criterion of wrongness,\nthis act of murder is not wrong. Many other kinds of act such as\nassaulting, stealing, promise breaking, and lying can be wrong even\nwhen doing them would produce slightly more good than not doing them\nwould. Again, the familiar, maximising form of act-consequentialism\ndenies this. Or consider someone who gives to her child, or keeps for herself,\nsome resource of her own instead of contributing it to help some\nstranger who would have gained slightly more from that resource. Such\nan action hardly seems wrong. Yet the maximising act-consequentialist\ncriterion judges it to be wrong. Indeed, imagine how much\nself-sacrifice an averagely well-off person would have to make before\nher further actions satisfied the maximising act-consequentialist\ncriterion of wrongness. She would have to give to the point where\nfurther sacrifices from her in order to benefit others would harm her\nmore than they would benefit the others.  Thus, the maximising\nact-consequentialist criterion of wrongness is often accused of being\nunreasonably demanding. The objections just directed at maximising act-consequentialism\ncould be side-stepped by a version of act-consequentialism that did\nnot require maximising the good. This sort of act-consequentialism is\nnow called satisficing consequentialism. See the entry on \n consequentialism/ for more on such a\ntheory. There are a number of different ways of formulating\nrule-consequentialism. For example, it can be formulated in terms of\nthe good that actually results from rules or in terms of the\nrationally expected good of the consequences of rules. It can be\nformulated in terms of the consequences of compliance with rules or in\nterms of the wider consequences of acceptance of rules. It can be\nformulated in terms of the consequences of absolutely everyone’s\naccepting the rules or in terms of the rules’ acceptance by something\nless than everyone.  Rule-consequentialism is more plausible if\nformulated in some ways than it is if formulated in other ways. This\nis explained in the following three subsections. Questions of\nformulation are also relevant in the later section on old objections\nto rule-consequentialism. As indicated, full rule-consequentialism consists in\nrule-consequentialist answers to three questions. The first is, what\nmakes acts morally wrong? The second is, what procedure should agents\nuse to make their moral decisions? The third is, what are the\nconditions under which moral sanctions such as blame, guilt, and\npraise are appropriate? As we have seen, the answer that full rule-consequentialists give\nto the question about decision procedure is the same as other kinds of\nconsequentialist give to that question. So let us focus on the points\nof contrast, i.e., the other two questions. These two questions\n— about what makes acts wrong and about when sanctions are\nappropriate — are more tightly connected than sometimes\nrealized. Indeed, J.S. Mill, one of the fathers of consequentialism, affirmed\ntheir tight connection: Let us assume that Mill took “ought to be punished, at least\nby one’s own conscience if not by others” to be roughly the same\nas “blameworthy”. With this assumption in hand, we can\ninterpret Mill as tying wrongness tightly to blameworthiness. In a\nmoment, we can consider what follows if Mill is mistaken that\nwrongness is tied tightly to blameworthiness. First, let us consider\nwhat follows if Mill is correct that wrongness is tied tightly to\nblameworthiness. Consider the following argument, whose first premise comes from\nMill: Surely, an agent cannot rightly be blamed for accepting and\nfollowing rules that the agent could not foresee would have\nsub-optimal consequences. From this, we get our second premise: From these two premises we get the conclusion: Of course, the actual consequences of accepting a set of rules may\nnot be the same as the foreseeable consequences of accepting that set.\nHence, if full rule-consequentialism claims that an act is wrong if\nand only if the foreseeable consequences of rules allowing\nthat act are sub-optimal, rule-consequentialism cannot hold that an\nact is wrong if and only if the actual consequences of rules\nallowing that act will be sub-optimal. Now suppose instead the relation between wrongness and\nblameworthiness is far looser than Mill suggested (cf. Sorensen 1996).\nThat is, suppose that our criterion of wrongness can be quite\ndifferent from our criterion of blameworthiness. In that case, we\ncould hold: and Here is how expected good of a set of rules is calculated. The\nacceptance of a set of rules of course has various possible\nalternative outcomes. Suppose we can identify the value or disvalue of\neach possible outcome. Multiply the value of each possible outcome by\nthe probability of that outcome’s occurring. Take all the products of\nthese multiplications and add them together. The resulting number is\nthe expected good of that set of rules. Note that expected good is not to be calculated by employing\nwhatever crazy estimates of probabilities people might assign to\npossible outcomes. Rather, expected good is calculated by multiplying\nthe value or disvalue of possible outcomes by rational or justified\nprobability estimates. There might be considerable scepticism about how often such\ncalculations are possible. Where such calculations are possible, they\nwill often be quite impressionistic and imprecise. Nevertheless, we\ncan reasonably hope to make at least some informed judgements\nabout the likely consequences of alternative possible rules.\nAnd we could be guided by such judgements. In contrast, which rules\nwould actually have the very best consequences will\nnormally be inaccessible. Hence, the expectablist\nrule-consequentialist criterion of blameworthiness is appealing. Now return to the proposal that, while the criterion of\nblameworthiness is the expectablist rule-consequentialist one, the\ncorrect criterion of moral wrongness is the actualist\nrule-consequentialist one. This is the proposal that rejects Mill’s\nmove of tying moral wrongness to blameworthiness. There is a very\nstrong objection to this proposal. What is the role and importance of\nmoral wrongness if it is disassociated from blameworthiness? In order to retain an obvious role and importance for moral\nwrongness, those committed to the expectablist rule-consequentialist\ncriterion of blameworthiness are likely to endorse: Indeed, once we have before us the distinction between the amount\nof value that actually results and the rationally expected good, the\nfull rule-consequentialist is likely to go for expectablist criteria\nof moral wrongness, blameworthiness, and decision procedures. What if, as far as we can tell, no one code has greater expected\nvalue than its rivals? We will need to amend our expectablist criteria\nin order to accommodate this possibility: The argument for using closeness to conventional morality to break\nties between otherwise equally promising codes begins with the\nobservation that social change regularly has unexpected consequences.\nAnd these unexpected consequences usually seem to be negative.\nFurthermore, the greater the difference between a new code and the one\nalready conventionally accepted, the greater the scope for unexpected\nconsequences. So, as between two codes we judge to have equally high\nexpected value, we should choose the one closest to the one we already\nknow. (For discussion of the situation where two codes have equally\nhigh expected value and seem equally close to conventional morality,\nsee Hooker 2000: 115. For a more nuanced view, see Hooker 2008: 83–4.) An implication of this is that we should make changes to the status\nquo where but only where these changes have greater expected value\nthan sticking with the status quo. Rule-consequentialism manifestly\nhas the capacity to recommend change. But it does not favor change for\nthe sake of change. Rule-consequentialism most definitely does need to be formulated so\nas to deal with ties in expected value. However, for the rest of this\narticle, I will ignore this complication. There are other important issues of formulation that\nrule-consequentialists face. One is the issue of whether\nrule-consequentialism should be formulated in terms of compliance with\nrules or in terms of acceptance of rules. Admittedly, the most\nimportant aspect of accepting rules is compliance with them. And early\nformulations of rule-consequentialism did indeed explicitly mention\ncompliance. For example, they said an act is morally wrong if and only\nif it is forbidden by rules the compliance with which will maximize\nthe good (or the expected good). (See Austin 1832; Brandt 1959;\nM. Singer 1955, 1961.) However, acceptance of a rule can have consequences other than\ncompliance with the rule. As Kagan (2000: 139) writes, “once\nembedded, rules can have an impact on results that is independent of\ntheir impact on acts: it might be, say, that merely thinking about a\nset of rules reassures people, and so contributes to happiness.”\n(For more on what we might call these ‘beyond-compliance\nconsequences’ of rules, see Sidgwick 1907: 405–6, 413;\nLyons 1965: 140; Williams 1973: 119–20, 122, 129–30; Adams\n1976, esp. 470; Scanlon 1998: 203–4; Kagan 1998:\n227–34.) These consequences of acceptance of rules should most definitely be\npart of a cost-benefit analysis of prospective rules. Formulating\nrule-consequentialism in terms of the consequences of acceptance\nallows them to be part of this analysis. In fact, consideration of\nassurance and incentive effects has played a large role in the\ndevelopment of rule-consequentialism (Harsanyi 1977, 1982:\n56–61; 1993: 116–18; Brandt 1979: 271–77; 1988:\n346ff [1992: 142ff.]; 1996: 126, 144; Johnson 1991, especially chs. 3,\n4, 9). Just as we need to move from thinking about the consequences of\ncompliance to thinking about the wider consequences of acceptance, we\nneed to go further. Focusing purely on the consequences of acceptance\nof rules ignores the “transition” costs of getting those\nrules accepted in the first place. And yet these can certainly be\nsignificant (Brandt 1963: section 4; 1967 [1992: 126]; 1983: 98; 1988:\n346–47, 349–50 [1992: 140–143, 144–47]; 1996:\n126–28, 145, 148, 152, 223). Suppose, for example, that, once a fairly simple and relatively\nundemanding code of rules Code A has been accepted, the\nexpected value of Code A would be n. Suppose the\nmore complicated and demanding alternative Code B would have\nan expected value of \\(n + 5\\) once Code B has been\naccepted. So if we just consider the expected values of acceptance of\nthe two alternative codes, Code B wins. But now let us add in the relative costs of getting the two codes\naccepted. Since Code A is fairly simple and relatively\nundemanding, the cost of getting it accepted is −1. Since Code\nB is more complicated and demanding, the cost of getting it\naccepted is −7. So if our comparison of the two codes considers\nthe respective costs of getting them accepted, Code A’s\nexpected value is \\(n-1\\), and Code B’s is \\(n+5-7\\). Once we\ninclude the respective costs of getting the codes accepted, Code\nA wins. As indicated, the costs of getting a code accepted are\n“transition costs”. But of course such transitions are\nalways to one arrangement from another. The arrangement we are\nimagining the transition being to is the acceptance of a\ncertain proposed code. The arrangement we are imagining the transition\nbeing from is … well, what? One answer is that the arrangement from which the transition is\nsupposed to be starting is whatever moral code the society happens to\naccept already. That might seem like the natural answer. However, it\nis a poor answer. The reason it is poor is that rule-consequentialism\nshould not let the cost/benefit analysis of a proposed code be\ninfluenced by the costs of getting people to give up whatever rules\nthey may have already internalised. This is for two reasons. Most importantly, rule-consequentialist assessment of codes needs\nto avoid giving weight directly or indirectly to moral ideas that have\ntheir source in other moral theories but not in rule-consequentialism\nitself. Suppose people in a given society were brought up to believe\nthat women should be subservient to men. Should rule-consequentialist\nevaluation of a proposed non-sexist code have to count the costs of\ngetting people to give up the sexist rules they have already\ninternalised so as to accept the new non-sexist ones? Since the sexist\nrules are unjustifiable, that they were accepted should not be allowed\nto infect rule-consequentialist assessment. Another reason for rejecting the answer we are considering is that\nit threatens to underwrite an unattractive relativism. Different\nsocieties may differ considerably in their extant moral beliefs. So a\nway of assessing proposed codes that considers the costs of getting\npeople already committed to some other code will end up having to\ncountenance different transition costs to get to the same code. For\nexample, the transition costs to a non-racist code are much more from\nan already accepted racist code than from an already accepted\nnon-racist one. Formulating rule-consequentialism so that it endorses\nthe same code for 1960s Michigan as for 1960s Mississippi is\ndesirable. The way to do this is to formulate the theory in terms of\nacceptance by new generations of humans. So we compare the\nrespective “teaching costs” of alternative codes, on the\nassumption that these codes will be taught to children who have not\nalready been educated to accept a moral code. We are to imagine the\nchildren start off with natural (non-moral) inclinations to be very\npartial towards themselves and a few others. We should also assume\nthat there is a cognitive cost associated with the learning of each\nrule. These are realistic assumptions, with big implications. One is that\na cost/benefit analysis of alternative codes of rules would have\nreason to favor simpler codes over more complex ones. Of course there\ncan also be benefits from having more, or more complicated, rules. Yet\nthere is probably a limit on how complicated or complex a code can be\nand still have greater expected value than simpler codes, once\nteaching costs are included. Another implication concerns prospective rules about making\nsacrifices to help others. Since children start off focused on their\nown gratifications, getting them to internalise a kind of impartiality\nthat constantly requires them to make large sacrifices for the sake of\nothers would have extremely high costs. There would also, of course,\nbe enormous benefits from the internalisation of such a rule —\npredominately, benefits to others. Would the benefits be greater than\nthe costs? At least since Sidgwick (1907: 434), many utilitarians have taken\nfor granted that human nature is such that the real possibilities are\n(1) that human beings care passionately about some and less about each\nof the rest of humanity or (2) that human beings care weakly but\nimpartially about everyone. In other words, what is not a realistic\npossibility, according to this view of human nature, is human beings’\ncaring strongly and impartially about everyone in the world. If this\nview is correct, then one enormous cost of successfully making people\ncompletely impartial is that doing so would leave them with only weak\nconcerns. Even if that picture of human nature is not correct, that is, even\nif making people completely impartial could be achieved without draining them of enthusiasm\nand passion, the cost of successfully making people care as much about\nevery other individual as they do about themselves would be\nprohibitive. At some point on the spectrum running from complete\npartiality to complete impartiality, the costs of pushing and inducing\neveryone further along the spectrum outweigh the benefits. Just as rule-consequentialists are more realistic if their\ncost/benefit analyses of codes count the cost of getting those codes\ninternalised by new generations, they are more realistic if they\nassume that the internalisation will not extend to every last\nperson. There will be some people who end up committed to mistaken\nviews about what is morally allowed. Others will never have accepted any\nmorality at all (psychopaths).  Rule-consequentialism needs to have\nrules for dealing with such people. These will consist mainly in rules about punishment. From a\nrule-consequentialist point of view, the main point of punishment is\nto deter certain kinds of act. There is also the need to get\nundeterred, dangerous people off the streets. Perhaps\nrule-consequentialism can admit that another point of punishment is to\nappease the primitive lust for revenge on the part of victims of such\nacts and their family and friends. Finally, there is the expressive\nand reinforcing power of rules about punishment. Nevertheless, some ways of formulating rule-consequentialism make\nhaving rules about punishment difficult to explain. One such way of\nformulating rule-consequentialism is: Suppose absolutely every adult human fully accepts rules forbidding\n(for example) physical attacks on the innocent, stealing, promise\nbreaking, and lying. Then presumably there would be little or no need\nfor rules about punishment. Without need for rules about punishment,\nsociety would get little or no benefit from such rules. But there is a\ncost associated with each rule included in a code. So there is a cost\nassociated with the inclusion of any rule about punishment. Because of\nthis combination of cost with no benefit, rules about punishment would\nnot be endorsed by the form of rule-consequentialism immediately\nabove. We need a form of rule-consequentialism that includes rules for\ndealing with people who are not committed to the right rules, indeed\neven for people who are irredeemable. In other words,\nrule-consequentialism needs to be formulated so as to conceptualise\nsociety as containing some people insufficiently committed to the\nright rules, and even some people never committed to any moral\nrules. Here is a way of doing so: Note that rule-consequentialism neither endorses nor condones the\nnon-acceptance of the code by those outside the overwhelming majority.\nOn the contrary, rule-consequentialism claims those people are morally\nmistaken. Indeed, the whole point of formulating rule-consequentialism\nthis way is to make room for rules about how to respond negatively to\nsuch people. Another point to make about the above formulation is of course that\n“overwhelming majority” is very imprecise. Picking a\nprecise percentage of society, say 90%, has an obvious element of\narbitrariness to it (why not 89% or 91%?). Nevertheless, we can argue\nfor a number in this range as a reasonable compromise between two\npressures. On the one hand, the percentage we pick should be close\nenough to 100% to retain the idea that moral rules are for acceptance\nby the whole society of human beings. On the other hand, the\npercentage needs to be far enough short of 100% to leave considerable\nscope for rules about punishment. It seems that 90% is in a defensible\nrange, given the need to balance those considerations. (For dissent\nfrom this, see Ridge 2006; for a reply to Ridge, see Hooker and\nFletcher 2008. The matter receives further discussion in H. Smith\n2010; Tobia 2013; Portmore 2015.) We have seen that rule-consequentialism evaluates rules on the\nbasis of the expected value of their acceptance by the overwhelming\nmajority.  What rules will such an approach endorse? It will endorse\nrules prohibiting physically attacking innocent people or their\nproperty, taking the property of others, breaking one’s promises, and\nlying. It will also endorse rules requiring one to pay special\nattention to the needs of one’s family and friends, but more generally\nto be willing to help others with their (morally permissible)\nprojects. Why? The crude answer is that a society where such rules are\nwidely internalised and thus accepted would be likely to have more\ngood in it than one lacking such rules. The fact that these rules are endorsed by rule-consequentialism\nmakes rule-consequentialism attractive. For, intuitively, these rules\nseem right. However, other moral theories endorse these rules as well.\nMost obviously, a familiar kind of moral pluralism contends that these\nintuitively attractive rules constitute the most basic level of\nmorality, i.e., that there is no deeper moral principle underlying and\nunifying these rules. Call this view Rossian pluralism (in honor of\nits champion W.D. Ross (1930, 1939)). Rule-consequentialism may agree with Rossian pluralism in endorsing\nrules against physically attacking the innocent, stealing, promise\nbreaking, and rules requiring various kinds of loyalty and more\ngenerally doing good for others. But rule-consequentialism goes beyond\nRossian pluralism by specifying an underlying unifying principle that\nprovides impartial justification for such rules. Other moral theories\ntry to do this too. Such theories include some forms of Kantianism\n(Audi 2001, 2004) and some forms of contractualism (Scanlon 1998;\nParfit 2011; Levy 2013). In any case, the first way of arguing for\nrule-consequentialism is to argue that it specifies an underlying\nprinciple that provides impartial justification for intuitively\nplausible moral rules, and that no rival theory does this as well\n(Urmson 1953; Brandt 1967; Hospers 1972; Hooker 2000). (Attacks on\nthis line of argument for rule-consequentialism include Stratton-Lake\n1997; Thomas 2000; D.E. Miller 2000; Montague 2000; Arneson 2005;\nMoore 2007; Hills 2010; Levy 2014.) This first way of arguing for rule-consequentialism might be seen\nas drawing on the idea that a theory is better justified to us to the\nextent that it increases coherence within our beliefs (Rawls 1951,\n1971: 19–21, 46–51; DePaul 1987; Ebertz 1993; Sayre-McCord\n1986, 1996). [See the entry on coherentist theories of epistemic\njustification.]  But the approach might also be seen as moderately\nfoundationalist in that it begins with a set of beliefs (in various\nmoral rules) to which it assigns independent credibility though not\ninfallibility (Audi 1996, 2004; Crisp 2000). [See the entry on foundationalist theories of epistemic\njustification.]  Admittedly, coherence with our moral beliefs does\nnot make a moral theory true, since our moral beliefs might\nof course be mistaken. Nevertheless, if a moral theory fails\nsignificantly to cohere with our moral beliefs, this undermines the\ntheory’s ability to be justified to us. The second way of arguing for rule-consequentialism is very\ndifferent. It starts from a commitment to consequentialist assessment,\nand then argues that assessing acts indirectly, e.g., by\nfocusing on the consequences of communal acceptance of rules, will in\nfact produce better consequences than assessing acts directly in terms\nof their own consequences (Austin 1832; Brandt 1963, 1979; Harsanyi\n1982: 58–60; 1993; Riley 2000). After all, making decisions\nabout what to do is the main point of moral assessment of acts. So if\na way of morally assessing acts is likely to lead to bad decisions, or\nmore generally lead to bad consequences, then, according to a\nconsequentialist point of view, so much the worse for that way of\nassessing acts. Earlier we saw that all consequentialists now accept that assessing\neach act individually by its expected value is in general a terrible\nprocedure for making moral decisions. There is widespread\nacknowledgement that agents should decide how to act by appeal to\ncertain rules such as “don’t physically attack others”,\n“don’t steal”, “don’t break your promises”,\n“pay special attention to the needs of your family and\nfriends”, and “be generally helpful to others”. And\nthese are the rules that rule-consequentialism endorses. Many\nconsequentialists, however, think this hardly shows that full\nrule-consequentialism is the best form of consequentialism. Once a\ndistinction is made between, on the one hand, the best procedure for\nmaking moral decisions about what to do and, on the other hand, the\ncriteria of moral rightness and wrongness, all consequentialists can\nadmit that we need rule-consequentialism’s rules for our decision\nprocedure. But consequentialists who are not rule-consequentialists\ncontend that such rules play no role in the criterion of moral\nrightness. Hence these consequentialists reject what this article has\ncalled full rule-consequentialism. However, whether the objection we have just been considering to the\nsecond way of arguing for rule-consequentialism is a good objection\ndepends on whether it is legitimate to distinguish between procedures\nappropriate for making moral decisions and the criteria of moral\nrightness or wrongness. That matter remains contentious (Hooker 2010;\nde Lazari-Radek and Singer 2014: ch. 10). Yet the second way of arguing for rule-consequentialism runs into\nanother and quite different objection. This objection is that the\nfirst step in this argument for rule-consequentialism is a commitment\nto consequentialist assessment. This first step itself needs\njustification. Why assume that assessing things in a consequentialist\nway is uniquely justified? It might be said that consequentialist assessment is justified\nbecause promoting the impartial good has an obvious intuitive appeal.\nBut that won’t do, since there are alternatives to consequentialist\nassessment that also have obvious intuitive appeal. This is true, for\nexample, of “act on the code that no one could reasonably\nreject”. In fact, no one very abstract moral idea is so clearly\nsuperior to its rivals that it can triumph without the aid of further\njustification.  What we need is a way of arguing for a moral theory\nthat does not start by begging the question which kind of theory is\nmost plausible. A third way of arguing for rule-consequentialism is contractualist\n(Harsanyi 1953, 1955, 1982, 1993; Brandt 1979, 1988, 1996; Scanlon\n1982, 1998; Parfit 2011; Levy 2013). Suppose we can specify reasonable\nconditions under which everyone would choose, or at least would have\nsufficient reason to choose, the same code of rules. Intuitively, such\nan idealized agreement would legitimate that code of rules. Now if\nthose rules are the ones whose internalisation would maximise the\nexpected good, contractualism is leading us to rule-consequentialism’s\nrules. There are different views about what would be reasonable conditions\nfor choosing among alternative possible moral rules. One view is that\neveryone’s impartiality would have to be insured by the imposition of\na hypothetical “veil of ignorance” behind which no one\nknew any specific facts about himself or herself (Harsanyi 1953,\n1955). Another view is that we should imagine that people would be\nchoosing a moral code on the basis of (a) full empirical information\nabout the different effects on everyone, (b) normal concerns\n(self-interested as well as altruistic), and (c) roughly equal\nbargaining power (Brandt 1979; cf. Gert 1998). Parfit (2011) proposes\nseeking rules that everyone has (personal or impartial) reason to\nchoose or will that everyone accept. If impartial reasons are always\nsufficient even when opposed by personal ones, then everyone has\nsufficient reason to will that everyone accept the rules whose\nuniversal acceptance will have the best consequences impartially\nconsidered. Similarly, Levy (2013) supposes that no one could\nreasonably reject a code of rules that would impose on her burdens\nthat add up to less than the aggregate of burdens that every other\ncode would impose on others. Such arguments suggest the extensional\nequivalence of contractualism and rule-consequentialism. (For\nassessment of whether Parfit’s contractualist arguments for\nrule-consequentialism succeed, see J. Ross 2009; Nebel 2012; Hooker\n2014.) Rule-consequentialism was not clearly formulated until Urmson 1953\nand Brandt 1959. The theory attracted considerable attention until the\nearly 1970s. Since the early 1970s, however, most moral philosophers\nhave thought of rule-consequentialism as fatally impaled on one or the\nother horn of the following dilemma: Either rule-consequentialism\ncollapses into practical equivalence with the simpler\nact-consequentialism, or rule-consequentialism is incoherent. Here is why some have thought rule-consequentialism collapses into\npractical equivalence with act-consequentialism. Consider a rule that\nrule-consequentialism purports to favor — e.g., “don’t\nsteal”. Now suppose an agent is in some situation where stealing\nwould produce more good than not stealing. If rule-consequentialism\nselects rules on the basis of their expected good,\nrule-consequentialism seems driven to admit that compliance with the\nrule “don’t steal except when … or … or\n…” is better than compliance with the simpler\n“don’t steal”. This point generalizes. In other words, for\nevery situation where compliance with some rule would not produce the\ngreatest expected good, rule-consequentialism seems driven to favor\ninstead compliance with some amended rule that does not miss out on\nproducing the greatest expected good in the case at hand. But if\nrule-consequentialism operates this way, then in practice it will end\nup requiring the very same acts that act-consequentialism\nrequires. If rule-consequentialism ends up requiring the very same acts that\nact-consequentialism requires, then rule-consequentialism is indeed in\nterrible trouble. Rule-consequentialism is the more complicated of the\ntwo theories. This leads to the following objection. What is the point\nof rule-consequentialism with its infinitely amended rules if we can\nget the same practical result much more efficiently with the simpler\nact-consequentialism? Rule-consequentialists in fact have an excellent reply to the\nobjection that their theory collapses into practical equivalence with\nact-consequentialism. This reply relies on the point that the best\nkind of rule-consequentialism ranks systems of rules not in\nterms of the expected good of complying with them, but in\nterms of the expected good of their acceptance. Now if a rule\nforbidding stealing, for example, has exception clause after exception\nclause after exception clause tacked on to it, the rule with all these\nexception clauses will provide too much opportunity for temptation to\nconvince agents that one of the exception clauses applies, when in\nfact stealing would be advantageous to the agent. And this point about\ntemptation will also undermine other people’s confidence that their\nproperty won’t be stolen. The same is true of most other moral rules:\nincorporating too many exception clauses could undermine people’s\nassurance that others will behave in certain ways (such as keeping\npromises and avoiding stealing). Furthermore, when comparing alternative rules, we must also\nconsider the relative costs of getting them internalised by new\ngenerations.  Clearly, the costs of getting new generations to learn\neither an enormous number of rules or hugely complicated rules would\nbe prohibitive. So rule-consequentialism will favor a code of rules\nwithout too many rules, and without too much complication within the\nrules. There are also costs associated with getting new generations to\ninternalise rules that require one to make enormous sacrifices for\nothers with whom one has no particular connection. Of course,\nfollowing such demanding rules will produce many benefits, mainly to\nothers. But the costs associated with internalising such rules should\nbe weighed against the benefits of following them. At some level of\ndemandingness, the costs of getting such demanding rules internalised\nwill outweigh the benefits that following them will produce. Hence,\ndoing a careful cost/benefit analysis of internalising demanding rules\nwill come out opposing rules’ being too demanding. The code of rules that rule-consequentialism favours (that is,\na code comprised of rules are not too numerous, too complicated, or too demanding)\ncan sometimes lead people to do acts that do not have the greatest\nexpected value. For example, following the simpler rule “Don’t\nsteal” will sometimes produce less good consequences than\nfollowing a more complicated rule “Don’t steal except when\n… or … or … or … or\n…”. Another example might be following a rule that allows\npeople to give some degree of priority to their own projects, even when\nthey could produce more good by sacrificing their own projects in order\nto help others. Still, rule-consequentialism’s contention is that\nbringing about widespread acceptance of a simpler and less demanding\ncode, even if acceptance of that code does sometimes lead people to do\nacts with sub-optimal consequences, has higher expected value in the\nlong run than bringing about widespread acceptance of a maximally\ncomplicated and demanding code. Since rule-consequentialism can tell\npeople to follow this simpler and less demanding code, even when following\nit will not to maximise expected good, rule-consequentialism escapes\ncollapse into practical equivalence to act-consequentialism. To the extent that rule-consequentialism circumvents collapse, this\ntheory is accused of incoherence. Rule-consequentialism is accused of\nincoherence for maintaining that an act can be morally permissible or\neven required though the act fails to maximise expected good. Behind\nthis accusation must be the assumption that\nrule-consequentialism contains an overriding commitment to maximise\nthe good. It is incoherent to have this overriding commitment and then\nto oppose an act required by the commitment. (For a recent\ndevelopments of this line of thought, see Arneson 2005; Card 2007;\nWall 2009.) In order to evaluate the incoherence objection to\nrule-consequentialism, we need to be clearer about the supposed\nlocation of an overriding commitment to maximize the good. Is this\ncommitment supposed to be part of the rule-consequentialist agent’s\nmoral psychology? Or is it supposed to be part of the theory\nrule-consequentialism? Well, rule-consequentialists need not have maximizing the good as\ntheir ultimate and overriding moral goal. Instead, they could have a\nmoral psychology as follows: Their fundamental moral motivation is to do what is impartially\ndefensible. They believe acting on impartially justified rules is impartially\ndefensible. They also believe that rule-consequentialism is on balance the best\naccount of impartially justified rules. Agents with this moral psychology — i.e., this combination of\nmoral motivation and beliefs — would be morally motivated to do\nas rule-consequentialism prescribes. This moral psychology is\ncertainly possible. And, for agents who have it, there is nothing\nincoherent about following rules when doing so will not maximize the\nexpected good. So, even if rule-consequentialist agents need not have an\noverriding commitment to maximize expected good, does their theory\ncontain such a commitment? No, rule-consequentialism is essentially\nthe conjunction of two claims: (1) that rules are to be selected\nsolely in terms of their consequences and (2) that these rules\ndetermine which kinds of acts are morally wrong. This is really all\nthere is to the theory — in particular, there is not some third\ncomponent consisting in or entailing an overriding commitment to\nmaximize expected good. Without an overriding commitment to maximize the expected good,\nthere is nothing incoherent in rule-consequentialism’s forbidding some\nkinds of act, even when they maximize the expected good. Likewise,\nthere is nothing incoherent about rule-consequentialism’s requiring\nother kinds of act, even when they conflict with maximizing the\nexpected good. The best known objection to rule-consequentialism dies\nonce we realize that neither the rule-consequentialist agent nor the\ntheory itself contains an overriding commitment to maximize the\ngood. The viability of this defense of rule-consequentialism against the\nincoherence objection may depend in part on what the argument for\nrule-consequentialism is supposed to be. The defense seems less viable\nif the argument for rule-consequentialism starts from a commitment to\nconsequentialist assessment. For starting with such a commitment seems\nvery close to starting from an overriding commitment to maximize the\nexpected good. The defence against the incoherence objection seems far\nmore secure, however, if the argument for rule-consequentialism is\nthat this theory does better than any other moral theory at specifying\nan impartial justification for intuitively plausible moral rules. (For\nmore on this, see Hooker 2005, 2007.) Another old objection to rule-consequentialism is that\nrule-consequentialists must be “rule-worshipers” —\ni.e., people who will stick to the rules even when doing so will\nobviously be disastrous. The answer to this objection is that rule-consequentialism endorses\na rule requiring one to prevent disaster, even if doing so requires\nbreaking other rules (Brandt 1992: 87–8, 150–1,\n156–7). To be sure, there are many complexities about what\ncounts as a disaster. Think about what counts as a disaster when the\n“prevent disaster” rule is in competition with a rule\nagainst lying. Now think about what counts as a disaster when the\n“prevent disaster” rule is in competition with a rule\nagainst stealing, or even more when in competition with a rule against\nphysically harming the innocent.  Rule-consequentialism may need to be\nclearer about such matters. But at least it cannot rightly be accused\nof potentially leading to disaster. An important confusion to avoid is to think that\nrule-consequentialism’s including a “prevent disaster”\nrule means that rule-consequentialism collapses into practical\nequivalence with maximising act-consequentialism. Maximising\nact-consequentialism holds that we should lie, or steal, or harm the\ninnocent whenever doing so would produce even a little more\nexpected good than not doing so would. A rule requiring one to prevent\ndisaster does not have this implication.  Rather, the “prevent\ndisaster” rule comes into play only when there is a very much\nlarger difference in the amounts of expected value at stake. From the mid 1960s until the mid 1990s, most philosophers thought\nrule-consequentialism couldn’t survive the objections discussed in the\nprevious section. So, during those three decades, most philosophers\ndidn’t bother with other objections to the theory. However, if\nrule-consequentialism has convincing replies to all three of the\nobjections just discussed, then a good question is whether or not\nthere are other fatal objections to the theory. Some other objections try to show that, given the theory’s\ncriterion for selecting rules, there are conditions under which it\nselects intuitively unacceptable rules. For example, Tom Carson (1991)\nargued that rule-consequentialism turns out to be extremely demanding\nin the real world. Mulgan (2001, esp. ch. 3) agreed with Carson about\nthat, and went on to argue that, even if rule-consequentialism’s\nimplications in the actual world are fine, the theory has\ncounterintuitive implications in possible worlds. If Mulgan were right\nabout that, this would cast doubt on rule-consequentialism’s claim to\nexplain why certain demands are appropriate in the actual\nworld. Debate about such matters continues (Hooker 2003; Lawlor 2004;\nWoollard 2015: 181–205). And Mulgan has become a developer of\nthe theory rather than a critic (Mulgan 2006, 2009, and 2015). A related objection to rule-consequentialism is that\nrule-consequentialism makes the justification of familiar rules\ncontingent on various empirical facts, such as what human nature is\nlike, and how many people there are in need or in positions to help.\nThe objection to rule-consequentialism is that some familiar moral\nrules are necessarily, not merely contingently, justified (McNaughton\nand Rawling 1998; Gaut 1999, 2002; Montague 2000; Suikkanen 2008). A\nsibling of this objection is that rule-consequentialism makes the\njustification of rules depend on the wrong facts (Arneson 2005;\nPortmore 2009). Again, debate about whether the theory does point to the wrong facts\ncontinues (see Woollard 2015, esp. pp. 185–86, 203–205). The mechanics of teaching new codes throws up serious questions for\nforms of rule-consequentialism that count the costs of getting rules\ninternalised by new generations. The reference to new generations is\nmeant to avoid having to count the costs of getting rules internalised\nby existing generations of people who have already internalised some\nother moral rules and ideas. But can we come up with a coherent\ndescription of those who are supposed to do the teaching of these new\ngenerations? If the teachers are imagined to have already internalised\nthe ideal code themselves, then how is that supposed to have happened?\nIf these teachers are imagined not to have already internalised the\nideal code, then there will be costs associated with the conflict\nbetween the ideal code and whatever they have already\ninternalised. (This objection was formulated by John Andrews, Robert\nEhman, and Andrew Moore. Cf. Levy 2000.) A related objection is that\nrule-consequentialism has not yet been formulated in a way that\nenables it to deal plausibly with conflicts among rules (Eggleston\n2007). Another line of objection to rule-consequentialism has focused on\nits idea that the considerations that determine moral right and wrong\nmust be suitable for public acknowledgement. Arneson (2005) and de\nLazari-Radek and Singer (2014) argue, as against\nrule-consequentialism, that there is a potential gap between the\nconsiderations suitable for public acknowledgement and the\nconsiderations that really do determine moral right and wrong. Others\ntake rule-consequentialism’s idea that the considerations that\ndetermine moral right and wrong must be suitable for public\nacknowledgement to be not only one of the aspects that\nrule-consequentialism shares with Kantian ethics but also one of\nrule-consequentialism’s attractions (Hooker 2000, 2010; Hill 2005;\nParfit 2011; Cureton 2015).  ","contact.mail":"b.w.hooker@reading.ac.uk","contact.domain":"reading.ac.uk"}]
