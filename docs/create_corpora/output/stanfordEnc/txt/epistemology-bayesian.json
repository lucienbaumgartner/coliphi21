[{"date.published":"2001-07-12","date.changed":"2008-03-26","url":"https://plato.stanford.edu/entries/epistemology-bayesian/","author1":"William Talbott","author1.info":"http://faculty.washington.edu/wtalbott/","entry":"epistemology-bayesian","body.text":"\n\n\n\n‘Bayesian epistemology’ became an epistemological movement\nin the 20th century, though its two main features can be\ntraced back to the eponymous Reverend Thomas Bayes (c. 1701–61). Those\ntwo features are: (1) the introduction of a formal apparatus\nfor inductive logic; (2) the introduction of a pragmatic\nself-defeat test (as illustrated by Dutch Book Arguments) for\nepistemic rationality as a way of extending the justification\nof the laws of deductive logic to include a justification for the laws\nof inductive logic. The formal apparatus itself has two main elements:\nthe use of the laws of probability as coherence constraints on\nrational degrees of belief (or degrees of confidence) and the\nintroduction of a rule of probabilistic inference, a rule or principle\nof conditionalization.\n\n\n\n\nBayesian epistemology did not emerge as a philosophical program\nuntil the first formal axiomatizations of probability theory in the\nfirst half of the 20th century. One important\napplication of Bayesian epistemology has been to the analysis of\nscientific practice in Bayesian Confirmation Theory. In\naddition, a major branch of statistics, Bayesian\nstatistics, is based on Bayesian principles. In psychology,\nan important branch of learning theory, Bayesian learning\ntheory, is also based on Bayesian principles. Finally, the\nidea of analyzing rational degrees of belief in terms of rational\nbetting behavior led to the 20th century development of a\nnew kind of decision theory, Bayesian decision theory, which is\nnow the dominant theoretical model for both the descriptive and\nnormative analysis of decisions. The combination of its precise\nformal apparatus and its novel pragmatic self-defeat test for\njustification makes Bayesian epistemology one of the most important\ndevelopments in epistemology in the 20th century, and one of\nthe most promising avenues for further progress in epistemology in the\n21st century. \n\n\n\nThere are two ways that the laws of deductive logic have been thought\nto provide rational constraints on belief: (1) Synchronically, the\nlaws of deductive logic can be used to define the notion of deductive\nconsistency and inconsistency. Deductive inconsistency so defined\ndetermines one kind of incoherence in belief, which I refer to as\ndeductive incoherence. (2) Diachronically, the laws of\ndeductive logic can constrain admissible changes in belief by\nproviding the deductive rules of inference. For example,\nmodus ponens is a deductive rule of inference that requires\nthat one infer Q from premises P and P\n → Q. \n\nBayesians propose additional standards of synchronic coherence —\nstandards of probabilistic coherence — and additional rules\nof inference — probabilistic rules of inference — in both\ncases, to apply not to beliefs, but degrees of belief (degrees of\nconfidence). For Bayesians, the most important standards of\nprobabilistic coherence are the laws of probability. For more on the\nlaws of probability, see the following supplementary article: \n\nFor Bayesians, the most important probabilistic rule of inference is\ngiven by a principle of conditionalization.  \n\nIf unconditional probabilities (e.g. P(S)) are taken\nas primitive, the conditional probability of S on T\ncan be defined as follows: \n\nBy itself, the definition of conditional probability is of little\nepistemological significance. It acquires epistemological\nsignificance only in conjunction with a further epistemological\nassumption: \n\nIn epistemological terms, this Simple Principle of Conditionalization\nrequires that the effects of evidence on rational degrees be analyzed\nin two stages: The first is non-inferential. It is the change in the\nprobability of the evidence statement E from\nPi(E), assumed to be greater\nthan zero and less than one, to\nPf(E) = 1. The second is a\nprobabilistic inference of conditionalizing on E from initial\nprobabilities (e.g., Pi(S)) to\nfinal probabilities (e.g., Pf(S)\n= Pi(S/E)). \n\nProblems with the Simple Principle (to be discussed below) have led\nmany Bayesians to qualify the Simple Principle by limiting its\nscope. In addition, some Bayesians follow Jeffrey in generalizing the\nSimple Principle to apply to cases in which one's new evidence is less\nthan certain (also discussed below). What unifies Bayesian\nepistemology is a conviction that conditionalizing (perhaps of a\ngeneralized sort) is rationally required in some important contexts\n— that is, that some sort of conditionalization principle is an\nimportant principle governing rational changes in degrees of\nbelief. \n\nMany arguments have been given for regarding the probability laws as\ncoherence conditions on degrees of belief and for taking some\nprinciple of conditionalization to be a rule of probabilistic\ninference. The most distinctively Bayesian are those referred to as\nDutch Book Arguments. Dutch Book Arguments represent the\npossibility of a new kind of justification for epistemological\nprinciples. \n\nA Dutch Book Argument relies on some descriptive or normative\nassumptions to connect degrees of belief with willingness to wager —\nfor example, a person with degree of belief p in sentence\nS is assumed to be willing to pay up to and including\n$p for a unit wager on S (i.e., a wager that pays $1\nif S is true) and is willing to sell such a wager for any\nprice equal to or greater than $p (one is assumed to be equally\nwilling to buy or sell such a wager when the price is exactly\n $p).[2]\n A Dutch Book is a combination of\nwagers which, on the basis of deductive logic alone, can be shown to\nentail a sure loss. A synchronic Dutch Book is a Dutch Book\ncombination of wagers that one would accept all at the same time.  A\ndiachronic Dutch Book is a Dutch Book combination of wagers\nthat one will be motivated to enter into at different times.  \n\nRamsey and de Finetti first employed synchronic Dutch Book Arguments\nin support of the probability laws as standards of synchronic\ncoherence for degrees of belief. The first diachronic Dutch Book\nArgument in support of a principle of conditionalization was reported\nby Teller, who credited David Lewis. The Lewis/Teller argument depends\non a further descriptive or normative assumption about conditional\nprobabilities due to de Finetti: An agent with conditional probability\nP(S/T) = p is assumed to be\nwilling to pay any price up to and including $p for a unit\nwager on S conditional on T. (A unit wager on\nS conditional on T is one that is called off, with\nthe purchase price returned to the purchaser, if T is not\ntrue. If T is true, the wager is not called off and the wager\npays $1 if S is also true.)  On this interpretation of\nconditional probabilities, Lewis, as reported by Teller, was able to\nshow how to construct a diachronic Dutch Book against anyone who, on\nlearning only that T, would predictably change his/her degree\nof belief in S to Pf(S)\n> Pi(S/T); and how\nto construct a diachronic Dutch Book against anyone who, on learning\nonly that T, would predictably change his/her degree of\nbelief in S to Pf(S)\n< Pi(S/T). For\nillustrations of the strategy of the Ramsey/de Finetti and the\nLewis/Teller arguments, see the following supplementary article: \n\nThere has been much discussion of exactly what it is that Dutch Book\nArguments are supposed to show. On the literal-minded\ninterpretation, their significance is that they show that those\nwhose degrees of belief violate the probability laws or those whose\nprobabilistic inferences predictably violate a principle of\nconditionalization are liable to enter into wagers on which they are\nsure to lose. There is very little to be said for the literal-minded\ninterpretation, because there is no basis for claiming that\nrationality requires that one be willing to wager in accordance with\nthe behavioral assumptions described above. An agent could simply\nrefuse to accept Dutch Book combinations of wagers. \n\nOne of the main motivations for Jeffrey's new approach to the\nfoundations of decision theory in Logic of Decision was his\ndissatisfaction with the identification of subjective probability with\nbetting ratios.  For example, no matter what one's degree of belief in\nthe proposition that all human life will be destroyed within the next\nten years, it would be not be rational to offer to buy a bet on its\ntruth.  Williamson extends de Finetti's Dutch Book Argument for a\nfinite additivity constraint on rational degrees of belief to produce\nan argument for a countable additivity constraint on degrees of\nbelief, but the argument is better interpreted as a reductio of the\nliteral-minded interpretation of Dutch Book Arguments than as an\nargument for the rationality of a countable additivity constraint.\nThe rational response to offers to bet on the proposition that all\nlife will be destroyed within the next ten years or to bet on a single\npossible outcome in a countably infinite set of equiprobable possible\noutcomes is simply not to. \n\nA more plausible interpretation of Dutch Book Arguments is that they\nare to be understood hypothetically, as symptomatic of what has been\ntermed pragmatic self-defeat. On this interpretation, Dutch\nBook Arguments are a kind of heuristic for determining when\none's degrees of belief have the potential to be\npragmatically self-defeating. The problem is not that one\nwho violates the Bayesian constraints is likely to enter into a\ncombination of wagers that constitute a Dutch Book, but that, on any\nreasonable way of translating one's degrees of belief into\naction, there is a potential for one's degrees of belief to\nmotivate one to act in ways that make things worse than they might\nhave been, when, as a matter of logic alone, it can be determined\nthat alternative actions would have made things better (on one's\nown evaluations of better and worse).  \n\nAnother way of understanding the problem of susceptibility to a Dutch\nBook is due to Ramsey: Someone who is susceptible to a Dutch Book\nevaluates identical bets differently based on how they are described.\nPutting it this way makes susceptibility to Dutch Books sound\nirrational.  But this standard of rationality would make it\nirrational not to recognize all the logical consequences of what one\nbelieves.  This is the assumption of logical omniscience\n(discussed below).   \n\nIf successful, Dutch Book Arguments would reduce the justification\nof the principles of Bayesian epistemology to two elements: (1) an\naccount of the appropriate relationship between degrees of belief and\nchoice; and (2) the laws of deductive logic. Because it would seem\nthat the truth about the appropriate relationship between the degrees\nof belief and choice is independent of epistemology, Dutch Book\nArguments hold out the potential of justifying the principles of\nBayesian epistemology in a way that requires no other epistemological\nresources than the laws of deductive logic. For this reason, it makes\nsense to think of Dutch Book Arguments as indirect, pragmatic\narguments for according the principles of Bayesian epistemology much\nthe same epistemological status as the laws of deductive logic.\nDutch Book Arguments are a truly distinctive contribution made by\nBayesians to the methodology of epistemology.   \n It should also be mentioned that some Bayesians have defended their\nprinciples more directly, with non-pragmatic arguments.  In addition\nto reporting Lewis's Dutch Book Argument, Teller offers a\nnon-pragmatic defense of Conditionalization.  There have been many\nproposed non-pragmatic defenses of the probability laws (e.g., van\nFraassen; Shimony).  The most compelling is due to Joyce.  All such\ndefenses, whether pragmatic or non-pragmatic, produce a puzzle for\nBayesian epistemology: The principles of Bayesian epistemology are\ntypically proposed as principles of inductive reasoning.  But\nif the principles of Bayesian epistemology depend ultimately for their\njustification solely on the laws of deductive logic, what reason is\nthere to think that they have any inductive content?  That is\nto say, what reason is there to believe that they do anything more\nthan extend the laws of deductive logic from beliefs to degrees of\nbelief?  It should be mentioned, however, that even if Bayesian\nepistemology only extended the laws of deductive logic to degrees of\nbelief, that alone would represent an extremely important advance in\nepistemology.   \n\nThis section reviews some of the most important results in the\nBayesian analysis of scientific practice — Bayesian Confirmation\nTheory. It is assumed that all statements to be evaluated have\nprior probability greater than zero and less than one. \nBayes' Theorem is a straightforward consequence of the probability\naxioms and the definition of conditional probability: \n The epistemological significance of Bayes' Theorem is that it\nprovides a straightforward corollary to the Simple Principle of\nConditionalization. Where the final probability of a hypothesis\nH is generated by conditionalizing on evidence E,\nBayes' Theorem provides a formula for the final probability of\nH in terms of the prior or initial likelihood of\nH on E\n(Pi(E/H)) and the prior\nor initial probabilities of H and E: \n Due to the influence of Bayesianism, likelihood is now a\ntechnical term of art in confirmation theory.  As used in this\ntechnical sense, likelihoods can be very useful.  Often, when the\nconditional probability of H on E is in doubt, the\nlikelihood of H on E can be computed from the\ntheoretical assumptions of H. \n\nA. Confirmation and disconfirmation. In Bayesian\nConfirmation Theory, it is said that evidence confirms (or would\nconfirm) hypothesis H (to at least some degree) just in case\nthe prior probability of H conditional on E is\ngreater than the prior unconditional probability of H:\nPi(H/E) >\nPi(H). E disconfirms\n(or would disconfirm) H if the prior probability of\nH conditional on E is less than the prior\nunconditional probability of H. \n\nThis is a qualitative conception of confirmation.  There is no general\nagreement in the literature on a quantitative measure of degree of\nconfirmation or degree of evidential support.  Earman (chap. 5) and\nFitelson both provide a good overview of the various proposals.  It\nmight be thought that the degree to which evidence E supports (or\nwould support) hypothesis H could be defined as\nPi(H/E) −\nPi(H).  One potential problem\nwith this proposal is that it has the consequence that no evidence can\nprovide much evidential support to a hypothesis that is antecedently\nvery probable, because as the probability of H approaches\none, the difference goes to zero.  Eells and Fitelson have argued that\nthis apparently counterintuitive consequence can be avoided by\ndistinguishing the historical question of how much a piece of evidence\nE actually contributed to the confirmation of H\n(which, of course, would have to be small if H were antecedently\nhighly probable) from the question of the degree of evidential support\nE provides for H, the answer to which, they propose,\nis relative to the background information.  So even if H is\nvery probable at the time that evidence E is acquired, we can\nask how much evidential support E would provide for\nH if we had no other evidence supporting H.  Eells\nand Fitelson have also provided a useful framework for evaluating the\nvarious proposals in the literature, a framework within which most of\nthem are found to be wanting.  \n\nB. Confirmation and disconfirmation by entailment.\nWhenever a hypothesis H logically entails evidence\nE, E confirms H. This follows from the fact\nthat to determine the truth of E is to rule out a possibility\nassumed to have non-zero prior probability that is incompatible with\nH — the possibility that ~E.  A corollary is\nthat, where H entails E, ~E would\ndisconfirm H, by reducing its probability to zero.  The most\ninfluential model of explanation in science is the\nhypothetico-deductive model (e.g., Hempel).  Thus, one of the most\nimportant sources of support for Bayesian Confirmation Theory is that\nit can explain the role of hypothetico-deductive explanation in\nconfirmation.   \n\nC. Confirmation of logical equivalents. If two\nhypotheses H1 and H2 are logically equivalent, then evidence\nE will confirm both equally. This follows from the fact that\nlogically equivalent statements always are assigned the same\nprobability. \n\nD. The confirmatory effect of surprising or diverse\nevidence. From the corollary above, it follows that whether\nE confirms (or disconfirms) H depends on whether\nE is more probable (or less probable) conditional on\nH than it is unconditionally — that is, on whether: \n\nAn intuitive way of understanding (b1) is to say that it states that\nE would be more expected (or less surprising) if it were\nknown that H were true. So if E is surprising, but\nwould not be surprising if we knew H were true, then\nE will significantly confirm H. Thus, Bayesians\nexplain the tendency of surprising evidence to confirm hypotheses on\nwhich the evidence would be expected. \n\nSimilarly, because it is reasonable to think that evidence\nE1 makes other evidence of the same kind much more\nprobable, after E1 has been determined to be true,\nother evidence of the same kind E2 will generally\nnot confirm hypothesis H as much as other diverse evidence\nE3, even if H is equally likely on both\nE2 and E3. The explanation is\nthat where E1 makes E2 much\nmore probable than E3\n(Pi(E2/E1)\n>>\nPi(E3/E1),\nthere is less potential for the discovery that E2\nis true to raise the probability of H than there is for the\ndiscovery that E3 is true to do so.  \n\nE. Relative confirmation and likelihood ratios. Often\nit is important to be able to compare the effect of evidence\nE on two competing hypotheses,\nHj and Hk, without\nhaving also to consider its effect on other hypotheses that may not be\nso easy to formulate or to compare with\nHj and Hk.\nFrom the first corollary above, the ratio of the final probabilities\nof Hj and Hk\nwould be given by: \n\nIf the odds of Hjrelative to\nHk are defined as ratio of their probabilities, then from\nthe Ratio Formula it follows that, in a case in which change in\ndegrees of belief results from conditionalizing on E, the\nfinal odds\n(Pf(Hj)/Pf(Hk))\nresult from multiplying the initial odds\n(Pi(Hj)/Pi(Hk))\nby the likelihood ratio\n(Pi(E/Hj)/Pi(E/Hk)). Thus,\nin pairwise comparisons of the odds of hypotheses, the likelihood\nratio is the crucial determinant of the effect of the evidence on the\nodds. \n\nF. Subjective and Objective Bayesianism. Are there\nconstraints on prior probabilities other than the probability laws?\nConsider a situation in which you are to draw a ball from an urn\nfilled with red and black balls.  Suppose you have no other\ninformation about the urn.  What is the prior probability (before\ndrawing a ball) that, given that a ball is drawn from the urn, that\nthe drawn ball will be black?  The question divides Bayesians into two\ncamps: \n\n(a) Subjective Bayesians emphasize the relative lack of\nrational constraints on prior probabilities.  In the urn example, they\nwould allow that any prior probability between 0 and 1 might be\nrational (though some Subjective Bayesians (e.g., Jeffrey) would rule\nout the two extreme values, 0 and 1).  The most extreme Subjective\nBayesians (e.g., de Finetti) hold that the only rational constraint on\nprior probabilities is probabilistic coherence.  Others (e.g.,\nJeffrey) classify themselves as subjectivists even though they allow\nfor some relatively small number of additional rational constraints on\nprior probabilities.  Since subjectivists can disagree about\nparticular constraints, what unites them is that their constraints\nrule out very little.  For Subjective Bayesians, our actual prior\nprobability assignments are largely the result of non-rational\nfactors—for example, our own unconstrained, free choice or\nevolution or socialization. \n\n(b) Objective Bayesians (e.g., Jaynes and Rosenkrantz)\nemphasize the extent to which prior probabilities are rationally\nconstrained.  In the above example, they would hold that rationality\nrequires assigning a prior probability of 1/2 to drawing a black ball\nfrom the urn.  They would argue that any other probability would fail\nthe following test: Since you have no information at all about which\nballs are red and which balls are black, you must choose prior\nprobabilities that are invariant with a change in label (“red” or\n“black”).  But the only prior probability assignment that is invariant\nin this way is the assignment of prior probability of 1/2 to each of\nthe two possibilities (i.e., that the ball drawn is black or that it\nis red). \n\nIn the limit, an Objective Bayesian would hold that rational\nconstraints uniquely determine prior probabilities in every\ncircumstance.  This would make the prior probabilities logical\nprobabilities determinable purely a priori.  None of\nthose who identify themselves as Objective Bayesians holds this\nextreme form of the view.  Nor do they all agree on precisely what the\nrational constraints on degrees of belief are.  For example,\nWilliamson does not accept Conditionalization in any form as a\nrational constraint on degrees of belief.  What unites all of the\nObjective Bayesians is their conviction that in many circumstances,\nsymmetry considerations uniquely determine the relevant prior\nprobabilities and that even when they don't uniquely determine the\nrelevant prior probabilities, they often so constrain the range of\nrationally admissible prior probabilities, as to assure convergence on\nthe relevant posterior probabilities.  Jaynes identifies four general\nprinciples that constrain prior probabilities, group invariance,\nmaximium entropy, marginalization, and coding theory, but he does not\nconsider the list exhaustive.  He expects additional principles to be\nadded in the future.  However, no Objective Bayesian claims that there\nare principles that uniquely determine rational prior probabilities in\nall cases. \n\nBy introducing symmetry constraints on prior probabilities, the\nObjective Bayesians inherit the difficulties of the classical\nPrinciple of Indifference, so-named by Keynes, but usually attributed\nto Laplace.  The simple example of the urn illustrates how invariance\nconsiderations can be used to give content to the Principle of\nIndifference.  There the objectivist is able to uniquely determine the\nprior probabilities from the requirement that the rational prior\nprobabilities should be invariant under switching the labels used to\nclassify the balls in the urn. \n\nHowever, it is generally agreed by both objectivists and subjectivists\nthat ignorance alone cannot be the basis for assigning prior\nprobabilities.  The reason is that in any particular case there must\nbe some information to pick out which parameters or which\ntransformations are the ones among which one is to be indifferent.\nWithout such information, indifference considerations lead to paradox.\nObjective Bayesians have been quite creative in finding ways to\nresolve many of the paradoxes (e.g., Jeffreys' solution to Bertrand's\nPardox, Jaynes's solution to Buffon's Needle Paradox, or Mikkelson's\nsolution to van Mises' Paradox).  But there are always more paradoxes.\nCharles, Höcker, Lacker, Le Diberder, and T'Jampens (Other\nInternet Resources) provide an actual example from physics where\nmaximum entropy yields conflicting results depending on\nparameterization and where a frequentist approach seems to be superior\nto any Objective Bayesian approach that employs any form of\nConditionalization. \n\nG. The typical differential effect of positive evidence and\nnegative evidence. Hempel first pointed out that we typically\nexpect the hypothesis that all ravens are black to be confirmed to\nsome degree by the observation of a black raven, but not by the\nobservation of a non-black, non-raven. Let H be the\nhypothesis that all ravens are black. Let E1\ndescribe the observation of a non-black, non-raven. Let\nE2 describe the observation of a black\nraven. Bayesian Confirmation Theory actually holds that both\nE1 and E2 may provide some\nconfirmation for H. Recall that E1\nsupports H just in case\nPi(E1/H)/Pi(E1)\n> 1. It is plausible to think that this ratio is ever so slightly\ngreater than one. On the other hand, E2 would seem to\nprovide much greater confirmation to H, because, in this example, it\nwould be expected that\nPi(E2/H)/Pi(E2)\n>>\nPi(E1/H)/Pi(E1).  \n\nThese are only a sample of the results that have provided support\nfor Bayesian Confirmation Theory as a theory of rational inference for\nscience. For further examples, see Howson and Urbach. It\nshould also be mentioned that an important branch of statistics,\nBayesian statistics is based on the principles of Bayesian\nepistemology.  \n\nOne of the important developments in Bayesian epistemology has been\nthe exploration of the social dimension to inquiry.  The obvious\nexample is scientific inquiry, because it is the community of\nscientists, rather than any individual scientist, who determine what\nis or is not accepted in the discipline.  In addition, scientists\ntypically work in research groups and even those who work alone rely\non the reports of other scientists to be able to design and carry out\ntheir own work.  Other important examples of the social dimension to\nknowledge include the use of juries to make factual determinations in\nthe legal system and the decentralization of knowledge over the\nInternet. \n\nThere are two ways that Bayesian epistemology can be applied to social\ninquiry: \n\n(1) Bayesian epistemology of testimony (understood generally, to\ninclude not only personal testimony but all media sources of\ninformation).  Goldman has developed a Bayesian epistemology of\ntestimony and applied it to social entities such as science and the\nlegal system.  In any such approach, a crucial issue is how to\nevaluate the reliability of the reports one receives.  Goldman's\napproach is to focus on institutional design to motivate the\nproduction of reliable reports.  Bovens and Hartmann instead try to\nmodel how, when there are reports from multiple sources, a Bayesian\nagent can use probabilistic reasoning to judge the reliability of the\nreports, and thus, how much credence to place in them.  The idea that\nin evaluating the probability of a report we are implicitly evaluating\nthe reliability of the reporter is developed by Barnes as a potential\nexplanation of the prediction/accommodation asymmetry, discussed in\nthe next section. \n\n(2) Aggregate Bayesianism.  If scientific knowledge or jury\ndeliberations produce a group product, it is natural to consider\nwhether the group's knowledge can be represented in aggregate form.\nIn Bayesian terms, the question is whether the individuals'\nprobabililty assignments can be usefully aggregated into a single\nprobability assignment that reflects the group's knowledge.  Although\nSeidenfeld, Kadane, and Schervish have shown that there is generally\nno way to define an aggregate Bayesian expected utility maximizer to\nrepresent the Pareto preferences of a group of two or more individual\nBayesian expected utility maximizers, there is no impossibility result\nprecluding the aggregation of individual probabililty assignments into\na group probability assignment.  However, there is no generally agreed\nupon rule for doing so.  If a group of Bayesian individuals all had\nbegun from the same initial probabilities, then simply sharing their\nevidence would lead them all to the same final probabilities.  It may\nseem unfortunate that unanimity in science and other social endeavors\ncannot be achieved so easily, but Kitcher has argued that this is a\nmistake, because cognitive diversity plays an important role in\nscientific progress. \n\nThe fruitfulness of Bayesian social epistemology may ultimately\ndepend on whether or not the idealizations of Bayesian theory are too\nunrealistic.  For example, if one of the important effects of jury\ndeliberations is that they tend to provide a way for the group to\ncorrect for the irrationality of individual members, then no model of\njurors as ideal Bayesians is likely to be able to explain that feature\nof the jury system. \n\nThis section reviews some of the most important potential problems\nfor Bayesian Confirmation Theory and for Bayesian epistemology\ngenerally. No attempt is made to evaluate their seriousness here,\nthough there is no generally agreed upon Bayesian solution to any of\nthem. \n\nA. The assumption of logical omniscience. The\nassumption that degrees of belief satisfy the probability laws implies\nomniscience about deductive logic, because the probability laws\nrequire that all deductive logical truths have probability one, all\ndeductive inconsistencies have probability zero, and the probability\nof any conjunction of sentences be no greater than any of its\ndeductive consequences. This seems to be an unrealistic standard for\nhuman beings. Hacking and Garber have made proposals to relax the\nassumption of logical omniscience. Because relaxing that assumption\nwould block the derivation of almost all the important results in\nBayesian epistemology, most Bayesians maintain the assumption of\nlogical omniscience and treat it as an ideal to which human beings can\nonly more or less approximate. \n\nB. The special epistemological status of the laws of\nclassical logic. Even if the assumption of logical\nomniscience is not too much of an idealization to provide a useful\nmodel for human reasoning, it has another potentially troubling\nconsequence.  It commits Bayesian epistemology to some sort of a\npriori/a posteriori distinction, because there could be no Bayesian\naccount of how empirical evidence might make it rational to adopt a\ntheory with a non-classical logic.  In this respect, Bayesian\nepistemology carries over the presumption from traditional\nepistemology that the laws of logic are immune to revision on the\nbasis of empirical evidence. \n\nIt is open to the Bayesian to try to downplay the significance of\nthis consequence, by articulating an a priori/a posteriori distinction\nthat aims to be pragmatic rather than metaphysical (e.g., Carnap's\nanalytic/synthetic distinction).  However, any such account must\naddress Quine's well-known holistic challenge to the\nanalytic-synthetic distinction. \n\nA. The problem of uncertain evidence. The Simple\nPrinciple of Conditionalization requires that the acquisition of\nevidence be representable as changing one's degree of belief in a\nstatement E to one — that is, to certainty. But many\nphilosophers would object to assigning probability of one to any\ncontingent statement, even an evidential statement, because, for\nexample, it is well-known that scientists sometimes give up previously\naccepted evidence. Jeffrey has proposed a generalization of the\nPrinciple of Conditionalization that yields that principle as a\nspecial case. Jeffrey's idea is that what is crucial about\nobservation is not that it yields certainty, but that it generates a\nnon-inferential change in the probability of an evidential statement\nE and its negation ~E (assumed to be the locus of\nall the non-inferential changes in probability) from initial\nprobabilities between zero and one to\nPf(E) and\nPf(~E) = [1 −\nPf(E)].  Then on\nJeffrey's account, after the observation, the rational degree of\nbelief to place in an hypothesis H would be given by the\nfollowing principle: \n\nCounting in favor of Jeffrey's Principle is its theoretical\nelegance. Counting against it is the practical problem that it\nrequires that one be able to completely specify the direct\nnon-inferential effects of an observation, something it is doubtful\nthat anyone has ever done. Skyrms has given it a Dutch Book defense.\n \n\nB. The problem of old evidence. On a Bayesian\naccount, the effect of evidence E in confirming (or\ndisconfirming) a hypothesis is solely a function of the increase in\nprobability that accrues to E when it is first determined to\nbe true. This raises the following puzzle for Bayesian Confirmation\nTheory discussed extensively by Glymour: Suppose that E is an\nevidentiary statement that has been known for some time — that\nis, that it is old evidence; and suppose that H is a\nscientific theory that has been under consideration for some time. One\nday it is discovered that H implies E. In scientific\npractice, the discovery that H implied E would\ntypically be taken to provide some degree of confirmatory support for\nH. But Bayesian Confirmation Theory seems unable to explain\nhow a previously known evidentiary statement E could provide\nany new support for H. For conditionalization to come into play, there\nmust be a change in the probability of the evidence statement\nE. Where E is old evidence, there is no change in\nits probability. Some Bayesians who have tried to solve this problem\n(e.g., Garber) have typically tried to weaken the logical omniscience\nassumption to allow for the possibility of discovering logical\nrelations (e.g., that H and suitable auxiliary assumptions\nimply E). As mentioned above, relaxing the logical\nomniscience assumption threatens to block the derivation of almost all\nof the important results in Bayesian epistemology.  Other Bayesians\n(e.g., Lange) employ the Bayesian formalism as a tool in the\nrational reconstruction of the evidentiary support for a\nscientific hypothesis, where it is irrelevant to the rational\nreconstruction whether the evidence was discovered before or after the\ntheory was initially formulated.  Joyce and Christensen agree that\ndiscovering new logical relations between previously accepted evidence\nand a theory cannot raise the probability of the theory.  However,\nthey suggest that using\nPi(H/E) −\nPi(H/-E) as a measure\nof support can at least explain how evidence that has probability one\ncould still support a theory.  Eells and Fitelson have criticized this\nproposal and argued that the problem is better addressed by\ndistinguishing two measures, the historical measure of the degree to\nwhich a piece of evidence E actually confirmed an hypothesis\nH and the ahistorical measure of how much a piece of evidence\nE would support an hypothesis H, on given background\ninformation B.  The second measure enables us to ask the\nahistorical question of how much E would support H\nif we had no other evidence supporting H.  \n\nC. The problem of rigid conditional probabilities.\nWhen one conditionalizes, one applies the initial conditional\nprobabilities to determine final unconditional probabilities.\nThroughout, the conditional probabilities themselves do not change;\nthey remain rigid. Examples of the Problem of Old Evidence are but\none of a variety of cases in which it seems that it can be rational\nto change one's initial conditional probabilities. Thus, many\nBayesians reject the Simple Principle of Conditionalization in favor\nof a qualified principle, limited to situations in which one does not\nchange one's initial conditional probabilities. There is no\ngenerally accepted account of when it is rational to maintain rigid\ninitial conditional probabilities and when it is not. \n\nD. The problem of prediction vs. accommodation.\nRelated to the problem of Old Evidence is the following potential\nproblem: Consider two different scenarios. In the first, theory\nH was developed in part to accommodate (i.e., to\nimply) some previously known evidence E. In the second, theory\nH was developed at a time when E was not known. It\nwas because E was derived as a prediction from\nH that a test was performed and E was found to be\ntrue. It seems that E's being true would provide a greater degree of\nconfirmation for H if the truth of E had been\npredicted by H than if H had been developed\nto accommodate the truth of E. There is no general\nagreement among Bayesians about how to resolve this problem. Some\n(e.g., Horwich) argue that Bayesianism implies that there is no\nimportant difference between prediction and accommodation, and try to\ndefend that implication. Others (e.g., Maher) argue that there is a\nway to understand Bayesianism so as to explain why there is an\nimportant difference between prediction and accommodation.  \n\nE. The problem of new theories. Suppose that there is\none theory H1 that is generally regarded as highly\nconfirmed by the available evidence E. It is possible that\nsimply the introduction of an alternative theory\nH2 can lead to an erosion of\nH1's support. It is plausible to think that\nCopernicus' introduction of the heliocentric hypothesis had this\neffect on the previously unchallenged Ptolemaic earth-centered\nastronomy. This sort of change cannot be explained by\nconditionalization. It is for this reason that many Bayesians prefer\nto focus on probability ratios of hypotheses (see the Ratio Formula\nabove), rather than their absolute probability; but it is clear that\nthe introduction of a new theory could also alter the probability\nratio of two hypotheses — for example, if it implied one of them\nas a special case. \n\nF. The problem of the priors. Are there constraints\non prior probabilities other than the probability laws?  This is the\nissue that divides the Subjective from the Objective Bayesians, as\ndiscussed above.  Consider Goodman's “new riddle of\ninduction”: In the past all observed emeralds have been\ngreen. Do those observations provide any more support for the\ngeneralization that all emeralds are green than they do for the\ngeneralization that all emeralds are grue (green if observed before\nnow; blue if observed later); or do they provide any more support for\nthe prediction that the next emerald observed will be green than for\nthe prediction that the next emerald observed will be grue (i.e.,\nblue)?  Almost everyone agrees that it would be irrational to have\nprior probabilities that were indifferent between green and grue, and\nthus made predictions of greenness no more probable than predictions of\ngrueness.  But there is no generally agreed upon explanation of this\nconstraint. \n\nThe problem of the priors identifies an important issue between the\nSubjective and Objective Bayesians.  If the constraints on rational\ninference are so weak as to permit any or almost any probabilistically\ncoherent prior probabilities, then there would be nothing to make\ninferences in the sciences any more rational than inferences in\nastrology or phrenology or in the conspiracy reasoning of a paranoid\nschizophrenic, because all of them can be reconstructed as inferences\nfrom probabilistically coherent prior probabilities.  Some Subjective\nBayesians believe that their position is not objectionably subjective,\nbecause of results (e.g., Doob or Gaifman and Snir) proving that even\nsubjects beginning with very different prior probabilities will tend\nto converge in their final probabilities, given a suitably long series\nof shared observations. These convergence results are not completely\nreassuring, however, because they only apply to agents who already\nhave significant agreement in their priors and they do not assure\nconvergence in any reasonable amount of time. Also, they typically\nonly guarantee convergence on the probability of predictions, not on\nthe probability of theoretical hypotheses. For example, Carnap favored\nprior probabilities that would never raise above zero the probability\nof a generalization over a potentially infinite number of instances\n(e.g., that all crows are black), no matter how many observations of\npositive instances (e.g., black crows) one might make without finding\nany negative instances (i.e., non-black crows). In addition, the\nconvergence results depend on the assumption that the only changes in\nprobabilities that occur are those that are the non-inferential\nresults of observation on evidential statements and those that result\nfrom conditionalization on such evidential statements.  But almost all\nsubjectivists allow that it can sometimes be rational to change one's\nprior probability assignments. \n\nBecause there is no generally agreed upon solution to the Problem of\nthe Priors, it is an open question whether Bayesian Confirmation\nTheory has inductive content, or whether it merely translates the\nframework for rational belief provided by deductive logic into a\ncorresponding framework for rational degrees of belief. \n\nOther principles of Bayesian epistemology have been proposed, but\nnone has garnered anywhere near a majority of support among\nBayesians.  The most important proposals are merely mentioned\nhere. It is beyond the scope of this entry to discuss them in any\ndetail. \n\nA. Other principles of synchronic coherence. Are the\nprobability laws the only standards of synchronic coherence for\ndegrees of belief?  Van Fraassen has proposed an additional principle\n(Reflection or Special Reflection), which he now regards as a special\ncase of an even more general principle (General\n Reflection).[3] \n\nB. Other probabilistic rules of inference. There seem\nto be at least two different concepts of probability: the probability\nthat is involved in degrees of belief (epistemic or subjective\nprobability) and the probability that is involved in random events,\nsuch as the tossing of a coin (chance). De Finetti thought this was a\nmistake and that there was only one kind of probability, subjective\nprobability. For Bayesians who believe in both kinds of probability,\nan important question is: What is (or should be) the relation between\nthem?  The answer can be found in the various proposals for principles\nof direct inference in the literature.  Typically, principles of\ndirect inference are proposed as principles for inferring subjective\nor epistemic probabilities from beliefs about objective chance (e.g.,\nPollock).  Lewis reverses the direction of inference, and proposes to\ninfer beliefs about objective chance from subjective or epistemic\nprobabilities, via his (Reformulated) Principal\n Principle.[4]\n Strevens argues that it is Lewis's Principal Principle that gives\nBayesianism its inductive content. \n\nC. Principles of rational acceptance. What is the\nrelation between beliefs and degrees of belief?  Jeffrey proposes to\ngive up the notion of belief (at least for empirical statements) and\nmake do with only degrees of belief.  Other authors (e.g., Levi,\nMaher, Kaplan) propose principles of rational acceptance as part of\naccounts of when it is rational to accept a statement as true, not\nmerely to regard it as probable."}]
