[{"date.published":"2014-03-19","date.changed":"2018-08-09","url":"https://plato.stanford.edu/entries/experimental-moral/","author1":"Mark Alfano","author2":"Don Loeb","author1.info":"http://www.tbm.tudelft.nl/en/about-faculty/departments/values-technology-and-innovation/sections/ethicsphilosophy-of-technology/staff/mark-alfano/","entry":"experimental-moral","body.text":"\n\n\n\nExperimental moral philosophy emerged as a methodology in the last\ndecade of the twentieth century, as a branch of the larger experimental\nphilosophy (X-Phi) approach.  Experimental moral philosophy is the empirical study of moral intuitions, judgments, and behaviors.  Like other forms of experimental philosophy, it involves gathering data using experimental methods and using these data to substantiate, undermine, or revise philosophical theories.  In this case, the theories in question concern the nature of moral reasoning and judgment; the extent and sources of moral obligations; the nature of a good person and a good life; even the scope and nature of moral theory itself.  This entry begins with a brief look at the historical uses of empirical data in moral theory and goes on to ask what, if anything, is distinctive about experimental moral philosophy—how should we distinguish it from related work in empirical moral psychology?  After discussing some strategies for answering this question, the entry examines two of the main projects within experimental moral philosophy, and then discusses some of the most prominent areas of reseatch within the field.  As we will see, in some cases experimental moral philosophy has opened up new avenues of investigation, while in other cases it has influenced longstanding debates within moral theory. \n\n\nThe idea that our actual moral judgments are an important source of\ninformation about the origins and justification of moral norms goes\nback to ancient Greece, if not further. Herodotus recounts a story in\nwhich the Persian emperor Darius invited Greek members of his court\n“and asked them what price would persuade them to eat the dead\nbodies of their fathers. They answered that there was no price for\nwhich they would do it.” Darius then summoned members of a\ndifferent group, “and asked them… what would make them\nwilling to burn their fathers at death. The Indians cried aloud, that\nhe should not speak of so horrid an act.” Herodotus concludes\nthat stories like these prove that, as the poet Pindar writes,\n“custom is king of all,” thereby providing an instance of\nthe argument from moral disagreement for relativism. Likewise, in\nthe Outlines of Skepticism, Sextus Empiricus stresses that\nempirical discoveries can destabilize our confidence in universal\nmoral agreement:\n\n\n \nWhile the use of empirical observation in moral theory has a long\nhistory, the contemporary movement known as experimental philosophy\ngoes back only a few decades. The current experimental philosophy\nmovement owes its beginnings to the work of Stephen Stich and Jonathan\nWeinberg (2001) and Joshua Knobe (2003), but the earliest instance of\nexperimental philosophy may be Truth as Conceived by Those Who Are\nNot Professional Philosophers (Naess 1938), which surveyed\nordinary speakers for their intuitions about the nature of\ntruth. Contemporary philosophers have not been uniformly accepting of\nthe movement, but as we will see, there are reasons to think that\nexperimental evidence might have a distinctive role, significance, and\nimportance in moral philosophy and theorizing. \nThe relationship between more traditional philosophy and experimental\nwork is instructive and brings out some tensions within moral\nphilosophy and theory: namely, morality is at once practical and\nnormative, and these two aspects inform and constrain the extent to\nwhich it is accountable to human psychology.\n\n \n\nInsofar as morality is practical, it should be accessible to and\nattainable by agents like us: if a theory is too demanding, or relies\non intuitions, judgments, motivations, or capacities that people do\nnot (or, worse, cannot) possess, we might on those grounds dismiss\nit. On the other hand, morality is also normative: it aims not just to\ndescribe what we actually do or think, but to guide our practice. For\nthis reason, some philosophers have responded to experimental results\nclaiming to show that attaining and reliably expressing virtues in a\nwide variety of situations is difficult (see section 3.1 below for a\ndiscussion of this literature) by pointing out that the fact that\npeople do not always make the right judgment, or perform actions for\nthe right reasons, does not falsify a theory—it simply shows\nthat people often act in ways that are morally deficient. We will\nreturn to these issues when we discuss criticisms of experimental\nmoral philosophy at the end of this entry; for now, we mention them to\nillustrate that the extent to which experimental moral philosophy\nchallenges traditional philosophical approaches is itself a\ncontroversial issue. Some moral philosophers see themselves as\nderiving moral principles a priori, without appeal to contingent facts\nabout human psychology. Others see themselves as working within a\ntradition, going back at least as far as Aristotle, that conceives of\nethics as the study of human flourishing. These philosophers have not\nnecessarily embraced experimental moral philosophy, but many\npractitioners envision their projects as outgrowths of the\nnaturalistic moral theories developed by Aristotle, Hume, and others.\n\n \n\nAs the examples discussed above reveal, a variety of types of\nempirical evidence are useful to moral theorizing (see also the\nentries on empirical moral psychology, empirical distributive justice,\nand empirical psychology and character). Anthropological observation\nand data have long played a role in moral philosophy. The\ntwentieth-century moral philosophers John Ladd and Richard Brandt\ninvestigated moral relativism in part by conducting their own\nethnographies in Native American communities. Brandt writes, “We\nhave… a question affecting the truth of ethical relativism\nwhich, conceivably, anthropology can help us settle. Does ethnological\nevidence support the view that “qualified persons” can\ndisagree in ethical attitude?” But, he notes, “some kinds\nof anthropological material will not help us—in particular, bare\ninformation about intercultural differences in ethical opinion or\nattitude.” (1952: 238). This is a caveat frequently cited by\nphilosophers engaged in empirical research: it is important to have\nphilosophers participate in experimental design and the gathering of\nempirical data, because there are certain questions that must be\naddressed for the data to have philosophical applications—in\nthis case, whether moral disagreements involve different factual\nbeliefs or other non-moral differences. Barry Hallen (1986, 2000)\nconducted a series of interviews and ethnographies among the Yoruba,\ninvestigating central evaluative concepts and language relating to\nepistemology, aesthetics, and moral value. Hallen was motivated by\nquestions about the indeterminacy of translation, but his work\nprovides an example of how in-depth interviews can inform\ninvestigations of philosophical concepts.  \n\nThese examples show that ethnography has a valuable role to play in\nphilosophical theory, but the remainder of this entry will focus\nprimarily on experiments. Paradigmatic experiments involve randomized\nassignment to varying conditions of objects or people from a\nrepresentative sample, followed by statistical comparison of the\noutcomes for each condition. The variation in conditions is sometimes\ncalled a manipulation. For example, an experimenter might try to\nselect a representative sample of people, randomly assign them either\nto find or not to find a dime in the coin return of a pay phone, and\nthen measure the degree to which they subsequently help someone they\ntake to be in need (Isen and Levin 1972). Finding or not finding the\ndime is the condition; degree of helpfulness is the outcome variable.\n\n \n\nWhile true experiments follow this procedure, other types of studies\nallow non-random assignment to conditions. Astronomers, for example,\nsometimes speak of natural experiments. Although we are in no position\nto affect the motions of heavenly bodies, we can observe them under a\nvariety of conditions, over long periods of time, and with a variety\nof instruments. Likewise, anthropological investigation of different\ncultures’ moral beliefs and practices is unlikely to involve\nmanipulating variables in the lives of the members of the culture, but\nsuch studies are valuable and empirically respectable. Still, such\nstudies can at best demonstrate correlation, not causation, so their\nevidential value of studies is less than that of experiments; most\npublished research in experimental philosophy involves true\nexperiments.\n\n \n\nEven within the category of experiments, we find a lot of diversity\nwith respect to inputs, methods of measurement, and outputs. The\nexperiment just described uses a behavioral measure and\nmanipulation—finding the dime is the input, helping is the\noutcome measured. Other experiments measure not behavior but judgment\nor intuition, and this can be done using a survey or other form of\nself–report or informant–report where subjects respond\nexplicitly to some question, situation, or dilemma. Studies measuring\njudgments might use either manipulations of the condition in which the\nsubject makes the judgment, or they might look for correlations\nbetween judgments and some other factor, such as brain activity,\nemotional response, reaction time, visual attention, and so on\n(Strohminger et al. 2014).\n\n \n\nThe experimental methods available have also changed over\ntime. Surveys have been the dominant method of experimental philosophy\nfor the past few decades, but technology may change this: advances in\nvirtual and augmented reality mean that philosophers can now immerse\npeople in moral dilemmas such as Thompson’s (1971) violinist\nthought experiment and different versions of the trolley\nproblem. Philosophers interested in the neural correlates of moral\njudgment can use transcranial magnetic stimulation (TMS) to\ninvestigate the effects of enhancing or lessening activity in certain\nareas of the brain. Even survey methods have seen advances thanks to\ntechnology; the ubiquity of smartphones allows researchers to ping\npeople in real time, asking for reports on mood (see section 3.2 below\nfor a discussion of surveys relating to happiness and mood).\n\n \n\nWhether experimental moral philosophy has to use true experiments or\ncan include studies and even ethnographies and other forms of\nqualitative data is partly a terminological question about how to\ndefine the field and whether we distinguish it from empirical moral\npsychology, a closely related research program. As we will see below,\nthough, a diversity of both methods and subjects is important in\nhelping experimental moral philosophy respond to its critics.\n\n \n\nLike experimental philosophy more generally, experimental moral\nphilosophy is interested in our intuitions and judgments about\nphilosophical thought experiments and moral dilemmas. But research in\nthis area also concerns the cognitive architecture underlying our\nmoral judgments; the developmental processes that give rise to moral\njudgments; the neuroscience of moral judgment; and other related\nfields.\n\n \n\nDirect experiments investigate whether a claim held (or\ndenied) by philosophers is corroborated or falsified. This might mean\ninvestigating an intuition and whether it is as widely shared as\nphilosophers claim, or it might mean investigating the claim that a\ncertain behavior or trait is widespread or that two factors\ncovary. For example, we find philosophers claiming that it is wrong to\nimprison an innocent person to prevent rioting; that a good life must\nbe authentic; and that moral judgments are intrinsically\nmotivating. Experimental research can be (and has been, as we will see\nbelow) brought to bear on each of these claims.\n\n \n\nIndirect experiments look at the nature of some capacity or\njudgment: for example, whether certain types of moral dilemmas engage\nparticular areas of the brain; how early children develop a capacity\nto empathize; and whether the moral/conventional distinction is\nuniversal across cultures. These claims have philosophical relevance\ninsofar as they help us understand the nature of moral judgment.\n\n \n\nIn addition to distinctions involving the type of data and how\ndirectly it bears on the question, we can also distinguish among\nexperimental applied ethics, experimental normative ethics, and\nexperimental metaethics. The first involves the variables that\ninfluence judgments about particular practical problems, such as how a\nself-driving car should respond to sacrificial dilemmas (Bonnefon,\nSharriff, and Rahwan 2016). The second involves investigations of how\nwe ought to behave, act, and judge, as well as our intuitions about\nmoral responsibility, character, and what constitutes a good life. The\nthird involves debates over moral realism and antirealism. In this\nentry we focus on the latter two.\n\n \n\nIn many of these cases, the line between experimental moral philosophy\nand its neighbors is difficult to draw: what distinguishes\nexperimental moral philosophy from empirical moral psychology? What is\nthe difference between experimental moral philosophy and psychology or\nneuroscience that investigates morality? What is the difference\nbetween experimental moral philosophy and metaethics? We might try to\nanswer these questions by pointing to the training of the\nexperimenters—as philosophers or as scientists—but much of\nthe work in these areas is done by collaborative teams involving both\nphilosophers and social scientists or neuroscientists. In addition,\nsome philosophers work in law and psychology departments, and graduate\nprograms increasingly offer cross-disciplinary training. Another\napproach would be to look at the literature with which the work\nengages: many psychologists (e.g., Haidt, Greene) investigating moral\njudgment situate their arguments within the debate between Kantians\nand Humeans, so engagement with the philosophical tradition might be\nused as a criterion to distinguish experimental moral philosophy from\nexperimental moral psychology. All this said, an inability to sharply\ndistinguish experimental moral philosophy from adjoining areas of\ninvestigation may not be particularly important. Experimental\nphilosophers often point out that the disciplinary divide between\nphilosophy and psychology is a relatively recent phenomenon; early\ntwentieth-century writers such as William James situated themselves in\nboth disciplines, making vital contributions to each. If there is a\nproblem here, it is not unique to experimental moral philosophy. For\nexample, is work on semantics that uses both linguistics and analytic\nphilosophy best understood as linguistics or philosophy of language?\nThese debates arise, and may be largely moot, for many research\nprograms that cut across disciplinary boundaries.\n\n \n\nThe rest of this entry proceeds as follows. Section 2 canvasses\nexperimental research on moral judgments and intuitions, describing\nvarious programmatic uses to which experimental results have been put,\nthen turning to examples of experimental research on moral judgment\nand intuition, including intuitions about intentionality and\nresponsibility, as well as the so-called linguistic analogy. Section 3\ndiscusses experimental results on thick (i.e., simultaneously\ndescriptive and normative) topics, including character and virtue,\nwellbeing, and emotion and affect. Section 4 discusses questions about\nmoral disagreement and moral language, both important sources of\nevidence in the longstanding debate over moral objectivity. Section 5\nconsiders some objections to experimental moral philosophy.\n\n \n\nOne role for experiments in moral philosophy, as indicated above, is\nto investigate our moral intuitions about cases, and to use the\nresults gleaned from such investigations to guide or constrain our\nmoral metaphysics, semantics, or epistemology. Philosophers often rely\non such judgments—in the form of claims to the effect that\n“we would judge x” or, “intuitively,\nx”—as data or evidence for a theory (though see Cappelen\n2012 and Deutsch 2016 for critical discussion of this point). Claims\nabout what we would judge or about the intuitive response to a case\nare empirically testable, and one project in experimental moral\nphilosophy (perhaps the dominant original project) has been to test\nsuch claims via an investigation of our intuitions and related moral\njudgments. In doing so, experimental moral philosophers can accomplish\none of two things: first, they can test the claims of traditional\nphilosophers about what is or is not intuitive; second, they can\ninvestigate the sources of our intuitions and judgments. These tasks\ncan be undertaken as part of a positive program, which uses our\nintuitions and judgments as inputs and constructs theories that\naccommodate and explain them. Alternatively, these tasks can figure in\na negative program, which uses experimental research to undermine\ntraditional appeals to intuition as evidence in moral philosophy and\nconceptual analysis more broadly. The negative program can proceed\ndirectly or indirectly: either via testing and refuting claims about\nintuitions themselves, or by discrediting the sources of those\nintuitions by discovering that they are influenced by factors widely\nregarded as not evidential or unreliable. We discuss both the negative\nprogram and the positive program below.\n\n \n\nEarly work in experimental philosophy suggested cross-cultural\ndifferences in semantic, epistemic, and moral intuitions. For example,\nMachery, Mallon, and Stich (2004) argued that East Asian subjects were\nmore likely to hold descriptivist intuitions than their Western\ncounterparts, who tended to embrace causal theories of\nreference. Haidt (2006) argued that the extent to which people judged\nharmless violations such as eating a deceased pet, or engaging in\nconsensual sibling incest, to be wrong depended on socioeconomic\nstatus. Since, presumably, moral wrongness doesn’t itself depend\non socioeconomic status, gender, or culture of the person making the\nmoral judgment, these results have been marshaled to argue either\nagainst the evidential value of intuitions or against the existence of\nmoral facts altogether.\n\n \n\nNegative experimental moral philosophy generates results that are then\nused to discount the evidential value of appeals to intuition. For\nexample, Walter Sinnott-Armstrong (2008d), Eric Schwitzgebel, Fiery\nCushman (2012), and Peter Singer (2005) have recently followed this\ntrain of thought, arguing that moral intuitions are subject to\nnormatively irrelevant situational influences (e.g., order effects),\nwhile Feltz & Cokely (2009) and Knobe (2011) have documented\ncorrelations between moral intuitions and (presumably) normatively\nirrelevant individual differences (e.g., extroversion). Such results\nmight warrant skepticism about moral intuitions, or at least about\nsome classes of intuitions or\nintuiters.[1] \n\nThe studies just mentioned involve results that suggest that the\ncontent of intuitions varies along some normatively irrelevant\ndimension. Another source of evidence for the negative program draws\non results regarding the cognitive mechanisms underlying or generating\nintuitions themselves. For example, studies that suggest that\ndeontological intuitions are driven by emotional aversions to harming\nothers have been used to argue that we ought to discount our\ndeontological intuitions in favor of consequentialist\nprinciples—an idea discussed in more detail below (see Singer\n2005, Weigman 2017).\n\n \n\nThe distinction between negative and positive experimental moral\nphilosophy is difficult to draw, partly because the negative program\noften discounts particular classes or types of intuitions in favor of\nothers that are supposed to be more reliable. For example, Singer\noffers an anti-deontological argument as part of the negative program\ninsofar as his argument uses the emotional origins of deontological\nintuitions to discount them. But because he then argues for the\nsuperiority of consequentialist intuitions, his position also fits\nwithin the positive program. So the difference between the two\nprograms is not in the data or the kinds of questions investigated,\nbut in how the data are put to use—whether they are seen as\ndebunking traditional philosophical appeals to intuition or as an\naddition to traditional philosophical appeals to intuition, by helping\nphilosophers distinguish between reliable and unreliable intuitions\nand their sources. In the next section, we look at positive uses of\nintuitions as evidence.\n\n \n\nOther philosophers are more sanguine about the upshot of experimental\ninvestigations of moral judgment and intuition. Knobe, for example,\nuses experimental investigations of the determinants of moral\njudgments to identify the contours of philosophically resonant\nconcepts and the mechanisms or processes that underlie moral\njudgment. He has argued for the pervasive influence of moral\nconsiderations throughout folk psychological concepts (2009, 2010; see\nalso Pettit & Knobe 2009), claiming, among other things, that the\nconcept of an intentional action is sensitive to the foreseeable\nevaluative valence of the consequences of that action (2003, 2004b,\n2006).[2] In a\nrecent paper, Knobe (2016) shows that only ten percent of experimental\nphilosophy aims to support or undercut a proposed conceptual analysis;\ninstead, most published papers aim to shed light on the cognitive and\naffective processes underlying the relevant phenomenon.  \n\nAnother line of research is due to Joshua Greene and his colleagues\n(Greene et al. 2001, 2004, 2008; Greene 2008), who investigate the\nneural bases of consequentialist and deontological moral\njudgments. Greene and his colleagues elicited the intuitions of\nsubjects about a variety of trolley problems—cases that present\na dilemma in which a trolley is racing towards five individuals, all\nof whom will be killed unless the trolley is instead diverted towards\none individual—while inside an fMRI scanner. The researchers\nfound that, when given cases in which the trolley is diverted by\npulling a switch, most subjects agreed that diverting the trolley away\nfrom the five and towards the one person was the right action. When,\ninstead, the case involved pushing a person off a bridge to land in\nfront of and halt the trolley, subjects were less likely to judge that\nsacrificing the one person as morally permissible. In addition, Greene\nfound that subjects who did judge it permissible to push the person\ntook longer to arrive at their judgment, suggesting that they had to\novercome conflicting intuitions to do so—a finding bolstered by\nthe fact that when subjects considered pushing the person off the\nbridge, their brains revealed increased activity in areas associated\nwith the aggregation and modulation of value signals (e.g.,\nventromedial prefrontal cortex and dorsolateral prefrontal\ncortex). Greene concludes that our aversion to pushing the person is\ndue to an emotional response to the thought of causing physical harm\nto someone, while our willingness to pull the switch is due to the\nrational calculation that saving five people is preferable to letting\nfive people die to spare one life. Greene and Singer use these\nfindings as a basis for a debunking of deontological intuitions and a\nvindication of consequentialism, since the latter rests on intuitions\nwhich stem from a source we consider both generally reliable and\nappropriately used as the basis for moral reasoning. It should be\nnoted, though, that this argument presupposes that emotional reactions\nare (at least in these cases) necessarily irrational or arational;\nphilosophers who are unsympathetic to such a view of emotions need not\nfollow Greene and Singer to their ultimate conclusions (Railton 2014).\n\n \n\nA related approach aims to identify the features to which intuitions\nabout philosophically important concepts are sensitive. Sripada (2011)\nthinks that the proper role of experimental investigations of moral\nintuitions is not to identify the mechanisms underlying moral\nintuitions. Such knowledge, it is claimed, contributes little of\nrelevance to philosophical theorizing. It is rather to investigate, on\na case by case basis, the features to which people are responding when\nthey have such intuitions. On this view, people (philosophers\nincluded) can readily identify whether they have a given intuition,\nbut not why they have it. An example from the debate over determinism\nand free will: manipulation cases have been thought to undermine\ncompatibilist intuitions—intuition supporting the notion that\ndeterminism is compatible with “the sort of free will required\nfor moral responsibility” (Pereboom 2001). In such cases, an\nunwitting victim is described as having been surreptitiously\nmanipulated into having and reflectively endorsing a motivation to\nperform some action. Critics of compatibilism say that such cases\nsatisfy compatibilist criteria for moral responsibility, and yet,\nintuitively, the actors are not morally responsible (Pereboom\n2001). Sripada (2011) makes a strong case, however, through both\nmediation analysis and structural equation modeling, that to the\nextent that people feel the manipulee not to be morally responsible,\nthey do so because they judge him in fact not to satisfy the\ncompatibilist criteria.[3] Thus, by determining which aspects of the case\nphilosophical intuitions are responding to, it might be possible to\nresolve otherwise intractable questions.  \n\nSince Knobe’s seminal (2003) paper, experimental philosophers\nhave investigated the complex patterns in people’s dispositions\nto make judgments about moral notions (praiseworthiness,\nblameworthiness, responsibility), cognitive attitudes (belief,\nknowledge, remembering), motivational attitudes (desire, favor,\nadvocacy), and character traits (compassion, callousness) in the\ncontext of violations of and conformity to various norms (moral,\nprudential, aesthetic, legal, conventional,\ndescriptive).[4]\nIn Knobe’s original experiment, participants first read a\ndescription of a choice scenario: the protagonist is presented with a\npotential policy (aimed at increasing profits) that would result in a\nside effect (either harming or helping the environment). Next, the\nprotagonist explicitly disavows caring about the side effect, and\nchooses to go ahead with the policy. The policy results as advertised:\nboth the primary and the side effect occur. Participants are asked to\nattribute intentionality or an attitude (or, in the case of later work\nby Robinson et al. 2013, a character trait) to the protagonist. What\nKnobe found was that participants were significantly more inclined to\nindicate that the protagonist had intentionally brought about the side\neffect when it was perceived to be bad (harming the environment) than\nwhen it was perceived to be good (helping the environment). This\neffect has been replicated dozens of times, and its scope has been\ngreatly expanded from intentionality attributions after violations of\na moral norm to attributions of diverse properties after violations of\na wide variety of norms. \n\nThe first-order aim of interpreters of this body of evidence is to\ncreate a model that predicts when the attribution asymmetry will crop\nup. The second-order aims are to explain as systematically as possible\nwhy the effect occurs, and to determine the extent to which the\nattribution asymmetry can be considered rational. Figure 1, presented\nhere for the first time, models how participants’ responses to\nthis sort of vignette are produced: Figure 1.  Model of Participant\nResponse to Experimental Philosophy Vignettes \n\nIn this model, the boxes represent constructs, the arrows represent\ncausal or functional influences, and the area in grey represents the\nmind of the participant, which is not directly observable but is the\ntarget of investigation. In broad strokes, the idea is that a\nparticipant first reads the text of the vignette and forms a mental\nmodel of what happens in the story. On the basis of this model (and\nalmost certainly while the vignette is still being read), the\nparticipant begins to interpret, i.e., to make both descriptive and\nnormative judgments about the scenario, especially about the mental\nstates and character traits of the people in it. The participant then\nreads the experimenter’s question, forms a mental model of what\nis being asked, and—based on her judgments about the\nscenario—forms an answer to that question. That answer may then\nbe pragmatically revised (to avoid unwanted implications, to bring it\nmore into accord with what the participant thinks the experimenter\nwants to hear, etc.) and is finally recorded as an explicit response\nto a statement about the protagonist’s attitudes (e.g.,\n“he brought about the side effect intentionally,” graded\non a Likert scale.)[5] \n\nA result that has been replicated repeatedly is that, when the\nvignette describes a norm violation, subjects indicate that they agree\nmore strongly that the action violating the norm was performed\nintentionally. While this finding could be used by proponents of the\nnegative program to undermine the conceptual coherence of our notion\nof moral responsibility, experimental moral philosophers working in\nthe positive program have taken up the task of explaining the\nasymmetry by postulating models of unobservable entities that mediate,\nexplain, and perhaps even rationalize the asymmetry. A discussion of\nseveral attempts to do so follows; each offers a different explanation\nof the asymmetry, but all represent vindications or at least\nrehabilitations of our intuitions about intention.\n\n The Conceptual Competence Model \nPerhaps the best known is Knobe’s conceptual competence model,\naccording to which the asymmetry arises at the judgment stage. On this\nview, normative judgments about the action influence otherwise\ndescriptive judgments about whether it was intentional (or desired, or\nexpected, etc.). Moreover, this influence is taken to be part of the\nvery conception of intentionality (desire, belief, etc.). Thus, on the\nconceptual competence model, the asymmetry in attributions is a\nrational expression of the ordinary conception of intentionality\n(desire, belief, etc.), which turns out to have a normative\ncomponent.[6] The Motivational Bias Model \n\nThe motivational bias model (Alicke 2008; Nadelhoffer 2004, 2006)\nagrees that the asymmetry originates in the judgment stage, and that\nnormative judgments influence descriptive judgments. However, unlike\nthe conceptual competence model, it takes this to be a bias rather\nthan an expression of conceptual competence. Thus, on this model, the\nasymmetry in attributions is a distortion of the correct conception of\nintentionality (desire, belief, etc.). The Deep Self Model \n\nThe deep self concordance model (Sripada 2010, 2012; Sripada\n& Konrath 2011) also locates the source of the asymmetry in the\njudgment stage, but does not recognize an influence (licit or illicit)\nof normative judgments on descriptive judgments. Instead, proponents\nof this model claim that when assessing intentional action, people not\nonly attend to their representation of a person’s\n“surface” self—her expectations, means-end beliefs,\nmoment-to-moment intentions, and conditional desires—but also to\ntheir representation of the person’s “deep” self,\nwhich harbors her sentiments, values, and core principles. According\nto this model, when assessing whether someone intentionally brings\nabout some state of affairs, people determine (typically\nunconsciously) whether there exists sufficient concordance between\ntheir representation of the outcome the agent brings about and what\nthey take to be her deep self. For instance, when the chairman says he\ndoes not care at all about either harming or helping the environment,\npeople attribute to him a deeply anti-environment stance. When he\nharms the environment, this is concordant with his anti-environment\ndeep self; in contrast, when the chairman helps the environment, this\nis discordant with his anti-environment deep self. According to the\ndeep self concordance model, then, the asymmetry in attributions is a\nreasonable expression of the folk psychological distinction between\nthe deep and shallow self. The Conversational Pragmatics Model \n\nUnlike the models discussed so far, the conversational pragmatics\nmodel (Adams & Steadman 2004, 2007) locates the source of the\nasymmetry in the pragmatic revision stage. According to this model,\nparticipants judge the protagonist not to have acted intentionally in\nboth norm-conforming and norm-violating cases. However, when it comes\ntime to tell the experimenter what they think, participants do not\nwant to be taken as suggesting that the harm-causing protagonist is\nblameless, so they report that he acted intentionally. This is a\nreasonable goal, so according to the pragmatic revision model, the\nattribution asymmetry is rational, though misleading. The Deliberation Model \n\nAccording to the deliberation model (Alfano, Beebe, & Robinson\n2012; Robinson, Stey, & Alfano 2013; Scaife & Webber 2013),\nthe best explanation of the complex patterns of evidence is that the\nvery first mental stage, the formation of a mental model of the\nscenario, differs between norm-violation and norm-conformity\nvignettes. When the protagonist is told that a policy he would\nordinarily want to pursue violates a norm, he acquires a reason to\ndeliberate further about what to do; in contrast, when the protagonist\nis told that the policy conforms to some norm, he acquires no such\nreason. Participants tend to think of the protagonist as deliberating\nabout what to do when and only when a norm would be violated. Since\ndeliberation leads to the formation of other mental states such as\nbeliefs, desires, and intentions, this basal difference between\nparticipants’ models of what happens in the story flows through\nthe rest of their interpretation and leads to the attribution\nasymmetry. On the deliberation model, then, the attribution asymmetry\noriginates earlier than other experimental philosophers suppose, and\nis due to rational processes. \n\nAnother positive program investigates the structure and form of moral\nintuitions, in addition to their content, with the aim of using these\nfeatures to inform a theory of the cognitive structures underlying\nmoral judgment and their etiology.  \n\nRawls (1971), drawing on Chomsky’s (1965) theory of generative\nlinguistics, suggested that moral cognition might be usefully modeled\non our language faculty, a parallel endorsed by Chomsky himself:\n\n Here Chomsky points to three similarities between the development\nof linguistic knowledge and the development of moral knowledge:  \n\nL1: A child raised in a particular linguistic community almost\ninevitably ends up speaking an idiolect of the local language despite\nlack of sufficient explicit instruction, lack of extensive negative\nfeedback for mistakes, and grammatical mistakes by caretakers. M1: A child raised in a particular moral community almost\ninevitably ends up judging in accordance with an idiolect of the local\nmoral code despite lack of sufficient explicit instruction, lack of\nsufficient negative feedback for moral mistakes, and moral mistakes by\ncaretakers. \n\nL2: While there is great diversity among natural languages, there are\nsystematic constraints on possible natural languages. \n\nM2: While there is great diversity among natural moralities, there are\nsystematic constraints on possible natural moralities. \n\nL3: Language-speakers obey many esoteric rules that they themselves\ntypically cannot articulate or explain, and which some would not even\nrecognize. \n\nM3: Moral agents judge according to esoteric rules (such as the\ndoctrine of double effect) that they themselves typically cannot\narticulate or explain, and which some would not even recognize. \n\nL4: Drawing on a limited vocabulary, a speaker can both produce and\ncomprehend a potential infinity of linguistic expressions. \n\nM4: Drawing on a limited moral vocabulary, an agent can produce and\nevaluate a very large (though perhaps not infinite) class of\naction-plans, which are ripe for moral judgment. \n\nWe will now explain and evaluate each of these pairs of claims in\nturn.\n\n \n\nL1/M1 refer to Chomsky’s poverty of the stimulus\nargument: despite receiving little explicit linguistic and grammatical\ninstruction, children develop language rapidly and at a young age, and\nquickly come to display competence applying complex grammatical\nrules. Similarly, Mikhail and other proponents of the analogy argue\nthat children acquire moral knowledge at a young age based on\nrelatively little explicit instruction. However, critics of the\nanalogy point out several points of difference. First, children\nactually receive quite a bit of explicit moral instruction and\ncorrection, and in contrast with the linguistic case, this often takes\nthe form of explicit statements of moral rules: ‘don’t\nhit,’ ‘share,’ and so on. Secondly, there is debate\nover the age at which children actually display moral competence. Paul\nBloom (2013; see also Blake, McAuliffe, and Warneken 2014) has argued\nthat babies display moral tendencies as early as 3–6 months, but\nothers (most famously Kohlberg (1969) and Piaget (1970); see also\nTuriel (1983) and Nucci (2002)) have argued that children are not\nfully competent with moral judgment until as late as 8–12 years,\nby which time they have received quite a bit of moral instruction,\nboth implicit and explicit. A related point concerns the ability to\nreceive instructions: in the case of language, a child requires some\nlinguistic knowledge or understanding in order even to receive\ninstruction: a child who has no understanding of language will not\nunderstand instructions given to her. But in the moral case, a child\nneed not understand moral rules in order to be instructed in them, so\nthere is less need to posit some innate knowledge or\nunderstanding. Nichols et al. (2016) have conducted a series of\nexperiments using statistical learning and Bayesian modeling to show\nhow children might learn complex rules with scant input. Finally,\nwhile children may initially acquire the moral values present in their\nenvironment, they sometimes change their values or develop their own\nvalues later in life in ways that present spontaneously and with\nlittle conscious effort. This is in marked contrast with language; as\nany second-language learner will recognize, acquiring a new language\nlater in life is effortful and, even if one succeeds in achieving\nfluency, the first language is rarely lost. Lastly, as Prinz (2008)\npoints out, children are punished for moral violations, which may\nexplain why they are quicker to learn moral than grammatical\nrules.  \n\nL2/M2 refer to the existence of so-called linguistic\nuniversals: structures present in all known languages. Whether\nthis is true in the moral case is controversial, for reasons\nwe’ll discuss further below. Prinz (2008) and Sripada (2004)\nhave argued that there are no exceptionless moral universals,\nunless one phrases or describes the norms in question in such a way as\nto render them vacuous. Sripada uses the example ‘murder is\nwrong’ as a vacuous rule: while this might seem like a plausible\ncandidate for a moral universal, when we consider that\n‘murder’ refers to a wrongful act of killing, we can see\nthat the norm is not informative. But Mikhail might respond by\nclaiming that the fact that all cultures recognize a subset of\nintentional killings as morally wrong, even if they differ in how they\ncircumscribe this subset, is itself significant, and the relevant\nanalogy here would be with the existence of categories like\n‘subject’, ‘verb’, and ‘object’ in\nall languages, or with features like recursion, which are present in\nthe grammars of all natural languages.\n\n \n\nL3/M3 refer to the patterns displayed by grammatical and moral\nintuitions. In the case of language, native speakers can recognize\ngrammatical and ungrammatical constructions relatively easily, but\ntypically cannot articulate the rules underlying these intuitions. In\nthe case of moral grammar, the analogy claims, the same is true: we\nproduce moral intuitions effortlessly without being able to explain\nthe rules underlying them. Indeed, in both cases, the rules underlying\nthe judgments might be quite esoteric and difficult for native\nspeakers to learn and understand—as anyone who has taught the\ndoctrine of double effect to introductory students can likely\nattest.  \n\nL4/M4 refer to the fact that we can embed linguistic phrases within\nother linguistic phrases to create novel and increasingly complex\nphrases and sentences. This property is known as recursion,\nand is present in all known natural languages (indeed, in a 2002\npaper, Chomsky suggests that perhaps recursion is the only linguistic\nuniversal; see Hauser, Chomsky, and Fitch 2002). For instance, just as\nphrases can be embedded in other phrases to form more complex\nphrases: \n\nso moral judgments can be embedded in other moral judgments to produce\nnovel moral judgments (Harman 2008, 346). For example: \n\nThe point is twofold: first, we can create complex action\ndescriptions; second, we can evaluate novel and complex actions and\nrespond with relatively automatic intuitions of grammatical or moral\npermissibility. Mikhail (2011: 43–48) uses experimental evidence\nof judgments about trolley problems to argue that our moral judgments\nare generated by imposing a deontic structure on our representation of\nthe causal and evaluative features of the action under\nconsideration. Mikhail points to a variation on the poverty of the\nstimulus argument, which he calls the poverty of the perceptual\nstimulus  (Mikhail 2009: 37): when faced with a particular moral\nsituation, we draw complex inferences about both act and actor based\non relatively little data. Mikhail (2010) uses this argument against\nmodels of moral judgment as affect-driven intuitions:  Unlike the traditional poverty of the stimulus argument, this\nversion does not rely on developmental evidence but on our ability to\nquickly and effortlessly appraise complicated scenarios, such as\nvariations on trolley problems, and then issue normative\njudgments. The postulated intervening step is like the unconscious\nappeal to rules of grammar, and the evidence for such a step must come\nfrom experiments showing that we do, in fact, have such intuitions,\nand that they conform to predictable patterns. \n\nThe linguistic analogy relies on experimental evidence about the\nnature and pattern of our moral intuitions, and it outlines an\nimportant role for experiments in moral theory. If the analogy holds,\nthen an adequate moral theory must be based on the judgments of\ncompetent moral judges, just as grammatical rules are constructed\nbased on the judgments of competent speakers. A pressing task will be\nthe systematic collection of such judgments. The analogy also suggests\na kind of rationalism about moral judgment, since it posits that our\njudgments result from the unconscious application of rules to\ncases. Finally, the analogy has metaethical implications. Just as we\ncan only evaluate grammaticality of utterances relative to a language,\nit may be that we can only evaluate the morality of an action relative\nto a specific moral system. How to individuate moralities, and how\nmany (assuming there are multiple ones) there are, is a question for\nfurther empirical investigation, and here again experimental evidence\nwill play a crucial role. \n\nUntil the 1950s, modern moral philosophy had largely focused on either\nconsequentialism or deontology. The revitalization of virtue ethics\nled to a renewed interest in virtues and vices (e.g., honesty,\ngenerosity, fairness, dishonesty, stinginess, unfairness), in\neudaimonia (often translated as ‘happiness’ or\n‘flourishing’), and in the emotions. In recent\ndecades, experimental work in psychology, sociology, and neuroscience\nhas been brought to bear on the empirical grounding of philosophical\nviews in these areas. \n\nA virtue is a complex disposition comprising sub-dispositions to\nnotice, construe, think, desire, and act in characteristic ways.  To\nbe generous, for instance, is (among other things) to be disposed to\nnotice occasions for giving, to construe ambiguous social cues\ncharitably, to desire to give people things they want, need, or would\nappreciate, to deliberate well about what they want, need, or would\nappreciate, and to act on the basis of such deliberation.\nManifestations of such a disposition are observable and hence ripe for\nempirical investigation. Virtue ethicists of the last several decades\nhave sometimes been optimistic about the distribution of virtue in the\npopulation. Alasdair MacIntyre claims, for example, that\n“without allusion to the place that justice and injustice,\ncourage and cowardice play in human life very little will be genuinely\nexplicable” (1984, 199). Julia Annas (2011, 8–10) claims\nthat “by the time we reflect about virtues, we already have\nsome.” Linda Zagzebski (2010) provides an\n“exemplarist” semantics for virtue terms that only gets\noff the ground if there are in fact many virtuous people. \n\nStarting with Owen Flanagan’s Varieties of Moral\nPersonality (1993), philosophers began to worry that empirical\nresults from social psychology were inconsistent with the structure of\nhuman agency presupposed by virtue theory. In this framework, people\nare conceived as having more or less fixed traits of character that\nsystematically order their perception, cognition, emotion, reasoning,\ndecision-making, and behavior. For example, a generous person is\ninclined to notice and seek out opportunities to give supererogatorily\nto others. The generous person is also inclined to think about what\nwould (and wouldn’t) be appreciated by potential recipients, to\nfeel the urge to give and the glow of satisfaction after giving, to\ndeliberate effectively about when, where, and how to give to whom, to\ncome to firm decisions based on such deliberation, and to follow\nthrough on those decisions once they’ve been made. Other traits\nare meant to fit the same pattern, structuring perception, cognition,\nmotivation, and action of their bearers. Famous results in social\npsychology, such as Darley and Batson’s (1973) Good Samaritan\nexperiment, seem to tell against this view of human moral\nconduct. When someone helps another in need, they may do so simply\nbecause they are not in a rush, rather than because they are\nexpressing a fixed trait like generosity or compassion. \nIn the virtue theoretic framework, people are not necessarily assumed\nto already be virtuous. However, they are assumed to be at least\npotentially responsive to the considerations that a virtuous person\nwould ordinarily notice and take into account. Flanagan (1993),\nfollowed by Doris (1998, 2002), Harman (1999, 2000), and Alfano\n(2013), made trouble for this framework by pointing to social\npsychological evidence suggesting that much of people’s\nthinking, feeling, and acting is instead predicted by (and hence\nresponsive to) situational factors that don’t seem to count as\nreasons at all—not even bad reasons or temptations to\nvice. These include influences such as ambient sensibilia (sounds,\nsmells, light levels, etc.), seemingly trivial and normatively\nirrelevant inducers of positive and negative moods, order of\npresentation of stimuli, and a variety of framing and priming effects,\nmany of which are reviewed in Alfano (2013:\n40–50).[7]\nIt’s worth emphasizing the depth of the problem these studies\npose. It’s not that they suggest that most people aren’t\nvirtuous (although they do suggest that as well). It’s that they\nsuggest that they undermine the entire framework in which people are\nconceived as cognitively sensitive and motivationally responsive to\nreasons. Someone whose failure to act virtuously because they gave in\nto temptation can be understood in the virtue theoretic\nframework. Someone whose failure to act virtuously because\nthey’d just been subliminally primed with physical coldness,\nwhich in turn is metaphorically associated with social coldness, finds\nno place in the virtue theoretic framework. These sorts of effects\npush us to revamp our whole notion of agency and personhood (Doris\n2009).\n \nEarly estimates suggested that individual difference variables\ntypically explain less than 10% of the variance in people’s\nbehavior (Mischel 1968)—though, as Funder & Ozer (1983)\npointed out, situational factors may explain less than\n16%.[8] More\nrecent aggregated evidence indicates that situational factors explain\napproximately twice as much of the variance in human behavior as the\nfive main trait factors (Rauthmann et al. 2014). Convergent evidence\nfrom both lexicographical and survey studies indicates that there are\nat least five dimensions of situations that reliably predict thought,\nfeeling, and behavior: (1) negative valence, (2) adversity, (3) duty,\n(4) complexity, and (5) positive valence (Rauthmann and Sherman 2018).\n \n\nAccording to Doris (2002), the best explanation of this lack of\ncross-situational consistency is that the great majority of people\nhave local rather than global, traits: they are not honest,\ncourageous, or greedy, but they may be honest-while-in-a-good-mood,\ncourageous-while-sailing-in-rough-weather-with-friends, and\ngreedy-unless-watched-by-fellow-parishioners. In contrast, Christian\nMiller (2013, 2014) thinks the evidence is best explained by a theory\nof mixed global traits, such as the disposition to (among other\nthings) help because it improves one’s mood. Such traits are\nglobal, in the sense that they explain and predict behavior across\nsituations (someone with such a disposition will, other things being\nequal, typically help so long as it will maintain her mood), but\nnormatively mixed, in the sense that they are neither virtues nor\nvices. Mark Alfano (2013) goes in a third direction, arguing that\nvirtue and vice attributions tend to function as self-fulfilling\nprophecies. People tend to act in accordance with the traits that are\nattributed to them, whether the traits are minor virtues such as\ntidiness (Miller, Brickman, & Bolen 1975) and ecology-mindedness\n(Cornelissen et al. 2006, 2007), major virtues such as charity (Jensen\n& Moore 1977), cooperativeness (Grusec, Kuczynski, Simutis &\nRushton 1978), and generosity (Grusec & Redler 1980), or vices\nsuch as cutthroat competitiveness (Grusec, Kuczynski, Simutis &\nRushton 1978). On Alfano’s view, when people act in accordance\nwith a virtue, they often do so not because they possess the trait in\nquestion, but because they think they do or because they know that\nother people think they do. He calls such simulations of moral\ncharacter factitious virtues, and even suggests that the\nnotion of a virtue should be revised to include reflexive and social\nexpectations.[9] \n\nIt might seem that the criticisms that motivate these novel approaches\nto virtue miss their mark. After all, virtue ethicists needn’t\n(and often don’t) commit themselves to the claim that almost\neveryone is virtuous. Instead, many argue that virtue is the\nnormative goal of moral development, and that people mostly fail in\nvarious ways to reach that goal. The argument from the fact that most\npeople’s dispositions are not virtues to a rejection of orthodox\nvirtue ethics, then, might be thought a non sequitur, at\nleast for such views. But empirically-minded critics of virtue ethics\ndo not stop there. They all have positive views about what sorts of\ndispositions people have instead of virtues. These\ndispositions are alleged to be so structurally dissimilar from virtues\n(as traditionally understood) that it may be psychologically\nunrealistic to treat (traditional) virtue as a regulative ideal.  What\nmatters, then, is the width of the gap between the descriptive and the\nnormative, between the (structure of the) dispositions most people\nhave and the (structure of the) dispositions that count as\nvirtues. \n\nThree leading defenses against this criticism have been offered. Some\nvirtue ethicists (Kupperman 2009) have conceded that virtue is\nextremely rare, but argued that it may still be a useful regulative\nideal. Others (Hurka 2006, Merritt 2000) have attempted to weaken the\nconcept of virtue in such a way as to enable more people, or at least\nmore behaviors, to count as virtuous. Still others (Kamtekar 2004,\nRussell 2009, Snow 2010, Sreenivasan 2002) have challenged the\nsituationist evidence or its interpretation. While it remains unclear\nwhether these defenses succeed, grappling with the situationist\nchallenge has led both defenders and challengers of virtue ethics to\ndevelop more nuanced and empirically informed\nviews.[10] \n\nPhilosophers have always been interested in what makes a human life go\nwell, but recent decades have seen a dramatic increase in both\npsychological and philosophical research into happiness, well-being,\nand what makes for a good life. It is important to distinguish here\nbetween ‘good life’ in the sense of a life that goes well\nfor the one who lives it, and a morally good life, since\nphilosophers have long debated whether a morally bad person could\nenjoy a good life. The empirical study of wellbeing focuses primarily\non lives that are good in the former sense: good for the person whose\nlife it is. Second, we need to distinguish between a hedonically good\nlife and an overall good life. A life that is hedonically good is one\nthat the subject experiences as pleasant; an overall good life might\nnot contain much pleasure but might be good for other reasons, such as\nwhat it accomplishes. We might decide, after investigation, that an\noverall good life must be a hedonically good life, but the two\nconcepts are distinct. \n\nWith these distinctions in mind, we can see the relevance of\nexperimental evidence to investigations in this area. First and\nperhaps most obviously, experiments can investigate our intuitions\nabout what constitutes a good life, thereby giving us insight into the\nordinary concepts of happiness, well-being, and flourishing. To this\nend, Phillips, Nyholm, & Liao (2014) investigated intuitions about\nthe relationship between morality and happiness. Their results suggest\nthat the ordinary conception of happiness involves both descriptive\nand normative components: specifically, we judge that people are happy\nif they are experiencing positive feelings that they ought to\nexperience. So, to use their examples, a Nazi doctor who gets positive\nfeelings from conducting his experiments is not happy. By contrast, a\nnurse who gets positive feelings from helping sick children is happy,\nthough a nurse who is made miserable by the same actions is not happy.\n\n \n\nAnother set of experimental findings bearing on this question involves\nNozick’s (1974: 44–45) experience machine thought\nexperiment. In response to the hedonist’s claim that pleasure is\nthe only intrinsic good, Nozick asks us to consider the following:\n\n \n\nNozick argues that our response to the experience machine reveals that\nwell-being is not purely subjective: “We learn that something\nmatters to us in addition to experience by imagining an experience\nmachine and then realizing that we would not use it.” DeBrigard\n(2010) reports finding that subjects’ intuitions about the\nexperience were different if they were told they were already in such\na machine, in which case they would not choose to unplug; he explains\nthis in terms of the status quo bias. Weijers (2014) goes further,\nasking subjects about Nozick’s original scenario while also\nasking them to justify their response; he found that many of the\njustifications implied a kind of imaginative resistance to the\nscenario or cited irrelevant factors. He also found that respondents\nwere more likely to say that a ‘plugged in life’ would be\nbetter when they were choosing for someone else, rather than for\nthemselves.\n\n\n \n\nA second type of study involves investigating the causes and\ncorrelates of happiness, well-being, and life-satisfaction. These\nexperiments look at the conditions under which people report positive\naffect or life-satisfaction, as well as the conditions under which\nthey judge that their lives are going well. This is distinct from the\nfirst type of research, since the fact that someone reports an\nexperience as being pleasurable does not necessarily tell us whether\nthey would judge that experience to be pleasurable for someone else;\nthere may be asymmetries in first- and third-person\nevaluations. Furthermore, this type of research can tell us how\nvarious candidates contribute to well-being from a first-person\nperspective, but that doesn’t settle the question of the concept\nof a good life. I might judge that my life is going well, yet fail to\nnotice that I am doing so because I am in a very good mood, and that\nin fact I am not accomplishing any of my goals; if confronted with\nanother person in a similar situation, I might not make the same\njudgment. Which of these judgments best represents our concept of\nwell-being is a tricky question, and a normative one since\nexperimental evidence alone may not settle it. As it turns out,\nexperiments have uncovered a number of factors that influence our own\nreports and assessments of pleasure and well-being. We will discuss\ntwo areas of research in particular: reports of pleasures and pains,\nand judgments of life satisfaction.\n\n \n\nFirst, in the realm of hedonic evaluation, there are marked\ndivergences between the aggregate sums of in-the-moment pleasures and\npains and ex post memories of pleasures and pains. For example, the\nremembered level of pain of a colonoscopy is well-predicted by the\naverage of the worst momentary level of pain and the final level of\npain; furthermore, the duration of the procedure has no measurable\neffect on ex post pain ratings (Redelmeier & Kahneman 1996). What\nthis means is that people’s after-the-fact summaries of their\nhedonic experiences are not simple integrals with respect to time of\nmomentary hedonic tone. If the colonoscopy were functionally completed\nafter minute 5, but arbitrarily prolonged for another 5 minutes so\nthat the final level of pain was less at the end of minute 10 than at\nthe end of minute 5, the patient would retrospectively evaluate the\nexperience as less painful. This complicates accounts of wellbeing in\nterms of pleasure (for example, Bentham’s 1789/1961 hedonism)\ninsofar as it raises the question whether the pleasure being measured\nis pleasure as experienced in the moment, or retrospectively: if, in\nthe very act of aggregating pleasure, we change the way we evaluate\nit, this is a complication for hedonism and for some versions of\nutilitarianism. Since well-being is supposed to be a normative notion\ncapable of guiding both individual actions and social policy, findings\nlike these also call into question what, exactly, we ought to be\nseeking to maximize: pleasurable moments, or the overall retrospective\nevaluation of pleasure.\n\n \n\nSuch findings have led some philosophers to seek out alternatives to\nhedonism in hopes of establishing a more empirically stable\nunderpinning for well-being: in particular, the idea that well-being\nconsists in life satisfaction. The most prominent psychologist in\nthis field is Ed \n  Diener[11] \n whose Satisfaction with Life Scale asks participants to agree or\ndisagree with statements such as, “I am satisfied with my\nlife” and “If I could live my life over, I would change\nalmost nothing.” These questions seem to get at more stable and\nsignificant features of life than hedonic assessments in terms of\npleasure and pain, and one might expect the responses to be more\nconsistent and robust. However, two problems arise. The first is that\nparticipants’ responses to life satisfaction questionnaires may\nnot be accurate reports of standing attitudes. Fox & Kahneman\n(1992), for instance, showed that, especially in personal domains\npeople seem to value (friends and love life), what predicts\nparticipants’ responses is not recent intrapersonal factors but\nsocial comparison. Someone who has just lost a friend but still thinks\nof herself as having more friends than her peers will tend to report\nhigher life satisfaction than someone who has just gained a friend but\nwho still thinks of himself as having fewer friends than his peers.\n \nLife satisfaction surveys also seem to be subject to order\n effects. For instance, if a participant is asked a global life\n satisfaction question and then asked about his romantic life, the\n correlation between these questions tends to be near zero, but if the\n participant is asked the dating question first, the correlation tends\n to be high and positive (Strack, Martin, & Schwarz\n 1988).[12]\n This suggests that life-satisfaction judgments might be unduly\n influenced by the topics and questions considered just before making\n a life-satisfaction judgment. Another example is Schwarz and Clore’s oft-cited 1983 study, in which the authors reported a correlation between weather and life-satisfaction when subjects were asked about weather first, but not when the weather question followed the life-satisfaction query.  We note, however, that there is\n significant controversy about this oft-cited example. Some\n recent papers claim to find a correlation between the two (e.g. Connolly 2013) while others claim there is no\n evidence for an effect of weather on life-satisfaction judgments\n (e.g. Lucas & Lawless 2013). \n\nFindings like the above have led some researchers (e.g., Haybron 2008)\nto argue that life-satisfaction judgments are too arbitrary to ever\nsatisfy the requirements of a theory of well-being. In response,\nTiberius and Plakias (2011) argue for an idealized life-satisfaction\ntheory they call value based life satisfaction, suggesting\nthat by asking subjects to consider their life-satisfaction while\nattending to the domains they most value much of the instability\nplaguing the studies described above is removed, a claim they support\nwith research showing that judgments made after priming subjects to\nthink about their values demonstrate higher levels of retest stability\n(Schimmack & Oishi 2005).\n\n \n\nAs much of the previous discussion reveals, the relationship between\nemotion and moral judgment is one of the central concerns of both\ntraditional and experimental moral philosophy. Our discussion of this\ntopic will focus on two types of research: the role of emotion in\nmoral reasoning generally, and the role of one specific\nemotion—disgust—in moral judgments.\n\n \n\nOne debate concerns whether hot, emotion-driven reasoning is\nnecessarily better or worse than reasoning based only on cooler, more\nreflective thinking—a distinction sometimes referred to using\nKahneman’s terminology of system 1/system 2 thinking. The\nterminology is not perfect, though, because Kahneman’s terms map\nonto a quick, automatic, unconscious system of judgments (system 1)\nand a slow, effortful, deliberative decision-making process (system\n2), and as we saw above, this is not a distinction between emotion and\nreason, since rule-based judgments can be automatic and unconscious\nwhile emotional judgments might be effortful and conscious. The debate\nbetween Mikhail and Haidt is a debate over the extent to which\nemotions rather than rules explain our moral judgments; Singer and\nGreene’s arguments against deontology rest on the claim that\nemotion-backed judgments are less justified than their utilitarian\ncounterparts.\n\n \n\nOne reason for thinking that moral judgments essentially involve some\nemotional component is that they tend to motivate us. Internalism is the view that there is a necessary connection between moral judgment and motivation. This contrasts\nwith externalism, which doesn’t deny that moral\njudgments are usually motivating, but does deny that they are\nnecessarily so, as the link between judgment and motivation is only\ncontingent. Since emotions are intrinsically motivational, showing\nthat moral judgments consist, even in part, of emotions would\nvindicate internalism. One route to this conclusion has involved\nsurveying people’s intuitions about moral judgment. Nichols\n(2002: 289) asked subjects whether an agent who “had no\nemotional reaction to hurting other people” but claims to know\nthat hurting others is wrong really understands that hurting others is\nwrong. He found that most subjects did attribute knowledge in such\ncases, suggesting that the ordinary concept of moral judgment is\nexternalist, a claim that is further supported by Strandberg and\nBjörklund (2013). An additional source of evidence comes from\npsychopaths and patients with traumatic brain injuries, both of whom\nshow evidence of impaired moral functioning—though how one\nregards this evidence depends on which perspective one begins with:\nwhile externalists (Nichols 2002, Roskies 2003) claim that the\nexistence of psychopaths provides a counterexample to the claim that\nmoral judgment is motivating (since psychopaths lack empathy and an\naversion to harming others), internalists (Smith 1994, Maibom 2005,\nKennett and Fine 2008) argue that psychopaths don’t actually\nmake full-fledged moral judgments. Psychologist Robert Hare (1993:\n129) quotes a researcher as saying that, they “know the words\nbut not the music.” Psychopaths also display other cognitive and\naffective deficiencies, as evidenced by their poor decision-making\nskills in other areas. This may mean that they should not be taken as\nevidence against internalism.\n\n \n\nA reason for thinking that moral judgments ought not involve emotion\nis that emotions sometimes seem to lead to judgments that are\ndistorted or off-track, or that seem otherwise unjustified. One\nemotion in particular is often mentioned in this context:\ndisgust. This emotion, which seems to be unique to human animals and\nemerges relatively late in development (from the ages of about\n5–8), involves a characteristic gaping facial expression, a\ntendency to withdraw from the object of disgust, a slight reduction in\nbody temperature and heart rate, and a sense of nausea and the need to\ncleanse oneself. In addition, the disgusted subject is typically\nmotivated to avoid and even expunge the offending object, experiences\nit as contaminating and repugnant, becomes more attuned to other\ndisgusting objects in the immediate environment, and is inclined to\ntreat anything that the object comes in contact with (whether\nphysically or symbolically) as also disgusting. This last\ncharacteristic is often referred to as ‘contamination\npotency’ and it is one of the features that makes disgust so\npotent and, according to its critics, so problematic. The disgust\nreaction can be difficult to repress, is easily recognized, and\nempathically induces disgust in those who do recognize\nit.[13] There\nare certain objects that almost all normal adults are disgusted by\n(feces, decaying corpses, rotting food, spiders, maggots, gross\nphysical deformities). But there is also considerable intercultural\nand interpersonal variation beyond these core objects of disgust,\nwhere the emotion extends into food choices, sexual behaviors,\nout-group members, and violations of social norms. Many studies have\nclaimed to show that disgust is implicated in harsher moral judgments\n(Schnall, Haidt, & Clore 2008), citing experiments in which\nsubjects filling out questionnaires in smelly or dirty rooms evaluated\nmoral transgressions more harshly. Others have gone further and argued\nthat disgust might itself cause or comprise a part of moral judgment\n(Haidt 2001; Wheatley & Haidt 2005). If this is true, critics\nargue, we ought to be wary of those judgments, because disgust has a\ncheckered past in multiple senses. First, it’s historically (and\ncurrently) associated with racism, sexism, homophobia and xenophobia;\nthe language of disgust is often used in campaigns of discrimination\nand even genocide. Secondly, disgust’s evolutionary history\ngives us reason to doubt it. Kelly (2011) argues that the universal\nbodily manifestations of disgust evolved to help humans avoid\ningesting toxins and other harmful substances, while the more\ncognitive or symbolic sense of offensiveness and contamination\nassociated with disgust evolved to help humans avoid diseases and\nparasites. This system is later recruited for an entirely distinct\npurpose: to help mark the boundaries between in-group and out-group,\nand thus to motivate cooperation with in-group members, punishment of\nin-group defectors, and exclusion of out-group members.  \n\nIf Kelly’s account of disgust is on the right track, it seems to\nhave a number of important moral upshots. One consequence, he argues,\nis “disgust skepticism” (139), according to which the\ncombination of disgust’s hair trigger and its ballistic\ntrajectory mean that it is especially prone to incorrigible false\npositives that involve unwarranted feelings of contamination and even\ndehumanization. Hence, “the fact that something is disgusting is\nnot even remotely a reliable indicator of moral foul play” but\nis instead “irrelevant to moral justification” (148).\n\n \n\nIt is important to note that the skeptical considerations Kelly raises\nare specific to disgust and its particular evolutionary history, so\nthey aren’t intended to undermine the role of all emotions in\nmoral judgment. Still, if Kelly is correct, and if disgust is\nimplicated in lots of moral judgments, we may have a reason to be\nskeptical of many of our judgments. Plakias (2011, 2017) argues\nagainst the first half of this antecedent, claiming that Kelly and\nother ‘disgust skeptics’ are wrong to claim that the\npurposes of moral and physical disgust are totally distinct; she\nsuggests that disgust is sometimes a fitting response to moral\nviolations that protects against social contagion. May (2014) argues\nagainst the second half, claiming that disgust’s role in moral\njudgment has been significantly overblown; at most, we have evidence\nthat disgust can, in certain cases, slightly amplify moral judgments\nthat are already in place. However, more recent empirical work\nindicates that incidental disgust has little effect on the harshness\nof moral judgments, though dispositional disgust-sensitivity does\n(Landy and Goodwin 2015).\n\n \n\nMetaethics steps back from moral theorizing to ask about the nature\nand function of morality. While first-order ethics seeks to explain\nwhat we should do, metaethics seeks to explain the status of those\ntheories themselves: what are their metaphysical commitments, and what\nevidence do we have for or against them? Which epistemology best\ncharacterizes our moral practices? What is the correct semantics for\nmoral language? These questions might not seem obviously empirical,\nbut insofar as it attempts to give an account of moral semantics, epistemology, and ontology, metaethics aims, in part, to capture or explain what we do when\nwe engage in moral talk, judgment, and evaluation. To the extent that\nmetaethics sees itself as characterizing our ordinary practice of\nmorality, it is therefore answerable to empirical data about that\npractice. To the extent that a theory claims that we are mistaken or in widespread error about the meaning of moral language, or that we lack justification for our core moral beliefs, this is taken to be a strike against that theory.  For example, relativism is often criticized on the grounds that it requires us to give up the (putatively) widespread belief that moral claims concern objective matters of fact and are true or false independently of our beliefs or attitudes.  We have already seen several ways that experimental data\nbears on theories about moral reasons (the debate between internalists\nand externalists) and the epistemology of moral judgment (the debate\nover the role of intuitions). In this section we will examine\nexperimental contributions to the debate over moral realism, arguments\nabout moral disagreement, and moral language.\n\n \n\nMuch contemporary metaethics relies on assumptions about the nature of\nordinary moral thought, discourse, and practice; metaethicists tend to\nsee their project as essentially conservative. For example, Michael\nSmith writes that the first step in metaethical theorizing is to\n“identify features that are manifest in ordinary moral\npractice” and the second step is to “make sense of a\npractice having these features.” (1994) This assumption has had\na major impact on the debate between realists and anti-realists, with\nrealists claiming to best capture the nature of ordinary moral\ndiscourse: “We begin as (tacit) cognitivists and realists about\nethics,” says Brink (1989), and then “we are led to some\nform of antirealism (if we are) only because we come to regard the\nmoral realist’s commitments as untenable… Moral realism\nshould be our metaethical starting point, and we should give it up\nonly if it does involve unacceptable metaphysical and epistemological\ncommitments.”\n\n \n\nBut experimental work has cast doubt on this claim, beginning with\nDarley and Goodwin (2008), and continued by James Beebe (2014) and\nothers (Wright et al. 2013; Campbell and Kumar 2012; Goodwin and\nDarley 2010; and Sarkissian et al. 2011). Goodwin and Darley asked\nsubjects to rate their agreement with statements drawn from the moral,\nethical, and aesthetic domain, and asked subjects whether they agreed\nwith the statement (for example, “before the 3rd month of\npregnancy, abortion for any reason (of the mother’s) is morally\npermissible,”), whether they thought it represented\na fact or an opinion or attitude, and whether, if\nsomeone were to disagree with them about the statement, at least one\nof the disputants would have to be mistaken. (We will say more about\nthe authors’ use of disagreement as a proxy for realism in the\nfollowing section.) In general, subjects rated moral statements as\nless factual than obviously factual statements (e.g. “the earth\nis at the center of the universe,”) but more factual than\nstatements about matters of taste or etiquette. What is striking about\nthese findings is not just that people are not straightforwardly\nrealist, but that they seem to treat moral questions variably: some\nare treated as matters of fact, others as matters of opinion. This\npattern has been replicated in several studies, and persists even when\nsubjects are allowed to determine for themselves which issues to\nassign to the moral domain, suggesting that subjects do not think\nmoral claims are uniformly objective\n\n \n\nAs we saw at the beginning of this entry, some of the earliest\nthinking in empirically-informed moral philosophy concerns moral\ndisagreement. Brandt and Ladd conducted in-depth investigations into\nthe moral codes of other groups, and some contemporary moral\nphilosophers have argued for continuing attention to the empirical\ndetails of moral disagreement. This is partly due to the influence of\nMackie’s (1977: 36–37) formulation of what he dubbed\n‘the argument from relativity’ in terms of an inference to\nthe best explanation: the best explanation of the nature and\npersistence of moral diversity, Mackie argues, is that our moral\njudgments represent “ways of life,” rather than\n“perceptions, most of them seriously inadequate and badly\ndistorted, of objective moral values.” Realists have tended to\nrespond to the argument by pointing to other possible explanations of\ndisagreement that are consistent with objectivity, such as mistakes\nabout the non-moral facts, irrationality, and failures of impartiality\nand imagination (see for example Brink 1984, Sturgeon 1988, Smith 1994, and\nShafer-Landau 2003; for an overview and analysis of realist responses, see Loeb 1998).\n \n\nHere it is useful to recall Brandt’s admonition that “bare\ninformation about intercultural differences” will not suffice to\nsettle the debate. Because the argument from disagreement turns, in\npart, on both the existence of moral disagreement and the best\nexplanation for it, evaluating the prospects for the argument requires\nattention to the empirical details of actual moral disagreements,\nrather than conjecture about the outcomes of possible moral\ndisagreements. For example, Doris and Plakias (2008) discuss several\ninstances of cross-cultural moral disagreement, and assess the\nprospects for applying what they call ‘defusing\nexplanations’ to these cases. A defusing explanation is one that\naccounts for the disagreement in terms of a non-moral difference or an\nepistemic shortcoming on the part of one or more disputant, thereby\nshowing that it is not, in fact, a moral disagreement. Their argument\nand the experiments they cite are discussed in detail in the entry on\nempirical moral psychology, so we will not discuss them in detail\nhere; for now, we will note that such explanations are difficult to\nassess via survey methods alone. This is why it is especially helpful\nto look to the anthropological record, as Oliver Curry et al. (forthcoming)\ndo in a recent landmark publication. Curry hypothesizes that morality\ncomprises stable, cooperative solutions to recurrent problems that can\nbe modeled as non-zero-sum games. There are a variety of such\nrecurrent problems, and game theory has established a suite of\nanalytical tools for diagnosing and solving them. Curry and his\ncolleagues show that such solutions are always seen as either\nmorally good or morally neutral in societies at various stages of\ndevelopment, from small-band hunter gatherers to industrialized\ndemocracies. This research suggests that philosophers may have greatly\nexaggerated the extent of moral disagreement that actually exists.\n\n \n\nOne reason disagreement is a useful measure of objectivity is that the\nimpossibility of faultless disagreement is taken to be characteristic\nof questions concerning objective matters of fact. That is, while we\nmight concede the possibility of faultless disagreements about matters\nconcerning the deliciousness of foods or the merits of a sports team,\nwhen we disagree over moral issues, we think that there is a correct\nanswer and that therefore at least one disputant is getting things\nwrong (for a discussion of the analogy between food and morality, see Loeb (2003)). To the extent that people judge a disagreement to be faultless,\nwe might think that they are evincing a kind of anti-realism about the\nissue under dispute. This is yet another way disagreement can bear on\nthe realism/antirealism debate. Can experimental evidence involving\ndisagreement tell us anything about the semantics of moral language?\n\n \n\nOne reason to think it can is that the very idea of faultless\ndisagreement strikes some as incoherent. In cases where one individual\nthinks (or says) that pistachio ice cream is delicious and another\nthinks (or says) that it is disgusting, we understand the two parties\nas expressing their own personal preference. To explain the apparent\nfaultlessness of the dispute, we reinterpret their thoughts or\nutterances as expressing something like, “pistachio ice cream is\ndelicious [disgusting] to me.“ Because the two parties\ndo not genuinely contradict one another, we need not say that one of\nthem is mistaken. Faultlessness is therefore supposed to be a point in\nfavor of the moral anti-realist, since it seems to imply that there is\nno single content about which the parties disagree (and about which\none might be mistaken).\n\n \n\nBy contrast, realists claim that their view is better able to capture\nour intuition that there is a genuine disagreement at stake when one\nperson says that stealing is wrong and another says that stealing is\nnot wrong. In these cases, realists argue, we have the intuition that\nthere really is a conflict, and only a theory on which moral language\ninvolves attributing properties to acts and things, rather than\nreporting or expressing speakers’ attitudes, can capture this\nintuition.\n\n \n\nWe have already seen some data bearing on this issue in our discussion\nof folk realism above. The claim here is not about realism per se, but\nabout whether experimental evidence can give us insight into the\nsemantics of moral language, since our intuitions about whether there\nis genuine faultlessness can tell us about whether there is a single\nshared content between two utterances—a single proposition that\none party asserts and another denies—or whether the two\nparties’ utterances contain implicit relativizations. This has,\nat least, been the assumption guiding much of the debate over\ndisagreement and its implication for moral semantics. In recent work,\nhowever, John Khoo and Joshua Knobe (2016) have cast doubt on this\nassumption; their experiments indicate that subjects do not see\ndisagreement as requiring exclusionary content—a single\nproposition that one party accepts and the other rejects. This\nresearch suggests that intuitions about disagreement may not be as\nstraightforwardly tied to moral semantics as philosophers have\nthought: judgments that two individuals genuinely disagree about some\nclaim do not necessarily imply a single shared content between the two\nspeakers. This work is still in early stages, but it reveals the\ncomplications involved in reading semantics off disagreement.\n\n \n\nA further challenge for attempts to experimentally investigate moral\nsemantics is the debate within antirealism between cognitivism and\nnoncognitivism. According to the cognitivist, ordinary moral sentences\nare best understood as factual assertions, expressing propositions\nthat attribute moral properties (such as rightness or goodness) to\nthings (such as actions or characters). Noncognitivists (including\ntheir contemporary representatives, the expressivists) hold that moral\nlanguage has a fundamentally different function, to express attitudes\nor to issue commands, for example. While this debate seems ripe for\nexperimental investigation, the noncognitivist typically acknowledges\nthat their view is a reforming one. Furthermore, the semantics of our\nterms may be opaque to ordinary users, to the extent that we cannot\nread off semantics from intuitions but must investigate them\nindirectly. Lastly, the cognitivist and noncognitivist can agree on a\nnumber of empirical features of moral judgment and discourse; the\nchallenge for experimentalists is to find predictions that confirm one\nview while disconfirming the other. This is a relatively new area of\ninvestigation and, while not without challenges, ripe for exploration.\n\n \n\nExperimental moral philosophy far outstrips what we have been able to\ncover here, and many issues and areas of productive research have\nbarely been touched upon. For example, experimental evidence is\nrelevant to moral questions in bioethics, such as euthanasia,\nabortion, genetic screening, and placebogenic interventions.\nLikewise, experiments in behavioral economics and cognitive psychology\nare being employed in asking moral questions about public policy\n(Bicchieri and Chavez 2010; Bicchieri and Xiao 2009).  We neglect\nthese issues only because of lack of space. In the few words\nremaining, we explore some potential criticisms of experimental\nphilosophy. \n\nAs a young field, experimental philosophy suffers from various\nproblems with experimental design and interpretation. These are not\ninsurmountable problems, and they are problems faced by related\nfields, such as social psychology, cognitive psychology, and\nbehavioral economics. \n\nOne issue that has recently come to the fore is the problem of\n replication.[14] \nStatistical analysis is not deductive inference, and the mere fact that\nstatistical analysis yields a positive result does not guarantee that\nanything has been discovered. Typically, an experimental result is\ntreated as “real” if its \\(p\\)-value is at most .05,\nbut such a value just indicates the probability that the observation in\nquestion would have been made if the null hypothesis were true. \nIt is not the probability that the null hypothesis is false given\nthe\n observation.[15] \nSo, even\nwhen statistical analysis indicates that the null hypothesis is to be\nrejected, that indication can be fallacious. Moreover, when\nmultiple hypotheses are tested, the chance of fallaciously rejecting\nthe null hypothesis at least once rises exponentially. \n\nWe should expect other failures of replication because of a bias built\ninto the system of funding experimentation and publishing results. The\nproportion of published false-positives is much higher for unexpected\nand unpredicted results than for expected and predicted results. Since\nexperimentalists are reluctant to report (and even discouraged by\njournal editors and referees from reporting) null results (i.e.,\nresults where the \\(p\\)-value is more than .05), for every published,\nunexpected result there may be any number of unpublished, unexpected\nnon-results. Thus, unexpected, published results are more likely to be\nfalse positives than they might appear. \n\nThe best way to tell whether such a result carries any evidential\nvalue is for the experiment to be replicated—preferably by\nanother research group. If a result cannot be replicated, it is\nprobably a mirage. Such mirages have turned up to a disturbing extent\nrecently, as Daniel Kahneman has famously pointed out (Yong 2012; see\nalso Wagenmakers et al. 2012). Kahneman proposed a “daisy\nchain” of replication, where no result in psychology would be\npublished until it had been successfully replicated by another\nprominent lab. This proposal has not yet been (and may never be)\ninstituted, but it has raised the problem of replication to salience,\nand a related project has taken off. The reproducibility project in\npsychology aims to establish the extent to which prominent, published\nresults can be replicated.[16] Experimental philosophers have followed suit\nwith their own replication project (see the Other Internet\nResources). This work has recently yielded encouraging fruit: a large\ncollaborative replication effort suggests that approximately 7 out of\n10 experimental philosophy results can be reproduced, whereas similar\nefforts show that less than half of the results in biomedicine,\neconomics, and psychology are replicable (Cova et al. 2018, Other Internet\nResources). \n\nA related issue with experimental design and interpretation has to do\nwith “fishing expeditions.” An experiment is sometimes\npejoratively referred to as a fishing expedition if no specific\npredictions are advanced prior to data collection, especially when\nmultiple hypotheses are tested. Likewise, critics argue that\nresearchers such as Weinberg, Nichols, & Stich (2008) have put\nforward hypotheses that are formulated so vaguely as to make them\nnearly unfalsifiable. This problem is exacerbated when no guiding\npositive heuristic is offered to explain observed patterns. \n\nAnother worry is that simultaneously testing many intuition-probes can\nlead unwary experimenters on snipe hunts. Suppose an experimental\nphilosopher conducts an experiment with two conditions: in the\nexperimental condition, participants are primed with deterministic\nideas, while in the control condition they are not primed one way or\nanother. She asks participants twenty different questions about their\nmoral intuitions, for instance, whether there is free will, whether\nmalefactors deserve to be punished, whether virtue deserves to be\nrewarded, and so on. She then makes pairwise comparisons of their\nresponses to each of the questions in an attempt to figure out whether\ndeterministic priming induces changes in moral intuitions. She thus\nmakes twenty independent comparisons, each at the industry-standard 5%\nlevel. Suppose now for the sake of argument that there is no\neffect—that all null hypotheses are true. In that case, the\nprobability that at least one of these tests will result in a Type I\nerror (rejecting the null hypothesis even though it is true) is\n64%. More generally, when an experimenter performs \\(n\\) independent\ncomparisons at the 5% level, the probability of at least one Type I\nerror is \\(1-.95^n\\). This problem can be addressed by various\nprocedures, most notably the Tukey method and the Bonferroni\nmethod.[17] \n\nOne way to establish that a result is real is to see whether the\nexperiment has a respectable effect size. The most common measure of\neffect size is Cohen’s \\(d\\), which is the ratio of the\ndifference in means between conditions to the standard deviation of\nthe relevant variable. So, for example, a \\(d\\) of 1.0 would indicate\nthat a manipulation moved the mean of the experimental condition an\nentire standard deviation away from the mean of the control condition,\na huge effect. Unfortunately, effect sizes have, until recently,\nrarely been reported in experimental philosophy, though that appears\nto be changing. \n\nOne might object that the real problem with experimental moral\nphilosophy is not with science, but with its relevance (or more\nprecisely, its irrelevance) to moral philosophy. The objection is that\nmoral philosophy is concerned not with how we are and what we do, but\nwith how we ought to be and what we ought to do. As such, it is a\nnormative enterprise, and is unaffected by empirical results. Science\nis hard, but so is morality; if we fail to understand and live up to\nthe demands of the latter, that doesn’t show a problem with our\nmoral theory but with our moral natures.  \n\nExperimental philosophers can agree with this objection, up to a\npoint. No one is suggesting that we read morality directly off survey\nresults. But, to return to the point with which we began, while\nmorality is normative, it is also essentially practical. Moral theory\nis a theory about what we ought to do: a theory about how creatures\nlike us ought to conduct ourselves and interact with one another. A\nmorality completely divorced from our natures, that demanded acts\nimpossible from us, would surely be unacceptable. This is not just a\npoint about experimental philosophy; utilitarianism is sometimes\ncritiqued as making unrealistic demands of impartiality. Alongside the\nfamous proscription against deriving an ought from\nan is, we also find the dictum that ought implies\ncan. The exact extent to which morality can be demanding without\nbeing unrealistic is itself a philosophical question, and so\nexperimental moral philosophy works in conjunction with philosophical\nanalysis; it does not aim to eliminate it. Exactly how the two relate\nto each other, and how empirical evidence will bear on and influence\ndebates in moral theory in the future, is a contested issue, but\nsurely traditional moral theory and experimental moral philosophy have\nmuch to learn from one another.\n\n \n\nWe need to proceed cautiously here. No one doubts that what we ought\nto do depends on how things are non-morally. For example, the moral\nclaim that a given man deserves to be punished presupposes the\nnon-moral fact that he committed the crime. It should come as no\nsurprise, then, that experimental evidence might be relevant in this\nway to morality. Whether experimental evidence is relevant to\ndiscovering the fundamental moral principles—those meant to be\nput into action one way or another depending on how the world is\nnon-morally—is still subject to debate. \n\nAnother version of this argument says that fundamental moral\nphilosophical principles are, if true at all, necessarily true, and\nthat empirical research can establish at best only contingent\ntruths.[18]\nBut if fundamental moral theories are necessary, then they are\nnecessary\nfor creatures like us. And one thing that empirical\ninvestigation can do is to help establish what sorts of creatures we\nare. Imagination needs material to work with. When one sits\nin one’s armchair, imagining a hypothetical scenario, one makes a\nwhole host of assumptions about what people are like, how psychological\nprocesses work, and so on. These assumptions can be empirically\nwell or poorly informed. It’s hard to see why anyone could\ndoubt that being well informed is to be preferred. Likewise\nit’s hard to see how anyone could doubt the relevance of\nexperimental evidence to better grounding our empirical assumptions, in\nthis case our assumptions relevant to moral philosophy. Exactly\nhow experimental—or more broadly, empirical—evidence is\nrelevant, and how relevant it is, are at present hotly contested\nmatters.","contact.mail":"mark.alfano@gmail.com","contact.domain":"gmail.com"},{"date.published":"2014-03-19","date.changed":"2018-08-09","url":"https://plato.stanford.edu/entries/experimental-moral/","author1":"Mark Alfano","author2":"Don Loeb","author1.info":"http://www.tbm.tudelft.nl/en/about-faculty/departments/values-technology-and-innovation/sections/ethicsphilosophy-of-technology/staff/mark-alfano/","entry":"experimental-moral","body.text":"\n\n\n\nExperimental moral philosophy emerged as a methodology in the last\ndecade of the twentieth century, as a branch of the larger experimental\nphilosophy (X-Phi) approach.  Experimental moral philosophy is the empirical study of moral intuitions, judgments, and behaviors.  Like other forms of experimental philosophy, it involves gathering data using experimental methods and using these data to substantiate, undermine, or revise philosophical theories.  In this case, the theories in question concern the nature of moral reasoning and judgment; the extent and sources of moral obligations; the nature of a good person and a good life; even the scope and nature of moral theory itself.  This entry begins with a brief look at the historical uses of empirical data in moral theory and goes on to ask what, if anything, is distinctive about experimental moral philosophy—how should we distinguish it from related work in empirical moral psychology?  After discussing some strategies for answering this question, the entry examines two of the main projects within experimental moral philosophy, and then discusses some of the most prominent areas of reseatch within the field.  As we will see, in some cases experimental moral philosophy has opened up new avenues of investigation, while in other cases it has influenced longstanding debates within moral theory. \n\n\nThe idea that our actual moral judgments are an important source of\ninformation about the origins and justification of moral norms goes\nback to ancient Greece, if not further. Herodotus recounts a story in\nwhich the Persian emperor Darius invited Greek members of his court\n“and asked them what price would persuade them to eat the dead\nbodies of their fathers. They answered that there was no price for\nwhich they would do it.” Darius then summoned members of a\ndifferent group, “and asked them… what would make them\nwilling to burn their fathers at death. The Indians cried aloud, that\nhe should not speak of so horrid an act.” Herodotus concludes\nthat stories like these prove that, as the poet Pindar writes,\n“custom is king of all,” thereby providing an instance of\nthe argument from moral disagreement for relativism. Likewise, in\nthe Outlines of Skepticism, Sextus Empiricus stresses that\nempirical discoveries can destabilize our confidence in universal\nmoral agreement:\n\n\n \nWhile the use of empirical observation in moral theory has a long\nhistory, the contemporary movement known as experimental philosophy\ngoes back only a few decades. The current experimental philosophy\nmovement owes its beginnings to the work of Stephen Stich and Jonathan\nWeinberg (2001) and Joshua Knobe (2003), but the earliest instance of\nexperimental philosophy may be Truth as Conceived by Those Who Are\nNot Professional Philosophers (Naess 1938), which surveyed\nordinary speakers for their intuitions about the nature of\ntruth. Contemporary philosophers have not been uniformly accepting of\nthe movement, but as we will see, there are reasons to think that\nexperimental evidence might have a distinctive role, significance, and\nimportance in moral philosophy and theorizing. \nThe relationship between more traditional philosophy and experimental\nwork is instructive and brings out some tensions within moral\nphilosophy and theory: namely, morality is at once practical and\nnormative, and these two aspects inform and constrain the extent to\nwhich it is accountable to human psychology.\n\n \n\nInsofar as morality is practical, it should be accessible to and\nattainable by agents like us: if a theory is too demanding, or relies\non intuitions, judgments, motivations, or capacities that people do\nnot (or, worse, cannot) possess, we might on those grounds dismiss\nit. On the other hand, morality is also normative: it aims not just to\ndescribe what we actually do or think, but to guide our practice. For\nthis reason, some philosophers have responded to experimental results\nclaiming to show that attaining and reliably expressing virtues in a\nwide variety of situations is difficult (see section 3.1 below for a\ndiscussion of this literature) by pointing out that the fact that\npeople do not always make the right judgment, or perform actions for\nthe right reasons, does not falsify a theory—it simply shows\nthat people often act in ways that are morally deficient. We will\nreturn to these issues when we discuss criticisms of experimental\nmoral philosophy at the end of this entry; for now, we mention them to\nillustrate that the extent to which experimental moral philosophy\nchallenges traditional philosophical approaches is itself a\ncontroversial issue. Some moral philosophers see themselves as\nderiving moral principles a priori, without appeal to contingent facts\nabout human psychology. Others see themselves as working within a\ntradition, going back at least as far as Aristotle, that conceives of\nethics as the study of human flourishing. These philosophers have not\nnecessarily embraced experimental moral philosophy, but many\npractitioners envision their projects as outgrowths of the\nnaturalistic moral theories developed by Aristotle, Hume, and others.\n\n \n\nAs the examples discussed above reveal, a variety of types of\nempirical evidence are useful to moral theorizing (see also the\nentries on empirical moral psychology, empirical distributive justice,\nand empirical psychology and character). Anthropological observation\nand data have long played a role in moral philosophy. The\ntwentieth-century moral philosophers John Ladd and Richard Brandt\ninvestigated moral relativism in part by conducting their own\nethnographies in Native American communities. Brandt writes, “We\nhave… a question affecting the truth of ethical relativism\nwhich, conceivably, anthropology can help us settle. Does ethnological\nevidence support the view that “qualified persons” can\ndisagree in ethical attitude?” But, he notes, “some kinds\nof anthropological material will not help us—in particular, bare\ninformation about intercultural differences in ethical opinion or\nattitude.” (1952: 238). This is a caveat frequently cited by\nphilosophers engaged in empirical research: it is important to have\nphilosophers participate in experimental design and the gathering of\nempirical data, because there are certain questions that must be\naddressed for the data to have philosophical applications—in\nthis case, whether moral disagreements involve different factual\nbeliefs or other non-moral differences. Barry Hallen (1986, 2000)\nconducted a series of interviews and ethnographies among the Yoruba,\ninvestigating central evaluative concepts and language relating to\nepistemology, aesthetics, and moral value. Hallen was motivated by\nquestions about the indeterminacy of translation, but his work\nprovides an example of how in-depth interviews can inform\ninvestigations of philosophical concepts.  \n\nThese examples show that ethnography has a valuable role to play in\nphilosophical theory, but the remainder of this entry will focus\nprimarily on experiments. Paradigmatic experiments involve randomized\nassignment to varying conditions of objects or people from a\nrepresentative sample, followed by statistical comparison of the\noutcomes for each condition. The variation in conditions is sometimes\ncalled a manipulation. For example, an experimenter might try to\nselect a representative sample of people, randomly assign them either\nto find or not to find a dime in the coin return of a pay phone, and\nthen measure the degree to which they subsequently help someone they\ntake to be in need (Isen and Levin 1972). Finding or not finding the\ndime is the condition; degree of helpfulness is the outcome variable.\n\n \n\nWhile true experiments follow this procedure, other types of studies\nallow non-random assignment to conditions. Astronomers, for example,\nsometimes speak of natural experiments. Although we are in no position\nto affect the motions of heavenly bodies, we can observe them under a\nvariety of conditions, over long periods of time, and with a variety\nof instruments. Likewise, anthropological investigation of different\ncultures’ moral beliefs and practices is unlikely to involve\nmanipulating variables in the lives of the members of the culture, but\nsuch studies are valuable and empirically respectable. Still, such\nstudies can at best demonstrate correlation, not causation, so their\nevidential value of studies is less than that of experiments; most\npublished research in experimental philosophy involves true\nexperiments.\n\n \n\nEven within the category of experiments, we find a lot of diversity\nwith respect to inputs, methods of measurement, and outputs. The\nexperiment just described uses a behavioral measure and\nmanipulation—finding the dime is the input, helping is the\noutcome measured. Other experiments measure not behavior but judgment\nor intuition, and this can be done using a survey or other form of\nself–report or informant–report where subjects respond\nexplicitly to some question, situation, or dilemma. Studies measuring\njudgments might use either manipulations of the condition in which the\nsubject makes the judgment, or they might look for correlations\nbetween judgments and some other factor, such as brain activity,\nemotional response, reaction time, visual attention, and so on\n(Strohminger et al. 2014).\n\n \n\nThe experimental methods available have also changed over\ntime. Surveys have been the dominant method of experimental philosophy\nfor the past few decades, but technology may change this: advances in\nvirtual and augmented reality mean that philosophers can now immerse\npeople in moral dilemmas such as Thompson’s (1971) violinist\nthought experiment and different versions of the trolley\nproblem. Philosophers interested in the neural correlates of moral\njudgment can use transcranial magnetic stimulation (TMS) to\ninvestigate the effects of enhancing or lessening activity in certain\nareas of the brain. Even survey methods have seen advances thanks to\ntechnology; the ubiquity of smartphones allows researchers to ping\npeople in real time, asking for reports on mood (see section 3.2 below\nfor a discussion of surveys relating to happiness and mood).\n\n \n\nWhether experimental moral philosophy has to use true experiments or\ncan include studies and even ethnographies and other forms of\nqualitative data is partly a terminological question about how to\ndefine the field and whether we distinguish it from empirical moral\npsychology, a closely related research program. As we will see below,\nthough, a diversity of both methods and subjects is important in\nhelping experimental moral philosophy respond to its critics.\n\n \n\nLike experimental philosophy more generally, experimental moral\nphilosophy is interested in our intuitions and judgments about\nphilosophical thought experiments and moral dilemmas. But research in\nthis area also concerns the cognitive architecture underlying our\nmoral judgments; the developmental processes that give rise to moral\njudgments; the neuroscience of moral judgment; and other related\nfields.\n\n \n\nDirect experiments investigate whether a claim held (or\ndenied) by philosophers is corroborated or falsified. This might mean\ninvestigating an intuition and whether it is as widely shared as\nphilosophers claim, or it might mean investigating the claim that a\ncertain behavior or trait is widespread or that two factors\ncovary. For example, we find philosophers claiming that it is wrong to\nimprison an innocent person to prevent rioting; that a good life must\nbe authentic; and that moral judgments are intrinsically\nmotivating. Experimental research can be (and has been, as we will see\nbelow) brought to bear on each of these claims.\n\n \n\nIndirect experiments look at the nature of some capacity or\njudgment: for example, whether certain types of moral dilemmas engage\nparticular areas of the brain; how early children develop a capacity\nto empathize; and whether the moral/conventional distinction is\nuniversal across cultures. These claims have philosophical relevance\ninsofar as they help us understand the nature of moral judgment.\n\n \n\nIn addition to distinctions involving the type of data and how\ndirectly it bears on the question, we can also distinguish among\nexperimental applied ethics, experimental normative ethics, and\nexperimental metaethics. The first involves the variables that\ninfluence judgments about particular practical problems, such as how a\nself-driving car should respond to sacrificial dilemmas (Bonnefon,\nSharriff, and Rahwan 2016). The second involves investigations of how\nwe ought to behave, act, and judge, as well as our intuitions about\nmoral responsibility, character, and what constitutes a good life. The\nthird involves debates over moral realism and antirealism. In this\nentry we focus on the latter two.\n\n \n\nIn many of these cases, the line between experimental moral philosophy\nand its neighbors is difficult to draw: what distinguishes\nexperimental moral philosophy from empirical moral psychology? What is\nthe difference between experimental moral philosophy and psychology or\nneuroscience that investigates morality? What is the difference\nbetween experimental moral philosophy and metaethics? We might try to\nanswer these questions by pointing to the training of the\nexperimenters—as philosophers or as scientists—but much of\nthe work in these areas is done by collaborative teams involving both\nphilosophers and social scientists or neuroscientists. In addition,\nsome philosophers work in law and psychology departments, and graduate\nprograms increasingly offer cross-disciplinary training. Another\napproach would be to look at the literature with which the work\nengages: many psychologists (e.g., Haidt, Greene) investigating moral\njudgment situate their arguments within the debate between Kantians\nand Humeans, so engagement with the philosophical tradition might be\nused as a criterion to distinguish experimental moral philosophy from\nexperimental moral psychology. All this said, an inability to sharply\ndistinguish experimental moral philosophy from adjoining areas of\ninvestigation may not be particularly important. Experimental\nphilosophers often point out that the disciplinary divide between\nphilosophy and psychology is a relatively recent phenomenon; early\ntwentieth-century writers such as William James situated themselves in\nboth disciplines, making vital contributions to each. If there is a\nproblem here, it is not unique to experimental moral philosophy. For\nexample, is work on semantics that uses both linguistics and analytic\nphilosophy best understood as linguistics or philosophy of language?\nThese debates arise, and may be largely moot, for many research\nprograms that cut across disciplinary boundaries.\n\n \n\nThe rest of this entry proceeds as follows. Section 2 canvasses\nexperimental research on moral judgments and intuitions, describing\nvarious programmatic uses to which experimental results have been put,\nthen turning to examples of experimental research on moral judgment\nand intuition, including intuitions about intentionality and\nresponsibility, as well as the so-called linguistic analogy. Section 3\ndiscusses experimental results on thick (i.e., simultaneously\ndescriptive and normative) topics, including character and virtue,\nwellbeing, and emotion and affect. Section 4 discusses questions about\nmoral disagreement and moral language, both important sources of\nevidence in the longstanding debate over moral objectivity. Section 5\nconsiders some objections to experimental moral philosophy.\n\n \n\nOne role for experiments in moral philosophy, as indicated above, is\nto investigate our moral intuitions about cases, and to use the\nresults gleaned from such investigations to guide or constrain our\nmoral metaphysics, semantics, or epistemology. Philosophers often rely\non such judgments—in the form of claims to the effect that\n“we would judge x” or, “intuitively,\nx”—as data or evidence for a theory (though see Cappelen\n2012 and Deutsch 2016 for critical discussion of this point). Claims\nabout what we would judge or about the intuitive response to a case\nare empirically testable, and one project in experimental moral\nphilosophy (perhaps the dominant original project) has been to test\nsuch claims via an investigation of our intuitions and related moral\njudgments. In doing so, experimental moral philosophers can accomplish\none of two things: first, they can test the claims of traditional\nphilosophers about what is or is not intuitive; second, they can\ninvestigate the sources of our intuitions and judgments. These tasks\ncan be undertaken as part of a positive program, which uses our\nintuitions and judgments as inputs and constructs theories that\naccommodate and explain them. Alternatively, these tasks can figure in\na negative program, which uses experimental research to undermine\ntraditional appeals to intuition as evidence in moral philosophy and\nconceptual analysis more broadly. The negative program can proceed\ndirectly or indirectly: either via testing and refuting claims about\nintuitions themselves, or by discrediting the sources of those\nintuitions by discovering that they are influenced by factors widely\nregarded as not evidential or unreliable. We discuss both the negative\nprogram and the positive program below.\n\n \n\nEarly work in experimental philosophy suggested cross-cultural\ndifferences in semantic, epistemic, and moral intuitions. For example,\nMachery, Mallon, and Stich (2004) argued that East Asian subjects were\nmore likely to hold descriptivist intuitions than their Western\ncounterparts, who tended to embrace causal theories of\nreference. Haidt (2006) argued that the extent to which people judged\nharmless violations such as eating a deceased pet, or engaging in\nconsensual sibling incest, to be wrong depended on socioeconomic\nstatus. Since, presumably, moral wrongness doesn’t itself depend\non socioeconomic status, gender, or culture of the person making the\nmoral judgment, these results have been marshaled to argue either\nagainst the evidential value of intuitions or against the existence of\nmoral facts altogether.\n\n \n\nNegative experimental moral philosophy generates results that are then\nused to discount the evidential value of appeals to intuition. For\nexample, Walter Sinnott-Armstrong (2008d), Eric Schwitzgebel, Fiery\nCushman (2012), and Peter Singer (2005) have recently followed this\ntrain of thought, arguing that moral intuitions are subject to\nnormatively irrelevant situational influences (e.g., order effects),\nwhile Feltz & Cokely (2009) and Knobe (2011) have documented\ncorrelations between moral intuitions and (presumably) normatively\nirrelevant individual differences (e.g., extroversion). Such results\nmight warrant skepticism about moral intuitions, or at least about\nsome classes of intuitions or\nintuiters.[1] \n\nThe studies just mentioned involve results that suggest that the\ncontent of intuitions varies along some normatively irrelevant\ndimension. Another source of evidence for the negative program draws\non results regarding the cognitive mechanisms underlying or generating\nintuitions themselves. For example, studies that suggest that\ndeontological intuitions are driven by emotional aversions to harming\nothers have been used to argue that we ought to discount our\ndeontological intuitions in favor of consequentialist\nprinciples—an idea discussed in more detail below (see Singer\n2005, Weigman 2017).\n\n \n\nThe distinction between negative and positive experimental moral\nphilosophy is difficult to draw, partly because the negative program\noften discounts particular classes or types of intuitions in favor of\nothers that are supposed to be more reliable. For example, Singer\noffers an anti-deontological argument as part of the negative program\ninsofar as his argument uses the emotional origins of deontological\nintuitions to discount them. But because he then argues for the\nsuperiority of consequentialist intuitions, his position also fits\nwithin the positive program. So the difference between the two\nprograms is not in the data or the kinds of questions investigated,\nbut in how the data are put to use—whether they are seen as\ndebunking traditional philosophical appeals to intuition or as an\naddition to traditional philosophical appeals to intuition, by helping\nphilosophers distinguish between reliable and unreliable intuitions\nand their sources. In the next section, we look at positive uses of\nintuitions as evidence.\n\n \n\nOther philosophers are more sanguine about the upshot of experimental\ninvestigations of moral judgment and intuition. Knobe, for example,\nuses experimental investigations of the determinants of moral\njudgments to identify the contours of philosophically resonant\nconcepts and the mechanisms or processes that underlie moral\njudgment. He has argued for the pervasive influence of moral\nconsiderations throughout folk psychological concepts (2009, 2010; see\nalso Pettit & Knobe 2009), claiming, among other things, that the\nconcept of an intentional action is sensitive to the foreseeable\nevaluative valence of the consequences of that action (2003, 2004b,\n2006).[2] In a\nrecent paper, Knobe (2016) shows that only ten percent of experimental\nphilosophy aims to support or undercut a proposed conceptual analysis;\ninstead, most published papers aim to shed light on the cognitive and\naffective processes underlying the relevant phenomenon.  \n\nAnother line of research is due to Joshua Greene and his colleagues\n(Greene et al. 2001, 2004, 2008; Greene 2008), who investigate the\nneural bases of consequentialist and deontological moral\njudgments. Greene and his colleagues elicited the intuitions of\nsubjects about a variety of trolley problems—cases that present\na dilemma in which a trolley is racing towards five individuals, all\nof whom will be killed unless the trolley is instead diverted towards\none individual—while inside an fMRI scanner. The researchers\nfound that, when given cases in which the trolley is diverted by\npulling a switch, most subjects agreed that diverting the trolley away\nfrom the five and towards the one person was the right action. When,\ninstead, the case involved pushing a person off a bridge to land in\nfront of and halt the trolley, subjects were less likely to judge that\nsacrificing the one person as morally permissible. In addition, Greene\nfound that subjects who did judge it permissible to push the person\ntook longer to arrive at their judgment, suggesting that they had to\novercome conflicting intuitions to do so—a finding bolstered by\nthe fact that when subjects considered pushing the person off the\nbridge, their brains revealed increased activity in areas associated\nwith the aggregation and modulation of value signals (e.g.,\nventromedial prefrontal cortex and dorsolateral prefrontal\ncortex). Greene concludes that our aversion to pushing the person is\ndue to an emotional response to the thought of causing physical harm\nto someone, while our willingness to pull the switch is due to the\nrational calculation that saving five people is preferable to letting\nfive people die to spare one life. Greene and Singer use these\nfindings as a basis for a debunking of deontological intuitions and a\nvindication of consequentialism, since the latter rests on intuitions\nwhich stem from a source we consider both generally reliable and\nappropriately used as the basis for moral reasoning. It should be\nnoted, though, that this argument presupposes that emotional reactions\nare (at least in these cases) necessarily irrational or arational;\nphilosophers who are unsympathetic to such a view of emotions need not\nfollow Greene and Singer to their ultimate conclusions (Railton 2014).\n\n \n\nA related approach aims to identify the features to which intuitions\nabout philosophically important concepts are sensitive. Sripada (2011)\nthinks that the proper role of experimental investigations of moral\nintuitions is not to identify the mechanisms underlying moral\nintuitions. Such knowledge, it is claimed, contributes little of\nrelevance to philosophical theorizing. It is rather to investigate, on\na case by case basis, the features to which people are responding when\nthey have such intuitions. On this view, people (philosophers\nincluded) can readily identify whether they have a given intuition,\nbut not why they have it. An example from the debate over determinism\nand free will: manipulation cases have been thought to undermine\ncompatibilist intuitions—intuition supporting the notion that\ndeterminism is compatible with “the sort of free will required\nfor moral responsibility” (Pereboom 2001). In such cases, an\nunwitting victim is described as having been surreptitiously\nmanipulated into having and reflectively endorsing a motivation to\nperform some action. Critics of compatibilism say that such cases\nsatisfy compatibilist criteria for moral responsibility, and yet,\nintuitively, the actors are not morally responsible (Pereboom\n2001). Sripada (2011) makes a strong case, however, through both\nmediation analysis and structural equation modeling, that to the\nextent that people feel the manipulee not to be morally responsible,\nthey do so because they judge him in fact not to satisfy the\ncompatibilist criteria.[3] Thus, by determining which aspects of the case\nphilosophical intuitions are responding to, it might be possible to\nresolve otherwise intractable questions.  \n\nSince Knobe’s seminal (2003) paper, experimental philosophers\nhave investigated the complex patterns in people’s dispositions\nto make judgments about moral notions (praiseworthiness,\nblameworthiness, responsibility), cognitive attitudes (belief,\nknowledge, remembering), motivational attitudes (desire, favor,\nadvocacy), and character traits (compassion, callousness) in the\ncontext of violations of and conformity to various norms (moral,\nprudential, aesthetic, legal, conventional,\ndescriptive).[4]\nIn Knobe’s original experiment, participants first read a\ndescription of a choice scenario: the protagonist is presented with a\npotential policy (aimed at increasing profits) that would result in a\nside effect (either harming or helping the environment). Next, the\nprotagonist explicitly disavows caring about the side effect, and\nchooses to go ahead with the policy. The policy results as advertised:\nboth the primary and the side effect occur. Participants are asked to\nattribute intentionality or an attitude (or, in the case of later work\nby Robinson et al. 2013, a character trait) to the protagonist. What\nKnobe found was that participants were significantly more inclined to\nindicate that the protagonist had intentionally brought about the side\neffect when it was perceived to be bad (harming the environment) than\nwhen it was perceived to be good (helping the environment). This\neffect has been replicated dozens of times, and its scope has been\ngreatly expanded from intentionality attributions after violations of\na moral norm to attributions of diverse properties after violations of\na wide variety of norms. \n\nThe first-order aim of interpreters of this body of evidence is to\ncreate a model that predicts when the attribution asymmetry will crop\nup. The second-order aims are to explain as systematically as possible\nwhy the effect occurs, and to determine the extent to which the\nattribution asymmetry can be considered rational. Figure 1, presented\nhere for the first time, models how participants’ responses to\nthis sort of vignette are produced: Figure 1.  Model of Participant\nResponse to Experimental Philosophy Vignettes \n\nIn this model, the boxes represent constructs, the arrows represent\ncausal or functional influences, and the area in grey represents the\nmind of the participant, which is not directly observable but is the\ntarget of investigation. In broad strokes, the idea is that a\nparticipant first reads the text of the vignette and forms a mental\nmodel of what happens in the story. On the basis of this model (and\nalmost certainly while the vignette is still being read), the\nparticipant begins to interpret, i.e., to make both descriptive and\nnormative judgments about the scenario, especially about the mental\nstates and character traits of the people in it. The participant then\nreads the experimenter’s question, forms a mental model of what\nis being asked, and—based on her judgments about the\nscenario—forms an answer to that question. That answer may then\nbe pragmatically revised (to avoid unwanted implications, to bring it\nmore into accord with what the participant thinks the experimenter\nwants to hear, etc.) and is finally recorded as an explicit response\nto a statement about the protagonist’s attitudes (e.g.,\n“he brought about the side effect intentionally,” graded\non a Likert scale.)[5] \n\nA result that has been replicated repeatedly is that, when the\nvignette describes a norm violation, subjects indicate that they agree\nmore strongly that the action violating the norm was performed\nintentionally. While this finding could be used by proponents of the\nnegative program to undermine the conceptual coherence of our notion\nof moral responsibility, experimental moral philosophers working in\nthe positive program have taken up the task of explaining the\nasymmetry by postulating models of unobservable entities that mediate,\nexplain, and perhaps even rationalize the asymmetry. A discussion of\nseveral attempts to do so follows; each offers a different explanation\nof the asymmetry, but all represent vindications or at least\nrehabilitations of our intuitions about intention.\n\n The Conceptual Competence Model \nPerhaps the best known is Knobe’s conceptual competence model,\naccording to which the asymmetry arises at the judgment stage. On this\nview, normative judgments about the action influence otherwise\ndescriptive judgments about whether it was intentional (or desired, or\nexpected, etc.). Moreover, this influence is taken to be part of the\nvery conception of intentionality (desire, belief, etc.). Thus, on the\nconceptual competence model, the asymmetry in attributions is a\nrational expression of the ordinary conception of intentionality\n(desire, belief, etc.), which turns out to have a normative\ncomponent.[6] The Motivational Bias Model \n\nThe motivational bias model (Alicke 2008; Nadelhoffer 2004, 2006)\nagrees that the asymmetry originates in the judgment stage, and that\nnormative judgments influence descriptive judgments. However, unlike\nthe conceptual competence model, it takes this to be a bias rather\nthan an expression of conceptual competence. Thus, on this model, the\nasymmetry in attributions is a distortion of the correct conception of\nintentionality (desire, belief, etc.). The Deep Self Model \n\nThe deep self concordance model (Sripada 2010, 2012; Sripada\n& Konrath 2011) also locates the source of the asymmetry in the\njudgment stage, but does not recognize an influence (licit or illicit)\nof normative judgments on descriptive judgments. Instead, proponents\nof this model claim that when assessing intentional action, people not\nonly attend to their representation of a person’s\n“surface” self—her expectations, means-end beliefs,\nmoment-to-moment intentions, and conditional desires—but also to\ntheir representation of the person’s “deep” self,\nwhich harbors her sentiments, values, and core principles. According\nto this model, when assessing whether someone intentionally brings\nabout some state of affairs, people determine (typically\nunconsciously) whether there exists sufficient concordance between\ntheir representation of the outcome the agent brings about and what\nthey take to be her deep self. For instance, when the chairman says he\ndoes not care at all about either harming or helping the environment,\npeople attribute to him a deeply anti-environment stance. When he\nharms the environment, this is concordant with his anti-environment\ndeep self; in contrast, when the chairman helps the environment, this\nis discordant with his anti-environment deep self. According to the\ndeep self concordance model, then, the asymmetry in attributions is a\nreasonable expression of the folk psychological distinction between\nthe deep and shallow self. The Conversational Pragmatics Model \n\nUnlike the models discussed so far, the conversational pragmatics\nmodel (Adams & Steadman 2004, 2007) locates the source of the\nasymmetry in the pragmatic revision stage. According to this model,\nparticipants judge the protagonist not to have acted intentionally in\nboth norm-conforming and norm-violating cases. However, when it comes\ntime to tell the experimenter what they think, participants do not\nwant to be taken as suggesting that the harm-causing protagonist is\nblameless, so they report that he acted intentionally. This is a\nreasonable goal, so according to the pragmatic revision model, the\nattribution asymmetry is rational, though misleading. The Deliberation Model \n\nAccording to the deliberation model (Alfano, Beebe, & Robinson\n2012; Robinson, Stey, & Alfano 2013; Scaife & Webber 2013),\nthe best explanation of the complex patterns of evidence is that the\nvery first mental stage, the formation of a mental model of the\nscenario, differs between norm-violation and norm-conformity\nvignettes. When the protagonist is told that a policy he would\nordinarily want to pursue violates a norm, he acquires a reason to\ndeliberate further about what to do; in contrast, when the protagonist\nis told that the policy conforms to some norm, he acquires no such\nreason. Participants tend to think of the protagonist as deliberating\nabout what to do when and only when a norm would be violated. Since\ndeliberation leads to the formation of other mental states such as\nbeliefs, desires, and intentions, this basal difference between\nparticipants’ models of what happens in the story flows through\nthe rest of their interpretation and leads to the attribution\nasymmetry. On the deliberation model, then, the attribution asymmetry\noriginates earlier than other experimental philosophers suppose, and\nis due to rational processes. \n\nAnother positive program investigates the structure and form of moral\nintuitions, in addition to their content, with the aim of using these\nfeatures to inform a theory of the cognitive structures underlying\nmoral judgment and their etiology.  \n\nRawls (1971), drawing on Chomsky’s (1965) theory of generative\nlinguistics, suggested that moral cognition might be usefully modeled\non our language faculty, a parallel endorsed by Chomsky himself:\n\n Here Chomsky points to three similarities between the development\nof linguistic knowledge and the development of moral knowledge:  \n\nL1: A child raised in a particular linguistic community almost\ninevitably ends up speaking an idiolect of the local language despite\nlack of sufficient explicit instruction, lack of extensive negative\nfeedback for mistakes, and grammatical mistakes by caretakers. M1: A child raised in a particular moral community almost\ninevitably ends up judging in accordance with an idiolect of the local\nmoral code despite lack of sufficient explicit instruction, lack of\nsufficient negative feedback for moral mistakes, and moral mistakes by\ncaretakers. \n\nL2: While there is great diversity among natural languages, there are\nsystematic constraints on possible natural languages. \n\nM2: While there is great diversity among natural moralities, there are\nsystematic constraints on possible natural moralities. \n\nL3: Language-speakers obey many esoteric rules that they themselves\ntypically cannot articulate or explain, and which some would not even\nrecognize. \n\nM3: Moral agents judge according to esoteric rules (such as the\ndoctrine of double effect) that they themselves typically cannot\narticulate or explain, and which some would not even recognize. \n\nL4: Drawing on a limited vocabulary, a speaker can both produce and\ncomprehend a potential infinity of linguistic expressions. \n\nM4: Drawing on a limited moral vocabulary, an agent can produce and\nevaluate a very large (though perhaps not infinite) class of\naction-plans, which are ripe for moral judgment. \n\nWe will now explain and evaluate each of these pairs of claims in\nturn.\n\n \n\nL1/M1 refer to Chomsky’s poverty of the stimulus\nargument: despite receiving little explicit linguistic and grammatical\ninstruction, children develop language rapidly and at a young age, and\nquickly come to display competence applying complex grammatical\nrules. Similarly, Mikhail and other proponents of the analogy argue\nthat children acquire moral knowledge at a young age based on\nrelatively little explicit instruction. However, critics of the\nanalogy point out several points of difference. First, children\nactually receive quite a bit of explicit moral instruction and\ncorrection, and in contrast with the linguistic case, this often takes\nthe form of explicit statements of moral rules: ‘don’t\nhit,’ ‘share,’ and so on. Secondly, there is debate\nover the age at which children actually display moral competence. Paul\nBloom (2013; see also Blake, McAuliffe, and Warneken 2014) has argued\nthat babies display moral tendencies as early as 3–6 months, but\nothers (most famously Kohlberg (1969) and Piaget (1970); see also\nTuriel (1983) and Nucci (2002)) have argued that children are not\nfully competent with moral judgment until as late as 8–12 years,\nby which time they have received quite a bit of moral instruction,\nboth implicit and explicit. A related point concerns the ability to\nreceive instructions: in the case of language, a child requires some\nlinguistic knowledge or understanding in order even to receive\ninstruction: a child who has no understanding of language will not\nunderstand instructions given to her. But in the moral case, a child\nneed not understand moral rules in order to be instructed in them, so\nthere is less need to posit some innate knowledge or\nunderstanding. Nichols et al. (2016) have conducted a series of\nexperiments using statistical learning and Bayesian modeling to show\nhow children might learn complex rules with scant input. Finally,\nwhile children may initially acquire the moral values present in their\nenvironment, they sometimes change their values or develop their own\nvalues later in life in ways that present spontaneously and with\nlittle conscious effort. This is in marked contrast with language; as\nany second-language learner will recognize, acquiring a new language\nlater in life is effortful and, even if one succeeds in achieving\nfluency, the first language is rarely lost. Lastly, as Prinz (2008)\npoints out, children are punished for moral violations, which may\nexplain why they are quicker to learn moral than grammatical\nrules.  \n\nL2/M2 refer to the existence of so-called linguistic\nuniversals: structures present in all known languages. Whether\nthis is true in the moral case is controversial, for reasons\nwe’ll discuss further below. Prinz (2008) and Sripada (2004)\nhave argued that there are no exceptionless moral universals,\nunless one phrases or describes the norms in question in such a way as\nto render them vacuous. Sripada uses the example ‘murder is\nwrong’ as a vacuous rule: while this might seem like a plausible\ncandidate for a moral universal, when we consider that\n‘murder’ refers to a wrongful act of killing, we can see\nthat the norm is not informative. But Mikhail might respond by\nclaiming that the fact that all cultures recognize a subset of\nintentional killings as morally wrong, even if they differ in how they\ncircumscribe this subset, is itself significant, and the relevant\nanalogy here would be with the existence of categories like\n‘subject’, ‘verb’, and ‘object’ in\nall languages, or with features like recursion, which are present in\nthe grammars of all natural languages.\n\n \n\nL3/M3 refer to the patterns displayed by grammatical and moral\nintuitions. In the case of language, native speakers can recognize\ngrammatical and ungrammatical constructions relatively easily, but\ntypically cannot articulate the rules underlying these intuitions. In\nthe case of moral grammar, the analogy claims, the same is true: we\nproduce moral intuitions effortlessly without being able to explain\nthe rules underlying them. Indeed, in both cases, the rules underlying\nthe judgments might be quite esoteric and difficult for native\nspeakers to learn and understand—as anyone who has taught the\ndoctrine of double effect to introductory students can likely\nattest.  \n\nL4/M4 refer to the fact that we can embed linguistic phrases within\nother linguistic phrases to create novel and increasingly complex\nphrases and sentences. This property is known as recursion,\nand is present in all known natural languages (indeed, in a 2002\npaper, Chomsky suggests that perhaps recursion is the only linguistic\nuniversal; see Hauser, Chomsky, and Fitch 2002). For instance, just as\nphrases can be embedded in other phrases to form more complex\nphrases: \n\nso moral judgments can be embedded in other moral judgments to produce\nnovel moral judgments (Harman 2008, 346). For example: \n\nThe point is twofold: first, we can create complex action\ndescriptions; second, we can evaluate novel and complex actions and\nrespond with relatively automatic intuitions of grammatical or moral\npermissibility. Mikhail (2011: 43–48) uses experimental evidence\nof judgments about trolley problems to argue that our moral judgments\nare generated by imposing a deontic structure on our representation of\nthe causal and evaluative features of the action under\nconsideration. Mikhail points to a variation on the poverty of the\nstimulus argument, which he calls the poverty of the perceptual\nstimulus  (Mikhail 2009: 37): when faced with a particular moral\nsituation, we draw complex inferences about both act and actor based\non relatively little data. Mikhail (2010) uses this argument against\nmodels of moral judgment as affect-driven intuitions:  Unlike the traditional poverty of the stimulus argument, this\nversion does not rely on developmental evidence but on our ability to\nquickly and effortlessly appraise complicated scenarios, such as\nvariations on trolley problems, and then issue normative\njudgments. The postulated intervening step is like the unconscious\nappeal to rules of grammar, and the evidence for such a step must come\nfrom experiments showing that we do, in fact, have such intuitions,\nand that they conform to predictable patterns. \n\nThe linguistic analogy relies on experimental evidence about the\nnature and pattern of our moral intuitions, and it outlines an\nimportant role for experiments in moral theory. If the analogy holds,\nthen an adequate moral theory must be based on the judgments of\ncompetent moral judges, just as grammatical rules are constructed\nbased on the judgments of competent speakers. A pressing task will be\nthe systematic collection of such judgments. The analogy also suggests\na kind of rationalism about moral judgment, since it posits that our\njudgments result from the unconscious application of rules to\ncases. Finally, the analogy has metaethical implications. Just as we\ncan only evaluate grammaticality of utterances relative to a language,\nit may be that we can only evaluate the morality of an action relative\nto a specific moral system. How to individuate moralities, and how\nmany (assuming there are multiple ones) there are, is a question for\nfurther empirical investigation, and here again experimental evidence\nwill play a crucial role. \n\nUntil the 1950s, modern moral philosophy had largely focused on either\nconsequentialism or deontology. The revitalization of virtue ethics\nled to a renewed interest in virtues and vices (e.g., honesty,\ngenerosity, fairness, dishonesty, stinginess, unfairness), in\neudaimonia (often translated as ‘happiness’ or\n‘flourishing’), and in the emotions. In recent\ndecades, experimental work in psychology, sociology, and neuroscience\nhas been brought to bear on the empirical grounding of philosophical\nviews in these areas. \n\nA virtue is a complex disposition comprising sub-dispositions to\nnotice, construe, think, desire, and act in characteristic ways.  To\nbe generous, for instance, is (among other things) to be disposed to\nnotice occasions for giving, to construe ambiguous social cues\ncharitably, to desire to give people things they want, need, or would\nappreciate, to deliberate well about what they want, need, or would\nappreciate, and to act on the basis of such deliberation.\nManifestations of such a disposition are observable and hence ripe for\nempirical investigation. Virtue ethicists of the last several decades\nhave sometimes been optimistic about the distribution of virtue in the\npopulation. Alasdair MacIntyre claims, for example, that\n“without allusion to the place that justice and injustice,\ncourage and cowardice play in human life very little will be genuinely\nexplicable” (1984, 199). Julia Annas (2011, 8–10) claims\nthat “by the time we reflect about virtues, we already have\nsome.” Linda Zagzebski (2010) provides an\n“exemplarist” semantics for virtue terms that only gets\noff the ground if there are in fact many virtuous people. \n\nStarting with Owen Flanagan’s Varieties of Moral\nPersonality (1993), philosophers began to worry that empirical\nresults from social psychology were inconsistent with the structure of\nhuman agency presupposed by virtue theory. In this framework, people\nare conceived as having more or less fixed traits of character that\nsystematically order their perception, cognition, emotion, reasoning,\ndecision-making, and behavior. For example, a generous person is\ninclined to notice and seek out opportunities to give supererogatorily\nto others. The generous person is also inclined to think about what\nwould (and wouldn’t) be appreciated by potential recipients, to\nfeel the urge to give and the glow of satisfaction after giving, to\ndeliberate effectively about when, where, and how to give to whom, to\ncome to firm decisions based on such deliberation, and to follow\nthrough on those decisions once they’ve been made. Other traits\nare meant to fit the same pattern, structuring perception, cognition,\nmotivation, and action of their bearers. Famous results in social\npsychology, such as Darley and Batson’s (1973) Good Samaritan\nexperiment, seem to tell against this view of human moral\nconduct. When someone helps another in need, they may do so simply\nbecause they are not in a rush, rather than because they are\nexpressing a fixed trait like generosity or compassion. \nIn the virtue theoretic framework, people are not necessarily assumed\nto already be virtuous. However, they are assumed to be at least\npotentially responsive to the considerations that a virtuous person\nwould ordinarily notice and take into account. Flanagan (1993),\nfollowed by Doris (1998, 2002), Harman (1999, 2000), and Alfano\n(2013), made trouble for this framework by pointing to social\npsychological evidence suggesting that much of people’s\nthinking, feeling, and acting is instead predicted by (and hence\nresponsive to) situational factors that don’t seem to count as\nreasons at all—not even bad reasons or temptations to\nvice. These include influences such as ambient sensibilia (sounds,\nsmells, light levels, etc.), seemingly trivial and normatively\nirrelevant inducers of positive and negative moods, order of\npresentation of stimuli, and a variety of framing and priming effects,\nmany of which are reviewed in Alfano (2013:\n40–50).[7]\nIt’s worth emphasizing the depth of the problem these studies\npose. It’s not that they suggest that most people aren’t\nvirtuous (although they do suggest that as well). It’s that they\nsuggest that they undermine the entire framework in which people are\nconceived as cognitively sensitive and motivationally responsive to\nreasons. Someone whose failure to act virtuously because they gave in\nto temptation can be understood in the virtue theoretic\nframework. Someone whose failure to act virtuously because\nthey’d just been subliminally primed with physical coldness,\nwhich in turn is metaphorically associated with social coldness, finds\nno place in the virtue theoretic framework. These sorts of effects\npush us to revamp our whole notion of agency and personhood (Doris\n2009).\n \nEarly estimates suggested that individual difference variables\ntypically explain less than 10% of the variance in people’s\nbehavior (Mischel 1968)—though, as Funder & Ozer (1983)\npointed out, situational factors may explain less than\n16%.[8] More\nrecent aggregated evidence indicates that situational factors explain\napproximately twice as much of the variance in human behavior as the\nfive main trait factors (Rauthmann et al. 2014). Convergent evidence\nfrom both lexicographical and survey studies indicates that there are\nat least five dimensions of situations that reliably predict thought,\nfeeling, and behavior: (1) negative valence, (2) adversity, (3) duty,\n(4) complexity, and (5) positive valence (Rauthmann and Sherman 2018).\n \n\nAccording to Doris (2002), the best explanation of this lack of\ncross-situational consistency is that the great majority of people\nhave local rather than global, traits: they are not honest,\ncourageous, or greedy, but they may be honest-while-in-a-good-mood,\ncourageous-while-sailing-in-rough-weather-with-friends, and\ngreedy-unless-watched-by-fellow-parishioners. In contrast, Christian\nMiller (2013, 2014) thinks the evidence is best explained by a theory\nof mixed global traits, such as the disposition to (among other\nthings) help because it improves one’s mood. Such traits are\nglobal, in the sense that they explain and predict behavior across\nsituations (someone with such a disposition will, other things being\nequal, typically help so long as it will maintain her mood), but\nnormatively mixed, in the sense that they are neither virtues nor\nvices. Mark Alfano (2013) goes in a third direction, arguing that\nvirtue and vice attributions tend to function as self-fulfilling\nprophecies. People tend to act in accordance with the traits that are\nattributed to them, whether the traits are minor virtues such as\ntidiness (Miller, Brickman, & Bolen 1975) and ecology-mindedness\n(Cornelissen et al. 2006, 2007), major virtues such as charity (Jensen\n& Moore 1977), cooperativeness (Grusec, Kuczynski, Simutis &\nRushton 1978), and generosity (Grusec & Redler 1980), or vices\nsuch as cutthroat competitiveness (Grusec, Kuczynski, Simutis &\nRushton 1978). On Alfano’s view, when people act in accordance\nwith a virtue, they often do so not because they possess the trait in\nquestion, but because they think they do or because they know that\nother people think they do. He calls such simulations of moral\ncharacter factitious virtues, and even suggests that the\nnotion of a virtue should be revised to include reflexive and social\nexpectations.[9] \n\nIt might seem that the criticisms that motivate these novel approaches\nto virtue miss their mark. After all, virtue ethicists needn’t\n(and often don’t) commit themselves to the claim that almost\neveryone is virtuous. Instead, many argue that virtue is the\nnormative goal of moral development, and that people mostly fail in\nvarious ways to reach that goal. The argument from the fact that most\npeople’s dispositions are not virtues to a rejection of orthodox\nvirtue ethics, then, might be thought a non sequitur, at\nleast for such views. But empirically-minded critics of virtue ethics\ndo not stop there. They all have positive views about what sorts of\ndispositions people have instead of virtues. These\ndispositions are alleged to be so structurally dissimilar from virtues\n(as traditionally understood) that it may be psychologically\nunrealistic to treat (traditional) virtue as a regulative ideal.  What\nmatters, then, is the width of the gap between the descriptive and the\nnormative, between the (structure of the) dispositions most people\nhave and the (structure of the) dispositions that count as\nvirtues. \n\nThree leading defenses against this criticism have been offered. Some\nvirtue ethicists (Kupperman 2009) have conceded that virtue is\nextremely rare, but argued that it may still be a useful regulative\nideal. Others (Hurka 2006, Merritt 2000) have attempted to weaken the\nconcept of virtue in such a way as to enable more people, or at least\nmore behaviors, to count as virtuous. Still others (Kamtekar 2004,\nRussell 2009, Snow 2010, Sreenivasan 2002) have challenged the\nsituationist evidence or its interpretation. While it remains unclear\nwhether these defenses succeed, grappling with the situationist\nchallenge has led both defenders and challengers of virtue ethics to\ndevelop more nuanced and empirically informed\nviews.[10] \n\nPhilosophers have always been interested in what makes a human life go\nwell, but recent decades have seen a dramatic increase in both\npsychological and philosophical research into happiness, well-being,\nand what makes for a good life. It is important to distinguish here\nbetween ‘good life’ in the sense of a life that goes well\nfor the one who lives it, and a morally good life, since\nphilosophers have long debated whether a morally bad person could\nenjoy a good life. The empirical study of wellbeing focuses primarily\non lives that are good in the former sense: good for the person whose\nlife it is. Second, we need to distinguish between a hedonically good\nlife and an overall good life. A life that is hedonically good is one\nthat the subject experiences as pleasant; an overall good life might\nnot contain much pleasure but might be good for other reasons, such as\nwhat it accomplishes. We might decide, after investigation, that an\noverall good life must be a hedonically good life, but the two\nconcepts are distinct. \n\nWith these distinctions in mind, we can see the relevance of\nexperimental evidence to investigations in this area. First and\nperhaps most obviously, experiments can investigate our intuitions\nabout what constitutes a good life, thereby giving us insight into the\nordinary concepts of happiness, well-being, and flourishing. To this\nend, Phillips, Nyholm, & Liao (2014) investigated intuitions about\nthe relationship between morality and happiness. Their results suggest\nthat the ordinary conception of happiness involves both descriptive\nand normative components: specifically, we judge that people are happy\nif they are experiencing positive feelings that they ought to\nexperience. So, to use their examples, a Nazi doctor who gets positive\nfeelings from conducting his experiments is not happy. By contrast, a\nnurse who gets positive feelings from helping sick children is happy,\nthough a nurse who is made miserable by the same actions is not happy.\n\n \n\nAnother set of experimental findings bearing on this question involves\nNozick’s (1974: 44–45) experience machine thought\nexperiment. In response to the hedonist’s claim that pleasure is\nthe only intrinsic good, Nozick asks us to consider the following:\n\n \n\nNozick argues that our response to the experience machine reveals that\nwell-being is not purely subjective: “We learn that something\nmatters to us in addition to experience by imagining an experience\nmachine and then realizing that we would not use it.” DeBrigard\n(2010) reports finding that subjects’ intuitions about the\nexperience were different if they were told they were already in such\na machine, in which case they would not choose to unplug; he explains\nthis in terms of the status quo bias. Weijers (2014) goes further,\nasking subjects about Nozick’s original scenario while also\nasking them to justify their response; he found that many of the\njustifications implied a kind of imaginative resistance to the\nscenario or cited irrelevant factors. He also found that respondents\nwere more likely to say that a ‘plugged in life’ would be\nbetter when they were choosing for someone else, rather than for\nthemselves.\n\n\n \n\nA second type of study involves investigating the causes and\ncorrelates of happiness, well-being, and life-satisfaction. These\nexperiments look at the conditions under which people report positive\naffect or life-satisfaction, as well as the conditions under which\nthey judge that their lives are going well. This is distinct from the\nfirst type of research, since the fact that someone reports an\nexperience as being pleasurable does not necessarily tell us whether\nthey would judge that experience to be pleasurable for someone else;\nthere may be asymmetries in first- and third-person\nevaluations. Furthermore, this type of research can tell us how\nvarious candidates contribute to well-being from a first-person\nperspective, but that doesn’t settle the question of the concept\nof a good life. I might judge that my life is going well, yet fail to\nnotice that I am doing so because I am in a very good mood, and that\nin fact I am not accomplishing any of my goals; if confronted with\nanother person in a similar situation, I might not make the same\njudgment. Which of these judgments best represents our concept of\nwell-being is a tricky question, and a normative one since\nexperimental evidence alone may not settle it. As it turns out,\nexperiments have uncovered a number of factors that influence our own\nreports and assessments of pleasure and well-being. We will discuss\ntwo areas of research in particular: reports of pleasures and pains,\nand judgments of life satisfaction.\n\n \n\nFirst, in the realm of hedonic evaluation, there are marked\ndivergences between the aggregate sums of in-the-moment pleasures and\npains and ex post memories of pleasures and pains. For example, the\nremembered level of pain of a colonoscopy is well-predicted by the\naverage of the worst momentary level of pain and the final level of\npain; furthermore, the duration of the procedure has no measurable\neffect on ex post pain ratings (Redelmeier & Kahneman 1996). What\nthis means is that people’s after-the-fact summaries of their\nhedonic experiences are not simple integrals with respect to time of\nmomentary hedonic tone. If the colonoscopy were functionally completed\nafter minute 5, but arbitrarily prolonged for another 5 minutes so\nthat the final level of pain was less at the end of minute 10 than at\nthe end of minute 5, the patient would retrospectively evaluate the\nexperience as less painful. This complicates accounts of wellbeing in\nterms of pleasure (for example, Bentham’s 1789/1961 hedonism)\ninsofar as it raises the question whether the pleasure being measured\nis pleasure as experienced in the moment, or retrospectively: if, in\nthe very act of aggregating pleasure, we change the way we evaluate\nit, this is a complication for hedonism and for some versions of\nutilitarianism. Since well-being is supposed to be a normative notion\ncapable of guiding both individual actions and social policy, findings\nlike these also call into question what, exactly, we ought to be\nseeking to maximize: pleasurable moments, or the overall retrospective\nevaluation of pleasure.\n\n \n\nSuch findings have led some philosophers to seek out alternatives to\nhedonism in hopes of establishing a more empirically stable\nunderpinning for well-being: in particular, the idea that well-being\nconsists in life satisfaction. The most prominent psychologist in\nthis field is Ed \n  Diener[11] \n whose Satisfaction with Life Scale asks participants to agree or\ndisagree with statements such as, “I am satisfied with my\nlife” and “If I could live my life over, I would change\nalmost nothing.” These questions seem to get at more stable and\nsignificant features of life than hedonic assessments in terms of\npleasure and pain, and one might expect the responses to be more\nconsistent and robust. However, two problems arise. The first is that\nparticipants’ responses to life satisfaction questionnaires may\nnot be accurate reports of standing attitudes. Fox & Kahneman\n(1992), for instance, showed that, especially in personal domains\npeople seem to value (friends and love life), what predicts\nparticipants’ responses is not recent intrapersonal factors but\nsocial comparison. Someone who has just lost a friend but still thinks\nof herself as having more friends than her peers will tend to report\nhigher life satisfaction than someone who has just gained a friend but\nwho still thinks of himself as having fewer friends than his peers.\n \nLife satisfaction surveys also seem to be subject to order\n effects. For instance, if a participant is asked a global life\n satisfaction question and then asked about his romantic life, the\n correlation between these questions tends to be near zero, but if the\n participant is asked the dating question first, the correlation tends\n to be high and positive (Strack, Martin, & Schwarz\n 1988).[12]\n This suggests that life-satisfaction judgments might be unduly\n influenced by the topics and questions considered just before making\n a life-satisfaction judgment. Another example is Schwarz and Clore’s oft-cited 1983 study, in which the authors reported a correlation between weather and life-satisfaction when subjects were asked about weather first, but not when the weather question followed the life-satisfaction query.  We note, however, that there is\n significant controversy about this oft-cited example. Some\n recent papers claim to find a correlation between the two (e.g. Connolly 2013) while others claim there is no\n evidence for an effect of weather on life-satisfaction judgments\n (e.g. Lucas & Lawless 2013). \n\nFindings like the above have led some researchers (e.g., Haybron 2008)\nto argue that life-satisfaction judgments are too arbitrary to ever\nsatisfy the requirements of a theory of well-being. In response,\nTiberius and Plakias (2011) argue for an idealized life-satisfaction\ntheory they call value based life satisfaction, suggesting\nthat by asking subjects to consider their life-satisfaction while\nattending to the domains they most value much of the instability\nplaguing the studies described above is removed, a claim they support\nwith research showing that judgments made after priming subjects to\nthink about their values demonstrate higher levels of retest stability\n(Schimmack & Oishi 2005).\n\n \n\nAs much of the previous discussion reveals, the relationship between\nemotion and moral judgment is one of the central concerns of both\ntraditional and experimental moral philosophy. Our discussion of this\ntopic will focus on two types of research: the role of emotion in\nmoral reasoning generally, and the role of one specific\nemotion—disgust—in moral judgments.\n\n \n\nOne debate concerns whether hot, emotion-driven reasoning is\nnecessarily better or worse than reasoning based only on cooler, more\nreflective thinking—a distinction sometimes referred to using\nKahneman’s terminology of system 1/system 2 thinking. The\nterminology is not perfect, though, because Kahneman’s terms map\nonto a quick, automatic, unconscious system of judgments (system 1)\nand a slow, effortful, deliberative decision-making process (system\n2), and as we saw above, this is not a distinction between emotion and\nreason, since rule-based judgments can be automatic and unconscious\nwhile emotional judgments might be effortful and conscious. The debate\nbetween Mikhail and Haidt is a debate over the extent to which\nemotions rather than rules explain our moral judgments; Singer and\nGreene’s arguments against deontology rest on the claim that\nemotion-backed judgments are less justified than their utilitarian\ncounterparts.\n\n \n\nOne reason for thinking that moral judgments essentially involve some\nemotional component is that they tend to motivate us. Internalism is the view that there is a necessary connection between moral judgment and motivation. This contrasts\nwith externalism, which doesn’t deny that moral\njudgments are usually motivating, but does deny that they are\nnecessarily so, as the link between judgment and motivation is only\ncontingent. Since emotions are intrinsically motivational, showing\nthat moral judgments consist, even in part, of emotions would\nvindicate internalism. One route to this conclusion has involved\nsurveying people’s intuitions about moral judgment. Nichols\n(2002: 289) asked subjects whether an agent who “had no\nemotional reaction to hurting other people” but claims to know\nthat hurting others is wrong really understands that hurting others is\nwrong. He found that most subjects did attribute knowledge in such\ncases, suggesting that the ordinary concept of moral judgment is\nexternalist, a claim that is further supported by Strandberg and\nBjörklund (2013). An additional source of evidence comes from\npsychopaths and patients with traumatic brain injuries, both of whom\nshow evidence of impaired moral functioning—though how one\nregards this evidence depends on which perspective one begins with:\nwhile externalists (Nichols 2002, Roskies 2003) claim that the\nexistence of psychopaths provides a counterexample to the claim that\nmoral judgment is motivating (since psychopaths lack empathy and an\naversion to harming others), internalists (Smith 1994, Maibom 2005,\nKennett and Fine 2008) argue that psychopaths don’t actually\nmake full-fledged moral judgments. Psychologist Robert Hare (1993:\n129) quotes a researcher as saying that, they “know the words\nbut not the music.” Psychopaths also display other cognitive and\naffective deficiencies, as evidenced by their poor decision-making\nskills in other areas. This may mean that they should not be taken as\nevidence against internalism.\n\n \n\nA reason for thinking that moral judgments ought not involve emotion\nis that emotions sometimes seem to lead to judgments that are\ndistorted or off-track, or that seem otherwise unjustified. One\nemotion in particular is often mentioned in this context:\ndisgust. This emotion, which seems to be unique to human animals and\nemerges relatively late in development (from the ages of about\n5–8), involves a characteristic gaping facial expression, a\ntendency to withdraw from the object of disgust, a slight reduction in\nbody temperature and heart rate, and a sense of nausea and the need to\ncleanse oneself. In addition, the disgusted subject is typically\nmotivated to avoid and even expunge the offending object, experiences\nit as contaminating and repugnant, becomes more attuned to other\ndisgusting objects in the immediate environment, and is inclined to\ntreat anything that the object comes in contact with (whether\nphysically or symbolically) as also disgusting. This last\ncharacteristic is often referred to as ‘contamination\npotency’ and it is one of the features that makes disgust so\npotent and, according to its critics, so problematic. The disgust\nreaction can be difficult to repress, is easily recognized, and\nempathically induces disgust in those who do recognize\nit.[13] There\nare certain objects that almost all normal adults are disgusted by\n(feces, decaying corpses, rotting food, spiders, maggots, gross\nphysical deformities). But there is also considerable intercultural\nand interpersonal variation beyond these core objects of disgust,\nwhere the emotion extends into food choices, sexual behaviors,\nout-group members, and violations of social norms. Many studies have\nclaimed to show that disgust is implicated in harsher moral judgments\n(Schnall, Haidt, & Clore 2008), citing experiments in which\nsubjects filling out questionnaires in smelly or dirty rooms evaluated\nmoral transgressions more harshly. Others have gone further and argued\nthat disgust might itself cause or comprise a part of moral judgment\n(Haidt 2001; Wheatley & Haidt 2005). If this is true, critics\nargue, we ought to be wary of those judgments, because disgust has a\ncheckered past in multiple senses. First, it’s historically (and\ncurrently) associated with racism, sexism, homophobia and xenophobia;\nthe language of disgust is often used in campaigns of discrimination\nand even genocide. Secondly, disgust’s evolutionary history\ngives us reason to doubt it. Kelly (2011) argues that the universal\nbodily manifestations of disgust evolved to help humans avoid\ningesting toxins and other harmful substances, while the more\ncognitive or symbolic sense of offensiveness and contamination\nassociated with disgust evolved to help humans avoid diseases and\nparasites. This system is later recruited for an entirely distinct\npurpose: to help mark the boundaries between in-group and out-group,\nand thus to motivate cooperation with in-group members, punishment of\nin-group defectors, and exclusion of out-group members.  \n\nIf Kelly’s account of disgust is on the right track, it seems to\nhave a number of important moral upshots. One consequence, he argues,\nis “disgust skepticism” (139), according to which the\ncombination of disgust’s hair trigger and its ballistic\ntrajectory mean that it is especially prone to incorrigible false\npositives that involve unwarranted feelings of contamination and even\ndehumanization. Hence, “the fact that something is disgusting is\nnot even remotely a reliable indicator of moral foul play” but\nis instead “irrelevant to moral justification” (148).\n\n \n\nIt is important to note that the skeptical considerations Kelly raises\nare specific to disgust and its particular evolutionary history, so\nthey aren’t intended to undermine the role of all emotions in\nmoral judgment. Still, if Kelly is correct, and if disgust is\nimplicated in lots of moral judgments, we may have a reason to be\nskeptical of many of our judgments. Plakias (2011, 2017) argues\nagainst the first half of this antecedent, claiming that Kelly and\nother ‘disgust skeptics’ are wrong to claim that the\npurposes of moral and physical disgust are totally distinct; she\nsuggests that disgust is sometimes a fitting response to moral\nviolations that protects against social contagion. May (2014) argues\nagainst the second half, claiming that disgust’s role in moral\njudgment has been significantly overblown; at most, we have evidence\nthat disgust can, in certain cases, slightly amplify moral judgments\nthat are already in place. However, more recent empirical work\nindicates that incidental disgust has little effect on the harshness\nof moral judgments, though dispositional disgust-sensitivity does\n(Landy and Goodwin 2015).\n\n \n\nMetaethics steps back from moral theorizing to ask about the nature\nand function of morality. While first-order ethics seeks to explain\nwhat we should do, metaethics seeks to explain the status of those\ntheories themselves: what are their metaphysical commitments, and what\nevidence do we have for or against them? Which epistemology best\ncharacterizes our moral practices? What is the correct semantics for\nmoral language? These questions might not seem obviously empirical,\nbut insofar as it attempts to give an account of moral semantics, epistemology, and ontology, metaethics aims, in part, to capture or explain what we do when\nwe engage in moral talk, judgment, and evaluation. To the extent that\nmetaethics sees itself as characterizing our ordinary practice of\nmorality, it is therefore answerable to empirical data about that\npractice. To the extent that a theory claims that we are mistaken or in widespread error about the meaning of moral language, or that we lack justification for our core moral beliefs, this is taken to be a strike against that theory.  For example, relativism is often criticized on the grounds that it requires us to give up the (putatively) widespread belief that moral claims concern objective matters of fact and are true or false independently of our beliefs or attitudes.  We have already seen several ways that experimental data\nbears on theories about moral reasons (the debate between internalists\nand externalists) and the epistemology of moral judgment (the debate\nover the role of intuitions). In this section we will examine\nexperimental contributions to the debate over moral realism, arguments\nabout moral disagreement, and moral language.\n\n \n\nMuch contemporary metaethics relies on assumptions about the nature of\nordinary moral thought, discourse, and practice; metaethicists tend to\nsee their project as essentially conservative. For example, Michael\nSmith writes that the first step in metaethical theorizing is to\n“identify features that are manifest in ordinary moral\npractice” and the second step is to “make sense of a\npractice having these features.” (1994) This assumption has had\na major impact on the debate between realists and anti-realists, with\nrealists claiming to best capture the nature of ordinary moral\ndiscourse: “We begin as (tacit) cognitivists and realists about\nethics,” says Brink (1989), and then “we are led to some\nform of antirealism (if we are) only because we come to regard the\nmoral realist’s commitments as untenable… Moral realism\nshould be our metaethical starting point, and we should give it up\nonly if it does involve unacceptable metaphysical and epistemological\ncommitments.”\n\n \n\nBut experimental work has cast doubt on this claim, beginning with\nDarley and Goodwin (2008), and continued by James Beebe (2014) and\nothers (Wright et al. 2013; Campbell and Kumar 2012; Goodwin and\nDarley 2010; and Sarkissian et al. 2011). Goodwin and Darley asked\nsubjects to rate their agreement with statements drawn from the moral,\nethical, and aesthetic domain, and asked subjects whether they agreed\nwith the statement (for example, “before the 3rd month of\npregnancy, abortion for any reason (of the mother’s) is morally\npermissible,”), whether they thought it represented\na fact or an opinion or attitude, and whether, if\nsomeone were to disagree with them about the statement, at least one\nof the disputants would have to be mistaken. (We will say more about\nthe authors’ use of disagreement as a proxy for realism in the\nfollowing section.) In general, subjects rated moral statements as\nless factual than obviously factual statements (e.g. “the earth\nis at the center of the universe,”) but more factual than\nstatements about matters of taste or etiquette. What is striking about\nthese findings is not just that people are not straightforwardly\nrealist, but that they seem to treat moral questions variably: some\nare treated as matters of fact, others as matters of opinion. This\npattern has been replicated in several studies, and persists even when\nsubjects are allowed to determine for themselves which issues to\nassign to the moral domain, suggesting that subjects do not think\nmoral claims are uniformly objective\n\n \n\nAs we saw at the beginning of this entry, some of the earliest\nthinking in empirically-informed moral philosophy concerns moral\ndisagreement. Brandt and Ladd conducted in-depth investigations into\nthe moral codes of other groups, and some contemporary moral\nphilosophers have argued for continuing attention to the empirical\ndetails of moral disagreement. This is partly due to the influence of\nMackie’s (1977: 36–37) formulation of what he dubbed\n‘the argument from relativity’ in terms of an inference to\nthe best explanation: the best explanation of the nature and\npersistence of moral diversity, Mackie argues, is that our moral\njudgments represent “ways of life,” rather than\n“perceptions, most of them seriously inadequate and badly\ndistorted, of objective moral values.” Realists have tended to\nrespond to the argument by pointing to other possible explanations of\ndisagreement that are consistent with objectivity, such as mistakes\nabout the non-moral facts, irrationality, and failures of impartiality\nand imagination (see for example Brink 1984, Sturgeon 1988, Smith 1994, and\nShafer-Landau 2003; for an overview and analysis of realist responses, see Loeb 1998).\n \n\nHere it is useful to recall Brandt’s admonition that “bare\ninformation about intercultural differences” will not suffice to\nsettle the debate. Because the argument from disagreement turns, in\npart, on both the existence of moral disagreement and the best\nexplanation for it, evaluating the prospects for the argument requires\nattention to the empirical details of actual moral disagreements,\nrather than conjecture about the outcomes of possible moral\ndisagreements. For example, Doris and Plakias (2008) discuss several\ninstances of cross-cultural moral disagreement, and assess the\nprospects for applying what they call ‘defusing\nexplanations’ to these cases. A defusing explanation is one that\naccounts for the disagreement in terms of a non-moral difference or an\nepistemic shortcoming on the part of one or more disputant, thereby\nshowing that it is not, in fact, a moral disagreement. Their argument\nand the experiments they cite are discussed in detail in the entry on\nempirical moral psychology, so we will not discuss them in detail\nhere; for now, we will note that such explanations are difficult to\nassess via survey methods alone. This is why it is especially helpful\nto look to the anthropological record, as Oliver Curry et al. (forthcoming)\ndo in a recent landmark publication. Curry hypothesizes that morality\ncomprises stable, cooperative solutions to recurrent problems that can\nbe modeled as non-zero-sum games. There are a variety of such\nrecurrent problems, and game theory has established a suite of\nanalytical tools for diagnosing and solving them. Curry and his\ncolleagues show that such solutions are always seen as either\nmorally good or morally neutral in societies at various stages of\ndevelopment, from small-band hunter gatherers to industrialized\ndemocracies. This research suggests that philosophers may have greatly\nexaggerated the extent of moral disagreement that actually exists.\n\n \n\nOne reason disagreement is a useful measure of objectivity is that the\nimpossibility of faultless disagreement is taken to be characteristic\nof questions concerning objective matters of fact. That is, while we\nmight concede the possibility of faultless disagreements about matters\nconcerning the deliciousness of foods or the merits of a sports team,\nwhen we disagree over moral issues, we think that there is a correct\nanswer and that therefore at least one disputant is getting things\nwrong (for a discussion of the analogy between food and morality, see Loeb (2003)). To the extent that people judge a disagreement to be faultless,\nwe might think that they are evincing a kind of anti-realism about the\nissue under dispute. This is yet another way disagreement can bear on\nthe realism/antirealism debate. Can experimental evidence involving\ndisagreement tell us anything about the semantics of moral language?\n\n \n\nOne reason to think it can is that the very idea of faultless\ndisagreement strikes some as incoherent. In cases where one individual\nthinks (or says) that pistachio ice cream is delicious and another\nthinks (or says) that it is disgusting, we understand the two parties\nas expressing their own personal preference. To explain the apparent\nfaultlessness of the dispute, we reinterpret their thoughts or\nutterances as expressing something like, “pistachio ice cream is\ndelicious [disgusting] to me.“ Because the two parties\ndo not genuinely contradict one another, we need not say that one of\nthem is mistaken. Faultlessness is therefore supposed to be a point in\nfavor of the moral anti-realist, since it seems to imply that there is\nno single content about which the parties disagree (and about which\none might be mistaken).\n\n \n\nBy contrast, realists claim that their view is better able to capture\nour intuition that there is a genuine disagreement at stake when one\nperson says that stealing is wrong and another says that stealing is\nnot wrong. In these cases, realists argue, we have the intuition that\nthere really is a conflict, and only a theory on which moral language\ninvolves attributing properties to acts and things, rather than\nreporting or expressing speakers’ attitudes, can capture this\nintuition.\n\n \n\nWe have already seen some data bearing on this issue in our discussion\nof folk realism above. The claim here is not about realism per se, but\nabout whether experimental evidence can give us insight into the\nsemantics of moral language, since our intuitions about whether there\nis genuine faultlessness can tell us about whether there is a single\nshared content between two utterances—a single proposition that\none party asserts and another denies—or whether the two\nparties’ utterances contain implicit relativizations. This has,\nat least, been the assumption guiding much of the debate over\ndisagreement and its implication for moral semantics. In recent work,\nhowever, John Khoo and Joshua Knobe (2016) have cast doubt on this\nassumption; their experiments indicate that subjects do not see\ndisagreement as requiring exclusionary content—a single\nproposition that one party accepts and the other rejects. This\nresearch suggests that intuitions about disagreement may not be as\nstraightforwardly tied to moral semantics as philosophers have\nthought: judgments that two individuals genuinely disagree about some\nclaim do not necessarily imply a single shared content between the two\nspeakers. This work is still in early stages, but it reveals the\ncomplications involved in reading semantics off disagreement.\n\n \n\nA further challenge for attempts to experimentally investigate moral\nsemantics is the debate within antirealism between cognitivism and\nnoncognitivism. According to the cognitivist, ordinary moral sentences\nare best understood as factual assertions, expressing propositions\nthat attribute moral properties (such as rightness or goodness) to\nthings (such as actions or characters). Noncognitivists (including\ntheir contemporary representatives, the expressivists) hold that moral\nlanguage has a fundamentally different function, to express attitudes\nor to issue commands, for example. While this debate seems ripe for\nexperimental investigation, the noncognitivist typically acknowledges\nthat their view is a reforming one. Furthermore, the semantics of our\nterms may be opaque to ordinary users, to the extent that we cannot\nread off semantics from intuitions but must investigate them\nindirectly. Lastly, the cognitivist and noncognitivist can agree on a\nnumber of empirical features of moral judgment and discourse; the\nchallenge for experimentalists is to find predictions that confirm one\nview while disconfirming the other. This is a relatively new area of\ninvestigation and, while not without challenges, ripe for exploration.\n\n \n\nExperimental moral philosophy far outstrips what we have been able to\ncover here, and many issues and areas of productive research have\nbarely been touched upon. For example, experimental evidence is\nrelevant to moral questions in bioethics, such as euthanasia,\nabortion, genetic screening, and placebogenic interventions.\nLikewise, experiments in behavioral economics and cognitive psychology\nare being employed in asking moral questions about public policy\n(Bicchieri and Chavez 2010; Bicchieri and Xiao 2009).  We neglect\nthese issues only because of lack of space. In the few words\nremaining, we explore some potential criticisms of experimental\nphilosophy. \n\nAs a young field, experimental philosophy suffers from various\nproblems with experimental design and interpretation. These are not\ninsurmountable problems, and they are problems faced by related\nfields, such as social psychology, cognitive psychology, and\nbehavioral economics. \n\nOne issue that has recently come to the fore is the problem of\n replication.[14] \nStatistical analysis is not deductive inference, and the mere fact that\nstatistical analysis yields a positive result does not guarantee that\nanything has been discovered. Typically, an experimental result is\ntreated as “real” if its \\(p\\)-value is at most .05,\nbut such a value just indicates the probability that the observation in\nquestion would have been made if the null hypothesis were true. \nIt is not the probability that the null hypothesis is false given\nthe\n observation.[15] \nSo, even\nwhen statistical analysis indicates that the null hypothesis is to be\nrejected, that indication can be fallacious. Moreover, when\nmultiple hypotheses are tested, the chance of fallaciously rejecting\nthe null hypothesis at least once rises exponentially. \n\nWe should expect other failures of replication because of a bias built\ninto the system of funding experimentation and publishing results. The\nproportion of published false-positives is much higher for unexpected\nand unpredicted results than for expected and predicted results. Since\nexperimentalists are reluctant to report (and even discouraged by\njournal editors and referees from reporting) null results (i.e.,\nresults where the \\(p\\)-value is more than .05), for every published,\nunexpected result there may be any number of unpublished, unexpected\nnon-results. Thus, unexpected, published results are more likely to be\nfalse positives than they might appear. \n\nThe best way to tell whether such a result carries any evidential\nvalue is for the experiment to be replicated—preferably by\nanother research group. If a result cannot be replicated, it is\nprobably a mirage. Such mirages have turned up to a disturbing extent\nrecently, as Daniel Kahneman has famously pointed out (Yong 2012; see\nalso Wagenmakers et al. 2012). Kahneman proposed a “daisy\nchain” of replication, where no result in psychology would be\npublished until it had been successfully replicated by another\nprominent lab. This proposal has not yet been (and may never be)\ninstituted, but it has raised the problem of replication to salience,\nand a related project has taken off. The reproducibility project in\npsychology aims to establish the extent to which prominent, published\nresults can be replicated.[16] Experimental philosophers have followed suit\nwith their own replication project (see the Other Internet\nResources). This work has recently yielded encouraging fruit: a large\ncollaborative replication effort suggests that approximately 7 out of\n10 experimental philosophy results can be reproduced, whereas similar\nefforts show that less than half of the results in biomedicine,\neconomics, and psychology are replicable (Cova et al. 2018, Other Internet\nResources). \n\nA related issue with experimental design and interpretation has to do\nwith “fishing expeditions.” An experiment is sometimes\npejoratively referred to as a fishing expedition if no specific\npredictions are advanced prior to data collection, especially when\nmultiple hypotheses are tested. Likewise, critics argue that\nresearchers such as Weinberg, Nichols, & Stich (2008) have put\nforward hypotheses that are formulated so vaguely as to make them\nnearly unfalsifiable. This problem is exacerbated when no guiding\npositive heuristic is offered to explain observed patterns. \n\nAnother worry is that simultaneously testing many intuition-probes can\nlead unwary experimenters on snipe hunts. Suppose an experimental\nphilosopher conducts an experiment with two conditions: in the\nexperimental condition, participants are primed with deterministic\nideas, while in the control condition they are not primed one way or\nanother. She asks participants twenty different questions about their\nmoral intuitions, for instance, whether there is free will, whether\nmalefactors deserve to be punished, whether virtue deserves to be\nrewarded, and so on. She then makes pairwise comparisons of their\nresponses to each of the questions in an attempt to figure out whether\ndeterministic priming induces changes in moral intuitions. She thus\nmakes twenty independent comparisons, each at the industry-standard 5%\nlevel. Suppose now for the sake of argument that there is no\neffect—that all null hypotheses are true. In that case, the\nprobability that at least one of these tests will result in a Type I\nerror (rejecting the null hypothesis even though it is true) is\n64%. More generally, when an experimenter performs \\(n\\) independent\ncomparisons at the 5% level, the probability of at least one Type I\nerror is \\(1-.95^n\\). This problem can be addressed by various\nprocedures, most notably the Tukey method and the Bonferroni\nmethod.[17] \n\nOne way to establish that a result is real is to see whether the\nexperiment has a respectable effect size. The most common measure of\neffect size is Cohen’s \\(d\\), which is the ratio of the\ndifference in means between conditions to the standard deviation of\nthe relevant variable. So, for example, a \\(d\\) of 1.0 would indicate\nthat a manipulation moved the mean of the experimental condition an\nentire standard deviation away from the mean of the control condition,\na huge effect. Unfortunately, effect sizes have, until recently,\nrarely been reported in experimental philosophy, though that appears\nto be changing. \n\nOne might object that the real problem with experimental moral\nphilosophy is not with science, but with its relevance (or more\nprecisely, its irrelevance) to moral philosophy. The objection is that\nmoral philosophy is concerned not with how we are and what we do, but\nwith how we ought to be and what we ought to do. As such, it is a\nnormative enterprise, and is unaffected by empirical results. Science\nis hard, but so is morality; if we fail to understand and live up to\nthe demands of the latter, that doesn’t show a problem with our\nmoral theory but with our moral natures.  \n\nExperimental philosophers can agree with this objection, up to a\npoint. No one is suggesting that we read morality directly off survey\nresults. But, to return to the point with which we began, while\nmorality is normative, it is also essentially practical. Moral theory\nis a theory about what we ought to do: a theory about how creatures\nlike us ought to conduct ourselves and interact with one another. A\nmorality completely divorced from our natures, that demanded acts\nimpossible from us, would surely be unacceptable. This is not just a\npoint about experimental philosophy; utilitarianism is sometimes\ncritiqued as making unrealistic demands of impartiality. Alongside the\nfamous proscription against deriving an ought from\nan is, we also find the dictum that ought implies\ncan. The exact extent to which morality can be demanding without\nbeing unrealistic is itself a philosophical question, and so\nexperimental moral philosophy works in conjunction with philosophical\nanalysis; it does not aim to eliminate it. Exactly how the two relate\nto each other, and how empirical evidence will bear on and influence\ndebates in moral theory in the future, is a contested issue, but\nsurely traditional moral theory and experimental moral philosophy have\nmuch to learn from one another.\n\n \n\nWe need to proceed cautiously here. No one doubts that what we ought\nto do depends on how things are non-morally. For example, the moral\nclaim that a given man deserves to be punished presupposes the\nnon-moral fact that he committed the crime. It should come as no\nsurprise, then, that experimental evidence might be relevant in this\nway to morality. Whether experimental evidence is relevant to\ndiscovering the fundamental moral principles—those meant to be\nput into action one way or another depending on how the world is\nnon-morally—is still subject to debate. \n\nAnother version of this argument says that fundamental moral\nphilosophical principles are, if true at all, necessarily true, and\nthat empirical research can establish at best only contingent\ntruths.[18]\nBut if fundamental moral theories are necessary, then they are\nnecessary\nfor creatures like us. And one thing that empirical\ninvestigation can do is to help establish what sorts of creatures we\nare. Imagination needs material to work with. When one sits\nin one’s armchair, imagining a hypothetical scenario, one makes a\nwhole host of assumptions about what people are like, how psychological\nprocesses work, and so on. These assumptions can be empirically\nwell or poorly informed. It’s hard to see why anyone could\ndoubt that being well informed is to be preferred. Likewise\nit’s hard to see how anyone could doubt the relevance of\nexperimental evidence to better grounding our empirical assumptions, in\nthis case our assumptions relevant to moral philosophy. Exactly\nhow experimental—or more broadly, empirical—evidence is\nrelevant, and how relevant it is, are at present hotly contested\nmatters.","contact.mail":"aplakias@hamilton.edu","contact.domain":"hamilton.edu"}]
