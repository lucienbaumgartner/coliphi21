[{"date.published":"2016-10-10","url":"https://plato.stanford.edu/entries/scientific-representation/","author1":"Roman Frigg","author1.info":"http://www.lse.ac.uk/collections/philosophyLogicAndScientificMethod/WhosWho/staffhomepages/frigg.htm","author2.info":"http://personal.lse.ac.uk/NGUYENJ1/","entry":"scientific-representation","body.text":"\n\n\nScience provides us with representations of atoms, elementary\nparticles, polymers, populations, genetic trees, economies, rational\ndecisions, aeroplanes, earthquakes, forest fires, irrigation systems,\nand the world’s climate. It’s through these\nrepresentations that we learn about the world. This entry explores\nvarious different accounts of scientific representation, with a\nparticular focus on how scientific models represent their\ntarget systems. As philosophers of science are increasingly\nacknowledging the importance, if not the primacy, of scientific models\nas representational units of science, it’s important to stress\nthat how they represent plays a fundamental role in how we are to\nanswer other questions in the philosophy of science (for instance in the\nscientific realism debate). This entry begins by disentangling\n“the” problem of scientific representation, and then \ncritically evaluates the current options available in the\nliterature.\n\nIn most general terms, any representation that is the product of a\nscientific endeavour is a scientific representation. These\nrepresentations are a heterogeneous group comprising anything from\nthermometer readings and flow charts to verbal descriptions,\nphotographs, X-ray pictures, digital imagery, equations, models, and\ntheories. How do these representations work? \nThe first thing that strikes the novice in the debate about scientific\nrepresentation is that there seems to be little agreement about what\nthe problem is. Different authors frame the problem of scientific\nrepresentation in different ways, and eventually they examine\ndifferent issues. So a discussion of scientific representation has to\nbegin with a clarification of the problem itself. Reviewing the\nliterature on the subject leads us to the conclusion that there is no\nsuch thing as the problem of scientific\nrepresentation—in fact there are at least five different\nproblems concerning scientific representation. In this section we\nformulate these problems and articulate five conditions of adequacy\nthat every account of scientific representation has to satisfy.  \n\nThe first problem is: what turns something into a scientific representation of something else? It has become customary to phrase\nthis problem in terms of necessary and sufficient conditions and ask: what fills the blank in “\\(S\\) is\na scientific representation of \\(T\\) iff ___”, where\n“\\(S\\)” stands for the object doing the representing and\n“\\(T\\)” for “target system”, the part or\naspect of the world the representation is about?[1] Let us call this the\nScientific Representation Problem (or SR-Problem for\nshort).  \nA number of contributors to the debate have emphasised that scientific\nrepresentation is an intentional concept, depending on factors such as\na user’s intentions, purposes and objectives, contextual\nstandards of accuracy, and intended audiences (see, for instance,\nGiere 2010; Mäki 2011; Suárez 2004; and van Fraassen\n2008). We will discuss these in detail below. At this point it needs\nto be emphasised that framing the problem in terms of a biconditional\ndoes not preclude such factors to be part of the analysis. One might\nworry that the above formulation presupposes that representation is an\nintrinsic relation between \\(S\\) and \\(T\\), i.e., a relation that only\ndepends on intrinsic properties of \\(S\\) and \\(T\\). This is a\nmisapprehension. The blank can be filled with a \\((n+2)\\)-ary relation\n\\(C(S, T, x_1, \\ldots, x_n)\\) (\\(C\\) for “constitutes”), where \\(n \\ge 0\\) is a natural number\nand the \\(x_i\\) are factors such as intentions and purposes. \nA first important condition of adequacy on any reply to this problem\nis that scientific representations allow us to form hypotheses about\ntheir target systems. An X-ray picture provides information about the\nbones of the patient, and models allow investigators to discover\nfeatures of the things models stands for. Every acceptable theory of\nscientific representation has to account for how reasoning conducted\non representations can yield claims about their target systems. Swoyer\n(1991: 449) refers to this kind of representation-based thinking as\n“surrogative reasoning” and so we call this the\nSurrogative Reasoning\n Condition.[2]\n This condition distinguishes models from lexicographical and\nindexical representations, which do not allow for surrogative\nreasoning. \nUnfortunately this condition does not constrain answers sufficiently\nbecause any account of representation that fills the blank in a way\nthat satisfies the surrogative reasoning condition will almost\ninvariably also cover other kinds of representations. Speed camera\nphotographs give the police information about drivers breaking the\nlaw, a cardboard model of the palace instructs us about its layout and\nproportions, and a weather map shows you where to expect rain, and therefore\nare likely to fall under an account of representation that explains\nsurrogative reasoning. Hence, representations other than scientific\nrepresentations also allow for surrogative reasoning, which raises the\nquestion: how do scientific representations differ from other kinds of\nrepresentations that allow for surrogative reasoning? Callender and\nCohen (2006: 68–69) point out that this is a version\nPopper’s demarcation problem, now phrased in terms of\nrepresentation, and so we refer to it as the Representational\nDemarcation Problem.  \nCallender and Cohen voice scepticism about there being a solution to\nthis problem and suggest that the distinction between scientific and\nnon-scientific representations is circumstantial (2006: 83):\nscientific representations are representations that are used or\ndeveloped by someone who is a scientist. Other authors do not\nexplicitly discuss the representational demarcation problem, but\nstances similar to Callender and Cohen’s are implicit in any\napproach that analyses scientific representation alongside other kinds\nof representation. Elgin (2010), French (2003), Frigg (2006), Hughes\n(1997), Suárez (2004), and van Fraassen (2008), for instance,\nall draw parallels between scientific and pictorial representation,\nwhich would make little sense if pictorial and scientific\nrepresentation were categorically different. \nThose who reject the notion that there is an essential difference\nbetween scientific and non-scientific representation can follow a\nsuggestion of Contessa’s (2007) and broaden the scope of the\ninvestigation. Rather than analysing scientific representation, they\ncan analyse the broader category of epistemic representation.\nThis category comprises scientific representations, but it also\nincludes other representations that allow for surrogative reasoning.\nThe task then becomes to fill the blank in “\\(S\\) is an\nepistemic representation of \\(T\\) iff ___”. We call this the\nEpistemic Representation Problem (ER-Problem, for\nshort), and the biconditional the ER-Scheme. So one can say\nthat the ER-Problem is to fill the blank in the ER-Scheme. \nNot all representations are of the same kind, not even if we restrict\nour attention to scientific representations (assuming they are found\nto be relevantly different to non-scientific epistemic\nrepresentations). An X-ray photograph represents an ankle joint in a\ndifferent way than a biomechanical model, a mercury thermometer\nrepresent the temperature of gas in a different way than statistical\nmechanics does, and chemical theory represents a C60 fullerene in\ndifferent way that an electron-microscope image of the molecule. Even\nwhen restricting attention to the same kind of representation, there\nare important differences: Weizsäcker’s liquid drop model,\nfor instance, represents the nucleus of an atom in a manner that seems\nto be different from the one of the shell model, and an electric\ncircuit model represents the brain function in a different way than a\nneural network model. In brief, there seem to be different\nrepresentational styles. This raises the question: what styles are\nthere and how can they be\n characterised?[3]\n We call this the Problem of\n Style.[4]\n There is no expectation that a complete list of styles be\nprovided in response. Indeed, it is unlikely that such a list can ever\nbe drawn up, and new styles will be invented as science progresses.\nFor this reason a response to the problem of style will always be\nopen-ended, providing a taxonomy of what is currently available while\nleaving room for later additions. \nSome representations are accurate; others aren’t. The quantum\nmechanical model is an accurate representation of the atom (at least by our current lights) but the\nThomson model isn’t. On what grounds do we make such judgments?\nMorrison (2008: 70) reminds us that it is a task for theory of\nrepresentation to identify what constitutes an accurate\nrepresentation. We call this the problem of Standards of\nAccuracy. Providing such standards is one of the issues an account of representation has to address.  \nThis problem goes hand in hand with a condition of adequacy: the\nPossibility of Misrepresentation. Asking what makes a\nrepresentation an accurate representation ipso facto\npresupposes that inaccurate representations are representations too.\nAnd this is how it should be. If \\(S\\) does not accurately represent\n\\(T\\), then it is a misrepresentation but not a non-representation. It\nis therefore a general constraint on a theory of scientific\nrepresentation that it has to make misrepresentation possible (see\nFrigg 2002: 16–17; Suárez 2003: 233–235; Contessa\n2007; and van Fraassen 2008: 13–15). \nA related condition concerns models that misrepresent in the sense\nthat they lack target systems. Models of ether, phlogiston, four-sex\npopulations, and so on, are all deemed scientific models, but ether,\nphlogiston, and four-sex populations don’t exist. Such models\nlack (actual) target systems, and one hopes that an account of\nscientific representation would allow us to understand how these\nmodels work. This need not imply the claim that they are representations in the same\nsense as models with actual targets, and, as we discuss below, there are\naccounts that deny targetless models the status of being\nrepresentations. \nA further condition of adequacy for an account of scientific representation\nis that it must account for the directionality of representation. As\nGoodman points out (1976: 5), representations are about their targets, but (at least\nin general) targets are not about their representations: a photograph\nrepresents the cracks in the wing of aeroplane, but the wing does not\nrepresent the photograph. So there is an essential directionality to\nrepresentations, and an account of scientific, or epistemic, representation has to\nidentify the root of this directionality. We call this the\nRequirement of Directionality. \nSome representations, in particular models and theories, are\nmathematized and their mathematical aspects are crucial to their\ncognitive and representational function. This forces us to reconsider\na time-honoured philosophical puzzle: the applicability of mathematics\nin the empirical sciences. The problem can be traced back at least to\nPlato’s Timaeus, but its modern expression is due to\nWigner who challenged us to find an explanation for the enormous\nusefulness of mathematics in the sciences (1960: 2). The question how\na mathematized model represents its target implies the question how\nmathematics applies to a physical system (see Pincock 2012 for an\nexplicit discussion of the relationship between scientific\nrepresentation and the applicability of mathematics). For this reason,\nour fifth and final condition of adequacy is that an account of\nrepresentation has to explain how mathematics is applied to the\nphysical world. We call this the Applicability of Mathematics\nCondition. \nIn answering the above questions one invariably runs up against a\nfurther problem, the Problem of Ontology: what kinds of\nobjects are representations? If representations are material objects\nthe answer is straightforward: photographic plates, pieces of paper\ncovered with ink, elliptical blocks of wood immersed in water, and so\non. But not all representations are like this. As Hacking (1983: 216)\nputs it, some representations one holds in one’s head rather\nthan one’s hands. The Newtonian model of the solar system, the\nLotka-Volterra model of predator-prey interaction and the general\ntheory of relativity are not things you can put on your laboratory\ntable and look at. The problem of ontology is to come clear on our\ncommitments and provide a list with things that we recognise—or\ndon’t recognise—as entities performing a representational\nfunction and give an account of what they are in case these entities\nraise questions (what exactly do we mean by something that one holds\nin one’s head rather than one’s hands?). Contessa (2010),\nFrigg (2010a,b), Godfrey-Smith (2006), Levy (2015), Thomson-Jones\n(2010), Weisberg (2013), among others, have drawn attention to this\nproblem in different ways.  \nIn sum, a theory of scientific representation has to respond to the\nfollowing issues: \nAny satisfactory answer to these five issues will have to meet the\nfollowing five conditions of adequacy: \nListing the problems in this way is not to say that these are separate\nand unrelated issues. This division is analytical, not factual. It\nserves to structure the discussion and to assess proposals; it does\nnot imply that an answer to one of these questions can be dissociated\nfrom what stance we take on the other issues.  \nAny attempt to tackle these questions faces an immediate\nmethodological problem. As per the problem of style, there are\ndifferent kinds of representations: scientific models, theories,\nmeasurement outcomes, images, graphs, diagrams, and linguistic\nassertions are all scientific representations, and even within these \ngroups there can be considerable variation. But every analysis has\nto start somewhere, and so the problem is where. One might adopt a\nuniversalist position, holding that the diversity of styles dissolves\nunder analysis and at bottom all instances of scientific/epistemic\nrepresentation function in the same way and are covered by the same\noverarching account. For such a universalist the problem loses its teeth\nbecause any starting point will lead to the same result. Those of\nparticularist bent deny that there is such a theory. They will first\ndivide the scientific/epistemic representations into relevant\nsubclasses and then analyse each subclass separately.  \nDifferent authors assume different stances in this debate, and we will\ndiscuss their positions below. However, there are few, if any,\nthoroughgoing universalists and so a review like the current one has\nto discuss different cases. Unfortunately space constraints prevent us\nfrom examining all the different varieties of scientific/epistemic\nrepresentation, and a selection has to be made. This invariably leads\nto the neglect of some kinds of representations, and the best we can\ndo about this is to be explicit about our choices. We resolve to\nconcentrate on scientific models, and therefore replace our variable \\(S\\) for the object doing the representing with the variable \\(M\\) for model.\nThis is in line both with the more\nrecent literature on scientific representation, which is predominantly\nconcerned with scientific models, and with the prime importance that\ncurrent philosophy of science attaches to models (see the SEP entry on\n models in science\n for a\n survey).[5] \nIt is, however, worth briefly mentioning some of the omissions that\nthis brings with it. Various types of images have their place in\nscience, and so do graphs, diagrams, and drawings. Perini (2010) and\nElkins (1999) provide discussions of visual representation in science.\nMeasurements also supply representations of processes in nature,\nsometimes together with the subsequent condensation of measurement\nresults in the form of charts, curves, tables and the like (see the\nSEP entry on\n measurement in science).\n Furthermore, theories represent their subject matter. At this point\nthe vexing problem of the nature of theories rears again (see the SEP\nentry on\n the structure of scientific theories\n and also Portides (forthcoming) for an extensive discussion).\nProponents of the semantic view of theories construe theories as\nfamilies of models, and so for them the question of how theories\nrepresent coincides with the question of how models represent. By\ncontrast, those who regard theories as linguistic entities see\ntheoretical representation as a special kind of linguistic\nrepresentation and focus on the analysis of scientific languages, in\nparticular the semantics of so-called theoretical terms (see the SEP\nentry on\n theoretical terms in science). \nBefore delving into the discussion a common misconception needs to be\ndispelled. The misconception is that a representation is a mirror\nimage, a copy, or an imitation of the thing it represents. On this\nview representation is ipso facto realistic representation.\nThis is a mistake. Representations can be realistic, but they need\nnot. And representations certainly need not be copies of the real\nthing (an observation exploited by Lewis Carroll and Jorge Luis Borges\nin their satires, Sylvie and Bruno and On Exactitude in\nScience respectively, about cartographers who produce maps as\nlarge as the country itself only to see them abandoned). Throughout\nthis review we encounter positions that make room for non-realistic\nrepresentation and hence testify to the fact that representation is a\nmuch broader notion than\n mirroring.[6] \nCallender and Cohen (2006) give a radical answer to the demarcation\nproblem: there is no difference between scientific representations and\nother kinds of representations, not even between scientific and\nartistic representation. Underlying this claim is a position they call\n“General Griceanism” (GG). The core of GG is the reductive\nclaim that all representations owe their status as representations to\na privileged core of fundamental representations. GG then comes with a\npractical prescription about how to proceed with the analysis of a\nrepresentation:  \nthe General Gricean view consists of two stages. First, it explains\nthe representational powers of derivative representations in terms of\nthose of fundamental representations; second, it offers some other\nstory to explain representation for the fundamental bearers of\ncontent. (2006: 73)  \nOf these stages only the second requires serious philosophical work,\nand this work is done in the philosophy of mind because the\nfundamental form of representation is mental representation. \nScientific representation is a derivative kind of representation\n(2006: 71, 75) and hence falls under the first stage of the above\nrecipe. It is reduced to mental representation by an act of\nstipulation. In Callender and Cohen’s own example, the salt\nshaker on the dinner table can represent Madagascar as long as someone\nstipulates that the former represents the latter, since  \nthe representational powers of mental states are so wide-ranging that\nthey can bring about other representational relations between\narbitrary relata by dint of mere stipulation. (2006: 73–74)  \nSo explaining any form of representation other than mental\nrepresentation is a triviality—all it takes is an act of\n“stipulative fiat” (2006: 75). This supplies an answer to\nthe ER-problem: \nStipulative Fiat: A scientific model \\(M\\) represents a\ntarget system \\(T\\) iff a model user stipulates that \\(M\\) represents\n\\(T\\).  \nThe first problem facing Stipulative Fiat is whether or not\nstipulation, or the bare intentions of language users, suffice to\nestablish representational relationships. In the philosophy of\nlanguage this gets called the “Humpty Dumpty” problem. It\nconcerns whether or not Lewis Carroll’s Humpty Dumpty could use\nthe word “glory” to mean “a nice knockdown\nargument” (Donnellan 1968; MacKay 1968). (We ignore the\ndifference between meaning and denotation here). In that context it\ndoesn’t seem like he can, and analogous questions can be posed\nin the context of scientific representation: can a scientist make any\nmodel represent any target simply by stipulating that it does? \nEven if stipulation were sufficient to establish some sort of\nrepresentational relationship, Stipulative Fiat fails to meet\nthe Surrogative Reasoning Condition: assuming a salt shaker represents\nMadagascar in virtue of someone’s stipulation that this is so,\nthis tells us nothing about how the salt shaker could be used to learn\nabout Madagascar in the way that scientific models are used to learn\nabout their targets (Liu 2015: 46–47, for a related objection see Bueno and French\n2011: 871–873). And\nappealing to additional facts about the salt shaker (the salt shaker\nbeing to the right of the pepper mill might allow us to infer that\nMadagascar is to the east of Mozambique) in order to answer this\nobjection goes beyond Stipulative Fiat. Callender and Cohen\ndo admit some representations are more useful than others, but claim\nthat  \nthe questions about the utility of these representational vehicles are\nquestions about the pragmatics of things that are representational\nvehicles, not questions about their representational status per\nse. (2006: 75)  \nBut even if the Surrogative Reasoning Condition is relegated to the\nrealm of “pragmatics” it seems reasonable to ask for an\naccount of how it is met.  \nAn important thing to note is that even if Stipulative Fiat\nis untenable, we needn’t give up on GG. GG only requires that\nthere be some explanation of how derivative representations\nrelate to fundamental representations; it does not require that this\nexplanation be of a particular kind, much less that it consist in\nnothing but an act of stipulation (Toon 2010: 77–78). As\nCallender and Cohen note, all that it requires is that there is a\nprivileged class of representations and that other types of\nrepresentations owe their representational capacities to their\nrelationship with the primitive ones. So philosophers need an account\nof how members of this privileged class of representations represent,\nand how derivative representations, which includes scientific models,\nrelate to this class. When stated like this, many recent contributors\nto the debate on scientific representation can be seen as falling\nunder the umbrella of GG. Indeed, As we will see below, many of the\nmore developed versions of the accounts of scientific representation\ndiscussed throughout this entry invoke the intentions of model users,\nalbeit in a more complex manner than Stipulative Fiat. \nSimilarity and representation initially appear to be two closely\nrelated concepts, and invoking the former to ground the latter has a\nphilosophical lineage stretching back at least as far as Plato’s\nThe\n Republic.[7]\n In its most basic guise the similarity conception of scientific\nrepresentation asserts that scientific models represent their targets\nin virtue of being similar to them. This conception has universal\naspirations in that it is taken to account for representation across a\nbroad range of different domains. Paintings, statues, and drawings are\nsaid to represent by being similar to their subjects, and Giere\nproclaimed that it covers scientific models alongside “words,\nequations, diagrams, graphs, photographs, and, increasingly,\ncomputer-generated images” (2004: 243). So the similarity view\nrepudiates the demarcation problem and submits that the same\nmechanism, namely similarity, underpins different kinds of\nrepresentation in a broad variety of contexts. \nThe view also offers an elegant account of surrogative reasoning.\nSimilarities between model and target can be exploited to carry over\ninsights gained in the model to the target. If the similarity between\n\\(M\\) and \\(T\\) is based on shared properties, then a property found\nin \\(M\\) would also have to be present in \\(T\\); and if the similarity\nholds between properties themselves, then \\(T\\) would have to\ninstantiate properties similar to \\(M\\). \nHowever, appeal to similarity in the context of representation leaves\nopen whether similarity is offered as an answer to the ER-Problem, the\nProblem of Style, or whether it is meant to set Standards of Accuracy.\nProponents of the similarity conception typically have offered little\nguidance on this issue. So we examine each option in turn and ask\nwhether similarity offers a viable answer. We then turn to the\nquestion of how the similarity view deals with the Problem of\nOntology. \nUnderstood as response to the ER-Problem, the simplest similarity view\nis the following:  \nSimilarity 1: A scientific model \\(M\\) represents a target\n\\(T\\) iff \\(M\\) and \\(T\\) are similar.  \nA well-known objection to this account is that similarity has the\nwrong logical properties. Goodman (1976: 4–5) points out that similarity is\nsymmetric and reflexive yet representation isn’t. If object\n\\(A\\) is similar to object \\(B\\), then \\(B\\) is similar to \\(A\\). But\nif \\(A\\) represents \\(B\\), then \\(B\\) need not (and in fact in most\ncases does not) represent \\(A\\). Everything is similar to itself, but\nmost things do not represent themselves. So this account does not meet\nour fourth condition of adequacy for an account of scientific\nrepresentation insofar as it does not provide a direction to\nrepresentation. \nHowever, there are accounts of similarity under which similarity is not a symmetric relation (see Tversky 1977; Weisberg 2012, 2013: ch. 8; and Poznic 2016:\nsec. 4.2). This raises the question of how to analyse similarity. We\nturn to this issue in the next subsection. However, even if we concede\nthat similarity need not always be symmetrical, this does not solve\nGoodman’s problem with reflexivity; nor does it, as we will see,\nsolve other problems of the similarity account. \nThe most significant problem facing Similarity 1 is that\nwithout constraints on what counts as similar, any two things can be\nconsidered similar (Aronson et al. 1995: 21; Goodman 1972:\n443–444). This, however, has the unfortunate consequence that\nanything represents anything else. A natural response to this\ndifficulty is to delineate a set of relevant respects and degrees to\nwhich \\(M\\) and \\(T\\) have to be similar. This idea can be moulded\ninto the following definition: \nSimilarity 2: A scientific model \\(M\\) represents a target\n\\(T\\) iff \\(M\\) and \\(T\\) are similar in relevant respects and to the\nrelevant degrees.  \nOn this definition one is free to choose one’s respects and\ndegrees so that unwanted similarities drop out of the picture. While\nthis solves the last problem, it leaves the problem of logical\nproperties untouched: similarity in relevant respects and to the\nrelevant degrees is reflexive (and symmetrical, depending on\none’s notion of similarity). Moreover, Similarity 2\nfaces three further problems. \nFirstly, similarity, even restricted to relevant similarities, is too\ninclusive a concept to account for representation. In many cases\nneither one of a pair of similar objects represents the other. This\npoint has been brought home in now-classical thought experiment due to\nPutnam (1981: 1–3). An ant is crawling on a patch of sand and\nleaves a trace that happens to resemble Winston Churchill. Has the ant\nproduced a picture, a representation, of Churchill? Putnam’s\nanswer is that it didn’t because the ant has never seen\nChurchill, had no intention to produce an image of him, was not\ncausally connected to Churchill, and so on. Although someone else\nmight see the trace as a depiction of Churchill, the trace itself does\nnot represent Churchill. The fact that the trace is similar to\nChurchill does not suffice to establish that the trace represents him.\nAnd what is true of the trace and Churchill is true of every other\npair of similar items: even relevant similarity on its own does not\nestablish representation. \nSecondly, as noted in\n Section 1,\n allowing for the possibility of misrepresentation is a key desiderata\nrequired of any account of scientific representation. In the context\nof a similarity conception it would seem that a misrepresentation is\none that portrays its target as having properties that are not similar\nin the relevant respects and to the relevant degree to the true\nproperties of the target. But then, on Similarity 2, \\(M\\) is\nnot a representation at all. The account thus has difficulty\ndistinguishing between misrepresentation and non-representation\n(Suárez 2003: 233–235). \nThirdly, there may simply be nothing to be similar to because some\nrepresentations represent no actual object. Some paintings represent\nelves and dragons, and some models represent phlogiston and the ether.\nNone of these exist. This is a problem for the similarity view because\nmodels without targets cannot represent what they seem to represent\nbecause in order for two things to be similar to each other both have\nto exist. If there is no ether, then an ether model cannot be similar\nto the ether.  \nAt least some of these problems can be resolved by taking the very act\nof asserting a specific similarity between a model and a\ntarget as constitutive of the scientific representation. Giere (1988:\n81) suggests that models come equipped with what he calls\n“theoretical hypotheses”, statements asserting that model\nand target are similar in relevant respects and to certain degrees. He\nemphasises that “scientists are intentional agents with goals\nand purposes” (2004: 743) and proposes to build this insight\nexplicitly into an account of representation. This involves adopting\nan agent-based notion of representation that focuses on “the\nactivity of representing” (2004). Analysing representation in\nthese terms amounts to analysing schemes like  \nAgents (1) intend; (2) to use model, \\(M\\); (3) to represent a part of\nthe world \\(W\\); (4) for purposes, \\(P\\). So agents specify which\nsimilarities are intended and for what purpose. (2010: 274)  \n(see also Mäki 2009, 2011; although see Rusanen and Lappi 2012:\n317 for arguments to the contrary). This leads to the following\ndefinition: \nSimilarity 3: A scientific model \\(M\\) represents a target\nsystem \\(T\\) iff there is an agent \\(A\\) who uses \\(M\\) to represent a\ntarget system \\(T\\) by proposing a theoretical hypothesis \\(H\\)\nspecifying a similarity (in certain respects and to certain degrees)\nbetween \\(M\\) and \\(T\\) for purpose \\(P\\).  \nThis version of the similarity view avoids problems with\nmisrepresentation because \\(H\\) being a hypothesis, there is no\nexpectation that the assertions made in \\(H\\) are true. If they are,\nthen the representation is accurate (or the representation is accurate\nto the extent that they hold). If they do not, then the representation\nis a misrepresentation. It also resolves the issue with directionality\nbecause \\(H\\) can be understood as introducing an asymmetry that is\nnot present in the similarity relation. However, it fails to resolve\nthe problem with representation without a target. If there is no\nether, no hypotheses can be asserted about it, at least in any straightforward way. \nSimilarity 3, by invoking an active role for the purposes and\nactions of scientists in constituting scientific representation, marks a\nsignificant change in emphasis for similarity-based accounts.\nSuárez (2003: 226–227), drawing on van Fraassen (2002)\nand Putnam (2002),\ndefines “naturalistic” accounts of representation as ones\nwhere  \nwhether or not representation obtains depends on facts about the world\nand does not in any way answer to the personal purposes, views or\ninterests of enquirers.  \nBy building the purposes of model users directly into an answer to the\nER-problem, Similarity 3 is explicitly not a naturalistic\naccount (in contrast to Similarity 1).  \nEven though Similarity 3 resolves a number of issues that\nbeset simpler versions, it does not seem to be a successful\nsimilarity-based solution to the ER-Problem. A closer look at\nSimilarity 3 reveals that the role of similarity has shifted.\nAs far as offering a solution to the ER-Problem is concerned, all the\nheavy lifting in Similarity 3 is done by the appeal to agents\nand their intentions. Giere implicitly concedes this when he observes\nthat similarity is “the most important way, but probably not the\nonly way” for models to function representationally (2004: 747).\nBut if similarity is not the only way in which a model can be used as\na representation, then similarity has become otiose in a reply to the\nER-problem. In fact, being similar in the relevant respects to the\nrelevant degree now plays the role either of a representational style\nor of a normative criterion for accurate representation, rather than constituting representation per se. We assess in the next\nsection whether similarity offers a cogent reply to the issues of\nstyle and accuracy and raise a further problem for any account of\nscientific representation that relies on the idea that models,\nspecifically non-concrete models, are similar to their targets.  \nThe fact that relevant properties can be delineated in different ways\ncould potentially provide an answer to the Problem of Style. If \\(M\\)\nrepresenting \\(T\\) involves the claim that \\(M\\) and \\(T\\) are similar\nin a certain respect, the respect chosen specifies the style of the\nrepresentation; and if \\(M\\) and \\(T\\) are in fact similar in that\nrespect (and to the specified degree), then \\(M\\) accurately\nrepresents \\(T\\) within that style. For example, if \\(M\\) and \\(T\\)\nare proposed to be similar with respect to their causal structure,\nthen we might have a style of causal modelling; if \\(M\\) and \\(T\\) are\nproposed to be similar with respect to structural properties, then we\nmight have a style of structural modelling; and so on and so forth.\n \nA first step in the direction of such an understanding of styles is\nthe explicit analysis of the notion of similarity. The standard way of\ncashing out what it means for an object to be similar to another\nobject is to require that they co-instantiate properties. In fact,\nthis is the idea that Quine (1969: 117–118) and Goodman (1972:\n443) had in mind in their influential critiques of similarity. The two\nmost prominent formal frameworks that develop this idea are the\ngeometric and contrast accounts (see Decock and Douven 2011 for a\ndiscussion). \nThe geometric account, associated with Shepard (1980), assigns objects\na place in a multidimensional space based on values assigned to their\nproperties. This space is then equipped with a metric and the degree\nof (dis)similarity between two objects is the distance between the\npoints representing the two objects in that space. This account is\nbased on the strong assumptions that values can be assigned to all\nfeatures relevant to similarity judgments, which is deemed unrealistic\n(and to the best of our knowledge no one has developed such an account\nin the context of scientific representation). \nThis problem is supposed to be overcome in Tversky’s contrast\naccount (1977). This account defines a gradated notion of similarity\nbased on a weighted comparison of properties. Weisberg has recently\nintroduced this account into the philosophy of science where it serves\nas the starting point for his weighted feature matching account of\nmodel world-relations (for details see Weisberg 2012, 2013: ch. 8). Although the\naccount has some advantages, questions remain whether it can capture\nthe distinction between what Niiniluoto (1988: 272–274) calls\n“likeness” and “partial identity”. Two objects\nare alike to the extent that they co-instantiate similar properties\n(for example, a red phone box and a red London bus might be alike with\nrespect to their colour, despite not instantiating the exact same\nshade of red). Two objects are partially identical to the extent that\nthey co-instantiate identical properties. As Parker (2015: 273)\nnotes, contrast based accounts of similarity like Weisberg’s\nhave difficulties capturing the former, and this is often pertinent in\nthe context of scientific representation where models and their\ntargets need not co-instantiate the exact same property. \nA further question that remains for someone who uses the notion of\nsimilarity to answer to the Problem of Style and provide standards of\naccuracy in the manner under consideration here is whether it truly\ncaptures all of scientific practice. Similarity theorists are\ncommitted to the claim that whenever a scientific model represents its\ntarget system, this is established in virtue of a model user\nspecifying a relevant similarity, and if the similarity holds, then\nthe representational relationship is accurate. These universal\naspirations require that the notion of similarity invoked capture the\nrelationship that holds between diverse entities such as the\nPhillips-Newlyn machine and an economy, a tube map and an underground\ntrain system, the Lotka-Volterra equations (or phase space associated\nwith them) and predator-prey populations, and so on. Whether all of\nthese relationships can be captured in terms of similarity remains an\nopen question. \nAnother problem facing similarity based approaches concerns their\ntreatment of the ontology of models. If models are supposed to be\nsimilar to their targets in the ways specified by theoretical\nhypotheses, then they must be the kind of things that can be\nso similar. For material models like the San Francisco Bay model\n(Weisberg 2013), ball and stick models of molecules (Toon 2011), the\nPhillips-Newlyn machine (Morgan and Boumans 2004), or model organisms\n(Ankeny and Leonelli 2011) this seems straightforward because they are\nof the same ontological kind as their respective targets. But many\ninteresting scientific models are not like this: they are what Hacking\naptly describes as “something you hold in your head rather than\nyour hands” (1983: 216). Following Thomson-Jones (2012) we call\nsuch models non-concrete models. The question then is how\nsuch models can be similar to their targets. At the very least these\nmodels are “abstract” in the sense that they have no\nspatiotemporal location. But if so, then it remains unclear how they\ncan instantiate the sorts of properties specified by theoretical\nhypotheses, since these properties are typically physical,\nand presumably being located in space and time is a necessary\ncondition on instantiating such properties. For further discussion of\nthis objection, and proposed solutions, see Teller (2001: 399),\nThomson-Jones (2010), and Giere (2009). \nThe structuralist conception of model-representation originated in the\nso-called semantic view of theories that came to prominence in the\nsecond half of the 20th century (see the SEP entry on the\n structure of scientific theories\n for further details). The semantic view was originally proposed as an\naccount of theory structure rather than scientific representation. The\ndriving idea behind the position is that scientific theories are best\nthought of as collections of models. This invites the questions: what\nare these models, and how do they represent their target systems? Most\ndefenders of the semantic view of theories (with the notable exception\nof Giere, whose views on scientific representation were discussed in\nthe previous section) take models to be structures, which represent\ntheir target systems in virtue of there being some kind of\nmorphism (isomorphism, partial isomorphism, homomorphism,\n…) between the two.  \nThis conception has two prima facie advantages. The first\nadvantage is that it offers a straightforward answer to the ER-Problem\n(or SR-problem if the focus is on scientific representation),\nand one that accounts for surrogative reasoning: the mappings between\nthe model and the target allow scientists to convert truths found in\nthe model into claims about the target system. The second advantage\nconcerns the applicability of mathematics. There is time-honoured\nposition in the philosophy of mathematics which sees mathematics as\nthe study of structures; see, for instance Resnik (1997) and Shapiro\n(2000). It is a natural\nmove for the scientific structuralist to adopt this point of view,\nwhich then provides a neat explanation of how mathematics is used in\nscientific modelling.  \nAlmost anything from a concert hall to a kinship system can be\nreferred to as a “structure”. So the first task for a\nstructuralist account of representation is to articulate what notion\nof structure it employs. A number of different notions of structure\nhave been discussed in the literature (for a review see Thomson-Jones\n2011), but by far the most common is the notion of structure one finds\nin set theory and mathematical logic. A structure \\(\\mathcal{S}\\) in\nthat sense (sometimes “mathematical structure” or\n“set-theoretic structure”) is a composite entity\nconsisting of the following: a non-empty set \\(U\\) of objects called\nthe domain (or universe) of the structure and an indexed set \\(R\\) of\nrelations on \\(U\\) (supporters of the partial structures approach,\ne.g., Da Costa and French (2003) and Bueno, French, and Ladyman (2002), use partial \\(n\\)-place\nrelations, for which it may be undefined whether or not some\n\\(n\\)-tuples are in their extension). This definition of structure is\nwidely used in mathematics and logic. We note, however, that in\nmathematical logic structures also contain a language and an\ninterpretation function, interpreting symbols of the language in terms\nof \\(U\\) (see for instance Machover 1996 and Hodges 1997), which is\nabsent from structures in the current context. It is convenient to\nwrite these as \\(\\mathcal{S}= \\langle U, R \\rangle\\), where\n“\\(\\langle \\, , \\rangle\\)” denotes an ordered tuple.  \nIt is important to be clear on what we mean by “object”\nand “relation” in this context. As regards objects, all that matters from a\nstructuralist point of view is that there are so and so many of them.\nWhether the objects are desks or planets is irrelevant. All we need\nare dummies or placeholders whose only property is\n“objecthood”. Similarly, when defining relations one\ndisregards completely what the relation is “in itself”.\nWhether we talk about “being the mother of” or\n“standing to the left of” is of no concern in the context\nof a structure; all that matters is between which objects it holds.\nFor this reason, a relation is specified purely extensionally: as a\nclass of ordered \\(n\\)-tuples. The relation literally is nothing over\nand above this class. So a structure consists of dummy-objects between\nwhich purely extensionally defined relations hold. \nThe first basic posit of the structuralist theory of representation is\nthat models are structures in this sense (the second is that models\nrepresent their targets by being suitably morphic to them; we discuss\nmorphisms in the next subsection). Suppes has articulated this stance\nclearly when he declared that “the meaning of the concept of\nmodel is the same in mathematics and the empirical sciences”\n(1960 [1969]: 12), and many have followed suit. So we are presented\nwith a clear answer to the Problem of Ontology: models are structures.\nThe remaining issue is what structures themselves are. Are they\nPlatonic entities, equivalence classes, modal constructs, or yet\nsomething else? In the context of a discussion of scientific\nrepresentation one can push these questions off to the philosophy of\nmathematics (see the SEP entries on the\n philosophy of mathematics,\n nominalism in the philosophy of mathematics, and\n Platonism in the philosophy of mathematics\n for further details).  \nThe most basic structuralist conception of scientific representation\nasserts that scientific models, understood as structures, represent\ntheir target systems in virtue of being isomorphic to them. An\nisomorphism between two structures \\(\\mathcal{S}\\) and\n\\(\\mathcal{S}'\\) is a bijective function from \\(U\\) to \\(U'\\) that\npreserves the relations on \\(U\\) (and inversely, the relations on\n\\(U'\\)). An isomorphism associates each object in \\(U\\) with an object\nin \\(U'\\) and pairs up each relation in \\(R\\) with a relation in\n\\(R'\\) so that a relation holds between certain objects in \\(U\\) iff\nthe corresponding relation holds between the objects in \\(U'\\) that\nare associated with\n them.[8]\n Assume now that the target system \\(T\\) exhibits the structure\n\\(\\mathcal{S}_T\\) and the model is the structure \\(\\mathcal{S}_M\\).\nThen the model represents the target iff it is isomorphic to the\ntarget: \nStructuralism 1: A scientific model \\(M\\) represents its\ntarget \\(T\\) iff \\(\\mathcal{S}_T\\) is isomorphic to \\(\\mathcal{S}_M\\).\n \nIt bears noting that few adherents of the structuralist account of\nscientific representation, most closely associated with the semantic\nview of theories, explicitly defend this position (although see Ubbink\n1960: 302). Representation was not the focus of attention in the\nsemantic view, and the attribution of (something like)\nStructuralism 1 to its supporters is an extrapolation.\nRepresentation became a much-debated topic in the first decade of the\n21st century, and many proponents of the semantic view then\neither moved away from Structuralism 1, or pointed out that\nthey never held such a view. We turn to more advanced positions\nshortly, but to understand what motivates such positions it is helpful\nto understand why Structuralism 1 fails. \nThe first and most obvious problem is the same as with the similarity\nview: isomorphism is symmetrical and reflexive (and transitive) but representation\nisn’t. This problem could be addressed by replacing isomorphism\nwith an alternative mapping. Bartels (2006), Lloyd (1984), and Mundy\n(1986) suggest homomorphism; van Fraassen (1980, 1997, 2008) and\nRedhead (2001) isomorphic embeddings; advocates of the partial\nstructures approach prefer partial isomophisms (Bueno 1997; Bueno and\nFrench 2011; Da Costa and\nFrench 1990, 2003; French 2003, 2014; French and Ladyman 1999); and\nSwoyer (1991) introduces what he calls \\(\\Delta/\\Psi\\) morphisms. We\nrefer to these collectively as “morphisms”. \nThese suggestions solve some, but not all problems. While many of\nthese mappings are not symmetrical, they are all still reflexive. But\neven if these formal issues could be resolved in one way or another, a\nview based on structural mappings would still face other serious\nproblems. For ease of presentation we discuss these problems in the\ncontext of the isomorphism view; mutatis mutandis other\nformal mappings suffer from the same difficulties. (For detailed\ndiscussions of homomorphism and partial isomorphism see Suárez\n(2003: 239–241) and Pero and Suárez (2016); Mundy (1986)\ndiscusses general constraints one may want to impose on morphisms.)\nLike similarity, isomorphism is too inclusive: not all things that are\nisomorphic represent each other. In the case of similarity this case\nwas brought home by Putnam’s thought experiment with the ant\ncrawling on the beach; in the case of isomorphism a look at the\nhistory of science will do the job. Many mathematical structures were discovered and discussed long before they were used in\nscience. Non-Euclidean geometries were studied by mathematicians long\nbefore Einstein used them in the context of spacetime theories, and\nHilbert spaces were studied by mathematicians prior to their use in\nquantum theory. If representation was nothing over and above\nisomorphism, then we would have to conclude that Riemann discovered\ngeneral relativity or that that Hilbert invented quantum mechanics.\nThis does not seem correct, so it doesn’t seem like isomorphism\non its own establishes scientific representation (Frigg 2002: 10). \nIsomorphism is more restrictive than similarity: not everything is\nisomorphic to everything else. But isomorphism is still too abundant\nto correctly identify what a model represents. The root of the\ndifficulties is that the same structures can be instantiated in\ndifferent kinds of target systems. Certain geometrical structures are\ninstantiated by many different systems; just think about how many\nspherical things we find in the world. The \\(1/r^2\\) law of Newtonian\ngravity is also the “mathematical skeleton” of\nCoulomb’s law of electrostatic attraction and the weakening of\nsound or light as a function of the distance to the source. The\nmathematical structure of the pendulum is also the structure of an\nelectric circuit with a condenser and a solenoid (Kroes 1989). The same\nstructure can be exhibited by more than one kind of target system, and\nso isomorphism by itself is too weak to identify a model’s\ntarget.  \nAs we have seen in the last section, a misrepresentation is one that\nportrays its target as having features it doesn’t have. In the\ncase of a structural account of representation, this means that the\nmodel portrays the target as having structural properties that it\ndoesn’t have. However, isomorphism demands identity of\nstructure: the structural properties of the model and the target must\ncorrespond to one another exactly. So a misrepresentation won’t\nbe isomorphic to the target. By the lights of Structuralism 1\nit is therefore is not a representation at all. Like simple similarity\naccounts, Structuralism 1 conflates misrepresentation with\nnon-representation (Suárez 2003: 234–235). Partial\nstructures can avoid a mismatch due to a target relation being omitted\nin the model and hence go some way to shoring up the structuralist\naccount (Bueno and French 2011: 888). It remains unclear, however, how they accounts for\ndistortive representations (Pincock 2005).  \nFinally, like similarity accounts, Structuralism 1 has a\nproblem with non-existent targets because no model can be isomorphic\nto something that doesn’t exist. If there is no ether, a model\ncan’t be isomorphic to it. Hence models without target cannot\nrepresent what they seem to represent.  \nMost of these problems can be resolved by making moves similar to the\nones that lead to\n Similarity 3:\n introduce agents and hypothetical reasoning into the account of\nrepresentation. Going through the motions one finds: \nStructuralism 2: A scientific model \\(M\\) represents a target\nsystem \\(T\\) iff there is an agent \\(A\\) who uses \\(M\\) to represent a\ntarget system \\(T\\) by proposing a theoretical hypothesis \\(H\\)\nspecifying an isomorphism between \\(\\mathcal{S}_M\\) and\n\\(\\mathcal{S}_T\\).  \nThis is in line with van Fraassen’s recent pronouncements on\nrepresentation. He offers the following as the\n“Hauptstatz” of a theory of representation:\n“There is no representation except in the sense that some\nthings are used, made, or taken, to represent things as thus and\nso” (2008: 23, original emphasis). Likewise, Bueno submits\nthat “representation is an intentional act relating two\nobjects” (2010: 94–95, original emphasis), and Bueno and French point\nout that using one thing to represent another thing is not only a\nfunction of (partial) isomorphism but also depends on\n“pragmatic” factors “having to do with the use to\nwhich we put the relevant models” (2011: 885).  \nAs in the shift from\n Similarity 2\n to\n Similarity 3,\n this seems like a successful move, with many (although not all) of\nthe aforementioned concerns being met. But, again, the role of\nisomorphism has shifted. The crucial ingredient is the agent’s\nintention and isomorphism has in fact become either a representational\nstyle or normative criterion for accurate representation. Let us now\nassess how well isomorphism fares as a response to these problems, and\nthe others outlined above. \nStructuralism’s stand on the Demarcation Problem is by and large\nan open question. Unlike similarity, which has been widely discussed\nacross different domains, structural mappings are tied closely to the\nformal framework of set theory, and have been discussed only sparingly\noutside the context of the mathematized sciences. An exception is\nFrench (2003), who discusses isomorphism accounts in the context of\npictorial representation. He discusses in detail Budd’s (1993)\naccount of pictorial representation and points out that it is based on\nthe notion of a structural isomorphism between the structure of the\nsurface of the painting and the structure of the relevant visual\nfield. Therefore representation is the perceived isomorphism of\nstructure (French 2003: 1475–1476) (this point is reaffirmed by\nBueno and French (2011: 864–865); see Downes (2009: 423–425) for a critical\ndiscussion).  \nThe Problem of Style is to identify representational styles and\ncharacterise them. A proposed structural mapping between the model and\nthe target offers an obvious response to this challenge: one can\nrepresent a system by coming up with a model that is proposed to be\nappropriately morphic to it. This delivers the isomorphism-style, the\nhomomorphism-style, the partial-isomorphism style and so on. We can\ncall these “morphism-styles” when referring to them in\ngeneral. Each of these styles also offers a clear-cut condition of\naccuracy: the representation is accurate if the hypothesised morphism\nholds; it is inaccurate if it doesn’t. \nThis is neat answer. The question is what status it has\nvis-à-vis the Problem of Style. Are morphism-styles\nmerely a subgroup of styles or are they privileged? The former is\nuncontentious. However, the emphasis many structuralists place on\nstructure preserving mappings suggests that they do not regard\nmorphisms as merely one way among others to represent something. What\nthey seem to have in mind is the stronger claim that a representation\nmust be of that sort, or that morphism-styles are the only\nacceptable styles.  \nThis claim seems to conflict with scientific practice in at least two\nrespects. Firstly, many representations are inaccurate (and known to\nbe) in some way. Some models distort, deform and twist properties of\nthe target in ways that seem to undercut isomorphism, or indeed any of\nthe proposed structure preserving mappings. Some models in statistical\nmechanics have an infinite number of particles and the Newtonian model\nof the solar system represents the sun as a perfect sphere where in\nreality it is fiery ball with no well-defined surface at all. It is at\nbest unclear how isomorphism, partial or otherwise, or homomorphism\ncan account for these kinds of idealisations. So it seems that styles\nof representation other than structure preserving mappings have to be\nrecognised. \nSecondly, the structuralist view is a rational reconstruction of\nscientific modelling, and as such it has some distance from the actual\npractice. Some philosophers have worried that this distance is too\nlarge and that the view is too far removed from the actual practice of\nscience to be able to capture what matters to the practice of\nmodelling (this is the thrust of many contributions to Morgan and\nMorrison 1999; see also Cartwright 1999). Although some models used by\nscientists may be best thought of as set theoretic structures, there\nare many where this seems to contradict how scientists actually talk\nabout, and reason with, their models. Obvious examples include\nphysical models like the San Francisco Bay model (Weisberg 2013), but\nalso systems such as the idealized pendulum or imaginary populations\nof interbreeding animals. Such models have the strange property of\nbeing concrete-if-real and scientists talk about them as if\nthey were real systems, despite the fact that they are obviously not\n(Godfrey-Smith 2006). Thomson-Jones (2010) dubs this “face value\npractice”, and there is a question whether structuralism can\naccount for that practice. \nThere remains a final problem to be addressed in the context of\nstructural accounts of scientific representation. Target systems are\nphysical objects: atoms, planets, populations of rabbits, economic\nagents, etc. Isomorphism is a relation that holds between two\nstructures and claiming that a set theoretic structure is isomorphic\nto a piece of the physical world is prima facie a category\nmistake. By definition, a morphism can only hold between two\nstructures. If we are to make sense of the claim that the model is\nisomorphic to its target we have to assume that the target somehow\nexhibits a certain structure \\(\\mathcal{S}_T\\). But what does it mean\nfor a target system—a part of the physical world—to\npossess a structure, and where in the target system is the structure\nlocated?  \nThere are two prominent suggestions in the literature. The first,\noriginally suggested by Suppes (1962 [1969]), is that data models are\nthe target-end structures represented by models. This approach faces a\nquestion whether we should be satisfied with an account of scientific\nrepresentation that precludes phenomena being represented (see Bogen\nand Woodward (1988) for a discussion of the distinction between data\nand phenomena, and Brading and Landry (2006) for a discussion of the\ndistinction in the context of scientific representation). Van Fraassen\n(2008) has addressed this problem and argues for a pragmatic\nresolution: in the context of use, there is no pragmatic difference\nbetween representing phenomena and data extracted from it (see Nguyen\n2016 for a critical discussion). The alternative approach locates the\ntarget-end structure in the target system itself. One version of this\napproach sees structures as being instantiated in target\nsystems. This view seems to be implicit in many versions of the\nsemantic view, and it is explicitly held by authors arguing for a\nstructuralist answer to the problem of the applicability of\nmathematics (Resnik 1997; Shapiro 1997). This approach faces\nunderdetermination issues in that the same target can instantiate\ndifferent structures. The issue can be seen as arising due to there\nbeing alternative descriptions of the system (Frigg 2006) or because a\nversion of “Newman’s Objection” also\nbites in the current context (Newman 1928; see Ainsworth 2009 and\nKetland 2004 for further discussion). A more radical version simply\nidentifies targets with structures (Tegmark 2008). This\napproach is highly revisionary in particular when considering target\nsystems like populations of breeding rabbits or economies. So the\nquestion remains for any structuralist account of scientific\nrepresentation: where are the required target-end structures to be\nfound?  \nThe core idea of the inferential conception is to analyse scientific\nrepresentation in terms of the inferential function of scientific\nmodels. In the previous accounts discussed, a model’s\ninferential capacity dropped out of whatever it was that was supposed\nto answer the ER-problem (or SR-problem): proposed morphisms or\nsimilarity relations between models and their targets for example. The\naccounts discussed in this section reverse this order and explain\nscientific representation directly in terms of surrogative reasoning.  \nAccording to Hughes’ Denotation, Demonstration, and\nInterpretation (DDI) account of scientific representation (1997,\n2010: ch. 5), models denote their targets; are such that\nmodel users can perform demonstrations on them; and\ninterpret the results of such demonstrations in terms of the\ntarget. The last step is necessary because demonstrations establish\nresults about the model itself, and in interpreting these results the\nmodel user draws inferences about the target from the model (1997:\n333). Unfortunately Hughes has little to say about what it means to\ninterpret a result of a demonstration on a model in terms of its\ntarget system, and so one has to retreat to an intuitive (and\nunanalysed) notion of drawing inferences about the target based on the\n model.[9] \nHughes is explicit that he is not attempting to answer the ER-problem,\nand that he does not offer denotation, demonstration, and\ninterpretation as individually necessary and jointly sufficient\nconditions for scientific representation. He prefers the more  \nmodest suggestion that, if we examine a theoretical model with these\nthree activities in mind, we shall achieve some insight into the kind\nof representation that it provides. (1997: 339)  \nThis is unsatisfactory because it ultimately remains unclear what\nallows scientists to use a model to draw inferences about the target,\nand it raises the question of what would have to be added to the DDI\nconditions to turn them into a full-fledged response to the\nER-problem. If, alternatively, the conditions were taken to\nbe necessary and sufficient, then the account would require further\nelaboration on what establishes the conditions.  \nSuárez argues that we should adopt a “deflationary or\nminimalist attitude and strategy” (2004: 770) when addressing\nthe problem of scientific representation. Two different notions of\ndeflationism are in operation in his account. The first is to abandon\nthe aim of seeking necessary and sufficient conditions; necessary\nconditions will be good enough (2004: 771). The second notion is that\nwe should seek “no deeper features to representation other than\nits surface features” (2004:771) or “platitudes”\n(Suárez and Solé 2006: 40), and that we should deny that\nan analysis of a concept “is the kind of analysis that will shed\nexplanatory light on our use of the concept” (Suárez\n2015: 39). Suárez intends his account of scientific representation to be\ndeflationary in both senses, and dubs it “inferentialism”.\nLetting \\(A\\) stand for the model and \\(B\\) for the target, he offers\nthe following analysis: \nInferentialism: “\\(A\\) represents \\(B\\) only if (i) the\nrepresentational force of \\(A\\) points towards \\(B\\), and (ii) \\(A\\)\nallows competent and informed agents to draw specific inferences\nregarding \\(B\\)” (2004: 773).  \nThe first condition addresses the Requirement of Directionality and\nensures that \\(A\\) and \\(B\\) indeed enter into a representational\nrelationship. On might worry that explaining\nrepresentation in terms of representational force sheds little\nlight on the matter as long as no analysis of representational force\nis offered. But Suárez resists attempts to explicate\nrepresentational force in terms of a stronger relation, like\ndenotation or reference, on grounds that this would violate\ndeflationism (2015: 41). The second condition is in fact just the\nSurrogative Reasoning Condition, now taken as a necessary condition on\nscientific representation. But Contessa (2007: 61) points out that it remains mysterious how these inferences are generated. An appeal to further analysis can, again, be blocked by\nappeal to deflationism because any attempt to explicate how inferences\nare drawn would go beyond “surface features”. So the\ntenability of Inferentialism in effect depends on the\ntenability of deflationism about scientific representation. Suárez (2015) defends deflationism\nby drawing analogies with three different deflationary theories about\ntruth, Ramsey’s “redundancy” theory, Wright’s “abstract\nminimalism” and Horwich’s “use theory” (for\nmore information of these theories see the SEP entry on\n the deflationary theory of truth).\n An alternative defence builds on Brandom’s inferentialism in\nthe philosophy of language (1994, 2000), a line of argument that is\ndeveloped in de Donato Rodríguez and Zamora Bonilla (2009). \nInferentialism provides a neat explanation of the possibility\nof misrepresentation because the inferences drawn about a target need\nnot be true (Suárez 2004: 776). In as far as one\naccepts representational force as a cogent concept, targetless models\nare dealt with successfully because representational force (unlike\ndenotation) does not require the existence of a target (2004: 772).\nInferentialism repudiates the Representational Demarcation Problem and\naims to offer an account of representation that also works in other\ndomains such as painting (2004: 777). The account is ontologically\nnon-committal because anything that has an internal structure that\nallows an agent to draw inferences can be a representation. Relatedly,\nsince the account is supposed to apply to a wide variety of entities\nincluding equations and mathematical structures, the account implies\nthat mathematics is successfully applied in the sciences, but in\nkeeping with the spirit of deflationism no explanation is offered\nabout how this is possible. The account does not directly address the\nProblem of Style. \nIn response to the difficulties with Inferentialism Contessa\nsubmits that “it is not clear why we should adopt a deflationary\nattitude from the start” (2007: 50) and provides a\n“interpretational account” of scientific representation\nthat is inspired by Suárez’s account, but without being\ndeflationary. Contessa introduces the notion of an\ninterpretation of a model, in terms of its target system, as a\nnecessary and sufficient condition on epistemic representation (see\nalso Ducheyne 2012 for a related account): \nInterpretation: “A [model \\(M\\)] is an epistemic\nrepresentation of a certain target [\\(T\\)] (for a certain user) if and\nonly if the user adopts an interpretation of the [\\(M\\)] in terms of\n[\\(T\\)].” (Contessa 2007: 57; see also Contessa 2011:\n126–127)  \nThe leading idea of an interpretation is that the model user first\nidentifies sets of relevant objects in the model and the target, and then pins down\nsets of properties and relations these objects instantiate both in the\nmodel and the target. The user then (a) takes \\(M\\) to denote \\(T\\);\n(b) takes every identified object in the model to denote exactly one\nobject in the target (and every relevant object in the target has to\nbe so denoted); (c) takes every property and relation in the model to\ndenote a property or relation of the same type in the target (and,\nagain, and every property and relation in the target has to be so\ndenoted). A formal rendering of these conditions is what Contessa\ncalls an “analytic interpretation” (see his 2007:\n57–62 for details; he also includes an additional condition\npertaining to functions in the model and target, which we suppress for\nbrevity). \nInterpretation offers a neat answer to the ER-problem. The\naccount also explains the directionality of representation:\ninterpreting a model in terms of a target does not entail interpreting\na target in terms of a model. However, it has been noted that\nInterpretation has difficulty accounting for the possibility\nof misrepresentation, since it seems to require that the relevant\nobjects, properties, and relations actually exist in the target (Shech\n2015) (although this objection turns on a very strict reading of\nContessa’s account). Contessa does not comment on the\napplicability of mathematics but since his account shares with the\nstructuralist account an emphasis on relations and one-to-one\nmodel-target correspondence, Contessa can appeal to the same account\nof the applicability of mathematics as the structuralist. Like\nSuárez, Contessa takes his account to be universal and apply\nto non-scientific representations such as portraits and maps. But it\nremains unclear how Interpretation addresses the Problem of\nStyle. As we have seen earlier, in particular visual representations\nfall into different categories. It is a question for future research\nhow these can be classified within the interpretational framework.\nWith respect to the Question of Ontology, Interpretation\nitself places few constraints on what scientific models are,\nontologically speaking. All it requires is that they consist of\nobjects, properties, relations, and functions (but see Contessa (2010)\nfor further discussion of what he takes models to be, ontologically\nspeaking). \nA recent family of approaches analyses models by drawing an analogy\nbetween models and literary fiction. This analogy can be used in two\nways, yielding two different version of the fiction view. The first is\nprimarily motivated by ontological considerations rather than the\nquestion of scientific representation per se. Scientific\ndiscourse is rife with passages that appear to be descriptions of\nsystems in a particular discipline, and the pages of textbooks and\njournals are filled with discussions of the properties and the\nbehaviour of those systems. In mechanics, for instance, the dynamical\nproperties of a system consisting of three spinning spheres with\nhomogenous mass distributions are the focus of attention, in biology\ninfinite populations are investigated, and in economics perfectly\nrational agents with access to perfect information exchange goods.\nTheir surface structure notwithstanding, no one would mistake\ndescriptions of such systems as descriptions of an actual\nsystem: we know very well that there are no such systems. \nThomson-Jones (2010: 284) refers to such a description as a\n“description of a missing system”. These descriptions are\nembedded in what he calls the “face value practice” (2010:\n285) the practice of talking and thinking about these systems as if\nthey were real. The face-value practice raises a number of questions.\nWhat account should be given of these descriptions and what sort of\nobjects, if any, do they describe? Are we putting forward\ntruth-evaluable claims when putting forward descriptions of missing\nsystems? \nThe fiction view of models provides an answer: models are akin to\nplaces and characters in literary fiction and claims about them are\ntrue or false in the same way in which claims about these places and\ncharacters are true or false. Such a position has been recently\ndefended explicitly by some authors (Frigg 2010a,b; Godfrey-Smith\n2006), but not without opposition (Giere 2009; Magnani 2012). It does bear\nnoting that the analogy has been around for a while (Cartwright 1983;\nMcCloskey 1990; Vaihinger 1911 [1924]). This leaves the thorny issue\nof how to analyse fictional places and characters. Here philosophers of science\ncan draw on discussions from aesthetics to fill in the details about\nthese questions (Friend 2007 and Salis 2013 provide useful\nreviews). \nThe second version of the fiction view explicitly focuses on\nrepresentation. Most theories of representation we have encountered so\nfar posit that there are model systems and construe scientific\nrepresentation as a relation between two entities, the model system\nand the target system. Toon calls this the indirect view of\nrepresentation (2012: 43). Indeed, Weisberg views this indirectness as\nthe defining feature of modelling (2007). This view contrasts with\nwhat Toon (2012: 43) and Levy (2015: 790) call a direct view\nof representation. This view does not recognise model systems and aims\ninstead to explain representation as a form of direct description. On\nthis view, models provide an “imaginative\ndescription of real things” (Levy 2012: 741) such as actual\npendula, and there is no such thing as a model system of which the\npendulum description is literally true (Toon 2012: 43–44).  \nToon articulates the direct view by drawing on Walton’s (1990)\ntheory of make-believe. At the heart of this theory is the notion of a\ngame of make-believe (see the SEP entry on\n imagination\n for further discussion). We play such a game if, for instance, when\nwalking through a forest we imagine that stumps are bears and if we\nspot a stump we imagine that we spot a bear. In Walton’s\nterminology the stumps are props, and the rule that we\nimagine a bear when we see a stump is a principle of\ngeneration. Together a prop and principle of generation prescribe\nwhat is to be imagined. Walton considers a vast variety of different\nprops, including statues and works of literary fiction. Toon focuses\non the particular kind of game in which we are prescribed to imagine\nsomething of a real world object. A statue showing Napoleon on\nhorseback (Toon 2012: 37) is a prop mandating us to imagine, for\ninstance, that Napoleon has a certain physiognomy and certain facial\nexpressions. When reading The War of the Worlds (2012: 39) we\nare prescribed to imagine that the dome of St Paul’s Cathedral\nhas been attacked by aliens and now has a gaping hole on its western\nside.  \nThe crucial move is to say that models are props in games of make\nbelieve. Specifically, material models are like the statue of Napoleon\nand theoretical models are like the text of The War of the\nWorlds: both prescribe, in their own way, to imagine something\nabout a real object. A ball-and-stick model of a methane molecule\nprescribes us to imagine particular things about methane, and a model\ndescription describing a point mass bob bouncing on a perfectly\nelastic spring represents the real ball and spring system by\nprescribing imaginings about the real system. This provides the\nfollowing answer to the ER-problem (Toon 2012: 62):  \nDirect Representation: \\(M\\) is a scientific representation\nof \\(T\\) iff \\(M\\) functions as prop in game of make-believe which\nprescribes imaginings about \\(T\\).  \nThis account solves some of the problems posed in\n Section 1: Direct Representation is asymmetrical, makes room for\nmisrepresentation, and, given its roots in aesthetics, it renounces\nthe Demarcation Problem. The view absolves the Problem of Ontology\nsince models are either physical objects or descriptions, neither or\nwhich are problematic in this context. Toon remains silent on both the\nProblem of Style, and the applicability of mathematics.  \nImportant questions remain. According to Direct\nRepresentation models prescribe us to imagine certain things\nabout their target system. The account remains silent, however, on the\nrelationship between what a model prescribes us to imagine and what a\nmodel user should actually infer about the target system, and so it\noffers no answer to the ER-problem. Levy (2015) identifies this as a\ngap in Toon’s account and proposes to fill it by invoking\nYablo’s (2014) notion of “partial truth”, the idea\nbeing that a model user should take the imagined propositions to be\npartially true of their target systems. However, as Levy admits, there\nare other sorts of cases that don’t fit the mould, most notably\ndistortive idealisations. These require a different treatment and\nit’s an open question what this treatment would be.  \nA further worry is how Direct Representation deals with\ntargetless models. If there is no target system, then what does the\nmodel prescribe imaginings about? Toon is well aware of such models\nand suggests the following solution: if a model has no target it\nprescribes imaginings about a fictional character (2012: 76). This\nsolution, however, comes with ontological costs, and one of the\ndeclared aims of the direct view was to avoid such costs by removing\nmodel systems from the picture. Levy (2015) aims to salvage\nontological parsimony and proposes a radical move: there are no\ntargetless models. If a (purported) model has no target then it is not\na model. There remains a question, however, how this view can be\nsquared with scientific practice where targetless models are not only\ncommon but also clearly acknowledged as such.  \nIn Goodman’s (1976)\naccount of aesthetic representation the idea is that a work of art\ndoes not just denote its subject, but moreover it represents it as\nbeing thus or so (see the SEP entry on\n Goodman’s aesthetics\n for further discussion). Elgin (2010) further developed this account\nand, crucially, suggested that it also applies to scientific\nrepresentations. We first discuss Goodman and Elgin’s notion of\nrepresentation-as and then consider a recent extension of their\nframework. \nMany instances of epistemic representation are instances of what\nGoodman and Elgin call “representation-as”. Caricatures\nare paradigmatic examples: Churchill is represented as a bulldog and\nThatcher is represented as a boxer. But the notion is more general:\nHolbein’s Portrait of Henry VIII represents Henry as\nimposing and powerful and Stoddart’s statue of David Hume\nrepresents him as thoughtful and wise. Using these representations we\ncan learn about their targets, for example we can learn about a\npolitician’s or philosopher’s personality. The leading\nidea of the views discussed in this section is that scientific\nrepresentation works in much the same way. A model of the solar system\nrepresents it as consisting of perfect spheres; the logistic model of\ngrowth represents the population as reproducing at fixed intervals of\ntime; and so on. In each instance, models can be used to attempt to\nlearn about their targets by determining what the former represent the\nlatter as being.  \nThe locution of representation-as functions in the following way: an\nobject \\(X\\) (e.g., a picture, statue, or model) represents a subject\n\\(Y\\) (e.g., a person or target system) as being thus or so \\((Z)\\).\nThe question then is what establishes this sort of representational\nrelationship. The answer requires introducing some of the concepts\nGoodman and Elgin use to develop their account of\nrepresentation-as. \nGoodman and Elgin draw a distinction between something being a\nrepresentation of a \\(Z\\), and something being a \\(Z\\)-representation\n(Elgin 2010: 1–2; Goodman 1976: 21–26). A painting of a unicorn is a unicorn-representation because it shows a unicorn, but it is not a\nrepresentation of a unicorn because there are no unicorns. Being a\n\\(Z\\)-representation is a one-place predicate that categorises\nrepresentations according to their subject matter. Being a\nrepresentation of something is established by denotation; it\nis a binary relation that holds between a symbol and the object which\nit denotes. The two can, but need not, coincide. Some\ndog-representations are representations of dogs, but not all are\n(e.g., a caricature of Churchill), and not all representations of dogs\nare dog-representations (e.g., a lightening bolt may represent the\nfastest greyhound at the races).  \nThe next notion is exemplification: an object \\(X\\)\nexemplifies a property \\(P\\) iff \\(X\\) instantiates \\(P\\) and thereby\nrefers back to \\(P\\) (Goodman 1976: 53). In the current context properties are to be\nunderstood in the widest possible sense. An item can exemplify\none-place properties, multi-place properties (i.e., relations), higher\norder properties, structural properties, etc. Paradigmatic examples of\nthis are samples. A chip of paint on a manufacturer’s sample\ncard instantiates a certain colour and at the same time refers to that\ncolour (Elgin 1983: 71). Notice that instantiation is necessary but\ninsufficient for exemplification: the sample card does not exemplify\nbeing rectangular for example. When a object exemplifies a\nproperty it provides us with epistemic access to that property. \nRepresentation-as is then established by combining these notions\ntogether: a \\(Z\\)-representation exemplifies properties associated\nwith\n \\(Z\\)s,[10]\n and if the \\(Z\\)-representation additionally denotes \\(Y\\), then\nthese properties can be imputed onto \\(Y\\) (cf. Elgin 2010: 10). This\nprovides the following account of epistemic representation: \nRepresentation-As: \\(X\\) is an epistemic representation of\n\\(Y\\) iff (i) \\(X\\) denotes \\(Y\\), (ii) \\(X\\) is a\n\\(Z\\)-representation exemplifying properties \\(P_1, \\ldots , P_n\\),\nand (iii) \\(X\\) imputes \\(P_1, \\ldots , P_n\\), or related properties,\nonto \\(Y\\).  \nApplying this in the scientific context, i.e., by letting \\(X\\) range\nover models and \\(Y\\) over target systems, we arrive at an answer to\nthe ER-problem. Representation-As also answers the other\nproblems introduced in\n Section 1:\n it repudiates the demarcation problem and it explains the\ndirectionality of representation. It accounts for surrogative\nreasoning in terms of the properties imputed to the target. If\n\\(Y\\) possesses the imputed properties then the representation is accurate, but\nsince the target doesn’t necessarily need to instantiate them it\nallows for the possibility of misrepresentation. Different styles can\nbe accounted for by categorising representations in terms of different\n\\(Z\\)s, or in terms of the properties they exemplify. However, at\nleast as stated, the account remains silent on the problem of ontology\nand the applicability of mathematics. We discuss below how to account\nfor targetless models. \n\n Representation-As\n raises a number of questions when applied in the scientific context.\nThe first concerns the notion of a \\(Z\\)-representation. While it has\nintuitive appeal in the case of pictures, it is less clear how it\nworks in the context of science. Phillips and Newlyn constructed an\nelaborate system of pipes and tanks to model an economy (see Morgan\nand Boumans 2004 for a useful discussion). So the machine is an\neconomy-representation. But what turns a system of pipes and tanks\ninto an economy-representation?  \nFrigg and Nguyen (2016: 227–8)\nargue that in order to turn an object \\(X\\) into a scientific model,\nit must be interpreted in the appropriate way (note that they do not\nuse “interpretation” in the way that Contessa uses it, as\ndiscussed above): properties that \\(X\\) has, qua object, are paired up with\nrelevant \\(Z\\) properties and for quantitative properties, i.e.,\nproperties such as mass or flow, which take numerical values, there\nneeds to a further association between the values of the \\(X\\)\nproperty and the values of the \\(Z\\) property to which it is mapped.\nIn the case of the Phillips-Newlyn machine, for example, hydraulic\nproperties of the machine are associated with economic properties and a\nrule is given specifying that a litre of water corresponds to certain\namount of a model-economy’s currency. The \\(X\\) and \\(Z\\)\nproperties that are so associated need not exhaust the properties that\n\\(X\\) instantiates, nor do all possible \\(Z\\) properties need be\nassociated with an \\(X\\) property. \n\n\nA scientific model can then be defined as a \\(Z\\)-representation,\ni.e., an object under an interpretation. This notion of a model\nexplicitly does not presuppose a target system and hence makes room\nfor targetless models. Models can then be seen as instantiating\n\\(Z\\)-properties under the relevant interpretation, which\nexplains how the model can exemplify such properties. \nThe next issue is that exemplified properties are rarely exactly\nimputed onto target systems. According to\n Representation-As\n the imputed properties are either the ones exemplified by the\n\\(Z\\)-representation, “or related ones”. Frigg and Nguyen (2016: 228),\nbuilding on Frigg (2010a: 125–135), prefer to be explicit about\nthe relationship between the exemplified properties and the ones to be\nimputed onto the target. They do this by introducing a\n“key”, which explicitly associates the\nexemplified properties with properties to be imputed onto the target.\nFor example, in the case of a London Tube map, the key associates\nparticular colours with particular tube lines, and in the case of\nidealisations the key associates de-idealised properties with\nmodel-properties.  \nGathering the various pieces together leads to the following account\nof representation (Frigg and Nguyen 2016: 229): \nDEKI: Let \\(M = \\langle X, I \\rangle\\) be a model, where \\(X\\) is an\nobject and \\(I\\) an interpretation. Let \\(T\\) be the target system.\n\\(M\\) represents \\(T\\) as \\(Z\\) iff all of the following conditions are\nsatisfied: \n\\(M\\) is a scientific representation of \\(T\\) iff \\(M\\) represents\n\\(T\\) as \\(Z\\) as defined in (i)–(iv). \nThe moniker “DEKI” highlights the account’s key\nfeatures: denotation, exemplification, keying-up and imputation.\nDEKI answers the problems from\n Section 1\n in much the same way as\n Representation-As\n did. However, it adds to the latter in at least three ways. Firstly,\nthe conditions given make it clear what makes scientific models\n\\(Z\\)-representations in the first place: interpretations. Secondly,\nit makes explicit that the properties exemplified by the model need\nnot be imputed exactly onto the target, and highlights the need to\ninvestigate keys specifying the relationship between properties in\nmodels and the properties that models actually impute onto their\ntargets. Finally, it makes explicit how to account for targetless\nmodels. A scientific model that fails to denote a target system can\nnevertheless be a \\(Z\\)-representation. A model of a bridge that is\nnever built is still a bridge-representation, which exemplifies\nproperties related to bridges (stability and so on), despite the fact that\nit is not a representation of anything. However, as in the case of\n Representation-As\n questions remain with respect to the problem of ontology and the\napplicability of mathematics. ","contact.mail":"r.p.frigg@lse.ac.uk","contact.domain":"lse.ac.uk"},{"date.published":"2016-10-10","url":"https://plato.stanford.edu/entries/scientific-representation/","author1":"Roman Frigg","author1.info":"http://www.lse.ac.uk/collections/philosophyLogicAndScientificMethod/WhosWho/staffhomepages/frigg.htm","author2.info":"http://personal.lse.ac.uk/NGUYENJ1/","entry":"scientific-representation","body.text":"\n\n\nScience provides us with representations of atoms, elementary\nparticles, polymers, populations, genetic trees, economies, rational\ndecisions, aeroplanes, earthquakes, forest fires, irrigation systems,\nand the world’s climate. It’s through these\nrepresentations that we learn about the world. This entry explores\nvarious different accounts of scientific representation, with a\nparticular focus on how scientific models represent their\ntarget systems. As philosophers of science are increasingly\nacknowledging the importance, if not the primacy, of scientific models\nas representational units of science, it’s important to stress\nthat how they represent plays a fundamental role in how we are to\nanswer other questions in the philosophy of science (for instance in the\nscientific realism debate). This entry begins by disentangling\n“the” problem of scientific representation, and then \ncritically evaluates the current options available in the\nliterature.\n\nIn most general terms, any representation that is the product of a\nscientific endeavour is a scientific representation. These\nrepresentations are a heterogeneous group comprising anything from\nthermometer readings and flow charts to verbal descriptions,\nphotographs, X-ray pictures, digital imagery, equations, models, and\ntheories. How do these representations work? \nThe first thing that strikes the novice in the debate about scientific\nrepresentation is that there seems to be little agreement about what\nthe problem is. Different authors frame the problem of scientific\nrepresentation in different ways, and eventually they examine\ndifferent issues. So a discussion of scientific representation has to\nbegin with a clarification of the problem itself. Reviewing the\nliterature on the subject leads us to the conclusion that there is no\nsuch thing as the problem of scientific\nrepresentation—in fact there are at least five different\nproblems concerning scientific representation. In this section we\nformulate these problems and articulate five conditions of adequacy\nthat every account of scientific representation has to satisfy.  \n\nThe first problem is: what turns something into a scientific representation of something else? It has become customary to phrase\nthis problem in terms of necessary and sufficient conditions and ask: what fills the blank in “\\(S\\) is\na scientific representation of \\(T\\) iff ___”, where\n“\\(S\\)” stands for the object doing the representing and\n“\\(T\\)” for “target system”, the part or\naspect of the world the representation is about?[1] Let us call this the\nScientific Representation Problem (or SR-Problem for\nshort).  \nA number of contributors to the debate have emphasised that scientific\nrepresentation is an intentional concept, depending on factors such as\na user’s intentions, purposes and objectives, contextual\nstandards of accuracy, and intended audiences (see, for instance,\nGiere 2010; Mäki 2011; Suárez 2004; and van Fraassen\n2008). We will discuss these in detail below. At this point it needs\nto be emphasised that framing the problem in terms of a biconditional\ndoes not preclude such factors to be part of the analysis. One might\nworry that the above formulation presupposes that representation is an\nintrinsic relation between \\(S\\) and \\(T\\), i.e., a relation that only\ndepends on intrinsic properties of \\(S\\) and \\(T\\). This is a\nmisapprehension. The blank can be filled with a \\((n+2)\\)-ary relation\n\\(C(S, T, x_1, \\ldots, x_n)\\) (\\(C\\) for “constitutes”), where \\(n \\ge 0\\) is a natural number\nand the \\(x_i\\) are factors such as intentions and purposes. \nA first important condition of adequacy on any reply to this problem\nis that scientific representations allow us to form hypotheses about\ntheir target systems. An X-ray picture provides information about the\nbones of the patient, and models allow investigators to discover\nfeatures of the things models stands for. Every acceptable theory of\nscientific representation has to account for how reasoning conducted\non representations can yield claims about their target systems. Swoyer\n(1991: 449) refers to this kind of representation-based thinking as\n“surrogative reasoning” and so we call this the\nSurrogative Reasoning\n Condition.[2]\n This condition distinguishes models from lexicographical and\nindexical representations, which do not allow for surrogative\nreasoning. \nUnfortunately this condition does not constrain answers sufficiently\nbecause any account of representation that fills the blank in a way\nthat satisfies the surrogative reasoning condition will almost\ninvariably also cover other kinds of representations. Speed camera\nphotographs give the police information about drivers breaking the\nlaw, a cardboard model of the palace instructs us about its layout and\nproportions, and a weather map shows you where to expect rain, and therefore\nare likely to fall under an account of representation that explains\nsurrogative reasoning. Hence, representations other than scientific\nrepresentations also allow for surrogative reasoning, which raises the\nquestion: how do scientific representations differ from other kinds of\nrepresentations that allow for surrogative reasoning? Callender and\nCohen (2006: 68–69) point out that this is a version\nPopper’s demarcation problem, now phrased in terms of\nrepresentation, and so we refer to it as the Representational\nDemarcation Problem.  \nCallender and Cohen voice scepticism about there being a solution to\nthis problem and suggest that the distinction between scientific and\nnon-scientific representations is circumstantial (2006: 83):\nscientific representations are representations that are used or\ndeveloped by someone who is a scientist. Other authors do not\nexplicitly discuss the representational demarcation problem, but\nstances similar to Callender and Cohen’s are implicit in any\napproach that analyses scientific representation alongside other kinds\nof representation. Elgin (2010), French (2003), Frigg (2006), Hughes\n(1997), Suárez (2004), and van Fraassen (2008), for instance,\nall draw parallels between scientific and pictorial representation,\nwhich would make little sense if pictorial and scientific\nrepresentation were categorically different. \nThose who reject the notion that there is an essential difference\nbetween scientific and non-scientific representation can follow a\nsuggestion of Contessa’s (2007) and broaden the scope of the\ninvestigation. Rather than analysing scientific representation, they\ncan analyse the broader category of epistemic representation.\nThis category comprises scientific representations, but it also\nincludes other representations that allow for surrogative reasoning.\nThe task then becomes to fill the blank in “\\(S\\) is an\nepistemic representation of \\(T\\) iff ___”. We call this the\nEpistemic Representation Problem (ER-Problem, for\nshort), and the biconditional the ER-Scheme. So one can say\nthat the ER-Problem is to fill the blank in the ER-Scheme. \nNot all representations are of the same kind, not even if we restrict\nour attention to scientific representations (assuming they are found\nto be relevantly different to non-scientific epistemic\nrepresentations). An X-ray photograph represents an ankle joint in a\ndifferent way than a biomechanical model, a mercury thermometer\nrepresent the temperature of gas in a different way than statistical\nmechanics does, and chemical theory represents a C60 fullerene in\ndifferent way that an electron-microscope image of the molecule. Even\nwhen restricting attention to the same kind of representation, there\nare important differences: Weizsäcker’s liquid drop model,\nfor instance, represents the nucleus of an atom in a manner that seems\nto be different from the one of the shell model, and an electric\ncircuit model represents the brain function in a different way than a\nneural network model. In brief, there seem to be different\nrepresentational styles. This raises the question: what styles are\nthere and how can they be\n characterised?[3]\n We call this the Problem of\n Style.[4]\n There is no expectation that a complete list of styles be\nprovided in response. Indeed, it is unlikely that such a list can ever\nbe drawn up, and new styles will be invented as science progresses.\nFor this reason a response to the problem of style will always be\nopen-ended, providing a taxonomy of what is currently available while\nleaving room for later additions. \nSome representations are accurate; others aren’t. The quantum\nmechanical model is an accurate representation of the atom (at least by our current lights) but the\nThomson model isn’t. On what grounds do we make such judgments?\nMorrison (2008: 70) reminds us that it is a task for theory of\nrepresentation to identify what constitutes an accurate\nrepresentation. We call this the problem of Standards of\nAccuracy. Providing such standards is one of the issues an account of representation has to address.  \nThis problem goes hand in hand with a condition of adequacy: the\nPossibility of Misrepresentation. Asking what makes a\nrepresentation an accurate representation ipso facto\npresupposes that inaccurate representations are representations too.\nAnd this is how it should be. If \\(S\\) does not accurately represent\n\\(T\\), then it is a misrepresentation but not a non-representation. It\nis therefore a general constraint on a theory of scientific\nrepresentation that it has to make misrepresentation possible (see\nFrigg 2002: 16–17; Suárez 2003: 233–235; Contessa\n2007; and van Fraassen 2008: 13–15). \nA related condition concerns models that misrepresent in the sense\nthat they lack target systems. Models of ether, phlogiston, four-sex\npopulations, and so on, are all deemed scientific models, but ether,\nphlogiston, and four-sex populations don’t exist. Such models\nlack (actual) target systems, and one hopes that an account of\nscientific representation would allow us to understand how these\nmodels work. This need not imply the claim that they are representations in the same\nsense as models with actual targets, and, as we discuss below, there are\naccounts that deny targetless models the status of being\nrepresentations. \nA further condition of adequacy for an account of scientific representation\nis that it must account for the directionality of representation. As\nGoodman points out (1976: 5), representations are about their targets, but (at least\nin general) targets are not about their representations: a photograph\nrepresents the cracks in the wing of aeroplane, but the wing does not\nrepresent the photograph. So there is an essential directionality to\nrepresentations, and an account of scientific, or epistemic, representation has to\nidentify the root of this directionality. We call this the\nRequirement of Directionality. \nSome representations, in particular models and theories, are\nmathematized and their mathematical aspects are crucial to their\ncognitive and representational function. This forces us to reconsider\na time-honoured philosophical puzzle: the applicability of mathematics\nin the empirical sciences. The problem can be traced back at least to\nPlato’s Timaeus, but its modern expression is due to\nWigner who challenged us to find an explanation for the enormous\nusefulness of mathematics in the sciences (1960: 2). The question how\na mathematized model represents its target implies the question how\nmathematics applies to a physical system (see Pincock 2012 for an\nexplicit discussion of the relationship between scientific\nrepresentation and the applicability of mathematics). For this reason,\nour fifth and final condition of adequacy is that an account of\nrepresentation has to explain how mathematics is applied to the\nphysical world. We call this the Applicability of Mathematics\nCondition. \nIn answering the above questions one invariably runs up against a\nfurther problem, the Problem of Ontology: what kinds of\nobjects are representations? If representations are material objects\nthe answer is straightforward: photographic plates, pieces of paper\ncovered with ink, elliptical blocks of wood immersed in water, and so\non. But not all representations are like this. As Hacking (1983: 216)\nputs it, some representations one holds in one’s head rather\nthan one’s hands. The Newtonian model of the solar system, the\nLotka-Volterra model of predator-prey interaction and the general\ntheory of relativity are not things you can put on your laboratory\ntable and look at. The problem of ontology is to come clear on our\ncommitments and provide a list with things that we recognise—or\ndon’t recognise—as entities performing a representational\nfunction and give an account of what they are in case these entities\nraise questions (what exactly do we mean by something that one holds\nin one’s head rather than one’s hands?). Contessa (2010),\nFrigg (2010a,b), Godfrey-Smith (2006), Levy (2015), Thomson-Jones\n(2010), Weisberg (2013), among others, have drawn attention to this\nproblem in different ways.  \nIn sum, a theory of scientific representation has to respond to the\nfollowing issues: \nAny satisfactory answer to these five issues will have to meet the\nfollowing five conditions of adequacy: \nListing the problems in this way is not to say that these are separate\nand unrelated issues. This division is analytical, not factual. It\nserves to structure the discussion and to assess proposals; it does\nnot imply that an answer to one of these questions can be dissociated\nfrom what stance we take on the other issues.  \nAny attempt to tackle these questions faces an immediate\nmethodological problem. As per the problem of style, there are\ndifferent kinds of representations: scientific models, theories,\nmeasurement outcomes, images, graphs, diagrams, and linguistic\nassertions are all scientific representations, and even within these \ngroups there can be considerable variation. But every analysis has\nto start somewhere, and so the problem is where. One might adopt a\nuniversalist position, holding that the diversity of styles dissolves\nunder analysis and at bottom all instances of scientific/epistemic\nrepresentation function in the same way and are covered by the same\noverarching account. For such a universalist the problem loses its teeth\nbecause any starting point will lead to the same result. Those of\nparticularist bent deny that there is such a theory. They will first\ndivide the scientific/epistemic representations into relevant\nsubclasses and then analyse each subclass separately.  \nDifferent authors assume different stances in this debate, and we will\ndiscuss their positions below. However, there are few, if any,\nthoroughgoing universalists and so a review like the current one has\nto discuss different cases. Unfortunately space constraints prevent us\nfrom examining all the different varieties of scientific/epistemic\nrepresentation, and a selection has to be made. This invariably leads\nto the neglect of some kinds of representations, and the best we can\ndo about this is to be explicit about our choices. We resolve to\nconcentrate on scientific models, and therefore replace our variable \\(S\\) for the object doing the representing with the variable \\(M\\) for model.\nThis is in line both with the more\nrecent literature on scientific representation, which is predominantly\nconcerned with scientific models, and with the prime importance that\ncurrent philosophy of science attaches to models (see the SEP entry on\n models in science\n for a\n survey).[5] \nIt is, however, worth briefly mentioning some of the omissions that\nthis brings with it. Various types of images have their place in\nscience, and so do graphs, diagrams, and drawings. Perini (2010) and\nElkins (1999) provide discussions of visual representation in science.\nMeasurements also supply representations of processes in nature,\nsometimes together with the subsequent condensation of measurement\nresults in the form of charts, curves, tables and the like (see the\nSEP entry on\n measurement in science).\n Furthermore, theories represent their subject matter. At this point\nthe vexing problem of the nature of theories rears again (see the SEP\nentry on\n the structure of scientific theories\n and also Portides (forthcoming) for an extensive discussion).\nProponents of the semantic view of theories construe theories as\nfamilies of models, and so for them the question of how theories\nrepresent coincides with the question of how models represent. By\ncontrast, those who regard theories as linguistic entities see\ntheoretical representation as a special kind of linguistic\nrepresentation and focus on the analysis of scientific languages, in\nparticular the semantics of so-called theoretical terms (see the SEP\nentry on\n theoretical terms in science). \nBefore delving into the discussion a common misconception needs to be\ndispelled. The misconception is that a representation is a mirror\nimage, a copy, or an imitation of the thing it represents. On this\nview representation is ipso facto realistic representation.\nThis is a mistake. Representations can be realistic, but they need\nnot. And representations certainly need not be copies of the real\nthing (an observation exploited by Lewis Carroll and Jorge Luis Borges\nin their satires, Sylvie and Bruno and On Exactitude in\nScience respectively, about cartographers who produce maps as\nlarge as the country itself only to see them abandoned). Throughout\nthis review we encounter positions that make room for non-realistic\nrepresentation and hence testify to the fact that representation is a\nmuch broader notion than\n mirroring.[6] \nCallender and Cohen (2006) give a radical answer to the demarcation\nproblem: there is no difference between scientific representations and\nother kinds of representations, not even between scientific and\nartistic representation. Underlying this claim is a position they call\n“General Griceanism” (GG). The core of GG is the reductive\nclaim that all representations owe their status as representations to\na privileged core of fundamental representations. GG then comes with a\npractical prescription about how to proceed with the analysis of a\nrepresentation:  \nthe General Gricean view consists of two stages. First, it explains\nthe representational powers of derivative representations in terms of\nthose of fundamental representations; second, it offers some other\nstory to explain representation for the fundamental bearers of\ncontent. (2006: 73)  \nOf these stages only the second requires serious philosophical work,\nand this work is done in the philosophy of mind because the\nfundamental form of representation is mental representation. \nScientific representation is a derivative kind of representation\n(2006: 71, 75) and hence falls under the first stage of the above\nrecipe. It is reduced to mental representation by an act of\nstipulation. In Callender and Cohen’s own example, the salt\nshaker on the dinner table can represent Madagascar as long as someone\nstipulates that the former represents the latter, since  \nthe representational powers of mental states are so wide-ranging that\nthey can bring about other representational relations between\narbitrary relata by dint of mere stipulation. (2006: 73–74)  \nSo explaining any form of representation other than mental\nrepresentation is a triviality—all it takes is an act of\n“stipulative fiat” (2006: 75). This supplies an answer to\nthe ER-problem: \nStipulative Fiat: A scientific model \\(M\\) represents a\ntarget system \\(T\\) iff a model user stipulates that \\(M\\) represents\n\\(T\\).  \nThe first problem facing Stipulative Fiat is whether or not\nstipulation, or the bare intentions of language users, suffice to\nestablish representational relationships. In the philosophy of\nlanguage this gets called the “Humpty Dumpty” problem. It\nconcerns whether or not Lewis Carroll’s Humpty Dumpty could use\nthe word “glory” to mean “a nice knockdown\nargument” (Donnellan 1968; MacKay 1968). (We ignore the\ndifference between meaning and denotation here). In that context it\ndoesn’t seem like he can, and analogous questions can be posed\nin the context of scientific representation: can a scientist make any\nmodel represent any target simply by stipulating that it does? \nEven if stipulation were sufficient to establish some sort of\nrepresentational relationship, Stipulative Fiat fails to meet\nthe Surrogative Reasoning Condition: assuming a salt shaker represents\nMadagascar in virtue of someone’s stipulation that this is so,\nthis tells us nothing about how the salt shaker could be used to learn\nabout Madagascar in the way that scientific models are used to learn\nabout their targets (Liu 2015: 46–47, for a related objection see Bueno and French\n2011: 871–873). And\nappealing to additional facts about the salt shaker (the salt shaker\nbeing to the right of the pepper mill might allow us to infer that\nMadagascar is to the east of Mozambique) in order to answer this\nobjection goes beyond Stipulative Fiat. Callender and Cohen\ndo admit some representations are more useful than others, but claim\nthat  \nthe questions about the utility of these representational vehicles are\nquestions about the pragmatics of things that are representational\nvehicles, not questions about their representational status per\nse. (2006: 75)  \nBut even if the Surrogative Reasoning Condition is relegated to the\nrealm of “pragmatics” it seems reasonable to ask for an\naccount of how it is met.  \nAn important thing to note is that even if Stipulative Fiat\nis untenable, we needn’t give up on GG. GG only requires that\nthere be some explanation of how derivative representations\nrelate to fundamental representations; it does not require that this\nexplanation be of a particular kind, much less that it consist in\nnothing but an act of stipulation (Toon 2010: 77–78). As\nCallender and Cohen note, all that it requires is that there is a\nprivileged class of representations and that other types of\nrepresentations owe their representational capacities to their\nrelationship with the primitive ones. So philosophers need an account\nof how members of this privileged class of representations represent,\nand how derivative representations, which includes scientific models,\nrelate to this class. When stated like this, many recent contributors\nto the debate on scientific representation can be seen as falling\nunder the umbrella of GG. Indeed, As we will see below, many of the\nmore developed versions of the accounts of scientific representation\ndiscussed throughout this entry invoke the intentions of model users,\nalbeit in a more complex manner than Stipulative Fiat. \nSimilarity and representation initially appear to be two closely\nrelated concepts, and invoking the former to ground the latter has a\nphilosophical lineage stretching back at least as far as Plato’s\nThe\n Republic.[7]\n In its most basic guise the similarity conception of scientific\nrepresentation asserts that scientific models represent their targets\nin virtue of being similar to them. This conception has universal\naspirations in that it is taken to account for representation across a\nbroad range of different domains. Paintings, statues, and drawings are\nsaid to represent by being similar to their subjects, and Giere\nproclaimed that it covers scientific models alongside “words,\nequations, diagrams, graphs, photographs, and, increasingly,\ncomputer-generated images” (2004: 243). So the similarity view\nrepudiates the demarcation problem and submits that the same\nmechanism, namely similarity, underpins different kinds of\nrepresentation in a broad variety of contexts. \nThe view also offers an elegant account of surrogative reasoning.\nSimilarities between model and target can be exploited to carry over\ninsights gained in the model to the target. If the similarity between\n\\(M\\) and \\(T\\) is based on shared properties, then a property found\nin \\(M\\) would also have to be present in \\(T\\); and if the similarity\nholds between properties themselves, then \\(T\\) would have to\ninstantiate properties similar to \\(M\\). \nHowever, appeal to similarity in the context of representation leaves\nopen whether similarity is offered as an answer to the ER-Problem, the\nProblem of Style, or whether it is meant to set Standards of Accuracy.\nProponents of the similarity conception typically have offered little\nguidance on this issue. So we examine each option in turn and ask\nwhether similarity offers a viable answer. We then turn to the\nquestion of how the similarity view deals with the Problem of\nOntology. \nUnderstood as response to the ER-Problem, the simplest similarity view\nis the following:  \nSimilarity 1: A scientific model \\(M\\) represents a target\n\\(T\\) iff \\(M\\) and \\(T\\) are similar.  \nA well-known objection to this account is that similarity has the\nwrong logical properties. Goodman (1976: 4–5) points out that similarity is\nsymmetric and reflexive yet representation isn’t. If object\n\\(A\\) is similar to object \\(B\\), then \\(B\\) is similar to \\(A\\). But\nif \\(A\\) represents \\(B\\), then \\(B\\) need not (and in fact in most\ncases does not) represent \\(A\\). Everything is similar to itself, but\nmost things do not represent themselves. So this account does not meet\nour fourth condition of adequacy for an account of scientific\nrepresentation insofar as it does not provide a direction to\nrepresentation. \nHowever, there are accounts of similarity under which similarity is not a symmetric relation (see Tversky 1977; Weisberg 2012, 2013: ch. 8; and Poznic 2016:\nsec. 4.2). This raises the question of how to analyse similarity. We\nturn to this issue in the next subsection. However, even if we concede\nthat similarity need not always be symmetrical, this does not solve\nGoodman’s problem with reflexivity; nor does it, as we will see,\nsolve other problems of the similarity account. \nThe most significant problem facing Similarity 1 is that\nwithout constraints on what counts as similar, any two things can be\nconsidered similar (Aronson et al. 1995: 21; Goodman 1972:\n443–444). This, however, has the unfortunate consequence that\nanything represents anything else. A natural response to this\ndifficulty is to delineate a set of relevant respects and degrees to\nwhich \\(M\\) and \\(T\\) have to be similar. This idea can be moulded\ninto the following definition: \nSimilarity 2: A scientific model \\(M\\) represents a target\n\\(T\\) iff \\(M\\) and \\(T\\) are similar in relevant respects and to the\nrelevant degrees.  \nOn this definition one is free to choose one’s respects and\ndegrees so that unwanted similarities drop out of the picture. While\nthis solves the last problem, it leaves the problem of logical\nproperties untouched: similarity in relevant respects and to the\nrelevant degrees is reflexive (and symmetrical, depending on\none’s notion of similarity). Moreover, Similarity 2\nfaces three further problems. \nFirstly, similarity, even restricted to relevant similarities, is too\ninclusive a concept to account for representation. In many cases\nneither one of a pair of similar objects represents the other. This\npoint has been brought home in now-classical thought experiment due to\nPutnam (1981: 1–3). An ant is crawling on a patch of sand and\nleaves a trace that happens to resemble Winston Churchill. Has the ant\nproduced a picture, a representation, of Churchill? Putnam’s\nanswer is that it didn’t because the ant has never seen\nChurchill, had no intention to produce an image of him, was not\ncausally connected to Churchill, and so on. Although someone else\nmight see the trace as a depiction of Churchill, the trace itself does\nnot represent Churchill. The fact that the trace is similar to\nChurchill does not suffice to establish that the trace represents him.\nAnd what is true of the trace and Churchill is true of every other\npair of similar items: even relevant similarity on its own does not\nestablish representation. \nSecondly, as noted in\n Section 1,\n allowing for the possibility of misrepresentation is a key desiderata\nrequired of any account of scientific representation. In the context\nof a similarity conception it would seem that a misrepresentation is\none that portrays its target as having properties that are not similar\nin the relevant respects and to the relevant degree to the true\nproperties of the target. But then, on Similarity 2, \\(M\\) is\nnot a representation at all. The account thus has difficulty\ndistinguishing between misrepresentation and non-representation\n(Suárez 2003: 233–235). \nThirdly, there may simply be nothing to be similar to because some\nrepresentations represent no actual object. Some paintings represent\nelves and dragons, and some models represent phlogiston and the ether.\nNone of these exist. This is a problem for the similarity view because\nmodels without targets cannot represent what they seem to represent\nbecause in order for two things to be similar to each other both have\nto exist. If there is no ether, then an ether model cannot be similar\nto the ether.  \nAt least some of these problems can be resolved by taking the very act\nof asserting a specific similarity between a model and a\ntarget as constitutive of the scientific representation. Giere (1988:\n81) suggests that models come equipped with what he calls\n“theoretical hypotheses”, statements asserting that model\nand target are similar in relevant respects and to certain degrees. He\nemphasises that “scientists are intentional agents with goals\nand purposes” (2004: 743) and proposes to build this insight\nexplicitly into an account of representation. This involves adopting\nan agent-based notion of representation that focuses on “the\nactivity of representing” (2004). Analysing representation in\nthese terms amounts to analysing schemes like  \nAgents (1) intend; (2) to use model, \\(M\\); (3) to represent a part of\nthe world \\(W\\); (4) for purposes, \\(P\\). So agents specify which\nsimilarities are intended and for what purpose. (2010: 274)  \n(see also Mäki 2009, 2011; although see Rusanen and Lappi 2012:\n317 for arguments to the contrary). This leads to the following\ndefinition: \nSimilarity 3: A scientific model \\(M\\) represents a target\nsystem \\(T\\) iff there is an agent \\(A\\) who uses \\(M\\) to represent a\ntarget system \\(T\\) by proposing a theoretical hypothesis \\(H\\)\nspecifying a similarity (in certain respects and to certain degrees)\nbetween \\(M\\) and \\(T\\) for purpose \\(P\\).  \nThis version of the similarity view avoids problems with\nmisrepresentation because \\(H\\) being a hypothesis, there is no\nexpectation that the assertions made in \\(H\\) are true. If they are,\nthen the representation is accurate (or the representation is accurate\nto the extent that they hold). If they do not, then the representation\nis a misrepresentation. It also resolves the issue with directionality\nbecause \\(H\\) can be understood as introducing an asymmetry that is\nnot present in the similarity relation. However, it fails to resolve\nthe problem with representation without a target. If there is no\nether, no hypotheses can be asserted about it, at least in any straightforward way. \nSimilarity 3, by invoking an active role for the purposes and\nactions of scientists in constituting scientific representation, marks a\nsignificant change in emphasis for similarity-based accounts.\nSuárez (2003: 226–227), drawing on van Fraassen (2002)\nand Putnam (2002),\ndefines “naturalistic” accounts of representation as ones\nwhere  \nwhether or not representation obtains depends on facts about the world\nand does not in any way answer to the personal purposes, views or\ninterests of enquirers.  \nBy building the purposes of model users directly into an answer to the\nER-problem, Similarity 3 is explicitly not a naturalistic\naccount (in contrast to Similarity 1).  \nEven though Similarity 3 resolves a number of issues that\nbeset simpler versions, it does not seem to be a successful\nsimilarity-based solution to the ER-Problem. A closer look at\nSimilarity 3 reveals that the role of similarity has shifted.\nAs far as offering a solution to the ER-Problem is concerned, all the\nheavy lifting in Similarity 3 is done by the appeal to agents\nand their intentions. Giere implicitly concedes this when he observes\nthat similarity is “the most important way, but probably not the\nonly way” for models to function representationally (2004: 747).\nBut if similarity is not the only way in which a model can be used as\na representation, then similarity has become otiose in a reply to the\nER-problem. In fact, being similar in the relevant respects to the\nrelevant degree now plays the role either of a representational style\nor of a normative criterion for accurate representation, rather than constituting representation per se. We assess in the next\nsection whether similarity offers a cogent reply to the issues of\nstyle and accuracy and raise a further problem for any account of\nscientific representation that relies on the idea that models,\nspecifically non-concrete models, are similar to their targets.  \nThe fact that relevant properties can be delineated in different ways\ncould potentially provide an answer to the Problem of Style. If \\(M\\)\nrepresenting \\(T\\) involves the claim that \\(M\\) and \\(T\\) are similar\nin a certain respect, the respect chosen specifies the style of the\nrepresentation; and if \\(M\\) and \\(T\\) are in fact similar in that\nrespect (and to the specified degree), then \\(M\\) accurately\nrepresents \\(T\\) within that style. For example, if \\(M\\) and \\(T\\)\nare proposed to be similar with respect to their causal structure,\nthen we might have a style of causal modelling; if \\(M\\) and \\(T\\) are\nproposed to be similar with respect to structural properties, then we\nmight have a style of structural modelling; and so on and so forth.\n \nA first step in the direction of such an understanding of styles is\nthe explicit analysis of the notion of similarity. The standard way of\ncashing out what it means for an object to be similar to another\nobject is to require that they co-instantiate properties. In fact,\nthis is the idea that Quine (1969: 117–118) and Goodman (1972:\n443) had in mind in their influential critiques of similarity. The two\nmost prominent formal frameworks that develop this idea are the\ngeometric and contrast accounts (see Decock and Douven 2011 for a\ndiscussion). \nThe geometric account, associated with Shepard (1980), assigns objects\na place in a multidimensional space based on values assigned to their\nproperties. This space is then equipped with a metric and the degree\nof (dis)similarity between two objects is the distance between the\npoints representing the two objects in that space. This account is\nbased on the strong assumptions that values can be assigned to all\nfeatures relevant to similarity judgments, which is deemed unrealistic\n(and to the best of our knowledge no one has developed such an account\nin the context of scientific representation). \nThis problem is supposed to be overcome in Tversky’s contrast\naccount (1977). This account defines a gradated notion of similarity\nbased on a weighted comparison of properties. Weisberg has recently\nintroduced this account into the philosophy of science where it serves\nas the starting point for his weighted feature matching account of\nmodel world-relations (for details see Weisberg 2012, 2013: ch. 8). Although the\naccount has some advantages, questions remain whether it can capture\nthe distinction between what Niiniluoto (1988: 272–274) calls\n“likeness” and “partial identity”. Two objects\nare alike to the extent that they co-instantiate similar properties\n(for example, a red phone box and a red London bus might be alike with\nrespect to their colour, despite not instantiating the exact same\nshade of red). Two objects are partially identical to the extent that\nthey co-instantiate identical properties. As Parker (2015: 273)\nnotes, contrast based accounts of similarity like Weisberg’s\nhave difficulties capturing the former, and this is often pertinent in\nthe context of scientific representation where models and their\ntargets need not co-instantiate the exact same property. \nA further question that remains for someone who uses the notion of\nsimilarity to answer to the Problem of Style and provide standards of\naccuracy in the manner under consideration here is whether it truly\ncaptures all of scientific practice. Similarity theorists are\ncommitted to the claim that whenever a scientific model represents its\ntarget system, this is established in virtue of a model user\nspecifying a relevant similarity, and if the similarity holds, then\nthe representational relationship is accurate. These universal\naspirations require that the notion of similarity invoked capture the\nrelationship that holds between diverse entities such as the\nPhillips-Newlyn machine and an economy, a tube map and an underground\ntrain system, the Lotka-Volterra equations (or phase space associated\nwith them) and predator-prey populations, and so on. Whether all of\nthese relationships can be captured in terms of similarity remains an\nopen question. \nAnother problem facing similarity based approaches concerns their\ntreatment of the ontology of models. If models are supposed to be\nsimilar to their targets in the ways specified by theoretical\nhypotheses, then they must be the kind of things that can be\nso similar. For material models like the San Francisco Bay model\n(Weisberg 2013), ball and stick models of molecules (Toon 2011), the\nPhillips-Newlyn machine (Morgan and Boumans 2004), or model organisms\n(Ankeny and Leonelli 2011) this seems straightforward because they are\nof the same ontological kind as their respective targets. But many\ninteresting scientific models are not like this: they are what Hacking\naptly describes as “something you hold in your head rather than\nyour hands” (1983: 216). Following Thomson-Jones (2012) we call\nsuch models non-concrete models. The question then is how\nsuch models can be similar to their targets. At the very least these\nmodels are “abstract” in the sense that they have no\nspatiotemporal location. But if so, then it remains unclear how they\ncan instantiate the sorts of properties specified by theoretical\nhypotheses, since these properties are typically physical,\nand presumably being located in space and time is a necessary\ncondition on instantiating such properties. For further discussion of\nthis objection, and proposed solutions, see Teller (2001: 399),\nThomson-Jones (2010), and Giere (2009). \nThe structuralist conception of model-representation originated in the\nso-called semantic view of theories that came to prominence in the\nsecond half of the 20th century (see the SEP entry on the\n structure of scientific theories\n for further details). The semantic view was originally proposed as an\naccount of theory structure rather than scientific representation. The\ndriving idea behind the position is that scientific theories are best\nthought of as collections of models. This invites the questions: what\nare these models, and how do they represent their target systems? Most\ndefenders of the semantic view of theories (with the notable exception\nof Giere, whose views on scientific representation were discussed in\nthe previous section) take models to be structures, which represent\ntheir target systems in virtue of there being some kind of\nmorphism (isomorphism, partial isomorphism, homomorphism,\n…) between the two.  \nThis conception has two prima facie advantages. The first\nadvantage is that it offers a straightforward answer to the ER-Problem\n(or SR-problem if the focus is on scientific representation),\nand one that accounts for surrogative reasoning: the mappings between\nthe model and the target allow scientists to convert truths found in\nthe model into claims about the target system. The second advantage\nconcerns the applicability of mathematics. There is time-honoured\nposition in the philosophy of mathematics which sees mathematics as\nthe study of structures; see, for instance Resnik (1997) and Shapiro\n(2000). It is a natural\nmove for the scientific structuralist to adopt this point of view,\nwhich then provides a neat explanation of how mathematics is used in\nscientific modelling.  \nAlmost anything from a concert hall to a kinship system can be\nreferred to as a “structure”. So the first task for a\nstructuralist account of representation is to articulate what notion\nof structure it employs. A number of different notions of structure\nhave been discussed in the literature (for a review see Thomson-Jones\n2011), but by far the most common is the notion of structure one finds\nin set theory and mathematical logic. A structure \\(\\mathcal{S}\\) in\nthat sense (sometimes “mathematical structure” or\n“set-theoretic structure”) is a composite entity\nconsisting of the following: a non-empty set \\(U\\) of objects called\nthe domain (or universe) of the structure and an indexed set \\(R\\) of\nrelations on \\(U\\) (supporters of the partial structures approach,\ne.g., Da Costa and French (2003) and Bueno, French, and Ladyman (2002), use partial \\(n\\)-place\nrelations, for which it may be undefined whether or not some\n\\(n\\)-tuples are in their extension). This definition of structure is\nwidely used in mathematics and logic. We note, however, that in\nmathematical logic structures also contain a language and an\ninterpretation function, interpreting symbols of the language in terms\nof \\(U\\) (see for instance Machover 1996 and Hodges 1997), which is\nabsent from structures in the current context. It is convenient to\nwrite these as \\(\\mathcal{S}= \\langle U, R \\rangle\\), where\n“\\(\\langle \\, , \\rangle\\)” denotes an ordered tuple.  \nIt is important to be clear on what we mean by “object”\nand “relation” in this context. As regards objects, all that matters from a\nstructuralist point of view is that there are so and so many of them.\nWhether the objects are desks or planets is irrelevant. All we need\nare dummies or placeholders whose only property is\n“objecthood”. Similarly, when defining relations one\ndisregards completely what the relation is “in itself”.\nWhether we talk about “being the mother of” or\n“standing to the left of” is of no concern in the context\nof a structure; all that matters is between which objects it holds.\nFor this reason, a relation is specified purely extensionally: as a\nclass of ordered \\(n\\)-tuples. The relation literally is nothing over\nand above this class. So a structure consists of dummy-objects between\nwhich purely extensionally defined relations hold. \nThe first basic posit of the structuralist theory of representation is\nthat models are structures in this sense (the second is that models\nrepresent their targets by being suitably morphic to them; we discuss\nmorphisms in the next subsection). Suppes has articulated this stance\nclearly when he declared that “the meaning of the concept of\nmodel is the same in mathematics and the empirical sciences”\n(1960 [1969]: 12), and many have followed suit. So we are presented\nwith a clear answer to the Problem of Ontology: models are structures.\nThe remaining issue is what structures themselves are. Are they\nPlatonic entities, equivalence classes, modal constructs, or yet\nsomething else? In the context of a discussion of scientific\nrepresentation one can push these questions off to the philosophy of\nmathematics (see the SEP entries on the\n philosophy of mathematics,\n nominalism in the philosophy of mathematics, and\n Platonism in the philosophy of mathematics\n for further details).  \nThe most basic structuralist conception of scientific representation\nasserts that scientific models, understood as structures, represent\ntheir target systems in virtue of being isomorphic to them. An\nisomorphism between two structures \\(\\mathcal{S}\\) and\n\\(\\mathcal{S}'\\) is a bijective function from \\(U\\) to \\(U'\\) that\npreserves the relations on \\(U\\) (and inversely, the relations on\n\\(U'\\)). An isomorphism associates each object in \\(U\\) with an object\nin \\(U'\\) and pairs up each relation in \\(R\\) with a relation in\n\\(R'\\) so that a relation holds between certain objects in \\(U\\) iff\nthe corresponding relation holds between the objects in \\(U'\\) that\nare associated with\n them.[8]\n Assume now that the target system \\(T\\) exhibits the structure\n\\(\\mathcal{S}_T\\) and the model is the structure \\(\\mathcal{S}_M\\).\nThen the model represents the target iff it is isomorphic to the\ntarget: \nStructuralism 1: A scientific model \\(M\\) represents its\ntarget \\(T\\) iff \\(\\mathcal{S}_T\\) is isomorphic to \\(\\mathcal{S}_M\\).\n \nIt bears noting that few adherents of the structuralist account of\nscientific representation, most closely associated with the semantic\nview of theories, explicitly defend this position (although see Ubbink\n1960: 302). Representation was not the focus of attention in the\nsemantic view, and the attribution of (something like)\nStructuralism 1 to its supporters is an extrapolation.\nRepresentation became a much-debated topic in the first decade of the\n21st century, and many proponents of the semantic view then\neither moved away from Structuralism 1, or pointed out that\nthey never held such a view. We turn to more advanced positions\nshortly, but to understand what motivates such positions it is helpful\nto understand why Structuralism 1 fails. \nThe first and most obvious problem is the same as with the similarity\nview: isomorphism is symmetrical and reflexive (and transitive) but representation\nisn’t. This problem could be addressed by replacing isomorphism\nwith an alternative mapping. Bartels (2006), Lloyd (1984), and Mundy\n(1986) suggest homomorphism; van Fraassen (1980, 1997, 2008) and\nRedhead (2001) isomorphic embeddings; advocates of the partial\nstructures approach prefer partial isomophisms (Bueno 1997; Bueno and\nFrench 2011; Da Costa and\nFrench 1990, 2003; French 2003, 2014; French and Ladyman 1999); and\nSwoyer (1991) introduces what he calls \\(\\Delta/\\Psi\\) morphisms. We\nrefer to these collectively as “morphisms”. \nThese suggestions solve some, but not all problems. While many of\nthese mappings are not symmetrical, they are all still reflexive. But\neven if these formal issues could be resolved in one way or another, a\nview based on structural mappings would still face other serious\nproblems. For ease of presentation we discuss these problems in the\ncontext of the isomorphism view; mutatis mutandis other\nformal mappings suffer from the same difficulties. (For detailed\ndiscussions of homomorphism and partial isomorphism see Suárez\n(2003: 239–241) and Pero and Suárez (2016); Mundy (1986)\ndiscusses general constraints one may want to impose on morphisms.)\nLike similarity, isomorphism is too inclusive: not all things that are\nisomorphic represent each other. In the case of similarity this case\nwas brought home by Putnam’s thought experiment with the ant\ncrawling on the beach; in the case of isomorphism a look at the\nhistory of science will do the job. Many mathematical structures were discovered and discussed long before they were used in\nscience. Non-Euclidean geometries were studied by mathematicians long\nbefore Einstein used them in the context of spacetime theories, and\nHilbert spaces were studied by mathematicians prior to their use in\nquantum theory. If representation was nothing over and above\nisomorphism, then we would have to conclude that Riemann discovered\ngeneral relativity or that that Hilbert invented quantum mechanics.\nThis does not seem correct, so it doesn’t seem like isomorphism\non its own establishes scientific representation (Frigg 2002: 10). \nIsomorphism is more restrictive than similarity: not everything is\nisomorphic to everything else. But isomorphism is still too abundant\nto correctly identify what a model represents. The root of the\ndifficulties is that the same structures can be instantiated in\ndifferent kinds of target systems. Certain geometrical structures are\ninstantiated by many different systems; just think about how many\nspherical things we find in the world. The \\(1/r^2\\) law of Newtonian\ngravity is also the “mathematical skeleton” of\nCoulomb’s law of electrostatic attraction and the weakening of\nsound or light as a function of the distance to the source. The\nmathematical structure of the pendulum is also the structure of an\nelectric circuit with a condenser and a solenoid (Kroes 1989). The same\nstructure can be exhibited by more than one kind of target system, and\nso isomorphism by itself is too weak to identify a model’s\ntarget.  \nAs we have seen in the last section, a misrepresentation is one that\nportrays its target as having features it doesn’t have. In the\ncase of a structural account of representation, this means that the\nmodel portrays the target as having structural properties that it\ndoesn’t have. However, isomorphism demands identity of\nstructure: the structural properties of the model and the target must\ncorrespond to one another exactly. So a misrepresentation won’t\nbe isomorphic to the target. By the lights of Structuralism 1\nit is therefore is not a representation at all. Like simple similarity\naccounts, Structuralism 1 conflates misrepresentation with\nnon-representation (Suárez 2003: 234–235). Partial\nstructures can avoid a mismatch due to a target relation being omitted\nin the model and hence go some way to shoring up the structuralist\naccount (Bueno and French 2011: 888). It remains unclear, however, how they accounts for\ndistortive representations (Pincock 2005).  \nFinally, like similarity accounts, Structuralism 1 has a\nproblem with non-existent targets because no model can be isomorphic\nto something that doesn’t exist. If there is no ether, a model\ncan’t be isomorphic to it. Hence models without target cannot\nrepresent what they seem to represent.  \nMost of these problems can be resolved by making moves similar to the\nones that lead to\n Similarity 3:\n introduce agents and hypothetical reasoning into the account of\nrepresentation. Going through the motions one finds: \nStructuralism 2: A scientific model \\(M\\) represents a target\nsystem \\(T\\) iff there is an agent \\(A\\) who uses \\(M\\) to represent a\ntarget system \\(T\\) by proposing a theoretical hypothesis \\(H\\)\nspecifying an isomorphism between \\(\\mathcal{S}_M\\) and\n\\(\\mathcal{S}_T\\).  \nThis is in line with van Fraassen’s recent pronouncements on\nrepresentation. He offers the following as the\n“Hauptstatz” of a theory of representation:\n“There is no representation except in the sense that some\nthings are used, made, or taken, to represent things as thus and\nso” (2008: 23, original emphasis). Likewise, Bueno submits\nthat “representation is an intentional act relating two\nobjects” (2010: 94–95, original emphasis), and Bueno and French point\nout that using one thing to represent another thing is not only a\nfunction of (partial) isomorphism but also depends on\n“pragmatic” factors “having to do with the use to\nwhich we put the relevant models” (2011: 885).  \nAs in the shift from\n Similarity 2\n to\n Similarity 3,\n this seems like a successful move, with many (although not all) of\nthe aforementioned concerns being met. But, again, the role of\nisomorphism has shifted. The crucial ingredient is the agent’s\nintention and isomorphism has in fact become either a representational\nstyle or normative criterion for accurate representation. Let us now\nassess how well isomorphism fares as a response to these problems, and\nthe others outlined above. \nStructuralism’s stand on the Demarcation Problem is by and large\nan open question. Unlike similarity, which has been widely discussed\nacross different domains, structural mappings are tied closely to the\nformal framework of set theory, and have been discussed only sparingly\noutside the context of the mathematized sciences. An exception is\nFrench (2003), who discusses isomorphism accounts in the context of\npictorial representation. He discusses in detail Budd’s (1993)\naccount of pictorial representation and points out that it is based on\nthe notion of a structural isomorphism between the structure of the\nsurface of the painting and the structure of the relevant visual\nfield. Therefore representation is the perceived isomorphism of\nstructure (French 2003: 1475–1476) (this point is reaffirmed by\nBueno and French (2011: 864–865); see Downes (2009: 423–425) for a critical\ndiscussion).  \nThe Problem of Style is to identify representational styles and\ncharacterise them. A proposed structural mapping between the model and\nthe target offers an obvious response to this challenge: one can\nrepresent a system by coming up with a model that is proposed to be\nappropriately morphic to it. This delivers the isomorphism-style, the\nhomomorphism-style, the partial-isomorphism style and so on. We can\ncall these “morphism-styles” when referring to them in\ngeneral. Each of these styles also offers a clear-cut condition of\naccuracy: the representation is accurate if the hypothesised morphism\nholds; it is inaccurate if it doesn’t. \nThis is neat answer. The question is what status it has\nvis-à-vis the Problem of Style. Are morphism-styles\nmerely a subgroup of styles or are they privileged? The former is\nuncontentious. However, the emphasis many structuralists place on\nstructure preserving mappings suggests that they do not regard\nmorphisms as merely one way among others to represent something. What\nthey seem to have in mind is the stronger claim that a representation\nmust be of that sort, or that morphism-styles are the only\nacceptable styles.  \nThis claim seems to conflict with scientific practice in at least two\nrespects. Firstly, many representations are inaccurate (and known to\nbe) in some way. Some models distort, deform and twist properties of\nthe target in ways that seem to undercut isomorphism, or indeed any of\nthe proposed structure preserving mappings. Some models in statistical\nmechanics have an infinite number of particles and the Newtonian model\nof the solar system represents the sun as a perfect sphere where in\nreality it is fiery ball with no well-defined surface at all. It is at\nbest unclear how isomorphism, partial or otherwise, or homomorphism\ncan account for these kinds of idealisations. So it seems that styles\nof representation other than structure preserving mappings have to be\nrecognised. \nSecondly, the structuralist view is a rational reconstruction of\nscientific modelling, and as such it has some distance from the actual\npractice. Some philosophers have worried that this distance is too\nlarge and that the view is too far removed from the actual practice of\nscience to be able to capture what matters to the practice of\nmodelling (this is the thrust of many contributions to Morgan and\nMorrison 1999; see also Cartwright 1999). Although some models used by\nscientists may be best thought of as set theoretic structures, there\nare many where this seems to contradict how scientists actually talk\nabout, and reason with, their models. Obvious examples include\nphysical models like the San Francisco Bay model (Weisberg 2013), but\nalso systems such as the idealized pendulum or imaginary populations\nof interbreeding animals. Such models have the strange property of\nbeing concrete-if-real and scientists talk about them as if\nthey were real systems, despite the fact that they are obviously not\n(Godfrey-Smith 2006). Thomson-Jones (2010) dubs this “face value\npractice”, and there is a question whether structuralism can\naccount for that practice. \nThere remains a final problem to be addressed in the context of\nstructural accounts of scientific representation. Target systems are\nphysical objects: atoms, planets, populations of rabbits, economic\nagents, etc. Isomorphism is a relation that holds between two\nstructures and claiming that a set theoretic structure is isomorphic\nto a piece of the physical world is prima facie a category\nmistake. By definition, a morphism can only hold between two\nstructures. If we are to make sense of the claim that the model is\nisomorphic to its target we have to assume that the target somehow\nexhibits a certain structure \\(\\mathcal{S}_T\\). But what does it mean\nfor a target system—a part of the physical world—to\npossess a structure, and where in the target system is the structure\nlocated?  \nThere are two prominent suggestions in the literature. The first,\noriginally suggested by Suppes (1962 [1969]), is that data models are\nthe target-end structures represented by models. This approach faces a\nquestion whether we should be satisfied with an account of scientific\nrepresentation that precludes phenomena being represented (see Bogen\nand Woodward (1988) for a discussion of the distinction between data\nand phenomena, and Brading and Landry (2006) for a discussion of the\ndistinction in the context of scientific representation). Van Fraassen\n(2008) has addressed this problem and argues for a pragmatic\nresolution: in the context of use, there is no pragmatic difference\nbetween representing phenomena and data extracted from it (see Nguyen\n2016 for a critical discussion). The alternative approach locates the\ntarget-end structure in the target system itself. One version of this\napproach sees structures as being instantiated in target\nsystems. This view seems to be implicit in many versions of the\nsemantic view, and it is explicitly held by authors arguing for a\nstructuralist answer to the problem of the applicability of\nmathematics (Resnik 1997; Shapiro 1997). This approach faces\nunderdetermination issues in that the same target can instantiate\ndifferent structures. The issue can be seen as arising due to there\nbeing alternative descriptions of the system (Frigg 2006) or because a\nversion of “Newman’s Objection” also\nbites in the current context (Newman 1928; see Ainsworth 2009 and\nKetland 2004 for further discussion). A more radical version simply\nidentifies targets with structures (Tegmark 2008). This\napproach is highly revisionary in particular when considering target\nsystems like populations of breeding rabbits or economies. So the\nquestion remains for any structuralist account of scientific\nrepresentation: where are the required target-end structures to be\nfound?  \nThe core idea of the inferential conception is to analyse scientific\nrepresentation in terms of the inferential function of scientific\nmodels. In the previous accounts discussed, a model’s\ninferential capacity dropped out of whatever it was that was supposed\nto answer the ER-problem (or SR-problem): proposed morphisms or\nsimilarity relations between models and their targets for example. The\naccounts discussed in this section reverse this order and explain\nscientific representation directly in terms of surrogative reasoning.  \nAccording to Hughes’ Denotation, Demonstration, and\nInterpretation (DDI) account of scientific representation (1997,\n2010: ch. 5), models denote their targets; are such that\nmodel users can perform demonstrations on them; and\ninterpret the results of such demonstrations in terms of the\ntarget. The last step is necessary because demonstrations establish\nresults about the model itself, and in interpreting these results the\nmodel user draws inferences about the target from the model (1997:\n333). Unfortunately Hughes has little to say about what it means to\ninterpret a result of a demonstration on a model in terms of its\ntarget system, and so one has to retreat to an intuitive (and\nunanalysed) notion of drawing inferences about the target based on the\n model.[9] \nHughes is explicit that he is not attempting to answer the ER-problem,\nand that he does not offer denotation, demonstration, and\ninterpretation as individually necessary and jointly sufficient\nconditions for scientific representation. He prefers the more  \nmodest suggestion that, if we examine a theoretical model with these\nthree activities in mind, we shall achieve some insight into the kind\nof representation that it provides. (1997: 339)  \nThis is unsatisfactory because it ultimately remains unclear what\nallows scientists to use a model to draw inferences about the target,\nand it raises the question of what would have to be added to the DDI\nconditions to turn them into a full-fledged response to the\nER-problem. If, alternatively, the conditions were taken to\nbe necessary and sufficient, then the account would require further\nelaboration on what establishes the conditions.  \nSuárez argues that we should adopt a “deflationary or\nminimalist attitude and strategy” (2004: 770) when addressing\nthe problem of scientific representation. Two different notions of\ndeflationism are in operation in his account. The first is to abandon\nthe aim of seeking necessary and sufficient conditions; necessary\nconditions will be good enough (2004: 771). The second notion is that\nwe should seek “no deeper features to representation other than\nits surface features” (2004:771) or “platitudes”\n(Suárez and Solé 2006: 40), and that we should deny that\nan analysis of a concept “is the kind of analysis that will shed\nexplanatory light on our use of the concept” (Suárez\n2015: 39). Suárez intends his account of scientific representation to be\ndeflationary in both senses, and dubs it “inferentialism”.\nLetting \\(A\\) stand for the model and \\(B\\) for the target, he offers\nthe following analysis: \nInferentialism: “\\(A\\) represents \\(B\\) only if (i) the\nrepresentational force of \\(A\\) points towards \\(B\\), and (ii) \\(A\\)\nallows competent and informed agents to draw specific inferences\nregarding \\(B\\)” (2004: 773).  \nThe first condition addresses the Requirement of Directionality and\nensures that \\(A\\) and \\(B\\) indeed enter into a representational\nrelationship. On might worry that explaining\nrepresentation in terms of representational force sheds little\nlight on the matter as long as no analysis of representational force\nis offered. But Suárez resists attempts to explicate\nrepresentational force in terms of a stronger relation, like\ndenotation or reference, on grounds that this would violate\ndeflationism (2015: 41). The second condition is in fact just the\nSurrogative Reasoning Condition, now taken as a necessary condition on\nscientific representation. But Contessa (2007: 61) points out that it remains mysterious how these inferences are generated. An appeal to further analysis can, again, be blocked by\nappeal to deflationism because any attempt to explicate how inferences\nare drawn would go beyond “surface features”. So the\ntenability of Inferentialism in effect depends on the\ntenability of deflationism about scientific representation. Suárez (2015) defends deflationism\nby drawing analogies with three different deflationary theories about\ntruth, Ramsey’s “redundancy” theory, Wright’s “abstract\nminimalism” and Horwich’s “use theory” (for\nmore information of these theories see the SEP entry on\n the deflationary theory of truth).\n An alternative defence builds on Brandom’s inferentialism in\nthe philosophy of language (1994, 2000), a line of argument that is\ndeveloped in de Donato Rodríguez and Zamora Bonilla (2009). \nInferentialism provides a neat explanation of the possibility\nof misrepresentation because the inferences drawn about a target need\nnot be true (Suárez 2004: 776). In as far as one\naccepts representational force as a cogent concept, targetless models\nare dealt with successfully because representational force (unlike\ndenotation) does not require the existence of a target (2004: 772).\nInferentialism repudiates the Representational Demarcation Problem and\naims to offer an account of representation that also works in other\ndomains such as painting (2004: 777). The account is ontologically\nnon-committal because anything that has an internal structure that\nallows an agent to draw inferences can be a representation. Relatedly,\nsince the account is supposed to apply to a wide variety of entities\nincluding equations and mathematical structures, the account implies\nthat mathematics is successfully applied in the sciences, but in\nkeeping with the spirit of deflationism no explanation is offered\nabout how this is possible. The account does not directly address the\nProblem of Style. \nIn response to the difficulties with Inferentialism Contessa\nsubmits that “it is not clear why we should adopt a deflationary\nattitude from the start” (2007: 50) and provides a\n“interpretational account” of scientific representation\nthat is inspired by Suárez’s account, but without being\ndeflationary. Contessa introduces the notion of an\ninterpretation of a model, in terms of its target system, as a\nnecessary and sufficient condition on epistemic representation (see\nalso Ducheyne 2012 for a related account): \nInterpretation: “A [model \\(M\\)] is an epistemic\nrepresentation of a certain target [\\(T\\)] (for a certain user) if and\nonly if the user adopts an interpretation of the [\\(M\\)] in terms of\n[\\(T\\)].” (Contessa 2007: 57; see also Contessa 2011:\n126–127)  \nThe leading idea of an interpretation is that the model user first\nidentifies sets of relevant objects in the model and the target, and then pins down\nsets of properties and relations these objects instantiate both in the\nmodel and the target. The user then (a) takes \\(M\\) to denote \\(T\\);\n(b) takes every identified object in the model to denote exactly one\nobject in the target (and every relevant object in the target has to\nbe so denoted); (c) takes every property and relation in the model to\ndenote a property or relation of the same type in the target (and,\nagain, and every property and relation in the target has to be so\ndenoted). A formal rendering of these conditions is what Contessa\ncalls an “analytic interpretation” (see his 2007:\n57–62 for details; he also includes an additional condition\npertaining to functions in the model and target, which we suppress for\nbrevity). \nInterpretation offers a neat answer to the ER-problem. The\naccount also explains the directionality of representation:\ninterpreting a model in terms of a target does not entail interpreting\na target in terms of a model. However, it has been noted that\nInterpretation has difficulty accounting for the possibility\nof misrepresentation, since it seems to require that the relevant\nobjects, properties, and relations actually exist in the target (Shech\n2015) (although this objection turns on a very strict reading of\nContessa’s account). Contessa does not comment on the\napplicability of mathematics but since his account shares with the\nstructuralist account an emphasis on relations and one-to-one\nmodel-target correspondence, Contessa can appeal to the same account\nof the applicability of mathematics as the structuralist. Like\nSuárez, Contessa takes his account to be universal and apply\nto non-scientific representations such as portraits and maps. But it\nremains unclear how Interpretation addresses the Problem of\nStyle. As we have seen earlier, in particular visual representations\nfall into different categories. It is a question for future research\nhow these can be classified within the interpretational framework.\nWith respect to the Question of Ontology, Interpretation\nitself places few constraints on what scientific models are,\nontologically speaking. All it requires is that they consist of\nobjects, properties, relations, and functions (but see Contessa (2010)\nfor further discussion of what he takes models to be, ontologically\nspeaking). \nA recent family of approaches analyses models by drawing an analogy\nbetween models and literary fiction. This analogy can be used in two\nways, yielding two different version of the fiction view. The first is\nprimarily motivated by ontological considerations rather than the\nquestion of scientific representation per se. Scientific\ndiscourse is rife with passages that appear to be descriptions of\nsystems in a particular discipline, and the pages of textbooks and\njournals are filled with discussions of the properties and the\nbehaviour of those systems. In mechanics, for instance, the dynamical\nproperties of a system consisting of three spinning spheres with\nhomogenous mass distributions are the focus of attention, in biology\ninfinite populations are investigated, and in economics perfectly\nrational agents with access to perfect information exchange goods.\nTheir surface structure notwithstanding, no one would mistake\ndescriptions of such systems as descriptions of an actual\nsystem: we know very well that there are no such systems. \nThomson-Jones (2010: 284) refers to such a description as a\n“description of a missing system”. These descriptions are\nembedded in what he calls the “face value practice” (2010:\n285) the practice of talking and thinking about these systems as if\nthey were real. The face-value practice raises a number of questions.\nWhat account should be given of these descriptions and what sort of\nobjects, if any, do they describe? Are we putting forward\ntruth-evaluable claims when putting forward descriptions of missing\nsystems? \nThe fiction view of models provides an answer: models are akin to\nplaces and characters in literary fiction and claims about them are\ntrue or false in the same way in which claims about these places and\ncharacters are true or false. Such a position has been recently\ndefended explicitly by some authors (Frigg 2010a,b; Godfrey-Smith\n2006), but not without opposition (Giere 2009; Magnani 2012). It does bear\nnoting that the analogy has been around for a while (Cartwright 1983;\nMcCloskey 1990; Vaihinger 1911 [1924]). This leaves the thorny issue\nof how to analyse fictional places and characters. Here philosophers of science\ncan draw on discussions from aesthetics to fill in the details about\nthese questions (Friend 2007 and Salis 2013 provide useful\nreviews). \nThe second version of the fiction view explicitly focuses on\nrepresentation. Most theories of representation we have encountered so\nfar posit that there are model systems and construe scientific\nrepresentation as a relation between two entities, the model system\nand the target system. Toon calls this the indirect view of\nrepresentation (2012: 43). Indeed, Weisberg views this indirectness as\nthe defining feature of modelling (2007). This view contrasts with\nwhat Toon (2012: 43) and Levy (2015: 790) call a direct view\nof representation. This view does not recognise model systems and aims\ninstead to explain representation as a form of direct description. On\nthis view, models provide an “imaginative\ndescription of real things” (Levy 2012: 741) such as actual\npendula, and there is no such thing as a model system of which the\npendulum description is literally true (Toon 2012: 43–44).  \nToon articulates the direct view by drawing on Walton’s (1990)\ntheory of make-believe. At the heart of this theory is the notion of a\ngame of make-believe (see the SEP entry on\n imagination\n for further discussion). We play such a game if, for instance, when\nwalking through a forest we imagine that stumps are bears and if we\nspot a stump we imagine that we spot a bear. In Walton’s\nterminology the stumps are props, and the rule that we\nimagine a bear when we see a stump is a principle of\ngeneration. Together a prop and principle of generation prescribe\nwhat is to be imagined. Walton considers a vast variety of different\nprops, including statues and works of literary fiction. Toon focuses\non the particular kind of game in which we are prescribed to imagine\nsomething of a real world object. A statue showing Napoleon on\nhorseback (Toon 2012: 37) is a prop mandating us to imagine, for\ninstance, that Napoleon has a certain physiognomy and certain facial\nexpressions. When reading The War of the Worlds (2012: 39) we\nare prescribed to imagine that the dome of St Paul’s Cathedral\nhas been attacked by aliens and now has a gaping hole on its western\nside.  \nThe crucial move is to say that models are props in games of make\nbelieve. Specifically, material models are like the statue of Napoleon\nand theoretical models are like the text of The War of the\nWorlds: both prescribe, in their own way, to imagine something\nabout a real object. A ball-and-stick model of a methane molecule\nprescribes us to imagine particular things about methane, and a model\ndescription describing a point mass bob bouncing on a perfectly\nelastic spring represents the real ball and spring system by\nprescribing imaginings about the real system. This provides the\nfollowing answer to the ER-problem (Toon 2012: 62):  \nDirect Representation: \\(M\\) is a scientific representation\nof \\(T\\) iff \\(M\\) functions as prop in game of make-believe which\nprescribes imaginings about \\(T\\).  \nThis account solves some of the problems posed in\n Section 1: Direct Representation is asymmetrical, makes room for\nmisrepresentation, and, given its roots in aesthetics, it renounces\nthe Demarcation Problem. The view absolves the Problem of Ontology\nsince models are either physical objects or descriptions, neither or\nwhich are problematic in this context. Toon remains silent on both the\nProblem of Style, and the applicability of mathematics.  \nImportant questions remain. According to Direct\nRepresentation models prescribe us to imagine certain things\nabout their target system. The account remains silent, however, on the\nrelationship between what a model prescribes us to imagine and what a\nmodel user should actually infer about the target system, and so it\noffers no answer to the ER-problem. Levy (2015) identifies this as a\ngap in Toon’s account and proposes to fill it by invoking\nYablo’s (2014) notion of “partial truth”, the idea\nbeing that a model user should take the imagined propositions to be\npartially true of their target systems. However, as Levy admits, there\nare other sorts of cases that don’t fit the mould, most notably\ndistortive idealisations. These require a different treatment and\nit’s an open question what this treatment would be.  \nA further worry is how Direct Representation deals with\ntargetless models. If there is no target system, then what does the\nmodel prescribe imaginings about? Toon is well aware of such models\nand suggests the following solution: if a model has no target it\nprescribes imaginings about a fictional character (2012: 76). This\nsolution, however, comes with ontological costs, and one of the\ndeclared aims of the direct view was to avoid such costs by removing\nmodel systems from the picture. Levy (2015) aims to salvage\nontological parsimony and proposes a radical move: there are no\ntargetless models. If a (purported) model has no target then it is not\na model. There remains a question, however, how this view can be\nsquared with scientific practice where targetless models are not only\ncommon but also clearly acknowledged as such.  \nIn Goodman’s (1976)\naccount of aesthetic representation the idea is that a work of art\ndoes not just denote its subject, but moreover it represents it as\nbeing thus or so (see the SEP entry on\n Goodman’s aesthetics\n for further discussion). Elgin (2010) further developed this account\nand, crucially, suggested that it also applies to scientific\nrepresentations. We first discuss Goodman and Elgin’s notion of\nrepresentation-as and then consider a recent extension of their\nframework. \nMany instances of epistemic representation are instances of what\nGoodman and Elgin call “representation-as”. Caricatures\nare paradigmatic examples: Churchill is represented as a bulldog and\nThatcher is represented as a boxer. But the notion is more general:\nHolbein’s Portrait of Henry VIII represents Henry as\nimposing and powerful and Stoddart’s statue of David Hume\nrepresents him as thoughtful and wise. Using these representations we\ncan learn about their targets, for example we can learn about a\npolitician’s or philosopher’s personality. The leading\nidea of the views discussed in this section is that scientific\nrepresentation works in much the same way. A model of the solar system\nrepresents it as consisting of perfect spheres; the logistic model of\ngrowth represents the population as reproducing at fixed intervals of\ntime; and so on. In each instance, models can be used to attempt to\nlearn about their targets by determining what the former represent the\nlatter as being.  \nThe locution of representation-as functions in the following way: an\nobject \\(X\\) (e.g., a picture, statue, or model) represents a subject\n\\(Y\\) (e.g., a person or target system) as being thus or so \\((Z)\\).\nThe question then is what establishes this sort of representational\nrelationship. The answer requires introducing some of the concepts\nGoodman and Elgin use to develop their account of\nrepresentation-as. \nGoodman and Elgin draw a distinction between something being a\nrepresentation of a \\(Z\\), and something being a \\(Z\\)-representation\n(Elgin 2010: 1–2; Goodman 1976: 21–26). A painting of a unicorn is a unicorn-representation because it shows a unicorn, but it is not a\nrepresentation of a unicorn because there are no unicorns. Being a\n\\(Z\\)-representation is a one-place predicate that categorises\nrepresentations according to their subject matter. Being a\nrepresentation of something is established by denotation; it\nis a binary relation that holds between a symbol and the object which\nit denotes. The two can, but need not, coincide. Some\ndog-representations are representations of dogs, but not all are\n(e.g., a caricature of Churchill), and not all representations of dogs\nare dog-representations (e.g., a lightening bolt may represent the\nfastest greyhound at the races).  \nThe next notion is exemplification: an object \\(X\\)\nexemplifies a property \\(P\\) iff \\(X\\) instantiates \\(P\\) and thereby\nrefers back to \\(P\\) (Goodman 1976: 53). In the current context properties are to be\nunderstood in the widest possible sense. An item can exemplify\none-place properties, multi-place properties (i.e., relations), higher\norder properties, structural properties, etc. Paradigmatic examples of\nthis are samples. A chip of paint on a manufacturer’s sample\ncard instantiates a certain colour and at the same time refers to that\ncolour (Elgin 1983: 71). Notice that instantiation is necessary but\ninsufficient for exemplification: the sample card does not exemplify\nbeing rectangular for example. When a object exemplifies a\nproperty it provides us with epistemic access to that property. \nRepresentation-as is then established by combining these notions\ntogether: a \\(Z\\)-representation exemplifies properties associated\nwith\n \\(Z\\)s,[10]\n and if the \\(Z\\)-representation additionally denotes \\(Y\\), then\nthese properties can be imputed onto \\(Y\\) (cf. Elgin 2010: 10). This\nprovides the following account of epistemic representation: \nRepresentation-As: \\(X\\) is an epistemic representation of\n\\(Y\\) iff (i) \\(X\\) denotes \\(Y\\), (ii) \\(X\\) is a\n\\(Z\\)-representation exemplifying properties \\(P_1, \\ldots , P_n\\),\nand (iii) \\(X\\) imputes \\(P_1, \\ldots , P_n\\), or related properties,\nonto \\(Y\\).  \nApplying this in the scientific context, i.e., by letting \\(X\\) range\nover models and \\(Y\\) over target systems, we arrive at an answer to\nthe ER-problem. Representation-As also answers the other\nproblems introduced in\n Section 1:\n it repudiates the demarcation problem and it explains the\ndirectionality of representation. It accounts for surrogative\nreasoning in terms of the properties imputed to the target. If\n\\(Y\\) possesses the imputed properties then the representation is accurate, but\nsince the target doesn’t necessarily need to instantiate them it\nallows for the possibility of misrepresentation. Different styles can\nbe accounted for by categorising representations in terms of different\n\\(Z\\)s, or in terms of the properties they exemplify. However, at\nleast as stated, the account remains silent on the problem of ontology\nand the applicability of mathematics. We discuss below how to account\nfor targetless models. \n\n Representation-As\n raises a number of questions when applied in the scientific context.\nThe first concerns the notion of a \\(Z\\)-representation. While it has\nintuitive appeal in the case of pictures, it is less clear how it\nworks in the context of science. Phillips and Newlyn constructed an\nelaborate system of pipes and tanks to model an economy (see Morgan\nand Boumans 2004 for a useful discussion). So the machine is an\neconomy-representation. But what turns a system of pipes and tanks\ninto an economy-representation?  \nFrigg and Nguyen (2016: 227–8)\nargue that in order to turn an object \\(X\\) into a scientific model,\nit must be interpreted in the appropriate way (note that they do not\nuse “interpretation” in the way that Contessa uses it, as\ndiscussed above): properties that \\(X\\) has, qua object, are paired up with\nrelevant \\(Z\\) properties and for quantitative properties, i.e.,\nproperties such as mass or flow, which take numerical values, there\nneeds to a further association between the values of the \\(X\\)\nproperty and the values of the \\(Z\\) property to which it is mapped.\nIn the case of the Phillips-Newlyn machine, for example, hydraulic\nproperties of the machine are associated with economic properties and a\nrule is given specifying that a litre of water corresponds to certain\namount of a model-economy’s currency. The \\(X\\) and \\(Z\\)\nproperties that are so associated need not exhaust the properties that\n\\(X\\) instantiates, nor do all possible \\(Z\\) properties need be\nassociated with an \\(X\\) property. \n\n\nA scientific model can then be defined as a \\(Z\\)-representation,\ni.e., an object under an interpretation. This notion of a model\nexplicitly does not presuppose a target system and hence makes room\nfor targetless models. Models can then be seen as instantiating\n\\(Z\\)-properties under the relevant interpretation, which\nexplains how the model can exemplify such properties. \nThe next issue is that exemplified properties are rarely exactly\nimputed onto target systems. According to\n Representation-As\n the imputed properties are either the ones exemplified by the\n\\(Z\\)-representation, “or related ones”. Frigg and Nguyen (2016: 228),\nbuilding on Frigg (2010a: 125–135), prefer to be explicit about\nthe relationship between the exemplified properties and the ones to be\nimputed onto the target. They do this by introducing a\n“key”, which explicitly associates the\nexemplified properties with properties to be imputed onto the target.\nFor example, in the case of a London Tube map, the key associates\nparticular colours with particular tube lines, and in the case of\nidealisations the key associates de-idealised properties with\nmodel-properties.  \nGathering the various pieces together leads to the following account\nof representation (Frigg and Nguyen 2016: 229): \nDEKI: Let \\(M = \\langle X, I \\rangle\\) be a model, where \\(X\\) is an\nobject and \\(I\\) an interpretation. Let \\(T\\) be the target system.\n\\(M\\) represents \\(T\\) as \\(Z\\) iff all of the following conditions are\nsatisfied: \n\\(M\\) is a scientific representation of \\(T\\) iff \\(M\\) represents\n\\(T\\) as \\(Z\\) as defined in (i)–(iv). \nThe moniker “DEKI” highlights the account’s key\nfeatures: denotation, exemplification, keying-up and imputation.\nDEKI answers the problems from\n Section 1\n in much the same way as\n Representation-As\n did. However, it adds to the latter in at least three ways. Firstly,\nthe conditions given make it clear what makes scientific models\n\\(Z\\)-representations in the first place: interpretations. Secondly,\nit makes explicit that the properties exemplified by the model need\nnot be imputed exactly onto the target, and highlights the need to\ninvestigate keys specifying the relationship between properties in\nmodels and the properties that models actually impute onto their\ntargets. Finally, it makes explicit how to account for targetless\nmodels. A scientific model that fails to denote a target system can\nnevertheless be a \\(Z\\)-representation. A model of a bridge that is\nnever built is still a bridge-representation, which exemplifies\nproperties related to bridges (stability and so on), despite the fact that\nit is not a representation of anything. However, as in the case of\n Representation-As\n questions remain with respect to the problem of ontology and the\napplicability of mathematics. ","contact.mail":"j.nguyen1@lse.ac.uk","contact.domain":"lse.ac.uk"}]
