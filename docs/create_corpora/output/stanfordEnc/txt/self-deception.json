[{"date.published":"2006-10-17","date.changed":"2016-11-07","url":"https://plato.stanford.edu/entries/self-deception/","author1":"Ian Deweese-Boyd","author1.info":"http://www.gordon.edu/page.cfm?iPageID=974&iCategoryID=99&Philosophy&Dr._DeWeese-Boyd","entry":"self-deception","body.text":"\n\n\nVirtually every aspect of self-deception, including its definition and\nparadigmatic cases, is a matter of controversy among philosophers.\nMinimally, self-deception involves a person who seems to acquire and\nmaintain some false belief in the teeth of evidence to the contrary as\na consequence of some motivation, and who may display behavior\nsuggesting some awareness of the truth. Beyond this, philosophers\ndivide over whether self-deception is intentional, involves belief or\nsome other sub-or-non-doxastic attitude, whether self-deceivers are\nmorally responsible for their self-deception, and whether\nself-deception is morally problematic (and if it is in what ways and\nunder what circumstances), whether self-deception is beneficial or\nharmful, whether and in what sense collectives can be self-deceived,\nhow this might affect individuals within such collectives, whether our\npenchant for self-deception was selected for or merely an accidental\nbyproduct of our evolutionary history, and if it was selected,\nwhy?\n\n\nThe discussion of self-deception and its associated puzzles sheds\nlight on the ways motivation affects belief acquisition and retention\nand other belief-like cognitive attitudes; it also prompts us to\nscrutinize the notion of belief and the limits of such folk\npsychological concepts to adequately explain phenomena of this sort.\nAnd yet insofar as self-deception represents an obstacle to\nself-knowledge, both individually and collectively, it is more than\njust another interesting philosophical puzzle. It is a problem of\nexistential concern, since it suggests that there is a distinct\npossibility that we live with distorted views of our selves, others\nand the world that may make us strangers to ourselves and blind to the\nnature of our significant moral engagements. \n\nWhat is self-deception? Traditionally, self-deception has been modeled\non interpersonal deception, where A intentionally gets\nB to believe some proposition p, all the while\nknowing or believing truly that ~p. Such deception is\nintentional and requires the deceiver to know or believe that\n~p and the deceived to believe that p. One reason\nfor thinking self-deception is analogous to interpersonal deception of\nthis sort is that it helps us to distinguish self-deception from mere\nerror, since the acquisition and maintenance of the false belief is\nintentional not accidental. If self-deception is properly modeled on\nsuch interpersonal deception, self-deceivers intentionally get\nthemselves to believe that p, all the while knowing or\nbelieving truly that ~p. On this traditional model, then,\nself-deceivers apparently must (1) hold contradictory beliefs, and (2)\nintentionally get themselves to hold a belief they know or believe\ntruly to be false. \nThe traditional model of self-deception, however, has been thought to\nraise two paradoxes: One concerns the self-deceiver’s state of\nmind—the so-called ‘static’ paradox. How can a\nperson simultaneously hold contradictory beliefs? The other concerns\nthe process or dynamics of self-deception—the so-called\n‘dynamic’ or ‘strategic’ paradox. How can a\nperson intend to deceive herself without rendering her intentions\nineffective? (Mele 1987a; 2001) \nThe requirement that self-deceivers holds contradictory beliefs raises\nthe ‘static’ paradox, since it seems to pose an impossible\nstate of mind, namely, consciously believing that p and\n~p at the same time. As deceiver, she must believe that\n~p, and, as deceived, she must believe that p.\nAccordingly, the self-deceiver consciously believes that p\nand ~p. But if believing both a proposition and its negation\nin full awareness is an impossible state of mind to be in, then\nself-deception as it has traditionally been understood seems to be\nimpossible as well. \nThe requirement that the self-deceiver intentionally get herself to\nhold a belief she knows to be false raises the ‘dynamic’\nor ‘strategic’ paradox, since it seems to involve the\nself-deceiver in an impossible project, namely, both deploying and\nbeing duped by some deceitful strategy. As deceiver, she must be aware\nshe’s deploying a deceitful strategy; but, as the deceived, she\nmust be unaware of this strategy for it to be effective. And yet it is\ndifficult to see how the self-deceiver could fail to be aware of her\nintention to deceive. A strategy known to be deceitful, however, seems\nbound to fail. How could I be taken in by your efforts to get me to\nbelieve something false, if I know what you’re up to? But if\nit’s impossible to be taken in by a strategy one knows is\ndeceitful, then, again, self-deception as it has traditionally been\nunderstood seems to be impossible as well. \nThese paradoxes have led a minority of philosophers to be skeptical\nthat self-deception is conceptually possible or even coherent (Paluch\n1967; Haight 1980; Kipp 1980). Borge (2003) contends that accounts of\nself-deception inevitably give up central elements of our\nfolk-psychological notions of “self” or\n“deception” to avoid paradox, leaving us to wonder whether\nthis framework itself is what gets in the way of explaining the\nphenomenon. Such skepticism toward the concept may seem warranted,\ngiven the obvious paradoxes involved. Most philosophers, however, have\nsought some resolution to these paradoxes, instead of giving up on the\nnotion itself, not only because empirical evidence suggests that\nself-deception is not only possible, but pervasive (Sahdra &\nThagard 2003), but also because the concept does seem to pick out a\ndistinct kind of motivated irrationality. Philosophical accounts of\nself-deception can be organized into two main groups: those that\nmaintain that the paradigmatic cases of self-deception are\nintentional, and those that deny this. Call these approaches\nintentionalist and revisionist respectively.\nIntentionalists find the model of intentional interpersonal deception\napt, since it helps to explain the selectivity of self-deception and\nthe apparent responsibility of self-deceiver, as well as providing a\nclear way of distinguishing self-deception from other sorts of\nmotivated belief such as wishful thinking. Revisionists are impressed\nby the static and dynamic paradoxes allegedly involved in modeling\nself-deception on intentional interpersonal deception and, in their\nview, the equally puzzling psychological models used by\nintentionalists to avoid these paradoxes, such as semi-autonomous\nsubsystems, unconscious beliefs and intentions and the like. To avoid\nparadox and psychological exotica revisionist approaches reformulate\nthe intention requirement, the belief requirement or both. \nThe chief problem facing intentional models of self-deception is the\ndynamic paradox, namely, that it seems impossible to form an intention\nto get oneself to believe what one currently disbelieves or believes\nis false. For one to carry out an intention to deceive oneself one\nmust know what one is doing, to succeed one must be ignorant of this\nsame fact. Intentionalists agree on the proposition that\nself-deception is intentional, but divide over whether it requires the\nholding of contradictory beliefs, and thus over the specific content\nof the alleged intention involved in self-deception. Insofar as even\nthe bare intention to acquire the belief that p for reasons\nnot having to do with one’s evidence for p seems\nunlikely to succeed if directly known, most intentionalists introduce\nsome sort of temporal or psychological partition to insulate\nself-deceivers from their deceptive stratagems. When self-deceivers\nare not consciously aware of their beliefs to the contrary or their\ndeceptive intentions, no paradox seems to be involved in deceiving\noneself. Many approaches utilize some combination of psychological and\ntemporal division (e.g., Bermúdez 2000).  \nSome intentionalists argue that self-deception is a complex process\nthat is often extended over time and as such a self-deceiver can\nconsciously set out to deceive herself into believing that p,\nknowing or believing that ~p, and along the way lose her\nbelief that ~p, either forgetting her original deceptive\nintention entirely, or regarding it as having, albeit accidentally,\nbrought about the true belief she would have arrived at anyway\n(Sorensen 1985; Bermúdez 2000). So, for instance, an official\ninvolved in some illegal behavior might destroy any records of this\nbehavior and create evidence that would cover it up (diary entries,\nemails and the like), knowing that she will likely forget having done\nthese things over the next few months. When her activities are\ninvestigated a year later, she has forgotten her tampering efforts and\nbased upon her falsified evidence comes to believe falsely that she\nwas not involved in the illegal activities of which she is accused.\nHere the self-deceiver need never simultaneously hold contradictory\nbeliefs even though she intends to bring it about that she believes\nthat p, which she regards as false at the outset of the\nprocess of deceiving herself and true at its completion. The\nself-deceiver need not even forget her original intention to deceive,\nso an unbeliever who sets out to get herself to believe in God (since\nshe thinks such a belief is prudent, having read Pascal) might well\nremember such an intention at the end of the process and deem that by\nGod’s grace even this misguided path led her to the truth. It is\ncrucial to see here that what enables the intention to succeed in such\ncases is the operation of what Johnston (1988) terms ‘autonomous\nmeans’ (e.g., the normal degradation of memory, the tendency to\nbelieve what one practices, etc.) not the continued awareness of the\nintention. Some non-intentionalists take this to be a hint that the\nprocess by which self-deception is accomplished is subintentional\n(Johnston 1988). In any case, while it is clear that such temporal\npartitioning accounts apparently avoid the static and dynamic\nparadoxes, many find such cases fail to capture the distinctive\nopacity, indirection and tension associated with garden-variety cases\nof self-deception (Levy 2004).  \nAnother strategy employed by intentionalists is the division of the\nself into psychological parts that play the role of the deceiver and\ndeceived respectively. These strategies range from positing strong\ndivision in the self, where the deceiving part is a relatively\nautonomous subagency capable of belief, desire and intention (Rorty\n1988); to more moderate division, where the deceiving part still\nconstitutes a separate center of agency (Pears 1984, 1986; 1991); to\nthe relatively modest division of Davidson, where there need only be a\nboundary between conflicting attitudes (1982, 1986). Such divisions\nare prompted in large part by the acceptance of the contradictory\nbelief requirement. It isn’t simply that self-deceivers hold\ncontradictory beliefs, which though strange, isn’t impossible.\nOne can believe that p and believe that ~p without\nbelieving that p & ~p, which would be\nimpossible. The problem such theorists face stems from the appearance\nthat the belief that ~p motivates and thus form a part of the\nintention to bring it about that one acquire and maintain the false\nbelief that p (Davidson 1986). So, for example, the Nazi\nofficial’s recognition that his actions implicate him in serious\nevil motivates him to implement a strategy to deceive himself into\nbelieving he is not so involved; he can’t intend to bring it\nabout that he holds such a false belief if he doesn’t recognize\nit is false, and he wouldn’t want to bring such a belief about\nif he didn’t recognize the evidence to the contrary. So long as\nthis is the case, the deceptive subsystem, whether it constitutes a\nseparate center of agency or something less robust, must be hidden\nfrom the conscious self being deceived if the self-deceptive intention\nis to succeed. While these psychological partitioning approaches seem\nto resolve the static and dynamic puzzles, they do so by introducing a\npicture of the mind that raises many puzzles of its own. On this\npoint, there appears to be consensus even among intentionalists that\nself-deception can and should be accounted for without invoking\ndivisions not already used to explain non-self-deceptive behavior,\nwhat Talbott (1995) calls ‘innocent’ divisions. \nSome intentionalists reject the requirement that self-deceivers hold\ncontradictory beliefs (Talbott 1995; Bermúdez 2000). According\nto such theorists, the only thing necessary for self-deception is the\nintention to bring it about that one believe that p where\nlacking such an intention one would not have acquired that belief. The\nself-deceiver thus need not believe that ~p. She might have\nno views at all regarding p, possessing no evidence either\nfor or against p; or she might believe that p is\nmerely possible, possessing evidence for or against p too\nweak to warrant belief that p or ~p (Bermúdez\n2000). Self-deceivers in this minimal sense intentionally acquire the\nbelief that p, despite their recognition at the outset that\nthey do not possess enough evidence to warrant this belief by\nselectively gathering evidence supporting p or otherwise\nmanipulating the belief-formation process to favor belief that\np. Even on this minimal account, such intentions will often\nbe unconscious, since a strategy to acquire a belief in violation of\none’s normal evidential standards seems unlikely to succeed if\none is aware of it.  \nA number of philosophers have moved away from modeling self-deception\ndirectly on intentional interpersonal deception, opting instead to\nrevise either the intention or the belief requirement traditional\nintentionalist models assume. Those revising the intention requirement\ntypically treat it self-deception as a species of motivationally\nbiased belief, thus avoiding the problems involved with intentionally\ndeceiving oneself. Call these non-intentionalist or deflationary\napproaches. Those revising the belief requirement either posit some\nother non-doxastic or quasi-doxastic attitude toward the proposition\ninvolved (‘hopes’, ‘suspicions’,\n‘doubts’, ‘anxieties’ Edwards 2013;\n‘besires’ Egan 2009; ‘pretense’ Gendler 2007;\n‘imagination’ Lazar 1999), or alter the content of the\nproposition believed in a way that avoids the paradoxes associated\nwith the dual belief requirement embedded in traditional\nintentionalist models of self-deception (e.g., Holton 2001; Funkhouser\n2005; Fernández 2013). Call these revision of belief\napproaches. Deflationary approaches focus on the process of\nself-deception, while the revision of belief approaches focus on the\nproduct. A revision of either of these aspects, of course, has\nramifications for the other. For example, if self-deception\ndoesn’t involve belief, but some other non-doxastic attitude\n(product), then one may well be able to intentionally enter that state\nwithout paradox (process). This section considers non-intentional or\ndeflationary approaches and the worries such approaches raise (3.1),\nand revision of belief approaches (3.2)  \nThese non-intentionalists allow that phenomena answering to the\nvarious intentionalist models available may be possible, but everyday\nor ‘garden-variety’ self-deception can be explained\nwithout adverting to subagents, or unconscious beliefs and intentions,\nwhich, even if they resolve the static and dynamic puzzles of\nself-deception, raise many puzzles of their own. If such non-exotic\nexplanations are available, intentionalist explanations seem\nunwarranted.  \nThe main paradoxes of self-deception seem to arise from modeling\nself-deception too closely on intentional interpersonal deception.\nAccordingly, non-intentionalists suggest the intentional model be\njettisoned in favor of one that takes ‘to be deceived’ to\nbe nothing more than to believe falsely or be mistaken in believing\n(Johnston 1988; Mele 2001). For instance, Sam mishears that it will be\na sunny day and relays this misinformation to Joan with the result\nthat she believes it will be a sunny day. Joan is deceived in\nbelieving it will be sunny and Sam has deceived her, albeit\nunintentionally. Initially, such a model may not appear promising for\nself-deception, since simply being mistaken about p or\naccidentally causing oneself to be mistaken about p\ndoesn’t seem to be self-deception at all but some sort of\ninnocent error—Sam doesn’t seem self-deceived, just\ndeceived. Non-intentionalists, however, argue that in cases of\nself-deception the false belief is not accidental but motivated by\ndesire (Mele 2001), anxiety (Johnston 1988, Barnes 1997) or some other\nemotion regarding p or related to p. So, for\ninstance, when Allison believes against the preponderance of evidence\navailable to her that her daughter is not having learning\ndifficulties, the non-intentionalist will explain the various ways she\nmisreads the evidence by pointing to such things as her desire that\nher daughter not have learning difficulties, her fear that she has\nsuch difficulties, or anxiety over this possibility. In such cases,\nAllison’s self-deceptive belief that her daughter is not having\nlearning difficulties, fulfills her desire, quells her fear or reduces\nher anxiety, and it is this function (not an intention) that explains\nwhy her belief formation process is bias. Allison’s false belief\nis not an innocent mistake, but a consequence of her motivational\nstates.  \nSome non-intentionalists suppose that self-deceivers recognize at some\nlevel that their self-deceptive belief that p is false,\ncontending that self-deception essentially involves an ongoing effort\nto resist the thought of this unwelcome truth or is driven by anxiety\nprompted by this recognition (Bach 1981; Johnston 1988). So, in\nAllison’s case, her belief that her daughter is having learning\ndifficulties along with her desire that it not be the case motivate\nher to employ means to avoid this thought and to believe the opposite.\nOthers, however, argue the needed motivation can as easily be supplied\nby uncertainty or ignorance whether p, or suspicion that\n~p (Mele 2001, Barnes 1997). Thus, Allison need not hold any\nopinion regarding her daughter’s having learning difficulties\nfor her false belief that she is not experiencing difficulties to\ncount as self-deception, since it is her regarding evidence in a\nmotivationally biased way in the face of evidence to the contrary, not\nher recognition of this evidence, that makes her belief\nself-deceptive. Accordingly, Allison need not intend to deceive\nherself nor believe at any point that her daughter is in fact having\nlearning difficulties. If we think someone like Allison is\nself-deceived, then self-deception requires neither contradictory\nbeliefs nor intentions regarding the acquisition or retention of the\nself-deceptive belief. Such approaches are ‘deflationary’\nin the sense that they take self-deception to be explicable without\nreaching for what Mele calls ‘mental exotica’ (Mele 2001).\n(For more on this sort of objection see Self-Deception and\nTension below). \nOn such deflationary views of self-deception, one need only hold a\nfalse belief that p, possess evidence that ~p, and\nhave some desire or emotion that explains why p is believed\nand retained. In general, if one possesses evidence that one normally\nwould take to support ~p and yet believes that p\ninstead due to some desire, emotion or other motivation one has\nrelated to p, then one is self-deceived.  \nCritics contend these deflationary accounts do not adequately\ndistinguish self-deception from other sorts of motivated believing\nsuch as wishful thinking, cannot explain the peculiar selectivity\nassociated with self-deception, its characteristic\n‘tension’, or they way it involves a failure of\nself-knowledge. \nSelf-Deception and Wishful Thinking: What distinguishes\nwishful thinking from self-deception, according to intentionalists,\njust is that the latter is intentional while the former is not (e.g.,\nBermúdez 2000). Non-intentionalists respond that what\ndistinguishes wishful thinking from self-deception is that\nself-deceivers recognize evidence against their self-deceptive belief\nwhereas wishful thinkers do not (Bach 1981; Johnston 1988), or merely\npossess, without recognizing, greater counterevidence than wishful\nthinkers. Scott-Kakures (2002) argues that in “wishful believing\nthe subject’s cognition is hijacked by desire, while in\nself-deception the subject is a willing participant in directing\ncognition towards the doxastic embrace of the favored\nproposition.” For Scott-Kakures, motivation exerts an influence\non the self-deceivers reflective reasoning and hypothesis testing that\nthe self-deceivers mistakenly believe to be free of such bias. For\nwishful thinkers motivation plays triggers a belief formation process\nin which the person does not play an active, conscious role\n(Scott-Kakures 2002; see also, Szabados 1973). While the precise\nrelationship between wishful thinking and self-deception is clearly a\nmatter of debate, there are plausible ways of distinguishing the two\nthat do not invoke the intention to deceive.  \nSelf-Deception and Selectivity: Another objection raised by\nintentionalists is that deflationary accounts cannot explain the\nselective nature of self-deception, termed the ‘selectivity\nproblem’ by Bermúdez (1997, 2000). Why is it, such\nintentionalists ask, that we are not rendered bias in favor of the\nbelief that p in many cases where we have a very strong\ndesire that p (or anxiety or some other motivation related to\np)? Intentionalists argue that an intention to get oneself to\nacquire the belief that p offers a relatively straightforward\nanswer to this question. Mele (2001), drawing on empirical research\nregarding lay hypothesis testing (Trope and Lieberman 1996), argues\nthat selectivity may be explained in terms of the agent’s\nassessment of the relative costs of erroneously believing that\np and ~p. So, for example, Josh would be happier\nbelieving falsely that the gourmet chocolate he finds so delicious\nisn’t produced by exploited farmers than falsely believing that\nit is, since he desires that it not be so produced. Because Josh\nconsiders the cost of erroneously believing his favorite chocolate is\ntainted by exploitation to be very high—no other chocolate gives\nhim the same pleasure, it takes a great deal more evidence to convince\nhim that his chocolate is so tainted than it does to convince him\notherwise. It is the low subjective cost of falsely believing the\nchocolate is not tainted that facilitates Josh’s self-deception.\nBut we can imagine Josh having the same strong desire that his\nchocolate not be tainted by exploitation and yet assessing the cost of\nfalsely believing it is not tainted differently. Say, for example, he\nworks for an organization promoting fair trade and non-exploitive\nlabor practices among chocolate producers and believes he has an\nobligation to accurately represent the labor practices of the producer\nof his favorite chocolate and would, furthermore, lose credibility if\nthe chocolate he himself consumes is tainted by exploitation. In these\ncircumstances, Josh is more sensitive to evidence that his favorite\nchocolate is tainted, despite his desire that it not be, since the\nsubjective cost of being wrong is higher for him than it was before.\nIt is the relative subjective costs of falsely believing p\nand ~p that explains why desire or other motivation biases\nbelief in some circumstances and not others. \nChallenging this solution, Bermúdez (2000) suggests that the\nselectivity problem may reemerge, since it isn’t clear why we\nfrequently do not become self-deceived in cases where there is a\nrelatively low cost for holding a self-deceptive belief favored by our\nmotivations. Mele (2001), however, points out that intentional\nstrategies have their own ‘selectivity problem’, since it\nisn’t clear why some intentions to acquire a self-deceptive\nbelief succeed while others do not. \nSmith (2014) also addresses a version of the selectivity problem,\nproposing a way to account for the the selectivity and apparent\nsuccess aptness of self-deception without resorting to intentions. In\nhis view, deflationary strategies like Mele’s end up making\nself-deception an accidental byproduct of having particular\nmotivational states and therefore not easily distinguished from other\nsorts of motivated believing. Smith looks to examples of deception in\nnon-human organisms to find a way to explain the\n“teleofunctional” nature of self-deception without having\nto attribute intentions. Smith points out that when a mirror orchid\ndeceives a male scolid wasp by mimicking the appearance and odor of a\nfemale scolid wasp, the deception in question can hardly be considered\naccidental even though the orchid lacks the capacity for intentional\nbehavior. With this sort of deception in mind, Smith proposes an\nalternative non-intentional model in which a “subpersonal neural\nmechanism with the proper fuction of selectively inhibiting the\nprocess of producing or extracting information from subdoxastic\nmodels” accounts for self-deceivers false belief without\nrequiring an intention to deceive. Moreover, by proposing that true\ninformation is encoded in some sub-doxastic state, Smith thinks the\nselectivity of self-deception may also be accounted for. In this\nlatter sense, Smith might be viewed as both a revision of intention\nand a revision of belief theorist (more on the latter below). \nSelf-Deception and Tension: A number of philosophers have\ncomplained that deflationary account fails to explain a certain\n‘tension’ supposed to be present in cases of genuine\nself-deception (e.g., Audi 1997; Bach 1997; Nelkin 2002; Funkhouser\n2005; Fernández 2013). This ‘tension’ involves some\nsort of psychic or behavioral ‘conflict’. Self-deceivers\nare said to experience ‘doubts’, ‘suspicions’,\nand the like regarding p, and to display ambiguous behavior\nsome pointing toward belief that p and some toward\n~p. Since deflationary approaches deny that self-deceivers\nreject the dual belief requirement, specifically, denying that\nself-deceivers need to hold that ~p, it seems difficult for\nsuch approaches to explain why self-deceivers would struggle with\ndoubts or display behavior at variance with their false belief that\np. Regarding the former, deflationary theorists accept the\npossibility that self-deceivers may ‘suspect’ or think\nthere is a significant chance that ~p (Mele 2001, 2009,\n2010). Clearly, a person who believes that p and suspects\nthat ~p may experience tension, moreover, such attitudes\ncombined with a desire that p help explain certain sorts of\navoidance behavior highlighted by critics. For his part, Mele things\nself-deception may often involve tension, but it certainly need not,\nthat is, some self-deception is tension free. While Lynch (2012) does\nnot think tension is necessary, he accepts the idea that it\nis characteristic of self-deception, and can be accounted for\nby construing self-deception as involving an unwarranted degree of\nconfidence that p, rather than wholehearted belief that\np as Mele does. On Lynch’s version of deflation,\nself-deceivers will encounter and appreciate evidence that casts doubt\ntheir assumption that p. This appreciation serves to motivate\n“attempts to deal with it (by, for example, trying to explain it\naway)” and explains the doubts regarding p critics have\nidentified. \nAs Lynch (2012) points out, these tensions are not the only, or\nperhaps, the central one’s raised by critics of deflation. For such\ncritics, self-deception involves a deeper behavioral conflict.\nSpecifically, what self-deceivers say about p is at odds with\ntheir non-verbal behavior, which justifies the attribution of the\nbelief that ~p (Audi, 1997; Patten 2003; Funkhouser 2005;\nFernández 2013). For example, Ellen says that she is doing well\nin her biology class, but systematically avoids looking at the results\non her quizzes and tests. She says she doesn’t need to look; she\nknows she didn’t miss anything. When her teacher tries to catch her\nafter class to discuss her poor grades, she is rushes off. Similarly,\nwhen she sees an email from her teacher, she ignores it. Ellen’s\nbehavior suggests to these critics that she knows she is not doing\nwell in her biology class, despite her avowals to the contrary.\nInsofar as deflationary approaches deny people like Ellen know the\ntruth, they fail adequately to explain her self-deception. While some\npropose these cases as a type of self-deception deflation\ncannot explain (Fernández 2013), others go further, suggesting\nthese cases show that deflation is not an account of self-deception at\nall, but of self-delusion (Audi 2007; Funkhouser 2005). In either\ncase, critics think such cases cannot adequately be explained by\ndeflationary account. \nThe significant difference between what deflationary accounts have in\nview (namely, people who do not believe the unwelcome truth that\n~p, having a motivation driven, unwarranted skepticism toward\nit), and deep conflict theorist do (namely, people who know the\nunwelcome truth that ~p and avoid reflecting on it or\nencountering evidence for it) prompts us to ask whether these\nphenomena belong to the same psychological kind, according to Lynch\n(2012). If they did, ‘self-deception’ would be rendered\nambiguous. As Mele (2010) points out, anyone meeting his first\ncondition, namely, acquiring the false belief that p could\nnot be self-deceived on deep conflict approaches (Audi 1997, 2007;\nGendler 2007). Similarly, anyone meeting Audi’s condition that\nself-deceivers are merely disposed to avow sincerely that p\nwhen they unconsciously believe that ~p could not be\nself-deceived on deflationary models like Mele’s. So, which\napproach has correctly identified the meaning of\n‘self-deception’? Lynch (2012) argues that\n‘deep-conflict’ cases do not obviously resemble cases of\ninterpersonal deception, “making it a mystery why they would be\nconsidered species of the same genus.” To be fair, such\napproaches do reflect the fact that deceivers often know the truth,\nbut it does seem strange to say a person could not be deceived\nregarding p just because they actually hold this false\nbelief. In view of these sorts of considerations, Lynch (2012) argues\nthat such deep conflict cases are not properly understood as\nself-deception, but more nearly resemble what Longeway (1990) calls\n‘escapism’. Whether such cases constitute a distinct\npsychological kind or not, or whether they reflect people’s\npretheoretical understanding of self-deception remains unclear, but\ndeflationary approaches do seem to be capable of explaining some of\nthe behavior such theorists insist justifies attributing an\nunconscious belief that ~p. Moreover, deep conflict theorists\nneed to explain why we should think one avowing that p does\nnot also believe it, and why the behavior in question cannot be\nexplained by nearby proxies like suspicion that p (Mele\n2010).  \nSelf-Deception and Self-Knowledge: A number of theorists have\nargued that deflationary approaches fail to capture the distinctive\nfailure of self-knowledge involved in cases of self-deception (Holton,\n2001; Scott-Kakures 2002; Funkhouser 2005; Fernández 2013).\nHolton (2001) argues that Mele’s conditions for being\nself-deceived are not sufficient, because they do not require\nself-deceivers to hold false beliefs about themselves. It seems\npossible for a person to acquire a false belief that p as a\nconsequence of treating data relevant to p in a\nmotivationally biased way, when the data available to her provides\ngreater warrant for p, in such a way that she retains\naccurate self-knowledge. Such a person would readily admit to ignoring\ncertain data, because it would undermine a belief she cherishes. She\nmakes no mistakes about herself, her beliefs or her belief formation\nprocess. Such a person, Holton argues, would be willfully ignorant,\nbut not self-deceived. If, however, her strategy was sufficiently\nopaque to her, she would be apt to deny that she was ignoring relevant\nevidence, and affirm that her belief was the result of what\nScott-Kakures (2002) calls “reflective, critical reasoning.” These\nerroneous beliefs represent a failure of self-knowledge that seems,\naccording to these critics, essential to self-deception. Scott-Kakures\n(2002) contends that this sort of error is also what distinguishes\nself-deception from wishful thinking (see above) and restricts it to\nthose capable of higher-order beliefs. Mele (2010), for his part,\nthinks adding the following sufficient condition to his account would\nput to rest these concerns: \nFernández (2013) distinguishes this sort of self-knowledge\nerror, which focus on the justification of one’s beliefs, from\nthose that involve errors about what one believes. One worry about\ncharacterizing the failure in terms of justification, according to\nFernández (2013), is that it requires a degree of awareness\nabout one’s reasons for believing that would rule out those who\ndo not engage in reflection on their reasons for belief.\nFernández (2013), like Funkhouser (2005), endorses an error\nabout belief approach to account for the sort of ‘deep\nconflict’ cases described above. Whether Mele’s (2010)\nproposed condition requires too much sophistication from\nself-deceivers is debatable, but it does suggests a way of accounting\nfor the intuition that self-deceivers fail to know themselves that\ndoes not require them to harbor hidden beliefs or intentions. \nApproaches that focus on revising the notion that self-deception\nrequires holding that p and ~p, the dual-belief\nrequirement implied by traditional intentionalism, either introduce\nsome “doxastic proxy” (Baghramian and Nicholson 2013) to\nreplace one or both beliefs, or alter the content of the\nself-deceiver’s belief in a way that preserves tension without\ninvolving outright conflict. These approaches resolve the doxastic\nparadox either by denying that self-deceivers believe that p,\nthe welcome but unwarranted belief (Audi 1982, 1988; Funkhouser 2005;\nGendler 2007; Fernádez 2013), by denying that they believe that\n~p, the unwelcome but warranted belief (Barnes 1997; Mele\n2001), or by denying that they hold either that p or\n~p (Edwards 2013; Porcher 2012).  \nDenying the Unwelcome Belief: As noted above, deflationary\napproaches in the tradition of Mele, deny that self-deceivers need to\nhold the unwelcome but warranted belief that ~p.[; it is\nsufficient for self-deceivers to acquire the unwarranted false belief\nthat p in a motivated way.] To explain the selectivity and\ntension that are often cited as reasons for attributing ~p to\nself-deceivers, Mele contends an attitude of suspicion, not belief,\n~p, would suffice. He also suggests that beliefs other than\nthe belief that ~p could do the necessary work without being\ndirectly contrary to what the self-deceiver comes to believe. Citing\nRorty’s (1988) case of Dr. Androvna, a cancer specialist who\nbelieves she does not have cancer, but who draws up a detailed will\nand writes uncharacteristically effusive letters suggesting her\nimpending departure, Mele (2009) points out that Androvna’s behavior\nmight easily be explained by her holding another belief, namely,\n“there is a significant chance that she has cancer.” And, this\nbelief is compatible with Androvna’s belief that she does not, in\nfact, have cancer. \nDenying the Welcome Belief: Another strand of revision of\nbelief approaches focuses on the welcome belief that p,\nproposing a variety of alternatives to this belief that function in\nways that explain what self-deceivers typically say and do.\nSelf-deceivers display ambiguous behavior that not only falls short of\nwhat one would expect from a person who believes that p, but\nactually justifies the attribution of the belief that ~p. For\ninstance, Androvna’s letter writing and will preparation might be\ntaken as reasons for attributing to her the belief that she won’t\nrecover, despite her verbal assertions to the contrary. Accordingly,\nRobert Audi (1982, 1988) attributes the unconscious belief that\n~p to self-deceivers and proposes sincere avowal or a\ndisposition to avow that p as a proxy for the belief that\np. Sincere avowal that p does not entail belief that\np, though belief-like, it does not carry with it “the full\nrange of behavior one would expect from genuine belief” (Audi 1988).\nSincere avowal isn’t exactly an attitude toward the proposition, but\nmay suggest some non-doxastic attitude is at play in the disposition\nto avow. Gendler (2007) suggests ‘pretense’ that\np plays the role of belief in terms “introspective\nvivicy, motivation of action in a wide range of circumstances.”\nUnlike belief, however, pretense is reality indifferent: this attitude\nis held primarily because the self-deceiver wishes to dwell in a world\nin which p obtains. Lazar (1999) closely resembles Gendler in\ntaking self-deceptive beliefs to be better understood along the lines\nof imaginations or fantasies that directly express the self-deceivers\nwishes, fears, hopes and the like, since they show a relative\ninsensitivity to evidence (unlike beliefs) but guide behavior (like\nbeliefs). Along these lines Egan (2009) proposes an intermediate state\nbetween belief and desire, ‘besire’, to account for the\nspecial pattern of behavior displayed by self-deceivers. \nOthers, instead of adjusting the attitude toward the welcome\nproposition p by offering a non-doxastic proxy, substitute a\nhigher-order belief (Funkhouser 2005; Fernández 2013).\nFunkhouser (2005), for instance, contends that self-deceivers\ndon’t believe p, they believe that they believe that\np, and this false second-order belief “I think that I\nbelieve that p” underlies and underwrites their sincere\navowal that p as well as their ability to entertain\np as true. In this way, self-deception is a kind of failure\nof self-knowledge, a misapprehension or misattribution of one’s own\nbeliefs. By shifting the content of the self-deceptive belief to the\nsecond-order, this approach not only avoids the doxastic paradox, it\nexplains the characteristic ‘tension’ or\n‘conflict’ attributed to self-deceivers in terms of the\ndisharmony between the first-order and second-order beliefs, the\nlatter explaining their avowed belief and the former their behavior\nthat goes against that avowed belief (Funkhouser 2005;\nFernández 2013). \nDenying both the Welcome Belief and the Unwelcome Belief:\nGiven the variety of proxies that have been offered for both the\nwelcome and the unwelcome belief, it should not be surprising that\nsome argue that self-deception can be explained without attributing\neither belief to self-deceivers, a position Edwards (2013) refers to\nas ‘nondoxasticism’. Porcher (2012) recommends against\nattributing beliefs to self-deceivers on the grounds that what they\nbelieve is indeterminate, since they are, as Schwitzgebel (2001, 2010)\ncontends, “in-between-believing,” neither fully believing\nthat p nor fully not believing that p. For Porcher\n(2012), self-deceivers show the limits of the folk psychological\nconcepts of belief and suggest the need to develop a dispositional\naccount of self-deception that focuses on the ways that\nself-deceivers’ dispositions deviate from those of stereotypical\nfull belief. Funkhouser (2009) also points to the limits of folk\npsychological concepts and suggests that in cases involving deep\nconflict between behavior and avowal “the self-deceived produce\na confused belief-like condition so that it is genuinely indeterminate\nwhat they believe regarding p.” Edwards (2013),\nhowever, rejects the claim that the belief is indeterminate or that\nfolk psychological concepts are inadequate. She argues that folk\npsychology offers a wide variety of nondoxastic attitudes such as\n‘hope,’ ‘suspicion,’ ‘anxiety,’ and the like that are more\nthan sufficient to explain self-deception without adverting to belief.\nIn her view, the so-called doxastic problem can be resolved simply by\navoiding the attribution of doxastic attitudes of any kind. \nWhile revision of belief approaches suggest a number of\nnon-paradoxical ways of thinking about self-deception. Some worry that\nthose approaches denying that self-deceivers hold the welcome but\nunwarranted belief that p eliminate what is central to the\nnotion of self-deception, namely, deception (see e.g., Lynch\n2012, Mele 2010). On such approaches, self-deceivers may be mistaken\nabout what they believe, but they don’t actually hold an\nunwarranted belief regarding the target proposition at the first-order\nlevel. However, those approaches focusing on higher-order beliefs\nlocate the deception or error at the second-order level. The\nSelf-deceiver’s false belief that she believe that p is\nunwarranted and may well be the result of motivation (Funkhouser 2005;\nFernández 2013). Interestingly, if this false second-order\nbelief is acquired in a suitably biased way, it may fit Mele’s\ndeflationary protoanalysis (Mele 2009), which is not restricted to\nfirst-order beliefs, thus capturing the intuition that self-deceivers\nare, in fact, deceived about something. Whatever the verdict, these\nrevision of belief approaches suggest that our way of characterizing\nbelief may not be fine-grained enough to account for the subtle\nattitudes or meta-attitudes self-deceivers bear to the proposition in\nquestion. Taken together these approaches make it clear that the\nquestion regarding what self-deceivers believe is by means\nresolved. \nSelf-deception that involves the acquisition of an unwanted belief,\ntermed ‘twisted self-deception’ by Mele (1999, 2001), has\ngenerated a small but growing literature of its own, most recently,\nBarnes (1997), Mele (1999, 2001), Scott-Kakures (2000; 2001). A\ntypical example of such self-deception is the jealous husband who\nbelieves on weak evidence that his wife is having an affair, something\nhe doesn’t want to be the case. In this case, the husband\napparently comes to have this false belief in the face of strong\nevidence to the contrary in ways similar to those ordinary\nself-deceivers come to believe something they want to be true.  \nOne question philosophers have sought to answer is how a single\nunified account of self-deception can explain both welcome and\nunwelcome beliefs. If a unified account is sought, then it seems\nself-deception cannot require that the self-deceptive belief itself be\ndesired. Pears (1984) has argued that unwelcome belief might be driven\nby fear or jealousy. My fear of my house burning down might motivate\nmy false belief that I have left the stove burner on. This unwelcome\nbelief serves to ensure that I avoid what I fear, since it leads me to\nconfirm that the burner is off. Barnes (1997) argues that the\nunwelcome belief must serve to reduce some relevant anxiety; in this\ncase my anxiety that my house is burning. Scott-Kakures (2000; 2001)\nargues, however, that since the unwelcome belief itself does not in\nmany cases serve to reduce but rather to increase anxiety or fear,\ntheir reduction cannot be the purpose of that belief. Instead, he\ncontends that we think of the belief as serving to make the\nagent’s goals and interests more probable than not, in my case,\npreserving my house. My testing and confirming an unwelcome belief may\nbe explained by the costs I associate with being in error, which is\ndetermined in view of my relevant aims and interests. If I falsely\nbelieve that I have left the burner on, the cost is relatively\nlow—I am inconvenienced by confirming that it is off. If I\nfalsely believe that I have not left the burner on, the cost is\nextremely high—my house being destroyed by fire. The asymmetry\nbetween these relative costs alone may account for my manipulation of\nevidence confirming the false belief that I have left the burner on.\nDrawing upon recent empirical research, both Mele (2001) and\nScott-Kakures (2000) advocate a model of this sort, since it helps to\naccount for the roles desires and emotions apparently play in cases of\ntwisted self-deception. Specifically, Mele refuses to identify the\nmotivating desire as a desire that p, leaving the content of\nthe motivation in question open. Nelkin (2002), however, argues that\nthe motivation for self-deceptive belief formation should be\nrestricted to a desire to believe that p. She points\nout that the phrase “unwelcome belief” is ambiguous, since\na belief itself might be desirable even if its being true is not. I\nmight want to hold the belief that I have left the burner on, but not\nwant it to be the case that I have left it on. The belief is desirable\nin this instance, because holding it ensures that it will not be true.\nIn Nelkin’s view, then, what unifies cases of\nself-deception—both twisted and straight—is that the\nself-deceptive belief is motivated by a desire to believe that\np; what distinguishes them is that twisted self-deceivers do\nnot want p to be the case, while straight self-deceivers do.\nRestricting the motivating desire to a desire to believe that\np, according to Nelkin, makes clear what twisted and straight\nself-deception have in common as well as why other forms of motivated\nbelief formation are not cases of self-deception. Mele (2009) argues\nthat self-deceivers need not have the specific desire to believe that\np, since a variety of other desires might well alter the\nacceptance thresholds such that p is believed, even a desire\nnot to acquire a false belief that p might serve to motivate\nself-deceptive belief that p.  \nNelkin (2012) acknowledges the boundaries between cases of\nself-deception and other sorts of irrational motivated belief are\nblurry, but notes that scrutiny of the content of the motivation is\nnecessary for adjudicating individual cases, and suggests that the\nnearer this content gets to the desire to believe that p the\nmore clearly it is a case of self-deception. Moreover, she contends\nthat her “desire to believe” model helps to differentiate\nself-deception from other cases of motivated biased belief and to\nexplain why self-deceivers may be morally responsible in some cases\n(see section 5.1 below). Though non-intentional models of twisted\nself-deception dominate the landscape, whether desire, emotion or some\ncombination of these attitudes plays the dominant role in such\nself-deception and whether their influence merely triggers the process\nor continues to guide it throughout remain matters of controversy.\n \nDespite the fact that much of the contemporary philosophical\ndiscussion of self-deception has focused on epistemology,\nphilosophical psychology and philosophy of mind, the morality of\nself-deception has been the central focus of discussion historically.\nAs a threat to moral self-knowledge, a cover for immoral activity, and\na violation of authenticity, self-deception has been thought to be\nmorally wrong or, at least, morally dangerous. Some thinkers, what\nMartin (1986) calls ‘the vital lie tradition’, however,\nhave held that self-deception can in some instances be salutary,\nprotecting us from truths that would make life unlivable (e.g., Rorty\n1972; 1994). There are two major questions regarding the morality of\nself-deception: First, can a person be held morally responsible for\nself-deception and if so under what conditions? Second, is there is\nanything morally problematic with self-deception, and if so, what and\nunder what circumstances? The answers to these questions are clearly\nintertwined. If self-deceivers cannot be held responsible for\nself-deception, then their responsibility for whatever morally\nobjectionable consequences it might have will be mitigated if not\neliminated. Nevertheless, self-deception might be morally significant\neven if one cannot be taxed for entering into it. To be ignorant of\none’s moral self, as Socrates saw, may represent a great\nobstacle to a life well lived whether or not one is at fault for such\nignorance. \nWhether self-deceivers can be held responsible for their\nself-deception is largely a question of whether they have the\nrequisite control over the acquisition and maintenance of their\nself-deceptive belief. In general, intentionalists hold that\nself-deceivers are responsible, since they intend to acquire the\nself-deceptive belief, usually recognizing the evidence to the\ncontrary. Even when the intention is indirect, such as when one\nintentionally seeks evidence in favor of p or avoids\ncollecting or examining evidence to the contrary, self-deceivers seem\nintentionally to flout their own normal standards for gathering and\nevaluating evidence. So, minimally, they are responsible for such\nactions and omissions.  \nInitially, non-intentionalist approaches may seem to remove the agent\nfrom responsibility by rendering the process by which she is\nself-deceived subintentional. If my anxiety, fear, or desire triggers\na process that ineluctably leads me to hold the self-deceptive belief,\nI cannot be held responsible for holding that belief. How can I be\nheld responsible for processes that operate without my knowledge and\nwhich are set in motion without my intention? Most non-intentionalist\naccounts, however, do allow for the possibility that self-deceivers\nare responsible for individual episodes of self-deception, or for the\nvices of cowardice and lack of self-control from which they spring, or\nboth. To be morally responsible in the sense of being an appropriate\ntarget for praise or blame requires, at least, that agents have\ncontrol over the actions in question. Mele (2001), for example, argues\nthat many sources of bias are controllable and that self-deceivers can\nrecognize and resist the influence of emotion and desire on their\nbelief acquisition and retention, particularly in matters they deem to\nbe important, morally or otherwise. The extent of this control,\nhowever, is an empirical question. Nelkin (2012), however, argues that\nsince Mele’s account leaves the content of motivation driving\nthe bias unrestricted, the mechanism in question is so complex that\n“it seems unreasonable to expect the self-deceiver to [be] guard\nagainst” its operation.  \nOther non-intentionalists take self-deceivers to be responsible for\ncertain epistemic vices such as cowardice in the face of fear or\nanxiety and lack of self-control with respect the biasing influences\nof desire and emotion. Thus, Barnes (1997) argues that self-deceivers\n“can, with effort, in some circumstances, resist their\nbiases” (83) and “can be criticized for failing to take\nsteps to prevent themselves from being biased; they can be criticized\nfor lacking courage in situations where having courage is neither\nsuperhumanly difficult nor costly” (175). Whether self-deception\nis due to a character defect or not, ascriptions of responsibility\ndepend upon whether the self-deceiver has control over the biasing\neffects of her desires and emotions.  \nLevy (2004) has argued that non-intentional accounts of self-deception\nthat deny the contradictory belief requirement should not suppose that\nself-deceivers are typically responsible, since it is rarely the case\nthat self-deceivers possess the requisite awareness of the biasing\nmechanisms operating to produce their self-deceptive belief. Lacking\nsuch awareness, self-deceivers do not appear to know when or on which\nbeliefs such mechanisms operate, rendering them unable to curb the\neffects of these mechanisms, even when they operate to form false\nbeliefs about morally significant matters. Levy also argues that if\nself-deceivers typically lack the control necessary for moral\nresponsibility in individual episodes of self-deception, they also\nlack control over being the sort of person disposed to\nself-deception. \nNon-intentionalists may respond by claiming that self-deceivers often\nare aware of the potentially biasing effects their desires and\nemotions might have and can exercise control over them (DeWeese-Boyd\n2007). They might also challenge the idea the self-deceivers must be\naware in the ways Levy suggests. One well known account of control,\nemployed by Levy, holds that a person is responsible just in case she\nacts on a mechanism that is moderately responsive to reasons\n(including moral reasons), such that were she to possess such reasons\nthis same mechanism would act upon those reasons in at least one\npossible world (Fischer and Ravizza 1999). Guidance control, in this\nsense, requires that the mechanism in question be capable of\nrecognizing and responding to moral and non-moral reasons sufficient\nfor acting otherwise. In cases of self-deception, deflationary views\nmay suggest that the biasing mechanism, while sensitive and responsive\nto motivation, is too simple to itself be responsive to reasons.\nNelkin (2011, 2012) argues for understanding reasons responsiveness to\napply to the agent, not the mechanism, requiring that\nagent’s have the capacity to exercise reason in the situation\nunder scrutiny. Accordingly, the question isn’t whether the\nbiasing mechanism itself is reasons responsive but whether the agent\ngoverning its operation is, that is, whether self-deceivers typically\ncould recognize and respond to moral and non-moral reasons to resist\nthe influence of their desires and emotions and instead exercise\nspecial scrutiny of the belief in question. According to Nelkin\n(2012), expecting self-deceivers to have such a capacity is more\nlikely if we understand the desire driving their bias a desire to\nbelieve that p, since awareness of this sort of\ndesire would make it easier to guard against its influence on the\nprocess of determining whether p. In view of these\nconsiderations, it is plausible that self-deceivers have the requisite\ncontrol for moral responsibility on deflationary approaches, and\ncertainly not obvious that they lack it. \nInsofar as it seems plausible that in some cases self-deceivers are\napt targets for censure, what prompts this attitude? Take the case of\na mother who deceives herself into believing her husband is not\nabusing their daughter because she can’t bear the thought that he\nis a moral monster (Barnes 1997). Why do we blame her? Here we\nconfront the nexus between moral responsibility for self-deception and\nthe morality of self-deception. Understanding what obligations may be\ninvolved and breached in cases of this sort will help to clarify the\ncircumstances in which ascriptions of responsibility are\nappropriate. \nWhile some instances of self-deception seem morally innocuous and\nothers may even be thought salutary in various ways (Rorty 1994), the\nmajority of theorists have thought there to be something morally\nobjectionable about self-deception or its consequences in many cases.\nSelf-deception has been considered objectionable because it\nfacilitates harm to others (Linehan 1982) and to oneself, undermines\nautonomy (Darwall 1988; Baron 1988), corrupts conscience (Butler\n1722), violates authenticity (Sartre 1943), manifests a vicious lack\nof courage and self-control that undermine the capacity for\ncompassionate action (Jenni 2003), violates an epistemic duty to\nproperly ground self-ascriptions (Fernández 2013), or violates\na general duty to form beliefs that “conform to the available\nevidence” (Nelkin 2012). Linehan (1982) argues that we have an\nobligation to scrutinize the beliefs that guide our actions that is\nproportionate to the harm to others such actions might involve. When\nself-deceivers induce ignorance of moral obligations, of the\nparticular circumstances, of likely consequences of actions, or of\ntheir own engagements, by means of their self-deceptive beliefs, they\nmay be culpable. They are guilty of negligence with respect to their\nobligation to know the nature, circumstances, likely consequences and\nso forth of their actions (Jenni 2003; see also Nelkin 2012).\nSelf-deception, accordingly, undermines or erodes agency by reducing\nour capacity for self-scrutiny and change. (Baron 1988) If I am\nself-deceived about actions or practices that harm others or myself,\nmy ability to take responsibility and change are also severely\nrestricted. Joseph Butler, in his well-known sermon “On\nSelf-Deceit”, emphasizes the ways in which self-deception about\none’s moral character and conduct, ‘self-ignorance’\ndriven by inordinate ‘self-love’, not only facilitates\nvicious actions but hinders the agent’s ability to change by\nobscuring them from view. Such ignorance, claims Butler,\n“undermines the whole principle of good … and corrupts\nconscience, which is the guide of life” (“On\nSelf-Deceit”). Existentialist philosophers such as Kierkegaard\nand Sartre, in very different ways, viewed self-deception as a threat\nto ‘authenticity’ insofar as self-deceivers fail to take\nresponsibility for themselves and their engagements past, present and\nfuture. By alienating us from our own principles, self-deception may\nalso threaten moral integrity (Jenni 2003). Furthermore,\nself-deception also manifests certain weakness of character that\ndispose us to react to fear, anxiety, or the desire for pleasure in\nways that bias our belief acquisition and retention in ways that serve\nthese emotions and desires rather than accuracy. Such epistemic\ncowardice and lack of self-control may inhibit the ability of\nself-deceivers to stand by or apply moral principles they hold by\nbiasing their beliefs regarding particular circumstances, consequences\nor engagements, or by obscuring the principles themselves. In all\nthese ways and a myriad of others, philosophers have found some\nself-deception objectionable in itself or for the consequences it has\non our ability to shape our lives. \nThose finding self-deception morally objectionable generally assume\nthat self-deception or, at least, the character that disposes us to\nit, is under our control to some degree. This assumption need not\nentail that self-deception is intentional only that it is avoidable in\nthe sense that self-deceivers could recognize and respond to reasons\nfor resisting bias by exercising special scrutiny (see section 5.1).\nIt should be noted, however, that self-deception still poses a serious\nworry even if one cannot avoid entering into it, since self-deceivers\nmay nevertheless have an obligation to overcome it. If exiting\nself-deception is under the guidance control of self-deceivers, then\nthey might reasonably be blamed for persisting in their self-deceptive\nbeliefs when they regard matters of moral significance. \nBut even if agents don’t bear specific responsibility for their\nbeing in that state, self-deception may nevertheless be morally\nobjectionable, destructive and dangerous. If radically deflationary\nmodels of self-deception do turn out to imply that our own desires and\nemotions, in collusion with social pressures toward bias, lead us to\nhold self-deceptive beliefs and cultivate habits of self-deception of\nwhich we are unaware and from which cannot reasonably be expected to\nescape on our own, self-deception would still undermine autonomy,\nmanifest character defects, obscure us from our moral engagements and\nthe like. For these reasons, Rorty (1994) emphasizes the importance of\nthe company we keep. Our friends, since they may not share our desires\nor emotions, are often in a better position to recognize our\nself-deception than we are. With the help of such friends,\nself-deceivers may, with luck, recognize and correct morally corrosive\nself-deception. \nEvaluating self-deception and its consequences for ourselves and\nothers is a difficult task. It requires, among other things:\ndetermining the degree of control self-deceivers have; what the\nself-deception is about (Is it important morally or otherwise?); what\nends the self-deception serves (Does it serve mental health or as a\ncover for moral wrongdoing?); how entrenched it is (Is it episodic or\nhabitual?); and, whether it is escapable (What means of correction are\navailable to the self-deceiver?). As Nelkin (2012) contends,\ndetermining whether and to what degree self-deceivers are culpably\nnegligent will ultimately need to be determined on a case by case\nbasis in light of answers to such questions about the stakes at play\nand the difficulty involved. Despite the difficulties involved in\nassigning responsibility, this discussion indicates the wide variety\nof serious moral problems associated with self-deception that account\nin part for the attention that has been devoted to this phenomenon\nfrom the very beginning, especially within the Christian tradition\n(e.g., Dyke 1633; Butler 1726). \nQuite aside from the doxastic, strategic and moral puzzles\nself-deception raises, there is the evolutionary puzzle of it’s\norigin. Why do human beings have this capacity in the first place? Why\nwould natural selection allow a capacity to survive that undermines\nthe accurate representation of reality, especially, when inaccuracies\nabout individual ability or likely risk can lead to catastrophic\nerrors?  \nMany argue that self-deceptively inflated views of ourselves, our\nabilities, our prospects, our control, so-called ‘positive\nillusions’, confer direct benefits in terms of psychological\nwellbeing, physical health and social advancement that serve fitness\n(Taylor and Brown, 1994; Taylor, 1989; McKay and Dennett, 2009). Just\nbecause ‘positive illusions’ make us ‘feel\ngood,’ of course, it does not follow that they are adaptive.\nFrom an evolutionary perspective, whether an organism ‘feels\ngood’ or is ‘happy’ is not significant unless it\nenhances survival and reproduction. McKay and Dennett (2009) argue\nthat positive illusions are not only tolerable evolutionarily\nspeaking, they actually appear to directly contribute to fitness.\nOverly positive beliefs about our abilities or chances for success\nappear to make us more apt to exceed our abilities and achieve success\nthan more accurate beliefs would (Taylor and Brown 1994, Bandura\n1989). According to Johnston and Fowler (2011), overconfidence is\n“advantageous, because it encourages individuals to claim\nresources they could not otherwise win if it came to a conflict\n(stronger but cautious rivals will sometime fail to make a claim, and\nit keeps them from walking away from conflicts they would surely\nwin.” Inflated attitudes regarding the personal qualities and\ncapacities of one’s partners and children also would seem to enhance\nfitness by facilitating the thriving of offspring (McKay and Dennett\n2009).  \nAlternatively, some argue that self-deception evolved to facilitate\ninterpersonal deception by eliminating the cues and cognitive load\nthat consciously lying produces and by mitigating retaliation should\nthe deceit become evident (von Hippel and Trivers 2011; Trivers 2011,\n2000, 1991). On this view, the real gains associated with ‘positive\nillusions’ and other self-deceptions are byproducts that serve this\ngreater evolutionary end by enhancing self-deceiver’s ability to\ndeceive. Von Hippel and Trivers (2011) contend that “by\ndeceiving themselves about their own positive qualities and the\nnegative qualities of others, people are able to display greater\nconfidence than they might otherwise feel, thereby enabling them to\nadvance socially and materially.” Critics have pointed to data\nsuggesting high self-deceivers are deemed less trustworthy than low\nself-deceivers (McKay and Dennett 2011). Others have complained that\nthere is little data to support this hypothesis (Dunning 2011, Van\nLeeuwen 2007a, 2013a). Some challenge this theory by noting that a\nsimple disregard for the truth would serve as well as self-deception\nand have the advantage of retaining true representations (McKay and\nPrelec 2011), or that often self-deceivers are the only one’s\ndeceived (Van Leeuwen 2007a; Kahlil 2011). Van Leeuwen (2013a) raises\nthe concern that the wide variety of phenomena identified by this\ntheory as self-deception render the category so broad that it is\ndifficult to tell whether it is a unified phenomenon traceable to\nparticular mechanisms that could plausibly be sensitive to selection\npressures.  \nIn view of these shortcomings, Van Leeuwen (2007a) argues the capacity\nfor self-deception is not a product of evolution; it is a\nspandrel—a byproduct of other aspects of our cognitive\narchitecture—not an adaptation, at least, not in the strong\nsense of being positively selected. That leaves open the possibility\nthat this capacity has nevertheless been retained as a consequence of\nits fitness value. Lopez and Fuxjager (2011) argue that the broad\nresearch on the so called “winner effect”—the\nincreased probability to achieve victory in social or physical\nconflicts following prior victories—lends support to the idea\nthat self-deception is at least weakly adaptive, since self-deception\nin the form of positive illusions, like past wins, confers a fitness\nadvantage. Lamba and Nityananda (2014) test the theory that\nself-deceived are better at deceiving others, specifically whether\noverconfident individuals are overrated by others and underconfident\nindividuals, underrated. In their study, students in tutorials were\nasked to predict their own performance on the next assignment as well\nas that of each of their peers in the tutorial in terms of absolute\ngrade and relative rank. Comparing these predictions and the actual\ngrades given on the assignment suggests a strong positive relationship\nbetween self-deception and deception. Those who self-deceptively rated\nthemselves higher were rated higher by their peers as well. These\nfindings lend suggestive support to the claim self-deception\nfacilitates other deception. While these studies certainly do not\nsupply all the data necessary to support the theory that the\npropensity to self-deception should be viewed as adaptation, they do\nsuggest ways to test these evolutionary hypotheses by focusing upon\nspecific phenomena. Whether or not the psychological and social\nbenefits identified by these theories explain the evolutionary origins\nof the capacity for self-deceit, they may well shed light on its\nprevalence and persistence, as well as pointing to ways to identify\ncontexts in which this tendency presents high collective risk (Lamba\nand Nityandanda 2014). \nCollective self-deception has received scant direct philosophical\nattention as compared with its individual counterpart. Collective\nself-deception might refer simply to a group of similarly\nself-deceived individuals or to a group-entity, such as a corporation,\ncommittee, jury or the like, that is self-deceived. These alternatives\nreflect two basic perspectives social epistemologists have taken on\nascriptions of propositional attitudes to collectives. On the one\nhand, such attributions might be taken summatively as simply\nan indirect way of attributing those states to members of the\ncollective (Quinton 1975/1976). This summative understanding, then,\nconsiders attitudes attributed to groups to be nothing more than\nmetaphors expressing the sum of the attitudes held by their members.\nTo say that students think tuition is too high is just a way of saying\nthat most students think so. On the other hand, such attributions\nmight be understood non-summatively as applying to collective\nentities, themselves ontologically distinct from the members upon\nwhich they depend. These so-called ‘plural subjects’\n(Gilbert 1989, 1994, 2005) or ‘social integrates’ (Pettit\n2003), while supervening upon the individuals comprising them, may\nwell express attitudes that diverge from individual members. For\ninstance, saying NASA believed the O-rings on the space\nshuttle’s booster rockets to be safe need not imply that most or\nall the members of this organizations personally held this belief only\nthat the institution itself did. The non-summative understanding,\nthen, considers collectives to be, like persons, apt targets for\nattributions of propositional attitudes, and potentially of moral and\nepistemic censure as well. Following this distinction, collective\nself-deception may be understood in either a summative or\nnon-summative sense. \nIn the summative sense, collective self-deception refers to\nself-deceptive belief shared by a group of individuals, who each come\nto hold the self-deceptive belief for similar reasons and by similar\nmeans, varying according to the account of self-deception followed. We\nmight call this self-deception across a collective. In the\nnon-summative sense, the subject of collective self-deception is the\ncollective itself, not simply the individuals comprising it. The\nfollowing sections offer an overview of these forms of collective\nself-deception, noting the significant challenges posed by each. \nUnderstood summatively, we might define collective self-deception as\nthe holding of a false belief in the face of evidence to the contrary\nby a group of people as a result of shared desires, emotions, or\nintentions (depending upon the account of self-deception) favoring\nthat belief. Collective self-deception is distinct from other forms of\ncollective false belief—such as might result from deception or\nlack of evidence—insofar as the false belief issues from the\nagents’ own self-deceptive mechanisms (however these are\nconstrued), not the absence of evidence to the contrary or presence of\nmisinformation. Accordingly, the individuals constituting the group\nwould not hold the false belief if their vision weren’t\ndistorted by their attitudes (desire, anxiety, fear or the like)\ntoward the belief. What distinguishes collective self-deception from\nsolitary self-deception just is its social context, namely, that it\noccurs within a group that shares both the attitudes bringing about\nthe false belief and the false belief itself. Compared to its solitary\ncounterpart, self-deception within a collective is both easier to\nfoster and more difficult to escape, being abetted by the\nself-deceptive efforts of others within the group. \nVirtually all self-deception has a social component, being wittingly\nor unwittingly supported by one's associates (See Ruddick 1988). In\nthe case of collective self-deception, however, the social dimension\ncomes to the fore, since each member of the collective unwittingly\nhelps to sustain the self-deceptive belief of the others in the group.\nFor example, my cancer stricken friend might self-deceptively believe\nher prognosis to be quite good. Faced with the fearful prospect of\ndeath, she does not form accurate beliefs regarding the probability of\nher full recovery, attending only to evidence supporting full recovery\nand discounting or ignoring altogether the ample evidence to the\ncontrary. Caring for her as I do, I share many of the anxieties, fears\nand desires that sustain my friend’s self-deceptive belief, and\nas a consequence I form the same self-deceptive belief via the same\nmechanisms. In such a case, I unwittingly support my friend’s\nself-deceptive belief and she mine—our self-deceptions are\nmutually reinforcing. We are collectively or mutually self-deceived,\nalbeit on a very small scale. Ruddick (1988) calls this ‘joint\nself-deception.’ \nOn a larger-scale, sharing common attitudes, large segments of a\nsociety might deceive themselves together. For example, we share a\nnumber of self-deceptive beliefs regarding our consumption patterns.\nMany of the goods we consume are produced by people enduring labor\nconditions we do not find acceptable and in ways that we recognize are\nenvironmentally destructive and likely unsustainable. Despite our\nbeing at least generally aware of these social and environmental\nramifications of our consumptive practices, we hold the overly\noptimistic beliefs that the world will be fine, that its peril is\noverstated, that the suffering caused by the exploitive and\necologically degrading practices are overblown, that our own\nconsumption habits are unconnected to these sufferings anyway, even\nthat our minimal efforts at conscientious consumption are an adequate\nremedy (See, Goleman 1989). When self-deceptive beliefs such as these\nare held collectively, they become entrenched and their consequences,\ngood or bad, are magnified (Surbey 2004). \nThe collective entrenches self-deceptive beliefs by providing positive\nreinforcement by others sharing the same false belief, as well as\nprotection from evidence that would destabilize the target belief.\nThere are, however, limits to how entrenched such beliefs can become\nand remain self-deceptive. The social support cannot be the sole or\nprimary cause of the self-deceptive belief, for then the belief would\nsimply be the result of unwitting interpersonal deception and not the\ndeviant belief formation process that characterizes self-deception. If\nthe environment becomes so epistemically contaminated as to make\ncounter-evidence inaccessible to the agent, then we have a case of\nfalse belief, not self-deception. Thus, even within a collective a\nperson is self-deceived just in case she would not hold her false\nbelief if she did not possess the motivations skewing her belief\nformation process. This said, relative to solitary self-deception, the\ncollective variety does present greater external obstacles to avoiding\nor escaping self-deception, and is for this reason more entrenched. If\nthe various proposed psychological mechanisms of self-deception pose\nan internal challenge to the self-deceiver’s power to control\nher belief formation, then these social factors pose an external\nchallenge to the self-deceiver’s control. Determining the how\nsuperable this challenge is will affect our assessment of individual\nresponsibility for self-deception as well as the prospects of\nunassisted escape from it. \nCollective self-deception can also be understood from the perspective\nof the collective itself in a non-summative sense. Though there are\nvarying accounts of group belief, generally speaking, a group can be\nsaid to believe, desire, value or the like just in case its members\n“jointly commit” to these things as a body (Gilbert 2005).\nA corporate board, for instance, might be jointly committed as a body\nto believe, value and strive for whatever the CEO recommends. Such\ncommitment need not entail that each individual board member\npersonally endorses such beliefs, values or goals, only that as\nmembers of the board they do (Gilbert 2005). While philosophically\nprecise accounts of non-summative self-deception remain largely\nunarticulated, the possibilities mirror those of individual\nself-deception. When collectively held attitudes motivate a group to\nespouse a false belief despite the group’s possession of\nevidence to the contrary, we can say that the group is collectively\nself-deceived in a non-summative sense. \nFor example, Robert Trivers (2000) suggests that ‘organizational\nself-deception’ led to NASA’s failure to represent\naccurately the risks posed by the space shuttle’s O-ring design,\na failure that eventually led to the Challenger disaster. The\norganization as a whole, he argues, had strong incentives to represent\nsuch risks as small. As a consequence, NASA’s Safety Unit\nmishandled and misrepresented data it possessed that suggested that\nunder certain temperature conditions the shuttle’s O-rings were\nnot safe. NASA, as an organization, then, self-deceptively believed\nthe risks posed by O-ring damage were minimal. Within the institution,\nhowever, there were a number of individuals who did not share this\nbelief, but both they and the evidence supporting their belief were\ntreated in a bias manner by the decision-makers within the\norganization. As Trivers (2000) puts it, this information was\nrelegated “to portions of … the organization that [were]\ninaccessible to consciousness (we can think of the people running NASA\nas the conscious part of the organization).” In this case,\ncollectively held values created a climate within NASA that clouded\nits vision of the data and led to its endorsement of a fatally false\nbelief. \nCollective self-deceit may also play a significant role in\nfacilitating unethical practices by corporate entities. For example, a\ncollective commitment by members of a corporation to maximizing\nprofits might lead members to form false beliefs about the ethical\npropriety of the corporation’s practices. Gilbert (2005)\nsuggests that such a commitment might lead executives and other\nmembers to “simply lose sight of moral constraints and values\nthey previously held”. Similarly, Tenbrunsel and Messick (2004)\nargue that self-deceptive mechanisms play a pervasive role in what\nthey call ‘ethical fading’, acting as a kind of\n‘bleach’ that renders organizations blind to the ethical\ndimensions of their decisions. They argue that such self-deceptive\nmechanisms must be recognized and actively resisted at the\norganizational level if unethical behavior is to be avoided. More\nspecifically, Gilbert (2005) contends that collectively accepting that\n“certain moral constraints must rein in the pursuit of corporate\nprofits” might shift corporate culture in such a way that\nefforts to respect these constraints are recognized as part of being a\ngood corporate citizen. In view of the ramifications this sort of\ncollective self-deception has for the way we understand corporate\nmisconduct and responsibility, understanding its specific nature in\ngreater detail remains an important task. \nCollective self-deception understood in either the summative or\nnon-summative sense raises a number of significant questions such as\nwhether individuals within collectives bear responsibility for their\nself-deception or the part they play in the collective’s\nself-deception, and whether collective entities can be held\nresponsible for their epistemic failures. Finally, collective\nself-deception prompts us to ask what means are available collectives\nand their members to resist, avoid and escape self-deception. To\nanswer these and other questions, more precise accounts of these forms\nof self-deception are needed. Given the capacity of collective\nself-deception to entrench false beliefs and to magnify their\nconsequences—sometimes with disastrous results—collective\nself-deception is not just a philosophical puzzle; it is a problem\nthat demands attention.","contact.mail":"ian.deweese-boyd@gordon.edu","contact.domain":"gordon.edu"}]
