[{"date.published":"2011-11-02","url":"https://plato.stanford.edu/entries/culture-cogsci/","author1":"Jesse Prinz","author1.info":"http://philosophy.unc.edu/people/jesse-prinz/","entry":"culture-cogsci","body.text":"\n\n\n\nWithin Western analytic philosophy, culture has not been a major topic\nof discussion. It sometimes appears as a topic in the philosophy of\nsocial science, and in continental philosophy, there is a long\ntradition of “Philosophical Anthropology,” which deals\nwith culture to some degree. Within core areas of analytic philosophy,\nculture has most frequently appeared in discussions of moral\nrelativism, radical translation, and discussions of perceptual\nplasticity, though little effort has been made to seriously\ninvestigate the impact of culture on these domains. Cognitive science\nhas also neglected culture, but in recent years, that has started to\nchange. There has been a sizable intensification of efforts to\nempirically test the impact of culture on mental processes. This entry\nsurveys ways in which the emerging cognitive science of culture has\nbeen informing philosophical debates.\n\n\n\nThe meaning of the term “culture” has been highly\ncontested, especially within anthropology (Kroeber and Kluckhohn 1952;\nBaldwin et al. 2006). The first highly influential definition came\nfrom Edward Tylor (1871, 1), who opens his seminal anthropology text\nwith the stipulation that culture is, “that complex whole which\nincludes knowledge, belief, art, law, morals, custom, and any other\ncapabilities and habits acquired by man as a member of society.”\nSubsequent authors have worried that Tylor's definition packs in too\nmuch, lumping together psychological items (e.g., belief) with\nexternal items (e.g., art). From a philosophical perspective, this\nwould be especially problematic for those who hope that culture could\nbe characterized as a natural kind, and thus as a proper subject for\nscientific inquiry. Other definitions often try to choose between the\nexternal and internal options in Tylor's definition. \n\nOn the external side, anthropologists have focused on both artifacts\nand behaviors. Herskovits (1948, 17) tells us that, “Culture is\nthe man-made part of the environment,” and Meade (1953, 22) says\nculture “is the total shared, learned behavior of a society or a\nsubgroup.” These dimensions are combined in Malinowski's (1931,\n623) formulation: “Culture is a well organized unity divided\ninto two fundamental aspects—a body of artifacts and a system of\ncustoms.” \n\nMore recently, externally focused definitions of culture have taken a\nsemiotic turn. According to Geertz (1973, 89), culture is “an\nhistorically transmitted pattern of meanings embodied in\nsymbols.” Culture, on such a view, is like a text—something\nthat needs to be interpreted through the investigation of symbols. For\nGeertz, interpretation involves the production of “thick\ndescriptions,” in which behavioral practices are described in\nsufficient detail to trace inferential associations between observed\nevents. It's not sufficient to refer to an observed ritual as a\n“marriage;” one must recognize that nuptial rites have\nvery different sequelae across social groups, and these must be\ndescribed. Ideally, the anthropologist can present a culture from the\npoint of view of its members. \n\nGeertz's thick descriptions may seem to move from the external focus\nof earlier approaches into a more psychological arena, but he does not\ntake interpretation to centrally involve psychological testing. The\nterm “thick description” is taken over from Ryle (1971),\nwhose approach to the mind emphasizes behavioral dispositions. An even\nmore radical break from psychology can be found in an approach called\n“cultural materialism” (Harris 2001). Cultural\nmaterialists believe that thick description thwarts explanation,\nbecause the factors that determine social practices are largely\nunknown to practitioners. For Harris, these factors principally\ninvolve material variables, such as the ecological conditions in which\na group lives and the technologies available to it. Cultural variation\nand change can be best explained by these factors without describing\nrichly elaborated practices, narratives, or psychological\nstates. Harris calls the materialistic approach “etic” and\ncontrasts it with the “emic” approaches, which try to\ncapture a culture from within. This differs from Tylor's\nexternal/internal distinction because even external cultural items,\nsuch as artworks, may be part of emic analyses on Harris's model,\nsince they belong to the symbolic environment of culture rather than,\nsay, the ecological or technological environments—variables that\ncan be repeated across cultural contexts. Harris aims for\ngeneralizations whereas Geertz aims for (highly particular)\ninterpretations. The debate between semioticians and materialists can\nbe described as a debate about whether anthropology is best pursued as\none of the humanities or as a science. \n\nAside from Tylor, the approaches that we have been surveying focus on\nexternal variables, with Harris's cultural materialism occupying one\nextreme. But psychological approaches to culture are also prevalent,\nand they have gained popularity as cognitive science has taken a\ncultural turn. D'Andrade (1995, 143) tells us that, since the 1950s,\n“Culture is often said to consist in rules… These rules\nare said to be implicit because ordinary people can't tell you what\nthey are” (D'Andrade himself favors a more encompassing,\nprocessual definition, which includes both external items and the\ncognitive processes that interact with them). Richerson and Boyd\n(2005, 5) define culture as “information capable of affecting\nindividuals' behavior that they acquire from other members of their\nspecies through teaching, imitation, and other forms of social\ntransmission.” Sperber (1996, 33) describes culture in terms of\n“widely distributed, lasting mental and public representations\ninhabiting a given social group.” \n\nThose who advance definitions of culture do not necessarily assume \nthat\na good analysis must be faithful to the colloquial understanding of\nthat term. Rather, these definitions are normative, insofar as\nthey can be used to guide research. A focus on artifacts might\norient research towards manufactured objects and institutions, a focus\non behavior might promote exploration of human activities, a focus on\nsymbols might take language as a principal subject of study, a\nmaterialist orientation might shift attention toward ecology, and a\nfocus on mental states might encourage psychological testing.\nPhilosophically, definitions that focus on external variables tend to\nimply that culture is not reducible to the mental states of\nindividuals, whereas psychological definitions may imply the\n opposite. This bears on debates about \n methodological individualism.\n At one extreme, there are definitions like Richerson and Boyd's\n(culture as information) that leave external variables out, and, at \nthe\nother, there are authors such as Harris, who say psychology can be\nignored. \n\nIn summary, most definitions characterize culture as something that\nis widely shared by members of a social group and shared in virtue of\nbelonging to that group. As stated, this formulation is too\ngeneral to be sufficient (a widespread influenza outbreak would qualify as\ncultural). Thus, this formulation must be refined by offering a\nspecific account of what kind of shared items qualify as cultural, and\nwhat kind of transmission qualifies as social. The definitions\nreviewed here illustrate that such refinements are matters of\ncontroversy. \n\nOne common thread in the definitions just surveyed is that culture\nis socially transmitted. That point was already emphasized in\nTylor's seminal definition. Social transmission is a major\narea of research and various theories have been offered to explain how\nit works. \n\nIt is a platitude that cultures change over time. Some\nresearch studies the nature of these changes. Such changes are\noften described under the rubric of cultural evolution. As the\nterm suggests, cultural change may resemble biological change in\nvarious respects. As with biological traits, we can think of\nculture as having trait-like units that arise and then spread to\nvarying degrees. The study of cultural evolution explores the\nfactors that can determine which cultural traits get passed on. \n\nSome authors push the analogy between cultural evolution and\nbiological evolution very far. Within biology, the most celebrated\nevolutionary process is natural selection: traits that increase\nfitness are more likely than others to get passed on from one\ngeneration to the next. 20th century evolutionary theory\n(“the modern synthesis”) supplements this Darwinian idea\nwith the principle that traits are transmitted genetically. Genes\nproduce traits (or phenotypes), which impact reproductive success, and\nthereby impact which genes will be copied into the next generation.\nRichard Dawkins (1976), who helped popularize this idea, suggests that\ncultural traits get reproduced in an analogous way. Dawkins\ncharacterizes cultural items as “memes” – a term\nthat echoes “gene” while emphasizing the idea that culture\nis passed on mimetically—that is, by imitation. Like a gene, a\nmeme will spread if it is successful (for development and defense, see\nDennett 1995; Blakemore 1999). \n\nSome authors have resisted the analogy, arguing that there are crucial\ndifferences between generic and cultural transmission (e.g., Atran\n2001; Boyd and Richerson 2001; Sperber 2001). In natural selection,\ngenes ordinarily spread vertically from parents to children. Cultural\nitems, in contrast, often spread laterally across peer groups, and can\neven spread from children to parents, as with the rise of email and\nother technological innovations.  Cultural traits are also spread in a\nway that is mediated by intentions, rather than blindly. A teacher may\nintend to spread a trait, and a student may recognize that the trait\nhas some value, and innovators may come up with new traits by\nintending to solve problems. Intentional creation is unlike random\nmutation because it can happen at a more rapid rate with immediate\ncorrection if the trait doesn't succeed. Success, too, is measured\ndifferently in the cultural case. Some cultural traits are passed on\nbecause they increase biological fitness, but traits that reduce\nreproduction rates, such as tools or war or contraception, can also\nspread, and many traits, such as music trends, spread without any\nimpact on procreation or survival. Unlike genes, cultural traits are\nalso copied imperfectly, sometimes changing slightly with each\ntransmission. And there is no clear distinction within culture between\na genotype and a phenotype; the trait that gets reproduced is often\nresponsible for the reproducing. For example, if someone learns to\nride a bicycle, there is no clear distinction between an inner\nmechanism and an outward manifestation; the skill is both the\nmechanism and its deployment. \n\nAll these contrasts suggest to some that the notion of a meme is\nmisleading. Cultural traits are spread in ways that differ\nsignificantly from genes. In an effort to bypass the comparison to\ngenes, Sperber (1996) offers an epidemiology analogy. Cultural\nitems, which for him are representations, are spread like\nviruses. They can be spread laterally, and they can reduce\nfitness. Viral transmission depends on contagion, and, like\nviruses, some cultural traits are catchier than others. That is\nto say, some traits are easier to learn—they are more psychologically\ncompelling. \n\nBoyer (2001) has applied this idea to the spread of religious\nbeliefs. Tales of the supernatural build on existing knowledge\nbut add variations that make them exciting, such as the idea of a \nperson\nwho can survive death and walk through walls. Boyer shows\nexperimentally that such exotic variations on ordinary categories are\neasy to remember and spread. \n\nThe epidemiology analogy may have limitations. For example,\nviruses do not usually spread with intentional mediation, and they are\noften harmful. But it has some advantages over the analogy to genetic\ntransmission. Ultimately, such analogies give way to actual models of\nhow transmission works. \n\nIn cultural transmission, an acquired trait possessed by one member\nof a social group ends up in another member of that group. In\norder for this to occur, there must be some learning mechanism that\neventuates in doing what another individual does. Traditional\nlearning mechanisms, such as associative learning, trial and error, \nand\nconditioning through reinforcement, are inadequate for explaining \nsocial\nlearning. If one individual performs a behavior in front of\nanother, the other may associate that behavior with the model, but\nassociation will not cause it to perform the behavior itself.\nLikewise, witnessing a behavior cannot lead to conditioning, because\nobservation alone does not have reinforcement value. Conditioning\ncan be used as a tool in social transmission, of course—a teacher\ncan reward a student—but such deployment depends on a prior\nachievement: the student must attempt to do what the teacher has done\nor instructed. Thus, transmission requires learning mechanisms\nthat go beyond those mentioned, mechanisms that cause a learner to\nreproduce what a model has done. \n\nIn a word, cultural transmission seems to depend on copying. When\nobserving a model, there are two things one might copy: the end or the\nmeans. If a model obtains fruit from a plant, an observer capable\nof copying ends may recognize that the plant bears fruit and try to\nobtain that fruit as a result of having seen what the model\nachieved. Tomasello (1996) calls such learning emulation.\nEmulation is not always successful, however, because one cannot always\nachieve an end without knowing the right means. Tomasello\nreserves the term “imitation” for cases where observers\nperform the actions that they observe. This is a powerful tool\nfor social transmission, and it is something human beings are very good\nat. Indeed there is evidence that we spontaneously imitate facial\nexpressions and gestures almost immediately after birth (Metzoff and\nMoore 1977). In fact, human children over-imitate: they copy\ncomplex stepwise procedures even when simpler ways of obtaining goals\nare conspicuously available (Horner and Whiten 2005). \n\nThe human tendency to imitate may help to explain why our capacity for\nsocial learning far exceeds other species. Apes may be more\nlikely to emulate than to imitate (Tomasello 1996). That is not\nto say that apes never imitate; they just imitate less than human\nbeings (Horner and Whiten 2005). Thus, apes do have some\ncapacity to learn from conspecifics. If culture is defined in terms of\npractices or abilities that are shared within groups in virtue of the\nachievements of particular group members, then one can even say that\napes have culture. Evidence for group-specific innovations, such\nas nut cracking techniques, have been found among chimpanzees (Whiten\net al. 2005) and orangutans (Van Schaik and Knott 2001).\nCulture and cultural transmission has also been documented in dolphins\n(Krützen et al. 2005). \n\nThis raises a question. If other creatures are capable of\ncultural transmission, why don't they show the extreme forms of\ncultural variation and accumulated cultural knowledge characteristic \nof\nour species? There are various possible answers. Great apes\nmay also be less innovative than humans, and this may stem from their\nlimited capacity to understand causal relations (Povinelli 2000), or\nto plan for the distant future. Apes may also have limitations on\nmemory that prevent them from building on prior innovations to create\ncultural products of ever-increasing complexity. In addition,\napes have less highly developed skills for mental state attribution\n(Povinelli 2000), and that may further reduce their capacity for\nimitative learning. Human infants do not just copy what adult\nmodels do; they copy what those models are trying to do (Metzoff,\n1995). Warneken and Tomasello (2006) have shown that young chimps\nunderstand intended actions to some degree, but less robustly than\ntheir human counterparts. Finally, the human capacity to build on\nprior innovations and transmit cultural knowledge is often\nlinguistically mediated, and apes and dolphins may have communication\nsystems with far more limited expressive potential, making it\nimpossible to move beyond simple copying and adopt the deferred form of\nimitation that we call instruction. \n\nIt is widely agreed that human cultural transmission often involves\nimitation, but there is also evidence that we do not imitate every\nbehavior we see. We imitate some observed behaviors more than\nothers. Much research explores the biases that we and other\ncreatures use when determining whom and when to imitate. \n\nBiases divide into two categories. Sometimes imitation depends on\ncontent. We are more likely to pass on a story if it is exciting\n(recall Boyer), we may be more likely to repeat a recipe if it is\ntasty, and we are more likely to reproduce a tool if it is\neffective. In other cases, imitation depends more on context than\ncontent. The term “context bias” refers to our\ntendency to acquire socially transmitted traits as a function of who \nis\ntransmitting them rather than what is getting transmitted (Henrich and\nMcErleath 2003). There are two basic kinds of context biases:\nthose based on frequency and those based on who is modeling the\ntrait. Let's consider these in turn. \n\nThe most important frequency-dependent bias is conformity.  Social\npsychologists have known for decades that people often copy the\nbehavior of the majority in a social group (e.g., Asch 1956).  Copying\nthe majority may help in creating cultural cohesion and communication,\nand it may also allow for group selection, a process in which a\ngroup's prospects for survival increases relative to other groups\nbased on its overall fitness. Group selection is hard to explain by\nappeal to biological evolution, because genetic mutations are\nlocalized to individuals, and are thus unlikely to result in whole\ngroups having different traits, but conformity allows for spread\nwithin a group, and thus overcomes this limitation of genes. This\nstory still depends on the possibility that an innovation that has not\nyet become widely practiced can get off the ground. If people only\ncopied the majority, that would never happen. One solution is to\nsuppose that conformity biases work in concert with an opposing trend:\nnonconformity. If we sometimes copy rare behaviors, then new\ninnovations can initially spread because of their novelty and then\nspread because of their high frequency. One example of these\ncomplementary processes is fashion. New fashions (such as street\nclothing coming from a small subculture, or the seasonal innovations\nof fashion designers) may initially appeal because of their novelty,\nand then spread through conformity. \n\nThe nonconformist bias is postulated to explain the observation that\npeople sometimes prefer to copy cultural forms simply because they are\nrare. Model-dependent biases (the second class of context biases\nmentioned above) also promotes the imitation of rare forms. In these\nbiases, people selectively copy specific members of a social group. We\ntend to copy those who are skilled, those who are successful, and\nthose who hold high prestige. The prestige bias is the most\nsurprising, because instrumental reasoning alone could lead us to copy\npeople who are skillful or successful. Prestige is not synonymous with\ndominance. We do not necessarily hold those who dominate us in high\nregard, and we do not seek to look at them, be near them, or be like\nthem. We do all of these things with high prestige individuals, and\nthis tendency goes beyond our bias to copy people who are skilled in\ndomains that we are trying to master.  Henrich and Gil White (2001)\nreview a large body of empirical evidence in support of this\nconclusion. For example, many people will shift attitudes towards\nexperts, even when the experts have no expertise on the topic under\nconsideration; people will copy the task-performance style of a\nprofessionally attired individual more often than they copy the style\nof a college student; and groups of high-status individuals exert more\ninfluence on dialect changes over time. Within the anthropological\nliterature, it has often been noted that high prestige individuals in\nsmall-scale societies are listened to more than others, even on topics\nthat have little to do with the domain in which their prestige was\nearned. Imitating prestigious individuals may confer advantages\nsimilar to imitating people who are skillful or successful,\nhowever. Doing so may increase the likelihood of acquiring\nprestige-enhancing traits. \n\nGiven the wide variety of biases, it may seem like a difficult task to\nfigure out whom to imitate on any given occasion. This is especially\ndaunting in cases where two biases conflict, as with conformity and\nprestige. To solve this problem, McElreath et al.  (2008) have\nproposed that imitation biases are hierarchically organized and\ncontext-sensitive. For example, conformity may be the default choice\nwhen payoffs in a group of models are similar, but prestige bias kicks\nin when the payoff differential increases. McElreath et al.  use\ncomputational models to show that such payoff sensitivity produces\nbehavioral patterns that fit with empirical evidence. \n\nCultural transmission of traits is often contrasted with biological\ntransmission. It is said to involve nurture rather than nature.\nAnthropologists emphasize the wide-ranging flexibility of human\nbehavior and regard cultural transmission as evidence for that.\nThis might suggest that cultural transmission operates in a way that is\nindependent of biology. But this idea has been challenged. \n\nOne challenge comes from evolutionary psychology. Evolutionary\npsychologists place greater emphasis on innate capacities.  Cultural\nvariation may appear to be inconsistent with nativism, but\nevolutionary psychologists believe that some variation can be\nexplained within a nativist framework. They admit that human groups\ndiffer in both their psychological states and customs, but deny that\nsuch variation requires a social explanation. The term “evoked\nculture” has been introduced to label the idea that differences\nin the physical environment may cause differences in how social groups\nthink and act (Tooby and Cosmides 1992). We may be evolved with inner\ntoggles that make us act in ways that are adaptive to different\nsettings. For example, cultures that struggle with resource scarcity\nmay be more belligerent than those that live in places of abundance,\nand it is possible that this personality difference hinges on an\ninnate switch that changes position in an environment-sensitive\nway. \n\nThe idea of evoked culture challenges the dichotomy between\nenvironmental and evolved causes of behavior, by proposing that some\nontogenetically acquired traits result from natural selection.\nBut critics of evolutionary psychology note that evoked culture cannot\nexplain the relatively open-ended nature of human innovation. Scarcity\nmay trigger a biological disposition for belligerence, but does not\ncause us to invent canons, peace treaties, or agriculture. Those\nspecific tools for coping with scarcity depend on insight and toil,\nrather than innate knowledge. \n\nThat dichotomy between biology and culture has been challenged in\nways that are less radical than the idea of evoked culture.\nIndeed, one challenge pushes in the opposite direction; rather than\nsaying cultural traits are innate, some say that innate traits depend\non culture. Some species change their environment in a way that\nalters evolutionary trajectories (Day et al. 2003). This\nphenomenon is called “niche construction.” Niche\nconstruction does not always involve culture: innate traits, such as\ndam building in beavers, can alter the environment in a way that\nintroduces selection pressures. But some niche construction is\ncultural. New inventions can lead to new environments that have\nbiological impact. For example, Simoons (1969) argues that adult\nhumans were all initially lactose intolerant, but acquired the ability\nto digest lactic acid as a consequence of technologies of dairy\nproduction. If so, culture can drive genetic change. \n\nA more controversial example is language. Some have argued that\nlanguage began as an invention, using domain general cognitive\nresources, but introduced a selective advantage for mutations that\nfacilitate rapid language learning and increasingly sophisticated\nconstructions – an example of what biologists call a\n“Baldwin effect,” named after the philosopher,\nJ.M. Baldwin (Deacon 1997). Language is socially transmitted and may\nhave been invented, securing its status as a cultural item, but, if\nnativists are night, it is now transmitted by specialized innate\nmachinery, which makes it bio-cultural. The idea that we can acquire\ntraits from biology and culture, and that these two interact, has been\ncalled dual-inheritance theory by Boyd and Richerson (1985). \n\nDual-inheritance theory suggests that cultural evolution need not be\nan alternative to biological evolution, but rather, can interact with\nit. In some cases, cultural changes may actually exert a biological\nforce. On the other hand, cultural evolution may tend to reduce the\nimpact of biology. Consider niche construction again. If human beings\ncan alter their environments through technology, they can mitigate the\neffects of external variables that might otherwise drive natural\nselection (Laland et al. 2001).  Thus, the capacity for cultural\nlearning may render biological transformations unnecessary. Cultural\nchange is faster, more flexible, and driven by forethought. The extent\nto which biology contributes to human variation across cultures is,\ntherefore, a matter of controversy. Evolutionary psychologists\nemphasize the biological contributions to variation, dual-inheritance\ntheorists emphasize bio-cultural interactions, and their critics\nsuggest that the human capacity for cultural transmission reduces the\nimport of biology. The latter perspective gains some support from the\nfact that many dramatic cultural differences have no known biological\ncauses or effects. \n\nPhilosophers have long speculated about cultural variation, raising\nquestions about whether people in different cultures differ\npsychologically. Clearly people in different cultures know\ndifferent things, believe different things, and have different\ntastes. But one might also wonder whether culture can influence\nthe way we think and experience the world. And one might wonder\nwhether differences in taste are a superficial veneer over underlying\nnormative universals, or whether, instead, culture plays a role in\nshaping normative facts. Cognitive science offers empirical\ninsights into cultural differences that have been taken to bear on\nthese enduring questions. What follows is a survey of some areas\nin which empirical investigation has been very active. \n\n20th century linguistics was born out of anthropology,\nand anthropological studies of language built on the efforts of\nEuropean missionaries to understand the languages of human societies\nthat had been isolated from European contact. Within this\ncontext, the study of language principally involved radical\ntranslation—attempting to translate the vocabulary of another\nlanguage when there is no bilingual interpreter to tell you what words\nmean. Anthropologists observing this practice, such as Franz Boas,\nwere struck by how different the world's languages can be, and\nthey began to wonder whether these differences pointed toward\ndifferences in how cultural groups understand the world. \n\nPhilosophers entered into such speculation too. Quine (1960) famously\nused the activity of radical translation as a springboard to present\nhis theses about limits on a theory of meaning. When trying to\nconstruct a translation manual for a foreign language based on verbal\nbehavior, there is a problem of underdetermination. If the language\nusers say “gavagai” when and only when a rabbit is\npresent, they may be referring to rabbits, but they may also be\nreferring to rabbit time slices or undetached rabbit parts.  Absent\nany resolution of this underdetermination, there would always be a\ndegree of indeterminacy in our theories of what other language users\nmean. Quine's behaviorism led him to think that these indeterminacies\nare not merely epistemic; linguistic behavior is not just evidence for\nwhat people mean, but the source of meaning, so there is no further\nfact that can settle what people mean by their words. This led Quine\nto be skeptical about the role of reference in his semantic theory,\nbut he didn't become a meaning nihilist. Without determinate\nreference, the meaning of words can be understood in terms of\ninferential roles. But Quine (1953) had earlier argued that there is\nno principled distinction between those inferences that are\nconstitutive of meaning, and those that merely reflect beliefs about\nthe world (the analytic/synthetic distinction). Thus, the meaning of a\nword depends, for Quine, on the total role of that word in its\nlanguage; Quine is a meaning holist. In the context of radical\ntranslation, this raises a striking philosophical possibility. When we\nencounter a word in another language, we cannot determine what it\nrefers to, so we must specify its meaning in terms of its total\ninferential role; but inferential roles vary widely across cultural\ngroups, because beliefs diverge; thus, the meaning of a word in a\nlanguage spoken by one cultural group is unlikely to have an exact\nanalogue in other languages. Meanings vary across cultures. In this\nsense, radical translation is actually impossible. One cannot\ntranslate a sentence in another language, because one cannot find\nsynonymous sentence in one's own. At best, one can write paragraph-,\nchapter-, or book-length gloss on inferential links that help convey\nwhat foreign speakers mean by their words. \n\nThis conjecture leads quickly to another that relates even more\ndirectly to psychology. Many philosophers have assumed a close\nrelationship between language and concepts. Words are sometimes\nsaid to constitute concepts and, more often, to express them.\nCorresponding to the linguistic inferential roles that constitute\nmeanings for Quine, one might posit isomorphic conceptual roles, and,\nif meanings are not shared, then it might follow that concepts are not\neither: people in different groups might conceptualize the world\ndifferently. The idea that languages may not be intertranslatable\nsuggests that there may also be incommensurable conceptual\nschemes. \n\nThis idea is challenged by Davidson (1974), who offers a kind of\ndilemma. Suppose we encounter a group whose beliefs and\nlinguistic behaviors differ from ours but can nevertheless be\naccurately characterized with patience and time. If we can\nunderstand these other people, then their concepts must be shared with\nours. Suppose, however, that we cannot ever understand what they\nmean by their words because they say things that can be offered no\ncoherent translation. Then it's best to assume they are not\nreally saying anything at all; their words are meaningless\nnoises. Either way, there is no proliferation of conceptual\nschemes. Davidson's argument, which is only roughly\npresented here, controversially presupposes a principle of charity,\naccording to which we should not attribute irrational (e.g.,\ninconsistent) beliefs. Davidson may also be overly demanding in\nrequiring accurate translation between languages as opposed to some\nweaker criterion of comprehension (see Bar-On 1994; Henderson \n1994). \n\nWell before Quine and Davidson were debating the incommensurability of\nmeanings, linguists had been exploring similar ideas. Edward\nSapir (1929), a student of Boaz, had proposed two interrelated theses:\nlinguistic determinism according to which language influences the way\npeople think, and linguistic variation, according to which languages\nhave profound differences in syntax and semantics (these terms are not\nSapir's, but exist in the literature). Together, these two\ntheses entail linguistic relativity: the thesis that speakers of\ndifferent languages differ in how they perceive and think in virtue of\nspeaking different languages. Sapir's student, Benjamin\nWhorf (1956), speculated that languages encode fundamentally different\n“logics,” which become so habitual to language users that\nthey seem natural, resulting in fundamentally different ways of\nunderstanding the world. For example, Whorf speculates that\nspeakers of Hopi are anti-realists about time, since tense in that\nlanguage is expressed using epistemic modals, which describe events as\nrecalled, reported, or anticipated, in lieu of past, present, or\nfuture. Sapir and Whorf's relativism about language has come to\nbe known as the Sapir-Whorf hypothesis. These two have been\ncriticized for offering insufficient support. They had limited\nknowledge of the languages they discuss, and throughout their\ndiscussions, they infer cognitive differences directly from linguistic\ndifferences rather than testing whether language causes (or even\ncorrelates) with difference in thought. \n\nThe Sapir-Whorf hypothesis went out of fashion with the advent of\nChomskyan linguistics. Chomsky argued that linguistic differences\nare superficial and scientifically uninteresting. Languages are\nunited by a universal grammar, and differences simply reflect \ndifferent\nsettings in universally shared rules. A further setback for the\nSapir-Whorf hypothesis came with early testing. Heider (1972) set\nout to see whether color vocabulary influenced color perception.\nShe investigated the Dani of New Guinea, who have only two color terms\n(“mili”, for dark cool colors, and “mola,”\nfor light and warm colors). Heider found that the Dani divide\ncolor space in much the same way as English speakers, and performed\nlike English speakers on color memory tests. There was also a\nfailed effort to show that Chinese speakers, who lack a counterfactual\nconstruction, have difficulty with subjunctive thought (Bloom 1981;\nAu 1983). Evidence for psychological differences across speakers\nof distinct languages were hard to come by. \n\nMore recently, however, some researchers have claimed to find such\ndifferences. Lucy (1992), for example, found that speakers of Yucatec\nMayan, a language that lacks count nouns, made errors on memory tasks\nthat required keeping track of specific quantities of items. English\nspeakers are more likely to notice when two pictures differ in the\nnumber of chickens as compare to the amount of grain, because\n“chicken” is encoded with a count noun, and\n“grain” is encoded with a mass noun. \n\nPederson et al. (1998) investigated speakers of Tzeltal, a language\nthat expressed absolute frames of reference (like “north”\nand “south”) but lacks terms for relative frames of\nreference (such as “left” and “right”).\nWhen performing spatial tasks, such as replicating a sequence of\nobjects in two different locations, they preserved the arrangement\nrelative to absolute coordinates even in conditions where English\nspeakers would use relative coordinates. \n\nGordon (2004) studied numerical cognition among the Pirahã, a\nlanguage with a number vocabulary limited to words that mean, roughly,\n“one,” “two,” and “many.” He\nfound that Pirahã made frequent numerical errors when copying\ndrawings of groups of lines, dropping nuts into a can, and reproducing a\nseries of beats. \n\nEven color perception, which was once regarded as immune to\nSapir-Whorf effects may be influenced by language. Kay and Kempton\n(1994) found that speaker Tarahumara, a language that does not\ndistinguish green and blue, were more accurate than English speakers\nat rating the similarity of color pairs within the blue-green range\n(see also Roberson et al.  2000). Winawer et al. (2007) found that\nspeakers of Russian, which has separate lexemes for light blue and\ndarker blues, show categorical perception effects for light blue, not\nfound in English speakers. In categorical perception, differences\nbetween stimuli that cross a categorical boundary are perceived as\ngreater than equal differences within a category. For Russian\nspeakers, a light and medium blue may look more different than a light\nand dark blue, even if two pairs are equidistant in colorspace. \n\nBoroditsky et al. (2003) also found that gendered articles have an\ninfluence on conceptualization. Speakers of Spanish and German\nassociate stereotypically gendered adjectives with common nouns as a\nfunction of the gender of those nouns in their languages, even when\nthey are tested in English. For example, the German word for key is\nSchlüssel, which is masculine, and the Spanish word,\nllave, is feminine. German speakers may describe keys as\nhard, heavy, and useful, while Spanish speakers describe them as\nlovely, little, and intricate. \n\nThese kinds of findings are now plentiful, but the Sapir-Whorf\nHypothesis has not gone unchallenged (for a review, see Bloom and Keil\n2001).  For example, Li and Gleitman (2002) showed that Tzetal\nspeakers can reproduce object arrays using relative reference frames\nin a simplified version of the experiments performed by Pederson et\nal.  (1998) (see Levinson et al. 2002 for a reply). Frank et al.\n(2008) found that Pirahã could match large quantities with\naccuracy, but failed to do so when they relied on memory. Such\nexperimental critiques suggest that Sapir-Whorf effects are fragile,\nand may be hard to show under certain conditions, but they also\nconfirm that language plays a role in encoding information, and\ncognitive differences arise when memory is involved. Studies on color\nperception and color comparison suggest that the effects are not\nlimited to memory, and Boroditsky's study of gendered pronouns suggest\nthat language can have an enduring impact on how we think about\nfamiliar categories. \n\nIn summary, it might be said that cognitive science has found evidence\nin support of the hypothesis that language can influence thought.\nBecause language is a cultural item, linguistic effects on thought can\nbe characterized as cultural effects. But the interest of such\neffects is open to debate. Neo-Whorfians will say that language\ncan establish modes of thinking that distinguish one group from\nanother, while critics say these differences are modest and don't\nimply the radically incommensurable worldviews advertised by Whorf. \n\nResearch on the Sapir-Whorf hypothesis looks for ways in which\nlanguage influences perception and thought. But language is not\nthe only way that a culture can influence cognition. Other\nresearch looks for cultural differences in language and perception that\nare not necessarily mediated by language. For example, there is\nresearch suggesting that cognition can be affected by methods of\nsubsistence or social values. \n\nIn the decades after World War II, psychologists began to do\nresearch on “cognitive styles.” Witkin (1950) introduced a\ndistinction between field-dependent psychological processing and\nfield-independent psychological processing. Field-dependent\nthinkers tend to notice context and the relationship between things,\nwhereas field-independent thinkers tend to abstract away from context\nand experience objects in a way that is less affected by their\nrelationships to other things. For example, field-independent\nthinkers do better on what Witkin called the embedded figure task, in\nwhich one shape (left) must be found embedded in another (right). \n\nWitkin's test was designed to study individual differences\nwithin his own culture, but Berry (1966) realized that it could also be\nused to investigate cultural variation. He was interested in how\ndifferent forms of subsistence might influence cognition. One\nhypothesis is that hunters and gatherers must be good at\ndifferentiating objects (plants or prey) from complex scenery.\nHorticulturalists, on the other hand, must pay close attention to the\nrelationship between the many environmental factors that can influence\ngrowth of a crop. To test this, Berry studied Inuit hunters and\nTemne horticulturalists in Africa, and found that the latter are more\nfield-dependent than the former. (See also Segall et al. 1966,\nwho found that hunter-gatherers are less susceptible to the\nMueller-Lyer illusion, because—the authors argue—they\ndon't live in a “carpentered world, full of right-angled\nbuildings.”) \n\nBerry was interested in isolated, small-scale societies, but the\nsame research methods and principles have also been applied to much\nlarger cultural groups. Cultures of every size differ on a number\nof dimensions. One distinction that has been extremely valuable\nin cross-cultural research is the contrast between individualist\ncultures and collectivist cultures (see Triandis, 1995). Individualists\nplace emphasis on individual achievements and goals; they value\nautonomy and disvalue dependency on others. Collectivists place\nemphasis on group membership and often value group cohesion and success\nabove personal achievement. Following Triandis, we can define\nmore precisely as follows: \n\nCollectivism: a social pattern in which individuals construe\nthemselves as parts of collectives and are primarily motivated by\nduties to those collectives \n\nIndividualism: a social pattern in which individuals see themselves\nas independent of collectives and are primarily motivated by their own\npreferences and needs \n\nThe difference can be brought out experimentally by giving people in\ndifferent cultures tasks that assess how much they value autonomy and\nhow much they value inter-dependence. For example, when asked to\npick a colored pen from an array of pens, individualists tend to pick\nthe most unusual color, and collectivists tend to pick the most\ncommon. \n\nIndividualist and collectivist cultures are distributed widely\nacross the globe. Countries in Western Europe, North America, and\nAnglophone Australasia score high in individualism. Collectivism\nis more common in East Asia, South Asia, the Middle East, the\nMediterranean, and South America. It should be obvious that these\nare vast and remote regions of the globe and highly diverse, culturally\nspeaking. Any large nation, such as India or America, will have\nscores of subcultures each of which might vary along these\ndimensions. The point is not that all collectivist cultures are\nalike. Differences between collectivist cultures and within\ncollectivist cultures are often greater than between collectivist and\nindividualist cultures. The point is simply that collectivist\ncultures share this one dimension of similarity, and that dimension, as\nwe will see, has an impact on cognitive style. Likewise for\nindividualists. Future research will offer more finely grained\ndistinctions, but at present, research on the cognitive effects of\nindividualism and collectivism offers some of the strongest evidence\nfor cultural differences in thought. \n\nSome researchers trace individualism and collectivism to material\nconditions. For example, many Western cultures are individualistic\nand trace their seminal cultural influence to ancient Greece, which had\nan economy based on fishing and herding. Far Eastern countries trace\ntheir seminal cultural influence to China, which had intensive\nagriculture. In the West, free mercantilism and capitalism\nemerged long ago, emphasizing individual achievement. In the\nEast, capitalism and free trade is comparatively new. So the\nEast/West contrast in collectivism and individualism may have its\norigins in how people made their livelihood in past centuries.\nOnce these differences are in place, they tend to be reflected in many\nother aspects of culture. Far Eastern languages use characters\nthat require a fine sensitivity to relationships between parts; Eastern\nreligion often focuses on relationships between human beings and\nnature; Eastern ethical systems often emphasize responsibilities to the\nfamily (Nisbett, 2003). These cultural differences can be used to\ntransmit and preserve psychological differences from generation to\ngeneration. \n\nNisbett et al. (2001) present a large body of research, which suggests\nthat members of individualist and collectivist cultures tend to have\nmeasurably different cognitive styles. Nisbett and his collaborators\n(mostly East Asian psychologists) talk about field-dependence and\nfield-independence, but also introduce the closely related terms:\nholistic and analytic cognitive styles. They postulate that, as\ncollectivists, East Asians will process information more holistically,\nseeing the relation between things, and individualists will process\ninformation more analytically, focusing on individual agents and\nobjects. They show that these differences come out in a wide variety\nof psychological tasks. Here are some examples reviewed by\nNisbett. \n\nWesterners are more likely than Easterners to attribute a person's\nbehavior to an internal trait rather than an environmental\ncircumstance. In many cases, such attributions are mistaken\n(social psychologists call this the Fundamental Attribution Error). \n\nEasterners are more likely to see both sides of a conflict when\nfaced with counter-arguments in a debate; Westerners dig in their\nheels. The Eastern responses are more dialectical, whereas\nWesterners are guided by the principle of Non-Contradiction. This\nis a principle central to modern logic in the West, which asserts that\na claim and its negation can't both be right. \n\nWesterners tend to categorize objects based on shared features (cows\ngo with chickens because they are both animals), whereas Easterners\nfocus more on relationships between objects (cows go with grass,\nbecause cows eat grass). \n\nWhen looking at a fish tank, Westerners first notice the biggest,\nfastest fish and ignore the background. Easterners are more\nlikely to notice background features and relational events (a fish\nswimming past some seaweed), and they are less likely to recall\nindividual fish on a memory test. In studies of expectations, Westerners\ntend to expect things to remain the same, whereas Easterners are more\nlikely to expect change. \nIn assessing the import of these differences, it is important to\nrealize that they are often subtle. In some cases, it is possible\nto get a Westerner to respond like an Easterner and conversely, if\nsubjects are properly instructed or primed (Oyseman & Lee,\n2008). But the results show that there are predictable and\nreplicable differences in default cognitive styles as a function of\nculture. \n\nSeveral philosophical ramifications deserve note. First,\nvariation in cognitive styles can be used to challenge the idea that\nthe rules used in thought are fixed by a hard-wired mental logic.\nThis idea was promulgated by Boole (1854) in his work on formal logic,\nand it helped pave the way for the advent of computing and, ultimately,\nfor the computational theory of mind. If there is no fixed mental\nlogic, then the study of reasoning may owe more to nurture than has\noften been assumed, and the traditional computational theory of mind\nmight even need a re-examination. Cultural differences do not\nrefute computational approaches, but they raise a question: if some\ncultures tend to rely on formal principles and others rely on\nstochastic approaches to reasoning, then we should not by default\nassume that the mind naturally functions like a classical computer as\nopposed to, say, a connectionist computer. \n\nSecond, variation in reasoning can also be used to raise questions\nabout whether certain cognitive norms (such as a preference for the\nprinciple of non-contradiction) are culturally inculcated and\ncontestable. This issue is related to contemporary debates about\nwhether classical logic is privileged. It was also the subject of\na provocative paper by Winch (1964), who, following ethnographic work\nby Evans-Pritchard on the logic of witchcraft among the Azanda, argued\nthat the Western allegiance to bivalence is culturally contingent,\nrather than normatively compulsory. \n\nThird, variation in perception raises questions about modularity; if\nvalues can influence how we see, then seeing may be more amendable to\ntop-down influences than defenders of modularity have supposed.\nCiting work on the Mueller-Lyer illusion, Fodor (1983) argues that\nmodularity is consistent with the possibility that cultural settings\ncan, over protracted time periods, alter how information is\nprocessed. But this concession may be inadequate: perceptual\nprocessing styles can be altered very quickly by priming cultural\nvalues such as individualism and collectivism. Moreover, unlike\nthe Mueller-Lyer illusion, which may involve bottom-up perceptual\nlearning, research on individualism and collectivism suggests that\nvalues can influence how we see. That's close in\nspirit to the idea that perception is theory-laden, which was the\ncentral thesis of New Look psychology—the theory that the\nmodularity hypothesis is supposed to challenge (Bruner, 1957; Hanson,\n1958). \n\nEmotions are a fundamental feature of human psychology. They\nare found in all cultures, and arguably, in all mammals. Indeed,\nwe seem to share many emotions with other animals. Dogs, for\nexample, show signs of fear (they cower), sadness (they cry), and\ndelight (they wag their tails giddily). This suggests that\nemotions are evolved responses. There is a good explanation for\nwhy emotions would be selected for: they help us cope with challenges\nthat have a tremendous impact on life and well-being. Fear protects\nus from dangers, sadness motivates us to withdraw when resources or \nkin\nare lost, and joy registers accomplishments and motivates us to take \non\nnew challenges. Thus, it seems highly likely that emotions are\npart of human nature. But emotions can also be influenced by\nnurture. Some researchers even suggest that emotions can be\nsocially constructed—they say some emotions come into existence\nthrough social learning. The thesis is controversial, of course,\nbut the claim that culture has an impact on emotional states is hard to\ndeny (for a review, see Mesquita and Frijda, 1992). \n\nTo see how culture might impact emotions, consider various things that\nnormally occur when people have emotional responses. There is\nsome elicitor of the emotion; there is characteristically some\nappraisal of that elicitor; this occurs along with\nfeelings; and these are associated with motivational\nstates as the body prepares to react; the emotion is also\nexpressed; and can lead to a decision about what\nactions to carry out, including complex strategic actions\nextended over time. Each of these things can come under cultural\ninfluence. \n\nBegin with elicitors. Culture can clearly influence what arouses\nour emotions. In Bali, crawling babies are said to arouse disgust\n(Geertz, 1973: 420), and in Japan, disgust can be caused by failing an\nexam (Haidt et al., 1997). In Sumatra, an encounter with a high\nstatus individual can cause shame (Fessler, 2004). In Iran, a\nwoman without a headscarf might cause anger, and in France, a woman\nwith a headscarf might cause the same reaction. \n\nFeelings can differ cross-culturally, as well. For example, it\nhas been reported that, while anger is typically associated\nwith high arousal in the West, in Malay, anger (or marah) is\nmore strongly associated with sullen brooding (Goddard, 1996).\nThere are corresponding differences in motivational states. Anger\nmight instill a disposition to aggress in the West, whereas sulking\nbehavior may be more typical in Malaysia. In Malay, aggression is\nassociated with amok, which refers (as the imported homophone\ndoes in English) to a frenzied state. Thus, there seems to be no\nexact synonym for anger: a state that is prototypically aggressive but\nnot frenzied. \n\nCulture can also impact expressions of emotions. This is\nsometimes done through active suppression. Ekman and Friesen\n(1971) present evidence that public expression of negative emotions is\ndiscouraged in Japan. New expressions may also be cultivated\nculturally. There is evidence that tongue biting is used by women\nto express shame in parts of India (Menon and Shweder, 1994).\nThere are also cultural difference in gestures used to express anger,\nsuch as the middle finger in North America or the double finger salute\nin Britain. What North Americans interpreted as an\n“okay” sign would be interpreted as a sexual insult in\nRussia or Brazil. As these gestures become habitual, they may\nbecome incorporated into automatic ways of expressing emotions in some\ncontexts. \n\nIn addition to emotional expressions, cultures can promote highly\ncomplex behavioral responses. Love is sometimes taken to be\ngrounds for marriage, but less so in cultures where marriage is\narranged. Grief in Biblical contexts might have been expressed by\ntearing ones clothes or covering oneself with dirt.\nShame can require culturally specific behaviors of self-abasement, such\nas bowing low. Hope may promote the use of lucky charms or\nprayers, depending on one's cultural beliefs. \n\nThese examples suggest that culture can impact emotional response in a\nwide variety of ways. As a consequence, emotions that are widely\nrecognized in one culture may go unnoticed or uninstantiated in\nanother. One example is amae, a Japanese emotion\nconstruct, which is characterized as a positive feeling of dependency\non another person, group, or institution (Doi, 1973). Another\nexample is the Samoan emotion of musu, which expresses a\nperson's reluctance to do what is required of him or her. In more\nisolated societies, it has even been argued that none of the named\nemotions correspond exactly to emotions that we would recognize\nhere. This may be the case among the Ifaluk, a small group in\nMicronesia (Lutz, 1988). \n\nIn arguing for cultural variation in emotions, researchers often cite\ndifferences in emotional vocabulary. Such differences would not\nbe especially powerful evidence were it not for independent evidence\n(just discussed) that culture can exert a causal impact.\nVocabulary differences may also be evidential in another way. The\nvery fact that a label exists in a language may have a causal impact on\nthe frequency or manifestation of a psychological state. This is\nwhat Hacking (1999) calls a “looping effect.” This\ncan sometimes be seen in the case of pathological emotions. For\nexample, incidence and symptoms of depression may increase as a\nconsequence of public discourse about depression (Ryder et al., 2008;\nsee also Murphy, 2006). Depression as we know it may be\nculturally specific in the way it presents, even if there are related\ndisorders in other cultures, such as melancholia and\nacidia in medieval Europe (Jackson, 1981). Some\nemotional disorders may be common in one society and virtually unheard\nof elsewhere. One example is latah, a disorder found\namong women in parts of South East Asia, in which victims enter a\ntrance-like state, shout obscenities, repeat what others say to them,\nand exhibit an extremely strong and sensitive startle response (Simons,\n1996). \n\nIn light of such cultural variation, some argue that emotions are\nsocially constructed (Averill, 1980; Harré, 1986; Armon-Jones,\n 1989; also see the entry\n naturalistic approaches to social construction.)\n Others resist this idea, arguing that emotions are innate biological\nprograms, shared across the species despite differences in emotion\nvocabulary. The latter position has been associated with evolutionary\napproaches to emotion (Plutchik, 2001), and research on universal\nrecognition of emotional facial expressions (Ekman et al. 1969). \n\nEkman and his collaborators studied an isolated culture, the Fore,\nin Papua New Guinea. These people had little contact with the\nWest, and Ekman wondered whether they assign the same significance to\nemotional expressions as we do. He identified six emotions that\nare very reliably identified in Western nations (joy, sadness, anger,\nfear, surprise, and disgust), and found corresponding words in\nFore. He asked his respondents to look at photos of expressions\nand identify which faces go with which words. He also described\nvarious scenarios (such as seeing an old friend or smelling something\nbad) and asked them to choose the face that best expressed how someone\nin those situations would feel. Using these methods, he was able\nto show that the Fore give responses that are very similar to the\nresponses we give in the West. Ekman concluded that emotional\nexpressions are not cultural inventions, but rather, are biologically\ndetermined. \n\nA close look at Ekman's data suggests that he may exaggerate the\ndegree of universality. The Fore do indeed respond similarly to their\nWestern counterparts, but not identically. For example,they are more\nlikely to label as fear the faces that we identify as surprise, and\nthey also associate sadness with the faces we label angry. So the\ndominant response among the Fore differs from ours in two of six\ncases. And even where they agree with our labeling, the level of\nagreement is often surprisingly low, with less than 50% giving the\nexpected response. Moreover, the Fore who had more exposure to\noutsiders also gave answers that were more like outsiders', suggesting\nsome cultural influence (see Russell, 1994, for more discussion). \n\nIt doesn't follow that emotions are mere social\nconstructions. Rather, it seems that we have biologically basic\nemotions that can be altered by culture. Whether these\nalternations qualify as different emotions or simply different\nmanifestations of the same emotion depends on what one takes emotions\nto be. The nature of emotions is a matter of considerable debate\n(Prinz, 2004). For those who take emotions to essentially involve\njudgments, constructivist theories of emotion are attractive, because\nculture can influence how people construe situations (Solomon,\n2002). Constructivism is also appealing to those who think of\nemotions as analogous to scripts, which include everything from\ncanonical eliciting to conditions to complex behavioral sequalae\n(Russell, 1991; Goddard, 1996; Goldie, 2000). Those who see\nemotions as automatic behavioral programs or patterned bodily changes\nhave been less inclined towards constructivism (James, 1884; Darwin,\n1872; Ekman, 1999; though see Prinz, 2002). Griffiths (1997) has\nargued that emotions are not a natural kind: some are culturally\nconstructed scripts, others are automatic behavioral programs, and\nothers are evolved strategic responses that unfold over longer\ntimescales. \n\nIt might seem that we can't settle on the question of whether\nculture shapes emotions without deciding between these theories of what\nemotions are. On the other hand, the evidence suggests that\nculture can influence every aspect of our emotional responses, and this\nsuggests that, whatever emotions really are, culture can have an\nimpact. It is open to debate whether the impact is sufficiently\nsignificant to warrant the conclusion that some emotions are social\nconstructs. \n\nFew deny that biology makes some contribution to morality.\nThere is a vast literature on prosocial behavior in primates, moral\nbehavior in early childhood, and universal dispositions to empathy and\naltruism (e.g., Warneken and Tomasello, 2009). But no account of\nmoral psychology can stop with biology. Morality is also\ninfluenced by culture. This raises traditional philosophical\nquestion about moral relativism. \n\nEvidence for cultural variation in values is easy to come by (see\nPrinz, 2007). Consider, for example, attitudes towards various\nforms of violence. Cannibalism, slavery, honor killing,\nheadhunting, public executions, and torture have\nbeen widely practiced by a range of societies, but are reviled in the\ncontemporary West. There is also considerable diversity in the\nsexual domain: polygamy, cousin marriage, masturbation, bestiality,\npre-marital sex, prostitution, concubinage, homosexuality, and other\npractices are accepted in some places and morally condemned\nelsewhere. The anthropological record suggests that just about\nevery behavior that we consider immoral has been an accepted cultural\npractice somewhere. Of course, a society wouldn't survive\nvery long if it encouraged random killing of next-door neighbors, but\nsocieties that encourage murder of people in the next village can\nendure indefinitely (see Chagnon, 1988, on the Yanamamo). \n\nOne can find further support of moral diversity by conducting\npsychological experiments on members of different cultures and\nsubcultures. Nisbett and Cohen (1996) compared Americans from Southern\nStates with Americans from the North, and found that Southerners were\nmuch more likely to endorse violence of various forms in response to\nmoral transgression (killing to defend property, corporal punishment,\ngun possession, and so on). They explain this by noticing that\nmany Southerners are descendents of Scots-Irish immigrants who had to\ndevelop a “culture of honor” to survive under harsh,\ncomparatively lawless conditions in Northern Ireland before coming to\nthe United States. \n\nCultural differences in morality have also been tested using\neconomic games (Henrich et al., 2005). One example is the\nultimatum game, in which one person is told that they must divide a sum\nof money (say $100) with a stranger. If the stranger rejects the\ndivision, no one gets any of the money. In the U.S., most people\noffer relatively equal splits. If they offer too little, the\nother person typically rejects the split out of spite, and both players\ngo home empty handed. This is a measure of moral attitude towards\nfairness, and there are subtle differences across cultures. The\nMachiguenga of Peru, who have an economic system that does not depend\nmuch on cooperation, make lower offers on average than Americans, and\nthey accept lower offers. Among the Au of New Guinea, people\nsometimes reject “hyper-fair” offers—that is offers\nover 50%. In the U.S., a hyper-fair offer would be happily\naccepted, but the Au routinely reject such generosity; a similar\npattern has been found in Russian and other former Soviet states\n(Herrmann et al., 2008). Hyper-fair offers may be regarded as\nostentatious or as trying to achieve some kind of dominance by making\nthe recipient feel indebted. \n\nSome philosophers have resisted the claim that there is cultural\nvariation in morality. Rachels (2003: chap. 2), for example,\nargues that some differences are merely apparent. Inuits tolerate\ninfanticide, but so would we if we lived in the Arctic tundra where\nresources are rare. Against this kind of reply, one might argue\nthat, in fact, values don't tend to change right away when we\nchange environments (the U.S. Southern culture of honor may be a\nhold-over from hard times in Northern Ireland prior to U.S.\nimmigration; Nisbett and Cohen, 1996). Moreover, the fact that\nour attitudes toward infanticide might shift in the tundra might be\ntaken as evidence for relativism rather than evidence against it;\nmorality is highly sensitive to environmental variables. \n\nOther critics have argued that we cannot adequately assess whether\ncultures differ in values. Moody-Adams (1997) argues that, absent\na complete understanding of another culture's beliefs, we might\nmistake differences in factual beliefs for moral differences. For\nexample, did the Aztecs really think cannibalism was okay, or were\nthey driven to this practice because of a cosmology that made them\nthink this was the only way to appease the Gods? We may never\nknow. On the other hand, anyone who is willing to concede that\nculture can alter people's non-moral beliefs might also concede\nthat values can be altered. \n\nThe most enduring philosophical debate about moral variation concerns\nmetaethical relativism. Does moral diversity imply that there is\nno single true morality? On its own, the answer is no. But\nsome relativists argue that that there is no source of morality other\nthan our attitudes (e.g., they argue for subjectivism), so cultural\nvariation implies that morality is relative (Prinz, 2007). Others\nargue that appeals to cultural history adequately explain why we have\nmoral values, so there is no pressure to posit a further domain of\nvalues that transcend culture (Harman, 1977). These views do not\nentail that any morality is possible. There may be a plurality of\nacceptable value systems, given human nature and the situations we find\nourselves in (Wong, 2006). Opponents of relativism think such\npluralism is still too generous. Demands of reason (Kant),\nintrinsic goods (consequentialism), natural conditions for flourishing\n(Aristotle), ideal observers (Smith), and divine commands have all been\nexplored as sources of absolute values. \n\nCultural variation bears on traditional philosophical questions,\nsuch as questions about moral relativism, the modularity of \nperception,\nand incommensurability of meaning. Cultural variation also bears\non the practice of philosophy itself. Some have argued that\nphilosophical theories are culturally informed, and that, therefore,\nphilosophers who take themselves to be seeking universal truths must\neither revise their aspirations or alter their methodology. \n\n One place where this issue has been confronted is\n comparative philosophy.\n For example, scholars of philosophical traditions in East Asia\nsometimes wonder to what extent these are related to traditions in the\nWest. A skeptical view would say that the starting assumptions,\nguiding questions, and dominant methods are so different that\ncomparison is of limited value. On the other extreme, one might\nthink that one can simply treat Eastern and Western philosophers as if\nthey were part of a single domain, and compare them easily just as one\nmight compare two figures coming out of the same cultural\nheritage. \n\nThe idea that philosophical ideas are culturally informed has also been\ninvestigated empirically. Experimental philosophers have\nconverted standard philosophical thought experiments into survey studies\nin an effort to see whether untutored intuitions align with those that\nhave been endorsed by professional philosophers. Some\nexperimental philosophers have used the survey method to do\ncross-cultural comparisons, most often comparing philosophical\nintuitions in the United States to those in China and other East Asian\nCountries. The results suggest that there is cultural\nvariation. \n\nIn one pioneering study, Weinberg et al. (2001) looked at epistemic\nintuitions. Within recent Western epistemology, the most\ninfluential thought experiments owe to Edmund Gettier (1963), who\ndevised them in an effort to argue against the prevailing view that\nknowledge is justified true belief. These cases are supposed to\nshow that a belief can be justified and true, without being an\nintuitive case of knowledge. For example, it is a majority view\nwithin Western philosophy that the following Gettier-inspired case does\nnot qualify as knowledge: \n\nBob has a friend, Jill, who has driven a Buick for many years.\nBob therefore thinks that Jill drives an American car. He is not\naware, however, that her Buick has recently been stolen, and he is also\nnot aware that Jill has replaced it with a Pontiac, which is a\ndifferent kind of American car. Does Bob really know that Jill\ndrives an American car, or does he only believe it? \n\nWeinberg et al. gave this vignette to college students of European,\nEast Asian, and South Asian descent. Most European\nAmericans shared the intuition that Bob does not know that Jill drives\nan American car, but the majority of East and South Asians had the\nopposite intuition. \n\nAnother cross-cultural study of philosophical intuitions is reported by\nMachery et al. (2004). They turned from epistemology to\nsemantics, and found that one of the most influential thought\nexperiments in the philosophy of language elicits different intuitions\nacross cultural groups. The thought experiment owes to Kripke\n(1979), who was arguing against descriptive theories of\nreference. According to descriptive theories, a proper name\nrefers to the individual who satisfies the descriptions most associated\nwith that name. For example, descriptivists would say\n“Gödel” refers to the person who proved the\nincompleteness of arithmetic. Kripke objects by constructing an\nimaginary case in which someone else came up with the proof and the\nperson we know as Gödel merely took credit for it.\nKripke's intution is that, even if this were so,\n“Gödel” would continue to refer to the same person,\nnot to this other guy who discovered the proof. That intuition\ncounts against descpritvism and in favor of a causal-historical theory\nof reference. Machery et al. show that American college students\nwith a Western cultural background were much more likely to share\nKripke's intuitions than students in Hong Kong in cases of this\nkind (for objections, see Marti, 2009; and replies in, Machery et al.\n2009). \n\nIn another study, Huebner et al. (2010) use cross-cultural methods to\ntest an intuition that has been important in consciousness\nstudies. Block (1979) argued against functionalism using thought\nexperiments in which the functional organization of a human mind is\nrealized by a population of people rather than a biological\nbrain. Block's intuition is that this collective would not\nbe conscious, and therefore functional organization in not sufficient\nfor consciousness. Huebner et al. show that students in Hong Kong\nare significantly more likely than American students to be willing to\nascribe consciousness to collectives. They conclude that the\nintuitions underlying Block's argument are not cross-culturally\nshared. \n\nThe authors of these studies emphasize two points. First, the\nstandard method of drawing philosophical conclusions by consulting\nintuitions may be problematic because those intuitions are not\nconsistently held across cultures. If philosophers seek to\ndiscover the nature of knowledge, reference, or consciousness, by\nanalyzing the corresponding concepts, they must reckon with the fact\nthat these concepts vary, and no single analysis is likely to\nemerge. Second, some of the variance may be accounted for by\ncultural variables. This suggests that concepts are culturally\ninfluenced, and that philosophical theories based on concepts may\nreflect the attitudes of a cultural group, rather than universally\nshared understanding of the target domain. From this perspective,\nphilosophy based on intuitive judgments begins to look more like\nauto-anthropology than a window into absolute truths. \n\nOpponents of experimental philosophy argue that surveys of college\nstudents reveal less about concepts than the intuitions of\nprofessional philosophers. These critics suggest that intuitions among\nprofessional philosophers engaged in careful discussion and\nargumentation are more likely to converge and are more reliable. But,\nthis prognosis may be overly optimistic. Professional philosophers\nwithin the same culture do not converge, so there is little prima\nfacie reason to expect cross-cultural converge. Moreover, it's\nimportant to bear in mind that intuitions are tapping into semantic\nknowledge, and semantic knowledge is not based on recollection of\nperfect forms in Plato's heaven. Rather, it is informed by everything\nfrom explicit instruction to language use within the community, and\nsalient exemplars. These sources of semantic knowledge may vary\ncross-culturally. Thus, it remains possible that cherished\nphilosophical theories are more parochial than we assumed. If so,\nresearch on the cognitive science of culture has important\nimplications for philosophical practice."}]
