[{"date.published":"2004-05-28","date.changed":"2021-04-08","url":"https://plato.stanford.edu/entries/economic-justice/","author1":"Marc Fleurbaey","author1.info":"https://sites.google.com/site/marcfleurbaey/Home","entry":"economic-justice","body.text":"\n\n\nDistributive justice is often considered not to belong to the scope of\neconomics, but there is actually an important literature in economics\nthat addresses normative issues in social and economic justice. A\nvariety of economic theories and approaches provide many insights in\nthese matters. Presented below are the theory of inequality and\npoverty measurement, welfare economics, the theory of social choice,\nthe theory of bargaining and of cooperative games, and the theory of\nfair allocation. There has been a good deal of cross-fertilization\nbetween these different branches of normative economics and\nphilosophical theories of justice, and many examples of such mutual\ninfluences are exhibited in this article.\n\nThe role of ethics in economic theorizing is still a debated issue. In\nspite of the reluctance of many economists to view normative issues as\npart and parcel of their discipline, normative economics now\nrepresents an impressive body of literature. One may, however, wonder\nif normative economics cannot also be considered a part of political\nphilosophy. \nIn the first half of the twentieth century, most leading economists\n(Pigou, Hicks, Kaldor, Samuelson, Arrow etc.) devoted a significant\npart of their research effort to normative issues, notably the\ndefinition of criteria for the evaluation of public policies. The\nsituation is very different nowadays. “Economists do not devote\na great deal of time to investigating the values on which their\nanalyses are based. Welfare economics is not a subject which every\npresent-day student of economics is expected to study”, \nwrites Atkinson (2001, p. 195), who regrets “the strange\ndisappearance of welfare economics”. Normative economics itself\nmay be partly guilty for this state of affairs, in view of its\nrepeated failure to provide conclusive results and its long-lasting\nfocus on impossibility theorems (see\n § 4.1).\n But there has also been a persistent ambiguity about the status of\nnormative propositions in economics. The subject matter of economics\nand its close relation to policy advice make it virtually impossible\nto avoid mingling with value judgments. Nonetheless, the desire to\nseparate positive statements from normative statements has often been\ntransformed into the illusion that economics could be a science only\nby shunning the latter. Robbins (1932) has been influential in this\npositivist move, in spite of a late clarification (Robbins 1981) that\nhis intention was not to disparage normative issues, but only to\nclarify the normative status of (useful and necessary) interpersonal\ncomparisons of welfare. It is worth emphasizing that many results in\nnormative economics are mathematical theorems with a primary\nanalytical function. Endowing them with a normative content may be\nconfusing, because they are most useful in clarifying ethical values\nand do not imply by themselves that these values must be endorsed.\n“It is a legitimate exercise of economic analysis to examine the\nconsequences of various value judgments, whether or not they are\nshared by the theorist.” (Samuelson 1947, p. 220) The role of\nethical judgments in economics has received recent and valuable\nscrutiny in Sen (1987), Hausman and McPherson (2006) and Mongin\n(2001b). \nThere have been many mutual influences between normative economics and\npolitical philosophy. In particular, Rawls’ difference principle\n(Rawls 1971) has been instrumental in making economic analysis of\nredistributive policies pay some attention to the maximin criterion,\nwhich puts absolute priority on the worst-off, and not only to\nsum-utilitarianism. (It has taken more time for economists to realize\nthat Rawls’ difference principle applies to primary goods, not\nutilities.) Conversely, many concepts used by political philosophers\ncome from various branches of normative economics (see below). \nThere are, however, differences in focus and in methodology. Political\nphilosophy tends to focus on the general issue of social justice,\nwhereas normative economics also covers microeconomic issues of\nresource allocation and the evaluation of public policies in an unjust\nsociety (although there is now philosophical work on non-ideal\ntheory). Political philosophy focuses on arguments and basic\nprinciples, whereas normative economics is more concerned with the\neffective ranking of social states than the arguments underlying a\ngiven ranking. The difference is thin in this respect, since the\naxiomatic analysis in normative economics may be interpreted as\nperforming not only a logical decomposition of a given ranking or\nprinciple, but also a clarification of the underlying basic principles\nor arguments. But consider for instance the “leveling-down\nobjection” (Parfit 1995), which states that egalitarianism is\nwrong because it considers that there is something good in\nachieving equality by leveling down (even when the egalitarian ranking\nsays that, all things considered, leveling down is bad). This\nkind of argument has to do with the reasons underlying a social\njudgment, not with the content of the all things considered judgment\nitself. It is hard to imagine if and how the leveling-down objection\ncould be incorporated in the models of normative economics. A final\ndifference between normative economics and political philosophy,\nindeed, lies in conceptual tools. Normative economics uses the formal\napparatus of economics, which gives powerful means to derive\nnon-intuitive conclusions from simple arguments, although it also\ndeprives the analyst of the possibility of exploring issues that are\nhard to formalize. \nThere are now several general surveys of normative economics, some of\nwhich do also cover the intersection with political philosophy: Arrow,\nSen and Suzumura (1997, 2002, 2011), Fleurbaey (1996), Hausman and\nMcPherson (2006, rev. and augmented in Hausman et al. 2016), Kolm\n(1996), Moulin (1988, 1995, 1998), Roemer (1996), Young (1994). \nFocusing traditionally on income inequality and poverty, this field\nhas been first built on the assumption that there is a given\nunidimensional measure of individual advantage. The gist of the\nanalysis is then about the distribution of this particular notion of\nadvantage. \nMore recently, partly due to the emergence of data about living\nconditions, there has been growing interest in the measurement of\ninequality and poverty when individual situations are described by a\nmultidimensional list of attributes or deprivations. This has\ngenerated the field of “multidimensional inequality and poverty\nmeasurement”. \nSo far most of this literature has remained disconnected from the\nwelfare economics literature in which interpersonal comparisons of\nwell-being in relation to individual preferences is a key issue. The\ntypical multidimensional indices do not refer to well-being or\npreferences. But the connection is being made and the welfare\neconomics literature will eventually blend with the inequality and\npoverty measurement literature. \nExcellent surveys of the unidimensional part of the theory include:\nChakravarty (1990, 2009), Cowell (2000), Dutta (2002), Lambert (1989),\nSen and Foster (1997), Silber (1999). The multidimensional approach is\nsurveyed or discussed in Weymark (2006), Chakravarty (2009), Decancq\nand Lugo (2013), Aaberge and Brandolini (2015), Alkire et al. (2015),\nDuclos and Tiberti (2016). The link between inequality and poverty\nmeasurement and welfare economics is discussed in Decancq et al.\n(2015) and in several chapters of Adler and Fleurbaey (2016). For a\ncomprehensive handbook on economic inequality, see Atkinson and\nBourguignon (2000, 2015). \nThe study of inequality and poverty indices started from a\nstatistical, pragmatic perspective, with such indices as the Gini\nindex of inequality or the poverty head count. Recent research has\nprovided two valuable insights. First, it is possible to relate\ninequality indices to social welfare functions, so as to give\ninequality indices a more transparent ethical content. The idea is\nthat an inequality index should not simply measure dispersion in a\ndescriptive way, but would gain in relevance if it measured the harm\nto social welfare done by inequality. There is a simple method to\nderive an inequality index from a social welfare function, due to Kolm\n(1969) and popularized by Atkinson (1970) and Sen (1973). Consider a\nsocial welfare function which is defined on distributions of income\nand is symmetrical (i.e., permuting the income of two individuals\nleaves social welfare unchanged). For any given unequal distribution\nof income, one may compute the egalitarian distribution of income\nwhich would yield the same social welfare as the unequal distribution.\nThis is called the “equally-distributed equivalent” (or\n“equal-equivalent”) distribution. If the social welfare\nfunction is averse to inequality, the total amount of income in the\nequal-equivalent distribution is less than in the unequal\ndistribution. In other words, the social welfare function condones\nsome sacrifice of total income in order to reach equality. This drop\nin income, measured in proportion of the initial total income, may\nserve as a valuable index of inequality. This index may also be used\nin a picturesque decomposition of social welfare. Indeed, an ordinally\nequivalent measure of social welfare is then total income (or average\nincome – it does not matter when the population is fixed) times\none minus the inequality index. \nThis method of construction of an index of inequality, often referred\nto as the ethical approach to inequality measurement, is most\nuseful when the argument of the social welfare function, and the\nobject of the measurement of inequality, is the distribution of\nindividual well-being (which may or may not be measured by income).\nThen the social welfare function is indeed symmetrical (by requirement\nof impartiality) and its aversion to inequality reflects its\nunderlying ethical principles. In other contexts, the method is more\nproblematic. Consider the case when social welfare depends on\nindividual well-being, and individual well-being depends on income\nwith some individual variability due to differential needs. Then\nincome equality may no longer be a valuable goal, because the needy\nindividuals may need more income than others. Using this method to\nconstruct an index of inequality of well-being is fine, but\nusing it to construct an index of inequality of incomes would\nbe strange, although it would immediately reveal that income\ninequality is not always bad (when it compensates for unequal needs).\nNow consider the case when social welfare is the utilitarian sum of\nindividual utilities, and all individuals have the same strictly\nconcave utility function (strict concavity means that it displays a\ndecreasing marginal utility). Then using this method to construct an\nindex of income inequality is amenable to a different interpretation.\nThe index then does not reflect a principled aversion to inequality in\nthe social welfare function, since the social welfare function has no\naversion to inequality of utilities. It only reflects the consequence\nof an empirical fact, the degree of concavity of individual utility\nfunctions. To call this the ethical approach, in this context, seems a\nmisnomer. \nIn the field of multidimensional inequality or poverty measurement, a\nkey divide has separated the measures that evaluate the distribution\nin every dimension (such as income, health, asset deprivation...)\nbefore they aggregate over the dimensions, from the measures that\nfirst evaluate individual situations, all dimensions included, before\naggregating over individuals. The latter has been praised (Decancq and\nLugo 2013) for being closer to the standard individualistic approach\nin welfare economics, and for making it possible to have measures that\nare sensitive to the correlation between disadvantages (e.g., the\npositive correlation between income and health), and therefore more\naccurately record the multidimensional suffering of the worst off. An\ninteresting feature of such measures is that a positive correlation\namong attributes of advantage or disadvantage worsens inequalities\nonly if the elasticity of substitution between attributes, in the\nmeasure of individual multidimensional advantage, is greater than the\ninequality aversion in the social index. To illustrate, consider two\ncanonical distributions, with two individuals and two attributes: \n(Perfect correlation) Ann: (1,1) and Bob: (2,2) \n(Anti-correlation) Ann: (1,2) and Bob: (2,1) \nIf the attributes are deemed perfectly substitutable (meaning that\nonly the sum, potentially weighted, of the attributes matters for the\nassessment of individual advantage), and the inequality aversion is\nzero (meaning that only the sum of individual indexes of advantage\nmatters), the two distributions are considered equally good. But they\nalso appear equally good if there is no possible substitution (only\nthe value of the worst attribute matters) and inequality aversion is\ninfinite (only the worst-off individual matters). In contrast, the\nfirst distribution appears worse if the attributes are substitutable\nand inequality aversion is strong (the first distribution is then\nunequal, unlike the second one); whereas it appears better if there is\nno possible substitution and inequality aversion is weak (only one\nindividual has a bad attribute in the first distribution, whereas both\nhave one in the second). \nThe second valuable contribution of recent research in this field is\nthe development of an alternative ethical approach through the\naxiomatic study of the properties of indices. The main ethical axioms\ndeal with transfers. The Pigou-Dalton principle of transfers says that\ninequality decreases (or social welfare increases) when an even\ntransfer is made from a richer to a poorer individual without\nreversing their pairwise ranking (although this may alter their\nranking relative to other individuals). Since this condition is about\neven transfers, it is quite weak and other axioms have been proposed\nin order to strengthen the priority of the worst-off. The principle of\ndiminishing transfers (Kolm 1976) says that a Pigou-Dalton transfer\nhas a greater impact the lower it occurs in the distribution. The\nprinciple of proportional transfers (Fleurbaey and Michel 2001) says\nthat an inefficient transfer in which what the donor gives and what\nthe beneficiary receives is proportional to their initial positions\nincreases social welfare. Similar transfer axioms have been adapted to\nthe measurement of poverty. For instance, Sen (1976) proposed the\ncondition saying that poverty increases when an even transfer is made\nfrom someone who is below the poverty line to a richer individual\n(below or above the line). The other axioms with which the axiomatic\nanalysis has been made usually have a less obvious ethical appeal, and\nrelate to decomposability of indices, scale invariance and the like.\nCharacterization results have been obtained, which identify classes of\nindices satisfying particular lists of axioms. The two ethical\napproaches may be combined, when one takes as an axiom the condition\nthat the index be derived from a social welfare function with\nparticular features. \nThe multiplicity of indices, even when a restriction to special\nsub-classes may be justified by axiomatic characterization, raises a\nserious problem for applications. How can one make sure that a\ndistribution is more or less unequal, or has more or less poverty,\nthan another without checking an infinite number of indices? Although\nthis may look like a purely practical issue, it has given rise to a\nbroad range of deep results, relating the statistical concept of\nstochastic dominance to general properties of social welfare functions\nand to the satisfaction of transfer axioms by inequality and poverty\nindices. This approach, in particular, justifies the widespread use of\nLorenz curves in the empirical studies of inequality. The Lorenz curve\ndepicts the percentage of the total amount of whatever is measured,\nincome, wealth or well-being, possessed by any given percentage of the\npoorest among the population. For instance, according to the Census\nBureau, in 2006 the poorest 20%’s share of total income was 3.7%, the\npoorest 40%’s share was 13.1%, the poorest 60%’s share was 28.1%, the\npoorest 80%’s share was 50.6%, while the top 5%’s share was 22.2%.\nThis indicates that the Lorenz curve is approximately as in the\nfollowing figure. \nConsiderable progress has been made in the development of dominance\ntechniques of the Lorenz type, with extensions to multidimensional\ninequality and to poverty measurement (Aaberge and Brandolini\n2015). \nPhilosophical interest in the measurement of inequality has recently\nrisen (Temkin 1993). Most of this philosophical literature, however,\ntends to focus on defining the right foundations for an aversion to\ninequality. In particular, Parfit (1995) proposes to give priority to\nthe worse-off not because of their relative position compared to the\nbetter-off, but because and to the extent that they are badly off.\nThis probably corresponds to defining social welfare by an additively\nseparable social welfare function, with diminishing marginal social\nutility (a social welfare function is additively separable when it is\nthe sum of separate terms, each of which depends only on one\nindividual’s well-being). Interestingly, if egalitarianism is defined\nin opposition to this “priority view” by the feature that\nit relies on judgments of relative positions, this means that\negalitarian values cannot be correctly represented by a separable\nsocial welfare function. This seems to raise the ethical stakes\nconcerning properties of decomposability of indices or separability of\nsocial welfare functions, which are usually considered in economics\nmerely as convenient conditions simplifying the functional forms\n(although separability may also be justified by the subsidiarity\nprinciple, according to which unconcerned individuals need not have a\nsay in a decision). The content and importance of the distinction\nbetween egalitarianism and prioritarianism remains a matter of debate\n(see, among many others, Tungodden 2003, and the contributions in\nHoltug and Lippert-Rasmussen 2007). It is also interesting to notice\nthat philosophers are often at ease to work with the notion of social\nwelfare (or social good, or inequality) as a numerical quantity with\ncardinal meaning, whereas economists typically restrict their\ninterpretation of social welfare or inequality to a purely ordinal\nranking of social states. Beside egalitarian and prioritarian\npositions one must also mention the “sufficiency view”,\ndefended e.g. by Frankfurt (1987) who argues that priority should be\ngiven only to those below a certain threshold. One may consider that\nthis view supports the idea that poverty indices might summarize\neverything that is relevant about social welfare. \nWelfare economics is the traditional generic label of normative\neconomics, but, in spite of substantial variations between\nauthors, it now tends to be associated with a particular\nsubcontinent of this domain, maybe as a result of the development of\n“non-welfarist” approaches and of approaches with a\nbroader scope, such as the theory of social choice. \nSurveys on welfare economics in its restricted definition can be found\nin Graff (1957), Boadway and Bruce (1984), Chipman and Moore (1978),\nSamuelson (1981). Many topics of welfare economics are addressed in\nthe more recent handbooks by Arrow, Sen and Suzumura (2002, 2011),\nAtkinson and Bourguignon (2000, 2015) and Adler and Fleurbaey (2016).\nAccessible introductions are given by (book-length) Adler (2019) and\n(article-length) Fleurbaey (2019). \nThe proponents of a “new” welfare economics (Hicks,\nKaldor, Scitovsky) have distanced themselves from their predecessors\n(Marshall, Pigou, Lerner) by abandoning the idea of making social\nwelfare judgments on the basis of interpersonal comparisons of\nutility. Their problem was then that in absence of any kind of\ninterpersonal comparisons, the only principle on which to ground their\njudgments was the Pareto principle, according to which a situation is\na global improvement if it is an improvement for every member of the\nconcerned population (there are variants of this principle depending\non how individual improvement is defined, in terms of preferences or\nsome notion of well-being, and depending on whether it is a strict\nimprovement for all members or some of them stay put). Since most\nchanges due to public policy hurt some subgroups for the benefit of\nothers, the Pareto principle remains generally silent. The need for a\nless restrictive criterion of evaluation has led Kaldor (1939) and\nHicks (1939) to propose an extension of the Pareto principle through\ncompensation tests. According to Kaldor’s criterion, a situation is a\nglobal improvement if ex post the gainers could compensate the losers.\nFor Hicks’ criterion, the condition is that ex ante the losers could\nnot compensate the gainers (a change from situation A to situation B\nis approved by Hicks’ criterion if the change from B to A is not\napproved by Kaldor’s criterion). These criteria are much less partial\nthan the Pareto principle, but they remain partial (that is, they fail\nto rank many pairs of alternatives). This is not, however, their main\ndrawback. They have been criticized for two basic flaws. First, for\nplausible definitions of how the compensation transfers could be\ncomputed, these criteria may lead to inconsistent social judgments:\nthe same criterion may simultaneously declare that a situation A is\nbetter than another situation B, and conversely. Scitovsky (1941) has\nproposed to combine the two criteria, but this does not prevent the\noccurrence of intransitive social judgments. Second, the compensation\ntests have a dubious ethical value. If the compensatory transfers are\nperformed in Kaldor’s criterion, then the Pareto criterion alone\nsuffices since after compensation everybody gains. If the compensatory\ntransfers are not performed, the losers remain losers and the mere\npossibility of compensation is a meager consolation to them. Such\ncriteria are then typically biased in favor of the rich whose\nwillingness to pay is generally high (i.e., they are willing to give a\nlot in order to obtain whatever they want, and therefore they can\neasily compensate the losers; when they do not actually pay the\ncompensation, they can have the cake and eat it too). \nCost-benefit analysis has more recently developed criteria which are\nvery similar and rely on the summation of willingness to pay across\nthe population. In spite of repeated criticism by specialists (Arrow\n1951, Boadway and Bruce 1984, Sen 1979, Blackorby and Donaldson 1990),\npractitioners of cost-benefit analysis and some branches of economic\ntheory (industrial organization, international economics) still\ncommonly rely on such criteria. More sophisticated variants of\ncost-benefit analysis (Layard and Glaister 1994, Drèze and\nStern 1987) avoid these problems by relying on weighted sums of\nwillingness to pay or even on consistent social welfare functions.\nAdler (2012) offers a comprehensive study of the foundations of the\nsocial welfare function approach to cost-benefit analysis. Many\nspecialists of public economics (e.g. Stiglitz 1987) have considered\nthat the Pareto criterion was the core ethical principle on which\neconomists should buttress their social evaluations, denouncing all\nsources of inefficiency in social organizations and public\npolicies. \nA subfield of welfare economics focused on the possibility of making\nsocial welfare judgments on the basis of national income. An increase\nin national income may reflect an increase in social welfare under\nsome stringent assumptions, most conspicuously the assumption that the\ndistribution of incomes is socially optimal. Although very\nrestrictive, this kind of result has a lasting influence, in theory\n(international economics) and in practice (the salience of GDP growth\nin policy discussions). There exists a school of social indicators\n(see the Social Indicators Research journal) which fights\nthis influence and the number of alternative indicators (of happiness,\ngenuine progress, social health, economic well-being, etc.) has soared\nin the last decades (see e.g. Miringoff and Miringoff 1999, Frey and\nStutzer 2002, Kahneman et al. 2004 and Gadrey and Jany-Catrice\n2006). \nBergson (1938) and Samuelson (1947, 1981) occupy a special position,\nwhich may be described as a third way between old and new welfare\neconomics. From the former, they retain the goal of making complete\nand consistent social welfare judgments with the help of well-defined\nsocial welfare functions. The formula\nW(U1(x),…,Un(x))\nis often named a “Bergson-Samuelson social welfare\nfunction” (x is the social state;\nUi(x), for\ni=1,…,n,  is individual i’s\nutility in this state). With the latter, however, they share the idea\nthat only ordinal non-comparable information should be retained about\nindividual preferences. This may seem contradictory with the formula\nof the Bergson-Samuelson social welfare function, in which individual\nutility functions appear, and there has been a controversy about the\npossibility of constructing a Bergson-Samuelson social welfare\nfunction on the sole basis of individual ordinal non-comparable\npreferences (see in particular Arrow (1951), Kemp and Ng (1976),\nSamuelson (1977, 1987), Sen (1986) and a recent discussion in\nFleurbaey and Mongin (2005)). Samuelson and his defenders are commonly\nconsidered to have lost the contest, but it may also be argued that\ntheir opponents have misunderstood them. Indeed, individual utility\nfunctions in the\nW(U1(x),…,Un(x))\nformula are, according to Bergson and Samuelson, to be constructed out\nof individual preference orderings, on the basis of fairness\nprinciples. The logical possibility of such a construction has been\nrepeatedly proven by Samuelson (1977), Pazner (1979), Mayston (1974,\n1982). The fact that such a construction does not require any other\ninformation than ordinal non-comparable preferences is indisputable.\nBergson and Samuelson acknowledged the need for interpersonal\ncomparisons, but considered that these could be done, in an ethically\nrelevant way, on the sole basis of non-comparable preference\norderings. They failed, however, to be more specific about the\nfairness principles on which the construction could be justified. The\ntheory of fair allocation (see\n § 6)\n may fill the gap. \nHarsanyi may be viewed as the last representative of the old welfare\neconomics, to which he made a major contribution in the form of two\narguments. The first one is often called the “impartial observer\nargument”. An impartial observer should decide for society as if\nshe had an equal chance of becoming anyone in the considered\npopulation. This is a risky situation in which the standard decision\ncriterion is expected utility. The computation of expected utility, in\nthis equal probability case, yields an arithmetic mean of the\nutilities that the observer would have if she became anyone in the\npopulation. Harsanyi (1953) considers this to be an argument in favor\nof utilitarianism. The obvious weakness of the argument, however, is\nthat not all versions of utilitarianism would measure individual\nutility in a way that may be entered in the computation of the\nexpected utility of the impartial observer. In other words, ask a\nutilitarian to compute social welfare, and ask an impartial observer\nto compute her expected utility. There is little reason to believe\nthat they will come up with similar conclusions, even though both\ncompute a sum or a mean. For instance, a very risk-averse impartial\nobserver may come arbitrarily close to the maximin criterion. \nThis argument has triggered controversies, in particular with Rawls\n(1974), about the soundness of the maximin criterion in the original\nposition, and with Sen (1977b). See Harsanyi (1976) and recent\nanalyses in Weymark (1991), Mongin (2001a). There is a related, but\ndifferent controversy about the consequences of the veil of ignorance\nin Dworkin’s hypothetical insurance scheme (Dworkin 2000). Roemer\n(1985) argues that if individuals maximize their expected utility on\nthe insurance market, they insure against states in which they have\nlow marginal utility. If low marginal utility happens to be the\nconsequence of some handicaps, then the hypothetical market will tax\nthe disabled for the benefit of the others, a paradoxical but typical\nconsequence of utilitarian policies. It is indeed well known that\ninsurance markets have strange consequences when utilities are\nstate-dependent (that is, when the utility of income is affected by\nrandom events). For a recent revival of this controversy, see Dworkin\n(2002), Fleurbaey (2008) and Roemer (2002a). \nHarsanyi’s second argument, the “aggregation theorem”, is\nabout a social planner who, facing risky prospects, maximizes expected\nsocial welfare and wants to respect individual preferences about\nprospects. Harsanyi (1955) shows that these two conditions imply that\nsocial welfare must be a weighted sum of individual utilities, and\nconcludes that this is another argument in favor of utilitarianism.\nRecent evaluation of this argument and its consequences may be found\nin Broome (1991), Weymark (1991). In particular, Broome uses the\nstructure of this argument to conclude that social good must be\ncomputed as the sum of individual goods, although this does not\npreclude incorporating a good deal of inequality aversion in the\nmeasurement of individual good. Diamond (1967) has raised a famous\nobjection against the idea that expected utility is a good criterion\nfor the social planner. This criterion implies that if the social\nplanner is indifferent between the distributions of utilities, for two\nindividuals, (1,0) and (0,1), then he must also be indifferent between\nthese two distributions and an equal probability of getting either\ndistribution. This is paradoxical, this lottery being ex ante better\nsince it gives equal prospects to individuals. Broome (1991) raises\nanother puzzle. An even better lottery would yield either (0,0) or\n(1,1) with equal probability. It is better because ex ante it gives\nindividuals the same prospects as the previous lottery, and it is more\negalitarian ex post. The problem is that it seems quite hard to\nconstruct a social criterion which ranks these four alternatives as\nsuggested here. Defining social welfare under uncertainty is still a\nmatter of bafflement. See Deschamps and Gevers (1979), Ben Porath,\nGilboa and Schmeidler (1997), Fleurbaey (2010). Things are even more\ndifficult when probabilities are subjective and individual beliefs may\ndiffer. Harsanyi’s aggregation theorem then transforms into an\nimpossibility theorem. On this, see in particular Hylland and\nZeckhauser (1979), Mongin (1995), Bradley (2005), Mongin and Pivato\n(2016, 2020). \nThe theory of social choice originated in Arrow’s failed attempt to\nsystematize the Bergson-Samuelson approach (see Arrow 1983, p.26). It\ndeveloped into an immense literature, with many ramifications to a\nvariety of subfields and topics. The social choice framework is,\npotentially, so general that one may think of using it to unify\nnormative economics. In a restrictive definition, however, social\nchoice is considered to deal with the problem of synthesizing\nheterogeneous individual preferences into a consistent ranking.\nSometimes an even more restrictive notion of “Arrovian social\nchoice” is used to name works which faithfully adopt Arrow’s\nparticular axioms. \nThere are many surveys of social choice theory, in broad and\nrestrictive senses: Arrow, Sen and Suzumura (1997, in particular chap.\n3, 4, 7, 11, 15; 2002, in particular chap. 1, 2, 3, 4, 7, 10; 2011, in\nparticular chap. 13, 14, 17–20), Sen (1970, 1977a, 1986, 1999,\n2009), Anand, Puppe and Pattanaik (2009). See also the entry on\n social choice theory. \nIn an attempt to construct a consistent social ranking of a set of\nalternatives on the basis of individual preferences over this set,\nArrow (1951) obtained: 1) an impossibility theorem; 2) a\ngeneralization of the framework of welfare economics, covering all\ncollective decisions from political democracy and committee decisions\nto market allocation; 3) an axiomatic method which set a standard of\nrigor for any future endeavor. \nThe impossibility theorem roughly says that there is no general way to\nrank a given set of (more than two) alternatives on the basis of (at\nleast two) individual preferences, if one wants to respect three\nconditions: (Weak Pareto) unanimous preferences are always respected\n(if everyone prefers A to B, then A is better than B); (Independence\nof Irrelevant Alternatives) any subset of two alternatives must be\nranked on the sole basis of individual preferences over this subset;\n(No-Dictatorship) no individual is a dictator in the sense that his\nstrict preferences are always obeyed by the ranking, no matter what\nthey and the other individuals’ preferences are. The impossibility\nholds when one wants to cover a great variety of possible profiles of\nindividual preferences. When there is sufficient homogeneity among\npreferences, for instance when alternatives differ only in one\ndimension and individual preferences are based on the distance of\nalternatives to their preferred alternative along this dimension\n(think, for instance, of political options on the left-right\nspectrum), then consistent methods exist (the majority rule, in this\nexample; Black 1958). \nArrow’s result clearly extends the scope of analysis beyond the\ntraditional focus of welfare economics, and nicely illuminates the\ndifficulties of democratic voting procedures such as the Condorcet\nparadox (consisting of the fact that majority rule may be\nintransitive). The analysis of voting procedures is wide domain. For\nrecent surveys, see e.g. Saari (2001) and Brams and Fishburn (2002),\nas well as the entry on\n Arrow’s Theorem.\n This analysis reveals a deep tension between rules based on the\nmajority principle and rules which protect minorities by taking\naccount of preferences in a more extended way (see Pattanaik\n2002). \nSpecialists of welfare economics once claimed that Arrow’s result had\nno bearing on economic allocation (e.g. Samuelson 1967), and there is\nsome ambiguity in Arrow (1951) about whether, in an economic context,\nthe best application of the theorem is about individual self-centered\ntastes over personal consumptions, in which case it is indeed\nrelevant to welfare economics, or about individual ethical\nvalues about general allocations. It is now generally\nconsidered that the formal framework of social choice can sensibly be\napplied to the Bergson-Samuelson problem of ranking allocations on the\nbasis of individual tastes. Applications of Arrow’s theorem to various\neconomic contexts have been made (see the surveys by Le Breton 1997,\nLe Breton and Weymark 2011). \nSen (1970a) proposes a further generalization of the social choice\nframework, by permitting consideration of information about individual\nutility functions, not only preferences. This enlargement is motivated\nby the impossibility theorem, but also by the ethical relevance of\nvarious kinds of data. Distributional issues obviously require\ninterpersonal comparisons of well-being. For instance, an egalitarian\nevaluation of allocations needs a determination of who the worst-off\nare. It is tempting to think of such comparisons in terms of\nutilities. This has triggered an important body of literature which\nhas greatly clarified the meaning of various kinds of interpersonal\nutility comparisons (of levels, differences, etc.) and the relation\nbetween them and various social criteria (egalitarianism,\nutilitarianism, etc.). This literature (esp. d’Aspremont and Gevers\n1977) has also provided an important formal analysis of the concept of\nwelfarism, showing that it contains two subcomponents. The first one\nis the Paretian condition that an alternative is equivalent to another\nwhen all individuals are indifferent between them. This excludes using\nnon-welfarist information about alternatives, but does not exclude\nusing non-welfarist information about individuals (one individual may\nbe favored because of a physical handicap). The second one is an\nindependence condition formulated in terms of utilities. It may be\ncalled Independence of Irrelevant Utilities (Hammond 1987), and says\nthat the social ranking of any pair of alternatives must depend only\non utility levels at these two alternatives, so that a change in the\nprofile of utility functions which would leave the utility levels\nunchanged at the two alternatives should not alter how they are\nranked. This excludes using non-welfarist information about\nindividuals, but does not exclude using non-welfarist information\nabout alternatives (one may be preferred because it has more freedom).\nThe combination of the two conditions excludes all non-welfare\ninformation. Excellent surveys are given in d’Aspremont (1985),\nd’Aspremont and Gevers (2002), Bossert and Weymark (2004), Mongin and\nd’Aspremont (1998). In spite of the important clarification made by\nthis literature, the introduction of utility functions essentially\namounts to going back to old welfare economics, after new welfare\neconomics and authors such as Bergson, Samuelson and Arrow failed to\nprovide appealing solutions with data on consumer tastes only. \nA related issue is how the evaluation of individual well-being must be\nmade, or, equivalently, how interpersonal comparisons must be\nperformed. There is now a growing interest in exploring concrete ways\nof measuring individual well-being, as illustrated by happiness\nstudies (section 7.5 below) and the handbook published by Adler and\nFleurbaey (2016). Welfare economics traditionally relied on\n“utility”, and the extended informational basis of social\nchoice is mostly formulated with utilities (although the use of\nextended preference orderings is often shown to be formally\nequivalent: for instance, saying that Jones is better-off than Smith\nis equivalent to saying that it is better to be Jones than to be\nSmith, in some social state). But utility functions may be given a\nvariety of substantial interpretations, so that the same formalism may\nbe used to discuss interpersonal comparisons of resources,\nopportunities, capabilities and the like. In other words, one may\nseparate two issues: 1) whether one needs more information than\nindividual preference orderings in order to perform interpersonal\ncomparisons; 2) what kind of additional information is ethically\nrelevant (subjective utility or objective notions of opportunities,\netc.). The latter issue is directly related to philosophical\ndiscussions about how well-being should be conceived and to the\n“equality of what” debate. This debate, which originates\nwith Sen (1980), focuses on seeking the appropriate metric of\nadvantage that should be used by theories of justice that are\negalitarian or that give priority to the worst-off. \nThe former issue is still debated. Extending the informational basis\nby introducing numerical indices of well-being (or equivalent extended\norderings) is not the only conceivable extension. Arrow’s\nimpossibility is obtained with the condition of Independence of\nIrrelevant Alternatives, which may be logically analyzed, when the\ntheorem is reformulated with utility functions as primitive data, as\nthe combination of Independence of Irrelevant Utilities (defined\nabove) with a condition of ordinal non-comparability, saying that the\nranking of two alternatives must depend only on individuals’ ordinal\nnon-comparable preferences. Arrow’s impossibility may be avoided by\nrelaxing the ordinal non-comparability condition, and this is the\nabove-described extension of the informational basis by relying on\nutility functions. But Arrow’s impossibility may also be avoided by\nrelaxing Independence of Irrelevant Utilities only. In particular, it\nmakes sense to rank alternatives on the basis of how these\nalternatives are considered by individuals in comparison to other\nalternatives. For instance, when considering to make a transfer of\nconsumption goods from Jones to Smith, it is not enough to know that\nJones is against it and Smith is in favor of it (this is the only\ninformation usable under Arrow’s condition). It is also relevant to\nknow if both consider that Jones has a better bundle, or not, which\ninvolves considering other alternatives in which bundles are permuted,\nfor instance. In this vein, Hansson (1973) and Pazner (1979) have\nproposed to weaken Arrow’s axiom so as to make the ranking of two\nalternatives depend on the indifference curves of individuals at these\ntwo alternatives. In particular, Pazner relates this approach to\nSamuelson’s (Samuelson 1977) and concludes that the Bergson-Samuelson\nsocial welfare function can indeed be constructed consistently in this\nway. Interpersonal comparisons may be sensibly made on the sole basis\nof indifference curves and therefore on the sole basis of ordinal\nnon-comparable preferences. This requires broadening the concept of\ninterpersonal comparisons in order to cover all kinds of comparisons,\nnot just utility comparisons (see Fleurbaey and Hammond 2004). \nThe concept of informational basis itself need not be limited to\nissues of interpersonal comparisons. Many conditions of equity,\nefficiency, separability, responsibility, etc. bear on the kind and\nquantity of information that is deemed relevant for the ranking of\nalternatives. The theory of social choice gives a convenient framework\nfor a rigorous analysis of this issue. \nThe theory of social choice with utility functions has greatly\nsystematized our understanding of social welfare functions. For\ninstance, it has shown how to construct a continuum of intermediate\nsocial welfare functions between sum-utilitarianism and the maximin\ncriterion (or its lexicographic refinement, the leximin criterion,\nwhich ranks distributions of well-being by examining first the\nworst-off position, then the position which is just above the\nworst-off, and so on; for instance, the maximin is indifferent between\nthe three distributions (1,2,5), (1,3,5) and (1,3,6), whereas the\nleximin ranks them in increasing order). Three other developments\naround utilitarian social welfare functions are worth mentioning. \nThe first development is related to the application of theories of\nequality of opportunity, and involves the construction of mixed social\nwelfare functions which combine utilitarianism and maximin. Suppose\nthat there is a double partition of the population, such that one\nwould like the social welfare function to display infinite inequality\naversion within subgroups of the first partition, and zero inequality\naversion within subgroups of the second partition. For instance,\nsubgroups of the first partition consist of equally deserving\nindividuals, for which one would like to obtain equality of outcomes,\nwhereas subgroups of the second partition consist of individuals who\nhave equal opportunities, so that inequalities among them do not\nmatter. Van de gaer (1993) proposes to apply average utilitarianism\nwithin each subgroup of the second partition, and to apply the maximin\ncriterion to the vector of average utilities obtained in this way. In\nother words, the average utilities measure the value of the\nopportunity sets offered to individuals, and one applies the maximin\ncriterion to such values, in order to equalize the value of\nopportunity sets. Roemer (1998) proposes to apply the maximin\ncriterion within each subgroup of the first partition, and then to\napply average utilitarianism to the vector of minimum utilities\nobtained in this way. In other words, one tries to equalize outcomes\nfor equally deserving individuals first, and then applies a\nutilitarian calculus. These may not be the only possible combinations\nof utilitarianism and maximin, but they are given an axiomatic\njustification which suggests that they are indeed salient, in Ooghe,\nSchokkaert and Van de gaer (2007) and Fleurbaey (2008). For a survey\non the applications of Roemer’s criterion, see Roemer (2002b) and,\nmore recently, Ferreira and Peragine (2016), Roemer and Trannoy\n(2016), Ramos and Van de gaer (2016). \nA second interesting development deals with intergenerational ethics.\nWith an infinite horizon, it is essentially impossible to combine the\nPareto criterion and anonymity (permuting the utilities of some\ngenerations does not change social welfare) in a fully satisfactory\nway, even when utilities are perfectly comparable. This is a similar\nbut more basic impossibility than Arrow’s theorem. The intuition of\nthe problem can be given with the following simple example. Consider\nthe following sequence of utilities: (1,2,1,2,…). Permute the\nutility of every odd period with the next one. One then obtains\n(2,1,2,1,…). Then permute the utility of every even period with\nthe next one. This yields (2,2,1,2,…). This third sequence\nPareto-dominates the first one, even though it was obtained only\nthrough simple permutations. This impossibility is now better\nunderstood, and various results point to the “catching up”\ncriterion as the most reasonable extension of sum-utilitarianism to\nthe infinite horizon setting. This criterion, which does not rank all\nalternatives, applies when the finite-horizon sums of utilities, for\ntwo infinite sequences of utilities, are ranked in the same way for\nall finite horizons above some finite time. Interestingly, this topic\nhas seen parallel and sometimes independent contributions by\neconomists and philosophers (see e.g. Lauwers and Liedekerke 1997,\nLauwers and Vallentyne 2003, Roemer and Suzumura 2007). \nA third development worth mentioning has to do with population ethics.\nSum-utilitarianism appears to be overly populationist, since it\nimplies the “repugnant conclusion” (Parfit 1984) that we\nshould aim for an unhappy but sufficiently large population in\npreference to a small and happy one. Conversely, average\nutilitarianism is “Malthusian”, preferring a happier\npopulation, no matter how small, to a less happy one, no matter how\nlarge. Here again there is an interesting tension, namely, between\naccepting all individuals whose utility is greater than zero,\naccepting equalization of utilities, and avoiding the “repugnant\nconclusion”. This tension is shown in this way. Start with a\ngiven affluent population of any size. Add any number of individuals\nwith positive but almost zero utilities. This does not reduce social\nwelfare. Then equalize utilities, which again does not reduce social\nwelfare. One then obtains, compared to the initial population, a\nlarger population with lower utilities. One sees that these lower\nutilities may be arbitrarily low, if the added individuals are\nsufficiently numerous and have sufficiently low initial utilities,\nthus yielding the repugnant conclusion (see Arrhenius 2000). Average\nutilitarianism disvalues additional individuals whose utility is below\nthe average, which is very restrictive for affluent populations. A\nless restrictive approach is that of critical-level utilitarianism,\nwhich disvalues only individuals whose utility level is below some\nfixed, low but positive threshold. For an extensive overview and a\ndefense of critical-level utilitarianism, see Blackorby, Bossert and\nDonaldson (1997, 2005), as well as Broome (2004). For an original\nproposal relying on a different social welfare function (inspired by\nthe Gini function), see Asheim and Zuber (2014). \nAt the time when Arrow declared social choice to be impossible, Nash\n(1950) published a possibility theorem for the bargaining problem,\nwhich is the problem of finding an option acceptable to two parties,\namong a subset of alternatives. Interestingly, Nash relied on the\naxiomatic analysis just like Arrow, so that both can be given credit\nfor the introduction of this method in normative economics. In the\nsame decade, a similar contribution was made by Shapley (1953) to the\ntheory of cooperative games. The development of such approaches has\nbeen impressive since then, but some questioning has emerged regarding\nthe ethical relevance of this theory to issues of distributive\njustice. \nNash (1950) adopted a welfarist framework, in which alternatives are\ndescribed only by the utility levels they give to the two parties. His\nsolution consists in choosing the alternative which, in the feasible\nset, maximizes the product of individual utility gains from the\ndisagreement point (this point is the fallback option when the parties\nfail to reach an agreement). This solution is therefore related to a\nparticular social welfare function which is somehow intermediate\nbetween sum-utilitarianism and the maximin criterion. Contrary to\nthese, however, it is invariant to independent changes in utility\nzeros and scales, which means that it can be applied with utility\nfunctions which are defined only up to an affine transformation (i.e.,\nno difference is made between utility function Ui\nand utility function ai Ui +\nbi), such as Von Neumann-Morgenstern utility\nfunctions. Nash uses this invariance property in his axiomatic\ncharacterization of the solution. He also uses another property, which\nholds for any solution maximizing a social welfare function, namely,\nthat removing non-selected options does not alter the choice. \nThis particular property is criticized in Kalai and Smorodinsky\n(1975), because it makes the solution ignore the relative size of the\nsacrifices made by the parties in order to reach a compromise. They\npropose another solution, which consists of equalizing the parties’\nsacrifice relative to the maximum gain they could expect in the\navailable set of options. This solution, contrary to Nash’s,\nguarantees that an enlargement of the set of options that is favorable\nto one party never hurts this party in the ultimate selection. It is\nvery similar to Gauthier’s (1986) “minimax relative\nconcession” solution. Many other solutions to the bargaining\nproblem have been proposed, but these two are by far the most\nprominent. \nThe relevance of bargaining theory to the theory of distributive\njustice has been questioned. First, if the disagreement point is\ndefined, as it probably should, in relation to the relative strength\nof parties in a “state of nature”, then the scope for\nredistributive solidarity is very limited. One obtains a theory of\n“justice as mutual advantage” (Barry 1989, 1995) which is\nnot satisfactory at the bar of any minimal conception of impartiality\nor equality. Second, the welfarist formal framework of the theory of\nbargaining is poor in information (Roemer 1986b, 1996). Describing\nalternatives only in terms of utility levels makes it impossible to\ntake account of basic physical features of allocations. For instance,\nit is impossible to find out, from utility data alone, which of the\nalternatives is a competitive equilibrium with equal shares. As\nanother illustration, Nash’s and Kalai and Smorodinsky’s solutions\nboth recommend allocating an indivisible prize by a fifty-fifty\nlottery, whether the prize is symmetric (a one-dollar bill for either\nparty) or asymmetric (a one-dollar bill if party 1 wins, ten dollars\nif party 2 wins). \nExtensive surveys of bargaining theory can be found in Peters (1992),\nThomson (1999). \nThe basic theory of bargaining focuses on the two-party case, but it\ncan readily be extended to the case when a greater number of parties\nare at the table. However, when there are more than two parties, it\nbecomes relevant to consider the possibility for subgroups\n(coalitions) to reach separate agreements. Such considerations lead to\nthe broader theory of cooperative games. \nThis broader theory is, however, more developed for the relatively\neasy case when coalition gains are like money prizes which can be\nallocated arbitrarily among coalition members (the “transferable\nutility case”). In this case, for the two-party bargaining\nproblem the Nash and Kalai-Smorodinsky solutions coincide and give\nequal gains to the two parties. The Shapley value is a solution which\ngeneralizes this to any number of parties and gives a party the\naverage value of the marginal contribution that this party brings to\nall coalitions which it can join. In other words, it rewards the\nparties in proportion to the increase in coalition gain that they\nbring about by gathering with others. \nAnother important concept is the core. This notion generalizes the\nidea that no rational party would accept an agreement that is less\nfavorable than the disagreement point. An allocation of the total\npopulation prize is in the core if the total amount received by any\ncoalition is at least as great as the prize this coalition could\nobtain on its own. Otherwise, obviously, the coalition has an\nincentive to “block” the agreement. Interestingly, the\nShapley value is not always in the core, except for “convex\ngames”, that is, games such that the marginal contribution of a\nparty to a coalition increases when the coalition is bigger. \nThe basics of this theory are very well presented in Moulin (1988) and\nMyerson (1991). Cooperative games are distinguished from\nnon-cooperative games by the fact that the players can commit to an\nagreement, whereas in a non-cooperative game every player always seeks\nhis interest and never commits to a particular strategy. The central\nconcept of the theory of non-cooperative games is the Nash equilibrium\n(every player chooses his best strategy, taking others’ strategies as\ngiven), which has nothing to do with Nash’s bargaining solution. It\nhas been shown, however, that Nash’s bargaining solution can be\nobtained as the Nash equilibrium of a non-cooperative bargaining game,\nin which players make offers alternatively, and accept or reject the\nother’s offer. \nThe theory of fair allocation studies the allocation of resources in\neconomic models. The seminal contribution is Kolm (1972), where the\ncriterion of equity as no-envy is extensively analyzed with the\nconceptual tools of general equilibrium theory. Later the theory\nborrowed the axiomatic method from bargaining theory, and it now\ncovers a great variety of economic models and encompasses a variety of\nfairness concepts. \nThere are several surveys of this theory: Thomson and Varian (1985),\nMoulin and Thomson (1997), Maniquet (1999), Thomson (2011). \nAn allocation is envy-free if no individual would prefer having the\nbundle of another. An egalitarian distribution in which everyone has\nthe same bundle is trivially envy-free, but is generally\nPareto-inefficient, which means that there exist other feasible\nallocations that are better for some individuals and worse for none. A\ncompetitive equilibrium with equal shares (i.e., equal budgets) is the\ncentral example of a Pareto-efficient and envy-free allocation. It is\nenvy-free since all agents have the same budget options, so that\neveryone could buy everyone’s bundle. It is Pareto-efficient because,\nby an important theorem of welfare economics, any perfectly\ncompetitive equilibrium is Pareto-efficient (in absence of asymmetric\ninformation, externalities, public goods). A non-technical\npresentation of this theorem can be found in Hausman and McPherson\n(2006, 5.2). \nThis concept of equity does not need any other information than\nindividual ordinal preferences. It is not welfarist, in the sense that\nfrom utility data alone it is impossible to distinguish an envy-free\nallocation from an allocation with envy. Moreover, an envy-free\nallocation may be Pareto-indifferent (everyone is indifferent) to\nanother allocation that has envy. On the other hand, this concept is\nstrongly egalitarian, and it is quite natural to view it as capturing\nthe idea of equality of resources (Dworkin 2000). When resources are\nmulti-dimensional, for instance when there are several consumption\ngoods, and when individual preferences are heterogeneous, it is not\nobvious to define equality of resources, but the no-envy criterion\nseems the best concept for this purpose. It guarantees that no\nindividual will consider that another has a better bundle than his. It\nhas been shown by Varian (1976) that, if preferences are sufficiently\ndiverse and numerous (a continuum), then the competitive equilibrium\nwith equal shares is the only Pareto-efficient and envy-free\nallocation. \nThis concept can also be related to the idea of equality of\nopportunities (Kolm 1996). An allocation is envy-free if and only if\nthe bundles granted to everyone could have been chosen by each\nindividual in the same opportunity set, such as, for instance, the set\ncontaining all the bundles of the allocation under consideration.\nAlong this vein, the concept of no-envy can also be shown to have a\nclose connection with incentive considerations. A no-envy test is used\nin the theory of optimal taxation in order to make sure that no one\nwould have interest to lie about one’s preferences (Boadway and Keen\n2000). Consider the condition that, when an allocation is selected and\nsome individuals’ preferences change so that their bundle goes up in\ntheir own preference ranking, then the selected allocation is still\nacceptable. A particular version of this condition plays a central\nrole in the theory of incentives, under the name of Maskin\nmonotonicity (see e.g. Jackson 2001), but it can also be given an\nethical meaning, in terms of neutrality with respect to changes in\npreferences. Notice that envy-free allocations satisfy this condition,\nsince after such a change of preferences every individual’s bundle\ngoes up in his ranking, thereby precluding any appearance of envy.\nConversely, it turns out that this condition implies that the selected\nallocation must be envy-free, under the additional assumption that, in\nany selected allocation, individuals with identical preferences must\nhave equivalent bundles. If one also requires the selection to be\nPareto-efficient, then one obtains a characterization of the\ncompetitive equilibrium with equal shares (Gevers 1986). \nKolm’s (1972) seminal monograph focused on the simple problem of\ndistributing a bundle of non-produced commodities, and on equity as\nno-envy. Other economic problems, and other fairness concepts, have\nbeen studied later. Here is a non-exhaustive list of other economic\nproblems that have been analyzed: sharing labor and consumption in the\nproduction of a consumption good; producing a public good and\nallocating the contribution burden among individuals; distributing\nindivisible commodities, with or without the possibility of making\nmonetary compensations; matching pairs of individuals (men-women,\nemployers-workers…); distributing compensations for\ndifferential needs; rationing on the basis of claims; distributing a\ndivisible commodity when preferences are satiable. In the main stream\nof this theory, the problem is to select a good subset of allocations\nunder perfect knowledge of the characteristics of the population and\nof the feasible set. There is also a branch which studies cost and\nsurplus sharing, when the only information available are the\nquantities demanded or contributed by the population, and the cost or\nsurplus may be distributed as a function of these quantities only (see\nMoulin 2002). The relevance of this literature for political\nphilosophers should not be underestimated. Even models which seem to\nbe devoted to narrow microeconomic allocation problems may turn out to\nbe quite relevant, and some models are addressing issues already\nsalient in political philosophy. This is the case in particular for\nthe model of production of a private good when individuals have\nunequal skills, which is a rough description of a market economy, and\nfor the model of differential needs. Both models are especially\nrelevant for analyzing the issue of responsibility, talent and\nhandicap, which is now prominent in egalitarian theories of justice. A\nsurvey on these two models in made in Fleurbaey and Maniquet (2011a),\nand a monograph connecting the various relevant fields of economic\nanalysis to theories of responsibility-sensitive egalitarianism is in\nFleurbaey (2008). \nAmong the other concepts of fairness which have been introduced, two\nfamilies are important. The first family contains principles of\nsolidarity, which require individuals to be affected in the same way\n(they all gain or all lose) by some external shock (change in\nresources, technology, population size, population characteristics).\nFor instance, if resources or technology improve, then it is natural\nto hope that everyone will benefit. The second family contains welfare\nbounds, which provide guarantees to everyone against extreme\ninequality. For instance, in the division of non-produced commodities,\nit is very natural to require that nobody should be worse-off than at\nthe equal-split allocation (i.e. the allocation in which everyone gets\nthe per capita amount of resources). \nLet us briefly describe some of the insights that are gained through\nthis theory and seem relevant to political philosophy. A very\nimportant one is that there is a conflict between no-envy and\nsolidarity (Moulin and Thomson 1988, 1997). This conflict is well\nillustrated by the fact that in a market economy, typically any change\nin technology benefits some agents and hurts others, even when the\nchange is a pure progress which could benefit all. Solidarity\nprinciples are not obeyed by allocation rules which pass the no-envy\ntest, and these principles point toward a different kind of\ndistribution, named “egalitarian-equivalence” by Pazner\nand Schmeidler (1978). An allocation is egalitarian-equivalent when\neveryone is indifferent between his bundle in this allocation and the\nbundle he would have in an egalitarian economy defined in some simple\nway. For instance, the egalitarian economy may be such that everyone\nhas the same bundle. In this case, an egalitarian-equivalent\nallocation is such that everyone is indifferent between his bundle and\none particular bundle. In more sophisticated versions, the egalitarian\neconomy is such that everyone has the same budget set, in some\nparticular family of budget sets. Egalitarian-equivalence is a serious\nalternative to no-envy for the definition of equality of resources,\nand its superiority in terms of solidarity is quite significant, in\nrelation to the next point. \nThe second insight, indeed, is that no-envy itself is a combination of\nconflicting principles (Fleurbaey and Maniquet 2011a, Fleurbaey 2008).\nThis conflict is made apparent in models with talents and handicaps.\nFor instance, Pazner and Schmeidler (1974) found out that there may\nnot exist envy-free and Pareto-efficient allocations in the context of\nproduction with unequal skills (when there are high-skilled\nindividuals who are strongly averse to labor). This results  from\nan incompatibility between a compensation principle saying that\nindividuals with identical preferences should have equivalent bundles\n(suppressing inequalities due to skills), and a reward principle\nsaying that individuals with the same skills should not envy each\nother (no preferential treatment on the basis of different\npreferences). Both principles are a logical implication of the no-envy\ntest. This is obvious for the latter. For the former, notice that\nno-envy among individuals with the same preferences means that they\nmust have bundles on the same indifference curve. Interestingly, the\ncompensation principle is a logical consequence of solidarity\nprinciples and is therefore perfectly compatible with them. It is very\nwell satisfied by egalitarian-equivalent allocation rules. In\ncontrast, it is violated by Dworkin’s hypothetical insurance which\napplies the no-envy test behind a veil of ignorance (see Dworkin 2000,\nFleurbaey 2008, and\n § 3.2).\n A recent philosophical analysis of the no-envy approach has been\ndeveloped in Olson (2020). The relation between envy and theories of\njustice is also scrutinized in the entry on\n envy. \nThe theory of fair allocations contains many positive results about\nthe existence of fair allocations, for various fairness concepts, and\nthis stands in contrast to Arrow’s impossibility theorem in the theory\nof social choice. The difference between the two theories has often\nbeen interpreted as due to the fact that they perform different\nexercises (Sen 1986, Moulin and Thomson 1997). The theory of social\nchoice, it is said, seeks a ranking of all options, while the theory\nof fair allocation focuses on the selection of a subset of\nallocations. This explanation is not convincing, since selecting a\nsubset of fair allocations is formally equivalent to defining a\nfull-blown albeit coarse ranking, with “good” and\n“bad” allocations. A more convincing explanation lies in\nthe fact that the information used in fairness criteria is richer than\nallowed by Arrow’s Independence of Irrelevant Alternatives (Fleurbaey,\nSuzumura and Tadenuma 2002). For instance, in order to check that an\nallocation is envy-free while another displays envy, it is not enough\nto know how individuals rank these two allocations in their\npreferences. One must know individual preferences over other\nalternatives involving permutations of bundles (an envious individual\nwould prefer an allocation in which his bundle is permuted with one he\nenvies). In this vein, one discovers that it is possible to extend the\ntheory of fair allocation so as to construct fine-grained rankings of\nall allocations. This is very useful for the discussion of public\npolicies in “second-best” settings, that is, in settings\nwhere incentive constraints make it impossible to reach\nPareto-efficiency. With this extension, the theory of fair allocation\ncan be connected to the theory of optimal taxation (Maniquet 2007),\nand becomes even more relevant to the political philosophy of\nredistributive institutions (Fleurbaey 2007). It turns out that the\negalitarian-equivalence approach is very convenient for the definition\nof fine-grained orderings of allocations, which provides an additional\nargument in its favor. A detailed study of fair social orderings is\nmade in Fleurbaey and Maniquet (2011b). \nSen (1970b) and Gibbard (1974) propose, within the framework of social\nchoice, paradoxes showing that it may not be easy to rank alternatives\nwhen some individuals have a special right to rank some alternatives\nthat differ only in matters belonging to their private sphere, and\nwhen their preferences are sensitive to what happens in other\nindividuals’ private spheres. For instance, as an illustration of\nGibbard’s paradox, individuals have the right to choose the color of\ntheir shirt, but, in terms of social ranking, should A and B wear the\nsame color or different colors, when A wants to imitate B and B wants\nto have a different color? There is a huge literature on this topic,\nand after Gaertner, Pattanaik and Suzumura (1992), who argue that no\nmatter what choice A and B make, their rights to choose their own\nshirt is respected, a good part of it examines how to describe rights\nproperly. The framework of game forms is an interesting alternative to\nthe social choice model. Recent surveys can be found in Arrow, Sen and\nSuzumura (1997, vol. 2). \nApart from this formal analysis of rights, economic theory is not very\nwell connected to libertarian philosophy, since economic models show\nthat, apart from the very specific context of perfect competition with\ncomplete markets, perfect information, no externalities and no public\ngoods, the laissez-faire allocation is typically inefficient and\narbitrarily unequal. Therefore libertarian philosophers do not find\nmuch help or inspiration in economic theory, and there is little\ncross-fertilization in this area. \nThe capability approach, developed in Sen (1985, 1992), is a\nparticular response to the “equality of what” debate, and\nis presented by Sen as the best way to think about the relevant\ninterpersonal comparisons to be made for evaluations of social\nsituations at the bar of distributive justice. It is often presented\nas intermediate between resourcist and welfarist approaches, but it is\nperhaps accurate to present it as more general. A\n“functioning” is any doing or being in the life of an\nindividual. A “capability set” is the set of functioning\nvectors that an individual has access to. This approach has attracted\na lot of interest in particular because it makes it possible to take\ninto account all the relevant dimensions of life, in contrast with the\nresourcist and welfarist approaches which can be criticized as too\nnarrow. \nBeing so general, the approach needs to be specified in order to\ninspire original applications. The body of empirical literature that\ntakes inspiration from the capability approach is now numerically\nimpressive. As noted in Robeyns (2006) and Schokkaert (2007b), in many\ncases the empirical studies are essentially similar, except for\nterminology, to the sociological studies of living conditions. But\nthere are more original applications, e.g., when an evaluation of\ndevelopment programs that takes account of capabilities is contrasted\nwith cost-benefit analysis (Alkire 2002) or when a list of basic\ncapabilities is enshrined in a theory of what a just society should\nprovide to all citizens (Nussbaum 2000). More generally, all studies\nwhich seek to incorporate multiple dimensions of quality of life into\nthe evaluation of individual and social situations can be considered,\nbroadly speaking, as pertaining to this approach. \nTwo central questions pervade the empirical applications. The first\nconcerns the distinction between capabilities and functionings. The\nlatter are easier to observe because individual achievements are more\naccessible to the statistician than pure potentialities. There is also\nthe normative issue of whether the evaluation of individual situations\nshould be based on capabilities only, viewed as opportunity sets, or\nshould take account of achieved functionings as well. The second\ncentral question is the index problem, which has also been raised\nabout Rawls’ theory of primary goods. There are many dimensions of\nfunctionings and capabilities and not all of them are equally\nvaluable. The definition of a proper system of weights has appeared\nproblematic in connection to the difficulties of social choice\ntheory. \nRecent surveys on this approach and its applications can be found in\nAlkire (2016), Basu and Lopez-Calva (2011), Kuklys (2005), Robeyns\n(2006), Robeyns and Van der Veen (2007), Schokkaert (2009). \nRoemer (1982, 1986c) proposes a renewed economic analysis of Marxian\nconcepts, in particular exploitation. He shows that, even if the\ntheory of labor value is flawed as a causal theory of prices, it may\nbe consistently used in order to measure exploitation and analyze the\ncorrelation between exploitation and the class status of individuals.\nHowever, he considers that this concept of exploitation is ethically\nnot very appealing, since it roughly amounts to requiring individual\nconsumption to be proportional to labor, and he suggests a different\ndefinition of exploitation, in terms of undue advantage due to unequal\ndistribution of some assets. This leads him eventually to merge this\nline of analysis with the general stream of egalitarian theories of\njustice. The idea that consumption should be proportional to labor has\nalso received some attention in the theory of fair allocation (Moulin\n1990, Roemer & Silvestre 1993). See Roemer (1986a) for a\ncollection of philosophical and economic essays on Marxism. There has\nbeen a recent wave of analysis of the concept of exploitation in\neconomics, in particular under the impulsion of Veneziani and\nYoshihara (2015, forthcoming). See also Veneziani (2013), Fleurbaey\n(2014) and Skillman (2014). For the references in philosophy, see the\nentry on\n exploitation. \nIn normative economics, theorists have often been wary of relying on\nconcepts which are disconnected from the layman’s intuition.\nQuestionnaire surveys, usually performed among students, have indeed\ngiven some disturbing results. Welfarist approaches have been\nquestioned by the results of Yaari and Bar Hillel (1984), the\nPigou-Dalton principle has been critically scrutinized by Amiel and\nCowell (1992), the principles of compensation and reward have obtained\nmixed support in Schokkaert and Devooght (1998), etc. It is of course\ndebatable how much theorists can learn from such results (Bossert\n1998). \nSurveys of this questionnaire approach are available in Schokkaert and\nOverlaet (1989), Amiel and Cowell (1999), Schokkaert (1999), Gaertner\nand Schokkaert (2011). Philosophers have also performed similar\ninquiries (Miller 1992). \nIt is standard in normative economics, as in political philosophy, to\nevaluate individual well-being on the basis of self-centered\npreferences, utility or advantage. Feelings of altruism, jealousy,\netc. are ignored in order not to make the allocation of resources\ndepend on the contingent distribution of benevolent and malevolent\nfeelings among the population (see e.g. Goodin 1986, Harsanyi 1982).\nIt may be worth mentioning here that the no-envy criterion discussed\nabove has nothing to do with interpersonal feelings, since it is\ndefined only with self-centered preferences. When an individual\n“envies” another in this particular sense, he simply\nprefer the other’s consumption to his own, but no feeling is involved\n(he might even not be aware of the existence of the other\nindividual). \nBut positive economics is quite relevantly interested in studying the\nimpact of individual feelings on behavior. Homo œconomicus may\nbe rational without being narrowly focused on his own consumption. The\nanalysis of labor relations, strategic interactions, transfers within\nthe family, generous gifts require a more complex picture of human\nrelations (Fehr and Fischbacher 2002). Reciprocity, in particular,\nseems to be a powerful source of motivation, leading individuals to\nincur substantial costs in order to reward nice partners and punish\nfaulty partners (Fehr and Gachter 2000). For an extensive survey of\nthis branch of the economic literature, see Gérard-Varet, Kolm\nand Mercier-Ythier (2004). \nThe literature on happiness has surged in the last decade. The\nfindings are well summarized in many surveys (see in particular Diener\n(1994, 2000), Diener et al. (1999), Frey and Stutzer (2002), Graham\n(2009), Kahneman et al. (1999), Kahneman and Krueger (2006), Layard\n(2005), Oswald (1997), Van Praag and Ferrer-i-Carbonell 2008), and\nreveal the main factors of happiness: personal temperament, health,\nsocial connections (in particular being married and employed). The\nimpact of material wealth is debated, some arguing that it is more a\nmatter of relative position than of absolute comfort, at least above a\nminimal level of affluence (Easterlin 1995, Clark et al. 2008), others\narguing that there is a positive (but logarithmic: doubling income\ninduces a constant increment on happiness) impact over the whole range\nof observed living standards (Deaton 2008, Sacks et al. 2010) . \nA hotly debated question is what to make of this approach in welfare\neconomics. There is a wide variety of positions, from those who\npropose to measure and maximize national happiness (Diener 2000,\nKahneman et al. 2004, Layard 2005) to those who firmly oppose this\nidea on various grounds (Burchardt 2006, Nussbaum 2008, among others).\nThere seems to be a consensus on the idea that happiness studies\nsuggest a welcome shift of focus, in social evaluation, from purely\nmaterialistic performances to a broader set of values. Above all, one\ncan consider that the traditional suspicion among economists about the\npossibility to measure subjective well-being is being assuaged by the\nrecent progress. \nHowever, the fact that subjective well-being can be measured does not\nimply that it ought to be taken as the metric of social evaluation.\nSurprisingly, the literature on happiness refers very little to the\nlively philosophical debates of the previous decades about welfarism,\nand in particular the criticisms raised by Rawls (1982) and Sen (1985)\nagainst utilitarianism. (Two exceptions are Burchardt (2006) and\nSchokkaert (2007). Layard (2005) also mentions and quickly rebuts some\nof the arguments against welfarism.) Nonetheless, one of the key\nelements of that earlier debate, namely, the fact that subjective\nadaptation is likely to hide objective inequalities, shows up in the\ndata, challenging happiness specialists. Subjective well-being seems\nrelatively immune in the long run to many aspects of objective\ncircumstances, individuals displaying a remarkable ability to adapt.\nAfter most important life events, satisfaction returns to its usual\nlevel and the various affects return to their usual frequency. If\nsubjective well-being is not so sensitive to objective circumstances,\nshould we stop caring about inequalities, safety, and\nproductivity? \nThese issues and the possible uses of subjective well-being data for\nwelfare analysis are discussed in detail in several chapters of Adler\nand Fleurbaey (2016), in particular the chapters by Fujiwara and\nDolan, Bykvist, Haybron, Lucas, Graham, Clark, Decancq and\nNeumann. \nNormative economics, even more so than political and moral philosophy,\nhas traditionally been anthropocentric, but growing interest in animal\nrights and animal interests is emerging, following the lead of\ninfluential philosophers (see the entry on the \n moral status of animals)\n and, e.g., Sunstein and Nussbaum 2004).\nInterestingly, specialized studies in animal welfare, in biology,\nadopt similar methods as welfare economics to estimate animal\npreferences and conceptualize various approaches to their needs and\ntheir well-being (e.g., Appleby et al. 2018). Many arguments being\ndeveloped against the current farming practices are still based on\nanthropocentric considerations such as climate change and ecosystem\nservices. But the idea of carving a place in the social welfare\nfunction for animals, alongside their fellow humans, is gaining ground\n(Johansson-Stenman 2018, Carlier and Treich 2020, Espinosa and Treich\n2021; for the opposite view, see Eichner and Pethig 2006). Budolfson\nand Spears (2020) propose a way to compute an inclusive utilitarian\nsocial welfare function based on a distinction between well-being\npotential and relative realized well-being.","contact.mail":"marc.fleurbaey@psemail.eu","contact.domain":"psemail.eu"}]
