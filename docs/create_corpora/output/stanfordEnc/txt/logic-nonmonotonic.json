[{"date.published":"2001-12-11","date.changed":"2019-04-20","url":"https://plato.stanford.edu/entries/logic-nonmonotonic/","author1":"Christian Strasser","author2":"G. Aldo Antonelli","author1.info":"http://rub.academia.edu/ChristianStrasser","entry":"logic-nonmonotonic","body.text":"\n\n\nThe term “non-monotonic logic” (in short, NML) covers a\nfamily of formal frameworks devised to capture and represent\ndefeasible inference. Reasoners draw conclusions defeasibly\nwhen they reserve the right to retract them in the light of further\ninformation. Examples are numerous, reaching from inductive\ngeneralizations to reasoning to the best explanation to inferences on\nthe basis of expert opinion, etc. We find defeasible inferences in\neveryday reasoning, in expert reasoning (e.g. medical diagnosis), and\nin scientific reasoning. \n\n\n\n Defeasible reasoning\n just like deductive reasoning, can follow complex patterns. However,\nsuch patterns are beyond reach for classical logic (CL),\nintuitionistic logic (IL) or other logics that characterize deductive\nreasoning since they—by their very nature—do not allow for\na retraction of inferences. The challenge tackled in the domain of\nNMLs is to provide for defeasible reasoning forms what CL or IL\nprovide for mathematical reasoning: namely a formally precise\naccount that is materially adequate, where material adequacy\nconcerns the question of how broad a range of examples is captured by\nthe framework, and the extent to which the framework can do justice to\nour intuitions on the subject (at least the most entrenched ones).\n\n\nDefeasible reasoning is dynamic in that it allows for a retraction of\ninferences. Take, for instance, reasoning on the basis of normality or\ntypicality assumptions. While we infer that Tweety flies on the basis\nof the information that Tweety is a bird and the background knowledge\nthat birds usually fly, we have good reasons to retract this inference\nwhen learning that Tweety is a penguin or a kiwi.  \nAnother example is abductive reasoning\n (Aliseda 2017).\n Given the observation that the streets are wet we may infer the\nexplanation that it has been raining recently. However, recalling that\nthis very day the streets are cleaned and that the roof tops are dry,\nwe will retract this inference.  \nAs a last example take probabilistic reasoning where we infer\n“X is a B” from “X is an\nA and most As are Bs”. Clearly, we may\nlearn that X is an exceptional A with respect to being a\nB and in view of this retract our previous inference.  \nOur previous examples are instances of ampliative reasoning. It\nis based on inferences for which the truth of the premises does not\nguarantee or necessitate the truth of the conclusion as in deductive\nreasoning. Instead, the premises support the conclusion defeasibly,\ne.g., the conclusion may hold in most/typical/etc. cases in which the\npremises hold.  \nReasoning may also turn defeasible when applied to an inconsistent\nstock of information, possibly obtained via different sources.\nClassical logic is not a viable option in such situations, since it\nallows us to derive just any consequence. A more cautious approach is\nto consider maximal consistent subsets (with respect to set inclusion)\nof the given information\n (Rescher and Manor 1970).\n For instance, where \\(p\\), \\(q\\), and \\(s\\) are logical atoms and\n\\(\\Gamma = \\{ p \\wedge q, \\neg p \\wedge q, s\\}\\), maximal consistent\nsubsets of \\(\\Gamma\\) are \\(\\Gamma_1 = \\{p \\wedge q, s\\}\\) and\n\\(\\Gamma_2 = \\{\\neg p \\wedge q, s\\}\\). Various consequence relations\nhave been defined on the basis of consistent subsets. We give two\nexamples (see\n Benferhat et al. (1997)\n for more).  \nLet \\(\\Sigma\\) be a possibly inconsistent set of formulas and let\n\\(\\mathrm{MCS}(\\Sigma)\\) be the set of maximal consistent subsets of\n\\(\\Sigma\\). The set \\(\\mathrm{Free}(\\Sigma)\\) of innocent\nbystanders in \\(\\Sigma\\) is obtained by intersecting all members\nof \\(\\mathrm{MCS}(\\Sigma)\\).  \nIn our example, the innocent bystander \\(s\\) is both a free and\ninevitable consequence, while \\(q\\) is merely an inevitable\nconsequence. In order to highlight the defeasible character of this\ntype of reasoning, consider the situation in which we obtain\nadditionally the information \\(\\neg s\\). We now have the additional\ntwo maximal consistent subsets \\(\\Gamma_{3} = \\{p \\wedge q, \\neg s\\}\\)\nand \\(\\Gamma_{4} = \\{p \\wedge \\neg q, \\neg s\\}\\) in view of which\n\\(s\\) is neither a free nor an inevitable consequence. E.g., although\n\\(\\Gamma \\nc_{\\mathrm{free}} s\\) we have \\(\\Gamma \\cup \\{\\neg s\\}\n\\nnc_{\\mathrm{free}} s\\).  \nThis kind of dynamics is characteristic for non-monotonic logics, in\nfact it is the reason for their name. They violate the Monotony\nproperty which holds for deductive reasoning, for instance, for the\nrelation of logical consequence \\(\\vDash\\) of CL (see the entry on\n classical logic\n for details on the relation \\(\\vDash\\)):  \nMonotony states that consequences are robust under the addition of\ninformation: if \\(\\phi\\) is a consequence of \\(\\Sigma\\) then it is\nalso a consequence of any set containing \\(\\Sigma\\) as a subset. Most\nof scholarly attention has been paid to the type of dynamics\nunderlying defeasible reasoning that results in violations of Montony\ndue to the retraction of inferences in view of conflicting new\ninformation. It has been called the synchronic\n (Pollock 2008)\n or the external dynamics\n (Batens 2004)\n of defeasible reasoning.  \nClearly, most forms of defeasible reasoning are externally dynamic and\nhence most logics for defeasible reasoning violate Monotony: they have\nnon-monotonic consequence relations for which consequences may not\npersist when new information is obtained. This feature is so central\nthat the formal logical study of defeasible reasoning is often taken\nto be coextensive with the domain of NML where non-monotonicity is\nunderstood as a property of the consequence relation of a logic.  \nIt has been noted, that beside the external there is also a\ndiachronic\n (Pollock 2008)\n or internal dynamics\n (Batens 2004)\n underlying defeasible reasoning. It is the result of retracting\ninferences without having available new information in terms of new\npremises: by analyzing the already available information we may find\n(possibly unexpected) inconsistencies.  \nLet us return to non-monotonicity as a property of the consequence\nrelation. Given that Monotony is abandoned in NMLs, we are naturally\nled to the question which formal properties are to replace Monotony\nand whether some weakened forms of robustness of the consequence set\nunder the addition of new information is also to be expected in the\nrealm of defeasible reasoning. We state here two of the most central\nproperties considered in the literature:  \nBoth Cautious and Rational Monotony are special cases of Monotony, and\nare therefore not in the foreground as long as we restrict ourselves\nto the classical consequence relation \\(\\vDash\\) of CL.  \nCautious Monotony is the converse of Cut:  \nCautious Montony (resp. Cut) states that adding a consequence \\(\\phi\\)\nto the premise-set \\(\\Sigma\\) does not lead to any decrease\n(resp. increase) in inferential power. Taken together these\nprinciples express that inference is a cumulative enterprise: we can\nkeep drawing consequences that can in turn be used as additional\npremises, without affecting the set of conclusions. In\n Gabbay (1985)\n it has been shown that some basic and intuitive assumptions about\nnon-monotonic derivations give rise to consequence relations which\nsatisfy Cautious Monotony, Cut and Reflexivity (If \\(\\phi \\in \\Sigma\\)\nthen \\(\\Sigma \\nc \\phi\\)). Accordingly, these properties are commonly\ntaken to be central principles of\n NML.[1] \nRational Monotony states that no conclusions of \\(\\Sigma\\) are lost\nwhen adding formulas \\(\\phi\\) to \\(\\Sigma\\) that are not contradicted\nby \\(\\Sigma\\). Rational Monotony is a more controversial property than\nCautious Monotony. For instance,\n Stalnaker (1994)\n gave a counter-example to it (see the\n supplementary document)\n in view of which it is clear that not in all application contexts\nRational Monotony is a desirable property of defeasible reasoning.\n \nA separate issue from the formal properties of a non-monotonic\nconsequence relation, although one that is strictly intertwined with\nit, is the issue of how conflicts between potential defeasible\nconclusions are to be handled.  \nWe can distinguish two types of conflict handling in defeasible\nreasoning both of which will be discussed in more detail below. On the\none hand, we have conflict resolution principles such as the\nSpecificity Principle or other measures of argument strength. On the\nother hand, we have reasoning types that deal in different ways with\nnon-resolvable conflicts, most prominently the Credulous and the\nSkeptical reasoning types. In this section we still stay on an\nabstract level while concrete NMLs are discussed in the section\n Non-Monotonic Formalisms.\n  \nThere are two different kinds of conflicts that can arise within a\ngiven non-monotonic framework: (i) conflicts between defeasible\nconclusions and “hard facts,” some of which possibly newly\nlearned; and (ii) conflicts between one potential defeasible\nconclusion and another (many formalisms, for instance, provide some\nform of defeasible inference rules, and such rules may have\nconflicting conclusions). When a conflict (of either kind) arises,\nsteps have to be taken to preserve or restore consistency.  \nConflicts of type (i) are to be resolved in favor of the hard\nfacts in the sense that the conflicting defeasible conclusion is to be\nretracted. More interesting are mechanisms to resolve conflicts of\ntype (ii). In order to analyze these, we will make use of\nschematic inference graphs (similar to the ones used in\n Inheritance Networks,\n see below). For instance, our previous example featuring the bird\nTweety is illustrated as follows:  \nWe use the following conventions: double arrows signify deductive or\nstrict (i.e., non-defeasible) inferences, single arrows signify\ndefeasible inferences, and strikethrough arrows signify that the\nnegation of the pointed formula is implied. So, we can read the\ndiagram as follows: Penguins are birds (no exceptions); Birds usually\nfly; and Penguins usually don’t fly.  \nWe have a conflict between the following two arguments (where\narguments are sequences of inferences): Penguin \\(\\Rightarrow\\)\nBird \\(\\rightarrow\\) flies and Penguin\n\\(\\rightarrow\\) not-flies. Both arguments include a final\ndefeasible inference. What is important to notice is that a penguin is\na specific type of bird since Penguin \\(\\Rightarrow\\)\nBird (while not Bird \\(\\Rightarrow\\) Penguin).\nAccording to the Specificity Principle an inference with a more\nspecific antecedent overrides a conflicting defeasible inference with\na less specific antecedent. Concerning the penguin Tweety we thus\ninfer that she doesn’t fly on the basis of Penguin\n\\(\\rightarrow\\) not-flies rather than that she flies on the\nbasis of Penguin \\(\\Rightarrow\\) Bird \\(\\rightarrow\\)\nflies.  \nLogicians distinguish between strong and weak\nspecificity: according to strong specificity \\(A \\not\\rightarrow\nC\\) overrides \\(A \\Rightarrow B \\rightarrow C\\); according weak\nspecificity \\(A \\not\\rightarrow C\\) overrides \\(A \\rightarrow B\n\\rightarrow C\\). Note that the difference concerns the nature of the\nlink between A and B.  \nA preference for one defeasible inference A \\(\\rightarrow\\)\nB over another conflicting one C \\(\\rightarrow\\)\nD may depend also on other factors. For instance, in an\nepistemic context we may compare the strengths of A\n\\(\\rightarrow\\) B and C \\(\\rightarrow\\) D by\nappealing to the reliability of the source from which the respective\nconditional knowledge stems. In the context of legal reasoning we may\nhave the principles lex superior resp. lex posterior,\naccording to which the higher ranked resp. the later issued law\ndominates.  \nGiven a way to compare the strength of defeasible inference steps by\nmeans of a preference relation \\(\\prec\\), there is still the question\nof how to compare the strength of conflicting sequences of inferences\nviz. arguments. We give some examples. For a systematic survey and\nclassification of preference handling mechanisms in NML the interested\nreader is referred to\n Delgrande et al. (2004)\n and to\n Beirlaen et al. (2018).\n  \nAccording to the Weakest Link Principle\n (Pollock 1991)\n an argument is preferred over another conflicting argument if its\nweakest defeasible link is stronger than the weakest defeasible link\nin the conflicting argument. Take, for example, the situation in the\nfollowing figure:  \nOn the left we see an inference graph with two conflicting arguments.\nOn the right we see the preference ordering. The argument \\(A\n\\rightarrow B \\rightarrow E\\) is stronger than \\(C \\rightarrow D\n\\not\\rightarrow E\\) since for its weakest link \\(D \\not\\rightarrow E\\)\nwe have \\(D \\not\\rightarrow E \\prec A \\rightarrow B\\) and \\(D\n\\not\\rightarrow E \\prec B \\rightarrow E\\).  \nAnother approach to preferences is procedural and greedy\n (Liao et al 2018).\n Roughly, it instructs to always apply the rule with the highest\npriority first. (There may be various such rules with highest\npriority, but for the sake of simplicity we neglect this possibility\nin what follows.) Take the following example that is frequently\ndiscussed in the literature. We have the rules  \nwhere \\(A \\rightarrow B \\prec A \\not\\rightarrow C \\prec B \\rightarrow\nC\\) and we take \\(A\\) to be given. We can apply the defeasible rules\n\\(A \\rightarrow B\\) and \\(A \\not\\rightarrow C\\). If we operate in a\n“greedy” way, we may apply \\(A \\not\\rightarrow C\\) to\nderive \\(C\\) before applying \\(A \\rightarrow B\\), since \\(A\n\\rightarrow B \\prec A \\not\\rightarrow C\\). Now only \\(A \\rightarrow\nB\\) is applicable. So we derive \\(B\\). Although the antecedent of \\(B\n\\rightarrow C\\) is already derived, we cannot apply this rule for the\nsake of consistency.\n Brewka and Eiter (2000)\n argue against this greedy approach and in favor of deriving \\(B\\) and\n\\(C\\).\n Delgrande and Schaub (2000)\n argue that the example presents an incoherent set of rules. This is\nput into question in\n Horty (2007)\n where a consistent deontic reading in terms of conditional\nimperatives is presented which also challenges the procedural approach\nby favoring the conclusions \\(B\\) and \\(C\\).  \n\n \n Ford (2004) pointed out that the order of strict and defeasible links\nin arguments matters. For instance, she argues that an argument of the\nform \\(A \\rightarrow B \\Rightarrow D\\) may be stronger than an\nargument of the form \\(A \\Rightarrow C \\not\\rightarrow D\\) (where \\(A\n\\rightarrow B\\) reads “Most As are Bs” and\n\\(A \\Rightarrow C\\) reads “All As are Cs.”).\nThe reason is that in the former case it is not possible that no\nA is a D while in the second case it is possible that no\nA is a not-D. This is illustrated in the following\nfigure: \nThe left diagram demonstrates that there are distributions such that\nno As are not-Ds although \\(A \\Rightarrow C\\) and \\(C\n\\not\\rightarrow D\\) hold. The right diagram features a distribution\nfor \\(A \\rightarrow B \\Rightarrow D\\). Whenever the extension of\nA is non-empty there will be As that are Ds.  \nWe now discuss questions that arise in view of conflicts that are\nirresolvable since no available resolution principles applies. One can\ndraw inferences either in a “cautious” or\n“bold” fashion (also known as “skeptical” or,\nrespectively, “credulous”). These two options correspond\nto significantly different ways to construe a given body of defeasible\nknowledge, and yield different results as to what defeasible\nconclusions are warranted on the basis of such a knowledge base.  \nThe difference between these basic attitudes comes to this. In the\npresence of potentially conflicting defeasible inferences (and in the\nabsence of further considerations such as specificity — see\nabove), the credulous reasoner always commits to as many defeasible\nconclusions as possible, subject to a consistency requirement, whereas\nthe skeptical reasoner withholds assent from potentially conflicted\ndefeasible conclusions.  \nA well-known example from the literature, the so-called “Nixon\ndiamond,” will help to make the distinction clear. Suppose our\nknowledge base contains (defeasible) information to the effect that a\ngiven individual, Nixon, is both a Quaker and a Republican. Quakers,\nby and large, are pacifists, whereas Republicans, by and large, are\nnot. This is illustrated in the following figure:  \nThe question is what defeasible conclusions are warranted on the basis\nof this body of knowledge, and in particular whether we should infer\nthat Nixon is a pacifist or that he is not a pacifist.  \nNeither the skeptical nor the credulous reasoner have any logical\ngrounds to prefer either conclusion (“Nixon is a\npacifist”; “Nixon is not a pacifist”). While the\ncredulous reasoner commits to both conclusions, the skeptical reasoner\nrefrains from either.  \nA rationale behind the credulous reasoning type is to provide an\noverview of possible conclusions given the conflicting defeasible\ninferences in order to subsequently make a choice among them. This is\nespecially interesting in practical reasoning contexts in which the\nchoice determines a course of action and in which extra-logical\nconsiderations (based on preferences, values, etc.) further narrow\ndown the choice.  \nIn contrast, the rationale behind the skeptical reasoning type is to\ndetermine uncontested defeasible conclusions. The purpose may be of a\nmore epistemological nature such as the updating of the agent’s belief\nor knowledge base with the chosen conclusions.  \nWe now discuss some further issues that arise in the context of\nconflicting arguments. The first issue is illustrated in the following\nfigure:  \nConsider the argument Penguin \\(\\Rightarrow\\) Bird\n\\(\\rightarrow\\) has wings. Since penguins do not fly, we know\nthat penguins are exceptional birds, at least with respect to the\nproperty of flying. A very cautious reasoner may take this to be a\nreason to be skeptical about attributing other typical properties of\nbirds to penguins. NMLs that do not allow to derive has wings\nare said to suffer from the Drowning Problem\n \n (Benferhat et al., 1993).  \nThe question whether the exceptional status of Penguin relative\nto flies should spread also to other properties of Bird\nmay depend on specific relevance relations among these properties. For\ninstance,\n Koons (2017)\n proposes that causal relations play a role: whereas has strong\nforlimb muscles is causally related to flies and hence\nshould not be attributed to penguins, the situation is different with\nis cold-blooded. Similarly,\n Pelletier and Elio (1994)\n argue that explanatory relations play a significant role in the way\nin which reasoners treat exceptional information in non-monotonic\ninference.  \nAnother much discussed issue (e.g.,\n Ginsberg 1994,\n Makinson and Schlechta 1991,\n Horty 2002)\n concerns the question whether a conclusion that is derivable via two\nconflicting arguments should be derived. Such conclusions are called\nFloating Conclusions. The following figure illustrates this\nwith an extended version of the Nixon Diamond.  \nThe floating conclusion in question concerns is political which\nis derivable via Nixon \\(\\Rightarrow\\) Quaker\n\\(\\rightarrow\\) Dove \\(\\rightarrow\\) is political and\nvia Nixon \\(\\Rightarrow\\) Republican \\(\\rightarrow\\)\nHawk \\(\\rightarrow\\) is political. Both arguments are\nsuper-arguments of the conflicting Nixon \\(\\Rightarrow\\)\nQuaker \\(\\rightarrow\\) Dove and Nixon\n\\(\\Rightarrow\\) Republican \\(\\rightarrow\\)\n Hawk.[2]Horty (1994)\n argues that floating conclusions are acceptable in reasoning contexts\nin which “the value of drawing conclusions is high relative to\nthe costs involved if some of those conclusions turn out not to be\ncorrect” while they should be avoided “when the cost of\nerror rises” (p. 123).  \nWe conclude our discussion with so-called Zombie-Arguments\n (Makinson and Schlechta 1991,\n Touretzky et al. 1991). Recall that a skeptical reasoner does not commit to a\nconflicting argument.\n Makinson and Schlechta (1991)\n argue that super-arguments of such conflicted arguments\n—although not acceptable— nevertheless still have the\npower to undermine the commitment of a reasoner to an otherwise\nunconflicted argument. We see an example in the following figure:  \nWe observe two conflicting arguments concerning \\(D\\): \\(A \\rightarrow\nB \\rightarrow D\\) and \\(A \\rightarrow C \\not\\rightarrow D\\). Thus, we\nhave ambiguous information concerning \\(D\\). We observe\nfurther, that \\(F\\) is a consequence of the (unconflicted) argument\n\\(A \\rightarrow C \\rightarrow E \\rightarrow F\\). It conflicts with the\nzombie-argument \\(A \\rightarrow B \\rightarrow D \\not\\rightarrow F\\)\nwhich is a super-argument of the conflicted \\(A \\rightarrow B\n\\rightarrow D\\). The name refers to undead beings since an argument\nsuch as \\(A \\rightarrow B \\rightarrow D \\not\\rightarrow F\\) to which\nwe have no commitment may still have the power to influence our\ncommitment to an otherwise unconflicted argument such as \\(A\n\\rightarrow C \\rightarrow E \\rightarrow F\\). In the literature we can\ndistinguish two approaches to such scenarios. In\nambiguitiy-propagating formalisms the ambiguity in \\(D\\)\npropagates to \\(F\\), while in ambiguity-blocking formalisms it\ndoes not and so \\(F\\) is considered a consequence in view of the\nuncontested argument \\(A \\rightarrow C \\rightarrow E \\rightarrow F\\)\n (Stein 1992).\n  \nPioneering work in the field of NMLs began with the realization that\nin order to give a mathematically precise characterization of\ndefeasible reasoning CL is inadequate. Such a realization was\naccompanied by the effort to reproduce the success of CL in the\nrepresentation of mathematical, or formal, reasoning. Among the\npioneers of the field in the late 1970s were J. McCarthy, D.\nMcDermott & J. Doyle, and R. Reiter (see\n Ginsberg (1987)\n for a collection of early papers in the field and\n Gabbay et al. (1994)\n for a collection of excellent survey papers). In 1980, the\nArtificial Intelligence Journal published an issue (vol. 13,\n1980) dedicated to these new formalisms, an event that has come to be\nregarded as the “coming of age” of NML.  \nIn this section an overview will be provided on some important\nformalisms. Since the evolutionary tree of NMLs has grown\nextraordinarily rich, we will restrict the focus on presenting the\nbasic ideas behind some of the most influential and well-known\napproaches.  \nIf one of the goals of non-monotonic logic is to provide a materially\nadequate account of defeasible reasoning, it is important to rely on a\nrich supply of examples to guide and hone intuitions. Database theory\nwas one of the earliest sources of such examples, especially as\nregards the closed world assumption. Suppose a travel agent\nwith access to a flight database needs to answer a client’s query\nabout the best way to get from Oshkosh to Minsk. The agents queries\nthe database and, not surprisingly, responds that there are no direct\nflights. How does the travel agent know?  \nIt is quite clear that, in a strong sense of “know,” the\ntravel agent does not know that there are no such flights. What\nis at work here is a tacit assumption that the database is\ncomplete, and that since the database does not list any direct\nflights between the two cities, there are none. A useful way to look\nat this process is as a kind of minimization, i.e., an attempt\nto minimize the extension of a given predicate\n(“flight-between,” in this case). Moreover, on pain of\ninconsistencies, such a minimization needs to take place not with\nrespect to what the database explicitly contains but with respect to\nwhat it implies.  \nThe idea of minimization is at the basis of one of the earliest\nnon-monotonic formalisms, McCarthy’s circumscription\n (McCarthy 1980).\n Circumscription makes explicit the intuition that, all other things\nbeing equal, extensions of certain predicates should be\nminimal. Consider principles such as “all normal birds\nfly”. Implicit in this principle is the idea that specimens\nshould not be considered to be abnormal unless there is positive\ninformation to that effect. McCarthy’s idea was to represent this\nformally, using second-order logic (SOL). In SOL, in contrast to\nfirst-order logic (FOL), one is allowed to explicitly quantify over\npredicates, forming sentences such as \\(\\exists P \\forall x Px\\)\n(“there is a universal predicate”) or \\(\\forall P (Pa\n\\equiv Pb)\\) (“a and b are indiscernible”).\n \nIn circumscription, given predicates P and Q, we\nabbreviate \\(\\forall x(Px \\supset Qx)\\) as \\(P \\le Q\\); similarly, we\nabbreviate \\(P \\le Q \\wedge \\neg(Q \\le P)\\) as \\(P < Q\\). If\n\\(A(P)\\) is a formula containing occurrences of a predicate P,\nthen the circumscription of P in A is the second-order\nsentence \\(A^{\\star}(P)\\):  \n\\(A(P) \\wedge \\neg\\exists Q[A(Q) \\wedge Q < P]\\)  \n\\(A^{\\star}(P)\\) expresses that P satisfies A, and that\nno smaller predicate does. Let \\(Px\\) be the predicate “x\nis abnormal,” and let \\(A(P)\\) be the sentence “All birds\nthat are not abnormal fly.” Then the sentence “Tweety is a\nbird,” together with \\(A^{\\star}(P)\\) implies “Tweety\nflies,” for the circumscription axiom forces the extension of\nP to be empty, so that “Tweety is normal” is\nautomatically true.  \nIn terms of consequence relations, circumscription allows us to\ndefine, for each predicate P, a non-monotonic relation \\(A(P)\n\\nc \\phi\\) that holds precisely when \\(A^{\\star}(P) \\vDash \\phi\\).\n(This basic form of circumscription has been generalized, for, in\npractice, one needs to minimize the extension of a predicate, while\nallowing the extension of certain other predicates to vary.) From the\npoint of view of applications, however, circumscription has a major\ncomputational shortcoming, which is due to the nature of the\nsecond-order language in which circumscription is formulated (see the\nentry on\n Second-order and Higher-order Logic\n for details). The problem is that SOL, contrary to FOL, lacks a\ncomplete inference procedure: the price one pays for the greater\nexpressive power of SOL is that there are no complete axiomatizations,\nas we have for FOL. It follows that there is no way to list, in an\neffective manner, all SOL validities, and hence to determine whether\n\\(A(P) \\nc \\phi\\).  \nAnother influential mechanism realizing the closed world assumption is\nNegation as Failure\n \n (or Default Negation). It can nicely be explained if we take a\nlook at Logic Programming. A logic program consists of a list\nof rules such as:  \n\\(\\tau ~~ \\leftarrow ~~ \\phi_1, \\dotsc, \\phi_n, \\mathit{not}~ \\psi_1,\n\\dotsc, \\mathit{not}~ \\psi_m\\)  \nIn basic logic programs \\(\\tau\\) is a logical atom and \\(\\phi_1,\n\\dotsc, \\phi_n, \\psi_1, \\dotsc, \\psi_m\\) are logical literals (i.e.,\natoms or negated atoms). The logical form or rules in such programs\nhave been generalized in various ways (e.g.,\n Alferes et al. 1995)\n and many ways of interpreting rules have been proposed. To understand\nthe meaning of the default negation not we consider a concrete\nexample for a rule, namely:  \nflies \\(~~\\leftarrow~~\\) bird, not penguin\n \nSuch rules read as expected, but with a small twist. As usual, the\nrule licenses its conclusion if the formulas in the antecedent (right\nhand side) hold. The twist is that the falsity of (default) negated\nformulas such as penguin need not be positively established:\ntheir falsity is assumed in the absence of a proof of the opposite. In\nour example, if penguin cannot be proved then not\npenguin is considered to hold (“by default”). A logic program for\nour Tweety example may consist of the rule above and  \nnot-flies \\(~~\\leftarrow~~\\) penguin\nbird \\(~~\\leftarrow~~\\) penguin  \nSuppose first all we know is bird. The latter two rules will\nnot be triggered. The first rule will be applicable:  bird  is\nthe case and we have no proof of penguin whence not\npenguin is assumed. This allows us to infer flies. Now\nsuppose we know penguin. In this case the first rule is not\napplicable since the default negation of penguin is false, but\nthe latter two rules are triggered and we derive bird and\nnot-flies.  \nWhenever we have a taxonomically organized body of knowledge, we\npresuppose that subclasses inherit properties from their superclasses:\ndogs have lungs because they are mammals, and mammals have lungs.\nHowever, there can be exceptions, which can interact in complex ways\nas in the following example: mammals, by and large, don’t fly; since\nbats are mammals, in the absence of any information to the contrary,\nwe are justified in inferring that bats do not fly. But if we learn\nthat bats are exceptional mammals, in that they do fly, the conclusion\nthat they don’t fly is retracted, and the conclusion that they fly is\ndrawn instead. Things can be more complicated still, for in turn, baby\nbats are exceptional bats, in that they do not fly (does that make\nthem unexceptional mammals?). Here we have potentially conflicting\ninferences. When we infer that Stellaluna, being a baby bat, does not\nfly, we are resolving all these potential conflicts based on the\nSpecificity Principle.  \nNon-monotonic inheritance networks were developed for the\npurpose of capturing taxonomic examples such as the one above. Such\nnetworks are collections of nodes and directed\n(“is-a”) links representing taxonomic information.\nWhen exceptions are allowed, the network is interpreted\ndefeasibly. The following figure gives a network representing\nthis state of affair:  \nIn such a network, links of the form \\(A \\rightarrow B\\) represent the\nfact that, typically and for the most part, As are Bs,\nand that therefore information about As is more specific than\ninformation about Bs. More specific information overrides more\ngeneric information. Research on non-monotonic inheritance focuses on\nthe different ways in which one can make this idea precise.  \nThe main issue in defeasible inheritance is to characterize the set of\nassertions that are supported by a given network. It is of course not\nenough to devise a representational formalism, one also needs to\nspecify how the formalism is to be interpreted. Such a\ncharacterization is accomplished through the notion of an\nextension of a given network. There are two competing\ncharacterizations of extension for this kind of networks, one that\nfollows the credulous strategy and one that follows the skeptical one.\nBoth proceed by first defining the degree of a path through the\nnetwork as the length of the longest sequence of links connecting its\nendpoints; extensions are then constructed by considering paths in\nascending order of their degrees. We are not going to review the\ndetails, since many of the same issues arise in connection with\n Default Logic\n (which is discussed below), but\n Horty (1994)\n provides an extensive survey. It is worth mentioning that since the\nnotion of degree makes sense only in the case of acyclic networks,\nspecial issues arise when networks contain cycles (see\n Antonelli (1997)\n for a treatment of inheritance on cyclic networks).  \nAlthough the language of non-monotonic networks is expressively\nlimited by design (in that only links of the form\n“is-a” — and their negations — can be\nrepresented in a natural fashion), such networks provide an extremely\nuseful setting in which to test and hone one’s intuitions and methods\nfor handling defeasible information. Such intuitions and methods are\nthen applied to more expressive formalisms.  \nIn argument-based approaches to defeasible reasoning the notion\nof a path through an inheritance network is generalized to the notion\nof an argument. Abstracting from the specifics and subtleties of\nformalisms proposed in the\n literature[3],\n an argument can be thought of in the following way. Given a\nlanguage \\(\\mathcal{L}\\), a set of \\(\\mathcal{L}\\)-formulas\n\\(\\Gamma\\), a set of strict rules SRules of the form \\(\\phi_1,\n\\dotsc, \\phi_n \\Rightarrow \\psi\\) (where \\(\\phi_i\\) and \\(\\psi\\) are\n\\(\\mathcal{L}\\)-formulas) and a set of defeasible rules DRules\nof the form \\(\\phi_1, \\dotsc, \\phi_n \\rightarrow \\psi\\) (where\n\\(\\phi_i\\) and \\(\\psi\\) are \\(\\mathcal{L}\\)-formulas) an\nargument \\((\\Theta, \\theta)\\) for \\(\\tau\\) is a proof of\n\\(\\tau\\) from some \\(\\Theta \\subseteq \\Gamma\\) using the rules in\nSRules and DRules.  \nA central notion in argument-based formalism is argumentative\nattack. We can, for instance, distinguish between rebuts and\nundercuts. A rebut of an argument \\((\\Theta, \\tau)\\) is an\nargument that establishes that \\(\\tau\\) is not the case, viz. an\nargument for \\(\\neg\\tau\\). An undercut of \\((\\Theta, \\tau)\\)\nestablishes that \\(\\Theta\\) does not support \\(\\tau\\). For instance,\nthe argument that concludes that an object is red from the fact that\nit looks red, is undercut by means of the observation that that object\nis illuminated by red light\n (Pollock 1995).\n Note that in order to undercut an argument for \\(\\tau\\) one need not\nestablish that \\(\\tau\\) doesn’t hold.  \nOn an intuitive level, the basic idea is that the question whether an\nargument is acceptable concerns the question whether it is\ndefended from its argumentative attacks.\n Dung (1995)\n proposed a way to address this question purely on the basis of the\nattack relations between arguments while abstracting from the concrete\nstructure of the given arguments. Where Args is the set of the\narguments that are generated from \\(\\Gamma\\) by the rules in\nSRules and DRules, we define an attack relation\n\\({\\leadsto} \\subseteq \\mathit{Args} \\times \\mathit{Args}\\) as\nfollows: \\(a \\leadsto b\\) if and only if \\(a\\) attacks (e.g., rebuts\nor undercuts) \\(b\\). This gives rise to a directed graph, the\nabstract argumentation framework, where arguments are nodes and\narrows represent the attack relation. Note that at the level of the\ndirected graph arguments are treated in an abstract way: the concrete\nstructure of the arguments is not presented in the graph.  \nVarious argumentation semantics have been proposed for such\ngraphs specifying criteria for selecting sets of arguments that\nrepresent stances of rational agents. Clearly, a selected set of\narguments \\(S \\subseteq \\mathit{Args}\\) should satisfy the following\nrequirements:  \nFor instance, given the following graph,  \n\\(\\{a\\}\\) is admissible, while \\(\\{a,b\\}\\) is not conflict-free and\n\\(\\{d\\}\\) is not admissible.  \nGiven these basic requirements we can define, for instance, the\nfollowing semantics which frequently appears in the literature:  \nIn our example \\(\\{a,d\\}\\) and \\(\\{b,d\\}\\) are the two preferred sets.\nThis shows that the preferred semantics does not determine a unique\nselection. In order to define a consequence relation we can proceed\neither according to the credulous rationale or according to the\nskeptical rationale. Considering an abstract argumentation framework\nbased on \\(\\Gamma\\), SRules, and DRules, we give two\nexamples of how a consequence set can be characterized by means of the\nskeptical approach\n (Prakken 2010):\n  \nClearly, the second approach is more cautious. Intuitively, it demands\nthat there is a specific argument for τ that is contained in each\nrational stance a reasoner can take given \\(\\Gamma\\), DRules,\nand SRules. The first option doesn’t bind the acceptability of\n\\(\\tau\\) to a specific argument: it is sufficient if according to each\nrational stance there is some argument for \\(\\tau\\).  \nIn Default Logic, the main representational tool is that of a\ndefault rule, or simply a default. A default is a\ndefeasible inference rule of the form  \n\\((\\gamma: \\theta) / \\tau\\)  \nwhere \\(\\gamma, \\theta\\), and \\(\\tau\\) are sentences in a given\nlanguage, respectively called the pre-requisite, the\njustification and the conclusion of the default. The\ninterpretation of the default is that if \\(\\gamma\\) is known, and\nthere is no evidence that \\(\\theta\\) is false, then \\(\\tau\\) can be\ninferred.  \nAs is clear, an application of the rule requires that a consistency\ncondition be satisfied. What makes meeting the condition complicated\nis the fact that rules can interact in complex ways. In particular, it\nis possible that an application of some rule might cause the\nconsistency condition to fail for some, not necessarily distinct,\nrule. For instance, if \\(\\theta\\) is \\(\\neg\\tau\\) then an application\nof the rule is in a sense self-defeating, in that an application of\nthe rule itself causes the consistency condition to fail.  \nReiter’s default logic\n (Reiter 1980)\n uses the notion of an extension to make precise the idea that\nthe consistency condition has to be met both before and after the rule\nis applied. Given a set \\(\\Delta\\) of defaults, an extension for\n\\(\\Delta\\) represents a set of inferences that can be drawn\nreasonably and consistently using defaults from\n\\(\\Delta\\). Such inferences are those that are warranted on the basis\nof a maximal set of defaults whose consistency condition is met both\nbefore and after their being triggered.  \nMore in particular, an extension is defined relative to a default\ntheory. The latter is a pair \\((\\Gamma, \\Delta)\\), where\n\\(\\Delta\\) is a (finite) set of defaults, and \\(\\Gamma\\) is a set of\nsentences (a world description). The idea is that \\(\\Gamma\\)\nrepresents the strict or background information, whereas \\(\\Delta\\)\nspecifies the defeasible information. We say that \\(\\Xi\\) is an\nextension for a default theory \\((\\Gamma, \\Delta)\\) if and only\nif  \n\\(\\Xi = \\Xi_0 \\cup \\Xi_1 \\cup \\ldots \\cup \\Xi_n \\cup \\ldots\\)  \nwhere \\(\\Xi_0 = \\Gamma\\), and  \n\\(\\Xi_{i+1} = \\mathrm{Cn}(\\Xi_i) \\cup \\bigl\\{\\tau \\mid (\\gamma :\n\\theta) / \\tau \\in \\Delta \\text{ where } \\neg\\theta \\notin \\Xi \\text{\nand } \\gamma \\in \\Xi_i \\bigr\\}\\)  \nwhere \\(\\mathrm{Cn}(\\cdot)\\) is the consequence relation of CL. It is\nimportant to notice the occurrence of the limit \\(\\Xi\\) in the\ndefinition of \\(\\Xi_{i+1}\\): the condition above is not a\ngarden-variety recursive definition, but a truly circular\ncharacterization of extensions.  \nThis circularity can be made explicit by giving an equivalent\ndefinition of extension as solution of fixpoint equations. Given a\ndefault theory \\((\\Gamma, \\Delta)\\), let \\(\\mathsf{S}\\) be an operator\ndefined on sets of sentences such that for any such set \\(\\Phi\\),\n\\(\\mathsf{S}(\\Phi)\\) is the smallest set that satisfies the following\nthree requirements:  \nThen one can show that \\(\\Xi\\) is an extension for \\((\\Gamma,\\Delta)\\)\nif and only if \\(\\Theta\\) is a fixed point of \\(\\mathsf{S}\\), i.e., if\n\\(\\mathsf{S}(\\Xi) = \\Xi\\).  \nNeither one of the two characterizations of extension for default\nlogic (i.e., the fixpoint definition and the pseudo-iterative one)\nprovides us with a way to “construct” extensions by means\nof anything resembling an iterative process. Essentially, one has to\n“guess” a set of sentences \\(\\Xi\\), and then verify that\nit satisfies the definition of an extension.  \nFor any given default theory, extensions need not exist, and even when\nthey exist, they need not be unique. We start with an example of the\nformer situation: let \\(\\Gamma = \\emptyset\\) and let \\(\\Delta\\)\ncomprise the single\n default[4] \n\\((\\top : \\theta) / \\neg \\theta\\)  \nIf \\(\\Xi\\) were an extension, then the justification \\(\\theta\\) of the\ndefault above would either be consistent with \\(\\Xi\\) or not, and\neither case is impossible. For if \\(\\theta\\) were consistent with\n\\(\\Xi\\), then the default would be applied to derive \\(\\neg\\theta\\) in\ncontradiction the the consistency of \\(\\Xi\\) with \\(\\theta\\).\nSimilarly, if \\(\\Xi\\) were inconsistent with \\(\\theta\\) then \\(\\Xi\n\\vDash \\neg \\theta\\) and hence, by deductive closure, \\(\\neg\\theta \\in\n\\Theta\\). Our default would not be applicable, in which case \\(\\Xi =\n\\Xi_1 = \\mathrm{Cn}(\\emptyset)\\). But then \\(\\neg\\theta \\notin\n\\Xi\\),—a contradiction.  \nFor normal default theories that only consist of normal\ndefaults, i.e., defaults of the form \\((\\gamma : \\theta) /\n\\theta\\), extensions always exist.  \n\n Lukaszewicz (1988)\n presents a modified definition of extension that avoids the previous\ntwo problems: it is defined in an iterative way and it warrants the\nexistence of an extension. In a nutshell the idea is to keep track of\nthe used justifications in the procedure. A default is applied in case\nits precondition is implied by the current beliefs and its conclusion\nis consistent with the given beliefs, its own justificiation, and each\nof the justifications of previously applied defaults. For normal\ntheories Lukaszewicz’s definition of extensions is equivalent to the\ndefinitions from above.  \nLet us now consider an example of a default theory with multiple\nextensions. Let \\(\\Gamma = \\emptyset\\), and suppose \\(\\Delta\\)\ncomprises the following two defaults  \n\\((\\top : \\theta) / \\neg\\tau\\) and \\((\\top: \\tau)/\\neg\\theta\\)  \nThis theory has exactly two extensions, one in which the first default\nis applied and one in which the second one is. It is easy to see that\nat least one default has to be applied in any extension, and that both\ndefaults cannot be applied in the same extension.  \nThe fact that default theories can have zero, one, or multiple\nextensions raises the issue of what inferences one is warranted in\ndrawing from a given default theory. The problem can be presented as\nfollows: given a default theory \\((\\Gamma, \\Delta)\\), what sentences\ncan be regarded as defeasible consequences of the theory?  \nSometimes it may be useful to map out all the consequences that can be\ndrawn from all the extensions, for instance, in order to\nidentify extensions that give rise to undesired consequences (in view\nof extralogical considerations). The credulous approach does just\nthat: \\((\\Gamma, \\Delta) \\nc \\phi\\) if and only if \\(\\phi\\) belongs to\nany extension of the theory. Clearly, in case of multiple\nextensions the consequence set will not be closed under CL and it may\nbe inconsistent.  \nAlternatively, one can adopt the skeptical strategy according to which\n\\((\\Gamma, \\Delta) \\nc \\phi\\) if and only if \\(\\phi\\) is contained in\nevery extension of \\((\\Gamma, \\Delta)\\).  \nSkeptical consequence, as based on Reiter’s notion of extension, fails\nto be cautiously monotonic\n (Makinson 1994).\n To see this, consider the default theory \\((\\emptyset, \\Delta)\\),\nwhere \\(\\Delta\\) comprises the following two defaults:  \n\\((\\top: \\theta)/\\theta\\) and \\((\\theta \\vee \\gamma : \\neg \\theta) /\n\\neg \\theta\\)  \nThis theory has only one extension, coinciding with the deductive\nclosure of \\(\\{\\theta\\}\\). Hence, according to skeptical consequence\nwe have \\((\\emptyset, \\Delta) \\nc \\theta\\), as well as \\((\\emptyset,\n\\Delta) \\nc \\theta \\vee \\gamma\\) (by the deductive closure of\nextensions).  \nNow consider the theory \\((\\{\\theta \\vee \\gamma\\}, \\Delta)\\). We have\ntwo extensions: one the same as before, but also another one\ncoinciding with the deductive closure of \\(\\{\\neg\\theta\\}\\), and hence\nnot containing \\(\\theta\\). It follows that the intersection of the\nextensions no longer contains \\(\\theta\\), so that \\((\\{\\theta \\vee\n\\gamma\\}, \\Delta) \\nc \\theta\\) fails, against Cautious\nMonotony. (Notice that the same example establishes a counter-example\nfor Cut for the credulous strategy, when we pick the extension of\n\\((\\{\\theta \\vee \\gamma\\}, \\Delta)\\) that contains \\(\\neg\\theta\\).)\n \nIn\n Antonelli (1999)\n a notion of general extension for default logic is introduced,\nshowing that this notion yields a well-behaved relation of defeasible\nconsequence \\(\\nc\\) that satisfies Supraclassicality (if \\(\\Gamma\n\\vDash \\phi\\) then \\(\\Gamma \\nc \\phi\\)) and the three central\nrequirements for NMLs Reflexivity, Cut, and Cautious Monotony from\n Gabbay (1985).\n The idea behind general extensions can be explained in a particularly\nsimple way in the case of pre-requisite free default theories\n(called “categorical” in Antonelli (1999)). A\ngeneral extension for such a default theory is a pair\n\\((\\Gamma^+, \\Gamma^-)\\) of sets of defaults (or conclusions thereof)\nthat simultaneously satisfies two fixpoint equations. The set\n\\(\\Gamma^+\\) comprises (conclusions of) defaults that are explicitly\ntriggered, and the set \\(\\Gamma^-\\) comprises (conclusions of)\ndefaults that are explicitly ruled out. The intuition is that defaults\nthat are not ruled out can still prevent other defaults from being\ntriggered (although they might not be triggered themselves). We thus\nobtain a “3-valued” approach (not unlike that of Kripke’s\ntheory of truth\n (Kripke 1975)),\n in virtue of which general extensions are now endowed with a\nnon-trivial (i.e., not “flat”) algebraic structure. It is\nthen possible to pick out, in a principled way, a particular general\nextension (for instance, the unique least one, which is always\nguaranteed to exist) on which to base a notion of defeasible\nconsequence.  \nA different set of issues arises in connection with the behavior of\ndefault logic from the point of view of computation. For a given\nsemi-decidable set \\(\\Phi\\) of sentences, the set of all \\(\\phi\\) that\nare a consequence of \\(\\Phi\\) in FOL is itself semi-decidable (see the\nentry on\n computability and complexity).\n In the case of default logic, to formulate the corresponding problem\none extends (in the obvious way) the notion of (semi-)decidability to\nsets of defaults. The problem, then, is to decide, given a default\ntheory \\((\\Gamma,\\Delta)\\) and a sentence φ whether\n\\((\\Gamma,\\Delta) \\nc \\phi\\), where \\(\\nc\\) is defined, say,\nskeptically. Such a problem is not even semi-decidable, since, in\norder to determine whether a default is triggered by a pair of sets of\nsentences, one has to perform a consistency check, and such checks are\nnot computable.  \nDefault logic as defined above does not prioritize among defaults. In\n Poole (1985)\n we find an approach in which the Specificity Principle is considered.\nIn\n Horty (2007)\n defaults are ordered by a strict partial order \\(\\prec\\) where\n\\((\\gamma : \\theta)/\\tau \\prec (\\gamma' : \\theta') / \\tau'\\) means\nthat \\((\\gamma' : \\theta') / \\tau'\\) has priority over \\((\\gamma :\n\\theta) / \\tau\\). The ordering \\(\\prec\\) may express —depending\non the application— specificity relations, the comparative\nreliability of the conditional knowledge expressed by defaults, etc.\nAn ordered default theory is then a triple \\((\\Gamma, \\Delta,\n\\prec)\\) where \\((\\Gamma, \\Delta)\\) is a default theory. We give an\nexample but omit a more technical explanation. Take \\(\\Gamma\\) =\n{bird, penguin}, \\(\\Delta\\) = {bird\n\\(\\rightarrow\\) flies, penguin \\(\\rightarrow\\)\n¬flies} and bird \\(\\rightarrow\\) flies\n\\(\\prec\\) penguin \\(\\rightarrow\\) ¬flies, where\n\\(\\phi \\rightarrow \\psi\\) represents the normal default \\((\\phi: \\psi)\n/ \\psi\\). We have two extensions of \\((\\Gamma,\\Delta)\\), one in which\nbird \\(\\rightarrow\\) flies is applied and one in which\npenguin \\(\\rightarrow\\) ¬flies is applied. Since the\nlatter default is \\(\\prec\\)-preferred over the former, only the latter\nextension is an extension of \\((\\Gamma,\\Delta,\\prec)\\).  \nAnother formalism closely related to default logic is Moore’s\nAutoepistemic Logic\n (Moore 1985).\n It models the reasoning of an ideal agent reflecting on her own\nbeliefs. For instance, sometimes the absence of a belief in \\(\\phi\\)\nmay give an agent a reason to infer \\(\\neg\\phi\\). Moore gives the\nfollowing example: If I had an older brother, I would know about it.\nSince I don’t, I believe not to have an older brother.  \nAn autoepistemic theory consists of the beliefs of an agent including\nher reflective beliefs about her beliefs. For the latter an\nautoepistemic belief operator \\(\\mathsf{B}\\) is used. In our example\nsuch a theory may contain \\(\\neg \\mathsf{B} \\mathit{brother} \\supset\n\\neg \\mathit{brother}\\). Autoepistemic logic specifies ideal\nproperties of such theories. Following\n Stalnaker (1993),\n an autoepistemic theory \\(\\Gamma\\) should be stable:  \nIf \\(\\Gamma\\) is consistent, stability implies that  \nLet us, for instance, consider the two types of consistent stable sets\nthat extend \\(\\Xi_1 = \\{ \\neg \\mathsf{B} \\mathit{brother} \\supset \\neg\n\\mathit{brother} \\}\\):  \nThe second option seems more intuitive since given only \\(\\neg\n\\mathsf{B} \\mathit{brother} \\supset \\neg \\mathit{brother}\\) the belief\nin \\(\\mathit{brother}\\) seems intuitively speaking ungrounded in the\ncontext of \\(\\Xi_1\\). To make this formally precise, Moore defines\n \nStable theories that are grounded in a set of assumptions \\(\\Xi\\) are\ncalled stable expansions of \\(\\Xi\\) or autoepistemic\nextensions of \\(\\Xi\\). Stable expansions \\(\\Gamma\\) of \\(\\Xi\\) can\nequivalently be characterized as fixed points:  \n\\(\\Gamma = \\mathrm{Cn}\\bigl( \\Xi \\cup \\{ \\mathsf{B}\\phi \\mid \\phi \\in\n\\Gamma\\} \\cup \\{\\neg \\mathsf{B} \\phi \\mid \\phi \\notin \\Gamma\\}\\bigr)\\)\n \nwhere \\(\\mathrm{Cn}(\\cdot)\\) is the consequence function of CL.  \nClearly, there is no stable theory that is grounded in \\(\\Xi_1\\) and\nthat contains \\(\\mathit{brother}\\) and/or \\(\\mathsf{B}\n\\mathit{brother}\\) like our \\(\\Gamma_1\\) above. The reason is that we\nfail to derive \\(\\mathit{brother}\\) from \\(\\Xi_1 \\cup \\{\\mathsf{B}\n\\psi \\mid \\psi \\in \\Gamma_1\\} \\cup \\{\\neg \\mathsf{B} \\psi \\mid \\psi\n\\notin \\Gamma_1\\}\\). The only stable extension of \\(\\Xi_1\\) contains\n\\(\\neg \\mathsf{B} \\mathit{brother}\\) and \\(\\neg \\mathit{brother}\\).\n \nJust as in default logic, some sets of assumptions have no stable\nextensions while some have multiple stable extensions. We demonstrate\nthe former case with \\(\\Xi_2 = \\{\\neg \\mathsf{B} \\phi \\supset\n\\phi\\}\\). Suppose there is a stable extension \\(\\Gamma\\) of \\(\\Xi_2\\).\nFirst note that there is no way to ground \\(\\phi\\) in view of\n\\(\\Xi_2\\). Hence \\(\\phi \\notin \\Gamma\\) which means that \\(\\neg\n\\mathsf{B} \\phi \\in \\Gamma\\). But then \\(\\phi \\in \\Gamma\\) by modus\nponens which is a contradiction.  \nA potentially problematic property of Moore’s notion of groundedness\nis that it allows for a type of epistemic bootstrapping. Take \\(\\Xi_3\n= \\{\\mathsf{B}\\phi \\supset \\phi\\}\\). Suppose an agent adopts the\nbelief that she believes \\(\\phi\\), i.e. \\(\\mathsf{B}\\phi\\). Now she\ncan use \\(\\mathsf{B}\\phi \\supset \\phi\\) to derive \\(\\phi\\). Hence, on\nthe basis of \\(\\Xi_3\\) she can ground her belief in \\(\\phi\\) on her\nbelief that she believes \\(\\phi\\). Indeed, there is a stable extension\nof \\(\\Xi_3\\) containing \\(\\phi\\) and \\(\\mathsf{B} \\phi\\). In view of\nthis, weaker forms of groundedness have been proposed in\n Konolige (1988)\n that do not allow for this form of bootstrapping and according to\nwhich we only have the extension of \\(\\Xi_3\\) that contains neither\n\\(\\phi\\) nor \\(\\mathsf{B}\\phi\\).  \nThe centrality of autoepistemic logic in NML is emphasized by the fact\nthat several tight links to other seminal formalism have been\nestablished. Let us mention three such links.  \nFirst, there are close connections between autoepistemic logic and\nlogic programming. For instance, Gelfond’s and Lifschitz’s stable\nmodel semantics for logic programming with\n negation as failure\n which serves as the foundation for the answer set programming\nparadigm in computer science has been equivalently expressed by means\nof autoepistemic logic\n (Gelfond and Lifschitz 1988).\n The result is achieved by translating clauses in logic programming\n \n\\(\\phi ~~ \\leftarrow ~~ \\phi_1, \\dotsc, \\phi_n, \\mathit{not}~\\psi_1,\n\\dotsc, \\mathit{not}~\\psi_m\\)  \nin such a way that negation as failure (\\(\\mathit{not}~\\psi\\)) gets\nthe meaning “it is not believed that \\(\\psi\\)” (\\(\\neg\n\\mathsf{B}\\psi\\)):  \n\\((\\phi_1 \\wedge \\ldots \\wedge \\phi_{n} \\wedge \\neg \\mathsf{B} \\psi_1\n\\wedge \\ldots \\wedge \\neg \\mathsf{B} \\psi_m) \\supset \\psi\\)  \nA second link has been established in\n Konolige (1988)\n with default logic which has been shown inter-translatable and\nequi-expressive with Konolige’s strongly grounded variant of\nautoepistemic logic. Default rules \\((\\gamma : \\theta) / \\tau\\) are\ntranslated by interpreting consistency conditions \\(\\theta\\) by \\(\\neg\n\\mathsf{B} \\neg \\theta\\) which can be read as “\\(\\theta\\) is\nconsistent with the given beliefs”:  \n\\((\\mathsf{B} \\gamma \\wedge \\neg \\mathsf{B} \\neg \\theta) \\supset\n\\tau\\)  \nEspecially the latter link is rather remarkable since the subject\nmatter of the given formalisms is quite different. While default logic\ndeals with defeasible rules, i.e., rules that allow for exceptions\n(such as ‘Birds fly’), the non-monotonicity of autoepistemic logic is\nrooted in the indexicality of its autoepistemic belief operator\n (Moore 1984,\n Konolige 1988): it refers to the \nautoepistemic theory into which it is\nembeded and hence its meaning may change when we add beliefs to the\ntheory.  \nVarious modal semantics have been proposed for autoepistemic logic\n(see the entry on\n modal logic\n for more background on modal logics). For instance,\n Moore (1984)\n proposes an S5-based Kripkean possible world semantics and\n Lin and Shoham (1990)\n propose bi-modal preferential semantics (see Section\n Selection semantics\n below) for both autoepistemic logic and default logic. In\n Konolige (1988)\n it has been observed that the fixed point characterization of stable\nexpansions can be alternatively phrased only on the basis of the set\nof formulas \\(\\Gamma_0\\) in \\(\\Gamma\\) that do not contain occurrences\nof the modal operator \\(\\mathsf{B}\\):  \n\\( \\Gamma = \\mathrm{Cn}_{\\mathsf{K45}}\\bigl( \\Xi \\cup \\{\n\\mathsf{B}\\phi \\mid \\phi \\in \\Gamma_0\\} \\cup \\{\\neg \\mathsf{B}\\phi\n\\mid \\phi \\notin \\Gamma_0\\}\\bigr)\\)  \nwhere \\(\\mathrm{Cn}_{\\mathsf{K45}}(\\cdot)\\) is the consequence\nfunction of the modal logic \\(\\mathsf{K45}\\).  \nIn CL a formula \\(\\phi\\) is entailed by \\(\\Gamma\\) (in signs \\(\\Gamma\n\\vDash \\phi\\)) if and only if \\(\\phi\\) is valid in all classical\nmodels of \\(\\Gamma\\). An influential idea in NML is to define\nnon-monotonic entailment not in terms of all classical models\nof \\(\\Gamma\\), but rather in terms of a selection of these\nmodels\n (Shoham 1987).\n Intuitively the idea is to read  \n\\(\\Gamma \\nc \\phi\\) as “\\(\\phi\\) holds in the most\nnormal/natural/etc. models of \\(\\Gamma\\).”  \nIn the seminal paper\n Kraus et al. (1990)\n this idea is investigated systematically. The authors introduce\nvarious semantic structures, among them preferential ones. A\npreferential structure \\(S\\) consists of  \nIn the context of preferential structures one may think of states in\nterms of labelled models \\(M_s\\) of classical propositional logic,\nwhere each label \\(s\\) is attached to a unique model \\(M\\) but a model\nmay occur under various labels in\n \\(\\Omega\\).[5]\n For the ease of demonstration we will henceforth just talk about\n‘models in \\(\\Omega\\)’ and not anymore refer to states or labelled\nmodels.  \nIntuitively, \\(M \\prec M'\\) if \\(M\\) is more normal than \\(M'\\). The\nrelation \\(\\prec\\) can be employed to formally realize the idea of\ndefining a consequence relation in view of the most normal models,\nnamely by focusing on \\(\\prec\\)-minimal models. Formally, where\n\\([\\psi]\\) is the set of all models of \\(\\psi\\) in \\(\\Omega\\),\n\\(\\nc^S\\), is defined as follows:  \n\\(\\psi \\nc^S \\phi\\) if and only if \\(\\phi\\) holds in all\n\\(\\prec\\)-minimal models in \\([\\psi]\\).  \nIn order to warrant that there are such minimal states, \\(\\prec\\) is\nconsidered to be smooth (also sometimes called\nstuttered), i.e., for each \\(M\\) either \\(M\\) is\n\\(\\prec\\)-minimal or there is a \\(\\prec\\)-minimal \\(M'\\) such that\n\\(M' \\prec M\\).  \nPreferential structures enjoy a central role in NML since they\ncharacterize preferential consequence relations, i.e.,\nnon-monotonic consequence relations \\(\\nc\\) that fulfill the following\ncentral properties, also referred to as the core properties or\nthe conservative core of non-monotonic reasoning systems or as\nthe KLM-properties (in reference to the authors of\n Kraus, Lehmann, Magidor 1990):\n  \nThe former three properties we have already seen above. According to\nLeft Logical Equivalence, classically equivalent formulas have the\nsame non-monotonic consequences. Where \\(\\psi\\) is classically\nentailed by \\(\\phi\\), Right Weakening expresses that whenever \\(\\phi\\)\nis a non-monotonic consequence of \\(\\tau\\) then so is \\(\\psi\\).  \nWithout further commentary we state two important derived rules:  \nIn\n Kraus et al. (1990)\n it is shown that a consequence relation \\(\\nc\\) is preferential if\nand only if \\(\\nc = \\nc^S\\) for some preferential structure \\(S\\).\n \nGiven a set of conditional assertions \\(\\mathbf{K}\\) of the type\n\\(\\phi \\nc \\psi\\) one may be interested in investigating what other\nconditional assertions follow. The following two strategems lead to\nthe same results. The first option is to intersect all preferential\nconsequence relations \\(\\nc\\) that extend \\(\\mathbf{K}\\) (in the sense\nthat the conditional assertions in \\(\\mathbf{K}\\) hold for \\(\\nc\\))\nobtaining the Preferential Closure \\(\\nc^{\\mathrm{P}}\\) of\n\\(\\mathbf{K}\\). The second option is to use the five defining\nproperties of preferential consequence relations as deduction rules\nfor syntactic units of the form \\(\\phi \\nc \\psi\\). This way we obtain\nthe deductive system P with its consequence relation\n\\(\\vdash^{\\mathrm{P}}\\) for which:  \n\\(\\mathbf{K} \\vdash^{\\mathrm{P}} \\phi \\nc \\psi\\) if and only if \\(\\phi\n\\nc^{\\mathrm{P}} \\psi\\).  \nOne of the most remarkable facts in the study of NMLs is that various\nother semantics have been proposed —often independently and\nbased on very different considerations— that also adequately\ncharacterize preferential consequence relations. This underlines the\ncentral status of the core properties in the formal study of\ndefeasible reasoning.  \nMany of these approaches use structures \\(S = (\\Omega, \\Pi)\\) where\n\\(\\Omega\\) is again a set of classical models and \\(\\Pi\\) is a mapping\nwith the domain \\(\\wp(\\Omega)\\) (the set of subsets of \\(\\Omega\\)) and\nan ordered co-domain \\((D, <)\\). The exact nature of \\((D, <)\\)\ndepends on the given approach and we give some examples below. The\nbasic common idea is to let \\(\\phi \\nc^S \\psi\\) in case \\(\\Pi([\\phi\n\\wedge \\psi])\\) is preferable to \\(\\Pi([\\phi \\wedge \\neg \\psi])\\) in\nview of \\(<\\). The following table lists some proposals which we\ndiscuss some more below:  \nPossibility measures assign real numbers in the interval [0,1] to\npropositions in order to measure their possibility, where 0\ncorresponds to impossible states and 1 to necessary states\n (Dubois and Prade 1990).\n Ordinal ranking functions rank propositions via natural numbers\nclosed with ∞\n (Goldszmidt and Pearl 1992,\n Spohn 1988). One may think of\n \\(\\kappa([\\phi])\\) as the level of\nsurprise we would face were \\(\\phi\\) to hold, where ∞ represents\nmaximal surprise. Finally, plausibility measures\n (Friedman and Halpern 1996,\n Rott 2013) associate propositions with \nelements in a partially\nordered domain with bottom element \\(\\bot\\) and top element \\(\\top\\)\nin order to compare their plausibilities. Given some simple\nconstraints on \\(\\mathrm{Pl}\\) (such as: If \\(\\mathrm{Pl}(X) =\n\\mathrm{Pl}(Y) = \\bot\\) then \\(\\mathrm{Pl}(X \\cup Y) = \\bot\\)) we\nspeak of qualitative plausibility structures. The following\nstatements are all equivalent which emphasizes the centrality of the\ncore properties in the study of NMLs:  \nYet another well-known semantics that characterizes preferential\nconsequence relations makes use of conditional probabilities.\nThe idea is that \\(\\phi \\nc \\psi\\) holds in a structure if the\nconditional probability \\(P(\\psi \\mid \\phi)\\) is closer to 1 than an\narbitrary \\(\\epsilon\\), whence the name \\(\\epsilon\\)-semantics\n (Adams 1975,\n Pearl 1989).  \nThe following example demonstrates that the intuitive idea of using a\nthreshold value such as ½ instead of infinitesimals and to\ninterpret \\(\\phi \\nc \\psi\\) as \\(P(\\psi \\mid \\phi)\\) > ½\ndoes not work in a straightforward way. Let \\(\\alpha\\) abbreviate\n“being a vegan”, \\(\\beta\\) abbreviate “being an\nenvironmentalist”, and \\(\\gamma\\) abbreviate “avoiding the\nuse of palm oil”. Further, let our knowledge base comprise the\nstatements “αs are usually βs,”\n“\\((\\alpha \\wedge \\beta)\\)s are usually γs”. The\nfollowing Euler diagram illustrates the conditional probabilities in a\npossible probability distribution for the given statements.  \nWe have for instance: \\(P(\\beta \\mid \\alpha)\\) = ¾, \\(P(\\gamma\n\\mid \\alpha \\wedge \\beta)\\) = ⅔ and \\(P(\\gamma \\mid \\alpha)\\) =\n½. Hence, under the proposed reading of \\(\\nc\\), we get\n\\(\\alpha \\nc \\beta\\) and \\(\\alpha \\wedge \\beta \\nc \\gamma\\) while we\ndo not have \\(\\alpha \\nc \\gamma\\). This means that Cut is violated.\nSimilarly, it can be shown that other properties such as Or are\nviolated under this reading (e.g.,\n Pearl 1988).\n  \nIn view of these difficulties it is remarkable that there is a\nprobabilistic account according to which \\(\\phi \\nc \\psi\\) is\ninterpreted as \\(P(\\psi \\mid \\phi)\\) > ½ and that\nnevertheless characterizes preferential consequence relations\n (Benferhat et al. 1999).\n The idea is to restrict the focus to structures \\(S= (\\Omega, P,\n\\prec)\\) that come with specific probability distributions known as\natomic bound systems or big-stepped probabilities.\nFirst, a linear order \\(\\prec\\) is imposed on the set of classical\nmodels in \\(\\Omega\\) over which the probability measure \\(P\\) is\ndefined. Second, \\(P\\) is required to respect this order by\n“taking big steps”, i.e., in such a way that for any \\(M\n\\in \\Omega\\), \\(P(\\{M\\}) > \\sum\\{P(\\{M'\\}) \\mid M' \\prec M\\}\\).\nThis warrants that \\(\\phi \\nc \\psi\\) holds if and only if the unique\n\\(\\prec\\)-maximal model in \\([\\phi]\\) validates \\(\\psi\\) (in signs,\n\\(\\max[\\phi] \\models\n \\psi\\)).[6]\n Here is how this helps us with the problematic example above:\n\\(\\alpha \\nc \\beta\\) means that \\(\\max[\\alpha] \\models \\beta\\) and\nhence that \\(\\max[\\alpha] = \\max[\\alpha \\wedge \\beta]\\). \\(\\alpha\n\\wedge \\beta \\nc \\gamma\\) means that \\(\\max[\\alpha \\wedge \\beta]\n\\models \\gamma\\) and hence \\(\\max[\\alpha] \\models \\gamma\\) which\nimplies \\(\\alpha \\nc \\gamma\\).  \nIn\n Gilio (2002)\n an approach is presented in which conditionals \\(\\alpha \\nc \\beta\\)\nare characterized by imprecise conditional probabilities \\(0\n\\le \\tau_1 \\le P(\\beta \\mid \\alpha) \\le \\tau_2 \\le 1\\) with a lower\nbound \\(\\tau_1\\) and an upper bound \\(\\tau_2\\) on the conditional\nprobabilities. In this approach it is possible to determine how the\nprobability bounds degrade in view of applications of specific\ninference rules. In\n Ford (2004)\n this is used to distinguish argument strengths (see\n above).\n  \nPreferential consequence relations do not in general validate  \nA preferential consequence relation \\(\\nc\\) that satisfies Rational\nMonotony is called a rational consequence relation. These are\ncharacterized by ranked structures which are preferential\nstructures \\(S = (\\Omega, \\prec)\\) for which \\(\\prec\\) is\nmodular, i.e., for all \\(M, M', M'' \\in \\Omega\\), if \\(M \\prec\nM'\\) then either \\(M'' \\prec M'\\) or \\(M \\prec M''\\). One can picture\nthis as follows: models in \\(\\Omega\\) are arranged in linearly ordered\nlevels and the level of a model reflects its degree of normality (its\nrank).  \nThe seminal\n Kraus et al. (1990)\n inspired a huge variety of subsequent work. We briefly highlight some\ncontributions.  \nWhile in\n Kraus et al. (1990)\n the standard of deduction was classical propositional logic, in\n Arieli and Avron (2000)\n also nonclassical monotonic core logics and variants with multiple\nconclusions are considered. Various publications investigate the\npreferential and rational consequence relations in a first-order\nlanguage (e.g.,\n Lehmann and Magidor 1990,\n Delgrande 1998,\n Friedman et al. 2000).\n  \nAs we have seen, the properties of preferential or rational\nconsequence relations may also serve as deductive rules for syntactic\nunits of the form \\(\\phi \\nc \\psi\\) under the usual readings such as\n“If \\(\\phi\\) then usually \\(\\psi\\).” This approach can be\ngeneralized to gain conditional logics by allowing for formulas\nwhere a conditional assertion \\(\\phi \\nc \\psi\\) is within the scope of\nclassical connectives such as \\(\\wedge, \\vee, \\neg\\), etc. (e.g.,\n Delgrande 1987,\n Asher and Morreau 1991,\n Friedman and Halpern 1996,\n Giordano et al. 2009). We state\n one remarkable result obtained in\n Boutilier (1990)\n that closely links the study of NMLs to the study of modal logics in\nthe Kripkean tradition. Suppose we translate the deduction rules of\nsystem P into Hilbert-style axiom schemes such that, for instance,\nCautious Monotony becomes  \n\\(\\vdash \\bigl( ( \\phi \\nc \\psi) \\wedge (\\phi \\nc \\tau) \\bigr) \\supset\n\\bigl( ( \\phi \\wedge \\psi) \\nc \\tau \\bigr)\\)  \nIt is shown that conditional assertions can be expressed in standard\nKripkean modal frames in such a way that system P (under this\ntranslation) corresponds to a fragment of the well-known modal logic\nS4. An analogous result is obtained for the modal logic S4.3 and the\nsystem that results from strengthening system P with an axiom scheme\nfor Rational Monotony.  \nVarious contributions are specifically devoted to problems related to\nrelevancy. Consider some of the conditional assertions in the Nixon\nDiamond: \\(\\mathbf{K}\\) = {Quaker \\(\\nc\\) Pacifist,\nRepublican \\(\\nc\\) ¬Pacifist}. It seems desirable to\nderive e.g. Quaker \\(\\wedge\\) worker \\(\\nc\\)\nPacifist since in view of \\(\\mathbf{K}\\), being a worker is\nirrelevant to the assertion Quaker \\(\\nc\\)\nPacifist. Intuitively speaking, Quaker \\(\\nc\\)\n¬worker should fail in which case Rational Monotony yields\nQuaker \\(\\wedge\\) worker \\(\\nc\\) Pacifist in view\nof Quaker \\(\\nc\\) Pacifist. Hence, prima facie we may\nwant to proceed as follows: let \\(\\nc^{R}\\) be the result of\nintersecting all rational consequence relations \\(\\nc\\) that extend\n\\(\\mathbf{K}\\) (in the sense that the conditional assertions in\n\\(\\mathbf{K}\\) hold for \\(\\nc\\)). Unfortunately it is not the\ncase that Quaker \\(\\wedge\\) worker \\(\\nc^{R}\\)\nPacifist. The reason is simply that there are rational\nconsequence relations for which Quaker \\(\\nc\\)\n¬worker and whence Rational Monotony does not yield the\ndesired Quaker \\(\\wedge\\) worker \\(\\nc\\)\nPacifist. Moreover, it has been shown that \\(\\nc^R\\) is\nidentical to the preferential closure \\(\\nc^P\\).  \nIn\n Lehmann and Magidor (1992)\n a Rational Closure for conditional knowledge bases such as\n\\(\\mathbf{K}\\) is proposed that yields the desired consequences. We\nomit the technical details. The basic idea is to assign natural\nnumbers, i.e., ranks, to formulas which indicate how exceptional they\nare relative to the given knowledge base \\(\\mathbf{K}\\). Then the\nranks of formulas are minimized which means that each formula is\ninterpreted as normally as possible. A conditional assertion \\(\\phi\n\\nc \\psi\\) is in the Rational Closure of \\(\\mathbf{K}\\) if the rank of\n\\(\\phi \\wedge \\psi\\) is strictly less than the rank of \\(\\phi \\wedge\n\\neg \\psi\\) (or \\(\\phi\\) has no rank). The rank of a formula\n\\(\\alpha\\) is calculated iteratively. Let \\(m(\\mathbf{K}') = \\{ \\phi\n\\supset \\psi \\mid \\phi \\nc \\psi \\in \\mathbf{K}'\\}\\) denote the\nmaterial counterpart of a given set of conditional assertions\n\\(\\mathbf{K}'\\). Let \\(\\mathbf{K}_0 = \\mathbf{K}\\). \\(\\alpha\\) has\nrank 0 if it is consistent with \\(m(\\mathbf{K}_0)\\). Let\n\\(\\mathbf{K}_{i+1}\\) be the set of all members \\(\\phi \\nc \\psi\\) of\n\\(\\mathbf{K}_i\\) for which the rank of \\(\\phi\\) is not less or equal\nto \\(i\\). \\(\\alpha\\) has rank \\(i+1\\) if it doesn’t have a rank\nsmaller or equal to \\(i\\) and it is consistent with\n\\(m(\\mathbf{K}_{i+1})\\).  \nIn our example Quaker \\(\\wedge\\) worker has rank 0, just like\nQuaker. This is stricly less than the rank 1 of Quaker\n\\(\\wedge\\) ¬Pacifist and Quaker \\(\\wedge\\) worker\n\\(\\wedge\\) ¬Pacifist. This means that the desired\nQuaker \\(\\wedge\\) worker \\(\\nc\\) Pacifist is in\nthe Rational Closure of our \\(\\mathbf{K}\\).  \nA system equivalent to Rational Closure has been independently\nproposed under the name system Z based on\n\\(\\epsilon\\)-semantics in\n Pearl (1990).\n  \nOne may consider it a drawback of Rational Closure that it suffers\nfrom the Drowning Problem (see\n above).\n To see this consider the following conditional knowledge base\nKL:  \nWe have the following ranks:  \nSince the ranks of \\(l \\wedge f\\) and \\(l \\wedge \\neg f\\) are equal,\n\\(l\\nc f\\) is not in the rational closure of \\(\\mathbf{KL}\\).  \nThis problem has been tackled in\n Lehmann (1995)\n with the formalism Lexicographic Closure. Rougly the idea is\nto compare models by measuring the severity of violations of\nassertions in the given conditional knowledge base to which they give\nrise. \\(\\phi \\nc \\psi\\) is entailed by \\(\\mathbf{K}\\) if the best\nmodels of \\(\\phi \\wedge \\psi\\) are better than the best models of\n\\(\\phi \\wedge \\neg \\psi\\). A model \\(M\\) violates a conditional\nassertion \\(\\phi \\nc \\psi\\) if it validates \\(\\phi\\) but not \\(\\psi\\).\nThe violation is the more severe the higher the rank of \\(\\phi\\). For\ninstance, in our example we have the following models of \\(l \\wedge\nf\\) resp. of \\(l \\wedge \\neg f\\):  \nThe best model of \\(l \\wedge f\\) is \\(M_3\\) since it doesn’t violate\nany conditional assertion of rank higher than 0, while all other\nmodels of \\(l \\wedge f\\) do. For the same reason \\(M_7\\) is the best\nmodel of \\(l \\wedge \\neg f\\). Moreover, \\(M_3\\) violates less\nconditional assertions of rank 0 than \\(M_7\\) and is thus the\npreferred interpretation. Hence, \\(l \\nc f\\) is in the Lexicographic\nClosure. Altogether, what avoids the drowning problem in Lehmann’s\napproach is a combination between specificity handling and a\nquantitative rationale according to which interpretations are\npreferred that violate less conditionals.  \nTo highlight the latter, consider a knowledge base \\(\\mathbf{K}\\)\nconsisting of  \nWe expect from each, Anne, Phil, and Frank, to come to the party.\nSuppose moreover we know that Party \\(\\wedge\\) ((¬\nAnne \\(\\wedge\\) ¬ Phil) \\(\\vee\\) ¬\nFrank). In view of this fact not all three assertions hold. At\nbest either the former two hold or the latter. If we try to validate\nas many conditional assertions as possible we will prefer the\nsituation in which only the latter is violated. This happens in the\nLexicographic Closure of \\(\\mathbf{K}\\) which contains  \nSimilar quantitative considerations play a role in the Maximum\nEntropy Approach in\n Goldzsmidt et al. (1993)\n which is based on \\(\\epsilon\\)-semantics. The basic idea is similar\nto Lexicographic Closure: \\(\\phi \\nc \\psi\\) is entailed by\n\\(\\mathbf{K}\\) if \\(\\min(\\{\\kappa(M) \\mid M \\models \\phi \\wedge\n\\psi\\}) < \\min (\\{\\kappa(M) \\mid M \\models \\phi \\wedge \\neg\n\\psi\\})\\), where \\(\\kappa(M)\\) outputs a weigthed sum of violations in\n\\(M\\) and where weights are attributed to violations in view of\nspecificity considerations. Similar to Lexicographic Closure the\nviolation of more specific conditionals weigh heavier than violations\nof more general conditionals. As a consequence, just like in\nLexicographic Closure, \\(l \\nc f\\) is entailed in our example and so\nthe drowning problem is avoided. A difference to Lexicographic Closure\nis, for instance, that \\(l \\wedge \\neg f \\nc c\\) is not entailed\naccording to the maximal entropy approach. The reason is that the\nviolation of several less specific assertions may in sum\ncounter-balance the violation of a more specific assertion. For\ninstance, while model \\(M_7\\) is preferred over model \\(M_8\\) in the\nLexicographic approach, in the Maximum Entropy both models turn out to\nbe equally good and the best models of \\(l \\wedge \\neg f\\).  \nIn a family of approaches defeasible inferences are encoded as\nmaterial inferences with explicit assumptions:  \n[†]    \\((\\phi \\wedge \\mathsf{as}) \\supset \\psi\\)\n \nexpresses that \\(\\phi\\) defeasibly implies \\(\\psi\\) on the assumption\nthat \\(\\mathsf{as}\\) holds. Assumptions are interpreted as valid\n“as much as possible”. There are various ways to give a\nmore precise meaning to this.  \nOne such approach is offered by Adaptive Logics\n (Batens 2007,\n Straßer 2014). An adaptive logic AL \nis given by a triple consisting of  \nLLL defines the deductive core of AL in that all LLL-valid inferences\nare also AL-valid. AL strengthens LLL by allowing for defeasible\ninferences by means of the following scheme:  \n[‡]    Where \\(\\mathsf{ab}\\) is an abnormal formula\nin \\(\\Omega\\): if \\(\\phi\\vdash \\psi \\vee \\mathsf{ab}\\) then \\(\\psi\\)\nfollows defeasibly from \\(\\phi\\) on the assumption that\n\\(\\mathsf{ab}\\) is false (or, equivalently, that \\(\\neg \\mathsf{ab}\\)\nis true).  \nWhere \\(\\mathsf{as} = \\neg \\mathsf{ab}\\), the antecedent of [‡]\nis equivalent to \\(\\vdash (\\phi \\wedge \\mathsf{as}) \\supset \\psi\\)\nwhich is [†] above (under the classical meaning of \\(\\neg,\n\\wedge\\), and \\(\\vee\\)).  \nExamples of concrete classes of adaptive logics are:  \nAdaptive logics implement the idea behind [‡] syntactically in\nterms of a dynamic proof theory. A dynamic proof from the\npremise set \\(\\{P(a), \\neg P(b)\\}\\) for an adaptive logic of inductive\ngeneralizations may look as follows:  \nThe last column of each line of the proof contains its condition,\ni.e., a set of abnormalities \\(\\mathrm{COND} \\subseteq \\Omega\\) that\nencodes the assumptions used to derive the formula in the second\ncolumn of the line: each \\(\\mathsf{ab} \\in \\mathrm{COND}\\) is assumed\nto be false. The generic rule RU (rule unconditional) represents any\ninference that is licenced by LLL. The generic rule RC (rule\nconditional) follows scheme [‡] where \\(\\mathsf{ab}\\) is pushed\nto the condition of the line. Sometimes there are good reasons to\nconsider assumptions as violated in which case the corresponding lines\nare ✓-marked as retracted. This is clearly the case if\nthe condition of a line is \\(\\mathrm{COND}\\) while for a\n\\(\\{\\mathsf{ab}_1, \\dotsc, \\mathsf{ab}_n\\} \\subseteq \\mathrm{COND}\\),\n\\(\\mathsf{ab}_1 \\vee \\mathsf{ab}_2 \\vee \\ldots \\vee \\mathsf{ab}_n\\) is\nderived without defeasible steps (i.e., on the condition ∅).\nThis means that (at least) one of the formulas in \\(\\mathrm{COND}\\) is\nfalse. Thus, line 2 is marked as retracted when we reach line 4 of the\nproof. In view of this behavior, dynamic proofs are internally\ndynamic: even if no new premises are introduced, the addition of new\nlines may cause the retraction of previous lines of a proof.  \nNot all cases of retraction are of this straightforward kind. Various\nadaptive strategies come with marking mechanisms to handle more\ncomplicated cases such as the one in the following proof:  \nThe formula \\(\\forall x P(x) \\vee \\forall x Q(x)\\) is derived at line\n4 and 5 on two respective conditions: \\(\\{\\exists x P(x) \\wedge \\neg\n\\forall x P(x)\\}\\) and \\(\\{\\exists x Q(x) \\wedge \\neg \\forall x\nQ(x)\\}\\). Neither \\(\\exists x P(x) \\wedge \\neg \\forall x P(x)\\) nor\n\\(\\exists x Q(x) \\wedge \\neg \\forall x Q(x)\\) is derivable on the\ncondition ∅. However, both are part of the (minimal) disjunction\nof abnormalities derived at line 6. According to one strategy, the\nminimal abnormality strategy, the premises are interpreted in\nsuch a way that as many abnormalities as possible are considered to be\nfalse, which leaves us with two interpretations: one in which\n\\(\\exists x P(x) \\wedge \\neg \\forall x P(x)\\) holds while \\(\\exists x\nQ(x) \\wedge \\neg \\forall x Q(x)\\) is false, and another one in which\n\\(\\exists x Q(x) \\wedge \\neg \\forall x Q(x)\\) holds while \\(\\exists x\nP(x) \\wedge \\neg \\forall x P(x)\\) is false. In both interpretations\neither the assumption of line 4 or the assumption of line 5 holds\nwhich means that in either interpretation the defeasible inference to\n\\(\\forall x P(x) \\vee \\forall x Q(x)\\) goes through. Thus, according\nto the minimal abnormality strategy neither line 4 nor line 5 is\nmarked (we omit the technical details). Another strategy, the\nreliability strategy, is more cautious. According to it any\nline that involves an abnormality in its condition that is part of a\nminimal disjunction of abnormalities derived on the condition ∅\nis marked. This means that in our example, lines 4 and 5 are marked.\n \nLines may get marked at specific stages of a proof just to get\nunmarked at latter stages and vice versa. This mirrors the internal\ndynamics of defeasible reasoning. In order to define a consequence\nrelation, a stable notion of derivability is needed. A formula derived\nat an unmarked line l in an adaptive proof from a premise set\n\\(\\Gamma\\) is considered a consequence of \\(\\Gamma\\) if any\nextension of the proof in which l is marked is further\nextendable so that the line is unmarked again.  \nSuch a consequence relation can equivalently be expressed semantically\nin terms of a preferential semantics (see Section\n Selection semantics).\n Given an LLL-model \\(M\\) we can identify its abnormal part\n\\(Ab(M) = \\{\\mathsf{ab} \\in \\Omega \\mid M \\models \\mathsf{ab}\\}\\) to\nbe the set of all abnormalities that hold in \\(M\\). The selection\nsemantics for minimal abnormality can be phrased as follows. We order\nthe LLL-models by \\(M \\prec M'\\) if and only if \\(Ab(M) \\subset\nAb(M')\\). Then we define that \\(\\phi\\) is a semantic consequence of\n\\(\\Gamma\\) if and only if for all \\(\\prec\\)-minimal LLL-models \\(M\\)\nof \\(\\Gamma\\), \\(M\\models \\phi\\). (We omit selection semantics for\nother strategies.)  \nA similar system to adaptive logics makes use of maximally consistent\nsets. In\n Makinson (2003)\n it was developed under the name default assumptions. Given a\nset of assumptions \\(\\Xi\\),  \n\\(\\Gamma \\nc[\\Xi] \\phi\\) if and only if \\(\\Xi' \\cup \\Gamma \\vDash\n\\phi\\) for all \\(\\Xi' \\subseteq \\Xi\\) that are maximally consistent\nwith \\(\\Gamma\\) (i.e., \\(\\Xi' \\cup \\Gamma\\) is consistent and there is\nno \\(\\Xi'' \\subseteq \\Xi\\) for which \\(\\Xi' \\subset \\Xi''\\) and\n\\(\\Xi'' \\cup \\Gamma\\) is consistent).  \nIf we take \\(\\Xi\\) to be \\(\\{\\neg \\mathsf{ab} \\mid \\mathsf{ab} \\in\n\\Omega\\}\\) then we have an equivalent characterization of adaptive\nlogics with the minimal abnormality strategy and the set of\nabnormalities \\(\\Omega\\)\n (Van De Putte 2013).\n  \nConditional Entailment is another assumption-based approach\n (Geffner and Pearl 1992).\n Suppose we start with a theory \\(T = (\\Delta, \\Gamma, \\Lambda)\\)\nwhere \\(\\Delta = \\{\\phi_i \\rightarrow \\psi_i \\mid i \\in I\\}\\) consists\nof default rules, \\(\\Gamma\\) consists of necessary facts, while\n\\(\\Lambda\\) consists of contingent facts. It is translated into an\nassumption-based theory \\(T' = (\\Delta', \\Gamma', \\Lambda)\\) as\nfollows:  \nJust as in the adaptive logic approach, models are compared with\nrespect to their abnormal parts. For a classical model \\(M\\) of\n\\(\\Gamma' \\cup \\Lambda\\), \\(Ab(M)\\) is the set of all \\(\\pi_i\\) for\nwhich \\(M \\models \\neg \\pi_i\\). One important aspect that\ndistinguishes conditional entailment from adaptive logics and default\nassumptions, is the fact that it implements the Specificity Principle.\nFor this, assumptions are ordered by means of a (smooth) relation\n<. Models are then compared as follows:  \n\\(M \\lessdot M'\\) if and only if \\(Ab(M) \\neq Ab(M')\\) and for all\n\\(\\pi_i \\in Ab(M)\\setminus Ab(M')\\) there is a \\(\\pi_j \\in Ab(M')\n\\setminus Ab(M)\\) for which \\(\\pi_i < \\pi_j\\).  \nThe idea is: \\(M\\) is preferred over \\(M'\\) if every assumption\n\\(\\pi_i\\) that doesn't hold in \\(M\\) but that holds in \\(M'\\) is\n‘compensated for’ by a more specific assumption \\(\\pi_j\\) that holds\nin \\(M\\) but that doesn’t hold in \\(M'\\).  \nFor this to work, < has to include specificity relations among\nassumptions. Such orders < are called admissible relative to\nthe background knowledge \\(\\Gamma'\\) if they satisfy the following\nproperty: for every set of assumptions \\(\\Pi \\subseteq \\{\\pi_i \\mid i\n\\in I\\}\\), if \\(\\Pi\\) violates some default \\(\\phi_j \\rightarrow\n\\pi_j\\) in view of the given background knowledge \\(\\Gamma'\\) (in\nsigns, \\(\\Pi, \\phi_j, \\Gamma' \\models \\neg \\pi_j\\)) then there is a\n\\(\\pi_k \\in \\Pi\\) for which \\(\\pi_k < \\pi_j\\).  \nThis is best understood when put into action. Take the case with\nTweety the penguin. We have \\(\\Delta' = \\{ p \\rightarrow \\pi_1, b\n\\rightarrow \\pi_2\\}\\), \\(\\Gamma' = \\{ p \\supset b, p \\wedge \\pi_1\n\\supset \\neg f, b \\wedge \\pi_2 \\supset f\\}\\), and \\(\\Lambda = \\{p\\}\\).\nLet \\(\\Pi = \\{\\pi_2\\}\\). Then \\(\\Pi, \\Gamma', p \\models \\neg \\pi_1\\)\nand thus for < to be admissible, \\(\\pi_2 < \\pi_1\\). We have two\ntypes of models of \\(\\Gamma' \\cup \\Lambda\\): models \\(M_1\\) for which\n\\(M_1 \\models \\pi_1\\) and therefore \\(M_1 \\models \\neg f\\) and models\n\\(M_2\\) for which \\(M_2 \\models \\pi_2\\) and thus \\(M_2 \\models f\\).\nNote that \\(M_1 \\lessdot M_2\\) since for the only assumption in\n\\(Ab(M_1)\\) —namely \\(\\pi_2\\)— there is \\(\\pi_1 \\in\nAb(M_2) \\setminus Ab(M_1)\\) and \\(\\pi_2 < \\pi_1\\).  \nAnalogous to adaptive logics with the minimal abnormality strategy,\nconditional entailment is defined via \\(\\lessdot\\)-minimal models:\n \n\\((\\Delta', \\Gamma', \\Lambda) \\nc \\phi\\) if and only if for each\nadmissible < (relative to \\(\\Gamma'\\)) and all \\(\\lessdot\\)-minimal\nmodels \\(M\\) of \\(\\Gamma' \\cup \\Lambda\\), \\(M \\models \\phi\\).  \nIn our example, \\(\\neg f\\) is a conditionally entailed since all\n\\(\\lessdot\\)-minimal models have the same abnormal part as \\(M_1\\).\n \nA consequence of expressing defeasible inferences via material\nimplication in assumption-based approaches is that defeasible\ninferences are contrapositable. Clearly, if \\(\\phi \\wedge \\pi\n\\supset \\psi\\) then \\(\\neg \\psi \\wedge \\pi \\supset \\neg \\phi\\). As a\nconsequence, formalisms such as default logic have a more greedy style\nof applying default rules. We demonstrate this with conditional\nentailment. Consider a theory consisting of the defaults \\(p_1\n\\rightarrow p_2\\), \\(p_2 \\rightarrow p_3\\), \\(p_3 \\rightarrow p_4\\)\nand the factual information \\(\\Lambda = \\{p_1, \\neg p_4\\}\\) (where\n\\(p_i\\) are logical atoms). In assumption-based approaches such as\nconditional entailment the defeasible rules will be encoded as \\(p_1\n\\wedge \\pi_1 \\supset p_2\\), \\(p_2 \\wedge \\pi_2 \\supset p_3\\), and\n\\(p_3 \\wedge \\pi_3 \\supset p_4\\). It can easily be seen that < =\n∅ is an admissible ordering which means that for instance a\nmodel \\(M\\) with \\(Ab(M) = \\{\\pi_1\\}\\) is \\(\\lessdot\\)-minimal. In\nsuch a model we have \\(M \\models \\neg p_3\\) and \\(M \\models \\neg p_2\\)\nby reasoning backwards via contraposition from \\(\\neg p_4 \\wedge\n\\pi_3\\) to \\(\\neg p_3\\) and from \\(\\neg p_3 \\wedge \\pi_2\\) to \\(\\neg\np_2\\). This means that neither \\(p_2\\) nor \\(p_3\\) is conditionally\nentailed.  \nThe situation is different in default logic where both \\(p_2\\) and\n\\(p_3\\) are derivable. The reasoning follows a greedy policy in\napplying default rules: whenever a rule is applicable (i.e., its\nantecedent holds by the currently held beliefs \\(\\Xi\\) and its\nconsequent doesn’t contradict with \\(\\Xi\\)) it is applied. There is\ndisagreement among scholars whether and when contraposition is a\ndesirable property for defeasible inferences (e.g.,\n Caminada 2008,\n Prakken 2012).  \nIn view of the fact that test subjects seem to perform very poorly in\nvarious paradigmatic reasoning tests (e.g., Wason’s Selection Task\n (Wason 1966)\n or the Supression Task\n (Byrne 1989)),\n main streams in the psychology of reasoning have traditionally\nascribed to logic at best a subordinate role in human reasoning. In\nrecent years this assessment has been criticized as the result of\nevaluating performances in tests against the standard of classical\nlogic whereas other standards based on probabilistic considerations or\non NMLs have been argued to be more appropriate.  \nThis resulted in the rise of a new probabilistic paradigm\n (Oaksford and Chater 2007,\n Pfeifer and Douven 2014) where \nprobability theory provides a calculus for\nrational belief update. Although the program is sometimes phrased in\ndecidedly anti-logicist\n terms,[7]\n logic is here usually understood as monotonic and deductive. The\nrelation to NML is less clear and it has been argued that there are\nclose connections especially to probabilistic accounts of NML\n (Over 2009,\n Pfeifer and Kleiter 2009).\n Politzer and Bonnefon 2009\n warn against the premature acceptance of the probabilistic paradigm\nin view of the rich variety of alternatives such as possibility\nmeasures, plausibility measures, etc.).\n  \nAnother argument for the relevance of NML is advocated in\n Stenning and Van Lambalgen (2008)\n who distinguish between reasoning to and reasoning from\nan interpretation. In the former process agents establish a logical\nform that is relative both to the specific context in which the\nreasoning takes place and to the agent’s goals. When establishing a\nlogical form agents choose—inter alia—a formal language, a\nsemantics (e.g., extensional vs. intensional), a notion of validity,\netc. Once a logical form is established, agents engage in lawlike\nrule-based inferences which are based on this form. It is argued that\nin the majority of cases in standard reasoning tasks, subjects use\nnon-monontonic logical forms that are based on closed world\nassumptions.  \nNon-monotonic logicians often state that their motivation stems from\nobserving the defeasible structure of actual commonsense reasoning.\nEmpirical studies have been explicitly cited as both inspiration for\nworking on NMLs and as standards against which to evaluate NMLs.\nHowever, it has also been noted that logicians often rely too much on\ntheir own intuitions without critically assessing them against the\nbackground of empirical studies\n (Pelletier and Elio 1997).\n  \nVarious studies investigate their test subjects’ tendency to reason\naccording to specific inference principles of NMLs. Most studies\nsupport the descriptive adequacy of the rules of system P. There are,\nhowever, some open or controversial issues. For instance, while some\nstudies report results suggestive of the adequacy of weakened monotony\nprinciples such as Cautious Monotony\n (Schurz 2005,\n Neves et al. 2002,\n Pfeifer and Kleiter 2005)\n and Rational Monotony\n (Neves et al. 2002),\n Benferhat et al. (2005) report mixed results. Specificity considerations play a\nrole in the reasoning process of test subjects in\n Schurz (2005),\n whereas according to\n Ford and Billington (2000)\n they do not.\n Benferhat et al. (2005)\n are specifically interested in the question whether the responses of\ntheir test subjects corresponded better to Lexicographic Closure or to\nRational Closure. While the results were not fully conclusive they\nstill suggest a preference for the former.  \n\n Pelletier and Elio (1994)\n investigate various relevant factors that influence subjects’\nreasoning about exceptions of defaults or inheritance relations. Their\nstudy makes use of the benchmark problems for defeasible reasoning\nproposed in\n Lifschitz (1989).\n It is, for instance, observed that the exceptional status of an\nobject A with respect to some default is more likely to spread\nto other objects if they share properties with A that may play\na role in explaining the exceptional status. For example, when\nconfronted with a student club that violates the default that student\nclubs only allow for student members, subjects are more likely to\nascribe this exceptional status also to another club if they learn\nthat both clubs have been struggling to maintain minimum membership\nrequirements.  \nThe question of the descriptive adequacy of NMLs to human reasoning is\nalso related to questions concerning the nature and limits of\ncognitive modules in view of which agents are capable of logical\nreasoning. For instance, the question arises, whether such modules\ncould be realized on a neurological level. Concerning the former\nquestion there are successful representations of NMLs in terms of\nneural networks (see\n Stenning and Van Lambalgen (2008),\n Garcez et al (2009),\n Hölldobler and Kalinke (1994)\n for\n logic programming\n with closed world assumptions,\n Besold et al (2017)\n for input/output logic, and\n Leitgeb (2001)\n for NMLs in the tradition of\n Selection semantics).\n  \nThere are three major issues connected with the development of logical\nframeworks that can adequately represent defeasible reasoning:\n(i) material adequacy; (ii) formal properties; and\n(iii) complexity. A non-monotonic formalism is materially\nadequate to the extent to which it captures examples of defeasible\nreasoning and to the extent to which it has intuitive properties. The\nquestion of formal properties has to do with the degree to which the\nformalism gives rise to a consequence relation that satisfies\ndesirable theoretic properties such as the above mentioned\nReflexivity, Cut, and Cautious Monotony. The third set of issues has\nto do with computational complexity of the most basic questions\nconcerning the framework.  \nThere is a potential tension between (i) and (ii): the\ndesire to capture a broad range of intuitions can lead to ad\nhoc solutions that can sometimes undermine the desirable formal\nproperties of the framework. In general, the development of NMLs and\nrelated formalisms has been driven, since its inception, by\nconsideration (i) and has relied on a rich and well-chosen\narray of examples. Of course, there is some question as to whether any\nsingle framework can aspire to be universal in this respect.  \nMore recently, researchers have started paying attention to\nconsideration (ii), looking at the extent to which NMLs have\ngenerated well-behaved relations of logical consequence. As\n Makinson (1994)\n points out, practitioners of the field have encountered mixed\nsuccess. In particular, one abstract property, Cautious Monotony,\nappears at the same time to be crucial and elusive for many of the\nframeworks to be found in the literature. This is a fact that is\nperhaps to be traced back, at least in part, to the above-mentioned\ntension between the requirement of material adequacy and the need to\ngenerate a well-behaved consequence relation.  \nThe complexity issue appears to be the most difficult among the ones\nthat have been singled out. NMLs appear to be stubbornly intractable\nwith respect to the corresponding problem for classical logic. This is\nclear in the case of default logic, given the ubiquitous consistency\nchecks. But besides consistency checks, there are other, often\noverlooked, sources of complexity that are purely combinatorial. Other\nforms of non-monotonic reasoning, besides default logic, are far from\nimmune from these combinatorial roots of intractability. Although some\nimportant work has been done trying to make various non-monotonic\nformalisms more tractable, this is perhaps the problem on which\nprogress has been slowest in coming. ","contact.mail":"Christian.Strasser@ruhr-uni-bochum.de","contact.domain":"ruhr-uni-bochum.de"}]
