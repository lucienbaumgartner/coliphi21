[{"date.published":"2012-03-26","date.changed":"2017-08-22","url":"https://plato.stanford.edu/entries/cellular-automata/","author1":"Francesco Berto","author2":"Jacopo Tagliabue","author1.info":"http://www.st-andrews.ac.uk/philosophy/people/fb96","entry":"cellular-automata","body.text":"\n\n\nCellular automata (henceforth: CA) are discrete, abstract\ncomputational systems that have proved useful both as general\nmodels of complexity and as more specific representations of\nnon-linear dynamics in a variety of scientific fields. Firstly, CA are\n(typically) spatially and temporally discrete: they are\ncomposed of a finite or denumerable set of homogenous, simple units,\nthe atoms or cells. At each time unit, the cells\ninstantiate one of a finite set of states. They evolve in parallel at\ndiscrete time steps, following state update functions or dynamical\ntransition rules: the update of a cell state obtains by taking into\naccount the states of cells in its local neighborhood (there are,\ntherefore, no actions at a distance). Secondly, CA are\nabstract: they can be specified in purely mathematical terms\nand physical structures can implement them. Thirdly, CA are\ncomputational systems: they can compute functions and solve\nalgorithmic problems. Despite functioning in a different way from\ntraditional, Turing machine-like devices, CA with suitable rules can\nemulate a universal\n Turing machine (see entry),\n and therefore compute, given Turing’s thesis (see entry on\n Church-Turing thesis),\n anything computable.\n\n\nThe mark of CA is in their displaying complex emergent behavior,\nstarting from simple atoms following simple local rules. Because of\nthis, CA attract a growing number of researchers from the cognitive\nand natural sciences willing to study pattern formation and complexity\nin a pure, abstract setting. This entry provides an introduction to CA\nand focuses on some of their philosophical applications: these range\nfrom the philosophy of computation and information processing, to\naccounts of reduction and emergence in metaphysics and cognition, to\ndebates around the foundations of physics.\n\n\nWe will proceed as follows. In the introductory Section 1, CA are\nfirst explained via an example: Section 1.1 describes a simple\none-dimensional automaton displaying an intuitively manifest behavior.\nSections 1.2–1.3 provide a short survey of the history and main\napplications of CA.\n\n\nIn Section 2, the general theory of CA is explained, together with a\nselection of computational and complexity-theoretic results in the\nfield. Section 2.1 provides a fourfold schematic definition of CA.\nSections 2.2–2.3 explain the classification of one-dimensional\nCA proposed by Stephen Wolfram. Section 2.4 introduces the Edge of\nChaos hypothesis, a key CA-related conjecture in complexity theory.\nSections 2.5–2.7 generalize to automata occupying more than one\nspatial dimension, and/or relaxing some parameters in the definition\nof 2.1. We focus on the Game of Life—possibly the most popular\nCA—and its computational capabilities. \n\n\nSection 3 describes four main uses of CA in philosophical\ninvestigation. Firstly, since CA display complex behavioral patterns\nemerging from simple local rules, they have been naturally linked to\nemergence: this topic is dealt with in Section 3.1, where\ndifferent notions of emergence are considered. Secondly, Section 3.2\nexplores how CA have been put to work, both by philosophers and by\nscientists, to address the traditional philosophical problems of\nfree will and determinism. Thirdly, Section 3.3\ndescribes the impact of CA theories on the philosophy of computation.\nFinally, Section 3.4 addresses ontological issues ranging from the\nsense in which CA count as modelling portions of reality, to the bold\nphilosophical conjecture of some scientists, who claim that the\nphysical world itself may be, at its bottom, a discrete, digital\nautomaton. \n\nWe introduce CA using a simple example. Think of an automaton as a\none-dimensional grid of simple elements (the cells). Each of them can\nonly instantiate one of two states; let us say that each cell can be\nturned on or off. The evolution of the system is\ndetermined by a transition rule, to be thought of as implemented in\neach cell. At each time step, each cell updates its status in response\nto what happens to its neighboring cells, following the rule. \nFig. 1 \nAlthough CA are abstract, having a concrete instance in mind can help\nin the beginning. So think of\n Fig. 1\n as representing the front row of a high school classroom. Each box\nstands for a student wearing (black) or not wearing (white) a hat. Let\nus make the two following assumptions:  \nHat rule: a student will wear the hat in the following class\nif one or the other—but not both—of the two classmates\nsitting immediately on her left and on her right has the hat in the\ncurrent class (if nobody wears a hat, a hat is out of fashion; but if\nboth neighbors wear it, a hat is now too popular to be trendy).  \nInitial class: during the first class in the morning, only\none student in the middle shows up with a hat (see\n Fig. 2). \nFig. 2 \n\n Fig. 3\n shows what happens as time goes by. Consecutive rows represent the\nevolution in time through subsequent classes.  \nFig. 3 \n\n Fig. 3\n may be surprising. The evolutionary pattern displayed contrasts with\nthe simplicity of the underlying law (the “Hat rule”) and\nontology (for in terms of object and properties, we only need to take\ninto account simple cells and two states). The global, emergent\nbehavior of the system supervenes upon its local, simple features, at\nleast in the following sense: the scale at which the decision to wear\nthe hat is made (immediate neighbors) is not the scale at which the\ninteresting patterns become manifest.  \nThis example is a paradigmatic illustration of what makes CA appealing\nto a vast range of researchers:  \neven perfect knowledge of individual decision rules does not always\nallow us to predict macroscopic structure. We get macro-surprises\ndespite complete micro-knowledge. (Epstein 1999: 48)  \nSince the notion of emergence and the micro-macro interplay\nhave such an important role in science and philosophy (see the entries\non\n supervenience\n and\n emergent properties;\n for a sample of scientific applications, see Mitchell 2009:\n2–13; Gell-Mann 1994: Ch. 9), it has been suggested that many\nscientific as well as conceptual puzzles can be addressed by adopting\nthe CA perspective. Stephen Wolfram has gone as far as claiming that\nCA may help us to solve longstanding issues in philosophy:  \nThese are very bold claims. In order to assess them, let us take a\ncloser look at the field.  \nThe surprising patterns in the aforementioned classroom example were\ngenerated by boxes in a line with just two states and a simple rule.\nOne may wonder how many variations are possible on such a basic\nframework. To address this issue, let us begin by considering how\nAndrew Ilachinski, in his review of the literature, narrows down CA\napplications to four main areas, which will be referred to in the rest\nof this entry (Ilachinski 2001: 7):  \n\n (CA1)\n emphasizes that CA perform computations. Just like Turing machines,\nthey can be specified in mathematical terms, and implemented in\ndifferent physical systems. However, CA are peculiar in two important\nways. First, unlike Turing machines and von Neumann-architecture\nconventional computers, CA compute in a parallel, distributed\nfashion. Second, computation is pretty much “in the eye of the\nbeholder”: there is no tape, but the evolution of the\ncells’ states can often be interpreted as a meaningful\ncomputational procedure (e.g., bits can be encoded using the\nwhite/black cell states). Computational hardware\ninspired by CA can help solve important technological problems (see\n Ilachinski 2001: 8), but apart from engineering issues,\n (CA1)\n also points to major conceptual questions, such as how exactly a\nuniversal Turing machine and an automaton can be rigorously compared\n(see Beraldo-de-Araújo & Baravalle forthcoming) and what\nare, if any, the philosophical implications of this comparison (see\nWolfram 2002: Ch. 12).  \n\n (CA2)\n comprises scientific applications of CA to the modelling of specific\nproblems—to mention just a few: urban evolution (Batty 2005),\nIsing models (Creutz 1986), neural networks (Franceschetti, et al.\n1992: 124–128), lattice fluids (Barberousse & Imbert 2013),\nbioinformatics (Xiao et al. 2011), and even turbulence phenomena (Chen\net al. 1983). As Ilachinski remarks, for instance, discrete models of\nturbulence show that  \nvery simple finite dynamical implementations of local conservation\nlaws are capable of exactly reproducing continuum system behavior on\nthe macroscale. (Ilachinski 2001: 8)  \n\n (CA3)\n and\n (CA4)\n enter very directly into the philosophical arena: as for\n (CA3),\n Daniel Dennett has resorted to a famous automaton we describe below,\nConway’s Game of Life, to make his point on determinism\nand the attribution of high-level concepts to emergent patterns\n(Dennett 1991, 2003). As for\n (CA4),\n CA can provide an account of microphysical dynamics by representing\ndiscrete counterparts of quantum field theories (see entry on\n Quantum Field Theory)\n alternative to the standard continuous frames. But the more\nphilosophical, and quite bolder, claim in this area is that nature\nitself may be a CA: Edward Fredkin, for instance, has advanced his\n“Finite Nature” hypothesis that our universe is an\nautomaton which, at each time step, digitally and locally processes\nits state for the next time step (see Fredkin 1993). Apart from the\ninterest generated by Fredkin’s claim, entertaining the\nhypothesis raises a number of questions at the crossroads of physics\nand metaphysics (what is a natural law?), epistemology (what are the\nlimits of physical systems predictability?) and the philosophy of\ninformation (what is the role of information in the physical world?).\nWe will address each of these questions in the third Section of this\nentry. \nThe father of CA is John von Neumann (von Neumann 1951). Working on\nself-replication and attempting to provide a reductionist theory of\nbiological development, von Neumann was trying to conceive a system\ncapable of producing exact copies of itself. Now biology prima\nfacie appears to be the realm of fluidity and continuous\ndynamics. But following a suggestion of his colleague Stanislaw Ulam,\nvon Neumann decided to focus on a discrete, two-dimensional system.\nInstead of just black-or-white cells, von\nNeumann’s automaton used 29 different states and rather\ncomplicated dynamics, and was capable of self-reproduction. Von\nNeumann’s CA was also the first discrete parallel computational\nmodel in history formally shown to be a universal computer, i.e.,\n capable of emulating a universal Turing machine and computing all\n recursive functions (see entry).\n  \nIn the early Sixties, E.F. Moore (1962) and Myhill (1963) proved the\nGarden-of-Eden theorems stating conditions for the existence of\nso-called Gardens of Eden, i.e., patterns that cannot appear on the\nlattice of a CA except as initial conditions. Gustav Hedlund (1969)\ninvestigated cellular automata within the framework of symbolic\ndynamics. In 1970 the mathematician John Conway introduced his\naforementioned Life game (Berkelamp, Conway, & Guy 1982),\narguably the most popular automaton ever, and one of the simplest\ncomputational models ever proved to be a universal computer. In 1977,\nTommaso Toffoli used cellular automata to directly model physical\nlaws, laying the foundations for the study of reversible CA (Toffoli\n1977). \nStephen Wolfram’s works in the 1980s contributed to putting the\ngrowing community of CA followers on the scientific map. In a series\nof papers, Wolfram extensively explored one-dimensional CA, providing\nthe first qualitative taxonomy of their behavior and laying the\ngroundwork for further research. A particular transition rule for\none-dimensional CA, known as Rule 110, was conjectured to be\nuniversal by Wolfram. Some twenty years after the conjecture, Matthew\nCook proved that Rule 110 is capable of universal computation\n(Cook 2004; Wolfram 2002 also contains a sketch of the proof).  \nWe are now taking a closer look at CA, focusing on models and results\nof philosophical interest. Although the variety of systems to be found\nin the CA literature is vast, one can generate virtually all CA by\ntuning the four parameters that define their structure:  \nOne can exhaustively describe, for instance, the automaton of our\nclassroom example:  \nA rule for a CA can be expressed as a conditional instruction:\n“If the neighborhood is this-and-this, then turn to state\ns”. One can write the general form of the rule for\none-dimensional CA:  \nWhere \\(\\sigma_{i}(t) \\in \\Sigma = \\{0, 1, \\ldots, k - 1\\}\\) is the\nstate of cell number i at time step t; r\nspecifies the range, that is, how many cells on any side\ncount as neighbors for a given cell; and \\(\\phi\\) is defined\nexplicitly by assigning values in \\(\\Sigma\\) to each of the \\(k^{2r+1}\n(2r + 1)\\)-tuples representing all the possible neighborhood\nconfigurations. For example, with \\(r = 1, \\Sigma = \\{1, 0\\}\\), a\npossible transition rule \\(\\phi\\) can be expressed as in\n Fig. 4\n (with 1 being represented as black, 0 as white):\n \nFig. 4 \nFor a given cell, each triple at the top represents a possible\nneighborhood configuration at t, the cell at issue being the\none in the middle: for each configuration, the square at the bottom\nspecifies the cell’s state at \\(t + 1\\). This is our classroom\nexample: you will have a black cell just in case precisely one of the\nneighbors was black.  \nThis simple representation is also at the core of the widely adopted\nWolfram code (Wolfram 1983), assigning to each rule a number: with\nblack = 1 and white = 0, the bottom row can be read\nas a binary number (01011010); converting to decimal gives you the\nrule’s name (in this case, Rule 90). Since rules for CA\nwith \\(r = 1\\) and \\(k = 2\\) differ just in the bottom row of the\ndiagram, this encoding scheme effectively identifies each possible\nrule in the class. One-dimensional CA with \\(r = 1\\) and \\(k = 2\\) are\namong the simplest CA one can define, yet their behavior is at time\nquite interesting. When Stephen Wolfram started to explore this field\nin the Eighties, that class seemed a perfect fit. With \\(r = 1\\),\nthere are 8 possible neighbors (see\n Fig. 4\n above) to be mapped to \\({1, 0}\\), giving a total of \\(2^8 = 256\\)\nrules. Starting with random initial conditions, Wolfram went on to\nobserve the behavior of each rule in many simulations. As a result, he\nwas able to classify the qualitative behavior of each rule in one of\nfour distinct classes. Repeating the original experiment, we simulated\nthe evolution of two rules for each class of Wolfram’s\nscheme. \nClass1 rules leading to\nhomogenous states, all cells stably ending up with the same value:\n \nRule 250 \nRule 254 \nClass2 rules leading to\nstable structures or simple periodic patterns:  \nRule 4 \nRule 108 \nClass3 rules leading to\nseemingly chaotic, non-periodic behavior:  \nRule 30 \nRule 90 \nClass4 rules leading to\ncomplex patterns and structures propagating locally in the lattice:\n \nRule 54 \nRule 110 \nClass1 comprises the rules that quickly produce uniform\nconfigurations. Rules in Class2 produce a uniform final\npattern, or a cycling between final patterns, depending on the initial\nconfigurations. The configurations produced by members of\nClass3 are pretty much random-looking, although some\nregular patterns and structures may be present.  \nClass4 deserves special attention. If we observe the\nuniverse generated by Rule 110 we see regular patterns\n(although not as regular as in Rule 108) as well as some\nchaotic behavior (although not as noisy as in Rule 90). Now\nthe basic feature a CA needs to perform computations is the capacity\nof its transition rule of producing “particle-like persistent\npropagating patterns” (Ilachinski 2001: 89), that is, localized,\nstable, but non-periodic configurations of groups of cells, sometimes\ncalled solitons in the literature, that can preserve their\nshape. These configurations can be seen as encoding packets\nof information, preserving them through time, and\nmoving them from one place to another: information can\npropagate in time and space without undergoing important decay. The\namount of unpredictability in the behavior of Class4 rules\nalso hints at computationally interesting features: by the Halting\nTheorem (see section in entry on\n Turing machines),\n it is a key feature of universal computation that one cannot in\nprinciple predict whether a given computation will halt given a\ncertain input. These insights led Wolfram to conjecture that\nClass4 CA were (the only ones) capable of universal\ncomputation. Intuitively, if we interpret the initial configuration of\na Class4 CA as its input data, a universal\nClass4 CA can evaluate any effectively computable function\nand emulate a universal Turing machine. As we mentioned above,\nRule 110 was indeed proved to be computationally\nuniversal. \n(See the supplementary document\n The 256 Rules.) \nThe intermediate nature of Class4 rules is connected to the\nidea that interesting complexity, such as the one displayed\nby biological entities and their dynamics, lies in a middle area\nbetween the two extremes of boring regularities and noisy chaos:  \nPerhaps the most exciting implication [of CA representation of\nbiological phenomena] is the possibility that life had its origin in\nthe vicinity of a phase transition and that evolution reflects the\nprocess by which life has gained local control over a successively\ngreater number of environmental parameters affecting its ability to\nmaintain itself at a critical balance point between order and chaos.\n(Langton 1990: 13) \nCA provided not just the intuition, but a formal framework to\ninvestigate the hypothesis. In the late Eighties the “Edge of\nChaos” picture received considerable interest by CA\npractitioners. Packard 1988 and Langton 1990 were the first studies to\ngive to the Edge of Chaos a now well-known interpretation in the CA\ncontext. As Miller and Page put it, “these early experiments\nsuggested that systems poised at the edge of chaos had the capacity\nfor emergent computation” (Miller & Page 2007: 129). The\nidea is simple enough: what happens if we take a rule like Rule\n110 and introduce a small perturbation? If we are to believe the\nEdge of Chaos hypothesis, we should expect the rules obtained by small\nchanges in Rule 110 to exhibit either simple or chaotic\nbehavior. Let us consider a single switch from 1 to 0 or 0 to 1 in the\ncharacteristic mapping of Rule 110. The results are the\nfollowing eight neighboring rules, each differing from Rule\n110 by a single bit (the diagonal in the array, with numbers in\nitalics): \nAt a first approximation, the Edge of Chaos hypothesis is confirmed:\nthree of the eight neighbors are Class3, three are\nClass2, two are Class1: Rule 110 is the\nonly Class4 in the table. To generalize these findings to\nthe entire class of rules for one-dimensional CA, Langton introduced a\nparameter, \\(\\lambda\\), that applies to each \\(\\phi\\): for \\(k = 2\\),\n\\(r = 1\\) (binary-state, unary-range) CA, \\(\\lambda(\\phi)\\) can be\ncomputed as the fraction of entries of the transition rule table that\nare mapped to a non-zero output (see Langton 1990: 14 for the general\ndefinition). In our case this means: \\(\\lambda(\\phi)\\) will be equal\nto the number of ones in the rule column—e.g., \\(\\lambda(\\phi) =\n5/8\\) for \\(\\phi\\) = Rule 110 and \\(\\lambda(\\phi) = 1/2\\) for\n\\(\\phi\\) = Rule 46. Langton’s major finding was that a\nsimple measure such as \\(\\lambda\\) correlates with the system\nbehavior: as \\(\\lambda\\) goes from 0 to 1, the average behavior of the\nsystems goes from freezing to periodic patterns to chaos. Langton\nsingled out 1/2 as the value of \\(\\lambda\\) at which the average\nbehavior first shows evidence of chaos: rules \\(\\phi\\) with\n\\(\\lambda(\\phi) \\sim 1/2\\) were highlighted as being on the Edge (see\nMiller & Page 2001: 133). \nBoth chaotic and complex rules have an average \\(\\lambda\\) value\naround 1/2, thus apparently supporting the Edge of Chaos hypothesis.\nIt is fair to say, though, that some have cast doubts on the\nexplanatory role of parameter \\(\\lambda\\) and the inferences drawn\nfrom it. In particular, the transition region of the Edge of Chaos\nseems to be itself complex. Miller and Page note that “there are\nmultiple edges, not just a single one” (Miller & Page 2007:\n133). Aggregate results do not hold when we analyze individual rules,\neven paradigmatic ones: \nAs the table shows, among the Rule 110 neighbors, some\nchaotic rules \\(\\phi\\) have \\(\\lambda(\\phi) = 3/4\\), some cyclic ones\nhave \\(\\lambda(\\phi) = 1/2\\) and, indeed,  \nevery one of the rules classified as complex in this space has at\nleast one chaotic neighbor with a lower \\(\\lambda\\) value and one with\nhigher value. (Miller & Page 2007: 135)  \nMelanie Mitchell, Peter Hraber and James Crutchfield replicated\nLangton and Packard’s experiments, reporting very different\nresults (Mitchell, Hraber, & Crutchfield 1994). In particular,\nthey report that serious computational phenomena take place much\ncloser to a chaotic \\(\\lambda(\\phi) = 1/2\\) than it was previously\nthought. Apart from technical points, a conceptual flaw in the\noriginal findings is the use of aggregate statistics, which are\ndifficult to interpret in a high variance context:  \nif, instead, the hypotheses are concerned with generic, statistical\nproperties of CA rule space—the “average” behavior\nof an “average CA” at a given \\(\\lambda\\)—then the\nnotion of “average behavior” must be better defined.\n(Mitchell, Hraber, & Crutchfield 1994: 14).  \nWhile it is fair to conclude that complex behavior does not lie at the\nEdge of Chaos taken in a simplistic sense (i.e., it is not\nstraightforwardly correlated with the simple \\(\\lambda\\)), the\ninterest in the connection between computational capabilities and\nphase transitions in the CA rule space has been growing since then. We\nwill consider such developments below, specifically in the context of\nCA and the philosophy of computation.  \nNotwithstanding the computational interest of one-dimensional CA,\nphilosophical issues have been discussed more often in connection with\ntwo-dimensional CA. The first CA, von Neumann’s self-reproducing\nautomaton, inhabited a two-dimensional grid. Besides, two-dimensional\nCA are suitable for representing many physical, biological, and even\nhuman phenomena, ranging from the dynamics of perfect gases to the\nmovements of birds in a storm and soldiers on a battlefield. The most\ncommon configurations have either square or hexagonal cells, given\ntheir translational and rotational symmetries. Moving to two\ndimensions, of course, also expands the possibly interesting\ncombinations of rules and neighborhoods. As for the latter, the two\nmost common options in a grid of squares are the von Neumann\nneighborhood, where each cell interacts only with its four horizontal\nand vertical adjacent mates, and the Moore neighborhood,\ncomprising all the eight immediately adjacent cells. \nBy way of example, we introduce the famous Game of Life (or,\nmore briefly, Life) by John Conway (see Berkelamp, Conway,\n& Guy 1982). Life fits well with our usual schema:  \nLife would definitely be considered a Class4 CA by\nWolfram’s taxonomy. In this simple setting, periodic structures,\nstable blocks and complex moving patterns come into existence, even\nstarting from a very simple initial configuration. Conway remarked:\n \nIt’s probable, given a large enough Life space,\ninitially in a random state, that after a long time, intelligent,\nself-reproducing animals will emerge and populate some parts of the\nspace. (cited in Ilachinski 2001: 131)  \nLife-fans explored the CA’s possible patterns of\nevolution, and shared their findings in what has been called\nLife’s zoology (Dennett 2003: 41). Here is a small\ngallery of samples together with snapshots of a typical simulation\n(for more pictures and animations, see\n Other Internet Resources\n at the end). Gliders are the most popular among the basic\nLife inhabitants: a simple 5-bit structure, a glider can\ntravel the Life grid in a 4-time step cycle: \nGlider \n\\(t_{0}\\) \n\\(t_{1}\\) \n\\(t_{12}\\) \nToads are period 2 blinking configurations: together with\nBlinkers and Beacons they are the simplest\noscillators of the universe.  \nToad \n\\(t_{0}\\) \n\\(t_{1}\\) \n\\(t_{3}\\) \nEaters have the feature of devouring other configurations,\ne.g., gliders, maintaining intact their own form (because of this,\nthey play an important role for Life’s computational\nabilities). \nAn Eater devouring a Glider \n\\(t_{0}\\) \n\\(t_{2}\\) \n\\(t_{4}\\) \nA typical evolution of Life starting from random initial\nconditions may contain all of the above notable figures and much more.\nSome initial configuration may end up, even after few time steps, into\nstatic or simple periodic structures. Other configurations, though,\ncan produce non-periodic, increasingly complex environments whose\ndevelopment can be unpredictable (even in the computational sense we\nare about to explore). As Ilachinski has suggestively conjectured from\nthis:  \nUpon observing the seemingly unlimited complexity and variety of\nLife’s evolving patterns, it becomes almost impossible\nto refrain from imagining, along with Conway, that, were the game\nreally to be played on an infinite lattice, there must surely arise\ntrue living “life-forms”, perhaps themselves evolving into\nmore complex, possibly sentient, “organisms”. (Ilachinski\n2001: 133) \n\\(t_{0}\\) \n\\(t_{10}\\) \n\\(t_{20}\\) \n\\(t_{30}\\) \n\\(t_{40}\\) \n\\(t_{175}\\) \nThe mathematical literature on CA does not refrain from describing the\nLife configurations using the same imaginative vocabulary we\nused: items are born, live, move around,\neat other figures, die, etc. The universe these\npatterns inhabit may also be described, though, as a collection of\nindividual cells, each of which does not directly depend on what is\nhappening on the macro-scale. And the life on Life can also\nbe described in the simple mathematical language of matrices and\ndiscrete sequences. But if one is only told the basic Life\nrule, one could hardly imagine the complexity it can\ngenerate—until one sees it. Life’s reputation\namong scientists and philosophers arguably comes from its challenging\nnaive intuitions about complexity, pattern formation and reality,\npersistence, and continuity: as a toy universe we ourselves built, we\nfeel we should know in advance what dynamics are allowed. This has\nbeen shown to be impossible, in a mathematically precise sense. \nLike any other CA, Life can be considered a computational\ndevice: an initial configuration of the automaton can encode an input\nstring. One can let the system run and, at some point, read the\ncurrent configuration as the result of the computation performed so\nfar, decoding it into an output string. But exactly what can\nLife compute? It turns out that Life can compute\neverything a universal Turing machine can and therefore, taking on\nboard Turing’s Thesis, function as a general purpose computer: a\nsuitable selection of initial conditions can ensure that the system\ncarry out arbitrary algorithmic procedures.  \nThe proof of the universal computational capacities of Life\npresented in Berkelamp, Conway, and Guy 1982 consists in showing that\nthe basic building blocks or primitives of standard digital\ncomputation can be emulated by appropriate patterns generated by\nLife—in particular: (a) data storage or memorization,\n(b) data transmission requiring wires and an internal clock, and (c)\ndata processing requiring a universal set of logic gates, like\nnegation, conjunction and disjunction—an actual Turing machine\nwas later explicitly implemented in Life by Paul Rendell (see\n Other Internet Resources). \nThis finding is not of great engineering importance (no one would\nspend their time translating “\\(24 + 26 / 13\\)” into\nLife). However, it raises a conceptual issue about any\nuniverse sharing the capacity of producing and hosting universal\ncomputers: because of the aforementioned Halting Theorem, no general\nalgorithm is to decide whether, given some initial configuration as\ninput, Life will eventually die out or halt. It is in this\nsense that the evolution of the automaton is unpredictable. Given that\nthe development of CA that are computationally universal cannot be\npredicted by direct mathematical analysis alone, it is no surprise\nthat CA practitioners have adopted the language of philosophy and\ntalked of phenomenological studies of CA (we will come back\nto this terminology in more detail in\n Section 3.4\n below, discussing how CA model whatever they can model). Here the\nautomaton is realized as a computer software, and the observable\nemergent properties of its evolution are empirically registered as the\ncomputer simulation advances. In Wolfram’s turn of phrase,\nLife is algorithmically irreducible: no algorithmic\nshortcut is available to anticipate the outcome of the system given\nits initial input. “Life—like all computationally\nuniversal systems—defines the most efficient simulation of its\nown behavior” (Ilachinski 2001: 15). This raises the important\nphilosophical question of the limits of the predictability of any\nuniverse capable, just as Life is, of producing and hosting\nuniversal computers.  \nNotwithstanding the historical and conceptual centrality of the CA\ndescribed in this section, many important developments in the field\ncould not be presented in the space allowed for this entry. One can\nrelax some of the assumptions in the general characterization of CA\nprovided in\n Section 2.1\n and get interesting results. The transition rule can be\nprobabilistic and take into consideration more than just one\ntime step (see Richards, Meyer, & Packard 1990: probabilistic\nautomata are widely used to represent the stochastic dynamics of\nmicrophysical systems); the cell state updating can be\nasynchronous (see Ingerson & Buvel 1984); the lattice can\nbe made of non-homogenous cells following different\ntransition rules (see Kauffman 1984); even the discreteness constraint\ncan be relaxed by having the set of states be the set of real\nnumbers (see Wolfram 2002: 155–157). \nCA are also being fruitfully used in connection to the issue of the\nthermodynamic limits of computation: is there a minimum amount of\nenergy needed to perform a logical operation? Landauer (1961) argued\nthat irreversible logical operations (i.e., operations that, not\ncorresponding to bijections, cannot be run backwards as they entail\nsome information loss) necessarily dissipate energy. The invention of\nthe Fredkin reversible logical gate and of the Billiard Ball Model of\nreversible computation (Fredkin & Toffoli 1982) strengthened the\nimportance of the link between universal reversible automata and the\nphysical properties of computation (for an overview, see Ilachinski\n2001: 309–323; for a sample reversible CA, see Berto, Rossi,\n& Tagliabue 2016). \nFinally, it is worth mentioning that genetic algorithms have\nbeen used with CA to study how evolution creates computation (for a\nsurvey of important results, see Mitchell, Crutchfield, & Das\n1996). While the aforementioned sources further explore these\npossibilities, the sample CA models discussed so far will be\nsufficient for the philosophical arguments we are going to address\nhenceforth. \nA growing number of CA-related philosophical arguments are being\nproduced, both by philosophers and by scientists interested in the\nconceptual implications of their work. Among the interesting issues\naddressed through the CA approach in the philosophical market are the\nstructure of emergence, free will, the nature of computation, and the\nphysical plausibility of a digital world.  \nCA can be considered a paradigmatic locus for the study of phenomena\nrelated to emergence (for an introduction, see the entry on\n emergent properties).\n One can initially divide the problem of emergence into two separate\nquestions, roughly corresponding to epistemological and ontological\nissues: How can we recognize emergence? What is the\nontological status of the high-level properties and features?\nAs a matter of historical fact, CA have been invoked mainly to address\nthe former, but we will see in\n Section 3.4\n below that there is work for CA also on the ontological side. \nEpistemological issues have often been raised in connection with\ncomplex systems in general. In their open agenda for complex social\nsystems, Miller and Page include the following question: “Is\nthere an objective basis for recognizing emergence and\ncomplexity?” (Miller & Page 2007: 233–234). The\nliterature on CA has variously addressed the issue. On the one hand,\nbeing a low-level simple and controllable environment, CA present\nthemselves as a natural framework for tackling the problem in its\npurest form. On the other hand, CA researchers have recognized how the\nsystemic and global features of a complex CA system can be hard to\npredict even with perfect knowledge of low-level entities and laws:\n \nOver and over again we will see the same kind of thing: that even\nthough the underlying rules for a system are simple, and even though\nthe system is started from simple initial conditions, the behavior\nthat the system shows can nevertheless be highly complex. (Wolfram\n2002: 28) \nDue to the local nature of a CA’s operations, it is typically\nvery hard, if not impossible, to understand the CA’s global\nbehavior (…) by directly examining either the bits in the\nlookup table or the temporal sequence of raw 1–0 spatial\nconfigurations of the lattice. (Hordijk, Crutchfield, & Mitchell\n1996: 2) \nNow the issue of detecting emergence is connected to the conceptual\nproblems of defining what an emerging feature is: we need\nsome idea of what we are looking for in order to scan the\nspace-time evolution of a system and recognize its patterns. We may\nstart with the fourfold characterization of emergence provided in\nClark 2013. Emergence may be taken:  \nIn the first sense, an emergent feature is “any interesting\nbehaviour that arises as a direct result of multiple self-organizing\n… interactions occurring in a system of simple elements”\n(Clark 2013: 132). CA clearly fit the\n E1\n bill, but that is because this is a rather generic characterization\n(What counts as interesting? What is self-organization?). Things get a\nbit more precise with\n E2:\n emergent features here are taken as unprogrammed, that is,\nas such that there is no program explicitly encoding the relevant\nphenomena, features, or processes in the target system (a typical\nexample is cricket phonotaxis, see Clark 2013: 120: female crickets\nmove towards males via a mechanical body system directing them to the\nsource of sounds of particular wavelengths; one can describe this as\nfemales aiming towards males after hearing their sound, but what is\nencoded in the cricket’s body functions is just an automatic\nearlier activation of the side of the body first reached by the\nsounds). According to the concept embodied in\n E3,\n we get emergence as interactive complexity when “complex,\ncyclic interactions give rise to stable and salient patterns of\nsystemic behavior” (Clark 2013: 134); in particular, the\ninteractions are supposed to be nonlinear (a typical example are\nconvection rolls in a fluid heated in a pan: see Kelso 1995: 5).  \nNow the emergent properties attracting CA scholars’ attention,\nunsurprisingly, have mainly been computational properties, i.e., the\nfeatures enabling a system to perform complex calculations in spite of\nnot being explicitly computationally encoded at the base level (which\nsits in the vicinity of\n E2).\n Additionally, as we have seen during our discussion of the Edge of\nChaos hypothesis, CA scholars have focused on the study of nonlinear\nglobal dynamics emerging from the local interactions of the CA cells\n(which sits in the vicinity of\n E3).\n In order to introduce the formal work on emergent CA computation, and\nto compare these findings with the available philosophical accounts,\nwe can start again with a concrete example. This is the\n“classification problem”.  \nWe want to design a one-dimensional automaton that answers a simple\nquestion: Are there more white or black cells at a given time \\(t_0\\)?\nStarting from any initial conditions with more white (black) cells,\nthe ideal automaton will halt having all its cells turned white\n(black) after a given number of time steps (designing an automaton\nthat always gives the right answer is not feasible in practice; so the\nperformance is judged by the fraction of random initial conditions\nthat are correctly classified).  \n\\(t_0\\) \n\\(t_n\\) \nThe task is far from trivial in a CA, involving the intricacy of the\nemergence in both\n E2\n and\n E3\n sense. The answer requires a global perspective (how many cells are\nwhite (black) in the lattice as a whole?). However, the cells work\nwith only local rules explicitly encoded in them: no single cell can\ndo the counting. The ideal automaton should find a way to aggregate\ninformation from several parts of its own lattice to give the final\nanswer. A kind of emergent computation is needed to successfully solve\nthis density classification task. It has been proved that no CA can\nsolve this problem precisely (see Land & Belew 1995). Since,\nhowever, CA with larger neighborhoods achieve better results in tasks\nof this kind, genetic algorithms are used to efficiently\nsearch the solution space (genetic algorithms are computational\nanalogues of genetic evolution, in which a computational problem is\naddressed by producing, combining and selecting solutions to it; the\ndetails of the procedure as applied to the classification problem are\nnot important for our purpose, but, for an accessible presentation,\nsee Mitchell 2009: 22; for a general introduction see Mitchell 1998).\nThe following is a diagram of the “Rule \\(\\phi_{17083}\\)”,\ndiscovered by James Crutchfield and Melanie Mitchell (1995). The CA\nimplementing the rule starts from an initial state with more white\ncells:  \nFig. 5 \nAt time step 250 (not shown in\n Fig. 5),\n the grey areas disappear and all cells end up white, i.e., the\nclassification made by the automaton is correct. A high-level\ndescription of what is going on would have it that the white, black\nand grey regions are “expanding”,\n“contracting”, “moving”, these being nonlinear\neffects of the low-level working of the cells computing their local\nstates, and by so doing manage to carry signals along the lattice. But\nhow are we to explain the emergent computation CA of this kind perform\nvia such nonlinear dynamics? Building on previous works on computation\ntheory applied to CA (Hanson & Crutchfield 1992; Crutchfield &\nHanson 1993), Mitchell and Crutchfield filtered out from the original\ndiagram what they call “domains”, i.e., dynamically\nhomogenous spatial regions (Crutchfield & Mitchell 1995: 10745):\n \nFig. 6 \nAlthough in this case the “domains” are manifest, it is\ncrucial to point out that their definition is rigorously mathematical.\nThe whole process of domain-detection can be carried out\nalgorithmically (see Hanson & Crutchfield 1992 for details). When\nthe boundary of a domain remains spatially localized over time, then\nthe domain becomes a “particle”:  \nEmbedded particles are a primary mechanism for carrying information\n(…) over long space-time distances. (…) Logical\noperations on the signals are performed when the particles interact.\nThe collection of domains, domain walls, particles and particle\ninteractions for a CA represents the basic information processing\nelements embedded in the CA’s behavior—the CA’s\n“intrinsic” computation. (Crutchfield & Mitchell 1995:\n10744) \nThere are five stable particles (termed α, γ, δ,\nε, µ) and one unstable particle (β) for this\nautomaton: their interaction (annihilation, decay, reaction) supports\nthe emergent logic of the system. The two circles in the image above\nare examples of what may happen during an interaction. In the first\ncase, \\(\\alpha + \\delta \\rightarrow \\mu\\), a spatial configuration\nrepresenting high, low, and then ambiguous densities is mapped to a\nhigh-density signal µ; in the second, \\(\\mu + \\gamma \\rightarrow\n\\alpha\\), a spatial configuration representing high, ambiguous, and\nthen low density is mapped to an ambiguous-density signal α\n(Crutchfield & Mitchell 1995: 10745). The whole computational\nmechanics is worth being explored in more detail, but we can already\nsafely generalize to the basic philosophical point of this and related\nworks.  \nAccording to O’Connor and Wong 2015, in the context of dynamic\nsystems and the study of complexity, emergence is characterized by\nmost authors  \nstrictly in terms of limits on human knowledge of complex systems.\nEmergence for such theorists is fundamentally an epistemological, not\nmetaphysical, category. (O’Connor & Wong 2015: Sec. 2)  \nBut the Crutchfield-Mitchell approach suggests a different\nperspective. Firstly, the emergent (both in the\n E2-\n and in the\n E3-\n sense) computational properties in CA can in an important sense be\nobjectively defined (see Crutchfield 1994a and the more accessible\nCrutchfield 1994b): although it is customary in this setting to talk\nof emergent computation being “in the eye of the\nbeholder”, because not explicitly encoded at the base level, the\ndetection and classification of patterns is itself algorithmic.\nSecondly, Crutchfield characterizes CA-emergence of this kind as, in a\nsense, intrinsic: the emerging patterns “are important\nwithin the system” (Crutchfield 1994b: 3), not merely\nimportant for an observer outside the system. More precisely:\nthey are mathematically grounded on the basic features of the system,\ndespite not being explicitly mentioned in the standard abstract\ncharacterization of the program, that is, the transition rule\nimplemented in the CA cells (Crutchfield mentions as non-intrinsic\nemergent phenomena the patterns in the Belousov-Zhabotinsky reaction\nand the energy recurrence in an harmonic oscillator chains reported by\nFermi, Pasta and Ulam—see Crutchfield 1994b).  \nCrutchfield infers from this that many cases of emergence are indeed\nnot reducible to some interaction with an observer. They are genuine\ninstances of an intrinsic phenomenon, not the results of some\nhuman-biased discovery (Crutchfield 1994b: 2). If emergence was not\nintrinsic, scientific activity would indeed be a subjective enterprise\nof “pattern discovery”:  \nWhy? Simply because emergence defined without this closure leads to an\ninfinite regress of observers detecting patterns of observers\ndetecting patterns… (Crutchfield 1994b: 10) \nSummarizing Crutchfield’s work, Miller and Page say that the\nconcept of emergence  \nhas thus made the transition from metaphor to a measure, from\nsomething that could only be identified by ocular magic to something\nthat can be captured using standard statistics. (Miller & Page\n2007: 234)  \nSuch remarks may sound philosophically naive to a trained\nepistemologist. It is not obvious, for instance, that the existence of\na mathematical or specifically algorithmic emergent pattern would\nblock a supposed regress entailed by a non-mathematical emergence. Why\nwould science as an activity of (occasionally) non-algorithmic pattern\ndiscovery be a merely subjective enterprise? If these claims can be\nre-phrased in a philosophically sophisticated way, though, they may\nchallenge standard definitions of weakly emergent properties\n(in the sense of Chalmers 2002). Teller 1992, Clark 1996, and Bedau\n1997, for instance, all run together instances of “pattern\ndiscovery”—, taken as a subjective, observer-dependent\nactivity—with instances of intrinsic emergence—a\nphenomenon that, as we have just seen, can be characterized in the\ncontext of CA as objective and statistically significant (see the\nrelevant section of the entry on\n emergent properties).\n  \nFinally, on to\n E4:\n emergence as incompressible unfolding. Bedau 1997 defines a\nmacro-state emergent in this sense just in case it can be\nderived from knowledge of the system’s micro-components only by\ndirect simulation of the overall system evolution. Here the idea is\none of “emergent phenomena as those for which\nprediction requires simulation” (Clark 2013:\n134):\n E4-emergent\n macro-features would be those that can only be predicted by directly\nmodelling the micro-features, with no computational shortcut to\ncompress the information at micro-level. The first thing to notice,\naccording to Clark, is that this notion of emergence is at odds with\nat least some of the previous ones:\n E3-emergence\n has it that  \nemergent phenomena are often precisely those phenomena in\nwhich complex interactions yield robust, salient patterns capable of\nsupporting prediction. (ibid)  \nthat is, patterns that deliver compressible information. Next, while\nthe characterization of\n E4,\n Bedau-style emergence may work pretty well in the case of completely\nchaotic systems, it does not sit well with such CA as Rule\n\\(\\phi_{17083}\\). According to the proposed definition, the answer to\nthe classification problem given by Rule \\(\\phi_{17083}\\) is an\nemergent phenomenon just in case the only way to go from \\(t_0\\) to\n\\(t_n\\) is by explicitly simulating the system evolution. \n\\(t_0\\) \n\\(t_n\\) \nAs it turns out, however, this is not the case. Using\nCrutchfield’s particle model it is possible to predict the\nresult of the classification by simply making particle-calculations,\nwithout bothering about the underlying dynamics (Hordijk, Crutchfield,\n& Mitchell 1996). Here then, the emerging computation in the CA\nwould not be a case of emergence for Bedau.  \nWhat about the ontological side of emergence? The issue of the reality\nof emerging patterns in CA has been examined both by reductionist\n(Dennett 2003) and by emergentist philosophers (Thompson 2007). It is\nfair to say that the CA literature so far has not significantly\ncontributed to the ongoing philosophical debate on the purely\nontological side of reductionism. CA patterns that are\n“objectively” detected via computation, as per the\nMitchell-Crutchfield approach, are not ipso facto new\nprimitives to be included in an ontology. It may well be that features\nof a CA that are objective, in the sense of not depending on the\ninteraction with an observer, are nevertheless ontologically reducible\nto more basic entities via suitable definitions (see Kim 1999; Dennett\n1991).  \nPhilosophers have debated the relationship between determinism and\nfree will for over two millennia. Two opposite stances can be taken\ntowards the problem: compatibilism maintains that free will\nis compatible with a deterministic world, which\nincompatibilism denies (see the entries on\n free will\n and\n compatibilism).\n Surprisingly enough, both Daniel Dennett and Stephen Wolfram argued\nthat adopting the CA perspective can provide a solution, or perhaps a\ndissolution, of the longstanding mystery of free will. \nA major obstacle to accepting compatibilism is our persuasion that\ndeterminism implies inevitability (Dennett 2003: 25). We may thus make\ncompatibilism palatable by exhibiting an intuitive counterexample to\nthat conviction: a deterministic world in which, however, not\neverything is inevitable, i.e., something is avoidable (Ibid: 56).\nDennett maintains that CA can do this. He takes Life as a\nvivid illustration of how, in a deterministic but complex enough\nworld, we can abstract away from the bottom level and the micro-laws\ndeterministically governing it, and describe what is happening by\ntaking the emergent level seriously. Recall the eater-glider dynamics:\n \nAn Eater devouring a Glider \n\\(t_0\\) \n\\(t_2\\) \n\\(t_4\\) \nAt \\(t_0\\), an observer aiming at predicting the evolution of this\nspace-time region has basically two choices: she can take into account\n(what Dennett calls) the physical level, and compute pixel by\npixel the value of each cell state at each time step; or, she can\nfocus on the design level, and employ high-level concepts\nsuch as those of glider and eater to ground her\npredictions (Dennett 2003: 39). The first option is perfectly\ndeterministic, but has a flaw: it is time consuming, in such a way\nthat, by the time you have made the required computation, the world\nhas already evolved (this is especially true of a universal\nCA—as we have already hinted at above, and shall expand on\nsoon). The second option is much faster: you know without much\ncalculation what is going to happen to a glider meeting an eater. The\npredictions though, cannot be 100% reliable:  \nWhereas at the physical level, there are absolutely no exceptions to\nthe general law, at the design level our generalizations have to be\nhedged: they require “usually” clauses (…). Stray\nbits of debris from earlier events can “break” or\n“kill” one of the objects in the ontology at this level.\nTheir salience as real things is considerable, but not guaranteed.\n(Dennett 2003: 40) \nDennett’s point is that avoidance itself is a\nhigh-level concept. As such, it is compatible with a deterministic\nbottom level (because the concepts at the emergent level are, by\ndesign, independent from the micro-laws). The physical\ndescription and the design description of Life\nare different interpretations of the same basic ontology, namely, the\nsparse ontology of CA. While in theory we could avoid the introduction\nof emergent concepts, in practice it is only by speaking of gliders,\nmovements and avoidance that we can make sense of the evolution of the\nsystem (Dennett 2003: 43–44). Even without knowing\nLife’s physics, we could do a good job if we predicted\nthe future by mentioning only high level patterns. Life is\njust a toy universe but, Dennett claims, these new intuitions are\nsufficient to see that, in some deterministic worlds, something is\navoidable. For instance, it is true at the design level that gliders\nactually avoid eaters. Thus, the inference from determinism to\ninevitability can be blocked.  \nA reply to Dennett’s argument consists in denying that\nLife-avoidance is real avoidance. Dennett himself puts a\nversion of this argument in the mouth of Conrad, a fictional skeptic\nphilosopher discussing Dennett’s idea throughout his book:  \nIt may look like avoidance, but it’s not real avoidance. Real\navoidance involves changing something that was going to happen into\nsomething that doesn’t happen. (Dennett 2003: 58) \nRephrasing Dennett’s example, we can identify an ambiguity in\nConrad’s argument. Imagine that a baseball is going to\nhit you in the face—but you dodge it: a clear case of\nreal human avoidance. In what sense was the baseball\n“going to” hit you in the face? (Dennett 2003: 59) One\nmight say that it was never really going to hit you,\nprecisely because it triggered the reaction of whatever\n“avoidance system” you have. What is the difference\nbetween this avoidance and Life-avoidance? For Dennett, this\nis not a difference in kind, but in complexity: gliders and humans\nboth have avoidance systems, but human systems are much more\nsophisticated. The choice of a universal CA as a toy universe allows\nus to draw a stronger conclusion: since we know that Life is\nequivalent to a universal Turing machine, as explained above, some\npatterns in that universe may display avoidance systems at least as\ncomplex as ours. Dennett claims that compatibilism has thus won the\nfirst round:  \nyou agree that (…) I’ve shifted the burden of proof:\nthere shall be no inferring inevitability in any sense from\ndeterminism without mounting a supporting argument. (Dennett 2003: 61)\n \nStephen Wolfram addresses the phenomenon of free will in his book on\nCA, with an ambitious tone: \nFrom the discoveries in this book it finally now seems possible to\ngive an explanation for this [free will]. And the key, I believe, is\nthe phenomenon of computational irreducibility. (Wolfram 2002:\n750) \nWe have introduced the issue of computational (or algorithmic)\nirreducibility when we explained the philosophical consequence of a\nuniversality proof for an automaton, namely that, although a system\nfollows definite underlying laws, “its overall behavior can\nstill have aspects that fundamentally cannot be described by\nreasonable laws” (Wolfram 2002: 750). This is again the issue of\npredictability via step by step micro-computations. In this\n“separation between the underlying rules for the system and its\noverall behavior” (Wolfram 2002: 751) lies the secret of free\nwill, since it seems that we attribute free will to a system just when\n“we cannot readily make predictions about the behavior of the\nsystem” (Wolfram 2002: 751). According to Wolfram, CA play a\nleading role in providing a new framework to understand the\nphenomenon. While explanations from chaos theory and quantum\nrandomness have recently been proposed (see the entry on\n chaos),\n “nothing like this is actually needed” (Wolfram 2002:\n752). By observing CA, we can understand how something with simple and\ndefinite micro-rules, like those governing our neurons, can produce a\nbehavior free of obvious rules:  \nthe crucial point is that this happens just through the intrinsic\nevolution of the system—without the need for any additional\ninput from outside or from any sort of explicit source of randomness.\n(Wolfram 2002: 752)  \nWolfram’s point is similar to some of Dennett’s remarks,\nnamely: taking some sort of “design stance”, Wolfram\nsuggests that one can talk about a cellular automaton as if it just\n“decides” to do this or that—“thereby\neffectively attributing to it some sort of free will” (Wolfram\n2002: 752). One easily sees the closeness to Dennett’s famous\nintentional stance (Dennett 1987; see the entry on\n intentionality,\n esp. Section 9). \nHow important are CA to these accounts? Dennett and Wolfram both use\nCA as intuition pumps. However, their positions seem to be slightly\ndifferent. For while the former sees CA as a “useful\ntoolkit” to develop intuitions and vividly illustrate his\narguments (Dennett 2003: 40), the latter claims that CA provides a\n“new kind of intuition”, one that “no branch of\neveryday experience” could provide (Wolfram 2002: 41).  \nThe importance Wolfram attaches to CA seems to rely on a single,\ngeneric “indispensability argument” to the conclusion that\nCA justify the foundation of “a new kind of science”\n(Wolfram 2002: 7–16). We can reconstruct this argument as\nfollows: \n (NKS1)\n is to be taken at face value. It entails that the concepts involved\nwere not previously known. Wolfram talks in terms of “the single\nmost surprising scientific discovery I have ever made” (Wolfram\n2002: 27). Is\n (NKS1)\n true? For sure, the idea that a deterministic and simple system may\nproduce unpredictable behavior started circulating in the scientific\ncommunity well before Wolfram’s work. Signs of what is now chaos\ntheory can be traced back to the 19th and early 20th century, e.g., to\nthe work of Poincaré 1914. One might grant that CA allowed the\ndiscovery that simple systems may produce complex\nbehavior via the proof that they have unpredictable emergent\ncomputational complexity (although this discovery itself, as outlined\nin our brief historical section, was not made but only greatly\npublicized by Wolfram). Why was this discovery not made earlier?\nWolfram’s own diagnosis is twofold: on the one hand, we have the\n“engineering” intuition that to produce something complex\nwe should build something complex—that is because this is how\nordinary machines work. On the other, CA were not obviously connected\nto any established discipline, and therefore they were not studied in\nacademic circles.  \nAs for\n (NKS2),\n we just examined the case of free will. In Wolfram’s\nperspective, free will looks just like another puzzling philosophical\nphenomenon explained away by the advance of (a new kind of) science.\nJust as life was puzzling before the discovery of the double helix,\nfree will was puzzling before the discovery of a suitable scientific\ntheory, one that can finally account for the separation between micro\nand macro level. Many reductionist philosophers are no strangers to\nthis kind of argument. The concepts and intuitions used in\ncontemporary philosophy are often rooted in current scientific\npractices. When groundbreaking discoveries are made, old arguments may\nbe revised: troublesome concepts become harmless and new challenges\nare introduced. From this perspective, Wolfram’s account of the\nfree will problem may lack philosophical rigor, but it is a promising\nstart to re-address the challenge armed with new scientific models of\ndeterminism and complexity—pretty much as Dennett does. While\nmany successful applications are needed to fully vindicate\n (NKS2),\n our first assessment concludes that, at the very least, it is not\nobviously false. As for the “new regularities” promised by\n (NKS2),\n we will address them in the next section.  \nCA are computational systems that perform complex tasks on the basis\nof the collective behavior of simple items. What, if anything, does it\ntell us about the importance of computation for systems in nature?\n \nDifferent conclusions have been drawn by practitioners in the field.\nSome have endorsed the more modest claim that the computational\nfeatures of CA are important to understand and compare social,\nbiological, and physical systems modeled by them; but others have\ntaken CA to support the view that computation and information\nprocessing in a discrete setting lie at the very foundations of\nreality. We will explore the stronger claim in\n Section 3.4\n below. As for the weaker claim, it is not possible here to address\nthe general importance of computational properties across the sciences\n(see Mitchell 2009: 169–185). We will focus instead on a\nspecific, and controversial, principle put forward by Stephen Wolfram,\nthe so-called “Principle of Computational\nEquivalence”: \nThere are various ways to state the Principle of Computational\nEquivalence, but probably the most general is just to say that almost\nall processes that are not obviously simple can be viewed as\ncomputations of equivalent sophistication. (Wolfram 2002:\n716–717) \nThe Principle is the most fundamental law of Wolfram’s New\nKind of Science, as well as a prominent regularity featured by\n (NKS2):\n “its implications are broad and deep, addressing a host of\nlongstanding issues not only in science, but also in mathematics,\nphilosophy and elsewhere” (Wolfram 2002: 715). Contrary to\nWolfram’s claims, the Principle may not be new to philosophy at\nall. That “all processes can be viewed as computations”\n(Wolfram 2002: 715) has often been argued for in the history of\nphilosophy, just as the claim that universal computation is a\nwidespread phenomenon in the natural world (see, e.g., Searle 1992;\nPutnam 1988 and the entry on\n computation in physical systems).\n However, Wolfram’s explanation of the Principle includes two\nfurther, and more specific, statements: i) No natural system\ncan compute more things than a universal digital computer (see Wolfram\n2002: 730), that is, “universal computation is an upper limit on\nthe complexity of computation” (Mitchell 2009: 157); and\nii) The computations performed by natural systems are\nessentially equivalent in sophistication (see Wolfram 2002:\n719–726). \nThe first point is relevant once we compare digital computation with\nthe idea of a computer working with real numbers in continuous time.\nIt has been proved (see C. Moore 1996) that such a device would be\nable to compute more functions than a traditional Turing machine.\nHowever, proponents of a discrete space-time like Wolfram treat\ncontinuous processes as, in a sense, epiphenomenal, since they already\nhave independent reasons (some of which will be addressed\n below)\n to believe in a fundamentally discrete universe. As for the second\npoint, its main problem is that the interpretation of\n“equivalent sophistication” is not straightforward. For\neven assuming that universal computation is widespread, it does not\nseem to follow that all computation is equivalent in sophistication.\nComplexity scientists, even after having agreed with Wolfram on the\nimportance of computation for social, biological and physical systems,\nand even on the extent to which universal computation is supported in\nnature, are puzzled by his claim: \nI find it plausible that my brain can support universal computation\n(…) and that the brain of the worm C. elegans is also\n(approximately) universal, but I don’t buy the idea that the\nactual computations we engage in, respectively, are equivalent in\nsophistication. (Mitchell 2009: 158) \nIt is not clear what to make of computational equivalence. Yes, there\nis a threshold in which systems are related to one another, but given\nthe difficulty of moving among them, is this any more useful than\nsaying that skateboards and Ferraris are equivalent means of moving\nabout? (Miller & Page 2007: 232) \nMiller and Page argue that, for all scientific purposes,\n“representations do matter, and what can be easily computed in\none system is often difficult (but still possible) to compute in\nanother”. Even if Wolfram is right when he claims that a simple\nautomaton can calculate the first few prime numbers (Wolfram 2002:\n640), the calculation we have to do to encode the input and decode the\noutput is very complex:  \nThis latter calculation could be much more “difficult” to\ncompute than the original problem, just as the complexity of a\ncompiler can far exceed the complexity of the programs it produces.\n(Miller & Page 2007: 232) \nTaking these objections ever further, the crucial consideration is\nthat any system with a large enough state space could be shown to be\n(in Wolfram sense) equivalent to “intelligent systems”.\nFar from supporting some form of universality, Aaronson argues that\nthis type of “equivalence” stems from a misunderstanding\nof the role of computational reductions:  \nSuppose we want to claim, for example, that a computation that plays\nchess is “equivalent” to some other computation that\nsimulates a waterfall. Then our claim is only non-vacuous if\nit’s possible to exhibit the equivalence (i.e., give the\nreductions) within a model of computation that isn’t itself\npowerful enough to solve the chess or waterfall problems. (2011:\n285–286) \nIn other words, unless it can be proved that the encoding/decoding\nfunctions are not doing all the heavy lifting (and just use a\nsecondary system, a waterfall or a CA, to vacuously transmit\ninformation), it is hard to consider the alleged\n“equivalence” meaningful at all: “we are merely\ntrading an infeasible search among programs for an infeasible search\namong input encoding schemes” (Aaronson 2002: 413). Moreover, a\nrationale for studying CA (Ilachinski 2001: 8) is that their\nimplementation can be massively optimized for specific problems with\nsignificant performance gain on standard computers (see for example\nZaheer et al. 2016). Unless Wolfram’s notion of\n“equivalent sophistication” simply means “they\ncompute the same functions”—in which case, the claim is a\ntruism—, the Principle cannot explain this empirical difference.\nThe Principle may have a more substantive reading if understood as a\nmetaphysical thesis about the universe in general, not as a scientific\ngeneralization having merely heuristic value. Under this stronger\nreading, the Principle is no more concerned with particular systems\nthat can be fruitfully analyzed via computation theory, but with the\nfact that (different epistemological properties notwithstanding) the\nworld itself is a computer. In a sense, any system would just be the\nemergent manifestation of a unique, underlying computational reality.\nWhich naturally leads us to finally address the boldest question: What\nif the universe itself was a CA?  \nWhen discussing CA as models of reality we need to carefully\ndistinguish the different meanings of modelling.\n (CA1)\n above\n (section 1.2)\n discussed CA as “models of computation”: CA model\nparallel computations in the rather trivial sense that they\nperform them; for that is what their cells do: they associate\ninputs to outputs by implementing algorithmic functions, together with\ntheir mates. In other words, they model computation as Turing machines\ndo (but, of course, with different underlying ideas).  \n\n (CA2)\n introduced a different sense of modelling for CA, i.e., the\nidea that CA are fruitfully used in current scientific practices to\nstudy an incredible variety of phenomena: chemical systems (e.g.,\nKier, Seybold, & Cheng 2005), urban growth (e.g., Aburas et al.\n2016), traffic flow (e.g., Lárragaa et al. 2005), even warfare\n(e.g., Ilachinski 2004). According to the characterization of\nBarberousse, Franceschelli, and Imbert 2007\n (Other Internet Resources),\n a common technique is the “phenomenological” modelling.\nPhenomenological modelling happens when one models in a direct way,\nthat is, without making use of a previous explanatory theory: one\nlooks at how traffic flows and tries to build a CA that reproduces a\nsufficiently similar behaviour and allows to make useful predictions.\nThe key question for modellers here is,  \nAre there well established correspondence rules that I can use to\ntranslate features of the system I want to model into specifications\nfor an adequate cellular automaton model of it? (Toffoli &\nMargolus 1990: 244)  \nIn this sense, CA modelling is a special case of “agent-based\nmodelling” (Miller & Page 2007): the modeller starts with\nmicro-rules to explore macro-behavior (for examples in social\nsciences, see the classic Schelling 1978).  \nStarting from\n (CA2),\n it is natural to ask whether it is possible to push the boundaries\neven further, i.e., using CA to model more “fundamental”\nparts of reality. For example Toffoli 1984 conjectures that CA may\nallow us to replace physical modelling with differential\nequations (and related notions of real variables, continuity, etc.).\nComputations with differential equations, Toffoli claims, are: \nat least three levels removed from the physical world that they try to\nrepresent. That is, first (a) we stylize physics into differential\nequations, then (b) we force these equations into the mold of discrete\nspace and time and truncate the resulting power series, so as to\narrive at finite difference equations, and finally, in order to commit\nthe latter to algorithms, (c) we project real-valued variables onto\nfinite computer words (“round-off”). At the end of the\nchain we find the computer – again a physical system;\nisn’t there a less roundabout way to make nature model itself?\n(Toffoli 1984: 121) \nSuch a less roundabout way can be provided, so the proposal goes, by\nCA. We see here a path, from the view that CA are useful as a\nphenomenological heuristic to predict the behaviour of some aspects of\nreality, to the claim that CA modelling may, in a sense, be closer to\nthe underlying physics than any non-discrete alternative, as\nanticipated in\n (CA4)\n above.  \nWe are now ready to move to the final step, taking us into speculative\nmetaphysics of physics. In the last fifty years various scientists\n(see Zuse 1982; Fredkin 1993; Wolfram 2002) have advanced a bold\nconjecture: that the physical universe is, fundamentally, a\ndiscrete computational structure. Everything in our\nworld—quarks, trees, human beings, remote galaxies—is just\na pattern in a CA, much like a glider in Life.  \nOne may dispute the very meaningfulness of claims of this kind,\nconcerning the world as a whole: something that, to speak Kantian, is\nnever given to us in experience. Floridi 2009 has argued against such\ndigital ontology, not by defending a continuous picture of reality,\nbut by arguing that the world is not the right kind of thing to which\nsuch notions as discreteness and continuity can meaningfully apply.\nThese concern rather, in Kantian fashion, our ways of modelling\nreality, or “modes of presentation of being”. If one, on\nthe contrary, thinks that there must be a fact of the matter about the\ndiscrete vs. continuous nature of the world (as argued in Berto &\nTagliabue 2014, on the basis of considerations from cardinality and\ngeneral mereology [see entry on\n mereology]),\n then the next issue is: what does (the philosophy of) fundamental\nphysics have to say about this? It is fair to claim that the issue is\nopen. Scholars such as Nobel prize winner ’t Hooft (1997)\nseriously explore discretist views, and approaches based on so-called\ncausal set theory (see Dowker 2003; Malament 2006) take the geometry\nof real-world spacetime as such that at the Planck length\n(\\(10^{-33}\\) cm) it is discrete. Cognate strategies take spacetime as\nmade of polysimplexes, usually polydimensional counterparts of\ntetrahedra (see Ambjorn et al. 2004) ; adding the claim that such\npolysimplexes compute functions takes us already in the vicinity of\nCA. Other scholars, instead, are against the idea of a digital world.\nDeutsch (2005) and Hardy (2005) reject the view that quantum\nprobabilities and quantum computing vindicate a discrete structure of\nspace-time, and claim that quantum mechanics complies with the idea\nthat the world is continuous even more than classical physics. While\nwe are, thus, in the realm of speculation, we can nevertheless single\nout two main reasons to investigate the provocative claim that the\nworld is a discrete CA. First, the arguments put forward to support\nthe view may be philosophically interesting in themselves. Second, the\nontological structure of a CA-world can be fruitfully compared to\nexisting metaphysical accounts. Let us take each point in turn.  \nThe picture of nature as a CA is supported by an epistemological\ndesideratum, i.e., having exact computational models of the\nphysical world (see for instance the discussion of ontic\npancomputationalism in the entry on\n computation in physical systems).\n While this is certainly one of the arguments involved, it is not the\nonly one and probably not the strongest. As Piccinini points out, even\nsomeone who shares that desire “may well question why we should\nexpect nature to fulfill it” (Piccinini 2010: Section 3.4).  \nIlachinski proposes a different “argument from\nepistemology” (Ilachinski 2001: 661–2). Let us consider\nagain the space-time diagram of Rule 110:  \nFig. 7 \nLet us imagine we ignore its being generated by the iteration of a\nsimple local rule, or even that it is an automaton. Then, says\nIlachinski:  \nNoticing that the figure consists of certain particle-like objects\nsprinkled on a more-or-less static background, the simplest (most\nnatural?) thing for you to do (…) is to begin cataloging the\nvarious “particles” and their “interactions.”\n(…) What you almost assuredly will not have, is any idea that\nthe underlying physics really consists of a single—very\nsimple—local deterministic rule(…). How different is\nthis alien two-dimensional world from our own? (Ilachinski 2001:\n662). \nThis highlights how CA may generate situations that we view as\nphysically realistic. But one may consider this as a mere suggestion:\nthat we cannot rule out a priori our universe’s being,\nat its bottom level, a CA does not entail that it actually is\na CA.  \nA firmer ground to explore the hypothesis comes from some independent\nreasons of theoretical dissatisfaction with contemporary physics. We\nwill limit ourselves to what we may call conceptual\ncomplaints, as opposed to ones more closely related to scientific\npractice, such as the failure of reductions of quantum mechanics and\nrelativity to a Theory of Everything. We will examine the\nfollowing three: (i) the problem of infinity, (ii)\nthe need for a transparent ontology, (iii) the physical role\nof information.  \nAs for complaint (i): while infinite and infinitesimal\nquantities provide us with powerful tools to model and advance\npredictions on the physical world, it remains controversial what\nontological conclusions should be drawn from this fact. Since the\ndiscovery of\n Zeno’s Paradox (see entry),\n the continuity of space-time, as well as other fundamental physical\nvariables, have puzzled philosophers and scientists alike. In the\nwords of the physicist Richard Feynman:  \nIt bothers me that, according to the laws as we understand them today,\nit takes a computing machine an infinite number of logical operations\nto figure out what goes on in no matter how tiny a region of space,\nand no matter how tiny a region of time. How can all that be going on\nin that tiny space? Why should it take an infinite amount of logic to\nfigure out what a tiny piece of space-time is going to do? So I have\noften made the hypothesis that ultimately physics will not require a\nmathematical statement, that in the end the machinery will be revealed\nand the laws will turn out to be simple, like the checker board with\nall its apparent complexities. (Feynman 1965) \nOne way theoretical physicists have approached the problem is to\nconjecture a fundamental layer of reality along the lines of Edward\nFredkin’s “Finite Nature Hypothesis”:  \nFinite Nature is a hypothesis that ultimately every quantity of\nphysics, including space and time, will turn out to be discrete and\nfinite; that the amount of information in any small volume of\nspace-time will be finite and equal to one of a small number of\npossibilities. (…) We take the position that Finite Nature\nimplies that the basic substrate of physics operates in a manner\nsimilar to the workings of certain specialized computers called\ncellular automata. (Fredkin 1993: 116) \nIf a cellular automaton is a model satisfying this hypothesis, then\n“underneath the laws of physics as we know them today it could\nbe that there lies a simple program from which all the known laws\n(…) emerge” (Wolfram 2002: 434). If, as we have seen\nabove, currently there is no agreement on the issue whether physical\nreality is fundamentally continuous or discrete, at least the Finite\nNature Hypothesis seems to be a no less falsifiable prediction (see\nFredkin 1990) than many speculative metaphysical pictures.\nUnfortunately, although we have attempts to recapture field theory\nwithin CA theory (see, e.g., Svozil 1987, Lee 1986), there is no\nagreed-upon derivation of today’s continuous physics within a CA\nframework; it is therefore safe to say that no party has a clear\nadvantage here. \nAs for complaint (ii): one reason to adopt the view of CA as\nmodels of a fundamentally discrete world is the desire for a\ntransparent ontology. Take a materialist philosopher for whom the task\nof physics is to provide an ultimate description of reality on the\nbasis of a handful of basic physical properties and relations. As\nargued in Beraldo-de-Araújo & Baravalle forthcoming, a\ndigital ontology may take different models of computation at its\nfoundation: by analyzing the ontological commitments of CA (vs.\ntraditional Turing machines), they conclude that CA are very close to\nsupporting a traditional form of physicalism. In this perspective, a\nCA-based physics may provide a neat and elegant ontological picture:\none that would be describable in a first-order formal theory including\nthe axioms of standard\n mereology (see entry)\n (even of mereotopology, as presented, e.g., in Casati, Varzi 1999),\nand whose theorems would be computable in finite time (see Berto,\nRossi, Tagliabue 2010: 73–87). Besides, CA make easier to\nreconcile prima facie contradictory properties of different physical\nlaws, such as the reversibility of micro-laws and the\nirreversibility of the Second Law of Thermodynamics (see for\nexample Wolfram 2002: 441–457; Berto, Rossi, Tagliabue 2010:\n43–46). There is no agreement on whether the Second Law gives us\na fundamental feature of physical reality, or it is a spin-off of\nunderlying principles which are time-reversal invariant and act on an\ninitial state of the universe at low entropy (see Albert 2000). If the\nworld is discrete and temporal reversibility is fundamental,\nreversible CA like, e.g., that of Berto, Rossi, Tagliabue (2016) may\nbe more than mere computational tools achieving some degree of\ncomputational efficiency via their reversibility.  \nAs for point (iii), concerning the physical role of\ninformation: CA can accommodate a speculative hypothesis entertained\nby a number of scientists (Wheeler 1990, Ilachinski 2001) and\nphilosophers (Chalmers 1996), namely that information is not just one\naspect of the physical world, but, in a sense, the most fundamental.\nFor instance, Fredkin’s Finite Nature Hypothesis not only\nstresses the importance of the informational aspects of physics, but\n“it insists that the informational aspects are all there is to\nphysics at the most microscopic level” (see Fredkin 1993).  \nOne way in which this idea has been developed is the so-called\n“it from bit” theory (see again Wheeler 1990). In\nDavid Chalmers’ words, this approach “stems from the\nobservation that in physical theories, fundamental physical states are\nindividuated as informational states” (Chalmers 1996:\n302). Physics is silent on what accomplishes the specified functional\nroles, so “any realization of these information states will\nserve as well for the purpose of a physical theory” (Chalmers\n1996: 302). The “it from bit” approach is particularly\nappealing to Chalmers as a philosopher of mind committed to\nqualia being intrinsic, non-reducible properties, because it\nallows for a simple unification: we need intrinsic properties to make\nsense of conscious experience, and we need intrinsic properties to\nground the informational states that make up the world’s\nphysics. If we claim that all the informational states are grounded in\nphenomenal or proto-phenomenal properties, we “get away with a\ncheap and elegant ontology, and solve two problems in a single\nblow” (Chalmers 1996: 305). The cell states in a CA fit the\nbill: if we interpret them as proto-phenomenal properties, we obtain\nthe intrinsic structure of some sort of computational neutral monism\n(for an historical introduction, see the entry on\n neutral monism). \nAlbeit individually controversial, taken together the three points\nsupport a simple and elegant metaphysical picture which is not\nevidently false or incoherent.  \nSupposing that the actual physical world is a giant, discrete\nautomaton, are there philosophically interesting conclusions to be\ndrawn? A first one has already been partially explored in connection\nwith Life: if nature is a CA, it has to be a\nuniversal CA, given that universal computers (e.g., the one\non which you are probably reading this entry) uncontroversially exist\nin the physical world. Then its evolution is algorithmically\nirreducible, given the Halting Problem. Notwithstanding the\nopportunity of devising approximate forecast tools, we are left with a\nuniverse whose evolution is unpredictable for a reason quite different\nfrom the ones commonly adduced by resorting to standard physics, such\nas quantum effects or random fluctuations: it is unpredictable just\nbecause of its computational complexity.  \nA second philosophical topic is the connection between a CA-world and\none of the most famous and controversial contemporary metaphysical\ntheses, namely David Lewis’ Humean Supervenience (HS).\nUsing Ned Hall’s characterization (see section on\n Humean supervenience in the entry on David Lewis’s metaphysics),\n we can state HS as the collection of these four claims about the\nstructure of our world: \nIf we substitute “space-time points” with\n“cells”, HS gets very close to a CA ontology: cells are\narranged in a lattice, have various spatiotemporal relations to one\nanother (e.g., being a neighborhood of), and have monadic\nproperties (states) which can be considered perfectly\nnatural, i.e., the basic properties out of which any other can be\nconstrued. A CA universe is thus a prima facie abstract model\nof Lewis’ HS and can be fruitfully used to illustrate\nLewis’ original point, which was a reductionist one:  \nThe point of defending Humean Supervenience is not to support\nreactionary physics, but rather to resist philosophical arguments that\nthere are more things in heaven and earth than physics has dreamt of.\n(Lewis 1994: 474). \nThere are, however, two differences between the ontology naturally\nsuggested by CA theories and Lewis’ view. First, for Lewis\nspace-time is an essentially continuous, four-dimensional manifold,\neternalistically conceived (see the section on eternalism in the entry\non\n time\n and the discussion on four-dimensionalism in the entry on\n temporal parts\n for an introduction), while in a standard CA-driven ontology, it is\nnot. Second, Lewis reduces laws of nature to particulars while, as we\nhave seen in Section 2 above, CA rules are always included as a\nfurther specification of the model. \nThe first disagreement may not be very substantial. A CA-world is\ncompatible, for instance, with an eternalist conception. The idea that\nthe world’s next state is computed at any time step can be seen\nas a merely heuristic device, a “shortcut” for a more\nproper eternalist description in which the cell’s states are\nonce and for all “stuck” in their space-time position (we\ndid this ourselves when describing the first picture in this section\nas the complete space-time evolution of a micro-universe).  \nThe second disagreement concerning the laws of nature may instead be a\nthorny issue. According to Lewis 1973, laws of nature are the true\ngeneralizations found in the deductive system that best describes our\nworld (where “best” basically refers to the optimal\ntrade-off between strength and simplicity; see the entry on\n laws of nature\n for an introduction to, and further details on, this debate): laws of\nnature supervene on the four-dimensional arrangement of particulars\nand their properties. To the contrary, the standard description of a\nCA does not take the space-time evolution for granted: it takes the\nautomaton’s initial conditions as given, and generates the\nsystem evolution over time via the CA transition function. Particulars\ndepend on laws, not vice versa. A CA world is not laid out in\nadvance, but it grows as long as the laws are applied to particulars\n(a similar point is also made in Wolfram 2002: 484–486). \nOn the other hand, one may tentatively interpret, in Lewisian fashion,\nthe laws of a CA as the generalizations contained within the deductive\nsystem that best describes the CA behavior. Let us consider one last\ntime our micro-universe from Rule 110:  \nFig. 7 \nA suitable deductive system for this space-time diagram may be\nobtained with just two axioms, one stating the initial conditions of\nthe system, the other phrased as a conditional expressing the CA\ntransition rule. If this conditional is a true generalization embedded\nin the deductive system that best describes our toy universe, then\nRule 110 can count as a Lewisian law of nature in this\nuniverse, as expected. \nAlthough some CA topics are still relatively untouched by philosophers\n(e.g., the nature of space and time (see Wolfram 2002: 481–496),\nthe representation of knowledge in Artificial Intelligence (see Berto,\nRossi, Tagliabue: 15–26), the relationship between information\nand energy (see Fredkin & Toffoli 1982)), there are many\nconceptual challenges raised in connection with CA. While in some\ncases the CA contribution was indeed overrated by practitioners, in\nothers CA proved to be useful models of important phenomena. \nAs a final comment: what is left, from a purely scientific\nperspective, of the NKS Argument? Let us go through it\nagain: \nEven granting the truth of the two premises (that is, even granting\nthe troublesome Principle of Computational Equivalence), it is\ndoubtful the desired conclusion would follow. Surely, CA have provided\nnew intuitions and explanations for a set of phenomena—Wolfram\nquite successfully applies his “discovery” to biology,\ncomputer science, physics, finance. However, there is no evidence that\nmany of our best scientific explanations will soon be reduced to the\nCA framework, and indeed many aspects of complexity itself still lie\noutside the CA paradigm, with no unification in sight. Paradigm shifts\nusually require the new paradigm to explain the same phenomena the old\none did, and some more. CA are a promising field, but many\ndevelopments are still needed for\n (NKS3)\n to be true.","contact.mail":"fb96@st-andrews.ac.uk","contact.domain":"st-andrews.ac.uk"},{"date.published":"2012-03-26","date.changed":"2017-08-22","url":"https://plato.stanford.edu/entries/cellular-automata/","author1":"Francesco Berto","author2":"Jacopo Tagliabue","author1.info":"http://www.st-andrews.ac.uk/philosophy/people/fb96","entry":"cellular-automata","body.text":"\n\n\nCellular automata (henceforth: CA) are discrete, abstract\ncomputational systems that have proved useful both as general\nmodels of complexity and as more specific representations of\nnon-linear dynamics in a variety of scientific fields. Firstly, CA are\n(typically) spatially and temporally discrete: they are\ncomposed of a finite or denumerable set of homogenous, simple units,\nthe atoms or cells. At each time unit, the cells\ninstantiate one of a finite set of states. They evolve in parallel at\ndiscrete time steps, following state update functions or dynamical\ntransition rules: the update of a cell state obtains by taking into\naccount the states of cells in its local neighborhood (there are,\ntherefore, no actions at a distance). Secondly, CA are\nabstract: they can be specified in purely mathematical terms\nand physical structures can implement them. Thirdly, CA are\ncomputational systems: they can compute functions and solve\nalgorithmic problems. Despite functioning in a different way from\ntraditional, Turing machine-like devices, CA with suitable rules can\nemulate a universal\n Turing machine (see entry),\n and therefore compute, given Turing’s thesis (see entry on\n Church-Turing thesis),\n anything computable.\n\n\nThe mark of CA is in their displaying complex emergent behavior,\nstarting from simple atoms following simple local rules. Because of\nthis, CA attract a growing number of researchers from the cognitive\nand natural sciences willing to study pattern formation and complexity\nin a pure, abstract setting. This entry provides an introduction to CA\nand focuses on some of their philosophical applications: these range\nfrom the philosophy of computation and information processing, to\naccounts of reduction and emergence in metaphysics and cognition, to\ndebates around the foundations of physics.\n\n\nWe will proceed as follows. In the introductory Section 1, CA are\nfirst explained via an example: Section 1.1 describes a simple\none-dimensional automaton displaying an intuitively manifest behavior.\nSections 1.2–1.3 provide a short survey of the history and main\napplications of CA.\n\n\nIn Section 2, the general theory of CA is explained, together with a\nselection of computational and complexity-theoretic results in the\nfield. Section 2.1 provides a fourfold schematic definition of CA.\nSections 2.2–2.3 explain the classification of one-dimensional\nCA proposed by Stephen Wolfram. Section 2.4 introduces the Edge of\nChaos hypothesis, a key CA-related conjecture in complexity theory.\nSections 2.5–2.7 generalize to automata occupying more than one\nspatial dimension, and/or relaxing some parameters in the definition\nof 2.1. We focus on the Game of Life—possibly the most popular\nCA—and its computational capabilities. \n\n\nSection 3 describes four main uses of CA in philosophical\ninvestigation. Firstly, since CA display complex behavioral patterns\nemerging from simple local rules, they have been naturally linked to\nemergence: this topic is dealt with in Section 3.1, where\ndifferent notions of emergence are considered. Secondly, Section 3.2\nexplores how CA have been put to work, both by philosophers and by\nscientists, to address the traditional philosophical problems of\nfree will and determinism. Thirdly, Section 3.3\ndescribes the impact of CA theories on the philosophy of computation.\nFinally, Section 3.4 addresses ontological issues ranging from the\nsense in which CA count as modelling portions of reality, to the bold\nphilosophical conjecture of some scientists, who claim that the\nphysical world itself may be, at its bottom, a discrete, digital\nautomaton. \n\nWe introduce CA using a simple example. Think of an automaton as a\none-dimensional grid of simple elements (the cells). Each of them can\nonly instantiate one of two states; let us say that each cell can be\nturned on or off. The evolution of the system is\ndetermined by a transition rule, to be thought of as implemented in\neach cell. At each time step, each cell updates its status in response\nto what happens to its neighboring cells, following the rule. \nFig. 1 \nAlthough CA are abstract, having a concrete instance in mind can help\nin the beginning. So think of\n Fig. 1\n as representing the front row of a high school classroom. Each box\nstands for a student wearing (black) or not wearing (white) a hat. Let\nus make the two following assumptions:  \nHat rule: a student will wear the hat in the following class\nif one or the other—but not both—of the two classmates\nsitting immediately on her left and on her right has the hat in the\ncurrent class (if nobody wears a hat, a hat is out of fashion; but if\nboth neighbors wear it, a hat is now too popular to be trendy).  \nInitial class: during the first class in the morning, only\none student in the middle shows up with a hat (see\n Fig. 2). \nFig. 2 \n\n Fig. 3\n shows what happens as time goes by. Consecutive rows represent the\nevolution in time through subsequent classes.  \nFig. 3 \n\n Fig. 3\n may be surprising. The evolutionary pattern displayed contrasts with\nthe simplicity of the underlying law (the “Hat rule”) and\nontology (for in terms of object and properties, we only need to take\ninto account simple cells and two states). The global, emergent\nbehavior of the system supervenes upon its local, simple features, at\nleast in the following sense: the scale at which the decision to wear\nthe hat is made (immediate neighbors) is not the scale at which the\ninteresting patterns become manifest.  \nThis example is a paradigmatic illustration of what makes CA appealing\nto a vast range of researchers:  \neven perfect knowledge of individual decision rules does not always\nallow us to predict macroscopic structure. We get macro-surprises\ndespite complete micro-knowledge. (Epstein 1999: 48)  \nSince the notion of emergence and the micro-macro interplay\nhave such an important role in science and philosophy (see the entries\non\n supervenience\n and\n emergent properties;\n for a sample of scientific applications, see Mitchell 2009:\n2–13; Gell-Mann 1994: Ch. 9), it has been suggested that many\nscientific as well as conceptual puzzles can be addressed by adopting\nthe CA perspective. Stephen Wolfram has gone as far as claiming that\nCA may help us to solve longstanding issues in philosophy:  \nThese are very bold claims. In order to assess them, let us take a\ncloser look at the field.  \nThe surprising patterns in the aforementioned classroom example were\ngenerated by boxes in a line with just two states and a simple rule.\nOne may wonder how many variations are possible on such a basic\nframework. To address this issue, let us begin by considering how\nAndrew Ilachinski, in his review of the literature, narrows down CA\napplications to four main areas, which will be referred to in the rest\nof this entry (Ilachinski 2001: 7):  \n\n (CA1)\n emphasizes that CA perform computations. Just like Turing machines,\nthey can be specified in mathematical terms, and implemented in\ndifferent physical systems. However, CA are peculiar in two important\nways. First, unlike Turing machines and von Neumann-architecture\nconventional computers, CA compute in a parallel, distributed\nfashion. Second, computation is pretty much “in the eye of the\nbeholder”: there is no tape, but the evolution of the\ncells’ states can often be interpreted as a meaningful\ncomputational procedure (e.g., bits can be encoded using the\nwhite/black cell states). Computational hardware\ninspired by CA can help solve important technological problems (see\n Ilachinski 2001: 8), but apart from engineering issues,\n (CA1)\n also points to major conceptual questions, such as how exactly a\nuniversal Turing machine and an automaton can be rigorously compared\n(see Beraldo-de-Araújo & Baravalle forthcoming) and what\nare, if any, the philosophical implications of this comparison (see\nWolfram 2002: Ch. 12).  \n\n (CA2)\n comprises scientific applications of CA to the modelling of specific\nproblems—to mention just a few: urban evolution (Batty 2005),\nIsing models (Creutz 1986), neural networks (Franceschetti, et al.\n1992: 124–128), lattice fluids (Barberousse & Imbert 2013),\nbioinformatics (Xiao et al. 2011), and even turbulence phenomena (Chen\net al. 1983). As Ilachinski remarks, for instance, discrete models of\nturbulence show that  \nvery simple finite dynamical implementations of local conservation\nlaws are capable of exactly reproducing continuum system behavior on\nthe macroscale. (Ilachinski 2001: 8)  \n\n (CA3)\n and\n (CA4)\n enter very directly into the philosophical arena: as for\n (CA3),\n Daniel Dennett has resorted to a famous automaton we describe below,\nConway’s Game of Life, to make his point on determinism\nand the attribution of high-level concepts to emergent patterns\n(Dennett 1991, 2003). As for\n (CA4),\n CA can provide an account of microphysical dynamics by representing\ndiscrete counterparts of quantum field theories (see entry on\n Quantum Field Theory)\n alternative to the standard continuous frames. But the more\nphilosophical, and quite bolder, claim in this area is that nature\nitself may be a CA: Edward Fredkin, for instance, has advanced his\n“Finite Nature” hypothesis that our universe is an\nautomaton which, at each time step, digitally and locally processes\nits state for the next time step (see Fredkin 1993). Apart from the\ninterest generated by Fredkin’s claim, entertaining the\nhypothesis raises a number of questions at the crossroads of physics\nand metaphysics (what is a natural law?), epistemology (what are the\nlimits of physical systems predictability?) and the philosophy of\ninformation (what is the role of information in the physical world?).\nWe will address each of these questions in the third Section of this\nentry. \nThe father of CA is John von Neumann (von Neumann 1951). Working on\nself-replication and attempting to provide a reductionist theory of\nbiological development, von Neumann was trying to conceive a system\ncapable of producing exact copies of itself. Now biology prima\nfacie appears to be the realm of fluidity and continuous\ndynamics. But following a suggestion of his colleague Stanislaw Ulam,\nvon Neumann decided to focus on a discrete, two-dimensional system.\nInstead of just black-or-white cells, von\nNeumann’s automaton used 29 different states and rather\ncomplicated dynamics, and was capable of self-reproduction. Von\nNeumann’s CA was also the first discrete parallel computational\nmodel in history formally shown to be a universal computer, i.e.,\n capable of emulating a universal Turing machine and computing all\n recursive functions (see entry).\n  \nIn the early Sixties, E.F. Moore (1962) and Myhill (1963) proved the\nGarden-of-Eden theorems stating conditions for the existence of\nso-called Gardens of Eden, i.e., patterns that cannot appear on the\nlattice of a CA except as initial conditions. Gustav Hedlund (1969)\ninvestigated cellular automata within the framework of symbolic\ndynamics. In 1970 the mathematician John Conway introduced his\naforementioned Life game (Berkelamp, Conway, & Guy 1982),\narguably the most popular automaton ever, and one of the simplest\ncomputational models ever proved to be a universal computer. In 1977,\nTommaso Toffoli used cellular automata to directly model physical\nlaws, laying the foundations for the study of reversible CA (Toffoli\n1977). \nStephen Wolfram’s works in the 1980s contributed to putting the\ngrowing community of CA followers on the scientific map. In a series\nof papers, Wolfram extensively explored one-dimensional CA, providing\nthe first qualitative taxonomy of their behavior and laying the\ngroundwork for further research. A particular transition rule for\none-dimensional CA, known as Rule 110, was conjectured to be\nuniversal by Wolfram. Some twenty years after the conjecture, Matthew\nCook proved that Rule 110 is capable of universal computation\n(Cook 2004; Wolfram 2002 also contains a sketch of the proof).  \nWe are now taking a closer look at CA, focusing on models and results\nof philosophical interest. Although the variety of systems to be found\nin the CA literature is vast, one can generate virtually all CA by\ntuning the four parameters that define their structure:  \nOne can exhaustively describe, for instance, the automaton of our\nclassroom example:  \nA rule for a CA can be expressed as a conditional instruction:\n“If the neighborhood is this-and-this, then turn to state\ns”. One can write the general form of the rule for\none-dimensional CA:  \nWhere \\(\\sigma_{i}(t) \\in \\Sigma = \\{0, 1, \\ldots, k - 1\\}\\) is the\nstate of cell number i at time step t; r\nspecifies the range, that is, how many cells on any side\ncount as neighbors for a given cell; and \\(\\phi\\) is defined\nexplicitly by assigning values in \\(\\Sigma\\) to each of the \\(k^{2r+1}\n(2r + 1)\\)-tuples representing all the possible neighborhood\nconfigurations. For example, with \\(r = 1, \\Sigma = \\{1, 0\\}\\), a\npossible transition rule \\(\\phi\\) can be expressed as in\n Fig. 4\n (with 1 being represented as black, 0 as white):\n \nFig. 4 \nFor a given cell, each triple at the top represents a possible\nneighborhood configuration at t, the cell at issue being the\none in the middle: for each configuration, the square at the bottom\nspecifies the cell’s state at \\(t + 1\\). This is our classroom\nexample: you will have a black cell just in case precisely one of the\nneighbors was black.  \nThis simple representation is also at the core of the widely adopted\nWolfram code (Wolfram 1983), assigning to each rule a number: with\nblack = 1 and white = 0, the bottom row can be read\nas a binary number (01011010); converting to decimal gives you the\nrule’s name (in this case, Rule 90). Since rules for CA\nwith \\(r = 1\\) and \\(k = 2\\) differ just in the bottom row of the\ndiagram, this encoding scheme effectively identifies each possible\nrule in the class. One-dimensional CA with \\(r = 1\\) and \\(k = 2\\) are\namong the simplest CA one can define, yet their behavior is at time\nquite interesting. When Stephen Wolfram started to explore this field\nin the Eighties, that class seemed a perfect fit. With \\(r = 1\\),\nthere are 8 possible neighbors (see\n Fig. 4\n above) to be mapped to \\({1, 0}\\), giving a total of \\(2^8 = 256\\)\nrules. Starting with random initial conditions, Wolfram went on to\nobserve the behavior of each rule in many simulations. As a result, he\nwas able to classify the qualitative behavior of each rule in one of\nfour distinct classes. Repeating the original experiment, we simulated\nthe evolution of two rules for each class of Wolfram’s\nscheme. \nClass1 rules leading to\nhomogenous states, all cells stably ending up with the same value:\n \nRule 250 \nRule 254 \nClass2 rules leading to\nstable structures or simple periodic patterns:  \nRule 4 \nRule 108 \nClass3 rules leading to\nseemingly chaotic, non-periodic behavior:  \nRule 30 \nRule 90 \nClass4 rules leading to\ncomplex patterns and structures propagating locally in the lattice:\n \nRule 54 \nRule 110 \nClass1 comprises the rules that quickly produce uniform\nconfigurations. Rules in Class2 produce a uniform final\npattern, or a cycling between final patterns, depending on the initial\nconfigurations. The configurations produced by members of\nClass3 are pretty much random-looking, although some\nregular patterns and structures may be present.  \nClass4 deserves special attention. If we observe the\nuniverse generated by Rule 110 we see regular patterns\n(although not as regular as in Rule 108) as well as some\nchaotic behavior (although not as noisy as in Rule 90). Now\nthe basic feature a CA needs to perform computations is the capacity\nof its transition rule of producing “particle-like persistent\npropagating patterns” (Ilachinski 2001: 89), that is, localized,\nstable, but non-periodic configurations of groups of cells, sometimes\ncalled solitons in the literature, that can preserve their\nshape. These configurations can be seen as encoding packets\nof information, preserving them through time, and\nmoving them from one place to another: information can\npropagate in time and space without undergoing important decay. The\namount of unpredictability in the behavior of Class4 rules\nalso hints at computationally interesting features: by the Halting\nTheorem (see section in entry on\n Turing machines),\n it is a key feature of universal computation that one cannot in\nprinciple predict whether a given computation will halt given a\ncertain input. These insights led Wolfram to conjecture that\nClass4 CA were (the only ones) capable of universal\ncomputation. Intuitively, if we interpret the initial configuration of\na Class4 CA as its input data, a universal\nClass4 CA can evaluate any effectively computable function\nand emulate a universal Turing machine. As we mentioned above,\nRule 110 was indeed proved to be computationally\nuniversal. \n(See the supplementary document\n The 256 Rules.) \nThe intermediate nature of Class4 rules is connected to the\nidea that interesting complexity, such as the one displayed\nby biological entities and their dynamics, lies in a middle area\nbetween the two extremes of boring regularities and noisy chaos:  \nPerhaps the most exciting implication [of CA representation of\nbiological phenomena] is the possibility that life had its origin in\nthe vicinity of a phase transition and that evolution reflects the\nprocess by which life has gained local control over a successively\ngreater number of environmental parameters affecting its ability to\nmaintain itself at a critical balance point between order and chaos.\n(Langton 1990: 13) \nCA provided not just the intuition, but a formal framework to\ninvestigate the hypothesis. In the late Eighties the “Edge of\nChaos” picture received considerable interest by CA\npractitioners. Packard 1988 and Langton 1990 were the first studies to\ngive to the Edge of Chaos a now well-known interpretation in the CA\ncontext. As Miller and Page put it, “these early experiments\nsuggested that systems poised at the edge of chaos had the capacity\nfor emergent computation” (Miller & Page 2007: 129). The\nidea is simple enough: what happens if we take a rule like Rule\n110 and introduce a small perturbation? If we are to believe the\nEdge of Chaos hypothesis, we should expect the rules obtained by small\nchanges in Rule 110 to exhibit either simple or chaotic\nbehavior. Let us consider a single switch from 1 to 0 or 0 to 1 in the\ncharacteristic mapping of Rule 110. The results are the\nfollowing eight neighboring rules, each differing from Rule\n110 by a single bit (the diagonal in the array, with numbers in\nitalics): \nAt a first approximation, the Edge of Chaos hypothesis is confirmed:\nthree of the eight neighbors are Class3, three are\nClass2, two are Class1: Rule 110 is the\nonly Class4 in the table. To generalize these findings to\nthe entire class of rules for one-dimensional CA, Langton introduced a\nparameter, \\(\\lambda\\), that applies to each \\(\\phi\\): for \\(k = 2\\),\n\\(r = 1\\) (binary-state, unary-range) CA, \\(\\lambda(\\phi)\\) can be\ncomputed as the fraction of entries of the transition rule table that\nare mapped to a non-zero output (see Langton 1990: 14 for the general\ndefinition). In our case this means: \\(\\lambda(\\phi)\\) will be equal\nto the number of ones in the rule column—e.g., \\(\\lambda(\\phi) =\n5/8\\) for \\(\\phi\\) = Rule 110 and \\(\\lambda(\\phi) = 1/2\\) for\n\\(\\phi\\) = Rule 46. Langton’s major finding was that a\nsimple measure such as \\(\\lambda\\) correlates with the system\nbehavior: as \\(\\lambda\\) goes from 0 to 1, the average behavior of the\nsystems goes from freezing to periodic patterns to chaos. Langton\nsingled out 1/2 as the value of \\(\\lambda\\) at which the average\nbehavior first shows evidence of chaos: rules \\(\\phi\\) with\n\\(\\lambda(\\phi) \\sim 1/2\\) were highlighted as being on the Edge (see\nMiller & Page 2001: 133). \nBoth chaotic and complex rules have an average \\(\\lambda\\) value\naround 1/2, thus apparently supporting the Edge of Chaos hypothesis.\nIt is fair to say, though, that some have cast doubts on the\nexplanatory role of parameter \\(\\lambda\\) and the inferences drawn\nfrom it. In particular, the transition region of the Edge of Chaos\nseems to be itself complex. Miller and Page note that “there are\nmultiple edges, not just a single one” (Miller & Page 2007:\n133). Aggregate results do not hold when we analyze individual rules,\neven paradigmatic ones: \nAs the table shows, among the Rule 110 neighbors, some\nchaotic rules \\(\\phi\\) have \\(\\lambda(\\phi) = 3/4\\), some cyclic ones\nhave \\(\\lambda(\\phi) = 1/2\\) and, indeed,  \nevery one of the rules classified as complex in this space has at\nleast one chaotic neighbor with a lower \\(\\lambda\\) value and one with\nhigher value. (Miller & Page 2007: 135)  \nMelanie Mitchell, Peter Hraber and James Crutchfield replicated\nLangton and Packard’s experiments, reporting very different\nresults (Mitchell, Hraber, & Crutchfield 1994). In particular,\nthey report that serious computational phenomena take place much\ncloser to a chaotic \\(\\lambda(\\phi) = 1/2\\) than it was previously\nthought. Apart from technical points, a conceptual flaw in the\noriginal findings is the use of aggregate statistics, which are\ndifficult to interpret in a high variance context:  \nif, instead, the hypotheses are concerned with generic, statistical\nproperties of CA rule space—the “average” behavior\nof an “average CA” at a given \\(\\lambda\\)—then the\nnotion of “average behavior” must be better defined.\n(Mitchell, Hraber, & Crutchfield 1994: 14).  \nWhile it is fair to conclude that complex behavior does not lie at the\nEdge of Chaos taken in a simplistic sense (i.e., it is not\nstraightforwardly correlated with the simple \\(\\lambda\\)), the\ninterest in the connection between computational capabilities and\nphase transitions in the CA rule space has been growing since then. We\nwill consider such developments below, specifically in the context of\nCA and the philosophy of computation.  \nNotwithstanding the computational interest of one-dimensional CA,\nphilosophical issues have been discussed more often in connection with\ntwo-dimensional CA. The first CA, von Neumann’s self-reproducing\nautomaton, inhabited a two-dimensional grid. Besides, two-dimensional\nCA are suitable for representing many physical, biological, and even\nhuman phenomena, ranging from the dynamics of perfect gases to the\nmovements of birds in a storm and soldiers on a battlefield. The most\ncommon configurations have either square or hexagonal cells, given\ntheir translational and rotational symmetries. Moving to two\ndimensions, of course, also expands the possibly interesting\ncombinations of rules and neighborhoods. As for the latter, the two\nmost common options in a grid of squares are the von Neumann\nneighborhood, where each cell interacts only with its four horizontal\nand vertical adjacent mates, and the Moore neighborhood,\ncomprising all the eight immediately adjacent cells. \nBy way of example, we introduce the famous Game of Life (or,\nmore briefly, Life) by John Conway (see Berkelamp, Conway,\n& Guy 1982). Life fits well with our usual schema:  \nLife would definitely be considered a Class4 CA by\nWolfram’s taxonomy. In this simple setting, periodic structures,\nstable blocks and complex moving patterns come into existence, even\nstarting from a very simple initial configuration. Conway remarked:\n \nIt’s probable, given a large enough Life space,\ninitially in a random state, that after a long time, intelligent,\nself-reproducing animals will emerge and populate some parts of the\nspace. (cited in Ilachinski 2001: 131)  \nLife-fans explored the CA’s possible patterns of\nevolution, and shared their findings in what has been called\nLife’s zoology (Dennett 2003: 41). Here is a small\ngallery of samples together with snapshots of a typical simulation\n(for more pictures and animations, see\n Other Internet Resources\n at the end). Gliders are the most popular among the basic\nLife inhabitants: a simple 5-bit structure, a glider can\ntravel the Life grid in a 4-time step cycle: \nGlider \n\\(t_{0}\\) \n\\(t_{1}\\) \n\\(t_{12}\\) \nToads are period 2 blinking configurations: together with\nBlinkers and Beacons they are the simplest\noscillators of the universe.  \nToad \n\\(t_{0}\\) \n\\(t_{1}\\) \n\\(t_{3}\\) \nEaters have the feature of devouring other configurations,\ne.g., gliders, maintaining intact their own form (because of this,\nthey play an important role for Life’s computational\nabilities). \nAn Eater devouring a Glider \n\\(t_{0}\\) \n\\(t_{2}\\) \n\\(t_{4}\\) \nA typical evolution of Life starting from random initial\nconditions may contain all of the above notable figures and much more.\nSome initial configuration may end up, even after few time steps, into\nstatic or simple periodic structures. Other configurations, though,\ncan produce non-periodic, increasingly complex environments whose\ndevelopment can be unpredictable (even in the computational sense we\nare about to explore). As Ilachinski has suggestively conjectured from\nthis:  \nUpon observing the seemingly unlimited complexity and variety of\nLife’s evolving patterns, it becomes almost impossible\nto refrain from imagining, along with Conway, that, were the game\nreally to be played on an infinite lattice, there must surely arise\ntrue living “life-forms”, perhaps themselves evolving into\nmore complex, possibly sentient, “organisms”. (Ilachinski\n2001: 133) \n\\(t_{0}\\) \n\\(t_{10}\\) \n\\(t_{20}\\) \n\\(t_{30}\\) \n\\(t_{40}\\) \n\\(t_{175}\\) \nThe mathematical literature on CA does not refrain from describing the\nLife configurations using the same imaginative vocabulary we\nused: items are born, live, move around,\neat other figures, die, etc. The universe these\npatterns inhabit may also be described, though, as a collection of\nindividual cells, each of which does not directly depend on what is\nhappening on the macro-scale. And the life on Life can also\nbe described in the simple mathematical language of matrices and\ndiscrete sequences. But if one is only told the basic Life\nrule, one could hardly imagine the complexity it can\ngenerate—until one sees it. Life’s reputation\namong scientists and philosophers arguably comes from its challenging\nnaive intuitions about complexity, pattern formation and reality,\npersistence, and continuity: as a toy universe we ourselves built, we\nfeel we should know in advance what dynamics are allowed. This has\nbeen shown to be impossible, in a mathematically precise sense. \nLike any other CA, Life can be considered a computational\ndevice: an initial configuration of the automaton can encode an input\nstring. One can let the system run and, at some point, read the\ncurrent configuration as the result of the computation performed so\nfar, decoding it into an output string. But exactly what can\nLife compute? It turns out that Life can compute\neverything a universal Turing machine can and therefore, taking on\nboard Turing’s Thesis, function as a general purpose computer: a\nsuitable selection of initial conditions can ensure that the system\ncarry out arbitrary algorithmic procedures.  \nThe proof of the universal computational capacities of Life\npresented in Berkelamp, Conway, and Guy 1982 consists in showing that\nthe basic building blocks or primitives of standard digital\ncomputation can be emulated by appropriate patterns generated by\nLife—in particular: (a) data storage or memorization,\n(b) data transmission requiring wires and an internal clock, and (c)\ndata processing requiring a universal set of logic gates, like\nnegation, conjunction and disjunction—an actual Turing machine\nwas later explicitly implemented in Life by Paul Rendell (see\n Other Internet Resources). \nThis finding is not of great engineering importance (no one would\nspend their time translating “\\(24 + 26 / 13\\)” into\nLife). However, it raises a conceptual issue about any\nuniverse sharing the capacity of producing and hosting universal\ncomputers: because of the aforementioned Halting Theorem, no general\nalgorithm is to decide whether, given some initial configuration as\ninput, Life will eventually die out or halt. It is in this\nsense that the evolution of the automaton is unpredictable. Given that\nthe development of CA that are computationally universal cannot be\npredicted by direct mathematical analysis alone, it is no surprise\nthat CA practitioners have adopted the language of philosophy and\ntalked of phenomenological studies of CA (we will come back\nto this terminology in more detail in\n Section 3.4\n below, discussing how CA model whatever they can model). Here the\nautomaton is realized as a computer software, and the observable\nemergent properties of its evolution are empirically registered as the\ncomputer simulation advances. In Wolfram’s turn of phrase,\nLife is algorithmically irreducible: no algorithmic\nshortcut is available to anticipate the outcome of the system given\nits initial input. “Life—like all computationally\nuniversal systems—defines the most efficient simulation of its\nown behavior” (Ilachinski 2001: 15). This raises the important\nphilosophical question of the limits of the predictability of any\nuniverse capable, just as Life is, of producing and hosting\nuniversal computers.  \nNotwithstanding the historical and conceptual centrality of the CA\ndescribed in this section, many important developments in the field\ncould not be presented in the space allowed for this entry. One can\nrelax some of the assumptions in the general characterization of CA\nprovided in\n Section 2.1\n and get interesting results. The transition rule can be\nprobabilistic and take into consideration more than just one\ntime step (see Richards, Meyer, & Packard 1990: probabilistic\nautomata are widely used to represent the stochastic dynamics of\nmicrophysical systems); the cell state updating can be\nasynchronous (see Ingerson & Buvel 1984); the lattice can\nbe made of non-homogenous cells following different\ntransition rules (see Kauffman 1984); even the discreteness constraint\ncan be relaxed by having the set of states be the set of real\nnumbers (see Wolfram 2002: 155–157). \nCA are also being fruitfully used in connection to the issue of the\nthermodynamic limits of computation: is there a minimum amount of\nenergy needed to perform a logical operation? Landauer (1961) argued\nthat irreversible logical operations (i.e., operations that, not\ncorresponding to bijections, cannot be run backwards as they entail\nsome information loss) necessarily dissipate energy. The invention of\nthe Fredkin reversible logical gate and of the Billiard Ball Model of\nreversible computation (Fredkin & Toffoli 1982) strengthened the\nimportance of the link between universal reversible automata and the\nphysical properties of computation (for an overview, see Ilachinski\n2001: 309–323; for a sample reversible CA, see Berto, Rossi,\n& Tagliabue 2016). \nFinally, it is worth mentioning that genetic algorithms have\nbeen used with CA to study how evolution creates computation (for a\nsurvey of important results, see Mitchell, Crutchfield, & Das\n1996). While the aforementioned sources further explore these\npossibilities, the sample CA models discussed so far will be\nsufficient for the philosophical arguments we are going to address\nhenceforth. \nA growing number of CA-related philosophical arguments are being\nproduced, both by philosophers and by scientists interested in the\nconceptual implications of their work. Among the interesting issues\naddressed through the CA approach in the philosophical market are the\nstructure of emergence, free will, the nature of computation, and the\nphysical plausibility of a digital world.  \nCA can be considered a paradigmatic locus for the study of phenomena\nrelated to emergence (for an introduction, see the entry on\n emergent properties).\n One can initially divide the problem of emergence into two separate\nquestions, roughly corresponding to epistemological and ontological\nissues: How can we recognize emergence? What is the\nontological status of the high-level properties and features?\nAs a matter of historical fact, CA have been invoked mainly to address\nthe former, but we will see in\n Section 3.4\n below that there is work for CA also on the ontological side. \nEpistemological issues have often been raised in connection with\ncomplex systems in general. In their open agenda for complex social\nsystems, Miller and Page include the following question: “Is\nthere an objective basis for recognizing emergence and\ncomplexity?” (Miller & Page 2007: 233–234). The\nliterature on CA has variously addressed the issue. On the one hand,\nbeing a low-level simple and controllable environment, CA present\nthemselves as a natural framework for tackling the problem in its\npurest form. On the other hand, CA researchers have recognized how the\nsystemic and global features of a complex CA system can be hard to\npredict even with perfect knowledge of low-level entities and laws:\n \nOver and over again we will see the same kind of thing: that even\nthough the underlying rules for a system are simple, and even though\nthe system is started from simple initial conditions, the behavior\nthat the system shows can nevertheless be highly complex. (Wolfram\n2002: 28) \nDue to the local nature of a CA’s operations, it is typically\nvery hard, if not impossible, to understand the CA’s global\nbehavior (…) by directly examining either the bits in the\nlookup table or the temporal sequence of raw 1–0 spatial\nconfigurations of the lattice. (Hordijk, Crutchfield, & Mitchell\n1996: 2) \nNow the issue of detecting emergence is connected to the conceptual\nproblems of defining what an emerging feature is: we need\nsome idea of what we are looking for in order to scan the\nspace-time evolution of a system and recognize its patterns. We may\nstart with the fourfold characterization of emergence provided in\nClark 2013. Emergence may be taken:  \nIn the first sense, an emergent feature is “any interesting\nbehaviour that arises as a direct result of multiple self-organizing\n… interactions occurring in a system of simple elements”\n(Clark 2013: 132). CA clearly fit the\n E1\n bill, but that is because this is a rather generic characterization\n(What counts as interesting? What is self-organization?). Things get a\nbit more precise with\n E2:\n emergent features here are taken as unprogrammed, that is,\nas such that there is no program explicitly encoding the relevant\nphenomena, features, or processes in the target system (a typical\nexample is cricket phonotaxis, see Clark 2013: 120: female crickets\nmove towards males via a mechanical body system directing them to the\nsource of sounds of particular wavelengths; one can describe this as\nfemales aiming towards males after hearing their sound, but what is\nencoded in the cricket’s body functions is just an automatic\nearlier activation of the side of the body first reached by the\nsounds). According to the concept embodied in\n E3,\n we get emergence as interactive complexity when “complex,\ncyclic interactions give rise to stable and salient patterns of\nsystemic behavior” (Clark 2013: 134); in particular, the\ninteractions are supposed to be nonlinear (a typical example are\nconvection rolls in a fluid heated in a pan: see Kelso 1995: 5).  \nNow the emergent properties attracting CA scholars’ attention,\nunsurprisingly, have mainly been computational properties, i.e., the\nfeatures enabling a system to perform complex calculations in spite of\nnot being explicitly computationally encoded at the base level (which\nsits in the vicinity of\n E2).\n Additionally, as we have seen during our discussion of the Edge of\nChaos hypothesis, CA scholars have focused on the study of nonlinear\nglobal dynamics emerging from the local interactions of the CA cells\n(which sits in the vicinity of\n E3).\n In order to introduce the formal work on emergent CA computation, and\nto compare these findings with the available philosophical accounts,\nwe can start again with a concrete example. This is the\n“classification problem”.  \nWe want to design a one-dimensional automaton that answers a simple\nquestion: Are there more white or black cells at a given time \\(t_0\\)?\nStarting from any initial conditions with more white (black) cells,\nthe ideal automaton will halt having all its cells turned white\n(black) after a given number of time steps (designing an automaton\nthat always gives the right answer is not feasible in practice; so the\nperformance is judged by the fraction of random initial conditions\nthat are correctly classified).  \n\\(t_0\\) \n\\(t_n\\) \nThe task is far from trivial in a CA, involving the intricacy of the\nemergence in both\n E2\n and\n E3\n sense. The answer requires a global perspective (how many cells are\nwhite (black) in the lattice as a whole?). However, the cells work\nwith only local rules explicitly encoded in them: no single cell can\ndo the counting. The ideal automaton should find a way to aggregate\ninformation from several parts of its own lattice to give the final\nanswer. A kind of emergent computation is needed to successfully solve\nthis density classification task. It has been proved that no CA can\nsolve this problem precisely (see Land & Belew 1995). Since,\nhowever, CA with larger neighborhoods achieve better results in tasks\nof this kind, genetic algorithms are used to efficiently\nsearch the solution space (genetic algorithms are computational\nanalogues of genetic evolution, in which a computational problem is\naddressed by producing, combining and selecting solutions to it; the\ndetails of the procedure as applied to the classification problem are\nnot important for our purpose, but, for an accessible presentation,\nsee Mitchell 2009: 22; for a general introduction see Mitchell 1998).\nThe following is a diagram of the “Rule \\(\\phi_{17083}\\)”,\ndiscovered by James Crutchfield and Melanie Mitchell (1995). The CA\nimplementing the rule starts from an initial state with more white\ncells:  \nFig. 5 \nAt time step 250 (not shown in\n Fig. 5),\n the grey areas disappear and all cells end up white, i.e., the\nclassification made by the automaton is correct. A high-level\ndescription of what is going on would have it that the white, black\nand grey regions are “expanding”,\n“contracting”, “moving”, these being nonlinear\neffects of the low-level working of the cells computing their local\nstates, and by so doing manage to carry signals along the lattice. But\nhow are we to explain the emergent computation CA of this kind perform\nvia such nonlinear dynamics? Building on previous works on computation\ntheory applied to CA (Hanson & Crutchfield 1992; Crutchfield &\nHanson 1993), Mitchell and Crutchfield filtered out from the original\ndiagram what they call “domains”, i.e., dynamically\nhomogenous spatial regions (Crutchfield & Mitchell 1995: 10745):\n \nFig. 6 \nAlthough in this case the “domains” are manifest, it is\ncrucial to point out that their definition is rigorously mathematical.\nThe whole process of domain-detection can be carried out\nalgorithmically (see Hanson & Crutchfield 1992 for details). When\nthe boundary of a domain remains spatially localized over time, then\nthe domain becomes a “particle”:  \nEmbedded particles are a primary mechanism for carrying information\n(…) over long space-time distances. (…) Logical\noperations on the signals are performed when the particles interact.\nThe collection of domains, domain walls, particles and particle\ninteractions for a CA represents the basic information processing\nelements embedded in the CA’s behavior—the CA’s\n“intrinsic” computation. (Crutchfield & Mitchell 1995:\n10744) \nThere are five stable particles (termed α, γ, δ,\nε, µ) and one unstable particle (β) for this\nautomaton: their interaction (annihilation, decay, reaction) supports\nthe emergent logic of the system. The two circles in the image above\nare examples of what may happen during an interaction. In the first\ncase, \\(\\alpha + \\delta \\rightarrow \\mu\\), a spatial configuration\nrepresenting high, low, and then ambiguous densities is mapped to a\nhigh-density signal µ; in the second, \\(\\mu + \\gamma \\rightarrow\n\\alpha\\), a spatial configuration representing high, ambiguous, and\nthen low density is mapped to an ambiguous-density signal α\n(Crutchfield & Mitchell 1995: 10745). The whole computational\nmechanics is worth being explored in more detail, but we can already\nsafely generalize to the basic philosophical point of this and related\nworks.  \nAccording to O’Connor and Wong 2015, in the context of dynamic\nsystems and the study of complexity, emergence is characterized by\nmost authors  \nstrictly in terms of limits on human knowledge of complex systems.\nEmergence for such theorists is fundamentally an epistemological, not\nmetaphysical, category. (O’Connor & Wong 2015: Sec. 2)  \nBut the Crutchfield-Mitchell approach suggests a different\nperspective. Firstly, the emergent (both in the\n E2-\n and in the\n E3-\n sense) computational properties in CA can in an important sense be\nobjectively defined (see Crutchfield 1994a and the more accessible\nCrutchfield 1994b): although it is customary in this setting to talk\nof emergent computation being “in the eye of the\nbeholder”, because not explicitly encoded at the base level, the\ndetection and classification of patterns is itself algorithmic.\nSecondly, Crutchfield characterizes CA-emergence of this kind as, in a\nsense, intrinsic: the emerging patterns “are important\nwithin the system” (Crutchfield 1994b: 3), not merely\nimportant for an observer outside the system. More precisely:\nthey are mathematically grounded on the basic features of the system,\ndespite not being explicitly mentioned in the standard abstract\ncharacterization of the program, that is, the transition rule\nimplemented in the CA cells (Crutchfield mentions as non-intrinsic\nemergent phenomena the patterns in the Belousov-Zhabotinsky reaction\nand the energy recurrence in an harmonic oscillator chains reported by\nFermi, Pasta and Ulam—see Crutchfield 1994b).  \nCrutchfield infers from this that many cases of emergence are indeed\nnot reducible to some interaction with an observer. They are genuine\ninstances of an intrinsic phenomenon, not the results of some\nhuman-biased discovery (Crutchfield 1994b: 2). If emergence was not\nintrinsic, scientific activity would indeed be a subjective enterprise\nof “pattern discovery”:  \nWhy? Simply because emergence defined without this closure leads to an\ninfinite regress of observers detecting patterns of observers\ndetecting patterns… (Crutchfield 1994b: 10) \nSummarizing Crutchfield’s work, Miller and Page say that the\nconcept of emergence  \nhas thus made the transition from metaphor to a measure, from\nsomething that could only be identified by ocular magic to something\nthat can be captured using standard statistics. (Miller & Page\n2007: 234)  \nSuch remarks may sound philosophically naive to a trained\nepistemologist. It is not obvious, for instance, that the existence of\na mathematical or specifically algorithmic emergent pattern would\nblock a supposed regress entailed by a non-mathematical emergence. Why\nwould science as an activity of (occasionally) non-algorithmic pattern\ndiscovery be a merely subjective enterprise? If these claims can be\nre-phrased in a philosophically sophisticated way, though, they may\nchallenge standard definitions of weakly emergent properties\n(in the sense of Chalmers 2002). Teller 1992, Clark 1996, and Bedau\n1997, for instance, all run together instances of “pattern\ndiscovery”—, taken as a subjective, observer-dependent\nactivity—with instances of intrinsic emergence—a\nphenomenon that, as we have just seen, can be characterized in the\ncontext of CA as objective and statistically significant (see the\nrelevant section of the entry on\n emergent properties).\n  \nFinally, on to\n E4:\n emergence as incompressible unfolding. Bedau 1997 defines a\nmacro-state emergent in this sense just in case it can be\nderived from knowledge of the system’s micro-components only by\ndirect simulation of the overall system evolution. Here the idea is\none of “emergent phenomena as those for which\nprediction requires simulation” (Clark 2013:\n134):\n E4-emergent\n macro-features would be those that can only be predicted by directly\nmodelling the micro-features, with no computational shortcut to\ncompress the information at micro-level. The first thing to notice,\naccording to Clark, is that this notion of emergence is at odds with\nat least some of the previous ones:\n E3-emergence\n has it that  \nemergent phenomena are often precisely those phenomena in\nwhich complex interactions yield robust, salient patterns capable of\nsupporting prediction. (ibid)  \nthat is, patterns that deliver compressible information. Next, while\nthe characterization of\n E4,\n Bedau-style emergence may work pretty well in the case of completely\nchaotic systems, it does not sit well with such CA as Rule\n\\(\\phi_{17083}\\). According to the proposed definition, the answer to\nthe classification problem given by Rule \\(\\phi_{17083}\\) is an\nemergent phenomenon just in case the only way to go from \\(t_0\\) to\n\\(t_n\\) is by explicitly simulating the system evolution. \n\\(t_0\\) \n\\(t_n\\) \nAs it turns out, however, this is not the case. Using\nCrutchfield’s particle model it is possible to predict the\nresult of the classification by simply making particle-calculations,\nwithout bothering about the underlying dynamics (Hordijk, Crutchfield,\n& Mitchell 1996). Here then, the emerging computation in the CA\nwould not be a case of emergence for Bedau.  \nWhat about the ontological side of emergence? The issue of the reality\nof emerging patterns in CA has been examined both by reductionist\n(Dennett 2003) and by emergentist philosophers (Thompson 2007). It is\nfair to say that the CA literature so far has not significantly\ncontributed to the ongoing philosophical debate on the purely\nontological side of reductionism. CA patterns that are\n“objectively” detected via computation, as per the\nMitchell-Crutchfield approach, are not ipso facto new\nprimitives to be included in an ontology. It may well be that features\nof a CA that are objective, in the sense of not depending on the\ninteraction with an observer, are nevertheless ontologically reducible\nto more basic entities via suitable definitions (see Kim 1999; Dennett\n1991).  \nPhilosophers have debated the relationship between determinism and\nfree will for over two millennia. Two opposite stances can be taken\ntowards the problem: compatibilism maintains that free will\nis compatible with a deterministic world, which\nincompatibilism denies (see the entries on\n free will\n and\n compatibilism).\n Surprisingly enough, both Daniel Dennett and Stephen Wolfram argued\nthat adopting the CA perspective can provide a solution, or perhaps a\ndissolution, of the longstanding mystery of free will. \nA major obstacle to accepting compatibilism is our persuasion that\ndeterminism implies inevitability (Dennett 2003: 25). We may thus make\ncompatibilism palatable by exhibiting an intuitive counterexample to\nthat conviction: a deterministic world in which, however, not\neverything is inevitable, i.e., something is avoidable (Ibid: 56).\nDennett maintains that CA can do this. He takes Life as a\nvivid illustration of how, in a deterministic but complex enough\nworld, we can abstract away from the bottom level and the micro-laws\ndeterministically governing it, and describe what is happening by\ntaking the emergent level seriously. Recall the eater-glider dynamics:\n \nAn Eater devouring a Glider \n\\(t_0\\) \n\\(t_2\\) \n\\(t_4\\) \nAt \\(t_0\\), an observer aiming at predicting the evolution of this\nspace-time region has basically two choices: she can take into account\n(what Dennett calls) the physical level, and compute pixel by\npixel the value of each cell state at each time step; or, she can\nfocus on the design level, and employ high-level concepts\nsuch as those of glider and eater to ground her\npredictions (Dennett 2003: 39). The first option is perfectly\ndeterministic, but has a flaw: it is time consuming, in such a way\nthat, by the time you have made the required computation, the world\nhas already evolved (this is especially true of a universal\nCA—as we have already hinted at above, and shall expand on\nsoon). The second option is much faster: you know without much\ncalculation what is going to happen to a glider meeting an eater. The\npredictions though, cannot be 100% reliable:  \nWhereas at the physical level, there are absolutely no exceptions to\nthe general law, at the design level our generalizations have to be\nhedged: they require “usually” clauses (…). Stray\nbits of debris from earlier events can “break” or\n“kill” one of the objects in the ontology at this level.\nTheir salience as real things is considerable, but not guaranteed.\n(Dennett 2003: 40) \nDennett’s point is that avoidance itself is a\nhigh-level concept. As such, it is compatible with a deterministic\nbottom level (because the concepts at the emergent level are, by\ndesign, independent from the micro-laws). The physical\ndescription and the design description of Life\nare different interpretations of the same basic ontology, namely, the\nsparse ontology of CA. While in theory we could avoid the introduction\nof emergent concepts, in practice it is only by speaking of gliders,\nmovements and avoidance that we can make sense of the evolution of the\nsystem (Dennett 2003: 43–44). Even without knowing\nLife’s physics, we could do a good job if we predicted\nthe future by mentioning only high level patterns. Life is\njust a toy universe but, Dennett claims, these new intuitions are\nsufficient to see that, in some deterministic worlds, something is\navoidable. For instance, it is true at the design level that gliders\nactually avoid eaters. Thus, the inference from determinism to\ninevitability can be blocked.  \nA reply to Dennett’s argument consists in denying that\nLife-avoidance is real avoidance. Dennett himself puts a\nversion of this argument in the mouth of Conrad, a fictional skeptic\nphilosopher discussing Dennett’s idea throughout his book:  \nIt may look like avoidance, but it’s not real avoidance. Real\navoidance involves changing something that was going to happen into\nsomething that doesn’t happen. (Dennett 2003: 58) \nRephrasing Dennett’s example, we can identify an ambiguity in\nConrad’s argument. Imagine that a baseball is going to\nhit you in the face—but you dodge it: a clear case of\nreal human avoidance. In what sense was the baseball\n“going to” hit you in the face? (Dennett 2003: 59) One\nmight say that it was never really going to hit you,\nprecisely because it triggered the reaction of whatever\n“avoidance system” you have. What is the difference\nbetween this avoidance and Life-avoidance? For Dennett, this\nis not a difference in kind, but in complexity: gliders and humans\nboth have avoidance systems, but human systems are much more\nsophisticated. The choice of a universal CA as a toy universe allows\nus to draw a stronger conclusion: since we know that Life is\nequivalent to a universal Turing machine, as explained above, some\npatterns in that universe may display avoidance systems at least as\ncomplex as ours. Dennett claims that compatibilism has thus won the\nfirst round:  \nyou agree that (…) I’ve shifted the burden of proof:\nthere shall be no inferring inevitability in any sense from\ndeterminism without mounting a supporting argument. (Dennett 2003: 61)\n \nStephen Wolfram addresses the phenomenon of free will in his book on\nCA, with an ambitious tone: \nFrom the discoveries in this book it finally now seems possible to\ngive an explanation for this [free will]. And the key, I believe, is\nthe phenomenon of computational irreducibility. (Wolfram 2002:\n750) \nWe have introduced the issue of computational (or algorithmic)\nirreducibility when we explained the philosophical consequence of a\nuniversality proof for an automaton, namely that, although a system\nfollows definite underlying laws, “its overall behavior can\nstill have aspects that fundamentally cannot be described by\nreasonable laws” (Wolfram 2002: 750). This is again the issue of\npredictability via step by step micro-computations. In this\n“separation between the underlying rules for the system and its\noverall behavior” (Wolfram 2002: 751) lies the secret of free\nwill, since it seems that we attribute free will to a system just when\n“we cannot readily make predictions about the behavior of the\nsystem” (Wolfram 2002: 751). According to Wolfram, CA play a\nleading role in providing a new framework to understand the\nphenomenon. While explanations from chaos theory and quantum\nrandomness have recently been proposed (see the entry on\n chaos),\n “nothing like this is actually needed” (Wolfram 2002:\n752). By observing CA, we can understand how something with simple and\ndefinite micro-rules, like those governing our neurons, can produce a\nbehavior free of obvious rules:  \nthe crucial point is that this happens just through the intrinsic\nevolution of the system—without the need for any additional\ninput from outside or from any sort of explicit source of randomness.\n(Wolfram 2002: 752)  \nWolfram’s point is similar to some of Dennett’s remarks,\nnamely: taking some sort of “design stance”, Wolfram\nsuggests that one can talk about a cellular automaton as if it just\n“decides” to do this or that—“thereby\neffectively attributing to it some sort of free will” (Wolfram\n2002: 752). One easily sees the closeness to Dennett’s famous\nintentional stance (Dennett 1987; see the entry on\n intentionality,\n esp. Section 9). \nHow important are CA to these accounts? Dennett and Wolfram both use\nCA as intuition pumps. However, their positions seem to be slightly\ndifferent. For while the former sees CA as a “useful\ntoolkit” to develop intuitions and vividly illustrate his\narguments (Dennett 2003: 40), the latter claims that CA provides a\n“new kind of intuition”, one that “no branch of\neveryday experience” could provide (Wolfram 2002: 41).  \nThe importance Wolfram attaches to CA seems to rely on a single,\ngeneric “indispensability argument” to the conclusion that\nCA justify the foundation of “a new kind of science”\n(Wolfram 2002: 7–16). We can reconstruct this argument as\nfollows: \n (NKS1)\n is to be taken at face value. It entails that the concepts involved\nwere not previously known. Wolfram talks in terms of “the single\nmost surprising scientific discovery I have ever made” (Wolfram\n2002: 27). Is\n (NKS1)\n true? For sure, the idea that a deterministic and simple system may\nproduce unpredictable behavior started circulating in the scientific\ncommunity well before Wolfram’s work. Signs of what is now chaos\ntheory can be traced back to the 19th and early 20th century, e.g., to\nthe work of Poincaré 1914. One might grant that CA allowed the\ndiscovery that simple systems may produce complex\nbehavior via the proof that they have unpredictable emergent\ncomputational complexity (although this discovery itself, as outlined\nin our brief historical section, was not made but only greatly\npublicized by Wolfram). Why was this discovery not made earlier?\nWolfram’s own diagnosis is twofold: on the one hand, we have the\n“engineering” intuition that to produce something complex\nwe should build something complex—that is because this is how\nordinary machines work. On the other, CA were not obviously connected\nto any established discipline, and therefore they were not studied in\nacademic circles.  \nAs for\n (NKS2),\n we just examined the case of free will. In Wolfram’s\nperspective, free will looks just like another puzzling philosophical\nphenomenon explained away by the advance of (a new kind of) science.\nJust as life was puzzling before the discovery of the double helix,\nfree will was puzzling before the discovery of a suitable scientific\ntheory, one that can finally account for the separation between micro\nand macro level. Many reductionist philosophers are no strangers to\nthis kind of argument. The concepts and intuitions used in\ncontemporary philosophy are often rooted in current scientific\npractices. When groundbreaking discoveries are made, old arguments may\nbe revised: troublesome concepts become harmless and new challenges\nare introduced. From this perspective, Wolfram’s account of the\nfree will problem may lack philosophical rigor, but it is a promising\nstart to re-address the challenge armed with new scientific models of\ndeterminism and complexity—pretty much as Dennett does. While\nmany successful applications are needed to fully vindicate\n (NKS2),\n our first assessment concludes that, at the very least, it is not\nobviously false. As for the “new regularities” promised by\n (NKS2),\n we will address them in the next section.  \nCA are computational systems that perform complex tasks on the basis\nof the collective behavior of simple items. What, if anything, does it\ntell us about the importance of computation for systems in nature?\n \nDifferent conclusions have been drawn by practitioners in the field.\nSome have endorsed the more modest claim that the computational\nfeatures of CA are important to understand and compare social,\nbiological, and physical systems modeled by them; but others have\ntaken CA to support the view that computation and information\nprocessing in a discrete setting lie at the very foundations of\nreality. We will explore the stronger claim in\n Section 3.4\n below. As for the weaker claim, it is not possible here to address\nthe general importance of computational properties across the sciences\n(see Mitchell 2009: 169–185). We will focus instead on a\nspecific, and controversial, principle put forward by Stephen Wolfram,\nthe so-called “Principle of Computational\nEquivalence”: \nThere are various ways to state the Principle of Computational\nEquivalence, but probably the most general is just to say that almost\nall processes that are not obviously simple can be viewed as\ncomputations of equivalent sophistication. (Wolfram 2002:\n716–717) \nThe Principle is the most fundamental law of Wolfram’s New\nKind of Science, as well as a prominent regularity featured by\n (NKS2):\n “its implications are broad and deep, addressing a host of\nlongstanding issues not only in science, but also in mathematics,\nphilosophy and elsewhere” (Wolfram 2002: 715). Contrary to\nWolfram’s claims, the Principle may not be new to philosophy at\nall. That “all processes can be viewed as computations”\n(Wolfram 2002: 715) has often been argued for in the history of\nphilosophy, just as the claim that universal computation is a\nwidespread phenomenon in the natural world (see, e.g., Searle 1992;\nPutnam 1988 and the entry on\n computation in physical systems).\n However, Wolfram’s explanation of the Principle includes two\nfurther, and more specific, statements: i) No natural system\ncan compute more things than a universal digital computer (see Wolfram\n2002: 730), that is, “universal computation is an upper limit on\nthe complexity of computation” (Mitchell 2009: 157); and\nii) The computations performed by natural systems are\nessentially equivalent in sophistication (see Wolfram 2002:\n719–726). \nThe first point is relevant once we compare digital computation with\nthe idea of a computer working with real numbers in continuous time.\nIt has been proved (see C. Moore 1996) that such a device would be\nable to compute more functions than a traditional Turing machine.\nHowever, proponents of a discrete space-time like Wolfram treat\ncontinuous processes as, in a sense, epiphenomenal, since they already\nhave independent reasons (some of which will be addressed\n below)\n to believe in a fundamentally discrete universe. As for the second\npoint, its main problem is that the interpretation of\n“equivalent sophistication” is not straightforward. For\neven assuming that universal computation is widespread, it does not\nseem to follow that all computation is equivalent in sophistication.\nComplexity scientists, even after having agreed with Wolfram on the\nimportance of computation for social, biological and physical systems,\nand even on the extent to which universal computation is supported in\nnature, are puzzled by his claim: \nI find it plausible that my brain can support universal computation\n(…) and that the brain of the worm C. elegans is also\n(approximately) universal, but I don’t buy the idea that the\nactual computations we engage in, respectively, are equivalent in\nsophistication. (Mitchell 2009: 158) \nIt is not clear what to make of computational equivalence. Yes, there\nis a threshold in which systems are related to one another, but given\nthe difficulty of moving among them, is this any more useful than\nsaying that skateboards and Ferraris are equivalent means of moving\nabout? (Miller & Page 2007: 232) \nMiller and Page argue that, for all scientific purposes,\n“representations do matter, and what can be easily computed in\none system is often difficult (but still possible) to compute in\nanother”. Even if Wolfram is right when he claims that a simple\nautomaton can calculate the first few prime numbers (Wolfram 2002:\n640), the calculation we have to do to encode the input and decode the\noutput is very complex:  \nThis latter calculation could be much more “difficult” to\ncompute than the original problem, just as the complexity of a\ncompiler can far exceed the complexity of the programs it produces.\n(Miller & Page 2007: 232) \nTaking these objections ever further, the crucial consideration is\nthat any system with a large enough state space could be shown to be\n(in Wolfram sense) equivalent to “intelligent systems”.\nFar from supporting some form of universality, Aaronson argues that\nthis type of “equivalence” stems from a misunderstanding\nof the role of computational reductions:  \nSuppose we want to claim, for example, that a computation that plays\nchess is “equivalent” to some other computation that\nsimulates a waterfall. Then our claim is only non-vacuous if\nit’s possible to exhibit the equivalence (i.e., give the\nreductions) within a model of computation that isn’t itself\npowerful enough to solve the chess or waterfall problems. (2011:\n285–286) \nIn other words, unless it can be proved that the encoding/decoding\nfunctions are not doing all the heavy lifting (and just use a\nsecondary system, a waterfall or a CA, to vacuously transmit\ninformation), it is hard to consider the alleged\n“equivalence” meaningful at all: “we are merely\ntrading an infeasible search among programs for an infeasible search\namong input encoding schemes” (Aaronson 2002: 413). Moreover, a\nrationale for studying CA (Ilachinski 2001: 8) is that their\nimplementation can be massively optimized for specific problems with\nsignificant performance gain on standard computers (see for example\nZaheer et al. 2016). Unless Wolfram’s notion of\n“equivalent sophistication” simply means “they\ncompute the same functions”—in which case, the claim is a\ntruism—, the Principle cannot explain this empirical difference.\nThe Principle may have a more substantive reading if understood as a\nmetaphysical thesis about the universe in general, not as a scientific\ngeneralization having merely heuristic value. Under this stronger\nreading, the Principle is no more concerned with particular systems\nthat can be fruitfully analyzed via computation theory, but with the\nfact that (different epistemological properties notwithstanding) the\nworld itself is a computer. In a sense, any system would just be the\nemergent manifestation of a unique, underlying computational reality.\nWhich naturally leads us to finally address the boldest question: What\nif the universe itself was a CA?  \nWhen discussing CA as models of reality we need to carefully\ndistinguish the different meanings of modelling.\n (CA1)\n above\n (section 1.2)\n discussed CA as “models of computation”: CA model\nparallel computations in the rather trivial sense that they\nperform them; for that is what their cells do: they associate\ninputs to outputs by implementing algorithmic functions, together with\ntheir mates. In other words, they model computation as Turing machines\ndo (but, of course, with different underlying ideas).  \n\n (CA2)\n introduced a different sense of modelling for CA, i.e., the\nidea that CA are fruitfully used in current scientific practices to\nstudy an incredible variety of phenomena: chemical systems (e.g.,\nKier, Seybold, & Cheng 2005), urban growth (e.g., Aburas et al.\n2016), traffic flow (e.g., Lárragaa et al. 2005), even warfare\n(e.g., Ilachinski 2004). According to the characterization of\nBarberousse, Franceschelli, and Imbert 2007\n (Other Internet Resources),\n a common technique is the “phenomenological” modelling.\nPhenomenological modelling happens when one models in a direct way,\nthat is, without making use of a previous explanatory theory: one\nlooks at how traffic flows and tries to build a CA that reproduces a\nsufficiently similar behaviour and allows to make useful predictions.\nThe key question for modellers here is,  \nAre there well established correspondence rules that I can use to\ntranslate features of the system I want to model into specifications\nfor an adequate cellular automaton model of it? (Toffoli &\nMargolus 1990: 244)  \nIn this sense, CA modelling is a special case of “agent-based\nmodelling” (Miller & Page 2007): the modeller starts with\nmicro-rules to explore macro-behavior (for examples in social\nsciences, see the classic Schelling 1978).  \nStarting from\n (CA2),\n it is natural to ask whether it is possible to push the boundaries\neven further, i.e., using CA to model more “fundamental”\nparts of reality. For example Toffoli 1984 conjectures that CA may\nallow us to replace physical modelling with differential\nequations (and related notions of real variables, continuity, etc.).\nComputations with differential equations, Toffoli claims, are: \nat least three levels removed from the physical world that they try to\nrepresent. That is, first (a) we stylize physics into differential\nequations, then (b) we force these equations into the mold of discrete\nspace and time and truncate the resulting power series, so as to\narrive at finite difference equations, and finally, in order to commit\nthe latter to algorithms, (c) we project real-valued variables onto\nfinite computer words (“round-off”). At the end of the\nchain we find the computer – again a physical system;\nisn’t there a less roundabout way to make nature model itself?\n(Toffoli 1984: 121) \nSuch a less roundabout way can be provided, so the proposal goes, by\nCA. We see here a path, from the view that CA are useful as a\nphenomenological heuristic to predict the behaviour of some aspects of\nreality, to the claim that CA modelling may, in a sense, be closer to\nthe underlying physics than any non-discrete alternative, as\nanticipated in\n (CA4)\n above.  \nWe are now ready to move to the final step, taking us into speculative\nmetaphysics of physics. In the last fifty years various scientists\n(see Zuse 1982; Fredkin 1993; Wolfram 2002) have advanced a bold\nconjecture: that the physical universe is, fundamentally, a\ndiscrete computational structure. Everything in our\nworld—quarks, trees, human beings, remote galaxies—is just\na pattern in a CA, much like a glider in Life.  \nOne may dispute the very meaningfulness of claims of this kind,\nconcerning the world as a whole: something that, to speak Kantian, is\nnever given to us in experience. Floridi 2009 has argued against such\ndigital ontology, not by defending a continuous picture of reality,\nbut by arguing that the world is not the right kind of thing to which\nsuch notions as discreteness and continuity can meaningfully apply.\nThese concern rather, in Kantian fashion, our ways of modelling\nreality, or “modes of presentation of being”. If one, on\nthe contrary, thinks that there must be a fact of the matter about the\ndiscrete vs. continuous nature of the world (as argued in Berto &\nTagliabue 2014, on the basis of considerations from cardinality and\ngeneral mereology [see entry on\n mereology]),\n then the next issue is: what does (the philosophy of) fundamental\nphysics have to say about this? It is fair to claim that the issue is\nopen. Scholars such as Nobel prize winner ’t Hooft (1997)\nseriously explore discretist views, and approaches based on so-called\ncausal set theory (see Dowker 2003; Malament 2006) take the geometry\nof real-world spacetime as such that at the Planck length\n(\\(10^{-33}\\) cm) it is discrete. Cognate strategies take spacetime as\nmade of polysimplexes, usually polydimensional counterparts of\ntetrahedra (see Ambjorn et al. 2004) ; adding the claim that such\npolysimplexes compute functions takes us already in the vicinity of\nCA. Other scholars, instead, are against the idea of a digital world.\nDeutsch (2005) and Hardy (2005) reject the view that quantum\nprobabilities and quantum computing vindicate a discrete structure of\nspace-time, and claim that quantum mechanics complies with the idea\nthat the world is continuous even more than classical physics. While\nwe are, thus, in the realm of speculation, we can nevertheless single\nout two main reasons to investigate the provocative claim that the\nworld is a discrete CA. First, the arguments put forward to support\nthe view may be philosophically interesting in themselves. Second, the\nontological structure of a CA-world can be fruitfully compared to\nexisting metaphysical accounts. Let us take each point in turn.  \nThe picture of nature as a CA is supported by an epistemological\ndesideratum, i.e., having exact computational models of the\nphysical world (see for instance the discussion of ontic\npancomputationalism in the entry on\n computation in physical systems).\n While this is certainly one of the arguments involved, it is not the\nonly one and probably not the strongest. As Piccinini points out, even\nsomeone who shares that desire “may well question why we should\nexpect nature to fulfill it” (Piccinini 2010: Section 3.4).  \nIlachinski proposes a different “argument from\nepistemology” (Ilachinski 2001: 661–2). Let us consider\nagain the space-time diagram of Rule 110:  \nFig. 7 \nLet us imagine we ignore its being generated by the iteration of a\nsimple local rule, or even that it is an automaton. Then, says\nIlachinski:  \nNoticing that the figure consists of certain particle-like objects\nsprinkled on a more-or-less static background, the simplest (most\nnatural?) thing for you to do (…) is to begin cataloging the\nvarious “particles” and their “interactions.”\n(…) What you almost assuredly will not have, is any idea that\nthe underlying physics really consists of a single—very\nsimple—local deterministic rule(…). How different is\nthis alien two-dimensional world from our own? (Ilachinski 2001:\n662). \nThis highlights how CA may generate situations that we view as\nphysically realistic. But one may consider this as a mere suggestion:\nthat we cannot rule out a priori our universe’s being,\nat its bottom level, a CA does not entail that it actually is\na CA.  \nA firmer ground to explore the hypothesis comes from some independent\nreasons of theoretical dissatisfaction with contemporary physics. We\nwill limit ourselves to what we may call conceptual\ncomplaints, as opposed to ones more closely related to scientific\npractice, such as the failure of reductions of quantum mechanics and\nrelativity to a Theory of Everything. We will examine the\nfollowing three: (i) the problem of infinity, (ii)\nthe need for a transparent ontology, (iii) the physical role\nof information.  \nAs for complaint (i): while infinite and infinitesimal\nquantities provide us with powerful tools to model and advance\npredictions on the physical world, it remains controversial what\nontological conclusions should be drawn from this fact. Since the\ndiscovery of\n Zeno’s Paradox (see entry),\n the continuity of space-time, as well as other fundamental physical\nvariables, have puzzled philosophers and scientists alike. In the\nwords of the physicist Richard Feynman:  \nIt bothers me that, according to the laws as we understand them today,\nit takes a computing machine an infinite number of logical operations\nto figure out what goes on in no matter how tiny a region of space,\nand no matter how tiny a region of time. How can all that be going on\nin that tiny space? Why should it take an infinite amount of logic to\nfigure out what a tiny piece of space-time is going to do? So I have\noften made the hypothesis that ultimately physics will not require a\nmathematical statement, that in the end the machinery will be revealed\nand the laws will turn out to be simple, like the checker board with\nall its apparent complexities. (Feynman 1965) \nOne way theoretical physicists have approached the problem is to\nconjecture a fundamental layer of reality along the lines of Edward\nFredkin’s “Finite Nature Hypothesis”:  \nFinite Nature is a hypothesis that ultimately every quantity of\nphysics, including space and time, will turn out to be discrete and\nfinite; that the amount of information in any small volume of\nspace-time will be finite and equal to one of a small number of\npossibilities. (…) We take the position that Finite Nature\nimplies that the basic substrate of physics operates in a manner\nsimilar to the workings of certain specialized computers called\ncellular automata. (Fredkin 1993: 116) \nIf a cellular automaton is a model satisfying this hypothesis, then\n“underneath the laws of physics as we know them today it could\nbe that there lies a simple program from which all the known laws\n(…) emerge” (Wolfram 2002: 434). If, as we have seen\nabove, currently there is no agreement on the issue whether physical\nreality is fundamentally continuous or discrete, at least the Finite\nNature Hypothesis seems to be a no less falsifiable prediction (see\nFredkin 1990) than many speculative metaphysical pictures.\nUnfortunately, although we have attempts to recapture field theory\nwithin CA theory (see, e.g., Svozil 1987, Lee 1986), there is no\nagreed-upon derivation of today’s continuous physics within a CA\nframework; it is therefore safe to say that no party has a clear\nadvantage here. \nAs for complaint (ii): one reason to adopt the view of CA as\nmodels of a fundamentally discrete world is the desire for a\ntransparent ontology. Take a materialist philosopher for whom the task\nof physics is to provide an ultimate description of reality on the\nbasis of a handful of basic physical properties and relations. As\nargued in Beraldo-de-Araújo & Baravalle forthcoming, a\ndigital ontology may take different models of computation at its\nfoundation: by analyzing the ontological commitments of CA (vs.\ntraditional Turing machines), they conclude that CA are very close to\nsupporting a traditional form of physicalism. In this perspective, a\nCA-based physics may provide a neat and elegant ontological picture:\none that would be describable in a first-order formal theory including\nthe axioms of standard\n mereology (see entry)\n (even of mereotopology, as presented, e.g., in Casati, Varzi 1999),\nand whose theorems would be computable in finite time (see Berto,\nRossi, Tagliabue 2010: 73–87). Besides, CA make easier to\nreconcile prima facie contradictory properties of different physical\nlaws, such as the reversibility of micro-laws and the\nirreversibility of the Second Law of Thermodynamics (see for\nexample Wolfram 2002: 441–457; Berto, Rossi, Tagliabue 2010:\n43–46). There is no agreement on whether the Second Law gives us\na fundamental feature of physical reality, or it is a spin-off of\nunderlying principles which are time-reversal invariant and act on an\ninitial state of the universe at low entropy (see Albert 2000). If the\nworld is discrete and temporal reversibility is fundamental,\nreversible CA like, e.g., that of Berto, Rossi, Tagliabue (2016) may\nbe more than mere computational tools achieving some degree of\ncomputational efficiency via their reversibility.  \nAs for point (iii), concerning the physical role of\ninformation: CA can accommodate a speculative hypothesis entertained\nby a number of scientists (Wheeler 1990, Ilachinski 2001) and\nphilosophers (Chalmers 1996), namely that information is not just one\naspect of the physical world, but, in a sense, the most fundamental.\nFor instance, Fredkin’s Finite Nature Hypothesis not only\nstresses the importance of the informational aspects of physics, but\n“it insists that the informational aspects are all there is to\nphysics at the most microscopic level” (see Fredkin 1993).  \nOne way in which this idea has been developed is the so-called\n“it from bit” theory (see again Wheeler 1990). In\nDavid Chalmers’ words, this approach “stems from the\nobservation that in physical theories, fundamental physical states are\nindividuated as informational states” (Chalmers 1996:\n302). Physics is silent on what accomplishes the specified functional\nroles, so “any realization of these information states will\nserve as well for the purpose of a physical theory” (Chalmers\n1996: 302). The “it from bit” approach is particularly\nappealing to Chalmers as a philosopher of mind committed to\nqualia being intrinsic, non-reducible properties, because it\nallows for a simple unification: we need intrinsic properties to make\nsense of conscious experience, and we need intrinsic properties to\nground the informational states that make up the world’s\nphysics. If we claim that all the informational states are grounded in\nphenomenal or proto-phenomenal properties, we “get away with a\ncheap and elegant ontology, and solve two problems in a single\nblow” (Chalmers 1996: 305). The cell states in a CA fit the\nbill: if we interpret them as proto-phenomenal properties, we obtain\nthe intrinsic structure of some sort of computational neutral monism\n(for an historical introduction, see the entry on\n neutral monism). \nAlbeit individually controversial, taken together the three points\nsupport a simple and elegant metaphysical picture which is not\nevidently false or incoherent.  \nSupposing that the actual physical world is a giant, discrete\nautomaton, are there philosophically interesting conclusions to be\ndrawn? A first one has already been partially explored in connection\nwith Life: if nature is a CA, it has to be a\nuniversal CA, given that universal computers (e.g., the one\non which you are probably reading this entry) uncontroversially exist\nin the physical world. Then its evolution is algorithmically\nirreducible, given the Halting Problem. Notwithstanding the\nopportunity of devising approximate forecast tools, we are left with a\nuniverse whose evolution is unpredictable for a reason quite different\nfrom the ones commonly adduced by resorting to standard physics, such\nas quantum effects or random fluctuations: it is unpredictable just\nbecause of its computational complexity.  \nA second philosophical topic is the connection between a CA-world and\none of the most famous and controversial contemporary metaphysical\ntheses, namely David Lewis’ Humean Supervenience (HS).\nUsing Ned Hall’s characterization (see section on\n Humean supervenience in the entry on David Lewis’s metaphysics),\n we can state HS as the collection of these four claims about the\nstructure of our world: \nIf we substitute “space-time points” with\n“cells”, HS gets very close to a CA ontology: cells are\narranged in a lattice, have various spatiotemporal relations to one\nanother (e.g., being a neighborhood of), and have monadic\nproperties (states) which can be considered perfectly\nnatural, i.e., the basic properties out of which any other can be\nconstrued. A CA universe is thus a prima facie abstract model\nof Lewis’ HS and can be fruitfully used to illustrate\nLewis’ original point, which was a reductionist one:  \nThe point of defending Humean Supervenience is not to support\nreactionary physics, but rather to resist philosophical arguments that\nthere are more things in heaven and earth than physics has dreamt of.\n(Lewis 1994: 474). \nThere are, however, two differences between the ontology naturally\nsuggested by CA theories and Lewis’ view. First, for Lewis\nspace-time is an essentially continuous, four-dimensional manifold,\neternalistically conceived (see the section on eternalism in the entry\non\n time\n and the discussion on four-dimensionalism in the entry on\n temporal parts\n for an introduction), while in a standard CA-driven ontology, it is\nnot. Second, Lewis reduces laws of nature to particulars while, as we\nhave seen in Section 2 above, CA rules are always included as a\nfurther specification of the model. \nThe first disagreement may not be very substantial. A CA-world is\ncompatible, for instance, with an eternalist conception. The idea that\nthe world’s next state is computed at any time step can be seen\nas a merely heuristic device, a “shortcut” for a more\nproper eternalist description in which the cell’s states are\nonce and for all “stuck” in their space-time position (we\ndid this ourselves when describing the first picture in this section\nas the complete space-time evolution of a micro-universe).  \nThe second disagreement concerning the laws of nature may instead be a\nthorny issue. According to Lewis 1973, laws of nature are the true\ngeneralizations found in the deductive system that best describes our\nworld (where “best” basically refers to the optimal\ntrade-off between strength and simplicity; see the entry on\n laws of nature\n for an introduction to, and further details on, this debate): laws of\nnature supervene on the four-dimensional arrangement of particulars\nand their properties. To the contrary, the standard description of a\nCA does not take the space-time evolution for granted: it takes the\nautomaton’s initial conditions as given, and generates the\nsystem evolution over time via the CA transition function. Particulars\ndepend on laws, not vice versa. A CA world is not laid out in\nadvance, but it grows as long as the laws are applied to particulars\n(a similar point is also made in Wolfram 2002: 484–486). \nOn the other hand, one may tentatively interpret, in Lewisian fashion,\nthe laws of a CA as the generalizations contained within the deductive\nsystem that best describes the CA behavior. Let us consider one last\ntime our micro-universe from Rule 110:  \nFig. 7 \nA suitable deductive system for this space-time diagram may be\nobtained with just two axioms, one stating the initial conditions of\nthe system, the other phrased as a conditional expressing the CA\ntransition rule. If this conditional is a true generalization embedded\nin the deductive system that best describes our toy universe, then\nRule 110 can count as a Lewisian law of nature in this\nuniverse, as expected. \nAlthough some CA topics are still relatively untouched by philosophers\n(e.g., the nature of space and time (see Wolfram 2002: 481–496),\nthe representation of knowledge in Artificial Intelligence (see Berto,\nRossi, Tagliabue: 15–26), the relationship between information\nand energy (see Fredkin & Toffoli 1982)), there are many\nconceptual challenges raised in connection with CA. While in some\ncases the CA contribution was indeed overrated by practitioners, in\nothers CA proved to be useful models of important phenomena. \nAs a final comment: what is left, from a purely scientific\nperspective, of the NKS Argument? Let us go through it\nagain: \nEven granting the truth of the two premises (that is, even granting\nthe troublesome Principle of Computational Equivalence), it is\ndoubtful the desired conclusion would follow. Surely, CA have provided\nnew intuitions and explanations for a set of phenomena—Wolfram\nquite successfully applies his “discovery” to biology,\ncomputer science, physics, finance. However, there is no evidence that\nmany of our best scientific explanations will soon be reduced to the\nCA framework, and indeed many aspects of complexity itself still lie\noutside the CA paradigm, with no unification in sight. Paradigm shifts\nusually require the new paradigm to explain the same phenomena the old\none did, and some more. CA are a promising field, but many\ndevelopments are still needed for\n (NKS3)\n to be true.","contact.mail":"tagliabue.jacopo@gmail.com","contact.domain":"gmail.com"}]
