[{"date.published":"2016-11-22","date.changed":"2016-11-29","url":"https://plato.stanford.edu/entries/moral-particularism-generalism/","author1":"Michael Ridge","author1.info":"http://www.philosophy.ed.ac.uk/people/full-academic/michael-ridge.html","author2.info":"https://www.davidson.edu/academics/philosophy/faculty-and-staff/sean-mckeever","entry":"moral-particularism-generalism","body.text":"\n\n\nAmong the many questions that arise in the attempt to come to\nphilosophical grips with morality is what role, if any, moral\nprinciples have to play. Moral generalists think morality is best\nunderstood in terms of moral principles; moral particularists deny\nthis. To many people, ordinary moral practice seems suffused with\nprinciples (keep your promises; do not steal; do unto others as you\nwould have them do unto you). To many moral theorists, the central\ntask of moral theory has been to articulate and defend moral\nprinciples, or, perhaps, a single ultimate moral principle (maximize\nimpersonal happiness; act only on maxims that can be willed as\nuniversal law). The debate between particularists and generalists thus\nhas the potential to force a reassessment of both moral theory and\nmoral practice. \n\n\nThis characterization of the debate is so far too impressionistic to\nprovide a tractable framework for philosophical inquiry. The\nliterature reveals many ways to sharpen the debate, and sharpening is\nindeed needed. But both generalism and particularism are best seen as\nintellectual traditions in moral philosophy, each of which has a\nnumber of distinct but related strands. This article attempts to\ndisentangle some of those strands with the most attention being given\nto recent stages of this debate.\n\n\nThe arguments for and against both particularism and generalism are\nalso diverse, arising from metaphysics, epistemology, normative theory\nand the philosophy of language. These arguments also interact in\ninteresting ways with other debates in moral philosophy. Finally, it\nis very much an open and interesting question to what extent other\nareas of philosophy (e.g., the philosophy of language and\nepistemology) can usefully draw on ideas developed in the debate\nbetween moral particularists and moral generalists. \n\nAristotle might reasonably be characterized as the\n“forefather” of particularism. Aristotle famously\nemphasizes that ethical inquiry is mistaken if it aims for “a\ndegree of exactness” too great for its subject matter, and added\nthat moral generalizations can hold only “for the most\npart”. Moreover, Aristotle tirelessly emphasizes that ethics\nultimately concerns particular cases, that no theory can fully address\nthem all, and that “judgment depends on perception” (NE,\n1109b). These ideas have all deeply inspired contemporary\nparticularists (John McDowell is a prominent case, though he does not\ntend to label himself as a particularist; see McDowell 1981, 1998).\nWhether Aristotle should ultimately be interpreted as a particularist\nis a matter of debate (Irwin 2000; Leibovitz 2013). \nInterestingly, no single major historic figure is most obviously\ncharacterized as the “forefather” of generalism. This is\npresumably because the most important historic generalists in effect\ndefended generalism by defending specific moral theories or\nprinciples. The two most important traditions here are the\ndeontological tradition which owes so much to Kant, and the\nconsequentialist tradition which owes so much to the British\nutilitarians (Bentham, Mill and Sidgwick). Nonetheless, each of these\ntraditions substantially enriched the generalist approach with a\nwealth of ideas and distinctions which need not be restricted to the\ntheories in which they were originally formulated. \nThe Kantian tradition puts enormous weight on the idea that morality\nmust be principled and that the ultimate principle of morality must be\none we can know a priori. According to Kant, the moral law as\napplied to imperfect agents who are subject to temptations, provides\nwhat he called a “categorical imperative”—an\nimperative whose rational authority is not dependent on the\nagent’s contingent ends. Kant provided several formulations of\nthe categorical imperative. The so-called “universal law”\nformulation holds that one must always act so that one’s maxim\ncould at the same time be willed as a universal law. The humanity\nformulation holds that one must always act so as to treat humanity,\nwhether in one’s own person or that of another, always as an end\nand never merely as a means. The Kantian tradition emphasizes common\nsense moral ideas like respect and dignity, and provides a distinctive\ninterpretation of the role of universalizability in moral thought. On\nsome readings of Kant, the moral law must itself be\nconstitutive of being a rational agent at all. This idea has,\nin turn, been enormously influential, especially in the late twentieth\nand early twenty-first century.  \nConsequentialism enriched the generalist framework in other ways. Most\nnotably, perhaps, consequentialists have often distinguished between\ntwo very different kinds of principles, corresponding to two\nrather different roles they may play. On the one hand, there\nare principles—call them “standards”—which\nprovide the deepest explanation of why certain actions are\nright or wrong. On the other hand, there are the principles which\nordinary agents ought to follow in their day to day deliberations.\nSuch principles are “guides”. Consider a simple analogy\nwith the stock market. The principle which explains what counts as\nsuccess might simply be “buy low and sell high”, but this\nprinciple is woefully inadequate as a guide to making investment\ndecisions in real time. A principle like “have a diversified\nportfolio” seems much more suitable for the latter role. \nEach of these traditions (the Kantian and the consequentialist) faces\na number of prima facie powerful objections. It is therefore\nperhaps not surprising that there was ultimately a reaction against\nthe broader generalist aspirations that these theories embodied. On\nsome readings, one of the earliest particularists in the modern sense\nwas Ewing, who in The Morality of Punishment (1929) argued\nthat consequentialism and deontology were the only plausible\nprincipled conceptions of morality, that neither was defensible, and\nthat morality was therefore not principled (cf. Lind &\nBrännmark 2008 interview with Dancy, who explicitly characterizes\nEwing in this way at p. 10). \nJust one year after Ewing in effect defended a fairly radical form of\nmoral particularism, W.D. Ross argued for a more moderate form. Ross\noccupies a very interesting place in the history of particularism, as\nhe has served as both an inspiration and a foil to modern\nparticularists. Ross put forward a battery of “prima\nfacie duties” specifying types of conduct—for example\nacts of gratitude—that are always, in some sense, obligatory.\nThe obligation in question need not be an all things considered one,\nhowever, since a conflicting prima facie duty might, in the\ncircumstances, be more important. \nSetting aside whether Ross thought anything theoretically useful could\nbe said about how to adjudicate conflicts of prima facie\nduty, he did not think it useful to try to formulate exceptionless\nprinciples with regard to all things considered duty (cf. Postow\n2006). Ross thus appears to be a generalist about prima facie\nduty, but a defender of particularism about overall duty. Some\ncontemporary particularists, however, insist on going beyond Ross and\ncasting doubt even on principles of prima facie duty, or\nprinciples specifying which considerations are pro tanto (or\n“contributory” in Jonathan Dancy’s terminology)\nreasons. \nJonathan Dancy has done more than anyone to articulate and defend an\nespecially radical form of particularism. Although Ross was both a\nfoil and an inspiration for Dancy, R.M. Hare was a more immediate\nopponent. Hare’s prescriptivism drew on ideas from both the\nKantian and the consequentialist tradition. Hare defended a strong\nform of universalizability which can be traced to Kant, but Hare then\nargued that universalizability lent support not to a deontological\nmoral theory, but to a form of consequentialism. Indeed it led to a\nform of consequentialism which emphasized the distinction between\nstandards and guides (cf. Hare 1963). \nIn the introduction of Moral Reasons, Dancy summarizes his\nconclusions as the “mirror image” of Hare’s. Perhaps\nmost notably, Dancy objected to an idea which he took to be implicit\nin Hare’s universalizability principle, that if a consideration\nis a reason in one context then it is a reason with the same valence\nin any possible context in which it occurs. (This reading of\nHare is open to objection. See McNaughton and Rawlings (2000) for\ndiscussion.) Dancy calls this idea, which he also attributes to Ross,\n“atomism” in the theory of reasons and argues against it\nand in favour of what he calls “holism”. \nAs Dancy’s early work came to fruition, it inspired his\nthen-colleague David McNaughton to advance distinct but complementary\narguments for particularism. McNaughton was also heavily influenced by\nthe work of John McDowell, who had argued that it was an advantage of\nhis own brand of moral realism that it did not presuppose generalism\n(see McDowell 1981; see also Blackburn 1981). In Moral\nVision, McNaughton defended a form of moral realism which he\nargued lent support to particularism. He also argued that\nparticularism better accounts for moral conflict, fits reasonably well\nwith ordinary practice and can explain why we might reasonably be\nsuspicious of the very idea of a moral expert. \nThe work of Dancy and McNaughton inspired a host of other philosophers\nto carry forward the particularist research programme, sometimes in\nrather different directions. This eventually led to a wide variety of\nviews all going under the heading of “particularism”. Nor\nwere the challenges posed by these many moral particularisms ignored\nby those with more generalist sympathies. Woken from their generalist\nslumbers, they began to develop arguments for generalism which did not\ndepend on the correctness of any particular moral principle(s). This\ngenerated a healthy debate, the contours of which the rest of this\nentry will outline. \nParticularists are united in their opposition to moral principles and\ngeneralists are united in their allegiance to them. What, though, is a\nmoral principle? At least three conceptions of principles are worth\ndistinguishing. First, there are principles qua\nstandards. Standards purport to offer explanations\nof why given actions are right or wrong, why a given consideration is\na reason with a certain valence and weight, why a given character\ntrait is a virtue, and the like. An especially robust metaphysical\nspin on this conception understands standards as being\ntruth-makers for moral propositions (cf. Armstrong 2004).\nSecond, there are principles qua guides. These\npurport to be well suited to guiding action. Third, there are\nprinciples purporting to play both of these roles\nsimultaneously—action-guiding standards. \nIt is not hard to see these different conceptions of moral principles\nat work in the history of moral philosophy. In the utilitarian\ntradition in moral philosophy, the principle of utility (however it is\nformulated) is characteristically understood as a standard. Even if\nsome politically minded utilitarians see advantages to using the\nprinciple of utility to guide public choice and justification, moral\nphilosophers tend to follow Mill in thinking that the principle is\nseldom apt for use in individual moral decision-making. They thus deny\nthat it should be understood as a principle qua\nguide. Indeed, some utilitarians go further and argue that\nthe principle of utility is self-effacing, in the sense that\nit recommends its own rejection (cf. Railton 1984; see also Parfit\n1984). Utilitarians instead hold that various maxims of common sense\nmorality should be understood as heuristics which work well enough for\nnormal human beings, so there is room in this picture for principles\nqua guides. \nKant, on the other hand, seemed to have understood the categorical\nimperative as a kind of action-guiding standard. Kant’s\ndiscussion of examples in the Groundwork (1785) and his\ncharacterization of the Formula of Universal Law as appropriate method\nfor testing our maxims makes clear that he thinks of it as\nappropriately guiding the actions of the morally virtuous agent.\nEqually clearly, the categorical imperative is to be understood as the\nmost fundamental explanation of why given actions are right or wrong,\nand so also counts as a principle qua standard. On a\nconstitutivist reading, the categorical imperative is meant to play\nboth of these roles in virtue of its constituting our rational agency.\nFinally, it is worth noting in this context that a principle can\nfunction usefully as a guide even if its application requires\njudgment and sensitivity; principles qua guides need not be\nalgorithmic. \nPrinciples can also be distinguished in terms of their scope.\nSome principles have purely non-moral antecedents (e.g., the principle\nof utility), whereas others use moral concepts in both their\nantecedents and consequents (e.g., “if an action is just then it\nis morally permissible”). Finally, principles can be\ndistinguished in terms of whether they are in some sense\n“hedged”, including a ceteris paribus clause of\nsome kind (e.g., “other things equal, lying is wrong”), or\nunhedged. \nOne might be a particularist or a generalist about moral principles\nunderstood in any of these ways. Whether being a particularist or\ngeneralist about principles in one sense drives one to be a\nparticularist or a generalist about principles in another sense is not\na trivial question. Further complicating matters, there is more than\none way to oppose principles (however those principles are conceived.)\nLast, the form a particularist’s opposition takes might\nreasonably vary across different types of principle. Let us now review\ndifferent ways one might oppose principles. \nThe simplest form of opposition, Principle Eliminativism,\nsimply denies that there are any moral principles. Of course, it must\nbe borne in mind here and below that a principle eliminativist may\ndeny that there are any principles of one sort, while allowing for\nprinciples of another sort. For example one might be an eliminativist\nabout principles purporting to give the application conditions for\nmoral predicates in entirely non-normative terms (McNaughton 1988) or\nan eliminativist about exceptionless principles (Little 2000).\nPrinciple Scepticism holds, more modestly, that we do not\nhave sufficient reason to believe there are any moral principles.\nPrincipled Particularism holds that while any given moral\ntruth is explained by a moral principle, no finite set of moral\nprinciples can explain all the moral truths (Holton 2002).\nAnti-Transcendental Particularism, which at one point at\nleast was Dancy’s favoured gloss of the view, holds that moral\nthought and judgment does not depend on the supply of a suitable stock\nof moral principles. Finally, Principle Abstinence asserts a\nmore practical opposition to moral principles, holding that we ought\nnot be guided by moral principles. For each of these forms of\nparticularism, there is a corresponding form of generalism which is\nsimply the denial of the particularist thesis in question. \nAlthough this taxonomy entails that the logical space for\nparticularist (and generalist) views is wide and heterogeneous, it\nwould be a mistake to assume that all of the positions which can be\nderived from a matrix constructed on the basis of these distinctions\nreally are distinct in any deep way. For example, Principle\nEliminativism about principles qua guides\narguably is equivalent to Principle Abstinence about\nprinciples tout court. \nThe debate between particularists and generalists is often framed in\nmetaphysical terms. In this guise, the debate primarily concerns\nprinciples conceived as standards. Moral principles might then be\nthought of as true and law-like generalizations about moral properties\nor, alternatively, as nomic regularities involving moral properties.\nTo be clear, generalizations in the relevant sense need not actually\nbe instantiated to be true; plausibly, the moral law would still be\ntrue in a world with no agents and hence with no right or wrong\nactions. This view has been developed, in different ways, by McKeever\nand Ridge (2006), Väyrynen (2006, 2009) and Lance and Little\n(2007), though it is not universally accepted (see Robinson 2008).\nThus understood, particularism is often taken to have an affinity with\nnon-reductive or non-naturalist views in ethics. Furthermore, it has\nbeen noted that contemporary particularism arose alongside a\nresurgence of interest in non-naturalism (cf. Little, 1994). To a\ndegree, this is understandable. After all some naturalist\nviews appear to entail generalism. A form of reductive naturalism\naccording to which being morally right is metaphysically identical\nwith being an act which maximizes human happiness appears to entail a\nrobust utilitarian principle and so, a fortiori, to entail\ngeneralism. Furthermore, if one denies any kind of reduction of moral\nproperties to natural properties then it becomes more difficult to see\nhow any informative statements connecting moral and non-moral\nproperties could be sufficiently law-like to count as principles.\nNevertheless, one ought not to take it as given that non-naturalists\nmust be particularists or that naturalists must be generalists. Both\nclassic and contemporary non-naturalists have endeavored to defend\nprinciples (Moore 1922 [1903]; Shafer-Landau 2003). Furthermore, there\nmay be room for particularists to embrace naturalism by claiming that\nparticular reasons are always grounded in some particular natural\nproperty instance while maintaining particularism by claiming that\nthere are no law-like generalizations connecting moral and non-moral\nproperty types. Perhaps because the commitments and resources of\nnon-naturalist and naturalist views in metaethics (and even how\nproperly to distinguish these views from each other) remains\ncontested, one cannot uncontroversially map the\ngeneralism/particularism debate onto the naturalism/non-naturalism\ndebate. \nNon-naturalism would seem to have less bearing on a further question:\nwhether there are moral principles connecting one moral property to\nanother. This issue is at play in Ross’s rejection of\nMoore’s claim that the right action is the action which\nmaximizes the good. Even if Ross relied on Moore’s own\n“open question” strategy to challenge Moore’s\nutilitarian principle, it is nevertheless the case that Moore’s\nprinciple is at least consistent with non-naturalism. More recently,\nphilosophers sympathetic to particularism have divided over the\navailability of intra-moral principles. Some are content to allow that\na claim such as, “the fact that an action is just is a reason in\nits favour”, is true and informative (cf. McNaughton and Rawling\n2000). Others propose a more radical particularism according to which\neven intra-moral principles—that is, principles linking one\nmoral concept with another—are unavailable (cf. Dancy 2004: ch\n7). \nNaturalists and non-naturalists typically share a commitment to\nsupervenience. Roughly put, supervenience says that, necessarily,\nthere can be no moral difference without some natural (or non-moral)\ndifference. There are various ways to interpret supervenience and its\nmetaphysical significance. So long as we reject a global error theory,\nthough, supervenience seems to guarantee some necessarily true\nuniversal generalizations involving moral predicates. \nNevertheless, it is generally agreed by all sides that such\n“supervenience functions” should not count as moral\nprinciples. The grounds offered for this are various, but include that\nsuch generalizations contain much potentially irrelevant information,\nthat they are massively disjunctive, and that they lack explanatory\nimport (cf. Little 2000; Dancy 2004; McKeever and Ridge 2005). The\nidea is that to be a successful moral principle (qua\nstandard) requires more than a true or even necessary connection\nbetween the descriptive and the moral. The connection must be\nexplanatory and not cite irrelevant features in the antecedent either.\nEven those who gesture at supervenience in mounting arguments for\ngeneralism concede that a successful argument requires significant\nadditional semantic or epistemological premises (see below, and cf.\nJackson, Pettit, & Smith 2000). \nWhile particularism has strong affinities with non-naturalism, the\nmost prominent argument for particularism—the argument from the\nholism of reasons—has proceeded from a more targeted and\nspecific claim about the metaphysics of moral reasons (see McNaughton\n1988; Dancy 1993; Little 2000). According to holism about reasons, a\nconsideration that counts as a reason in one case may not count as a\nreason in another case, or may count as a reason, but in a different\ndirection. By way of illustration, the fact that a remark would be\nfunny might be, in one case a reason for making the remark, in another\ncase a reason against making the remark, and in still another case no\nreason at all. In short it depends on context. Importantly, holism is\nmeant to be a universal and modal claim. It says that for any\nconsideration that is a reason it is possible that that consideration\nmight behave differently in another case. Thus understood, holism is\nconsistent with the possibility that some considerations are, as a\nmatter of fact, reasons (of the same force and direction) in every\ncase. Holism also seems to presuppose that the considerations that are\nreasons are not brutely unique; the insight of holism—if it is\nan insight—is built upon the thought that a consideration which\nis a reason in one case is repeatable in other cases. Only if, for\nexample, the funniness of a remark is a consideration that is\nrepeatable can we say, as the holist wants us to, that the funniness\nof a remark is a reason in one case but is not a reason in\nanother. \nThose attracted to holism about reasons agree that it is typically\nspecific elements of context that further account for whether a\nconsideration counts as a reason, and a rich language for\ncharacterizing context has been developed. For example, a putative\nreason might be defeated, enabled, or intensified by specific elements\nof the context. To continue the previous example, the fact that a\ngenuinely funny remark would also be offensive might defeat whatever\nreason-giving force that the humor might otherwise have had. On this\nreading, the humor of the remark is no reason at all; not just a\nreason that is outweighed. To vary the case again, the fact that\none’s audience will appreciate a (non-offensive) funny remark\nenables the humor to be a reason. Here the humor is a reason, but only\nagainst the background of a receptive audience; the background\nfunctions as an “enabler”. Finally, the fact that a funny\nremark will break an unduly somber mood may intensify the force of\nhumor as a reason. Humor itself is especially apt, but only because\nthe mood is unduly somber. Other factors could function as\nattenuators, weakening the force of a reason (see Dancy 2004: ch 5).\n \nHolism depends crucially on the sustainability of the distinction\nbetween the particular considerations that count as reasons and the\ncontextual factors (defeaters, enablers, etc.) that impact whether a\nconsideration counts as a reason. Context-sensitivity without such a\ndistinction would be unable to explain why a feature which is a reason\nin one context can fail to be a reason in another. Moreover, we need\nto know why the relevant features should not be “hoovered\nup” into the content of the reasons themselves. After all,\natomists need not be simple atomists. A hedonist who held that\npleasure and pain are both always reasons and the only reasons, would\ncertainly count as an atomist. But atomists can allow for significant\npluralism and complexity. One way to do so is to insist that the\nconsiderations that a holist calls, variously, reasons, defeaters,\nenablers, and so on are all but parts of a larger more complex\n“whole” reason. Such views have been proposed by Bennett\n(1995), Crisp (2000), Hooker (2003) and Raz (2000), and rejected by\nDancy (2004: 6.2). One worry about the atomists’ appeal to whole\nreasons is that if reasons are identified with large complexes of\nfacts, then the same reason may seldom recur across cases and the\nclaim that agents act for reasons may fall under threat (Price\n2013). \nSetting aside whether holism is true, does it support particularism?\nGeneralists have rejected the inference on the grounds that holism\nleaves open the possibility that the behaviour of reasons, defeaters,\nenablers, and intensifiers/attenuators is codifiable (see\nVäyrynen 2004; McKeever and Ridge 2005). They also observe that\nsome paradigmatic generalists seem to have exploited this logical\nspace. For example, Kant arguably thinks that the fact that a course\nof action would advance someone’s happiness is of variable moral\nsignificance, counting in favor whenever the happiness and its\npurchase is consistent with the categorical imperative and counting as\nno reason at all otherwise (McKeever and Ridge 2005). Particularists\nhave countered that even if holism is logically consistent with\nprinciples it would nevertheless render them “cosmic\naccidents” (Dancy 2004: 82). If this were right it would be\nenough to cast doubt on the generalist tradition in moral philosophy.\nWhy should the heart of a discipline be the search for cosmic\naccidents?! Generalists counter that whether principles are cosmic\naccidents depends entirely upon underlying metaphysical issues and not\non whether principles tolerate holism. For example, if the property of\nbeing good is identical to the property of being non-malicious\npleasure, then the associated holism tolerating principle does not\nlook to be a cosmic accident (see McKeever and Ridge 2006: 2.2). \nSelim Berker (2007) has challenged the particularist argument from\nholism in another way. He argues that the conjunction of holism with\nwhat he calls the particularist’s\n“noncombinatorialism” about the ways reasons combine to\nfix an overall verdict leaves the particularist with no coherent\nnotion of a reason for action. To understand noncombinatorialism, one\nmust first understand the idea of a “combinatorial\nfunction”. A combinatorial function takes as input all the\nreasons and their valences in a given situation and gives the\nrightness or wrongness of actions in that situation as an output.\nNoncombinatorialism simply asserts that the combinatorial function for\nreasons cannot be finitely expressed (and so, in particular, is not\nadditive). Berker argues that particularists are committed to\nnoncombinatorialism, but that this leaves them with no coherent notion\nof a reason for action. Particularists typically gloss being a reason\nas “counting in favour” of that for which the\nconsideration is a reason. Berker’s point is that talk of a\nconsideration “counting in favour” of something is itself\nhard to make intelligible once we abandon a combinatorial conception\nof how reasons combine to fix an overall verdict. We are left with a\nmetaphor that cannot be cashed out in any helpful way. Particularists\ncould of course abandon the noncombinatorial conception of reasons,\nbut Berker argues that this would commit them to the truth of numerous\nexceptionless principles, thus compromising their particularism. (For\ncritical discussion of Berker’s argument, see Lechler 2012.) \nSo far we have focused on generalist replies to metaphysical arguments\nfor particularism. Generalists are not without positive metaphysical\narguments for their own views, though. Most notably, so-called\n“constitutivists” sometimes invoke premises about the\nmetaphysics of rational agency to argue for generalism. Kantian\nconstitutivists are the most influential and clear-cut instance of\nthis style of argument. Christine Korsgaard, for example, argues that\nthe categorical imperative is constitutive of rational agency\n(Korsgaard 2008, 2009). The rough idea is that the principles of\npractical reasons unify us as agents, and allow us to take control\nover our representations of the world and our movements (Korsgaard\n2008: 9). Insofar as simply being a rational agent commits one to the\nrelevant principle(s), this strategy for defending generalism is also\nmeant to be especially effective at silencing sceptical challenges,\ne.g., classic “why be moral?” challenges. The thought is\nthat the sceptic has no coherent perspective from which to reject the\nrelevant principles. \nWhatever the success of these metaphysical arguments, some\nparticularists have worried that an excessive focus on metaphysics\nthreatens to lead us astray—not to falsehood so much as\nmisplaced emphasis. The ontological status of moral laws and the\ngrounding of moral reasons ought not predominate the particularist\nprogram. Instead, the particularist should emphasize how their account\nof moral psychology makes sense of moral development and competence\n(see Bakhurst 2008, 2013).  \nParticularists and generalists typically share a commitment to moral\nknowledge. This common ground is not strictly entailed by either view.\nFor example, proponents of Hare’s universal prescriptivism will\ninsist that moral thought is principled even if, in their rejection of\nthe truth-aptness of moral language, they deny that there is moral\nknowledge. On the other side, a fictionalist might reject moral\nknowledge while insisting that the moral fiction is itself devoid of\nprincipled structure, just as the particularist insists. Nevertheless,\nboth generalists and particularists do in fact typically see moral\nthought and judgment as achieving (sometimes) significant success and\nin this context the shared commitment to moral knowledge is not\nsurprising.  \nParticularists and generalists often treat moral knowledge as being on\na par with other types of commonly accepted knowledge. Just as we can\nknow that our internet connection is running slow, that the milk is on\nthe verge of going stale, or that our friend is annoyed by the story\njust told at his expense, so too we can know that it would be wrong\nrefuse directions to the person who is lost, that our co-worker was\ncourageous to criticize her supervisor, and that the American justice\nsystem treats many people unfairly. Because the commitment to moral\nknowledge is a shared one, many of the arguments both for and against\nparticularism have sought to use it for dialectical leverage. The\nquestions at stake include whether particularism or generalism best\nexplains our capacity to achieve moral knowledge and whether\nparticularism or generalism best models the person who has and uses\nmoral knowledge. \nSome moral knowledge, it is agreed, involves the transmission or\nextension of other moral knowledge already achieved. If Solomon tells\nme the treaty is unjust, I may know this by relying on his testimony.\nIf every member of the Diogenes Society whom I have met is honest,\nthen I may know that Walter, who is also a member, is honest. Here, I\nrely on an induction from my other moral knowledge. While highly\ninteresting, these types of knowledge are typically regarded as\nderivative (Zangwill 2006) and are therefore set aside in arguments\nover moral particularism. The question is what explains our most basic\nmoral knowledge. How strong an assumption can be made about our moral\nknowledge while remaining on ground common to both generalists and\nparticularists? Obviously, particularists will not grant that we have\nknowledge of moral principles, and the point of surest agreement is\nthat we sometimes know the moral status of a particular case, e.g.,\nthat this act was wrong. However, most arguments both for and against\nparticularism deploy somewhat stronger assumptions.  \nFirst, one may make a stronger assumption about the objects of moral\nknowledge. Of special interest is the possibility that we can know\ngeneral truths about morality even while such general truths fall\nshort of counting as moral principles. For example, while\nparticularists will deny that there is any exceptionless moral\nprinciple to the effect that pain is bad, many sympathetic to\nparticularism would agree that, as a general matter, pain is bad and\nthat we can know this. On a deflationary reading, one might treat the\nclaim that pain is bad as a useful heuristic, a reminder that pain has\noften been bad in the past and may well be so in the future (Dancy\n1993). Alternatively, that pain is bad might capture an interesting\nmetaphysical fact about pain; its default status is the status of\nbeing bad. We can understand default status in terms of an explanatory\nasymmetry. When pain is not bad there must be something that explains\nwhy it is not, but when pain is bad there needn’t be any further\nexplanation of what makes pain bad (Dancy 1993, 2004). Finally, one\nmight try to invest such generalizations with real explanatory power\nwhile insisting they remain exception laden. That pain is bad is a\nkind of defeasible generalization, where this amounts the claim that\npain is bad in a privileged set of worlds (Little 2000; Lance and\nLittle 2004; for critical discussion of each of these possibilities,\nsee Stangl 2006). \nSecond, one may make a stronger assumption about the scope of moral\nknowledge, at least for some people. Some people, one may assume, are\n(or become) especially good at acquiring moral knowledge; they have a\nmeasure of practical wisdom or expertise. Their knowledge thus readily\nextends not just to their actual circumstances but to a broad array of\nnovel circumstances as they arise. In so far as this is so, we should\nlike to have a good explanation not only of how humans acquire\nspecific knowledge but also of how they develop over time into more\ncompetent moral knowers (Bakhurst 2005, 2013). \nTwo models of moral knowledge predominate in defences of\nparticularism: a perceptual model and a skill based model. According\nto the perceptual model successful moral judgment is properly\nanalogous to sense perception even if it is not, literally, a form of\nsense perception (McDowell 1979, 1985; McNaughton 1988). Moral\njudgment on this view depends upon a range of sensibilities, developed\nthrough experience and acculturation. Once developed, however, one can\njust “see”, for example, that a certain response is\nmerited by a situation. As John McDowell puts it,  \nOccasion by occasion, one knows what to do, if one does, not by\napplying universal principles, but by being a certain kind of person:\none who sees situations in a certain distinctive way. (McDowell 1979:\n350) \nSince sensibilities may be more or less refined, the perceptual model\nappears to fit well with the idea that there are both moral novices\nand experts. Whatever further account is to be given of these\nsensibilities, the resulting knowledge is not dependent upon any\ndeduction from general moral principles, at least not one\ntransparently and readily available to the knower. Generalists have\nobserved that similar perceptual metaphors seem equally apt in domains\nthat admit of principles (McKeever and Ridge 2006: ch 4). For example,\none might just “see” that a sentence is ungrammatical even\nif grammaticality is rule-governed. Furthermore, some who develop and\ndefend a perceptual model are not led by it to particularism (Audi\n2013). So the perceptual model of moral knowledge seems not to\nestablish particularism, but it was likely never meant to. Instead,\nthe perceptual model is intended to offer more indirect support. If\nour moral experts reliably achieve moral knowledge without\nself-consciously adverting to moral principles, then the generalist\ninherits at least some burden to explain why principles should be a\ncenterpiece of moral theorizing. \nTwo related constraints confront the development of the perceptual\nmodel and may threaten the particularism the model is taken to\nsupport. The first is that the model must extend to prospective and\nhypothetical cases. Particularists and generalists typically agree\nthat we sometimes have knowledge that if we were to perform an action\n(say maintain a confidence) in our actual circumstances, that action\nwould be right. This seems essential if moral knowledge is to precede\nand guide virtuous conduct. Similarly, if slightly more\ncontroversially, we sometimes have knowledge that a certain course of\nconduct would be right in some hypothetical circumstance. While one\nmight try to account for such cases by appeal to inductive reasoning\nfrom past actual cases, this is not, in fact, how proponents of the\nperceptual model have proceeded. The second constraint arises from the\nfact that moral properties are grounded in other properties. For\nexample, it barely makes sense to say that an action’s wrongness\nis a brute fact about it; if wrong an action must be wrong on account\nof some otherwise specifiable features it has. While this\n“because constraint” admits of various explications, the\nbasic idea is common ground and widely thought to be a priori\n(Zangwill 2006). \nGeneralists argue that, once spelled out, the perceptual model is not\nthe a posteriori epistemology it might first have seemed but\ninstead commits us to a priori intuitions relating moral\nfeatures to their grounds. Particularists may grant that basic moral\nknowledge is a priori knowledge of “what is a moral\nreason for what” (Dancy 2004: 141) while maintaining that the\nobject of knowledge remains particularized and does not implicate\nprinciples. One challenge for the particularist is that “what is\na reason for what” in a particular case is contingent, and so\nthe particularist risks being committed to a priori knowledge\nof contingent truths. In his defense of particularism, Dancy has been\nwilling to embrace this apparent consequence (Dancy 2004; for\ncriticism, see McKeever and Ridge 2006). Other particularists have\nsought to avoid the implication (Leibovitz 2014). \nParticularists sometimes pursue a somewhat different model of moral\nknowledge, one that likens the practically wise agent to a person who\nhas a developed skill. Just how different this model is from the\nperceptual one must depend upon how each is spelled out. But whereas\nthe perceptual model directs our attention first to how the virtuous\nperson understands her situation, the skill model draws attention to\nthe knower as agent, someone who classifies actions, agents, and\nstates of affairs as falling under moral categories, who reasons to\nmoral conclusions, and ultimately puts their knowledge into outward\naction. How might this skill be understood and, relatedly, how much of\nan account of it does the particularist owe? Some particularists\n(sometimes) demur. For example, Dancy described the virtuous agent as\nsomeone possessed of a “contentless ability” to discern\nwhat matters when it matters (Dancy 1993: 50). But many sympathetic to\nparticularism would want to say more (Garfield 2000; Leibovitz 2014).\nOne might liken the skill of the virtuous person to a behavioral\nability, such as the ability to ride a bicycle. While this analogy\ncould prove apt, it risks underrating the extent to which the virtuous\nperson’s action is rich with judgment and reasoning and is not\nsimply a sequence of successful performance. \nOne way to develop the skill model is to urge that the skill of the\nvirtuous person is akin to the skill of the person with conceptual\ncompetence and then rely on Wittgensteinian rule-following\nconsiderations to urge that conceptual competence cannot be fully\nunderstood in terms of rules or principles. This approach lends itself\nto a form of particularism that is less hostile to principles. The\nclaim is not that there are no principles but that practical wisdom\ncannot be fully reduced to principles (McDowell 1979). A\nperhaps similar strategy can be pursued by focusing on principles of\nreasoning and urging that valid principles of reasoning cannot be\ntreated simply as objects of propositional knowledge akin to premises\n(Carroll 1895; Thomas 2011). One seeming consequence of these\nstrategies is that particularism it not something distinctive of\nmorality and other cognate domains. Particularism would be true\neverywhere we apply concepts or everywhere we reason. Some might\nwelcome such global particularism, but we would have lost what for\nsome was initially attractive—that particularism seemed to\nidentify something distinctive (even if not unique) about morality. A\nsecond worry is that particularism may no longer pose the threat to\ntraditional moral theory that is sometimes supposed. If the\ncategorical imperative were shown to have the same status as modus\nponens, Kantians could sleep easily. \nAnother way to develop the skill model could urge that the skill in\nquestion is the skill of applying (or reasoning with) generalizations\nof a certain kind. Here the claim may be that moral principles (or\ngeneralizations) require judgment to apply, or are defeasible, or come\nwith implicit ceteris paribus clauses. This commits the\nparticularist to principles of a kind, while also allowing both that\nmorality is importantly distinctive and that some traditional moral\ntheorists have erred by seeking a sort of principle that is not to be\nfound. This path leads to interesting intermediate positions that are\ncertainly more friendly to principles than Dancy’s particularism\nwhile at the same time concerned to emphasize the limitations of\nprinciples. For example, Richard Holton (2002) suggests that sound\nmoral principles are conditionals containing an implicit\n“that”s it’ clause. The dictum that lying is wrong\nis then more perspicuously expressed as the claim that if an action\namounts to lying and “that”s it’ then the action is\nwrong. In this context, “that’s it” expresses the\nidea that no other moral principle, given the facts at hand,\nsupersedes the principle that lying is wrong. \nA different but similar idea is developed by Mark Lance and Margaret\nLittle, who advance a model of true but defeasible moral\ngeneralizations. Here, the claim that lying is morally wrong is\nelaborated as the claim that lying is wrong under privileged or normal\nconditions. Conditions might fail to be privileged for any number of\nreasons—perhaps because the murderer is at the door looking for\nyour helpful information or, less dramatically, we might be playing a\ngame in which deception is part of the fun. As this last possibility\nsuggests, Lance and Little’s proposal seems more expansive than\nHolton’s in so far as they allow that a moral generalization\nmight fail to govern a situation not only in the case that it is\nsuperseded by other moral principles but because the circumstances\nmight be such that the point of the moral generalization is simply\nlost. (See Little 2000 and Lance and Little 2004. For discussion of\nthe skill needed to apply generalizations see Garfield 2000 and Thomas\n2011. For discussion of reasoning with defaults see Horty 2007.) \nOne interesting question for this approach is whether the skill part\nof the equation can be further explicated in terms of principles, even\nif these further principles are grasped only implicitly. This issue\nhas received significant attention from philosophers outside the\nparticularism debate who are interested in the question whether\nknowledge-how can be reduced to knowledge-that (Ryle 1946; Stanley\n2011). Perhaps surprisingly, the literature on particularism has not\n(to our knowledge) drawn significantly from that debate. \nSome generalists, agreeing with particularists that moral knowledge\npresupposes a sensitivity to the moral landscape and skill in\ndeploying what appear to be ceteris paribus laden principles,\nargue that such sensitivity and skill is possible only if the\nlandscape itself is sufficiently patterned (McKeever and Ridge 2006)\nThis argument is supposed to allow for holism about reasons, and so\nthe relevant patterning consists in there being a finite number of\nconsiderations that can function as reasons, and that these can be\naffected by a finite number of enablers and defeaters operating in\nregular, “principled” ways. Particular pieces of moral\nknowledge, on this argument, presuppose only “default moral\nprinciples” which specify a feature which ground reasons,\nceteris paribus. A full array of exceptionless principles,\nthe argument continues, are presupposed by practical wisdom,\ncharacterized as including a capacity for reliably acquiring moral\nknowledge in a full range of novel circumstances. \nSome resist this argument in its entirety on grounds that we can\nregularly gain knowledge in other areas without recourse to principles\n(Schroeder 2009). Some charge that the second stage of the argument\ndepends on overly strong assumptions about the extent of practical\nwisdom (Schroeder 2009), and that more modest forms of practical\nwisdom can be explained without recourse to exceptionless principles.\nSome argue that a proper account of hedged moral principles is enough\n(Väyrynen 2009); others prefer to see moral wisdom as a skill\nwhich, while wide ranging, can fail in utterly novel circumstances\n(Leibowitz 2014). Still others have worried that the argument relies\non inflated assumptions about what is required for justification and\nknowledge, for example that the knower must be in a position to\naffirmatively rule out any possible defeaters (Thomas 2011). \nA recurring charge against generalism is that it assumes an outmoded\ndeductive-nomological (D-N) account of successful explanation.\nAccording to that account, any successful explanation must take a\ndeductive structure in which a covering law is identified that,\ntogether with empirical information, could yield a conclusion\nexpressing the phenomenon to be explained. For many reasons, the D-N\nmodel is now widely thought to be misguided. \nOn behalf of the generalist, one might make two points. First, it is\nnot clear that a generalist argument from practical wisdom needs to\nassume that all successful explanations must conform to the\nD-N model. The argument draws upon claims about the person of (highly\nideal) practical wisdom and asks how best to explain her reliability.\nSecond, while the argument does insist that we must credit the\nvirtuous agent with at least an implicit grasp of a principle, it is\nless clear that the argument must treat this principle as functioning\nas the major premise in a deduction. Likewise, we might credit an\nagent with grasping modus ponens to explain her logical success\nwithout thereby assuming that she uses modus ponens as a premise. \nGeneralists sometimes invoke premises about the nature of moral\nconcepts or about the meanings of moral words to argue for their view.\nUltimately these arguments appeal to what can be derived from a\ncertain kind of competence—either semantic or conceptual\ncompetence. It is probably no accident that purely semantic/conceptual\narguments to settle the debate over particularism/generalism have been\nmonopolized by generalists. If the generalist could show that\nsemantic/conceptual competence commits one to some specific moral\nprinciple(s), or to the existence and availability of some such\nprinciples, then that would already be enough to establish an\nambitious form of generalism. By contrast, a particularist who showed\nonly that such competencies do not yet commit one either to some\nspecific moral principle(s) or to the existence and availability of\nsuch principles would not yet have established a very ambitious form\nof particularism. For that negative conclusion is logically consistent\nwith the availability of a convincing epistemological, practical or\nmetaphysical argument for the existence and availability of suitable\nmoral principles. \nGeneralists can and have proceeded in one of two main ways here.\nFirst, they might argue that semantic/conceptual competence directly\ncommits one to the truth of some specific moral principle(s). Second,\nthey might argue that such competence commits one only to the weaker\nthesis that if there are any substantive moral truths then\nthere must be some true moral principle(s). This second thesis is\nweaker both in that it takes a conditional form, so that an error\ntheorist could endorse it but deny the existence of any true moral\nprinciples and in that it does not entail that there is some\nspecific moral principle(s) to which one is committed insofar as one\nthinks there are substantive moral truths. Consider each of these\nstrategies in turn. \nThe most ambitious and straightforward version of the first strategy\nis effectively just to argue for a form of analytic naturalism in\nmeta-ethics. For example, consider the meta-ethical theory that\n“is morally right” just means “is an action\nwhich maximizes happiness”, where “happiness” is\nitself cashed out in purely naturalistic terms. Any convincing\nargument for that theory would provide a way of carrying out a very\nambitious version of the first of the two strategies discussed above.\nClearly, insofar as that theory is correct, semantic competence with\n“is morally right” is enough to commit one to the thesis\nthat, necessarily, an action is morally right if and only if it\nmaximizes happiness, and that certainly looks like just the\nright sort of generalization to function as a principle qua\nstandard in the sense laid out in\n section 2. \nOf course, this strategy for defending generalism is for good reason a\nhighly controversial one. For a start, nobody has come close to\noffering a fully reductive definition of predicates like “is\nmorally right” which has met with widespread assent. Moreover,\nsome philosophers are sceptical of the very idea that knowing the\nmeaning of a word (or possessing a concept) is already enough, in\nprinciple, to know how to live a good life. In way, this concern about\npulling a highly substantive rabbit out of a purely\nsemantic/conceptual hat can be seen as what lies behind one of the\nhistorically most influential arguments against analytic naturalism,\nnamely G.E. Moore’s “Open Question Argument” (Moore\n1922 [1903]). Finally, anyone who is initially sympathetic to\nparticularism is very unlikely to find analytic naturalism an ex\nante plausible view, given how trivially it entails a very robust\nform of generalism. There is a sense, then, in which this strategy for\ndefending generalism, however sound it might turn out to be, is\nunlikely to convince anyone who needs convincing (cf. Jackson, Pettit,\n& Smith 2000—the argument there seems ultimately to turn\ninto a version of this first strategy). \nA less ambitious form of the first strategy focuses on so-called\n“thick” evaluative words or concepts. Such words/concepts\nin some sense have both specific descriptive and normative contents.\nConcepts associated with virtues and vices are classic examples of\nthick evaluative concepts—concepts like courage, justice,\nfairness and generosity are all paradigm cases. The argument for\ngeneralism focusing on these concepts takes the same form as the more\nambitious argument just canvassed. That is, the argument derives a\ncommitment to moral principle(s) from mere conceptual/semantic\ncompetence. \nHowever, the intended conclusion of an argument in this style is more\nmodest. For here the relevant principles do not take one from a purely\ndescriptive antecedent to a purely normative all things considered\nconsequent, as with (e.g.) the principle of utility. Rather, the\nrelevant principles here take one from an antecedent deploying a thick\nevaluative concept (like the concept of justice) to a consequent\ndeploying a thin normative concept (like the concept of a reason).\nSuch an argument might maintain, for example, that competence with the\nconcept of justice commits one to a moral principle of the form,\n“if an action is just then there is at least some reason to\nperform it (namely, its justice)”. \nEven this modest form of generalism is not uncontroversial. Dancy, for\nexample, argues that even thick evaluative features can vary in their\nnormative valence from one context to another, going so far as to\nmaintain that “almost all the standard thick concepts…are\nof variable relevance” (Dancy 2004: 121). Insofar as this sort\nof view is as much as semantically/conceptually coherent, there can be\nno straightforward derivation of moral principles of the sort\ncanvassed above from mere semantic/conceptual competence. Of course,\nthere may be more “hedged” principles linking thick\nevaluative concepts with thin normative concepts—principles\nwhich either enumerate or quantify over further conditions which must\nbe met before the application of a thick evaluative predicate entails\nthe application of a thin normative predicate. In effect, this is just\nthe point about holism not entailing particularism again. However, it\nis also unclear just how one would plausibly argue that insofar as\nsuch hedged principles are not vacuous, they really do follow from\nmere semantic/conceptual competence. \nThere may also be some interesting asymmetries between virtue concepts\nand vice concepts which are relevant to how we should think about\nthese arguments. In an interesting series of papers, Rebecca Stangl\nhas argued for a view she calls “asymmetrical virtue\nparticularism” (Stangl 2010). On this view, an action is right,\nall things considered, insofar as it is overall virtuous. However, the\nvirtues of an action in any specific respect (justice, courage, or\nwhatever) can vary in normative valence. However, vices on\nthis view are invariable—they always count against an action.\nThe deeper explanation of this asymmetry, on Stangl’s view, is\nthat virtues have “targets” at which they aim, whereas\nvices are simply tendencies to miss the relevant targets. Vices are\nthus parasitic on virtues but not vice-versa. Thus a given virtue\n(e.g., mercy) can sometimes be wrong-making because it helps explain\nwhy the agent (badly) misses the target associated with some other\nvirtue (e.g., justice). By contrast, Stangl argues, a vice always is a\ntendency to miss some relevant target, and so is therefore always to\nthat extent wrong-making. Insofar as Stangl makes a convincing case\nfor this asymmetry (and obviously a lot more could be said about\nthis), we should be less sympathetic to arguments which hold that\nthere is a semantic/conceptual link between the virtuousness of an\naction in a specific way and the presence of an associated reason for\naction.  Moreover, this more modest form of generalism presupposes that our\nthick concepts of justice, courage, generosity, and the like must be\ngenuinely evaluative concepts. But this is controversial. Pekka\nVäyrynen (2013), for instance, argues that the evaluations we\ntypically associate with thick terms such as “just” and\n“courageous” are conversational implications which arise\nfrom our use of those words in a wide range of contexts. Very roughly,\nthe idea is that evaluative content is a kind of generalized content\nwhich is explained pragmatically. For example, it may become common\nknowledge that only people who disapprove of the sexually explicit\ntend to use the word “lewd”. In that case, someone who\nuses that word thereby implies that she disapproves of the sexually\nexplicit – otherwise, why use the word “lewd” instead of\n“sexually explicit”, given that one’s interlocutors\nwill reasonably infer from the use of the former that one disapproves\nof the sexually explicit. \nIf this is right, then the status of thick words as evaluative depends\non contingent facts about the pragmatics of our use of those words.\nThere is then an important sense in which thick terms are, on this\nview, descriptive in their semantic content. So although there is a\nbroader kind of speaker competence which involves understanding the\nconversational defaults associated with the relevant words, this is\nnot the kind of semantic competence that could ground an argument for\ngeneralism or particularism. Semantic competence with thick words is\nalso unlikely to commit one to any interesting moral principles.\nDepending on our views of concepts, this view about thick language can\nallow that some thinkers' concepts of justice, generosity, and courage\nmay be evaluative. But that is unlikely to be essential to those\nconcepts, nor will the capacity forthought about justice and other\nthick notions depend on having genuinely evaluative thick concepts\n(Väyrynen 2013: 123–4, 206). In that case, competence with concepts\nlike justice, courage, and generosity is also unlikely to commit us to\nany interesting moral principles.  Moreover, the more modest form of\ngeneralism may require that a concept isn't a concept of justice, or\ncourage, or generosity, unless it is evaluative. In that case the\npragmatic view of thick evaluative language would support the view\nthat there are no thick evaluative concepts and, therefore, no such\nthing as competence with thick evaluative concepts. \nHowever, generalists do not have a monopoly on arguments which take\ntheses about thick evaluative concepts/predicates as their main\npremise. Some particularists argue that thick evaluative concepts are\n“shapeless” with respect to the descriptive (see\nespecially McDowell 1981). Others take a more metaphysical approach,\nand argue that thick evaluative properties are “irreducibly\nthick” in a way that puts pressure on the generalist. Indeed,\nsome go so far as to suggest that this even undermines some important\nforms of supervenience (see, e.g., Roberts 2011). Whether these\narguments are forceful may depend on the extent to which the argument\nthat there really are thick evaluative concepts or properties\nin the needed sense can avoid begging the question. In this context,\nit is not enough that no “shape” at the descriptive level\nis built into the meaning of evaluative concepts. Such a weaker\nshapelessness thesis would seem to rule out only principles that are\nboth analytic and reductive. But it seems compatible with the\npossibility that someone who did know the extension of evaluative\nconcepts could then discover a unity or “shape” to that\nextension which could be expressed using descriptive concepts. To rule\nout this possibility would seem to require a stronger shapelessness\nthesis according to which the extension of evaluative terms, properly\nunderstood, has no shape at all. Generalists will want to see an\nargument for this stronger thesis. Perhaps more importantly, though,\nsettling whether this stronger version of the shapelessness thesis is\ntrue would seem to require more than a priori theorizing\nabout moral concepts and more than semantic theorizing about\nevaluative terms. (For discussion of shapelessness and the metaethical\nlessons to be drawn from it see Väyrynen 2014 and Miller\n2003.) \nSo much for the first of the two strategies for giving a\nsemantic/conceptual argument for generalism canvassed above. What\nabout the second? Recall that the second strategy is less ambitious\ninsofar as it aims to establish only a conditional thesis linking\nsubstantive moral truth to the existence of some moral principle(s) or\nother. The guiding idea here is that a proper analysis of our moral\nconcepts will reveal that deploying those concepts to make a\nsubstantive moral judgment commits one to the existence and truth of\nsome moral principle(s) or other which somehow explains the truth of\nthat judgment. Crucially, though, this commitment to the existence of\nsome such moral principle(s) does not entail that the speaker is\ncommitted to any particular moral principle(s), or even to\nthe possibility in principle of discovering what the relevant\nprinciple(s) are. \nA modified version of T.M. Scanlon’s contractualist theory of\n“what we owe one another” (Scanlon 1998) helps to\nillustrate this strategy. Scanlon himself does not intend his theory\nas a conceptual analysis, in part because there are strands of moral\nthinking, like our thoughts about the moral status of nonhuman animals\nand the environment and certain forms of moralizing about human\nsexuality, which do not fit very well into his proposed framework.\nHowever, a version of his theory which was offered as an analysis of\nour moral concepts would provide a clear illustration of the strategy\nfor defending generalism under consideration. On Scanlon’s view,\nto be morally wrong in the sense of “wrong” associated\nwith what he calls the “morality of what we owe one\nanother” is to be forbidden by principles for the general\nregulation of human behaviour which nobody could reasonably reject.\nThe notion of the “reasonable” is a thick evaluative\nconcept, so the view is not a reductive one. If the view were to be\nunderstood as following directly from an analysis of our moral\nconcepts, then it would follow that anyone who makes a substantive\nmoral judgment that some action is morally wrong would thereby be\ncommitted to the existence of at least a range of moral principles\n(the “reasonable” ones) which are such that they all\nforbid the action in question. At the same time, making such a\njudgment does not entail that one can articulate what the relevant\nprinciple(s) is (are), or even that they are such that one could in\nprinciple discover them. \nAnother way of arguing for this sort of view is to take a broader\nfocus on normative and evaluative language. On some views (e.g., Ridge\n2014), all uses of “good”, “reason”,\n“ought” and “must” advert to\nstandards of some kind, but the context of utterance\ndetermines the relevant kind of standards. Sometimes, as in moral\ncontexts, the relevant standards will be normative in some rich sense.\nOther times, the relevant standards will be purely conventional, as\nwhen we discuss what one ought to do as a matter of etiquette. In\nother contexts the standards will be purely strategic/instrumental, as\nwhen we discuss what move one ought to make in a game of chess, say,\nor what military strategy is best, but where one can sincerely make\nthese judgments while finding chess a total waste of time or being a\ncommitted pacifist. The view aims to accommodate the\ncontext-sensitivity of the relevant words without implausibly\npostulating a brute ambiguity across the wide variety of contexts in\nwhich such words are used. As with the conceptual version of\nScanlon’s view, this view is also one on which making a\nsubstantive moral judgment commits one to the existence of a\nrange of moral standards which require the relevant action (or count\nthe relevant consideration as a reason, or whatever).  \nAn attraction of this strategy is that it draws its plausibility from\nhigh level semantic features of words like “good”,\n“reason”, “ought” and “must” which\nare not specific to normative contexts. It is therefore perhaps\nespecially unlikely to beg the question against the particularist.\nThis stands in sharp contrast with the attempt to derive specific\nmoral principles from mere competence with moral words or\nconcepts. \nAs the taxonomy of\n section 2 above\n emphasized, whether moral principles are necessary for moral\nunderstanding or moral explanation is not the only debate between\nparticularists and generalists. Distinct questions remain about the\nplace and value of principles in guiding moral decision-making and\naction and in interpersonal justification. Generalists typically see a\nlarger and more important role for principles to play in these\ncontexts. Particularists typically find at least some sympathy with\nDavid McNaughton’s claim that moral principles are “at\nbest useless and at worst a hindrance” (McNaughton 1988: 191).\nIn considering this aspect of the debate, it is helpful to treat as\ncommon ground the idea that it is at least possible for an agent to be\n(in some sense) guided by a principle. This assumption has, of course,\nbeen challenged, most prominently by some readings of\nWittgenstein’s arguments concerning rule-following (Kripke\n1982). If guidance by principle were utterly impossible, then\nquestions about the value and importance of principled guidance would\nbe largely moot. For similar reasons, it is helpful to assume, at\nleast provisionally, that an agent can eschew being guided by\nprinciples and yet still act rationally and for reasons and with some\nmeasure of consistency. \nAgainst this background, we may distinguish two questions. First, we\nmight ask whether guidance by principles constitutes a superior\nstrategy for acting well as compared to guidance by particular\njudgments untutored by principles. One familiar way to understand the\nsuperiority of a strategy is in terms of its reliability at leading an\nagent to act rightly and for morally good reasons (McKeever and Ridge\n2006; Väyrynen 2008). Second, we might ask whether guidance by\nprinciples enables us to secure morally valuable goods (or avoid\nsignificant moral evils) that would otherwise be out of reach. If\nparticularism tells us to eschew guidance by principles and if doing\nso comes with significant costs, then, to use Brad Hooker’s\nphrase, there is something “bad” about particularism\n(Hooker 2000, 2008). Similarly, if generalism tells us to use\nprinciples and this has serious costs, then there is something bad\nabout generalism. \nThese questions leave one familiar and related question largely to the\nside. This is the question whether there is something inherently\nmorally valuable about being a “person of principle”\nindependent of the content of those principles and how, more\nspecifically, they lead one to act. Generalists may, but need not,\nsubscribe to such a view, and even particularists could (consistently\nwith holism) allow that across some range of contexts being principled\nis, itself, a favoring consideration. Turning to the first question\njust noted, how might principles constitute a good strategy for moral\naction? \nMost ambitiously, the ultimate principles qua\nstandards—that is, the principles which provide the deepest\nexplanations of why right actions are right—could be well suited\nto guiding action directly. Arguably this is the view we find in Kant\nand in many modern Kantian moral theories. The categorical imperative\nis both the ultimate standard of right action and at the same time is\nwell suited to guide the decision-making of a conscientious moral\nagent. This view of principled guidance ought to be distinguished from\na distinct meta-ethical view according to which an ultimate moral\nstandard must, if it is to be valid at all, be such that agents can be\n(in some sense) guided by it (Bales 1971; Smith 2012). Such a view may\nbe attractive to those (such as Kant) who think that moral principles\nmust comport with autonomy and that morality is a species of\nrationality. It may also be attractive to those who believe that moral\nprinciples must provide reasons on which agents can act. But even a\nvery ambitious generalist model of principled guidance need not\nsubscribe to this meta-ethical view. Kant, at least in some passages,\nencourages optimism about our ability to apply the ultimate standard\nof right and wrong directly to our individual decisions. Other\nphilosophers within the generalist tradition, such as Ross, defend\nprinciples which look, on their face, to be eminently usable, and if\nRoss is correct that such principles are ultimate standards, then one\nmight feel entitled at least to a weak presumption in favour of the\nclaim that using them would be a good strategy. \nWhen we consider other candidates for the ultimate moral principle,\nhowever, many find reasons to be sceptical that the ambitious model\njust canvassed will carry us very far. This has been a recurring worry\nfor act consequentialism and, for that reason, many of the most\ninfluential attempts to deal with it have emerged from philosophers\nworking in that tradition. The basic idea is that the consequences of\nour action are so many, so various, and (often) so far reaching that\nagents cannot figure out in a timely fashion what the right act is by\ndirectly using a consequentialist principle. Using the\nconsequentialist principle in this sense must of course include\ngathering the facts about the consequences, not just applying the\nprinciples to the facts as one believes or knows them to be. (For\ndiscussion of weaker and stronger senses in which an agent might\n“use” a principle, see Smith 2012.) Properly understood,\nthe worry here is not that the act consequentialist principle provides\nno guidance whatsoever; it may point quite clearly to the kinds of\ninformation that must be gathered and heeded. The worry is that\nattempts to follow the principle will not reliably lead to morally\nright action. Moreover, the worry is not simply that the principle\nfails to constitute a complete and reliable strategy. Any model of\nprincipled guidance—even one such as Kant’s—is\nliable to require that we rely also on cognitive and emotional powers\nthat go beyond the principle itself. The worry is that our normal\ncognitive and emotional powers together with the principle do not\nyield a reliable strategy for performing morally right actions. \nInstead of concluding that principled guidance is hopeless, many act\nconsequentialists have instead proposed that we replace the project of\nbeing guided by the ultimate moral standard (assuming this for the\nmoment to be some form of act consequentialism) and instead be guided\nby some more tractable set of principles. According to such\n“indirect” consequentialism, the principles we typically\nemploy in deliberation are not the ultimate standards of right\nconduct. However, an agent who employs them in deliberation will\nregularly and systematically act rightly. Such proposals have been a\nstaple of consequentialist thinking dating back at least to the work\nof Mill and Sidgwick. An especially well known recent version of the\nidea is defended by R.M. Hare, who calls reliance on such principles\n“intuitive moral thinking”. By contrast, “critical\nmoral thinking” proceeds in terms of the actual standards of\nmoral conduct (Hare 1981). Importantly, neither indirect models of\nprincipled guidance nor the worry that inspires them need be married\nto a consequentialist view of moral standards. Kantian moral\nphilosophers have sometimes stressed the need for\n“mid-level” principles (Hill 1989, 1992). Even\nparticularists about standards could consistently embrace the use of\nsuch an indirect strategy and so embrace a kind of generalism about\nmoral guidance, though so far as we know no one has actually adopted\nthis position. \nDiscussions of indirect consequentialism often proceed as if the\ncorrect moral standard could, in principle, be applied directly to any\ngiven circumstance and, if so applied, would indicate the morally\nright action(s) to take. Leaving aside whether this is true of (some)\nconsequentialist principles, many claim that it is not true of other\ncandidate moral standards. Consider, for example, principles such as\n“all persons must be treated as moral equals”, or\n“property rights must be respected”, or, to borrow a less\nmorally loaded example from Onora O’Neill, “teachers must\nassign work appropriate to their students’ abilities”\n(O’Neill 1996: 73–77). Such principles may not yield\ndeterminate guidance in concrete circumstances even given a full array\nof non-moral facts. To be properly applied, such principles may\nrequire additional moral judgment. We must determine just\nwhich individuals are persons and what it is to treat persons as moral\nequals. We must determine which claims to property correspond to valid\nrights and what invasions of property amount to a failure to respect\nthose rights. May an exhausted runner harmlessly trespass in order to\ncool off beneath the shade of another person’s tree? We must\neven decide how difficult is too difficult when it comes to\nchallenging students. The obstacle to using the standard as a direct\nguide to conduct is not that our cognitive resources come up short,\nbut that the standard is itself not yet sufficiently determinate. This\nsituation presents an opportunity for principles to play a guiding\nrole by helping to fill in the normative content of higher level\nstandards. (Whether such guiding principles would themselves count as\nnon-ultimate standards is a question we here set aside.) Importantly,\nhowever, guiding principles in this sense need not make fully\ndeterminate the higher level principles that they help to fill out.\nThey may, instead, explicitly identify further questions to be\nsettled—whether by other principles or by judgment. For example,\nthe principle that a duly convicted criminal ought to receive only the\namount of punishment he deserves is highly abstract. How ought we to\ndetermine whether a punishment is deserved? The further principle that\nthe punishment ought to be proportional to the crime may direct us to\nfind a way to proportionately rank less and more serious crimes, and\nit may thus point us part, but not all, of the way towards complying\nwith the higher level principle.  \nWe now have at least three accounts of how principles might\nfigure in a reliable strategy for acting well. But why think that\nprinciples do or must figure in the best strategies for moral action?\nOr, taking the other side, why think that principles are useless or\neven counterproductive? If one could establish or assume a specific\ngeneralist account of moral standards, this would open up many lines\nof argument for guidance by principle. The same would be true if one\ncould establish particularism about standards. However, such\nassumptions are not dialectically available in the\ngeneralism/particularism debate. Accordingly, we here focus on\narguments that are largely neutral about the content of the moral\ndomain and whether it is “principled”. \nSome generalists argue that moral principles help avoid “special\npleading”—interpreting one’s moral duties in ways\nthat favour one’s own interests and in ways that go beyond what\na reasonable accommodation of self-interest would allow. Agents who\nengage in special pleading do not do so consciously, but rather think\nthey are impartially assessing what morality demands in their\ncircumstances. The adoption of moral principles might be thought to\nhelp with this problem. For one thing, principles can be adopted and\ninternalized well before any conflict with the agent’s interests\narises. Having internalized the relevant principle well in advance may\nmake it easier to avoid special pleading when a conflict does arise\n(cf. McKeever and Ridge 2006: 202–203). Furthermore, a practice\nof articulating these principles publicly endows them with symbolic\nmeaning. Violating explicitly endorsed principles or adding caveats in\nan ad hoc manner to suit one’s interests can come to\nstand for our lacking the right kind of commitment to morality more\ngenerally (see Nozick 1993: 29; McKeever and Ridge 2006:\n204–205). Anecdotally, some people seem to think New\nYears’ resolutions work in this way, and George Ainslie has\nprovided a body of empirical evidence that such public resolutions can\nhelp motivate agents to (e.g.) stop smoking in a way that somehow\nprevents the thought that “one cigarette won’t make any\nnon-negligible difference” from undermining their resolve\n(Ainslie 1975 and Ainslie 1986). \nParticularists agree that special pleading is a problem but they do\nnot think that principles afford the proper solution to that problem.\nInstead, they typically suggest that one simply needs to “look\nharder” at the case at hand to avoid such special pleading: \n…the remedy for poor moral judgment is not a different style of\nmoral judgment, principle-based judgment, but just better moral\njudgment. There is only one real way to stop oneself distorting things\nin one’s favour, and that is to look again, as hard as one can,\nat the reasons present in the case, and see if really one is so\ndifferent from others that what would be required of them is not\nrequired of oneself. The method is not infallible, I know; but then\nnor was the appeal to principle. (Dancy 2013) \nGeneralists worry that the exhortation to look again is simply\nunrealistic, given human nature, and is therefore not only fallible\nbut unlikely to do much good. If so, then even if principles are far\nfrom infallible rejecting them wholesale is premature. The best way to\navoid special pleading could involve an array of more specific\nstrategies with principles playing some significant role. \nOn the other side particularists worry that reliance on principles\nbreeds inflexibility and a problematic tendency to shoehorn a\nmorally complex situation into some more familiar set of categories.\nMcNaughton describes such inflexibility as a “serious\nvice” and claims that reliance on principles is partly to blame\n(McNaughton 1988: 203). Dancy remarks that,  \nWe all know the sort of person who refuses to make the decision here\nthat the facts are obviously calling for, because he cannot see how to\nmake that decision consistent with one he made on a different\noccasion. (Dancy 1993: 64)  \nImportantly, this worry cannot be dismissed simply on the grounds that\ngeneralists can (and do) allow judgment to also play a role in our use\nand application of principles; the worry is that the use of principles\nhas a distorting influence of its own. One interesting and empirically\nminded proposal for evaluating the force of the particularist’s\nconcern looks to the literature on the comparative success of rules\nand expert judgment in other domains (Zamzow 2015). Much of this\nliterature suggests that rules outperform expert judgment (see Grove\net al. 2000). \nLet us turn now to a second family of arguments for principled\nguidance. Setting aside whether principles are a winning strategy for\nthe individual aiming at virtuous action, one might think that our\ncollective use of principles enables us to achieve morally valuable\ngoods. One such argument appeals to the value of predictability\n(Hooker 2000, 2008). Successful cooperation and coordination yield\nenormous benefits yet it requires an ability to predict the behaviour\nof others and a willingness to rely on those predictions when making\none’s own choices. If principled guidance supports\npredictability, so much the better for principles. Not surprisingly,\nparticularists have questioned whether principles are necessary for\npredictability. “People are quite capable of judging how to\nbehave case by case, and in a way that would enable us to predict what\nthey will in fact do” (Dancy 2004: 83). The key issue is\ncomparative. Is the person guided by principles thereby more\npredictable than the person who eschews principles? Someone who\nrejects moral rules altogether and always just tries to judge each\ncase on its own merits plausibly is less predictable than someone who\nhas internalized and follows a set of moral principles. But as we saw\nabove, assessing the force of this generalist argument would benefit\nfrom consideration of careful empirical research. One challenge for\ngeneralists who might further develop this argument is that it stands\nin some tension with other themes stressed by generalists, for\nexample, that principles can incorporate various hedges and so exhibit\nthe kind of flexibility particularists embrace (Väyrynen 2008)\nand that principles are often indeterminate and must be supplemented\nby judgment. To be consistent, generalists will need to show not only\nthat guidance by crude principles makes one more predictable, but that\nguidance by a combination of hedged principles and judgment makes one\nmore predictable than guidance by judgment alone. \nA very different practical argument for generalism has roots in the\nKantian tradition and has recently been advanced by Stephen Darwall\n(2013, see also Darwall 2006). He contends that publicly formulable\nprinciples are necessary for us to realize a valuable form of\ninterpersonal accountability in our shared moral life. He further\nargues that such accountability is necessary for moral obligations\n(though not necessarily for moral reasons). Within the framework here\ndeveloped, one might see Darwall’s argument as a defense of\ngeneralism about standards but with the argument restricted\nto standards of moral obligation. Alternatively, one might\nsee it as a practical argument for attempting to formulate shared\npublic principles because, if we fail to do so (or fail to continue to\ndo so), we will lose something that we take to be valuable about\nmorality, namely the respect for persons that is inherent in a\npractice of interpersonal accountability (Darwall 2013: especially\n183–191). Darwall’s argument fits very well with Kantian\ncontractualism of the sort defended by T.M. Scanlon, which emphasizes\nthe value of our being able to justify ourselves to others and sees\nprinciples as mediating justification. It might also be instructive to\ncompare Darwall’s argument with some of the ideas found in the\ntradition of discourse ethics associated with Jürgen Habermas\n(see, e.g., Habermas 1990). An important challenge for this argument\nis to persuasively establish the premise that accountability (or\ninterpersonal justification) must advert to principles. Particularists\nmay allow that accountability is an important value while urging that\nthe interpersonal process of holding one another accountable can\nproceed entirely in terms of the reasons, defeaters, enablers, and\nintensifiers that are at play in the case at hand.","contact.mail":"mridge@staffmail.ed.ac.uk","contact.domain":"staffmail.ed.ac.uk"},{"date.published":"2016-11-22","date.changed":"2016-11-29","url":"https://plato.stanford.edu/entries/moral-particularism-generalism/","author1":"Michael Ridge","author1.info":"http://www.philosophy.ed.ac.uk/people/full-academic/michael-ridge.html","author2.info":"https://www.davidson.edu/academics/philosophy/faculty-and-staff/sean-mckeever","entry":"moral-particularism-generalism","body.text":"\n\n\nAmong the many questions that arise in the attempt to come to\nphilosophical grips with morality is what role, if any, moral\nprinciples have to play. Moral generalists think morality is best\nunderstood in terms of moral principles; moral particularists deny\nthis. To many people, ordinary moral practice seems suffused with\nprinciples (keep your promises; do not steal; do unto others as you\nwould have them do unto you). To many moral theorists, the central\ntask of moral theory has been to articulate and defend moral\nprinciples, or, perhaps, a single ultimate moral principle (maximize\nimpersonal happiness; act only on maxims that can be willed as\nuniversal law). The debate between particularists and generalists thus\nhas the potential to force a reassessment of both moral theory and\nmoral practice. \n\n\nThis characterization of the debate is so far too impressionistic to\nprovide a tractable framework for philosophical inquiry. The\nliterature reveals many ways to sharpen the debate, and sharpening is\nindeed needed. But both generalism and particularism are best seen as\nintellectual traditions in moral philosophy, each of which has a\nnumber of distinct but related strands. This article attempts to\ndisentangle some of those strands with the most attention being given\nto recent stages of this debate.\n\n\nThe arguments for and against both particularism and generalism are\nalso diverse, arising from metaphysics, epistemology, normative theory\nand the philosophy of language. These arguments also interact in\ninteresting ways with other debates in moral philosophy. Finally, it\nis very much an open and interesting question to what extent other\nareas of philosophy (e.g., the philosophy of language and\nepistemology) can usefully draw on ideas developed in the debate\nbetween moral particularists and moral generalists. \n\nAristotle might reasonably be characterized as the\n“forefather” of particularism. Aristotle famously\nemphasizes that ethical inquiry is mistaken if it aims for “a\ndegree of exactness” too great for its subject matter, and added\nthat moral generalizations can hold only “for the most\npart”. Moreover, Aristotle tirelessly emphasizes that ethics\nultimately concerns particular cases, that no theory can fully address\nthem all, and that “judgment depends on perception” (NE,\n1109b). These ideas have all deeply inspired contemporary\nparticularists (John McDowell is a prominent case, though he does not\ntend to label himself as a particularist; see McDowell 1981, 1998).\nWhether Aristotle should ultimately be interpreted as a particularist\nis a matter of debate (Irwin 2000; Leibovitz 2013). \nInterestingly, no single major historic figure is most obviously\ncharacterized as the “forefather” of generalism. This is\npresumably because the most important historic generalists in effect\ndefended generalism by defending specific moral theories or\nprinciples. The two most important traditions here are the\ndeontological tradition which owes so much to Kant, and the\nconsequentialist tradition which owes so much to the British\nutilitarians (Bentham, Mill and Sidgwick). Nonetheless, each of these\ntraditions substantially enriched the generalist approach with a\nwealth of ideas and distinctions which need not be restricted to the\ntheories in which they were originally formulated. \nThe Kantian tradition puts enormous weight on the idea that morality\nmust be principled and that the ultimate principle of morality must be\none we can know a priori. According to Kant, the moral law as\napplied to imperfect agents who are subject to temptations, provides\nwhat he called a “categorical imperative”—an\nimperative whose rational authority is not dependent on the\nagent’s contingent ends. Kant provided several formulations of\nthe categorical imperative. The so-called “universal law”\nformulation holds that one must always act so that one’s maxim\ncould at the same time be willed as a universal law. The humanity\nformulation holds that one must always act so as to treat humanity,\nwhether in one’s own person or that of another, always as an end\nand never merely as a means. The Kantian tradition emphasizes common\nsense moral ideas like respect and dignity, and provides a distinctive\ninterpretation of the role of universalizability in moral thought. On\nsome readings of Kant, the moral law must itself be\nconstitutive of being a rational agent at all. This idea has,\nin turn, been enormously influential, especially in the late twentieth\nand early twenty-first century.  \nConsequentialism enriched the generalist framework in other ways. Most\nnotably, perhaps, consequentialists have often distinguished between\ntwo very different kinds of principles, corresponding to two\nrather different roles they may play. On the one hand, there\nare principles—call them “standards”—which\nprovide the deepest explanation of why certain actions are\nright or wrong. On the other hand, there are the principles which\nordinary agents ought to follow in their day to day deliberations.\nSuch principles are “guides”. Consider a simple analogy\nwith the stock market. The principle which explains what counts as\nsuccess might simply be “buy low and sell high”, but this\nprinciple is woefully inadequate as a guide to making investment\ndecisions in real time. A principle like “have a diversified\nportfolio” seems much more suitable for the latter role. \nEach of these traditions (the Kantian and the consequentialist) faces\na number of prima facie powerful objections. It is therefore\nperhaps not surprising that there was ultimately a reaction against\nthe broader generalist aspirations that these theories embodied. On\nsome readings, one of the earliest particularists in the modern sense\nwas Ewing, who in The Morality of Punishment (1929) argued\nthat consequentialism and deontology were the only plausible\nprincipled conceptions of morality, that neither was defensible, and\nthat morality was therefore not principled (cf. Lind &\nBrännmark 2008 interview with Dancy, who explicitly characterizes\nEwing in this way at p. 10). \nJust one year after Ewing in effect defended a fairly radical form of\nmoral particularism, W.D. Ross argued for a more moderate form. Ross\noccupies a very interesting place in the history of particularism, as\nhe has served as both an inspiration and a foil to modern\nparticularists. Ross put forward a battery of “prima\nfacie duties” specifying types of conduct—for example\nacts of gratitude—that are always, in some sense, obligatory.\nThe obligation in question need not be an all things considered one,\nhowever, since a conflicting prima facie duty might, in the\ncircumstances, be more important. \nSetting aside whether Ross thought anything theoretically useful could\nbe said about how to adjudicate conflicts of prima facie\nduty, he did not think it useful to try to formulate exceptionless\nprinciples with regard to all things considered duty (cf. Postow\n2006). Ross thus appears to be a generalist about prima facie\nduty, but a defender of particularism about overall duty. Some\ncontemporary particularists, however, insist on going beyond Ross and\ncasting doubt even on principles of prima facie duty, or\nprinciples specifying which considerations are pro tanto (or\n“contributory” in Jonathan Dancy’s terminology)\nreasons. \nJonathan Dancy has done more than anyone to articulate and defend an\nespecially radical form of particularism. Although Ross was both a\nfoil and an inspiration for Dancy, R.M. Hare was a more immediate\nopponent. Hare’s prescriptivism drew on ideas from both the\nKantian and the consequentialist tradition. Hare defended a strong\nform of universalizability which can be traced to Kant, but Hare then\nargued that universalizability lent support not to a deontological\nmoral theory, but to a form of consequentialism. Indeed it led to a\nform of consequentialism which emphasized the distinction between\nstandards and guides (cf. Hare 1963). \nIn the introduction of Moral Reasons, Dancy summarizes his\nconclusions as the “mirror image” of Hare’s. Perhaps\nmost notably, Dancy objected to an idea which he took to be implicit\nin Hare’s universalizability principle, that if a consideration\nis a reason in one context then it is a reason with the same valence\nin any possible context in which it occurs. (This reading of\nHare is open to objection. See McNaughton and Rawlings (2000) for\ndiscussion.) Dancy calls this idea, which he also attributes to Ross,\n“atomism” in the theory of reasons and argues against it\nand in favour of what he calls “holism”. \nAs Dancy’s early work came to fruition, it inspired his\nthen-colleague David McNaughton to advance distinct but complementary\narguments for particularism. McNaughton was also heavily influenced by\nthe work of John McDowell, who had argued that it was an advantage of\nhis own brand of moral realism that it did not presuppose generalism\n(see McDowell 1981; see also Blackburn 1981). In Moral\nVision, McNaughton defended a form of moral realism which he\nargued lent support to particularism. He also argued that\nparticularism better accounts for moral conflict, fits reasonably well\nwith ordinary practice and can explain why we might reasonably be\nsuspicious of the very idea of a moral expert. \nThe work of Dancy and McNaughton inspired a host of other philosophers\nto carry forward the particularist research programme, sometimes in\nrather different directions. This eventually led to a wide variety of\nviews all going under the heading of “particularism”. Nor\nwere the challenges posed by these many moral particularisms ignored\nby those with more generalist sympathies. Woken from their generalist\nslumbers, they began to develop arguments for generalism which did not\ndepend on the correctness of any particular moral principle(s). This\ngenerated a healthy debate, the contours of which the rest of this\nentry will outline. \nParticularists are united in their opposition to moral principles and\ngeneralists are united in their allegiance to them. What, though, is a\nmoral principle? At least three conceptions of principles are worth\ndistinguishing. First, there are principles qua\nstandards. Standards purport to offer explanations\nof why given actions are right or wrong, why a given consideration is\na reason with a certain valence and weight, why a given character\ntrait is a virtue, and the like. An especially robust metaphysical\nspin on this conception understands standards as being\ntruth-makers for moral propositions (cf. Armstrong 2004).\nSecond, there are principles qua guides. These\npurport to be well suited to guiding action. Third, there are\nprinciples purporting to play both of these roles\nsimultaneously—action-guiding standards. \nIt is not hard to see these different conceptions of moral principles\nat work in the history of moral philosophy. In the utilitarian\ntradition in moral philosophy, the principle of utility (however it is\nformulated) is characteristically understood as a standard. Even if\nsome politically minded utilitarians see advantages to using the\nprinciple of utility to guide public choice and justification, moral\nphilosophers tend to follow Mill in thinking that the principle is\nseldom apt for use in individual moral decision-making. They thus deny\nthat it should be understood as a principle qua\nguide. Indeed, some utilitarians go further and argue that\nthe principle of utility is self-effacing, in the sense that\nit recommends its own rejection (cf. Railton 1984; see also Parfit\n1984). Utilitarians instead hold that various maxims of common sense\nmorality should be understood as heuristics which work well enough for\nnormal human beings, so there is room in this picture for principles\nqua guides. \nKant, on the other hand, seemed to have understood the categorical\nimperative as a kind of action-guiding standard. Kant’s\ndiscussion of examples in the Groundwork (1785) and his\ncharacterization of the Formula of Universal Law as appropriate method\nfor testing our maxims makes clear that he thinks of it as\nappropriately guiding the actions of the morally virtuous agent.\nEqually clearly, the categorical imperative is to be understood as the\nmost fundamental explanation of why given actions are right or wrong,\nand so also counts as a principle qua standard. On a\nconstitutivist reading, the categorical imperative is meant to play\nboth of these roles in virtue of its constituting our rational agency.\nFinally, it is worth noting in this context that a principle can\nfunction usefully as a guide even if its application requires\njudgment and sensitivity; principles qua guides need not be\nalgorithmic. \nPrinciples can also be distinguished in terms of their scope.\nSome principles have purely non-moral antecedents (e.g., the principle\nof utility), whereas others use moral concepts in both their\nantecedents and consequents (e.g., “if an action is just then it\nis morally permissible”). Finally, principles can be\ndistinguished in terms of whether they are in some sense\n“hedged”, including a ceteris paribus clause of\nsome kind (e.g., “other things equal, lying is wrong”), or\nunhedged. \nOne might be a particularist or a generalist about moral principles\nunderstood in any of these ways. Whether being a particularist or\ngeneralist about principles in one sense drives one to be a\nparticularist or a generalist about principles in another sense is not\na trivial question. Further complicating matters, there is more than\none way to oppose principles (however those principles are conceived.)\nLast, the form a particularist’s opposition takes might\nreasonably vary across different types of principle. Let us now review\ndifferent ways one might oppose principles. \nThe simplest form of opposition, Principle Eliminativism,\nsimply denies that there are any moral principles. Of course, it must\nbe borne in mind here and below that a principle eliminativist may\ndeny that there are any principles of one sort, while allowing for\nprinciples of another sort. For example one might be an eliminativist\nabout principles purporting to give the application conditions for\nmoral predicates in entirely non-normative terms (McNaughton 1988) or\nan eliminativist about exceptionless principles (Little 2000).\nPrinciple Scepticism holds, more modestly, that we do not\nhave sufficient reason to believe there are any moral principles.\nPrincipled Particularism holds that while any given moral\ntruth is explained by a moral principle, no finite set of moral\nprinciples can explain all the moral truths (Holton 2002).\nAnti-Transcendental Particularism, which at one point at\nleast was Dancy’s favoured gloss of the view, holds that moral\nthought and judgment does not depend on the supply of a suitable stock\nof moral principles. Finally, Principle Abstinence asserts a\nmore practical opposition to moral principles, holding that we ought\nnot be guided by moral principles. For each of these forms of\nparticularism, there is a corresponding form of generalism which is\nsimply the denial of the particularist thesis in question. \nAlthough this taxonomy entails that the logical space for\nparticularist (and generalist) views is wide and heterogeneous, it\nwould be a mistake to assume that all of the positions which can be\nderived from a matrix constructed on the basis of these distinctions\nreally are distinct in any deep way. For example, Principle\nEliminativism about principles qua guides\narguably is equivalent to Principle Abstinence about\nprinciples tout court. \nThe debate between particularists and generalists is often framed in\nmetaphysical terms. In this guise, the debate primarily concerns\nprinciples conceived as standards. Moral principles might then be\nthought of as true and law-like generalizations about moral properties\nor, alternatively, as nomic regularities involving moral properties.\nTo be clear, generalizations in the relevant sense need not actually\nbe instantiated to be true; plausibly, the moral law would still be\ntrue in a world with no agents and hence with no right or wrong\nactions. This view has been developed, in different ways, by McKeever\nand Ridge (2006), Väyrynen (2006, 2009) and Lance and Little\n(2007), though it is not universally accepted (see Robinson 2008).\nThus understood, particularism is often taken to have an affinity with\nnon-reductive or non-naturalist views in ethics. Furthermore, it has\nbeen noted that contemporary particularism arose alongside a\nresurgence of interest in non-naturalism (cf. Little, 1994). To a\ndegree, this is understandable. After all some naturalist\nviews appear to entail generalism. A form of reductive naturalism\naccording to which being morally right is metaphysically identical\nwith being an act which maximizes human happiness appears to entail a\nrobust utilitarian principle and so, a fortiori, to entail\ngeneralism. Furthermore, if one denies any kind of reduction of moral\nproperties to natural properties then it becomes more difficult to see\nhow any informative statements connecting moral and non-moral\nproperties could be sufficiently law-like to count as principles.\nNevertheless, one ought not to take it as given that non-naturalists\nmust be particularists or that naturalists must be generalists. Both\nclassic and contemporary non-naturalists have endeavored to defend\nprinciples (Moore 1922 [1903]; Shafer-Landau 2003). Furthermore, there\nmay be room for particularists to embrace naturalism by claiming that\nparticular reasons are always grounded in some particular natural\nproperty instance while maintaining particularism by claiming that\nthere are no law-like generalizations connecting moral and non-moral\nproperty types. Perhaps because the commitments and resources of\nnon-naturalist and naturalist views in metaethics (and even how\nproperly to distinguish these views from each other) remains\ncontested, one cannot uncontroversially map the\ngeneralism/particularism debate onto the naturalism/non-naturalism\ndebate. \nNon-naturalism would seem to have less bearing on a further question:\nwhether there are moral principles connecting one moral property to\nanother. This issue is at play in Ross’s rejection of\nMoore’s claim that the right action is the action which\nmaximizes the good. Even if Ross relied on Moore’s own\n“open question” strategy to challenge Moore’s\nutilitarian principle, it is nevertheless the case that Moore’s\nprinciple is at least consistent with non-naturalism. More recently,\nphilosophers sympathetic to particularism have divided over the\navailability of intra-moral principles. Some are content to allow that\na claim such as, “the fact that an action is just is a reason in\nits favour”, is true and informative (cf. McNaughton and Rawling\n2000). Others propose a more radical particularism according to which\neven intra-moral principles—that is, principles linking one\nmoral concept with another—are unavailable (cf. Dancy 2004: ch\n7). \nNaturalists and non-naturalists typically share a commitment to\nsupervenience. Roughly put, supervenience says that, necessarily,\nthere can be no moral difference without some natural (or non-moral)\ndifference. There are various ways to interpret supervenience and its\nmetaphysical significance. So long as we reject a global error theory,\nthough, supervenience seems to guarantee some necessarily true\nuniversal generalizations involving moral predicates. \nNevertheless, it is generally agreed by all sides that such\n“supervenience functions” should not count as moral\nprinciples. The grounds offered for this are various, but include that\nsuch generalizations contain much potentially irrelevant information,\nthat they are massively disjunctive, and that they lack explanatory\nimport (cf. Little 2000; Dancy 2004; McKeever and Ridge 2005). The\nidea is that to be a successful moral principle (qua\nstandard) requires more than a true or even necessary connection\nbetween the descriptive and the moral. The connection must be\nexplanatory and not cite irrelevant features in the antecedent either.\nEven those who gesture at supervenience in mounting arguments for\ngeneralism concede that a successful argument requires significant\nadditional semantic or epistemological premises (see below, and cf.\nJackson, Pettit, & Smith 2000). \nWhile particularism has strong affinities with non-naturalism, the\nmost prominent argument for particularism—the argument from the\nholism of reasons—has proceeded from a more targeted and\nspecific claim about the metaphysics of moral reasons (see McNaughton\n1988; Dancy 1993; Little 2000). According to holism about reasons, a\nconsideration that counts as a reason in one case may not count as a\nreason in another case, or may count as a reason, but in a different\ndirection. By way of illustration, the fact that a remark would be\nfunny might be, in one case a reason for making the remark, in another\ncase a reason against making the remark, and in still another case no\nreason at all. In short it depends on context. Importantly, holism is\nmeant to be a universal and modal claim. It says that for any\nconsideration that is a reason it is possible that that consideration\nmight behave differently in another case. Thus understood, holism is\nconsistent with the possibility that some considerations are, as a\nmatter of fact, reasons (of the same force and direction) in every\ncase. Holism also seems to presuppose that the considerations that are\nreasons are not brutely unique; the insight of holism—if it is\nan insight—is built upon the thought that a consideration which\nis a reason in one case is repeatable in other cases. Only if, for\nexample, the funniness of a remark is a consideration that is\nrepeatable can we say, as the holist wants us to, that the funniness\nof a remark is a reason in one case but is not a reason in\nanother. \nThose attracted to holism about reasons agree that it is typically\nspecific elements of context that further account for whether a\nconsideration counts as a reason, and a rich language for\ncharacterizing context has been developed. For example, a putative\nreason might be defeated, enabled, or intensified by specific elements\nof the context. To continue the previous example, the fact that a\ngenuinely funny remark would also be offensive might defeat whatever\nreason-giving force that the humor might otherwise have had. On this\nreading, the humor of the remark is no reason at all; not just a\nreason that is outweighed. To vary the case again, the fact that\none’s audience will appreciate a (non-offensive) funny remark\nenables the humor to be a reason. Here the humor is a reason, but only\nagainst the background of a receptive audience; the background\nfunctions as an “enabler”. Finally, the fact that a funny\nremark will break an unduly somber mood may intensify the force of\nhumor as a reason. Humor itself is especially apt, but only because\nthe mood is unduly somber. Other factors could function as\nattenuators, weakening the force of a reason (see Dancy 2004: ch 5).\n \nHolism depends crucially on the sustainability of the distinction\nbetween the particular considerations that count as reasons and the\ncontextual factors (defeaters, enablers, etc.) that impact whether a\nconsideration counts as a reason. Context-sensitivity without such a\ndistinction would be unable to explain why a feature which is a reason\nin one context can fail to be a reason in another. Moreover, we need\nto know why the relevant features should not be “hoovered\nup” into the content of the reasons themselves. After all,\natomists need not be simple atomists. A hedonist who held that\npleasure and pain are both always reasons and the only reasons, would\ncertainly count as an atomist. But atomists can allow for significant\npluralism and complexity. One way to do so is to insist that the\nconsiderations that a holist calls, variously, reasons, defeaters,\nenablers, and so on are all but parts of a larger more complex\n“whole” reason. Such views have been proposed by Bennett\n(1995), Crisp (2000), Hooker (2003) and Raz (2000), and rejected by\nDancy (2004: 6.2). One worry about the atomists’ appeal to whole\nreasons is that if reasons are identified with large complexes of\nfacts, then the same reason may seldom recur across cases and the\nclaim that agents act for reasons may fall under threat (Price\n2013). \nSetting aside whether holism is true, does it support particularism?\nGeneralists have rejected the inference on the grounds that holism\nleaves open the possibility that the behaviour of reasons, defeaters,\nenablers, and intensifiers/attenuators is codifiable (see\nVäyrynen 2004; McKeever and Ridge 2005). They also observe that\nsome paradigmatic generalists seem to have exploited this logical\nspace. For example, Kant arguably thinks that the fact that a course\nof action would advance someone’s happiness is of variable moral\nsignificance, counting in favor whenever the happiness and its\npurchase is consistent with the categorical imperative and counting as\nno reason at all otherwise (McKeever and Ridge 2005). Particularists\nhave countered that even if holism is logically consistent with\nprinciples it would nevertheless render them “cosmic\naccidents” (Dancy 2004: 82). If this were right it would be\nenough to cast doubt on the generalist tradition in moral philosophy.\nWhy should the heart of a discipline be the search for cosmic\naccidents?! Generalists counter that whether principles are cosmic\naccidents depends entirely upon underlying metaphysical issues and not\non whether principles tolerate holism. For example, if the property of\nbeing good is identical to the property of being non-malicious\npleasure, then the associated holism tolerating principle does not\nlook to be a cosmic accident (see McKeever and Ridge 2006: 2.2). \nSelim Berker (2007) has challenged the particularist argument from\nholism in another way. He argues that the conjunction of holism with\nwhat he calls the particularist’s\n“noncombinatorialism” about the ways reasons combine to\nfix an overall verdict leaves the particularist with no coherent\nnotion of a reason for action. To understand noncombinatorialism, one\nmust first understand the idea of a “combinatorial\nfunction”. A combinatorial function takes as input all the\nreasons and their valences in a given situation and gives the\nrightness or wrongness of actions in that situation as an output.\nNoncombinatorialism simply asserts that the combinatorial function for\nreasons cannot be finitely expressed (and so, in particular, is not\nadditive). Berker argues that particularists are committed to\nnoncombinatorialism, but that this leaves them with no coherent notion\nof a reason for action. Particularists typically gloss being a reason\nas “counting in favour” of that for which the\nconsideration is a reason. Berker’s point is that talk of a\nconsideration “counting in favour” of something is itself\nhard to make intelligible once we abandon a combinatorial conception\nof how reasons combine to fix an overall verdict. We are left with a\nmetaphor that cannot be cashed out in any helpful way. Particularists\ncould of course abandon the noncombinatorial conception of reasons,\nbut Berker argues that this would commit them to the truth of numerous\nexceptionless principles, thus compromising their particularism. (For\ncritical discussion of Berker’s argument, see Lechler 2012.) \nSo far we have focused on generalist replies to metaphysical arguments\nfor particularism. Generalists are not without positive metaphysical\narguments for their own views, though. Most notably, so-called\n“constitutivists” sometimes invoke premises about the\nmetaphysics of rational agency to argue for generalism. Kantian\nconstitutivists are the most influential and clear-cut instance of\nthis style of argument. Christine Korsgaard, for example, argues that\nthe categorical imperative is constitutive of rational agency\n(Korsgaard 2008, 2009). The rough idea is that the principles of\npractical reasons unify us as agents, and allow us to take control\nover our representations of the world and our movements (Korsgaard\n2008: 9). Insofar as simply being a rational agent commits one to the\nrelevant principle(s), this strategy for defending generalism is also\nmeant to be especially effective at silencing sceptical challenges,\ne.g., classic “why be moral?” challenges. The thought is\nthat the sceptic has no coherent perspective from which to reject the\nrelevant principles. \nWhatever the success of these metaphysical arguments, some\nparticularists have worried that an excessive focus on metaphysics\nthreatens to lead us astray—not to falsehood so much as\nmisplaced emphasis. The ontological status of moral laws and the\ngrounding of moral reasons ought not predominate the particularist\nprogram. Instead, the particularist should emphasize how their account\nof moral psychology makes sense of moral development and competence\n(see Bakhurst 2008, 2013).  \nParticularists and generalists typically share a commitment to moral\nknowledge. This common ground is not strictly entailed by either view.\nFor example, proponents of Hare’s universal prescriptivism will\ninsist that moral thought is principled even if, in their rejection of\nthe truth-aptness of moral language, they deny that there is moral\nknowledge. On the other side, a fictionalist might reject moral\nknowledge while insisting that the moral fiction is itself devoid of\nprincipled structure, just as the particularist insists. Nevertheless,\nboth generalists and particularists do in fact typically see moral\nthought and judgment as achieving (sometimes) significant success and\nin this context the shared commitment to moral knowledge is not\nsurprising.  \nParticularists and generalists often treat moral knowledge as being on\na par with other types of commonly accepted knowledge. Just as we can\nknow that our internet connection is running slow, that the milk is on\nthe verge of going stale, or that our friend is annoyed by the story\njust told at his expense, so too we can know that it would be wrong\nrefuse directions to the person who is lost, that our co-worker was\ncourageous to criticize her supervisor, and that the American justice\nsystem treats many people unfairly. Because the commitment to moral\nknowledge is a shared one, many of the arguments both for and against\nparticularism have sought to use it for dialectical leverage. The\nquestions at stake include whether particularism or generalism best\nexplains our capacity to achieve moral knowledge and whether\nparticularism or generalism best models the person who has and uses\nmoral knowledge. \nSome moral knowledge, it is agreed, involves the transmission or\nextension of other moral knowledge already achieved. If Solomon tells\nme the treaty is unjust, I may know this by relying on his testimony.\nIf every member of the Diogenes Society whom I have met is honest,\nthen I may know that Walter, who is also a member, is honest. Here, I\nrely on an induction from my other moral knowledge. While highly\ninteresting, these types of knowledge are typically regarded as\nderivative (Zangwill 2006) and are therefore set aside in arguments\nover moral particularism. The question is what explains our most basic\nmoral knowledge. How strong an assumption can be made about our moral\nknowledge while remaining on ground common to both generalists and\nparticularists? Obviously, particularists will not grant that we have\nknowledge of moral principles, and the point of surest agreement is\nthat we sometimes know the moral status of a particular case, e.g.,\nthat this act was wrong. However, most arguments both for and against\nparticularism deploy somewhat stronger assumptions.  \nFirst, one may make a stronger assumption about the objects of moral\nknowledge. Of special interest is the possibility that we can know\ngeneral truths about morality even while such general truths fall\nshort of counting as moral principles. For example, while\nparticularists will deny that there is any exceptionless moral\nprinciple to the effect that pain is bad, many sympathetic to\nparticularism would agree that, as a general matter, pain is bad and\nthat we can know this. On a deflationary reading, one might treat the\nclaim that pain is bad as a useful heuristic, a reminder that pain has\noften been bad in the past and may well be so in the future (Dancy\n1993). Alternatively, that pain is bad might capture an interesting\nmetaphysical fact about pain; its default status is the status of\nbeing bad. We can understand default status in terms of an explanatory\nasymmetry. When pain is not bad there must be something that explains\nwhy it is not, but when pain is bad there needn’t be any further\nexplanation of what makes pain bad (Dancy 1993, 2004). Finally, one\nmight try to invest such generalizations with real explanatory power\nwhile insisting they remain exception laden. That pain is bad is a\nkind of defeasible generalization, where this amounts the claim that\npain is bad in a privileged set of worlds (Little 2000; Lance and\nLittle 2004; for critical discussion of each of these possibilities,\nsee Stangl 2006). \nSecond, one may make a stronger assumption about the scope of moral\nknowledge, at least for some people. Some people, one may assume, are\n(or become) especially good at acquiring moral knowledge; they have a\nmeasure of practical wisdom or expertise. Their knowledge thus readily\nextends not just to their actual circumstances but to a broad array of\nnovel circumstances as they arise. In so far as this is so, we should\nlike to have a good explanation not only of how humans acquire\nspecific knowledge but also of how they develop over time into more\ncompetent moral knowers (Bakhurst 2005, 2013). \nTwo models of moral knowledge predominate in defences of\nparticularism: a perceptual model and a skill based model. According\nto the perceptual model successful moral judgment is properly\nanalogous to sense perception even if it is not, literally, a form of\nsense perception (McDowell 1979, 1985; McNaughton 1988). Moral\njudgment on this view depends upon a range of sensibilities, developed\nthrough experience and acculturation. Once developed, however, one can\njust “see”, for example, that a certain response is\nmerited by a situation. As John McDowell puts it,  \nOccasion by occasion, one knows what to do, if one does, not by\napplying universal principles, but by being a certain kind of person:\none who sees situations in a certain distinctive way. (McDowell 1979:\n350) \nSince sensibilities may be more or less refined, the perceptual model\nappears to fit well with the idea that there are both moral novices\nand experts. Whatever further account is to be given of these\nsensibilities, the resulting knowledge is not dependent upon any\ndeduction from general moral principles, at least not one\ntransparently and readily available to the knower. Generalists have\nobserved that similar perceptual metaphors seem equally apt in domains\nthat admit of principles (McKeever and Ridge 2006: ch 4). For example,\none might just “see” that a sentence is ungrammatical even\nif grammaticality is rule-governed. Furthermore, some who develop and\ndefend a perceptual model are not led by it to particularism (Audi\n2013). So the perceptual model of moral knowledge seems not to\nestablish particularism, but it was likely never meant to. Instead,\nthe perceptual model is intended to offer more indirect support. If\nour moral experts reliably achieve moral knowledge without\nself-consciously adverting to moral principles, then the generalist\ninherits at least some burden to explain why principles should be a\ncenterpiece of moral theorizing. \nTwo related constraints confront the development of the perceptual\nmodel and may threaten the particularism the model is taken to\nsupport. The first is that the model must extend to prospective and\nhypothetical cases. Particularists and generalists typically agree\nthat we sometimes have knowledge that if we were to perform an action\n(say maintain a confidence) in our actual circumstances, that action\nwould be right. This seems essential if moral knowledge is to precede\nand guide virtuous conduct. Similarly, if slightly more\ncontroversially, we sometimes have knowledge that a certain course of\nconduct would be right in some hypothetical circumstance. While one\nmight try to account for such cases by appeal to inductive reasoning\nfrom past actual cases, this is not, in fact, how proponents of the\nperceptual model have proceeded. The second constraint arises from the\nfact that moral properties are grounded in other properties. For\nexample, it barely makes sense to say that an action’s wrongness\nis a brute fact about it; if wrong an action must be wrong on account\nof some otherwise specifiable features it has. While this\n“because constraint” admits of various explications, the\nbasic idea is common ground and widely thought to be a priori\n(Zangwill 2006). \nGeneralists argue that, once spelled out, the perceptual model is not\nthe a posteriori epistemology it might first have seemed but\ninstead commits us to a priori intuitions relating moral\nfeatures to their grounds. Particularists may grant that basic moral\nknowledge is a priori knowledge of “what is a moral\nreason for what” (Dancy 2004: 141) while maintaining that the\nobject of knowledge remains particularized and does not implicate\nprinciples. One challenge for the particularist is that “what is\na reason for what” in a particular case is contingent, and so\nthe particularist risks being committed to a priori knowledge\nof contingent truths. In his defense of particularism, Dancy has been\nwilling to embrace this apparent consequence (Dancy 2004; for\ncriticism, see McKeever and Ridge 2006). Other particularists have\nsought to avoid the implication (Leibovitz 2014). \nParticularists sometimes pursue a somewhat different model of moral\nknowledge, one that likens the practically wise agent to a person who\nhas a developed skill. Just how different this model is from the\nperceptual one must depend upon how each is spelled out. But whereas\nthe perceptual model directs our attention first to how the virtuous\nperson understands her situation, the skill model draws attention to\nthe knower as agent, someone who classifies actions, agents, and\nstates of affairs as falling under moral categories, who reasons to\nmoral conclusions, and ultimately puts their knowledge into outward\naction. How might this skill be understood and, relatedly, how much of\nan account of it does the particularist owe? Some particularists\n(sometimes) demur. For example, Dancy described the virtuous agent as\nsomeone possessed of a “contentless ability” to discern\nwhat matters when it matters (Dancy 1993: 50). But many sympathetic to\nparticularism would want to say more (Garfield 2000; Leibovitz 2014).\nOne might liken the skill of the virtuous person to a behavioral\nability, such as the ability to ride a bicycle. While this analogy\ncould prove apt, it risks underrating the extent to which the virtuous\nperson’s action is rich with judgment and reasoning and is not\nsimply a sequence of successful performance. \nOne way to develop the skill model is to urge that the skill of the\nvirtuous person is akin to the skill of the person with conceptual\ncompetence and then rely on Wittgensteinian rule-following\nconsiderations to urge that conceptual competence cannot be fully\nunderstood in terms of rules or principles. This approach lends itself\nto a form of particularism that is less hostile to principles. The\nclaim is not that there are no principles but that practical wisdom\ncannot be fully reduced to principles (McDowell 1979). A\nperhaps similar strategy can be pursued by focusing on principles of\nreasoning and urging that valid principles of reasoning cannot be\ntreated simply as objects of propositional knowledge akin to premises\n(Carroll 1895; Thomas 2011). One seeming consequence of these\nstrategies is that particularism it not something distinctive of\nmorality and other cognate domains. Particularism would be true\neverywhere we apply concepts or everywhere we reason. Some might\nwelcome such global particularism, but we would have lost what for\nsome was initially attractive—that particularism seemed to\nidentify something distinctive (even if not unique) about morality. A\nsecond worry is that particularism may no longer pose the threat to\ntraditional moral theory that is sometimes supposed. If the\ncategorical imperative were shown to have the same status as modus\nponens, Kantians could sleep easily. \nAnother way to develop the skill model could urge that the skill in\nquestion is the skill of applying (or reasoning with) generalizations\nof a certain kind. Here the claim may be that moral principles (or\ngeneralizations) require judgment to apply, or are defeasible, or come\nwith implicit ceteris paribus clauses. This commits the\nparticularist to principles of a kind, while also allowing both that\nmorality is importantly distinctive and that some traditional moral\ntheorists have erred by seeking a sort of principle that is not to be\nfound. This path leads to interesting intermediate positions that are\ncertainly more friendly to principles than Dancy’s particularism\nwhile at the same time concerned to emphasize the limitations of\nprinciples. For example, Richard Holton (2002) suggests that sound\nmoral principles are conditionals containing an implicit\n“that”s it’ clause. The dictum that lying is wrong\nis then more perspicuously expressed as the claim that if an action\namounts to lying and “that”s it’ then the action is\nwrong. In this context, “that’s it” expresses the\nidea that no other moral principle, given the facts at hand,\nsupersedes the principle that lying is wrong. \nA different but similar idea is developed by Mark Lance and Margaret\nLittle, who advance a model of true but defeasible moral\ngeneralizations. Here, the claim that lying is morally wrong is\nelaborated as the claim that lying is wrong under privileged or normal\nconditions. Conditions might fail to be privileged for any number of\nreasons—perhaps because the murderer is at the door looking for\nyour helpful information or, less dramatically, we might be playing a\ngame in which deception is part of the fun. As this last possibility\nsuggests, Lance and Little’s proposal seems more expansive than\nHolton’s in so far as they allow that a moral generalization\nmight fail to govern a situation not only in the case that it is\nsuperseded by other moral principles but because the circumstances\nmight be such that the point of the moral generalization is simply\nlost. (See Little 2000 and Lance and Little 2004. For discussion of\nthe skill needed to apply generalizations see Garfield 2000 and Thomas\n2011. For discussion of reasoning with defaults see Horty 2007.) \nOne interesting question for this approach is whether the skill part\nof the equation can be further explicated in terms of principles, even\nif these further principles are grasped only implicitly. This issue\nhas received significant attention from philosophers outside the\nparticularism debate who are interested in the question whether\nknowledge-how can be reduced to knowledge-that (Ryle 1946; Stanley\n2011). Perhaps surprisingly, the literature on particularism has not\n(to our knowledge) drawn significantly from that debate. \nSome generalists, agreeing with particularists that moral knowledge\npresupposes a sensitivity to the moral landscape and skill in\ndeploying what appear to be ceteris paribus laden principles,\nargue that such sensitivity and skill is possible only if the\nlandscape itself is sufficiently patterned (McKeever and Ridge 2006)\nThis argument is supposed to allow for holism about reasons, and so\nthe relevant patterning consists in there being a finite number of\nconsiderations that can function as reasons, and that these can be\naffected by a finite number of enablers and defeaters operating in\nregular, “principled” ways. Particular pieces of moral\nknowledge, on this argument, presuppose only “default moral\nprinciples” which specify a feature which ground reasons,\nceteris paribus. A full array of exceptionless principles,\nthe argument continues, are presupposed by practical wisdom,\ncharacterized as including a capacity for reliably acquiring moral\nknowledge in a full range of novel circumstances. \nSome resist this argument in its entirety on grounds that we can\nregularly gain knowledge in other areas without recourse to principles\n(Schroeder 2009). Some charge that the second stage of the argument\ndepends on overly strong assumptions about the extent of practical\nwisdom (Schroeder 2009), and that more modest forms of practical\nwisdom can be explained without recourse to exceptionless principles.\nSome argue that a proper account of hedged moral principles is enough\n(Väyrynen 2009); others prefer to see moral wisdom as a skill\nwhich, while wide ranging, can fail in utterly novel circumstances\n(Leibowitz 2014). Still others have worried that the argument relies\non inflated assumptions about what is required for justification and\nknowledge, for example that the knower must be in a position to\naffirmatively rule out any possible defeaters (Thomas 2011). \nA recurring charge against generalism is that it assumes an outmoded\ndeductive-nomological (D-N) account of successful explanation.\nAccording to that account, any successful explanation must take a\ndeductive structure in which a covering law is identified that,\ntogether with empirical information, could yield a conclusion\nexpressing the phenomenon to be explained. For many reasons, the D-N\nmodel is now widely thought to be misguided. \nOn behalf of the generalist, one might make two points. First, it is\nnot clear that a generalist argument from practical wisdom needs to\nassume that all successful explanations must conform to the\nD-N model. The argument draws upon claims about the person of (highly\nideal) practical wisdom and asks how best to explain her reliability.\nSecond, while the argument does insist that we must credit the\nvirtuous agent with at least an implicit grasp of a principle, it is\nless clear that the argument must treat this principle as functioning\nas the major premise in a deduction. Likewise, we might credit an\nagent with grasping modus ponens to explain her logical success\nwithout thereby assuming that she uses modus ponens as a premise. \nGeneralists sometimes invoke premises about the nature of moral\nconcepts or about the meanings of moral words to argue for their view.\nUltimately these arguments appeal to what can be derived from a\ncertain kind of competence—either semantic or conceptual\ncompetence. It is probably no accident that purely semantic/conceptual\narguments to settle the debate over particularism/generalism have been\nmonopolized by generalists. If the generalist could show that\nsemantic/conceptual competence commits one to some specific moral\nprinciple(s), or to the existence and availability of some such\nprinciples, then that would already be enough to establish an\nambitious form of generalism. By contrast, a particularist who showed\nonly that such competencies do not yet commit one either to some\nspecific moral principle(s) or to the existence and availability of\nsuch principles would not yet have established a very ambitious form\nof particularism. For that negative conclusion is logically consistent\nwith the availability of a convincing epistemological, practical or\nmetaphysical argument for the existence and availability of suitable\nmoral principles. \nGeneralists can and have proceeded in one of two main ways here.\nFirst, they might argue that semantic/conceptual competence directly\ncommits one to the truth of some specific moral principle(s). Second,\nthey might argue that such competence commits one only to the weaker\nthesis that if there are any substantive moral truths then\nthere must be some true moral principle(s). This second thesis is\nweaker both in that it takes a conditional form, so that an error\ntheorist could endorse it but deny the existence of any true moral\nprinciples and in that it does not entail that there is some\nspecific moral principle(s) to which one is committed insofar as one\nthinks there are substantive moral truths. Consider each of these\nstrategies in turn. \nThe most ambitious and straightforward version of the first strategy\nis effectively just to argue for a form of analytic naturalism in\nmeta-ethics. For example, consider the meta-ethical theory that\n“is morally right” just means “is an action\nwhich maximizes happiness”, where “happiness” is\nitself cashed out in purely naturalistic terms. Any convincing\nargument for that theory would provide a way of carrying out a very\nambitious version of the first of the two strategies discussed above.\nClearly, insofar as that theory is correct, semantic competence with\n“is morally right” is enough to commit one to the thesis\nthat, necessarily, an action is morally right if and only if it\nmaximizes happiness, and that certainly looks like just the\nright sort of generalization to function as a principle qua\nstandard in the sense laid out in\n section 2. \nOf course, this strategy for defending generalism is for good reason a\nhighly controversial one. For a start, nobody has come close to\noffering a fully reductive definition of predicates like “is\nmorally right” which has met with widespread assent. Moreover,\nsome philosophers are sceptical of the very idea that knowing the\nmeaning of a word (or possessing a concept) is already enough, in\nprinciple, to know how to live a good life. In way, this concern about\npulling a highly substantive rabbit out of a purely\nsemantic/conceptual hat can be seen as what lies behind one of the\nhistorically most influential arguments against analytic naturalism,\nnamely G.E. Moore’s “Open Question Argument” (Moore\n1922 [1903]). Finally, anyone who is initially sympathetic to\nparticularism is very unlikely to find analytic naturalism an ex\nante plausible view, given how trivially it entails a very robust\nform of generalism. There is a sense, then, in which this strategy for\ndefending generalism, however sound it might turn out to be, is\nunlikely to convince anyone who needs convincing (cf. Jackson, Pettit,\n& Smith 2000—the argument there seems ultimately to turn\ninto a version of this first strategy). \nA less ambitious form of the first strategy focuses on so-called\n“thick” evaluative words or concepts. Such words/concepts\nin some sense have both specific descriptive and normative contents.\nConcepts associated with virtues and vices are classic examples of\nthick evaluative concepts—concepts like courage, justice,\nfairness and generosity are all paradigm cases. The argument for\ngeneralism focusing on these concepts takes the same form as the more\nambitious argument just canvassed. That is, the argument derives a\ncommitment to moral principle(s) from mere conceptual/semantic\ncompetence. \nHowever, the intended conclusion of an argument in this style is more\nmodest. For here the relevant principles do not take one from a purely\ndescriptive antecedent to a purely normative all things considered\nconsequent, as with (e.g.) the principle of utility. Rather, the\nrelevant principles here take one from an antecedent deploying a thick\nevaluative concept (like the concept of justice) to a consequent\ndeploying a thin normative concept (like the concept of a reason).\nSuch an argument might maintain, for example, that competence with the\nconcept of justice commits one to a moral principle of the form,\n“if an action is just then there is at least some reason to\nperform it (namely, its justice)”. \nEven this modest form of generalism is not uncontroversial. Dancy, for\nexample, argues that even thick evaluative features can vary in their\nnormative valence from one context to another, going so far as to\nmaintain that “almost all the standard thick concepts…are\nof variable relevance” (Dancy 2004: 121). Insofar as this sort\nof view is as much as semantically/conceptually coherent, there can be\nno straightforward derivation of moral principles of the sort\ncanvassed above from mere semantic/conceptual competence. Of course,\nthere may be more “hedged” principles linking thick\nevaluative concepts with thin normative concepts—principles\nwhich either enumerate or quantify over further conditions which must\nbe met before the application of a thick evaluative predicate entails\nthe application of a thin normative predicate. In effect, this is just\nthe point about holism not entailing particularism again. However, it\nis also unclear just how one would plausibly argue that insofar as\nsuch hedged principles are not vacuous, they really do follow from\nmere semantic/conceptual competence. \nThere may also be some interesting asymmetries between virtue concepts\nand vice concepts which are relevant to how we should think about\nthese arguments. In an interesting series of papers, Rebecca Stangl\nhas argued for a view she calls “asymmetrical virtue\nparticularism” (Stangl 2010). On this view, an action is right,\nall things considered, insofar as it is overall virtuous. However, the\nvirtues of an action in any specific respect (justice, courage, or\nwhatever) can vary in normative valence. However, vices on\nthis view are invariable—they always count against an action.\nThe deeper explanation of this asymmetry, on Stangl’s view, is\nthat virtues have “targets” at which they aim, whereas\nvices are simply tendencies to miss the relevant targets. Vices are\nthus parasitic on virtues but not vice-versa. Thus a given virtue\n(e.g., mercy) can sometimes be wrong-making because it helps explain\nwhy the agent (badly) misses the target associated with some other\nvirtue (e.g., justice). By contrast, Stangl argues, a vice always is a\ntendency to miss some relevant target, and so is therefore always to\nthat extent wrong-making. Insofar as Stangl makes a convincing case\nfor this asymmetry (and obviously a lot more could be said about\nthis), we should be less sympathetic to arguments which hold that\nthere is a semantic/conceptual link between the virtuousness of an\naction in a specific way and the presence of an associated reason for\naction.  Moreover, this more modest form of generalism presupposes that our\nthick concepts of justice, courage, generosity, and the like must be\ngenuinely evaluative concepts. But this is controversial. Pekka\nVäyrynen (2013), for instance, argues that the evaluations we\ntypically associate with thick terms such as “just” and\n“courageous” are conversational implications which arise\nfrom our use of those words in a wide range of contexts. Very roughly,\nthe idea is that evaluative content is a kind of generalized content\nwhich is explained pragmatically. For example, it may become common\nknowledge that only people who disapprove of the sexually explicit\ntend to use the word “lewd”. In that case, someone who\nuses that word thereby implies that she disapproves of the sexually\nexplicit – otherwise, why use the word “lewd” instead of\n“sexually explicit”, given that one’s interlocutors\nwill reasonably infer from the use of the former that one disapproves\nof the sexually explicit. \nIf this is right, then the status of thick words as evaluative depends\non contingent facts about the pragmatics of our use of those words.\nThere is then an important sense in which thick terms are, on this\nview, descriptive in their semantic content. So although there is a\nbroader kind of speaker competence which involves understanding the\nconversational defaults associated with the relevant words, this is\nnot the kind of semantic competence that could ground an argument for\ngeneralism or particularism. Semantic competence with thick words is\nalso unlikely to commit one to any interesting moral principles.\nDepending on our views of concepts, this view about thick language can\nallow that some thinkers' concepts of justice, generosity, and courage\nmay be evaluative. But that is unlikely to be essential to those\nconcepts, nor will the capacity forthought about justice and other\nthick notions depend on having genuinely evaluative thick concepts\n(Väyrynen 2013: 123–4, 206). In that case, competence with concepts\nlike justice, courage, and generosity is also unlikely to commit us to\nany interesting moral principles.  Moreover, the more modest form of\ngeneralism may require that a concept isn't a concept of justice, or\ncourage, or generosity, unless it is evaluative. In that case the\npragmatic view of thick evaluative language would support the view\nthat there are no thick evaluative concepts and, therefore, no such\nthing as competence with thick evaluative concepts. \nHowever, generalists do not have a monopoly on arguments which take\ntheses about thick evaluative concepts/predicates as their main\npremise. Some particularists argue that thick evaluative concepts are\n“shapeless” with respect to the descriptive (see\nespecially McDowell 1981). Others take a more metaphysical approach,\nand argue that thick evaluative properties are “irreducibly\nthick” in a way that puts pressure on the generalist. Indeed,\nsome go so far as to suggest that this even undermines some important\nforms of supervenience (see, e.g., Roberts 2011). Whether these\narguments are forceful may depend on the extent to which the argument\nthat there really are thick evaluative concepts or properties\nin the needed sense can avoid begging the question. In this context,\nit is not enough that no “shape” at the descriptive level\nis built into the meaning of evaluative concepts. Such a weaker\nshapelessness thesis would seem to rule out only principles that are\nboth analytic and reductive. But it seems compatible with the\npossibility that someone who did know the extension of evaluative\nconcepts could then discover a unity or “shape” to that\nextension which could be expressed using descriptive concepts. To rule\nout this possibility would seem to require a stronger shapelessness\nthesis according to which the extension of evaluative terms, properly\nunderstood, has no shape at all. Generalists will want to see an\nargument for this stronger thesis. Perhaps more importantly, though,\nsettling whether this stronger version of the shapelessness thesis is\ntrue would seem to require more than a priori theorizing\nabout moral concepts and more than semantic theorizing about\nevaluative terms. (For discussion of shapelessness and the metaethical\nlessons to be drawn from it see Väyrynen 2014 and Miller\n2003.) \nSo much for the first of the two strategies for giving a\nsemantic/conceptual argument for generalism canvassed above. What\nabout the second? Recall that the second strategy is less ambitious\ninsofar as it aims to establish only a conditional thesis linking\nsubstantive moral truth to the existence of some moral principle(s) or\nother. The guiding idea here is that a proper analysis of our moral\nconcepts will reveal that deploying those concepts to make a\nsubstantive moral judgment commits one to the existence and truth of\nsome moral principle(s) or other which somehow explains the truth of\nthat judgment. Crucially, though, this commitment to the existence of\nsome such moral principle(s) does not entail that the speaker is\ncommitted to any particular moral principle(s), or even to\nthe possibility in principle of discovering what the relevant\nprinciple(s) are. \nA modified version of T.M. Scanlon’s contractualist theory of\n“what we owe one another” (Scanlon 1998) helps to\nillustrate this strategy. Scanlon himself does not intend his theory\nas a conceptual analysis, in part because there are strands of moral\nthinking, like our thoughts about the moral status of nonhuman animals\nand the environment and certain forms of moralizing about human\nsexuality, which do not fit very well into his proposed framework.\nHowever, a version of his theory which was offered as an analysis of\nour moral concepts would provide a clear illustration of the strategy\nfor defending generalism under consideration. On Scanlon’s view,\nto be morally wrong in the sense of “wrong” associated\nwith what he calls the “morality of what we owe one\nanother” is to be forbidden by principles for the general\nregulation of human behaviour which nobody could reasonably reject.\nThe notion of the “reasonable” is a thick evaluative\nconcept, so the view is not a reductive one. If the view were to be\nunderstood as following directly from an analysis of our moral\nconcepts, then it would follow that anyone who makes a substantive\nmoral judgment that some action is morally wrong would thereby be\ncommitted to the existence of at least a range of moral principles\n(the “reasonable” ones) which are such that they all\nforbid the action in question. At the same time, making such a\njudgment does not entail that one can articulate what the relevant\nprinciple(s) is (are), or even that they are such that one could in\nprinciple discover them. \nAnother way of arguing for this sort of view is to take a broader\nfocus on normative and evaluative language. On some views (e.g., Ridge\n2014), all uses of “good”, “reason”,\n“ought” and “must” advert to\nstandards of some kind, but the context of utterance\ndetermines the relevant kind of standards. Sometimes, as in moral\ncontexts, the relevant standards will be normative in some rich sense.\nOther times, the relevant standards will be purely conventional, as\nwhen we discuss what one ought to do as a matter of etiquette. In\nother contexts the standards will be purely strategic/instrumental, as\nwhen we discuss what move one ought to make in a game of chess, say,\nor what military strategy is best, but where one can sincerely make\nthese judgments while finding chess a total waste of time or being a\ncommitted pacifist. The view aims to accommodate the\ncontext-sensitivity of the relevant words without implausibly\npostulating a brute ambiguity across the wide variety of contexts in\nwhich such words are used. As with the conceptual version of\nScanlon’s view, this view is also one on which making a\nsubstantive moral judgment commits one to the existence of a\nrange of moral standards which require the relevant action (or count\nthe relevant consideration as a reason, or whatever).  \nAn attraction of this strategy is that it draws its plausibility from\nhigh level semantic features of words like “good”,\n“reason”, “ought” and “must” which\nare not specific to normative contexts. It is therefore perhaps\nespecially unlikely to beg the question against the particularist.\nThis stands in sharp contrast with the attempt to derive specific\nmoral principles from mere competence with moral words or\nconcepts. \nAs the taxonomy of\n section 2 above\n emphasized, whether moral principles are necessary for moral\nunderstanding or moral explanation is not the only debate between\nparticularists and generalists. Distinct questions remain about the\nplace and value of principles in guiding moral decision-making and\naction and in interpersonal justification. Generalists typically see a\nlarger and more important role for principles to play in these\ncontexts. Particularists typically find at least some sympathy with\nDavid McNaughton’s claim that moral principles are “at\nbest useless and at worst a hindrance” (McNaughton 1988: 191).\nIn considering this aspect of the debate, it is helpful to treat as\ncommon ground the idea that it is at least possible for an agent to be\n(in some sense) guided by a principle. This assumption has, of course,\nbeen challenged, most prominently by some readings of\nWittgenstein’s arguments concerning rule-following (Kripke\n1982). If guidance by principle were utterly impossible, then\nquestions about the value and importance of principled guidance would\nbe largely moot. For similar reasons, it is helpful to assume, at\nleast provisionally, that an agent can eschew being guided by\nprinciples and yet still act rationally and for reasons and with some\nmeasure of consistency. \nAgainst this background, we may distinguish two questions. First, we\nmight ask whether guidance by principles constitutes a superior\nstrategy for acting well as compared to guidance by particular\njudgments untutored by principles. One familiar way to understand the\nsuperiority of a strategy is in terms of its reliability at leading an\nagent to act rightly and for morally good reasons (McKeever and Ridge\n2006; Väyrynen 2008). Second, we might ask whether guidance by\nprinciples enables us to secure morally valuable goods (or avoid\nsignificant moral evils) that would otherwise be out of reach. If\nparticularism tells us to eschew guidance by principles and if doing\nso comes with significant costs, then, to use Brad Hooker’s\nphrase, there is something “bad” about particularism\n(Hooker 2000, 2008). Similarly, if generalism tells us to use\nprinciples and this has serious costs, then there is something bad\nabout generalism. \nThese questions leave one familiar and related question largely to the\nside. This is the question whether there is something inherently\nmorally valuable about being a “person of principle”\nindependent of the content of those principles and how, more\nspecifically, they lead one to act. Generalists may, but need not,\nsubscribe to such a view, and even particularists could (consistently\nwith holism) allow that across some range of contexts being principled\nis, itself, a favoring consideration. Turning to the first question\njust noted, how might principles constitute a good strategy for moral\naction? \nMost ambitiously, the ultimate principles qua\nstandards—that is, the principles which provide the deepest\nexplanations of why right actions are right—could be well suited\nto guiding action directly. Arguably this is the view we find in Kant\nand in many modern Kantian moral theories. The categorical imperative\nis both the ultimate standard of right action and at the same time is\nwell suited to guide the decision-making of a conscientious moral\nagent. This view of principled guidance ought to be distinguished from\na distinct meta-ethical view according to which an ultimate moral\nstandard must, if it is to be valid at all, be such that agents can be\n(in some sense) guided by it (Bales 1971; Smith 2012). Such a view may\nbe attractive to those (such as Kant) who think that moral principles\nmust comport with autonomy and that morality is a species of\nrationality. It may also be attractive to those who believe that moral\nprinciples must provide reasons on which agents can act. But even a\nvery ambitious generalist model of principled guidance need not\nsubscribe to this meta-ethical view. Kant, at least in some passages,\nencourages optimism about our ability to apply the ultimate standard\nof right and wrong directly to our individual decisions. Other\nphilosophers within the generalist tradition, such as Ross, defend\nprinciples which look, on their face, to be eminently usable, and if\nRoss is correct that such principles are ultimate standards, then one\nmight feel entitled at least to a weak presumption in favour of the\nclaim that using them would be a good strategy. \nWhen we consider other candidates for the ultimate moral principle,\nhowever, many find reasons to be sceptical that the ambitious model\njust canvassed will carry us very far. This has been a recurring worry\nfor act consequentialism and, for that reason, many of the most\ninfluential attempts to deal with it have emerged from philosophers\nworking in that tradition. The basic idea is that the consequences of\nour action are so many, so various, and (often) so far reaching that\nagents cannot figure out in a timely fashion what the right act is by\ndirectly using a consequentialist principle. Using the\nconsequentialist principle in this sense must of course include\ngathering the facts about the consequences, not just applying the\nprinciples to the facts as one believes or knows them to be. (For\ndiscussion of weaker and stronger senses in which an agent might\n“use” a principle, see Smith 2012.) Properly understood,\nthe worry here is not that the act consequentialist principle provides\nno guidance whatsoever; it may point quite clearly to the kinds of\ninformation that must be gathered and heeded. The worry is that\nattempts to follow the principle will not reliably lead to morally\nright action. Moreover, the worry is not simply that the principle\nfails to constitute a complete and reliable strategy. Any model of\nprincipled guidance—even one such as Kant’s—is\nliable to require that we rely also on cognitive and emotional powers\nthat go beyond the principle itself. The worry is that our normal\ncognitive and emotional powers together with the principle do not\nyield a reliable strategy for performing morally right actions. \nInstead of concluding that principled guidance is hopeless, many act\nconsequentialists have instead proposed that we replace the project of\nbeing guided by the ultimate moral standard (assuming this for the\nmoment to be some form of act consequentialism) and instead be guided\nby some more tractable set of principles. According to such\n“indirect” consequentialism, the principles we typically\nemploy in deliberation are not the ultimate standards of right\nconduct. However, an agent who employs them in deliberation will\nregularly and systematically act rightly. Such proposals have been a\nstaple of consequentialist thinking dating back at least to the work\nof Mill and Sidgwick. An especially well known recent version of the\nidea is defended by R.M. Hare, who calls reliance on such principles\n“intuitive moral thinking”. By contrast, “critical\nmoral thinking” proceeds in terms of the actual standards of\nmoral conduct (Hare 1981). Importantly, neither indirect models of\nprincipled guidance nor the worry that inspires them need be married\nto a consequentialist view of moral standards. Kantian moral\nphilosophers have sometimes stressed the need for\n“mid-level” principles (Hill 1989, 1992). Even\nparticularists about standards could consistently embrace the use of\nsuch an indirect strategy and so embrace a kind of generalism about\nmoral guidance, though so far as we know no one has actually adopted\nthis position. \nDiscussions of indirect consequentialism often proceed as if the\ncorrect moral standard could, in principle, be applied directly to any\ngiven circumstance and, if so applied, would indicate the morally\nright action(s) to take. Leaving aside whether this is true of (some)\nconsequentialist principles, many claim that it is not true of other\ncandidate moral standards. Consider, for example, principles such as\n“all persons must be treated as moral equals”, or\n“property rights must be respected”, or, to borrow a less\nmorally loaded example from Onora O’Neill, “teachers must\nassign work appropriate to their students’ abilities”\n(O’Neill 1996: 73–77). Such principles may not yield\ndeterminate guidance in concrete circumstances even given a full array\nof non-moral facts. To be properly applied, such principles may\nrequire additional moral judgment. We must determine just\nwhich individuals are persons and what it is to treat persons as moral\nequals. We must determine which claims to property correspond to valid\nrights and what invasions of property amount to a failure to respect\nthose rights. May an exhausted runner harmlessly trespass in order to\ncool off beneath the shade of another person’s tree? We must\neven decide how difficult is too difficult when it comes to\nchallenging students. The obstacle to using the standard as a direct\nguide to conduct is not that our cognitive resources come up short,\nbut that the standard is itself not yet sufficiently determinate. This\nsituation presents an opportunity for principles to play a guiding\nrole by helping to fill in the normative content of higher level\nstandards. (Whether such guiding principles would themselves count as\nnon-ultimate standards is a question we here set aside.) Importantly,\nhowever, guiding principles in this sense need not make fully\ndeterminate the higher level principles that they help to fill out.\nThey may, instead, explicitly identify further questions to be\nsettled—whether by other principles or by judgment. For example,\nthe principle that a duly convicted criminal ought to receive only the\namount of punishment he deserves is highly abstract. How ought we to\ndetermine whether a punishment is deserved? The further principle that\nthe punishment ought to be proportional to the crime may direct us to\nfind a way to proportionately rank less and more serious crimes, and\nit may thus point us part, but not all, of the way towards complying\nwith the higher level principle.  \nWe now have at least three accounts of how principles might\nfigure in a reliable strategy for acting well. But why think that\nprinciples do or must figure in the best strategies for moral action?\nOr, taking the other side, why think that principles are useless or\neven counterproductive? If one could establish or assume a specific\ngeneralist account of moral standards, this would open up many lines\nof argument for guidance by principle. The same would be true if one\ncould establish particularism about standards. However, such\nassumptions are not dialectically available in the\ngeneralism/particularism debate. Accordingly, we here focus on\narguments that are largely neutral about the content of the moral\ndomain and whether it is “principled”. \nSome generalists argue that moral principles help avoid “special\npleading”—interpreting one’s moral duties in ways\nthat favour one’s own interests and in ways that go beyond what\na reasonable accommodation of self-interest would allow. Agents who\nengage in special pleading do not do so consciously, but rather think\nthey are impartially assessing what morality demands in their\ncircumstances. The adoption of moral principles might be thought to\nhelp with this problem. For one thing, principles can be adopted and\ninternalized well before any conflict with the agent’s interests\narises. Having internalized the relevant principle well in advance may\nmake it easier to avoid special pleading when a conflict does arise\n(cf. McKeever and Ridge 2006: 202–203). Furthermore, a practice\nof articulating these principles publicly endows them with symbolic\nmeaning. Violating explicitly endorsed principles or adding caveats in\nan ad hoc manner to suit one’s interests can come to\nstand for our lacking the right kind of commitment to morality more\ngenerally (see Nozick 1993: 29; McKeever and Ridge 2006:\n204–205). Anecdotally, some people seem to think New\nYears’ resolutions work in this way, and George Ainslie has\nprovided a body of empirical evidence that such public resolutions can\nhelp motivate agents to (e.g.) stop smoking in a way that somehow\nprevents the thought that “one cigarette won’t make any\nnon-negligible difference” from undermining their resolve\n(Ainslie 1975 and Ainslie 1986). \nParticularists agree that special pleading is a problem but they do\nnot think that principles afford the proper solution to that problem.\nInstead, they typically suggest that one simply needs to “look\nharder” at the case at hand to avoid such special pleading: \n…the remedy for poor moral judgment is not a different style of\nmoral judgment, principle-based judgment, but just better moral\njudgment. There is only one real way to stop oneself distorting things\nin one’s favour, and that is to look again, as hard as one can,\nat the reasons present in the case, and see if really one is so\ndifferent from others that what would be required of them is not\nrequired of oneself. The method is not infallible, I know; but then\nnor was the appeal to principle. (Dancy 2013) \nGeneralists worry that the exhortation to look again is simply\nunrealistic, given human nature, and is therefore not only fallible\nbut unlikely to do much good. If so, then even if principles are far\nfrom infallible rejecting them wholesale is premature. The best way to\navoid special pleading could involve an array of more specific\nstrategies with principles playing some significant role. \nOn the other side particularists worry that reliance on principles\nbreeds inflexibility and a problematic tendency to shoehorn a\nmorally complex situation into some more familiar set of categories.\nMcNaughton describes such inflexibility as a “serious\nvice” and claims that reliance on principles is partly to blame\n(McNaughton 1988: 203). Dancy remarks that,  \nWe all know the sort of person who refuses to make the decision here\nthat the facts are obviously calling for, because he cannot see how to\nmake that decision consistent with one he made on a different\noccasion. (Dancy 1993: 64)  \nImportantly, this worry cannot be dismissed simply on the grounds that\ngeneralists can (and do) allow judgment to also play a role in our use\nand application of principles; the worry is that the use of principles\nhas a distorting influence of its own. One interesting and empirically\nminded proposal for evaluating the force of the particularist’s\nconcern looks to the literature on the comparative success of rules\nand expert judgment in other domains (Zamzow 2015). Much of this\nliterature suggests that rules outperform expert judgment (see Grove\net al. 2000). \nLet us turn now to a second family of arguments for principled\nguidance. Setting aside whether principles are a winning strategy for\nthe individual aiming at virtuous action, one might think that our\ncollective use of principles enables us to achieve morally valuable\ngoods. One such argument appeals to the value of predictability\n(Hooker 2000, 2008). Successful cooperation and coordination yield\nenormous benefits yet it requires an ability to predict the behaviour\nof others and a willingness to rely on those predictions when making\none’s own choices. If principled guidance supports\npredictability, so much the better for principles. Not surprisingly,\nparticularists have questioned whether principles are necessary for\npredictability. “People are quite capable of judging how to\nbehave case by case, and in a way that would enable us to predict what\nthey will in fact do” (Dancy 2004: 83). The key issue is\ncomparative. Is the person guided by principles thereby more\npredictable than the person who eschews principles? Someone who\nrejects moral rules altogether and always just tries to judge each\ncase on its own merits plausibly is less predictable than someone who\nhas internalized and follows a set of moral principles. But as we saw\nabove, assessing the force of this generalist argument would benefit\nfrom consideration of careful empirical research. One challenge for\ngeneralists who might further develop this argument is that it stands\nin some tension with other themes stressed by generalists, for\nexample, that principles can incorporate various hedges and so exhibit\nthe kind of flexibility particularists embrace (Väyrynen 2008)\nand that principles are often indeterminate and must be supplemented\nby judgment. To be consistent, generalists will need to show not only\nthat guidance by crude principles makes one more predictable, but that\nguidance by a combination of hedged principles and judgment makes one\nmore predictable than guidance by judgment alone. \nA very different practical argument for generalism has roots in the\nKantian tradition and has recently been advanced by Stephen Darwall\n(2013, see also Darwall 2006). He contends that publicly formulable\nprinciples are necessary for us to realize a valuable form of\ninterpersonal accountability in our shared moral life. He further\nargues that such accountability is necessary for moral obligations\n(though not necessarily for moral reasons). Within the framework here\ndeveloped, one might see Darwall’s argument as a defense of\ngeneralism about standards but with the argument restricted\nto standards of moral obligation. Alternatively, one might\nsee it as a practical argument for attempting to formulate shared\npublic principles because, if we fail to do so (or fail to continue to\ndo so), we will lose something that we take to be valuable about\nmorality, namely the respect for persons that is inherent in a\npractice of interpersonal accountability (Darwall 2013: especially\n183–191). Darwall’s argument fits very well with Kantian\ncontractualism of the sort defended by T.M. Scanlon, which emphasizes\nthe value of our being able to justify ourselves to others and sees\nprinciples as mediating justification. It might also be instructive to\ncompare Darwall’s argument with some of the ideas found in the\ntradition of discourse ethics associated with Jürgen Habermas\n(see, e.g., Habermas 1990). An important challenge for this argument\nis to persuasively establish the premise that accountability (or\ninterpersonal justification) must advert to principles. Particularists\nmay allow that accountability is an important value while urging that\nthe interpersonal process of holding one another accountable can\nproceed entirely in terms of the reasons, defeaters, enablers, and\nintensifiers that are at play in the case at hand.","contact.mail":"semckeever@davidson.edu","contact.domain":"davidson.edu"}]
