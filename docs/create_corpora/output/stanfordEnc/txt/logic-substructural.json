[{"date.published":"2000-07-04","date.changed":"2018-02-21","url":"https://plato.stanford.edu/entries/logic-substructural/","author1":"Greg Restall","author1.info":"http://consequently.org/","entry":"logic-substructural","body.text":"\n\n\n\nSubstructural logics are non-classical logics weaker\nthan classical logic, notable for the absence of structural\nrules present in classical logic. These logics are motivated by\nconsiderations from philosophy (relevant logics), linguistics (the\nLambek calculus) and computing (linear logic). In addition, techniques\nfrom substructural logics are useful in the study of traditional\nlogics such as classical and intuitionistic logic. This article\nprovides a brief overview of the field of substructural logic. For a\nmore detailed introduction, complete with theorems, proofs and\nexamples, the reader can consult the books and articles in the\nBibliography.\n\n\n\nLogic is about logical consequence. As a result, the\nconditional is a central notion in logic because of its\nintimate connection with logical consequence. This connection is\nneatly expressed in the residuation condition (also known\nas the deduction theorem): \n\nIt says that \\(r\\) follows from \\(p\\) together with\n\\(q\\) just when \\(q \\rightarrow r\\) follows\nfrom \\(p\\) alone. The validity of the transition from \\(q\\)\nto \\(r\\) (given \\(p)\\) is recorded by the conditional\n\\(q \\rightarrow r\\).  \n\nThis connection between the conditional and consequence is called\nresiduation by analogy with the case in mathematics. Consider\nthe connection between addition and substraction. \\(a + b = c\\) if and\nonly if \\(a = c - b\\). The resulting \\(a\\) (which is \\(c - b)\\) is the\nresidual, what is left of \\(c\\) when \\(b\\) is taken\naway. Another name for this connection is the deduction\ntheorem. \n\nHowever, there the connection between consequence and the\nconditional contains one extra factor. Not only is there the turnstile,\nfor logical consequence, and the conditional, encoding consequence\ninside the language of propositions, there is also the comma,\nindicating the combination of premises. We have read\n“\\(p, q \\vdash r\\)” as “\\(r\\) follows from \\(p\\)\ntogether with \\(q\\)”. To combine premises is to\nhave a way to take them together. But how can we take them\ntogether? It turns out that there are different ways to do so, and so,\ndifferent substructural logics. The behaviour of premise combination\nvaries as the behaviour of the conditional varies. In this introduction\nwe will consider some examples of this. \n\nIt is one thing for \\(p\\) to be true. It is another for the\nconditional \\(q \\rightarrow p\\) to be true. Yet, if\n‘\\(\\rightarrow\\)’ is a material conditional, \\(q\n\\rightarrow p\\) follows from \\(p\\). For many different reasons, we may\nwish to understand how a conditional might work in\nthe absence of this inference. This is tied to the behaviour\nof premise combination, as can be shown by this demonstration.  \n\nFrom the axiomatic \\(p \\vdash p\\) (anything follows from\nitself) we deduce that \\(p\\) follows from \\(p\\) together with\n\\(q\\), and then by residuation, \\(p \\vdash q \\rightarrow p\\). If we\nwish to reject the inference from \\(p\\) to \\(q \\rightarrow p\\), then\nwe either reject residuation, or reject the identity axiom at the\nstart of the proof, or we reject the first step of the proof. It is\nilluminating to consider what is involved in this last option. Here,\nwe are to deny that \\(p\\) follows from \\(p, q\\). In general, we are to\nreject the inference rule that has this form:  \n\nThis is called the rule of weakening. The rule steps from a\nstronger statement, that \\(A\\) follows from \\(X\\) to a\npossibly weaker one, that \\(A\\) follows from \\(X\\) together\nwith \\(Y\\).  \n\nPeople have offered different reasons for rejecting the rule of\nweakening, depending on the interpretation of consequence and premise\ncombination. One of the early motivating examples comes from a concern\nfor relevance. If the logic is relevant (if to say that\n\\(p\\) entails \\(q\\) is true is to say, at least, that\n\\(q\\) truly depends on \\(p)\\) then the comma need\nnot not satisfy weakening. We may indeed have \\(A\\) following\nfrom \\(X\\), without \\(A\\) following from\n\\(X,Y\\), for it need not be the case that \\(A\\)\ndepends on \\(X\\) and \\(Y\\) together. \n\nIn relevant logics the rule of weakening fails on the other\nside too, in that we wish this argument to be invalid too: \n\nAgain, \\(q\\) may follow from \\(q\\), but this does not mean\nthat it follows from \\(p\\) together with \\(q\\),\nprovided that “together with” is meant in an appropriately\nstrong sense. So, in relevant logics, the inference from an arbitrary\npremise to a logical truth such as \\(q \\rightarrow q\\) may\nwell fail.  \n\nIf the mode of premise combination is commutative (if anything which\nfollows from \\(X, Y\\) also follows from \\(Y,\nX)\\) then we can reason as follows, using just the identity\naxiom and residuation:  \n\nIn the absence of commutativity of premise combination, this proof is\nnot available. This is another simple example of the connection between\nthe behaviour of premise combination and that of deductions involving\nthe conditional.  \n\nThere are many kinds of conditional for which this inference fails.\nIf “\\(\\rightarrow\\)” has modal force (if it\nexpresses a kind of entailment, in which \\(p \\rightarrow q\\) is true\nwhen in every related circumstance in which \\(p\\) holds, \\(q\\) does\ntoo), and if “\\(\\vdash\\)” expresses local consequence\n\\((p\\vdash q\\) if and only if any model, at any circumstance at which\n\\(p\\) holds, so does \\(q)\\) it fails. It may be true that Greg is a\nlogician \\((p)\\) and it is true that Greg’s being a logician\nentails Greg’s being a philosopher \\((p \\rightarrow q\\) –\nin related circunstances in which Greg is a logician, he is a\nphilosopher) but this does not entail that Greg is a\nphilosopher. (There are many circumstances in which the entailment\n\\((p \\rightarrow q)\\) is true but \\(q\\) is not.) So we a circumstance\nin which \\(p\\) is true but \\((p \\rightarrow q) \\rightarrow q\\) is\nnot. The argument is invalid. \n\nThis counterexample can also be understood in terms of behaviour of\npremise combination. Here when we say \\(X,A \\vdash B\\) is true, we are\nnot just saying that \\(B\\) holds in any circumstance in which \\(X\\)\nand \\(A\\) both hold.  If we are after a\ngenuine entailment A \\(\\rightarrow\\) B, then we want\n\\(B\\) to be true in any (related) circumstance in which \\(A\\) is\ntrue. So, \\(X,A \\vdash B\\) says that in any possibility in\nwhich \\(A\\) is true, so is \\(B\\). These possibilities might not\nsatisfy all of \\(X\\). (In classical theories of entailment, the\npossibilities are those in which all that is taken\nas necessary in \\(X\\) are true.) \n\nIf premise combination is not commutative, then residuation can go in\ntwo ways. In addition to the residuation condition giving the\nbehaviour of \\(\\rightarrow\\), we may wish to define a new arrow\n\\(\\leftarrow\\) as follows: \n\nFor the left-to-right arrow we have modus ponens in this\ndirection:  \n\nFor the right-to-left arrow, modus ponens is provable with the\npremises in the opposite order:  \n\nThis is a characteristic of substructural logics. When we pay attention\nto what happens when we don’t have the full complement of structural\nrules, then new possibilities open up. We uncover two\nconditionals underneath what was previously one (in intuitionistic or\nclassical logic).  \n\nIn the next section we will see\n another example\nmotivating non-commutative premise combination and these two different\nconditionals. \n\nHere is another way that structural rules influence proof. The\nassociativity of premise combination provides the following proof:  \n\nThis proof uses the cut rule at the topmost step. The idea is\nthat inferences can be combined. If \\(X \\vdash A\\) and \\(Y(A) \\vdash\nB\\) (where \\(Y(A)\\) is a structure of premises possibly including\n\\(A\\) one or more times) then \\(Y(X) \\vdash B\\) too (where \\(Y(X)\\) is\nthat structure of premises with those instances of \\(A\\) replaced by\n\\(X)\\). In this proof, we replace the \\(p\\) in \\(p \\rightarrow q, p\n\\vdash q\\) by \\(r \\rightarrow p, r\\) on the basis of the validity of\n\\(r \\rightarrow p, r \\vdash p\\).  \n\nA final important example is the rule of contraction which\ndictates how premises may be reused. Contraction is crucial in the\ninference of \\(p \\rightarrow q\\) from \\(p \\rightarrow \n(p \\rightarrow q)\\)  \n\nThese different examples give you a taste of what can be done by\nstructural rules. Not only do structural rules influence the\nconditional, but they also have their effects on other connectives,\nsuch as conjunction and disjunction (as we shall see below) and\nnegation (Dunn 1993; Restall 2000).  \n\nSince the introduction of Gentzen’s sequent calculus (Gentzen\n1935), we have known that the difference between classical\nlogic and intuitionistic logic can also be understood as a\ndifference of structural rules. Instead of considering sequents of the\nform \\(X \\vdash A\\), in\nwhich we have a collection of antecedents and a single consequent, for\nclassical logic it is fruitful to consider sequents of the form  \n\nwhere both \\(X\\) and \\(Y\\) are collections of statements. The\nintended interpretation is that from all of the \\(X\\) it\nfollows that some of the \\(Y\\). In other words, we cannot\nhave all of the \\(X\\) and none of the \\(Y\\) obtaining.  \n\nAllowing sequents with multiple consequents and translating the\nrules into this expanded context, we are able to derive classical\ntautologies. For example, the derivation \n\nshows that either \\(p \\rightarrow q\\) or \\(p\\) must hold.\nThis is classically valid (if \\(p\\) fails, \\(p\\) is\nfalse, and conditionals with false antecedents are true), but\ninvalid in intuitionistic logic. The difference between classical and\nintuitionistic logic, then, can be understood formally as a difference\nbetween the kinds of structural rules permitted, and the kinds of\nstructures appropriate to use in the analysis of logical consequence.  \n\nThere are many different formal systems in the family of substructural\nlogics. These logics can be motivated in different ways.  \n\nMany people have wanted to give an account of logical validity which\npays some attention to conditions of relevance. If \\(X,A\n\\vdash B\\) holds, then \\(X\\) must somehow be relevant to\n\\(A\\).  Premise combination is restricted in the following way. We may\nhave \\(X \\vdash A\\) without also having \\(X,Y \\vdash A\\) . The new\nmaterial \\(Y\\) might not be relevant to the deduction. In the 1950s,\nMoh (1950), Church (1951) and Ackermann (1956) all gave accounts of\nwhat a ‘relevant’ logic could be. The ideas have been\ndeveloped by a stream of workers centred around Anderson and Belnap,\ntheir students Dunn and Meyer, and many others.  The canonical\nreferences for the area are Anderson, Belnap and Dunn’s\ntwo-volume Entailment (1975 and 1992). Other introductions\ncan be found in Read’s Relevant Logic, Dunn and\nRestall’s Relevance Logic (2002), and\nMares’ Relevant Logic: a philosophical\ninterpretation (2004).  \n\nThis is not the only way to restrict premise combination. Girard (1987)\nintroduced linear logic as a model for processes and resource\nuse. The idea in this account of deduction is that resources must be\nused (so premise combination satisfies the relevance criterion) and\nthey do not extend indefinitely. Premises cannot be\n\\(re\\)-used. So, I might have \\(X,X \\vdash A\\), which says that I can use \\(X\\) twice\nto get \\(A\\). I might not have \\(X \\vdash A\\), which says that I can use \\(X\\) once\nalone to get \\(A\\). A helpful introduction to linear logic is\ngiven in Troelstra’s Lectures on Linear Logic (1992).\nThere are other formal logics in which the contraction rule\n(from \\(X,X \\vdash A\\) to\n\\(X \\vdash A)\\) is absent.\nMost famous among these are Łukasiewicz’s many-valued\nlogics. There has been a sustained interest in logics without this rule\nbecause of Curry’s paradox (Curry 1977, Geach 1995; see also\nRestall 1994 in Other Internet Resources).  \n\nIndependently of either of these traditions, Joachim Lambek considered\nmathematical models of language and syntax (Lambek 1958, 1961). The\nidea here is that premise combination corresponds to composition of\nstrings or other linguistic units. Here \\(X,X\\) differs\nin content from \\(X\\), but in addition, \\(X,Y\\)\ndiffers from Y,X. Not only does the number of\npremises used count but so does their order. Good\nintroductions to the Lambek calculus (also called categorial\ngrammar) can be found in books by Moortgat (1988) and Morrill\n(1994). \n\nWe have already seen a fragment of one way to present substructural\nlogics, in terms of proofs. We have used the residuation condition,\nwhich can be understood as including two rules for the conditional, one\nto introduce a conditional  \n\nand another to eliminate it.  \n\nRules like these form the cornerstone of a natural deduction system,\nand these systems are available for the wide sweep of substructural\nlogics. But proof theory can be done in other ways. Gentzen\nsystems operate not by introducing and eliminating connectives, but by\nintroducing them both on the left and the right of the turnstile of\nlogical consequence. We keep the introduction rule above, and replace\nthe elimination rule by one introducing the conditional on the left:  \n\nThis rule is more complex, but it has the same effect as the arrow\nelimination rule: It says that if \\(X\\) suffices for \\(A\\), and if you\nuse \\(B\\) (in some context \\(Y)\\) to prove \\(C\\) then you could just\nas well have used \\(A \\rightarrow B\\) together with \\(X\\) (in that\nsame context \\(Y)\\) to prove \\(C\\), since \\(A \\rightarrow B\\) together\nwith \\(X\\) gives you \\(B\\).  \n\nGentzen systems, with their introduction rules on the left and the\nright, have very special properties which are useful in studying\nlogics. Since connectives are always introduced in a proof\n(read from top to bottom) proofs never lose structure. If a\nconnective does not appear in the conclusion of a proof, it will not\nappear in the proof at all, since connectives cannot be eliminated. \n\nIn certain substructural logics, such as linear logic and the Lambek\ncalculus, and in the fragment of the relevant logic \\(\\mathbf{R}\\)\nwithout disjunction, a Gentzen system can be used to show that the\nlogic is decidable, in that an algorithm can be found to\ndetermine whether or not an argument \\(X \\vdash A\\) is valid. This is\ndone by searching for proofs of \\(X \\vdash A\\) in a Gentzen\nsystem. Since premises of this conclusion must feature no language not\nin this conclusion, and they have no greater complexity (in these\nsystems), there are only a finite number of possible premises. An\nalgorithm can check if these satisfy the rules of the system, and\nproceed to look for premises for these, or to quit if we hit an\naxiom. In this way, decidability of some substructural logics is\nassured. \n\nHowever, not all substructural logics are decidable in this sense.\nMost famously, the relevant logic \\(\\mathbf{R}\\) is not decidable.\nThis is partly because its proof theory is more complex than that of\nother substructural logics. \\(\\mathbf{R}\\) differs from linear\nlogic and the Lambek calculus in having a straightforward treatment of\nconjunction and disjunction. In particular, conjunction and disjunction\nsatisfy the rule of distribution: \n\nThe natural proof of distribution in any proof system uses both\nweakening and contraction, so it is not available in the relevant logic\n\\(\\mathbf{R}\\), which does not contain weakening. As a result,\nproof theories for \\(\\mathbf{R}\\) either contain distribution as a\nprimitive rule, or contain a second form of premise combination (so\ncalled extensional combination, as opposed to the\nintensional premise combination we have seen) which satisfies\nweakening and contraction.  \n\nIn recent years, a great deal of work has been done on the proof\ntheory of classical logic, inspired and informed by research\ninto substructural logics. Classical logic has the full complement of\nstructural rules, and is historically prior to more recent systems of\nsubstructural logics. However, when it comes to attempting to\nunderstand the deep structure of classical proof systems (and\nin particular, when two derivations that differ in some superficial\nsyntactic way are really different ways to represent the one\nunderlying ‘proof’) it is enlightening to think of\nclassical logic as formed by a basic substructural logic, in which\nextra structural rules are imposed as additions. In particular, it has\nbecome clear that what distinguishes classical proof from its siblings\nis the presence of the structural rules of contraction and weakening in\ntheir complete generality (see, for example, Bellin et al.\n2006 and the literature cited therein). \n\nWhile the relevant logic \\(\\mathbf{R}\\) has a proof system more\ncomplex than the substructural logics such as linear logic, which lack\ndistribution of (extensional) conjunction over disjunction, its\nmodel theory is altogether more simple. A Routley-Meyer\nmodel for the relevant logic \\(\\mathbf{R}\\) is comprised\nof a set of points \\(P\\) with a three-place relation\n\\(R\\) on \\(P\\). A conditional \\(A \\rightarrow B\\) is\nevaluated at a world as follows:  \n\\(A \\rightarrow B\\) is true at \\(x\\) if and only if for each \\(y\\) and\n\\(z\\) where \\(Rxyz\\), if \\(A\\) is true at \\(y, B\\) is true at \\(z\\).\n \n\nAn argument is valid in a model just when in any point at\nwhich the premises are true, so is the conclusion. The argument \\(A\n\\vdash B \\rightarrow B\\) is invalid because we may have a point \\(x\\)\nat which \\(A\\) is true, but at which \\(B \\rightarrow B\\) is not.  We\ncan have \\(B \\rightarrow B\\) fail to be true at \\(x\\) simply by having\n\\(Rxyz\\) where \\(B\\) is true at \\(y\\) but not at \\(z\\).  \n\nThe three place relation \\(R\\) follows closely the behaviour of the\nmode of premise combination in the proof theory for a substructural\nlogic. For different logics, different conditions can be placed on\n\\(R\\). For example, if premise combination is commutative, we place\na symmetry condition on \\(R\\) like this: \\(Rxyz\\) if and only\nif \\(Ryxz\\). Ternary relational semantics gives us great facility\nto model the behaviour of substructural logics. (The extent\nof the correspondence between the proof theory and algebra of\nsubstructural logics and the semantics is charted in Dunn’s work\non Gaggle Theory (1991) and is summarised in\nRestall’s Introduction to Substructural Logics\n(2000).) \n\nFurthermore, if conjunction and disjunction satisfy the distribution\naxiom mentioned in the previous section, they can be modelled\nstraightforwardly too: a conjunction is true at a point just when both\nconjuncts are true at that point, and a disjunction is true at a point\njust when at least one disjunct is true there. For logics, such as\nlinear logic, without the distribution axiom, the semantics\nmust be more complex, with a different clause for disjunction required\nto invalidate the inference of distribution. \n\nIt is one thing to use a semantics as a formal device to model a\nlogic. It is another to use a semantics as an interpretive\ndevice to apply a logic. The literature on substructural\nlogics provides us with a number of different ways that the ternary\nrelational semantics can be applied to describe the logical structure\nof some phenomena in which the traditional structural rules do not\napply. \n\nFor logics like the Lambek calculus, the interpretation of the\nsemantics is straightforward. We can take the points to be linguistic\nitems, and the ternary relation to be the relation of concatenation\n(\\(Rxyz\\) if and only if \\(x\\) concatenated with \\(y\\)\nresults in \\(z)\\). In these models, the structural rules of\ncontraction, weakening and permutation all fail, but premise\ncombination is associative. \n\nThe contemporary literature on linguistic classification extends the\nbasic Lambek Calculus with richer forms of combination, in which more\nsyntactic features can be modelled (see Moortgat 1995). \n\nAnother application of these models is in the treatment of the\nsemantics of function application. We can think of the points\nin a model structure as both functions and data, and\nhold that \\(Rxyz\\) if and only if \\(x\\) (considered as a\nfunction) applied to \\(y\\) (considered as data) is \\(z\\).\nTraditional accounts of functions do not encourage this dual use, since\nfunctions are taken to be of a ‘higher’ than their inputs\nor outputs (on the traditional set-theoretic model of functions, a\nfunction \\(is\\) the set of its input-output pairs, and\nso, it can never take itself as an input, since sets cannot\ncontain themselves as members). However, systems of functions modelled\nby the untyped \\(\\lambda\\)-calculus, for example, allow for\nself-application. Given this reading of points in a model, a point is\nof type \\(A \\rightarrow B\\) just if whenever it takes inputs\nof type \\(A\\), it takes outputs of type \\(B\\). The inference\nrules of this system are then principles governing types of functions:\nthe sequent \n\ntells us that whenever a function takes \\(A\\)s to \\(B\\)s and\n\\(A\\)s to \\(C\\)s, then it takes \\(A\\)s to things that\nare both \\(B\\) and \\(C\\).  \n\nThis example gives us a model in which the appropriate substructural\nlogic is extremely weak. None of the usual structural rules\n(not even associativity) are satisfied in this model. This example of a\nternary relational model is discussed in (Restall 2000, Chapter\n11). \n\nFor the relevant logic \\(\\mathbf{R}\\) and its interpretation of\nnatural language conditionals, more work must be done in identifying\nwhat features of reality the formal semantics models. This has been a\nmatter of some controversy, since not only is the ternary relation\nunfamiliar to those whose exposure is primarily to modal logics with a\nsimpler binary accessibility relation between possible worlds,\nbut also because of the novelty of the treatment of negation\nin models for relevant logics. It is not our place to discuss this\ndebate in much detail here, Some of this work is reported in the\narticle on\n relevant logic\n in this\nEncyclopedia, and a book-length treatment of relevant logic in this\nlight is Mares’ Relevant Logic: a philosophical\ninterpretation (2004). \nThe treatment of quantifiers in models for substructural logics has\nproved to be quite difficult, but advances have been made in the early\n2000s. The difficulty came in what seemed to be a mismatch between the\nproof theory and model theory for quantifiers. Appropriate axioms or\nrules for the quantifiers are relatively straightforward. The\nuniversal quantifier elimination axiom \\[ \\forall xA \\rightarrow\nA[t/x] \\] states that an instance follows (in the relevant sense) from\nits universal generalisation. The introduction rule \\[ \\cfrac{\\vdash\nA\\rightarrow B} {\\vdash A\\rightarrow \\forall xB} \\] (where the proviso\nthat \\(x\\) is not free in \\(A\\) holds) tells us that if we can prove\nan instance of the generalisation \\(\\forall xB\\), as a matter of\nlogic, from some assumption which makes no particular claim about that\ninstance, we can also prove the generalisation from that\nassumption. This axiom and rule seems to fit nicely with any\ninterpretation of the first-order quantifiers in a range of\nsubstructural logics, from the weakest systems, to strong systems like\n\\(\\mathbf{R}\\).\n \nWhile the proof theory for quantifiers seems well behaved, the\ngeneralisation to model theory for substructural logics has proved\ndifficult. Richard Routley (1980) showed that  adding the rules for\nthe quantifiers to a very weak system of substructural logic\n\\(\\mathbf{B}\\) fits appropriately with the ternary relational\nsemantics, where quantifiers are interpreted as ranging over a domain\nof objects, constant across all of the points in the model. This fact\ndoes not apply for stronger logics, in particular, the\nrelevant logic \\(\\mathbf{R}\\).  Kit Fine (1989) showed that there\nexists a complex formula which holds in all constant domain frame\nmodels for \\(\\mathbf{R}\\) but which is not derivable from the axioms.\nThe details of Fine’s argument are not important for our purposes, but\nthe underlying cause for the mismatch is relatively straightforward to\nexplain. In the constant domain semantics, the universal\ngeneralisation \\(\\forall x Fx\\) has exactly the same truth\nconditions—at every point in the model—as the family of\ninstances \\(Fx_1\\), \\(Fx_2\\), \\(Fx_3,\\ldots\\), \\(Fx_\\lambda,\\ldots\\),\nwhere the objects of the domains are enumerated by the values of the\nterms \\(x_i\\).  So, the quantified expression \\(\\forall x Fx\\) is\nsemantically indistinguishable from the (possibly infinite)\nconjunction \\(Fx_1\\land Fx_2\\land Fx_3\\land\\cdots \\). However, no\nconjunction of instances (even an infinite one) could\nbe relevantly equivalent to the universally quantified claim\n\\(\\forall x Fx\\), because the instances could be true in a\ncircumstance (or could be made true by a circumstance) without also\nmaking true the generalisation—if there had been more\nthings than those. So, constant domain models seem ill-suited to the\nproject of a relevant theory of quantification.\n \nRecent work by Goldblatt and Mares (2006) has shown that there is an\nalternative, and it turns out to be elegant and relatively\nstraightforward. The crucial idea is to modify the ternary relational\nsemantics just a little, so that not every set of points need count as\na ‘proposition’. That is, not every set of points is the\npossible semantic value for a sentence. So, while there is a set of\nworlds determined by the infinite conjunction of instances of\n\\(\\forall xFx\\): \\(Fx_1\\land Fx_2\\land Fx_3\\land\\cdots \\), that\nprecise set of worlds may not count as a proposition. (Perhaps there\nis no way to single out those particular objects in such a way as to\ndraw them together in the one judgement.) What we can say is\nthe generalisation \\(\\forall xFx\\) and that is a proposition that\nentails each of the instances (that is the universal quantifier\nelimination axiom), and if a proposition entails each instance, it\nentails the generalisation (that is the introduction rule), so the\nproposition expressed by \\(\\forall xFx\\) is the semantically\nweakest proposition that entails each instance Fa. This\nis precisely the modelling condition for the universal quantifier in\nGoldblatt & Mares’ models, and it matches the axioms exactly.\n","contact.mail":"restall@unimelb.edu.au","contact.domain":"unimelb.edu.au"}]
