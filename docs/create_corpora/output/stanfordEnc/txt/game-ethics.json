[{"date.published":"2004-10-16","date.changed":"2010-06-08","url":"https://plato.stanford.edu/entries/game-ethics/","author1":"Bruno Verbeek","author2":"Christopher Morris","author1.info":"http://www.philosophy.umd.edu/people/morris","entry":"game-ethics","body.text":"\n\n\n\nGame theory is the systematic study of interdependent\nrational choice. It should be distinguished from decision theory, the\nsystematic study of individual (practical and epistemic) choice in\nparametric contexts (i.e., where the agent is choosing or deliberating\nindependently of other agents). Decision theory has several\napplications to ethics (see Dreier 2004; Mele and Rawlings 2004).\n\n\n\nGame theory may be used to explain, to predict, and to evaluate\nhuman behavior in contexts where the outcome of action depends on what\nseveral agents choose to do and where their choices depend on what\nothers choose to do. (See the entry on\n game theory)\n Game theory consequently is relevant to ethics, and it is\nused in moral and political philosophy in a variety of ways.\n\n\n\nWe shall concentrate on the influence and use of game theory in\nethics and those parts of political theory involving norms or\nprinciples of justice, ignoring questions about political and legal\ninstitutions on the one hand and questions about issues dealing with\nmoral virtues on the other.\n\n\n\nOne can distinguish three distinctive kinds of inquiries in the\nliterature. The first we shall call functionalist: game theory\nis used to identify the function of morality. It is used to\ndescribe the problem(s) that would occur in the absence of morality,\nand inferences about the remedial or ameliorative function of morality\nare drawn from this description. The second approach,\ncontractarianism, uses game theory (especially bargaining\ntheory) to formalize social contract theory. This older tradition\nunderstands political institutions or norms to be justified to the\nextent that rational agents would agree to them under suitable\nconditions. Bargaining theory has been used to establish, first, that\nthere will be agreement in such conditions and, secondly, to predict\nthe outcome of this bargaining process. Third and finally, game theory,\nespecially evolutionary game theory, is used to “recover”\nmany traditional moral norms or practices. In what follows, we shall\nconsider each of these approaches and the results and problems they\nhave encountered. We shall start with some historical background.\n\n\n\nIn 1954 the British philosopher Richard Braithwaite gave his\ninaugural lecture entitled Theory of Games as a Tool for the Moral\nPhilosopher (Braithwaite 1955). In his lecture Braithwaite argued\nthat many questions about distributive justice have the same structure\nas “the bargaining problem”. This problem had been analyzed\nsome years before by John Nash, the later Nobel Prize winner, using\ngame theory (Nash 1950). Braithwaite predicted that game theory would\nfundamentally change moral philosophy. His prediction came less than\nten years after the publication of John von Neumann and Oskar\nMorgenstern's Theory of Games and Economic Behaviour—a\nbook that started a completely new branch of social science and applied\nmathematics (Von Neumann and Morgenstern 1944). \n\nThe introduction of game theory in ethics was not entirely a new\ndevelopment. Game-theoretic ideas can be found, for instance, in the\nwork of Thomas Hobbes and David Hume (see Gauthier 1969; Kavka 1986;\nHampton 1986; Vanderschraaf 1998)). Nevertheless, Braithwaite's\nprediction has not come true. Game theory has not (yet) fundamentally\nchanged ethics. Ten years after Braithwaite, Brian Barry\npublished Political Argument, and a few years later David\nLewis' seminal work Convention came out (Barry 1965; Lewis\n1969). In the late 60's, the first of a series of publications by\nDavid Gauthier appeared. In these he used game theory to develop his\nmoral theory (Gauthier 1967). However, until recently, the influence\nof game theory in ethics has not been anywhere as great as in the\nsocial sciences in general. Notwithstanding this faltering start, the\nintroduction of game theory in moral philosophy has produced a\nsteadily increasing flow of important publications. \n\nGame theory has been used to analyze the function of\nmorality. A good example is Edna Ullmann-Margalit's The Emergence\nof Norms, in which she argues that moral norms enable agents to\ncooperate and coordinate their actions in situations where the pursuit\nof self-interest prevents this (Ullmann-Margalit 1977). Her now classic\nexample is that of two artillerymen who face the choice to flee from\nthe advancing enemy or stay and operate their gun. Their gun is located\nin a strategically important pass. If both stay, they have a\nsignificant chance of being injured, but it is certain that the advance\nof the enemy will be halted. If both flee, the enemy will be able to\ntake the mountain pass, overtake and capture them. If just one of them\nstays while the other flees, the brave artillerist will die in battle,\nbut the other gunner will have just enough time to escape safely.\nSupposing that both try to survive this ordeal, preferably unhurt, each\nsoldier has reason to flee. The reason for this is that they are\nengaged in a\n prisoner's dilemma\n (see Figure 1). Each gunner has the choice between fleeing and\nstaying and fighting. This choice is represented in the rows for\ngunner #1 and the columns for gunner #2. Each cell in the matrix\nrepresents the outcome of each possible pair of choices. Each cell has\na pair of numbers. The number in the lower left corner of each cell\nrepresents how gunner #1 ranks this outcome, relative to the other\npossible outcomes—ranks represented by “utility”\nnumbers. The number in the upper right corner represents the ranking\nof this outcome by #2. \n\nConsider the case for #1. Suppose #2 decides to stay and fight. In\nthat case, #1 is best off by fleeing. He will survive without getting\nhurt. In the formal representation of the matrix, he will secure a\nhigher ranking (3 rather than 2). Suppose #2 decides to flee. Again,\n#1 does best by fleeing. He will survive the battle, although he will\nbe imprisoned for the duration of the war. If he were to stay and\nfight, he would certainly die; by fleeing he will secure a higher\nranking (1 rather than 0). Gunner #2 is in the same position as #1:\nfor him as well, whatever the other does, he fares best by fleeing. In\nshort, each individual gunner would be better off fleeing, regardless\nof what the other does. However, it remains true—and to some,\nparadoxical—that both would be better off if both stood their\nground. The outcome of individually rational action is\nPareto-inefficient (or sub-optimal). \n\nSuppose that both understand the structure of their predicament.\nSince they would see that each has good reasons to flee, they could try\nto rule out this possibility. For example, they could chain each other\nto the gun, thus preventing flight. Ullmann-Margalit argued that the\nsituation of the gunners (i.e., the prisoner's dilemma) is structurally\nequivalent to many everyday interactions governed by morality.\nFurthermore, just as the mutual chaining commits the gunners to stay\nand fight, morality commits agents to avoid Pareto-inefficient or\nsub-optimal outcomes. Morality binds individuals to their guns, as it\nwere. On this view, the function of morality is to prevent the failures\nof rationality (Mackie 1977). \n\nThere are several problems with this functional analysis of\nmorality. First, there are some well-known problems with functionalist\nexplanations in the social sciences. The fact that a practice or an\ninstitution has a particular function need not explain either its\nemergence or its maintenance. It might be argued, for instance, that\nthe function of the public education system is to educate the young,\nthe function of the state to serve the interests of the ruling classes,\nor that of religion to serve as the opiate of the masses. However,\nuntil it can be shown that these apparent functions are causally\neffective in bringing into existence and maintaining the educational\nsystem, the state, or religion respectively, no explanation has been\nprovided. Similarly, even if moral norms and practices serve to bring\nabout Pareto-superior outcomes not realizable through uncoordinated\nindividually rational action, no explanation of the existence and\npersistence of morality is provided unless it is shown that this\nfunction somehow motivates human action and or in some other way is\ncausally effective in bringing about mutually beneficial outcomes. \n\nSecondly, it is open to question whether morality coincides with\nmutually advantageous or Pareto-superior outcomes in the manner\nsuggested. Many thinkers have argued that we often are morally required\nto act in ways which are disadvantageous to all. An obvious example is\nthe often-affirmed prohibition against selling oneself into slavery. It\nmight very well be advantageous to both slave and master (the slave\nwould be able to pay off his debts and the master would have a\npractical solution for the daily housework), yet it is morally and\nlegally prohibited. \n\nThird, the functionalist account clearly assumes that the demands of\nmorality conflict with individual rationality. Morality is supposed to\ncorrect problems of threatening Pareto-inefficiency which would be the\nresult of unfettered (interdependent) individual rational action. On\nthe functionalist account the moral agent seems ipso facto to\nbe irrational (barring considerations of guilt-avoidance or regret).\nThis then begs the question ‘why be moral?’. Functionalism\nprecludes an answer to this question. \n\nFourth and finally, the objective of functionalist accounts is of\nlimited interest to moral theorists. Functionalism appears to seek\nexplanations of the emergence and persistence of moral norms\nand practices. Moral theorists are not interested principally in such\nexplanations. Rather, they usually seek to understand morality with the\naim of ascertaining what we should do or what we are obligated to do.\nIt is morality as a guide to action and to life that is the principal\ninterest of the moral philosopher. Morality here is normative,\na source of guidance. Suppose that there were a plausible functional\nexplanation of particular moral norms. Does that explanation show that\nI am, in fact, obligated to follow these norms when they apply\nto me? There seems to be a difference between (a) determining the\nfunction(s) of morality and (b) ascertaining whether a particular set\nof norms and practices are, in fact, the ones we should follow. It is\nnot clear how this question is answered by functionalist accounts. \n\nAs we saw above, one of the criticisms of functionalism is that it\ndoes not explain the connection between individual choice and the\nemergence and persistence of moral norms. Morality is introduced as\nsomething outside of individual rational choice. In response to this\ndifficulty, many theorists have tried to understand morality as the\nresult of individual rational choice. Roughly, we can distinguish two\nstrategies. First, there are those who model morality as the result of\na one-time choice of a very large collection of agents, the moral\ncommunity. Secondly, there are those who approach morality as the\nresult of a series of repeated small-scale interactions. We will\ndiscuss this second approach in section 7. Here we discuss the approach\nthat regards morality as the intended result of the interactions\nbetween rational agents under equally ideal circumstances. This is an\nold idea in moral and political philosophy: it is the idea of the\nsocial contract (see the entry on\n contractarianism).\n Morality is interpreted as the outcome of a bargaining process. \n\nThe introduction of game theory, especially those parts of the\ntheory that are concerned with bargaining (so-called cooperative game\ntheory and bargaining theory), has stimulated interest in social\ncontract theory over the last decades. John Harsanyi, Richard\nBraithwaite, John Rawls, Brian Barry, and David Gauthier have used the\ngame and decision theory to formulate versions of the theory (Harsanyi\n1955; Braithwaite 1955; Barry 1965; Rawls 1971; Gauthier 1986).\nInvoking bargaining theory, they attempted to show (1) that rational\nagents in a suitably idealized bargaining situation will agree on a\nspecific, unique distribution of the benefits of cooperation, (2) what\nthis distribution looks like, (3) that this distribution determines\nwhat is just, and (4), in case of Gauthier, that rational agents will\ncomply with the terms of the bargain. \n\nIt is important for these theories exactly how the bargaining\nsituation is characterized. Gauthier, as well as many others, thinks of\nit as a prisoner's dilemma. That is, the predicament of the parties in\nthe ideal bargaining position is structurally equivalent to the\nsituation of the artillerists as we described above. Without any\ncooperation the gunners are doomed to flee and spend the remainder of\nthe war in captivity. Suppose that it is possible to make binding\nagreements in this situation. Does this solve the problem of\nthreatening Pareto-inefficiency? It does not because it is not obvious\nhow the benefits of cooperation will be distributed. It might\nseem that in this case there is only one way in which these can be\ndistributed, but appearances deceive. The artillerists could decide to\nfollow a mixed strategy. A mixed strategy is a lottery over\nthe available strategies of each individual. For example, the gunners\ncould decide to flee with a probability of, say,\n1/3 and stay and fight with a probability of\n2/3. (It should be noted that the idea of a mixed\nstrategy usually is introduced in the context of so-called cardinal\nutilities. Whereas before the numbers in the matrix (0, 1, 2 and\n3) only signified the ranking of the outcome, here it is\nassumed that the numbers provide some information about the\nrelative ranking of the outcome. For example, the utility of\n“2” of the cooperative outcome means that the agent is\nindifferent between this outcome and a gamble which offers her\n“0” (the worst outcome) with probability 1/3 and\n“3” (her best outcome) with probability 2/3. (For a\ndetailed discussion of cardinal utility theory see Section 3.5 of the\nentry on\n interpretations of probability).\n\n From here onwards, we assume that the numbers in the matrix are such\ncardinal utilities.) \n\nThe gunners realize that they each individually can realize at least\nthe one but worst outcome of non-cooperation. This means that the\noutcome of their agreement should be at least as good as the\nnon-cooperative outcome. Therefore, the distribution that they will\nagree to should at least be 1. Suppose that the gunners have a pair of\ndice. Now they can realize cooperative distributions other than 2 each.\nFor example, if they agree to throw both dice and if a total of 6 or\nless comes up #1 will flee (thus realizing a utility value of 3).\nHowever, if the total of both dice is more than 6, #1 will stay and\nfight the enemy (realizing his worst outcome of 0). The expected\nutility of this deal for #1 is 5/12·3 +\n7/12·0 = 1.25, while #2 can expect 1.75\nfrom this deal. In this way the gunners can realize a whole range of\noutcomes by varying the chances that improves on the non-cooperative\noutcome. These outcomes form the bargaining area (see Figure 2). \n\nIntuitively it may seem straightforward that the outcome of the\nagreement between #1 and #2 will be (2,2). Formally this is anything\nbut straightforward. Every outcome that gives each gunner an expected\nutility of more than 1 seems rationally acceptable. Which one will\nrational gunners select? Within bargaining theory, the part of game\ntheory that deals with these problems, there are two approaches that\nseek to answer this question (Binmore 1998, chapter 1). First, there is\nthe traditional axiomatic approach as developed in the context\nof cooperative game theory. This branch of game theory assumes that,\nonce rational agents have come to an agreement, they will comply with\nit. The task of the theorist is to consider the bargaining area and\ndetermine which outcome(s) would satisfy a number of reasonable\nrequirements of a rational outcome of the negotiations. Things such as\nthe names of the parties concerned should not matter for the result,\nwhereas their preferences do matter. This approach has been very\ninfluential in game-theoretic social contract theory. Harsanyi, Rawls,\nBarry, and Gauthier all have used axiomatic approaches to justify their\nfavorite version. Their verdict in the case of the gunners is the same:\nthe rational thing to agree to is a distribution that gives each gunner\nan expected utility of 2. \n\nThe axiomatic approach pays no attention to the structure of the\nprocess of negotiation. All it requires as input is information about\nthe pay-offs of the parties. Whereas it is true that sometimes it does\nnot really matter how exactly the negotiation process is structured,\nsometimes it is very important. For example, if it is the case that #1\ncan make a claim and all #2 can do is to accept or refuse, #1 does best\nby offering #2 an expected utility of 1.00001 and claim 2.99999 for\nhimself. Given the rules of the negotiation process #2 will have to\naccept this since the alternative is (slightly) worse. On the other\nhand, if the rules allow for exchanges of claims and offers the\nsituation is quite different. Therefore, if you want to predict what\nthe result of the negotiation process between rational agents will be,\nit is crucial to know the rules of negotiation in detail as well as the\nbargaining area. In addition, it is important to know whether the\nparties will keep to the agreement. For if this is not the case, it is\nunlikely that the parties concerned will accept the agreement instead\nof an agreement that will turn out to be binding. \n\nTherefore, it is better to think of the bargaining process as a\nseries of possible moves in a game that precedes the game that the\ngunners face. This is the second approach, which regards bargaining\nprocesses as non-cooperative games. The solution to such a\ngame then corresponds to the solution of the bargaining process. On\nthis approach, one needs to pay a lot of attention to detail.\nConsequently the analysis is complicated and often messy. (This is\nanother reason why the axiomatic approach is so attractive to\nsome.) \n\nHowever, it is very well possible that the solution to the game and\nthe solution based on the axiomatic approach are identical. In fact,\nthis is what you would expect if the proposed axiomatic solution is at\nall plausible. This intuition is the driving force of the so-called\nNash program (Nash 1950). This program aims at evaluating\naxiomatic solutions by checking whether the outcome of a negotiation\ngame leads to the same outcome. The success of the Nash program is\ncrucial for the plausibility of the classic axiomatic theories of the\nsocial contract. Such theories regard morality as the result of\n(hypothetical) negotiations between ideally rational agents but do not\nbother to spell out exactly how the parties reach this result.\nConsequently, if there is not at least the promise of such a detailed\nanalysis, as is promised by the Nash program, the result they present\nlacks plausibility. (See also Rubinstein 1982 and Binmore 1998 for more\nrecent treatments of the bargaining problem.) \n\nOne of the most influential contractarian theories currently around\nis that of David Gauthier. His theory, however, is different from other\ncontractarian approaches, not only in its extensive use of game- and\nbargaining theory, but also in the following respect. One of the\ndifficulties we signaled with regards to the functionalist approach is\nthat it provides no answer to the question “Why be moral?”\nIt is here that Gauthier's contractarian theory distinguishes itself\nfrom those of Rawls, Harsanyi, and others. Gauthier not only uses\nbargaining theory to determine, as Rawls and Harsanyi sought to do, the\ncontent of fundamental moral principles; he also tries to show that\nrational agents will act morally. For this reason we discuss it in more\ndetail than the others. \n\nGauthier's moral theory, “morals by agreement” (Gauthier\n1986), is a theory about the nature and rationality of morality. (See\nalso Section 3 of the entry on\n contractarianism).\n It consists of four\nparts. The first is an account of practical reason and the natural\ncondition of humankind, much of it familiar to rational choice\ntheorists and to contractarian moral theorists (Gauthier 1986, chapters\n2–4). Next is an account of the principles of conduct that rational\nagents would hypothetically agree to—a kind of “social\ncontract” (Gauthier 1986, chapter 5). The third element is a\ncontroversial revisionist account of practical rationality essential to\nhis argument aiming to show that virtually everyone under normal\ncircumstances has reason to accept and to abide by the constraints\nimposed by these principles (Gauthier 1986, chapter 6). Lastly,\nGauthier argues that the principles in question are principles of\nmorality, an argument which makes implicit reference to a functionalist\naccount of moral norms (Gauthier 1986, chapters 7–8). The third part is\nGauthier's answer to the question “Why be moral?”. It\ntouches upon some very fundamental issues in game- and decision theory,\nwhich is why we discuss it a bit further here. \n\nAs Hobbes already realized, it is one thing to come to an agreement;\nit is quite another thing to perform one's part of an agreement.\nMorality, at least as it is traditionally conceived, often requires us\nto sacrifice our interests or aims. This is, at least on the face of\nit, contrary to what rationality requires. Gauthier's response to this\nis to argue that we misconceive practical rationality, even\ninstrumental rationality, if we think the aim of rationality determines\nin any straightforward way the manner in which we should reason or\ndeliberate. The aim of rationality—to do as well as\npossible—does not necessarily determine our principle of\ndecision—for instance, to choose the best alternative at\neach moment of choice. In terms of the utility-maximizing conception of\nrationality which he has accepted until recently (Gauthier,\nforthcoming), Gauthier argues that the aim of maximizing utility does\nnot mean that we should, at each decision point, maximize utility.\nInstead we should reason in ways which are utility maximizing. Just as\nit is sometimes the case that we do best or at least well by not aiming\nto do best or well, so it may sometimes be that the utility maximizing\ncourse of action is not to maximize utility at each decision point.\nGiven that our mode of reasoning or deliberation itself affects our\nprospects, our aims or purposes are sometimes best served by our not\nseeking to do best at every decision point. \n\nGauthier's discussion in Morals by Agreement is conducted\nin terms of “dispositions to choose” and specifically of\n“constrained maximization”, the disposition to cooperate\nwith other cooperators even in circumstances where defecting is more\nadvantageous. In later work Gauthier develops his revisionist account\nof practical rationality in terms of rational plans and intentions and\nof modes of deliberation. If we grant that agents may do better in any\nnumber of circumstances by acting in ways that are not\n“straightforwardly maximizing”, the problem is to determine\nhow acting as a constrained maximizer is rational. In the book Gauthier\nassumes that if our dispositions to choose is rational, then our\nchoices determined by these dispositions are also rational. A number of\ntheorists have followed Thomas Schelling in arguing that it is often\nrational to do things that are irrational, but they argue that the\nlatter do not in the circumstances cease being irrational. Gauthier\nthinks that if a course of action is better than any other in its\neffects, then it may under certain conditions be rational to adopt it\nand to intend to carry out its element even if some of them are not,\nfrom the standpoint of the moment of execution, the best thing to do in\nterms of one's aims or purposes. He seeks therefore to establish that\nif a mode of deliberation or a plan of action is rational, then acting\naccording to it can be rational even if so acting requires doing things\nthat are not, considered from the standpoint of the moment of action,\noptimal. Principled action constrains one's action, and it is rational\nto be so constrained. Thus, if Gauthier is right, it can be rational to\nabide by certain norms or principles, even when they require acting in\nways that are not best from the standpoint of the time of action. Much\nof Gauthier's work since Morals by Agreement develops and\ndefends this revisionist account of practical rationality. (See\nGauthier 1994, 1996, 1998a and b. For an alternative revisionist\naccount, see McClennen 1990). \n\nGauthier's defense of “constrained maximization”\nconstitutes a major revision of standard game- and decision theory.\nOrthodox theory focuses upon the rationality of actions at the time of\nchoice. The mode of deliberation itself about actions falls out of the\nscope of the theory. (Or rather, orthodox theory presents itself as\nsuch a mode of deliberation.) Some critics have argued against\nincluding the mode of deliberation in the scope of the theory (for\nexample, Velleman 1997). Most game theorists, however, argue instead\nthat if it is feasible to choose the mode of deliberation, this choice\nitself can be modeled as a move in a more complex decision game, thus\nincluding Gauthier's proposal into standard theory (for example,\nBinmore 1994, p. 179–182). \n\nThe contractarian approach—and Gauthier's theory is not\ndifferent in this respect—presumes a fundamental connection\nbetween rationality and morality, just like functionalism. However,\nunlike the functionalist project, the contractarian approach has a\nsophisticated argument as to why this should be so. Moral norms (or\ninstitutions, or whatever is the object of the theory in question) are\nrationally acceptable according to the contractarian tradition only if\nthere is no feasible alternative arrangement where all parties\nconcerned would be better off. We can make this claim more vivid.\nImagine that parties are bargaining over what norm to use to share a\ncake. Rational parties would not agree to a norm that would leave some\ncake on the table going to waste. Similarly with moral norms: rational\nagents would not agree to a norm that could be expected to leave mutual\nadvantages unexploited. Therefore, according to the contractarian's\nconception of morality, it is necessarily the case that the correct\nmorality leads to Pareto-efficient outcomes. For this reason, rational\nchoice contractarianism is often regarded as revisionist in its\nimplications. The claim is not that common sense or ordinary morality\nleads to Pareto-efficient results (if followed). Instead, the claim of\nrational choice contractarianism is that the correct account of binding\nmoral norms is one that implies that if these norms are followed, the\noutcomes will be Pareto-efficient. \n\nCritics have long argued that it's not clear why the outcome of\nhypothetical agreement should influence what agents outside of\nthe idealized circumstances of “the social contract” should\ndo. Some have argued that hypothetical contracts (or promises) do not\nbind. However, this is to misunderstand the nature of these theories;\nhypothetical rational agreement is not meant to be promissory.\nRather, it is first of all heuristic, a mechanism designed to\ndetermine the nature and content of mutually beneficial, fair\nprinciples. \n\nWhereas the remarks above address all forms of contractarianism,\nthere are some specific problems with versions that rely as heavily on\ngame-theoretic bargaining theory as that of Gauthier and the others.\nThe most fundamental seems to be the plausibility of the Nash program:\nis there really a rational solution to all bargaining problems that can\nbe specified and tested with the use of non-cooperative game theory?\nSimilarly, how can we be sure that there is always one unique solution,\nor are bargaining problems to some extent underdetermined? The\nplurality of bargaining solution concepts that are discussed in\nbargaining theory is a bad omen in this regard. There are reasons to\ndoubt that the game-theoretic approach to bargaining can really help us\npredict the outcome of the negotiations of rational agents. Both the\naxiomatic approach and the non-cooperative game approach proceed from\nthe assumption that there is a unique, rational outcome of such\nnegotiations. While that may be plausible in some situations, it is far\nfrom obvious that this is always the case. That is, the outcome of\nnegotiations often seems rationally underdetermined (Sugden 1991).\nNon-rational factors, such as salience, precedence, etc., are far more\nimportant for determining the result of such negotiations than standard\nbargaining and game theory lead us to believe. \n\nThere is also another kind of worry, one which leads naturally to\nthe third major movement in game theory and ethics. Contractarians like\nGauthier understand the fundamental norms that govern us as issuing\nfrom a (hypothetical) choice situation which would have a very large\nnumber of agents bargaining over different principles or social\narrangements. However, it is an open question whether that is an\nappropriate way to model the rational choice process that leads to the\nemergence of morality. \n\nAt this point, there is a fundamental difference with the third way\nin which game theory had been applied to ethics. This third way is\n evolutionary game-theory.\n Rather than\nregarding morality as the intended result of a complex large scale\nbargaining process between fully informed and fully rational agents,\nthe evolutionary approach moves away from all these assumptions. First,\nmorality is seen as the unintended side-effect of the interactions of\nagents. Secondly, morality emerges from a series of repeated\ninteractions between small groups of agents (most models deal with\ntwo-person interactions only). To put this in functionalist terms:\nmorality is not to solve one problem, but frequently re-occurring\nproblems. Third, rather than assuming full information and full\nrationality, evolutionary game theory makes less demanding assumptions\nof the cognitive and deliberative skills of the agents. This can lead\nto fundamentally different results. \n\nWe can illustrate this as follows. Rousseau describes the state of\nnature as one that resembles the so-called Stag Hunt (Rousseau 1964, p.\n166–167). (See Skyrms 2004 for a contemporary treatment of this game.)\nImagine two hunters who can choose to hunt for hare. Their chances of\ncatching a hare are not affected by the actions of others. However,\nboth prefer to have venison for dinner, but if they were to hunt for\nstag, they will only be successful if the other does so as well. \n\nSuppose #1 and #2 coordinate on (Hare, Hare). This equilibrium is\nstrictly Pareto-inferior to (Stag, Stag). Whereas contractarian choice\nwould have it that (Stag, Stag) is the correct norm to settle upon,\nevolutionary game theory teaches us that it is unlikely that the\nPareto-efficient equilibrium will be selected in a process of repeated\ninteractions. What is more, the Pareto-efficient equilibrium is\nunstable: occasional deviations from this equilibrium will lead the\npopulation as a whole to coordinate on (hare, hare) rather than (stag,\nstag). \n\nPresumably this is true of some of our actual norms—social,\nlegal, or moral. They may be deficient relative to other norms,\nespecially those that issue from the sorts of idealized social choice\nsituations of contractarian moral theory. However, most of our actual\nnorms are often stable, and it is not clear that we have reason to\ndepart from them. Therefore, we are left wondering if the norms\ndiscovered by game theoretic bargaining theory are norms that are\nfeasible for most societies, communities and groups. Since\n“ought” implies “can”, we have reason to doubt\nthat the contractarian approach gives us a correct account of the\nmorality we ought to follow. \n\nThe main result of the evolutionary approach so far is the\n“recovery” of many existing moral intuitions and norms.\nThus, evolutionary game theorists writing about ethics (as well as\nmoral philosophers using evolutionary game theory) have shown that\namong not-so-fully rational agents many of the norms of coordination\nand cooperation can emerge that are the object of inquiry of the more\ntraditional moral theories. (For example, Sugden 1986; Binmore 1994,\n1998; Skyrms 1996.) Furthermore, Skyrms (1996) and others have\ndemonstrated that otherwise self-interested agents will develop\nreasoning heuristics such as the Golden Rule (do to others as\nyou want to be done by) and a version of Gauthier's “constraint\nmaximization” under appropriate circumstances. That is, they show\nthat evolution favors not only the emergence of patterns of behavior\nthat conform to moral standards, but also favor the development of\ncognitive heuristics that have all the characteristics of moral\nreasoning. \n\nMost authors who have embraced the evolutionary approach, are quick\nto point out that this approach avoids much of the criticism raised\nagainst the previous two approaches. First, the evolutionary approach\nprovides a genuine explanation of the emergence and persistence of\nmoral norms. Norms are the unintended side-effect of the actions of\n(boundedly) rational agents and emerge in the process of repeated\ninteractions. On the evolutionary approach, the “function”\nof a moral norm is to select a stable equilibrium, in a situation in\nwhich there is more than one. Thus stable norms can be\nPareto-inefficient. There is no fundamental link between efficiency and\nmorality on the evolutionary approach. Its focus is on equilibrium and\nnot on efficiency. This is also the reason why an agent in such a\npopulation should follow that norm. That is, the fact that the other\nmembers of a population follow a norm explains why, and justifies that,\nan individual in such a population will do so as well. As a\nconsequence, the evolutionary approach provides an answer to the\nquestion “Why be moral?” Following an existing norm is\nindividually rational. Furthermore, no unorthodox revisions of choice\ntheory need to be accepted to achieve this result, which is a big\nadvantage over Gauthier's claims for “constrained\nmaximization”. \n\nHowever, there is also some reason to be wary of the success of the\nevolutionary approach. For just like the functionalist approach and\nunlike the contractarian project, its focus is on explanation.\nEvolutionary game theory is primarily used to explain the emergence and\nstability of existing norms. It does not supply the instruments to be\ncritical of the content of these norms. It provides no justification of\na code of conduct as one that is decidedly moral (however, see Binmore\n1994, 1998). \n\nThis tendency is especially worrisome when we see in the literature\non the evolution of behavior explanations for nasty dispositions such\nas the propensity of men to rape, the human inclination to make status\ndistinctions based on race, and the like. So it is not clear to what\nextend this approach provides an alternative to existing moral\ntheories. It is probably best understood as a form of social theory,\nalbeit one that is ambivalent as to whether it is an empirically\ninformed theory or a form of a priori theorizing (Sugden\n2001). Of course, one may come to think that evolutionary game theory\nis not an alternative to moral theory as much as a vehicle for\nundermining or debunking moral claims. If the source of our moral\ndispositions and judgments is essentially the same as the nasty\ninclinations mentioned above, then perhaps we should conclude that our\nmoral judgments are false or unjustified and our moral dispositions\nuntrustworthy. Evolutionary game theory, on this interpretation, would\nsupport a kind of moral skepticism (see Section 1 of the entry on\n moral skepticism).\n Some answers to this\nskepticism may be found, for instance, in Gibbard (1990). \n\nRegardless of the merits of the three approaches we discussed above,\nthere are some remarkable insights that the application of game theory\noffers to the moral theorist. As we noted above, there are many games\nwith multiple equilibria. This is especially the case with iterated\nplays of particular games such as the prisoner's dilemma. One of the\nimplications of this fact is that insofar as these games are helpful\nrepresentations or models of our social interactions, we have reason to\nexpect much indeterminacy in the world. As a consequence, we have\nreason to be wary of moral theorists that claim universality and\ngenerality for their specific normative recommendations (Hardin 1988,\n2003). \n\nSecondly, game theory makes clear that in any sufficiently large\npopulation we can expect determinate mixes of behavioral dispositions.\nConsider the well-known Hawk-Dove game (Smith 1982): \n\nThe two equilibria in pure strategies in the simple 2 X 2 game\nresult from each player adopting a different strategy. If we think of\n“Hawk” and “Dove” strategies as representing\nmoral dispositions or characters, then we may have reason to expect\nthat human populations will consist of agents with different\ncharacters, so to speak (see also Frank 1988; Smith 1982; Skyrms 1996).\nWhat is more, given this analysis it is far from clear that the moral\ntheorist is in any position to recommend the same disposition, i.e.,\nthe same virtue, for all agents in this population: some should be\n“Hawks” others “Doves” (see also Kuhn\n2004). \n\nWhereas the latter two observations point to original insights for\nmoral theorists, we cannot avoid mentioning some of the criticisms that\nhave been formulated against the application of game theory to ethics.\nThe most fundamental ones concern the implicit anthropology of the\nrational agent. The question is whether everything that is relevant for\nmoral theory about the agent can be captured by the rather\none-dimensional picture of rational man as proposed by game theory. The\nagent is supposed to be completely characterized by his preference\nrankings over outcomes and his beliefs at each stage of the game.\nHowever, morally important distinctions—e.g., between\ndifferences in character—have no place in this\ncharacterization. \n\nWe can illustrate this worry with the way the concept of reputation\nis used in models of altruistic cooperation. Recent game theory has\nmade use of the notion of a player's reputation in efforts to\nexplain cooperation in iterated plays of games such as the prisoner's\ndilemma (Kreps and Wilson 1982). In many repeated prisoner dilemma\ngames it pays to have a reputation to be cooperative. However, it is\nnot clear what exactly it means to have a reputation in these\ncontexts. Ordinarily, a reputation is what is generally believed about\na person's character. In these models, on the other hand, a\nreputation is simply a history of the player's moves in\nsimilar games. There is a morally relevant difference between the two.\nWhat do we believe when we learn that a merchant is honest? Ordinarily\nwe suppose this means that he is the kind of person who will not cheat\nothers, for instance, customers, even in situations where it might pay\nhim to do so. Why might the merchant do this? While another merchant\ndoesn't cheat because (or when) it does not pay, our merchant is honest\nand does not cheat because of his honesty, that is, his character.\nOrdinarily, this makes a big difference in how we would judge on these\ntwo merchants. Both behave cooperatively, but only the latter is\npraiseworthy for his honesty. Game theory and utility theory generally\nhas no room for this distinction (see Morris 1999). (Of relevance here\nis Brennan and Pettit, 2004.) \n\nMost contemporary authors in ethics who use game theory in their\nwork are either contractarians or evolutionary theorists. The two\napproaches represent two different combinations of game theory and\nethics. The contractarian tradition, with its emphasis on fully\nrational agents and bargaining, represents a more traditional use of\ngame theory. The evolutionary approach, on the other hand, with its\nemphasis on bounded rational agents and repeated interactions, is a\nmore recent arrival. To most experts in the field a synthesis of these\napproaches seems highly desirable. (Binmore 1994, 1998 is to date the\nonly attempt.)"}]
