[{"date.published":"2006-09-06","date.changed":"2019-05-24","url":"https://plato.stanford.edu/entries/logic-linear/","author1":"Roberto Di Cosmo","author1.info":"http://www.dicosmo.org","author2.info":"http://www.lix.polytechnique.fr/Labo/Dale.Miller/","entry":"logic-linear","body.text":"\n\n\n\nLinear logic is a refinement of classical and intuitionistic logic.\nInstead of emphasizing truth, as in classical logic, or\nproof, as in intuitionistic logic, linear logic emphasizes the\nrole of formulas as resources. To achieve this focus, linear\nlogic does not allow the usual structural rules of contraction and\nweakening to apply to all formulas but only those formulas marked with\ncertain modals. Linear logic contains a fully involutive negation while\nmaintaining a strong constructive interpretation. Linear logic also\nprovides new insights into the nature of proofs in both classical and\nintuitionistic logic. Given its focus on resources, linear logic has\nfound many applications in Computer Science.\n\n\n\nLinear logic was introduced by Jean-Yves Girard in his\nseminal work\n(Girard 1987).\n While the origin of the discovery of this new logic comes from a\nsemantical analysis of the models of System F (or polymorphic \\(\\lambda\\)-calculus), \none can see the whole system of linear logic as a bold\nattempt to reconcile the beauty and symmetry of the systems for\nclassical logic with the quest for constructive proofs that had led to\nintuitionistic logic. \n\nIndeed, one could present a fragment of linear logic, known as\nmultiplicative additive linear logic (MALL), as the outcome\nof two simple observations. \n\nSo, if we want to eliminate the non-constructive proofs without\ndestroying the symmetry of the sequent calculus, as is done in\nintuitionistic logic, we can try to eliminate the contraction and\nweakening rules instead. In doing so, we are left with two different\nversions of each connective: an additive version and a multiplicative\nversion of conjunction and of disjunction. These different versions\nof the same connecitve are now no longer equivalent. These new\nconnectives are & (“with”, additive and),\n\\(\\oplus\\) (“plus”, additive or, \\(\\otimes\\)\n(“tensor”, multiplicative and) and \\(\\lpar\\)\n(“par”, multiplicative or). \nThis duplication of the connectives actually leads to a much clearer\nunderstanding of the conflict between classical and intuitionistic\nlogic. For example, the law of excluded middle (\\(A\\) or\nnot-\\(A\\)) is considered valid in the classical world and absurd in\nthe intuitionistic one. But in linear logic, this law has two\nreadings: the additive version \\((A \\oplus \\neg A)\\) is not provable\nand corresponds to the intuitionistic reading of disjunction; the\nmultiplicative version \\((A \\lpar \\neg A)\\) is trivially provable and\nsimply corresponds to the tautology \\((A\\)\nimplies \\(A)\\) that is perfectly acceptable in\nintuitionistic logic too. \n\nAlso, the disjunction property, essential in constructivism, is\neasily established for the additive disjunction. \n\nWe find then inside this richer logic a way to represent both the\nneeds of intuitionism and the elegance of classical logic: negation is\ninvolutive, sequents are symmetric, and connectives are inter-definable.\nContrast these properties with those of intuitionistic logic,\nwhere negation is not involutive, sequents are not symmetric, and\nconnectives are all not inter-definable. \n\nNotice though that once one has eliminated the contraction and\nweakening rule, formulas no longer behave as immutable truth values:\nindeed, when we have a proof of \\(A \\Rightarrow B\\) and a\nproof of \\(A\\) in linear logic, by composing them we actually\nconsume them to get a proof of \\(B\\), so that \\(A \\Rightarrow B\\) and \\(A\\) are no longer available after the\ncomposition. Linear logic formulas behave now more like\nresources that can only be used once. \n\nTo recover the full expressive power of intuitionistic and classical\nlogic, it is then necessary to add to the MALL fragment two dual\nmodalities, which are usually called exponentials in the\nlinear logic literature. In particular, the “of-course”\nexponential \\(\\bang\\) permits contraction and weakening to be\napplied to the formula \\(\\bang B\\) in the left-hand sequent context\nwhile the “why-not” exponential\n\\(\\quest\\) permits contraction and weakening to be applied to\nthe formula \\(\\quest B\\) on the right-hand sequent context. This\nleads to the full propositional linear logic and to a very nice\nconnection with computer science. \nNotice that besides MALL, there are two other widely used fragments of\nLinear Logic: Multiplicative Linear Logic (MLL), which is MALL without\nthe additive connectives; and Multiplicative Exponential Linear Logic\n(MELL), which is Linear Logic without the additive connectives.\n \nPrior to the introduction of linear logic in 1987, various researchers\nhad been working on various kinds of substructural logic in which not\nall of Gentzen’s structural rules (contraction, weakening, and\nexchange) are accepted. Lambek studied a sequent calculus proof\nsystems in which none of these structural rules were permitted (Lambek 1958).\nOther examples of such logics are relevant logic (in which weakening\nis not accepted)\n(Avron 1988, Read 1988).\nand affine logic (in which contraction is not accepted)\n(Grishin 1981).\n \n\nProof-theory is focused on formal proof systems and such formal\nsystems have been developed for intuitionistic predicate calculus,\nclassical predicate calculus, arithmetics, higher-order calculi, among\nmany others. Intuitionistic and constructive logic began when people\nsaw the possibility of reading ‘\\(A \\Rightarrow B\\)’ as\n‘if you give me an \\(A\\), I will give you a \\(B\\)’, which\nis a significant departure from the classical reading ‘\\(A\\) is\nfalse or \\(B\\) is true’. \n\nComputer science, on the other hand, focuses on computational\nmechanisms: function application, exception handling, method\ninvocation in object-oriented languages, variable assignment and\nsimilar sets of process-building rules. Except that the mechanisms of\nthese processes have to be made explicit: a function of type \\(A\n\\rightarrow B\\) gives a formal account of how to transform an \\(A\\)\ninto a \\(B\\). \n\nAt a given moment these two senses met. H. B. Curry and W. Howard\nrealized that the set of implication-only intuitionistic\ndeductions was a core functional language called simply-typed\n\\(\\lambda\\)-calculus: the programming language was a logic, the logic a\nprogramming language. This memorable meeting was called the\n‘Curry-Howard isomorphism’ \n(Howard 1980). \n\nLinear logic provides a further twist in the interpretation of the implication\n‘\\(A \\Rightarrow B\\)’: now it can be read as ‘give me\nas many \\(A\\)'s as I might need and I will give you\none \\(B\\)’. The notion of copy which is\nso central to the idea of computation is now wired into the logic.\n \n\nThis new viewpoint opens up new possibilities, including: \n\nThe core propositional connectives of linear logic are divided into\nadditive and multiplicative connectives. The classical conjunction and\nits identity, \\(\\wedge\\) and \\(\\top\\), split into the additive\n\\(\\amp\\) (with) and \\(\\top\\) (top) and the multiplicative \\(\\otimes\\)\n(tensor) and 1 (one). Similarly, the classical disjunction and its\nidentity, \\(\\vee\\) and \\(\\bot\\), split into the additive \\(\\oplus\\)\n(oplus) and 0 (zero) and the multiplicative \\(\\lpar\\) (par) and\n\\(\\bot\\) (bottom). Negation is generally treated in one of two ways in\npresentations a linear logic. Negation can be viewed as a primitive\npropositional connective with no restrictions on its occurrences\nwithin formulas. Since De Morgan dualities exist between negation and\nall propositional connectives, exponentials, and quantifiers, it is\nalso possible to treat negation as a special symbol that only occurs\napplied to atomic formulas. Implications are also commonly introduced\ninto linear logic via definitions: the linear implication \\(B \\limp\nC\\) can be defined as \\(B^{\\bot} \\lpar C\\), while the intuitionistic\nimplication \\(B \\Rightarrow C\\) can be defined as \\(\\bang B \\limp\nC\\). The operators \\(\\bang\\) and \\(\\quest\\) are variously called\nmodals or exponentials. The term “exponential” is\nparticularly appropriate since, following the usual relationship\nbetween exponentiation, addition, and multiplication, linear logic\nsupports the equivalences \\(\\bang (B \\amp C) \\equiv (\\bang B \\otimes\n\\bang C)\\) and \\(\\quest(B \\oplus C) \\equiv (\\quest B \\lpar \\quest C)\\),\nas well as the 0-ary versions of these equivalences, namely,\n\\((\\bang\\top \\equiv 1)\\) and \\((\\quest 0 \\equiv \\bot)\\). Here, we use the\nbinary equivalence \\(B \\equiv C\\) to mean that the formula \\((B \\limp\nC) \\amp(C \\limp B)\\) is derivable in linear logic. \n\nA two-sided sequent calculus for linear logic is presented in the\nfigure below. Notice here that negation is treated as if it were any\nother logic connective: that is, its occurrences in formulas are not\nrestricted and there are introduction rules on the left and right for\nnegation.  The left and right side of sequents are multiset of\nformulas: thus, the order of formulas in these contexts does not\nmatter but their multiplicity does matter.  \n\nNotice that the rules of weakening and\ncontraction are available only for formulas marked with the\nexponential \\(\\bang\\) on the left or \\(\\quest\\) on\nthe right of the sequent. \nThe \\(\\quest\\)R and \\(\\bang\\)L rules\nare often called “dereliction” rules.\nThe \\(\\quest\\)L and \\(\\bang\\)R rules\nare often called “promotion” rules and are the same as the\npossibility and necessity rules found in Kripke’s S4 modal logic.\nThe usual proviso for the \\(\\forall\\)-right and\n\\(\\exists\\)-left introduction rules are assumed: in particular, the\nvariable \\(y\\) must not be free in the formulas of the lower sequent\nof those inference rules. Quantification here is assumed to\nbe first-order: higher-order versions of linear logic can be written\nalong standard lines. \n\nThe cut rule can be eliminated and completeness is still maintained.\nDually, the init rule can also be eliminated as well except\nfor the occurrences of init involving atomic formulas. \n\nAn important normal form theorem for the structure of cut-free\nproofs was provided by Andreoli\n (1992).\nHe classified a non-atomic formula as asynchronous if its\ntop-level logical connective is \\(\\top\\), &, \\(\\bot , \\lpar\\),\n\\(\\quest\\), or \\(\\forall\\) or synchronous if its\ntop-level logical connective is \\(0, \\oplus , 1, \\otimes\\),\n\\(\\bang\\), or \\(\\exists\\). \n\nWhen viewing proof search as a computational model, we can see\nformulas in a sequent as being “agents” that may act\nindependently or in concert with others in their environment. Here, the actions\nof such agents are determined by reading the introduction rule for them\nbottom-up. If an asynchronous formula occurs on the right of a sequent,\nit can evolve without affecting provability and without interacting\nwith its context,\ni.e., the corresponding introduction rule is invertible. \nFor example, the agent \\((B \\lpar C)\\) becomes (by applying the \\(\\lpar\\)-right introduction rule)\nthe two agents \\(B\\) and \\(C\\) (now working in parallel).\nSimilarly, the agent \\((B \\amp C)\\) yields (by applying\nthe &-right introduction rule) two different identical worlds\n(sequents) except that \\(B\\) is in one of these worlds and\n\\(C\\) is in the other. \n\nOn the other hand, if we view a synchronous formula as an agent\nwhose evolution is determined by the corresponding right-introduction\nrule, then it is possible for a provable sequent to evolve to a\nnon-provable sequent (for example, by applying the \\(\\oplus\\)\nright-introduction rule). Also, the instances of such inference rules\ndepend on details of the context of the formula. For example, the\nsuccess of the 1-right introduction rule requires that the surrounding\ncontext is empty and the success of the \\(\\otimes\\)-right\nintroduction rule depends on how the agent’s surrounding context is\ndivided into two contexts. Thus, the evolution of such agents\ndepends on “synchronizing” with other parts of the\ncontext. \n\nNow consider a one-sided sequent calculus presentation of linear\nlogic where the only introduction rules are right-introduction rules.\nGiven the above classification of connectives, it is possible to show\nthat proof search can be structured into the following phases without\nloss of completeness. The asynchronous phase occurs if there\nis an asynchronous formula present in the sequent. In this phase,\nright-introduction rules are applied in any order until there are no\nfurther asynchronous formulas. In the synchronous phase some\nsynchronous formula is selected and becomes the “focus” of\nthis phase: that is, right-introduction rules are applied to it and to\nany synchronous subformula that it might generate. \n\nThe following figure illustrates the focusing proof system linear\nlogic. Notice that the two phases are represented by different arrows:\nthe up-arrow denotes the asynchronous phase and the down-arrow denotes\nthe synchronous phase. Also, sequents are divided into three zones\n(where the zones are separated by either a semicolon or an up or down-arrow).\nIn particular, to the left of the up-arrow and down-arrow are the two zones.\nThe zone written as \\(\\Psi\\) denotes a set of\nformulas that can be used any number of times in the proof of that sequent.\nThe zone written as \\(\\Delta\\) denotes a multiset of formulas\nthat are restricted as in MALL.\nThe zone to the right of an up-arrow is also a multiset of\nformulas while the zone to the right of a down-arrow is a single formula.\nIt is\npossible to impose an arbitrary order on the formulas to the right of\nthe up-arrow since the introduction of asynchronous formulas can be\ndone in any order. \nAtoms are given polarity and in the figure below,\n\\(A\\) stands for positive atoms and the negation of \\(A\\) stands \nfor negative atoms.\nProofs built by these inference rules are called\nfocused proofs. The result in\n Andreoli 1992\n is that focused proofs are complete for linear logic. \n\nFocused proof systems have also been designed for classical and intuitionistic\nlogics (Danos et al. 1997; \nLaurent et al. 2005; \nLiang & Miller 2009). \n\nProofs presented using sequent calculus contain a lot of detail that\nsometimes is uninteresting: consider for example how many\nuninterestingly different ways there are to form a proof of \\(\\vdash \\Gamma , (A_1\\lpar A_2),\n\\ldots ,(A_{n-1}\\lpar A_n)\\) from a derivation of \\(\\vdash \\Gamma ,\nA_1, A_2 , \\ldots ,A_n\\). This unpleasant fact derives from the\nsequential nature of proofs in sequent calculus: if we want to apply a\nset \\(S\\) of \\(n\\) rules to different parts of a sequent, we\ncannot apply them in one step, even if they do not interfere with each\nother! We must sequentialize them,\ni.e., choose a linear order on \\(S\\) and apply the rules in\n\\(n\\) steps, according to this order. \n\nA natural question arises: “Is there a representation of\nproofs that abstracts from such uninteresting details?”. A\nsimilar question is answered positively in the case of intuitionistic\nsequent calculus by means of what is known as natural\ndeduction, that has, via the Curry-Howard correspondence, a strong\nconnection with the computational device known as \\(\\lambda\\)-calculus. \n\nFor linear logic, this succinct representation of proofs is given by\nproof nets, graph-like structures that enjoy particularly\ngood properties for the MLL fragment of the logic. The first step\ntowards this representation is to convert all the sequent calculus\nsystem, using the involutivity of negation, into a one-sided system,\nwhere sequents are of the form \\(\\vdash \\Gamma\\). As a consequence, the\nnumber of rules is reduced since we have no left-introduction rules,\nbut we keep the same expressive power, as provability stays the\nsame. \n\nTo each sequent calculus proof in MLL, one can\ninductively associate a proof net with the same conclusions\nas follows: \n\nAll this can be properly formalized using hypergraphs (formulas are\nnodes and “links” are oriented hyperedges with hypotheses\nand conclusions), and we can formally define as a proof net a\nhypergraph inductively built out of a sequent calculus derivation of\nMLL. Notice that there are quite a lot of hypergraphs that are not\nproof nets. \n\nNow if you look at the proof net built from the derivations of \\(\\vdash \\Gamma , (A_1\\lpar A_2),\n\\ldots ,(A_{n-1}\\lpar A_n)\\) obtained from \\(\\vdash \\Gamma ,\nA_1, A_2 , \\ldots ,A_n\\), you will see that all trace of the\norder of application of the rules has disappeared. In a sense, the\nproof nets are an equivalence class of sequent calculus derivations\nwith respect to the derivation order of rules whose application\ncommute. \n\nSuppose that somebody now comes to you with a huge hypergraph built\nwith axiom, cut, par and tensor links, pretending that it is actually a\nrepresentation of the proof of some long-standing open mathematical\nproblem. How can you verify that it is actually a representation\nof a proof, and not just a random structure? \n\nPerforming this correctness check is a challenge that amounts\nto rebuilding a sequential construction history for your structure,\ncorresponding to a derivation in sequent calculus, and seems at first\na very complex problem: the first correctness criterion for MLL proof\nnets, called the “long trip criterion”, and present in\nGirard’s original paper, is exponential, as well as the ACC (Acyclic\nconnected) criterion of Danos and Regnier (1989) \nfound later on.\nNevertheless, there exists a much more efficient criterion, known as\nContractibility, due to Danos and Regnier, that has more recently been\nreformulated as the following elegant graph parsing criterion by\nGuerrini, Martini and Masini: a hypergraph is a proof net if and only\nif it reduces to the singleton node “net” via the\nfollowing graph reduction rules \n  \n\nPerforming this check naively can take quadratic time (each\napplication of a rule may require an entire lookup of the graph to\nfind the redex, and we need to perform as many steps as there are\nhyperlinks in the graph).\nLinear time algorithms have been give by Guerrini (2011) \nand by Murawski and Ong (2006). \nAnother style of correctness criterion for MLL proof nets is given by \nRetoré (2003) in which a quadratic\nalgorithm is given for MLL.\n \n\nOn proof nets, one can perform cut elimination in a particularly clean\nway: due to their parallel nature, cuts can be eliminated locally via\ntwo simplification rules: \n\nThese are actually computation rules over proof nets, and the\ncorrectness criteria allow to verify easily that any such rule\npreserves correctness, and as a consequence, the reduction of a proof net\nstill comes from a sequent calculus proof of the same sequent. \n\nHence, cut elimination in MLL proof nets can be performed in linear\ntime and gives a simple, elegant cut-elimination result for all of\nMLL. \n\nThe proof nets approach can be extended to larger subsets of linear\nlogic, but then it is less clear how to obtain the same elegant results\nas for MLL: the original system proposed in\n Girard 1987\n works for MELL, for example, by associating to the four exponential\nrules the following hypergraph constructions: \n\nWhile these constructions and the associated graph reductions bear\nstriking similarity with \\(\\lambda\\)-calculus with explicit substitutions,\nas first remarked by Di Cosmo & Kesner\n (1997),\n they are too similar to the corresponding sequent calculus rules: the\nparallelization effect so elegant for MLL does not properly carry on\nhere, and the graph reduction rules involve boxes and are not\nlocal. \n\nTo recover a satisfactory system, many proposals have been made,\nstarting from the one by Danos & Regnier\n (1995)\n but we want to mention here the very elegant\napproach by Guerrini, Martini and Masini\n (Guerrini et al. 2003),\n that neatly shows the connection between two level proof systems for\nmodal logic, proper proof nets for MELL, and optimal reduction in the\n\\(\\lambda\\)-calculus. \nA recent paper by Heijltjes and Houston (2016)\nhas shown that there can be no satisfactory notion of proof nets for MLL if \nunits are also allowed. \n \nIt is possible to provide a canonical treatment of additive\nconnectives, even with first-order quantification \n(Heijltjes et al. 2018). \nProof nets for formulas containing both multiplicative and\nadditive connectives have various technical presentations, none of\nwhich appears canonical and satisfactory. Their treatment in\nproof-net-like proof systems is currently a topic of active research.\nIn particular, see (Hughes and van Glabbeek 2005) and \n(Hughes and Heijltjes 2016).\n \n\nApproaching the semantics of linear logic is usually done along two\ndifferent paths. First, there are various semantic structures\navailable that can be used to map formulas to denotations in such\nstructures. That approach can be used to establish soundness and\ncompleteness for various fragments of linear logic. A more novel\nsemantic approach to linear logic involves giving semantics to proofs\ndirectly. We describe briefly these two approaches and provide some\nlinks to the literature. \n\nOne approach to attempting a sound and complete semantics for\nfragments of linear logic associates to a formula the set of all\ncontexts that can be used to prove that formula. Of course, such a\ncollection may need to be more abstract and to be given various\nclosure properties. The phase semantics of Girard\n (1987)\n provides one such semantics: some uses of such semantics have been\nmade in computer science to provide counterexamples and as a tool that\ncan help establish that a given concurrent system cannot evolve into\nanother with certain properties\n (Fages et al. 2001).\n Similarly,\nKripke-style semantics have been provided in\n Allwein & Dunn 1993\n and\n Hodas & Miller 1994.\n Quantales, certain kind of partially ordered algebraic structures,\nhave also been used to provide early semantic models for parts of\nlinear logic\n (Yetter 1990). \n\nIn the formulas-as-types analogy which is so popular and fruitful in\ntheoretical computer science, a logical system is put in\ncorrespondence with a typed computational device (like typed \\(\\lambda\\)-calculus), \nby associating to each proof of that formula a program having\nthat formula as a type. For example, a proof of the tautology\n\\(A \\Rightarrow A\\) corresponds to the program\nfun\\((x:A).x:A\\rightarrow A\\),\nthe identity function on objects of type \\(A\\). This is why, in\nconstructive logical systems (such as intuitionistic logic and arithmetic),\nand in linear logic, so much importance\nis attached to proofs, to the point that building and studying models\nof proofs gets so much more attention than building and studying\nmodels of provability: we are not satisfied to know that a formula is\nprovable, we really want to know the computational content of\nits proof. \n\nMany models of linear logic proofs have been proposed; we consider\nthat, to date, the simplest and most intuitive construction is those\nbased on the so-called “relational semantics” or\n“Kripke-style semantics”, where formulas are interpreted\nas multisets, one-sided sequents are interpreted as tuples of\nmultisets, and proofs are interpreted as relations over the\ninterpretation of sequents. If one wants to give a purely\nset-theoretic semantics, without resorting to multisets, it is\npossible to do it by means of coherence spaces, sets equipped with a\nspecial coherence relation, as originally shown by in\n Girard 1987.\n There are interesting\ncategory theoretical models of linear logic, such as the *-autonomous\ncategories\n (Barr 1991)\n and hypercoherences\n (Ehrhard 1993). \n\nAnother approach to the semantics of proofs is given by Girard’s\nGeometry of Interaction, that allows us to obtain a fully\nalgebraic characterization of proofs. To each proof net, one can\nassociate a partial permutation matrix \\(\\sigma\\) corresponding to the\ncut links, and a proper matrix \\(M\\) corresponding expressions built out of a \ncertain\ndynamic algebra, that describe the possible paths inside the proof\nnet. It is then possible to fully describe the proof net via the\nexecution formula \n\nwhich, in the MLL case, is an invariant of the normalization\nprocess. Some nice connection to results coming from data-flow theory\nhas been shown in some early work of Abramsky & Jagadeesan\n (1994). \nThe area of semantics that has developed around so-called game\nsemantics deserves special attention. The strong connection between\ngames and linear logic was pointed out quite early by A. Blass \n(1992).\nIn fact, there are two different traditions to connecting logic\nto games. In the tradition of dialog games dating back to\nLorenzen, one player attempts to prove a formula while a second player\nattempts to refute it. It is possible to provide MALL with such a\ndialog game that is completely symmetric for both the prover and the\nrefuter (Delande et al. 2010).\nIn another tradition, formulas are\ninterpreted as games, logical connectives as game constructors, and\nproofs as strategies that describe how a player reacts to opponent\nmoves. By imposing different restrictions on the rules of the game,\none can actually provide a precise semantics (technically, a\nfully abstract model) for various features of actual programming\nlanguages, hence the huge interest in this area over the past\nyears. See, for example, \n Abramsky & Jagadeesan 1994,\n Abramsky & Melliès 1999,\n and\n Hyland & Ong 2000.\n \nFor any given logic, it is useful to know whether or not there is an\neffective procedure to determine, for each sentence in the logic, if\nit is provable or not. A decidable logic—i.e., one for\nwhich there is an effective procedure for provability—is often\ndescribed by its\ncomplexity class, which characterizes how difficult it is\nto perform the decision procedure.\nExtensive research work has been dedicated to the study of the\ncomplexity and decidability issues for several fragments of\npropositional linear logic. It is known that \nNP, PSPACE, and EXPSPACE are complexity classes such that NP \\(\\subseteq\\)\nPSPACE \\(\\subseteq\\) EXPSPACE. Surprisingly, for those that may forget that\nthe novelty in linear logic lies in the way formulas are managed\nwithout the structural rules of contraction and weakening, \nthese results stay the same even if we focus\non the fragments of the logics where only the constants, and no\npropositional variables, are allowed (Kanovich 1994,\n Lincoln & Winkler 1994). Indeed, it is\npossible to encode arbitrary formulas into constant-only formulas\npreserving provability. \nMELL is a surprisingly expressive logic. For example, the\nreachability problem in Petri nets can be encoded into MELL (Gunter & Gehlot 1989) and that problem is\nequivalent to the reachability problem of vector addition systems with\nstates (VASS) (Reutenauer 1989).\nFurthermore, the decidability problem of MELL is equivalent to the\nreachability problem for branching VASS (de\nGroote et al. 2004) and the latter is known to have a\nnon-elementary lower bound (Lazic and Schmitz\n2015). Thus, if MELL turns out to be decidable it will be at\nleast TOWER-hard (Lazic and Schmitz 2015).\nA proof of the decidability of MELL has been given by Bimbó\n(2015) but a gap in that proof \nhas been reported in Straßburger (forthcoming).\n \nLinear logic with the unrestricted weakening rule added \n(also known as linear affine logic) is decidable\n(Kopylov 1995) and to be exponential \nspace hard (Urquhart 2000).\n \nA good overview of complexity results surrounding linear logic can\nbe found in\n Lincoln 1995. \n\nWhen intuitionistic logic was first proposed early in the last\ncentury, it was presented as a challenge to the way traditional\nmathematicians were supposed to do business. Uses of the excluded middle\nand of proof-by-contradiction were considered suspect and problematic,\nparticularly in the presence of infinity. As intuitionistic logic\nconcerns were developed into constructive mathematics, new constructive\napproaches have arisen to topics such as topology, algebra, and\nanalysis. Given that linear logic encompasses the dynamics of proof\n(algorithm) and resources, its primary impacts has been not in\ntraditional mathematics but in computer science. Before overviewing the\nnature of that impact, we outline the various ways in which logic more\ngenerally is used in computer science. \n\nLogic plays different roles in the specification of computations. We\ncan identify the following broad different approaches and note which\nroles have felt influences from linear logic. \n\nIn the computation-as-model approach, computations are\nencoded as mathematical structures and consist of such items as nodes,\ntransitions, and states. Logic is used in an external sense to make\nstatements about those structures. That is, computations are\nused as models for logical expressions. Intensional operators, such as\nthe modals of temporal and dynamic logics or the triples of Hoare\nlogic, are often employed to express propositions about the change in\nstate. This use of logic to represent and reason about computation is\nprobably the oldest and most broadly successful use of logic for\nrepresenting computation. This role for logic has felt little influence\nfrom linear logic. \n\nIn the computation-as-deduction approach, pieces of logic’s\nsyntax (such as formulas, terms, types, and proofs) are used directly\nas elements of the specified computation. In this more rarefied\nsetting, there are two rather different approaches to how computation\nis modeled, called the proof normalization approach and the\nproof search approach. \n\nWe outline below the significant impacts that linear logic has had on\nboth of these different settings. \n\nThe proof normalization approach views the state of a\ncomputation as a proof term and the process of computing as\nnormalization (known alternatively as \\(\\beta\\)-reduction or cut-elimination).\nFunctional programming can be explained using proof-normalization as\nits theoretical basis\n (Martin-Löf 1982)\n and has been used to justify the design of new functional\n programming languages, e.g.,\n Abramsky 1993.\n Linear logic provides this approach to computational specification\nwith new types, new declarative means for statically understanding how\nresources may be used in a computation, and provided an appealing\nmeans for formalizing the duality between a function and the\nenvironment that supplies it with arguments. \n\nAnother area where linear logic has been a powerful theoretical\ninstrument is that of optimal reduction. The problem of\nbuilding efficient (optimal) interpreters for the \\(\\lambda\\)-calculus, that\nstayed open for quite a long time after its original definition by J.J.\nLévy, was solved for the first time in \n Lamping 1990, \n via a sophisticated sharing graph implementation involving a quite\nimpressive amount of rules. Using ideas and intuition from linear\nlogic, many authors reconstructed Lamping’s solution, simplifying it\nand leading to a rich theory connected to that of the Geometry of\nInteraction. For further reading, a good reference\nis Asperti & Guerrini 1998.\n \n\nThe refinement of intuitionistic logic provided by linear logic and\nthe dualities of linear logic provided a setting in which one could\nview a function and its environment as similar entities that interact\ndually. For example, a function with the type \\(A \\limp B\\) can be\nmodeled as a process that consumes a value of type \\(A\\) from its\nenvironment and transforms it into a value of type \\(B\\). In linear\nlogic, this implication is equivalent to its contrapositive form: the\ntype \\(B^{\\bot} \\limp A^{\\bot}\\) can lead to interpreting the same\nfunction as a process that transforms a demand for a value of type\n\\(B\\) into a demand for a value of type \\(A\\) (notice that this does\nnot happen with functions of intuitionistic type since, for example,\ninput argument may be vacuous)\n (Curien 2003).\n The recent successes of using game semantics to model functional\ncomputation are similarly related to the dual treatment of function\nand environment (Abramsky and Jagadeesan 1994,\n Hyland & Ong 2000). \n\nFinally, we mention that in the area of encoding computation as proof\nnormalization, linear logic has been used to provide a type-based\ndescription of polytime recursive functions. For example, M.\n Hofmann\n (2003)\n introduced a \\(\\lambda\\)-calculus with\nmodal and linear types that extended the function algebra of\n Bellantoni & Cook 1992\n to higher types. Types based on linear logic have also been used\nwithin functional programs: see\n Guzman & Hudak 1990\n and\n Wadler 1991. \n\nThe proof search approach views the state of a computation\nas a sequent (a structured collection of formulas) and the process of\ncomputing as the process of searching for a proof of a sequent: the\nchanges that take place in sequents capture the dynamics of\ncomputation. \nWith this view of computation, we generally read\ninference rules bottom up, i.e., \nas a transformation of their conclusion into their premise(s). \nLogic programming can be explained using proof search as\nits theoretical basis, and linear logic provides this approach to\ncomputational specification with new combinators for building logic\nprograms, new means to capture rich dynamics, and new\ndeclarative approaches to specifying concurrent computations. (See\n Miller 2004\n for an overview of linear logic programming languages.) \n\nThe completeness of focusing proof system can be used to provide a\ndeclarative explanation of part of the operational semantics of logic\nprogramming within linear logic. Consider, for example, the subset\n\\(L\\) of formulas of linear logic that are built from only the\nconnectives \\(\\top\\), &, \\(\\limp , \\Rightarrow\\), and \\(\\forall\\). (Notice\nthat if one adds \\(\\bot\\) to this list, it is possible to encode all\nconnectives of linear logic.) It is possible to see that cut-free\nproof search in \\(L\\) can be defined into to phases. Given a\nsequent \\(\\Gamma\\); \\(\\Delta \\rightarrow G\\), where \\(\\Gamma\\) is a set of\nformulas (which can be contracted and weakened), \\(\\Delta\\) is multiset\nof formulas (which cannot be contracted nor weakened), and \\(G\\)\n(the “goal” formula) is a single formula (all\nfrom \\(L)\\), then proof search proceeds as follows. \n\nFormally, these various phases can be described using the following\ninference rules. Here, a new sequent arrow is introduced:\nthis arrow is labeled with the formula that is the result of a\nleft-introduction rule. Notice that the rule for left-introduction of\n\\(\\limp\\) requires splitting the \\(\\Delta\\) context\ninto two parts \\(\\Delta_1,\\Delta_2\\) (when reading\nthe rule bottom up). There are, of course, \\(2^n\\) such\nsplittings if that context has \\(n \\ge 0\\) distinct\nformulas.\nThe syntactic variable \\(A\\) in these inference rules ranges over\natomic formulas. \n\nLinear logic restricted to \\(L\\) can be viewed as a linear logic\nprogramming language. As a consequence, it can serve as a\nspecification language for computational systems, a role that is also\noccupied by, say, Petri nets, process calculi, \\(\\lambda\\)-calculus,\netc. Given that linear logic has a proof theory and various kinds of\nsemantics, broad avenues of reasoning about computations specified in\n\\(L\\) are provided by the meta-theory of linear logic. \n\nGiven that the sequent calculus for linear logic uses multisets of formulas,\nproof search can directly encode multiset rewriting. Since\nmany computations can naturally be seen as multiset rewriting, it has\nbeen possible to make numerous connections between linear logic and\nPetri nets\n (Gunter & Gehlot 1989),\n process calculi\n (Andreoli & Pareschi 1991,\n Kobayashi et al. 1999,\n Miller 1996),\n and security protocols\n (Cervesato et al. 1999,\n Miller 2003). \n\nThe exponentials \\(\\bang\\) and \\(\\quest\\) in linear\nlogic are less carved in the marble than the other\nconnectives. Indeed, if one uses traditional sequent calculus\npresentations, the exponentials are not canonical in the following sense: if\nyou introduce another copy of exponentials, say\n\\(\\bang'\\) and \\(\\quest'\\), with the same\nrules as the original ones, there is no way to prove that\n\\(\\bang\\) is equivalent to \\(\\bang'\\), and\n\\(\\quest\\) to \\(\\quest'\\), while for the other\nconnectives this is easily established. \nVarious applications of non-canonical exponentials can be\nfound in (Danos et. al., 1993; \nNigam & Miller, 2009). \nAlthough the decidability of MELL is currently being debated \n(Bimbó 2015,\nStraßburger forthcoming), \nextending MLL with three pairs of \\(\\bang\\) and\n\\(\\quest\\) yields a logic that is undecidable\n (Chaudhuri 2018). \nMartini and \nMasini 1995 describe a “2-sequent” \nproof system in which the exponentials are canonical. \nThe fact that cut-elimination can make proofs in classical and\nintuitionistic logic grow to enormous size can be analyzed in terms of the\napplication of the contraction rule in those proof systems. If proof systems\nintroduce restrictions on contraction, it is possible to design new\nlogics and proof systems for which cut-elimination has a much-reduced\ncomplexity. For example, elementary linear logic (ELL) is\nobtained by replacing the \\(\\bang\\) and \\(\\quest\\)\nintroduction by a single rule introducing \\(\\bang\\) and\n\\(\\quest\\) at the same time. As a consequence, ELL can encode\nall and only the Kalmar elementary functions (computable in time\nbounded by a tower of exponentials of fixed height) \n(Girard 1998, \nBaillot 2015). Still, other variations on the inference rules for the\nexponentials have been studied. For example, light linear\nlogic (Girard 1998) and soft linear\nlogic (Lafont 2004) both characterize\nfunctions computable in polynomial time: see also\n (Baillot & Terui 2004).\n \n\nWhile linear logic rejects the universal application of the two\nstructural rules of weakening and contraction, it allows the\nunrestricted use of the structural rule called exchange. A sequent\ncalculus that does not universally employ the exchange rule has\nsequents whose left and right contexts are lists: the order of formulas\nwithin context becomes an expressive element of the logic. In this\ncase, the multiplicative disjunction and conjunction can become\nnon-commutative. \n\nOne of the first logics that rejects all three structural rules of\nthe sequent calculus was given in \n Lambek 1958.\n While this logic contains two implications, it does not\ncontain a negation nor exponentials. Various recent papers have\nproposed extending linear logic to include non-commutative features\nand, at present, no proposal seems canonical. For a sampling of\nnon-commutative linear logics, see\n Yetter 1990,\n Abrusci 1991,\n Retoré 1997,\n Abrusci & Ruet 1999, and\n Guglielmi & Straßburger 2001. \nWhile the MALL logic is an expressive and novel logic, it is also\ndecidable and, thus, not capable of capturing the unbounded behaviors \nfound in, say, mathematics and computer science. As described above, \nthe addition of the exponentials ! and ? enriches MALL to full linear \nlogic and to a setting where unbounded behaviors can be captured. \nA second approach to extending MALL to capture unbounded behaviors \ninvolves the addition of\nthe least and greatest fixed point operators as logical connectives \ndirectly into MALL. In order to properly characterize fixed points \nas being either the least\nor the greatest, it is necessary for the inference rules for fixed\npoints to be\n“higher-order” in \nthe sense that they involve invariants. Such an extension to MALL \n(also with first-order\nquantification and term equality) has been developed by Baelde \n(Baelde & Miller, \n2007; \nBaelde 2012) and has been used to \nprovide a proof-theoretic foundation for model checking \n(Heath & Miller 2018).\n","contact.mail":"roberto@dicosmo.org","contact.domain":"dicosmo.org"},{"date.published":"2006-09-06","date.changed":"2019-05-24","url":"https://plato.stanford.edu/entries/logic-linear/","author1":"Roberto Di Cosmo","author1.info":"http://www.dicosmo.org","author2.info":"http://www.lix.polytechnique.fr/Labo/Dale.Miller/","entry":"logic-linear","body.text":"\n\n\n\nLinear logic is a refinement of classical and intuitionistic logic.\nInstead of emphasizing truth, as in classical logic, or\nproof, as in intuitionistic logic, linear logic emphasizes the\nrole of formulas as resources. To achieve this focus, linear\nlogic does not allow the usual structural rules of contraction and\nweakening to apply to all formulas but only those formulas marked with\ncertain modals. Linear logic contains a fully involutive negation while\nmaintaining a strong constructive interpretation. Linear logic also\nprovides new insights into the nature of proofs in both classical and\nintuitionistic logic. Given its focus on resources, linear logic has\nfound many applications in Computer Science.\n\n\n\nLinear logic was introduced by Jean-Yves Girard in his\nseminal work\n(Girard 1987).\n While the origin of the discovery of this new logic comes from a\nsemantical analysis of the models of System F (or polymorphic \\(\\lambda\\)-calculus), \none can see the whole system of linear logic as a bold\nattempt to reconcile the beauty and symmetry of the systems for\nclassical logic with the quest for constructive proofs that had led to\nintuitionistic logic. \n\nIndeed, one could present a fragment of linear logic, known as\nmultiplicative additive linear logic (MALL), as the outcome\nof two simple observations. \n\nSo, if we want to eliminate the non-constructive proofs without\ndestroying the symmetry of the sequent calculus, as is done in\nintuitionistic logic, we can try to eliminate the contraction and\nweakening rules instead. In doing so, we are left with two different\nversions of each connective: an additive version and a multiplicative\nversion of conjunction and of disjunction. These different versions\nof the same connecitve are now no longer equivalent. These new\nconnectives are & (“with”, additive and),\n\\(\\oplus\\) (“plus”, additive or, \\(\\otimes\\)\n(“tensor”, multiplicative and) and \\(\\lpar\\)\n(“par”, multiplicative or). \nThis duplication of the connectives actually leads to a much clearer\nunderstanding of the conflict between classical and intuitionistic\nlogic. For example, the law of excluded middle (\\(A\\) or\nnot-\\(A\\)) is considered valid in the classical world and absurd in\nthe intuitionistic one. But in linear logic, this law has two\nreadings: the additive version \\((A \\oplus \\neg A)\\) is not provable\nand corresponds to the intuitionistic reading of disjunction; the\nmultiplicative version \\((A \\lpar \\neg A)\\) is trivially provable and\nsimply corresponds to the tautology \\((A\\)\nimplies \\(A)\\) that is perfectly acceptable in\nintuitionistic logic too. \n\nAlso, the disjunction property, essential in constructivism, is\neasily established for the additive disjunction. \n\nWe find then inside this richer logic a way to represent both the\nneeds of intuitionism and the elegance of classical logic: negation is\ninvolutive, sequents are symmetric, and connectives are inter-definable.\nContrast these properties with those of intuitionistic logic,\nwhere negation is not involutive, sequents are not symmetric, and\nconnectives are all not inter-definable. \n\nNotice though that once one has eliminated the contraction and\nweakening rule, formulas no longer behave as immutable truth values:\nindeed, when we have a proof of \\(A \\Rightarrow B\\) and a\nproof of \\(A\\) in linear logic, by composing them we actually\nconsume them to get a proof of \\(B\\), so that \\(A \\Rightarrow B\\) and \\(A\\) are no longer available after the\ncomposition. Linear logic formulas behave now more like\nresources that can only be used once. \n\nTo recover the full expressive power of intuitionistic and classical\nlogic, it is then necessary to add to the MALL fragment two dual\nmodalities, which are usually called exponentials in the\nlinear logic literature. In particular, the “of-course”\nexponential \\(\\bang\\) permits contraction and weakening to be\napplied to the formula \\(\\bang B\\) in the left-hand sequent context\nwhile the “why-not” exponential\n\\(\\quest\\) permits contraction and weakening to be applied to\nthe formula \\(\\quest B\\) on the right-hand sequent context. This\nleads to the full propositional linear logic and to a very nice\nconnection with computer science. \nNotice that besides MALL, there are two other widely used fragments of\nLinear Logic: Multiplicative Linear Logic (MLL), which is MALL without\nthe additive connectives; and Multiplicative Exponential Linear Logic\n(MELL), which is Linear Logic without the additive connectives.\n \nPrior to the introduction of linear logic in 1987, various researchers\nhad been working on various kinds of substructural logic in which not\nall of Gentzen’s structural rules (contraction, weakening, and\nexchange) are accepted. Lambek studied a sequent calculus proof\nsystems in which none of these structural rules were permitted (Lambek 1958).\nOther examples of such logics are relevant logic (in which weakening\nis not accepted)\n(Avron 1988, Read 1988).\nand affine logic (in which contraction is not accepted)\n(Grishin 1981).\n \n\nProof-theory is focused on formal proof systems and such formal\nsystems have been developed for intuitionistic predicate calculus,\nclassical predicate calculus, arithmetics, higher-order calculi, among\nmany others. Intuitionistic and constructive logic began when people\nsaw the possibility of reading ‘\\(A \\Rightarrow B\\)’ as\n‘if you give me an \\(A\\), I will give you a \\(B\\)’, which\nis a significant departure from the classical reading ‘\\(A\\) is\nfalse or \\(B\\) is true’. \n\nComputer science, on the other hand, focuses on computational\nmechanisms: function application, exception handling, method\ninvocation in object-oriented languages, variable assignment and\nsimilar sets of process-building rules. Except that the mechanisms of\nthese processes have to be made explicit: a function of type \\(A\n\\rightarrow B\\) gives a formal account of how to transform an \\(A\\)\ninto a \\(B\\). \n\nAt a given moment these two senses met. H. B. Curry and W. Howard\nrealized that the set of implication-only intuitionistic\ndeductions was a core functional language called simply-typed\n\\(\\lambda\\)-calculus: the programming language was a logic, the logic a\nprogramming language. This memorable meeting was called the\n‘Curry-Howard isomorphism’ \n(Howard 1980). \n\nLinear logic provides a further twist in the interpretation of the implication\n‘\\(A \\Rightarrow B\\)’: now it can be read as ‘give me\nas many \\(A\\)'s as I might need and I will give you\none \\(B\\)’. The notion of copy which is\nso central to the idea of computation is now wired into the logic.\n \n\nThis new viewpoint opens up new possibilities, including: \n\nThe core propositional connectives of linear logic are divided into\nadditive and multiplicative connectives. The classical conjunction and\nits identity, \\(\\wedge\\) and \\(\\top\\), split into the additive\n\\(\\amp\\) (with) and \\(\\top\\) (top) and the multiplicative \\(\\otimes\\)\n(tensor) and 1 (one). Similarly, the classical disjunction and its\nidentity, \\(\\vee\\) and \\(\\bot\\), split into the additive \\(\\oplus\\)\n(oplus) and 0 (zero) and the multiplicative \\(\\lpar\\) (par) and\n\\(\\bot\\) (bottom). Negation is generally treated in one of two ways in\npresentations a linear logic. Negation can be viewed as a primitive\npropositional connective with no restrictions on its occurrences\nwithin formulas. Since De Morgan dualities exist between negation and\nall propositional connectives, exponentials, and quantifiers, it is\nalso possible to treat negation as a special symbol that only occurs\napplied to atomic formulas. Implications are also commonly introduced\ninto linear logic via definitions: the linear implication \\(B \\limp\nC\\) can be defined as \\(B^{\\bot} \\lpar C\\), while the intuitionistic\nimplication \\(B \\Rightarrow C\\) can be defined as \\(\\bang B \\limp\nC\\). The operators \\(\\bang\\) and \\(\\quest\\) are variously called\nmodals or exponentials. The term “exponential” is\nparticularly appropriate since, following the usual relationship\nbetween exponentiation, addition, and multiplication, linear logic\nsupports the equivalences \\(\\bang (B \\amp C) \\equiv (\\bang B \\otimes\n\\bang C)\\) and \\(\\quest(B \\oplus C) \\equiv (\\quest B \\lpar \\quest C)\\),\nas well as the 0-ary versions of these equivalences, namely,\n\\((\\bang\\top \\equiv 1)\\) and \\((\\quest 0 \\equiv \\bot)\\). Here, we use the\nbinary equivalence \\(B \\equiv C\\) to mean that the formula \\((B \\limp\nC) \\amp(C \\limp B)\\) is derivable in linear logic. \n\nA two-sided sequent calculus for linear logic is presented in the\nfigure below. Notice here that negation is treated as if it were any\nother logic connective: that is, its occurrences in formulas are not\nrestricted and there are introduction rules on the left and right for\nnegation.  The left and right side of sequents are multiset of\nformulas: thus, the order of formulas in these contexts does not\nmatter but their multiplicity does matter.  \n\nNotice that the rules of weakening and\ncontraction are available only for formulas marked with the\nexponential \\(\\bang\\) on the left or \\(\\quest\\) on\nthe right of the sequent. \nThe \\(\\quest\\)R and \\(\\bang\\)L rules\nare often called “dereliction” rules.\nThe \\(\\quest\\)L and \\(\\bang\\)R rules\nare often called “promotion” rules and are the same as the\npossibility and necessity rules found in Kripke’s S4 modal logic.\nThe usual proviso for the \\(\\forall\\)-right and\n\\(\\exists\\)-left introduction rules are assumed: in particular, the\nvariable \\(y\\) must not be free in the formulas of the lower sequent\nof those inference rules. Quantification here is assumed to\nbe first-order: higher-order versions of linear logic can be written\nalong standard lines. \n\nThe cut rule can be eliminated and completeness is still maintained.\nDually, the init rule can also be eliminated as well except\nfor the occurrences of init involving atomic formulas. \n\nAn important normal form theorem for the structure of cut-free\nproofs was provided by Andreoli\n (1992).\nHe classified a non-atomic formula as asynchronous if its\ntop-level logical connective is \\(\\top\\), &, \\(\\bot , \\lpar\\),\n\\(\\quest\\), or \\(\\forall\\) or synchronous if its\ntop-level logical connective is \\(0, \\oplus , 1, \\otimes\\),\n\\(\\bang\\), or \\(\\exists\\). \n\nWhen viewing proof search as a computational model, we can see\nformulas in a sequent as being “agents” that may act\nindependently or in concert with others in their environment. Here, the actions\nof such agents are determined by reading the introduction rule for them\nbottom-up. If an asynchronous formula occurs on the right of a sequent,\nit can evolve without affecting provability and without interacting\nwith its context,\ni.e., the corresponding introduction rule is invertible. \nFor example, the agent \\((B \\lpar C)\\) becomes (by applying the \\(\\lpar\\)-right introduction rule)\nthe two agents \\(B\\) and \\(C\\) (now working in parallel).\nSimilarly, the agent \\((B \\amp C)\\) yields (by applying\nthe &-right introduction rule) two different identical worlds\n(sequents) except that \\(B\\) is in one of these worlds and\n\\(C\\) is in the other. \n\nOn the other hand, if we view a synchronous formula as an agent\nwhose evolution is determined by the corresponding right-introduction\nrule, then it is possible for a provable sequent to evolve to a\nnon-provable sequent (for example, by applying the \\(\\oplus\\)\nright-introduction rule). Also, the instances of such inference rules\ndepend on details of the context of the formula. For example, the\nsuccess of the 1-right introduction rule requires that the surrounding\ncontext is empty and the success of the \\(\\otimes\\)-right\nintroduction rule depends on how the agent’s surrounding context is\ndivided into two contexts. Thus, the evolution of such agents\ndepends on “synchronizing” with other parts of the\ncontext. \n\nNow consider a one-sided sequent calculus presentation of linear\nlogic where the only introduction rules are right-introduction rules.\nGiven the above classification of connectives, it is possible to show\nthat proof search can be structured into the following phases without\nloss of completeness. The asynchronous phase occurs if there\nis an asynchronous formula present in the sequent. In this phase,\nright-introduction rules are applied in any order until there are no\nfurther asynchronous formulas. In the synchronous phase some\nsynchronous formula is selected and becomes the “focus” of\nthis phase: that is, right-introduction rules are applied to it and to\nany synchronous subformula that it might generate. \n\nThe following figure illustrates the focusing proof system linear\nlogic. Notice that the two phases are represented by different arrows:\nthe up-arrow denotes the asynchronous phase and the down-arrow denotes\nthe synchronous phase. Also, sequents are divided into three zones\n(where the zones are separated by either a semicolon or an up or down-arrow).\nIn particular, to the left of the up-arrow and down-arrow are the two zones.\nThe zone written as \\(\\Psi\\) denotes a set of\nformulas that can be used any number of times in the proof of that sequent.\nThe zone written as \\(\\Delta\\) denotes a multiset of formulas\nthat are restricted as in MALL.\nThe zone to the right of an up-arrow is also a multiset of\nformulas while the zone to the right of a down-arrow is a single formula.\nIt is\npossible to impose an arbitrary order on the formulas to the right of\nthe up-arrow since the introduction of asynchronous formulas can be\ndone in any order. \nAtoms are given polarity and in the figure below,\n\\(A\\) stands for positive atoms and the negation of \\(A\\) stands \nfor negative atoms.\nProofs built by these inference rules are called\nfocused proofs. The result in\n Andreoli 1992\n is that focused proofs are complete for linear logic. \n\nFocused proof systems have also been designed for classical and intuitionistic\nlogics (Danos et al. 1997; \nLaurent et al. 2005; \nLiang & Miller 2009). \n\nProofs presented using sequent calculus contain a lot of detail that\nsometimes is uninteresting: consider for example how many\nuninterestingly different ways there are to form a proof of \\(\\vdash \\Gamma , (A_1\\lpar A_2),\n\\ldots ,(A_{n-1}\\lpar A_n)\\) from a derivation of \\(\\vdash \\Gamma ,\nA_1, A_2 , \\ldots ,A_n\\). This unpleasant fact derives from the\nsequential nature of proofs in sequent calculus: if we want to apply a\nset \\(S\\) of \\(n\\) rules to different parts of a sequent, we\ncannot apply them in one step, even if they do not interfere with each\nother! We must sequentialize them,\ni.e., choose a linear order on \\(S\\) and apply the rules in\n\\(n\\) steps, according to this order. \n\nA natural question arises: “Is there a representation of\nproofs that abstracts from such uninteresting details?”. A\nsimilar question is answered positively in the case of intuitionistic\nsequent calculus by means of what is known as natural\ndeduction, that has, via the Curry-Howard correspondence, a strong\nconnection with the computational device known as \\(\\lambda\\)-calculus. \n\nFor linear logic, this succinct representation of proofs is given by\nproof nets, graph-like structures that enjoy particularly\ngood properties for the MLL fragment of the logic. The first step\ntowards this representation is to convert all the sequent calculus\nsystem, using the involutivity of negation, into a one-sided system,\nwhere sequents are of the form \\(\\vdash \\Gamma\\). As a consequence, the\nnumber of rules is reduced since we have no left-introduction rules,\nbut we keep the same expressive power, as provability stays the\nsame. \n\nTo each sequent calculus proof in MLL, one can\ninductively associate a proof net with the same conclusions\nas follows: \n\nAll this can be properly formalized using hypergraphs (formulas are\nnodes and “links” are oriented hyperedges with hypotheses\nand conclusions), and we can formally define as a proof net a\nhypergraph inductively built out of a sequent calculus derivation of\nMLL. Notice that there are quite a lot of hypergraphs that are not\nproof nets. \n\nNow if you look at the proof net built from the derivations of \\(\\vdash \\Gamma , (A_1\\lpar A_2),\n\\ldots ,(A_{n-1}\\lpar A_n)\\) obtained from \\(\\vdash \\Gamma ,\nA_1, A_2 , \\ldots ,A_n\\), you will see that all trace of the\norder of application of the rules has disappeared. In a sense, the\nproof nets are an equivalence class of sequent calculus derivations\nwith respect to the derivation order of rules whose application\ncommute. \n\nSuppose that somebody now comes to you with a huge hypergraph built\nwith axiom, cut, par and tensor links, pretending that it is actually a\nrepresentation of the proof of some long-standing open mathematical\nproblem. How can you verify that it is actually a representation\nof a proof, and not just a random structure? \n\nPerforming this correctness check is a challenge that amounts\nto rebuilding a sequential construction history for your structure,\ncorresponding to a derivation in sequent calculus, and seems at first\na very complex problem: the first correctness criterion for MLL proof\nnets, called the “long trip criterion”, and present in\nGirard’s original paper, is exponential, as well as the ACC (Acyclic\nconnected) criterion of Danos and Regnier (1989) \nfound later on.\nNevertheless, there exists a much more efficient criterion, known as\nContractibility, due to Danos and Regnier, that has more recently been\nreformulated as the following elegant graph parsing criterion by\nGuerrini, Martini and Masini: a hypergraph is a proof net if and only\nif it reduces to the singleton node “net” via the\nfollowing graph reduction rules \n  \n\nPerforming this check naively can take quadratic time (each\napplication of a rule may require an entire lookup of the graph to\nfind the redex, and we need to perform as many steps as there are\nhyperlinks in the graph).\nLinear time algorithms have been give by Guerrini (2011) \nand by Murawski and Ong (2006). \nAnother style of correctness criterion for MLL proof nets is given by \nRetoré (2003) in which a quadratic\nalgorithm is given for MLL.\n \n\nOn proof nets, one can perform cut elimination in a particularly clean\nway: due to their parallel nature, cuts can be eliminated locally via\ntwo simplification rules: \n\nThese are actually computation rules over proof nets, and the\ncorrectness criteria allow to verify easily that any such rule\npreserves correctness, and as a consequence, the reduction of a proof net\nstill comes from a sequent calculus proof of the same sequent. \n\nHence, cut elimination in MLL proof nets can be performed in linear\ntime and gives a simple, elegant cut-elimination result for all of\nMLL. \n\nThe proof nets approach can be extended to larger subsets of linear\nlogic, but then it is less clear how to obtain the same elegant results\nas for MLL: the original system proposed in\n Girard 1987\n works for MELL, for example, by associating to the four exponential\nrules the following hypergraph constructions: \n\nWhile these constructions and the associated graph reductions bear\nstriking similarity with \\(\\lambda\\)-calculus with explicit substitutions,\nas first remarked by Di Cosmo & Kesner\n (1997),\n they are too similar to the corresponding sequent calculus rules: the\nparallelization effect so elegant for MLL does not properly carry on\nhere, and the graph reduction rules involve boxes and are not\nlocal. \n\nTo recover a satisfactory system, many proposals have been made,\nstarting from the one by Danos & Regnier\n (1995)\n but we want to mention here the very elegant\napproach by Guerrini, Martini and Masini\n (Guerrini et al. 2003),\n that neatly shows the connection between two level proof systems for\nmodal logic, proper proof nets for MELL, and optimal reduction in the\n\\(\\lambda\\)-calculus. \nA recent paper by Heijltjes and Houston (2016)\nhas shown that there can be no satisfactory notion of proof nets for MLL if \nunits are also allowed. \n \nIt is possible to provide a canonical treatment of additive\nconnectives, even with first-order quantification \n(Heijltjes et al. 2018). \nProof nets for formulas containing both multiplicative and\nadditive connectives have various technical presentations, none of\nwhich appears canonical and satisfactory. Their treatment in\nproof-net-like proof systems is currently a topic of active research.\nIn particular, see (Hughes and van Glabbeek 2005) and \n(Hughes and Heijltjes 2016).\n \n\nApproaching the semantics of linear logic is usually done along two\ndifferent paths. First, there are various semantic structures\navailable that can be used to map formulas to denotations in such\nstructures. That approach can be used to establish soundness and\ncompleteness for various fragments of linear logic. A more novel\nsemantic approach to linear logic involves giving semantics to proofs\ndirectly. We describe briefly these two approaches and provide some\nlinks to the literature. \n\nOne approach to attempting a sound and complete semantics for\nfragments of linear logic associates to a formula the set of all\ncontexts that can be used to prove that formula. Of course, such a\ncollection may need to be more abstract and to be given various\nclosure properties. The phase semantics of Girard\n (1987)\n provides one such semantics: some uses of such semantics have been\nmade in computer science to provide counterexamples and as a tool that\ncan help establish that a given concurrent system cannot evolve into\nanother with certain properties\n (Fages et al. 2001).\n Similarly,\nKripke-style semantics have been provided in\n Allwein & Dunn 1993\n and\n Hodas & Miller 1994.\n Quantales, certain kind of partially ordered algebraic structures,\nhave also been used to provide early semantic models for parts of\nlinear logic\n (Yetter 1990). \n\nIn the formulas-as-types analogy which is so popular and fruitful in\ntheoretical computer science, a logical system is put in\ncorrespondence with a typed computational device (like typed \\(\\lambda\\)-calculus), \nby associating to each proof of that formula a program having\nthat formula as a type. For example, a proof of the tautology\n\\(A \\Rightarrow A\\) corresponds to the program\nfun\\((x:A).x:A\\rightarrow A\\),\nthe identity function on objects of type \\(A\\). This is why, in\nconstructive logical systems (such as intuitionistic logic and arithmetic),\nand in linear logic, so much importance\nis attached to proofs, to the point that building and studying models\nof proofs gets so much more attention than building and studying\nmodels of provability: we are not satisfied to know that a formula is\nprovable, we really want to know the computational content of\nits proof. \n\nMany models of linear logic proofs have been proposed; we consider\nthat, to date, the simplest and most intuitive construction is those\nbased on the so-called “relational semantics” or\n“Kripke-style semantics”, where formulas are interpreted\nas multisets, one-sided sequents are interpreted as tuples of\nmultisets, and proofs are interpreted as relations over the\ninterpretation of sequents. If one wants to give a purely\nset-theoretic semantics, without resorting to multisets, it is\npossible to do it by means of coherence spaces, sets equipped with a\nspecial coherence relation, as originally shown by in\n Girard 1987.\n There are interesting\ncategory theoretical models of linear logic, such as the *-autonomous\ncategories\n (Barr 1991)\n and hypercoherences\n (Ehrhard 1993). \n\nAnother approach to the semantics of proofs is given by Girard’s\nGeometry of Interaction, that allows us to obtain a fully\nalgebraic characterization of proofs. To each proof net, one can\nassociate a partial permutation matrix \\(\\sigma\\) corresponding to the\ncut links, and a proper matrix \\(M\\) corresponding expressions built out of a \ncertain\ndynamic algebra, that describe the possible paths inside the proof\nnet. It is then possible to fully describe the proof net via the\nexecution formula \n\nwhich, in the MLL case, is an invariant of the normalization\nprocess. Some nice connection to results coming from data-flow theory\nhas been shown in some early work of Abramsky & Jagadeesan\n (1994). \nThe area of semantics that has developed around so-called game\nsemantics deserves special attention. The strong connection between\ngames and linear logic was pointed out quite early by A. Blass \n(1992).\nIn fact, there are two different traditions to connecting logic\nto games. In the tradition of dialog games dating back to\nLorenzen, one player attempts to prove a formula while a second player\nattempts to refute it. It is possible to provide MALL with such a\ndialog game that is completely symmetric for both the prover and the\nrefuter (Delande et al. 2010).\nIn another tradition, formulas are\ninterpreted as games, logical connectives as game constructors, and\nproofs as strategies that describe how a player reacts to opponent\nmoves. By imposing different restrictions on the rules of the game,\none can actually provide a precise semantics (technically, a\nfully abstract model) for various features of actual programming\nlanguages, hence the huge interest in this area over the past\nyears. See, for example, \n Abramsky & Jagadeesan 1994,\n Abramsky & Melliès 1999,\n and\n Hyland & Ong 2000.\n \nFor any given logic, it is useful to know whether or not there is an\neffective procedure to determine, for each sentence in the logic, if\nit is provable or not. A decidable logic—i.e., one for\nwhich there is an effective procedure for provability—is often\ndescribed by its\ncomplexity class, which characterizes how difficult it is\nto perform the decision procedure.\nExtensive research work has been dedicated to the study of the\ncomplexity and decidability issues for several fragments of\npropositional linear logic. It is known that \nNP, PSPACE, and EXPSPACE are complexity classes such that NP \\(\\subseteq\\)\nPSPACE \\(\\subseteq\\) EXPSPACE. Surprisingly, for those that may forget that\nthe novelty in linear logic lies in the way formulas are managed\nwithout the structural rules of contraction and weakening, \nthese results stay the same even if we focus\non the fragments of the logics where only the constants, and no\npropositional variables, are allowed (Kanovich 1994,\n Lincoln & Winkler 1994). Indeed, it is\npossible to encode arbitrary formulas into constant-only formulas\npreserving provability. \nMELL is a surprisingly expressive logic. For example, the\nreachability problem in Petri nets can be encoded into MELL (Gunter & Gehlot 1989) and that problem is\nequivalent to the reachability problem of vector addition systems with\nstates (VASS) (Reutenauer 1989).\nFurthermore, the decidability problem of MELL is equivalent to the\nreachability problem for branching VASS (de\nGroote et al. 2004) and the latter is known to have a\nnon-elementary lower bound (Lazic and Schmitz\n2015). Thus, if MELL turns out to be decidable it will be at\nleast TOWER-hard (Lazic and Schmitz 2015).\nA proof of the decidability of MELL has been given by Bimbó\n(2015) but a gap in that proof \nhas been reported in Straßburger (forthcoming).\n \nLinear logic with the unrestricted weakening rule added \n(also known as linear affine logic) is decidable\n(Kopylov 1995) and to be exponential \nspace hard (Urquhart 2000).\n \nA good overview of complexity results surrounding linear logic can\nbe found in\n Lincoln 1995. \n\nWhen intuitionistic logic was first proposed early in the last\ncentury, it was presented as a challenge to the way traditional\nmathematicians were supposed to do business. Uses of the excluded middle\nand of proof-by-contradiction were considered suspect and problematic,\nparticularly in the presence of infinity. As intuitionistic logic\nconcerns were developed into constructive mathematics, new constructive\napproaches have arisen to topics such as topology, algebra, and\nanalysis. Given that linear logic encompasses the dynamics of proof\n(algorithm) and resources, its primary impacts has been not in\ntraditional mathematics but in computer science. Before overviewing the\nnature of that impact, we outline the various ways in which logic more\ngenerally is used in computer science. \n\nLogic plays different roles in the specification of computations. We\ncan identify the following broad different approaches and note which\nroles have felt influences from linear logic. \n\nIn the computation-as-model approach, computations are\nencoded as mathematical structures and consist of such items as nodes,\ntransitions, and states. Logic is used in an external sense to make\nstatements about those structures. That is, computations are\nused as models for logical expressions. Intensional operators, such as\nthe modals of temporal and dynamic logics or the triples of Hoare\nlogic, are often employed to express propositions about the change in\nstate. This use of logic to represent and reason about computation is\nprobably the oldest and most broadly successful use of logic for\nrepresenting computation. This role for logic has felt little influence\nfrom linear logic. \n\nIn the computation-as-deduction approach, pieces of logic’s\nsyntax (such as formulas, terms, types, and proofs) are used directly\nas elements of the specified computation. In this more rarefied\nsetting, there are two rather different approaches to how computation\nis modeled, called the proof normalization approach and the\nproof search approach. \n\nWe outline below the significant impacts that linear logic has had on\nboth of these different settings. \n\nThe proof normalization approach views the state of a\ncomputation as a proof term and the process of computing as\nnormalization (known alternatively as \\(\\beta\\)-reduction or cut-elimination).\nFunctional programming can be explained using proof-normalization as\nits theoretical basis\n (Martin-Löf 1982)\n and has been used to justify the design of new functional\n programming languages, e.g.,\n Abramsky 1993.\n Linear logic provides this approach to computational specification\nwith new types, new declarative means for statically understanding how\nresources may be used in a computation, and provided an appealing\nmeans for formalizing the duality between a function and the\nenvironment that supplies it with arguments. \n\nAnother area where linear logic has been a powerful theoretical\ninstrument is that of optimal reduction. The problem of\nbuilding efficient (optimal) interpreters for the \\(\\lambda\\)-calculus, that\nstayed open for quite a long time after its original definition by J.J.\nLévy, was solved for the first time in \n Lamping 1990, \n via a sophisticated sharing graph implementation involving a quite\nimpressive amount of rules. Using ideas and intuition from linear\nlogic, many authors reconstructed Lamping’s solution, simplifying it\nand leading to a rich theory connected to that of the Geometry of\nInteraction. For further reading, a good reference\nis Asperti & Guerrini 1998.\n \n\nThe refinement of intuitionistic logic provided by linear logic and\nthe dualities of linear logic provided a setting in which one could\nview a function and its environment as similar entities that interact\ndually. For example, a function with the type \\(A \\limp B\\) can be\nmodeled as a process that consumes a value of type \\(A\\) from its\nenvironment and transforms it into a value of type \\(B\\). In linear\nlogic, this implication is equivalent to its contrapositive form: the\ntype \\(B^{\\bot} \\limp A^{\\bot}\\) can lead to interpreting the same\nfunction as a process that transforms a demand for a value of type\n\\(B\\) into a demand for a value of type \\(A\\) (notice that this does\nnot happen with functions of intuitionistic type since, for example,\ninput argument may be vacuous)\n (Curien 2003).\n The recent successes of using game semantics to model functional\ncomputation are similarly related to the dual treatment of function\nand environment (Abramsky and Jagadeesan 1994,\n Hyland & Ong 2000). \n\nFinally, we mention that in the area of encoding computation as proof\nnormalization, linear logic has been used to provide a type-based\ndescription of polytime recursive functions. For example, M.\n Hofmann\n (2003)\n introduced a \\(\\lambda\\)-calculus with\nmodal and linear types that extended the function algebra of\n Bellantoni & Cook 1992\n to higher types. Types based on linear logic have also been used\nwithin functional programs: see\n Guzman & Hudak 1990\n and\n Wadler 1991. \n\nThe proof search approach views the state of a computation\nas a sequent (a structured collection of formulas) and the process of\ncomputing as the process of searching for a proof of a sequent: the\nchanges that take place in sequents capture the dynamics of\ncomputation. \nWith this view of computation, we generally read\ninference rules bottom up, i.e., \nas a transformation of their conclusion into their premise(s). \nLogic programming can be explained using proof search as\nits theoretical basis, and linear logic provides this approach to\ncomputational specification with new combinators for building logic\nprograms, new means to capture rich dynamics, and new\ndeclarative approaches to specifying concurrent computations. (See\n Miller 2004\n for an overview of linear logic programming languages.) \n\nThe completeness of focusing proof system can be used to provide a\ndeclarative explanation of part of the operational semantics of logic\nprogramming within linear logic. Consider, for example, the subset\n\\(L\\) of formulas of linear logic that are built from only the\nconnectives \\(\\top\\), &, \\(\\limp , \\Rightarrow\\), and \\(\\forall\\). (Notice\nthat if one adds \\(\\bot\\) to this list, it is possible to encode all\nconnectives of linear logic.) It is possible to see that cut-free\nproof search in \\(L\\) can be defined into to phases. Given a\nsequent \\(\\Gamma\\); \\(\\Delta \\rightarrow G\\), where \\(\\Gamma\\) is a set of\nformulas (which can be contracted and weakened), \\(\\Delta\\) is multiset\nof formulas (which cannot be contracted nor weakened), and \\(G\\)\n(the “goal” formula) is a single formula (all\nfrom \\(L)\\), then proof search proceeds as follows. \n\nFormally, these various phases can be described using the following\ninference rules. Here, a new sequent arrow is introduced:\nthis arrow is labeled with the formula that is the result of a\nleft-introduction rule. Notice that the rule for left-introduction of\n\\(\\limp\\) requires splitting the \\(\\Delta\\) context\ninto two parts \\(\\Delta_1,\\Delta_2\\) (when reading\nthe rule bottom up). There are, of course, \\(2^n\\) such\nsplittings if that context has \\(n \\ge 0\\) distinct\nformulas.\nThe syntactic variable \\(A\\) in these inference rules ranges over\natomic formulas. \n\nLinear logic restricted to \\(L\\) can be viewed as a linear logic\nprogramming language. As a consequence, it can serve as a\nspecification language for computational systems, a role that is also\noccupied by, say, Petri nets, process calculi, \\(\\lambda\\)-calculus,\netc. Given that linear logic has a proof theory and various kinds of\nsemantics, broad avenues of reasoning about computations specified in\n\\(L\\) are provided by the meta-theory of linear logic. \n\nGiven that the sequent calculus for linear logic uses multisets of formulas,\nproof search can directly encode multiset rewriting. Since\nmany computations can naturally be seen as multiset rewriting, it has\nbeen possible to make numerous connections between linear logic and\nPetri nets\n (Gunter & Gehlot 1989),\n process calculi\n (Andreoli & Pareschi 1991,\n Kobayashi et al. 1999,\n Miller 1996),\n and security protocols\n (Cervesato et al. 1999,\n Miller 2003). \n\nThe exponentials \\(\\bang\\) and \\(\\quest\\) in linear\nlogic are less carved in the marble than the other\nconnectives. Indeed, if one uses traditional sequent calculus\npresentations, the exponentials are not canonical in the following sense: if\nyou introduce another copy of exponentials, say\n\\(\\bang'\\) and \\(\\quest'\\), with the same\nrules as the original ones, there is no way to prove that\n\\(\\bang\\) is equivalent to \\(\\bang'\\), and\n\\(\\quest\\) to \\(\\quest'\\), while for the other\nconnectives this is easily established. \nVarious applications of non-canonical exponentials can be\nfound in (Danos et. al., 1993; \nNigam & Miller, 2009). \nAlthough the decidability of MELL is currently being debated \n(Bimbó 2015,\nStraßburger forthcoming), \nextending MLL with three pairs of \\(\\bang\\) and\n\\(\\quest\\) yields a logic that is undecidable\n (Chaudhuri 2018). \nMartini and \nMasini 1995 describe a “2-sequent” \nproof system in which the exponentials are canonical. \nThe fact that cut-elimination can make proofs in classical and\nintuitionistic logic grow to enormous size can be analyzed in terms of the\napplication of the contraction rule in those proof systems. If proof systems\nintroduce restrictions on contraction, it is possible to design new\nlogics and proof systems for which cut-elimination has a much-reduced\ncomplexity. For example, elementary linear logic (ELL) is\nobtained by replacing the \\(\\bang\\) and \\(\\quest\\)\nintroduction by a single rule introducing \\(\\bang\\) and\n\\(\\quest\\) at the same time. As a consequence, ELL can encode\nall and only the Kalmar elementary functions (computable in time\nbounded by a tower of exponentials of fixed height) \n(Girard 1998, \nBaillot 2015). Still, other variations on the inference rules for the\nexponentials have been studied. For example, light linear\nlogic (Girard 1998) and soft linear\nlogic (Lafont 2004) both characterize\nfunctions computable in polynomial time: see also\n (Baillot & Terui 2004).\n \n\nWhile linear logic rejects the universal application of the two\nstructural rules of weakening and contraction, it allows the\nunrestricted use of the structural rule called exchange. A sequent\ncalculus that does not universally employ the exchange rule has\nsequents whose left and right contexts are lists: the order of formulas\nwithin context becomes an expressive element of the logic. In this\ncase, the multiplicative disjunction and conjunction can become\nnon-commutative. \n\nOne of the first logics that rejects all three structural rules of\nthe sequent calculus was given in \n Lambek 1958.\n While this logic contains two implications, it does not\ncontain a negation nor exponentials. Various recent papers have\nproposed extending linear logic to include non-commutative features\nand, at present, no proposal seems canonical. For a sampling of\nnon-commutative linear logics, see\n Yetter 1990,\n Abrusci 1991,\n Retoré 1997,\n Abrusci & Ruet 1999, and\n Guglielmi & Straßburger 2001. \nWhile the MALL logic is an expressive and novel logic, it is also\ndecidable and, thus, not capable of capturing the unbounded behaviors \nfound in, say, mathematics and computer science. As described above, \nthe addition of the exponentials ! and ? enriches MALL to full linear \nlogic and to a setting where unbounded behaviors can be captured. \nA second approach to extending MALL to capture unbounded behaviors \ninvolves the addition of\nthe least and greatest fixed point operators as logical connectives \ndirectly into MALL. In order to properly characterize fixed points \nas being either the least\nor the greatest, it is necessary for the inference rules for fixed\npoints to be\n“higher-order” in \nthe sense that they involve invariants. Such an extension to MALL \n(also with first-order\nquantification and term equality) has been developed by Baelde \n(Baelde & Miller, \n2007; \nBaelde 2012) and has been used to \nprovide a proof-theoretic foundation for model checking \n(Heath & Miller 2018).\n","contact.mail":"dale.miller@inria.fr","contact.domain":"inria.fr"}]
