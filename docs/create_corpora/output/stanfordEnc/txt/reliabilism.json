[{"date.published":"2008-04-21","date.changed":"2021-05-21","url":"https://plato.stanford.edu/entries/reliabilism/","author1":"Alvin Goldman","author1.info":"http://philosophy.rutgers.edu/index.php?option=com_content&task=view&id=102&Itemid=210","author2.info":"http://www.bobbeddor.com/","entry":"reliabilism","body.text":"\n\n\nOne of the main goals of epistemologists is to provide a substantive\nand explanatory account of the conditions under which a belief has\nsome desirable epistemic status (typically, justification or\nknowledge). According to the reliabilist approach to epistemology, any\nadequate account will need to mention the reliability of the process\nresponsible for the belief, or truth-conducive considerations more\ngenerally. Historically, one major motivation for\nreliabilism—and one source of its enduring interest—is its\nnaturalistic potential. According to reliabilists, epistemic\nproperties can be explained in terms of reliability, which in turn can\nbe understood without reference to any unreduced epistemic notions,\nsuch as evidence or knowledge.\n\n\nThis article begins by surveying some of the main forms of\nreliabilism, concentrating on process reliabilism as a theory of\njustification. It proceeds to review some of the main objections to\nreliabilism, and some of the responses that have been offered on the\nreliabilist’s behalf. After canvassing some recent developments\nin reliabilist epistemology, the article concludes by considering\nvarious cousins and spin-offs of reliabilist epistemology, including\nvirtue reliabilism and various evidentialist-reliabilist hybrids.\n\nIn the 1960s, a wide range of epistemologists were absorbed by the\nquestion: what does it take for a belief to amount to\nknowledge? It was generally agreed that for a person,\nS, to know some proposition p, at least three\nconditions must be met. First, p must be true. Second, S\nmust believe p. And third, S must be justified\nin believing p. Thus, knowledge requires justified true\nbelief. But does the satisfaction of these three conditions\nsuffice to entail that S knows p?\nUnfortunately, as Edmund Gettier (1963) showed with several convincing\ncases, justified true belief doesn’t guarantee knowledge. \nSome subsequent attempts to explicate knowledge had broadly\n“reliabilist” features, although they did not use this\nterminology. According to “relevant alternatives\ntheories”, a subject is said to know p provided that they\ncan “rule out” relevant alternatives where p does\nnot obtain (Dretske 1970; Goldman 1976; Stine 1976; Lewis 1996).\nAccording to “truth-tracking theories”, a subject knows\np provided their beliefs “track the truth” of\np across modal space. Truth-tracking theorists typically cash\nthis out in terms of subjunctive conditionals, such as\n“Sensitivity”: If p had been false, S\nwouldn’t have believed p (Nozick 1981), or\n“Safety”: If S were to believe p, p\nwould be true (Sosa 1999; Williamson 2000; Pritchard 2005). These\nviews are united by the idea that knowledge requires some form of\nreliability. (See the entry on the\n analysis of knowledge.) \nMeanwhile, many epistemologists have turned their attention to a\nrelated epistemic concept: the concept of (epistemic)\njustification. Justified belief is widely regarded as a\nnecessary—though insufficient—condition for\nknowledge. Hence, justification must be regarded as a core concept for\nepistemologists to explore and elucidate. \nHowever, justification also proves to be a very elusive concept. In\n1979 Alvin Goldman published a paper entitled “What Is Justified\nBelief?”, which departed from several well-entrenched positions\non the nature of epistemic justification. Years later, a number of\nepistemologists recognized this paper as marking a significant turning\npoint, or “paradigm shift”, in epistemology. Michael\nWilliams (2016: 3) called it “the Reliabilist Revolution”.\nThis turning point has given rise to a lively debate about the kinds\nof factors that determine the epistemic status of a person’s\nbeliefs or credences. \nThe key idea behind Goldman’s reliabilist approach is that the\njustifiedness of a belief depends on the mental history of\nthe subject’s belief. In particular, it depends on the\nreliability of the process(es) which cause the belief in\nquestion. Somewhat similar ideas (or segments thereof) have been\nadvanced by a number of predecessors, often focusing on knowledge\nrather than justification. Frank Ramsey (1931) wrote that a belief\nqualifies as knowledge if it is true, certain, and obtained\nby a reliable process. He did not, however, provide a detailed defense\nof this thesis. Peter Unger (1968) proposed that S knows that\np just in case “it is not at all accidental” that\nS is right about its being the case that p. David\nArmstrong (1973) offered an analysis of non-inferential knowledge that\nexplicitly used the term “reliable”. He drew an analogy\nbetween a thermometer that reliably indicates the temperature and a\nbelief that reliably indicates the truth. All of these\nwriters seemed to endorse some variant of reliabilism,\nalthough typically there were minor or major differences from the\nversion we shall focus on here. For example, Armstrong promoted an\n“indicator” variant of reliabilism rather than a\n“psychological process” variant. And Unger presented\n“non-accidentality” rather than\n“truth-conduciveness” as the central determinant of\njustifiedness. Clearly, however, there is a great deal of convergence\nin these views. So, contemporary defenders of epistemic reliabilism\nhave grounds for optimism that they are laboring in promising terrain.\nThe nitty-gritty details, however, still need additional work, as we\nshall see in the body of this entry. We turn now to some of the\nprincipal details of Goldman’s form of reliabilism for\njustification (Goldman, 1979, 1986). \nGoldman began by proposing some desiderata on any account of\njustification. First, theories of justification should specify\nconditions for justified belief that do not invoke the concept of\njustification itself, or any other epistemically normative concepts\nsuch as reasonability or rationality. The aim is to provide a\n“reductive” account of justification that does not appeal\nexplicitly or implicitly to any notions that entail justification or\nother members of that family. There is bite in this requirement. For\nexample, it might preclude an analysis of justified belief in terms of\n“evidence”, unless evidence can itself be characterized in\nnon-epistemic terms. What kinds of terms or properties, then, are\nappropriate for constructing an account of justification? Permissible\nconcepts or properties would include doxastic ones, such as belief,\ndisbelief, suspension of judgment, and any other purely psychological\nconcepts, such as ones that refer to perceptual experience or memory.\nGiven the assumption that truth and falsity are non-epistemic notions,\nthey would also be perfectly legitimate for use in analyzing\njustifiedness. Another admissible element in an account of\njustifiedness is the causal relation. \nProceeding under these constraints, Goldman was led to the\n“reliable process” theory as follows. (Note that the main\nconcept to be tackled here is doxastic justifiedness rather\nthan propositional justifiedness. That is, it focuses on what\nit takes for a belief to be justified rather than what it\ntakes for someone to have grounds for forming such a belief.)\nFirst, examples were adduced to show that the justifiedness of\nparticular beliefs depends on how those beliefs are caused,\nor causally sustained, in the mind of the thinker. Suppose\nArthur justifiedly believes a conjunction of propositions, \\(q \\amp\nr\\), from which proposition \\(p\\) follows logically. Further suppose\nthat, soon after forming his belief in this conjunction, Arthur also\nforms a belief in \\(p\\). Does it follow from this that Arthur’s\nbelief in \\(p\\) is justified? No. Although Arthur believes \\(q \\amp\nr\\), this conjunction may not have played any causal role in his\ncoming to believe \\(p\\). He may have formed his belief in \\(p\\) purely\nby wishful thinking. Perhaps he hoped \\(p\\) would be true,\nand therefore (somehow) came to believe it. Alternatively, suppose\nArthur employed confused reasoning that began with \\(q \\amp r\\), and\nserendipitously led to \\(p\\). In neither case is his resulting belief\nin \\(p\\) justified. This shows that a necessary condition for a belief\nto be justified is that it be produced or generated\nin a suitable way. Of course, this immediately raises the\nquestion: which kinds of belief-forming processes are suitable and\nwhich are defective or unsuitable? \nOne feature that is shared by wishful thinking and confused reasoning\nis doxastic unreliability. These belief-forming methods commonly\ngenerate beliefs that are false rather than true. By contrast, what\ntypes of belief-forming processes commonly confer justification? They\ninclude standard perceptual processes, remembering, good reasoning,\nand introspection. What is shared by these processes? What they share\nis reliability: most of the beliefs they produce are true. (This\nformulation will be slightly refined later.) Thus, the central\nproposal made in “What Is Justified Belief” is that the\njustifiedness or unjustifiedness of a belief is determined by the\nreliability or unreliability of the process or processes that cause\nit. Reliability can here be understood either in a frequency\nsense (pertaining to what occurs in the actual world) or in a\npropensity sense (pertaining both to the actual-world and\nother possible worlds.). A belief earns the status of\n“justified” if it is produced by a process (or series of\nprocesses) that has a high truth-ratio. Precisely how high a\ntruth-ratio must be in order to confer justifiedness is left vague,\njust as the concept of justification itself is vague. The truth-ratio\nthreshold need not be as high as 1.0, but it must surely be greater\n(presumably, quite a lot greater) than .50. \nA number of conclusions were drawn from these main points, and\nrefinements were added. One consequence was that process reliabilism\nis a historical type of theory. For example, a reliable inferential\nprocess confers justification on a new belief only if the input\nbeliefs (premises) were themselves justified. How could the\njustifiedness of these input beliefs have arisen? Presumably, their\njustifiedness arose because they were produced by earlier applications\nof reliable processes. Such a chain of processes must ultimately\noriginate from one or more reliable processes that themselves had no\ndoxastic inputs. Perceptual inputs are good candidates for such\nprocesses. So, on this approach, justifiedness is often a product of a\nhistory of personal cognitive processes. The historical framework of\nsuch a process theory contrasts sharply with more traditional\nepistemological frameworks, such as coherentism and (certain versions\nof) evidentialism. According to these more traditional theories,\ncausal and historical relations play no role in determining\njustifiedness. (Though see, e.g., Goldberg 2012 and Fleisher 2019 for\nviews that combine elements of coherentism and reliabilism; for views\nthat integrate evidentialism and reliabilism, see\n §4.2\n below.) More generally, reliabilism marks an important break with\n“current time-slice” approaches, according to which the\nepistemic status of a belief at time t depends entirely on the\nsubject’s mental states at t. \nThese fundamental ideas were spelled out by Goldman in “What Is\nJustified Belief?” (1979), in a series of principles including\nbase-clause principles and recursive-clause principles. The initial\none was (1): \nThis principle would fit cases of perceptually caused beliefs and\nother beliefs that make no use of prior doxastic states (as inputs).\nBut inference-generated beliefs require a different principle. When a\nnew belief results from an inference, its justificational status\ndepends not only on the properties of the inferential\nprocess, but also on whether the input beliefs themselves\nwere justified. To accommodate this, a slightly more complex principle\nwas introduced: \nBy philosophical standards, these are not terribly complex principles.\nThus, process reliabilism is a comparatively simple and\nstraightforward theory. Such simplicity has usually been viewed as a\nvirtue of the approach. Of course, matters are more complicated than\nthe foregoing principles convey. We will survey some potential\ncomplications and refinements of this theory below. \nIs it true, as process reliabilism claims, that beliefs formed by\nreliable processes are (intuitively) considered justified and that\nbeliefs formed by unreliable processes are (intuitively) considered\nunjustified? Here are some examples of processes that frequently lead\nto false beliefs: wishful thinking, reliance on emotional attachment,\nmere hunch or guesswork, and hasty generalization. Beliefs produced by\nsuch processes would all be considered, intuitively, unjustified. So\nthere is a high correlation between process-unreliability and\nunjustifiedness. Similarly, here are some examples of processes that\ncommonly lead to true beliefs: standard perceptual processes, good\nreasoning, and introspection. Here again there is a strong correlation\nbetween process-reliability and justified belief. \nWe should notice, of course, that justifiedness is not a purely\ncategorial concept. We can and do regard certain beliefs as more\ncertain and more justified than others. Furthermore, our intuitions of\ncomparative justifiedness go along with our beliefs about the\ncomparative reliability of the belief-causing processes (Goldman 1979;\n1986: 103–4; 1992; 2008). This comports well with process\nreliabilism. \nBy now, a number of problems have been raised for process reliabilism.\nHere we review some of the main challenges, focusing on the three that\nhave received the most attention in the literature: the clairvoyance\nproblem\n (§2.1),\n the new evil demon problem\n (§2.2),\n and the generality problem\n (§2.3).\n Afterwards, we will briefly survey some challenges of a more recent\nvintage\n (§2.4). \nOne early challenge to reliabilist theories of justification was\nadvanced by Laurence BonJour (1980), concerning a hypothetical\nclairvoyant named “Norman”. Norman has a perfectly\nreliable clairvoyance faculty. But he has no evidence or reasons for\nor against the general possibility of a clairvoyant power or for or\nagainst his possessing such a power. One day Norman’s\nclairvoyance faculty generates in him a belief that the President is\ncurrently in New York City, but with no accompanying perception-like\nexperience, just the bare belief itself. Intuitively, says BonJour,\nNorman isn’t justified in holding this belief. Yet process\nreliabilism seems to imply otherwise. Since Norman’s clairvoyant\npower has a high truth ratio, Norman’s belief about the\nPresident must be justified. So reliabilism seems to get this wrong.\n(Similar examples were offered by Keith Lehrer (1990) and Alvin\nPlantinga (1993).) \nReliabilists have offered various responses to this challenge,\nincluding: \nOne response is to opt for a variant of simple process reliabilism,\nwhich goes by the names of “two-stage reliabilism”\n(Goldman 1992) or “approved-list reliabilism” (Fricker\n2016). Rather than directly giving an account of what justification\nis, this approach seeks to give a theory of how ordinary people make\njustification attributions. Approved-list reliabilists offer the\nfollowing conjecture about how this works. In a preliminary stage,\nattributors form opinions about the reliability or unreliability of\nassorted belief-forming processes, using observation and/or inference\nto draw conclusions about the track-records of these processes in the\nactual world. They thereby construct mental lists of reliable and\nunreliable processes: lists of approved and disapproved processes\n(respectively). In the second stage, they deploy these lists to make\njudgments about particular beliefs (actual or hypothetical). If\nsomebody’s belief was caused by a process that is on their\napproved list—or strongly resembles one on their approved\nlist—they consider it justified. If it is caused by a process on\ntheir disapproved list, it is classed as unjustified. \nHow would approved-list reliabilism explain intuitive judgments in the\nclairvoyance case? Presumably, an ordinary attributor would not have a\nclairvoyance process on either of her lists. But she might well have\nprocesses like extra-sensory-perception or\ntelekinesis on her list, especially her disapproved list. The\nprocess or faculty that Norman uses to arrive at his belief about the\nPresident sounds very similar to one of those obscure and suspect\npowers. Hence, Norman’s belief is intuitively classified as\nunjustified. This is despite the fact that—as potential\nattributors are told—Norman’s clairvoyance process is\nthoroughly reliable. \nApproved list reliabilism is a theory of the factors that influence\nour attributions of epistemic justification. It is thus\nnaturally construed as an attributor theory—a theory of\nthe conditions under which a justification attribution (that is, a\nsentence of the form, “S is justified in believing\np”) is judged to be true or false. In this regard, it\nparallels attributor theories of knowledge (e.g., DeRose 1992). There\nare different ways of developing an approved list attributor theory\nmore precisely. For instance, a contextualist implementation might\nhold that a justification attribution is true if and only if the\nsubject’s belief-forming process belongs to the speaker’s\napproved list. Alternatively, one could adopt an assessor-relativist\nimplementation, according to which the truth-conditions of\njustification attributions are relativized to contexts of assessment\n(cf. MacFarlane 2005). An assessor-relativist version of the approved\nlist might hold that a justification attribution is true at a context\nof assessment if and only if the subject’s belief-forming\nprocess belongs to the assessor’s approved list. \nA different response to the clairvoyance problem is to concede that\nbeing the result of a reliable process is not sufficient for a belief\nto be prima facie justified. Rather, some further condition\nmust be met. One version of this approach has been developed by Jack\nLyons (2009, 2011) who argues that in order for a non-inferential\nbelief to be justified, it must be the result of a “primal\nsystem”. Drawing on research in cognitive science, Lyons\nproposes that a primal system is any cognitive system that meets two\nconditions: (i) it is “inferentially opaque”—that\nis, its outputs are not the result of an introspectively accessible\ntrain of reasoning, (ii) it develops as a result of a combination of\nlearning and innate constraints (2009: 144). For Lyons, our perceptual\nsystems are paradigmatic examples of such primal systems. \nHow does this help with the clairvoyance objection? According to\nLyons, BonJour’s presentation of the Norman example invites the\nassumption that Norman’s clairvoyance was the result of some\nrecent development—e.g., “a recent encounter with\nradioactive waste” or a “neurosurgical\nprank”—not the result of some combination of learning and\ninnate constraints (2009: 118–119). Given this assumption,\nNorman’s clairvoyance-based belief is not the result of a primal\nsystem, hence it is not prima facie justified. \nA third possible response to the clairvoyance objection—which\ninvolves combining reliabilism with evidentialist elements—will\nbe discussed in\n §4.2\n below. \nA second problem for process reliabilism is the “new evil-demon\nproblem” (Cohen 1984; Pollock 1984; Feldman 1985; Foley 1985).\nImagine a world where an evil demon creates non-veridical perceptions\nof physical objects in everybody’s minds. All of these\nperceptions are qualitatively identical to ours, but are false in the\nworld in question. Hence, their perceptual belief-forming processes\n(as judged by the facts in that world) are unreliable; and their\nbeliefs so caused are unjustified. But since their perceptual\nexperiences—hence evidence—are qualitatively identical to\nours, shouldn’t those beliefs in the demon world be\njustified? \nAs with the clairvoyance objection, one response is to move from\nsimple reliabilism to approved list reliabilism (see\n §2.1\n above). As before, approved-list reliabilists will maintain that a\npotential attributor constructs lists of belief-forming processes, one\nfor approved process types and one for disapproved types. Perceptual\nprocesses (of various sorts) would be on the approved list. Since the\npeople in the evil-demon case use perceptual processes that would be\non the approved list, an attributor would consider their resulting\nbeliefs justified—even though s/he is told that the perceptual\nprocesses in the evil-demon world are unreliable. \nA number of philosophers have explored related ideas for solving the\nNew Evil Demon Problem. One similar strategy starts by distinguishing\ntwo different ways a process can be reliable. Suppose we inhabit the\nactual world (@), and we’re evaluating a subject S who\ninhabits some other world \\(w_s\\). Then there are two different things\nwe could mean when we say that S’s belief-forming process\nis reliable: we could mean that it’s reliable relative to @, or\nwe could mean that it’s reliable relative to \\(w_s\\) (Sosa 1993,\n2001). Comesaña (2002) uses this distinction to provide a\nsolution to the new evil demon problem cast in the framework of\ntwo-dimensional semantics (Stalnaker 1999). On Comesaña’s\nproposal, the sentence, “S is justified in believing\np” has two readings: (i) that S’s\nbelief-forming process is reliable relative to @, (ii) that\nS’s belief-forming process is reliable relative to\n\\(w_s\\). If \\(w_s\\) is a demon world, then reading (i) will be true,\nbut reading (ii) is false. While Comesaña’s use of\ntwo-dimensional semantics has drawn criticism (Ball &\nBlome-Tillman 2013), the basic strategy of solving the New Evil Demon\nproblem by appealing to two types of reliability remains popular. For\ndiscussion of a related approach, see the discussion of normality\nreliabilism in\n §3.1  below. \nThe foregoing responses seek to accommodate the claim that the person\nin the demon world has justified beliefs (call this the “New\nEvil Demon Claim”). Another response is to reject this claim.\nOne way of motivating the New Evil Demon Claim is by appealing to the\npremise that the person in the new evil demon scenario has the very\nsame evidence that we do at the actual world. However, some\nphilosophers reject this premise in favor of an externalist conception\nof evidence. For example, Williamson (2000: ch. 9) suggests that an\nagent’s evidence is just their knowledge. Since the victim of an\nevil demon knows less than we do, it follows that they have less\nevidence than we do. As Schellenberg (2016) emphasizes, this sort of\nview is compatible with claiming that there is some evidence\nthat both we and the demon victim have in common. It’s just that\nthere is further body of evidence that we possess but the demon victim\nlacks. This sort of responses raises larger questions about what\nreliabilists should say about the nature of evidence; for further\ndiscussion, see\n §4.2\n below. \nPhilosophers who go this route typically emphasize that the beliefs of\nthe person at the demon world have some positive status, even if this\nstatus falls short of justification. For example, Lyons (2013) points\nout that the inferential beliefs of the demon’s victim are\nformed by conditionally reliable processes, which is an epistemic good\nin its own right. Other philosophers have claimed that the beliefs of\nthe demon’s victim are blameless or excusable, even though they\nare not justified (e.g., Pritchard 2012a). This issue is closely\nrelated to a growing recent literature on the relationship between\nepistemic justification and epistemic blamelessness (see, e.g., Kelp\n& Simon 2017; Brown 2018; D. Greco forthcoming; Williamson\nforthcoming). \nPerhaps the most widely discussed problem for process reliabilism is\nthe generality problem. Originally anticipated by Goldman in\n“What Is Justified Belief?”, it has been pressed more\nsystematically by Feldman (1985) and Conee and Feldman (1998). Any\nparticular belief is the product of a token causal process in the\nsubject’s mind/brain, which occurs at a particular time and\nplace. Such a process token can be “typed”, however, in\nmany broader or narrower ways. Each type will have its own associated\nlevel of reliability, often distinct from the levels of reliability of\nother types it instantiates. Which repeatable type should be selected\nfor purposes of assigning a reliability number to the process token?\nIf no (unique) type can be selected, what establishes the\njustificatory status of the resulting belief? \nConsider a concrete example (Conee & Feldman 1998): Smith sees a\nmaple tree outside his window one sunny afternoon and forms the belief\nthat there is a maple tree near his house. How should we type his\nbelief-forming process? Is the relevant type vision? Or\nperhaps something more fine-grained, such as visual experience of\na maple tree on a sunny afternoon? Or is it something more\ncoarse-grained, such as perception? The worry is that\nSmith’s token belief-forming process seems to instantiate all\nthese process types (and many more). So singling out any single one of\nthem as the “right” way of typing the process seems\narbitrary. \nReliabilists have proposed various strategies for dealing with the\ngenerality problem. Some of the main responses include: \nNot every way of describing a belief-forming process carves\npsychological reality at its joints. Consider, for example, the\nprocess type, forming a perceptual belief while wearing green\nsocks. Intuitively, this is an “inappropriate” or\n“irrelevant” way of describing Smith’s\nbelief-forming process. But why is it inappropriate? According to\npsychological approaches, it is inappropriate because it mentions\nfeatures of Smith’s circumstances that play no causal role in\nthe psychological processes responsible for his belief. \nIn their 1998 discussion of the generality problem, Conee and Feldman\nacknowledge that turning to psychology will help winnow down the\nnumber of eligible process types. But they express skepticism that it\nwill always yield a unique process type. Why won’t there be\nmultiple psychologically “real” process types responsible\nfor a given belief token? Subsequent developments of the psychological\napproach have tried to address this worry. For example, Beebe (2004)\nproposes that the relevant process type will always be an\ninformation-processing procedure or algorithm. Of course, there will\noften be indefinitely many types of this kind, of varying reliability.\nTo pick out the appropriate type, Beebe offers the following\ninstructions. Let A be the broadest such type. Choose a\npartition that is the broadest objectively homogeneous subclass of\nA within which the token process falls, where a class is\nobjectively homogeneous if no statistically relevant partition of it\ncan be effected. Beebe’s proposal has been challenged by Dutant\nand Olsson (2013), who argue that it faces a dilemma: either it does\nnot always yield a unique process type or it leads to trivialization\nby collapsing reliability into truth. For a more recent variant of\nBeebe’s solution, aimed at addressing Dutant and Olsson’s\nconcerns, see Kampa (2018). \nPerhaps the most fully developed version of a psychological approach\nto the generality problem comes from Lyons (2019). Lyons agrees with\nBeebe that the relevant psychological process types are\ninformation-processing algorithms. But Lyons additionally suggests\nthat these algorithms need to be relativized to parameters,\nunderstood as psychological variables that affect processing in a\nlaw-like way. For example, lighting conditions are a\nparameter that affects the speed and accuracy of visual information\nprocessing. As Lyons develops this view, the appropriate process type\nfor a given belief token B is provided by the complete\nalgorithmic specification of every psychological process that is\ncausally relevant to B, along with the parameter values for all\nof these processes. As Lyons notes, one upshot of this approach is\nthat the relevant process types will typically be very fine-grained.\nSmith’s belief-forming process type will not be vision,\nbut something more like: visual recognition of objects based on\nretinal stimulus of sort S, in lighting conditions C,\nwith attention distributed in manner M. \nA different approach to the generality problem is to insist that a\nversion of the problem arises for any adequate epistemology, not just\nreliabilists. A version of this “parrying response” has\nbeen developed by Juan Comesaña (2006), who argues that every\naccount of doxastic justification needs to appeal to the basing\nrelation. This is true even of evidentialist accounts: after all,\nevidentialists maintain that in order for a belief B to be\ndoxastically justified, B needs to be based on a body of\nevidence that supports B. (More on evidentialism in\n §4.2\n below.) But, Comesaña argues, any attempt to characterize the\nbasing relation will run into the generality problem, or something\nvery similar to it. Moreover, Comesaña contends, if\nevidentialists are willing to simply take for granted some notion of\nbasing in their theory, then there is no reason why reliabilists\ncannot follow suit, and deploy the basing relation in their solution\nto the generality problem. \nA rather different parrying response has been defended by Michael\nBishop (2010), who argues that the problem will arise for any theory\nthat allows for the possibility of “reflective\njustification”—that is, having a belief B that is\njustified on the basis of one’s knowledge that one formed\nB via a reliable form of reasoning. For further discussion, see\nMatheson (2015) and Tolly (2017). \nBoth Comesaña and Bishop focus on the idea that all\nepistemologists face a version of the generality problem. A\nrelated but distinct idea is to insist that versions of the generality\nproblem crop up everywhere, not just in epistemology. This response\nhas been developed recently by Goldman (forthcoming), who points out\nthat we regularly evaluate the reliability of all sorts of processes,\nnot all of them cognitive. Goldman illustrates with the example of\nGeraldine, who enjoys shooting hoops at her local gym.\nGeraldine’s performance is a function of many factors, including\nhow she focuses her eyes on the target hoop, how she grips the ball,\nhow she selects an angle to hit the backboard, etc. Now consider\nGeraldine’s friend, Henry, who watches as Geraldine consistently\nsinks more than 80% of her shots, using roughly the technique each\ntime. Henry may not be able to provide a detailed specification of\nGeraldine’s hoop-shooting process. Nonetheless, it seems he is\nin a position to conclude that Geraldine uses some process\ntype that is responsible for her frequent attainment of her athletic\ngoal, and that this process is fairly reliable. \nGoldman (forthcoming) argues that these considerations carry two\nlessons. First, they show that the generality problem is very general,\nsince some version of it arises in non-epistemic contexts. Second,\nGoldman takes these considerations to cast doubt on the common\nassumption—voiced explicitly by Conee and Feldman (1998:\n2–3)—that an adequate solution to the generality problem\nwill need to specify a unique process type responsible for any and\nevery token belief. According to Goldman, an evaluator can correctly\n(and justifiably) describe a process as reliable, without being able\nto specify in any detail the sort of process type at issue. \nYet another strategy is to switch tack and inquire into how ordinary\npeople type belief-forming processes. Suppose we ask a person on the\nstreet, “How did Smith form his belief?” Chances are,\nthey’ll answer “vision”, not “visual\nexperience of a maple tree on a Tuesday afternoon while\nwearing…” Inspired by this observation, common sense\napproaches seek to solve the generality problem in two steps. Step\nOne: develop a psychological theory of how ordinary people type\nbelief-forming processes. Step Two: Use these “common\nsense” typing methods to winnow down the range of candidate\nprocess types. \nA version of this approach has been elaborated by Erik Olsson (2016),\nwho appeals to a well-supported psychological theory about\nconceptualization called basic-level theory, developed by\nEleanor Rosch in the 1970s (Rosch et al. 1976). Rosch and her\ncollaborators studied the deployment of taxonomically related concepts\nlike “animal”, “dog”, and\n“labrador”. In such a taxonomy, one term is a\nsuperordinate concept (“animal”), another is an\nintermediate-level concept (“dog”), and a third is a\nsubordinate concept (“labrador”). It turns out that\nintermediate-level concepts are overwhelmingly preferred in free\nnaming tasks (e.g., “What would you call this?”). For\nexample, in one study Rosch et al. found that, out of 540 responses,\n530 to 533 converged on the same intermediate-level word for naming a\nphysical object. Olsson suggests that ordinary people might similarly\ntend to converge on an intermediate-level concept when typing\nbelief-forming processes. This conjecture has been empirically\nsupported in work by Jönsson (2013). Jönsson showed subjects\nclips in which characters arrived at various conclusions, and then\nasked the subjects to specify how the characters arrived at their\nbeliefs. Subjects converged on the choice of verbs describing the\nbelief-formation processes, even without linguistic cues to guide the\nprocess-typing task. Jönsson also found a correlation between\nsubjects’ estimates of the reliability of the characters’\nbelief-forming processes and subjects’ judgments about whether\nthe characters were justified in holding the beliefs in question. Thus\nthere is some evidence that folk psychological propensities lead us to\nconverge on belief-typing tasks, and that our reliability assessments\ntrack our justification judgments. \nIn addition to these three main objections, a number of further\nchallenges have been raised for reliabilism, including the three that\nfollow. \nConsider the following case, due to Vogel (2000): Roxanne is a driver\nwho believes whatever her gas gauge says about the state of her fuel\ntank, although she has no antecedent reasons to believe it is\nreliable. So Roxanne often looks at the gauge and arrives at\nconjunctive beliefs like the following: On this occasion the gauge\nreads “Full” & the tank is full. Now, the\nperceptual process by which she arrives at the belief that the gauge\nreads “Full” is reliable, and so is the process by which\nshe arrives at the belief that the tank is full (given that the gauge\nfunctions reliably). According to reliabilism, therefore, her belief\nin the indicated conjunction should be justified. Now Roxanne deduces\nthe proposition, On this occasion, the gauge is reporting\naccurately. From multiple instances of this reasoning, she\ninduces the further conclusion: The gauge is generally\nreliable. Finally, with a little more deduction she concludes she\nis justified in believing that her gas tank is full. Since\ndeduction and induction are reliable processes, Roxanne must also be\njustified in believing that her gas gauge is full. But is this verdict\nplausible? Definitely not, says Vogel, because such bootstrapping\namounts to a vicious form of epistemic circularity. \nIn response to this problem, we should start by noting that this\nproblem is not specific to reliabilism (Cohen 2002). Indeed, the\nproblem arises for all theories that allow for “basic\njustification”—that is, justification that is obtained via\nsome process or method X without antecedent justification for\nbelieving that X is reliable. As van Cleve (2003) forcefully\nargues, theories that do not allow for basic justification seem to\nlead to wide-ranging skepticism. \nIf we wish to allow for basic justification, can we still give a\nprincipled explanation of why some forms of bootstrapping seem\nillegitimate (for example, the case of Roxanne)? This is an area of\nactive research. One suggestion is that illegitimate forms of\nbootstrapping involve No Lose Investigations. Roughly, a No\nLose Investigation into a hypothesis \\(h\\) is an investigation that\ncould never, in principle, count against \\(h\\). (For suggestions along\nthese lines, see Kornblith 2009; Titelbaum 2010; Douven & Kelp\n2013.) Another suggestion is that illegitimate forms of bootstrapping\nall involve epistemic feedback (Weisberg 2010). Suppose an\nagent believes premises \\(p_1\\) … \\(p_n\\) from which she infers\nlemmas \\(l_1\\) … \\(l_n\\), from which she in turn infers a\nconclusion \\(c\\). Epistemic feedback is present when the probability\nof \\(c\\) conditional on \\(l_1\\) … \\(l_n\\) is greater than the\nprobability of \\(c\\) conditional on \\(p_1\\) … \\(p_n\\).\nRoxanne’s case can be understood in these terms. She first\nbelieves various premises about the gas gauge readings (e.g., The\ngas gauge read full at time \\(t\\); the gauge reads half-empty at\n\\(t^*\\)). She then infers various lemmas about the state of the\ngas tank (e.g., The tank was full at \\(t\\); the tank was\nhalf-empty at \\(t^*\\)). Finally, by conjoining these premises with\nthese lemmas, she comes to believe the conclusion: The gas tank is\nreliable. The probability of this conclusion conditional on just\nthe lemmas (that is, the beliefs about the state of the gas tank) is\nhigher than the probability of the conclusion conditional on the\npremises (that is, the gas gauge readings). Perhaps by imposing a ban\non either No Lose Investigations or epistemic feedback (or both), we\ncan account for the intuition about Roxanne, while still allowing for\nbasic justification. (For an overview of various responses to the\nbootstrapping problem, see Weisberg 2012.) \nAnother challenge for reliabilism comes from the phenomenon of\nepistemic defeat. Consider a case where an agent reliably forms a\nbelief that \\(p\\) at some initial time, and later receives some\nevidence (perhaps misleading evidence) indicating that \\(p\\) is false.\nFor example, suppose Alice looks at a red vase in good lighting\nconditions, and forms the belief that the vase is red. A friend comes\nalong and tells her that she is actually looking at a white vase\nilluminated by red lights. It seems that the receipt of this testimony\nrenders her belief unjustified, even though it was originally formed\nvia a reliable process. Can reliabilists accommodate this verdict? \nIn “What is Justified Belief?”, Goldman acknowledged this\nsort of problem, and suggested adding a “No Defeaters”\ncondition to the theory of epistemic justification. There, he\nelucidated an account of defeat in counterfactual terms. Roughly, your\nbelief B is defeated provided there is some reliable (or\nconditionally reliable) process X available to you such that,\nif you were you use X, you would no longer hold B. On\nthis view, Alice’s belief is defeated because if she were to use\nthe process believing her friend’s testimony, she would\nnot have believed B. However, this account of defeat has been\nsubject to various challenges. For example, Beddor (2015) argues that\nit commits a version of the “counterfactual fallacy”,\nrendering it susceptible to counterexamples. And both Lyons (2009:\n124) and Beddor (2021) point out that it has trouble accommodating\ncases where one defeater is defeated by another. \nBut even if we reject an account of defeat along these lines, the\nreliabilist may have other options for dealing with the problem. For\nexample, some might suggest that we can handle this problem by\nappropriately typing the agent’s belief. Perhaps after Alice\nreceives her friend’s testimony, her belief is no longer the\nresult of vision alone, but rather of vision while\ndisregarding testimony that vision is unreliable. (See Constantin\n2020; Nagel 2021 for versions of this response.) An important question\nfor this response is whether it is consistent with our most promising\ntheories of process-typing; in this regard, the problem of defeat is\nconnected to the generality problem. Another strategy for handling\ndefeat is to modify reliabilism by incorporating some evidentialist\nelements into the theory. For now, we will defer a more detailed\ndiscussion of this maneuver to\n §4.2\n below. \nIt is also worth noting that the reliabilist’s treatment of\ndefeat may bear on other problems facing reliabilism. Consider again\nthe clairvoyance objection. Yet another response to this objection,\nsuggested briefly by Goldman (1986: 112) is that Norman’s belief\nis prima facie justified, but it is defeated. Whether this\nresponse is viable will depend on the details of the\nreliabilist’s theory of defeat. \nA more recent challenge to reliabilism, due to Frise (2018), is the\n“temporality problem”. Reliabilists maintain that the\njustificatory status of a belief depends on the reliability of the\nprocess responsible for that belief. But, Frise points out, a process\ncan be more reliable at one time than at another. To give one of\nFrise’s examples, weather forecasting has improved over time. So\nthe process type, forming a belief based on the forecast is\nmore reliable now than it was twenty years ago. This raises a question\nabout the temporal parameters that we should use when evaluating\nreliability. Suppose we are evaluating whether a belief B is\njustified at a time t. Do we restrict our attention to whether\nthe belief-forming process responsible for B is reliable at\nt? Or do we look at whether it has been reliable at all times\nup until t? Or all times that are temporally close to t?\nOr something else? \nThis issue has not received much attention from reliabilists, though\nsee Tolly (2019) for an exception. One question that merits further\ninvestigation is whether the reliabilist’s preferred solution to\nthe generality problem will generalize to help with the temporality\nproblem. For example, according to the “common sense”\napproach described above, there is considerable convergence in\nordinary people’s judgments about how to type belief-forming\nprocesses. If this is right, is there also convergence in ordinary\npeople’s judgments about which times are relevant to assessing\nthe reliability of a given process? If so, could we use this common\nsense consensus to make progress on the temporality problem? \nWe now turn to consider some relatively recent developments in\nreliabilist epistemology. In the next section, we turn to consider\nvarious cousins and spin-offs of reliabilism. \nAs we saw in\n §2.2,\n a crucial question facing reliability theories concerns the domain in\nwhich a process is assessed for reliability. Recently, some writers\nhave explored the idea that we should take this domain to be the\nnormal conditions for the use of a given process. \nFor example, Jarrett Leplin (2007, 2009) rejects the common view of\nreliable processes as those that produce a high ration of truths to\nfalsehoods. In its place, Leplin advances a conception of reliability\naccording to which a process/method is reliable if it would never\nproduce or sustain false beliefs under normal conditions (see\nLeplin 2007: 33: 2009: 34–35). A similar proposal has been\ndeveloped by Peter Graham (e.g., Graham, 2012, 2020). Graham draws on\nan etiological account of function due to Larry Wright (1973) and Ruth\nMillikan (1984), among others, to advance a theory of epistemic\nentitlement in terms of proper functioning. Then, like Leplin, Graham\ntries to use a normality approach to address some familiar\ncounterexamples to process reliabilism. \nWhy favor a normality-based version of reliabilism? One motivation\ncomes from the new evil demon problem. The victim of the evil demon\nforms beliefs using perception—a process that is unreliable at\ntheir world. But, the response runs, the normal conditions for\nperception are free from evil demons and the like. At these worlds,\nperception is indeed reliable. \nThere remains work to be done in developing a normality-based version\nof reliability, particularly when it comes to elucidating the notion\nof “normal conditions” here. But at the very least\nnormality-based approaches offer a welcome variant on more traditional\nforms of reliabilism. Normality-based approaches also parallel recent\ndevelopments in the analysis of knowledge. For example, D. Greco\n(2014), taking inspiration from an idea in Dretske (1981), develops an\ninformation-theoretic analysis of knowledge, which he cashed out in\nterms of normal conditions. In a similar vein, both Goodman and Salow\n(2018) and Beddor and Pavese (2020) have proposed “normal\nconditions” variants of a safety condition on knowledge (of the\nsort discussed in\n §1). \nMost versions of reliabilism are “individualistic” in at\nleast two senses. First, they assume that the justificatory status of\nan agent’s belief depends entirely on the reliability of\nprocesses that take place within that agent’s head. Second, they\nassume that the bearers of justificatory status are the beliefs of\nindividual agents, rather than groups. Recently, several philosophers\nhave developed versions of reliabilism that revise or abandon these\nindividualistic assumptions. \nSanford Goldberg (2010) advances a distinctive view of testimonial\nbelief that abandons the first individualistic assumption. Goldberg\ninvites us to imagine that an informant (A) forms a perceptual\nbelief that p, which they convey via testimony to an audience\n(B), who then comes to believe p. However,\nA’s perceptual belief that p was formed in a way\nthat falls just shy of the threshold for justification. Goldberg\ncontends that B’s testimony-based belief that p\ndoes not amount to knowledge. What’s more, the reason why it\ndoes not amount to knowledge is that it is not justified. After all,\nthe belief could well be true, and free from Gettierization. But if\nB’s belief that p is not justified, this\njustificatory failing is not due to any unreliability in\nB’s mental processing of A’s testimony.\nRather, it’s due to the fact that A’s original\nbelief that p was insufficiently justified. Goldberg concludes\nthat the justificatory status of testimonial beliefs depends—in\npart—on the reliability of the testifier’s cognitive\nprocesses. \nTurn next to the second individualistic assumption: the bearers of\njustificatory status are always the beliefs of individual agents. A\nnew movement in social epistemology has called this assumption into\nquestion. This movement starts with the observation that we routinely\nascribe beliefs to groups. For example, we talk about whether the jury\nbelieves the defendant is guilty, or what the Committee on Climate\nChange believes to be the causes of global warming. A burgeoning body\nof literature investigates the nature of group belief, and the ways in\nwhich group belief depends on the beliefs of the group’s\nmembers. For important work on this topic, see Gilbert (1989); List\nand Pettit (2011); for an overview, see the entry on\n belief merging and judgment aggregation. \nIn addition to inquiring into the conditions under which a group holds\na particular belief, we can also inquire into the conditions under\nwhich group beliefs are justified. Some social\nepistemologists have sought to answer this question in reliabilist\nterms. For example, Goldman (2014) develops a view of group\njustification that is modelled on the way inference transmits\njustification within an individual agent. According to process\nreliabilism for individuals, inferential justification depends on two\nfactors: (a) the justifiedness of the premise beliefs and (b) the\nconditional reliability of the inferential process used.\nSimilarly, Goldman suggests, group justification depends on two\nanalogous factors: (a) the justifiedness of the members’ beliefs\nand (b) the conditional reliability of the belief aggregation function\n(a function that specifies the way in which the group’s beliefs\ndepend on the members’ beliefs). The details of Goldman’s\nproposal have been critically discussed by both Lackey (2016) and Dunn\n(forthcoming), both of whom propose alternative accounts of the\nconditions under which group beliefs are justified. \nHistorically, reliabilism has been offered as an account of the\njustificatory status of full or outright belief. However, it’s\nwidely thought that beliefs come in degrees: a person might believe\nthat it’s sunny and also believe that it’s Monday, but\nhave a higher degree of belief in the former than the latter. This\nraises the question: can reliabilism be extended to provide an account\nof the justificatory status of degrees of belief? \nFormal epistemologists have long been interested in different\n“scoring rules”—functions that measure the accuracy\nor inaccuracy of degrees of belief (hereafter, credences). For\nexample, one widely discussed scoring rule is the Brier score\n(Brier 1950). Let \\(C(p)\\) be an agent’s credence in \\(p\\); let\n\\(T(p)\\) be \\(p\\)’s indicator function, which equals 1 if \\(p\\)\nis true, and 0 if \\(p\\) is false. \\(C(p)\\)’s Brier score is\ncalculated by the formula: \nThus, a credence of 1 in a true proposition will get a Brier score of\n0—the best score possible. A credence of 1 in a false\nproposition will get a Brier score of 1—the worst score\npossible. An intermediate credence of .6 will get a Brier score of .16\nif the proposition is true, and .36 if it is false. \nGiven a particular scoring rule R, we can develop a measure of\nprocess reliability (Dunn 2015; Tang 2016; Pettigrew 2021). Let\nX be some credence-forming process: that is, a process that\noutputs credences in a range of propositions. We can use R to\nscore all of the credences that X produces. Average all of\nthese scores, and we have a measure of X’s degree of\nreliability. Process reliabilists can then use this measure of\nreliability to give an account of justification for credences: a\ncredence is (prima facie) justified iff it is produced by a\nreliable credence-forming process. \nWhat is the most suitable scoring rule for process reliabilism to use?\nRecent work has begun to tackle this question. In what follows, we\nconfine ourselves to discussing two particularly prominent scoring\nrules—the Brier score and a calibration score. \nGiven its prominence in the literature, the Brier score is a natural\noption. But using the Brier score to measure the reliability of\ncredence-forming processes faces challenges. For example, Dunn (2015)\nand Tang (2016) object that if the Brier score is used, a\ncredence-forming process that only outputs mid-level credences (say, a\ncredence of .6) will never qualify as highly reliable; hence the\ncredences it produces will never count as highly justified. Both Dunn\nand Tang object to this consequence. For instance, Tang argues that\nsometimes a particular input requires having a mid-level credence. If\nI have a vague visual experience of the silhouette of a horse, then it\nseems I should only have a mid-level credence that there is a horse in\nfront of me: a credence of .6 in this proposition might well be\njustified, whereas a credence of 1 or 0 would not. \nAnother option is to measure the reliability of credence-forming\nprocesses using a calibration score. To see what it means for\na credal state to be well-calibrated, consider the following example\nfrom van Fraassen: \nConsider a weather forecaster who says in the morning that the\nprobability of rain equals .8. That day it either rains or does not.\nHow good a forecaster is he? Clearly, to evaluate him we must look at\nhis performance over a longer period of time. Calibration is a measure\nof agreement between judgments and actual frequencies… This\nforecaster was perfectly calibrated over the past year, for example,\nif, for every number r, the proportion of rainy days among\nthose days on which he announced probability r for rain,\nequaled r. (van Fraassen 1984: 245) \nAccording to the calibration approach, a credence is justified iff it\nis produced by a well-calibrated process. This avoids the objection to\nusing the Brier score: after all, a credence-forming process that\nproduces mid-level credences can still be well-calibrated. \nHowever, the calibration approach has also elicited criticism. Goldman\n(1986) asks us to imagine an agent A, 70% of whose opinions\nturn out to be true. A can achieve a perfectly calibrated\ncredence function by adopting a .7 credence in every proposition about\nwhich she has an opinion. However, Goldman argues that it’s\nwrong to automatically conclude that A’s credal state is\nperfectly reliable. If A has no good reason for adopting a .7\ncredence in many of the propositions in question, then her credal\nstate shouldn’t count as justified. Dunn (2015) defends the\ncalibration approach, arguing that the relevant question is whether\nthe process that produced A’s credal state is\nreliable. In order to answer this question, it’s not enough to\nlook at the truth-ratio of A’s opinions at the actual\nworld; rather, we should look across a range of nearby worlds. If\nit’s just a matter of chance that 70% of the propositions\nA has an opinion about are true, then by looking at the\ntruth-values of A’s opinions at nearby worlds the\ncalibration approach will be able to avoid the counterintuitive\nconsequence that A’s credal state is perfectly\nreliable. \nTang (2016) objects to the calibration approach on the grounds that a\ncredence-forming process can be well-calibrated even though that\nprocess is insensitive to relevant evidence. In light of the perceived\nshortcomings of the calibration approach (and those of alternative\nscoring rules), Tang proposes a synthesis of reliabilism and\nevidentialism, where evidentialism can roughly be understood as the\nview that a belief’s justification is determined by how well it\nis supported by the believer’s evidence. According to\nTang’s proposal, a credence of \\(C(p)\\) is only justified if it\nis based on some ground \\(g\\), such that the objective probability of\nthe credence having a true content given \\(g\\) approximates \\(C(p).\\)\nMore recently, Pettigrew (2021) has argued that these two approaches\nshould not be viewed as competitors at all. Pettigrew suggests that we\ncan develop a version of the calibration approach that makes reference\nto the agent’s evidence. Once we do, this version turns out to\nbe extensionally equivalent to a version of Tang’s approach.\nBoth Tang and Pettigrew’s approaches to this issue can thus be\nviewed as syntheses of reliabilism and evidentialism, to be discussed\nin more detail in\n §4.2\n below. \nOnly recently have philosophers started to systematically explore the\npossibility of using scoring rules to provide a reliabilist theory of\ncredal justification. Given its position at the intersection of\ntraditional and formal epistemology, this will likely prove to be a\nrich and important area of ongoing research. \nA number of theories have “branched off” from process\nreliabilism, borrowing some key ideas but parting company with respect\nto others. This section discusses two such cousins of process\nreliabilism: virtue reliabilism and syntheses of reliabilism and\nevidentialism. \nAs its label suggests, virtue reliabilism is a branch of virtue\nepistemology that emerged in the mid-1980s in the wake of process\nreliabilism and shares some significant features with it. In\nparticular, one of its central theoretical notions, that of an\nepistemic competence, resembles that of a reliable belief-forming\nprocess type. And its notion of the exercise of an epistemic\ncompetence resembles that of a token of a reliable process. Leading\nproponents of virtue reliabilism include Ernest Sosa (1991, 2007,\n2010, 2015), John Greco (1999, 2010) and Duncan Pritchard (2012b).\nHere we will focus primarily on Sosa’s version. \nMost virtue reliabilists do not explicitly use the notion of a\n“reliable process”, preferring instead the notions of\n“competence”, “virtue”, “skill” or\n“ability”. How should we understand these notions? Sosa\noften characterizes competences in terms of dispositions, for\ninstance: \nA competence is a certain sort of disposition to succeed when you try.\nSo, exercise of a competence involves aiming at a certain outcome. It\nis a competence in part because it is a disposition to succeed\nreliably enough when one makes such attempts… It is thus tied\nto a conditional of the form: if one tried to \\(\\varphi\\), one would\n(likely enough) succeed. (2015: 96) \nEpistemic competences—the sort of competence that is\nrelevant to epistemology—are dispositions of a specific variety:\ndispositions to arrive at the truth. \nOne question that arises for such accounts of competence is how we are\nto understand the dispositions in question. Are they general\ndispositions of an agent to arrive at the truth about some matter? Or\nare they to be understood as implicitly relativized to belief-forming\nprocesses or methods, in which case an epistemic competence is really\nof the form: a disposition to arrive at the truth when employing\nprocess X? \nFrom a process reliabilist perspective, it’s necessary to\nrelativize the dispositions to belief-forming processes or methods.\nAfter all, process reliabilists will insist that in order to know\nwhether an agent’s belief that p is justified or counts\nas knowledge, it’s not enough to know whether the agent is\ngenerally disposed to arrive at truths about p-related matters.\nInstead, we’ll need to know whether the agent’s particular\nbelief that p was the result of a reliable process. (After all,\nan agent could form the belief that p via an ultra-reliable\nprocess, even if she’s generally disposed to form beliefs about\np-related matters in highly unreliable ways.) In effect,\ncommitted process reliabilists will suggest that virtue reliabilists\nface a dilemma: either epistemic competences are general dispositions\nof the agent, in which case they won’t be able to perform the\nvarious jobs required of them (specifically, explaining whether a\nbelief is justified, or amounts to knowledge), or they are implicitly\nrelativized to processes, in which case epistemic competences are not\nsignificantly different from reliable belief-forming processes. In the\nlatter case, epistemic competences “collapse” into\nreliable processes. \nIn at least some discussions of epistemic competences, virtue\nreliabilists indicate a willingness to relativize epistemic\ncompetences to processes. For example, Sosa describes good eyesight\nand color vision as paradigmatic epistemic competences (Sosa 1991:\n271; 2010: 467)—both of which are also standard examples of\nreliable processes. If epistemic competences are understood as\ninvolving reliable processes, then virtue reliabilism inherits many of\nthe challenges facing process reliabilism—in particular, the\ngenerality problem. (In virtue reliabilist terms, this will amount to\nthe question: “How exactly should we type epistemic\ncompetences?”) Of course, this result is unsurprising if the\ngenerality problem is a problem for everyone who tries to give an\nadequate theory of justified belief, as proponents of the\n“parrying response” suggest\n (§2.3). \nVirtue reliabilism differs from traditional process reliabilism in its\nchoice of analysandum. Historically process reliabilists have focused\non giving an account of justification; by contrast, virtue\nreliabilists have focused on giving an account of knowledge.\nHowever, one certainly could try to extend one’s virtue\nreliabilism to justification. Indeed, if one assumes that knowledge\nentails justification, being a virtue reliabilist about the former\nseems to lead naturally to virtue reliabilism about the latter. And if\nepistemic competences are understood as reliable processes, the\nresulting virtue reliabilist account of justification would presumably\namount to a version of process reliabilism. \nLet us turn now to virtue reliabilist accounts of knowledge. How do\nvirtue reliabilists propose to understand knowledge in terms of\nepistemic competences? There are a variety of slightly different\nproposals in the literature (J. Greco 2009, 2010; Sosa 2007, 2015;\nTurri 2011). However, virtue reliabilists typically understand\nknowledge as involving some sort of explanatory relation between\nhaving a true belief and the exercise of an epistemic competence. For\ninstance, Sosa (2007) holds that S knows p if and only\nif S aptly believes p, where S’s belief is\napt if and only if it is correct because of the exercise of\nan epistemic competence (see also J. Greco 2009, 2010 for a closely\nrelated account). More recently, Sosa (2010, 2015) defends a similar\naccount couched in terms of “manifestation”: knowledge is\nbelief whose correctness manifests the agent’s epistemic\ncompetence (see Turri 2011 for a similar account). \nHow do such accounts handle Gettier cases? Sosa 2007: 94–97\ndiscusses Lehrer’s (1965) Nogot/Havit case, in which a subject\nS truly believes that someone here owns a Ford, but he only\ndoes so on the basis of Nogot’s misleading testimony. Sosa\nclaims that while S holds this belief because of the exercise\nof an epistemic competence, S’s belief isn’t\ncorrect because of the exercise of an epistemic competence.\nThis explanation raises important questions about how to understand\nthe relevant “because of” relation here: what exactly is\nthe difference between a true belief being held because of an\nepistemic competence, and a belief being correct because of an\nepistemic competence? Other ways of fleshing out the details of a\nvirtue reliabilist analysis raise similar questions. \nEven if a virtue reliabilist account of knowledge can handle some\nGettier cases, there remains a question of whether it will be able to\nhandle the full spectrum of Gettier cases. One case that has been\nthought to cause particular trouble for virtue reliabilists is the\nfake barn scenario (introduced by Goldman 1976, who credits the\nexample to Carl Ginet). In the fake barn scenario, Henry sees from the\nroad the one genuine barn in an area filled with many convincing barn\nfaçades. Henry forms a true belief that there’s a barn in\nfront of him; what’s more, the fact that he correctly believes\nthere’s a barn in front of him seems to be causally explained by\nan exercise of his visual competence. (See Lackey 2007 for a forceful\nstatement of this point.) \nOne response to this challenge is to abandon the hope that virtue\nreliabilism on its own will solve every Gettier case. Pritchard\n(2012b) takes this line, opting for a view that combines elements of\nvirtue epistemology with a safety requirement on knowledge (where,\nagain, safety is roughly the requirement that the belief in question\ncouldn’t easily have been held falsely). On Pritchard’s\nview, Henry’s belief that he sees a barn is unsafe, hence fails\nto count as knowledge. Whether this reply is adequate is a matter of\ndebate; for relevant discussion, see Lackey (2006); Beddor and Pavese\n(2020). \nA full assessment of these issues is beyond the scope of the current\narticle. This much is clear: one feature that distinguishes virtue\nreliabilism from classical process reliabilism is its distinctive\ntreatment of knowledge. However, this treatment gives rise to\nimportant questions—questions that remain very much an area of\nactive research. \nProcess reliabilism and evidentialism have long been viewed as\ncompetitors, even antitheses of one another, with one of them\n(reliabilism) being a paradigm of externalism and the other\n(evidentialism) a paradigm of internalism. However, a number of\nepistemologists have recently questioned whether these views are\nnecessarily opposed. For example, Comesaña (2010), Goldman\n(2011), Tang (2016), Goldberg (2018), Pettigrew (2021), Miller (2019)\nand Beddor (2021) have all developed reliabilist views that\nincorporate certain elements traditionally associated with\nevidentialism. \nLet us start with Comesaña’s version of a hybrid view.\nComesaña defends: \nEvidentialist Reliabilism: S’s belief\nthat p is justified if and only if: \nThere are a few respects in which this departs from standard versions\nof reliabilism. The most obvious is that it involves an evidential\nrequirement. This is intended to serve two functions. First, it\nis designed to help with the clairvoyance problem. One crucial feature\nof Norman’s situation is that he has no evidence regarding his\nclairvoyance, or regarding the whereabouts of the President. This is\nat least one of the reasons (says Comesaña) why we have the\nintuition that Norman is not justified. Second, Comesaña\nsuggests that by incorporating bodies of evidence into the\nbelief-forming process, we can make headway on the generality problem.\nOn this view, the relevant type for a given belief-forming process is\nalways: producing a belief that such-and-such on the basis of body\nof evidence e. \nWhile incorporating the notion of evidence into a reliablist theory\ncarries potential advantages, it also raises issues of its own. As\nwe’ve seen, traditional process reliabilists resisted defining\n“justification” in terms of evidence because they\ndidn’t want an analysis that relied on any unreduced epistemic\nnotions (Goldman 1979). Moreover, even those who do not share these\nreductive ambitions may well want some account of the notion of\nevidence possession that appears in clause 1) of Evidentialist\nReliabilism. Comesaña suggests following Conee and Feldman\n(2004) in opting for a “mentalist” construal of our\nevidence, according to which our evidence ultimately consists in\nvarious mental states. While this is a start, there remains the\nquestion of which mental states constitute a subject’s\nevidence. Are they conscious experiences? States that are accessible\nto consciousness? Beliefs? \nOne possibility—not pursued directly by\nComesaña—would be to appeal to reliabilist resources to\nprovide an answer. Goldman (2011) makes a suggestion along these lines\nin developing his preferred synthesis of reliabilism and\nevidentialism. Goldman points out that while reliabilists have not\ntraditionally appealed to the notion of evidence, the notions of\nmental or psychological states play an important role in\nreliabilist theories. After all, in addition to belief-forming\nprocesses, there are also states that serve as\ninputs to those processes. These include both doxastic states\n(beliefs, primarily) and various experiences (perceptual, memorial,\netc.). Although reliabilists typically do not call these states\n“evidence”, there is no principled reason why they could\nnot do so. A similar suggestion is made by Beddor (2021), framed in\nterms of reasons rather than evidence. On\nBeddor’s proposal, a given psychological state s\nconstitutes a prima facie reason for an agent to hold a\nbelief B just in case there is some reliable (or, in the case\nof inferential beliefs, conditionally reliable) process available to\nthe agent that is disposed to produce B when fed s as\ninput. (More on the applications of this sort of view below.) Perhaps,\nthen, not only does a reliabilist-evidentialist hybrid help address\nproblems for reliabilism, it also helps answer some pressing questions\nthat have historically faced evidentialists. \nA further question that arises for reliabilist-evidentialist hybrids\nconcerns the role of historical features (or the lack thereof) in the\ntheory of justifiedness. As noted in\n §1\n above, traditional forms of reliabilism make the epistemic status of\na belief at a time t depend not only on features of the agent\nat t, but also on facts about how the believer acquired the\nbelief in question. Here’s an example that motivates this\n“historicist” dimension to traditional reliabilism\n(Goldman 1999). Last year Sally read about the health benefits of\nbroccoli in a New York Times science section story. She then forms a\njustified belief in broccoli’s beneficial effects. She still\nretains that belief today but no longer recalls the evidence she had\nupon first reading the story. And she hasn’t encountered any\nfurther evidence in the interim, from any kind of source. Isn’t\nher belief in broccoli’s beneficial effects still justified?\nPresumably this is because of her past acquisition. True, she also has\na different kind of evidence, namely, her (justified) belief that\nwhenever she seems to remember a (putative) fact it is usually true.\nBut this is not her entire evidence. It is an important determinant of\nher belief’s justificatory status at t that she was\njustified in forming it originally on the basis of good evidence (of\nanother kind). Had her original belief been based on very poor\nevidence, e.g., reading a similar story in an untrustworthy news\nsource, so that the belief wasn’t justified from the start, her\nbelief at time t would be unjustified—or at least much\nless justified. This indicates that the evidence she acquired\noriginally still has some impact on the justificatory status\nof her belief at t. \nNotably, Comesaña’s Evidentalist Reliabilism lacks any\nsuch historical condition on justifiedness. However, other versions of\na hybrid theory do incorporate a historical condition, and emphasize\nit as a selling point of the view (Goldman 2011; Goldberg 2018; Beddor\n2021). For example, Goldman (2011) advocates a\n“two-component” approach to justification, which makes\nroom for a “degree of support” dimension of justification\nas well as a “proper causal generation” dimension. Here is\none simple way of developing such a theory: \nTwo-Component Hybrid View: S’s belief\nthat p is justified at t iff both: \n\n Condition 1\n incorporates the traditional evidentialist take on justification.\n(Though, as noted above, this condition could itself be given a\nreliabilist spin, if we characterize evidence as the inputs to\nreliable processes). By contrast,\n condition 2\n captures the causal generation dimension of justification. Goldman\nsuggests that a two-component view is nicely positioned to preserve\nthe best of both approaches. \nA final motivation for hybrid views is also worth noting. We saw\nearlier\n (§2.4)\n that some authors have argued that reliabilists have trouble\naccounting cases of defeat — cases where an agent reliably forms\na belief that p at some initial time, and later receives\nevidence indicating that p is false. Intuitively, this further\nevidence defeats S’s justification for believing\np, rendering their belief unjustified (even if it was\npreviously justified). Recently, some authors have suggested that the\nbest way of accommodating defeat in a reliabilist framework is to draw\non evidentialist elements (broadly construed). For example, Miller\n(2019) defends a version of a Two-Component Hybrid View. On her view,\ncases of defeat are cases where\n condition 1\n (the evidential support condition) is not satisfied. \nAnother approach to this issue is developed in Beddor (2021), who\noffers a synthesis of a reliabilist view with a “reasons\nfirst” account of justification of the sort developed by John\nPollock (see, e.g., Pollock 1987, 1995). On Pollock’s view, a\nbelief is justified as long as it is based on a chain of undefeated\nreasons that support it. One distinctive feature of Pollock’s\nframework is that he goes on to define defeaters in terms of reasons:\na defeater for a belief B is a prima facie reason to\nbelieve that B is false (rebutting defeater) or a prima\nfacie reason to believe that the agent’s beliefs do not\nsupport B (undercutting defeater). Beddor suggests that by\nsupplementing this account with a reliabilist analysis of prima\nfacie reasons (of the sort sketched above), we get a view that is\nfaithful to the main motivations for reliabilism, while also providing\na more satisfactory treatment of defeat. \nThus there are a number of different ways of developing a hybrid of\nreliabilism and evidentialism. Such hybrids hold considerable promise\nfor overcoming some of the problems facing both reliabilism and\nevidentialism. In view of this promise, such hybrids are a potentially\nfruitful area for further research.","contact.mail":"goldman@philosophy.rutgers.edu","contact.domain":"philosophy.rutgers.edu"},{"date.published":"2008-04-21","date.changed":"2021-05-21","url":"https://plato.stanford.edu/entries/reliabilism/","author1":"Alvin Goldman","author1.info":"http://philosophy.rutgers.edu/index.php?option=com_content&task=view&id=102&Itemid=210","author2.info":"http://www.bobbeddor.com/","entry":"reliabilism","body.text":"\n\n\nOne of the main goals of epistemologists is to provide a substantive\nand explanatory account of the conditions under which a belief has\nsome desirable epistemic status (typically, justification or\nknowledge). According to the reliabilist approach to epistemology, any\nadequate account will need to mention the reliability of the process\nresponsible for the belief, or truth-conducive considerations more\ngenerally. Historically, one major motivation for\nreliabilism—and one source of its enduring interest—is its\nnaturalistic potential. According to reliabilists, epistemic\nproperties can be explained in terms of reliability, which in turn can\nbe understood without reference to any unreduced epistemic notions,\nsuch as evidence or knowledge.\n\n\nThis article begins by surveying some of the main forms of\nreliabilism, concentrating on process reliabilism as a theory of\njustification. It proceeds to review some of the main objections to\nreliabilism, and some of the responses that have been offered on the\nreliabilist’s behalf. After canvassing some recent developments\nin reliabilist epistemology, the article concludes by considering\nvarious cousins and spin-offs of reliabilist epistemology, including\nvirtue reliabilism and various evidentialist-reliabilist hybrids.\n\nIn the 1960s, a wide range of epistemologists were absorbed by the\nquestion: what does it take for a belief to amount to\nknowledge? It was generally agreed that for a person,\nS, to know some proposition p, at least three\nconditions must be met. First, p must be true. Second, S\nmust believe p. And third, S must be justified\nin believing p. Thus, knowledge requires justified true\nbelief. But does the satisfaction of these three conditions\nsuffice to entail that S knows p?\nUnfortunately, as Edmund Gettier (1963) showed with several convincing\ncases, justified true belief doesn’t guarantee knowledge. \nSome subsequent attempts to explicate knowledge had broadly\n“reliabilist” features, although they did not use this\nterminology. According to “relevant alternatives\ntheories”, a subject is said to know p provided that they\ncan “rule out” relevant alternatives where p does\nnot obtain (Dretske 1970; Goldman 1976; Stine 1976; Lewis 1996).\nAccording to “truth-tracking theories”, a subject knows\np provided their beliefs “track the truth” of\np across modal space. Truth-tracking theorists typically cash\nthis out in terms of subjunctive conditionals, such as\n“Sensitivity”: If p had been false, S\nwouldn’t have believed p (Nozick 1981), or\n“Safety”: If S were to believe p, p\nwould be true (Sosa 1999; Williamson 2000; Pritchard 2005). These\nviews are united by the idea that knowledge requires some form of\nreliability. (See the entry on the\n analysis of knowledge.) \nMeanwhile, many epistemologists have turned their attention to a\nrelated epistemic concept: the concept of (epistemic)\njustification. Justified belief is widely regarded as a\nnecessary—though insufficient—condition for\nknowledge. Hence, justification must be regarded as a core concept for\nepistemologists to explore and elucidate. \nHowever, justification also proves to be a very elusive concept. In\n1979 Alvin Goldman published a paper entitled “What Is Justified\nBelief?”, which departed from several well-entrenched positions\non the nature of epistemic justification. Years later, a number of\nepistemologists recognized this paper as marking a significant turning\npoint, or “paradigm shift”, in epistemology. Michael\nWilliams (2016: 3) called it “the Reliabilist Revolution”.\nThis turning point has given rise to a lively debate about the kinds\nof factors that determine the epistemic status of a person’s\nbeliefs or credences. \nThe key idea behind Goldman’s reliabilist approach is that the\njustifiedness of a belief depends on the mental history of\nthe subject’s belief. In particular, it depends on the\nreliability of the process(es) which cause the belief in\nquestion. Somewhat similar ideas (or segments thereof) have been\nadvanced by a number of predecessors, often focusing on knowledge\nrather than justification. Frank Ramsey (1931) wrote that a belief\nqualifies as knowledge if it is true, certain, and obtained\nby a reliable process. He did not, however, provide a detailed defense\nof this thesis. Peter Unger (1968) proposed that S knows that\np just in case “it is not at all accidental” that\nS is right about its being the case that p. David\nArmstrong (1973) offered an analysis of non-inferential knowledge that\nexplicitly used the term “reliable”. He drew an analogy\nbetween a thermometer that reliably indicates the temperature and a\nbelief that reliably indicates the truth. All of these\nwriters seemed to endorse some variant of reliabilism,\nalthough typically there were minor or major differences from the\nversion we shall focus on here. For example, Armstrong promoted an\n“indicator” variant of reliabilism rather than a\n“psychological process” variant. And Unger presented\n“non-accidentality” rather than\n“truth-conduciveness” as the central determinant of\njustifiedness. Clearly, however, there is a great deal of convergence\nin these views. So, contemporary defenders of epistemic reliabilism\nhave grounds for optimism that they are laboring in promising terrain.\nThe nitty-gritty details, however, still need additional work, as we\nshall see in the body of this entry. We turn now to some of the\nprincipal details of Goldman’s form of reliabilism for\njustification (Goldman, 1979, 1986). \nGoldman began by proposing some desiderata on any account of\njustification. First, theories of justification should specify\nconditions for justified belief that do not invoke the concept of\njustification itself, or any other epistemically normative concepts\nsuch as reasonability or rationality. The aim is to provide a\n“reductive” account of justification that does not appeal\nexplicitly or implicitly to any notions that entail justification or\nother members of that family. There is bite in this requirement. For\nexample, it might preclude an analysis of justified belief in terms of\n“evidence”, unless evidence can itself be characterized in\nnon-epistemic terms. What kinds of terms or properties, then, are\nappropriate for constructing an account of justification? Permissible\nconcepts or properties would include doxastic ones, such as belief,\ndisbelief, suspension of judgment, and any other purely psychological\nconcepts, such as ones that refer to perceptual experience or memory.\nGiven the assumption that truth and falsity are non-epistemic notions,\nthey would also be perfectly legitimate for use in analyzing\njustifiedness. Another admissible element in an account of\njustifiedness is the causal relation. \nProceeding under these constraints, Goldman was led to the\n“reliable process” theory as follows. (Note that the main\nconcept to be tackled here is doxastic justifiedness rather\nthan propositional justifiedness. That is, it focuses on what\nit takes for a belief to be justified rather than what it\ntakes for someone to have grounds for forming such a belief.)\nFirst, examples were adduced to show that the justifiedness of\nparticular beliefs depends on how those beliefs are caused,\nor causally sustained, in the mind of the thinker. Suppose\nArthur justifiedly believes a conjunction of propositions, \\(q \\amp\nr\\), from which proposition \\(p\\) follows logically. Further suppose\nthat, soon after forming his belief in this conjunction, Arthur also\nforms a belief in \\(p\\). Does it follow from this that Arthur’s\nbelief in \\(p\\) is justified? No. Although Arthur believes \\(q \\amp\nr\\), this conjunction may not have played any causal role in his\ncoming to believe \\(p\\). He may have formed his belief in \\(p\\) purely\nby wishful thinking. Perhaps he hoped \\(p\\) would be true,\nand therefore (somehow) came to believe it. Alternatively, suppose\nArthur employed confused reasoning that began with \\(q \\amp r\\), and\nserendipitously led to \\(p\\). In neither case is his resulting belief\nin \\(p\\) justified. This shows that a necessary condition for a belief\nto be justified is that it be produced or generated\nin a suitable way. Of course, this immediately raises the\nquestion: which kinds of belief-forming processes are suitable and\nwhich are defective or unsuitable? \nOne feature that is shared by wishful thinking and confused reasoning\nis doxastic unreliability. These belief-forming methods commonly\ngenerate beliefs that are false rather than true. By contrast, what\ntypes of belief-forming processes commonly confer justification? They\ninclude standard perceptual processes, remembering, good reasoning,\nand introspection. What is shared by these processes? What they share\nis reliability: most of the beliefs they produce are true. (This\nformulation will be slightly refined later.) Thus, the central\nproposal made in “What Is Justified Belief” is that the\njustifiedness or unjustifiedness of a belief is determined by the\nreliability or unreliability of the process or processes that cause\nit. Reliability can here be understood either in a frequency\nsense (pertaining to what occurs in the actual world) or in a\npropensity sense (pertaining both to the actual-world and\nother possible worlds.). A belief earns the status of\n“justified” if it is produced by a process (or series of\nprocesses) that has a high truth-ratio. Precisely how high a\ntruth-ratio must be in order to confer justifiedness is left vague,\njust as the concept of justification itself is vague. The truth-ratio\nthreshold need not be as high as 1.0, but it must surely be greater\n(presumably, quite a lot greater) than .50. \nA number of conclusions were drawn from these main points, and\nrefinements were added. One consequence was that process reliabilism\nis a historical type of theory. For example, a reliable inferential\nprocess confers justification on a new belief only if the input\nbeliefs (premises) were themselves justified. How could the\njustifiedness of these input beliefs have arisen? Presumably, their\njustifiedness arose because they were produced by earlier applications\nof reliable processes. Such a chain of processes must ultimately\noriginate from one or more reliable processes that themselves had no\ndoxastic inputs. Perceptual inputs are good candidates for such\nprocesses. So, on this approach, justifiedness is often a product of a\nhistory of personal cognitive processes. The historical framework of\nsuch a process theory contrasts sharply with more traditional\nepistemological frameworks, such as coherentism and (certain versions\nof) evidentialism. According to these more traditional theories,\ncausal and historical relations play no role in determining\njustifiedness. (Though see, e.g., Goldberg 2012 and Fleisher 2019 for\nviews that combine elements of coherentism and reliabilism; for views\nthat integrate evidentialism and reliabilism, see\n §4.2\n below.) More generally, reliabilism marks an important break with\n“current time-slice” approaches, according to which the\nepistemic status of a belief at time t depends entirely on the\nsubject’s mental states at t. \nThese fundamental ideas were spelled out by Goldman in “What Is\nJustified Belief?” (1979), in a series of principles including\nbase-clause principles and recursive-clause principles. The initial\none was (1): \nThis principle would fit cases of perceptually caused beliefs and\nother beliefs that make no use of prior doxastic states (as inputs).\nBut inference-generated beliefs require a different principle. When a\nnew belief results from an inference, its justificational status\ndepends not only on the properties of the inferential\nprocess, but also on whether the input beliefs themselves\nwere justified. To accommodate this, a slightly more complex principle\nwas introduced: \nBy philosophical standards, these are not terribly complex principles.\nThus, process reliabilism is a comparatively simple and\nstraightforward theory. Such simplicity has usually been viewed as a\nvirtue of the approach. Of course, matters are more complicated than\nthe foregoing principles convey. We will survey some potential\ncomplications and refinements of this theory below. \nIs it true, as process reliabilism claims, that beliefs formed by\nreliable processes are (intuitively) considered justified and that\nbeliefs formed by unreliable processes are (intuitively) considered\nunjustified? Here are some examples of processes that frequently lead\nto false beliefs: wishful thinking, reliance on emotional attachment,\nmere hunch or guesswork, and hasty generalization. Beliefs produced by\nsuch processes would all be considered, intuitively, unjustified. So\nthere is a high correlation between process-unreliability and\nunjustifiedness. Similarly, here are some examples of processes that\ncommonly lead to true beliefs: standard perceptual processes, good\nreasoning, and introspection. Here again there is a strong correlation\nbetween process-reliability and justified belief. \nWe should notice, of course, that justifiedness is not a purely\ncategorial concept. We can and do regard certain beliefs as more\ncertain and more justified than others. Furthermore, our intuitions of\ncomparative justifiedness go along with our beliefs about the\ncomparative reliability of the belief-causing processes (Goldman 1979;\n1986: 103–4; 1992; 2008). This comports well with process\nreliabilism. \nBy now, a number of problems have been raised for process reliabilism.\nHere we review some of the main challenges, focusing on the three that\nhave received the most attention in the literature: the clairvoyance\nproblem\n (§2.1),\n the new evil demon problem\n (§2.2),\n and the generality problem\n (§2.3).\n Afterwards, we will briefly survey some challenges of a more recent\nvintage\n (§2.4). \nOne early challenge to reliabilist theories of justification was\nadvanced by Laurence BonJour (1980), concerning a hypothetical\nclairvoyant named “Norman”. Norman has a perfectly\nreliable clairvoyance faculty. But he has no evidence or reasons for\nor against the general possibility of a clairvoyant power or for or\nagainst his possessing such a power. One day Norman’s\nclairvoyance faculty generates in him a belief that the President is\ncurrently in New York City, but with no accompanying perception-like\nexperience, just the bare belief itself. Intuitively, says BonJour,\nNorman isn’t justified in holding this belief. Yet process\nreliabilism seems to imply otherwise. Since Norman’s clairvoyant\npower has a high truth ratio, Norman’s belief about the\nPresident must be justified. So reliabilism seems to get this wrong.\n(Similar examples were offered by Keith Lehrer (1990) and Alvin\nPlantinga (1993).) \nReliabilists have offered various responses to this challenge,\nincluding: \nOne response is to opt for a variant of simple process reliabilism,\nwhich goes by the names of “two-stage reliabilism”\n(Goldman 1992) or “approved-list reliabilism” (Fricker\n2016). Rather than directly giving an account of what justification\nis, this approach seeks to give a theory of how ordinary people make\njustification attributions. Approved-list reliabilists offer the\nfollowing conjecture about how this works. In a preliminary stage,\nattributors form opinions about the reliability or unreliability of\nassorted belief-forming processes, using observation and/or inference\nto draw conclusions about the track-records of these processes in the\nactual world. They thereby construct mental lists of reliable and\nunreliable processes: lists of approved and disapproved processes\n(respectively). In the second stage, they deploy these lists to make\njudgments about particular beliefs (actual or hypothetical). If\nsomebody’s belief was caused by a process that is on their\napproved list—or strongly resembles one on their approved\nlist—they consider it justified. If it is caused by a process on\ntheir disapproved list, it is classed as unjustified. \nHow would approved-list reliabilism explain intuitive judgments in the\nclairvoyance case? Presumably, an ordinary attributor would not have a\nclairvoyance process on either of her lists. But she might well have\nprocesses like extra-sensory-perception or\ntelekinesis on her list, especially her disapproved list. The\nprocess or faculty that Norman uses to arrive at his belief about the\nPresident sounds very similar to one of those obscure and suspect\npowers. Hence, Norman’s belief is intuitively classified as\nunjustified. This is despite the fact that—as potential\nattributors are told—Norman’s clairvoyance process is\nthoroughly reliable. \nApproved list reliabilism is a theory of the factors that influence\nour attributions of epistemic justification. It is thus\nnaturally construed as an attributor theory—a theory of\nthe conditions under which a justification attribution (that is, a\nsentence of the form, “S is justified in believing\np”) is judged to be true or false. In this regard, it\nparallels attributor theories of knowledge (e.g., DeRose 1992). There\nare different ways of developing an approved list attributor theory\nmore precisely. For instance, a contextualist implementation might\nhold that a justification attribution is true if and only if the\nsubject’s belief-forming process belongs to the speaker’s\napproved list. Alternatively, one could adopt an assessor-relativist\nimplementation, according to which the truth-conditions of\njustification attributions are relativized to contexts of assessment\n(cf. MacFarlane 2005). An assessor-relativist version of the approved\nlist might hold that a justification attribution is true at a context\nof assessment if and only if the subject’s belief-forming\nprocess belongs to the assessor’s approved list. \nA different response to the clairvoyance problem is to concede that\nbeing the result of a reliable process is not sufficient for a belief\nto be prima facie justified. Rather, some further condition\nmust be met. One version of this approach has been developed by Jack\nLyons (2009, 2011) who argues that in order for a non-inferential\nbelief to be justified, it must be the result of a “primal\nsystem”. Drawing on research in cognitive science, Lyons\nproposes that a primal system is any cognitive system that meets two\nconditions: (i) it is “inferentially opaque”—that\nis, its outputs are not the result of an introspectively accessible\ntrain of reasoning, (ii) it develops as a result of a combination of\nlearning and innate constraints (2009: 144). For Lyons, our perceptual\nsystems are paradigmatic examples of such primal systems. \nHow does this help with the clairvoyance objection? According to\nLyons, BonJour’s presentation of the Norman example invites the\nassumption that Norman’s clairvoyance was the result of some\nrecent development—e.g., “a recent encounter with\nradioactive waste” or a “neurosurgical\nprank”—not the result of some combination of learning and\ninnate constraints (2009: 118–119). Given this assumption,\nNorman’s clairvoyance-based belief is not the result of a primal\nsystem, hence it is not prima facie justified. \nA third possible response to the clairvoyance objection—which\ninvolves combining reliabilism with evidentialist elements—will\nbe discussed in\n §4.2\n below. \nA second problem for process reliabilism is the “new evil-demon\nproblem” (Cohen 1984; Pollock 1984; Feldman 1985; Foley 1985).\nImagine a world where an evil demon creates non-veridical perceptions\nof physical objects in everybody’s minds. All of these\nperceptions are qualitatively identical to ours, but are false in the\nworld in question. Hence, their perceptual belief-forming processes\n(as judged by the facts in that world) are unreliable; and their\nbeliefs so caused are unjustified. But since their perceptual\nexperiences—hence evidence—are qualitatively identical to\nours, shouldn’t those beliefs in the demon world be\njustified? \nAs with the clairvoyance objection, one response is to move from\nsimple reliabilism to approved list reliabilism (see\n §2.1\n above). As before, approved-list reliabilists will maintain that a\npotential attributor constructs lists of belief-forming processes, one\nfor approved process types and one for disapproved types. Perceptual\nprocesses (of various sorts) would be on the approved list. Since the\npeople in the evil-demon case use perceptual processes that would be\non the approved list, an attributor would consider their resulting\nbeliefs justified—even though s/he is told that the perceptual\nprocesses in the evil-demon world are unreliable. \nA number of philosophers have explored related ideas for solving the\nNew Evil Demon Problem. One similar strategy starts by distinguishing\ntwo different ways a process can be reliable. Suppose we inhabit the\nactual world (@), and we’re evaluating a subject S who\ninhabits some other world \\(w_s\\). Then there are two different things\nwe could mean when we say that S’s belief-forming process\nis reliable: we could mean that it’s reliable relative to @, or\nwe could mean that it’s reliable relative to \\(w_s\\) (Sosa 1993,\n2001). Comesaña (2002) uses this distinction to provide a\nsolution to the new evil demon problem cast in the framework of\ntwo-dimensional semantics (Stalnaker 1999). On Comesaña’s\nproposal, the sentence, “S is justified in believing\np” has two readings: (i) that S’s\nbelief-forming process is reliable relative to @, (ii) that\nS’s belief-forming process is reliable relative to\n\\(w_s\\). If \\(w_s\\) is a demon world, then reading (i) will be true,\nbut reading (ii) is false. While Comesaña’s use of\ntwo-dimensional semantics has drawn criticism (Ball &\nBlome-Tillman 2013), the basic strategy of solving the New Evil Demon\nproblem by appealing to two types of reliability remains popular. For\ndiscussion of a related approach, see the discussion of normality\nreliabilism in\n §3.1  below. \nThe foregoing responses seek to accommodate the claim that the person\nin the demon world has justified beliefs (call this the “New\nEvil Demon Claim”). Another response is to reject this claim.\nOne way of motivating the New Evil Demon Claim is by appealing to the\npremise that the person in the new evil demon scenario has the very\nsame evidence that we do at the actual world. However, some\nphilosophers reject this premise in favor of an externalist conception\nof evidence. For example, Williamson (2000: ch. 9) suggests that an\nagent’s evidence is just their knowledge. Since the victim of an\nevil demon knows less than we do, it follows that they have less\nevidence than we do. As Schellenberg (2016) emphasizes, this sort of\nview is compatible with claiming that there is some evidence\nthat both we and the demon victim have in common. It’s just that\nthere is further body of evidence that we possess but the demon victim\nlacks. This sort of responses raises larger questions about what\nreliabilists should say about the nature of evidence; for further\ndiscussion, see\n §4.2\n below. \nPhilosophers who go this route typically emphasize that the beliefs of\nthe person at the demon world have some positive status, even if this\nstatus falls short of justification. For example, Lyons (2013) points\nout that the inferential beliefs of the demon’s victim are\nformed by conditionally reliable processes, which is an epistemic good\nin its own right. Other philosophers have claimed that the beliefs of\nthe demon’s victim are blameless or excusable, even though they\nare not justified (e.g., Pritchard 2012a). This issue is closely\nrelated to a growing recent literature on the relationship between\nepistemic justification and epistemic blamelessness (see, e.g., Kelp\n& Simon 2017; Brown 2018; D. Greco forthcoming; Williamson\nforthcoming). \nPerhaps the most widely discussed problem for process reliabilism is\nthe generality problem. Originally anticipated by Goldman in\n“What Is Justified Belief?”, it has been pressed more\nsystematically by Feldman (1985) and Conee and Feldman (1998). Any\nparticular belief is the product of a token causal process in the\nsubject’s mind/brain, which occurs at a particular time and\nplace. Such a process token can be “typed”, however, in\nmany broader or narrower ways. Each type will have its own associated\nlevel of reliability, often distinct from the levels of reliability of\nother types it instantiates. Which repeatable type should be selected\nfor purposes of assigning a reliability number to the process token?\nIf no (unique) type can be selected, what establishes the\njustificatory status of the resulting belief? \nConsider a concrete example (Conee & Feldman 1998): Smith sees a\nmaple tree outside his window one sunny afternoon and forms the belief\nthat there is a maple tree near his house. How should we type his\nbelief-forming process? Is the relevant type vision? Or\nperhaps something more fine-grained, such as visual experience of\na maple tree on a sunny afternoon? Or is it something more\ncoarse-grained, such as perception? The worry is that\nSmith’s token belief-forming process seems to instantiate all\nthese process types (and many more). So singling out any single one of\nthem as the “right” way of typing the process seems\narbitrary. \nReliabilists have proposed various strategies for dealing with the\ngenerality problem. Some of the main responses include: \nNot every way of describing a belief-forming process carves\npsychological reality at its joints. Consider, for example, the\nprocess type, forming a perceptual belief while wearing green\nsocks. Intuitively, this is an “inappropriate” or\n“irrelevant” way of describing Smith’s\nbelief-forming process. But why is it inappropriate? According to\npsychological approaches, it is inappropriate because it mentions\nfeatures of Smith’s circumstances that play no causal role in\nthe psychological processes responsible for his belief. \nIn their 1998 discussion of the generality problem, Conee and Feldman\nacknowledge that turning to psychology will help winnow down the\nnumber of eligible process types. But they express skepticism that it\nwill always yield a unique process type. Why won’t there be\nmultiple psychologically “real” process types responsible\nfor a given belief token? Subsequent developments of the psychological\napproach have tried to address this worry. For example, Beebe (2004)\nproposes that the relevant process type will always be an\ninformation-processing procedure or algorithm. Of course, there will\noften be indefinitely many types of this kind, of varying reliability.\nTo pick out the appropriate type, Beebe offers the following\ninstructions. Let A be the broadest such type. Choose a\npartition that is the broadest objectively homogeneous subclass of\nA within which the token process falls, where a class is\nobjectively homogeneous if no statistically relevant partition of it\ncan be effected. Beebe’s proposal has been challenged by Dutant\nand Olsson (2013), who argue that it faces a dilemma: either it does\nnot always yield a unique process type or it leads to trivialization\nby collapsing reliability into truth. For a more recent variant of\nBeebe’s solution, aimed at addressing Dutant and Olsson’s\nconcerns, see Kampa (2018). \nPerhaps the most fully developed version of a psychological approach\nto the generality problem comes from Lyons (2019). Lyons agrees with\nBeebe that the relevant psychological process types are\ninformation-processing algorithms. But Lyons additionally suggests\nthat these algorithms need to be relativized to parameters,\nunderstood as psychological variables that affect processing in a\nlaw-like way. For example, lighting conditions are a\nparameter that affects the speed and accuracy of visual information\nprocessing. As Lyons develops this view, the appropriate process type\nfor a given belief token B is provided by the complete\nalgorithmic specification of every psychological process that is\ncausally relevant to B, along with the parameter values for all\nof these processes. As Lyons notes, one upshot of this approach is\nthat the relevant process types will typically be very fine-grained.\nSmith’s belief-forming process type will not be vision,\nbut something more like: visual recognition of objects based on\nretinal stimulus of sort S, in lighting conditions C,\nwith attention distributed in manner M. \nA different approach to the generality problem is to insist that a\nversion of the problem arises for any adequate epistemology, not just\nreliabilists. A version of this “parrying response” has\nbeen developed by Juan Comesaña (2006), who argues that every\naccount of doxastic justification needs to appeal to the basing\nrelation. This is true even of evidentialist accounts: after all,\nevidentialists maintain that in order for a belief B to be\ndoxastically justified, B needs to be based on a body of\nevidence that supports B. (More on evidentialism in\n §4.2\n below.) But, Comesaña argues, any attempt to characterize the\nbasing relation will run into the generality problem, or something\nvery similar to it. Moreover, Comesaña contends, if\nevidentialists are willing to simply take for granted some notion of\nbasing in their theory, then there is no reason why reliabilists\ncannot follow suit, and deploy the basing relation in their solution\nto the generality problem. \nA rather different parrying response has been defended by Michael\nBishop (2010), who argues that the problem will arise for any theory\nthat allows for the possibility of “reflective\njustification”—that is, having a belief B that is\njustified on the basis of one’s knowledge that one formed\nB via a reliable form of reasoning. For further discussion, see\nMatheson (2015) and Tolly (2017). \nBoth Comesaña and Bishop focus on the idea that all\nepistemologists face a version of the generality problem. A\nrelated but distinct idea is to insist that versions of the generality\nproblem crop up everywhere, not just in epistemology. This response\nhas been developed recently by Goldman (forthcoming), who points out\nthat we regularly evaluate the reliability of all sorts of processes,\nnot all of them cognitive. Goldman illustrates with the example of\nGeraldine, who enjoys shooting hoops at her local gym.\nGeraldine’s performance is a function of many factors, including\nhow she focuses her eyes on the target hoop, how she grips the ball,\nhow she selects an angle to hit the backboard, etc. Now consider\nGeraldine’s friend, Henry, who watches as Geraldine consistently\nsinks more than 80% of her shots, using roughly the technique each\ntime. Henry may not be able to provide a detailed specification of\nGeraldine’s hoop-shooting process. Nonetheless, it seems he is\nin a position to conclude that Geraldine uses some process\ntype that is responsible for her frequent attainment of her athletic\ngoal, and that this process is fairly reliable. \nGoldman (forthcoming) argues that these considerations carry two\nlessons. First, they show that the generality problem is very general,\nsince some version of it arises in non-epistemic contexts. Second,\nGoldman takes these considerations to cast doubt on the common\nassumption—voiced explicitly by Conee and Feldman (1998:\n2–3)—that an adequate solution to the generality problem\nwill need to specify a unique process type responsible for any and\nevery token belief. According to Goldman, an evaluator can correctly\n(and justifiably) describe a process as reliable, without being able\nto specify in any detail the sort of process type at issue. \nYet another strategy is to switch tack and inquire into how ordinary\npeople type belief-forming processes. Suppose we ask a person on the\nstreet, “How did Smith form his belief?” Chances are,\nthey’ll answer “vision”, not “visual\nexperience of a maple tree on a Tuesday afternoon while\nwearing…” Inspired by this observation, common sense\napproaches seek to solve the generality problem in two steps. Step\nOne: develop a psychological theory of how ordinary people type\nbelief-forming processes. Step Two: Use these “common\nsense” typing methods to winnow down the range of candidate\nprocess types. \nA version of this approach has been elaborated by Erik Olsson (2016),\nwho appeals to a well-supported psychological theory about\nconceptualization called basic-level theory, developed by\nEleanor Rosch in the 1970s (Rosch et al. 1976). Rosch and her\ncollaborators studied the deployment of taxonomically related concepts\nlike “animal”, “dog”, and\n“labrador”. In such a taxonomy, one term is a\nsuperordinate concept (“animal”), another is an\nintermediate-level concept (“dog”), and a third is a\nsubordinate concept (“labrador”). It turns out that\nintermediate-level concepts are overwhelmingly preferred in free\nnaming tasks (e.g., “What would you call this?”). For\nexample, in one study Rosch et al. found that, out of 540 responses,\n530 to 533 converged on the same intermediate-level word for naming a\nphysical object. Olsson suggests that ordinary people might similarly\ntend to converge on an intermediate-level concept when typing\nbelief-forming processes. This conjecture has been empirically\nsupported in work by Jönsson (2013). Jönsson showed subjects\nclips in which characters arrived at various conclusions, and then\nasked the subjects to specify how the characters arrived at their\nbeliefs. Subjects converged on the choice of verbs describing the\nbelief-formation processes, even without linguistic cues to guide the\nprocess-typing task. Jönsson also found a correlation between\nsubjects’ estimates of the reliability of the characters’\nbelief-forming processes and subjects’ judgments about whether\nthe characters were justified in holding the beliefs in question. Thus\nthere is some evidence that folk psychological propensities lead us to\nconverge on belief-typing tasks, and that our reliability assessments\ntrack our justification judgments. \nIn addition to these three main objections, a number of further\nchallenges have been raised for reliabilism, including the three that\nfollow. \nConsider the following case, due to Vogel (2000): Roxanne is a driver\nwho believes whatever her gas gauge says about the state of her fuel\ntank, although she has no antecedent reasons to believe it is\nreliable. So Roxanne often looks at the gauge and arrives at\nconjunctive beliefs like the following: On this occasion the gauge\nreads “Full” & the tank is full. Now, the\nperceptual process by which she arrives at the belief that the gauge\nreads “Full” is reliable, and so is the process by which\nshe arrives at the belief that the tank is full (given that the gauge\nfunctions reliably). According to reliabilism, therefore, her belief\nin the indicated conjunction should be justified. Now Roxanne deduces\nthe proposition, On this occasion, the gauge is reporting\naccurately. From multiple instances of this reasoning, she\ninduces the further conclusion: The gauge is generally\nreliable. Finally, with a little more deduction she concludes she\nis justified in believing that her gas tank is full. Since\ndeduction and induction are reliable processes, Roxanne must also be\njustified in believing that her gas gauge is full. But is this verdict\nplausible? Definitely not, says Vogel, because such bootstrapping\namounts to a vicious form of epistemic circularity. \nIn response to this problem, we should start by noting that this\nproblem is not specific to reliabilism (Cohen 2002). Indeed, the\nproblem arises for all theories that allow for “basic\njustification”—that is, justification that is obtained via\nsome process or method X without antecedent justification for\nbelieving that X is reliable. As van Cleve (2003) forcefully\nargues, theories that do not allow for basic justification seem to\nlead to wide-ranging skepticism. \nIf we wish to allow for basic justification, can we still give a\nprincipled explanation of why some forms of bootstrapping seem\nillegitimate (for example, the case of Roxanne)? This is an area of\nactive research. One suggestion is that illegitimate forms of\nbootstrapping involve No Lose Investigations. Roughly, a No\nLose Investigation into a hypothesis \\(h\\) is an investigation that\ncould never, in principle, count against \\(h\\). (For suggestions along\nthese lines, see Kornblith 2009; Titelbaum 2010; Douven & Kelp\n2013.) Another suggestion is that illegitimate forms of bootstrapping\nall involve epistemic feedback (Weisberg 2010). Suppose an\nagent believes premises \\(p_1\\) … \\(p_n\\) from which she infers\nlemmas \\(l_1\\) … \\(l_n\\), from which she in turn infers a\nconclusion \\(c\\). Epistemic feedback is present when the probability\nof \\(c\\) conditional on \\(l_1\\) … \\(l_n\\) is greater than the\nprobability of \\(c\\) conditional on \\(p_1\\) … \\(p_n\\).\nRoxanne’s case can be understood in these terms. She first\nbelieves various premises about the gas gauge readings (e.g., The\ngas gauge read full at time \\(t\\); the gauge reads half-empty at\n\\(t^*\\)). She then infers various lemmas about the state of the\ngas tank (e.g., The tank was full at \\(t\\); the tank was\nhalf-empty at \\(t^*\\)). Finally, by conjoining these premises with\nthese lemmas, she comes to believe the conclusion: The gas tank is\nreliable. The probability of this conclusion conditional on just\nthe lemmas (that is, the beliefs about the state of the gas tank) is\nhigher than the probability of the conclusion conditional on the\npremises (that is, the gas gauge readings). Perhaps by imposing a ban\non either No Lose Investigations or epistemic feedback (or both), we\ncan account for the intuition about Roxanne, while still allowing for\nbasic justification. (For an overview of various responses to the\nbootstrapping problem, see Weisberg 2012.) \nAnother challenge for reliabilism comes from the phenomenon of\nepistemic defeat. Consider a case where an agent reliably forms a\nbelief that \\(p\\) at some initial time, and later receives some\nevidence (perhaps misleading evidence) indicating that \\(p\\) is false.\nFor example, suppose Alice looks at a red vase in good lighting\nconditions, and forms the belief that the vase is red. A friend comes\nalong and tells her that she is actually looking at a white vase\nilluminated by red lights. It seems that the receipt of this testimony\nrenders her belief unjustified, even though it was originally formed\nvia a reliable process. Can reliabilists accommodate this verdict? \nIn “What is Justified Belief?”, Goldman acknowledged this\nsort of problem, and suggested adding a “No Defeaters”\ncondition to the theory of epistemic justification. There, he\nelucidated an account of defeat in counterfactual terms. Roughly, your\nbelief B is defeated provided there is some reliable (or\nconditionally reliable) process X available to you such that,\nif you were you use X, you would no longer hold B. On\nthis view, Alice’s belief is defeated because if she were to use\nthe process believing her friend’s testimony, she would\nnot have believed B. However, this account of defeat has been\nsubject to various challenges. For example, Beddor (2015) argues that\nit commits a version of the “counterfactual fallacy”,\nrendering it susceptible to counterexamples. And both Lyons (2009:\n124) and Beddor (2021) point out that it has trouble accommodating\ncases where one defeater is defeated by another. \nBut even if we reject an account of defeat along these lines, the\nreliabilist may have other options for dealing with the problem. For\nexample, some might suggest that we can handle this problem by\nappropriately typing the agent’s belief. Perhaps after Alice\nreceives her friend’s testimony, her belief is no longer the\nresult of vision alone, but rather of vision while\ndisregarding testimony that vision is unreliable. (See Constantin\n2020; Nagel 2021 for versions of this response.) An important question\nfor this response is whether it is consistent with our most promising\ntheories of process-typing; in this regard, the problem of defeat is\nconnected to the generality problem. Another strategy for handling\ndefeat is to modify reliabilism by incorporating some evidentialist\nelements into the theory. For now, we will defer a more detailed\ndiscussion of this maneuver to\n §4.2\n below. \nIt is also worth noting that the reliabilist’s treatment of\ndefeat may bear on other problems facing reliabilism. Consider again\nthe clairvoyance objection. Yet another response to this objection,\nsuggested briefly by Goldman (1986: 112) is that Norman’s belief\nis prima facie justified, but it is defeated. Whether this\nresponse is viable will depend on the details of the\nreliabilist’s theory of defeat. \nA more recent challenge to reliabilism, due to Frise (2018), is the\n“temporality problem”. Reliabilists maintain that the\njustificatory status of a belief depends on the reliability of the\nprocess responsible for that belief. But, Frise points out, a process\ncan be more reliable at one time than at another. To give one of\nFrise’s examples, weather forecasting has improved over time. So\nthe process type, forming a belief based on the forecast is\nmore reliable now than it was twenty years ago. This raises a question\nabout the temporal parameters that we should use when evaluating\nreliability. Suppose we are evaluating whether a belief B is\njustified at a time t. Do we restrict our attention to whether\nthe belief-forming process responsible for B is reliable at\nt? Or do we look at whether it has been reliable at all times\nup until t? Or all times that are temporally close to t?\nOr something else? \nThis issue has not received much attention from reliabilists, though\nsee Tolly (2019) for an exception. One question that merits further\ninvestigation is whether the reliabilist’s preferred solution to\nthe generality problem will generalize to help with the temporality\nproblem. For example, according to the “common sense”\napproach described above, there is considerable convergence in\nordinary people’s judgments about how to type belief-forming\nprocesses. If this is right, is there also convergence in ordinary\npeople’s judgments about which times are relevant to assessing\nthe reliability of a given process? If so, could we use this common\nsense consensus to make progress on the temporality problem? \nWe now turn to consider some relatively recent developments in\nreliabilist epistemology. In the next section, we turn to consider\nvarious cousins and spin-offs of reliabilism. \nAs we saw in\n §2.2,\n a crucial question facing reliability theories concerns the domain in\nwhich a process is assessed for reliability. Recently, some writers\nhave explored the idea that we should take this domain to be the\nnormal conditions for the use of a given process. \nFor example, Jarrett Leplin (2007, 2009) rejects the common view of\nreliable processes as those that produce a high ration of truths to\nfalsehoods. In its place, Leplin advances a conception of reliability\naccording to which a process/method is reliable if it would never\nproduce or sustain false beliefs under normal conditions (see\nLeplin 2007: 33: 2009: 34–35). A similar proposal has been\ndeveloped by Peter Graham (e.g., Graham, 2012, 2020). Graham draws on\nan etiological account of function due to Larry Wright (1973) and Ruth\nMillikan (1984), among others, to advance a theory of epistemic\nentitlement in terms of proper functioning. Then, like Leplin, Graham\ntries to use a normality approach to address some familiar\ncounterexamples to process reliabilism. \nWhy favor a normality-based version of reliabilism? One motivation\ncomes from the new evil demon problem. The victim of the evil demon\nforms beliefs using perception—a process that is unreliable at\ntheir world. But, the response runs, the normal conditions for\nperception are free from evil demons and the like. At these worlds,\nperception is indeed reliable. \nThere remains work to be done in developing a normality-based version\nof reliability, particularly when it comes to elucidating the notion\nof “normal conditions” here. But at the very least\nnormality-based approaches offer a welcome variant on more traditional\nforms of reliabilism. Normality-based approaches also parallel recent\ndevelopments in the analysis of knowledge. For example, D. Greco\n(2014), taking inspiration from an idea in Dretske (1981), develops an\ninformation-theoretic analysis of knowledge, which he cashed out in\nterms of normal conditions. In a similar vein, both Goodman and Salow\n(2018) and Beddor and Pavese (2020) have proposed “normal\nconditions” variants of a safety condition on knowledge (of the\nsort discussed in\n §1). \nMost versions of reliabilism are “individualistic” in at\nleast two senses. First, they assume that the justificatory status of\nan agent’s belief depends entirely on the reliability of\nprocesses that take place within that agent’s head. Second, they\nassume that the bearers of justificatory status are the beliefs of\nindividual agents, rather than groups. Recently, several philosophers\nhave developed versions of reliabilism that revise or abandon these\nindividualistic assumptions. \nSanford Goldberg (2010) advances a distinctive view of testimonial\nbelief that abandons the first individualistic assumption. Goldberg\ninvites us to imagine that an informant (A) forms a perceptual\nbelief that p, which they convey via testimony to an audience\n(B), who then comes to believe p. However,\nA’s perceptual belief that p was formed in a way\nthat falls just shy of the threshold for justification. Goldberg\ncontends that B’s testimony-based belief that p\ndoes not amount to knowledge. What’s more, the reason why it\ndoes not amount to knowledge is that it is not justified. After all,\nthe belief could well be true, and free from Gettierization. But if\nB’s belief that p is not justified, this\njustificatory failing is not due to any unreliability in\nB’s mental processing of A’s testimony.\nRather, it’s due to the fact that A’s original\nbelief that p was insufficiently justified. Goldberg concludes\nthat the justificatory status of testimonial beliefs depends—in\npart—on the reliability of the testifier’s cognitive\nprocesses. \nTurn next to the second individualistic assumption: the bearers of\njustificatory status are always the beliefs of individual agents. A\nnew movement in social epistemology has called this assumption into\nquestion. This movement starts with the observation that we routinely\nascribe beliefs to groups. For example, we talk about whether the jury\nbelieves the defendant is guilty, or what the Committee on Climate\nChange believes to be the causes of global warming. A burgeoning body\nof literature investigates the nature of group belief, and the ways in\nwhich group belief depends on the beliefs of the group’s\nmembers. For important work on this topic, see Gilbert (1989); List\nand Pettit (2011); for an overview, see the entry on\n belief merging and judgment aggregation. \nIn addition to inquiring into the conditions under which a group holds\na particular belief, we can also inquire into the conditions under\nwhich group beliefs are justified. Some social\nepistemologists have sought to answer this question in reliabilist\nterms. For example, Goldman (2014) develops a view of group\njustification that is modelled on the way inference transmits\njustification within an individual agent. According to process\nreliabilism for individuals, inferential justification depends on two\nfactors: (a) the justifiedness of the premise beliefs and (b) the\nconditional reliability of the inferential process used.\nSimilarly, Goldman suggests, group justification depends on two\nanalogous factors: (a) the justifiedness of the members’ beliefs\nand (b) the conditional reliability of the belief aggregation function\n(a function that specifies the way in which the group’s beliefs\ndepend on the members’ beliefs). The details of Goldman’s\nproposal have been critically discussed by both Lackey (2016) and Dunn\n(forthcoming), both of whom propose alternative accounts of the\nconditions under which group beliefs are justified. \nHistorically, reliabilism has been offered as an account of the\njustificatory status of full or outright belief. However, it’s\nwidely thought that beliefs come in degrees: a person might believe\nthat it’s sunny and also believe that it’s Monday, but\nhave a higher degree of belief in the former than the latter. This\nraises the question: can reliabilism be extended to provide an account\nof the justificatory status of degrees of belief? \nFormal epistemologists have long been interested in different\n“scoring rules”—functions that measure the accuracy\nor inaccuracy of degrees of belief (hereafter, credences). For\nexample, one widely discussed scoring rule is the Brier score\n(Brier 1950). Let \\(C(p)\\) be an agent’s credence in \\(p\\); let\n\\(T(p)\\) be \\(p\\)’s indicator function, which equals 1 if \\(p\\)\nis true, and 0 if \\(p\\) is false. \\(C(p)\\)’s Brier score is\ncalculated by the formula: \nThus, a credence of 1 in a true proposition will get a Brier score of\n0—the best score possible. A credence of 1 in a false\nproposition will get a Brier score of 1—the worst score\npossible. An intermediate credence of .6 will get a Brier score of .16\nif the proposition is true, and .36 if it is false. \nGiven a particular scoring rule R, we can develop a measure of\nprocess reliability (Dunn 2015; Tang 2016; Pettigrew 2021). Let\nX be some credence-forming process: that is, a process that\noutputs credences in a range of propositions. We can use R to\nscore all of the credences that X produces. Average all of\nthese scores, and we have a measure of X’s degree of\nreliability. Process reliabilists can then use this measure of\nreliability to give an account of justification for credences: a\ncredence is (prima facie) justified iff it is produced by a\nreliable credence-forming process. \nWhat is the most suitable scoring rule for process reliabilism to use?\nRecent work has begun to tackle this question. In what follows, we\nconfine ourselves to discussing two particularly prominent scoring\nrules—the Brier score and a calibration score. \nGiven its prominence in the literature, the Brier score is a natural\noption. But using the Brier score to measure the reliability of\ncredence-forming processes faces challenges. For example, Dunn (2015)\nand Tang (2016) object that if the Brier score is used, a\ncredence-forming process that only outputs mid-level credences (say, a\ncredence of .6) will never qualify as highly reliable; hence the\ncredences it produces will never count as highly justified. Both Dunn\nand Tang object to this consequence. For instance, Tang argues that\nsometimes a particular input requires having a mid-level credence. If\nI have a vague visual experience of the silhouette of a horse, then it\nseems I should only have a mid-level credence that there is a horse in\nfront of me: a credence of .6 in this proposition might well be\njustified, whereas a credence of 1 or 0 would not. \nAnother option is to measure the reliability of credence-forming\nprocesses using a calibration score. To see what it means for\na credal state to be well-calibrated, consider the following example\nfrom van Fraassen: \nConsider a weather forecaster who says in the morning that the\nprobability of rain equals .8. That day it either rains or does not.\nHow good a forecaster is he? Clearly, to evaluate him we must look at\nhis performance over a longer period of time. Calibration is a measure\nof agreement between judgments and actual frequencies… This\nforecaster was perfectly calibrated over the past year, for example,\nif, for every number r, the proportion of rainy days among\nthose days on which he announced probability r for rain,\nequaled r. (van Fraassen 1984: 245) \nAccording to the calibration approach, a credence is justified iff it\nis produced by a well-calibrated process. This avoids the objection to\nusing the Brier score: after all, a credence-forming process that\nproduces mid-level credences can still be well-calibrated. \nHowever, the calibration approach has also elicited criticism. Goldman\n(1986) asks us to imagine an agent A, 70% of whose opinions\nturn out to be true. A can achieve a perfectly calibrated\ncredence function by adopting a .7 credence in every proposition about\nwhich she has an opinion. However, Goldman argues that it’s\nwrong to automatically conclude that A’s credal state is\nperfectly reliable. If A has no good reason for adopting a .7\ncredence in many of the propositions in question, then her credal\nstate shouldn’t count as justified. Dunn (2015) defends the\ncalibration approach, arguing that the relevant question is whether\nthe process that produced A’s credal state is\nreliable. In order to answer this question, it’s not enough to\nlook at the truth-ratio of A’s opinions at the actual\nworld; rather, we should look across a range of nearby worlds. If\nit’s just a matter of chance that 70% of the propositions\nA has an opinion about are true, then by looking at the\ntruth-values of A’s opinions at nearby worlds the\ncalibration approach will be able to avoid the counterintuitive\nconsequence that A’s credal state is perfectly\nreliable. \nTang (2016) objects to the calibration approach on the grounds that a\ncredence-forming process can be well-calibrated even though that\nprocess is insensitive to relevant evidence. In light of the perceived\nshortcomings of the calibration approach (and those of alternative\nscoring rules), Tang proposes a synthesis of reliabilism and\nevidentialism, where evidentialism can roughly be understood as the\nview that a belief’s justification is determined by how well it\nis supported by the believer’s evidence. According to\nTang’s proposal, a credence of \\(C(p)\\) is only justified if it\nis based on some ground \\(g\\), such that the objective probability of\nthe credence having a true content given \\(g\\) approximates \\(C(p).\\)\nMore recently, Pettigrew (2021) has argued that these two approaches\nshould not be viewed as competitors at all. Pettigrew suggests that we\ncan develop a version of the calibration approach that makes reference\nto the agent’s evidence. Once we do, this version turns out to\nbe extensionally equivalent to a version of Tang’s approach.\nBoth Tang and Pettigrew’s approaches to this issue can thus be\nviewed as syntheses of reliabilism and evidentialism, to be discussed\nin more detail in\n §4.2\n below. \nOnly recently have philosophers started to systematically explore the\npossibility of using scoring rules to provide a reliabilist theory of\ncredal justification. Given its position at the intersection of\ntraditional and formal epistemology, this will likely prove to be a\nrich and important area of ongoing research. \nA number of theories have “branched off” from process\nreliabilism, borrowing some key ideas but parting company with respect\nto others. This section discusses two such cousins of process\nreliabilism: virtue reliabilism and syntheses of reliabilism and\nevidentialism. \nAs its label suggests, virtue reliabilism is a branch of virtue\nepistemology that emerged in the mid-1980s in the wake of process\nreliabilism and shares some significant features with it. In\nparticular, one of its central theoretical notions, that of an\nepistemic competence, resembles that of a reliable belief-forming\nprocess type. And its notion of the exercise of an epistemic\ncompetence resembles that of a token of a reliable process. Leading\nproponents of virtue reliabilism include Ernest Sosa (1991, 2007,\n2010, 2015), John Greco (1999, 2010) and Duncan Pritchard (2012b).\nHere we will focus primarily on Sosa’s version. \nMost virtue reliabilists do not explicitly use the notion of a\n“reliable process”, preferring instead the notions of\n“competence”, “virtue”, “skill” or\n“ability”. How should we understand these notions? Sosa\noften characterizes competences in terms of dispositions, for\ninstance: \nA competence is a certain sort of disposition to succeed when you try.\nSo, exercise of a competence involves aiming at a certain outcome. It\nis a competence in part because it is a disposition to succeed\nreliably enough when one makes such attempts… It is thus tied\nto a conditional of the form: if one tried to \\(\\varphi\\), one would\n(likely enough) succeed. (2015: 96) \nEpistemic competences—the sort of competence that is\nrelevant to epistemology—are dispositions of a specific variety:\ndispositions to arrive at the truth. \nOne question that arises for such accounts of competence is how we are\nto understand the dispositions in question. Are they general\ndispositions of an agent to arrive at the truth about some matter? Or\nare they to be understood as implicitly relativized to belief-forming\nprocesses or methods, in which case an epistemic competence is really\nof the form: a disposition to arrive at the truth when employing\nprocess X? \nFrom a process reliabilist perspective, it’s necessary to\nrelativize the dispositions to belief-forming processes or methods.\nAfter all, process reliabilists will insist that in order to know\nwhether an agent’s belief that p is justified or counts\nas knowledge, it’s not enough to know whether the agent is\ngenerally disposed to arrive at truths about p-related matters.\nInstead, we’ll need to know whether the agent’s particular\nbelief that p was the result of a reliable process. (After all,\nan agent could form the belief that p via an ultra-reliable\nprocess, even if she’s generally disposed to form beliefs about\np-related matters in highly unreliable ways.) In effect,\ncommitted process reliabilists will suggest that virtue reliabilists\nface a dilemma: either epistemic competences are general dispositions\nof the agent, in which case they won’t be able to perform the\nvarious jobs required of them (specifically, explaining whether a\nbelief is justified, or amounts to knowledge), or they are implicitly\nrelativized to processes, in which case epistemic competences are not\nsignificantly different from reliable belief-forming processes. In the\nlatter case, epistemic competences “collapse” into\nreliable processes. \nIn at least some discussions of epistemic competences, virtue\nreliabilists indicate a willingness to relativize epistemic\ncompetences to processes. For example, Sosa describes good eyesight\nand color vision as paradigmatic epistemic competences (Sosa 1991:\n271; 2010: 467)—both of which are also standard examples of\nreliable processes. If epistemic competences are understood as\ninvolving reliable processes, then virtue reliabilism inherits many of\nthe challenges facing process reliabilism—in particular, the\ngenerality problem. (In virtue reliabilist terms, this will amount to\nthe question: “How exactly should we type epistemic\ncompetences?”) Of course, this result is unsurprising if the\ngenerality problem is a problem for everyone who tries to give an\nadequate theory of justified belief, as proponents of the\n“parrying response” suggest\n (§2.3). \nVirtue reliabilism differs from traditional process reliabilism in its\nchoice of analysandum. Historically process reliabilists have focused\non giving an account of justification; by contrast, virtue\nreliabilists have focused on giving an account of knowledge.\nHowever, one certainly could try to extend one’s virtue\nreliabilism to justification. Indeed, if one assumes that knowledge\nentails justification, being a virtue reliabilist about the former\nseems to lead naturally to virtue reliabilism about the latter. And if\nepistemic competences are understood as reliable processes, the\nresulting virtue reliabilist account of justification would presumably\namount to a version of process reliabilism. \nLet us turn now to virtue reliabilist accounts of knowledge. How do\nvirtue reliabilists propose to understand knowledge in terms of\nepistemic competences? There are a variety of slightly different\nproposals in the literature (J. Greco 2009, 2010; Sosa 2007, 2015;\nTurri 2011). However, virtue reliabilists typically understand\nknowledge as involving some sort of explanatory relation between\nhaving a true belief and the exercise of an epistemic competence. For\ninstance, Sosa (2007) holds that S knows p if and only\nif S aptly believes p, where S’s belief is\napt if and only if it is correct because of the exercise of\nan epistemic competence (see also J. Greco 2009, 2010 for a closely\nrelated account). More recently, Sosa (2010, 2015) defends a similar\naccount couched in terms of “manifestation”: knowledge is\nbelief whose correctness manifests the agent’s epistemic\ncompetence (see Turri 2011 for a similar account). \nHow do such accounts handle Gettier cases? Sosa 2007: 94–97\ndiscusses Lehrer’s (1965) Nogot/Havit case, in which a subject\nS truly believes that someone here owns a Ford, but he only\ndoes so on the basis of Nogot’s misleading testimony. Sosa\nclaims that while S holds this belief because of the exercise\nof an epistemic competence, S’s belief isn’t\ncorrect because of the exercise of an epistemic competence.\nThis explanation raises important questions about how to understand\nthe relevant “because of” relation here: what exactly is\nthe difference between a true belief being held because of an\nepistemic competence, and a belief being correct because of an\nepistemic competence? Other ways of fleshing out the details of a\nvirtue reliabilist analysis raise similar questions. \nEven if a virtue reliabilist account of knowledge can handle some\nGettier cases, there remains a question of whether it will be able to\nhandle the full spectrum of Gettier cases. One case that has been\nthought to cause particular trouble for virtue reliabilists is the\nfake barn scenario (introduced by Goldman 1976, who credits the\nexample to Carl Ginet). In the fake barn scenario, Henry sees from the\nroad the one genuine barn in an area filled with many convincing barn\nfaçades. Henry forms a true belief that there’s a barn in\nfront of him; what’s more, the fact that he correctly believes\nthere’s a barn in front of him seems to be causally explained by\nan exercise of his visual competence. (See Lackey 2007 for a forceful\nstatement of this point.) \nOne response to this challenge is to abandon the hope that virtue\nreliabilism on its own will solve every Gettier case. Pritchard\n(2012b) takes this line, opting for a view that combines elements of\nvirtue epistemology with a safety requirement on knowledge (where,\nagain, safety is roughly the requirement that the belief in question\ncouldn’t easily have been held falsely). On Pritchard’s\nview, Henry’s belief that he sees a barn is unsafe, hence fails\nto count as knowledge. Whether this reply is adequate is a matter of\ndebate; for relevant discussion, see Lackey (2006); Beddor and Pavese\n(2020). \nA full assessment of these issues is beyond the scope of the current\narticle. This much is clear: one feature that distinguishes virtue\nreliabilism from classical process reliabilism is its distinctive\ntreatment of knowledge. However, this treatment gives rise to\nimportant questions—questions that remain very much an area of\nactive research. \nProcess reliabilism and evidentialism have long been viewed as\ncompetitors, even antitheses of one another, with one of them\n(reliabilism) being a paradigm of externalism and the other\n(evidentialism) a paradigm of internalism. However, a number of\nepistemologists have recently questioned whether these views are\nnecessarily opposed. For example, Comesaña (2010), Goldman\n(2011), Tang (2016), Goldberg (2018), Pettigrew (2021), Miller (2019)\nand Beddor (2021) have all developed reliabilist views that\nincorporate certain elements traditionally associated with\nevidentialism. \nLet us start with Comesaña’s version of a hybrid view.\nComesaña defends: \nEvidentialist Reliabilism: S’s belief\nthat p is justified if and only if: \nThere are a few respects in which this departs from standard versions\nof reliabilism. The most obvious is that it involves an evidential\nrequirement. This is intended to serve two functions. First, it\nis designed to help with the clairvoyance problem. One crucial feature\nof Norman’s situation is that he has no evidence regarding his\nclairvoyance, or regarding the whereabouts of the President. This is\nat least one of the reasons (says Comesaña) why we have the\nintuition that Norman is not justified. Second, Comesaña\nsuggests that by incorporating bodies of evidence into the\nbelief-forming process, we can make headway on the generality problem.\nOn this view, the relevant type for a given belief-forming process is\nalways: producing a belief that such-and-such on the basis of body\nof evidence e. \nWhile incorporating the notion of evidence into a reliablist theory\ncarries potential advantages, it also raises issues of its own. As\nwe’ve seen, traditional process reliabilists resisted defining\n“justification” in terms of evidence because they\ndidn’t want an analysis that relied on any unreduced epistemic\nnotions (Goldman 1979). Moreover, even those who do not share these\nreductive ambitions may well want some account of the notion of\nevidence possession that appears in clause 1) of Evidentialist\nReliabilism. Comesaña suggests following Conee and Feldman\n(2004) in opting for a “mentalist” construal of our\nevidence, according to which our evidence ultimately consists in\nvarious mental states. While this is a start, there remains the\nquestion of which mental states constitute a subject’s\nevidence. Are they conscious experiences? States that are accessible\nto consciousness? Beliefs? \nOne possibility—not pursued directly by\nComesaña—would be to appeal to reliabilist resources to\nprovide an answer. Goldman (2011) makes a suggestion along these lines\nin developing his preferred synthesis of reliabilism and\nevidentialism. Goldman points out that while reliabilists have not\ntraditionally appealed to the notion of evidence, the notions of\nmental or psychological states play an important role in\nreliabilist theories. After all, in addition to belief-forming\nprocesses, there are also states that serve as\ninputs to those processes. These include both doxastic states\n(beliefs, primarily) and various experiences (perceptual, memorial,\netc.). Although reliabilists typically do not call these states\n“evidence”, there is no principled reason why they could\nnot do so. A similar suggestion is made by Beddor (2021), framed in\nterms of reasons rather than evidence. On\nBeddor’s proposal, a given psychological state s\nconstitutes a prima facie reason for an agent to hold a\nbelief B just in case there is some reliable (or, in the case\nof inferential beliefs, conditionally reliable) process available to\nthe agent that is disposed to produce B when fed s as\ninput. (More on the applications of this sort of view below.) Perhaps,\nthen, not only does a reliabilist-evidentialist hybrid help address\nproblems for reliabilism, it also helps answer some pressing questions\nthat have historically faced evidentialists. \nA further question that arises for reliabilist-evidentialist hybrids\nconcerns the role of historical features (or the lack thereof) in the\ntheory of justifiedness. As noted in\n §1\n above, traditional forms of reliabilism make the epistemic status of\na belief at a time t depend not only on features of the agent\nat t, but also on facts about how the believer acquired the\nbelief in question. Here’s an example that motivates this\n“historicist” dimension to traditional reliabilism\n(Goldman 1999). Last year Sally read about the health benefits of\nbroccoli in a New York Times science section story. She then forms a\njustified belief in broccoli’s beneficial effects. She still\nretains that belief today but no longer recalls the evidence she had\nupon first reading the story. And she hasn’t encountered any\nfurther evidence in the interim, from any kind of source. Isn’t\nher belief in broccoli’s beneficial effects still justified?\nPresumably this is because of her past acquisition. True, she also has\na different kind of evidence, namely, her (justified) belief that\nwhenever she seems to remember a (putative) fact it is usually true.\nBut this is not her entire evidence. It is an important determinant of\nher belief’s justificatory status at t that she was\njustified in forming it originally on the basis of good evidence (of\nanother kind). Had her original belief been based on very poor\nevidence, e.g., reading a similar story in an untrustworthy news\nsource, so that the belief wasn’t justified from the start, her\nbelief at time t would be unjustified—or at least much\nless justified. This indicates that the evidence she acquired\noriginally still has some impact on the justificatory status\nof her belief at t. \nNotably, Comesaña’s Evidentalist Reliabilism lacks any\nsuch historical condition on justifiedness. However, other versions of\na hybrid theory do incorporate a historical condition, and emphasize\nit as a selling point of the view (Goldman 2011; Goldberg 2018; Beddor\n2021). For example, Goldman (2011) advocates a\n“two-component” approach to justification, which makes\nroom for a “degree of support” dimension of justification\nas well as a “proper causal generation” dimension. Here is\none simple way of developing such a theory: \nTwo-Component Hybrid View: S’s belief\nthat p is justified at t iff both: \n\n Condition 1\n incorporates the traditional evidentialist take on justification.\n(Though, as noted above, this condition could itself be given a\nreliabilist spin, if we characterize evidence as the inputs to\nreliable processes). By contrast,\n condition 2\n captures the causal generation dimension of justification. Goldman\nsuggests that a two-component view is nicely positioned to preserve\nthe best of both approaches. \nA final motivation for hybrid views is also worth noting. We saw\nearlier\n (§2.4)\n that some authors have argued that reliabilists have trouble\naccounting cases of defeat — cases where an agent reliably forms\na belief that p at some initial time, and later receives\nevidence indicating that p is false. Intuitively, this further\nevidence defeats S’s justification for believing\np, rendering their belief unjustified (even if it was\npreviously justified). Recently, some authors have suggested that the\nbest way of accommodating defeat in a reliabilist framework is to draw\non evidentialist elements (broadly construed). For example, Miller\n(2019) defends a version of a Two-Component Hybrid View. On her view,\ncases of defeat are cases where\n condition 1\n (the evidential support condition) is not satisfied. \nAnother approach to this issue is developed in Beddor (2021), who\noffers a synthesis of a reliabilist view with a “reasons\nfirst” account of justification of the sort developed by John\nPollock (see, e.g., Pollock 1987, 1995). On Pollock’s view, a\nbelief is justified as long as it is based on a chain of undefeated\nreasons that support it. One distinctive feature of Pollock’s\nframework is that he goes on to define defeaters in terms of reasons:\na defeater for a belief B is a prima facie reason to\nbelieve that B is false (rebutting defeater) or a prima\nfacie reason to believe that the agent’s beliefs do not\nsupport B (undercutting defeater). Beddor suggests that by\nsupplementing this account with a reliabilist analysis of prima\nfacie reasons (of the sort sketched above), we get a view that is\nfaithful to the main motivations for reliabilism, while also providing\na more satisfactory treatment of defeat. \nThus there are a number of different ways of developing a hybrid of\nreliabilism and evidentialism. Such hybrids hold considerable promise\nfor overcoming some of the problems facing both reliabilism and\nevidentialism. In view of this promise, such hybrids are a potentially\nfruitful area for further research.","contact.mail":"rbeddor@gmail.com","contact.domain":"gmail.com"}]
