[{"date.published":"2018-02-23","url":"https://plato.stanford.edu/entries/disagreement/","author1":"Bryan Frances","author2":"Jonathan Matheson","author1.info":"http://bryanfrances.weebly.com/","entry":"disagreement","body.text":"\n\n\n\nWe often find ourselves in disagreement with others. You may think\nnuclear energy is so volatile that no nuclear energy plants should be\nbuilt anytime soon. But you are aware that there are many people who\ndisagree with you on that very question. You disagree with your sister\nregarding the location of the piano in your childhood home, with you\nthinking it was in the primary living area and her thinking it was in\nthe small den. You and many others believe Jesus Christ rose from the\ndead; millions of others disagree.\n\n\n\nIt seems that awareness of disagreement can, at least in many cases,\nsupply one with a powerful reason to think that one’s belief is\nfalse. When you learned that your sister thought the piano had been in\nthe den instead of the living room, you acquired a good reason to\nthink it really wasn’t in the living room, as you know full well\nthat your sister is a generally intelligent individual, has the\nappropriate background experience (she lived in the house too), and is\nabout as honest, forthright, and good at remembering events from\nchildhood as you are. If, in the face of all this, you stick with your\nbelief that the piano was in the living room, will your retaining that\nbelief be reasonable?\n\n\n\nIn the piano case there is probably nothing important riding on the\nquestion of what to do in the face of disagreement. But in many cases\nour disagreements are of great weight, both in the public arena and in\nour personal lives. You may disagree with your spouse or partner about\nwhether to live together, whether to get married, where you should\nlive, or how to raise your children. People with political power\ndisagree about how to spend enormous amounts of money, or about what\nlaws to pass, or about wars to fight. If only we were better able to\nresolve our disagreements, we would probably save millions of lives\nand prevent millions of others from living in poverty.\n\n\n\nThis article examines the central epistemological issues tied to the\nrecognition of disagreement.\n\n\n\nCompared to many other topics treated in this encyclopedia, the\nepistemology of disagreement is a mere infant. While the discussion of\ndisagreement isn’t altogether absent from the history of\nphilosophy, philosophers didn’t start, as a group, thinking\nabout the topic in a rigorous and detailed way until the 21st\ncentury. For that reason, it is difficult to know what the primary\nissues and questions are concerning the general topic. At this early\nstage of investigation we are just getting our feet wet. In this\nessay, we begin by trying to motivate what we think should be the\nprimary issues and questions before we move on to look at some of the\nmain ideas in the literature. In so doing we also introduce some new\nterminology and make some novel distinctions that we think are helpful\nin navigating this relatively recent debate.\n\n\n\nTo a certain extent, it may seem that there are just three doxastic\nattitudes to adopt regarding the truth of a claim: believe it’s\ntrue, believe it’s false (i.e., disbelieve it), and suspend\njudgment on it. In the most straightforward sense, two individuals\ndisagree about a proposition when they adopt different doxastic\nattitudes toward the same proposition (i.e., one believes it and one\ndisbelieves it, or one believes it and one suspends judgment). But of\ncourse there are levels of confidence one can have regarding a\nproposition as well. We may agree that global warming is occurring but\nyou may be much more confident than I am. It can be useful to use\n‘disagreement’ to cover any difference in levels of\nconfidence: if \\(X\\) has one level of confidence regarding belief\n\\(B\\)’s truth while \\(Y\\) has a different level of confidence,\nthen they “disagree” about \\(B\\)—even if this is a\nslightly artificial sense of ‘disagree’. These levels of\nconfidence, or degrees of belief, are often represented as point\nvalues on a 0–1 scale (inclusive), with larger values indicating\ngreater degrees of confidence that the proposition is true. Even if\nsomewhat artificial, such representations allow for more precision in\ndiscussing cases. \n\nWe are contrasting disagreements about belief from disagreements about\nmatters of taste. Our focus is on disagreements where there is a fact\nof the matter, or at least the participants are reasonable in\nbelieving that there is such a fact. \n\nSuppose Jop and Dop are college students who are dating. They disagree\nabout two matters: whether it’s harder to get top grades in\neconomics classes or philosophy classes, and whether they should move\nin together this summer. The first disagreement is over the truth\nof a claim: is the claim (or belief) ‘It is harder to get\ntop grades in economics classes compared to philosophy classes’\ntrue or not? The second disagreement is over an action:\nshould we move in together or not (the action = moving in together)?\nCall the first kind of disagreement belief-disagreement; call\nthe second kind action-disagreement. \n\nThe latter is very different from the former. Laksha is a doctor faced\nwith a tough decision regarding one of her patients. She needs to\nfigure out whether it’s best, all things considered, to just\ncontinue with the medications she has been prescribing or stop them\nand go with surgery. She confers closely with some of her\ncolleagues. Some of them say surgery is the way to go, others say she\nshould continue with medications and see what happens, but no one has\na firm opinion: all the doctors agree that it’s a close call,\nall things considered. Laksha realizes that as far as anyone can tell\nit really is a tie. \n\nIn this situation Laksha should probably suspend judgment on each of\nthe two claims ‘Surgery is the best overall option for this\npatient’ and ‘Medication is the best overall option for\nthis patient’. When asked ‘Which option is best?’\nshe should suspend judgment. \n\nThat’s all well and good, but she still has to do\nsomething. She can’t just refuse to treat the patient. Even if\nshe continues to investigate the case for days and days, in effect she\nhas made the decision to not do surgery. She has made a choice even if\nshe dithers. \n\nThe point is this: when it comes to belief-disagreements,\nthere are three broad options with respect to a specific claim:\nbelieve it, disbelieve it, and suspend judgment on it. (And of course\nthere are a great many levels of confidence to take as well.) But when\nit comes to action-disagreements, there are just two options\nwith respect to an action \\(X\\): do \\(X\\), don’t do\n\\(X\\). Suspending judgment just doesn’t exist when it comes to\nan action. Or, to put it a different way, suspending judgment on\nwhether to do \\(X\\) does exist but is pretty much the same thing as\nnot doing \\(X\\), since in both cases you don’t do \\(X\\) (Feldman\n2006c). \n\nThus, there are disagreements over what to believe and\nwhat to do. Despite this distinction, we can achieve some\nsimplicity and uniformity by construing disagreements over what to do\nas disagreements over what to believe. We do it this way: if we\ndisagree over whether to do action \\(X\\), we are disagreeing over the\ntruth of the claim ‘We should do \\(X\\)’ (or ‘I\nshould do \\(X\\)’ or ‘\\(X\\) is the best thing for us to\ndo’; no, these aren’t all equivalent). This translation of\naction-disagreements into claim-disagreements makes it easy for us to\nconstrue all disagreements as disagreements about what to\nbelieve, where the belief may or may not concern an action. Keep in\nmind, though, that this “translation” doesn’t mean\nthat action-disagreements are just like belief-disagreements that\ndon’t involve actions: the former still requires a choice on\nwhat one is actually going to do. \n\nWith those points in mind, we can formulate the primary questions\nabout the epistemology of disagreement. \n\nHowever, it is worth noting that agreement also has\nepistemological implications. If learning that a large number and\npercentage of your epistemic peers or superiors disagree with you\nshould probably make you lower your confidence in your belief, then\nlearning that those same individuals agree with you should probably\nmake you raise your confidence in your belief—provided they have\ngreater confidence in it than you did before you found out about their\nagreement. \n\nIn posing the questions we start with a single individual who realizes\nthat one or more other people disagree/agree with her regarding one of\nher beliefs. We can formulate the questions with regard to just\ndisagreement or to agreement and disagreement; we also have the choice\nof focusing on just agreement/disagreement or going with levels of\nconfidence. \n\nHere are the primary epistemological questions for just disagreement\nand no levels of confidence: Response Question: Suppose you realize that some people\ndisagree with your belief \\(B\\). How must you respond to the\nrealization in order for that response to be epistemically\nrational (or perhaps wise)? \nBelief Question: Suppose you realize that some people disagree with\nyour belief \\(B\\). How must you respond to the realization in order\nfor your subsequent position on \\(B\\) to be epistemically\nrational? \n\nHere are the questions for agreement/disagreement plus levels of\nconviction: Response Question*: Suppose you realize that some people have a\nconfidence level in \\(B\\) that is different from yours. How must you\nrespond to the realization in order for that response to be\nepistemically rational (or perhaps wise)? \nBelief Question*: Suppose you realize that some people have a\nconfidence level in \\(B\\) that is different from yours. How must you\nrespond to the realization in order for your subsequent\nposition on \\(B\\) to be epistemically rational? \n\nA person can start out with a belief that is irrational, obtain some\nnew relevant evidence concerning that belief, respond to that new\nevidence in a completely reasonable way, and yet end up with an\nirrational belief. This fact is particularly important when it comes\nto posing the central questions regarding the epistemology of\ndisagreement (Christensen 2011). \n\nSuppose Bub’s belief that Japan is a totalitarian state, belief\n\\(J\\), is based on a poor reading of the evidence and a raging,\nirrational bias that rules his views on this topic. He has let his\nbias ruin his thinking through his evidence properly. \n\nThen he gets some new information: some Japanese police have been\ncaught on film beating government protesters. After hearing this, Bub\nretains his old confidence level in \\(J\\). \n\nWe take it that when Bub learns about the police, he has not acquired\nsome new information that should make him think ‘Wait a minute;\nmaybe I’m wrong about Japan’. He shouldn’t lose\nconfidence in his belief \\(J\\) merely because he learned some facts\nthat do not cast any doubt on his belief! \n\nThe lesson of this story is this: Bub’s action of\nmaintaining his confidence in his belief as a result of his new\nknowledge is reasonable even though his retained belief itself is\nunreasonable. Bub’s assessment of the original\nevidence concerning \\(J\\) was irrational, but his reaction to the\nnew information was rational; his subsequent belief in \\(J\\)\nwas (still) irrational (because although the video gives a little\nsupport to \\(J\\), it’s not much). The question, ‘Is Bub\nbeing rational after he got his new knowledge?’ has two\nreasonable interpretations: ‘Is his retained belief in \\(J\\)\nrational after his acquisition of the new knowledge?’\nvs. ‘Is his response to the new knowledge rational?’ \n\nOn the one hand, “rationality demands” that upon his\nacquisition of new knowledge Bub drop his belief \\(J\\) that Japan is a\ntotalitarian state: after all, his overall evidence for it is very\nweak. On the other hand, “rationality demands” that upon\nhis acquisition of new knowledge Bub keep his belief \\(J\\) given\nthat that acquisition—which is the only thing that’s\nhappened to him—gives him no reason to doubt \\(J\\). This\nsituation still might strike you as odd. After all, we’re saying\nthat Bub is being rational in keeping an irrational belief! But no:\nthat’s not what we’re saying. The statement ‘Bub is\nbeing rational’ is ambiguous: is it saying that Bub’s\nretained belief \\(J\\) is rational or is it saying that Bub’s\nretaining of that belief was rational? The statement can take on\neither meaning, and the two meanings end up with different verdicts:\nthe retained belief is irrational but the retaining\nof the belief is rational. In the first case, a state is being\nevaluated, in the second, an action is being evaluated. \n\nConsider a more mundane case. Jack hears a bump in the night and\nirrationally thinks there is an intruder in his house (he has long had\nthree cats and two dogs, so he should know by now that bumps are\nusually caused by his pets; further, he has been a house owner long\nenough to know full well that old houses like his make all sorts of\nodd noises at night, pets or no). Jack has irrational belief \\(B\\):\nthere is an intruder upstairs or there is an intruder downstairs. Then\nafter searching upstairs he learns that there is no intruder upstairs.\nClearly, the reasonable thing for him to do is infer that there is an\nintruder downstairs—that’s the epistemically reasonable\ncognitive move to make in response to the new information,\ngiven—despite the fact that the new belief ‘There is an\nintruder downstairs’ is irrational in an evidential sense. \n\nThese two stories show that one’s action of retaining\none’s belief—that intellectual action—can be\nepistemically fine even though the retained belief is not. And, more\nimportantly, we have to distinguish two questions about the\nacquisition of new information (which need not have anything at all to\ndo with disagreement): \n\nThe latter question concerns an intellectual action (an\nintellectual response to the acquisition of new information), whereas\nthe former question concerns the subsequent level of\nconfidence itself, the new confidence level you end up with,\nwhich comes about partially as a causal result of the intellectual\naction. As we have seen with the Japan and intruder stories the\nepistemic reasonableness of the one is partially independent of that\nof the other. \n\nA child has belief \\(B\\) that Hell is a real place located in the\ncenter of the earth. You disagree. This is a case in which you\ndisagree with someone who you recognize to be your epistemic\ninferior on the question of whether \\(B\\) is true. You believe\nthat Babe Ruth was the greatest baseball player ever. Then you find\nout that a sportswriter who has written several books on the history\nof baseball disagrees, saying that so-and-so was the greatest ever. In\nthis case, you realize that you’re disagreeing with\nan epistemic superior on the matter, since you know that\nyou’re just an amateur when it comes to baseball. In a third\ncase, you disagree with your sister regarding the name of the town\nyour family visited on vacation when you were children. You know from\nlong experience that your memory is about as reliable as hers on\nmatters like this one; this is a disagreement with a\nrecognized epistemic peer. \n\nThere are several ways to define the terms ‘superior’,\n‘inferior’, and ‘peer’ (Elga, 2007; see section 5 below). \n\nYou can make judgments about how likely someone is compared to you\nwhen it comes to answering ‘Is belief \\(B\\) true?’\ncorrectly.  If you think she is more likely (e.g., you suppose that\nthe odds that she will answer it correctly are about 90% whereas your\nodds are just around 80%), then you think she is your likelihood\nsuperior on that question; if you think she is less likely, then\nyou think she is your likelihood inferior on that question;\nif you think she is about equally likely, then you think she is\nyour likelihood peer on that question. Another way to\ndescribe these distinctions is by referencing the epistemic position\nof the various parties.  One’s epistemic position describes how\nwell-placed they are, epistemically speaking, with respect to a given\nproposition. The better one’s epistemic position, the more\nlikely one is to be correct. \n\nThere are many factors that help determine one’s epistemic\nposition, or how likely one is to answer ‘Is belief \\(B\\)\ntrue?’ correctly. Here are the main ones (Frances 2014): \n\nCall these Disagreement Factors. Presumably, what determines\nthat \\(X\\) is more likely than \\(Y\\) to answer ‘Is \\(B\\)\ntrue?’ correctly are the differences in the Disagreement Factors\nfor \\(X\\) and \\(Y\\). \n\nFor any given case of disagreement between just two people, the odds\nare that they will not be equivalent on all Disagreement Factors:\n\\(X\\) will surpass \\(Y\\) on some factors and \\(Y\\) will surpass \\(X\\)\non other factors.  If you are convinced that a certain person is\nclearly lacking compared to you on many Disagreement Factors when it\ncomes to answering the question ‘Is \\(B\\) true?’ then\nyou’ll probably say that you are more likely than she is to\nanswer the question correctly provided you are not lacking compared to\nher on other Disagreement Factors. If you are convinced that a certain\nperson definitely surpasses you on many Disagreement Factors when it\ncomes to answering ‘Is \\(B\\) true?’ then you’ll\nprobably say that you are less likely than she is to answer the\nquestion correctly provided you have no advantage over her when it\ncomes to answering ‘Is \\(B\\) true?’. If you think the two\nof you differ in Disagreement Factors but the differences do not add\nup to one person having a net advantage (so you think any differences\ncancel out), then you’ll think you are peers on that\nquestion. \n\nNotice that in this peer case you need not think that the two of you\nare equal on each Disagreement Factor. On occasion, a philosopher will\ndefine ‘epistemic peer’ so that \\(X\\) and \\(Y\\) are peers\non belief \\(B\\) if and only if they are equal on all\nDisagreement Factors.  If \\(X\\) and \\(Y\\) are equal on all\nDisagreement Factors, then they will be equally likely to judge \\(B\\)\ncorrectly, but the reverse does not hold.  Deficiencies of a peer in\none area may be accounted for by advantages in other areas with the\nfinal result being that the two individuals are in an equivalently\ngood epistemic position despite the existence of some inequalities\nregarding particular disagreement factors. \n\nIn order to understand the alternative definitions of\n‘superior’, ‘inferior’, and\n‘peer’, we will look at two cases of disagreement (Frances\n2014). \n\nSuppose I believe \\(B\\), that global warming is happening. Suppose I\nalso believe \\(P\\), that Taylor is my peer regarding \\(B\\) in this\nsense: I think we are equally likely to judge \\(B\\) correctly. I have\nthis opinion of Taylor because I figure that she knows about as well\nas I do the basic facts about expert consensus, she understands and\nrespects that consensus about as much as I do, and she based her\nopinion of \\(B\\) on those facts. (I know she has some opinion on \\(B\\)\nbut I have yet to actually hear her voice it.) Thus, I think she is\nmy likelihood peer on \\(B\\). \n\nBut in another sense I don’t think she is my peer on\n\\(B\\). After all, if someone asked me ‘Suppose you find out\nlater today that Taylor sincerely thinks \\(B\\) is false. What do you\nthink are the odds that you’ll be right and she’ll be\nwrong about \\(B\\)?’ I would reply with ‘Over 95%!’ I\nwould answer that way because I’m very confident in\n\\(B\\)’s truth and if I find out that Taylor disagrees with that\nidea, then I will be quite confident that she’s wrong and\nI’m right. So in that sense I think I have a definite\nepistemic advantage over her: given how confident I am in \\(B\\),\nI think that if it turns out we disagree over \\(B\\), there is a 95%\nchance I’m right and she’s wrong. Of course, given that I\nthink that we are equally likely to judge \\(B\\) correctly and\nI’m very confident in \\(B\\), I’m also very confident that\nshe will judge \\(B\\) to be true; so when I’m asked to think\nabout the possibility that Taylor thinks \\(B\\) is false, I think\nI’m being asked to consider a very unlikely scenario. But the\nimportant point here is this: if I have the view that if it turns out\nthat she really thinks \\(B\\) is false then the odds that I’m\nright and she’s wrong are 95%, then in some sense my view is\nthat she’s not “fully” my peer on \\(B\\), as I think\nthat when it comes to the possibility of disagreement I’m very\nconfident that I will be in the right and she won’t be. \n\nNow consider another case. Suppose Janice and Danny are the same age\nand take all the same math and science classes through high school.\nThey are both moderately good at math. In fact, they almost always get\nthe same grades in math. On many occasions they come up with different\nanswers for homework problems. As far as they have been able to\ndetermine, in those cases 40% of the time Janice has been right, 40%\nof the time Danny has been right, and 20% of the time they have both\nbeen wrong. Suppose they both know this interesting fact about their\ntrack records! Now they are in college together. Danny believes, on\nthe basis of their track records, that on the next math problem they\nhappen to disagree about, the probability that Janice’s answer\nis right equals the probability that his answer is right—unless\nthere is some reason to think one of them has some advantage in this\nparticular case (e.g., Danny has had a lot more time to work on it, or\nsome other significant discrepancy in Disagreement Factors). Suppose\nfurther that on the next typical math problem they work on Danny\nthinks that neither of them has any advantage over the other this time\naround. And then Danny finds out that Janice got an answer different\nfrom his. \n\nIn this math case Danny first comes to think that \\(B\\) (his answer)\nis true. But he also thinks that if he were to discover that Janice\nthinks \\(B\\) is false, the probability that he is right and Jan is\nwrong are equal to the probability that he is wrong and Janice is\nright. That’s very different from the global warming case in\nwhich I thought that if I were to discover that Taylor thinks \\(B\\) is\nfalse, the probability that I’m right and she’s wrong are\n19 times the probability that I’m wrong and she’s right\n(95% is 19 times 5%). \n\nLet’s say that I think you’re my conditional peer\non \\(B\\) if and only if before I find out your view on \\(B\\) but after\nI have come to believe \\(B\\) I think that if it turns out\nthat you disbelieve \\(B\\), then the chance that I’m\nright about \\(B\\) is equal to the chance that you’re right about\n\\(B\\). So although I think Taylor is my likelihood peer on the global\nwarming belief, I don’t think she is my conditional peer on that\nbelief.  I think she is my conditional inferior on that matter. But in\nthe math case Danny thinks Janice is his likelihood peer and\nhis conditional peer on the relevant belief. \n\nSo, central to answering the Response Question and the Belief\nQuestion is the following: \n\nPut in terms of levels of confidence we get the following: \n\nThe Better Position Question is often not very easy to answer. For\nthe majority of cases of disagreement, with \\(X\\) realizing she disagrees\nwith \\(Y\\), \\(X\\) will not have much evidence to think \\(Y\\) is her peer, superior,\nor inferior when it comes to correctly judging \\(B\\). For instance, if I am\ndiscussing with a neighbor whether our property taxes will be\nincreasing next year, and I discover that she disagrees with me, I may\nhave very little idea how we measure up on the Disagreement Factors. I\nmay know that I have more raw intelligence than she has, but I probably\nhave no idea how much she knows about local politics, how much she has\nthought about the issue before, etc. I will have little basis for\nthinking I’m her superior, inferior, or peer. We can call these\nthe unknown cases. Thus, when you discover that you disagree\nwith someone over \\(B\\), you need not think, or have reason to think, that\nshe is your peer, your superior, or your inferior when it comes to\njudging \\(B\\). \n\nA related question is whether there is any important difference\nbetween cases where you are justified in believing your interlocutor\nis your peer and cases where you may be justified in believing that\nyour interlocutor is not your peer but lack any reason to think that\nyou, or your interlocutor, are in the better epistemic\nposition. Peerhood is rare, if not entirely a fictional idealization,\nyet in many real-world cases of disagreement we are not justified in\nmaking a judgment regarding which party is better positioned to answer\nthe question at hand. The question here is whether different answers\nto the Response Question and the Belief Question are to be given in\nthese two cases.  Plausibly, the answer is no. An analogy may help. It\nis quite rare for two people to have the very same weight. So for any\ntwo people it is quite unlikely that they are ‘weight\npeers’. That said, in many cases it may be entirely unclear\nwhich party weighs more than the other party, even if they agree that\nit is unreasonable to believe they weigh the exact same\namount. Rational decisions about what to do where the weight of the\nparty matters do not seem to differ in cases where there are\n‘weight peers’ and cases where the parties simply lack a\ngood reason to believe either party weighs more. Similarly, it seems\nthat the answers to the Response Question and the Belief Question will\nnot differ in cases of peer disagreement and cases where the parties\nsimply lack any good reason to believe that either party is\nepistemically better positioned on the matter. \n\nAnother challenge in answering the Better Position Question occurs\nwhen you are a novice about some topic and you are trying to determine\nwho the experts on the topic are. This is what Goldman terms the\n‘novice/expert problem’ (Goldman 2001). While novices\nought to turn to experts for intellectual guidance, a novice in some\ndomain seems ill-equipped to even determine who the experts in that\ndomain are. Hardwig (1985, 1991) claims that such novice reliance on\nan expert must necessarily be blind, and thus exhibit an unjustified\ntrust. In contrast, Goldman explores five potential evidential sources\nfor reasonably determining someone to be an expert in a domain: \n\nThe vast majority of the literature on the epistemic significance of\ndisagreement, however, concerns recognized peer disagreement (for\ndisagreement with superiors, see Frances 2013). We turn now to this\nissue. \n\nBefore we begin our discussion of peer disagreements it is important\nto set aside a number of cases. Epistemic peers with respect to \\(P\\)\nare in an equally good epistemic position with respect to \\(P\\). Peers\nabout \\(P\\) can both be in a very good epistemic position with respect\nto \\(P\\), or they could both be in a particularly bad epistemic\nposition with respect to \\(P\\). Put differently, two fools could be\npeers. However, disagreement between fool peers has not been of\nparticular epistemic interest in the literature. The literature on\npeer disagreement has instead focused on disagreement between\ncompetent epistemic peers, where competent peers with respect to \\(P\\)\nare in a good epistemic position with respect to \\(P\\)—they are\nlikely to be correct about \\(P\\). Our discussion of peer disagreement\nwill be restricted to competent peer disagreement. In the\nliterature on peer disagreements, four main views have emerged: the\nEqual Weight View, the Steadfast View, the Justificationist View, and\nthe Total Evidence View. \n\nThe Equal Weight View is perhaps the most prominently discussed view\non the epistemic significance of disagreement. Competitor views of\npeer disagreements are best understood as a rejection of various\naspects of the Equal Weight View, so it is a fitting place to begin\nour examination. As we see it, the Equal Weight View is a combination\nof three claims: \nDefeat: Learning that a peer disagrees with you about \\(P\\)\ngives you a reason to believe you are mistaken about \\(P\\). \nEqual Weight: The reason to think you are mistaken about\n\\(P\\) coming from your peer’s opinion about \\(P\\) is just as\nstrong as the reason to think you are correct about \\(P\\) coming from\nyour opinion about \\(P\\). \nIndependence: Reasons to discount your peer’s opinion\nabout \\(P\\) must be independent of the disagreement itself. \n\nDefenses of the Equal Weight View in varying degrees can be found in\nBogardus 2009, Christensen 2007, Elga 2007, Feldman 2006, and Matheson\n2015a. Perhaps the best way to understand the Equal Weight View comes\nfrom exploring the motivation that has been given for the view. We can\ndistinguish between three broad kinds of support that have been given\nfor the view: examining central cases, theoretical considerations, and\nthe use of analogies. The central case that has been used to motivate\nthe Equal Weight View is Christensen’s Restaurant Check\nCase. \n\nUnderstood as a case of peer disagreement, where the friends have a\ntrack record of being equally good at such calculation, and where\nneither party has a reason to believe that on this occasion either\nparty is especially sharp or dull, Christensen claims that upon\nlearning of the disagreement regarding the shares he should become\nsignificantly less confident that the shares are $43 and significantly\nmore confident that they are $45. In fact, he claims that these\ncompetitor propositions ought to be given roughly equal credence. \n\nThe Restaurant Check Case supports Defeat since in learning\nof his peer’s belief, Christensen becomes less justified in his\nbelief. His decrease in justification is seen by the fact that he must\nlower his confidence to be in a justified position on the issue.\nLearning of the disagreement gives him reason to revise and an\nopportunity for epistemic improvement. Further, the Restaurant Check\nCase supports Equal Weight, since the reason Christensen\ngains to believe he is mistaken is quite strong. Since he should be\nequally confident that the shares are $45 as that they are $43, his\nreasons equally support these claims. Giving the peer opinions equal\nweight has typically been understood to require ‘splitting the\ndifference’ between the peer opinions, at least when the two\npeer opinions exhaust one’s evidence about the opinions on the\nmatter.  Splitting the difference is a kind of doxastic compromise\nthat calls for the peers to meet in the middle. So, if one peer\nbelieves \\(P\\) and one peer disbelieves \\(P\\), giving the peer\nopinions equal weight would call for each peer to suspend judgment\nabout \\(P\\). Applied to the richer doxastic picture that includes\ndegrees of belief, if one peer as a 0.7 degree of belief that \\(P\\)\nand the other has a 0.3 degree of belief that \\(P\\), giving the peer\nopinions equal weight will call for each peer to adopt a 0.5 degree of\nbelief that \\(P\\). It is important to note that what gets\n‘split’ is the peer attitudes, not the content of the\nrelevant propositions. For instance, in the Restaurant Check Case,\nsplitting the difference does not require believing that the shares\nare $44. Perhaps it is obvious that the shares are not an even amount.\nSplitting the difference is only with respect to the disparate\ndoxastic attitudes concerning any one proposition (the disputed target\nproposition). The content of the propositions believed by the parties\nare not where the compromise occurs. Finally, the Restaurant Check\nCase supports Independence. The reasons that Christensen\ncould have to discount his peer’s belief about the shares could\ninclude that he had a little too much to drink tonight, that he is\nespecially tired, that Christensen double checked but his friend\ndidn’t, etc., but could not include that the shares actually are\n$43, that Christensen disagrees, etc. \n\nTheoretical support for the Equal Weight View comes from first\nthinking about ordinary cases of testimony. Learning that a reliable\ninquirer has come to believe a proposition gives you a reason to\nbelieve that proposition as well. The existence of such a reason does\nnot seem to depend upon whether you already have a belief about that\nproposition. Such testimonial evidence is some evidence to believe the\nproposition regardless of whether you agree, disagree, or have never\nconsidered the proposition. This helps motivate Defeat, since\na reason to believe the proposition when you disbelieve it amounts to\na reason to believe that you have made a mistake regarding that\nproposition. Similar considerations apply to more fine-grained degrees\nof confidence. Testimonial evidence that a reliable inquirer has\nadopted a 0.8 degree of belief that \\(P\\) gives you a reason to adopt\na 0.8 degree of belief toward \\(P\\), and this seems to hold regardless\nof whether you already have a level of confidence that \\(P\\). \n\nEqual Weight is also motivated by considerations regarding\ntestimonial evidence. The weight of a piece of testimonial evidence is\nproportional to the epistemic position of the testifier (or what the\nhearer’s evidence supports about the epistemic position of the\ntestifier). So, if you have reason to believe that Jai’s\nepistemic position with respect to \\(P\\) is inferior to Mai’s,\nthen discovering that Jai believes \\(P\\) will be a weaker reason to\nbelieve \\(P\\) than discovering that Mai believes \\(P\\). However, in\ncases of peer disagreement, both parties are in an equally good\nepistemic position, so it would follow that their opinions on the\nmatter should be given equal weight. \n\nFinally, Independence has been theoretically motivated by\nexamining what kind of reasoning its denial would permit. In\nparticular, a denial of independence has been thought to permit a\nproblematic kind of question-begging by allowing one to use\none’s own reasoning to come to the conclusion that their peer is\nmistaken.  Something seems wrong with the following line of reasoning,\n“My peer believes not-\\(P\\), but I concluded \\(P\\), so my peer\nis wrong” or “I thought \\(S\\) was my peer, but \\(S\\)\nthinks not-\\(P\\), and I think \\(P\\), so \\(S\\) is not my peer after\nall” (see Christensen (2011). Independence forbids both of these\nways of blocking the reason to believe that you are mistaken from the\ndiscovery of the disagreement. \n\nThe Equal Weight View has also been motivated by way of analogies.  Of\nparticular prominence are analogies to thermometers. Thermometers take\nin pieces of information as inputs and given certain temperature\nverdicts as outputs. Humans are a kind of cognitive machine that takes\nin various kinds of information as inputs and give doxastic attitudes\nas outputs. In this way, humans and thermometers are\nanalogous. Support for the Equal Weight View has come from examining\nwhat it would be rational to believe in a case of peer thermometer\ndisagreement. Suppose that you and I know we have equally reliable\nthermometers and while investigating the temperature of the room we\nare in discover that our thermometers give different outputs (yours\nreads ‘75’ and mine reads ‘72’). What is it\nrational for us to believe about the room temperature? It seems it\nwould be irrational for me to continue believing it was 72 simply\nbecause that was the output of the thermometer that I was\nholding. Similarly, it seems irrational for me to believe that your\nthermometer is malfunctioning simply because my thermometer gave a\ndifferent output. It seems that I would need some information\nindependent from this ‘disagreement’ to discount your\nthermometer. So, it appears that I have been given a reason to believe\nthat the room’s temperature is not 72 by learning of your\nthermometer, that this reason is as strong as my reason to believe it\nis 72, and that this reason is only defeated by independent\nconsiderations. If the analogy holds, then we have reason to accept\neach of the three theses of the Equal Weight View. \n\nThe Equal Weight View is not the only game in town when it comes to\nthe epistemic significance of disagreement. In what follows we will\nexamine the competitor views of disagreement highlighting where and\nwhy they depart from the Equal Weight View. \n\nOn the spectrum of views on the epistemic significance of\ndisagreement, the Equal Weight View and the Steadfast View lie on\nopposite ends. While the Equal Weight View is quite conciliatory, the\nSteadfast View maintains that sticking to one’s guns in a case\nof peer disagreement can be rational. That is, discovering a peer\ndisagreement does not mandate any doxastic change. While the Equal\nWeight View may be seen to emphasize intellectual humility, the\nSteadfast View emphasizes having the courage of your convictions.\nDifferent motivations for Steadfast Views can be seen to reject\ndistinct aspects of the Equal Weight View. We have organized the\nvarious motivations for the Steadfast View according to which aspect\nof the Equal Weight View it (at least primarily) rejects. \n\nDefeat has been rejected by defenders of the Steadfast View\nin a number of ways. First, Defeat has been denied with an\nappeal to private evidence. Peter van Inwagen (1996) has defended the\nSteadfast View by maintaining that in cases of peer disagreement one\ncan appeal to having an incommunicable insight or special evidence\nthat the other party lacks. The basic idea is that if I have access to\na special body of evidence that my peer lacks access to, then\nrealizing that my peer disagrees with me need not give me a reason to\nthink that I’ve made any mistake. After all, my peer\ndoesn’t have everything that I have to work with regarding an\nevaluation of \\(P\\) and it can be reasonable to think that if the peer\nwere to be aware of everything that I am aware of, she would also\nshare my opinion on the matter. Further, some evidence is undoubtedly\nprivate. While I can tell my peer about my intuitions or my\nexperiences, I cannot give him my intuitions or experiences. Given our\nlimitations, peers can never fully share their evidence. However, if\nthe evidence isn’t fully shared, then my peer evaluating his\nevidence one way needn’t show that I have mis-evaluated my\nevidence. Our evidence is importantly different. While van\nInwagen’s claims may entail that the two disagreeing parties are\nnot actually peers due to their evidential differences, these\nconsideration may be used to resist Defeat at least on looser\nconceptions of peerhood that do not require evidential equality. \n\nA related argument is made by Huemer (2011), who argues for an\nagent-centered account of evidence. On this account, an experience\nbeing your own evidentially counts for more than someone\nelse’s experience. So, with this conception of evidence in hand\nthere will be an important evidential asymmetry even in cases where\nboth parties share all their evidence. \n\nDefenders of the Equal Weight View have noted that these\nconsiderations cut both ways (see Feldman 2006). For\ninstance, while you may not be able to fully share your evidence with\nyour peer, these same considerations motivate that your peer similarly\ncannot fully share his or her evidence with you. So, the symmetry that\nmotivated the Equal Weight View may still obtain since both parties\nhave private evidence. A relevant asymmetry only obtains if one has\nspecial reason to believe that their body of private evidence is\nprivileged over their peer’s, and the mere fact that it is\none’s own would not do this. Feldman’s Dean on the Quad\ncase can also help make this clear. \n\nFeldman takes this case to be one where both parties should\nsignificantly conciliate even though it is clear that both possess\nprivate evidence. While both parties can report about their\nexperience, neither party can give their experience to the other. The\nexperiential evidence possessed by each party is private. So, if\nconciliation is still called for, we have reason to question the\nsignificance of private evidence. \n\nSecond, Defeat has been denied by focusing on how things seem\nto the subject. Plantinga (2000a) has argued that there is a sense of\njustification that is simply doing the best that one can. Plantinga\nnotes that despite all the controlled variables an important asymmetry\nremains even in cases of peer disagreement. In cases where I believe\n\\(P\\) and I discover that my peer disbelieves \\(P\\), often \\(P\\) will\ncontinue to seem true to me. That is, there is an important\nphenomenological difference between the two peers—different\nthings seem true to them. Plantinga claims that given that we are\nfallible epistemic creatures some amount of epistemic risk is\ninevitable, and given this, we can do no better than believe in\naccordance with what seems true to us. So, applied to cases of peer\ndisagreement, even upon learning that my peer disbelieves \\(P\\), so\nlong as \\(P\\) continues to seem true to me, it is rational for me to\ncontinue to believe. Any reaction to the disagreement will contain\nsome epistemic risk, so I might as well go with how things seem to\nme. A similar defense of Steadfast Views which emphasizes the\nphenomenology of the subject can be found in Henderson et\nal. 2017. \n\nWhile an individual may not be to blame for continuing to believe as\nthings seem to them, defenders of the Equal Weight View have claimed\nthat the notion of epistemic justification at issue here is distinct. Sometimes doing the best one can is insufficient, and\nwhile some epistemic risk is inevitable, it does not follow that the\noptions are equally risky. While your belief may still seem true to\nyou having discovered the disagreement, other things that seem true to\nyou are relevant as well. For instance, it will seem to you that your\ninterlocutor is an epistemic peer (that they are in an equally good\nepistemic position on the matter) and that they disagree with you.\nThose additional seeming states have epistemological import. In\nparticular, they give you reason to doubt that the truth about the\ndisputed belief is as it seems to you. The mere fact that your belief\ncontinues to seem true to you is unable to save its justificatory\nstatus. Consider the Müller-Lyer illusion: \n\nTo most, line \\(B\\) seems to be longer, but a careful measurement\nreveals that \\(A\\) and \\(B\\) are of equal lengths. Despite knowing of\nthe illusion, however, line \\(B\\) continues to seem longer to many.\nNevertheless, given that it also seems that a reliable measuring\nindicates that the lines are of equal length, one is not justified in\nbelieving that \\(B\\) is longer, despite it continuing to seem that\nway. This result holds even when we appreciate our fallibility and\nthe fallibility of measuring instruments. A parallel account appears\nto apply to cases of peer disagreement. Even if your original belief\ncontinues to seem true to you, you have become aware of information\nthat significantly questions that seeming state. Further, we can\nimagine a scenario where \\(P\\) seems true to me and I subsequently\ndiscover 10,000 peers and superiors on the issue that disagree with me\nabout \\(P\\).  Nevertheless, when I contemplate \\(P\\), it still seems\ntrue to me. In such a case, sticking to my guns about \\(P\\) seems to\nneither be doing the best that I can nor the reasonable thing to\ndo. \n\nThird, Defeat has been denied by denying that peer opinions about\n\\(P\\) are evidence that pertains to \\(P\\). Kelly (2005) distinguishes\nthe following three claims: \n\nKelly (2005) argues that while 3 is evidence for 2 it is not evidence\nfor 1. If 3 is not evidence for 1, then in learning 3 (by discovering\nthe peer disagreement) one does not gain any evidence relevant to the\ndisputed proposition. If learning of the peer disagreement\ndoesn’t affect one’s evidence relevant to the disputed\nproposition, then such a discovery makes no change for which doxastic\nattitude is justified for the peers to take toward the target\nproposition. On this view, the discovery of peer disagreement makes no\ndifference for what you should believe about the disputed\nproposition. \n\nWhy think that 3 is not evidence for 1? Kelly (2005) cites several\nreasons. First, when people cite their justification for their\nbeliefs, they do not typically cite things like 3. We typically treat\nthe fact that someone believes a proposition as the result of\nthe evidence for that proposition, not as another piece of\nevidence for that proposition. Second, since people form beliefs on\nthe basis of a body of evidence, to count their belief as yet another\npiece of evidence would amount to double-counting that original body\nof evidence. On this line of thought, one’s belief that \\(P\\)\nserves as something like a place-holder for the evidence upon which\none formed the belief. So, to count both the belief and the original\nevidence would be to double-count the original evidence, and\ndouble-counting is not a legitimate way of counting. \n\nDefenders of the Equal Weight View have responded by claiming that the\nimpropriety in citing one’s own belief as evidence for the\nproposition believed can be explained in ways that do not require that\none’s belief is not in fact evidence. For instance, it could be\nthat conversational maxims would be violated since the fact that one\nbelieves the proposition is already understood to be the case by the\nother party. Alternatively, citing one’s own belief as evidence\nmay exhibit hubris in a way that many would want to avoid. Finally, it\nseems clear that someone else’s belief that \\(P\\) can be\nevidence for \\(P\\), so denying that the subject’s belief can be\nevidence for the subject entails a kind of relativity of evidence that\nsome reject.  Regarding the double-counting, it has been argued that\nthe fact that a reliable evidential evaluator has evaluated a body of\nevidence to support a proposition is a new piece of evidence, one that\nat least enhances the support between the body of evidence and the\ntarget proposition. For instance, that a forensic expert evaluates the\nrelevant forensic evidence to support the defendant’s guilt\nappears to be an additional piece of evidence in favor of the\ndefendant’s guilt, rather than a mere repetition of that initial\nforensic evidence. \n\nFinally, Defeat has been denied by appealing to epistemic\npermissiveness. The Equal Weight View, and Defeat in\nparticular, has been thought to rely on the Uniqueness Thesis. \n\nIf a body of evidence can only support one doxastic attitude between\nbelief, disbelief, and suspension of judgment with respect to \\(P\\),\nand two people who share their evidence disagree about \\(P\\), then one\nof them must have an unjustified attitude. So, if the Uniqueness\nThesis is true, there is a straightforward route\nto Defeat. However, if evidence is permissive, allowing for\nmultiple distinct justified attitudes toward the same proposition,\nthen discovering that someone has evaluated your shared evidence\ndifferently than you have need not give you any reason to think that\nyou have made a mistake. If evidence is permissive, then you may both\nhave justified responses to the shared evidence even though you\ndisagree. So, another way to motivate the Steadfast View is to endorse\nevidential permissiveness. For reasons to reject or doubt the\nUniqueness Thesis, see Ballantyne and Coffman 2011, Conee 2009,\nFrances 2014, Goldman 2010, Kelly 2010, Kopec 2015, Raleigh 2017,\nRosen 2001, and Rosa 2012. \n\nDefenses of the Equal Weight View either defend the Uniqueness Thesis\n(see Dogramici and Horowitz 2016, Greco and Hedden 2016, Matheson\n2011, White 2005, White 2013) or argue that the Equal Weight View is\nnot actually committed to evidential uniqueness (see Christensen 2009,\nChristensen 2016, Cohen 2013, Lee 2003, Levinstein 2017, Peels and\nBooth 2014, and Henderson et al 2017). \n\nThe Steadfast View has also been motivated by denying Equal\nWeight. If your peer’s opinion about \\(P\\) does not count\nfor as much as your own opinion, then you may not need to make any\ndoxastic conciliation. While most find it implausible that your own\nopinion can count for more merely because it is your own, a related\nand more plausible defense comes from appealing to self-trust. Enoch\n(2010), Foley (2001), Pasnau (2015), Schafer (2015), Wedgwood (2007;\n2010), and Zagzebski (2012) have all appealed to self-trust in\nresponding to peer disagreements. Foley emphasizes the essential and\nineliminable role of first-personal reasoning. Applied to cases of\ndisagreement, Foley claims, “I am entitled to make what I can of\nthe conflict using the faculties, procedures, and opinions I have\nconfidence in, even if these faculties, procedures, and opinions are\nthe very ones being challenged by others” (2001, 79). Similarly,\nWedgwood asserts that it is rational to have a kind of egocentric\nbias—a fundamental trust in one’s own faculties and mental\nstates. On this account, while peer disagreements have a kind of\nsymmetry from the third-person perspective, neither party occupies\nthat perspective.  Rather, each party to the disagreement has a\nfirst-person perspective from which it is rational to privilege\nitself. Self-trust is fundamental and the trust that one must place in\none’s own faculties and states simply cannot be given to\nanother. \n\nOpponents have rejected the epistemic importance of the first-person\nperspective (see Bogardus 2013b and Rattan 2014). While\nthe first-person perspective is ineliminable, it is not infallible.\nFurther, there are reasons from the first-person perspective to make\ndoxastic conciliation. It is my evidence the supports that my\ninterlocutor is my peer and my evidence about what she\nbelieves which call for doxastic change. So, conciliation can be seen\nto be called for from within the first-person perspective. One\nneedn’t, and indeed cannot, abandon one’s own perspective\nin dealing with disagreement. There are also worries concerning what\nsuch an emphasis on self-trust would permit. If self-trust is relevant\nin cases of peer disagreement, it is difficult to see how it is not\nrelevant in cases of novice-expert disagreement. However, most\nmaintain that when the novice learns that the expert disagrees he\nshould make some doxastic movement if not completely defer. So,\nself-trust cannot be the ultimate deciding factor in all cases of\ndisagreement. \n\nA final motivation for the Steadfast View comes from re-evaluating the\nevidential support relations in a case of peer disagreement. It will\nbe helpful here to distinguish between two kinds of evidence. \nFirst-Order Evidence: First-order evidence for \\(P\\) is evidence\nthat directly pertains to \\(P\\). \nHigher-Order Evidence: Higher-order evidence for \\(P\\) is evidence\nabout one’s evidence for \\(P\\). \n\nSo, the cosmological argument, the teleological argument, and the\nproblem of evil are all items of first-order evidence regarding\nGod’s existence, whereas the fact that a competent evaluator of\nsuch evidence finds it to on balance support God’s existence is a\npiece of higher-order evidence that God exists. That a competent\nevidential evaluator has evaluated a body of evidence to support a\nproposition is evidence that the body of evidence in question does in\nfact support that proposition. \n\nApplied to cases of peer disagreement, the first-order evidence is\nthe evidence directly pertaining to the disputed proposition, and each\npeer opinion about the disputed proposition is the higher-order\nevidence (it is evidence that the first-order evidence supports the\nrespective attitudes). \n\nThe Right Reasons View is a steadfast view of peer disagreement that\nemphasizes the role of the shared first-order evidence in peer\ndisagreements. Following Kelly (2005) we can represent the discovery of\na peer disagreement as follows: \n\nAccording to the Right Reasons View, the two pieces of higher-order\nevidence (ii) and (iii) are to be accorded equal weight. Having\nweighed (ii) and (iii) equally, they neutralize in my total body of\nevidence at t’. However, with (ii) and (iii) neutralized, I am\nleft with (i) and am justified in believing what (i) supports. The\nRight Reasons View then notes that what I am justified in believing at\n\\(t\\) and what I am justified in believing at t’ is exactly the\nsame. In both cases what I should believe is entirely a matter of what\n\\(E\\) supports, so what matters in a case of peer disagreement is what\nthe first-order evidence supports. If I believed in accordance with my\nevidence at \\(t\\), then learning of the peer disagreement does nothing\nto alter what I should believe about \\(P\\) at \\(t_2\\). Having rightly\nresponded to my reasons at \\(t\\), nothing epistemically changes\nregarding what attitude I should have toward \\(P\\). \n\nThis argument for the Right Reasons View has been responded to in\nseveral ways. Kelly (2010) has since rejected the argument, claiming\nthat when a greater proportion of one’s evidence supports\nsuspending judgment some conciliation will be called for. Since the\nhigher-order evidence calls for suspending judgment regarding the\ndisputed proposition, there will be a conciliatory push even if the\noriginal first order evidence still plays an important role in what\nattitude is justified. Others have responded to the argument by\nrejecting Kelly’s original description of the case (see Matheson\n2009). If my evidence at \\(t\\) includes not only the first-order\nevidence, but also the higher-order evidence about myself (ii), then\neven if the new piece of higher-order evidence gained at \\(t'\\),\n(iii), cancels out (ii) this will still call for some doxastic\nconciliation from \\(t\\) to \\(t'\\). Alternatively, (ii) and (iii) can\nbe seen to together call for a suspension of judgment over whether\n\\(E\\) supports \\(P\\). Some have argued that a justified suspension of\njudgment over whether your evidence supports \\(P\\) has it that your\ntotal evidence supports a suspension of judgment toward \\(P\\) (see\nFeldman 2006 and Matheson 2015a). See Lasonen-Aarnio 2014 for an\nalternative view of the impact of higher-order evidence. \n\nA more recent defense of the Right Reasons View is found in\nTitelbaum 2015. Titelbaum argues for the Fixed Point Thesis –\nthat mistakes about rationality are mistakes of rationality. In other\nwords, it is always a rational mistake to have a false belief about\nrationality. So, on this view a false belief about what attitude is\nrational does not ‘trickle down’ to affect the rationality\nof the lower-level belief. Given this, if an individual’s initial\nresponse to the evidence is rational, no amount of misleading\nhigher-order evidence affects the rationality of that belief. A correct\nresponse to the first-order evidence remains correct regardless of what\nhigher-order evidence is added. \n\nA remaining problem for the Right Reasons View is its verdicts in\nparadigm cases of peer disagreement. Many have the strong intuition\nthat conciliation is the Restaurant Check Case regardless of whether\nyou correctly evaluated the first-order evidence. \n\nOn the spectrum of views of the epistemic significance of\ndisagreement, the Justificationist View lies somewhere in between the\nEqual Weight View and the Steadfast View. In defending the\nJustificationist View, Jennifer Lackey agrees with the Equal Weight\nView’s verdicts in cases like the Restaurant Check Case, but\nthinks that not all cases should be handled in this way. Along these\nlines she gives the following: \n\nIn Elementary Math, Lackey finds it implausible that she should\nbecome less confident that 2+2=4, never mind to split the difference\nwith her interlocutor and suspend judgment about the matter. In other\nwords, the claim is that the Equal Weight Views gives the wrong\nverdicts in what we might call cases of ‘extreme\ndisagreement’. What justifies treating Elementary Math\ndifferently than the Restaurant Check Case? According to Lackey, if\nprior to discovering the peer disagreement you are highly justified in\nbelieving the soon to be disputed proposition, then upon discovering\nthe peer disagreement little to no conciliation is called for. So,\nsince Lackey is highly justified in believing that 2+2=4 prior to\ntalking to her colleague, not conciliation is called for, but since\nChristensen was not highly justified in believing that the shares are\n$43 prior to discovering the disagreement, a great deal of conciliation\nis called for. According to the Justificationist View, one’s\nantecedent degree of justification determines the rational response to\npeer disagreement. Strong antecedent justification for believing the\ntarget proposition matters since when coupled with the discovered\ndisagreement you now have reasons to believe your interlocutor is not\nyour peer after all. In Elementary Math, Lackey should significantly\nrevise her views about her colleague’s epistemic position\nregarding elementary math. In contrast, the Restaurant Check Case calls\nfor no similar demotion. This difference is explained by the differing\ndegrees of antecedent justification. \n\nApplied to our framework, the Justificationist View denies\nIndependence. In cases where you first-order evidence strongly\nsupports believing p, this fact can be used to reassess your\ninterlocutor’s epistemic credentials. Independence only\npermitted information from ‘outside’ the disagreement to\naffect assessment of peerhood credentials, but here, the fact that your\ninterlocutor disagrees with something you are highly justified in\nbelieving give you a reason to discount his opinion on the matter. \n\nLackey defends the legitimacy of such a demotion due to the\nexistence of personal information. In any case of peer disagreement, I\nwill have information about myself that I simply lack (or lack to the\nsame extent) regarding my interlocutor. I will always be more aware of\nmy alertness, sincerity, open-mindedness, and so forth, than I will be\nof my interlocutor. A similar claim is defended in Benjamin 2015. This\nasymmetry, when coupled with my high antecedent justification for\nbelieving the disputed proposition makes it rational to demote my\nalleged peer. Since in extreme disagreements one party is severely\nmalfunctioning, my personal information makes the best explanation of\nthis fact that it is my peer who is malfunctioning. \n\nThe Justificationist View has been criticized in several ways. Some\nobject that high antecedent justification for believing the target\nproposition can make the relevant difference (see Christensen 2007,\nVavova 2014a, 2014b). Consider the following case: \n\nIn this case, I have very high antecedent justification for\nbelieving that your ticket is not a winner. Nevertheless, upon hearing\nyou exclaim that you won, the rational response is not to downgrade\nyour epistemic credentials. Even high antecedent justification can be\ndefeated by new information. \n\nOthers have agreed that personal information can act as symmetry\nbreaker giving the subject some reason to privilege their own view but\ndeny that such an advantage would be had in suitably idealized cases of\npeer disagreement (Matheson 2015a). The use of personal information to\ndiscount your interlocutor’s opinion would not violate\nIndependence, so the defender of the Equal Weight View\nneedn’t disagree on this score. \n\nLike the Justificationist View, the Total Evidence View lies somewhere\nbetween the Steadfast View and the Equal Weight View. The Total\nEvidence View claims that in cases of peer disagreement, one is\njustified in believing what one’s total evidence supports (Kelly\n2010). While this might sound like something of a truism, central to\nthe view is an additional claim about the relation between first-order\nevidence and higher-order evidence. Let’s first revisit the\nEqual Weight View. According to the Equal Weight View, in a peer\ndisagreement where one individual has a 0.7 degree of belief that\n\\(P\\) and the other has a 0.3 degree of belief that \\(P\\), both peers\nshould split the difference and adopt a 0.5 degree of belief that\n\\(P\\). On the Equal Weight View, then, the attitude that you are\njustified in adopting toward the disputed proposition is entirely\ndetermined by the higher-order evidence. The justified attitude is the\nmean between the two peer attitudes, which ignores what their shared\nfirst-order evidence supports. According to the Total Evidence View,\nthis is a mistake – the first-order evidence must also factor in\nto what the peers are reasonable in believing. Such an incorporation\nof the first-order evidence is what leads to the name “Total\nEvidence View”. \n\nKelly gives the following case to motivate the view: \n\nWhile the Equal Weight View seems to be committed to the peers being\njustified in adopting the 0.8 degree of belief in \\(H\\), Kelly finds such a\nconsequence implausible. After all, both peers badly misjudged the\nfirst-order evidence! This argument can be seen as an argument against\nIndependence. In these cases, the disputed first-order\nevidence can exert an ‘upwards epistemic push” to mitigate\nthe impact of the higher-order evidence. Kelly takes Independence on\ndirectly with the following case: \n\nIndependence claims that my reasons for believing \\(P\\) cannot\nbe used to discount my interlocutor’s opinion about \\(P\\). Absent\nthose first-order reasons, however, Kelly doubts that there is much\nleft to work with the discount the interlocutor, and the drastic\nconciliation that should result without a good reason to discount his\nopinion is implausible. \n\nThis motivation for the Total Evidence View has been responded to in\nseveral different ways. One route of response is deny Kelly’s\nassessment of the cases (Matheson 2015a). According to this response,\nthe individuals in Bootstrapping were both presented with powerful,\nthough misleading, higher-order evidence. However, misleading evidence\nis evidence nevertheless. Given this, it can be argued that the\nindividuals still correctly responded to their total body of evidence.\nFor instance, we can imagine a logician working on a new proof. Suppose\nthat it seems to him that he has successfully completed the proof, yet\nhe nevertheless has made a subtle error rendering the whole thing\ninvalid. In such a case, the logician has significantly mis-evaluated\nhis first-order evidence, yet he has strong higher-order evidence that\nhe is good at things like this. Suppose he then shows his work to a\ncapable colleague who also maintains that the proof is successful. In\nthis case, it may seem that it is rational for the logician to believe\nthat the proof is successful, and perhaps be quite confident, even\nthough this conclusion is significantly different from what the\nfirst-order evidence supports. According to this rejoinder, the call to\nsplit the difference is best seen as addressing the Belief\nQuestion. \n\nA second route of response is to emphasize the distinction between\nthe Response Question and the Belief Question. According to this\nresponse, while there may be something epistemically defective about\nthe final doxastic states of the individuals in Bootstrapping, they\nnevertheless had the rational response to the higher-order evidence\n(Christensen 2011). The fact that they each misjudged the original\nevidence is an epistemic flaw that carries over to their final doxastic\nattitude, but on this line of thinking the doxastic response that each\nparty made upon comparing notes was nevertheless rational. According to\nthis rejoinder, the call to split the difference is best seen as\naddressing the Response Question. \n\nOther objections to the Equal Weight View are not tied to any other\nparticular view of disagreement, and some apply to more than just the\nEqual Weight View. In this section we briefly examine some of these\nobjections. \n\nA prominent objection to the Equal Weight View and other views that\nprescribe doxastic conciliation is that such views are self-defeating.\nFor expressions of this objection, see Elga 2010, Frances 2010,\nO’Connor 1999, Plantinga 2000a and 2000b, Taliaferro 2009,\nWeatherson 2014, and Weintraub 2013. For responses, see Bogardus 2009,\nChristensen 2009, Elga 2010, Graves 2013, Kornblith 2013, Littlejohn\n2013, Matheson 2015b, and Pittard 2015. In brief, there is disagreement\nabout the epistemic significance of disagreement itself, so any view\nthat calls for conciliation upon the discovery of disagreement can have\nit that it calls for its own rejection. For instance, a defender of the\nEqual Weight View could become aware of enough individuals that are\nsuitably epistemically well-positioned on the epistemology of\ndisagreement that nevertheless deny that the Equal Weight View is\ncorrect. Following the prescriptions of the Equal Weight View would\nrequire this defender to abandon the view, and perhaps even accept a\ncompetitor account. For these reasons, Plantinga (2000a) has claimed\nthat such views are, ‘self-referentially inconsistent’\n(522) and Elga (2010) has claimed that such views are\n‘incoherent’ and ‘self-undermining’ (179). Such\na worry seems to apply to the Equal Weight View, the Justificationist\nView, and the Total Evidence View. Since all three views prescribe\nconciliation in at least some cases, they are all (at least in\nprinciple) subject to such a result. \n\nDefenders of these conciliatory views have responded in a number of\nways. First, some emphasize the way in which these views are\nself-defeating is not a way that shows these views to be false, or\nincapable of being true. ‘No true sentences have\nmore than 5 words’ may also be said to be self-defeating, but\nthis is a different kind of defeat. At its worst, the consequences here\nfor conciliatory views is that given certain contingent circumstances\nthey cannot be reasonably believed, but such an inability to be\nreasonably believed does not demonstrate their falsity. Further, a\nskeptical attitude toward the epistemic significance of disagreement\nseems to fit the spirit of these views quite well (more on this\nbelow). \n\nAnother way such a consequence has been downplayed is by comparing\nit to other principles that share the same result. Along these lines,\nChristensen gives the following: \n\nThe principle of Minimal Humility is quite plausible, yet there are\ncontingent circumstances under which it calls for its own rejection\ntoo. If such a consequence is untenable, then it would call for the\nrejection of principles beyond those endorsed by the Equal Weight View,\nthe Justificationist View, and the Total Evidence View. \n\nA final response argues that these principles about disagreement are\nthemselves exempt from their conciliatory prescriptions. So, correctly\nunderstood, these principles call for conciliation in ordinary\ndisagreements, but prescribe remaining steadfast in disagreements about\ndisagreements. So on this view, the true principles are not\nself-defeating. Several philosophers have endorsed such a response to\nthe self-defeat worry. Bogardus (2009) argues that we can ‘just\nsee’ that conciliatory principles are true and this prevents them\nfrom being self-undermining. Elga (2010) argues that conciliatory\nviews, properly understood, are self-exempting since fundamental\nprinciples must be dogmatic about their own correctness. Pittard (2015)\nargues that remaining resolute in conciliationism is no more\nnon-deferential than being conciliatory about conciliationism. The\nreasoning here is that to conciliate about one’s conciliatory\nprinciples would be deferential about one’s belief or credence,\nbut steadfast about one’s reasoning. So, once we appreciate the\ndistinct levels of belief/credence and reasoning, either response to a\ndisagreement about the significance of disagreement will require being\nsteadfast at one level. This, argues Pittard, makes remaining steadfast\nabout conciliationism unproblematic. \n\nWhile such responses would avoid the self-defeat charge, some see it\nguilty of arbitrariness (see Pittard 2015, Blessenohl 2015). \n\nA further set of issues regarding the Equal Weight View come from\nconsiderations within formal epistemology. Fitelson and Jelhe (2009)\nargue that there are difficulties in making precise the Equal Weight\nView along Bayesian lines. In particular, they argue that the most\nintuitive understandings of the Equal Weight View have untenable\nconsequences. Gardiner (2014) and Wilson (2010) each raise an\nobjection that Equal Weight View (at least as typically understood)\nviolates the principle of commutativity of evidence. If we imagine an\nindividual encountering a number of disagreeing peers sequentially,\nthen which doxastic attitude is reasonable for the peer will depend\nupon the order at which the peers are confronted. However, the\nprinciple of commutativity of evidence claims that the order of\nevidential acquisition should not make such a\ndifference. Lasonen-Arnio (2013) sets up a trilemma for the Equal\nWeight View arguing that either (i) it violates intuitively correct\nupdates, (ii) it places implausible restrictions on priors, or (iii)\nit is non-substantive. \n\nAnother issue concerns which disagreements are of epistemic\nsignificance. While actual peer disagreement is rare, if not\nnon-existent (see below), merely possible peer disagreement is\neverywhere. For any belief you have, it is possible that an epistemic\npeer of yours disagrees. Since we are fallible epistemic agents,\npossible peer disagreement is inevitable. One challenge is to\ndistinguish the epistemic significance of actual peer disagreement\nfrom the significance of merely possible peer disagreement. Kelly\n(2005) first raises this challenge. After all, whether this possible\ndisagreeing peer actually exists is a contingent and fragile matter,\nso to only care about it may be to exhibit an ‘actual world\nchauvinism’. (This term comes from Carey 2011.) \n\nChristensen (2007) responds to this challenge by noting that while\nmerely possible disagreement only shows that we are fallible, actual\ndisagreement demonstrates that someone has in fact made a mistake.\nSince we are already aware that we are fallible epistemic agents,\nthinking about possible peer disagreements does not add any information\nthat calls for (further) doxastic change. In contrast, discovering an\nactual peer disagreement gives us information that we lacked. In a case\nof peer disagreement, one of the parties has made a mistake. While the\npossibility of error does not demand belief revision, an increase in\nthe probability of having made an error does. \n\nA further question is whether actual peer disagreements are the only\npeer disagreements with epistemic significance. For instance, suppose\nthat you have created an argument that you find sound in the solitude\nof your office. When thinking about what your (peer) colleague would\nthink, suppose that you reasonably conclude that she would disagree\nabout the merits of your argument. If such a conclusion is reasonable\nfor you, then it seems that this fact should have some epistemic\nconsequences for you despite the fact that there is not (at least as of\nyet) any actual disagreement. Arguably, such a merely possible\ndisagreement even has the same epistemic significance as an actual\ndisagreement (see Carey & Matheson 2013). Similarly, if an evil\ntyrant believes \\(P\\) and then chooses to eliminate all disagreeing peers\nwho believe not-\\(P\\), he would not thereby become justified in his\npreviously contentious belief (Kelly 2005). A challenge is to pick out\nwhich merely possible disagreements are epistemically significant,\nsince at the risk of global skepticism, clearly not all are (Barnett\nand Li 2017). Issues surrounding counterfactual disagreement are also\nexamined in Ballantyne 2013b, Bogardus 2016, and Morgensen 2016. \n\nA final issue concerns peer disagreement itself. As some have noted,\nepistemic peers are extremely rare, if not non-existent (Frances 2010,\n2014; King 2011; Matheson 2014). After all, what are the odds\nthat someone else is in precisely as good of an epistemic position as\nyou on some matter—and even she was, would you know it? As we\nhave seen, there are a number of disagreement factors, and the odds\nthat they end in a tie between any two individuals at any given time is\nquite unlikely. The paucity of peers may be taken to show that the\ndebate of the epistemic significance of peer disagreement is a futile\nexercise in extreme hypotheticals. After all, if you have no epistemic\npeers that disagree with you, doesn’t the epistemic threat from\ndisagreement dissolve? Further, there may seem to have been a deceptive\nshift in the debate. Much of the puzzle of disagreement is motivated by\nmessy real world cases of disagreement, but the vast majority of the\nliterature is focused on idealized cases of disagreement that rarely,\nif ever, occur. \n\nThere are several reasons to think about the significance of peer\ndisagreement beyond its intrinsic appeal. First, considering the\nidealized cases of peer disagreement helps to isolate the epistemic\nsignificance of the disagreement itself. By controlling for other\nepistemic factors, cases of peer disagreement help us focus on what\nepistemic effects discovered disagreement has. While in non-idealized\ncases this is but one factor in determining what to believe, the debate\nabout peer disagreements attempts to help us better understand this one\nfactor. Second, while peers may be quite rare, as we have noted above,\nit is often not clear which party is in the better epistemic position.\nFor instance, while it is quite rare for two individuals to be the\nexact same weight, it can often be unclear which individual weighs\nmore. These unknown cases may have the same epistemic significance as\npeer cases. If what is needed is a positive reason to privilege\none’s own view, as opposed to positive reasons to think that the\nother is a peer, then unknown cases should be treated like peer\ncases. \n\nIn what follows we turn to examining the epistemic significance of\ndisagreement outside of these idealized cases of peer disagreement. \n\nMany disagreements are one-on-one: one person disagrees with another\nperson and as far as they know they are the only two who have any\nopinion on the matter. Lisa thinks that she and Marie should move in\ntogether; then Lisa discovers that Marie has the opposite opinion. Bob\nand his sister Teri disagree about whether their father had an affair\nwhen they were children. In this case they know that others have the\nanswer—their father, for one—but for various reasons the\nopinions of others are not accessible. \n\nMany other disagreements involve just a few people. Bob, Rob, Hob, and\nGob work in a small hotel and are wondering whether to ask for raises\nin their hourly pay rate. After discussion Bob thinks they should, Rob\nand Hob think they shouldn’t, and Gob is undecided.  When Bob\nlearns all this about his three colleagues, what should his doxastic\nreaction be to this mixed bag of agreement and disagreement? \n\nHowever, when it comes to many of your beliefs, including some of the\nmost interesting ones, you are fully aware that millions of\npeople disagree with you and millions of other people agree\nwith you. Just consider a belief about religion—just about any\nbelief at all, pro or con. You must have some views on\ncontroversial matters; virtually every human does. Moreover,\nyou’re perfectly aware that they are controversial. For the most\npart, it’s not as though you believe \\(B\\), \\(B\\) happens to be\ncontroversial, but you had no idea it was controversial. \n\nMoreover, when it comes to these controversial beliefs that large\nnumbers of people have taken positions on, it’s often the case\nthat there are experts on the matter. In many cases the experts have a\ndefinite opinion: global warming is happening and the earth is many\nmillions of years old. Other times they don’t: electrons and\nquarks come from “strings”. \n\nIf the numbers matter, then disagreement poses a skeptical threat for\nnearly every view of the significance of peer disagreement. The\nskeptical threat for conciliatory views (the Equal Weight View, the\nJustificationist View, and the Total Evidence View) is pretty\nstraightforward. On the Equal Weight View, since for many\ncontroversial beliefs we are not justified in believing that the\nweighing of opinions favors our own opinion on the matter, the reasons\nfor thinking that we are mistaken outweigh our reasons for thinking we\nare correct. The added resources of the Justificationist View and the\nTotal Evidence View also do not seem to help in resisting the\nskeptical conclusion.  For many controversial views we lack the strong\nfirst-order evidence and high antecedent justification that these\nviews utilize to mitigate the call to conciliate. Further, while\nappeals to personal information may be good symmetry-breakers in cases\nof one-to-one disagreement, when the numbers of disagreeing parties\nare much larger, the effectiveness of such appeals radically\ndiminishes. Similar considerations apply to most Steadfast Views. Most\ndefenses of Steadfast Views attempt to find a symmetry-breaker in the\npeer-to-peer disagreement that allow for one to privilege one’s\nown belief. For instance, even if self-trust or private evidence can\ngive one a reason to privilege their own belief, such a\nsymmetry-breaker is seemingly not up to the task when the belief in\nquestion is a minority view. Given that most controversial beliefs in\nscience, religion, politics, and philosophy are minority views, it\nappears that even if many Steadfast Views of peer disagreement are\ncorrect, they still face a skeptical challenge regarding disagreement\nmore generally. The notable exception here is the Right Reasons\nView. Since according to the Right Reasons View, what one is justified\nin believing is entirely determined by the first-order evidence, no\namount of discovered disagreement would change which controversial\nbeliefs are rational. While the Right Reasons View, may be safe from\nsuch skeptical concerns, such safety only comes by way of what many\nsee as the feature that makes it implausible. For instance, the Right\nReasons View has it that you can be justified in believing \\(p\\) even\nwhen you are aware that every other peer and superior to you believes\nnot-\\(p\\). While this avoids the more general skeptical threat, many\nsee this as too high a price. \n\nAnother issue concerning how the numbers matter regards the\nindependence of the relevant opinions. Our beliefs are shaped by a\nnumber of factors, and not all of them are epistemically\nrelevant. Certain religious beliefs, political beliefs, and even\nphilosophical beliefs are correlated with growing up in particular\nregions or going to certain schools. For this reason, it may be\nthought that the agreement of individuals who came to their opinions\non a matter independently count for more, epistemically speaking, then\nagreement of individuals with a greater shared background. For more on\nthis issue, see Carey & Matheson 2013, Goldman 2001, and Lackey 2013b. \n\nSo, the phenomenon of disagreement supplies a skeptical\nthreat: for many of our cherished beliefs. If we aren’t\nsheltered, then we know that there is a great deal of controversy\nabout those beliefs even among the people who are the smartest and\nhave worked the hardest in trying to figure out the truth of the\nmatter.  There is good reason to think that retaining a belief in the\nface of that kind of controversy is irrational, and a belief that is\nirrational does not amount to knowledge. It follows that our beliefs\nwe recognize as controversial do not amount to knowledge. This is the\nthreat of disagreement skepticism (Frances 2018, 2013, 2005;\nChristensen 2009; Fumerton 2010; Goldberg 2009, 2013b; Kornblith 2010,\n2013; Lammenranta 2011, 2013; Machuca 2013). \n\nFor the sake of argument, we can assume that our controversial\nbeliefs start out epistemically rational. Roughly put, the\ndisagreement skeptic thinks that even if a controversial belief starts\nout as rational, once one appreciates the surrounding controversy,\none’s belief will no longer be rational, and thus not an item of\nknowledge. The disagreement skeptic focuses on beliefs that satisfy\nthe following recognition-of-controversy conditions. \n\nYou know that the belief \\(B\\) in question has been investigated and\ndebated (i) for a very long time by (ii) a great many (iii) very smart\npeople who (iv) are your epistemic peers and superiors on the matter\nand (v) have worked very hard (vi) under optimal circumstances to\nfigure out if \\(B\\) is true. But you also know that (vii) these\nexperts have not come to any significant agreement on \\(B\\) and (viii)\nthose who agree with you are not, as a group, in an appreciably better\nposition to judge \\(B\\) than those who disagree with you. \n\nNotice that the problem does not emerge from a mere lack of\nconsensus. Very few, if any, beliefs are disagreement-free. Rather,\nthe skeptical threat comes from both the extent of the disagreement\n(conditions (i) and (ii)) and the nature of the disagreeing parties\n(conditions (iii) – (viii)). While not every belief meets these\nrecognition-of-controversy conditions, many do, and among those that\ndo are some of our most cherished beliefs. \n\nFor instance, I might have some opinion regarding the nature of free\nwill or the moral permissibility of capital punishment or whether God\nexists. I know full well that these matters have been debated by an\nenormous number of really smart people for a very long time—in\nsome cases, for centuries. I also know that I’m no expert on any\nof these topics. I also know that there are genuine experts on those\ntopics—at least, they have thought about those topics\nmuch longer than I have, with a great deal more awareness of\nrelevant considerations, etc. It’s no contest: I know I’m\njust an amateur compared to them. Part of being reflective is coming to\nknow about your comparative epistemic status on controversial subjects.\nThat said, being an expert in the relevant field doesn’t remove\nthe problem either. Even if I am an expert on free will, I am aware\nthat there are many other such experts, that I am but one such voice\namong many, and that disagreement is rampant amongst us. \n\nThe person who knows (i)–(viii) is robbed of the reasonableness\nof several comforting responses to the discovery of controversy. If\nshe is reasonable, then she realizes that she can’t make, at\nleast with confidence, anything like the following remarks: \n\nThis phenomenon is particularly prevalent with regard to religion,\npolitics, morality, and philosophy. If when it comes to debates about\nfree will, capital punishment, affirmative action, and many other\nstandard controversial topics you say to yourself regarding the\nexperts who disagree with you ‘Those people just don’t\nunderstand the issues’, ‘They aren’t very\nsmart’, ‘They haven’t thought about it much’,\net cetera, then you are doing so irrationally in the sense\nthat you should know better than to say that, at least if\nyou’re honest with yourself and informed of the state of the\ndebate over free will. \n\nHowever, connection between controversy and skepticism won’t\napply to many of our other beliefs. No one (or no one you know) is\ngoing around saying your parents don’t love you, you\naren’t a basically moral person, etc. So those beliefs are\nprobably immune to any skeptical argument of the form ‘There is\nlong-standing disagreement among experts regarding your belief \\(B\\);\nyou know all about it (viz. conditions (i)–(viii)); you have no\ngood reason to discount the ones who disagree with you; so, you\nshouldn’t retain your belief \\(B\\)’. This is not to say\nthat those beliefs escape all skeptical arguments based on human error\nand related phenomena. But, the first thing to note about disagreement\nskepticism is that it is contained. Only beliefs that meet\nsomething like the recognition-of-controversy conditions are subject\nto this skeptical threat. Interestingly, however, it is not itself\nexempt from these skeptical consequences. Such views of disagreement\nare themselves quite controversial, so here too is another place where\nthe self-defeat worry arises. \n\nDisagreement skepticism is also contingent. The nature and\nextent of disagreements are both contingent matters, so since\ndisagreement skepticism relies on these factors, the skeptical\nconsequences of disagreement are also contingent. At one point in time\nthe shape of the Earth was quite contentious. While there is not now\nuniversal agreement that the Earth is roughly spherical, the\nrecognition-of-controversy conditions are no longer met on this matter.\nSimilarly, issues of great current controversy may too at some point\nfail to meet the recognition-of-controversy conditions. So, the\nskeptical threat from disagreement can come and go. That said, the\ntrack-record for the staying power of various philosophical\ndisagreements strongly indicates that they aren’t going anywhere\nanytime soon. \n\nFinally, disagreement skepticism is exclusively epistemic. At issue\nhere has solely been one’s epistemic reasons for holding a\nbelief. Meeting the recognition-of-controversy conditions raises a\nproblem for these reasons, but we haven’t said anything about\nwhat moral, prudential, or even religious reasons you may have for\nholding a controversial belief. The skeptical threat from disagreement\nonly concerns our epistemic reasons. Relatedly, if there is an\nall-things-considered norm of belief, disagreement skepticism may have\nsome implications for this norm, but only by way of addressing the\nepistemic reasons that one has for belief. \n\nA related point is that these consequences are doxastic\nconsequences. Disagreement skepticism is about what beliefs are/are\nnot rational and which changes in confidence are/are not rational.\nDisagreement skepticism is not a view about which views should be\ndefended or what theses should be further researched. When coupled\nwith the knowledge norm of assertion or the knowledge norm of action,\ndisagreement skepticism would have further consequences about what\nclaims can be asserted or acted upon, but these consequences only\nfollow from such a combination of views.","contact.mail":"bryan.frances@yahoo.com","contact.domain":"yahoo.com"},{"date.published":"2018-02-23","url":"https://plato.stanford.edu/entries/disagreement/","author1":"Bryan Frances","author2":"Jonathan Matheson","author1.info":"http://bryanfrances.weebly.com/","entry":"disagreement","body.text":"\n\n\n\nWe often find ourselves in disagreement with others. You may think\nnuclear energy is so volatile that no nuclear energy plants should be\nbuilt anytime soon. But you are aware that there are many people who\ndisagree with you on that very question. You disagree with your sister\nregarding the location of the piano in your childhood home, with you\nthinking it was in the primary living area and her thinking it was in\nthe small den. You and many others believe Jesus Christ rose from the\ndead; millions of others disagree.\n\n\n\nIt seems that awareness of disagreement can, at least in many cases,\nsupply one with a powerful reason to think that one’s belief is\nfalse. When you learned that your sister thought the piano had been in\nthe den instead of the living room, you acquired a good reason to\nthink it really wasn’t in the living room, as you know full well\nthat your sister is a generally intelligent individual, has the\nappropriate background experience (she lived in the house too), and is\nabout as honest, forthright, and good at remembering events from\nchildhood as you are. If, in the face of all this, you stick with your\nbelief that the piano was in the living room, will your retaining that\nbelief be reasonable?\n\n\n\nIn the piano case there is probably nothing important riding on the\nquestion of what to do in the face of disagreement. But in many cases\nour disagreements are of great weight, both in the public arena and in\nour personal lives. You may disagree with your spouse or partner about\nwhether to live together, whether to get married, where you should\nlive, or how to raise your children. People with political power\ndisagree about how to spend enormous amounts of money, or about what\nlaws to pass, or about wars to fight. If only we were better able to\nresolve our disagreements, we would probably save millions of lives\nand prevent millions of others from living in poverty.\n\n\n\nThis article examines the central epistemological issues tied to the\nrecognition of disagreement.\n\n\n\nCompared to many other topics treated in this encyclopedia, the\nepistemology of disagreement is a mere infant. While the discussion of\ndisagreement isn’t altogether absent from the history of\nphilosophy, philosophers didn’t start, as a group, thinking\nabout the topic in a rigorous and detailed way until the 21st\ncentury. For that reason, it is difficult to know what the primary\nissues and questions are concerning the general topic. At this early\nstage of investigation we are just getting our feet wet. In this\nessay, we begin by trying to motivate what we think should be the\nprimary issues and questions before we move on to look at some of the\nmain ideas in the literature. In so doing we also introduce some new\nterminology and make some novel distinctions that we think are helpful\nin navigating this relatively recent debate.\n\n\n\nTo a certain extent, it may seem that there are just three doxastic\nattitudes to adopt regarding the truth of a claim: believe it’s\ntrue, believe it’s false (i.e., disbelieve it), and suspend\njudgment on it. In the most straightforward sense, two individuals\ndisagree about a proposition when they adopt different doxastic\nattitudes toward the same proposition (i.e., one believes it and one\ndisbelieves it, or one believes it and one suspends judgment). But of\ncourse there are levels of confidence one can have regarding a\nproposition as well. We may agree that global warming is occurring but\nyou may be much more confident than I am. It can be useful to use\n‘disagreement’ to cover any difference in levels of\nconfidence: if \\(X\\) has one level of confidence regarding belief\n\\(B\\)’s truth while \\(Y\\) has a different level of confidence,\nthen they “disagree” about \\(B\\)—even if this is a\nslightly artificial sense of ‘disagree’. These levels of\nconfidence, or degrees of belief, are often represented as point\nvalues on a 0–1 scale (inclusive), with larger values indicating\ngreater degrees of confidence that the proposition is true. Even if\nsomewhat artificial, such representations allow for more precision in\ndiscussing cases. \n\nWe are contrasting disagreements about belief from disagreements about\nmatters of taste. Our focus is on disagreements where there is a fact\nof the matter, or at least the participants are reasonable in\nbelieving that there is such a fact. \n\nSuppose Jop and Dop are college students who are dating. They disagree\nabout two matters: whether it’s harder to get top grades in\neconomics classes or philosophy classes, and whether they should move\nin together this summer. The first disagreement is over the truth\nof a claim: is the claim (or belief) ‘It is harder to get\ntop grades in economics classes compared to philosophy classes’\ntrue or not? The second disagreement is over an action:\nshould we move in together or not (the action = moving in together)?\nCall the first kind of disagreement belief-disagreement; call\nthe second kind action-disagreement. \n\nThe latter is very different from the former. Laksha is a doctor faced\nwith a tough decision regarding one of her patients. She needs to\nfigure out whether it’s best, all things considered, to just\ncontinue with the medications she has been prescribing or stop them\nand go with surgery. She confers closely with some of her\ncolleagues. Some of them say surgery is the way to go, others say she\nshould continue with medications and see what happens, but no one has\na firm opinion: all the doctors agree that it’s a close call,\nall things considered. Laksha realizes that as far as anyone can tell\nit really is a tie. \n\nIn this situation Laksha should probably suspend judgment on each of\nthe two claims ‘Surgery is the best overall option for this\npatient’ and ‘Medication is the best overall option for\nthis patient’. When asked ‘Which option is best?’\nshe should suspend judgment. \n\nThat’s all well and good, but she still has to do\nsomething. She can’t just refuse to treat the patient. Even if\nshe continues to investigate the case for days and days, in effect she\nhas made the decision to not do surgery. She has made a choice even if\nshe dithers. \n\nThe point is this: when it comes to belief-disagreements,\nthere are three broad options with respect to a specific claim:\nbelieve it, disbelieve it, and suspend judgment on it. (And of course\nthere are a great many levels of confidence to take as well.) But when\nit comes to action-disagreements, there are just two options\nwith respect to an action \\(X\\): do \\(X\\), don’t do\n\\(X\\). Suspending judgment just doesn’t exist when it comes to\nan action. Or, to put it a different way, suspending judgment on\nwhether to do \\(X\\) does exist but is pretty much the same thing as\nnot doing \\(X\\), since in both cases you don’t do \\(X\\) (Feldman\n2006c). \n\nThus, there are disagreements over what to believe and\nwhat to do. Despite this distinction, we can achieve some\nsimplicity and uniformity by construing disagreements over what to do\nas disagreements over what to believe. We do it this way: if we\ndisagree over whether to do action \\(X\\), we are disagreeing over the\ntruth of the claim ‘We should do \\(X\\)’ (or ‘I\nshould do \\(X\\)’ or ‘\\(X\\) is the best thing for us to\ndo’; no, these aren’t all equivalent). This translation of\naction-disagreements into claim-disagreements makes it easy for us to\nconstrue all disagreements as disagreements about what to\nbelieve, where the belief may or may not concern an action. Keep in\nmind, though, that this “translation” doesn’t mean\nthat action-disagreements are just like belief-disagreements that\ndon’t involve actions: the former still requires a choice on\nwhat one is actually going to do. \n\nWith those points in mind, we can formulate the primary questions\nabout the epistemology of disagreement. \n\nHowever, it is worth noting that agreement also has\nepistemological implications. If learning that a large number and\npercentage of your epistemic peers or superiors disagree with you\nshould probably make you lower your confidence in your belief, then\nlearning that those same individuals agree with you should probably\nmake you raise your confidence in your belief—provided they have\ngreater confidence in it than you did before you found out about their\nagreement. \n\nIn posing the questions we start with a single individual who realizes\nthat one or more other people disagree/agree with her regarding one of\nher beliefs. We can formulate the questions with regard to just\ndisagreement or to agreement and disagreement; we also have the choice\nof focusing on just agreement/disagreement or going with levels of\nconfidence. \n\nHere are the primary epistemological questions for just disagreement\nand no levels of confidence: Response Question: Suppose you realize that some people\ndisagree with your belief \\(B\\). How must you respond to the\nrealization in order for that response to be epistemically\nrational (or perhaps wise)? \nBelief Question: Suppose you realize that some people disagree with\nyour belief \\(B\\). How must you respond to the realization in order\nfor your subsequent position on \\(B\\) to be epistemically\nrational? \n\nHere are the questions for agreement/disagreement plus levels of\nconviction: Response Question*: Suppose you realize that some people have a\nconfidence level in \\(B\\) that is different from yours. How must you\nrespond to the realization in order for that response to be\nepistemically rational (or perhaps wise)? \nBelief Question*: Suppose you realize that some people have a\nconfidence level in \\(B\\) that is different from yours. How must you\nrespond to the realization in order for your subsequent\nposition on \\(B\\) to be epistemically rational? \n\nA person can start out with a belief that is irrational, obtain some\nnew relevant evidence concerning that belief, respond to that new\nevidence in a completely reasonable way, and yet end up with an\nirrational belief. This fact is particularly important when it comes\nto posing the central questions regarding the epistemology of\ndisagreement (Christensen 2011). \n\nSuppose Bub’s belief that Japan is a totalitarian state, belief\n\\(J\\), is based on a poor reading of the evidence and a raging,\nirrational bias that rules his views on this topic. He has let his\nbias ruin his thinking through his evidence properly. \n\nThen he gets some new information: some Japanese police have been\ncaught on film beating government protesters. After hearing this, Bub\nretains his old confidence level in \\(J\\). \n\nWe take it that when Bub learns about the police, he has not acquired\nsome new information that should make him think ‘Wait a minute;\nmaybe I’m wrong about Japan’. He shouldn’t lose\nconfidence in his belief \\(J\\) merely because he learned some facts\nthat do not cast any doubt on his belief! \n\nThe lesson of this story is this: Bub’s action of\nmaintaining his confidence in his belief as a result of his new\nknowledge is reasonable even though his retained belief itself is\nunreasonable. Bub’s assessment of the original\nevidence concerning \\(J\\) was irrational, but his reaction to the\nnew information was rational; his subsequent belief in \\(J\\)\nwas (still) irrational (because although the video gives a little\nsupport to \\(J\\), it’s not much). The question, ‘Is Bub\nbeing rational after he got his new knowledge?’ has two\nreasonable interpretations: ‘Is his retained belief in \\(J\\)\nrational after his acquisition of the new knowledge?’\nvs. ‘Is his response to the new knowledge rational?’ \n\nOn the one hand, “rationality demands” that upon his\nacquisition of new knowledge Bub drop his belief \\(J\\) that Japan is a\ntotalitarian state: after all, his overall evidence for it is very\nweak. On the other hand, “rationality demands” that upon\nhis acquisition of new knowledge Bub keep his belief \\(J\\) given\nthat that acquisition—which is the only thing that’s\nhappened to him—gives him no reason to doubt \\(J\\). This\nsituation still might strike you as odd. After all, we’re saying\nthat Bub is being rational in keeping an irrational belief! But no:\nthat’s not what we’re saying. The statement ‘Bub is\nbeing rational’ is ambiguous: is it saying that Bub’s\nretained belief \\(J\\) is rational or is it saying that Bub’s\nretaining of that belief was rational? The statement can take on\neither meaning, and the two meanings end up with different verdicts:\nthe retained belief is irrational but the retaining\nof the belief is rational. In the first case, a state is being\nevaluated, in the second, an action is being evaluated. \n\nConsider a more mundane case. Jack hears a bump in the night and\nirrationally thinks there is an intruder in his house (he has long had\nthree cats and two dogs, so he should know by now that bumps are\nusually caused by his pets; further, he has been a house owner long\nenough to know full well that old houses like his make all sorts of\nodd noises at night, pets or no). Jack has irrational belief \\(B\\):\nthere is an intruder upstairs or there is an intruder downstairs. Then\nafter searching upstairs he learns that there is no intruder upstairs.\nClearly, the reasonable thing for him to do is infer that there is an\nintruder downstairs—that’s the epistemically reasonable\ncognitive move to make in response to the new information,\ngiven—despite the fact that the new belief ‘There is an\nintruder downstairs’ is irrational in an evidential sense. \n\nThese two stories show that one’s action of retaining\none’s belief—that intellectual action—can be\nepistemically fine even though the retained belief is not. And, more\nimportantly, we have to distinguish two questions about the\nacquisition of new information (which need not have anything at all to\ndo with disagreement): \n\nThe latter question concerns an intellectual action (an\nintellectual response to the acquisition of new information), whereas\nthe former question concerns the subsequent level of\nconfidence itself, the new confidence level you end up with,\nwhich comes about partially as a causal result of the intellectual\naction. As we have seen with the Japan and intruder stories the\nepistemic reasonableness of the one is partially independent of that\nof the other. \n\nA child has belief \\(B\\) that Hell is a real place located in the\ncenter of the earth. You disagree. This is a case in which you\ndisagree with someone who you recognize to be your epistemic\ninferior on the question of whether \\(B\\) is true. You believe\nthat Babe Ruth was the greatest baseball player ever. Then you find\nout that a sportswriter who has written several books on the history\nof baseball disagrees, saying that so-and-so was the greatest ever. In\nthis case, you realize that you’re disagreeing with\nan epistemic superior on the matter, since you know that\nyou’re just an amateur when it comes to baseball. In a third\ncase, you disagree with your sister regarding the name of the town\nyour family visited on vacation when you were children. You know from\nlong experience that your memory is about as reliable as hers on\nmatters like this one; this is a disagreement with a\nrecognized epistemic peer. \n\nThere are several ways to define the terms ‘superior’,\n‘inferior’, and ‘peer’ (Elga, 2007; see section 5 below). \n\nYou can make judgments about how likely someone is compared to you\nwhen it comes to answering ‘Is belief \\(B\\) true?’\ncorrectly.  If you think she is more likely (e.g., you suppose that\nthe odds that she will answer it correctly are about 90% whereas your\nodds are just around 80%), then you think she is your likelihood\nsuperior on that question; if you think she is less likely, then\nyou think she is your likelihood inferior on that question;\nif you think she is about equally likely, then you think she is\nyour likelihood peer on that question. Another way to\ndescribe these distinctions is by referencing the epistemic position\nof the various parties.  One’s epistemic position describes how\nwell-placed they are, epistemically speaking, with respect to a given\nproposition. The better one’s epistemic position, the more\nlikely one is to be correct. \n\nThere are many factors that help determine one’s epistemic\nposition, or how likely one is to answer ‘Is belief \\(B\\)\ntrue?’ correctly. Here are the main ones (Frances 2014): \n\nCall these Disagreement Factors. Presumably, what determines\nthat \\(X\\) is more likely than \\(Y\\) to answer ‘Is \\(B\\)\ntrue?’ correctly are the differences in the Disagreement Factors\nfor \\(X\\) and \\(Y\\). \n\nFor any given case of disagreement between just two people, the odds\nare that they will not be equivalent on all Disagreement Factors:\n\\(X\\) will surpass \\(Y\\) on some factors and \\(Y\\) will surpass \\(X\\)\non other factors.  If you are convinced that a certain person is\nclearly lacking compared to you on many Disagreement Factors when it\ncomes to answering the question ‘Is \\(B\\) true?’ then\nyou’ll probably say that you are more likely than she is to\nanswer the question correctly provided you are not lacking compared to\nher on other Disagreement Factors. If you are convinced that a certain\nperson definitely surpasses you on many Disagreement Factors when it\ncomes to answering ‘Is \\(B\\) true?’ then you’ll\nprobably say that you are less likely than she is to answer the\nquestion correctly provided you have no advantage over her when it\ncomes to answering ‘Is \\(B\\) true?’. If you think the two\nof you differ in Disagreement Factors but the differences do not add\nup to one person having a net advantage (so you think any differences\ncancel out), then you’ll think you are peers on that\nquestion. \n\nNotice that in this peer case you need not think that the two of you\nare equal on each Disagreement Factor. On occasion, a philosopher will\ndefine ‘epistemic peer’ so that \\(X\\) and \\(Y\\) are peers\non belief \\(B\\) if and only if they are equal on all\nDisagreement Factors.  If \\(X\\) and \\(Y\\) are equal on all\nDisagreement Factors, then they will be equally likely to judge \\(B\\)\ncorrectly, but the reverse does not hold.  Deficiencies of a peer in\none area may be accounted for by advantages in other areas with the\nfinal result being that the two individuals are in an equivalently\ngood epistemic position despite the existence of some inequalities\nregarding particular disagreement factors. \n\nIn order to understand the alternative definitions of\n‘superior’, ‘inferior’, and\n‘peer’, we will look at two cases of disagreement (Frances\n2014). \n\nSuppose I believe \\(B\\), that global warming is happening. Suppose I\nalso believe \\(P\\), that Taylor is my peer regarding \\(B\\) in this\nsense: I think we are equally likely to judge \\(B\\) correctly. I have\nthis opinion of Taylor because I figure that she knows about as well\nas I do the basic facts about expert consensus, she understands and\nrespects that consensus about as much as I do, and she based her\nopinion of \\(B\\) on those facts. (I know she has some opinion on \\(B\\)\nbut I have yet to actually hear her voice it.) Thus, I think she is\nmy likelihood peer on \\(B\\). \n\nBut in another sense I don’t think she is my peer on\n\\(B\\). After all, if someone asked me ‘Suppose you find out\nlater today that Taylor sincerely thinks \\(B\\) is false. What do you\nthink are the odds that you’ll be right and she’ll be\nwrong about \\(B\\)?’ I would reply with ‘Over 95%!’ I\nwould answer that way because I’m very confident in\n\\(B\\)’s truth and if I find out that Taylor disagrees with that\nidea, then I will be quite confident that she’s wrong and\nI’m right. So in that sense I think I have a definite\nepistemic advantage over her: given how confident I am in \\(B\\),\nI think that if it turns out we disagree over \\(B\\), there is a 95%\nchance I’m right and she’s wrong. Of course, given that I\nthink that we are equally likely to judge \\(B\\) correctly and\nI’m very confident in \\(B\\), I’m also very confident that\nshe will judge \\(B\\) to be true; so when I’m asked to think\nabout the possibility that Taylor thinks \\(B\\) is false, I think\nI’m being asked to consider a very unlikely scenario. But the\nimportant point here is this: if I have the view that if it turns out\nthat she really thinks \\(B\\) is false then the odds that I’m\nright and she’s wrong are 95%, then in some sense my view is\nthat she’s not “fully” my peer on \\(B\\), as I think\nthat when it comes to the possibility of disagreement I’m very\nconfident that I will be in the right and she won’t be. \n\nNow consider another case. Suppose Janice and Danny are the same age\nand take all the same math and science classes through high school.\nThey are both moderately good at math. In fact, they almost always get\nthe same grades in math. On many occasions they come up with different\nanswers for homework problems. As far as they have been able to\ndetermine, in those cases 40% of the time Janice has been right, 40%\nof the time Danny has been right, and 20% of the time they have both\nbeen wrong. Suppose they both know this interesting fact about their\ntrack records! Now they are in college together. Danny believes, on\nthe basis of their track records, that on the next math problem they\nhappen to disagree about, the probability that Janice’s answer\nis right equals the probability that his answer is right—unless\nthere is some reason to think one of them has some advantage in this\nparticular case (e.g., Danny has had a lot more time to work on it, or\nsome other significant discrepancy in Disagreement Factors). Suppose\nfurther that on the next typical math problem they work on Danny\nthinks that neither of them has any advantage over the other this time\naround. And then Danny finds out that Janice got an answer different\nfrom his. \n\nIn this math case Danny first comes to think that \\(B\\) (his answer)\nis true. But he also thinks that if he were to discover that Janice\nthinks \\(B\\) is false, the probability that he is right and Jan is\nwrong are equal to the probability that he is wrong and Janice is\nright. That’s very different from the global warming case in\nwhich I thought that if I were to discover that Taylor thinks \\(B\\) is\nfalse, the probability that I’m right and she’s wrong are\n19 times the probability that I’m wrong and she’s right\n(95% is 19 times 5%). \n\nLet’s say that I think you’re my conditional peer\non \\(B\\) if and only if before I find out your view on \\(B\\) but after\nI have come to believe \\(B\\) I think that if it turns out\nthat you disbelieve \\(B\\), then the chance that I’m\nright about \\(B\\) is equal to the chance that you’re right about\n\\(B\\). So although I think Taylor is my likelihood peer on the global\nwarming belief, I don’t think she is my conditional peer on that\nbelief.  I think she is my conditional inferior on that matter. But in\nthe math case Danny thinks Janice is his likelihood peer and\nhis conditional peer on the relevant belief. \n\nSo, central to answering the Response Question and the Belief\nQuestion is the following: \n\nPut in terms of levels of confidence we get the following: \n\nThe Better Position Question is often not very easy to answer. For\nthe majority of cases of disagreement, with \\(X\\) realizing she disagrees\nwith \\(Y\\), \\(X\\) will not have much evidence to think \\(Y\\) is her peer, superior,\nor inferior when it comes to correctly judging \\(B\\). For instance, if I am\ndiscussing with a neighbor whether our property taxes will be\nincreasing next year, and I discover that she disagrees with me, I may\nhave very little idea how we measure up on the Disagreement Factors. I\nmay know that I have more raw intelligence than she has, but I probably\nhave no idea how much she knows about local politics, how much she has\nthought about the issue before, etc. I will have little basis for\nthinking I’m her superior, inferior, or peer. We can call these\nthe unknown cases. Thus, when you discover that you disagree\nwith someone over \\(B\\), you need not think, or have reason to think, that\nshe is your peer, your superior, or your inferior when it comes to\njudging \\(B\\). \n\nA related question is whether there is any important difference\nbetween cases where you are justified in believing your interlocutor\nis your peer and cases where you may be justified in believing that\nyour interlocutor is not your peer but lack any reason to think that\nyou, or your interlocutor, are in the better epistemic\nposition. Peerhood is rare, if not entirely a fictional idealization,\nyet in many real-world cases of disagreement we are not justified in\nmaking a judgment regarding which party is better positioned to answer\nthe question at hand. The question here is whether different answers\nto the Response Question and the Belief Question are to be given in\nthese two cases.  Plausibly, the answer is no. An analogy may help. It\nis quite rare for two people to have the very same weight. So for any\ntwo people it is quite unlikely that they are ‘weight\npeers’. That said, in many cases it may be entirely unclear\nwhich party weighs more than the other party, even if they agree that\nit is unreasonable to believe they weigh the exact same\namount. Rational decisions about what to do where the weight of the\nparty matters do not seem to differ in cases where there are\n‘weight peers’ and cases where the parties simply lack a\ngood reason to believe either party weighs more. Similarly, it seems\nthat the answers to the Response Question and the Belief Question will\nnot differ in cases of peer disagreement and cases where the parties\nsimply lack any good reason to believe that either party is\nepistemically better positioned on the matter. \n\nAnother challenge in answering the Better Position Question occurs\nwhen you are a novice about some topic and you are trying to determine\nwho the experts on the topic are. This is what Goldman terms the\n‘novice/expert problem’ (Goldman 2001). While novices\nought to turn to experts for intellectual guidance, a novice in some\ndomain seems ill-equipped to even determine who the experts in that\ndomain are. Hardwig (1985, 1991) claims that such novice reliance on\nan expert must necessarily be blind, and thus exhibit an unjustified\ntrust. In contrast, Goldman explores five potential evidential sources\nfor reasonably determining someone to be an expert in a domain: \n\nThe vast majority of the literature on the epistemic significance of\ndisagreement, however, concerns recognized peer disagreement (for\ndisagreement with superiors, see Frances 2013). We turn now to this\nissue. \n\nBefore we begin our discussion of peer disagreements it is important\nto set aside a number of cases. Epistemic peers with respect to \\(P\\)\nare in an equally good epistemic position with respect to \\(P\\). Peers\nabout \\(P\\) can both be in a very good epistemic position with respect\nto \\(P\\), or they could both be in a particularly bad epistemic\nposition with respect to \\(P\\). Put differently, two fools could be\npeers. However, disagreement between fool peers has not been of\nparticular epistemic interest in the literature. The literature on\npeer disagreement has instead focused on disagreement between\ncompetent epistemic peers, where competent peers with respect to \\(P\\)\nare in a good epistemic position with respect to \\(P\\)—they are\nlikely to be correct about \\(P\\). Our discussion of peer disagreement\nwill be restricted to competent peer disagreement. In the\nliterature on peer disagreements, four main views have emerged: the\nEqual Weight View, the Steadfast View, the Justificationist View, and\nthe Total Evidence View. \n\nThe Equal Weight View is perhaps the most prominently discussed view\non the epistemic significance of disagreement. Competitor views of\npeer disagreements are best understood as a rejection of various\naspects of the Equal Weight View, so it is a fitting place to begin\nour examination. As we see it, the Equal Weight View is a combination\nof three claims: \nDefeat: Learning that a peer disagrees with you about \\(P\\)\ngives you a reason to believe you are mistaken about \\(P\\). \nEqual Weight: The reason to think you are mistaken about\n\\(P\\) coming from your peer’s opinion about \\(P\\) is just as\nstrong as the reason to think you are correct about \\(P\\) coming from\nyour opinion about \\(P\\). \nIndependence: Reasons to discount your peer’s opinion\nabout \\(P\\) must be independent of the disagreement itself. \n\nDefenses of the Equal Weight View in varying degrees can be found in\nBogardus 2009, Christensen 2007, Elga 2007, Feldman 2006, and Matheson\n2015a. Perhaps the best way to understand the Equal Weight View comes\nfrom exploring the motivation that has been given for the view. We can\ndistinguish between three broad kinds of support that have been given\nfor the view: examining central cases, theoretical considerations, and\nthe use of analogies. The central case that has been used to motivate\nthe Equal Weight View is Christensen’s Restaurant Check\nCase. \n\nUnderstood as a case of peer disagreement, where the friends have a\ntrack record of being equally good at such calculation, and where\nneither party has a reason to believe that on this occasion either\nparty is especially sharp or dull, Christensen claims that upon\nlearning of the disagreement regarding the shares he should become\nsignificantly less confident that the shares are $43 and significantly\nmore confident that they are $45. In fact, he claims that these\ncompetitor propositions ought to be given roughly equal credence. \n\nThe Restaurant Check Case supports Defeat since in learning\nof his peer’s belief, Christensen becomes less justified in his\nbelief. His decrease in justification is seen by the fact that he must\nlower his confidence to be in a justified position on the issue.\nLearning of the disagreement gives him reason to revise and an\nopportunity for epistemic improvement. Further, the Restaurant Check\nCase supports Equal Weight, since the reason Christensen\ngains to believe he is mistaken is quite strong. Since he should be\nequally confident that the shares are $45 as that they are $43, his\nreasons equally support these claims. Giving the peer opinions equal\nweight has typically been understood to require ‘splitting the\ndifference’ between the peer opinions, at least when the two\npeer opinions exhaust one’s evidence about the opinions on the\nmatter.  Splitting the difference is a kind of doxastic compromise\nthat calls for the peers to meet in the middle. So, if one peer\nbelieves \\(P\\) and one peer disbelieves \\(P\\), giving the peer\nopinions equal weight would call for each peer to suspend judgment\nabout \\(P\\). Applied to the richer doxastic picture that includes\ndegrees of belief, if one peer as a 0.7 degree of belief that \\(P\\)\nand the other has a 0.3 degree of belief that \\(P\\), giving the peer\nopinions equal weight will call for each peer to adopt a 0.5 degree of\nbelief that \\(P\\). It is important to note that what gets\n‘split’ is the peer attitudes, not the content of the\nrelevant propositions. For instance, in the Restaurant Check Case,\nsplitting the difference does not require believing that the shares\nare $44. Perhaps it is obvious that the shares are not an even amount.\nSplitting the difference is only with respect to the disparate\ndoxastic attitudes concerning any one proposition (the disputed target\nproposition). The content of the propositions believed by the parties\nare not where the compromise occurs. Finally, the Restaurant Check\nCase supports Independence. The reasons that Christensen\ncould have to discount his peer’s belief about the shares could\ninclude that he had a little too much to drink tonight, that he is\nespecially tired, that Christensen double checked but his friend\ndidn’t, etc., but could not include that the shares actually are\n$43, that Christensen disagrees, etc. \n\nTheoretical support for the Equal Weight View comes from first\nthinking about ordinary cases of testimony. Learning that a reliable\ninquirer has come to believe a proposition gives you a reason to\nbelieve that proposition as well. The existence of such a reason does\nnot seem to depend upon whether you already have a belief about that\nproposition. Such testimonial evidence is some evidence to believe the\nproposition regardless of whether you agree, disagree, or have never\nconsidered the proposition. This helps motivate Defeat, since\na reason to believe the proposition when you disbelieve it amounts to\na reason to believe that you have made a mistake regarding that\nproposition. Similar considerations apply to more fine-grained degrees\nof confidence. Testimonial evidence that a reliable inquirer has\nadopted a 0.8 degree of belief that \\(P\\) gives you a reason to adopt\na 0.8 degree of belief toward \\(P\\), and this seems to hold regardless\nof whether you already have a level of confidence that \\(P\\). \n\nEqual Weight is also motivated by considerations regarding\ntestimonial evidence. The weight of a piece of testimonial evidence is\nproportional to the epistemic position of the testifier (or what the\nhearer’s evidence supports about the epistemic position of the\ntestifier). So, if you have reason to believe that Jai’s\nepistemic position with respect to \\(P\\) is inferior to Mai’s,\nthen discovering that Jai believes \\(P\\) will be a weaker reason to\nbelieve \\(P\\) than discovering that Mai believes \\(P\\). However, in\ncases of peer disagreement, both parties are in an equally good\nepistemic position, so it would follow that their opinions on the\nmatter should be given equal weight. \n\nFinally, Independence has been theoretically motivated by\nexamining what kind of reasoning its denial would permit. In\nparticular, a denial of independence has been thought to permit a\nproblematic kind of question-begging by allowing one to use\none’s own reasoning to come to the conclusion that their peer is\nmistaken.  Something seems wrong with the following line of reasoning,\n“My peer believes not-\\(P\\), but I concluded \\(P\\), so my peer\nis wrong” or “I thought \\(S\\) was my peer, but \\(S\\)\nthinks not-\\(P\\), and I think \\(P\\), so \\(S\\) is not my peer after\nall” (see Christensen (2011). Independence forbids both of these\nways of blocking the reason to believe that you are mistaken from the\ndiscovery of the disagreement. \n\nThe Equal Weight View has also been motivated by way of analogies.  Of\nparticular prominence are analogies to thermometers. Thermometers take\nin pieces of information as inputs and given certain temperature\nverdicts as outputs. Humans are a kind of cognitive machine that takes\nin various kinds of information as inputs and give doxastic attitudes\nas outputs. In this way, humans and thermometers are\nanalogous. Support for the Equal Weight View has come from examining\nwhat it would be rational to believe in a case of peer thermometer\ndisagreement. Suppose that you and I know we have equally reliable\nthermometers and while investigating the temperature of the room we\nare in discover that our thermometers give different outputs (yours\nreads ‘75’ and mine reads ‘72’). What is it\nrational for us to believe about the room temperature? It seems it\nwould be irrational for me to continue believing it was 72 simply\nbecause that was the output of the thermometer that I was\nholding. Similarly, it seems irrational for me to believe that your\nthermometer is malfunctioning simply because my thermometer gave a\ndifferent output. It seems that I would need some information\nindependent from this ‘disagreement’ to discount your\nthermometer. So, it appears that I have been given a reason to believe\nthat the room’s temperature is not 72 by learning of your\nthermometer, that this reason is as strong as my reason to believe it\nis 72, and that this reason is only defeated by independent\nconsiderations. If the analogy holds, then we have reason to accept\neach of the three theses of the Equal Weight View. \n\nThe Equal Weight View is not the only game in town when it comes to\nthe epistemic significance of disagreement. In what follows we will\nexamine the competitor views of disagreement highlighting where and\nwhy they depart from the Equal Weight View. \n\nOn the spectrum of views on the epistemic significance of\ndisagreement, the Equal Weight View and the Steadfast View lie on\nopposite ends. While the Equal Weight View is quite conciliatory, the\nSteadfast View maintains that sticking to one’s guns in a case\nof peer disagreement can be rational. That is, discovering a peer\ndisagreement does not mandate any doxastic change. While the Equal\nWeight View may be seen to emphasize intellectual humility, the\nSteadfast View emphasizes having the courage of your convictions.\nDifferent motivations for Steadfast Views can be seen to reject\ndistinct aspects of the Equal Weight View. We have organized the\nvarious motivations for the Steadfast View according to which aspect\nof the Equal Weight View it (at least primarily) rejects. \n\nDefeat has been rejected by defenders of the Steadfast View\nin a number of ways. First, Defeat has been denied with an\nappeal to private evidence. Peter van Inwagen (1996) has defended the\nSteadfast View by maintaining that in cases of peer disagreement one\ncan appeal to having an incommunicable insight or special evidence\nthat the other party lacks. The basic idea is that if I have access to\na special body of evidence that my peer lacks access to, then\nrealizing that my peer disagrees with me need not give me a reason to\nthink that I’ve made any mistake. After all, my peer\ndoesn’t have everything that I have to work with regarding an\nevaluation of \\(P\\) and it can be reasonable to think that if the peer\nwere to be aware of everything that I am aware of, she would also\nshare my opinion on the matter. Further, some evidence is undoubtedly\nprivate. While I can tell my peer about my intuitions or my\nexperiences, I cannot give him my intuitions or experiences. Given our\nlimitations, peers can never fully share their evidence. However, if\nthe evidence isn’t fully shared, then my peer evaluating his\nevidence one way needn’t show that I have mis-evaluated my\nevidence. Our evidence is importantly different. While van\nInwagen’s claims may entail that the two disagreeing parties are\nnot actually peers due to their evidential differences, these\nconsideration may be used to resist Defeat at least on looser\nconceptions of peerhood that do not require evidential equality. \n\nA related argument is made by Huemer (2011), who argues for an\nagent-centered account of evidence. On this account, an experience\nbeing your own evidentially counts for more than someone\nelse’s experience. So, with this conception of evidence in hand\nthere will be an important evidential asymmetry even in cases where\nboth parties share all their evidence. \n\nDefenders of the Equal Weight View have noted that these\nconsiderations cut both ways (see Feldman 2006). For\ninstance, while you may not be able to fully share your evidence with\nyour peer, these same considerations motivate that your peer similarly\ncannot fully share his or her evidence with you. So, the symmetry that\nmotivated the Equal Weight View may still obtain since both parties\nhave private evidence. A relevant asymmetry only obtains if one has\nspecial reason to believe that their body of private evidence is\nprivileged over their peer’s, and the mere fact that it is\none’s own would not do this. Feldman’s Dean on the Quad\ncase can also help make this clear. \n\nFeldman takes this case to be one where both parties should\nsignificantly conciliate even though it is clear that both possess\nprivate evidence. While both parties can report about their\nexperience, neither party can give their experience to the other. The\nexperiential evidence possessed by each party is private. So, if\nconciliation is still called for, we have reason to question the\nsignificance of private evidence. \n\nSecond, Defeat has been denied by focusing on how things seem\nto the subject. Plantinga (2000a) has argued that there is a sense of\njustification that is simply doing the best that one can. Plantinga\nnotes that despite all the controlled variables an important asymmetry\nremains even in cases of peer disagreement. In cases where I believe\n\\(P\\) and I discover that my peer disbelieves \\(P\\), often \\(P\\) will\ncontinue to seem true to me. That is, there is an important\nphenomenological difference between the two peers—different\nthings seem true to them. Plantinga claims that given that we are\nfallible epistemic creatures some amount of epistemic risk is\ninevitable, and given this, we can do no better than believe in\naccordance with what seems true to us. So, applied to cases of peer\ndisagreement, even upon learning that my peer disbelieves \\(P\\), so\nlong as \\(P\\) continues to seem true to me, it is rational for me to\ncontinue to believe. Any reaction to the disagreement will contain\nsome epistemic risk, so I might as well go with how things seem to\nme. A similar defense of Steadfast Views which emphasizes the\nphenomenology of the subject can be found in Henderson et\nal. 2017. \n\nWhile an individual may not be to blame for continuing to believe as\nthings seem to them, defenders of the Equal Weight View have claimed\nthat the notion of epistemic justification at issue here is distinct. Sometimes doing the best one can is insufficient, and\nwhile some epistemic risk is inevitable, it does not follow that the\noptions are equally risky. While your belief may still seem true to\nyou having discovered the disagreement, other things that seem true to\nyou are relevant as well. For instance, it will seem to you that your\ninterlocutor is an epistemic peer (that they are in an equally good\nepistemic position on the matter) and that they disagree with you.\nThose additional seeming states have epistemological import. In\nparticular, they give you reason to doubt that the truth about the\ndisputed belief is as it seems to you. The mere fact that your belief\ncontinues to seem true to you is unable to save its justificatory\nstatus. Consider the Müller-Lyer illusion: \n\nTo most, line \\(B\\) seems to be longer, but a careful measurement\nreveals that \\(A\\) and \\(B\\) are of equal lengths. Despite knowing of\nthe illusion, however, line \\(B\\) continues to seem longer to many.\nNevertheless, given that it also seems that a reliable measuring\nindicates that the lines are of equal length, one is not justified in\nbelieving that \\(B\\) is longer, despite it continuing to seem that\nway. This result holds even when we appreciate our fallibility and\nthe fallibility of measuring instruments. A parallel account appears\nto apply to cases of peer disagreement. Even if your original belief\ncontinues to seem true to you, you have become aware of information\nthat significantly questions that seeming state. Further, we can\nimagine a scenario where \\(P\\) seems true to me and I subsequently\ndiscover 10,000 peers and superiors on the issue that disagree with me\nabout \\(P\\).  Nevertheless, when I contemplate \\(P\\), it still seems\ntrue to me. In such a case, sticking to my guns about \\(P\\) seems to\nneither be doing the best that I can nor the reasonable thing to\ndo. \n\nThird, Defeat has been denied by denying that peer opinions about\n\\(P\\) are evidence that pertains to \\(P\\). Kelly (2005) distinguishes\nthe following three claims: \n\nKelly (2005) argues that while 3 is evidence for 2 it is not evidence\nfor 1. If 3 is not evidence for 1, then in learning 3 (by discovering\nthe peer disagreement) one does not gain any evidence relevant to the\ndisputed proposition. If learning of the peer disagreement\ndoesn’t affect one’s evidence relevant to the disputed\nproposition, then such a discovery makes no change for which doxastic\nattitude is justified for the peers to take toward the target\nproposition. On this view, the discovery of peer disagreement makes no\ndifference for what you should believe about the disputed\nproposition. \n\nWhy think that 3 is not evidence for 1? Kelly (2005) cites several\nreasons. First, when people cite their justification for their\nbeliefs, they do not typically cite things like 3. We typically treat\nthe fact that someone believes a proposition as the result of\nthe evidence for that proposition, not as another piece of\nevidence for that proposition. Second, since people form beliefs on\nthe basis of a body of evidence, to count their belief as yet another\npiece of evidence would amount to double-counting that original body\nof evidence. On this line of thought, one’s belief that \\(P\\)\nserves as something like a place-holder for the evidence upon which\none formed the belief. So, to count both the belief and the original\nevidence would be to double-count the original evidence, and\ndouble-counting is not a legitimate way of counting. \n\nDefenders of the Equal Weight View have responded by claiming that the\nimpropriety in citing one’s own belief as evidence for the\nproposition believed can be explained in ways that do not require that\none’s belief is not in fact evidence. For instance, it could be\nthat conversational maxims would be violated since the fact that one\nbelieves the proposition is already understood to be the case by the\nother party. Alternatively, citing one’s own belief as evidence\nmay exhibit hubris in a way that many would want to avoid. Finally, it\nseems clear that someone else’s belief that \\(P\\) can be\nevidence for \\(P\\), so denying that the subject’s belief can be\nevidence for the subject entails a kind of relativity of evidence that\nsome reject.  Regarding the double-counting, it has been argued that\nthe fact that a reliable evidential evaluator has evaluated a body of\nevidence to support a proposition is a new piece of evidence, one that\nat least enhances the support between the body of evidence and the\ntarget proposition. For instance, that a forensic expert evaluates the\nrelevant forensic evidence to support the defendant’s guilt\nappears to be an additional piece of evidence in favor of the\ndefendant’s guilt, rather than a mere repetition of that initial\nforensic evidence. \n\nFinally, Defeat has been denied by appealing to epistemic\npermissiveness. The Equal Weight View, and Defeat in\nparticular, has been thought to rely on the Uniqueness Thesis. \n\nIf a body of evidence can only support one doxastic attitude between\nbelief, disbelief, and suspension of judgment with respect to \\(P\\),\nand two people who share their evidence disagree about \\(P\\), then one\nof them must have an unjustified attitude. So, if the Uniqueness\nThesis is true, there is a straightforward route\nto Defeat. However, if evidence is permissive, allowing for\nmultiple distinct justified attitudes toward the same proposition,\nthen discovering that someone has evaluated your shared evidence\ndifferently than you have need not give you any reason to think that\nyou have made a mistake. If evidence is permissive, then you may both\nhave justified responses to the shared evidence even though you\ndisagree. So, another way to motivate the Steadfast View is to endorse\nevidential permissiveness. For reasons to reject or doubt the\nUniqueness Thesis, see Ballantyne and Coffman 2011, Conee 2009,\nFrances 2014, Goldman 2010, Kelly 2010, Kopec 2015, Raleigh 2017,\nRosen 2001, and Rosa 2012. \n\nDefenses of the Equal Weight View either defend the Uniqueness Thesis\n(see Dogramici and Horowitz 2016, Greco and Hedden 2016, Matheson\n2011, White 2005, White 2013) or argue that the Equal Weight View is\nnot actually committed to evidential uniqueness (see Christensen 2009,\nChristensen 2016, Cohen 2013, Lee 2003, Levinstein 2017, Peels and\nBooth 2014, and Henderson et al 2017). \n\nThe Steadfast View has also been motivated by denying Equal\nWeight. If your peer’s opinion about \\(P\\) does not count\nfor as much as your own opinion, then you may not need to make any\ndoxastic conciliation. While most find it implausible that your own\nopinion can count for more merely because it is your own, a related\nand more plausible defense comes from appealing to self-trust. Enoch\n(2010), Foley (2001), Pasnau (2015), Schafer (2015), Wedgwood (2007;\n2010), and Zagzebski (2012) have all appealed to self-trust in\nresponding to peer disagreements. Foley emphasizes the essential and\nineliminable role of first-personal reasoning. Applied to cases of\ndisagreement, Foley claims, “I am entitled to make what I can of\nthe conflict using the faculties, procedures, and opinions I have\nconfidence in, even if these faculties, procedures, and opinions are\nthe very ones being challenged by others” (2001, 79). Similarly,\nWedgwood asserts that it is rational to have a kind of egocentric\nbias—a fundamental trust in one’s own faculties and mental\nstates. On this account, while peer disagreements have a kind of\nsymmetry from the third-person perspective, neither party occupies\nthat perspective.  Rather, each party to the disagreement has a\nfirst-person perspective from which it is rational to privilege\nitself. Self-trust is fundamental and the trust that one must place in\none’s own faculties and states simply cannot be given to\nanother. \n\nOpponents have rejected the epistemic importance of the first-person\nperspective (see Bogardus 2013b and Rattan 2014). While\nthe first-person perspective is ineliminable, it is not infallible.\nFurther, there are reasons from the first-person perspective to make\ndoxastic conciliation. It is my evidence the supports that my\ninterlocutor is my peer and my evidence about what she\nbelieves which call for doxastic change. So, conciliation can be seen\nto be called for from within the first-person perspective. One\nneedn’t, and indeed cannot, abandon one’s own perspective\nin dealing with disagreement. There are also worries concerning what\nsuch an emphasis on self-trust would permit. If self-trust is relevant\nin cases of peer disagreement, it is difficult to see how it is not\nrelevant in cases of novice-expert disagreement. However, most\nmaintain that when the novice learns that the expert disagrees he\nshould make some doxastic movement if not completely defer. So,\nself-trust cannot be the ultimate deciding factor in all cases of\ndisagreement. \n\nA final motivation for the Steadfast View comes from re-evaluating the\nevidential support relations in a case of peer disagreement. It will\nbe helpful here to distinguish between two kinds of evidence. \nFirst-Order Evidence: First-order evidence for \\(P\\) is evidence\nthat directly pertains to \\(P\\). \nHigher-Order Evidence: Higher-order evidence for \\(P\\) is evidence\nabout one’s evidence for \\(P\\). \n\nSo, the cosmological argument, the teleological argument, and the\nproblem of evil are all items of first-order evidence regarding\nGod’s existence, whereas the fact that a competent evaluator of\nsuch evidence finds it to on balance support God’s existence is a\npiece of higher-order evidence that God exists. That a competent\nevidential evaluator has evaluated a body of evidence to support a\nproposition is evidence that the body of evidence in question does in\nfact support that proposition. \n\nApplied to cases of peer disagreement, the first-order evidence is\nthe evidence directly pertaining to the disputed proposition, and each\npeer opinion about the disputed proposition is the higher-order\nevidence (it is evidence that the first-order evidence supports the\nrespective attitudes). \n\nThe Right Reasons View is a steadfast view of peer disagreement that\nemphasizes the role of the shared first-order evidence in peer\ndisagreements. Following Kelly (2005) we can represent the discovery of\na peer disagreement as follows: \n\nAccording to the Right Reasons View, the two pieces of higher-order\nevidence (ii) and (iii) are to be accorded equal weight. Having\nweighed (ii) and (iii) equally, they neutralize in my total body of\nevidence at t’. However, with (ii) and (iii) neutralized, I am\nleft with (i) and am justified in believing what (i) supports. The\nRight Reasons View then notes that what I am justified in believing at\n\\(t\\) and what I am justified in believing at t’ is exactly the\nsame. In both cases what I should believe is entirely a matter of what\n\\(E\\) supports, so what matters in a case of peer disagreement is what\nthe first-order evidence supports. If I believed in accordance with my\nevidence at \\(t\\), then learning of the peer disagreement does nothing\nto alter what I should believe about \\(P\\) at \\(t_2\\). Having rightly\nresponded to my reasons at \\(t\\), nothing epistemically changes\nregarding what attitude I should have toward \\(P\\). \n\nThis argument for the Right Reasons View has been responded to in\nseveral ways. Kelly (2010) has since rejected the argument, claiming\nthat when a greater proportion of one’s evidence supports\nsuspending judgment some conciliation will be called for. Since the\nhigher-order evidence calls for suspending judgment regarding the\ndisputed proposition, there will be a conciliatory push even if the\noriginal first order evidence still plays an important role in what\nattitude is justified. Others have responded to the argument by\nrejecting Kelly’s original description of the case (see Matheson\n2009). If my evidence at \\(t\\) includes not only the first-order\nevidence, but also the higher-order evidence about myself (ii), then\neven if the new piece of higher-order evidence gained at \\(t'\\),\n(iii), cancels out (ii) this will still call for some doxastic\nconciliation from \\(t\\) to \\(t'\\). Alternatively, (ii) and (iii) can\nbe seen to together call for a suspension of judgment over whether\n\\(E\\) supports \\(P\\). Some have argued that a justified suspension of\njudgment over whether your evidence supports \\(P\\) has it that your\ntotal evidence supports a suspension of judgment toward \\(P\\) (see\nFeldman 2006 and Matheson 2015a). See Lasonen-Aarnio 2014 for an\nalternative view of the impact of higher-order evidence. \n\nA more recent defense of the Right Reasons View is found in\nTitelbaum 2015. Titelbaum argues for the Fixed Point Thesis –\nthat mistakes about rationality are mistakes of rationality. In other\nwords, it is always a rational mistake to have a false belief about\nrationality. So, on this view a false belief about what attitude is\nrational does not ‘trickle down’ to affect the rationality\nof the lower-level belief. Given this, if an individual’s initial\nresponse to the evidence is rational, no amount of misleading\nhigher-order evidence affects the rationality of that belief. A correct\nresponse to the first-order evidence remains correct regardless of what\nhigher-order evidence is added. \n\nA remaining problem for the Right Reasons View is its verdicts in\nparadigm cases of peer disagreement. Many have the strong intuition\nthat conciliation is the Restaurant Check Case regardless of whether\nyou correctly evaluated the first-order evidence. \n\nOn the spectrum of views of the epistemic significance of\ndisagreement, the Justificationist View lies somewhere in between the\nEqual Weight View and the Steadfast View. In defending the\nJustificationist View, Jennifer Lackey agrees with the Equal Weight\nView’s verdicts in cases like the Restaurant Check Case, but\nthinks that not all cases should be handled in this way. Along these\nlines she gives the following: \n\nIn Elementary Math, Lackey finds it implausible that she should\nbecome less confident that 2+2=4, never mind to split the difference\nwith her interlocutor and suspend judgment about the matter. In other\nwords, the claim is that the Equal Weight Views gives the wrong\nverdicts in what we might call cases of ‘extreme\ndisagreement’. What justifies treating Elementary Math\ndifferently than the Restaurant Check Case? According to Lackey, if\nprior to discovering the peer disagreement you are highly justified in\nbelieving the soon to be disputed proposition, then upon discovering\nthe peer disagreement little to no conciliation is called for. So,\nsince Lackey is highly justified in believing that 2+2=4 prior to\ntalking to her colleague, not conciliation is called for, but since\nChristensen was not highly justified in believing that the shares are\n$43 prior to discovering the disagreement, a great deal of conciliation\nis called for. According to the Justificationist View, one’s\nantecedent degree of justification determines the rational response to\npeer disagreement. Strong antecedent justification for believing the\ntarget proposition matters since when coupled with the discovered\ndisagreement you now have reasons to believe your interlocutor is not\nyour peer after all. In Elementary Math, Lackey should significantly\nrevise her views about her colleague’s epistemic position\nregarding elementary math. In contrast, the Restaurant Check Case calls\nfor no similar demotion. This difference is explained by the differing\ndegrees of antecedent justification. \n\nApplied to our framework, the Justificationist View denies\nIndependence. In cases where you first-order evidence strongly\nsupports believing p, this fact can be used to reassess your\ninterlocutor’s epistemic credentials. Independence only\npermitted information from ‘outside’ the disagreement to\naffect assessment of peerhood credentials, but here, the fact that your\ninterlocutor disagrees with something you are highly justified in\nbelieving give you a reason to discount his opinion on the matter. \n\nLackey defends the legitimacy of such a demotion due to the\nexistence of personal information. In any case of peer disagreement, I\nwill have information about myself that I simply lack (or lack to the\nsame extent) regarding my interlocutor. I will always be more aware of\nmy alertness, sincerity, open-mindedness, and so forth, than I will be\nof my interlocutor. A similar claim is defended in Benjamin 2015. This\nasymmetry, when coupled with my high antecedent justification for\nbelieving the disputed proposition makes it rational to demote my\nalleged peer. Since in extreme disagreements one party is severely\nmalfunctioning, my personal information makes the best explanation of\nthis fact that it is my peer who is malfunctioning. \n\nThe Justificationist View has been criticized in several ways. Some\nobject that high antecedent justification for believing the target\nproposition can make the relevant difference (see Christensen 2007,\nVavova 2014a, 2014b). Consider the following case: \n\nIn this case, I have very high antecedent justification for\nbelieving that your ticket is not a winner. Nevertheless, upon hearing\nyou exclaim that you won, the rational response is not to downgrade\nyour epistemic credentials. Even high antecedent justification can be\ndefeated by new information. \n\nOthers have agreed that personal information can act as symmetry\nbreaker giving the subject some reason to privilege their own view but\ndeny that such an advantage would be had in suitably idealized cases of\npeer disagreement (Matheson 2015a). The use of personal information to\ndiscount your interlocutor’s opinion would not violate\nIndependence, so the defender of the Equal Weight View\nneedn’t disagree on this score. \n\nLike the Justificationist View, the Total Evidence View lies somewhere\nbetween the Steadfast View and the Equal Weight View. The Total\nEvidence View claims that in cases of peer disagreement, one is\njustified in believing what one’s total evidence supports (Kelly\n2010). While this might sound like something of a truism, central to\nthe view is an additional claim about the relation between first-order\nevidence and higher-order evidence. Let’s first revisit the\nEqual Weight View. According to the Equal Weight View, in a peer\ndisagreement where one individual has a 0.7 degree of belief that\n\\(P\\) and the other has a 0.3 degree of belief that \\(P\\), both peers\nshould split the difference and adopt a 0.5 degree of belief that\n\\(P\\). On the Equal Weight View, then, the attitude that you are\njustified in adopting toward the disputed proposition is entirely\ndetermined by the higher-order evidence. The justified attitude is the\nmean between the two peer attitudes, which ignores what their shared\nfirst-order evidence supports. According to the Total Evidence View,\nthis is a mistake – the first-order evidence must also factor in\nto what the peers are reasonable in believing. Such an incorporation\nof the first-order evidence is what leads to the name “Total\nEvidence View”. \n\nKelly gives the following case to motivate the view: \n\nWhile the Equal Weight View seems to be committed to the peers being\njustified in adopting the 0.8 degree of belief in \\(H\\), Kelly finds such a\nconsequence implausible. After all, both peers badly misjudged the\nfirst-order evidence! This argument can be seen as an argument against\nIndependence. In these cases, the disputed first-order\nevidence can exert an ‘upwards epistemic push” to mitigate\nthe impact of the higher-order evidence. Kelly takes Independence on\ndirectly with the following case: \n\nIndependence claims that my reasons for believing \\(P\\) cannot\nbe used to discount my interlocutor’s opinion about \\(P\\). Absent\nthose first-order reasons, however, Kelly doubts that there is much\nleft to work with the discount the interlocutor, and the drastic\nconciliation that should result without a good reason to discount his\nopinion is implausible. \n\nThis motivation for the Total Evidence View has been responded to in\nseveral different ways. One route of response is deny Kelly’s\nassessment of the cases (Matheson 2015a). According to this response,\nthe individuals in Bootstrapping were both presented with powerful,\nthough misleading, higher-order evidence. However, misleading evidence\nis evidence nevertheless. Given this, it can be argued that the\nindividuals still correctly responded to their total body of evidence.\nFor instance, we can imagine a logician working on a new proof. Suppose\nthat it seems to him that he has successfully completed the proof, yet\nhe nevertheless has made a subtle error rendering the whole thing\ninvalid. In such a case, the logician has significantly mis-evaluated\nhis first-order evidence, yet he has strong higher-order evidence that\nhe is good at things like this. Suppose he then shows his work to a\ncapable colleague who also maintains that the proof is successful. In\nthis case, it may seem that it is rational for the logician to believe\nthat the proof is successful, and perhaps be quite confident, even\nthough this conclusion is significantly different from what the\nfirst-order evidence supports. According to this rejoinder, the call to\nsplit the difference is best seen as addressing the Belief\nQuestion. \n\nA second route of response is to emphasize the distinction between\nthe Response Question and the Belief Question. According to this\nresponse, while there may be something epistemically defective about\nthe final doxastic states of the individuals in Bootstrapping, they\nnevertheless had the rational response to the higher-order evidence\n(Christensen 2011). The fact that they each misjudged the original\nevidence is an epistemic flaw that carries over to their final doxastic\nattitude, but on this line of thinking the doxastic response that each\nparty made upon comparing notes was nevertheless rational. According to\nthis rejoinder, the call to split the difference is best seen as\naddressing the Response Question. \n\nOther objections to the Equal Weight View are not tied to any other\nparticular view of disagreement, and some apply to more than just the\nEqual Weight View. In this section we briefly examine some of these\nobjections. \n\nA prominent objection to the Equal Weight View and other views that\nprescribe doxastic conciliation is that such views are self-defeating.\nFor expressions of this objection, see Elga 2010, Frances 2010,\nO’Connor 1999, Plantinga 2000a and 2000b, Taliaferro 2009,\nWeatherson 2014, and Weintraub 2013. For responses, see Bogardus 2009,\nChristensen 2009, Elga 2010, Graves 2013, Kornblith 2013, Littlejohn\n2013, Matheson 2015b, and Pittard 2015. In brief, there is disagreement\nabout the epistemic significance of disagreement itself, so any view\nthat calls for conciliation upon the discovery of disagreement can have\nit that it calls for its own rejection. For instance, a defender of the\nEqual Weight View could become aware of enough individuals that are\nsuitably epistemically well-positioned on the epistemology of\ndisagreement that nevertheless deny that the Equal Weight View is\ncorrect. Following the prescriptions of the Equal Weight View would\nrequire this defender to abandon the view, and perhaps even accept a\ncompetitor account. For these reasons, Plantinga (2000a) has claimed\nthat such views are, ‘self-referentially inconsistent’\n(522) and Elga (2010) has claimed that such views are\n‘incoherent’ and ‘self-undermining’ (179). Such\na worry seems to apply to the Equal Weight View, the Justificationist\nView, and the Total Evidence View. Since all three views prescribe\nconciliation in at least some cases, they are all (at least in\nprinciple) subject to such a result. \n\nDefenders of these conciliatory views have responded in a number of\nways. First, some emphasize the way in which these views are\nself-defeating is not a way that shows these views to be false, or\nincapable of being true. ‘No true sentences have\nmore than 5 words’ may also be said to be self-defeating, but\nthis is a different kind of defeat. At its worst, the consequences here\nfor conciliatory views is that given certain contingent circumstances\nthey cannot be reasonably believed, but such an inability to be\nreasonably believed does not demonstrate their falsity. Further, a\nskeptical attitude toward the epistemic significance of disagreement\nseems to fit the spirit of these views quite well (more on this\nbelow). \n\nAnother way such a consequence has been downplayed is by comparing\nit to other principles that share the same result. Along these lines,\nChristensen gives the following: \n\nThe principle of Minimal Humility is quite plausible, yet there are\ncontingent circumstances under which it calls for its own rejection\ntoo. If such a consequence is untenable, then it would call for the\nrejection of principles beyond those endorsed by the Equal Weight View,\nthe Justificationist View, and the Total Evidence View. \n\nA final response argues that these principles about disagreement are\nthemselves exempt from their conciliatory prescriptions. So, correctly\nunderstood, these principles call for conciliation in ordinary\ndisagreements, but prescribe remaining steadfast in disagreements about\ndisagreements. So on this view, the true principles are not\nself-defeating. Several philosophers have endorsed such a response to\nthe self-defeat worry. Bogardus (2009) argues that we can ‘just\nsee’ that conciliatory principles are true and this prevents them\nfrom being self-undermining. Elga (2010) argues that conciliatory\nviews, properly understood, are self-exempting since fundamental\nprinciples must be dogmatic about their own correctness. Pittard (2015)\nargues that remaining resolute in conciliationism is no more\nnon-deferential than being conciliatory about conciliationism. The\nreasoning here is that to conciliate about one’s conciliatory\nprinciples would be deferential about one’s belief or credence,\nbut steadfast about one’s reasoning. So, once we appreciate the\ndistinct levels of belief/credence and reasoning, either response to a\ndisagreement about the significance of disagreement will require being\nsteadfast at one level. This, argues Pittard, makes remaining steadfast\nabout conciliationism unproblematic. \n\nWhile such responses would avoid the self-defeat charge, some see it\nguilty of arbitrariness (see Pittard 2015, Blessenohl 2015). \n\nA further set of issues regarding the Equal Weight View come from\nconsiderations within formal epistemology. Fitelson and Jelhe (2009)\nargue that there are difficulties in making precise the Equal Weight\nView along Bayesian lines. In particular, they argue that the most\nintuitive understandings of the Equal Weight View have untenable\nconsequences. Gardiner (2014) and Wilson (2010) each raise an\nobjection that Equal Weight View (at least as typically understood)\nviolates the principle of commutativity of evidence. If we imagine an\nindividual encountering a number of disagreeing peers sequentially,\nthen which doxastic attitude is reasonable for the peer will depend\nupon the order at which the peers are confronted. However, the\nprinciple of commutativity of evidence claims that the order of\nevidential acquisition should not make such a\ndifference. Lasonen-Arnio (2013) sets up a trilemma for the Equal\nWeight View arguing that either (i) it violates intuitively correct\nupdates, (ii) it places implausible restrictions on priors, or (iii)\nit is non-substantive. \n\nAnother issue concerns which disagreements are of epistemic\nsignificance. While actual peer disagreement is rare, if not\nnon-existent (see below), merely possible peer disagreement is\neverywhere. For any belief you have, it is possible that an epistemic\npeer of yours disagrees. Since we are fallible epistemic agents,\npossible peer disagreement is inevitable. One challenge is to\ndistinguish the epistemic significance of actual peer disagreement\nfrom the significance of merely possible peer disagreement. Kelly\n(2005) first raises this challenge. After all, whether this possible\ndisagreeing peer actually exists is a contingent and fragile matter,\nso to only care about it may be to exhibit an ‘actual world\nchauvinism’. (This term comes from Carey 2011.) \n\nChristensen (2007) responds to this challenge by noting that while\nmerely possible disagreement only shows that we are fallible, actual\ndisagreement demonstrates that someone has in fact made a mistake.\nSince we are already aware that we are fallible epistemic agents,\nthinking about possible peer disagreements does not add any information\nthat calls for (further) doxastic change. In contrast, discovering an\nactual peer disagreement gives us information that we lacked. In a case\nof peer disagreement, one of the parties has made a mistake. While the\npossibility of error does not demand belief revision, an increase in\nthe probability of having made an error does. \n\nA further question is whether actual peer disagreements are the only\npeer disagreements with epistemic significance. For instance, suppose\nthat you have created an argument that you find sound in the solitude\nof your office. When thinking about what your (peer) colleague would\nthink, suppose that you reasonably conclude that she would disagree\nabout the merits of your argument. If such a conclusion is reasonable\nfor you, then it seems that this fact should have some epistemic\nconsequences for you despite the fact that there is not (at least as of\nyet) any actual disagreement. Arguably, such a merely possible\ndisagreement even has the same epistemic significance as an actual\ndisagreement (see Carey & Matheson 2013). Similarly, if an evil\ntyrant believes \\(P\\) and then chooses to eliminate all disagreeing peers\nwho believe not-\\(P\\), he would not thereby become justified in his\npreviously contentious belief (Kelly 2005). A challenge is to pick out\nwhich merely possible disagreements are epistemically significant,\nsince at the risk of global skepticism, clearly not all are (Barnett\nand Li 2017). Issues surrounding counterfactual disagreement are also\nexamined in Ballantyne 2013b, Bogardus 2016, and Morgensen 2016. \n\nA final issue concerns peer disagreement itself. As some have noted,\nepistemic peers are extremely rare, if not non-existent (Frances 2010,\n2014; King 2011; Matheson 2014). After all, what are the odds\nthat someone else is in precisely as good of an epistemic position as\nyou on some matter—and even she was, would you know it? As we\nhave seen, there are a number of disagreement factors, and the odds\nthat they end in a tie between any two individuals at any given time is\nquite unlikely. The paucity of peers may be taken to show that the\ndebate of the epistemic significance of peer disagreement is a futile\nexercise in extreme hypotheticals. After all, if you have no epistemic\npeers that disagree with you, doesn’t the epistemic threat from\ndisagreement dissolve? Further, there may seem to have been a deceptive\nshift in the debate. Much of the puzzle of disagreement is motivated by\nmessy real world cases of disagreement, but the vast majority of the\nliterature is focused on idealized cases of disagreement that rarely,\nif ever, occur. \n\nThere are several reasons to think about the significance of peer\ndisagreement beyond its intrinsic appeal. First, considering the\nidealized cases of peer disagreement helps to isolate the epistemic\nsignificance of the disagreement itself. By controlling for other\nepistemic factors, cases of peer disagreement help us focus on what\nepistemic effects discovered disagreement has. While in non-idealized\ncases this is but one factor in determining what to believe, the debate\nabout peer disagreements attempts to help us better understand this one\nfactor. Second, while peers may be quite rare, as we have noted above,\nit is often not clear which party is in the better epistemic position.\nFor instance, while it is quite rare for two individuals to be the\nexact same weight, it can often be unclear which individual weighs\nmore. These unknown cases may have the same epistemic significance as\npeer cases. If what is needed is a positive reason to privilege\none’s own view, as opposed to positive reasons to think that the\nother is a peer, then unknown cases should be treated like peer\ncases. \n\nIn what follows we turn to examining the epistemic significance of\ndisagreement outside of these idealized cases of peer disagreement. \n\nMany disagreements are one-on-one: one person disagrees with another\nperson and as far as they know they are the only two who have any\nopinion on the matter. Lisa thinks that she and Marie should move in\ntogether; then Lisa discovers that Marie has the opposite opinion. Bob\nand his sister Teri disagree about whether their father had an affair\nwhen they were children. In this case they know that others have the\nanswer—their father, for one—but for various reasons the\nopinions of others are not accessible. \n\nMany other disagreements involve just a few people. Bob, Rob, Hob, and\nGob work in a small hotel and are wondering whether to ask for raises\nin their hourly pay rate. After discussion Bob thinks they should, Rob\nand Hob think they shouldn’t, and Gob is undecided.  When Bob\nlearns all this about his three colleagues, what should his doxastic\nreaction be to this mixed bag of agreement and disagreement? \n\nHowever, when it comes to many of your beliefs, including some of the\nmost interesting ones, you are fully aware that millions of\npeople disagree with you and millions of other people agree\nwith you. Just consider a belief about religion—just about any\nbelief at all, pro or con. You must have some views on\ncontroversial matters; virtually every human does. Moreover,\nyou’re perfectly aware that they are controversial. For the most\npart, it’s not as though you believe \\(B\\), \\(B\\) happens to be\ncontroversial, but you had no idea it was controversial. \n\nMoreover, when it comes to these controversial beliefs that large\nnumbers of people have taken positions on, it’s often the case\nthat there are experts on the matter. In many cases the experts have a\ndefinite opinion: global warming is happening and the earth is many\nmillions of years old. Other times they don’t: electrons and\nquarks come from “strings”. \n\nIf the numbers matter, then disagreement poses a skeptical threat for\nnearly every view of the significance of peer disagreement. The\nskeptical threat for conciliatory views (the Equal Weight View, the\nJustificationist View, and the Total Evidence View) is pretty\nstraightforward. On the Equal Weight View, since for many\ncontroversial beliefs we are not justified in believing that the\nweighing of opinions favors our own opinion on the matter, the reasons\nfor thinking that we are mistaken outweigh our reasons for thinking we\nare correct. The added resources of the Justificationist View and the\nTotal Evidence View also do not seem to help in resisting the\nskeptical conclusion.  For many controversial views we lack the strong\nfirst-order evidence and high antecedent justification that these\nviews utilize to mitigate the call to conciliate. Further, while\nappeals to personal information may be good symmetry-breakers in cases\nof one-to-one disagreement, when the numbers of disagreeing parties\nare much larger, the effectiveness of such appeals radically\ndiminishes. Similar considerations apply to most Steadfast Views. Most\ndefenses of Steadfast Views attempt to find a symmetry-breaker in the\npeer-to-peer disagreement that allow for one to privilege one’s\nown belief. For instance, even if self-trust or private evidence can\ngive one a reason to privilege their own belief, such a\nsymmetry-breaker is seemingly not up to the task when the belief in\nquestion is a minority view. Given that most controversial beliefs in\nscience, religion, politics, and philosophy are minority views, it\nappears that even if many Steadfast Views of peer disagreement are\ncorrect, they still face a skeptical challenge regarding disagreement\nmore generally. The notable exception here is the Right Reasons\nView. Since according to the Right Reasons View, what one is justified\nin believing is entirely determined by the first-order evidence, no\namount of discovered disagreement would change which controversial\nbeliefs are rational. While the Right Reasons View, may be safe from\nsuch skeptical concerns, such safety only comes by way of what many\nsee as the feature that makes it implausible. For instance, the Right\nReasons View has it that you can be justified in believing \\(p\\) even\nwhen you are aware that every other peer and superior to you believes\nnot-\\(p\\). While this avoids the more general skeptical threat, many\nsee this as too high a price. \n\nAnother issue concerning how the numbers matter regards the\nindependence of the relevant opinions. Our beliefs are shaped by a\nnumber of factors, and not all of them are epistemically\nrelevant. Certain religious beliefs, political beliefs, and even\nphilosophical beliefs are correlated with growing up in particular\nregions or going to certain schools. For this reason, it may be\nthought that the agreement of individuals who came to their opinions\non a matter independently count for more, epistemically speaking, then\nagreement of individuals with a greater shared background. For more on\nthis issue, see Carey & Matheson 2013, Goldman 2001, and Lackey 2013b. \n\nSo, the phenomenon of disagreement supplies a skeptical\nthreat: for many of our cherished beliefs. If we aren’t\nsheltered, then we know that there is a great deal of controversy\nabout those beliefs even among the people who are the smartest and\nhave worked the hardest in trying to figure out the truth of the\nmatter.  There is good reason to think that retaining a belief in the\nface of that kind of controversy is irrational, and a belief that is\nirrational does not amount to knowledge. It follows that our beliefs\nwe recognize as controversial do not amount to knowledge. This is the\nthreat of disagreement skepticism (Frances 2018, 2013, 2005;\nChristensen 2009; Fumerton 2010; Goldberg 2009, 2013b; Kornblith 2010,\n2013; Lammenranta 2011, 2013; Machuca 2013). \n\nFor the sake of argument, we can assume that our controversial\nbeliefs start out epistemically rational. Roughly put, the\ndisagreement skeptic thinks that even if a controversial belief starts\nout as rational, once one appreciates the surrounding controversy,\none’s belief will no longer be rational, and thus not an item of\nknowledge. The disagreement skeptic focuses on beliefs that satisfy\nthe following recognition-of-controversy conditions. \n\nYou know that the belief \\(B\\) in question has been investigated and\ndebated (i) for a very long time by (ii) a great many (iii) very smart\npeople who (iv) are your epistemic peers and superiors on the matter\nand (v) have worked very hard (vi) under optimal circumstances to\nfigure out if \\(B\\) is true. But you also know that (vii) these\nexperts have not come to any significant agreement on \\(B\\) and (viii)\nthose who agree with you are not, as a group, in an appreciably better\nposition to judge \\(B\\) than those who disagree with you. \n\nNotice that the problem does not emerge from a mere lack of\nconsensus. Very few, if any, beliefs are disagreement-free. Rather,\nthe skeptical threat comes from both the extent of the disagreement\n(conditions (i) and (ii)) and the nature of the disagreeing parties\n(conditions (iii) – (viii)). While not every belief meets these\nrecognition-of-controversy conditions, many do, and among those that\ndo are some of our most cherished beliefs. \n\nFor instance, I might have some opinion regarding the nature of free\nwill or the moral permissibility of capital punishment or whether God\nexists. I know full well that these matters have been debated by an\nenormous number of really smart people for a very long time—in\nsome cases, for centuries. I also know that I’m no expert on any\nof these topics. I also know that there are genuine experts on those\ntopics—at least, they have thought about those topics\nmuch longer than I have, with a great deal more awareness of\nrelevant considerations, etc. It’s no contest: I know I’m\njust an amateur compared to them. Part of being reflective is coming to\nknow about your comparative epistemic status on controversial subjects.\nThat said, being an expert in the relevant field doesn’t remove\nthe problem either. Even if I am an expert on free will, I am aware\nthat there are many other such experts, that I am but one such voice\namong many, and that disagreement is rampant amongst us. \n\nThe person who knows (i)–(viii) is robbed of the reasonableness\nof several comforting responses to the discovery of controversy. If\nshe is reasonable, then she realizes that she can’t make, at\nleast with confidence, anything like the following remarks: \n\nThis phenomenon is particularly prevalent with regard to religion,\npolitics, morality, and philosophy. If when it comes to debates about\nfree will, capital punishment, affirmative action, and many other\nstandard controversial topics you say to yourself regarding the\nexperts who disagree with you ‘Those people just don’t\nunderstand the issues’, ‘They aren’t very\nsmart’, ‘They haven’t thought about it much’,\net cetera, then you are doing so irrationally in the sense\nthat you should know better than to say that, at least if\nyou’re honest with yourself and informed of the state of the\ndebate over free will. \n\nHowever, connection between controversy and skepticism won’t\napply to many of our other beliefs. No one (or no one you know) is\ngoing around saying your parents don’t love you, you\naren’t a basically moral person, etc. So those beliefs are\nprobably immune to any skeptical argument of the form ‘There is\nlong-standing disagreement among experts regarding your belief \\(B\\);\nyou know all about it (viz. conditions (i)–(viii)); you have no\ngood reason to discount the ones who disagree with you; so, you\nshouldn’t retain your belief \\(B\\)’. This is not to say\nthat those beliefs escape all skeptical arguments based on human error\nand related phenomena. But, the first thing to note about disagreement\nskepticism is that it is contained. Only beliefs that meet\nsomething like the recognition-of-controversy conditions are subject\nto this skeptical threat. Interestingly, however, it is not itself\nexempt from these skeptical consequences. Such views of disagreement\nare themselves quite controversial, so here too is another place where\nthe self-defeat worry arises. \n\nDisagreement skepticism is also contingent. The nature and\nextent of disagreements are both contingent matters, so since\ndisagreement skepticism relies on these factors, the skeptical\nconsequences of disagreement are also contingent. At one point in time\nthe shape of the Earth was quite contentious. While there is not now\nuniversal agreement that the Earth is roughly spherical, the\nrecognition-of-controversy conditions are no longer met on this matter.\nSimilarly, issues of great current controversy may too at some point\nfail to meet the recognition-of-controversy conditions. So, the\nskeptical threat from disagreement can come and go. That said, the\ntrack-record for the staying power of various philosophical\ndisagreements strongly indicates that they aren’t going anywhere\nanytime soon. \n\nFinally, disagreement skepticism is exclusively epistemic. At issue\nhere has solely been one’s epistemic reasons for holding a\nbelief. Meeting the recognition-of-controversy conditions raises a\nproblem for these reasons, but we haven’t said anything about\nwhat moral, prudential, or even religious reasons you may have for\nholding a controversial belief. The skeptical threat from disagreement\nonly concerns our epistemic reasons. Relatedly, if there is an\nall-things-considered norm of belief, disagreement skepticism may have\nsome implications for this norm, but only by way of addressing the\nepistemic reasons that one has for belief. \n\nA related point is that these consequences are doxastic\nconsequences. Disagreement skepticism is about what beliefs are/are\nnot rational and which changes in confidence are/are not rational.\nDisagreement skepticism is not a view about which views should be\ndefended or what theses should be further researched. When coupled\nwith the knowledge norm of assertion or the knowledge norm of action,\ndisagreement skepticism would have further consequences about what\nclaims can be asserted or acted upon, but these consequences only\nfollow from such a combination of views.","contact.mail":"jonathan.matheson@gmail.com","contact.domain":"gmail.com"}]
