[{"date.published":"2001-11-10","date.changed":"2020-10-16","url":"https://plato.stanford.edu/entries/model-theory/","author1":"Wilfrid Hodges","author1.info":"http://wilfridhodges.co.uk/","entry":"model-theory","body.text":"\n\n\nModel theory began with the study of formal languages and their\ninterpretations, and of the kinds of classification that a particular\nformal language can make. Mainstream model theory is now a\nsophisticated branch of mathematics (see the entry on\n first-order model theory).\n But in a broader sense, model theory is the study of the\ninterpretation of any language, formal or natural, by means of\nset-theoretic structures, with Alfred Tarski’s\n truth definition\n as a paradigm. In this broader sense, model theory meets philosophy\nat several points, for example in the theory of logical consequence\nand in the semantics of natural languages. \n\nSometimes we write or speak a sentence \\(S\\) that expresses nothing\neither true or false, because some crucial information is missing\nabout what the words mean. If we go on to add this information, so\nthat \\(S\\) comes to express a true or false statement, we are said to\ninterpret \\(S\\), and the added information is called an\ninterpretation of \\(S\\). If the interpretation \\(I\\) happens\nto make \\(S\\) state something true, we say that \\(I\\) is a\nmodel of \\(S\\), or that \\(I\\) satisfies \\(S\\), in\nsymbols ‘\\(I \\vDash S\\)’. Another way of saying that \\(I\\)\nis a model of \\(S\\) is to say that \\(S\\) is true in \\(I\\),\nand so we have the notion of model-theoretic truth, which is\ntruth in a particular interpretation. But one should remember that the\nstatement ‘\\(S\\) is true in \\(I\\)’ is just a paraphrase of\n‘\\(S\\), when interpreted as in \\(I\\), is true’; so\nmodel-theoretic truth is parasitic on plain ordinary truth, and we can\nalways paraphrase it away. \nFor example I might say \nand offer the interpretation that ‘he’ is Alfonso\nArblaster of 35 The Crescent, Beetleford, and that ‘them’\nare the pigeons in his loft. This interpretation explains (a) what\nobjects some expressions refer to, and (b) what classes some\nquantifiers range over. (In this example there is one quantifier:\n‘all of them’). Interpretations that consist of items (a)\nand (b) appear very often in model theory, and they are known as\nstructures. Particular kinds of model theory use particular\nkinds of structure; for example mathematical model theory tends to use\nso-called first-order structures, model theory of modal\nlogics uses Kripke structures, and so on.  \nThe structure \\(I\\) in the previous paragraph involves one fixed\nobject and one fixed class. Since we described the structure today,\nthe class is the class of pigeons in Alfonso’s loft today, not\nthose that will come tomorrow to replace them. If Alfonso Arblaster\nkills all the pigeons in his loft today, then \\(I\\) satisfies the\nquoted sentence today but won’t satisfy it tomorrow, because\nAlfonso can’t kill the same pigeons twice over. Depending on\nwhat you want to use model theory for, you may be happy to evaluate\nsentences today (the default time), or you may want to record how they\nare satisfied at one time and not at another. In the latter case you\ncan relativise the notion of model and write ‘\\(I \\vDash_t\nS\\)’ to mean that \\(I\\) is a model of \\(S\\) at time \\(t\\). The\nsame applies to places, or to anything else that might be picked up by\nother implicit indexical features in the sentence. For example if you\nbelieve in possible worlds, you can index \\(\\vDash\\) by the possible\nworld where the sentence is to be evaluated. Apart from using set\ntheory, model theory is completely agnostic about what kinds of thing\nexist. \nNote that the objects and classes in a structure carry labels that\nsteer them to the right expressions in the sentence. These labels are\nan essential part of the structure. \nIf the same class is used to interpret all quantifiers, the class is\ncalled the domain or universe of the structure. But\nsometimes there are quantifiers ranging over different classes. For\nexample if I say \nyou will look for an interpretation that assigns a class of diseases\nto ‘those thingummy diseases’ and a class of birds to\n‘the birds’. Interpretations that give two or more classes\nfor different quantifiers to range over are said to be\nmany-sorted, and the classes are sometimes called the\nsorts.  \nThe ideas above can still be useful if we start with a sentence \\(S\\)\nthat does say something either true or false without needing further\ninterpretation. (Model theorists say that such a sentence is fully\ninterpreted.) For example we can consider\nmisinterpretations \\(I\\) of a fully interpreted sentence\n\\(S\\). A misinterpretation of \\(S\\) that makes it true is known as a\nnonstandard or unintended model of \\(S\\). The branch\nof mathematics called nonstandard analysis is based on nonstandard\nmodels of mathematical statements about the real or complex number\nsystems; see\n Section 4\n below. \nOne also talks of model-theoretic semantics of natural\nlanguages, which is a way of describing the meanings of\nnatural language sentences, not a way of giving them\nmeanings. The connection between this semantics and model theory is a\nlittle indirect. It lies in Tarski’s truth definition of 1933.\nSee the entry on\n Tarski’s truth definitions\n for more details. \nA sentence \\(S\\) divides all its possible interpretations into two\nclasses, those that are models of it and those that are not. In this\nway it defines a class, namely the class of all its models, written\n\\(\\Mod(S)\\). To take a legal example, the sentence  \ndefines a class of structures which take the form of labelled\n4-tuples, as for example (writing the label on the left):  \nThis is a typical model-theoretic definition, defining a class of\nstructures (in this case, the class known to the lawyers as\ntrusts).  \nWe can extend the idea of model-theoretic definition from a single\nsentence \\(S\\) to a set \\(T\\) of sentences; \\(\\Mod(T)\\) is the class\nof all interpretations that are simultaneously models of all the\nsentences in \\(T\\). When a set \\(T\\) of sentences is used to define a\nclass in this way, mathematicians say that \\(T\\) is a theory\nor a set of axioms, and that \\(T\\) axiomatises the\nclass \\(\\Mod(T)\\). \nTake for example the following set of first-order sentences: \nHere the labels are the addition symbol ‘+’, the minus\nsymbol ‘\\(-\\)’ and the constant symbol ‘0’. An\ninterpretation also needs to specify a domain for the quantifiers.\nWith one proviso, the models of this set of sentences are precisely\nthe structures that mathematicians know as abelian groups.\nThe proviso is that in an abelian group \\(A\\), the domain should\ncontain the interpretation of the symbol 0, and it should be closed\nunder the interpretations of the symbols + and \\(-\\). In mathematical\nmodel theory one builds this condition (or the corresponding\nconditions for other function and constant symbols) into the\ndefinition of a structure.  \nEach mathematical structure is tied to a particular first-order\nlanguage. A structure contains interpretations of certain predicate,\nfunction and constant symbols; each predicate or function symbol has a\nfixed arity. The collection \\(K\\) of these symbols is called the\nsignature of the structure. Symbols in the signature are\noften called nonlogical constants, and an older name for them\nis primitives. The first-order language of signature \\(K\\) is\nthe first-order language built up using the symbols in \\(K\\), together\nwith the equality sign =, to build up its atomic formulas. (See the\nentry on\n classical logic.)\n If \\(K\\) is a signature, \\(S\\) is a sentence of the language of\nsignature \\(K\\) and \\(A\\) is a structure whose signature is \\(K\\),\nthen because the symbols match up, we know that \\(A\\) makes \\(S\\)\neither true or false. So one defines the class of abelian groups to be\nthe class of all those structures of signature \\(+\\), \\(-\\), \\(0\\) which are\nmodels of the sentences above. Apart from the fact that it uses a\nformal first-order language, this is exactly the algebraists’\nusual definition of the class of abelian groups; model theory\nformalises a kind of definition that is extremely common in\nmathematics. \nNow the defining axioms for abelian groups have three kinds of symbol\n(apart from punctuation). First there is the logical symbol = with a\nfixed meaning. Second there are the nonlogical constants, which get\ntheir interpretation by being applied to a particular structure; one\nshould group the quantifier symbols with them, because the structure\nalso determines the domain over which the quantifiers range. And third\nthere are the variables \\(x, y\\) etc. This three-level pattern of\nsymbols allows us to define classes in a second way. Instead of\nlooking for the interpretations of the nonlogical constants that will\nmake a sentence true, we fix the interpretations of the\nnonlogical constants by choosing a particular structure \\(A\\), and we\nlook for assignments of elements of \\(A\\) to variables which will make\na given formula true in \\(A\\). \nFor example let \\(\\mathbb{Z}\\) be the additive group of integers. Its\nelements are the integers (positive, negative and 0), and the symbols\n\\(+\\), \\(-\\), \\(0\\) have their usual meanings. Consider the formula \nIf we assign the number \\(-3\\) to \\(v_1\\) and the number \\(-6\\) to\n\\(v_2\\), the formula works out as true in \\(\\mathbb{Z}\\). We express\nthis by saying that the pair \\((-3,-6)\\) satisfies this\nformula in \\(\\mathbf{Z}\\). Likewise (15,30) and (0,0) satisfy\nit, but \\((2,-4)\\) and (3,3) don’t. Thus the formula\ndefines a binary relation on the integers, namely the set of\npairs of integers that satisfy it. A relation defined in this way in a\nstructure \\(A\\) is called a first-order definable relation in\n\\(A\\). A useful generalisation is to allow the defining formula to use\nadded names for some specific elements of \\(A\\); these elements are\ncalled parameters and the relation is then definable with\nparameters.  \nThis second type of definition, defining relations inside a structure\nrather than classes of structure, also formalises a common\nmathematical practice. But this time the practice belongs to geometry\nrather than to algebra. You may recognise the relation in the field of\nreal numbers defined by the formula \nIt’s the circle of radius 1 around the origin in the real plane.\nAlgebraic geometry is full of definitions of this kind.  \nDuring the 1940s it occurred to several people (chiefly Anatolii\nMal’tsev in Russia, Alfred Tarski in the USA and Abraham\nRobinson in Britain) that the metatheorems of classical logic could be\nused to prove mathematical theorems about classes defined in the two\nways we have just described. In 1950 both Robinson and Tarski were\ninvited to address the International Congress of Mathematicians at\nCambridge Mass. on this new discipline (which as yet had no name\n– Tarski proposed the name ‘theory of models’ in\n1954). The conclusion of Robinson’s address to that Congress is\nworth quoting: \nIn fact Mal’tsev had already made quite deep applications of\nmodel theory in group theory several years earlier, but under the\npolitical conditions of the time his work in Russia was not yet known\nin the West. By the end of the twentieth century, Robinson’s\nhopes had been amply fulfilled; see the entry on\n first-order model theory. \nThere are at least two other kinds of definition in model theory\nbesides these two above. The third is known as interpretation\n(a special case of the interpretations that we began with). Here we\nstart with a structure \\(A\\), and we build another structure \\(B\\)\nwhose signature need not be related to that of \\(A\\), by defining the\ndomain \\(X\\) of \\(B\\) and all the labelled relations and functions of\n\\(B\\) to be the relations definable in \\(A\\) by certain formulas with\nparameters. A further refinement is to find a definable equivalence\nrelation on \\(X\\) and take the domain of \\(B\\) to be not \\(X\\) itself\nbut the set of equivalence classes of this relation. The structure\n\\(B\\) built in this way is said to be interpreted in the\nstructure \\(A\\). \nA simple example, again from standard mathematics, is the\ninterpretation of the group \\(\\mathbb{Z}\\) of integers in the\nstructure \\(\\mathbb{N}\\) consisting of the natural numbers 0, 1, 2\netc. with labels for 0, 1 and +. To construct the domain of\n\\(\\mathbb{Z}\\) we first take the set \\(X\\) of all ordered pairs of\nnatural numbers (clearly a definable relation in \\(\\mathbb{N})\\), and\non this set \\(X\\) we define the equivalence relation \\(\\sim\\) by \n(again definable). The domain of \\(\\mathbb{Z}\\) consists of the\nequivalence classes of this relation. We define addition on\n\\(\\mathbb{Z}\\) by  \nThe equivalence class of \\((a,b)\\) becomes the integer \\(a - b\\).  \nWhen a structure \\(B\\) is interpreted in a structure \\(A\\), every\nfirst-order statement about \\(B\\) can be translated back into a\nfirst-order statement about \\(A\\), and in this way we can read off the\ncomplete theory of \\(B\\) from that of \\(A\\). In fact if we carry out\nthis construction not just for a single structure \\(A\\) but for a\nfamily of models of a theory \\(T\\), always using the same defining\nformulas, then the resulting structures will all be models of a theory\n\\(T'\\) that can be read off from \\(T\\) and the defining formulas. This\ngives a precise sense to the statement that the theory \\(T'\\) is\ninterpreted in the theory \\(T\\). Philosophers of science have\nsometimes experimented with this notion of interpretation as a way of\nmaking precise what it means for one theory to be reducible to\nanother. But realistic examples of reductions between scientific\ntheories seem generally to be much subtler than this simple-minded\nmodel-theoretic idea will allow. See the entry on\n intertheory relations in physics. \nThe fourth kind of definability is a pair of notions, implicit\ndefinability and explicit definability of a particular relation in a\ntheory. See section 3.3 of the entry on\n first-order model theory. \nUnfortunately there used to be a very confused theory about\nmodel-theoretic axioms, that also went under the name of implicit\ndefinition. By the end of the nineteenth century, mathematical\ngeometry had generally ceased to be a study of space, and it had\nbecome the study of classes of structures which satisfy certain\n‘geometric’ axioms. Geometric terms like\n‘point’, ‘line’ and ‘between’\nsurvived, but only as the primitive symbols in axioms; they no longer\nhad any meaning associated with them. So the old question, whether\nEuclid’s parallel postulate (as a statement about space) was\ndeducible from Euclid’s other assumptions about space, was no\nlonger interesting to geometers. Instead, geometers showed that if one\nwrote down an up-to-date version of Euclid’s other assumptions,\nin the form of a theory \\(T\\), then it was possible to find models of\n\\(T\\) which fail to satisfy the parallel postulate. (See the entry on\n geometry in the 19th century\n for the contributions of Lobachevski and Klein to this achievement.)\nIn 1899 David Hilbert published a book in which he constructed such\nmodels, using exactly the method of interpretation that we have just\ndescribed. \nProblems arose because of the way that Hilbert and others described\nwhat they were doing. The history is complicated, but roughly the\nfollowing happened. Around the middle of the nineteenth century people\nnoticed, for example, that in an abelian group the minus function is\ndefinable in terms of 0 and + (namely: \\(-a\\) is the element \\(b\\)\nsuch that \\(a + b = 0)\\). Since this description of minus is in fact\none of the axioms defining abelian groups, we can say (using a term\ntaken from J. D. Gergonne, who should not be held responsible for the\nlater use made of it) that the axioms for abelian groups\nimplicitly define minus. In the jargon of the time, one said\nnot that the axioms define the function minus, but that they define\nthe concept minus. Now suppose we switch around and try to\ndefine plus in terms of minus and 0. This way round it can’t be\ndone, since one can have two abelian groups with the same 0 and minus\nbut different plus functions. Rather than say this, the nineteenth\ncentury mathematicians concluded that the axioms only partially define\nplus in terms of minus and 0. Having swallowed that much, they went on\nto say that the axioms together form an implicit definition of the\nconcepts plus, minus and 0 together, and that this implicit definition\nis only partial but it says about these concepts precisely as much as\nwe need to know. \nOne wonders how it could happen that for fifty years nobody challenged\nthis nonsense. In fact some people did challenge it, notably the\ngeometer Moritz Pasch who in section 12 of his Vorlesungen\nüber Neuere Geometrie (1882) insisted that geometric axioms\ntell us nothing whatever about the meanings of ‘point’,\n‘line’ etc. Instead, he said, the axioms give us\nrelations between the concepts. If one thinks of a structure\nas a kind of ordered \\(n\\)-tuple of sets etc., then a class\n\\(\\Mod(T)\\) becomes an \\(n\\)-ary relation, and Pasch’s account\nagrees with ours. But he was unable to spell out the details, and\nthere is some evidence that his contemporaries (and some more recent\ncommentators) thought he was saying that the axioms may not determine\nthe meanings of ‘point’ and ‘line’, but they\ndo determine those of relational terms such as ‘between’\nand ‘incident with’! Frege’s demolition of the\nimplicit definition doctrine was masterly, but it came too late to\nsave Hilbert from saying, at the beginning of his Grundlagen der\nGeometrie, that his axioms give ‘the exact and\nmathematically adequate description’ of the relations\n‘lie’, ‘between’ and ‘congruent’.\nFortunately Hilbert’s mathematics speaks for itself, and one can\nsimply bypass these philosophical faux pas. The model-theoretic\naccount that we now take as a correct description of this line of work\nseems to have surfaced first in the group around Giuseppe Peano in the\n1890s, and it reached the English-speaking world through Bertrand\nRussell’s Principles of Mathematics in 1903. \nSuppose \\(L\\) is a language of signature \\(K, T\\) is a set of\nsentences of \\(L\\) and \\(\\phi\\) is a sentence of \\(L\\). Then the\nrelation  \nexpresses that every structure of signature \\(K\\) which is a model of\n\\(T\\) is also a model of \\(\\phi\\). This is known as the\nmodel-theoretic consequence relation, and it is written for\nshort as  \nThe double use of \\(\\vDash\\) is a misfortune. But in the particular\ncase where \\(L\\) is first-order, the completeness theorem (see the\nentry on\n classical logic)\n tells us that ‘\\(T \\vDash \\phi\\)’ holds if and only if\nthere is a proof of \\(\\phi\\) from \\(T\\), a relation commonly\nwritten \nSince \\(\\vDash\\) and \\(\\vdash\\) express exactly the same relation in\nthis case, model theorists often avoid the double use of \\(\\vDash\\) by\nusing \\(\\vdash\\) for model-theoretic consequence. But since what\nfollows is not confined to first-order languages, safety suggests we\nstick with \\(\\vDash\\) here. \nBefore the middle of the nineteenth century, textbooks of logic\ncommonly taught the student how to check the validity of an argument\n(say in English) by showing that it has one of a number of standard\nforms, or by paraphrasing it into such a form. The standard forms were\nsyntactic and/or semantic forms of argument in English. The process\nwas hazardous: semantic forms are almost by definition not visible on\nthe surface, and there is no purely syntactic form that guarantees\nvalidity of an argument. For this reason most of the old textbooks had\na long section on ‘fallacies’ – ways in which an\ninvalid argument may seem to be valid. \nIn 1847 George Boole changed this arrangement. For example, to\nvalidate the argument \nBoole would interpret the symbols \\(P, Q, R\\) as names of classes:\n \nThen he would point out that the original argument paraphrases into a\nset-theoretic consequence:  \n(This example is from Stanley Jevons, 1869. Boole’s own account\nis idiosyncratic, but I believe Jevons’ example represents\nBoole’s intentions accurately.) Today we would write \\(\\forall\nx(Px \\rightarrow Qx)\\) rather than \\(P \\subseteq Q\\), but this is\nessentially the standard definition of \\(P \\subseteq Q\\), so the\ndifference between us and Boole is slight.  \nInsofar as they follow Boole, modern textbooks of logic establish that\nEnglish arguments are valid by reducing them to model-theoretic\nconsequences. Since the class of model-theoretic consequences, at\nleast in first-order logic, has none of the vaguenesses of the old\nargument forms, textbooks of logic in this style have long since\nceased to have a chapter on fallacies. \nBut there is one warning that survives from the old textbooks: If you\nformalise your argument in a way that is not a\nmodel-theoretic consequence, it doesn’t mean the argument is\nnot valid. It may only mean that you failed to analyse the\nconcepts in the argument deeply enough before you formalised. The old\ntextbooks used to discuss this in a ragbag section called\n‘topics’ (i.e. hints for finding arguments that you might\nhave missed). Here is an example from Peter of Spain’s 13th\ncentury Summulae Logicales: \nHilbert and Ackermann, possibly the textbook that did most to\nestablish the modern style, discuss in their section III.3 a very\nsimilar example: ‘If there is a son, then there is a\nfather’. They point out that any attempt to justify this by\nusing the symbolism  \nis doomed to failure. “A proof of this statement is possible\nonly if we analyze conceptually the meanings of the two predicates\nwhich occur”, as they go on to illustrate. And of course the\nanalysis finds precisely the relation that Peter of Spain referred to.\n \nOn the other hand if your English argument translates into an invalid\nmodel-theoretic consequence, a counterexample to the consequence may\nwell give clues about how you can describe a situation that would make\nthe premises of your argument true and the conclusion false. But this\nis not guaranteed. \nOne can raise a number of questions about whether the modern textbook\nprocedure does really capture a sensible notion of logical\nconsequence. For example in Boole’s case the set-theoretic\nconsequences that he relies on are all easily provable by formal\nproofs in first-order logic, not even using any set-theoretic axioms;\nand by the completeness theorem (see the entry on\n classical logic)\n the same is true for first-order logic. But for some other logics it\nis certainly not true. For instance the model-theoretic consequence\nrelation for some logics of time presupposes some facts about the\nphysical structure of time. Also, as Boole himself pointed out, his\ntranslation from an English argument to its set-theoretic form\nrequires us to believe that for every property used in the argument,\nthere is a corresponding class of all the things that have the\nproperty. This comes dangerously close to Frege’s inconsistent\ncomprehension axiom! \nIn 1936 Alfred Tarski proposed a definition of logical consequence for\narguments in a fully interpreted formal language. His proposal was\nthat an argument is valid if and only if: under any allowed\nreinterpretation of its nonlogical symbols, if the premises are true\nthen so is the conclusion. Tarski assumed that the class of allowed\nreinterpretations could be read off from the semantics of the\nlanguage, as set out in his\n truth definition.\n He left it undetermined what symbols count as nonlogical; in fact he\nhoped that this freedom would allow one to define different kinds of\nnecessity, perhaps separating ‘logical’ from\n‘analytic’. One thing that makes Tarski’s proposal\ndifficult to evaluate is that he completely ignores the question we\ndiscussed above, of analysing the concepts to reach all the logical\nconnections between them. The only plausible explanation I can see for\nthis lies in his parenthetical remark about \nThis suggests to me that he wants his primitive signs to be by\nstipulation unanalysable. But then by stipulation it will be\npurely accidental if his notion of logical consequence captures\neverything one would normally count as a logical consequence.  \nHistorians note a resemblance between Tarski’s proposal and one\nin section 147 of Bernard Bolzano’s Wissenschaftslehre\nof 1837. Like Tarski, Bolzano defines the validity of a proposition in\nterms of the truth of a family of related propositions. Unlike Tarski,\nBolzano makes his proposal for propositions in the vernacular, not for\nsentences of a formal language with a precisely defined semantics. \nOn all of this section, see also the entry on\n logical consequence. \nA sentence \\(S\\) defines its class \\(\\Mod(S)\\) of models. Given two\nlanguages \\(L\\) and \\(L'\\), we can compare them by asking whether\nevery class \\(\\Mod(S)\\), with \\(S\\) a sentence of \\(L\\), is also a\nclass of the form \\(\\Mod(S')\\) where \\(S'\\) is a sentence of \\(L'\\).\nIf the answer is Yes, we say that \\(L\\) is reducible to\n\\(L'\\), or that \\(L'\\) is at least as expressive as \\(L\\).\n \nFor example if \\(L\\) is a first-order language with identity, whose\nsignature consists of 1-ary predicate symbols, and \\(L'\\) is the\nlanguage whose sentences consist of the four syllogistic forms (All\n\\(A\\) are \\(B\\), Some \\(A\\) are \\(B\\), No \\(A\\) are \\(B\\), Some \\(A\\)\nare not \\(B)\\) using the same predicate symbols, then \\(L'\\) is\nreducible to \\(L\\), because the syllogistic forms are expressible in\nfirst-order logic. (There are some quarrels about which is the right\nway to express them; see the entry on the traditional\n square of opposition.)\n But the first-order language \\(L\\) is certainly not reducible to the\nlanguage \\(L'\\) of syllogisms, since in \\(L\\) we can write down a\nsentence saying that exactly three elements satisfy \\(Px\\), and there\nis no way of saying this using just the syllogistic forms. Or moving\nthe other way, if we form a third language \\(L''\\) by adding to \\(L\\)\nthe quantifier \\(Qx\\) with the meaning “There are uncountably\nmany elements \\(x\\) such that …”, then trivially \\(L\\) is\nreducible to \\(L''\\), but the downward Loewenheim-Skolem theorem shows\nat once that \\(L''\\) is not reducible to \\(L\\). \nThese notions are useful for analysing the strength of database query\nlanguages. We can think of the possible states of a database as\nstructures, and a simple Yes/No query becomes a sentence that elicits\nthe answer Yes if the database is a model of it and No otherwise. If\none database query language is not reducible to another, then the\nfirst can express some query that can’t be expressed in the\nsecond. \nSo we need techniques for comparing the expressive strengths of\nlanguages. One of the most powerful techniques available consists of\nthe back-and-forth games of Ehrenfeucht and Fraïssé\nbetween the two players Spoiler and Duplicator; see the entry on\n logic and games\n for details. Imagine for example that we play the usual first-order\nback-and-forth game \\(G\\) between two structures \\(A\\) and \\(B\\). The\ntheory of these games establishes that if some first-order sentence\n\\(\\phi\\) is true in exactly one of \\(A\\) and \\(B\\), then there is a\nnumber \\(n\\), calculable from \\(\\phi\\), with the property that Spoiler\nhas a strategy for \\(G\\) that will guarantee that he wins in at most\n\\(n\\) steps. So conversely, to show that first-order logic can’t\ndistinguish between \\(A\\) and \\(B\\), it suffices to show that for\nevery finite \\(n\\), Duplicator has a strategy that will guarantee she\ndoesn’t lose \\(G\\) in the first \\(n\\) steps. If we succeed in\nshowing this, it follows that any language which does distinguish\nbetween \\(A\\) and \\(B\\) is not reducible to the first-order language\nof the structures \\(A\\) and \\(B\\). \nThese back-and-forth games are immensely flexible. For a start, they\nmake just as much sense on finite structures as they do on infinite;\nmany other techniques of classical model theory assume that the\nstructures are infinite. They can also be adapted smoothly to many\nnon-first-order languages. \nIn 1969 Per Lindström used back-and-forth games to give some\nabstract characterisations of first-order logic in terms of its\nexpressive power. One of his theorems says that if \\(L\\) is a language\nwith a signature \\(K, L\\) is closed under all the first-order\nsyntactic operations, and \\(L\\) obeys the downward Loewenheim-Skolem\ntheorem for single sentences, and the compactness theorem, then \\(L\\)\nis reducible to the first-order language of signature \\(K\\). These\ntheorems are very attractive; see Chapter XII of Ebbinghaus, Flum and\nThomas for a good account. But they have never quite lived up to their\npromise. It has been hard to find any similar characterisations of\nother logics. Even for first-order logic it is a little hard to see\nexactly what the characterisations tell us. But very roughly speaking,\nthey tell us that first-order logic is the unique logic with two\nproperties: (1) we can use it to express arbitrarily complicated\nthings about finite patterns, and (2) it is hopeless for\ndiscriminating between one infinite cardinal and another. \nThese two properties (1) and (2) are just the properties of\nfirst-order logic that allowed Abraham Robinson to build his\nnonstandard analysis. The background is that Leibniz, when he\ninvented differential and integral calculus, used infinitesimals, i.e.\nnumbers that are greater than 0 and smaller than all of 1/2, 1/3, 1/4\netc. Unfortunately there are no such real numbers. During the\nnineteenth century all definitions and proofs in the Leibniz style\nwere rewritten to talk of limits instead of infinitesimals. Now let\n\\(\\mathbb{R}\\) be the structure consisting of the field of real\nnumbers together with any structural features we care to give names\nto: certainly plus and times, maybe the ordering, the set of integers,\nthe functions sin and log, etc. Let \\(L\\) be the first-order language\nwhose signature is that of \\(\\mathbb{R}\\). Because of the expressive\nstrength of \\(L\\), we can write down any number of theorems of\ncalculus as sentences of \\(L\\). Because of the expressive weakness of\n\\(L\\), there is no way that we can express in \\(L\\) that\n\\(\\mathbb{R}\\) has no infinitesimals. In fact Robinson used the\ncompactness theorem to build a structure \\(\\mathbb{R}'\\) that is a\nmodel of exactly the same sentences of \\(L\\) as \\(\\mathbb{R}\\), but\nwhich has infinitesimals. As Robinson showed, we can copy\nLeibniz’s arguments using the infinitesimals in \\(\\mathbb{R}'\\),\nand so prove that various theorems of calculus are true in\n\\(\\mathbb{R}'\\). But these theorems are expressible in \\(L\\), so they\nmust also be true in \\(\\mathbb{R}\\). \nSince arguments using infinitesimals are usually easier to visualise\nthan arguments using limits, nonstandard analysis is a helpful tool\nfor mathematical analysts. Jacques Fleuriot in his Ph.D. thesis (2001)\nautomated the proof theory of nonstandard analysis and used it to\nmechanise some of the proofs in Newton’s Principia. \nTo model a phenomenon is to construct a formal theory that\ndescribes and explains it. In a closely related sense, you\nmodel a system or structure that you plan to build, by\nwriting a description of it. These are very different senses of\n‘model’ from that in model theory: the ‘model’\nof the phenomenon or the system is not a structure but a theory, often\nin a formal language. The Universal Modeling Language, UML\nfor short, is a formal language designed for just this purpose.\nIt’s reported that the Australian Navy once hired a model\ntheorist for a job ‘modelling hydrodynamic phenomena’.\n(Please don’t enlighten them!)  \nA little history will show how the word ‘model’ came to\nhave these two different uses. In late Latin a ‘modellus’\nwas a measuring device, for example to measure water or milk. By the\nvagaries of language, the word generated three different words in\nEnglish: mould, module, model. Often a device that measures out a\nquantity of a substance also imposes a form on the substance. We see\nthis with a cheese mould, and also with the metal letters (called\n‘moduli’ in the early 17th century) that carry ink to\npaper in printing. So ‘model’ comes to mean an object in\nhand that expresses the design of some other objects in the world: the\nartist’s model carries the form that the artist depicts, and\nChristopher Wren’s ‘module’ of St Paul’s\nCathedral serves to guide the builders. \nAlready by the late 17th century the word ‘model’ could\nmean an object that shows the form, not of real-world objects, but of\nmathematical constructs. Leibniz boasted that he didn’t need\nmodels in order to do mathematics. Other mathematicians were happy to\nuse plaster or metal models of interesting surfaces. The models of\nmodel theory first appeared as abstract versions of this kind of\nmodel, with theories in place of the defining equation of a surface.\nOn the other hand one could stay with real-world objects but show\ntheir form through a theory rather than a physical copy in hand;\n‘modelling’ is building such a theory. \nWe have a confusing halfway situation when a scientist describes a\nphenomenon in the world by an equation, for example a differential\nequation with exponential functions as solutions. Is the model the\ntheory consisting of the equation, or are these exponential functions\nthemselves models of the phenomenon? Examples of this kind, where\ntheory and structures give essentially the same information, provide\nsome support for Patrick Suppes’ claim that “the meaning\nof the concept of model is the same in mathematics and the empirical\nsciences” (1969, 12). Several\nphilosophers of science have pursued the idea of using an informal\nversion of model-theoretic models for scientific modelling. Sometimes\nthe models are described as non-linguistic – this might be hard\nto reconcile with our definition of models in section 1 above. \nCognitive science is one area where the difference between models and\nmodelling tends to become blurred. A central question of cognitive\nscience is how we represent facts or possibilities in our minds. If\none formalises these mental representations, they become something\nlike ‘models of phenomena’. But it is a serious hypothesis\nthat in fact our mental representations have a good deal in common\nwith simple set-theoretic structures, so that they are\n‘models’ in the model-theoretic sense too. In 1983 two\ninfluential works of cognitive science were published, both under the\ntitle Mental Models. The first, edited by Dedre Gentner and\nAlbert Stevens, was about people’s\n‘conceptualizations’ of the elementary facts of physics;\nit belongs squarely in the world of ‘modelling of\nphenomena’. The second, by Philip Johnson-Laird, is largely\nabout reasoning, and makes several appeals to ‘model-theoretic\nsemantics’ in our sense. Researchers in the Johnson-Laird\ntradition tend to refer to their approach as ‘model\ntheory’, and to see it as allied in some sense to what we have\ncalled model theory. \nPictures and diagrams seem at first to hover in the middle ground\nbetween theories and models. In practice model theorists often draw\nthemselves pictures of structures, and use the pictures to think about\nthe structures. On the other hand pictures don’t generally carry\nthe labelling that is an essential feature of model-theoretic\nstructures. There is a fast growing body of work on reasoning with\ndiagrams, and the overwhelming tendency of this work is to see\npictures and diagrams as a form of language rather than as a form of\nstructure. For example Eric Hammer and Norman Danner (1996) describe a\n‘model theory of Venn diagrams’; the Venn diagrams\nthemselves are the syntax, and the model theory is a set-theoretical\nexplanation of their meaning.  (A curious counterexample is the\nhorizontal line diagrams of the 12th century Baghdad Jewish scholar\nAbū l-Barakāt they represent structures and not\npropositions, and Abū l-Barakāt uses them to express\nmodel-theoretic consequence in syllogisms.  Further details are in\nHodges 2018 on model-theoretic consequence.) \nThe model theorist Yuri Gurevich introduced abstract state\nmachines (ASMs) as a way of using model-theoretic ideas for\nspecification in computer science. According to the Abstract State\nMachine website (see Other Internet Resources below), \nThe book of Börger and Stärk cited below is an authoritative\naccount of ASMs and their uses.  \nToday you can make your name and fortune by finding a good\nrepresentation system. There is no reason to expect that every such\nsystem will fit neatly into the syntax/semantics framework of model\ntheory, but it will be surprising if model-theoretic ideas don’t\ncontinue to make a major contribution in this area.","contact.mail":"wilfrid.hodges@btinternet.com","contact.domain":"btinternet.com"}]
