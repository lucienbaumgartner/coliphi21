[{"date.published":"2004-06-18","date.changed":"2014-01-14","url":"https://plato.stanford.edu/entries/consciousness/","author1":"Robert Van Gulick","author1.info":"http://thecollege.syr.edu/people/faculty/pages/phi/vangulick-robert.html","entry":"consciousness","body.text":"\n\n\n\nPerhaps no aspect of mind is more familiar or more puzzling than\nconsciousness and our conscious experience of self and world. The\nproblem of consciousness is arguably the central issue in current\ntheorizing about the mind. Despite the lack of any agreed upon theory\nof consciousness, there is a widespread, if less than universal,\nconsensus that an adequate account of mind requires a clear\nunderstanding of it and its place in nature. We need to understand both\nwhat consciousness is and how it relates to other, nonconscious, aspects\nof reality.\n\n\n\nQuestions about the nature of conscious awareness have likely been\nasked for as long as there have been humans. Neolithic burial practices\nappear to express spiritual beliefs and provide early evidence for at\nleast minimally reflective thought about the nature of human\nconsciousness (Pearson 1999, Clark and Riel-Salvatore 2001).\nPreliterate cultures have similarly been found invariably to embrace\nsome form of spiritual or at least animist view that indicates a degree\nof reflection about the nature of conscious awareness. \n\nNonetheless, some have argued that consciousness as we know it today\nis a relatively recent historical development that arose sometime after\nthe Homeric era (Jaynes 1974). According to this view, earlier humans\nincluding those who fought the Trojan War did not experience themselves\nas unified internal subjects of their thoughts and actions, at least\nnot in the ways we do today. Others have claimed that even during the\nclassical period, there was no word of ancient Greek that corresponds\nto “consciousness” (Wilkes 1984, 1988, 1995). Though the\nancients had much to say about mental matters, it is less clear whether\nthey had any specific concepts or concerns for what we now think of as \nconsciousness. \n\nAlthough the words “conscious” and\n“conscience” are used quite differently today, it is likely\nthat the Reformation emphasis on the latter as an inner source of truth\nplayed some role in the inward turn so characteristic of the modern\nreflective view of self. The Hamlet who walked the stage in 1600\nalready saw his world and self with profoundly modern eyes. \n\nBy the beginning of the early modern era in the seventeenth century,\nconsciousness had come full center in thinking about the mind. Indeed\nfrom the mid-17th through the late 19th century, consciousness was\nwidely regarded as essential or definitive of the mental. René\nDescartes defined the very notion of thought (pensée) in terms of\nreflexive consciousness or self-awareness. In the Principles of\nPhilosophy (1640) he wrote, \n\nLater, toward the end of the 17th century, John Locke offered a\nsimilar if slightly more qualified claim in An Essay on Human\nUnderstanding (1688), \n\nLocke explicitly forswore making any hypothesis about the\nsubstantial basis of consciousness and its relation to matter, but he\nclearly regarded it as essential to thought as well as to personal\nidentity. \n\nLocke's contemporary G.W. Leibniz, drawing possible inspiration from\nhis mathematical work on differentiation and integration, offered a\ntheory of mind in the Discourse on Metaphysics (1686) that\nallowed for infinitely many degrees of consciousness and perhaps even\nfor some thoughts that were unconscious, the so called “petites\nperceptions”. Leibniz was the first to distinguish explicitly\nbetween perception and apperception, i.e., roughly between awareness\nand self-awareness. In the Monadology (1720) he also offered\nhis famous analogy of the mill to express his belief that consciousness\ncould not arise from mere matter. He asked his reader to imagine\nsomeone walking through an expanded brain as one would walk through a\nmill and observing all its mechanical operations, which for Leibniz\nexhausted its physical nature. Nowhere, he asserts, would such an\nobserver see any conscious thoughts. \n\nDespite Leibniz's recognition of the possibility of unconscious\nthought, for most of the next two centuries the domains of thought and\nconsciousness were regarded as more or less the same. Associationist\npsychology, whether pursued by Locke or later in the eighteenth century\nby David Hume (1739) or in the nineteenth by James Mill (1829), aimed\nto discover the principles by which conscious thoughts or ideas\ninteracted or affected each other. James Mill's son, John Stuart Mill\ncontinued his father's work on associationist psychology, but he\nallowed that combinations of ideas might produce resultants that went\nbeyond their constituent mental parts, thus providing an early model of\nmental emergence (1865). \n\nThe purely associationist approach was critiqued in the late\neighteenth century by Immanuel Kant (1787), who argued that an adequate\naccount of experience and phenomenal consciousness required a far\nricher structure of mental and intentional organization. Phenomenal\nconsciousness according to Kant could not be a mere succession of\nassociated ideas, but at a minimum had to be the experience of a\nconscious self situated in an objective world structured with respect\nto space, time and causality. \n\nWithin the Anglo-American world, associationist approaches continued\nto be influential in both philosophy and psychology well into the\ntwentieth century, while in the German and European sphere there was a\ngreater interest in the larger structure of experience that lead in\npart to the study of phenomenology through the work of Edmund Husserl\n(1913, 1929), Martin Heidegger (1927), Maurice Merleau-Ponty (1945) and\nothers who expanded the study of consciousness into the realm of the\nsocial, the bodily and the interpersonal. \n\nAt the outset of modern scientific psychology in the mid-nineteenth\ncentury, the mind was still largely equated with consciousness, and\nintrospective methods dominated the field as in the work of Wilhelm\nWundt (1897), Hermann von Helmholtz (1897), William James (1890) and\nAlfred Titchener (1901). However, the relation of consciousness to\nbrain remained very much a mystery as expressed in T. H. Huxley's\nfamous remark, \n\nThe early twentieth century saw the eclipse of consciousness from\nscientific psychology, especially in the United States with the rise of\nbehaviorism (Watson 1924, Skinner 1953) though movements such as\nGestalt psychology kept it a matter of ongoing scientific concern in\nEurope (Köhler 1929, Köffka 1935). In the 1960s, the grip of\nbehaviorism weakened with the rise of cognitive psychology and its\nemphasis on information processing and the modeling of internal mental\nprocesses (Neisser 1965, Gardiner 1985). However, despite the renewed\nemphasis on explaining cognitive capacities such as memory, perception\nand language comprehension, consciousness remained a largely neglected\ntopic for several further decades. \n\nIn the 1980s and 90s there was a major resurgence of scientific and\nphilosophical research into the nature and basis of consciousness\n(Baars 1988, Dennett 1991, Penrose 1989, 1994, Crick 1994, Lycan 1987,\n1996, Chalmers 1996). Once consciousness was back under discussion,\nthere was a rapid proliferation of research with a flood of books and\narticles, as well as the introduction of specialty journals (The\nJournal of Consciousness Studies, Consciousness and Cognition,\nPsyche), professional societies (Association for the Scientific\nStudy of Consciousness—ASSC) and annual conferences devoted\nexclusively to its investigation (“The Science of\nConsciousness”). \n\nThe words “conscious” and “consciousness”\nare umbrella terms that cover a wide variety of mental phenomena. Both\nare used with a diversity of meanings, and the adjective\n“conscious” is heterogeneous in its range, being applied\nboth to whole organisms—creature consciousness—and to\nparticular mental states and processes—state consciousness\n(Rosenthal 1986, Gennaro 1995, Carruthers 2000). \n\nAn animal, person or other cognitive system may be regarded as\nconscious in a number of different senses. \n\nSentience. It may be conscious in the generic sense of\nsimply being a sentient creature, one capable of sensing and\nresponding to its world (Armstrong 1981). Being conscious in this sense\nmay admit of degrees, and just what sort of sensory capacities are\nsufficient may not be sharply defined. Are fish conscious in the\nrelevant respect? And what of shrimp or bees? \n\nWakefulness. One might further require that the organism\nactually be exercising such a capacity rather than merely having the\nability or disposition to do so. Thus one might count it as conscious\nonly if it were awake and normally alert. In that sense\norganisms would not count as conscious when asleep or in any of the\ndeeper levels of coma. Again boundaries may be blurry, and intermediate\ncases may be involved. For example, is one conscious in the relevant\nsense when dreaming, hypnotized or in a fugue state? \n\nSelf-consciousness. A third and yet more demanding sense\nmight define conscious creatures as those that are not only aware but\nalso aware that they are aware, thus treating creature consciousness as\na form of self-consciousness (Carruthers 2000). The\nself-awareness requirement might get interpreted in a variety of ways,\nand which creatures would qualify as conscious in the relevant sense\nwill vary accordingly. If it is taken to involve explicit conceptual\nself-awareness, many non-human animals and even young children might\nfail to qualify, but if only more rudimentary implicit forms of\nself-awareness are required then a wide range of nonlinguistic\ncreatures might count as self-conscious. \n\nWhat it is like. Thomas Nagel's (1974)\nfamous“what it is like” criterion aims to capture\nanother and perhaps more subjective notion of being a conscious\norganism. According to Nagel, a being is conscious just if there is\n“something that it is like” to be that creature, i.e., some\nsubjective way the world seems or appears from the creature's mental or\nexperiential point of view. In Nagel's example, bats are conscious\nbecause there is something that it is like for a bat to experience its\nworld through its echo-locatory senses, even though we humans from our\nhuman point of view can not emphatically understand what such a mode of\nconsciousness is like from the bat's own point of view. \n\nSubject of conscious states. A fifth alternative would be\nto define the notion of a conscious organism in terms of conscious\nstates. That is, one might first define what makes a mental state a\nconscious mental state, and then define being a conscious creature in\nterms of having such states. One's concept of a conscious organism\nwould then depend upon the particular account one gives of conscious\nstates (section 2.2). \n\nTransitive Consciousness. In addition to describing\ncreatures as conscious in these various senses, there are also related\nsenses in which creatures are described as being conscious of\nvarious things. The distinction is sometimes marked as that between\ntransitive and intransitive notions of consciousness,\nwith the former involving some object at which consciousness is\ndirected (Rosenthal 1986). \n\nThe notion of a conscious mental state also has a variety of\ndistinct though perhaps interrelated meanings. There are at least six\nmajor options. \n\nStates one is aware of. On one common reading, a conscious\nmental state is simply a mental state one is aware of being in\n(Rosenthal 1986, 1996). Conscious states in this sense involve a form\nof meta-mentality or meta-intentionality in so far as\nthey require mental states that are themselves about mental states. To\nhave a conscious desire for a cup of coffee is to have such a desire\nand also to be simultaneously and directly aware that one has such a\ndesire. Unconscious thoughts and desires in this sense are simply\nthose we have without being aware of having them, whether our lack of\nself-knowledge results from simple inattention or more deeply\npsychoanalytic causes. \n\nQualitative states. States might also be regarded as\nconscious in a seemingly quite different and more qualitative\nsense. That is, one might count a state as conscious just if it has or\ninvolves qualitative or experiential properties of the sort often\nreferred to as “qualia” or “raw sensory feels”.\n(See the entry on\n qualia.)\n One's perception of the Merlot one is drinking or of the fabric one\nis examining counts as a conscious mental state in this sense because\nit involves various sensory qualia, e.g., taste qualia in the wine\ncase and color qualia in one's visual experience of the cloth. There\nis considerable disagreement about the nature of such qualia\n(Churchland 1985, Shoemaker 1990, Clark 1993, Chalmers 1996) and even\nabout their existence. Traditionally qualia have been regarded as\nintrinsic, private, ineffable monadic features of experience, but\ncurrent theories of qualia often reject at least some of those\ncommitments (Dennett 1990). \n\nPhenomenal states. Such qualia are sometimes referred to as\nphenomenal properties and the associated sort of consciousness as\nphenomenal consciousness, but the latter term is perhaps more\nproperly applied to the overall structure of experience and involves\nfar more than sensory qualia. The phenomenal structure of consciousness\nalso encompasses much of the spatial, temporal and conceptual\norganization of our experience of the world and of ourselves as agents\nin it. (See section\n 4.3)\n It is therefore probably\nbest, at least initially, to distinguish the concept of phenomenal\nconsciousness from that of qualitative consciousness, though they no\ndoubt overlap. \n\nWhat-it-is-like states. Consciousness in both those senses\nlinks up as well with Thomas Nagel's (1974) notion of a conscious\ncreature, insofar as one might count a mental state as conscious in the\n“what it is like” sense just if there is something\nthat it is like to be in that state. Nagel's criterion might be\nunderstood as aiming to provide a first-person or internal conception\nof what makes a state a phenomenal or qualitative state. \n\nAccess consciousness. States might be conscious in a\nseemingly quite different access sense, which has more to do with\nintra-mental relations. In this respect, a state's being conscious is a\nmatter of its availability to interact with other states and of the\naccess that one has to its content. In this more functional sense,\nwhich corresponds to what Ned Block (1995) calls access\nconsciousness, a visual state's being conscious is not so much a\nmatter of whether or not it has a qualitative “what it's\nlikeness”, but of whether or not it and the visual information\nthat it carries is generally available for use and guidance by the\norganism. In so far as the information in that state is richly and\nflexibly available to its containing organism, then it counts as a\nconscious state in the relevant respect, whether or not it has any\nqualitative or phenomenal feel in the Nagel sense. \n\nNarrative consciousness. States might also be regarded as\nconscious in a narrative sense that appeals to the notion of\nthe “stream of consciousness”, regarded as an ongoing more\nor less serial narrative of episodes from the perspective of an actual\nor merely virtual self. The idea would be to equate the person's\nconscious mental states with those that appear in the stream (Dennett\n1991, 1992). \n\nAlthough these six notions of what makes a state conscious can be\nindependently specified, they are obviously not without potential\nlinks, nor do they exhaust the realm of possible options. Drawing\nconnections, one might argue that states appear in the stream of\nconsciousness only in so far as we are aware of them, and thus forge a\nbond between the first meta-mental notion of a conscious state and the\nstream or narrative concept. Or one might connect the access with the\nqualitative or phenomenal notions of a conscious state by trying to\nshow that states that represent in those ways make their contents\nwidely available in the respect required by the access notion. \n\nAiming to go beyond the six options, one might distinguish conscious\nfrom nonconscious states by appeal to aspects of their intra-mental\ndynamics and interactions other than mere access relations; e.g.,\nconscious states might manifest a richer stock of content-sensitive\ninteractions or a greater degree of flexible purposive guidance of the\nsort associated with the self-conscious control of thought.\nAlternatively, one might try to define conscious states in terms of\nconscious creatures. That is, one might give some account of what it is\nto be a conscious creature or perhaps even a conscious self, and then\ndefine one's notion of a conscious state in terms of being a state of\nsuch a creature or system, which would be the converse of the last\noption considered above for defining conscious creatures in terms of\nconscious mental states. \n\nThe noun “consciousness” has an equally diverse range of\nmeanings that largely parallel those of the adjective\n“conscious”. Distinctions can be drawn between creature and\nstate consciousness as well as among the varieties of each. One can\nrefer specifically to phenomenal consciousness, access consciousness,\nreflexive or meta-mental consciousness, and narrative consciousness\namong other varieties. \n\nHere consciousness itself is not typically treated as a substantive\nentity but merely the abstract reification of whatever property or\naspect is attributed by the relevant use of the adjective\n“conscious”. Access consciousness is just the property of\nhaving the required sort of internal access relations, and qualitative\nconsciousness is simply the property that is attributed when\n“conscious” is applied in the qualitative sense to mental\nstates. How much this commits one to the ontological status of\nconsciousness per se will depend on how much of a Platonist one is\nabout universals in general. (See the entry on\n the medieval problem of universals.)\n It need not commit one to consciousness as a distinct entity any more\nthan one's use of “square”, “red” or\n“gentle” commits one to the existence of squareness,\nredness or gentleness as distinct entities. \n\nThough it is not the norm, one could nonetheless take a more\nrobustly realist view of consciousness as a component of reality. That\nis one could think of consciousness as more on a par with\nelectromagnetic fields than with life. \n\nSince the demise of vitalism, we do not think of life per\nse as something distinct from living things. There are living\nthings including organisms, states, properties and parts of organisms,\ncommunities and evolutionary lineages of organisms, but life is not\nitself a further thing, an additional component of reality, some vital\nforce that gets added into living things. We apply the adjectives\n“living” and “alive” correctly to many things,\nand in doing so we might be said to be attributing life to them but\nwith no meaning or reality other than that involved in their being\nliving things. \n\nElectromagnetic fields by contrast are regarded as real and\nindependent parts of our physical world. Even though one may sometimes\nbe able to specify the values of such a field by appeal to the behavior\nof particles in it, the fields themselves are regarded as concrete\nconstituents of reality and not merely as abstractions or sets of\nrelations among particles. \n\nSimilarly one could regard “consciousness” as referring\nto a component or aspect of reality that manifests itself in conscious\nstates and creatures but is more than merely the abstract\nnominalization of the adjective “conscious” we apply to\nthem. Though such strongly realist views are not very common at\npresent, they should be included within the logical space of\noptions. \n\nThere are thus many concepts of consciousness, and both\n“conscious” and “consciousness” are used in a\nwide range of ways with no privileged or canonical meaning. However,\nthis may be less of an embarrassment than an embarrassment of riches.\nConsciousness is a complex feature of the world, and understanding it\nwill require a diversity of conceptual tools for dealing with its many\ndiffering aspects. Conceptual plurality is thus just what one would\nhope for. As long as one avoids confusion by being clear about one's\nmeanings, there is great value in having a variety of concepts by which\nwe can access and grasp consciousness in all its rich complexity.\nHowever, one should not assume that conceptual plurality implies\nreferential divergence. Our multiple concepts of consciousness may in\nfact pick out varying aspects of a single unified underlying mental\nphenomenon. Whether and to what extent they do so remains an open\nquestion. \n\nThe task of understanding consciousness is an equally diverse\nproject. Not only do many different aspects of mind count as conscious\nin some sense, each is also open to various respects in which it might\nbe explained or modeled. Understanding consciousness involves a\nmultiplicity not only of explananda but also of questions that they\npose and the sorts of answers they require. At the risk of\noversimplifying, the relevant questions can be gathered under three\ncrude rubrics as the What, How, and Why questions: \n\nThe three questions focus respectively on describing the features of\nconsciousness, explaining its underlying basis or cause, and\nexplicating its role or value. The divisions among the three are of\ncourse somewhat artificial, and in practice the answers one gives to\neach will depend in part on what one says about the others. One can\nnot, for example, adequately answer the what question and describe the\nmain features of consciousness without addressing the why issue of its\nfunctional role within systems whose operations it affects. Nor could\none explain how the relevant sort of consciousness might arise from\nnonconscious processes unless one had a clear account of just what\nfeatures had to be caused or realized to count as producing it. Those\ncaveats notwithstanding, the three-way division of questions provides a\nuseful structure for articulating the overall explanatory project and\nfor assessing the adequacy of particular theories or models of\nconsciousness. \n\nThe What question asks us to describe and model the\nprincipal features of consciousness, but just which features are\nrelevant will vary with the sort of consciousness we aim to capture.\nThe main properties of access consciousness may be quite unlike those\nof qualitative or phenomenal consciousness, and those of reflexive\nconsciousness or narrative consciousness may differ from both. However,\nby building up detailed theories of each type, we may hope to find\nimportant links between them and perhaps even to discover that they\ncoincide in at least some key respects. \n\nThe general descriptive project will require a variety of\ninvestigational methods (Flanagan 1992). Though one might naively\nregard the facts of consciousness as too self-evident to require any\nsystematic methods of gathering data, the epistemic task is in reality\nfar from trivial (Husserl 1913). \n\nFirst-person introspective access provides a rich and essential\nsource of insight into our conscious mental life, but it is neither\nsufficient in itself nor even especially helpful unless used in a\ntrained and disciplined way. Gathering the needed evidence about the\nstructure of experience requires us both to become phenomenologically\nsophisticated self-observers and to complement our introspective\nresults with many types of third-person data available to external\nobservers (Searle 1992, Varela 1995, Siewert 1998) \n\nAs phenomenologists have known for more than a century, discovering\nthe structure of conscious experience demands a rigorous inner-directed\nstance that is quite unlike our everyday form of self-awareness\n(Husserl 1929, Merleau-Ponty 1945). Skilled observation of the needed\nsort requires training, effort and the ability to adopt alternative\nperspectives on one's experience. \n\nThe need for third-person empirical data gathered by external\nobservers is perhaps most obvious with regard to the more clearly\nfunctional types of consciousness such as access consciousness, but it\nis required even with regard to phenomenal and qualitative\nconsciousness. For example, deficit studies that correlate various\nneural and functional sites of damage with abnormalities of conscious\nexperience can make us aware of aspects of phenomenal structure that\nescape our normal introspective awareness. As such case studies show,\nthings can come apart in experience that seem inseparably unified or\nsingular from our normal first-person point of view (Sacks 1985,\nShallice 1988, Farah 1995). \n\nOr to pick another example, third-person data can make us aware of\nhow our experiences of acting and our experiences of event-timing\naffect each other in ways that we could never discern through mere\nintrospection (Libet 1985, Wegner 2002). Nor are the facts gathered by\nthese third person methods merely about the causes or bases of\nconsciousness; they often concern the very structure of phenomenal\nconsciousness itself. First-person, third-person and perhaps even\nsecond-person (Varela 1995) interactive methods will all be needed to\ncollect the requisite evidence. \n\nUsing all these sources of data, we will hopefully be able to\nconstruct detailed descriptive models of the various sorts of\nconsciousness. Though the specific features of most importance may vary\namong the different types, our overall descriptive project will need to\naddress at least the following seven general aspects of consciousness\n(sections 4.2–4.7). \n\nQualitative character is often equated with so called\n“raw feels” and illustrated by the redness one experiences\nwhen one looks at ripe tomatoes or the specific sweet savor one\nencounters when one tastes an equally ripe pineapple (Locke 1688). The\nrelevant sort of qualitative character is not restricted to sensory\nstates, but is typically taken to be present as an aspect of\nexperiential states in general, such as experienced thoughts or desires\n(Siewert 1998). \n\nThe existence of such feels may seem to some to mark the threshold\nfor states or creatures that are really conscious. If an organism\nsenses and responds in apt ways to its world but lacks such qualia,\nthen it might count as conscious at best in a loose and less than\nliteral sense. Or so at least it would seem to those who take\nqualitative consciousness in the “what it is like” sense to\nbe philosophically and scientifically central (Nagel 1974, Chalmers\n1996). \n\nQualia problems in many forms—Can there be inverted qualia?\n(Block 1980a 1980b, Shoemaker 1981, 1982) Are qualia epiphenomenal?\n(Jackson 1982, Chalmers 1996) How could neural states give rise to\nqualia? (Levine 1983, McGinn 1991)—have loomed large in the\nrecent past. But the What question raises a more basic problem of\nqualia: namely that of giving a clear and articulated description of\nour qualia space and the status of specific qualia within it. \n\nAbsent such a model, factual or descriptive errors are all too\nlikely. For example, claims about the unintelligibility of the link\nbetween experienced red and any possible neural substrate of such an\nexperience sometimes treat the relevant color quale as a simple and\nsui generis property (Levine 1983), but phenomenal redness in\nfact exists within a complex color space with multiple systematic\ndimensions and similarity relations (Hardin 1992). Understanding the\nspecific color quale relative to that larger relational structure not\nonly gives us a better descriptive grasp of its qualitative nature, it\nmay also provide some “hooks” to which one might attach\nintelligible psycho-physical links. \n\nColor may be the exception in terms of our having a specific and\nwell developed formal understanding of the relevant qualitative space,\nbut it is not likely an exception with regard to the importance of such\nspaces to our understanding of qualitative properties in general (Clark\n1993, P.M. Churchland 1995). (See the entry on\n qualia.) \n\nPhenomenal structure should not be conflated with\nqualitative structure, despite the sometimes interchangeable use of\n“qualia” and “phenomenal properties” in the\nliterature. “Phenomenal organization” covers all the\nvarious kinds of order and structure found within the domain of\nexperience, i.e., within the domain of the world as it appears\nto us. There are obviously important links between the phenomenal and\nthe qualitative. Indeed qualia might be best understood as properties\nof phenomenal or experienced objects, but there is in fact far more to\nthe phenomenal than raw feels. As Kant (1787), Husserl (1913), and\ngenerations of phenomenologists have shown, the phenomenal structure of\nexperience is richly intentional and involves not only sensory ideas\nand qualities but complex representations of time, space, cause, body,\nself, world and the organized structure of lived reality in all its\nconceptual and nonconceptual forms. \n\nSince many non-conscious states also have intentional and\nrepresentational aspects, it may be best to consider phenomenal\nstructure as involving a special kind of intentional and\nrepresentational organization and content, the kind distinctively\nassociated with consciousness (Siewert 1998). (See the entry on\n representational theories of consciousness). \n\nAnswering the What question requires a careful account of the\ncoherent and densely organized representational framework within which\nparticular experiences are embedded. Since most of that structure is\nonly implicit in the organization of experience, it can not just be\nread off by introspection. Articulating the structure of the phenomenal\ndomain in a clear and intelligible way is a long and difficult process\nof inference and model building (Husserl 1929). Introspection can aid\nit, but a lot of theory construction and ingenuity are also needed. \nThere has been recent philosophical debate about the range of\nproperties that are phenomenally present or manifest in conscious\nexperience, in particular with respect to cognitive states such as\nbelieving or thinking.  Some have argued for a so called\n“thin” view according to which phenomenal properties are\nlimited to qualia representing basic sensory properties, such as\ncolors, shapes, tones and feels.  According to such theorists, there\nis no distinctive “what-it-is-likeness” involved in\nbelieving that Paris is the capital of France or that 17 is a prime\nnumber (Tye, Prinz 2012).  Some imagery, e.g., of the Eiffel Tower, may\naccompany our having such a thought, but that is incidental to it\nand the cognitive state itself has no phenomenal feel.  On the thin\nview, the phenomenal aspect of perceptual states as well is limited to\nbasic sensory features; when one sees an image of Winston Churchill,\none's perceptual phenomenology is limited only to the spatial aspects\nof his face.\n \nOthers holds a “thick” view according to which the\nphenomenology of perception includes a much wider range of features\nand cognitive states have a distinctive phenomenology as well\n(Strawson 2003, Pitt 2004, Seigel 2010). On the thick view, the\nwhat-it-is-likeness of perceiving an image of Marilyn Monroe includes\none's recognition of her history as part of the felt aspect of the\nexperience, and beliefs and thoughts as well can and typically do have\na distinctive nonsensory phenomenology.  Both sides of the debate are\nwell represented in the volume Cognitive Phenomenology (Bayne and\nMontague 2010).  \n\nSubjectivity is another notion sometimes equated with the\nqualitative or the phenomenal aspects of consciousness in the\nliterature, but again there are good reason to recognize it, at least\nin some of its forms, as a distinct feature of\nconsciousness—related to the qualitative and the phenomenal but\ndifferent from each.  In particular, the epistemic form of\nsubjectivity concerns apparent limits on the knowability or even the\nunderstandability of various facts about conscious experience (Nagel\n1974, Van Gulick 1985, Lycan 1996). \n\nOn Thomas Nagel's (1974) account, facts about what it is like to be\na bat are subjective in the relevant sense because they can be fully\nunderstood only from the bat-type point of view. Only creatures capable\nof having or undergoing similar such experiences can understand their\nwhat-it's-likeness in the requisite empathetic sense. Facts about\nconscious experience can be at best incompletely understood from an\noutside third person point of view, such as those associated with\nobjective physical science. A similar view about the limits of\nthird-person theory seems to lie behind claims regarding what Frank\nJackson's (1982) hypothetical Mary, the super color scientist, could\nnot understand about experiencing red because of her own impoverished\nhistory of achromatic visual experience. \n\nWhether facts about experience are indeed epistemically limited in\nthis way is open to debate (Lycan 1996), but the claim that\nunderstanding consciousness requires special forms of knowing and\naccess from the inside point of view is intuitively plausible and has a\nlong history (Locke 1688). Thus any adequate answer to the What\nquestion must address the epistemic status of consciousness, both our\nabilities to understand it and their limits (Papineau 2002, Chalmers\n2003). (See the entry on \n self-knowledge). \n\nThe perspectival structure of consciousness is one aspect of its\noverall phenomenal organization, but it is important enough to merit\ndiscussion in its own right. Insofar as the key perspective is that of\nthe conscious self, the specific feature might be called\nself-perspectuality. Conscious experiences do not exist as\nisolated mental atoms, but as modes or states of a conscious self or\nsubject (Descartes 1644, Searle 1992, though pace Hume 1739). A visual\nexperience of a blue sphere is always a matter of there being some self\nor subject who is appeared to in that way. A sharp and stabbing pain is\nalways a pain felt or experienced by some conscious subject. The self\nneed not appear as an explicit element in our experiences, but as Kant\n(1787) noted the “I think” must at least potentially\naccompany each of them. \n\nThe self might be taken as the perspectival point from which the\nworld of objects is present to experience (Wittgenstein 1921). It\nprovides not only a spatial and temporal perspective for our experience\nof the world but one of meaning and intelligibility as well. The\nintentional coherence of the experiential domain relies upon the dual\ninterdependence between self and world: the self as perspective from\nwhich objects are known and the world as the integrated structure of\nobjects and events whose possibilities of being experienced implicitly\ndefine the nature and location of the self (Kant 1787, Husserl\n1929). \n\nConscious organisms obviously differ in the extent to which they\nconstitute a unified and coherent self, and they likely differ\naccordingly in the sort or degree of perspectival focus they embody in\ntheir respective forms of experience (Lorenz 1977). Consciousness may\nnot require a distinct or substantial self of the traditional Cartesian\nsort, but at least some degree of perspectivally self-like organization\nseems essential for the existence of anything that might count as\nconscious experience. Experiences seem no more able to exist without a\nself or subject to undergo them than could ocean waves exist without\nthe sea through which they move. The Descriptive question thus requires\nsome account of the self-perspectival aspect of experience and the\nself-like organization of conscious minds on which it depends, even if\nthe relevant account treats the self in a relatively deflationary and\nvirtual way (Dennett 1991, 1992). \n\nUnity is closely linked with the self-perspective, but it\nmerits specific mention on its own as a key aspect of the organization\nof consciousness. Conscious systems and conscious mental states both\ninvolve many diverse forms of unity. Some are causal unities associated\nwith the integration of action and control into a unified focus of\nagency. Others are more representational and intentional forms of unity\ninvolving the integration of diverse items of content at many scales\nand levels of binding (Cleeremans 2003). \n\nSome such integrations are relatively local as when diverse features\ndetected within a single sense modality are combined into a\nrepresentation of external objects bearing those features, e.g. when\none has a conscious visual experience of a moving red soup can passing\nabove a green striped napkin (Triesman and Gelade 1980). \n\nOther forms of intentional unity encompass a far wider range of\ncontents. The content of one's present experience of the room in which\none sits depends in part upon its location within a far larger\nstructure associated with one's awareness of one's existence as an\nongoing temporally extended observer within a world of spatially\nconnected independently existing objects (Kant 1787, Husserl 1913). The\nindividual experience can have the content that it does only because it\nresides within that larger unified structure of representation. (See\nthe entry on\n unity of consciousness.) \nParticular attention has been paid recently to the notion of\nphenomenal unity (Bayne 2010) and its relation to other forms of\nconscious unity such as those involving representational, functional\nor neural integration. Some have argued that phenomenal unity can be\nreduced to representational unity (Tye 2005) while others have denied\nthe possibility of any such reduction (Bayne 2010). \n\nConscious mental states are typically regarded as having a\nrepresentational or intentional aspect in so far as they are about\nthings, refer to things or have satisfaction conditions. One's\nconscious visual experience correctly represents the world if\nthere are lilacs in a white vase on the table (pace Travis 2004), one's\nconscious memory is of the attack on the World Trade Center,\nand one's conscious desire is for a glass of cold water.\nHowever, nonconscious states can also exhibit intentionality in such\nways, and it is important to understand the ways in which the\nrepresentational aspects of conscious states resemble and differ from\nthose of nonconscious states (Carruthers 2000). Searle (1990) offers a\ncontrary view according to which only conscious states and dispositions\nto have conscious states can be genuinely intentional, but most\ntheorists regard intentionality as extending widely into the\nunconscious domain. (See the entry on\n consciousness and intentionality.) \n\nOne potentially important dimension of difference concerns so called\ntransparency, which is an important feature of consciousness\nin two interrelated metaphoric senses, each of which has an\nintentional, an experiential and a functional aspect. \n\nConscious perceptual experience is often said to be transparent, or\nin G.E. Moore's (1922) phrase “diaphanous”. We\ntransparently “look through” our sensory experience in so\nfar as we seem directly aware of external objects and events present to\nus rather than being aware of any properties of experience by which it\npresents or represents such objects to us. When I look out at the\nwind-blown meadow, it is the undulating green grass of which I am aware\nnot of any green property of my visual experience. (See the entry on\n representational theories of consciousness.)\n Moore himself believed we could become aware of those latter\nqualities with effort and redirection of attention, though some\ncontemporary transparency advocates deny it (Harman 1990, Tye\n1995, Kind 2003). \n\nConscious thoughts and experiences are also transparent in a\nsemantic sense in that their meanings seem immediately known to us in\nthe very act of thinking them (Van Gulick 1992). In that sense we might\nbe said to ‘think right through’ them to what they mean or\nrepresent. Transparency in this semantic sense may correspond at least\npartly with what John Searle calls the “intrinsic\nintentionality” of consciousness (Searle 1992). \n\nOur conscious mental states seem to have their meanings\nintrinsically or from the inside just by being what they are in\nthemselves, by contrast with many externalist theories of mental\ncontent that ground meaning in causal, counterfactual or informational\nrelations between bearers of intentionality and their semantic or\nreferential objects. \n\nThe view of conscious content as intrinsically determined and\ninternally self-evident is sometimes supported by appeals to brain in\nthe vat intuitions, which make it seem that the envatted brain's\nconscious mental states would keep all their normal intentional\ncontents despite the loss of all their normal causal and informational\nlinks to the world (Horgan and Tienson 2002). There is continued\ncontroversy about such cases and about competing internalist (Searle\n1992) and externalist views (Dretske 1995) of conscious\nintentionality. \n\nThough semantic transparency and intrinsic intentionality have some\naffinities, they should not be simply equated, since it may be possible\nto accommodate the former notion within a more externalist account of\ncontent and meaning. Both semantic and sensory transparency obviously\nconcern the representational or intentional aspects of consciousness,\nbut they are also experiential aspects of our conscious life. They are\npart of what it's like or how it feels phenomenally to be conscious.\nThey also both have functional aspects, in so far as conscious experiences\ninteract with each other in richly content-appropriate ways that\nmanifest our transparent understanding of their contents. \n\nThe dynamics of consciousness are evident in the coherent\norder of its ever changing process of flow and self-transformation,\nwhat William James (1890) called the “stream of\nconsciousness.” Some temporal sequences of experience are\ngenerated by purely internal factors as when one thinks through a\npuzzle, and others depend in part upon external causes as when one\nchases a fly ball, but even the latter sequences are shaped in large\npart by how consciousness transforms itself. \n\nWhether partly in response to outer influences or entirely from\nwithin, each moment to moment sequence of experience grows coherently\nout of those that preceded it, constrained and enabled by the global\nstructure of links and limits embodied in its underlying prior\norganization (Husserl 1913). In that respect, consciousness is an\nautopoietic system, i.e., a self-creating and self-organizing system\n(Varela and Maturana 1980). \n\nAs a conscious mental agent I can do many things such as scan my\nroom, scan a mental image of it, review in memory the courses of a\nrecent restaurant meal along with many of its tastes and scents, reason\nmy way through a complex problem, or plan a grocery shopping trip and\nexecute that plan when I arrive at the market. These are all routine\nand common activities, but each involves the directed generation of\nexperiences in ways that manifest an implicit practical understanding\nof their intentional properties and interconnected contents (Van Gulick\n2000). \n\nConsciousness is a dynamic process, and thus an adequate descriptive\nanswer to the What question must deal with more than just its static or\nmomentary properties. In particular, it must give some account of the\ntemporal dynamics of consciousness and the ways in which its\nself-transforming flow reflects both its intentional coherence and the\nsemantic self-understanding embodied in the organized controls through\nwhich conscious minds continually remake themselves as autopoietic\nsystems engaged with their worlds. \n\nA comprehensive descriptive account of consciousness would need to\ndeal with more than just these seven features, but having a clear\naccount of each of them would take us a long way toward answering the\n“What is consciousness?” question. \n\nThe How question focuses on explanation rather than\ndescription. It asks us to explain the basic status of consciousness\nand its place in nature. Is it a fundamental feature of reality in its\nown right, or does its existence depend upon other nonconscious items,\nbe they physical, biological, neural or computational? And if the\nlatter, can we explain or understand how the relevant nonconscious\nitems could cause or realize consciousness? Put simply, can we explain\nhow to make something conscious out of things that are not\nconscious? \n\nThe How question is not a single question, but rather a general\nfamily of more specific questions (Van Gulick 1995). They all concern\nthe possibility of explaining some sort or aspect of consciousness, but\nthey vary in their particular explananda, the restrictions on their\nexplanans, and their criteria for successful explanation. For example,\none might ask whether we can explain access consciousness\ncomputationally by mimicking the requisite access relations in a\ncomputational model. Or one might be concerned instead with whether the\nphenomenal and qualitative properties of a conscious creature's mind\ncan be a priori deduced from a description of the neural\nproperties of its brain processes. Both are versions of the How\nquestion, but they ask about the prospects of very different\nexplanatory projects, and thus may differ in their answers (Lycan\n1996). It would be impractical, if not impossible, to catalog all the\npossible versions of the How question, but some of the main options can be\nlisted. \n\nExplananda. Possible explananda would include the various\nsorts of state and creature consciousness distinguished above, as well\nas the seven features of consciousness listed in response to the What\nquestion. Those two types of explananda overlap and intersect. We might\nfor example aim to explain the dynamic aspect either of phenomenal or\nof access consciousness. Or we could try to explain the subjectivity of\neither qualitative or meta-mental consciousness. Not every feature\napplies to every sort of consciousness, but all apply to several. How\none explains a given feature in relation to one sort of consciousness\nmay not correspond with what is needed to explain it relative to\nanother. \n\nExplanans. The range of possible explanans is also diverse.\nIn perhaps its broadest form, the How question asks how consciousness\nof the relevant sort could be caused or realized by nonconscious items,\nbut we can generate a wealth of more specific questions by further\nrestricting the range of the relevant explanans. One might seek to\nexplain how a given feature of consciousness is caused or realized by\nunderlying neural processes, biological structures,\nphysical mechanisms, functional or\nteleofunctional relations, computational\norganization, or even by nonconscious mental states. The\nprospects for explanatory success will vary accordingly. In general the\nmore limited and elementary the range of the explanans, the more\ndifficult the problem of explaining how could it suffice to produce\nconsciousness (Van Gulick 1995). \n\nCriteria of explanation. The third key parameter is how one\ndefines the criterion for a successful explanation. One might require\nthat the explanandum be a priori deducible from the explanans,\nalthough it is controversial whether this is either a necessary or a\nsufficient criterion for explaining consciousness (Jackson 1993). Its\nsufficiency will depend in part on the nature of the premises from\nwhich the deduction proceeds. As a matter of logic, one will need some\nbridge principles to connect propositions or sentences about\nconsciousness with those that do not mention it. If one's premises\nconcern physical or neural facts, then one will need some bridge\nprinciples or links that connect such facts with facts about\nconsciousness (Kim 1998). Brute links, whether nomic or merely well\nconfirmed correlations, could provide a logically sufficient bridge to\ninfer conclusions about consciousness. But they would probably not\nallow us to see how or why those connections hold, and thus they would\nfall short of fully explaining how consciousness exists (Levine 1983,\n1993, McGinn 1991). \n\nOne could legitimately ask for more, in particular for some account\nthat made intelligible why those links hold and perhaps why they could\nnot fail to do so. A familiar two-stage model for explaining\nmacro-properties in terms of micro-substrates is often invoked. In the\nfirst step, one analyzes the macro-property in terms of functional\nconditions, and then in the second stage one shows that the\nmicro-structures obeying the laws of their own level nomically suffice\nto guarantee the satisfaction of the relevant functional conditions\n(Armstrong 1968, Lewis 1972). \n\nThe micro-properties of collections of H2O molecules at 20°C\nsuffice to satisfy the conditions for the liquidity of the water they\ncompose. Moreover, the model makes intelligible how the liquidity is\nproduced by the micro-properties. A satisfactory explanation of how\nconsciousness is produced might seem to require a similar two stage\nstory. Without it, even a priori deducibility might seem\nexplanatorily less than sufficient, though the need for such a story\nremains a matter of controversy (Block and Stalnaker 1999, Chalmers\nand Jackson 2001). \n\nOur current inability to supply a suitably intelligible link is\nsometimes described, following Joseph Levine (1983), as the existence\nof an explanatory gap, and as indicating our incomplete\nunderstanding of how consciousness might depend upon a nonconscious\nsubstrate, especially a physical substrate. The basic gap claim admits\nof many variations in generality and thus in strength. \n\nIn perhaps its weakest form, it asserts a practical limit\non our present explanatory abilities; given our current\ntheories and models we can not now articulate an intelligible link. A\nstronger version makes an in principle claim about our\nhuman capacities and thus asserts that given our human\ncognitive limits we will never be able to bridge the gap. To us, or\ncreatures cognitively like us, it must remain a residual mystery\n(McGinn 1991). Colin McGinn (1995) has argued that given the inherently\nspatial nature of both our human perceptual concepts and the scientific\nconcepts we derive from them, we humans are not conceptually suited for\nunderstanding the nature of the psychophysical link. Facts about that\nlink are as cognitively closed to us as are facts about multiplication\nor square roots to armadillos. They do not fall within our conceptual\nand cognitive repertoire. An even stronger version of the gap claim\nremoves the restriction to our cognitive nature and denies in\nprinciple that the gap can be closed by any cognitive\nagents. \n\nThose who assert gap claims disagree among themselves about what\nmetaphysical conclusions, if any, follow from our supposed epistemic\nlimits. Levine himself has been reluctant to draw any anti-physicalist\nontological conclusions (Levine 1993, 2001). On the other hand some\nneodualists have tried to use the existence of the gap to refute\nphysicalism (Foster 1996, Chalmers 1996). The stronger one's\nepistemological premise, the better the hope of deriving a metaphysical\nconclusion. Thus unsurprisingly, dualist conclusions are often\nsupported by appeals to the supposed impossibility in\nprinciple of closing the gap. \n\nIf one could see on a priori grounds that there is no way\nin which consciousness could be intelligibly explained as arising from\nthe physical, it would not be a big step to concluding that it in fact\ndoes not do so (Chalmers 1996). However, the very strength of such an\nepistemological claim makes it difficult to assume with begging the\nmetaphysical result in question. Thus those who wish to use a strong\nin principle gap claim to refute physicalism must find\nindependent grounds to support it. Some have appealed to conceivability\narguments for support, such as the alleged conceivability of zombies\nmolecularly identical with conscious humans but devoid of all\nphenomenal consciousness (Campbell 1970, Kirk 1974, Chalmers 1996).\nOther supporting arguments invoke the supposed non-functional nature of\nconsciousness and thus its alleged resistance to the standard\nscientific method of explaining complex properties (e.g., genetic\ndominance) in terms of physically realized functional conditions (Block\n1980a, Chalmers 1996). Such arguments avoid begging the\nanti-physicalist question, but they themselves rely upon claims and\nintuitions that are controversial and not completely independent of\none's basic view about physicalism. Discussion on the topic remains\nactive and ongoing. \n\nOur present inability to see any way of closing the gap may exert\nsome pull on our intuitions, but it may simply reflect the limits of\nour current theorizing rather than an unbridgeable in principle barrier\n(Dennett 1991). Moreover, some physicalists have argued that\nexplanatory gaps are to be expected and are even entailed by plausible\nversions of ontological physicalism, ones that treat human agents as\nphysically realized cognitive systems with inherent limits that derive\nfrom their evolutionary origin and situated contextual mode of\nunderstanding (Van Gulick 1985, 2003; McGinn 1991, Papineau 1995,\n2002). On this view, rather than refuting physicalism, the existence of\nexplanatory gaps may confirm it. Discussion and disagreement on these\ntopics remains active and ongoing. \n\nAs the need for intelligible linkage has shown, a priori\ndeducibility is not in itself obviously sufficient for successful\nexplanation (Kim 1980), nor is it clearly necessary. Some weaker\nlogical link might suffice in many explanatory contexts. We can\nsometimes tell enough of a story about how facts of one sort depend\nupon those of another to satisfy ourselves that the latter do in fact\ncause or realize the former even if we can not strictly deduce all the\nformer facts from the latter. \n\nStrict intertheoretical deduction was taken as the reductive norm by\nthe logical empiricist account of the unity of science (Putnam and\nOppenheim 1958), but in more recent decades a looser nonreductive\npicture of relations among the various sciences has gained favor. In\nparticular, nonreductive materialists have argued for the so called\n“autonomy of the special sciences” (Fodor 1974) and for the\nview that understanding the natural world requires us to use a\ndiversity of conceptual and representational systems that may not be\nstrictly intertranslatable or capable of being put into the tight\ncorrespondence required by the older deductive paradigm of interlevel\nrelations (Putnam 1975). \n\nEconomics is often cited as an example (Fodor 1974, Searle 1992).\nEconomic facts may be realized by underlying physical processes, but no\none seriously demands that we be able to deduce the relevant economic\nfacts from detailed descriptions of their underlying physical bases or\nthat we be able to put the concepts and vocabulary of economics in\ntight correspondence with those of the physical sciences. \n\nNonetheless our deductive inability is not seen as cause for\nontological misgivings; there is no “money-matter” problem.\nAll that we require is some general and less than deductive\nunderstanding of how economic properties and relations might be\nunderlain by physical ones. Thus one might opt for a similar criterion\nfor interpreting the How question and for what counts as explaining how\nconsciousness might be caused or realized by nonconscious items.\nHowever, some critics, such as Kim (1987), have challenged the\ncoherence of any view that aims to be both non-reductive and\nphysicalist, though supporters of such views have replied in turn (Van\nGulick 1993). \n\nOthers have argued that consciousness is especially resistant to\nexplanation in physical terms because of the inherent differences\nbetween our subjective and objective modes of understanding. Thomas\nNagel famously argued (1974) that there are unavoidable limits placed on our\nability to understand the phenomenology of bat experience by our\ninability to empathetically take on an experiential perspective like\nthat which characterizes the bat's echo-locatory auditory experience of\nits world. Given our inability to undergo similar experience, we can\nhave at best partial understanding of the nature of such experience. No\namount of knowledge gleaned from the external objective third-person\nperspective of the natural sciences will supposedly suffice to allow us\nto understand what the bat can understand of its own experience from\nits internal first-person subjective point of view. \n\nThe How question thus subdivides into a diverse family of more\nspecific questions depending upon the specific sort or feature of\nconsciousness one aims to explain, the specific restrictions one places\non the range of the explanans and the criterion one uses to define\nexplanatory success. Some of the resulting variants seem easier to\nanswer than others. Progress may seem likely on some of the so called\n“easy problems” of consciousness, such as explaining the\ndynamics of access consciousness in terms of the functional or\ncomputational organization of the brain (Baars 1988). Others may seem\nless tractable, especially the so-called “hard problem”\n(Chalmers 1995) which is more or less that of giving an intelligible\naccount that lets us see in an intuitively satisfying way how\nphenomenal or “what it's like” consciousness might arise\nfrom physical or neural processes in the brain. \n\nPositive answers to some versions of the How questions seem near at\nhand, but others appear to remain deeply baffling. Nor should we assume\nthat every version has a positive answer. If dualism is true, then\nconsciousness in at least some of its types may be basic and\nfundamental. If so,we will not be able to explain how it arises from\nnonconscious items since it simply does not do so. \n\nOne's view of the prospects for explaining consciousness will\ntypically depend upon one's perspective. Optimistic physicalists will\nlikely see current explanatory lapses as merely the reflection of the\nearly stage of inquiry and sure to be remedied in the not too distant\nfuture (Dennett 1991, Searle 1992, P. M.Churchland 1995). To dualists,\nthose same impasses will signify the bankruptcy of the physicalist\nprogram and the need to recognize consciousness as a fundamental\nconstituent of reality in its own right (Robinson 1982, Foster 1989,\n1996, Chalmers 1996). What one sees depends in part on where one\nstands, and the ongoing project of explaining consciousness will be\naccompanied by continuing debate about its status and prospects for\nsuccess. \n\nThe functional or Why question asks about the\nvalue or role or consciousness and thus indirectly\nabout its origin. Does it have a function, and if so what\nis it? Does it make a difference to the operation of systems in which\nit is present, and if so why and how? If consciousness exists as a\ncomplex feature of biological systems, then its adaptive value is\nlikely relevant to explaining its evolutionary origin, though of course\nits present function, if it has one, need not be the same as that it\nmay have had when it first arose. Adaptive functions often change over\nbiological time. Questions about the value of consciousness also have a\nmoral dimension in at least two ways. We are inclined to\nregard an organism's moral status as at least partly determined by the\nnature and extent to which it is conscious, and conscious states,\nespecially conscious affective states such as pleasures and pains, play\na major role in many of the accounts of value that underlie moral\ntheory (Singer 1975). \n\nAs with the What and How questions, the Why question poses a general\nproblem that subdivides into a diversity of more specific inquiries. In\nso far as the various sorts of consciousness, e.g., access, phenomenal,\nmeta-mental, are distinct and separable—which remains an open\nquestion—they likely also differ in their specific roles and\nvalues. Thus the Why question may well not have a single or uniform\nanswer. \n\nPerhaps the most basic issue posed by any version of the Why\nquestion is whether or not consciousness of the relevant sort has any\ncausal impact at all. If it has no effects and makes no causal\ndifference whatsoever, then it would seem unable to play any\nsignificant role in the systems or organisms in which it is present,\nthus undercutting at the outset most inquiries about its possible\nvalue. Nor can the threat of epiphenomenal irrelevance be simply\ndismissed as an obvious non-option, since at least some forms of\nconsciousness have been seriously alleged in the recent literature to\nlack causal status. (See the entry on\n epiphenomenalism.)\n Such worries have been raised especially with regard to qualia and\nqualitative consciousness (Huxley 1874, Jackson 1982, Chalmers 1996),\nbut challenges have also been leveled against the causal status of\nother sorts including meta-mental consciousness (Velmans 1991). \n\nBoth metaphysical and empirical arguments have been given in support\nof such claims. Among the former are those that appeal to intuitions\nabout the conceivability and logical possibility of zombies, i.e., of\nbeings whose behavior, functional organization, and physical structure\ndown to the molecular level are identical to those of normal human\nagents but who lack any qualia or qualitative consciousness. Some (Kirk\n1970, Chalmers 1996) assert such beings are possible in worlds that\nshare all our physical laws, but others deny it (Dennett 1991, Levine\n2001). If they are possible in such worlds, then it would seem to\nfollow that even in our world, qualia do not affect the course of\nphysical events including those that constitute our human behaviors. If\nthose events unfold in the same way whether or not qualia are present,\nthen qualia appear to be inert or epiphenomenal at least with respect\nto events in the physical world. However, such arguments and the zombie\nintuitions on which they rely are controversial and their soundness\nremains in dispute (Searle 1992, Yablo 1998, Balog 1999). \n\nArguments of a far more empirical sort have challenged the causal\nstatus of meta-mental consciousness, at least in so far as its presence\ncan be measured by the ability to report on one's mental state.\nScientific evidence is claimed to show that consciousness of that sort\nis neither necessary for any type of mental ability nor does it occur\nearly enough to act as a cause of the acts or processes typically\nthought to be its effects (Velmans 1991). According to those who make\nsuch arguments, the sorts of mental abilities that are typically\nthought to require consciousness can all be realized unconsciously in\nthe absence of the supposedly required self-awareness. \n\nMoreover, even when conscious self-awareness is present, it\nallegedly occurs too late to be the cause of the relevant actions\nrather than their result or at best a joint effect of some shared prior\ncause (Libet 1985). Self-awareness or meta-mental consciousness\naccording to these arguments turns out to be a psychological\nafter-effect rather than an initiating cause, more like a post\nfacto printout or the result displayed on one's computer screen\nthan like the actual processor operations that produce both the\ncomputer's response and its display. \n\nOnce again the arguments are controversial, and both the supposed\ndata and their interpretation are subjects of lively disagreement (see\nFlanagan 1992, and commentaries accompanying Velmans 1991). Though the\nempirical arguments, like the zombie claims, require one to consider\nseriously whether some forms of consciousness may be less causally\npotent than is typically assumed, many theorists regard the empirical\ndata as no real threat to the causal status of consciousness. \n\nIf the epiphenomenalists are wrong and consciousness, in its various\nforms, is indeed causal, what sorts of effects does it have and what\ndifferences does it make? How do mental processes that involve the\nrelevant sort of consciousness differ form those that lack it? What\nfunction(s) might consciousness play? The following six sections\n(6.2–6.7) discuss some of the more commonly given\nanswers. Though the various functions overlap to some degree, each is\ndistinct, and they differ as well in the sorts of consciousness with\nwhich each is most aptly linked. \n\nIncreased flexibility and sophistication of control.\nConscious mental processes appear to provide highly flexible and\nadaptive forms of control. Though unconscious automatic processes can\nbe extremely efficient and rapid, they typically operate in ways that\nare more fixed and predetermined than those which involve conscious\nself-awareness (Anderson 1983). Conscious awareness is thus of most\nimportance when one is dealing with novel situations and previously\nunencountered problems or demands (Penfield 1975, Armstrong 1981). \n\nStandard accounts of skill acquisition stress the importance of\nconscious awareness during the initial learning phase, which gradually\ngives way to more automatic processes of the sort that require little\nattention or conscious oversight (Schneider and Shiffrin 1977).\nConscious processing allows for the construction or compilation of\nspecifically tailored routines out of elementary units as well as for\nthe deliberate control of their execution. \n\nThere is a familiar tradeoff between flexibility and speed;\ncontrolled conscious processes purchase their customized versatility at\nthe price of being slow and effortful in contrast to the fluid rapidity\nof automatic unconscious mental operations (Anderson 1983). The\nrelevant increases in flexibility would seem most closely connected\nwith the meta-mental or higher-order form of consciousness in so far as\nthe enhanced ability to control processes depends upon greater\nself-awareness. However, flexibility and sophisticated modes of control\nmay be associated as well with the phenomenal and access forms of\nconsciousness. \n\nEnhanced capacity for social coordination. Consciousness of\nthe meta-mental sort may well involve not only an increase in\nself-awareness but also an enhanced understanding of the mental states\nof other minded creatures, especially those of other members of one's\nsocial group (Humphreys 1982). Creatures that are conscious in the\nrelevant meta-mental sense not only have beliefs, motives, perceptions\nand intentions but understand what it is to have such states and are\naware of both themselves and others as having them. \n\nThis increase in mutually shared knowledge of each other's minds,\nenables the relevant organisms to interact, cooperate and communicate\nin more advanced and adaptive ways. Although meta-mental consciousness\nis the sort most obviously linked to such a socially coordinative role,\nnarrative consciousness of the kind associated with the stream of\nconsciousness is also clearly relevant in so far as it involves the\napplication to one's own case of the interpretative abilities that\nderive in part from their social application (Ryle 1949, Dennett 1978,\n1992). \n\nMore unified and densely integrated representation of\nreality. Conscious experience presents us with a world of objects\nindependently existing in space and time. Those objects are typically\npresent to us in a multi-modal fashion that involves the integration of\ninformation from various sensory channels as well as from background\nknowledge and memory. Conscious experience presents us not with\nisolated properties or features but with objects and events situated in\nan ongoing independent world, and it does so by embodying in its\nexperiential organization and dynamics the dense network of relations\nand interconnections that collectively constitute the meaningful\nstructure of a world of objects (Kant 1787, Husserl 1913, Campbell\n1997). \n\nOf course, not all sensory information need be experienced to have\nan adaptive effect on behavior. Adaptive non-experiential sensory-motor\nlinks can be found both in simple organisms, as well as in some of the\nmore direct and reflexive processes of higher organisms. But when\nexperience is present, it provides a more unified and integrated\nrepresentation of reality, one that typically allows for more\nopen-ended avenues of response (Lorenz 1977). Consider for example the\nrepresentation of space in an organism whose sensory input channels are\nsimply linked to movement or to the orientation of a few fixed\nmechanisms such as those for feeding or grabbing prey, and compare it\nwith that in an organism capable of using its spatial information for\nflexible navigation of its environment and for whatever other spatially\nrelevant aims or goals it may have, as when a person visually scans her\noffice or her kitchen (Gallistel 1990). \n\nIt is representation of this latter sort that is typically made\navailable by the integrated mode of presentation associated with\nconscious experience. The unity of experienced space is just one\nexample of the sort of integration associated with our conscious\nawareness of an objective world. (See the entry on\n unity of consciousness.) \nThis integrative role or value is most directly associated with access\nconsciousness, but also clearly with the larger phenomenal and\nintentional structure of experience. It is relevant even to the\nqualitative aspect of consciousness in so far as qualia play an\nimportant role in our experience of unified objects in a unified space\nor scene.  It is intimately tied as well to the transparency of\nexperience described in response to the What question, especially to\nsemantic transparency (Van Gulick 1993). Integration of information\nplays a major role in several current neuro-cognitive theories of\nconsciousness especially Global Workspace theories (see section 9.5)\nand Giulio Tononi's Integrated Information theory. (section 9.6\nbelow).\n\n \n\nMore global informational access. The information carried\nin conscious mental states is typically available for use by a\ndiversity of mental subsystems and for application to a wide range of\npotential situations and actions (Baars 1988). Nonconscious information\nis more likely to be encapsulated within particular mental modules and\navailable for use only with respect to the applications directly\nconnected to that subsystem's operation (Fodor 1983). Making\ninformation conscious typically widens the sphere of its influence and\nthe range of ways it which it can be used to adaptively guide or shape\nboth inner and outer behavior. A state's being conscious may be in part\na matter of what Dennett calls “cerebral celebrity”, i.e.,\nof its ability to have a content-appropriate impact on other mental\nstates. \nThis particular role is most directly and definitionally tied to the\nnotion of access consciousness (Block 1995), but meta-mental\nconsciousness as well as the phenomenal and qualitative forms all seem\nplausibly linked to such increases in the availability of information\n(Armstrong 1981, Tye 1985). Diverse cognitive and neuro-cognitive\ntheories incorporate access as a central feature of consciousness and\nconscious processing. Global Workspace theories, Prinz's Attendend\nIntermediate Representation (AIR) (Prinz 2012) and Tononi's Integrated\nInformation Theory (IIT) all distinguish conscious states and\nprocesses at least partly in terms of enhanced wide spread access to\nthe state's content (See section 9.6)\n\n \n\nIncreased freedom of choice or free will. The issue of free\nwill remains a perennial philosophical problem, not only with regard to\nwhether or not it exists but even as to what it might or should consist\nin (Dennett 1984, van Inwagen 1983, Hasker 1999, Wegner 2002). (See\nthe entry on\n free will.)\n The notion of free will may itself remain too murky and contentious\nto shed any clear light on the role of consciousness, but there is a\ntraditional intuition that the two are deeply linked. \n\nConsciousness has been thought to open a realm of possibilities, a\nsphere of options within which the conscious self might choose or act\nfreely. At a minimum, consciousness might seem a necessary precondition\nfor any such freedom or self-determination (Hasker 1999). How could one\nengage in the requisite sort of free choice, while remaining solely\nwithin the unconscious domain? How can one determine one's own will\nwithout being conscious of it and of the options one has to shape\nit. \n\nThe freedom to chose one's actions and the ability to determine\none's own nature and future development may admit of many interesting\nvariations and degrees rather than being a simple all or nothing matter,\nand various forms or levels of consciousness might be correlated with\ncorresponding degrees or types of freedom and self-determination\n(Dennett 1984, 2003). The link with freedom seems strongest for the\nmeta-mental form of consciousness given its emphasis on self-awareness,\nbut potential connections also seem possible for most of the other\nsorts as well. \n\nIntrinsically motivating states. At least some conscious\nstates appear to have the motive force they do intrinsically. In\nparticular, the functional and motivational roles of conscious\naffective states, such as pleasures and pains, seem intrinsic to their\nexperiential character and inseparable from their qualitative and\nphenomenal properties, though the view has been challenged (Nelkin\n1989, Rosenthal 1991). The attractive positive motivational aspect of a\npleasure seems a part of its directly experienced phenomenal feel, as\ndoes the negative affective character of a pain, at least in the case\nof normal non-pathological experience. \n\nThere is considerable disagreement about the extent to which the\nfeel and motive force of pain can dissociate in abnormal cases, and\nsome have denied the existence of such intrinsically motivating aspects\naltogether (Dennett 1991). However, at least in the normal case, the\nnegative motivational force of pain seems built right into the\nfeel of the experience itself. \n\nJust how this might be so remains less than clear, and\nperhaps the appearance of intrinsic and directly experienced\nmotivational force is illusory. But if it is real, then it may be one\nof the most important and evolutionarily oldest respects in which\nconsciousness makes a difference to the mental systems and processes in\nwhich it is present (Humphreys 1992). \n\nOther suggestions have been made about the possible roles and value\nof consciousness, and these six surely do not exhaust the options.\nNonetheless, they are among the most prominent recent hypotheses, and\nthey provide a fair survey of the sorts of answers that have been\noffered to the Why question by those who believe consciousness does\nindeed make a difference. \n\nOne further point requires clarification about the various respects\nin which the proposed functions might answer the Why question. In\nparticular one should distinguish between constitutive cases\nand cases of contingent realization. In the former, fulfilling\nthe role constitutes being conscious in the relevant sense, while in\nthe latter case consciousness of a given sort is just one way among\nseveral in which the requisite role might be realized (Van Gulick\n1993). \n\nFor example, making information globally available for use by a wide\nvariety of subsystems and behavioral applications may constitute its\nbeing conscious in the access sense. By contrast, even if the\nqualitative and phenomenal forms of consciousness involve a highly\nunified and densely integrated representation of objective reality, it\nmay be possible to produce representations having those functional\ncharacteristics but which are not qualitative or phenomenal in\nnature. \n\nThe fact that in us the modes of representation with those\ncharacteristics also have qualitative and phenomenal properties may\nreflect contingent historical facts about the particular design\nsolution that happened to arise in our evolutionary ancestry. If so,\nthere may be quite other means of achieving a comparable result without\nqualitative or phenomenal consciousness. Whether this is the right way\nto think about phenomenal and qualitative conscious is unclear; perhaps\nthe tie to unified and densely integrated representation is in fact as\nintimate and constitutive as it seems to be in the case of access\nconsciousness (Carruthers 2000). Regardless of how that issue gets\nresolved, it is important to not to conflate constitution accounts with\ncontingent realization accounts when addressing the function of\nconsciousness and answering the question of why it exists (Chalmers\n1996). \n\nIn response to the What, How and Why questions many theories of\nconsciousness have been proposed in recent years. However, not all\ntheories of consciousness are theories of the same thing. They vary not\nonly in the specific sorts of consciousness they take as their object,\nbut also in their theoretical aims. \n\nPerhaps the largest division is between general metaphysical\ntheories that aim to locate consciousness in the overall ontological\nscheme of reality and more specific theories that offer detailed\naccounts of its nature, features and role. The line between the two\nsorts of theories blurs a bit, especially in so far as many specific\ntheories carry at least some implicit commitments on the more general\nmetaphysical issues. Nonetheless, it is useful to keep the division in\nmind when surveying the range of current theoretical offerings. \n\nGeneral metaphysical theories offer answers to the conscious version\nof the mind-body problem, “What is the ontological status of\nconsciousness relative to the world of physical reality?” The\navailable responses largely parallel the standard mind-body options\nincluding the main versions of dualism and physicalism. \n\nDualist theories regard at least some aspects of\nconsciousness as falling outside the realm of the physical,but specific\nforms of dualism differ in just which aspects those are. (See the entry\n on\n dualism.) \n\nSubstance dualism, such as traditional Cartesian dualism\n(Descartes 1644), asserts the existence of both physical and\nnon-physical substances. Such theories entail the existence of\nnon-physical minds or selves as entities in which consciousness\ninheres. Though substance dualism is at present largely out of favor,\nit does have some contemporary proponents (Swinburne 1986, Foster 1989,\n1996). \n\nProperty dualism in its several versions enjoys a greater\nlevel of current support. All such theories assert the existence of\nconscious properties that are neither identical with nor reducible to\nphysical properties but which may nonetheless be instantiated by the\nvery same things that instantiate physical properties. In that respect\nthey might be classified as dual aspect theories. They take\nsome parts of reality—organisms, brains, neural states or\nprocesses—to instantiate properties of two distinct and\ndisjoint sorts: physical ones and conscious, phenomenal or qualitative\nones. Dual aspect or property dualist theories can be of at least three\ndifferent types. \n\nFundamental property dualism regards conscious mental\nproperties as basic constituents of reality on a par with fundamental\nphysical properties such as electromagnetic charge. They may interact\nin causal and law-like ways with other fundamental properties such as\nthose of physics, but ontologically their existence is not dependent\nupon nor derivative from any other properties (Chalmers 1996). \n\nEmergent property dualism treats conscious properties as\narising from complex organizations of physical constituents but as\ndoing so in a radical way such that the emergent result is something\nover and above its physical causes and is not a priori\npredictable from nor explicable in terms of their strictly physical\nnatures. The coherence of such emergent views has been challenged (Kim\n1998) but they have supporters (Hasker 1999). \n\nNeutral monist property dualism treats both conscious\nmental properties and physical properties as in some way dependent upon\nand derivative from a more basic level of reality, that in itself is\nneither mental nor physical (Russell 1927, Strawson 1994). However, if\none takes dualism to be a claim about there being two distinct realms\nof fundamental entities or properties, then perhaps neutral monism\nshould not be classified as a version of property dualism in so far as\nit does not regard either mental or physical properties as ultimate or\nfundamental. \n\nPanpsychism might be regarded as a fourth type of property\ndualism in that it regards all the constituents of reality as having\nsome psychic, or at least proto-psychic, properties distinct from\nwhatever physical properties they may have (Nagel 1979). Indeed\nneutral monism might be consistently combined with some version\nof panprotopsychism (Chalmers 1996) according to which the\nproto-mental aspects of micro-constituents can give rise under\nsuitable conditions of combination to full blown consciousness. (See\nthe entry on\n panpsychism.) \nThe nature of the relevant proto-psychic aspect remains unclear, and\nsuch theories face a dilemma if offered in hope of answering the Hard\nProblem. Either the proto-psychic properties involve the sort of\nqualitative phenomenal feel that generates the Hard Problem or they do\nnot. If they do, it is difficult to understand how they could possibly\noccur as ubiquitous properties of reality. How could an electron or a\nquark have any such experiential feel? However, if the proto-psychic\nproperties do not involve any such feel, it is not clear how they are\nany better able than physical properties to account for qualitative\nconsciousness in solving the Hard Problem. \nA more modest form of panpsychism has been advocated by the\nneuroscientist Giulio Tononi (2008) and endorsed by other\nneuroscientists including Christof Koch (2012). This version derives\nfrom Tononi's integrated information theory (IIT) of consciousness\nthat identifies consciousness with integrated information which can\nexist in many degrees (see section 9.6 below). According to IIT, even\na simple indicator device such as a single photo diode possesses some\ndegree of integrated information and thus some limited degree of\nconsciousness, a consequence which both Tononi and Koch embrace as a\nform of panpsychism.  \n\nA variety of arguments have been given in favor of dualist and other\nanti-physicalist theories of consciousness. Some are largelya\npriori in nature such as those that appeal to the supposed\nconceivability of zombies (Kirk 1970, Chalmers 1996) or versions of the\nknowledge argument (Jackson 1982, 1986) which aim to reach an\nanti-physicalist conclusion about the ontology of consciousness from\nthe apparent limits on our ability to fully understand the qualitative\naspects of conscious experience through third-person physical accounts\nof the brain processes. (See Jackson 1998, 2004 for a contrary view;\nsee also entries on\n Zombies,\n and\n Qualia: The Knowledge Argument)\n Other arguments for dualism are made on more empirical grounds, such\nas those that appeal to supposed causal gaps in the chains of physical\ncausation in the brain (Eccles and Popper 1977) or those based on\nalleged anomalies in the temporal order of conscious awareness (Libet\n1982, 1985). Dualist arguments of both sorts have been much disputed\nby physicalists (P.S. Churchland 1981, Dennett and Kinsbourne\n1992). \n\nMost other metaphysical theories of consciousness are versions of\nphysicalism of one familiar sort or another. \n\nEliminativist theories reductively deny the existence of\nconsciousness or at least the existence of some of its commonly\naccepted sorts or features. (See the entry on\n eliminative materialism.)\n The radical eliminativists reject the very notion of consciousness as\nmuddled or wrong headed and claim that the conscious/nonconscious\ndistinction fails to cut mental reality at its joints (Wilkes 1984,\n1988). They regard the idea of consciousness as sufficiently off\ntarget to merit elimination and replacement by other concepts and\ndistinctions more reflective of the true nature of mind\n(P. S. Churchland 1983). \n\nMost eliminativists are more qualified in their negative assessment.\nRather than rejecting the notion outright, they take issue only with\nsome of the prominent features that it is commonly thought to involve,\nsuch as qualia (Dennett 1990, Carruthers 2000), the conscious self\n(Dennett 1992), or the so called “Cartesian Theater” where\nthe temporal sequence of conscious experience gets internally\nprojected (Dennett and Kinsbourne 1992). More modest eliminativists,\nlike Dennett, thus typically combine their qualified denials with a\npositive theory of those aspects of consciousness they take as real,\nsuch as the Multiple Drafts Model (section\n 9.3\n below). \n\nIdentity theory, at least strict psycho-physical type-type\nidentity theory, offers another strongly reductive option by\nidentifying conscious mental properties, states and processes with\nphysical ones, most typically of a neural or neurophysiological\nnature.  If having a qualitative conscious experience of phenomenal\nred just is being in a brain state with the relevant\nneurophysiological properties, then such experiential properties are\nreal but their reality is a straight forwardly physical reality. \n\nType-type identity theory is so called because it identifies\nmental and physical types or properties on a par with identifying the\nproperty of being water with the property of being composed of\nH2O molecules. After a brief period of popularity in the\nearly days of contemporary physicalism during the 1950s and 60s (Place\n1956, Smart 1959) it has been far less widely held because of problems\nsuch as the multiple realization objection according to which mental\nproperties are more abstract and thus capable of being realized by\nmany diverse underlying structural or chemical substrates (Fodor 1974,\nHellman and Thompson 1975). If one and the same conscious property\ncan be realized by different neurophysiological (or even\nnon-neurophysiological) properties in different organisms, then the\ntwo properties can not be strictly identical. \n\nNonetheless the type-type identity theory has enjoyed a recent if\nmodest resurgence at least with respect to qualia or qualitative\nconscious properties. This has been in part because treating the\nrelevant psycho-physical link as an identity is thought by some to\noffer a way of dissolving the explanatory gap problem (Hill and\nMcLaughlin 1998, Papineau 1995, 2003). They argue that if the\nconscious qualitative property and the neural property are identical,\nthen there is no need to explain how the latter causes or gives rise\nto the former. It does not cause it, it is it. And\nthus there is no gap to bridge, and no further explanation is needed.\nIdentities are not the sort of thing that can be explained, since\nnothing is identical with anything but itself, and it makes no sense\nto ask why something is identical with itself. \n\nHowever, others contend that the appeal to type-type identity does not\nso obviously void the need for explanation (Levine 2001). Even if two\ndescriptions or concepts in fact refer to one and the same property,\none may still reasonably expect some explanation of that convergence,\nsome account of how they pick out one and the same thing despite not\ninitially or intuitively seeming to do so. In other cases of\nempirically discovered property identities, such as that of heat and\nkinetic energy, there is a story to be told that explains the\nco-referential convergence, and it seems fair to expect the same in\nthe psycho-physical case. Thus appealing to type-type identities may\nnot in itself suffice to dissolve the explanatory gap problem. \n\nMost physicalist theories of consciousness are neither eliminativist\nnor based on strict type-type identities. They acknowledge the reality\nof consciousness but aim to locate it within the physical world on the\nbasis of some psycho-physical relation short of strict property\nidentity. \n\nAmong the common variants are those that take conscious reality to\nsupervene on the physical, be composed of the\nphysical, or be realized by the physical. \n\nFunctionalist theories in particular rely heavily on the\nnotion of realization to explicate the relation between\nconsciousness and the physical. According to functionalism, a state or\nprocess counts as being of a given mental or conscious type in virtue\nof the functional role it plays within a suitably organized system\n(Block 1980a). A given physical state realizes the relevant conscious\nmental type by playing the appropriate role within the larger physical\nsystem that contains it. (See the entry on \n functionalism.)\n The functionalist often appeals to analogies with other inter-level\nrelations, as between the biological and biochemical or the chemical\nand the atomic. In each case properties or facts at one level are\nrealized by complex interactions between items at an underlying\nlevel. \n\nCritics of functionalism often deny that consciousness can be\nadequately explicated in functional terms (Block 1980a, 1980b, Levine\n1983, Chalmers 1996). According to such critics, consciousness may have\ninteresting functional characteristics but its nature is not\nessentially functional. Such claims are sometimes supported by appeal\nto the supposed possibility of absent or inverted qualia, i.e., the\npossibility of beings who are functionally equivalent to normal humans\nbut who have reversed qualia or none at all. The status of such\npossibilities is controversial (Shoemaker 1981, Dennett 1990,\nCarruthers 2000), but if accepted they would seem to pose a problem for\nthe functionalist. (See the entry on\n qualia.) \n\nThose who ground ontological physicalism on the realization relation\noften combine it with a nonreductive view at the conceptual or\nrepresentational level that stresses the autonomy of the special\nsciences and the distinct modes of description and cognitive access\nthey provide. \n\nNon-reductive physicalism of this sort denies that the\ntheoretical and conceptual resources appropriate and adequate for\ndealing with facts at the level of the underlying substrate or\nrealization level must be adequate as well for dealing with those at\nthe realized level (Putnam 1975, Boyd 1980). As noted above in response\nto the How question, one can believe that all economic facts are\nphysically realized without thinking that the resources of the physical\nsciences provide all the cognitive and conceptual tools we need for\ndoing economics (Fodor 1974). \n\nNonreductive physicalism has been challenged for its alleged failure\nto “pay its physicalist dues” in reductive coin. It is\nfaulted for supposedly not giving an adequate account of how conscious\nproperties are or could be realized by underlying neural, physical or\nfunctional structures or processes (Kim 1987, 1998). Indeed it has\nbeen charged with incoherence because of its attempt to combine a\nclaim of physical realization with the denial of the ability to spell\nout that relation in a strict and a priori intelligible way\n(Jackson 2004). \n\nHowever, as noted above in discussion of the How question,\nnonreductive physicalists reply by agreeing that some account of\npsycho-physical realization is indeed needed, but adding that the\nrelevant account may fall far short of a priori deducibility,\nyet still suffice to satisfy our legitimate explanatory demands (McGinn\n1991, Van Gulick 1985). The issue remains under debate. \n\nAlthough there are many general metaphysical/ontological theories of\nconsciousness, the list of specific detailed theories about its nature\nis even longer and more diverse. No brief survey could be close to\ncomprehensive, but seven main types of theories may help to indicate the\nbasic range of options: higher-order theories, representational\ntheories, interpretative narrative theories, cognitive theories,\nneural theories, quantum theories and nonphysical theories.  The\ncategories are not mutually exclusive; for example, many cognitive\ntheories also propose a neural substrate for the relevant cognitive\nprocesses.  Nonetheless grouping them in the seven classes provides a\nbasic overview. \n\nHigher-order (HO) theories analyze the notion of a conscious mental\nstate in terms of reflexive meta-mental self-awareness. The core idea\nis that what makes a mental state M a conscious mental state is the\nfact that it is accompanied by a simultaneous and non-inferential\nhigher-order (i.e., meta-mental) state whose content is that one is now\nin M. Having a conscious desire for some chocolate involves being in\ntwo mental states; one must have both a desire for some chocolate and\nalso a higher-order state whose content is that one is now having just\nsuch a desire. Unconscious mental states are unconscious precisely in\nthat we lack the relevant higher-order states about them. Their being\nunconscious consists in the fact that we are not reflexively and\ndirectly aware of being in them. (See the entry on\n higher-order theories of consciousness.) \n\nHigher-order theories come in two main variants that differ\nconcerning the psychological mode of the relevant conscious-making\nmeta-mental states. Higher-order thought (HOT) theories take the\nrequired higher-order state to be an assertoric thought-like meta-state\n(Rosenthal 1986, 1993). Higher-order perception (HOP) theories take\nthem to be more perception-like and associated with a kind of inner\nsense and intra-mental monitoring systems of some sort (Armstrong 1981,\nLycan 1987, 1996). \n\nEach has its relative strengths and problems. HOT theorists note\nthat we have no organs of inner sense and claim that we experience no\nsensory qualities other than those presented to us by outer directed\nperception. HOP theorists on the other hand can argue that their view\nexplains some of the additional conditions required by HO accounts as\nnatural consequences of the perception-like nature of the relevant\nhigher-order states. In particular the demands that the\nconscious-making meta-state be noninferential and simultaneous with its\nlower level mental object might be explained by the parallel conditions\nthat typically apply to perception. We perceive what is happening now,\nand we do so in a way that involves no inferences, at least not any\nexplicit personal-level inferences. Those conditions are no less\nnecessary on the HOT view but are left unexplained by it, which might\nseem to give some explanatory advantage to the HOP model (Lycan 2004,\nVan Gulick 2000), though some HOT theorists argue otherwise (Carruthers\n2000). \n\nWhatever their respective merits, both HOP and HOT theories face some\ncommon challenges, including what might be called thegenerality\nproblem. Having a thought or perception of a given\nitem X—be it a rock, a pen or a potato—does not\nin general make X a conscious X. Seeing or thinking\nof the potato on the counter does not make it a conscious potato. Why\nthen should having a thought or perception of a given desire or a\nmemory make it a conscious desire or memory (Dretske 1995, Byrne\n1997). Nor will it suffice to note that we do not apply the term\n“conscious” to rocks or pens that we perceive or think of,\nbut only to mental states that we perceive or think of (Lycan 1997,\nRosenthal 1997). That may be true, but what is needed is some account\nof why it is appropriate to do so. \n\nThe higher-order view is most obviously relevant to the meta-mental\nforms of consciousness, but some of its supporters take it to explain\nother types of consciousness as well, including the more subjective\nwhat it's like and qualitative types. One common strategy is to analyze\nqualia as mental features that are capable of occurring unconsciously;\nfor example they might be explained as properties of inner states whose\nstructured similarity relations given rise to beliefs about objective\nsimilarities in the world (Shoemaker 1975, 1990). Though unconscious\nqualia can play that functional role, there need be nothing that it is\nlike to be in a state that has them (Nelkin 1989, Rosenthal 1991,\n1997). According to the HO theorist, what-it's-likeness enters\nonly when we become aware of that first-order state and its qualitative\nproperties by having an appropriate meta-state directed at it. \n\nCritics of the HO view have disputed that account, and some have\nargued that the notion of unconscious qualia on which it relies is\nincoherent (Papineau 2002). Whether or not such proposed HO accounts of\nqualia are successful, it is important to note that most HO advocates\ntake themselves to be offering a comprehensive theory of consciousness,\nor at least the core of such a general theory, rather than merely one\nlimited to some special meta-mental forms of it. \n\nOther variants of HO theory go beyond the standard HOT and HOP\nversions including some that analyze consciousness in terms of\ndispositional rather than occurrent higher-order thoughts (Carruthers\n2000). Others appeal to implicit rather than explicit higher-order\nunderstanding and weaken or remove the standard assumption that the\nmeta-state must be distinct and separate from its lower-order object\n(Gennaro 1995, Van Gulick 2000, 2004) with such views overlapping with\nso called reflexive theories discussed in the section. Other variants\nof HO theory continue to be offered, and debate between supporters and\ncritics of the basic approach remains active. (See the recent papers\nin Gennaro 2004.)  \n\nReflexive theories, like higher-order theories, imply a strong link\nbetween consciousness and self-awareness.  They differ in that they\nlocate the aspect of self-awareness directly within the conscious\nstate itself rather than in a distinct meta-state directed at it. The\nidea that conscious states involve a double intentionality goes back\nat least to Brentano (1874) in the 19th century.  The conscious state\nis intentionally directed at an object outside itself—such as a\ntree or chair in the case of a conscious perception—as well as\nintentionally directed at itself. One and the same state is both an\nouter-directed awareness and an awareness of itself.  Several recent\ntheories have claimed that such reflexive awareness is a central\nfeature of conscious mental states.  Some view themselves as variants\nof higher-order theory (Gennaro 2004, 2012) while others reject the\nhigher-order category and describe their theories as presenting a\n“same-order” account of consciousness as self-awareness\n(Kriegel 2009). Yet others challenge the level distinction by\nanalyzing the meta-intentional content as implicit in the phenomenal\nfirst-order content of conscious states, as in so called Higher-Order\nGlobal State models (HOGS) (Van Gulick 2004,2006). A sample of papers,\nsome supporting and some attacking the reflexive view can be found in\nKrigel and Williford (2006). \n\nAlmost all theories of consciousness regard it as having\nrepresentational features, but so called representationalist theories\nare defined by the stronger view that its representational features\nexhaust its mental features (Harman 1990, Tye 1995, 2000). According to\nthe representationalist, conscious mental states have no mental\nproperties other than their representational properties. Thus two\nconscious or experiential states that share all their representational\nproperties will not differ in any mental respect. \n\nThe exact force of the claim depends on how one interprets the idea\nof being “representationally the same” for which there are\nmany plausible alternative criteria. One could define it coarsely in\nterms of satisfaction or truth conditions, but understood in that way\nthe representationalist thesis seems clearly false. There are too many\nways in which states might share their satisfaction or truth conditions\nyet differ mentally, including those that concern their mode of\nconceptualizing or presenting those conditions. \n\nAt the opposite extreme, one could count two states as\nrepresentationally distinct if they differed in any features that\nplayed a role in their representational function or operation. On such\na liberal reading any differences in the bearers of content would count\nas representational differences even if they bore the same intentional\nor representational content; they might differ only in their\nmeans or mode of representation not their\ncontent. \n\nSuch a reading would of course increase the plausibility of the\nclaim that a conscious state's representational properties exhaust its\nmental properties but at the cost of significantly weakening or even\ntrivializing the thesis. Thus the representationalist seems to need an\ninterpretation of representational sameness that goes beyond\nmere satisfaction conditions and reflects all the intentional or\ncontentful aspects of representation without being sensitive to mere\ndifferences in underlying non-contentful features of the processes at\nthe realization level. Thus most representationalists provide conditions\nfor conscious experience that include both a content condition plus\nsome further causal role or format requirements (Tye 1995, Dretske\n1995, Carruthers 2000). Other representationalists accept the existence\nof qualia but treat them as objective properties that external objects\nare represented as having, i.e., they treat them as\nrepresented properties rather than as properties\nof representations or mental states (Dretske 1995, Lycan\n1996). \n\nRepresentationalism can be understood as a qualified form of\neliminativism insofar as it denies the existence of properties of a\nsort that conscious mental states are commonly thought to \nhave—or at least seem to have—namely those that are mental but not\nrepresentational. Qualia, at least if understood as intrinsic monadic\nproperties of conscious states accessible to introspection, would seem\nto be the most obvious targets for such elimination. Indeed part of the\nmotivation for representationalism is to show that one can accommodate\nall the facts about consciousness, perhaps within a physicalist\nframework, without needing to find room for qualia or any other\napparently non-representational mental properties (Dennett 1990, Lycan\n1996, Carruthers 2000). \n\nRepresentationalism has been quite popular in recent years and had\nmany defenders, but it remains highly controversial and intuitions\nclash about key cases and thought experiments (Block 1996). In\nparticular the possibility of inverted qualia provides a crucial test\ncase. To anti-representationalists, the mere logical possibility of\ninverted qualia shows that conscious states can differ in a significant\nmental respect while coinciding representationally.\nRepresentationalists in reply deny either the possibility of such\ninversion or its alleged import (Dretske 1995, Tye 2000). \n\nMany other arguments have been made for and against\nrepresentationalism, such as those concerning perceptions in different\nsense modalities of one and the same state of affairs—seeing\nand feeling the same cube—which might seem to involve mental\ndifferences distinct from how the relevant states represent the world\nto be (Peacocke 1983, Tye 2003). In each case, both sides can muster\nstrong intuitions and argumentative ingenuity. Lively debate\ncontinues. \nSome theories of consciousness stress the interpretative nature of\nfacts about consciousness.  According to such views, what is or is not\nconscious is not always a determinate fact, or at least not so\nindependent of a larger context of interpretative judgments.  The most\nprominent philosophical example is the Multiple Drafts Model (MDM) of\nconsciousness, advanced by Daniel Dennett (1991). It combines elements\nof both representationalism and higher-order theory but does so in a\nway that varies interestingly from the more standard versions of\neither providing a more interpretational and less strongly realist\nview of consciousness. \nThe MDM includes many distinct but interrelated features. Its name\nreflects the fact that at any given moment content fixations of many\nsorts are occurring throughout the brain. What makes some of these\ncontents conscious is not that they occur in a privileged spatial or\nfunctional location—the so called “Cartesian\nTheater”—nor in a special mode or format, all of which the\nMDM denies. Rather it a matter of what Dennett calls “cerebral\ncelebrity”, i.e., the degree to which a given content influences\nthe future development of other contents throughout the brain,\nespecially with regard to how those effects are manifest in the\nreports and behaviors that the person makes in response to various\nprobes that might indicate her conscious state. One of the MDM's key\nclaims is that different probes (e. g., being asked different\nquestions or being in different contexts that make differing\nbehavioral demands) may elicit different answers about the person's\nconscious state. Moreover, according to the MDM there may be no\nprobe-independent fact of the matter about what the person's conscious\nstate really was. Hence the “multiple” of the Multiple\nDrafts Model. \nThe MDM is representationalist in that it analyzes consciousness in\nterms of content relations. It also denies the existence of qualia and\nthus rejects any attempt to distinguish conscious states from\nnonconscious states by their presence. It rejects as well the notion\nof the self as an inner observer, whether located in the Cartesian\nTheater or elsewhere. The MDM treats the self as an emergent or\nvirtual aspect of the coherent roughly serially narrative that is\nconstructed through the interactive play of contents in the\nsystem. Many of those contents are bound together at the intentional\nlevel as perceptions or fixations from a relatively unified and\ntemporally extended point of view, i.e., they cohere in their contents\nas if they were the experiences of a ongoing self. But it is the order\nof dependence that is crucial to the MDM account. The relevant\ncontents are not unified because they are all observed by a single\nself, but just the converse. It is because they are unified and\ncoherent at the level of content that they count as the experiences of\na single self, at least of a single virtual self. \nIt is in this respect that the MDM shares some elements with\nhigher-order theories. The contents that compose the serial narrative\nare at least implicitly those of an ongoing if virtual self, and it is\nthey that are most likely to be expressed in the reports the person\nmakes of her conscious state in response to various probes. They thus\ninvolve a certain degree of reflexivity or self-awareness of the sort\nthat is central to higher-order theories, but the higher-order aspect\nis more an implicit feature of the stream of contents rather than\npresent in distinct explicit higher-order states of the sort found in\nstandard HO theories. \nDennett's MDM has been highly influential but has also drawn\ncriticism, especially from those who find it insufficiently realist in\nits view of consciousness and at best incomplete in achieving its\nstated goal to fully explain it (Block 1994, Dretske 1994, Levine\n1994). Many of its critics acknowledge the insight and value of the\nMDM, but deny that there are no real facts of consciousness other than\nthose captured by it (Rosenthal 1994, Van Gulick 1994, Akins\n1996). \nFrom a more empirical perspective, the neuroscientist Michael\nGazzaniga (2011) has introduced the idea of an “interpreter\nmodule” based in the left hemisphere that makes sense of our\nactions in any inferential way and constructs an ongoing narrative of\nour actions and experience.  Though the theory is not intended as a\ncomplete theory of consciousness, it accords a major role to such\ninterpretative narrative activity. \n\nA number theories of consciousness associate it with a distinct\ncognitive architecture or with a special pattern of activity with that\nstructure. \nGlobal Workspace. A major psychological example of the\ncognitive approach is the Global Workspace theory. As initially\ndeveloped by Bernard Baars (1988)) global workspace theory describes\nconsciousness in terms of a competition among processors and outputs\nfor a limited capacity resource that “broadcasts” information for\nwidespread access and use.  Being available in that way to the global\nworkspace makes information conscious at least in the access sense. It\nis available for report and the flexible control of behavior. Much\nlike Dennett's “cerebral celebrity”, being broadcast in the workspace\nmakes contents more accessible and influential with respect to other\ncontents and other processors.  At the same time the original content\nis strengthened by recurrent support back from the workspace and from\nother contents with which it coheres.  The capacity limits on the\nworkspace correspond to the limits typically placed on focal attention\nor working memory in many cognitive models.  \n\nThe model has been further developed with proposed connections to\nparticular neural and functional brain systems by Stanislas Dehaene\nand others (2000). Of special importance is the claim that\nconsciousness in both the access and phenomenal sense occurs when and\nonly when the relevant content enters the larger global network\ninvolving both primary sensory areas as well as many other areas\nincluding frontal and parietal areas associated with\nattention. Dehaene claims that conscious perception begins only with\nthe “ignition” of that larger global network; activity in the primary\nsensory areas will not suffice no matter how intense or recurrent\n(though see the contrary view of Victor Lamme in section 9.7). \nAttended Intermediate Representation. Another cognitive theory\nis Jesse Prinz's (2012) Attended Intermediate level Representation\ntheory (AIR).  The theory is a neuro-cognitive hybrid account of\nconscious. According to AIR theory, a conscious perception must meet\nboth cognitive and neural conditions. It must be a representation of a\nperceptually intermediate property which Prinz argues are the only\nproperties of which we are aware in conscious experience—we\nexperience only basic features of external objects such as colors,\nshapes, tones, and feels.  According to Prinz, our awareness of higher\nlevel properties—such as being a pine tree or my car keys—is\nwholly a matter of judging and not of conscious experience.  Hence the\nIntermediate Representational (IR) aspect of AIR.  To be conscious\nsuch a represented content must also be Attended (the A aspect of\nAIR). Prinz proposes a particular neural substrate for each component.\nHe identifies the intermediate level representations with gamma\n(40–80hz) vector activity in sensory cortex and the attentional\ncomponent with synchronized oscillations that can incorporate that\ngamma vector activity.   \n\nThe integration of information from many sources is an important\nfeature of consciousness and, as noted above (section 6.4), is often\ncited as one of its major functions.  Content integration plays an\nimportant role in various theories especially global workspace theory\n(section 9.3).  However, a proposal by the neuroscientist Giulio\nTononi (2008) goes further in identifying consciousness with\nintegrated information and asserting that information integration of\nthe relevant sort is both necessary and sufficient for consciousness\nregardless of the substrate in which it is realized (which need not be\nneural or biological).  According to Tononi's Integrated Information\nTheory (IIT), consciousness is a purely information-theoretic property\nof systems.  He proposes a mathematical measure φ that aims to\nmeasure not merely the information in the parts of a given system but\nalso the information contained in the organization of the system over\nand above that in its parts. φ thus corresponds to the system's\ndegree of informational integration.  Such a system can contain many\noverlapping complexes and the complex with the highest φ value\nwill be conscious according to IIT.  According to IIT, consciousness varies in quantity and comes in\nmany degrees which correspond to φ values.  Thus even a simple\nsystem such a single photo diode will be conscious to some degree if\nit is not contained within a larger complex.  In that sense, IIT\nimplies a form of panpsychism that Tononi explicitly endorses.\nAccording to IIT, the quality of the relevant consciousness is\ndetermined by the totality of informational relations within the\nrelevant integrated complex.  Thus IIT aims to explain both the\nquantity and quality of phenomenal consciousness.  Other\nneuroscientists, notably Christof Koch, have also endorsed the IIT\napproach (Koch 2012). Neural theories of consciousness come in many forms, though most in\nsome way concern the so called “neural correlates of\nconsciousness” or NCCs. Unless one is a dualist or other\nnon-physicalist, more than mere correlation is required; at least some\nNCCs must be the essential substrates of consciousness. An explanatory\nneural theory needs to explain why or how the relevant correlations\nexist, and if the theory is committed to physicalism that will require\nshowing how the underlying neural substrates could be identical with\ntheir neural correlates or at least realize them by satisfying the\nrequired roles or conditions (Metzinger 2000). \n\nSuch theories are diverse not only in the neural processes or\nproperties to which they appeal but also in the aspects of\nconsciousness they take as their respective explananda. Some are based\non high-level systemic features of the brain, but others focus on more\nspecific physiological or structural properties, with corresponding\ndifferences in their intended explanatory targets.  Most in some way\naim to connect with theories of consciousness at other levels of\ndescription such as cognitive, representational or higher-order\ntheories. \n\nA sampling of recent neural theories might include models that\nappeal to global integrated fields (Kinsbourne), binding through\nsynchronous oscillation (Singer 1999, Crick and Koch 1990),\nNMDA-mediated transient neural assemblies (Flohr 1995), thalamically\nmodulated patterns of cortical activation (Llinas 2001), reentrant\ncortical loops (Edelman 1989), comparator mechanisms that engage in\ncontinuous action-prediction-assessment loops between frontal and\nmidbrain areas (Gray 1995), left hemisphere based interpretative\nprocesses (Gazzaniga 1988), and emotive somatosensory hemostatic\nprocesses based in the frontal-limbic nexus (Damasio 1999) or in the\nperiaqueductal gray (Panksepp 1998). \n\nIn each case the aim is to explain how organization and activity at\nthe relevant neural level could underlie one or another major type or\nfeature of consciousness. Global fields or transient synchronous\nassemblies could underlie the intentional unity of phenomenal\nconsciousness. NMDA-based plasticity, specific thalamic projections\ninto the cortex, or regular oscillatory waves could all contribute to\nthe formation of short term but widespread neural patterns or\nregularities needed to knit integrated conscious experience out of the\nlocal activity in diverse specialized brain modules. Left hemisphere\ninterpretative processes could provide a basis for narrative forms of\nconscious self-awareness. Thus it is possible for multiple distinct\nneural theories to all be true, with each contributing some partial\nunderstanding of the links between conscious mentality in its diverse\nforms and the active brain at its many levels of complex organization\nand structure. \nOne particular recent controversy has concerned the issue of whether\nglobal or merely local recurrent activity is sufficient for phenomenal\nconsciousness.  Supporters of the global neuronal workspace model\n(Dehaene 2000) have argued that consciousness of any sort can occur\nonly when contents are activated with a large scale pattern of\nrecurrent activity involving frontal and parietal areas as well as\nprimary sensory areas of cortex.  Others in particular the\npsychologist Victor Lamme (2006) and the philosopher Ned Block (2007)\nhave argued that local recurrent activity between higher and lower\nareas within sensory cortex (e.g. with visual cortex) can suffice for\nphenomenal consciousness even in the absence of verbal reportability\nand other indicators of access consciousness.  \n\nOther physical theories have gone beyond the neural and placed the\nnatural locus of consciousness at a far more fundamental level, in\nparticular at the micro-physical level of quantum phenomena. According\nto such theories, the nature and basis of consciousness can not be\nadequately understood within the framework of classical physics but\nmust be sought within the alternative picture of physical reality\nprovided by quantum mechanics. The proponents of the quantum\nconsciousness approach regard the radically alternative and often\ncounterintuitive nature of quantum physics as just what is needed to\novercome the supposed explanatory obstacles that confront more standard\nattempts to bridge the psycho-physical gap. \n\nAgain there are a wide range of specific theories and models that\nhave been proposed, appealing to a variety of quantum phenomena to\nexplain a diversity of features of consciousness. It would be\nimpossible to catalog them here or even explain in any substantial way\nthe key features of quantum mechanics to which they appeal. However, a\nbrief selective survey may provide a sense, however partial and\nobscure, of the options that have been proposed. \n\nThe physicist Roger Penrose (1989, 1994) and the anesthesiologist\nStuart Hameroff (1998) have championed a model according to which\nconsciousness arises through quantum effects occurring within\nsubcellular structures internal to neurons known as\nmicrotubules. The model posits so called “objective\ncollapses” which involve the quantum system moving from a\nsuperposition of multiple possible states to a single definite state,\nbut without the intervention of an observer or measurement as in most\nquantum mechanical models. According to the Penrose and Hameroff, the\nenvironment internal to the microtubules is especially suitable for\nsuch objective collapses, and the resulting self-collapses produce a\ncoherent flow regulating neuronal activity and making non-algorithmic\nmental processes possible. \n\nThe psychiatrist Ian Marshall has offered a model that aims to\nexplain the coherent unity of consciousness by appeal to the production\nwithin the brain of a physical state akin to that of a\nBose-Einstein condensate. The latter is a quantum phenomenon in\nwhich a collection of atoms acts as a single coherent entity and the\ndistinction between discrete atoms is lost. While brain states are not\nliterally examples of Bose-Einstein condensates, reasons have been\noffered to show why brains are likely to give rise to states that are\ncapable of exhibiting a similar coherence (Marshall and Zohar\n1990). \n\nA basis for consciousness has also been sought in\nthe holistic nature of quantum mechanics and the phenomenon of\nentanglement, according to which particles that have\ninteracted continue to have their natures depend upon each other even\nafter their separation. Unsurprisingly these models have been targeted\nespecially at explaining the coherence of consciousness, but they have\nalso been invoked as a more general challenge to the atomistic\nconception of traditional physics according to which the properties of\nwholes are to be explained by appeal to the properties of their parts\nplus their mode of combination, a method of explanation that might be\nregarded as unsuccessful to date in explaining consciousness\n(Silberstein 1998, 2001). \n\nOthers have taken quantum mechanics to indicate that consciousness\nis an absolutely fundamental property of physical reality, one that\nneeds to be brought in at the very most basic level (Stapp 1993). They\nhave appealed especially to the role of the observer in the collapse of\nthe wave function, i.e., the collapse of quantum reality from a\nsuperposition of possible states to a single definite state when a\nmeasurement is made. Such models may or may not embrace a form of\nquasi-idealism, in which the very existence of physical reality depends\nupon its being consciously observed. \n\nThere are many other quantum models of consciousness to be found in\nthe literature—some advocating a radically revisionist\nmetaphysics and others not—but these four provide a reasonable,\nthough partial, sample of the alternatives. \n\nMost specific theories of consciousness—whether cognitive,\nneural or quantum mechanical—aim to explain or model\nconsciousness as a natural feature of the physical world. However,\nthose who reject a physicalist ontology of consciousness must find ways\nof modeling it as a nonphysical aspect of reality. Thus those who adopt\na dualist or anti-physicalist metaphysical view must in the end provide\nspecific models of consciousness different from the five types above.\nBoth substance dualists and property dualists must develop the details\nof their theories in ways that articulate the specific natures of the\nrelevant non-physical features of reality with which they equate\nconsciousness or to which they appeal in order to explain it. \n\nA variety of such models have been proposed including the following.\nDavid Chalmers (1996) has offered an admittedly speculative version of\npanpsychism which appeals to the notion of information not only to\nexplain psycho-physical invariances between phenomenal and physically\nrealized information spaces but also to possibly explain the ontology\nof the physical as itself derived from the informational (a version of\n“it from bit” theory). In a somewhat similar vein, Gregg\nRosenberg has (2004) proposed an account of consciousness that\nsimultaneously addresses the ultimate categorical basis of causal\nrelations. In both the causal case and the conscious case, Rosenberg\nargues the relational-functional facts must ultimately depend upon a\ncategorical non-relational base, and he offers a model according to\nwhich causal relations and qualitative phenomenal facts both depend\nupon the same base. Also, as noted just above (section 9.8), some\nquantum theories treat consciousness as a fundamental feature of\nreality (Stapp 1993), and insofar as they do so, they might be\nplausibly classified as non-physical theories as well. \n\nA comprehensive understanding of consciousness will likely require\ntheories of many types. One might usefully and without contradiction\naccept a diversity of models that each in their own way aim\nrespectively to explain the physical, neural, cognitive, functional,\nrepresentational and higher-order aspects of consciousness. There is\nunlikely to be any single theoretical perspective that suffices for\nexplaining all the features of consciousness that we wish to\nunderstand. Thus a synthetic and pluralistic approach may provide the\nbest road to future progress.","contact.mail":"rnvangul@syr.edu","contact.domain":"syr.edu"}]
