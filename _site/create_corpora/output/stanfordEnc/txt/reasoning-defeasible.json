[{"date.published":"2005-01-21","date.changed":"2017-05-01","url":"https://plato.stanford.edu/entries/reasoning-defeasible/","author1":"Robert Koons","author1.info":"https://liberalarts.utexas.edu/philosophy/faculty/koons","entry":"reasoning-defeasible","body.text":"\n\n\nReasoning is defeasible when the corresponding argument is\nrationally compelling but not deductively valid. The truth of the\npremises of a good defeasible argument provide support for the\nconclusion, even though it is possible for the premises to be true and\nthe conclusion false. In other words, the relationship of support\nbetween premises and conclusion is a tentative one, potentially\ndefeated by additional information. Philosophers have studied the\nnature of defeasible reasoning since Aristotle’s analysis of\ndialectical reasoning in the Topics and the\nPosterior Analytics, but the subject has been studied with\nunique intensity over the last forty years, largely due to the\ninterest it attracted from the artificial intelligence movement in\ncomputer science. There have been two approaches to the study of\nreasoning: treating it either as a branch of epistemology (the study\nof knowledge) or as a branch of logic. In recent work, the term\ndefeasible reasoning has typically been limited to inferences\ninvolving rough-and-ready, exception-permitting generalizations, that\nis, inferring what has or will happen on the basis of what\nnormally happens. This narrower sense of defeasible\nreasoning, which will be the subject of this article, excludes\nfrom the topic the study of other forms of non-deductive reasoning,\nincluding inference to the best explanation, abduction, analogical\nreasoning, and scientific induction. This exclusion is to some extent\nartificial, but it reflects the fact that the formal study of these\nother forms of non-deductive reasoning remains quite rudimentary. \n\nDefeasible reasoning has been the subject of study by both\nphilosophers and computer scientists (especially those involved in the\nfield of artificial intelligence). The philosophical history of the\nsubject goes back to Aristotle, while the field of artificial\nintelligence has greatly intensified interest in it over the last\nforty years. \nAccording to Aristotle, deductive logic (especially in the form of the\nsyllogism) plays a central role in the articulation of scientific\nunderstanding, deducing observable phenomena from definitions of\nnatures that hold universally and without exception. However, in the\npractical matters of everyday life, we rely upon generalizations that\nhold only “for the most part”, under normal circumstances,\nand the application of such common sense generalizations involves\nmerely dialectical reasoning, reasoning that is defeasible\nand falls short of deductive validity. Aristotle lays out a large\nnumber and great variety of examples of such reasoning in his work\nentitled the Topics. \nInvestigations in logic after Aristotle (from later antiquity through\nthe twentieth century) seem to have focused exclusively on deductive\nlogic. This continued to be true as the predicate logic was developed\nby Peirce, Frege, Russell, Whitehead, and others in the late\nnineteenth and early twentieth centuries. With the collapse of logical\npositivism in the mid-twentieth century (and the abandonment of\nattempts to treat the physical world as a logical construction from\nfacts about sense data), new attention was given to the relationship\nbetween sense perception and the external world. Roderick Chisholm\n(Chisholm 1957; Chisholm 1966) argued that sensory appearances give\ngood, but defeasible, reasons for believing in corresponding facts\nabout the physical world. If I am “appeared to redly”\n(have the sensory experience as of being in the presence of something\nred), then, Chisholm argued, I may presume that I really am in the\npresence of something red. This presumption can, of course, be\ndefeated, if, for example, I learn that my environment is relevantly\nabnormal (for instance, all the ambient light is red). \nJohn L. Pollock developed Chisholm’s idea into a theory of\nprima facie reasons and defeaters of those reasons\n(Pollock 1967; Pollock 1979; Pollock 1974). Pollock distinguished\nbetween two kinds of defeaters of a defeasible inference:\nrebutting defeaters (which give one a prima facie reason for\nbelieving the denial of the original conclusion) and\n undercutting defeaters\n (which give one a reason for doubting that the usual relationship\nbetween the premises and the conclusion hold in the given case).\nAccording to Pollock, a conclusion is warranted, given all of\none’s evidence, if it is supported by an ultimately undefeated\nargument whose premises are drawn from that evidence. \nAs the subdiscipline of artificial intelligence took shape in the\n1960s, pioneers like John M. McCarthy and Patrick J. Hayes soon\ndiscovered the need to represent and implement the sort of defeasible\nreasoning that had been identified by Aristotle and Chisholm. McCarthy\nand Hayes (McCarthy and Hayes 1969) developed a formal language they\ncalled the “situation calculus,” for use by expert systems\nattempting to model changes and interactions among a domain of objects\nand actors. McCarthy and Hayes encountered what they called the\nframe problem: the problem of deciding which conditions will\nnot change in the wake of an event. They required a\ndefeasible principle of inertia: the presumption that any given\ncondition will not change, unless required to do so by actual events\nand dynamic laws. In addition, they encountered the qualification\nproblem: the need for a presumption that an action can be\nsuccessfully performed, once a short list of essential prerequisites\nhave been met. McCarthy (McCarthy 1977, 1038–1044) suggested\nthat the solution lay in a logical principle of\ncircumscription: the presumption that the actual situation is\nas unencumbered with abnormalities and oddities (including unexplained\nchanges and unexpected interferences) as is consistent with our\nknowledge of it. (McCarthy 1982; McCarthy 1986) In effect, McCarthy\nsuggests that it is warranted to believe whatever is true in all the\nminimal (or otherwise preferred) models of\none’s initial information set. \nIn the early 1980s, several systems of defeasible reasoning were\nproposed by others in the field of artificial intelligence: Ray\nReiter’s default logic (Reiter 1980; Etherington and Reiter\n1983, 104–108), McDermott and Doyle’s Non-Monotonic Logic\nI (McDermott and Doyle, 1982), Robert C. Moore’s Autoepistemic\nLogic (Moore 1985), and Hector Levesque’s formalization of the\n“all I know” operator (Levesque 1990). These early\nproposals involved the search for a kind of fixed point or\ncognitive equilibrium. Special rules (called default rules by\nReiter) permit drawing certain conclusions so long as these\nconclusions are consistent with what one knows, including all that one\nknows on the basis of these very default rules. In some cases, no such\nfixed point exists, and, in others, there are multiple, mutually\ninconsistent fixed points. In addition, these systems were procedural\nor computational in nature, in contrast to the semantic\ncharacterization of warranted conclusions (in terms of preferred\nmodels) in McCarthy’s circumscription system. Later work in\nartificial intelligence has tended to follow McCarthy’s lead in\nthis respect. \nPhilosophers and theorists of artificial intelligence have found a\nwide variety of applications for defeasible reasoning. In some cases,\nthe defeasibility seems to be grounded in some aspect of the subject\nor the context of communication, and in other cases in facts about the\nobjective world. The first includes defeasible rules as communicative\nor representational conventions and autoepistemic (reasoning\nabout one’s own knowledge and lack of knowledge). The latter,\nthe objective sources of defeasibility, include defeasible\nobligations, defeasible laws of nature, induction, abduction, and\nOckham’s razor (the presumption that the world is as\nuncomplicated as possible). \nMuch of John McCarthy’s early work in artificial intelligence\nconcerned the interpretation of stories and puzzles (McCarthy and\nHayes 1969; McCarthy 1977). McCarthy found that we often make\nassumptions based on what is not said. So, for example, in a puzzle\nabout safely crossing a river by canoe, we assume that there are no\nbridges or other means of conveyance available. Similarly, when using\na database to store and convey information, the information that, for\nexample, no flight is scheduled at a certain time is represented\nsimply by not listing such a flight. Inferences based on\nthese conventions are defeasible, however, because the conventions can\nthemselves be explicitly abrogated or suspended. \nNicholas Asher and his collaborators (Lascarides and Asher 1993, Asher\nand Lascarides 2003, Vieu, Bras, Asher, and Aurnague 2005, Txurruka\nand Asher 2008) have argued that defeasible reasoning is useful in\nunpacking the pragmatics of conversational implicature. \nRobert C. Moore (Moore 1985) pointed out that we sometimes infer\nthings about the world based on our not knowing certain\nthings. So, for instance, I might infer that I do not have a sister,\nsince, if I did, I would certainly know it, and I do not in fact know\nthat I have a sister. Such an inference is, of course, defeasible,\nsince if I subsequently learn that I have a sister after all, the\nbasis for the original inference is nullified. \nGeneric terms (like birds in Birds fly) are\nexpressed in English by means of bare common noun phrases (without\ndeterminer). Adverbs like normally and typically are\nalso indicators of generic predication. As Asher and Pelletier (Asher\nand Pelletier 1997) have argued, the semantics for such sentences\nseems to involve intentionality: a generic sentence can be true even\nif the majority of the kind, or even all of the kind, fail to conform\nto the generalization. It can be true that birds fly even if, as a\nresult of a freakish accident, all surviving birds are abnormally\nflightless. A promising semantic theory for the generic is to\nrepresent generic predication by means of a defeasible rule or\nconditional. \nThe progressive verb involves a similar kind of intentionality. (Asher\n1992) If Jones is crossing the street, then it would normally\nbe the case that Jones will succeed in crossing the street.\nHowever, this inference is clearly defeasible: Jones might be hit by a\ntruck midway across and never complete the crossing. \nJonathan Dancy (Dancy 1993, 2004) has developed and defended an\nanti-Humean conception of practical reasoning, according to which it\nis the facts themselves, and not our desires, aversions, or other\nattitudes towards those facts, that constitute reasons for\nacting. These facts consist of particulars’ having\nproperties, and those properties provide in each such case some reason\nfor acting--as, for example, someone’s need can provide a reason\nfor meeting that need. However, each general property can provide a\nreason only defeasibly: not only can a reason be overwhelmed by\ncontrary considerations, but a property’s valence for action can\nbe completely neutralized or even reversed by further considerations.\nFor example, even if giving pleasure is in general a reason in favor\nof acting in a certain way, the fact that some action would give\npleasure to those pleased by the suffering of others is a reason \nagainst and not for so acting. Dancy has introduced (in Dancy\n2004) the concepts of intensifiers and attenuators,\napplying to facts that strengthen or weaken the force of reasons. In\nthe extreme case, a fact can disable a reason altogether,\ncorresponding to what Joseph Raz had described as an exclusionary\nreason (Raz 1975), and to John Pollock’s idea of an\n undercutting defeater. \nTo the extent that our practical reasoning is guided at all by general\nrules or principles (something that Dancy explicitly denies), the\nreasoning must be defeasible, as John Horty has argued (Horty 2007b).\nFrom this perspective, Dancy’s thesis of moral\nparticularism corresponds to the potential defeasibility of all\ngeneral reasons (see Lance and Little 2004, 2007). Defeasible logic\ncan enable general rules to play an indispensable role despite the\nreasons holism that Dancy has uncovered. \nIn addition, defeasible reasoning can be used to illuminate moral and\nlegal dilemmas, cases in which general rules come into conflict (see\nHorty 1994, 2003). This can be done without attributing logical\ninconsistency to the conflicting rules and without treating the\nconflict as merely apparent, i.e., as due to an incomplete\nrepresentation of the rules. \nPhilosophers have, for quite some time, been interested in defeasible\nobligations, which give rise to defeasible inferences about what we\nare, all things considered, obliged to do. David Ross, in 1930,\ndiscussed the phenomena of prima facie obligations (Ross\n1930, 1939). The existence of a prima facie obligation gives one good,\nbut defeasible grounds, for believing that one ought to fulfill that\nobligation. When formal deontic logic was developed by\nChisholm and others in the 1960s (Chisholm 1963), the use of classical\nlogic gave rise to certain paradoxes, such as Chisholm’s paradox\nof contrary-to-duty imperatives. These paradoxes can be resolved by\nrecognizing that the inference from imperative to actual duty is a\ndefeasible one (Asher and Bonevac 1996; Nute 1997).  \nSuch defeasible obligations can also appear in the domain of law: see\nPrakken and Sartor 1995 and 1996. \nPhilosophers David M. Armstrong and Nancy Cartwright have argued that\nthe actual laws of nature are oaken rather than iron\n(to use Armstrong’s terms). (Armstrong 1983; Armstrong 1997,\n230–231; Cartwright 1983). Oaken laws admit of exceptions: they\nhave tacit ceteris paribus (other things being equal) or\nceteris absentibus (other things being absent) conditions. As\nCartwright points out, an inference based on such a law of nature is\nalways defeasible, since we may discover that additional\nphenomenological factors must be added to the law in question\nin special cases.  \nThere are several reasons to think that deductive logic is not an\nadequate tool for dealing with this phenomenon. In order to apply\ndeduction to the laws and the initial conditions, the laws must be\nrepresented in a form that admits of no exceptions. This would require\nexplicitly stating each potentially relevant condition in the\nantecedent of each law-stating conditional. This is impractical, not\nonly because it makes the statement of each and every law extremely\ncumbersome, but also because we know that there are many exceptional\ncases that we have not yet encountered and may not be able to imagine.\nDefeasible laws enable us to express what we really know to be the\ncase, rather than forcing us to pretend that we can make an exhaustive\nlist of all the possible exceptions. \nMore recently, Tohmé, Delrieux, and Bueno (2011) have argued\nthat defeasible reasoning is crucial to the understanding of\nscientific research programs. \nMany classical philosophical arguments, especially those in the\nperennial philosophy that endured from Plato and Aristotle to the end\nof scholasticism, can be fruitfully reconstructed by means of\ndefeasible logic. Metaphysical principles, like the laws of nature,\nmay hold in normal cases, while admitting of occasional exceptions.\nThe principle of causality, for example, that plays a central role in\nthe cosmological argument for God’s existence, can plausibly\nconstrued as a defeasible generalization (Koons 2001). \nAs discussed above (in section 1.1), prima facie reasons and defeaters\nof those reasons play a central role in contemporary epistemology, not\nonly in relation to perceptual knowledge, but also in relation to\nevery other source of knowledge: memory, imagination (as an indicator\nof possibility) and testimony, at the very least. In each cases, an\nimpression or appearance provides good but defeasible evidence of a\ncorresponding reality. \nPrediction always involves an element of defeasibilty. If one predicts\nwhat will, or what would, under some hypotheis, happen, one must\npresume that there are no unknown factors that might interfere with\nthose factors and conditions that are known. Any prediction can be\nupset by such unanticipated interventions. Prediction thus proceeds\nfrom the assumption that the situation as modeled constitutes a\nclosed world: that nothing outside that situation could\nintrude in time to upset one’s predictions. In addition, we seem\nto presume that any factor that is not known to be causally relevant\nis in fact causally irrelevant, since we are constantly encountering\nnew factors and novel combinations of factors, and it is impossible to\nverify their causal irrelevance in advance. This closed-world\nassumption is one of the principal motivations for McCarthy’s\nlogic of circumscription (McCarthy 1982; McCarthy 1986). \nWe can treat the study of defeasible reasoning either as a branch of\nepistemology (the theory of knowledge), or as a branch of logic. In\nthe epistemological apporach, defeasible reasoning is studied as a\nform of inference, that is, as a process by which we add to our stock\nof knowledge. The epistemological approach is concerned with the\ntransmission of warrant, with the question of when an\ninference, starting with justified or warranted beliefs, produces a\nnew belief that is also warranted. This approach focuses explicitly on\nthe norms of belief change. \nIn contrast, a logical approach to defeasible reasoning fastens on a\nrelationship between propositions or possible bodies of information.\nJust as deductive logic consists of the study of a certain\nconsequence relation between propositions or sets of\npropositions (the relation of valid implication), so defeasible (or\nnonmonotonic) logic consists of the study of a different kind\nof consequence relation. Deductive consequence is monotonic: if a set\nof premises logically entails a conclusion, than any superset (any set\nof premises that includes all of the first set) will also entail that\nsome conclusion. In contrast, defeasible consequence is nonmonotonic.\nA conclusion follows defeasibly or nonmonotonically from a set of\npremises just in case it is true in nearly all of the models\nthat verify the premises, or in the most normal models that\ndo. \nThe two approaches are related. In particular, a logical theory of\ndefeasible consequence will have epistemological consequences. It is\npresumably true that an ideally rational thinker will have a set of\nbeliefs that are closed under defeasible, as well as deductive,\nconsequence. However, a logical theory of defeasible consequence would\nhave a wider scope of application than a merely epistemological theory\nof inference. Defeasible logic would provide a mechanism for engaging\nin hypothetical reasoning, not just reasoning from actual\nbeliefs. \nConversely, as David Makinson and Peter Gärdenfors have pointed\nout (Makinson and Gärdenfors 1991, 185–205; Makinson 2005),\nan epistemological theory of belief change can be used to define a set\nof nonmonotonic consequence relations (one relation for each initial\nbelief state). We can define the consequence relation \\(\\alpha \\dproves \\beta\\), for a given set of beliefs \\(T\\), as holding just in case\nthe result of adding belief \\(\\alpha\\) to \\(T\\) would include belief\nin \\(\\beta\\). However, on this approach, there would be many distinct\nnonmonotonic consequence relations, instead of a single\nperspective-independent one. \nThere are have been three versions of the epistemological approach,\neach of which attempts to define how an cognitively ideal agent\narrives at warranted conclusions, given an initial input. The first\ntwo of these, John L. Pollock’s theory of defeasible reasoning\nand the theory of semantic inheritance networks, are explicitly\ncomputational in nature. They take as input a complex, structured\nstate, representing the data available to the agent, and they define a\nprocedure by which new conclusions can be warranted. The third\napproach, based on the theory of belief change (the AGM model)\ndeveloped by Alchourrón, Gärdenfors, and Makinson\n(Alchourrón, Gärdenfors, and Makinson 1982), instead lays\ndown a set of conditions that an ideal process of belief change ought\nto satisfy. The AGM model can be used to define a nonmonotonic\nconsequence relation that is temporary and local. This can represent\nreasoning that is hypothetically or counterfactually defeasible, in\nthe sense that what “follows” from a conjunctive\nproposition \\((p \\amp q)\\) need not be a superset of\nwhat “follows” from \\(p\\) alone. \nJohn Pollock’s approach to defeasible reasoning consists of\nenumerating a set of rules that are constructive and effectively\ncomputable, and that aim at describing how an ideal cognitive agent\nbuilds up a rich set of beliefs, beginning with a relatively sparse\ndata set (consisting of beliefs about immediate sensory appearances,\napparent memories, and such things). The inferences involved are not,\nfor the most part, deductive. Instead, Pollock defines, first, what it\nis for one belief to be a prima facie reason for believing\nanother proposition. In addition, Pollock defines what it is for one\nbelief, say in \\(p\\), to be a defeater for \\(q\\) as\na prima facie reason for \\(r\\). In fact. Pollock distinguishes\ntwo kinds of defeaters:\n rebutting defeaters,\n which are themselves prima facie reasons for believing the negation\nof the conclusion, and undercutting defeaters, which provide\na reason for doubting that q provides any support, in the actual\ncircumstances, for \\(r\\). (Pollock 1987, 484) A belief is\nultimately warranted in relation to a data set (or\nepistemic basis) just in case it is supported by some\nultimately undefeated argument proceeding from that epistemic\nbasis. \nIn his most recent work (Pollock 1995), Pollock uses a directed graph\nto represent the structure of an ideal cognitive state. Each directed\nlink in the network represents the first node’s being a prima\nfacie reason for the second. The new theory includes an account of\nhypothetical, as well as categorical reasoning, since each\nnode of the graph includes a (possibly empty) set of hypotheses.\nSomewhat surprisingly, Pollock assumes a principle of monotonicity\nwith respect to hypotheses: a belief that is warranted relative to a\nset of hypotheses is also warranted with respect to any superset of\nhypotheses. Pollock also permits conditionalization and reasoning by\ncases. \nAn argument is self-defeating if it supports a defeater for\none of its own defeasible steps. Here is an interesting example: (1)\nRobert says that the elephant beside him looks pink. (2)\nRobert’s color vision becomes unreliable in the presence of pink\nelephants. Ordinarily, belief 1 would support the conclusion that the\nelephant is pink, but this conclusion undercuts the argument, thanks\nto belief 2. Thus, the argument that the elephant is pink is\nself-defeating. Pollock argues that all self-defeating arguments\nshould be rejected, and that they should not be allowed to defeat\nother arguments. In addition, a set of nodes can experience mutual\ndestruction or collective defeat if each member of the set is\ndefeated by some other member, and no member of the set is defeated by\nan undefeated node that is outside the set. \nIn formalizing the undercutting rebuttal, Pollock introduces a new\nconnective, \\(\\otimes\\), where \\(p \\otimes q\\) means that it is not\nthe case that \\(p\\) wouldn’t be true unless \\(q\\) were\ntrue. Pollock uses rules, rather than conditional propositions, to\nexpress the prima facie relation. If he had, instead, introduced a\nspecial connective \\(\\Rightarrow\\), with \\(p \\Rightarrow q\\) meaning\nthat \\(p\\) would be a prima facie reason for \\(q\\), then undercutting\ndefeaters could be represented by means of negating this\nconditional. To express the fact that \\(r\\) is an undercutting\ndefeater of \\(p\\) as a prima facie reason for \\(q\\), we could state\nboth that \\((p \\Rightarrow q)\\) and \\(\\neg((p \\amp r) \\Rightarrow\nq)\\). \nIn the case of conflicting prima facie reasons, Pollock rejects the\nprinciple of specificity, a widely accepted principle\naccording to which the defeasible rule with the more specific\nantecedent takes priority over conflicting rules with less specific\nantecedents. Pollock does, however, accept a special case of\nspecificity in the area of statistical syllogisms with projectible\nproperties. (Pollock 1995, 64–66) So, if I know that most\n\\(A\\)s are \\(B\\)s, and the most \\(AC\\)s are not\n\\(B\\)s, then I should, upon learning that individual \\(b\\)\nis both \\(A\\) and \\(C\\), give priority to the \\(AC\\)\ngeneralization over the \\(A\\) generalization (concluding that\n\\(b\\) is not a \\(B)\\). \nPollock’s theory of warrant is intended to provide normative\nrules for belief, of the form: if you have warranted beliefs that are\nprima facie reasons for some further belief, and you have no\nultimately undefeated defeaters for those reasons, then that further\nbelief is warranted and should be believed. For more details of\nPollock’s theory, see the following supplementary document: \nWolfgang Spohn (Spohn 2002) has argued that Pollock’s system is\nnormatively defective because, in the end, Pollock has no\nnormative standard to appeal to, other than ad hoc intuitions about\nhow a reasonable person would respond to this or that cognitive\nsituation. Spohn suggests that, with respect to the state of\ndevelopment of the study of defeasible reasoning, Pollock’s\ntheory corresponds to C. I. Lewis’s early investigations into\nmodal logic. Lewis suggested a number of possible axiom systems, but\nlacked an adequate semantic theory that could provide an independent\ncheck on the correctness or completeness of any given list (of the\nkind that was later provided by Kripke and Kanger). Analogously, Spohn\nargues that Pollock’s system is in need of a unifying normative\nstandard. This very same criticism can be lodged, with equal justice,\nagainst a number of other theories of defeasible reasoning, including\nsemantic inheritance networks and default logic. \nThe system of semantic inheritance networks, developed by Horty,\nThomason, and Touretzky (1990), is similar to Pollock’s system.\nBoth represent cognitive states by means of directed graphs, with\nlinks representing defeasible inferences. The semantic inheritance\nnetwork theory has a intentionally narrower scope: the initial nodes\nof the network represent particular individuals, and all non-initial\nnodes represent kinds, categories or properties. A link from an\ninitial (individual) node to a category node represents simply\npredication: that Felix (initial node) is a cat (category node), for\nexample. Links between category nodes represent defeasible or generic\ninclusion: that birds (normally or usually) are flying things. To be\nmore precise, there are both positive (“is a”) and\nnegative (“is not a”) links. The negative links are\nusually reprented by means of a slash through the body of the\narrow. \nSemantic inheritance networks differ from Pollock’s system in\ntwo important ways. First, they cannot represent one fact’s\nconstituting an undercutting defeater of an inference,\nalthough they can represent rebutting defeaters. For example,\nthey do not allow an inference from the apparent color of an elephant\nto its actual color to be undercut by the information that my color\nvision is unreliable, unless I have information about the actual color\nof the elephant that contradicts its apparent color. Secondly, they do\nincorporate the principle of specificity (the principle that rules\nwith more specific antecedents take priority in case of conflict) into\nthe very definition of a warranted conclusion. In fact, in contrast to\nPollock, the semantic inheritance approach gives priority to rules\nwhose antecedents are weakly or defeasibly more specific. That is, if\nthe antecedent of one rule is defeasibly linked to the antecedent of a\nsecond rule, the first rule gains priority. For example, if Quakers\nare typically pacifists, then, when reasoning about a Quaker pacifist,\nrules pertaining to Quakers would override rules pertaining to\npacifists. For the details of semantic inheritance theory, see the\nfollowing supplementary document: \nDavid Makinson (Makinson 1994) has pointed out that semantic network\ntheory is very sensitive to the form in which defeasible information\nis represented. There is a great difference between having a direct\nlink between two nodes and having a path between the two nodes being\nsupported by the graph as a whole. The notion of preemption gives\nspecial powers to explicitly given premises over conclusions. Direct\nlinks always take priority over longer paths. Consequently,\ninheritance networks lack two desirable metalogical properties: cut\nand cautious monotony (which will be covered in more detail in the\nsection on Logical Approaches). \nCumulativity (Cut plus Cautious Monotony) corresponds to reasoning by\nlemmas or subconclusions. The Horty-Thomason-Touretzky system does\nsatisfy special cases of Cut and Cautious Monotony: if \\(A\\) is\nan atomic statement (a link from an individual to a category), then if\ngraph \\(G\\) supports \\(A\\), then for any statement\n\\(B, G \\cup \\{A\\}\\) supports \\(B\\) if and\nonly if \\(G\\) supports \\(B\\). \nAnother form of inference that is not supported by semantic\ninheritance networks is that of reasoning by cases or by dilemma. In\naddition, semantic networks do not license modus-tollens-like\ninferences: from the fact that birds normally fly and Tweety does not\nfly, we are not licensed to infer that Tweety is not a bird. (This\nfeature is also lacking in Pollock’s system.) \nAlchourrón, Gärdenfors, and Makinson (1982) developed a\nformal theory of belief revision and contraction, drawing largely on\nWillard van Orman Quine’s model of the web of belief\n(Quine and Ullian 1970). The cognitive agent is modelled as believing\na set of propositions that are ordered by their degree of\nentrenchment. This model provides the basis for a set of normative\nconstraints on belief contraction (subtracting a belief) and belief\nrevision (adding a new belief that is inconsistent with the original\nset). When a belief is added that is logically consistent with the\noriginal belief set, the agent is supposed to believe the logical\nclosure of the original set plus the new belief. When a belief is\nadded that is inconsistent with the original set, the agent retreats\nto the most entrenched of the maximal subsets of the set that are\nconsistent with the new belief, adding the new proposition to that set\nand closing under logical consequence. For the axioms of the AGM\nmodel, see the following supplementary document: \nAGM belief revision theory can be used as the basis for a system of\ndefeasible reasoning or nonmonotonic logic, as Gärdenfors and\nMakinson have recognized (Makinson and Gärdenfors 1991). If\n\\(K\\) is an epistemic state, then a nonmonotonic consequence\nrelation\n\\(\\dproves\\)\ncan be defined as follows: \\(A \\dproves B\\) iff \\(B \\in K * A\\). Unlike\nPollock’s system or semantic inheritance networks, this\ndefeasible consequence relation depends upon a background epistemic\nstate. Thus, the belief revision approach gives rise, not to a single\nnonmonotonic consequence relation, but to family of relations. Each\nbackground state \\(K\\) gives rise to its own characteristic\nconsequence relation. \nOne significant limitation of the belief-revision approach is that\nthere is no representation in the object-language of a defeasible or\ndefault rule or conditional (that is, of a conditional of the form\nIf p, then normally q or That p would be a prima facie\nreason for accepting that q). In fact, Gärdenfors\n(Gärdenfors 1978; Gärdernfors 1986) proved that no\nconditional satisfying the Ramsey test can be added to the AGM system\nwithout trivializing the revision\n relation.[1]\n (A conditional \\(\\Rightarrow\\) satisfies the Ramsey test just in case, for\nevery epistemic state \\(K, K\\) includes \\((A \\Rightarrow B)\\) iff \\(K * A\\) includes \\(B\\).) \nSince the AGM system cannot include conditional beliefs, it cannot\nelucidate the question of what logical relationships hold between\nconditional defaults. \nThe lack of a representation of conditional beliefs is closely\nconnected to another limitation of the AGM system: its inability to\nmodel repeated or iterated belief revision. The input to a\nbelief change is an epistemic state, consisting both of a set of\npropositions believed and an entrenchment relation on that set. The\noutput of an AGM revision, in contrast, consists simply of a set of\nbeliefs. The system provides no guidance on the question of what would\nbe the result of revising an epistemic state in two or more steps. If\nthe entrenchment relation could be explicitly represented by means of\nconditional propositions, then it would be possible to define the new\nentrenchment relation that would result from a single belief revision,\nmaking iterated belief revision representable. A number of proposals\nalong these lines have been made. The difficulty lies in defining\nexactly what would constitute a minimal change in the\nrelative entrenchment or epistemic ranking of a set of beliefs. To\nthis point, no clear consensus has emerged on this question. (See\nSpohn 1988; Nayak 1994; Wobcke 1995; Bochman 2001.) \nOn the larger question of the relation between belief revision and\ndefeasible reasoning, there are two possibilities: that a theory of\ndefeasible reasoning should be grounded in a theory of belief\nrevision, and that a theory of belief revision should be grounded in a\ntheory of defeasible reasoning. The second view has been defended by\nJohn Pollock (Pollock 1987; Pollock 1995) and by Hans Rott (Rott\n1989). On this second view, we must make a sharp distinction between\nbasic or foundational beliefs on the one hand and inferred or derived\nbeliefs on the other. We can then model belief change on the\nassumption that new beliefs are added to the foundation (and are\nlogically consistent with the existing set of those beliefs). Beliefs\ncan be added which are inconsistent with previous inferred beliefs,\nand the new belief state consists simply in the closure of the new\nfoundational set under the relation of defeasible consequence. On such\nan approach, default conditionals can be explicitly represented among\nthe agent’s beliefs. Gärdenfors’s triviality result\nis then avoided by rejecting one of the assumptions of the theorem,\npreservation: \nPreservation:\nIf \\(\\neg A \\not\\in K\\),then \\(K \\subseteq K * A\\). \nFrom the perspective that uses defeasible reasoning to define belief\nrevision, there is no good reason to accept Preservation. One can add\na belief that is consistent with what one already believes and thereby\nlose beliefs, since the new information might be an\nundercutting defeater to some defeasible inference that had been\nsuccessful. \nLogical approaches to defeasible reasoning treat the subject as a part\nof logic: the study of nonmonotonic consequence relations (in\ncontrast to the monotonicity of classical logic). These relations are\ndefined on propositions, not on the beliefs of an agent, so the focus\nis not on epistemology per se, although a theory of nonmonotonic logic\nwill certainly have implications for epistemology. \nA consequence relation is a mathematical relation that models what\nfollows logically from what. Consequence relations can be defined in a\nvariety of ways, such as Hilbert, Tarski, and Scott relations. A\nHilbert consequence relation is a relation between pairs of formulas,\na Tarski relation is a relation between sets of formulas (possibly\ninfinite) and individual formulas, and a Scott relation is a relation\nbetween two sets of formulas. In the case of Hilbert and Tarski\nrelations, \\(A \\vDash B\\) or \\(\\Gamma \\vDash B\\) mean\nthat the formula \\(B\\) follows from formula \\(A\\) or from\nset of formulas \\(\\Gamma\\). In the case of Scott consequence relations,\n\\(\\Gamma \\vDash \\Delta\\) means that the joint truth of all the members\nof \\(\\Gamma\\) implies (in some sense) the truth of at least one member of\n\\(\\Delta\\). To this point, studies of nonmonotonic logic have defined\nnonmonotonic consequence relations in the style of Hilbert or Tarski,\nrather than Scott. \nA (Tarski) consequence relation is monotonic just in case it\nsatisfies the following condition, for all formulas \\(p\\) and all\nsets \\(\\Gamma\\) and \\(\\Delta\\): \nMonotonicity:\nIf \\(\\Gamma \\vDash p\\), then \\(\\Gamma \\cup \\Delta \\vDash p\\). \nAny consequence relation that fails this condition is\nnonmonotonic. A relation of defeasible consequence clearly\nmust be nonmonotonic, since a defeasible inference can be defeated by\nadding additional information that constitutes a rebutting or\nundercutting defeater. \nOnce monotonicity is given up, the question arises: why call the\nrelation of defeasible consequence a logical consequence\nrelation at all? What properties do defeasible consequence and\nclassical logical consequence have in common, that would justify\ntreating them as sub-classes of the same category? What justifies\ncalling nonmonotonic consequence logical? \nTo count as logical, there are certain minimal properties\nthat a relation must satisfy. First, the relation ought to permit\nreasoning by lemmas or subconclusions. That is, if a proposition\n\\(p\\) already follows from a set \\(\\Gamma\\), then it should make no\ndifference to add \\(p\\) to \\(\\Gamma\\) as an additional premise.\nRelations that satisfy this condition are called cumulative.\nCumulative relations satisfy the following two conditions (where\n“\\(C(\\Gamma)\\)” represents the set of defeasible\nconsequences of \\(\\Gamma)\\): \nCut:\nIf \\(\\Gamma \\subseteq \\Delta \\subseteq C(\\Gamma)\\), then \\(C(\\Delta) \\subseteq C(\\Gamma)\\). \nCautious Monotony:\nIf \\(\\Gamma \\subseteq \\Delta \\subseteq C(\\Gamma)\\), then \\(C(\\Gamma) \\subseteq C(\\Delta)\\). \nIn addition, a defeasible consequence relation ought to be\nsupraclassical: if \\(p\\) follows from \\(q\\) in\nclassical logic, then it ought to be included in the defeasible\nconsequences of \\(q\\) as well. A formula \\(q\\) ought to\ncount as an (at least) defeasible consequence of itself, and anything\nincluded in the content of \\(q\\) (any formula \\(p\\) that\nfollows from \\(q\\) in classical logic) ought to count as a\ndefeasible consequence of \\(q\\) as well. Moreover, the defeasible\nconsequences of a set \\(\\Gamma\\) ought to depend only on the content of\nthe formulas in \\(\\Gamma\\), not in how that content is represented.\nConsequently, the defeasible consequence relation ought to treat\n\\(\\Gamma\\) and the classical logical closure of \\(\\Gamma\\) (which we’ll\nrepresent as “\\(Cn(\\Gamma)\\)”) in exactly the same\nway. A consequence relation that satisfies these two conditions is\nsaid to satisfy full absorption (see Makinson 1994, 47). \nFull Absorption:\n\\(Cn(C(\\Gamma)) = C(\\Gamma) = C(Cn(\\Gamma))\\) \nFinally, a genuinely logical consequence relation ought to enable us\nto reason by cases. So, it should satisfy a principle called\ndistribution: if a formula \\(p\\) follows defeasibly from both\n\\(q\\) and \\(r\\), then it ought to follow from their\ndisjunction. (To require the converse principle would be to reinstate\nmonotonicity.) The relevant principle is this: \nDistribution:\n\\(C(\\Gamma) \\cap C(\\Delta) \\subseteq C(Cn(\\Gamma) \\cap Cn(\\Delta))\\). \nConsequence relations that are cumulative, strongly absorptive, and\ndistributive satisfy a number of other desirable properties, including\nconditionalization: If a formula \\(p\\) is a defeasible\nconsequence of \\(\\Gamma \\cup \\{q\\}\\), then the material\nconditional \\((q \\rightarrow p)\\) is a defeasible consequence\nof \\(\\Gamma\\) alone. In addition, such logics satisfy the property of\nloop: if \\(p_1 \\dproves p_2 \\ldots p_{n-1} \\dproves p_n\\) (where “\n\\(\\dproves\\)\n” represents the defeasible consequence relation), then the\ndefeasible consequences of \\(p_i\\) and\n\\(p_j\\) are exactly the same, for any\n\\(i\\) or\n \\(j\\).[2] \nThere are three further conditions that have been much discussed in\nthe literature, but whose status remains controversial:\ndisjunctive rationality, rational monotony, and\nconsistency preservation. \nDisjunctive Rationality:\nIf \\(\\Gamma \\cup \\{p\\} \\notdproves r\\), and \\(\\Gamma \\cup \\{q\\}\n\\notdproves r\\), then \\(\\Gamma \\cup \\{\\)(p \\(\\vee\\) q)\\(\\} \\notdproves\nr\\). \nRational Monotony:\nIf \\(\\Gamma \\dproves A\\), then either \\(\\Gamma \\cup \\{B\\} \\dproves A\\)\nor \\(\\Gamma \\dproves \\neg B\\). \nConsistency Preservation:\nIf \\(\\Gamma\\) is classically consistent, then so is \\(C(\\Gamma)\\) (the\nset of defeasible consequences of \\(\\Gamma)\\). \nAll three properties seem desirable, but they set a very hight\nstandard for the defeasible reasoner. \nRay Reiter’s default logic (Reiter 1980; Etherington and Reiter\n1983) was part of the first generation of defeasible systems developed\nin the field of artificial intelligence. The relative ease of\ncomputing default extensions has made it one of the more popular\nsystems. \nReiter’s system is based on the use of default rules. A\ndefault rule consists of three formulas: the prerequisite,\nthe justification, and the consequent. If one\naccepts the prerequisite of a default rule, and the justification is\nconsistent with all one knows (including what one knows on the basis\nof the default rules themselves), then one is entitled to accept the\nconsequent. The most popular use of default logic relies solely on\nnormal defaults, in which the justification and the\nconsequent are identical. Thus, a normal default of the form\n\\((p\\); \\(q \\therefore q)\\) allows one to infer\n\\(q\\) from \\(p\\), so long as \\(q\\) is consistent with\none’s endpoint (the extension of the default\ntheory). \nA default theory consists of a set of formulas (the facts), together\nwith a set of default rules. An extension of a default theory\nis a fixed point of a particular inferential process: an extension\n\\(E\\) must be a consistent theory (a consistent set closed under\nclassical consequence) that contains all of the facts of the default\ntheory \\(T\\), and, in addition, for each normal default\n\\((p \\Rightarrow q)\\), if \\(p\\) belongs to \\(E\\),\nand \\(q\\) is consistent with \\(E\\), then \\(q\\) must\nbelong to \\(E\\) also. \nSince the consequence relation is defined by a fixed-point condition,\nthere are default theories that have no extension at all, and other\ntheories that have multiple, mutually inconsistent extensions. For\nexample, the theory consisting of the fact \\(p\\) and the pair of\ndefaults \\((p\\) ; \\((q \\amp r) \\therefore q)\\) and \\((q\\) ; \\(\\neg r\n\\therefore \\neg r)\\) has no extension. If the first default is\napplied, then the second must be, and if the second default is not\napplied, the first must be. However, the conclusion of the second\ndefault contradicts the prerequisite of the first, so the first cannot\nbe applied if the second is. There are many default theories that have\nmultiple extensions. Consider the theory consisting of the facts \\(q\\)\nand r and the pair of defaults \\((q\\) ; \\(p \\therefore p)\\) and \\((r\\)\n; \\(\\neg p \\therefore \\neg p)\\). One or the other, but not both,\ndefaults must be applied.  \nFurthermore, there is no guarantee that if \\(E\\) and\n\\(E'\\) are both extensions of theory \\(T\\), then the\nintersection of \\(E\\) and \\(E'\\) is also an extension\n(the intersection of two fixed points need not be itself a fixed\npoint). Default logic is usually interpreted as a credulous\nsystem: as a system of logic that allows the reasoner to select\nany extension of the theory and believe all of the members of\nthat theory, even though many of the resulting beliefs will involve\npropositions that are missing from other extensions (and may even be\ncontradicted in some of those extensions). \nDefault logic fails many of the tests for a logical relation that were\nintroduced in the previous section. It satisfied Cut and Full\nAbsorption, but it fails Cautious Monotony (and thus fails to be\ncumulative). In addition, it fails Distribution, a serious limitation\nthat rules out reasoning by cases. For example, if one knows that\nSmith is either Amish or Quaker, and both Quakers and Amish are\nnormally pacifists, one cannot infer that Smith is a pacifist. Default\nlogic also fails to represent Pollock’s undercutting\ndefeaters. Finally, default logic does not incorporate any form\nof the principle of Specificity, the principle that defaults\nwith more specific prerequisites ought, in cases of conflict, to take\npriority over defaults with less specific prerequisites. Recently,\nJohn Horty (Horty 2007a, 2007b) has examined the implications of\nadding priorities among defaults (in the form of a partial ordering),\nwhich would permit the recognition of specificity and other grounds\nfor preferring one default to another. In addition, Horty allows for\ndefeasible reasoning about these priorities (the relative weights of\nvarious defaults) by means of higher-order default rules. Such\ndefeasible reasoning about relative weights enables Horty to give an\naccount of Pollock’s\n undercutting defeaters:\n an undercutting defeater is a triggered default rule that lowers the\nweight of the undercut rule below some threshold, with the result that\nthe undercut rule can no longer be triggered. \nIn both McDermott-Doyle’s Nonmonotonic Logic I and Moore’s\nAutoepistemic logic (McDermott and Doyle, 1982; Moore, 1985; Konolige\n1994), a modal operator \\(M\\) (representing a kind of epistemic\npossibility) is used. Default rules take the following form: \\(((p\n\\amp Mq) \\rightarrow q)\\), that is, if \\(p\\) is true and \\(q\\) is\n“possible” (in the relevant sense), then \\(q\\) is also\ntrue. In both cases, the extension of a theory is defined, as in\nReiter’s default logic, by means of a fixed-point\noperation. \\(Mp\\) represents the fact that \\(\\neg p\\) does not belong\nto the extension. For example, in Moore’s case, a set \\(\\Delta\\)\nis a stable expansion of a theory \\(\\Gamma\\) just in case\n\\(\\Delta\\) is the set of classical consequences of the set \\(\\Gamma\n\\cup \\{\\neg Mp: p \\in \\Delta \\} \\cup \\{Mp: p \\not\\in \\Delta \\}\\). As\nin the case of Reiter’s default logic, some theories will lack a\nstable expansion, or have more than one. In addition, these systems\nfail to incorporate Specificity. \nIn circumscription (McCarthy 1982; McCarthy 1986; Lifschitz 1988), one\nor more predicates of the language are selected for minimization\n(there is, in addition, a further technical question of which\npredicates to treat as fixed and which to treat as variable). The\nnonmonotonic consequences of a theory \\(T\\) then consist of all\nthe formulas that are true in every model of \\(T\\) that minimizes\nthe extensions of the selected predicates. One model \\(M\\) of\n\\(T\\) is preferred to another, \\(M'\\), if and only if,\nfor each designated predicate \\(F\\), the extension of \\(F\\)\nin \\(M\\) is a subset of the extension of \\(F\\) in\n\\(M'\\), and, for some such predicate, the extension in\n\\(M\\) is a proper subset of the extension in\n\\(M'\\). \nThe relation of circumscriptive consequence has all the desirable\nmeta-logical properties. It is cumulative (satisfies Cut and Cautious\nMonotony), strongly absorptive, and distributive. In addition, it\nsatisfies Consistency Preservation, although not Rational\nMonotony. \nThe most critical problem in applying circumscription is that of\ndeciding on what predicates to minimize (there is, in addition, a\nfurther technical question about which predicates to treat as fixed\nand which as variable in extension). Most often what is done is to\nintroduce a family of abnormality predicates \\(ab_1, ab_2\\),\netc. A default rule then can be written in the form: \\(\\forall x((F(x)\n\\amp \\neg ab_i (x) ) \\rightarrow G(x))\\), where\n“\\(\\rightarrow\\)” is the ordinary material conditional of\nclassical logic. To derive the consequences of a theory, all of the\nabnormality predicates are simultaneously minimized. This simple\napproach fails to satisfy the principle of Specificity, since each\ndefault is given its own, independent abnormality predicate, and each\nis therefore treated with the same priority. It is possible to add\nspecial rules for the prioritizing of circumscription, but these are,\nof necessity, ad hoc and exogenous, rather than a natural result of\nthe definition of the consequence relation. \nCircumscription does have the capacity of representing the existence\nof undercutting defeaters. Suppose that satisfying predicate\n\\(F\\) provides a prima facie reason for supposing something to be\na \\(G\\), and suppose that we use the abnormality predicate\n\\(ab_1\\) in representing this default rule. We can\nstate that the predicate \\(H\\) provides an undercutting defeater\nto this inference by simply adding the rule: \\(\\forall x\n(H(x) \\rightarrow ab_1 (x))\\),\nstating that all \\(H\\)s are abnormal in respect number 1. \nCircumscription is a special case of a wider class of defeasible\nlogics, the preferential logics (Shoham 1987). In\npreferential logics, \\(\\Gamma \\dproves p\\) iff \\(p\\) is true in all of the most\npreferred models of \\(\\Gamma\\). In the case of circumscription, the\nmost preferred models are those that minimize the extension of certain\npredicates, but many other kinds of preference relations can be used\ninstead, so long as the preference relations are transitive and\nirreflexive (a strict partial order). A structure consisting of a set\nof models of a propositional or first-order language, together with a\npreference order on those models, is called a preferential\nstructure. The symbol \\(\\prec\\) shall represent the preference\nrelation. \\(M \\prec M'\\) means that \\(M\\)\nis strictly preferred to \\(M'\\). A most preferred model is\none that is minimal in the ordering. \nIn order to give rise to a cumulative logic (one that satisfies Cut\nand Cautious Monotony), we must add an additional condition to the\npreferential structures, a Limit Assumption (also known as the\ncondition of stopperedness or smoothness: \nLimit Assumption: Given a theory \\(T\\), and\n\\(M\\), a non-minimal model of \\(T\\), there exists a model\n\\(M'\\) which is preferred to \\(M\\) and which is a\nminimal model of \\(T\\). \nThe Limit Assumption is satisfied if the preferential structure does\nnot contain any infinite descending chains of more and more preferred\nmodels, with no minimal member. This is a difficult condition to\nmotivate as natural, but without it, we can find preferential\nstructures that give rise to nonmonotonic consequence relations that\nfail to be cumulative. \nOnce we have added the Limit Assumption, it is easy to show that any\nconsequence relation based upon a preferential model is not only\ncumulative but also supraclassical, strongly absorptive, and\ndistributive. Let’s call such logics preferential. In\nfact, Kraus, Lehmann, and Magidor (Kraus, Lehmann, and Magidor 1990;\nMakinson 1994, 77; Makinson 2005, PAGE) proved the following\nrepresentation theorem for preferential logics: \nRepresentation Theorem for Preferential Logics: if\n\\(\\dproves\\) is a cumulative, supraclassical, strongly absorptive, and\ndistributive consequence relation (i.e., a preferential relation) then\nthere is a preferential structure \\(\\mathcal{M}\\) satisfying the Limit\nAssumption such that for all finite theories \\(T\\), the set\nof \\(\\dproves\\) -consequences of \\(T\\) is exactly the set of formulas\ntrue in every preferred model of \\(T\\)\n in M.[3] \nThere are preferential logics that fail to satisfy consistency\npreservation, as well as disjunctive rationality and rational\nmonotony: \nDisjunctive Rationality:\nIf \\(\\Gamma \\cup \\{p\\} \\notdproves r\\), and \\(\\Gamma \\cup \\{q\\}\n\\notdproves r\\), then \\(\\Gamma \\cup \\{(p \\vee q)\\} \\notdproves\nr\\). \nRational Monotony: \nIf \\(\\Gamma \\dproves p\\), then either \\(\\Gamma \\cup \\{q\\} \\dproves p\\)\nor \\(\\Gamma \\dproves \\neg q\\). \nA very natural condition has been found by Kraus, Lehmann, and Magidor\nthat corresponds to Rational Monotony: that of ranked models.\n(No condition on preference structures has been found that ensures\ndisjunctive rationality without also ensuring rational monotony.) A\npreferential structure \\(\\mathcal{M}\\) satisfies the\nRanked Models condition just in case there is a function \\(r\\)\nthat assigns an ordinal number to each model in such a way that\n\\(M \\prec M'\\) iff \\(r(M) \\lt r(M')\\). Let’s say that a preferential\nconsequence relation is a rational relation just in case it\nsatisfies Rational Monotony, and that a preferential structure is a\nrational structure just in case it satisfies the ranked\nmodels condition. Kraus, Lehmann, and Magidor (Kraus, Lehmann, and\nMagidor 1990; Makinson 1994, 71–81) also proved the following\nrepresentation theorem: \nRepresentation Theorem for Rational Logics: if\n\\(\\dproves\\) is a rational consequence relation (i.e., a preferential\nrelation that satisfies Rational Monotony) then there is a\npreferential structure \\(\\mathcal{M}\\) satisfying the Limit Assumption\nand the Ranked Models Assumption such that for all finite theories\n\\(T\\), the set of \\(\\dproves\\) -consequences of \\(T\\) is exactly the\nset of formulas true in every preferred model of \\(T\\) in\n\\(\\mathcal{M}\\). \nFreund proved an analogous representation result for preferential\nlogics that satisfy disjunctive rationality, replacing the\nranking condition with a weaker condition of filtered models:\na filtered model is one such that, for every formula, if two worlds\nnon-minimally satisfy the formula, then there is a world less than\nboth of them that also satisfies the formula (Freund 1993). \nLehmann and Magidor (Lehmann and Magidor 1992) noticed an interesting\ncoincidence: the metalogical conditions for preferential consequence\nrelations correspond exactly to the axioms for a logic of conditionals\ndeveloped by Ernest W. Adams (Adams\n1975).[4]\nAdams’s logic was based on a conditional, \\(\\Rightarrow\\),\nintended to represent a relation of very high conditional probability:\n\\((p \\Rightarrow q)\\) means that the conditional probability\n\\(Pr(q/p)\\) is extremely close to 1. Adams used the standard\ndelta-epsilon definition of the calculus to make this idea\nprecise. Let us suppose that a theory \\(T\\) consists of a set of\nconditional-free formulas (the facts) and a set of probabilistic\nconditionals. A conclusion \\(p\\) follows defeasibly from \\(T\\) if and\nonly if every probability function satisfies the following\ncondition: \nFor every \\(\\delta\\), there is an \\(\\varepsilon\\) such that, if the probability\nof every fact in \\(T\\) is assigned a probability at least as high\nas 1 – \\(\\varepsilon\\), and every conditional in \\(T\\) is\nassigned a conditional probability at least as high as 1 –\n\\(\\varepsilon\\), then the probability of the conclusion \\(p\\) is at\nleast 1 – \\(\\delta\\). \nThe resulting defeasible consequence relation is a preferential\nrelation. (It need not, however, be consistency-preserving.) This\nconsequence relation also corresponds to a relation, 0-entailment,\ndefined by Judea Pearl (Pearl 1990), as the common core to all\ndefeasible consequence relations. \nLehmann and Magidor (1992) proposed a variation on Adams’s idea.\nInstead of using the delta-epsilon construction, they made use of\nnonstandard measure theory, that is, a theory of probability functions\nthat can take values that are infinitesimals (infinitely\nsmall numbers). In addition, instead of defining the consequence\nrelation by quantifying over all probability functions,\nLehmann and Magidor assume that we can select a single probability\nfunction (representing something like the ideally rational, or\nobjective probability). On their construction, a conclusion \\(p\\)\nfollows from \\(T\\) just in case the probability of \\(p\\) is\ninfinitely close to 1, on the assumption that the probabilities\nassigned to members of \\(T\\) are infinitely close to 1. Lehmann\nand Magidor proved that the resulting consequence relation is always\nnot only preferential: it is also rational. The logic defined\nby Lehmann and Magidor also corresponds exactly to the theory of\nPopper functions, another extension of probability theory designed to\nhandle cases of conditioning on propositions with infinitesimal\nprobability (see Harper 1976; van Fraassen 1995; Hawthorne 1998). For\na brief discussion of Popper functions, see the following\nsupplementary document: \n Popper Functions\n  \nArló Costa and Parikh, using van Fraassen’s account (van\nFraassen, 1995) of primitive conditional probabilities (a variant of\nPopper functions), proved a representation result for both finite and\ninfinite languages (Arló Costa and Parikh, 2005). For infinite\nlanguages, they assumed an axiom of countable additivity for\nprobabilities. \nKraus, Lehmann, and Magidor proved that, for every preferential\nconsequence relation \\(\\dproves\\) that is probabilistically\n admissible,[5]\n there is a unique rational consequence relation \\(\\dproves^*\\) that\nminimally extends it (that is, that the intersection of all the\nrational consequence relations extending \\(\\dproves\\) is also a\nrational consequence relation). This relation, \\(\\dproves^*\\), is\ncalled the rational closure of \\(\\dproves\\). To find the\nrational closure of a preferential relation, one can perform the\nfollowing operation on a preferential structure that supports that\nrelation: assign to each model in the structure the smallest number\npossible, respecting the preference relation. Judea Pearl also\nproposed the very same idea under the name\n1-entailment or System \\(Z\\) (Pearl 1990). \nA critical advantage to the Lehmann-Magidor-Pearl 1-entailment system\nover Adams’s epsilon-entailment lies in the way in which\n1-entailment handles irrelevant information. Suppose, for example,\nthat we know that birds fly \\((B \\Rightarrow F)\\), Tweety is\na bird \\((B)\\), and Nemo is a whale \\((W)\\). These premises\ndo not epsilon-entail \\(F\\) (that Tweety flies), since there is\nno guarantee that a probability function assign a high probability to\n\\(F\\), given the conjunction of \\(B\\) and\n\\(W\\). In contrast, 1-entailment does give us the conclusion\n\\(F\\). \nMoreover, 1-entailment satisfies a condition of weak independence\nof defaults: conditionals with logically unrelated antecedents\ncan “fire” independently of each other: one can warrant a\nconclusion even though we are given an explicit exception to the\nother. Consider, for example, the following case: birds fly \\((B\n\\Rightarrow F)\\), Tweety is a bird that doesn’t fly \\((B \\amp\n\\neg F)\\), whales are large \\((W \\Rightarrow L)\\), and Nemo is a whale\n\\((W)\\). These premises 1-entail that Nemo is large \\((L)\\). In\naddition, 1-entailment automatically satisfies the principle of\nSpecificity: conditionals with more specific antecedents are always\ngiven priority over those with less specific antecedents. \nThere is another form of independence, strong independence,\nthat even 1-entailment fails to satisfy. If we are given one exception\nto a rule involving a given antecedent, then we are unable to use any\nconditional with the same antecedent to derive any conclusion\nwhatsoever. Suppose, for example, that we know that birds fly \\((B\n\\Rightarrow F)\\), Tweety is a bird that doesn’t fly \\((B \\amp\n\\neg F)\\), and birds lay eggs \\((B \\Rightarrow E)\\). Even under\n1-entailment, the conclusion that Tweety lays eggs \\((E)\\) fails to\nfollow. This failure to satisfy Strong Independence is also known\nas the Drowning Problem (since all conditionals with the same\nantecedent are “drowned” by a single exception). \nA consensus is growing that the Drowning Problem should not be\n“solved” (see Pelletier and Elio 1994; Wobcke 1995, 85;\nBonevac, 2003, 461–462). Consider the following variant on the\nproblem: birds fly, Tweety is a bird that doesn’t fly, and birds\nhave strong forelimb muscles. Here it seems we should refrain from\nconcluding that Tweety has strong forelimb muscles, since there is\nreason to doubt that the strength of wing muscles is causally (and\nhence, probabilistically) independent of capacity for flight. Once we\nknow that Tweety is an exceptional bird, we should refrain from\napplying other conditionals with Tweety is a bird as their\nantecedents, unless we know that these conditionals are independent of\nflight, that is, unless we know that the conditional with the stronger\nantecedent, Tweety is a non-flying bird, is also true. \nNonetheless, several proposals have been made for securing strong\nindependence and solving the Drowning Problem. Geffner and Pearl\n(Geffner and Pearl 1992) proposed a system of conditional\nentailment, a variant of circumscription, in which the preference\nrelation on models is defined in terms of the sets of defaults that\nare satisfied. This enables Geffner and Pearl to satisfy both the\nSpecificity principle and Strong Independence. Another proposal is the\nmaximum entropy approach (Pearl 1988, 490–496; Goldszmidt,\nMorris and Pearl, 1993; Pearl 1990). A theory \\(T\\), consisting\nof defaults \\(\\Delta\\) and facts \\(F\\), entails \\(p\\) just in\ncase the probability of \\(p\\), conditional on \\(F\\),\napproaches 1 as the probabilities associated with \\(\\Delta\\) approach 1,\nusing the\n entropy-maximizing[6]\n probability function that respects the defaults in \\(\\Delta\\). The\nmaximum-entropy approaches satisfies both Specificity and Strong\nIndependence. \nEvery attempt to solve the drowning problem (including conditional\nentailment and the maximum-entropy approach) comes at the cost of\nsacrificing cumulativity. Securing strong independence makes the\nsystems very sensitive to the exact form in which the default\ninformation is stored. Consider, for example the following case:\nSwedes are (normally) fair, Swedes are (normally) tall, Jon is a short\nSwede. Conditional entailment and maximum-entropy entailment would\npermit the conclusion that Jon is fair in this case. However, if we\nreplace the first two default conditionals by the single default,\nSwedes are normally both tall and fair, then the conclusion\nno longer follows, despite the fact that the new conditional is\nlogically equivalent to the conjunction of the two original\nconditionals. \nApplying the logic of extreme probabilities to real-world defeasible\nreasoning generates an obvious problem, however. We know perfectly\nwell that, in the case of the default rules we actually use, the\nconditional probability of the conclusion on the premises is nowhere\nnear 1. For example, the probability that an arbitrary bird can fly is\ncertainly not infinitely close to 1. This problem resembles that of\nusing idealizations in science, such as frictionless planes and ideal\ngases. It seems reasonable to think that, in deploying the machinery\nof defeasible logic, we indulge in the degree of make-believe\nnecessary to make the formal models applicable. Nonetheless, this is\nclearly a problem warranting further attention. \nWith relatively few exceptions, the logical approaches to defeasible\nreasoning developed so far put severe restrictions on the logical form\nof propositions included in a set of premises. In particular, they\nrequire the default conditional operator, \\(\\Rightarrow\\), to have\nwide scope in every formula in which it appears. Default conditionals\nare not allowed to be nested within other default conditionals, or\nwithin the scope of the usual Boolean operators of propositional logic\n(negation, conjunction, disjunction, material conditional). This is a\nvery severe restriction and one that is quite difficult to defend. For\nexample, in representing undercutting defeaters, it would be\nvery natural to use a negated default conditional of the form\n\\(\\neg((p \\amp q) \\Rightarrow r)\\) to signify that \\(q\\) defeats \\(p\\)\nas a prima facie reason for \\(r\\). In addition, it seems plausible\nthat one might come gain\ndisjunctive default information: for example, that either\ncustomers are gullible or salesman are wily. \nAsher and Pelletier (Asher and Pelletier 1997) have argued that, when\ntranslating generic sentences in natural language, it is essential\nthat we be allowed to nest default conditionals. For example, consider\nthe following English sentences: \nClose friends are (normally) people who (normally) trust one\nanother. \nPeople who (normally) rise early (normally) go to bed early. \nIn the first case, a conditional is nested within the consequent of\nanother conditional: \n\\(\\forall x \\forall y (\\textit{Friend}(x,y) \\Rightarrow \\forall z\n(\\textit{Time}(z) \\Rightarrow \\textit{Trust}(x,y,z)))\\) \nIn the second case, we seem to have conditionals nested within both\nthe antecedent and the consequent of a third conditional, something\nlike: \n\n\\(\\forall x (\\textit{Person}(x) \\rightarrow\\)\n  \\((\\forall y(\\textit{Day}(y) \\Rightarrow\n\\textit{Rise-early}(x,y)) \\Rightarrow \\forall z (\\textit{Day}(z) \\Rightarrow\n\\textit{Bed-early}(x,z))))\\) \nThis nesting of conditionals can be made possible by borrowing and\nmodifying the semantics of the subjunctive or counterfactual\nconditional, developed by Robert Stalnaker and David K. Lewis (Lewis\n1973). For an axiomatization of Lewis’s conditional logic, see\nthe following supplementary document: \n David Lewis’s Conditional Logic\n  \nThe only modification that is essential is to drop the condition of\nCentering (both strong and weak), a condition that makes modus ponens\n(affirming the antecedent) logically valid. If the conditional \\(\\Rightarrow\\)\nis to represent a default conditional, we do not want modus ponens to\nbe valid: we do not want \\((p \\Rightarrow q)\\) and \\(p\\)\nto entail \\(q\\) classically (i.e., monotonically). If Centering\nis dropped, the resulting logic can be made to correspond exactly to\neither a preferential or a rational defeasible entailment relation.\nFor example, the condition of Rational Monotony is the exact\ncounterpart of the CV axiom of Lewis’s logic: \nCV: \n\\((p \\Rightarrow q) \\rightarrow [((p \\amp r) \\Rightarrow q) \\vee(p\n\\Rightarrow \\neg r )]\\)\n \nSomething like this was proposed first by James Delgrande (Delgrande\n1987), and the idea has been most thoroughly developed by Nicholas\nAsher and his collaborators (Asher and Morreau 1991; Asher 1995; Asher\nand Bonevac 1996; Asher and Mao 2001) under the name Commonsense\n Entailment.[7]\n Commonsense Entailment is a preferential (although not a rational)\nconsequence relation, and it automatically satisfies the Specificity\nprinciple. It permits the arbitrary nesting of default conditionals\nwithin other logical operators, and it can be used to represent\nundercutting defeaters, through the use of negated defaults (Asher and\nMao 2001). \nThe models of Commonsense Entailment differ significantly from those\nof preferential logic and the logic of extreme probabilities. Instead\nof having structures that contain sets of models of a\nstandard, default-free language, a model of the language of\nCommonsense Entailment includes a set of possible worlds,\ntogether with a function that assigns standard interpretation (a model\nof the default-free language) to each world. In addition, to each pair\nconsisting of a world \\(w\\) and a set of worlds (proposition) \\(A\\),\nthere is a function \\(*\\) that assigns a set of worlds \\({*}(w,A)\\) to\nthe pair. The set \\({*}(w,A)\\) is the set of most normal \\(A\\)-worlds,\nfrom the perspective of \\(w\\). A default conditional \\((p \\Rightarrow\nq)\\) is true in a world \\(w\\) (in such a model) just in case all of\nthe most normal \\(p\\) worlds (from \\(w\\)’s perspective) are\nworlds in which \\(q\\) is also true. Since we can assign\ntruth-conditions to each such conditional, we can define the truth of\nnested conditionals, whether the conditionals are nested within\nBoolean operators or within other conditionals. Moreover, we can\ndefine both a classical, monotonic consequence relation for this class\nof models and a defeasible, nonmonotonic relation (in fact, the\nnonmonotonic consequence relation can be defined in a variety of\nways). We can then distinguish between a default conditional’s\nfollowing with logical necessity from a default theory and\nits following defeasibly from that same theory.\nContraposition, for example — inferring \\((\\neg q \\Rightarrow\n\\neg p)\\) from \\((p \\Rightarrow q)\\) — is not logically valid\nfor default conditionals, but it might be a defeasibly correct\n inference.[8] \nThe one critical drawback to Commonsense Entailment, when compared to\nthe logic of extreme probabilities, is that it lacks a single, clear\nstandard of normativity. The truth-conditions of the default\nconditional and the definition of nonmonotonic consequence can be\nfine-tuned to match many of our intuitions, but in the end of the day,\nthe theory of Commonsense Entailment offers no simple answer to the\nquestion of what its conditional or its consequence relation are\nsupposed (ideally) to represent. \nLogics of extreme probability (beginning with the work of Ernest\nAdams) did not permit the nesting of default conditionals for this\nreason: the conditionals were supposed to represent something like\nsubjective conditional probabilities of the agent, to which the agent\nwas supposed to have perfect introspective access. Consequently, it\nmade no sense to nest this conditionals within disjunctions (as though\nthe agent couldn’t tell which disjunct represented his actual\nprobability assignment) or within other conditionals (since the\nsubjective probability of a subjective probability is always trivial\n— either exactly 1 or exactly 0). However, there is no reason\nwhy the logic of extreme probabilities couldn’t be given a\ndifferent interpretation, with \\((p \\Rightarrow q)\\)\nrepresenting something like the objective probability of\n\\(q\\), conditional on \\(p\\), is infinitely close to 1.\nIn this case, it makes perfect sense to nest such statements of\nobjective conditional probability within Boolean operators (either the\nprobability of \\(q\\) on \\(p\\) is close to 1, or the\nprobability of \\(r\\) on \\(s\\) is close to 1), or within\noperators of objective probability (the objective probability that the\nobjective probability of \\(p\\) is close to 1 is itself close to\n1). What is required in the latter case is a theory of\nhigher-order probabilities. \nFortunately, such a theory of higher-order probabilities is available\n(see Skyrms 1980; Gaifman 1988). The central principle of this theory\nis Miller’s principle. For a description of the models of the\nlogic of extreme, higher-order probability, see the following\nsupplementary document: \n Models of Higher-Order Probability\n  \nThe following proposition is logically valid in this logic,\nrepresenting the presence of a defeasible modus ponens rule: \n\\(((p \\amp(p \\Rightarrow q)) \\Rightarrow q)\\)\n \nThis system can be the basis for a family of rational nonmonotonic\nconsequence relations that include the Adams \\(\\varepsilon\\)-entailment\nsystem as a proper part (see Koons 2000, 298–319). \nIn an early paper (Israel 1980), David Israel raised a number of\nobjections to the very idea of nonmonotonic logic. First, he\npointed out that the nonmonotonic consequences of a finite theory are\ntypically not semi-decidable (recursively enumerable). This remains\ntrue of most current systems, but it is also true of second-order\nlogic, infinitary logic, and a number of other systems that are now\naccepted as logical in nature. \nSecondly, and more to the point, Israel argued that the concept of\nnonmonotonic logic evinces a confusion between the rules of\nlogic and rules of inference. In other words, Israel accused defenders\nof nonmonotonic logic of confusing a theory of defeasible inference (a\nbranch of epistemology) with a theory of genuine consequence relations\n(a branch of logic). Inference is nonmonotonic, but logic (according\nto Israel) is essentially monotonic. \nThe best response to Israel is to point out that, like deductive\nlogic, a theory of nonmonotonic or defeasible consequence has a number\nof applications besides that of guiding actual inference. Defeasible\nlogic can be used as part of a theory of scientific explanation, and\nit can be used in hypothetical reasoning, as in planning. It can be\nused to interpret implicit features of stories, even fantastic ones,\nso long as it is clear which actual default rules to suspend. Thus,\ndefeasible logic extends far beyond the boundaries of the theory of\nepistemic justification. Moreover, as we have seen, nonmonotonic\nconsequence relations (especially the preferential ones) share a\nnumber of very significant formal properties with classical\nconsequence, warranting the inclusion of them all in a larger family\nof logics. From this perspective, classical deductive logic is simply\na special case: the study of indefeasible consequence. \nIn a recent paper, Charles Morgan (Morgan 2000) has argued that\nnonmonotonic logic is impossible. Morgan offers a series of\nimpossibility proofs. All of Morgan’s proofs turn on the fact\nthat nonmonotonic logics cannot support a generalized deduction\ntheorem, i.e., something of the following form: \n\\(\\Gamma \\cup \\{p\\} \\dproves q\\) iff \\(\\Gamma \\dproves\n(p \\Rightarrow q)\\)\n \nMorgan is certainly right about this. \nHowever, there are good grounds for thinking that a system of\nnonmonotonic logic should fail to include a generalized\ndeduction theorem. The very nature of defeasible consequence ensures\nthat it must be so. Consider, for example, the left-to-right\ndirection: suppose that \\(\\Gamma \\cup \\{p\\} \\dproves q\\). Should it\nfollow that \\(\\Gamma \\dproves (p \\Rightarrow q)\\)? Not at all. It may\nbe that, normally, if \\(p\\) then \\(\\neg q\\), but \\(\\Gamma\\) may\ncontain defaults and information that defeat and override this\ninference. For instance, it might contain the fact \\(r\\) and the\ndefault \\(((r \\amp p) \\Rightarrow q)\\). Similarly, consider the\nright-to-left direction: suppose that \\(\\Gamma \\dproves (p \\Rightarrow\nq)\\). Should it follow that \\(\\Gamma \\cup \\{p\\} \\dproves q\\)? Again,\nclearly not. \\(\\Gamma\\) might contain both \\(r\\) and a default \\(((p\n\\amp r) \\Rightarrow \\neg q)\\), in which case \\(\\Gamma \\cup \\{p\\}\n\\dproves \\neg q\\). \nIt would be reasonable, however, to demand that a system of\nnonmonotonic logic satisfy the following special deduction\ntheorem: \n\\(\\{p\\} \\dproves q\\) iff \\(\\varnothing \\dproves (p \\Rightarrow q)\\)\n \nThis is certainly possible. The special deduction theorem holds\ntrivially; if we define\\(\\{p\\} \\dproves q\\) as \\(\\varnothing \\vDash(p\n\\Rightarrow q)\\); that is, \\(\\{p\\}\\) defeasibly entails \\(q\\) if and\nonly if (by definition) \\((p \\Rightarrow q)\\) is a theorem of the\nclassical conditional\n logic.[9] \nHanks and McDermott, computer scientists at Yale, demonstrated that\nthe existing systems of nonmonotonic logic were unable to give the\nright solution to a simple problem about predicting the course of\nevents (Hanks and McDermott 1987). The problem became known as the\nYale shooting problem. Hanks and McDermott assume that some sort\nof law of inertia can be assumed: that normally properties of\nthings do not change. In the Yale shooting problem, there are two\nrelevant properties: being loaded (a property of a gun) and being\nalive (a property of the intended victim of the shooting). Let’s\nassume that in the initial situation, \\(s_0\\), the gun\nis loaded and the victim is alive,\nLoaded\\((s_0)\\) and\nAlive\\((s_0)\\), and that two actions are\nperformed in sequence: Wait and Shoot. Let’s\ncall the situation that results from a moment of waiting\n\\(s_1\\), and the situation that follows both waiting\nand then shooting \\(s_2\\). There are then three\ninstances of the law of inertia that are relevant: \nWe need to make one final assumption: that shooting the victim with a\nloaded gun results in death (not being alive): \nIntuitively, we should be able to derive the defeasible conclusion\nthat the victim is still alive after waiting, but dead after waiting\nand shooting: Alive\\((s_1) \\amp \\neg\\)Alive\\((s_2)\\). However, none of the\nnonmonotonic logics described above give us this result, since each of\nthe three instances of the law of inertia can be violated: by the\nvictim’s inexplicably dying while we are waiting, by the\ngun’s miraculously becoming unloaded while we are waiting, or by\nthe victim’s dying as a result of the shooting. Nothing\nintroduced into nonmonotonic logic up to this point provides us with a\nbasis for preferring the second exception to the law of inertia to the\nfirst or third. What’s missing is a recognition of the\nimportance of causal structure to defeasible\n consequence.[10] \nThere are several even simpler examples that illustrate the need to\ninclude explicitly causal information in the input to defeasible\nreasoning. Consider, for instance, this problem of Judea Pearl’s\n(Pearl 1988): if the sprinkler is on, then normally the sidewalk is\nwet, and, if the sidewalk is wet, then normally it is raining.\nHowever, we should not infer that it is raining from the fact that the\nsprinkler is on. (See Lifschitz 1990 and Lin and Reiter 1994 for\nadditional examples of this kind.) Similarly, if we also know that if\nthe sidewalk is wet, then it is slippery, we should be able to infer\nthat the sidewalk is slippery if the sprinkler is on and it is\nnot raining. \nHans Reichenbach, in his analysis of the interaction of causality and\nprobability (Reichenbach 1956), observed that the immediate causes of\nan event probabilistically screen off from that event any\nother event that is not causally posterior to it. This means that,\ngiven the immediate causal antecedents of an event, the occurrence of\nthat event is rendered probabilistically independent of any\ninformation about non-posterior events. When this insight is applied\nto the nonmonotonic logic of extreme probabilities, we can use causal\ninformation to identify which defaults function independently of\nothers: that is, we can decide when the fact that one default\nconditional has an exception is irrelevant to the question of whether\na second conditional is also violated (see Koons 2000, 320–323).\nIn effect, we have a selective version of Independence of Defaults\nthat is grounded in causal information, enabling us to dissolve the\nDrowning Problem. \nFor example, in the case of Pearl’s sprinkler, since rain is\ncausally prior to the sidewalk’s being wet, the causal structure\nof the situation does not ensure that the rain is probabilistically\nindependent of whether the sprinkler is on, given the fact that the\nsidewalk is wet. That is, we have no grounds for thinking that the\nprobability of rain, conditional on the sidewalk’s being wet, is\nidentical to the probability of rain, conditional on the\nsidewalk’s being wet and the sprinkler’s being on\n(presumably, the former is higher than the latter). This failure of\nindependence prevents us from using the (Wet \\(\\Rightarrow\\)\nRain) default, in the presence of the additional fact that\nthe sprinkler is on.  \nIn the case of the Yale shooting problem, the state of the gun’s\nbeing loaded in the aftermath of waiting,\nLoaded\\((s_1)\\), has at its only causal\nantecedent the fact that the gun is loaded in \\(s_0\\).\nThe fact of Loaded\\((s_0)\\) screens off the\nfact that the victim is alive in \\(s_0\\) from the\nconclusion Loaded\\((s_1)\\). Similarly, the\nfact that the victim is alive in \\(s_0\\) screens off\nthe fact that the gun is loaded in \\(s_0\\) from the\nconclusion that the victim is still alive in \\(s_1\\).\nIn contrast, the fact that the victim is alive at\n\\(s_1\\) does not screen off the fact that the\ngun is loaded at \\(s_1\\) from the conclusion that the\nvictim is still alive at \\(s_2\\). Thus, we can assign\nhigher priority to the law of inertia with respect to both\nLoad and Alive at \\(s_0\\), and we can\nconclude that the victim is alive and the gun is loaded at\n\\(s_1\\). The causal law for shooting then gives us the\ndesired conclusion, namely, that the victim is dead at\n\\(s_2\\). \nOur knowledge of causal relatedness is itself very partial. In\nparticular, it is difficult for us to verify conclusively that any two\nrandomly selected facts are or are not causally related. It seems that\nin practice we apply something like Occam’s razor, assuming that\ntwo randomly selected facts are not causally related unless we have\npositive reason for thinking otherwise. This invites the use of\nsomething like circumscription, minimizing the extension of the\npredicate causes. (This is in fact exactly what Fangzhen Lin\ndoes in his 1995 papers [Lin 1995].) \nOnce we have a set of tentative conclusions about the causal structure\nof the world, we can use Reichenbach’s insight to enable us to\nlocalize the problem of reasoning by default in the presence of known\nabnormality. If a known abnormality is screened off from a\ndefault’s rule’s consequent by constituent of its\nantecedent, then the rule may legitimately be deployed.  \nSince circumscription is itself a nonmonotonic logical system, there\nare at least two independent sources of nonmonotonicity, or\ndefeasibility: the minimization or circumscription of causal\nrelevance, and the application of defeasible causal laws and laws of\ninertia. \nA number of researchers in artificial intelligence have recently\ndeployed one version of circumscription (namely, the stable\nmodels of Gelfond and Lifschitz [1988]) to problems of causal\nreasoning, building on an idea of Norman McCain and Hudson\nTurner’s [McCain and Turner 1997]. McCain and Turner employ\ncausal rules that specify when an atomic fact is adequately caused and\nwhen it is exogenous and not in need of causal explanation. They then\nassume a principle of universal causation, permitting only\nthose models that provide adequate causal explanations for all\nnon-exempt atomic facts, while in effect circumscribing the extension\nof the causally explained. This approach has been extended and applied\nby Giunchiglia, Lee, Lifschitz, McCain and Turner [2004], Ferraris\n[2007], and Ferraris, Lee, Lierler, Lifschitz and Yang [2012].","contact.mail":"koons@mail.utexas.edu","contact.domain":"mail.utexas.edu"}]
