[{"date.published":"2017-01-12","date.changed":"2021-02-02","url":"https://plato.stanford.edu/entries/games-abstraction/","author1":"Felice Cardone","author1.info":"http://www.di.unito.it/~felice/","entry":"games-abstraction","body.text":"\n\n\nComputer programs are particular kinds of texts. It is therefore\nnatural to ask what is the meaning of a program or, more generally,\nhow can we set up a formal semantical account of a programming\nlanguage. \n\n\nThere are many possible answers to such questions, each motivated by\nsome particular aspect of programs. So, for instance, the fact that\nprograms are to be executed on some kind of computing machine gives\nrise to operational semantics, whereas the similarities of programming\nlanguages with the formal languages of mathematical logic have\nmotivated the denotational approach that interprets programs and their\nconstituents by means of set-theoretical models. \n\n\nEach of these accounts induces its own synonymy relation on the\nphrases of the programming language: in a nutshell, the full\nabstraction property states that the denotational and operational\napproaches define the same relation. This is a benchmark property for\na semantical account of a programming language, and its failure for an\nintuitive denotational account of a simple language based on\nlambda-calculus has led eventually to refinements of the technical\ntools of denotational semantics culminating in game semantics, partly\ninspired by the dialogue games originally used in the semantics of\nintuitionistic logic by Lorenzen and his school, and later extended by\nBlass and others to the interpretation of Girard’s linear logic.\nThis bridge between constructive logic and programming has also\nsuggested stronger forms of relation between semantics and\nproof-theory, of which the notion of full completeness is perhaps the\nmost remarkable instance. \n\nThe notion of full abstraction arises from the Scott-Strachey approach\nto the semantical analysis of programming languages (Scott &\nStrachey 1971; Strachey 1966, 1967), also known as\ndenotational semantics. One fundamental aim of a denotational\nsemantics of a programming language \\({L}\\) is to give a\ncompositional interpretation \\({\\mathcal{M}}: {L}\\to D\\) of\nthe program phrases of \\({L}\\) as elements of abstract\nmathematical structures (domains) \\(D\\). \nWe may choose another way of giving meaning to programs, based on\ntheir execution. This operational interpretation is only\ndefined on the set Prog of programs of\n\\({L}\\), and involves the definition of a suitable set of program\nvalues, which are the observables of \\({L}\\). If the\nexecution of program \\(e\\) terminates with value \\(v\\), a situation\nexpressed by the notation \\(e \\opDownarrow v\\), then \\(v\\) is the\noperational meaning of \\(e\\). This defines the operational\ninterpretation of programs as a partial function \\({\\mathcal{O}}\\)\nfrom programs to values, where \\({\\mathcal{O}}(e) = v\\) when \\(e\n\\opDownarrow v\\). \nBoth interpretations induce natural equivalence relations on program\nphrases. In one of its formulations, full abstraction states the\ncoincidence of the denotational equivalence on a language with one\ninduced by the operational semantics. Full abstraction has been first\ndefined in a paper by Robin Milner (1975), which also exposes the\nessential conceptual ingredients of denotational semantics:\ncompositionality, and the relations between observational and\ndenotational equivalence of programs. For this reason, full\nabstraction can be taken as a vantage point into the vast landscape of\nprogramming language semantics, and is therefore quite relevant to the\ncore problems of the philosophy of programming languages (White 2004)\nand of computer science (Turner 2016). \nCompositionality (Szabó 2013) is a desirable feature of a\nsemantical analysis of a programming language, because it allows one\nto calculate the meaning of a program as a function of the meanings of\nits constituents. Actually, in Milner’s account (see especially\n1975: sec. 1, 4), compositionality applies even more generally to\ncomputing agents assembled from smaller ones by means of\nappropriate composition operations. These agents may include, beside\nprograms, hardware systems like a computer composed of a memory,\ncomposed in turn of two memory registers, and a processing unit, where\nall components are computing agents. This allows one to include in one\nframework systems composed of hardware, of software and even of both.\nNow, the syntactic rules that define inductively the various\ncategories of phrases of a programming language allow us to regard\n\\({L}\\) as an algebra of program phrases, whose signature is\ndetermined by these rules. One account of compositionality that is\nespecially suitable to the present setting (Szabó 2013: sec. 2)\nidentifies a compositional interpretation of programs with a\nhomomorphism from this algebra to the domain of denotations\nassociating with every operation of the algebra of programs a\ncorresponding semantical operation on denotations. \nAs an example, consider a simple imperative language whose programs\n\\(\\mathtt{c}\\) denote state transformations\n\\({\\mathcal{M}}(\\mathtt{c}) : \\Sigma \\to \\Sigma\\). Among the\noperations on programs of this language there is sequential\ncomposition, building a program \\(\\mathtt{c}_1 ; \\mathtt{c}_2\\)\nfrom programs \\(\\mathtt{c}_1\\) and \\(\\mathtt{c}_2\\). The intended\noperational meaning of this program is that, if \\(\\mathtt{c}_1 ;\n\\mathtt{c}_2\\) is executed starting from a state \\(\\sigma \\in\n\\Sigma\\), we first execute \\(\\mathtt{c}_1\\) starting form state\n\\(\\sigma\\). If the execution terminates we obtain a state \\(\\sigma'\\),\nfrom which we start the execution of \\(\\mathtt{c}_2\\) reaching, if the\nexecution terminates, a state \\(\\sigma''\\). The latter state is the\nstate reached by the execution of \\(\\mathtt{c}_1 ; \\mathtt{c}_2\\) from\nstate \\(\\sigma\\). From a denotational point of view, we have the\noperation of composition on functions \\(\\Sigma \\to \\Sigma\\), and the\ncompositional interpretation of our program is given by the following\nidentity, to be read as a clause of a definition of \\({\\mathcal{M}}\\)\nby induction on the structure of programs: \n\n\\[{\\mathcal{M}}(\\mathtt{c}_1 ; \\mathtt{c}_2) = {\\mathcal{M}}(\\mathtt{c}_2) \\circ {\\mathcal{M}}(\\mathtt{c}_1)\\]\n\n or, more\nexplicitly, for any state \\(\\sigma\\): \n\n\\[{\\mathcal{M}}(\\mathtt{c}_1 ; \\mathtt{c}_2) (\\sigma) = {\\mathcal{M}}(\\mathtt{c}_2) ({\\mathcal{M}}(\\mathtt{c}_1) (\\sigma)).\\]\n\n As most programming\nlanguages have several categories of phrases (for instance\nexpressions, declarations, instructions) the algebras of programs will\ngenerally be multi-sorted, with one sort for each category of phrase.\nDenotational semantics pursues systematically the idea of associating\ncompositionally to each program phrase a denotation of the matching\nsort (see Stoy 1977 for an early account). \nThe existence of an interpretation of a programming language \\({L}\\)\ninduces in a standard way an equivalence of program\nphrases: \nDefinition 1.1 (Denotational equivalence). Given any\ntwo program phrases \\(e,e'\\), they are denotationally\nequivalent, written \\(e \\simeq_{\\mathcal{M}}e'\\), when\n\\({\\mathcal{M}}(e) = {\\mathcal{M}}(e')\\). \nIf \\({\\mathcal{M}}\\) is compositional, then \\({\\simeq_{\\mathcal{M}}}\\)\nis a congruence over the algebra of programs, whose derived\noperations, those obtained by composition of operations of the\nsignature, are called contexts. A context \\(C\\blbr\\)\nrepresents a program phrase with a “hole” that can be\nfilled by program phrases \\(e\\) of appropriate type to yield the\nprogram phrase \\(C[e]\\). By means of contexts we can characterize\neasily the compositionality of a semantic mapping: \nProposition 1.1. If \\({\\mathcal{M}}\\) is\ncompositional, then for all phrases \\(e,e'\\) and all contexts\n\\(C\\blbr\\): \n\n\\[\\tag{1}\\label{compositionality}{e \\simeq_{\\mathcal{M}} e'} \\Rightarrow {C[e] \\simeq_{\\mathcal{M}} C[e']}.\\] \nThis formulation highlights another valuable aspect of\ncompositionality, namely the referentially transparency of\nall contexts, equivalently their extensionality:\ndenotationally equivalent phrases can be substituted in any context\nleaving unchanged the denotation of the resulting phrase. The\nimplication (\\(\\ref{compositionality}\\)) states, in particular, that\n\\({\\simeq_{\\mathcal{M}}}\\) is a congruence. In order to compare\ndenotational and operational congruence, therefore, we must carve a\ncongruence out of the naive operational equivalence defined by setting\n\\(e \\sim e'\\) if and only if \\({\\mathcal{O}}(e) = {\\mathcal{O}}(e')\\).\nThis can be done by exploiting program contexts \\(C\\blbr\\),\nrepresenting a program with a “hole” that can be filled by\nprogram phrases \\(e\\) of suitable type to yield a complete program\n\\(C[e]\\). \nDefinition 1.2 (Observational equivalence) Given any\ntwo program phrases \\(e,e'\\), they are observational\nequivalent, written \\(e \\simeq_{\\mathcal{O}}e'\\), when, for all\nprogram contexts \\(C\\blbr\\) and all program values \\(v\\): \n\n\\[C[e] \\opDownarrow v\\  \\text{ if and only if }\\  C[e'] \\opDownarrow v.\\]\n\n \nObservational equivalence is then a congruence over the algebra of\nprogram phrases, and in fact it is the largest congruence contained in\n\\(\\sim\\). From the general point of view of the account of Milner\n(1975), that we are following closely, the context of a computing\nagent represents one of its possible environments. If we adopt the\nprinciple that “the overt behavior constitutes the\nwhole meaning of a computing agent” (Milner 1975: 160),\nthen the contexts represents intuitively the observations that we can\nmake on the behavior of the computing agent. In the case of programs,\nthe observables are the values, so observational equivalence\nidentifies phrases that cannot be distinguished by means of\nobservations whose outcomes are distinct values. One consequence of\nMilner’s methodological principle is that a computing agent\nbecomes a  \ntransducer, whose input sequence consists of enquiries by, or\nresponses from, its environment, and whose output sequence consists of\nenquiries of, or responses to, its environment. (Milner 1975: 160)\n \nA behavior of a computing agent takes then the form of a\ndialogue between the agent and its environment, a metaphor\nthat will be at the heart of the game theoretic approaches to\nsemantics to be discussed in\n Section 3.\n This behavioral stance, which has its roots in the work of engineers\non finite state devices has also been extended by Milner to a\nmethodology of modeling concurrent systems, with the aim  \nto describe a concurrent system fully enough to determine exactly what\nbehaviour will be seen or experienced by an external observer. Thus\nthe approach is thoroughly extensional; two systems are\nindistinguishable if we cannot tell them apart without pulling them\napart. (Milner 1980: 2)  \nIn addition, the roles of system and observer are symmetric, to such\nan extent that  \nwe would like to represent the observer as a machine, then to\nrepresent the composite observer/machine as a machine, then to\nunderstand how this machine behaves for a new observer. (Milner 1980:\n19) \nWhile observational equivalence is blind to the inner details of a\ncomputing agent but only observes the possible interactions\nwith its environment in which it takes part, denotational equivalence\ntakes as given the internal structure of a computing agent and, in a\ncompositional way, synthesizes its description from those of its\ninternal parts. The notion of full abstraction is precisely intended\nto capture the coincidence of these dual perspectives: \nDefinition 1.3 (Full abstraction). A denotational\nsemantics \\({\\mathcal{M}}\\) is fully abstract with respect to\nan operational semantics \\({\\mathcal{O}}\\) if the induced equivalences\n\\({\\simeq_{\\mathcal{M}}}\\) and \\({\\simeq_{\\mathcal{O}}}\\)\ncoincide. \nAs a tool for investigating program properties, full abstraction can\nbe seen as a completeness property of denotational semantics:\nevery equivalence of programs that can be proved operationally, can\nalso be proved by denotational means. Equivalently, a denotational\nproof that two terms are not equivalent will be enough to show that\nthey are not interchangeable in every program context. \nFull abstraction also functions as a criterion for assessing a\ntranslation \\(\\vartheta\\) from a language \\({L}_1\\) into a (not\nnecessarily different) language \\({L}_2\\), provided the two languages\nhave the same sets of observables, say Obs (Riecke 1993).\nThen \\(\\vartheta\\) is fully abstract if observational\nequivalence (defined with respect to Obs) of \\(e,e' \\in\n{L}_1\\) is equivalent to observational equivalence of\n\\(\\vartheta(e),\\vartheta(e')\\) in \\({L}_2\\). The existence of fully\nabstract translation between languages can be used to compare their\nexpressive power, following a suggestion of (Mitchell 1993; Riecke\n1993): \\({L}_1\\) is no more expressive than \\({L}_2\\) if there is a\nfully abstract translation of \\({L}_1\\) into \\({L}_2\\). \nBefore going on in this general introduction to full abstraction and\nrelated notions in the area of programming languages semantics, in\norder to show the broad relevance of these notions, it is interesting\nto observe that there is a very general setting in which it is\npossible to study the full abstraction property, suggested by recent\ninvestigations on compositionality in natural and artificial languages\nby Hodges (2001) and others. In this setting, full abstraction is\nconnected to the problem of finding a compositional extension of a\nsemantic interpretation of a subset \\(X\\) of a language \\(Y\\) to an\ninterpretation of the whole language, via Frege’s Context\nPrinciple (see Janssen 2001 on this), stating that the meaning of\nan expression in \\(Y\\) is the contribution it makes to the meaning of\nthe expressions of \\(X\\) that contain it. In the original formulation\nby Frege \\(X\\) was the set of sentences and \\(Y\\) the set of all\nexpressions, while in programming theory \\(X\\) is the set of programs,\n\\(Y\\) the set of all program phrases. \nA weakening of the definition of full abstraction represents an\nessential adequacy requirement for a denotational interpretation of a\nlanguage: \nDefinition 1.4 (Computational adequacy). A\ndenotational semantics \\({\\mathcal{M}}\\) is computationally\nadequate with respect to an operational semantics\n\\({\\mathcal{O}}\\) if, for all programs \\(e\\) and all values \\(v\\)\n\n\\[{\\mathcal{O}}(e) = v \\ \\text{ if and only if } \\ {\\mathcal{M}}(e) = {\\mathcal{M}}(v).\\]\n\n  \nAn equivalent formulation of computational adequacy allows to\nhighlight its relation to full abstraction: \nProposition 1.2. Assume that \\({\\mathcal{M}}\\) is a\ncompositional denotational interpretation such that \\({\\mathcal{O}}(e)\n= v\\) implies \\({\\mathcal{M}}(e) = {\\mathcal{M}}(v)\\). The following\ntwo statements are equivalent: \nWhile the definition of the full abstraction property is\nstraightforward, fully abstract models for very natural examples of\nprogramming languages have proved elusive, giving rise to a full\nabstraction problem. In our discussion of full abstraction we\nshall mainly concentrate on the full abstraction problem for the\nlanguage PCF (Programming language for Computable Functions, Plotkin\n1977), a simply typed \\(\\lambda\\)-calculus with arithmetic primitives\nand a fixed-point combinator at all types proposed in Scott 1969b.\nThis language is important because it includes most of the programming\nfeatures semantic analysis has to cope with: higher-order functions,\ntypes and recursion, with reduction rules that provide an abstract\nsetting for experimenting with several evaluation strategies.\nFurthermore, PCF is also a model for other extensions of simply typed\n\\(\\lambda\\)-calculus used for experimenting with programming features,\nlike the Idealized Algol of Reynolds (1981). The efforts towards a\nsolution of the full abstraction problem for PCF contributed, as a\nside effect, to the systematic development of a set of mathematical\ntechniques for semantical analysis whose usefulness goes beyond their\noriginal applications. We shall describe some of them in\n Section 2,\n devoted to the semantic analysis of PCF based on partially ordered\nstructures, the domains introduced by Dana Scott (1970), that\nwe examine in\n Section 2.3.\n Technical developments in the theory of domains and also in the new\nresearch area focussed on Girard’s linear logic (Girard\n1987) have led to game semantics (Abramsky, Jagadeesan, &\nMalacaria 2000; Hyland & Ong 2000), which is now regarded as a\nviable alternative to standard denotational semantics based on\ndomains. It is to this approach that we shall dedicate\n Section 3\n trying to provide enough details to orient the reader in an extensive\nand still growing literature documenting the applications of games to\nthe interpretation of a wide spectrum of programming language\nfeatures. \nThe full abstraction problem has proved especially hard for a version\nof simply typed \\(\\lambda\\)-calculus with arithmetic primitives called\nPCF (Programming with Computable Functions) (Plotkin 1977), a toy\nprogramming language based on the Logic for Computable Functions of\nScott (1969) and Milner (1973). In this section we introduce (a\nversion of) the language with its operational and denotational\nsemantics, and outline how the full abstraction problem arises for\nthis language. The problem has been one of the major concerns of the\ntheoretical investigation of programming languages for about two\ndecades, from its original formulation in the landmark papers (Milner\n1977; Plotkin 1977) to the first solutions proposed in 1993 (Abramsky\net al. 2000; Hyland & Ong 2000) using game semantics, for which\nsee\n Section 3. \nPCF is a language based on simply typed \\(\\lambda\\)-calculus extended\nwith arithmetic and boolean primitives, and its type system is defined\naccordingly: \nDefinition 2.1 (PCF types). The set Types\nof types of PCF is defined inductively\nas follows \nParentheses will be omitted whenever possible, with the convention\nthat they associate to the right, so that a type \\(\\sigma_1 \\to \\cdots\n\\sigma_n \\to \\tau\\) is equivalent to \\((\\sigma_1 \\to (\\sigma_2 \\to\n(\\cdots (\\sigma_n \\to \\tau)\\cdots)))\\) \nPCF terms are the terms of simply typed \\(\\lambda\\)-calculus extended\nwith the following arithmetic constants, of the indicated type: \nTerms are built inductively according to rules that allow to infer\njudgements of the form \\(B \\vdash e : \\sigma\\), stating that\nterm \\(e\\) is of type \\(\\sigma\\) under the assumption that the\nvariables occurring free in \\(e\\) are given unique types in a\nbasis \\(B\\) of the form \n\n\\[{\\{ x_1:\\sigma_1,\\ldots,x_k:\\sigma_k \\}}.\\]\n\n The rule for building\nPCF-terms are therefore inference rules for such judgements. In\nparticular there are rules for typed constants, for example in any\nbasis \\(B\\) there is a judgement \\(B \\vdash \\texttt{zero?} :\n\\texttt{num}\\to \\texttt{bool}\\), and we have rules for typed\n\\(\\lambda\\)-abstractions \n\n\\[\\frac{B,x:\\sigma \\vdash e:\\tau}{B \\vdash {\\lambda x:\\sigma{\\, . \\,}e}:\\sigma \\to \\tau}\\]\n\n and applications \n\n\\[\\frac{B \\vdash e_1 : \\sigma \\to \\tau \\qquad B \\vdash e_2 : \\sigma}{B \\vdash e_1 e_2 : \\tau}\\]\n\n and\na rule for the fixed-point operator: \n\n\\[\\frac{B \\vdash e:\\sigma \\to \\sigma} {B \\vdash {\\mathtt{Y}(e)}:\\sigma}.\\]\n\n  \nA PCF program is a closed term of ground type. We specify how\nprograms are to be executed by defining an evaluation relation \\(e\n\\opDownarrow v\\) between closed terms \\(e\\) and values \\(v\\),\nwhere the values are the constants and abstractions of the form\n\\({\\lambda x:\\sigma{\\, . \\,}e}\\). In particular, values of ground type\nbool are \\(\\texttt{tt},\\texttt{ff}\\),\nand values of the ground type num are\n\\({0}\\) and all terms of the form \n\n\\[\\mathtt{n} = \\underbrace{\\texttt{succ}(\\ldots \\texttt{succ}}_{n}({0}) \\ldots ) .\\]\n\n Evaluation is defined\nby cases according to the structure of terms, by means of inference\nrules for judgements of the form \\(e \\opDownarrow v\\). These rules\nstate how the result of the evaluation of a term depends on the result\nof the evaluation of other terms, the only axioms having the form \\(v\n\\opDownarrow v\\) for every value \\(v\\). For example there is a rule\n\n\\[\\frac{e \\opDownarrow v}{{\\texttt{succ }e} \\opDownarrow  {\\texttt{succ }v}}\\]\n\n that states that, if the result of the evaluation of\n\\(e\\) is \\(v\\), then the result of the evaluation of \\({\\texttt{succ\n}e}\\) is \\({\\texttt{succ } v}\\). Similarly we can describe the\nevaluation of the other constants. The evaluation of a term of the\nform \\(e_1\\ e_2\\) proceeds as follows: first \\(e_1\\) is evaluated; if\nthe evaluation terminates with value \\(v'\\), then the evaluation of\n\\(e_1\\ e_2\\) proceeds with the evaluation of \\(v'\\ e_2\\); if this\nterminates with value \\(v\\), this is the value of \\(e_1\\ e_2\\),\nformally \n\n\\[\\frac{e_1 \\opDownarrow v' \\qquad v'\\ e_2 \\opDownarrow v}{e_1\\ e_2 \\opDownarrow v}\\]\n\n For a value of the form \\({\\lambda x:\\sigma{\\, .\n\\,}e_1}\\), its application to a term \\(e_2\\) has the value (if any)\nobtained by evaluating the term \\(e_1[e_2/x]\\) resulting by\nsubstituting \\(e_2\\) to all free occurrences of \\(x\\) in \\(e_1\\):\n\n\\[\\frac{e_1[e_2/x] \\opDownarrow v}{({\\lambda x:\\sigma{\\, . \\,}e_1}) e_2 \\opDownarrow v}.\\]\n\n These implement a call-by-name evaluation\nstrategy: in an application, the term in function position must be\nevaluated completely before the term in argument position, which is\nthen passed as actual parameter. The fixed point combinator is\nessential to the encoding of recursive definitions. Its evaluation is\ndescribed by the rule \n\n\\[\\frac{e({\\mathtt{Y}(e)}) \\opDownarrow v}{{\\mathtt{Y}(e)} \\opDownarrow v}\\]\n\n which is the only rule whose\npremiss involves the evaluation of a larger term than the one to be\nevaluated: this is why the definition of the evaluation relation\ncannot be reduced to structural induction. \nWe shall be especially interested in situations when the evaluation of\na term \\(e\\) does not have a value; in these case we say that \\(e\\)\ndiverges, and write \\(e \\opUparrow\\). It is in the presence\nof divergent terms that the causal structure of the evaluation process\nis exposed. The initial example is in fact a term that diverges in a\nvery strong sense: \nDefinition 2.2 (Undefined). For any ground type\n\\(\\gamma\\), define \\(\\Omega:\\gamma\\) as \n\n\\[{\\mathtt{Y}({\\lambda x:\\gamma{\\, . \\,}x})}\\]\n\n  \nBy inspecting the evaluation rules we see that the only possible\nevaluation process gives rise to an infinite regress, therefore\n\\(\\Omega \\opUparrow\\). \nWe can define the usual boolean operations by means of the conditional\noperator, as in the following examples: \n\n\\[\\begin{align}\n\\tag{2} \\texttt{and} &= {\\lambda x:\\texttt{bool}, y:\\texttt{bool}{\\, . \\,}{\\texttt{if }x\\texttt{ then }y\\texttt{ else }\\texttt{ff}}}.\n                                    \\label{etbivalente} \\\\\n\\tag{3} \\texttt{or} &= {\\lambda x:\\texttt{bool}, y:\\texttt{bool}{\\, . \\,}{\\texttt{if }x\\texttt{ then }\\texttt{tt}\\texttt{ else }y}}\n                                \\label{velbivalente}\\end{align}\\]\n\n with the usual\ntruth tables. However, we have now to take into account the\npossibility of divergence of the evaluation process, for example in a\nterm like \\(\\texttt{or}(\\Omega,\\texttt{tt})\\), therefore we extend the\nusual truth tables by adding a new boolean value, representing absence\nof information, \\(\\bot\\) (read as “undefined”) to\n\\(\\texttt{tt}\\) and \\(\\texttt{ff}\\), as the value of the term\n\\(\\Omega\\). Here, the first argument to be evaluated is the one on the\nleft, and if the evaluation of this diverges then the whole evaluation\nprocess diverges. Consider now an operator por\nwhose interpretation is given by the\ntable \n\n\\[\\tag{4}\\label{por}\n \\begin{array}{r|lll} \n\\texttt{por}& \\textit{tt}& \\textit{ff}&\\bot \\\\\\hline\n\\textit{tt}& \\textit{tt}& \\textit{tt}&\\textit{tt}\\\\\n \\textit{ff}& \\textit{tt}& \\textit{ff}&\\bot\\\\\n \\bot & \\textit{tt}& \\bot &\\bot \n\\end{array}\\]\n\n In this case \\(\\texttt{por}(\\texttt{tt},\\Omega) =\n\\texttt{por}(\\Omega,\\texttt{tt}) = \\texttt{tt}\\): this is the\nparallel-or which plays a central role in the full\nabstraction problem for PCF. It will turn out that is is not definable\nby any PCF term, precisely because of its parallel nature. In order to\ncarry out a semantical analysis of PCF, we need a theory of data types\nwith partial elements and of functions over them that support\nan abstract form of recursive definition through fixed point\nequations: this is what is achieved in Scott’s theory of\ndomains, the original mathematical foundation for denotational\nsemantics of programming languages as conceived by Strachey (1966,\n1967). \nWhat are the general structural properties of a space of partial data?\nThe mathematical theory of computation elaborated by Dana Scott (1970)\nis an answer to this question, that takes partially ordered sets\ngenerically called domains as basic structures. The partial\norder of a domain describes a qualitative notion of\n“information” carried by the elements. In such a framework\nit is natural to reify divergence by introducing a new element\n\\(\\bot\\) representing absence of information. When \\(x \\sqsubseteq y\\)\nin this partial order,  \n\\(y\\) is consistent with \\(x\\) and is (possibly) more\naccurate than \\(x [\\ldots]\\) thus \\(x \\sqsubseteq y\\) means that\n\\(x\\) and \\(y\\) want to approximate the same entity, but \\(y\\) gives\nmore information about it. This means we have to allow\n“incomplete” entities, like \\(x\\), containing only\n“partial” information. (Scott 1970: 171)  \nThe resulting partially ordered sets should also have the property\nthat sequences of approximations, in particular infinite chains \\(x_0\n\\sqsubseteq x_1 \\sqsubseteq \\ldots\\) should converge to a\nlimit containing the information cumulatively provided by the\n\\(x_i\\). The same structure is also exploited in Kleene’s proof\nof the First Recursion Theorem in Kleene 1952 (secs. 66,\n348–50), and will allow to define a notion of continuous\nfunction in terms of preservation of limits. \nDefinition 2.3 (Complete partial orders). A complete\npartial order (cpo) is a partially ordered set \\({\\langle\nD,\\sqsubseteq \\rangle}\\) with a least element \\(\\bot\\), and such that\nevery increasing chain \\(x_0 \\sqsubseteq x_1 \\sqsubseteq \\ldots\\) of\nelements of \\(D\\) has a least upper bound \\(\\bigsqcup_n x_n\\). \nGiven any set \\(X\\), we write \\(X_{\\bot}\\) for the set \\(X \\cup \\{\n\\bot \\}\\) obtained by adding a new element \\(\\bot\\). It is natural to\norder the elements of \\(X_{\\bot}\\) according to their amount of\ninformation, by setting for \\(x,y \\in X_{\\bot}\\), \n\n\\[\\begin{aligned}\nx \\sqsubseteq y &\\Longleftrightarrow (x = \\bot \\ \\text{ or } \\   x = y).\\end{aligned}\\]\n\nPartially ordered structures of the form \\(X_\\bot\\) are called\nflat domains, among which we have \\(\\texttt{bool}= {\\{\n{\\textit{tt}},{\\textit{ff}}\\}}_\\bot\\) and \\(\\texttt{num}=\n{\\mathbb{N}}_\\bot\\), that will be used to interpret the ground types\nof PCF. \nA general requirement on domains is that every element be a limit of\nits finite approximations, for a notion of finiteness (or\ncompactness) that can be formulated entirely in terms of the\npartial order structure: \nDefinition 2.4 (Finite elements of a cpo). If \\(D\\)\nis a cpo, an element \\(d \\in D\\) is finite if, for every\nincreasing chain \\(x_0 \\sqsubseteq x_1 \\sqsubseteq \\ldots\\)\n\n\\[d \\sqsubseteq \\bigsqcup_n x_n  \\Longrightarrow \\exists x_i\\ \\left(d \\sqsubseteq x_i \\right).\\]\n\n For \\(d \\in D\\), the notation \\(\\mathcal{A}(d)\\) denotes\nthe set of finite elements below \\(d\\); \\(\\mathcal{A}(D)\\) is the set\nof finite elements of \\(D\\). Finite elements are also called\ncompact. \nObserve that finite subsets of a set \\(X\\) are exactly the finite\nelements of the complete lattice of subsets of \\(X\\). It is useful\nalso to observe that this definition only partially matches our\nintuition: consider for example the finite element \\(\\infty + 1\\) in\nthe cpo \n\n\\[0 \\sqsubseteq 1 \\sqsubseteq 2 \\sqsubseteq \\cdots \\sqsubseteq \\infty \\sqsubseteq \\infty + 1.\\]\n\n  \nDefinition 2.5 (Algebraic cpo). A \\(D\\) is\nalgebraic if, for every \\(d \\in D\\), there is an increasing\nchain \\(x_0 \\sqsubseteq x_1 \\sqsubseteq \\ldots\\) of finite\napproximations of \\(d\\) such that \n\n\\[d = \\bigsqcup_n x_n.\\]\n\n If \\(D\\) is algebraic,\nwe say that the finite elements form a basis of \\(D\\). \nOne last completeness assumption on algebraic cpo’s is needed in\norder to get a category of domains suitable for the interpretation of\nPCF: \nDefinition 2.6. Given a cpo \\(D\\), if \\(X \\subseteq\nD\\) has an upper bound we say that \\(X\\) is consistent, and\nwrite \\(\\opuparrow X\\), or \\(x \\opuparrow y\\) when \\(X = {\\{ x,y\n\\}}\\). \\(D\\) is consistently complete if every \\(X \\subseteq\nD\\) such that \\(\\opuparrow X\\) has a least upper bound. \nThe following notion of domain that has proved extremely convenient as\na framework for the denotational semantics of programming languages\n(Scott 1982): \nDefinition 2.7 (Domain). A domain is a\nconsistently complete algebraic cpo with a countable basis. \nHow can we use the notion of information implicit in the ordering on\nthe elements of domains to develop an abstract notion of\ncomputability? Clearly, a computable function should preserve\nmonotonically any increase of information on its inputs:\n\\(f(x) \\sqsubseteq f(y)\\) whenever \\(x \\sqsubseteq y\\). In particular,\nstrict functions \\(f : D \\to E\\) over flat domains, those for\nwhich \\(f(\\bot_D) = \\bot_E\\), are monotonic. \nConsider the domain \\({\\{ 0,1 \\}}^\\infty\\) whose elements are finite\nand infinite sequences of bits \\(0,1\\), where \\(u \\sqsubseteq v\\) if\neither \\(u\\) is infinite and \\(u = v\\), or \\(u\\) is finite and \\(u\\)\nis a prefix of \\(v\\). What properties should be true of a computable\nfunction taking as arguments an infinite sequence of bits \\({\\langle\nb_1,b_2,b_3,\\ldots \\rangle}\\)? Take as an example the function\n\\(\\textit{search}:{\\{ 0,1 \\}}^\\infty \\to {\\mathbb{B}}_\\bot\\) whose\nvalue is \\({\\textit{tt}}\\) if, for \\(u \\in {\\{ 0,1 \\}}^\\infty\\), \\(1\\)\noccurs in \\(u\\) at least once, otherwise \\(\\bot\\). Think of the\nsequence \\({\\langle b_1,b_2,b_3,\\ldots \\rangle}\\) as given one element\nat a time: the initial segments obtained in this process are an\nincreasing chain of finite elements of \\({\\{ 0,1 \\}}^\\infty\\),\n\n\\[{\\langle  \\rangle} \\sqsubseteq {\\langle b_1 \\rangle} \\sqsubseteq {\\langle b_1,b_2 \\rangle} \\sqsubseteq {\\langle b_1,b_2,b_3 \\rangle} \\sqsubseteq \\ldots\\]\n\n having \\({\\langle b_1,b_2,b_3,\\ldots \\rangle}\\) as a\nlimit (i.e., least upper bound). By monotonicity we have a\ncorresponding increasing chain of values \n\n\\[\\textit{search}({\\langle  \\rangle}) \\sqsubseteq \\textit{search}({\\langle b_1 \\rangle}) \\sqsubseteq \\textit{search}({\\langle b_1,b_2 \\rangle}) \\sqsubseteq \\textit{search}({\\langle b_1,b_2,b_3 \\rangle}) \\sqsubseteq \\ldots\\]\n\n If\n\\(\\textit{search}({\\langle b_1,b_2,b_3,\\ldots \\rangle}) =\n{\\textit{tt}}\\), then there must be a finite initial segment\n\\({\\langle b_1,b_2,\\ldots,b_n \\rangle}\\) for which\n\\(\\textit{search}({\\langle b_1,b_2,\\ldots,b_n \\rangle}) =\n{\\textit{tt}}\\), and this will be the cumulative value of the function\nfor the infinite sequence \\({\\langle b_1,b_2,b_3,\\ldots \\rangle}\\). In\ngeneral, a computable function \\(f : D \\to E\\) should (be monotonic\nand) have the property that a finite amount of information on the\noutput \\(f(x)\\) must be already obtainable by giving a finite amount\nof information on the input \\(x\\). This is equivalent to the notion of\ncontinuity originally introduced by Scott in his theory of computable\nfunctions over domains: \nDefinition 2.8 (Continuous functions). If \\({\\langle\nD,\\sqsubseteq _D \\rangle},{\\langle E,\\sqsubseteq _E \\rangle}\\) are\ncpo’s and \\(f : D \\to E\\) is monotonic, \\(f\\) is\ncontinuous if \n\n\\[f(\\bigsqcup_i x_i) = \\bigsqcup_i f(x_i)\\]\n\n for every increasing chain \\(x_0\n\\sqsubseteq x_1 \\sqsubseteq \\ldots \\subseteq D\\). \nFrom the point of view of denotational semantics, a fundamental\nproperty of continuous functions \\(D \\to D\\) is that they admit a\nleast fixed point, whose construction can be carried out uniformly and\ncontinuously: \nTheorem 2.1 (The Fixed Point Theorem for continuous\nfunctions) Let \\(f : D \\to D\\) be a continuous function and \\(x \\in\nD\\) be such that \\(x \\sqsubseteq f(x)\\). Then the element \n\n\\[\\bigsqcup_{n \\in {\\mathbb{N}}} f^{(n)}(x)\\]\n\nis the least \\(y \\sqsupseteq x\\) such that \\(f(y) = y\\). \nDefinition 2.9. The least fixed point of a continuous\n\\(f : D \\to D\\) is the element of \\(D\\) defined by \n\n\\[{\\texttt{fix}(f)} =_{\\textrm{def}} \\bigsqcup_{n \\in {\\mathbb{N}}} f^{(n)}(\\bot).\\]\n\n  \nThe continuous functions from \\(D\\) to \\(E\\), for cpo’s\n\\({\\langle D,\\sqsubseteq _D \\rangle}\\) e \\({\\langle E,\\sqsubseteq _E\n\\rangle}\\), form a cpo \\([D \\to E]\\), ordered pointwise by setting,\nfor \\(f,g:D \\to E\\): \n\n\\[f \\sqsubseteq g \\Longleftrightarrow \\forall d \\in D. f(d) \\sqsubseteq _E g(d).\\]\n\n \\([D \\to E]\\) is a domain if \\(D\\)\nand \\(E\\) are, and \\({\\texttt{fix}(\\cdot)}:[D \\to D] \\to D\\) is\ncontinuous. A further construction on cpo’s which also extends\nto domains and is very frequently used is cartesian product:\ngiven cpo’s \\(D,E\\), their cartesian product is defined as the\nset \\(D \\times E\\) of pairs \\({\\langle d,e \\rangle}\\) where \\(d \\in\nD\\) and \\(e \\in E\\), ordered pointwise: \\({\\langle d,e \\rangle}\n\\sqsubseteq {\\langle d',e' \\rangle}\\) if and only if \\(d \\sqsubseteq\n_D d'\\) and \\(e \\sqsubseteq _E e'\\). We can summarize these\nconstructions in categorical language (Plotkin 1978, Other Internet\nResources), saying that the category whose objects are domains and\nwhose morphisms are the continuous functions is cartesian\nclosed. \nThe standard interpretation of PCF consists of a family of\ncpos \\(D^\\sigma\\), for each type \\(\\sigma\\), where \\(D^\\texttt{num}=\n{\\mathbb{N}}_{\\bot}\\) and \\(D^\\texttt{bool}= {\\mathbb{B}}_{\\bot}\\),\n\\(D^{\\sigma \\to \\tau} = [D^\\sigma \\to D^\\tau]\\) and the PCF constants\nhave the natural interpretation as strict continuous functions of the\nappropriate type, for example \\(\\texttt{cond}: {\\mathbb{B}}_{\\bot} \\to\n{\\mathbb{N}}_{\\bot} \\to {\\mathbb{N}}_{\\bot} \\to {\\mathbb{N}}_{\\bot}\\)\nis interpreted as: \n\n\\[\\textit{cond}(b)(x)(y) = \\left\\{    \\begin{array}{ll}\n                            x&\\text{if \\(b = \\texttt{tt}\\)}\\\\\n                            y &\\text{if \\(b = \\texttt{ff}\\)}\\\\\n                            \\bot    &\\text{if \\(b = \\bot\\),}    \n                            \\end{array}\n                \\right.\\]\n\n Furthermore, the operator\n\\({\\mathtt{Y}(\\cdot)}\\) is interpreted as the continuous functional\n\\({\\texttt{fix}(\\cdot)}\\) at the appropriate type. This is the\ninterpretation considered in Scott 1969b) and Milner 1973. \nThe possibility that \\(e\\) may contain free occurrences of variables\n(whose types are given by a basis \\(B\\)) slightly complicates the\ninterpretation of terms, making it depend on a further parameter, an\nenvironment \\(\\rho\\) mapping each free variable \\(x:\\tau\\) of\n\\(e\\) to an element of \\(D^\\tau\\) (if the latter condition is\nsatisfied, we say that \\(\\rho\\) respects \\(B\\)). Of course,\nthe environment is irrelevant when \\(e\\) is closed. \nThe standard interpretation of PCF terms \\(e:\\sigma\\) (from a basis\n\\(B\\)) is then an element \\({\\lll e\\rll \\rho} \\in D^\\sigma\\), for any\nenvironment \\(\\rho\\) such that \\(\\rho\\) respects \\(B\\), built by\nstructural induction on terms, interpreting application as function\napplication and \\(\\lambda\\)-abstractions by (continuous) functions.\nMore generally, an interpretation is continuous if every\n\\(D^\\sigma\\) is a cpo and \\(D^{\\sigma \\to \\tau}\\) consists of\ncontinuous functions \\(D^\\sigma \\to D^\\tau\\). \nA model of PCF is an interpretation that satisfies the\nexpected identities between terms of the same type. We shall omit the\ndetails of the general characterization of models of PCF, for which\nthe reader is referred to Ong (1995: sec. 3.2) and Berry, Curien,\n& Lévy (1985: sec. 4), but just to point out an example of\nwhat must be taken into account when such a generality is needed, in\norder to admit interpretations where the elements at function types\nare not, strictly speaking, functions, we have to assume a family of\napplication operations \n\n\\[\\cdot_{\\sigma\\tau}: D^{\\sigma \\to \\tau} \\times D^\\sigma \\to D^\\tau\\]\n\n so that, if \\(B \\vdash\ne_1 : \\sigma \\to \\tau\\) and \\(B \\vdash e_2 ; \\sigma\\), \\({\\lll\ne_1e_2\\rll \\rho} = {\\lll e_1\\rll \\rho} \\cdot_{\\sigma\\tau} {\\lll\ne_2\\rll \\rho} \\in {{{D}^{\\tau}}}\\). A model is\norder-extensional if, for all elements \\(f,g \\in\n{{{D}^{\\sigma \\to \\tau}}}\\), \\(f \\sqsubseteq g\\) if and only if \\(f\n\\cdot x \\sqsubseteq g \\cdot x\\) for all \\(x \\in {{{D}^{\\sigma}}}\\). A\nmodel is extensional if, for all elements \\(f,g \\in\n{{{D}^{\\sigma \\to \\tau}}}\\), \\(f = g\\) if and only if \\(f \\cdot x = g\n\\cdot x\\) for all \\(x \\in {{{D}^{\\sigma}}}\\). An element \\(d \\in\nD^\\sigma\\) of a model is definable is there is a closed terms\n\\(e:\\sigma\\) such that \\(d = {\\lll e\\rll }\\). \nThe general setting for discussing full abstraction requires that we\nintroduce the following notions: \nDefinition 2.11 (Observational preorder and\nequivalence) Given PCF terms \\(e\\) and \\(e'\\) of the same type\n\\(\\sigma\\), we write \\(e \\precsim_{\\textrm{obs}} e'\\) (read \\(e\\)\nis observationally less defined than \\(e'\\)) if, for every\nprogram context \\(C\\blbr\\) with a hole of type \\(\\sigma\\) and any\nvalue \\(v\\), \n\n\\[C[e] \\opDownarrow v \\ \\text{ implies that } \\ C[e'] \\opDownarrow v.\\]\n\n We say that \\(e\\) and \\(e'\\) are\nobservationally equivalent, and write \\(e\n\\simeq_{\\textrm{obs}} e'\\), if \\(e \\precsim_{\\textrm{obs}} e'\\) and\n\\(e' \\precsim_{\\textrm{obs}} e\\). \nObservational equivalence is a congruence. Another congruence on PCF\nterms is given by equality of denotations in a model: \nDefinition 2.11 (Denotational preorder and\nequivalence). Given PCF terms \\(e\\) and \\(e'\\) of the same type\n\\(\\sigma\\) relative to a basis \\(B\\), we write \\(e\n\\precsim_{\\textrm{den}} e'\\) if \\({\\lll e\\rll \\rho} \\sqsubseteq {{\\lll\ne'\\rll} \\rho}\\) for all environments \\(\\rho\\) respecting \\(B\\). We\nwrite \\(e \\simeq_{\\textrm{den}} e'\\) if \\(e \\precsim_{\\textrm{den}}\ne'\\) and \\(e' \\precsim_{\\textrm{den}} e\\) . \nProposition 2.1 (Computational adequacy for PCF). The\nfollowing two statements hold for the standard model of PCF, and are\nequivalent: \nWe can now justify our intuitive interpretation of \\(\\bot\\) in the\nstandard model, where ground types are interpreted as flat\ndomains: \nCorollary 2.1. For any closed PCF term \\(e\\) of\nground type, \\(e \\opUparrow\\) if and only if \\({\\lll e\\rll } =\n\\bot\\). \nIn\n Section 1.3\n we have already defined a very general notion of (equational) full\nabstraction, based on synonymy, i.e., equality of interpretation of\nterms. In the case PCF, whose intended models are partially ordered at\nall types, we can define a stronger property: \nDefinition 2.12 (Inequational full abstraction). A\ncontinuous model \\({\\langle {\\{ {{{D}^{\\sigma}}} \\mid \\sigma \\in\n\\texttt{Types}}\\},{\\lll \\cdot\\rll \\cdot} \\rangle}\\) of PCF is\ninequationally fully abstract if, for closed terms \\(e,e'\\),\n\\(e \\precsim_{\\textrm{obs}} e'\\) implies \\({\\lll e\\rll } \\sqsubseteq\n{\\lll e'\\rll }\\). \nDefinability is the key to full abstraction, as shown by the following\nimportant result of Milner and Plotkin: \nTheorem 2.2. A continuous, order-extensional model of\nPCF is fully abstract if and only if for every type \\(\\sigma\\),\n\\({{{D}^{\\sigma}}}\\) is a domain whose finite elements are\ndefinable. \nWe turn now to the failure of the full abstraction property for the\nstandard model of PCF, as shown by Plotkin in his classic study\n(Plotkin 1977): \nProposition 2.2. The standard model of PCF is not\nfully abstract with respect to call-by-name evaluation. \nThe proof is based on the observation that we can build PCF terms of\ntype \\((\\texttt{bool}\\to \\texttt{bool}\\to \\texttt{bool}) \\to\n\\texttt{num}\\) that recognize the parallel-or function. Specifically,\nconsider the “test” terms \\(T_i\\) defined as follows,\nwhere \\(i = {0},1\\): \nThen, \\({\\mathcal{D}\\lll T_{0}\\rll}\\ \\texttt{por} = {0}\\neq 1 =\n{\\mathcal{D}\\lll T_1 \\rll }\\ \\texttt{por} \\), where por\nis defined by table \\((\\ref{por})\\), so\n\\(T_{0} {\\simeq_{\\textrm{den}}}T_1\\) does not hold. However, no\nprogram context in PCF can separate \\(T_{0}\\) and \\(T_1\\) because\npor is not definable. This can be shown\nby characterizing in a combinatorial way the relations of dependence\ninduced by the evaluation process of a program among the evaluation\nprocesses of its (sub)terms, as Plotkin does in the Activity Lemma\n(Plotkin 1977: Lemma 4.2). As an alternative, it is possible to build\na computationally adequate models of PCF whose functions enjoy a weak\nsequentiality property (that we discuss below, in\n Section 2.5.1)\n and where, therefore, the function por\nis ruled out: a complete formal proof along these lines is given in\nGunter 1992 (sec. 6.1). \nOne option to solve the full abstraction problem is to extend the\nlanguage: a remarkable result of Plotkin (1977) shows that adding\nparallel-or is enough: \nProposition 2.3. The standard model is fully abstract\nfor the language PCF extended with parallel-or. \nMilner (1977) has shown that there is a fully abstract model of PCF,\nby taking the set of closed terms at each type \\(\\sigma\\) identifying\nobservationally equivalent terms and by completing the resulting\npartially ordered set turning it into a cpo. \nCorollary 2.2. There is a unique continuous, order\nextensional, inequationally fully abstract model of PCF, up to\nisomorphism. \nThe full abstraction problem for PCF consists in finding a direct\ndescription of the class of domains and continuous functions that make\nup the fully abstract model. A solution to this problem would require\na precise criterion for assessing the extent to which a proposed\ndescription of the model is satisfactory. If one accepts the\n“precise minimal condition that a semantic solution of the full\nabstraction problem should satisfy” given by Jung &\nStoughton (1993), namely the possibility of describing in an effective\nway the domains \\(D^\\sigma\\) of a finitary version of PCF (whose only\nground type is bool), then the story of\nfailed attempts to give such a direct description of the fully\nabstract model is justified, with hindsight, by a result of Loader\n(2001): \nTheorem 2.3. Observational equivalence for finitary\nPCF is not decidable. \nIt is still possible, however, that one could find a direct\ndescription of an intensionally fully abstract model\n(Abramsky et al. 2000: 411): \nDefinition 2.13 (Intensional full abstraction). A\nmodel of PCF is intensionally fully abstract if every\n\\(D^\\sigma\\) is algebraic and all its compact elements are\ndefinable. \nPursuing this line of development of the full abstraction problem\nleads us to game semantics, which will be the topic of the next\nSection. Before that, we outline the main attempts to reduce the model\nby means of a semantical characterization of higher-order sequential\ncomputation. \nThe reason for the failure of full abstraction of the continuous\nsemantics of PCF is the existence of functions whose evaluation\nrequires parallel computation. We describe now some proposals for\ncharacterizing sequentiality of functions by means of\nproperties related to the structure of the domains on which they are\ndefined. This has been an area of intensive research toward the\nsolution of the full abstraction problem for PCF, and some of the\ninsights that emerged from it lead very naturally to the game models\ndiscussed in\n Section 3.\n In addition, the following summary of attempts at a characterization\nof sequentiality is also a very interesting demonstration of the\nexpressive power of the language of partial order in the semantic\nanalysis of programming concepts. \nIntuitively, a sequential function is one whose evaluation proceeds\nserially: this means that it is possible to schedule the evaluation of\nits arguments so that the evaluation of the function terminates with\nthe correct value; if the evaluation of one of them diverges, the\nwhole evaluation diverges. At each stage of this process there is an\nargument whose value is needed to obtain more information on the\noutput of the function. In order to account for this causal structure\nof computations at the semantical level, we need to enrich the domain\nstructure so that the order on the elements reflect the happening of\ncomputational events and their causal order. This suggests\nanother way of interpreting the abstract notion of information that\nmotivated the axioms of a cpo in\n Section 2.3.1.\n Now,  \ninformation has to do with (occurrences of) events: namely the\ninformation that those events occurred. For example in the case of\n\\({\\mathbb{N}}_{\\bot}\\), \\(\\bot\\) might mean that no event occurred\nand an integer \\(n\\), might mean that the event occurred of the\ninteger \\(n\\) being output (or, in another circumstance being input).\n(Plotkin 1978, Other Internet Resources) \nOne interpretation of events regards them as the production of values\nin the evaluation of an expression. This interpretation originates in\nthe context of bottom-up computation of recursive programs developed\nby Berry (1976), where a recursive definition is translated into a\ngraph displaying the dependence of results of an expression on results\nof its subexpressions. This context naturally suggests the notion of\nproducer of an event \\(x\\), as a set of events that must have\nhappened in order that \\(x\\) may happen. Reformulating this\nobservation in the language of partial orders, Berry (1976)\ndefined: \nDefinition 2.14 (Stability). Let \\(D_1,\\ldots,D_n,\nD\\) be flat cpo’s and \\(f: D_1\\times \\ldots \\times D_n \\to D\\)\nmonotonic (hence continuous). Then \\(f\\) is stable if for\nevery \\(\\vec{x} = {\\langle x_1,\\ldots,x_n \\rangle} \\in D_1\\times\n\\ldots \\times D_n\\) there is a unique minimal element \\(m(f,x)\n\\sqsubseteq \\vec{x}\\) such that \\(f(m(f,\\vec{x})) = f(\\vec{x})\\). \nClearly, the parallel-or function is not stable: the value\n\\(\\texttt{por}(\\bot,{\\textit{tt}}) = {\\textit{tt}}=\n\\texttt{por}({\\textit{tt}},\\bot)\\) has no minimal producer. A\nremarkable property of stable functions is that they allow to build a\nnew model of PCF, where \\({{{D}^{\\sigma \\to \\tau}}}\\) is the set of\nstable functions on the domains that interpret the types \\(\\sigma\\)\nand \\(\\tau\\), which are refinements of Scott domains called\ndI-domains (Berry 1978). From our point of view, the\nimportant outcome of these definitions is the following adequacy\nresult (Gunter 1992: chap. 6): \nProposition 2.4. The interpretation of PCF terms as\nelements of dI-domains, where \\(D^{\\sigma \\to \\tau}\\) is the dI-domain\nof stable functions from \\(D^\\sigma\\) to \\(D^\\tau\\) with the stable\norder, is a computationally adequate model of PCF. \nThis result completes the argument showing the failure of full\nabstraction for the continuous model of PCF at the end of\n Section 2.4,\n if the informal notion of sequentiality used there is formalized as\nstability. The stable model of PCF has recently been shown to be fully\nabstract for an extension of PCF (Paolini 2006). \nThe first definitions of sequentiality, due to Vuillemin (1974) and\nMilner (1977) stated that an \\(n\\)-ary functions \\(f\\) over flat\ndomains is sequential at argument \\({\\langle x_1,\\ldots,x_n\n\\rangle}\\) if there is a sequentiality index \\(i\\) of\n\\(f\\), depending on \\({\\langle x_1,\\ldots,x_n \\rangle}\\), such that\nevery increase in the output information must increase the information\nat argument \\(i\\). For example, the function \\(\\texttt{cond} :\n{\\mathbb{B}}_{\\bot} \\times {\\mathbb{N}}_{\\bot} \\times\n{\\mathbb{N}}_{\\bot} \\to {\\mathbb{N}}_{\\bot}\\) is sequential in this\nsense at any input tuple. In fact, its sequentiality index at\n\\({\\langle \\bot,m,n \\rangle}\\) is 1; its sequentiality index at\n\\({\\langle {\\textit{tt}},m,n \\rangle}\\) is 2, and its sequentiality\nindex at \\({\\langle {\\textit{ff}},m,n \\rangle}\\) is 3. There is\nhowever no sequentiality index for the function \\(\\texttt{por} :\n{\\mathbb{B}}_{\\bot} \\times {\\mathbb{B}}_{\\bot} \\to\n{\\mathbb{B}}_{\\bot}\\) at the input \\({\\langle \\bot,\\bot\n\\rangle}\\). \nWhile all sequential functions (over flat domains) are stable,\nsequentiality is strictly stronger than stability. For example, the\ncontinuous function from \\({\\mathbb{B}}_\\bot \\times {\\mathbb{B}}_\\bot\n\\times {\\mathbb{B}}_\\bot\\) to \\({\\mathbb{B}}_\\bot\\) defined as the\nsmallest continuous extension of the three assignments \n\n\\[{\\langle {\\textit{tt}},{\\textit{ff}},\\bot \\rangle} \\mapsto {\\textit{tt}}, {\\langle {\\textit{ff}},\\bot,{\\textit{tt}}\\rangle} \\mapsto {\\textit{tt}}, {\\langle \\bot,{\\textit{tt}},{\\textit{ff}}\\rangle} \\mapsto {\\textit{tt}}.\\]\n\nhas no sequentiality index at the argument \\({\\langle \\bot,\\bot,\\bot\n\\rangle}\\), but is stable because the arguments \\({\\langle\n{\\textit{tt}},{\\textit{ff}},\\bot \\rangle},{\\langle\n{\\textit{ff}},\\bot,{\\textit{tt}}\\rangle},{\\langle\n\\bot,{\\textit{tt}},{\\textit{ff}}\\rangle}\\) are pairwise\ninconsistent. \nThe following result adds support to the search for a semantical\ncharacterizations of sequentiality: \nProposition 2.5. Let \\(f : D_1 \\times \\cdots \\times\nD_n \\to D\\) be a continuous function, where \\(D_i,D\\) are either\n\\({\\mathbb{N}}_\\bot\\) or \\({\\mathbb{B}}_\\bot\\). Then \\(f\\) is\nsequential if and only if it is definable in PCF. \nIf the domains needed for an adequate definition of sequentiality are\nto describe the causality relations among occurrences of computational\nevents, then it is necessary to enrich our picture by considering\nevents as located at places, generalizing the notion of\nargument place in the definitions of Vuillemin and Milner which\ndepends on how a function is presented. This led to a notion of\nconcrete data structure (cds) (Kahn & Plotkin 1993) and\nto an axiomatization of the order-theoretic properties of domains of\nfirst-order data. Kahn and Plotkin obtained a representation theorem\nfor the domains described by their axioms, the concrete\ndomains, in terms of the states of a process of\nexploration of a concrete data structure that consists in filling,\ngiven a state \\(x\\), any cell enabled by sets of events that have\nalready happened in \\(x\\), starting from initial cells\nenabled in the initial, empty state: this is similar to proving\ntheorems in an abstract deductive system whose rules are the\nenablings. As a motivating example, think of a linked list of, say,\nnatural numbers. The initial cell may be filled at any time with any\nvalue \\(n_1\\). This event enables the second cell of the list, which\nmay then (and only then) be filled with any value \\(n_2\\), and so on\nfor all later cells. \nObserve that the framework of concrete data structures gives the\nnecessary notions to reconstruct a semantical version of\nsequentiality. Roughly, a monotonic function \\(f\\) from states of\n\\(M\\) to states of \\(M'\\) is sequential (at state \\(x\\)) if,\nfor any output cell \\(c'\\), there is an input cell \\(c\\) that must be\nfilled in any transition from \\(x\\) to \\(y\\) such that the transition\nfrom \\(f(x)\\) to \\(f(y)\\) fills \\(c'\\) (if such a \\(c'\\) does exist)\n(Curien 1986: Def. 2.4.5). The cell \\(c\\) is the\nsequentiality index for \\(f\\) at \\(x\\) for \\(c'\\). \nThe category whose objects are the concrete data structures and whose\nmorphisms are the sequential functions just defined is, however, not\ncartesian closed, not unexpectedly. This observation (for a simple\nproof, see Amadio & Curien 1998 (theorem 14.1.12)) prevents the\nuse of this category as a model of PCF. However, it is possible to\ndefine for every two concrete data structures \\(M,M'\\) a new one \\(M\n\\to M'\\) whose states represent sequential algorithms and\nwhich is the exponential object of \\(M\\) and \\(M'\\) in a cartesian\nclosed category whose morphisms are sequential algorithms (Curien\n1986: sec. 2.5). The generalizations of the model theory of PCF to\ncategorical models allows us to obtain a model of PCF from this new\ncategory, even though its morphisms are not functions in the usual\nset-theoretic sense. It turns out that the sequential algorithm model\nis not extensional, because there are distinct PCF terms that denote\nthe same continuous function yet represent distinct algorithms. As an\nexample, consider the following two terms, that denote the same\nfunction but different algorithms: \n\n\\[\\begin{aligned}\n\\texttt{lror}(x,y) &= \\texttt{if }x\\texttt{ then }({\\texttt{if }y\\texttt{ then }\\texttt{tt}  \\texttt{ else }x}) \\\\\n&\\quad \\texttt{ else }({\\texttt{if }y\\texttt{ then }\\texttt{tt}\\texttt{ else }\\texttt{ff}}) \\\\\n\\texttt{rlor}(x,y) &= \\texttt{if }y\\texttt{ then }({\\texttt{if }x\\texttt{ then }\\texttt{tt}\\texttt{ else }y})\\\\\n&\\quad \\texttt{ else }({\\texttt{if } x\\texttt{ then }\\texttt{tt}\\texttt{ else }\\texttt{ff}}).    \n\\end{aligned}\\]\n\n By suitably\nintroducing error values \\(\\textit{error}_1,\\textit{error}_2\\) in the\nsemantics, and enforcing an error-propagation property of the\ninterpretations of terms (thus enlarging the observables of the\nlanguage), the functions corresponding to the above terms can\nthen be distinguished: clearly, for the interpreting functions\n\\(\\textit{lror}\\) and \\(\\textit{rlor}\\) we have \n\n\\[\\begin{aligned}\n \\textit{lror}(\\textit{error}_1,\\textit{error}_2) &= \\textit{error}_1 &\\textit{rlor}(\\textit{error}_1,\\textit{error}_2) &= \\textit{error}_2\\end{aligned}\\]\n\n which\nalso points to the possibility of proving full abstraction of this\n(non-standard) extensional model with respect to an extension of PCF\nwith control operators (Cartwright, Curien, & Felleisen 1994). \nBefore leaving this overview of the quest for an extensional\ncharacterization of higher-order sequentiality, we should mention\nBucciarelli & Ehrhard (1994) who introduced a refinement of the\ndI-domains of Berry supporting a notion of strongly stable\nfunction which allows them to build an extensional model of PCF,\nwhich is not fully abstract. The reason for the failure of full\nabstraction in this case depends on the fact that PCF-definable\nfunctionals satisfy extensionality properties that fail when functions\nare ordered by the stable order. This was also the reason that\nmotivated the introduction of bidomains (Berry 1978), where\nthe stable and extensional (= pointwise) orderings of functions\ncoexist. \nThe problem of full abstraction has been anticipated in a large amount\nof work on the relations between the denotational and operational\ninterpretations of programming languages. In particular, the\npioneering work on the semantics of recursive programs carried out in\nStanford in the early 1970s by a group of people gathering around\nZohar Manna, and including Jean Marie Cadiou, Robin Milner and Jean\nVuillemin, also interacting with Gilles Kahn. \nA related tradition was also quite influential on the background of\nthe full abstraction problem, namely the characterizations of\nsemantical notions like continuity and sequentiality inside syntactic\nmodels of the (untyped) \\(\\lambda\\)-calculus based on Böhm trees\n(Barendregt 1984), mainly due to Lévy and Berry (see Berry et\nal. 1985 and Curien 1992) for accounts of the search for fully\nabstract models of PCF along this line). \nThe basic papers on full abstraction for PCF are Milner 1977; Plotkin\n1977. They can be read together as giving a coherent picture of the\nsemantic analysis of this language. An independent approach to full\nabstraction came from the Russian logician Vladimir Sazonov who\ncharacterized definability in PCF in terms of a certain class of\nsequential computational strategies (Sazonov 1975, 1976). His work,\nhowever, had no direct influence on the bulk of research on the full\nabstraction problem, and only recently there have been attempts to\nrelate Sazonov’s characterization to the game theoretic\napproaches (Sazonov 2007). \nAnother, completely different approach to full abstraction, exploits\nspecial kinds of logical relations in order to isolate\nquotients of the continuous model. The first use of logical relations\nin the context of the problem of full abstraction is Mulmuley 1987,\nbut the resulting construction of a fully abstract model is obtained\nby brute force and therefore is not what the full abstraction problem\nsearches for. Later, Sieber (1992) and O’Hearn & Riecke\n(1995) have employed refinements of this technique to gain a better\ninsight into the structure of the fully abstract models,\ncharacterizing the definable elements of the standard continuous model\nby means of invariance under special logical relations cutting out the\nnon-sequential functions. \nDetailed accounts of the full abstraction problem for PCF can be found\nin Gunter 1992 (chaps 5,6), Streicher 2006, Ong 1995, Stoughton 1988\nand Amadio & Curien 1998 (chaps 6, 12, 14), in approximately\nincreasing order of technical complexity. The emphasis on the\nrecursion-theoretic aspects of PCF and its full abstraction problem\nare dealt with in detail in the textbook (Longley & Normann 2015:\nchaps 6, 7); a shorter account can be found in Longley 2001 (sec.\n4). \n\n Theorem 2.2\n highlights the fundamental role of definability of finite elements in\nthe fully abstract model of PCF, an aspect that has been stressed in\nCurien 2007. As a smooth transition to the formalisms based on games,\nand partly following the historical development of the subject, we\npause shortly to examine another aspect of definability that arises at\nthe border between computation and the proof theory of constructive\nlogical systems. It has been a remarkable discovery that the structure\nof natural deduction proofs for, say, the implicative fragment of\nintuitionistic propositional calculus is completely described by terms\nof the simply typed \\(\\lambda\\)-calculus, where a provable\npropositional formula of the form \\(\\sigma \\to \\tau\\) is read as the\ntype of the terms representing its proofs. This is the\npropositions-as-types correspondence, to be attributed to\nCurry, de Bruijn, Scott, Läuchli, Lawvere and Howard, which\nextends to much richer formal systems (for a history of this\ncorrespondence see Cardone & Hindley 2009: sec. 8.1.4). \nThe existence of this correspondence makes it possible to speak of a\nsemantics of proofs, that extends to constructive formal\nproofs the denotational interpretations of typed \\(\\lambda\\)-calculi,\nand in this context it also makes sense to ask whether an element\n\\(x\\) of some \\(D^\\sigma\\) in a model of a typed \\(\\lambda\\)-calculus\nis the interpretation of some proof of formula \\(\\sigma\\). A further\nquestion asks whether every element of \\(D^\\sigma\\)\nsatisfying a suitably chosen property is the interpretation of a proof\nof formula \\(\\sigma\\). Suitable properties may be for example\ninvariance under logical relations, suitably defined over each\n\\(D^\\sigma\\), like in several results of Plotkin, Statman and others\nsummarized in Barendregt, Dekkers, & Statman 2013 (I.3, I.4). We\ncan read the latter question as asking for a strong form of\ncompleteness for that system called full completeness\n(Abramsky & Jagadeesan 1994), whose definition can be better\nunderstood in a categorical semantics of systems of constructive\nlogic. It is common to interpret formulas \\(A\\) of such systems as\nobjects \\({\\lll A \\rll }\\) of suitable categories \\(\\mathbb{M}\\), and\nproofs \\(p\\) of sequents \\(A \\vdash B\\) as morphisms \\(\\lll p \\rll :\n\\lll A \\rll \\longrightarrow \\lll B \\rll\\). While ordinary completeness\nstates that for every valid sequent \\(A \\vdash B\\) the set\n\\(\\mathbb{M}({\\lll A \\rll },{\\lll B \\rll })\\) of morphisms is not\nempty, in the present setting full completeness expresses the stronger\nrequirement that every morphism \\(f: \\lll A \\rll \\longrightarrow \\lll\nB \\rll\\) in a semantical category \\(\\mathbb{M}\\) arises as the\ninterpretation of some proof, i.e., \\(f = {\\lll p \\rll }\\) for some\nproof \\(p\\) of the sequent \\(A \\vdash B\\). Full completeness results\nhave been proved for several subsystems of linear logic Girard (1987),\nsee Abramsky (2000) for a general framework. Furthermore, it has also\nsuggested techniques for achieving the definition of models of PCF\nenjoying the strong definability property required by intensional full\nabstraction. \nIn our description of the refinements to the continuous model of PCF\nin order to guarantee the definability of finite elements at each\ntype, we have progressively come closer to an interactive explanation\nof computation. For example, the action of a sequential algorithm \\(M\n\\to M'\\) (Curien 1986: sec. 3.4) exploits an external calling agent\nwhich triggers a cycle of requests and responses on input cells\nleading (possibly) to the emission of an output value. That\ninteraction should be a central notion in the analysis of computation,\nespecially in relation to full abstraction, is perhaps a natural\noutcome of the observational stance taken in the definition of\noperational equivalence. Our short account of game semantics starts\nprecisely from an analysis of a general notion of interaction\nas a motivation to a first formalization of games which is however\nrich enough to provide a universe for the interpretation of a\nrestricted set of types and terms. Later we shall add to this\ndefinition of game and strategies the features needed to express the\nconstraints that allow strategies to characterize precisely\nhigher-order, sequential computations, which is the aim set for\ndenotational semantics by the full abstraction problem. The present\naccount of the conceptual background of game semantics owes much to\nthe work of Abramsky and Curien (Abramsky 1994, 1996, 1997; Curien\n2003a). \nThe relevant notion of interaction has been isolated as the result of\ncontributions that come from widely different research areas\nintensively investigated only in relatively recent years, notably\nlinear logic (Girard 1987) and the theory of concurrent processes. It\nis in these areas that a notion of composition as interaction\nof modules takes shape. We give here just a simple example\nwhere the composition of modules in the form of “parallel\ncomposition + hiding” is found in nature, in order to connect it\nwith the origin of this idea in the semantics of concurrent processes\ndeveloped by Hoare (1985), and also to afford a first glimpse into a\nsimplified game formalism. \nConsider a module \\(S\\) with four channels labeled\n\\(a_\\textrm{in},a_\\textrm{out},r_\\textrm{in},r_\\textrm{out}\\). The\nmodule is intended to return on channel \\(a_\\textrm{out}\\) the\nsuccessor of the number \\(n\\) incoming through channel\n\\(a_\\textrm{in}\\), therefore its behavior can be specified as\nfollows: \n(This pattern of interaction is formally identical to the\nhandshake protocol which is used in hardware design to\nsynchronize components in order to avoid hazards caused by\ninterference of signals.) This behavior can be mapped on the channels\nas follows: \nFigure 1: A module for the successor\nfunction. \nwhere \\(\\circ\\) means input or, more generally, a passive\ninvolvement of the module in the corresponding action, whereas\n\\(\\bullet\\) means output, or active involvement in the\naction. We can describe the behavior of \\(S\\) using traces\n(Hoare 1985), i.e., finite sequences of symbols from the infinite\nalphabet \\( \\alpha S = {\\{\n\\mathbf{?}_\\textrm{in},\\mathbf{?}_\\textrm{out},n_\\textrm{in},m_\\textrm{out}\n\\}}: \\) \n\n\\[\\tau S = {\\{ \\varepsilon,\\mathbf{?}_\\textrm{in},\\mathbf{?}_\\textrm{in}  \\mathbf{?}_\\textrm{out}, \\mathbf{?}_\\textrm{in}  \\mathbf{?}_\\textrm{out} n_\\textrm{in},\\mathbf{?}_\\textrm{in}  \\mathbf{?}_\\textrm{out} n_\\textrm{in}  n+1_\\textrm{out},\\ldots \\}}\\]\n\n If we consider another instance \\(S'\\) of \\(S\\)\nwith alphabet \\( \\alpha S' = {\\{\n\\mathbf{?}_\\textrm{in}',\\mathbf{?}_\\textrm{out}',n_\\textrm{in}',m_\\textrm{out}'\n\\}} \\) we can compose \\(S\\) and \\(S'\\) by identifying (= connecting)\nchannels \\(r_\\textrm{out},r_\\textrm{in}'\\), and \\(a_\\textrm{in} ,\na_\\textrm{out}'\\), and the signals passing through them, as shown:\n\n\\[\\begin{aligned}\n\\mathbf{?}_\\textrm{out} , \\mathbf{?}_\\textrm{in}' &\\leadsto x\\\\\nn+1_\\textrm{in} , n+1_\\textrm{out}' &\\leadsto y\\end{aligned}\\]\n\n This represents the parallel composition of the modules,\n\\(S \\| S'\\): \nFigure 2 \nThe behavior of the compound module is described by the set of traces\n\n\\[{\\{ \\varepsilon,\n\\mathbf{?}_\\textrm{in},\n\\mathbf{?}_\\textrm{in}  x, \n\\mathbf{?}_\\textrm{in}  x  \\mathbf{?}_\\textrm{out}',\n\\mathbf{?}_\\textrm{in}  x  \\mathbf{?}_\\textrm{out}'  n_\\textrm{in}',\n\\mathbf{?}_\\textrm{in}  x  \\mathbf{?}_\\textrm{out}'  n_\\textrm{in}'  y, \n\\mathbf{?}_\\textrm{in}  x  \\mathbf{?}_\\textrm{out}'  n_\\textrm{in}'  y  n+2_\\textrm{out}, \\ldots \\}}\\]\n\n The symbols \\(x,y\\) can now be hidden, representing the\nbehavior of the final system \nFigure 3 \nwhose traces have the required form \n\n\\[{\\{ \n\\varepsilon,\n\\mathbf{?}_\\textrm{in},\n\\mathbf{?}_\\textrm{in}  \\mathbf{?}_\\textrm{out}',\n\\mathbf{?}_\\textrm{in}   \\mathbf{?}_\\textrm{out}' n_\\textrm{in}',\n\\mathbf{?}_\\textrm{in}   \\mathbf{?}_\\textrm{out}'  n_\\textrm{in}'   n+2_\\textrm{out}, \\ldots \\}}.\\]\n\n This example contains\nmany of the ingredients on which game semantics is based. There is the\nidea of a System, whose behavior is triggered by an incoming request\nfrom its Environment: in a game formalism these are the roles of\nProponent and Opponent in a two-person game. The behavior of each\nmodule is described as the trace of its possible interactions with\nother agents, and the behaviors can be composed by a peculiar change\nof role whereby the module who plays as System (in the above example,\n\\(S\\) emitting a request signal on channel \\(r_\\textrm{out}\\)) is made\nto behave as Environment with respect to \\(S'\\) when this signal is\nreceived in input on channel \\(r_\\textrm{in}'\\). Let us see how this\nexample can be generalized. \nWe only give the definitions needed to understand the basic\nconstructions on games and to see how these form a category, following\nAbramsky 1997 and Hyland 1997 that contain more formal details and\nproofs. \nDefinition 3.1 A game \\(G\\) is specified by\ngiving a set of moves \\(M_G\\), a labeling \\(\\ell_G\\)\nof the moves as either moves of the Proponent (\\(P\\)) or as\nmoves of the Opponent (\\(O\\)). Furthermore, there is a set of\npositions \\(P_G\\) which is a set of sequences of moves where:\n(1) the two players alternate, starting with \\(O\\); (2) if \\(s \\in\nP_G\\) then every prefix \\(s'\\) of \\(s\\) is also in \\(P_G\\). \nAs an example, consider a game associated with the data-type of\nBoolean values, \\(G_\\texttt{bool}\\). There are three possible\nmoves, \n(i.e., \\(\\ell_\\texttt{bool}(?_\\texttt{bool}) = O,\n\\ell_\\texttt{bool}({\\textit{tt}}) = \\ell_\\texttt{bool}({\\textit{ff}})\n= P\\)). The positions in this game are \n\n\\[?_{\\texttt{bool}}, ?_{\\texttt{bool}} \\texttt{tt}, ?_{\\texttt{bool}} \\texttt{ff}:\\]\n\n think of\n\\(?_\\texttt{bool}\\) as a cell (as in a concrete data structure) which\ncan be filled by one of the two values \\({\\textit{tt}}\\) and\n\\({\\textit{ff}}\\), or as a question by the Opponent that admits as\nanswers by the Proponent either \\({\\textit{tt}}\\) or\n\\({\\textit{ff}}\\). Similarly we can describe a game \\(G_\\texttt{num}\\)\nwith an \\(O\\)-move \\(?_\\texttt{num}\\) and \\(P\\)-moves \\(n \\in\n{\\mathbb{N}}\\). \nThe players move in a game \\(G\\) alternately, at each move reaching a\nlegal position in \\(P_G\\). Their behavior is best thought of as\ndescribing a strategy that prescribes deterministically what is\n\\(P\\)’s response to \\(O\\) in a position where it is its turn to\nmove. \nDefinition 3.2. A strategy \\(\\sigma\\) on a\ngame \\(G\\) is a prefix-closed set of even-length positions of \\(G\\)\nsuch that, each time \\(sab,sac \\in \\sigma\\), we have \\(b=c\\). \nFor example, the strategies on \\(G_\\texttt{num}\\) are \\(\\varepsilon\\)\nand all sequences \\(?_\\texttt{num}n\\), corresponding respectively to\nthe elements \\(\\bot\\) and \\(n\\) of the domain \\({\\mathbb{N}}_\\bot\\).\n \nWe would like to consider the behavior of the successor module\ndescribed above as an element of a set \\(G_\\texttt{num}\\multimap\nG_\\texttt{num}\\) of strategies that compute functions over the natural\nnumbers. If we consider only the sequences of interactions of \\(S\\)\ntaking place either on the left or on the right side of the module of\n Figure 1,\n we see that they describe positions of \\(G_\\texttt{num}\\), with an\ninversion of polarity (active/passive) depending on which side the\ninteractions take place: the module is initially passive, and becomes\nactive upon receiving a request from the environment. Such inversion,\nrepresented by the complementary labeling of the moves\n\\(\\overline{\\lambda_G}\\), assigning to Proponent the moves of the\nOpponent in \\(G\\) and conversely, is essential to the definition of a\ngame \\(G \\multimap H\\): \nDefinition 3.3. Given any pair of games \\(G,H\\), the\ngame \\(G \\multimap H\\) has moves \\(M_{G \\multimap H}\\) the disjoint\nunion \\(M_G + M_H\\) of the games \\(G\\) and \\(H\\), where \n\n\\[\\lambda_{G \\multimap H} (m) = \n \\begin{cases}\n         \\overline{\\lambda_{G}} (m) =   &\\text{if \\(m \\in M_G\\),}\\\\\n    \\lambda_{H} (m) =   &\\text{if \\(m \\in M_H\\).}\n    \\end{cases}\\]\n\nand a position in \\(P_{G \\multimap H}\\) is any alternating sequence\n\\(s\\) of moves (of \\(M_{G \\multimap H}\\)) whose restrictions \\(s\n\\upharpoonright M_G,s \\upharpoonright M_H\\) to the moves in \\(G\\) and\n\\(H\\), respectively, are positions of \\(G\\) and \\(H\\). \nThe strategy that interprets \\(\\texttt{succ}:\\texttt{num}\\to\n\\texttt{num}\\) corresponds to the behavior of the module \\(S\\) used\nabove as a guiding example. The parallel composition + hiding approach\nused to compose two instances of the successor module can now be\nreinterpreted as composition of strategies, suggesting a general\npattern: \nDefinition 3.4. The composition \\(\\tau \\circ \\sigma\\)\non \\(G \\multimap K\\) of strategies \\(\\sigma\\) on \\(G \\multimap H\\) and\n\\(\\tau\\) on \\(H \\multimap K\\) consists of the sequences of moves of\n\\(M_G + M_K\\) obtained by hiding the moves of \\(M_H\\) from the\nsequences \\(s\\) of moves in \\(M_G + M_H + M_K\\) such that \\(s\n\\upharpoonright G,H\\) is in \\(P_{G \\multimap H}\\) and \\(s\n\\upharpoonright H,K\\) is in \\(P_{H \\multimap K}\\). \nThere is one strategy that deserves a special name, because it is the\nidentity morphism in the category whose objects are games and whose\nmorphisms from \\(G\\) to \\(H\\) are the strategies on \\(G \\multimap H\\).\nThe copy-cat strategy \\(\\textsf{id}\\) on \\(G \\multimap G\\) is\ndefined as the set of sequences of moves \\(s\\) such that the\nrestriction of \\(s\\) to the left instance of \\(G\\) coincides with its\nrestriction to the right instance. \nThe game formalism just introduced is not detailed enough to\ncharacterize the kind of sequential computation at higher types needed\nto achieve definability. For this purpose, a richer structure on games\nis needed, making them closer to dialogue games between\nProponent and Opponent exchanging questions and\nanswers. This allows to formulate restrictions on plays by\nmatching answers with the corresponding questions in an appropriate\nmanner. The strategies for this refined game notion, that we study\nnext essentially through examples, will yield a richer notion of\nmorphism between games, allowing to make finer distinctions of a\ncomputational nature needed for intensionally fully abstract model of\nPCF, following essentially the approach of Hyland & Ong (2000)\ndrawing also material from Abramsky & McCusker (1999) and Curien\n(2006). \nThe moves of the refined game notion will be either questions\nor answers played by Proponent or by the Opponent. We have\nthen four classes of moves each represented by a kind of (round or\nsquare) bracket: Proponent’s questions ‘(’;\nOpponent’s answers ‘)’; Opponent’s questions\n‘[’; and Proponent’s answer ‘]’. This\nlabeling of the moves subsumes under the usual well-formedness\ncriterion for bracket sequences, at one time: the alternation between\nProponent and Opponent, the fact that Opponent is the first to move\nand that each answer of a player answers a unique question of the\npartner. This is not enough, however: a further justification\nstructure on questions and answers is needed to discipline the nesting\nof (sub)dialogues in the evaluation of higher-order functions,\nallowing to characterize the well-bracketed strategies.\nConsider now the strategy in \\((G^{11}_\\texttt{bool}\\to\nG^{12}_\\texttt{bool}\\to G^1_\\texttt{bool}) \\to G_\\texttt{bool}\\),\ndescribed informally using a labeling of the copies of\n\\(G_\\texttt{bool}\\) as shown: \nHere, the Proponent’s moves at steps (3.\\(i\\)) answer the\nquestion asked by Opponent at step (1), not the questions asked by the\nOpponent at steps (3.1), (3.2) that are still pending. This violates a\n“no dangling question mark” condition on dialogues\nintroduced under this name by Robin Gandy in his unpublished work on\nhigher-type computability (and well-known in the tradition of game\nsemantics for intuitionistic logic initiated by Lorenzen (1961)).\nStrategies such as these interpret control operators that do not exist\nin the fully abstract game model of PCF, but do exist, for example, in\nthe model based on sequential algorithms (Curien 1986: sec. 3.2.7,\n3.2.8). A different phenomenon occurs in a variation of the previous\nexample: \nHere the strategy prescribes a response to the moves by Opponent\ndepending on the internal detail of the latter’s behavior. The\nresponse prescribed to Proponent by the strategy to the initial\nquestion should not depend on what happens between the\nProponent’s question \\(?_1\\) and the Opponent’s answer\n\\({\\textit{tt}}\\). This is the property of innocence, that\nlimits the amount of detail that a strategy for \\(P\\) can access. For\nthis reason, failure of innocence allows strategies to model storage\nphenomena. \nThis gives us the necessary terminology to understand the statement of\nthe intensional full abstraction theorem proved in Hyland & Ong\n2000 (th. 7.1), where the types of PCF are interpreted as games\nand terms as innocent and well-bracketed strategies, see also Abramsky\net al. 2000 (th. 3.2), Curien 2006 (th. 5.1): \nTheorem 3.1. For every PCF type \\(\\sigma = \\sigma_1\n\\to \\cdots \\to \\sigma_n \\to \\kappa\\) with \\(\\kappa = \\texttt{num}\\) or\n\\(\\kappa = \\texttt{bool}\\), every (compact) innocent and\nwell-bracketed strategy corresponds to the denotation of a closed\nterm. \nThis closes our quick overview of game semantics applied to the full\nabstraction problem for PCF, but opens a broad research area in the\nclassification of programming disciplines according to the possible\ncombinations of restrictions (innocence, well-bracketing) on general\nstrategies for games as defined above. An introductory picture (the\n“semantic square” by Abramsky and his students) of this\nlandscape, that we leave to the contemplation of the reader, can be\nfound in Abramsky & McCusker 1999. \nGames as a semantic framework have a longstanding tradition, from\nancient logic onwards. Here we list of the main sources and further\nreadings pertaining to game semantics applied to programming\nlanguages. \nThe use of game semantic for dealing with the full abstraction problem\nfor PCF originates from Abramsky et al. 2000 and Hyland & Ong\n2000. Hanno Nickau (1994) proposed independently a game model similar\nto that of Hyland and Ong: their games are sometimes called\ncollectively “H2O games”. \nAs a background for game semantics, from intuitionistic logic we have\nthe very early Lorenzen (1961) on dialogue games, then from linear\nlogic Lafont and Streicher (1991) and Blass (1992) and from\nCoquand’s game theoretical analysis of classical provability\n(Coquand 1995). From combinatorial game theory the categorical account\nby Joyal (1977), “the first person to make a category of games\nand winning strategies” according to Abramsky & Jagadeesan\n(1994). A readable historical account of the first uses of games in\nthe interpretation of constructive logical formalisms, especially\nlinear logic, is included in Abramsky & Jagadeesan 1994. It should\nbe observed that games for logic require winning strategies in order\nto capture validity, an issue that we have not dealt with at all in\nthis entry. \nConnections with concrete data structures were first noticed by\nLamarche (1992) and Curien (1994), see Curien 2003b. Antonio\nBucciarelli (1994) explains the connections between Kleene’s\nunimonotone functions and concrete data structures: the use of\ndialogues in the former is mentioned in Hyland & Ong 2000 (sec.\n1.4). \nFinally, among the introductions to game semantics for PCF and other\nlanguages, we suggest Abramsky 1997; Abramsky & McCusker 1999. The\nlatter also contains a description of the applications of game\nsemantics to imperative languages, notably Idealized Algol. Other\nexcellent introductions to game semantics are Hyland 1997 and Curien\n2006. A broad account of the use of games in the semantics of\nprogramming languages with many pointers to Lorenzen games, and\nintended for a philosophical audience, is Jürjens 2002.","contact.mail":"felice.cardone@unito.it","contact.domain":"unito.it"}]
