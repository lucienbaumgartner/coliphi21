[{"date.published":"2016-06-06","url":"https://plato.stanford.edu/entries/medicine/","author1":"Julian Reiss","author1.info":"http://jreiss.org/","author2.info":"http://researchers.adelaide.edu.au/profile/rachel.ankeny","entry":"medicine","body.text":"\n\n\nPhilosophy of medicine is a field that seeks to explore fundamental\nissues in theory, research, and practice within the health sciences,\nparticularly metaphysical and epistemological topics. Its historic\nroots arguably date back to ancient times, to the Hippocratic corpus\namong other sources, and there have been extended scholarly\ndiscussions on key concepts in the philosophy of medicine since at\nleast the 1800s. Debates have occurred in the past over whether there\nis a distinct field rightly termed “philosophy of\nmedicine” (e.g., Caplan 1992) but as there are now dedicated\njournals and professional organizations, a relatively well-established\ncanon of scholarly literature, and distinctive questions and problems,\nit is defensible to claim that philosophy of medicine has now\nestablished itself. Although ethics and values are part of many\nproblems addressed within the philosophy of medicine, bioethics is\ngenerally considered to be a distinct field, and hence is not explored\nin this entry (but see the entry on \n theory and bioethics).  \nThat being said, philosophy of medicine serves as a foundation for\nmany debates within bioethics, given that it analyzes fundamental\ncomponents of the practice of medicine that frequently arise in\nbioethics such as concepts of disease. The philosophy of medicine also\nhas made important contributions to general philosophy of science, and\nparticularly to understandings of explanation, causation, and\nexperimentation as well as debates over applications of scientific\nknowledge. Finally, the philosophy of medicine has contributed to\ndiscussions on methods and goals within both research and practice in\nthe medical and health sciences. This entry focuses primarily on\nphilosophy of medicine in the Western tradition, although there are\ngrowing literatures on philosophy of non-Western and alternative\nmedical practices. It emphasizes philosophical literature while\nutilizing relevant scholarly publications from other disciplinary\nperspectives.\n\n\nOne of the fundamental and most long-standing debates in the\nphilosophy of medicine relates to the basic concepts of health and\ndisease (see\n concepts of health and disease).\n It may seem obvious what we mean by such statements: people seek\ntreatment from medical professionals when they are feeling unwell, and\nclinicians treat patients in order to help them restore or maintain\ntheir health. But people seek advice and assistance from medical\nprofessionals for other reasons, such as pregnancy which cannot be\nconstrued as a disease state, and high blood pressure which is\nasymptomatic. Thus the dividing line between disease and health is\nnotoriously vague, due in part to the wide range of variations present\nin the human population and to debates over whether many concepts of\ndisease are socially constructed. One of the further complicating\nfactors is that both the concepts of health and disease typically\ninvolve both descriptive and evaluatory aspects (Engelhardt 1975),\nboth in common usage among lay persons and members of the medical\nprofession. \nExploring these distinctions remains epistemologically and morally\nimportant as these definitions influence when and where people seek\nmedical treatment, and whether society regards them as\n“ill”, including in some health systems whether they are\npermitted to receive treatment. As Tristram Engelhardt has argued,\n \nthe concept of disease acts not only to describe and explain, but also\nto enjoin to action. It indicates a state of affairs as undesirable\nand to be overcome. (1975: 127)  \nHence how we define disease, health, and related concepts is not a\nmatter of mere philosophical or theoretical interest, but critical for\nethical reasons, particularly to make certain that medicine\ncontributes to people’s well-being, and for social reasons, as\none’s well-being is critically related to whether one can live a\ngood life. \nThe terms “disease” and “illness” often are\nused interchangeably, particularly by the general public but also by\nmedical professionals. “Disease” is generally held to\nrefer to any condition that literally causes “dis-ease” or\n“lack of ease” in an area of the body or the body as a\nwhole. Such a condition can be caused by internal dysfunctions such as\nautoimmune diseases, by external factors such as infectious or\nenvironmentally-induced diseases, or by a combination of these factors\nas is the case with many so-called “genetic” diseases (on\nthe idea of genetic disease and associated problems, see for instance\nHesslow 1984, Ankeny 2002, Juengst 2004). It has been argued that\nthere is no philosophically or scientifically compelling distinction\nbetween diseases and other types of complaints that many would not\nconsider to be diseases such as small stature, obesity, or migraine\nheadaches (Reznek 1987). The notion of “disease” is common\namong most cultures, and may even be a universal concept (Fabrega\n1979). It is a useful concept as it allows a clear focus on problems\nthat afflict particular human beings and suggests that medicine can\nhelp to control or ameliorate such problems. In contrast,\n“illness” is usually used to describe the more\nnon-objective features of a condition, such as subjective feelings of\npain and discomfort. It often refers to behavioral changes which are\njudged as undesirable and unwanted within a particular culture, and\nhence lead members of that culture to seek help, often from\nprofessionals identified as health providers of some type within that\nculture (on some of the complexities relating to the triad of concepts\n“disease, illness, sickness”, see Hofmann 2002). \nThe term “sickness” emphasizes the more social aspects of\nill health, and typically highlights the lack of value placed on a\nparticular condition by society. Disease conditions are investigated\nnot only to be understood scientifically, but in hopes of correcting,\npreventing, or caring for the states that are disvalued, or that make\npeople sick. The classic work of the sociologist Talcott Parsons\n(1951) showed how the “sick role” relieves one of certain\nsocial responsibilities (for example, allows one to take time off work\nor to avoid family responsibilities) and also relieves blame for being\nill (though not necessarily from having become ill in the first\nplace). Although there are exceptions and counterexamples to this\nmodel (for example, some chronic diseases), it does fit our generally\naccepted societal notions of what it means to be sick (and healthy),\nand the moral duties and responsibilities that accompany the\ndesignation of someone as sick. \nThe dominant approach in much of the recent philosophical scholarship\non the philosophy of medicine views disease concepts as involving\nempirical judgments about human physiology (Boorse 1975, 1977, 1997;\nScadding 1990; Wachbroit 1994; Thagard 1999; Ereshefsky 2009). These\nso-called “naturalists” (sometimes called\n“objectivists”, for example see Kitcher 1997, or\n“descriptivists”) focus on what is biologically natural\nand normal functioning for all human beings (or more precisely human\nbeings who are members of relevant classes such as those within a\nparticular age group or of the same sex). They argue that medicine\nshould aim to discover and describe the underlying biological criteria\nwhich allow us to define various diseases. Christopher Boorse’s\nrevised account has been the most influential in the literature,\nclaiming that health is the absence of disease, where a disease is an\ninternal state which either impairs normal functional ability or else\na limitation on functional ability caused by the environment (Boorse\n1997). “Normal functioning” is defined in terms of a\nreference class which is a natural class of organisms of uniform\nfunctional design (i.e., within a specific age group and sex), so that\nwhen a process or a part (such as an organ) functions in a normal way,\nit makes a contribution that is statistically typical to the survival\nand reproduction of the individual whose body contains that process or\npart. His definition includes specific reference to the environment so\nas not to rule out environmentally-induced conditions which are so\ncommon as to be statistically normal such as dental caries. \nMany have criticized these approaches (to name just a few, Goosens\n1980; Reznek 1987; Wakefield 1992; Amundson 2000; Cooper 2002), as\nwell as naturalistic accounts of disease more generally. As they have\nnoted, naturalistic accounts do not reflect our typical usage of the\nterms “disease” and “health” because they\nneglect to take into account any values which shape judgments about\nwhether or not someone is healthy. The usual counterexamples proposed\nto naturalism are masturbation, which was widely believed to be a\nserious disease entity in the 18th and 19th\ncenturies (Engelhardt 1974), and homosexuality, which for most of the\n20th century was classified as a disease in the Diagnostic\nand Statistical Manual (DSM) of the American Psychiatric Association.\nThese are counterexamples as their redefinitions as non-disease\nconditions were due not to new biological information about these\nstates of being but changes in society’s moral values.\nNaturalists respond to such arguments by pointing out that\nhomosexuality and masturbation were never diseases in the first place\nbut erroneous classifications, and thus these examples do not affect\nthe validity of the definition of disease favored by them when it is\napplied rigorously. \nA more telling criticism of naturalism is that although its advocates\nclaim to rely exclusively on biological science to generate their\ndefinitions of health and disease, these rely implicitly on an\nequation of statistical and theoretical normality (or the\n“natural state” of the organism), at least in\nBoorse’s formulation (Ereshefsky 2009). But biology does not\ngive us these norms directly, nor is there anything absolutely\nstandard in “species design” (as many philosophers of\nbiology have argued) despite Boorse’s claims. No particular\ngenes are the “natural” ones for a given population, even\nif we take a subgroup according to age or gender (Sober 1980). Nor\ndoes standard physiology provide these norms (Ereshefsky 2009), not in\nthe least part because physiological accounts typically provide\nidealized and simplified descriptions of organs and their functions,\nbut not of their natural states (Wachbroit 1994). Rachel Cooper (2002)\ncompellingly argues that coming up with an acceptable conception of\nnormal function (and in turn dysfunction) is the major problem with\nBoorsian-style accounts, arguing that his analysis should focus on\ndisposition to malfunction instead. This argument utilizes\ncounterexamples such as activities that interfere with normal\nfunctioning such as taking contraceptive pills that are not diseases,\nas well as examples of persons with chronic diseases controlled by\ndrugs who function normally as a result. Elselijn Kingma (2007, 2010)\nhas critiqued Boorse’s appeal to reference classes as\nobjectively discoverable, arguing that these cannot be established\nwithout reference to normative judgments. A further issue often noted\nwith regard to naturalistic accounts of disease (for example, that of\nLennox 1995) is the underlying assumption that biological fitness\n(survival and reproduction) is the goal of human life, and along with\nthis that medicine is only considered to be interested in biological\nfitness, rather than other human goals and values, some of which might\nindeed run contrary to or make no difference in terms of the goal of\nbiological fitness, such as relief of pain. \nAn alternative approach in the philosophical literature to\nnaturalist/descriptivist/objectivist definitions of disease and health\ncan roughly be termed “normative” or\n“constructivist”. Most proponents agree that we must\ndefine the terms “disease” and “health”\nexplicitly and that our definitions are a function of our values\n(Margolis 1976; Goosens 1980; Sedgewick 1982; Engelhardt 1986). Hence\ndefining various disease conditions is not merely a matter of\ndiscovering patterns in nature, but requires a series of normative\nvalue judgments and invention of appropriate terms to describe such\nconditions. Conversely, health involves shared judgments about what we\nvalue and what we want to be able to do; disease is a divergence from\nthese social norms. Normativists believe that their definitions are\nvalid not only philosophically but also reflect actual usage of the\nterminology associated with disease and health both in common language\nand among medical professionals. They also claim that this approach\nmore adequately explains how certain conditions can come to be viewed\nin different ways over the course of history as our values changed\ndespite relatively few changes in our underlying biological theories\nabout the condition, for example homosexuality. Further, they are able\nto accommodate examples of so-called folk illnesses or culture-bound\nsyndromes such as ghost sickness among some Native American tribes,\nthe evil eye in many Mediterranean cultures, or susto in\nLatin and South American cultures, as their theories explicitly allow\nfor cross-cultural differences in understandings of disease and\nhealth. \nHowever normativism also generates a series of typical criticisms: it\ncannot cope adequately with cases where there is general agreement\nthat a state is undesirable (such as alcoholism or morbid obesity) but\nno similar general agreement that the state is actually a disease\ncondition (Ershefsky 2009). Another classic objection is that\nnormative accounts do not allow us to make retrospective judgments\nabout the validity of disease categories such as\n“drapetomania” (a disease which was commonly diagnosed\namong American slaves in the 19th century, with the main\nsymptom being the tendency to run away) (Cartwright 1851). The\nnormativist can point to changes in values to explain the abandonment\nof belief in this disease condition, but would not be able to claim\nthat the doctors were in any sense “wrong” to consider\ndrapetomania to be a disease. Hence there is more involved in our\neveryday usage of the terms “disease” and\n“health” than just value or normative conditions. \nHybrid theories of health and disease attempt to overcome the gaps in\nboth the naturalistic and normative approaches, by hybridizing aspects\nof both theories (Reznek 1987; Wakefield 1992; Caplan 1992). For\ninstance Jerome Wakefield (1992, 1996, 2007), writing about\npsychiatric conditions in particular, notes that a condition should be\nconsidered a disease if it both causes harm to the person or otherwise\ncontributes diminished value, and the condition results from some\ninternal mechanism failing to perform its natural function (hence for\ninstance much of what is diagnosed as “depression” would\nfail to count as a disease condition). Whereas the normativist is\ncommitted to calling any undesirable state a disease condition, these\nhybrid criteria rule out calling conditions “diseases”\nwhich are non-biological,. Then various marginal cases might be\nconsidered to be healthy rather than potentially described as\ndiseased, and hence might not be eligible for treatment within\nconventional medicine. Examples include those organs or structures\nthat no longer have a function due to evolutionary processes cannot\nmalfunction and so cannot be diseased. Many hybrid approaches also\nretain too many assumptions about their naturalistic components, and\nhence are criticized for relying on a notion of natural function which\ncannot be supported by biology. \nThe concept of health has been relatively undertheorized in comparison\nto those of disease and illness, perhaps in part because it raises\neven more complicated issues than these concepts describing its\nabsence. One could be a straightforward naturalist about health, and\ndefine it as being a product of a functional biology; however this\nargument would run afoul of the same criticisms of naturalism\nrecounted above (see Hare 1986). The source for the classic definition\nof health comes from the Constitution of the World Health Organization\n(WHO) which defines health  \na state of complete physical, mental and social well-being and not\nmerely the absence of disease or infirmity. (WHO 1948: preamble)  \nNotice that according to this formulation, health is not just the\nabsence of disease but a positive state of well-being and flourishing\n(notoriously ambiguous concepts in themselves). Although quality of\nlife is often cited as critical to definitions and theories of health,\nmany commentators are wary of the expansiveness of a definition\nsimilar to the WHO’s terminology, as it seems to encompass many\nthings beyond the health of the individual which could contribute (or\ndiminish) his or her “well-being”. \nA more narrow definition of health takes its rightful domain as being\nthe state which medicine aims to restore, and its opposite to be\n“unhealth” or falling short of being healthy, rather than\ndisease as such (Kass 1975). Under such a definition, medicine should\nnot engage in aesthetic surgery or elective terminations of pregnancy\nor similar procedures which do not (strictly speaking) seek to restore\nhealth. Caroline Whitbeck (1981) has defined health in terms of the\npsychological and physiological capacities of an individual that allow\nhim or her to pursue a wide range of goals and projects. Hence her\naccount is a type of hybrid approach, since she places biological\ncapacities at the core of her definition of health but only in so far\nas they help individuals to flourish and live their lives as they wish\nto do. The concept of health here is much more than the absence of\ndisease; for instance, one could have a high level of health while\nstill suffering from a particular disease condition. \nOne much discussed philosophical approach to defining health is that\nof Georges Canguilhem (1991, based on work in the early 1940s), who\nargued against equating it with normality. He noted that the concept\nof a norm could not be defined objectively in a manner that could be\ndetermined using scientific methods. Physiology deals with the science\nof norms, but even scientifically-based medical approaches should not\nfocus solely on norms, contrary to for instance the ideal vision of\nmedicine according to Claude Bernard (1865). The history of how the\ndistinction between the normal and pathological became so entrenched\nis explored in detail in Michel Foucault’s now classic work\n(1963). Both Foucault and Canguilhem sought to reveal how values have\nbeen built into the epistemological framework underlying modern\nmedicine. \nOne of the key points in Canguilhem’s argument is that our usage\nof the term “normal” often conflates two distinct\nmeanings: the usual or typical, and that which is as it ought to be.\nConsequently, he argues that there can be no purely scientific or\nobjective definition of the normal that allows us to take the theories\nof physiology and apply them in medical practice, and accordingly we\ncannot define health as normality either. Instead, according to him,\nhealth is that which confers a survival value, particularly\nadaptability within a set of environmental conditions: “to be in\ngood health is being able to fall sick and recover; it is a biological\nluxury” (1991: 199).\nDisease, then, is reduction in the levels of tolerance for the\nvagaries of the environment. As Mary Tiles (1993) has noted, this\nemphasis on health rather than normality is a particularly useful tool\nfor enriching contemporary debates over preventative medicine and more\ngenerally the trend toward the development of a positive conception of\nhealth. Havi Carel (2007, 2008) has contributed to this strand of\nthought, developing a phenomenological notion of health which\nemphasizes that health should be understood as the lived experience of\none's own body rather than as simply statistically normal bodily\nfunctioning in abstract biological terms. Hence she develops an\nexpressly revisionist project, emphasizing that a phenomenological\nperspective accommodates cases where someone is ill (in biological\nterms) but healthy, such as in chronic illness. \nA number of authors have made even more extreme claims, arguing that\nseeking concepts of disease is bound to be a failed effort. For\ninstance, Peter Schwartz (2007) claims that there is not an underlying\ngeneral concept of disease within the biomedical sciences that is\ncoherent enough to be analyzed, and that different concepts of disease\nmight be useful within different contexts. Some philosophers have\nargued that to seek correct definitions for “disease” and\n“health” is distracting and irrelevant when it comes to\nclinical decisions: as Germund Hesslow puts it, “the\nhealth/disease distinction is irrelevant for most decisions and\nrepresents a conceptual straightjacket [sic]” (1993: 1). The key is whether or not a\nparticular state is desirable to its bearer, and not whether the\nperson actually has a disease or defect. For instance, the term\n“malady” has been proposed as a more appropriate\nalternative to “disease” (Clouser, Culver, and Gert 1981),\nand which should be extended to include all illnesses, injuries,\nhandicaps, dysfunctions, and even asymptomatic conditions. A malady is\npresent when there is something wrong with a person; regardless of the\ncause (mental or physical), to be a malady, the condition must be part\nof its bearer and not distinct or external to him or her. The clear\nadvantage of this approach is that it unifies a range of phenomena and\ndescriptions that seem intuitively to be related. The disadvantages\ninclude that it relies in part on an objectivist approach to disease,\nand hence suffers from some of the difficulties detailed above that\nplague some versions of naturalism (for a provocative reaction to this\ndebate, see Worrall and Worrall 2001). \nAn alternative approach to defining disease and health has been\ndescribed by Marc Ereshefsky (2009) in terms of making distinct state\ndescriptions (descriptions of physiological or psychological states\nwhile avoiding any claims about naturalness, functionality, or\nnormality), and normative claims (explicit judgments about whether we\nvalue or disvalue a particular physiological or psychological state).\nThis approach has the advantages of allowing more clarity about\ncontroversial “disease” conditions as it avoids the need\nto apply the term explicitly. It also forces us to pinpoint the key\nissues that matter to understanding and treating someone suffering\nfrom ill health. But perhaps most persuasively, he argues that this\napproach allows us to distinguish the current state of a human from\nthose we wish to promote or diminish, whereas the terms\n“disease” and “health” do not adequately\nhighlight this critical distinction. \nIn short, philosophers of medicine continue to debate a range of\naccounts: in broad outline, the most vigorous disagreement centers on\nwhether more objective, biologically-based, and generalizable accounts\nare preferable to those that incorporate social and experiential\nperspectives. It is clear that none satisfy all of the desiderata of a\ncomplete and robust philosophical account that also can be useful for\npractitioners; although some would dispute whether the latter should\nbe a requirement, many believe that philosophy of medicine should be\nresponsive to and helpful for actual clinical practices. \nSome disease categories are far from straightforward in terms of being\nrecognized, named, classified, and made legitimate both within\nmedicine itself and for the wider society. In recent times there have\nbeen long-standing debates over a range of conditions including Lyme\ndisease, fibromyalgia, and chronic fatigue syndrome (CFS), to name\njust a few (for extended historical discussions of these and related\nconditions, see Aronowitz 1998, 2001; Shorter 2008). Take CFS as an\nexample: its main symptoms are fatigue after exertion over a period\nlasting at least six months, but sufferers can have a wide array of\ncomplaints in diverse systems of the body; the range of severity is as\nwide as the range of symptoms. The condition has been associated with\nseveral other controversial syndromes and sometimes equated to with\nthem, most notably myalgic encephalitis and fibromyalgia, as well as\nother illnesses of inexact definition such as multiple chemical\nsensitivity and irritable bowel syndrome; more popular (and\nderogatory) labels also have been attached to it such as yuppie flu.\nDefinitive evidence as to the cause or basis of CFS has remained\nelusive, and in the absence of causal explanations, accurate diagnoses\nand effective treatments often have been difficult to obtain. Thus the\nillness has been perceived by many as being illegitimate because of\ndifficulties in proving the existence of a discrete disease condition,\ngiven the lack of traditional forms of clinical evidence for it, and\nit has had different statuses in different locales (see Ankeny and\nMackenzie 2016). These issues severely impact on the lives of those\naffected by this condition, and on the care that is thought to be\nappropriate to be made available to them. \nMental illnesses (and the term “mental health” itself)\nalso have traditionally posed considerable problems for categorization\nand conceptualization for both medical practitioners and philosophers\nof medicine. Many authors advocate the case that it is critical to\nmake a distinction between mental and physical illness (Macklin 1972),\nparticularly because of the moral implications associated with\nlabeling a condition as mental or psychological. Psychiatry is a field\nwhich has historically been loaded with value judgments, many of which\nwere quite dubious. There is a long history of using mental illness as\na way to categorize behaviors which are socially deviant as well as\nthose conditions of ill health with no apparent organic cause and\nwhich do not otherwise fit into our dominant biomedical model. Many\nscholars (e.g., Ritchie 1989; Gaines 1992; Mezzich et al. 1996;\nHorwitz and Wakefield 2007; Demazeux and Singy 2015) have critiqued\napproaches and the underlying assumptions of the various editions of\nthe Diagnostic and Statistical Manual published by the American\nPsychiatric Association, which is a “bible” for\npsychiatric conditions for many practitioners and also has\nconsiderable public influence for instance on who can seek care. Key\nexamples of contested issues within the DSM include the highly\npoliticized nature of the processes of revision across various\neditions, various cultural, sexist, and gender biases inherent in\nspecific diagnostic categories, and the relatively weak reliability\nand validity of the classification system. \nOne key question is whether the biomedical model is the most\nappropriate approach to psychological or mental conditions and their\ntreatment. Some theorists have argued in favor of naturalistic\naccounts of disease, notably Thomas Szasz (1961, 1973, 1987). As a\nresult, he famously claimed that “mental diseases” are a\nmyth and do not exist because they do not result from tissue damage;\nin his view, all diseases must be correlated with this sort of\nphysical damage. He thus argues that the concept of mental illness is\na prescriptive concept used as though it were a merely descriptive\none, and also a justificatory concept masquerading as an explanatory\none. These conclusions lead him to a highly critical analysis of\npsychiatric practices, and to reclassifying such forms of suffering as\n“problems in living” rather than diseases. However it is\nnot always clear in his account what his evidence for these claims is,\nand in particular whether he is making an in principle objection or\none that is grounded in the history of the mistreatment of people with\nmental illnesses, and the disservice done to them in part because of\nthe adoption of the medical model. In addition, some have noted that\nsome psychiatric conditions do in fact correlate with physiologically\ndetectable and other types of biological abnormalities. For instance\ntwin studies have demonstrated that genetics is a major factor in the\netiology of schizophrenia among other conditions typically considered\nto be psychiatric, although clearly not all conditions that are\ndiagnosable according to contemporary psychiatric standards fit this\nmodel. \nA prominent functionalist approach to mental disorders more recently\nhas been that of Wakefield (1992, 1996, 2007), as discussed above, who\nargues that mental disorders are best understood as\n“harmful” dysfunctions, which permits a supposedly\nvalue-free foundation in terms of biological function gauged in\nevolutionary terms) with judgments coming in only in terms of the\njudgment of whether certain dysfunctions are harmful to their bearers.\nSuch accounts have been criticized along lines similar to analyses of\nBoorsian accounts by emphasizing that function and dysfunction cannot\nin fact be defined independently of value terms, but Wakefield’s\naccount also has been questioned in terms of its practical\nimplications (e.g., Sadler and Agich 1995) and whether malfunction is\na necessary component of mental disorder (Murphy and Woolfolk\n2000). \nOther authors, notably George Engel (1977), have argued for the need\nto unify our understandings of mental and physical illness under a\nbroader, biopsychosocial model. Such a model would focus clinicians to\ntake account of both the physical, psychological, and social factors\nthat contribute to ill health, in contrast to the traditional\nbiomedical model which is faulted for being overly reductionistic\nrather than holistic. Such an account, it is claimed, would be more\neffective in dealing with borderline cases including people who are\ntold they are in need of treatment due to abnormal lab results or\nsimilar but who are feeling well, as well as those who appear to have\nno underlying somatic disease condition but are feeling unwell. Hence\nthis type of account does not draw any sharp distinction between the\nphysical and the mental (or even the social), leaving the question of\nappropriate therapies or approaches as a matter to be decided by the\ndoctor and his or her patient. Engel compellingly defended this type\nof account as more appropriate not only for clinical work but for\nresearch and teaching in medicine. It is arguable that it has\nimplicitly (and often explicitly) been adopted in much of current-day\nmedical practice and teaching, although it is less clear whether it\nhas had much influence in biomedical research, much of which tends to\nremain more reductionistic in its nature. \nThere is no widely accepted notion of what a scientific theory is. The\nlogical positivists thought that theories are sets of\npropositions, formalizable in first-order logic, at one point, and as\nclasses of set-theoretic models at another. For our purposes here one\ncan distinguish two senses of theory, a narrower and a broader sense.\nIn the narrower sense, a theory comprises a set of symbols and\nconcepts used to represent the entities in a domain of discourse as\nwell as a set of simple general-purpose principles that describe the\nbehavior of these entities in abstract terms. In the broader sense,\ntheory refers to any statement or set of statements used to explain\nthe phenomena of a given domain. \nIn medicine one can find theories in both the narrower and the broader\nsense. Humorism, for instance, holds that the human body is filled\nwith four basic substances or “humors”: black bile, yellow\nbile, phlegm, and blood. The humors are in balance in a healthy\nperson; diseases are explained by excesses or deficiencies in one or\nmore humors. Humorism has ancient origins and influenced Western\nmedicine well into the 18th century. Eastern medicine has analogous\nsystems of thought. Indian Ayurveda medicine, for example, is a theory\nof the three primary humors wind, bile, and phlegm, and diseases are\nsimilarly understood as imbalances in humors (Magner 2002). \nIn contemporary Western medicine, such highly unifying and general\ntheories play a limited role, however. Evolutionary and Darwinian medicine may\nwell constitute exceptions but these are at best emergent fields at\npresent (see Méthot 2011). Contemporary Western medical\nresearchers and practitioners instead seek to explain medical outcomes\nusing mechanistic hypotheses about their causes—symptoms by\nhypotheses about diseases, diseases by hypotheses about antecedents,\nepidemics by hypotheses about changes in environmental or behavioral\nconditions (Thagard 2006). What distinguishes these contemporary\nmedical theories from the ancient approaches is that the causes of\nsymptoms, diseases, and epidemics can in principle be as multifarious\nas the outcomes themselves; in the ancient approaches, lack of humoral\nbalance was the only possible cause. In contemporary Western medicine, \nthere is no presupposition concerning number, form, or mode of action \nof the causes that explain the outcome other than there being \nsome cause or set of causes responsible. \nNot every cause is equally explanatory. A given person’s death\ncan be described as one by cardiac arrest, pulmonary embolism or lung\ncancer, for instance. The lung cancer may have had a genetic mutation,\nthe deposition of carcinogens in lung tissue and smoking in its causal\nhistory. The smoking, in turn, was caused by the smoker’s\nproneness to addictive behavior, peer pressure and socio-economic\nenvironment, let us suppose. Which of the many candidate hypotheses of\nthe form “X causes (or caused) Y”, where\nY refers to the patient’s death, does best explain the\noutcome? There is no absolute answer to this question. The goodness of\na medical explanation depends in part on the context in which it is\ngiven (see entry on\n scientific explanation).\n When asked “Why did Y happen?” a coroner might\nrefer to the pulmonary embolism, the patient’s physician to the\nlung cancer and an epidemiologist to the patient’s tobacco\nconsumption. The adequacy of a medical explanation is related to our\nability to intervene on the factor in question. A pulmonary embolism\ncan be prevented by screening the patient for blood clots. The\naccumulation of carcinogens in lung tissue can be prevented by\nstopping smoking. By contrast, even though certain kinds of genetic\nmutations are in the causal history of any cancer, the mutation is not\nat present of much explanatory interest to most clinicians, as this is\nnot a factor on which they can easily intervene. There is considerable\ncurrent medical research to identify mutations associated with various\nsubtypes of cancer and using these to develop targeted therapies and\ninterventions, as well as to provide more accurate prognostic\ninformation. Medical explanation, thus, is closely related to our instrumental \ninterests in controlling, preventing and controlling outcomes (Whitbeck 1977). \nOne issue that is currently debated in the philosophy of medicine is\nthe desirability (or lack thereof) of citing information about the\nmechanisms responsible for a medical outcome to explain this outcome.\nWhile mechanisms are usually characterized in causal terms (e.g.,\nGlennan 2002; Woodward 2002; Steel 2008), it is not the case that\nevery cause acts through or is a part of some mechanism, which is\nunderstood as a more or less complex arrangement of causal factors\nthat are productive of change (e.g., Machamer et al. 2000). Absences,\nsuch as lack of sunlight, can cause medical outcomes but are not\nrelated to them through continuous mechanisms from cause to effect\n(Reiss 2012). Neuroscientific explanations are often acceptable\ndespite the lack of knowledge or false assumptions about mechanisms\n(Weber 2008). However, we may ask whether mechanistic explanations are \ngenerally preferable to non-mechanistic causal explanations. \nMany medical researchers and philosophers of medicine subscribe to a\nreductionist paradigm, according to which bottom-up explanations that\nfocus on the generative physiological mechanisms for medical outcomes\nare the only acceptable ones or at least always preferable. Indeed,\nmacro-level claims such as “Smoking causes lung cancer”\nseem to raise more questions than they answer: Why does smoking have\nadverse health consequences? To prevent these consequences, is it\nnecessary to stop smoking? Is it possible to produce cigarettes the\nsmoking of which has fewer or no adverse consequences? What is the\nbest policy to improve morbidity and mortality from lung cancer?\nKnowing that it is specific carcinogens in tobacco smoke and genetic\nsusceptibility that are jointly responsible for the onset of the\ndisease helps to address many of these questions. \nNevertheless it would be wrong to assume that we cannot explain\noutcomes without full knowledge of the mechanisms responsible. When,\nin the mid-1950s, smoking was established as a cause of lung cancer,\nit was certainly possible to explain lung cancer epidemics in many\ncountries where people had exchanged pipe smoking for cigarette\nsmoking half a century earlier—even though the mechanism of\naction was not understood at the time. Differences in lung cancer\nincidence between men and women or between different countries can be\nexplained with reference to different smoking behaviors. Policy\ninterventions, in this case the addition of warning labels to\ncigarette packets, could not wait until sufficient mechanistic\nknowledge was available, nor did they have to wait. \nFor reasons such as these, a number of philosophers of medicine have\nproposed to adopt an “explanatory pluralism” for medicine\n(De Vreese et al. 2010; Campaner 2012). If nothing else, this is\ncertainly a position that is consistent with the explanatory practices\nin the field. \nAs in many fields, debates over reductionism versus holism are rife in\nmedicine both with reference to medical research and practice, and the\nterms often are used rather loosely to mean a range of things (for a\nrelated discussion see entry on\n  reductionism in biology).\n In the broadest terms, reductionistic approaches to disease look for\nfundamental mechanisms or processes that are the underlying causes of\nthat disease. In recent years in light of large-scale genomic\nsequencing initiatives notably the Human Genome Project, there has\nbeen considerable emphasis on reducing diseases to the genetic or\nmolecular level. Those who advocate more holistic approaches note that\nreductionism leaves out important information based on the\npatient’s experiences of the disease at the phenotypic level,\nand such information is critical to pursuit of effective treatments.\nMany diseases typically viewed as “genetic” have proven to\nbe extremely difficult in practice to reduce to unified disease\nentities with singular (or simple) genetic causes, including mental\nillnesses (Harris and Schaffner 1992), cystic fibrosis (Ankeny 2002),\nand Alzheimer’s disease (Dekkers and Rikkert 2008). As Catherine\nDekeuwer (2015) notes, given that there probably is genetic variation\nin susceptibility to virtually all diseases, there is no clear\ndemarcation between genetic diseases and diseases for which there are\ngenetic risk factors; hence she argues that our tendency to focus on\ngenetic determinants of disease may reinforce folk notions of the\ngeneticization of both people and of human behavior. \nWith regard to research, critics of reductionism point out that there\nhas been an overemphasis on the pursuit of genetic or molecular level\nexplanations of disease to the neglect of alternative levels of\nexplanation. Further, such limitations are highly detrimental to\npatients, especially because there are not likely to be short-term\ncures or treatments for most genetic diseases, perhaps beyond avoiding\nhaving children carrying particular genes in the first instance (see for instance \nHubbard and Wald 1999), although this domain of medicine is\nrapidly changing as new treatments are developed and the\nunderstandings of the effects of genomic mutations improve. Focusing\noverly or solely on the genetic level results in a process which the\nsociologist Abby Lippmann (1991) terms “geneticization”,\nnamely reducing the differences between individuals to their DNA, and\nin turn viewing genetics as the most promising approach to curing\ndisease, rather than viewing people and the illnesses that they suffer\nat a phenotypic and much more environmentally-situated level. In\naddition, as Elisabeth Lloyd (2002) argues, higher levels of social\norganization that are culturally sanctioned have unrecognized causal\neffects on health, and hence medical research should not be restricted\nsolely to the molecular level. \nFred Gifford (1990) claims that although all phenotypic traits are the result of an\ninteraction between genes and the environment within which they are\nexpressed, nonetheless it makes sense to distinguish certain traits as\n“genetic”; he argues in terms of populations that if it is\ngenetic differences that make the differences in that trait variable\nin a given population, and if genetic traits can be individuated in a\nway that matches what some genetic factors cause specifically, then a\ntrait (including a disease trait) can be understood as genetic. Kelly\nSmith (1992) disputes this, noting that the second condition depends\non an extremely problematic distinction between causes (in this case\ngenes) and mere conditions (e.g., epigenetic factors). Lisa Gannett\n(1999) argues for a “pragmatic” account of genetic\nexplanation, claiming that when a disease is classed as\n“genetic”, the reasons for singling out genes as causes\nover other conditions necessarily include pragmatic dimensions\ninasmuch as they are relative to a given causal background (which\nincludes both genetic and nongenetic factors), relative to a\npopulation, and relative to our present state of knowledge. More\nrecently it has been argued that although explanatory reduction cannot\nbe defended on metaphysical grounds, reductive explanations might be\nindispensable ways to address certain questions in the most accurate,\nadequate, and efficient ways (van Bouwel et al. 2011). \n“Evidence-based medicine” (EBM) describes a movement that\nwas started (under that name) in the early 1990s by a group of\nepidemiologists at McMaster University in Hamilton, Canada, as a\nreaction against what was perceived as an over-reliance on clinical\njudgment and experience in making treatment decisions for patients.\nAccording to a widely cited definition:  \nEvidence based medicine is the conscientious, explicit, and judicious\nuse of current best evidence in making decisions about the care of\nindividual patients. (Sackett et al. 1996: 312)  \nSuch a definition has bite only when the concept of evidence used is\nrelatively narrow. In particular, it should not allow clinical\njudgment and experience to count as “best evidence”. \nTo this effect, proponents of EBM have developed so-called\n“hierarchies of evidence” that categorize different\nresearch methods with respect to their supposed quality. While there\nis no universally accepted hierarchy, the different proposed\nhierarchies all agree in the priority they give to randomized\ncontrolled trials (RCTs) and reviews thereof. A typical hierarchy\nlooks as follows (Weightman et al. 2005): \nEvidence produced by RCTs has thus been called the “gold\nstandard” of evidence in EBM (e.g., by Timmermans and Berg\n2003). \nIn an RCT, a population of individuals who might benefit from a new\nmedical treatment are divided into a treatment group—the group\nwhose members receive the new treatment—and one or several\ncontrol groups—groups whose members receive either an\nalternative or “standard” treatment or a\nplacebo.  Individual patients are assigned to a group by means of a random process such as the flip of a coin. A placebo is an intervention that resembles the new treatment in\nall respects except that it has no known ingredients active for the\ncondition under investigation (i.e., it is some kind of “sugar\npill”). Patients, researchers, nurses, and analysts are all\nblinded with respect to treatment status of all patients until after\nthe analysis. After a period of time, a pre-determined outcome\nvariable is observed and the values of the variable are compared\nbetween the groups. If the value of the outcome variable differs\nbetween different treatment groups at the desired level of statistical\nsignificance, the treatment is judged to be effective. \nProponents of EBM regard RCTs as reliable means to judge treatment\nefficacy because they can help to control for a variety of (though not\nall) biases and confounders. If, for instance, the symptoms of a\npatient or group of patients improve after an intervention, this may\nbe due to spontaneous remission rather than the treatment. An\nexperimental design that compares a treatment group with one or\nseveral control groups is therefore better able to control for this\nconfounder than a simple “before-and-after” design.\nSimilarly, a design in which the allocation to treatment and control\ngroups is done by a non-random process, it is possible that healthier\npatients end up in the treatment and less healthy patients in the\ncontrol group. If so, the measured improvement may be due to the\nhealth status of the patients rather than the intervention. Especially\nif the allocation is done by a medical researcher who has a stake in\nthe matter (for instance because she has developed the new treatment),\nallocation decisions may consciously or subconsciously be influenced\nby expectations about who will profit from the intervention and thus\ncreate unbalanced groups. Allocation by a random process helps to\ncontrol this source of bias. \nNo one denies that RCTs are powerful experimental designs—and\nthat their power stems from the ability to control numerous sources of\nbias and confounding. However, to refer to RCTs as the “gold\nstandard” of evidence suggests that they are more. Specifically,\none may be led to assume that RCTs are necessary for reliable causal\ninference or that RCTs are guaranteed to deliver reliable results. A\nnumber of philosophers of medicine have in the past decade or so\nargued that these stronger claims do not hold to scrutiny. \nIn particular, the following claims have been criticized: \nA final but very important issue is that of the external validity of\nthe RCT results. Even under ideal conditions (i.e., when medical\nresearchers have very strong reasons to presume the assumptions under\nwhich an RCT works to be satisfied), the RCT can only establish that\nthe treatment is effective in the test population. Typical\ntest populations differ from the target populations (i.e., those\npopulations for whom the treatment has been developed and who will\neventually receive the treatment) in more or less systematic ways. For\nexample, many RCTs will exclude elderly patients or patients with\nco-morbidities but the treatment will be marketed to these patients.\nFor financial reasons, many RCTs are nowadays conducted in developing\ncountries whereas the treatments are mainly or exclusively marketed to\npatients in developed countries. Whereas the protocols for conducting\nan RCT are very strict and detailed, there are no good guidelines how\nto make treatment decisions when the patient at hand belongs to a\npopulation that differs from the population in which the RCT was\nconducted (e.g., Cartwright 2011). \nThere are in fact two problems of external validity in the application\nof RCT results. On the one hand there is the population-level problem\nof making an inference from test to target\npopulation. On the other hand, there is the problem of making an\ninference from population to individual. The RCT\nprovides evidence for a population-level claim: “In population\np (the test population) intervention X is effective\nin the treatment of condition Y”.  For this claim to be\ntrue, the treatment must be on average effective, which allows the\neffectiveness to vary among the individuals in the population. Indeed,\nit is possible that the intervention is effective (and beneficial) on\naverage but ineffective or positively harmful in some individuals\n(i.e., members of some subpopulations). Proponents of EBM to some\nextent oversell their case when they write that EBM  \nde-emphasizes intuition, unsystematic clinical experience, and\npathophysiologic rationale… and [instead] stresses the\nexamination of evidence from clinical research. (Evidence-Based Medicine Working Group 1992)\n \nbecause inferences from test to target population and from any\npopulation to the individual receiving the treatment are necessarily\nbased on clinical judgment. \nJohn Worrall argues that, at the end of the day, RCTs are a powerful\nmeans to control selection bias, but no more than that (Worrall 2002,\n2007a,b). As he uses the term, selection bias occurs when treatment\nand control group are unbalanced with respect to some prognostic\nfactors because a medical researcher has selected which patients will\nreceive which treatment. Selection bias in this sense obviously cannot\noccur in an RCT because in an RCT the allocation is made by a random\nprocess. But it is also clear that randomization is at best sufficient\nbut not necessary to achieve the result. A large number of alternative\ndesigns may be used to the same effect: allocation can be made by a\nstrict, albeit non-random protocol; allocation is made by non-experts\nwho are unrelated to the treatment development and therefore have no\nexpectations concerning outcomes; treatment and control groups are\ndeliberately matched (again by persons who have nothing at stake or\naccording to some protocol); and so on. \nA controversial issue is the role of mechanistic knowledge, that is,\nknowledge about the biological and physiological mechanisms\nresponsible for medical outcomes (and thus treatment efficacy) should\nplay in EBM. As mentioned above, the RCT provides evidence for\nblack-box causal claims of the form “In population p,\nintervention X is effective in the treatment of condition\nY”. As we have seen, proponents of EBM also believe EBM\nto de-emphasize patho-physiologic rationale (a different term for\n“mechanistic knowledge”). Nevertheless, a number of\nphilosophers of medicine have pointed out that mechanistic knowledge\nis in fact important in EBM or that it should receive more attention.\nFederica Russo and Jon Williamson have, for instance, argued that\ncausal claims need both statistical evidence as well as evidence about\nthe mechanisms that connect an intervention with the outcome variable\nin order to be established (Russo and Williamson 2007). Others\ndisagree (Reiss 2012) or qualify the claim (Gillies 2011; Howick\n2011a; Illari 2011). Further, it has been pointed out that mechanistic\nknowledge plays an important role in the design and preparation of an\nRCT, as well as in the interpretation and application of RCT results\n(La Caze 2011; Solomon 2015). Especially when it comes to\nextrapolating research results from a test to another population,\nmechanistic knowledge is supposed to be vital (Steel 2008; see also\nnext section). On the other hand, knowledge about mechanisms is often\nhighly problematic and should not be relied on too heavily in\napplications (Andersen 2012). \nNew therapies are often trialed using animal models before they are\ntested on humans in a randomized trial. Animal models also play\nimportant roles in establishing whether or not a substance is toxic\nfor humans. The International Agency for Research on Cancer (IARC),\nfor example, classifies substances with respect to the quality of the\nevidence for their carcinogenicity into five groups. Evidence from\nanimal models is referred to in the characterization of each group\n(IARC 2006). This raises questions about how such extrapolations from\nanimal models to humans work, and how reliable they are. \nAnimal models are widely used in biomedical research because\nexperimental interventions on animals are easier to conduct and\ncheaper than experiments on humans. Both kinds of experiments involve\nethical dilemmas, but animal experimentation is usually regarded as\nless problematic from an ethical point of view than experimentation\nwith humans. At any rate, the number of animals killed, maimed, or\nmade sick in biomedical research is much higher than the number of\nhumans adversely affected in this research. \nThere is a fundamental inferential problem in transferring what has\nbeen learned in any model (whether human, animal, or whatever) to some\ntarget population of interest has been described as the\n“experimenter’s circle[special-character:rdquo (Steel 2008). The problem is essentially this. What is true of a model \ncan be presumed to be true\nof the target only to the extent that the model is similar to the target\nin relevant respects. The reason we experiment on models in the first\nplace is, however, that the model differs in important respects from\nthe target (if animals were just like humans, we would not find\nexperiments on the former to be ethically less problematic than\nexperiments on the latter). Extrapolation—the inference from\nmodel to target—is therefore only worthwhile to the extent that\nthere are significant limitations in our ability to study the target\ndirectly. If so, there can be no good grounds to decide whether a\nmodel is a good one for the target. To do so, we would have to\ninvestigate whether the target is relevantly similar to the model; but\nif we could do so, there would be no reason to study the model in the\nfirst place. \nThis inferential problem has led some commentators to maintain highly\nskeptical views concerning our ability to use animals as models for\nhumans in biomedical research. Hugh LaFollette and Niall Shanks argue\nthat animal models cannot be reliably used for extrapolation at all,\nbut at best only heuristically, as sources of hypotheses that have to\nbe tested on humans (LaFollette and Shanks 1997). They introduce two\nterms to make their argument: causal analogue model (CAM) and\nhypothetical analogue model (HAM). The former can be used to make\nreliable predictions about target populations of interest; the latter\nonly heuristically. The main premise in their argument that animal\nmodels in biomedical research are at best HAMs but not CAMs is that\nfor a model to be a CAM there cannot be causally relevant disanalogies\nbetween model and target—a condition which is rarely if ever met\nby animal models (again, this is why we study animals in the\nlaboratory in the first place). \nDaniel Steel (2008: ch. 5) argues that LaFollette and Shanks’\ncondition for reliable extrapolation is too stringent. Whether a claim\nabout a model can be extrapolated depends, he argues, also on the\nstrength of the claim to be exported. It is one thing, say, to reason\nfrom  \nx% of the members of population p will show symptoms\nof poisoning after ingesting substance S  \nto  \nx% of the members of population \\(q \\ne p\\) will show\nsymptoms of poisoning after ingesting substance S,  \nquite another to reason from the quantitative claim to a qualitative\nclaim such as “Substance S is poisonous for the members\nof q”. \nSteel’s own reconstruction of how extrapolation works in the\nbiomedical sciences is called comparative process tracing. He\nassumes that causes C (such as medical interventions or the\ningestion of toxic substances) bring about their effects E\n(such as the appearance of symptoms or improvements or deteriorations\nof symptoms) through a series of steps or stages. To trace a causal\nprocess means to investigate through what set of stages C\nbrings about E. Process tracing is comparative when the set\nof stages through which C brings about E in one\nspecies or population is compared to the set through which it does so\n(if it does so indeed) in another. \nComparative process tracing would be futile if, in order to know that\nC causes E in the target species or population, we\nwould have to compare all the stages of the process between\nmodel and target. This is because in order to do so, we would have to\nknow all stages of the process through which C causes\nE, but if we did, we would already know that C\ncauses E. This brings us back to the extrapolator’s\ncircle. Steel now argues that comparative process tracing avoids the\nextrapolator’s circle by demanding processes to be compared only\nat stages where they are likely to differ and assuming that\ndifferences between model and target matter only to stages that are\ndownstream from where they obtain. Thus, if we compare an intermediate\nstage of the process which obtains in the model with that stage in the\ntarget and find them to be relevantly similar, then the only\ndifferences that may still obtain will be downstream from this stage.\nWe therefore do not require knowledge of the entire process from\nC to E in the target, and the extrapolator’s\ncircle is successfully avoided. \nHow useful comparative process tracing is as a method for\nextrapolation for the biomedical sciences depends on how reliable the\nassumption that only downstream differences matter to extrapolation\nis, the reliability with which stages where there might be differences\nbetween model and target can be identified and the reliability of our\nmechanistic knowledge more generally. If, say, our reasons for\nsupposing that C causes E through a series of stages\nX, Y, Z in the model, or that X\nand Z are the stages where model and target are likely to\ndiffer, are not very strong, then the method does not get off the\nground. This is an issue that depends on the quality of the existing\nknowledge about a given case and cannot be addressed for the\nbiomedical sciences as a whole. There are certainly some examples of\nwell-established causal claims where it is known only that C\ncauses E but the details of the causal process are entirely\nbeyond our current grasp (Reiss forthcoming-a). \nAn alternative to comparative process tracing that has been\nproposed is extrapolation by knowledge of causal capacities.\nIf C has a causal capacity to bring about E, then\nC causes E in a somewhat stable or invariant manner.\nSpecifically, C will then continue to contribute to the\nproduction of E even when disturbing factors are present\n(Cartwright 1989). To establish that C has the causal\ncapacity to cause E therefore means to show that\nC’s causing E is independent of the background\nin which C and E occur to some extent. And\ntherefore, if C causes E in a model species or\npopulation and C has the causal capacity to bring about\nE, then there is some reason to believe that C\ncauses E also in the target species or population (for a\ndefense, see Cartwright 2011). \nThe usefulness of the method of extrapolation by causal capacities\ndepends, among other things, on the extent to which biomedical factors\ncan be characterized as having capacities. Many biomedical causes do\nindeed have some degree of stability. The sickle cell trait is 50%\nprotective against mild clinical malaria, 75% protective against\nadmission to the hospital for malaria, and almost 90% protective\nagainst severe or complicated malaria (Williams et al. 2005). These\nfigures suggest a reading along the lines of,  \nin the presence of the sickle cell trait (a preventer of/disturbing\nfactor for malaria), infection with Plasmodium malaria\ncontinues to affect outcomes consistently. (Reiss 2015b: 19) \nBut there is a high degree of interaction with other factors as well.\nWhether or not a substance is toxic for an organism depends on minute\ndetails of its metabolic system, and unless the conditions are just\nright, the organism may not be affected by the substance at all. To\nwhat extent this method will be successful therefore similarly\ncase-dependent as comparative process tracing. \nAs we can see, there is no general answer to the question whether or not\nanimal studies are valuable from a purely epistemic (as opposed to\nethical, economic, or combined) view. Other authors have developed a\npractice-based taxonomy of animal modes to allow more accurate\nassessment of the epistemic merits and shortcomings, and predictive\ncapacities of specific modeling practices (Degeling and Johnson 2013).\nThere is much evidence that species differ enormously with respect to\ntheir susceptibility to have toxic reactions to substances. Thus,\nwhile it is very likely that for any one toxin, there is some species\nthat is predictive of the human response, it is often hard to tell\nwhich one is most appropriate for any particular toxin. A species that\npredicts the human response well for one substance may be a bad model\nfor another. However, some authors suggest that extrapolations \nfrom animal models have been made successfully in at least some cases (Steel 2008\ndiscusses the extrapolation of claims concerning the carcinogenicity\nof aflatoxin from Fisher rats to humans; see Reiss 2010a for a\ncritical appraisal and Steel 2013 for a response). \nFrequently, in the biomedical sciences, reliable animal or other\nnon-human models are not available and RCTs on humans are infeasible\nfor ethical or practical reasons. In these and other cases, biomedical\nhypotheses can be established using observational methods. As we have\nseen in\n Section 5,\n evidence-based medicine regards observational methods as generally\nless reliable than RCTs and other experimental methods. This is\nbecause observational studies are subject to a host of confounders and\nbiases that can be controlled when the hypothesis is tested by\na—well-designed and well-conducted—RCT. But it is not the\ncase that observational methods cannot deliver reliable results. In\nfact, it is well possible that the medical knowledge that has been\nestablished observationally by far exceeds the knowledge that comes\nfrom RCTs. Here are some examples of medical interventions that are\nwidely accepted as effective but whose effectiveness has not been\ntested using RCTs: penicillin in the treatment of pneumonia, aspirin\nfor mild headache, diuretics for heart failure, appendectomy for acute\nappendicitis and cholecystectomy for gallstone disease (Worrall 2007a:\n986); automatic external defibrillation to start a stopped heart,\ntracheostomy to open a blocked air passage, the Heimlich maneuver to\ndislodge an obstruction in the breathing passages, rabies vaccines and\nepinephrine in the treatment of anaphylactic shock (Howick 2011b,\n40). \nObservational studies often begin by reporting a recorded correlation\nbetween a medical outcome of interest and one or a set of independent\nvariables: lung cancer rates are higher in groups of smokers than in\ngroups of non-smokers, liver cancer rates are higher in populations\nthat tend to consume food that has been contaminated with aflatoxin\nthan in populations whose food is uncontaminated, to give a few\nexamples. That smoking causes lung cancer, or aflatoxin cancer of the\nliver, would indeed account for the observed correlations. But so\nwould a variety of other hypotheses. Generally, if two variables\nX and Y are correlated, it may be the case that\nX causes Y, Y causes X or a common\nfactor Z causes both X and Y (or a\ncombination of these). In the smoking/lung cancer case, all three\nhypotheses were invoked as possible accounts of the data. Ronald\nFisher famously proposed that it may be the case that early stages of\nbronchial carcinoma cause an individual to crave cigarettes, and he\nprovided some evidence that both smoking behavior and susceptibility\nto lung cancer have a common genetic basis (Fisher 1958). Moreover, it\nis possible that the correlation itself is spurious—that the\ndata are correlated as per some measure of correlation such as\nPearson’s coefficient, but that the underlying variables are not\nin fact correlated in the population of interest. Selection bias is\nnormally understood as the bias that obtains when individuals\nself-select into the observed population and the reasons for which\nthey do so are correlated with the outcome variable. If an\nobservational study examines only hospitalized patients and smokers\nare more likely to be in hospital for reasons that have nothing to do\nwith lung cancer, then smoking and lung cancer can be correlated in\nthe data even if the variables are independent in the general population.\nMismeasurement and diagnostic error provide another account of spurious correlation.\nSuppose tuberculosis was on the rise a generation or so after many\npeople traded pipe smoking for cigarette smoking. Then, if it was\ndifficult to distinguish a death from tuberculosis from a death from\nlung cancer because necropsy techniques were not sufficiently well\ndeveloped, the data might again show a correlation even though the\npopulation variables are uncorrelated. \nRetrospective observational studies work by ruling out alternative\nhypotheses such as these ex post rather than controlling for\nthem ex ante as RCTs do (Reiss 2015a). In an RCT,\nmismeasurement should not obtain because the protocol specifies\nmeasurement procedures for the outcome variables in great detail in\nadvance. Selection bias should not obtain because patients are\nrandomized into treatment groups. Once allocated to a group, they are\nprevented from obtaining another treatment elsewhere, and researchers\nmake sure that patients comply with the treatment regime. But there\nare equivalent means to rule out these possibilities in observational\nsettings. While it may well be the case that early stages of cancer\ncause a craving for cigarettes, this hypothesis cannot explain the\nprotective effect that stopping smoking has. At the time of the\nsmoking/lung cancer controversy in the mid-1950s, misdiagnosis was\nindeed a problem. However, it could be shown that in order to account\nfor the observed rise in lung cancer incidence, the diagnostic error\nat autopsy among older people would have to have been an order of magnitude \nhigher than the diagnostic error among younger people (Gilliam 1955).\nMismeasurement could therefore also be ruled out. Similar\nconsiderations helped to rule out other alternative hypotheses\n(Cornfield et al. 1959). \nEven if one were to believe, with the proponents of EBM, that\nobservational studies are generally less reliable than RCTs, medicine\ncould—fairly obviously—not do without them. There are\nlarge numbers of pressing questions that could not be addressed by an\nRCT for ethical, financial and other practical reasons. No-one would\nseriously consider testing a proposition such as “Aflatoxin\ncauses cancer of the liver (in humans)” by an RCT. This is not\nmerely because of the straightforward ethical issues involved in\ndeliberately exposing humans to a potential carcinogen for the sake of\nmedical progress. It is also because exposure to low levels of aflatoxin can\ntake many years or even decades to produce symptoms. The ability of\nresearchers to control food intake in a large group of experimental\nsubjects for a very long has evident practical financial and\nlimitations. RCTs can also not be used when researchers or patients or\nboth cannot be blinded, and many medical interventions do require the\ndoctor’s or the patient’s knowledge of details about the\nintervention. \nMoreover, it is not clear that RCTs are always more reliable than\nobservational studies to answer questions both methods are able to\naddress. Whether or not a study is reliable depends on whether or not\nconfounders and biases have in fact been eliminated, not by which\nmethod they have been eliminated. Issues concerning the reliability of\na method can be entangled with issues concerning its ability to\naddress the research question the biomedical scientist seeks to\nanswer. Both RCTs and observational studies in the biomedical sciences\nare typically employed to test rather complex hypotheses about the\nsafety and efficacy of medical interventions. It may well be that some\nof the issues are more reliably treated by one method and others by\nthe other. \nA famous controversy in which the results from observational studies\nand those from RCTs conflicted was that over the benefits and safety\nof hormone replacement therapy (HRT) in the early 2000s (Vandenbroucke\n2009). HRT seemed protective for coronary heart disease in\nobservational studies, whereas RCTs indicated an increase in the first\nyears of use. For breast cancer, combined hormone preparations showed\na smaller risk in an RCT than in observational studies. In the end it\nturned out that the timescale of the effects was responsible, and that\nbecause of the way they are typically run, observational studies got\nsome issues right and RCTs others: \nThe observational studies had picked up a true signal for the women\ncloser to menopause. In the randomised trial, that signal was diluted\nbecause fewer women close to menopause were enrolled… The\nrandomised trials had it right for coronary heart disease but failed\nto sufficiently focus on women close to menopause for breast cancer.\nThe main reasons for the discrepancies were changes of the effects of\nHRT over different times… (Vandenbroucke 2009: 1234) \nCase reports remain extremely popular in medicine both as publications\nto communicate within the field and for pedagogical purposes. In\nshort, a case report describes a medical problem experienced by one or\nmore patient, usually involving the presentation of an illness or\nsimilar that in some way difficult to explain or categorize based on\nexisting understandings of disease or understandings of physiology and\npathology. Cases in medicine take highly standardized forms of\npresentation which are inculcated in health care professionals during\ntheir education, and many have commented on their highly standardized\nnarrative structure and its epistemic and other implications (Hunter\n1991; Hurwitz 2006). Cases typically provide details on the\npresentation of the disease, diagnosis, treatment, and outcomes for\nthe patient, with a focus on practice-based observations and clinical\ncare (rather than the results of randomized controlled trials or other\nexperimental methodologies). One of the purposes of cases is to gather\ndetailed information including facts that may not be immediately\nrelevant, but that could prove to be (Ankeny 2011). Thus the\ninformation contained in the case and the case itself can be useful\nover the long term particularly if it can be systematically combined\nwith other cases into larger datasets. \nSingle cases are seen by some as problematic as a form of evidence\nparticularly in the era of EBM, because they often focus on highly\nunusual manifestations of illness and disease, rather than typical or\nrepeatedly observed conditions that might support generalizable rules.\nThis feature has led some to describe medicine as a “science of\nparticulars” (Gorovitz and MacIntyre 1976), or as an art rather\nthan a science (Pellegrino 1979), particularly in processes of\ndiagnosis (see\n Section 9).\n However standard accounts of EBM include the case series as a type of\nevidence, which involves the aggregation of individual cases of\npatients with similar attributes (e.g., who received the same\ntreatment or therapy) who are tracked over time using descriptive data\nand without utilizing particular hypotheses to look for evidence of\ncause and effect. EBM does place the case series quite low in its\nhierarchy of evidence but nonetheless it is acknowledged that cases\nhave potential usefulness especially where forms of evidence that rate\nmore highly are not available, as may often be the case where human\npatients are concerned due to practical or ethical reasons, or where\nthe available evidence at higher levels has been produced in a manner\nthat is methodologically or otherwise flawed. \nCases can serve other purposes: for instance analyses of cases can\nprovide working hypotheses about casual attribution that can ground\nfurther tests of causal relations (Ankeny 2014), which in turn allows\nuse of more traditional methodologies such as RCTs, cohort studies,\nand so on to explore these causal hypotheses. In the context of\nclinical care, cases can allow health care providers to identify a\ncause that can be manipulated to cure (or prevent) the condition in\nquestion, in order to treat ill patients, even in the absence of more\nrigorous forms of evidence. \nDiagnosis is the process through which a clinician determines what is\nwrong with a patient who is ill or ailing in some way. Although a\ncritical part of the practice of medicine, it has been relatively\nneglected in the literature of philosophy of medicine particularly in\ncomparison to more statistically-based methods for evaluating evidence\nin other fields (Stanley and Campos 2013). The key philosophical\nissues that arise in this context relate to how such determinations\ncan be made in a manner that is accurate given the high amount of\nuncertainty and complexity often associated with the human condition,\nand hence involve logical, epistemological, and ontological issues.\nThe usual way of proceeding in a clinical setting is to ask the\npatient to articulate what is ailing him or her, and thus to use a\nstandardized reporting format to detail various symptoms which\nrepresent subjective manifestations of the illness or disease. In\naddition, clinicians perform various tests and examinations that allow\nmore objective manifestations or signs to be recorded, such as heart\nrate, blood pressure and count, reflexes, and so on. A perennial\ndebate in the philosophy of medicine is what constitutes symptoms and\nsigns and whether they are in fact distinct, which relates to deeper\nissues about the realism of disease conditions as discussed above\n (Section 2). \nThe tricky part of the process is to find a means for mapping these\nsymptoms and signs onto a particular disease condition. Some would\nadvocate that this process is no different than usual methods in\nphilosophy of science for hypothesis generation and testing based on\nevidence, and this type of model fits with what is termed differential\ndiagnosis. Differential diagnosis involves a set of hypothetical\nexplanations for a particular condition which come to be ruled in (or\nout) based on the evidence together with additional data that is\ncollected, hence relying on a form of reasoning via decision nodes or\nalgorithmic pathways (Stanley and Campos 2013). However, the details\nof the rules of reasoning that underlie this sort of process remain\nlargely unarticulated, as does the amount of “tacit”\nknowledge that may contribute to diagnostic reasoning. \nThere are various ways in which diagnosis is taught and\noperationalized in clinical settings: in some subspecialties in\nparticular, “pattern” recognition often using pictorial\nrepresentations seems to be common, and hence diagnosis is a form of\nrecognizing repeated patterns. However this approach can be dangerous\nparticularly among novices, given the large number of similar patterns\namong common diseases. Some have claimed that the making of a\ndiagnosis is both a deontic act and computable, and that diagnoses are\nrelative only inasmuch as they occur in a complex context which in\nturn makes them a social practice (Sadegh-Zadeh 2011).\nComputer-assisted diagnostic techniques have improved and are used\nincreasingly in clinical settings; Kenneth Schaffner (1981) provided\nan early analysis of the criteria which an ideal diagnostic logic\nwould need to satisfy (for updated discussions see Schaffner 1993,\n2010, and for arguments about the limitations of such types of\ndiagnosis see Wartofsky 1986). In recent years there is a relative\nconsensus among medical professionals and those involved in medical\ninformatics that medical diagnosis almost certainly relies on some\nform of “fuzzy logic” (e.g., Sadegh-Zadeh 2000; Barro and\nMarin 2002). \nAs we have seen in\n Section 5,\n hierarchies of evidence in evidence-based medicine rank study results\nfrom “systematic” clinical research such as RCTs and\nobservational studies higher than “unsystematic” expert\nopinion. The epidemiologists who initiated the formal EBM movement in\nthe early 1990s had good reason to be skeptical about expert opinion.\nWhen therapies are subjected to systematic tests, tradition and expert\nopinion are sometimes shown to be flawed. John Worrall discusses three\nexamples: grommets for glue ear, ventricular ectopic beats repressing\nsubstances such as encainide or flecainide for cardiac arrest, and\nroutine fetal heart rate monitoring to prevent infant death (Worrall\n2007a: 985). In each case we have a procedure the effectiveness of which is\nindicated by common sense and knowledge about the patho-physiological\npathways—glue ear is a condition produced by a build-up of fluid\nin the middle ear that is unable to drain away because of pressure\ndifferentials, grommets act by letting air into the middle ear and\nthereby equalizing pressure, for instance—but which, when tested\nby a randomized trial, turns out to be ineffective at best and\npositively harmful in the worst case. \nMisjudgments concerning the efficacy of therapies for purely epistemic\nreasons are not the only worry that one might have about expert\nopinion. Medical experts and patients are in what economists call a\nprincipal-agent relationship. The principal—in this case, the\npatient—desires the delivery of a certain good or\nservice—in this case, his health. He instructs an agent—in\nthis case, the doctor—with it, because he lacks the expertise to\nproduce the good himself. The good can only be produced with\nuncertainty: no therapy is 100% effective. Moreover, the success at\ndelivering the good depends in part on the agent’s effort. The\ndoctor may not always choose the optimal therapy for a patient (we can\nsuppose that it takes some effort to select the optimal therapy for a\npatient), and any therapy can be implemented sloppily. Moreover,\nlacking expertise, the patient cannot observe the level of effort a\ndoctor puts in. He therefore cannot design a contract that makes\npayments dependent on level of effort (much less on success, as\nsuccess is in part influenced by factors outside of either\nparty’s control). Agents therefore have an incentive to cheat:\nnot to put in the level of effort required to select and deliver the\noptimal therapy from a patient’s point of view. \nIf patients and doctors were perfectly rational and motivated only by\ntheir own material welfare, and in the absence of regulation, there\nsimply wouldn’t be a market for health services. Doctors would\nchoose therapies that are best for them and not for patients, and\npatients would anticipate this behavior and stop seeking\ndoctor’s services in the first place. In our world, neither\npatients nor doctors are particularly rational, nor are they motivated\npurely by self-interest, there are ethical codes such as the modern\nform of the Hippocratic Oath, and the health sector is one of the most\nregulated industries of all. All this does not, however, change the\nincentive structure in which doctors and other providers of health\nservices operate. Because they and not the patients are experts, they\nhave incentives to choose therapies that are in their best interests\nand not in the patients’ interests. \nThere is a further complication. Many, probably most, doctors have\nconnections to the pharmaceutical industry in one form or another.\nAccording to one study, 94% of U.S. physicians receive financial\nbenefits from the pharmaceutical industry (Bekelman et al. 2003). Even\nif we suppose that doctors do not prescribe a therapy because they are\npaid to do so, marketing efforts directed at them will influence\ntreatment recommendations, if only because they know certain pills\nbetter than others, or because some treatments are at the top of their\nheads. \nFor all these reasons, the EBM principle that treatment decisions\nshould be based on the best available evidence from systematic\nresearch does not come out of nowhere. If, say, there is an RCT or an\nobservational study that reports that treatment X is more\neffective at relieving symptoms S than treatment Y,\nit would seem bad to recommend a patient who suffers from S\nto take Y because his GP doesn’t know about X,\ndoesn’t know the study result, personally profits from\nprescribing Y or is inattentive. However, while these are all\nbad reasons to recommend Y over X in the light of\nthe study result, there may be a variety of good reasons. \nAs discussed in\n Section 5,\n RCTs and many observational studies are population-level studies,\nwhich produce average results that are not straightforwardly\napplicable to individuals. If, say, treatment X reduces the\nrisk of suffering from some adverse event over a period of time by 50%\nin population p, that is, the risk ratio (RR) for this\ntreatment is 50%, then there may be no individual in p for\nwhom the treatment halves the risk. Instead, the RR may vary\ndramatically among the subpopulations of p, and it may well\nbe the case that Y is more effective than X for some\nsubpopulations. \nThe same is true of side effects. Tonelli (2006) discusses a case\nwhere a patient who suffers from multiple sclerosis receives a\ntreatment that does seem to alleviate her symptoms, but since she has\nstarted taking it, she has been plagued by severe episodes of\ndepression. Clinical trial results indicate that the drug is effective\nin treating multiple sclerosis, and no adverse psychiatric effects\nhave been reported. Her GP and her psychiatrist now debate whether to\ncontinue the treatment. There are various reasons why the clinical\nstudies do not show evidence of mental health effects: the trial\nsubjects weren’t properly screened for depression; adverse\neffects were found but not reported; the adverse effects were not\nstatistically significant—but they may have been clinically\nsignificant for some subpopulations; the side effects only obtain in\npopulations that differ from the trial populations. \nThis case shows that a treatment’s effectiveness in relieving\nthe symptoms of the disease for which it was prescribed is not the\nonly consideration when making a treatment decision. The goal of the\ntreatment is to improve the patient’s wellbeing, which is well\nrecognized by the proponents of EBM. A patient’s wellbeing has\nmany components, of course, and the symptoms of any given disease are\nat best one element in its determination. This is another reason why\nclinical judgment must be exercised in the derivation of a treatment\nrecommendation. \nUnfortunately, experts—like all humans—are notoriously bad\ndecision makers. Cognitive psychologists have established a large\nnumber of cognitive biases to which human experts are subject: they\nsuffer from overconfidence (e.g., Dawes and Mulford 1996) and\nhindsight bias (e.g., Fischhoff 1975; Hugh and Dekker 2009); are\nregularly outperformed by simple mechanical algorithms (e.g., Grove\nand Meehl 1996); commit the conjunction fallacy (Tversky and Kahneman\n1983; Rao 2009), and many others. \nTo give an example for a simple mechanical algorithm outperforming\nexperts, consider the Goldberg Rule, according to which a patient is\nto be qualified as neurotic if \\(x = (\\textrm{L} + \\textrm{Pa}+\n\\textrm{Sc}) - (\\textrm{Hy} + \\textrm{Pt}) > 45\\) (where L is a\nvalidity scale and Pa, Sc, Hy, and Pt are clinical scales of a\nMinnesota Multiphasic Personality Inventory or MMPI test) and as\npsychotic otherwise. Lewis Goldberg tested the rule on a set of MMPI\nprofiles from 861 patients who had been diagnosed by the psychiatric\nstaff in their hospital or clinic and found it to be 70% accurate;\nclinicians’ accuracy ranged from 55% to 67% (Goldberg 1968; for\na discussion, see Bishop and Trout 2005). \nThere is no one strategy to deal with the various biases and interests\nthat affect clinicians’ judgments. Better numeracy and\nstatistical training at universities can help to eliminate some\ncognitive biases (Gigerenzer 2014). Computer-aided medical diagnosis and decision making\nmay alleviate others. No training or computer program can make\nnormative judgments, however, and neither will help with adverse\nincentive structures and financial interests. These difficulties also\nbeset committees of medical experts to which we are turning\nnext. \nOne way to help overcome expert bias is by making medical decisions\nnot dependent on individual expert judgments but instead have groups\nof experts coming to some form of aggregate judgment. The U.S.\nNational Institutes of Health, for instance, used to organize\nso-called consensus conferences designed to resolve scientific\ncontroversy. Panel members are chosen from clinicians, researchers,\nmethodologists and the general public. Federal employees are not\neligible, nor are researchers who have published on the subject at\nhand or have financial conflicts of interest (Solomon 2007). These\nexclusions are intended to contribute to controlling government\ninfluences as well as any biases due to financial or intellectual\ninterests. \nConsensus conferences and other mechanisms for reaching group\njudgments are clearly no panacea. Miriam Solomon (2015), for instance,\nargues that consensus conferences tend to “miss the window of\nepistemic opportunity” in that they often take place after the\nmedical community has already settled an issue. More important in the\npresent context is the observation that while these conferences\npossibly help to control some forms of partiality, they are\nineffective in reducing others and may be responsible for the\nintroduction of new biases. One concern is that panel members may read\nthe existing evidence selectively, for instance, because of weighing\nsalient studies or studies that are available to them more heavily.\nAnother is that phenomena such as groupthink (Janis 1982) and peer\npressure may influence results. In an NIH consensus conference panel\nmembers have to come to a verdict after only two days of hearings and\ndeliberations. Under these conditions it is certainly possible that\nmore outspoken panel members or those who perform well under extreme\npressure have a undue influence on results. Moreover, it is not clear\nthat excluding clinicians who have published on the issue at hand is\nalways such a good idea. After all, it is not implausible to maintain\nthat those scientists who actively work on a research topic are those\nwho best understand it and therefore can make the best informed\njudgments. For these and other reasons, Solomon (2007, 2015) explores\nthe consequences of judgment aggregation. In this process group\nmembers typically do not deliberate but instead cast their opinions\nwhich are then aggregated using some pre-determined procedure. The\nmajority rule would be a simple example of such a procedure. \nComing to a group judgment using a mechanical procedure such as\nmajority vote has a number of advantages. First, there are epistemic\nadvantages that can be illustrated by Condorcet’s Jury Theorem.\nThis theorem shows that if (a) the judgment concerns a proposition\nthat can either be true or false, (b) jury members have an independent\nprobability \\(>.5\\) that they get the judgment right, (c) the\nindividual judgments are aggregated using majority vote, then the\nlarger the jury, the more likely it is to reach the correct group\njudgment. Under these conditions, then, a committee of experts is\nlikely to make a better judgment than a single expert. Moreover, in\nthe absence of deliberation and pressure to come to a unanimous\nresults, and when voting is secret, the influence of groupthink, peer\npressure etc. is attenuated or eliminated. \nWhen conditions (a)–(c) do not hold, results are more ambiguous\nor even negative. When experts are not reliable, i.e., the individual\nprobability of getting the judgment right is \\(<.5\\), the larger\nthe group, the less likely is it to reach a correct group\njudgment and the optimal group size is a single expert. When the\noutcome can have more than two values, inconsistent results can\nobtain. This can easily be demonstrated with an example in which there\nare three possible outcomes and three experts. Suppose, for instance,\nthat a panel has to decide which of three treatments A,\nB and C is the most effective in treating some disease.\nThe individual panel members have the following individual\nrankings: \nExpert I: \\(A > B > C\\) \nExpert II: \\(B > C > A\\) \nExpert III: \\(C > A > B\\), \nwhere “>” means “more effective”. There is\nnow a majority that holds that A is more effective than\nB (I&III), a majority that holds that B is more effective\nthan C (I&II) and a majority that holds that C is\nmore effective than A (II&III). More generally, whenever\nthere are logical relations among the propositions to be decided (in\nthis case: \\(A > B\\) and \\(B > C\\) implies that \\(A > C\\)),\nthere are at least three panel members, and votes are aggregated by\nthe majority rule, inconsistencies can arise at the group level\n(Pettit 2001). \nThe majority rule is of course only one way to aggregate judgments.\nThe Delphi method (e.g., Dalkey and Helmer 1963; for an application to\nmedicine, see Jones and Hunter 1995) applies to cases where the task\nis to provide a numerical estimate of some variable of interest (say,\nthe risk difference a new treatment makes). Experts answer\nquestionnaires in several rounds. After each round, a facilitator\nprovides an anonymous summary of the experts’ estimates from the\nprevious round and the reasons given for their judgments. Experts are\nthus supposed to be encouraged to revise their earlier answers in\nlight of other experts’ estimates and justifications. During\nthis process the range of the estimate will often decrease, and it is\nhoped that the group will converge towards the correct answer. The\nprocess is stopped after a pre-determined stopping criterion such as\nnumber of rounds, achievement of consensus, stability of results, and\nan average of the estimates of the final round is used as result. \nSolomon (2011, 2015) raises a fundamental issue concerning group\njudgments that is entirely independent of the specific method used. She argues that we\ndo not often find group judgment methods to determine the truth of\nscientific hypotheses or estimates of variables in the natural\nsciences (though see Staley 2004). If there is uncertainty about, say, which of two alternative\nhypotheses is true or what value a natural constant has, scientists go\nout and test, experiment, measure. Controversies, in other words, are\nsettled on the basis of evidence, not (individual or group) opinion.\nShouldn’t we, with the advancement of evidence-based medicine,\nexpect the same to happen in medicine? Consequently, she recommends\nmore widespread use of mechanical techniques for amalgamating evidence\nsuch as meta-analysis in lieu of consensus conferences and the\nlike. \nThe frequency of NIH consensus conferences has indeed markedly\ndeclined in recent years (Solomon 2011, 2015). But this is\nof course no reason to maintain that group judgments are no longer\nneeded. Consensus conferences may be the wrong tool for the purposes\nof the NIH, or the NIH may have a mistaken view about the ability of\nevidence to settle disputes adequately. Indeed, there are at least two\nreasons to believe that group judgment procedures are here to\nstay. \nThe first reason is that, as we have seen above, medical decisions are\nalways in part decisions about normative matters. No treatment is\nentirely without side effects and so if judgments about efficacy are\nto be of practical guidance, they must include a weighing of benefit\n(alleviation of disease symptoms) against cost (suffering from side\neffects)—even if economic costs and benefits are not to\nbe taken into consideration. Second, government agencies such as the\nU.S. Food and Drug Administration (FDA) have to decide whether new\ntreatments should be licensed to be marketed. These decisions often\nhave significant consequences, and democracies tend to prefer to be\nable to hold someone accountable for making them. Drug approval\ntherefore cannot be determined on the basis of evidence according to\nsome mechanical algorithm. \nBiddle (2007) discusses epistemological and moral issues of drug\napproval in the context of a case study on Vioxx, an analgesic. Vioxx\nwas approved by the FDA in 1999 but five years later pulled from the\nmarket by its manufacturer Merck due to safety concerns. It is\nestimated that some 55,000 people died from taking the drug (Harris\n2005). Biddle observes that the FDA is not sufficiently independent of\nthe pharmaceutical industry to make unbiased decisions likely. Many of\nthe members of the FDA’s drug approval committees have financial\nconflicts of interests (often in the form of receiving benefits from\nthe pharmaceutical company whose drug is to be approved), and a large\nnumber of employees of the FDA are dependent on the “user\nfees” industry pays to help cover the cost of drug approval. To\nsolve these problems of conflicts of interests, Biddle proposes to\ninstitute an adversarial system in which two groups of advocates, a\ngroup of representatives of the manufacturer and a group of\nindependent scientists, would argue before a panel of judges over\nwhether a drug should be allowed on the market. The panel of judges in\nthis model also consists of independent FDA or university scientists.\nHe argues that the adversarial system would better acknowledge the\nfact that an increasing number of medical researchers have financial\nties to the pharmaceutical industry by treating them as advocates\nrather than disinterested experts. (See also Reiss and Wieten 2015, Reiss forthcoming-b.) \nThere is no doubt that medical research is shaped by various external\nvalues, in ways similar to the value ladeness that is well-recognized\nin other areas of science (see entry on\n scientific objectivity).\n Many of these values create a variety of ethical dilemmas relating to\nequity of access to health care and similar. Even in recent years once\nmedical research has been made more inclusive, this trend has\nintroduced a host of additional philosophical and ethical issues\n(Epstein 2007). For our purposes, we will focus on the implications of\nthe systematic exclusion of certain types of individuals, groups, or\ndiseases from research for future research as well as clinical medical\npractice in terms of the validity of evidence produced and decisions\nmade based on that evidence.  \nIn traditional medical research, it was generally assumed that white\nmale participants could be used as the basis of generalizations that\nin turn could be extrapolated to all other populations, including\nminorities and females (Dresser 1992). Reviews of the literature\nindicate that women in particular have been excluded (especially older\nwomen), and that research on women has usually been related to\nreproductive function and capacity (Inborn and Whittle 2001). Such\ntypes of research have been argued to fail the ideals of quality\nmedical research as well as evidence-based health care (Dodds 2008).\nAlthough some improvements have been made in recent years, there\nremain certain forms of blanket exclusions for instance of women of\nchildbearing age or pregnant women in many types of medical research.\nThese types of systematic exclusion are highly problematic especially\nbecause there is clear evidence of critical differences between men\nand women with regard to a range of factors relating to receptivity to\ntherapies for both biological and social reasons.  \nIn the case of minorities such as African-Americans in the United\nStates, even when research trials seek to recruit them, a range of\nfactors may contribute to them not being involved in medical and other\ntypes of research studies. These include distrust due to historical\nand institutional racism including research performed without consent;\nlack of understanding about research and consent; social stigma;\nfinancial considerations; and lack of culturally-sensitive recruitment\nmethods by researchers (e.g., Huang and Coker 2010). Such gaps in\nmedical research potentially lead to use of treatments or therapies\nthat may in fact be harmful for particular groups, and may result in\nthe withholding of therapies that might be beneficial. \nMedical research also is affected by which conditions or diseases are\nselected for investigation (Reiss and Kitcher 2008): perhaps most\nnotoriously, “orphan” diseases which are either rare,\ncommon only in minority populations, or only present in certain\ndeveloping world or other lower socioeconomic settings, are often\nneglected for drug and other therapy development because it is\nperceived that there will not be a viable commercial market for any\nproducts on which research might be done due to the at-risk or\naffected population (and hence such potential products are often\ntermed “orphan drugs”). In some cases patients may pursue\n“off-label” use of drugs which are approved for a\ncondition other than the one they have, because approval for an\n“orphan” disease is unlikely due to cost and demand;\nhowever such off-label uses of drugs even when overseen by a physician\ntypically result in lack of consistent collection of evidence and\nabsence of typical risk-benefit regulatory considerations utilized\nwhen a drug is approved for particular purposes. \nA final way in which our knowledge in medicine generated by research\nis potentially adversely affected by values is through the funding\npatterns connected with research. As implied above, pharmaceutical\ncompanies sponsor a considerable portion of drug trials and have a\nvariety of interests at stake in these investments well beyond the\ngathering of evidence for the effectiveness (or lack thereof) of a\nparticular product. There is consistent evidence that negative\nresearch results typically are suppressed when sponsored by industry\n(Lexchin 2012a), leading to a bias in what is reported and thus what\nevidence is available on which to make prescribing and treatment\ndecisions. Bias also has been found in a number of other areas: within\nthe study itself in the choice of research question or topic of\ninvestigation, in the choice of doses or drugs against which the drug\nunder study is to be compared, in the control over trial design and\nvarious changes in protocols, and in decisions to terminate clinical\ntrials early, and in the reinterpretation of data, as well as in the\npublication of data such as restrictions on publication rights, use of\nfake journals, favoring journal supplements and symposia rather than\npeer review venues, the use of ghostwriting, and in the details of the\nreporting of results and outcomes (Sismondo 2008; Reiss 2010b; Lexchin 2012b). All of these\nissues weaken the evidence base on which clinical care judgments are\nmade, and also lead to potentially adverse effects for patients. \nIn order to evaluate medical outcomes quantitatively, they have to be\nmeasured. There are numerous reasons for aiming to quantify medical\noutcomes. We may want to compare two or more treatments with respect\nto their efficacy at relieving certain symptoms or their ability to\nprevent deaths due to a certain disease. When resources are scarce, we\nmay not only want to invest in treatments that are efficacious (that\nis, they do improve patient morbidity, mortality or both) but also\nefficient (that is, it is more efficacious than other treatments\nrelative to the cost of procuring it). For matters of international\ncomparison, development and international justice, we also want to\nhave measures of disease burden: Which of a number of\ntropical diseases has the highest cost in terms of increased morbidity\nand mortality? For each research dollar spent on treatments for\ndisease X, how much can we expect to reduce the morbidity and\nmortality it causes? \nClinical trials now often report so-called patient-reported outcome\nmeasures or PROMs. A PROM is a questionnaire given to patients to\nevaluate certain aspects of their quality of life, functioning or\nhealth status after a medical intervention without interpretation of\nthe patient’s response by a clinician or other people. It might\nask, for example, how difficult patients find it to climb up a flight\nof stairs after hip surgery or whether or not a cancer treatment helps\nthem to pursue their hobbies. The main goal of a PROM is the\nassessment of treatment benefit or risk in cases where the medical\noutcome is best known by the patient or best measured from the patient\nperspective. \nPROMs can vary considerably in length and complexity depending on the\nconcept that is being measured. In simple, straightforward cases\n(e.g., intensity of a certain kind of pain), a single question might\nsuffice. In others, it may be necessary to address several aspects of\na more complex functioning with a number of questions each. Either\nway, the design of the questionnaire should make sure that the\ninstrument reliably measures the concept of interest. The FDA\ndistinguishes the following six measurement properties or\n“tests” (FDA 2009: 11): \nDespite their plausibility, these tests are not methodologically\ninnocuous. Content validity, for instance, is assessed on the basis of\nqualitative research in the form of patient interviews, focus groups,\nand qualitative cognitive interviewing (the latter refers to a method\nthat asks respondents to think aloud and describe their thought\nprocesses as they answer the instrument questions and involves\nfollow-up questions in a field test interview to gain a better\nunderstanding of how patients interpret questions). This qualitative\nresearch aims to develop questions with standardized meanings that are\nshared between patients and clinicians. Arguably, however, there will\nalways be differences in interpreting phrases such as “bodily\npain” or “difficulty in lifting one”s arm’\nbecause they refer to a patient’s experiences, and these will\ndiffer from patient to patient and, in a given patient, from time to\ntime (Rapkin and Schwartz 2004). Moreover, there may be good\nphilosophical reasons to allow for the expression of a sufficient\narray of legitimate perspectives on health and quality of life instead\nof insisting on a standardization of meaning across patients and\ncontexts (McClimans 2010). Similarly, internal consistency can be\ndesirable only to the extent that the concept is a relatively simple\none and different questions really do address the same concept. It is\nof less relevance when the disorder is heterogeneous (McClimans and\nBrowne 2011). These kinds of worries can be raised with respect to\neach of the measurement tests. Finally, there is an issue when several\nPROMs that address a given disorder or treatment exist. Different\nPROMs will score differently with respect to the different tests, and\nthere is no universally valid schema to weigh their relative\nimportance (ibid.). \nDisability-adjusted life years or DALYs aim to measure burden of\ndisease. The measure was originally developed by Harvard University\nfor the World Bank and World Health Organization (WHO) in 1990 and is\nnow widely used by heath policy researchers for comparisons between\ncountries and over time and as a tool for policy making. It can also\nbe used to measure the effectiveness of interventions, though these\nare usually health policy rather than medical interventions\nnarrowly construed. The WHO makes regular global disease burden\nestimates in terms of DALYs at regional and global level for more than\n135 causes of disease and injury (Mathers et al. 2002). \nThe principal idea behind DALYs is simple. If a woman in Guatemala\ndies of Chagas disease at age 63, this adds 20 DALYs to the global\ndisease burden because her death is 20 years “premature”\nas compared to Japanese life expectancy (which is taken as the\nstandard because it is the highest world wide). If a man in\nHamburg has an accident that confines him to the wheelchair for the\nrest of his life, this contributes 0.57 DALYs for each of his\nremaining life years because the weight for paraplegia is 0.57. Every\nkind of disease or impairment is thus given a number between 0 and 1\n(where 0 = full health and 1 = death) that makes it comparable to\nother conditions. For example, blindness has a weight of 0.43. As\nblindness contributes less to the burden of disease than paraplegia,\nthis means that blindness is regarded as the less severe of the two in\nterms of its reduction of functional capacity\n(Prüss-Üstün et al. 2003). \nThe simple idea is complicated by two adjustments, however. Typical\nburden of disease studies weigh an impairment differently depending on\nthe age of the person whose functional capacity is impaired by the\ndisease or disability. Blindness, say, has a greater impact on the\nburden of disease if it occurs at age 20 than if it occurs at very\nyoung or older ages (Prüss-Üstün et al. 2003).\nMoreover, if the man who has the accident now can be expected to live\nwith the disease for 30 years, future years of disability are\ndiscounted by a factor. The further into the future a disability\noccurs, the less it contributes to the disease burden\n(ibid.). \nThe adequacy of any socio-economic indicator has to be evaluated in\nthe light of the purpose that it is meant to serve (Reiss 2008). If\nDALYs are supposed to measure the everyday concept “burden of\ndisease”, we may criticize, for instance, that the indicator\nfails to take account of societal, cultural, climatic and other\nvariations within which the disease or disability occurs. Being\nparaplegic, say, is less burdensome when it occurs in societies that\nspend more resources on making public buildings and transport\nwheelchair accessible, that display more tolerance towards the\nhandicapped, or in flatter than in hillier regions. Arguably,\ntherefore, DALYs measure ill-health rather than disease burden (Anand\nand Hanson 1997). Similarly, because ill-health is measured as a\npercentage, a disease occurring in a person who is already handicapped\ncontributes less to the measure than the same disease occurring in an\notherwise comparable but not handicapped person. If DALYs are used to\nmake public health decisions, however, it might be better to\nprioritize those individuals who are least well off instead of those\nwho are relatively better off (ibid.). \nThe WHO is very explicit that numerous choices made in the\nconstruction of the DALY measure are value-based (Murray 1994;\nPrüss-Üstün et al. 2003). Clearly, there is no matter\nof fact whether paraplegia constitutes a more severe impairment of\nsomeone’s functional capacity than blindness, much less the\nprecise extent to which it contributes to the burden of disease. The\nsame is true of the duration of the time lost due to premature death,\nage weights and time preference. While any given choice will, due to\nits value-laden nature, be controversial, the WHO makes some efforts\nto represent societal preferences instead of, say, a priori\nphilosophical arguments. For example, the disability weights used in\nthe 2003 World Health Survey were based on health state valuations\nfrom large representative population samples in over 70 countries\n(Prüss-Üstün et al. 2003: Ch. 3). Similarly, age\nweights are based on empirical studies that have indicated there is a\nbroad social preference to value a year lived by a young adult more\nhighly than a year lived by a young child, or lived at older ages\n(Murray 1996).","contact.mail":"julian.reiss@jku.at","contact.domain":"jku.at"},{"date.published":"2016-06-06","url":"https://plato.stanford.edu/entries/medicine/","author1":"Julian Reiss","author1.info":"http://jreiss.org/","author2.info":"http://researchers.adelaide.edu.au/profile/rachel.ankeny","entry":"medicine","body.text":"\n\n\nPhilosophy of medicine is a field that seeks to explore fundamental\nissues in theory, research, and practice within the health sciences,\nparticularly metaphysical and epistemological topics. Its historic\nroots arguably date back to ancient times, to the Hippocratic corpus\namong other sources, and there have been extended scholarly\ndiscussions on key concepts in the philosophy of medicine since at\nleast the 1800s. Debates have occurred in the past over whether there\nis a distinct field rightly termed “philosophy of\nmedicine” (e.g., Caplan 1992) but as there are now dedicated\njournals and professional organizations, a relatively well-established\ncanon of scholarly literature, and distinctive questions and problems,\nit is defensible to claim that philosophy of medicine has now\nestablished itself. Although ethics and values are part of many\nproblems addressed within the philosophy of medicine, bioethics is\ngenerally considered to be a distinct field, and hence is not explored\nin this entry (but see the entry on \n theory and bioethics).  \nThat being said, philosophy of medicine serves as a foundation for\nmany debates within bioethics, given that it analyzes fundamental\ncomponents of the practice of medicine that frequently arise in\nbioethics such as concepts of disease. The philosophy of medicine also\nhas made important contributions to general philosophy of science, and\nparticularly to understandings of explanation, causation, and\nexperimentation as well as debates over applications of scientific\nknowledge. Finally, the philosophy of medicine has contributed to\ndiscussions on methods and goals within both research and practice in\nthe medical and health sciences. This entry focuses primarily on\nphilosophy of medicine in the Western tradition, although there are\ngrowing literatures on philosophy of non-Western and alternative\nmedical practices. It emphasizes philosophical literature while\nutilizing relevant scholarly publications from other disciplinary\nperspectives.\n\n\nOne of the fundamental and most long-standing debates in the\nphilosophy of medicine relates to the basic concepts of health and\ndisease (see\n concepts of health and disease).\n It may seem obvious what we mean by such statements: people seek\ntreatment from medical professionals when they are feeling unwell, and\nclinicians treat patients in order to help them restore or maintain\ntheir health. But people seek advice and assistance from medical\nprofessionals for other reasons, such as pregnancy which cannot be\nconstrued as a disease state, and high blood pressure which is\nasymptomatic. Thus the dividing line between disease and health is\nnotoriously vague, due in part to the wide range of variations present\nin the human population and to debates over whether many concepts of\ndisease are socially constructed. One of the further complicating\nfactors is that both the concepts of health and disease typically\ninvolve both descriptive and evaluatory aspects (Engelhardt 1975),\nboth in common usage among lay persons and members of the medical\nprofession. \nExploring these distinctions remains epistemologically and morally\nimportant as these definitions influence when and where people seek\nmedical treatment, and whether society regards them as\n“ill”, including in some health systems whether they are\npermitted to receive treatment. As Tristram Engelhardt has argued,\n \nthe concept of disease acts not only to describe and explain, but also\nto enjoin to action. It indicates a state of affairs as undesirable\nand to be overcome. (1975: 127)  \nHence how we define disease, health, and related concepts is not a\nmatter of mere philosophical or theoretical interest, but critical for\nethical reasons, particularly to make certain that medicine\ncontributes to people’s well-being, and for social reasons, as\none’s well-being is critically related to whether one can live a\ngood life. \nThe terms “disease” and “illness” often are\nused interchangeably, particularly by the general public but also by\nmedical professionals. “Disease” is generally held to\nrefer to any condition that literally causes “dis-ease” or\n“lack of ease” in an area of the body or the body as a\nwhole. Such a condition can be caused by internal dysfunctions such as\nautoimmune diseases, by external factors such as infectious or\nenvironmentally-induced diseases, or by a combination of these factors\nas is the case with many so-called “genetic” diseases (on\nthe idea of genetic disease and associated problems, see for instance\nHesslow 1984, Ankeny 2002, Juengst 2004). It has been argued that\nthere is no philosophically or scientifically compelling distinction\nbetween diseases and other types of complaints that many would not\nconsider to be diseases such as small stature, obesity, or migraine\nheadaches (Reznek 1987). The notion of “disease” is common\namong most cultures, and may even be a universal concept (Fabrega\n1979). It is a useful concept as it allows a clear focus on problems\nthat afflict particular human beings and suggests that medicine can\nhelp to control or ameliorate such problems. In contrast,\n“illness” is usually used to describe the more\nnon-objective features of a condition, such as subjective feelings of\npain and discomfort. It often refers to behavioral changes which are\njudged as undesirable and unwanted within a particular culture, and\nhence lead members of that culture to seek help, often from\nprofessionals identified as health providers of some type within that\nculture (on some of the complexities relating to the triad of concepts\n“disease, illness, sickness”, see Hofmann 2002). \nThe term “sickness” emphasizes the more social aspects of\nill health, and typically highlights the lack of value placed on a\nparticular condition by society. Disease conditions are investigated\nnot only to be understood scientifically, but in hopes of correcting,\npreventing, or caring for the states that are disvalued, or that make\npeople sick. The classic work of the sociologist Talcott Parsons\n(1951) showed how the “sick role” relieves one of certain\nsocial responsibilities (for example, allows one to take time off work\nor to avoid family responsibilities) and also relieves blame for being\nill (though not necessarily from having become ill in the first\nplace). Although there are exceptions and counterexamples to this\nmodel (for example, some chronic diseases), it does fit our generally\naccepted societal notions of what it means to be sick (and healthy),\nand the moral duties and responsibilities that accompany the\ndesignation of someone as sick. \nThe dominant approach in much of the recent philosophical scholarship\non the philosophy of medicine views disease concepts as involving\nempirical judgments about human physiology (Boorse 1975, 1977, 1997;\nScadding 1990; Wachbroit 1994; Thagard 1999; Ereshefsky 2009). These\nso-called “naturalists” (sometimes called\n“objectivists”, for example see Kitcher 1997, or\n“descriptivists”) focus on what is biologically natural\nand normal functioning for all human beings (or more precisely human\nbeings who are members of relevant classes such as those within a\nparticular age group or of the same sex). They argue that medicine\nshould aim to discover and describe the underlying biological criteria\nwhich allow us to define various diseases. Christopher Boorse’s\nrevised account has been the most influential in the literature,\nclaiming that health is the absence of disease, where a disease is an\ninternal state which either impairs normal functional ability or else\na limitation on functional ability caused by the environment (Boorse\n1997). “Normal functioning” is defined in terms of a\nreference class which is a natural class of organisms of uniform\nfunctional design (i.e., within a specific age group and sex), so that\nwhen a process or a part (such as an organ) functions in a normal way,\nit makes a contribution that is statistically typical to the survival\nand reproduction of the individual whose body contains that process or\npart. His definition includes specific reference to the environment so\nas not to rule out environmentally-induced conditions which are so\ncommon as to be statistically normal such as dental caries. \nMany have criticized these approaches (to name just a few, Goosens\n1980; Reznek 1987; Wakefield 1992; Amundson 2000; Cooper 2002), as\nwell as naturalistic accounts of disease more generally. As they have\nnoted, naturalistic accounts do not reflect our typical usage of the\nterms “disease” and “health” because they\nneglect to take into account any values which shape judgments about\nwhether or not someone is healthy. The usual counterexamples proposed\nto naturalism are masturbation, which was widely believed to be a\nserious disease entity in the 18th and 19th\ncenturies (Engelhardt 1974), and homosexuality, which for most of the\n20th century was classified as a disease in the Diagnostic\nand Statistical Manual (DSM) of the American Psychiatric Association.\nThese are counterexamples as their redefinitions as non-disease\nconditions were due not to new biological information about these\nstates of being but changes in society’s moral values.\nNaturalists respond to such arguments by pointing out that\nhomosexuality and masturbation were never diseases in the first place\nbut erroneous classifications, and thus these examples do not affect\nthe validity of the definition of disease favored by them when it is\napplied rigorously. \nA more telling criticism of naturalism is that although its advocates\nclaim to rely exclusively on biological science to generate their\ndefinitions of health and disease, these rely implicitly on an\nequation of statistical and theoretical normality (or the\n“natural state” of the organism), at least in\nBoorse’s formulation (Ereshefsky 2009). But biology does not\ngive us these norms directly, nor is there anything absolutely\nstandard in “species design” (as many philosophers of\nbiology have argued) despite Boorse’s claims. No particular\ngenes are the “natural” ones for a given population, even\nif we take a subgroup according to age or gender (Sober 1980). Nor\ndoes standard physiology provide these norms (Ereshefsky 2009), not in\nthe least part because physiological accounts typically provide\nidealized and simplified descriptions of organs and their functions,\nbut not of their natural states (Wachbroit 1994). Rachel Cooper (2002)\ncompellingly argues that coming up with an acceptable conception of\nnormal function (and in turn dysfunction) is the major problem with\nBoorsian-style accounts, arguing that his analysis should focus on\ndisposition to malfunction instead. This argument utilizes\ncounterexamples such as activities that interfere with normal\nfunctioning such as taking contraceptive pills that are not diseases,\nas well as examples of persons with chronic diseases controlled by\ndrugs who function normally as a result. Elselijn Kingma (2007, 2010)\nhas critiqued Boorse’s appeal to reference classes as\nobjectively discoverable, arguing that these cannot be established\nwithout reference to normative judgments. A further issue often noted\nwith regard to naturalistic accounts of disease (for example, that of\nLennox 1995) is the underlying assumption that biological fitness\n(survival and reproduction) is the goal of human life, and along with\nthis that medicine is only considered to be interested in biological\nfitness, rather than other human goals and values, some of which might\nindeed run contrary to or make no difference in terms of the goal of\nbiological fitness, such as relief of pain. \nAn alternative approach in the philosophical literature to\nnaturalist/descriptivist/objectivist definitions of disease and health\ncan roughly be termed “normative” or\n“constructivist”. Most proponents agree that we must\ndefine the terms “disease” and “health”\nexplicitly and that our definitions are a function of our values\n(Margolis 1976; Goosens 1980; Sedgewick 1982; Engelhardt 1986). Hence\ndefining various disease conditions is not merely a matter of\ndiscovering patterns in nature, but requires a series of normative\nvalue judgments and invention of appropriate terms to describe such\nconditions. Conversely, health involves shared judgments about what we\nvalue and what we want to be able to do; disease is a divergence from\nthese social norms. Normativists believe that their definitions are\nvalid not only philosophically but also reflect actual usage of the\nterminology associated with disease and health both in common language\nand among medical professionals. They also claim that this approach\nmore adequately explains how certain conditions can come to be viewed\nin different ways over the course of history as our values changed\ndespite relatively few changes in our underlying biological theories\nabout the condition, for example homosexuality. Further, they are able\nto accommodate examples of so-called folk illnesses or culture-bound\nsyndromes such as ghost sickness among some Native American tribes,\nthe evil eye in many Mediterranean cultures, or susto in\nLatin and South American cultures, as their theories explicitly allow\nfor cross-cultural differences in understandings of disease and\nhealth. \nHowever normativism also generates a series of typical criticisms: it\ncannot cope adequately with cases where there is general agreement\nthat a state is undesirable (such as alcoholism or morbid obesity) but\nno similar general agreement that the state is actually a disease\ncondition (Ershefsky 2009). Another classic objection is that\nnormative accounts do not allow us to make retrospective judgments\nabout the validity of disease categories such as\n“drapetomania” (a disease which was commonly diagnosed\namong American slaves in the 19th century, with the main\nsymptom being the tendency to run away) (Cartwright 1851). The\nnormativist can point to changes in values to explain the abandonment\nof belief in this disease condition, but would not be able to claim\nthat the doctors were in any sense “wrong” to consider\ndrapetomania to be a disease. Hence there is more involved in our\neveryday usage of the terms “disease” and\n“health” than just value or normative conditions. \nHybrid theories of health and disease attempt to overcome the gaps in\nboth the naturalistic and normative approaches, by hybridizing aspects\nof both theories (Reznek 1987; Wakefield 1992; Caplan 1992). For\ninstance Jerome Wakefield (1992, 1996, 2007), writing about\npsychiatric conditions in particular, notes that a condition should be\nconsidered a disease if it both causes harm to the person or otherwise\ncontributes diminished value, and the condition results from some\ninternal mechanism failing to perform its natural function (hence for\ninstance much of what is diagnosed as “depression” would\nfail to count as a disease condition). Whereas the normativist is\ncommitted to calling any undesirable state a disease condition, these\nhybrid criteria rule out calling conditions “diseases”\nwhich are non-biological,. Then various marginal cases might be\nconsidered to be healthy rather than potentially described as\ndiseased, and hence might not be eligible for treatment within\nconventional medicine. Examples include those organs or structures\nthat no longer have a function due to evolutionary processes cannot\nmalfunction and so cannot be diseased. Many hybrid approaches also\nretain too many assumptions about their naturalistic components, and\nhence are criticized for relying on a notion of natural function which\ncannot be supported by biology. \nThe concept of health has been relatively undertheorized in comparison\nto those of disease and illness, perhaps in part because it raises\neven more complicated issues than these concepts describing its\nabsence. One could be a straightforward naturalist about health, and\ndefine it as being a product of a functional biology; however this\nargument would run afoul of the same criticisms of naturalism\nrecounted above (see Hare 1986). The source for the classic definition\nof health comes from the Constitution of the World Health Organization\n(WHO) which defines health  \na state of complete physical, mental and social well-being and not\nmerely the absence of disease or infirmity. (WHO 1948: preamble)  \nNotice that according to this formulation, health is not just the\nabsence of disease but a positive state of well-being and flourishing\n(notoriously ambiguous concepts in themselves). Although quality of\nlife is often cited as critical to definitions and theories of health,\nmany commentators are wary of the expansiveness of a definition\nsimilar to the WHO’s terminology, as it seems to encompass many\nthings beyond the health of the individual which could contribute (or\ndiminish) his or her “well-being”. \nA more narrow definition of health takes its rightful domain as being\nthe state which medicine aims to restore, and its opposite to be\n“unhealth” or falling short of being healthy, rather than\ndisease as such (Kass 1975). Under such a definition, medicine should\nnot engage in aesthetic surgery or elective terminations of pregnancy\nor similar procedures which do not (strictly speaking) seek to restore\nhealth. Caroline Whitbeck (1981) has defined health in terms of the\npsychological and physiological capacities of an individual that allow\nhim or her to pursue a wide range of goals and projects. Hence her\naccount is a type of hybrid approach, since she places biological\ncapacities at the core of her definition of health but only in so far\nas they help individuals to flourish and live their lives as they wish\nto do. The concept of health here is much more than the absence of\ndisease; for instance, one could have a high level of health while\nstill suffering from a particular disease condition. \nOne much discussed philosophical approach to defining health is that\nof Georges Canguilhem (1991, based on work in the early 1940s), who\nargued against equating it with normality. He noted that the concept\nof a norm could not be defined objectively in a manner that could be\ndetermined using scientific methods. Physiology deals with the science\nof norms, but even scientifically-based medical approaches should not\nfocus solely on norms, contrary to for instance the ideal vision of\nmedicine according to Claude Bernard (1865). The history of how the\ndistinction between the normal and pathological became so entrenched\nis explored in detail in Michel Foucault’s now classic work\n(1963). Both Foucault and Canguilhem sought to reveal how values have\nbeen built into the epistemological framework underlying modern\nmedicine. \nOne of the key points in Canguilhem’s argument is that our usage\nof the term “normal” often conflates two distinct\nmeanings: the usual or typical, and that which is as it ought to be.\nConsequently, he argues that there can be no purely scientific or\nobjective definition of the normal that allows us to take the theories\nof physiology and apply them in medical practice, and accordingly we\ncannot define health as normality either. Instead, according to him,\nhealth is that which confers a survival value, particularly\nadaptability within a set of environmental conditions: “to be in\ngood health is being able to fall sick and recover; it is a biological\nluxury” (1991: 199).\nDisease, then, is reduction in the levels of tolerance for the\nvagaries of the environment. As Mary Tiles (1993) has noted, this\nemphasis on health rather than normality is a particularly useful tool\nfor enriching contemporary debates over preventative medicine and more\ngenerally the trend toward the development of a positive conception of\nhealth. Havi Carel (2007, 2008) has contributed to this strand of\nthought, developing a phenomenological notion of health which\nemphasizes that health should be understood as the lived experience of\none's own body rather than as simply statistically normal bodily\nfunctioning in abstract biological terms. Hence she develops an\nexpressly revisionist project, emphasizing that a phenomenological\nperspective accommodates cases where someone is ill (in biological\nterms) but healthy, such as in chronic illness. \nA number of authors have made even more extreme claims, arguing that\nseeking concepts of disease is bound to be a failed effort. For\ninstance, Peter Schwartz (2007) claims that there is not an underlying\ngeneral concept of disease within the biomedical sciences that is\ncoherent enough to be analyzed, and that different concepts of disease\nmight be useful within different contexts. Some philosophers have\nargued that to seek correct definitions for “disease” and\n“health” is distracting and irrelevant when it comes to\nclinical decisions: as Germund Hesslow puts it, “the\nhealth/disease distinction is irrelevant for most decisions and\nrepresents a conceptual straightjacket [sic]” (1993: 1). The key is whether or not a\nparticular state is desirable to its bearer, and not whether the\nperson actually has a disease or defect. For instance, the term\n“malady” has been proposed as a more appropriate\nalternative to “disease” (Clouser, Culver, and Gert 1981),\nand which should be extended to include all illnesses, injuries,\nhandicaps, dysfunctions, and even asymptomatic conditions. A malady is\npresent when there is something wrong with a person; regardless of the\ncause (mental or physical), to be a malady, the condition must be part\nof its bearer and not distinct or external to him or her. The clear\nadvantage of this approach is that it unifies a range of phenomena and\ndescriptions that seem intuitively to be related. The disadvantages\ninclude that it relies in part on an objectivist approach to disease,\nand hence suffers from some of the difficulties detailed above that\nplague some versions of naturalism (for a provocative reaction to this\ndebate, see Worrall and Worrall 2001). \nAn alternative approach to defining disease and health has been\ndescribed by Marc Ereshefsky (2009) in terms of making distinct state\ndescriptions (descriptions of physiological or psychological states\nwhile avoiding any claims about naturalness, functionality, or\nnormality), and normative claims (explicit judgments about whether we\nvalue or disvalue a particular physiological or psychological state).\nThis approach has the advantages of allowing more clarity about\ncontroversial “disease” conditions as it avoids the need\nto apply the term explicitly. It also forces us to pinpoint the key\nissues that matter to understanding and treating someone suffering\nfrom ill health. But perhaps most persuasively, he argues that this\napproach allows us to distinguish the current state of a human from\nthose we wish to promote or diminish, whereas the terms\n“disease” and “health” do not adequately\nhighlight this critical distinction. \nIn short, philosophers of medicine continue to debate a range of\naccounts: in broad outline, the most vigorous disagreement centers on\nwhether more objective, biologically-based, and generalizable accounts\nare preferable to those that incorporate social and experiential\nperspectives. It is clear that none satisfy all of the desiderata of a\ncomplete and robust philosophical account that also can be useful for\npractitioners; although some would dispute whether the latter should\nbe a requirement, many believe that philosophy of medicine should be\nresponsive to and helpful for actual clinical practices. \nSome disease categories are far from straightforward in terms of being\nrecognized, named, classified, and made legitimate both within\nmedicine itself and for the wider society. In recent times there have\nbeen long-standing debates over a range of conditions including Lyme\ndisease, fibromyalgia, and chronic fatigue syndrome (CFS), to name\njust a few (for extended historical discussions of these and related\nconditions, see Aronowitz 1998, 2001; Shorter 2008). Take CFS as an\nexample: its main symptoms are fatigue after exertion over a period\nlasting at least six months, but sufferers can have a wide array of\ncomplaints in diverse systems of the body; the range of severity is as\nwide as the range of symptoms. The condition has been associated with\nseveral other controversial syndromes and sometimes equated to with\nthem, most notably myalgic encephalitis and fibromyalgia, as well as\nother illnesses of inexact definition such as multiple chemical\nsensitivity and irritable bowel syndrome; more popular (and\nderogatory) labels also have been attached to it such as yuppie flu.\nDefinitive evidence as to the cause or basis of CFS has remained\nelusive, and in the absence of causal explanations, accurate diagnoses\nand effective treatments often have been difficult to obtain. Thus the\nillness has been perceived by many as being illegitimate because of\ndifficulties in proving the existence of a discrete disease condition,\ngiven the lack of traditional forms of clinical evidence for it, and\nit has had different statuses in different locales (see Ankeny and\nMackenzie 2016). These issues severely impact on the lives of those\naffected by this condition, and on the care that is thought to be\nappropriate to be made available to them. \nMental illnesses (and the term “mental health” itself)\nalso have traditionally posed considerable problems for categorization\nand conceptualization for both medical practitioners and philosophers\nof medicine. Many authors advocate the case that it is critical to\nmake a distinction between mental and physical illness (Macklin 1972),\nparticularly because of the moral implications associated with\nlabeling a condition as mental or psychological. Psychiatry is a field\nwhich has historically been loaded with value judgments, many of which\nwere quite dubious. There is a long history of using mental illness as\na way to categorize behaviors which are socially deviant as well as\nthose conditions of ill health with no apparent organic cause and\nwhich do not otherwise fit into our dominant biomedical model. Many\nscholars (e.g., Ritchie 1989; Gaines 1992; Mezzich et al. 1996;\nHorwitz and Wakefield 2007; Demazeux and Singy 2015) have critiqued\napproaches and the underlying assumptions of the various editions of\nthe Diagnostic and Statistical Manual published by the American\nPsychiatric Association, which is a “bible” for\npsychiatric conditions for many practitioners and also has\nconsiderable public influence for instance on who can seek care. Key\nexamples of contested issues within the DSM include the highly\npoliticized nature of the processes of revision across various\neditions, various cultural, sexist, and gender biases inherent in\nspecific diagnostic categories, and the relatively weak reliability\nand validity of the classification system. \nOne key question is whether the biomedical model is the most\nappropriate approach to psychological or mental conditions and their\ntreatment. Some theorists have argued in favor of naturalistic\naccounts of disease, notably Thomas Szasz (1961, 1973, 1987). As a\nresult, he famously claimed that “mental diseases” are a\nmyth and do not exist because they do not result from tissue damage;\nin his view, all diseases must be correlated with this sort of\nphysical damage. He thus argues that the concept of mental illness is\na prescriptive concept used as though it were a merely descriptive\none, and also a justificatory concept masquerading as an explanatory\none. These conclusions lead him to a highly critical analysis of\npsychiatric practices, and to reclassifying such forms of suffering as\n“problems in living” rather than diseases. However it is\nnot always clear in his account what his evidence for these claims is,\nand in particular whether he is making an in principle objection or\none that is grounded in the history of the mistreatment of people with\nmental illnesses, and the disservice done to them in part because of\nthe adoption of the medical model. In addition, some have noted that\nsome psychiatric conditions do in fact correlate with physiologically\ndetectable and other types of biological abnormalities. For instance\ntwin studies have demonstrated that genetics is a major factor in the\netiology of schizophrenia among other conditions typically considered\nto be psychiatric, although clearly not all conditions that are\ndiagnosable according to contemporary psychiatric standards fit this\nmodel. \nA prominent functionalist approach to mental disorders more recently\nhas been that of Wakefield (1992, 1996, 2007), as discussed above, who\nargues that mental disorders are best understood as\n“harmful” dysfunctions, which permits a supposedly\nvalue-free foundation in terms of biological function gauged in\nevolutionary terms) with judgments coming in only in terms of the\njudgment of whether certain dysfunctions are harmful to their bearers.\nSuch accounts have been criticized along lines similar to analyses of\nBoorsian accounts by emphasizing that function and dysfunction cannot\nin fact be defined independently of value terms, but Wakefield’s\naccount also has been questioned in terms of its practical\nimplications (e.g., Sadler and Agich 1995) and whether malfunction is\na necessary component of mental disorder (Murphy and Woolfolk\n2000). \nOther authors, notably George Engel (1977), have argued for the need\nto unify our understandings of mental and physical illness under a\nbroader, biopsychosocial model. Such a model would focus clinicians to\ntake account of both the physical, psychological, and social factors\nthat contribute to ill health, in contrast to the traditional\nbiomedical model which is faulted for being overly reductionistic\nrather than holistic. Such an account, it is claimed, would be more\neffective in dealing with borderline cases including people who are\ntold they are in need of treatment due to abnormal lab results or\nsimilar but who are feeling well, as well as those who appear to have\nno underlying somatic disease condition but are feeling unwell. Hence\nthis type of account does not draw any sharp distinction between the\nphysical and the mental (or even the social), leaving the question of\nappropriate therapies or approaches as a matter to be decided by the\ndoctor and his or her patient. Engel compellingly defended this type\nof account as more appropriate not only for clinical work but for\nresearch and teaching in medicine. It is arguable that it has\nimplicitly (and often explicitly) been adopted in much of current-day\nmedical practice and teaching, although it is less clear whether it\nhas had much influence in biomedical research, much of which tends to\nremain more reductionistic in its nature. \nThere is no widely accepted notion of what a scientific theory is. The\nlogical positivists thought that theories are sets of\npropositions, formalizable in first-order logic, at one point, and as\nclasses of set-theoretic models at another. For our purposes here one\ncan distinguish two senses of theory, a narrower and a broader sense.\nIn the narrower sense, a theory comprises a set of symbols and\nconcepts used to represent the entities in a domain of discourse as\nwell as a set of simple general-purpose principles that describe the\nbehavior of these entities in abstract terms. In the broader sense,\ntheory refers to any statement or set of statements used to explain\nthe phenomena of a given domain. \nIn medicine one can find theories in both the narrower and the broader\nsense. Humorism, for instance, holds that the human body is filled\nwith four basic substances or “humors”: black bile, yellow\nbile, phlegm, and blood. The humors are in balance in a healthy\nperson; diseases are explained by excesses or deficiencies in one or\nmore humors. Humorism has ancient origins and influenced Western\nmedicine well into the 18th century. Eastern medicine has analogous\nsystems of thought. Indian Ayurveda medicine, for example, is a theory\nof the three primary humors wind, bile, and phlegm, and diseases are\nsimilarly understood as imbalances in humors (Magner 2002). \nIn contemporary Western medicine, such highly unifying and general\ntheories play a limited role, however. Evolutionary and Darwinian medicine may\nwell constitute exceptions but these are at best emergent fields at\npresent (see Méthot 2011). Contemporary Western medical\nresearchers and practitioners instead seek to explain medical outcomes\nusing mechanistic hypotheses about their causes—symptoms by\nhypotheses about diseases, diseases by hypotheses about antecedents,\nepidemics by hypotheses about changes in environmental or behavioral\nconditions (Thagard 2006). What distinguishes these contemporary\nmedical theories from the ancient approaches is that the causes of\nsymptoms, diseases, and epidemics can in principle be as multifarious\nas the outcomes themselves; in the ancient approaches, lack of humoral\nbalance was the only possible cause. In contemporary Western medicine, \nthere is no presupposition concerning number, form, or mode of action \nof the causes that explain the outcome other than there being \nsome cause or set of causes responsible. \nNot every cause is equally explanatory. A given person’s death\ncan be described as one by cardiac arrest, pulmonary embolism or lung\ncancer, for instance. The lung cancer may have had a genetic mutation,\nthe deposition of carcinogens in lung tissue and smoking in its causal\nhistory. The smoking, in turn, was caused by the smoker’s\nproneness to addictive behavior, peer pressure and socio-economic\nenvironment, let us suppose. Which of the many candidate hypotheses of\nthe form “X causes (or caused) Y”, where\nY refers to the patient’s death, does best explain the\noutcome? There is no absolute answer to this question. The goodness of\na medical explanation depends in part on the context in which it is\ngiven (see entry on\n scientific explanation).\n When asked “Why did Y happen?” a coroner might\nrefer to the pulmonary embolism, the patient’s physician to the\nlung cancer and an epidemiologist to the patient’s tobacco\nconsumption. The adequacy of a medical explanation is related to our\nability to intervene on the factor in question. A pulmonary embolism\ncan be prevented by screening the patient for blood clots. The\naccumulation of carcinogens in lung tissue can be prevented by\nstopping smoking. By contrast, even though certain kinds of genetic\nmutations are in the causal history of any cancer, the mutation is not\nat present of much explanatory interest to most clinicians, as this is\nnot a factor on which they can easily intervene. There is considerable\ncurrent medical research to identify mutations associated with various\nsubtypes of cancer and using these to develop targeted therapies and\ninterventions, as well as to provide more accurate prognostic\ninformation. Medical explanation, thus, is closely related to our instrumental \ninterests in controlling, preventing and controlling outcomes (Whitbeck 1977). \nOne issue that is currently debated in the philosophy of medicine is\nthe desirability (or lack thereof) of citing information about the\nmechanisms responsible for a medical outcome to explain this outcome.\nWhile mechanisms are usually characterized in causal terms (e.g.,\nGlennan 2002; Woodward 2002; Steel 2008), it is not the case that\nevery cause acts through or is a part of some mechanism, which is\nunderstood as a more or less complex arrangement of causal factors\nthat are productive of change (e.g., Machamer et al. 2000). Absences,\nsuch as lack of sunlight, can cause medical outcomes but are not\nrelated to them through continuous mechanisms from cause to effect\n(Reiss 2012). Neuroscientific explanations are often acceptable\ndespite the lack of knowledge or false assumptions about mechanisms\n(Weber 2008). However, we may ask whether mechanistic explanations are \ngenerally preferable to non-mechanistic causal explanations. \nMany medical researchers and philosophers of medicine subscribe to a\nreductionist paradigm, according to which bottom-up explanations that\nfocus on the generative physiological mechanisms for medical outcomes\nare the only acceptable ones or at least always preferable. Indeed,\nmacro-level claims such as “Smoking causes lung cancer”\nseem to raise more questions than they answer: Why does smoking have\nadverse health consequences? To prevent these consequences, is it\nnecessary to stop smoking? Is it possible to produce cigarettes the\nsmoking of which has fewer or no adverse consequences? What is the\nbest policy to improve morbidity and mortality from lung cancer?\nKnowing that it is specific carcinogens in tobacco smoke and genetic\nsusceptibility that are jointly responsible for the onset of the\ndisease helps to address many of these questions. \nNevertheless it would be wrong to assume that we cannot explain\noutcomes without full knowledge of the mechanisms responsible. When,\nin the mid-1950s, smoking was established as a cause of lung cancer,\nit was certainly possible to explain lung cancer epidemics in many\ncountries where people had exchanged pipe smoking for cigarette\nsmoking half a century earlier—even though the mechanism of\naction was not understood at the time. Differences in lung cancer\nincidence between men and women or between different countries can be\nexplained with reference to different smoking behaviors. Policy\ninterventions, in this case the addition of warning labels to\ncigarette packets, could not wait until sufficient mechanistic\nknowledge was available, nor did they have to wait. \nFor reasons such as these, a number of philosophers of medicine have\nproposed to adopt an “explanatory pluralism” for medicine\n(De Vreese et al. 2010; Campaner 2012). If nothing else, this is\ncertainly a position that is consistent with the explanatory practices\nin the field. \nAs in many fields, debates over reductionism versus holism are rife in\nmedicine both with reference to medical research and practice, and the\nterms often are used rather loosely to mean a range of things (for a\nrelated discussion see entry on\n  reductionism in biology).\n In the broadest terms, reductionistic approaches to disease look for\nfundamental mechanisms or processes that are the underlying causes of\nthat disease. In recent years in light of large-scale genomic\nsequencing initiatives notably the Human Genome Project, there has\nbeen considerable emphasis on reducing diseases to the genetic or\nmolecular level. Those who advocate more holistic approaches note that\nreductionism leaves out important information based on the\npatient’s experiences of the disease at the phenotypic level,\nand such information is critical to pursuit of effective treatments.\nMany diseases typically viewed as “genetic” have proven to\nbe extremely difficult in practice to reduce to unified disease\nentities with singular (or simple) genetic causes, including mental\nillnesses (Harris and Schaffner 1992), cystic fibrosis (Ankeny 2002),\nand Alzheimer’s disease (Dekkers and Rikkert 2008). As Catherine\nDekeuwer (2015) notes, given that there probably is genetic variation\nin susceptibility to virtually all diseases, there is no clear\ndemarcation between genetic diseases and diseases for which there are\ngenetic risk factors; hence she argues that our tendency to focus on\ngenetic determinants of disease may reinforce folk notions of the\ngeneticization of both people and of human behavior. \nWith regard to research, critics of reductionism point out that there\nhas been an overemphasis on the pursuit of genetic or molecular level\nexplanations of disease to the neglect of alternative levels of\nexplanation. Further, such limitations are highly detrimental to\npatients, especially because there are not likely to be short-term\ncures or treatments for most genetic diseases, perhaps beyond avoiding\nhaving children carrying particular genes in the first instance (see for instance \nHubbard and Wald 1999), although this domain of medicine is\nrapidly changing as new treatments are developed and the\nunderstandings of the effects of genomic mutations improve. Focusing\noverly or solely on the genetic level results in a process which the\nsociologist Abby Lippmann (1991) terms “geneticization”,\nnamely reducing the differences between individuals to their DNA, and\nin turn viewing genetics as the most promising approach to curing\ndisease, rather than viewing people and the illnesses that they suffer\nat a phenotypic and much more environmentally-situated level. In\naddition, as Elisabeth Lloyd (2002) argues, higher levels of social\norganization that are culturally sanctioned have unrecognized causal\neffects on health, and hence medical research should not be restricted\nsolely to the molecular level. \nFred Gifford (1990) claims that although all phenotypic traits are the result of an\ninteraction between genes and the environment within which they are\nexpressed, nonetheless it makes sense to distinguish certain traits as\n“genetic”; he argues in terms of populations that if it is\ngenetic differences that make the differences in that trait variable\nin a given population, and if genetic traits can be individuated in a\nway that matches what some genetic factors cause specifically, then a\ntrait (including a disease trait) can be understood as genetic. Kelly\nSmith (1992) disputes this, noting that the second condition depends\non an extremely problematic distinction between causes (in this case\ngenes) and mere conditions (e.g., epigenetic factors). Lisa Gannett\n(1999) argues for a “pragmatic” account of genetic\nexplanation, claiming that when a disease is classed as\n“genetic”, the reasons for singling out genes as causes\nover other conditions necessarily include pragmatic dimensions\ninasmuch as they are relative to a given causal background (which\nincludes both genetic and nongenetic factors), relative to a\npopulation, and relative to our present state of knowledge. More\nrecently it has been argued that although explanatory reduction cannot\nbe defended on metaphysical grounds, reductive explanations might be\nindispensable ways to address certain questions in the most accurate,\nadequate, and efficient ways (van Bouwel et al. 2011). \n“Evidence-based medicine” (EBM) describes a movement that\nwas started (under that name) in the early 1990s by a group of\nepidemiologists at McMaster University in Hamilton, Canada, as a\nreaction against what was perceived as an over-reliance on clinical\njudgment and experience in making treatment decisions for patients.\nAccording to a widely cited definition:  \nEvidence based medicine is the conscientious, explicit, and judicious\nuse of current best evidence in making decisions about the care of\nindividual patients. (Sackett et al. 1996: 312)  \nSuch a definition has bite only when the concept of evidence used is\nrelatively narrow. In particular, it should not allow clinical\njudgment and experience to count as “best evidence”. \nTo this effect, proponents of EBM have developed so-called\n“hierarchies of evidence” that categorize different\nresearch methods with respect to their supposed quality. While there\nis no universally accepted hierarchy, the different proposed\nhierarchies all agree in the priority they give to randomized\ncontrolled trials (RCTs) and reviews thereof. A typical hierarchy\nlooks as follows (Weightman et al. 2005): \nEvidence produced by RCTs has thus been called the “gold\nstandard” of evidence in EBM (e.g., by Timmermans and Berg\n2003). \nIn an RCT, a population of individuals who might benefit from a new\nmedical treatment are divided into a treatment group—the group\nwhose members receive the new treatment—and one or several\ncontrol groups—groups whose members receive either an\nalternative or “standard” treatment or a\nplacebo.  Individual patients are assigned to a group by means of a random process such as the flip of a coin. A placebo is an intervention that resembles the new treatment in\nall respects except that it has no known ingredients active for the\ncondition under investigation (i.e., it is some kind of “sugar\npill”). Patients, researchers, nurses, and analysts are all\nblinded with respect to treatment status of all patients until after\nthe analysis. After a period of time, a pre-determined outcome\nvariable is observed and the values of the variable are compared\nbetween the groups. If the value of the outcome variable differs\nbetween different treatment groups at the desired level of statistical\nsignificance, the treatment is judged to be effective. \nProponents of EBM regard RCTs as reliable means to judge treatment\nefficacy because they can help to control for a variety of (though not\nall) biases and confounders. If, for instance, the symptoms of a\npatient or group of patients improve after an intervention, this may\nbe due to spontaneous remission rather than the treatment. An\nexperimental design that compares a treatment group with one or\nseveral control groups is therefore better able to control for this\nconfounder than a simple “before-and-after” design.\nSimilarly, a design in which the allocation to treatment and control\ngroups is done by a non-random process, it is possible that healthier\npatients end up in the treatment and less healthy patients in the\ncontrol group. If so, the measured improvement may be due to the\nhealth status of the patients rather than the intervention. Especially\nif the allocation is done by a medical researcher who has a stake in\nthe matter (for instance because she has developed the new treatment),\nallocation decisions may consciously or subconsciously be influenced\nby expectations about who will profit from the intervention and thus\ncreate unbalanced groups. Allocation by a random process helps to\ncontrol this source of bias. \nNo one denies that RCTs are powerful experimental designs—and\nthat their power stems from the ability to control numerous sources of\nbias and confounding. However, to refer to RCTs as the “gold\nstandard” of evidence suggests that they are more. Specifically,\none may be led to assume that RCTs are necessary for reliable causal\ninference or that RCTs are guaranteed to deliver reliable results. A\nnumber of philosophers of medicine have in the past decade or so\nargued that these stronger claims do not hold to scrutiny. \nIn particular, the following claims have been criticized: \nA final but very important issue is that of the external validity of\nthe RCT results. Even under ideal conditions (i.e., when medical\nresearchers have very strong reasons to presume the assumptions under\nwhich an RCT works to be satisfied), the RCT can only establish that\nthe treatment is effective in the test population. Typical\ntest populations differ from the target populations (i.e., those\npopulations for whom the treatment has been developed and who will\neventually receive the treatment) in more or less systematic ways. For\nexample, many RCTs will exclude elderly patients or patients with\nco-morbidities but the treatment will be marketed to these patients.\nFor financial reasons, many RCTs are nowadays conducted in developing\ncountries whereas the treatments are mainly or exclusively marketed to\npatients in developed countries. Whereas the protocols for conducting\nan RCT are very strict and detailed, there are no good guidelines how\nto make treatment decisions when the patient at hand belongs to a\npopulation that differs from the population in which the RCT was\nconducted (e.g., Cartwright 2011). \nThere are in fact two problems of external validity in the application\nof RCT results. On the one hand there is the population-level problem\nof making an inference from test to target\npopulation. On the other hand, there is the problem of making an\ninference from population to individual. The RCT\nprovides evidence for a population-level claim: “In population\np (the test population) intervention X is effective\nin the treatment of condition Y”.  For this claim to be\ntrue, the treatment must be on average effective, which allows the\neffectiveness to vary among the individuals in the population. Indeed,\nit is possible that the intervention is effective (and beneficial) on\naverage but ineffective or positively harmful in some individuals\n(i.e., members of some subpopulations). Proponents of EBM to some\nextent oversell their case when they write that EBM  \nde-emphasizes intuition, unsystematic clinical experience, and\npathophysiologic rationale… and [instead] stresses the\nexamination of evidence from clinical research. (Evidence-Based Medicine Working Group 1992)\n \nbecause inferences from test to target population and from any\npopulation to the individual receiving the treatment are necessarily\nbased on clinical judgment. \nJohn Worrall argues that, at the end of the day, RCTs are a powerful\nmeans to control selection bias, but no more than that (Worrall 2002,\n2007a,b). As he uses the term, selection bias occurs when treatment\nand control group are unbalanced with respect to some prognostic\nfactors because a medical researcher has selected which patients will\nreceive which treatment. Selection bias in this sense obviously cannot\noccur in an RCT because in an RCT the allocation is made by a random\nprocess. But it is also clear that randomization is at best sufficient\nbut not necessary to achieve the result. A large number of alternative\ndesigns may be used to the same effect: allocation can be made by a\nstrict, albeit non-random protocol; allocation is made by non-experts\nwho are unrelated to the treatment development and therefore have no\nexpectations concerning outcomes; treatment and control groups are\ndeliberately matched (again by persons who have nothing at stake or\naccording to some protocol); and so on. \nA controversial issue is the role of mechanistic knowledge, that is,\nknowledge about the biological and physiological mechanisms\nresponsible for medical outcomes (and thus treatment efficacy) should\nplay in EBM. As mentioned above, the RCT provides evidence for\nblack-box causal claims of the form “In population p,\nintervention X is effective in the treatment of condition\nY”. As we have seen, proponents of EBM also believe EBM\nto de-emphasize patho-physiologic rationale (a different term for\n“mechanistic knowledge”). Nevertheless, a number of\nphilosophers of medicine have pointed out that mechanistic knowledge\nis in fact important in EBM or that it should receive more attention.\nFederica Russo and Jon Williamson have, for instance, argued that\ncausal claims need both statistical evidence as well as evidence about\nthe mechanisms that connect an intervention with the outcome variable\nin order to be established (Russo and Williamson 2007). Others\ndisagree (Reiss 2012) or qualify the claim (Gillies 2011; Howick\n2011a; Illari 2011). Further, it has been pointed out that mechanistic\nknowledge plays an important role in the design and preparation of an\nRCT, as well as in the interpretation and application of RCT results\n(La Caze 2011; Solomon 2015). Especially when it comes to\nextrapolating research results from a test to another population,\nmechanistic knowledge is supposed to be vital (Steel 2008; see also\nnext section). On the other hand, knowledge about mechanisms is often\nhighly problematic and should not be relied on too heavily in\napplications (Andersen 2012). \nNew therapies are often trialed using animal models before they are\ntested on humans in a randomized trial. Animal models also play\nimportant roles in establishing whether or not a substance is toxic\nfor humans. The International Agency for Research on Cancer (IARC),\nfor example, classifies substances with respect to the quality of the\nevidence for their carcinogenicity into five groups. Evidence from\nanimal models is referred to in the characterization of each group\n(IARC 2006). This raises questions about how such extrapolations from\nanimal models to humans work, and how reliable they are. \nAnimal models are widely used in biomedical research because\nexperimental interventions on animals are easier to conduct and\ncheaper than experiments on humans. Both kinds of experiments involve\nethical dilemmas, but animal experimentation is usually regarded as\nless problematic from an ethical point of view than experimentation\nwith humans. At any rate, the number of animals killed, maimed, or\nmade sick in biomedical research is much higher than the number of\nhumans adversely affected in this research. \nThere is a fundamental inferential problem in transferring what has\nbeen learned in any model (whether human, animal, or whatever) to some\ntarget population of interest has been described as the\n“experimenter’s circle[special-character:rdquo (Steel 2008). The problem is essentially this. What is true of a model \ncan be presumed to be true\nof the target only to the extent that the model is similar to the target\nin relevant respects. The reason we experiment on models in the first\nplace is, however, that the model differs in important respects from\nthe target (if animals were just like humans, we would not find\nexperiments on the former to be ethically less problematic than\nexperiments on the latter). Extrapolation—the inference from\nmodel to target—is therefore only worthwhile to the extent that\nthere are significant limitations in our ability to study the target\ndirectly. If so, there can be no good grounds to decide whether a\nmodel is a good one for the target. To do so, we would have to\ninvestigate whether the target is relevantly similar to the model; but\nif we could do so, there would be no reason to study the model in the\nfirst place. \nThis inferential problem has led some commentators to maintain highly\nskeptical views concerning our ability to use animals as models for\nhumans in biomedical research. Hugh LaFollette and Niall Shanks argue\nthat animal models cannot be reliably used for extrapolation at all,\nbut at best only heuristically, as sources of hypotheses that have to\nbe tested on humans (LaFollette and Shanks 1997). They introduce two\nterms to make their argument: causal analogue model (CAM) and\nhypothetical analogue model (HAM). The former can be used to make\nreliable predictions about target populations of interest; the latter\nonly heuristically. The main premise in their argument that animal\nmodels in biomedical research are at best HAMs but not CAMs is that\nfor a model to be a CAM there cannot be causally relevant disanalogies\nbetween model and target—a condition which is rarely if ever met\nby animal models (again, this is why we study animals in the\nlaboratory in the first place). \nDaniel Steel (2008: ch. 5) argues that LaFollette and Shanks’\ncondition for reliable extrapolation is too stringent. Whether a claim\nabout a model can be extrapolated depends, he argues, also on the\nstrength of the claim to be exported. It is one thing, say, to reason\nfrom  \nx% of the members of population p will show symptoms\nof poisoning after ingesting substance S  \nto  \nx% of the members of population \\(q \\ne p\\) will show\nsymptoms of poisoning after ingesting substance S,  \nquite another to reason from the quantitative claim to a qualitative\nclaim such as “Substance S is poisonous for the members\nof q”. \nSteel’s own reconstruction of how extrapolation works in the\nbiomedical sciences is called comparative process tracing. He\nassumes that causes C (such as medical interventions or the\ningestion of toxic substances) bring about their effects E\n(such as the appearance of symptoms or improvements or deteriorations\nof symptoms) through a series of steps or stages. To trace a causal\nprocess means to investigate through what set of stages C\nbrings about E. Process tracing is comparative when the set\nof stages through which C brings about E in one\nspecies or population is compared to the set through which it does so\n(if it does so indeed) in another. \nComparative process tracing would be futile if, in order to know that\nC causes E in the target species or population, we\nwould have to compare all the stages of the process between\nmodel and target. This is because in order to do so, we would have to\nknow all stages of the process through which C causes\nE, but if we did, we would already know that C\ncauses E. This brings us back to the extrapolator’s\ncircle. Steel now argues that comparative process tracing avoids the\nextrapolator’s circle by demanding processes to be compared only\nat stages where they are likely to differ and assuming that\ndifferences between model and target matter only to stages that are\ndownstream from where they obtain. Thus, if we compare an intermediate\nstage of the process which obtains in the model with that stage in the\ntarget and find them to be relevantly similar, then the only\ndifferences that may still obtain will be downstream from this stage.\nWe therefore do not require knowledge of the entire process from\nC to E in the target, and the extrapolator’s\ncircle is successfully avoided. \nHow useful comparative process tracing is as a method for\nextrapolation for the biomedical sciences depends on how reliable the\nassumption that only downstream differences matter to extrapolation\nis, the reliability with which stages where there might be differences\nbetween model and target can be identified and the reliability of our\nmechanistic knowledge more generally. If, say, our reasons for\nsupposing that C causes E through a series of stages\nX, Y, Z in the model, or that X\nand Z are the stages where model and target are likely to\ndiffer, are not very strong, then the method does not get off the\nground. This is an issue that depends on the quality of the existing\nknowledge about a given case and cannot be addressed for the\nbiomedical sciences as a whole. There are certainly some examples of\nwell-established causal claims where it is known only that C\ncauses E but the details of the causal process are entirely\nbeyond our current grasp (Reiss forthcoming-a). \nAn alternative to comparative process tracing that has been\nproposed is extrapolation by knowledge of causal capacities.\nIf C has a causal capacity to bring about E, then\nC causes E in a somewhat stable or invariant manner.\nSpecifically, C will then continue to contribute to the\nproduction of E even when disturbing factors are present\n(Cartwright 1989). To establish that C has the causal\ncapacity to cause E therefore means to show that\nC’s causing E is independent of the background\nin which C and E occur to some extent. And\ntherefore, if C causes E in a model species or\npopulation and C has the causal capacity to bring about\nE, then there is some reason to believe that C\ncauses E also in the target species or population (for a\ndefense, see Cartwright 2011). \nThe usefulness of the method of extrapolation by causal capacities\ndepends, among other things, on the extent to which biomedical factors\ncan be characterized as having capacities. Many biomedical causes do\nindeed have some degree of stability. The sickle cell trait is 50%\nprotective against mild clinical malaria, 75% protective against\nadmission to the hospital for malaria, and almost 90% protective\nagainst severe or complicated malaria (Williams et al. 2005). These\nfigures suggest a reading along the lines of,  \nin the presence of the sickle cell trait (a preventer of/disturbing\nfactor for malaria), infection with Plasmodium malaria\ncontinues to affect outcomes consistently. (Reiss 2015b: 19) \nBut there is a high degree of interaction with other factors as well.\nWhether or not a substance is toxic for an organism depends on minute\ndetails of its metabolic system, and unless the conditions are just\nright, the organism may not be affected by the substance at all. To\nwhat extent this method will be successful therefore similarly\ncase-dependent as comparative process tracing. \nAs we can see, there is no general answer to the question whether or not\nanimal studies are valuable from a purely epistemic (as opposed to\nethical, economic, or combined) view. Other authors have developed a\npractice-based taxonomy of animal modes to allow more accurate\nassessment of the epistemic merits and shortcomings, and predictive\ncapacities of specific modeling practices (Degeling and Johnson 2013).\nThere is much evidence that species differ enormously with respect to\ntheir susceptibility to have toxic reactions to substances. Thus,\nwhile it is very likely that for any one toxin, there is some species\nthat is predictive of the human response, it is often hard to tell\nwhich one is most appropriate for any particular toxin. A species that\npredicts the human response well for one substance may be a bad model\nfor another. However, some authors suggest that extrapolations \nfrom animal models have been made successfully in at least some cases (Steel 2008\ndiscusses the extrapolation of claims concerning the carcinogenicity\nof aflatoxin from Fisher rats to humans; see Reiss 2010a for a\ncritical appraisal and Steel 2013 for a response). \nFrequently, in the biomedical sciences, reliable animal or other\nnon-human models are not available and RCTs on humans are infeasible\nfor ethical or practical reasons. In these and other cases, biomedical\nhypotheses can be established using observational methods. As we have\nseen in\n Section 5,\n evidence-based medicine regards observational methods as generally\nless reliable than RCTs and other experimental methods. This is\nbecause observational studies are subject to a host of confounders and\nbiases that can be controlled when the hypothesis is tested by\na—well-designed and well-conducted—RCT. But it is not the\ncase that observational methods cannot deliver reliable results. In\nfact, it is well possible that the medical knowledge that has been\nestablished observationally by far exceeds the knowledge that comes\nfrom RCTs. Here are some examples of medical interventions that are\nwidely accepted as effective but whose effectiveness has not been\ntested using RCTs: penicillin in the treatment of pneumonia, aspirin\nfor mild headache, diuretics for heart failure, appendectomy for acute\nappendicitis and cholecystectomy for gallstone disease (Worrall 2007a:\n986); automatic external defibrillation to start a stopped heart,\ntracheostomy to open a blocked air passage, the Heimlich maneuver to\ndislodge an obstruction in the breathing passages, rabies vaccines and\nepinephrine in the treatment of anaphylactic shock (Howick 2011b,\n40). \nObservational studies often begin by reporting a recorded correlation\nbetween a medical outcome of interest and one or a set of independent\nvariables: lung cancer rates are higher in groups of smokers than in\ngroups of non-smokers, liver cancer rates are higher in populations\nthat tend to consume food that has been contaminated with aflatoxin\nthan in populations whose food is uncontaminated, to give a few\nexamples. That smoking causes lung cancer, or aflatoxin cancer of the\nliver, would indeed account for the observed correlations. But so\nwould a variety of other hypotheses. Generally, if two variables\nX and Y are correlated, it may be the case that\nX causes Y, Y causes X or a common\nfactor Z causes both X and Y (or a\ncombination of these). In the smoking/lung cancer case, all three\nhypotheses were invoked as possible accounts of the data. Ronald\nFisher famously proposed that it may be the case that early stages of\nbronchial carcinoma cause an individual to crave cigarettes, and he\nprovided some evidence that both smoking behavior and susceptibility\nto lung cancer have a common genetic basis (Fisher 1958). Moreover, it\nis possible that the correlation itself is spurious—that the\ndata are correlated as per some measure of correlation such as\nPearson’s coefficient, but that the underlying variables are not\nin fact correlated in the population of interest. Selection bias is\nnormally understood as the bias that obtains when individuals\nself-select into the observed population and the reasons for which\nthey do so are correlated with the outcome variable. If an\nobservational study examines only hospitalized patients and smokers\nare more likely to be in hospital for reasons that have nothing to do\nwith lung cancer, then smoking and lung cancer can be correlated in\nthe data even if the variables are independent in the general population.\nMismeasurement and diagnostic error provide another account of spurious correlation.\nSuppose tuberculosis was on the rise a generation or so after many\npeople traded pipe smoking for cigarette smoking. Then, if it was\ndifficult to distinguish a death from tuberculosis from a death from\nlung cancer because necropsy techniques were not sufficiently well\ndeveloped, the data might again show a correlation even though the\npopulation variables are uncorrelated. \nRetrospective observational studies work by ruling out alternative\nhypotheses such as these ex post rather than controlling for\nthem ex ante as RCTs do (Reiss 2015a). In an RCT,\nmismeasurement should not obtain because the protocol specifies\nmeasurement procedures for the outcome variables in great detail in\nadvance. Selection bias should not obtain because patients are\nrandomized into treatment groups. Once allocated to a group, they are\nprevented from obtaining another treatment elsewhere, and researchers\nmake sure that patients comply with the treatment regime. But there\nare equivalent means to rule out these possibilities in observational\nsettings. While it may well be the case that early stages of cancer\ncause a craving for cigarettes, this hypothesis cannot explain the\nprotective effect that stopping smoking has. At the time of the\nsmoking/lung cancer controversy in the mid-1950s, misdiagnosis was\nindeed a problem. However, it could be shown that in order to account\nfor the observed rise in lung cancer incidence, the diagnostic error\nat autopsy among older people would have to have been an order of magnitude \nhigher than the diagnostic error among younger people (Gilliam 1955).\nMismeasurement could therefore also be ruled out. Similar\nconsiderations helped to rule out other alternative hypotheses\n(Cornfield et al. 1959). \nEven if one were to believe, with the proponents of EBM, that\nobservational studies are generally less reliable than RCTs, medicine\ncould—fairly obviously—not do without them. There are\nlarge numbers of pressing questions that could not be addressed by an\nRCT for ethical, financial and other practical reasons. No-one would\nseriously consider testing a proposition such as “Aflatoxin\ncauses cancer of the liver (in humans)” by an RCT. This is not\nmerely because of the straightforward ethical issues involved in\ndeliberately exposing humans to a potential carcinogen for the sake of\nmedical progress. It is also because exposure to low levels of aflatoxin can\ntake many years or even decades to produce symptoms. The ability of\nresearchers to control food intake in a large group of experimental\nsubjects for a very long has evident practical financial and\nlimitations. RCTs can also not be used when researchers or patients or\nboth cannot be blinded, and many medical interventions do require the\ndoctor’s or the patient’s knowledge of details about the\nintervention. \nMoreover, it is not clear that RCTs are always more reliable than\nobservational studies to answer questions both methods are able to\naddress. Whether or not a study is reliable depends on whether or not\nconfounders and biases have in fact been eliminated, not by which\nmethod they have been eliminated. Issues concerning the reliability of\na method can be entangled with issues concerning its ability to\naddress the research question the biomedical scientist seeks to\nanswer. Both RCTs and observational studies in the biomedical sciences\nare typically employed to test rather complex hypotheses about the\nsafety and efficacy of medical interventions. It may well be that some\nof the issues are more reliably treated by one method and others by\nthe other. \nA famous controversy in which the results from observational studies\nand those from RCTs conflicted was that over the benefits and safety\nof hormone replacement therapy (HRT) in the early 2000s (Vandenbroucke\n2009). HRT seemed protective for coronary heart disease in\nobservational studies, whereas RCTs indicated an increase in the first\nyears of use. For breast cancer, combined hormone preparations showed\na smaller risk in an RCT than in observational studies. In the end it\nturned out that the timescale of the effects was responsible, and that\nbecause of the way they are typically run, observational studies got\nsome issues right and RCTs others: \nThe observational studies had picked up a true signal for the women\ncloser to menopause. In the randomised trial, that signal was diluted\nbecause fewer women close to menopause were enrolled… The\nrandomised trials had it right for coronary heart disease but failed\nto sufficiently focus on women close to menopause for breast cancer.\nThe main reasons for the discrepancies were changes of the effects of\nHRT over different times… (Vandenbroucke 2009: 1234) \nCase reports remain extremely popular in medicine both as publications\nto communicate within the field and for pedagogical purposes. In\nshort, a case report describes a medical problem experienced by one or\nmore patient, usually involving the presentation of an illness or\nsimilar that in some way difficult to explain or categorize based on\nexisting understandings of disease or understandings of physiology and\npathology. Cases in medicine take highly standardized forms of\npresentation which are inculcated in health care professionals during\ntheir education, and many have commented on their highly standardized\nnarrative structure and its epistemic and other implications (Hunter\n1991; Hurwitz 2006). Cases typically provide details on the\npresentation of the disease, diagnosis, treatment, and outcomes for\nthe patient, with a focus on practice-based observations and clinical\ncare (rather than the results of randomized controlled trials or other\nexperimental methodologies). One of the purposes of cases is to gather\ndetailed information including facts that may not be immediately\nrelevant, but that could prove to be (Ankeny 2011). Thus the\ninformation contained in the case and the case itself can be useful\nover the long term particularly if it can be systematically combined\nwith other cases into larger datasets. \nSingle cases are seen by some as problematic as a form of evidence\nparticularly in the era of EBM, because they often focus on highly\nunusual manifestations of illness and disease, rather than typical or\nrepeatedly observed conditions that might support generalizable rules.\nThis feature has led some to describe medicine as a “science of\nparticulars” (Gorovitz and MacIntyre 1976), or as an art rather\nthan a science (Pellegrino 1979), particularly in processes of\ndiagnosis (see\n Section 9).\n However standard accounts of EBM include the case series as a type of\nevidence, which involves the aggregation of individual cases of\npatients with similar attributes (e.g., who received the same\ntreatment or therapy) who are tracked over time using descriptive data\nand without utilizing particular hypotheses to look for evidence of\ncause and effect. EBM does place the case series quite low in its\nhierarchy of evidence but nonetheless it is acknowledged that cases\nhave potential usefulness especially where forms of evidence that rate\nmore highly are not available, as may often be the case where human\npatients are concerned due to practical or ethical reasons, or where\nthe available evidence at higher levels has been produced in a manner\nthat is methodologically or otherwise flawed. \nCases can serve other purposes: for instance analyses of cases can\nprovide working hypotheses about casual attribution that can ground\nfurther tests of causal relations (Ankeny 2014), which in turn allows\nuse of more traditional methodologies such as RCTs, cohort studies,\nand so on to explore these causal hypotheses. In the context of\nclinical care, cases can allow health care providers to identify a\ncause that can be manipulated to cure (or prevent) the condition in\nquestion, in order to treat ill patients, even in the absence of more\nrigorous forms of evidence. \nDiagnosis is the process through which a clinician determines what is\nwrong with a patient who is ill or ailing in some way. Although a\ncritical part of the practice of medicine, it has been relatively\nneglected in the literature of philosophy of medicine particularly in\ncomparison to more statistically-based methods for evaluating evidence\nin other fields (Stanley and Campos 2013). The key philosophical\nissues that arise in this context relate to how such determinations\ncan be made in a manner that is accurate given the high amount of\nuncertainty and complexity often associated with the human condition,\nand hence involve logical, epistemological, and ontological issues.\nThe usual way of proceeding in a clinical setting is to ask the\npatient to articulate what is ailing him or her, and thus to use a\nstandardized reporting format to detail various symptoms which\nrepresent subjective manifestations of the illness or disease. In\naddition, clinicians perform various tests and examinations that allow\nmore objective manifestations or signs to be recorded, such as heart\nrate, blood pressure and count, reflexes, and so on. A perennial\ndebate in the philosophy of medicine is what constitutes symptoms and\nsigns and whether they are in fact distinct, which relates to deeper\nissues about the realism of disease conditions as discussed above\n (Section 2). \nThe tricky part of the process is to find a means for mapping these\nsymptoms and signs onto a particular disease condition. Some would\nadvocate that this process is no different than usual methods in\nphilosophy of science for hypothesis generation and testing based on\nevidence, and this type of model fits with what is termed differential\ndiagnosis. Differential diagnosis involves a set of hypothetical\nexplanations for a particular condition which come to be ruled in (or\nout) based on the evidence together with additional data that is\ncollected, hence relying on a form of reasoning via decision nodes or\nalgorithmic pathways (Stanley and Campos 2013). However, the details\nof the rules of reasoning that underlie this sort of process remain\nlargely unarticulated, as does the amount of “tacit”\nknowledge that may contribute to diagnostic reasoning. \nThere are various ways in which diagnosis is taught and\noperationalized in clinical settings: in some subspecialties in\nparticular, “pattern” recognition often using pictorial\nrepresentations seems to be common, and hence diagnosis is a form of\nrecognizing repeated patterns. However this approach can be dangerous\nparticularly among novices, given the large number of similar patterns\namong common diseases. Some have claimed that the making of a\ndiagnosis is both a deontic act and computable, and that diagnoses are\nrelative only inasmuch as they occur in a complex context which in\nturn makes them a social practice (Sadegh-Zadeh 2011).\nComputer-assisted diagnostic techniques have improved and are used\nincreasingly in clinical settings; Kenneth Schaffner (1981) provided\nan early analysis of the criteria which an ideal diagnostic logic\nwould need to satisfy (for updated discussions see Schaffner 1993,\n2010, and for arguments about the limitations of such types of\ndiagnosis see Wartofsky 1986). In recent years there is a relative\nconsensus among medical professionals and those involved in medical\ninformatics that medical diagnosis almost certainly relies on some\nform of “fuzzy logic” (e.g., Sadegh-Zadeh 2000; Barro and\nMarin 2002). \nAs we have seen in\n Section 5,\n hierarchies of evidence in evidence-based medicine rank study results\nfrom “systematic” clinical research such as RCTs and\nobservational studies higher than “unsystematic” expert\nopinion. The epidemiologists who initiated the formal EBM movement in\nthe early 1990s had good reason to be skeptical about expert opinion.\nWhen therapies are subjected to systematic tests, tradition and expert\nopinion are sometimes shown to be flawed. John Worrall discusses three\nexamples: grommets for glue ear, ventricular ectopic beats repressing\nsubstances such as encainide or flecainide for cardiac arrest, and\nroutine fetal heart rate monitoring to prevent infant death (Worrall\n2007a: 985). In each case we have a procedure the effectiveness of which is\nindicated by common sense and knowledge about the patho-physiological\npathways—glue ear is a condition produced by a build-up of fluid\nin the middle ear that is unable to drain away because of pressure\ndifferentials, grommets act by letting air into the middle ear and\nthereby equalizing pressure, for instance—but which, when tested\nby a randomized trial, turns out to be ineffective at best and\npositively harmful in the worst case. \nMisjudgments concerning the efficacy of therapies for purely epistemic\nreasons are not the only worry that one might have about expert\nopinion. Medical experts and patients are in what economists call a\nprincipal-agent relationship. The principal—in this case, the\npatient—desires the delivery of a certain good or\nservice—in this case, his health. He instructs an agent—in\nthis case, the doctor—with it, because he lacks the expertise to\nproduce the good himself. The good can only be produced with\nuncertainty: no therapy is 100% effective. Moreover, the success at\ndelivering the good depends in part on the agent’s effort. The\ndoctor may not always choose the optimal therapy for a patient (we can\nsuppose that it takes some effort to select the optimal therapy for a\npatient), and any therapy can be implemented sloppily. Moreover,\nlacking expertise, the patient cannot observe the level of effort a\ndoctor puts in. He therefore cannot design a contract that makes\npayments dependent on level of effort (much less on success, as\nsuccess is in part influenced by factors outside of either\nparty’s control). Agents therefore have an incentive to cheat:\nnot to put in the level of effort required to select and deliver the\noptimal therapy from a patient’s point of view. \nIf patients and doctors were perfectly rational and motivated only by\ntheir own material welfare, and in the absence of regulation, there\nsimply wouldn’t be a market for health services. Doctors would\nchoose therapies that are best for them and not for patients, and\npatients would anticipate this behavior and stop seeking\ndoctor’s services in the first place. In our world, neither\npatients nor doctors are particularly rational, nor are they motivated\npurely by self-interest, there are ethical codes such as the modern\nform of the Hippocratic Oath, and the health sector is one of the most\nregulated industries of all. All this does not, however, change the\nincentive structure in which doctors and other providers of health\nservices operate. Because they and not the patients are experts, they\nhave incentives to choose therapies that are in their best interests\nand not in the patients’ interests. \nThere is a further complication. Many, probably most, doctors have\nconnections to the pharmaceutical industry in one form or another.\nAccording to one study, 94% of U.S. physicians receive financial\nbenefits from the pharmaceutical industry (Bekelman et al. 2003). Even\nif we suppose that doctors do not prescribe a therapy because they are\npaid to do so, marketing efforts directed at them will influence\ntreatment recommendations, if only because they know certain pills\nbetter than others, or because some treatments are at the top of their\nheads. \nFor all these reasons, the EBM principle that treatment decisions\nshould be based on the best available evidence from systematic\nresearch does not come out of nowhere. If, say, there is an RCT or an\nobservational study that reports that treatment X is more\neffective at relieving symptoms S than treatment Y,\nit would seem bad to recommend a patient who suffers from S\nto take Y because his GP doesn’t know about X,\ndoesn’t know the study result, personally profits from\nprescribing Y or is inattentive. However, while these are all\nbad reasons to recommend Y over X in the light of\nthe study result, there may be a variety of good reasons. \nAs discussed in\n Section 5,\n RCTs and many observational studies are population-level studies,\nwhich produce average results that are not straightforwardly\napplicable to individuals. If, say, treatment X reduces the\nrisk of suffering from some adverse event over a period of time by 50%\nin population p, that is, the risk ratio (RR) for this\ntreatment is 50%, then there may be no individual in p for\nwhom the treatment halves the risk. Instead, the RR may vary\ndramatically among the subpopulations of p, and it may well\nbe the case that Y is more effective than X for some\nsubpopulations. \nThe same is true of side effects. Tonelli (2006) discusses a case\nwhere a patient who suffers from multiple sclerosis receives a\ntreatment that does seem to alleviate her symptoms, but since she has\nstarted taking it, she has been plagued by severe episodes of\ndepression. Clinical trial results indicate that the drug is effective\nin treating multiple sclerosis, and no adverse psychiatric effects\nhave been reported. Her GP and her psychiatrist now debate whether to\ncontinue the treatment. There are various reasons why the clinical\nstudies do not show evidence of mental health effects: the trial\nsubjects weren’t properly screened for depression; adverse\neffects were found but not reported; the adverse effects were not\nstatistically significant—but they may have been clinically\nsignificant for some subpopulations; the side effects only obtain in\npopulations that differ from the trial populations. \nThis case shows that a treatment’s effectiveness in relieving\nthe symptoms of the disease for which it was prescribed is not the\nonly consideration when making a treatment decision. The goal of the\ntreatment is to improve the patient’s wellbeing, which is well\nrecognized by the proponents of EBM. A patient’s wellbeing has\nmany components, of course, and the symptoms of any given disease are\nat best one element in its determination. This is another reason why\nclinical judgment must be exercised in the derivation of a treatment\nrecommendation. \nUnfortunately, experts—like all humans—are notoriously bad\ndecision makers. Cognitive psychologists have established a large\nnumber of cognitive biases to which human experts are subject: they\nsuffer from overconfidence (e.g., Dawes and Mulford 1996) and\nhindsight bias (e.g., Fischhoff 1975; Hugh and Dekker 2009); are\nregularly outperformed by simple mechanical algorithms (e.g., Grove\nand Meehl 1996); commit the conjunction fallacy (Tversky and Kahneman\n1983; Rao 2009), and many others. \nTo give an example for a simple mechanical algorithm outperforming\nexperts, consider the Goldberg Rule, according to which a patient is\nto be qualified as neurotic if \\(x = (\\textrm{L} + \\textrm{Pa}+\n\\textrm{Sc}) - (\\textrm{Hy} + \\textrm{Pt}) > 45\\) (where L is a\nvalidity scale and Pa, Sc, Hy, and Pt are clinical scales of a\nMinnesota Multiphasic Personality Inventory or MMPI test) and as\npsychotic otherwise. Lewis Goldberg tested the rule on a set of MMPI\nprofiles from 861 patients who had been diagnosed by the psychiatric\nstaff in their hospital or clinic and found it to be 70% accurate;\nclinicians’ accuracy ranged from 55% to 67% (Goldberg 1968; for\na discussion, see Bishop and Trout 2005). \nThere is no one strategy to deal with the various biases and interests\nthat affect clinicians’ judgments. Better numeracy and\nstatistical training at universities can help to eliminate some\ncognitive biases (Gigerenzer 2014). Computer-aided medical diagnosis and decision making\nmay alleviate others. No training or computer program can make\nnormative judgments, however, and neither will help with adverse\nincentive structures and financial interests. These difficulties also\nbeset committees of medical experts to which we are turning\nnext. \nOne way to help overcome expert bias is by making medical decisions\nnot dependent on individual expert judgments but instead have groups\nof experts coming to some form of aggregate judgment. The U.S.\nNational Institutes of Health, for instance, used to organize\nso-called consensus conferences designed to resolve scientific\ncontroversy. Panel members are chosen from clinicians, researchers,\nmethodologists and the general public. Federal employees are not\neligible, nor are researchers who have published on the subject at\nhand or have financial conflicts of interest (Solomon 2007). These\nexclusions are intended to contribute to controlling government\ninfluences as well as any biases due to financial or intellectual\ninterests. \nConsensus conferences and other mechanisms for reaching group\njudgments are clearly no panacea. Miriam Solomon (2015), for instance,\nargues that consensus conferences tend to “miss the window of\nepistemic opportunity” in that they often take place after the\nmedical community has already settled an issue. More important in the\npresent context is the observation that while these conferences\npossibly help to control some forms of partiality, they are\nineffective in reducing others and may be responsible for the\nintroduction of new biases. One concern is that panel members may read\nthe existing evidence selectively, for instance, because of weighing\nsalient studies or studies that are available to them more heavily.\nAnother is that phenomena such as groupthink (Janis 1982) and peer\npressure may influence results. In an NIH consensus conference panel\nmembers have to come to a verdict after only two days of hearings and\ndeliberations. Under these conditions it is certainly possible that\nmore outspoken panel members or those who perform well under extreme\npressure have a undue influence on results. Moreover, it is not clear\nthat excluding clinicians who have published on the issue at hand is\nalways such a good idea. After all, it is not implausible to maintain\nthat those scientists who actively work on a research topic are those\nwho best understand it and therefore can make the best informed\njudgments. For these and other reasons, Solomon (2007, 2015) explores\nthe consequences of judgment aggregation. In this process group\nmembers typically do not deliberate but instead cast their opinions\nwhich are then aggregated using some pre-determined procedure. The\nmajority rule would be a simple example of such a procedure. \nComing to a group judgment using a mechanical procedure such as\nmajority vote has a number of advantages. First, there are epistemic\nadvantages that can be illustrated by Condorcet’s Jury Theorem.\nThis theorem shows that if (a) the judgment concerns a proposition\nthat can either be true or false, (b) jury members have an independent\nprobability \\(>.5\\) that they get the judgment right, (c) the\nindividual judgments are aggregated using majority vote, then the\nlarger the jury, the more likely it is to reach the correct group\njudgment. Under these conditions, then, a committee of experts is\nlikely to make a better judgment than a single expert. Moreover, in\nthe absence of deliberation and pressure to come to a unanimous\nresults, and when voting is secret, the influence of groupthink, peer\npressure etc. is attenuated or eliminated. \nWhen conditions (a)–(c) do not hold, results are more ambiguous\nor even negative. When experts are not reliable, i.e., the individual\nprobability of getting the judgment right is \\(<.5\\), the larger\nthe group, the less likely is it to reach a correct group\njudgment and the optimal group size is a single expert. When the\noutcome can have more than two values, inconsistent results can\nobtain. This can easily be demonstrated with an example in which there\nare three possible outcomes and three experts. Suppose, for instance,\nthat a panel has to decide which of three treatments A,\nB and C is the most effective in treating some disease.\nThe individual panel members have the following individual\nrankings: \nExpert I: \\(A > B > C\\) \nExpert II: \\(B > C > A\\) \nExpert III: \\(C > A > B\\), \nwhere “>” means “more effective”. There is\nnow a majority that holds that A is more effective than\nB (I&III), a majority that holds that B is more effective\nthan C (I&II) and a majority that holds that C is\nmore effective than A (II&III). More generally, whenever\nthere are logical relations among the propositions to be decided (in\nthis case: \\(A > B\\) and \\(B > C\\) implies that \\(A > C\\)),\nthere are at least three panel members, and votes are aggregated by\nthe majority rule, inconsistencies can arise at the group level\n(Pettit 2001). \nThe majority rule is of course only one way to aggregate judgments.\nThe Delphi method (e.g., Dalkey and Helmer 1963; for an application to\nmedicine, see Jones and Hunter 1995) applies to cases where the task\nis to provide a numerical estimate of some variable of interest (say,\nthe risk difference a new treatment makes). Experts answer\nquestionnaires in several rounds. After each round, a facilitator\nprovides an anonymous summary of the experts’ estimates from the\nprevious round and the reasons given for their judgments. Experts are\nthus supposed to be encouraged to revise their earlier answers in\nlight of other experts’ estimates and justifications. During\nthis process the range of the estimate will often decrease, and it is\nhoped that the group will converge towards the correct answer. The\nprocess is stopped after a pre-determined stopping criterion such as\nnumber of rounds, achievement of consensus, stability of results, and\nan average of the estimates of the final round is used as result. \nSolomon (2011, 2015) raises a fundamental issue concerning group\njudgments that is entirely independent of the specific method used. She argues that we\ndo not often find group judgment methods to determine the truth of\nscientific hypotheses or estimates of variables in the natural\nsciences (though see Staley 2004). If there is uncertainty about, say, which of two alternative\nhypotheses is true or what value a natural constant has, scientists go\nout and test, experiment, measure. Controversies, in other words, are\nsettled on the basis of evidence, not (individual or group) opinion.\nShouldn’t we, with the advancement of evidence-based medicine,\nexpect the same to happen in medicine? Consequently, she recommends\nmore widespread use of mechanical techniques for amalgamating evidence\nsuch as meta-analysis in lieu of consensus conferences and the\nlike. \nThe frequency of NIH consensus conferences has indeed markedly\ndeclined in recent years (Solomon 2011, 2015). But this is\nof course no reason to maintain that group judgments are no longer\nneeded. Consensus conferences may be the wrong tool for the purposes\nof the NIH, or the NIH may have a mistaken view about the ability of\nevidence to settle disputes adequately. Indeed, there are at least two\nreasons to believe that group judgment procedures are here to\nstay. \nThe first reason is that, as we have seen above, medical decisions are\nalways in part decisions about normative matters. No treatment is\nentirely without side effects and so if judgments about efficacy are\nto be of practical guidance, they must include a weighing of benefit\n(alleviation of disease symptoms) against cost (suffering from side\neffects)—even if economic costs and benefits are not to\nbe taken into consideration. Second, government agencies such as the\nU.S. Food and Drug Administration (FDA) have to decide whether new\ntreatments should be licensed to be marketed. These decisions often\nhave significant consequences, and democracies tend to prefer to be\nable to hold someone accountable for making them. Drug approval\ntherefore cannot be determined on the basis of evidence according to\nsome mechanical algorithm. \nBiddle (2007) discusses epistemological and moral issues of drug\napproval in the context of a case study on Vioxx, an analgesic. Vioxx\nwas approved by the FDA in 1999 but five years later pulled from the\nmarket by its manufacturer Merck due to safety concerns. It is\nestimated that some 55,000 people died from taking the drug (Harris\n2005). Biddle observes that the FDA is not sufficiently independent of\nthe pharmaceutical industry to make unbiased decisions likely. Many of\nthe members of the FDA’s drug approval committees have financial\nconflicts of interests (often in the form of receiving benefits from\nthe pharmaceutical company whose drug is to be approved), and a large\nnumber of employees of the FDA are dependent on the “user\nfees” industry pays to help cover the cost of drug approval. To\nsolve these problems of conflicts of interests, Biddle proposes to\ninstitute an adversarial system in which two groups of advocates, a\ngroup of representatives of the manufacturer and a group of\nindependent scientists, would argue before a panel of judges over\nwhether a drug should be allowed on the market. The panel of judges in\nthis model also consists of independent FDA or university scientists.\nHe argues that the adversarial system would better acknowledge the\nfact that an increasing number of medical researchers have financial\nties to the pharmaceutical industry by treating them as advocates\nrather than disinterested experts. (See also Reiss and Wieten 2015, Reiss forthcoming-b.) \nThere is no doubt that medical research is shaped by various external\nvalues, in ways similar to the value ladeness that is well-recognized\nin other areas of science (see entry on\n scientific objectivity).\n Many of these values create a variety of ethical dilemmas relating to\nequity of access to health care and similar. Even in recent years once\nmedical research has been made more inclusive, this trend has\nintroduced a host of additional philosophical and ethical issues\n(Epstein 2007). For our purposes, we will focus on the implications of\nthe systematic exclusion of certain types of individuals, groups, or\ndiseases from research for future research as well as clinical medical\npractice in terms of the validity of evidence produced and decisions\nmade based on that evidence.  \nIn traditional medical research, it was generally assumed that white\nmale participants could be used as the basis of generalizations that\nin turn could be extrapolated to all other populations, including\nminorities and females (Dresser 1992). Reviews of the literature\nindicate that women in particular have been excluded (especially older\nwomen), and that research on women has usually been related to\nreproductive function and capacity (Inborn and Whittle 2001). Such\ntypes of research have been argued to fail the ideals of quality\nmedical research as well as evidence-based health care (Dodds 2008).\nAlthough some improvements have been made in recent years, there\nremain certain forms of blanket exclusions for instance of women of\nchildbearing age or pregnant women in many types of medical research.\nThese types of systematic exclusion are highly problematic especially\nbecause there is clear evidence of critical differences between men\nand women with regard to a range of factors relating to receptivity to\ntherapies for both biological and social reasons.  \nIn the case of minorities such as African-Americans in the United\nStates, even when research trials seek to recruit them, a range of\nfactors may contribute to them not being involved in medical and other\ntypes of research studies. These include distrust due to historical\nand institutional racism including research performed without consent;\nlack of understanding about research and consent; social stigma;\nfinancial considerations; and lack of culturally-sensitive recruitment\nmethods by researchers (e.g., Huang and Coker 2010). Such gaps in\nmedical research potentially lead to use of treatments or therapies\nthat may in fact be harmful for particular groups, and may result in\nthe withholding of therapies that might be beneficial. \nMedical research also is affected by which conditions or diseases are\nselected for investigation (Reiss and Kitcher 2008): perhaps most\nnotoriously, “orphan” diseases which are either rare,\ncommon only in minority populations, or only present in certain\ndeveloping world or other lower socioeconomic settings, are often\nneglected for drug and other therapy development because it is\nperceived that there will not be a viable commercial market for any\nproducts on which research might be done due to the at-risk or\naffected population (and hence such potential products are often\ntermed “orphan drugs”). In some cases patients may pursue\n“off-label” use of drugs which are approved for a\ncondition other than the one they have, because approval for an\n“orphan” disease is unlikely due to cost and demand;\nhowever such off-label uses of drugs even when overseen by a physician\ntypically result in lack of consistent collection of evidence and\nabsence of typical risk-benefit regulatory considerations utilized\nwhen a drug is approved for particular purposes. \nA final way in which our knowledge in medicine generated by research\nis potentially adversely affected by values is through the funding\npatterns connected with research. As implied above, pharmaceutical\ncompanies sponsor a considerable portion of drug trials and have a\nvariety of interests at stake in these investments well beyond the\ngathering of evidence for the effectiveness (or lack thereof) of a\nparticular product. There is consistent evidence that negative\nresearch results typically are suppressed when sponsored by industry\n(Lexchin 2012a), leading to a bias in what is reported and thus what\nevidence is available on which to make prescribing and treatment\ndecisions. Bias also has been found in a number of other areas: within\nthe study itself in the choice of research question or topic of\ninvestigation, in the choice of doses or drugs against which the drug\nunder study is to be compared, in the control over trial design and\nvarious changes in protocols, and in decisions to terminate clinical\ntrials early, and in the reinterpretation of data, as well as in the\npublication of data such as restrictions on publication rights, use of\nfake journals, favoring journal supplements and symposia rather than\npeer review venues, the use of ghostwriting, and in the details of the\nreporting of results and outcomes (Sismondo 2008; Reiss 2010b; Lexchin 2012b). All of these\nissues weaken the evidence base on which clinical care judgments are\nmade, and also lead to potentially adverse effects for patients. \nIn order to evaluate medical outcomes quantitatively, they have to be\nmeasured. There are numerous reasons for aiming to quantify medical\noutcomes. We may want to compare two or more treatments with respect\nto their efficacy at relieving certain symptoms or their ability to\nprevent deaths due to a certain disease. When resources are scarce, we\nmay not only want to invest in treatments that are efficacious (that\nis, they do improve patient morbidity, mortality or both) but also\nefficient (that is, it is more efficacious than other treatments\nrelative to the cost of procuring it). For matters of international\ncomparison, development and international justice, we also want to\nhave measures of disease burden: Which of a number of\ntropical diseases has the highest cost in terms of increased morbidity\nand mortality? For each research dollar spent on treatments for\ndisease X, how much can we expect to reduce the morbidity and\nmortality it causes? \nClinical trials now often report so-called patient-reported outcome\nmeasures or PROMs. A PROM is a questionnaire given to patients to\nevaluate certain aspects of their quality of life, functioning or\nhealth status after a medical intervention without interpretation of\nthe patient’s response by a clinician or other people. It might\nask, for example, how difficult patients find it to climb up a flight\nof stairs after hip surgery or whether or not a cancer treatment helps\nthem to pursue their hobbies. The main goal of a PROM is the\nassessment of treatment benefit or risk in cases where the medical\noutcome is best known by the patient or best measured from the patient\nperspective. \nPROMs can vary considerably in length and complexity depending on the\nconcept that is being measured. In simple, straightforward cases\n(e.g., intensity of a certain kind of pain), a single question might\nsuffice. In others, it may be necessary to address several aspects of\na more complex functioning with a number of questions each. Either\nway, the design of the questionnaire should make sure that the\ninstrument reliably measures the concept of interest. The FDA\ndistinguishes the following six measurement properties or\n“tests” (FDA 2009: 11): \nDespite their plausibility, these tests are not methodologically\ninnocuous. Content validity, for instance, is assessed on the basis of\nqualitative research in the form of patient interviews, focus groups,\nand qualitative cognitive interviewing (the latter refers to a method\nthat asks respondents to think aloud and describe their thought\nprocesses as they answer the instrument questions and involves\nfollow-up questions in a field test interview to gain a better\nunderstanding of how patients interpret questions). This qualitative\nresearch aims to develop questions with standardized meanings that are\nshared between patients and clinicians. Arguably, however, there will\nalways be differences in interpreting phrases such as “bodily\npain” or “difficulty in lifting one”s arm’\nbecause they refer to a patient’s experiences, and these will\ndiffer from patient to patient and, in a given patient, from time to\ntime (Rapkin and Schwartz 2004). Moreover, there may be good\nphilosophical reasons to allow for the expression of a sufficient\narray of legitimate perspectives on health and quality of life instead\nof insisting on a standardization of meaning across patients and\ncontexts (McClimans 2010). Similarly, internal consistency can be\ndesirable only to the extent that the concept is a relatively simple\none and different questions really do address the same concept. It is\nof less relevance when the disorder is heterogeneous (McClimans and\nBrowne 2011). These kinds of worries can be raised with respect to\neach of the measurement tests. Finally, there is an issue when several\nPROMs that address a given disorder or treatment exist. Different\nPROMs will score differently with respect to the different tests, and\nthere is no universally valid schema to weigh their relative\nimportance (ibid.). \nDisability-adjusted life years or DALYs aim to measure burden of\ndisease. The measure was originally developed by Harvard University\nfor the World Bank and World Health Organization (WHO) in 1990 and is\nnow widely used by heath policy researchers for comparisons between\ncountries and over time and as a tool for policy making. It can also\nbe used to measure the effectiveness of interventions, though these\nare usually health policy rather than medical interventions\nnarrowly construed. The WHO makes regular global disease burden\nestimates in terms of DALYs at regional and global level for more than\n135 causes of disease and injury (Mathers et al. 2002). \nThe principal idea behind DALYs is simple. If a woman in Guatemala\ndies of Chagas disease at age 63, this adds 20 DALYs to the global\ndisease burden because her death is 20 years “premature”\nas compared to Japanese life expectancy (which is taken as the\nstandard because it is the highest world wide). If a man in\nHamburg has an accident that confines him to the wheelchair for the\nrest of his life, this contributes 0.57 DALYs for each of his\nremaining life years because the weight for paraplegia is 0.57. Every\nkind of disease or impairment is thus given a number between 0 and 1\n(where 0 = full health and 1 = death) that makes it comparable to\nother conditions. For example, blindness has a weight of 0.43. As\nblindness contributes less to the burden of disease than paraplegia,\nthis means that blindness is regarded as the less severe of the two in\nterms of its reduction of functional capacity\n(Prüss-Üstün et al. 2003). \nThe simple idea is complicated by two adjustments, however. Typical\nburden of disease studies weigh an impairment differently depending on\nthe age of the person whose functional capacity is impaired by the\ndisease or disability. Blindness, say, has a greater impact on the\nburden of disease if it occurs at age 20 than if it occurs at very\nyoung or older ages (Prüss-Üstün et al. 2003).\nMoreover, if the man who has the accident now can be expected to live\nwith the disease for 30 years, future years of disability are\ndiscounted by a factor. The further into the future a disability\noccurs, the less it contributes to the disease burden\n(ibid.). \nThe adequacy of any socio-economic indicator has to be evaluated in\nthe light of the purpose that it is meant to serve (Reiss 2008). If\nDALYs are supposed to measure the everyday concept “burden of\ndisease”, we may criticize, for instance, that the indicator\nfails to take account of societal, cultural, climatic and other\nvariations within which the disease or disability occurs. Being\nparaplegic, say, is less burdensome when it occurs in societies that\nspend more resources on making public buildings and transport\nwheelchair accessible, that display more tolerance towards the\nhandicapped, or in flatter than in hillier regions. Arguably,\ntherefore, DALYs measure ill-health rather than disease burden (Anand\nand Hanson 1997). Similarly, because ill-health is measured as a\npercentage, a disease occurring in a person who is already handicapped\ncontributes less to the measure than the same disease occurring in an\notherwise comparable but not handicapped person. If DALYs are used to\nmake public health decisions, however, it might be better to\nprioritize those individuals who are least well off instead of those\nwho are relatively better off (ibid.). \nThe WHO is very explicit that numerous choices made in the\nconstruction of the DALY measure are value-based (Murray 1994;\nPrüss-Üstün et al. 2003). Clearly, there is no matter\nof fact whether paraplegia constitutes a more severe impairment of\nsomeone’s functional capacity than blindness, much less the\nprecise extent to which it contributes to the burden of disease. The\nsame is true of the duration of the time lost due to premature death,\nage weights and time preference. While any given choice will, due to\nits value-laden nature, be controversial, the WHO makes some efforts\nto represent societal preferences instead of, say, a priori\nphilosophical arguments. For example, the disability weights used in\nthe 2003 World Health Survey were based on health state valuations\nfrom large representative population samples in over 70 countries\n(Prüss-Üstün et al. 2003: Ch. 3). Similarly, age\nweights are based on empirical studies that have indicated there is a\nbroad social preference to value a year lived by a young adult more\nhighly than a year lived by a young child, or lived at older ages\n(Murray 1996).","contact.mail":"rachel.ankeny@adelaide.edu.au","contact.domain":"adelaide.edu.au"}]
