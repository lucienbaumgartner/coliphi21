[{"date.published":"2000-02-29","date.changed":"2018-09-08","url":"https://plato.stanford.edu/entries/logic-modal/","author1":"James Garson","author1.info":"http://www.hfac.uh.edu/phil/garson/Jim_Garson.htm","entry":"logic-modal","body.text":"\n\n\n\nA modal is an expression (like ‘necessarily’ or\n‘possibly’) that is used to qualify the truth of a\njudgement. Modal logic is, strictly speaking, the study of the\ndeductive behavior of the expressions ‘it is necessary\nthat’ and ‘it is possible that’. However, the term\n‘modal logic’ may be used more broadly for a family of\nrelated systems. These include logics for belief, for tense and other\ntemporal expressions, for the deontic (moral) expressions such as\n‘it is obligatory that’ and ‘it is permitted\nthat’, and many others. An understanding of modal logic is\nparticularly valuable in the formal analysis of philosophical argument,\nwhere expressions from the modal family are both common and confusing.\nModal logic also has important applications in computer science. \n\n\n\n\nNarrowly construed, modal logic studies reasoning that involves the\nuse of the expressions ‘necessarily’ and\n‘possibly’. However, the term ‘modal logic’ is\nused more broadly to cover a family of logics with similar rules and a\nvariety of different symbols. \n\nA list describing the best known of these logics follows. \n\nThe most familiar logics in the modal family are constructed from a\nweak logic called \\(\\bK\\) (after Saul Kripke). Under the narrow\nreading, modal logic concerns necessity and possibility. A variety of\ndifferent systems may be developed for such logics using\n\\(\\bK\\) as a foundation. The symbols of \\(\\bK\\) include\n‘\\({\\sim}\\)’ for ‘not’,\n‘\\(\\rightarrow\\)’ for ‘if…then’, and\n‘\\(\\Box\\)’ for the modal operator ‘it is necessary\nthat’. (The connectives ‘\\(\\amp\\)’,\n‘\\(\\vee\\)’, and ‘\\(\\leftrightarrow\\)’ may be\ndefined from ‘\\({\\sim}\\)’ and\n‘\\(\\rightarrow\\)’ as is done in propositional logic.)\n\\(\\bK\\) results from adding the following to the principles of\npropositional logic.  \nNecessitation Rule:   If \\(A\\) is a theorem\nof \\(\\bK\\), then so is \\(\\Box A\\). \n\nDistribution Axiom: \\(\\Box(A\\rightarrow B) \\rightarrow \n(\\Box A\\rightarrow \\Box B)\\). \n\n(In these principles we use ‘\\(A\\)’ and\n‘\\(B\\)’ as metavariables ranging over formulas of the\nlanguage.) According to the Necessitation Rule, any theorem of logic\nis necessary. The Distribution Axiom says that if it is necessary that\nif \\(A\\) then \\(B\\), then if necessarily \\(A\\), then\nnecessarily \\(B\\). \n\nThe operator \\(\\Diamond\\) (for ‘possibly’) can be defined\nfrom \\(\\Box\\) by letting \\(\\Diamond A = {\\sim}\\Box{\\sim}A\\). In\n\\(\\bK\\), the operators \\(\\Box\\) and \\(\\Diamond\\) behave very much like\nthe quantifiers \\(\\forall\\) (all) and \\(\\exists\\) (some). For example,\nthe definition of \\(\\Diamond\\) from \\(\\Box\\) mirrors the equivalence\nof \\(\\forall xA\\) with \\({\\sim}\\exists x{\\sim}A\\) in predicate\nlogic. Furthermore, \\(\\Box(A \\amp B)\\) entails \\(\\Box A \\amp \\Box B\\)\nand vice versa; while \\(\\Box A\\vee \\Box B\\) entails \\(\\Box (A\\vee\nB)\\), but not vice versa. This reflects the patterns\nexhibited by the universal quantifier: \\(\\forall x(A \\amp B)\\) entails\n\\(\\forall xA \\amp \\forall xB\\) and vice versa, while \\(\\forall xA \\vee\n\\forall xB\\) entails \\(\\forall x(A \\vee B)\\) but not vice\nversa. Similar parallels between \\(\\Diamond\\) and \\(\\exists\\) can be\ndrawn. The basis for this correspondence between the modal operators\nand the quantifiers will emerge more clearly in the section on\n Possible Worlds Semantics. \n\nThe system \\(\\bK\\) is too weak to provide an adequate\naccount of necessity. The following axiom is not provable\nin \\(\\bK\\), but it is clearly desirable. \n\n\\((M)\\) claims that whatever is necessary is the case. Notice\nthat \\((M)\\) would be incorrect were \\(\\Box\\) to be read ‘it\nought to be that’, or ‘it was the case that’. So the\npresence of axiom \\((M)\\) distinguishes logics for necessity from other logics\nin the modal family. A basic modal logic \\(M\\) results from\nadding \\((M)\\) to \\(\\bK\\). (Some authors call this\nsystem \\(\\mathbf{T}\\).) \n\nMany logicians believe that \\(M\\) is still too weak to correctly\nformalize the logic of necessity and possibility. They recommend\nfurther axioms to govern the iteration, or repetition of modal\noperators. Here are two of the most famous iteration axioms: \n\n\\(\\mathbf{S4}\\) is the system that results from adding (4) to\n\\(M\\). Similarly \\(\\mathbf{S5}\\) is \\(M\\) plus (5). In\n\\(\\mathbf{S4}\\), the sentence \\(\\Box \\Box A\\) is\nequivalent to \\(\\Box A\\). As a result, any string of boxes may\nbe replaced by a single box, and the same goes for strings of\ndiamonds. This amounts to the idea that iteration of the modal\noperators is superfluous. Saying that \\(A\\) is necessarily\nnecessary is considered a uselessly long-winded way of saying that\n\\(A\\) is necessary. The system \\(\\mathbf{S5}\\) has even\nstronger principles for simplifying strings of modal operators. In\n\\(\\mathbf{S4}\\), a string of operators of the same kind\ncan be replaced for that operator; in \\(\\mathbf{S5}\\), strings\ncontaining both boxes and diamonds are equivalent to the last operator\nin the string. So, for example, saying that it is possible that\n\\(A\\) is necessary is the same as saying that \\(A\\) is\nnecessary. A summary of these features of \\(\\mathbf{S4}\\) and\n\\(\\mathbf{S5}\\) follows. \n\nOne could engage in endless argument over the correctness or\nincorrectness of these and other iteration principles for \\(\\Box\\) and\n\\(\\Diamond\\). The controversy can be partly resolved by recognizing that the\nwords ‘necessarily’ and ‘possibly’, have many\ndifferent uses. So the acceptability of axioms for modal logic depends\non which of these uses we have in mind. For this reason, there is no\none modal logic, but rather a whole family of systems built around\n\\(M\\). The relationship between these systems is diagrammed in\n Section 8,\n and their application to different uses of\n‘necessarily’ and ‘possibly’ can be more deeply\nunderstood by studying their possible world semantics in\n Section 6. \n\nThe system \\(\\mathbf{B}\\) (for the logician Brouwer) is formed by adding axiom\n\\((B)\\) to \\(M\\). \n\nIt is interesting to note that \\(\\mathbf{S5}\\) can be formulated\nequivalently by adding \\((B)\\) to \\(\\mathbf{S4}\\). The axiom \\((B)\\)\nraises an important point about the interpretation of modal\nformulas. \\((B)\\) says that if \\(A\\) is the case, then \\(A\\) is\nnecessarily possible. One might argue that \\((B)\\) should always be\nadopted in any modal logic, for surely if \\(A\\) is the case, then it\nis necessary that \\(A\\) is possible. However, there is a problem with\nthis claim that can be exposed by noting that \\(\\Diamond \\Box\nA\\rightarrow A\\) is provable from \\((B)\\). So \\(\\Diamond \\Box\nA\\rightarrow A\\) should be acceptable if \\((B)\\) is. However,\n\\(\\Diamond \\Box A\\rightarrow A\\) says that if \\(A\\) is possibly\nnecessary, then \\(A\\) is the case, and this is far from obvious. Why\ndoes \\((B)\\) seem obvious, while one of the things it entails seems\nnot obvious at all? The answer is that there is a dangerous ambiguity\nin the English interpretation of \\(A\\rightarrow \\Box \\Diamond A\\). We\noften use the expression ‘If \\(A\\) then necessarily \\(B\\)’\nto express that the conditional ‘if \\(A\\) then \\(B\\)’ is\nnecessary. This interpretation corresponds to \\(\\Box(A\\rightarrow\nB)\\). On other occasions, we mean that if \\(A\\), then \\(B\\) is\nnecessary: \\(A\\rightarrow \\Box B\\). In English,\n‘necessarily’ is an adverb, and since adverbs are usually\nplaced near verbs, we have no natural way to indicate whether the\nmodal operator applies to the whole conditional, or to its\nconsequent. For these reasons, there is a tendency to confuse \\((B):\nA\\rightarrow \\Box \\Diamond A\\) with \\(\\Box(A\\rightarrow \\Diamond\nA)\\). But \\(\\Box(A\\rightarrow \\Diamond A)\\) is not the same as\n\\((B)\\), for \\(\\Box(A\\rightarrow \\Diamond A)\\) is already a theorem of\n\\(M\\), and \\((B)\\) is not. One must take special care that our\npositive reaction to \\(\\Box(A\\rightarrow \\Diamond A)\\) does not infect\nour evaluation of \\((B)\\). One simple way to protect ourselves is to\nformulate \\(B\\) in an equivalent way using the axiom: \\(\\Diamond \\Box\nA\\rightarrow A\\), where these ambiguities of scope do not arise. \n\nDeontic logics introduce the primitive symbol \\(O\\) for ‘it is\nobligatory that’, from which symbols \\(P\\) for ‘it is\npermitted that’ and \\(F\\) for ‘it is forbidden that’\nare defined: \\(PA = {\\sim}O{\\sim}A\\) and \\(FA = O{\\sim}A\\). The\ndeontic analog of the modal axiom \\((M): OA\\rightarrow A\\) is clearly\nnot appropriate for deontic logic. (Unfortunately, what ought to be is\nnot always the case.) However, a basic system \\(\\mathbf{D}\\) of\ndeontic logic can be constructed by adding the weaker axiom \\((D)\\) to\n\\(\\bK\\). \n\nAxiom \\((D)\\) guarantees the consistency of the system of\nobligations by insisting that when \\(A\\) is obligatory,\n\\(A\\) is permissible. A system which obligates us to bring about\n\\(A\\), but doesn’t permit us to do so, puts us in an inescapable\nbind. Although some will argue that such conflicts of obligation are\nat least possible, most deontic logicians accept \\((D)\\). \n\n\\(O(OA\\rightarrow A)\\) is another deontic\naxiom that seems desirable. Although it is wrong to say that if\n\\(A\\) is obligatory then \\(A\\) is the case\n\\((OA\\rightarrow A)\\), still, this conditional\nought to be the case. So some deontic logicians believe that\n\\(D\\) needs to be supplemented with\n\\(O(OA\\rightarrow A)\\) as well. \n\nControversy about iteration (repetition) of operators arises again in\ndeontic logic. In some conceptions of obligation, \\(OOA\\) just amounts\nto \\(OA\\). ‘It ought to be that it ought to be’ is treated\nas a sort of stuttering; the extra ‘ought’s do not add\nanything new. So axioms are added to guarantee the equivalence of\n\\(OOA\\) and \\(OA\\). The more general iteration policy embodied in\n\\(\\mathbf{S5}\\) may also be adopted. However, there are conceptions of\nobligation where distinction between \\(OA\\) and \\(OOA\\) is\npreserved. The idea is that there are genuine differences between the\nobligations we actually have and the obligations\nwe should adopt. So, for example, ‘it ought to be that\nit ought to be that \\(A\\)’ commands adoption of some obligation\nwhich may not actually be in place, with the result that \\(OOA\\) can\nbe true even when \\(OA\\) is false. \n\nIn temporal logic (also known as tense logic), there are two basic\noperators, \\(G\\) for the future, and \\(H\\) for the past. \\(G\\) is read\n‘it always will be that’ and the defined operator \\(F\\)\n(read ‘it will be the case that’) can be introduced by\n\\(FA = {\\sim}G{\\sim}A\\). Similarly \\(H\\) is read: ‘it always was\nthat’ and \\(P\\) (for ‘it was the case that’) is\ndefined by \\(PA={\\sim}H{\\sim}A\\). A basic system of temporal logic\ncalled \\(\\mathbf{Kt}\\) results from adopting the principles of \\(\\bK\\)\nfor both \\(G\\) and \\(H\\), along with two axioms to govern the\ninteraction between the past and future operators: Necessitation Rules: \n If \\(A\\) is a theorem then so are\n\\(GA\\) and \\(HA\\). \n \nDistribution Axioms: \n\\(G(A\\rightarrow B) \\rightarrow(GA\\rightarrow GB)\\) and\n\\(H(A\\rightarrow B) \\rightarrow (HA\\rightarrow HB)\\) \nInteraction Axioms:\n\\(A\\rightarrow GPA\\) and \\(A\\rightarrow HFA\\) \n\nThe interaction axioms raise questions concerning asymmetries between\nthe past and the future. A standard intuition is that the past is\nfixed, while the future is still open. The first interaction axiom\n\\((A\\rightarrow GPA)\\) conforms to this\nintuition in reporting that what is the case \\((A)\\), will at all\nfuture times, be in the past \\((GPA)\\). However\n\\(A\\rightarrow HFA\\) may appear to have\nunacceptably deterministic overtones, for it claims, apparently, that\nwhat is true now \\((A)\\) has always been such that it will occur\nin the future \\((HFA)\\). However, possible\nworld semantics for temporal logic reveals that this worry results\nfrom a simple confusion, and that the two interaction axioms are\nequally acceptable. \n\nNote that the characteristic axiom of modal logic, \\((M):\n\\Box A\\rightarrow A\\), is not acceptable for either\n\\(H\\) or \\(G\\), since \\(A\\) does not follow from\n‘it always was the case that \\(A\\)’, nor from\n‘it always will be the case that \\(A\\)’. However, it\nis acceptable in a closely related temporal logic where \\(G\\) is\nread ‘it is and always will be’, and \\(H\\) is read\n‘it is and always was’. \n\nDepending on which assumptions one makes about the structure of\ntime, further axioms must be added to temporal logics. A list of axioms\ncommonly adopted in temporal logics follows. An account of how they\ndepend on the structure of time will be found in the section\n Possible Worlds Semantics. \n\nIt is interesting to note that certain combinations of past tense and\nfuture tense operators may be used to express complex tenses in\nEnglish. For example, \\(FPA\\), corresponds to sentence \\(A\\) in the\nfuture perfect tense, (as in ‘20 seconds from now the light will\nhave changed’). Similarly, \\(PPA\\) expresses the past perfect\ntense. \n\nFor a more detailed discussion, see the entry\n on\n temporal logic. \n\nThe founder of modal logic, C. I. Lewis, defined a series of modal\nlogics which did not have \\(\\Box\\) as a primitive symbol. Lewis was\nconcerned to develop a logic of conditionals that was free of the so\ncalled Paradoxes of Material Implication, namely the classical\ntheorems \\(A\\rightarrow({\\sim}A\\rightarrow B)\\) and\n\\(B\\rightarrow(A\\rightarrow B)\\). He introduced the symbol\n\\(\\fishhook\\) for “strict implication” and developed\nlogics where neither \\(A\\fishhook ({\\sim}A\\fishhook B)\\) nor\n\\(B\\fishhook (A\\fishhook B)\\) is provable. The modern practice has\nbeen to define \\(A\\fishhook B\\) by \\(\\Box(A\\rightarrow B)\\), and use\nmodal logics governing \\(\\Box\\) to obtain similar results. However,\nthe provability of such formulas as \\((A \\amp{\\sim}A)\\fishhook B\\) in\nsuch logics seems at odds with concern for the paradoxes. Anderson and\nBelnap (1975) have developed systems \\(\\mathbf{R}\\) (for Relevance\nLogic) and \\(\\mathbf{E}\\) (for Entailment) which are designed to\novercome such difficulties. These systems require revision of the\nstandard systems of propositional logic. (See Mares (2004) and the\nentry on\n relevance logic.) \n\nDavid Lewis (1973) and others have developed \n conditional logics \n to handle counterfactual expressions, that is, expressions of the\nform ‘if \\(A\\) were to happen then \\(B\\) would\nhappen’. (Kvart (1980) is another good source on the topic.)\nCounterfactual logics differ from those based on strict implication\nbecause the former reject while the latter accept contraposition. \n\nThe purpose of logic is to characterize the difference between valid\nand invalid arguments. A logical system for a language is a set of\naxioms and rules designed to prove exactly the valid\narguments statable in the language. Creating such a logic may be a\ndifficult task. The logician must make sure that the system is\nsound, i.e. that every argument proven using the rules and\naxioms is in fact valid. Furthermore, the system should be\ncomplete, meaning that every valid argument has a proof in\nthe system. Demonstrating soundness and completeness of formal systems\nis a logician’s central concern.  \n\nSuch a demonstration cannot get underway until the concept of validity\nis defined rigorously. Formal semantics for a logic provides a\ndefinition of validity by characterizing the truth behavior of the\nsentences of the system. In propositional logic, validity can be\ndefined using truth tables. A valid argument is simply one where every\ntruth table row that makes its premises true also makes its conclusion\ntrue. However truth tables cannot be used to provide an account of\nvalidity in modal logics because there are no truth tables for\nexpressions such as ‘it is necessary that’, ‘it is\nobligatory that’, and the like. (The problem is that the truth\nvalue of \\(A\\) does not determine the truth value for \\(\\Box A\\). For\nexample, when \\(A\\) is ‘Dogs are dogs’, \\(\\Box A\\) is\ntrue, but when \\(A\\) is ‘Dogs are pets’, \\(\\Box A\\) is\nfalse.) Nevertheless, semantics for modal logics can be defined by\nintroducing possible worlds. We will illustrate possible worlds\nsemantics for a logic of necessity containing the symbols \\({\\sim},\n\\rightarrow\\), and \\(\\Box\\). Then we will explain how the same\nstrategy may be adapted to other logics in the modal family. \n\nIn propositional logic, a valuation of the atomic sentences (or row of\na truth table) assigns a truth value \\((T\\) or \\(F)\\) to\neach propositional variable \\(p\\). Then the truth values of the\ncomplex sentences are calculated with truth tables. In modal semantics,\na set \\(W\\) of possible worlds is introduced. A valuation then\ngives a truth value to each propositional variable for each of the\npossible worlds in \\(W\\). This means that value assigned to\n\\(p\\) for world \\(w\\) may differ from the value assigned to\n\\(p\\) for another world \\(w'\\). \n\nThe truth value of the atomic sentence \\(p\\) at world \\(w\\) given by\nthe valuation \\(v\\) may be written \\(v(p, w)\\). Given this notation,\nthe truth values \\((T\\) for true, \\(F\\) for false) of complex\nsentences of modal logic for a given valuation \\(v\\) (and member \\(w\\)\nof the set of worlds \\(W)\\) may be defined by the following truth\nclauses. (‘iff’ abbreviates ‘if and only\nif’.) \n\nClauses \\(({\\sim})\\) and \\((\\rightarrow)\\) simply describe the\nstandard truth table behavior for negation and material implication\nrespectively. According to (5), \\(\\Box A\\) is true (at a world \\(w)\\)\nexactly when \\(A\\) is true in all possible worlds. Given the\ndefinition of \\(\\Diamond\\), (namely, \\(\\Diamond A =\n{\\sim}\\Box{\\sim}A)\\) the truth condition (5) insures that \\(\\Diamond\nA\\) is true just in case \\(A\\) is true in some possible\nworld. Since the truth clauses for \\(\\Box\\) and \\(\\Diamond\\) involve\nthe quantifiers ‘all’ and ‘some’\n(respectively), the parallels in logical behavior between \\(\\Box\\) and\n\\(\\forall x\\), and between \\(\\Diamond\\) and \\(\\exists x\\) noted in\nsection 2 will be expected. \n\nClauses \\(({\\sim}), (\\rightarrow)\\), and (5) allow us to calculate the truth value\nof any sentence at any world on a given valuation. A definition of\nvalidity is now just around the corner. An argument is 5-valid for\na given set W (of possible worlds) if and only if every valuation\nof the atomic sentences that assigns the premises \\(T\\) at a\nworld in \\(W\\) also assigns the conclusion \\(T\\) at the same\nworld. An argument is said to be 5-valid iff it is valid for\nevery non empty set \\(W\\) of possible worlds. \n\nIt has been shown that \\(\\mathbf{S5}\\) is sound and complete for\n5-validity (hence our use of the symbol ‘5’). The 5-valid\narguments are exactly the arguments provable in\n\\(\\mathbf{S5}\\). This result suggests that \\(\\mathbf{S5}\\) is\nthe correct way to formulate a logic of necessity. \n\nHowever, \\(\\mathbf{S5}\\) is not a reasonable logic for all members\nof the modal family. In deontic logic, temporal logic, and others, the\nanalog of the truth condition (5) is clearly not appropriate;\nfurthermore there are even conceptions of necessity where (5) should\nbe rejected as well. The point is easiest to see in the case of\ntemporal logic. Here, the members of \\(W\\) are moments of time,\nor worlds “frozen”, as it were, at an instant. For simplicity let us\nconsider a future temporal logic, a logic where\n\\(\\Box A\\) reads: ‘it will always be the case\nthat’. (We formulate the system using \\(\\Box\\) rather than the\ntraditional \\(G\\) so that the connections with other modal logics\nwill be easier to appreciate.) The correct clause for \\(\\Box\\) should\nsay that \\(\\Box A\\) is true at time \\(w\\) iff \\(A\\)\nis true at all times in the future of \\(w\\). To restrict\nattention to the future, the relation \\(R\\) (for ‘earlier\nthan’) needs to be introduced. Then the correct clause can be\nformulated as follows. \n\nThis says that \\(\\Box A\\) is true at \\(w\\) just in case\n\\(A\\) is true at all times after \\(w\\). \n\nValidity for this brand of temporal logic can now be defined. A\nframe \\(\\langle W, R\\rangle\\) is a pair consisting of a non-empty set\n\\(W\\) (of worlds) and a binary relation \\(R\\) on\n\\(W\\). A model \\(\\langle F, v\\rangle\\) consists of a frame \\(F\\), and\na valuation \\(v\\) that assigns truth values to each atomic sentence at\neach world in \\(W\\). Given a model, the values of all complex\nsentences can be determined using \\(({\\sim}), (\\rightarrow)\\), and\n\\((K)\\). An argument is \\(\\bK\\)-valid just in case any model whose\nvaluation assigns the premises \\(T\\) at a world also assigns the\nconclusion \\(T\\) at the same world. As the reader may have guessed\nfrom our use of ‘\\(\\bK\\)’, it has been shown that the\nsimplest modal logic \\(\\bK\\) is both sound and complete for\n\\(\\bK\\)-validity. \n\nOne might assume from this discussion that \\(\\bK\\) is the correct\nlogic when \\(\\Box\\) is read ‘it will always be the case\nthat’. However, there are reasons for thinking that \\(\\bK\\) is\ntoo weak. One obvious logical feature of the relation \\(R\\) (earlier\nthan) is transitivity. If \\(wRv (w\\) is earlier than \\(v)\\) and \\(vRu\n(v\\) is earlier than \\(u)\\), then it follows that \\(wRu (w\\) is\nearlier than \\(u)\\). So let us define a new kind of validity that\ncorresponds to this condition on \\(R\\). Let a 4-model be any model\nwhose frame \\(\\langle W, R\\rangle\\) is such that \\(R\\) is a transitive\nrelation on \\(W\\). Then an argument is 4-valid iff any 4-model whose\nvaluation assigns \\(T\\) to the premises at a world also assigns \\(T\\)\nto the conclusion at the same world. We use ‘4’ to\ndescribe such a transitive model because the logic which is adequate\n(both sound and complete) for 4-validity is \\(\\mathbf{K4}\\), the logic\nwhich results from adding the axiom (4): \\(\\Box A\\rightarrow \\Box \\Box\nA\\) to \\(\\bK\\). \n\nTransitivity is not the only property which we might want to require\nof the frame \\(\\langle W, R\\rangle\\) if \\(R\\) is to be read ‘earlier\nthan’ and \\(W\\) is a set of moments. One condition (which is\nonly mildly controversial) is that there is no last moment of time,\ni.e. that for every world \\(w\\) there is some world \\(v\\) such that\n\\(wRv\\). This condition on frames is called\nseriality. Seriality corresponds to the axiom \\((D): \\Box\nA\\rightarrow \\Diamond A\\), in the same way that transitivity\ncorresponds to (4). A \\(\\mathbf{D}\\)-model is a \\(\\bK\\)-model with a\nserial frame. From the concept of a \\(\\mathbf{D}\\)-model the\ncorresponding notion of \\(\\mathbf{D}\\)-validity can be defined just as\nwe did in the case of 4-validity. As you probably guessed, the system\nthat is adequate with respect to \\(\\mathbf{D}\\)-validity is\n\\(\\mathbf{KD}\\), or \\(\\bK\\) plus \\((D)\\). Not only that, but the\nsystem \\(\\mathbf{KD4}\\) (that is \\(\\bK\\) plus (4) and \\((D))\\) is\nadequate with respect to \\(\\mathbf{D4}\\)-validity, where a\n\\(\\mathbf{D4}\\)-model is one where \\(\\langle W, R\\rangle\\) is both\nserial and transitive. \n\nAnother property which we might want for the relation ‘earlier\nthan’ is density, the condition which says that between any two\ntimes we can always find another. Density would be false if time were\natomic, i.e. if there were intervals of time which could not be broken\ndown into any smaller parts. Density corresponds to the axiom\n\\((C4): \\Box \\Box A\\rightarrow \\Box A\\), the\nconverse of (4), so for example, the system \\(\\mathbf{KC4}\\),\nwhich is \\(\\bK\\) plus \\((C4)\\) is adequate with\nrespect to models where the frame \\(\\langle W, R\\rangle\\) is\ndense, and \\(\\mathbf{KDC4}\\), adequate with respect to models\nwhose frames are serial and dense, and so on. \n\nEach of the modal logic axioms we have discussed corresponds to a\ncondition on frames in the same way. The relationship between\nconditions on frames and corresponding axioms is one of the central\ntopics in the study of modal logics. Once an interpretation of the\nintensional operator \\(\\Box\\) has been decided on, the appropriate\nconditions on \\(R\\) can be determined to fix the corresponding\nnotion of validity. This, in turn, allows us to select the right set\nof axioms for that logic. \n\nFor example, consider a deontic logic, where \\(\\Box\\) is read\n‘it is obligatory that’. Here the truth of \\(\\Box A\\) does\nnot demand the truth of \\(A\\) in every possible world, but\nonly in a subset of those worlds where people do what they ought. So\nwe will want to introduce a relation \\(R\\) for this kind of logic as\nwell, and use the truth clause \\((K)\\) to evaluate \\(\\Box A\\) at a\nworld. However, in this case, \\(R\\) is not earlier than. Instead\n\\(wRw'\\) holds just in case world \\(w'\\) is a morally acceptable\nvariant of \\(w\\), i.e. a world that our actions can bring about which\nsatisfies what is morally correct, or right, or just. Under such a\nreading, it should be clear that the relevant frames should obey\nseriality, the condition that requires that each possible world have a\nmorally acceptable variant. The analysis of the properties desired for\n\\(R\\) makes it clear that a basic deontic logic can be formulated by\nadding the axiom \\((D)\\) and to \\(\\bK\\). \n\nEven in modal logic, one may wish to restrict the range of possible\nworlds which are relevant in determining whether \\(\\Box A\\) is true at\na given world. For example, I might say that it is necessary for me to\npay my bills, even though I know full well that there is a possible\nworld where I fail to pay them. In ordinary speech, the claim that\n\\(A\\) is necessary does not require the truth of \\(A\\) in all\npossible worlds, but rather only in a certain class of worlds which I\nhave in mind (for example, worlds where I avoid penalties for failure\nto pay). In order to provide a generic treatment of necessity, we must\nsay that \\(\\Box A\\) is true in \\(w\\) iff \\(A\\) is true in all\nworlds that are related to \\(w\\) in the right way. So for an\noperator \\(\\Box\\) interpreted as necessity, we introduce a\ncorresponding relation \\(R\\) on the set of possible worlds \\(W\\),\ntraditionally called the accessibility relation. The accessibility\nrelation \\(R\\) holds between worlds \\(w\\) and \\(w'\\) iff \\(w'\\) is\npossible given the facts of \\(w\\). Under this reading for \\(R\\), it\nshould be clear that frames for modal logic should be reflexive. It\nfollows that modal logics should be founded on \\(M\\), the system that\nresults from adding \\((M)\\) to \\(\\bK\\). Depending on exactly how the\naccessibility relation is understood, symmetry and transitivity may\nalso be desired. \n\nA list of some of the more commonly discussed conditions on frames\nand their corresponding axioms along with a map showing the\nrelationship between the various modal logics can be found in the next\nsection. \n\nThe following diagram shows the relationships between the best known\nmodal logics, namely logics that can be formed by adding a selection\nof the axioms \\((D), (M)\\), (4), \\((B)\\) and (5) to\n\\(\\bK\\). A list of these (and other) axioms along with\ntheir corresponding frame conditions can be found below the diagram. Diagram of Modal Logics \n\nIn this chart, systems are given by the list of their axioms. So, for\nexample \\(\\mathbf{M4B}\\) is the result of adding \\((M)\\), (4) and\n\\((B)\\) to \\(\\bK\\). In boldface, we have indicated traditional names\nof some systems. When system \\(\\mathbf{S}\\) appears below and/or to\nthe left of \\(\\mathbf{S}'\\) connected by a line, then \\(\\mathbf{S}'\\)\nis an extension of \\(\\mathbf{S}\\). This means that every argument\nprovable in \\(\\mathbf{S}\\) is provable in \\(\\mathbf{S}'\\), but\n\\(\\mathbf{S}\\) is weaker than \\(\\mathbf{S}'\\), i.e. not all arguments\nprovable in \\(\\mathbf{S}'\\) are provable in \\(\\mathbf{S}\\). \n\nThe following list indicates axioms, their names, and the\ncorresponding conditions on the accessibility relation \\(R\\), for\naxioms so far discussed in this encyclopedia entry. \n\nIn the list of conditions on frames, and in the rest of this article,\nthe variables ‘\\(w\\)’, ‘\\(v\\)’,\n‘\\(u\\)’, ‘\\(x\\)’ and the quantifier\n‘\\(\\exists u\\)’ are understood to range over\n\\(W\\). ‘&’ abbreviates ‘and’ and\n‘\\(\\Rightarrow\\)’ abbreviates\n‘if…then’. \n\nThe notion of correspondence between axioms and frame conditions that\nis at issue here was explained in the previous section. When S is a\nlist of axioms and F(S) is the corresponding set of frame conditions,\nthen S corresponds to F(S) exactly when the system K+S is adequate\n(sound and complete) for F(S)-validity, that is, an argument is\nprovable in K+S iff it is F(S)-valid. Several stronger notions of\ncorrespondence between axioms and frame conditions have emerged in\nresearch on modal logic.  \n\nThe correspondence between axioms and conditions on frames may seem\nsomething of a mystery. A beautiful result of Lemmon and Scott (1977)\ngoes a long way towards explaining those relationships. Their theorem\nconcerned axioms which have the following form:  \n\nWe use the notation ‘\\(\\Diamond^n\\)’ to represent \\(n\\)\ndiamonds in a row, so, for example, ‘\\(\\Diamond^3\\)’\nabbreviates a string of three diamonds: ‘\\(\\Diamond \\Diamond\n\\Diamond\\)’. Similarly ‘\\(\\Box^n\\)’ represents a\nstring of \\(n\\) boxes. When the values of \\(h, i, j\\), and \\(k\\) are\nall 1, we have axiom \\((C)\\): \n\nThe axiom \\((B)\\) results from setting \\(h\\) and \\(i\\)\nto 0, and letting \\(j\\) and \\(k\\) be 1: \n\nTo obtain (4), we may set \\(h\\) and \\(k\\) to 0, set\n\\(i\\) to 1 and \\(j\\) to 2: \n\nMany (but not all) axioms of modal logic can be obtained by setting the\nright values for the parameters in \\((G)\\)  \n\nOur next task will be to give the condition on frames which\ncorresponds to \\((G)\\) for a given selection of values for \\(h, i,\nj\\), and \\(k\\). In order to do so, we will need a definition. The\ncomposition of two relations \\(R\\) and \\(R'\\) is a new relation \\(R\n\\circ R'\\) which is defined as follows: \n\nFor example, if \\(R\\) is the relation of being a brother, and \\(R'\\)\nis the relation of being a parent then \\(R \\circ R'\\) is the relation\nof being an uncle, (because \\(w\\) is the uncle of \\(v\\) iff for some\nperson \\(u\\), both \\(w\\) is the brother of \\(u\\) and \\(u\\) is the\nparent of \\(v)\\). A relation may be composed with itself. For example,\nwhen \\(R\\) is the relation of being a parent, then \\(R \\circ R\\) is\nthe relation of being a grandparent, and \\(R \\circ R \\circ R\\) is the\nrelation of being a great-grandparent. It will be useful to write\n‘\\(R^n\\)’, for the result of composing \\(R\\) with itself\n\\(n\\) times. So \\(R^2\\) is \\(R \\circ R\\), and \\(R^4\\) is \\(R \\circ R\n\\circ R \\circ R\\). We will let \\(R^1\\) be \\(R\\), and \\(R^0\\) will be\nthe identity relation, i.e. \\(wR^0 v\\) iff \\(w=v\\). \n\nWe may now state the Scott-Lemmon result. It is that the condition\non frames which corresponds exactly to any axiom of the shape \\((G)\\) is\nthe following. \n\nIt is interesting to see how the familiar conditions on \\(R\\) result\nfrom setting the values for \\(h\\), \\(i\\), \\(j\\), and \\(k\\) according to the\nvalues in the corresponding axiom. For example, consider (5). In this\ncase \\(i=0\\), and \\(h=j=k=1\\). So the corresponding condition is \n\nWe have explained that \\(R^0\\) is the identity relation. So if \\(vR^0\nx\\) then \\(v=x\\). But \\(\\exists x (v=x \\amp uRx)\\), is equivalent to\n\\(uRv\\), and so the Euclidean condition is obtained: \n\nIn the case of axiom (4), \\(h=0, i=1, j=2\\) and \\(k=0\\). So the\ncorresponding condition on frames is \n\nResolving the identities this amounts to:  \n\nBy the definition of \\(R^2, vR^2 u\\) iff \\(\\exists x(vRx \\amp xRu)\\),\nso this comes to: \n\nwhich by predicate logic, is equivalent to transitivity.  \n\nThe reader may find it a pleasant exercise to see how the\ncorresponding conditions fall out of hijk-Convergence when the values\nof the parameters \\(h\\), \\(i\\), \\(j\\), and \\(k\\)\nare set by other axioms. \n\nThe Scott-Lemmon results provides a quick method for establishing\nresults about the relationship between axioms and their corresponding\nframe conditions. Since they showed the adequacy of any logic that\nextends \\(\\bK\\) with a selection of axioms of the form \\((G)\\) with\nrespect to models that satisfy the corresponding set of frame\nconditions, they provided “wholesale” adequacy proofs for\nthe majority of systems in the modal family. Sahlqvist (1975) has\ndiscovered important generalizations of the Scott-Lemmon result\ncovering a much wider range of axiom types. \nThe reader should be warned, however, that the neat correspondence\nbetween axioms and conditions on frames is atypical. There are\ncondtions on frames that correspond to no axioms, and there are even\nconditions on frames for which no system is adequate. (For an example\nsee Boolos, 1993, pp. 148ff.) \nTwo dimensional semantics\nis a variant of possible world semantics that uses two (or more) kinds\nof parameters in truth evaluation, rather than possible worlds alone.\nFor example, a logic of indexical expressions, such as\n‘I’, ‘here’, ‘now’, and the like,\nneeds to bring in the linguistic context (or context for short).\nGiven a context \\(c = \\langle s, p, t\\rangle\\) where\n\\(s\\) is the speaker, \\(p\\) the place, and \\(t\\) the time of\nutterance, then ‘I’ refers to \\(s\\), ‘here’\nto \\(p\\), and ‘now’ to \\(t\\). So in the context\n\\(c = \\langle\\)Jim Garson, Houston, 3:00 P.M. CST on 4/3/\\(2014\\rangle\\)\n‘I am here now’ is T iff Jim Garson is in Houston, at 3:00\nP.M. CST on 4/3/2014.  \nIn possible worlds semantics, a sentence’s truth-value depended on the\nworld at which it is evaluated. However, indexicals bring in a second\ndimension – so we need to generalize again. Kaplan (1989) defines the\ncharacter of a sentence B to be a function from the set of\n(linguistic) contexts to the content (or intension) of B, where the\ncontent, in turn, is simply the intension of B, that is a function\nfrom possible worlds to truth-values. Here, truth evaluation is\ndoubly dependent – on both linguistic contexts and possible worlds. \nOne of Kaplan’s most interesting observations is that some indexical\nsentences are contingent, but at the same time analytically true. An\nexample is (1). \nJust from the meaning of the words, you can see that (1) must be true\nin any context \\(c = \\langle s, p, t\\rangle\\). After\nall, \\(c\\) counts as a linguistic context just in case \\(s\\) is\na speaker who is at place \\(p\\) at time \\(t\\). Therefore (1) is\ntrue at \\(c\\), and that means that the pattern of truth-values (1)\nhas along the context dimension must be all Ts (given the possible\nworld is held fixed). This suggests that the context dimension is apt\nfor tracking analytic knowledge obtained from the mastery of our\nlanguage. On the other hand, the possible-worlds dimension keeps\ntrack of what is necessary. Holding the context fixed, there there\nare possible worlds where (1) is false. For example, when \\(c = \\langle\\)Jim Garson, Houston, 3:00 P.M. CST on 4/3/\\(2014\\rangle\\), (1) fails at\n\\(c\\) in a possible world where Jim Garson is in Boston at 3:00\nP.M. CST on 4/3/2014. It follows that ‘I am here now’ is\na contingent analytic truth. Therefore, two-dimensional semantics can\nhandle situations where necessity and analyticity come apart. \nAnother example where bringing in two dimension is useful is in the\nlogic for an open future (Thomason, 1984; Belnap, et al., 2001).\nHere one employs a temporal structure where many possible future\nhistories extend from a given time. Consider (2).  If (2) is contingent, then there is a possible history where the\nbattle occurs the day after the time of evaluation, and another one\nwhere it does not occur then. So to evaluate (2) you need to know two\nthings: what is the time t of evaluation, and which of the histories h\nthat run through t is the one to be considered. So a sentence in such\na logic is evaluated at a pair \\(\\langle t, h\\rangle\\). \nAnother problem resolved by two-dimensional semantics is the\ninteraction between ‘now’ and other temporal expressions\nlike the future tense ‘it will be the case that’. Then it\nis plausible to think that ‘now’ refers to the time of\nevaluation. So we would have the following truth condition: \nHowever this will not work for sentences like (3). \nWith \\(\\mathrm{F}\\) as the future tense operator, (3) might be\ntranslated: \n(The correct translation cannot be \\(\\forall x(\\text{Now} Lx\n\\rightarrow \\mathrm{F}Ux)\\), with \\(\\mathrm{F}\\) taking narrow scope,\nbecause (3) says there is a future time when all things now living are\nunknown together, not that each living thing will be unknown in some\nfuture time of its own). When the truth conditions for (3)\\('\\)\ncalculated, using (Now) and the truth condition (\\(\\mathrm{F}\\)) for\n\\(\\mathrm{F}\\), it turns out that (3)\\('\\) is true at time \\(u\\) iff\nthere is a time \\(t\\) after \\(u\\) such that everything that is living\nat \\(t\\) (not \\(u\\)!)  is unknown at \\(t\\). \nTo evaluate (3)\\('\\) correctly so that it matches what we mean by\n(3), we must make sure that ‘now’ always refers back to\nthe original time of utterance when ‘now’ lies in the\nscope of other temporal operators such as F. Therefore we need to\nkeep track of which time is the time of utterance \\((u)\\) as well\nas which time is the time of evaluation \\((t)\\). So our indices\ntake the form of a pair \\(\\langle u,\ne\\rangle\\), where \\(u\\) is the time of utterance, and \\(e\\) is the time of\nevaluation. Then the truth condition (Now) is revised to (2DNow). \nThis has it that the Now\\(B\\) is true at a time u of utterance and\ntime e of evaluation provided that B is true when u is taken to be the\ntime of evaluation. When the truth conditions for F, \\(\\forall\\), and\n\\(\\rightarrow\\) are revised in the obvious way (just ignore the u in\nthe pair), (3)\\('\\) is true at \\(\\langle u, e\\rangle\\) provided that\nthere is a time \\(e'\\) later than e such that everything that is\nliving at \\(u\\) is unknown at \\(e'\\). By carrying along a record of\nwhat \\(u\\) is during the truth calculation, we can always fix the\nvalue for ‘now’ to the original time of utterance, even\nwhen ‘now’ is deeply embedded in other temporal\noperators. \nA similar phenomenon arises in modal logics with an actuality operator\nA (read ‘it is actually the case that’). To properly evaluate\n(4) we need to keep track of which world is taken to be the actual (or\nreal) world as well as which one is taken to the world of evaluation. \nThe idea of distinguishing different possible world dimensions in\nsemantics has had useful applications in philosophy. For example,\nChalmers (1996) has presented arguments from the conceivability of\n(say) zombies to dualist conclusions in the philosophy of mind.\nChalmers (2006) has deployed two-dimensional semantics to help\nidentify an a priori aspect of meaning that would support such\nconclusions.  \nThe idea has also been deployed in the philosophy of language. Kripke\n(1980) famously argued that ‘Water is H2O’ is a posteriori\nbut nevertheless a necessary truth, for given that water just is H20,\nthe there is no possible world where THAT stuff is (say) a basic\nelement as the Greeks thought. On the other hand, there is a strong\nintuition that had the real world been somewhat different from what it\nis, the odorless liquid that falls from the sky as rain, fills our\nlakes and rivers, etc. might perfectly well have been an element. So\nin some sense it is conceivable that water is not H20. Two\ndimensional semantics makes room for these intuitions by providing a\nseparate dimension that tracks a conception of water that lays aside\nthe chemical nature of what water actually is. Such a ‘narrow\ncontent’ account of the meaning of ‘water’ can\nexplain how one may display semantical competence in the use of that\nterm and still be ignorant about the chemistry of water (Chalmers,\n2002). \n\nModal logic has been useful in clarifying our understanding of central\nresults concerning provability in the foundations of mathematics\n(Boolos, 1993). Provability logics are systems where the propositional\nvariables \\(p, q, r\\), etc. range over formulas\nof some mathematical system, for example Peano’s system\n\\(\\mathbf{PA}\\) for arithmetic. (The system chosen for mathematics\nmight vary, but assume it is \\(\\mathbf{PA}\\) for this discussion.)\nGödel showed that arithmetic has strong expressive powers. Using\ncode numbers for arithmetic sentences, he was able to demonstrate a\ncorrespondence between sentences of mathematics and facts about which\nsentences are and are not provable in \\(\\mathbf{PA}\\). For\nexample, he showed there there is a sentence \\(C\\) that is true\njust in case no contradiction is provable in \\(\\mathbf{PA}\\) and\nthere is a sentence \\(G\\) (the famous Gödel sentence) that\nis true just in case it is not provable in \\(\\mathbf{PA}\\). \n\nIn provability logics, \\(\\Box p\\) is interpreted as a formula (of\narithmetic) that expresses that what \\(p\\) denotes is provable in\n\\(\\mathbf{PA}\\). Using this notation, sentences of provability logic\nexpress facts about provability. Suppose that \\(\\bot\\) is a constant\nof provability logic denoting a contradiction. Then \\({\\sim}\\Box\n\\bot\\) says that \\(\\mathbf{PA}\\) is consistent and \\(\\Box A\\rightarrow\nA\\) says that \\(\\mathbf{PA}\\) is sound in the sense that when it\nproves \\(A, A\\) is indeed true. Furthermore, the box may be\niterated. So, for example, \\(\\Box{\\sim}\\Box \\bot\\) makes the dubious\nclaim that \\(\\mathbf{PA}\\) is able to prove its own consistency, and\n\\({\\sim}\\Box \\bot \\rightarrow{\\sim}\\Box{\\sim}\\Box \\bot\\) asserts\n(correctly as Gödel proved) that if \\(\\mathbf{PA}\\) is consistent\nthen \\(\\mathbf{PA}\\) is unable to prove its own consistency. \n\nAlthough provability logics form a family of related systems, the\nsystem \\(\\mathbf{GL}\\) is by far the best known. It results from\nadding the following axiom to \\(\\bK\\): \n\nThe axiom (4): \\(\\Box A\\rightarrow \\Box \\Box A\\) is provable in\n\\(\\mathbf{GL}\\), so \\(\\mathbf{GL}\\) is actually a strengthening of\n\\(\\mathbf{K4}\\). However, axioms such as \\((M): \\Box A\\rightarrow A\\),\nand even the weaker \\((D): \\Box A\\rightarrow \\Diamond A\\) are not\navailable (nor desirable) in \\(\\mathbf{GL}\\). In provability logic,\nprovability is not to be treated as a brand of necessity. The reason\nis that when \\(p\\) is provable in an arbitrary system \\(\\mathbf{S}\\)\nfor mathematics, it does not follow that \\(p\\) is true, since\n\\(\\mathbf{S}\\) may be unsound. Furthermore, if \\(p\\) is provable in\n\\(\\mathbf{S} (\\Box p)\\) it need not even follow that \\({\\sim}p\\) lacks\na proof \\(({\\sim}\\Box{\\sim}p = \\Diamond p). \\mathbf{S}\\) might be\ninconsistent and so prove both \\(p\\) and \\({\\sim}p\\). \n\nAxiom \\((GL)\\) captures the content of Loeb’s Theorem, an\nimportant result in the foundations of arithmetic. \\(\\Box A\\rightarrow\nA\\) says that \\(\\mathbf{PA}\\) is sound for \\(A\\), i.e. that if \\(A\\)\nwere proven, A would be true. (Such a claim might not be secure for an\narbitrarily selected system \\(\\mathbf{S}\\), since A might be provable\nin \\(\\mathbf{S}\\) and false.) \\((GL)\\) claims that if \\(\\mathbf{PA}\\)\nmanages to prove the sentence that claims soundness for a given\nsentence \\(A\\), then \\(A\\) is already provable in\n\\(\\mathbf{PA}\\). Loeb’s Theorem reports a kind of modesty on\n\\(\\mathbf{PA}\\)’s part (Boolos, 1993, p. 55). \\(\\mathbf{PA}\\)\nnever insists (proves) that a proof of \\(A\\) entails \\(A\\)’s\ntruth, unless it already has a proof of \\(A\\) to back up that\nclaim. \n\nIt has been shown that \\(\\mathbf{GL}\\) is adequate for provability\nin the following sense. Let a sentence of \\(\\mathbf{GL}\\) be\nalways provable exactly when the sentence of arithmetic it\ndenotes is provable no matter how its variables are assigned values to\nsentences of \\(\\mathbf{PA}\\). Then the provable sentences of\n\\(\\mathbf{GL}\\) are exactly the sentences that are always\nprovable. This adequacy result has been extremely useful, since\ngeneral questions concerning provability in \\(\\mathbf{PA}\\) can be\ntransformed into easier questions about what can be demonstrated in\n\\(\\mathbf{GL}\\). \n\n\\(\\mathbf{GL}\\) can also be outfitted with a possible world\nsemantics for which it is sound and complete. A corresponding\ncondition on frames for \\(\\mathbf{GL}\\)-validity is that the frame\nbe transitive, finite and irreflexive. \n\n The applications of modal logic to mathematics and computer science\nhave become increasingly important. Provability logic is only one\nexample of this trend. The term “advanced modal logic”\nrefers to a tradition in modal logic research that is particularly\nwell represented in departments of mathematics and computer\nscience. This tradition has been woven into the history of modal logic\nright from its beginnings (Goldblatt, 2006). Research into\nrelationships with topology and algebras represents some of the very\nfirst technical work on modal logic. However the term ‘advanced\nmodal logic’ generally refers to a second wave of work done\nsince the mid 1970s. Some examples of the many interesting topics\ndealt with include results on decidability (whether it is possible to\ncompute whether a formula of a given modal logic is a theorem) and\ncomplexity (the costs in time and memory needed to compute such facts\nabout modal logics). \n\nBisimulation provides a good example of the fruitful interactions that\nhave been developed between modal logic and computer science. In\ncomputer science, labeled transition systems (LTSs) are commonly used\nto represent possible computation pathways during execution of a\nprogram. LTSs are generalizations of Kripke frames, consisting of a\nset \\(W\\) of states, and a collection of \\(i\\)-accessibility relations\n\\(R_i\\), one for each computer process \\(i\\). Intuitively, \\(wR_i w'\\)\nholds exactly when \\(w'\\) is a state that results from applying the\nprocess \\(i\\) to state \\(w\\). \n\nThe language of poly-modal or dynamic logic introduces a collection of\nmodal operators \\(\\Box_i\\), one for each program \\(i\\) (Harel,\n1984). Then \\(\\Box_i\\)A states that sentence \\(A\\) holds in every\nresult of applying \\(i\\). So ideas like the correctness and successful\ntermination of programs can be expressed in this language. Models for\nsuch a language are like Kripke models save that LTSs are used in\nplace of frames. A bisimulation is a counterpart relation\nbetween states of two such models such that exactly the same\npropositional variables are true in counterpart states, and whenever\nworld \\(v\\) is \\(i\\)-accessible from one of two counterpart states,\nthen the other counterpart bears the \\(i\\)-accessibility relation to\nsome counterpart of \\(v\\). In short, the \\(i\\)-accessibility structure\none can “see” from a given state mimics what one sees from\na counterpart. Bisimulation is a weaker notion than isomorphism (a\nbisimulation relation need not be 1-1), but it is sufficient to\nguarantee equivalence in processing. \n\nIn the 1970s, a version of bisimulation had already been developed by\nmodal logicians to help better understand the relationship between\nmodal logic axioms and their corresponding conditions on Kripke\nframes. Kripke’s semantics provides a basis for translating\nmodal axioms into sentences of a second-order language where\nquantification is allowed over one-place predicate letters\n\\(P\\). Replace metavariables \\(A\\) with open sentences \\(Px\\),\ntranslate \\(\\Box Px\\) to \\(\\forall y(Rxy \\rightarrow Py)\\), and close\nfree variables \\(x\\) and predicate letters \\(P\\) with universal\nquantifiers. For example, the predicate logic translation of the axiom\nschema \\(\\Box A\\rightarrow A\\) comes to \\(\\forall P \\forall x[\\forall\ny(Rxy\\rightarrow Py) \\rightarrow Px\\)]. Given this translation, one\nmay instantiate the variable \\(P\\) to an arbitrary one-place\npredicate, for example to the predicate \\(Rx\\) whose extension is the\nset of all worlds w such that \\(Rxw\\) for a given value of\n\\(x\\). Then one obtains \\(\\forall x[\\forall y(Rxy\\rightarrow Rxy)\n\\rightarrow Rxx\\)], which reduces to \\(\\forall xRxx\\), since \\(\\forall\ny(Rxy\\rightarrow Rxy)\\) is a tautology. This illuminates the\ncorrespondence between \\(\\Box A\\rightarrow A\\) and reflexivity of\nframes \\((\\forall xRxx)\\). Similar results hold for many other axioms\nand frame conditions. The “collapse” of second-order axiom\nconditions to first order frame conditions is very helpful in\nobtaining completeness results for modal logics. For example, this is\nthe core idea behind the elegant results of Sahlqvist (1975). \n\nBut when does the second-order translation of an axiom reduce to a\nfirst-order condition on \\(R\\) in this way? In the 1970s, van\nBenthem showed that this happens iff the translation’s holding in a\nmodel entails its holding in any bisimular model, where two models are\nbisimular iff there is a bisimulation between them in the special case\nwhere there is a single accessibility relation. That result\ngeneralizes easily to the poly-modal case (Blackburn et. al., 2001, p. 103). \nThis suggests that poly-modal logic lies at exactly the right\nlevel of abstraction to describe, and reason about, computation and\nother processes. (After all, what really matters there is the\npreservation of truth values of formulas in models rather than the\nfiner details of the frame structures.) Furthermore the implicit\ntranslation of those logics into well-understood fragments of\npredicate logic provides a wealth of information of interest to\ncomputer scientists. As a result, a fruitful area of research in\ncomputer science has developed with bisimulation as its core idea\n(Ponse et al. 1995). \nThe interaction between the theory of games and modal logic is a flourishing new area of research (van der Hoek and Pauly, 2007; van Benthem, 2011, Ch. 10, and 2014). This work has interesting applications to understanding cooperation and competition among agents as information available to them evolves.  \nThe Prisoner’s Dilemma illustrates some of the concepts in game theory that can be analyzed using modal logics. Imagine two players that choose to either cooperate or cheat. If both cooperate, they both achieve a reward of 3 points, if they both cheat, they both get nothing, and if one cooperates and the other cheats, the cheater makes off with 5 points and the cooperator gets nothing. If both players are altruistic and motivated to maximize the sum of their rewards, they will both cooperate, as this is the best they can do together. However, they are both tempted to cheat to increase their own reward from 3 to 5. On the other hand, if they are rational, they may recognize that if they cheat their opponent threatens to cheat and leave them with nothing. So cooperation is the best one can do given this threat. And if each thinks the other realizes this, they may be motivated to cooperate. An extended (or iterated) version of this game gives the players multiple moves, that is, repeated opportunities to play and collect rewards. If players have information about the history of the moves and their outcomes, new concerns come into play, as success in the game depends on knowing their opponent’s strategy, and determining (for example) when he/she can be trusted not to cheat. In multi-player versions of the game, where players are drawn in pairs from a larger pool at each move, one’s own best strategy may well depend on whether one can recognize one’s opponents and the strategies they have adopted. (See Grim et. al., 1998 for fascinating research on Interated Prisoner’s Dilemmas.)  \nIn games like Chess, players take turns making their moves and their\nopponents can see the moves made. If we adopt the convention that the\nplayers in a game take turns making their moves, then the Iterated\nPrisoner’s Dilemma is a game with missing information about the\nstate of play – the player with the second turn lacks\ninformation about what the other player’s last move was. This\nillustrates the interest of games with imperfect information.  \n\nThe application of games to logic has a long history. One influential\napplication with important implications for linguistics is Game\nTheoretic Semantics (GTS) (Hintikka et. al. 1983), where validity is\ndefined by the outcome of a game between two players one trying to\nverify and the other trying to falsify a given formula. GTS has\nsignificantly stronger resources that standard Tarski-style semantics,\nas it can be used (for example) to explain how meaning evolves in a\ndiscourse (a sequence of sentences).  However, the work on games and modal logic to be described here is\nsomewhat different. Instead of using games to analyze the semantics of\na logic, the modal logics at issue are used to analyze games. The\nstructure of games and their play is very rich, as it involves the\nnature of the game itself (the allowed moves, and the rewards for the\noutcomes), the strategies (which are sequences of moves through time),\nand the flow of information available to the players as the game\nprogresses. Therefore, the development of modal logic for games draws\non features found in logics involving concepts like time, agency,\npreference, goals, knowledge, belief, and cooperation.  \nTo provide some hint at this variety, here is a limited description of\nsome of the modal operators that turn up in the analysis of games and\nsome of the things that can be expressed with them. The basic idea in\nthe semantics is that a game consists of a set of players 1, 2, 3,\n…, and a set of W of game states. For each player i, there is\nan accessibility relation \\(R_i\\) understood so that \\(sR_i t\\) holds\nfor states \\(s\\) and \\(t\\) iff when the game has come to state \\(s\\)\nplayer \\(i\\) has the option of making a move that results in\n\\(t\\). This collection of relations defines a tree whose branches\ndefine every possible sequence of moves in the game. The semantics\nalso assigns truth-values to atoms that keep track of the payoffs. So,\nfor example in a game like Chess, there could be an atom \\(\\win_i\\)\nsuch that \\(v(\\win_i, s)=T\\) iff state s is a win for player\n\\(i\\). Model operators \\(\\Box_i\\) and \\(\\Diamond_i\\) for each player i\nmay then be defined as follows. \nSo \\(\\Box_i A\\) \\((\\Diamond_i A)\\) is true in s provided that sentence\n\\(A\\) holds true in every (some) state that \\(i\\) can chose from state\n\\(s\\). Given that \\(\\bot\\) is a contradiction (so \\({\\sim}\\bot\\) is a\ntautology), \\(\\Diamond_i {\\sim}\\bot\\) is true at a state when it is\n\\(i\\)’s turn to move. For a two-player game \\(\\Box_1\\bot\\) &\n\\(\\Box_2\\bot\\) is true of a state that ends the game, because neither\n1 nor 2 can move. \\(\\Box_1\\Diamond_2\\)win\\(_2\\) asserts that player 1\nhas a loss because whatever 1 does from the present state, 2 can win\nin the following move.  \nFor a more general account of the player’s payoffs, ordering\nrelations \\(\\leq_i\\) can be defined over the states so that \\(s\\leq_i\nt\\) means that \\(i\\)’s payoff for \\(t\\) is at least as good as\nthat for \\(s\\). Another generalization is to express facts about\nsequences \\(q\\) of moves, by introducing operators interpreted by\nrelations \\(sR_q t\\) indicating that the sequence \\(q\\) starting from\ns eventually arrives at \\(t\\). With these and related resources, it is\npossible express (for example) that q is \\(i\\)’s best strategy\ngiven the present state. \nIt is crucial to the analysis of games to have a way to express the\ninformation available to the players. One way to accomplish this is to\nborrow ideas from epistemic logic. Here we may introduce an\naccessibility relation \\({\\sim}_i\\) for each player such that\n\\(s{\\sim}_i t\\) holds iff \\(i\\) cannot distinguish between states\n\\(s\\) and \\(t\\). Then knowledge operators \\(\\rK_i\\) for the players\ncan be defined so that \\(\\rK_i A\\) says at \\(s\\) that \\(A\\) holds in\nall worlds that \\(i\\) can distinguish from \\(s\\); that is, despite\n\\(i\\)’s ignorance about the state of play, he/she can still be\nconfident that \\(A\\). \\(\\rK\\) operators may be used to say that player\n1 is in a position to resign, for he knows that 2 sees she has a win:\n\\(\\rK_1 \\rK_2\\Box_1\\Diamond_2\\win_2\\). \nSince player’s information varies as the game progresses, it is\nuseful to think of moves of the game as indexed by times, and to\nintroduce operators \\(O\\) and \\(U\\) from tense logic for\n‘next’ and ‘until’. Then \\(K_i OA\n\\rightarrow OK_i A\\) expresses that player \\(i\\) has “perfect\nrecall”, that is, that when \\(i\\) knows that \\(A\\) happens next, then\nat the next moment \\(i\\) has not forgotten that \\(A\\) has\nhappened. This illustrates how modal logics for games can reflect\ncognitive idealizations, and a player’s success (or failure) at\nliving up to them. \nThe technical side of the modal logics for games is challenging. The\nproject of identifying systems of rules that are sound and complete\nfor a language containing a large collection of operators may be\nguided by past research, but the interactions between the variety of\naccessibility relations leads to new concerns. Furthermore, the\ncomputational complexity of various systems and their fragments is a\nlarge landscape largely unexplored. \nGame theoretic concepts can be applied in a surprising variety of ways\n– from checking an argument for validity to succeeding in the\npolitical arena. So there are strong motivations for formulating\nlogics that can handle games. What is striking about this research is\nthe power one obtains by weaving together logics of time, agency,\nknowledge, belief, and preference in a unified setting. The lessons\nlearned from that integration have value well beyond what they\ncontribute to understanding games. \n\nIt would seem to be a simple matter to outfit a modal logic with the\nquantifiers \\(\\forall\\) (all) and \\(\\exists\\) (some). One would simply\nadd the standard (or classical) rules for quantifiers to the\nprinciples of whichever propositional modal logic one\nchooses. However, adding quantifiers to modal logic involves a number\nof difficulties. Some of these are philosophical. For example, Quine\n(1953) has famously argued that quantifying into modal contexts is\nsimply incoherent, a view that has spawned a gigantic\nliterature. Quine’s complaints do not carry the weight they once\ndid. See Barcan (1990) for a good summary, and note Kripke’s\n(2017) (written in the 60’s for a class with Quine) which\nprovides a strong formal argument that there can be nothing wrong with\n“quantifying in”.  \nA second kind of complication is technical. There is a wide variety in\nthe choices one can make in the semantics for quantified modal logic,\nand the proof that a system of rules is correct for a given choice can\nbe difficult. The work of Corsi (2002) and Garson (2005) goes some way\ntowards bringing unity to this terrain, and Johannesson (2018)\nintroduces constraints that help reduce the number of options;\nnevertheless the situation still remains challenging. \n\nAnother complication is that some logicians believe that modality\nrequires abandoning classical quantifier rules in favor of the weaker\nrules of free logic (Garson 2001). The main points of disagreement\nconcerning the quantifier rules can be traced back to decisions about\nhow to handle the domain of quantification. The simplest alternative,\nthe fixed-domain (sometimes called the possibilist) approach, assumes\na single domain of quantification that contains all the possible\nobjects. On the other hand, the world-relative (or actualist)\ninterpretation, assumes that the domain of quantification changes from\nworld to world, and contains only the objects that actually exist in a\ngiven world. \n\nThe fixed-domain approach requires no major adjustments to the\nclassical machinery for the quantifiers. Modal logics that are\nadequate for fixed domain semantics can usually be axiomatized by\nadding principles of a propositional modal logic to classical\nquantifier rules together with the Barcan Formula\n\\((BF)\\) (Barcan 1946). (For an account of some\ninteresting exceptions see Cresswell (1995)). \n\nThe fixed-domain interpretation has advantages of simplicity and\nfamiliarity, but it does not provide a direct account of the semantics\nof certain quantifier expressions of natural language. We do not think\nthat ‘Some man exists who signed the Declaration of\nIndependence’ is true, at least not if we read\n‘exists’ in the present tense. Nevertheless, this sentence\nwas true in 1777, which shows that the domain for the natural language\nexpression ‘some man exists who’ changes to reflect which\nmen exist at different times. A related problem is that on the\nfixed-domain interpretation, the sentence \\(\\forall y\\Box \\exists\nx(x=y)\\) is valid. Assuming that \\(\\exists x(x=y)\\) is read: \\(y\\)\nexists, \\(\\forall y\\Box \\exists x(x=y)\\) says that everything exists\nnecessarily. However, it seems a fundamental feature of common ideas\nabout modality that the existence of many things is contingent, and\nthat different objects exist in different possible worlds.  \n\nThe defender of the fixed-domain interpretation may respond to these\nobjections by insisting that on his (her) reading of the quantifiers,\nthe domain of quantification contains all possible objects,\nnot just the objects that happen to exist at a given world. So the\ntheorem \\(\\forall y\\Box \\exists x(x=y)\\) makes the innocuous claim\nthat every possible object is necessarily found in the domain\nof all possible objects. Furthermore, those quantifier expressions of\nnatural language whose domain is world (or time) dependent can be\nexpressed using the fixed-domain quantifier \\(\\exists x\\) and a\npredicate letter \\(E\\) with the reading ‘actually\nexists’. For example, instead of translating ‘Some \\(M\\)an\nexists who \\(S\\)igned the Declaration of Independence’ by \n\nthe defender of fixed domains may write:  \n\nthus ensuring the translation is counted false at the present time.\nCresswell (1991) makes the interesting observation that world-relative\nquantification has limited expressive power relative to fixed-domain\nquantification. World-relative quantification can be defined with\nfixed domain quantifiers and \\(E\\), but there is no way to fully\nexpress fixed-domain quantifiers with world-relative ones. Although\nthis argues in favor of the classical approach to quantified modal\nlogic, the translation tactic also amounts to something of a\nconcession in favor of free logic, for the world-relative quantifiers\nso defined obey exactly the free logic rules.  \n\nA problem with the translation strategy used by defenders of fixed\ndomain quantification is that rendering the English into logic is less\ndirect, since \\(E\\) must be added to all translations of all\nsentences whose quantifier expressions have domains that are context\ndependent. A more serious objection to fixed-domain quantification is\nthat it strips the quantifier of a role which Quine recommended for\nit, namely to record robust ontological commitment. On this view, the\ndomain of \\(\\exists x\\) must contain only entities that are\nontologically respectable, and possible objects are too abstract to\nqualify. Actualists of this stripe will want to develop the logic of a\nquantifier \\(\\exists x\\) which reflects commitment to what is\nactual in a given world rather than to what is merely possible. \n\nHowever, some work on\n actualism (Menzel, 1990) \ntends to undermine this objection. For example, Linsky and Zalta\n(1994) and Williamson, (2013) argue that the fixed-domain quantifier\ncan be given an interpretation that is perfectly acceptable to\nactualists. Pavone (2018) even contends that on the haecceitist\ninterpretation, which quantifies over individual essences, fixed\ndomains are required. Actualists who employ possible worlds\nsemantics routinely quantify over possible worlds in their semantical\ntheory of language. So it would seem that possible worlds are actual\nby these actualist’s lights. By populating the domain with\nabstract entities no more objectionable than possible worlds,\nactualists may vindicate the Barcan Formula and classical\nprinciples.  \nNote however, that some actualists may respond that they need not be\ncommitted to the actuality of possible worlds so long as it is\nunderstood that quantifiers used in their theory of language lack\nstrong ontological import. Furthermore, Hayaki (2006) argues that\nquantifying over abstract entities is actually incompatible with any\nserious form of actualism. In any case, it is open to actualists (and\nnon actualists as well) to investigate the logic of quantifiers with\nmore robust domains, for example domains excluding possible worlds and\nother such abstract entities, and containing only the spatio-temporal\nparticulars found in a given world. For quantifiers of this kind, a\nworld-relative domains are appropriate. \n\nSuch considerations motivate interest in systems that acknowledge the\ncontext dependence of quantification by introducing world-relative\ndomains. Here each possible world has its own domain of quantification\n(the set of objects that actually exist in that world), and the\ndomains vary from one world to the next. When this decision is made, a\ndifficulty arises for classical quantification theory. Notice that the\nsentence \\(\\exists x(x=t)\\) is a theorem of classical logic, and so\n\\(\\Box \\exists x(x=t)\\) is a theorem of \\(\\bK\\) by the Necessitation\nRule. Let the term \\(t\\) stand for Saul Kripke. Then this theorem says\nthat it is necessary that Saul Kripke exists, so that he is in the\ndomain of every possible world. The whole motivation for the\nworld-relative approach was to reflect the idea that objects in one\nworld may fail to exist in another. If standard quantifier rulers are\nused, however, every term \\(t\\) must refer to something that exists in\nall the possible worlds. This seems incompatible with our ordinary\npractice of using terms to refer to things that only exist\ncontingently. \n\nOne response to this difficulty is simply to eliminate terms. Kripke\n(1963) gives an example of a system that uses the world-relative\ninterpretation and preserves the classical rules. However, the costs\nare severe. First, his language is artificially impoverished, and\nsecond, the rules for the propositional modal logic must be\nweakened. \n\nPresuming that we would like a language that includes terms, and that\nclassical rules are to be added to standard systems of propositional\nmodal logic, a new problem arises. In such a system, it is possible to\nprove \\((CBF)\\), the converse of the Barcan\nFormula. \n\nThis fact has serious consequences for the system’s\nsemantics. It is not difficult to show that every world-relative model\nof \\((CBF)\\) must meet condition \\((ND)\\) (for ‘nested\ndomains’).  \n\nHowever \\((ND)\\) conflicts with the point of introducing\nworld-relative domains. The whole idea was that existence of objects\nis contingent so that there are accessible possible worlds where one\nof the things in our world fails to exist.  \n\nA straightforward solution to these problems is to abandon classical\nrules for the quantifiers and to adopt rules for free logic\n\\((\\mathbf{FL})\\) instead. The rules of \\(\\mathbf{FL}\\) are the same\nas the classical rules, except that inferences from \\(\\forall xRx\\)\n(everything is real) to \\(Rp\\) (Pegasus is real) are blocked. This is\ndone by introducing a predicate ‘\\(E\\)’ (for\n‘actually exists’) and modifying the rule of universal\ninstantiation. From \\(\\forall xRx\\) one is allowed to obtain \\(Rp\\)\nonly if one also has obtained \\(Ep\\). Assuming that the universal\nquantifier \\(\\forall x\\) is primitive, and the existential quantifier\n\\(\\exists x\\) is defined by \\(\\exists xA =_{df} {\\sim}\\forall\nx{\\sim}A\\), then \\(\\mathbf{FL}\\) may be constructed by adding the\nfollowing two principles to the rules of propositional logic \nUniversal Generalization.\nIf \\(B\\rightarrow(Ey\\rightarrow A(y))\\) is a theorem, so is\n\\(B\\rightarrow \\forall xA(x)\\). \nUniversal Instantiation.\n\\(\\forall xA(x)\\rightarrow(En\\rightarrow A(n))\\)\n \n\n(Here it is assumed that \\(A(x)\\) is any well-formed formula of\npredicate logic, and that \\(A(y)\\) and \\(A(n)\\) result from replacing\n\\(y\\) and \\(n\\) properly for each occurrence of \\(x\\) in \\(A(x)\\).)\nNote that the instantiation axiom is restricted by mention of \\(En\\)\nin the antecedent. The rule of Universial Generalization is modified\nin the same way. In \\(\\mathbf{FL}\\), proofs of formulas like \\(\\exists\nx\\Box(x=t)\\), \\(\\forall y\\Box \\exists x(x=y)\\), \\((CBF)\\), and\n\\((BF)\\), which seem incompatible with the world-relative\ninterpretation, are blocked.  \n\nOne philosophical objection to \\(\\mathbf{FL}\\) is that \\(E\\)\nappears to be an existence predicate, and many would argue that\nexistence is not a legitimate property like being green or weighing\nmore than four pounds. So philosophers who reject the idea that\nexistence is a predicate may object to \\(\\mathbf{FL}\\). However in\nmost (but not all) quantified modal logics that include identity \\((=)\\)\nthese worries may be skirted by defining \\(E\\) as follows. \n\nThe most general way to formulate quantified modal logic is to create\n\\(\\mathbf{FS}\\) by adding the rules of \\(\\mathbf{FL}\\) to a\ngiven propositional modal logic \\(\\mathbf{S}\\). In situations\nwhere classical quantification is desired, one may simply add\n\\(Et\\) as an axiom to \\(\\mathbf{FS}\\), so that the\nclassical principles become derivable rules. Adequacy results for such\nsystems can be obtained for most choices of the modal logic\n\\(\\mathbf{S}\\), but there are exceptions.  \n\nA final complication in the semantics for quantified modal logic is\nworth mentioning. It arises when non-rigid expressions such as\n‘the inventor of bifocals’ are introduced to the language.\nA term is non-rigid when it picks out different objects in different\npossible worlds. The semantical value of such a term can be given by\nwhat Carnap (1947) called an individual concept, a function that picks\nout the denotation of the term for each possible world. One approach\nto dealing with non-rigid terms is to employ Russell’s theory of\ndescriptions. However, in a language that treats non rigid expressions\nas genuine terms, it turns out that neither the classical nor the free\nlogic rules for the quantifiers are acceptable. (The problem can not\nbe resolved by weakening the rule of substitution for identity.) A\nsolution to this problem is to employ a more general treatment of the\nquantifiers, where the domain of quantification contains individual\nconcepts rather than objects. This more general interpretation\nprovides a better match between the treatment of terms and the\ntreatment of quantifiers and results in systems that are adequate for\nclassical or free logic rules (depending on whether the fixed domains\nor world-relative domains are chosen). It also provides a language\nwith strong and much needed expressive powers (Bressan, 1973, Belnap\nand Müller, 2013a, 2013b). ","contact.mail":"JGarson@uh.edu","contact.domain":"uh.edu"}]
