[{"date.published":"2001-12-31","date.changed":"2016-02-24","url":"https://plato.stanford.edu/entries/closure-epistemic/","author1":"Steven Luper","author1.info":"http://www.trinity.edu/departments/philosophy/steven_luperhome_page.htm","entry":"closure-epistemic","body.text":"\n\n\nMost of us think we can safely enlarge our knowledge base by accepting\nthings that are entailed by (or logically implied by) things we know.\nRoughly speaking, the set of things we know is closed under entailment\n(or under deduction or logical implication), so we know that a given\nclaim is true upon recognizing, and accepting thereby, that it follows\nfrom what we know. This is not to say that our usual way of adding to\nour knowledge is simply to recognize and accept what follows from what\nwe already know. Obviously much more is involved. For instance, we\ngather data and construct explanations of those data, and under\nsuitable circumstances we learn from others. More to the point at\nhand, when we claim that we know, of some proposition, that it is\ntrue, that claim is itself subject to error; often, seeing what\nfollows from a knowledge claim prompts us to reassess and even\nwithdraw our claim, instead of concluding, of the things that follow\nfrom it, that we know that they are true. Still, it seems reasonable\nto think that if we do know that some proposition is true\nthen we are in a position to know, of the things that follow from it,\nthat they, too, are true. However, some theorists have denied that\nknowledge is closed under entailment. The arguments against closure\ninclude the following:\n\n\n\n\nThe argument from the analysis of knowledge: given the\ncorrect analysis, knowledge is not closed, so it isn’t. For\nexample, if the correct analysis includes a tracking condition, then\nclosure fails.\n\n\nThe argument from nonclosure of knowledge modes: since the\nmodes of gaining, preserving or extending knowledge, such as\nperception, testimony, proof, memory, indication, and information are\nnot individually closed, neither is knowledge.\n\n\nThe argument from unknowable (or not easily knowable)\npropositions: certain sorts of propositions cannot be known\n(without special measures); given closure, they could be known\n(without special measures), by deducing them from mundane claims we\nknown, so knowledge is not closed.\n\n\nThe argument from skepticism: skepticism is false but it\nwould be true if knowledge were closed, so knowledge is not\nclosed.\n\n\n\nWhile proponents of closure have responses to these arguments, they\nalso argue, somewhat in the style of G. E. Moore (1959), that closure\nitself is a firm datum—it is obvious enough to rule out any\nunderstanding of knowledge or related notions that undermines\nclosure.\n\n\nA closely related idea is that it is rational (justifiable) for us to\nbelieve anything that follows from what it is rational for us to\nbelieve. This idea is intimately related to the thesis that knowledge\nis closed, since, according to some theorists, knowing p\nentails justifiably believing p. If knowledge entails\njustification, closure failure of the latter might lead to closure\nfailure of the former.\n\nPrecisely what is meant by the claim that knowledge is closed under\nentailment? One response is that the following straight principle of\nclosure of knowledge under entailment is true: \nThe conditional involved in the straight principle might be the\nmaterial conditional, the subjunctive conditional, or entailment,\nyielding three possibilities, each stronger than the one before: \nHowever, each version of the straight principle is false, since we can\nknow one thing, p, but fail to see that p entails\nq, or for some other reason fail to believe q. Since\nknowledge entails belief (according to nearly all theorists), we fail\nto know q. A less obvious worry is that we might reason badly\nin coming to believe that p entails q. Perhaps we\nthink that p entails q because we think everything\nentails everything, or because we have a warm tingly feeling between\nour toes. Hawthorne (2005) raises the possibility that, in the course\nof grasping that p entails q, S will cease\nto know p. He also notes that SP1 is defensible on the\n(deviant) assumption that a thought, p, is equivalent to\nanother, q, if p and q hold in all of the\nsame possible worlds. Suppose p entails q. Then\np is equivalent to the conjunction of p and\nq, and so the thought p is identical to the thought\np and q. Hence in knowing p S\nknows p and q. Assuming that, in knowing p\nand q, S knows p and S knows q,\nthen when S knows p S knows q, as\nSP1 says. \nThe straight principle needs qualifying, but this should not concern\nus so long as the qualifications are natural given the idea we are\ntrying to capture, namely, that we can extend our knowledge by\nrecognizing, and accepting thereby, things that follow from something\nthat we know. The qualifications embedded in the following principle\n(construed as a material conditional) seem natural enough: \nAs Williamson (2000) notes, the idea that we can extend our knowledge\nby applying deduction to what we know supports a closure principle\nthat is stronger than K. It is a principle that says we know\nthings we believe on the grounds that they are jointly implied by\nseveral separate known items. Suppose I know Mary is tall and I know\nMary is left handed. K does not authorize my putting these two\npieces of knowledge together so as to know that Mary is tall and left\nhanded. But the following generalized closure principle covers\ndeductions involving separate known items: \nSome theorists distinguish between something they call “single\npremise” and something they call “multiple-premise\nclosure”. Such theorists would deny that K captures\n“single premise” closure, because K says that\nS knows q if S knows that two\nthings are true: that p is true as well as that p\nentails q. The “single premise” closure principle\nis usually formulated roughly as follows (following Williamson 2002\nand Hawthorne 2004): \nHowever, it is far from clear that one may competently deduce\nq from p without relying on any knowledge aside from\np. Fortunately, it seems that nothing hinges on this\npossibility, except perhaps for people interested in whether we can\nidentify something that can appropriately be labeled “single\npremise closure principle”. \nProponents of closure might accept both K and GK,\nperhaps further qualified in natural ways (but they might not: see the\nconcerns about justification closure raised in section 6). By\ncontrast, Fred Dretske and Robert Nozick reject K and therefore\nGK as well. They reject any closure principle, no matter how\nnarrowly restricted, that warrants our knowing that skeptical\nhypotheses (e.g., I am a brain in a vat) are false on the basis of\nmundane knowledge claims (e.g., I am not in a vat). In addition to\nrejecting K and GK, they deny knowledge closure across\ninstantiation and simplification, but not across equivalence (Nozick\n1981: 227–229):  \nLet us turn to their arguments. \nThe argument from the analysis of knowledge says that the correct\naccount of knowledge leads to K failure. We can distinguish two\nversions. According to the first version, K fails because\nknowledge requires belief tracking. According to the second, any\nrelevant alternatives account, such as Dretske’s and Nozick’s, leads\nto K failure. According to Dretske (2003: 112–3; 2005:\n19), any relevant alternatives account leads “naturally”\nbut “not inevitably” to K failure.  \nIn rough outline, the first version involves defending say Dretske’s\nor Nozick’s tracking analysis of knowledge, then showing that it\nundermines K (versions of the tracking account are also\ndefended by Becker 2009, by Murphy and Black 2007, and by Roush 2005,\nthe last of whom modifies the tracking account so as to preserve\nclosure; for criticisms of Rouse see Brueckner 2012). We can skip the\ndefense, which consists largely in showing that tracking does a better\njob than competitors in dealing with our epistemic intuitions about\ncases of purported knowledge. We may also simplify the analyses.\nAccording to Nozick, to know p is, very roughly (and ignoring\nhis thoroughly discredited fourth condition for knowledge, criticized,\ne.g, in Luper 1984 and 2009 and in Kripke 2011), to have a belief\np which meets the following condition\n(‘BT’ for belief tracking): \nThat is, in the close worlds to the actual world in which\nnot-p holds, S does not believe p. The\nactual world is one’s situation as it is when one arrives at the\nbelief p. BT requires that in all nearby\nnot-p worlds S fails to believe p. (The\nsemantics of subjunctive conditionals is clarified in Stalnaker 1968,\nLewis 1973, and modified by Nozick 1981 note 8.) On Dretske’s view\nknowing p is roughly a matter of having a reason R\nfor believing p which meets the following condition\n(‘CR’ for conclusive reason): \nThat is, in the close worlds to the actual world in which\nnot-p holds, R does not. When R meets this\ncondition, Dretske says R is a conclusive reason for\nbelieving p. \nDretske pointed out (2003, n. 9; 2005, n. 4) that his view does not\nface one of the objections which Saul Kripke (2011, 162–224; Dretske\nhad access to a draft circulated prior to publication) deploys against\nNozick’s account. Suppose I am driving through a neighborhood in\nwhich, unbeknownst to me, papier-mâché barns are\nscattered, and I see that the object in front of me is a barn. I also\nnotice that it is red. Because I have barn-before-me percepts, I\nbelieve barn: the object in front of me is a (ordinary) barn\n(the example is attributed to Ginet in Goldman 1976). Our intuitions\nsuggest that I fail to know barn. And so say BT and\nCR. But now suppose that the neighborhood has no fake\nred barns; the only fake barns are blue. (Call this the red\nbarn case.) Then on Nozick’s view I can track the fact that there is a\nred barn, since I would not believe there was a red barn (via my\nred-barn percepts) if no red barn were there, but I cannot track the\nfact that there is a barn, since I might believe there was a barn (via\nblue-barn percepts) even if no barn were there. Dretske said\nthat this juxtaposition, in which I know something yet fail to know a\nsecond thing that is intimately related to the first (there being a\nred barn, which I know, entails there being a barn, which I do not),\n“is an embarrassment,” and in this respect, he thought,\nhis view is superior to Nozick’s. Let R, my basis for belief,\nbe the fact that I have red-barn percepts. If no barn were there,\nR would fail to hold, so I know a barn is there. Further, if\nno red barn were there, R would still fail to hold,\nso I know a red barn is there. So Dretske can avoid the\nobjectionable juxtaposition. Still, it is surprising that Dretske\ncited the red barn case as the basis for preferring his version of\ntracking over Nozick’s. First, Dretske himself accepted juxtapositions\nof knowledge and ignorance that are at least equally bizarre, as we\nshall see. Second, Nozick avoided the very juxtaposition Dretske\ndiscussed by restating his account to make reference to the methods\nvia which we come to believe things (Hawthorne 2005). On a more\npolished version of his account, Nozick said that to know p\nis, roughly, to have a belief p, arrived at through a method\nM, which meets the following condition\n(‘BMT’ for belief method tracking): \nIf no red barn were there I would believe neither that there was a\nbarn, nor that there was a red barn, via red-barn percepts.\n \nThird, the red barn case is one about which intuitions will vary. It\nis not obvious that I do know there is a red barn in the\ncircumstances Dretske sketches, which differ from those in Ginet’s\noriginal barn case (where I fail to know barn) only in the\nstipulations that I see a red barn and that none of the barn simulacra\nare red. What is more, both Dretske’s and Nozick’s accounts have the\nodd implication that I know there is a barn if I base my belief on my\nred barn percepts yet I fail to know this if, in basing it on my barn\npercepts, I ignore the barn’s color. Presumably the barn’s color is\nnot relevant to its being a barn.  \nThe tracking accounts permit counterexamples to K. Dretske’s\nwell-known illustration is the zebra case (1970): suppose you are at a\nzoo in ordinary circumstances standing in front of a cage marked\n‘zebra’; the animal in the cage is a zebra, and you\nbelieve zeb, the animal in the cage is a zebra, because you\nhave zebra-in-a-cage visual percepts. It occurs to you that\nzeb entails not-mule, it is not the case that the\nanimal in the cage is a cleverly disguised mule rather than a zebra.\nYou then believe not-mule by deducing it from zeb.\nWhat do you know? You know zeb, since, if zeb were\nfalse, you would not have zebra-in-a-cage visual percepts; instead,\nyou would have empty-cage percepts, or aardvark-in-a-cage percepts, or\nthe like. Do you know not-mule? If not-mule were\nfalse, you would still have zebra-in-a-cage visual percepts (and you\nwould still believe zeb, and you would still believe\nnot-mule by deducing it from zeb). So you do\nnot know not-mule. But notice that we have: \nIn view of (a)–(c), we have a counterexample to K, which\nentails that if (a) you know zeb, and (b) you believe\nnot-mule by recognizing that zeb entails\nnot-mule, then you do know not-mule,\ncontrary to (c). \nHaving rejected K, and denying that we know things like\nnot-mule, Nozick also had to deny closure across\nsimplification. For if some proposition p entails another\nproposition q, then p is equivalent to the\nconjunction p & q; accordingly, given closure across\nequivalence, which Nozick accepted, if we know zeb we can\nknow the conjunction zeb & not-mule, but if we also\naccept closure across simplification, we will be able to know\nnot-mule.  \nIn response to this first version of the argument from the analysis of\nknowledge, some theorists (e.g., Luper 1984, BonJour 1987, DeRose\n1995) argued that K has great plausibility in its own right\n(which Dretske acknowledged in 2005: 18) so it should be abandoned\nonly in the face of compelling reasons, yet there are no such\nreasons. \nTo show there are no compelling reasons to abandon K, theorists\nhave provided accounts of knowledge that (a) handle our intuitions at\nleast as successfully as the tracking analyses and yet (b) underwrite\nK. One way to do this is to weaken the tracking analysis so\nthat we know things that we track or that we believe because we know\nthat they follow from things that we track (this sort of option has\nbeen turned against Nozick by various theorists; Roush defends it in\n2005, 41–51). Another approach is as follows. Knowing p is\nroughly a matter of having a reason R for believing\np which meets the following condition\n(‘SI’ for safe indication): \nSI requires that p be true in the nearby R\nworlds. When R meets this condition, let us say that\nR is a safe indicator that p is true.\n(Different versions of the safety condition have been defended; see,\nfor example, Luper 1984; Sosa 1999, 2003, 2007, 2009; Williamson 2000;\nand Pritchard 2007.) SI is the contraposition of CR, but\nthe contraposition of a subjunctive conditional is not equivalent to\nthe original. \nLet us suppose without argument that SI handles cases of\nknowledge and ignorance as intuitively as CR. Why say SI\nunderwrites K? The key point is that if R safely\nindicates that p is true, then it safely indicates that\nq is true, where q is any of p’s\nconsequences. Put another way, the point is that the following\nreasoning is valid (being an instance of strengthening the\nconsequence): \nHence, if a person S knows p on the basis of\nR, S is in a position to know q on the\nbasis of R, where q follows from p.\nS is also in a position to know q on the basis of\nthe conjunction of R together with the fact that p\nentails q. Thus if S knows p on some basis\nR, and believes q on the basis of R (on\nwhich p rests) together with the fact that p entails\nq, then S knows q. Again: if \nthen \nas K requires. To illustrate, let us use Dretske’s example.\nHaving based your belief zeb on your zebra-in-the-cage\npercepts, you know zeb according to SI: given your\ncircumstances, if you had those percepts, zeb would be true.\nMoreover, when you believe not-mule by first believing\nzeb on the basis of your zebra-in-the-cage percepts then\ndeducing not-mule from zeb, you know\nnot-mule according to SI: if you had those percepts\nnot only would zeb hold, so would its consequence\nnot-mule. \nLet us digress briefly in order to note that some versions of the\nsafety account will not uphold closure (Murphy 2005 presses this\nobjection against Sosa’s version of the safety account). For example,\nat one point Ernest Sosa discussed the following version of the\ncondition: \nIf S were to believe p, p would be true.\n \nThis is to require that one’s belief safely indicates its own\ntruth. However, it is entirely possible to be so situated that one’s\nbelief safely indicates its truth even though the requisite condition\nis not met for something that follows from that belief. The point can\nbe illustrated with a version of the red barn case. Suppose that (on\nthe basis of my red-barn percepts) I believe red barn: there\nis a red barn in front of me. Suppose, too, that there is indeed a red\nbarn there. However (you guessed it) many fake barns are scattered\nthrough the neighborhood, all of which are blue, not red. In the close\nworlds in which I believe red barn, I am correct, so I meet\nthe requisite condition for knowing red barn, which is that\nmy believing red barn safely indicates its own truth. Now,\nred barn entails barn: there is a barn in front of\nme. But, according to the view on offer, the requisite condition for\nknowing barn is not that my belief red barn safely\nindicates that barn holds. What is required instead is that\nmy belief barn safely indicates its own truth.\nAssuming that I would believe barn if I saw one of the blue\nfakes, then my belief barn does not safely indicate its\ntruth. \nTo pick up the thread again: now, K fails if knowledge entails\nCR but not if knowledge entails SI, but it may not be\npossible to underwrite K merely by replacing CR with\nSI, since some other condition for knowledge might block\nclosure. We can underwrite closure if we assume that believing\np on “safe” grounds is sufficient for\nknowing p, but this assumption is dubious. As we have\nunderstood safety, we can believe things on safe grounds without\nknowing them. An obvious example is any necessary truth: because it\nholds in all possible worlds we can safely believe it for any reason.\nFor another example, recall the red barn case discussed earlier:\ndespite the many fake blue barns in the neighborhood, my red-barn\npercepts are safe indicators that the object in front of me is a barn\nand that it is a red barn, so no objectionable juxtaposition\n(such as I know there is a red barn but not there is a\nbarn) occurs, but some theorists will insist that, in the\ncircumstances sketched, I know neither that the object is a\nbarn nor that it is a red barn.  \nThe second version of the argument from the analysis of knowledge has\nit that any relevant alternatives view, not just tracking accounts, is\nin tension with K. An analysis is a relevant alternatives\naccount when it meets two conditions. First, it yields an appropriate\nunderstanding of ‘relevant alternative.’ Dretske’s\napproach qualifies since it allows us to say that an alternative\nA to p is relevant if and only if: \nAccording to the second condition, the analysis must say that knowing\np requires ruling out all relevant alternatives to\np but not all alternatives to p. Dretske’s\napproach qualifies once again. It says an alternative A is\nruled out on the basis of R if and only if the following\ncondition is met: \nAnd, on Dretske’s approach, an alternative A must be ruled\nout if and only if A meets CRA. \nSo the tracking account is a relevant alternatives approach. But why\nsay that relevant alternatives accounts of knowledge are in tension\nwith K? We will say this if, like Dretske, we accept the\nfollowing crucial tenet: the negation of a proposition p is\nautomatically a relevant alternative to p (no matter how\nbizarre or remote not-p might be) but often not a\nrelevant alternative to things that imply p. For a relevant\nalternatives theorist, this tenet suggests that we can know something\np only if we can rule out not-p but we can know\nthings that entail p even if we cannot rule out\nnot-p, which opens up the possibility that there are cases\nthat violate K. For while our inability to rule out\nnot-p stops us from knowing p it does not stop us\nfrom knowing things that entail p. And an example is ready to\nhand: the zebra case. Perhaps you cannot rule out mule; but\nthat stops you from knowing not-mule without stopping you\nfrom knowing zeb. These points can be restated in terms of\nthe conclusive reasons account. For Dretske, the negation of a\nproposition p is automatically a relevant alternative since\ncondition CRA is automatically met; that is, it is vacuously\ntrue that: \nwere p false, not-p might hold. \nTherefore mule is a relevant alternative to\nnot-mule. Furthermore, you fail to know not-mule\nsince you cannot rule out mule: you believe not-mule\non the basis of your zebra-in-the-cage percepts, but you would still\nhave these if mule held, contrary to CRR. Yet you know\nzeb in spite of your inability to rule out mule, for\nwere zeb false you would not have your zebra-in-the-cage\npercepts. \nAccording to the second version of the argument from the analysis of\nknowledge any relevant alternatives view is in tension with K.\nHow compelling is this argument? As Dretske acknowledged (2003), it is\nactually a weak challenge to K since some relevant alternatives\naccounts are fully consistent with K. For an example, we have\nonly to adapt the safe indication view so as to make it clear that it\nis a relevant alternatives account (Luper 1984, 1987c, 2006). \nThe safe indication view can be adapted in two steps. First, we say\nthat an alternative to p, A, is relevant if and only\nif the following condition is met: \nThus any possibility that is remote is automatically irrelevant,\nfailing SRA. Second, we say that A is ruled out on the\nbasis of R if and only if the following condition is met: \nThis way of understanding relevant alternatives upholds K. The\nkey point is that if S knows p on the basis of\nR, and is thus able to rule out p’s relevant\nalternatives, then S can also rule out q’s relevant\nalternatives, where q is anything p implies. If\nR were to hold, q’s alternatives would not. \nApparently, the relevant alternatives account can be construed in a\nway that supports K as well as a way that does not. Hence\nDretske is not well positioned to claim that the relevant alternatives\nview leads “naturally” to closure failure. \nOn one version of reliabilism (defended by Ramsey 1931 and Armstrong\n1973, among others) one knows p if and only if one arrives at\n(or sustains) the belief p via a reliable method. Is the\nreliabilist committed to K? The answer depends on precisely\nhow the relevant notion of reliability is understood. If we understand\nreliability as tracking theorists do, we will reject closure. But\nthere are other versions of reliabilism which sustain K. For\nexample, the safe indication account is a type of reliabilism. Also,\nwe could say that a true belief p is reliably formed if and\nonly if based on an event that usually would occur only if\np (or a p-type belief) were true. Any event that, in\nthis sense, reliably indicates that p is true will also\nreliably indicate that p’s consequences are true. \nDretske argued (2003, 2005) that we should expect K failure\nbecause none of the modes of gaining, preserving or extending\nknowledge are individually closed. Dretske made his point in the form\nof a rhetorical question: “how is one supposed to get closure on\nsomething when every way of getting, extending and preserving it is\nopen (2003: 113–4)?” \nAs examples of modes of gaining, sustaining and extending knowledge\nDretske suggested perception, testimony, proof, memory, indication,\nand information. To say of these items that they are not individually\nclosed is to say that the following modes closure principles, with or\nwithout the parenthetical qualifications, are false: \nAnd, according to Dretske, each of these principles fails. We may\nperceive that we have hands, for example, without perceiving that\nthere are physical things. \nThere have been various rejoinders to Dretske’s argument from\nnonclosure of knowledge modes. \nFirst, failure of one or more of the modes closure principles does not\nimply that K fails. What matters is whether the various modes\nof knowledge Dretske discusses position us to know the consequences of\nthe things we know. In other words, the issue is whether the following\nprinciple is true: \nSecond, theorists have defended some of these modes closure\nprinciples, such as PC, IC and NC. Dretske\nrejects these three principles because he thinks perception,\nindication and information are best analyzed in terms of conclusive\nreasons, which undermines closure. But the three principles (or\nsomething very much like them) may be defended if we analyze\nperception, indication and information in terms of safe indication.\nConsider IC and NC. Both are true if we analyze\nindication and information as follows: \nR indicates p iff p would be true if\nR held. \nR carries the information that p iff p\nwould be true if R held. \nA version of PC may be defended if we make use of Dretske’s own\nnotion of indirect perception (1969). Consider a scientist who studies\nthe behavior of electrons by watching bubbles they leave behind in a\ncloud chamber. The electrons themselves are invisible, but the\nscientist can perceive that the (invisible) electrons are\nmoving in certain ways by perceiving that the (visible)\nbubbles left behind are arranging themselves in specific ways. What we\ndirectly perceive positions us to perceive various things indirectly.\nNow assume that when we directly or indirectly perceive p,\nand this causes us to believe q, where p entails\nq, we are positioned to perceive q indirectly. Then\nwe are well on our way to accepting some version of PC, such\nas, for example: \nAnother anticlosure argument is that there are some sorts of\npropositions we cannot know unless perhaps we take extraordinary\nmeasures, yet such propositions are entailed by mundane claims whose\ntruth we do know. Since this would be impossible if K were\ncorrect, K must be false. The same difficulty is sometimes\ndiscussed under the heading problem of easy knowledge, since\nsome theorists (Cohen 2002) believe that certain things are difficult\nto know, in the sense that they cannot be known by deduction from\nbanal knowledge. The argument has different versions depending on\nwhich propositions are said to be hard knowledge. According to Dretske\n(and perhaps Nozick as well), we cannot easily know that limiting\npropositions or heavyweight propositions are true. These\nresemble propositions Moore (1959) considered certainly true and that\nWittgenstein (1969) declared to be unknowable (but Wittgenstein\nconsidered them unknowable on the dubious grounds that they must be\ntrue if we are to entertain doubts). Another possibility is that we\ncannot easily know lottery propositions. A special case of\nthe argument from unknowable propositions starts with the claim that\nwe cannot know the falsity of skeptical hypotheses. We will consider\nthis third view in the next section. \nDretske did not clearly delineate the class of propositions he called\n“limiting” (in 2003) or “heavyweight” (in\n2005). Some of the examples he provided are “There is a\npast,” “There are physical objects,” and “I am\nnot being fooled by a clever deception.” He appeared to think\nthat these propositions have a property we may call\n“elusiveness,” where p is elusive for me if and\nonly if p’s falsity would not change my experiences. But\nbeing limiting does not coincide with being elusive. If there were no\nphysical objects, my experiences would be changed dramatically, since\nI would not exist. So some limiting propositions are not elusive. As\nto whether all elusive claims are limiting, it is hard to say, because\nof the squishiness of the term “limiting”.\nNot-mule is elusive, but is it limiting? \nCan’t we know limiting propositions? If not, and if we do know things\nthat entail them, Dretske thought he had further support for his\nconclusive reasons view, assuming, as he did, that his view rules out\nour knowing limiting propositions (while allowing knowledge of things\nthat entail them). However, this assumption is false (Hawthorne 2005,\nLuper 2006). We do have conclusive reason to believe some limiting\npropositions, such as that there are physical objects. Still, Dretske\nmight abandon the notion of a limiting proposition in favor of the\nnotion of elusive propositions, and cite, in favor of his conclusive\nreasons view, and against K, the facts that we cannot know\nelusive claims but we can know things that imply them. \nIn order to rule out knowledge of limiting/elusive propositions,\nDretske offered two sorts of argument, which we may call the\nargument from perception and the argument from\npseudocircularity. \nThe argument from perception starts with the claims that (a) we do not\nperceive that limiting/elusive claims hold and (b) we do not know, via\nperception, that limiting/elusive claims hold. Since it is hard to see\nhow else we could know limiting/elusive propositions, (a) and (b) are\ngood grounds for concluding that we just do not know that they\nhold. \nThere is no doubt that (a) and (b) have considerable plausibility.\nNonetheless, they are controversial. To explain the truth of (a) and\n(b), Dretske counted on his conclusive reasons analysis of perception.\nHis critics may cite the safe indication account of perception as the\nbasis for rejecting (a) and (b). Luper (2006), for example, argues\nagainst both, chiefly on the grounds that we can perceive and know\nsome elusive claims (such as not-mule) indirectly, by\ndirectly perceiving claims (such as zeb) that entail\nthem. \nDretske suggested another reason for ruling out knowledge of\nlimiting/elusive claims. He thought we can know banal facts (e.g., we\nate breakfast) without knowing limiting/elusive claims they entail\n(e.g., the past is real) so long as those limiting/elusive\nclaims are true, but we cannot then turn around and employ\nthe former as our basis for knowing the latter. Suppose we take\nourselves to know some claim, q, by inferring it from another\nclaim, p, which we know, but our knowing p in the\nfirst place depends on the truth of q. Call this\npseudocircular reasoning. According to Dretske,\npseudocircular reasoning is unacceptable, and yet it is precisely what\nwe rely on when we attempt to know limiting/elusive claims such as\ndenials of skeptical hypotheses by deducing them from ordinary\nknowledge claims that entail them: we will not know the latter in the\nfirst place unless the former are true. The problem Dretske here\nraised was pressed earlier by critics of broadly reliabilist accounts\nof knowledge, such as Richard Fumerton (1995, 178). Jonathan Vogel\n(2000) discusses it under the heading bootstrapping, the\nprocedure employed when, e.g., someone who has no initial evidence\nabout the reliability of a gas gauge, comes to believe p on\nseveral different occasions because the gauge indicates p,\nand thereby knows p according to reliabilist accounts of\nknowledge, then infers that the gauge is reliable, by induction. By\nbootstrapping we may move—illegitimately, according to\nVogel—from beliefs formed through a reliable process to the\nknowledge that those beliefs were arrived at through a reliable\nprocess. One may know p using a gauge in the first instance\nonly if that gauge is reliable; hence, to conclude it is reliable\nsolely on the basis of its track record involves pseudocircular\nreasoning. \nTheorists have long objected to knowledge claims whose truth depends\non a fact that itself has not been established, especially if that\nfact is merely taken for granted. It is also standard to reject any\nknowledge claim whose pedigree smacks of circularity. Both worries\narise if we claim to know that one proposition, q, is true on\nthe grounds that it is entailed by a second proposition, p,\neven though the truth of q was taken for granted in coming to\nknow that p is true. Many theorists will reject\npseudocircular reasoning on precisely these traditional grounds.\nDretske did not share the first worry but he did raise the second, the\nconcern about pseudocircular reasoning. But there is a growing body of\nwork that breaks with tradition and defends some forms of epistemic\ncircularity (this work is heavily criticized, in turn, on the grounds\nthat it is open to versions of traditional objections). Max Black\n(1949) and Nelson Goodman (1955) were early examples; others include\nVan Cleve 1979 and 2003; Luper 2004; Papineau 1992; and Alston 1993.\nDretske himself meant to break with tradition, writing under the\nbanner of ‘externalism.’ He explicitly said that most, if\nnot all, of our mundane knowledge claims depend on facts we have not\nestablished. Indeed, he cited this as a virtue of his conclusive\nreasons view. Yet nothing in the nature of the conclusive reasons\naccount rules out our knowing limiting propositions using\npseudocircular reasoning, which leaves his reservations mysterious. A\nset of jar-ish experiences can constitute a conclusive reason for\nbelieving jar, a jar of cookies is in front of me. If I then\nbelieve objects, there are physical objects, because it is\nentailed by jar, I have conclusive reason for believing\nobjects, a limiting proposition. (If objects were\nfalse, jar would be too, and I would lack my jar-ish\nexperiences.) \nDretske might have fallen back on the view that the conclusive reasons\naccount rules out knowing elusive, as opposed to limiting, claims\nthrough pseudocircular reasoning, because we lack conclusive reasons\nfor elusive claims no matter what sort of reasoning we employ. But\nthis does not put Dretske’s account at odds with pseudocircular\nreasoning. And even this more limited position can be challenged\n(adapting a charge against Nozick in Shatz 1987). We might insist that\np itself is a conclusive reason for believing q when\nwe know p and p entails q. After all,\nassuming p entails q, if q were false so\nwould p be. On this strategy we have a further argument for\nK: if S knows p (relying on some conclusive\nreason R), and S believes q because\nS knows p entails q, S has a\nconclusive reason for believing q, namely p (rather\nthan R), and hence S knows q. \nAnother doubt about knowing elusive claims deductively via mundane\nclaims is that this maneuver is improperly ampliative. Cohen claims\nthat knowing the table is red does not position us to know “I am\nnot a brain-in-a-vat being deceived into believing that the table is\nred” nor “it’s not the case that the table is white [but]\nilluminated by red lights” (2002: 313). In the transition from\nthe former to the latter, our knowledge appears to have been amplified\nimproperly. This concern may be due at least in large part to lack of\nprecision in the application of entailment or deductive implication\n(Klein 2004). Let red be the proposition that the table is\nred, white the proposition that the table is white, and\nlight the proposition that the table is being illuminated by\na red light. Red does not entail anything about the\nconditions under which the table is illuminated. In particular it does\nnot entail the conjunction, light & not-white. The most\nwe can infer is that the conjunction, white & light, is\nfalse, and that gives us no information whatever about the lighting\nconditions of the table. One could as easily infer the falsity of the\nconjunction, white & not-light. No\namplification of the original known proposition, red, has\ncome about. \nIt seems apparent that I do not know not-win, I will not win\nthe state lottery tonight, even though my odds for hitting it big are\nvanishingly small. But suppose my heart’s desire is to own a 10\nmillion dollar villa in the French Riviera. It seems plausible to say\nthat I know not-buy, I will not buy that villa tomorrow,\nsince I lack the means, and that I know the conditional, if\nwin then buy, i.e., tomorrow I will buy the villa if\nI win the state lottery tonight. From the conditional and\nnot-buy it follows that not-win, so, given closure,\nknowing the conditional and not-buy positions me to know\nnot-win. As this reasoning shows, the unknowability of claims\nlike not-win together with the knowability of claims like\nnot-buy position us to launch another challenge to\nclosure. \nLet a lottery proposition be a proposition, like\nnot-win, that (at least normally) is supportable only on the\ngrounds that its probability is very high but less than 1. Vogel\n(1990, 2004) and Hawthorne (2004, 2005) have noted that a great number\nof propositions that do not actually involve lotteries resemble\nlottery propositions in that they can be given a probability that is\nclose to but less than 1. Such propositions might be described as\nlotteryesque. The events mentioned in a claim can be subsumed\nunder indefinitely many reference classes, and there is no\nauthoritative way to choose which among these determines the\nprobability of the subsumed events. By carefully selecting among these\nclasses we can often find ways to suggest that the probability of a\nclaim is less than 1. Take, for example, not-stolen, the\nproposition that the car you just parked in front of the house has not\nbeen stolen: by selecting the class, red cars stolen from in front\nof your house in the last hour, we can portray the statistical\nprobability of not-stolen as 1. But by selecting, cars\nstolen in the U.S., we can portray the probability as\nsignificantly less than 1. If, like lottery propositions, lotteryesque\npropositions are not easily known, they increase the pressure on the\nclosure principle, since they are entailed by a wide range of mundane\npropositions which become unknowable, given closure. \nHow great a threat to K (and GK) are lottery and\nlotteryesque propositions? The matter is somewhat controversial.\nHowever, there is a great deal to be said for treating lottery\npropositions one way and lotteryesque propositions another. \nAs for lottery propositions: several theorists suggest that we do not\nin fact know that they are true because knowing them requires\nbelieving them because of something that establishes their\ntruth, and we (normally) cannot establish the truth of lottery\npropositions. There are various ways to understand what is meant by\n“establishing” the truth of a claim. Dretske, as we have\nseen, thinks that knowledge entails having a conclusive reason for\nthinking as we do. David Armstrong (1973, p. 187) said that knowledge\nentails having a belief state that “ensures” truth. Safe\nindication theorists suggest that we know things when we believe them\nbecause of something that safely indicates their truth. And Harman and\nSherman (2004, p. 492) say that knowledge requires believing as we do\nbecause of something “that settles the truth of that\nbelief.” On all four views, we fail to know that a claim is true\nwhen our only grounds for believing it is that it is highly likely.\nHowever, the unknowability of lottery propositions is not a\nsubstantial threat to closure, since it is not obvious that there are\npropositions that are both known to be true and that entail lottery\npropositions. Consider the example discussed earlier: the conditional\nif win then buy together with not-buy. If I\nknow these, then, by GK, I know not-win, a lottery\nproposition. But it is quite plausible to deny that I do know these.\nAfter all, I might win the lottery. \nNow consider lotteryesque propositions. We cannot defend closure by\ndenying that we know any mundane proposition that entails a\nlotteryesque proposition since it is clear that we know that many\nthings are true that entail lotteryesque propositions. To defend\nclosure we must instead say that lotteryesque propositions are\nknowable. They differ from genuine lottery propositions in that they\nmay be supportable on grounds that establish their truth. If I base my\nbelief not-stolen solely on crime statistics, I will fail to\nknow that it is true. But I can instead base it on observations, such\nas having just parked it in my garage, and so forth, that, under the\ncircumstances, establish that not-stolen holds. \nAccording to Dretske and Nozick, we can account for the appeal of\nskepticism and explain where it goes wrong if we accept their view of\nknowledge and reject K. Rejecting knowledge closure is\ntherefore the key to resolving skepticism. Given the importance of\ninsight into the problem of skepticism, they would seem to have a good\ncase for denying closure. Let us consider the story they present, and\nsome worries about its acceptability. \nDretske and Nozick focused on a form of skepticism that combines\nK with the assumption that we do not know that skeptical\nhypotheses are false. For example, I do not know\nnot-biv: I am not a brain in a vat on a planet far\nfrom earth being deceiving by alien scientists. On the strength of\nthese assumptions, skeptics argue that we do not know all sorts of\ncommonsense claims that entail the falsity of skeptical hypotheses.\nFor example, since not-biv is entailed by\nh, I am in San Antonio, skeptics may argue as follows: \nDretske and Nozick were well aware that this argument can be turned on\nits head, as follows: \nTurning tables on the skeptic in this way was roughly Moore’s (1959)\nantiskeptical strategy. (Tendentiously, some writers now call this\nstrategy dogmatism). However, instead of K, Moore\npresupposed the truth of a stronger principle: \nUnlike K, PK underwrites Moore’s famous argument: Moore\nknows he is standing; his knowing that he is standing entails that he\nis not dreaming; therefore, he knows (or rather is in a position to\nknow) that he is not dreaming. \nAccording to Dretske and Nozick, skepticism is appealing because\nskeptics are partially right. They are correct when they say that we\ndo not know that skeptical hypotheses fail to hold. For I do not track\nnot-biv: if biv were true, I would still\nhave the experiences that lead me to believe that biv is\nfalse. Something similar can be said about antiskepticism:\nantiskeptics are correct when they say we know all sorts of\ncommonsense claims that entail the falsity of skeptical hypotheses.\nHaving gotten this far, however, skeptics appeal to K, and argue that\nsince I would know not-biv if I knew h, then I must\nnot know h after all, while Moore-style antiskeptics appeal\nto K in order to conclude that I do know not-biv. But\nthis is precisely where skeptics and antiskeptics alike go wrong, for\nK is false. Consider the position skeptics are in. Having\naccepted the tracking view—as they do when they deny that we\nknow skeptical hypotheses are false—skeptics cannot appeal to\nthe principle of closure, which is false on the tracking theory. We\ntrack (hence know) the truth of ordinary knowledge claims yet fail to\ntrack (or know) the truth of things that follow, such as that\nincompatible skeptical hypotheses are false. \nOne shortcoming of this story is that it cannot come to terms with all\ntypes of skepticism. There are two main forms of skepticism (and\nvarious sub-categories): regress (or Pyrrhonian) skepticism, and\nindiscernability (Cartesian) skepticism. At best, Dretske and Nozick\nhave provided a way of dealing with the latter. \nAnother worry about Dretske’s and Nozick’s response to Cartesian\nskepticism is that it forces us to give up K (as well as\nGK, and closure across instantiation and simplification). Given\nthe intuitive appeal of these principles, some theorists have looked\nfor alternative ways of explaining skepticism, which they then offer\nas superior in part on the grounds that they do no violence to\nK. Consider two possibilities, one offered by advocates of the\nsafe indication theory, and one by contextualists. \nAdvocates of the safe indication theory accept the gist of the\ntracking theorist explanation of the appeal of skepticism but retain\nthe principle of closure. One reason skepticism tempts us is that we\ntend to confuse CR with SI (Sosa 1999, Luper 1984,\n1987c, 2003a). After all, CR—if p were false,\nR would not hold—closely resembles\nSI—R would hold only if p were true.\nWhen we run the two together, we sometimes apply CR and\nconclude that we do not know that skeptical scenarios do not hold.\nThen we shift back to the safe indication account, and go along with\nskeptics when they appeal to the principle of entailment, which is\nsustained by the safe indication account, and conclude that ordinary\nknowledge claims are false. But, as Moore claimed, skeptics are wrong\nwhen they say we do not know that skeptical hypotheses are false.\nRoughly, we know skeptical possibilities do not hold since (given our\ncircumstances) they are remote. \nSkepticism might also result from the assumption that, if a belief\nformation method M were, in some situation, to yield a belief\nwithout enabling us to know the truth of that belief, then it cannot\never generate bona fide knowledge (of that sort of belief), no matter\nwhat circumstances it is used in. (M must be strengthened\nsomehow, say with a supplemental method, or with evidence about the\ncircumstances at hand, if knowledge is to be procured.) This\nassumption might rest on the idea that any belief M yields\nis, at best, accidentally correct, if in any circumstances M\nyields a false or an accidentally correct belief (Luper 1987b,c). On\nthis assumption, we can rule out a method of belief formation\nM as a source of knowledge merely by sketching circumstances\nin which M yields a belief that is false or accidentally\ncorrect. Traditional skeptical scenarios suffice; so do Gettieresque\nsituations. Externalist theorists reject the assumption, saying that\nM can generate knowledge when used in circumstances under\nwhich the belief it yields is not accidentally correct. In highly\nGettierized circumstances M must put us in an especially\nstrong epistemic position if M is to generate knowledge; in\nordinary circumstances, less exacting methods can produce knowledge.\nThe standards a method must meet to produce knowledge depend on the\ncontext in which it is used. This view, on which the requirements for\na subject or agent S to know p vary with\nS’s context (e.g., how exacting S’s method of belief\nformation must be to yield knowledge depend on S’s\ncircumstances), might be called agent-centered (or\nsubject) contextualism. Both tracking theorists and\nsafe indication theorists defend agent-centered contextualism. \nTheorists writing under the label “contextualism,” such as\nDavid Lewis (1979, 1996), Stewart Cohen (1988, 1999), and Keith DeRose\n(1995), offer a related way of explaining skepticism without denying\nclosure. For clarity, we might call them speaker-centered (or\nattributor) contextualists since they contrast their view\nwith agent-centered contextualism. According to (speaker-centered)\ncontextualists, whether it is correct for a judge to\nattribute knowledge to someone depends on that judge’s\ncontext, and the standards for knowledge differ from context to\ncontext. When the man on the street judges knowledge, the applicable\nstandards are relatively modest. But an epistemologist takes all sorts\nof possibilities seriously that are ignored by ordinary folk, and so\nmust apply quite stringent standards in order to reach correct\nassessments. What passes for knowledge in ordinary contexts does not\nqualify for knowledge in contexts where heightened criteria apply.\nSkepticism is explained by the fact that the contextual variation of\nepistemic standards is easily overlooked. Skeptics note that in the\nepistemic context it is inappropriate to grant anyone knowledge.\nHowever, skeptics assume—falsely—that what goes in the\nepistemic context goes in all contexts. They assume that since those\nwho take skepticism seriously must deny anyone knowledge, then\neveryone, regardless of context, should deny anyone knowledge. Yet\npeople in ordinary contexts are perfectly correct in claiming that\nthey know all sorts of things. \nFurthermore, the closure principle is correct, contextualists say, so\nlong as it is understood to operate within given contexts, not across\ncontexts. That is, so long as we stay within a given context, we know\nthe things we deduce from other things we know. But if I am in an\nordinary context, knowing I am in San Antonio, I cannot come to know,\nvia deduction, that I am not a brain in a vat on a distant planet,\nsince the moment I take that skeptical possibility seriously, I\ntransform my context into one in which heightened epistemic standards\napply. When I take the vat possibility seriously, I must wield\ndemanding standards that rule out my knowing I am not a brain in a\nvat. By the same token, these standards preclude my knowing I am in\nSan Antonio. Thinking seriously about knowledge undermines our\nknowledge. \nTo say that justified belief is closed under entailment is to say that\nsomething like one of the following principles is correct (or that\nboth are): \nHowever, GJ generates paradoxes (Kyburg 1961). To see why,\nnotice that if the chances of winning a lottery are sufficiently\nremote, I am justified in believing that my ticket, ticket 1, will\nlose. I am also justified in believing that ticket 2 will lose, and\nthat 3 will lose, and so on. However, I am not justified in believing\nthe conjunction of these propositions. If I were, I would justifiably\nbelieve that no ticket will win. If a proposition is justified when\nprobable enough, lottery examples undermine GJ. No matter how\ngreat the probability that suffices for justification, unless that\nprobability is 1, in some lotteries we will be justified in believing,\nof an arbitrary ticket, that it will lose, and thus, by GJ, we\nwill be justified in believing that all of the tickets will lose. \nEven if we reject GJ, it does not follow that we must reject\nGK, which concerns knowledge closure. Consider the\nlottery example again. How justified we are in believing that ticket 1\nwill lose depends on how probable its losing is. Now, the probability\nthat ticket 2 will lose is equal to the probability that ticket 1 will\nlose. The same goes for each ticket. However, consider the\nconjunction, Ticket 1 will lose & ticket 2 will lose. The\nprobability of this conjunctive proposition is less than the\nprobability of either of its conjuncts. Suppose we continue to add\nconjuncts. For example, next in line will be: Ticket 1 will lose\n& ticket 2 will lose & ticket 3 will lose. Each time a\nconjunct is added, the probability of the resulting proposition is\nstill lower. This illustrates the fact that we can begin with a\ncollection of propositions each of which surpasses some threshold\nlevel of justification (let it be whatever is necessary for a belief\nto count as “justified” according to GJ) and, by\nconjoining them, we can end up with a proposition which falls below\nthat threshold level of justification. We may “justifiably\nbelieve” each conjunct, but not the conjunction, so GJ\nfails. However, we need not reject GK on these grounds. Even if\nwe grant that we justifiably believe that Ticket 1 will\nlose is true we might deny that we know that this\nproposition is true. We might take the position that if we believe\nsome proposition p on the basis of its probability, nothing\nless than a probability of 1 will suffice to enable us to know that it\nis true. In that case GK will not succumb to our objection to\nGJ, for if the probability of two or more propositions is 1\nthen the probability of their conjunction is also 1.  \nWe can reject GJ. Should we also reject J? The status of\nthis principle is much more controversial. Some theorists argue\nagainst it using counterexamples like Dretske’s own zebra case:\nbecause the zebra is in plain sight, you seem fully justified in\nbelieving zeb, but it is not so clear that you are justified\nin believing not-mule, even if you deduce this belief from\nzeb. Anyone who rejects K on the grounds that\nK sanctions the knowledge of limiting or heavyweight\npropositions (discussed earlier) is likely to reject J on\nsimilar grounds: justifiably believing that we have hands, it might\nseem, does not position us to justifiably believe that there are\nphysical objects even if we see that the former entails the latter.\n \nOne response is that cases such as Dretske’s do not count against\nJ, but rather against the following principle (of the\ntransmissibility of evidence): \nEven if we reject this principle, it does not follow that\njustification is not closed under entailment, as Peter Klein (1981)\npointed out. Arguably, for justification closure, all that is\nnecessary is that when, given all of our relevant evidence e,\nwe are justified in believing p, we also have\nsufficient justification for believing each of p’s\nconsequences. Our justification for p’s consequences need not\nbe e. Instead, it might be p itself, which is, after\nall, a justified belief. And since p entails its\nconsequences, it is sufficient to justify them. Moreover, any good\nevidence we have against a consequence of p counts against\np itself, preventing us from being justified in believing\np in the first place, so if we are justified in believing\np, considering all our evidence, pro and con, we will not\nhave overwhelming evidence against propositions entailed by\np. (A similar move could be defended against the tracking\ntheorists when they deny the closure of knowledge: if we track\np, and believe q by deducing it from p,\nthen we track q if we take p as our basis for\nbelieving q.) Looked at in this way, J seems\nplausible. (There is a substantial literature on the transmissibility\nof evidence and its failure; see, for example, Crispin Wright (1985)\nand Martin Davies (1998). \nSome final observations can be made using Roderick Firth’s (1978)\ndistinction between propositional and doxastic justification.\nProposition p has propositional justification for S if and\nonly if, given the grounds S possesses, p would\ncount as rational. That p has propositional justification for\nS does not require that S actually base p\non these grounds, or even that S believe p. Whether\nS’s belief has doxastic justification depends on S’s\nactual grounds for believing p: if, on these grounds,\np would count as rational, then p possesses doxastic\njustification. Consider the following principles: \nClearly JD faces two fatal objections. First, we might fail to\nbelieve some of the things implied by our beliefs. Second, we may have\nperfectly respectable reasons for believing something p, yet,\nfailing to see that p entails q, we might not be\naware of any grounds for believing q, or, worse, we might\nbelieve q for bogus reasons. But neither difficulty threatens\nJP. First, propositional justification does not entail belief.\nSecond, S might be propositionally justified in believing\nq on the basis of p whether or not S fails\nto see that p entails q, and even if S\nbelieves q for bogus reasons. As further support for\nJP, we might cite the fact that, if p entails\nq, whatever counts against q also counts against\np."}]
