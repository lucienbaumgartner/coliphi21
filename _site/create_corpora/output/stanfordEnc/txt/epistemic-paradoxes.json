[{"date.published":"2006-06-21","date.changed":"2017-09-07","url":"https://plato.stanford.edu/entries/epistemic-paradoxes/","author1":"Roy Sorensen","entry":"epistemic-paradoxes","body.text":"\n\n\nEpistemic paradoxes are riddles that turn on the concept of knowledge\n(episteme is Greek for knowledge). Typically, there are\nconflicting, well-credentialed answers to these questions (or\npseudo-questions). Thus the riddle immediately informs us of an\ninconsistency. In the long run, the riddle goads and guides us into\ncorrecting at least one deep error – if not directly about\nknowledge, then about its kindred concepts such as justification,\nrational belief, and evidence.\n\n\nSuch corrections are of interest to epistemologists. Historians date\nthe origin of epistemology to the appearance of skeptics. As manifest\nin Plato’s dialogues featuring Socrates, epistemic paradoxes\nhave been discussed for twenty five hundred years. Given their\nhardiness, some of these riddles about knowledge will be discussed for\nthe next twenty five hundred years.\n\nA teacher announces that there will be a surprise test next week. A\nstudent objects that this is impossible: “The class meets on\nMonday, Wednesday, and Friday. If the test is given on Friday, then on\nThursday I would be able to predict that the test is on Friday. It\nwould not be a surprise. Can the test be given on Wednesday? No,\nbecause on Tuesday I would know that the test will not be on Friday\n(thanks to the previous reasoning) and know that the test was not on\nMonday (thanks to memory). Therefore, on Tuesday I could foresee that\nthe test will be on Wednesday. A test on Wednesday would not be a\nsurprise. Could the surprise test be on Monday? On Sunday, the\nprevious two eliminations would be available to me. Consequently, I\nwould know that the test must be on Monday. So a Monday test would\nalso fail to be a surprise. Therefore, it is impossible for there to\nbe a surprise test.” \nCan the teacher fulfill her announcement? We have an embarrassment of\nriches. On the one hand, we have the student’s elimination\nargument. (For a recent formalization, see Holliday 2017.) On the\nother hand, common sense says that surprise tests are possible even\nwhen we have had advance warning that one will occur at some point.\nEither of the answers would be decisive were it not for the\ncredentials of the rival answer. Thus we have a paradox. But a paradox\nof what kind? ‘Surprise test’ is being defined in terms of\nwhat can be known. Specifically, a test is a surprise if and only if\nthe student cannot know beforehand which day the test will\noccur. Therefore the riddle of the surprise test qualifies as an\nepistemic paradox. \nParadoxes are more than edifying surprises. Professor\nStatistics announces she will give random quizzes: “Class meets\nevery day of the week. Each day I will open by rolling a die. When the\nroll yields a six, I will immediately give a quiz.” Today,\nMonday, a six came up. So you are taking a quiz. The last question of\nher quiz is: “Which of the subsequent days is most likely to be\nthe day of the next random test?” Most people answer that each\nof the subsequent days has the same probability of being the next\nquiz. But the correct answer is: Tomorrow (Tuesday).  \nUncontroversial facts about probability reveal the mistake and\nestablish the correct answer. For the next test to be on Wednesday,\nthere would have to be a conjunction of two events: no test\non Tuesday (a 5/6 chance of that) and a test on Wednesday (a\n1/6 chance). The probability for each subsequent day becomes less and\nless. (It would be astounding if the next quiz day were a hundred days\nfrom now!) The question is not whether a six will be rolled on any\ngiven day, but when the next six will be rolled. Which day is\nthe next one depends partly on what happens meanwhile, as well as\ndepending partly on the roll of the die on that day.  \nThis riddle is instructive and will be referenced throughout this\nentry. But the existence of quick, decisive solution shows that only a\nmild revision of our prior beliefs was needed. In contrast, when our\ndeep beliefs conflict, proposed amendments reverberate unpredictably.\n“Problems worthy of attack prove their worth by fighting\nback” (Hein 1966). \nThe solution to a complex epistemic paradox relies on\nsolutions (or partial solutions) to more fundamental epistemic\nparadoxes. The surprise test paradox, which will be disassembled in\nstages throughout this essay, conveniently illustrates this nesting of\nparadox within paradox. Inside the surprise test is the lottery\nparadox; inside the lottery paradox is the preface paradox; inside the\npreface paradox is Moore’s paradox (all of which will discussed\nbelow). In addition to this depth-wise connection, there are lateral\nconnections to other epistemic paradoxes such as the knower paradox\nand the problem of foreknowledge. \nThere are also ties to issues that are not clearly paradoxes –\nor to issues whose status as paradoxes is at least contested. Some\nphilosophers find only irony in self-defeating predictions,\nonly cognitive illusion in the Monty Hall problem, only an\nembarrassment in the “knowability paradox”\n(discussed below). Calling a problem a paradox tends to quarantine it\nfrom the rest of our inquiries. Those who wish to rely on the\nsurprising result will therefore deny that there is any paradox.  \nThe surprise test paradox has yet more oblique connections to some\nparadoxes that are not epistemic, such as the liar paradox and\nPseudo-Scotus’ paradoxes of validity. They will be discussed in\npassing, chiefly to set boundaries.  \nWe can look forward to future philosophers drawing edifying historical\nconnections. The backward elimination argument underlying the surprise\ntest paradox can be discerned in German folktales dating back to 1756\n(Sorensen 2003a, 267). Perhaps, medieval scholars explored these\nslippery slopes. But let me turn to commentary to which we presently\nhave access. \nIn the twentieth century, the first published reaction to the surprise\ntext paradox was to endorse the student’s elimination argument.\nD. J. O’Connor (1948) regarded the teacher’s\nannouncement as self-defeating. If the teacher had not announced that\nthere would be a surprise test, the teacher would have been able to\ngive the surprise test. The pedagogical moral of the paradox would\nthen be that if you want to give a surprise test do not announce your\nintention to your students! \nMore precisely, O’Connor compared the teacher’s\nannouncement to sentences such as ‘I remember nothing at\nall’ and ‘I am not speaking now’. Although these\nsentences are consistent, they “could not conceivably be true in\nany circumstances” (O’Connor 1948, 358). L. Jonathan Cohen\n(1950) agreed and classified the announcement as a pragmatic paradox.\nHe defined a pragmatic paradox to be a statement that is falsified by\nits own utterance. The teacher overlooked how the manner in which a\nstatement is disseminated can doom it to falsehood.  \nCohen’s classification is too monolithic. True, the\nteacher’s announcement does compromise one aspect of the\nsurprise: Students now know that there will be a test. But this\ncompromise is not itself enough to make the announcement\nself-falsifying. The existence of a surprise test has been\nrevealed but perhaps that allows surviving uncertainty as to\nwhich day the test will occur. The announcement of a\nforthcoming surprise aims at changing uninformed ignorance into\naction-guiding awareness of ignorance. A student who misses the\nannouncement does not realize that there is a test. If no one passes\non the intelligence about the surprise test, the student with simple\nignorance will be less prepared than classmates who know they do not\nknow the day of the test.  \nAnnouncements are made to serve different goals simultaneously.\nCompetition between accuracy and helpfulness makes it possible for an\nannouncement to be self-fulfilling by being self-defeating. Consider a\nweatherman who warns ‘The midnight tsunami will cause fatalities\nalong the shore’. Because of the warning, spectacle-seekers make\na special trip to witness the wave. Some drown. The weatherman’s\nannouncement succeeds as a prediction by backfiring as a warning. \nInstead of viewing self-defeating predictions as showing how the\nteacher is refuted, some philosophers construe self-defeating\npredictions as showing how the student is refuted. The\nstudent’s elimination argument embodies hypothetical predictions\nabout which day the teacher will give a test. Isn’t the student\noverlooking the teacher’s ability and desire to thwart those\nexpectations? Some game theorists suggest that the teacher could\ndefeat this strategy by choosing the test date at random.  \nStudents can be kept uncertain if the teacher is willing to be\nfaithfully random. She will need to prepare a quiz each day. She will\nneed to brace for the possibility that she will give too many quizzes\nor too few or have an unrepresentative distribution of quizzes.  \nIf the instructor finds these costs onerous, then she may be tempted\nby an alternative: at the beginning of the week, randomly select a\nsingle day. Keep the identity of that day secret. Since the student\nwill only know that the quiz is on some day or other, pupils will not\nbe able to predict the day of the quiz.  \nUnfortunately, this plan is risky. If, through the chance process, the\nlast day happens to be selected, then abiding by the outcome means\ngiving an unsurprising test. For as in the original scenario, the\nstudent has knowledge of the teacher’s announcement and\nawareness of past testless days. So the teacher must exclude random\nselection of the last day. The student is astute. He will replicate\nthis reasoning that excludes a test on the last day. Can the teacher\nabide by the random selection of the next to last day? Now the\nreasoning becomes all too familiar.  \nAnother critique of the student’s replication of the\nteacher’s reasoning adapts a thought experiment from Michael\nScriven (1964). To refute predictive determinism (the thesis that all\nevents are foreseeable), Scriven conjures an agent\n“Predictor” who has all the data, laws, and calculating\ncapacity needed to predict the choices of others. Scriven goes on to\nimagine, “Avoider”, whose dominant motivation is to avoid\nprediction. Therefore, Predictor must conceal his prediction. The\ncatch is that Avoider has access to the same data, laws, and\ncalculating capacity as Predictor. Thus Avoider can duplicate\nPredictor’s reasoning. Consequently, the optimal predictor\ncannot predict Avoider. Let the teacher be Avoider and the student be\nPredictor. Avoider must win. Therefore, it is possible to give a\nsurprise test. \nScriven’s original argument assumes that Predictor and Avoider\ncan simultaneously have all the needed data, laws, and calculating\ncapacity. David Lewis and Jane Richardson object: \nAccording to Lewis and Richardson, Scriven equivocates on ‘Both\nPredictor and Avoider have enough time to finish their\ncalculations’. Reading the sentence one way yields a truth:\nagainst any given avoider, Predictor can finish and against any given\npredictor, Avoider can finish. However, the compatibility premise\nrequires the false reading in which Predictor and Avoider can finish\nagainst each other.  \nIdealizing the teacher and student along the lines of Avoider and\nPredictor would fail to defeat the student’s elimination\nargument. We would have merely formulated a riddle that falsely\npresupposes that the two types of agent are co-possible. It would be\nlike asking ‘If Bill is smarter than anyone else and Hillary is\nsmarter than anyone else, which of the two is the\nsmartest?’. \nPredictive determinism states that everything is foreseeable.\nMetaphysical determinism states that there is only one way the future\ncould be given the way the past is. Simon Laplace used metaphysical\ndeterminism as a premise for predictive determinism. He reasoned that\nsince every event has a cause, a complete description of any stage of\nhistory combined with the laws of nature implies what happens at any\nother stage of the universe. Scriven was only challenging predictive\ndeterminism in his thought experiment. The next approach challenges\nmetaphysical determinism. \nPrior knowledge of an action seems incompatible with it being a free\naction. If I know that you will finish reading this article tomorrow,\nthen you will finish tomorrow (because knowledge implies truth). But\nthat means you will finish the article even if you resolve not to.\nAfter all, given that you will finish, nothing can stop you from\nfinishing. So if I know that you will finish reading this article\ntomorrow, you are not free to do otherwise. \nMaybe all of your reading is compulsory. If God exists, then He knows\neverything. So the threat to freedom becomes total for the theist. The\nproblem of divine foreknowledge insinuates that theism precludes\nmorality. \nIn response to the apparent conflict between freedom and\nforeknowledge, medieval philosophers denied that future contingent\npropositions have a truth-value. They took themselves to be extending\na solution Aristotle discusses in De Interpretatione to the\nproblem of logical fatalism. According to this truth-value gap\napproach, ‘You will finish this article tomorrow’ is not\ntrue now. The prediction will become true tomorrow.\nA morally serious theist can agree with the Rubaiyat of Omar\nKhayyam: \nGod’s omniscience only requires that He knows every true\nproposition. God will know ‘You will finish this article\ntomorrow’ as soon it becomes true – but not before.  \nThe teacher has freewill. Therefore, predictions about what he will do\nare not true (prior to the examination). Accordingly, Paul Weiss\n(1952) concludes that the student’s argument falsely assumes he\nknows that the announcement is true. The student can know that the\nannouncement is true after it becomes true – but not\nbefore. \nW. V. Quine (1953) agrees with Weiss’ conclusion that the\nteacher’s announcement of a surprise test fails to give the\nstudent knowledge that there will be a surprise test. Yet Quine\nabominates Weiss’ reasoning. Weiss breeches the law of bivalence\n(which states that every proposition has a truth-value, true or\nfalse). Quine believes that the riddle of the surprise test should not\nbe answered by surrendering classical logic. \nW. V. Quine insists that the student’s elimination argument is\nonly a reductio ad absurdum of the supposition that the\nstudent knows that the announcement is true (rather than a\nreductio of the announcement itself). He accepts this\nepistemic reductio but rejects the metaphysical\nreductio. Given the student’s ignorance of the\nannouncement, Quine concludes that a test on any day would be\nunforeseen.  \nCommon sense suggests that the students are informed by the\nannouncement. The teacher is assuming that the announcement will\nenlighten the students. She seems right to assume that the\nannouncement of this intention produces the same sort of knowledge as\nher other declarations of intentions (about which topics will be\nselected for lecture, the grading scale, and so on). \nThere are skeptical premises that could yield Quine’s conclusion\nthat the students do not know the announcement is true. If no one can\nknow anything about the future, as alleged by David Hume’s\nproblem of induction, then the student cannot know that the\nteacher’s announcement is true. (See the entry on\n the problem of induction.)\n But denying all knowledge of the future in order to deny the\nstudent’s knowledge is disproportionate. A fly swatter should be\nused to kill a fly, not a nuclear winter of ignorance.  \nIn later writings, Quine evinces general reservations about the\nconcept of knowledge. One of his pet objections is that\n‘know’ is vague. If knowledge entails absolute certainty,\nthen too little will count as known. Quine infers that we must equate\nknowledge with firmly held true belief. Asking just how firm the\nbelief must be is akin to asking just how big something has to be to\ncount as being big. There is no answer to the question because\n‘big’ lacks the sort of boundary enjoyed by precise\nwords. \nQuine is alluding to Rudolf Carnap’s (1950) generalization that\nscientists replace qualitative terms (tall) with comparatives\n(taller than) and then replace the comparatives with\nquantitative terms (being n millimeters in height).  \nIt is true that some borderline cases of a qualitative term are not\nborderline cases for the corresponding comparative. But the reverse\nholds as well. A tall man who stoops may stand less high than another\ntall man who is not as lengthy but better postured. Both men are\nclearly tall. It is unclear that ‘The lengthier man is\ntaller’. Qualitative terms can be applied when a vague quota is\nsatisfied without the need to sort out the details. Only comparative\nterms are bedeviled by tie-breaking issues. \nScience is about what is the case rather than what ought to be case.\nThis seems to imply that science does not tell us what we ought to\nbelieve. The traditional way to fill the normative gap is to delegate\nissues of justification to epistemologists. However, Quine is\nuncomfortable with delegating such authority to philosophers. He\nprefers the thesis that psychology is enough to handle the issues\ntraditionally addressed by epistemologists (or at least the issues\nstill worth addressing in an Age of Science). This “naturalistic\nepistemology” seems to imply that ‘know’ and\n‘justified’ are antiquated terms – as empty as\n‘phlogiston’ or ‘soul’. \nThose willing to abandon the concept of knowledge can dissolve the\nsurprise test paradox. But to epistemologists, this is like using a\nsuicide bomb to kill a fly.  \nOur suicide bomber may protest that the flies have been undercounted.\nEpistemic eliminativism dissolves all epistemic paradoxes.\nAccording to the eliminativist, epistemic paradoxes are symptoms of a\nproblem with the very concept of knowledge. \nNotice that the eliminativist is more radical than the skeptic. The\nskeptic thinks the concept of knowledge is fine. We just fall short of\nbeing knowers. The skeptic treats ‘No man is a knower’\nlike ‘No man is an immortal’. There is nothing wrong with\nthe concept of immortality. Biology just winds up guaranteeing that\nevery man falls short of being immortal.  \nUnlike the believer in ‘No man is an immortal’, the\nskeptic has trouble asserting ‘There is no knowledge’. For\nassertion expresses the belief that one knows. That is why Sextus\nEmpiricus (Outlines of Pyrrhonism, I., 3, 226) condemns the\nassertion ‘There is no knowledge’ as dogmatic\nskepticism. Sextus prefers agnosticism about knowledge rather than\nskepticism (considered as “atheism” about knowledge). Yet\nit just as inconsistent to assert ‘No one can know whether\nanything is known’. For that conveys the belief that one knows\nthat no one can know whether anything is known. \nAgnostics overestimate how easy it is to identify what cannot be\nknown. To know, one need only find a single proof. To know that there\nis no way to know, one must prove the negative generalization that\nthere is no proof. After all, inability to imagine a proof is commonly\ndue to a failure of ingenuity rather than the non-existence of a\nproof. In addition to being a more general proposition, a proof of\nunknowability requires epistemological premises about what constitutes\nproof. Consequently, meta-proof (proof about proofs) is even more\ndemanding than proof. \nThe agnostic might be tempted to avoid presumptuousness by converting\nto meta-agnosticism. But this “retreats” in the wrong\ndirection. Meta-meta-proof is, in turn, even more demanding than\nmeta-proof. Meta-meta-proof requires both the epistemological premises\nabout what constitutes proof that meta-proof needs and, in addition,\nmeta-meta-proof needs epistemological premises about what constitutes\nmeta-proof. \nThe eliminativist has even more severe difficulties in stating his\nposition than the skeptic. Some eliminativists dismiss the threat of\nself-defeat by drawing an analogy. Those who denied the existence of\nsouls were accused of undermining a necessary condition for asserting\nanything. However, the soul theorist’s account of what is needed\ngives no reason to deny that a healthy brain suffices for mental\nstates. \nIf the eliminativist thinks that assertion only imposes the aim of\nexpressing a truth, then he can consistently assert that\n‘know’ is a defective term. However, an epistemologist can\nrevive the charge of self-defeat by showing that assertion does indeed\nrequire the speaker to attribute knowledge to himself. This\nknowledge-based account of assertion has recently been supported by\nwork on our next paradox.  \nLotteries pose a problem for the theory that we can assert whatever we\nthink is true. Given that there are a million tickets and only one\nwinner, the probability of ‘This ticket is a losing\nticket’ is very high. If our aim were merely to utter truths, we\nshould be willing to assert the proposition. Yet we are reluctant. \nWhat is missing? Speakers will assert the proposition after seeing the\nresult of the lottery drawing or hearing about the winning ticket from\na newscaster or remembering what the winning ticket was. This suggests\nthat asserters represent themselves as knowing. This in turn suggests\nthat there is a rule, or norm, governing the practice of making\nassertions that requires us to assert only what we know. This\nknowledge norm explains why the hearer can appropriately ask\n“How do you know?” (Williamson 2000, 249–255).\nPerception, testimony, and memory are reliable processes that furnish\nanswers to this challenge.  \nDo these processes furnish certainty? When pressed, we admit\nthere is a small chance that we misperceived the drawing or that the\nnewscaster misread the winning number or that we are misremembering.\nWhile in this conciliatory mood, we are apt to relinquish our claim to\nknow. The skeptic generalizes from this surrender (Hawthorne 2004).\nFor any contingent proposition, there is a lottery statement that is\nmore probable and which is unknown. A known proposition cannot be less\nprobable than an unknown proposition. So no contingent proposition is\nknown. \nThis skeptical paradox was noticed by Gilbert Harman (1968, 166). But\nhis views about the role of causation in inferential knowledge seemed\nto solve the problem (DeRose 2017, chapter 5). The baby paradox was\ndismissed as stillborn. Since the new arrival did not get the\ncustomary baptism of attention, epistemologists did not notice that\nthe demise of the causal theory of knowledge meant new life for\nHarman’s lottery paradox.  \nThe probability skeptic’s mild suggestions about how we might be\nmistaken contrast with the extraordinary possibilities conjured by\nRené Descartes’ skeptic. The Cartesian skeptic tries to\nundermine vast swaths of knowledge with a single untestable\ncounter-explanation of the evidence (such as the hypothesis that you\nare dreaming or the hypothesis that an evil demon is deceiving you).\nThese comprehensive alternatives are designed to evade any empirical\nrefutation. The probabilistic skeptic, in contrast, points to a\nplethora of pedestrian counter-explanations. Each is easy to test:\nmaybe you transposed the digits of a phone number, maybe the ticket\nagent thought you wanted to fly to Moscow, Russia rather than Moscow,\nIdaho, etc. You can check for errors, but any check itself has a small\nchance of being wrong. So there is always something to check, given\nthat the issues cannot be ignored on grounds of improbability.  \nYou can check any of these possible errors but you cannot\ncheck them all. You cannot discount these pedestrian\npossibilities as science fiction. These are exactly the sorts of\npossibilities we check when plans go awry. For instance, you think you\nknow that you have an appointment to meet a prospective employer for\nlunch at noon. When she fails to show at the expected time, you begin\na forced march backwards through your premises: Is your watch slow?\nAre you remembering the right restaurant? Could there be another\nrestaurant in the city with the same name? Is she just detained?\nCould she have just forgotten? Could there have been a\nmiscommunication?  \nProbabilistic skepticism dates back to Arcesilaus who took over the\nAcademy two generations after Plato’s death. This moderate kind\nof skepticism, recounted by Cicero (Academica 2.74, 1.46)\nfrom his days as a student at the Academy, allows for justified\nbelief. Many scientists are attracted to probabilism and dismiss the\nepistemologist’s preoccupation with knowledge as\nold-fashioned. \nDespite the early start of the qualitative theory of probability, the\nquantitative theory did not develop until Blaise Pascal’s study\nof gambling in the seventeenth century (Hacking 1975). Only in the\neighteenth century did it penetrate the insurance industry (even\nthough insurers realized that a fortune could be made by accurately\ncalculating risk). Only in the nineteenth century did probability make\na mark in physics. And only in the twentieth century do probabilists\nmake important advances over Arcesilaus. \nMost of these philosophical advances are reactions to the use of\nprobability by scientists. In the twentieth century, editors of\nscience journals began to demand that the author’s hypothesis\nshould be accepted only when it was sufficiently probable – as\nmeasured by statistical tests. The threshold for acceptance was\nacknowledged to be somewhat arbitrary. And it was also conceded that\nthe acceptance rule might vary with one’s purposes. For\ninstance, we demand a higher probability when the cost of accepting a\nfalse hypothesis is high. \nIn 1961 Henry Kyburg pointed out that this policy conflicted with a\nprinciple of agglomeration: If you rationally believe \\(p\\) and\nrationally believe \\(q\\) then you rationally believe both\n\\(p\\) and \\(q\\). Little pictures of the same scene should\nsum to a bigger picture of the same scene. If rational belief can be\nbased on an acceptance rule that only requires a high probability,\nthere will be rational belief in a contradiction! To see why, suppose\nthe acceptance rule permits belief in any proposition that has a\nprobability of at least .99. Given a lottery with 100 tickets and\nexactly one winner, the probability of ‘Ticket \\(n\\) is a\nloser’ licenses belief. Symbolize propositions about ticket\n\\(n\\) being a loser as \\(p_n\\). Symbolize\n‘I rationally believe’ as \\(B\\). Belief in a\ncontradiction follows: \nSince belief in an obvious contradiction is a paradigm example of\nirrationality, Kyburg poses a dilemma: either reject agglomeration or\nreject rules that license belief for a probability of less than one.\n(Martin Smith (2016, 186–196) warns that even a probability of\none leads to joint inconsistency for a lottery that has infinitely\nmany tickets.) Kyburg rejects agglomeration. He promotes toleration of\njoint inconsistency (having beliefs that cannot all be true\ntogether) to avoid belief in contradictions. Reason forbids us from\nbelieving a proposition that is necessarily false but permits us to\nhave a set of beliefs that necessarily contains a falsehood. Henry\nKyburg’s choice was soon supported by the discovery of a\ncompanion paradox. \nIn D. C. Makinson’s (1965) preface paradox, an author rationally\nbelieves each of the assertions in his book. But since the author\nregards himself as fallible, he rationally believes the conjunction of\nall his assertions is false. If the agglomeration principle holds,\n\\((Bp \\amp Bq) \\rightarrow B(p \\amp q)\\), then it follows that it\nwould be rational for the author to believe the conjunction of all\nassertions in his book and also that it would be rational for the\nauthor to disbelieve the same thing!  \nThe preface paradox does not rely on a probabilistic acceptance rule.\nThe preface belief is generated in a qualitative fashion. The author\nis merely reflecting on his humbling resemblance to other authors who\nare fallible, his own past failing that he subsequently discovered,\nhis imperfection in fact checking, and so on. \nAt this juncture many philosophers join Kyburg in rejecting\nagglomeration and conclude that it can be rational to have jointly\ninconsistent beliefs. Kyburg’s solution to the preface paradox\nraises a methodological question about the nature of paradox. How can\nparadoxes change our minds if joint inconsistency is permitted?  \nA paradox is commonly defined as a set of propositions that are\nindividually plausible but jointly inconsistent. Paradoxes pressure us\nto revise beliefs in a highly structured way. For instance, much\nepistemology orbits a riddle posed by the regress of justification,\nnamely, which of the following is false? \nFoundationalists reject (1). They take some propositions to be\nself-evident. Coherentists reject (2). They tolerate some forms of\ncircular reasoning. For instance, Nelson Goodman (1965) has\ncharacterized the method of reflective equilibrium as\nvirtuously circular. Charles Peirce (1933–35, 5.250)\nrejected (3), an approach later refined by Peter Klein (2007) and\nchampioned at book-length by Scott F. Aikin (2011). Infinitists\nbelieve that infinitely long chains of justification are no more\nimpossible than infinitely long chains of causation. Finally, the\nepistemological anarchist rejects (4). As Paul Feyerabend refrains in\nAgainst Method, “Anything goes” (1988, vii, 5,\n14, 19, 159). \nVery elegant! But if joint inconsistency is rationally tolerable, why\ndo these philosophers bother to offer solutions? Why is it not\nrational to believe each of (1)–(4), despite their joint\ninconsistency? \nKyburg might answer that there is a scale effect. Although the dull\npressure of joint inconsistency is tolerable when diffusely\ndistributed over a large set of propositions, the pain of\ncontradiction becomes unbearable as the set gets smaller (Knight\n2002). And indeed, paradoxes are always represented as a\nsmall set of propositions.  \nIf you know that your beliefs are jointly inconsistent, then you\nshould reject R. M. Sainsbury’s definition of a paradox as\n“an apparently unacceptable conclusion derived by apparently\nacceptable reasoning from apparently acceptable premises” (1995,\n1). Take the negation of any of your beliefs as a conclusion and your\nremaining beliefs as the premises. You should judge this jumble\nargument as valid, and as having premises that you accept, and yet as\nhaving a conclusion you reject (Sorensen 2003b, 104–110). If the\nconclusion of this argument counts as a paradox, then the negation of\nany of your beliefs counts as a paradox. \nThe resemblance between the preface paradox and the surprise test\nparadox becomes more visible through an intermediate case. The preface\nof Siddhartha Mukherjee’s The Emperor of All Maladies: A\nBiography of Cancer warns: “In cases where there was no\nprior public knowledge, or when interviewees requested privacy, I have\nused a false name, and deliberately confounded identities to make it\ndifficult to track.” Those who refuse consent to be lied to are\nfree to close Doctor Mukherjee’s chronicle. But nearly all\nreaders think the physician’s trade-off between lies and new\ninformation is acceptable. They rationally anticipate being rationally\nmisled. Nevertheless, these readers learn much about the history of\ncancer. Similarly, students who are warned that they will receive a\nsurprise test rationally expect to be rationally misled about the day\nof the test. The prospect of being misled does not lead them to drop\nthe course.  \nThe preface paradox pressures Kyburg to extend his tolerance of joint\ninconsistency to the acceptance of contradictions (Sorensen 2001,\n156–158). Consider a logic student who is required to pick one\nhundred truths from a mixed list of tautologies and contradictions.\nAlthough the modest student believes each of his answers, \\(A_1, A_2,\n\\ldots, A_{100}\\), he also believes that at least of one these answers\nis false. This ensures he believes a contradiction. If any of his\nanswers is false, then the student believes a contradiction (because\nthe only falsehoods on the question list are contradictions).  If all\nof his test answers are true, then the student believes the following\ncontradiction: \\({\\sim}(A_1 \\amp A_2 \\amp \\ldots \\amp A_{100})\\).\nAfter all, a conjunction of tautologies is itself a tautology and the\nnegation of any tautology is a contradiction. \nIf paradoxes were always sets of propositions or arguments or\nconclusions, then they would always be meaningful. But some paradoxes\nare semantically flawed (Sorensen 2003b, 352) and some have answers\nthat are backed by a pseudo-argument employing a defective\n“lemma” that lacks a truth-value. Kurt Grelling’s\nparadox, for instance, opens with a distinction between autological\nand heterological words. An autological word describes itself, e.g.,\n‘polysyllabic’ is polysllabic, ‘English’ is\nEnglish, ‘noun’ is a noun, etc. A heterological word does\nnot describe itself, e.g., ‘monosyllabic’ is not\nmonosyllabic, ‘Chinese’ is not Chinese, ‘verb’\nis not a verb, etc. Now for the riddle: Is ‘heterological’\nheterological or autological? If ‘heterological’ is\nheterological, then since it describes itself, it is autological. But\nif ‘heterological’ is autological, then since it is a word\nthat does not describe itself, it is heterological. The common\nsolution to this puzzle is that ‘heterological’, as\ndefined by Grelling, is not a genuine predicate (Thomson 1962). In\nother words, “Is ‘heterological’\nheterological?” is without meaning. There can be no predicate\nthat applies to all and only those predicates it does not apply to for\nthe same reason that there can be no barber who shaves all and only\nthose people who do not shave themselves.  \nThe eliminativist, who thinks that ‘know’ or\n‘justified’ is meaningless, will diagnose the epistemic\nparadoxes as questions that only appear to be well-formed.\nFor instance, the eliminativist about justification would not accept\nproposition (4) in the regress paradox: ‘Some beliefs are\njustified’. His point is not that no beliefs meet the high\nstandards for justification, as an anarchist might deny that any\nostensible authorities meet the high standards for legitimacy.\nInstead, the eliminativist unromantically diagnoses\n‘justified’ as a pathological term. Just as the astronomer\nignores ‘Are there a zillion stars?’ on the grounds that\n‘zillion’ is not a genuine numeral, the eliminativist\nignores ‘Are some beliefs justified?’ on the grounds that\n‘justified’ is not a genuine adjective. \nIn the twentieth century, suspicions about conceptual pathology were\nstrongest for the liar paradox: Is ‘This sentence is\nfalse’ true? Philosophers who thought that there was something\ndeeply defective with the surprise test paradox assimilated it to the\nliar paradox. Let us review the assimilation process. \nIn the surprise test paradox, the student’s premises are\nself-defeating. Any reason the student has for predicting a test date\nor a non-test date is available to the teacher. Thus the teacher can\nsimulate the student’s forecast and know what the student\nexpects.  \nThe student’s overall conclusion, that the test is impossible,\nis also self-defeating. If the student believes his conclusion then he\nwill not expect the test. So if he receives a test, it will be a\nsurprise. The event will be all the more unexpected because the\nstudent has deluded himself into thinking the test is impossible.  \nJust as someone’s awareness of a prediction can affect the\nlikelihood of it being true, awareness of that sensitivity to his\nawareness can also affect its truth. If each cycle of awareness is\nself-defeating, then there is no stable resting place for a\nconclusion. \nSuppose a psychologist offers you a red box and a blue box (Skyrms\n1982). The psychologist can predict which box you will choose with 90%\naccuracy. He has put one dollar in the box he predicts you will choose\nand ten dollars in the other box. Should you choose the red box or the\nblue box? You cannot decide. For any choice becomes a reason to\nreverse your decision.  \nEpistemic paradoxes affect decision theory because rational choices\nare based on beliefs and desires. If the agent cannot form a\nrational belief, it is difficult to interpret his behavior as a\nchoice. The purpose of attributing beliefs and desires is to\nset up practical syllogisms that make sense of actions as means to\nends. Subtracting rationality from the agent makes framework useless.\nGiven this commitment to charitable interpretation, there is no\npossibility of your rationally choosing an option that you believe to\nbe inferior. So if you choose, you cannot really believe you were\noperating as an anti-expert, that is, someone whose opinions on a\ntopic are reliably wrong  (Egan and Elga 2005). \nThe medieval philosopher John Buridan (Sophismata, Sophism\n13) gave a starkly minimal example of such instability: \nIf you believe (B) it is false. If you do not believe (B) it is true.\nYou are an anti-expert about (B); your opinion is reliably wrong. An\noutsider who monitors your opinion can reckon whether (B) is true. But\nyou are not able to exploit your anti-expertise. \nOn the bright side, you are able to exploit the anti-expertise of\nothers. Four out of five anti-experts recommend against reading any\nfurther. \nDavid Kaplan and Richard Montague (1960) think the announcement by the\nteacher in our surprise exam example is equivalent to the\nself-referential \nKaplan and Montague note that the number of alternative test dates can\nbe increased indefinitely. Shockingly, they claim the number of\nalternatives can be reduced to zero! The announcement is then\nequivalent to  \nIf (K-0) is true then it known to be false. Whatever is known to be\nfalse, is false. Since no proposition can be both true and false, we\nhave proven that (K-0) is false. Given that proof produces knowledge,\n(K-0) is known to be false. But wait! That is exactly what (K-0) says\n– so (K-0) must be true. \nThe (K-0) argument stinks of the liar paradox. Subsequent commentators\nsloppily switch the negation sign in the formal presentations of the\nreasoning from \\(K{\\sim}p\\) to \\({\\sim}Kp\\) (that is, from\n‘It is known that not-\\(p\\)’, to ‘It is not the\ncase that it is known that \\(p\\)’). Ironically, this garbled\ntransmission results in a cleaner variation of the knower: \nIs (K) true? On the one hand, if (K) is true, then what it says is\ntrue, so no one knows it. On the other hand, that very reasoning seems\nto be a proof of (K). Proving a proposition is sufficient for\nknowledge of it, so someone must know (K). But then (K) is false!\nSince no one can know a proposition that is false, (K) is not\nknown. \nThe skeptic could hope to solve (K-0) by denying that anything is\nknown. This remedy does not cure (K). If nothing is known then (K) is\ntrue. Can the skeptic instead challenge the premise that proving a\nproposition is sufficient for knowing it? This solution would be\nparticularly embarrassing to the skeptic. The skeptic presents himself\nas a stickler for proof. If it turns out that even proof will not sway\nhim, he bears a damning resemblance to the dogmatist he so frequently\nchides. \nBut the skeptic should not lose his nerve. Proof does not always yield\nknowledge. Consider a student who correctly guesses that a step in his\nproof is valid. The student does not know the conclusion but did prove\nthe theorem. His instructor might have trouble getting the student to\nunderstand why his answer constitutes a valid proof. The intransigence\nmay stem from the prover’s intelligence rather than his\nstupidity. L. E. J. Brouwer is best known in mathematics for his\nbrilliant fixed point theorem. But Brouwer regarded his proof as\ndubious. He had philosophical doubts about the Axiom of Choice and Law\nof Excluded Middle. Brouwer persuaded a minority of mathematicians and\nphilosophers, known as intuitionists, to emulate his inability to be\neducated by non-constructive proofs.  \nThe logical myth that “You cannot prove a universal\nnegative” is itself a universal negative. So it implies its own\nunprovability. This implication of unprovability is correct but only\nbecause the principle is false. For instance, exhaustive inspection\nproves the universal negative ‘No adverbs appear in this\nsentence’. A reductio ad absurdum proves the universal\nnegative ‘There is no largest prime number’.  \nTrivially, false propositions cannot be proved true. Are\nthere any true propositions that cannot be proved true? \nYes, there are infinitely many. Kurt Gödel’s incompleteness\ntheorem demonstrated that any system that is strong enough to express\narithmetic is also strong enough to express a formal counterpart of\nthe self-referential proposition in the surprise test example\n‘This statement cannot be proved in this system’. If the\nsystem cannot prove its “Gödel sentence”, then this\nsentence is true. If the system can prove its Gödel sentence, the\nsystem is inconsistent. So either the system is incomplete or\ninconsistent. (See the entry on\n Kurt Gödel.) \nOf course, this result concerns provability relative to a system. One\nsystem can prove another system’s Gödel sentence. Kurt\nGödel (1983, 271) thought that proof was not needed for knowledge\nthat arithmetic is consistent.  \nJ. R. Lucas (1964) claims that this reveals human beings are not\nmachines. A computer is a concrete instantiation of a formal system.\nHence, its “knowledge” is restricted to what it can prove.\nBy Gödel’s theorem, the computer will be either\ninconsistent or incomplete. However, a human being with a full command\nof arithmetic can be consistent (even if he is actually\ninconsistent due to inattention or wishful thinking). \nCritics of Lucas defend the parity between people and computers. They\nthink we have our own Gödel sentences (Lewis 1999,\n166–173). In this egalitarian spirit, G. C. Nerlich (1961)\nmodels the student’s beliefs in the surprise test example as a\nlogical system. The teacher’s announcement is then a Gödel\nsentence about the student: There will be a test next week but you\nwill not be able to prove which day it will occur on the basis of this\nannouncement and memory of what has happened on previous exam days.\nWhen the number of exam days equals zero the announcement is\nequivalent to sentence K. \nSeveral commentators on the surprise test paradox object that\ninterpreting surprise as unprovability changes the topic. Instead of\nposing the surprise test paradox, it poses a variation of the liar\nparadox. Other concepts can be blended with the liar. For instance,\nmixing in alethic notions generates the possible liar:  Is\n‘This statement is possibly false’ true? (Post 1970)\n(If  it is false, then it is false that it is possibly false.\nWhat cannot possibly be false is necessarily true. But if it is\nnecessarily true, then it cannot be possibly false.) Since the\nsemantic concept of validity involves the notion of possibility, one\ncan also derive validity liars such as Pseudo-Scotus’ paradox:\n‘Squares are squares, therefore, this argument is invalid’\n(Read 1979). Suppose Pseudo-Scotus’ argument is valid. Since the\npremise is necessarily true, the conclusion would be necessarily true.\nBut the conclusion contradicts the supposition that argument is valid.\nTherefore, by reductio, the argument is necessarily invalid. Wait! The\nargument can be invalid only if it is possible for the premise to be\ntrue and the conclusion to be false. But we have already proved that\nthe conclusion of ‘Squares are squares, therefore, this argument\nis invalid’ is necessarily true. There is no consistent judgment\nof the argument’s validity. A similar predicament follows from\n‘The test is on Friday but this prediction cannot be soundly\ndeduced from this announcement’. \nOne can mock up a complicated liar paradox that resembles the surprise\ntest paradox. But this complex variant of the liar is not an\nepistemic paradox. For the paradoxes turn on the semantic\nconcept of truth rather than an epistemic concept.  \nFrederic Fitch (1963) reports that in 1945 he first learned of this\nproof of unknowable truths from a referee report on a manuscript he\nnever published. Thanks to Joe Salerno’s (2009) archival\nresearch, we now know that referee was Alonzo Church.  \nAssume there is a true sentence of the form ‘p but p is not\nknown’. Although this sentence is consistent, modest principles\nof epistemic logic imply that sentences of this form are\nunknowable. \nSince all the assumptions are discharged, the conclusion is a\nnecessary truth. So it is a necessary truth that \\(p \\amp{\\sim}Kp\\) is\nnot known. In other words, \\(p \\amp{\\sim}Kp\\) is unknowable.  \nThe cautious draw a conditional moral: If there are actual unknown\ntruths, there are unknowable truths. After all, some philosophers will\nreject the antecedent because they believe there is an omniscient\nbeing.  \nBut secular idealists and logical positivists concede that there are\nsome actual unknown truths. How can they continue to believe that all\ntruths are knowable?  Astonishingly, these eminent philosophers\nseem refuted by a pinch of epistemic logic. Also injured are those who\nlimit their claims of universal knowability to a limited domain. For\ninstance, Immanuel Kant (A223/B272) asserts that all empirical\npropositions are knowable. This pocket of optimism would be enough to\nignite the contradiction (Stephenson 2015).  \nTimothy Williamson doubts that this casualty list is enough for the\nresult to qualify as a paradox: \nAn apparent counterexample can be set aside as anomaly if it conflicts\nwith a highly confirmed law of nature. But if the counterexample only\nconflicts with a speculative generalization, the theory should be\nrejected.  \nThose who believe that the Church-Fitch result is a genuine paradox\ncan respond to Williamson with paradoxes that accord with common sense\n(and science –and religious orthodoxy). For instance, common\nsense heartily agrees with the conclusion that something exists. But\nit is surprising that this can be proved without empirical premises.\nSince the quantifiers of standard logic (first order predicate logic\nwith identity) have existential import, the logician can deduce that\nsomething exists from the principle that everything is identical to\nitself. Most philosophers balk at this simple proof because they feel\nthat the existence of something cannot be proved by sheer logic.\nLikewise, many philosophers balk at the proof of unknowables because\nthey feel that such a profound result cannot be obtained from such\nlimited means.  \nChurch’s referee report was composed in 1945. The timing and\nstructure of his argument for unknowables suggests that Church may\nhave been by inspired G. E. Moore’s (1942, 543) sentence: \nMoore’s problem is to explain what is odd about declarative\nutterances such as (M). This explanation needs to encompass both\nreadings of (M): ‘\\(p \\amp B{\\sim}p\\)’\nand ‘\\(p \\amp{\\sim}Bp\\)’. (This scope ambiguity\nis exploited by a popular joke: René Descartes sits in a bar, having a\ndrink. The bartender asks him if he would care for another. “I\nthink not,” he says, and disappears.) \nThe common explanation of Moore’s absurdity is that the speaker\nhas managed to contradict himself without uttering a contradiction. So\nthe sentence is odd because it is a counterexample to the\ngeneralization that anyone who contradicts himself utters a\ncontradiction. \nThere is no problem with third person counterparts of (M). Anyone else\ncan say about Moore, with no paradox, ‘G. E. Moore went to the\npictures last Tuesday but he does not believe it’. (M) can also\nbe embedded unparadoxically in conditionals: ‘If I went to the\npictures last Tuesday but I do not believe it, then I am suffering\nfrom a worrisome lapse of memory ’. The past tense is fine:\n‘I went to the picture shows last Tuesday but I did not believe\nit’. The future tense, ‘I went to the picture shows last\nTuesday but I will not believe it’, is a bit more of a stretch\n(Bovens 1995). We tend to picture our future selves as better\ninformed. Later selves are, as it were, experts to whom earlier selves\nshould defer. When an earlier self foresees that his later self\nbelieves \\(p\\), then the prediction is a reason to believe\n\\(p\\). Bas van Fraassen (1984, 244) dubs this “the\nprinciple of reflection”: I ought to believe a proposition given\nthat I will believe it at some future time. \nRobert Binkley (1968) anticipates van Fraassen by applying the\nreflection principle to the surprise test paradox. The student can\nforesee that he will not believe the announcement if no test is given\nby Thursday. The conjunction of the history of testless days\nand the announcement will imply the Moorean sentence: \nSince the less evident member of the conjunction is the announcement,\nthe student will choose not to believe the announcement. At the\nbeginning of the week, the student foresees that his future self may\nnot believe the announcement. So the student on Sunday will not\nbelieve the announcement when it is first uttered. \nBinkley illuminates this reasoning with doxastic logic. The inference\nrules for this logic of belief can be understood as idealizing the\nstudent into an ideal reasoner. In general terms, an ideal reasoner is\nsomeone who infers what he ought and refrains from inferring any more\nthan he ought. Since there is no constraint on his premises, we may\ndisagree with the ideal reasoner. But if we agree with the ideal\nreasoner’s premises, we appear bound to agree with his\nconclusion. Binkley specifies some requirements to give teeth to the\nstudent’s status as an ideal reasoner: the student is perfectly\nconsistent, believes all the logical consequences of his beliefs, and\ndoes not forget. Binkley further assumes that the ideal reasoner is\naware that he is an ideal reasoner. According to Binkley, this ensures\nthat if the ideal reasoner believes p, then he believes that he will\nbelieve p thereafter. \nBinkley’s account of the student’s hypothetical epistemic\nstate on Thursday is compelling. But his argument for spreading the\nincredulity from the future to the past is open to three\nchallenges. \nThe first objection is that it delivers the wrong result. The student\n\\(is\\) informed by the teacher’s announcement, so Binkley\nought not to use a model in which the announcement is as absurd as the\nconjunction ‘I went to the pictures last Tuesday but I do not\nbelieve it’.  \nSecond, the future mental state envisaged by Binkley is only\nhypothetical: \\(If\\) no test is given by Thursday, the student\nwill find the announcement incredible. At the beginning of the week,\nthe student does not know (or believe) that the teacher will wait that\nlong. A principle that tells me to defer to the opinions of my future\nself does not imply that I should defer to the opinions of my\nhypothetical future self. For my hypothetical future self is\nresponding to propositions that need not be actually true. \nThird, the principle of reflection may need more qualifications than\nBinkley anticipates. Binkley realizes that an ordinary agent foresees\nthat he will forget details. That is why we write reminders for our\nown benefit. An ordinary agent foresees periods of impaired judgment.\nThat is why we limit how much money we bring to the bar.  \nBinkley stipulates that the students do not forget. He needs to add\nthat the students know that they will not forget. For the mere threat\nof a memory lapse sometimes suffices to undermine knowledge. Consider\nProfessor Anesthesiology’s scheme for surprise tests: “A\nsurprise test will be given either Wednesday or Friday with the help\nof an amnesia drug. If the test occurs on Wednesday, then the drug\nwill be administered five minutes after Wednesday’s class. The\ndrug will instantly erase memory of the test and the students will\nfill in the gap by confabulation.” You have just completed\nWednesday’s class and so temporarily know that the test will be\non Friday. Ten minutes after the class, you lose this knowledge. No\ndrug was administered and there is nothing wrong with your memory. You\nare correctly remembering that no test was given on Wednesday.\nHowever, you do not know your memory is accurate because you also know\nthat if the test was given Wednesday then you would have a\npseudo-memory indistinguishable from your present memory. Despite not\ngaining any new evidence, you change your mind about the test\noccurring on Wednesday and lose your knowledge that the test is on\nFriday. (The change of belief is not crucial; you would still lack\nforeknowledge of the test even if you dogmatically persisted\nin believing that the test will be on Friday.)  \nIf the students know that they will not forget and know there will be\nno undermining by outside evidence, then we may be inclined to agree\nwith Binkley’s summary that his idealized student never loses\nthe knowledge he accumulates. As we shall see, however, this overlooks\nother ways in which rational agents may lose knowledge. \nA blindspot is a consistent but inaccessible proposition. Blindspots\nare relative to the means of reaching the proposition, the person\nmaking the attempt, and time at which he tries. Although I cannot\nknow the blindspot ‘There is intelligent\nextra-terrestrial life but no one knows it’, I can\nsuspect it. Although \\(I\\) cannot rationally believe\n‘Polar bears have black skin but I do not believe it’\nyou can. This means there can be disagreement between ideal\nreasoners (even under strong idealizations such as Binkley’s).\nThe anthropologist Gontran de Poncins begins his chapter on the arctic\nmissionary, Father Henry, with a prediction: \nGontran de Poncins’ subsequent testimony might lead the reader\nto believe someone can indeed be content to live in an ice-house. The\nsame testimony might lead another reader to doubt that Poncins is\ntelling the truth. But no reader ought to believe ‘Someone can\nbe content to live in an ice house and I doubt it’. \nIf Gontran believes a proposition that is a blindspot to his reader,\nthen he cannot furnish good grounds for his reader to share his\nbelief. This holds even if they are ideal reasoners. So one\nimplication of blindspots is that there can be disagreement among\nideal reasoners because they differ in their blindspots.  \nThis is relevant to the surprise test paradox. The students are the\nsurprisees. Since the announcement entails that the date of the\nsurprise test a blindspot for them, non-surprisees cannot persuade\nthem.  \nThe same point holds for intra-personal disagreement over time.\nEvidence that persuaded me on Sunday that ‘This security code is\n390524085 but on Friday I will not believe it’ should no longer\npersuade me on Friday (given my belief that the day is Friday). For\nthat proposition is a blindspot to my Friday self. \nAlthough each blindspot is inaccessible, a disjunction of blindspots\nis normally not a blindspot. I can rationally believe that\n‘Either the number of stars is even and I do not believe it, or\nthe number of stars is odd and I do not believe it’. The\nauthor’s preface statement that there is some mistake in his\nbook is equivalent to a very long disjunction of blindspots. The\nauthor is saying he either falsely believes his first statement or\nfalsely believes his second statement or … or falsely believes\nhis last statement.  \nThe teacher’s announcement that there will be a surprise test is\nequivalent to a disjunction of future mistakes: ‘Either there\nwill be a test on Monday and the student will not believe it\nbeforehand or there will be a test Wednesday and the student will not\nbelieve it beforehand or the test is on Friday and the student will\nnot believe it beforehand.’ \nThe points made so far suggest a solution to the surprise test paradox\n(Sorensen 1988, 328–343). As Binkley (1968) asserts, the test\nwould be a surprise even if the teacher waited until the last day. Yet\nit can still be true that the teacher’s announcement is\ninformative. At the beginning of the week, the students are justified\nin believing the teacher’s announcement that there will be a\nsurprise test.  This announcement is equivalent to: \nConsider the student’s predicament on Thursday (given that the\ntest has not been on Monday or Wednesday). If he knows that no test\nhas been given, he cannot also know that (A) is true. Because that\nwould imply \nAlthough (iii) is consistent and might be knowable by others, (iii)\ncannot be known by the student before Friday. (iii) is a blindspot for\nthe students but not for, say, the teacher’s colleagues. Hence,\nthe teacher can give a surprise test on Friday because that would\nforce the students to lose their knowledge of the original\nannouncement (A). Knowledge can be lost without forgetting anything.\n \nThis solution makes who you are relevant to what you can know. In\naddition to compromising the impersonality of knowledge, there will be\ncompromise on its temporal neutrality.  \nSince the surprise test paradox can also be formulated in terms of\nrational belief, there will be parallel adjustments for what we ought\nto believe. We are criticized for failures to believe the logical\nconsequences of what we believe and criticized for believing\npropositions that conflict with each other. Anyone who meets these\nideals of completeness and consistency will be unable to believe a\nrange of consistent propositions that are accessible to other complete\nand consistent thinkers. In particular, they will not be able to\nbelieve propositions attributing specific errors to them, and\npropositions that entail these off-limit propositions. \nSome people wear T-shirts with Question Authority! written on\nthem. Questioning authority is generally regarded as a matter of\nindividual discretion. The surprise test paradox shows that it is\nsometimes mandatory. The student is rationally required to doubt the\nteacher’s announcement even though the teacher has not given any\nevidence of being unreliable. Indeed, the student can foresee that\ntheir change of mind opens a new opportunity for surprise. \nThere can be disagreement amongst ideal reasoners who agree on the\nsame impersonal data. Consider the colleagues of the teachers. They\nare not amongst those that the teacher targets for surprise. Since\n‘surprise’ here means ‘surprise to the\nstudents’, the teacher’s colleagues can consistently infer\nthat the test will be on the last day from the premise that it has not\nbeen given on any previous day.  \nThe above anomalies (losing knowledge without forgetting, disagreement\namongst equally well-informed ideal reasoners, rationally changing\nyour mind without the acquisition of counter-evidence) would be more\ntolerable if reinforced by separate lines of reasoning. The most\nfertile source of this collateral support is in puzzles about updating\nbeliefs. \nThe natural strategy is to focus on the knower when he is stationary.\nHowever, just as it is easier for an Eskimo to observe an arctic fox\nwhen it moves, we often get a better understanding of the knower\ndynamically, when he is in the process of gaining or losing knowledge.\n \nWhen on trial for impiety, Socrates traced his inquisitiveness to the\nOracle at Delphi (Apology 21d in Cooper 1997). Prior to\nbeginning his mission of inquiry, Chaerephon asked the Oracle:\n“Who is the wisest of men?” The Oracle answered “No\none is wiser than Socrates.” This astounded Socrates because he\nbelieved he knew nothing. Whereas a less pious philosopher might have\nquestioned the reliability of the Delphic Oracle, Socrates followed\nthe general practice of treating the Oracle as infallible. The only\ncogitation appropriate to an infallible answer is interpretation.\nAccordingly, Socrates resolved his puzzlement by inferring that his\nwisdom lay in recognizing his own ignorance. While others may know\nnothing, Socrates knows that he knows nothing.  \nSocrates continues to be praised for his insight. But his\n“discovery” is a contradiction. If Socrates knows that he\nknows nothing, then he knows something (the proposition that he knows\nnothing) and yet does not know anything (because knowledge implies\ntruth). \nSocrates could regain consistency by downgrading his meta-knowledge to\nthe status of a belief. If he believes he knows nothing, then he\nnaturally wishes to remedy his ignorance by asking about everything.\nThis rationale is accepted throughout the early dialogues. But when we\nreach the Meno, one of his interlocutors has an epiphany.\nAfter Meno receives the standard treatment from Socrates about the\nnature of virtue, Meno discerns a conflict between Socratic ignorance\nand Socratic inquiry (Meno 80d, in Cooper 1997). How would\nSocrates recognize the correct answer even if Meno gave it?  \nThe general structure of Meno’s paradox is a dilemma: If you\nknow the answer to the question you are asking, then nothing can be\nlearned by asking. If you do not know the answer, then you cannot\nrecognize a correct answer even if it is given to you. Therefore, one\ncannot learn anything by asking questions. \nThe natural solution to Meno’s paradox is to characterize the\ninquirer as only partially ignorant. He knows enough to recognize a\ncorrect answer but not enough to answer on his own. For instance,\nspelling dictionaries are useless to six year old children because\nthey seldom know more than the first letter of the word in question.\nTen year old children have enough partial knowledge of the\nword’s spelling to narrow the field of candidates. Spelling\ndictionaries are also useless to those with full knowledge of spelling\nand those with total ignorance of spelling. But most of us have an\nintermediate amount of knowledge.  \nIt is natural to analyze partial knowledge as knowledge of\nconditionals. The ten year old child knows the spoken version of\n‘If the spelling dictionary spells the month after January as\nF-e-b-r-u-a-r-y, then that spelling is correct’. Consulting the\nspelling dictionary gives him knowledge of the antecedent of the\nconditional. \nMuch of our learning from conditionals runs as smoothly as this\nexample suggests. Knowledge of the conditional is conditional\nknowledge (that is, conditional upon learning the antecedent and\napplying the inference rule modus ponens: If P then Q, P, therefore\nQ). But the next section is devoted to some known conditionals that\nare repudiated when we learn their antecedents. \nSaul Kripke’s ruminations on the surprise test paradox led him\nto a paradox about dogmatism. He lectured on both paradoxes at\nCambridge University to the Moral Sciences Club in 1972. (A descendent\nof this lecture now appears as Kripke 2011). Gilbert Harman\ntransmitted Kripke’s new paradox as follows:  \nDogmatists accept this reasoning. For them, knowledge closes inquiry.\nAny “evidence” that conflicts with what is known can be\ndismissed as misleading evidence. Forewarned is forearmed.  \nThis conservativeness crosses the line from confidence to\nintransigence. To illustrate the excessive inflexibility, here is a\nchain argument for the dogmatic conclusion that my reliable colleague\nDoug has given me a misleading report (corrected from Sorensen\n1988b): \nBy hypothesis, I am justified in believing (C\\(_1)\\). Premise\n(C\\(_2)\\) is a certainty because it is analytically true. The\nargument from (C\\(_1)\\) and (C\\(_2)\\) to (C\\(_3)\\)\nis valid. Therefore, my degree of confidence in (C\\(_3)\\) must\nequal my degree of confidence in (C\\(_1)\\). Since we are also\nassuming that I gain sufficient justification for (C\\(_4)\\), it\nseems to follow that I am justified in believing (C\\(_5)\\) by\nmodus ponens. Similar arguments will lead me to dismiss further\nevidence such as a phone call from the towing service and my failure\nto see my car when I confidently stride over to the parking lot. \nGilbert Harman diagnoses the paradox as follows: \nIn effect, Harman denies the hardiness of knowledge. The hardiness\nprinciple states that one knows only if there is no evidence such that\nif one knew about the evidence one would not be justified in believing\none’s conclusion. New knowledge cannot undermine old knowledge.\nHarman disagrees. \nMost epistemologists have accepted Harman’s vague solution. They\nhave just tried to make it precise. Some import details philosophy of\nlanguage (Sorensen 1988b). Earl Conee (2004) argues epistemologists\nhas sufficient indigenous resources. All we need is evidentialism, the\ndoctrine that you are justified in believing p exactly when supported\nby the totality of your evidence. However, Mike Vesey rejects\nHarman’s solution as irrational. One is never entitled to\ndiscard evidence, even after it has been identified as misleading. And\nindeed, intelligence analysts during World War II scoured German\npropaganda for clues about bombing accuracy, shortages, and rivalry\nbetween branches of the German military. In a close study of our\nactual responses to identified misleading evidence, Maria\nLasonen-Aarnio (2014) suggests that we are sometimes justified in\nignoring misleading evidence and sometimes not. Since Harman has not\nprovided criteria for warranted ignoring, his solution is incomplete.\n \nHarman’s belief that new knowledge can undermine old knowledge\nmay be relevant to the surprise test paradox. Perhaps the students\nlose knowledge of the test announcement even though they do not forget\nthe announcement or do anything else incompatible with their\ncredentials as ideal reasoners. A student on Thursday is better\ninformed about the outcomes of test days than he was on Sunday. He\nknows the test was not on Monday and not on Wednesday. But he can only\npredict that the test is on Friday if he continues to know the\nannouncement. Perhaps the extra knowledge of the testless days\nundermines knowledge of the announcement. \nWe cannot coherently predict that any specific new epistemic paradox\nawaits discovery. To see why, consider the prediction Jon Wynne-Tyson\nattributes to Leonardo Da Vinci: “I have learned from an early\nage to abjure the use of meat, and the time will come when men such as\nI will look upon the murder of animals as they now look upon the\nmurder of men.” (1985, 65) By predicting this progress, Leonardo\ninadvertently reveals he already believes that the murder of\nanimals is the same as the murder of men. If you believe that a\nproposition is true but will be first believed at a later time, then\nyou already believe it – and so are inconsistent. (The actual\ntruth is irrelevant.)  \nSpecific regress can be anticipated. During the Korean war, vague\ncharges that the United States military was conducting biological\nwarfare set the stage for precise confessions by two captured American\npilots in 1953. Other captured pilots expected to be\n“brainwashed” into corroborating the sensational\nconfessions. The asymmetry between predicting progress and predicting\nregress is based on a magnetic asymmetry between truth and falsehood.\nTruth attracts belief. Falsehood repels. More precisely, perceived\ntruth creates belief while perceived falsehood creates disbelief. When\nI try to predict my first acquisition of a specific truth, I pre-empt\nmyself. When I try to predict my first acquisition of a specific\nfalsehood, there is no pre-emption.  \nThere would be no problem with predicting progress if Leonardo thinks\nthe moral progress lies in the moral preferability of the vegetarian\nbelief rather than the truth of the matter. One might admire\nvegetarianism without accepting the correctness of vegetarianism. But\nLeonardo is endorsing the correctness of the belief. This sentence\nembodies a Moorean absurdity. It is like saying ‘Leonardo took\ntwenty five years to complete The Virgin on the Rocks but I\nwill first believe so tomorrow’. (This absurdity will prompt\nsome to object that I have uncharitably interpreted Leonardo; he must\nhave intended to make an exception for himself and only be referring\nto men of his kind.) \nI cannot specifically anticipate the first acquisition of the true\nbelief that \\(p\\). For that prediction would show that I already\nhave the true belief that \\(p\\). The truth cannot wait. The\nimpatience of the truth imposes a limit on the prediction of\ndiscoveries. ","contact.mail":"roy.sorensen@austin.utexas.edu","contact.domain":"austin.utexas.edu"}]
