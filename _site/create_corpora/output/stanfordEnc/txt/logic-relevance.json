[{"date.published":"1998-06-17","date.changed":"2020-11-13","url":"https://plato.stanford.edu/entries/logic-relevance/","author1":"Edwin Mares","author1.info":"http://www.vuw.ac.nz/phil/ed.html","entry":"logic-relevance","body.text":"\n\n\nRelevance logics are non-classical logics. Called\n‘relevant logics’ in Britain and Australasia, these\nsystems developed as attempts to avoid the paradoxes of material and\nstrict implication. These so-called paradoxes are valid conclusions\nthat follow from the definitions of material and strict implication\nbut are seen, by some, as problematic.\n\n\nFor example, the material implication \\((p \\rightarrow q)\\)\nis true whenever \\(p\\) is false or \\(q\\) is true —\ni.e., \\((\\neg p \\vee q)\\). So if \\(p\\) is true,\nthen the material implication is true when \\(q\\) is true. Among\nthe paradoxes of material implication are the following:\n\n\\[\\begin{align}\n& p \\rightarrow(q \\rightarrow p), \\\\\n& \\neg p \\rightarrow(p \\rightarrow q), \\\\\n& (p \\rightarrow q) \\vee(q \\rightarrow r).\n\\end{align}\\]\n\n\nThe first asserts that every proposition implies a true one; the\nsecond that a false proposition implies every proposition, and the\nthird that for any three propositions, either the first implies the\nsecond or the second implies the third.\n\n\nSimilarly, the strict implication \\((p \\rightarrow q)\\) is\ntrue whenever it is not possible that \\(p\\) is true and\n\\(q\\) is false — i.e., \\(\\neg \\diamond(p \\amp \\neg q)\\). Among the paradoxes of strict implication are the\nfollowing:\n\n\\[\\begin{align}\n& (p \\amp \\neg p) \\rightarrow q, \\\\\n& p \\rightarrow(q \\rightarrow q), \\\\\n& p \\rightarrow(q \\vee \\neg q).\n\\end{align}\\]\n\n\nThe first asserts that a contradiction strictly implies every\nproposition; the second and third imply that every proposition\nstrictly implies a tautology.\n\n\nMany philosophers, beginning with Hugh MacColl (1908), have claimed\nthat these theses are counterintuitive. They claim that these formulae\nfail to be valid if we interpret \\(\\rightarrow\\) as representing the concept of\nimplication that we have before we learn classical logic. Relevance\nlogicians claim that what is unsettling about these so-called\nparadoxes is that in each of them the antecedent seems irrelevant to\nthe consequent.\n\n\nIn addition, relevance logicians have had qualms about certain\ninferences that classical logic makes valid. For example, consider the\nclassically valid inference\n\n\nThe moon is made of green cheese. Therefore, either it is raining in\nEcuador now or it is not.\n\n\n\nAgain here there seems to be a failure of relevance. The conclusion\nseems to have nothing to do with the premise. Relevance logicians have\nattempted to construct logics that reject theses and arguments that\ncommit “fallacies of relevance”.\n\n\nRelevant logicians point out that what is wrong with some of the\nparadoxes (and fallacies) is that the antecedents and consequents (or\npremises and conclusions) are on completely different topics. The\nnotion of a topic, however, would seem not to be something that a\nlogician should be interested in — it has to do with the\ncontent, not the form, of a sentence or inference. But there is a\nformal principle that relevant logicians apply to force theorems and\ninferences to “stay on topic”. This is the variable\nsharing principle. The variable sharing principle says that no\nformula of the form \\(A \\rightarrow B\\) can be proven in a relevance\nlogic if \\(A\\) and \\(B\\) do not have at least one propositional\nvariable (sometimes called a proposition letter) in common and that no\ninference can be shown valid if the premises and conclusion do not\nshare at least one propositional variable.\n\n\nAt this point some confusion is natural about what relevant logicians\nare attempting to do. The variable sharing principle is only a\nnecessary condition that a logic must have to count as a relevance\nlogic. It is not sufficient. Moreover, this principle does not give us\na criterion that eliminates all of the paradoxes and fallacies. Some\nremain paradoxical or fallacious even though they satisfy variable\nsharing. As we shall see, however, relevant logic does provide us with\na relevant notion of proof in terms of the real use of premises (see\nthe section “Proof Theory” below), but it does not by\nitself tell us what counts as a true (and relevant) implication. It is\nonly when the formal theory is put together with a philosophical\ninterpretation that it can do this (see the section “Semantics\nfor Relevant Implication” below).\n\n\nIn this article we will give a brief and relatively non-technical\noverview of the field of relevance logic.\n\nOur exposition of relevant logic is backwards to most found in the\nliterature We will begin, rather than end, with the semantics, since\nmost philosophers at present are semantically inclined. \nThe semantics that is presented here is the ternary relation semantics\ndue to Richard Routley and Robert K. Meyer. This semantics is a\ndevelopment of Alasdair Urquhart’s “semilattice\nsemantics” (Urquhart 1972). There is a similar semantics, due to\nKit Fine, that was developed at the same time as the Routley-Meyer\ntheory (Fine 1974). And there is an algebraic semantics due to\nJ. Michael Dunn. Urquhart’s, Fine’s, and Dunn’s\nmodels are very interesting in their own right, but we do not have\nroom to discuss them here. \nThe idea behind the ternary relation semantics is rather simple.\nConsider C.I. Lewis’ attempt to avoid the paradoxes of material\nimplication. He added a new connective to classical logic, that of\nstrict implication. In post-Kripkean semantic terms, \\(A \\prurel B\\)\nis true at a world \\(w\\) if and only if for all \\(w'\\) such that\n\\(w'\\) is accessible to \\(w\\), either \\(A\\) fails in \\(w'\\) or \\(B\\)\nobtains there. Now, in Kripke’s semantics for modal logic, the\naccessibility relation is a binary relation. It holds between pairs of\nworlds. Unfortunately, from a relevant point of view, the theory of\nstrict implication is still irrelevant. That is, we still make valid\nformulae like \\(p \\prurel (q \\prurel q)\\). We can see quite\neasily that the Kripke truth condition forces this formula on us. \nLike the semantics of modal logic, the semantics of relevance logic\nrelativises truth of formulae to worlds. But Routley and Meyer go\nmodal logic one better and use a three-place relation on worlds. This\nallows there to be worlds at which \\(q \\rightarrow q\\) fails\nand that in turn allows worlds at which \\(p \\rightarrow(q \\rightarrow q)\\) fails. Their truth condition for \\(\\rightarrow\\) on this\nsemantics is the following: \n\\(A \\rightarrow B\\) is true at a world \\(a\\) if and only\nif for all worlds \\(b\\) and \\(c\\) such that \\(Rabc\\)\n\\((R\\) is the accessibility relation) either \\(A\\) is false\nat \\(b\\) or \\(B\\) is true at \\(c\\).\n \nFor people new to the field it takes some time to get used to this\ntruth condition. But with a little work it can be seen to be just a\ngeneralisation of Kripke’s truth condition for strict implication\n(just set \\(b = c\\)). \nThe ternary relation semantics can be adapted to be a semantics for a\nwide range of logics. Placing different constraints on the relation\nmakes valid different formulae and inferences. For example, if we\nconstrain the relation so that \\(Raaa\\) holds for all worlds\n\\(a\\), then we make it true that if \\((A \\rightarrow B) \\amp A\\) is true at a world, then \\(B\\) is\nalso true there. Given other features of the Routley-Meyer semantics,\nthis makes the thesis \\(((A \\rightarrow B) \\amp A) \\rightarrow B\\) valid. If we make the ternary relation\nsymmetrical in its first two places, that is, we constrain it so that,\nfor all worlds \\(a, b\\), and \\(c\\), if\n\\(Rabc\\) then \\(Rbac\\), then we make valid the thesis\n\\(A \\rightarrow ((A \\rightarrow B) \\rightarrow B)\\). \nThe ternary accessibility relation needs a philosophical\ninterpretation in order to give relevant implication a real meaning on\nthis semantics. Recently there have been several interpretations\ndeveloped based on theories of information. \nOne interpretation is suggested in Jon Barwise (1993) and developed in\nRestall (1996). On this view, worlds are taken to be\ninformation-theoretic “sites” and “channels”.\nA site is a context in which information is received and a channel is\na conduit through which information is transferred. Thus, for example,\nwhen the BBC news appears on the television in my living room, we can\nconsider the living room to be a site and the wires, satellites, and\nso on, that connect my television to the studio in London to be a\nchannel. Using channel theory to interpret the Routley-Meyer\nsemantics, we take \\(Rabc\\) to mean that \\(a\\) is an\ninformation-theoretic channel between sites \\(b\\) and \\(c\\).\nThus, we take \\(A \\rightarrow B\\) to be true at \\(a\\) if\nand only if, whenever \\(a\\) connects a site \\(b\\) at which\n\\(A\\) obtains to a site \\(c, B\\) obtains at\n\\(c\\). \nSimilarly, Mares (1997) uses a theory of information due to David\nIsrael and John Perry (1990). In addition to other information a world\ncontains informational links, such as laws of nature, conventions, and\nso on. For example, a Newtonian world will contain the information\nthat all matter attracts all other matter. In information-theoretic\nterms, this world contains the information that two things’ being\nmaterial carries the information that they attract each other. On this\nview, \\(Rabc\\) if and only if, according to the links in\n\\(a\\), all the information carried by what obtains in \\(b\\)\nis contained in \\(c\\). Thus, for example, if \\(a\\) is a\nNewtonian world and the information that \\(x\\) and \\(y\\) are\nmaterial is contained in \\(b\\), then the information that\n\\(x\\) and \\(y\\) attract each other is contained in\n\\(c\\). \nAnother interpretation is developed in Mares (2004). This\ninterpretation takes the Routley-Meyer semantics to be a formalisation\nof the notion of “situated implication”. This\ninterpretation takes the “worlds” of the Routley-Meyer\nsemantics to be situations. A situation is a perhaps partial\nrepresentation of the universe. The information contained in two\nsituations, \\(a\\) and \\(b\\) might allow us to infer further\ninformation about the universe that is contained in neither situation.\nThus, for example, suppose in our current situation that we have the\ninformation contained in the laws of the theory of general relativity\n(this is Einstein’s theory of gravity). Then we hypothesise a\nsituation in which we can see a star moving in an ellipse. Then, on\nthe basis of the information that we have and the hypothesised\nsituation, we can infer that there is a situation in which there is a\nvery heavy body acting on this star. \nWe can model situated inference using a relation \\(I\\) (for\n“implication”). Then we have \\(IabP\\), where\n\\(P\\) is a proposition, if and only if the information in\n\\(a\\) and \\(b\\) together license the inference to there\nbeing a situation in which \\(P\\) holds. We can think of a\nproposition itself as a set of situations. We set \\(A \\rightarrow B\\) to hold at \\(a\\) if and only if, for all situations\n\\(b\\) in which \\(A\\) holds, \\(Iab|B|,\\) where\n\\(|B\\)| is the set of situations at which \\(B\\) is true. We\nset \\(Rabc\\) to hold if and only if \\(c\\) belongs to every\nproposition \\(P\\) such that \\(IabP\\). With the addition of\nthe postulate that, for any set of propositions \\(P\\) such that\n\\(IabP\\), the intersection of that set \\(X\\) is such that\n\\(IabX\\), we find that the implications that are made true on any\nsituation using the truth condition that appeals to \\(I\\) are the\nsame as those that are made true by the Routley-Meyer truth condition.\nThus, the notion of situated inference gives a way of understanding\nthe Routley-Meyer semantics. (This is a very brief version of the\ndiscussion of situated inference that is in chapters 2 and 3 of Mares\n(2004).) \nAnother informational interpretation is in Dunn (2015). This\ninterpretation neatly connects the concept of relevance in relevance\nlogic with the pragmatic notion of relevance in Grice’s conversational\nmaxims and in Sperber and Wilson’s pragmatic theory. The idea is that\nthe relation \\(R\\) holds between three “states”,\n\\(a,b\\), and \\(c\\) if in the context \\(a,\nb\\) is relevant to \\(c\\). This means that using the\ninformation both in \\(a\\) and \\(b\\) allows one to derive the\ninformation in \\(c\\). The notion of derivation here is one that\nSperber and Wilson call “contextual implication”. The result\nis derivable from the information in \\(a\\) and \\(b\\), but\nnot from the information in either alone (Sperber and Wilson, 2002, p.\n251). There are various ways to think of the combination of\ninformation in \\(a\\) and \\(b\\). One that Dunn discusses is\nto think of \\(a\\) and \\(b\\) as being similar to computer\nprograms and the combination of the two is their composition -- the\nresult of running \\(b\\) and taking the result of that as input\nfor \\(a\\), and then running \\(a\\). This combination is\nrelevant to \\(c\\) if the information produced by it is all\ncontained in \\(c\\). \nA different sort of interpretation is given by Beall, et al. (2012).\nIn fact, Beall, et al (2012) presents three different interpretations\nof the ternary relation. These interpretations link the ternary\nrelation with different notions of “conditionality”. I\ndiscuss only two of these interpretations here. The third is a bit too\ninvolved for inclusion in an encyclopedia entry. On the first of these\ninterpretations, a conditional \\(A\\rightarrow B\\) holds at a\nworld \\(a\\) if there is no counterexample to this conditional,\ni.e. a place salient to \\(a\\) at which \\(A\\) holds and\n\\(B\\) fails to hold. This “place” is not a single\nworld, but a pair of worlds, \\(b, c\\). A pair consists in\na counterexample to the conditional if \\(A\\) is true at the first\nof the pair and \\(B\\) is not true at the second. \nOn the second interpretation, the points of Routley-Meyer models are\nconsidered to be both operators (in the mathematical sense) and the\nthings that they operate on. On this understanding, \\(Rabc\\)\nmeans that considered as an operator, \\(a\\) when applied to\n\\(b\\) yields information all of which is contained in \\(c\\).\nThis interpretation makes the Routley-Meyer semantics very similar in\nintent to Fine’s operational semantics. And this interpretaion is very\nclosely related to Dunn’s interpetation (in particular in his notion\nof the combining of information in states).  \nBy itself, the use of the ternary relation is not sufficient to avoid\nall the paradoxes of implication. Given what we have said so far, it\nis not clear how the semantics can avoid paradoxes such as \\((p \\amp \\neg p) \\rightarrow q\\) and \\(p \\rightarrow \n(q \\vee \\neg q)\\). These paradoxes are avoided by the\ninclusion of inconsistent and non-bivalent worlds in the semantics.\nFor, if there were no worlds at which \\(p \\amp \\neg p\\)\nholds, then, according to our truth condition for the arrow,\n\\((p \\amp \\neg p) \\rightarrow q\\) would also hold\neverywhere. Likewise, if \\(q \\vee \\neg q\\) held at every\nworld, then \\(p \\rightarrow(q \\vee \\neg q)\\) would\nbe universally true. \nAn approach to relevance that does not require the ternary relation is\ndue to Routley and Loparic (1978) and Priest (1992) and (2008). This\nsemantics uses a set of worlds and a binary relation, \\(S\\).\nWorlds are divided into two categories: normal worlds and non-normmal\nworlds. An implication \\(A \\rightarrow B\\) is true at a\nnormal world \\(a\\) if and only if for all worlds \\(b\\), if\n\\(A\\) is true at \\(b\\) then \\(B\\) is also true true at\n\\(b\\). At non-normal worlds, the truth values for implications\nare random. Some may be true and others false. A formula is valid if\nand only if it is true on every such model in its normal\nworlds. This division of worlds into normal and non-normal and the use\nof random truth values for implications at non-normal worlds enables\nus to find countermodels for formulas such as \\(p \\rightarrow \n(q \\rightarrow q)\\). \nPriest interprets non-normal worlds as the worlds that correspond to\n“logic fictions”. In a science fiction, the laws of nature\nmay be different than those in our universe. Similarly, in a logic\nfiction the laws of logic may be different from our laws. For example,\n\\(A \\rightarrow A\\) may fail to be true in some logic\nfiction. The worlds that such fictions describe are non-normal worlds.\n \nOne problem with the semantics without the ternary relation is that it\nis difficult to use it to characterize as wide a range of logical\nsystems as can done with the ternary relation. In addition, the logics\ndetermined by this semantics are quite weak. For example, they do not\nhave as a theorem the transitivity of implication — \\(((A\n\\rightarrow B) \\amp(B \\rightarrow C)) \\rightarrow (A \\rightarrow\nC)\\). \nLike the ternary relation semantics, this semantics requires some\nworlds to be inconsistent and some to be non-bivalent. \nThe use of non-bivalent and inconsistent worlds requires a\nnon-classical truth condition for negation. In the early 1970s,\nRichard and Val Routley invented their “star operator” to\ntreat negation. The operator is an operator on worlds. For each world\n\\(a\\), there is a world \\(a\\)*. And \n\\(\\neg A\\) is true at \\(a\\) if and only if \\(A\\) is\nfalse at \\(a\\)*. \nOnce again, we have the difficulty of interpreting a part of the\nformal semantics. One interpretation of the Routley star is that of\nDunn (1993). Dunn uses a binary relation, \\(C\\), on worlds.\n\\(Cab\\) means that \\(b\\) is compatible with \\(a.\na\\)*, then, is the maximal world (the world containing the most\ninformation) that is compatible with \\(a\\). \nThere are other semantics for negation. One, due to Dunn, is a\nfour-valued semantics. As is the case for truth tables for classical\nlogic, this semantics begins with the values T (true) and F (false). A\nformula is given a set of these truth values. Thus, a formula \\(A\\)\ncan get the values \\(\\{\\True\\}\\), \\(\\{\\False\\}\\),\n\\(\\{\\True,\\False\\}\\), or \\(\\varnothing\\). If a formula gets the value\n\\(\\{\\True\\}\\), then it is just true; likewise, if it gets the value\n\\(\\{\\False\\}\\) it is just false; if it gets the value\n\\(\\{\\True,\\False\\}\\) it is both true and false; if it gets the value\n\\(\\varnothing\\), it is neither true nor false. \nEach formula is given a truth condition and a falsity condition. For\nexample, T is in the value of \\(\\neg A\\) if and only if F is in\nthe value of \\(A\\) and F is in the value of \\(\\neg A\\) if and\nonly if T is in the value of \\(A\\). With regard to conjunction, T\nis in the value of \\(A \\amp B\\) if and only if T is in the\nvalue of \\(A\\) and T is in the value of \\(B\\) and F is in\nthe value of \\(A \\amp B\\) if and only if F is the value\nof \\(A\\) or F is in the value of \\(B\\). Disjunction has very\nsimilar truth and falsity conditions.  \nDunn put forward his semantics to characterize the logic of First\nDegree Entailment (FDE), which treats only entailments between\nimplication-free formulas. (For papers on the nature and development\nof FDE, see Omori & Wansing 2017.) Richard Routley (1988) extended\nthe theory to treat some weak relevant logics, and Restall (1995)\nextended the theory to treat logics just weaker than the promenant\nrelevant logics E and R (see sections 4 and 5 below). Mares (2004a)\nused a neighbourhood semantics, together with four truth-values to\ngive a semantics for R. The four-valued semantics is treated in more\ndetail the entry on paraconsistent\nlogics. Other treatments of negation, some of which have been\nused for relevance logics, can be found in Wansing (2001) and in the\nentry on negation. \nIn (1980), Richard Routley conjectured that a constant domain\nsemantics, in the sense that is familiar from modal logic, will\ncharacterize quantified relevant relevant logics. On this semantics, a\nuniversally quantified formula \\(\\forall xA(x)\\) is true\nat a world if and only if \\(A(x)\\) is true on every\ninterpretation of \\(x\\). \nUnfortunately, Kit Fine (1988a) proved that the logic RQ (the logic R\nof relevant implication together with some standard quantificational\naxioms) is incomplete over the constant domain semantics.  \nFine (1988b) also developed a semantics over which RQ is complete and\nwhich can be modified to accommodate any of the mainstream relevance\nlogics. Fine’s semantics is “stratified”. This means that a\nmodel is made up of a collection of miniature models, each with its\nown domain of individuals. Each of these mini-models is related to\nmodels with larger domains, and each world in a model is similarly\nrelated to worlds in these models with larger domains. A very clear\nexplanation of how Fine’s semantics works is given in Shay Logan\n(2019).  \nAnother semantics for quantified relevance logics is given by Mares\nand Robert Goldblatt (2006) and further developed in Goldblatt (2011).\nIn addition to worlds and domains, a model on this theory contains a\nset of propositions, which are designated sets of words. A formula\n\\(\\forall xA(x)\\) is true at a world \\(w\\) if and\nonly if there is a proposition \\(\\pi\\) true at \\(w\\) such that \\(\\pi\\)\nentails every instance of \\(A(x)\\). This means that at\nevery world in the set \\(\\pi\\), every instance of \\(A(x)\\)\nis true.  \nThe Mares-Goldblatt semantics is called an “admissible set”\nsemantics. The propositions are the admissible sets. In some models at\nleast, not every set of worlds counts as a proposition. One rationale\nfor that comes from reflection on how humans relate circumstances\ntogether as similar. Not every set of situations are such that we\nwould see a similarity that the members of the set have to one another\nand to no other situations outside the set. It seems reasonable to\nthink of a proposition as a set of worlds that could act as a content\nfor some person. (Perhaps if we were to construct a language to talk\nabout what people could think in other words, we could index sets of\npropositions to worlds. But that is a topic to be left for some other\ntime.)  \nOne useful addition to the relevant theory of quantification is a\nconditional that is used to represent restricted quantification. This\nis developed by Jc Beall, et al. (2006). Consider the categorial\nscheme, “All \\(A\\)s are \\(B\\)s”. This scheme is\ntranslated into the language of classical logic as\n\\(\\forall x(A(x)\\supset B(x))\\).\nThe material conditional, \\(\\supset\\), is too weak to do this job in\nrelevant logic (where \\(A\\supset B\\) is understood as\n\\(\\neg A\\vee B)\\). If we were to use material implication\nis this manner, in a model for relevant logic, we could have a world\nin which all \\(A\\)s are \\(B\\)s, and some \\(i\\) is\n\\(A\\), but where \\(i\\) is not \\(B\\). The material\nconditional is too weak, but relevant implication is too strong. When\none says, for example, “Everyone in this room owns a dog”,\nshe does not mean that it follows from being in this room that people\nown a dog. Rather, it just happens that every person in this room owns\na dog. It is this connection, that lies somewhere between material and\nrelevant implication that the restricted quantificational conditional\nis supposed to capture.  \nIt is unclear, however, that the conditional of Beall, et al. (2006)\nis the right connective to use, at least with regard to some weaker\nrelevance logics. One virtue of some weaker systems is that they can\nbe used to formalise naive set theory (see\n section 6).\n Zach Weber (2010) has formalised naive set theory, using this\nconditional to define the subset relation. The resulting system,\nunfortunately, is trivial in that every formula is provable in it. \nThe logic that is often taken to be the paradigm relevance logic is\nthe logic \\(\\mathbf{R}\\). For an axiomatisation of\n\\(\\mathbf{R}\\), see\n Logic \\(\\mathbf{R}\\). \nThere are now several approaches to the proof theory for\n\\(\\mathbf{R}\\). There is a sequent calculus for the negation-free\nfragment of the logic \\(\\mathbf{R}\\) due to Gregory Mints (1972)\nand J.M. Dunn (1973) and an elegant and very general approach called\n“Display Logic” developed by Nuel Belnap (1982). But here\nI will only deal with the natural deduction system for the relevant\nlogic \\(\\mathbf{R}\\) due to Anderson and Belnap. \nAnderson and Belnap’s natural deduction system is based on Fitch’s\nnatural deduction systems for classical and intuitionistic logic. The\neasiest way to understand this technique is by looking at an\nexample. \nThis is a simple case of modus ponens. The numbers in set brackets\nindicate the hypotheses used to prove the formula. We will call them\n‘indices’. The indices in the conclusion indicate which\nhypotheses are really used in the derivation of the conclusion. In the\nfollowing “proof” the second premise is not really\nused: \nThis “proof” really just shows that the inference from\n\\(A\\) and \\(A \\rightarrow B\\) to \\(B\\) is\nrelevantly valid. Because the number 2 does not appear in the\nsubscript on the conclusion, the second “premise” does not\nreally count as a premise. \nSimilarly, when an implication is proven relevantly, the assumption of\nthe antecedent must really be used to prove the conclusion. Here is an\nexample of the proof of an implication: \nWhen we discharge a hypothesis, as in lines 4 and 5 of this proof, the\nnumber of the hypothesis must really occur in the subscript of the\nformula that is to become the consequent of the implication. \nNow, it might seem that the system of indices allows irrelevant\npremises to creep in. One way in which it might appear that\nirrelevances can intrude is through the use of a rule of conjunction\nintroduction. That is, it might seem that we can always add in an\nirrelevant premise by doing, say, the following: \nTo a relevance logician, the first premise is completely out of place\nhere. To block moves like this, Anderson and Belnap give the following\nconjunction introduction rule: \nFrom \\(A_i\\) and \\(B_i\\) to infer \\((A \\amp B)_i\\).\n \nThis rule says that two formulae to be conjoined must have the same\nindex before the rule of conjunction introduction can be used. \nThere is, of course, a lot more to the natural deduction system (see\nAnderson and Belnap 1975 and Anderson, Belnap, and Dunn 1992), but\nthis will suffice for our purposes. The theory of relevance that is\ncaptured by at least some relevant logics can be understood in terms\nof how the corresponding natural deduction system records the real use\nof premises. \nIn the work of Anderson and Belnap the central systems of relevance\nlogic were the logic \\(\\mathbf{E}\\) of relevant entailment and the\nsystem \\(\\mathbf{R}\\) of relevant implication. The relationship\nbetween the two systems is that the entailment connective of\n\\(\\mathbf{E}\\) was supposed to be a strict (i.e. necessitated)\nrelevant implication. To compare the two, Meyer added a necessity\noperator to \\(\\mathbf{R}\\) (to produce the logic\n\\(\\mathbf{NR})\\). Larisa Maksimova, however, discovered that\n\\(\\mathbf{NR}\\) and \\(\\mathbf{E}\\) are importantly different\n— that there are theorems of \\(\\mathbf{NR}\\) (on the natural\ntranslation) that are not theorems of \\(\\mathbf{E}\\). This has\nleft some relevant logicians with a quandary. They have had to decide\nwhether to take \\(\\mathbf{NR}\\) or \\(\\mathbf{E}\\) to be the\nsystem of relevant entailment. If \\(\\mathbf{E}\\) is chosen, then\nperhaps it is not reasonable to say that entailment is just relevant\nimplication together with logical necessity. It may be that entailment\nand implication are related in some other way. \nOn the other hand, there are those relevance logicians who reject both\n\\(\\mathbf{R}\\) and \\(\\mathbf{E}\\). There are those, like Arnon\nAvron, who accept logics stronger than \\(\\mathbf{R}\\) (Avron\n1990). And there are those, like Ross Brady, John Slaney, Steve\nGiambrone, Richard Sylvan, Graham Priest, Greg Restall, and others,\nwho have argued for the acceptance of systems weaker than\n\\(\\mathbf{R}\\) or \\(\\mathbf{E}\\). One extremely weak system is\nthe logic \\(\\mathbf{S}\\) of Robert Meyer and Errol Martin. As\nMartin has proven, this logic contains no theorems of the form\n\\(A \\rightarrow A\\). In other words, according to\n\\(\\mathbf{S}\\), no proposition implies itself and no argument of\nthe form ‘\\(A\\), therefore \\(A\\)’ is valid.\nThus, this logic does not make valid any circular arguments. \nFor more details on these logics see supplements on the\n logic \\(\\mathbf{E}\\),\n logic \\(\\mathbf{R}\\),\n logic \\(\\mathbf{NR}\\),\n and\n logic \\(\\mathbf{S}\\).\n  \nAmong the points in favour of weaker systems is that, unlike\n\\(\\mathbf{R}\\) or \\(\\mathbf{E}\\), many of them are decidable.\nAnother feature of some of these weaker logics that makes them\nattractive is that they can be used to construct a naïve set\ntheory. A naïve set theory is a theory of sets that includes as a\ntheorem the naïve comprehension axiom, viz., for all formulae\n\\(A(y)\\), \n\\(\\exists x\\forall y(y \\in x \\leftrightarrow A(y))\\).\n \nIn set theories based on strong relevant logics, like\n\\(\\mathbf{E}\\) and \\(\\mathbf{R}\\), as well as in classical set\ntheory, if we add the naïve comprehension axiom, we are able to\nderive any formula at all. Thus, naïve set theories based on\nsystems such as \\(\\mathbf{E}\\) and \\(\\mathbf{R}\\) are said to\nbe “trivial”. Here is an intuitive sketch of the proof of\nthe triviality of a naïve set theory using principles of\ninference from the logic R. Let \\(p\\) be an\narbitrary proposition: \nThus we show that any arbitrary proposition is derivable in this\nnaïve set theory. This is the infamous Curry Paradox. The\nexistence of this paradox has led Grishen, Brady, Restall, Priest, and\nothers to abandon the axiom of contraction \\(((A \\rightarrow \n(A \\rightarrow B)) \\rightarrow(A \\rightarrow B))\\). Brady has shown that by removing contraction, plus some\nother key theses, from \\(\\mathbf{R}\\) we obtain a logic that can\naccept naïve comprehension without becoming trivial (Brady\n2005). \nIn terms of the natural deduction system, the presence of contraction\ncorresponds to allowing premises to be used more than once. Consider\nthe following proof: \nWhat enables the derivation of contraction is the fact that our\nsubscripts are sets. We do not keep track of how many times (more than\nonce) that a hypothesis is used in its derivation. In order to reject\ncontraction, we need a way of counting the number of uses of\nhypotheses. Thus natural deduction systems for contraction-free\nsystems use “multisets” of relevance numerals instead of\nsets — these are structures in which the number of occurrences\nof a particular numeral counts, but the order in which they occurs\ndoes not. Even weaker systems can be constructed, which keep track\nalso of the order in which hypotheses are used (see Read 1986 and\nRestall 2000). \nFor three of the better known and more widely used weak relevant\nlogics, \\(\\mathbf{B}, \\mathbf{DK}\\), and\n\\(\\mathbf{DJ}\\), see the supplement on them:  \n The logics \\(\\mathbf{B}, \\mathbf{DJ}\\), and \\(\\mathbf{DK}\\).\n  \nThere are some systems that deserve to be called relevant\nthat are not mainstream relevant logic. One such system is Graham\nPriest’s logic N\\(_4\\). The easiest way to present this logic is\nto explain its semantics. \nA model for N\\(_4\\) consists in a set of world that is\npartitioned into normal and non-normal worlds. At every world,\nformulas are given one of four truth values, in accordance with Dunn’s\nsemantics explained in section 2 above, with regard to conjunction,\ndisjunction, and negation. But the treatment of implication is rather\ninteresting. At normal worlds, an implication\n\\(A\\rightarrow B\\), is true if and only if in every world w,\nif \\(A\\) is true in w, then \\(B\\) is also true in w. The\nimplication is false if there is at least one world in which\n\\(A\\) is true and \\(B\\) is false. At non-normal worlds,\nimplications are made true and false randomly.  \nN\\(_4\\) is a relevant logic. It has the variable-sharing\nproperty. And it has a very simple and intuitive semantics. It is,\nhowever, a very weak logic. It does not contain any transitivity\naxioms for implication. It has a transitivity rule. It does not\ncontain either the contraposition axiom nor the rule form of\ncontraposition. \nAnother very interesting logic is Neil Tennant’s Core Logic. One of\nthe “fallacies” that relevance logic was created to avoid\nis ex falso quodlibet, or explosion – the inference from a\ncontradiction to any proposition whatsoever. C.I. Lewis justified\nexplosion by means of a little argument. He started with the\npremise \\(p \\amp \\neg p\\). By conjunction elimination he\nderived, \\(p\\), and by disjunction\nintroduction, \\(p\\vee q\\). From the premise, he also\nderived \\(\\neg p\\), by conjunction elimination. Thus, he\nhad \\(p\\vee q\\) and \\(\\neg p\\). From these, by\ndisjunctive syllogism, Lewis derived \\(q\\). Mainstream relevance\nlogicians block this argument by rejecting disjunctive syllogism. The\nrejection of disjunctive syllogism, however, has become one of the\nmost controversial aspects of relevance logic. \n\nTennant’s core logic, however, accepts disjunctive syllogism. It also\naccepts conjunction elimination and disjunction introduction. In fact,\nCore Logic supports all the standard primitive rules that we find in\nthe proof theory of \n intuitionist logic. Thus, one could say\nthat the meanings of the connectives in Core logic are just their\nmeanings in intuitionist logic. What is different is its treatment of\none of the structural rules of proof -- it rejects the transitivity of\nlogical consequence in its most general form.  \nYet another logical system that is closely related to relevance logic\nis William Parry’s logic of Analytic Implication. Analytic Implication\nis motivated by the desire to satisfy a very strong form of\nvariable-sharing. No implication \\(A\\rightarrow B\\) is\nprovable in this logic unless \\(\\mathbf{all}\\) the variables in \\(B\\)\nare contained in \\(A\\). In order to satisfy this strong\nvariable-sharing principle, the principle of disjunction introduction\nneeds to be restricted. So, instead of having\n\\(A\\rightarrow(A\\vee B)\\) as a theorem for all\nformulas \\(A\\) and \\(B\\), this schema is valid only when all\nthe propositional variables in \\(B\\) are also in \\(A\\). The\nprinciple of contraposition and some transitivity principles for\nimplication also have to be restricted.  \nAnalytic Implication has been given an elegant possible worlds\nsemantics by Kit Fine. Fine adds to a possible worlds model a domain\nof subject matters. An implication holds at a world if and only if it\nboth preserves truth at all accessible worlds and also every subject\nmatter of the consequent is also a subject matter of the antecedent\n(Fine 1986). \nFor a comparison of Analytic Implication and relevance logic, see\nRoutley, et al., 1982, pages 96–101. For a detailed examination and\ndefense of Analytic Implication, see Ferguson (2017). \nApart from the motivating applications of providing better formalisms\nof our pre-formal notions of implication and entailment and providing\na basis for naïve set theory, relevance logic has been put to\nvarious uses in philosophy and computer science. Here I will list just\na few. \nDunn has developed a theory of intrinsic and essential properties\nbased on relevant logic. This is his theory of relevant\npredication. Briefly put, a thing \\(i\\) has a property\n\\(F\\) relevantly iff \\(\\forall x(x{=}i \\rightarrow F(x))\\). Informally, an object has a property\nrelevantly if being that thing relevantly implies having that\nproperty. Since the truth of the consequent of a relevant implication\nis by itself insufficient for the truth of that implication, things\ncan have properties irrelevantly as well as relevantly. Dunn’s\nformulation would seem to capture at least one sense in which we use\nthe notion of an intrinsic property. Adding modality to the language\nallows for a formalisation of the notion of an essential property as a\nproperty that is had both necessarily and intrinsically (see Anderson,\nBelnap, and Dunn 1992, §74). \nRelevant logic has been used as the basis for mathematical theories\nother than set theory. Meyer has produced a variation of Peano\narithmetic based on the logic \\(\\mathbf{R}\\). Meyer gave a\nfinitary proof that his relevant arithmetic does not have \\(0 = 1\\) as a\ntheorem. Thus Meyer solved one of Hilbert’s central problems in the\ncontext of relevant arithmetic; he showed using finitary means that\nrelevant arithmetic is absolutely consistent. This makes relevant\nPeano arithmetic an extremely interesting theory. Unfortunately, as\nMeyer and Friedman have shown, relevant arithmetic does not contain\nall of the theorems of classical Peano arithmetic. Hence we cannot\ninfer from this that classical Peano arithmetic is absolutely\nconsistent (see Meyer and Friedman 1992). \nAnderson (1967) formulated a system of deontic logic based on\n\\(\\mathbf{R}\\) and, more recently, relevance logic has been used\nas a basis for deontic logic by Mares (1992) and Lou Goble (1999).\nThese systems avoid some of the standard problems with more\ntraditional deontic logics. One problem that standard deontic logics\nface is that they make valid the inference from \\(A\\)’s being a\ntheorem to \\(OA\\)’s being a theorem, where\n‘\\(OA\\)’ means ‘it ought to be that\n\\(A\\)’. The reason that this problem arises is that it is\nnow standard to treat deontic logic as a normal modal logic. On the\nstandard semantics for modal logic, if \\(A\\) is valid, then it is\ntrue at all possible worlds. Moreover, \\(OA\\) is true at a world\n\\(a\\) if and only if \\(A\\) is true at every world accessible\nto \\(a\\). Thus, if \\(A\\) is a valid formula, then so is\n\\(OA\\). But it seems silly to say that every valid formula ought\nto be the case. Why should it be the case that either it is now\nraining in Ecuador or it is not? In the semantics for relevant logics,\nnot every world makes true every valid formula. Only a special class\nof worlds (sometimes called “base worlds” and sometimes\ncalled “normal worlds”) make true the valid formulae. Any\nvalid formula can fail at a world. By allowing these “non-normal\nworlds” in our models, we invalidate this problematic rule. \nOther sorts of modal operators have been added to relevance logic as\nwell. Fuhrmann (1990) adapts the usual axioms for the familiar\nclassical modal logics to the relevant context to produce a collection\nof relevant modal logics and proves completeness results for them.\nEpistemic modal operators have been added to relevance logics by\nHeinrich Wansing (2002), Marta Bilkova, Ondrej Majer, Michal\nPeliš, and Greg Restall (2010), among others. Shawn Standefer\n(2019) has produced a relevant version of justification logic and has\nvery recently added an actuality opertor to relevance logic. There is even a relevant logic of questions and answers (see Punčochář forthcoming). \nRoutley and Val Plumwood (1989) and Mares and André Fuhrmann\n(1995) present theories of counterfactual conditionals based on\nrelevant logic. Their semantics adds to the standard Routley-Meyer\nsemantics an accessibility relation that holds between a formula and\ntwo worlds. On Routley and Plumwood’s semantics, \\(A\\gt B\\)\nholds at a world \\(a\\) if and only if for all worlds \\(b\\) such that\n\\(SAab\\), \\(B\\) holds at \\(b\\). Mares and Fuhrmann’s semantics\nis slightly more complex: \\(A\\gt B\\) holds at a world \\(a\\) if and\nonly if for all worlds \\(b\\) such that \\(SAab\\), \\(A \\rightarrow B\\)\nholds at \\(b\\) (also see Brady (ed.) 2002, §10 for details of\nboth semantics). Mares (2004) presents a more complex theory of\nrelevant conditionals that includes counterfactual conditionals. All\nof these theories avoid the analogues of the paradoxes of implication\nthat appear in standard logics of counterfactuals. \nRelevant logics have been used in computer science as well as in\nphilosophy. Linear logics — a branch of logic initiated by\nJean-Yves Girard — is a logic of computational resources. Linear\nlogicians read an implication \\(A \\rightarrow B\\) as saying that\nhaving a resource of type \\(A\\) allows us to obtain something of type\n\\(B\\). If we have \\(A \\rightarrow(A \\rightarrow B)\\), then, we know\nthat we can obtain a \\(B\\) from two resources of type \\(A\\). But this\ndoes not mean that we can get a \\(B\\) from a single resource of type\n\\(A\\), i.e. we don’t know whether we can obtain \\(A \\rightarrow\nB\\). Hence, contraction fails in linear logic. Linear logics are, in\nfact, relevant logics that lack contraction and the distribution of\nconjunction over disjunction \\(((A \\amp(B \\vee C)) \\rightarrow((A \\amp\nB) \\vee(A \\amp C)))\\). They also include two operators (! and ?) that\nare known as “exponentials”. Putting an exponential in\nfront of a formula gives that formula the ability to act classically,\nso to speak. For example, just as in standard relevance logic, we\ncannot usually merely add an extra premise to a valid inference and\nhave it remain valid. But we can always add a premise of the form\n\\(!A\\) to a valid inference and have it remain valid. Linear logic\nalso has contraction for formulae of the form \\(!A\\), i.e., it is a\ntheorem of these logics that \\((!A \\rightarrow(!A \\rightarrow B))\n\\rightarrow(!A \\rightarrow B)\\) (see Troelstra 1992). The use of !\nallows for the treatment of resources “that can be duplicated or\nignored at will” (Restall 2000, p 56). For more about linear\nlogic, see the entry on\n substructural logic.","contact.mail":"Edwin.Mares@vuw.ac.nz","contact.domain":"vuw.ac.nz"}]
