[{"date.published":"2011-11-07","date.changed":"2021-04-14","url":"https://plato.stanford.edu/entries/montague-semantics/","author1":"Theo M. V. Janssen","author2":"Thomas Ede Zimmermann","entry":"montague-semantics","body.text":"\n\n\nMontague semantics is a theory of natural language semantics and of\nits relation with syntax. It was originally developed by the logician\nRichard Montague (1930–1971) and subsequently modified and\nextended by linguists, philosophers, and logicians. The most important\nfeatures of the theory are its use of model theoretic semantics which\nis nowadays commonly used for the semantics of logical languages and\nits adherence to the principle of compositionality—that is, the\nmeaning of the whole is a function of the meanings of its parts and\ntheir mode of syntactic combination. This entry presents the origins\nof Montague Semantics, summarizes important aspects of the classical\ntheory, and sketches more recent developments. We conclude with a\nsmall example, which illustrates some modern features.\n\nMontague semantics is the approach to the semantics of natural\nlanguage introduced by Richard Montague in the 1970s. He described the\naim of his enterprise as follows: \nThe salient points of Montague’s approach are a model theoretic\nsemantics, a systematic relation between syntax and semantics, and a\nfully explicit description of a fragment of natural language. His\napproach constituted a revolution: after the Chomskyan revolution that\nbrought mathematical methods into syntax, now such methods were\nintroduced in semantics. \nMontague’s approach became influential, as many authors began to\nwork in his framework and conferences were devoted to ‘Montague\ngrammar’. Later on, certain aspects of his approach were adapted\nor changed, became generally accepted or were entirely abandoned.\nNowadays not many authors would describe their own work as\n‘Montague semantics’ given the many differences that have\ntaken shape in semantics since Montague’s own work, but his\nideas have left important traces, and changed the semantic landscape\nforever. In our presentation of Montague semantics the focus will be\non these developments. \nRichard Montague was a mathematical logician who had specialized in\nset theory and modal logic. His views on natural language must be\nunderstood with his mathematical background in mind. Montague held the\nview that natural language was a formal language very much in the same\nsense as predicate logic was a formal language. As such, in\nMontague’s view, the study of natural language belonged to\nmathematics, and not to psychology (Thomason 1974, 2). Montague\nformulated his views: \nSometimes only the first part of the quote is recalled, and that might\nraise the question whether he did not notice the great differences:\nfor instance that natural languages develop without an a priori set of\nrules whereas artificial languages have an explicit syntax and are\ndesigned for a special purpose. But the quote as a whole expresses\nclearly what Montague meant by ‘no important theoretical\ndifference’; the ‘single natural and mathematically\nprecise theory’ which he aimed at, is presented in his paper\n‘Universal Grammar’ (Montague 1970c). He became most\nwell-known after the appearance of Montague 1973, in which the theory\nis applied to some phenomena which were discussed intensively in the\nphilosophical literature of those days. \nAccording to Caponigro (forthcoming), Montague’s interest in the\nfield arose when preparing a seminar on the philosophy of language as\na visiting professor in Amsterdam in 1966. Only a couple of years\nearlier, he had deemed the “systematic exploration of the\nEnglish language, indeed of what might be called the ‘logic of\nordinary English’, […] either extremely laborious or\nimpossible” and did ‘not find it rewarding’\n(Montague and Kalish 1964, 10). Yet he appears to have changed his\nmind after perusing Quine’s (1960) Word and Object as\nwell as Chomsky’s (1965) Aspects of the Theory of\nSyntax: the latter opened the perspective of treating the syntax\nof natural language as a formal system but failed to provide any\nserious analysis of linguistic meaning; the former offered a\nsystematic connection between traditional grammar and formal logic\n– and much more systematically so than contemporary logic texts.\nIn fact, Montague’s semantic work owes a lot to Quine’s\ndescriptive insights into the ‘logic of ordinary English’,\nbut differs from his predecessor by making the connection between\nlanguage and logic in rigorous, mathematical terms: \nWe next describe the basic ideas of Montague semantics. Section\n 2\n presents several components of Montague semantics in more detail.\nSection\n 3\n includes a discussion of philosophically interesting aspects, and\nSection\n 4\n provides a detailed example and further reading. \nTo implement his objective, Montague applied the method which is\nstandard for logical languages: model theoretic semantics. This means\nthat, using constructions from set theory, a model is defined, and\nthat natural language expressions are interpreted as elements (or\nsets, or functions) in this universe. Such a model should not be\nconceived of as a model of reality. On the one hand, the model gives\nmore than reality: natural language does not only speak about past,\npresent and future of the real world, but also about situations that\nmight be the case, or are imaginary, or cannot be the case at all. On\nthe other hand, however, the model offers less: it merely specifies\nreality as conceived by language. An example: we speak about mass\nnouns such as water as if every part of water is water again,\nas if it has no minimal parts, which physically is not correct. For\nmore information on natural language metaphysics, see Bach 1986b. \nMontague semantics is not interested in a particular situation (e.g.\nthe real world) but in semantical properties of language. When\nformalizing such properties, reference to a class of models has to be\nmade, and therefore the interpretation of a language will be defined\nwith respect to a set of (suitable) models. For example, in the\nintroduction we mentioned that the characterization of entailment was\na basic goal of semantics. That notion is defined as follows. Sentence\n\\(A\\) entails sentence \\(B\\) if in all models in which the\ninterpretation of \\(A\\) is true, also the interpretation of \\(B\\) is\ntrue. Likewise, a tautology is true in all models, and a contradiction\nis true in no model. \nAn essential feature of Montague semantics is the systematic relation\nbetween syntax and semantics. This relation is described by the\nPrinciple of Compositionality, which reads, in a formulation\nthat is standard nowadays: \nAn example: Suppose that the meaning of walk, or\nsing is (for each model in the class) defined as the set of\nindividuals who share respectively the property of (being an\nindividual that is) walking or the property of (being an individual\nthat is) singing. By appealing to the principle of compositionality,\nif there is a rule that combines these two expressions to the verb\nphrase walk and sing, there must be a corresponding rule that\ndetermines the meaning of that verb phrase. In this case, the\nresulting meaning will be the intersection of the two sets.\nConsequently, in all models the meaning of walk and sing is a\nsubset of the meaning of walk. Furthermore, we have a rule\nthat combines the noun phrase John with a verb phrase. The\nresulting sentence John walks and sings means that John is an\nelement of the set denoted by the verb phrase. Note that in any model\nin which John is element of the intersection of walkers and singers,\nhe is an element of the set of walkers. So John walks and\nsings entails John walks. \nAn important consequence of the principle of compositionality is that\nall the parts that play a role in the syntactic composition of a\nsentence must also have a meaning. And furthermore, each syntactic\nrule must be accompanied by a semantic rule which says how the meaning\nof the compound is obtained. Thus, the meaning of an expression is\ndetermined by the way in which the expression is formed, and as such\nthe derivational history plays a role in determining the meaning. For\nfurther discussion, see Section\n 2.5. \nThe formulation of the aim of Montague semantics mentioned in the\nintroduction (‘to characterize truth and entailment of\nsentences’) suggests that the method is restricted to\ndeclarative sentences. But this need not be the case. In Montague 1973\n(241 fn) we already find suggestions for how to deal with imperatives\nand questions. Hamblin (1973) and Karttunen (1977) have given a\nsemantics for questions by analyzing them as expressing sets of\npropositions, viz. those expressed by their (declarative) answers; an\nalternative approach, taken by Groenendijk and Stokhof (1989)\nconsiders questions as partitioning logical space into mutually\nexcluding possibilities. \nSince Montague only considered sentences in isolation, certain\ncommentators pointed out that the sentence boundary was a serious\nlimitation for the approach. But what about discourse? An obvious\nrequirement is that the sentences from a discourse are interpreted one\nby one. How then to treat co-referentiality of anaphora over sentence\nboundaries? The solution which was proposed first was Discourse\nRepresentation Theory (Kamp 1981). On the one hand, that was an\noffspring of Montague’s approach because it used model theoretic\nsemantics; on the other hand, it was a deviation because (discourse)\nrepresentations were an essential ingredient. Nowadays there are\nseveral reformulations of DRT that fit into Montague’s framework\n(see van Eijck and Kamp 1997). A later solution was based upon a\nchange of the logic; dynamic Montague semantics was developed and that\ngave a procedure for binding free variables in logic which has an\neffect on subsequent formulas (Groenendijk and Stokhof 1990, 1991).\nHence the sentence boundary is not a fundamental obstacle for Montague\nsemantics. \nMontague’s most influential article was ‘The Proper\nTreatment of Quantification in Ordinary English’ (Montague\n1973), commonly abbreviated as ‘PTQ’. It presented a\nfragment of English that covered several phenomena which were in those\ndays discussed extensively. One of the examples gave rise to the\ntrademark of Montague grammar: the unicorn (several publications on\nMontague grammar are illustrated with unicorns). \nConsider the two sentences John finds a unicorn and John\nseeks a unicorn. These are syntactically alike\n(subject-verb-object), but are semantically very different. From the\nfirst sentence follows that there exists at least one unicorn, whereas\nthe second sentence is ambiguous between the so called de\ndicto (or non-specific, or notional) reading\nwhich does not imply the existence of unicorns, and the de re\n(or specific, or objectual) reading from which\nexistence of unicorns follows. \nThe two sentences are examples of a traditional problem called\n‘quantification into intensional contexts’. Traditionally,\nthe second sentence as a whole was seen as an intensional context, and\nthe novelty of Montague’s solution was that he considered the\nobject position of seek as the source of the phenomenon. He\nformalized seek not as a relation between two individuals,\nbut as a relation between an individual and a more abstract entity\n(see section 2.2). Under this analysis the existence of a unicorn does\nnot follow. The de re reading is obtained in a different way\n(see section 2.5). \nIt was Montague’s strategy to apply to all expressions of a\ncategory the most general approach, and narrow this down, when\nrequired, by meaning postulates (and, in some cases, logical\ndecomposition). So initially, find is also considered to be a\nrelation between an individual and such an abstract entity, but some\nmeaning postulate restricts the class of models in which we interpret\nthe fragment to only those models in which the relation for\nfind is the (classical) relation between individuals. \nAs a consequence of this strategy, Montague’s paper has many\nmeaning postulates. Nowadays semanticists often prefer to express the\nsemantic properties of individual lexical items directly in their\nlexical meaning, and then find is directly interpreted as a\nrelation between individuals. Meaning postulates are mainly used to\nexpress structural properties of the models (for instance, the\nstructure of the time axis), and to express relations between the\nmeanings of words. For a discussion of the role of meaning postulates,\nsee Zimmermann 1999. \nNoun phrases like a pig, every pig, and\nBabe, behave in many respects syntactically alike: they can\noccur in the same positions, can be conjoined, etc. But a uniform\nsemantics seems problematic. There were proposals which said that\nevery pig denotes the universally generic pig, and a\npig an arbitrary pig. Such proposals were famously rejected by\nLewis (1970), who raised, for instance, the question which would be\nthe color of the universal pig, all colors, or would it be\ncolorless? \nMontague proposed the denotation of a descriptive phrase to be a set\nof properties. For instance, the denotation of John is the\nset consisting of properties which hold for him, and of every\nman the set of properties which hold for every man. Thus they are\nsemantically uniform, and then conjunction and/or disjunction of\narbitrary quantifier phrases (including e.g. most but not\nall) can be dealt with in a uniform way. \nThis abstract approach has led to generalized quantifier theory, see\nBarwise and Cooper 1981 as well as Peters and Westerståhl 2006.\nAmong the most popular achievements of generalized quantifier theory\nis a semantic characterization of so-called ‘negative polarity\nitems’: words like yet and ever. Their\noccurrence can be licensed by negation: The 6:05 has arrived\nyet is out, whereas The 6:05 hasn’t arrived yet is\nOK. But there are more contexts in which negative polarity items may\noccur, and syntacticians did not succeed in characterizing them.\nLadusaw (1980) did so by using a characterization from generalized\nquantifier theory. This has been widely acknowledged as a great\nsuccess for formal semantics. His proposal roughly was as follows.\nDownward entailing expressions are expressions that license inferences\nfrom supersets to subsets. No is downward entailing because\nfrom No man walks it follows that No father walks. A\nnegative polarity item is acceptable only if it is interpreted in the\nscope of a downward entailing expression, e.g. No man ever\nwalks. Further research showed that the analysis needed refining,\nand that a hierarchy of negative polarity items should be used\n(Ladusaw 1996, Homer 2021). \nAn expression may directly be associated with some element from the\nmodel. For instance, walk with some set of individuals. Then\nalso the operations on meanings have to be specified directly, and\nthat leads to formulations such as: \nSuch descriptions are not easy to understand, nor convenient to work\nwith. Montague (1973, 228) said, ‘it is probably more\nperspicuous to proceed indirectly’. For this purpose he\nintroduced a language, called ‘intensional logic’. The\noperation described above is then represented by \\(^{\\wedge}\\lambda\nt\\lambda u[t = u\\)]. The \\(\\lambda t\\) says that it is a function that\ntakes \\(t\\) as argument, likewise for \\(\\lambda u\\). So \\(\\lambda\nt\\lambda u[t = u\\)] is a function which takes two arguments, and\nyields true if the arguments are equal, and otherwise false. The\npreceding \\(^{\\wedge}\\) says that we consider a function from possible\nworlds and moments of time to the thus defined function. \nThree features of the Montague’s ‘intensional logic’\nattracted attention: \nIt is a higher-order logic. Even though type logic was\nalready an established logical framework in those days, linguists,\nphilosophers and mathematicians were more familiar with first order\nlogic (the logic in which there are only variables for basic\nentities). Since in Montague semantics the parts of expressions must\nhave meaning too, a higher order logic was needed (we have already\nseen that every man denotes a set of properties). \nIt is intensional in that it obeys neither Leibniz’ law\nof substitution of co-extensional terms nor existential\ngeneralization, thereby seemingly bringing logic closer to natural\nlanguage. To achieve this, Montague generalized Kripke’s (1963)\ngroundbreaking semantic techniques from first-order modal logic to\nhigher-order type logic. However, the same interpretive effect could\nhave been achieved by using a two-sorted, extensional type logic\n(Gallin 1975; Zimmermann 1989; 2021), which many semanticsists prefer\ntoday. \nMontague used \\(\\lambda\\)-abstraction, which at the time was\nnot a standard ingredient of logic. As illustrated in section 4.1, the\n\\(\\lambda\\)-operator makes it possible to express higher-order\nfunctions, which may serve as the contributions that parts of\nsentences make to their truth-values. The importance of\n\\(\\lambda\\)-expressions was once expressed by Barbara Partee in a talk\non ‘The first decade of Montague Grammar’: ‘Lambdas\nchanged my life’ (Partee 1996, 24). Nowadays\n\\(\\lambda\\)-expressions are a standard tool in natural language\nsemantics, and particularly in the type-driven approach made popular\nby Heim and Kratzer (1998). In section 4.1, an example will be given\nthat illustrates the power of \\(\\lambda\\)-expressions. \nThis motivation for indirect interpretation – by way of\ncompositional translation as a tool for obtaining perspicuous\nrepresentations of meaning – has a number of important\nconsequences: \nThe method of using logical notation for representing meanings has a\nlong history, going back at least to philosophers such as Dalgarno and\nLeibniz who developed formal languages in order to express philosophy\nclearly. In the 19th century, there were several proposals for\nartificial languages in order to make mathematical argumentation more\ntransparent, for instance by Frege and by Peano. Frege’s\n‘Begriffsschrift’ (Frege 1879) can be seen as the birth of\npredicate logic: he introduced quantifiers. His motivation came from\nmathematical needs; he did not use his Begriffsschrift in his papers\non natural language. Russell (1905) used logic to represent the\nmeanings of natural language. A classical example in his paper is the\nanalysis of The king of France is bald. Syntactically it has\nthe form subject-predicate, but if it were constructed logically as a\nsubject-predicate, then the king of France, which denotes\nnothing, cannot be the subject. So syntactic form and logical form may\ndiverge: natural language obscures the view of the real meaning. This\nbecame known as the ‘misleading form thesis’. Therefore,\nphilosophers of language saw, in those days, the role of logic as a\ntool to improve natural language, an aim that is alien to Montague\nsemantics. In fact, using higher-order functional type theory (Church\n1940) as the target of his translation, Montague (1970c) developed a\n‘compositional’ version of Russell‘s analysis, which\ndoes preserve the constituent structure of the source language\n(English). An interesting overview of the history of translating\nnatural language into logic is given in Stokhof 2007. \nMontague defined the denotation of a sentence as a function from\npossible worlds and moments of time to truth values. Such a function\nis called an ‘intension’. As he said (Montague 1970a,\n220), this made it possible to deal with the semantics of common\nphenomena such as modifiers, e.g. in Necessarily the father of\nCain is Adam. Its denotation cannot be obtained from the truth\nvalue of The father of Cain is Adam: one needs to know the\ntruth value for other possible worlds and moments of time. The\nintensional approach also made it possible to deal with several\nclassical puzzles. Two examples from Montague 1973 are: The\ntemperature is rising, which should not be analyzed as stating\nthat some number is rising; and John wishes to catch a fish and\neat it, which should not be analyzed as implying that John has a\nparticular fish in mind. \nIntensional semantics has been criticized for the fact that all\ntautologies get the same meaning (are synonymous). Indeed, a tautology\nas John is ill or he is not ill gets as intension the\nfunction that constantly yields true, and the same holds for\nother tautologies. If one is interested in discriminating semantically\nbetween tautologies, then a refinement of the notions\n‘meaning’ and ‘equivalence’ is needed:\n‘meaning’ should see distinctions between tautologies, and\n‘equivalence’ should be sensitive for the thus refined\nnotion of meaning. The oldest proposals to account for this problem\ngoes back to Carnap (1947, §14) and was later taken up by Lewis\n(1970, sec. 5): propositions are structured by including in their\nmeanings also the meanings of their parts. Then indeed Green grass\nis green and White snow is white have different\nmeanings. However, lexical synonyms still pose a problem. Since\nwoodchuck and groundhog are names for the same\nspecies, John believes that Phil is a groundhog is, under\nthis view, equivalent with John believes that Phil is a\nwoodchuck. One could consider belief contexts a separate problem,\nbut most authors see it as part of the problem of equivalence of all\ntautologies. \nLater several proposals for dealing with this have been developed;\nsurveys can be found in Bäuerle and Cresswell (2003), Fox and\nLappin (2005), and Egré (2021). The latter authors explain that\nthere are two strategies: the first is to introduce impossible worlds\nin which woodchuck and groundhog are not equivalent,\nand the second is to introduce an entailment relation with the\nproperty that identity does not follow from reciprocal entailment. Fox\nand Lappin follow the second strategy. \nA well known example of scope ambiguity is Every man loves a\nwoman. Is there only one woman involved (e.g. Mother Mary), or\ndoes every man love a different woman? The sentence has no lexically\nambiguous words, and there are no syntactic arguments to assign them\nmore than one constituent structure. How to account for the\nambiguity? \nIn Montague 1973, the scope ambiguity is dealt with by providing for\nthe sentence two different derivations. On the reading that\nevery has wide scope, the sentence is produced from every\nman and loves a woman. On the reading that only one\nwoman is involved, the sentence is obtained from Every man loves\nhim\\(_1\\). The him\\(_1\\) is an artifact, a placeholder,\nor, one might say, a syntactic variable. A special kind of rule,\ncalled a ‘quantifying-in rule’, will replace this\nhim\\(_1\\) by a noun phrase or a pronoun (in case there are\nmore occurrences of this placeholder). The placeholder corresponds\nwith a logical variable that becomes bound by the semantic counterpart\nof the quantifying-in rule. For the sentence under discussion, the\neffect of the application of the quantifying-in rule to a\nwoman and Every man loves him\\(_1\\) is that the desired\nsentence is produced and that the quantifier corresponding with a\nwoman gets wide scope. When we would depict its derivation as a\ntree, this tree would be larger than the constituent structure of the\nsentence due to the introduction and later removal of\nhim\\(_1\\). \nThis quantifying-in rule is used by Montague for other phenomena as\nwell. An example is co-referentiality: Mary loves the man whom she\nkissed is obtained from He\\(_1\\) loves the man whom\nhe\\(_1\\) kissed. And the de re reading of\nJohn seeks a unicorn is obtained from a unicorn and\nJohn seeks him\\(_1\\). \nMany researchers did not like this analysis in which powerful\nsyntactic rules and artificial symbols (him\\(_1)\\) are used.\nBelow we consider two strategies to remedy. \nThe first strategy was to deny the ambiguity. Some linguists have\nargued that the scope order is the same as the surface order; this is\nknown as ‘Jackendoff’s principle’ (Jackendoff 1972).\nBut there are sentences where this does not work. Others said that it\nis sufficient only to obtain the weakest reading (every wide\nscope), and that the stronger reading is inferred when additional\ninformation is available. But there are sentences for which the\ndifferent scope readings are logically independent, as in Every\nwoman loves one man. \nThe second strategy was to capture the ambiguity in another way than\nby the quantifying-in rules. Historically the first method was to put\nthe interpretations of the noun phrases in a store from which these\ninterpretations could be retrieved when needed: different stages of\nretrieving correspond with differences in scope. One might see this as\na grammar in which the direct correspondence between syntax and\nsemantics has been relaxed. The method is called ‘Cooper\nStore’, after the author who proposed this (Cooper 1983). A\nlater proposal is DRT \\((=\\) Discourse Representation Theory), where\nrepresentations are used to account for such ambiguities (van Eijck\nand Kamp 1997). \nA recent method is by means of ‘lifting rules’ (see\nsection 3.3): the meaning of a noun-phrase is ‘lifted’ to\na more abstract level, and different levels yield different scope\nreadings (see Hendriks 2001 and Jacobson 2014). \nEven if the role of derivational history can be avoided for scope and\nco-referentiality, other phenomena remain for which derivational\nhistories have a role. An example is John wondered when Alice said\nshe would leave. This is ambiguous between John asking for the\ntime of leaving, or for the time of saying. So the sentence is\nambiguous, even though there are no arguments for assigning to it more\nthan one constituent structure. Pelletier (1993) presents this\nsentence and others, and says: ‘In order to maintain the\nCompositionality Principle, theorists have resorted to a number of\ndevices which are all more or less unmotivated (except to maintain the\nPrinciple): Montagovian “quantifying-in” rules, traces,\ngaps, […].’ Pelletier’s objection can be\nappreciated if one assumes that meaning assignment is directly linked\nwith constituent structure. But, as explained in Section\n 1.2,\n this is not the case. The derivation specifies which rules are\ncombined in which order, and this derivation constitutes the input to\nthe meaning assignment function. The constituent structure is\ndetermined by the output of the syntactic rules, and different\nderivation processes may generate one and the same constituent\nstructure. In this way, semantic ambiguities are accounted for. One\nshould not call something ‘constituent structure’ if it is\nnot intended as such, and next refute it because it does not have the\ndesired properties. \nThe distinction between a derivation tree and a constituent tree is\nmade in several theories of grammar. In Tree Adjoining Grammars (TAGs)\nthe different scope readings of the sentence about loving a woman\ndiffer in the order in which the noun-phrases are substituted in the\nbasic tree. A classical example in Chomskyan grammar is The\nshooting of the hunters was bloody, which is ambiguous between\nthe hunters shooting, or the hunters being shot at. The two readings\ncome from two different sources: one in which the hunters is\nthe subject of the sentence, and one in which it is the object. \nThroughout most of his semantic work, Montague avowedly adopted a\nversion of Frege’s (1892) distinction between\n‘sense’ and ‘denotation’. Frege’s\noriginal line of thought concerns sentences like The Greeks did\nnot know that the morning star is the evening star, which does\nnot seem to express that the Greeks were confused about the\nself-identity of Venus. Frege’s analysis accounts for this\nobservation by having descriptive names like the morning star\ndenote their referents in ordinary contexts, but something different\nin embedded clauses (or, more generally, in ‘indirect\ncontexts’): their ‘sense’ – a semantic value\nthat captures the way in which an object is referred to. Since\nreferring to a celestial object by the morning star differs\nfrom referring to it by the evening star, the embedded clause\ndoes not denote an analytic truth but a contingent proposition, whose\ntruth may well have escaped the Greeks. \nFrege’s approach is known to run into a number of problems. One\nof them concerns the iteration of indirect contexts, as in Gottlob\nsuspected that the Greeks did not know that the morning star is the\nevening star. Though he did not explicitly address the issue,\nFrege is usually understood as resorting to an infinite hierarchy of\never more indirect senses to be associated with each otherwise\nnon-ambiguous expression (Dummett 1981, 267; Carnap 1947, §30;\nKripke 2008, 183; see however Parsons 1981 for a more cautious\ninterpretation). The purported Fregean line of analysis has been\ncriticized for multiplying ambiguity beyond necessity (Janssen 2012)\nas well as raising serious learnability issues (Davidson 1968, 11).\nThough Montague did acknowledge a hierarchy of senses, he did not\nemploy it for the analysis of iterated indirect contexts. Instead, he\nidentified Frege’s (1892) senses with intensions along\nthe lines of Carnap (1947) – set theoretic functions on a\nlogical space of possible worlds (or world-time-pairs) whose values\nare the denotations of expressions – their extensions.\nIn particular, the way in which a description refers to its referent\nis captured by its dependence on contingent facts. As a case in point,\nthe famous Fregean descriptions differ in intension as long as there\nis a possible world in which the brightest star at dawn is not the\nsame object as the brightest star at night. \nThe replacement of senses by intensions paves the way to an\nalternative approach to iterated intensionality: generalizing\nKripke’s (1963) semantics of modality, Montague (1970b, 73)\naccounted for clausal embedding in terms of propositional operators\nwhose extension, like that of their argument, depends on a given point\nin logical space. As it turns out, this so-called ‘neighborhood\nsemantics’ of clausal embedding does without reference to a\nsense hierarchy even in iterated indirect environments\n(ibid., 76), which is why Montague used it as the basis for\nhis general compositional analysis of natural language. Montague\n(ibid., 75f.) still presented his approach as being in line\nwith Frege’s, thereby emphasizing the commonalities in the\noverall architecture of semantic theory, which he identified as\n‘Frege’s functionality principle’: \nMoreover, Montague (1970c, 390) called one of the key constructions of\nhis general theory of reference ‘Fregean interpretation’;\nand in his type-logical hierarchy, intensions are marked by the letter\n‘\\(s\\)’, which is short for ‘sense’\n(ibid., 379). This notation has become quite common in\nlinguistic semantics, although the ‘\\(s\\)’ is frequently\ntaken to stand for possible \\(s\\)ituations! \nOnly at one point in his semantic work did Montague abandon his\nFregean stance: in his essay ‘English as a formal\nlanguage’ (1970a), he employed a one-level architecture of\n‘Russellian’ denotations and expressed his doubts about\nthe cogency of Frege’s motivation for non-propositional senses\n(ibid., sec. 9, remark xi), thereby foreshadowing\nKaplan’s (1975) comparison between the frameworks of Frege 1892\nand Russell 1905. Yet in his ‘Universal Grammar’, Montague\ncommented: \nEven though Montague tended to play down the difference, the switch\nfrom senses to intensions is known to have dramatic consequences on\nthe fine-grainedness of semantic analysis. In particular, as mentioned\nin section 2.4, any two logically equivalent sentences come out as\nhaving the same intension; yet their senses will diverge if their\ntruth value is not determined in the same way. Montague indicated how\nthis unwelcome consequence may be avoided in terms of mismatches\nbetween worlds and contexts, creating what he called\n‘“unactualizable” points of reference’\n(ibid., 382), but he did not provide a detailed analysis to\nsubstantiate his sketchy remarks. \nFor Montague the principle of compositionality did not seem to be a\nsubject of deliberation or discussion, but the only way to proceed. In\neffect he made compositionality the core part of his ‘theory of\nmeaning’ (Montague 1970c, 378), which was later summed up in the\nslogan: ‘Syntax is an algebra, semantics is an algebra, and\nmeaning is a homomorphism between them’ (Janssen 1983, 25). Yet\nalthough Montague used the term ‘Frege’s functionality\nprinciple’ for the way in which extension and intension are\ncompositionally intertwined, he did not have a special term for\ncompositionality in general. Later authors, who identified the\nPrinciple of Compositionality as a cornerstone of Montague’s\nwork, also used the term ‘Frege’s Principle’\n(originating with Cresswell 1973, 75); Thomason 1980 is an early\nsource for the term ‘compositional’. \nIt has been claimed that Montague’s analysis of pronouns is not compositional. This is, however, not the case. In order to\nexplain the compositional nature of his treatment of pronouns, both\nJanssen (1997) and Dowty (2007) explain how variables are interpreted\nin logic; we follow their explanations. Consider the following clauses\nfrom the traditional Tarskian interpretation of predicate logic. \nThe first clause says: \\(\\varphi \\wedge \\psi\\) is true when using\nassignment \\(g\\) if and only if \\(\\varphi\\) and \\(\\psi\\) are true when\nthe assignment \\(g\\) is used. In the second clause assignments \\(h\\)\nare introduced (by \\(\\sim_x g)\\) which are equal to \\(g\\) except maybe\nfor the value they assign to variable \\(x\\). Montague uses the same\nformat, with the difference that besides \\(g\\) he also has \\(i\\), the\ntime of reference and \\(j\\), the possible world, as superscripts. \nIn the formulation of the clauses there is nothing which can be\npointed at as ‘the meaning’, in fact it is a definition of\ntruth with \\(g\\) and \\(h\\) as parameters. So how is it possible that\nthis (and Montague’s work) are compositional? \nThe answer requires a shift in perspective. The meaning of a formula\n\\(\\varphi\\), shortly \\(M(\\varphi)\\), is the set of assignments for\nwhich the formula is true. Then the first clause says that \nso a simple set-theoretic combination on the two meanings is\nperformed. And \ni.e., \\(\\{g \\mid \\text{for some }h \\in\nM(\\varphi), g \\sim_x h \\}\\), which can be described as: extend the set\n\\(M(\\varphi)\\) with all \\(x\\)-variants. (The reference to\n‘\\(x\\)’ may be felt as problematic, but Montague even\neliminated this trace of non-compositionality by assigning appropriate\nmeanings to variables; see Zimmermann and Sternefeld 2013, ch. 10, for\npertinent details.) In general, in Montague semantics the meaning of\nan expression is a function which has as domain the triples\n\\(\\langle\\)moment of time, possible world, assignment to\nvariables\\(\\rangle\\). \nIs it possible to achieve compositionality for natural language?\nObvious candidates for counterexamples are idioms, because their\nmeanings seem not to be built from their constituting words. However,\nWesterståhl (2002) presents a collection of methods, varying\nfrom compound basic expressions, to deviant meanings for constituting\nparts. Janssen (1997) refutes several other counterexamples that are\nput forward in the literature. \nHow strong is compositionality? Mathematical results show that any\nlanguage can be given a compositional semantics, either by using an\nunorthodox syntax (Janssen 1997) or by using an unorthodox semantics\n(Zadrozny 1994). However their proofs are not helpful in practice.\nHodges (2001) showed under which circumstances a given compositional\nsemantics for a fragment can be extended to a larger language. \nThere is no general agreement among formal semanticists about the role\nand status of compositionality; at least the following four positions\nhave been held (nearly the same list is given in Partee 1996): \nAn extensive discussion of compositionality is given in Janssen 1997,\nand in the entry on\n compositionality. \nAccording to Montague, the purpose of syntax is to provide the input\nto semantics: \nAlthough syntax was in his eyes subordinate, he was fully explicit in\nhis rules in which he used some ad hoc syntactic tools. \nIn Montague 1970a and 1970c, the relation between syntactic categories\nand semantic types is given only by a list. Montague (1973) defines a\nsystematic relation which amounts to the same relation as one would\nhave in categorial grammar. However, Montague’s syntax is not a\ncategorial syntax because the rules are not always category driven and\nbecause some of the rules are not concatenation rules. \nFor each of these two aspects, proposals have been put forward to\nchange the situation. One direction was to stay closer to the ideals\nof categorial grammar, with only type-driven rules, sometimes allowing\nfor a restricted extension of the power of concatenation rules (see,\nfor example, Morrill 1994, Carpenter 1998). The other approach was to\nincorporate in Montague grammar as much as possible the insights from\nsyntactic theories, especially originating from the tradition of\nChomsky. A first step was made by Partee (1973), who let the grammar\nproduce structures (labelled bracketings); a syntactically\nsophisticated grammar (with Chomskyan movement rules) was used in the\nRosetta translation project (Rosetta 1994). The influential textbook\nby Heim and Kratzer (1998) combined the two approaches by applying\ntype-driven interpretation to the syntactic level of (Chomskyan)\nLogical Forms. \nIn his syntactic accounts, Montague tended to treat\n‘logical‘ words like determiners (the, a,\nevery) and conjunctions (and, or, not)\nsyncategorematically, i.e., not by means of lexical entries, but as\nthe effect of specific syntactic rules; the reason for this decision\nis unknown, but it may be speculated that it was part of a\ncharacterization of grammatical meaning in terms of logicality,\npresumably along the lines of Tarski’s 1986 invariance\ncriterion. As a consequence, a different rule is needed for John\nwalks and sings than for John walks and Mary sings:\nsyntactically the first one is a conjunction of verb phrases and the\nsecond one of sentences. However, the two meanings of and are\nclosely related and a generalization is missed. As a general solution\nit was proposed to use rules (or alternatively general principles)\nthat change the category of an expression – a change that\ncorresponds with a semantic rule that ‘lifts’ the meaning.\nFor instance, the meaning of and as a connective between verb\nphrases is obtained by lifting the meaning of the sentence connective\n\\(\\wedge\\) to \\(\\lambda P\\lambda Q\\lambda x[P(x) \\wedge Q(x)].\\) The\nline of analysis has been extensively studied in Partee and Rooth\n1983, Partee 1987, Hendriks 2001, and Winter 2001. \nMontague’s method of defining fragments with a fully explicit\nsyntax has become far less popular than it was in the heyday of\nMontague Grammar in the 1980s. Nowadays semanticists prefer to focus\non specific phenomena, suggesting rules which are only explicit\nconcerning the semantic side. This tendency has been criticized by\nPartee in Janssen 1997 and Jacobson 2014, where a fragment is actually\nprovided. \nThe truth conditions of sentences sometimes vary with the context of\nuse. Thus, whether I am happy is true, depends on who the\nspeaker is; other examples include the referents of here and\nthis. Montague (1968; 1970b) addressed these factors,\nindicating that they could be treated by introducing additional\nparameters besides the time and the possible world. Despite occasional\ncritcism (Cresswell 1973, 111; Lewis 1980, 86f.), the treatment of\ncontextual dependence by way of a fixed finite list of parameters has\nbecome quite standard in formal semantics. \nMontague initially treated contextual parameters on a par with times\nand worlds, but in ‘Universal Grammar’ (Montague 1970c) he\nindicated that a distinction should be made between those that\ndetermine the content (which, following Frege 1892, is what is denoted\nin indirect contexts) from those that constitute it: \nWhile these remarks are still a far cry from double-indexing\napproaches to context dependence (Kamp 1971), they do exhibit the\nbasic idea underlying the shiftability criterion for distinguishing\ncontext and index (Lewis 1980). In particular, Montague’s\nmeanings share a core feature with Kaplan’s (1989) characters:\nboth map paramteterized contexts to propositions, understood as\n(characteristic functions of) sets of possible worlds. \nMontague (1970c, 68) followed Bar-Hillel 1954 in treating context\ndependence as part of pragmatics. It was only after his death, that\nhis framework was connected to other aspects of pragmatics. In\nparticular, in early work on Montague grammar, various proposals were\nmade to give compositional characterizations of presuppositions and\n(conventional) implicatures (Peters 1979; Karttunen and Peters 1979),\nbut later treatments were not always completely compositional, taking\nseveral contextual factors into account (Beaver 1997). In a similar\nvein, early work in the tradition was rather optimistic about directly\napplying Montague semantics to non-declarative uses of (declarative)\nsentences (Cresswell 1973), but later accounts had to invoke a lot\nmore than linguistic meaning, including models of interlocutors’\nperspectives (Gunlogson 2003). \nMontague’s semantic analyses were given in terms of a\ntype-logical hierarchy whose basic ingredients were truth values,\npossible individuals, and possible worlds. While the exact nature of\nindividuals and worlds depends on the (arbitrary) choice of a\nparticular model (or ‘Fregean interpretation’), the truth\nvalues 1 (true) and 0 (false) transcend the class of all models, thus\nemphasizing their status as logical objects. A lot of work in current\nlinguistic semantics still applies Montague’s type-logical\nhierarchy, which is however often enriched by events (or,\nmore generally: eventualities) that serve as the referents of\nverbs and verb phrases (Bach 1986a; Parsons 1990). \nIn early work on intensional analysis (Carnap 1947, Kaplan 1964),\npossible worlds had been identified with models of a suitable\nextensional language. For reasons indicated in section 3.1, Montague\n(1969, 164) broke with this tradition, appealing to Kripke’s\naccount of modality based on possible worlds as unstructured basic\nobjects. In his essay ‘On the nature of certain philosophical\nentities’ (Montague 1969), he argued that this seemingly minor\ntechnical innovation opens a new perspective in philosophical\nanalysis, by reducing certain ‘dubious’ entities to\npredicate intensions or properties – functions mapping\npossible worlds to sets of objects. The idea was that, once the\nconceptual and techical problems of the semantics of intensional\nlanguages had been overcome, they may replace extensional predicate\nlogic as a basis of philosophical argument: \nMontague illustrated his claim by detailed analyses of (talk about)\npains, tasks, obligations, and events in terms of second-order\nintensional logic, which contained the core elements of his (slightly)\nlater compositional interpretation of English. \nAlthough it has since become common in linguistic semantics to analyse\ncontent in terms of possible worlds, they are not always taken to be\ntotally devoid of structure. As a case in point, Kratzer (2002) has\nargued that the verb know relates subjects to facts and thus\nits interpretation requires appeal to the mereology of worlds: facts\nare concrete parts worlds. Moreover, as in Kripke’s original\napproach, semantic theory frequently imposes some external structure\non logical space. Thus, accessibility relations and distance measures\nbetween worlds are invoked to account for, respectively, propositional\nattitudes (along the lines of Hinitkka 1969) and counterfactual\nconditionals (following Lewis 1973). In a similar vein, the universe\nof individuals (or ‘entities’, in Montague’s\nparlance) nowadays gives way to a richer domain of structured objects,\nincluding substances and their parts, which may serve as extensions of\nmass nouns such as water (Pelletier & Schubert 2003), as\nwell as groups and their members, which are denoted by plural noun\nphrases (Link 1983). Also when properties (loving John) are\nconsidered as entities for which predicates may hold (Mary likes\nloving John), additional structure is needed: property theory\ngives the tools to incorporate them (Turner 1983). \nOccasional doubts have been raised as to the adequacy of\nMontague’s higher-order intensional logic as a tool for the\nsemantic interpretation of natural language: \nThis objection does not appreciate the role played by higher-order\nabstraction in compositional semantics, which is not to form sentences\nabout higher-order functions. Rather, \\(\\lambda\\)-abstraction is used\nas a heuristic tool to describe compositional contributions of\nexpressions to larger syntactic environments (cf. Zimmermann 2021,\nsec. 2.1). Thus, e.g., the extension of a determiner is defined as its\ncontribution to the truth value of a sentence in which it occurs (in\nsubject position), which can be described in terms of the extensions\nof the nouns and verb phrases it combines with – and these\nextensions are themselves sets (by a similar reasoning). The abstract\nhigher-order objects are thus merely convenient ways of describing the\nkinematics of compositionality and do not serve as the objects that\nthe sentences of the language so described are about, or that its\nterms refer to. As a case in point, it can be shown that even though\nthe (indirect) interpretation of the English fragment of Montague 1973\nmakes use of \\(\\lambda\\)-abstraction over second-order variables, its\nexpressive power is much weaker than higher-order type logic and does\nnot even have the resources to formulate certain meaning postulates to\nwhich its lexical items abide (Zimmermann 1983). In fact,\nHintikka’s alternative (game-theoretical) semantics fares no\nbetter once it is formulated in a compositional way (see Hodges 1997\nor Caicedo et al. 2009). \nMontague revolutionized the field of semantic theory. He introduced\nmethods and tools from mathematical logic, and set standards for\nexplicitness in semantics. Now all semanticists know that logic has\nmore to offer than first-order logic only. \nA recent introduction is Jacobson 2014. It is a gentle introduction to\nthe field, especially for linguists and philosophers. It presents\nseveral successes obtained by the approach. Older introductions are\nDowty et al. 1981 and Gamut 1991, which are more technical\nand prepare for Montague’s original papers. An overview of the\nhistory of the field is given by Partee and Hendriks (1997) as well as\nPartee (2011); Caponigro (forthcoming) provides an extensive\nbiographical background on Montague. Collections of important papers\nare Portner and Partee (eds.) 2002 and Partee 2004; further\ninformation is provided in the volume edited by McNally and\nSzabó (forthcoming). The ‘Handbook of\ncompositionality’(Werning et al. 2011) discusses many aspects of\nthe approach. The most important journals in the field are\nLinguistics and Philosophy, the Journal of\nSemantics, Natural Language Semantics, and Semantics\nand Pragmatics. \nA small example is presented below, it consists of the two sentences\nJohn is singing, and Every man is singing. The\nexample is not presented in Montague’s original way, but\nmodernized: there is a lifting rule, the determiner is a basic\nexpression, and intensional aspects are not considered. \nThe grammar has four basic expressions: \nThe grammar has three rules. \nThe example given with the last rule helps us to understand the\nformula for every : that denotes a relation between\nproperties \\(A\\) and \\(B\\) which holds in case every \\(A\\) has\nproperty \\(B\\). \nThe next step is now easy. Apply the rule for combining a Noun Phrase\nand an Intransitive Verb to the last result, producing Every man\nis singing. The output of the semantic rule is \\(\\lambda Q\\forall\nx[\\textbf{man}(x) \\rightarrow Q(x)](\\textbf{sing})\\). By lambda\nconversion we obtain \\(\\forall x[\\textbf{man}(x) \\rightarrow\n\\textbf{sing}(x)],\\) which is the traditional logical representation\nof Every man is singing. \nNote the role of lambda-operators:","contact.mail":"T.E.Zimmermann@lingua.uni-frankfurt.de","contact.domain":"lingua.uni-frankfurt.de"}]
