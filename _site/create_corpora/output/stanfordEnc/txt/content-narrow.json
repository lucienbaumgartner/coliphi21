[{"date.published":"2002-11-20","date.changed":"2016-06-08","url":"https://plato.stanford.edu/entries/content-narrow/","author1":"Curtis Brown","author1.info":"http://www.trinity.edu/cbrown/","entry":"content-narrow","body.text":"\n\n\n\nNarrow mental content is a kind of mental content that does not\ndepend on an individual's environment. Narrow content contrasts with\n“broad” or “wide” content, which depends on\nfeatures of the individual's environment as well as on features of the\nindividual. It is controversial whether there is any such thing as\nnarrow content. Assuming that there is, it is also controversial what\nsort of content it is, what its relation to ordinary or\n“broad” content is, and how it is determined by the\nindividual's intrinsic properties.\n\n\n\nWhat is narrow mental content? Mental content simply means\nthe content of a mental state such as a thought, a belief, a desire, a\nfear, an intention, or a wish. Content is a deliberately vague\nterm; it is a rough synonym of another vague term,\n‘meaning’. A state with content is a state that\nrepresents some part or aspect of the world; its content is\nthe way it represents the world as being. For example, consider my\nbelief that water is a liquid at room temperature. The content of this\nbelief is what it says about the world, namely that a certain\nsubstance, water, has a certain property, being a liquid, under\nspecified conditions, namely being at room temperature. Whether a\nbelief is true or false depends on its content: it is true if the world\nreally is the way the belief represents it as being; otherwise it is\nfalse. \n\nA narrow content of a particular state is a content of\nthat state that is completely determined by the individual's intrinsic\nproperties. An intrinsic property of an individual is a\nproperty that does not depend at all on the individual's environment.\nFor example, having a certain shape is, arguably, an intrinsic property\nof a particular penny; being in my pocket is not an intrinsic property\nof the penny. This is because the penny's shape depends only on\ninternal properties of the penny, whereas the fact that it is in my\npocket depends on where it happens to be, which is an extrinsic\nproperty. The shape of the penny could not be different unless the\npenny itself were different in some way, but the penny could be exactly\nthe way it is even if it were not in my pocket. Again, there could not\nbe an exact duplicate of the penny that did not share its shape, but\nthere could be an exact duplicate that was not in my pocket. Similarly,\na narrow content of a belief or other mental state is a content that\ncould not be different unless the subject who has the state were\ndifferent in some intrinsic respect: no matter how different the\nindividual's environment were, the belief would have the same content\nit actually does. Again, a narrow content of an individual's belief is\na content that must be shared by any exact duplicate of the individual.\n(If some form of dualism is true, then the intrinsic properties of an\nindividual may include properties that are not completely determined by\nthe individual's physical properties. In that case an “exact\nduplicate” must be understood to be an individual who shares all\nintrinsic nonphysical properties as well as physical ones.) \n(The notion of an intrinsic property turns out to be surprisingly\ndifficult to define precisely. A good guide to the various approaches\nthat have been taken, and their difficulties and refinements, is the\nentry on\n intrinsic vs. extrinsic properties.) \n\nOn first encounter, it may seem strange that the idea of narrow\ncontent should be controversial, or even that we should need a special\nterm for it. Most people, if they were ever to explicitly consider the\nissue of whether mental content is narrow or broad, would probably hold\nthat all mental content is narrow, i.e. that all of the contents of our\nmental states are entirely determined by our intrinsic properties. It\nseems conceivable, for example, as Descartes argued in his First\nMeditation, that our perceptual states and beliefs could be exactly as\nthey are even if the world were nothing like we think it is. This seems\nto presuppose that no difference in our environment, however radical,\ncould make a difference to the contents of our beliefs so long as our\nintrinsic properties remained the same. \n\nWhy, then, have philosophers believed they need to define narrow\ncontent and argue for its existence? The reason is that many\nphilosophers have been convinced by some influential arguments that, in\nthe most ordinary or typical sense of ‘content’, most or\neven all of the contents of our mental states are broad rather than\nnarrow. If this conclusion is correct, if ordinary content is broad,\nthen it requires some work to define an alternative, narrow conception\nof content, and it requires arguments to show that there is any such\nthing. To understand the issues about narrow content, then, it is\nessential to first understand the arguments that most ordinary content\nis broad. \n\nAmong the earliest and most influential arguments for broad content\nwere Hilary Putnam's arguments in such essays as “The Meaning of\n‘Meaning’” (1975). Putnam's arguments were not\ndesigned specifically with mental content in mind. They\napplied in the first instance to linguistic content, more\nspecifically to the reference of terms in a natural language. However,\nthey have been widely applied to mental content. I will first discuss\nPutnam's argument concerning linguistic content, and then note how it\ncan be extended to mental content. \n\nPutnam's most famous examples involve “Twin Earth,” an\nimaginary planet which is molecule-for-molecule identical to Earth,\nincluding having exact duplicates of Earth's inhabitants,\nexcept for a systematic change in certain parts of the\nnatural environment. In a particularly well-known version of this\nexample, we consider Earth as it was around 1750, before the chemical\nstructure of water was discovered, and we consider an inhabitant of\nEarth named “Oscar” who is a competent user of the term\n‘water’. We then imagine a Twin Earth which is exactly\nlike Earth in every way, including having an exact duplicate of Oscar,\nwith one exception: for every place on Earth that contains\nH2O, the Twin Earthly duplicate of that place instead\ncontains XYZ, a substance with a different microstructure from water\nbut with similar observable properties. On Twin Earth, it is XYZ, not\nH2O, that falls from the skies and fills the lakes and\noceans. \n\nPutnam argues that the stuff that falls from the skies and fills the\nlakes on Twin Earth is not water. According to Putnam, when\npeople used the term ‘water’, even in 1750, they intended\nto refer to a natural kind, a kind of thing whose instances\nshare a common nature, not directly observable, which explains the\nobservable properties of instances of the kind. They identified water\nby observable characteristics like colorlessness and odorlessness, but they\nalso assumed that there was a microstructure which explains these\nobservable properties. Since 1750, we have learned what this\nmicrostructure is, namely that water consists of molecules of\nH2O. But water was H2O even in 1750,\nbefore we learned this. (Other natural kind terms work in the same way.\nFor instance, we identify diseases by their symptoms, but we assume\nthat there is an underlying cause of these symptoms, for example a\nparticular microorganism, and that even before we know what this\nunderlying cause is, it makes the disease what it is.) \n\nNow Twin Oscar, being an exact duplicate of Earth's Oscar, will have\nmany of the same properties Oscar has. For instance, he will be\ndisposed to accept a sentence of Twin English that is written and\npronounced exactly like the English sentence “Water is\nwet.” However, Putnam argues, Twin Oscar's word ‘water’ does\nnot refer to water. There is no water on Twin Earth,\nonly XYZ; Twin Oscar has never seen water, talked about water, or\ninteracted with water in any way. So it seems that he cannot possibly\nrefer to water. \n\n(Two points should be made parenthetically about this example. (1)\nThe observable properties of XYZ do not need to be identical\nto those of water; all that is needed is that Oscar and Twin Oscar have\nnot observed the differences. (2) In some ways it is unfortunate that\nthe water/XYZ example has become Putnam's best known example, because\nit has a failing that many of his other examples lack, namely that most\nof the human body consists of water. This has the consequence that Twin\nOscar cannot be an exact duplicate of Oscar unless Twin Oscar also\nconsists largely of water. Other examples Putnam considers involve\nswitching aluminum and molybdenum, beeches and elms, diseases, and so\non, and these examples do not suffer from the same problem.) \n\nIt is important for this example that, although 1750 residents of\nEarth did not yet realize this, all water was in fact H2O.\nHad it turned out instead that some of the stuff called\n“water” was H2O while other stuff called\n“water” was XYZ, then water would not have turned out to be\na single “natural kind.” In that case the English word\n“water” would refer to anything that was either\nH2O or XYZ, and we could say that the Earthly and\nTwin-Earthly ‘water’-words referred to the same thing.\nAgain, if it had turned out that there were a huge number of different\nmicrostructures that produced the observable properties of water, then\nwater would not have been a natural kind at all. In that case we would\nprobably say that anything with the right observable properties was\nwater, and in that case again we could say both\n‘water’-words were coreferential. In fact, though, neither\nof these possibilities obtains. Water is a natural kind whose essential\nnature is that it has the chemical structure H2O; since\nthere is no H2O on Twin Earth, there is no water there. Twin\nEarthlings never had occasion to give a label to water, since there is\nnone on their planet, so their word “water” does not refer\nto water. \n\nSince Oscar and Twin Oscar have exactly the same intrinsic\nproperties, yet refer to different substances when they use their\n‘water’-words, their intrinsic properties cannot suffice to\ndetermine what they refer to. If the meaning of a word suffices to\ndetermine its reference, then meaning cannot be determined by intrinsic\nproperties either. As Putnam famously puts it,\n“‘meanings’ just ain't in the head!”\n(1975, p. 227). \n\nAlthough the argument as presented so far concerns the reference of\n‘water’ and other natural kind terms, it is natural to\nextend it to mental content as well (McGinn 1977; Burge 1979, note 2).\nNot only does Twin Oscar not refer to water when he uses the term\n‘water’, he does not have beliefs about water either. To be\nsure, he has beliefs that play the same role in his mental life that\nOscar's water-beliefs play in his. But in Twin Oscar's case, those\nbeliefs are not about water. In particular, while Oscar believes that\nwater is wet, Twin Oscar does not. Since Oscar and Twin Oscar have\nidentical intrinsic properties, yet Oscar believes that water is wet\nwhile Twin Oscar does not, mental content cannot be determined solely\nby intrinsic properties. \n\nThe second main source of arguments that ordinary mental content is\nbroad is a series of influential articles by Tyler Burge, including\n“Individualism and the Mental” (1979). Burge has offered\nseveral lines of argument for the externalist view he calls\n“anti-individualism.” These are helpfully distinguished\nand described in the Introduction to Burge 2007. One line of argument,\nclosely related to Putnam's water example, emphasizes the role of the\nenvironment in thought about natural kinds. Another line of argument\ndefends anti-individualism about perceptual content. I will consider a\nthird much-discussed line of argument, which relies on the fact that\nin many cases we intend what we are thinking or talking about to\ndepend to some extent on the beliefs of others in our community,\nespecially those more expert than we. \n\nBurge's most famous example involves the concept of arthritis. He\nconsiders an individual who is unaware that arthritis is a disease\nspecifically of the joints. His subject believes that he has arthritis\nin his thigh. This belief is false, since one cannot have arthritis in\nthe thigh. However, Burge argues, in a world in which all the\nintrinsic facts about the subject were exactly the same as they\nactually are, but in which the term ‘arthritis’ is\ngenerally used in the subject's community to refer to rheumatoid\nailments in general, the subject's belief would have a different\ncontent. It would be a belief that the subject had a rheumatoid\nailment in the thigh, and this is a belief which could possibly be\ntrue. Burge offers a wide variety of other examples making the same\npoint, involving beliefs about such things as sofas and\ncontracts. These latter examples are important because, if successful,\nthey show that broad content extends far beyond beliefs about natural\nkinds. \n\nThe idea that mental content is broad is the idea that it is not\ndetermined entirely by an individual's intrinsic properties, but is\ndetermined in part by features of the individual's environment. But if\nthe content of my beliefs is not determined entirely by my internal\nstates, what else could determine it? How could anything other than my\nintrinsic properties determine what I think and believe? The examples\njust discussed point to two different sorts of environmental\nfactor. Putnam's example of Oscar and his Twin Earth duplicate focuses\non the contribution of the natural environment. The crucial\nidea here is that when we have thoughts or beliefs about natural\nkinds, we often do not know what the essential features of those kinds\nare, even though we assume that there are such essential features. In\nsuch cases, what we are thinking about depends not only on internally\navailable factors, but also on facts about the physical, chemical, or\nbiological makeup of the kinds we are thinking about. Burge's\narthritis example, by contrast, focuses on the contribution of\nthe social environment. In our thoughts about many kinds of\nthings, including natural kinds but also including kinds invented by\nhumans, such as furniture or contracts, we assume that others may have\nmore expertise than we do about what is and what is not included in\nthe kind in question. Thus, what we are thinking about depends not\nonly on our intrinsic properties, but also on expert\nopinion. We defer to the experts with regard to what exactly\nwe are thinking about. For this reason, this sort of contribution of\nthe social environment is sometimes referred to as “semantic\ndeference.” \n\nThe phenomenon of semantic deference is closely related to what\nPutnam memorably termed “the linguistic division of labor.”\nPutnam's idea was that as long as there are experts on what certain\nwords refer to, we do not all need to have that specialized knowledge;\nwe can rely on the knowledge of the experts. In Burge's treatment,\nhowever, the phenomenon is not merely linguistic: it is not just that\nwe defer to the experts on the meaning of the word\n‘arthritis’; we also defer to the experts on the nature of\nthe disease arthritis. Thus, for Burge, the phenomenon affects\nnot only what we mean by the words we use, but also the very contents\nof our thoughts. \n\nWe can distinguish between three broad categories of response to the\nexamples of Putnam and Burge. On one extreme, to use the terminology of\nSegal (2000), we have the unqualified acceptance of the extreme\nexternalist. Many philosophers have been persuaded by examples\nlike those of Putnam and Burge that all or nearly all mental\ncontent is broad. Such philosophers are highly skeptical about the\nusefulness of any notion of narrow content. Burge himself is a\nnoteworthy proponent of extreme externalism; other extreme externalists\ninclude Robert Stalnaker (1989, 1990, 2008) and Robert A. Wilson (1995). \n\nA second response takes us to the opposite extreme, extreme\ninternalism. According to this response, Putnam's and Burge's\nexamples do not succeed in showing that any content is\nbroad. This position has been defended by, among others, Kent Bach\n(1987), Tim Crane (1991), and Gabriel Segal (2000). These authors\nquestion the externalist interpretation of the examples we have\ndiscussed. For example, in response to Putnam, Segal points out that\nwe have some empty natural kind concepts — that is, we\nhave concepts which we intend to be natural kind concepts, but which\nin fact do not succeed in referring to a real kind. Possible examples\ninclude the concepts of witches, ghosts, and phlogiston. In these\nexamples, the environment cannot make the sort of contribution\ndiscussed by Putnam, because the environment contains no relevant\nkind. Nevertheless, people who have them use these concepts in their\nreasoning, and their behavior is partly explained by these\nconcepts. If so, then we can have natural kind concepts that do not\nhave an environmental component. Now, it seems that with respect to\nexplanations of our reasoning and action, it does not make a\ndifference whether the kinds we think we are reasoning about actually\nexist: so long as we think they exist, we will make the same\ninferences and perform the same actions regardless of whether we are\ncorrect or not. This may lead us to suspect that even in the case of\nnon-empty natural kind concepts, our reasoning and action are best\nexplained in terms of concepts whose content is not environmentally\ndetermined — in short, in terms of concepts whose content is\nnarrow. \n\nWith respect to Burge's examples, Segal suggests that it is odd to\nregard someone who thinks it possible to have arthritis in the thigh\nas having the concept of arthritis at all. Arthritis just is\nan inflammation of the joints; it seems peculiar to say that someone\nwho does not realize this has the concept of arthritis. Instead, we\nshould say that the subject in Burge's example has a\ndifferent concept, a concept he mistakenly associates with\nthe English word ‘arthritis’. Thus we might want to deny\nthat Burge's subject really believes he has arthritis in his thigh.\nWhat he really believes is something it is hard to express in English,\nsince we do not have a word that applies to all and only the cases he\nwould regard as cases of arthritis. \n\n(Segal takes these arguments to undermine the idea that Putnam's and\nBurge's examples establish that thoughts and beliefs about kinds have\nonly broad contents. He does not take them to refute\n“two-factor” theories according to which beliefs have both\nbroad and narrow contents, although he does offer additional arguments\nspecifically targeted against two-factor theories.) \n\nAlthough extreme internalists advocate narrow content, they also\nhold that ordinary content is already narrow, so that we do not need a\nspecial or technical notion of narrow content. Thus, much of the\nliterature in favor of narrow content is written by those who accept\nthe third response to Putnam's and Burge's arguments, moderate\ninternalism (which we could equally well call “moderate\nexternalism,” since it is a compromise between the two extreme\nviews). This is the view that, while Putnam's and Burge's examples do\nshow that ordinary content is broad, there are also contents\nthat are narrow. On a moderate internalist view, many beliefs have both\nbroad and narrow contents. Since, on this view, ordinary content is\noften broad, we need a distinctive, specialized notion of narrow\ncontent as different in some way from ordinary content. \n\nWhy do moderate internalists believe that, despite the success of\narguments that ordinary content is often or always broad, we\nnevertheless need a notion of narrow content? There are four main\nkinds of arguments they have found persuasive. \n\nOne influential argument for narrow content (Fodor 1987; a recent \ndefense of this kind of argument, with repies to criticisms, is \nGaukroger, forthcoming) appeals to\nconsiderations involving causal explanation. We might outline the\nargument like this. A first premise is that mental states causally\nexplain behavior by virtue of the content they have. Although this has\nbeen denied by some, it certainly seems to be a central part of\ncommonsense psychology. Our behavior seems to be a causal consequence\nof our beliefs and desires; moreover, the content of those beliefs and\ndesires seems to be centrally involved in the causation of behavior. We\nbehave the way we do because of what we want and what we believe, and\nthis seems to be just another way of saying that we behave as we do\nbecause of the contents of our beliefs and desires. A second premise is\nthat the causal powers of an entity, its capacity to produce effects,\nmust be intrinsic features of the entity. Thus twins, who share all\ntheir intrinsic properties, must share their causal powers. This\npremise seems plausible for at least two reasons. First, causation is\nlocal. It seems that features of the environment can affect an\nindividual's actions only by way of effects on the individual's\nintrinsic properties. Second, causal powers should be evaluated across\ncontexts. If an astronaut on the Moon can easily lift a\none-hundred-kilogram weight and I, on Earth, cannot, this does not mean that the\nastronaut is stronger; the crucial issue is whether the astronaut can\nlift more than I can in the same environments. This appears to show\nthat my Twin Earth counterpart and I have the same causal powers even\nthough I can obtain water by turning on the faucet and he cannot, since\nour parallel actions will achieve parallel results provided that our\nenvironments are the same. A third and final premise is that broad\ncontent does not characterize intrinsic features, at least not\nessentially; thus twins need not share broad contents. According to the\nfirst premise, mental states must have a kind of content that causally\nexplains behavior. Taken together, the second and third premises show\nthat broad content cannot fulfill this role. The conclusion of the\nargument, then, is that mental states must have narrow contents,\ncontents that are shared between twins. \n\nExternalists have attacked this argument at its second premise, the\npremise that causal powers must be intrinsic properties. Against the\nargument that causal powers must be intrinsic because causation is\nlocal, Burge (1986, 1989) has argued that local causation is\nentirely compatible with broad individuation. Against the\nargument that the cross-context test for sameness of causal powers\nshows that they are intrinsic, Burge (1989) suggests that causal powers\nare typically identified relative to a normal environment; thus, for\nexample, it would be reasonable to distinguish between a heart and a\nsimilar organ whose function is to pump waste even if one of these\norgans could be successfully surgically replaced by the other. Burge\n(1986) also argues that actual psychological theories, such as Marr's\ntheory of vision, do not satisfy internalist constraints. (For\ncriticisms of Burge's interpretation of Marr, see Segal 1989 and Egan\n1991. Burge 2010 is a book-length defense of the claim that perceptual\npsychology is anti-individualistic.) \n\nIn a later essay (Fodor 1991), Fodor defends a weaker and more\ncomplicated version of the second premise. He suggests that there are\nsome extrinsic properties, such as being a planet, that affect\ncausal powers, and others, like being part of a universe in which a\ncertain coin toss comes out heads, that are irrelevant to causal\npowers. He then offers a criterion for distinguishing between causally\nrelevant extrinsic properties and causally irrelevant extrinsic\nproperties: roughly, an extrinsic property is causally irrelevant to\noutcomes that it is logically connected to. He then argues that broad\ncontent does not satisfy the criterion for being a causally relevant\nextrinsic property. (It should be noted that in still more recent work\n(Fodor 1994), Fodor has abandoned the idea that narrow content is\nimportant for psychology.) \n\nA somewhat different motivation for narrow content (Loar 1988)\nappeals to the idea that we have introspective access to the contents\nof our own thoughts. In particular, it seems that we should be able to\ndetermine introspectively whether two of our thoughts have the same\ncontent or not. But the kind of difference in content that\ndistinguishes Oscar's thoughts from Twin Oscar's thoughts seems to be\nthe sort of difference that they could not in principle be\nintrospectively aware of. From the inside, so to speak, there is no way\nfor Oscar and Twin Oscar to tell whether they are thinking XYZ-thoughts\nor H2O-thoughts. (Recall that they are unaware of what the\nmicrostructure of the substance they call “water” is,\nalthough they assume that it has one.) The difference in broad content\nbetween the beliefs of Oscar and Twin Oscar seems to be a difference to\nwhich they themselves have no access. \n\nIt is difficult to formulate this point precisely, however. For\ninstance, Oscar can think that water is wet and then think the\nmeta-level thought, “that thought I just had was about\nwater!”, referring thereby to H2O and thus\nexpressing the very aspect of his original thought which distinguishes\nhis content from Twin Oscar's. Since neither Oscar nor Twin Oscar has\nthoughts about the substance his twin has thoughts about, it is not\nclear what it means to say that they cannot introspectively distinguish\nbetween these different thoughts. One way to try to clarify and\nreinforce the argument is to consider the phenomenon of “slow\nswitching” (introduced in Burge 1988, and used by Boghossian 1989 to pose difficulties for self-knowledge). Suppose Oscar moves to Twin Earth.\nInitially his water-thoughts will continue to be about water, but it\nseems that gradually, the longer he interacts with XYZ and the longer\nhe is out of touch with H2O, his thoughts will come to be\nabout XYZ rather than H2O. If this is correct, then his\n‘water’-thoughts will have come over time to have a\ndifferent broad content than they previously had. However, this change\nin content will be completely invisible to Oscar himself. From his own\nsubjective point of view, his thoughts appear to have exactly the same\ncontent as before. If there is a kind of mental content to which we\nhave introspective access, and if introspective access must include the\nability to recognize when contents are the same or different, then the\nsort of content to which we have introspective access cannot be broad\ncontent. This suggests that we need a concept of narrow content to\ncapture the kind of content that we are immediately aware of. \n\nBurge's response to this sort of argument is to accept that we have\nintrospective knowledge of the contents of our own thoughts, but deny\nthat this entails that we can tell introspectively whether two contents\nare the same or different (Burge 1988). In response, some suggest that\nknowing that my thought is about water requires ruling out relevant\nalternative possibilities, and that in slow switching cases the\npossibility that my thought is instead about XYZ is in fact a relevant\nalternative that we cannot rule out. (For further dialectical twists\nand turns, see Ludlow and Martin 1998, and Nuccetelli 2003.) \n\nA related issue is that describing a subject's beliefs in terms of\nbroad content can make them appear irrational even\nthough they are not: when beliefs are described in terms of broad\ncontent, they can be inconsistent with one another even though the\ninconsistency is in principle not discoverable by the subject. A famous\nexample is due to Saul Kripke (1979). In Kripke's example, Pierre, a\nFrenchman, grows up with a belief he expresses by saying “Londres\nest jolie.” This belief has the (broad) content that London is\npretty. Later he moves to England, where he learns English by immersion\nrather than by translation. He comes to have a second belief, which he\nexpresses in English by saying “London is not pretty.” This\nbelief has the broad content that London is not pretty. Pierre never\nrealizes that the city he thinks of as Londres and the city he thinks\nof as London are in fact the same city. His two beliefs directly\ncontradict one another, and yet he is not guilty of any sort of failure\nof rationality; it is impossible for him to ascertain that the two\nbeliefs are contradictory. Kripke himself does not offer a solution to\nhis puzzle and does not discuss narrow content. But a natural response\nto the example is to suppose that, while the belief Pierre accepts and\nthe one he rejects have the same broad content, they have different\nnarrow contents. If so, then the sort of content most relevant to\ndetermining whether someone's beliefs and inferences are rational is\nnot broad content but narrow content. \n\nOne response to this sort of argument is offered by Stalnaker (1990)\nin a critique of Loar (1988). Stalnaker agrees that examples like that\nof Pierre require us to distinguish between the world as it is\naccording to Pierre, on the one hand, and, on the other hand, the\npropositions ordinarily expressed by the sentences we use to describe\nthose beliefs, e.g. the proposition that London is pretty. However, in\nhis view it does not follow that an accurate description of the world\naccording to Pierre must be narrow: “I don't think the belief\nstates themselves — the ways the world is according to the\nthinker — are any less causally and socially infected than the\nlanguage in which beliefs are ascribed” (p. 203). Jackson (2003)\nresponds to Stalnaker's reasons for skepticism about narrow\ncontent. \n\nA recent argument for the existence of narrow content is an argument\nfrom phenomenal intentionality (Loar 2003; Horgan and Tienson 2002;\nHorgan, Tienson and Graham 2004; Kriegel 2013). To\nunderstand this argument, we first need to understand what its\nproponents mean by “phenomenal intentionality.”\nPhilosophers of mind have traditionally drawn a sharp distinction\nbetween two sorts of properties of mental states, phenomenal\nproperties and intentional properties. Phenomenal properties have to\ndo with the felt character of conscious experience, with “what\nit's like,” in Thomas Nagel's famous phrase (Nagel\n1974). Intentional properties have to do with the representational\ncharacter of mental states, i.e. with their content. One view of the\nrelation between phenomenal and intentional properties, called\n“separatism” by Horgan and Tienson (2002), is that they\nare independent of one another: any given phenomenal character could\nbe accompanied by any intentional properties (or none), and vice\nversa. According to Lycan (2008 §9), this view was “the\nstandard attitude among philosophers of mind between the 1950s and the\n1980s.” On another view of the relation between the intentional\nand the phenomenal, known as representationalism, the phenomenal\ncharacter of experience is completely determined by its intentional\nnature. The key thesis of phenomenal intentionality is that, while\nrepresentationalism is correct that there is an intimate connection\nbetween phenomenology and intentionality, the determination runs in\nthe opposite direction: there is a kind of intentional content,\nphenomenal intentionality, which is entirely constitutively determined\nby the phenomenal character of a mental state.  \n\nThis thesis is one premise of the argument from phenomenal\nintentionality to narrow content. The other premise is that the\nphenomenal character of experience is itself narrow. Putting the two\npremises together, we get the following argument for the existence of\nnarrow content: “(1) There is pervasive intentional content that\nconstitutively depends on phenomenology alone. (2) Phenomenology\nconstitutively depends only on narrow factors. So, (3) There is\npervasive intentional content that constitutively depends only on\nnarrow factors” (Horgan and Tienson 2002, p. 527; cf. Horgan,\nTienson and Graham 2004, p. 300). \n\nBoth premises of this argument are controversial. The second premise,\nthat phenomenology is narrow, is rejected by phenomenal externalists\n(Lycan 2008, §14), while the controversial character of the first\npremise, that there is intentional content that is entirely determined\nby phenomenology, can be seen in the fact that its proponents have\nadvanced it as a departure from orthodoxy. Defenders of phenomenal\nintentionality have supported both premises by appeal to brain-in-vat\nscenarios. Suppose that alien beings synthesize a structure identical\nto your own brain, and connect it to a computer-controlled apparatus\nthat provides inputs to this brain-like object which maintain its\nsimilarity to your brain over a substantial period of time. (See\nHorgan, Tienson and Graham 2004 for further details. This fairly\nelaborate brain-in-vat scenario avoids some of Burge's objections\n(Burge 2003, pp. 443–445) to Loar's less-fully-described version (Loar\n2003).) Defenders of phenomenal intentionality find it intuitively\nplausible that by virtue of its physical similarity with your brain,\nthe brain-like object will also share your phenomenology, supporting\nthe narrowness of phenomenology; and that the brain-like object will,\nby virtue of sharing your phenomenology, also share many of the\ncontents of your mental states, supporting the existence of\nphenomenally-determined intentionality. (For these two uses of the\nbrain-in-vat scenario, see Horgan, Tienson and Graham 2004,\np. 302. For additional arguments for the existence of phenomenal\nintentionality, see Kriegel 2013, §2.1.\nCriticisms of phenomenal intentionality may be found in Bailey and\nRichards 2014 and Werner 2015.) \n\nThe most immediately plausible purported example of phenomenal\nintentionality is the content of perceptual experience. If perceptual\nexperience is a genuine example of phenomenally determined\nintentionality, but also the only example, then the argument from\nphenomenal intentionality would show the existence of narrow contents\nof perceptual states, but would be silent on whether other mental\nstates such as beliefs and desires have narrow contents. However, some\ndefenders of phenomenal intentionality (e.g. Horgan, Tienson and\nGraham 2004 and several of the contributors to Bayne and Montague 2011) \nwould go further, arguing that there are distinctive\nphenomenologies of agency and of propositional attitudes including\nbeliefs and desires; that the phenomenal properties of these mental\nstates also constitutively determine intentional properties; and\nmoreover that all intentionality either is identical with, or\nis derived from, phenomenal intentionality. If these bolder theses are\ncorrect, then the argument from phenomenal intentionality would give\nreason to think that all of the propositional attitudes have narrow\ncontents, and that their wide contents, if any, are derived from these\nnarrow contents. \n\nSupposing that there is a sort of content of at least some mental\nstates that is narrow, how should we conceive of it? What sort of thing\nis narrow content? There are many different proposals in the literature\n(although in some cases the differences between them may not be as\ngreat as they first appear). We consider several. \n\nPerhaps the most obvious suggestion is that the narrow content of a\nparticular belief can be understood as a more detailed description of\nwhat is believed. More specifically, the idea is that the narrow\ncontent of a particular concept is a description of what the concept\nexpresses or refers to. \n\nAn example will make this idea clearer. Consider Oscar, who believes\nthat water is wet. This belief involves the concept of water, and\narguments like Putnam's appear to show that the ordinary content of\nthis concept is broad. The proposal we are considering is that there is\na more detailed description that captures the narrow content, for\nOscar, of the concept of water. This description might be something\nlike “clear, colorless, odorless liquid that falls from the sky\nand fills the lakes.” Oscar and his Twin may share this\ndescriptive content even though their ‘water’-concepts do\nnot have the same broad content. The suggestion, then, is that, when\nOscar thinks the thought that he would express by saying “water\nis wet,” and when Twin Oscar thinks the thought that he would\nexpress by saying, in Twin English, “water is wet,” both of\nthem are expressing a thought with the descriptive content “the\nclear, colorless, odorless liquid that falls from the sky and fills the\nlakes is wet.” This narrow content, the proposal continues,\ndetermines, on Twin Earth, the broad content that XYZ is wet, while on\nEarth it determines the broad content that water (i.e. H2O)\nis wet. \n\nNotice that if this description is to succeed in determining the\nappropriate broad content on Earth and on Twin Earth, then it must have\na subtle “indexical” component. An indexical is a term,\nlike ‘I’ or ‘now’, whose referent is\ncontext-relative. The referent of ‘I’ depends on who utters\nor thinks it; the referent of ‘now’ depends on the time at\nwhich it is uttered or thought. The supposedly narrow content\n“colorless odorless liquid that falls from the sky and fills the\nlakes” must have an implicit indexical component: the content in\nquestion is really something like “the colorless, odorless liquid\nthat falls from the sky and fills the lakes around here”\n(Putnam 1975, p. 234). \n\nThere is an obvious and serious problem with the proposal that\nnarrow content is descriptive content, however. The problem is simply\nthat the description which is intended to give the narrow content of a\nconcept such as Oscar's ‘water’-concept may itself be broad\n(Lepore and Loewer, 1986; Taylor, 1989). In my example, several of the\nconcepts involved in the descriptive content arguably have broad\ncontents. The notion of a liquid has a technical meaning that need not\ncorrespond to the observable properties we associate with it. And\nperhaps concepts like those of sky, lake, and color are also broad. \n\nThis objection need not be entirely crushing, but it certainly makes\nthe descriptive content approach more difficult to spell out in detail.\nIf we specify the description that is supposed to capture a narrow\ncontent in ordinary language, then we will need to use only\nordinary-language terms that do not have broad contents. If the moral\nof the arguments for broad content is as sweeping as philosophers like\nBurge believe, it may be difficult or impossible to find enough\nordinary-language expressions that satisfy this requirement. We could\nregard the description we have been discussing as a first step; the\nsecond step would be to replace the expressions \n‘liquid’,\n‘sky’, ‘lake’, and so on with their own\ndescriptive contents. But these descriptions in turn might well contain\nexpressions with broad contents, which would then need to be replaced\nwith still further descriptions. It is not clear that we will be able\nto find enough purely narrow expressions to do all the descriptive work\nwe need. (Mendola 2008 is a recent attempt to develop a detailed version \nof the descriptive approach that can overcome such worries.) \n\nA second approach to narrow content identifies narrow contents with\n“conceptual roles.” This approach was laid out in a\nprogrammatic way by Ned Block in his essay “Advertisement for a\nSemantics for Psychology” (Block 1986). The general idea is that\nthe conceptual role of a particular state is a matter of its causal\nrelations to other states. As Block puts it, conceptual role “is\na matter of the causal role of the expression in reasoning and\ndeliberation and, in general, in the way the expression combines and\ninteracts with other expressions so as to mediate between sensory\ninputs and behavioral outputs” (p. 93). However, conceptual role\nshould not be understood to include all the causal relations\nbetween a given state and other states: “Conceptual role\nabstracts away from all causal relations except the ones that mediate\ninferences, inductive or deductive, decision making, and the\nlike” (p. 94). \n\nThe easiest way to get a feeling for conceptual role semantics is to\nconsider the kind of example that it seems to fit most naturally.\nSuppose that we have a mental representation we will symbolize as\n‘*’. Suppose further that ‘*’ stands in the\nfollowing causal relations with other mental representations. \n\nIf the representation ‘*’ is related in these ways to\nother mental representations, it seems reasonable to say that it\nexpresses the relation of conjunction, i.e. that\n‘*’ should be interpreted as ‘and’. In fact, we\nmight want to go so far as to say that satisfying the conditions above\nconstitutes meaning conjunction. It is worth noticing that\nthese three conditions closely resemble the rules that typically\ncharacterize conjunction in natural deduction systems of propositional\nlogic. Reflecting on this similarity may suggest some potential\nproblems for conceptual role semantics. \n\nThese potential problems include the following. (1) Rules of inference\nare normative rather than descriptive. They tell us what inferences\nare permissible; they do not purport to provide an empirical account\nof what inferences people actually make. It is not clear how a\ndescription of the causal interactions between mental states can\ncapture this normative element (Williams 1990; for a critique of the\nidea that mental content is normative, see Glüer and Wikforss\n2009). (2) One might wonder whether there is something backward about\nthe view that conceptual role determines meaning. In the case of\npropositional logic, a standard view is that the meaning of logical\nconnectives such as conjunction is given by a truth table,\nwhich shows how the truth or falsity of a compound sentence is\ndetermined by the truth values of its component sentences. The\nadequacy of a system of inference rules is then determined by whether\nit permits derivations of all and only those arguments that are\nsemantically valid. Similarly, perhaps the causal roles of mental\nstates should be explained in part by their semantics, instead of the\nother way around. (3) Conceptual role semantics seems more plausible\nfor logical connectives than for other sorts of representations. It is\none thing to regard the meaning of a mental symbol for conjunction as\ndetermined by the inferences a subject will make between mental\nrepresentations that contain the symbol and those that do not. After\nall, that is what conjunction is for. It is another and much\nbolder thing to regard more empirical mental representations as having\ntheir meanings determined in this way. \n\nTwo additional problems, already identified in Block's essay, have been \nmuch discussed since. First, conceptual role semantics seems to lead to a\nvery extreme holism. If all or nearly all of the inferential\nrelations between mental representations are included in their\nconceptual role, then it seems that a change in the meaning of any\nrepresentation will also change the meanings of all or nearly all the\nothers, and also that nearly any change in belief will result in a\nchange in the meaning of one's representations. We ordinarily think\nthat there is an important difference between changes of belief and\nchanges of meaning, but it is hard to see how to capture this\ndifference within conceptual role semantics. Second, conceptual role,\nas understood by Block and others, may seem too “syntactic”\nto constitute a conception of content at all. In particular, conceptual\nrole does not naturally give rise to an account of truth conditions. As\nBlock puts it, “is narrow content really content?” Block\nhimself regards conceptual role as a determinant of content,\nand leaves it an open question whether it is also a kind of\ncontent. But if conceptual role is not actually a kind of content, then\nit does not satisfy all of the original motivations for introducing a\nnotion of narrow content. \n\nWhite (1982) and Fodor (1987) have offered a rather different, and\nhighly influential, way of thinking about narrow content. This\nconception focuses on what narrow contents are supposed to accomplish.\nA narrow content is supposed to be something that Oscar and Twin Oscar\nshare, and by virtue of which Oscar believes that water is wet and Twin\nOscar believes that XYZ is wet. Similarly, it should be something that\nArt in his actual environment shares with Art in his envisioned\ncounterfactual environment, and by virtue of which he believes, in his\nactual environment, that he has arthritis in his thigh, and believes,\nin the counterfactual environment, that he has a different and broader\ndisease in his thigh. So one approach to narrow content is simply to\ndeclare that a narrow content is something that, given a particular\nenvironment, determines a particular broad content. Block (1991) calls\nthis the “mapping theory,” since on this account a narrow\ncontent maps environments into broad contents. \n\nSome care is required in determining what the relevant environments\nare. What matters is not only the environment the subject is currently\nin, but rather the environment in which the subject acquired the\nrelevant beliefs and other mental states. If we zipped Oscar to Twin\nEarth and Twin Oscar to Earth, we would not thereby change what their\nthoughts are about (at least not immediately). Oscar would still be\nthinking about water, and would probably misidentify XYZ as water; Twin\nOscar would still be thinking about XYZ, and would probably misidentify\nwater as XYZ. What determines the broad content of their thoughts is\nnot merely the environment they are in at the moment, but also the\nenvironment in which they first acquired their thoughts and beliefs\nabout watery stuff. Provided we understand “context” to\ninclude both sorts of facts, we can describe the mapping conception as\na conception on which narrow content is a function from contexts to\nbroad contents. \n\n(White (1982) actually distinguishes between “contexts of\nacquisition” and “contexts of occurrence”, and\ndefines a notion of “partial character” as a higher-order\nfunction which takes a context of acquisition as argument and yields as\nthe resulting value a function from contexts of occurrence to broad\ncontents. The relation between White's view and Fodor's is easier to\nsee, however, if we employ a more inclusive conception of context that\nincludes both one's current environment and one's history of\nacquisition of the relevant concept. If we do, we can collapse both\nlevels of White's higher-order function into one, yielding a\nlower-order function like Fodor's. The broad content determined by a\nFodorian narrow content applied to a particular context is the same as\nthe broad content determined by applying White's partial character to\nthat context, and then applying the resulting function to the very same\ncontext.) \n\nThe mapping theory faces a number of difficulties. (1) As Fodor\nnotes, on the mapping view narrow content seems to be ineffable. We\nwould like to be able to say what the narrow content of a particular\nthought or belief is, but on Fodor's view this cannot be done. To\nexpress a narrow content we would presumably need to find an English\nexpression that is synonymous with it. But the content of English\nexpressions is broad, not narrow, so this seems to be impossible. \n\n(Valerie Walker (1990) and Stephen Stich (1991) propose that narrow\ncontents could be expressed if English were supplemented with a\n“bracketing” notation. For example, an expression of the\nform ‘___ has the (narrow) content that [p]’ is said to\nhave as its extension “in any possible world the class of brain\nstate tokens whose (broad) content is p, along with physically\nidentical tokens in all doppelgangers of people who harbor tokens whose\nbroad content is p” (Stich 1991, p. 247). The chief difficulty\nwith this proposal is that it has the consequence that every token with\na given broad content has the same narrow content. But mental states\nwith a particular broad content can be very unlike one another: compare\nOscar's belief that water is wet with that of an expert in chemistry,\nor the very different ways in which Pierre is related to the\nproposition that London is pretty. If narrow content is to be useful in\nexplaining behavior and rational inference, it must be the case not\nonly that Twins share their narrow contents despite their different\nbroad contents, but also that individuals with the same broad content\nmay have different narrow contents (Brown 1993).) \n\n(2) A second difficulty noted by Fodor is that, like conceptual role\nsemantics, the mapping conception may not deserve to be called\n“content,” because the narrow contents it yields do not\nsuffice to determine truth conditions. A central characteristic of\nbroad content is that a thought or belief with broad content thereby\nhas truth conditions: in some possible circumstances it is true, and in\nothers it is false. On the mapping conception, narrow content does not\nsuffice to determine truth conditions in this sense. To determine truth\nconditions, one needs to fix not only a narrow content but also a\ncontext. For instance, given the narrow content shared by Oscar and\nTwin Oscar when they think, “Lake Superior is full of\nwater,” we do not have enough information to say whether that\nthought is true or false in a particular situation. Suppose Lake\nSuperior is full of XYZ. Then Twin Oscar's thought is true but Oscar's\nthought is false, even though both thoughts have the same narrow\ncontent. So it seems that narrow content by itself is not enough to\ndetermine what truth conditions a thought has. (However, see the\nfollowing section on “Diagonal Propositions.”) \n\n(3) Finally, although the mapping conception gives us an abstract,\nformal conception of narrow content, it does not give us an algorithm\nfor finding the narrow content of a particular state. Although\napparently any function from contexts to contents would count as a\n“narrow content” in Fodor's sense, some of these functions\ncould not really be the content of a mental state. To use a\ncomputational analogy, we are really interested only in\n“computable” functions from context to content, functions\nthat can be implemented somehow in a human mind, and this suggests that\nit is not the function itself that is of interest but rather the\nalgorithm by means of which it is computed. \n\nThe complaint that on the mapping conception, narrow contents are\nnot truth conditional, and hence perhaps should not be called\n“contents” at all, can be met by an interesting twist on\nthe mapping conception. Instead of considering a function from contexts\nof acquisition to broad contents in its full generality, we can focus\nour attention on a narrower function, the “diagonal\nproposition” determined by a Fodorian narrow content. The idea,\nand the term “diagonal proposition,” were originally\nintroduced by Robert Stalnaker in a different context (Stalnaker 1999,\nespecially papers 4, 6, and 7), but it turns out to be useful here. It\nis not clear that anyone has actually proposed this idea as an account\nof narrow content, but Stalnaker has suggested it as an interpretation\nof Loar's view (Stalnaker 1990, discussing Loar 1988), and the view of\nChalmers (1996) has sometimes been understood in this way (e.g. by\nBlock and Stalnaker 1999). \n\nRecall that on the mapping conception, a narrow content is a\nfunction from environments or contexts of acquisition to broad\ncontents. Broad contents in turn are thought of as determining truth\nconditions; that is, a broad content will be true in some situations\nand false in others. How should we think of the environments or\ncontexts that determine broad content, and the situations in which\nbroad contents are true or false? One reasonably natural suggestion is\nthe following. Oscar and Twin Oscar both actually exist (in Putnam's\nfantasy), but they have different environments, different contexts of\nacquisition. We can think of their contexts as including all\nthe objective or nonperspectival facts about the actual world,\nplus a bit more, namely information about their locations in\nthat world. This may be more information than we need, but it gives us\na simple way to characterize contexts, and it is guaranteed to include\neverything relevant to the contribution of the natural and social\nenvironment to the contents of their beliefs. And of course, in\naddition to the actual contexts of Oscar and Twin Oscar, we can\nconsider other possible contexts, other environments that they might\nhave inhabited. In general, we can say that a context of an individual\nat a time is a centered world, a possible world that we regard\nas centered on the relevant individual and time. \n\nWith this background, we can consider a way to visualize the mapping\nconception. We will consider how the account applies to an example\nsimilar to that of Oscar and Twin Oscar. To keep things simple, we will\nchange the example slightly. Instead of regarding Earth and Twin Earth\nas two different planets both of which exist in the actual world, we\nwill consider them as different ways things could have turned out to be\non our actual planet. In the actual world, the watery stuff on Earth is\nH2O; in a possible counterfactual world, it is XYZ instead.\nWe will envision Oscar looking at a beaker full of a colorless,\nodorless liquid and thinking a thought that he would express by saying\n“that beaker contains water.” \n\nNow, we consider three possible environments or contexts, which we\nare thinking of as centered worlds. These are: \n\nIn context 2 and context 3, Oscar's ‘water’-thoughts are\nabout water, i.e. H2O, while in context 1 they are about\nXYZ. Whether Oscar's thought about the substance in the beaker is true\nor not depends on two things: what his thought means, i.e. its broad\ncontent, and a certain fact about the world, namely what substance is\nin the beaker. Since a context includes all the objective facts about a\nworld plus additional information about the “center” of the\nworld, each context determines a unique possible world. For example, if\nwe take context 1 and subtract the information about the time and\nindividual on which the context is centered, we obtain a possible world\nwe could call w(context 1). \n\nWe can summarize the situation in the following table: \n\nThe items in the left-hand column of our table are contexts. The\nhorizontal row to the right of each context represents the truth\nconditions or broad content Oscar's thought has if it originated in the\nindicated context. For instance, in context 1, Oscar's thought has the\nbroad content that there is XYZ in the beaker. This thought is true in\nthe world of context 1, false in the world of context 2 (since the\nbeaker contains H2O in that world), and false in the world\nof context 3. A suitably extended version of our table, then, could be\nregarded as visually representing the narrow content of Oscar's thought\nabout the substance in the beaker, on the mapping conception of narrow\ncontent, since it would illustrate, for each context, the broad content\nassociated with Oscar's thought by that context. \n\nNow we can say what the “diagonal proposition” is. It is\nsimply the proposition represented by the diagonal from the upper left\nto the lower right of the above table. This represents the truth value\nOscar's belief has, for any context, in the world of that\ncontext. The truth conditions this gives us are different from any\nof the three broad contents Oscar's belief might have depending on his\ncontext. But arguably they also give a better account of his narrow\ncontent than any of the horizontal propositions does. Unaware as he is\nof the chemical structure of water, Oscar has no direct access to which\npossible context is his actual context, and thus in a sense does not\nknow what broad content his thoughts have. He also does not know for\ncertain what liquid the beaker contains. What he does know is\nthat if his ‘water’-thoughts are anchored in XYZ\nand the substance in the glass is also XYZ, then his belief is true;\nand if his ‘water’-thoughts are anchored in\nH2O and the substance in the glass is also H2O,\nthen his belief is true; and if his\n‘water’-thoughts are anchored in H2O and the\nsubstance in the glass is H2SO4, then his belief\nis false; and so on. In short, although his internal state does not\nsuffice to determine any of the horizontal propositions, it does\nsuffice to determine the diagonal proposition, which therefore seems to\ndo a better job of capturing Oscar's state of mind than the horizontal\npropositions do. \n\nThe diagonal proposition view seems to avoid many of the\ndifficulties of other approaches to narrow content. In particular, it\ndoes provide truth conditions, and hence seems clearly to be a kind of\ncontent. (However, Kriegel (2008) points out that, while two-dimensional\naccounts like this one and the epistemic account to be discussed next can provide\ntruth conditions for “the mental analog of a\nsentence” and thus explain how it\n“puts us in cognitive contact with a state\nof affairs that constitutes its potential truth maker” (305),\nit is not so clear how the account can associate the mental analogs of\nsubsentential expressions with worldly things and properties. Kriegel\noffers an account according to which concepts, the mental analogs of\npredicate terms, denote response-dependent properties.) \n\nThe main difficulties for the diagonal proposition account concern (1)\nhow to apply it in order to determine the narrow content of a given\nmental state, and (2) the fact that it gives a way of defining the\ntruth conditions of a mental state only in centered worlds in which\nthe state actually exists. In the example above, for instance, Oscar\nis presumed to be in the same mental state in each context, although\ndifferences in how he came to be in that state affect its content. But\nthis raises the problem of what we need to “hold constant”\nin considering various counterfactual contexts in order to be\nconsidering a context in which Oscar is in the relevant state. These\nissues are considered briefly in section 5.1. \n\nA final view about the nature of narrow content has some striking\nstructural resemblances to the idea of a diagonal proposition, but is\nmotivated very differently. This is the view of David Chalmers (1996,\n2002); a related view has been defended by David Lewis (1979, 1994). In\na nutshell, the view construes narrow contents as sets of maximal\nepistemic possibilities, or scenarios. (Scenarios closely\nresemble the centered worlds used to define diagonal propositions.\nWhether there is a centered world for every scenario, and vice versa,\nare debated issues: see Chalmers 2006, section 3.4.) The motivation for\nthis view requires some development. \n\nNarrow content is intended to capture a subject's perspective on the\nworld, the way the world is according to the subject. A very natural\nway to think of this is to consider the narrow content of a belief or\nother thought to be a way of dividing up the ways things could\nconceivably be into those that are compatible with the thought and\nthose that are ruled out by it. \n\nOf course, broad contents also produce a kind of\npartitioning of possibilities. Any sort of content that\ndetermines truth conditions will rule in some possibilities and rule\nout others. But broad content does not provide the kind of partitioning\nneeded for narrow content. Twin Earth is ruled out by the broad content\nof my belief that the lakes are full of water, since the lakes on Twin\nEarth do not contain water. But narrow content was introduced precisely\nin order to have a kind of content that my Twin and I share, so the\nnarrow content of my thought that the lakes contain water should come\nout true in a Twin Earth environment centered on my Twin, just as my\nTwin's parallel thought comes out true there. A related way to see why\nTwin Earth is not ruled out by the narrow content of my thought is to\nnotice that I can imagine finding out that all the watery stuff in my\nactual environment is XYZ. In that case I would not conclude\nthat the lakes do not contain water; instead I would conclude that\nwater is XYZ. So the narrow content of my thought that the lakes\ncontain water does not rule out Twin Earth, even though its broad\ncontent does. \n\nChalmers develops this line of thought with the help of the\nfollowing apparatus. A thought is said to be epistemically\npossible if it cannot be ruled out a priori, i.e. if its negation\ncannot be conclusively established without any appeal to experience.\nSuch a thought corresponds to an epistemic possibility, a way the world\ncould be for all one can tell a priori. A scenario is then\ndefined to be a maximally specific epistemic possibility, an epistemic\npossibility with no detail left unspecified. Epistemic space\nis the set of all such scenarios. Any thought carves out a particular\nregion of epistemic space by endorsing some scenarios and\nexcluding others. A thought endorses a scenario when, if we\naccept that the scenario is actual, we should accept the thought as\ntrue. For instance, if we accept as actual a scenario in which\nthe liquid that falls from the skies and fills the lakes is XYZ, we\nshould accept as true the thought that water is XYZ. We can then think\nof the narrow content of a thought as constituted by the way the\nthought divides epistemic space into those scenarios it endorses and\nthose it excludes. More specifically, we can think of the narrow\ncontent of a thought as a function from scenarios to truth values, or\n(equivalently if we have only two truth values) simply as a set of\nscenarios, namely those endorsed by the thought. (This paragraph closely\nfollows Chalmers 2002, p. 610. Chalmers gives related but somewhat\nmore detailed expositions in Chalmers 2003, especially pp. 47, 54, and\nin Chalmers 2006, especially pp. 76ff. Note that a thought endorses\na scenario iff the scenario verifies the thought: Chalmers 2006 uses\nthe latter terminology but not the former.) \n\nScenarios clearly have much in common with centered worlds. Indeed,\nit may be possible to simply identify scenarios with centered worlds.\n(Chalmers is cautious about this, noting reasons that some might reject\nthis identification, but makes use of it for some purposes.) If\nscenarios are thought of as centered worlds, then the idea that narrow\ncontent is a function from scenarios to truth values is obviously a\nclose cousin of the idea that narrow contents are diagonal\npropositions, which can also be thought of as functions from centered\nworlds to truth values. The differences between the two accounts should\nnot be underestimated, however. An immediate formal difference is that\nnarrow contents on Chalmers' approach are defined over a larger class\nof centered worlds than are diagonal propositions. On the diagonal\napproach, the centered worlds with respect to which a thought is\nevaluated must include a token of that very thought at the center,\nwhile this is not the case on the approach we are now considering.\nAnother substantive difference between the two views is that they lead\nto very different strategies for determining narrow contents, as will\nemerge in sections 5.1 and 5.4. \n\nRecent work on phenomenal intentionality (see section 3.4) does not\nseem to have introduced any fundamentally new conceptions of narrow\ncontent. Some writing on the topic suggests the descriptive\nconception: “I suspect that in phenomenal intentionality the\nreferential connection to the world works roughly as suggested in the\ndescriptive theory of linguistic reference, rather than as suggested by\ndirect-reference theories” (Kriegel 2013,\np. 19). Loar's view of phenomenal intentionality (Loar 2003) has\nbeen interpreted as a version of the mapping conception (Lycan 2008\n§13; Burge 2003, p. 448). Horgan and Tienson suggest that their\nconception of phenomenal intentionality is similar to “the\napproach of so-called two-dimensional modal semantics” (Horgan\nand Tienson 2002, note 26; cf. Horgan, Tienson and Graham 2004, note\n13), of which the maximal epistemic possibilities conception described\nin section 4.4 is a version. Chalmers has explicitly proposed a way of\nextending the epistemic possibilities approach to the content of\nperceptual experience (Chalmers 2010, especially pp. 376–377 of the\nAfterword on “The Two-Dimensional Content of\nPerception”). \n\nWe have seen that there are various sorts of thing a narrow content\ncould be: a description, a conceptual role, a function from contexts to\nbroad contents, a diagonal proposition, or a set of maximal epistemic\npossibilities. It is a further question which items of the relevant\nsort (which diagonal propositions or epistemic possibilities, for\nexample) constitute the narrow content of a particular state of a\nparticular subject. \n\nHow can we find out what the narrow content of a mental\nstate is? Even more centrally, what is it about a mental state that\nmakes it appropriate to describe it as having a particular narrow\ncontent? In the remainder of this section, I consider several\nstrategies for determining narrow content. I do not address the issue\nof whether these strategies should be regarded as giving the essential\nnature of narrow content, or merely as heuristic devices for\napproximating it in practice. \n\nArguably, it is these differences over the appropriate strategy for\ndetermining narrow contents that are the most important differences\nbetween rival views of narrow content. Although we have considered\nseveral different views about the sort of semantic entities narrow\ncontents might be, all these views, with the exception of conceptual\nrole semantics, are close cousins of the view that narrow contents are\nsets of centered worlds. The most substantive differences between rival\nviews concern how to determine which centered worlds are included in\nthe narrow content of a particular state of a particular subject. \n\nA first strategy fits neatly with the view of narrow content as a\ndiagonal proposition. If we want to know the narrow content of a\nparticular mental state, we simply construct the diagonal proposition.\nThat is, we first envision a variety of situations or environments in\nwhich the mental state could be embedded, i.e. a set of contexts or\ncentered worlds that contain, at the center, the very mental state\nwhose content we are interested in. For each of these contexts, we use\nour knowledge of broad content and how it is determined to discover the\nbroad content that the mental state would have in that context. And\nthen we determine whether, in the world of that context, a belief with\nthat broad content would be true. \n\nThere are three main problems with this strategy. First, it treats\nbroad content as fundamental, and narrow content as derivative.\nHowever, for many advocates of narrow content (e.g. Chalmers 2002),\nnarrow content is at least as fundamental as broad content. In fact, it\nis tempting to regard broad content as determined by narrow content in\nconjunction with facts about context. But the strategy we are\nconsidering can only be applied to determine narrow content if we\nalready have an independent way of determining broad content. \n\nA second problem for the diagonalization strategy is a problem of\nscope (Chalmers, 2002). Although the diagonalization strategy yields a\ntruth-conditional notion of content, the only centered worlds at which\nthe diagonal proposition is evaluated will be worlds that contain at\ntheir center the mental state we are interested in. In effect this\nmeans that every mental state represents itself as existing. But it is\npuzzling why I could not have mental states whose content has nothing\nto do with their own existence. Chalmers offers these examples (Chalmers\n2002, p. 625): it\nseems that my thought that I am a philosopher should be true in worlds\ncentered on a philosopher even if he is not currently thinking that he\nis a philosopher. Again, it seems that the thought that someone is\nthinking should be false, not undefined, at centered worlds that do not\ncontain a thinking person. \n\nThird, there is the problem of what to “hold constant”\nin determining which possible contexts to consider (Block and Stalnaker\n1999). The strategy requires us to consider contexts that include the\nmental state whose content we are interested in. But exactly what\ncounts as a context that includes a particular mental state? And how\nclosely, and in which respects, must the version of the state in the\nother worlds resemble the version in the actual world? \n\nBlock and Stalnaker argue in some detail that the likely candidates\nfor what to hold constant all give the wrong results. Consider how we\nmight find the diagonal proposition associated with Oscar's belief that\nwater is wet. Suppose that a belief is, or is associated with, a mental\nanalog of a sentence. We will suppose that, like a sentence, a mental\ntoken can be identified separately from its meaning. Then Oscar's\nmental token, like the sentence “Water is wet,” could, in\nsome possible mental language, mean that dogs have fur. Now if in\ndiagonalizing we consider all possible worlds centered on someone who\npossesses the same mental sentence as Oscar's water-sentence,\nregardless of its meaning, we get a diagonal proposition that is much\ntoo unconstrained to serve as a narrow content. We surely do not want\nto say that the narrow content of Oscar's belief that water is wet has\nthe value True in a world that contains no remotely watery substance,\nbut in which dogs are furry and the mental token in question means that\ndogs are furry. \n\nSo it is not sufficient to hold a syntactically identified mental\ntoken constant in deciding which worlds to include in the diagonal\nproposition. We must somehow consider worlds in which the token carries\nthe same meaning it carries in the actual world. However, if we\nconsider only worlds in which the token has the broad meaning\nthat water is wet, the diagonal proposition will be too constrained to\nplay the role of narrow content: it will be false, not true, in a world\ncentered on Twin Oscar. \n\nStill another possibility is to hold constant, not the broad content\nof the mental token, but its narrow content. This will give the results\nwe want, but at the cost of making the account completely circular;\ndiagonalizing cannot be a useful strategy for discovering narrow\ncontents if we must already know the narrow content of a mental token\nin order to apply the strategy. \n\nThe subtraction strategy (Brown 1992) is an attempt to identify the\nnarrow contents of a subject's beliefs by considering all of the\ncontents of the subject's belief and subtracting those that are\nnot narrow. The contents that remain must be narrow. More\nprecisely, if a content of my belief is something I believe, then a\nnarrow content of my belief is something that I believe\nand that is believed by every possible duplicate of me\n(possibly within some restricted class of worlds). I say\n“ordinary content” instead of “broad content”\nhere, since the subtraction strategy presupposes that not all ordinary\ncontents are broad. \n\nTo see why this strategy might be appealing, we can consider an\nanalogy with perception. (A similar analogy with action is also\npossible.) Consider the perceptual state of someone looking at an\napple. We can characterize this state in terms of what the person sees,\njust as we can characterize Oscar's belief state in terms of what he\nbelieves. In this case, our subject sees an apple, so one way to\ncharacterize her perceptual state is as “seeing an apple,”\njust as one way to describe Oscar's belief state is as “believing\nthat water is wet.” However, we can easily construct scenarios in\nwhich our perceiver is in exactly the same narrow state, but does not\nsee an apple — perhaps because everything except the apple's\nfacing surface has been cut away. We can easily find a content of the\nsubject's perception that is a content of the very same perceptual\nstate but which characterizes it more narrowly: the subject sees the\nfacing surface of the apple, and it is by virtue of seeing the facing\nsurface that she sees the apple as a whole. Characterizing the\nperceptual state as “seeing the facing surface of an apple”\nis a narrower characterization in a very simple sense: if we consider\nalternative situations in which the subject is intrinsically exactly\nthe same, but her environment is different, we will observe that in\nevery situation in which she sees an apple, she also sees its facing\nsurface, but that there are additional situations in which she sees the\nfacing surface but does not thereby see an entire apple. Similarly, if\nwe consider Oscar's belief that water is wet, we notice that a Twin\nEarth-like scenario provides a situation in which he is in the very\nsame cognitive state but does not believe that water is wet. So we look\nfor other contents of his belief, other things he believes, that\ncharacterize his state more narrowly. In this case we notice that in\nevery situation in which he is in exactly the same intrinsic state and\nbelieves that water is wet, he also believes that the colorless,\nodorless liquid called ‘water’ is wet, but not conversely.\nSo this latter belief seems to characterize his intrinsic state more\nnarrowly than does the content “water is wet.” \n\nIt is important to notice that neither the perceptual content of seeing the\nfacing surface of an apple, nor the belief content of believing that the\ncolorless, odorless liquid called\n‘water’ is wet, is completely\nnarrow. We can find still more remote possibilities in which the subject's\nperceptual or belief state is exactly the same, but he or she does not have\nthis perceptual or belief content. (The\n“apple” could be a wax\nimitation or a holographic projection; Oscar's Twin could live in an\nenvironment in which the word\n‘liquid’ refers to very finely\ngranulated solids.) To find truly narrow contents we will need to press our\nsubtraction strategy still further, and appeal to objects that are very\ndifferent from the ordinary objects of perception or belief\n— perhaps colored shapes or sense-data in the case of\nperception; perhaps beliefs about the subject's perceptual inputs and\nbehavioral outputs in the case of belief (cf. McDermott 1986). \n\nThis suggests an important point which is rarely mentioned (but see\nRecanati 1994 for a related observation). Narrowness need not be\nconstrued as an all-or-nothing property. We can understand it instead\nas a matter of degree: one content of a mental state is narrower than\nanother the further away from the actual world we need to go in logical\nspace in order to find a world in which the subject's intrinsic\nproperties are the same but the state does not have that content.\n(Alternatively, we could relativize the notion of narrow content to a\nset of possibilities; the more possibilities the set includes, the\nfewer contents will count as narrow. For many purposes we never\nconsider Twin-Earth possibilities; for such purposes the proposition\nthat water is wet may count as a narrow content of a subject's belief.)\nOn this way of thinking of things, narrowness as it is usually defined\nis a limiting case: narrowness relative to the set of all\nmetaphysically possible worlds. The concept of narrowness may be useful\neven if the limiting case never occurs, just as the concept of flatness\nis useful even though in this world the limiting case of absolute\nflatness never occurs. \n\nPossible problems for the subtraction strategy include the\nfollowing. (1) The strategy presupposes that all the narrow contents of\nour beliefs are included in the ordinary contents of belief, so that\nonce we have subtracted the non-narrow contents away the narrow\ncontents will remain. On many conceptions of narrow content, however,\nnarrow content is a more specialized and technical notion than this,\nand we cannot suppose that the ordinary contents of belief will include\nnarrow contents. (2) The conception of narrow content with which the\nsubtraction strategy fits most naturally is the descriptive content\nconception discussed in section 2.1. It inherits the principal\nobjection to that view, namely that it is not clear that ordinary\nlanguage can offer a narrow vocabulary sufficient to describe the\nnarrow contents of our thoughts. Two points should be made in response\nto this worry. First, while the subtraction strategy assumes that the\nnarrow contents of belief are a subset of the ordinary contents of\nbelief, it need not be committed to the view that all of these ordinary\ncontents are describable in natural language. Second, as noted above,\nwe can think of completely narrow content as a limiting ideal case. The\nsubtraction strategy offers a way of relating broad beliefs to the\nnarrower beliefs on which they depend. This may be useful even if the\nprocess does not terminate in beliefs which are absolutely narrow. (3)\nAlthough the subtraction strategy offers a way of determining one's\ntotal narrow content, it is not clear whether or how it could be\napplied to more specific belief states. (4) The subtraction strategy\nalso shares with the diagonalization strategy the problem that it gives\nus a method of identifying narrow contents only if we already have an\nindependent method of identifying contents in general. \n\nThis strategy is proposed by Dennett (1982). The idea is that a\n(centered) world is included in one's narrow content if and only if it\nis a world to which one is ideally suited. Place a subject in some\nenvironments, and everything will work out extremely well: the\nsubject's attempts to satisfy his or her desires will succeed every\ntime. Other environments will be much less friendly; somehow the\nsubject's actions will never turn out to have quite the desired\neffects. Dennett's thought is roughly that we can capture the way the\nworld is from the subject's point of view by taking the set of centered\nworlds to which the subject is ideally adapted. One attraction of this\nstrategy is that it does not make narrow content parasitic on broad\ncontent; another is that it does not require the subject to be able to\nanswer questions or reflect on the content of the subject's thoughts,\nso that it could easily be applied to cats and dogs as well as to\nhumans. \n\nA possible problem for the ideal environment strategy is that, while\nit may give us a way to determine a subject's total view of the world,\nit does not provide a way of parceling out narrow contents to more\nspecific states. \n\nA second problem is that the strategy does not seem to properly\ndiscriminate cognitive content from other sorts of information a\nsubject's body may carry. A baby is better adapted to worlds in which\nextreme heat can damage its body than to worlds in which it cannot.\nWhen the baby touches something hot it automatically jerks away. This\naction has a useful purpose in a world in which heat is damaging, but\nwould be pointless in a world in which it was not. But it does not\nfollow that the baby believes that extreme heat is damaging.\n(See Stalnaker 1989, White 1991.) \n\nA third problem is that, in some cases in which an individual's\nstates do seem contentful, the ideal environment strategy, as stated\nabove, seems to yield the wrong content. In the most obvious sense, I\nam better suited to worlds that do not contain a homicidal maniac who\nwants to kill me than I am to worlds that do contain such a maniac,\neven if I believe that such a maniac exists. So it seems that the ideal\nenvironment strategy will not correctly include the content of this\nbelief among those it attributes to me. (Related examples are offered\nby Stalnaker 1989, White 1991, and Chalmers 2002.) As Stalnaker notes\n(1999: 182–183), Dennett is better understood to mean, not that the\nworlds I am best suited to are those in which I would do best, but\nrather that they are those with which I am best prepared to cope. But\nrefining this account is a challenging task. (For instance, martial\narts training might prepare me to cope with dangers that I do not\nbelieve to exist, raising the worry that the ideal environment strategy\non this interpretation will attribute to me beliefs I do not in fact\nhave.) \n\nThe epistemic strategy is recommended by Chalmers (2002, 2003,\n2006). The framework that gives rise to this strategy was presented in\nsection 3.5. Narrow contents are to be thought of as effecting a\npartition of scenarios, which are similar to the centered worlds\nemployed by the diagonalization strategy, into those endorsed by the\nthought and those excluded by it. But how exactly are we to determine\nwhich scenarios are which? On the diagonalization strategy, we make use\nof our preexisting grasp of ordinary content to determine what ordinary\ncontent the thought would express if it were located at the center of a\nparticular centered world, and then determine whether that ordinary\ncontent is true at that centered world. The epistemic strategy is\nradically different, and treats narrow content as at least as\nfundamental as ordinary content. \n\nSo, what function from scenarios to truth values constitutes the\nnarrow content of my thought that the lakes contain water? Put slightly\ndifferently, which scenarios does this narrow content include and which\ndoes it exclude? To find out whether the narrow content of the thought\nthat the lakes contain water includes a given scenario, I consider the\nhypothesis that the scenario is actual. For example, if I consider the\nhypothesis that a scenario in which the oceans and lakes around me\ncontain H2O is actual, then I will be led by a priori\nreasoning to the conclusion that the lakes contain water; hence, the\nnarrow content of my thought that the lakes contain water includes this\nTwin Earthly scenario. Similarly, if I consider the hypothesis that a\nscenario in which the oceans and lakes contain XYZ is actual, I will\nstill conclude that the lakes contain water, since in Twin Earth\nscenarios my water-thoughts are about XYZ. So the Twin Earthly scenario\nis also included in the narrow content of my thought that the lakes\ncontain water. By contrast, the narrow content of my thought that water\nis H2O will separate these two scenarios. If I consider the\nhypothesis that an Earthly scenario is actual, I will conclude that\nwater is H2O, so the narrow content of the thought that\nwater is H2O includes Earthly scenarios. However, if I\nconsider the hypothesis that a Twin Earthly scenario is actual, I will\nconclude that water is not H2O (rather, it is XYZ), so the\nnarrow content of my thought that water is H2O excludes Twin\nEarthly scenarios. \n\nIt is crucial that when I consider the hypothesis that the\nTwin-Earthly (or any other) scenario is actual, and ask whether, in\nthat case, my thought that lakes contain water is true, I am\nnot asking whether, had a Twin-Earthly world obtained, lakes\nwould have contained water. The answer to that question is\n“no,” but it is a different question. When I ask this\nlatter question, I am considering the Twin-Earthly world as\ncounterfactual. Presupposing that the world is not actually that way, I\nask what would be true if it were that way. Such questions, in which we\nconsider alternative worlds as counterfactual, are the appropriate way\nto determine issues of metaphysical possibility. The sort of\nquestion relevant to epistemic possibility is different. It\ninvolves considering scenarios as actual, not as\ncounterfactual: seeing what is the case if the world\nis that way, not seeing what would be the case if the\nworld were that way. Questions about epistemic possibility, in\nwhich we consider scenarios as actual, are naturally posed in\nindicative conditionals: if the substance in the lakes is XYZ,\nis it water? \n\nA full account must say much more than this about precisely what it\nis to consider a scenario as actual, and what it is for a scenario to\nbe endorsed by a particular belief. In order to consider a scenario, we\nmust have a complete description of some sort. On the other hand, there\nmust be restrictions on thevocabulary in which the description is\nexpressed. In particular, it cannot contain expressions like\n‘water’, for which Twin Earth examples can be constructed.\nChalmers offers a detailed account that addresses such questions. (This\nis presented briefly in Chalmers 2002 and Chalmers 2003, and in much\nmore detail in Chalmers 2006.) Here is the short version (Chalmers\n2002, p. 611): \n\nUnlike the diagonalization strategy, the epistemic strategy does not\ndepend on a prior determination of the broad content of the expression\nor state. Moreover, it does not require that narrow contents be\nevaluated only in scenarios that contain a token of the mental state at\ntheir center. \n\nPotential problems for the epistemic strategy include: (1) whether\nit can be applied to nonhuman animals, many of whom presumably also\nhave contentful mental states; (2) whether a canonical language that\nsatisfies the necessary constraints is possible (see e.g. Schroeter\n2004; Soames 2005, pp. 216–218; Sawyer 2007); and (3) whether a version of the\n“what is held constant” \nproblem for the diagonalization\nstrategy also poses problems for the epistemic strategy. (This last\npoint is discussed a bit further in section 6.2.) \n\nThis section addresses some more technical issues that have been\nsidestepped or ignored in earlier sections. \n\nWe have frequently considered the narrow content of Oscar's beliefs\nabout water, for instance his belief that water is wet. Is the mental\nstate we are concerned with here a type or a token? That is, are we\nconcerned with a particular instance of a mental state, which occurs at\na particular place and time, namely Oscar's belief on this particular\noccasion that water is wet, or are we concerned with a general kind of\nbelief, the belief that water is wet, which many different people could\nhave on many different occasions? \n\nIt seems that it cannot be the general type of belief that we are\ninterested in here, at least not if the type in question is\n“belief that water is wet,” since different people (or even\nthe same person on different occasions) could have beliefs of this type\nwhich had different narrow contents. Oscar is ignorant of the molecular\nstructure of water; he identifies water as a clear, odorless, colorless\nsubstance that falls from the skies and fills the lakes. As we have\nalready seen, Twin Oscar shares Oscar's narrow content, but in his\nenvironment this narrow content determines that he believes that XYZ is\nwet, not that water is wet. However, an earthly expert chemist who has\ndone years of laboratory research on water, and is well aware of its\nmolecular structure, will have a different water-concept than Oscar\ndoes, and his belief that water is wet will have a different narrow\ncontent than Oscar's does. The chemist's Twin Earth duplicate does not\nbelieve that XYZ is wet, since he is aware of the chemical composition\nof water and his beliefs explicitly concern H2O. He believes\nthat water is wet (though he also believes, falsely, that the substance\nthat fills the lakes and emerges from the taps is water). \n\nAlthough Oscar and the chemist share the (broad) belief that water\nis wet, they have different narrow contents associated with this\nbelief. So when we say that it is a belief that has a particular narrow\ncontent, we cannot be speaking of a general type of belief, at least\nnot if the type is determined by the broad content of the belief.\nRather, we must be speaking of a particular token belief, in this case\nOscar's belief on a particular occasion that water is wet. \n\nWe cannot completely evade issues about the nature of the token\nmental states we are considering, however. Even if the object of our\nconcern is a particular token, we need to know how to identify the\nparticular token we are interested in. Compare: suppose we decided we\nwanted to know the weight of a certain animal. A first question would\nbe whether we are talking about a type of animal or a token animal. In\nthis case we almost certainly intend to refer to the token rather than\nthe type. (If the token belongs to a type of animal all or most of\nwhose tokens have weights that fall in a fairly narrow range, we may\nlater decide that we can also assign a weight to the type, but it is\nthe weight of the tokens that is primary.) In this case there seems to\nbe no problem: we can easily determine the weight of this animal, and\neven determine what its weight would be in other environments, without\ndeciding whether the relevant type might be Pomeranians, or dogs, or\ncanines, for example. \n\nHowever, our ability to determine the weight of a token animal depends\non the fact that we already know what animals are and how to\nidentify them. If someone told us to find the weight of that\nthing over there, we would need a further specification of the\nthing in question before we could find its weight. Which thing? The dog?\nThe dog's front leg? The dog's fur? The cat over there next to the dog?\nOr possibly even the disjoint thing consisting of both the cat and the\ndog? It is not clear that asking about the narrow content of Oscar's\nbelief that water is wet is a much more clearly defined task than\nasking about the weight of that thing over there. Do we really have a\nmeans of picking out the mental state in question in a way that\ndistinguishes it from other beliefs in the vicinity? What properties\ndoes it have? For example, does it have a syntactic structure? Is it an\nintrinsic state? Does it have a particular location in the brain? Is it\nentirely distinct from Oscar's beliefs that water is a liquid, that\nwater can form droplets, and that water feels a certain way to the\ntouch? \n\nThe problem of identifying the bearer of narrow content is obviously\nclosely related to the problem of what to hold constant when employing\nthe diagonalization strategy. But the problem may also affect views on\nwhich we do not need to require that a token state be present in a\ncounterfactual situation in order to determine whether its narrow\ncontent would be true in that situation. It still seems that in order\nto know exactly what question we are asking, we need to know what it is\nwhose content we are evaluating in the counterfactual situations. We\nneed to know what the token state is in the actual world whether or not\nwe insist on its presence in the counterfactual one. \n\nThe discussion so far has presupposed that the mental states that\nhave narrow contents are what we might call local mental states. For\ninstance, we might want to know the narrow content of Oscar's belief\nthat water is wet without wanting to know the narrow content of the\nrest of his beliefs. However, an alternative possibility is that narrow\ncontents cannot be parceled out belief-by-belief in this way. It could\nbe that the best we can do is to find the narrow content of a subject's\ntotal belief state, the subject's complete understanding of what the\nworld is like. It could still make sense to discuss narrow contents\nless all-encompassing than one's total narrow belief content: we might\nsay that any necessary consequence of the subject's total narrow\ncontent is also a narrow content of the subject's belief. On a holistic\nview, though, there need not be an identifiable distinct belief state\nby virtue of which the subject has that narrow content, whereas on a\nparticularist view there will be. \n\nWhether holism or particularism is correct may depend on the correct\nview of the nature of mental representations. On one extremely\ninfluential view (Fodor 1987, and many other writings), cognitive\nstates are best thought of as relations to internal representations.\nThese representations are thought of as similar to expressions in a\nnatural language; indeed, Fodor describes these mental representations\nas a “language of thought.” On this view, Oscar's belief\nthat water is wet will be understood as a relation to a sentence-like\ninternal representation. This view may permit a particularist\nunderstanding of narrow content (although it is also possible to\ncombine particularism about mental representations with holism about\ntheir content; see Block 1991). \n\nOn the other hand, Frank Jackson has suggested that we might\nrepresent the world by means of something more like a map than like a\ncollection of sentences (Jackson 1996; Braddon-Mitchell and Jackson\n1996). If this is the right understanding of representational mental\nstates, then we would expect holism rather than particularism to be\ntrue. As Braddon-Mitchell and Jackson note, a map “says which\nisland is the largest by saying something about the size of all the\nislands, and it says something about the size of any particular island\nin the course of saying something about where it is and what shape it\nis” (p. 183). Although the map does convey particular bits of\ninformation, we cannot neatly identify these bits of information with\nparticular pieces of the map. \n\nWhether the content of a particular state is narrow or not depends\non whether it would be shared by the corresponding state of every\nduplicate of the subject who has the state. But this means that whether\nthe content of a state is narrow depends on how we individuate the\nsubject who has the state. A content that is broad relative to one\nsubject might be narrow relative to another, more inclusive subject. I\nmight have an internal state that represents the condition of a\nparticular cone in my retina. If we take the subject in this case to be\nme — all of me — this content might be narrow,\nwhile if we construe the subject more narrowly as, say, my brain, then\nthe very same content of the very same state will be broad rather than\nnarrow (since a duplicate state could have a different content if\nhooked up to a different kind of eye). For at least some purposes, for\ninstance discussing brain-in-a-vat skeptical scenarios, we will no\ndoubt want to construe the subject very narrowly, while for other\npurposes we might want to include such external objects as a notebook\nor PDA as part of the subject's memory (Clark and Chalmers\n1998). \n\nIt should be evident that the idea of narrow content is highly\ncontroversial. Many thinkers reject the very idea of narrow content,\nwhile to many others it seems an attractive way to think about the kind\nor aspect of mental content that most closely captures the subject's\nperspective on the world, the nature of rational belief and inference,\nand the nature and extent of a priori knowledge. Even among its\nadvocates, however, there is substantial disagreement on the precise\nform a theory of narrow content should take. There is much work left to\nbe done on this topic: to develop the various approaches more fully; to\ndetermine to what extent they are compatible with one another; and, to\nthe extent that they are not, to compare their advantages and\ndisadvantages.","contact.mail":"cbrown@trinity.edu","contact.domain":"trinity.edu"}]
