[{"date.published":"2005-12-23","url":"https://plato.stanford.edu/entries/ecology/","author1":"Sahotra Sarkar","author1.info":"https://liberalarts.utexas.edu/philosophy/faculty/sarkars1","entry":"ecology","body.text":"\n\n\n\nThe science of ecology studies interactions between individual\norganisms and their environments, including interactions with both\nconspecifics and members of other species. Though ecology emerged in\nthe 19th century much of its theoretical structure only emerged in the\ntwentieth century. Though ecology includes a wide variety of\nsub-fields, philosophical analysis of ecology has so far been\nrestricted to population, community, and ecosystem ecology. Central\nphilosophical problems include explication of relevant notions of\necological diversity and stability the relation between diversity and\nstability. Other debated questions are the nature of laws and theories\nin ecology, strategies of model-building, and reductionism.\nContemporary ecology is undergoing a conceptual upheaval because of\nincreased computational power. The recent emphasis on individual-based\nmodels, which embrace methodological individualism, should be viewed as\na return of reductionism in ecology. Other important developments\ninclude widespread interest in spatially explicit models and the advent\nof Geographical Information Systems.\n\n\n\nThe term “ecology” was coined by the German zoologist,\nErnst Haeckel, in 1866 to describe the “economies” of\nliving\n forms.[1]\n The theoretical practice of ecology consists, by and\nlarge, of the construction of models of the interaction of living\nsystems with their environment (including other living\n systems).[2]\n These models are then tested in the laboratory and the\nfield. (Field-work in ecology also consists of data collection that\nneed not be inspired by any theory.) \n\nTheory in ecology consists of the heuristics—or\nprinciples—used to construct models. Unlike evolutionary theory,\necology has no generally accepted global principles such as Mendel's\n(and other) rules of genetic\n inheritance.[3]\n Contemporary ecology consists of a patchwork of sub-disciplines\nincluding population ecology, community ecology, conservation ecology,\necosystem ecology, metapopulation ecology, metacommunity ecology,\nspatial ecology, landscape ecology, physiological ecology,\nevolutionary ecology, functional ecology, and behavioral ecology. What\nis common to all these fields is the view that: (i) different biota\ninteract in ways that can be described with sufficient precision and\ngenerality to permit their scientific study; and (ii) ecological\ninteractions set the stage for evolution to occur primarily because\nthey provide the external component of an entity's fitness. The latter\naspect makes ecology a central part of\n biology.[4]\n As van Valen once put it: “evolution is the control of\ndevelopment by\n ecology.”[5]\n However, the creation of a unified theoretical framework for\nevolution and ecology remains the task for the future and will be of\nno further concern in this entry. \n\nTurning to the philosophy of ecology, beyond those interpretive and\nconceptual problems that arise because of the evolutionary context,\necology also presents interpretive and philosophical problems from its\nown unique conceptual structure and experimental practices. In this\nentry, attention will largely be restricted to population, community,\nand ecosystem ecology since these have been the focus of the little\nphilosophical attention that has so far been afforded to ecology;\nthere will also be some limited treatment of spatial ecology (in\n Section 5.2).\n However, because ecology has not received the degree of professional\nphilosophical attention it deserves—while popular\n“ecological philosophies” abound—this entry\nconcentrates more on foundational and interpretive issues raised by\nthe science of ecology rather than only on what philosophers have\nwritten about the subject. \n\nThis entry treats experimental and theoretical work simultaneously\nwith a bias in favor of those theoretical results that are\nunambiguously testable. It was once commonplace for even ecologists to\naccuse ecological theory of\n untestability.[6]\n This criticism was not completely fair even in the past; moreover,\nboth experimental and theoretical developments during the last few\ndecades have removed much of its force. Instead, what ecology poses is\na much more philosophically intriguing set of seven problems: \n Some typical examples of all these largely theoretical problems will\nbe pointed out later in this entry. Fieldwork, on which all empirically\nsound ecological theory should presumably be based, poses an additional\nproblem: \n\nFinally, many philosophers and some ecologists have also argued that\necological experimentation is confronted with two additional\nproblems: \n\nThe last two problems often preclude the use of laboratory experiments\nand model systems as a guide to what should happen in the\nfield. Moreover, according to skeptics, they are an impediment to the\nreplication of field experiments: the extent to which this is a\nserious obstacle to ecological experimentation remains\ncontroversial. These two problems will lurk in the background of all\nthe discussions here. \n\nThere are also many other general philosophical problems about science\nthat also occur in the ecological context, for instance, the role of\nidealizations, models, and so on. But ecology does not seem to make\nany unique contribution to these problems—they will be ignored\nhere in the interest of focusing on ecology per se.  The aim\nof this entry is to describe—in broad terms—the type of\nphilosophical questions raised by different areas of ecology so as to\nencourage further philosophical work. No general conclusions will be\ndrawn from the various cases because none seem feasible at\npresent. \n\nThe golden age of theoretical ecology (1920-1940)—to borrow\nthe title of a book edited by Scudo and Ziegler—consisted\nprimarily of population\n ecology.[10]\n The next generation saw a shift of theoretical interest to community\necology. In recent years, interest has reverted to population ecology,\nsometimes in the form of metapopulation models (consisting of a set of\npopulations with migration between them).  Models in population\necology are based on representing an ecological system as the set of\npopulations (of the same or different species) it consists of. Each\npopulation, in turn, consists of potentially interacting individuals\nof a species. Populations may be characterized by their state\nvariables (parameters representing properties of the population as a\nwhole, for instance, size, density, growth-rate, etc.) or by\nindividual variables, that is, the properties of the\nindividuals in them (for instance, individual fecundity, interactions,\n etc.).[11]\n Classical population ecology was restricted to the study of\nstate-based models primarily because of the requirement that models be\ntractable, so as to permit predictions and\n explanations.[12]\n State-based models will be the focus of this section;\nindividual-based models will be discussed in\n Section 5.1.\n Classical population ecology is the part of ecology that is\ntheoretically the most developed. The central issue of interest in\npopulation ecology is the change in the size of populations (their\n“abundances”) over time. \n\nPopulation ecology considers both deterministic and stochastic\nmodels. Much of philosophical writing on population ecology has been\nrestricted to deterministic population models and this relatively large\nbody of work will only be very briefly summarized. More attention will\nbe paid to stochastic models which raise much more interesting\nphilosophical issues that have not been adequately explored. \n\nIf population sizes are large, they can be studied using deterministic\nmodels, that is, fluctuations in populations sizes due to chance\nfactors (such as accidental births and deaths) can be ignored.\nUsually a model considers members of a single or a very few\ninteracting species, for instance, a few predator and a prey\n species.[13]\n A typical result, based on the Lotka-Volterra (coupled differential\nequations) model, is that predator-prey interactions lead to\npopulation cycles, with the predator population cycle temporally\ntracking the prey population cycle. The explanation of this phenomenon\nis straightforward: as prey populations increase, the increased\navailability of resources allows a rise in predator populations a\nlittle later in time. But the increase of predators leads to an\nincrease of prey consumption and, consequently, a decrease in prey\npopulations. But, now, the lack of resources leads to a decline of\npredator populations. As predator populations decline, prey\npopulations increase initiating the cycle once again. See\nFigure 1: \n The Lotka-Volterra model mathematically predicts these cycles. As\nsuch, it exemplifies the explanatory ideal of ecology: not only is\nthere a predictively accurate quantitative model, but the mechanisms\nincorporated in the model have a perspicuous biological\ninterpretation. Unfortunately, in ecology, because of the\nformalization and interpretation indeterminacy problems, the last\ncondition is rarely satisfied. \n\nFor the simpler case of single species, two standard models are that\nof exponential and logistic growth.  The exponential growth model is\nsupposed to capture the behavior of a population when there is no\nresource limitation; the logistic growth model is one of the simplest\nways to try to capture the self-regulation of population sizes when\nthere is such a\n limitation.[14]\nSee Box 1.1 and 1.2. Let r = b − d. Then the\npopulation dynamics is described by the growth equation: This is the exponential growth model. It\nassumes that no resource limitation constrains the \"intrinsic\ngrowth rate\", r. It can be solved to give: where n0 is the size of the population\nat t0.  where K is called the \"carrying capacity\" of \nthe environment; this parameter is supposed to incorporate\nhow resource limitation affects population growth by regulating\nit.  When n = K, the growth rate, and the population does not grow any further. Moreover, \nwhen there is no resource limitation, that is K\n→ ∞, this model reduces to the exponential\ngrowth model.  Figure 2b shows how a population \ngoverned by the logistic equation grows in size.\nAt the level of individual behavior, this model\ndoes not have the kind of justification that the exponential\ngrowth model does in the sense that the \nlogistic equation cannot be plausibly derived from the\nproperties of individuals. In this sense it is a purely\n\"phenomenological\" model. \n The exponential growth model appeals to only one essentially\necological parameter, the intrinsic growth rate (r) of a\npopulation, interpreted as the rate at which the population would grow\nif there were no external factor limiting growth; the logistic model\nalso appeals to the carrying capacity (K), interpreted as the\nmaximum size of the population that can persist in a given\nenvironment.  See Figures 2a and 2b: \n \n (a) \n \n (b) \n Figures 2a and 2b: The Logistic Growth Model\n\n The figure on the top (from Gause [1934], p. 35) shows theoretical\ncurves. “Geometric increase” represents the exponential\ngrowth model discussed in the text; “saturating population”\nrefers to the carrying capacity (see\n Box 2).\n The figure on the bottom (from Gause [1934], p. 36) shows\nan example of an empirical growth curve obtained in the laboratory. If\nthe curve is fitted to a logistic curve (to which it shows similarity),\nthen K = 375 is the estimated carrying capacity. \n In general, biological experience suggests that all populations\nregulate their sizes, that is, they show self-regulation. Theoretical\nexploration of models has made it clear that a wide variety of\nmechanisms can lead to such self-regulation but it is usually unclear\nwhich models are more plausible than others thanks to the typical\nformalization indeterminacy of the field. Moreover, the precise\nmechanisms that are playing regulative roles in individual cases are\noften very hard to determine in the field, a classic case of partial\nobservability. Even parameters such as the intrinsic growth rate and\ncarrying capacity are unusually difficult to estimate precisely. \n\nThe last mentioned difficulties are perhaps most famously illustrated\nby the 10-year cycle of snowshoe hares, muskrats and their predators\nin the North American boreal forests and, especially, the 4-year cycle\nof lemmings and, possibly, other microtines in the arctic tundra of\nEurasia and North America. In spite of almost seventy-five years of\ncontinuous research on these well-documented cycles the mechanisms\ndriving them remain unresolved. Models producing such cycles abound,\nbut the structural uncertainty of most of these models, coupled with\npartial observability of many of the parameters in the field have\nprecluded resolution of the\n debate.[15] \n\nThe models discussed so far are continuous-time models, that is, the\ntemporal or dynamic parameter is assumed to be a continuous variable.\nHowever, discrete-time models have also been used to study population\nprocesses. A discrete analog of the logistic growth model was one of\nthe first systems in which chaotic dynamic phenomena were\n discovered.[16]\n Over the years there has been considerable debate over the question\nwhether ecological systems with chaotic dynamics exist in nature; the\ncurrent consensus is that they have not yet been\n found.[17] \n\nIf population sizes are small, then models should be stochastic: the\neffects of fluctuations due of population size must be explicitly\nanalyzed. Stochastic models in ecology are among the most\nmathematically complex models in science. Nevertheless they have begun\nto be systematically studied because of their relevance to biological\nconservation—see the entry on \n conservation biology.\n They also raise philosophically interesting questions because they\nunderscore the extent to which the nature of randomness and\nuncertainty remains poorly explored in biological\n contexts.[18] \n\nWhat has, by and large, become the standard classification of\nstochasticity goes back to a 1978 dissertation by Shaffer. The context\nof that dissertation provides a striking exemplar of the social\ndetermination of science. The United States National Forest Management\nAct of 1976 required the Forest Service to “provide for\ndiversity of plant and animal communities based on the suitability and\ncapability of the specific land\n area.”[19]\n In 1979 the planning regulations developed to implement this\nprovision required the Forest Service to “maintain viable\npopulations of existing native and desired non-native vertebrate\nspecies in the planning\n area.”[20]\n A viable population was defined as “one which has the estimated\nnumbers and distribution of reproductive individuals to insure its\ncontinued existence in the planning area.” For large\npopulations, falling within the domain of deterministic models,\nestablishing viability is relatively trivial: all that must be ensured\nis that, on the average, a population is not declining in size. For\nsmall populations, even if it is increasing in size on the average, a\nchance fluctuation can result in extinction. Stochastic models are\nnecessary to predict parameters such as the probability of extinction\nwithin a specified time period or the expected time to extinction. \n\nIn his dissertation, Shaffer attempted such an analysis for the grizzly\nbears (Ursus arctos) of Yellowstone which were believed to\nface the prospect of stochastic extinction. Shaffer distinguished four\nsources of uncertainty that can contribute to random extinction: \n\nShaffer went on to argue that all these factors increase in importance\nas the population size decreases—a claim that will be questioned\nbelow—and, therefore, that their effects are hard to\ndistinguish. Finally, he defined a minimum viable population (MVP):\n“A minimum viable population for any given species in any given\nhabitat is the smallest population having at least a 95% chance of\nremaining extant for 100 years despite the foreseeable effects of\ndemographic, environmental, and genetic stochasticity, and natural\n catastrophes.”[22]\n Both numbers (95% and 100 years) are conventional, and to be\ndetermined by social choice, rather than by biological factors, a\npoint that Shaffer explicitly recognized. \n\nIn the 1980s, techniques to determine MVPs came to be called\n“population viability analysis” and the enthusiasm for the\nnew framework was captured in the much-worn slogan: “MVP is the\nproduct, PVA the\n process.”[23]\n By the late 1980s, however, it became clear that the concept of a MVP\nwas at best of very limited use. Leaving aside the conventional\nelements of the definition given above, even for the same species,\npopulations in marginally different habitat patches often show highly\nvariable demographic trends resulting in highly variable MVP estimates\nfor them, with each estimate depending critically on the local\n context.[24]\n Moreover, as will be illustrated below for stochastic population\nmodels in general, the determination of MVPs suffers from irremediable\nstructural uncertainty. This should not come as a surprise: what would\nhave been more surprising is if legislative fiat had identified a\nscientifically valuable parameter. After the demise of the concept of\nthe MVP, PVA began to be performed largely to estimate other\nparameters, especially the expected time to extinction of a population\nthe estimation of which does not require any conventional\nchoices—see the entry on \n conservation biology. \n\nWithin the context of PVA, Shaffer's classification—though\nusually with “random catastrophe” replacing “natural\ncatastrophe”—became canonical within both ecology and\nconservation\n biology.[25]\n However, the philosophical question remains as to whether it makes\nsense—classification, as many philosophers have pointed out, is\nnot innocent of substantive theoretical assumptions. The first point\nto note is that genetic stochasticity is not even the same type of\nmechanism as the other three: its presence makes Shaffer's\nclassification oddly heterogeneous. The reason for this is that\ngenetic stochasticity is a consequence of demographic stochasticity:\nin small populations, a particular allele may reach fixation purely by\nchance reproductive events. It is even possible that stochasticity\nincreases the rate at which a beneficial allele may go to fixation in\na small population provided that the initial frequency of that allele\nis already high. \n\nLeaving genetic stochasticity aside, do the other three categories\nprovide a good classification of stochasticity, or is the\nclassification more like that of animals in Borges' notorious Chinese\n encyclopedia?[26]\n For any classification to be a good one, it must, at the very least\nsatisfy three criteria: (i) it must organize phenomena into a\nrelevantly homogeneous class of categories. Relevance is determined\ncontextually by the possibility of there being a coherent account of\nhow those categories came to be defined. Including genetic\nstochasticity in the classification leads to a lack of such\ncoherence—hence, its exclusion above; (ii) the categories should\nbe jointly exhaustive, able to subsume all cases of the relevant\nphenomena; and (iii) the categories should be mutually exclusive, that\nis, no phenomenon should be subsumed under more than one category. \n\nIt is the third criterion that is often called into question by\nShaffer's classification of stochasticity primarily because of\nformalization indeterminacy. Consider some small reptile that fails to\nbreed because a flood creates a barrier across its habitat that it\ncannot cross and there are no available mates on its side of the\nbarrier. Is this environmental or demographic stochasticity? On the\none hand, it is obviously environmental because floods are precisely\nthe type of mechanism by which environmental stochasticity is\nexpressed. On the other hand, it is equally obviously demographic\nbecause the failure to reproduce is due to the chance unavailability\nof a mate on the appropriate side of the barrier. Ultimately, as will\nbe discussed below in some detail, whether this is a case of\ndemographic or environmental stochasticity depends on how it is\nmodeled. There is an important philosophical lesson here: especially\nwhen a new discipline is being formed, the structure of the\nphenomena—how they are distinguished and classified—are in\npart determined by the models used to represent them. Consequently,\nclassification is not theoretically innocent. This is as true in\necology as in any other scientific context. \n\nThus, as a prelude to modeling, Lande et al. argue that\ndemographic stochasticity “refers to chance events of individual\nmortality and reproduction, which are usually conceived of as being\nindependent among individuals” whereas environmental\nstochasticity “refers to temporal fluctuations in the\nprobability of mortality and the reproductive rate of all individuals\nin a population in the same or similar fashion. The impact of\nenvironmental stochasticity is roughly the same for small and large\n populations.”[27]\n This is further elaborated: “Random variation in the expected\nfitness that is independent of population density constitutes\nenvironmental stochasticity. Random variation in individual fitness,\ncoupled with sampling effects in a finite population, produces\ndemographic\n stochasticity.”[28]\n Nevertheless, environmental fluctuations or even random catastrophes\naffect the size of a population only insofar as they affect\nreproduction and death rates, that is, by creating demographic\nfluctuations; at least in this sense, the second and third categories\nof stochasticity are not conceptually independent of the first.\nMoreover, Lande and others regard random catastrophes as extreme cases\nof environmental stochasticity. Consequently, it requires explicit\nmathematical models in which these distinctions are made exact through\nformal\n definitions.[29]\n Usually, models of demographic stochasticity are distinguished from\nmodels of environmental stochasticity using as a criterion whether the\nstochastic factor explicitly depends on the population size as a\nparameter. If it does, the model in question is one of demographic\nstochasticity; if it does not, it is one of environmental\nstochasticity. This choice captures the intuition mentioned earlier\nthat the effect of the former depends on the population size whereas\nthe effect of the latter does not. \n\nThe mathematical analysis of these models is non-trivial. The most\ngeneral and uncontroversial theoretical result to date is that\nprogressively larger populations are required for safety in the face\nof demographic, environmental, and random catastrophic stochasticity.\nMoreover, because of the structural uncertainly of these models,\napparently slight differences in assumptions and techniques routinely\nlead to widely divergent predictions. This can be illustrated using\nthe well-studied example of the Yellowstone grizzlies. In 1994 Foley\nconstructed a model for this population incorporating environmental\nstochasticity alone and depending on the intrinsic growth rate of the\npopulation and the carrying capacity of the\n environment.[30]\n The model's prediction augured well for the grizzlies: with a\nreasonable value for the carrying capacity and the measured value for\nthe intrinsic growth rate, the expected time to extinction was about\n12,000 years. In 1997 Foley constructed another model incorporating\nboth demographic and environmental stochasticity but with the option\nof setting either part equal to\n 0.[31]\n When this model is solved with the demographic stochasticity equal to\n0 (a case not analyzed by Foley), it should give the same result as\nthe 1994 model. It does not. It predicts a much lower expected time to\n extinction.[32] \n\nCommunity ecology consists of models of interacting species, forming\nan ecological “community,” in which each species is\ntreated as a unit. The appropriate definition of\n“community” has been widely debated among ecologists and\nphilosophers; what is being given here is an interactive\n definition.[33]\n Alternative options include defining community by mere geographical\nassociation of species at one extreme, or by requiring a good deal of\nstructure in the interactions at the other, making the community\nanalogous to an organism. The interactive definition given above is\nattractive for two reasons: (a) mere association leaves little of\ntheoretical or practical interest to study, while requiring some\nspecified elevated levels of interaction introduces an unnecessary\narbitrariness in a definition of community; and (b) the former would\nmake any association of species a\n community[34]\n whereas the latter would typically introduce so much structure that\nvirtually no association would constitute a community. \n\nCommunity models can be conveniently represented as\nloop,\n diagrams[35]\n generalized graphs that have each species as a vertex and edges\nconnecting these vertices when the species interact. The edges\nindicate whether the relevant species benefit or are harmed by the\ninteraction, that is, whether they tend to increase or decrease in\nabundance, by an interaction. See Figure 3: \n As with population ecology, what is of most interest is are the\nchanges in a community over time. This brings us to one of the most\ninteresting—and one of the most vexed—questions of\necology: the relationship between diversity and stability. A deeply\nrooted intuition among ecologists has been that diversity begets\nstability. If this claim is true, it has significant consequences for\nbiodiversity conservation—see\n conservation biology.[36] \n\nWhat confuses this question from the very beginning, is the\nmultiplicity of possible definitions of “diversity” and\n“stability.” There are probably no better instances of\nformalization indeterminacy in any scientific context. For instance, a\nreasonable first attempt to define diversity would be to equate the\ndiversity of a community to the number of species in it, that is, its\nspecies “richness.” The trouble is that there is ample\nreason to doubt that richness captures all that is relevant about\ndiversity, whether or not we are interested in only its relationship\nto stability. Consider two communities, the first consisting of 50%\nspecies A and 50% species B, and a second consisting\nof 99.9 % species A and 0.1% species B. Both\ncommunities have the same richness because they both have two species;\nhowever, there is a clear sense in which the first is more\ndiverse—or less homogeneous—than the second. Moreover, the\ndifference is likely to be relevant. If diversity does beget stability\nin these communities, then that stability must be a result some\ninteraction between the two species. If species B comprises\nonly 0.1% of the community, the scope for such interaction is\ntypically much less than if it comprises\n 50%.[37]\n Diversity must mean more than richness. There\nhave been several attempts to define and quantify diversity beyond\nrichness; one of them is described in Box 2. Though many measures of α-diversity have been proposed over\nthe years, MacArthur's (1965) proposal to use the Shannon measure of\ninformation content in a communication process (Shannon 1948) has\nremained the most popular (though not universally accepted).  According to this measure, the α-diversity of a community\nwith n species is given by where pi is the frequency of\nthe i-th species.  This is a measure of the diversity of a\ncommunity in the same way that the Shannon measure of information\ncontent is a measure of the variety in a signal.  Turning to the two communities discussed in the text, a simple\ncalculation shows that the diversity of the first is given by α\n= 0.693, while the diversity of the second is given by α =\n0.008, verifying the intuition that the first is more diverse than the\nsecond. \n Unfortunately, though, there has been little success in tying these\nconcepts to theoretical rules or even empirical\n generalizations.[38]\n (For a discussion of the related concept of biodiversity, see\nthe entry on \n biodiversity.) \n\nStability turns out to be even more difficult to\n define.[39]\n At one extreme, stability can be defined to require that a community\nbe truly in equilibrium: it does not change in either its composition\n(the abundances of every component)or in the interactions among these\ncomponents. At the practical level, this definition faces the problem\nof vacuous scope: almost no natural community satisfies such a strict\nrequirement of equilibrium. Moreover, almost every community\nexperiences significant disturbances. With this in mind, stability has\nbeen variously explicated using a system's response to disturbances or\nits tendency not to change beyond specified limits even in the absence\nof disturbance. Boxes 3 and 4 (see below) list some of the definitions of stability that\nhave been in vogue and how they may be measured in the\n field.[40] \n\nHow do any of these measures of stability relate to diversity? The\nonly honest answer is that no one is sure. If diversity is interpreted\nas richness, traditionally, it was commonly assumed that diversity is\npositively correlated with at least persistence. However, there was\nnever much hard evidence supporting this assumption. If stability is\ninterpreted as a return to equilibrium, mathematical models that\nshould answer questions about stability are easy to construct but hard\nto analyze unless the system is already close to equilibrium. This is\ncalled local stability analysis. The most systematic analyses\nperformed so far give no straightforward positive\n correlation.[48]\n It was once believed that natural ecosystems are usually at\nequilibrium (the “balance of\n nature”).[49]\n But ample empirical data now suggests that this assumption is almost\nnever correct: natural ecosystems are usually far from\n equilibrium.[50]\n Moreover, if natural selection between species occurs during the\ntransition to equilibrium, equilibrium communities will be less rich\nthan those that are yet to reach equilibrium. On short time scales\n(short enough to make speciation unlikely), selection between species\nthat utilize the same resources (that is, they occupy the same\n“niche”) will lead to the exclusion of the less fit by the\nmore fit through “competitive\n exclusion.”[51]\n The eventual equilibrium community, one in which selection would no\nlonger be acting, the (controversially) so-called “climax\ncommunity,” is necessarily less rich than those that temporally\npreceded it. \n\nThe traditional assumption of a general positive correlation between\ndiversity (as richness) and stability has been seriously challenged on\nboth theoretical and empirical grounds since the\n 1970s.[52]\n However, more recently, Tilman has suggested an empirical connection\nbetween richness and stability, interpreted as constancy, in grassland\n habitats.[53]\n The scope of this generalization, even whether it can be replicated\nfor other grasslands than those that Tilman studied, remains to be\ninvestigated. Meanwhile, Pfisterer and Schmid have produced equally\ncompelling empirical evidence that richness is inversely correlated\nwith stability, interpreted as resilience and\n resistance.[54]\n Much remains to be found out. All that is certain is that McCann's\nconfident 2000 verdict in favor of a positive diversity-stability\nrelationship was\n premature.[55]\n Note, finally, that virtually no theoretical or practical exploration\nof this question has used concepts of diversity other than\nrichness. At least at the theoretical level, this remains an open\nfield for philosophers. (Clear formal results would not go unnoticed\nby ecologists.) \n\nWithin community ecology, philosophers have lately paid considerable\nattention to the theory of island biogeography and the controversies\nsurrounding its relevance for the design of networks of biological\n reserves.[56]\n The basis for this theory is the species-area relation: larger areas\nof the same habitat type usually contain more species than smaller\n ones.[57]\n Thus there is a monotonic relationship between species richness and\narea. But, what is the form of this relationship?  Moreover, what is\nthe mechanism responsible for it? In spite of sporadic work over\nalmost an entire century, these remain open questions. Perhaps the\nmost popular answer to the first question, but one that gives no hint\nof the operative mechanism, is a power law going back to\n Arrhenius:[58]S = cAz, where S is the\nnumber of species, A the area, and c and z\nconstants. This power law represents what is often called the\n“species-area curve.” Turning to the question of\nmechanisms, traditionally, the species-area relation was attributed to\nenvironmental heterogeneity. Larger areas were presumed to have\ngreater habitat heterogeneity and could, therefore, host a larger\nnumber of species each with its own specific needs. In recent years\nthe relation is more often attributed to the belief that larger areas\ncan support larger populations of any\n species.[59]\n Thus fewer populations are likely to become extinct in a larger area\nthan a smaller one in any specified time interval.  Consequently, on\nthe average, more species are likely to be present in larger areas\nthan smaller ones even if both started with the same species\nrichness. \n\nWhether the species-area curve (rather than the mere qualitative\nrelation) has any empirical support remains a matter of\n contention.[60]\n In the 1950s, Preston was a strong advocate of the power law model\nwhich he believed to be the result of a dynamic equilibrium of the\nexchange of species between isolated habitat\n patches.[61]\n (The same idea had been worked out in some detail much earlier by\nMunroe but did not receive any\n attention.)[62]\n Preston's work was extended by MacArthur and Wilson to construct the\ntheory of island\n biogeography.[63]\n According to this theory, the number of species in islands with the\nsame habitat (at the same latitude) depends only on the size of the\nisland and its isolation. There is a dynamic equilibrium in the sense\nthat this number does not change over time though there is a turnover\nof species which changes the composition of the\n community.[64]\n The equilibrium is supposed to be a result of a balance between\nimmigration and extinction. The immigration rate varies inversely with\nthe degree of isolation while the extinction rate decreases with\narea. Thus, this theory incorporates the second mechanism for the\nspecies-area relation mentioned in the last paragraph. While some\ninitial experimental evidence seemed to support the theory, by the\nmid-1970s its status had become\n controversial.[65] \n\nNevertheless, in the 1970s, island biogeography began to be viewed as\na model for biological reserves which, by being surrounded by\nanthropogenically transformed lands, were supposed to be similar to\nislands—see the entry on\n conservation biology.\n The initially prevalent view, based on island biogeography theory,\nwas that reserves should be as large as\n possible.[66]\n In particular, one conclusion drawn from island biogeography theory\nwas that “[i]n cases where one large area is infeasible, it must\nbe realized that several smaller ones, adding up to the same total\narea as the single large one, are not biogeographically equal to it:\nthey will tend to support a smaller species\n total.”[67]\n Though this conclusion was incorporated into the design of the World\nConservation Strategy of the International Union for the Conservation\nof Nature, there was almost no data that ever supported\n it.[68]\n It was also challenged by Simberloff and Abele on both\ntheoretical and empirical\n grounds.[69]\n Among other things they pointed out that several small reserves may\nincrease the probability of the survival of species in the face of\nenvironmental stochasticity, for instance, random catastrophes such as\noutbreaks of infectious disease. This objection sparked the SLOSS\n(Single Large or Several Small) debate about the design of biological\nreserve networks. The SLOSS debate dominated discussions of reserve\nnetwork design for about a decade. Meanwhile the species-area curve\nalso began to generate serious skepticism. Soulé et\nal. predicted in 1979 from a model based on the species-area\ncurve that the Serengeti National Park of Tanzania will lose 50% of\nits large mammals (15 ungulate species) in 250\n years.[70]\n However, once Western and Ssemakula incorporated habitat diversity\ndata in 1981, it appeared that only 1 such species will go\n extinct.[71]\n There are many other such examples and it is hard not to sympathize\nwith Zimmerman and Bierregard who observe that, besides the ecological\ntruism that species richness increases with area, there is little of\nvalue in the species-area curve (and the theory of island\n biogeography).[72]\n In the context of biodiversity conservation, the relevance of the\nspecies-area curve, and island biogeography, has never been\nuncontroversially accepted. Important early criticism of the use of\nisland biogeography theory for reserve network design came from\nMargules and several collaborators in\n 1982.[73]\n They pointed out that the theory was yet to be empirically\nestablished in the field, that biological reserves were not very\nsimilar to islands because landscapes between reserves were not\ncompletely uninhabitable by the species in the reserves (unlike the\ncase of oceans separating islands), that habitats are largely\nheterogeneous rather than homogeneous (as assumed in the theory), and\nthat species richness should not be the only criterion used to select\nreserves. By 1986, it became clear that there would be no winner in\nthe SLOSS debate; since then there has been no unequivocal role for\nisland biogeography theory to play in the design of biodiversity\nreserve\n networks.[74]\n (For more on these issues, see the entry on \n conservation biology.) \n\nThe term “ecosystem” was coined in 1935 by Tansley who\ndefined it as “the whole system (in the sense of\nphysics) including not only the organism-complex [that is, the\ncommunity], but also the whole complex of physical factors forming\nwhat we call the environment of the biome—the habitat factors in\nthe widest\n sense.”[75]\n Tansley went on to argue that ecosystems “are the basic units\nof nature on the face of the earth.” For Tansley, using the term\n“ecosystem” implied a physical description of a community\nin its habitat. Even though that perspective still illuminates\necosystem studies (see below), it is no longer a necessary or even\ncommon connotation of the term “ecosystem.” However,\nindependent of the use of “ecosystem,” ecosystem ecology,\nin contrast to other ecological sub-disciplines, and in continuity\nwith its history, does retain an emphasis on physical processes.\nShould ecosystem ecology, then, be regarded as an instance of the\nunification of the physical and biological sciences? There has been so\nlittle philosophical attention to ecology that this question does not\nappear ever to have been broached. \n\nThe introduction and rapidly growing popularity of the term\n“ecosystem,” especially during the late 1950s and 1960s,\nwas marked by two major cognitive and one sociological shift in the\npractice of ecology: (a) coming at the end of the so-called golden age\nof theoretical population ecology of the late 1920s and 1930s (see\n Section 2),\n turning to ecosystems helped shift emphasis from\npopulations with interacting individuals to much larger and more\ninclusive systems. In this sense it was a deliberate\nanti-“reductionist”\n move.[76]\n Ecosystem enthusiasts follow a long holistic tradition in natural\nhistory that tends to deify complexity and deny the possibility of\nexplaining wholes in terms of their\n parts.[77]\n “Systems thinking” was supposed to replace\nreductionism, the decomposition of wholes into parts for the sake of\nanalysis (see\n Section 5);\n (b) a second cognitive shift is that ecosystem studies\ninvolve models based at least partly on\nnon-biological\n variables.[78]\n For instance, instead of tracking individuals or even species in\ncommunities, models may track energy or matter flow in food webs as a\nwhole; and (c) at the sociological level, the expansion of ecosystem\nstudies led to what one historian has called the invention of\n“big biology” in the 1960s, chiefly in the\n US.[79]\n These studies, for instance the massive Hubbard Brook\nEcosystem\n Study,[80]\n required more than just many biologists working together.  They also\ndemanded that other specialists, including geochemists and soil\nscientists, be brought in so that all the relevant physical parameters\nof ecosystems, besides the biological ones, could be tracked\nsimultaneously. This study constituted the biologists' attempt to\nengage in publicly-funded Big Science, initiated by the physicists\nduring the Manhattan Project, and subsequently profitably exploited by\nsocial scientists since the 1950s. \n\nUntil the last decade, some seventy years after the introduction of\nthe term “ecosystem” and forty years after a veritable\nexplosion of ecosystem studies, it was less than clear what important\nnew insights this disciplinary move produced. The trouble was that, at\nthis level of analysis, very few general claims could be sustained.\nThose that could—for instance, that Sun is ultimately the source\nof all energy in biological systems or that primary producers have to\ncontain chlorophyll or some other such molecule—were usually\ntrivial and well-known long before the initiation of systematic\nlarge-scale ecosystem studies in the 1960s. Usually ecosystem studies\nproduced detailed analyses of nutritional or climatic requirements of\nparticular communities. But the details of nutritional requirements\nwere either so general as to be almost irrelevant, or so specific that\nthey were rarely transportable from one ecosystem to another. Almost\nall of what is known about climatic requirements of vegetation types\n(and other communities) was known to biogeographers long before the\ninvention of ecosystem studies. The carbon and nitrogen cycles had\nalso been worked out long before the advent of ecosystem studies as an\norganized discipline. \n\nHowever, the physical characteristics of habitats do matter to\norganisms living in them. Moreover, physical changes on a global\nscale, for instance, climate change through global warming, have\nserious long-term implications for\n biota.[81]\n The changes other than climate change include increasing\nconcentration of carbon-dioxide in the atmosphere and changes in the\nbiogeochemistry of the global nitrogen cycle, besides changes in land\ncover and land\n use.[82]\n During the last decade, ecosystem studies and models have finally\nmatured to produce novel intellectual insights even about previously\nwell-characterized ecosystem processes such as the carbon and nitrogen\n cycles.[83]\n For instance, the effects of disturbance and fire on ecosystem\nprocesses are now being seriously\n assessed.[84] \n\nIn one interesting analysis—one among many—Ryan has used a\ncomplex model tying physiological processes to the physical\nenvironment to suggest that increased temperature will make\nmaintenance respiration (which represents the physiological costs of\nprotein synthesis and replacement, membrane repair, and the\nmaintenance of ion gradients in cells) for plants more\n difficult.[85]\n This is important because the total plant respiration, including\nmaintenance respiration, is an important component of the carbon\nbalance in any ecosystem. Ryan's model is based on observed\nstatistical associations of the different parameters; the underlying\nmechanisms resulting in the high sensitivity of maintenance\nrespiration to temperature change (as well as changes in many other\nphysical parameters such as carbon dioxide and protein concentrations)\nremain unknown. Ryan's result is important because of the ongoing\nclimate change through global warming. \n\nIn another example, Aerts and Chapin provide a systematic review of\nnutritional ecology of wild plants including nutrient-limited growth,\nnutrient acquisition, use efficiency, and recycling through\n decomposition.[86]\n This review underscores the conclusion that plant growth in\nterrestrial ecosystems is not only very often controlled by nitrogen\navailability in the nutrients but that it is also often similarly\ndependent on phosphorus availability. \n\nWhat has made much of the new work possible is not only increased\nexperience with ecosystems but also significant technical innovation,\nincluding the advent of high-speed microcomputers, satellite imagery,\nand Geographic Information Systems (GIS) which will be discussed next\n(in\n Section 5).\n The future of ecosystem ecology appears much more\nsecure today than it did a decade ago. \n\nThere have been two recent developments in ecology which are of\ngeneral philosophical interest; moreover, they help mitigate the\nproblems of complexity and uniqueness noted in\n Section 1.\n Both developments were made possible by the astronomical\nincrease in the speed and ease of computation since the early\n1980s. \n\nIn the type of population ecology that was discussed earlier (in\n Section 2),\n populations were characterized by their state variables,\nparameters such as size or density describing the population as a\nwhole and—with two exceptions—ignoring individual\ndifferences. The exceptions are age and stage; the age or stage\nstructure of populations (the fraction of individuals in each age or\ndevelopmental stage class) is sometimes incorporated in the\ntraditional models of population ecology. Since about 1980, that\nsituation began to change when the so-called “individual-based\nmodels” (IBMs), which incorporate individual differences, began\nto be explored\n systematically.[87]\n IBMs represent a population as a collection of individuals with\nvariable properties such as size, growth-rate, biomass, and so on. The\ninteractions between individuals are incorporated into the\nmodel. Since, because of their sheer complexity, such models are\ntypically impossible to study analytically, they are studied by\nsimulation on a computer. The wealth of detail that can be\nincorporated into IBMs allows specific predictions to be made. Part of\nthe attraction of IBMs has been their relatively greater predictive\nsuccess compared to other types of ecological\n models.[88] \n\nIBMs are particularly useful because they can also be spatially\nexplicit (see\n Section 5.2),\n that is, they can incorporate locational relationships between the\nindividuals being modeled. These models have even been used to assess\nchange on a global scale. For instance, forest models (which are among\nthe most successful IBMs) have been used to assess the result of\nclimate change on the atmosphere because of a potential breakdown of\nthe presumed balance between production and decomposition of\ncarbon-containing compounds. Such an extrapolation of scale relies on\nsampling each of the terrestrial lifezones and constructing some IBMs\nfor all of them, and subsequently integrating the\n results.[89]\n The future will show how reliable this strategy is. IBMs have also\nrecently begun to be used for population viability analysis, tracking\nthe trajectory of each individual during its\n lifetime.[90]\n This use is likely to grow. In both the situations discussed here,\nthe main problem with the use of IBMs is the immense quantity of\nreliable data that they require. \n\nWithin the context of population ecology, since the behavior of the\nentire population is putatively being explained on the basis of the\nproperties of the individuals within them, using IBMs is,\nphilosophically, a reductionist strategy called “methodological\n individualism.”[91]\n Here, “reductionism” means that models of large systems\nshould try to explain their behavior entirely in terms of the\nproperties of their parts (nowhere referring to intrinsically\n “systemic”[92]\n properties). More specifically, such a reductionism amounts to the\nassumption that properties and interactions of individuals alone\nsuffice to explain all behavior at the level of populations (and\nhigher units): there is no need to refer to higher level or systemic\nproperties which cannot be defined in terms of individual properties\n(for instance, the density of a population).  Moreover, since\ninteractions between individuals of different species can also be\nincorporated into these models, community-level properties can also\npotentially be explained by IBMs. For instance, the structure of food\nwebs can potentially be explained by IBMs that take into account\nhabitat size and\n resources.[93]\n Thus, even community structure is potentially reducible\nto individual interactions. In this sense, community ecology, like\npopulation ecology, is also being reduced to\n IBMs.[94]\n In this way, IBMs are unifying at least these two subfields within\necology. Demarcation ambiguity is not a problem for IBMs; rather, it\nis a virtue. It remains surprising how little philosophical attention\nIBMs have so far received. If they succeed, they will help end the\nlong and, at least arguably, sterile tradition of anti-reductionism\n(or holism) in ecology. \n\nNevertheless, an important limitation of IBMs should not go unnoticed:\nmodels of this type—that is, all models that have to be analyzed\nby computer simulation—have the shortcoming that they often fail\nto provide theoretical insight in the sense of identifying the\ncritical heuristics or principles that are responsible for a type of\nbehavior. Are the dynamical rules responsible for some behavior? Or\nthe structural constraints, such as the initial conditions? Or the\nprecise parameter values? To answer such questions—which is at\nleast part of what theoretical understanding consists\nof—minimally requires the simulation of a large class of related\nmodels, often hard to achieve in practice. It remains the case that\nthese questions can often easily be answered using traditional\nmathematical models: an ounce of algebra may well be worth a ton of\ncomputer simulation. Thus any defense of reductionism in ecology based\non IBMs must be very limited. \n\nWhat has perhaps the greatest potential for altering the shape of\necology is the advent of Geographic Information Systems (GIS) which\nenables the detailed spatial representation and rapid manipulation of\ngeographical data on computers. GIS came along at a time when\necologists had already begun to explore the role of spatial structure\non the dynamics of populations, communities, and ecosystems. Within\nspatial ecology these were represented as entities having spatial\nrelations with each other, besides the traditional ecological\nrelations defined by their interactions. However, before GIS,\ntractable models required the idealization of uniform geometries (even\nin IBMs). The advent of GIS allowed the replacement of this\nidealization with more veridical spatial relations. Since philosophers\nof science have so far paid little attention to the history or\nimplications of GIS technology, the discussion here will be somewhat\nmore detailed than the treatment of other aspects of ecology. \n\nGIS originated in sparsely-populated Canada which, until the 1950s, at\nboth the federal and provincial governmental levels, viewed land and\nother resources as unlimited. The late but inevitable realization that\nthis was not the case led the Canadian federal government to initiate\na national inventory of land and other natural resources. The purpose\nof what was christened as the “Canadian Geographical Information\nSystem” in 1963-64 was to analyze data collected by the Canada\nLand Inventory (CLI) to produce statistics that could be used to\ndevelop land management plans for effective resource utilization in\nlarge areas of rural\n Canada.[95]\n The CLI produced seven maps classifying\n land.[96]\n Constructing the CGIS meant developing techniques for the rapid\nhandling and analysis of these maps and the data on which they were\nbased. Today's commercial packages GIS parasitize key conceptual and\ntechnical innovations of the CGIS. At the technical level, when the\nCGIS project was initiated, there was no prior experience on how to\nstructure geographical data internally (within the computer); there\nwere no techniques for the overlay of maps or for calculating area. An\nexperimental scanner to scan map data had yet to be built. \n\nAmong conceptual innovations, the most important was the distinction\nbetween: (a) the data used to draw the polygons forming the boundary\nof a place (locational information); and (b) the set of features it\nhas, that is, its attributes. Polygons need not have the same size or\ngeometry. When ecological populations and communities are modeled in a\nGIS framework, explicit asymmetric irregular spatial information can\nbe incorporated without unrealistic simplifying assumptions such as\nthat of representing the spatial structure as a square or some other\nregular geometric grid. The exploitation of this possibility takes\nspatially explicit ecological modeling beyond its traditional confines\nin which the only spatial structures that could be considered are\nthose with regular geometries. Though GIS-based ecological modeling is\nstill in its infancy (and an early example will be discussed in the\nnext paragraph), it is clear that these techniques will allow the\nconstruction of spatially-explicit ecological models at a level of\ndetail that was impossible before. Moreover IBMs can now be\nconstructed with such detailed spatial representation. The confluence\nof IBMs and GIS is arguably the most fecund area of ecological\nmodeling today. \n\nEqually as important as the distinction between polygon and attribute\nwas the decision to “vectorize” the scanned\nimages. Scanned images gave “raster” data, that is, data\nin the form of regular grid points which either do or do not possess a\nspecific property, for instance, the presence of a given vegetation\ntype. Vectorization is the replacement of these point-based structures\nby lines that are naturally interpreted (such as boundaries of habitat\ntypes). What is critical is that these lines can then be joined to\nform polygons. Raster data can be obtained from a variety of sources\nincluding maps and photographs; in the present context what is\ncritical is that raster data can be obtained by remote sensing through\nsatellite imagery from which the distribution of many vegetation and\nsoil types can be inferred. As early as 1989 Running and several\ncollaborators estimated the annual evapotranspiration and net\nphotosynthesis for a 28 ´ 55 sq km region of Montana using a GIS\nsoftware\n package.[97]\n The study region was divided into 1.1 ´ 1.1 sq km cells defined\nby satellite sensor pixel size. The GIS package was used to integrate\ntopographic, soil, vegetation and climatic data from a variety of\nsources including the results of remote sensing. Ecological\nassumptions entered into the models that were then used to predict\nevapotranspiration and net photosynthesis. The results obtained were\nin fairly good agreement with field data. \n\nWithin ecology the use of GIS-based models is the analog of visual\nmodeling in other\n sciences.[98]\n It is no longer controversial that visual representation, at least as\na heuristic, offers resources for scientific innovation not offered by\npurely linear representations (such as linguistic or mathematical\nrepresentations). GIS-based models constitute two-dimensional visual\nrepresentations of ecological systems. It is likely that these\nrepresentations incorporate spatial insights that will result in new\nand fecund directions for ecological modeling to take. \n\nNevertheless, what is somewhat philosophically troubling about the use\nof GIS in ecology is the conceptualization and representation of\ngeographical information as: (a) a linked set of places, linked in the\nsense that the places must maintain fully precise adjacency relations;\nbut (b) an unlinked set of attributes (for instance, the presence or\nabsence of species or other biological features). There is something\ndisarmingly natural about this: it certainly seems to capture the\ngeographical rootedness in place that lies at the basis of planning\nfor biodiversity conservation. But this choice of representation has\nits costs: the mode of representation which is at the core of GIS\nmakes it “natural” to represent systems in such a way that\ncertain types of relationships tend to get lost, or at least relegated\nto the background, while others receive emphasis. Consider the\nfollowing example. Carnivores cannot be present at any place unless\nprey species also exist. This trivial and obvious ecological fact\ncannot be explicitly represented using the standard resources of any\nGIS package (that is, it cannot be represented without writing special\nprograms).  Attributes are represented without relations between\nthem. This encourages, though does not require, analyses that do not\nuse relations between attributes. (Obviously, one can start with a\nGIS-based representation and add other relations as part of the\nsuperstructure of the model.) Philosophers of science have long known\nthat modes of representation influence the introduction and\ndevelopment of conceptual systems based on them. GIS may have such an\ninfluence through representational choices that guides ecology down a\npath where relations between attributes receive less emphasis than\nthey would in traditional ecological models. \n\nThe diversity of the conceptual issues discussed in this entry\npreclude any compelling general conclusions to be drawn at this stage\nof the development of the philosophy of ecology. Even the defense of\nreductionism in ecology using IBMs can with so many attendant\nqualifiers that it cannot be regarded as an unequivocal endorsement.\nThat GIS models seem to introduce a new type of visual representation\nin the sciences is another conclusion that requires similar\nqualification and further scrutiny before it is accepted. It should\nalso be clear from the preceding discussion that ecology may\nprovide a fertile ground for the exploration of concepts of complexity\nand systematicity that have recently begun to engage philosophers and\nscientists\n alike.[99] \n\nHowever, the inability to draw general philosophical conclusions about\necology is at least as much due to the relative lack of philosophical\nscrutiny of ecology as it is due to the nature of the subject. Even\nwithin the philosophy of biology, ecology has received little\nattention compared to other sub-disciplines of biology, especially\nevolution, and, lately,\n development.[100]\n Ecology deserves better. As this entry has emphasized, there are many\nfoundational and conceptual issues within ecology that can be\nclarified and better framed through carefully philosophical\nanalysis. The diversity-stability problem is exemplary in this\nrespect.  The relevance of ecology to human well-being and\nbiodiversity should also be obvious— see\n conservation biology\n and\n environmental ethics.\n But, even leaving aside these narrower considerations, ecology\nprovides ample opportunity to illuminate general questions about many\nof the traditional themes of the philosophy of science: complexity,\ncontingency, holism, lawlikeness, reductionism, representation,\netc. This entry is an invitation to philosophers to take an active\ninterest in ecology."}]
