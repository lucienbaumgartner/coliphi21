[{"date.published":"2004-06-18","date.changed":"2020-12-23","url":"https://plato.stanford.edu/entries/content-teleological/","author1":"Karen Neander","author2":"Peter Schulte","author1.info":"http://fds.duke.edu/db/aas/Philosophy/kneander","entry":"content-teleological","body.text":"\n\n\nConsider, for example, the thought that blossoms are forming. On a\nrepresentational theory of thought, this involves a representation of\nblossoms forming. A theory of mental content aims to tell us, among\nother things, why this representation has this content, and so why it\nis a thought about blossoms forming, rather than about the sun\nshining, pigs flying, or nothing at all. In general, a theory of\nmental content tries to explain why mental states, events or processes\n(or, assuming a representational theory of them, the mental\nrepresentations involved) count as having the contents they have.\n\n\nAccording to teleological theories, the contents of mental\nrepresentations depend, at least in part, on functions, such as the\nfunctions of the systems that use or produce them. The relevant notion\nof function is held to be one used in biology and neurobiology in\nattributing functions to items, as in “a function of the pineal\ngland is secreting melatonin” and “a function of brain\narea MT is processing information about motion”. Proponents of\nteleological theories of mental content usually understand these\nfunctions to be what the items with the functions were selected for,\neither by phylogenetic natural selection or by some other similar\nprocess. As discussed below, such functions are characterized as being\nin some sense both normative and teleological.\n\nMany (perhaps all) mental states are about things, or are directed on\nto things, in the way that a belief that spring is coming is about\nspring coming, or in the way that a desire for chocolate is directed\non to chocolate. The philosopher Franz Brentano (1838–1917)\nspoke of such mental states as involving presentations of the objects\nof our thoughts. The idea was that we couldn’t desire chocolate\nunless chocolate was in some way presented to our minds. We might\ninstead say that chocolate must be represented in or by our minds if\nit is chocolate that we desire. Teleological theories of mental\ncontent, like other theories of mental content, attempt to solve\nBrentano’s problem, assuming that is broadly understood as the\nproblem of explaining how mental states can be about things, directed\non to things, or represent things. \nSolving Brentano’s problem is sometimes regarded as, not just\nvery difficult, but impossible. This alleged impossibility is one\nreason someone might think that some mental phenomena are among the\nunexplained explainers of the universe. \nArguments for this view have been offered at least since Abelard\ncriticized Aristotle’s theory of intentionality, and are\nvarious. A stark and simple argument to this effect, often attributed\nto Brentano, but perhaps more correctly attributed to Roderick\nChisholm (1957), concerns thoughts about non-existent objects.\nChisholm argued that the aboutness (or intentionality) of mental\nstates cannot be due to a physical relation between a mental state and\nwhat it is about (its intentional object), because, in the case of a\nphysical relation, all of the relata must exist, while the\nintentional objects of mental states might not exist. If the sun\nshines on a garden, then both the sun and the garden must exist. If\nwater streams down a hill, there must be the water and the hill. In\ncontrast, Billy can love Santa and hope to meet a unicorn, even if\nSanta does not exist and there are no unicorns. \nOne obvious suggestion in response to this worry is that mental\nrepresentations of things that don’t exist could be composed of\nrepresentations of things that do exist. Perhaps concepts of unicorns\nare composed of concepts of horses, horns, foreheads, and so on. There\nare indeed reasons to think that we will need to explain some concepts\nas depending on other concepts, yet this general strategy also faces\nnotorious difficulties. Among these are those raised by the Quinean\ncritique of meaning and analyticity, and the Kripkean problems of\nerror and ignorance. It is also up for debate whether even some of the\nsimplest of mental representations could have empty contents, and so\nnothing actual in their extensions. These are quite complex issues\nthat, given space considerations, cannot be explored here, but they\nform an important part of the philosophical background, since\nteleological theories of mental content are primarily concerned with\noriginal intentionality. That is, they are primarily concerned with\nintentionality at its most fundamental, or, in other words, with\nintentionality that does not derive from other intentionality.\nHowever, there is disagreement, among both proponents and\nnon-proponents, regarding which intentional phenomena have original\n(as opposed to derived) intentionality. \nOne might conclude, along with Chisholm, that it is hard to see how\nintentionality can be a physical phenomenon. In contrast, those who\noffer teleological theories usually adopt a physicalist framework, and\naim to give a naturalistic theory, or in other words a theory that is\nconsistent with the natural sciences and their presumed working\nassumption that neither intentionality nor consciousness is\nontologically fundamental. Most teleological theories try to show how\nintentionality, at its most fundamental, can be part of the natural\nworld, by showing how it can be understood as deriving from other\n(non-mental) natural things. \nA theory of mental content nevertheless needs to account for what is\nfrequently referred to as the “normative” nature of mental\nrepresentation. We may evaluate beliefs as true or false, memories as\naccurate or inaccurate, perceptions as veridical or illusory, desires\nas satisfied or not satisfied, and motor instructions as correctly or\nincorrectly executed. Certain mental states count as true or false\n(etc.) by virtue of their contents, as well as by virtue of other\nthings (such as the actual state of the world). For example, the truth\nof a belief that today is sunny depends on whether it is sunny, but\nalso on it being a belief that today is sunny. If the content of the\nbelief were different (e.g., if it were a belief that today is hot)\nthen its truth value might be different. The “normative”\nnature of mental content poses at least a prima facie problem for all\nnaturalistic theories of it, given the Humean warning against trying\nto derive prescriptive from descriptive facts. Teleological theories\nshare the strategy of explaining the norms pertaining to mental\ncontent as deriving from so-called functional “norms”,\nwhich are regarded as descriptive rather than prescriptive. I return\nto this in the next section. \nIn relation to the “normative” nature of mental content,\nmuch attention is paid to the possibility of misrepresentation, since\nthe distinction between correct and incorrect representation is\narguably central. In fact, a capacity for misrepresentation is often\nregarded as essential for genuine representation (see esp. Grice\n1957). To see why, it might help to consider a mental representation\nthat has all and only cats in its extension. In order for it to have\nthis extension, it must be the case that, if the representation were\napplied to a non-cat, such as a dog, in certain contexts (such as in\nassertoric labeling contexts) then it would count as misrepresenting\nit. \nCases of misrepresentation reveal that representing can involve a\nrepresentation, its target on a given occasion, and also its content.\nSuppose that, on a particular occasion, you see out of the corner of\nyour eye some crumpled paper blown by the wind, and see it as a cat\nslinking down the street. There are at least three things involved.\nFirst, there is the mental representation that does the representing.\nIn this case, assuming physicalism, we may suppose that it involves\nsome sort of neurological state, event or process in you. In this\nentry, mental representations are denoted by capitalized English\nexpressions that have corresponding contents. So, on this particular\noccasion, a CAT representation was tokened. Second, there is what the\nrepresentation is aimed at representing. On the occasion just\nmentioned, the CAT representation was aimed at representing the\ncrumpled paper blown by the wind. Cummins (1996) calls this the\ntarget of the token representation. Third is the content of\nthe representation. CAT-representations have all and only cats in\ntheir extension. Thus we might say that the content of CAT is\ncat. Misrepresentation has occurred on this occasion because\nthere is a mismatch between the target and the content. The paper, the\ntarget, is not in the extension of the CAT representation. A theory of\nmental content attempts to describe the relation that holds between a\nmental representation and its contents, or whatever grounds the fact\nthat the mental representation has that content. \nClearly, there are other aspects of mental representation on which a\ncomprehensive theory of mental representation might focus, and these\ndo not exhaust the questions that one might profitably ask, but it\nhelps to distinguish the following three key questions. (1) The\nquestion of representational status: In virtue of what do mental\nrepresentations count as representations? (2) The question of target\ndetermination: Why do mental representations count as having the\ntargets that they have on specific occasions of use? (3) The question\nof content determination: in virtue of what do mental representations\nhave the contents they have? What determines their extensions? For\nexample, why does the aforementioned CAT-representation count as a\nrepresentation? Why (to continue with the same example) did the\ncrumpled paper count as the target of its tokening on that occasion?\nWhat makes it the case that a CAT representation has the content\ncat? Why (in virtue of what) do all and only cats belong in\nits extension? One can offer teleological theories in answer to all of\nthese questions, but, as the name implies, teleological theories of\nmental content are primarily concerned with the third,\ncontent-determination, question. \nA distinction is sometimes made between representation of and\nrepresentation as. Whether or not teleological theories of\ncontent are concerned with representation as or of\ndepends on how those locutions are being used. Suffice it to say that\nthe teleological theories generally offer theories of referential\ncontent, rather than of cognitive content or mode of presentation. \nFurther, the proponents of teleological theories rarely believe that\nreferential content is a kind of narrow content, and so they are not\nusually offering theories of narrow content. How to characterize\nnarrow content is controversial, but the proponents of teleological\ntheories tend to agree with those who think that two beings (e.g., two\npeople or two creatures) who are physical replicas at a time\nt “from the skin in”, so to speak, can differ in\nthe referential contents of their mental states at t. Of\ncourse, this view is also shared by plenty of other philosophers, who\nthink that mental reference to content supervenes (in part) on things\nthat are external to the individuals whose mental states are in\nquestion, such as on features of their social or physical environments\nand/or learning histories (perhaps for the reasons given by Putnam\n1975 and Burge 1979, 1986). Still, a teleological theory of mental\nreference to content could be combined with the view that there is\nalso a useful notion of narrow content. Teleological theories of\nmental content (unlike most theories of narrow content) generally try\nto give (largely) non-revisitionist accounts of psycho-semantic norms.\nThat is, they generally try to accommodate the actual semantic\nevaluations made in the relevant domain (e.g., in folk psychology or\nin scientific psychology, depending on the particular theory). A\nsuccessful theory along those lines could leave open the question of\nwhether such evaluations need supplementing or revising, and whether a\nnarrow notion of content is needed as well or instead. \nTeleological theories of mental content are not usually theories about\nhow we grasp meanings, understand them, or are conscious of them.\nAccounts of such sophisticated mental states as these would typically\npresuppose that there are intentional mental states, whereas\nteleological theories of mental content try to explain the nature of\nintentionality at its most fundamental; they aim to say how we can\nhave mental representations with content. \nA final point about broad aims is that teleological theories of mental\ncontent are usually intended as real nature theories. Those who offer\nreal nature theories of intentional mental states think that our\neveryday ability to recognize the intentional mental states of\nourselves and others does not make us experts on the fundamental\nnature of these intentional mental states, any more than our everyday\nability to recognize water makes us experts on the fundamental nature\nof water. Teleological theories of mental content do not entail that,\nif Bill thinks that Mavis knows that today is Tuesday, then Bill must,\nin so thinking, be thinking about certain teleological functions\npertaining to Mavis’s cognitive system. \nWhile teleological theories of mental content are quite diverse, they\nall share the idea that psycho-semantic norms depend, in part at\nleast, on functional norms. Later sections explain various ideas about\nthe nature of this dependence. This section describes the notion of\nfunction employed. It is generally thought to be in some sense both\nteleological and normative, but both “teleological” and\n“normative” need qualifying, and the use of these terms\ncan lead to unnecessary misunderstanding. Let’s take the first\nof these terms first. \nTalk of biological functions does often seem to have at least a\nteleological flavor. For example, to say that it is the function of\nthe heart to pump blood can seem equivalent to saying that hearts are\nfor pumping blood, or that hearts are there in order\nto pump blood (see esp. Wright 1972). There is also a closely\nrelated concept of an artifact’s function that appears to be\npurposive: for example, when we say that moving the cursor is the\nfunction of the computer’s trackpad, we might mean that this is\nwhat it was designed to do or was intended to do by the\ncomputer’s designer or user. Of course, if a teleological theory\nof mental content is to be a non-circular theory of original\nintentionality, the functions to which it appeals, as grounding\noriginal intentionality, cannot in turn depend on other intentional\nphenomena. (Some, but not all, prefer to use the term\n“teleonomic” in that case.) \nSome theorists, even some who favor teleological theories of mental\ncontent, have occasionally spoken as if “Mother Nature”\nitself were intentional or purposive. This can be confusing, when\nstacked up against the naturalistic aims mentioned above. The apparent\nconflict can be resolved by a weakening of the naturalistic aims, or\nby a weakening of the claim concerning nature itself being intentional\nor purposive. For example, Dennett (in his 1988) has spoken in this\nway, but this was a time when he also seemed to support an\ninstrumentalist view of even our intentionality. Millikan has also (in\nher 2002) used “biological function” and “biological\npurpose” as synonyms. Her aims are clearly naturalistic, but her\nchoice of words does not seem meant to dispute the substance of the\npreceding paragraph, and so her talk of “biological\npurpose” should probably be interpreted as merely metaphorical\nrather than literal. \nThe claim that the relevant notion of function is in some sense\n“normative” should also be read with care. What is meant\nby it is generally just that, when using this notion, we (and\nbiologists) may speak of systems functioning normally or properly, as\nwell as of abnormal functioning, malfunction, dysfunction, functional\nimpairment, and so on. The relevant notion of function is one that\npermits the possibility of malfunction. That is, it allows for the\npossibility that a token trait could have a function to do Z\neven if it lacks the disposition to do Z. For example,\nJoe’s pineal gland could have the function to secrete melatonin\neven if it cannot secrete melatonin because it is malfunctioning.\nWhether it is appropriate to describe the notion as genuinely\n“normative” is unclear, since it is unclear what genuine\nnormativity requires. But all that is usually meant by saying that the\nrelevant notion of function is normative, at least by proponents of\nteleological theories of mental content, is that the relevant notion\npermits the possibility of malfunction, and underwrites the central\nfunction/dysfunction distinction employed in biology. \nRecall that, as mentioned earlier, the relevant functional norms are\nunderstood by proponents of teleological theories of mental content to\nbe descriptive rather than prescriptive. Some prefer to reserve the\nterm “normative” for prescriptive contexts. On that way of\nspeaking, a statement would count as normative only if it entailed an\nought-claim without the addition of further premises. Proponents of\nteleological theories of mental content may all agree that no\nought-claim follows from a function ascription without the addition of\nfurther premises (for discussion, see Jacob 2001), and thus that the\nrelevant function ascriptions are not prescriptive and hence are not\ngenuinely “normative” if that is what normatively\nrequires. Different terminological practices dominate different\ndiscourses, but it is worth remembering that talk of purely\ndescriptive “norms” is well established in some contexts\n(e.g., in talk of statistical norms). If either psycho-semantic or\nfunctional norms were prescriptive, the attempt to naturalize them\nwould seem to ignore Hume’s warning to beware trying to derive\nought-statements from is-statements, but those who\noffer teleological theories of mental content claim that the norms of\nboth functions and content both fall on the is side of any\nis/ought divide. \nThose who favor teleological theories of content usually favor an\netiological theory of functions, according to which an item’s\nfunction is determined by its history of selection or by past\nselection of things of that type. Roughly, on an etiological theory of\nfunctions, an items function is what it was selected for, or what\nthing of the type were selected for. \nWright (1973, 1976) offered the first developed defense of an\netiological theory of functions by a philosopher but earlier\nexpressions of the idea can be found in the writings of some\nbiologists (e.g., Ayala 1970). Wright’s (1976, p. 81) proposed\nanalysis is as follows. \nWright intended this formula to work for a wide variety of function\nascriptions; for artifacts as well as the parts of organisms, and for\nfunction ascriptions in Creationist as well as Evolutionary biology.\nFor this reason, he intended the “does” of the second\nrequirement to be tenseless. Thus the second requirement is intended\nto be read as requiring that X be there because it does, did\nor will do Z. The precise tense would depend on the nature of\nthe relevant consequence etiology, the causal history that explains\nX being there because of its effect, Z. \nThe details of this formula are often regarded as problematic. For\ninstance, it is unclear how it renders malfunction possible, given the\nfirst requirement. The second requirement is also too loose to capture\nonly function-conferring consequence etiologies. As Wright (2010)\nconcedes, if a man’s gripping a pole were to cause electricity\nto run through him and this prevented him from letting go of the pole,\nthen his original analysis entails that the function of the\nman’s holding on to the pole is to allow electricity to run\nthrough him. In light of this problem, Wright has amended his analysis\nby proposing that what is needed is a particular kind of consequence\netiology, a “virtue etiology” in which the consequence\nimplicated in the etiology must be a “virtue”. In the case\nof functions derived from natural selection, he views a\n“virtuous” consequence as an adaptive consequence. \nOthers who offer etiological theories of function drop Wright’s\nfirst requirement and speak more specifically of selection as the\nbackground process that is responsible for the consequence etiology.\nOn this view, a/the function of an item is (roughly) what it (or items\nof the type) were selected for. Millikan (1989a) and Neander (1991)\nargue that an analysis of functions along these lines need not be\nunderstood as an ordinary language analysis. Neander bases her\nproposal on function ascriptions of biologists, precisified by\nbackground theory. In her paper of 1991 (p. 74), she gives the\nfollowing definition for functions in physiology: \nEtiological theories of biological function need to allow for the fact\nthat ancestral traits might have been selected for something other\nthan the present function of descendent traits. For example, a\npenguin’s flippers and an emu’s vestigial wings no longer\nhave the function of flight, even though ancestral forelimbs were\nselected for flight. Griffiths (1993) and Godfrey-Smith (1994) offer\n“modern history” versions of the etiological theory,\naccording to which functions are determined by recent selection. Note\nthat selection does not cease when traits “go to fixation”\nif on-going maintenance selection is still weeding out fresh harmful\nmutations as they arise. However, selection does require some\nvariation and Schwartz (1999) suggests that a continuing usefulness\nsupplement is needed, which kicks in if variation is absent for a\ntime. In the absence of any variation, the trait retains its function\nif it is still adaptive. \nA further issue is whether the etiological theory is circular (see\ne.g., Nanay 2011). The worry is that, if a trait token is typed by its\nfunction and if a trait’s function depends on the selection\nhistory that pertains to the relevant type, the analysis is circular.\nNeander and Rosenberg (2012) respond that the function of a trait and\nits function-specific type co-supervene on the history of selection\nand that there is only a superficial appearance of circularity. To\nfigure out if token trait X has the function to Z,\nthey say, first identify the lineage of traits to which X\nbelongs; a lineage of traits connects ancestral and descendent traits\nby the mechanisms responsible for inheritance. Then segment the\nlineage at those places where selection for Z stops and\nstarts. X has the function to Z only if there was\nselection for X-ing in X’s segment of the\nlineage. This procedure does not presuppose prior knowledge of\nX’s function or prior knowledge of X’s\nmembership in a function-specific classification of traits. This is\nalso an alternative proposal for handling vestigiality. \nTo play a role in a naturalistic account of mental content, the\nrelevant selection process must be non-intentional but it need not be\nnatural selection operating over an evolutionary span of time.\nMillikan (1984) offers an etiological theory of functions on which\nfunctions can also result from meme selection. Papineau (1984) speaks\nof learning and Dretske (1986) invokes functions that depend on\nrecruitment by conditioning. Garson (2011) argues that the notion of\nselection should be loosened so that differential retention without\ndifferential replication could count as selection, in which case\nneural selection could count as a form of selection that could\nunderwrite the functions that underwrite content. While the contents\nof sensory-perceptual representations might be determined by the\nfunctions that derive from natural selection operating over an\nevolutionary span of time, the role of learning in concept acquisition\nsuggests that other kinds of functions that derive from other kinds of\nselection might be needed for the contents of learned concepts. There\nis, though, no established agreement about how best to more broadly\ndefine the relevant class of functions. \nWhile etiological theories dominate the discussion of normative\nfunctions in philosophy of biology, the etiological theory is not\nuncontroversial. Some question whether teleology can be naturalized\n(e.g., Bedau 1991). Others support other theories for other reasons.\nPerhaps the systemic theory is the most popular alternative (see esp.\nCummins 1975). Systemic theories of function emphasize the role of\nfunction ascriptions in functional analyses of systems. Functional\nanalyses of systems conceptually decompose complex activities of whole\nsystems into the activities of their contributing parts. The function\nof a part is its contribution to the complex activity of the system\nthat is under analysis. Proponents of the etiological theory have no\nobjection to the idea that biologists give functional analyses of\nsystems but contend that the systemic analysis, on its own, fails to\nnaturalize the normativity of functions or to do so successfully. Some\nwho support a systemic theory argue that biology has no need for a\nnaturalistic notion of malfunction (e.g., Davies 2001), while others\nargue that abnormal functioning is statistically atypical (Boorse\n2002, Craver 2001, Lewens 2004). (Readers who would like to read more\non this and other theories of function could turn to several volumes\nof readings that have appeared: see esp. Allen, Bekoff & Lauder\n(1998), Buller (1999) and Ariew, Cummins & Perlman (2002).) \nIt is usual to note that etiological (teleological) functions are\ndistinct from the causal-role functions involved in what is usually\ncalled “functionalism” in philosophy of mind. Causal-role\nfunctions are often defined as a select subset of a trait’s\nactual causal dispositions, and functionalism is often defined as the\nview that mental states are individuated or classified into types on\nthe basis of such dispositions (see, e.g., Block 1984). If causal-role\nfunctions are a subset of dispositions actually possessed by token\ntraits then they do not permit the possibility of malfunction because\na trait cannot have the causal-role function to Z and at the\nsame time lack the disposition to Z. \nThat said, the distinction between functionalism and what might be\ntermed “teleo-functionalism” is less stark than might be\nthought. One reason is that formulations of classical functionalism\noften spoke of the characteristic or normal causal\nroles of mental states. Sometimes this was explicitly to allow for\npathology (see, e.g., Lewis 1980). Another reason is that, although\nteleological functions are often said to be selected effects or\neffects for which traits were selected, such functions can also be\ndescribed as selected dispositions or dispositions for which traits\nwere selected. Both forms of functionalism also permit multiple\nphysical realizability of traits that perform the same functions. \nWhat all teleological (or “teleosemantic”) theories of\nmental content have in common is the idea that psycho-semantic norms\nare ultimately derivable from functional norms. Beyond saying this, it\nis hard to give a neat definition of the group of theories that\nqualify. \nConsider, for instance, some theories that are clearly intended as\nalternatives to teleosemantics, such as Fodor’s (1990b)\nasymmetric dependency theory or theories that appeal to convergence\nunder ideal epistemic conditions (see Rey 1997 for an outline).\nElaboration of these theories is beyond the scope of this entry but we\ncan note that they both seem to need a notion of normal or\nproper functioning. Fodor’s theory adverts to the\n“intact” perceiver and thinker. Presumably this is someone\nwhose perceptual and cognitive systems are functioning properly (this\nis covered under the ceterus paribus part of the laws to\nwhich Fodor’s theory refers). The idea of convergence under\nideal epistemic conditions also involves a notion of normal\nfunctioning, for epistemic conditions are not ideal if perceivers and\nthinkers are abnormal in certain respects, such as if they are blind\nor psychotic. If normal or proper functioning is analyzed in terms of\nan etiological theory, which says that a system functions normally or\nproperly only if all of its parts possess the dispositions for which\nthey were selected, then these theories would qualify as teleological\ntheories of mental content under the characterization provided in the\nfirst paragraph of this section. Those who propose these theories\nmight reject an etiological theory of functions, but they need some\nanalysis of them. There could anyway be etiological or teleological\nversions of theories of this sort. \nAn appeal to teleological functions can also be combined with a\nvariety of other ideas about how content is determined. For example,\nthere can be both isomorphic and informational versions of\nteleosemantics. In the former case, the proposal might be that the\nrelevant isomorphism is one that cognitive systems were adapted to\nexploit. An alternative idea is that the isomorphism does not need to\nbe specified given that the targets of representations are determined\nby teleological functions. This appears to be the view of Cummins\n(1996, see esp. p.120) although Cummins is generally critical of\nteleological functions in biology. A teleological version of an\ninformational theory is given when content is said to depend on\ninformation carrying, storing or processing functions of mechanisms.\nThe relevant notion of information is variously defined but (roughly\nspeaking) a type of state (event, etc.) is said to carry natural\ninformation about some other state (event, etc.) when it is caused by\nit or corresponds to it. \nIt is sometimes said that the role of functions in a teleological\ntheory of content is to explain how error is possible, rather than to\nexplain how content is determined, but the two go hand in hand. To see\nthis, it helps to start with the crude causal theory of content and to\nsee how the problem of error arises for it. According to the crude\ncausal theory, a mental representation represents whatever causes\nrepresentations of the type; Rs represent Cs if and\nonly if Cs cause Rs. One problem with this simple\nproposal is its failure to provide for the possibility of\nmisrepresentation, as Fodor (1987, 101–104) points out. To see\nthe problem, recall the occasion on which crumpled paper is seen as a\ncat. The crude causal theory does not permit this characterization of\nthe event because, if crumpled paper caused a tokening of CAT then\ncrumpled paper is in the extension of CAT, according to the\ncrude causal theory. Since cats also sometimes cause CATs, cats are in\nthe extension too. However, the problem is that crumpled paper is\nincluded in the extension as soon as it causes a CAT to be tokened and\nso, on this theory, there is no logical space for the possibility of\nerror since candidate errors are transformed into non-errors by their\nvery occurrence. Note that the problem is simultaneously one of ruling\nin the right causes without also ruling in the wrong ones. CAT cannot\nhave the content cat unless non-cats (including crumpled\npaper) are excluded from its content. So explaining how content is\ndetermined and how the possibility of error are accommodated are not\nseparate tasks. \nThe error problem is an aspect of what (after Fodor) is often called\n“the disjunction problem.” With respect to the crude\ncausal theory, the name applies because the theory entails disjunctive\ncontents when it should not. For example, it entails that CATs have\nthe content cats or crumpled paper in the case just\nconsidered. The disjunction problem is larger than the problem of\nerror, however, because it is not only in cases of error that mental\nrepresentations are caused by things that are not in their extensions\n(Fodor, 1990c). Suppose, for example, that Mick’s talking about\nhis childhood pet dog reminds Scott of his childhood pet cat. In this\ncase no misrepresentation is involved but the crude causal theory\nagain entails inappropriate disjunctive contents. Now it entails that\nScott’s CATs has a content along the lines of cats or talk\nof pet dogs. This last aspect of the disjunction problem might be\ncalled the problem of representation in absentia: how do we\nexplain our capacity to think about absent things? How do mental\nrepresentations retain or obtain their contents outside of perceptual\ncontexts? \nAsking how to alter the crude causal theory to allow for error is one\nplace to begin looking for a more adequate proposal. One approach\nwould be to try to describe certain situations in which only the right\ncauses can produce the representation in question and to maintain that\nthe content of the representation is whatever can cause the\nrepresentation in such situations. This is sometimes referred to as a\n“type 1 theory.” A type 1 theory distinguishes between two\ntypes of situations, ones in which only the right causes can cause a\nrepresentation and ones in which other things can too. A type-1 theory\nsays that the first type of situation is content-determining. A type 1\nteleological theory might state, for example, that the content of a\nperceptual representation is whatever can cause it when the perceptual\nsystem is performing its proper function, or when conditions are\noptimal for the proper performance of its function. The content of\nrepresentations in abstract thought might then, it might be proposed,\nbe derived from their role in perception. Not all teleological\ntheories of content are type 1 theories, however. The theory described\nin the next section is arguably a variant of a type 1 theory but some\nof the theories described in later sections are not. \nThe following sub-sections describe some key differences among\nteleological theories. It is not possible to describe all extant\ntheories but some different approaches are sketched, along with a\nbrief review of some of their strengths and weaknesses. General\nobjections to teleological theories are discussed later, in\n section 4. \nStampe (1977) was one of the first philosophers in modern times to\nsuggest a theory of content according to which content is a matter of\nreliable causes. Dretske’s book, Knowledge and the Flow of\nInformation (1981) has also been very influential. The theory\nDretske develops in that book is not a teleological theory of mental\ncontent but Dretske (1986, 1988, 1991) later offers a teleo-functional\nversion of indicator-semantics. He begins with a notion of\ninformation-carrying, which he calls “indicating”, and\nsuggests that a representation’s content is what it has the\nfunction to indicate. \nDretske (1981) provides the most careful analysis of the indication\nrelation and he often refers back to this in his later work. However,\nit adverts to background knowledge and, since knowledge is\nintentional, this aspect of it is omitted in his theory of content, at\nleast as it applies to the simplest kinds of mental representations.\nThe analysis of indication on which his theory of content relies is as\nfollows: an event of type R indicates that a state of affairs\nof type C is the case if and only if the probability of\nC, given that R is instanced, is one (assuming that\ncertain background or “channel conditions” obtain). \nAlthough indication is often underwritten by a causal regularity such\nthat Cs cause Rs, Dretske tell us that it is not a\nrequirement that Cs cause Rs. Cs and\nRs might have a common cause, for instance. He also tells us\nthat it need not be a law that if R then C, though\nit cannot be merely coincidental. For local reasons, it could be that\nif there is an R then there is always a C. One of\nhis examples is of doorbell ringings: if there is someone ringing the\ndoorbell whenever the doorbell rings in his neighborhood, its ringing\nindicates that someone is at the door. But if squirrels start to ring\ndoorbells because people start making them out of nuts, a ringing\ndoorbell will no longer indicate that someone is at the door. \nDretske points out that representation is not equivalent to\nindication. “R indicates C” entails\n“if R then C.” (At any rate,\n“R indicates C” entails “if\nR then C” if the relevant channel conditions\nobtain.) But, since misrepresentation is possible, it must be the case\nthat “R represents C” does not entail\n“if R then C.” So Dretske (1986)\nsuggests that perceptual representations have the function of\nindicating. The starting idea is this: if something has the function\nof indicating something else then it is supposed to indicate it but,\nsince items don’t always perform their functions, room for error\nhas been made. Dretske appears to rely on an etiological analysis of\nfunctions (see e.g., Dretske 1995, p. 7). He speaks of states\nacquiring a function to indicate by being selected or recruited for\nindicating. Roughly, Dretske suggests that Rs represent\nCs iff Rs were recruited for indicating Cs\nand for causing a bodily movement, M. \nDretske (1995, p. 2) says, “[t]he fundamental idea is that a\nsystem, S, represents a property, F, if and only if\nS has the function of indicating (providing information\nabout) the F of a certain domain of objects. The way\nS performs its function (when it performs it) is by occupying\ndifferent states s1, s2, … sn\ncorresponding to the different determinate values f1,\nf2 … fn, of F.” For example,\npart of the visual system might represent the orientation of lines in\na region of the visual field. If so, it does so because it has the\nfunction of carrying information about the orientation of lines in\nthat region and it performs this function (when it performs it) by\nentering into different states when different orientations of lines\nare present in that region. \nThis account of representation seems to make room for error, because\nit implies that representations need only indicate their contents\nduring recruitment or in the environment and given the channel\nconditions in which recruitment took place; error being possible after\nthat time or in other environments or circumstances. However, Dretske\n(1986) sees a problem with this suggestion. He illustrates the problem\nwith the case of ocean-dwelling anaerobic bacteria that have tiny\nmagnets (magnetosomes) that are attracted to magnetic north, which\nserve to direct the bacteria downwards into the relatively oxygen-free\nsediment on the ocean floor . Plausibly, the function of the\nmagnetosomes is to direct the bacteria to anaerobic conditions. If we\n“fool” the bacteria by holding a bar magnet nearby and\nlead the bacteria upward to their death, this looks like a case of\nnatural misrepresentation. We were, in Dretske’s words, looking\nfor “nature’s way of making a mistake” and we seem\nto have found it. The problem, says Dretske, is that it is\nindeterminate how we should describe the function of the magnetosomes.\nWe can plausibly say that they have the function of indicating the\noxygen-free sediment. But we can also plausibly say that they have the\nfunction of indicating geo-magnetic or even local magnetic north. If\nwe say the latter, no misrepresentation has occurred. So\nDretske’s interim conclusion is that we cannot count this as an\nunambiguous case of error, on his theory as outlined so far. \nA number of distinct problems go under the name of “the\nfunctional indeterminacy problem”\n (section 4.1)\n and the magnetesome example can be used to illustrate several of\nthem. However, Dretske’s response to the indeterminacy problem\nthat he raised suggests that his main concern was with what is known\nas the problem of distal content. His problem, then, is this. Suppose\nthat we have a simple system that has just one way of detecting the\npresence of some feature of the environment. We have just seen a case\nof this for the anaerobic bacteria have just one way of detecting\nanaerobic conditions (via the local magnetic field). In such a case,\nif an inner state indicates the distal feature (anaerobic conditions)\nit will also indicate the more proximal feature (local magnetic\nnorth). Moreover, if there was selection for indicating the distal\nfeature, there will also have been selection for indicating the more\nproximal feature (since it is by indicating the latter that it\nindicates the former). Dretske further points out that, even if a\ncreature has several routes by which it can detect a given distal\nfeature (e.g., even if the bacteria can detect anaerobic conditions by\nmeans of light sensors as well) there would still be a disjunction of\nmore proximal features that the representation could count as\nrepresenting, since it could still count as having the function of\nindicating the disjunction of more proximal features (i.e., local\nmagnetic north or reduced light). \nWhile we might be perfectly willing to allow that the magnetosomes in\nanaerobic bacteria do not represent or misrepresent, the problem of\ndistal content generalizes. When you see a chair across the room as a\nchair across the room, you represent it as a solid 3D object at a\ndistance from you and not as a stream of light reflected from it or as\na pattern of firings in your retinas. Otherwise you would not try to\nwalk to the chair and sit on it. An informational theory of content\nmust therefore explain how mental representations represent distal\nfeatures of the world, as opposed to the more proximal items that\ncarry information about those distal features to the representations\nthat represent them. \nDretske (1986) therefore modifies his proposal and maintains that a\ncreature that is capable of representing determinate content must be\ncapable of learning any number of new epistemic routes to the same\ndistal feature. In that case, he says, there is no closed disjunction\nof more proximal stimuli that the representation could count as\nrepresenting. He speaks of conditioning in this context. The relevant\nrepresentation is recruited by conditioning to indicate the distal\nfeature rather than the disjunction of more proximal features, because\nthere is no finite time-invariant disjunction of more proximal stimuli\nthat it has the function of indicating. Loewer (1987) points out that\nconditioning ends at death, at which point no further epistemic routes\ncan be acquired. So, at the death of a creature, there will be a\nclosed disjunction of proximal features that each of the\ncreature’s representations was recruited to indicate. (Loewer\ncomments that Dretske might appeal to epistemic routes that could\npossibly be acquired by a creature but is unsure if this\nsucceeds.) \nThe claim that misrepresentation is impossible without learning anyway\nseems problematic, since it seems to preclude representations produced\nby innate input systems, such as innate sensory-perceptual systems.\nSome psychologists also claim that some core concepts are innate\n(e.g., see Carey 2009). Later, Dretske (1988) drops his conditioning\nrequirement insofar as it is a requirement on content possession but\nhe keeps it as a requirement for the kind of content that can explain\nbehavior. (For discussion of Dretske’s account of the causal\nefficacy of content, see the essays in McLaughlin (1991).) This\nre-raises the question of how representations produced by innate input\nanalyzers have distal content. \nDretske’s strict characterization of indication is thought by\nsome to be troublesome. One reason is that there can be no\nnon-intentional process of selection for something to do Z\nunless that thing, or things of that type at least, did do Z.\nHearts cannot be selected for pumping blood by natural selection\nunless some hearts pump blood. Similarly, no mechanism can be selected\nfor producing Rs because they indicate Cs unless\nsome Rs indicate Cs. However, all Rs must\nindicate Cs in a region of space-time if any are to do so,\ngiven the strict characterization of indication (for if Rs\nindicate Cs in that region, then in that region it must be\nthe case that C being the case, given an R-tokening,\nhas a probability of one). Hence, where and while recruitment\ncontinues, Rs cannot occur without Cs. Fodor (1990b)\nquestions whether this requirement would be met or met often enough,\ngiven that misrepresentation can occur later. Perhaps Dretske’s\nappeal to channel conditions can help him out of this apparent\ndifficulty. However, specifying channel conditions without being\nad hoc or circular or adverting to intentional phenomena\n(such as that a perceiver is not distracted) could prove\ndifficult. \nThere are some hints in Dretske’s writings of a willingness to\nuse a less strict notion of indication for he sometimes speaks of the\ncontent of a representation as the “maximally indicated\nstate.” This suggests that there are more minimally indicated\nstates, which would be an oxymoron on the strict interpretation.\nHowever, this looser interpretation is not developed in\nDretske’s writings and his (1981) offers several arguments\nagainst loosening the requirement. \nA further objection against indicator semantics is Millikan’s\n(2004, ch. 6) argument that no system can have the function to produce\nstates that carry correlational information, even if the correlation\nneed not be one hundred percent reliable. On Millikan’s view,\nalthough representation producing systems do produce representations\nthat carry a form of natural information when they function properly,\nthey do not have the function to do so. (While hearts produce thumping\nsounds when they are functioning properly, they do not have the\nfunction to produce thumping sounds; it is a side effect of their\nproper functioning.) She points out that it cannot be the function of\nher visual system to ensure a general correlation between\nrepresentations of a certain type (e.g., all REDs produced by human\nvisual systems) and contents of a certain type (e.g., all red\ninstantiations). Her visual system, for instance, cannot have the\nfunction to ensure that your visual system produces REDs only in the\npresence of red. If this objection succeeds, it still leaves open the\npossibility that an alternative notion of natural information, such as\na causal notion, could be used (as discussed in\n section 3.5). \nDespite some problems with the detailed articulation of\nDretske’s indicator semantics, his central insight seems\nimportant and appealing. It is plausible that sensory-perceptual\nsystems have the function to produce representations that carry\ninformation and that this bears on their content. An alternative\nattempt to elaborate this insight is sketched later. \nMillikan (1984) and Papineau (1984) were the first to offer\nnon-informational, “benefit-based” or\n“consumer-based,” versions of teleological theories of\nmental content. Millikan’s theory is described in this section\nand Papineau’s in the next. Millikan’s view is richly\nelaborated in her (1984), her (1989) provides a compressed version,\nwhile her (2004, part IV) is somewhere between the two in terms of\ndetail. \nAt least in her earlier work, Millikan’s theory of content\nfocussed heavily on the “consumers” of representations,\nwhere the consumers of representations are the systems that have\nhistorically used the mapping between the representations and their\ncontents to perform their (the consumers’) proper functions. In\nher (1989) Millikan maintains that the production of mental\nrepresentations is irrelevant to their contents. She has claimed that\nattention to the consumers is crucial for solving a certain functional\nindeterminacy problem, a claim to be discussed in\n section 4.1. \nOn Millikan’s theory, when the relevant representation is used\nto communicate between creatures, the producer and the consumer of the\nrepresentation are different creatures. One of Millikan’s\nexamples is of a beaver splash: the beaver that splashes its tail is\nthe producer of the representation and the consumers are the nearby\nbeavers that dive for cover, having been warned of danger. In the case\nof internal representations, it is less clear what counts as the\nproducer and consumer. Millikan sometimes speaks as if they are\ndifferent sub-systems and sometimes as if they are different\ntime-slices of the same system, before and after the representation is\ntokened. In either case, a consumer is a system that Normally exploits\nthe mapping between a representation and its represented in the\nperformance of its proper function, where ‘Normally’ is\nunderstood in a special, non-statistical sense (for details, cf.\nMillikan 1984, pp. 33–34). \nConsumers might or might not be cognitive systems; Millikan does not\nseem to require them to be cognitive systems. Consider the often\nmentioned case of the frog, which responds to anything appropriately\nsmall, dark and moving past its retinas by darting out its tongue. In\nthis case, one relevant consumer of the frog’s\nsensory-perceptual representation might be the frog’s\nprey-catching system. The performance of its function of feeding the\nfrog depends on and in that sense exploits the mapping between the\nfrog’s sensory-perceptual representation and its content, which\nis (Millikan says) frog food. \nTo find out the content of a representation, says Millikan, we look at\nthe functions of its consumers, which are co-adapted with the\nproducing systems. If a consumer system has a function then past\nsystems of the type did something adaptive that contributed to the\npreservation or proliferation of such systems in the population.\nAncestral frogs had ancestral prey-catching systems, for example, and\nthese did things that contributed to the preservation and\nproliferation of such prey-catching systems in frogs. It is the\nexplanation of this selection of the consumer system that most nearly\nconcerns the content of the representation, says Millikan. To\ndetermine the content of a representation, we consider those past\noccasions on which consumer systems of the type contributed to\nselection of that type of system and we ask what mapping between the\nrepresentation and the world was required for this contribution.\nAccording to Millikan, the frog’s visual representation\nrepresents frog food, since it was only when there was frog food where\nthe frog snapped that the frog was fed and so it was only then that\nthe frog’s prey-catching system contributed to the selection of\nsystems of that type through the use of the representation. As\nMillikan puts it, the fact that the representation maps onto the\npresence of frog food in this way is a Normal condition for the\nperformance of the proper function of the consumer, and this is why\nthe representation has the content frog food (or, more\nprecisely, there’s frog food). For ease of exposition,\nlet us call the condition that the representation is supposed to map\nonto its ‘Normal mapping condition’. Then we can summarize\nMillikan’s position by saying that the content of a\nrepresentation is its Normal mapping condition. \nSome argue that Millikan’s theory has advantages in comparison\nwith Dretske’s indicator semantics (see e.g., Godfrey-Smith 1989\nand Millikan 2004). On Millikan’s theory, a representation,\nR, can represent some environmental feature, C, even\nif it was never entirely reliable that if there was an R then\nthere was a C. It is enough, on her theory, that Rs\nmapped on to Cs often enough for the representation’s\nconsumers to have (so to speak) benefited from that mapping. There is\nno need to provide independently specifiable channel conditions or to\ndistinguish between recruitment and post-recruitment environments. \nIt can also be argued that Millikan has solved the problem of distal\ncontent for innate as well as learned concepts. Neither retinal images\nnor light reflected from prey feed a frog. So it can be argued that\nthe Normal condition for the performance of the proper function of the\nconsumer of the frog’s perceptual representation is that it maps\nonto frog food, not that it maps onto light reflected from the prey,\nor onto retinal images. However, whether Millikan’s solution to\nthe problem of distal content survives closer scrutiny is not clear. A\nsolution must exclude inappropriately proximal items, as well as\ninclude appropriately distal items. Food is included in the content of\nthe frog’s perceptual representation, on Millikan’s\ntheory, but the issue is whether the proximal items that carry\ninformation about the food to the frog are excluded. Frog food is of\nno use to a frog if the frog cannot detect it and a frog can only\nNormally detect its prey if light is reflected from it and an\nappropriate retinal image results. So a worry is whether the Normal\nmapping condition includes the more proximal links in the causal chain\nas well. \nA related objection to Millikan’s theory has to do with\nomnipresent beneficial background conditions, the prima facie\nworry being whether her theory excludes them. To stay with the same\nexample, consider that other things besides frog food were required\nfor a contribution to fitness on past occasions when the frog’s\nperceptual representation was used (e.g., oxygen and gravity). Does\nher theory entail that the frog’s perceptual representation\nmeans, not frog food, but something more like frog food\nin the presence of oxygen and gravity? To this worry, Millikan\nmight reply as follows: no, omnipresent background conditions do not\nenter into the frog’s perceptual contents, since these contents\nare constituted exclusively by external states of affairs that\nNormally vary with the frog’s perceptual\nrepresentations, in accordance with a certain mapping rule (Millikan\n1989b, p. 287; 2004, p. 76). On a natural reading of this requirement,\nit is simply not the case that stable background conditions are part\nof these varying states of affairs. Consequently, they are excluded\nfrom the frog’s perceptual contents. \nThis entry refers to Millikan’s theory as a\n“benefit-based” theory, since it links content to the\nbenefit to the creatures (or to the consuming systems) that accrues\nfrom the use of a representation. That to which a representation\nrefers is not necessarily beneficial; it might instead be its\navoidance that is beneficial (e.g., the avoidance of danger, in the\ncase of the beaver splash). While gravity is beneficial, being tied to\nEarth by gravity is not a benefit that accrues to frogs due to the use\nof their prey-representations. The ingestion of nutritional\nsubstances, on the other hand, is something that results from the use\nof the prey-representations. Benefit-based theories need not be\nconsumer-based theories, however, since we could speak of benefits to\nproducing systems or (when the relevant selection is natural selection\noperating over an evolutionary span of time) to the inclusive fitness\nof the creature as a whole. \nAnother objection to Millikan’s theory is that Normal mapping\nconditions (as we have called them) are overly specific for plausible\ncontents. Consider the fact that all sorts of circumstances could\nprevent a contribution to fitness: for example, an infected fly or a\ncrow standing nearby could spell disease or death instead of nutrition\nfor the frog (Hall, 1990). It has been argued that Millikan’s\ntheory has the unintended consequence that the frog’s\nrepresentation has the content food that is not infected, when no\ncrow is standing by … , etc. \nPietroski (1992) also argues that Millikan’s theory provides\nimplausible intentional explanations. His tale of the kimu is intended\nto press the point. The kimu are color-blind creatures, until a\nmutation arises which results in a mechanism that produces a brain\nstate, B, in response to red. Those who inherit this\nmechanism enjoy the sensation, which leads them to climb to the top of\nthe nearest hill every morning (to see the rising sun or some\nflowers). The result is that they avoid the dawn-marauding predators,\nthe snorf, who hunt in the valley below and, solely as a result of\nthis, there is selection for the mutation. As Pietroski wants to\ndescribe the case, Bs have the content red (or\nthere is some red) and the kimu enjoy the sight or red and\nseek out the sight of red things. The point of the story is that\nMillikan’s theory does not allow the story to be told this way.\nOn her theory, the kimu do not see a visual target as red or desire\nthe sight of red, given that it was not the mapping between\nBs and red but between Bs and snorf-free-space that\nwas crucial for the fitness of the kimu (and so for the selection of\nany relevant consumers of the representation). On Millikan’s\ntheory, Bs mean snorf-free-space and there is no\nrepresentation of red in a kimu’s brain. \nPietroski argues that biting the bullet is radically revisionist in\nthis case. Behavioral tests, he says, could support his claim. Plant a\nred flag among a crowd of snorf and the kimu will eagerly join them.\nIt is consistent with his story that contemporary kimu might never\nhave seen a snorf and might be unable to recognise one were it stood\nsmack in front of their faces. Intuitively, we want to say that they\nmight know nothing of snorf, he says. Pietroski suggests that this\nmight be a problem for all teleological theories of content. However,\nit is more specifically an objection to a benefit-based version (some\nother teleological theories of content imply that the kimu represent\nred, see\n section 3.5). \nMillikan (2000, p. 149) agrees that her theory entails that the\nkimu’s B-states represent fewer snorf this way. She\nargues that we need to distinguish between the properties represented\nand the properties that cause representations. How else, she asks,\ncould a tortoise think chow this way, given that being\nnutritious is an invisible property and so could not cause a\nsensory-perceptual representation? Setting aside what a tortoise\nreally thinks, the worry is how a causal theory of content can allow\nfor the representation of that which lies behind the surface features\nof objects, or how a causal theory of content can account for natural\nkind concepts that have hidden or unknown “essences”\n(e.g., a concept of water, which is necessarily composed of\nH2O). \nPrice (2001) offers a detailed teleological theory that is similar to\nMillikan’s. She defends Millikan’s interpretation of the\nmind of the kimu on the ground that it better explains their behavior.\nShe endorses the idea that the point of making content ascriptions is\nto rationalize behavior and her claim is that a desire to avoid snorf\nis a better reason to climb to the top of the hill than a desire to\nwatch the sun rise or see red flowers. Several responses are possible.\nOne is that a desire to watch a sunrise is reason enough to climb a\nhill. Another is that we are left without a rational explanation of\nwhy a kimu would be eager to enter snorf-infested space when the snorf\nare near red, other than that they are psychologically incapable of\ncorrectly representing the presence of snorf when snorf are near red.\nA further possible response is to question whether it is the role of\ncontent ascriptions to rationalize behavior (as famously claimed by\nDavidson (1985) and Dennett (1996)). \nIn relation to this last point, one can ask if some content\nascriptions are suitable for some theoretical purposes and others for\nothers. One might agree that folk psychological ascriptions of\nintentional mental states are meant to rationalize behavior but\nquestion whether this is their role in cognitive science. In the\nlatter case, the aim is to explain the psychological capacities of\nhumans and (in the case of cognitive neuroethology) other creatures.\nThus a question to ask is what content ascriptions would serve the\nexplanatory purposes of the mind and brain sciences, rather than our\nfolk psychological intuitions. Neander (2006) and Schulte (2012) argue\nthat benefit-based theories generate the wrong contents for mainstream\n(information-processing) theories of perception in relation to the\nsimple system cases discussed in the philosophy literature. A\nprinciple of such mainstream theories is is that, in vision, the\ninvisible properties of objects are only represented after the visible\nsurface features of objects are first represented (see, e.g., Palmer\n1999). The worry is that benefit-based theories can entail that it is\nonly the invisible but beneficial property that are represented in\nperception. \nFurther afield, Shapiro (1992) discusses the role of content\nascriptions in foraging theory, which raises a different set of\ntheoretical considerations. \nMillikan occasionally makes it clear that her theory is intended as a\nversion of an isomorphism theory. According to an isomorphism theory,\nrepresentation is a matter of mirroring the relations among the\nelements in the represented domain in the relations among elements in\nthe representing domain. Since the relevant resemblances are\nrelational, there is no requirement that representations share\nproperties other than abstract relational properties with their\nrepresenteds. This makes isomorphism theories more plausible than\ncrude resemblance theories. However, this aspect of Millikan’s\ntheory is not much developed. (See Shea 2013 for discussion of the\nrole of isomorphism in her theory.) \nTo a large extent, Millikan’s theory has been responsible for\nthe great interest, both positive and negative, that philosophers have\nshown in this general class of theories. Her writings on the topic are\nextensive and this section has only touched on the basics of her\nview. \nA further way in which teleological theories of content can differ is\nwith respect to the contents that they aim to explain. David\nPapineau’s theory, developed at the same time as\nMillikan’s, will help illustrate this point. Papineau (1984,\n1987, 1990 and 1993) develops a theory that is top-down, or\nnon-combinatorial, insofar as the representational states to which his\ntheory most directly applies are whole propositional attitudes (e.g.,\nbeliefs and desires). In early writings, Millikan sometimes seems to\nhold a similar view and some objections initially raised against her\ntheory are based on this interpretation of her view (see, e.g., Fodor\n1990b, 64–69, where he raises some of the following points). \nIn Papineau’s theory, the contents of desires are primary and\nthose of beliefs are secondary in terms of their derivation. According\nto Papineau, a desire’s “real satisfaction\ncondition” is “… that effect which it is the\ndesire’s biological purpose to produce” (1993,\n58–59), by which he means that “[s]ome past selection\nmechanism has favored that desire — or, more precisely, the\nability to form that type of desire — in virtue of that desire\nproducing that effect” (1993, 59). So desires have the function\nof causing us, in collaboration with our beliefs, to bring about\ncertain conditions, conditions that enhanced the fitness of people in\nthe past who had these desires. Desires, in general, were selected for\ncausing us to bring about conditions that contributed to our fitness,\nand particular desires were selected for causing us to bring about\nparticular conditions. These conditions are referred to as their\nsatisfaction conditions and they are the contents of desires. \nThe “real truth condition” of a belief, Papineau tells us,\nis the condition that must obtain if the desire with which it\ncollaborates in producing an action is to be satisfied by the\ncondition brought about by that action. A desire that has the function\nof bringing it about that we have food has the content that we have\nfood, since it was selected for bringing it about that we have food,\nand if this desire collaborates with a belief to cause us to go to the\nfridge, the content of the belief is that there is food in the fridge\nif our desire for food would only be satisfied by our doing so if it\nis true that there is food in the fridge (Papineau’s\nexample). \nThis seems to reject the Language of Thought hypothesis, according to\nwhich thought employs a combinatorial semantics. Language is\ncombinatorial to the extent that the meaning of a sentence is a\nfunction of the meanings of the words in the sentence and their\nsyntactic relations. “Rover attacked Fluff” has a\ncombinatorial meaning if its meaning is a function of the meaning of\n“Rover”, the meaning of “attacked” and the\nmeaning of “Fluff”, along with their syntactic relations\n(so that “Rover attacked Fluff” differs in meaning from\n“Fluff attacked Rover”). According to some philosophers\n(see esp. Fodor 1975) the content of propositional attitudes is\ncombinatorial in an analogous sense. That is, for instance, the\ncontent of a belief is a function of the contents of the component\nconcepts employed in the proposition believed, along with their\nsyntactic relations. A teleological theory of content can be\ncombinatorial, for it can maintain that the content of a\nrepresentation that expresses a proposition is determined by the\nseparate histories of the representations for the conceptual\nconstituents of the proposition (and, perhaps, by the selection\nhistory of the syntactic rules that apply to their syntactic\nrelations). Papineau’s theory is not combinatorial, at least for\nsome propositional attitudes. Instead, the proposal is that the\ncontents of concepts are a function of their role in the beliefs and\ndesires in which they participate. \nPapineau’s theory is a benefit-based theory, and some issues\ndiscussed in the previous sub-section are relevant to an assessment of\nit. For instance, it is unclear that what we desire is always what is\nbeneficial to fitness. One might want sex, not babies or bonding, and\nyet it might be the babies and the bonding that are crucial for\nfitness. However, this section will not attempt an overview of the\nstrengths and weaknesses of this theory but will focus on issues\npeculiar to non-combinatorial accounts. \nAny non-combinatorial theory must face certain general objections to\nnon-combinatorial theories, such as the objection that it cannot\naccount for the productivity and systematicity of thought (Fodor 1981,\n1987). This entry will not rehearse that argument (see the entry on\n the language of thought hypothesis)\n but special problems for a teleological version of a\nnon-combinatorial theory need to be mentioned. Consider, for example,\nthe desire to dance around a magnolia tree when the stars are bright,\nwhile wearing two carrots for horns and two half cabbages for breasts.\nProbably no-one has wanted to do this. But now suppose that someone\ndoes develop this desire (to prove Papineau wrong, say) so that it is\ndesired for the first time. We cannot characterize the situation in\nthis way, according to a non-combinatorial teleological theory. Since\nit has never been desired before, it has no history of selection and\nso no content on its first occurrence, on that style of theory. It is\nalso a problem for this kind of theory that some desires do not or\ncannot contribute to their own satisfaction (e.g., the desire for rain\ntomorrow or the desire to be immortal) and that some desires that do\ncontribute to their own satisfaction will not be selected for doing so\n(e.g., the desire to smoke or to kill one’s children). In\ncontrast, teleological theories that are combinatorial have no special\nproblem with novel desires, desires that cannot contribute to bringing\nabout their own satisfaction conditions or desires that have\nsatisfaction conditions that do not enhance fitness, as long as their\nconstitutive concepts have appropriate selection histories or are\nsomehow built up from simpler concepts that have appropriate selection\nhistories. \nPapineau can respond by agreeing that some concessions to a\ncombinatorial semantics have to be made. Once some desires and beliefs\nhave content, the concepts involved acquire content from their role in\nthese and they can be used to produce further novel, or\nself-destructive or causally impotent desires. However, it needs to be\nshown that such a concession is not ad hoc. The problem is to\njustify the claim that the desire to blow up a plane with a shoe\nexplosive is combinatorial, whereas the belief that there is food in\nthe fridge is not. \nIn contrast to Papineau’s theory, some teleological theories are\ncombinatorial theories. According to these theories, a teleological\ntheory directly accounts for the contents of just the representational\nsimples and combinatorial processes are in addition involved in\ndetermining the content of more complex representations. \nThere are two kinds of possible combinatorial processes that might be\ninvolved. One operates at the level of a proposition, or at the level\nof entire map-like or pictorial representations. This type of\ncombinatorial process is thought to play a role that is roughly\nanalogous to the role of a grammar in a spoken language, or a role\nthat is roughly analogous to the principles of map-formation in\ncartography or pictorial composition in picturing. For example, it\nmight allow us to combine the concepts CAT, ON and MAT to produce the\nthought (belief, desire, etc.) that the cat is on the mat. \nA second kind of combinatorial process that might be involved operates\nat the level of single concepts and their associated conceptions. Some\nthink that simpler concepts could be combined in conceptions to\nformulate more sophisticated concepts or to fix the reference of more\nsophisticated concepts that remain at roughly the grain of the lexemes\nof a language. Most simply, the concepts MALE, ADULT and NOT MARRIED\nmight be combined to form the concept BACHELOR by means of a\ndefinitional conception. Or there might be other types of conceptions\ninvolved, such as Wittgensteinian family resemblance conceptions or\nprototype-style conceptions. \nTeleological theories can be more or less modest in their scope. A\nmodest theory only aims to directly account for the contents of\nrepresentational simples. Dretske (1986), expresses a\n“modest” view when he gives voice to the hope that more\nsophisticated representations can be built out of the simple\nsensory-perceptual representations his theory accommodates. However,\nthere is as yet no clear agreement among philosophers or psychologists\nas to which the representational simples are. \nOne modest view is that a teleological theory should directly apply to\nsensory-perceptual and motor representations and to innate concepts\nonly (i.e., those that can be produced without learning). However,\neven this needs qualifying, since it is controversial which of our\nconcepts are innate. On a radical nativist view, such as that of Fodor\n(1981), all or almost all of the concepts expressed by the lexical\nmorphemes (the smallest meaningful components) of a language are\ninnate (not learned, only triggered). If that were really so, a theory\nthat aimed to account for the contents of all innate concepts would\nneed to be quite ambitious. Those who propose genuinely modest\nteleological theories of content do not hold this view, for they claim\nthat some mental representations that correspond to lexical morphemes\nare sophisticated, in the sense that they are somehow composed out of\nor acquired through the use of other representations. \nSterelny (1990) describes his teleological theory as\n“modest” because it only attempts to give an account of\ninnate representations and he assumes these to be a relatively small\nsubset of the complete set of our mental representations. As for\ngiving an account of the human propositional attitudes, Sterelny\nmaintains that a teleological theory of content will face\n“appalling difficulties.” He believes that a teleological\ntheory for the representational simples will be part of the complete\npsycho-semantic theory but not the whole of it. This contrasts with\nPapineau’s theory, which most directly applies to propositional\nattitudes. It also contrasts with Millikan’s (1984) highly\nambitious attempt to directly account, not only for the contents of\nall mental representations, but also for the meanings of all\nlinguistic utterances via a teleological theory. \nA modest teleological theory might claim some advantages. Most\nobviously, unless some concepts can be derived from other concepts,\nteleological theories would seem to have trouble accounting for empty\nconcepts. For example, no unicorns were ever indicated by UNICORNs,\nthe presence of a unicorn was never a Normal condition for the\nperformance of the proper function of a consumer of UNICORNs, and the\ndesire to find a unicorn has never been satisfied so that the\nconditions involved in the satisfaction of this desire could not have\ncontributed to selection of the mechanisms that produce desires of the\ntype. This problem is avoided by a teleological theory that aims to\ndirectly account for the contents of just the representational\nsimples, on the assumption that no representational simple expresses\nan empty concept. (Rey (2010) questions that assumption.) \nIt is sometimes argued that the lack of unicorns as (e.g.) Normal\nconditions is unproblematic since UNICORN does not refer (to anything\nactual). Arguably, non-modest theories deliver the correct referential\ncontent. It is a question whether a theory of referential content\nneeds to determine the extension of a concept in all possible worlds.\n(If the reader’s view is that there are no unicorns in any\npossible worlds because unicorns are essentially fictional, the reader\nshould here substitute another example of an actually empty but\npossibly non-empty concept, such as a concept of phlogiston or of\nentelechies.) Some theories of referential content do and some do not\ntake on this task. \nThe greatest challenge to those offering modest theories will be to\nexplain how complex concepts can be composed out of or derived from\nsimpler concepts. It might fairly be said that it is not the task of a\nfundamental theory of mental content per se to explain how\ncomplex concepts can be composed out of simpler ones, but it is a\nproblem for modest theories if no such explanation is available.\nMoreover, providing such an explanation is generally thought to be\nproblematic. Some say that “modest” theories have some\nseriously immodest consequences. One is alleged to be that there must\nbe a principled analytic/synthetic distinction. See, for instance,\nFodor and Lepore (1992), who argue that we must choose between three\noptions: defending a principled analytic/synthetic distinction,\naccepting meaning holism or accepting that virtually no concepts of\nroughly the grain of the lexemes of a language are composed out of\nsimpler concepts. They further argue that the first two options are\nnot viable. However, some psychologists maintain that we must somehow\n“bootstrap” up from simple to sophisticated concepts (see\ne.g., Carey (2009)). And some philosophers are anyway unconvinced by\nFodor and Lepore’s arguments. (Readers who would like to read\nmore on concepts and conceptions might start with the introduction to\nand readings in Margolis and Laurence (1999) and the entries in this\nencyclopedia on concepts and on the analytic-synthetic\ndistinction.) \nTo round out this survey of views, we return to informational\ntheories, to look at some more recent work that is broadly in the\ntradition of Stampe and Dretske. These theories take seriously the\nidea that mental representations have informational functions. \nFirst, a response is offered to an argument that is intended to block\nall informational versions of teleosemantics. This argument is that,\nbecause functions are selected effects, any appeal to\nrepresentational functions must be an appeal to the effects of\nrepresentations and not their causes (Millikan (1989b, 85), Papineau\n(1998, 3)). One response is to accept this argument’s conclusion\nbut to maintains that an additional informational requirement can\nnonetheless be added to an appeal to functions; teleological theories\nof mental content can appeal to other things besides functions (Shea,\n2007). \nAn alternative response rejects the argument. Neander (2012) claims\nthat sensory-perceptual systems have what she calls “response\nfunctions,” where to respond to something is to be caused by it\nto do something else. For example, a visual system might be caused by\na red instantiation to change into a RED state, and it might have been\nselected (in part) for being disposed to change into a RED state in\nresponse to red and have the function to do so. \nOn Neander’s view, these state changes represent the causes to\nwhich the system is supposed to respond by producing the\nrepresentation in question. They are, so to speak, the Normal causes\nof the producer of the representation, rather than the Normal mapping\nconditions determined by the proper function of the\nrepresentation’s consumer. On this view, RED has the content\nred if the visual system that produces it has the function to\nproduce it in response to red, or more specifically in response to red\nbeing instanced in the receptive field of the perceptual processing\npathways responsible for the RED’s production. This is the basic\nidea though further complications are added. One is intended to solve\nthe problem of distal content as follows: \nThe second requirement is intended to determine appropriately distal\ncontent and is to be applied only after the first requirement is\napplied. The first requirement on its own does not determine suitably\ndistal content because there is a causal chain leading from C\nto R and, if the system had been selected for responding to\nCs by producing Rs, it must also have been selected\nfor responding to the proximal items in the causal chain (such as the\nlight reflected from Cs toward the retina of the eye, in the\ncase of visual perception). These more proximal items in the causal\nchain carry information about C to the system and through the\nsystem to the R. There is, however, an asymmetry, to which\nthe second requirement appeals. The system was selected for its\ndisposition to respond to the proximal items because by that means it\nresponded to the more distal items, but the system was not selected\nfor responding to the more distal item because by that means it\nresponded to the more proximal items. (It does not respond to the more\nproximal items by means of its responding to the more distal items;\nthat is not how the means-end analysis pans out). \nOn this causal theory, a sensory-perceptual system need not have\nproduced Rs only in the presence of Cs during\nselection of the system. There is no need to specify channel\nconditions or conditions in which representation is reliable. This is\nnot a type-1 teleological theory of content. The idea that\nrepresentations are reliably caused by or correlated with their\ncontents in some conditions does not figure in the proposal. \nThe first requirement ensures different content ascriptions to those\ngenerated by benefit-based teleological theories. For example,\nconsider again the kimu (see\n section 3.2).\n As stipulated by Pietrosky, it is the presence of red and not the\nabsence of snorf that causes the relevant mechanism in a kimu to\nproduce a B-state. Mechanisms of the type were not selected\nfor a disposition to be caused by an absence of snorf to produce\nB-states. They had no such disposition, so they could not\nhave been selected for it. The relevant mechanisms in the kimu were\nselected for a disposition to be caused by red to produce a\nB-state, as well as for further causing certain movements\n(hill climbing of a morning) thereby. They were selected for this\nbecause red correlated well enough with snorflessness in the\nkimu’s habitat. However, on this proposal, that further fact\nbecomes a background evolutionary fact that is not content\nconstitutive. The candidate content fewer snorf this way\nfails to pass the first requirement. \nConsider too the notorious case of the frog. Plausibly, the relevant\nvisual pathways in the frog’s brain were selected for their\ndisposition to be caused by a certain configuration of visible\nfeatures (roughly, something’s being small, dark and moving) to\nproduce the sensory-perceptual representation in question, as well as\nfor their disposition to initiate orienting and so on thereby. They\nwere plausibly selected for this preferential response to the\nconfiguration of visible features because things with these features\nwere often enough nutritious for the frog. The visual pathways in the\nfrog were not selected for a disposition to respond to the nutritional\nvalue of a stimulus, however. For the normal frog’s visual\nsystem has no causal sensitivity to the nutritional value of the\nstimulus and cannot have been selected for a causal sensitivity it did\nnot have. So, on this proposal, the visual content of the\nrepresentation is something small, dark, moving (or something\nalong these lines) rather than frog food. According to\nNeander (2006) the configuration of visible features is the right\nstyle of visual content to ascribe for the purpose of mainstream\nscientific explanations of an anuran’s visual capacities. \nNor does this proposal seem to generate overly specific contents of\nthe kind mentioned earlier in relation to benefit-based theories. On\nthis informational theory, the frog does not represent the stimulus as\nnot carrying an infectious disease, even if only those small, dark and\nmoving things that were not carrying an infectious disease contributed\nto frog fitness when the frog was fed. Sensory-perceptual systems can\nonly have been selected for causal dispositions which past systems of\nthe type possessed. Since past systems had no disposition to respond\npreferentially to the absence of an infectious disease in visual\nstimuli that were small, dark and moving, the fact that contributions\nto fitness were made only on those occasions when an infectious\ndisease was absent is, again, a background evolutionary fact that is\nnot content-constitutive on this proposal. \nOne possible concern is whether sufficient room for misrepresentation\nhas been made. Some early discussions of teleological theories of\ncontent assumed that the content of the frog’s representation\nmust be frog food or fly or else misrepresentation\nwould be impossible. The frog would not be in error when it snapped at\nsomething small, dark and moving that was not frog food, or not a fly.\nHowever, misrepresentation is possible on this proposal. A\nrepresentation that is supposed to be produced in response to\nsomething that is small, dark and moving and is instead produced in\nresponse to something large and looming would count as misrepresenting\nand a neurologically damaged frog (e.g., one with a damaged thalamus)\nwill indeed attempt to catch all sorts of inappropriate things (e.g.,\nan experimenter’s hand or even the frog’s own limbs). This\ninformational theory also entails that a kimu’s B-state\nwill misrepresent if it is tokened in response to anything that is not\nred. More importantly, perhaps, it seems to entail that human REDs\nwill misrepresent if tokened at something not-red, as could happen in\nred-green color blindness, in color contrast illusions or in unusual\nviewing conditions. \nAs Millikan (2012) and others have pointed out, there are\nrepresentations that cannot be caused by their contents, such as\nTOMORROW. No tomorrow has ever caused a thought about tomorrow.\nHowever, TOMORROW is not a sensory-perceptual representation and so\nthis is not an objection to this proposal per se. As with other modest\ntheories, however, the challenge is explaining how to link this modest\ntheory for some mental contents to a more comprehensive theory that\naccounts for all of the contents of all of our concepts (see section\n section 3.4). \nThe preceding survey of teleological theories of content does not\nmention all of the extant teleological theories but it illustrates\nsome of the commonalities and differences among them. Now we turn to\nsome objections that have been raised against the general idea of\nteleosemantics. This section looks at the objections that have been\nmost influential. Some have already been touched on in previous\nsections. \nThere are several potential indeterminacy problems. Aside from the\nproblem of distal content, which has already been discussed above in\nrelation to the different theories that treat it in different ways,\nthere are two other indeterminacy problems. One concerns the fact that\nnatural selection is extensional (Fodor, 1990b) and the other concerns\nthe fact that natural selection selects traits for complex causal\nroles (Neander, 1995). Both problems can perhaps be attributed to\nDretske (1986), though Dretske did not distinguish them from the\nproblem of distal content, the problem he seems primarily to have been\ninterested in solving. \nFodor once devised a teleological theory of mental content (published\nyears later, as Fodor 1990a). However, he quickly repudiated the idea\nand has since been one of the most vigorous critics of the general\nidea. His main objection was initially that teleological theories\nleave content indeterminate because functions are indeterminate.\nFunctional indeterminacy, according to Fodor (1990b), stems from the\nfact that natural selection is extensional in the following sense: if\nit is adaptive for an organism, O, to do something,\nM, in the presence of environmental feature, F, and\nF is reliably co-extensive with another feature, G,\nthen it is equally adaptive for O to do M in the\npresence of G. Fodor argues that teleological theories\ntherefore cannot distinguish between candidate contents that are\nco-extensional in the environment in which a creature evolved. \nFodor’s example is the frog that snaps at anything that is\nsuitably small, dark and moving and thereby feeds itself. According to\nFodor, if it was adaptive for the frog to snap at flies then it was\nequally adaptive for it to snap at small, dark, moving things on the\nsimplifying assumption that flies and small, dark, moving things were\nreliably co-extensive in the frog’s natural habitat. According\nto Fodor, we can equally well say that the function of the device is\nto detect flies and that its function is to detect small,\ndark, moving things. So, if we try to determine the content of the\nrepresentation by reference to the function of the detection\nmechanism, the content remains indeterminate. We can choose to\ndescribe the function one way or another but if the content depends on\nhow we choose to describe the function it is not a naturalized\ncontent. Note that the candidate contents fly and frog\nfood and small, dark moving thing each license different\nassessments concerning misrepresentation. If the frog is representing\nthe stimulus as a fly, for instance, it misrepresents something that\nis small, dark and moving that is not a fly, using the relevant\nrepresentation. If it represents the stimulus as small, dark and\nmoving, it does not. \nThe standard response to this objection starts by pointing out that\nthe function of a trait is what that type of trait was selected\nfor and that the notion of selection for is a causal\nnotion (Sterelny 1990, Millikan 1991). A trait is selected\nfor its possession of a certain property only if that\nproperty causally contributed to selection of traits of the type (see\nSober 1984). The heart was selected for circulating blood but not for\nmaking a thumping noise even though the two co-occured. It was\nselected for pumping rather than thumping given that the pumping but\nnot the thumping causally contributed to the inclusive fitness of\nancestral creatures and thus causally contributed to the selection of\nhearts. Functions can therefore distinguish between two properties\nthat reliably co-vary as long as one but not caused the trait to be\nselected. This point has mostly been well-taken. \nHowever, appeal to selection for does not suffice to\ndisambiguate content (Griffiths & Goode 1995, Neander 1995). In\nthe case of the frog’s detection device, its responding to\nsmall, dark, moving things and its helping the frog to catch and\nswallow something nutritious both played a causal role in\nselection of the relevant representation producing or consuming\nsystems. It was by detecting small, dark moving things that\nthe frog got fed. So neither the detecting of something small, dark\nand moving, nor the eating of something nutritious was a mere\nside-effect or mere piggy back trait. We return to this issue in a\nmoment. \nFodor (1996) anyway continues to object that there is a remainder of a\nproblem along these lines because content, he claims, is more\nfine-grained than selection histories can account for. He maintains\nthat teleological theories cannot discriminate contents finely enough\nwhen there are properties that are logically or nomologically\nco-extensive. Being triangular (being a closed plane figure with three\nstraight sides) and being trilateral (being a closed plane figure with\nthree inner angles) are logically co-extensive properties. Being a\nrenate (a creature with a kidney) and being a cordate (a creature with\na heart) are (Fodor assumes) nomologically co-extensive. According to\nFodor, we cannot distinguish between selection for adaptive responses\nin the presence of one versus the other of two such properties. We can\nrepresent each distinctly but, according to Fodor, selection histories\nare not sufficiently fine-grained to distinguish such contents. \nConsider the two options: either the causal powers of two\nco-extensional properties F and G are distinct or\nthey are not distinct. Suppose first that they are not distinct. On\nsome plausible and medium-grained theories of property individuation,\nproperties are individuated by their causal powers, so if there is no\ndifference in the causal powers of F and G, they are\nthe same property on such a theory. On this way of individuating\nproperties, a representation that refers to the one must refer to the\nother too and so there is no problem here for a theory of referential\ncontent. On this way of thinking, if there is no distinction between\nthe causal powers of triangularity and trilaterality, any difference\nin the mental representations TRIANGULAR and TRILATERAL must be a\ndifference of a different sort. It might be a difference in\nrepresentational vehicle, or in other words, the two might be\ndifferent predicates denoting the same property. They might,\nconsistent with this, differ in their cognitive roles. Alternatively,\nmodest theories can maintain that these two representations are\nsemantically complex, in which case there might be a difference (even\na referential difference) in the constituent concepts out of which\nTRIANGULAR and TRILATERAL are composed (e.g., one mentions angles and\none does not). \nSuppose, on the other hand, that F and G do have\ndistinct causal powers. Most would agree that this is in fact the case\nif X is the property of being a creature with a kidney and\nY is the property of being a creature with a heart. In that\ncase, this version of the objection does not get off the ground. If\nthe causal powers of the properties differ, they can play different\nroles in selection histories. Consider, for example, the proposal that\nthe contents of sensory-perceptual representations are (so to speak)\ntheir Normal causes. A system can have a disposition to be caused by\nFs to do M, without having a disposition to be\ncaused by Gs to do M, if F and G\nhave distinct causal powers even (if they are co-extensive). The\nsystem can be selected for the one disposition that it has but it\ncannot be selected for the disposition that it does not have. \nFodor’s objection has evolved into a general objection to any\nadaptational explanation and to the very notion of selection\nfor. It would take too much space to follow the trail further\nhere. (See Fodor and Piatelli-Palmarini 2010 and see esp. Block and\nKitcher 2010 and Sober 2011 (Other Internet Resources) for effective\ncritical discussion). \nWe turn now to the second functional indeterminacy problem. It stems\nfrom the fact that organic systems are selected for complex causal\nroles, as indicated earlier. For example, a gene in an antelope might\nhave been selected because it (i) altered the shape of hemoglobin,\n(ii) which increased oxygen uptake, (iii) which allowed the antelope\nto move to higher ground, (iv) which gave them access to richer\npasture in summer, (v) and so improved their nutritional status, their\nimmunity to disease, their vigor in avoiding predation, their\nattraction to mates and (vi) their chances of survival and\nreproduction (Neander, 1995). To determine the function of a trait,\nsuch as the altered shape of the hemoglobin, the etiological theory of\nfunctions tells us to ask, “what did past instances do that was\nadaptive and that caused traits of that type to be selected?”.\nIn this case, the answer is (ii) through (vi). The altered shape of\nthe hemoglobin did all of this, and all of this was adaptive, and all\nof this contributed to the selection of the trait (i.e., it was\nselected for all of this). So all of this would seem to be\nthe trait’s function. Its function is the complex causal role\nfor which it was selected. \nThe problem for content can be seen when we consider mechanisms that\nproduce or consume representations. For instance, the frog’s\ndetection device was selected because it (a) responded to small, dark,\nmoving things and (b) that helped the frog catch these things, and (c)\nthat provided the frog with nutrients and (d) that contributed to the\nfrog’s chances of survival and reproduction in various ways.\nThus ancestral detection devices contributed to the selection of that\ntype of device by way of a complex causal route in which the visible\nconfiguration of the stimulus and the nutritional properties of the\nstimulus both play a role. Note that this does not depend on these\nfeatures of the environment being co-extensional. Even if not all\nsmall, dark and moving things were nutritious and not all nutritious\nthings were small, dark and moving in the frog’s natural\nhabitat, this problem of complex causal roles would still remain. The\nproblem is that the systems responsible for the production and the\nconsumption of representations were selected for complex causal roles\nin which a number of environmental features were involved. \nAgar (1993) supports the idea that the frog’s representation\nrepresents small, dark, moving food, a content intended to incorporate\nall of the properties causally responsible for the selection. Price\n(1998, 2001) claims that, contrary to what has just been said, there\nis a unique, correct function ascription for each trait and\nshe elaborates a number of principles to isolate the unique, correct\nfunction ascription. Enc (2002) endorses Price’s claim that\nfunction ascriptions must be determinate if any teleological theory of\ncontent is to succeed but raises problems for her attempt to show that\nfunction ascriptions are suitably determinate. \nHowever, teleological theories of content do not merely gesture toward\nfunctions and leave it at that. Consider again the causal theory\ndiscussed in the preceding section. The content of the frog’s\nsensory-perceptual representation is not indeterminate between the\nconfiguration of visible features and something nutritious on that\ntheory, since the frog’s visual system was not selected for\nproducing the relevant sensory-perceptual representation in response\nto the nutritional value of the stimulus. A frog’s visual system\nis not causally sensitive to the presence or absence of nutrients and\ncould not have been selected for a causal sensitivity it did not have.\nThe general point here is that teleological theories of content appeal\nto functions in certain ways and one must examine the particular\ntheory to see if the theory isolates a sufficiently determinate\ncontent. \nIn responding to the indeterminacy problem, Millikan (1991) might be\nthought to rely on the fact that, on her theory, it is the proper\nfunction of the consumer and not that of the producer of the\nrepresentation that determines its content. For instance, in\ndiscussing Dretske’s magnetosome example she says that,\n“[t]he mechanisms THAT USE the magnetosome’s offerings\ndon’t care at all whether the magnet points to magnetic north,\ngeomagnetic north or, say, to the North Star. The only one of the\nconditions Dretske mentioned that is necessary FOR THE USER’S\nPROPER FUNCTIONING is that the magnet point in the direction of lesser\noxygen” (Millikan (1991, 163) original emphasis). However, it\nseems (to this author) that Millikan’s emphasis here does not\nput the emphasis in the right place for her theory. Arguably, one\nconsumer of the frog’s perceptual representation is the motor\ncontrol system which controls the frog’s orienting toward the\nstimulus. We can describe its function as controlling the frog’s\norienting toward frog food, but we could also describe it as\ncontrolling the frog’s orienting toward small, dark, moving\nthings. A mere appeal to consumers would seem to shift the problem\nwithout solving it. However, it does not follow that Millikan’s\ntheory leaves content indeterminate. It is Millikan’s appeal to\nNormal conditions that does more work in disambiguating the content\nfor her. \nFinally, some proponents of teleological theories do not think that\ncontent is determinate in the cases used to illustrate the\nalleged problem. Dennett (1995) maintains that such content\nindeterminacy is unproblematic. Papineau (1997) maintains that content\nis indeterminate in the case of a creatures that lacks a belief-desire\npsychological structure. Whether a creature lacks a belief-desire\nstructure will in part depend on how we construe this requirement. It\nis not straightforward whether frogs lack a belief-desire\npsychological structure given that they have both informational and\nmotivational states. Nonetheless, Papineau is probably right that the\ninformational and motivational states are not so distinct as ours and\nhe might also be right that content indeterminacy at this level is\nunproblematic. We will, however, need to resolve related content\nindeterminacy problems for human mental states. \nAnother objection that has been influential is the Swampman objection.\nSwampman-style examples have been around for some time. Boorse (1976)\nimagines a population of rabbits accidentally coalescing into\nexistence as a counter-example to Wright’s etiological theory of\nfunctions. Boorse’s claim was that we could ascribe functions to\nthe rabbits’ parts even if the rabbits lacked any\nselection-history. Swampman in particular was raised by Davidson\n(1987) as a potential objection to his own historical (but not\nteleological) theory of content. When Swampman comes into existence he\nis a synchronic (at a time, but not extended over time) physical\nreplica of Davidson at a certain point in time (t).\nSwampman’s history differs radically from Davidson’s\nbecause he comes into existence as a result of a purely accidental\ncollision of elementary particles. Crucially, he does not partake in\nour evolutionary history or have any other evolutionary history or any\ndevelopmental history of his own. Nor is he created by God or copied\nfrom Davidson by a machine. The resemblance between Davidson and\nSwampman is nothing but a stupendous coincidence. Swampman’s\nappearance of design is deceptive because he in no way derives from\nany design process, natural or intentional. Swampman’s component\nparts have no functions according to an etiological theory of function\nand so his “brain” states have no contents according to a\nteleological theory of mental content. \nMany people find these results highly counter-intuitive, especially\nthe result that Swampman lacks all intentional states. Assuming\nphysicalism, we could substitute Swampman for Davidson and no one,\nincluding his most intimate friends and family, would detect a\ndifference. Swampman would make noises that his friends and family\nwould interpret as witty, interesting and meaningful but, according to\nteleological theories (and Davidson’s own theory of content)\nSwampman has no ideas about philosophy, no perceptions of his\nsurroundings and no beliefs or desires about anything at all. \nThere are two broad strategies in responding to this objection. One is\nto try to loosen the grip of the intuition that Swampman has\nintentional states and the other is to argue that any intuitions that\nremain do not show that teleological theories are wrong. In either\ncase, it is important to isolate the relevant intuition because, by\nall accounts, Swampman would have much that Davidson had at\nt. All of the chemical activity in Davidson’s brain\nwhen he understood words, for example, would occur in Swampman’s\nbrain-analog and certain descriptions of this activity will apply to\nboth equally: e.g., physical, chemical and formal descriptions of it.\nFurther, it is trivial that Swampman has narrow content if\n“narrow content” is defined as whatever most closely\napproximates content that nonetheless supervenes on just the narrow\nphysical states of an individual at a time and “from the skin\nin.” By definition, whatever narrow content Davidson’s\nmental states had at t, Swampman’s inner states had\ntoo, since Swampman is at t physically indistinguishable\n“from the skin in” from Davidson at t. What\nteleological theories entail is that Swampman, no matter what narrow\ncontent he has, lacks regular normative content. The intuition that\nconflicts with teleological theories, therefore, is that\nSwampman’s inner states, which are narrowly identical to\nDavidson’s, are true, false, accurate or inaccurate in the usual\nsense. \nIt is clear that, if Swampman’s inner states do have\ntruth-evaluable contents, they cannot always have the same truth\nvalues as Davidson’s. Everyone will probably agree that, at\nt, Swampman cannot remember his past life since at most he\ncould only have pseudo-memories of Davidson’s. Everyone will\nalso agree that Swampman cannot correctly think that he is returning\nhome to his wife and sitting in his house, since the house and the\nwife are not his. Further, it should be kept in mind that many think\nthat Putnam (1975) has shown that the contents of natural kind\nconcepts do not supervene on just what is “in the head.”\nIf Putnam-style twin cases can be constructed for other mental\nrepresentations and their contents as well (see Burge 1979, 1986) then\nSwampman’s lack of history might anyway be an issue even before\nconsidering the further complication of a teleological theory. It thus\nrequires careful analysis with respect to controversial issues to\ndetermine just what intuitions about Swampman would tell against the\nexternalism of teleological theories in particular. \nThose who try to dislodge any remaining intuitions against\nteleological theories argue that an appearance of design can be\nmisleading. (Recall that “design” here includes the\nmechanical design-work of natural selection.) Consider, for example,\nBoorse’s swamprabbits. It might be intuitive to attribute\nfunctions to their eye-analogs. But in nature nothing so intricately\norganized as if for the performance of a function fails to be the\nresult of a design process. It is argued that habits of thought, which\nusually take us from an appearance of design to a function ascription,\nlead to false ascriptions in purely hypothetical unrealistic cases\n(Neander 1991). Dretske (1996) argues the case with another imaginary\nexample. Twin-Tercel, a random replica of his old Tercel, comes about\nas the result of a freakish storm in a junk yard. It is\nmolecule-for-molecule identical to his old Tercel, except that its\n“gas-gauge” does not move in relation to the amount of gas\nin its “tank”. We might be tempted to say that the thing\nis broken, but Dretske says that there is no basis for saying that it\ndoes not work because to say that it does not work implies that it was\ndesigned to do something it cannot do and it was not designed to do\nanything. If we should reform our intuitions in the one case, perhaps\nwe should also reform them in the case of Swampman’s\nintentionality, he says. \nWe might grant Dretske his claim about Twin-Tercel and yet resist the\nmove from functions to intentionality. The problem for theories of\ncontent, as opposed to theories of function, is exacerbated by the\nrelation between intentionality and consciousness. Many philosophers\nfind it plausible that an individual’s phenomenal consciousness\nat a time supervenes on just the inner physical properties of that\nindividual at that time. If this narrow supervenience thesis is true,\nthen Swampman will have phenomenal consciousness when he comes into\nexistence, assuming Davidson did at t. However, it is hard to\nsee how we can attribute phenomenal consciousness to Swampman without\nalso attributing some intentional states to him. Suppose, for example,\nthat Swampman has a red-sensation. Then presumably it will seem to him\nthat he is seeing something red. But it seeming to him that he is\nseeing something red is presumably an intentional state. \nHere we connect with another important issue that lies outside of the\nscope of this entry. However, a couple of points can be made. First,\nsome proponents of teleological theories of content are not troubled\nby this line of argument because they reject the view that\nconsciousness supervenes on narrow states and hold theories of\nphenomenal consciousness that deny consciousness to Swampman.\nAccording to some, phenomenal consciousness supervenes on (non-narrow)\ncontent, so if Swampman lacks content he must also lack phenomenal\nconsciousness on this view (see esp. Dretske 1995). \nIf, though, any proponents of teleosemantics accept the narrow\nsupervenience thesis for phenomenal consciousness, they cannot deny\nthat Swampman would have phenomenal consciousness. In that case, the\nobjection remains in force. Then there appear to be just two options.\nOne is to maintain that Swampman can have a red sensation without it\nseeming to him that he sees something red. The other is to maintain\nthat, although it seems to Swampman that he sees something red, this\nseeming is not truth-evaluable in the usual sense. This last option\nfits with the traditional idea that seemings have a special epistemic\nstatus; it fits with the idea that we cannot be mistaken about how\nthings seem to us and that, in that context, misrepresentation is not\npossible. It does not, however, fit with the idea that a person is, in\nprinciple, always fallible with respect even to how things seem. \nThe second broad strategy is to argue that Swampman intuitions cannnot\nshow that teleological theories are incorrect because they are\nirrelevant. They are, it can be argued, not to the point if a\nteleological theory is offered as a real-nature theory (Millikan\n(1996), Neander (1996)). The analogy with an a posteriori\nanalysis of the nature of water is thought to be helpful here. Recall\nthat XYZ is an imaginary liquid that is superficially\nindistinguishable from water (H2O), although it has a\ndifferent molecular constitution (dubbed “XYZ”). We can,\nit is argued, agree that “water” and WATER can refer to\nH2O exclusively, even if all of the members of the relevant\ncommunity would classify XYZ as water were they to find some, given\ntheir ignorance of water’s chemical composition. Following\nKripke and Putnam, many have been persuaded that “water”\nand WATER might have referred to H2O exclusively, even\nbefore it was known that water is H2O, because there was\ndeference to an unknown nature that explained the superficial\nproperties by means of which we usually recognise instances of the\nliquid. On this view, it was (in 1700) an epistemological possibility\nthat water was not H2O, but it was not a metaphysical\npossibility, given that water is in fact H2O.\nAlong similar lines, it can be argued that it is only an\nepistemological and not a genuine metaphysical possibility that\nSwampman might have intentionality. \nNote that this last claim is not the claim that it is merely an\nepistemological possibility that Swampman might exist. Rather, the\ncrucial claim is that, even if he did exist, it would remain a mere\nepistemological possibility that he would have genuine intentionality.\nThis parallels the claim regarding water and XYZ. Even if XYZ were to\nexist on Twin-Earth and Twin-Earth were in our universe, it would not\nbe water. Superficial appearances would be on the side of\nSwampman’s having intentionality, just as they would be on the\nside of XYZ’s being water, but it may turn out that\nSwampman’s “intentionality” is not intentionality,\njust as it would turn out that XYZ is not water (it is just\ntwin-water). Intuitions about Swampman, it is claimed, cannot decide\nthe issue of what the correct analysis of intentionality is. Rather,\nthe decision about Swampman’s intentionality should be driven by\nthe theory of content that best accounts for the real kind. That in\nturn should be driven by other considerations, such as which theory\ndelivers correct content ascriptions for us and other existing\ncreatures. \nOf course, in the case of intentionality, unlike the case of water,\nthe hidden nature or essence cannot be an inner structure, if a\nteleological theory is correct. On such a theory, intentionality is\nalleged to be an historical kind, so the previously hidden nature is\nalleged to be a matter of history. As proponents of teleological\ntheories point out, there is an apparent need for other historical\nkinds in biology (e.g., offspring, homologs and species).\n(Braddon-Mitchell and Jackson (1997) have argued that this “real\nnature” response is not available to proponents of teleological\ntheories of content. See Papineau 2001 for a response.) \nThe Methodological Individualism debate is also relevant here, since\nit questions whether science should have any historical\nkinds. If those who favor methodological invidualism are correct,\nteleological theories of content do not provide us with a good\nscientific way to individuate psychological states (Fodor 1991). One\nargument for methodological individualism involves the claim that\nscience should individuate kinds on the basis of causal powers. In\nbrief, the idea is that, since science is in the business of causal\nexplanations and causal powers are what are relevant for causal\nexplanations, science should classify items on the basis of\nsimilarities and differences in causal powers. Since there are no\ndifferences in causal powers between Davidson’s kidney or\nbeliefs at t and Swampman’s kidney-analog and\nbelief-analogs when he first pops into existence, Davidson’s\nkidney and Swampman’s kidney-analog should belong to all of the\nsame scientific kind and Davidson’s beliefs and Swampman’s\nbelief-analogs should belong to all of the same scientific kinds. (For\ndiscussion of this issue, see Heil & Mele eds. 1993.) \nOne problem with methodological individualism is that it is radically\nrevisionary, for biology at least. Moreover, if we classify kidneys on\nthe basis of actual causal powers, we include Swampman’s\nkidney-analog at the cost of excluding many real kidneys, such as the\nkidneys of people on dialysis. While the arguments given in favor of\nmethodological individualism may seem plausible, they are not usually\naccompanied by any attempt to understand the role that historical\nclassifications play in biology or elsewhere. That being the case, we\nhave reason to worry that the understanding of scientific\nclassification that supports methodological individualism is too\nsimple. Further, it must be kept in mind that the proponents of\nteleological theories claim that a historical theory of content is\nneeded to capture psycho-semantic norms. Perhaps this is wrong. But if\nit is right, and if cognitive science needs such a normative notion,\nthen methodological individualism must be wrong. Thus the debate must\nturn on the more specific issues of whether normative content involves\nhistory and whether cognitive science needs normative content. \nThe weightiest objection to teleological theories of content and the\nhardest to assess is that it is unclear how such theories could\nexplain our most sophisticated concepts and cognitive capacities. \nNo naturalistic theory of content at this time yet makes perfectly\nclear how we think about democracy, virtue, quarks or perhaps even\ntomorrow, and so this is not a problem that is peculiar to\nteleo-functional theories. However, it is sometimes argued that\nteleological theories of content have a special problem in this\nrespect (e.g., Peacocke (1992)). The thought is that they may have\nsome hope of working for contents that concern things that impact on\nfitness — food, shelter, mates, etc.\n— but that they are, in principle, unable to deal with contents\nthat cannot have impacted on fitness, or not in any suitably selective\nway. Some contents cannot have impacted on fitness because they belong\nto the future or are non-existent. Others cannot affect fitness in any\nsuitably selective way because, although they have an impact, their\nimpact is too non-specific: for example, quarks have an impact but\nbecause they are omnipresent in our environment they cannot qualify as\nthe content of a representation by virtue of some simple selectional\nstory. \nThis objection is hard to assess for a number of reasons. One is that\nthere are many different kinds of sophisticated concepts and\ncapacities and accounting for them all is a large task. Another is\nthat, while the objection is posed as an objection to all\nteleosemantic theories, different versions will address it in\ndifferent ways. Yet another is that we might allow that it is still\nearly days with respect to the development of teleological (and other)\nnaturalistic theories of mental content. It has really only been since\nthe advent of cognitive science in the middle of the last century and\nthe general acceptance of a broadly physicalist perspective on the\nmind in the decades that followed that philosophers of mind have\ndevoted much effort to trying to give a naturalistic theory of mental\ncontent. \nIn view of all of this, the present section can do little more than\noffer a few remarks about how some versions of teleosemantics make\nsome inroads on the issue. Most of the points that follow have been\ntouched on in earlier sections. \nIt should be emphasized that those who favor teleosemantic theories\nrarely restrict the relevant functions to those that derive from\nnatural selection operating over an evolutionary span of time. As\nremarked earlier, there might be non-intentional selection processes\nthat operate over the span of a culture or over the span of an\nindividual’s own development or life. Meme selection,\nconditioning or some other forms of learning and neural selection are\nconsidered to be relevant kinds of selection by some proponents of\nteleosemantics. \nThose who favor modest teleo-functional theories would also emphasize\nthat conceptual atomism is highly controversial. Conceptual atomism is\nthe view that every concept of roughly the grain of a lexeme of a\nnatural language derives its content, constitutively speaking,\nindependently of every other such concept’s content. Many\npsychologists and some philosophers believe that some complex concepts\nare somehow composed out of or are anyway learned through the use of\nsimpler concepts. Crucially, to deny that conceptual atomism is true\ndoes not commit one to the view that complex concepts are simply\ndefined in terms of simpler concepts (a fuller discussion of concepts\nand whether conceptions can play any role in determining reference is\noutside of the scope of this entry). \nMillikan would in this context ask us to take note of her notions of\nderived and adapted proper functions. What Millikan refers to as a\n“direct proper function” belongs to a mechanism for which\nthere has been selection. The mechanisms that produce camouflage\npatterns on the surface of the octopus have the direct proper function\nto do so. The patterns that the mechanisms produce by means of which\nthey perform this function possess what Millikan calls a\n“derived proper function,” derived from the function of\nthe mechanism to provide camouflage. Further, a pattern produced on a\nparticular occasion has an “adapted derived proper\nfunction,” which is a relational function, in this case to\nprovide camouflage in that particular setting in which the octopus is\nsituated. Millikan makes use of these extended senses in which items\nmay have functions to try to explain the contents of novel\nrepresentations and representations that are produced as a result of\nlearning. Learning mechanisms have certain functions and when they\nperform their functions in particular circumstances their products can\nhave adapted derived proper functions in relation to those\ncircumstances, whether or not the circumstances obtained during the\nhistory of our species. \nMillikan (2000) gives an extensive treatment of concepts. In brief,\nher view is that conceptions play no role in determining the\nextensions of the concepts with which they are associated.\nMillikan’s theory presupposes innate learning mechanisms that\nare tuned to identify substances of different sorts in accord with\ncertain principles. The relevant sort of substance is that which\naccounts for the past selective success of the learning mechanisms.\nFor instance, some mental mechanisms might have been selected for\nrecognizing faces of individuals in accord with certain principles of\noperation, and others might have been selected for recognizing animals\nof different species in accord with other principles of operation.\nThese mechanisms can acquire the “purpose” to recognize\nsomething more specific, such as a particular individual’s face\nor animals of a particular species, because the mechanisms were\nselected for recognizing things in that domain (faces or animals) in\naccord with certain principles of operation and, in accord with those\nprinciples, it is a particular individual’s face or animals of a\nparticular species that it now has the “purpose” to\nrecognize. The extension of a substance concept, she tells us, is what\nsubstance it was selected to recognize. \nLarge issues relevant to assessing the different teleological theories\nof content remain to be settled. On a hopeful note, much good work has\nbeen done in exploring the possible range of such theories, in\nproducing interesting in-principle objections and in responding to\nsuch objections in ways that have resulted in better developed or\nbetter defended versions. We should also keep in mind that serious\nwork on naturalistic theories of content has only been going on for\ndecades rather than centuries and that, on a philosophical timescale,\nthat is quite a short time.","contact.mail":"jenspeter.schulte@uzh.ch","contact.domain":"uzh.ch"}]
