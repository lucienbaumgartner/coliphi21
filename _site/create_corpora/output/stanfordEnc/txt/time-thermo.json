[{"date.published":"2001-11-15","date.changed":"2021-03-17","url":"https://plato.stanford.edu/entries/time-thermo/","author1":"Craig Callender","author1.info":"http://philosophy.ucsd.edu/faculty/ccallender/","entry":"time-thermo","body.text":"\n\n\nThe thermodynamic time asymmetry is one of the most salient and\nconsequential features of the physical universe. Heat flows from hot\nto cold, never the reverse. The smell of coffee spreads throughout its\navailable volume, never the reverse. Car engines convert fuel energy\ninto work and thermal energy, never the reverse. And so on. The\nscience of thermodynamics is able to capture these generalizations as\nconsequences of its claim that systems spontaneously evolve to future\nequilibrium states but do not spontaneously evolve away from\nequilibrium states. This generalization covers an amazing amount of\nmacroscopic physics and is rightly celebrated as one of the great laws\nof physics.\n\n\nDespite its familiarity, however, the thermodynamic arrow of time\nraises many deep questions relevant to both philosophy and the\nfoundations of physics. This entry concentrates on two of them. In\ncontemporary parlance, they are each questions about grounding. (1)\nWhat grounds the thermodynamic asymmetry in time? In a world possibly\ngoverned at bottom by time-symmetric laws, how do the time-asymmetric\nlaws of thermodynamics arise? (2) Does the thermodynamic time\nasymmetry ground any other temporal asymmetries? Does it account, for\ninstance, for the fact that we know more about the past than the\nfuture? The discussion thus divides between thermodynamics being an\nexplanandum or explanans. What grounds the thermodynamic asymmetry,\nand given the asymmetry, what does it ground?\n\nFirst developed in Sadi Carnot’s Reflections on the Motive\nPower of Fire 1824, the science of classical thermodynamics is\nintimately associated with the industrial revolution. Most of the\nresults responsible for the science originated from the practice of\nengineers trying to improve steam engines. Originating in France and\nEngland in the late eighteenth and early nineteenth centuries, the\nscience quickly spread throughout Europe. By the mid-nineteenth\ncentury, Rudolf Clausius in Germany and William Thomson (later Lord\nKelvin) in England had developed the theory in great detail. Once\ndeveloped, its scope grew from steam engines and the like to arguably\nall macroscopic processes. \nThermodynamics is a “phenomenal” science. That means that\nits variables range over macroscopic parameters such as temperature,\npressure and volume. These are properties that hold at equilibrium,\ni.e., when the values of the macroscopic variables remain\napproximately stable. Whether the microphysics underlying these\nvariables are motive atoms in the void or an imponderable fluid is\nlargely irrelevant to this science. The developers of the theory both\nprided themselves on this fact and at the same time worried about it.\nClausius, for instance, was one of the first to speculate that heat\nconsisted solely of the motion of particles (without an ether), for it\nmade the equivalence of heat with mechanical work less surprising.\nHowever, as was common, he kept his “ontological” beliefs\nseparate from his official statement of the principles of\nthermodynamics because he didn’t wish to (in his words)\n“taint” the latter with the speculative character of the\n former.[1] \nA treatment of thermodynamics naturally begins with the statements it\ntakes to be laws of nature. These laws are founded upon observations\nof relationships between particular macroscopic parameters and they\nare justified by the fact they are empirically adequate. No further\njustification of these laws is to be found—at this\nstage—from the details of microphysics. Rather, stable,\ncounterfactual-supporting generalizations about macroscopic features\nare enshrined as law. The typical textbook treatment of thermodynamics\ndescribes some basic concepts, states the laws in a more or less rough\nway and then proceeds to derive the concepts of temperature and\nentropy and the various thermodynamic equations of state. It is worth\nremarking, however, that in the last fifty years the subject has been\npresented with a degree of mathematical rigor not previously achieved.\nOriginating from the early axiomatization by Carathéodory in\n1909, the development of “rational thermodynamics” has\nclarified the concepts and logic of classical thermodynamics to a\ndegree not generally appreciated. There now exist many quite\ndifferent, mathematically exact approaches to thermodynamics, each\nstarting with different primitive kinds and/or observational\nregularities as axioms. (For a popular presentation of a recent\naxiomatization, see Lieb and Yngvason 2000.) \nIn the traditional approach classical thermodynamics has two laws, the\nFirst and Second\n Laws.[2]\n The First Law expresses the conservation of energy and is founded\nupon the impossibility of creating a machine that can create energy.\nThe law uses the concept of the internal energy of a system, \\(U\\),\nwhich is a function of the system’s macroscopic variables, e.g.,\ntemperature, volume. For thermally isolated (adiabatic)\nsystems—think of systems such as coffee in a thermos—the\nlaw states that this function, \\(U\\), is such that the work \\(W\\)\ndelivered to a system’s surroundings is compensated by a loss of\ninternal energy, i.e., \\(dW = -dU\\). When James Joule and others\nshowed that mechanical work and heat were interconvertible,\nconsistency with the principle of energy conservation demanded that\nheat, \\(Q\\), considered as a different form of energy, be taken into\naccount. For non-isolated systems we extend the law as \\(dQ = dU +\ndW\\), where \\(dQ\\) is the differential of the amount of heat added to\nthe system (in a reversible manner). \nThe conservation of energy tells us nothing about temporally\nasymmetric behavior. It doesn’t follow from the First Law that\ninteracting systems quickly tend to approach equilibrium, and once\nachieved, never leave this state. It is perfectly consistent with the\nFirst Law that systems in equilibrium leave equilibrium. In\nparticular, no limitations are placed on transforming energy from one\nform into another, so the Law permits the possibility of machines that\nremove heat from their environment and turn it into work (a so-called\nperpetual mobile of the second kind). To rule out such machines, and\nmore generally, to capture the amazingly general temporally asymmetric\nbehavior we find, another law is needed. Although Carnot was the first\nto state it, the formulations of Kelvin and Clausius are standard: \nKelvin’s Second Law: There is no thermodynamic process whose\nsole effect is to transform heat extracted from a source at uniform\ntemperature completely into work. \nClausius’ Second Law: There is no thermodynamic process whose\nsole effect is to extract a quantity of heat from a colder reservoir\nand deliver it to a hotter reservoir. \nKelvin’s version is essentially the same as the version arrived\nat by both Carnot and Planck, whereas Clausius’ version differs\nfrom these in a few\n ways.[3] \nClausius’ version transparently rules out anti-thermodynamic\nbehavior such as a hot iron bar extracting heat from a neighboring\ncold iron bar. The cool bar cannot give up a quantity of heat to the\nwarmer bar (without something else happening). Kelvin’s\nstatement is perhaps less obvious. It originates in an observation\nabout steam engines, namely, that heat energy is a “poor”\ngrade of energy. Consider a gas-filled cylinder with a frictionless\npiston holding the gas down at one end. If we put a flame under the\ncylinder, the gas will expand and the piston can perform work, e.g.,\nit might move a ball. However, we can never convert the heat energy\nstraight into work without some other effect occurring. In this case,\nthe gas occupies a larger volume. \nIn 1854, Clausius introduced the notion of the “equivalence\nvalue” of a transformation, a concept that is the ancestor of\nthe modern day concept of entropy. Later in 1865 Clausius coined the\nterm “entropy” for a similar concept (the word derives\nfrom the Greek word for transformation). The entropy of a state \\(A\\),\n\\(S(A)\\) is defined as the integral \\(S(A) = \\int^{A}_{O} dQ/T\\) over\na reversible transformation, where \\(O\\) is some arbitrary fixed\nstate. For \\(A\\) to have an entropy, the transformation from \\(O\\) to\n\\(A\\) must be quasi-static, i.e., a succession of equilibrium states.\nContinuity considerations then imply that the initial and final states\n\\(O\\) and \\(A\\) must also be equilibrium states. Put in the language\nof entropy, the Second Law states that in a transformation from\nequilibrium state \\(A\\) to equilibrium state \\(B\\), the inequality\n\\(S(B) - S(A)\\) is greater than or equal to the \\(\\int^{A}_{B} dQ/T\\).\nLoosely put, for realistic systems, this implies that in the\nspontaneous evolution of a thermally closed system the entropy can\nnever decrease and that it attains its maximum value at equilibrium.\nWe are invited to think of the Second Law as driving the system to its\nnew, higher entropy equilibrium state. \nWith the Second Law thermodynamics is able to characterize an\nextraordinary range of phenomena under one simple law. Remarkably,\nwhether they are gases filling their available volumes, iron bars in\ncontact coming to the same temperature, vinegar and oil separating, or\nmilk mixing in your coffee, they all have an observable property in\ncommon: their entropy increases. Coupled with the First Law, the\nSecond Law is remarkably powerful. It appears that all classical\nthermodynamical behavior can be derived from these two simple\nstatements (O. Penrose 1970). \nThe above sketch represents the conventional way of describing\nthermodynamics and its Second Law. Let me mention a few questions that\nit raises. \nFirst, what is the precise location of the time-asymmetry? Almost all\ncommentators claim that it lay in the Second Law. If Uffink (2001) and\nBrown and Uffink (2001) are correct, however, then this\n“static” Second Law does not encode any time asymmetry at\nall. It is, after all, simply a relation between a few variables at\nequilibrium. While that may be right, there is no question that\nthermodynamics, if not its Second Law, makes time-asymmetric\nclaims. The spontaneous movement from non-equilibrium to equilibrium\nhappens and is assumed throughout the field. The only question is\nwhether it must be regarded as a separate assumption (perhaps\ndemanding its own name) or can somehow be derived from existing\nprinciples. It’s also worth remarking that many other principles\nof thermodynamics are time-asymmetric, e.g., the classical heat\nequation. \nSecond, what is the scope of the Second Law? There are two issues\nhere. First, does it apply to the universe as a whole, so that we can\nsay the universe’s entropy is increasing, or does it only apply\nto select sub-systems of the universe? (See Uffink 2001 for an\ninteresting historical discussion of this topic.) Many philosophers\nand physicists have balked at the idea that the universe itself has an\nentropy. As one might expect, those in the grip of an operationalist\nphilosophy are especially prone to deny that the universe as a whole\nhas an entropy. Second, what sub-systems of the universe does it\ngovern? Are the principles of thermodynamics responsible for\ngeneralizations about black holes? The field of black hole\nthermodynamics assumes it is (see the section on black hole\nthermodynamics in the entry on\n singularities and black holes,\n for discussion and references), although not all are convinced\n(Dougherty & Callender forthcoming). What about the\nmicro-realm? \nThird, how are these laws framed in a relativistic universe? They were\ndeveloped in the nineteenth century with a classical spacetime\nbackground in mind. How do we write the theory in a modern\nformulation? Surprisingly, the issue is as much conceptual as\ntechnical. The correct (special) relativistic transformation rules for\nthermodynamic quantities are controversial. Do Lorentz boosted gases\nappear hotter or colder in the new inertial frame? Albert Einstein\nhimself answered the question about the gas differently throughout his\nlife! With all the current activity of physicists being focused on the\nthermodynamics of black holes in general relativity and quantum\ngravity, it is amusing to note that special relativistic\nthermodynamics is still a field with many open questions, both\nphysically and philosophically (see Earman 1981 and Liu 1994). \nFourth, another important question concerns the reduction of\nthermodynamic concepts such as entropy to their mechanical, or\nstatistical mechanical, basis. As even a cursory glance at statistical\nmechanics reveals, there are many candidates for the statistical\nmechanical entropy, each the center of a different program in the\nfoundations of the field. Surprisingly, there is no consensus as to\nwhich entropy is best suited to be the reduction basis of the\nthermodynamic entropy (see, for example, Sklar 1993; Callender 1999;\nLavis 2005; Frigg 2008; Robertson forthcoming). Consequently, there is little\nagreement about what grounds the Second Law in statistical\nmechanics. \nDespite the worthiness of all of these issues, this article focuses on\ntwo distinct problems associated with the direction of time. \nThe first “problem of the direction of time” is: what\naccounts for the time asymmetry of thermodynamics? Thermodynamics is\nnot a fundamental physical science. Hence it must inherit its massive\ntime asymmetry from the microworld. But where? In virtue of what,\nfundamentally, is thermodynamics time asymmetric? The puzzle is\nusually said to arise due to fundamental physics being time symmetric,\nor more precisely, time reversal invariant. (A theory is time reversal\ninvariant, loosely speaking, if its laws don’t care about the\ndirection of time.) No asymmetry in, no asymmetry out; therefore there\nis a puzzle over where the asymmetry enters. However, even if\nfundamental physics is time asymmetric one can and should still demand\nan answer to the question of what accounts for thermodynamics time\nasymmetry. The answer could be non-trivial because the time asymmetry\nof fundamental physics may have nothing to do with the time asymmetry\nof thermodynamics. This situation actually appears to be the case, as\nweak interactions between quarks and leptons can violate time symmetry\nyet these violations don’t appear to be responsible for\nthermodynamic behavior. \nHistorically the problem arose in a wonderful series of debates and\narguments between the great physicist Ludwig Boltzmann and some of his\ncontemporaries, notably, Johann Loschmidt, Ernst Zermelo and Edward\nCulverwell. Boltzmann was one of the founders and most influential\ndevelopers of the field of statistical mechanics, as well as (later in\nlife) a philosopher. While seeking a mechanical underpinning of the\nSecond Law, he discovered a particularly ingenious explanation for why\nsystems tend toward equilibrium. \nIgnoring historical details (Brush 1976, Frigg & Werndl 2011,\nSklar 1993, Uffink 2006), here is the core idea loosely reconstructed\nfrom Boltzmann’s later writings. Consider an isolated gas of\n\\(N\\) particles in a box, where \\(N\\) is large enough to make the\nsystem macroscopic \\((N \\approx 10^{23}+)\\). For the sake of\nfamiliarity we will work with classical mechanics. We can characterize\nthe gas by the coordinates and momenta \\(x_{in}, p_{in}\\) of each of\nits particles and represent the whole system by a point \\(X = (q,p)\\)\nin a \\(6N\\)-dimensional phase space known as \\(\\Gamma\\), where \\(q =\n(q_1 \\ldots q_{3N})\\) and \\(p = (p_1 \\ldots p_{3N})\\).\nBoltzmann’s great insight was to see that the thermodynamic\nentropy arguably “reduced” to the volume in \\(\\Gamma\\)\npicked out by the macroscopic parameters of the system. The key\ningredient is partitioning \\(\\Gamma\\) into compartments, such that all\nof the microstates \\(X\\) in a compartment are macroscopically (and\nthus thermodynamically) indistinguishable. To each macrostate \\(M\\),\nthere corresponds a volume of \\(\\Gamma\\), \\(\\lvert\\Gamma_M\\rvert\\),\nwhose size will depend on the macrostate in question. For\ncombinatorial reasons, almost all of \\(\\Gamma\\) corresponds to a state\nof thermal equilibrium. There are simply many more ways to be\ndistributed with uniform temperature and pressure than ways to be\ndistributed with nonuniform temperature and pressure. There is a vast\nnumerical imbalance in \\(\\Gamma\\) between the states in thermal\nequilibrium and the states in thermal nonequilibrium. We now introduce Boltzmann’s famous formula (up to an additive constant) for what we might call the “Boltzmann entropy” \\(S_B\\): \\[ S_B (M(X)) = k \\log \\lvert\\Gamma_M\\rvert \\] where \\(\\lvert\\Gamma_M\\rvert\\) is the volume in \\(\\Gamma\\) associated with the macrostate \\(M\\), \\(X\\) is the microstate of the system, and \\(k\\) is Boltzmann’s constant. \\(S_B\\) provides a relative measure of the amount of \\(\\Gamma\\) corresponding to each \\(M\\). \nGiven the mentioned asymmetry in \\(\\Gamma\\), almost all microstates\nrealizing non-equilibrium macrostates are such that their\nentropy value is overwhelmingly likely to increase with time. When the\nconstraints are released on systems initially confined to small\nsections of \\(\\Gamma\\), typical systems will evolve into\nlarger compartments. Since the new equilibrium distribution occupies\nalmost all of the newly available phase space, nearly all of\nthe microstates originating in the smaller volume will tend toward\nequilibrium. Except for those incredibly rare microstates conspiring\nto stay in small compartments, microstates will evolve in such a way\nas to have \\(S_B\\) increase. Substantial questions can be raised about\nthe details of this approach. What justifies, for instance, the\nstandard probability measure on \\(\\Gamma\\)? Nonetheless, the\nBoltzmannian explanation seems to offer a plausible and powerful\nframework for understanding why the entropy of systems tends\nto increase with time. (For further explanation and discussion see\nBricmont 1995; Frigg 2008, 2009; Goldstein 2001; Hemmo & Shenker\n2012; Klein 1973; Lavis 2005; Lebowitz 1993; Uffink 2006.) \nTrouble looms over this explanation of time asymmetry (see Brown,\nMyrvold, & Uffink 2009). Before Boltzmann explained entropy\nincrease as described above, he proposed a now notorious\n“proof” known as the “\\(H\\)-theorem” to the\neffect that entropy must always increase. Loschmidt 1876/1877 and\nZermelo 1896 launched objections to the \\(H\\)-theorem. If we take as\npremises classical mechanical dynamics, they pointed out, it’s\nimpossible to get any function of the classical state to monotonically\nincrease. Loschmidt focused on the time reversal invariance of the\nclassical dynamics and Zermelo on its recurrence property (roughly,\nthat a bounded system, left to itself, will eventually return\narbitrarily close to its initial state, for any given initial state).\nThey were right: time reversal means that for every entropy-increasing\nsolution to the classical equations there is a mirror\nentropy-decreasing solution; and recurrence means that every solution\nwill at some point have its entropy decrease if we wait long enough.\nSome time asymmetric ingredient that had not been properly announced\nhad been smuggled into the theorem. \nThe reader can find this story in many textbooks and in many\nreferences cited above. An objection in their spirit (specifically,\nLoschmidt’s) can also be advanced against Boltzmann’s\nlater view sketched above. Loosely put, because the classical\nequations of motion are time reversal invariant, nothing in the\noriginal explanation necessarily referred to the direction of time\n(see Hurley 1986). Although we just stated the Boltzmannian account of\nentropy increase in terms of entropy increasing into the future, the\nexplanation can be turned around and made for the past\ntemporal direction as well. Given a gas in a box that is in a\nnonequilibrium state, the vast majority of microstates that are\nantecedents of the dynamical evolution leading to the present\nmacrostate correspond to a macrostate with higher entropy\nthan the present one. Therefore, not only is it highly likely that\ntypical microstates corresponding to a nonequilibrium state will\nevolve to  higher entropy states, but it is also highly likely\nthat they evolved from higher entropy states. \nConcisely put, the problem is that given a nonequilibrium state at\ntime \\(t_2\\), it is overwhelmingly likely that \nbut that due to the reversibility of the dynamics it is also\noverwhelmingly likely that \nwhere \\(t_1 \\lt t_2 \\lt t_3\\). However, transitions described by\n (2)\n do not seem to occur; or phrased more carefully, not both\n (1)\n and\n (2)\n occur. However we choose to use the terms “earlier” and\n“later”, clearly entropy doesn’t increase in both\ntemporal directions. For ease of exposition let us dub\n (2)\n the culprit. \nThe traditional problem is not merely that nomologically possible\n(anti-thermodynamic) behavior does not occur when it could. That is\nnot straightforwardly a problem: all sorts of nomologically\nallowed processes do not occur. Rather, the problem is that\nstatistical mechanics seems to make a prediction that is falsified,\nand that is a problem according to anyone’s theory of\nconfirmation. \nMany solutions to this problem have been proposed. Generally speaking,\nthere are two ways to solve the problem: eliminate transitions of type\n (2)\n either with special boundary conditions or with laws of nature. The\nformer method works if we assume that earlier states of the\nuniverse are of comparatively low-entropy and that\n(relatively) later states are not also low-entropy states.\nThere are no high-to-low-entropy processes simply because earlier\nentropy was very low. Alternatively, the latter method works if we can\nsomehow restrict the domain of physically possible worlds to those\nadmitting only low-to-high transitions. The laws of nature are the\nstraightjacket on what we deem physically possible. Since we need to\neliminate transitions of type\n (2)\n while keeping those of type\n (1)\n (or vice versa), a necessary condition of the laws doing this job is\nthat they be time reversal noninvariant. Our choice of strategy boils\ndown to either assuming temporally asymmetric boundary conditions or\nof adding (or changing to) time reversal noninvariant laws of nature\nthat make entropy increase likely. Many approaches to this problem\nhave thought to avoid this dilemma, but a little analysis of any\nproposed “third way” arguably proves this to be false. \nWithout proclaiming the laws of nature time asymmetric, there is no\nway to eliminate as impossible transitions\n (2)\n in favor of\n (1).\n Nevertheless, appealing to temporally asymmetric boundary conditions\nallows us to describe a world wherein\n (1)\n but not\n (2)\n occur. A cosmological hypothesis claiming that in the very distant\npast entropy was much lower will work. Boltzmann, as well as many of\nthis century’s greatest scientists, e.g., Einstein, Richard\nFeynman, and Erwin Schroedinger, saw that this hypothesis is necessary\ngiven our (mostly) time asymmetric laws. (Boltzmann, however,\nexplained this low-entropy condition by treating the observable\nuniverse as a natural statistical fluctuation away from equilibrium in\na vastly larger universe.) Earlier states do not have higher entropy\nthan present states because we make the cosmological posit that the\nuniverse began in an extremely tiny section of its available phase\nspace. Albert (2000) calls this the “Past Hypothesis” and\nargues that it solves both this problem of the direction of time and\nalso the one to be discussed below. Note that classical mechanics is\nalso compatible with a “Future Hypothesis”: the claim that\nentropy is very low in the distant future. The restriction to\n“distant” is needed, for if the near future were of\nlow-entropy, we would not expect the thermodynamic behavior that we\nsee—see Cocke 1967, Price 1996, and Schulman 1997 for discussion\nof two-time boundary conditions. \nThe Past Hypothesis offers an elegant solution to the problem of the\ndirection of time. However, there are some concerns. \nFirst, some find it incredible that (e.g.) gases everywhere for all\ntime should expand through their available volumes due to special\ninitial conditions. The common cause of these events is viewed as\nitself monstrously unlikely. Expressing this feeling, R. Penrose\n(1989) estimates that the probability, given the standard measure on\nphase space, of the universe starting in the requisite state is\nastronomically small. In response, one may hold that the Past\nHypothesis is lawlike. If so, then the probability for this state, if\nsuch exists, is one! Even if one doesn’t go down this path, one\nmay have other problems with claiming that the initial condition of\nthe universe needs further explanation. See Callender 2004a,b for such\na view and Price 1996, 2004 for the contrary position. \nSecond, another persistent line of criticism might be labeled the\n“subsystem” worry. It’s consistent with the Past\nHypothesis, after all, that none of the subsystems on Earth ever\ndisplay thermodynamically asymmetric behavior. How exactly does the\nglobal entropy increase of the universe imply local\nentropy increase among the subsystems (which, after all, is what\ncauses us to posit the Second Law in the first place)? See Winsberg\n2004 for this objection and Callender 2011a, Frisch 2010, and North\n2011 for discussion. \nThird, what exactly does the Past Hypothesis say in the context of our\nbest and most recent physics? While not denying that temporally\nasymmetric boundary conditions are needed to solve the problem, Earman\n(2006) is very critical of the Past Hypothesis, concluding that it\nisn’t even coherent enough to be false. The main problem Earman\nsees is that we cannot state the Past Hypothesis in the language of\ngeneral relativity. Callender (2010, 2011b) and Wallace (2010) discuss\nthe related question of stating the Past Hypothesis when\nself-gravitation is included. One may also consider the question in\nthe context of quantum theory (see Wallace 2013). \nIf we place an isolated concentrated homogeneous gas in the middle of\na large empty volume, we would expect the particles to spread out in\nan expanding sphere about the center of the gas, much as waves of\nradiation spread out from concentrated charge sources. It is therefore\ntempting to think that there is a relationship between the\nthermodynamic and electromagnetic arrows of time. In a debate in 1909,\nAlbert Einstein and Walther Ritz apparently disagreed about the nature\nof this relationship, although the exact points of dispute remain a\nbit unclear. The common story told is that Ritz took the position that\nthe asymmetry of radiation had to be judged lawlike and that the\nthermodynamic asymmetry could be derived from this law.\nEinstein’s position is instead that “irreversibility is\nexclusively based on reasons of probability” (Ritz and Einstein\n1909, English translation from Zeh 1989: 13). It is unclear whether\nEinstein meant probability plus the right boundary conditions, or\nsimply probability alone. In any case, Ritz is said to believe that\nthe radiation arrow causes the thermodynamic one, whereas Einstein is\nsaid to hold something closer to the opposite position. The real story\nis far more complicated, as Ritz had a particle-based ontology in mind\nas well as many additional considerations (see Frisch and Pietsch 2016\nfor subtleties of the actual historical debate). \nIf this common tale is correct—and there is reason to\nthink it isn’t the full story—then it seems that Einstein\nmust be closer to being correct than Ritz. Ritz’ position\nappears implausible if only because it implies gases composed of\nneutral particles will not tend to spread out. That aside,\nEinstein’s position is attractive if we concentrate on the wave\nasymmetry mentioned above. Using Popper 1956’s famous mechanical\nwave example as an analogy, throwing a rock into a pond so that waves\non the surface spread out into the future requires every bit the\nconspiracy that is needed for waves to converge on a point in order to\neject a rock from the bottom. However, here it does seem clear that\none process is favored thermodynamically and the other disfavored once\nwe have a thermodynamic arrow in hand. Given a solution to the\nthermodynamic arrow, impulses directed toward the center of a pond\nsuch as to eject a rock are unlikely, whereas a rock triggering\nspherical waves diverging from the point of impact are likely. Here\nthe radiation arrow seems plausibly connected to and perhaps even\nderivable from the thermodynamic arrow. The main interesting\ndifference is that Popper’s time-reversed pond seems\napproximately attainable whereas anti-thermodynamic processes seem\nmore absolutely forbidden (or at least dramatically harder to engine,\nrequiring a so-called Maxwell Demon). \nIf the wave asymmetry were the only electromagnetic arrow, then the\nabove sketch would plausibly capture the core connection between the\nthermodynamic and electromagnetic arrows of time. We would have reason\nto think that whatever causes the thermodynamic arrow also is\nresponsible for the electromagnetic arrow. That may ultimately be\ncorrect. However, it’s too early to conclude that, for\nelectromagnetism is chock full of arrows of time besides the wave\nasymmetry. Maxwell’s equations are well-known to include both “advanced” and “retarded” solutions. The retarded solution \\[ \\phi_{\\text{ret}}(r,t) = \\int dr' \\rho\\frac{(r', t- \\frac{\\lvert r'-r\\rvert}{c})}{\\lvert r'-r\\rvert} \\] gives the field amplitude \\(\\phi_{\\text{ret}}\\) at \\(r,t\\) by finding the source density \\(r\\) at \\(r'\\) at earlier times. The advanced solution \\[ \\phi_{\\text{adv}}(r,t) = \\int dr' \\rho\\frac{(r', t+ \\frac{\\lvert r'-r\\rvert}{c})}{\\lvert r'-r\\rvert} \\] gives the field amplitude in terms of the source density at \\(r'\\) at later times. Physicists routinely discard the advanced solutions for reasons of “causality”. It is not so clear thermodynamic considerations are behind this rejection of solutions, an asymmetry made all the harder to see given the freedom electromagnetism has to rewrite retarded fields in terms of advanced fields and outgoing sourceless radiation (and vice versa). Electromagnetism is also said to be allow emissions and not absorptions. Accelerating charges are also damped and not anti-damped by the field. With so many arrows besides the wave asymmetry—emission/absorption, in/out, retarded/advanced, damped/anti-damped—it’s premature to say that the thermodynamic arrow is the one arrow to rule them all. Most agree that the wave asymmetry is ultimately “thermodynamic” but after that matters are contested. \nFor further discussion of these controversial points, see the\narticles/chapters by Allori 2015; Arntzenius 1994; Atkinson 2006;\nEarman 2011; Frisch 2000, 2006; Frisch and Pietsch 2016; North 2003;\nPrice 1996, 2006; Rohrlich 2006; and Zeh 1989. \nCosmology presents us with a number of apparently temporally\nasymmetric mechanisms. The most obvious one is the inexorable\nexpansion of the universe. The spatial scale factor \\(a(t)\\), which we\nmight conceive roughly as the radius of the universe (it gives the\ndistance between co-moving observers), is increasing. The universe\nseems to be uniformly expanding relative to our local frame. Since\nthis temporal asymmetry occupies a rather unique status it is natural\nto wonder whether it might be the “master” arrow. \nThe cosmologist Thomas Gold 1962 proposed just this. Believing that\nentropy values covary with the size of the universe, Gold asserts that\nat the maximum radius the thermodynamic arrow will “flip”\ndue to the re-contraction. However, as Richard Tolman 1934 has shown\nin some detail, a universe filled with non-relativistic particles will\nnot suffer entropy increase due to expansion, nor will an expanding\nuniverse uniformly filled with blackbody radiation increase its\nentropy either. Interestingly, Tolman demonstrated that more realistic\nuniverses containing both matter and radiation will change\ntheir entropy contents. Coupled with expansion, various processes will\ncontribute to entropy increase, e.g., energy will flow from the\n“hot” radiation to the “cool” matter. So long\nas the relaxation time of these processes is larger than the expansion\ntime scale, they should generate entropy. We thus have a purely\ncosmological method of entropy generation. \nOthers (e.g., Davies 1994) have thought inflation provides a kind of\nentropy-increasing behavior—again, given the sort of matter\ncontent we have in our universe. The inflationary model is an\nalternative of sorts to the standard big bang model, although by now\nit is so well entrenched in the cosmology community that it really\ndeserves the tag “standard”. In this scenario, the\nuniverse is very early in a quantum state called a “false\nvacuum”, a state with a very high energy density and negative\npressure. Gravity acts like Einstein’s cosmological constant, so\nthat it is repulsive rather than attractive. Under this force the\nuniverse enters a period of exponential inflation, with geometry\nresembling de Sitter space. When this period ends any initial\ninhomogeneities will have been smoothed to insignificance. At this\npoint ordinary stellar evolution begins. Loosely associating\ngravitational homogeneity with low-entropy and inhomogeneity with\nhigher entropy, inflation is arguably a source of a low entropy\n“initial” condition. \nThere are other proposed sources of cosmological entropy generation,\nbut these should suffice to give the reader a flavor of the idea. We\nshall not be concerned with evaluating these scenarios in any detail.\nRather, our concern is about how these proposals explain time’s\narrow. In particular, how do they square with our earlier claim that\nthe issue boils down to either assuming temporally asymmetric boundary\nconditions or of adding time reversal non-invariant laws of\nnature? \nThe answer is not always clear, owing in part to the fact that the\nseparation between laws of nature and boundary conditions is\nespecially slippery in the science of cosmology. Advocates of the\ncosmological explanation of time’s arrow typically see\nthemselves as explaining the origin of the needed low-entropy\ncosmological condition. Some explicitly state that special initial\nconditions are needed for the thermodynamic arrow, but differ with the\nconventional “statistical” school in deducing the origin\nof these initial conditions. Earlier low-entropy conditions are not\nviewed as the boundary conditions of the spacetime. They came about,\naccording to the cosmological schools, about a second or more after\nthe big bang. But when the universe is the size of a small particle, a\nsecond or more is enough time for some kind of cosmological mechanism\nto bring about our low-entropy “initial” condition. What\ncosmologists (primarily) differ about is the precise nature of this\nmechanism. Once the mechanism creates the “initial”\nlow-entropy we have the same sort of explanation of the thermodynamic\nasymmetry as discussed in the previous section. Because the proposed\nmechanisms are supposed to make the special initial conditions\ninevitable or at least highly probable, this maneuver seems like the\nalleged “third way” mentioned above. \nThe central question about this type of explanation, as far as\nwe’re concerned, is this: Is the existence of the low\n“initial” state a consequence of the laws of nature alone\nor the laws plus boundary conditions? In other words, first, does the\nproposed mechanism produce low-entropy states given any\ninitial condition, and second, is it a consequence of the\nlaws alone or a consequence of the laws plus initial\nconditions? We want to know whether our question has merely been\nshifted back a step, whether the explanation is a disguised appeal to\nspecial initial conditions. Though we cannot here answer the question\nin general, we can say that the two mechanisms mentioned are not\nlawlike in nature. Expansion fails on two counts. There are boundary\nconditions in expanding universes that do not lead to an entropy\ngradient, i.e., conditions without the right matter-radiation content,\nand there are boundary conditions that do not lead to expansion in\nwhich entropy nonetheless increases, e.g., matter-filled Friedmann\nmodels that do not expand. Inflation fails at least on the second\ncount. Despite advertising, arbitrary initial conditions will not give\nrise to an inflationary period. Furthermore, it’s not clear that\ninflationary periods will give rise to thermodynamic asymmetries\n(Price 1996: ch. 2). The cosmological scenarios do not seem to make\nthe thermodynamic asymmetries a result of nomic necessity. The\ncosmological hypotheses may be true, and in some sense, they may even\nexplain the low-entropy initial state. But they do not appear to\nprovide an explanation of the thermodynamic asymmetry that makes it\nnomologically necessary or even likely. \nAnother way to see the point is to consider the question of whether\nthe thermodynamic arrow would “flip” if (say) the universe\nstarted to contract. Gold, as we said above, asserts that at the\nmaximum radius the thermodynamic arrow must “flip” due to\nthe re-contraction. Not positing a thermodynamic flip while\nmaintaining that entropy values covary with the radius of the universe\nis clearly inconsistent—it is what Price (1996) calls the\nfallacy of a “temporal double standard”. Gold does not\ncommit this fallacy, and so he claims that the entropy must decrease\nif ever the universe started to re-contract. However, as Albert\nwrites, \nthere are plainly locations in the phase space of the world from which\n… the world’s radius will inexorably head up and the\nworld’s entropy will inexorably head down. (2000: 90) \nSince that is the case, it doesn’t follow from law that the\nthermodynamic arrow will flip during re-contraction; therefore,\nwithout changing the fundamental laws, the Gold mechanism cannot\nexplain the thermodynamic arrow in the sense we want. \nFrom these considerations we can understand the basic dilemma\nthat runs throughout Price (1995, 1996): either we explain the earlier\nlow-entropy condition Gold-style or it is inexplicable by\ntime-symmetric physics. Because there is no net asymmetry in a Gold\nuniverse, we might paraphrase Price’s conclusion in a more\ndisturbing manner as the claim that the (local) thermodynamic arrow is\nexplicable just in case (globally) there isn’t one. However,\nnotice that this remark leaves open the idea that the laws governing\nexpansion or inflation are not time reversal invariant. (For more on\nPrice’s basic dilemma, see Callender 1998 and Price 1995.) \nFinally, it’s important to remember that this dilemma and the\nneed for a Past Hypothesis are dependent upon a particular physical\nset-up. Can we explain the thermodynamic arrow without invoking a Past\nHypothesis?  Inspired by the idea of eternal spontaneous inflation,\nCarroll and Chen (2004, Other Internet Resources) describe a model in\nwhich new baby universes (or “pocket universes”) are\nrepeatedly born from existing universes. Each birth increases the\noverall entropy of the multiverse although within each baby universe\nwe have our familiar thermodynamic asymmetry. The crucial assumption\nin this model – one also found in the gravitational theory of Barbour,\nKoslowski, and Mercati (2014) – is that entropy is unbound. It can be\narbitrarily high. With this assumption and in these models, one can do\nwithout a past Hypothesis. For discussion, see Goldstein, Tumulka,\n& Zanghi 2016 and Lazarovici and Reichert 2020. \nQuantum cosmology, it is often said, is the theory of the\nuniverse’s initial conditions. Presumably this entails that its\nposits are to be regarded as lawlike. Because theories are typically\nunderstood as containing a set of laws, quantum cosmologists\napparently assume that the distinction between laws and initial\nconditions is fluid. Particular initial conditions will be said to\nobtain as a matter of law. Hawking writes, for example, \nwe shall not have a complete model of the universe until we can say\nmore about the boundary conditions than that they must be whatever\nwould produce what we observe, (1987: 163). \nCombining such aspirations with the observation that thermodynamics\nrequires special boundary conditions leads quite naturally to the\nthought that “the second law becomes a selection principle for\nthe boundary conditions of the universe [for quantum cosmology]”\n(Laflamme 1994: 358). In other words, if one is to have a theory of\ninitial conditions, it would certainly be desirable to deduce initial\nconditions that will lead to the thermodynamic arrow. This is\nprecisely what many quantum cosmologists have sought. (This should be\ncontrasted with the arrows of time discussed in semiclassical quantum\ngravity, for example, the idea that quantum scattering processes in\nsystems with black holes violate the CPT theorem.) Since quantum\ncosmology is currently very speculative, it might be premature to\nstart worrying about what it says about time’s arrow.\nNevertheless, there has been a substantial amount of debate on this\nissue (see Haliwell et al. 1994). \nSome philosophers have sought an answer to the problem of time’s\narrow by claiming that time itself is directed. They do not\nmean time is asymmetric in the sense intended by advocates of the\ntensed theory of time. Their proposals are firmly rooted in the idea\nthat time and space are properly represented on a four-dimensional\nmanifold. The main idea is that the asymmetries in time indicate\nsomething about the nature of time itself. Christensen (1993) argues\nthat this is the most economical response to our problem since it\nposits nothing besides time as the common cause of the asymmetries,\nand we already believe in time. A proposal similar to\nChristensen’s is Weingard’s “time-ordering\nfield” (1977). Weingard’s speculative thesis is that\nspacetime is temporally oriented by a “time potential”, a\ntimelike vector field that at every spacetime point directs a vector\ninto its future light cone. In other words, supposing our spacetime is\ntemporally orientable, Weingard wants to actually orient it. The main\nvirtue of this is that it provides a time sense everywhere, even in\nspacetimes containing closed timelike curves (so long as they’re\ntemporally orientable). As he shows, any explication of the\n“earlier than” relation in terms of some other physical\nrelation will have trouble providing a consistent description of time\ndirection in such spacetimes. Another virtue of the idea is that it is\nin principle capable of explaining all the temporal\nasymmetries. If coupled to the various asymmetries in time, it would\nbe the “master arrow” responsible for the arrows of\ninterest. As Sklar (1985) notes, Weingard’s proposal makes the\npast-future asymmetry very much like the up-down asymmetry. As the\nup-down asymmetry was reduced to the existence of a gravitational\npotential—and not an asymmetry of space itself—so the\npast-future asymmetry would reduce to the time potential—and not\nan asymmetry of time itself. Of course, if one thinks of the\ngravitational metric field as part of spacetime, there is a sense in\nwhich the reduction of the up-down asymmetry really was a reduction to\na spacetime asymmetry. And if the metric field is conceived as part of\nspacetime—which is itself a huge source of contention in\nphilosophy of physics—it is natural to think of Weingard’s\ntime-ordering field as also part of spacetime. Thus his proposal\nshares a lot in common with Christensen’s suggestion. \nThis sort of proposal has been criticized by Sklar on methodological\ngrounds. Sklar (1985) claims that scientists would not accept such an\nexplanation (1985: 111–2). One might point out, however, that\nmany scientists did believe in analogues of the time-ordering field as\npossible causes of the CP\n violations.[4]\n The time-ordering field, if it exists, would be an unseen (except\nthrough its effects) common cause of strikingly ubiquitous phenomena.\nScientists routinely accept such explanations. To find a problem with\nthe time-ordering field we need not invoke methodological scruples;\ninstead we can simply ask whether it does the job asked of it. Is\nthere a mechanism that will couple the time-ordering field to\nthermodynamic phenomena? Weingard says the time potential field needs\nto be suitably coupled (1977: 130) to the non-accidental asymmetric\nprocesses, but neither he nor Christensen elaborate on how this is to\nbe accomplished. Until this is addressed satisfactorily, this\nspeculative idea must be considered interesting yet embryonic. For\nmore recent work in this vein, see Maudlin 2002. \nWhen explaining time’s arrow many philosophers and physicists\nhave focused their attention upon the unimpeachable fact that real\nsystems are open systems that are subjected to interactions of various\nsorts. Thermodynamic systems cannot be truly isolated. To take the\nmost obvious example, we can not shield a system from the influence of\ngravity. At best, we can move systems to locations feeling less and\nless gravitational force, but we can never completely decouple a\nsystem from the gravitational field. Not only do we ignore the weak\ngravitational force when doing classical thermodynamics, but we also\nignore less exotic matters, such as the walls in the standard gas in a\nbox scenario. We can do this because the time it takes for a gas to\nreach equilibrium with itself is vastly shorter than the time it takes\nthe gas plus walls system to reach equilibrium. For this reason we\ntypically discount the effects of the box walls on the gas. \nIn this approximation many have thought there lies a possible solution\nto the problem of the direction of time. Indeed, many have thought\nherein lies a solution that does not change the laws of\nclassical mechanics and does not allow for the nomological\npossibility of anti-thermodynamic behavior. In other words, advocates\nof this view seem to believe it embodies a third way. Blatt 1959;\nReichenbach 1956; Redhead and Ridderbos 1998, and to some extent,\nHorwich 1987 are a few works charmed by this idea. Myrvold 2020 is a\nrecent picture that is also in this neighborhood. \nThe idea is to take advantage of what a random perturbation of the\nrepresentative phase point would do to the evolution of a system.\nGiven our Boltzmannian setup, there is a tremendous asymmetry in phase\nspace between the volumes of points leading to equilibrium and of\npoints leading away from equilibrium. If the representative point of a\nsystem were knocked about randomly, then due to this asymmetry, it\nwould be very probable that the system at any given time be on a\ntrajectory leading toward equilibrium. Thus, if it could be argued\nthat the earlier treatment of the statistical mechanics of ideal\nsystems ignored a random perturber in the environment of the system,\nthen one would seem to have a solution to our problems. Even if the\nperturbation were weak it would still have the desired effect. The\nweak “random” previously ignored knocking of the\nenvironment is is claimed to be the cause of the approach to\nequilibrium. Prima facie, this answer to the problem escapes\nthe appeal to special initial conditions and the appeal to new\nlaws. \nBut only prima facie. A number of criticisms have been\nleveled against this maneuver. One that seems on the mark is the\nobservation that if classical mechanics is to be a universal theory,\nthen the environment must be governed by the laws of classical\nmechanics as well. The environment is not some mechanism outside the\ngovernance of physical law, after all, and when we treat it too, the\n“deus ex machina”—the random\nperturber—disappears. If we treat the gas-plus-the-container\nwalls as a classical system, it is still governed by time-reversible\nlaws that will cause the same problem as we met with the gas alone. At\nthis point one sometimes sees the response that this combined system\nof gas plus walls has a neglected environment too, and so on, and so\non, until we get to the entire universe. It is then questioned whether\nwe have a right to expect laws to apply universally (Reichenbach 1956:\n81ff). Or the point is made that we cannot write down the Hamiltonian\nfor all the interactions a real system suffers, and so there will\nalways be something “outside” what is governed by the\ntime-reversible Hamiltonian. Both of these points rely, one suspects,\non an underlying instrumentalism about the laws of nature. Our problem\nonly arises if we assume or pretend that the world literally is the\nway the theory says; dropping this assumption naturally\n“solves” the problem. Rather than further address these\nresponses, let us turn to the claim that this maneuver need not modify\nthe laws of classical mechanics. \nIf one does not make the radical proclamation that physical law does\nnot govern the environment, then it is easy to see that whatever law\ndescribes the perturber’s behavior, it cannot be the laws of\nclassical mechanics \\(if\\) the environment is to do the job required\nof it. A time-reversal noninvariant law, in contrast to the time\nsymmetric laws of classical mechanics, must govern the external\nperturber. Otherwise we can in principle subject the whole system,\nenvironment plus system of interest, to a Loschmidt reversal. The\nsystem’s velocities will reverse, as will the velocities of the\nmillions of tiny perturbers. “Miraculously”, as if there\nwere a conspiracy between the reversed system and the millions of\n“anti-perturbers”, the whole system will return to a time\nreverse of its original state. What is more, this reversal will be\njust as likely as the original process if the laws are time reversal\ninvariant. A minimal criterion of adequacy, therefore, is that the\nrandom perturbers be time reversal noninvariant. But the laws\nof classical mechanics are time reversal invariant. Consequently, if\nthis “solution” is to succeed, it must exercise new laws\nand modify or supplement classical mechanics. (Since the perturbations\nneed to be genuinely random and not merely unpredictable, and since\nclassical mechanics is deterministic, the same sort of argument could\nbe run with indeterminism instead of irreversibility. See Price 2002\nfor a diagnosis of why people have made this mistake, and also for an\nargument objecting to interventionism for offering a\n“redundant” physical mechanism responsible for entropy\n increase.)[5] \nTo the best of our knowledge our world is fundamentally quantum\nmechanical, not classical mechanical. Does this change the situation?\n“Maybe” is perhaps the best answer. Not surprisingly,\nanswers to the question are affected by one’s interpretation of\nquantum mechanics. Quantum mechanics suffers from the notorious\nmeasurement problem, a problem which demands one or another\ninterpretation of the quantum formalism. These interpretations fall\nbroadly into two types, depending on their view of the unitary\nevolution of the quantum state (e.g., evolution according to the\nSchroedinger equation): they either say that there is something more\nthan the quantum state, or that the unitary evolution is not entirely\ncorrect. The former are called “no-collapse”\ninterpretations while the latter are dubbed “collapse”\ninterpretations. This is not the place to go into the details of these\ninterpretations, but we can still sketch the outlines of the picture\npainted by quantum mechanics (for more see Albert 1992). \nModulo some philosophical concerns about the meaning of time reversal\n(Albert 2000; Earman 2002), the equation governing the unitary\nevolution of the quantum state is time reversal invariant. For\ninterpretations that add something to quantum mechanics, this\ntypically means that the resulting theory is time reversal invariant\ntoo (since it would be odd or even inconsistent to have one part of\nthe theory invariant and the other part not). Since the resulting\ntheory is time reversal invariant, it is possible to generate the\nproblem of the direction of time just as we did with classical\nmechanics. While many details are altered in the change from classical\nto no-collapse quantum mechanics, the logical geography seems to\nremain the same. \nCollapse interpretations are more interesting with respect to our\ntopic. Collapses interrupt or outright replace the unitary evolution\nof the quantum state. To date, they have always done so in a time\nreversal noninvariant manner. The resulting theory,\ntherefore, is not time reversal invariant. This fact offers a\npotential escape from our problem: the transitions of type\n (2)\n in our above statement of the problem may not be lawful. And this has\nled many thinkers throughout the century to believe that collapses\nsomehow explain the thermodynamic time asymmetry. \nMostly these postulated methods fail to provide what we want. We think\ngases relax to equilibrium even when they’re not measured by\nBohrian observers or Wignerian conscious beings. This complaint is,\nadmittedly, not independent of more general complaints about the\nadequacy of these interpretations. But perhaps because of these\ncontroversial features they have not been pushed very far in\nexplaining thermodynamics. \nMore satisfactory collapse theories exist, however. One, due to\nGhirardi, Rimini, and Weber, commonly known as GRW, can describe\ncollapses in a closed system—no dubious appeal to observers\noutside the quantum system is required. Albert (1992, 2000) has\nextensively investigated the impact GRW would have on statistical\nmechanics and thermodynamics. GRW would ground a temporally asymmetric\nprobabilistic tendency for systems to evolve toward equilibrium.\nAnti-thermodynamic behavior is not impossible according to this\ntheory. Instead it is tremendously unlikely. The innovation of the\ntheory lies in the fact that although entropy is overwhelmingly likely\nto increase toward the future, it is not also overwhelmingly likely to\nincrease toward the past (because there are no dynamic backwards\ntransition probabilities provided by the theory). So the theory does\nnot suffer from a problem of the direction of time as stated\nabove. \nThis does not mean, however, that it removes the need for something\nlike the Past Hypothesis. GRW is capable of explaining why, given a\npresent nonequilibrium state, later states should have higher entropy;\nand it can do this without also implying that earlier states have\nhigher entropy too. But it does not explain how the universe ever got\ninto a nonequilibrium state in the first place. As indicated before,\nsome are not sure what would explain this fact, if anything,\nor whether it’s something we should even aspire to explain. The\nprincipal virtue GRW would bring to the situation, Albert thinks, is\nthat it would solve or bypass various troubles involving the nature of\nprobabilities in statistical mechanics.  \nThe same type of benefit, plus arguably others, come from\na recent proposal by Chen (forthcoming). Chen suggests that we adopt\na position known as density matrix realism to help understand time’s\narrow. Instead of regarding the wavefunction as the basic\nontology of quantum theory, we take the quantum state to be represented\nby an impure density matrix. When we express the Past Hypothesis in\nterms of a density matrix, a number of virtues appear, including\ngreater harmony between the probabilities of statistical mechanics and\nquantum mechanics. It may be that interpretations of quantum mechanics\nthat are not like GRW can possess some of the same benefits that GRW\nbrings. \nMore detailed discussion of the impact quantum mechanics has on our\nproblem can be found in Albert 2000, North 2002, Price 2002 and Chen\nforthcoming. But if our superficial review is correct, we can say that\nquantum mechanics will not obviate our need for a Past Hypothesis\nthough it may well solve at least one problem related to the direction\nof time. \nFinally, let’s return to a point made in passing about the\nstatus of the Past Hypothesis. Without some new physics that\neliminates or explains the Past Hypothesis, or some satisfactory\n“third way”, it seems we are left with a bald posit of\nspecial initial conditions. One can question whether there really is\nanything unsatisfactory about this (Sklar 1993; Callender 2004b). But\nperhaps we were wrong in the first place to think of the Past\nHypothesis as a contingent boundary condition. The question “why\nthese special initial conditions?” would be answered with\n“it’s physically impossible for them to be\notherwise”, which is always a conversation stopper. Indeed,\nFeynman (1965: 116) speaks this way when explaining the statistical\nversion of the second law. \nAbsent a particular understanding of laws of nature, there is perhaps\nnot much to say about the issue. But given particular conceptions of\nlawhood, it is clear that various judgments about this issue follow\nnaturally—as we will see momentarily. However, let’s\nacknowledge that this may be to get matters backwards. It might be\nsaid that we first ought to find out whether the boundary\nconditions are lawlike, and then devise a theory of\nlaw appropriate to the answer. To decide whether or not the boundary\nconditions are lawlike based merely on current philosophical theories\nof law is to prejudge the issue. Perhaps this objection is really\nevidence of the feeling that settling the issue based on one’s\nconception of lawhood seems a bit unsatisfying. It is hard to deny\nthis. Even so, it is illuminating to have a brief look at the\nrelationships between some conceptions of lawhood and the topic of\nspecial initial conditions. For discussion and references on laws of\nnature, please refer to the entry on that topic. \nFor instance, if one agrees with John Stuart Mill that from the laws\none should be able to deduce everything and one considers the\nthermodynamic part of that “everything”, then the special\ninitial condition will be needed for such a deduction. The modern heir\nof this conception of lawhood, the one associated with Frank Ramsey\nand David Lewis (see Loewer 1996), sees laws as the axioms of the\nsimplest, most powerful, consistent deductive system possible. It is\nlikely that the specification of a special initial condition would\nemerge as an axiom in such a system, for such a constraint may well\nmake the laws much more powerful than they otherwise would be. \nWe should not expect the naïve regularity view of laws to follow\nsuit, however. On this sort of account, roughly, if \\(B\\)s always\nfollow \\(A\\)s, then it is a law of nature that \\(A\\) causes \\(B\\). To\navoid finding laws everywhere, however, this account needs to assume\nthat \\(A\\)s and \\(B\\)s are instantiated plenty of times. But the\ninitial conditions occur only once. \nFor more robust realist conceptions of law, it’s difficult to\npredict whether the special initial conditions will emerge as lawlike.\nNecessitarian accounts like Pargetter’s (1984) maintain that it\nis a law that \\(P\\) in our world iff \\(P\\) obtains at every possible\nworld joined to ours by a nomic accessibility relation. Without more\nspecific information about the nature of the accessibility relations\nand the worlds to which we’re related, one can only guess\nwhether all of the worlds relative to ours have the same special\ninitial conditions. Nevertheless some realist theories offer\napparently prohibitive criteria, so they are able to make negative\njudgments. For instance, “universalist” theories\nassociated with David Armstrong say that laws are relations between\nuniversals. Yet a constraint on initial conditions isn’t in any\nnatural way put in this form; hence it would seem the universalist\ntheory would not consider this constraint lawlike. \nPhilosophical opinion is certainly divided. The problem is that a\nlawlike boundary condition lacks many of the features we ordinarily\nattribute to laws, e.g., multiple instances, governing temporal\nevolution, etc., yet different accounts of laws focus on different\nsubsets of these features. When we turn to the issue at hand, what we\nfind is the disagreement we expect. \nLife is filled with temporal asymmetries. This directedness is one of\nthe most general features of the world we inhabit. We can break this\ngeneral tendency down into a few more specific temporal arrows. \nThe above list is not meant to be exhaustive or especially clean.\nTemporal asymmetries are everywhere. We age and die. Punchlines are at\nthe ends of jokes. Propensities and dispositions and reproductive\nfitness are all future-directed. We prefer rags-to-riches stories to\nriches-to-rags stories. Obviously there are connections amongst many\nof these arrows. Some authors have explicitly or implicitly proposed\nvarious “dependency charts” that are supposed to explain\nwhich of the above arrows depend on which for their existence. Horwich\n(1987) argues for an explanatory relationship wherein the\ncounterfactual arrow depends on the causal arrow, which depends on the\narrow of explanation, which depends on the epistemological arrow.\nLewis (1979), by contrast, thinks an alleged over-determination of\ntraces grounds the asymmetry of counterfactuals and that this in turn\ngrounds the rest. Suhler and Callender (2011) ground the psychological\narrow on the causal and knowledge asymmetries. The chart one judges\nmost appropriate will depend, to a large degree, upon one’s\ngeneral philosophical stance on many large topics. \nWhich dependency chart is the correct one is not our concern here.\nRather, the second “problem of the direction of time”\nasks: do any (all?) of these arrows ultimately hold in virtue of the\nthermodynamic arrow of time (or what grounds it)? \nSklar (1985) provides useful examples to have in mind. Consider the\nup-down asymmetry. It plausibly reduces to the local gravitational\ngradient. Astronauts on the moon think down is the direction toward\nthe center of the moon, not wherever it was when they left Earth. By\ncontrast, there is (probably) merely a correlation between the\nleft-right asymmetry (say, in snail shells) and parity violations in\nhigh-energy particle physics. The second problem asks whether any of\nthe above temporal asymmetries are to the thermodynamic arrow as the\nup-down asymmetry is to the local gravitational gradient. Of course,\nwe don’t expect anything quite so straightforward. Sklar\ndescribes an experiment where iron dust inserted in the ear sacs of\nfish cause the fish to swim upside down when a magnet is held over the\ntank, presumably altering their sense of up and down. But as Jos\nUffink remarked to me, going inside a refrigerator doesn’t cause\nus to remember the future. The connections, if any, are bound to be\nsubtle. \nInspired by Boltzmann’s attempts in this regard, many\nphilosophers have sought such reductions, either partial or total.\nGrünbaum (1973) and Smart (1967) develop entropic accounts of the\nknowledge asymmetry. Lewis (1979) suspects the asymmetry of traces is\nlinked to the thermodynamic arrow but provides no specifics. Dowe\n(1992), like a few others, ties the direction of causation to the\nentropy gradient. And some have also tied the psychological arrow to\nthis gradient (for a discussion see Kroes 1985). Perhaps the most\nambitious attempts at grounding many arrows all at once can be found\nin Reichenbach 1956, Horwich 1987, and Albert 2000, 2015. Each of\nthese books offers possible thermodynamic explanations for the causal\nand epistemic arrows, as well as many subsidiary arrows. \nA straightforward reduction of these arrows to entropy is probably not\nin the cards (Earman 1974; Horwich 1987). Consider the epistemic arrow\nof time. The traditional entropic account claimed that because we know\nthere are many more entropy-increasing rather than entropy-decreasing\nsystems in the world (or our part of it), we can infer when we see a\nlow-entropy system that it was preceded and caused by an interaction\nwith something outside the system. To take the canonical example,\nimagine you are walking on the beach and come across a footprint in\nthe sand. You can infer that earlier someone walked by (in contrast to\nit arising as a random fluctuation). In other words, you infer, due to\nits high order, that it was caused by something previously also of\nhigh (or higher) order, i.e, someone walking. \nHowever, the entropic account faces some very severe challenges.\nFirst, do footprints on beaches have well-defined thermodynamic\nentropies? To describe the example we switched from low-entropy to\nhigh order, but the association between entropy and our ordinary\nconcept of order is tenuous at best and usually completely misleading.\n(To appreciate this, just consider what happens to your salad dressing\nafter it is left undisturbed. Order increases when the oil and vinegar\nseparate, yet entropy has increased.) To describe the range of systems\nabout which we have knowledge, the account needs something broader\nthan the thermodynamic entropy. But what? Reichenbach is forced to\nmove to a notion of quasi-entropy, losing the reduction in the\nprocess. Second, the entropic account doesn’t license the\ninference to a human being walking on the beach. All it tells you is\nthat the grains of sand in the footprint interacted with its\nenvironment previously, which barely scratches the surface of our\nability to tell detailed stories about what happened in the past.\nThird, even if we entertain a broader understanding of entropy, it\nstill doesn’t always work. Consider Earman’s (1974)\nexample of a bomb destroying a city. From the destruction we may infer\nthat a bomb went off; yet the bombed city does not have lower entropy\nthan its surroundings or even any type of intuitively higher order\nthan its surroundings. \nPresumably for these reasons, contemporary theories abandon the\nattempt to ground the arrows of time on thermodynamic entropy.\nInstead, they turn to statistical mechanics, that which grounds the\nthermodynamic arrow. This more general basis is regarded as more\nfertile ground for the other arrows. In effect, the thermodynamic\narrow is just regarded as another non-basic arrow like those four\nmention above. Horwich (1987) traces the arrows back to initial\nmicro-chaos. Albert (2000, 2015) and Loewer (2012) instead trace them\nto a package dubbed the Mentaculus (after the Coen\nbrothers’ film, A Serious Man, 2009). Let’s\nbriefly consider how Albert and Loewer propose to derive the\nthermodynamic arrow, the epistemic arrow, and the causal arrow all\nfrom the Mentaculus. \nIn the Coen brothers’ film, the character Arthur Gopnik, a\nmathematician, spends his days on a couch filling a notebook with a\nprobability map of the universe, the Mentaculus. It is an apt name for\nwhat statistical mechanics provides us according to Albert and Loewer.\nIn effect, it provides us with a probability map for every macroscopic\ngeneralization because it provides probabilities over all the\nmicrostates realizing these macrostates. The package is composed of\nthe following elements: the past hypothesis (that the entropy of\ninitial macrostate \\(M(0)\\) is extremely low), a uniform probability\ndistribution over the microstates that realize \\(M(0)\\), the present\nmacrostate \\(M(t)\\), and the dynamical laws of the microlevel. \nThis package, they say, implies the thermodynamic arrow. We\n“derive” it from basic physics by making a case at time\n\\(t\\) that \nBoltzmann, Gibbs and many others make the case, although it’s\nworth bearing in mind that they do so rigorously only in ideal cases\nand much remains controversial (see above). Still, it strikes many as\nphysically plausible. One could say a lot more, but let’s grant\nthis. Then notice that the first problem of the direction of time is\nblocked by the Past Hypothesis. One conditionalizes on the uniform\ndistribution given \\(M(0)\\) and \\(M(t)\\), not merely \\(M(t)\\). The\nconstraint at one end of the universe makes the claim that earlier\nentropy was higher unlikely. If correct, we have an honest-to-goodness\nreduction of a special science law “the second law of\nthermodynamics” from the bottom. \nBut this package also implies more. Turn to the causal arrow. As a\nvery rough first approximation, causation can be analyzed\nprobabilistically. Cause \\(C\\) causes effect \\(E\\) just in case \\(C\\)\nis prior to \\(E\\) and the probability of \\(E\\) given \\(C\\) and\nbackground \\(B\\) is greater than the probability of \\(E\\) given \\(B\\)\nalone. Of course, there are major problems with this account (see the\nentry on Probabilistic Causation). Yet the core intuition appears to\ncome from the package, as one gets the temporal priority of causes\nfrom the Past Hypothesis and the probabilities from statistical\nmechanics. Together, they are claimed to explain why we can manipulate\ncauses to produce effects but not vice versa. Turn to the epistemic\narrow. Reflect on the nature of records. When you weigh yourself on a\nscale, one produces a record of one’s weight. This record is\nbased on an inference comparing the states of the scale at two\ndifferent times. I’m (say) 180 lbs if the scale was in its\nfunctioning ready state at 0 lbs before I stepped on it. The idea,\nvery loosely (see Albert 2000, 2015 and Loewer 2012 for the details)\nis that the Past Hypothesis effectively is the world’s Ready\nState. This highly constrained state is what causes there to be\nmacroscopic traces of the past in the present but not macroscopic\ntraces of the future in the present. \nNaturally, this ambitious program met with vigorous criticism. The\nidea that statistical mechanics implies (probabilistically) the truth\nor falsity of virtually every counterfactual-supporting generalization\nin all of science and everyday life strikes many as going too far. See\nCallender and Cohen 2010, Earman 2006, Frisch 2010, Leeds 2003, North\n2011, Westlake 2014, Winsberg 2004 and some essays in Wilson 2014. \nLong ago Boltzmann (e.g., 1895) suggested that the temporal\nasymmetries discussed above are explained by the direction of\nincreasing entropy. A lot of progress has been made developing this\ntantalizing thesis. Nevertheless, just as work on the first problem of\nthe origins of the thermodynamic arrow remains active, so too does\nresearch on the second.","contact.mail":"ccallender@ucsd.edu","contact.domain":"ucsd.edu"}]
