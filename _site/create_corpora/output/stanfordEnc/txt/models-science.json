[{"date.published":"2006-02-27","date.changed":"2020-02-04","url":"https://plato.stanford.edu/entries/models-science/","author1":"Roman Frigg","author1.info":"http://www.lse.ac.uk/collections/philosophyLogicAndScientificMethod/WhosWho/staffhomepages/frigg.htm","author2.info":"http://stephanhartmann.org/","entry":"models-science","body.text":"\n\n\nModels are of central importance in many scientific contexts. The\ncentrality of models such as inflationary models in cosmology,\ngeneral-circulation models of the global climate, the double-helix\nmodel of DNA, evolutionary models in biology, agent-based models in\nthe social sciences, and general-equilibrium models of markets in\ntheir respective domains is a case in point (the\n Other Internet Resources\n section at the end of this entry contains links to online resources\nthat discuss these models). Scientists spend significant amounts of\ntime building, testing, comparing, and revising models, and much\njournal space is dedicated to interpreting and discussing the\nimplications of models.\n\n\nAs a result, models have attracted philosophers’ attention and\nthere are now sizable bodies of literature about various aspects of\nscientific modeling. A tangible result of philosophical engagement\nwith models is a proliferation of model types recognized in the\nphilosophical literature. Probing models,\nphenomenological models, computational models,\ndevelopmental models, explanatory models,\nimpoverished models, testing models, idealized\nmodels, theoretical models, scale models,\nheuristic models, caricature models, exploratory\nmodels, didactic models, fantasy models,\nminimal models, toy models, imaginary\nmodels, mathematical models, mechanistic\nmodels, substitute models, iconic models,\nformal models, analogue models, and instrumental\nmodels are but some of the notions that are used to categorize\nmodels. While at first glance this abundance is overwhelming, it can\nbe brought under control by recognizing that these notions pertain to\ndifferent problems that arise in connection with models. Models raise\nquestions in semantics (how, if at all, do models represent?),\nontology (what kind of things are models?), epistemology (how do we\nlearn and explain with models?), and, of course, in other domains\nwithin philosophy of science.\n\nMany scientific models are representational models: they represent a\nselected part or aspect of the world, which is the model’s\ntarget system. Standard examples are the billiard ball model of a gas,\nthe Bohr model of the atom, the Lotka–Volterra model of predator–prey\ninteraction, the Mundell–Fleming model of an open economy, and the\nscale model of a bridge. \nThis raises the question what it means for a model to represent a\ntarget system. This problem is rather involved and decomposes into\nvarious subproblems. For an in-depth discussion of the issue of\nrepresentation, see the entry on\n scientific representation.\n At this point, rather than addressing the issue of what it means for\na model to represent, we focus on a number of different kinds of\nrepresentation that play important roles in the practice of\nmodel-based science, namely scale models, analogical models, idealized\nmodels, toy models, minimal models, phenomenological models,\nexploratory models, and models of data. These categories are not\nmutually exclusive, and a given model can fall into several categories\nat once. \nScale models. Some models are down-sized or enlarged copies\nof their target systems (Black 1962). A typical example is a small\nwooden car that is put into a wind tunnel to explore the actual\ncar’s aerodynamic properties. The intuition is that a scale\nmodel is a naturalistic replica or a truthful mirror image of the\ntarget; for this reason, scale models are sometimes also referred to\nas “true models” (Achinstein 1968: Ch. 7). However, there\nis no such thing as a perfectly faithful scale model; faithfulness is\nalways restricted to some respects. The wooden scale model of the car\nprovides a faithful portrayal of the car’s shape but not of its\nmaterial. And even in the respects in which a model is a faithful\nrepresentation, the relation between model-properties and\ntarget-properties is usually not straightforward. When engineers use,\nsay, a 1:100 scale model of a ship to investigate the resistance that\nan actual ship experiences when moving through the water, they cannot\nsimply measure the resistance the model experiences and then multiply\nit with the scale. In fact, the resistance faced by the model does not\ntranslate into the resistance faced by the actual ship in a\nstraightforward manner (that is, one cannot simply scale the water\nresistance with the scale of the model: the real ship need not have\none hundred times the water resistance of its 1:100 model). The two\nquantities stand in a complicated nonlinear relation with each other,\nand the exact form of that relation is often highly nontrivial and\nemerges as the result of a thoroughgoing study of the situation\n(Sterrett 2006, forthcoming; Pincock forthcoming). \nAnalogical models. Standard examples of analogical models\ninclude the billiard ball model of a gas, the hydraulic model of an\neconomic system, and the dumb hole model of a black hole. At the most\nbasic level, two things are analogous if there are certain relevant\nsimilarities between them. In a classic text, Hesse (1963)\ndistinguishes different types of analogies according to the kinds of\nsimilarity relations into which two objects enter. A simple type of\nanalogy is one that is based on shared properties. There is an analogy\nbetween the earth and the moon based on the fact that both are large,\nsolid, opaque, spherical bodies that receive heat and light from the\nsun, revolve around their axes, and gravitate towards other bodies.\nBut sameness of properties is not a necessary condition. An analogy\nbetween two objects can also be based on relevant similarities between\ntheir properties. In this more liberal sense, we can say that there is\nan analogy between sound and light because echoes are similar to\nreflections, loudness to brightness, pitch to color, detectability by\nthe ear to detectability by the eye, and so on. \nAnalogies can also be based on the sameness or resemblance of\nrelations between parts of two systems rather than on their monadic\nproperties. It is in this sense that the relation of a father to his\nchildren is asserted to be analogous to the relation of the state to\nits citizens. The analogies mentioned so far have been what Hesse\ncalls “material analogies”. We obtain a more formal notion\nof analogy when we abstract from the concrete features of the systems\nand only focus on their formal set-up. What the analogue model then\nshares with its target is not a set of features, but the same pattern\nof abstract relationships (i.e., the same structure, where structure\nis understood in a formal sense). This notion of analogy is closely\nrelated to what Hesse calls “formal analogy”. Two items\nare related by formal analogy if they are both interpretations of the\nsame formal calculus. For instance, there is a formal analogy between\na swinging pendulum and an oscillating electric circuit because they\nare both described by the same mathematical equation. \nA further important distinction due to Hesse is the one between\npositive, negative, and neutral analogies. The positive analogy\nbetween two items consists in the properties or relations they share\n(both gas molecules and billiard balls have mass); the negative\nanalogy consists in the properties they do not share (billiard balls\nare colored, gas molecules are not); the neutral analogy comprises the\nproperties of which it is not known (yet) whether they belong to the\npositive or the negative analogy (do billiard balls and molecules have\nthe same cross section in scattering processes?). Neutral analogies\nplay an important role in scientific research because they give rise\nto questions and suggest new hypotheses. For this reason several\nauthors have emphasized the heuristic role that analogies play in\ntheory and model construction, as well as in creative thought\n(Bailer-Jones and Bailer-Jones 2002; Bailer-Jones 2009: Ch. 3; Hesse\n1974; Holyoak and Thagard 1995; Kroes 1989; Psillos 1995; and the\nessays collected in Helman 1988). See also the entry on\n analogy and analogical reasoning. \nIt has also been discussed whether using analogical models can in some\ncases be confirmatory in a Bayesian sense. Hesse (1974: 208–219)\nargues that this is possible if the analogy is a material analogy.\nBartha (2010, 2013 [2019]) disagrees and argues that analogical models\ncannot be confirmatory in a Bayesian sense because the information\nencapsulated in an analogical model is part of the relevant background\nknowledge, which has the consequence that the posterior probability of\na hypothesis about a target system cannot change as a result of\nobserving the analogy. Analogical models can therefore only establish\nthe plausibility of a conclusion in the sense of justifying a\nnon-negligible prior probability assignment (Bartha 2010:\n§8.5). \nMore recently, these questions have been discussed in the context of\nso-called analogue experiments, which promise to provide knowledge\nabout an experimentally inaccessible target system (e.g., a black\nhole) by manipulating another system, the source system (e.g., a\nBose–Einstein condensate). Dardashti, Thébault, and Winsberg\n(2017) and Dardashti, Hartmann et al. (2019) have argued that, given\ncertain conditions, an analogue simulation of one system by another\nsystem can confirm claims about the target system (e.g., that black\nholes emit Hawking radiation). See Crowther et al. (forthcoming) for a\ncritical discussion, and also the entry on\n computer simulations in science. \nIdealized models. Idealized models are models that involve a\ndeliberate simplification or distortion of something complicated with\nthe objective of making it more tractable or understandable.\nFrictionless planes, point masses, completely isolated systems,\nomniscient and fully rational agents, and markets in perfect\nequilibrium are well-known examples. Idealizations are a crucial means\nfor science to cope with systems that are too difficult to study in\ntheir full complexity (Potochnik 2017). \nPhilosophical debates over idealization have focused on two general\nkinds of idealizations: so-called Aristotelian and Galilean\nidealizations. Aristotelian idealization amounts to “stripping\naway”, in our imagination, all properties from a concrete object\nthat we believe are not relevant to the problem at hand. There is\ndisagreement on how this is done. Jones (2005) and Godfrey-Smith\n(2009) offer an analysis of abstraction in terms of truth: while an\nabstraction remains silent about certain features or aspects of the\nsystem, it does not say anything false and still offers a true (albeit\nrestricted) description. This allows scientists to focus on a limited\nset of properties in isolation. An example is a classical-mechanics\nmodel of the planetary system, which describes the position of an\nobject as a function of time and disregards all other properties of\nplanets. Cartwright (1989: Ch. 5), Musgrave (1981), who uses the term\n“negligibility assumptions”, and Mäki (1994), who\nspeaks of the “method of isolation”, allow abstractions to\nsay something false, for instance by neglecting a causally relevant\nfactor. \nGalilean idealizations are ones that involve deliberate distortions:\nphysicists build models consisting of point masses moving on\nfrictionless planes; economists assume that agents are omniscient;\nbiologists study isolated populations; and so on. Using\nsimplifications of this sort whenever a situation is too difficult to\ntackle was characteristic of Galileo’s approach to science. For\nthis reason it is common to refer to ‘distortive’\nidealizations of this kind as “Galilean idealizations”\n(McMullin 1985). An example for such an idealization is a model of\nmotion on an ice rink that assumes the ice to be frictionless, when,\nin reality, it has low but non-zero friction. \nGalilean idealizations are sometimes characterized as controlled\nidealizations, i.e., as ones that allow for de-idealization by\nsuccessive removal of the distorting assumptions (McMullin 1985;\nWeisberg 2007). Thus construed, Galilean idealizations don’t\ncover all distortive idealizations. Batterman (2002, 2011) and Rice\n(2015, 2019) discuss distortive idealizations that are ineliminable in\nthat they cannot be removed from the model without dismantling the\nmodel altogether. \nWhat does a model involving distortions tell us about reality? Laymon\n(1991) formulated a theory which understands idealizations as ideal\nlimits: imagine a series of refinements of the actual situation which\napproach the postulated limit, and then require that the closer the\nproperties of a system come to the ideal limit, the closer its\nbehavior has to come to the behavior of the system at the limit\n(monotonicity). If this is the case, then scientists can study the\nsystem at the limit and carry over conclusions from that system to\nsystems distant from the limit. But these conditions need not always\nhold. In fact, it can happen that the limiting system does not\napproach the system at the limit. If this happens, we are faced with a\nsingular limit (Berry 2002). In such cases the system at the limit can\nexhibit behavior that is different from the behavior of systems\ndistant from the limit. Limits of this kind appear in a number of\ncontexts, most notably in the theory of phase transitions in\nstatistical mechanics. There is, however, no agreement over the\ncorrect interpretation of such limits. Batterman (2002, 2011) sees\nthem as indicative of emergent phenomena, while Butterfield (2011a,b)\nsees them as compatible with reduction (see also the entries on\n intertheory relations in physics\n and\n scientific reduction). \nGalilean and Aristotelian idealizations are not mutually exclusive,\nand many models exhibit both in that they take into account a narrow\nset of properties and distort them. Consider again the\nclassical-mechanics model of the planetary system: the model only\ntakes a narrow set of properties into account and distorts them, for\ninstance by describing planets as ideal spheres with a\nrotation-symmetric mass distribution. \nA concept that is closely related to idealization is approximation. In\na broad sense, A can be called an approximation of B if\nA is somehow close to B. This, however, is too broad\nbecause it makes room for any likeness to qualify as an approximation.\nRueger and Sharp (1998) limit approximations to quantitative\ncloseness, and Portides (2007) frames it as an essentially\nmathematical concept. On that notion A is an approximation of\nB iff A is close to B in a specifiable\nmathematical sense, where the relevant sense of “close”\nwill be given by the context. An example is the approximation of one\ncurve with another one, which can be achieved by expanding a function\ninto a power series and only keeping the first two or three terms. In\ndifferent situations we approximate an equation with another one by\nletting a control parameter tend towards zero (Redhead 1980). This\nraises the question of how approximations are different from\nidealizations, which can also involve mathematical closeness. Norton\n(2012) sees the distinction between the two as referential: an\napproximation is an inexact description of the target while an\nidealization introduces a secondary system (real or fictitious) which\nstands for the target system (while being distinct from it). If we say\nthat the period of the pendulum on the wall is roughly two seconds,\nthen this is an approximation; if we reason about the real pendulum by\nassuming that the pendulum bob is a point mass and that the string is\nmassless (i.e., if we assume that the pendulum is a so-called ideal\npendulum), then we use an idealization. Separating idealizations and\napproximations in this way does not imply that there cannot be\ninteresting relations between the two. For instance, an approximation\ncan be justified by pointing out that it is the mathematical\nexpression of an acceptable idealization (e.g., when we neglect a\ndissipative term in an equation of motion because we make the\nidealizing assumption that the system is frictionless). \nToy models. Toy models are extremely simplified and strongly\ndistorted renderings of their targets, and often only represent a\nsmall number of causal or explanatory factors (Hartmann 1995;\nReutlinger et al. 2018; Nguyen forthcoming). Typical examples are the\nLotka–Volterra model in population ecology (Weisberg 2013) and the\nSchelling model of segregation in the social sciences (Sugden\n2000). Toy models usually\ndo not perform well in terms of prediction and empirical adequacy, and\nthey seem to serve other epistemic goals (more on these in\n Section 3).\n This raises the question whether they should be regarded as\nrepresentational at all (Luczak 2017). \nSome toy models are characterized as “caricatures”\n(Gibbard and Varian 1978; Batterman and Rice 2014). Caricature models\nisolate a small number of salient characteristics of a system and\ndistort them into an extreme case. A classic example is\nAkerlof’s (1970) model of the car market (“the market for\nlemons”), which explains the difference in price between new and\nused cars solely in terms of asymmetric information, thereby\ndisregarding all other factors that may influence the prices of cars\n(see also Sugden 2000).\nHowever, it is controversial whether such highly idealized models can\nstill be regarded as informative representations of their target\nsystems. For a discussion of caricature models, in particular in\neconomics, see Reiss (2006). \nMinimal models. Minimal models are closely related to toy\nmodels in that they are also highly simplified. They are so simplified\nthat some argue that they are non-representational: they lack any\nsimilarity, isomorphism, or resemblance relation to the world\n(Batterman and Rice 2014). It has been argued that many economic\nmodels are of this kind (Grüne-Yanoff 2009). Minimal economic models are\nalso unconstrained by natural laws, and do not isolate any real\nfactors (ibid.). And yet, minimal models help us to learn\nsomething about the world in the sense that they function as\nsurrogates for a real system: scientists can study the model to learn\nsomething about the target. It is, however, controversial whether\nminimal models can assist scientists in learning something about the\nworld if they do not represent anything (Fumagalli 2016). Minimal\nmodels that purportedly lack any similarity or representation are also\nused in different parts of physics to explain the macro-scale behavior\nof various systems whose micro-scale behavior is extremely diverse\n(Batterman and Rice 2014; Rice 2018, 2019; Shech 2018). Typical\nexamples are the features of phase transitions and the flow of fluids.\nProponents of minimal models argue that what provides an explanation\nof the macro-scale behavior of a system in these cases is not a\nfeature that system and model have in common, but the fact that the\nsystem and the model belong to the same universality class (a\nclass of models that exhibit the same limiting behavior even though\nthey show very different behavior at finite scales). It is, however,\ncontroversial whether explanations of this kind are possible without\nreference to at least some common features (Lange 2015; Reutlinger\n2017). \nPhenomenological models. Phenomenological models have been\ndefined in different, although related, ways. A common definition\ntakes them to be models that only represent observable properties of\ntheir targets and refrain from postulating hidden mechanisms and the\nlike (Bokulich 2011). Another approach, due to McMullin (1968),\ndefines phenomenological models as models that are independent of\ntheories. This, however, seems to be too strong. Many phenomenological\nmodels, while failing to be derivable from a theory, incorporate\nprinciples and laws associated with theories. The liquid-drop model of\nthe atomic nucleus, for instance, portrays the nucleus as a liquid\ndrop and describes it as having several properties (surface tension\nand charge, among others) originating in different theories\n(hydrodynamics and electrodynamics, respectively). Certain aspects of\nthese theories—although usually not the full theories—are\nthen used to determine both the static and dynamical properties of the\nnucleus. Finally, it is tempting to identify phenomenological models\nwith models of a phenomenon. Here, “phenomenon”\nis an umbrella term covering all relatively stable and general\nfeatures of the world that are interesting from a scientific point of\nview. The weakening of sound as a function of the distance to the\nsource, the decay of alpha particles, the chemical reactions that take\nplace when a piece of limestone dissolves in an acid, the growth of a\npopulation of rabbits, and the dependence of house prices on the base\nrate of the Federal Reserve are phenomena in this sense. For further\ndiscussion, see Bailer-Jones (2009: Ch. 7), Bogen and Woodward (1988),\nand the entry on\n theory and observation in science. \nExploratory models. Exploratory models are models which are\nnot proposed in the first place to learn something about a specific\ntarget system or a particular experimentally established phenomenon.\nExploratory models function as the starting point of further\nexplorations in which the model is modified and refined. Gelfert\n(2016) points out that exploratory models can provide\nproofs-of-principle and suggest how-possibly explanations (2016: Ch. 4). As an example, Gelfert mentions early models in theoretical\necology, such as the Lotka–Volterra model of predator–prey\ninteraction, which mimic the qualitative behavior of speed-up and\nslow-down in population growth in an environment with limited\nresources (2016: 80). Such models do not give an accurate account of\nthe behavior of any actual population, but they provide the starting\npoint for the development of more realistic models. Massimi (2019)\nnotes that exploratory models provide modal knowledge. Fisher (2006)\nsees these models as tools for the examination of the features of a\ngiven theory. \nModels of data. A model of data (sometimes also “data\nmodel”) is a corrected, rectified, regimented, and in many\ninstances idealized version of the data we gain from immediate\nobservation, the so-called raw data (Suppes 1962). Characteristically,\none first eliminates errors (e.g., removes points from the record that\nare due to faulty observation) and then presents the data in a\n“neat” way, for instance by drawing a smooth curve through\na set of points. These two steps are commonly referred to as\n“data reduction” and “curve fitting”. When we\ninvestigate, for instance, the trajectory of a certain planet, we\nfirst eliminate points that are fallacious from the observation\nrecords and then fit a smooth curve to the remaining ones. Models of\ndata play a crucial role in confirming theories because it is the\nmodel of data, and not the often messy and complex raw data, that\ntheories are tested against. \nThe construction of a model of data can be extremely complicated. It\nrequires sophisticated statistical techniques and raises serious\nmethodological as well as philosophical questions. How do we decide\nwhich points on the record need to be removed? And given a clean set\nof data, what curve do we fit to it? The first question has been dealt\nwith mainly within the context of the philosophy of experiment (see,\nfor instance, Galison 1997 and Staley 2004). At the heart of the\nlatter question lies the so-called curve-fitting problem, which is\nthat the data themselves dictate neither the form of the fitted curve\nnor what statistical techniques scientists should use to construct a\ncurve. The choice and rationalization of statistical techniques is the\nsubject matter of the philosophy of statistics, and we refer the\nreader to the entry\n Philosophy of Statistics\n and to Bandyopadhyay and Forster (2011) for a discussion of these\nissues. Further discussions of models of data can be found in\nBailer-Jones (2009: Ch. 7), Brewer and Chinn (1994), Harris (2003),\nHartmann (1995), Laymon (1982), Mayo (1996, 2018), and Suppes\n(2007). \nThe gathering, processing, dissemination, analysis, interpretation, and\nstorage of data raise many important questions beyond the relatively\nnarrow issues pertaining to models of data. Leonelli (2016, 2019)\ninvestigates the status of data in science, argues that data should\nbe defined not by their provenance but by their evidential function,\nand studies how data travel between different contexts. \nWhat are models? That is, what kind of object are scientists dealing\nwith when they work with a model? A number of authors have voiced\nskepticism that this question has a meaningful answer, because models\ndo not belong to a distinctive ontological category and anything can\nbe a model (Callender and Cohen 2006; Giere 2010; Suárez 2004;\nSwoyer 1991; Teller 2001). Contessa (2010) replies that this is a\nnon sequitur. Even if, from an ontological point of view,\nanything can be a model and the class of things that are referred to\nas models contains a heterogeneous collection of different things, it\ndoes not follow that it is either impossible or pointless to develop\nan ontology of models. This is because even if not all models are of a\nparticular ontological kind, one can nevertheless ask to what\nontological kinds the things that are de facto used as models\nbelong. There may be several such kinds and each kind can be analyzed\nin its own right. What sort of objects scientists use as models has\nimportant repercussions for how models perform relevant functions such\nas representation and explanation, and hence this issue cannot be\ndismissed as “just sociology”. \nThe objects that commonly serve as models indeed belong to different\nontological kinds: physical objects, fictional objects, abstract\nobjects, set-theoretic structures, descriptions, equations, or\ncombinations of some of these, are frequently referred to as models,\nand some models may fall into yet other classes of things. Following\nContessa’s advice, the aim then is to develop an ontology for\neach of these. Those with an interest in ontology may see this as a\ngoal in its own right. It pays noting, however, that the question has\nreverberations beyond ontology and bears on how one understands the\nsemantics and the epistemology of models. \nSome models are physical objects. Such models are commonly referred to\nas “material models”. Standard examples of models of this\nkind are scale models of objects like bridges and ships (see\n Section 1),\n Watson and Crick’s metal model of DNA (Schaffner 1969),\nPhillips and Newlyn’s hydraulic model of an economy (Morgan and\nBoumans 2004), the US Army Corps of Engineers’ model of the San\nFrancisco Bay (Weisberg 2013), Kendrew’s plasticine model of\nmyoglobin (Frigg and Nguyen 2016), and model organisms in the life\nsciences (Leonelli and Ankeny 2012; Leonelli 2010; Levy and Currie\n2015). All these are material objects that serve as models. Material\nmodels do not give rise to ontological difficulties over and above the\nwell-known problems in connection with objects that metaphysicians\ndeal with, for instance concerning the nature of properties, the\nidentity of objects, parts and wholes, and so on. \nHowever, many models are not material models. The Bohr model\nof the atom, a frictionless pendulum, or an isolated population, for\ninstance, are in the scientist’s mind rather than in the\nlaboratory and they do not have to be physically realized and\nexperimented upon to serve as models. These “non-physical”\nmodels raise serious ontological questions, and how they are best\nanalyzed is debated controversially. In the remainder of this section\nwe review some of the suggestions that have attracted attention in the\nrecent literature on models. \nWhat has become known as the fiction view of models sees\nmodels as akin to the imagined objects of literary fiction—that\nis, as akin to fictional characters like Sherlock Holmes or fictional\nplaces like Middle Earth (Godfrey-Smith 2007). So when Bohr introduced\nhis model of the atom he introduced a fictional object of the same\nkind as the object Conan Doyle introduced when he invented Sherlock\nHolmes. This view squares well with scientific practice, where\nscientists often talk about models as if they were objects and often\ntake themselves to be describing imaginary atoms, populations,\nor economies. It also squares well with philosophical views that see\nthe construction and manipulation of models as essential aspects of\nscientific investigation (Morgan 1999), even if models are not\nmaterial objects, because these practices seem to be directed toward\nsome kind of object. \nWhat philosophical questions does this move solve? Fictional discourse\nand fictional entities face well-known philosophical questions, and\none may well argue that simply likening models to fictions amounts to\nexplaining obscurum per obscurius (for a discussion of these\nquestions, see the entry on\n fictional entities).\n One way to counter this objection and to motivate the fiction view of\nmodels is to point to the view’s heuristic power. In this vein\nFrigg (2010b) identifies five specific issues that an ontology of\nmodels has to address and then notes that these issues arise in very\nsimilar ways in the discussion about fiction (the issues are the\nidentity conditions, property attribution, the semantics of\ncomparative statements, truth conditions, and the epistemology of\nimagined objects). Likening models to fiction then has heuristic value\nbecause there is a rich literature on fiction that offers a number of\nsolutions to these issues. \nOnly a small portion of the options available in the extensive\nliterature on fictions have actually been explored in the context of\nscientific models. Contessa (2010) formulates what he calls the\n“dualist account”, according to which a model is an\nabstract object that stands for a possible concrete object. The\nRutherford model of the atom, for instance, is an abstract object that\nacts as a stand-in for one of the possible systems that contain an\nelectron orbiting around a nucleus in a well-defined orbit.\nBarberousse and Ludwig (2009) and Frigg (2010b) take a different route\nand develop an account of models as fictions based on Walton’s\n(1990) pretense theory of fiction. According to this view the\nsentences of a passage of text introducing a model should be seen as a\nprop in a game of make-believe, and the model is the product of an act\nof pretense. This is an antirealist position in that it takes talk of\nmodel “objects” to be figures of speech because ultimately\nthere are no model objects—models only live in scientists’\nimaginations. Salis (forthcoming) reformulates this view to become\nwhat she calls the “the new fiction view of models”. The\ncore difference lies in the fact that what is considered as the model\nare the model descriptions and their content rather than the\nimaginings that they prescribe. This is a realist view of models,\nbecause descriptions exist. \nThe fiction view is not without critics. Giere (2009), Magnani (2012),\nPincock (2012), Portides (2014), and Teller (2009) reject the fiction\napproach and argue, in different ways, that models should not be\nregarded as fictions. Weisberg (2013) argues for a middle position\nwhich sees fictions as playing a heuristic role but denies that they\nshould be regarded as forming part of a scientific model. The common\ncore of these criticisms is that the fiction view misconstrues the\nepistemic standing of models. To call something a fiction, so the\ncharge goes, is tantamount to saying that it is false, and it is\nunjustified to call an entire model a fiction—and thereby claim\nthat it fails to capture how the world is—just because the model\ninvolves certain false assumptions or fictional elements. In other\nwords, a representation isn’t automatically counted as fiction\njust because it has some inaccuracies. Proponents of the fiction view\nagree with this point but deny that the notion of fiction should be\nanalyzed in terms of falsity. What makes a work a fiction is not its\nfalsity (or some ratio of false to true claims): neither is everything\nthat is said in a novel untrue (Tolstoy’s War and Peace\ncontains many true statements about Napoleon’s Franco-Russian\nWar), nor does every text containing false claims qualify as fiction\n(false news reports are just that, they are not fictions). The\ndefining feature of a fiction is that readers are supposed to\nimagine the events and characters described, not that they\nare false (Frigg 2010a; Salis forthcoming). \nGiere (1988) advocated the view that “non-physical” models\nare abstract entities. However, there is little agreement on the\nnature of abstract objects, and Hale (1988: 86–87) lists no less\nthan twelve different possible characterizations (for a review of the\navailable options, see the entry on\n abstract objects).\n In recent publications, Thomasson (2020) and Thomson-Jones\n(2020) develop what they call an “artifactualist\nview” of models, which is based on Thomasson’s (1999)\ntheory of abstract artifacts. This view agrees with the pretense\ntheory that the content of text that introduces a fictional character\nor a model should be understood as occurring in pretense, but at the\nsame time insists that in producing such descriptions authors create\nabstract cultural artifacts that then exist independently of either\nthe author or the readers. Artifactualism agrees with Platonism that\nabstract objects exist, but insists, contra Platonism, that\nabstract objects are brought into existence through a creative act and\nare not eternal.  This allows the artifactualist to preserve the\nadvantages of pretense theory while at the same time holding the\nrealist view that fictional characters and models actually exist. \nAn influential point of view takes models to be set-theoretic\nstructures. This position can be traced back to Suppes (1960) and is\nnow, with slight variants, held by most proponents of the so-called\nsemantic view of theories (for a discussion of this view, see the\nentry on\n the structure of scientific theories).\n There are differences between the versions of the semantic view, but\nwith the exception of Giere (1988) all versions agree that models are\nstructures of one sort or another (Da Costa and French 2000). \nThis view of models has been criticized on various grounds. One\npervasive criticism is that many types of models that play an\nimportant role in science are not structures and cannot be\naccommodated within the structuralist view of models, which can\nneither account for how these models are constructed nor for how they\nwork in the context of investigation (Cartwright 1999; Downes 1992;\nMorrison 1999). Examples for such models are interpretative models and\nmediating models, discussed later in\n Section 4.2.\n Another charge held against the set-theoretic approach is that\nset-theoretic structures by themselves cannot be representational\nmodels—at least if that requires them to share some structure\nwith the target—because the ascription of a structure to a\ntarget system which forms part of the physical world relies on a\nsubstantive (non-structural) description of the target, which goes\nbeyond what the structuralist approach can afford (Nguyen and Frigg\nforthcoming). \nA time-honored position has it that a model is a stylized description\nof a target system. It has been argued that this is what scientists\ndisplay in papers and textbooks when they present a model (Achinstein\n1968; Black 1962). This view has not been subject to explicit\ncriticism. However, some of the criticisms that have been marshaled\nagainst the so-called syntactic view of theories equally threaten a\nlinguistic understanding of models (for a discussion of this view, see the\nentry on\n the structure of scientific theories).\n First, a standard criticism of the syntactic view is that by\nassociating a theory with a particular formulation, the view\nmisconstrues theory identity because any change in the formulation\nresults in a new theory (Suppe 2000). A view that associates models\nwith descriptions would seem to be open to the same criticism. Second,\nmodels have different properties than descriptions: the Newtonian\nmodel of the solar system consists of orbiting spheres, but it makes\nno sense to say this about its description. Conversely, descriptions\nhave properties that models do not have: a description can be written\nin English and consist of 517 words, but the same cannot be said of a\nmodel. One way around these difficulties is to associate the model\nwith the content of a description rather than with the description\nitself. For a discussion of a position on models that builds on the\ncontent of a description, see Salis (forthcoming). \nA contemporary version of descriptivism is Levy’s (2012, 2015)\nand Toon’s (2012) so-called direct-representation view. This\nview shares with the fiction view of models\n (Section 2.2)\n the reliance on Walton’s pretense theory, but uses it in a\ndifferent way. The main difference is that the views discussed earlier\nsee modeling as introducing a vehicle of representation, the model,\nthat is distinct from the target, and they see the problem as\nelucidating what kind of thing the model is. On the\ndirect-representation view there are no models distinct from the\ntarget; there are only model-descriptions and targets, with no models\nin-between them. Modeling, on this view, consists in providing an\nimaginative description of real things. A model-description prescribes\nimaginings about the real system; the ideal pendulum, for instance,\nprescribes model-users to imagine the real spring as perfectly elastic\nand the bob as a point mass. This approach avoids the above problems\nbecause the identity conditions for models are given by the conditions\nfor games of make-believe (and not by the syntax of a description) and\nproperty ascriptions take place in pretense. There are, however,\nquestions about how this account deals with models that have no target\n(like models of the ether or four-sex populations), and about how\nmodels thus understood deal with idealizations. For a discussion of\nthese points, see Frigg and Nguyen (2016), Poznic (2016), and Salis\n(forthcoming). \nA closely related approach sees models as equations. This is a version\nof the view that models are descriptions, because equations are\nsyntactic items that describe a mathematical structure. The issues\nthat this view faces are similar to the ones we have already\nencountered: First, one can describe the same situation using\ndifferent kinds of coordinates and as a result obtain different\nequations but without thereby also obtaining a different model.\nSecond, the model and the equation have different properties. A\npendulum contains a massless string, but the equation describing its\nmotion does not; and an equation may be inhomogeneous, but the system\nit describes is not. It is an open question whether these issues can\nbe avoided by appeal to a pretense account. \nOne of the main reasons why models play such an important role in\nscience is that they perform a number of cognitive functions. For\nexample, models are vehicles for learning about the world. Significant\nparts of scientific investigation are carried out on models rather\nthan on reality itself because by studying a model we can discover\nfeatures of, and ascertain facts about, the system the model stands\nfor: models allow for “surrogative reasoning” (Swoyer\n1991). For instance, we study the nature of the hydrogen atom, the\ndynamics of a population, or the behavior of a polymer by studying\ntheir respective models. This cognitive function of models has been\nwidely acknowledged in the literature, and some even suggest that\nmodels give rise to a new style of reasoning, “model-based\nreasoning”, according to which “inferences are made by\nmeans of creating models and manipulating, adapting, and evaluating\nthem” (Nersessian 2010: 12; see also Magnani, Nersessian, and\nThagard 1999; Magnani and Nersessian 2002; and Magnani and Casadio\n2016). \nLearning about a model happens in two places: in the construction of\nthe model and in its manipulation (Morgan 1999). There are no fixed\nrules or recipes for model building and so the very activity of\nfiguring out what fits together, and how, affords an opportunity to\nlearn about the model. Once the model is built, we do not learn about\nits properties by looking at it; we have to use and manipulate the\nmodel in order to elicit its secrets. \nDepending on what kind of model we are dealing with, building and\nmanipulating a model amount to different activities demanding\ndifferent methodologies. Material models seem to be straightforward\nbecause they are used in common experimental contexts (e.g., we put\nthe model of a car in the wind tunnel and measure its air resistance).\nHence, as far as learning about the model is concerned, material\nmodels do not give rise to questions that go beyond questions\nconcerning experimentation more generally. \nNot so with fictional and abstract models. What constraints are there\nto the construction of fictional and abstract models, and how do we\nmanipulate them? A natural response seems to be that we do this by\nperforming a thought experiment. Different authors (e.g., Brown 1991;\nGendler 2000; Norton 1991; Reiss 2003; Sorensen 1992) have explored\nthis line of argument, but they have reached very different and often\nconflicting conclusions about how thought experiments are performed\nand what the status of their outcomes is (for details, see the entry\non\n thought experiments). \nAn important class of models is computational in nature. For some\nmodels it is possible to derive results or solve equations of a\nmathematical model analytically. But quite often this is not the case.\nIt is at this point that computers have a great impact, because they\nallow us to solve problems that are otherwise intractable. Hence,\ncomputational methods provide us with knowledge about (the\nconsequences of) a model where analytical methods remain silent. Many\nparts of current research in both the natural and social sciences rely\non computer simulations, which help scientists to explore the\nconsequences of models that cannot be investigated otherwise. The\nformation and development of stars and galaxies, the dynamics of\nhigh-energy heavy-ion reactions, the evolution of life, outbreaks of\nwars, the progression of an economy, moral behavior, and the\nconsequences of decision procedures in an organization are explored\nwith computer simulations, to mention only a few examples. \nComputer simulations are also heuristically important. They can\nsuggest new theories, models, and hypotheses, for example, based on a\nsystematic exploration of a model’s parameter space (Hartmann\n1996). But computer simulations also bear methodological perils. For\nexample, they may provide misleading results because, due to the\ndiscrete nature of the calculations carried out on a digital computer,\nthey only allow for the exploration of a part of the full parameter\nspace, and this subspace need not reflect every important feature of\nthe model. The severity of this problem is somewhat mitigated by the\nincreasing power of modern computers. But the availability of more\ncomputational power can also have adverse effects: it may encourage\nscientists to swiftly come up with increasingly complex but\nconceptually premature models, involving poorly understood assumptions\nor mechanisms and too many additional adjustable parameters (for a\ndiscussion of a related problem in the social sciences, see Braun and\nSaam 2015: Ch. 3). This can lead to an increase in empirical\nadequacy—which may be welcome for certain forecasting\ntasks—but not necessarily to a better understanding of the\nunderlying mechanisms. As a result, the use of computer simulations\ncan change the weight we assign to the various goals of science.\nFinally, the availability of computer power may seduce scientists into\nmaking calculations that do not have the degree of trustworthiness one\nwould expect them to have. This happens, for instance, when computers\nare used to propagate probability distributions forward in time, which\ncan turn out to be misleading (see Frigg et al. 2014). So it is\nimportant not to be carried away by the means that new powerful\ncomputers offer and lose sight of the actual goals of research. For a\ndiscussion of further issues in connection with computer simulations,\nwe refer the reader to the entry on\n computer simulations in science. \nOnce we have knowledge about the model, this knowledge has to be\n“translated” into knowledge about the target system. It is\nat this point that the representational function of models becomes\nimportant again: if a model represents, then it can instruct us about\nreality because (at least some of) the model’s parts or aspects\nhave corresponding parts or aspects in the world. But if learning is\nconnected to representation and if there are different kinds of\nrepresentations (analogies, idealizations, etc.), then there are also\ndifferent kinds of learning. If, for instance, we have a model we take\nto be a realistic depiction, the transfer of knowledge from the model\nto the target is accomplished in a different manner than when we deal\nwith an analogue, or a model that involves idealizing assumptions. For\na discussion of the different ways in which the representational\nfunction of models can be exploited to learn about the target, we\nrefer the reader to the entry\n Scientific Representation. \nSome models explain. But how can they fulfill this function given that\nthey typically involve idealizations? Do these models explain\ndespite or because of the idealizations\nthey involve? Does an explanatory use of models presuppose that they\nrepresent, or can non-representational models also explain? And what\nkind of explanation do models provide? \nThere is a long tradition requesting that the explanans of a\nscientific explanation must be true. We find this requirement in the\ndeductive-nomological model (Hempel 1965) as well as in the more\nrecent literature. For instance, Strevens (2008: 297) claims that “no causal\naccount of explanation … allows nonveridical models to\nexplain”. For further discussions, see also Colombo et al.\n(2015). \nAuthors working in this tradition deny that idealizations make a\npositive contribution to explanation and explore how models can\nexplain despite being idealized. McMullin (1968, 1985) argues that a\ncausal explanation based on an idealized model leaves out only\nfeatures which are irrelevant for the respective explanatory task (see\nalso Salmon 1984 and\nPiccinini and Craver 2011 for a discussion of mechanism sketches).\nFriedman (1974) argues\nthat a more realistic (and hence less idealized) model explains better\non the unification account. The idea is that idealizations can (at\nleast in principle) be de-idealized (for a critical discussion of this\nclaim in the context of the debate about scientific explanations, see\nBatterman 2002; Bokulich 2011; Morrison 2005, 2009; Jebeile and\nKennedy 2015; and Rice 2015). Strevens (2008) argues that an explanatory\ncausal model has to provide an accurate representation of the relevant\ncausal relationships or processes which the model shares with the\ntarget system. The idealized assumptions of a model do not make a\ndifference for the phenomenon under consideration and are therefore\nexplanatorily irrelevant. In contrast, both Potochnik (2017) and Rice\n(2015) argue that models that explain can directly distort\nmany difference-making causes. \nAccording to Woodward’s (2003) theory, models are tools to find\nout about the causal relations that hold between certain facts or\nprocesses, and it is these relations that do the explanatory work.\nMore specifically, explanations provide information about patterns of\ncounterfactual dependence between the explanans and the explanandum\nwhich  \nenable us to see what sort of difference it would have made for the\nexplanandum if the factors cited in the explanans had been different\nin various possible ways. (Woodward 2003: 11)  \nAccounts of causal explanation have also led to various claims about\nhow idealized models can provide explanations, exploring to what\nextent idealization allows for the misrepresentation of irrelevant\ncausal factors by the explanatory model (Elgin and Sober 2002;\nStrevens 2004, 2008; Potochnik 2007; Weisberg\n2007, 2013). However, having the causally relevant features in common\nwith real systems continues to play the essential role in showing how\nidealized models can be explanatory. \nBut is it really the truth of the explanans that makes the model\nexplanatory? Other authors pursue a more radical line and argue that\nfalse models explain not only despite their falsity, but in\nfact because of their falsity. Cartwright (1983: 44)\nmaintains that “the truth doesn’t explain much”. In\nher so-called “simulacrum account of explanation”, she\nsuggests that we explain a phenomenon by constructing a model that\nfits the phenomenon into the basic framework of a grand theory (1983:\nCh. 8). On this account, the model itself is the explanation we seek.\nThis squares well with basic scientific intuitions, but it leaves us\nwith the question of what notion of explanation is at work (see also\nElgin and Sober 2002) and of what explanatory function idealizations\nplay in model explanations (Rice 2018, 2019). Wimsatt (2007: Ch. 6)\nstresses the role of false models as means to arrive at true theories.\nBatterman and Rice (2014) argue that models explain because the\ndetails that characterize specific systems do not matter for the\nexplanation. Bokulich (2008, 2009, 2011, 2012) pursues a similar line\nof reasoning and sees the explanatory power of models as being closely\nrelated to their fictional nature. Bokulich (2009) and Kennedy (2012)\npresent non-representational accounts of model explanation (see also\nJebeile and Kennedy 2015). Reiss (2012) and Woody (2004) provide general discussions of the relationship between\nrepresentation and explanation. \nMany authors have pointed out that understanding is one of the central\ngoals of science (see, for instance, de Regt 2017; Elgin 2017; Khalifa\n2017; Potochnik 2017). In some cases, we want to understand a certain\nphenomenon (e.g., why the sky is blue); in other cases, we want to\nunderstand a specific scientific theory (e.g., quantum mechanics) that\naccounts for a phenomenon in question. Sometimes we gain understanding\nof a phenomenon by understanding the corresponding theory or model.\nFor instance, Maxwell’s theory of electromagnetism helps us\nunderstand why the sky is blue. It is, however, controversial whether\nunderstanding a phenomenon always presupposes an\nunderstanding of the corresponding theory (de Regt 2009: 26).  \nAlthough there are many different ways of gaining understanding,\nmodels and the activity of scientific modeling are of particular\nimportance here (de Regt et al. 2009; Morrison 2009; Potochnik 2017;\nRice 2016). This insight\ncan be traced back at least to Lord Kelvin who, in his famous 1884\nBaltimore Lectures on Molecular Dynamics and the Wave Theory of\nLight, maintained that “the test of ‘Do we or do we\nnot understand a particular subject in physics?’ is ‘Can\nwe make a mechanical model of it?’” (Kelvin 1884 [1987: 111]; see also Bailer-Jones 2009: Ch. 2; and de Regt 2017: Ch. 6).  \nBut why do models play such a crucial role in the understanding of a\nsubject matter? Elgin (2017) argues that this is not despite, but\nbecause, of models being literally false. She views false models as\n“felicitous falsehoods” that occupy center stage in the\nepistemology of science, and mentions the ideal-gas model in\nstatistical mechanics and the Hardy–Weinberg model in genetics as\nexamples for literally false models that are central to their\nrespective disciplines. Understanding is holistic and it concerns a\ntopic, a discipline, or a subject matter, rather than isolated claims\nor facts. Gaining understanding of a context means to have  \nan epistemic commitment to a comprehensive, systematically linked body\nof information that is grounded in fact, is duly responsive to reasons\nor evidence, and enables nontrivial inference, argument, and perhaps\naction regarding the topic the information pertains to (Elgin 2017:\n44)  \nand models can play a crucial role in the pursuit of these epistemic\ncommitments. For a discussion of Elgin’s account of models and\nunderstanding, see Baumberger and Brun (2017) and Frigg and Nguyen\n(forthcoming). \nElgin (2017), Lipton (2009), and Rice (2016) all argue that models can be used to understand\nindependently of their ability to provide an explanation. Other\nauthors, among them Strevens (2008, 2013), argue that understanding\npresupposes a scientific explanation and that \nan individual has scientific understanding of a phenomenon just in\ncase they grasp a correct scientific explanation of that phenomenon.\n(Strevens 2013: 510; see,\nhowever, Sullivan and Khalifa 2019)  \nOn this account, understanding consists in a particular form of\nepistemic access an individual scientist has to an explanation. For\nStrevens this aspect is “grasping”, while for de Regt\n(2017) it is “intelligibility”. It is important to note\nthat both Strevens and de Regt hold that such “subjective”\naspects are a worthy topic for investigations in the philosophy of\nscience. This contrasts with the traditional view (see, e.g., Hempel\n1965) that delegates them to the realm of psychology. See Friedman\n(1974), Trout (2002), and\nReutlinger et al. (2018) for further discussions of understanding. \nBesides the functions already mentioned, it has been emphasized\nvariously that models perform a number of other cognitive functions.\nKnuuttila (2005, 2011) argues that the epistemic value of models is\nnot limited to their representational function, and develops an account\nthat views models as epistemic artifacts which allow us to gather\nknowledge in diverse ways. Nersessian (1999, 2010) stresses the role\nof analogue models in concept-formation and other cognitive processes.\nHartmann (1995) and Leplin (1980) discuss models as tools for theory\nconstruction and emphasize their heuristic and pedagogical value.\nEpstein (2008) lists a number of specific functions of models in the\nsocial sciences. Peschard (2011) investigates the way in which models\nmay be used to construct other models and generate new target systems.\nAnd Isaac (2013) discusses non-explanatory uses of models which do not\nrely on their representational capacities. \nAn important question concerns the relation between models and\ntheories. There is a full spectrum of positions ranging from models\nbeing subordinate to theories to models being independent of\ntheories. \nTo discuss the relation between models and theories in science it is\nhelpful to briefly recapitulate the notions of a model and of a theory\nin logic. A theory is taken to be a (usually deductively\nclosed) set of sentences in a formal language. A model is a\nstructure (in the sense introduced in\n Section 2.3)\n that makes all sentences of a theory true when its symbols are\ninterpreted as referring to objects, relations, or functions of a\nstructure. The structure is a model of the theory in the\nsense that it is correctly described by the theory (see Bell and\nMachover 1977 or Hodges 1997 for details). Logical models are\nsometimes also referred to as “models of theory” to\nindicate that they are interpretations of an abstract formal\nsystem. \nModels in science sometimes carry over from logic the idea of being\nthe interpretation of an abstract calculus (Hesse 1967). This is\nsalient in physics, where general laws—such as Newton’s\nequation of motion—lie at the heart of a theory. These laws are\napplied to a particular system—e.g., a pendulum—by\nchoosing a special force function, making assumptions about the mass\ndistribution of the pendulum etc. The resulting model then is an\ninterpretation (or realization) of the general law. \nIt is important to keep the notions of a logical and a\nrepresentational model separate (Thomson-Jones 2006): these are\ndistinct concepts. Something can be a logical model without being a\nrepresentational model, and vice versa. This, however, does\nnot mean that something cannot be a model in both senses at once. In\nfact, as Hesse (1967) points out, many models in science are both\nlogical and representational models. Newton’s model of planetary\nmotion is a case in point: the model, consisting of two homogeneous\nperfect spheres located in otherwise empty space that attract each\nother gravitationally, is simultaneously a logical model (because it\nmakes the axioms of Newtonian mechanics true when they are interpreted\nas referring to the model) and a representational model (because it\nrepresents the real sun and earth). \nThere are two main conceptions of scientific theories, the so-called\nsyntactic view of theories and the so-called semantic view of theories\n(see the entry on\n the structure of scientific theories).\n On both conceptions models play a subsidiary role to theories, albeit\nin very different ways. The syntactic view of theories (see entry\nsection on\n the syntactic view)\n retains the logical notions of a model and a theory. It construes a\ntheory as a set of sentences in an axiomatized logical system, and a\nmodel as an alternative interpretation of a certain calculus\n(Braithwaite 1953; Campbell 1920 [1957]; Nagel 1961; Spector 1965).\nIf, for instance, we take the mathematics used in the kinetic theory\nof gases and reinterpret the terms of this calculus in a way that\nmakes them refer to billiard balls, the billiard balls are a model of\nthe kinetic theory of gases in the sense that all sentences of the\ntheory come out true. The model is meant to be something that we are\nfamiliar with, and it serves the purpose of making an abstract formal\ncalculus more palpable. A given theory can have different models, and\nwhich model we choose depends both on our aims and our background\nknowledge. Proponents of the syntactic view disagree about the\nimportance of models. Carnap and Hempel thought that models only serve\na pedagogic or aesthetic purpose and are ultimately dispensable\nbecause all relevant information is contained in the theory (Carnap\n1938; Hempel 1965; see also Bailer-Jones 1999). Nagel (1961) and\nBraithwaite (1953), on the other hand, emphasize the\nheuristic role of models, and Schaffner (1969) submits that\ntheoretical terms get at least part of their meaning from models. \nThe semantic view of theories (see entry section on\n the semantic view)\n dispenses with sentences in an axiomatized logical system and\nconstrues a theory as a family of models. On this view, a theory\nliterally is a class, cluster, or family of models—models are the\nbuilding blocks of which scientific theories are made up. Different\nversions of the semantic view work with different notions of a model,\nbut, as noted in\n Section 2.3,\n in the semantic view models are mostly construed as set-theoretic\nstructures. For a discussion of the different options, we refer the\nreader to the relevant entry in this encyclopedia (linked at the\nbeginning of this paragraph). \nIn both the syntactic and the semantic view of theories models are\nseen as subordinate to theory and as playing no role outside the\ncontext of a theory. This vision of models has been challenged in a\nnumber of ways, with authors pointing out that models enjoy various\ndegrees of freedom from theory and function autonomously in many\ncontexts. Independence can take many forms, and large parts of the\nliterature on models are concerned with investigating various forms of\nindependence. \nModels as completely independent of theory. The most radical\ndeparture from a theory-centered analysis of models is the realization\nthat there are models that are completely independent from any theory.\nAn example of such a model is the Lotka–Volterra model. The model\ndescribes the interaction of two populations: a population of\npredators and one of prey animals (Weisberg 2013). The model was\nconstructed using only relatively commonsensical assumptions about\npredators and prey and the mathematics of differential equations.\nThere was no appeal to a theory of predator–prey interactions or a\ntheory of population growth, and the model is independent of theories\nabout its subject matter. If a model is constructed in a domain where\nno theory is available, then the model is sometimes referred to as a\n“substitute model” (Groenewold 1961), because the model\nsubstitutes a theory. \nModels as a means to explore theory. Models can also be used\nto explore theories (Morgan and Morrison 1999). An obvious way in\nwhich this can happen is when a model is a logical model of a theory\n(see\n Section 4.1).\n A logical model is a set of objects and properties that make a formal\nsentence true, and so one can see in the model how the axioms of the\ntheory play out in a particular setting and what kinds of behavior\nthey dictate. But not all models that are used to explore theories are\nlogical models, and models can represent features of theories in other\nways. As an example, consider chaos theory. The equations of\nnon-linear systems, such as those describing the three-body\nproblem, have solutions that are too complex to study with\npaper-and-pencil methods, and even computer simulations are limited in\nvarious ways. Abstract considerations about the qualitative behavior\nof solutions show that there is a mechanism that has been dubbed\n“stretching and folding” (see the entry\n Chaos).\n To obtain an idea of the complexity of the dynamics exhibiting\nstretching and folding, Smale proposed to study a simple model of the\nflow—now known as the “horseshoe map” (Tabor 1989)—which\nprovides important insights into the nature of stretching and folding.\nOther examples of models of that kind are the Kac ring model that is\nused to study equilibrium properties of systems in statistical\nmechanics (Lavis 2008)\nand Norton’s dome in Newtonian mechanics (Norton 2003). \nModels as complements of theories. A theory may be\nincompletely specified in the sense that it only imposes certain\ngeneral constraints but remains silent about the details of concrete\nsituations, which are provided by a model (Redhead 1980). A special\ncase of this situation is when a qualitative theory is known and the\nmodel introduces quantitative measures (Apostel 1961). Redhead’s\nexample of a theory that is underdetermined in this way is axiomatic\nquantum field theory, which only imposes certain general constraints\non quantum fields but does not provide an account of particular\nfields. Harré (2004) notes that models can complement theories by providing\nmechanisms for processes that are left unspecified in the theory even\nthough they are responsible for bringing about the observed\nphenomena. \nTheories may be too complicated to handle. In such cases a model can\ncomplement a theory by providing a simplified version of the\ntheoretical scenario that allows for a solution. Quantum\nchromodynamics, for instance, cannot easily be used to investigate the\nphysics of an atomic nucleus even though it is the relevant\nfundamental theory. To get around this difficulty, physicists\nconstruct tractable phenomenological models (such as the MIT bag\nmodel) which effectively describe the relevant degrees of freedom of\nthe system under consideration (Hartmann 1999, 2001). The advantage of\nthese models is that they yield results where theories remain silent.\nTheir drawback is that it is often not clear how to understand the\nrelationship between the model and the theory, as the two are, strictly\nspeaking, contradictory. \nModels as preliminary theories. The notion of a model as a\nsubstitute for a theory is closely related to the notion of a\ndevelopmental model. This term was coined by Leplin (1980),\nwho pointed out how useful models were in the development of early\nquantum theory, and it is now used as an umbrella notion covering\ncases in which models are some sort of a preliminary exercise to\ntheory. \nAlso closely related is the notion of a probing model (or\n“study model”). Models of this kind do not perform a\nrepresentational function and are not expected to instruct us about\nanything beyond the model itself. The purpose of these models is to\ntest new theoretical tools that are used later on to build\nrepresentational models. In field theory, for instance, the so-called\nφ4-model was studied extensively, not because it was\nbelieved to represent anything real, but because it served several\nheuristic functions: the simplicity of the φ4-model\nallowed physicists to “get a feeling” for what quantum\nfield theories are like and to extract some general features that this\nsimple model shared with more complicated ones. Physicists could study\ncomplicated techniques such as renormalization in a simple setting,\nand it was possible to get acquainted with important\nmechanisms—in this case symmetry-breaking—that could later\nbe used in different contexts (Hartmann 1995). This is true not only\nfor physics. As Wimsatt (1987, 2007) points out, a false model in\ngenetics can perform many useful functions, among them the following:\nthe false model can help answering questions about more realistic\nmodels, provide an arena for answering questions about properties of\nmore complex models, “factor out” phenomena that would not\notherwise be seen, serve as a limiting case of a more general model\n(or two false models may define the extremes of a continuum of cases\non which the real case is supposed to lie), or lead to the\nidentification of relevant variables and the estimation of their\nvalues. \nInterpretative models. Cartwright (1983, 1999) argues that\nmodels do not only aid the application of theories that are somehow\nincomplete; she claims that models are also involved whenever\na theory with an overarching mathematical structure is applied. The\nmain theories in physics—classical mechanics, electrodynamics,\nquantum mechanics, and so on—fall into this category. Theories of\nthat kind are formulated in terms of abstract concepts that need to be\nconcretized for the theory to provide a description of the target\nsystem, and concretizing the relevant concepts, idealized objects and\nprocesses are introduced. For instance, when applying classical\nmechanics, the abstract concept of force has to be replaced with a\nconcrete force such as gravity. To obtain tractable equations, this\nprocedure has to be applied to a simplified scenario, for instance\nthat of two perfectly spherical and homogeneous planets in otherwise\nempty space, rather than to reality in its full complexity. The result\nis an interpretative model, which grounds the application of\nmathematical theories to real-world targets. Such models are\nindependent from theory in that the theory does not determine their\nform, and yet they are necessary for the application of the theory to\na concrete problem. \nModels as mediators. The relation between models and theories\ncan be complicated and disorderly. The contributors to a programmatic\ncollection of essays edited by Morgan and Morrison (1999) rally around\nthe idea that models are instruments that mediate between theories and\nthe world. Models are “autonomous agents” in that they are\nindependent from both theories and their target systems, and it is\nthis independence that allows them to mediate between the two.\nTheories do not provide us with algorithms for the construction of a\nmodel; they are not “vending machines” into which one can\ninsert a problem and a model pops out (Cartwright 1999). The\nconstruction of a model often requires detailed knowledge about\nmaterials, approximation schemes, and the setup, and these are not\nprovided by the corresponding theory. Furthermore, the inner workings\nof a model are often driven by a number of different theories working\ncooperatively. In contemporary climate modeling, for instance,\nelements of different theories—among them fluid dynamics,\nthermodynamics, electromagnetism—are put to work cooperatively.\nWhat delivers the results is not the stringent application of one\ntheory, but the voices of different theories when put to use in chorus\nwith each other in one model. \nIn complex cases like the study of a laser system or the global\nclimate, models and theories can get so entangled that it becomes\nunclear where a line between the two should be drawn: where does the\nmodel end and the theory begin? This is not only a problem for\nphilosophical analysis; it also arises in scientific practice.\nBailer-Jones (2002) interviewed a group of physicists about their\nunderstanding of models and their relation to theories, and reports\nwidely diverging views: (i) there is no substantive difference between\nmodel and theory; (ii) models become theories when their\ndegree of confirmation increases; (iii) models contain simplifications\nand omissions, while theories are accurate and complete; (iv) theories\nare more general than models, and modeling is about applying general\ntheories to specific cases. The first suggestion seems to be too\nradical to do justice to many aspects of practice, where a distinction\nbetween models and theories is clearly made. The second view is in\nline with common parlance, where the terms “model” and\n“theory” are sometimes used to express someone’s\nattitude towards a particular hypothesis. The phrase “it’s\njust a model” indicates that the hypothesis at stake is asserted\nonly tentatively or is even known to be false, while something is\nawarded the label “theory” if it has acquired some degree\nof general acceptance. However, this use of “model” is\ndifferent from the uses we have seen in\n Sections 1 to 3\n and is therefore of no use if we aim to understand the relation\nbetween scientific models and theories (and, incidentally, one can\nequally dismiss speculative claims as being “just a\ntheory”). The third proposal is correct in associating models\nwith idealizations and simplifications, but it overshoots by\nrestricting this to models; in fact, also theories can contain\nidealizations and simplifications. The fourth view seems closely\naligned with interpretative models and the idea that models are\nmediators, but being more general is a gradual notion and hence does\nnot provide a clear-cut criterion to distinguish between theories and\nmodels. \nThe debate over scientific models has important repercussions for\nother issues in the philosophy of science (for a historical account of\nthe philosophical discussion about models, see Bailer-Jones 1999).\nTraditionally, the debates over, say, scientific realism, reductionism,\nand laws of nature were couched in terms of theories, because theories\nwere seen as the main carriers of scientific knowledge. Once models\nare acknowledged as occupying an important place in the edifice of\nscience, these issues have to be reconsidered with a focus on models.\nThe question is whether, and if so how, discussions of these issues\nchange when we shift focus from theories to models. Up to now, no\ncomprehensive model-based account of any of these issues has emerged,\nbut models have left important traces in the discussions of these\ntopics. \nAs we have seen in\n Section 1,\n models typically provide a distorted representation of their targets.\nIf one sees science as primarily model-based, this could be taken to\nsuggest an antirealist interpretation of science. Realists, however,\ndeny that the presence of idealizations in models renders a realist\napproach to science impossible and point out that a good model, while\nnot literally true, is usually at least approximately true, and/or\nthat it can be improved by de-idealization (Laymon 1985; McMullin\n1985; Nowak 1979; Brzezinski and Nowak 1992). \nApart from the usual worries about the elusiveness of the notion of\napproximate truth (for a discussion, see the entry on\n truthlikeness),\n antirealists have taken issue with this reply for two (related)\nreasons. First, as Cartwright (1989) points out, there is no reason to\nassume that one can always improve a model by adding de-idealizing\ncorrections. Second, it seems that de-idealization is not in\naccordance with scientific practice because it is unusual that\nscientists invest work in repeatedly de-idealizing an existing model.\nRather, they shift to a different modeling framework once the\nadjustments to be made get too involved (Hartmann 1998). The various\nmodels of the atomic nucleus are a case in point: once it was realized\nthat shell effects are important to understand various subatomic\nphenomena, the (collective) liquid-drop model was put aside and the\n(single-particle) shell model was developed to account for the\ncorresponding findings. A further difficulty with de-idealization is\nthat most idealizations are not “controlled”. For example,\nit is not clear in what way one could de-idealize the MIT bag model to\neventually arrive at quantum chromodynamics, the supposedly correct\nunderlying theory. \nA further antirealist argument, the “incompatible-models\nargument”, takes as its starting point the observation that\nscientists often successfully use several incompatible models of\none and the same target system for predictive purposes\n(Morrison 2000). These models seemingly contradict each other, as they\nascribe different properties to the same target system. In nuclear\nphysics, for instance, the liquid-drop model explores the analogy of\nthe atomic nucleus with a (charged) fluid drop, while the shell model\ndescribes nuclear properties in terms of the properties of protons and\nneutrons, the constituents of an atomic nucleus. This practice appears\nto cause a problem for scientific realism: Realists typically hold\nthat there is a close connection between the predictive success of a\ntheory and its being at least approximately true. But if several\nmodels of the same system are predictively successful and if these\nmodels are mutually inconsistent, then it is difficult to maintain\nthat they are all approximately true. \nRealists can react to this argument in various ways. First, they can\nchallenge the claim that the models in question are indeed\npredictively successful. If the models are not good predictors, then\nthe argument is blocked. Second, they can defend a version of\n“perspectival realism” (Giere 2006; Massimi 2017; Rueger\n2005). Proponents of this position (which is sometimes also called\n“perspectivism”) situate it somewhere between\n“standard” scientific realism and antirealism, and where\nexactly the right middle position lies is the subject matter of active\ndebate (Massimi 2018a,b; Saatsi 2016; Teller 2018; and the\ncontributions to Massimi and McCoy 2019). Third, realists can deny\nthat there is a problem in the first place, because scientific models,\nwhich are always idealized and therefore strictly speaking false, are\njust the wrong vehicle to make a point about realism (which should be\ndiscussed in terms of theories). \nA particular focal point of the realism debate are laws of nature,\nwhere the questions arise what laws are and whether they are\ntruthfully reflected in our scientific representations. According to\nthe two currently dominant accounts, the best-systems approach and the\nnecessitarian approach, laws of nature are understood to be universal\nin scope, meaning that they apply to everything that there is in the\nworld (for discussion of laws, see the entry on\n laws of nature).\n This take on laws does not seem to sit well with a view that places\nmodels at the center of scientific research. What role do general laws\nplay in science if it is models that represent what is happening in\nthe world? And how are models and laws related? \nOne possible response to these questions is to argue that laws of\nnature govern entities and processes in a model rather than\nin the world. Fundamental laws, on this approach, do not state facts\nabout the world but hold true of entities and processes in\nthe model. This view has been advocated in different variants:\nCartwright (1983) argues that all laws are ceteris paribus\nlaws. Cartwright (1999) makes use of “capacities” (which\nshe considers to be prior to laws) and introduces the notion of a\n“nomological machine”. This is  \na fixed (enough) arrangement of components, or factors, with stable\n(enough) capacities that in the right sort of stable (enough)\nenvironment will, with repeated operation, give rise to the kind of\nregular behavior that we represent in our scientific laws. (1999: 50;\nsee also the entry on\n ceteris paribus laws)\n  \nGiere (1999) argues that the laws of a theory are better thought of,\nnot as encoding general truths about the world, but rather as\nopen-ended statements that can be filled in various ways in the\nprocess of building more specific scientific models. Similar positions\nhave also been defended by Teller (2001) and van Fraassen (1989). \nThe multiple-models problem mentioned in\n Section 5.1\n also raises the question of how different models are related.\nEvidently, multiple models for the same target system do not generally\nstand in a deductive relationship, as they often contradict each\nother. Some (Cartwright 1999; Hacking 1983) have suggested a picture\nof science according to which there are no systematic relations that\nhold between different models. Some models are tied together because\nthey represent the same target system, but this does not imply that\nthey enter into any further relationships (deductive or otherwise). We\nare confronted with a patchwork of models, all of which hold\nceteris paribus in their specific domains of\napplicability. \nSome argue that this picture is at least partially incorrect because\nthere are various interesting relations that hold between different\nmodels or theories. These relations range from thoroughgoing reductive\nrelations (Scheibe 1997, 1999, 2001: esp. Chs. V.23 and V.24) and\ncontrolled approximations over singular limit relations (Batterman\n2001 [2016]) to structural relations (Gähde 1997) and rather\nloose relations called “stories” (Hartmann 1999; see also\nBokulich 2003; Teller 2002; and the essays collected in Part III of\nHartmann et al. 2008). These suggestions have been made on the basis\nof case studies, and it remains to be seen whether a more general\naccount of these relations can be given and whether a deeper\njustification for them can be provided, for instance, within a\nBayesian framework (first steps towards a Bayesian understanding of\nreductive relations can be found in Dizadji-Bahmani et al. 2011;\nLiefke and Hartmann 2018; and Tešić 2019). \nModels also figure in the debate about reduction and emergence in\nphysics. Here, some authors argue that the modern approach to\nrenormalization challenges Nagel’s (1961) model of reduction or\nthe broader doctrine of reductions (for a critical discussion, see,\nfor instance, Batterman 2002, 2010, 2011; Morrison 2012; and Saatsi and Reutlinger 2018).\nDizadji-Bahmani et al. (2010) provide a defense of the Nagel–Schaffner\nmodel of reduction, and Butterfield (2011a,b, 2014) argues that\nrenormalization is consistent with Nagelian reduction. Palacios (2019)\nshows that phase transitions are compatible with reductionism, and\nHartmann (2001) argues that the effective-field-theories research\nprogram is consistent with reductionism (see also Bain 2013 and\nFranklin forthcoming). Rosaler (2015) argues for a “local”\nform of reduction which sees the fundamental relation of reduction\nholding between models, not theories, which is, however, compatible\nwith the Nagel–Schaffner model of reduction. See also the entries on\n intertheory relations in physics\n and\n scientific reduction. \nIn the social sciences, agent-based models (ABMs) are increasingly\nused (Klein et al. 2018). These models show how surprisingly complex\nbehavioral patterns at the macro-scale can emerge from a small number\nof simple behavioral rules for the individual agents and their\ninteractions. This raises questions similar to the questions mentioned\nabove about reduction and emergence in physics, but so far one only\nfinds scattered remarks about reduction in the literature. See\nWeisberg and Muldoon (2009) and Zollman (2007) for the application of\nABMs to the epistemology and the social structure of science, and\nColyvan (2013) for a discussion of methodological questions raised by\nnormative models in general.","contact.mail":"r.p.frigg@lse.ac.uk","contact.domain":"lse.ac.uk"},{"date.published":"2006-02-27","date.changed":"2020-02-04","url":"https://plato.stanford.edu/entries/models-science/","author1":"Roman Frigg","author1.info":"http://www.lse.ac.uk/collections/philosophyLogicAndScientificMethod/WhosWho/staffhomepages/frigg.htm","author2.info":"http://stephanhartmann.org/","entry":"models-science","body.text":"\n\n\nModels are of central importance in many scientific contexts. The\ncentrality of models such as inflationary models in cosmology,\ngeneral-circulation models of the global climate, the double-helix\nmodel of DNA, evolutionary models in biology, agent-based models in\nthe social sciences, and general-equilibrium models of markets in\ntheir respective domains is a case in point (the\n Other Internet Resources\n section at the end of this entry contains links to online resources\nthat discuss these models). Scientists spend significant amounts of\ntime building, testing, comparing, and revising models, and much\njournal space is dedicated to interpreting and discussing the\nimplications of models.\n\n\nAs a result, models have attracted philosophers’ attention and\nthere are now sizable bodies of literature about various aspects of\nscientific modeling. A tangible result of philosophical engagement\nwith models is a proliferation of model types recognized in the\nphilosophical literature. Probing models,\nphenomenological models, computational models,\ndevelopmental models, explanatory models,\nimpoverished models, testing models, idealized\nmodels, theoretical models, scale models,\nheuristic models, caricature models, exploratory\nmodels, didactic models, fantasy models,\nminimal models, toy models, imaginary\nmodels, mathematical models, mechanistic\nmodels, substitute models, iconic models,\nformal models, analogue models, and instrumental\nmodels are but some of the notions that are used to categorize\nmodels. While at first glance this abundance is overwhelming, it can\nbe brought under control by recognizing that these notions pertain to\ndifferent problems that arise in connection with models. Models raise\nquestions in semantics (how, if at all, do models represent?),\nontology (what kind of things are models?), epistemology (how do we\nlearn and explain with models?), and, of course, in other domains\nwithin philosophy of science.\n\nMany scientific models are representational models: they represent a\nselected part or aspect of the world, which is the model’s\ntarget system. Standard examples are the billiard ball model of a gas,\nthe Bohr model of the atom, the Lotka–Volterra model of predator–prey\ninteraction, the Mundell–Fleming model of an open economy, and the\nscale model of a bridge. \nThis raises the question what it means for a model to represent a\ntarget system. This problem is rather involved and decomposes into\nvarious subproblems. For an in-depth discussion of the issue of\nrepresentation, see the entry on\n scientific representation.\n At this point, rather than addressing the issue of what it means for\na model to represent, we focus on a number of different kinds of\nrepresentation that play important roles in the practice of\nmodel-based science, namely scale models, analogical models, idealized\nmodels, toy models, minimal models, phenomenological models,\nexploratory models, and models of data. These categories are not\nmutually exclusive, and a given model can fall into several categories\nat once. \nScale models. Some models are down-sized or enlarged copies\nof their target systems (Black 1962). A typical example is a small\nwooden car that is put into a wind tunnel to explore the actual\ncar’s aerodynamic properties. The intuition is that a scale\nmodel is a naturalistic replica or a truthful mirror image of the\ntarget; for this reason, scale models are sometimes also referred to\nas “true models” (Achinstein 1968: Ch. 7). However, there\nis no such thing as a perfectly faithful scale model; faithfulness is\nalways restricted to some respects. The wooden scale model of the car\nprovides a faithful portrayal of the car’s shape but not of its\nmaterial. And even in the respects in which a model is a faithful\nrepresentation, the relation between model-properties and\ntarget-properties is usually not straightforward. When engineers use,\nsay, a 1:100 scale model of a ship to investigate the resistance that\nan actual ship experiences when moving through the water, they cannot\nsimply measure the resistance the model experiences and then multiply\nit with the scale. In fact, the resistance faced by the model does not\ntranslate into the resistance faced by the actual ship in a\nstraightforward manner (that is, one cannot simply scale the water\nresistance with the scale of the model: the real ship need not have\none hundred times the water resistance of its 1:100 model). The two\nquantities stand in a complicated nonlinear relation with each other,\nand the exact form of that relation is often highly nontrivial and\nemerges as the result of a thoroughgoing study of the situation\n(Sterrett 2006, forthcoming; Pincock forthcoming). \nAnalogical models. Standard examples of analogical models\ninclude the billiard ball model of a gas, the hydraulic model of an\neconomic system, and the dumb hole model of a black hole. At the most\nbasic level, two things are analogous if there are certain relevant\nsimilarities between them. In a classic text, Hesse (1963)\ndistinguishes different types of analogies according to the kinds of\nsimilarity relations into which two objects enter. A simple type of\nanalogy is one that is based on shared properties. There is an analogy\nbetween the earth and the moon based on the fact that both are large,\nsolid, opaque, spherical bodies that receive heat and light from the\nsun, revolve around their axes, and gravitate towards other bodies.\nBut sameness of properties is not a necessary condition. An analogy\nbetween two objects can also be based on relevant similarities between\ntheir properties. In this more liberal sense, we can say that there is\nan analogy between sound and light because echoes are similar to\nreflections, loudness to brightness, pitch to color, detectability by\nthe ear to detectability by the eye, and so on. \nAnalogies can also be based on the sameness or resemblance of\nrelations between parts of two systems rather than on their monadic\nproperties. It is in this sense that the relation of a father to his\nchildren is asserted to be analogous to the relation of the state to\nits citizens. The analogies mentioned so far have been what Hesse\ncalls “material analogies”. We obtain a more formal notion\nof analogy when we abstract from the concrete features of the systems\nand only focus on their formal set-up. What the analogue model then\nshares with its target is not a set of features, but the same pattern\nof abstract relationships (i.e., the same structure, where structure\nis understood in a formal sense). This notion of analogy is closely\nrelated to what Hesse calls “formal analogy”. Two items\nare related by formal analogy if they are both interpretations of the\nsame formal calculus. For instance, there is a formal analogy between\na swinging pendulum and an oscillating electric circuit because they\nare both described by the same mathematical equation. \nA further important distinction due to Hesse is the one between\npositive, negative, and neutral analogies. The positive analogy\nbetween two items consists in the properties or relations they share\n(both gas molecules and billiard balls have mass); the negative\nanalogy consists in the properties they do not share (billiard balls\nare colored, gas molecules are not); the neutral analogy comprises the\nproperties of which it is not known (yet) whether they belong to the\npositive or the negative analogy (do billiard balls and molecules have\nthe same cross section in scattering processes?). Neutral analogies\nplay an important role in scientific research because they give rise\nto questions and suggest new hypotheses. For this reason several\nauthors have emphasized the heuristic role that analogies play in\ntheory and model construction, as well as in creative thought\n(Bailer-Jones and Bailer-Jones 2002; Bailer-Jones 2009: Ch. 3; Hesse\n1974; Holyoak and Thagard 1995; Kroes 1989; Psillos 1995; and the\nessays collected in Helman 1988). See also the entry on\n analogy and analogical reasoning. \nIt has also been discussed whether using analogical models can in some\ncases be confirmatory in a Bayesian sense. Hesse (1974: 208–219)\nargues that this is possible if the analogy is a material analogy.\nBartha (2010, 2013 [2019]) disagrees and argues that analogical models\ncannot be confirmatory in a Bayesian sense because the information\nencapsulated in an analogical model is part of the relevant background\nknowledge, which has the consequence that the posterior probability of\na hypothesis about a target system cannot change as a result of\nobserving the analogy. Analogical models can therefore only establish\nthe plausibility of a conclusion in the sense of justifying a\nnon-negligible prior probability assignment (Bartha 2010:\n§8.5). \nMore recently, these questions have been discussed in the context of\nso-called analogue experiments, which promise to provide knowledge\nabout an experimentally inaccessible target system (e.g., a black\nhole) by manipulating another system, the source system (e.g., a\nBose–Einstein condensate). Dardashti, Thébault, and Winsberg\n(2017) and Dardashti, Hartmann et al. (2019) have argued that, given\ncertain conditions, an analogue simulation of one system by another\nsystem can confirm claims about the target system (e.g., that black\nholes emit Hawking radiation). See Crowther et al. (forthcoming) for a\ncritical discussion, and also the entry on\n computer simulations in science. \nIdealized models. Idealized models are models that involve a\ndeliberate simplification or distortion of something complicated with\nthe objective of making it more tractable or understandable.\nFrictionless planes, point masses, completely isolated systems,\nomniscient and fully rational agents, and markets in perfect\nequilibrium are well-known examples. Idealizations are a crucial means\nfor science to cope with systems that are too difficult to study in\ntheir full complexity (Potochnik 2017). \nPhilosophical debates over idealization have focused on two general\nkinds of idealizations: so-called Aristotelian and Galilean\nidealizations. Aristotelian idealization amounts to “stripping\naway”, in our imagination, all properties from a concrete object\nthat we believe are not relevant to the problem at hand. There is\ndisagreement on how this is done. Jones (2005) and Godfrey-Smith\n(2009) offer an analysis of abstraction in terms of truth: while an\nabstraction remains silent about certain features or aspects of the\nsystem, it does not say anything false and still offers a true (albeit\nrestricted) description. This allows scientists to focus on a limited\nset of properties in isolation. An example is a classical-mechanics\nmodel of the planetary system, which describes the position of an\nobject as a function of time and disregards all other properties of\nplanets. Cartwright (1989: Ch. 5), Musgrave (1981), who uses the term\n“negligibility assumptions”, and Mäki (1994), who\nspeaks of the “method of isolation”, allow abstractions to\nsay something false, for instance by neglecting a causally relevant\nfactor. \nGalilean idealizations are ones that involve deliberate distortions:\nphysicists build models consisting of point masses moving on\nfrictionless planes; economists assume that agents are omniscient;\nbiologists study isolated populations; and so on. Using\nsimplifications of this sort whenever a situation is too difficult to\ntackle was characteristic of Galileo’s approach to science. For\nthis reason it is common to refer to ‘distortive’\nidealizations of this kind as “Galilean idealizations”\n(McMullin 1985). An example for such an idealization is a model of\nmotion on an ice rink that assumes the ice to be frictionless, when,\nin reality, it has low but non-zero friction. \nGalilean idealizations are sometimes characterized as controlled\nidealizations, i.e., as ones that allow for de-idealization by\nsuccessive removal of the distorting assumptions (McMullin 1985;\nWeisberg 2007). Thus construed, Galilean idealizations don’t\ncover all distortive idealizations. Batterman (2002, 2011) and Rice\n(2015, 2019) discuss distortive idealizations that are ineliminable in\nthat they cannot be removed from the model without dismantling the\nmodel altogether. \nWhat does a model involving distortions tell us about reality? Laymon\n(1991) formulated a theory which understands idealizations as ideal\nlimits: imagine a series of refinements of the actual situation which\napproach the postulated limit, and then require that the closer the\nproperties of a system come to the ideal limit, the closer its\nbehavior has to come to the behavior of the system at the limit\n(monotonicity). If this is the case, then scientists can study the\nsystem at the limit and carry over conclusions from that system to\nsystems distant from the limit. But these conditions need not always\nhold. In fact, it can happen that the limiting system does not\napproach the system at the limit. If this happens, we are faced with a\nsingular limit (Berry 2002). In such cases the system at the limit can\nexhibit behavior that is different from the behavior of systems\ndistant from the limit. Limits of this kind appear in a number of\ncontexts, most notably in the theory of phase transitions in\nstatistical mechanics. There is, however, no agreement over the\ncorrect interpretation of such limits. Batterman (2002, 2011) sees\nthem as indicative of emergent phenomena, while Butterfield (2011a,b)\nsees them as compatible with reduction (see also the entries on\n intertheory relations in physics\n and\n scientific reduction). \nGalilean and Aristotelian idealizations are not mutually exclusive,\nand many models exhibit both in that they take into account a narrow\nset of properties and distort them. Consider again the\nclassical-mechanics model of the planetary system: the model only\ntakes a narrow set of properties into account and distorts them, for\ninstance by describing planets as ideal spheres with a\nrotation-symmetric mass distribution. \nA concept that is closely related to idealization is approximation. In\na broad sense, A can be called an approximation of B if\nA is somehow close to B. This, however, is too broad\nbecause it makes room for any likeness to qualify as an approximation.\nRueger and Sharp (1998) limit approximations to quantitative\ncloseness, and Portides (2007) frames it as an essentially\nmathematical concept. On that notion A is an approximation of\nB iff A is close to B in a specifiable\nmathematical sense, where the relevant sense of “close”\nwill be given by the context. An example is the approximation of one\ncurve with another one, which can be achieved by expanding a function\ninto a power series and only keeping the first two or three terms. In\ndifferent situations we approximate an equation with another one by\nletting a control parameter tend towards zero (Redhead 1980). This\nraises the question of how approximations are different from\nidealizations, which can also involve mathematical closeness. Norton\n(2012) sees the distinction between the two as referential: an\napproximation is an inexact description of the target while an\nidealization introduces a secondary system (real or fictitious) which\nstands for the target system (while being distinct from it). If we say\nthat the period of the pendulum on the wall is roughly two seconds,\nthen this is an approximation; if we reason about the real pendulum by\nassuming that the pendulum bob is a point mass and that the string is\nmassless (i.e., if we assume that the pendulum is a so-called ideal\npendulum), then we use an idealization. Separating idealizations and\napproximations in this way does not imply that there cannot be\ninteresting relations between the two. For instance, an approximation\ncan be justified by pointing out that it is the mathematical\nexpression of an acceptable idealization (e.g., when we neglect a\ndissipative term in an equation of motion because we make the\nidealizing assumption that the system is frictionless). \nToy models. Toy models are extremely simplified and strongly\ndistorted renderings of their targets, and often only represent a\nsmall number of causal or explanatory factors (Hartmann 1995;\nReutlinger et al. 2018; Nguyen forthcoming). Typical examples are the\nLotka–Volterra model in population ecology (Weisberg 2013) and the\nSchelling model of segregation in the social sciences (Sugden\n2000). Toy models usually\ndo not perform well in terms of prediction and empirical adequacy, and\nthey seem to serve other epistemic goals (more on these in\n Section 3).\n This raises the question whether they should be regarded as\nrepresentational at all (Luczak 2017). \nSome toy models are characterized as “caricatures”\n(Gibbard and Varian 1978; Batterman and Rice 2014). Caricature models\nisolate a small number of salient characteristics of a system and\ndistort them into an extreme case. A classic example is\nAkerlof’s (1970) model of the car market (“the market for\nlemons”), which explains the difference in price between new and\nused cars solely in terms of asymmetric information, thereby\ndisregarding all other factors that may influence the prices of cars\n(see also Sugden 2000).\nHowever, it is controversial whether such highly idealized models can\nstill be regarded as informative representations of their target\nsystems. For a discussion of caricature models, in particular in\neconomics, see Reiss (2006). \nMinimal models. Minimal models are closely related to toy\nmodels in that they are also highly simplified. They are so simplified\nthat some argue that they are non-representational: they lack any\nsimilarity, isomorphism, or resemblance relation to the world\n(Batterman and Rice 2014). It has been argued that many economic\nmodels are of this kind (Grüne-Yanoff 2009). Minimal economic models are\nalso unconstrained by natural laws, and do not isolate any real\nfactors (ibid.). And yet, minimal models help us to learn\nsomething about the world in the sense that they function as\nsurrogates for a real system: scientists can study the model to learn\nsomething about the target. It is, however, controversial whether\nminimal models can assist scientists in learning something about the\nworld if they do not represent anything (Fumagalli 2016). Minimal\nmodels that purportedly lack any similarity or representation are also\nused in different parts of physics to explain the macro-scale behavior\nof various systems whose micro-scale behavior is extremely diverse\n(Batterman and Rice 2014; Rice 2018, 2019; Shech 2018). Typical\nexamples are the features of phase transitions and the flow of fluids.\nProponents of minimal models argue that what provides an explanation\nof the macro-scale behavior of a system in these cases is not a\nfeature that system and model have in common, but the fact that the\nsystem and the model belong to the same universality class (a\nclass of models that exhibit the same limiting behavior even though\nthey show very different behavior at finite scales). It is, however,\ncontroversial whether explanations of this kind are possible without\nreference to at least some common features (Lange 2015; Reutlinger\n2017). \nPhenomenological models. Phenomenological models have been\ndefined in different, although related, ways. A common definition\ntakes them to be models that only represent observable properties of\ntheir targets and refrain from postulating hidden mechanisms and the\nlike (Bokulich 2011). Another approach, due to McMullin (1968),\ndefines phenomenological models as models that are independent of\ntheories. This, however, seems to be too strong. Many phenomenological\nmodels, while failing to be derivable from a theory, incorporate\nprinciples and laws associated with theories. The liquid-drop model of\nthe atomic nucleus, for instance, portrays the nucleus as a liquid\ndrop and describes it as having several properties (surface tension\nand charge, among others) originating in different theories\n(hydrodynamics and electrodynamics, respectively). Certain aspects of\nthese theories—although usually not the full theories—are\nthen used to determine both the static and dynamical properties of the\nnucleus. Finally, it is tempting to identify phenomenological models\nwith models of a phenomenon. Here, “phenomenon”\nis an umbrella term covering all relatively stable and general\nfeatures of the world that are interesting from a scientific point of\nview. The weakening of sound as a function of the distance to the\nsource, the decay of alpha particles, the chemical reactions that take\nplace when a piece of limestone dissolves in an acid, the growth of a\npopulation of rabbits, and the dependence of house prices on the base\nrate of the Federal Reserve are phenomena in this sense. For further\ndiscussion, see Bailer-Jones (2009: Ch. 7), Bogen and Woodward (1988),\nand the entry on\n theory and observation in science. \nExploratory models. Exploratory models are models which are\nnot proposed in the first place to learn something about a specific\ntarget system or a particular experimentally established phenomenon.\nExploratory models function as the starting point of further\nexplorations in which the model is modified and refined. Gelfert\n(2016) points out that exploratory models can provide\nproofs-of-principle and suggest how-possibly explanations (2016: Ch. 4). As an example, Gelfert mentions early models in theoretical\necology, such as the Lotka–Volterra model of predator–prey\ninteraction, which mimic the qualitative behavior of speed-up and\nslow-down in population growth in an environment with limited\nresources (2016: 80). Such models do not give an accurate account of\nthe behavior of any actual population, but they provide the starting\npoint for the development of more realistic models. Massimi (2019)\nnotes that exploratory models provide modal knowledge. Fisher (2006)\nsees these models as tools for the examination of the features of a\ngiven theory. \nModels of data. A model of data (sometimes also “data\nmodel”) is a corrected, rectified, regimented, and in many\ninstances idealized version of the data we gain from immediate\nobservation, the so-called raw data (Suppes 1962). Characteristically,\none first eliminates errors (e.g., removes points from the record that\nare due to faulty observation) and then presents the data in a\n“neat” way, for instance by drawing a smooth curve through\na set of points. These two steps are commonly referred to as\n“data reduction” and “curve fitting”. When we\ninvestigate, for instance, the trajectory of a certain planet, we\nfirst eliminate points that are fallacious from the observation\nrecords and then fit a smooth curve to the remaining ones. Models of\ndata play a crucial role in confirming theories because it is the\nmodel of data, and not the often messy and complex raw data, that\ntheories are tested against. \nThe construction of a model of data can be extremely complicated. It\nrequires sophisticated statistical techniques and raises serious\nmethodological as well as philosophical questions. How do we decide\nwhich points on the record need to be removed? And given a clean set\nof data, what curve do we fit to it? The first question has been dealt\nwith mainly within the context of the philosophy of experiment (see,\nfor instance, Galison 1997 and Staley 2004). At the heart of the\nlatter question lies the so-called curve-fitting problem, which is\nthat the data themselves dictate neither the form of the fitted curve\nnor what statistical techniques scientists should use to construct a\ncurve. The choice and rationalization of statistical techniques is the\nsubject matter of the philosophy of statistics, and we refer the\nreader to the entry\n Philosophy of Statistics\n and to Bandyopadhyay and Forster (2011) for a discussion of these\nissues. Further discussions of models of data can be found in\nBailer-Jones (2009: Ch. 7), Brewer and Chinn (1994), Harris (2003),\nHartmann (1995), Laymon (1982), Mayo (1996, 2018), and Suppes\n(2007). \nThe gathering, processing, dissemination, analysis, interpretation, and\nstorage of data raise many important questions beyond the relatively\nnarrow issues pertaining to models of data. Leonelli (2016, 2019)\ninvestigates the status of data in science, argues that data should\nbe defined not by their provenance but by their evidential function,\nand studies how data travel between different contexts. \nWhat are models? That is, what kind of object are scientists dealing\nwith when they work with a model? A number of authors have voiced\nskepticism that this question has a meaningful answer, because models\ndo not belong to a distinctive ontological category and anything can\nbe a model (Callender and Cohen 2006; Giere 2010; Suárez 2004;\nSwoyer 1991; Teller 2001). Contessa (2010) replies that this is a\nnon sequitur. Even if, from an ontological point of view,\nanything can be a model and the class of things that are referred to\nas models contains a heterogeneous collection of different things, it\ndoes not follow that it is either impossible or pointless to develop\nan ontology of models. This is because even if not all models are of a\nparticular ontological kind, one can nevertheless ask to what\nontological kinds the things that are de facto used as models\nbelong. There may be several such kinds and each kind can be analyzed\nin its own right. What sort of objects scientists use as models has\nimportant repercussions for how models perform relevant functions such\nas representation and explanation, and hence this issue cannot be\ndismissed as “just sociology”. \nThe objects that commonly serve as models indeed belong to different\nontological kinds: physical objects, fictional objects, abstract\nobjects, set-theoretic structures, descriptions, equations, or\ncombinations of some of these, are frequently referred to as models,\nand some models may fall into yet other classes of things. Following\nContessa’s advice, the aim then is to develop an ontology for\neach of these. Those with an interest in ontology may see this as a\ngoal in its own right. It pays noting, however, that the question has\nreverberations beyond ontology and bears on how one understands the\nsemantics and the epistemology of models. \nSome models are physical objects. Such models are commonly referred to\nas “material models”. Standard examples of models of this\nkind are scale models of objects like bridges and ships (see\n Section 1),\n Watson and Crick’s metal model of DNA (Schaffner 1969),\nPhillips and Newlyn’s hydraulic model of an economy (Morgan and\nBoumans 2004), the US Army Corps of Engineers’ model of the San\nFrancisco Bay (Weisberg 2013), Kendrew’s plasticine model of\nmyoglobin (Frigg and Nguyen 2016), and model organisms in the life\nsciences (Leonelli and Ankeny 2012; Leonelli 2010; Levy and Currie\n2015). All these are material objects that serve as models. Material\nmodels do not give rise to ontological difficulties over and above the\nwell-known problems in connection with objects that metaphysicians\ndeal with, for instance concerning the nature of properties, the\nidentity of objects, parts and wholes, and so on. \nHowever, many models are not material models. The Bohr model\nof the atom, a frictionless pendulum, or an isolated population, for\ninstance, are in the scientist’s mind rather than in the\nlaboratory and they do not have to be physically realized and\nexperimented upon to serve as models. These “non-physical”\nmodels raise serious ontological questions, and how they are best\nanalyzed is debated controversially. In the remainder of this section\nwe review some of the suggestions that have attracted attention in the\nrecent literature on models. \nWhat has become known as the fiction view of models sees\nmodels as akin to the imagined objects of literary fiction—that\nis, as akin to fictional characters like Sherlock Holmes or fictional\nplaces like Middle Earth (Godfrey-Smith 2007). So when Bohr introduced\nhis model of the atom he introduced a fictional object of the same\nkind as the object Conan Doyle introduced when he invented Sherlock\nHolmes. This view squares well with scientific practice, where\nscientists often talk about models as if they were objects and often\ntake themselves to be describing imaginary atoms, populations,\nor economies. It also squares well with philosophical views that see\nthe construction and manipulation of models as essential aspects of\nscientific investigation (Morgan 1999), even if models are not\nmaterial objects, because these practices seem to be directed toward\nsome kind of object. \nWhat philosophical questions does this move solve? Fictional discourse\nand fictional entities face well-known philosophical questions, and\none may well argue that simply likening models to fictions amounts to\nexplaining obscurum per obscurius (for a discussion of these\nquestions, see the entry on\n fictional entities).\n One way to counter this objection and to motivate the fiction view of\nmodels is to point to the view’s heuristic power. In this vein\nFrigg (2010b) identifies five specific issues that an ontology of\nmodels has to address and then notes that these issues arise in very\nsimilar ways in the discussion about fiction (the issues are the\nidentity conditions, property attribution, the semantics of\ncomparative statements, truth conditions, and the epistemology of\nimagined objects). Likening models to fiction then has heuristic value\nbecause there is a rich literature on fiction that offers a number of\nsolutions to these issues. \nOnly a small portion of the options available in the extensive\nliterature on fictions have actually been explored in the context of\nscientific models. Contessa (2010) formulates what he calls the\n“dualist account”, according to which a model is an\nabstract object that stands for a possible concrete object. The\nRutherford model of the atom, for instance, is an abstract object that\nacts as a stand-in for one of the possible systems that contain an\nelectron orbiting around a nucleus in a well-defined orbit.\nBarberousse and Ludwig (2009) and Frigg (2010b) take a different route\nand develop an account of models as fictions based on Walton’s\n(1990) pretense theory of fiction. According to this view the\nsentences of a passage of text introducing a model should be seen as a\nprop in a game of make-believe, and the model is the product of an act\nof pretense. This is an antirealist position in that it takes talk of\nmodel “objects” to be figures of speech because ultimately\nthere are no model objects—models only live in scientists’\nimaginations. Salis (forthcoming) reformulates this view to become\nwhat she calls the “the new fiction view of models”. The\ncore difference lies in the fact that what is considered as the model\nare the model descriptions and their content rather than the\nimaginings that they prescribe. This is a realist view of models,\nbecause descriptions exist. \nThe fiction view is not without critics. Giere (2009), Magnani (2012),\nPincock (2012), Portides (2014), and Teller (2009) reject the fiction\napproach and argue, in different ways, that models should not be\nregarded as fictions. Weisberg (2013) argues for a middle position\nwhich sees fictions as playing a heuristic role but denies that they\nshould be regarded as forming part of a scientific model. The common\ncore of these criticisms is that the fiction view misconstrues the\nepistemic standing of models. To call something a fiction, so the\ncharge goes, is tantamount to saying that it is false, and it is\nunjustified to call an entire model a fiction—and thereby claim\nthat it fails to capture how the world is—just because the model\ninvolves certain false assumptions or fictional elements. In other\nwords, a representation isn’t automatically counted as fiction\njust because it has some inaccuracies. Proponents of the fiction view\nagree with this point but deny that the notion of fiction should be\nanalyzed in terms of falsity. What makes a work a fiction is not its\nfalsity (or some ratio of false to true claims): neither is everything\nthat is said in a novel untrue (Tolstoy’s War and Peace\ncontains many true statements about Napoleon’s Franco-Russian\nWar), nor does every text containing false claims qualify as fiction\n(false news reports are just that, they are not fictions). The\ndefining feature of a fiction is that readers are supposed to\nimagine the events and characters described, not that they\nare false (Frigg 2010a; Salis forthcoming). \nGiere (1988) advocated the view that “non-physical” models\nare abstract entities. However, there is little agreement on the\nnature of abstract objects, and Hale (1988: 86–87) lists no less\nthan twelve different possible characterizations (for a review of the\navailable options, see the entry on\n abstract objects).\n In recent publications, Thomasson (2020) and Thomson-Jones\n(2020) develop what they call an “artifactualist\nview” of models, which is based on Thomasson’s (1999)\ntheory of abstract artifacts. This view agrees with the pretense\ntheory that the content of text that introduces a fictional character\nor a model should be understood as occurring in pretense, but at the\nsame time insists that in producing such descriptions authors create\nabstract cultural artifacts that then exist independently of either\nthe author or the readers. Artifactualism agrees with Platonism that\nabstract objects exist, but insists, contra Platonism, that\nabstract objects are brought into existence through a creative act and\nare not eternal.  This allows the artifactualist to preserve the\nadvantages of pretense theory while at the same time holding the\nrealist view that fictional characters and models actually exist. \nAn influential point of view takes models to be set-theoretic\nstructures. This position can be traced back to Suppes (1960) and is\nnow, with slight variants, held by most proponents of the so-called\nsemantic view of theories (for a discussion of this view, see the\nentry on\n the structure of scientific theories).\n There are differences between the versions of the semantic view, but\nwith the exception of Giere (1988) all versions agree that models are\nstructures of one sort or another (Da Costa and French 2000). \nThis view of models has been criticized on various grounds. One\npervasive criticism is that many types of models that play an\nimportant role in science are not structures and cannot be\naccommodated within the structuralist view of models, which can\nneither account for how these models are constructed nor for how they\nwork in the context of investigation (Cartwright 1999; Downes 1992;\nMorrison 1999). Examples for such models are interpretative models and\nmediating models, discussed later in\n Section 4.2.\n Another charge held against the set-theoretic approach is that\nset-theoretic structures by themselves cannot be representational\nmodels—at least if that requires them to share some structure\nwith the target—because the ascription of a structure to a\ntarget system which forms part of the physical world relies on a\nsubstantive (non-structural) description of the target, which goes\nbeyond what the structuralist approach can afford (Nguyen and Frigg\nforthcoming). \nA time-honored position has it that a model is a stylized description\nof a target system. It has been argued that this is what scientists\ndisplay in papers and textbooks when they present a model (Achinstein\n1968; Black 1962). This view has not been subject to explicit\ncriticism. However, some of the criticisms that have been marshaled\nagainst the so-called syntactic view of theories equally threaten a\nlinguistic understanding of models (for a discussion of this view, see the\nentry on\n the structure of scientific theories).\n First, a standard criticism of the syntactic view is that by\nassociating a theory with a particular formulation, the view\nmisconstrues theory identity because any change in the formulation\nresults in a new theory (Suppe 2000). A view that associates models\nwith descriptions would seem to be open to the same criticism. Second,\nmodels have different properties than descriptions: the Newtonian\nmodel of the solar system consists of orbiting spheres, but it makes\nno sense to say this about its description. Conversely, descriptions\nhave properties that models do not have: a description can be written\nin English and consist of 517 words, but the same cannot be said of a\nmodel. One way around these difficulties is to associate the model\nwith the content of a description rather than with the description\nitself. For a discussion of a position on models that builds on the\ncontent of a description, see Salis (forthcoming). \nA contemporary version of descriptivism is Levy’s (2012, 2015)\nand Toon’s (2012) so-called direct-representation view. This\nview shares with the fiction view of models\n (Section 2.2)\n the reliance on Walton’s pretense theory, but uses it in a\ndifferent way. The main difference is that the views discussed earlier\nsee modeling as introducing a vehicle of representation, the model,\nthat is distinct from the target, and they see the problem as\nelucidating what kind of thing the model is. On the\ndirect-representation view there are no models distinct from the\ntarget; there are only model-descriptions and targets, with no models\nin-between them. Modeling, on this view, consists in providing an\nimaginative description of real things. A model-description prescribes\nimaginings about the real system; the ideal pendulum, for instance,\nprescribes model-users to imagine the real spring as perfectly elastic\nand the bob as a point mass. This approach avoids the above problems\nbecause the identity conditions for models are given by the conditions\nfor games of make-believe (and not by the syntax of a description) and\nproperty ascriptions take place in pretense. There are, however,\nquestions about how this account deals with models that have no target\n(like models of the ether or four-sex populations), and about how\nmodels thus understood deal with idealizations. For a discussion of\nthese points, see Frigg and Nguyen (2016), Poznic (2016), and Salis\n(forthcoming). \nA closely related approach sees models as equations. This is a version\nof the view that models are descriptions, because equations are\nsyntactic items that describe a mathematical structure. The issues\nthat this view faces are similar to the ones we have already\nencountered: First, one can describe the same situation using\ndifferent kinds of coordinates and as a result obtain different\nequations but without thereby also obtaining a different model.\nSecond, the model and the equation have different properties. A\npendulum contains a massless string, but the equation describing its\nmotion does not; and an equation may be inhomogeneous, but the system\nit describes is not. It is an open question whether these issues can\nbe avoided by appeal to a pretense account. \nOne of the main reasons why models play such an important role in\nscience is that they perform a number of cognitive functions. For\nexample, models are vehicles for learning about the world. Significant\nparts of scientific investigation are carried out on models rather\nthan on reality itself because by studying a model we can discover\nfeatures of, and ascertain facts about, the system the model stands\nfor: models allow for “surrogative reasoning” (Swoyer\n1991). For instance, we study the nature of the hydrogen atom, the\ndynamics of a population, or the behavior of a polymer by studying\ntheir respective models. This cognitive function of models has been\nwidely acknowledged in the literature, and some even suggest that\nmodels give rise to a new style of reasoning, “model-based\nreasoning”, according to which “inferences are made by\nmeans of creating models and manipulating, adapting, and evaluating\nthem” (Nersessian 2010: 12; see also Magnani, Nersessian, and\nThagard 1999; Magnani and Nersessian 2002; and Magnani and Casadio\n2016). \nLearning about a model happens in two places: in the construction of\nthe model and in its manipulation (Morgan 1999). There are no fixed\nrules or recipes for model building and so the very activity of\nfiguring out what fits together, and how, affords an opportunity to\nlearn about the model. Once the model is built, we do not learn about\nits properties by looking at it; we have to use and manipulate the\nmodel in order to elicit its secrets. \nDepending on what kind of model we are dealing with, building and\nmanipulating a model amount to different activities demanding\ndifferent methodologies. Material models seem to be straightforward\nbecause they are used in common experimental contexts (e.g., we put\nthe model of a car in the wind tunnel and measure its air resistance).\nHence, as far as learning about the model is concerned, material\nmodels do not give rise to questions that go beyond questions\nconcerning experimentation more generally. \nNot so with fictional and abstract models. What constraints are there\nto the construction of fictional and abstract models, and how do we\nmanipulate them? A natural response seems to be that we do this by\nperforming a thought experiment. Different authors (e.g., Brown 1991;\nGendler 2000; Norton 1991; Reiss 2003; Sorensen 1992) have explored\nthis line of argument, but they have reached very different and often\nconflicting conclusions about how thought experiments are performed\nand what the status of their outcomes is (for details, see the entry\non\n thought experiments). \nAn important class of models is computational in nature. For some\nmodels it is possible to derive results or solve equations of a\nmathematical model analytically. But quite often this is not the case.\nIt is at this point that computers have a great impact, because they\nallow us to solve problems that are otherwise intractable. Hence,\ncomputational methods provide us with knowledge about (the\nconsequences of) a model where analytical methods remain silent. Many\nparts of current research in both the natural and social sciences rely\non computer simulations, which help scientists to explore the\nconsequences of models that cannot be investigated otherwise. The\nformation and development of stars and galaxies, the dynamics of\nhigh-energy heavy-ion reactions, the evolution of life, outbreaks of\nwars, the progression of an economy, moral behavior, and the\nconsequences of decision procedures in an organization are explored\nwith computer simulations, to mention only a few examples. \nComputer simulations are also heuristically important. They can\nsuggest new theories, models, and hypotheses, for example, based on a\nsystematic exploration of a model’s parameter space (Hartmann\n1996). But computer simulations also bear methodological perils. For\nexample, they may provide misleading results because, due to the\ndiscrete nature of the calculations carried out on a digital computer,\nthey only allow for the exploration of a part of the full parameter\nspace, and this subspace need not reflect every important feature of\nthe model. The severity of this problem is somewhat mitigated by the\nincreasing power of modern computers. But the availability of more\ncomputational power can also have adverse effects: it may encourage\nscientists to swiftly come up with increasingly complex but\nconceptually premature models, involving poorly understood assumptions\nor mechanisms and too many additional adjustable parameters (for a\ndiscussion of a related problem in the social sciences, see Braun and\nSaam 2015: Ch. 3). This can lead to an increase in empirical\nadequacy—which may be welcome for certain forecasting\ntasks—but not necessarily to a better understanding of the\nunderlying mechanisms. As a result, the use of computer simulations\ncan change the weight we assign to the various goals of science.\nFinally, the availability of computer power may seduce scientists into\nmaking calculations that do not have the degree of trustworthiness one\nwould expect them to have. This happens, for instance, when computers\nare used to propagate probability distributions forward in time, which\ncan turn out to be misleading (see Frigg et al. 2014). So it is\nimportant not to be carried away by the means that new powerful\ncomputers offer and lose sight of the actual goals of research. For a\ndiscussion of further issues in connection with computer simulations,\nwe refer the reader to the entry on\n computer simulations in science. \nOnce we have knowledge about the model, this knowledge has to be\n“translated” into knowledge about the target system. It is\nat this point that the representational function of models becomes\nimportant again: if a model represents, then it can instruct us about\nreality because (at least some of) the model’s parts or aspects\nhave corresponding parts or aspects in the world. But if learning is\nconnected to representation and if there are different kinds of\nrepresentations (analogies, idealizations, etc.), then there are also\ndifferent kinds of learning. If, for instance, we have a model we take\nto be a realistic depiction, the transfer of knowledge from the model\nto the target is accomplished in a different manner than when we deal\nwith an analogue, or a model that involves idealizing assumptions. For\na discussion of the different ways in which the representational\nfunction of models can be exploited to learn about the target, we\nrefer the reader to the entry\n Scientific Representation. \nSome models explain. But how can they fulfill this function given that\nthey typically involve idealizations? Do these models explain\ndespite or because of the idealizations\nthey involve? Does an explanatory use of models presuppose that they\nrepresent, or can non-representational models also explain? And what\nkind of explanation do models provide? \nThere is a long tradition requesting that the explanans of a\nscientific explanation must be true. We find this requirement in the\ndeductive-nomological model (Hempel 1965) as well as in the more\nrecent literature. For instance, Strevens (2008: 297) claims that “no causal\naccount of explanation … allows nonveridical models to\nexplain”. For further discussions, see also Colombo et al.\n(2015). \nAuthors working in this tradition deny that idealizations make a\npositive contribution to explanation and explore how models can\nexplain despite being idealized. McMullin (1968, 1985) argues that a\ncausal explanation based on an idealized model leaves out only\nfeatures which are irrelevant for the respective explanatory task (see\nalso Salmon 1984 and\nPiccinini and Craver 2011 for a discussion of mechanism sketches).\nFriedman (1974) argues\nthat a more realistic (and hence less idealized) model explains better\non the unification account. The idea is that idealizations can (at\nleast in principle) be de-idealized (for a critical discussion of this\nclaim in the context of the debate about scientific explanations, see\nBatterman 2002; Bokulich 2011; Morrison 2005, 2009; Jebeile and\nKennedy 2015; and Rice 2015). Strevens (2008) argues that an explanatory\ncausal model has to provide an accurate representation of the relevant\ncausal relationships or processes which the model shares with the\ntarget system. The idealized assumptions of a model do not make a\ndifference for the phenomenon under consideration and are therefore\nexplanatorily irrelevant. In contrast, both Potochnik (2017) and Rice\n(2015) argue that models that explain can directly distort\nmany difference-making causes. \nAccording to Woodward’s (2003) theory, models are tools to find\nout about the causal relations that hold between certain facts or\nprocesses, and it is these relations that do the explanatory work.\nMore specifically, explanations provide information about patterns of\ncounterfactual dependence between the explanans and the explanandum\nwhich  \nenable us to see what sort of difference it would have made for the\nexplanandum if the factors cited in the explanans had been different\nin various possible ways. (Woodward 2003: 11)  \nAccounts of causal explanation have also led to various claims about\nhow idealized models can provide explanations, exploring to what\nextent idealization allows for the misrepresentation of irrelevant\ncausal factors by the explanatory model (Elgin and Sober 2002;\nStrevens 2004, 2008; Potochnik 2007; Weisberg\n2007, 2013). However, having the causally relevant features in common\nwith real systems continues to play the essential role in showing how\nidealized models can be explanatory. \nBut is it really the truth of the explanans that makes the model\nexplanatory? Other authors pursue a more radical line and argue that\nfalse models explain not only despite their falsity, but in\nfact because of their falsity. Cartwright (1983: 44)\nmaintains that “the truth doesn’t explain much”. In\nher so-called “simulacrum account of explanation”, she\nsuggests that we explain a phenomenon by constructing a model that\nfits the phenomenon into the basic framework of a grand theory (1983:\nCh. 8). On this account, the model itself is the explanation we seek.\nThis squares well with basic scientific intuitions, but it leaves us\nwith the question of what notion of explanation is at work (see also\nElgin and Sober 2002) and of what explanatory function idealizations\nplay in model explanations (Rice 2018, 2019). Wimsatt (2007: Ch. 6)\nstresses the role of false models as means to arrive at true theories.\nBatterman and Rice (2014) argue that models explain because the\ndetails that characterize specific systems do not matter for the\nexplanation. Bokulich (2008, 2009, 2011, 2012) pursues a similar line\nof reasoning and sees the explanatory power of models as being closely\nrelated to their fictional nature. Bokulich (2009) and Kennedy (2012)\npresent non-representational accounts of model explanation (see also\nJebeile and Kennedy 2015). Reiss (2012) and Woody (2004) provide general discussions of the relationship between\nrepresentation and explanation. \nMany authors have pointed out that understanding is one of the central\ngoals of science (see, for instance, de Regt 2017; Elgin 2017; Khalifa\n2017; Potochnik 2017). In some cases, we want to understand a certain\nphenomenon (e.g., why the sky is blue); in other cases, we want to\nunderstand a specific scientific theory (e.g., quantum mechanics) that\naccounts for a phenomenon in question. Sometimes we gain understanding\nof a phenomenon by understanding the corresponding theory or model.\nFor instance, Maxwell’s theory of electromagnetism helps us\nunderstand why the sky is blue. It is, however, controversial whether\nunderstanding a phenomenon always presupposes an\nunderstanding of the corresponding theory (de Regt 2009: 26).  \nAlthough there are many different ways of gaining understanding,\nmodels and the activity of scientific modeling are of particular\nimportance here (de Regt et al. 2009; Morrison 2009; Potochnik 2017;\nRice 2016). This insight\ncan be traced back at least to Lord Kelvin who, in his famous 1884\nBaltimore Lectures on Molecular Dynamics and the Wave Theory of\nLight, maintained that “the test of ‘Do we or do we\nnot understand a particular subject in physics?’ is ‘Can\nwe make a mechanical model of it?’” (Kelvin 1884 [1987: 111]; see also Bailer-Jones 2009: Ch. 2; and de Regt 2017: Ch. 6).  \nBut why do models play such a crucial role in the understanding of a\nsubject matter? Elgin (2017) argues that this is not despite, but\nbecause, of models being literally false. She views false models as\n“felicitous falsehoods” that occupy center stage in the\nepistemology of science, and mentions the ideal-gas model in\nstatistical mechanics and the Hardy–Weinberg model in genetics as\nexamples for literally false models that are central to their\nrespective disciplines. Understanding is holistic and it concerns a\ntopic, a discipline, or a subject matter, rather than isolated claims\nor facts. Gaining understanding of a context means to have  \nan epistemic commitment to a comprehensive, systematically linked body\nof information that is grounded in fact, is duly responsive to reasons\nor evidence, and enables nontrivial inference, argument, and perhaps\naction regarding the topic the information pertains to (Elgin 2017:\n44)  \nand models can play a crucial role in the pursuit of these epistemic\ncommitments. For a discussion of Elgin’s account of models and\nunderstanding, see Baumberger and Brun (2017) and Frigg and Nguyen\n(forthcoming). \nElgin (2017), Lipton (2009), and Rice (2016) all argue that models can be used to understand\nindependently of their ability to provide an explanation. Other\nauthors, among them Strevens (2008, 2013), argue that understanding\npresupposes a scientific explanation and that \nan individual has scientific understanding of a phenomenon just in\ncase they grasp a correct scientific explanation of that phenomenon.\n(Strevens 2013: 510; see,\nhowever, Sullivan and Khalifa 2019)  \nOn this account, understanding consists in a particular form of\nepistemic access an individual scientist has to an explanation. For\nStrevens this aspect is “grasping”, while for de Regt\n(2017) it is “intelligibility”. It is important to note\nthat both Strevens and de Regt hold that such “subjective”\naspects are a worthy topic for investigations in the philosophy of\nscience. This contrasts with the traditional view (see, e.g., Hempel\n1965) that delegates them to the realm of psychology. See Friedman\n(1974), Trout (2002), and\nReutlinger et al. (2018) for further discussions of understanding. \nBesides the functions already mentioned, it has been emphasized\nvariously that models perform a number of other cognitive functions.\nKnuuttila (2005, 2011) argues that the epistemic value of models is\nnot limited to their representational function, and develops an account\nthat views models as epistemic artifacts which allow us to gather\nknowledge in diverse ways. Nersessian (1999, 2010) stresses the role\nof analogue models in concept-formation and other cognitive processes.\nHartmann (1995) and Leplin (1980) discuss models as tools for theory\nconstruction and emphasize their heuristic and pedagogical value.\nEpstein (2008) lists a number of specific functions of models in the\nsocial sciences. Peschard (2011) investigates the way in which models\nmay be used to construct other models and generate new target systems.\nAnd Isaac (2013) discusses non-explanatory uses of models which do not\nrely on their representational capacities. \nAn important question concerns the relation between models and\ntheories. There is a full spectrum of positions ranging from models\nbeing subordinate to theories to models being independent of\ntheories. \nTo discuss the relation between models and theories in science it is\nhelpful to briefly recapitulate the notions of a model and of a theory\nin logic. A theory is taken to be a (usually deductively\nclosed) set of sentences in a formal language. A model is a\nstructure (in the sense introduced in\n Section 2.3)\n that makes all sentences of a theory true when its symbols are\ninterpreted as referring to objects, relations, or functions of a\nstructure. The structure is a model of the theory in the\nsense that it is correctly described by the theory (see Bell and\nMachover 1977 or Hodges 1997 for details). Logical models are\nsometimes also referred to as “models of theory” to\nindicate that they are interpretations of an abstract formal\nsystem. \nModels in science sometimes carry over from logic the idea of being\nthe interpretation of an abstract calculus (Hesse 1967). This is\nsalient in physics, where general laws—such as Newton’s\nequation of motion—lie at the heart of a theory. These laws are\napplied to a particular system—e.g., a pendulum—by\nchoosing a special force function, making assumptions about the mass\ndistribution of the pendulum etc. The resulting model then is an\ninterpretation (or realization) of the general law. \nIt is important to keep the notions of a logical and a\nrepresentational model separate (Thomson-Jones 2006): these are\ndistinct concepts. Something can be a logical model without being a\nrepresentational model, and vice versa. This, however, does\nnot mean that something cannot be a model in both senses at once. In\nfact, as Hesse (1967) points out, many models in science are both\nlogical and representational models. Newton’s model of planetary\nmotion is a case in point: the model, consisting of two homogeneous\nperfect spheres located in otherwise empty space that attract each\nother gravitationally, is simultaneously a logical model (because it\nmakes the axioms of Newtonian mechanics true when they are interpreted\nas referring to the model) and a representational model (because it\nrepresents the real sun and earth). \nThere are two main conceptions of scientific theories, the so-called\nsyntactic view of theories and the so-called semantic view of theories\n(see the entry on\n the structure of scientific theories).\n On both conceptions models play a subsidiary role to theories, albeit\nin very different ways. The syntactic view of theories (see entry\nsection on\n the syntactic view)\n retains the logical notions of a model and a theory. It construes a\ntheory as a set of sentences in an axiomatized logical system, and a\nmodel as an alternative interpretation of a certain calculus\n(Braithwaite 1953; Campbell 1920 [1957]; Nagel 1961; Spector 1965).\nIf, for instance, we take the mathematics used in the kinetic theory\nof gases and reinterpret the terms of this calculus in a way that\nmakes them refer to billiard balls, the billiard balls are a model of\nthe kinetic theory of gases in the sense that all sentences of the\ntheory come out true. The model is meant to be something that we are\nfamiliar with, and it serves the purpose of making an abstract formal\ncalculus more palpable. A given theory can have different models, and\nwhich model we choose depends both on our aims and our background\nknowledge. Proponents of the syntactic view disagree about the\nimportance of models. Carnap and Hempel thought that models only serve\na pedagogic or aesthetic purpose and are ultimately dispensable\nbecause all relevant information is contained in the theory (Carnap\n1938; Hempel 1965; see also Bailer-Jones 1999). Nagel (1961) and\nBraithwaite (1953), on the other hand, emphasize the\nheuristic role of models, and Schaffner (1969) submits that\ntheoretical terms get at least part of their meaning from models. \nThe semantic view of theories (see entry section on\n the semantic view)\n dispenses with sentences in an axiomatized logical system and\nconstrues a theory as a family of models. On this view, a theory\nliterally is a class, cluster, or family of models—models are the\nbuilding blocks of which scientific theories are made up. Different\nversions of the semantic view work with different notions of a model,\nbut, as noted in\n Section 2.3,\n in the semantic view models are mostly construed as set-theoretic\nstructures. For a discussion of the different options, we refer the\nreader to the relevant entry in this encyclopedia (linked at the\nbeginning of this paragraph). \nIn both the syntactic and the semantic view of theories models are\nseen as subordinate to theory and as playing no role outside the\ncontext of a theory. This vision of models has been challenged in a\nnumber of ways, with authors pointing out that models enjoy various\ndegrees of freedom from theory and function autonomously in many\ncontexts. Independence can take many forms, and large parts of the\nliterature on models are concerned with investigating various forms of\nindependence. \nModels as completely independent of theory. The most radical\ndeparture from a theory-centered analysis of models is the realization\nthat there are models that are completely independent from any theory.\nAn example of such a model is the Lotka–Volterra model. The model\ndescribes the interaction of two populations: a population of\npredators and one of prey animals (Weisberg 2013). The model was\nconstructed using only relatively commonsensical assumptions about\npredators and prey and the mathematics of differential equations.\nThere was no appeal to a theory of predator–prey interactions or a\ntheory of population growth, and the model is independent of theories\nabout its subject matter. If a model is constructed in a domain where\nno theory is available, then the model is sometimes referred to as a\n“substitute model” (Groenewold 1961), because the model\nsubstitutes a theory. \nModels as a means to explore theory. Models can also be used\nto explore theories (Morgan and Morrison 1999). An obvious way in\nwhich this can happen is when a model is a logical model of a theory\n(see\n Section 4.1).\n A logical model is a set of objects and properties that make a formal\nsentence true, and so one can see in the model how the axioms of the\ntheory play out in a particular setting and what kinds of behavior\nthey dictate. But not all models that are used to explore theories are\nlogical models, and models can represent features of theories in other\nways. As an example, consider chaos theory. The equations of\nnon-linear systems, such as those describing the three-body\nproblem, have solutions that are too complex to study with\npaper-and-pencil methods, and even computer simulations are limited in\nvarious ways. Abstract considerations about the qualitative behavior\nof solutions show that there is a mechanism that has been dubbed\n“stretching and folding” (see the entry\n Chaos).\n To obtain an idea of the complexity of the dynamics exhibiting\nstretching and folding, Smale proposed to study a simple model of the\nflow—now known as the “horseshoe map” (Tabor 1989)—which\nprovides important insights into the nature of stretching and folding.\nOther examples of models of that kind are the Kac ring model that is\nused to study equilibrium properties of systems in statistical\nmechanics (Lavis 2008)\nand Norton’s dome in Newtonian mechanics (Norton 2003). \nModels as complements of theories. A theory may be\nincompletely specified in the sense that it only imposes certain\ngeneral constraints but remains silent about the details of concrete\nsituations, which are provided by a model (Redhead 1980). A special\ncase of this situation is when a qualitative theory is known and the\nmodel introduces quantitative measures (Apostel 1961). Redhead’s\nexample of a theory that is underdetermined in this way is axiomatic\nquantum field theory, which only imposes certain general constraints\non quantum fields but does not provide an account of particular\nfields. Harré (2004) notes that models can complement theories by providing\nmechanisms for processes that are left unspecified in the theory even\nthough they are responsible for bringing about the observed\nphenomena. \nTheories may be too complicated to handle. In such cases a model can\ncomplement a theory by providing a simplified version of the\ntheoretical scenario that allows for a solution. Quantum\nchromodynamics, for instance, cannot easily be used to investigate the\nphysics of an atomic nucleus even though it is the relevant\nfundamental theory. To get around this difficulty, physicists\nconstruct tractable phenomenological models (such as the MIT bag\nmodel) which effectively describe the relevant degrees of freedom of\nthe system under consideration (Hartmann 1999, 2001). The advantage of\nthese models is that they yield results where theories remain silent.\nTheir drawback is that it is often not clear how to understand the\nrelationship between the model and the theory, as the two are, strictly\nspeaking, contradictory. \nModels as preliminary theories. The notion of a model as a\nsubstitute for a theory is closely related to the notion of a\ndevelopmental model. This term was coined by Leplin (1980),\nwho pointed out how useful models were in the development of early\nquantum theory, and it is now used as an umbrella notion covering\ncases in which models are some sort of a preliminary exercise to\ntheory. \nAlso closely related is the notion of a probing model (or\n“study model”). Models of this kind do not perform a\nrepresentational function and are not expected to instruct us about\nanything beyond the model itself. The purpose of these models is to\ntest new theoretical tools that are used later on to build\nrepresentational models. In field theory, for instance, the so-called\nφ4-model was studied extensively, not because it was\nbelieved to represent anything real, but because it served several\nheuristic functions: the simplicity of the φ4-model\nallowed physicists to “get a feeling” for what quantum\nfield theories are like and to extract some general features that this\nsimple model shared with more complicated ones. Physicists could study\ncomplicated techniques such as renormalization in a simple setting,\nand it was possible to get acquainted with important\nmechanisms—in this case symmetry-breaking—that could later\nbe used in different contexts (Hartmann 1995). This is true not only\nfor physics. As Wimsatt (1987, 2007) points out, a false model in\ngenetics can perform many useful functions, among them the following:\nthe false model can help answering questions about more realistic\nmodels, provide an arena for answering questions about properties of\nmore complex models, “factor out” phenomena that would not\notherwise be seen, serve as a limiting case of a more general model\n(or two false models may define the extremes of a continuum of cases\non which the real case is supposed to lie), or lead to the\nidentification of relevant variables and the estimation of their\nvalues. \nInterpretative models. Cartwright (1983, 1999) argues that\nmodels do not only aid the application of theories that are somehow\nincomplete; she claims that models are also involved whenever\na theory with an overarching mathematical structure is applied. The\nmain theories in physics—classical mechanics, electrodynamics,\nquantum mechanics, and so on—fall into this category. Theories of\nthat kind are formulated in terms of abstract concepts that need to be\nconcretized for the theory to provide a description of the target\nsystem, and concretizing the relevant concepts, idealized objects and\nprocesses are introduced. For instance, when applying classical\nmechanics, the abstract concept of force has to be replaced with a\nconcrete force such as gravity. To obtain tractable equations, this\nprocedure has to be applied to a simplified scenario, for instance\nthat of two perfectly spherical and homogeneous planets in otherwise\nempty space, rather than to reality in its full complexity. The result\nis an interpretative model, which grounds the application of\nmathematical theories to real-world targets. Such models are\nindependent from theory in that the theory does not determine their\nform, and yet they are necessary for the application of the theory to\na concrete problem. \nModels as mediators. The relation between models and theories\ncan be complicated and disorderly. The contributors to a programmatic\ncollection of essays edited by Morgan and Morrison (1999) rally around\nthe idea that models are instruments that mediate between theories and\nthe world. Models are “autonomous agents” in that they are\nindependent from both theories and their target systems, and it is\nthis independence that allows them to mediate between the two.\nTheories do not provide us with algorithms for the construction of a\nmodel; they are not “vending machines” into which one can\ninsert a problem and a model pops out (Cartwright 1999). The\nconstruction of a model often requires detailed knowledge about\nmaterials, approximation schemes, and the setup, and these are not\nprovided by the corresponding theory. Furthermore, the inner workings\nof a model are often driven by a number of different theories working\ncooperatively. In contemporary climate modeling, for instance,\nelements of different theories—among them fluid dynamics,\nthermodynamics, electromagnetism—are put to work cooperatively.\nWhat delivers the results is not the stringent application of one\ntheory, but the voices of different theories when put to use in chorus\nwith each other in one model. \nIn complex cases like the study of a laser system or the global\nclimate, models and theories can get so entangled that it becomes\nunclear where a line between the two should be drawn: where does the\nmodel end and the theory begin? This is not only a problem for\nphilosophical analysis; it also arises in scientific practice.\nBailer-Jones (2002) interviewed a group of physicists about their\nunderstanding of models and their relation to theories, and reports\nwidely diverging views: (i) there is no substantive difference between\nmodel and theory; (ii) models become theories when their\ndegree of confirmation increases; (iii) models contain simplifications\nand omissions, while theories are accurate and complete; (iv) theories\nare more general than models, and modeling is about applying general\ntheories to specific cases. The first suggestion seems to be too\nradical to do justice to many aspects of practice, where a distinction\nbetween models and theories is clearly made. The second view is in\nline with common parlance, where the terms “model” and\n“theory” are sometimes used to express someone’s\nattitude towards a particular hypothesis. The phrase “it’s\njust a model” indicates that the hypothesis at stake is asserted\nonly tentatively or is even known to be false, while something is\nawarded the label “theory” if it has acquired some degree\nof general acceptance. However, this use of “model” is\ndifferent from the uses we have seen in\n Sections 1 to 3\n and is therefore of no use if we aim to understand the relation\nbetween scientific models and theories (and, incidentally, one can\nequally dismiss speculative claims as being “just a\ntheory”). The third proposal is correct in associating models\nwith idealizations and simplifications, but it overshoots by\nrestricting this to models; in fact, also theories can contain\nidealizations and simplifications. The fourth view seems closely\naligned with interpretative models and the idea that models are\nmediators, but being more general is a gradual notion and hence does\nnot provide a clear-cut criterion to distinguish between theories and\nmodels. \nThe debate over scientific models has important repercussions for\nother issues in the philosophy of science (for a historical account of\nthe philosophical discussion about models, see Bailer-Jones 1999).\nTraditionally, the debates over, say, scientific realism, reductionism,\nand laws of nature were couched in terms of theories, because theories\nwere seen as the main carriers of scientific knowledge. Once models\nare acknowledged as occupying an important place in the edifice of\nscience, these issues have to be reconsidered with a focus on models.\nThe question is whether, and if so how, discussions of these issues\nchange when we shift focus from theories to models. Up to now, no\ncomprehensive model-based account of any of these issues has emerged,\nbut models have left important traces in the discussions of these\ntopics. \nAs we have seen in\n Section 1,\n models typically provide a distorted representation of their targets.\nIf one sees science as primarily model-based, this could be taken to\nsuggest an antirealist interpretation of science. Realists, however,\ndeny that the presence of idealizations in models renders a realist\napproach to science impossible and point out that a good model, while\nnot literally true, is usually at least approximately true, and/or\nthat it can be improved by de-idealization (Laymon 1985; McMullin\n1985; Nowak 1979; Brzezinski and Nowak 1992). \nApart from the usual worries about the elusiveness of the notion of\napproximate truth (for a discussion, see the entry on\n truthlikeness),\n antirealists have taken issue with this reply for two (related)\nreasons. First, as Cartwright (1989) points out, there is no reason to\nassume that one can always improve a model by adding de-idealizing\ncorrections. Second, it seems that de-idealization is not in\naccordance with scientific practice because it is unusual that\nscientists invest work in repeatedly de-idealizing an existing model.\nRather, they shift to a different modeling framework once the\nadjustments to be made get too involved (Hartmann 1998). The various\nmodels of the atomic nucleus are a case in point: once it was realized\nthat shell effects are important to understand various subatomic\nphenomena, the (collective) liquid-drop model was put aside and the\n(single-particle) shell model was developed to account for the\ncorresponding findings. A further difficulty with de-idealization is\nthat most idealizations are not “controlled”. For example,\nit is not clear in what way one could de-idealize the MIT bag model to\neventually arrive at quantum chromodynamics, the supposedly correct\nunderlying theory. \nA further antirealist argument, the “incompatible-models\nargument”, takes as its starting point the observation that\nscientists often successfully use several incompatible models of\none and the same target system for predictive purposes\n(Morrison 2000). These models seemingly contradict each other, as they\nascribe different properties to the same target system. In nuclear\nphysics, for instance, the liquid-drop model explores the analogy of\nthe atomic nucleus with a (charged) fluid drop, while the shell model\ndescribes nuclear properties in terms of the properties of protons and\nneutrons, the constituents of an atomic nucleus. This practice appears\nto cause a problem for scientific realism: Realists typically hold\nthat there is a close connection between the predictive success of a\ntheory and its being at least approximately true. But if several\nmodels of the same system are predictively successful and if these\nmodels are mutually inconsistent, then it is difficult to maintain\nthat they are all approximately true. \nRealists can react to this argument in various ways. First, they can\nchallenge the claim that the models in question are indeed\npredictively successful. If the models are not good predictors, then\nthe argument is blocked. Second, they can defend a version of\n“perspectival realism” (Giere 2006; Massimi 2017; Rueger\n2005). Proponents of this position (which is sometimes also called\n“perspectivism”) situate it somewhere between\n“standard” scientific realism and antirealism, and where\nexactly the right middle position lies is the subject matter of active\ndebate (Massimi 2018a,b; Saatsi 2016; Teller 2018; and the\ncontributions to Massimi and McCoy 2019). Third, realists can deny\nthat there is a problem in the first place, because scientific models,\nwhich are always idealized and therefore strictly speaking false, are\njust the wrong vehicle to make a point about realism (which should be\ndiscussed in terms of theories). \nA particular focal point of the realism debate are laws of nature,\nwhere the questions arise what laws are and whether they are\ntruthfully reflected in our scientific representations. According to\nthe two currently dominant accounts, the best-systems approach and the\nnecessitarian approach, laws of nature are understood to be universal\nin scope, meaning that they apply to everything that there is in the\nworld (for discussion of laws, see the entry on\n laws of nature).\n This take on laws does not seem to sit well with a view that places\nmodels at the center of scientific research. What role do general laws\nplay in science if it is models that represent what is happening in\nthe world? And how are models and laws related? \nOne possible response to these questions is to argue that laws of\nnature govern entities and processes in a model rather than\nin the world. Fundamental laws, on this approach, do not state facts\nabout the world but hold true of entities and processes in\nthe model. This view has been advocated in different variants:\nCartwright (1983) argues that all laws are ceteris paribus\nlaws. Cartwright (1999) makes use of “capacities” (which\nshe considers to be prior to laws) and introduces the notion of a\n“nomological machine”. This is  \na fixed (enough) arrangement of components, or factors, with stable\n(enough) capacities that in the right sort of stable (enough)\nenvironment will, with repeated operation, give rise to the kind of\nregular behavior that we represent in our scientific laws. (1999: 50;\nsee also the entry on\n ceteris paribus laws)\n  \nGiere (1999) argues that the laws of a theory are better thought of,\nnot as encoding general truths about the world, but rather as\nopen-ended statements that can be filled in various ways in the\nprocess of building more specific scientific models. Similar positions\nhave also been defended by Teller (2001) and van Fraassen (1989). \nThe multiple-models problem mentioned in\n Section 5.1\n also raises the question of how different models are related.\nEvidently, multiple models for the same target system do not generally\nstand in a deductive relationship, as they often contradict each\nother. Some (Cartwright 1999; Hacking 1983) have suggested a picture\nof science according to which there are no systematic relations that\nhold between different models. Some models are tied together because\nthey represent the same target system, but this does not imply that\nthey enter into any further relationships (deductive or otherwise). We\nare confronted with a patchwork of models, all of which hold\nceteris paribus in their specific domains of\napplicability. \nSome argue that this picture is at least partially incorrect because\nthere are various interesting relations that hold between different\nmodels or theories. These relations range from thoroughgoing reductive\nrelations (Scheibe 1997, 1999, 2001: esp. Chs. V.23 and V.24) and\ncontrolled approximations over singular limit relations (Batterman\n2001 [2016]) to structural relations (Gähde 1997) and rather\nloose relations called “stories” (Hartmann 1999; see also\nBokulich 2003; Teller 2002; and the essays collected in Part III of\nHartmann et al. 2008). These suggestions have been made on the basis\nof case studies, and it remains to be seen whether a more general\naccount of these relations can be given and whether a deeper\njustification for them can be provided, for instance, within a\nBayesian framework (first steps towards a Bayesian understanding of\nreductive relations can be found in Dizadji-Bahmani et al. 2011;\nLiefke and Hartmann 2018; and Tešić 2019). \nModels also figure in the debate about reduction and emergence in\nphysics. Here, some authors argue that the modern approach to\nrenormalization challenges Nagel’s (1961) model of reduction or\nthe broader doctrine of reductions (for a critical discussion, see,\nfor instance, Batterman 2002, 2010, 2011; Morrison 2012; and Saatsi and Reutlinger 2018).\nDizadji-Bahmani et al. (2010) provide a defense of the Nagel–Schaffner\nmodel of reduction, and Butterfield (2011a,b, 2014) argues that\nrenormalization is consistent with Nagelian reduction. Palacios (2019)\nshows that phase transitions are compatible with reductionism, and\nHartmann (2001) argues that the effective-field-theories research\nprogram is consistent with reductionism (see also Bain 2013 and\nFranklin forthcoming). Rosaler (2015) argues for a “local”\nform of reduction which sees the fundamental relation of reduction\nholding between models, not theories, which is, however, compatible\nwith the Nagel–Schaffner model of reduction. See also the entries on\n intertheory relations in physics\n and\n scientific reduction. \nIn the social sciences, agent-based models (ABMs) are increasingly\nused (Klein et al. 2018). These models show how surprisingly complex\nbehavioral patterns at the macro-scale can emerge from a small number\nof simple behavioral rules for the individual agents and their\ninteractions. This raises questions similar to the questions mentioned\nabove about reduction and emergence in physics, but so far one only\nfinds scattered remarks about reduction in the literature. See\nWeisberg and Muldoon (2009) and Zollman (2007) for the application of\nABMs to the epistemology and the social structure of science, and\nColyvan (2013) for a discussion of methodological questions raised by\nnormative models in general.","contact.mail":"stephan.hartmann@lrz.uni-muenchen.de","contact.domain":"lrz.uni-muenchen.de"}]
