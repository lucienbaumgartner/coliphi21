[{"date.published":"2006-08-25","date.changed":"2019-05-21","url":"https://plato.stanford.edu/entries/type-theory-church/","author1":"Christoph Benzmüller","author2":"Peter Andrews","entry":"type-theory-church","body.text":"\n\n\nChurch’s type theory, aka simple type theory, is a formal\nlogical language which includes classical first-order and\npropositional logic, but is more expressive in a practical sense. It\nis used, with some modifications and enhancements, in most modern\napplications of type theory. It is particularly well suited to the\nformalization of mathematics and other disciplines and to specifying\nand verifying hardware and software. It also plays an important role\nin the study of the formal semantics of natural language. When\nutilizing it as a meta-logic to semantically embed expressive\n(quantified) non-classical logics further topical applications are\nenabled in artificial intelligence and philosophy.\n\n\nA great wealth of technical knowledge can be expressed very naturally\nin it. With possible enhancements, Church’s type theory\nconstitutes an excellent formal language for representing the\nknowledge in automated information systems, sophisticated automated\nreasoning systems, systems for verifying the correctness of\nmathematical proofs, and a range of projects involving logic and\nartificial intelligence. Some examples and further references are\ngiven in Sections\n 1.2.2\n and\n 5\n below. \n\n\nType theories are also called higher-order logics, since they allow\nquantification not only over individual variables (as in first-order\nlogic), but also over function, predicate, and even higher order\nvariables. Type theories characteristically assign types to entities,\ndistinguishing, for example, between numbers, sets of numbers,\nfunctions from numbers to sets of numbers, and sets of such functions.\nAs illustrated in\n Section 1.2.2\n below, these distinctions allow one to discuss the conceptually rich\nworld of sets and functions without encountering the paradoxes of\nnaive set theory.\n\n\nChurch’s type theory is a formulation of type theory that was\nintroduced by Alonzo Church in Church 1940. In certain respects, it is\nsimpler and more general than the type theory introduced by Bertrand\nRussell in Russell 1908 and Whitehead & Russell 1927a. Since\nproperties and relations can be regarded as functions from entities to\ntruth values, the concept of a function is taken as primitive in\nChurch’s type theory, and the λ-notation which Church\nintroduced in Church 1932 and Church 1941 is incorporated into the\nformal language. Moreover, quantifiers and description operators are\nintroduced in a way so that additional binding mechanisms can be\navoided, λ-notation is reused instead. λ-notation is\nthus the only binding mechanism employed in Church’s type\ntheory.\n\n\n\n\nWe start with an informal description of the fundamental ideas\nunderlying the syntax of Church’s formulation of type\ntheory. \nAll entities have types, and if α and β are types, the type\nof functions from elements of type β to elements of type α\nis written as \\((\\alpha \\beta)\\). (This notation was introduced by\nChurch, but some authors write \\((\\beta \\rightarrow \\alpha)\\) instead\nof \\((\\alpha \\beta)\\). See, for example, Section 2 of the entry on\n type theory.) \nAs noted by Schönfinkel (1924), functions of more than one\nargument can be represented in terms of functions of one argument when\nthe values of these functions can themselves be functions. For\nexample, if f is a function of two arguments, for each element\nx of the left domain of f there is a function g\n(depending on x) such that \\(gy = fxy\\) for each element\ny of the right domain of f. We may now write \\(g = fx\\),\nand regard f as a function of a single argument, whose value\nfor any argument x in its domain is a function \\(fx\\), whose\nvalue for any argument y in its domain is fxy. \nFor a more explicit example, consider the function + which carries any\npair of natural numbers to their sum. We may denote this function by\n\\(+_{((\\sigma \\sigma)\\sigma)}\\), where \\(\\sigma\\) is the type of\nnatural numbers. Given any number x, \\([+_{((\\sigma\n\\sigma)\\sigma)}x]\\) is the function which, when applied to any number\ny, gives the value \\([[+_{((\\sigma \\sigma)\\sigma)}x]y]\\), which\nis ordinarily abbreviated as \\(x + y\\). Thus \\([+_{((\\sigma\n\\sigma)\\sigma)}x]\\) is the function of one argument which adds\nx to any number. When we think of \\(+_{((\\sigma\n\\sigma)\\sigma)}\\) as a function of one argument, we see that it maps\nany number x to the function \\([+_{((\\sigma\n\\sigma)\\sigma)}x]\\). \nMore generally, if f is a function which maps n-tuples\n\\(\\langle w_{\\beta},x_{\\gamma},\\ldots ,y_{\\delta},z_{\\tau}\\rangle\\) of\nelements of types \\(\\beta\\), \\(\\gamma\\),…, \\(\\delta\\)\n,\\(\\tau\\), respectively, to elements of type α, we may assign to\nf the type \\(((\\ldots((\\alpha \\tau)\\delta)\\ldots\n\\gamma)\\beta)\\). It is customary to use the convention of association\nto the left to omit parentheses, and write this type symbol simply as\n\\((\\alpha \\tau \\delta \\ldots \\gamma \\beta)\\). \nA set or property can be represented by a function (often called\ncharacteristic function) which maps elements to truth values,\nso that an element is in the set, or has the property, in question iff\nthe function representing the set or property maps that element to\ntruth. When a statement is asserted, the speaker means that it is\ntrue, so that \\(s x\\) means that \\(s x\\) is true, which also expresses\nthe assertions that s maps x to truth and that \\(x \\in\ns\\). In other words, \\(x \\in s\\) iff \\(s x\\). We take \\({o}\\) as the\ntype symbol denoting the type of truth values, so we may speak of any\nfunction of type \\(({o}\\alpha)\\) as a set of elements of type\nα. A function of type \\((({o}\\alpha)\\beta)\\) is a binary\nrelation between elements of type β and elements of type α.\nFor example, if \\(\\sigma\\) is the type of the natural numbers, and\n\\(<\\) is the order relation between natural numbers, \\(<\\) has\ntype \\(({o}\\sigma \\sigma)\\), and for all natural numbers x and\n\\(y, {<}x y\\) (which we ordinarily write as \\(x < y)\\) has the\nvalue truth iff x is less than y. Of course, \\(<\\)\ncan also be regarded as the function which maps each natural number\nx to the set \\(<x\\) of all natural numbers y such\nthat x is less than y. Thus sets, properties, and\nrelations may be regarded as particular kinds of functions.\nChurch’s type type theory is thus a logic of functions, and, in\nthis sense, it is in the tradition of the work of Frege’s\nBegriffsschrift. The opposite approach would be to reduce\nfunctions to relations, which was the approach taken by Whitehead and\nRussell (1927a) in the Principia Mathematica. \nExpressions which denote elements of type α are called wffs\nof type α. Thus, statements of type theory are wffs of type\n\\({o}\\). \nIf \\(\\bA_{\\alpha}\\) is a wff of type α in which \\(\\bu_{\\alpha\n\\beta}\\) is not free, the function (associated with) \\(\\bu_{\\alpha\n\\beta}\\) such that \\(\\forall \\bv_{\\beta}[\\bu_{\\alpha \\beta}\\bv_{\\beta}\n= \\bA_{\\alpha}]\\) is denoted by \\([\\lambda \\bv_{\\beta}\\bA_{\\alpha}]\\).\nThus \\(\\lambda \\bv_{\\beta}\\) is a variable-binder, like \\(\\forall\n\\bv_{\\beta}\\) or \\(\\exists \\bv_{\\beta}\\) (but with a quite different\nmeaning, of course); λ is known as an abstraction\noperator. \\([\\lambda \\bv_{\\beta}\\bA_{\\alpha}]\\) denotes the\nfunction whose value on any argument \\(\\bv_{\\beta}\\) is\n\\(\\bA_{\\alpha}\\), where \\(\\bv_{\\beta}\\) may occur free in\n\\(\\bA_{\\alpha}\\). For example, \\([\\lambda n_{\\sigma}[4\\cdot\nn_{\\sigma}+3]]\\) denotes the function whose value on any natural\nnumber n is \\(4\\cdot n+3\\). Hence, when we apply this function\nto the number 5 we obtain \\([\\lambda n_{\\sigma}[4\\cdot n_{\\sigma}+3]]5\n= 4\\cdot 5+3 = 23\\). \nWe use \\(\\textsf{Sub}(\\bB,\\bv,\\bA)\\) as a notation for the result of\nsubstituting \\(\\bB\\) for \\(\\bv\\) in \\(\\bA\\), and\n\\(\\textsf{SubFree}(\\bB,\\bv,\\bA)\\) as a notation for the result of\nsubstituting \\(\\bB\\) for all free occurrences of \\(\\bv\\) in \\(\\bA\\).\nThe process of replacing \\([\\lambda\n\\bv_{\\beta}\\bA_{\\alpha}]\\bB_{\\beta}\\) by\n\\(\\textsf{SubFree}(\\bB_{\\beta},\\bv_{\\beta},\\bA_{\\alpha})\\) (or\nvice-versa) is known as β-conversion, which is one form\nof λ-conversion. Of course, when \\(\\bA_{{o}}\\) is a\nwff of type \\({o}\\), \\([\\lambda \\bv_{\\beta}\\bA_{{o}}]\\) denotes the\nset of all elements \\(\\bv_{\\beta}\\) (of type \\(\\beta)\\) of which\n\\(\\bA_{{o}}\\) is true; this set may also be denoted by\n\\(\\{\\bv_{\\beta}|\\bA_{{o}}\\}\\). For example, \\([\\lambda x\\ x<y]\\)\ndenotes the set of x such that x is less than y\n(as well as that property which a number x has if it is less\nthan y). In familiar set-theoretic notation,  \nwould be written \n(By the Axiom of Extensionality for truth values, when \\(\\bC_{{o}}\\)\nand \\(\\bD_{{o}}\\) are of type \\({o}, \\bC_{{o}} \\equiv \\bD_{{o}}\\) is\nequivalent to \\(\\bC_{{o}} = \\bD_{{o}}\\).) \nPropositional connectives and quantifiers can be assigned types and\ncan be denoted by constants of these types. The negation function maps\ntruth values to truth values, so it has type \\(({o}{o})\\). Similarly,\ndisjunction and conjunction (etc.) are binary functions from truth\nvalues to truth values, so they have type \\(({o}{o}{o})\\). \nThe statement \\(\\forall \\bx_{\\alpha}\\bA_{{o}}\\) is true iff the set\n\\([\\lambda \\bx_{\\alpha}\\bA_{{o}}]\\) contains all elements of type\nα. A constant \\(\\Pi_{{o}({o}\\alpha)}\\) can be introduced (for\neach type symbol \\(\\alpha)\\) to denote a property of sets: a set\n\\(s_{{o}\\alpha}\\) has the property \\(\\Pi_{{o}({o}\\alpha)}\\) iff\n\\(s_{{o}\\alpha}\\) contains all elements of type α. With this\ninterpretation  \nshould be true, as well as  \nfor any wff \\(\\bA_{{o}}\\) and variable \\(\\bx_{\\alpha}\\). Since by\nλ-conversion we have  \nequation can be written more simply as  \nThus, \\(\\forall \\bx_{\\alpha}\\) can be defined in terms of\n\\(\\Pi_{{o}({o}\\alpha)}\\), and λ is the only variable-binder\nthat is needed. \nBefore we state the definition of a “formula”, a word of\ncaution is in order. The reader may be accustomed to thinking of a\nformula as an expression which plays the role of an assertion in a\nformal language, and of a term as an expression which designates an\nobject. Church’s terminology is somewhat different, and provides\na uniform way of discussing expressions of many different types. What\nwe call well-formed formula of type α\n(\\(\\textrm{wff}_{\\alpha}\\)) below would in more standard terminology\nbe called term of type α, and then only certain terms,\nnamely those with type \\({o}\\), would be called formulas. Anyhow, in\nthis entry we have decided to stay with Church’s original\nterminology. Another remark concerns the use of some specific\nmathematical notation. In what follows, the entry distinguishes\nbetween the symbols \\(\\imath\\), \\(\\iota_{(\\alpha({o}\\alpha))}\\), and \\(\\atoi\\). The first is\nthe symbol used for the type of individuals; the second is the symbol\nused for a logical constant (see\n Section 1.2.1\n below); the third is the symbol used as a variable-binding operator\nthat represents the definite description “the” (see\n Section 1.3.4).\n The reader should not confuse them and check to see that the browser\nis displaying these symbols correctly. \nType symbols are defined inductively as follows: \nThe primitive symbols are the following: \nA formula is a finite sequence of primitive symbols. Certain\nformulas are called well-formed formulas (wffs). We\nwrite \\(\\textrm{wff}_{\\alpha}\\) as an abbreviation for wff of\ntype α, and define this concept inductively as follows: \nNote, for example, that by (a) \\(\\nsim_{({o}{o})}\\) is a\nwff\\(_{({o}{o})}\\), so by (b) if \\(\\bA_{{o}}\\) is a wff\\(_{{o}}\\),\nthen \\([\\nsim_{({o}{o})}\\bA_{{o}}]\\) is a wff\\(_{{o}}\\). Usually, the\nlatter wff will simply be written as \\(\\nsim \\bA\\). It is often\nconvenient to avoid parentheses, brackets and type symbols, and use\nconventions for omitting them. For formulas we use the convention of\nassociation to the right, and we may write \\(\\lor_{((oo)o)}\\bA_{{o}}\n\\bB_{{o}}\\) instead of \\([[\\lor_{((oo)o)}\\bA_{{o}}] \\bB_{{o}}]\\). For\ntypes the corresponding convention is association to the left, and we\nmay write \\(ooo\\) instead of \\(((oo)o)\\). \nThe last definition is known as the Leibnizian definition of equality.\nIt asserts that x and y are the same if y has\nevery property that x has. Actually, Leibniz called his\ndefinition “the identity of indiscernibles” and gave it in\nthe form of a biconditional: x and y are the same if\nx and y have exactly the same properties. It is not\ndifficult to show that these two forms of the definition are logically\nequivalent. \nWe now provide a few examples to illustrate how various assertions and\nconcepts can be expressed in Church’s type theory. \n Example 1 To express the assertion that\n“Napoleon is charismatic” we introduce constants\n\\(\\const{Charismatic}_{{o}\\imath}\\) and \\(\\const{Napoleon}_{\\imath}\\),\nwith the types indicated by their subscripts and the obvious meanings,\nand assert the wff  \nIf we wish to express the assertion that\n“Napoleon has all the properties of a great\ngeneral”, we might consider interpreting this to mean that\n“Napoleon has all the properties of some great\ngeneral”, but it seems more appropriate to interpret this\nstatement as meaning that “Napoleon has all the properties\nwhich all great generals have”. If the constant\n\\(\\const{GreatGeneral}_{{o}\\imath}\\) is added to the formal language,\nthis can be expressed by the wff  \nAs an example of such a property, we note that the sentence\n“Napoleon’s soldiers admire him” can be\nexpressed in a similar way by the wff  \nBy λ-conversion, this is equivalent to  \nThis statement asserts that one of the properties which Napoleon has\nis that of being admired by his soldiers. The property itself is\nexpressed by the wff  \nExample 2 We illustrate some potential applications\nof type theory with the following fable. \nA rich and somewhat eccentric lady named Sheila has an ostrich and a\ncheetah as pets, and she wishes to take them from her hotel to her\nremote and almost inaccessible farm. Various portions of the trip may\ninvolve using elevators, boxcars, airplanes, trucks, very small boats,\ndonkey carts, suspension bridges, etc., and she and the pets will not\nalways be together. She knows that she must not permit the ostrich and\nthe cheetah to be together when she is not with them. \nWe consider how certain aspects of this problem can be formalized so\nthat Sheila can use an automated reasoning system to help analyze the\npossibilities. \nThere will be a set Moments of instants or intervals of time\nduring the trip. She will start the trip at the location\n\\(\\const{Hotel}\\) and moment \\(\\const{Start}\\), and end it at the\nlocation \\(\\const{Farm}\\) and moment \\(\\const{Finish}\\). Moments will\nhave type \\(\\tau\\), and locations will have type \\(\\varrho\\). A\nstate will have type \\(\\sigma\\) and will specify the location\nof Sheila, the ostrich, and the cheetah at a given moment. A\nplan will specify where the entities will be at each moment\naccording to this plan. It will be a function from moments to states,\nand will have type \\((\\sigma \\tau)\\). The exact representation of\nstates need not concern us, but there will be functions from states to\nlocations called \\(\\const{LocationOfSheila}\\),\n\\(\\const{LocationOfOstrich}\\), and \\(\\const{LocationOfCheetah}\\) which\nprovide the indicated information. Thus,\n\\(\\const{LocationOfSheila}_{\\varrho \\sigma}[p_{\\sigma \\tau}t_{\\tau}]\\)\nwill be the location of Sheila according to plan \\(p_{\\sigma \\tau}\\)\nat moment \\(t_{\\tau}\\). The set \\(\\const{Proposals}_{{o}(\\sigma\n\\tau)}\\) is the set of plans Sheila is considering. \nWe define a plan p to be acceptable if, according to that plan,\nthe group starts at the hotel, finishes at the farm, and whenever the\nostrich and the cheetah are together, Sheila is there too. Formally,\nwe define \\(\\const{Acceptable}_{{o}(\\sigma \\tau)}\\) as  \nWe can express the assertion that Sheila has a way to accomplish her\nobjective with the formula \nExample 3 We now provide a mathematical example.\nMathematical ideas can be expressed in type theory without introducing\nany new constants. An iterate of a function f from a\nset to itself is a function which applies f one or more times.\nFor example, if \\(g(x) = f(f(f(x)))\\), then g is an iterate of\nf.\n\\([\\text{ITERATE+}_{{o}(\\imath\\imath)(\\imath\\imath)}f_{\\imath\\imath}g_{\\imath\\imath}]\\)\nmeans that \\(g_{\\imath\\imath}\\) is an iterate of \\(f_{\\imath\\imath}\\).\n\\(\\text{ITERATE+}_{{o}(\\imath\\imath)(\\imath\\imath)}\\) is defined\n(inductively) as  \nThus, g is an iterate of f if g is in every set\np of functions which contains f and which contains the\nfunction \\(\\lambda\nx_{\\imath}f_{\\imath\\imath}[j_{\\imath\\imath}x_{\\imath}]\\) (i.e.,\nf composed with j) whenever it contains j. \nA fixed point of f is an element y such that\n\\(f(y) = y\\). \nIt can be proved that if some iterate of a function f has a\nunique fixed point, then f itself has a fixed point. This\ntheorem can be expressed by the wff  \nSee Andrews et al. 1996, for a discussion of how this theorem, which\nis called THM15B, can be proved automatically. \nExample 4 An example from philosophy is\nGödel’s variant of the ontological argument for the\nexistence of God. This example illustrates two interesting\naspects: \nChurch’s type theory can be employed as a meta-logic to\nconcisely embed expressive other logics such as the higher-order modal\nlogic assumed by Gödel. By exploiting the possible world\nsemantics of this target logic, its syntactic elements are defined in\nsuch a way that the infrastructure of the meta-logic are reused as\nmuch as possible. In this technique, called shallow semantical\nembedding, the modal operator \\(\\Box\\), for example, is simply\nidentified with (taken as syntactic sugar for) the λ-formula\n \nwhere \\(R_{{o}\\imath\\imath}\\) denotes the accessibility relation\nassociated with \\(\\Box\\) and type \\({\\imath}\\) is identified with\npossible worlds. Moreover, since \\(\\forall x_{\\alpha} [\\bA_{{o}\\alpha}\nx_{\\alpha}]\\) is shorthand in Church’s type theory for\n\\(\\Pi_{{o}({o}\\alpha)} [\\lambda x_{\\alpha} [\\bA_{{o}\\alpha}\nx_{\\alpha}]]\\), the modal formula  \nis represented as  \nwhere \\(\\Pi'\\) stands for the λ-term  \nand the \\(\\Box\\) gets resolved as described above. The above choice of\n\\(\\Pi'\\) realizes a possibilist notion of quantification. By\nintroducing a binary “existence” predicate in the\nmeta-logic and by utilizing this predicate as an additional guard in\nthe definition of \\(\\Pi'\\) an actualist notion of quantification\ncan be obtained. Expressing that an embedded modal formula\n\\(\\varphi_{{o}\\imath}\\) is globally valid is then captured by the\nformula \\(\\forall x_{\\imath} [\\varphi_{{o}\\imath} x_{\\imath}]\\). Local\nvalidity (and also actuality) can be modeled as \\(\\varphi_{{o}\\imath}\nn_{\\imath}\\), where \\(n_{\\imath}\\) is a nominal (constant symbol in\nthe meta-logic) denoting a particular possible world. \nThe above technique can be exploited for a natural encoding and\nautomated assessment of Gödel’s ontological argument in\nhigher-order modal logic, which unfolds into formulas in\nChurch’s type theory such that higher-order theorem provers can\nbe applied. Further details are presented in Section 6 (Logic and\nPhilosophy) of the SEP entry on\n automated reasoning\n and also in\n Section 5.2;\n moreover, see Benzmüller & Woltzenlogel-Paleo 2014 and\nBenzmüller 2019. \nExample 5 Suppose we omit the use of type symbols in\nthe definitions of wffs. Then we can write the formula \\(\\lambda\nx\\nsim[xx]\\), which we shall call \\(\\textrm{R}\\). It can be regarded as\ndenoting the set of all sets x such that x is not in\nx. We may then consider the formula \\([\\textrm{R R}]\\), which\nexpresses the assertion that \\(\\textrm{R}\\) is in itself. We can clearly\nprove \\([\\textrm{R R}] \\equiv [[\\lambda x\\nsim [xx]] \\textrm{R}]\\), so by\nλ-conversion we can derive \\([\\textrm{R R}] \\equiv\\,\n\\nsim[\\textrm{R R}]\\), which is a contradiction. This is\nRussell’s paradox. Russell’s discovery of this paradox\n(Russell 1903, 101-107) played a crucial role in the development of\ntype theory. Of course, when type symbols are present, \\(\\textrm{R}\\) is not\nwell-formed, and the contradiction cannot be derived. \nWe start by listing the axioms for what we shall call elementary\ntype theory.  \nThe theorems of elementary type theory are those theorems which can be\nderived, using the rules of inference, from Axioms\n(1)–\\((6^{\\alpha})\\) (for all type symbols \\(\\alpha)\\). We shall\nsometimes refer to elementary type theory as \\(\\cT\\). It embodies the\nlogic of propositional connectives, quantifiers, and\nλ-conversion in the context of type theory. \nTo illustrate the rules and axioms introduced above, we give a short\nand trivial proof in \\(\\cT\\). Following each wff of the proof, we\nindicate how it was inferred. (The proof is actually quite\ninefficient, since line 3 is not used later, and line 7 can be derived\ndirectly from line 5 without using line 6. The additional proof lines\nhave been inserted to illustrate some relevant aspects. For the sake\nof readability, many brackets have been deleted from the formulas in\nthis proof. The diligent reader should be able to restore them.)  \nNote that (3) can be written as  \nand (7) can be written as  \nWe have thus derived a well known law of quantification theory. We\nillustrate one possible interpretation of the wff \\((7')\\) (which\nis closely related to Axiom 6) by considering a situation in which a\nrancher puts some horses in a corral and leaves for the night. Later,\nhe cannot remember whether he closed the gate to the corral. While\nreflecting on the situation, he comes to a conclusion which can be\nexpressed by \\((7')\\) if we take the horses to be the elements of\ntype \\(\\imath\\), interpret \\(p_{{o}}\\) to mean “the gate was\nclosed”, and interpret \\(r_{{o}\\imath}\\) so that\n\\(r_{{o}\\imath}x_{\\imath}\\) asserts “\\(x_{\\imath}\\) left the\ncorral”. With this interpretation, \\((7')\\) says  \nIf it is true of every horse that the gate was closed or that the\nhorse left the corral, then the gate was closed or every horse left\nthe corral. \nTo the axioms listed above we add the axioms below to obtain\nChurch’s type theory. \nThe axioms of boolean and functional extensionality are the following:\n \nChurch did not include Axiom \\(7^{{o}}\\) in his list of axioms in\nChurch 1940, but he mentioned the possibility of including it. Henkin\ndid include it in Henkin 1950. \nThe expression  \nstands for  \nFor example,  \nstands for  \nBy λ-conversion, this is equivalent to  \nwhich reduces by λ-conversion to  \nThis asserts that there is a unique element which has the property\n\\(P_{{o}\\alpha}\\). From this example we can see that in general,\n\\(\\exists_1\\bx_{\\alpha}\\bA_{{o}}\\) expresses the assertion that\n“there is a unique \\(\\bx_{\\alpha}\\) such that\n\\(\\bA_{{o}}\\)”. \nWhen there is a unique such element \\(\\bx_{\\alpha}\\), it is convenient\nto have the notation \\(\\atoi\\bx_{\\alpha}\\bA_{{o}}\\) to represent the\nexpression “the \\(\\bx_{\\alpha}\\) such that \\(\\bA_{{o}}\\)”.\nRussell showed in Whitehead & Russell 1927b how to provide\ncontextual definitions for such notations in his formulation of type\ntheory. In Church’s type theory \\(\\atoi\\bx_{\\alpha}\\bA_{{o}}\\)\nis defined as \\(\\iota_{\\alpha({o}\\alpha)}[\\lambda\n\\bx_{\\alpha}\\bA_{{o}}]\\). Thus, \\(\\atoi\\) behaves like a\nvariable-binding operator, but it is defined in terms of λ with\nthe aid of the constant \\(\\iota_{\\alpha({o}\\alpha)}\\). Thus, λ\nis still the only variable-binding operator that is needed. \nSince \\(\\bA_{{o}}\\) describes \\(\\bx_{\\alpha},\n\\iota_{\\alpha({o}\\alpha)}\\) is called a description operator.\nAssociated with this notation is the following: \nThis says that when the set \\(p_{{o}\\alpha}\\) has a unique member,\nthen \\(\\iota_{\\alpha({o}\\alpha)}p_{{o}\\alpha}\\) is in\n\\(p_{{o}\\alpha}\\), and therefore is that unique member. Thus, this\naxiom asserts that \\(\\iota_{\\alpha({o}\\alpha)}\\) maps one-element sets\nto their unique members. \nIf from certain hypotheses one can prove  \nthen by using Axiom \\(8^{\\alpha}\\) one can derive  \nwhich can also be written as  \nWe illustrate the usefulness of the description operator with a small\nexample. Suppose we have formalized the theory of real numbers, and\nour theory has constants \\(1_{\\varrho}\\) and \\(\\times_{\\varrho \\varrho\n\\varrho}\\) to represent the number 1 and the multiplication function,\nrespectively. (Here \\(\\varrho\\) is the type of real numbers.) To\nrepresent the multiplicative inverse function, we can define the wff\n\\(\\textrm{INV}_{\\varrho \\varrho}\\) as  \nOf course, in traditional mathematical notation we would not write the\ntype symbols, and we would write \\(\\times_{\\varrho \\varrho\n\\varrho}z_{\\varrho}x_{\\varrho}\\) as \\(z \\times x\\) and write\n\\(\\textrm{INV}_{\\varrho \\varrho}z\\) as \\(z^{-1}\\). Thus \\(z^{-1}\\) is\ndefined to be that x such that \\(z \\times x = 1\\). When\nZ is provably not 0, we will be able to prove \\(\\exists_1\nx_{\\varrho}[\\times_{\\varrho \\varrho \\varrho} \\textrm{Z x}_{\\varrho} =\n1_{\\varrho}]\\) and \\(Z \\times Z^{-1} = 1\\), but if we cannot establish\nthat Z is not 0, nothing significant about \\(Z^{-1}\\) will be\nprovable. \nThe Axiom of Choice can be expressed as follows in Church’s type\ntheory:  \n\\((9^{\\alpha})\\) says that the choice function\n\\(\\iota_{\\alpha({o}\\alpha)}\\) chooses from every nonempty set\n\\(p_{{o}\\alpha}\\) an element, designated as\n\\(\\iota_{\\alpha({o}\\alpha)}p_{{o}\\alpha}\\), of that set. When this\nform of the Axiom of Choice is included in the list of axioms,\n\\(\\iota_{\\alpha({o}\\alpha)}\\) is called a selection operator instead\nof a description operator, and \\(\\atoi\\bx_{\\alpha} \\bA_{{o}}\\) means\n“an \\(\\bx_{\\alpha}\\) such that \\(\\bA_{{o}}\\)” when there\nis some such element \\(\\bx_{\\alpha}\\). These selection operators have\nthe same meaning as Hilbert’s \\(\\epsilon\\)-operator (Hilbert\n1928). However, we here provide one such operator for each type\nα. \nIt is natural to call \\(\\atoi\\) a definite description operator in\ncontexts where \\(\\atoi\\bx_{\\alpha}\\bA_{{o}}\\) means “the\n\\(\\bx_{\\alpha}\\) such that \\(\\bA_{{o}}\\)”, and to call it an\nindefinite description operator in contexts where\n\\(\\atoi\\bx_{\\alpha}\\bA_{{o}}\\) means “an \\(\\bx_{\\alpha}\\) such\nthat \\(\\bA_{{o}}\\)”. \nClearly the Axiom of Choice implies the Axiom of Descriptions, but\nsometimes formulations of type theory are used which include the Axiom\nof Descriptions, but not the Axiom of Choice. \nAnother formulation of the Axiom of Choice simply asserts the\nexistence of a choice function without explicitly naming it:  \nNormally when one assumes the Axiom of Choice in type theory, one\nassumes it as an axiom schema, and asserts AC\\(^{\\alpha}\\) for each\ntype symbol α. A similar remark applies to the axioms for\nextensionality and description. However, modern proof systems for\nChurch’s type theory, which are, e.g., based on resolution, do\nin fact avoid the addition of such axiom schemata for reasons as\nfurther explained in\n Sections 3.4\n and\n 4\n below. They work with more constrained, goal-directed proof rules\ninstead. \nBefore proceeding, we need to introduce some terminology. \\(\\cQ_0\\) is\nan alternative formulation of Church’s type theory which will be\ndescribed in\n Section 1.4\n and is equivalent to the system described above using Axioms\n(1)–(8). A type symbol is propositional if the only symbols\nwhich occur in it are \\({o}\\) and parentheses. \nYasuhara (1975) defined the relation “\\(\\ge\\)” between\ntypes as the reflexive transitive closure of the minimal relation such\nthat \\((\\alpha \\beta) \\ge \\alpha\\) and \\((\\alpha \\beta) \\ge \\beta\\).\nHe established that: \nThe existence of a choice functions for “higher” types\nthus entails the existence of choice functions for “lower”\ntypes, the opposite is generally not the case though. \nBüchi (1953) has shown that while the schemas expressing the\nAxiom of Choice and Zorn’s Lemma can be derived from each other,\nthe relationships between the particular types involved are\ncomplex. \nOne can define the natural numbers (and therefore other basic\nmathematical structures such as the real and complex numbers) in type\ntheory, but to prove that they have the required properties (such as\nPeano’s Postulates), one needs an Axiom of Infinity. There are\nmany viable possibilities for such an axiom, such as those discussed\nin Church 1940, section 57 of Church 1956, and section 60 of Andrews\n2002. \nIn\n Section 1.2.1,\n \\(\\nsim_{({o}{o})}, \\lor_{(({o}{o}){o})}\\), and the\n\\(\\Pi_{({o}({o}\\alpha))}\\)’s were taken as primitive\nconstants, and the wffs \\(\\sfQ_{{o}\\alpha \\alpha}\\) which denote\nequality relations at type α were defined in terms of these. We\nnow present an alternative formulation \\(\\cQ_0\\) of Church’s\ntype theory in which there are primitive constants \\(\\sfQ_{{o}\\alpha\n\\alpha}\\) denoting equality, and \\(\\nsim_{({o}{o})},\n\\lor_{(({o}{o}){o})}\\), and the \\(\\Pi_{({o}({o}\\alpha))}\\)’s\nare defined in terms of the \\(\\sfQ_{{o}\\alpha \\alpha}\\)’s. \nTarski (1923) noted that in the context of higher-order logic, one can\ndefine propositional connectives in terms of logical equivalence and\nquantifiers. Quine (1956) showed how both quantifiers and connectives\ncan be defined in terms of equality and the abstraction operator\nλ in the context of Church’s type theory. Henkin (1963)\nrediscovered these definitions, and developed a formulation of\nChurch’s type theory based on equality in which he restricted\nattention to propositional types. Andrews (1963) simplified the axioms\nfor this system. \n\\(\\cQ_0\\) is based on these ideas, and can be shown to be equivalent\nto a formulation of Church’s type theory using Axioms\n(1)–(8) of the preceding sections. This section thus provides an\nalternative to the material in the preceding Sections\n1.2.1–1.3.4. More details about \\(\\cQ_0\\) can be found in\nAndrews 2002. \n\\(T_{{o}}\\) denotes truth. The meaning of \\(\\Pi_{{o}({o}\\alpha)}\\)\nwas discussed in\n Section 1.1.\n To see that this definition of \\(\\Pi_{{o}({o}\\alpha)}\\) is\nappropriate, note that \\(\\lambda x_{\\alpha}T\\) denotes the set of all\nelements of type α, and that\n\\(\\Pi_{{o}({o}\\alpha)}s_{{o}\\alpha}\\) stands for\n\\(\\sfQ_{{o}({o}\\alpha)({o}\\alpha)}[\\lambda x_{\\alpha}T]\ns_{{o}\\alpha}\\), respectively for \\([\\lambda x_{\\alpha}T] =\ns_{{o}\\alpha}\\). Therefore \\(\\Pi_{{o}({o}\\alpha)}s_{{o}\\alpha}\\)\nasserts that \\(s_{{o}\\alpha}\\) is the set of all elements of type\nα, so \\(s_{{o}\\alpha}\\) contains all elements of type α.\nIt can be seen that \\(F_{{o}}\\) can also be written as \\(\\forall\nx_{{o}}x_{{o}}\\), which asserts that everything is true. This is\nfalse, so \\(F_{{o}}\\) denotes falsehood. The expression \\(\\lambda\ng_{{o}{o}{o}}[g_{{o}{o}{o}}x_{{o}}y_{{o}}]\\) can be used to represent\nthe ordered pair \\(\\langle x_{{o}},y_{{o}}\\rangle\\), and the\nconjunction \\(x_{{o}} \\land y_{{o}}\\) is true iff \\(x_{{o}}\\) and\n\\(y_{{o}}\\) are both true, i.e., iff \\(\\langle T_{{o}},T_{{o}}\\rangle\n= \\langle x_{{o}},y_{{o}}\\rangle\\). Hence \\(x_{{o}} \\land y_{{o}}\\)\ncan be expressed by the formula \\([\\lambda\ng_{{o}{o}{o}}[g_{{o}{o}{o}}T_{{o}}T_{{o}}]] = [\\lambda\ng_{{o}{o}{o}}[g_{{o}{o}{o}}x_{{o}}y_{{o}}]]\\). \nOther propositional connectives and the existential quantifier are\neasily defined. By using \\(\\iota_{(\\imath({o}\\imath))}\\), one can\ndefine description operators \\(\\iota_{\\alpha({o}\\alpha)}\\) for all\ntypes α. \n\\(\\cQ_0\\) has a single rule of inference. \nRule R: From \\(\\bC\\) and \\(\\bA_{\\alpha} =\n\\bB_{\\alpha}\\), to infer the result of replacing one occurrence of\n\\(\\bA_{\\alpha}\\) in \\(\\bC\\) by an occurrence of \\(\\bB_{\\alpha}\\),\nprovided that the occurrence of \\(\\bA_{\\alpha}\\) in \\(\\bC\\) is not (an\noccurrence of a variable) immediately preceded by λ. \nThe axioms for \\(\\cQ_0\\) are the following: \nIt is natural to compare the semantics of type theory with the\nsemantics of first-order logic, where the theorems are precisely the\nwffs which are valid in all interpretations. From an intuitive point\nof view, the natural interpretations of type theory are standard\nmodels, which are defined below. However, it is a consequence of\nGödel’s Incompleteness Theorem (Gödel 1931) that\naxioms (1)–(9) do not suffice to derive all wffs which are valid in\nall standard models, and there is no consistent recursively\naxiomatized extension of these axioms which suffices for this purpose.\nNevertheless, experience shows that these axioms are sufficient for\nmost purposes, and Leon Henkin considered the problem of clarifying in\nwhat sense they are complete. The definitions and theorem below\nconstitute Henkin’s (1950) solution to this problem, which is\noften referred to as general semantics or Henkin\nsemantics. \nA frame is a collection \\(\\{\\cD_{\\alpha}\\}_{\\alpha}\\) of\nnonempty domains (sets) \\(\\cD_{\\alpha}\\), one for each type symbol\nα, such that \\(\\cD_{{o}} = \\{\\sfT,\\sfF\\}\\) (where \\(\\sfT\\)\nrepresents truth and \\(\\sfF\\) represents falsehood), and \\(\\cD_{\\alpha\n\\beta}\\) is some collection of functions mapping \\(\\cD_{\\beta}\\) into\n\\(\\cD_{\\alpha}\\). The members of \\(\\cD_{\\imath}\\) are called\nindividuals. \nAn interpretation \\(\\langle \\{\\cD_{\\alpha}\\}_{\\alpha},\n\\frI\\rangle\\) consists of a frame and a function \\(\\frI\\) which maps\neach constant C of type α to an appropriate element of\n\\(\\cD_{\\alpha}\\), which is called the denotation of C.\nThe logical constants are given their standard denotations. \nAn assignment of values in the frame\n\\(\\{\\cD_{\\alpha}\\}_{\\alpha}\\) to variables is a function \\(\\phi\\) such\nthat \\(\\phi \\bx_{\\alpha} \\in \\cD_{\\alpha}\\) for each variable\n\\(\\bx_{\\alpha}\\). (Notation: The assignment \\(\\phi[a/x]\\) maps\nvariable x to value a and it is identical with \\(\\phi\\)\nfor all other variable symbols different from x.) \nAn interpretation \\(\\cM = \\langle \\{\\cD_{\\alpha}\\}_{\\alpha},\n\\frI\\rangle\\) is a general model (aka Henkin model)\niff there is a binary function \\(\\cV\\) such that\n\\(\\cV_{\\phi}\\bA_{\\alpha} \\in \\cD_{\\alpha}\\) for each assignment\n\\(\\phi\\) and wff \\(\\bA_{\\alpha}\\), and the following conditions are\nsatisfied for all assignments and all wffs: \nIf an interpretation \\(\\cM\\) is a general model, the function \\(\\cV\\)\nis uniquely determined. \\(\\cV_{\\phi}\\bA_{\\alpha}\\) is called the\nvalue of \\(\\bA_{\\alpha}\\) in \\(\\cM\\) with respect to\n\\(\\phi\\). \nOne can easily show that the following statements hold in all general\nmodels \\(\\cM\\) for all assignments \\(\\phi\\) and all wffs \\(\\bA\\) and\n\\(\\bB\\): \nThe semantics of general models is thus as expected. However, there is\na subtlety to note regarding the following condition for arbitrary\ntypes α: \nWhen the definitions of\n Section 1.2.1\n are employed, where equality has been defined in terms of\nLeibniz’ principle, then this statement is not implied for all\ntypes α. It only holds if we additionally require that the\ndomains \\(\\cD_{{o}\\alpha}\\) contain all the unit sets of objects of\ntype α, or, alternatively, that the domains\n\\(\\cD_{{o}\\alpha\\alpha}\\) contain the respective identity relations on\nobjects of type α (which entails the former). The need for this\nadditional requirement, which is not included in the original work of\nHenkin (1950), has been demonstrated in Andrews 1972a. \nWhen instead the alternative definitions of\n Section 1.4\n are employed, then this requirement is obviously met due to the\npresence of the logical constants \\(\\sfQ_{{o}\\alpha \\alpha}\\) in the\nsignature, which by definition denote the respective identity\nrelations on the objects of type α and therefore trivially\nensure their existence in each general model \\(\\cM\\). It is therefore\na natural option to always assume primitive equality constants (for\neach type α) in a concrete choice of base system for\nChurch’s type theory, just as realized in Andrews’ system\n\\(\\cQ_0\\). \nAn interpretation \\(\\langle \\{\\cD_{\\alpha}\\}_{\\alpha}, \\frI\\rangle\\)\nis a standard model iff for all α and \\(\\beta ,\n\\cD_{\\alpha \\beta}\\) is the set of all functions from \\(\\cD_{\\beta}\\)\ninto \\(\\cD_{\\alpha}\\). Clearly a standard model is a general\nmodel. \nWe say that a wff \\(\\bA\\) is valid in a model \\(\\cM\\) iff\n\\(\\cV_{\\phi}\\bA = \\sfT\\) for every assignment \\(\\phi\\) into \\(\\cM\\). A\nmodel for a set \\(\\cH\\) of wffs is a model in which each wff of\n\\(\\cH\\) is valid. \nA wff \\(\\bA\\) is valid in the general [standard]\nsense iff \\(\\bA\\) is valid in every general [standard] model.\nClearly a wff which is valid in the general sense is valid in the\nstandard sense, but the converse of this statement is false. \nCompleteness and Soundness Theorem (Henkin 1950):\nA wff is a theorem if and only if it is valid in the general\nsense. \nNot all frames belong to interpretations, and not all interpretations\nare general models. In order to be a general model, an interpretation\nmust have a frame satisfying certain closure conditions which are\ndiscussed further in Andrews 1972b. Basically, in a general model\nevery wff must have a value with respect to each assignment. \nA model is said to be finite iff its domain of individuals is\nfinite. Every finite model for \\(\\cQ_0\\) is standard (Andrews 2002,\nTheorem 5404), but every set of sentences of \\(\\cQ_0\\) which has\ninfinite models also has nonstandard models (Andrews2002, Theorem\n5506). \nAn understanding of the distinction between standard and nonstandard\nmodels can clarify many phenomena. For example, it can be shown that\nthere is a model \\(\\cM = \\langle \\{\\cD_{\\alpha}\\}_{\\alpha},\n\\frI\\rangle\\) in which \\(\\cD_{\\imath}\\) is infinite, and all the\ndomains \\(\\cD_{\\alpha}\\) are countable. Thus \\(\\cD_{\\imath}\\) and\n\\(\\cD_{{o}\\imath}\\) are both countably infinite, so there must be a\nbijection h between them. However, Cantor’s Theorem\n(which is provable in type theory and therefore valid in all models)\nsays that \\(\\cD_{\\imath}\\) has more subsets than members. This\nseemingly paradoxical situation is called Skolem’s Paradox. It\ncan be resolved by looking carefully at Cantor’s Theorem, i.e.,\n\\(\\nsim \\exists g_{{o}\\imath\\imath}\\forall f_{{o}\\imath}\\exists\nj_{\\imath}[g_{{o}\\imath\\imath}j_{\\imath} = f_{{o}\\imath}]\\), and\nconsidering what it means in a model. The theorem says that there is\nno function \\(g \\in \\cD_{{o}\\imath\\imath}\\) from \\(\\cD_{\\imath}\\) into\n\\(\\cD_{{o}\\imath}\\) which has every set \\(f_{{o}\\imath} \\in\n\\cD_{{o}\\imath}\\) in its range. The usual interpretation of the\nstatement is that \\(\\cD_{{o}\\imath}\\) is bigger (in cardinality) than\n\\(\\cD_{\\imath}\\). However, what it actually means in this model is\nthat h cannot be in \\(\\cD_{{o}\\imath\\imath}\\). Of course,\n\\(\\cM\\) must be nonstandard. \nWhile the Axiom of Choice is presumably true in all standard models,\nthere is a nonstandard model for \\(\\cQ_0\\) in which AC\\(^{\\imath}\\) is\nfalse (Andrews 1972b). Thus, AC\\(^{\\imath}\\) is not provable in\n\\(\\cQ_0\\). \nThus far, investigations of model theory for Church’s type\ntheory have been far less extensive than for first-order logic.\nNevertheless, there has been some work on methods of constructing\nnonstandard models of type theory and models in which various forms of\nextensionality fail, models for theories with arbitrary (possibly\nincomplete) sets of logical constants, and on developing general\nmethods of establishing completeness of various systems of axioms with\nrespect to various classes of models. Relevant papers include Andrews\n1971, 1972a,b, and Henkin 1975. Further related work can be found in\nBenzmüller et al. 2004, Brown 2004, 2007, and Muskens 2007. \nThe first three rules of inference in\n Section 1.3.1\n are called rules of λ-conversion. If \\(\\bD\\) and\n\\(\\bE\\) are wffs, we write \\(\\bD \\conv \\bE\\) to indicate that \\(\\bD\\)\ncan be converted to \\(\\bE\\) by applications of these rules. This is an\nequivalence relation between wffs. A wff \\(\\bD\\) is in\nβ-normal form iff it has no well-formed parts of the\nform \\([[\\lambda \\bx_{\\alpha}\\bB_{\\beta}]\\bA_{\\alpha}]\\). Every wff is\nconvertible to one in β-normal form. Indeed, every sequence of\ncontractions (applications of rule 2, combined as necessary with\nalphabetic changes of bound variables) of a wff is finite; obviously,\nif such a sequence cannot be extended, it terminates with a wff in\nβ-normal form. (This is called the strong normalization theorem.)\nBy the Church-Rosser Theorem, this wff in β-normal form is unique\nmodulo alphabetic changes of bound variables. For each wff \\(\\bA\\) we\ndenote by \\({\\downarrow}\\bA\\) the first wff (in some enumeration) in\nβ-normal form such that \\(\\bA \\conv {\\downarrow} \\bA\\). Then \\(\\bD\n\\conv \\bE\\) if and only if \\({\\downarrow} \\bD = {\\downarrow} \\bE\\). \nBy using the Axiom of Extensionality one can obtain the following\nderived rule of inference: \n\\(\\eta\\)-Contraction. Replace a well-formed part \\([\\lambda\n\\by_{\\beta}[\\bB_{\\alpha \\beta}\\by_{\\beta}]]\\) of a wff by\n\\(\\bB_{\\alpha \\beta}\\), provided \\(\\by_{\\beta}\\) does not occur free\nin \\(\\bB_{\\alpha \\beta}\\). \nThis rule and its inverse (which is called\n\\(\\eta\\)-Expansion) are sometimes used as additional rules of\nλ-conversion. See Church 1941, Stenlund 1972, Barendregt 1984,\nand Barendregt et al. 2013 for more information about\nλ-conversion. \nIt is worth mentioning (again) that λ-abstraction replaces the\nneed for comprehension axioms in Church’s type theory. \nThe challenges in higher-order unification are outlined very briefly.\nMore details on the topic are given in Dowek 2001; its utilization in\nhigher-order theorem provers is also discussed in Benzmüller\n& Miller 2014. \nDefinition. A higher-order unifier for a\npair \\(\\langle \\bA,\\bB\\rangle\\) of wffs is a substitution \\(\\theta\\)\nfor free occurrences of variables such that \\(\\theta \\bA\\) and\n\\(\\theta \\bB\\) have the same β-normal form. A higher-order\nunifier for a set of pairs of wffs is a unifier for each of the pairs\nin the set. \nHigher-order unification differs from first-order unification (Baader\n& Snyder 2001) in a number of important respects. In\nparticular: \nHowever, an algorithm has been devised (Huet 1975, Jensen &\nPietrzykowski 1976), called pre-unification, which will find\na unifier for a set of pairs of wffs if one exists. The pre-unifiers\ncomputed by Huet’s procedure are substitutions that can reduce\nthe original unification problem to one involving only so called\nflex-flex unification pairs. Flex-flex pairs have variable\nhead symbols in both terms to be unified and they are known to always\nhave a solution. The concrete computation of these solutions can thus\nbe postponed or omitted. Pre-unification is utilized in all the\nresolution based theorem provers mentioned in\n Section 4.\n  \nPattern unification refers a small subset of unification\nproblems, first studied by Miller 1991, whose identification has been\nimportant for the construction of practical systems. In a pattern\nunification problem every occurrence of an existentially quantified\nvariable is applied to a list of arguments that are all distinct\nvariables bound by either a λ-binder or a universal quantifier\nin the scope of the existential quantifier. Thus, existentially\nquantified variables cannot be applied to general terms but a very\nrestricted set of bound variables. Pattern unification, like\nfirst-order unification, is decidable and most general unifiers exist\nfor solvable problems. This is why pattern unification is preferably\nemployed (when applicable) in some state-of-the-art theorem provers\nfor Church’s type theory.  \nThe Unifying Principle was introduced in Smullyan 1963 (see\nalso Smullyan 1995) as a tool for deriving a number of basic\nmetatheorems about first-order logic in a uniform way. The principle\nwas extended to elementary type theory by Andrews (1971) and to\nextensional type theory, that is, Henkin’s general semantics\nwithout description or choice, by Benzmüller, Brown and Kohlhase\n(2004). We outline these extensions in some more detail below. \nThe Unifying Principle was extended to elementary type theory (the\nsystem \\(\\cT\\) of\n Section 1.3.2)\n in Andrews 1971 by applying ideas in Takahashi 1967. This Unifying\nPrinciple for \\(\\cT\\) has been used to establish cut-elimination for\n\\(\\cT\\) in Andrews 1971 and completeness proofs for various systems of\ntype theory in Huet 1973a, Kohlhase 1995, and Miller 1983. We first\ngive a definition and then state the principle. \nDefinition. A property \\(\\Gamma\\) of finite sets of\nwffs\\(_{{o}}\\) is an abstract consistency property iff for\nall finite sets \\(\\cS\\) of wffs\\(_{{o}}\\), the following properties\nhold (for all wffs A, B): \nNote that consistency is an abstract consistency\nproperty. \nUnifying Principle for \\(\\cT\\). If \\(\\Gamma\\) is an\nabstract consistency property and \\(\\Gamma(\\cS)\\), then \\(\\cS\\) is\nconsistent in \\(\\cT\\). \nHere is a typical application of the Unifying Principle. Suppose there\nis a procedure \\(\\cM\\) which can be used to refute sets of sentences,\nand we wish to show it is complete for \\(\\cT\\). For any set of\nsentences, let \\(\\Gamma(\\cS)\\) mean that \\(\\cS\\) is not refutable by\n\\(\\cM\\), and show that \\(\\Gamma\\) is an abstract consistency property.\nNow suppose that \\(\\bA\\) is a theorem of \\(\\cT\\). Then \\(\\{\\nsim\n\\bA\\}\\) is inconsistent in \\(\\cT\\), so by the Unifying Principle not\n\\(\\Gamma(\\{\\nsim \\bA\\})\\), so \\(\\{\\nsim \\bA\\}\\) is refutable by\n\\(\\cM\\). \nExtensions of the above Unifying principle towards Church’s type\ntheory with general semantics were studied since the mid nineties. A\nprimary motivation was to support (refutational) completeness\ninvestigations for the proof calculi underlying the emerging\nhigher-order automated theorem provers (see\n Section 4\n below). The initial interest was on a fragment of Church’s type\ntheory, called extensional type theory, that includes the\nextensionality axioms, but excludes \\(\\iota_{(\\alpha({o}\\alpha))}\\)\nand the axioms for it (description and choice were largely neglected\nin the automated theorem provers at the time). Analogous to before, a\ndistinction has been made between extensional type theory with\ndefined equality (as in\n Section 1.2.1,\n where equality is defined via Leibniz’ principle) and\nextensional type theory with primitive equality (e.g., system\n\\(\\cQ_0\\) as in\n Section 1.4,\n or, alternatively, a system based on logical constants\n\\(\\nsim_{({o}{o})}, \\lor_{(({o}{o}){o})}\\), and the\n\\(\\Pi_{({o}({o}\\alpha))}\\)’s as in\n Section 1.2.1,\n but with additional primitive logical constants\n\\(=_{{o}\\alpha\\alpha}\\) added). \nA first attempt towards a Unifying Principle for extensional type\ntheory with primitive equality is presented in Kohlhase 1993. The\nconditions given there, which are still\n incomplete[1],\n were subsequently modified and complemented as follows: \nTo obtain a Unifying Principle for extensional type theory with\ndefined equality, Benzmüller & Kohlhase 1997 added the\nfollowing conditions for boolean extensionality, functional\nextensionality and saturation to the above conditions 1.-7. for\n\\(\\cT\\) (their presentation has been adapted here; for technical reasons,\nthey also employ a slightly stronger variant for condition 2. based on\nβ-conversion rather than β-normalization): \nThe saturation condition 10. was required to properly establish the\nprinciple. However, since this condition is related to the proof\ntheoretic notion of cut-elimination, it limits the utility of the\nprinciple in completeness proofs for machine-oriented calculi. The\nprinciple was nevertheless used in Benzmüller & Kohlhase\n1998a and Benzmüller 1999a,b to obtain a completeness proof for a\nsystem of extensional higher-order resolution. The principle was also\napplied in Kohlhase 1998 to study completeness for a related\nextensional higher-order tableau\n calculus,[2]\n in which the extensionality rules for Leibniz equality were adapted\nfrom Benzmüller & Kohlhase 1998a, respectively\nBenzmüller 1997. \nDifferent options for achieving a Unifying Principle for extensional\ntype theory with primitive equality are presented in Benzmüller\n1999a (in this work primitive logical constants\n\\(=_{{o}\\alpha\\alpha}\\) were used in addition to \\(\\nsim_{({o}{o})},\n\\lor_{(({o}{o}){o})}\\), and the \\(\\Pi_{({o}({o}\\alpha))}\\)’s;\nsuch a redundant choice of logical constants is not rare in\nhigher-order theorem provers). One option is to introduce a\nreflexivity and substitutivity condition. An alternative is to combine\na reflexivity condition with a condition connecting primitive with\ndefined equality, so that the substitutivity condition follows. Note\nthat introducing a defined notion of equality based on the Leibniz\nprinciple is, of course, still possible in this context (defined\nequality is denoted in the remainder of this section by \\(\\doteq\\) to\nproperly distinguish it from primitive equality \\(=\\)): \nThe saturation condition 10. still has to be added independent of\nwhich option is considered. The principle was applied in\nBenzmüller 1999a,b to\nprove completeness for the extensional higher-order\n RUE-resolution[3]\n calculus underlying the higher-order automated theorem prover LEO and\nits successor LEO-II. \nIn Benzmüller et al. 2004 the principle is presented in a very\ngeneral way which allows for various possibilities concerning the\ntreatment of extensionality and equality in the range between\nelementary type theory and extensional type theory. The principle is\napplied to obtain completeness proofs for an associated range of\nnatural deduction calculi. The saturation condition is still used in\nthis work. \nBased on insights from Brown’s (2004, 2007) thesis, a solution\nfor replacing the undesirable saturation condition by two weaker\nconditions is presented in Benzmüller, Brown, and Kohlhase 2009;\nthis work also further studies the relation between saturation and\ncut-elimination. The two weaker conditions, termed mating and\ndecomposition, are easier to demonstrate than saturation in\ncompleteness proofs for machine-oriented calculi. They are (omitting\nsome type information in the second one and abusing notation): \nThe modified principle is applied in Benzmüller et al. 2009 to\nshow completeness for a sequent calculus for extensional type theory\nwith defined equality. \nA further extended Unifying Principle for extensional type theory with\nprimitive equality is presented and used in Backes & Brown 2011 to\nprove the completeness of a tableau calculus for type theory which\nincorporates the axiom of choice. \nA closely related and further simplified principle has also been\npresented and studied in Steen 2018, where it was applied for showing\ncompleteness of the paramodulation calculus (Steen 2018) that is\nunderlying the theorem prover Leo-III (Steen & Benzmüller\n2018). \nCut-elimination proofs (see also the SEP entry on\n proof theory)\n for Church’s type theory, which are often closely related to\nsuch proofs (Takahashi 1967, 1970; Prawitz 1968; Mints 1999) for other\nformulations of type theory, may be found in Andrews 1971, Dowek &\nWerner 2003, and Brown 2004. In Benzmüller et al. 2009 it is\nshown how certain wffs\\(_{{o}}\\), such as axioms of extensionality,\ndescriptions, choice (see\n Sections 1.3.3\n to\n 1.3.5),\n and induction, can be used to justify cuts in cut-free sequent\ncalculi for elementary type theory. Moreover, the notions of\ncut-simulation and cut-strong axioms are introduced\nin this work, and the need for omitting defined equality and for\neliminating cut-strong axioms such as extensionality,\ndescription, choice and induction in machine-oriented calculi (e.g.,\nby replacing them with more constrained, goal-directed rules) in order\nto reduce cut-simulation effects are discussed as a major\nchallenge for higher-order automated theorem proving. In other words,\nincluding cut-strong axioms in a machine-oriented proof calculus for\nChurch’s type theory is essentially as bad as including a cut\nrule, since the cut rule can be mimicked by them. \nAn expansion proof is a generalization of the notion of a\nHerbrand expansion of a theorem of first-order logic; it provides a\nvery elegant, concise, and nonredundant representation of the\nrelationship between the theorem and a tautology which can be obtained\nfrom it by appropriate instantiations of quantifiers and which\nunderlies various proofs of the theorem. Miller (1987) proved that a\nwff \\(\\bA\\) is a theorem of elementary type theory if and only if\n\\(\\bA\\) has an expansion proof. \nIn Brown 2004 and 2007, this concept is generalized to that of an\nextensional expansion proof to obtain an analogous theorem\ninvolving type theory with extensionality. \nSince type theory includes first-order logic, it is no surprise that\nmost systems of type theory are undecidable. However, one may look for\nsolvable special cases of the decision problem. For example, the\nsystem \\(\\cQ_{0}^1\\) obtained by adding to \\(\\cQ_0\\) the additional\naxiom \\(\\forall x_{\\imath}\\forall y_{\\imath}[x_{\\imath}=y_{\\imath}]\\)\nis decidable. \nAlthough the system \\(\\cT\\) of elementary type theory is analogous to\nfirst-order logic in certain respects, it is a considerably more\ncomplex language, and special cases of the decision problem for\nprovability in \\(\\cT\\) seem rather intractable for the most part.\nInformation about some very special cases of this decision problem may\nbe found in Andrews 1974, and we now summarize this. \nA wff of the form \\(\\exists \\bx^1 \\ldots \\exists \\bx^n [\\bA=\\bB]\\) is\na theorem of \\(\\cT\\) iff there is a substitution \\(\\theta\\) such that\n\\(\\theta \\bA \\conv \\theta \\bB\\). In particular, \\(\\vdash \\bA=\\bB\\) iff\n\\(\\bA \\conv \\bB\\), which solves the decision problem for wffs of the\nform \\([\\bA=\\bB]\\). Naturally, the circumstance that only trivial\nequality formulas are provable in \\(\\cT\\) changes drastically when\naxioms of extensionality are added to \\(\\cT\\). \\(\\vdash \\exists\n\\bx_{\\beta}[\\bA=\\bB]\\) iff there is a wff \\(\\bE_{\\beta}\\) such that\n\\(\\vdash[\\lambda \\bx_{\\beta}[\\bA=\\bB]]\\bE_{\\beta}\\), but the decision\nproblem for the class of wffs of the form \\(\\exists\n\\bx_{\\beta}[\\bA=\\bB]\\) is unsolvable. \nA wff of the form \\(\\forall \\bx^1 \\ldots \\forall \\bx^n\\bC\\), where\n\\(\\bC\\) is quantifier-free, is provable in \\(\\cT\\) iff \\({\\downarrow}\n\\bC\\) is tautologous. On the other hand, the decision problem for wffs\nof the form \\(\\exists \\bz\\bC\\), where \\(\\bC\\) is quantifier-free, is\nunsolvable. (By contrast, the corresponding decision problem in\nfirst-order logic with function symbols is known to be solvable\n(Maslov 1967).) Since irrelevant or vacuous quantifiers can always be\nintroduced, this shows that the only solvable classes of wffs of\n\\(\\cT\\) in prenex normal form defined solely by the structure of the\nprefix are those in which no existential quantifiers occur. \nThe development, respectively improvement, of machine-oriented proof\ncalculi for Church’s type theory is still a challenge research\ntopic. Compared, e.g., to the theoretical and practical maturity\nachieved in first-order automated theorem proving, the area is still\nin its infancy. Obviously, the challenges are also much bigger than in\nfirst-order logic. The practically way more expressive nature of the\nterm-language of Church’s type theory causes a larger, bushier\nand more difficult to traverse proof search space than in first-order\nlogic. Moreover, remember that unification, which constitutes a very\nimportant control and filter mechanism in first-order theorem proving,\nis undecidable (in general) in type theory; see\n Section 3.2.\n On the positive side, however, there is a chance to find\nsignificantly shorter proofs than in first-order logic. This is well\nillustrated with a small, concrete example in Boolos 1987. Clearly,\nmuch further progress is needed to further leverage the practical\nrelevance of existing calculi for Church’s type theory and their\nimplementations (see\n Section 4.3).\n The challenges include \nIt is planned that future editions of this article further elaborate\non machine-oriented proof calculi for Church’s type theory. For\nthe time being, however, we provide only a selection of historical and\nmore recent references for the interested reader (see also\n Section 5 below): \nEarly computer systems for proving theorems of Church’s type\ntheory (or extensions of it) include HOL (Gordon 1988; Gordon &\nMelham 1993), TPS (Andrews et al. 1996; Andrews & Brown 2006),\nIsabelle (Paulson 1988, 1990), PVS (Owre et al. 1996; Shankar 2001),\nIMPS (Farmer et al. 1993), HOL\nLight (Harrison 1996), OMEGA (Siekmann et al. 2006), and λClam\n(Richardson et al. 1998). See\n Other Internet References\n section below for links to further info on these and other provers\nmentioned later.  \nThe majority of the above systems focused (at least initially) on\ninteractive proof and provided rather limited support for additional\nproof automation. Full proof automation was pioneered, in particular,\nby the TPS project. Progress was made in the nineties, when other\nprojects started similar activities, respectively, enforced theirs.\nHowever, the resource investments and achievements were lacking much\nbehind those seen in first-order theorem proving. Significant progress\nwas fostered only later, in particular, through the development of a\ncommonly supported syntax for Church’s type theory, called TPTP\nTHF (Sutcliffe & Benzmüller 2010), and the inclusion, from\n2009 onwards, of a TPTP THF division in the yearly CASC competitions\n(kind of world championships for automated theorem proving; see\nSutcliffe 2016 for further details). \nAn selection of theorem provers for Church’s type theory is\npresented. The focus is on systems that have successfully participated\nin TPTP THF CASC competitions in the past. The latest editions of most\nmentioned systems can be accessed online via the SystemOnTPTP\ninfrastructure (Sutcliffe 2017). Nearly all mentioned systems produce\nverifiable proof certificates in the TPTP TSTP syntax. Further details\non the automation of Church’s type theory are given in\nBenzmüller & Miller 2014. \nThe TPS prover (Andrews et al. 1996, Andrews & Brown 2006) can be\nused to prove theorems of elementary type theory or extensional type\ntheory automatically, interactively, or semi-automatically. When\nsearching for a proof automatically, TPS first searches for an\nexpansion proof (Miller 1987) or an extensional expansion proof (Brown\n2004, 2007) of the theorem. Part of this process involves searching\nfor acceptable matings (Andrews 1981, Bishop 1999). The behavior of\nTPS is controlled by sets of flags, also called modes. A simple\nscheduling mechanism is employed in the latest versions of TPS to\nsequentially run a about fifty modes for a limited amount of time. TPS\nwas the winner of the first THF CASC competition in 2009. \nThe LEO-II prover (Benzmüller et al. 2015) is the successor of\nLEO (Benzmüller & Kohlhase 1998b, which was hardwired with\nthe OMEGA proof assistant (LEO stands for Logical Engine of OMEGA).\nThe provers are based on the RUE-resolution calculi developed in\nBenzmüller 1999a,b. LEO\nwas the first prover to implement calculus rules for extensionality to\navoid cut-simulation effects. LEO-II inherits and adapts them, and\nprovides additional calculus rules for description and choice. The\nprover, which internally collaborates with first-order provers\n(preferably E) and SAT solvers, has pioneered cooperative\nhigher-order/first-order proof automation. Since the prover is often\ntoo weak to find a refutation among the steadily growing set of\nclauses on its own, some of the clauses in LEO-II’s search space\nattain a special status: they are first-order clauses modulo the\napplication of an appropriate transformation function. Therefore,\nLEO-II progressively launches time limited calls with these clauses to\na first-order theorem prover, and when the first-order prover reports\na refutation, LEO-II also terminates. Parts of these ideas were\nalready implemented in the predecessor LEO. Communication between\nLEO-II and the cooperating first-order theorem provers uses the TPTP\nlanguage and standards. LEO-II was the winner of the second THF CASC\ncompetition in 2010. \nThe Satallax prover (Brown 2012) is based on a complete ground tableau\ncalculus for Church’s type theory with choice (Backes &\nBrown 2011). An initial tableau branch is formed from the assumptions\nof a conjecture and negation of its conclusion. From that point on,\nSatallax tries to determine unsatisfiability or satisfiability of this\nbranch. Satallax progressively generates higher-order formulas and\ncorresponding propositional clauses. Satallax uses the SAT solver\nMiniSat as an engine to test the current set of propositional clauses\nfor unsatisfiability. If the clauses are unsatisfiable, the original\nbranch is unsatisfiable. Satallax provides calculus rules for\nextensionality, description and choice. If there are no quantifiers at\nfunction types, the generation of higher-order formulas and\ncorresponding clauses may terminate. In that case, if MiniSat reports\nthe final set of clauses as satisfiable, then the original set of\nhigher-order formulas is satisfiable (by a standard model in which all\ntypes are interpreted as finite sets). Satallax was the winner of the\nTHF CASC competition in 2011 and since 2013.  \nThe Isabelle/HOL system (Nipkow, Wenzel, & Paulson 2002) has\noriginally been designed as an interactive prover. However, in order\nto ease user interaction several automatic proof tactics have been\nadded over the years. By appropriately scheduling a subset of these\nproof tactics, some of which are quite powerful, Isabelle/HOL has\nsince about 2011 been turned also into an automatic theorem prover for\nTPTP THF (and other TPTP syntax formats), that can be run from a\ncommand shell like other provers. The most powerful proof tactics that\nare scheduled by Isabelle/HOL include the Sledgehammer tool\n(Blanchette et al. 2013),\nwhich invokes a sequence of external first-order and higher-order\ntheorem provers, the model finder Nitpick (Blanchette &\nNipkow 2010), the equational reasoner simp, the untyped\ntableau prover blast, the simplifier and classical reasoners\nauto, force, and fast, and the best-first\nsearch procedure best. In contrast to all other automated\ntheorem provers mentioned above, the TPTP incarnation of Isabelle/HOL\ndoes not yet output proof certificates. Isabelle/HOL was the winner of\nthe THF CASC competition in 2012.  \nThe agsyHOL prover is based on a generic lazy narrowing proof search\nalgorithm. Backtracking is employed and a comparably small search\nstate is maintained. The prover outputs proof terms in sequent style\nwhich can be verified in the Agda system.  \ncoqATP implements (the non-inductive) part of the calculus of\nconstructions (Bertot & Castéran 2004). The system outputs\nproof terms which are accepted as proofs (after the addition of a few\ndefinitions) by the Coq proof assistant. The prover employs axioms for\nfunctional extensionality, choice, and excluded middle. Boolean\nextensionality is not supported. In addition to axioms, a small\nlibrary of basic lemmas is employed.  \nThe Leo-III prover implements a paramodulation calculus for\nChurch’s type theory (Steen 2018). The system, which is a\ndescendant of LEO and LEO-II, provides calculus rules for\nextensionality, description and choice. The system has put an emphasis\non the implementation of an efficient set of underlying data\nstructures, on simplification routines and on heuristic rewriting. In\nthe tradition of its predecessors, Leo-III cooperates with first-order\nreasoning tools using translations to many-sorted first-order logic.\nThe prover accepts every common TPTP syntax dialect and is thus very\nwidely applicable. Recently, the prover has also been extended to\nnatively supports almost every normal higher-order modal logic. \nZipperposition (Bentkamp et al. 2018) is new and inspiring\nhigher-order theorem prover which, at the current state of\ndevelopment, is still working for a comparably weak fragment of\nChurch’s type theory, called lambda-free higher-order\nlogic (a comprehension-free higher-order logic,\nwhich is nevertheless supporting λ-notation). The system, which\nis based on superposition calculi, is developed bottom up, and it is\nprogressively extended towards stronger fragments of Church’s\ntype theory and to support other relevant extensions such datatypes,\nrecursive functions and arithmetic.  \nVarious so called proof hammers, in the spirit of\nIsabelle’s Sledgehammer tool, have recently been developed and\nintegrated with modern proof assistants. Prominent examples include\nHOL(y)Hammer (Kaliszyk & Urban 2015) for HOL Light and a similar\nhammer (Czaika & Kaliszyk 2018) for the proof assistant Coq.  \nSupport for finding finite models or countermodels for formulas of\nChurch’s type theory was implemented already in the\ntableau-based prover HOT (Konrad 1998). Restricted (counter-)model\nfinding capabilities are also implemented in the provers Satallax,\nLEO-II and LEO-III. The most advanced (finite) model finding support\nis currently realized in the systems Nitpick, Nunchaku and Refute. These tools\nhave been integrated with the Isabelle proof assistant. Nitpick is\nalso available as a standalone tool that accepts TPTP THF syntax. The\nsystems are particularly valuable for exposing errors and\nmisconceptions in problem encodings, and for revealing bugs in the THF\ntheorem provers. \nChurch’s type theory plays an important role in the study of the\nformal semantics of natural language. Pioneering work on this was done\nby Richard Montague. See his papers “English as a formal\nlanguage”, “Universal grammar”, and “The\nproper treatment of quantification in ordinary English”, which\nare reprinted in Montague 1974. A crucial component of\nMontague’s analysis of natural language is the definition of a\ntensed intensional logic (Montague 1974: 256), which is an enhancement\nof Church’s type theory. Montague Grammar had a huge impact, and\nhas since been developed in many further directions, not least in\nTypelogical/Categorical Grammar. Further related work on intensional\nand higher-order modal logic is presented in Gallin 1975 and Muskens\n2006. \nProof assistants based on Church’s Type Theory, including\nIsabelle/HOL, HOL Light, HOL4, and PVS, have been successfully\nutilized in a broad range of application in computer science and\nmathematics. \nApplications in computer science include the verification of hardware,\nsoftware and security protocols. A prominent example is the\nL4.verified project in which Isabelle/HOL was used to formally prove\nthat the seL4 operating system kernel implements an abstract,\nmathematical model specifying of what the kernel is supposed to do\n(Klein et al. 2018).  \nIn mathematics proof assistants have been applied for the development\nof libraries mathematical theories and the verification of challenge\ntheorems. An early example is the mathematical library that was\ndeveloped since the eighties in the TPS project. A exemplary list of\ntheorems that were proved automatically with TPS is given in Andrews\net al. 1996. A very prominent recent example is Hales Flyspeck in\nwhich HOL Light was employed to develop a formal proof for\nKepler’s conjecture (Hales et al. 2017). An example that\nstrongly exploits automation support in Isabelle/HOL with Sledgehammer\nand Nitpick is presented in Benzmüller & Scott forthcoming.\nIn this work different axiom systems for category theory were explored\nand compared.  \nA solid overview on past and ongoing formalization projects can be\nobtained by consulting respective sources such as Isabelle’s\nArchive of Formal Proofs, the Journal of Formalized Reasoning, or the\nTHF entries in Sutcliffe’s TPTP problem library.  \nFurther improving proof automation within these proof\nassistants—based on proof hammering tools or on other forms of\nprover integration—is relevant for minimizing interaction effort\nin future applications.  \nChurch’s type theory is a Classical logic, but topical\napplications in philosophy and artificial intelligence often require\nexpressive non-classical logics. In order to support such applications\nwith reasoning tools for Church’s type theory, the shallow\nsemantical embedding technique (see also\n Section 1.2.2)\n has been developed that generalizes and extends the ideas underlying\nthe well known standard translation of modal logics to first-order\nlogic. The technique was applied for the assessment of modern variants\nof the ontological argument with a range of higher-order theorem\nprovers, including LEO-II, Satallax, Nitpick and Isabelle/HOL. In the\ncourse of experiments, LEO-II detected an inconsistency in the\npremises of Gödel’s argument, while the provers succeeded\nin automatically proving Scott’s emendation of it and to confirm\nthe consistency of the emended premises. More details on this work are\npresented in a related SEP entry on\n automated reasoning\n (see Section 4.6 on Logic and Philosophy). The semantical embedding\napproach has been adapted and further extended for a range of other\nnon-classical logics and related applications. In philosophy this\nincludes the encoding and formal assessment of ambitious ethical and\nmetaphysical theories, and in artificial intelligence this includes\nthe mechanization of deontic logics and normative reasoning as well as\nan automatic proof of the\n muddy children puzzle (see Appendix B of dynamic epistemic logic),\n which is a famous puzzle in epistemic reasoning, respectively dynamic\nepistemic reasoning.","contact.mail":"c.benzmueller@fu-berlin.de","contact.domain":"fu-berlin.de"}]
