[{"date.published":"2007-10-15","date.changed":"2020-10-20","url":"https://plato.stanford.edu/entries/dynamic-choice/","author1":"Chrisoula Andreou","entry":"dynamic-choice","body.text":"\n\n\nSometimes a series of choices do not serve one’s concerns well\neven though each choice in the series seems perfectly well suited to\nserving one’s concerns. In such cases, one has a dynamic choice\nproblem. Otherwise put, one has a problem related to the fact that\none’s choices are spread out over time. There is a growing\nphilosophical literature, which crosses over into psychology and\neconomics, on the obstacles to effective dynamic choice. This\nliterature examines the challenging choice situations and problematic\npreference structures that can prompt dynamic choice problems. It also\nproposes solutions to such problems. Increasingly, familiar but\npotentially puzzling phenomena—including, for example,\nself-destructive addictive behavior and dangerous environmental\ndestruction—have been illuminated by dynamic choice theory. This\nsuggests that the philosophical and practical significance of dynamic\nchoice theory is quite broad.\n\nEffective choice over time can be extremely difficult given certain\nchallenging choice situations or problematic preference structures,\nsuch as the ones described below. As will become apparent, these\nchoice situations or preference structures can prompt a series of\ndecisions that serve one’s large-scale, ongoing concerns very\nbadly. (Note that, as is standard in dynamic choice theory, the\ndiscussion in this entry leaves room for non-selfish preferences and\nconcerns; it thus leaves room for the possibility that one can be\ndetermined to serve one’s preferences and concerns as well as\npossible without being an egoist.) \nLet us first consider situations that involve choosing between\nincommensurable alternatives. \nAccording to the standard conception of incommensurability explored\nextensively by philosophers such as Joseph Raz and John Broome (see,\nfor example, Raz 1986 and Broome 2000), two alternatives are\nincommensurable if neither alternative is better than the other, nor\nare the two alternatives equally good. \nIt might seem as though the idea of incommensurable alternatives does\nnot really make sense. For if the value of an alternative (to a\nparticular agent) is neither higher nor lower than the value of\nanother alternative, then the values of the two alternatives must, it\nseems, be equal. But this assumes that there is a common measure that\none can use to express and rank the value of every alternative; and,\nif there are incommensurable alternatives, then this assumption is\nmistaken. \nNow consider the following: If all alternatives were commensurable,\nthen whenever one faced two alternatives neither of which was better\nthan the other, slightly improving one of the alternatives would, it\nseems, ‘break the tie’ and render one alternative, namely\nthe improved alternative, superior. But there seem to be cases in\nwhich there are two alternatives such that (i) neither alternative is\nbetter than the other and (ii) this feature is not changed by slightly\nimproving one of the alternatives. Consider, for example, the\nfollowing case: For Kay, neither of the following alternatives is\nbetter than the other: \n(A1) going on a six-day beach vacation with her children \n(A2) taking a two-month oil-painting course. \nFurthermore, although the alternative \nis a slight improvement on A1, A1+ is not better than A2.\nThis scenario seems possible, and if it is, then we have a case of\nincommensurable alternatives. For, in this case, A1 is not better than\nA2, A2 is not better than A1, and yet A1 and A2 are not equally good.\nIf A1 and A2 were equally good, then an improvement on A1, such as\nA1+, would be better than A2. But, for Kay, A1+\nis not better than A2. \nIt is often supposed that incommensurable alternatives must be\nincomparable. But things are complicated once it is recognized that\nthere is conceptual room for two alternatives that are not comparable\nas one better than the other or as equally good (and so are\nincommensurable according the conception of incommensurability\nidentified above) to be comparable as ‘in the same league’\nor ‘on a par,’ and thus not altogether incomparable, as\nwould be the case if there were no positive relation connecting the\noverall value of each option (see Chang 2002). For the purposes of\nthis discussion, the question of whether incommensurable alternatives\nare invariably incomparable can be put aside, since the dynamic choice\nproblem that will be discussed in relation to incommensurability\napplies regardless of whether the incommensurable options at issue are\nincomparable or are instead comparable as on a par. \nAlthough there is still some controversy concerning the possibility of\nincommensurable alternatives (compare, for example, Raz 1997 and Regan\n1997), there is widespread agreement that we often treat\nalternatives as incommensurable. Practically speaking, determining the\nvalue of two very different alternatives in terms of a common measure,\neven if this is possible, may be too taxing. It is thus often natural\nto treat two alternatives as though they are neither equal nor one\nbetter than the other. \nThe existence or appearance of incommensurable alternatives can give\nrise to dynamic choice problems. Consider Abraham’s case, as\ndescribed by John Broome in his work on incommensurability: \nGiven that the options of submitting to God and saving Isaac are\nincommensurable (and even if they were only incommensurable as far as\na reasonable person could tell), Abraham’s deciding to submit to\nGod seems rationally permissible. So it is easy to see how\nAbraham’s situation might prompt him to set out for the mountain\nin order to sacrifice Isaac. But it is also easy to see how, once at\nthe foot of the mountain, Abraham might decide to turn back. For, even\nthough, as Broome puts it, “turning back at the foot of the\nmountain is definitely worse than never having set out at all”\nsince “trust between father and son [has already been] badly\ndamaged” (2001, 115), the option of saving Isaac by turning back\nand the option of submitting to God and sacrificing Isaac may be\nincommensurable. This becomes apparent if one recalls Kay’s case\nand labels Abraham’s above-mentioned options as follows: \n(B1) saving Isaac by turning back at the foot of the mountain \n(B1+) saving Isaac by refusing to set out for the\nmountain \n(B2) submitting to God and sacrificing Isaac. \nEven though B1+ is better than B1, both B1+ and\nB1 may be incommensurable with B2. But if B1 is incommensurable with\nB2, then Abraham could, once at the foot of the mountain, easily\ndecide to opt for B1 over B2. Given that B1 is worse than\nB1+, Abraham could thus easily end up with an outcome that\nis worse than another that was available to him, even if each of his\nchoices makes sense given the value of the alternatives he faces. \nThe moral, in general terms, is that in cases of incommensurability\n(or cases in which it is tempting to treat two alternatives as\nincommensurable), decisions that seem individually defensible can,\nwhen combined, result in a series of decisions that fit together very\npoorly relative to the agent’s large-scale, ongoing\nconcerns. \nAnother source of dynamic choice problems is present-biased\npreferences. \nLike other animals, humans give more weight to present satisfaction\nthan to future satisfaction. In other words, we discount future\nutility. Insofar as one discounts future utility, one prefers, other\nthings equal, to get a reward sooner rather than later; relatedly, the\ncloser one gets to a future reward, the more the reward is valued. If\nwe map the value (to a particular agent) of a given future reward as a\nfunction of time, we get a discount curve, such as in Figure 1: \nFigure 1. The discounted value of a\nreward gradually increases as t, the time at which the reward\nwill be available, approaches. \nResearch in experimental psychology (see, for example, Kirby &\nHerrnstein 1995, Millar & Navarick 1984, Solnick et al. 1980, and\nAinslie 2001) suggests that, given how animals, including humans,\ndiscount future utility, there are plenty of cases in which the\ndiscount curves from two rewards, one a small reward and the other a\nlarger later reward, cross, as in Figure 2: \nFigure 2. Two crossing discount curves,\none tracking the discounted value of a small reward that will be\navailable at t1 and the other tracking the\ndiscounted value of a large reward that will be available at\nt2. \nIn such cases, the agent’s discounting of future utility induces\na preference reversal with respect to the two possible rewards. When\nneither reward is imminent, before the discount curves cross, the\nagent consistently prefers the larger later reward over the smaller\nearlier reward. But when the opportunity to accept the small reward is\nsufficiently close, the discounted value of the small reward catches\nup with and then overtakes the discounted value of the larger later\nreward. As the discount curves cross, the agent’s preferences\nreverse and she prefers the small reward over the larger later\nreward. \nDiscounting-induced preference reversals make consistent and efficient\nchoice over time a challenge. An agent subject to discounting-induced\npreference reversals can easily find herself performing a series of\nactions she planned against and will soon regret. Consider the agent\nwho wants to save for a decent retirement but, as each opportunity to\nsave approaches, prefers to spend her potential retirement\ncontribution on just one more trivial indulgence before finally\ntightening her belt for the sake of the future satisfaction she feels\nis essential to her well-being. Though this agent consistently plans\nto save for her retirement, her plans can be consistently thwarted by\nher discounting-induced preference reversals. Her life may thus end up\nlooking very different from the sort of life she wanted. \nInterestingly, in addition to giving more weight to present\nsatisfaction than to future satisfaction, human beings also seem to\ngive more weight to future satisfaction than to past satisfaction.\nRelatedly, human beings seem to discount past pain more than future\npain. Suppose, to appeal to a variation on Derek Parfit’s famous\nthought experiment (1984, 165–6), your situation is such that\neither you’ve already suffered a perfectly safe but terribly\npainful ten-hour medical procedure yesterday or else you will suffer a\nperfectly safe but terribly painful nine-hour medical procedure\ntomorrow. (You don’t know which situation you’re in\nbecause amnesia is administered right after the procedure and\nyou’ve just woken up in the hospital confused about whether\nyou’re recovering from the procedure or being prepped for it.)\nWouldn’t you prefer to be in the former situation? Intuitively,\nit seems like the prevailing and rational response would be\n“most definitely!” But there is some concern that this\nform of future bias, in which past rewards or costs are discounted\nmore than future rewards or costs, can lead to trouble (Dougherty\n2011; Greene and Sullivan 2015). For example, Preston Greene and\nMeghan Sullivan (2015) argue that it can be a recipe for a life of\n“meager returns” and/or regret. Their reasoning is quite\nelaborate, but the following simple illustration and somewhat\nextemporized analysis, will hopefully provide a glimpse into some of\nthe interesting philosophical issues at stake. Consider Massimo, who\nthoroughly enjoys massages and who can choose between a longer massage\nearly on or a shorter massage later. If Massimo is future biased,\nthen, with some variation on the length and timing of the massages, he\ncan easily find himself faced with the following dilemma: if he opts\nfor getting a longer massage early on, he will, sometime after getting\nthe longer massage and before the shorter massage would have been\navailable, regret accepting a pleasure, now past, that could have\nstill been in the future (even if diminished); if, alternatively, he\nopts for getting a shorter massage later on (thus avoiding regret of\nthe preceding sort), he will face a life of “meager\nreturns,” in which less pleasure later is, potentially\nroutinely, chosen over more pleasure earlier (a scenario that can\nitself generate regret and/or concern, particularly once both massage\ntimes are past, or if one recognizes, even as one is gladly awaiting a\nlesser pleasure after giving up a greater pleasure that would now have\nbeen in the past, that, insofar as the same sort of choice has arisen\nrepeatedly and will continue to arise repeatedly, repeated choices for\nless pleasure later make for a life that is both retrospectively and\nprospectively much less appealing than repeated choices for more\npleasure early on). \nAn agent’s preference structure need not be changing over time\nfor it to prompt dynamic choice problems. Such problems can also be\nprompted by preferences that are stable but intransitive. \nOne’s preferences count as transitive if they satisfy the\nfollowing condition: for all x, y, and z,\nif one prefers x to y, and y to z,\nthen one also prefers x to z. If one’s\npreferences over a set of options do not satisfy this condition, then\nthese preferences count as intransitive. When one’s preferences\nover a set of options are intransitive, then one cannot rank the\noptions from most preferred to least preferred. This holds even if\none’s preferences over the options are complete, in the sense\nthat all the options are ranked with respect to one another. Suppose,\nfor example, that one prefers job A to job B, job\nB to job C, but job C to job A. In\nthis case, one’s complete preferences over the set {job\nA, job B, job C} form a preference loop,\nwhich can be represented as follows: \nFigure 3. \nwhere x > y is to be read as x is\npreferred to y. \nCould an agent really have intransitive preferences? Work in\nexperimental and theoretical economics (see, for example, Tversky\n1969) suggests that intransitive preferences exist and may\nbe quite common. Consideration of the following situation might\nhelp make it clear how intransitive preferences can arise (whether or\nnot they are rational). Suppose Jay can accept one of three jobs: job\nA is very stimulating but low-paying; job B is\nsomewhat stimulating and pays decently; job C is not\nstimulating but pays very well. Given this situation, one can imagine\nJay having the following preferences: He prefers job A over\njob B because the difference between having a low-paying job\nand a decently-paying job is not significant enough to make Jay want\nto pass up a very stimulating job. Similarly, he prefers job\nB over job C because the difference between having a\ndecently-paying job and a high-paying job is not significant enough to\nmake Jay want to pass up a stimulating job. But he prefers job\nC over job A because the difference between having a\nhigh-paying job and a low-paying job is significant enough to make Jay\nwant to pass up even a very stimulating job. \nGiven the famous “money pump argument,” developed by\nDonald Davidson, J. McKinsey, and Patrick Suppes (1955), it is clear\nthat intransitive preferences can be problematic. Like Dutch book\narguments regarding betting, in which the rationality of an agent is\nput into question because the agent is susceptible to having a book\nmade against her (i.e., to accepting a series of bets which are such\nthat she is bound to lose more than she can gain), the money-pump\nargument is concerned with agents who are vulnerable to making a\ncombination of choices that lead to a sure loss. According to the\nmoney-pump argument, intransitive preferences are irrational because\nthey can prompt an agent to accept a series of trade offers that\nleaves the agent with the same option he began with, but with less\nmoney. Here is a case of the relevant sort. Suppose that Alex has the\nfollowing intransitive preferences: he prefers owning a computer of\ntype A to owning a computer of type B, owning a\ncomputer of type B to owning a computer of type C,\nand owning a computer of type C to owning a computer of type\nA. Suppose also that Alex owns a computer of type C\nand a hundred dollars in spending money. Suppose finally that, given\nhis preferences between different computer types, Alex prefers (i)\nowning a computer of type B and one less dollar of spending\nmoney over owning a computer of type C, (ii) owning a\ncomputer of type A and one less dollar of spending money over\nowning a computer of type B, and (iii) owning a computer of\ntype C and one less dollar of spending money over owning a\ncomputer of type A. Then a series of unanticipated trade\nopportunities can spell trouble for Alex. In particular, given the\nopportunity to trade his current (type C) computer and a\ndollar for a computer of type B, Alex’s preferences\nwill prompt him to make the trade. Given the further opportunity to\ntrade his current (type B) computer and a dollar for a\ncomputer of type A, Alex’s preferences will prompt him\nto trade again. And given the opportunity to trade his current (type\nA) computer and a dollar for a computer of type C,\nAlex’s preferences will prompt him to make a third trade. But\nthis series of trades leaves Alex with the type of computer he started\noff with and only 97 dollars. And, given that unexpected trading\nopportunities may keep popping up, Alex’s situation may continue\nto deteriorate. Even though he values his spending money, his\npreferences make him susceptible to being used as a ‘money\npump.’ Moreover, interesting variations on the basic money pump\nargument show that an agent with intransitive preferences like those\njust considered is susceptible to being money-pumped even if he shows\nforesight and correctly anticipates his upcoming trading\nopportunities. See, for example, Rabinowicz 2000 and Dougherty\n2014. \nEven if he does not serve as a money pump, an agent with intransitive\npreferences can get into a great deal of trouble. To see this,\nconsider Warren Quinn’s “puzzle of the\nself-torturer” (1993): Suppose someone—who, for reasons\nthat will become apparent, Quinn calls the self-torturer—has a\nspecial electric device attached to him. The device has 1001 settings:\n0, 1, 2, 3, …, 1000 and works as follows: moving up a setting\nraises, by a tiny increment, the amount of electric current applied to\nthe self-torturer’s body. The increments in current are so small\nthat the self-torturer cannot tell the difference between adjacent\nsettings. He can, however, tell the difference between settings that\nare far apart. And, in fact, there are settings at which the\nself-torturer would experience excruciating pain. Once a week, the\nself-torturer can compare all the different settings. He must then go\nback to the setting he was at and decide if he wants to move up a\nsetting. If he does so, he gets $10,000, but he can never permanently\nreturn to a lower setting. Like most of us, the self-torturer would\nlike to increase his fortune but also cares about feeling well. Since\nthe self-torturer cannot feel any difference in comfort between\nadjacent settings but gets $10,000 at each advance, he prefers, for\nany two consecutive settings s and s+1, stopping at\ns+1 to stopping at s. But, since he does not want to\nlive in excruciating pain, even for a great fortune, he also prefers\nstopping at a low setting, such as 0, over stopping at a high setting,\nsuch as 1000. \nGiven his preferences, the self-torturer cannot rank the setting\noptions he faces from most preferred to least preferred. More\nspecifically, his preferences incorporate the following preference\nloop: \nFigure 4. \nRelatedly, the self-torturer’s preferences over the available\nsetting options are intransitive. If his preferences were transitive,\nthen, given that he prefers setting 2 to setting 1 and setting 1 to\nsetting 0, he would prefer setting 2 to setting 0. Given that he also\nprefers setting 3 to setting 2, he would (assuming transitivity)\nprefer setting 3 to setting 0. Given that he also prefers setting 4 to\nsetting 3, he would (assuming transitivity) prefer setting 4 to\nsetting 0. Continuing with this line of reasoning leads to the\nconclusion that he would, if his preferences were transitive, prefer\nsetting 1000 to setting 0. Since he does not prefer setting 1000 to\nsetting 0, his preferences are intransitive. And this intransitivity\ncan lead the self-torturer down a terrible path. In particular, if,\neach week, the self-torturer follows his preference over the pair of\nsettings he must choose between, he will end up in a situation that he\nfinds completely unacceptable. This is quite disturbing, particularly\nonce one realizes that, although the situation of the self-torturer is\npure science fiction, the self-torturer is not really alone in his\npredicament. As Quinn stresses, “most of us are like him in one\nway or another. [For example, most of us] like to eat but also care\nabout our appearance. Just one more bite will give us pleasure and\nwon’t make us look fatter; but very many bites will”\n(Quinn 1993, 199). \nGiven the money pump argument and the puzzle of the self-torturer, we\ncan, it seems, conclude that although intransitive preferences are\nsometimes understandable, acting on them can be far from sensible.\n(Note, however, that, as Duncan MacIntosh (2010) suggests, the notion\nof “an unacceptable situation” plays an important role\nhere and the question of how to cash out this notion stands in need of\nadditional attention. For a recent attempt at addressing this issue,\nsee (Andreou 2015), wherein instrumental rationality is portrayed as\naccountable to “subjective appraisal responses” that go\nbeyond the agent’s preferences and that sometimes allow some\noutcomes in a “preference loop” to figure as (rationally)\nacceptable and others to figure as (rationally) unacceptable.) \nLike intransitive preferences, vague goals or projects can prompt\ndynamic choice problems even if the agent’s preference structure\nis not changing over time. Indeed, some have suggested that the deep\nsource of the self-torturer’s problem, and what prompts his\nintransitive preferences, is that his goal of avoiding extreme pain is\nvague in the sense that, in the situation described, avoiding extreme\npain requires engaging in a multitude of goal-directed actions that\nare not individually necessary or sufficient for the achievement of\nthe goal and that are thus dispensable and perhaps even dominated if\nconsidered individually (Tenenbaum and Raffman, 2012). It may be\nhelpful to consider a more familiar example of a vague goal or\nproject, such as that of writing a good book. As Sergio Tenenbaum and\nDiana Raffman explain, this project may be characterizable as follows\n(2012, 99–100): \nIt is not difficult to see how, in a case like this, seemingly\nrational “local” decisions can lead one off course. \nTenenbaum and Raffman’s discussion of the pursuit of vague goals\nis interestingly related to Luca Ferrero’s suggestion that many\nactivities are “made up of momentary actions that relate in\nnon-local ways that span over the entire length of the\nactivities” and “require the agent’s continuous\nappreciation of the structure and outcome of the extended activities\ntaken as a whole” (2009, 406). Ferrero focuses on activities\nthat have a narrative dimension, in that “the unfolding of the\ncharacteristic temporal structure of …[the] activities can be\nfully and perspicuously described solely by a narrative”\n(412–3), but the pursuit of vague goals also seems to fit\nFerrero’s initial description, as well as his idea that\nactivities of the relevant sort involve the “paradigmatic\noperation” of the “diachronic will” (406). In all\nsuch activities, relentless guidance by “proximal\nconcerns” interferes with what is required by “the\nactivity’s global structure” (406). \nThe discussions in the preceding three sections suggest that, when it\ncomes to serving one’s concerns well, the ability to choose\ncounter-preferentially may be quite helpful. This point is reinforced\nby the possibility of autonomous benefit cases. \nIn autonomous benefit cases, one benefits from forming a certain\nintention but not from carrying out the associated action. The\nautonomous benefit cases that have figured most prominently in the\nliterature on dynamic choice are those in which carrying out the\naction associated with the beneficial intention is detrimental rather\nthan just unrewarding. Among the most famous autonomous benefit cases\nis Gregory Kavka’s “toxin puzzle” (1983). In\nKavka’s invented case, \nPart of what is interesting about this case is that, even though most\npeople would gladly drink the toxin for a million dollars, getting the\nmillion dollars is not that easy. This is because one does not get the\nmillion dollars for drinking the toxin. Indeed, one does not get\nanything but a day of illness for drinking the toxin. As Kavka\nexplains, by the time the toxin is to be consumed, one either already\nhas the million in one’s account or not; and drinking the toxin\nwill not get one any (additional) funds. Assuming one has no desire to\nbe ill for nothing, drinking the toxin seems to involve acting\ncounter-preferentially—and this is, if not impossible, at least\nno easy feat. So, given a clear understanding of the situation, one is\nlikely to find it difficult, if not impossible, to form the intention\nto drink the toxin. Presumably, one cannot form the intention to drink\nthe toxin if one is confident that one will not drink it. If only one\ncould somehow rely on the cooperation of one’s future self, one\ncould then genuinely form the intention to drink the toxin and thus\nget the million—a wonderful result from the perspective of both\none’s current and one’s future self. But, alas,\none’s future self will, it seems, have no reason to drink the\ntoxin when the time for doing so arrives. \nHere again we have a situation in which doing well by oneself is not\neasy. \nGiven how much trouble dynamic choice problems can cause, it is\nnatural to wonder whether and how they can be solved. Various\nsolutions of varying scope have been proposed in the literature on\ndynamic choice. The first three subsections that follow focus on ideas\nregarding the practical issue of dealing with dynamic choice problems.\nThe fourth subsection focuses on attempts at resolving the theoretical\npuzzles concerning rational choice raised by various dynamic choice\nproblems. \nTwo strategies that we can sometimes use to solve (in the sense of\npractically deal with) dynamic choice problems are suggested in\nKavka’s description of the toxin puzzle. One strategy is to use\ngimmicks that cause one to reason or choose in a way that does not\naccord with one’s preferences. The other strategy involves the\narrangement of external incentives. Although such maneuvers are ruled\nout in Kavka’s case, they can prove useful in less restrictive\ncases. This subsection considers the former strategy and the next\nsubsection considers the latter strategy. \nIf one accepts the common assumption that causing oneself to reason or\nchoose in a way that does not accord with one’s preferences\ninvolves rendering oneself irrational, the former strategy can be\nthought of as aiming at rationally-induced irrationality. A fanciful\nbut clear illustration of this strategy is presented in Derek\nParfit’s work (1984). In Parfit’s example (which is\nlabeled Schelling’s Answer to Armed Robbery because it\ndraws on Thomas Schelling’s view that “it is not a\nuniversal advantage in situations of conflict to be inalienably and\nmanifestly rational in decision and motivation” (Schelling 1960,\n18)), a robber breaks into someone’s house and orders the owner,\ncall him Moe, to open the safe in which he hoards his gold. The robber\nthreatens to shoot Moe’s children unless Moe complies. But Moe\nrealizes that both he and his children will probably be shot even if\nhe complies, since the robber will want to get rid of them so that\nthey cannot record his getaway car information and get it to the\npolice (who will be arriving from the nearest town in about 15 minutes\nin response to Moe’s call, which was prompted by the first signs\nof the break-in). Fortunately, Moe has a special drug at hand that, if\nconsumed, causes one to be irrational for a brief period. Recognizing\nthat this drug is his only real hope, Moe consumes the drug and\nimmediately loses his wits. He begins “reeling about the\nroom” saying things like “Go ahead. I love my children. So\nplease kill them” (Parfit 1984, 13). Given Moe’s current\nstate, the robber cannot do anything that will induce Moe to open the\nsafe. There is no point in killing Moe or his children. The only\nsensible thing to do now is to hurry off before the police arrive. \nGiven that consuming irrationality drugs and even hiring hypnotists\nare normally not feasible solutions to our dynamic choice problems,\nthe possibility of rationally inducing irrationality may seem\npractically irrelevant. But it may be that we often benefit from the\nnon-conscious employment of what is more or less a version of this\nstrategy. We sometimes, for example, engage in self-deception or\nindulge irrational fears or superstitions when it is convenient to do\nso. Many of us might, in toxin-type cases, be naturally prone to dwell\non and indulge superstitious fears, like the fear that one will\nsomehow be jinxed if one manages to get the million dollars but then\ndoes not drink the toxin. Given this fear, one might be quite\nconfident that one will drink the toxin if one gets the million; and\nso it might be quite easy for one to form the intention to drink the\ntoxin. Although this is not a solution to the toxin puzzle that one\ncan consciously plan on using (nor is it one that resolves the\ntheoretical issues raised by the case), it may nonetheless often help\nus effectively cope with toxin-type cases. (For a clear and compact\ndiscussion concerning self-deception, “motivationally biased\nbelief,” and “motivated irrationality” more\ngenerally, see, for example, Mele 2004.) \nThe other above-mentioned strategy that is often useful for dealing\nwith certain dynamic choice problems is the arrangement of external\nincentives that make it worthwhile for one’s future self to\ncooperate with one’s current plans. This strategy can be\nparticularly useful in dealing with discounting-induced preference\nreversals. Consider again the agent who wants to save for a decent\nretirement but, as each opportunity to save approaches, prefers to\nspend her potential retirement contribution on just one more trivial\nindulgence before finally tightening her belt for the sake of the\nfuture satisfaction she feels is essential to her well-being. If this\nagent’s plans are consistently thwarted by her\ndiscounting-induced preference reversals, she might come to the\nconclusion that she will never manage to save for a decent retirement\nif she doesn’t supplement her plans with incentives that will\nprevent the preference reversals that are causing her so much trouble.\nIf she is lucky, she may find an existing precommitment device that\nshe can take advantage of. Suppose, for example, that she can sign up\nfor a program at work that, starting in a month, automatically\ndeposits a portion of her pay into a retirement fund. If she cannot\nremove deposited funds without a significant penalty, and if she must\nprovide a month’s notice to discontinue her participation in the\nprogram, signing up for the program might change the cost-and-reward\nstructure of spending her potential retirement contributions on\ntrivial indulgences enough to make this option consistently\ndispreferred. If no ready-made precommitment device is available, she\nmight be able to create a suitable one herself. If, for example, she\nis highly averse to breaking promises, she might be able to solve her\nproblem by simply promising a concerned friend that she will\nhenceforth deposit a certain percentage of her pay into a retirement\nfund. \nIn some cases, one might not be confident that one can arrange for\nexternal incentives that will get one’s future self to\nvoluntarily cooperate with one’s current plans. One might\ntherefore favor the related but more extreme strategy of making sure\nthat one’s future self does not have the power to thwart\none’s current plans. Rather than simply making cooperation more\nworthwhile (and thus, in a sense, more compelling), this strategy\ninvolves arranging for the use of force (which compels in a\nstronger sense of the term). A fictional but particularly famous\nemployment of the strategy (which is discussed in, for example, Elster\n1984) is its employment by Odysseus in Homer’s Odyssey.\nBecause he longed to hear the enchanting singing of the Sirens, but\nfeared that he would thereby be lured into danger, Odysseus instructed\nhis companions to tie him to the mast of his ship and to resist his\n(anticipated) attempts at freeing himself from the requested\nbonds. \nAnother strategy for dealing with certain dynamic choice\nproblems—this one proposed by Robert Nozick (1993)—is the\nstrategy of investing actions with symbolic utility (or value) and\nthen allowing oneself to be influenced not only by the causal\nsignificance of one’s actions, but also by their symbolic\nsignificance. According to Nozick, “actions and outcomes can\nsymbolize still further events … [and] draw upon themselves the\nemotional meaning (and utility…) of these other events”\n(26). If “we impute to actions… utilities coordinate with\nwhat they symbolize, and we strive to realize (or avoid) them as we\nwould strive for what they stand for” (32), our choices will\ndiffer from what they would be if we considered only the causal\nsignificance of our actions. Consider, for example, the case of the\nself-torturer. Suppose the self-torturer has moved up ten settings in\nten weeks. He is still in a very comfortable range, but he is starting\nto worry about ending up at a high setting that would leave him in\nexcruciating pain. It occurs to him that he should quit while he is\nahead, and he begins to symbolically associate moving up a setting at\nthe next opportunity with moving up a setting at every upcoming\nopportunity. By the time the next opportunity to move up a setting\ncomes around, the extremely negative symbolic significance of this\npotential action steers him away from performing the action. For a\nstructurally similar but more down-to-earth example, consider someone\nwho loves overeating but is averse to becoming overweight. If this\nindividual comes to symbolically associate having an extra helping\nwith overeating in general and thus with becoming overweight, he may\nbe averse to having the extra helping, even if, in causal terms, what\nhe does in this particular case is negligible. \nThe three strategies discussed so far suggest that, to cope with\ndynamic choice problems, one must either mess with one’s\nrationality or else somehow change the payoffs associated with the\noptions one will face. Some philosophers—including, for example,\nMichael Bratman (1999; 2006), David Gauthier (1986; 1994), and Edward\nMcClennen (1990; 1997)—have, however, suggested that the\nrational agent will not need to resort to such gimmicks as often as\none might think—a good thing, since making the necessary\narrangements can require a heavy investment of time, energy, and/or\nmoney. The key to their arguments is the idea that adopting plans can\naffect what it is rational for one to do even when the plans do not\naffect the payoffs associated with the options one will face;\nrelatedly, their arguments incorporate the idea that rationality at\nleast sometimes calls for resolutely sticking to a plan even if the\nplan disallows an action that would fit as well or better with\none’s preferences than the action required by the plan. (For\nsome interesting discussion relating resoluteness, one’s current\noptions, and the options one will face, see Portmore 2019.) For\nBratman, Gauthier, and McClennen, being resolute is not simply useful\nin coping with dynamic choice problems. Rather, it figures as part of\na conception of rationality that resolves the theoretical puzzles\nconcerning rationality and choice over time posed by various dynamic\nchoice problems. In particular, it figures as part of a conception of\nrationality whose dictates provide intuitively sensible guidance not\nonly in simple situations but also in challenging dynamic choice\nsituations. (Significantly, in some of his more recent work, Bratman\n(2014; 2018) distances himself from the idea that rational\nresoluteness involves acting contrary to one’s current\npreferences by suggesting that when rationality calls for sticking to\na plan even if this is not called for by one’s current\npreferences, there may be “rational pressure” to change\none’s current preferences.) \nWe are, as Michael Bratman (1983; 1987) stresses, planning creatures.\nOur reasoning is structured by our plans, which enable us to achieve\ncomplex personal and social goals. To benefit from planning, one must\ntake plans seriously. For Bratman, this involves, among other things,\n(i) recognizing a general rational pressure favoring sticking to\none’s plan so long as there is no problem with the plan (Bratman\n2006, section 8), and (ii) “taking seriously how one will see\nmatters at the conclusion of one’s plan, or at appropriate\nstages along the way, in the case of plans or policies that are\nongoing” (1999, 86). In accordance with these proposed\nrequirements, Bratman (1999) concludes that rationality at least\nsometimes calls for sticking to a plan even if this is not called for\nby one’s current preferences. Moreover, although this conception\nof rationality requires that one sometimes resist one’s current\npreferences, it is taken to prompt more sensible choices in\nchallenging dynamic choice situations than do conceptions of\nrationality whose dictates do not take plans seriously. \nThe significance of the first requirement is easy to see. If there is\na general rational pressure favoring sticking to one’s plan so\nlong as there is no problem with it, then a rational agent that takes\nplans seriously will not get into the sort of trouble Broome imagines\nAbraham might get into. When faced with incommensurable alternatives,\nthe rational agent who takes plans seriously will adopt a plan and\nthen stick to it even if his preferences are consistent with pursuing\nan alternative course of action. \nWhat about the significance of the second requirement? For Bratman, if\none is concerned about how one will see matters at the conclusion of\none’s plan or at appropriate stages along the way, then one\nwill, other things equal, avoid adjusting one’s plan in ways\nthat one will regret in the future. So Bratman’s planning\nconception of rationality includes a “no-regret\ncondition.” And, according to Bratman, given this condition, his\nconception of rationality gives intuitively plausible guidance in\ncases of temptation like the case of the self-torturer or the\nretirement contribution case. In particular, it implies that, in such\ncases, the rational planner will adopt a plan and refrain from\nadjusting it. For in both sorts of cases, if the simple fact that\none’s preferences favor adjusting one’s plan leads one to\nadjust it, one is bound to end up, via repeated adjustments of\none’s plan, in the situation one finds unacceptable. One is thus\nbound to experience future regret. And, while Bratman allows that\nregret can sometimes be misguided—which is why he does not\npresent avoiding regret as an exceptionless imperative—there are\nnot, for Bratman, any special considerations that would make regret\nmisguided if one gave into temptation in cases like the case of the\nself-torturer or the retirement contribution case. \nBased on their own reasoning concerning rational resoluteness,\nGauthier (1994) and McClennen (1990; 1997) argue that rational\nresoluteness can help an agent do well in autonomous benefit cases\nlike the toxin case. They maintain that being rational is not a matter\nof always choosing the action that best serves one’s concerns.\nRather it is a matter of acting in accordance with the deliberative\nprocedure that best serves one’s concerns. Now it might seem as\nthough the deliberative procedure that best serves one’s\nconcerns must be the deliberative procedure that calls for always\nchoosing the action that best serves one’s concerns. But\nautonomous benefit cases like the toxin case suggest that this is not\nquite right. For, the deliberative procedure that calls for always\nchoosing the action that best serves one’s concerns does not\nserve one’s concerns well in autonomous benefit cases. More\nspecifically, someone who reasons in accordance with this deliberative\nprocedure does worse in autonomous benefit cases than someone who is\nwilling to resolutely stick to a prior plan that he did well to adopt.\nAccordingly, Gauthier and McClennen deny that the best deliberative\nprocedure requires one to always choose the action that best serves\none’s concerns; in their view, the best deliberative procedure\nrequires some resoluteness. Relatedly, they see drinking the toxin in\naccordance with a prior plan to drink the toxin as rational, indeed as\nrationally required, given that one did well to adopt the plan; so\nrationality helps one benefit, rather than hindering one from\nbenefiting, in autonomous benefit cases like the toxin case. \nNote that, while there is widespread agreement that a plausible\nconception of rationality will imply that the self-torturer should\nresist the temptation to keep advancing one more setting, there is no\nwidespread agreement that a plausible conception of rationality will\nimply that it is rational to drink the toxin. For those who find the\nidea that it is rational to drink the toxin completely\ncounter-intuitive, its emergence figures as a problematic, rather than\nwelcome, implication of Gauthier’s and McClennen’s views\nconcerning rational resoluteness. \nIf Bratman and/or Gauthier and McClennen are on the right\ntrack—and this is, of course, a big if—then (some form of)\nresoluteness may often be the key to keeping oneself out of potential\ndynamic choice traps. It may also be the key to resolving various\npuzzles concerning rationality and dynamic choice. \nIn an interesting critique of planning solutions to cases of\ntemptation, Tenenbaum and Raffman (2012) challenge the purported\ncentrality of resoluteness. They suggest that, in cases of temptation,\ninstrumental rationality may not require planning and resoluteness,\nbut simply exercising “sufficiently many”\n“permissions” to do something other than what “would\nbe best at a given moment” when this is required by a\n“rationally innocent” goal or project. For instance,\n“suppose you take a break from writing an important memo and\nstart surfing the web. Surely surfing for one additional second will\nnot prevent you from completing the memo, but if you surf for long\nenough you won’t have time to finish it” (110).\nInstrumental rationality requires that you stop surfing at an\nacceptable point. But this need not involve stopping at a point\ndetermined by a prior plan. Whether or not you have a plan to stop at\ntime t, and whether or not you resolutely adhere to such a plan need\nnot be of crucial importance. What matters is that, ultimately, you\nstop in good time by exercising, at one or more points, the rational\npermission to do something other than what would be best at that\nmoment with an eye to achieving the rationally innocent goal of\ncompleting the important memo. Tenenbaum (forthcoming) develops a\ntheory of instrumental rationality that illuminates and accommodates\nthe need to exercise rational permissions of the sort just\ndescribed. \nAlthough dynamic choice problems are often presented with the help of\nfanciful thought experiments, their interest is not strictly\ntheoretical. As this section highlights, they can wreak havoc in our\nreal lives, supporting phenomena such as self-destructive addictive\nbehavior and dangerous environmental destruction. In some cases, these\nphenomena can be understood in terms of procrastination (Andreou\n2007), which seems to be, by its very nature, a dynamic choice problem\n(Stroud 2010). \nAccording to the most familiar model of self-destructive addictive\nbehavior, such behavior results from cravings that limit “the\nscope for volitional control of behavior” and can in some cases\nbe irresistible, “overwhelm[ing] decision making\naltogether” (Loewenstein 1999, 235–6). But, as we know\nfrom dynamic choice theory, self-destructive behavior need not be\ncompelled. It can also be supported by challenging choice situations\nand problematic preference structures that prompt dynamic choice\nproblems. Reflection on this point has led to new ideas concerning\npossible sources of self-destructive addictive behavior. For example,\nGeorge Ainslie (2001) has developed the view that addictive habits\nsuch as smoking—which can, it seems, flourish even in the\nabsence of irresistible craving—are often supported by\ndiscounting-induced preference reversals. Given the possibility of\ndiscounting-induced preference reversals, even someone who cares\ndeeply about having a healthy future, and who therefore does not want\nto be a heavy smoker, can easily find herself smoking cigarette after\ncigarette, where this figures as a series of indulgences that she\nplans against and then regrets. \nReflection on dynamic choice theory has also led to new ideas in\nenvironmental philosophy. For example, Chrisoula Andreou (2006) argues\nthat, although dangerous environmental destruction is usually analyzed\nas resulting from interpersonal conflicts of interest, such\ndestruction can flourish even in the absence of such conflicts. In\nparticular, where individually negligible effects are involved, as is\nthe case among “creeping environmental problems” such as\npollution, “an agent, whether it be an individual or a\nunified collective, can be led down a course of destruction\nsimply as a result of following its informed and perfectly\nunderstandable but intransitive preferences” (Andreou\n2006, 96). Notice, for example, that if a unified collective values a\nhealthy community, but also values luxuries whose production or use\npromotes a carcinogenic environment, it can find itself in a situation\nthat is structurally similar to the situation of the self-torturer.\nLike the self-torturer, such a collective must cope with the fact that\nwhile one more day, and perhaps even one more month of indulgence can\nprovide great rewards without bringing about any significant\nalterations in (physical or psychic) health, “sustained\nindulgence is far from innocuous” (Andreou 2006, 101). \nClearly, success in achieving a long-term goal can require showing\nsome restraint along the way; but it is tempting to put off showing\nrestraint and to favor a bit more indulgence over embarking on the\nchallenging doings or omissions that will serve the valued long-term\ngoal. Here, as in many other contexts, procrastination figures as a\nserious threat. \nThough both philosophically intriguing and practically significant,\nprocrastination has only recently received substantial attention as an\nimportant topic of philosophical debate. (Much of the debate can be\nfound in a collection of papers on the topic edited by Chrisoula\nAndreou and Mark D. White (2010).) It has perhaps been assumed that\nprocrastination is just a form of weakness of will and so, although\nthere has been little explicit discussion of procrastination, most of\nthe philosophical work necessary for understanding procrastination has\nalready been done. But, as Sarah Stroud has argued (2010), this\nassumption is problematic, since there are cases of procrastination\nthat do not fit with the traditional conception of weakness of will,\nwhich casts the agent as acting against her better judgment, or with\nthe influential revisionary conception of weakness of will due to\nRichard Holton (1999), which casts the agent as acting irresolutely.\nAlthough the well-developed literature on weakness of will is an\nimportant resource in the study of procrastination, there is a lot\nmore philosophical work that needs to be done, and the modeling work\nthat seems to be most promising focuses heavily on the fact that\nprocrastination is a problem faced by agents whose choices are spread\nout over time. \nWhen one performs a series of actions that do not serve one’s\nconcerns well, it is natural to feel regret and frustration. Why, it\nmight be wondered, is one doing so badly by oneself? Self-loathing,\ncompulsion, or simple ignorance might in some cases explain the\nsituation; but, oftentimes, none of these things seems to be at the\nroot of the problem. For, in many cases, one’s steps along a\ndisadvantageous course seem voluntary, motivated by the prospect of\nsome benefit, and performed in light of a correct understanding of the\nconsequences of each step taken. As we have seen, dynamic choice\ntheory makes it clear how such cases are possible. \nAlthough an agent with a dynamic choice problem can often be described\nas insufficiently resolute, she is normally guided by her preferences\nor her evaluation of the options she faces. As such, she is not, in\ngeneral, properly described as simply out of control. Still, the\ncontrol she exhibits is inadequate with respect to the task of\neffectively governing her (temporally-extended) self. So her problem\nis, at least in part, a problem of effective self-governance over\ntime. Accordingly, some work on choice over time (e.g. Velleman 2000;\nBratman, 2012) includes discussion of effective self-governance over\ntime and explores the connection between the requirements for\neffective self-governance over time and the requirements for rational\nchoice over time (sometimes referred to as the requirements of\ndiachronic rationality). Some big questions in this area include the\nfollowing: To what extent does self-governance over time (or at least\neffective self-governance over time) require cross-temporal coherence\nin the form of a presumption in favor of prior intentions? To what\nextent does diachronic rationality require self-governance over time?\nAnd to what extent does diachronic rationality require cross-temporal\ncoherence in the form of a presumption in favor of prior intentions.\nMy own view is that it is ensuring the avoidance of self-defeating\nbehavior rather than ensuring self-governance over time that is\nrationally required, and so diachronic rationality requires a\npresumption in favor of prior intentions only when this is necessary\nfor avoiding self-defeating behavior (Andreou, 2012). But debate on\nthis topic has not been very extensive and further exploration of the\ntopic is certainly in order.","contact.mail":"andreou@philosophy.utah.edu","contact.domain":"philosophy.utah.edu"}]
