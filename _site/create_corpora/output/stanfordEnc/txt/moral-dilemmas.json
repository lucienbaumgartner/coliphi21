[{"date.published":"2002-04-15","date.changed":"2018-06-16","url":"https://plato.stanford.edu/entries/moral-dilemmas/","author1":"Terrance McConnell","author1.info":"http://www.uncg.edu/~tcmcconn/","entry":"moral-dilemmas","body.text":"\n\n\n\nMoral dilemmas, at the very least, involve conflicts between moral\nrequirements. Consider the cases given below.\n\n\n\nIn Book I of Plato’s Republic, Cephalus defines\n‘justice’ as speaking the truth and paying one’s debts.\nSocrates quickly refutes this account by suggesting that it would be\nwrong to repay certain debts—for example, to return a borrowed\nweapon to a friend who is not in his right mind. Socrates’ point is not\nthat repaying debts is without moral import; rather, he wants to show\nthat it is not always right to repay one’s debts, at least not exactly\nwhen the one to whom the debt is owed demands repayment. What we have\nhere is a conflict between two moral norms: repaying one’s debts and\nprotecting others from harm. And in this case, Socrates maintains that\nprotecting others from harm is the norm that takes priority. \n\nNearly twenty-four centuries later, Jean-Paul Sartre described a\nmoral conflict the resolution of which was, to many, less obvious than\nthe resolution to the Platonic conflict. Sartre (1957) tells of a\nstudent whose brother had been killed in the German offensive of 1940.\nThe student wanted to avenge his brother and to fight forces that he\nregarded as evil. But the student’s mother was living with him, and he\nwas her one consolation in life. The student believed that he had\nconflicting obligations. Sartre describes him as being torn between two\nkinds of morality: one of limited scope but certain efficacy, personal\ndevotion to his mother; the other of much wider scope but uncertain\nefficacy, attempting to contribute to the defeat of an unjust\naggressor. \n\nWhile the examples from Plato and Sartre are the ones most commonly\ncited, there are many others. Literature abounds with such cases. In\nAeschylus’s Agamemnon, the protagonist ought to save his\ndaughter and ought to lead the Greek troops to Troy; he ought to do\neach but he cannot do both. And Antigone, in Sophocles’s play\nof the same name, ought to arrange for the burial of her brother,\nPolyneices, and ought to obey the pronouncements of the city’s\nruler, Creon; she can do each of these things, but not both. Areas of\napplied ethics, such as biomedical ethics, business ethics, and legal\nethics, are also replete with such cases. \n\nWhat is common to the two well-known cases is conflict. In each\ncase, an agent regards herself as having moral reasons to do each of\ntwo actions, but doing both actions is not possible. Ethicists have\ncalled situations like these moral dilemmas. The crucial\nfeatures of a moral dilemma are these: the agent is required to do each\nof two (or more) actions; the agent can do each of the actions; but the\nagent cannot do both (or all) of the actions. The agent thus seems\ncondemned to moral failure; no matter what she does, she will do\nsomething wrong (or fail to do something that she ought to do). \n\nThe Platonic case strikes many as too easy to be characterized as a\ngenuine moral dilemma. For the agent’s solution in that case is\nclear; it is more important to protect people from harm than to return\na borrowed weapon. And in any case, the borrowed item can be returned\nlater, when the owner no longer poses a threat to others. Thus in this\ncase we can say that the requirement to protect others from serious\nharm overrides the requirement to repay one’s debts by\nreturning a borrowed item when its owner so demands. When one of the\nconflicting requirements overrides the other, we have a conflict but\nnot a genuine moral dilemma. So in addition to the features mentioned\nabove, in order to have a genuine moral dilemma it must also\nbe true that neither of the conflicting requirements is overridden\n(Sinnott-Armstrong 1988, Chapter 1). \n\nIt is less obvious in Sartre’s case that one of the requirements\noverrides the other. Why this is so, however, may not be so obvious.\nSome will say that our uncertainty about what to do in this case is\nsimply the result of uncertainty about the consequences. If we were\ncertain that the student could make a difference in defeating the\nGermans, the obligation to join the military would prevail. But if the\nstudent made little difference whatsoever in that cause, then his\nobligation to tend to his mother’s needs would take precedence, since\nthere he is virtually certain to be helpful. Others, though, will say\nthat these obligations are equally weighty, and that uncertainty about\nthe consequences is not at issue here. \n\nEthicists as diverse as Kant (1971/1797), Mill (1979/1861), and Ross\n(1930, 1939) have assumed that an adequate moral theory should not\nallow for the possibility of genuine moral dilemmas. Only\nrecently—in the last sixty years or so—have philosophers\nbegun to challenge that assumption. And the challenge can take at\nleast two different forms. Some will argue that it is not\npossible to preclude genuine moral dilemmas. Others will argue\nthat even if it were possible, it is not desirable to do\nso. \n\nTo illustrate some of the debate that occurs regarding whether it is\npossible for any theory to eliminate genuine moral dilemmas, consider\nthe following. The conflicts in Plato’s case and in Sartre’s case\narose because there is more than one moral precept (using\n‘precept’ to designate rules and principles), more than\none precept sometimes applies to the same situation, and in some of\nthese cases the precepts demand conflicting actions. One obvious\nsolution here would be to arrange the precepts, however many there\nmight be, hierarchically. By this scheme, the highest ordered precept\nalways prevails, the second prevails unless it conflicts with the\nfirst, and so on. There are at least two glaring problems with this\nobvious solution, however. First, it just does not seem credible to\nhold that moral rules and principles should be hierarchically\nordered. While the requirements to keep one’s promises and to prevent\nharm to others clearly can conflict, it is far from clear that one of\nthese requirements should always prevail over the other. In\nthe Platonic case, the obligation to prevent harm is clearly\nstronger. But there can easily be cases where the harm that can be\nprevented is relatively mild and the promise that is to be kept is\nvery important. And most other pairs of precepts are like this. This\nwas a point made by Ross in The Right and the Good (1930,\nChapter 2). \n\nThe second problem with this easy solution is deeper. Even if it were\nplausible to arrange moral precepts hierarchically, situations can\narise in which the same precept gives rise to conflicting obligations.\nPerhaps the most widely discussed case of this sort is taken from\nWilliam Styron’s Sophie’s Choice (1980; see\nGreenspan 1983 and Tessman 2015, 160–163). Sophie and her two\nchildren are at a Nazi concentration camp. A guard confronts Sophie\nand tells her that one of her children will be allowed to live and one\nwill be killed. But it is Sophie who must decide which child will be\nkilled. Sophie can prevent the death of either of her children, but\nonly by condemning the other to be killed. The guard makes the\nsituation even more excruciating by informing Sophie that if she\nchooses neither, then both will be killed. With this added factor,\nSophie has a morally compelling reason to choose one of her children.\nBut for each child, Sophie has an apparently equally strong reason to\nsave him or her. Thus the same moral precept gives rise to conflicting\nobligations. Some have called such cases symmetrical\n(Sinnott-Armstrong 1988, Chapter 2). \n\nWe shall return to the issue of whether it is possible to preclude\ngenuine moral dilemmas. But what about the desirability of doing so?\nWhy have ethicists thought that their theories should preclude the\npossibility of dilemmas? At the intuitive level, the existence of\nmoral dilemmas suggests some sort of inconsistency. An agent caught in\na genuine dilemma is required to do each of two acts but cannot do\nboth. And since he cannot do both, not doing one is a condition of\ndoing the other. Thus, it seems that the same act is both required and\nforbidden. But exposing a logical inconsistency takes some work; for\ninitial inspection reveals that the inconsistency intuitively felt is\nnot present. Allowing \\(OA\\) to designate that the agent in\nquestion ought to do \\(A\\) (or is morally obligated to do\n\\(A\\), or is morally required to do \\(A)\\), that \\(OA\\)\nand \\(OB\\) are both true is not itself inconsistent, even if one\nadds that it is not possible for the agent to do both \\(A\\) and\n\\(B\\). And even if the situation is appropriately described as\n\\(OA\\) and \\(O\\neg A\\), that is not a\ncontradiction; the contradictory of \\(OA\\) is\n\\(\\neg OA\\). (See Marcus 1980 and McConnell 1978, 273.) \n\nSimilarly rules that generate moral dilemmas are not inconsistent, at\nleast on the usual understanding of that term. Ruth Marcus suggests\nplausibly that we “define a set of rules as consistent if there\nis some possible world in which they are all obeyable in all\ncircumstances in that world.” Thus, “rules are\nconsistent if there are possible circumstances in which no conflict\nwill emerge,” and “a set of rules is inconsistent if there\nare no circumstances, no possible world, in which all the\nrules are satisfiable” (Marcus 1980, 128 and 129). Kant, Mill, and Ross were likely aware that a dilemma-generating theory\nneed not be inconsistent. Even so, they would be disturbed if their\nown theories allowed for such predicaments. If this speculation is correct, it suggests that Kant, Mill, Ross, and others thought\nthat there is an important theoretical feature that dilemma-generating\ntheories lack. And this is understandable. It is certainly no comfort\nto an agent facing a reputed moral dilemma to be told that at least\nthe rules which generate this predicament are consistent because there\nis a possible world in which they do not conflict. For a good\npractical example, consider the situation of the criminal defense\nattorney. She is said to have an obligation to hold in confidence the\ndisclosures made by a client and to be required to conduct herself\nwith candor before the court (where the latter requires that the\nattorney inform the court when her client commits perjury) (Freedman\n1975, Chapter 3). It is clear that in this world these two\nobligations often conflict. It is equally clear that in some possible\nworld—for example, one in which clients do not commit\nperjury—that both obligations can be satisfied. Knowing this is\nof no assistance to defense attorneys who face a conflict between\nthese two requirements in this world. \n\nEthicists who are concerned that their theories not allow for moral\ndilemmas have more than consistency in mind. What is\ntroubling is that theories that allow for dilemmas fail to be\nuniquely action-guiding. A theory can fail to be uniquely\naction-guiding in either of two ways: by recommending incompatible\nactions in a situation or by not recommending any action at all.\nTheories that generate genuine moral dilemmas fail to be uniquely\naction-guiding in the former way. Theories that have no way, even in\nprinciple, of determining what an agent should do in a particular\nsituation have what Thomas E. Hill, Jr. calls “gaps” (Hill 1996,\n179–183); they fail to be action-guiding in the latter way. Since one\nof the main points of moral theories is to provide agents with\nguidance, that suggests that it is desirable for theories to eliminate\ndilemmas and gaps, at least if doing so is possible. \n\nBut failing to be uniquely action-guiding is not the only reason\nthat the existence of moral dilemmas is thought to be troublesome. Just\nas important, the existence of dilemmas does lead to inconsistencies if\ncertain other widely held theses are true. Here we shall consider two\ndifferent arguments, each of which shows that one cannot consistently\nacknowledge the reality of moral dilemmas while holding selected (and seemingly plausible)\nprinciples. \n\nThe first argument shows that two standard principles of deontic logic\nare, when conjoined, incompatible with the existence of moral\ndilemmas. The first of these is the principle of deontic\nconsistency \n\nIntuitively this principle just says that the same action cannot be\nboth obligatory and forbidden. Note that as initially described, the\nexistence of dilemmas does not conflict with PC. For as described,\ndilemmas involve a situation in which an agent ought to do \\(A\\),\nought to do \\(B\\), but cannot do both \\(A\\) and \\(B\\).  But if we add\na principle of deontic logic, then we obtain a conflict with\nPC: \n\nIntuitively, PD just says that if doing \\(A\\) brings about\n\\(B\\), and if \\(A\\) is obligatory (morally required), then\n\\(B\\) is obligatory (morally required). The first\nargument that generates inconsistency can now be stated. Premises\n(1), (2), and (3) represent the claim that moral dilemmas exist. \n \n\nLine (10) directly conflicts with PC. And from PC and (1), we can\nconclude: \n\nAnd, of course, (9) and (11) are contradictory. So if we assume PC and\nPD, then the existence of dilemmas generates an inconsistency of the\nold-fashioned logical sort. (Note: In standard deontic logic, the\n‘\\(\\Box\\)’ in PD typically designates logical necessity.\nHere I take it to indicate physical necessity so that the appropriate\nconnection with premise (3) can be made. And I take it that logical\nnecessity is stronger than physical necessity.) \n\nTwo other principles accepted in most systems of deontic logic\nentail PC. So if PD holds, then one of these additional two principles\nmust be jettisoned too. The first says that if an action is obligatory,\nit is also permissible. The second says that an action is permissible\nif and only if it is not forbidden. These principles may be stated\nas: \nand  \n\nPrinciples OP and D are basic; they seem to be conceptual truths\n(Brink 1994, section IV).\n\nThe second argument that generates inconsistency, like the\nfirst, has as its first three premises a symbolic representation of a\nmoral dilemma. \n\nAnd like the first, this second argument shows that the existence of\ndilemmas leads to a contradiction if we assume two other commonly\naccepted principles. The first of these principles is that\n‘ought’ implies ‘can’. Intuitively this says\nthat if an agent is morally required to do an action, it must be\npossible for the agent to do it. This principle seems necessary if moral judgments are to be uniquely action-guiding. We may represent this as \n\nThe other principle, endorsed by most systems of deontic logic, says\nthat if an agent is required to do each of two actions, she is required\nto do both. We may represent this as  \n\nThe argument then proceeds:  \n\nSo if one assumes that ‘ought’ implies ‘can’\nand if one assumes the principle represented in (5)—dubbed by some\nthe agglomeration principle (Williams 1965)—then again a\ncontradiction can be derived. \n\nNow obviously the inconsistency in the first argument can be avoided\nif one denies either PC or PD. And the inconsistency in the second\nargument can be averted if one gives up either the principle that\n‘ought’ implies ‘can’ or the agglomeration\nprinciple. There is, of course, another way to avoid these\ninconsistencies: deny the possibility of genuine moral dilemmas. It is\nfair to say that much of the debate concerning moral dilemmas in the\nlast sixty years has been about how to avoid the inconsistencies\ngenerated by the two arguments above. \n\nOpponents of moral dilemmas have generally held that the crucial\nprinciples in the two arguments above are conceptually true, and\ntherefore we must deny the possibility of genuine dilemmas. (See, for\nexample, Conee 1982 and Zimmerman 1996.) Most of the debate, from\nall sides, has focused on the second argument. There is an oddity\nabout this, however. When one examines the pertinent principles in\neach argument which, in combination with dilemmas, generates an\ninconsistency, there is little doubt that those in the first argument\nhave a greater claim to being conceptually true than those in the\nsecond. (One who recognizes the salience of the first argument is Brink 1994, section V.) Perhaps the focus on the second argument is due to the impact\nof Bernard Williams’s influential essay (Williams 1965). But notice\nthat the first argument shows that if there are genuine dilemmas, then\neither PC or PD must be relinquished. Even most supporters of dilemmas\nacknowledge that PC is quite basic. E.J. Lemmon, for example, notes\nthat if PC does not hold in a system of deontic logic, then all that\nremains are truisms and paradoxes (Lemmon 1965, p. 51). And giving\nup PC also requires denying either OP or D, each of which also seems\nbasic. There has been much debate about PD—in particular,\nquestions generated by the Good Samaritan paradox—but still it\nseems basic. So those who want to argue against dilemmas purely on\nconceptual grounds are better off focusing on the first of the two\narguments above. \n\nSome opponents of dilemmas also hold that the pertinent principles\nin the second argument—the principle that ‘ought’\nimplies ‘can’ and the agglomeration principle—are\nconceptually true. But foes of dilemmas need not say this. Even if they\nbelieve that a conceptual argument against dilemmas can be made by\nappealing to PC and PD, they have several options regarding the second\nargument. They may defend ‘ought’ implies\n‘can’, but hold that it is a substantive normative\nprinciple, not a conceptual truth. Or they may even deny the truth of\n‘ought’ implies ‘can’ or the agglomeration\nprinciple, though not because of moral dilemmas, of course. \n\nDefenders of dilemmas need not deny all of the pertinent\nprinciples. If one thinks that each of the principles at least has\nsome initial plausibility, then one will be inclined to retain as many\nas possible. Among the earlier contributors to this debate, some took\nthe existence of dilemmas as a counterexample to ‘ought’\nimplies ‘can’ (for example, Lemmon 1962 and Trigg 1971);\nothers, as a refutation of the agglomeration principle (for example,\nWilliams 1965 and van Fraassen 1973). A common response to the first\nargument is to deny PD. A more complicated response is to grant that\nthe crucial deontic principles hold, but only in ideal worlds. In the\nreal world, they have heuristic value, bidding agents in conflict\ncases to look for permissible options, though none may exist (Holbo\n2002, especially sections 15–17). \n\nFriends and foes of dilemmas have a burden to bear in responding to\nthe two arguments above. For there is at least a prima facie\nplausibility to the claim that there are moral dilemmas and to the\nclaim that the relevant principles in the two arguments are true. Thus\neach side must at least give reasons for denying the pertinent claims\nin question. Opponents of dilemmas must say something in response to\nthe positive arguments that are given for the reality of such\nconflicts. One reason in support of dilemmas, as noted above, is\nsimply pointing to examples. The case of Sartre’s student and that\nfrom Sophie’s Choice are good ones; and clearly these can be\nmultiplied indefinitely. It will tempting for supporters of dilemmas\nto say to opponents, “If this is not a real dilemma, then tell\nme what the agent ought to do and why?” It is\nobvious, however, that attempting to answer such questions is\nfruitless, and for at least two reasons. First, any answer given to\nthe question is likely to be controversial, certainly not always\nconvincing. And second, this is a game that will never end; example\nafter example can be produced. The more appropriate response on the\npart of foes of dilemmas is to deny that they need to answer the\nquestion. Examples as such cannot establish the reality of\ndilemmas. Surely most will acknowledge that there are situations in\nwhich an agent does not know what he ought to do. This may be because\nof factual uncertainty, uncertainty about the consequences,\nuncertainty about what principles apply, or a host of other things. So\nfor any given case, the mere fact that one does not know which of two\n(or more) conflicting obligations prevails does not show that none\ndoes. \n\nAnother reason in support of dilemmas to which opponents must\nrespond is the point about symmetry. As the cases from Plato and Sartre\nshow, moral rules can conflict. But opponents of dilemmas can argue\nthat in such cases one rule overrides the other. Most will grant this\nin the Platonic case, and opponents of dilemmas will try to extend this\npoint to all cases. But the hardest case for opponents is the\nsymmetrical one, where the same precept generates the conflicting\nrequirements. The case from Sophie’s Choice is of this sort.\nIt makes no sense to say that a rule or principle overrides itself. So\nwhat do opponents of dilemmas say here? They are apt to argue that the\npertinent, all-things-considered requirement in such a case is\ndisjunctive: Sophie should act to save one or the other of her\nchildren, since that is the best that she can do (for example,\nZimmerman 1996, Chapter 7). Such a move need not be ad hoc,\nsince in many cases it is quite natural. If an agent can afford to make\na meaningful contribution to only one charity, the fact that there are\nseveral worthwhile candidates does not prompt many to say that the\nagent will fail morally no matter what he does. Nearly all of us think\nthat he should give to one or the other of the worthy candidates.\nSimilarly, if two people are drowning and an agent is situated so that\nshe can save either of the two but only one, few say that she is doing\nwrong no matter which person she saves. Positing a disjunctive requirement in\nthese cases seems perfectly natural, and so such a move is available to\nopponents of dilemmas as a response to symmetrical cases. \n\nSupporters of dilemmas have a burden to bear too. They need to cast\ndoubt on the adequacy of the pertinent principles in the two arguments\nthat generate inconsistencies. And most importantly, they need to\nprovide independent reasons for doubting whichever of the principles\nthey reject. If they have no reason other than cases of putative\ndilemmas for denying the principles in question, then we have a mere\nstandoff. Of the principles in question, the most commonly questioned\non independent grounds are the principle that ‘ought’\nimplies ‘can’ and PD. Among supporters of dilemmas, Walter\nSinnott-Armstrong (Sinnott-Armstrong 1988, Chapters 4 and 5) has gone\nto the greatest lengths to provide independent reasons for questioning\nsome of the relevant principles. \n\nOne well-known argument for the reality of moral dilemmas has not\nbeen discussed yet. This argument might be called\n“phenomenological.” It appeals to the emotions that agents\nfacing conflicts experience and our assessment of those emotions. \n\nReturn to the case of Sartre’s student. Suppose that he joins the\nFree French forces. It is likely that he will experience remorse or\nguilt for having abandoned his mother. And not only will he experience\nthese emotions, this moral residue, but it is appropriate that he does.\nYet, had he stayed with his mother and not joined the Free French\nforces, he also would have appropriately experienced remorse or guilt.\nBut either remorse or guilt is appropriate only if the agent properly\nbelieves that he has done something wrong (or failed to do something\nthat he was all-things-considered required to do). Since no matter what\nthe agent does he will appropriately experience remorse or guilt, then\nno matter what he does he will have done something wrong. Thus, the\nagent faces a genuine moral dilemma. (The best known proponents of\narguments for dilemmas that appeal to moral residue are Williams 1965\nand Marcus 1980; for a more recent contribution, see Tessman 2015, especially Chapter 2.) \n\nMany cases of moral conflict are similar to Sartre’s example with regard to the agent’s reaction after acting. Certainly\nthe case from Sophie’s Choice fits here. No matter which of\nher children Sophie saves, she will experience enormous guilt for the\nconsequences of that choice. Indeed, if Sophie did not experience such\nguilt, we would think that there was something morally wrong with her.\nIn these cases, proponents of the argument (for dilemmas) from moral\nresidue must claim that four things are true: (1) when the agents\nacts, she experiences remorse or guilt; (2) that she experiences these\nemotions is appropriate and called for; (3) had the agent acted on the\nother of the conflicting requirements, she would also have experienced\nremorse or guilt; and (4) in the latter case these emotions would have\nbeen equally appropriate and called for (McConnell 1996,\npp. 37–38). In these situations, then, remorse or guilt will be\nappropriate no matter what the agent does and these emotions are\nappropriate only when the agent has done something wrong. Therefore,\nthese situations are genuinely dilemmatic and moral failure is inevitable for agents who face them. \n\nThere is much to say about the moral emotions and situations of\nmoral conflict; the positions are varied and intricate. Without\npretending to resolve all of the issues here, it will be pointed out\nthat opponents of dilemmas have raised two different objections to the\nargument from moral residue. The first objection, in effect, suggests\nthat the argument is question-begging (McConnell 1978 and Conee\n1982); the second objection challenges the assumption that remorse\nand guilt are appropriate only when the agent has done wrong. \n\nTo explain the first objection, note that it is uncontroversial that\nsome bad feeling or other is called for when an agent is in a\nsituation like that of Sartre’s student or Sophie. But the negative\nmoral emotions are not limited to remorse and guilt. Among these other\nemotions, consider regret. An agent can appropriately experience\nregret even when she does not believe that she has done something\nwrong. For example, a parent may appropriately regret that she must\npunish her child even though she correctly believes that the\npunishment is deserved. Her regret is appropriate because a bad state\nof affairs is brought into existence (say, the child’s discomfort),\neven when bringing this state of affairs into existence is morally\nrequired. Regret can even be appropriate when a person has no causal\nconnection at all with the bad state of affairs. It is appropriate for\nme to regret the damage that a recent fire has caused to my neighbor’s\nhouse, the pain that severe birth defects cause in infants, and the\nsuffering that a starving animal experiences in the wilderness. Not\nonly is it appropriate that I experience regret in these cases, but I\nwould probably be regarded as morally lacking if I did not. (For\naccounts of moral remainders as they relate specifically to Kantianism\nand virtue ethics, see, respectively, Hill 1996, 183–187 and\nHursthouse 1999, 44–48 and 68–77.) \n\nWith remorse or guilt, at least two components are present: the\nexperiential component, namely, the negative feeling that the\nagent has; and the cognitive component, namely, the belief\nthat the agent has done something wrong and takes responsibility for\nit. Although this same cognitive component is not part of regret, the\nnegative feeling is. And the experiential component alone cannot serve\nas a gauge to distinguish regret from remorse, for regret can range\nfrom mild to intense, and so can remorse. In part, what distinguishes\nthe two is the cognitive component. But now when we examine the case of\nan alleged dilemma, such as that of Sartre’s student, it is\nquestion-begging to assert that it is appropriate for him to experience\nremorse no matter what he does. No doubt, it is appropriate for him to\nexperience some negative feeling. To say, however, that it is\nremorse that is called for is to assume that the agent appropriately\nbelieves that he has done something wrong. Since regret is warranted\neven in the absence of such a belief, to assume that remorse is\nappropriate is to assume, not argue, that the agent’s\nsituation is genuinely dilemmatic. Opponents of dilemmas can say that\none of the requirements overrides the other, or that the agent faces a\ndisjunctive requirement, and that regret is appropriate because even\nwhen he does what he ought to do, some bad will ensue. Either side,\nthen, can account for the appropriateness of some negative moral\nemotion. To get more specific, however, requires more than is warranted\nby the present argument. This appeal to moral residue, then, does not by itself\nestablish the reality of moral dilemmas. \n\nMatters are even more complicated, though, as the second objection to\nthe argument from moral residue shows. The residues contemplated by\nproponents of the argument are diverse, ranging from guilt or remorse\nto a belief that the agent ought to apologize or compensate persons\nwho were negatively impacted by the fact that he did not satisfy one\nof the conflicting obligations. The argument assumes that\nexperiencing remorse or guilt or believing that one ought to apologize\nor compensate another are appropriate responses only if the agent\nbelieves that he has done something wrong. But this assumption is\ndebatable, for multiple reasons. \n\nFirst, even when one obligation clearly overrides another in a\nconflict case, it is often appropriate to apologize to or to explain\noneself to any disadvantaged parties. Ross provides such a case\n(1930, 28): one who breaks a relatively trivial promise in order to\nassist someone in need should in some way make it up to the promisee.\nEven though the agent did no wrong, the additional actions promote\nimportant moral values (McConnell 1996, 42–44). \n\nSecond, as Simon Blackburn argues, compensation or its like may be\ncalled for even when there was no moral conflict at all (Blackburn\n1996, 135–136). If a coach rightly selected Agnes for the team rather\nthan Belinda, she still is likely to talk to Belinda, encourage her\nefforts, and offer tips for improving. This kind of “making\nup” is just basic decency. \n\nThird, the consequences of what one has done may be so horrible as to\nmake guilt inevitable. Consider the case of a middle-aged man, Bill,\nand a seven-year-old boy, Johnny. It is set in a midwestern village on\na snowy December day. Johnny and several of his friends are riding\ntheir sleds down a narrow, seldom used street, one that intersects\nwith a busier, although still not heavily traveled, street. Johnny, in\nhis enthusiasm for sledding, is not being very careful. During his\nfinal ride he skidded under an automobile passing through the\nintersection and was killed instantly. The car was driven by\nBill. Bill was driving safely, had the right of way, and was not\nexceeding the speed limit. Moreover, given the physical arrangement,\nit would have been impossible for Bill to have seen Johnny\ncoming. Bill was not at fault, legally or morally, for Johnny’s\ndeath. Yet Bill experienced what can best be described as remorse or\nguilt about his role in this horrible event (McConnell 1996, 39). \n\nAt one level, Bill’s feelings of remorse or guilt are not\nwarranted. Bill did nothing wrong. Certainly Bill does not deserve to\nfeel guilt (Dahl 1996, 95–96). A friend might even recommend that Bill\nseek therapy. But this is not all there is to say. Most of us\nunderstand Bill’s response. From Bill’s point of view, the\nresponse is not inappropriate, not irrational, not uncalled-for. To\nsee this, imagine that Bill had had a very different response. Suppose\nthat Bill had said, “I regret Johnny’s death. It is a\nterrible thing. But it certainly was not my fault. I have nothing to\nfeel guilty about and I don’t owe his parents any\napologies.” Even if Bill is correct intellectually, it is hard\nto imagine someone being able to achieve this sort of objectivity\nabout his own behavior. When human beings have caused great harm, it\nis natural for them to wonder if they are at fault, even if to\noutsiders it is obvious that they bear no moral responsibility for the\ndamage. Human beings are not so finely tuned emotionally that when\nthey have been causally responsible for harm, they can easily\nturn guilt on or off depending on their degree of\nmoral responsibility. (See Zimmerman 1988, 134–135.) \n\nWork in moral psychology can help to explain why self-directed moral\nemotions like guilt or remorse are natural when an agent has acted\ncontrary to a moral norm, whether justifiably or not. Many moral\npsychologists describe dual processes in humans for arriving at moral\njudgments (see, for example, Greene 2013, especially Chapters 4–5, and\nHaidt 2012, especially Chapter 2). Moral emotions are automatic, the\nbrain’s immediate response to a situation. Reason is more like\nthe brain’s manual mode, employed when automatic settings are\ninsufficient, such as when norms conflict. Moral emotions are likely\nthe product of evolution, reinforcing conduct that promotes social\nharmony and disapproving actions that thwart that end. If this is\ncorrect, then negative moral emotions are apt to be experienced, to\nsome extent, any time an agent’s actions are contrary to what is\nnormally a moral requirement. \n\nSo both supporters and opponents of moral dilemmas can give an account\nof why agents who face moral conflicts appropriately experience\nnegative moral emotions. But there is a complex array of issues\nconcerning the relationship between ethical conflicts and moral\nemotions, and only book-length discussions can do them justice. (See\nGreenspan 1995 and Tessman 2015.) \n\nIn the literature on moral dilemmas, it is common to draw\ndistinctions among various types of dilemmas. Only some of these\ndistinctions will be mentioned here. It is worth noting that both\nsupporters and opponents of dilemmas tend to draw some, if not all, of\nthese distinctions. And in most cases the motivation for doing so is\nclear. Supporters of dilemmas may draw a distinction between dilemmas\nof type \\(V\\) and \\(W\\). The upshot is typically a message to\nopponents of dilemmas: “You think that all moral conflicts are\nresolvable. And that is understandable, because conflicts of type\n\\(V\\) are resolvable. But conflicts of type \\(W\\) are not\nresolvable. Thus, contrary to your view, there are some genuine moral\ndilemmas.” By the same token, opponents of dilemmas may draw a\ndistinction between dilemmas of type \\(X\\) and \\(Y\\). And\ntheir message to supporters of dilemmas is this: “You think that\nthere are genuine moral dilemmas, and given certain facts, it is\nunderstandable why this appears to be the case. But if you draw a\ndistinction between conflicts of types \\(X\\) and \\(Y\\), you\ncan see that appearances can be explained by the existence of type\n\\(X\\) alone, and type \\(X\\) conflicts are not genuine\ndilemmas.” With this in mind, let us note a few of the\ndistinctions. \n\nOne distinction is between epistemic conflicts and\nontological conflicts. (For different terminology, see\nBlackburn 1996, 127–128.) The former involve conflicts between two (or\nmore) moral requirements and the agent does not know which of the\nconflicting requirements takes precedence in her situation. Everyone\nconcedes that there can be situations where one requirement does take\npriority over the other with which it conflicts, though at the time\naction is called for it is difficult for the agent to tell which\nrequirement prevails. The latter are conflicts between two (or more)\nmoral requirements, and neither is overridden. This is not simply\nbecause the agent does not know which requirement is\nstronger; neither is. Genuine moral dilemmas, if there are any, are\nontological. Both opponents and supporters of dilemmas acknowledge\nthat there are epistemic conflicts. \n\nThere can be genuine moral dilemmas only if neither of the conflicting\nrequirements is overridden. Ross (1930, Chapter 2) held that all\nmoral precepts can be overridden in particular circumstances. This\nprovides an inviting framework for opponents of dilemmas to adopt.\nBut if some moral requirements cannot be overridden—if they hold\nabsolutely—then it will be easier for supporters of dilemmas to\nmake their case. Lisa Tessman has distinguished between negotiable\nand non-negotiable moral requirements (Tessman 2015, especially\nChapters 1 and 3). The former, if not satisfied, can be adequately\ncompensated or counterbalanced by some other good. Non-negotiable\nmoral requirements, however, if violated produce a cost that no one\nshould have to bear; such a violation cannot be counterbalanced by any\nbenefits. If non-negotiable moral requirements can conflict—and\nTessman argues that the can—then those situations will be\ngenuine dilemmas and agents facing them will inevitably fail morally.\nIt might seem that if there is more than one moral precept that holds\nabsolutely, then moral dilemmas must be possible. Alan Donagan,\nhowever, argues against this. He maintains that moral rules hold\nabsolutely, and apparent exceptions are accounted for because tacit\nconditions are built in to each moral rule (Donagan 1977, Chapters 3\nand 6, especially 92–93). So even if some moral requirements cannot\nbe overridden, the existence of dilemmas may still be an open\nquestion. \n\nAnother distinction is between self-imposed moral dilemmas\nand dilemmas imposed on an agent by the world, as it were.\nConflicts of the former sort arise because of the agent’s own\nwrongdoing (Aquinas; Donagan 1977, 1984; and McConnell 1978). If an\nagent made two promises that he knew conflicted, then through his own\nactions he created a situation in which it is not possible for him to\ndischarge both of his requirements. Dilemmas imposed on the agent by\nthe world, by contrast, do not arise because of the agent’s\nwrongdoing. The case of Sartre’s student is an example, as is the\ncase from Sophie’s Choice. For supporters of dilemmas, this\ndistinction is not all that important. But among opponents of\ndilemmas, there is a disagreement about whether the distinction is\nimportant. Some of these opponents hold that self-imposed dilemmas are\npossible, but that their existence does not point to any deep flaws in\nmoral theory (Donagan 1977, Chapter 5). Moral theory tells agents how\nthey ought to behave; but if agents violate moral norms, of course\nthings can go askew. Other opponents deny that even self-imposed\ndilemmas are possible. They argue that an adequate moral theory should\ntell agents what they ought to do in their current circumstances,\nregardless of how those circumstances arose. As Hill puts it,\n“[M]orality acknowledges that human beings are imperfect and often\nguilty, but it calls upon each at every new moment of moral\ndeliberation to decide conscientiously and to act rightly from that\npoint on” (Hill 1996, 176). Given the prevalence of wrongdoing,\nif a moral theory did not issue uniquely action-guiding\n“contrary-to-duty imperatives,” its practical import would be limited.  \n\nYet another distinction is between obligation dilemmas and\nprohibition dilemmas. The former are situations in which more\nthan one feasible action is obligatory. The latter involve cases in\nwhich all feasible actions are forbidden. Some (especially, Valentyne\n1987 and 1989) argue that plausible principles of deontic logic may\nwell render obligation dilemmas impossible; but they do not preclude\nthe possibility of prohibition dilemmas. The case of Sartre’s student,\nif genuinely dilemmatic, is an obligation dilemma; Sophie’s case is a\nprohibition dilemma. There is another reason that friends of dilemmas\nemphasize this distinction. Some think that the “disjunctive\nsolution” used by opponents of dilemmas—when equally\nstrong precepts conflict, the agent is required to act on one or the\nother—is more plausible when applied to obligation\ndilemmas than when applied to prohibition dilemmas. \n\nAs moral dilemmas are typically described, they involve a single\nagent. The agent ought, all things considered, to do \\(A\\),\nought, all things considered, to do \\(B\\), and she cannot do both\n\\(A\\) and \\(B\\). But we can distinguish\nmulti-person dilemmas from single agent ones. The two-person\ncase is representative of multi-person dilemmas. The situation is such\nthat one agent, P1, ought to do \\(A\\), a second agent, P2, ought\nto do \\(B\\), and though each agent can do what he ought to do, it\nis not possible both for P1 to do \\(A\\) and P2 to do\n\\(B\\). (See Marcus 1980, 122 and McConnell 1988.)\nMulti-person dilemmas have been called “interpersonal moral\nconflicts.” Such conflicts are most theoretically worrisome if\nthe same moral system (or theory) generates the conflicting\nobligations for P1 and P2. A theory that precludes single-agent moral\ndilemmas remains uniquely action-guiding for each agent. But if that\nsame theory does not preclude the possibility of interpersonal moral\nconflicts, not all agents will be able to succeed in discharging their\nobligations, no matter how well-motivated or how hard they try. For\nsupporters of moral dilemmas, this distinction is not all that\nimportant. They no doubt welcome (theoretically) more types of\ndilemmas, since that may make their case more persuasive. But if they\nestablish the reality of single-agent dilemmas, in one sense their\nwork is done. For opponents of dilemmas, however, the distinction may\nbe important. This is because at least some opponents believe that the\nconceptual argument against dilemmas applies principally to\nsingle-agent cases. It does so because the ought-to-do operator of\ndeontic logic and the accompanying principles are properly understood\nto apply to entities who can make decisions. To be clear,\nthis position does not preclude that collectives (such as businesses\nor nations) can have obligations. But a necessary condition for this\nbeing the case is that there is (or should be) a central deliberative\nstandpoint from which decisions are made. This condition is not\nsatisfied when two otherwise unrelated agents happen to have\nobligations both of which cannot be discharged. Put simply, while an\nindividual act involving one agent can be the object of choice, a\ncompound act involving multiple agents is difficult so to conceive.\n(See Smith 1986 and Thomason 1981.) Erin Taylor (2011) has recently argued\nthat neither universalizability nor the principle that ‘ought’ implies\n‘can’ ensure that there will be no interpersonal moral conflicts (what\nshe calls “irreconcilable differences”).\nThese conflicts would raise no difficulties if morality required\ntrying rather than acting, but such a view is not plausible. Still, moral theories should minimize cases of\ninterpersonal conflict (Taylor 2011, pp. 189–190).To the extent that\nthe possibility of interpersonal moral conflicts raises an intramural\ndispute among opponents of dilemmas, that dispute concerns how to\nunderstand the principles of deontic logic and what can reasonably be\ndemanded of moral theories. Another issue raised by the topic of moral dilemmas is the\nrelationship among various parts of morality. Consider this\ndistinction. General obligations are moral requirements that\nindividuals have simply because they are moral agents. That agents\nare required not to kill, not to steal, and not to assault are\nexamples of general obligations. Agency alone makes these precepts\napplicable to individuals. By contrast, role-related obligations are\nmoral requirements that agents have in virtue of their role,\noccupation, or position in society. That lifeguards are required to\nsave swimmers in distress is a role-related obligation. Another\nexample, mentioned earlier, is the obligation of a defense attorney to\nhold in confidence the disclosures made by a client. These categories\nneed not be exclusive. It is likely that anyone who is in a position\nto do so ought to save a drowning person. And if a person has\nparticularly sensitive information about another, she should probably\nnot reveal it to third parties regardless of how the information was\nobtained. But lifeguards have obligations to help swimmers in\ndistress when most others do not because of their abilities and\ncontractual commitments. And lawyers have special obligations of\nconfidentiality to their clients because of implicit promises and the\nneed to maintain trust. General obligations and role-related obligations can, and sometimes\ndo, conflict. If a defense attorney knows the whereabouts of a\ndeceased body, she may have a general obligation to reveal this\ninformation to family members of the deceased. But if she obtained\nthis information from her client, the role-related obligation of\nconfidentiality prohibits her from sharing it with others. Supporters\nof dilemmas may regard conflicts of this sort as just another\nconfirmation of their thesis. Opponents of dilemmas will have to hold\nthat one of the conflicting obligations takes priority. The latter\ntask could be discharged if it were shown that one these two types of\nobligations always prevails over the other. But such a claim is\nimplausible; for it seems that in some cases of conflict general\nobligations are stronger, while in other cases role-related duties\ntake priority. The case seems to be made even better for supporters\nof dilemmas, and worse for opponents, when we consider that the same\nagent can occupy multiple roles that create conflicting requirements.\nThe physician, Harvey Kelekian, in Margaret Edson’s (1999/1993)\nPulitzer Prize winning play, Wit, is an oncologist, a medical\nresearcher, and a teacher of residents. The obligations generated by\nthose roles lead Dr. Kelekian to treat his patient, Vivian Bearing, in\nways that seem morally questionable (McConnell 2009). At first blush,\nanyway, it does not seem possible for Kelekian to discharge all of the\nobligations associated with these various roles. In the context of issues raised by the possibility of moral\ndilemmas, the role most frequently discussed is that of the political\nactor. Michael Walzer (1973) claims that the political ruler, qua\npolitical ruler, ought to do what is best for the state; that is his\nprincipal role-related obligation. But he also ought to abide by the\ngeneral obligations incumbent on all. Sometimes the political\nactor’s role-related obligations require him to do\nevil—that is, to violate some general obligations. Among the\nexamples given by Walzer are making a deal with a dishonest ward boss\n(necessary to get elected so that he can do good) and authorizing the\ntorture of a person in order to uncover a plot to bomb a public\nbuilding. Since each of these requirements is binding, Walzer\nbelieves that the politician faces a genuine moral dilemma, though,\nstrangely, he also thinks that the politician should choose the good\nof the community rather than abide by the general moral norms. (The\nissue here is whether supporters of dilemmas can meaningfully talk\nabout action-guidance in genuinely dilemmatic situations. For one who\nanswers this in the affirmative, see Tessman 2015, especially Chapter\n5.) Such a situation is sometimes called “the dirty hands\nproblem.” The expression, “dirty hands,” is taken\nfrom the title of a play by Sartre (1946). The idea is that no one\ncan rule without becoming morally tainted. The role itself is fraught\nwith moral dilemmas. This topic has received much attention recently.\nJohn Parrish (2007) has provided a detailed history of how\nphilosophers from Plato to Adam Smith have dealt with the issue. And\nC.A.J. Coady (2008) has suggested that this reveals a “messy\nmorality.” For opponents of moral dilemmas, the problem of dirty hands\nrepresents both a challenge and an opportunity. The challenge is to\nshow how conflicts between general obligations and role-related\nobligations, and those among the various role-related obligations, can\nbe resolved in a principled way. The opportunity for theories that\npurport to have the resources to eliminate dilemmas—such as\nKantianism, utilitarianism, and intuitionism—is to show how the many\nmoralities under which people are governed are related. \n\nDebates about moral dilemmas have been extensive during the last six\ndecades. These debates go to the heart of moral theory. Both\nsupporters and opponents of moral dilemmas have major burdens to bear.\nOpponents of dilemmas must show why appearances are deceiving. Why are\nexamples of apparent dilemmas misleading? Why are certain moral\nemotions appropriate if the agent has done no wrong? Supporters must\nshow why several of many apparently plausible principles should be\ngiven up—principles such as PC, PD, OP, D, ‘ought’\nimplies ‘can’, and the agglomeration principle. And each\nside must provide a general account of obligations, explaining whether\nnone, some, or all can be overridden in particular circumstances.\nMuch progress has been made, but the debate is apt to continue.","contact.mail":"tcmcconn@uncg.edu","contact.domain":"uncg.edu"}]
