[{"date.published":"2019-03-04","url":"https://plato.stanford.edu/entries/logics-for-games/","author1":"Johan van Benthem","author1.info":"http://staff.science.uva.nl/~johan/","author2.info":"http://dominikklein.dk/","entry":"logics-for-games","body.text":"\n\n\nIn light of logic’s historical roots in dialogue and\nargumentation, games and logic are a natural fit. Argumentation is a\ngame-like activity that involves taking turns, saying the right things\nat the right time, and, in competitive settings, has clear pay-offs in\nterms of winning and losing. Pursuing this connection, specialized\nlogic games have already been used in the middle ages as a tool for\nlogic training (Hamblin 1970). The\nmodern area augmented this picture with formal dialogue games as\nfoundation for logic, relating winning strategies in argumentation to\ncogent proofs (Kamlah 1973 [1984]).\nToday, connections between logic and game theory span across a great\nnumber of different strands, involving the interface with game theory,\nbut also linguistics, computer science, and further fields.\n\n\nThemes from the extensive and growing area surrounding logic and games\noccur in various entries of this Encyclopedia, in particular on\n uses of games in logic,\n epistemic foundations of game theory,\n formal approaches to social procedures,\n logics for analyzing powers of agents, and\n game semantics for programming and process languages.\n These entries differ in their emphasis, which may be on logic, game\ntheory, or foundations of computer science. The present entry is\nconcerned with logics for analyzing games, broadly speaking. It makes\nreference to other perspectives in this Encyclopedia where\nrelevant.\n\nThe present entry provides a comprehensive survey of logics for\nanalyzing games, arranged under a number of unifying themes and\nperspectives. Also, occasional connections are made with other strands\nat the interface of logic and games covered elsewhere in this\nEncyclopedia. This overview section is a brief tour\nd’horizon for topics that will return in more detail later\non. \nSpecific games stand for significant recurrent patterns of social\ninteraction. In a perspective called ‘logic of games’,\nnotions and results from logic are used to analyze the structure of\nvarious games. In fact, much classic reasoning about games involves\nnotions that are familiar from logic. \nExample Game solution reasoning. \nConsider the following game tree for two players A, E,\nwith turns marked, and with pay-offs written with the value for\nA first. Alternatively, these values can be interpreted as\nencoding players’ qualitative (or ordinal) preferences between\noutcomes. \nFigure 1. \n ⓘ \nHere is how players might reason. At her turn, E faces a\nstandard decision problem, with two available actions and the outcome\nof action left better for her than that of right. So\nshe will choose left. Knowing this, A expects that his choosing\nright will give him outcome 0, while going left\ngives him outcome 1, so he chooses left. As a result, both players are\nworse off than they would have been, had they played\nright/right. The reasoning in this scenario, in\nshort, leads to an outcome that is not Pareto-optimal. \nThe example raises the question just why players should act this way,\nand whether, say, a more cooperative behavior could also be justified.\nAn answer obviously depends on the players’ information and\nstyle of reasoning. Here it becomes of interest to probe the structure\nof the example. Looking more closely, many notions are involved in the\nabove scenario: actions and their results, players knowledge about the\nstructure of the game, their preferences about its results, but also\nhow they believe the game will proceed. There are even counterfactual\nconditionals in the background, such as A’s explaining\nhis choice afterwards by saying that “if I had played\nright, E would have played left”.\nThese notions, moreover, are entangled in subtle ways. For instance,\nA does not choose left because it dominates\nright in the standard sense of always being better for him,\nbut rather because left dominates right according to\nhis beliefs. How these beliefs are formed, in turn, depends on many\nother features of the game, including the nature of the players. \nIn short, even a very simple game like the one discussed brings\ntogether large parts of the agenda of philosophical logic in one very\nconcrete setting. This entry will zoom in on the aspects mentioned\nhere, with\n Section 3\n dedicated to players’ preferences and beliefs, while\n Section 4\n addresses reasoning styles and the dynamics of attitudes as the game\nproceeds. \nThe analysis is structured by a few broad distinctions. Intuitively,\ngames involve several phases that involve logic in different ways:\ndeliberation prior to the game, as many game-theoretic solution\nconcepts are in fact deliberation procedures that create initial\nexpectations about how a game will go on. Observation and belief\nrevision during game play, including reactions to deviations from\nprior expectations. And finally, post-game analysis, say, to settle\nwhat can be learnt from a defeat, or to engage in spin about\none’s performance. Moreover all this can be considered in two\nmodes, assuming either a first-person participant or a third-person\nobserver view of games and play. \nIn many of the above topics, logics meets game theory. One such\ninterface area is\n epistemic game theory\n where game play and solution concepts are analyzed and justified in\nlight of various assumptions about players and their epistemic states,\nsuch as common knowledge or common belief in rationality. Epistemic\ngame theory may be viewed as a joint offspring of logic and game\ntheory, a form of progeny which constitutes a reliable sign of success\nof an interdisciplinary contact. \nThere are also other viable logical perspectives. In particular, one\ncan look at game theory the way mathematical logicians look at any\nbranch of mathematics. Following the style of the famous Erlangen\nProgram, one can discuss the structures studied in that field and look\nfor structural invariance relations and matching logical languages.\nGame theory is rich in structure, as it has several different natural\nnotions of invariance. The tree format of extensive games offers a\ndetailed view of what happens step by step as players make their\nmoves, whereas the matrix format of strategic form games offers a\nhigh-level view that centers on outcomes. Yet other formats, to be\ndiscussed below, focus on players’ control over the various\noutcomes. All these different levels of game structure come with their\nown logical systems, as will be detailed in\n Section 2.\n Moreover, these different logics do not just provide isolated\nsnapshots: they can be related in a systematic manner. \nIn this way, the usual logical techniques can be brought to bear. For\ninstance, formal languages can express basic properties of games,\nwhile model-checking techniques can determine efficiently whether\nthese hold in given concrete games (cf. Clarke,\nGrumberg, & Peled 1999). \nExample Winning strategies. \nConsider the following game tree, with move relations for both\nplayers, and propositional letters \\(\\win_{i}\\) marking winning\npositions for player i. \nFigure 2.\n ⓘ \nClearly, player E has a winning strategy against player\nA, i.e., a recipe that guarantees her to win, no matter what\nA does. This is expressed by a modal formula capturing exactly\nthe right dynamics: \nHere \\([\\move_A]\\) is the universal modality “for all moves by\nplayer A\", and \\(\\langle \\move_E\\rangle\\) is the existential\nmodality “for some move by player E\". This two-step\nmodality- or quantifier-based response pattern is typical for\nstrategic powers of players in arbitrary games, as it captures the\nessence of sequential interaction. Crucially, logical laws can acquire\ngame-theoretic import. For instance, the law of Excluded Middle\napplied to the above formula yields: \nor in a logically equivalent formulation: \nIn two-step games like the above, where exactly one player wins (i.e.,\n\\(\\win_A\\leftrightarrow\\neg\\win_E\\)), the latter formula expresses\nthat either player E or player A has a winning strategy.\nMore generally, this disjunctive assertion is a special case of\nZermelo’s theorem, stating that every finite full information\ngame is determined. \nHaving established the connection to logical languages, further\nmodel-theoretic themes can be applied fruitfully to games. Language\nbased reasoning allows, for instance, to examine the preservation of\nproperties between different games, based on the exact syntactic shape\nof their definition. Besides, logical syntax also supports logical\nproof theory. Hence, the latter’s rich pool of proof calculi may\nhelp to analyze basic results in game theory. This entry illustrates\nmajor recurring patterns of reasoning about interaction that come to\nlight in this way. \nGame theory also has a further natural level of representation,\nsuppressing details of local moves and choices. The most familiar\nformat for this are games in strategic form. In the simplest\ncase of only two players, these correspond to a two-dimensional\nmatrix, with rows standing for some player’s strategies, and\ncolumns for the other’s. Individual cells of such matrix hence\ncorrespond to the different possible strategy profiles of the\ngame. Typically, all cells are labeled with information about the\noutcomes resulting from playing the corresponding strategies\nagainst one another. This labeling specifies players’ attitudes\nto outcome in terms of pay-offs, more abstract utilities, or ordinal \nmarkers for players’ preferences orders among outcomes. \nStrategic form games, too, can model significant social scenarios.\nHere is an illustration from the philosophical literature on the\nevolution of social behavior. \nExample The following game in matrix\nform is the Stag Hunt of Skyrms\n(2003), going back to ideas of David Hume. It serves as a\nmetaphor for the social contract. \nEach agent must decide between pursuing their own little project,\nhunting a hare, or joining in a larger collective endeavor, hunting\nstag. The former gives a moderate but guaranteed income, no matter\nwhat others do. The collective endeavor, on the other hand, can only\nsucceed if all contribute, in which case everybody receives a high\nprofit. If, however, some do not join, all contributions are lost and\nno contributor receives anything. In the corresponding strategic form\ngame, all players have to decide on what to do in parallel, without\nknowing the actions of others. \nThe Stag Hunt game has two pure strategy Nash equilibria: every\ncontributes, and nobody contributes. Which of these\nstable outcomes ensues will crucially depend on the players’\nreasoning, their expectations about each other, and perhaps even\nfurther information stemming, for instance, from pre-game\ncommunication. \nClearly, analyzing strategic games involves agentive information,\nreasoning and expectations. All these aspects have tight connections\nto logic. Viewing outcomes as possible worlds, three relevant\nrelations emerge between these. Within the matrix above, relating all\ncells in the same row fixes a unique choice already made by the row\nplayer A, while leaving E’s move completely open.\nIn short, each horizontal row lists all possible choices of the column\nplayer E which A has to take into account. The\ncorresponding modality may hence be said to describe A’s\nknowledge about the outcomes of the game given his choice. Still\nassuming the row player’s perspective, relating cells vertically\nrather than horizontally corresponds to A’s freedom of\nchoice among his available strategies. Of course, one could also\nassume player E’s perspective instead, viewing the\nhorizontal direction as E’s freedom of movement, while\nthe vertical directions captures her epistemic uncertainty. \nThus, a bimodal logic arises for matrix games with laws such as \ncapturing the grid structure of matrix games. For more than two\nplayers, this logic gains some additional options and subtleties to be\ndiscussed in\n Section 2.6. \nThe crucial third relation is that of player’s preferences among\noutcomes. These, again, have matching modalities, now taken from\npreference logic (Hansson 2001). With\nthe help of some auxiliary devices, the three modalities can define\nthe central game-theoretic notion of a Nash equilibrium (Harrenstein\n2004; van der Hoek & Pauly\n2007). \nLogics for matrix games differ from those for extensive games, as\ngrids behave quite differently from trees in terms of complexity. Yet,\nboth fall under the same general methodology. Towards a common\nunderstanding, one might view the logic of matrix games as capturing\nthe basic laws of parallel, rather than sequential action. \nPhilosophical logic and mathematical logic are not the only\nilluminating perspectives on games. A third relevant viewpoint is that\nof computational logic. In modern computation, the paradigm is no\nlonger single Turing machines but interacting systems of multiple\nprocessors. These processors may cooperate, but they might also\ncompete for resources. In general, hence, it is useful to study\nmultiple agents engaging in computation, be it within human,\nartificial or mixed societies. Though doing so, games become a natural\nmodel for computation, too. In fact, games are rich multi-agent\nsystems where agents process information, communicate, and engage in\nactions, all driven by their respective preferences and goals. In the\nconverse direction, computer science themes such as complexity and\nalgorithmics have entered game theory, resulting in the area of \ncomputational game theory (Nisan et al.\n2007). For a richer survey of computational logics of agency\nand games, see van der Hoek and Pauly\n(2007) and Shoham and Leyton-Brown\n(2008). The present entry contains occasional links to\ncomputation. These are especially prominent for reasoning about\ntemporally extended games and their strategies (Sections\n 4.2,\n 4.4) and in the context of gamification\n (Section 6),\n where games are explored as a novel semantics for classical logical\nsystems. \nFinally, recall the start of this section, but with reverse\nperspective: instead of asking what logic can do for games, ask what\ngames can do for logic. Argumentation and dialogue are basic notions\nfor logic. Both can be studied using techniques and results from game\ntheory (Lorenzen & Lorenz 1978; Hamblin\n1970). In this perspective, logical validity of consequence\nrests on there being a winning strategy for a Proponent claiming the\nconclusion against an Opponent granting the premises in a game where\nmoves are regulated by the logical constants. Many games have found\nuses in modern logic since the 1950s, with\nEhrenfeucht-Fraïssé games for model comparison being a\nparadigmatic example. Besides these, also semantic verification or\nmodel construction can be cast as\n natural logic games. \nThis raises an intricate issue within in the philosophy of logic,\nconcerning the nature of logic and in particular that of logical\nconstants. A ‘weak thesis’ would hold that games\nconstitute a natural technique for analyzing logical notions, as well\nas a didactic tool for teaching logic that appeals directly to vivid\nintuitions. Parts of the literature, however, also defend a\n‘strong thesis’, suggesting that the primary semantics of\ncertain logical systems may be procedural and game-theoretic, rather\nthan denotational in a standard sense. This perspective, sometimes\ncalled ‘logic as games’, occurs in some attractive\nsemantics for first-order languages (Hintikka\n& Sandu 1997), as well as in\n game semantics for programming languages. \nThe theme of logic as games will appear only briefly in the present\nentry, which is mainly directed toward logics of games.\n Section 6\n will discuss which questions arise from joining both perspectives on\nthe interface of logic and games. \nAs it happens, the logic-as-games perspective is of broader relevance.\nLogic games were originally designed for particular tasks inside\nlogic. Yet, taken to reality, they can help analyze or streamline\nactual lines of argumentation. As such they may be compared to\ndesigned parlor games that challenge reasoning skills. A game like\nClue involves an intriguing mix of logical deduction, new\ninformation from drawing cards or public observation of moves, but\nalso private communication acts by players (van\nDitmarsch 2000). Other parlor games, such as Nine Men\nMorris (Gasser 1996) are graph\ngames (Grädel, Thomas, & Wilke\n2002) with added chance moves that serve to diminish the risk\nof finding a repeatable simple strategy on the fixed board. The\nlogical study of playable designed games for bounded agents, and the\ndesign of new such games, is a natural sequel to this entry (cf.\nvan Benthem & Liu 2019). \nGame theory may be understood as generalized interactive decision\ntheory. A major vehicle for the latter, just as for standard decision\ntheory, is probability theory. Within games, probability can assume\nmany roles. It may, for instance, express players’ degrees of\nbelief quantitatively, but it can also enrich the space of actions\nwith mixed strategies, thereby laying the ground for general\nequilibrium results. Probability can even play a role in the very\ndefinition of certain important games, especially in evolutionary game\ntheory (Osborne & Rubinstein 1994).\nIn this entry, probability is only mentioned in passing.\n Section 5,\n however, maps some combinations of logic and probability that are\nsuggested by the study of games. \nGames have a natural interface with logic in all its varieties,\nincluding mathematical, philosophical, and computational logic. In one\ndirection of contact, logic can provide new abstract notions\nunderneath game theory. Conversely, game-theoretic notions can also\nserve to enrich logical analysis. The present entry mainly\nconcentrates on the first of these directions, the use of logic for\nanalyzing games. It does so mostly from a semantic perspective, the\ndominant paradigm so far in the area. Though proof-theoretic\napproaches will be mentioned occasionally. The sections to follow\nelaborate on this theme along several dimensions. Specific\nperspectives include logics for game structures\n (Section 2),\n logical analysis of the nature of players\n (Section 3)\n and of the process of game play\n (Section 4).\n Additional spotlights are put on the relationship between logic and\nprobability in the context of games\n (Section 5)\n and the endeavor of Gamification\n (Section 6).\n Each section forms a free-standing exposition, which results in some\nunavoidable, and perhaps useful, overlap. Throughout the exposition,\nsome familiarity is assumed with the basic concepts of logic and game\ntheory. In particular, notions of game theory left unexplained here\ncan be found in the corresponding\n entry\n and in Leyton-Brown and Shoham\n(2008). \nThis first spotlight section focuses on game structures in a narrow\nsense. Game forms leave aside agents and notions typical for\nthese, such as preferences or information. Players, as well as the\ntemporal progression of play will be added in later sections. Even so,\nthere is already a good deal of structure in game forms to be studied by\nlogical techniques. \nThe starting point of any logical analysis is to fix its perspective\non games. This section will review several major candidates for doing\nso, starting with the two most prominent perspectives. The first of\nthese makes the temporal structure of a game explicit, representing it\nas a tree in the standard mathematical sense. \nExample A two-player extensive form\ngame. \nFigure 3.\n ⓘ \nA game in extensive form is a tree where each non-terminal\nnode or state specifies which player is to move next, while\nedges correspond to the players’ possible moves. The leaves of\nthe tree, finally, denote the possible outcomes O of game play.\nThere are many possible variations on these stipulations for states\nand moves, but they do not affect the essentials of a logical\nanalysis. \nThe second major perspective on games emphasizes the players’\navailable strategies. Suppressing all information about temporal\nstructure, a game in strategic form yields the matrix\npictures known from game theory. In its classic interpretation, a game\nin strategic form represents a set of players that each select a\ncomplete strategy for the entire game without knowledge of the other\nplayers’ choices. Each strategy profile, i.e., combination of\none strategy per player, then induces an outcome \\(O_i\\). The\nmotivation for this structure might seem complex on first sight. Yet,\nit can also be viewed as something quite simple: a one-step game with\nparallel rather than sequential moves, which is the simplest case of\nsimultaneous action. \nExample A two-player strategic form\ngame. \nExtensive and strategic forms differ in their focus. The former\nemphasize the sequential temporal structure of a game, while the\nlatter highlights strategy choice prior to play. One can freely switch\nbetween both when appropriate to the purpose at hand. Besides these\ntwo, there are other natural dimensions, highlighting players’\npowers for influencing outcomes (cf.\n Section 2.5)\n or players’ information about the game (cf.\n Section 3.6). \nRemark While all examples so far\nconcerned two-player games, no such restriction is needed. Both\nextensive games and strategic form games work for any number of\nplayers, although occasional subtleties may occur. A few will be\nmentioned below. Moreover, with more players, possible coalitions\nenter the picture, a topic that will not be treated in this entry.\nFinally, selected aspects of agency may sometimes enter through the\nback door. Many scenarios in real life contain external chance events\noutside of any player’s control, such as a roll of a die,\nweather conditions, or technical malfunctions. Such factors can\nusually be incorporated into a logical analysis by admitting Nature as\nadditional player. \nWith different ways of representing a game at hand, there is a natural\nfollow up question concerning equivalence. Given two game structures,\nwhen are they representations of the same underlying game? The answer\nis that it very much depends on what aspects one is interested in. \nExample The same game, or not? \nFigure 4.\n ⓘ \nConsider the two game forms above. If one cares about exact sequences\nof moves or the choices players have along the way, these games are\ndifferent. The game to the left has A move first, while\nE begins in the game on the right. In the game on the right,\nA may face a choice between p and q. This cannot\nhappen on the left. \nCaring about exact moves as done here constitutes a fine-grained\nperspective on games. There are others. When focusing on\nplayers’ powers for bringing about certain outcomes, for\ninstance, the analysis changes. In the game on the left, A has\na strategy (playing left) that ensures the game to end up in\nan outcome satisfying p, and one (playing right) that\nrestricts possible outcomes to those satisfying \\(q \\lor r\\). With\nthis second strategy, the further choice which of \\(q or r\\) gets\nrealized is left up to player E. Also the second player,\nE, has two strategies in the game on the left, one (playing\nleft) ensuring the outcome to satisfy \\(p\\lor q\\), the other\n(playing right) guaranteeing that the outcome satisfies \\(p\n\\lor r\\). \nPerforming the same calculations for the game on the right, virtually\nthe same player powers emerge. More precisely, A’s\nuniform strategies left-left and right-right yield\np and \\(q\\lor r\\) respectively, exactly the same powers as in\nthe left game. The two remaining strategies left-right and\nright-left yield \\(p\\lor q\\) and \\(p\\lor r\\), both of which\nare mere weakenings of A’s power to achieve p.\nThus, at the level of players’ powers, the above two game forms\nshould be considered the same. \nAs this example illustrates, there are several legitimate ways of\ncomparing games. When taking a fine-grained focus on the internal\nstructure of a game, a natural candidate is the notion of a\nbisimulation (cf. Blackburn, de Rijke,\n& Venema 2001). A bisimulation \\(Z\\subseteq G_1\\times G_2\\)\nrelates states of two game forms \\(G_1\\) and \\(G_2\\) subject to four\nconditions: States m and n may only be related when\n(i) the same player is to move in m and n,\n(ii) m and n do not differ in any of their\nbasic local properties, while (iiia) whenever there is an\navailable move of type a in \\(G_1\\) leading to a state \\(m'\\),\nthere is a matching available move of type a in \\(G_2\\) leading\nto a state \\(n'\\) with \\(m'Zn'\\), and vice versa (iiib)\nwhenever there is a move in \\(G_2\\) that leads to a state \\(n'\\),\nthere there is a move of the same type in \\(G_1\\) leading to a state\n\\(m'\\) with \\(m'Zn'\\). \nExample A bisimulation between\ngames. \nFigure 5.\n ⓘ \nThis particular notion of bisimulation is not the only invariance that\nmakes sense for games. A more coarse-grained perspective, for\ninstance, might not distinguish moves by their particular action\ntypes, but merely by which player is to perform them. A corresponding\nbisimulation can be defined by omitting references to particular\naction types in conditions (iiia) and (iiib)\nabove. \nFurther notions of bisimulation take an even coarser perspective on\nthe games’ move structure, for instance by allowing to contract\nzones where the same player moves several times in a row. Finally,\ndropping all information about players and their choices, games can be\ncompared by the sequences of moves they admit. This purely\nobservational notion, known as trace equivalence in\ncomputation, may, however, be less relevant in the context of games.\nAn alternative approach to coarsening focuses on the players’\npowers to control outcomes, cf.\n Section 2.5 and van Benthem, Bezhanishvili and Enqvist (forthcoming-a). \nWhile most notions of invariance discussed so far related to extensive\nform games, a similar style of analysis applies to games in strategic\nform. Van Benthem, Pacuit, and Roy\n(2011) define modal bisimulations that connect outcome states\nof different matrices, and apply bisimulation’s back-and-forth\nconditions to the relevant relations of players’ choice,\nfreedom, and preference. \nThis may be a good point to stress once more that the present section\nis concerned with game forms only, omitting any player related aspect\nsuch as preferences between outcomes. When these are added,\nidentifying appropriate notions of invariance becomes more\nchallenging, as will be discussed in\n Section 3\n below. \nThe choice of invariance relations mirrors which structure is deemed\nrelevant within a given perspective on games. A central tool for\nbringing out such relevant aspects is the existence of a logical\nlanguage matching some invariance relation. In general, the more\nfine-grained the invariance perspective, the more distinctions a\nmatching language should be able to make. \nFor a start, if one is interested in the properties a player can bring\nabout through moves, a good choice of language is based on modalities\n\\(\\langle \\move_i\\rangle \\varphi\\), expressing that at least one of\ni’s available moves leads to a next stage satisfying\n\\(\\varphi\\). The following illustrates how this language works in a\ngiven extensive form game. \nExample Modal game language. \nFigure 6.\n ⓘ \nThe modal formula \\([\\move_A]\\langle \\move_E\\rangle \\win_E\\), true at\nroot r, expresses that E has a strategy that ensures her\na win in two steps: whatever A does, E can react in such\na way that she ends up in a node where she wins. In a more\nfine-grained perspective, the modal language could add expressions\n\\([a],[b]\\ldots\\) for specific move types \\(a,b,\\ldots\\). In this\nlanguage, the coarse-grained modality \\(\\langle \\move_i\\rangle\n\\varphi\\) is definable by the disjunction \\(\\bigvee_{a\\text{ is a move\nfor }i}\\langle a \\rangle\\varphi\\), making the new language a\nrefinement of the old. \nIn this way, general results of modal logic apply to games. For\ninstance, take pointed models such as game trees with an indicator for\nthe current moment. Whenever two such pointed models \\(\\G,m\\) and\n\\(\\G',m'\\) are bisimilar in the first sense defined above, the\nequivalence \\(\\G, m\\vDash\\varphi\\) iff \\(\\G', m'\\vDash\\varphi\\) holds\nfor all formulas \\(\\varphi\\) in a sufficiently rich modal language\nwith modalities \\([a]\\) for each move label. Thus, one can switch\nbetween syntactic, language based perspectives and semantic invariance\nrelations, depending on what is convenient for a given perspective on\ngames. Entirely similar points hold for bisimulations and modal\nlanguages for power perspectives, or for strategic form games. \nFinally, modal languages do not have exclusive rights. If still more\nfine-grained perspectives are needed, more expressive first-order or\nhigher-order languages become serious contenders for describing\ngames. \nA language for games facilitates both, defining properties of games\nand reasoning about them. An example are winning strategies for\nplayers in a two-step extensive game as just discussed. More\ngenerally, for any finite extensive game, there are formulas\n\\(\\varphi_j\\) for each agent j that are true iff j has a\nwinning strategy: \nwhere the number of operators in the formula corresponds to the depth\nof the tree. \nThus, logical laws governing reasoning with such formulas acquire\ngame-theoretic content. For instance, the negation of the statement\nthat one player, A, has a winning strategy is provably\nequivalent to saying that the other player, E, has a winning\nstrategy, at least in those cases where A wins if and only if\nE does not:  \nHence, the logical law of excluded middle in its modal guise\ncorresponds to Zermelo’s theorem, stating determinacy for finite\ngames. \nYet, there are limitations to such characterizations of game-theoretic\nproperties in terms of logical laws. Formulas stating whether some\nplayer has a winning strategy change from model to model, as the\nnumber of modal operators depends on the size of the game tree. In\nfact, there is no uniform formula in the basic modal language\nexpressing that player i can win in an arbitrary finite\nextensive form game. Such a formula can only be found in the modal\nμ-calculus (Venema 2008), where the\nstatement that i has winning strategy can be expressed with the\nfixed-point formula  \nThe more general point here is that the recursive nature of\ngame-theoretic equilibria and solution concepts reflects naturally in\nlogics with fixed-point operators for induction and recursion. \nIn this setting, known results about modal logic acquire a new\nsignificance. In the realm of finite models, for instance, having the\nsame modal formulas true at two states is equivalent to there\nbeing a bisimulation connecting those two states (cf.\nBlackburn, de Rijke, & Venema 2001).\nHence, whenever two finite games satisfy the same modal propositions\nin their respective roots they are equivalent in the sense of\nbisimulation. For infinite models, such results are less direct. A\nfull equivalence between bisimulation and satisfying the same\nformulas, for instance, only holds for an extended modal language with\ninfinite conjunctions and disjunctions. Other relevant results include\nthe existence of modal formulas that define given pointed models up to\nbisimulation. Such formulas sometimes exist in the basic modal\nlanguage, sometimes in the μ-calculus, and always in the infinitary\nmodal language. Applied to concrete games G, these modal\ndefinitions can be viewed as complete descriptions of all properties\nof G at the relevant level of invariance. \nFinally, modal logic has many complete proof systems for capturing the\nvalid consequences on various classes of models (Blackburn,\nde Rijke, & Venema 2001).\nThese calculi of reasoning also apply to games, where they can capture\naspects of specialized game-theoretic argumentation. Proof-theoretic\nperspectives are not the focus of this entry, but a number of strands\nwill be mentioned where appropriate. \nBesides extensive form games, standard modal logic is also suitable\nfor the power perspective on game structure. Sometimes, one ignores\nthe internal mechanisms of a game altogether, merely viewing it as a\nblack box social mechanisms where players control outcomes to a\ncertain extent. In this perspective, a player can force the\noutcome of the game to be in some set X if she commands a\nstrategy that ensures the game to end up in an outcome of X, no\nmatter what the other players do (van\nder Hoek & Pauly 2007). Similarly, a player can force that\nsome proposition \\(\\varphi\\) holds if she has the power to enforce\nthat the game ends in a \\(\\varphi\\) state. The collection of all sets\nof outcomes an agent can force are often called her forcing\npowers. In classical game theory, these forcing powers sometimes\ngo by the name of effectivity functions (Peleg\n1997), which are often also studied for\ncoalitions of players (see Pauly 2001; Goranko,\nJamroga, & Turrini 2013; and the entry on\n logics for analyzing power in normal form games). \nExample Powers in extensive games. \nFigure 7.\n ⓘ \nNotably, forcing powers are not closed under conjunction. In the game\nabove, agent A can force p and q individually\nwithout being able to force \\(p \\land q\\). In modal logic terms,\nforcing powers give rise to a neighborhood logic (Pacuit\n2017), where the neighborhood\nfunctions list the set of outcomes players can enforce from a given\nstate. Reasoning about forcing powers can then employ a logical\nlanguage with forcing modalities \\(\\{i\\}\\) for each player: \n\\(\\{i\\}\\varphi\\): agent i can force the outcome of the game to\nsatisfy \\(\\varphi\\).  \nThese modalities can be interpreted over the extended game forms with\nneighborhood functions described above. On the semantic side, a\ngeneralization of the above neighborhood models support a\ngeneralized notion of power bisimulation, see van\nBenthem, Pacuit, and Roy (2011). \nThe modal logic of powers allows to reason about games at a global\nlevel of description. The modal logic of neighborhood models validates\nthe standard modal monotonicity principle as follows\nalready from the truth definition of forcing modalities. However, as\nforcing powers are not closed under intersection, the aggregation law\nfails: \nInstead, the logic contains new valid principles relating forcing\nmodalities for different players. For instance, if i can force\nthe truth of \\(\\varphi\\), then no other player j can force its\nfalsity. Thus, \nis a valid principle of ‘consistency of powers’ in the\nlogic of forcing powers. The converse of this principle for games with\ntwo players \\(i, j\\) \nexpresses the notion of determinacy from the last section. This\nformula is not generally valid, but is an axiom for the special\nclass of determined games. \nFinally, there also is an alternative, more algebraic perspective on\npowers, assuming an earlier-mentioned perspective of logic games. The\ntwo games depicted in the core example of\n Section 2.2\n may be seen as evaluation games for propositional formulas \nTheir equivalence qua powers, described earlier, then matches\nthe standard propositional law of distribution. This algebraic\nperspective will return in\n Section 2.9. \nMore recent views of forcing and powers re-interpret the sets X\nof outcomes employed in the above definitions as referring to both\nplayers: one player restricts the total set of outcomes, while the\nother players can achieve all outcomes within that set. This variation\nsignificantly impacts the corresponding notions of game equivalence,\nas well as the modal languages used (van\nBenthem, Bezhanishvili, & Enqvist forthcomingb). \nIn the strategic perspective on games, players select actions\nsimultaneously, without having learned about their opponents’\nchoices of actions. This requires an additional level of analysis.\nBesides the various possible moves, an adequate representation must\nalso track players’ uncertainty about how their opponents might\nact. \nIn terms of matching logical languages, this suggest a\nmulti-modal approach, with \\([\\approx_i]\\) ranging over\ni’s possible choices, and \\([\\equiv_i]\\) representing her\nuncertainty about the opponents, see van\nBenthem, Pacuit, and Roy (2011). Moreover, when considering\ngames rather than game forms, this picture needs to be enriched with a\nthird feature, viz. preference modalities \\([\\preceq_i]\\), see\n Section 3. \nGames in strategic form can be viewed naturally as models for a modal\nlanguage of choice and uncertainty, where each state m\nconsists of a strategy profiles, i.e., a sequence \\((m_1,m_2\\ldots)\\)\nlisting each player’s choice of action. For convenience, the\npreference modality has been included: \nThis multi-modal language can express a variety of statements about\nstrategic form games, such as: \nIn the case of two players, one agent’s choices corresponds to\nthe other’s uncertainty and vice versa. This shows in the\nvalidity of principles such as  \nMore generally, the logic of matrix games includes the \\(\\mathsf{S}5\\)\naxioms for both \\([\\approx_i]\\) and \\([\\equiv_i]\\), but also the\ncommutation law \nexpressing the grid-like structure of matrix games. This logic bears\nsome resemblance to STIT-type logics of actions (Herzig\n& Lorini 2010). Technically, a\ngrid structure in models allows for encoding of undecidable\ncomputational problems (Blackburn, de\nRijke, & Venema 2001), rendering it an open problem\nwhether expressive modal logics of game matrices are decidable. \nThe step from two to more players, often routine in epistemic logics,\ncan be delicate in the logic of matrix games. Accessibility relations\nof type \\([\\approx_i]\\), interpreted as identity of profiles except\nfor the \\(i^{}\\)-coordinate, yield a product logic akin to the\nthree-variable fragment of first-order logic which is known to be\nundecidable (Bezhanishvili 2006).\nHowever, with only relations of identity at the i-coordinate,\ni.e., \\([\\equiv_i]\\), the logic remains decidable (Venema\n1998; Van De Putte, Tamminga, & Duijf\n2017; Lomuscio, van der Meyden, & Ryan 2000). \nThere is further structure in extensive games than just single moves.\nIn game trees, a player’s strategy specifies what to do\nat each turn, whether this turn will ever be reached or not. An\nincreasing body of work examines such strategies and their underlying\nformats, see van Benthem, Ghosh, and Verbrugge\n(2015) for an overview of various logical frameworks for\nreasoning about strategies. \nIn one concrete perspective, a strategy is akin to a program that\ninstructs the agent on how to navigate a game tree. Hence, a natural\nlogic of strategies uses the language of\n propositional dynamic logic of programs\n PDL, an approach that will return later. As programs are in general\nnon-deterministic, such logics let a strategy recommend one or more\nactions the agent should take at each turn. In this perspective,\nstrategies resemble plans that might remain partial. \nIn a program format, strategies start with basic actions, representing\nindividual moves in a game tree. From there, complex programs \\(\\pi\\)\ncan be created using operations including sequential compositions\n\\(\\pi_{1} \\,;\\pi_{2}\\) (\\(\\pi_{1}\\) is to be performed followed by\n\\(\\pi_{2}\\)), or choice \\(\\pi_{1}\\, \\cup_{i} \\pi_{2}\\) (agent i\nis to pick between actions \\(\\pi_{1}\\) and \\(\\pi_{2}\\) ). Moreover, a\ntest operation \\(?\\varphi\\) for checking whether \\(\\varphi\\) holds,\nenables strategies to react to properties of states or\nopponents’ past actions. Finally, to describe continuous\nexecution of a strategy along a game tree, it makes sense to have an\noperation \\(\\pi^{*}\\) of program iteration, stating that \\(\\pi\\) be\nexecuted arbitrarily often. \nThe language of PDL then has modal operators \\([\\pi]\\) for every\nprogram \\(\\pi\\) that can be defined from the basic actions and the\noperations just described. A simple such strategy advises player\ni to do a whenever it is her turn. The following formula\nstates that this strategy ensures that \\(\\varphi\\) holds\nthroughout: \nProgram definitions for strategies given here are closely related to\nthe use of finite automata for defining strategies in computer science\nand game theory (Osborne & Rubinstein 1994;\nGrädel, Thomas, & Wilke 2002; Ramanujam & Simon\n2008). \nIn the extensive form games of\n Section 2.1,\n players move in sequence and can base their decisions on full\ninformation of what has happened so far. The other extreme were games\nin strategic form, where agents move in parallel or, in the\ninterpretation of strategy selection, have no means of picking up\ninformation during actual play. There are ample scenarios in between\nthese extremes. Public good games with optional retribution against\nnon-cooperators (Andrighetto et al.\n2013), for instance, combine moments where some or all players\nmake simultaneous moves with information collection along the way.\nSuch parallel action can be mimicked in sequential games by limiting\nthe information available to players at various states of the game.\nThe resulting games of imperfect information will be discussed in\n Section 3,\n alongside other sources of imperfect information. \nFurther well-known logical approaches to parallel action employ STIT\nlogic (Horty & Belnap 1995; Broersen\n2009), and temporal logics such as ATL (Alur,\nHenzinger, & Kupferman 2002) or its\nepistemic variant ATEL (van der Hoek &\nWooldridge 2003). \nSo far, games were treated as monolithic entities that agents reason\nabout in their entirety. This can be at odds with how real life agents\nconceptualize games. To facilitate reasoning, games are often broken\nup into smaller tasks that are easier to handle separately. A chess\nplayer, for instance, may know how to solve different end games.\nRather than reasoning about every possible situation until its end,\nshe will evaluate different options in mid-play by considering which\nof these end games they will, most likely, lead up to. In this\nperspective, complex games are constructed out of simpler games that\nmay profit from separate analysis. Games then form an algebra with\noperations that construct complex games from simpler ones. This style\nof thinking is reinforced when games are viewed as scenarios for\ninteractive computation, where again algebraic methods are used\nwidely (Bergstra, Ponse, & Smolka\n2001). \nHere is an illustration of this approach. For simplicity, consider\nonly two players, A and E, the latter of which starts\nthe game. One influential game algebra has the following operations,\ncf. Parikh (1985). \nFor instance, take a chess player in mid-game reasoning. For\nsimplicity, restrict the possible end games to \\(G_{F_1}\\) and\n\\(G_{F_2}\\). The player can then conceptualize mid-play as a game\n\\(G_{mid}\\) with end nodes labeled by propositions \\(p_1\\) or \\(p_2\\),\ndescribing which of the two end games follows. The full remaining\nchess tree is then given by \nEquational axiomatizations for this game algebra can be found in Goranko\n(2003) and Venema\n(2003). However, following the analogy\nof propositional dynamic logic for an algebra of programs, there also\nis a dynamic game logic for this algebra of games, (Parikh\n1985). It adds a modality\n\\(\\{G\\}\\varphi\\) for each game G, with \\(\\{G\\}\\varphi\\)\nexpressing that in game G, the first player E has a\nstrategy to force the truth of \\(\\varphi\\). For the case of\nnon-determined games, the language will be extended further to include\nseparate modalities \\(\\{G, i\\}\\varphi\\), one for each player i.\nDynamic game logic shows in a perspicuous manner how strategic\nabilities for complex games supervene on abilities in simpler games.\nThis is done by means of reduction laws such as \nFor a complete list of reduction laws, as well as open problems in\nthis dynamic game logic see Pauly (2001), van Benthem\n(2014). For other styles of game algebra, including also forms\nof parallel composition, cf. Abramsky\n(1997). \nIt should be said that imperfect information challenges this approach\nto game algebra. For instance, one may have to decompose a larger game\ninto smaller subgames where agents need not know which of these\nsubgames they are in. Game algebras with imperfect information have\nbeen studied in the context of Boolean Games (Harrenstein\net al. 2001). A recent\npower-based game algebra with operations encoding imperfect\ninformation, showing some analogies with IF logic (Mann,\nSandu, & Sevenster 2011) can be\nfound in van Benthem, Bezhanishvili, and\nEnqvist (forthcomingb). \nCoalitions and Networks Nothing has been\nsaid so far about social or structural relations between players: they\nmove individually and in interaction with all other players. However,\nin many games, groups of players can team up to jointly pursue goals,\npossibly in competition with other groups. Coalitions are a natural,\nbut non-trivial extension of the logical frameworks introduced here,\nas strategic abilities of groups may exceed those of all members\ncombined, see Peleg (1997), Van de Putte & Klein (2018), and the entry\non\n coalition powers in games.\n In other studies of social phenomena, the set of players is equipped\nwith an additional network structure. An agents’ outcome or\nbehavior will then depend upon what network neighbors do (Baltag\net al. forthcoming; Christoff 2016).\nLastly, games on networks are closely related to information flows in\nsocial networks, as studied in depth by Liu,\nSeligman, and Girard (2014) and Seligman\nand Thompson (2015) from a logical perspective. \nTracking This section contains a wide\nvariety of perspectives on games. These differ in their invariance\nrelations and their matching languages, offering different foci such\nas outcomes, powers, or the detailed temporal evolution of games. Even\nfurther perspectives will no doubt keep emerging. This diversity may\nseem overwhelming, making the field rather scattered. But here,\nanother role of logic shows, by not just proliferating systems, but\nalso as connecting them. Various logical translations exist between\nthe languages and levels involved. Often, reasoning about games in a\nlogic for some level can be mirrored precisely under translation into\nthe logic of another level. Moreover, these translations can often\nkeep track of changes in games under actions of information updates, a\ntopic to be taken up in Section 3. Tracking of this kind is defined\nand studied in general logical terms in van\nBenthem (2016) and Cinà\n(2017). \nInfinite games So far, games were\ntacitly assumed finite in length. This assumption is innocuous for\nmany real life scenarios, yet there are notable exceptions. A\nprominent example are safety games, where one of the players, the\nguard, has to ensure a system to never leave a certain state, while\nthe opponent attempts to deviate. Many technical tools for finite\ngames also work for infinite games. There is, however, a number of\nconceptual and logical discontinuities. Since infinite games have no\nlast moments, for instance, outcomes must be attached to complete\nhistories of game play, rather than leaves of a tree. Reasoning about\ngames then requires temporal modalities for a given history, but also\nmodalities ranging over all open future histories. For analyzing\npowers, then, temporal versions of forcing modalities are needed. With\nthese modifications, a logical style of analysis still applies. For\ninstance, it is well-known that determinacy fails for infinite games\n(Jech 2003). However, what holds for all\ngames is a law of ‘weak determinacy’ stating that, if\ni has no strategy to force a set of histories satisfying\n\\(\\varphi\\), her opponent j can ensure that i will never\nobtain such a \\(\\varphi\\)-strategy in the future. The difference\nbetween standard determinacy and weak determinacy is captured by the\nfollowing two formulas, that are entirely in line with this\nsection’s style of analysis:\n\\(\\{i\\}\\varphi\\,\\lor\\,\\{j\\}\\neg\\varphi\\) (determinacy) versus\n\\(\\{i\\}\\varphi\\lor\\{j\\}G\\neg\\{i\\}\\varphi\\) (weak determinacy), where\nG is the temporal modality of ‘always in the future on\nthe current history’. \nGame forms may be seen as spaces where players can operate. A game,\nhowever, is not fully determined by its game form alone. Rather, the\nplayers involved may import additional features relevant for game\nplay. Players can, for instance, be limited in their powers of\nobservation, either by aspects of the game structure or through\ncognitive limitations. The most striking added feature, however, is\nthat players have preferences. Agents not only observe the world or\nact in it. While these describe mere kinematics of a game, agents also\nevaluate current state and various possible futures. Being driven by\npreferences, it is such evaluations that are the moving force behind\nplayer’s choices. Preference, hence, take a prominent\nexplanatory role for true game dynamics. \nThis section places its focus on the preferential and epistemic\ndimensions of players. Such factors are essential to notions of\nrationality where information, action, and preference are often\nentangled. In game theory, a harmony between these is often sought in\nnotions of equilibrium for strategy profiles. \nGame trees and game matrices specify the moves available to players at\ndifferent moments in time. They also indicate all possible outcomes,\neither as cells in a matrix, or as leaf nodes in an extensive game.\nHowever, to study what players should or will do in\na game, a further component is needed: players’ preferences.\nSuch preferences need not only reflect material pay-offs or other\nfeatures of outcome states. Rather, they may also relate to the\nprocess of play itself, and which moves lead to a certain outcome. Moreover, preferences may contain irreducibly\nsubjective elements. Even when assuming the same role in a game,\ndifferent players may disagree about the relative desirability of\ncertain outcomes (Fehr & Schmidt\n1999). \nWithin a static, outcome-oriented perspective on games, a major\nemphasis is on equilibria: strategy combinations where all players do\nthe best they can in light of their preferences and the\nopponents’ strategies. A further, dynamic perspective focuses on\nhow such equilibria relate to the individual players’ stepwise local\nreasoning on how to act in light of their beliefs and desires. This\nperspective is taken up in\n Section 4. \nFor reasoning about preferences, it must first be specified what it is\nthat agents’ preferences apply to. The orthodox account lets\npreferences exclusively range over possible outcomes (Osborne\n& Rubinstein 1994). However, a\ngrowing trend in the logical literature assumes agents to rather care\nabout the truth value of general propositions than can describe both\nthe progression or outcome of a game. While not equivalent, the two\nperspectives are compatible. Both will be discussed in this\nsection. \nIn the classical picture, player i’s preferences on a\ngame tree are represented by a preference relation \\(\\prec_i\\) ranging\nover the set of outcomes. Such a relation is usually assumed\ntransitive and reflexive, but need not be total. \nExample A game tree with\npreferences. \nFigure 8. \n ⓘ \nJust as with the earlier modal logics for game forms, a relatively\nsimple logical formalism can already express relevant aspects of\nagency in games. It offers a low-complexity language for stating\nbasic features of action and information, without going into details\nof the underlying quantitative mechanisms. More precisely, games with\npreferences naturally support a logic with modal operators\n\\([\\preceq_i]\\) interpreted as: \nLogics of this type can express various properties relevant to games.\nThey can, for instance, say that all states better than the current\none are \\(\\varphi\\) states, making moving towards \\(\\varphi\\) states a\nnecessary condition for maximizing utility. They can also express,\nthat all best states are \\(\\varphi\\) states, with the formula  \nFor more on modal preference logics, see \nHansson (1990, 2001),Girard\n(2008) and van der Torre\n(1997). \nModal preference logic has further extensions with natural connections\nto games. In a refined perspective, for instance, preferences may\nderive from reasons, say, criteria or goals various agents want to\nachieve. This gives rise to a duality between preference relations\namong outcome states and priority orders over formulas, describing the\nagents’ goals. Dynamic accounts, finally, track how preference\ncan change under various input events. For more on both of these\nissues, see Liu (2011). \nHowever, modal preference logics, construed either way, are not yet\nrich enough to express one of the essential notions of game theory.\nFurther extensions are needed to deal with best responses,\nexpressing that the current move of a player is the best she can do in\nlight of her opponent’s actions. \nBest response moves are the main ingredient for game equilibria.\nFormally, a Nash equilibrium is a strategy profile, fixing a\nunique choice for each player, where nobody can improve by\nunilaterally changing strategy when all others maintain theirs. There\nare several ways of defining this property in extended modal\npreference languages. One possibility is to simply introduce a new\natom \\(b_i\\), stating that the current world is the best player\ni could have achieved in light of the opponents’ actions.\nIn this language, Nash equilibrium are characterized by  \nMore explicit definitions exist, building on the strict preference\nmodalities of van Benthem, Girard, and Roy\n(2009). Yet, perhaps the simplest illuminating approach uses an\nintersection modality from hybrid logic (Areces\nand ten Cate 2007) combining the\nagent’s preference relation with her uncertainty between the\nopponent’s action to characterize best responses and Nash\nequilibria (cf.\n Section 2.6): \nExpressing Nash equilibrium has served as a benchmark for logics of\nstrategic games (van der Hoek & Pauly\n2007). Yet there are other desiderata, often connected to\nanalyzing standard game-theoretic solution concepts for games. These\nare usually designed to find Nash equilibria or at least narrow down\nthe strategy profiles to those compatible with certain requirements of\nrationality. Well-known methods of this kind are Backward Induction\nfor extensive games and Iterated Removal of Strictly Dominated\nStrategies for strategic form games (Osborne\n& Rubinstein 1994). These will be discussed now, as they\nraise intriguing further logical issues. \nHere is a high-level description of Backward Induction. In extensive\ngame forms, the aim is to introduce a new preference-based relation\n\\(\\best_i\\), denoting that some move is the best a player can do at\nsome given state. Thus, \\(\\best_i\\) is a subset of player\ni’s total move relation, to be defined in a suitable\nmanner. \nFor final moves, standard decision theory suggests that a choice is\nbest for the active player if no other move leads to a better outcome.\nWhen extending the analysis to earlier positions of the game, things\ndepend crucially on players’ expectations about their\nopponents’ future behavior. Several possible policies exist,\ndepending on the types of player involved. A widespread assumption in\nepistemic game theory is common belief in rationality, i.e., that all\nplayers involved are rational, believe their opponents to be rational,\nbelieve their opponents to believe that opponents are rational, and so\non. In line with this assumption, the following algorithm extends the\n\\(\\best_i\\) relation recursively to non-terminal nodes: \nWhenever player i is to move at state s, possible\nchoices are assessed by comparing what would happen if, after that\nmove, everybody followed their \\(\\best\\) relation. A possible move at\ns is included in i’s \\(\\best\\) relation if the\nbest outcome of this move followed by repeated \\(\\best\\) moves by all\nplayers is at least as good as every other move i could make at\ns, followed by \\(\\best\\) moves by all players. \nHere is how this bottom-up procedure works in practice. \nExample Backward Induction. \nFigure 9.\n ⓘ \nThis procedure is a qualitative version of classic game theory’s\nBackward Induction, which is based on utility values rather than\npreference relations (Leyton-Brown & Shoham\n2008). \nBackward Induction and the resulting \\(\\best\\) relation is a prime\nexample for the complex entanglement of preferences, information and\naction. A key modal axiom governing this relation was identified by\nvan Benthem, van Otterloo, and Roy\n(2006). \\(\\best^*\\) denotes here the transitive closure of the\nunion of all \\(\\best_i\\) relations. \nDescribing the limit of a dynamic process with a static property, this\nequivalence exemplifies a family of characterization theorems\nthat play a crucial role within the logical analysis of games. Other\ndynamic perspectives can be analyzed in a similar logical style (Liu\n2011). \nIterative reasoning strategies akin to Backward Induction also exist\nfor games in strategic form. Rather than defining a new unary\nmove-predicate \\(\\best\\), however, these procedures work by\neliminating suboptimal actions. An action a is labeled\nsuboptimal or dominated if there is some other available\naction, b, that guarantees a better result than a, no\nmatter what the opponents do. In this case a rational player should\ndrop a from her space of admissible acts, as she would never\nplay it. \nJust as Backward Induction, dominance reasoning has an iterative\nflavor. Assuming common belief of rationality, players can expect\ntheir opponents to also drop dominated actions from consideration.\nDoing so reduces the game and might render further moves dominated, as\nis illustrated in the following example. Within the left-to-right\ntemporal progression, moves are greyed out as they get discarded.\nPlayers’ preferences are represented with numerical values with\n1 the best and 4 the worst. \nThe fact that further strategies may become dominated suggests to\nrepeat the procedure, turning removal of dominated strategies into an\niterated process. When games are finite, this process is guaranteed to\nconverge in finite time. Iterated removal of dominated strategies on\nbinary preference relations is a qualitative variant of the version\nemployed in classical game theory, where cardinal utility values are\nassumed (Leyton-Brown & Shoham\n2008). \nA closely related process is iterated removal of weakly\ndominated strategies, where some move a is deleted if\nthere exists a b that outperforms a on some of the\nopponents’ moves, while being at least as good on the remaining\nones. Unlike its strict counterpart, iterated removal of weakly\ndominated strategies suffers from a number of technical and conceptual\nintricacies, such as order dependence of iterated deletion (Samuelson\n1992; Pacuit & Roy 2011). \nGeneralizing the concept of winning or losing, agents can be assigned\ngoals they pursue in a game. Restricting to a single goal per agent\nretains a binary perspective: A goal is reached or not. Goals,\nhowever, allow for additional flexibility. Besides pure competition as\nin win-lose games, these can also express pure coordination games,\nwith everybody pursuing the same goal, or mixed motive games with\npartial overlap between different players’ goals. \nThe concept of goal functions is particularly prominent in the logical\nframework of\n Boolean games\n (Harrenstein 2004). There, each agent\nis given control over some atomic propositions, permitting her to\nfreely decide on their truth value. Goals are then formulated as\npropositional formulas over the set of all players’ atoms.\nCrucially, a player’s goal formula might hence involve atoms\nthat are not under her control. In iterated extensive Boolean games,\ngoal formulas might also refer to properties of histories of play\ndefined in temporal logics (Gutierrez,\nHarrenstein, & Wooldridge 2015) \nThere are various types of information players can possess or lack\nabout a game. First and foremost, players can be uncertain about the\ntypes of opponents they face: their preferences, their reasoning\nabout the game and how they expect the game to unfold. Second,\nagents’ uncertainty can extend to the game itself. Players, of\ncourse’ won’t know their opponents choices in a\nsimultaneous move game. Besides, agents might also have limited\ninformation about past moves and events. Such uncertainty can arise\nfrom the game structure eschewing certain observations, but also from\nfailing to record past information properly. In yet more extreme\ncases, agents might even be unsure about the moves available to their\nopponents. \nGiven the various limitations to their knowledge, players may\nentertain beliefs to structure their uncertainty. Such beliefs may,\nnaturally, change over time, as players communicate or observe the\ngame unfold. The importance of beliefs in the logical analysis of\ngames has been emphasized in Stalnaker\n(1998), who was the first to highlight the role of belief\nrevision in analyzing reasoning about game solution. \nIn one sense of uncertainty, even highly idealized agents might have\nbut limited information of what has happened so far. In certain cases,\nthe game’s structure may limit some players’ observational\npowers of their opponents’ moves. In other instances, agents may\nsuffer under cognitive limitations restricting their perspective on\nthe game. Or, sometimes, agents might simply fail to record some of\nthe moves made by themselves or others. \nWithin extensive games with imperfect information, all such\ncases are represented by indistinguishability relations \\(-\\,-\\,-\\,-_A\\)\nbetween states \\(m,m'\\), expressing that agent A cannot\ndistinguish between being at m and \\(m'\\). Notably, this does\nnot preclude the player from learning later on in the game whether he\nhas been at m or \\(m'\\). \nExample A game with imperfect\ninformation. \nFigure 10.\n ⓘ \nWhile allowing agents to lack information of various kinds, the above\nanalysis makes one structural assumption about players: they always\nknow which moves are available to them at a given node. In extensive\ngames with imperfect information, this translates to the requirement\nthat whenever two states are indistinguishable to some agent, they\ncoincide on the set of her possible actions. \nThe move from perfect to imperfect information has major implications\nfor strategic reasoning. In the game depicted above, player A\ncannot distinguish between being at m and \\(m'\\). When at the\nformer, she may, for all she knows, be at \\(m'\\) instead. Hence\nA’s decision needs to account for both possibilities; she\ncannot base her choice on any property that holds at only of those\nlocations. In particular, A has no available strategy that\nguarantees her ending up in a \\(\\win_A\\) node. Since E cannot\nensure a win either, no player has a winning strategy. This is a\ncentral difference with finite perfect information games, where it is\nguaranteed that one of the players has a winning strategy, cf.\n Section 2.4. \nReasoning about imperfect information requires to extended languages\nfor extensive form games with epistemic modalities. For each player\ni, modality \\(K_i\\varphi\\) represents i’s\nknowledge. The usual semantics of epistemic logic relates this to\nuncertainty, as encoded by the players’s indistinguishability\nrelation: \n\\(\\mathcal{M},m\\vDash K_i\\varphi\\quad\\)\nall states \\(m' \\text{ with } m\\,-\\,-\\,-\\,-_i\\,m'\\)\nsatisfy \\(\\mathcal{M},m'\\vDash\\varphi\\)\n \nThis language is best illustrated with the above game tree. To this\nend, interpret the tree as the classic children’s game where one\nplayer, A, has to guess in which hand her opponent, E,\nhides some little token. Once E has hidden the token in, say,\nher right hand (move \\(h_R\\)), the guessing player has a winning move\nde re: she should pick right (\\(p_R\\)). However, as\nthe token was placed in secret, she may not know that picking\nright is a winning move: the player has no winning strategy\nde dicto. This is expressed by:  \nIn a game theoretic setting, the de re vs. de dicto\ndistinction has been studied by Horty and\nPacuit (2017) and van Benthem\n(2001). \nIn light of these considerations, many logics for defining strategies \ninvolve epistemic elements. It seems reasonable to demand that agents \ncannot base their choice of strategy on everything that has happened before, \nbut only on what they know, i.e., their current information (Pacuit, Parikh, & Cogan 2006). The resulting \nuniform strategies (Maubert 2014), can be\ndefined by the knowledge programs of Fagin,\nHalpern et al. (1997). Further restrictions are possible, for\ninstance granting agents limited memory that only reaches back a fixed\nnumber of moves (Gutierrez, Harrenstein, &\nWooldridge 2015). \nThe epistemic action language can express many further phenomena in\nimperfect information games. The following game is an\nillustration. \nFigure 11.\n ⓘ \nOnce player E arrives at node n, she cannot discern that\nactual situation from node \\(n'\\). However, E must have\npossessed information earlier on that distinguishes n from\n\\(n'\\): to arrive at n, she must have played a as her\nfirst choice, while \\(n'\\) can only be reached after playing b.\nThus, E can only be uncertain between these two nodes if she\nforgot about her own previous actions. \nThe epistemic action language can distinguish between such scenarios\nwith memory loss and those without. The property of Perfect\nRecall states that players retain full memory of all moves they\nobserved. This can be expressed by the following axiom scheme (Halpern\n& Vardi 1986; Bonanno 2004) \nAlso the converse of this scheme admits a natural interpretation: \nThis No Miracles property expresses that players can only\nlearn by observing moves, not by any other methods extraneous to the\ngame. \nOf course, logic does not presuppose that all players have perfect\nmemory, or that they cannot pick up any information outside the\nprogression of play. Epistemic action language can equally well be\nemployed to analyze more general scenarios where the above axioms do\nnot hold. Especially within dynamic-epistemic versions, epistemic\nlogics can produce modified versions that cover many more cases than\nthose described here (van Benthem 2014).\nMoreover, further modalities from epistemic logic make sense, in\nparticular, those for common or distributed knowledge in groups of\nplayers (Fagin, Halpern et al. 1995; Meyer\n& van der Hoek 1995). \nAn epistemic component with operators \\(K_i\\) fits with many logical\nperspectives on games. In particular, epistemic extensions are as\ncompatible with coarse logics such as the earlier-mentioned\n\\([\\move_i]\\)-setting with a single move-modality per player, as with\nfine logics where each individual action type is represent by a\ndistinct modality \\([a]\\). In fact, in\n Section 2.6,\n epistemic operators were used for analyzing games in strategic form,\nwhere modalities naturally relate to uncertainty about the other\nplayers’ strategies. \nIn more general settings, uncertainty does not stop at the\nopponents’ informational states. In international relations or\neconomic bargaining, also the players’ motivations and\npreferences are not fully known to all parties involved. Within the\ncorresponding extended form games, players may be uncertain about\ntheir opponents’ preferences and strategic options, whether they\ncan afford a certain move or whether they actually possess the\ninformation they threatened to reveal. Obviously, uncertainty about\npreferences or available options will impact reasoning about the\nequilibria of a game. Strategic players might even try to exploit such\nuncertainties, for instance by pretending to have options they do not\npossess. \nIn a first pass, this type of uncertainty can be expressed by\nintroducing nature as hypothetical player, with a first move that\ndetermines the preferences and available options for all players. A\nsimple example is the game depicted below. At the start, A is\nuncertain whether E can reply to A’s move f\nby playing e. Likewise, she lacks information on whether\nE prefers \\(O_3\\) over \\(O_4\\), or vice versa. \nFigure 12.\n ⓘ \nFrom a logical point of view, this miraculous initial move by Nature\nis not needed. Standard epistemic models can represent the above\nscenario, and many more complex ones, by means of the\nindistinguishability relations introduced above. Technically, this\nrequires to move beyond standard imperfect information trees to\nso-called epistemic forests (van\nBenthem, Gerbrandy, Hoshi, & Pacuit 2009), sets of trees\nlinked by epistemic relations. In particular, the above game tree\ntransforms into \nFigure 13.\n ⓘ \nThe epistemic action language for trees works just as well on\nepistemic forests. However, in suitably expressive languages, the\nlogic of forests is weaker than that of trees, as the set of\nvalidities on the class of n-player trees is a strict superset\nof the validities on n-player forests. \nFurther enrichments of the logical framework add semantic structure to\nthe agents’ uncertainty. When unable to determine the exact\nsituation, players may classify options with respect to plausibility.\nTo this end, epistemic models have been equipped with plausibility\norderings \\(\\geq_i\\) for players i (Boutilier\n1994; Stalnaker 1968; Baltag & Smets\n2008). \nIn the preceding example, plausibility order might work as\nfollows: \nFigure 14.\n ⓘ \nThis richer structure is reflected by introducing new modalities for\nagents’ beliefs, determined by the most plausible states: \n\\(\\mathcal{M},w\\vDash B_i^{\\phantom{\\psi}}\\varphi\\quad\\)\n\\(\\varphi\\) holds in all \\(\\geq_i\\)-maximal states in i’s epistemic\nrange. \nConditional belief, important to players’ planning within a\ngame, can be interpreted in the same style: \n\\(\\mathcal{M},w\\vDash B_i^\\psi\\varphi\\quad\\) \\(\\varphi\\) holds in all\n\\(\\geq_i\\)-maximal \\(\\psi\\)-states in i’s epistemic\nrange. \nThese clauses are intended to work in finite as well as in infinite\nsettings. However, in the latter case minor modifications might be\nneeded akin to those in\n conditional logic.\n These have been proposed in various alternatives. Notably, this\nenriched epistemic-doxastic logic allows for further, less standard\ninterpretations beyond those illustrated so far. Examples are\n‘strong belief’, expressing that all relevant\n\\(\\varphi\\)-states are more plausible than all relevant\n\\(\\neg\\varphi\\) states, or ‘safe belief’ saying that\n\\(\\varphi\\) holds at all states that are at least as plausible as the\ncurrent one. See van Benthem and Smets\n(2015) for an overview of plausibility semantics and its\nconnections to conditional logic, belief revision theory,\ndynamic-epistemic logic, and a wide range of philosophical and\ntechnical issues. \nIn various scenarios, agents reason not only about the\nopponents’ preferences or admissible moves, but also about their\nbeliefs about the game and others’ behavior therein. In fact,\nsuch higher-order reasoning can have a major impact on game play. A\nprime example is the Backward Induction procedure of\n Section 3.3,\n where the construction of a best move relation crucially relied on\ncommon knowledge of rationality. More generally, agent’s best\nmoves frequently depend upon what they expect others to do. This\nphenomenon is especially prominent for simultaneous move games, where\nit occurs in both coordinative scenarios (Skyrms\n2003; Lewis 2002) as well as\ncompetitive ones (Hotelling 1929). More\ndetails can be found in the entry on\n epistemic game theory. \nArbitrary first and higher order levels of knowledge and belief can be\nrepresented with the above relational models, the standard tool in\n epistemic\n and doxastic logic. For information in extensive form games, the\nepistemic-doxastic perspective on states can be combined with\n\\(\\move\\)-relations in exactly the way described before. The result\nare epistemic-doxastic trees or forests that can\nrepresent most types of knowledge or belief players might have about\nthe game, including its exact shape, previous moves, opponents’\npreferences or opponents’ first- and higher-order beliefs on any\nof these matters. \nOutside of logic, higher-order information has also been modeled in\nclassical game theory. Quantitative frameworks represent information\nas probability distributions over a given event space. In this\nsetting, higher-order information corresponds to probability\ndistributions over probability distributions of the right kind. More\nspecifically, \\(n^{\\textrm{th}}\\) order information corresponds to a\nprobability distribution over the space of \\((n-1)^{\\textrm{th}}\\)\norder beliefs. As shown by Harsanyi\n(1967–1968), the limit of specifying higher and higher\nlevels of information can be represented as a type space, where each\nagents’ type is a probability distribution over states of nature\nand the other players’ types. In an abstract sense to be\ndiscussed below, these types correspond to states in standard models\nof modal logic. \nIn addition to standard modal models, logic also has a straightforward\nanalogue to probabilistic type spaces: logical type spaces.\nIn a formal framework first introduced by Fagin,\nGeanakoplos et al. (1999), an\nn-type is a sequence \\(\\mathfrak{f}_n=\\langle\nf_0,f_1\\ldots,f_{n}\\rangle\\) where \\(f_0\\) specifies the state of\nnature, i.e., a valuation recording which atomic propositions are true\nor false, and \\(f_1\\) lists for all players the states of nature they\nconsider possible. \\(f_m\\) for \\(m\\geq 0\\) then specifies for all\nplayers which \\((m-1)\\)-types, i.e., sequences \\(\\langle\ng_0,\\ldots,g_{m-1}\\rangle\\) they consider possible. In this way, an\nn-type fixes the player’s higher-order beliefs up to\nlevel n. These types are, of course, subject to coherence\nconditions: the agents’ k-types for different k\nmust fit together. For instance, whenever some agent considers a\nk-type \\(\\mathfrak{f}_k\\) possible, she must also consider any\ninitial segment \\(\\mathfrak{f}_{k'}\\) for \\(k'<k\\) possible.\nConversely, any \\(k'\\) type the agent considers must be the initial\nsegment of some k type the agent holds possible. Type\nspaces offer a semantics for the epistemic language: Inductively, for\na formula \\(\\varphi\\) of modal depth m, \\(K_i\\varphi\\) is true\nat a type \\(\\mathfrak{f}_n\\) if all \\(g_{m}\\in f_{m+1}(i)\\) satisfy\n\\(\\varphi\\) or if \\(m>n\\). \nAlternatively, the set of n-types allows for a natural\ninterpretation as relational models with accessibility relations\ndefined by \n\\(\\langle f_0,\\ldots f_n\\rangle R_i\\langle g_0,\\ldots g_n\\rangle\\quad\\)\nFor all \\(m\\leq n\\) holds \\(g_{m-1}\\in f_m(i)\\) \nInterpreting the set of n-types as a relational model yields a\nsecond way of evaluating the epistemic language on logical type\nspaces. For formulas of modal depth less than n the two\ninterpretations coincide. Hence, up to finite depths, type spaces and\ntheir associated relational models are two perspectives on the same\ninformational situation. \nTo fix all of the agents’ beliefs, the analysis moves to types\n\\(\\mathfrak{f}=\\langle f_0,f_1,\\ldots\\rangle\\), containing some\n\\(f_n\\) for every natural number n. In this extended framework\nthe situation becomes more complicated. The space of all such types is\nuniversal in the following sense: every relational model can be mapped\nin a truth-preserving manner to the space of all types by sending each\nstate to a full description of the agents’ corresponding first-\nand higher-order informational attitudes. This map, however, is\nusually not a modal bisimulation. In fact, the process of type\nconstruction could be continued indefinitely, yielding a transfinite\nhierarchy of mutually non-bisimilar type spaces (Heifetz\n& Samet 1998). Such transfinite\ntypes can become relevant when the epistemic language is enriched with\nmodalities for common group knowledge, in which case a full\ndescription of all expressible attitudes involves infinite hierarchies\nof higher-order information (Fagin, Geanakoplos\net al. 1999). A recent logical study of type spaces including\ntheir probabilistic structure can be found in Bjorndahl\nand Halpern (2017). \nThe tight connection between type spaces and relational models is\ncompatible with additional assumptions that might be imposed on the\nplayers’ mental states. Fagin,\nGeanakoplos et al. (1999) characterizes when type spaces give\nrise to \\(S5\\) models, while Galeazzi &\nLorini (2016) do the same for multi-agent KD45\nbelief. \nWhile relational models and logical type spaces represent exactly the\nsame information, their main differences is in perspective. Relational\nmodels take a third person bird’s eye view on possible worlds.\nTheir starting point is a set of worlds rich enough to contain all\nstates considered possible by the relevant agents, together with\naccessibility relations modeling players’ information. From\nthere, agents’ first-order beliefs at the various worlds can be\nread off and, subsequently, also all higher levels of information.\nLogical type spaces, by contrast, assume a first person\nperspective. They take a full description of first and higher-order\nbeliefs as primitive and treat indistinguishability as a derived\nrelation. \nFinally, it should be noted that type spaces assume a static\nperspective on games. No provisions are taken for representing moves\nor strategies explicitly, nor for incorporating updates of knowledge\nand belief that occur as a game in extensive form unfolds, cf. the\ndiscussion in\n Section 4.\n Thus, there is some distance between type spaces and the earlier\nepistemic-doxastic forest models for extensive games. As a first step\ntowards filling this gap, it has been shown how type spaces can\naccommodate product updates from dynamic epistemic logic (Klein\n& Pacuit 2014). \nBesides variations in preferences and beliefs, a third crucial aspect\nof players is their styles of information processing, decision making,\nand reasoning. Real cognitive agents are bounded in their information\nprocessing, as both their memory and reasoning capacities are limited.\nIn particular, players may not be able to represent the entire game\nthey are in, nor reason until the end of the game. This phenomenon of\nshort sight has been studied in Grossi\nand Turrini (2012) and Turrini\n(2016). Moreover, in real-life iterated social interaction,\npayoffs are generated along the game, and may not be clear beforehand,\n(Axelrod & Hamilton 1981). In such\ncontexts, the best strategy in terms of short-term payoffs need not be\noptimal in the long run, but bounded agents may miss this longer\nhorizon, (Klein, Marx, & Scheller\nforthcoming). \nLogical literature on bounded agency is too broad to be surveyed here.\nFor a few research lines relevant to games, see Fagin\nand Halpern (1987) and Heifetz, Meier, and\nSchipper (2006) on epistemic logics with awareness, Artemov\n(2008) on\n justification logics,\n van Benthem and Pacuit (2011) on\nevidence logics, and Hansson (1998) and Lorini\n(2018) on doxastic logics with computationally tractable belief\nbases. \nIn the game theoretic literature, bounded agents have often been\nrepresented as finite state machines (Gutierrez,\nHarrenstein, & Wooldridge 2015;\nBinmore & Samuelson 1992). Limitations on reasoning\ncapacities or memory size then translate into bounds on the machine\nsize. The resulting hierarchy allows for a fine grained analysis of\ninformation processing, reasoning, and thus bounded players of\ndifferent types. This perspective fits well with the logical study of\nagency in computer science, (Grädel,\nThomas, & Wilke 2002; Wooldridge 2009). \nIn an integrated perspective, preferences, beliefs and reasoning\nstyles can all be subsumed under the game-theoretic notion of a\nplayer type. For reasoning about the future course of a game,\nplayers will hence often entertain beliefs about each others’\ntypes. A simple example is Backward Induction, where players assume\nall opponents fully rational throughout. In more complex settings,\nindividual actors may attempt to rationalize various moves observed\nand derive predictions about their opponents’ future behavior by\ntaking a broader range of options into account. Such players may start\nby assuming the counter-player to be a simple machine, and only move\nup to more complex views when required by evidence. In particular,\nthere is no reason to assume uniformity of players or views. Within a\ngiven scenario, a diversity of player types might be present (Liu 2009; Liu\n& Wang 2013; Paul & Ramanujam 2011;\nGhosh & Verbrugge 2018; Bergwerff et al. 2014). For some\ngame-theoretic proposals concerning most frequently occurring player\ntypes, see Camerer (2003). \nThis section has outlined a variety of ways for incorporating players\nand agency into game forms. These come in a hierarchy of richness,\nranging from annotated game trees to epistemic forests, type spaces,\nor yet more abstract models of games. \nAt the thinner end, the focus is on structural aspects of the game,\nincorporating players’ preferences, but not necessarily their\nbeliefs. Such frameworks are typically just rich enough to represent\nequilibria or backward induction paths, and to reason about these in\nlogics of action and preference. Thin models leave much information\nabout players’ knowledge, beliefs, or their modus\noperandi unspecified, and put less emphasis on the actual\ndynamics of game play. \nAt the thicker end, models for games have lush worlds encoding\nplayers’ preferences, information, beliefs, and perhaps even\ntheir complete types, including memory and reasoning capacities.\nTypical models of this kind are found in Stalnaker\n(1998) and Halpern\n(2001). When applied to extensive\ngames rather than strategic-form games, thick models can anticipate\nanything that can happen in one large temporal universe, allowing to\nderive a full prediction about how play will proceed. \nThe distinction between thick and thin logical models seems folklore\nin applied logic. In fact, it occurred already in the\nearlier-mentioned choice between local logics with single step\nmodalities versus temporal logics built over a complete universe of\nhistories. Yet, there does not seem to be a unique best perspective.\nRather, the choice between thick and thin models often depends on the\nexact goals pursued. A central consideration in this trade off is\nwhere the dynamics of stepwise play should be located: Thick models\npre-encoded such dynamics, whereas thin models allow for an external\ndynamic logics for updates (Baltag, Smets, and\nZvesper 2009). The next section will highlight a number of ways\nfor complementing a thin perspective with dynamic information on game\nplay through representations of actions and updates. \nDeontic reasoning Preference is closely\nrelated to obligation and permission. This shows in particular on the\nformal side, where preference logic in both static and dynamic\nvariants (Hansson 1990; van Benthem, Grossi,\n& Liu 2014) has clear analogies with\n deontic logic.\n Moreover, deontic and game-theoretic perspectives have given rise to\nmany fruitful connections. In one direction, deontic notions may be\nseen as high-level descriptions of optimal actions given the\ninformation and obligations of agents (Kooi\n& Tamminga 2008; Anglberger, Gratzl, & Roy 2015).\nConversely, game solution procedures can enrich accounts of deontic\nnotions (Başkent, Loohuis and Parikh 2012; Horty 2018).\nLastly, in artificial intelligence, deontic perspectives arise in\ntracking the behavior of a distributed system in relation to its\ngoals, (Ågotnes & Wooldridge\n2010). \nMathematical foundations Incorporating\nplayers raises new questions about game equivalence. When agency\nmatters, adequate notions of equivalence cannot stop at preserving\nproperties of the underlying game form. Rather, player-dependent\nequivalences will also require preservation of players’\nbeliefs, preferences or reasoning types. Incorporating such additional\nparameters makes it harder for two games to be equivalent, as new\nspace for variation comes into play. On the other hand, agent\nlimitations might also create new simpler game equivalences that can\nbe studied by the tools of this entry. \nThe term ‘game theory’ suggests that everything of\ninterest is captured in the format of a game with its moves and\noutcomes. The present entry reassembles this perspective, considering\nadditional structure. A first extension was offered in\n Section 3,\n treating the nature of players as a topic in its own right. This\nsections puts a spotlight on a second topic, game play in a wider\nsense. \nMany themes in the literature on logic and games fall into three\nphases connected to play. Certain activities can already be conducted\nbefore the actual game. Examples are assessing the opponent\nor forming a plan. Most relevant choices and decisions, however, take\nplace during the game - at least unless one thinks of players\nas automata blindly following preset strategies. Lastly, also\nafter a game significant activities occur. These involve\nlearning about opponent types, identifying crucial mistakes made, or\nrationalizing the moves taken. In what follows, examples will be\npresented of each phase. \nWhen viewing games as static structures, rationality can be defined in\nterms of coherence between players’\n beliefs, preferences and choices or intentions\n (Elster 1988). However, rationality\nalso describes a quality of behavior, related to how players act or\nwhat they take advantage of when deliberating about a game. The\nrelation between both perspectives can be made concrete when\ninterpreting game solution procedures as styles of pregame\ndeliberation. To follow is a dynamic analysis of Backward Induction\n(cf.\n Section 3.3)\n that differs conceptually from\n characterization theorems\n in terms of static properties such as common knowledge or common\nbelief. In the dynamic analysis, these group properties are not\nassumed as preconditions. Rather, they are produced through the logic\nof deliberation. \nThe Backward Induction algorithm is usually presented in a\nquantitative setting, where each outcome is associated with  utility values for all players. \n(Leyton-Brown and Shoham 2008). However,\nthe same algorithm also works in a qualitative setting, with attitudes\nexpressed by a preference relation between outcomes. \nBackward Induction Backward Induction\ncomputes optimal moves for players. More specifically, at each choice\nnode of an extensive form game, one or more of the available moves is\nlabeled as optimal. For each player this set of optimal moves often\nforms a strategy in the usual game-theoretic sense, i.e., a function\nselecting a unique action to take at each of her choice nodes. Yet,\nthere are degenerate cases where backward induction merely creates a\nrelational strategy, restricting the available moves, while still\nleaving some choices to the player. \nThe principle driving the Backward Induction algorithm is that no\nplayer should ever select a move that is dominated by another move\navailable at the same moment. Dominance here works in a recursive\nmanner. Move a dominates move b if the corresponding\nplayer prefers each final outcome reachable from a by following\nBackward Induction moves to every outcome reachable from b by\nBackward Induction moves. \nPublic announcement of rationality In\none perspective, Backward Induction can be understood as a process of\nprior-to-play deliberation, executed by players whose minds proceed in\nharmony. Deliberation steps are repeated public announcements\n(\\(!\\rat\\)) of rationality-at-nodes: \nDominance here is a relation between the outcomes available after a\ncertain move has been made. In one interpretation, some move a\ndominates another move b if every outcome that remains\nobtainable after a is preferred to any outcome reachable after\na b move. However, there is a dynamic twist: crucially, the\ngame tree considered, and hence the outcomes available, changes during\nthe deliberation procedure. \nThe semantics of\n announcement updates\n works by trimming models. \\(!\\varphi\\) transforms a model M\ninto a sub-model \\(M_{|\\varphi}\\) consisting of all those points in\nM that satisfy \\(\\varphi\\), while deleting all \\(\\neg\\varphi\\)\nnodes. Relations on \\(M_{|\\varphi}\\) are those inherited from\nM. Crucially, deletion may change the truth value of formulas:\nafter announcing \\(!\\varphi\\), some nodes in \\(M_{|\\varphi}\\) may\nsatisfy \\(\\neg\\varphi\\). In particular, with M the set of\npoints in a game tree, the set of available histories may keep\nshrinking as successive announcements are made. Hence, repeated\nannouncements of \\(!\\rat \\) make sense. In finite games, this process\nalways reaches a limit, a smallest subgame where no move is dominated\nby another. \nExample Solving games through iterated\nassertions of rationality. \nConsider the following game, already introduced in\n Section 1.1.\n Iterated announcements of \\(!\\rat \\) removes nodes that can only be\nreached by dominated moves as long as this can be done. The trace of\nthis procedure is: \nFigure 15.\n ⓘ \nHere, the Backward Induction solution emerges step by step. Stage 1 of\nthe procedure rules out the leaf labeled with (\\(2,2\\)) as the only\npoint where \\(\\rat \\) fails. Stage 2 then rules out E’s\nchoice node as new node where \\(\\rat\\) fails. In the resulting game\ntree, \\(\\rat \\) holds throughout. \nMore generally, let \\((!\\varphi, M)^\\#\\) be the limit (i.e., the first\nfixed point) of M under repeatedly announcing \\(\\varphi\\) as\nlong as it still true. In any game tree, the fixed-point \\((!\\rat ,\nM)^\\#\\) has \\(\\rat\\) true throughout. Its nodes contain the actual\nplay computed by the Backward Induction algorithm (van\nBenthem 2014). \nLimit behavior Rationality is\n‘self-fulfilling’ in the limit: if players commit to it in\ndeliberation for long enough, they prune away all irrational moves\nand, a fortiori, all moves incompatible with common belief of\nrationality. The final outcome is a model with rational play at every\npoint, a form of common knowledge of rationality. However, iterated\nannouncements can also yield a different type of limit behavior:\nself-refutation. A prime example for this is the classic Muddy\nChildren puzzle (Gierasimczuk & Szymanik\n2011) where repeatedly communicating ignorance leads to\nknowledge in the end. Also within game theory, a number of situations\nexist where (credible) announcements of future irrationality can leave\nsome player better off than the Backward Induction solution (Leyton-Brown\n& Shoham 2008). \nIterated belief revision. A different\nperspective of pre-game deliberation is couched in terms of belief\ninstead of knowledge. The driving force here is\nrationality-in-belief: \nIn this setting, the game tree itself remains invariant during\ndeliberation: no histories are removed or ruled out. What may change instead \nis the relative plausibility of occurrence players assign to end nodes\nor, in infinite games, histories. \nIn plausibility semantics (briefly introduced in\n Section 3.6),\n an agent believes propositions that hold true in all those\nepistemically accessible worlds that are maximal in her plausibility\norder. The corresponding dynamics of deliberation does not proceed by\npoint deletion, but by soft updates modifying the\nagents’ plausibility ordering. For Backward Induction, a\n‘radical upgrade’ \\(\\Uparrow\\varphi\\) suffices, that moves\nall \\(\\varphi\\)-worlds above all \\(\\neg\\varphi\\)-worlds states while\nmaintaining the ordering within these two sets (Baltag\n& Smets 2008). \nHere is how this mechanism works in a game setting. Start with all end\nnodes equiplausible for all players. Since upgrades proceed by public\nannouncement, all players will share the same beliefs throughout. In\nthe procedure to follow, a move x is dominated in\nbelief by a move y of the same choice node if, in the\nacting agent’s plausibility ordering, the most plausible end\nnodes reachable after y are all better for her than each most\nplausible end node compatible with move x. Now perform radical\nupgrades of type \nExample Backward Induction, soft\nversion. \nHere are the stages for the new procedure in the preceding example,\nwhere the letters \\(x, y, z\\) stand for end nodes or histories of the\ngame: \nFigure 16.\n ⓘ \nIn the top node of the leftmost tree, going right is not dominated in\nbeliefs for player A by going left. So, \\(\\rat ^*\\) only\naffects E’s turn, and radical upgrade with \\(\\Uparrow\\rat\n^*\\) makes \\((0, 3)\\) more plausible than \\((2,2)\\) . After this\nchange, going right has become dominated in beliefs in the top node,\nand a new upgrade takes place, making A’s going left most\nplausible. \nIterated upgrade with \\(\\rat ^*\\) always stabilizes to a fixed\nplausibility order, which is the same for all players. Identifying\neach history of a game with its end node allows for a belief analysis\nof Backward Induction (van Benthem &\nGheerbrant 2010). On finite trees, the histories emerging when\nall players resort to their Backward Induction strategies exactly\ncorrespond to the most plausible end nodes created by iterated radical\nupgrade with rationality-in-belief. An alternative dynamic-epistemic\ncharacterization of Backward Induction, using similar ideas in a\ndifferent mix, can be found in Baltag, Smets,\nand Zvesper (2009). \nStabilization cannot be taken for granted. For other assertions\n\\(\\varphi\\), iterated upgrades \\(\\Uparrow\\varphi\\) can lead to\noscillating or divergent plausibility orders. However, this divergence\nis limited. While cycles can occur for conditional beliefs, every\ntruthful iterated sequence of radical upgrades eventually stabilizes\nall propositional beliefs (Baltag & Smets\n2009). \nFixed-point logic In a more technical\nperspective, Backward Induction strategies can be defined as largest\nsubrelation of the total \\(\\move\\) relation that has at least one\nsuccessor at each non-terminal node, while satisfying a confluence\nproperty between action and preference: \nThis fact is the basis for proving that Backward Induction is\ndefinable in First Order Fix point logic LFP(FFO) (van\nBenthem & Gheerbrant 2010). Results\nin this line of research connect game solution and game-theoretic\nequilibria with fixed-point logics of computation. In simple settings,\nsuch as that of Zermelo’s Theorem mentioned earlier, modal\nfixed-point logics akin to μ-calculus suffice. \nFurther game solution concepts can be analyzed with logics of iterated\nupdate. In particular, iterated updates are not restricted to\nextensive form games, but can also provide insights for games in\nstrategic form. A paradigmatic algorithm is Iterated Removal of\nStrictly Dominated Strategies \\((SD^\\infty)\\). In this setting, a\nstrategy is considered dominated if there exists another strategy that\nyields a strictly higher payoff against any of the opponent’s\nactions. \nExample Iterated removal of strictly\ndominated strategies \\((SD^\\infty)\\). \nConsider the following matrix. As usual, pairs list A’s\nutility first, E’s second. \nFirst remove the right-hand column, i.e., E’s action\nc which is dominated by either of a and b. With c\nbeing removed, A’s action f has become strictly\ndominated. After its removal, E’s action b becomes\nstrictly dominated, and after that, A’s action e.\nAt the end of the process, iterated removal leaves nothing but the\nstate \\((d,a)\\), the game’s unique Nash equilibrium. In general,\nthe resulting game matrix after all removals is guaranteed to contain\nall Nash equilibria of the original game, but it may also contain\nfurther strategy combinations. \nIn this setting, the formal dynamic apparatus involves assertions\nappropriate to the matrix games of\n Section 2.\n In fact, various different types of rationality can be defined in\nlogics for matrix games. Here is an illustration for two-player games,\ninvolving announcements of ‘Weak Rationality’: \nThis statement is the negation, for each player, of her current action\nbeing strongly dominated. Naturally, this property can be expressed\nformally with suitable epistemic action modalities. Yet, even as it\nstands, it is clear that Weak Rationality can be announced to prune\naway strategy profiles, and that in a iterated manner. The strategic\ngame will change every time weak rationality is announced, initiating\na stepwise process that resembles the earlier iterative announcements\nof rationality for Backward Induction. As observed there, limits of\npublic announcements are always reached eventually, as models can only\nget smaller. For announcing Weak Rationality, these limits match the\noutcome of \\(SD^\\infty\\) precisely (van Benthem\n2007). \nA similar style of analysis can be extended to other notions of\nrationality. For instance, taking \\(B_i\\) to stand for ‘the\ncurrent action of player i is best for her against all actions\nof the opponent’, the following formula may be dubbed strong\nrationality SR \nBriefly, the formula expresses that both players have a reasonable\nhope of doing well. Strong Rationality in this sense is\nrelated to the rationalizability program for game solution (Pearce\n1964; de Bruin 2005), where actions\nare discarded if a better response exists under all circumstances.\nStrong Rationality, too, drives a game solution method. \nExample Updates with iterated\nannouncements of strong rationality (SR). \nConsider a slight variation on the previous example. Below is the\nsequence of updates for iterated announcements of strong rationality\n\\((\\textit{SR}^\\omega)\\) \nEach box may be viewed as an epistemic game model, as explained\nearlier. Again, every step of announcement increases players’\nknowledge, until a fixed-point is reached, constituting an equilibrium\nwhere each player knows as much as they can. \nStrong rationality is a more demanding condition than weak\nrationality. While SR implies WR, there can be moves\nthat satisfy weak but not strong rationality. This shows in the\nfollowing difference between the current and the previous example. In the present matrix,\nannouncing Weak Rationality stops after the first step elimination of\naction c. The reason is that, in the second matrix, the row\nplayer’s bottom move is not strictly dominated by any other\naction, so this row remains after re-announcing WR. However,\nunder no possible circumstance is the row player’s bottom action\nbest for her. This contradicts strong rationality and hence that row\nis eliminated by the next SR announcement. More generally,\nthe game matrix resulting from \\((\\textit{SR})^\\infty\\) is a\nsub-matrix of that produced by \\((\\textit{WR})^\\infty\\). Notably, this\nis not entirely obvious, as the two update sequences may produce\ndifferent epistemic models satisfying different formulas. A proof can\nbe found in van Benthem (2014). \nJust as with Backward Induction, there are connections between\niterated announcements and fixed-point logics. The set of strategy\nprofiles that survive iterated announcements of strong rationality can\nbe defined in modal μ-calculi (Kozen 1983;\nVenema 2008). If announcements are generalized to arbitrary\nformulas, so-called deflationary fixed-point logics are needed for\nstudying limit behavior (Ebbinghaus & Flum\n1995; Dawar, Grädel, & Kreutzer 2004). \nFurther game solution concepts have been analyzed in a similar dynamic\nupdate style. The iterated regret minimization of Halpern\nand Pass (2012), for instance, has\nbeen captured in terms of iterated announcements (Bobbio\n& Cio 2018). \nIt should be noted, that there are also more deductive takes on\nsolution concepts, where successive inferences assume the role of the\nsemantic updates above. A systematic proof-theoretic perspective on\ngame-theoretic reasoning toward solution can be found in de\nBruin (2005). Lastly, alternative analyses\nof Strong and Weak Rationality as well as other game solution\nconcepts, in an abstract rewriting format of computational logic can\nbe found in Apt (2005). \nDigression: comparing across representation\nlevels Different iterative announcement procedures\nlead to different analyses of games. Moreover when comparing various\nprocedures across different frameworks, surprises may occur. For an\nillustration, take Backward Induction. Its dynamic analysis produced a\nnew ‘best move’ relation or plausibility order on an\nextensive form game. The resulting strategy profiles may differ from a\nNash equilibrium analysis of the associated strategic form game: \nExample Backward Induction and Nash\nequilibria. \nConsider the following game. E has no preferences between any\noutcomes, but A does, as marked by the utility values.\n \nFigure 17. \n ⓘ \nIn the earlier BI analysis, neither move for A dominates the\nother in beliefs, so no move is eliminated. Now consider the two\npossible strategy profiles of each player and compute Nash\nequilibria: \n(Left, right) is not a Nash equilibrium, since A would\ndo better by playing Right, but (Left, left) is. \nThis illustrates differences in logical perspective on strategic and\nextensive form games. Primitive elements of the former, strategies,\nare complex objects in the latter’s game tree that cannot be\nidentified completely at the level of individual nodes alone. A\nrelated point of connecting perspectives in classic game theory gave\nrise to the concept of subgame perfect Nash equilibria (Selten\n1975). \nFurther scenarios Casting game solution\nin terms of deliberation renders it an internal mental process:\nnormally opponents do not sit down together to discuss their game play\nin advance, but reason about the opponents’ possible actions and\nconsiderations. However, the deliberative techniques introduced above\nalso apply to real conversational scenarios. An example related to\ngame theory is the topic of disagreement, first introduced in an\nepistemic setting by Aumann’s\n1976 seminal agreeing to disagree\nresult. Dégremont and Roy (2012)\ninvestigate this topic with techniques of dynamic logic, building on\nclassical results from Geanakoplos and\nPolemarchakis (1982). In this framework, any dialogue where\nagents keep stating whether or not they believe some formula\n\\(\\varphi\\) leads to agreement in the limit model, where updates no\nlonger have any effect. Briefly said, agents cannot disagree forever,\nat least when starting with different hard information, while sharing\na well-founded plausibility order. \nGame play is a dynamic process, where players repeatedly obtain new\ninformation about other players. Certain aspects of information\ncollection are hard-wired into the game’s structure, such as\nobserving moves, or, in settings of imperfect observation, changing\nfrom one information state to another. Other updates may be\nextraneous, such as signals about the type of opponent one is dealing\nwith. As of now, there is no general logical theory encompassing all\nthese phenomena. Yet, instructive samples exist. The first topic to\naddress concerns the players’ knowledge, the second their\nbelief. \nIn one perspective, games annotated with imperfect information cells\ncan be interpreted as recording a process of actual play. However, an\nimperfect information tree does not suffice to fully specify the trace\nof a real game. This raises the question on how to tease out what has\nreally happened. One style of analysis involves techniques from\n dynamic-epistemic logic.\n In this approach, players are assumed to have perfect recall, they do\nnot forget anything they once knew, while also satisfying No Miracles:\nobservation of actual game play is their only source of information,\n(cf.\n Section 3.6). \nIn a first approximation, every move triggers a public announcement,\ninforming all players what just happened. Many games, however, include\npartially observable moves, where some players merely learn that an\nact has been performed, but not necessarily which. In this case,\ninformation processing requires product updates from\ndynamic-epistemic logic (cf.\nBaltag & Moss\n2004), allowing for an appropriate mixture of\nknowledge and uncertainty. \nExample Decorating a game tree by\nupdates. \nThe left-hand side of the following diagram displays the game’s\nbare action structure, without any information on observability.\nHowever, when moving, players can distinguish their own actions, but\nnot all moves of their opponents. Their precise observational powers\nare described by event models for the individual moves (cf.\nvan Ditmarsch, van der Hoek, & Kooi\n2007). \nFigure 18.\n ⓘ \nThe observational structure on possible moves is encoded by relations\nbetween the corresponding nodes, as described for games of imperfect\ninformation\n (Section 3.6).\n Here are the successive updates that create the uncertainty links in\nthe tree: \nFigure 19.\n ⓘ \nThe resulting annotated tree is the following imperfect information\ngame: \nFigure 20.\n ⓘ \nA similar analysis applies to infinite trees as well as to epistemic\nforests (cf.\n Section 3.6).\n More generally, any imperfect information structure can arise from\ninformation updates, provided players satisfy perfect recall and no\nmiracles, and moves in the game have logically definable preconditions\ngoverning their availability. Precise formulations and proofs can be\nfound in van Benthem, Gerbrandy, Hoshi, and\nPacuit (2009). A generalization to game play without assumption\nof synchronicity is provided in Dégremont,\nLöwe, and Witzel\n(2011). \nNo miracles and perfect recall are typical assumptions for most types\nof agents in game theory. However, certain scenarios require\nmodifications, (cf. Osborne & Rubinstein\n1994 on the ‘drunken driver’ scenario). Moreover,\nif players are represented as finite automata, (cf.\n Section 3.8),\n perfect recall fails, and quite different patterns of uncertainty\nbecome possible. Characterizations results for memory-free and\nmemory-bounded players can be found in Liu\n(2011). \nIn addition to observational restrictions built into the game setup,\nproduct updates can also model extraneous communication or other\ninformation flow parallel to actual play. Some such scenarios will be\nlisted under Further Directions below. \nCertain types of information may be judged inconclusive or not fully\nreliable. While unsuitable for advancing knowledge, such information\nmay prompt agents to alter some of their beliefs. Such inconclusive\nevidence often concerns expectations concerning opponents’\nplayer types. Leaving aside the possibility of mere mistakes, all\nmoves can be assumed to result from intentional, strategic\nconsiderations. By interpreting opponents’ past moves, agents\nmay hence infer about their beliefs, preferences, risk attitudes or\nreasoning types. Naturally, most such observations are not fully\nconclusive. The corresponding updates hence cannot delete any\nalternatives. Rather, they merely change the agent’s\nplausibility ordering \\(\\leq_i\\) among different options. Formally,\nthis can be handled with the plausibility updates introduced for\nBackward Induction. However, the interpretation differs. Here, these\nupdates do not represent steps in pregame deliberation, but result\nfrom actual moves during the game. Besides the radical upgrade\nintroduced above, a number of further updating policies reflecting\ndifferent attitudes to the information acquired are defined in Baltag\nand Smets (2008). The\nepistemic-plausibility patterns that can arise from systematic\nplausibility update in games have been identified in Dégremont\n(2010), using two\ncounterparts of the earlier perfect recall and no miracles properties:\n‘Plausibility Revelation’ and ‘Plausibility\nPropagation’. \nThese results refer to but one aspect of belief in games. There are\nothers. A further type of belief describes agents prior attitudes to\nthe game, generated by past experience or deliberation. Another refers\nto the agents’ beliefs about where they are located in the game\ntree, based on previous observations during play. To keep these\nnotions separate, one might distinguish between more local\n‘beliefs’ during play and future-oriented\n‘expectations’ about the game’s progression.\nPlausibility orders created by Backward Induction, for instance,\ndescribe expectations about future game play. These are not based on\nobservations already made in the present game, and significantly, fail\nto satisfy the properties of plausibility revelation and propagation.\nHere is a particular strand of logical belief and its revision that is\nof independent game-theoretic interest. \nForward Induction Suppose some player\nhas deviated from her Backward Induction strategy as computed in\npre-game deliberation. What are others to make of this? Answers\noffered in the literature range from interpreting the deviation as an\nerror without any future implications (Aumann\n1995) to treating it as significant in various ways (Bicchieri\n1993). In the latter vein, the\ndeviation could be a signal for cooperation (believable or not), a\nsign of limited resources, or it could reveal other relevant\ninformation about the player’s type. \nMore explicitly, the situation has the following aspects. At any stage\nof a game, players have several types of information, including their\nprior expectations of how the game would proceed and the perhaps\nsurprising observations made along the way. If the game is to continue\nfurther, as in the state marked below, agents need to integrate both\ninto expectations about the future course of the game. \nFigure 21.\n ⓘ \nRationalizing There is no unique best\nway of integrating information of the various kinds. Yet, a natural\noption is to maintain the assumption of opponents’ rationality,\ntaken in the earlier sense. Assuming preferences to be common\nknowledge, observed moves hence provide new information about the\nopponent’s belief. More specifically, these beliefs have two\ncomponents: expectations about what other players will do, and\nintentions about their own future actions. The driving principle will\nthen be Rationalizing     \nBy playing a move, a rational player communicates that this move is\nnot strictly dominated-in-beliefs for her. \nClearly, rationalizing can only be maintained as long as the player\ndoes not choose a move that is strictly dominated under all\ncircumstances. In that case, one must ascend a ladder of further\nhypotheses about the opponent, including the possibility of her making\nmistakes. \nReasoning policies of the above type are called Forward\nInduction. Battigalli and Siniscalchi (2002) and\nBrandenburger (2007), analyze Forward Induction in extensive\nform games based on its known tight connection with Iterated Removal\nof Weakly Dominated Strategies in strategic form games. The following\nexample involving explicit reasoning is from Perea\n(2012). \nExample A Forward Induction\nscenario. \nFigure 22.\n ⓘ \nIn the matrix game, no move dominates any other. Hence E should\nconsider all outcomes possible. In this case, going left is\nsafer for her than going right, and hence A should\nplay Left at the start. However, if E rationalizes,\nand observes A going Right, she has extra information\navailable at her choice node. Following the rationality assumption,\nA expects to do better than 3, which is only possible if he\nintends to play Up in the matrix game. Now this tells\nE to proceed to the matrix and play the left column\ntherein. E’s results in a better payoff than the 2 of her\noriginal safe option. \nFrom a logical perspective, a study of Forward Induction requires\nepistemic-doxastic models with ternary world-dependent plausibility\nrelations, combined with the public announcement updates or\nplausibility upgrade described above (Section 4.1.2;\n see. also van Benthem 2014). No definitive logical analysis of\nForward Induction has been published so far. \nComparatively little attention has been paid in the literature to what\nplayers do after a game. Yet, these follow up-activities are often\ncrucial, for instance to establish general lessons learned that may be\nvaluable for future game play. Such interpretations are especially\nprominent in small or isolated groups, where the same opponent might\nbe encountered again in the future. \nPreference change after a game At a\nsimple level, post-game activity can consist in setting, or altering,\nthe second input parameter of rational choice beside belief: the\nplayers’ preferences. Several folklore results relate to this\noption. For instance, when playing against a given strategy of another\nplayer with known preferences, any strategy can be rationalized by\nchoosing suitable preferences among outcomes. Liu\n(2011) discusses several preference based\nrationalization algorithms using dynamic logics of preference\nchange. \nPreference change can also occur during a game. Players may receive\nnew information about the game’s end states and their\nproperties. They may also follow a command or a suggestion from an\nauthority, establishing a preference or reversing an earlier one.\nRelatedly, players may change their external goals pursued in the\ngame, or they may adjust their preferences for more internal reasons,\nas in the phenomenon of ‘sour grapes’ (Elster\n1983). \nThe main focus of this section is the local dynamics of what happens\nbefore, during and after a single game. There is also a broader\nperspective of time, in which all these activities are embedded in an\nextended temporal universe, large enough to include all possible\ntrajectories of the game, finite or just as well infinite. In\n evolutionary game theory,\n in particular, infinite games typically arise from iterated play of\nfinite games, with Lewis’\nsignaling games (2002) as prominent\nexample in philosophy. \nAssuming an extended infinite temporal perspective raises additional\nquestions about players’ strategic foresight and adaptation\n(Christoff 2016). Various long-term\nperspectives differ drastically in this respect, ranging from the\nminimal rationality assumptions typical of evolutionary game theory to\nhigh reasoning complexities of agents anticipating the long term\neffects of their choices. \nTemporal logics While infinite game\nforms were briefly alluded to in\n Section 2.10,\n infinite play focuses on agency over time. A host of temporal logics\nfor this end have been put forward, including interpreted systems\n(Fagin, Halpern et al. 1995),\nepistemic-temporal logic (Parikh &\nRamanujam 2003), STIT (Belnap &\nPerloff 1988; Horty & Belnap 1995), ATL (Alur,\nHenzinger, & Kupferman 2002; van der Hoek\n& Wooldridge 2003), and others. Many of these systems\ncombine multiple modalities. Consequentially, their complexity can be\nvery high (undecidable, non-axiomatizable, or even non-arithmetical),\nas Halpern & Vardi (1986) show in a\npioneering study for the case of combining time and knowledge.\nSurveying this area is beyond the scope of this entry, cf. the entry\non\n temporal logics.\n A unifying view of connections between the various paradigms is\npresented in van Benthem and Pacuit\n(2006). \nFigure 23.\n ⓘ \nJust as with finite games, players’ preferences must be\nspecified for studying equilibria in potentially infinite games. In\nlack of outcome nodes or final moments to attach preferences to, these\nare naturally thought of in terms of players’ goals, expressed\nas properties the game’s histories should satisfy. Such goals\ncan be local propositional facts true at some particular moment. But\ngoals can also concern global properties of histories such as avoiding\nor reaching the same position some specified number of times, or more\nabstractly, achieving safety or fairness in some appropriate sense.\nAll such properties can be specified in temporal logics. For the case\nof Linear Temporal Logic (LTL), the ‘Boolean\ngames’ of Gutierrez, Harrenstein, and\nWooldridge (2015) have developed the temporal goal based\napproach in depth. Notably, this framework validates a logical version\nof the ‘folk theorem’ for iterated games, cf. Osborne\n& Rubinstein (1994): Under natural\nconditions on goals, iterated games can have novel equilibria not\nsupervenient on the base game’s Nash equilibria. Further\nsignificant uses of temporal logics connect game theory with belief\nrevision theory (Battigalli & Bonanno 1999;\nPerea 2012; Stalnaker 1998). \nEvolutionary game theory and dynamical\nsystems A prominent application of iterated games\noccurs in evolutionary game theory (Maynard\nSmith 1982; Hofbauer & Sigmund 1998; Gintis 2000), a\nframework that has many applications in biology, formal sociology, but\nalso linguistics and philosophy (Lewis 2002;\nSkyrms 2010; Alexander 2007; Clark 2012). \nLittle work has been done so far on the logical analysis of\nevolutionary games along the dimensions of this entry. In fact, there\nare striking conceptual differences between evolutionary games and the\nstyle of analysis pursued here that might be dubbed ‘high\nrationality’-oriented. Rather than incorporating intentional,\nstrategic actors, evolutionary games work by temporal progression of a\ndynamical system which is driven by individuals’ fitness values\nderived from game-like encounters with others. Within such systems,\nbehavior is not driven by belief updates or complex strategic\nconsiderations. Rather, players typically display ‘low\nrationality, following certain hard-wired strategies. Much of the\nevolutionary system’s dynamics is then driven by changes in the\npopulation’s composition of strategy types. \nEven so, evolutionary game theory does invite connections to logic.\nThe evolutionary success of simple strategies like Tit-for-Tat (Axelrod\n& Hamilton 1981) raises the\nquestion of just when complex logically based high-rationality\nstrategies can be replaced by equally efficient alternatives simple\nenough to be played by automata or similar models of bounded agents,\n(Grädel, Thomas, & Wilke 2002).\nAt a higher level of abstraction, there also is an incipient line of\nresearch into the connection between logic and dynamical systems, a\nstandard tool for analyzing evolutionary games. This strand includes a\nbimodal topological logic of time (Kremer &\nMints 2007), fixed-point logics of oscillation (van\nBenthem 2015), and a systematic linkage\nbetween dynamic-epistemic update logics and dynamical systems over\nmetric spaces (Klein & Rendsvig\n2017). At a much concreter level, one important species of\nevolutionary games are signaling games (Lewis\n2002; Cho & Kreps 1987; Osborne & Rubinstein 1994; Skyrms\n2010: van Rooy 2004), where agents send and receive signals\nabout the state of the world. Signaling games match up naturally with\nthe earlier dynamics logic of information flow during play. \nTopics discussed in this section are less standard in the literature\nthan those of the sections before. In an orthodox reading, various of\nthe aspects addressed would not be considered part of game theory\nproper. The extended agenda followed here has been embraced by van\nBenthem, Pacuit, and Roy (2011) as a\nlarger program for logic, going under the heading ‘Theory of\nPlay’. The underlying line of reasoning is that games do not\nfully determine their outcomes, as they allow for various styles of\nplay. Hence, it might be the process of play itself, including\nplayers’ types and how they change over time, that might the\nbest focus for understanding interaction, rather than mere games or\ngame forms alone. Similar lines of argument can be found in the\nfoundations of computation where it has been proposed that the\nessential topic of study should be behavior (Abramsky\n2008). \nBelief revision and learning theory\nBelief revision in repeated games bears natural resemblance to limit\nlearning of\n formal learning theory\n (Kelly 1996). Baltag,\nGierasimczuk, and Smets (2011) analyze\nlearning in terms of initial epistemic-doxastic models over which\nfinite histories of signals trigger the learner to revise beliefs,\nrepresented as changes in epistemic accessibility or plausibility\norder. It turns out that both iterated public announcement and\niterated radical upgrade as discussed above are universal learning\nmethods, though only the latter maintains this property in the\npresence of (finitely many) errors in the input stream. \nGoal dynamics and intentions While\npreferences and goals have so far been assumed fixed and universally\nknown, this is by no means necessary. van\nOtterloo (2005) presents a dynamic logic of strategic powers,\nwhere information about players’ intentions and preferences can\nbe announced during play. Roy (2008)\nuses announcements of intentions to obtain simplified solution\nprocedures for strategic games. More concrete scenarios of extraneous\ninformation flow are found in Parikh,\nTaşdemı̇r, and Witzel (2013), where agents\nmanipulate the knowledge of others during play. \nGame change In many real life scenarios,\nplayers do not know the full game tree they are playing. Even if they\ndid, it might change during play. Or, at least, players may attempt to\nchange the game. A concrete example is provided by the game tree in\n Section 4.1.1.\n There, the inefficient Backward induction outcome \\((1, 0)\\) could be\navoided by E promising not to go left. When made binding (for\ninstance through imposing a fine) this announcement eliminates\nhistories and, consequentially, a new backward Induction outcome of\n\\((2,2)\\) results. Hence, both players can be made better off by\nrestricting the freedom of one. Game theory has sophisticated analyses\nof such scenarios, including an analysis of ‘cheap talk’\n(Osborne & Rubinstein 1994), asking\nwhen such announcements are credible. On the logical side, this\nsuggests an analysis of signaling games (van\nRooy 2004). We are not aware of any logical work done in this\ndirection. \nReal games The discrepancy between\nspecification of a game and the realities of play is especially\nstriking in real game play, either of the ‘natural kind’\nin common parlor games (van Ditmarsch &\nKooi 2015), or of the artificial kind found in the laboratory\nexperiments of experimental game theory (Camerer\n2003). Little work has been done by\nlogicians in this realm, though there is a broad tradition of\ncomputational analysis of games (Schaeffer\n& van der Herik 2002; Kurzen 2011). Any adequate\nlogical analysis would clearly need to incorporate the considerations\non bounded agency discussed in\n Section 3. \nMathematical foundations Logic of play\nas discussed here raises issues of how to interfaces local with global\ndynamics. This shows in particular with logical limit behavior, where\nobservations and assertions are made repeatedly. Limit models of\npublic announcement, as described earlier, can be\n‘self-fulfilling’ or ’self-refuting’. In the\nfirst case, the property asserted becomes common knowledge among all\nagents, whereas in the second it eventually becomes false at the\nactual world. With soft update on plausibility models, a third option\narises, namely, infinite oscillation, or even divergence (Baltag\n& Smets 2009). To date, there is\nno general logical theory of these phenomena, but see van Benthem (2011) on the use of\nfixed-point logics for limit models, Miller and\nMoss (2005) on the high complexity of public announcement logic\nwith finitely iterated announcements, and Klein\nand Rendsvig (2017) on limit behavior of product updates. \nThe topic of limit behavior also raises the issue of how local dynamic\nlogics of agency relate to the global temporal logics discussed in\n Section 4.2.4.\n Towards clarifying the connection, van\nBenthem, Gerbrandy, Hoshi, and Pacuit (2009), show how\ndynamic-epistemic logics can be seen as decidable fragments of more\nexpressive temporal logics. Baltag, Smets, and\nZvesper (2009) discuss the related theme of how dynamic\nrepresentations can decrease complexity by shifting information from\nthe temporal universe to dynamic events. \nProbabilities are central to game theory, where they serve two\nprominent roles. First, they structure players’ uncertainty\nabout various aspects of the game, including the state of nature, the\ntype of opponent faced, and past, present, and future moves of other\nplayers. Second, ever since the origins of Game Theory (von\nNeumann & Morgenstern 1944),\nprobabilistic randomization has served to expand the agents’\nspace of possible actions. While the interpretation of such mixed\nstrategies has been the subject of extensive debate (Sugden\n1991), it is uncontroversial that\nrandomized moves add significant depth to the analysis of games. In\nfact, the concept of mixed strategies is vital for a number of seminal\nresults in classic game theory including the existence of Nash\nequilibria in finite games of imperfect information. \nProbability and its logic is a major topic in both mathematics and\nphilosophy, as discussed in the entries on\n interpretations of probability,\n and\n logic and probability.\n The current section merely outlines a few key connections between\nprobability and the logical analysis of games. The following\npresentation assumes all state spaces to be finite, ignoring\nimportant technical and conceptual issues around the transition from\nfinite to infinite state spaces. \nProbabilistic methods are widely employed to represent beliefs of\nagents within and outside of games, witness\n Bayesian epistemology.\n Typically, a probabilistic belief model consists of two components: a\nspace of possible states that the agent’s beliefs range over,\nplus a quantitative probability function denoting how probable the\nagent judges different propositions or states to be. In qualitative\nlogical models, on the other hand, agentive belief is represented in\nvarying degree of detail. The coarsest approach only distinguishes\nstates the agent considers possible from those she rules out. This is the\nperspective of standard epistemic-doxastic logics, such as multi-agent\nS5 and KD45 discussed in\n Section 3.6.\n More fine-grained perspectives are employed in the plausibility\nmodels of Boutilier (1994) and Baltag\nand Smets (2008), where the range of\nepistemic options is structured further by plausibility orderings\nencoding which options agents take to be less or more likely. See also\nSections\n 3.6.4\n and\n 4.2. \nBoth probabilistic and plausibilistic perspectives can express that\nsome alternative is more likely than another. However, there are also\nconceptual differences between the two frameworks. Probabilistic\nmodels can aggregate, allowing their logic to express, for instance,\nwhether many low-probability events combined can outweigh even the\nhighest-probability worlds. Aggregated probabilities play a key\nrole, for instance, in calculations of expected utility. Yet no such\nthing can be expressed in plausibility semantics. For another striking\ndifference, plausibility models lead to a notion of belief that is\nclosed under conjunction. This conjunction closure typically fails for\nprobabilistic accounts of belief. See however Leitgeb\n(2017) for a sophisticated bridge\nbetween both types of modeling.  \nOn a received view, logical and probabilistic frameworks emphasize\ndifferent aspects of belief. Logic emphasizes coherence properties\nbetween the propositions believed, such as closure under logical\nimplications or conjunction. Probabilistic reasoning, on the other\nhand, stresses graded information and attitudes towards uncertain\nevents such as lotteries. Even so, there is a variety of approaches\nattempting to unify the two types of reasoning by constructing bridges\nbetween the frameworks. \nFrom qualitative to quantitative\nprobability Early attempts in this direction go back\nto Finetti (1970 [1974]), striving for a\npurely qualitative axiomatization of probability theory. A step\nfurther towards logical reasoning are various theories of qualitative\nprobability (Kyburg 1994), often based\non the assumption that classical quantitative notions of probability\nare too demanding for real-life agents. In this line of research\nagents need only reason with partial, comparative probability\nassessments, rather than having fully specified probabilities for all\nevents. Logical frameworks for qualitative probability include Segerberg\n(1971), Fagin, Halpern, and Megiddo\n(1990), and Delgrande and Renne\n(2015). While differing in detail, all logics in this line have\nin common that they allow for expressions of the form\n\\(\\varphi\\preceq\\psi\\), indicating that \\(\\psi\\) is judged at least as\nprobable at \\(\\varphi\\). Recent frameworks add various additional\nrefinements to this language. Similarly, Heifetz\nand Mongin (2001) expand the axiomatic\nanalysis of probabilistic beliefs to higher order reasoning, working\non probabilistic type space akin to those introduced in\n Section 3.7. \nYet, the concept of qualitative probability is sometimes considered\nflawed: a complete set of probabilistic-logical principles\nguaranteeing that every complete description in the logical language\ncorresponds to a unique probability measure turns out to require a\ncomplex calculus, involving an opaque infinite rule (Kraft,\nPratt, & Seidenberg 1959; Scott\n1964). A new angle has been proposed in Harrison-Trainor,\nHolliday, and Icard (2016)\nthrough axiomatizing a low-complexity qualitative probabilistic logic\nthat emerges from relaxing the above unique correspondence requirement\nto merely requiring compatibility with all probability measures of a\ncertain family. \nHowever, none of the frameworks described here are specific for games.\nIn fact, it remains to be seen whether qualitative probabilistic\nlogics, old or recent, can be used for a qualitative analysis of\ngame-theoretic solution concepts. \nFrom quantitative to qualitative\nprobability While the preceding line of research aims\nat recovering quantitative probability from qualitative notions, a\nconverse project shows how ubiquitous qualitative patterns might arise\nnaturally within a quantitative probabilistic setting. Building on\nwhat is sometimes dubbed the Lockean Thesis, threshold\napproaches connect probability to logic by stipulating that some\n\\(\\varphi\\) is to be believed simpliciter if the probability of\n\\(\\varphi\\) is above some appropriate numerical threshold t.\nFor most choices of threshold t, such translations do not\nsquare well with standard logical desiderata, as beliefs will in\ngeneral not be closed under conjunction. However, in recent work Leitgeb\n(2017) and Lin\nand Kelly (2012) have identified conditions under which one can\ndo better. Building on ideas of Skyrms\n(1977), Leitgeb identifies\nstrong, context-dependent ‘robustness conditions’ on\nthresholds that guarantee the defined belief operator to satisfy the\nKD45 axioms after all. Lin and Kelly, on\nthe other hand, work with non-uniform thresholds for transitioning\nbetween logical and probabilistic notions of belief, allowing to\nderive coherence between different forms of belief dynamics on the two\nsides. For a recent study of the mathematical foundations and limits\nof these approaches, as well as the conditional logics they generate\nsee Mierzewski (2018). \nIn the dynamic perspective of game play, every move constitutes a new\npiece of information agents have to take into account. Besides,\nplayers may also change their beliefs about the game upon\ndeliberation, through communication or any other signals they receive,\nbe they reliable or not ( cf.\n Section 4).\n All such dynamic events raise the question of how new information is\nto be incorporated into the agents’ beliefs and when\nprobabilistic updates have corresponding logical revisions or vice\nversa. \nIf the new information is of the hard type, accepted as irrevocably\ntrue by all agents, the probabilistic counterpart of logical public\nannouncements is Bayesian conditioning. Both notions track each other\nat a semantic level, meaning that their outputs amount to the same\nthing. Computing beliefs after a public announcement means recomputing\nin the submodel consisting of all states where the information\nreceived was true. This is exactly the same mechanism as for\nrecalculating probabilities in Bayesian update. Moreover, for\nreasoning about updates, both approaches require conditional notions:\nconditional belief and conditional probability respectively. The\nquantitative notion of conditional belief relates to the logical\nnotion of conditional belief \\(B(\\varphi|\\psi)\\), with the slight\ncaveat that the latter also allows for epistemic or doxastic operators\ninside either argument. More refined logical notions of conditional\nbelief arise in the earlier-mentioned plausibility semantics of\n Section 4.1.2,\n (Baltag & Smets 2008). \nGiven the co-existence of qualitative and quantitative perspectives,\nit makes sense to ask whether one can track the other. In a\nstatic sense, tracking asks whether different notions of belief can be\ntranslated into each other by omitting or transforming some of the\nsemantic details involved. A dynamic interpretation expands on this by\nasking whether updating, either in the hard or soft varieties of\n Section 4,\n is compatible with these translations in a commutative diagram:\nInformation update in a new perspective after translation should yield\nsame result as first performing a matching update in the old\nperspective and then translating (van Benthem\n2016). In games, the topic of tracking may refer not just to\ninformation update, but also to solution concepts or moves in game\nplay described at the various levels considered in\n Section 2. \nThe existence of tracking maps depends on the exact type of update\nconsidered. By now there is a wide variety of updating policies on\nplausibility models (van Benthem & Smets\n2015), not all of which have obvious probabilistic\ncounterparts. Likewise, for well-known varieties of probabilistic\nupdate, such as Jeffrey update, where the probability of selected\npropositions can be reset at will, plausibility counterparts are not\neasy to find, though the attempt of van Benthem,\nGerbrandy, and Kooi (2009) modifies dynamic-epistemic logic to\nallow for Jeffrey update and other generalized probabilistic\npolicies. \nVirtually all aspects of game theory provide contacts between logical\nand probabilistic perspectives. Clearly, this is true for the\ndifferent representations of knowledge, beliefs and their dynamics\njust discussed. Other contacts occur at the level of game forms, cf.\n Section 2,\n where probabilities enrich the space of strategies. The resulting mixed moves require players to expand their\npreferences to mixed outcomes, cf.\n Section 3.\n Finally, at the level of reasoning about game play, cf.\n Section 4,\n probabilistic beliefs play a role in solution techniques such as\ndominance or expected utility based reasoning. \nAvailable actions and mixed strategies\nProbabilistic mixtures of pure strategies are prominent in game\ntheory, as they can secure outcomes and payoffs that no pure strategy\nalone could guarantee. \nExample Matching Pennies. \nConsider the well-known game of matching pennies in matrix form: \nFor Ann, a mixed strategy of playing a exactly half of the time\nguarantees an expected outcome of 0, no matter what Bob does. No pure\nstrategy could have achieved this. \nFrom a logical point of view, mixed strategies can be conceptualized as new\nprimitive actions in the earlier logics of games ( cf.\n Section 2).\n Yet, this treatment immediately renders the set of available actions\ninfinite. A cautiously refined logical language, extending logical\napproaches to qualitative probability, can allow for expressions such\nas an agent playing action a with probability at least\nq, (Delgrande and Renne\n2015). \nA more challenging general question is how to relate classic\nprobabilistic approaches with their fixed-point results and ensuing\nequilibrium existence theorems, with the logical fixed-point\napproaches mentioned at several places in this entry. The latter\noperate with step-by-step ordinal iterations, as opposed to the\ngradual, approximative procedures that underlie the Brouwer or\nKakutani fixed-point theorems relevant for classical game theory. A\nrelated question is just how much logic is needed to reproduce\nprobabilistic existence theorems within a qualitative framework. \nAdding players’ preferences Once\npreferences are added, mixed strategies trigger additional\nintricacies. A strategy profile where some players pursue mixed\nstrategies does not produce a unique outcome, but a weighted\ncombination of outcomes. Thus, permitting mixed strategies requires\nlifting preference relations to probabilistic mixtures of outcomes or\nstrategy profiles. Incorporating such mixtures may implicitly depart\nfrom the standard, purely qualitative perspective on outcomes (Ramsey\n1931; Savage 1954). \nExample Extended preference\ncomparison. \nThe following two games are equivalent in terms of qualitative (i.e.,\nordinal) preferences between outcomes for both players. However, they\ndiffer in preferences between mixed outcomes, with  \nholding in the game to the left, but not in that to the right. \nGoing this way poses some logical challenges. For example, consider a\npreference relation over probabilistic mixtures of outcomes, where\n\\(m^t(a,b)\\) stands for obtaining a with a probability of\nt, and b otherwise. This setting is in the scope of\nvon Neumann and Morgenstern’s\n1944 well-known ‘continuity\naxiom’ that is characterized by an implicit infinite\ndisjunction:  \nThis seems well beyond the expressive power of standard probabilistic\nlogics. \nSolution concepts and game play\nProbabilization also impact the process of game play and its reasoning\ndynamics, for instance by changing the earlier-mentioned calculus of\nweak and strong dominance\n (Section 3.4).\n Consider the following game, cf. de Bruin\n(2005): \nNone of A’s strategies are dominated in terms of pure\nstrategies. However, in terms of expected outcomes, c is\ndominated by an equal mixture of a and b. Thus, solution\nprocedures analyzed earlier such as iterated removal of weakly or\nstrongly dominated strategies may provide different and incompatible\noutcomes, depending on whether mixed strategies are considered or not.\nNo satisfactory logical analysis of the earlier kind seems to exist\nfor this setting. \nFurther challenges to the interplay of logic and probabilistic\nreasoning abound. By way of conclusion, here is a dimension that seems\nhard to capture in purely qualitative logical terms. A characteristic\nfeature of game- and decision-theoretic reasoning is that beliefs and\npreferences are entangled in various ways (Liu\n2011). For instance, the crucial notion\nof expected utility entangles probability, representing beliefs, with\nutilities, standing for preferences. Players faced with probabilistic\nuncertainty about the opponent’s present and future actions are\noften advised to maximize expected utility (von\nNeumann & Morgenstern 1944; Savage 1954). Hence, even if\none has found qualitative counterparts for probabilistic belief and\ncardinal utility separately, entanglement poses the additional\ndifficulty of merging these two qualitative analyses in a way that\nmatches what the quantitative side achieves easily by forming some\narithmetical combination of both components. \nThe main topic of this entry is a logical approach to game theory,\nbringing classical notions and methods from logic to bear upon games.\nThis project is sometimes called ‘logic of games’. There\nalso is a converse direction of ‘logic as games’, where\ngame theoretic concepts are employed to elucidate basic notions of\nlogic. This section presents a brief discussion on this direction as a\nnatural counterpoint to the main lines of the entry. For an extensive\nsurvey see the entries on\n logic and games\n and\n games, abstraction and completeness. \nMany notions in logic have been analyzed in game-theoretic terms \nEvaluation games There are well-known\ntwo-player games for evaluating a first-order formula \\(\\varphi\\)\nwithin a given logical model. These games are played between Verifier\nand Falsifier, who can both test atomic assertions, and specify the\nvalue of variables from a given domain (Hintikka\n1973). The schedule of the game is\ndetermined from the syntactic structure of the formula \\(\\varphi\\).\nDisjunctions and existential quantifiers require choices of the\nVerifier, conjunctions and universal quantifiers of the Falsifier,\nand negations trigger a role switch between the two players. The\nresult is the following match between winning strategies and the\nordinary semantic notion of truth: \nFormula \\(\\varphi\\) is true in model M under assignment\ns iff the Verifier has a winning strategy in the associated\ngame \\(game(M, s, \\varphi)\\).  \nCorrespondingly, Falsifier has a winning strategy if the formula\n\\(\\varphi\\) is false in the model. Evaluation games turn out to be an\nextremely flexible tool. By suitably modulating rules and winning\nconventions, adequate evaluation games can be found for most logical\nsystems. Doing so, however, can be a highly non-trivial task, as\nwitnessed by the intricate infinite ‘parity games’\ncorresponding to fixed-point logics such as the modal μ-calculus\n(Venema 2008). For the present purpose,\nit should be noted that this style of analysis ties the very logical\noperations, conjunctions, disjunctions, modal operators, to natural\nmoves in a game. Similarly, the notion of truth is linked to the\nfundamental game-theoretic notion of a strategy in an extensive form\ngame (cf.\n Section 2):\n a complex, structured object which may here be understood as a reason\nor an explanation for the truth or falsity of the formula. \nThe links between both perspectives are so close, that valid\nprinciples of logic come to express game-theoretic facts. For\ninstance, after a little analysis, the law of excluded middle implies\nthat always either Verifier or Falsifier has a winning strategy, cf. Section 2.4. In\nother words, logical evaluation games for classical logic are\ndetermined in the game-theoretic sense. In fact, This property extends\nto most games for non-classical logics. \nFurther logic games Logic games exist\nfor many other purposes. Ehrenfeucht-Fraïssé games serve\nmodel comparison (Ehrenfeucht 1961; Ebbinghaus\n& Flum 1995), Lorenzen games perform proof analysis (Kamlah\n1973 [1984]) and tableau games execute\nmodel construction (Hodges 1985). In\neach case, strategies in the game match important logical notions. In\nLorenzen dialogue games, for instance, winning strategies for the\nProponent of a claim correspond to proofs of that claim from premises\ngranted by the Opponent, whereas winning strategies for the Opponent\nare constructions of counter-models. Thus, proofs and models, two\nquite distinct notions in logic, co-exist within a single game. \nThere exists an alternative, game-theoretic way of interpreting these\nconnective results. Suppose the game under study is fixed, and\nassociated with some sort of ‘game board’ representing\nmajor features of the game’s general state (think of Chess,\nthough more abstract game boards may occur). Then the above\nequivalences suggest that winning strategies, i.e., a typical\ngame-theoretic notion defined in terms of the complete extensive game\ntree, is equivalent to a simpler ‘invariant’ that can be\ndefined entirely in terms of some game board associated with the\ntree’s nodes. Identifying useful such invariants is a well-known\nart in the analysis of concrete games. In terms of a main theme of\nthis entry, invariants can live at different levels of representation\nassociated with a given class of games. \nGame semantics One can view logic games\nas mere didactic devices analyzing logical notions that were already\nwell-understood. Or, in other terms, as offering a concrete way of\nteaching logic that draws on game-theoretic intuitions. However, logic\ngames have more to offer. First of all, new logics are suggested by\npursuing natural variations in winning conventions, moves, or\nscheduling within existing logic games. Moreover, viewing logical\noperations as game constructors suggests a new, refined view on\nlogical constants. Conjunction, for instance, now splits naturally\ninto a sequential and a parallel version. Similar examples of\nparallelism also exist in logics of computation. Moreover, associating\nquantifiers with object picking, as in evaluation games, turns\nquantifiers into special types of atomic games that connect to the\nfollowing formula by an abstract operation of game composition. The\ngeneral logic of this abstract composition operation combined with\npropositional operations of choice and switch has been shown\ndecidable, providing a new decidable core logic inside first-order\nlogic whose existence had not been suspected (van\nBenthem 2014). Games, hence, can offer a\nfresh perspective on existing logical systems. \nA major source of independent, game-theoretic perspectives on logic is\nthe game semantics of computational logics. In this setting, the\nstatus of logic games may change. Rather than being a mere pedagogical\nor exploratory device, to some, these games are considered the true\nmeaning of logical constants. \nThe distinction between game logics and logic games is not always\nsharp. Recent literature has seen a number of games whose design is\nconnected to logic, yet they are not meant to analyze logical notions\nper se. \nExample Sabotage Games. \nSabotage games were proposed to analyze algorithmic tasks in adverse\ncircumstances. Consider the below network between some European\ncities: \nFigure 24.\n ⓘ \nIt is easy to travel either way between Amsterdam and the German town\nof Saarbruecken. Now, let a malevolent Demon start canceling\nconnections in the network. At every stage, let the Demon take out one\nlink, while the Traveler can afterwards follow one of the remaining\nlinks. This turns a one-agent planning problem into a two-player\nsabotage game. Zermelo-style reasoning shows that, from Saarbruecken,\na German Traveler still has a winning strategy, while in Amsterdam,\nthe Demon has the winning strategy against the Dutch Traveler, by\nfirst cutting a link close to Saarbruecken. The symmetry of the\noriginal search problem is broken. \nThe sabotage game has been applied to a variety of scenarios,\nincluding learning (Gierasimczuk, Kurzen, &\nVelázquez-Quesada 2009), and communication networks\n(Aucher, van Benthem, & Grossi\n2018). On finite graphs, the game is clearly determined, with\nthe computational complexity of identifying who has a winning strategy\nbeing Pspace-complete (Löding & Rohde\n2003). \nThe existence of this winning strategy can be expressed by a\nfirst-order formula. More specifically, winning conditions can be\ndefined in a bimodal logic that combines a standard modality for\ntravel steps with a new modality for one-step arrow deletion,\ninterpreted in models \\(M = (W, R, V)\\): \n\\(M, s \\vDash [{-}]\\varphi\\quad\\)\nFor each edge \\((u, v)\\) in \\(R:\\, \\, (W, R {-} \\{(u. v)\\}, V) \\vDash\n\\varphi\\) \nThis logic fits the sabotage game closely. On top, it is a natural\nfragment of the first-order language of graphs. Surprisingly, this\nlogic is undecidable (Löding & Rohde\n2003), making it one of the simplest examples of an undecidable\nmodal logic over arbitrary models. \nFurther graph games in a similar spirit exist, including the poison\ngame of Duchet and Meyniel (1993), where\nthe Demon poisons nodes, rather than deleting edges. Extensive studies\nof modal logics for changing graphs, and μ-calculi for defining\ngeneric solutions to graph games are given in Areces,\nFigueira et al. (2011); Areces, Fervari, and\nHoffmann (2015); and Aucher, van Benthem, and Grossi (2018). A\nclassification of graph games including the effects of complex goal\nformulas and imperfect information is found in van\nBenthem and Liu (2019). \nOne perspective on such logics for reasoning about model change is the\nsemantic games approach of\n Section 6.1.\n In standard evaluation games, the initial model does not change.\nModalities for model change, however, require a process of formula\nevaluation where the model of evaluation changes as, say, witnesses\nfor quantifiers are not replaced (unlike in standard semantics for\nfirst-order logic), or moves change facts by causing damage to\naccessibility relations. In other contexts, similar modalities are\njustified by physical measurements that change the phenomenon under\ninvestigation, (Hintikka 2002; Renardel 2001;\nÅgotnes and Wáng 2017). Such generalized form of\nsemantics are of independent logical interest. \nExample Knowledge Games. \nNew logical games also arise naturally within the dynamics of\ninformation, knowledge or belief as triggered by the process of game\nplay (cf.\n Section 4).\n In particular, information update suggests conversation games between\nparticipants with similar or different goals. These games may be\ncooperative, with players aiming to pool their information, thereby\nturning distributed knowledge into common knowledge (Meyer\n& van der Hoek 1995). But they can\nalso be competitive, say, when players strive to be the first to know\nwhether some relevant proposition holds. Mixtures between both modes\nalso occur, for instance with some players aiming to communicate a\nfact that outsiders should not learn about (van\nDitmarsch 2003). \nA concrete example are the ‘announcement games’ of Ågotnes\nand van Ditmarsch (2011).\nPlayers speak simultaneously and only once, while pursuing goal that\nare specified as epistemic formulas. Speaking is modeled by public\nannouncement, and players preferences are binary. They prefer final\nmodels where their goal formula holds over those where it is\nfalse. \nThese games are conducted under imperfect information, as players may\nnot know the true state of their epistemic model. Accordingly, the\nrelevant strategies need to be uniform. Players must say the same\nthing in all states they cannot distinguish. In general, then, many\nsolution concepts produce mixed strategy outcomes. In fact, it can be\nshown that there exists simple announcement games without any unique\nequilibrium in pure strategies. However, there is a relevant role for\nlogic to play. Suppose that the goal statements are all\n‘universal’, i.e., constructed from literals by applying\nonly conjunction, disjunction, knowledge operators, and dynamic\nmodalities with universal announcements. Truth of such formulas is\npreserved when transitioning from a model to a submodel. Consequently,\nepistemic uncertainty becomes less harmful and knowledge games with\nuniversal goals have equilibria in pure strategies. Recently,\nknowledge games have been expanded further to include both questions\nand answers as separate actions of issue change and information change\n(Ågotnes, van Benthem et al.\n2012). \nExample Boolean games. \nA third example of game design in between game logics and logic games\nare the Boolean games of Harrenstein et al.\n(2001) and Gutierrez, Harrenstein, and\nWooldridge (2015) that have been mentioned several times\nalready. Each player is handed control over a subset of the\npropositional variables, and can pick truth values for these at will.\nUsing goals specified in temporal logics, these games can model a\nlarge number of relevant scenarios of agency. By now, a growing\nbody of work addresses various aspects of Boolean games including\ntheir computational characteristics (both single-shot and iterated),\ntheir game-theoretic properties and equilibria (Gutierrez,\nHarrenstein, & Wooldridge\n2015), and their connections with games played on social\nnetworks (Seligman & Thompson 2015).\nFurther discussion can be found in the entry on\n coalitional powers. \nBack and forth between game logics and logic\ngames The topic of this section suggests cycles\nbetween the two perspectives on logic and games. Given a logical\nsystem, one can design logical games for it, which can then again be\nstudied using some appropriate game logic. Conversely, given a game,\none can introduce a logic for describing it, and then introduce\nevaluation games for that logic, and so on. Sometimes these cycles\nreach fixed-points, where, say, the evaluation game for a formula\ndescribing some game is isomorphic to that game itself. But sometimes,\nthe cycling continues. For discussion, see Rebuschi\n(2006) and van Benthem (2014). \nImperfect information Logic games\nnaturally support imperfect information, where players do not have\ncomplete access to what their opponents do. Epistemic variations can\nhave far-reaching consequences for the corresponding logics. A\nparticularly prominent framework among this lines is the\n independence friendly logic\n of Hintikka and Sandu (1989), see also\nHintikka and Sandu (1997) and Mann, Sandu, and\nSevenster (2011). \nArgumentation games and graph games\nAnother strand of game analysis with a connection to logic is the\nstudy of argumentation networks (Dung 1995;\nCaminada & Gabbay 2009), with uses in AI and philosophy\n(Grossi 2013; Shi 2018) \nComputational logic The material in this\nsection is closely connected to games in computational logic, which\nserve to analyze expressive power of languages. For relevant results\nand connections with automata theory, see Grädel,\nThomas, and Wilke (2002) and\nvan Benthem (2014). \nGaming and mechanism design Game design\nis a well-known aspect in the area of gaming (Rouse\n2000). Likewise, mechanism design is an\nestablished topic in game theory (Nisan &\nRonen 2001; Osborne & Rubinstein 1994). For connections\nbetween between logic, game design and planning, see (Löwe,\nPacuit, & Witzel 2011; Löwe\n2008). \nThis entry presents an overview of current work at the interface of\nlogic and games. The topics surveyed fall in a number of strands\nincluding current logical analysis of games in the broadest sense,\ncontacts between logic and classic game theory, connections with\nprobability and with computation, and, lastly, the game theoretic\ncontent of logic itself. All this produced a perhaps bewildering\nvariety of logical systems. Yet, this entry emphasized the coherence\nof different approaches to logical analysis, some ‘zooming\nin’ on particular aspects in detail, others ‘zooming\nout’, thereby focusing on general patterns. What has hopefully\nbecome clear in this way is that the various topics span a highly\ninterconnected field. For further details, see the various\ngame-related entries in this Encyclopedia and the literature\ncited. \nIn terms of further desiderata, the coarse grained perspective of\nlogical modeling may help discover new abstract, general patterns in\nsocial behavior beyond the details of games and game theory. A\nconcrete example might be a description of general skills and insights\nthat players acquire by playing a given type of games. A more\nfoundational example would be a formalization of the insight that all\nconcrete social interaction rest on underlying general notions of\n‘dependence’ with their own high-level logic, cf. the\nsemantic dependence logics of Väänänen\n(2007) and Baltag (2016). For an\nalternative proof-theoretic approach in this style, relying on the\ngeneral postulates for competitive games of Johansen\n(1982), see Hu\nand Kaneko (2014). \nThe interface area of logic and games still is in statu\nnascendi. Correspondingly, there are obvious gaps and desiderata\non the logic side, which are reflected in the material in this\nentry. \nIn particular, one fundamental theme are syntactic perspectives on\ngame-theoretic reasoning. Samples of a proof-theoretic style of\nanalysis for play can be found in de Bruin\n(2005). More concretely, Zvesper\n(2010) analyzes classical results in epistemic game theory,\n(cf. Tan & Werlang 1988; Aumann\n1999), in terms of abstract modalities for belief and\noptimality, showing how a few simple proof rules from modal\nμ-calculus can capture the essence of famous results in epistemic\ngame theory. Proof-theoretic aspects of logic have so far been \novershadowed by semantic analyses, although this situation is changing\nslowly (Artemov 2014; Kaneko 2002; Kaneko &\nSuzuki 2003). Model-based reasoning provides abstract semantic\nperspectives on games that can aid conceptual clarification, and the\ndiscovery of general laws. But it might turn out to be proof theory\nthat governs the concrete reasoning used in the semantics, and that\nmay be able to guide the context of justification in establishing\ngeneral facts about games. \nA further contact with logic that has been ignored in this entry is\nthe rich interface between games and descriptive set theory (Woodin\n2010; Kanamori 2003). \nIt should be stressed once more that logic is not the only formal\ndiscipline that throws light on games. Quantitative probability enters\nthe study of games in many ways, both in classical and in evolutionary\ngame theory. The interface of logic and games may well profit from the\nmany old and new contacts between logic and probability (Leitgeb\n2017; Lin & Kelly 2012;\nHarrison-Trainor, Holliday, & Icard 2016). \nAnother link that remained underrepresented in this entry are\ncomputational aspects. The study of games, play and players has\nnatural connections with computation and agency in computer science\nand AI (Grädel, Thomas, & Wilke 2002;\nAbramsky 2008; Halpern 2013; Perea 2012; Brandenburger 2014).\nThe proper perspective on what has been presented here may well turn\nout to be a triangle of interfaces between logic, games, and\ncomputation. \nAs for still broader connections, we have not done justice to all\nlinks between logic, games and philosophy, of which more are found in\nStalnaker (1996, 1999). The same is true\nfor links to linguistics and psychology (Clark\n2012). In this language-oriented connection, one should also\nmention the work of Bjorndahl, Halpern, and\nPass (2017) on the natural language used in specifying games\nand reasoning about them, thus making game analysis more\ndescription-dependent. \nFinally, the main thrust of this entry is theoretical and\nfoundational. However, there also is a more practical aspect to logic\nand games. Logic plays a role in cognitive psychology and experimental\ngame theory, if only to identify testable hypotheses related to Theory\nof Mind or strategic reasoning (Ghosh,\nMeijering, & Verbrugge 2014; Ghosh & Verbrugge 2018; Bicchieri\n1993; Fagin, Halpern et al. 1995). Lastly, some work at the\ninterface of logic and games suggests outreach to the world of actual\nparlor games (van Ditmarsch & Kooi 2015;\nvan Benthem & Liu 2019). \nAll in all, the claim of this entry is a modest one. Logic and games\nform a natural combination, that may reveal interesting things when\npursued explicitly. Even so, too much logic may import too much of a\nformal apparatus, which may end up strangling the games perspective:\nlogical systems are infinite machineries that can easily overwhelm a\nconcrete game of interest. In short, the contact has to be managed\nwith care.","contact.mail":"johan@science.uva.nl","contact.domain":"science.uva.nl"},{"date.published":"2019-03-04","url":"https://plato.stanford.edu/entries/logics-for-games/","author1":"Johan van Benthem","author1.info":"http://staff.science.uva.nl/~johan/","author2.info":"http://dominikklein.dk/","entry":"logics-for-games","body.text":"\n\n\nIn light of logic’s historical roots in dialogue and\nargumentation, games and logic are a natural fit. Argumentation is a\ngame-like activity that involves taking turns, saying the right things\nat the right time, and, in competitive settings, has clear pay-offs in\nterms of winning and losing. Pursuing this connection, specialized\nlogic games have already been used in the middle ages as a tool for\nlogic training (Hamblin 1970). The\nmodern area augmented this picture with formal dialogue games as\nfoundation for logic, relating winning strategies in argumentation to\ncogent proofs (Kamlah 1973 [1984]).\nToday, connections between logic and game theory span across a great\nnumber of different strands, involving the interface with game theory,\nbut also linguistics, computer science, and further fields.\n\n\nThemes from the extensive and growing area surrounding logic and games\noccur in various entries of this Encyclopedia, in particular on\n uses of games in logic,\n epistemic foundations of game theory,\n formal approaches to social procedures,\n logics for analyzing powers of agents, and\n game semantics for programming and process languages.\n These entries differ in their emphasis, which may be on logic, game\ntheory, or foundations of computer science. The present entry is\nconcerned with logics for analyzing games, broadly speaking. It makes\nreference to other perspectives in this Encyclopedia where\nrelevant.\n\nThe present entry provides a comprehensive survey of logics for\nanalyzing games, arranged under a number of unifying themes and\nperspectives. Also, occasional connections are made with other strands\nat the interface of logic and games covered elsewhere in this\nEncyclopedia. This overview section is a brief tour\nd’horizon for topics that will return in more detail later\non. \nSpecific games stand for significant recurrent patterns of social\ninteraction. In a perspective called ‘logic of games’,\nnotions and results from logic are used to analyze the structure of\nvarious games. In fact, much classic reasoning about games involves\nnotions that are familiar from logic. \nExample Game solution reasoning. \nConsider the following game tree for two players A, E,\nwith turns marked, and with pay-offs written with the value for\nA first. Alternatively, these values can be interpreted as\nencoding players’ qualitative (or ordinal) preferences between\noutcomes. \nFigure 1. \n ⓘ \nHere is how players might reason. At her turn, E faces a\nstandard decision problem, with two available actions and the outcome\nof action left better for her than that of right. So\nshe will choose left. Knowing this, A expects that his choosing\nright will give him outcome 0, while going left\ngives him outcome 1, so he chooses left. As a result, both players are\nworse off than they would have been, had they played\nright/right. The reasoning in this scenario, in\nshort, leads to an outcome that is not Pareto-optimal. \nThe example raises the question just why players should act this way,\nand whether, say, a more cooperative behavior could also be justified.\nAn answer obviously depends on the players’ information and\nstyle of reasoning. Here it becomes of interest to probe the structure\nof the example. Looking more closely, many notions are involved in the\nabove scenario: actions and their results, players knowledge about the\nstructure of the game, their preferences about its results, but also\nhow they believe the game will proceed. There are even counterfactual\nconditionals in the background, such as A’s explaining\nhis choice afterwards by saying that “if I had played\nright, E would have played left”.\nThese notions, moreover, are entangled in subtle ways. For instance,\nA does not choose left because it dominates\nright in the standard sense of always being better for him,\nbut rather because left dominates right according to\nhis beliefs. How these beliefs are formed, in turn, depends on many\nother features of the game, including the nature of the players. \nIn short, even a very simple game like the one discussed brings\ntogether large parts of the agenda of philosophical logic in one very\nconcrete setting. This entry will zoom in on the aspects mentioned\nhere, with\n Section 3\n dedicated to players’ preferences and beliefs, while\n Section 4\n addresses reasoning styles and the dynamics of attitudes as the game\nproceeds. \nThe analysis is structured by a few broad distinctions. Intuitively,\ngames involve several phases that involve logic in different ways:\ndeliberation prior to the game, as many game-theoretic solution\nconcepts are in fact deliberation procedures that create initial\nexpectations about how a game will go on. Observation and belief\nrevision during game play, including reactions to deviations from\nprior expectations. And finally, post-game analysis, say, to settle\nwhat can be learnt from a defeat, or to engage in spin about\none’s performance. Moreover all this can be considered in two\nmodes, assuming either a first-person participant or a third-person\nobserver view of games and play. \nIn many of the above topics, logics meets game theory. One such\ninterface area is\n epistemic game theory\n where game play and solution concepts are analyzed and justified in\nlight of various assumptions about players and their epistemic states,\nsuch as common knowledge or common belief in rationality. Epistemic\ngame theory may be viewed as a joint offspring of logic and game\ntheory, a form of progeny which constitutes a reliable sign of success\nof an interdisciplinary contact. \nThere are also other viable logical perspectives. In particular, one\ncan look at game theory the way mathematical logicians look at any\nbranch of mathematics. Following the style of the famous Erlangen\nProgram, one can discuss the structures studied in that field and look\nfor structural invariance relations and matching logical languages.\nGame theory is rich in structure, as it has several different natural\nnotions of invariance. The tree format of extensive games offers a\ndetailed view of what happens step by step as players make their\nmoves, whereas the matrix format of strategic form games offers a\nhigh-level view that centers on outcomes. Yet other formats, to be\ndiscussed below, focus on players’ control over the various\noutcomes. All these different levels of game structure come with their\nown logical systems, as will be detailed in\n Section 2.\n Moreover, these different logics do not just provide isolated\nsnapshots: they can be related in a systematic manner. \nIn this way, the usual logical techniques can be brought to bear. For\ninstance, formal languages can express basic properties of games,\nwhile model-checking techniques can determine efficiently whether\nthese hold in given concrete games (cf. Clarke,\nGrumberg, & Peled 1999). \nExample Winning strategies. \nConsider the following game tree, with move relations for both\nplayers, and propositional letters \\(\\win_{i}\\) marking winning\npositions for player i. \nFigure 2.\n ⓘ \nClearly, player E has a winning strategy against player\nA, i.e., a recipe that guarantees her to win, no matter what\nA does. This is expressed by a modal formula capturing exactly\nthe right dynamics: \nHere \\([\\move_A]\\) is the universal modality “for all moves by\nplayer A\", and \\(\\langle \\move_E\\rangle\\) is the existential\nmodality “for some move by player E\". This two-step\nmodality- or quantifier-based response pattern is typical for\nstrategic powers of players in arbitrary games, as it captures the\nessence of sequential interaction. Crucially, logical laws can acquire\ngame-theoretic import. For instance, the law of Excluded Middle\napplied to the above formula yields: \nor in a logically equivalent formulation: \nIn two-step games like the above, where exactly one player wins (i.e.,\n\\(\\win_A\\leftrightarrow\\neg\\win_E\\)), the latter formula expresses\nthat either player E or player A has a winning strategy.\nMore generally, this disjunctive assertion is a special case of\nZermelo’s theorem, stating that every finite full information\ngame is determined. \nHaving established the connection to logical languages, further\nmodel-theoretic themes can be applied fruitfully to games. Language\nbased reasoning allows, for instance, to examine the preservation of\nproperties between different games, based on the exact syntactic shape\nof their definition. Besides, logical syntax also supports logical\nproof theory. Hence, the latter’s rich pool of proof calculi may\nhelp to analyze basic results in game theory. This entry illustrates\nmajor recurring patterns of reasoning about interaction that come to\nlight in this way. \nGame theory also has a further natural level of representation,\nsuppressing details of local moves and choices. The most familiar\nformat for this are games in strategic form. In the simplest\ncase of only two players, these correspond to a two-dimensional\nmatrix, with rows standing for some player’s strategies, and\ncolumns for the other’s. Individual cells of such matrix hence\ncorrespond to the different possible strategy profiles of the\ngame. Typically, all cells are labeled with information about the\noutcomes resulting from playing the corresponding strategies\nagainst one another. This labeling specifies players’ attitudes\nto outcome in terms of pay-offs, more abstract utilities, or ordinal \nmarkers for players’ preferences orders among outcomes. \nStrategic form games, too, can model significant social scenarios.\nHere is an illustration from the philosophical literature on the\nevolution of social behavior. \nExample The following game in matrix\nform is the Stag Hunt of Skyrms\n(2003), going back to ideas of David Hume. It serves as a\nmetaphor for the social contract. \nEach agent must decide between pursuing their own little project,\nhunting a hare, or joining in a larger collective endeavor, hunting\nstag. The former gives a moderate but guaranteed income, no matter\nwhat others do. The collective endeavor, on the other hand, can only\nsucceed if all contribute, in which case everybody receives a high\nprofit. If, however, some do not join, all contributions are lost and\nno contributor receives anything. In the corresponding strategic form\ngame, all players have to decide on what to do in parallel, without\nknowing the actions of others. \nThe Stag Hunt game has two pure strategy Nash equilibria: every\ncontributes, and nobody contributes. Which of these\nstable outcomes ensues will crucially depend on the players’\nreasoning, their expectations about each other, and perhaps even\nfurther information stemming, for instance, from pre-game\ncommunication. \nClearly, analyzing strategic games involves agentive information,\nreasoning and expectations. All these aspects have tight connections\nto logic. Viewing outcomes as possible worlds, three relevant\nrelations emerge between these. Within the matrix above, relating all\ncells in the same row fixes a unique choice already made by the row\nplayer A, while leaving E’s move completely open.\nIn short, each horizontal row lists all possible choices of the column\nplayer E which A has to take into account. The\ncorresponding modality may hence be said to describe A’s\nknowledge about the outcomes of the game given his choice. Still\nassuming the row player’s perspective, relating cells vertically\nrather than horizontally corresponds to A’s freedom of\nchoice among his available strategies. Of course, one could also\nassume player E’s perspective instead, viewing the\nhorizontal direction as E’s freedom of movement, while\nthe vertical directions captures her epistemic uncertainty. \nThus, a bimodal logic arises for matrix games with laws such as \ncapturing the grid structure of matrix games. For more than two\nplayers, this logic gains some additional options and subtleties to be\ndiscussed in\n Section 2.6. \nThe crucial third relation is that of player’s preferences among\noutcomes. These, again, have matching modalities, now taken from\npreference logic (Hansson 2001). With\nthe help of some auxiliary devices, the three modalities can define\nthe central game-theoretic notion of a Nash equilibrium (Harrenstein\n2004; van der Hoek & Pauly\n2007). \nLogics for matrix games differ from those for extensive games, as\ngrids behave quite differently from trees in terms of complexity. Yet,\nboth fall under the same general methodology. Towards a common\nunderstanding, one might view the logic of matrix games as capturing\nthe basic laws of parallel, rather than sequential action. \nPhilosophical logic and mathematical logic are not the only\nilluminating perspectives on games. A third relevant viewpoint is that\nof computational logic. In modern computation, the paradigm is no\nlonger single Turing machines but interacting systems of multiple\nprocessors. These processors may cooperate, but they might also\ncompete for resources. In general, hence, it is useful to study\nmultiple agents engaging in computation, be it within human,\nartificial or mixed societies. Though doing so, games become a natural\nmodel for computation, too. In fact, games are rich multi-agent\nsystems where agents process information, communicate, and engage in\nactions, all driven by their respective preferences and goals. In the\nconverse direction, computer science themes such as complexity and\nalgorithmics have entered game theory, resulting in the area of \ncomputational game theory (Nisan et al.\n2007). For a richer survey of computational logics of agency\nand games, see van der Hoek and Pauly\n(2007) and Shoham and Leyton-Brown\n(2008). The present entry contains occasional links to\ncomputation. These are especially prominent for reasoning about\ntemporally extended games and their strategies (Sections\n 4.2,\n 4.4) and in the context of gamification\n (Section 6),\n where games are explored as a novel semantics for classical logical\nsystems. \nFinally, recall the start of this section, but with reverse\nperspective: instead of asking what logic can do for games, ask what\ngames can do for logic. Argumentation and dialogue are basic notions\nfor logic. Both can be studied using techniques and results from game\ntheory (Lorenzen & Lorenz 1978; Hamblin\n1970). In this perspective, logical validity of consequence\nrests on there being a winning strategy for a Proponent claiming the\nconclusion against an Opponent granting the premises in a game where\nmoves are regulated by the logical constants. Many games have found\nuses in modern logic since the 1950s, with\nEhrenfeucht-Fraïssé games for model comparison being a\nparadigmatic example. Besides these, also semantic verification or\nmodel construction can be cast as\n natural logic games. \nThis raises an intricate issue within in the philosophy of logic,\nconcerning the nature of logic and in particular that of logical\nconstants. A ‘weak thesis’ would hold that games\nconstitute a natural technique for analyzing logical notions, as well\nas a didactic tool for teaching logic that appeals directly to vivid\nintuitions. Parts of the literature, however, also defend a\n‘strong thesis’, suggesting that the primary semantics of\ncertain logical systems may be procedural and game-theoretic, rather\nthan denotational in a standard sense. This perspective, sometimes\ncalled ‘logic as games’, occurs in some attractive\nsemantics for first-order languages (Hintikka\n& Sandu 1997), as well as in\n game semantics for programming languages. \nThe theme of logic as games will appear only briefly in the present\nentry, which is mainly directed toward logics of games.\n Section 6\n will discuss which questions arise from joining both perspectives on\nthe interface of logic and games. \nAs it happens, the logic-as-games perspective is of broader relevance.\nLogic games were originally designed for particular tasks inside\nlogic. Yet, taken to reality, they can help analyze or streamline\nactual lines of argumentation. As such they may be compared to\ndesigned parlor games that challenge reasoning skills. A game like\nClue involves an intriguing mix of logical deduction, new\ninformation from drawing cards or public observation of moves, but\nalso private communication acts by players (van\nDitmarsch 2000). Other parlor games, such as Nine Men\nMorris (Gasser 1996) are graph\ngames (Grädel, Thomas, & Wilke\n2002) with added chance moves that serve to diminish the risk\nof finding a repeatable simple strategy on the fixed board. The\nlogical study of playable designed games for bounded agents, and the\ndesign of new such games, is a natural sequel to this entry (cf.\nvan Benthem & Liu 2019). \nGame theory may be understood as generalized interactive decision\ntheory. A major vehicle for the latter, just as for standard decision\ntheory, is probability theory. Within games, probability can assume\nmany roles. It may, for instance, express players’ degrees of\nbelief quantitatively, but it can also enrich the space of actions\nwith mixed strategies, thereby laying the ground for general\nequilibrium results. Probability can even play a role in the very\ndefinition of certain important games, especially in evolutionary game\ntheory (Osborne & Rubinstein 1994).\nIn this entry, probability is only mentioned in passing.\n Section 5,\n however, maps some combinations of logic and probability that are\nsuggested by the study of games. \nGames have a natural interface with logic in all its varieties,\nincluding mathematical, philosophical, and computational logic. In one\ndirection of contact, logic can provide new abstract notions\nunderneath game theory. Conversely, game-theoretic notions can also\nserve to enrich logical analysis. The present entry mainly\nconcentrates on the first of these directions, the use of logic for\nanalyzing games. It does so mostly from a semantic perspective, the\ndominant paradigm so far in the area. Though proof-theoretic\napproaches will be mentioned occasionally. The sections to follow\nelaborate on this theme along several dimensions. Specific\nperspectives include logics for game structures\n (Section 2),\n logical analysis of the nature of players\n (Section 3)\n and of the process of game play\n (Section 4).\n Additional spotlights are put on the relationship between logic and\nprobability in the context of games\n (Section 5)\n and the endeavor of Gamification\n (Section 6).\n Each section forms a free-standing exposition, which results in some\nunavoidable, and perhaps useful, overlap. Throughout the exposition,\nsome familiarity is assumed with the basic concepts of logic and game\ntheory. In particular, notions of game theory left unexplained here\ncan be found in the corresponding\n entry\n and in Leyton-Brown and Shoham\n(2008). \nThis first spotlight section focuses on game structures in a narrow\nsense. Game forms leave aside agents and notions typical for\nthese, such as preferences or information. Players, as well as the\ntemporal progression of play will be added in later sections. Even so,\nthere is already a good deal of structure in game forms to be studied by\nlogical techniques. \nThe starting point of any logical analysis is to fix its perspective\non games. This section will review several major candidates for doing\nso, starting with the two most prominent perspectives. The first of\nthese makes the temporal structure of a game explicit, representing it\nas a tree in the standard mathematical sense. \nExample A two-player extensive form\ngame. \nFigure 3.\n ⓘ \nA game in extensive form is a tree where each non-terminal\nnode or state specifies which player is to move next, while\nedges correspond to the players’ possible moves. The leaves of\nthe tree, finally, denote the possible outcomes O of game play.\nThere are many possible variations on these stipulations for states\nand moves, but they do not affect the essentials of a logical\nanalysis. \nThe second major perspective on games emphasizes the players’\navailable strategies. Suppressing all information about temporal\nstructure, a game in strategic form yields the matrix\npictures known from game theory. In its classic interpretation, a game\nin strategic form represents a set of players that each select a\ncomplete strategy for the entire game without knowledge of the other\nplayers’ choices. Each strategy profile, i.e., combination of\none strategy per player, then induces an outcome \\(O_i\\). The\nmotivation for this structure might seem complex on first sight. Yet,\nit can also be viewed as something quite simple: a one-step game with\nparallel rather than sequential moves, which is the simplest case of\nsimultaneous action. \nExample A two-player strategic form\ngame. \nExtensive and strategic forms differ in their focus. The former\nemphasize the sequential temporal structure of a game, while the\nlatter highlights strategy choice prior to play. One can freely switch\nbetween both when appropriate to the purpose at hand. Besides these\ntwo, there are other natural dimensions, highlighting players’\npowers for influencing outcomes (cf.\n Section 2.5)\n or players’ information about the game (cf.\n Section 3.6). \nRemark While all examples so far\nconcerned two-player games, no such restriction is needed. Both\nextensive games and strategic form games work for any number of\nplayers, although occasional subtleties may occur. A few will be\nmentioned below. Moreover, with more players, possible coalitions\nenter the picture, a topic that will not be treated in this entry.\nFinally, selected aspects of agency may sometimes enter through the\nback door. Many scenarios in real life contain external chance events\noutside of any player’s control, such as a roll of a die,\nweather conditions, or technical malfunctions. Such factors can\nusually be incorporated into a logical analysis by admitting Nature as\nadditional player. \nWith different ways of representing a game at hand, there is a natural\nfollow up question concerning equivalence. Given two game structures,\nwhen are they representations of the same underlying game? The answer\nis that it very much depends on what aspects one is interested in. \nExample The same game, or not? \nFigure 4.\n ⓘ \nConsider the two game forms above. If one cares about exact sequences\nof moves or the choices players have along the way, these games are\ndifferent. The game to the left has A move first, while\nE begins in the game on the right. In the game on the right,\nA may face a choice between p and q. This cannot\nhappen on the left. \nCaring about exact moves as done here constitutes a fine-grained\nperspective on games. There are others. When focusing on\nplayers’ powers for bringing about certain outcomes, for\ninstance, the analysis changes. In the game on the left, A has\na strategy (playing left) that ensures the game to end up in\nan outcome satisfying p, and one (playing right) that\nrestricts possible outcomes to those satisfying \\(q \\lor r\\). With\nthis second strategy, the further choice which of \\(q or r\\) gets\nrealized is left up to player E. Also the second player,\nE, has two strategies in the game on the left, one (playing\nleft) ensuring the outcome to satisfy \\(p\\lor q\\), the other\n(playing right) guaranteeing that the outcome satisfies \\(p\n\\lor r\\). \nPerforming the same calculations for the game on the right, virtually\nthe same player powers emerge. More precisely, A’s\nuniform strategies left-left and right-right yield\np and \\(q\\lor r\\) respectively, exactly the same powers as in\nthe left game. The two remaining strategies left-right and\nright-left yield \\(p\\lor q\\) and \\(p\\lor r\\), both of which\nare mere weakenings of A’s power to achieve p.\nThus, at the level of players’ powers, the above two game forms\nshould be considered the same. \nAs this example illustrates, there are several legitimate ways of\ncomparing games. When taking a fine-grained focus on the internal\nstructure of a game, a natural candidate is the notion of a\nbisimulation (cf. Blackburn, de Rijke,\n& Venema 2001). A bisimulation \\(Z\\subseteq G_1\\times G_2\\)\nrelates states of two game forms \\(G_1\\) and \\(G_2\\) subject to four\nconditions: States m and n may only be related when\n(i) the same player is to move in m and n,\n(ii) m and n do not differ in any of their\nbasic local properties, while (iiia) whenever there is an\navailable move of type a in \\(G_1\\) leading to a state \\(m'\\),\nthere is a matching available move of type a in \\(G_2\\) leading\nto a state \\(n'\\) with \\(m'Zn'\\), and vice versa (iiib)\nwhenever there is a move in \\(G_2\\) that leads to a state \\(n'\\),\nthere there is a move of the same type in \\(G_1\\) leading to a state\n\\(m'\\) with \\(m'Zn'\\). \nExample A bisimulation between\ngames. \nFigure 5.\n ⓘ \nThis particular notion of bisimulation is not the only invariance that\nmakes sense for games. A more coarse-grained perspective, for\ninstance, might not distinguish moves by their particular action\ntypes, but merely by which player is to perform them. A corresponding\nbisimulation can be defined by omitting references to particular\naction types in conditions (iiia) and (iiib)\nabove. \nFurther notions of bisimulation take an even coarser perspective on\nthe games’ move structure, for instance by allowing to contract\nzones where the same player moves several times in a row. Finally,\ndropping all information about players and their choices, games can be\ncompared by the sequences of moves they admit. This purely\nobservational notion, known as trace equivalence in\ncomputation, may, however, be less relevant in the context of games.\nAn alternative approach to coarsening focuses on the players’\npowers to control outcomes, cf.\n Section 2.5 and van Benthem, Bezhanishvili and Enqvist (forthcoming-a). \nWhile most notions of invariance discussed so far related to extensive\nform games, a similar style of analysis applies to games in strategic\nform. Van Benthem, Pacuit, and Roy\n(2011) define modal bisimulations that connect outcome states\nof different matrices, and apply bisimulation’s back-and-forth\nconditions to the relevant relations of players’ choice,\nfreedom, and preference. \nThis may be a good point to stress once more that the present section\nis concerned with game forms only, omitting any player related aspect\nsuch as preferences between outcomes. When these are added,\nidentifying appropriate notions of invariance becomes more\nchallenging, as will be discussed in\n Section 3\n below. \nThe choice of invariance relations mirrors which structure is deemed\nrelevant within a given perspective on games. A central tool for\nbringing out such relevant aspects is the existence of a logical\nlanguage matching some invariance relation. In general, the more\nfine-grained the invariance perspective, the more distinctions a\nmatching language should be able to make. \nFor a start, if one is interested in the properties a player can bring\nabout through moves, a good choice of language is based on modalities\n\\(\\langle \\move_i\\rangle \\varphi\\), expressing that at least one of\ni’s available moves leads to a next stage satisfying\n\\(\\varphi\\). The following illustrates how this language works in a\ngiven extensive form game. \nExample Modal game language. \nFigure 6.\n ⓘ \nThe modal formula \\([\\move_A]\\langle \\move_E\\rangle \\win_E\\), true at\nroot r, expresses that E has a strategy that ensures her\na win in two steps: whatever A does, E can react in such\na way that she ends up in a node where she wins. In a more\nfine-grained perspective, the modal language could add expressions\n\\([a],[b]\\ldots\\) for specific move types \\(a,b,\\ldots\\). In this\nlanguage, the coarse-grained modality \\(\\langle \\move_i\\rangle\n\\varphi\\) is definable by the disjunction \\(\\bigvee_{a\\text{ is a move\nfor }i}\\langle a \\rangle\\varphi\\), making the new language a\nrefinement of the old. \nIn this way, general results of modal logic apply to games. For\ninstance, take pointed models such as game trees with an indicator for\nthe current moment. Whenever two such pointed models \\(\\G,m\\) and\n\\(\\G',m'\\) are bisimilar in the first sense defined above, the\nequivalence \\(\\G, m\\vDash\\varphi\\) iff \\(\\G', m'\\vDash\\varphi\\) holds\nfor all formulas \\(\\varphi\\) in a sufficiently rich modal language\nwith modalities \\([a]\\) for each move label. Thus, one can switch\nbetween syntactic, language based perspectives and semantic invariance\nrelations, depending on what is convenient for a given perspective on\ngames. Entirely similar points hold for bisimulations and modal\nlanguages for power perspectives, or for strategic form games. \nFinally, modal languages do not have exclusive rights. If still more\nfine-grained perspectives are needed, more expressive first-order or\nhigher-order languages become serious contenders for describing\ngames. \nA language for games facilitates both, defining properties of games\nand reasoning about them. An example are winning strategies for\nplayers in a two-step extensive game as just discussed. More\ngenerally, for any finite extensive game, there are formulas\n\\(\\varphi_j\\) for each agent j that are true iff j has a\nwinning strategy: \nwhere the number of operators in the formula corresponds to the depth\nof the tree. \nThus, logical laws governing reasoning with such formulas acquire\ngame-theoretic content. For instance, the negation of the statement\nthat one player, A, has a winning strategy is provably\nequivalent to saying that the other player, E, has a winning\nstrategy, at least in those cases where A wins if and only if\nE does not:  \nHence, the logical law of excluded middle in its modal guise\ncorresponds to Zermelo’s theorem, stating determinacy for finite\ngames. \nYet, there are limitations to such characterizations of game-theoretic\nproperties in terms of logical laws. Formulas stating whether some\nplayer has a winning strategy change from model to model, as the\nnumber of modal operators depends on the size of the game tree. In\nfact, there is no uniform formula in the basic modal language\nexpressing that player i can win in an arbitrary finite\nextensive form game. Such a formula can only be found in the modal\nμ-calculus (Venema 2008), where the\nstatement that i has winning strategy can be expressed with the\nfixed-point formula  \nThe more general point here is that the recursive nature of\ngame-theoretic equilibria and solution concepts reflects naturally in\nlogics with fixed-point operators for induction and recursion. \nIn this setting, known results about modal logic acquire a new\nsignificance. In the realm of finite models, for instance, having the\nsame modal formulas true at two states is equivalent to there\nbeing a bisimulation connecting those two states (cf.\nBlackburn, de Rijke, & Venema 2001).\nHence, whenever two finite games satisfy the same modal propositions\nin their respective roots they are equivalent in the sense of\nbisimulation. For infinite models, such results are less direct. A\nfull equivalence between bisimulation and satisfying the same\nformulas, for instance, only holds for an extended modal language with\ninfinite conjunctions and disjunctions. Other relevant results include\nthe existence of modal formulas that define given pointed models up to\nbisimulation. Such formulas sometimes exist in the basic modal\nlanguage, sometimes in the μ-calculus, and always in the infinitary\nmodal language. Applied to concrete games G, these modal\ndefinitions can be viewed as complete descriptions of all properties\nof G at the relevant level of invariance. \nFinally, modal logic has many complete proof systems for capturing the\nvalid consequences on various classes of models (Blackburn,\nde Rijke, & Venema 2001).\nThese calculi of reasoning also apply to games, where they can capture\naspects of specialized game-theoretic argumentation. Proof-theoretic\nperspectives are not the focus of this entry, but a number of strands\nwill be mentioned where appropriate. \nBesides extensive form games, standard modal logic is also suitable\nfor the power perspective on game structure. Sometimes, one ignores\nthe internal mechanisms of a game altogether, merely viewing it as a\nblack box social mechanisms where players control outcomes to a\ncertain extent. In this perspective, a player can force the\noutcome of the game to be in some set X if she commands a\nstrategy that ensures the game to end up in an outcome of X, no\nmatter what the other players do (van\nder Hoek & Pauly 2007). Similarly, a player can force that\nsome proposition \\(\\varphi\\) holds if she has the power to enforce\nthat the game ends in a \\(\\varphi\\) state. The collection of all sets\nof outcomes an agent can force are often called her forcing\npowers. In classical game theory, these forcing powers sometimes\ngo by the name of effectivity functions (Peleg\n1997), which are often also studied for\ncoalitions of players (see Pauly 2001; Goranko,\nJamroga, & Turrini 2013; and the entry on\n logics for analyzing power in normal form games). \nExample Powers in extensive games. \nFigure 7.\n ⓘ \nNotably, forcing powers are not closed under conjunction. In the game\nabove, agent A can force p and q individually\nwithout being able to force \\(p \\land q\\). In modal logic terms,\nforcing powers give rise to a neighborhood logic (Pacuit\n2017), where the neighborhood\nfunctions list the set of outcomes players can enforce from a given\nstate. Reasoning about forcing powers can then employ a logical\nlanguage with forcing modalities \\(\\{i\\}\\) for each player: \n\\(\\{i\\}\\varphi\\): agent i can force the outcome of the game to\nsatisfy \\(\\varphi\\).  \nThese modalities can be interpreted over the extended game forms with\nneighborhood functions described above. On the semantic side, a\ngeneralization of the above neighborhood models support a\ngeneralized notion of power bisimulation, see van\nBenthem, Pacuit, and Roy (2011). \nThe modal logic of powers allows to reason about games at a global\nlevel of description. The modal logic of neighborhood models validates\nthe standard modal monotonicity principle as follows\nalready from the truth definition of forcing modalities. However, as\nforcing powers are not closed under intersection, the aggregation law\nfails: \nInstead, the logic contains new valid principles relating forcing\nmodalities for different players. For instance, if i can force\nthe truth of \\(\\varphi\\), then no other player j can force its\nfalsity. Thus, \nis a valid principle of ‘consistency of powers’ in the\nlogic of forcing powers. The converse of this principle for games with\ntwo players \\(i, j\\) \nexpresses the notion of determinacy from the last section. This\nformula is not generally valid, but is an axiom for the special\nclass of determined games. \nFinally, there also is an alternative, more algebraic perspective on\npowers, assuming an earlier-mentioned perspective of logic games. The\ntwo games depicted in the core example of\n Section 2.2\n may be seen as evaluation games for propositional formulas \nTheir equivalence qua powers, described earlier, then matches\nthe standard propositional law of distribution. This algebraic\nperspective will return in\n Section 2.9. \nMore recent views of forcing and powers re-interpret the sets X\nof outcomes employed in the above definitions as referring to both\nplayers: one player restricts the total set of outcomes, while the\nother players can achieve all outcomes within that set. This variation\nsignificantly impacts the corresponding notions of game equivalence,\nas well as the modal languages used (van\nBenthem, Bezhanishvili, & Enqvist forthcomingb). \nIn the strategic perspective on games, players select actions\nsimultaneously, without having learned about their opponents’\nchoices of actions. This requires an additional level of analysis.\nBesides the various possible moves, an adequate representation must\nalso track players’ uncertainty about how their opponents might\nact. \nIn terms of matching logical languages, this suggest a\nmulti-modal approach, with \\([\\approx_i]\\) ranging over\ni’s possible choices, and \\([\\equiv_i]\\) representing her\nuncertainty about the opponents, see van\nBenthem, Pacuit, and Roy (2011). Moreover, when considering\ngames rather than game forms, this picture needs to be enriched with a\nthird feature, viz. preference modalities \\([\\preceq_i]\\), see\n Section 3. \nGames in strategic form can be viewed naturally as models for a modal\nlanguage of choice and uncertainty, where each state m\nconsists of a strategy profiles, i.e., a sequence \\((m_1,m_2\\ldots)\\)\nlisting each player’s choice of action. For convenience, the\npreference modality has been included: \nThis multi-modal language can express a variety of statements about\nstrategic form games, such as: \nIn the case of two players, one agent’s choices corresponds to\nthe other’s uncertainty and vice versa. This shows in the\nvalidity of principles such as  \nMore generally, the logic of matrix games includes the \\(\\mathsf{S}5\\)\naxioms for both \\([\\approx_i]\\) and \\([\\equiv_i]\\), but also the\ncommutation law \nexpressing the grid-like structure of matrix games. This logic bears\nsome resemblance to STIT-type logics of actions (Herzig\n& Lorini 2010). Technically, a\ngrid structure in models allows for encoding of undecidable\ncomputational problems (Blackburn, de\nRijke, & Venema 2001), rendering it an open problem\nwhether expressive modal logics of game matrices are decidable. \nThe step from two to more players, often routine in epistemic logics,\ncan be delicate in the logic of matrix games. Accessibility relations\nof type \\([\\approx_i]\\), interpreted as identity of profiles except\nfor the \\(i^{}\\)-coordinate, yield a product logic akin to the\nthree-variable fragment of first-order logic which is known to be\nundecidable (Bezhanishvili 2006).\nHowever, with only relations of identity at the i-coordinate,\ni.e., \\([\\equiv_i]\\), the logic remains decidable (Venema\n1998; Van De Putte, Tamminga, & Duijf\n2017; Lomuscio, van der Meyden, & Ryan 2000). \nThere is further structure in extensive games than just single moves.\nIn game trees, a player’s strategy specifies what to do\nat each turn, whether this turn will ever be reached or not. An\nincreasing body of work examines such strategies and their underlying\nformats, see van Benthem, Ghosh, and Verbrugge\n(2015) for an overview of various logical frameworks for\nreasoning about strategies. \nIn one concrete perspective, a strategy is akin to a program that\ninstructs the agent on how to navigate a game tree. Hence, a natural\nlogic of strategies uses the language of\n propositional dynamic logic of programs\n PDL, an approach that will return later. As programs are in general\nnon-deterministic, such logics let a strategy recommend one or more\nactions the agent should take at each turn. In this perspective,\nstrategies resemble plans that might remain partial. \nIn a program format, strategies start with basic actions, representing\nindividual moves in a game tree. From there, complex programs \\(\\pi\\)\ncan be created using operations including sequential compositions\n\\(\\pi_{1} \\,;\\pi_{2}\\) (\\(\\pi_{1}\\) is to be performed followed by\n\\(\\pi_{2}\\)), or choice \\(\\pi_{1}\\, \\cup_{i} \\pi_{2}\\) (agent i\nis to pick between actions \\(\\pi_{1}\\) and \\(\\pi_{2}\\) ). Moreover, a\ntest operation \\(?\\varphi\\) for checking whether \\(\\varphi\\) holds,\nenables strategies to react to properties of states or\nopponents’ past actions. Finally, to describe continuous\nexecution of a strategy along a game tree, it makes sense to have an\noperation \\(\\pi^{*}\\) of program iteration, stating that \\(\\pi\\) be\nexecuted arbitrarily often. \nThe language of PDL then has modal operators \\([\\pi]\\) for every\nprogram \\(\\pi\\) that can be defined from the basic actions and the\noperations just described. A simple such strategy advises player\ni to do a whenever it is her turn. The following formula\nstates that this strategy ensures that \\(\\varphi\\) holds\nthroughout: \nProgram definitions for strategies given here are closely related to\nthe use of finite automata for defining strategies in computer science\nand game theory (Osborne & Rubinstein 1994;\nGrädel, Thomas, & Wilke 2002; Ramanujam & Simon\n2008). \nIn the extensive form games of\n Section 2.1,\n players move in sequence and can base their decisions on full\ninformation of what has happened so far. The other extreme were games\nin strategic form, where agents move in parallel or, in the\ninterpretation of strategy selection, have no means of picking up\ninformation during actual play. There are ample scenarios in between\nthese extremes. Public good games with optional retribution against\nnon-cooperators (Andrighetto et al.\n2013), for instance, combine moments where some or all players\nmake simultaneous moves with information collection along the way.\nSuch parallel action can be mimicked in sequential games by limiting\nthe information available to players at various states of the game.\nThe resulting games of imperfect information will be discussed in\n Section 3,\n alongside other sources of imperfect information. \nFurther well-known logical approaches to parallel action employ STIT\nlogic (Horty & Belnap 1995; Broersen\n2009), and temporal logics such as ATL (Alur,\nHenzinger, & Kupferman 2002) or its\nepistemic variant ATEL (van der Hoek &\nWooldridge 2003). \nSo far, games were treated as monolithic entities that agents reason\nabout in their entirety. This can be at odds with how real life agents\nconceptualize games. To facilitate reasoning, games are often broken\nup into smaller tasks that are easier to handle separately. A chess\nplayer, for instance, may know how to solve different end games.\nRather than reasoning about every possible situation until its end,\nshe will evaluate different options in mid-play by considering which\nof these end games they will, most likely, lead up to. In this\nperspective, complex games are constructed out of simpler games that\nmay profit from separate analysis. Games then form an algebra with\noperations that construct complex games from simpler ones. This style\nof thinking is reinforced when games are viewed as scenarios for\ninteractive computation, where again algebraic methods are used\nwidely (Bergstra, Ponse, & Smolka\n2001). \nHere is an illustration of this approach. For simplicity, consider\nonly two players, A and E, the latter of which starts\nthe game. One influential game algebra has the following operations,\ncf. Parikh (1985). \nFor instance, take a chess player in mid-game reasoning. For\nsimplicity, restrict the possible end games to \\(G_{F_1}\\) and\n\\(G_{F_2}\\). The player can then conceptualize mid-play as a game\n\\(G_{mid}\\) with end nodes labeled by propositions \\(p_1\\) or \\(p_2\\),\ndescribing which of the two end games follows. The full remaining\nchess tree is then given by \nEquational axiomatizations for this game algebra can be found in Goranko\n(2003) and Venema\n(2003). However, following the analogy\nof propositional dynamic logic for an algebra of programs, there also\nis a dynamic game logic for this algebra of games, (Parikh\n1985). It adds a modality\n\\(\\{G\\}\\varphi\\) for each game G, with \\(\\{G\\}\\varphi\\)\nexpressing that in game G, the first player E has a\nstrategy to force the truth of \\(\\varphi\\). For the case of\nnon-determined games, the language will be extended further to include\nseparate modalities \\(\\{G, i\\}\\varphi\\), one for each player i.\nDynamic game logic shows in a perspicuous manner how strategic\nabilities for complex games supervene on abilities in simpler games.\nThis is done by means of reduction laws such as \nFor a complete list of reduction laws, as well as open problems in\nthis dynamic game logic see Pauly (2001), van Benthem\n(2014). For other styles of game algebra, including also forms\nof parallel composition, cf. Abramsky\n(1997). \nIt should be said that imperfect information challenges this approach\nto game algebra. For instance, one may have to decompose a larger game\ninto smaller subgames where agents need not know which of these\nsubgames they are in. Game algebras with imperfect information have\nbeen studied in the context of Boolean Games (Harrenstein\net al. 2001). A recent\npower-based game algebra with operations encoding imperfect\ninformation, showing some analogies with IF logic (Mann,\nSandu, & Sevenster 2011) can be\nfound in van Benthem, Bezhanishvili, and\nEnqvist (forthcomingb). \nCoalitions and Networks Nothing has been\nsaid so far about social or structural relations between players: they\nmove individually and in interaction with all other players. However,\nin many games, groups of players can team up to jointly pursue goals,\npossibly in competition with other groups. Coalitions are a natural,\nbut non-trivial extension of the logical frameworks introduced here,\nas strategic abilities of groups may exceed those of all members\ncombined, see Peleg (1997), Van de Putte & Klein (2018), and the entry\non\n coalition powers in games.\n In other studies of social phenomena, the set of players is equipped\nwith an additional network structure. An agents’ outcome or\nbehavior will then depend upon what network neighbors do (Baltag\net al. forthcoming; Christoff 2016).\nLastly, games on networks are closely related to information flows in\nsocial networks, as studied in depth by Liu,\nSeligman, and Girard (2014) and Seligman\nand Thompson (2015) from a logical perspective. \nTracking This section contains a wide\nvariety of perspectives on games. These differ in their invariance\nrelations and their matching languages, offering different foci such\nas outcomes, powers, or the detailed temporal evolution of games. Even\nfurther perspectives will no doubt keep emerging. This diversity may\nseem overwhelming, making the field rather scattered. But here,\nanother role of logic shows, by not just proliferating systems, but\nalso as connecting them. Various logical translations exist between\nthe languages and levels involved. Often, reasoning about games in a\nlogic for some level can be mirrored precisely under translation into\nthe logic of another level. Moreover, these translations can often\nkeep track of changes in games under actions of information updates, a\ntopic to be taken up in Section 3. Tracking of this kind is defined\nand studied in general logical terms in van\nBenthem (2016) and Cinà\n(2017). \nInfinite games So far, games were\ntacitly assumed finite in length. This assumption is innocuous for\nmany real life scenarios, yet there are notable exceptions. A\nprominent example are safety games, where one of the players, the\nguard, has to ensure a system to never leave a certain state, while\nthe opponent attempts to deviate. Many technical tools for finite\ngames also work for infinite games. There is, however, a number of\nconceptual and logical discontinuities. Since infinite games have no\nlast moments, for instance, outcomes must be attached to complete\nhistories of game play, rather than leaves of a tree. Reasoning about\ngames then requires temporal modalities for a given history, but also\nmodalities ranging over all open future histories. For analyzing\npowers, then, temporal versions of forcing modalities are needed. With\nthese modifications, a logical style of analysis still applies. For\ninstance, it is well-known that determinacy fails for infinite games\n(Jech 2003). However, what holds for all\ngames is a law of ‘weak determinacy’ stating that, if\ni has no strategy to force a set of histories satisfying\n\\(\\varphi\\), her opponent j can ensure that i will never\nobtain such a \\(\\varphi\\)-strategy in the future. The difference\nbetween standard determinacy and weak determinacy is captured by the\nfollowing two formulas, that are entirely in line with this\nsection’s style of analysis:\n\\(\\{i\\}\\varphi\\,\\lor\\,\\{j\\}\\neg\\varphi\\) (determinacy) versus\n\\(\\{i\\}\\varphi\\lor\\{j\\}G\\neg\\{i\\}\\varphi\\) (weak determinacy), where\nG is the temporal modality of ‘always in the future on\nthe current history’. \nGame forms may be seen as spaces where players can operate. A game,\nhowever, is not fully determined by its game form alone. Rather, the\nplayers involved may import additional features relevant for game\nplay. Players can, for instance, be limited in their powers of\nobservation, either by aspects of the game structure or through\ncognitive limitations. The most striking added feature, however, is\nthat players have preferences. Agents not only observe the world or\nact in it. While these describe mere kinematics of a game, agents also\nevaluate current state and various possible futures. Being driven by\npreferences, it is such evaluations that are the moving force behind\nplayer’s choices. Preference, hence, take a prominent\nexplanatory role for true game dynamics. \nThis section places its focus on the preferential and epistemic\ndimensions of players. Such factors are essential to notions of\nrationality where information, action, and preference are often\nentangled. In game theory, a harmony between these is often sought in\nnotions of equilibrium for strategy profiles. \nGame trees and game matrices specify the moves available to players at\ndifferent moments in time. They also indicate all possible outcomes,\neither as cells in a matrix, or as leaf nodes in an extensive game.\nHowever, to study what players should or will do in\na game, a further component is needed: players’ preferences.\nSuch preferences need not only reflect material pay-offs or other\nfeatures of outcome states. Rather, they may also relate to the\nprocess of play itself, and which moves lead to a certain outcome. Moreover, preferences may contain irreducibly\nsubjective elements. Even when assuming the same role in a game,\ndifferent players may disagree about the relative desirability of\ncertain outcomes (Fehr & Schmidt\n1999). \nWithin a static, outcome-oriented perspective on games, a major\nemphasis is on equilibria: strategy combinations where all players do\nthe best they can in light of their preferences and the\nopponents’ strategies. A further, dynamic perspective focuses on\nhow such equilibria relate to the individual players’ stepwise local\nreasoning on how to act in light of their beliefs and desires. This\nperspective is taken up in\n Section 4. \nFor reasoning about preferences, it must first be specified what it is\nthat agents’ preferences apply to. The orthodox account lets\npreferences exclusively range over possible outcomes (Osborne\n& Rubinstein 1994). However, a\ngrowing trend in the logical literature assumes agents to rather care\nabout the truth value of general propositions than can describe both\nthe progression or outcome of a game. While not equivalent, the two\nperspectives are compatible. Both will be discussed in this\nsection. \nIn the classical picture, player i’s preferences on a\ngame tree are represented by a preference relation \\(\\prec_i\\) ranging\nover the set of outcomes. Such a relation is usually assumed\ntransitive and reflexive, but need not be total. \nExample A game tree with\npreferences. \nFigure 8. \n ⓘ \nJust as with the earlier modal logics for game forms, a relatively\nsimple logical formalism can already express relevant aspects of\nagency in games. It offers a low-complexity language for stating\nbasic features of action and information, without going into details\nof the underlying quantitative mechanisms. More precisely, games with\npreferences naturally support a logic with modal operators\n\\([\\preceq_i]\\) interpreted as: \nLogics of this type can express various properties relevant to games.\nThey can, for instance, say that all states better than the current\none are \\(\\varphi\\) states, making moving towards \\(\\varphi\\) states a\nnecessary condition for maximizing utility. They can also express,\nthat all best states are \\(\\varphi\\) states, with the formula  \nFor more on modal preference logics, see \nHansson (1990, 2001),Girard\n(2008) and van der Torre\n(1997). \nModal preference logic has further extensions with natural connections\nto games. In a refined perspective, for instance, preferences may\nderive from reasons, say, criteria or goals various agents want to\nachieve. This gives rise to a duality between preference relations\namong outcome states and priority orders over formulas, describing the\nagents’ goals. Dynamic accounts, finally, track how preference\ncan change under various input events. For more on both of these\nissues, see Liu (2011). \nHowever, modal preference logics, construed either way, are not yet\nrich enough to express one of the essential notions of game theory.\nFurther extensions are needed to deal with best responses,\nexpressing that the current move of a player is the best she can do in\nlight of her opponent’s actions. \nBest response moves are the main ingredient for game equilibria.\nFormally, a Nash equilibrium is a strategy profile, fixing a\nunique choice for each player, where nobody can improve by\nunilaterally changing strategy when all others maintain theirs. There\nare several ways of defining this property in extended modal\npreference languages. One possibility is to simply introduce a new\natom \\(b_i\\), stating that the current world is the best player\ni could have achieved in light of the opponents’ actions.\nIn this language, Nash equilibrium are characterized by  \nMore explicit definitions exist, building on the strict preference\nmodalities of van Benthem, Girard, and Roy\n(2009). Yet, perhaps the simplest illuminating approach uses an\nintersection modality from hybrid logic (Areces\nand ten Cate 2007) combining the\nagent’s preference relation with her uncertainty between the\nopponent’s action to characterize best responses and Nash\nequilibria (cf.\n Section 2.6): \nExpressing Nash equilibrium has served as a benchmark for logics of\nstrategic games (van der Hoek & Pauly\n2007). Yet there are other desiderata, often connected to\nanalyzing standard game-theoretic solution concepts for games. These\nare usually designed to find Nash equilibria or at least narrow down\nthe strategy profiles to those compatible with certain requirements of\nrationality. Well-known methods of this kind are Backward Induction\nfor extensive games and Iterated Removal of Strictly Dominated\nStrategies for strategic form games (Osborne\n& Rubinstein 1994). These will be discussed now, as they\nraise intriguing further logical issues. \nHere is a high-level description of Backward Induction. In extensive\ngame forms, the aim is to introduce a new preference-based relation\n\\(\\best_i\\), denoting that some move is the best a player can do at\nsome given state. Thus, \\(\\best_i\\) is a subset of player\ni’s total move relation, to be defined in a suitable\nmanner. \nFor final moves, standard decision theory suggests that a choice is\nbest for the active player if no other move leads to a better outcome.\nWhen extending the analysis to earlier positions of the game, things\ndepend crucially on players’ expectations about their\nopponents’ future behavior. Several possible policies exist,\ndepending on the types of player involved. A widespread assumption in\nepistemic game theory is common belief in rationality, i.e., that all\nplayers involved are rational, believe their opponents to be rational,\nbelieve their opponents to believe that opponents are rational, and so\non. In line with this assumption, the following algorithm extends the\n\\(\\best_i\\) relation recursively to non-terminal nodes: \nWhenever player i is to move at state s, possible\nchoices are assessed by comparing what would happen if, after that\nmove, everybody followed their \\(\\best\\) relation. A possible move at\ns is included in i’s \\(\\best\\) relation if the\nbest outcome of this move followed by repeated \\(\\best\\) moves by all\nplayers is at least as good as every other move i could make at\ns, followed by \\(\\best\\) moves by all players. \nHere is how this bottom-up procedure works in practice. \nExample Backward Induction. \nFigure 9.\n ⓘ \nThis procedure is a qualitative version of classic game theory’s\nBackward Induction, which is based on utility values rather than\npreference relations (Leyton-Brown & Shoham\n2008). \nBackward Induction and the resulting \\(\\best\\) relation is a prime\nexample for the complex entanglement of preferences, information and\naction. A key modal axiom governing this relation was identified by\nvan Benthem, van Otterloo, and Roy\n(2006). \\(\\best^*\\) denotes here the transitive closure of the\nunion of all \\(\\best_i\\) relations. \nDescribing the limit of a dynamic process with a static property, this\nequivalence exemplifies a family of characterization theorems\nthat play a crucial role within the logical analysis of games. Other\ndynamic perspectives can be analyzed in a similar logical style (Liu\n2011). \nIterative reasoning strategies akin to Backward Induction also exist\nfor games in strategic form. Rather than defining a new unary\nmove-predicate \\(\\best\\), however, these procedures work by\neliminating suboptimal actions. An action a is labeled\nsuboptimal or dominated if there is some other available\naction, b, that guarantees a better result than a, no\nmatter what the opponents do. In this case a rational player should\ndrop a from her space of admissible acts, as she would never\nplay it. \nJust as Backward Induction, dominance reasoning has an iterative\nflavor. Assuming common belief of rationality, players can expect\ntheir opponents to also drop dominated actions from consideration.\nDoing so reduces the game and might render further moves dominated, as\nis illustrated in the following example. Within the left-to-right\ntemporal progression, moves are greyed out as they get discarded.\nPlayers’ preferences are represented with numerical values with\n1 the best and 4 the worst. \nThe fact that further strategies may become dominated suggests to\nrepeat the procedure, turning removal of dominated strategies into an\niterated process. When games are finite, this process is guaranteed to\nconverge in finite time. Iterated removal of dominated strategies on\nbinary preference relations is a qualitative variant of the version\nemployed in classical game theory, where cardinal utility values are\nassumed (Leyton-Brown & Shoham\n2008). \nA closely related process is iterated removal of weakly\ndominated strategies, where some move a is deleted if\nthere exists a b that outperforms a on some of the\nopponents’ moves, while being at least as good on the remaining\nones. Unlike its strict counterpart, iterated removal of weakly\ndominated strategies suffers from a number of technical and conceptual\nintricacies, such as order dependence of iterated deletion (Samuelson\n1992; Pacuit & Roy 2011). \nGeneralizing the concept of winning or losing, agents can be assigned\ngoals they pursue in a game. Restricting to a single goal per agent\nretains a binary perspective: A goal is reached or not. Goals,\nhowever, allow for additional flexibility. Besides pure competition as\nin win-lose games, these can also express pure coordination games,\nwith everybody pursuing the same goal, or mixed motive games with\npartial overlap between different players’ goals. \nThe concept of goal functions is particularly prominent in the logical\nframework of\n Boolean games\n (Harrenstein 2004). There, each agent\nis given control over some atomic propositions, permitting her to\nfreely decide on their truth value. Goals are then formulated as\npropositional formulas over the set of all players’ atoms.\nCrucially, a player’s goal formula might hence involve atoms\nthat are not under her control. In iterated extensive Boolean games,\ngoal formulas might also refer to properties of histories of play\ndefined in temporal logics (Gutierrez,\nHarrenstein, & Wooldridge 2015) \nThere are various types of information players can possess or lack\nabout a game. First and foremost, players can be uncertain about the\ntypes of opponents they face: their preferences, their reasoning\nabout the game and how they expect the game to unfold. Second,\nagents’ uncertainty can extend to the game itself. Players, of\ncourse’ won’t know their opponents choices in a\nsimultaneous move game. Besides, agents might also have limited\ninformation about past moves and events. Such uncertainty can arise\nfrom the game structure eschewing certain observations, but also from\nfailing to record past information properly. In yet more extreme\ncases, agents might even be unsure about the moves available to their\nopponents. \nGiven the various limitations to their knowledge, players may\nentertain beliefs to structure their uncertainty. Such beliefs may,\nnaturally, change over time, as players communicate or observe the\ngame unfold. The importance of beliefs in the logical analysis of\ngames has been emphasized in Stalnaker\n(1998), who was the first to highlight the role of belief\nrevision in analyzing reasoning about game solution. \nIn one sense of uncertainty, even highly idealized agents might have\nbut limited information of what has happened so far. In certain cases,\nthe game’s structure may limit some players’ observational\npowers of their opponents’ moves. In other instances, agents may\nsuffer under cognitive limitations restricting their perspective on\nthe game. Or, sometimes, agents might simply fail to record some of\nthe moves made by themselves or others. \nWithin extensive games with imperfect information, all such\ncases are represented by indistinguishability relations \\(-\\,-\\,-\\,-_A\\)\nbetween states \\(m,m'\\), expressing that agent A cannot\ndistinguish between being at m and \\(m'\\). Notably, this does\nnot preclude the player from learning later on in the game whether he\nhas been at m or \\(m'\\). \nExample A game with imperfect\ninformation. \nFigure 10.\n ⓘ \nWhile allowing agents to lack information of various kinds, the above\nanalysis makes one structural assumption about players: they always\nknow which moves are available to them at a given node. In extensive\ngames with imperfect information, this translates to the requirement\nthat whenever two states are indistinguishable to some agent, they\ncoincide on the set of her possible actions. \nThe move from perfect to imperfect information has major implications\nfor strategic reasoning. In the game depicted above, player A\ncannot distinguish between being at m and \\(m'\\). When at the\nformer, she may, for all she knows, be at \\(m'\\) instead. Hence\nA’s decision needs to account for both possibilities; she\ncannot base her choice on any property that holds at only of those\nlocations. In particular, A has no available strategy that\nguarantees her ending up in a \\(\\win_A\\) node. Since E cannot\nensure a win either, no player has a winning strategy. This is a\ncentral difference with finite perfect information games, where it is\nguaranteed that one of the players has a winning strategy, cf.\n Section 2.4. \nReasoning about imperfect information requires to extended languages\nfor extensive form games with epistemic modalities. For each player\ni, modality \\(K_i\\varphi\\) represents i’s\nknowledge. The usual semantics of epistemic logic relates this to\nuncertainty, as encoded by the players’s indistinguishability\nrelation: \n\\(\\mathcal{M},m\\vDash K_i\\varphi\\quad\\)\nall states \\(m' \\text{ with } m\\,-\\,-\\,-\\,-_i\\,m'\\)\nsatisfy \\(\\mathcal{M},m'\\vDash\\varphi\\)\n \nThis language is best illustrated with the above game tree. To this\nend, interpret the tree as the classic children’s game where one\nplayer, A, has to guess in which hand her opponent, E,\nhides some little token. Once E has hidden the token in, say,\nher right hand (move \\(h_R\\)), the guessing player has a winning move\nde re: she should pick right (\\(p_R\\)). However, as\nthe token was placed in secret, she may not know that picking\nright is a winning move: the player has no winning strategy\nde dicto. This is expressed by:  \nIn a game theoretic setting, the de re vs. de dicto\ndistinction has been studied by Horty and\nPacuit (2017) and van Benthem\n(2001). \nIn light of these considerations, many logics for defining strategies \ninvolve epistemic elements. It seems reasonable to demand that agents \ncannot base their choice of strategy on everything that has happened before, \nbut only on what they know, i.e., their current information (Pacuit, Parikh, & Cogan 2006). The resulting \nuniform strategies (Maubert 2014), can be\ndefined by the knowledge programs of Fagin,\nHalpern et al. (1997). Further restrictions are possible, for\ninstance granting agents limited memory that only reaches back a fixed\nnumber of moves (Gutierrez, Harrenstein, &\nWooldridge 2015). \nThe epistemic action language can express many further phenomena in\nimperfect information games. The following game is an\nillustration. \nFigure 11.\n ⓘ \nOnce player E arrives at node n, she cannot discern that\nactual situation from node \\(n'\\). However, E must have\npossessed information earlier on that distinguishes n from\n\\(n'\\): to arrive at n, she must have played a as her\nfirst choice, while \\(n'\\) can only be reached after playing b.\nThus, E can only be uncertain between these two nodes if she\nforgot about her own previous actions. \nThe epistemic action language can distinguish between such scenarios\nwith memory loss and those without. The property of Perfect\nRecall states that players retain full memory of all moves they\nobserved. This can be expressed by the following axiom scheme (Halpern\n& Vardi 1986; Bonanno 2004) \nAlso the converse of this scheme admits a natural interpretation: \nThis No Miracles property expresses that players can only\nlearn by observing moves, not by any other methods extraneous to the\ngame. \nOf course, logic does not presuppose that all players have perfect\nmemory, or that they cannot pick up any information outside the\nprogression of play. Epistemic action language can equally well be\nemployed to analyze more general scenarios where the above axioms do\nnot hold. Especially within dynamic-epistemic versions, epistemic\nlogics can produce modified versions that cover many more cases than\nthose described here (van Benthem 2014).\nMoreover, further modalities from epistemic logic make sense, in\nparticular, those for common or distributed knowledge in groups of\nplayers (Fagin, Halpern et al. 1995; Meyer\n& van der Hoek 1995). \nAn epistemic component with operators \\(K_i\\) fits with many logical\nperspectives on games. In particular, epistemic extensions are as\ncompatible with coarse logics such as the earlier-mentioned\n\\([\\move_i]\\)-setting with a single move-modality per player, as with\nfine logics where each individual action type is represent by a\ndistinct modality \\([a]\\). In fact, in\n Section 2.6,\n epistemic operators were used for analyzing games in strategic form,\nwhere modalities naturally relate to uncertainty about the other\nplayers’ strategies. \nIn more general settings, uncertainty does not stop at the\nopponents’ informational states. In international relations or\neconomic bargaining, also the players’ motivations and\npreferences are not fully known to all parties involved. Within the\ncorresponding extended form games, players may be uncertain about\ntheir opponents’ preferences and strategic options, whether they\ncan afford a certain move or whether they actually possess the\ninformation they threatened to reveal. Obviously, uncertainty about\npreferences or available options will impact reasoning about the\nequilibria of a game. Strategic players might even try to exploit such\nuncertainties, for instance by pretending to have options they do not\npossess. \nIn a first pass, this type of uncertainty can be expressed by\nintroducing nature as hypothetical player, with a first move that\ndetermines the preferences and available options for all players. A\nsimple example is the game depicted below. At the start, A is\nuncertain whether E can reply to A’s move f\nby playing e. Likewise, she lacks information on whether\nE prefers \\(O_3\\) over \\(O_4\\), or vice versa. \nFigure 12.\n ⓘ \nFrom a logical point of view, this miraculous initial move by Nature\nis not needed. Standard epistemic models can represent the above\nscenario, and many more complex ones, by means of the\nindistinguishability relations introduced above. Technically, this\nrequires to move beyond standard imperfect information trees to\nso-called epistemic forests (van\nBenthem, Gerbrandy, Hoshi, & Pacuit 2009), sets of trees\nlinked by epistemic relations. In particular, the above game tree\ntransforms into \nFigure 13.\n ⓘ \nThe epistemic action language for trees works just as well on\nepistemic forests. However, in suitably expressive languages, the\nlogic of forests is weaker than that of trees, as the set of\nvalidities on the class of n-player trees is a strict superset\nof the validities on n-player forests. \nFurther enrichments of the logical framework add semantic structure to\nthe agents’ uncertainty. When unable to determine the exact\nsituation, players may classify options with respect to plausibility.\nTo this end, epistemic models have been equipped with plausibility\norderings \\(\\geq_i\\) for players i (Boutilier\n1994; Stalnaker 1968; Baltag & Smets\n2008). \nIn the preceding example, plausibility order might work as\nfollows: \nFigure 14.\n ⓘ \nThis richer structure is reflected by introducing new modalities for\nagents’ beliefs, determined by the most plausible states: \n\\(\\mathcal{M},w\\vDash B_i^{\\phantom{\\psi}}\\varphi\\quad\\)\n\\(\\varphi\\) holds in all \\(\\geq_i\\)-maximal states in i’s epistemic\nrange. \nConditional belief, important to players’ planning within a\ngame, can be interpreted in the same style: \n\\(\\mathcal{M},w\\vDash B_i^\\psi\\varphi\\quad\\) \\(\\varphi\\) holds in all\n\\(\\geq_i\\)-maximal \\(\\psi\\)-states in i’s epistemic\nrange. \nThese clauses are intended to work in finite as well as in infinite\nsettings. However, in the latter case minor modifications might be\nneeded akin to those in\n conditional logic.\n These have been proposed in various alternatives. Notably, this\nenriched epistemic-doxastic logic allows for further, less standard\ninterpretations beyond those illustrated so far. Examples are\n‘strong belief’, expressing that all relevant\n\\(\\varphi\\)-states are more plausible than all relevant\n\\(\\neg\\varphi\\) states, or ‘safe belief’ saying that\n\\(\\varphi\\) holds at all states that are at least as plausible as the\ncurrent one. See van Benthem and Smets\n(2015) for an overview of plausibility semantics and its\nconnections to conditional logic, belief revision theory,\ndynamic-epistemic logic, and a wide range of philosophical and\ntechnical issues. \nIn various scenarios, agents reason not only about the\nopponents’ preferences or admissible moves, but also about their\nbeliefs about the game and others’ behavior therein. In fact,\nsuch higher-order reasoning can have a major impact on game play. A\nprime example is the Backward Induction procedure of\n Section 3.3,\n where the construction of a best move relation crucially relied on\ncommon knowledge of rationality. More generally, agent’s best\nmoves frequently depend upon what they expect others to do. This\nphenomenon is especially prominent for simultaneous move games, where\nit occurs in both coordinative scenarios (Skyrms\n2003; Lewis 2002) as well as\ncompetitive ones (Hotelling 1929). More\ndetails can be found in the entry on\n epistemic game theory. \nArbitrary first and higher order levels of knowledge and belief can be\nrepresented with the above relational models, the standard tool in\n epistemic\n and doxastic logic. For information in extensive form games, the\nepistemic-doxastic perspective on states can be combined with\n\\(\\move\\)-relations in exactly the way described before. The result\nare epistemic-doxastic trees or forests that can\nrepresent most types of knowledge or belief players might have about\nthe game, including its exact shape, previous moves, opponents’\npreferences or opponents’ first- and higher-order beliefs on any\nof these matters. \nOutside of logic, higher-order information has also been modeled in\nclassical game theory. Quantitative frameworks represent information\nas probability distributions over a given event space. In this\nsetting, higher-order information corresponds to probability\ndistributions over probability distributions of the right kind. More\nspecifically, \\(n^{\\textrm{th}}\\) order information corresponds to a\nprobability distribution over the space of \\((n-1)^{\\textrm{th}}\\)\norder beliefs. As shown by Harsanyi\n(1967–1968), the limit of specifying higher and higher\nlevels of information can be represented as a type space, where each\nagents’ type is a probability distribution over states of nature\nand the other players’ types. In an abstract sense to be\ndiscussed below, these types correspond to states in standard models\nof modal logic. \nIn addition to standard modal models, logic also has a straightforward\nanalogue to probabilistic type spaces: logical type spaces.\nIn a formal framework first introduced by Fagin,\nGeanakoplos et al. (1999), an\nn-type is a sequence \\(\\mathfrak{f}_n=\\langle\nf_0,f_1\\ldots,f_{n}\\rangle\\) where \\(f_0\\) specifies the state of\nnature, i.e., a valuation recording which atomic propositions are true\nor false, and \\(f_1\\) lists for all players the states of nature they\nconsider possible. \\(f_m\\) for \\(m\\geq 0\\) then specifies for all\nplayers which \\((m-1)\\)-types, i.e., sequences \\(\\langle\ng_0,\\ldots,g_{m-1}\\rangle\\) they consider possible. In this way, an\nn-type fixes the player’s higher-order beliefs up to\nlevel n. These types are, of course, subject to coherence\nconditions: the agents’ k-types for different k\nmust fit together. For instance, whenever some agent considers a\nk-type \\(\\mathfrak{f}_k\\) possible, she must also consider any\ninitial segment \\(\\mathfrak{f}_{k'}\\) for \\(k'<k\\) possible.\nConversely, any \\(k'\\) type the agent considers must be the initial\nsegment of some k type the agent holds possible. Type\nspaces offer a semantics for the epistemic language: Inductively, for\na formula \\(\\varphi\\) of modal depth m, \\(K_i\\varphi\\) is true\nat a type \\(\\mathfrak{f}_n\\) if all \\(g_{m}\\in f_{m+1}(i)\\) satisfy\n\\(\\varphi\\) or if \\(m>n\\). \nAlternatively, the set of n-types allows for a natural\ninterpretation as relational models with accessibility relations\ndefined by \n\\(\\langle f_0,\\ldots f_n\\rangle R_i\\langle g_0,\\ldots g_n\\rangle\\quad\\)\nFor all \\(m\\leq n\\) holds \\(g_{m-1}\\in f_m(i)\\) \nInterpreting the set of n-types as a relational model yields a\nsecond way of evaluating the epistemic language on logical type\nspaces. For formulas of modal depth less than n the two\ninterpretations coincide. Hence, up to finite depths, type spaces and\ntheir associated relational models are two perspectives on the same\ninformational situation. \nTo fix all of the agents’ beliefs, the analysis moves to types\n\\(\\mathfrak{f}=\\langle f_0,f_1,\\ldots\\rangle\\), containing some\n\\(f_n\\) for every natural number n. In this extended framework\nthe situation becomes more complicated. The space of all such types is\nuniversal in the following sense: every relational model can be mapped\nin a truth-preserving manner to the space of all types by sending each\nstate to a full description of the agents’ corresponding first-\nand higher-order informational attitudes. This map, however, is\nusually not a modal bisimulation. In fact, the process of type\nconstruction could be continued indefinitely, yielding a transfinite\nhierarchy of mutually non-bisimilar type spaces (Heifetz\n& Samet 1998). Such transfinite\ntypes can become relevant when the epistemic language is enriched with\nmodalities for common group knowledge, in which case a full\ndescription of all expressible attitudes involves infinite hierarchies\nof higher-order information (Fagin, Geanakoplos\net al. 1999). A recent logical study of type spaces including\ntheir probabilistic structure can be found in Bjorndahl\nand Halpern (2017). \nThe tight connection between type spaces and relational models is\ncompatible with additional assumptions that might be imposed on the\nplayers’ mental states. Fagin,\nGeanakoplos et al. (1999) characterizes when type spaces give\nrise to \\(S5\\) models, while Galeazzi &\nLorini (2016) do the same for multi-agent KD45\nbelief. \nWhile relational models and logical type spaces represent exactly the\nsame information, their main differences is in perspective. Relational\nmodels take a third person bird’s eye view on possible worlds.\nTheir starting point is a set of worlds rich enough to contain all\nstates considered possible by the relevant agents, together with\naccessibility relations modeling players’ information. From\nthere, agents’ first-order beliefs at the various worlds can be\nread off and, subsequently, also all higher levels of information.\nLogical type spaces, by contrast, assume a first person\nperspective. They take a full description of first and higher-order\nbeliefs as primitive and treat indistinguishability as a derived\nrelation. \nFinally, it should be noted that type spaces assume a static\nperspective on games. No provisions are taken for representing moves\nor strategies explicitly, nor for incorporating updates of knowledge\nand belief that occur as a game in extensive form unfolds, cf. the\ndiscussion in\n Section 4.\n Thus, there is some distance between type spaces and the earlier\nepistemic-doxastic forest models for extensive games. As a first step\ntowards filling this gap, it has been shown how type spaces can\naccommodate product updates from dynamic epistemic logic (Klein\n& Pacuit 2014). \nBesides variations in preferences and beliefs, a third crucial aspect\nof players is their styles of information processing, decision making,\nand reasoning. Real cognitive agents are bounded in their information\nprocessing, as both their memory and reasoning capacities are limited.\nIn particular, players may not be able to represent the entire game\nthey are in, nor reason until the end of the game. This phenomenon of\nshort sight has been studied in Grossi\nand Turrini (2012) and Turrini\n(2016). Moreover, in real-life iterated social interaction,\npayoffs are generated along the game, and may not be clear beforehand,\n(Axelrod & Hamilton 1981). In such\ncontexts, the best strategy in terms of short-term payoffs need not be\noptimal in the long run, but bounded agents may miss this longer\nhorizon, (Klein, Marx, & Scheller\nforthcoming). \nLogical literature on bounded agency is too broad to be surveyed here.\nFor a few research lines relevant to games, see Fagin\nand Halpern (1987) and Heifetz, Meier, and\nSchipper (2006) on epistemic logics with awareness, Artemov\n(2008) on\n justification logics,\n van Benthem and Pacuit (2011) on\nevidence logics, and Hansson (1998) and Lorini\n(2018) on doxastic logics with computationally tractable belief\nbases. \nIn the game theoretic literature, bounded agents have often been\nrepresented as finite state machines (Gutierrez,\nHarrenstein, & Wooldridge 2015;\nBinmore & Samuelson 1992). Limitations on reasoning\ncapacities or memory size then translate into bounds on the machine\nsize. The resulting hierarchy allows for a fine grained analysis of\ninformation processing, reasoning, and thus bounded players of\ndifferent types. This perspective fits well with the logical study of\nagency in computer science, (Grädel,\nThomas, & Wilke 2002; Wooldridge 2009). \nIn an integrated perspective, preferences, beliefs and reasoning\nstyles can all be subsumed under the game-theoretic notion of a\nplayer type. For reasoning about the future course of a game,\nplayers will hence often entertain beliefs about each others’\ntypes. A simple example is Backward Induction, where players assume\nall opponents fully rational throughout. In more complex settings,\nindividual actors may attempt to rationalize various moves observed\nand derive predictions about their opponents’ future behavior by\ntaking a broader range of options into account. Such players may start\nby assuming the counter-player to be a simple machine, and only move\nup to more complex views when required by evidence. In particular,\nthere is no reason to assume uniformity of players or views. Within a\ngiven scenario, a diversity of player types might be present (Liu 2009; Liu\n& Wang 2013; Paul & Ramanujam 2011;\nGhosh & Verbrugge 2018; Bergwerff et al. 2014). For some\ngame-theoretic proposals concerning most frequently occurring player\ntypes, see Camerer (2003). \nThis section has outlined a variety of ways for incorporating players\nand agency into game forms. These come in a hierarchy of richness,\nranging from annotated game trees to epistemic forests, type spaces,\nor yet more abstract models of games. \nAt the thinner end, the focus is on structural aspects of the game,\nincorporating players’ preferences, but not necessarily their\nbeliefs. Such frameworks are typically just rich enough to represent\nequilibria or backward induction paths, and to reason about these in\nlogics of action and preference. Thin models leave much information\nabout players’ knowledge, beliefs, or their modus\noperandi unspecified, and put less emphasis on the actual\ndynamics of game play. \nAt the thicker end, models for games have lush worlds encoding\nplayers’ preferences, information, beliefs, and perhaps even\ntheir complete types, including memory and reasoning capacities.\nTypical models of this kind are found in Stalnaker\n(1998) and Halpern\n(2001). When applied to extensive\ngames rather than strategic-form games, thick models can anticipate\nanything that can happen in one large temporal universe, allowing to\nderive a full prediction about how play will proceed. \nThe distinction between thick and thin logical models seems folklore\nin applied logic. In fact, it occurred already in the\nearlier-mentioned choice between local logics with single step\nmodalities versus temporal logics built over a complete universe of\nhistories. Yet, there does not seem to be a unique best perspective.\nRather, the choice between thick and thin models often depends on the\nexact goals pursued. A central consideration in this trade off is\nwhere the dynamics of stepwise play should be located: Thick models\npre-encoded such dynamics, whereas thin models allow for an external\ndynamic logics for updates (Baltag, Smets, and\nZvesper 2009). The next section will highlight a number of ways\nfor complementing a thin perspective with dynamic information on game\nplay through representations of actions and updates. \nDeontic reasoning Preference is closely\nrelated to obligation and permission. This shows in particular on the\nformal side, where preference logic in both static and dynamic\nvariants (Hansson 1990; van Benthem, Grossi,\n& Liu 2014) has clear analogies with\n deontic logic.\n Moreover, deontic and game-theoretic perspectives have given rise to\nmany fruitful connections. In one direction, deontic notions may be\nseen as high-level descriptions of optimal actions given the\ninformation and obligations of agents (Kooi\n& Tamminga 2008; Anglberger, Gratzl, & Roy 2015).\nConversely, game solution procedures can enrich accounts of deontic\nnotions (Başkent, Loohuis and Parikh 2012; Horty 2018).\nLastly, in artificial intelligence, deontic perspectives arise in\ntracking the behavior of a distributed system in relation to its\ngoals, (Ågotnes & Wooldridge\n2010). \nMathematical foundations Incorporating\nplayers raises new questions about game equivalence. When agency\nmatters, adequate notions of equivalence cannot stop at preserving\nproperties of the underlying game form. Rather, player-dependent\nequivalences will also require preservation of players’\nbeliefs, preferences or reasoning types. Incorporating such additional\nparameters makes it harder for two games to be equivalent, as new\nspace for variation comes into play. On the other hand, agent\nlimitations might also create new simpler game equivalences that can\nbe studied by the tools of this entry. \nThe term ‘game theory’ suggests that everything of\ninterest is captured in the format of a game with its moves and\noutcomes. The present entry reassembles this perspective, considering\nadditional structure. A first extension was offered in\n Section 3,\n treating the nature of players as a topic in its own right. This\nsections puts a spotlight on a second topic, game play in a wider\nsense. \nMany themes in the literature on logic and games fall into three\nphases connected to play. Certain activities can already be conducted\nbefore the actual game. Examples are assessing the opponent\nor forming a plan. Most relevant choices and decisions, however, take\nplace during the game - at least unless one thinks of players\nas automata blindly following preset strategies. Lastly, also\nafter a game significant activities occur. These involve\nlearning about opponent types, identifying crucial mistakes made, or\nrationalizing the moves taken. In what follows, examples will be\npresented of each phase. \nWhen viewing games as static structures, rationality can be defined in\nterms of coherence between players’\n beliefs, preferences and choices or intentions\n (Elster 1988). However, rationality\nalso describes a quality of behavior, related to how players act or\nwhat they take advantage of when deliberating about a game. The\nrelation between both perspectives can be made concrete when\ninterpreting game solution procedures as styles of pregame\ndeliberation. To follow is a dynamic analysis of Backward Induction\n(cf.\n Section 3.3)\n that differs conceptually from\n characterization theorems\n in terms of static properties such as common knowledge or common\nbelief. In the dynamic analysis, these group properties are not\nassumed as preconditions. Rather, they are produced through the logic\nof deliberation. \nThe Backward Induction algorithm is usually presented in a\nquantitative setting, where each outcome is associated with  utility values for all players. \n(Leyton-Brown and Shoham 2008). However,\nthe same algorithm also works in a qualitative setting, with attitudes\nexpressed by a preference relation between outcomes. \nBackward Induction Backward Induction\ncomputes optimal moves for players. More specifically, at each choice\nnode of an extensive form game, one or more of the available moves is\nlabeled as optimal. For each player this set of optimal moves often\nforms a strategy in the usual game-theoretic sense, i.e., a function\nselecting a unique action to take at each of her choice nodes. Yet,\nthere are degenerate cases where backward induction merely creates a\nrelational strategy, restricting the available moves, while still\nleaving some choices to the player. \nThe principle driving the Backward Induction algorithm is that no\nplayer should ever select a move that is dominated by another move\navailable at the same moment. Dominance here works in a recursive\nmanner. Move a dominates move b if the corresponding\nplayer prefers each final outcome reachable from a by following\nBackward Induction moves to every outcome reachable from b by\nBackward Induction moves. \nPublic announcement of rationality In\none perspective, Backward Induction can be understood as a process of\nprior-to-play deliberation, executed by players whose minds proceed in\nharmony. Deliberation steps are repeated public announcements\n(\\(!\\rat\\)) of rationality-at-nodes: \nDominance here is a relation between the outcomes available after a\ncertain move has been made. In one interpretation, some move a\ndominates another move b if every outcome that remains\nobtainable after a is preferred to any outcome reachable after\na b move. However, there is a dynamic twist: crucially, the\ngame tree considered, and hence the outcomes available, changes during\nthe deliberation procedure. \nThe semantics of\n announcement updates\n works by trimming models. \\(!\\varphi\\) transforms a model M\ninto a sub-model \\(M_{|\\varphi}\\) consisting of all those points in\nM that satisfy \\(\\varphi\\), while deleting all \\(\\neg\\varphi\\)\nnodes. Relations on \\(M_{|\\varphi}\\) are those inherited from\nM. Crucially, deletion may change the truth value of formulas:\nafter announcing \\(!\\varphi\\), some nodes in \\(M_{|\\varphi}\\) may\nsatisfy \\(\\neg\\varphi\\). In particular, with M the set of\npoints in a game tree, the set of available histories may keep\nshrinking as successive announcements are made. Hence, repeated\nannouncements of \\(!\\rat \\) make sense. In finite games, this process\nalways reaches a limit, a smallest subgame where no move is dominated\nby another. \nExample Solving games through iterated\nassertions of rationality. \nConsider the following game, already introduced in\n Section 1.1.\n Iterated announcements of \\(!\\rat \\) removes nodes that can only be\nreached by dominated moves as long as this can be done. The trace of\nthis procedure is: \nFigure 15.\n ⓘ \nHere, the Backward Induction solution emerges step by step. Stage 1 of\nthe procedure rules out the leaf labeled with (\\(2,2\\)) as the only\npoint where \\(\\rat \\) fails. Stage 2 then rules out E’s\nchoice node as new node where \\(\\rat\\) fails. In the resulting game\ntree, \\(\\rat \\) holds throughout. \nMore generally, let \\((!\\varphi, M)^\\#\\) be the limit (i.e., the first\nfixed point) of M under repeatedly announcing \\(\\varphi\\) as\nlong as it still true. In any game tree, the fixed-point \\((!\\rat ,\nM)^\\#\\) has \\(\\rat\\) true throughout. Its nodes contain the actual\nplay computed by the Backward Induction algorithm (van\nBenthem 2014). \nLimit behavior Rationality is\n‘self-fulfilling’ in the limit: if players commit to it in\ndeliberation for long enough, they prune away all irrational moves\nand, a fortiori, all moves incompatible with common belief of\nrationality. The final outcome is a model with rational play at every\npoint, a form of common knowledge of rationality. However, iterated\nannouncements can also yield a different type of limit behavior:\nself-refutation. A prime example for this is the classic Muddy\nChildren puzzle (Gierasimczuk & Szymanik\n2011) where repeatedly communicating ignorance leads to\nknowledge in the end. Also within game theory, a number of situations\nexist where (credible) announcements of future irrationality can leave\nsome player better off than the Backward Induction solution (Leyton-Brown\n& Shoham 2008). \nIterated belief revision. A different\nperspective of pre-game deliberation is couched in terms of belief\ninstead of knowledge. The driving force here is\nrationality-in-belief: \nIn this setting, the game tree itself remains invariant during\ndeliberation: no histories are removed or ruled out. What may change instead \nis the relative plausibility of occurrence players assign to end nodes\nor, in infinite games, histories. \nIn plausibility semantics (briefly introduced in\n Section 3.6),\n an agent believes propositions that hold true in all those\nepistemically accessible worlds that are maximal in her plausibility\norder. The corresponding dynamics of deliberation does not proceed by\npoint deletion, but by soft updates modifying the\nagents’ plausibility ordering. For Backward Induction, a\n‘radical upgrade’ \\(\\Uparrow\\varphi\\) suffices, that moves\nall \\(\\varphi\\)-worlds above all \\(\\neg\\varphi\\)-worlds states while\nmaintaining the ordering within these two sets (Baltag\n& Smets 2008). \nHere is how this mechanism works in a game setting. Start with all end\nnodes equiplausible for all players. Since upgrades proceed by public\nannouncement, all players will share the same beliefs throughout. In\nthe procedure to follow, a move x is dominated in\nbelief by a move y of the same choice node if, in the\nacting agent’s plausibility ordering, the most plausible end\nnodes reachable after y are all better for her than each most\nplausible end node compatible with move x. Now perform radical\nupgrades of type \nExample Backward Induction, soft\nversion. \nHere are the stages for the new procedure in the preceding example,\nwhere the letters \\(x, y, z\\) stand for end nodes or histories of the\ngame: \nFigure 16.\n ⓘ \nIn the top node of the leftmost tree, going right is not dominated in\nbeliefs for player A by going left. So, \\(\\rat ^*\\) only\naffects E’s turn, and radical upgrade with \\(\\Uparrow\\rat\n^*\\) makes \\((0, 3)\\) more plausible than \\((2,2)\\) . After this\nchange, going right has become dominated in beliefs in the top node,\nand a new upgrade takes place, making A’s going left most\nplausible. \nIterated upgrade with \\(\\rat ^*\\) always stabilizes to a fixed\nplausibility order, which is the same for all players. Identifying\neach history of a game with its end node allows for a belief analysis\nof Backward Induction (van Benthem &\nGheerbrant 2010). On finite trees, the histories emerging when\nall players resort to their Backward Induction strategies exactly\ncorrespond to the most plausible end nodes created by iterated radical\nupgrade with rationality-in-belief. An alternative dynamic-epistemic\ncharacterization of Backward Induction, using similar ideas in a\ndifferent mix, can be found in Baltag, Smets,\nand Zvesper (2009). \nStabilization cannot be taken for granted. For other assertions\n\\(\\varphi\\), iterated upgrades \\(\\Uparrow\\varphi\\) can lead to\noscillating or divergent plausibility orders. However, this divergence\nis limited. While cycles can occur for conditional beliefs, every\ntruthful iterated sequence of radical upgrades eventually stabilizes\nall propositional beliefs (Baltag & Smets\n2009). \nFixed-point logic In a more technical\nperspective, Backward Induction strategies can be defined as largest\nsubrelation of the total \\(\\move\\) relation that has at least one\nsuccessor at each non-terminal node, while satisfying a confluence\nproperty between action and preference: \nThis fact is the basis for proving that Backward Induction is\ndefinable in First Order Fix point logic LFP(FFO) (van\nBenthem & Gheerbrant 2010). Results\nin this line of research connect game solution and game-theoretic\nequilibria with fixed-point logics of computation. In simple settings,\nsuch as that of Zermelo’s Theorem mentioned earlier, modal\nfixed-point logics akin to μ-calculus suffice. \nFurther game solution concepts can be analyzed with logics of iterated\nupdate. In particular, iterated updates are not restricted to\nextensive form games, but can also provide insights for games in\nstrategic form. A paradigmatic algorithm is Iterated Removal of\nStrictly Dominated Strategies \\((SD^\\infty)\\). In this setting, a\nstrategy is considered dominated if there exists another strategy that\nyields a strictly higher payoff against any of the opponent’s\nactions. \nExample Iterated removal of strictly\ndominated strategies \\((SD^\\infty)\\). \nConsider the following matrix. As usual, pairs list A’s\nutility first, E’s second. \nFirst remove the right-hand column, i.e., E’s action\nc which is dominated by either of a and b. With c\nbeing removed, A’s action f has become strictly\ndominated. After its removal, E’s action b becomes\nstrictly dominated, and after that, A’s action e.\nAt the end of the process, iterated removal leaves nothing but the\nstate \\((d,a)\\), the game’s unique Nash equilibrium. In general,\nthe resulting game matrix after all removals is guaranteed to contain\nall Nash equilibria of the original game, but it may also contain\nfurther strategy combinations. \nIn this setting, the formal dynamic apparatus involves assertions\nappropriate to the matrix games of\n Section 2.\n In fact, various different types of rationality can be defined in\nlogics for matrix games. Here is an illustration for two-player games,\ninvolving announcements of ‘Weak Rationality’: \nThis statement is the negation, for each player, of her current action\nbeing strongly dominated. Naturally, this property can be expressed\nformally with suitable epistemic action modalities. Yet, even as it\nstands, it is clear that Weak Rationality can be announced to prune\naway strategy profiles, and that in a iterated manner. The strategic\ngame will change every time weak rationality is announced, initiating\na stepwise process that resembles the earlier iterative announcements\nof rationality for Backward Induction. As observed there, limits of\npublic announcements are always reached eventually, as models can only\nget smaller. For announcing Weak Rationality, these limits match the\noutcome of \\(SD^\\infty\\) precisely (van Benthem\n2007). \nA similar style of analysis can be extended to other notions of\nrationality. For instance, taking \\(B_i\\) to stand for ‘the\ncurrent action of player i is best for her against all actions\nof the opponent’, the following formula may be dubbed strong\nrationality SR \nBriefly, the formula expresses that both players have a reasonable\nhope of doing well. Strong Rationality in this sense is\nrelated to the rationalizability program for game solution (Pearce\n1964; de Bruin 2005), where actions\nare discarded if a better response exists under all circumstances.\nStrong Rationality, too, drives a game solution method. \nExample Updates with iterated\nannouncements of strong rationality (SR). \nConsider a slight variation on the previous example. Below is the\nsequence of updates for iterated announcements of strong rationality\n\\((\\textit{SR}^\\omega)\\) \nEach box may be viewed as an epistemic game model, as explained\nearlier. Again, every step of announcement increases players’\nknowledge, until a fixed-point is reached, constituting an equilibrium\nwhere each player knows as much as they can. \nStrong rationality is a more demanding condition than weak\nrationality. While SR implies WR, there can be moves\nthat satisfy weak but not strong rationality. This shows in the\nfollowing difference between the current and the previous example. In the present matrix,\nannouncing Weak Rationality stops after the first step elimination of\naction c. The reason is that, in the second matrix, the row\nplayer’s bottom move is not strictly dominated by any other\naction, so this row remains after re-announcing WR. However,\nunder no possible circumstance is the row player’s bottom action\nbest for her. This contradicts strong rationality and hence that row\nis eliminated by the next SR announcement. More generally,\nthe game matrix resulting from \\((\\textit{SR})^\\infty\\) is a\nsub-matrix of that produced by \\((\\textit{WR})^\\infty\\). Notably, this\nis not entirely obvious, as the two update sequences may produce\ndifferent epistemic models satisfying different formulas. A proof can\nbe found in van Benthem (2014). \nJust as with Backward Induction, there are connections between\niterated announcements and fixed-point logics. The set of strategy\nprofiles that survive iterated announcements of strong rationality can\nbe defined in modal μ-calculi (Kozen 1983;\nVenema 2008). If announcements are generalized to arbitrary\nformulas, so-called deflationary fixed-point logics are needed for\nstudying limit behavior (Ebbinghaus & Flum\n1995; Dawar, Grädel, & Kreutzer 2004). \nFurther game solution concepts have been analyzed in a similar dynamic\nupdate style. The iterated regret minimization of Halpern\nand Pass (2012), for instance, has\nbeen captured in terms of iterated announcements (Bobbio\n& Cio 2018). \nIt should be noted, that there are also more deductive takes on\nsolution concepts, where successive inferences assume the role of the\nsemantic updates above. A systematic proof-theoretic perspective on\ngame-theoretic reasoning toward solution can be found in de\nBruin (2005). Lastly, alternative analyses\nof Strong and Weak Rationality as well as other game solution\nconcepts, in an abstract rewriting format of computational logic can\nbe found in Apt (2005). \nDigression: comparing across representation\nlevels Different iterative announcement procedures\nlead to different analyses of games. Moreover when comparing various\nprocedures across different frameworks, surprises may occur. For an\nillustration, take Backward Induction. Its dynamic analysis produced a\nnew ‘best move’ relation or plausibility order on an\nextensive form game. The resulting strategy profiles may differ from a\nNash equilibrium analysis of the associated strategic form game: \nExample Backward Induction and Nash\nequilibria. \nConsider the following game. E has no preferences between any\noutcomes, but A does, as marked by the utility values.\n \nFigure 17. \n ⓘ \nIn the earlier BI analysis, neither move for A dominates the\nother in beliefs, so no move is eliminated. Now consider the two\npossible strategy profiles of each player and compute Nash\nequilibria: \n(Left, right) is not a Nash equilibrium, since A would\ndo better by playing Right, but (Left, left) is. \nThis illustrates differences in logical perspective on strategic and\nextensive form games. Primitive elements of the former, strategies,\nare complex objects in the latter’s game tree that cannot be\nidentified completely at the level of individual nodes alone. A\nrelated point of connecting perspectives in classic game theory gave\nrise to the concept of subgame perfect Nash equilibria (Selten\n1975). \nFurther scenarios Casting game solution\nin terms of deliberation renders it an internal mental process:\nnormally opponents do not sit down together to discuss their game play\nin advance, but reason about the opponents’ possible actions and\nconsiderations. However, the deliberative techniques introduced above\nalso apply to real conversational scenarios. An example related to\ngame theory is the topic of disagreement, first introduced in an\nepistemic setting by Aumann’s\n1976 seminal agreeing to disagree\nresult. Dégremont and Roy (2012)\ninvestigate this topic with techniques of dynamic logic, building on\nclassical results from Geanakoplos and\nPolemarchakis (1982). In this framework, any dialogue where\nagents keep stating whether or not they believe some formula\n\\(\\varphi\\) leads to agreement in the limit model, where updates no\nlonger have any effect. Briefly said, agents cannot disagree forever,\nat least when starting with different hard information, while sharing\na well-founded plausibility order. \nGame play is a dynamic process, where players repeatedly obtain new\ninformation about other players. Certain aspects of information\ncollection are hard-wired into the game’s structure, such as\nobserving moves, or, in settings of imperfect observation, changing\nfrom one information state to another. Other updates may be\nextraneous, such as signals about the type of opponent one is dealing\nwith. As of now, there is no general logical theory encompassing all\nthese phenomena. Yet, instructive samples exist. The first topic to\naddress concerns the players’ knowledge, the second their\nbelief. \nIn one perspective, games annotated with imperfect information cells\ncan be interpreted as recording a process of actual play. However, an\nimperfect information tree does not suffice to fully specify the trace\nof a real game. This raises the question on how to tease out what has\nreally happened. One style of analysis involves techniques from\n dynamic-epistemic logic.\n In this approach, players are assumed to have perfect recall, they do\nnot forget anything they once knew, while also satisfying No Miracles:\nobservation of actual game play is their only source of information,\n(cf.\n Section 3.6). \nIn a first approximation, every move triggers a public announcement,\ninforming all players what just happened. Many games, however, include\npartially observable moves, where some players merely learn that an\nact has been performed, but not necessarily which. In this case,\ninformation processing requires product updates from\ndynamic-epistemic logic (cf.\nBaltag & Moss\n2004), allowing for an appropriate mixture of\nknowledge and uncertainty. \nExample Decorating a game tree by\nupdates. \nThe left-hand side of the following diagram displays the game’s\nbare action structure, without any information on observability.\nHowever, when moving, players can distinguish their own actions, but\nnot all moves of their opponents. Their precise observational powers\nare described by event models for the individual moves (cf.\nvan Ditmarsch, van der Hoek, & Kooi\n2007). \nFigure 18.\n ⓘ \nThe observational structure on possible moves is encoded by relations\nbetween the corresponding nodes, as described for games of imperfect\ninformation\n (Section 3.6).\n Here are the successive updates that create the uncertainty links in\nthe tree: \nFigure 19.\n ⓘ \nThe resulting annotated tree is the following imperfect information\ngame: \nFigure 20.\n ⓘ \nA similar analysis applies to infinite trees as well as to epistemic\nforests (cf.\n Section 3.6).\n More generally, any imperfect information structure can arise from\ninformation updates, provided players satisfy perfect recall and no\nmiracles, and moves in the game have logically definable preconditions\ngoverning their availability. Precise formulations and proofs can be\nfound in van Benthem, Gerbrandy, Hoshi, and\nPacuit (2009). A generalization to game play without assumption\nof synchronicity is provided in Dégremont,\nLöwe, and Witzel\n(2011). \nNo miracles and perfect recall are typical assumptions for most types\nof agents in game theory. However, certain scenarios require\nmodifications, (cf. Osborne & Rubinstein\n1994 on the ‘drunken driver’ scenario). Moreover,\nif players are represented as finite automata, (cf.\n Section 3.8),\n perfect recall fails, and quite different patterns of uncertainty\nbecome possible. Characterizations results for memory-free and\nmemory-bounded players can be found in Liu\n(2011). \nIn addition to observational restrictions built into the game setup,\nproduct updates can also model extraneous communication or other\ninformation flow parallel to actual play. Some such scenarios will be\nlisted under Further Directions below. \nCertain types of information may be judged inconclusive or not fully\nreliable. While unsuitable for advancing knowledge, such information\nmay prompt agents to alter some of their beliefs. Such inconclusive\nevidence often concerns expectations concerning opponents’\nplayer types. Leaving aside the possibility of mere mistakes, all\nmoves can be assumed to result from intentional, strategic\nconsiderations. By interpreting opponents’ past moves, agents\nmay hence infer about their beliefs, preferences, risk attitudes or\nreasoning types. Naturally, most such observations are not fully\nconclusive. The corresponding updates hence cannot delete any\nalternatives. Rather, they merely change the agent’s\nplausibility ordering \\(\\leq_i\\) among different options. Formally,\nthis can be handled with the plausibility updates introduced for\nBackward Induction. However, the interpretation differs. Here, these\nupdates do not represent steps in pregame deliberation, but result\nfrom actual moves during the game. Besides the radical upgrade\nintroduced above, a number of further updating policies reflecting\ndifferent attitudes to the information acquired are defined in Baltag\nand Smets (2008). The\nepistemic-plausibility patterns that can arise from systematic\nplausibility update in games have been identified in Dégremont\n(2010), using two\ncounterparts of the earlier perfect recall and no miracles properties:\n‘Plausibility Revelation’ and ‘Plausibility\nPropagation’. \nThese results refer to but one aspect of belief in games. There are\nothers. A further type of belief describes agents prior attitudes to\nthe game, generated by past experience or deliberation. Another refers\nto the agents’ beliefs about where they are located in the game\ntree, based on previous observations during play. To keep these\nnotions separate, one might distinguish between more local\n‘beliefs’ during play and future-oriented\n‘expectations’ about the game’s progression.\nPlausibility orders created by Backward Induction, for instance,\ndescribe expectations about future game play. These are not based on\nobservations already made in the present game, and significantly, fail\nto satisfy the properties of plausibility revelation and propagation.\nHere is a particular strand of logical belief and its revision that is\nof independent game-theoretic interest. \nForward Induction Suppose some player\nhas deviated from her Backward Induction strategy as computed in\npre-game deliberation. What are others to make of this? Answers\noffered in the literature range from interpreting the deviation as an\nerror without any future implications (Aumann\n1995) to treating it as significant in various ways (Bicchieri\n1993). In the latter vein, the\ndeviation could be a signal for cooperation (believable or not), a\nsign of limited resources, or it could reveal other relevant\ninformation about the player’s type. \nMore explicitly, the situation has the following aspects. At any stage\nof a game, players have several types of information, including their\nprior expectations of how the game would proceed and the perhaps\nsurprising observations made along the way. If the game is to continue\nfurther, as in the state marked below, agents need to integrate both\ninto expectations about the future course of the game. \nFigure 21.\n ⓘ \nRationalizing There is no unique best\nway of integrating information of the various kinds. Yet, a natural\noption is to maintain the assumption of opponents’ rationality,\ntaken in the earlier sense. Assuming preferences to be common\nknowledge, observed moves hence provide new information about the\nopponent’s belief. More specifically, these beliefs have two\ncomponents: expectations about what other players will do, and\nintentions about their own future actions. The driving principle will\nthen be Rationalizing     \nBy playing a move, a rational player communicates that this move is\nnot strictly dominated-in-beliefs for her. \nClearly, rationalizing can only be maintained as long as the player\ndoes not choose a move that is strictly dominated under all\ncircumstances. In that case, one must ascend a ladder of further\nhypotheses about the opponent, including the possibility of her making\nmistakes. \nReasoning policies of the above type are called Forward\nInduction. Battigalli and Siniscalchi (2002) and\nBrandenburger (2007), analyze Forward Induction in extensive\nform games based on its known tight connection with Iterated Removal\nof Weakly Dominated Strategies in strategic form games. The following\nexample involving explicit reasoning is from Perea\n(2012). \nExample A Forward Induction\nscenario. \nFigure 22.\n ⓘ \nIn the matrix game, no move dominates any other. Hence E should\nconsider all outcomes possible. In this case, going left is\nsafer for her than going right, and hence A should\nplay Left at the start. However, if E rationalizes,\nand observes A going Right, she has extra information\navailable at her choice node. Following the rationality assumption,\nA expects to do better than 3, which is only possible if he\nintends to play Up in the matrix game. Now this tells\nE to proceed to the matrix and play the left column\ntherein. E’s results in a better payoff than the 2 of her\noriginal safe option. \nFrom a logical perspective, a study of Forward Induction requires\nepistemic-doxastic models with ternary world-dependent plausibility\nrelations, combined with the public announcement updates or\nplausibility upgrade described above (Section 4.1.2;\n see. also van Benthem 2014). No definitive logical analysis of\nForward Induction has been published so far. \nComparatively little attention has been paid in the literature to what\nplayers do after a game. Yet, these follow up-activities are often\ncrucial, for instance to establish general lessons learned that may be\nvaluable for future game play. Such interpretations are especially\nprominent in small or isolated groups, where the same opponent might\nbe encountered again in the future. \nPreference change after a game At a\nsimple level, post-game activity can consist in setting, or altering,\nthe second input parameter of rational choice beside belief: the\nplayers’ preferences. Several folklore results relate to this\noption. For instance, when playing against a given strategy of another\nplayer with known preferences, any strategy can be rationalized by\nchoosing suitable preferences among outcomes. Liu\n(2011) discusses several preference based\nrationalization algorithms using dynamic logics of preference\nchange. \nPreference change can also occur during a game. Players may receive\nnew information about the game’s end states and their\nproperties. They may also follow a command or a suggestion from an\nauthority, establishing a preference or reversing an earlier one.\nRelatedly, players may change their external goals pursued in the\ngame, or they may adjust their preferences for more internal reasons,\nas in the phenomenon of ‘sour grapes’ (Elster\n1983). \nThe main focus of this section is the local dynamics of what happens\nbefore, during and after a single game. There is also a broader\nperspective of time, in which all these activities are embedded in an\nextended temporal universe, large enough to include all possible\ntrajectories of the game, finite or just as well infinite. In\n evolutionary game theory,\n in particular, infinite games typically arise from iterated play of\nfinite games, with Lewis’\nsignaling games (2002) as prominent\nexample in philosophy. \nAssuming an extended infinite temporal perspective raises additional\nquestions about players’ strategic foresight and adaptation\n(Christoff 2016). Various long-term\nperspectives differ drastically in this respect, ranging from the\nminimal rationality assumptions typical of evolutionary game theory to\nhigh reasoning complexities of agents anticipating the long term\neffects of their choices. \nTemporal logics While infinite game\nforms were briefly alluded to in\n Section 2.10,\n infinite play focuses on agency over time. A host of temporal logics\nfor this end have been put forward, including interpreted systems\n(Fagin, Halpern et al. 1995),\nepistemic-temporal logic (Parikh &\nRamanujam 2003), STIT (Belnap &\nPerloff 1988; Horty & Belnap 1995), ATL (Alur,\nHenzinger, & Kupferman 2002; van der Hoek\n& Wooldridge 2003), and others. Many of these systems\ncombine multiple modalities. Consequentially, their complexity can be\nvery high (undecidable, non-axiomatizable, or even non-arithmetical),\nas Halpern & Vardi (1986) show in a\npioneering study for the case of combining time and knowledge.\nSurveying this area is beyond the scope of this entry, cf. the entry\non\n temporal logics.\n A unifying view of connections between the various paradigms is\npresented in van Benthem and Pacuit\n(2006). \nFigure 23.\n ⓘ \nJust as with finite games, players’ preferences must be\nspecified for studying equilibria in potentially infinite games. In\nlack of outcome nodes or final moments to attach preferences to, these\nare naturally thought of in terms of players’ goals, expressed\nas properties the game’s histories should satisfy. Such goals\ncan be local propositional facts true at some particular moment. But\ngoals can also concern global properties of histories such as avoiding\nor reaching the same position some specified number of times, or more\nabstractly, achieving safety or fairness in some appropriate sense.\nAll such properties can be specified in temporal logics. For the case\nof Linear Temporal Logic (LTL), the ‘Boolean\ngames’ of Gutierrez, Harrenstein, and\nWooldridge (2015) have developed the temporal goal based\napproach in depth. Notably, this framework validates a logical version\nof the ‘folk theorem’ for iterated games, cf. Osborne\n& Rubinstein (1994): Under natural\nconditions on goals, iterated games can have novel equilibria not\nsupervenient on the base game’s Nash equilibria. Further\nsignificant uses of temporal logics connect game theory with belief\nrevision theory (Battigalli & Bonanno 1999;\nPerea 2012; Stalnaker 1998). \nEvolutionary game theory and dynamical\nsystems A prominent application of iterated games\noccurs in evolutionary game theory (Maynard\nSmith 1982; Hofbauer & Sigmund 1998; Gintis 2000), a\nframework that has many applications in biology, formal sociology, but\nalso linguistics and philosophy (Lewis 2002;\nSkyrms 2010; Alexander 2007; Clark 2012). \nLittle work has been done so far on the logical analysis of\nevolutionary games along the dimensions of this entry. In fact, there\nare striking conceptual differences between evolutionary games and the\nstyle of analysis pursued here that might be dubbed ‘high\nrationality’-oriented. Rather than incorporating intentional,\nstrategic actors, evolutionary games work by temporal progression of a\ndynamical system which is driven by individuals’ fitness values\nderived from game-like encounters with others. Within such systems,\nbehavior is not driven by belief updates or complex strategic\nconsiderations. Rather, players typically display ‘low\nrationality, following certain hard-wired strategies. Much of the\nevolutionary system’s dynamics is then driven by changes in the\npopulation’s composition of strategy types. \nEven so, evolutionary game theory does invite connections to logic.\nThe evolutionary success of simple strategies like Tit-for-Tat (Axelrod\n& Hamilton 1981) raises the\nquestion of just when complex logically based high-rationality\nstrategies can be replaced by equally efficient alternatives simple\nenough to be played by automata or similar models of bounded agents,\n(Grädel, Thomas, & Wilke 2002).\nAt a higher level of abstraction, there also is an incipient line of\nresearch into the connection between logic and dynamical systems, a\nstandard tool for analyzing evolutionary games. This strand includes a\nbimodal topological logic of time (Kremer &\nMints 2007), fixed-point logics of oscillation (van\nBenthem 2015), and a systematic linkage\nbetween dynamic-epistemic update logics and dynamical systems over\nmetric spaces (Klein & Rendsvig\n2017). At a much concreter level, one important species of\nevolutionary games are signaling games (Lewis\n2002; Cho & Kreps 1987; Osborne & Rubinstein 1994; Skyrms\n2010: van Rooy 2004), where agents send and receive signals\nabout the state of the world. Signaling games match up naturally with\nthe earlier dynamics logic of information flow during play. \nTopics discussed in this section are less standard in the literature\nthan those of the sections before. In an orthodox reading, various of\nthe aspects addressed would not be considered part of game theory\nproper. The extended agenda followed here has been embraced by van\nBenthem, Pacuit, and Roy (2011) as a\nlarger program for logic, going under the heading ‘Theory of\nPlay’. The underlying line of reasoning is that games do not\nfully determine their outcomes, as they allow for various styles of\nplay. Hence, it might be the process of play itself, including\nplayers’ types and how they change over time, that might the\nbest focus for understanding interaction, rather than mere games or\ngame forms alone. Similar lines of argument can be found in the\nfoundations of computation where it has been proposed that the\nessential topic of study should be behavior (Abramsky\n2008). \nBelief revision and learning theory\nBelief revision in repeated games bears natural resemblance to limit\nlearning of\n formal learning theory\n (Kelly 1996). Baltag,\nGierasimczuk, and Smets (2011) analyze\nlearning in terms of initial epistemic-doxastic models over which\nfinite histories of signals trigger the learner to revise beliefs,\nrepresented as changes in epistemic accessibility or plausibility\norder. It turns out that both iterated public announcement and\niterated radical upgrade as discussed above are universal learning\nmethods, though only the latter maintains this property in the\npresence of (finitely many) errors in the input stream. \nGoal dynamics and intentions While\npreferences and goals have so far been assumed fixed and universally\nknown, this is by no means necessary. van\nOtterloo (2005) presents a dynamic logic of strategic powers,\nwhere information about players’ intentions and preferences can\nbe announced during play. Roy (2008)\nuses announcements of intentions to obtain simplified solution\nprocedures for strategic games. More concrete scenarios of extraneous\ninformation flow are found in Parikh,\nTaşdemı̇r, and Witzel (2013), where agents\nmanipulate the knowledge of others during play. \nGame change In many real life scenarios,\nplayers do not know the full game tree they are playing. Even if they\ndid, it might change during play. Or, at least, players may attempt to\nchange the game. A concrete example is provided by the game tree in\n Section 4.1.1.\n There, the inefficient Backward induction outcome \\((1, 0)\\) could be\navoided by E promising not to go left. When made binding (for\ninstance through imposing a fine) this announcement eliminates\nhistories and, consequentially, a new backward Induction outcome of\n\\((2,2)\\) results. Hence, both players can be made better off by\nrestricting the freedom of one. Game theory has sophisticated analyses\nof such scenarios, including an analysis of ‘cheap talk’\n(Osborne & Rubinstein 1994), asking\nwhen such announcements are credible. On the logical side, this\nsuggests an analysis of signaling games (van\nRooy 2004). We are not aware of any logical work done in this\ndirection. \nReal games The discrepancy between\nspecification of a game and the realities of play is especially\nstriking in real game play, either of the ‘natural kind’\nin common parlor games (van Ditmarsch &\nKooi 2015), or of the artificial kind found in the laboratory\nexperiments of experimental game theory (Camerer\n2003). Little work has been done by\nlogicians in this realm, though there is a broad tradition of\ncomputational analysis of games (Schaeffer\n& van der Herik 2002; Kurzen 2011). Any adequate\nlogical analysis would clearly need to incorporate the considerations\non bounded agency discussed in\n Section 3. \nMathematical foundations Logic of play\nas discussed here raises issues of how to interfaces local with global\ndynamics. This shows in particular with logical limit behavior, where\nobservations and assertions are made repeatedly. Limit models of\npublic announcement, as described earlier, can be\n‘self-fulfilling’ or ’self-refuting’. In the\nfirst case, the property asserted becomes common knowledge among all\nagents, whereas in the second it eventually becomes false at the\nactual world. With soft update on plausibility models, a third option\narises, namely, infinite oscillation, or even divergence (Baltag\n& Smets 2009). To date, there is\nno general logical theory of these phenomena, but see van Benthem (2011) on the use of\nfixed-point logics for limit models, Miller and\nMoss (2005) on the high complexity of public announcement logic\nwith finitely iterated announcements, and Klein\nand Rendsvig (2017) on limit behavior of product updates. \nThe topic of limit behavior also raises the issue of how local dynamic\nlogics of agency relate to the global temporal logics discussed in\n Section 4.2.4.\n Towards clarifying the connection, van\nBenthem, Gerbrandy, Hoshi, and Pacuit (2009), show how\ndynamic-epistemic logics can be seen as decidable fragments of more\nexpressive temporal logics. Baltag, Smets, and\nZvesper (2009) discuss the related theme of how dynamic\nrepresentations can decrease complexity by shifting information from\nthe temporal universe to dynamic events. \nProbabilities are central to game theory, where they serve two\nprominent roles. First, they structure players’ uncertainty\nabout various aspects of the game, including the state of nature, the\ntype of opponent faced, and past, present, and future moves of other\nplayers. Second, ever since the origins of Game Theory (von\nNeumann & Morgenstern 1944),\nprobabilistic randomization has served to expand the agents’\nspace of possible actions. While the interpretation of such mixed\nstrategies has been the subject of extensive debate (Sugden\n1991), it is uncontroversial that\nrandomized moves add significant depth to the analysis of games. In\nfact, the concept of mixed strategies is vital for a number of seminal\nresults in classic game theory including the existence of Nash\nequilibria in finite games of imperfect information. \nProbability and its logic is a major topic in both mathematics and\nphilosophy, as discussed in the entries on\n interpretations of probability,\n and\n logic and probability.\n The current section merely outlines a few key connections between\nprobability and the logical analysis of games. The following\npresentation assumes all state spaces to be finite, ignoring\nimportant technical and conceptual issues around the transition from\nfinite to infinite state spaces. \nProbabilistic methods are widely employed to represent beliefs of\nagents within and outside of games, witness\n Bayesian epistemology.\n Typically, a probabilistic belief model consists of two components: a\nspace of possible states that the agent’s beliefs range over,\nplus a quantitative probability function denoting how probable the\nagent judges different propositions or states to be. In qualitative\nlogical models, on the other hand, agentive belief is represented in\nvarying degree of detail. The coarsest approach only distinguishes\nstates the agent considers possible from those she rules out. This is the\nperspective of standard epistemic-doxastic logics, such as multi-agent\nS5 and KD45 discussed in\n Section 3.6.\n More fine-grained perspectives are employed in the plausibility\nmodels of Boutilier (1994) and Baltag\nand Smets (2008), where the range of\nepistemic options is structured further by plausibility orderings\nencoding which options agents take to be less or more likely. See also\nSections\n 3.6.4\n and\n 4.2. \nBoth probabilistic and plausibilistic perspectives can express that\nsome alternative is more likely than another. However, there are also\nconceptual differences between the two frameworks. Probabilistic\nmodels can aggregate, allowing their logic to express, for instance,\nwhether many low-probability events combined can outweigh even the\nhighest-probability worlds. Aggregated probabilities play a key\nrole, for instance, in calculations of expected utility. Yet no such\nthing can be expressed in plausibility semantics. For another striking\ndifference, plausibility models lead to a notion of belief that is\nclosed under conjunction. This conjunction closure typically fails for\nprobabilistic accounts of belief. See however Leitgeb\n(2017) for a sophisticated bridge\nbetween both types of modeling.  \nOn a received view, logical and probabilistic frameworks emphasize\ndifferent aspects of belief. Logic emphasizes coherence properties\nbetween the propositions believed, such as closure under logical\nimplications or conjunction. Probabilistic reasoning, on the other\nhand, stresses graded information and attitudes towards uncertain\nevents such as lotteries. Even so, there is a variety of approaches\nattempting to unify the two types of reasoning by constructing bridges\nbetween the frameworks. \nFrom qualitative to quantitative\nprobability Early attempts in this direction go back\nto Finetti (1970 [1974]), striving for a\npurely qualitative axiomatization of probability theory. A step\nfurther towards logical reasoning are various theories of qualitative\nprobability (Kyburg 1994), often based\non the assumption that classical quantitative notions of probability\nare too demanding for real-life agents. In this line of research\nagents need only reason with partial, comparative probability\nassessments, rather than having fully specified probabilities for all\nevents. Logical frameworks for qualitative probability include Segerberg\n(1971), Fagin, Halpern, and Megiddo\n(1990), and Delgrande and Renne\n(2015). While differing in detail, all logics in this line have\nin common that they allow for expressions of the form\n\\(\\varphi\\preceq\\psi\\), indicating that \\(\\psi\\) is judged at least as\nprobable at \\(\\varphi\\). Recent frameworks add various additional\nrefinements to this language. Similarly, Heifetz\nand Mongin (2001) expand the axiomatic\nanalysis of probabilistic beliefs to higher order reasoning, working\non probabilistic type space akin to those introduced in\n Section 3.7. \nYet, the concept of qualitative probability is sometimes considered\nflawed: a complete set of probabilistic-logical principles\nguaranteeing that every complete description in the logical language\ncorresponds to a unique probability measure turns out to require a\ncomplex calculus, involving an opaque infinite rule (Kraft,\nPratt, & Seidenberg 1959; Scott\n1964). A new angle has been proposed in Harrison-Trainor,\nHolliday, and Icard (2016)\nthrough axiomatizing a low-complexity qualitative probabilistic logic\nthat emerges from relaxing the above unique correspondence requirement\nto merely requiring compatibility with all probability measures of a\ncertain family. \nHowever, none of the frameworks described here are specific for games.\nIn fact, it remains to be seen whether qualitative probabilistic\nlogics, old or recent, can be used for a qualitative analysis of\ngame-theoretic solution concepts. \nFrom quantitative to qualitative\nprobability While the preceding line of research aims\nat recovering quantitative probability from qualitative notions, a\nconverse project shows how ubiquitous qualitative patterns might arise\nnaturally within a quantitative probabilistic setting. Building on\nwhat is sometimes dubbed the Lockean Thesis, threshold\napproaches connect probability to logic by stipulating that some\n\\(\\varphi\\) is to be believed simpliciter if the probability of\n\\(\\varphi\\) is above some appropriate numerical threshold t.\nFor most choices of threshold t, such translations do not\nsquare well with standard logical desiderata, as beliefs will in\ngeneral not be closed under conjunction. However, in recent work Leitgeb\n(2017) and Lin\nand Kelly (2012) have identified conditions under which one can\ndo better. Building on ideas of Skyrms\n(1977), Leitgeb identifies\nstrong, context-dependent ‘robustness conditions’ on\nthresholds that guarantee the defined belief operator to satisfy the\nKD45 axioms after all. Lin and Kelly, on\nthe other hand, work with non-uniform thresholds for transitioning\nbetween logical and probabilistic notions of belief, allowing to\nderive coherence between different forms of belief dynamics on the two\nsides. For a recent study of the mathematical foundations and limits\nof these approaches, as well as the conditional logics they generate\nsee Mierzewski (2018). \nIn the dynamic perspective of game play, every move constitutes a new\npiece of information agents have to take into account. Besides,\nplayers may also change their beliefs about the game upon\ndeliberation, through communication or any other signals they receive,\nbe they reliable or not ( cf.\n Section 4).\n All such dynamic events raise the question of how new information is\nto be incorporated into the agents’ beliefs and when\nprobabilistic updates have corresponding logical revisions or vice\nversa. \nIf the new information is of the hard type, accepted as irrevocably\ntrue by all agents, the probabilistic counterpart of logical public\nannouncements is Bayesian conditioning. Both notions track each other\nat a semantic level, meaning that their outputs amount to the same\nthing. Computing beliefs after a public announcement means recomputing\nin the submodel consisting of all states where the information\nreceived was true. This is exactly the same mechanism as for\nrecalculating probabilities in Bayesian update. Moreover, for\nreasoning about updates, both approaches require conditional notions:\nconditional belief and conditional probability respectively. The\nquantitative notion of conditional belief relates to the logical\nnotion of conditional belief \\(B(\\varphi|\\psi)\\), with the slight\ncaveat that the latter also allows for epistemic or doxastic operators\ninside either argument. More refined logical notions of conditional\nbelief arise in the earlier-mentioned plausibility semantics of\n Section 4.1.2,\n (Baltag & Smets 2008). \nGiven the co-existence of qualitative and quantitative perspectives,\nit makes sense to ask whether one can track the other. In a\nstatic sense, tracking asks whether different notions of belief can be\ntranslated into each other by omitting or transforming some of the\nsemantic details involved. A dynamic interpretation expands on this by\nasking whether updating, either in the hard or soft varieties of\n Section 4,\n is compatible with these translations in a commutative diagram:\nInformation update in a new perspective after translation should yield\nsame result as first performing a matching update in the old\nperspective and then translating (van Benthem\n2016). In games, the topic of tracking may refer not just to\ninformation update, but also to solution concepts or moves in game\nplay described at the various levels considered in\n Section 2. \nThe existence of tracking maps depends on the exact type of update\nconsidered. By now there is a wide variety of updating policies on\nplausibility models (van Benthem & Smets\n2015), not all of which have obvious probabilistic\ncounterparts. Likewise, for well-known varieties of probabilistic\nupdate, such as Jeffrey update, where the probability of selected\npropositions can be reset at will, plausibility counterparts are not\neasy to find, though the attempt of van Benthem,\nGerbrandy, and Kooi (2009) modifies dynamic-epistemic logic to\nallow for Jeffrey update and other generalized probabilistic\npolicies. \nVirtually all aspects of game theory provide contacts between logical\nand probabilistic perspectives. Clearly, this is true for the\ndifferent representations of knowledge, beliefs and their dynamics\njust discussed. Other contacts occur at the level of game forms, cf.\n Section 2,\n where probabilities enrich the space of strategies. The resulting mixed moves require players to expand their\npreferences to mixed outcomes, cf.\n Section 3.\n Finally, at the level of reasoning about game play, cf.\n Section 4,\n probabilistic beliefs play a role in solution techniques such as\ndominance or expected utility based reasoning. \nAvailable actions and mixed strategies\nProbabilistic mixtures of pure strategies are prominent in game\ntheory, as they can secure outcomes and payoffs that no pure strategy\nalone could guarantee. \nExample Matching Pennies. \nConsider the well-known game of matching pennies in matrix form: \nFor Ann, a mixed strategy of playing a exactly half of the time\nguarantees an expected outcome of 0, no matter what Bob does. No pure\nstrategy could have achieved this. \nFrom a logical point of view, mixed strategies can be conceptualized as new\nprimitive actions in the earlier logics of games ( cf.\n Section 2).\n Yet, this treatment immediately renders the set of available actions\ninfinite. A cautiously refined logical language, extending logical\napproaches to qualitative probability, can allow for expressions such\nas an agent playing action a with probability at least\nq, (Delgrande and Renne\n2015). \nA more challenging general question is how to relate classic\nprobabilistic approaches with their fixed-point results and ensuing\nequilibrium existence theorems, with the logical fixed-point\napproaches mentioned at several places in this entry. The latter\noperate with step-by-step ordinal iterations, as opposed to the\ngradual, approximative procedures that underlie the Brouwer or\nKakutani fixed-point theorems relevant for classical game theory. A\nrelated question is just how much logic is needed to reproduce\nprobabilistic existence theorems within a qualitative framework. \nAdding players’ preferences Once\npreferences are added, mixed strategies trigger additional\nintricacies. A strategy profile where some players pursue mixed\nstrategies does not produce a unique outcome, but a weighted\ncombination of outcomes. Thus, permitting mixed strategies requires\nlifting preference relations to probabilistic mixtures of outcomes or\nstrategy profiles. Incorporating such mixtures may implicitly depart\nfrom the standard, purely qualitative perspective on outcomes (Ramsey\n1931; Savage 1954). \nExample Extended preference\ncomparison. \nThe following two games are equivalent in terms of qualitative (i.e.,\nordinal) preferences between outcomes for both players. However, they\ndiffer in preferences between mixed outcomes, with  \nholding in the game to the left, but not in that to the right. \nGoing this way poses some logical challenges. For example, consider a\npreference relation over probabilistic mixtures of outcomes, where\n\\(m^t(a,b)\\) stands for obtaining a with a probability of\nt, and b otherwise. This setting is in the scope of\nvon Neumann and Morgenstern’s\n1944 well-known ‘continuity\naxiom’ that is characterized by an implicit infinite\ndisjunction:  \nThis seems well beyond the expressive power of standard probabilistic\nlogics. \nSolution concepts and game play\nProbabilization also impact the process of game play and its reasoning\ndynamics, for instance by changing the earlier-mentioned calculus of\nweak and strong dominance\n (Section 3.4).\n Consider the following game, cf. de Bruin\n(2005): \nNone of A’s strategies are dominated in terms of pure\nstrategies. However, in terms of expected outcomes, c is\ndominated by an equal mixture of a and b. Thus, solution\nprocedures analyzed earlier such as iterated removal of weakly or\nstrongly dominated strategies may provide different and incompatible\noutcomes, depending on whether mixed strategies are considered or not.\nNo satisfactory logical analysis of the earlier kind seems to exist\nfor this setting. \nFurther challenges to the interplay of logic and probabilistic\nreasoning abound. By way of conclusion, here is a dimension that seems\nhard to capture in purely qualitative logical terms. A characteristic\nfeature of game- and decision-theoretic reasoning is that beliefs and\npreferences are entangled in various ways (Liu\n2011). For instance, the crucial notion\nof expected utility entangles probability, representing beliefs, with\nutilities, standing for preferences. Players faced with probabilistic\nuncertainty about the opponent’s present and future actions are\noften advised to maximize expected utility (von\nNeumann & Morgenstern 1944; Savage 1954). Hence, even if\none has found qualitative counterparts for probabilistic belief and\ncardinal utility separately, entanglement poses the additional\ndifficulty of merging these two qualitative analyses in a way that\nmatches what the quantitative side achieves easily by forming some\narithmetical combination of both components. \nThe main topic of this entry is a logical approach to game theory,\nbringing classical notions and methods from logic to bear upon games.\nThis project is sometimes called ‘logic of games’. There\nalso is a converse direction of ‘logic as games’, where\ngame theoretic concepts are employed to elucidate basic notions of\nlogic. This section presents a brief discussion on this direction as a\nnatural counterpoint to the main lines of the entry. For an extensive\nsurvey see the entries on\n logic and games\n and\n games, abstraction and completeness. \nMany notions in logic have been analyzed in game-theoretic terms \nEvaluation games There are well-known\ntwo-player games for evaluating a first-order formula \\(\\varphi\\)\nwithin a given logical model. These games are played between Verifier\nand Falsifier, who can both test atomic assertions, and specify the\nvalue of variables from a given domain (Hintikka\n1973). The schedule of the game is\ndetermined from the syntactic structure of the formula \\(\\varphi\\).\nDisjunctions and existential quantifiers require choices of the\nVerifier, conjunctions and universal quantifiers of the Falsifier,\nand negations trigger a role switch between the two players. The\nresult is the following match between winning strategies and the\nordinary semantic notion of truth: \nFormula \\(\\varphi\\) is true in model M under assignment\ns iff the Verifier has a winning strategy in the associated\ngame \\(game(M, s, \\varphi)\\).  \nCorrespondingly, Falsifier has a winning strategy if the formula\n\\(\\varphi\\) is false in the model. Evaluation games turn out to be an\nextremely flexible tool. By suitably modulating rules and winning\nconventions, adequate evaluation games can be found for most logical\nsystems. Doing so, however, can be a highly non-trivial task, as\nwitnessed by the intricate infinite ‘parity games’\ncorresponding to fixed-point logics such as the modal μ-calculus\n(Venema 2008). For the present purpose,\nit should be noted that this style of analysis ties the very logical\noperations, conjunctions, disjunctions, modal operators, to natural\nmoves in a game. Similarly, the notion of truth is linked to the\nfundamental game-theoretic notion of a strategy in an extensive form\ngame (cf.\n Section 2):\n a complex, structured object which may here be understood as a reason\nor an explanation for the truth or falsity of the formula. \nThe links between both perspectives are so close, that valid\nprinciples of logic come to express game-theoretic facts. For\ninstance, after a little analysis, the law of excluded middle implies\nthat always either Verifier or Falsifier has a winning strategy, cf. Section 2.4. In\nother words, logical evaluation games for classical logic are\ndetermined in the game-theoretic sense. In fact, This property extends\nto most games for non-classical logics. \nFurther logic games Logic games exist\nfor many other purposes. Ehrenfeucht-Fraïssé games serve\nmodel comparison (Ehrenfeucht 1961; Ebbinghaus\n& Flum 1995), Lorenzen games perform proof analysis (Kamlah\n1973 [1984]) and tableau games execute\nmodel construction (Hodges 1985). In\neach case, strategies in the game match important logical notions. In\nLorenzen dialogue games, for instance, winning strategies for the\nProponent of a claim correspond to proofs of that claim from premises\ngranted by the Opponent, whereas winning strategies for the Opponent\nare constructions of counter-models. Thus, proofs and models, two\nquite distinct notions in logic, co-exist within a single game. \nThere exists an alternative, game-theoretic way of interpreting these\nconnective results. Suppose the game under study is fixed, and\nassociated with some sort of ‘game board’ representing\nmajor features of the game’s general state (think of Chess,\nthough more abstract game boards may occur). Then the above\nequivalences suggest that winning strategies, i.e., a typical\ngame-theoretic notion defined in terms of the complete extensive game\ntree, is equivalent to a simpler ‘invariant’ that can be\ndefined entirely in terms of some game board associated with the\ntree’s nodes. Identifying useful such invariants is a well-known\nart in the analysis of concrete games. In terms of a main theme of\nthis entry, invariants can live at different levels of representation\nassociated with a given class of games. \nGame semantics One can view logic games\nas mere didactic devices analyzing logical notions that were already\nwell-understood. Or, in other terms, as offering a concrete way of\nteaching logic that draws on game-theoretic intuitions. However, logic\ngames have more to offer. First of all, new logics are suggested by\npursuing natural variations in winning conventions, moves, or\nscheduling within existing logic games. Moreover, viewing logical\noperations as game constructors suggests a new, refined view on\nlogical constants. Conjunction, for instance, now splits naturally\ninto a sequential and a parallel version. Similar examples of\nparallelism also exist in logics of computation. Moreover, associating\nquantifiers with object picking, as in evaluation games, turns\nquantifiers into special types of atomic games that connect to the\nfollowing formula by an abstract operation of game composition. The\ngeneral logic of this abstract composition operation combined with\npropositional operations of choice and switch has been shown\ndecidable, providing a new decidable core logic inside first-order\nlogic whose existence had not been suspected (van\nBenthem 2014). Games, hence, can offer a\nfresh perspective on existing logical systems. \nA major source of independent, game-theoretic perspectives on logic is\nthe game semantics of computational logics. In this setting, the\nstatus of logic games may change. Rather than being a mere pedagogical\nor exploratory device, to some, these games are considered the true\nmeaning of logical constants. \nThe distinction between game logics and logic games is not always\nsharp. Recent literature has seen a number of games whose design is\nconnected to logic, yet they are not meant to analyze logical notions\nper se. \nExample Sabotage Games. \nSabotage games were proposed to analyze algorithmic tasks in adverse\ncircumstances. Consider the below network between some European\ncities: \nFigure 24.\n ⓘ \nIt is easy to travel either way between Amsterdam and the German town\nof Saarbruecken. Now, let a malevolent Demon start canceling\nconnections in the network. At every stage, let the Demon take out one\nlink, while the Traveler can afterwards follow one of the remaining\nlinks. This turns a one-agent planning problem into a two-player\nsabotage game. Zermelo-style reasoning shows that, from Saarbruecken,\na German Traveler still has a winning strategy, while in Amsterdam,\nthe Demon has the winning strategy against the Dutch Traveler, by\nfirst cutting a link close to Saarbruecken. The symmetry of the\noriginal search problem is broken. \nThe sabotage game has been applied to a variety of scenarios,\nincluding learning (Gierasimczuk, Kurzen, &\nVelázquez-Quesada 2009), and communication networks\n(Aucher, van Benthem, & Grossi\n2018). On finite graphs, the game is clearly determined, with\nthe computational complexity of identifying who has a winning strategy\nbeing Pspace-complete (Löding & Rohde\n2003). \nThe existence of this winning strategy can be expressed by a\nfirst-order formula. More specifically, winning conditions can be\ndefined in a bimodal logic that combines a standard modality for\ntravel steps with a new modality for one-step arrow deletion,\ninterpreted in models \\(M = (W, R, V)\\): \n\\(M, s \\vDash [{-}]\\varphi\\quad\\)\nFor each edge \\((u, v)\\) in \\(R:\\, \\, (W, R {-} \\{(u. v)\\}, V) \\vDash\n\\varphi\\) \nThis logic fits the sabotage game closely. On top, it is a natural\nfragment of the first-order language of graphs. Surprisingly, this\nlogic is undecidable (Löding & Rohde\n2003), making it one of the simplest examples of an undecidable\nmodal logic over arbitrary models. \nFurther graph games in a similar spirit exist, including the poison\ngame of Duchet and Meyniel (1993), where\nthe Demon poisons nodes, rather than deleting edges. Extensive studies\nof modal logics for changing graphs, and μ-calculi for defining\ngeneric solutions to graph games are given in Areces,\nFigueira et al. (2011); Areces, Fervari, and\nHoffmann (2015); and Aucher, van Benthem, and Grossi (2018). A\nclassification of graph games including the effects of complex goal\nformulas and imperfect information is found in van\nBenthem and Liu (2019). \nOne perspective on such logics for reasoning about model change is the\nsemantic games approach of\n Section 6.1.\n In standard evaluation games, the initial model does not change.\nModalities for model change, however, require a process of formula\nevaluation where the model of evaluation changes as, say, witnesses\nfor quantifiers are not replaced (unlike in standard semantics for\nfirst-order logic), or moves change facts by causing damage to\naccessibility relations. In other contexts, similar modalities are\njustified by physical measurements that change the phenomenon under\ninvestigation, (Hintikka 2002; Renardel 2001;\nÅgotnes and Wáng 2017). Such generalized form of\nsemantics are of independent logical interest. \nExample Knowledge Games. \nNew logical games also arise naturally within the dynamics of\ninformation, knowledge or belief as triggered by the process of game\nplay (cf.\n Section 4).\n In particular, information update suggests conversation games between\nparticipants with similar or different goals. These games may be\ncooperative, with players aiming to pool their information, thereby\nturning distributed knowledge into common knowledge (Meyer\n& van der Hoek 1995). But they can\nalso be competitive, say, when players strive to be the first to know\nwhether some relevant proposition holds. Mixtures between both modes\nalso occur, for instance with some players aiming to communicate a\nfact that outsiders should not learn about (van\nDitmarsch 2003). \nA concrete example are the ‘announcement games’ of Ågotnes\nand van Ditmarsch (2011).\nPlayers speak simultaneously and only once, while pursuing goal that\nare specified as epistemic formulas. Speaking is modeled by public\nannouncement, and players preferences are binary. They prefer final\nmodels where their goal formula holds over those where it is\nfalse. \nThese games are conducted under imperfect information, as players may\nnot know the true state of their epistemic model. Accordingly, the\nrelevant strategies need to be uniform. Players must say the same\nthing in all states they cannot distinguish. In general, then, many\nsolution concepts produce mixed strategy outcomes. In fact, it can be\nshown that there exists simple announcement games without any unique\nequilibrium in pure strategies. However, there is a relevant role for\nlogic to play. Suppose that the goal statements are all\n‘universal’, i.e., constructed from literals by applying\nonly conjunction, disjunction, knowledge operators, and dynamic\nmodalities with universal announcements. Truth of such formulas is\npreserved when transitioning from a model to a submodel. Consequently,\nepistemic uncertainty becomes less harmful and knowledge games with\nuniversal goals have equilibria in pure strategies. Recently,\nknowledge games have been expanded further to include both questions\nand answers as separate actions of issue change and information change\n(Ågotnes, van Benthem et al.\n2012). \nExample Boolean games. \nA third example of game design in between game logics and logic games\nare the Boolean games of Harrenstein et al.\n(2001) and Gutierrez, Harrenstein, and\nWooldridge (2015) that have been mentioned several times\nalready. Each player is handed control over a subset of the\npropositional variables, and can pick truth values for these at will.\nUsing goals specified in temporal logics, these games can model a\nlarge number of relevant scenarios of agency. By now, a growing\nbody of work addresses various aspects of Boolean games including\ntheir computational characteristics (both single-shot and iterated),\ntheir game-theoretic properties and equilibria (Gutierrez,\nHarrenstein, & Wooldridge\n2015), and their connections with games played on social\nnetworks (Seligman & Thompson 2015).\nFurther discussion can be found in the entry on\n coalitional powers. \nBack and forth between game logics and logic\ngames The topic of this section suggests cycles\nbetween the two perspectives on logic and games. Given a logical\nsystem, one can design logical games for it, which can then again be\nstudied using some appropriate game logic. Conversely, given a game,\none can introduce a logic for describing it, and then introduce\nevaluation games for that logic, and so on. Sometimes these cycles\nreach fixed-points, where, say, the evaluation game for a formula\ndescribing some game is isomorphic to that game itself. But sometimes,\nthe cycling continues. For discussion, see Rebuschi\n(2006) and van Benthem (2014). \nImperfect information Logic games\nnaturally support imperfect information, where players do not have\ncomplete access to what their opponents do. Epistemic variations can\nhave far-reaching consequences for the corresponding logics. A\nparticularly prominent framework among this lines is the\n independence friendly logic\n of Hintikka and Sandu (1989), see also\nHintikka and Sandu (1997) and Mann, Sandu, and\nSevenster (2011). \nArgumentation games and graph games\nAnother strand of game analysis with a connection to logic is the\nstudy of argumentation networks (Dung 1995;\nCaminada & Gabbay 2009), with uses in AI and philosophy\n(Grossi 2013; Shi 2018) \nComputational logic The material in this\nsection is closely connected to games in computational logic, which\nserve to analyze expressive power of languages. For relevant results\nand connections with automata theory, see Grädel,\nThomas, and Wilke (2002) and\nvan Benthem (2014). \nGaming and mechanism design Game design\nis a well-known aspect in the area of gaming (Rouse\n2000). Likewise, mechanism design is an\nestablished topic in game theory (Nisan &\nRonen 2001; Osborne & Rubinstein 1994). For connections\nbetween between logic, game design and planning, see (Löwe,\nPacuit, & Witzel 2011; Löwe\n2008). \nThis entry presents an overview of current work at the interface of\nlogic and games. The topics surveyed fall in a number of strands\nincluding current logical analysis of games in the broadest sense,\ncontacts between logic and classic game theory, connections with\nprobability and with computation, and, lastly, the game theoretic\ncontent of logic itself. All this produced a perhaps bewildering\nvariety of logical systems. Yet, this entry emphasized the coherence\nof different approaches to logical analysis, some ‘zooming\nin’ on particular aspects in detail, others ‘zooming\nout’, thereby focusing on general patterns. What has hopefully\nbecome clear in this way is that the various topics span a highly\ninterconnected field. For further details, see the various\ngame-related entries in this Encyclopedia and the literature\ncited. \nIn terms of further desiderata, the coarse grained perspective of\nlogical modeling may help discover new abstract, general patterns in\nsocial behavior beyond the details of games and game theory. A\nconcrete example might be a description of general skills and insights\nthat players acquire by playing a given type of games. A more\nfoundational example would be a formalization of the insight that all\nconcrete social interaction rest on underlying general notions of\n‘dependence’ with their own high-level logic, cf. the\nsemantic dependence logics of Väänänen\n(2007) and Baltag (2016). For an\nalternative proof-theoretic approach in this style, relying on the\ngeneral postulates for competitive games of Johansen\n(1982), see Hu\nand Kaneko (2014). \nThe interface area of logic and games still is in statu\nnascendi. Correspondingly, there are obvious gaps and desiderata\non the logic side, which are reflected in the material in this\nentry. \nIn particular, one fundamental theme are syntactic perspectives on\ngame-theoretic reasoning. Samples of a proof-theoretic style of\nanalysis for play can be found in de Bruin\n(2005). More concretely, Zvesper\n(2010) analyzes classical results in epistemic game theory,\n(cf. Tan & Werlang 1988; Aumann\n1999), in terms of abstract modalities for belief and\noptimality, showing how a few simple proof rules from modal\nμ-calculus can capture the essence of famous results in epistemic\ngame theory. Proof-theoretic aspects of logic have so far been \novershadowed by semantic analyses, although this situation is changing\nslowly (Artemov 2014; Kaneko 2002; Kaneko &\nSuzuki 2003). Model-based reasoning provides abstract semantic\nperspectives on games that can aid conceptual clarification, and the\ndiscovery of general laws. But it might turn out to be proof theory\nthat governs the concrete reasoning used in the semantics, and that\nmay be able to guide the context of justification in establishing\ngeneral facts about games. \nA further contact with logic that has been ignored in this entry is\nthe rich interface between games and descriptive set theory (Woodin\n2010; Kanamori 2003). \nIt should be stressed once more that logic is not the only formal\ndiscipline that throws light on games. Quantitative probability enters\nthe study of games in many ways, both in classical and in evolutionary\ngame theory. The interface of logic and games may well profit from the\nmany old and new contacts between logic and probability (Leitgeb\n2017; Lin & Kelly 2012;\nHarrison-Trainor, Holliday, & Icard 2016). \nAnother link that remained underrepresented in this entry are\ncomputational aspects. The study of games, play and players has\nnatural connections with computation and agency in computer science\nand AI (Grädel, Thomas, & Wilke 2002;\nAbramsky 2008; Halpern 2013; Perea 2012; Brandenburger 2014).\nThe proper perspective on what has been presented here may well turn\nout to be a triangle of interfaces between logic, games, and\ncomputation. \nAs for still broader connections, we have not done justice to all\nlinks between logic, games and philosophy, of which more are found in\nStalnaker (1996, 1999). The same is true\nfor links to linguistics and psychology (Clark\n2012). In this language-oriented connection, one should also\nmention the work of Bjorndahl, Halpern, and\nPass (2017) on the natural language used in specifying games\nand reasoning about them, thus making game analysis more\ndescription-dependent. \nFinally, the main thrust of this entry is theoretical and\nfoundational. However, there also is a more practical aspect to logic\nand games. Logic plays a role in cognitive psychology and experimental\ngame theory, if only to identify testable hypotheses related to Theory\nof Mind or strategic reasoning (Ghosh,\nMeijering, & Verbrugge 2014; Ghosh & Verbrugge 2018; Bicchieri\n1993; Fagin, Halpern et al. 1995). Lastly, some work at the\ninterface of logic and games suggests outreach to the world of actual\nparlor games (van Ditmarsch & Kooi 2015;\nvan Benthem & Liu 2019). \nAll in all, the claim of this entry is a modest one. Logic and games\nform a natural combination, that may reveal interesting things when\npursued explicitly. Even so, too much logic may import too much of a\nformal apparatus, which may end up strangling the games perspective:\nlogical systems are infinite machineries that can easily overwhelm a\nconcrete game of interest. In short, the contact has to be managed\nwith care.","contact.mail":"d.klein@uu.nl","contact.domain":"uu.nl"}]
