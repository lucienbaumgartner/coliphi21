[{"date.published":"2007-02-01","date.changed":"2019-01-25","url":"https://plato.stanford.edu/entries/logic-dynamic/","author1":"Nicolas Troquard","author1.info":"http://www.inf.unibz.it/~ntroquard/","author2.info":"http://www.irit.fr/~Philippe.Balbiani/","entry":"logic-dynamic","body.text":"\n\n\n\nLogics of programs are modal logics arising from the idea of\nassociating with each computer program α of a programming\nlanguage a modality [α].  This idea stems from the line of works\nby Engeler [1967], Hoare [1969], Yanov [1959], and others who\nformulated and studied logical languages in which the properties of\nprogram connectives can be expressed.  The algorithmic logic (AL)\nfirst developed by Salwicki [1970] and the dynamic logic (DL)\nelaborated by Pratt [1976] are proper continuations of these works. We\nwill here concentrate on DL. The numerous papers devoted to DL and its\nvariants as well as its multifarious applications in program\nverification and data structures show that it constitutes a useful\ntool in studying properties of programs. Pratt chose to depict DL on\nwhat one might call the first-order level, and it was his work that\ntriggered Fischer and Ladner [1979] to define the propositional variant\nof DL a couple of years later. This article presents an introduction\nto PDL, the propositional variant of DL.\n\n\nDynamic Logics (DL) are modal logics for representing the states and\nthe events of dynamic systems. The language of DLs is both an\nassertion language able to express properties of computation states,\nand a programming language able to express properties of system\ntransitions between these states. DLs are logics of programs,\nand permit to talk and reason about states of affairs, processes,\nchanges, and results.\n \nPratt’s original dynamic logic of programs was a first-order\nmodal logic. Propositional Dynamic Logic (PDL) is the\npropositional counterpart of it. It was presented as a logic in its\nown right in Fischer and Ladner [1979]. Being propositional, the\nlanguage of PDL makes no use of terms, predicates, or functions. Thus\nin PDL, there are two syntactic categories: propositions and programs.\n \nTo give meaning to statements in PDL, we typically work with an\nabstract semantics in terms of Labeled Transition Systems (LTS). LTSs\ncan be seen as a generalization of Kripke models, where transitions\nbetween worlds, or states, are “labeled” by names of\natomic programs. A valuation indicates for every state what\npropositions are true in it. A transition labeled π from\none state x to a state y—noted\nxR(π)y, or\n(x,y) ∈ R(π)—indicates\nthat starting in x, there is a possible execution of the\nprogram π that finishes in y. If the proposition\nA is true in y, then the formula\n<π>A is true in x: i.e., in the state\nx there is a possible execution of the program α that\nends in a state satisfying A. One recognizes in <π>\na modality reminiscent of the modality of possibility (often noted\n◊) of modal logic. Unsurprisingly, there is also a corresponding\nnotion of necessity (whose modality is often noted □). The\nformula [π]A will be true in the state x if\nA is true in every state reachable from x by a\ntransition labeled π.\n \nThe possible executions of complex programs can be next defined\ncompositionally. For instance, a program “first α, then\nβ” is a complex program, more specifically a\nsequence. A possible execution can be represented in an LTS\nby composing a two-step transition —hence a transition which can\nbe signified by R(α;β)—between the states\nx and x′: there is a possible execution in\nx of the program α that finishes in a state y\nand there is a possible execution in y of the program β\nthat finishes in x′. If the proposition A is\ntrue in x′, then the formula\n<α;β>A will be true in the state\nx. The programs α and β could be complex program\nthemselves. Yet more programs can be expressed with more constructs\nthat we will present in due time.\n \nA program is then seen in an extensional way: it is a binary relation\nbetween pairs of states of an LTS. Precisely, it is the set of pairs\nof the form (x,y) such that the program can be\nexecuted in the state x and can lead to the state\ny. On the other hand, a proposition is a statement about a\nstate; it is either true or false in a state. A proposition can thus\nalso be seen in an extensional way: the set of states of the LTS where\nit is true.\n With the acronym PDL, here we refer precisely to the propositional\ndynamic logic with the following program constructs: sequence,\nnon-deterministic choice, unbounded iteration, and test. We present it\nin section 2, together with some properties and\nfundamental results. In particular, we will address its axiomatization\nand its decidability. The Hoare calculus from Hoare [1969] is a landmark for logics of\nprograms. It concerns the truth of statements of the form\n{A}α{B}—meaning that with the\nprecondition A the program α always has B as a\npost-condition—and is defined axiomatically. It comes from a\nwant of rigorous methods to reason about the properties of programs,\nand thus giving to the activity of programming a certain place in the\nrealm of science. Burstall [1974] saw the analogy between modal logics\nand reasoning about programs, but the actual work on it started with\nPratt [1976] when it was suggested to him by R. Moore, a student of\nhis at the time. PDL comes from Pratt’s interpretation of Hoare’s\ncalculus in the formalism of modal logic. An introduction to the\ngenesis of PDL can be found in Pratt [1980b]. The Hoare-triple\n{A}α{B} is captured by the PDL formula\nA → [α]B meaning literally that if\nA is true, then every successfully terminating execution of\nα will end with B being true. With this connection\nrealized, it is a routine to prove the initial rules of Hoare’s\ncalculus using exclusively the axiomatization of PDL. This is\nsomething we will do in detail in section 3\nwhich concentrates on the reasoning about the correctness of\nstructured programs.\n \nAdditional topics related to PDL include results concerning\ncomparative power of expression, decidability, complexity, and\ncompleteness of a number of interesting variants obtained by extending\nor restricting PDL in various ways.\n\nSince its inception, many variants of PDL have received\nattention. These variants may consider deterministic programs,\nrestricted tests, non-regular programs, programs as automata,\ncomplementation and intersection of programs, converse and infinite\ncomputations, etc. We will present some of them\nin section 4, providing some pointers regarding\ntheir relative expressivity, their axiomatizations, and their\ncomputational complexity.\n \nWe conclude in section 5.\n We present the syntax and semantics of PDL\nin section 2.1.  The proof theory of PDL is\npresented in section 2.2 with axiomatizations\nand pointers to the literature on completeness. We address the problem\nof decidability and complexity in section\n2.3. Propositional dynamic logic (PDL) is designed for representing and\nreasoning about propositional properties of programs. Its syntax is\nbased upon two sets of symbols: a countable set Φ0 of\natomic formulas and a countable set Π0 of atomic\nprograms. Complex formulas and complex programs over this base are\ndefined as follows: The other Boolean connectives 1,\n ∧, →, and ↔ are used as abbreviations in the standard way. In\naddition, we abbreviate ¬[α]¬A to\n<α>A (“some execution of α from the present\nstate leads to a state where A is true”) as in modal\nlogic. We write αn for α;…;α with\nn occurrences of α. More formally: \nis often useful to represent an iteration that is unbounded but occurs\nat least once.  Finally, we adopt the standard rules for omission of\nparentheses.\n Formulas can be used to describe the properties that hold after the\nsuccessful execution of a program. For example, the formula\n[α∪β]A means that whenever program α or\nβ is successfully executed, a state is reached where A\nholds, whereas the formula <(α;β)*>A means\nthat there is a sequence of alternating executions of α and\nβ such that a state is reached where A\nholds. Semantically speaking, formulas are interpreted by sets of\nstates and programs are interpreted by binary relations over states in\na transition system. More precisely, the meaning of PDL formulas and\nprograms is interpreted over Labeled Transition Systems (LTS)\nM = (W, R,V)\nwhere W is a nonempty set of worlds or states, R is\na mapping from the set Π0 of atomic programs into binary\nrelations on W and V is a mapping from the set\nΦ0 of atomic formulas into subsets of\nW. Informally, the mapping R assigns to each atomic\nprogram π ∈ Π0 some binary\nrelation R(π) on W with intended meaning\nxR(π)y iff there exists an execution of\nπ from x that leads to y, whereas the mapping\nV assigns to each atomic formula\np ∈ Φ0 some subset\nV(p) of W with intended meaning\nx ∈ V(p) iff p\nis true in x. Given our readings of 0, ¬A,\nA∨B,\n[α]A, α;β, α∪β, α* and\nA?, it is clear that R and V must be\nextended inductively as follows to supply the intended meanings for\nthe complex programs and formulas: If x ∈ V(A) then we\nsay that A is satisfied at state x in M, or\n“M, x sat A”. \nCall M the LTS depicted above on the left\nand M′ the LTS depicted on the right. Formally defined,\nwe\nhave M = (W, R, V)\nwith W =\n{x1,x2}, R(π1)\n=\n{(x1,x1)}, R(π2)\n=\n{(x1,x2)}, V(p)\n= {x1}, V(q) =\n{x2}, and we have\nM′ = (W′, R′, V′)\nwith W′ =\n{y1,y2,y3,y4},\n R(π1)\n= {(y1,y2),\n(y2,y2)}, R′(π2)\n= {(y1,y3),\n(y2,y4)}, V′(p)\n=\n{y1, y2}, V′(q)\n= {y3, y4}. We have for\ninstance: Now consider a formula\nA. We say that A is valid in M or\nthat M is a model of A, or “M\n ⊨ A”,\n iff for all worlds x,\nx ∈ V(A).  A is\nsaid to be valid, or\n “⊨\n A”, iff for all models M, M\n ⊨\n A. We say that A is satisfiable in M\nor that M satisfies A, or “M sat\nA”, iff there exists a world x such that\nx ∈ V(A). A is\nsaid to be satisfiable, or “sat A”, iff there exists a model\nM such that M sat A. Interestingly, Some remarkable formulas of PDL are valid. (The reader may try to\nprove them formally, or at least start convincing themselves on the\nfew examples displayed above.) Equivalently, we can write them under their dual form. \nOne interesting notion concerns the amount of information, expressed\nwith PDL formulas, that is contained in an LTS. The behavior of a\nsystem described as an LTS is indeed often slightly hidden in its\nform. For instance, on simple inspection, it is easy to convince\noneself that the two LTSs depicted above have the same behavior, and\nsatisfy the same PDL formulas. To finish this section on syntax and\nsemantics we give the theoretical foundation of these claims.\n \nGiven two LTSs, one may ask whether they satisfy the same formulas.\nThe notion of bisimulation has become the standard measure for\nequivalence of Kripke models and Labeled Transition\nSystems. A bisimulation between the LTSs\nM = (W, R,V)\nand M′ = (W′,\n R′, V′) is a binary relation\nZ between their states such that for all worlds x in\nM and for all worlds x′ in M′,\nif xZx′ then \nWe say that two LTSs are bisimilar when there exists a\nbisimulation between them.  It is known since the beginning of PDL\nthat in two bisimilar LTSs M and M′,\nfor all worlds x in M and for all\nworlds x′ in\nM′, if xZx′ then for all PDL formulas\nA, x  ∈ V(A)\niff x′ \n∈ V′(A). Thus when two LTSs are\nbisimilar under the definition of bisimulation above, it is the\ncase that, if xZx′ then Hence one can simply compare the behaviors of two LTSs by\ninspecting solely the atomic programs and safely extrapolate on the\ncomparative behavior of these LTSs even for complex programs. We say\nthat the program constructs of PDL are safe for bisimulation. See Van\nBenthem [1998] for precise characterizations of program constructs\nthat are safe for bisimulation. \nIt is readily seen that the two instances of LTSs above are\nbisimilar. A bisimulation Z between M and\nM′ can be given as: Z =\n{(x1,y1),\n(x1,y2),\n(x2,y3),\n(x2,y4)}. The states\nx1 and y1 satisfy exactly the\nsame PDL formulas. So do the states x1 and\ny2, etc.\n The purpose of the proof theory is to provide the characterization\nof the property ⊨ A in terms of axioms and rules of\ninference. In this section, we define a deducibility predicate ⊢\ninductively by operations on formulas that depend only on their\nsyntactic structure in such a way that for all formulas\nA, Of course, PDL is an extension of classical propositional logic. We\nfirst expect that all propositional tautologies hold, and all\npropositional reasoning is allowed. In particular, modus ponens is a\nvalid rule: from A and A → B\ninfer B. For any program α, restricting an LTS to the\nrelation R(α) we obtain a Kripke model in which the\nlogic of the modality [α] is the weakest propositional normal\nmodal logic, namely, the logic K. Thus, PDL contains every instance of\nthe familiar distribution axiom schema: and it is closed under the following rule of inference\n(necessitation rule): A modal logic is normal if it obeys (A0) and (N). Important\nproperties for all α, are that [α] distributes over the\nconjunction ∧, and the rule of monotony, which permits\nfrom A → B to infer [α]A →\n[α]B, can be proven. Finally, PDL is the least normal\nmodal logic containing every instance of the following axiom schemas\n and closed under the following rule of inference (loop\ninvariance rule): If X is a set of formulas and A is a formula then we\nsay that A is\n ⊢-deducible\n from  X, or “X\n ⊢\n A”, if there exists a sequence A0,\nA1, …, An of\nformulas such that\nAn = A and for all\ni≤n, Ai is an\ninstance of an axiom schema, or a formula of X, or comes from\nearlier formulas of the sequence by a rule of inference. Further,\n ⊢\n A iff ∅\n ⊢\n A; in this case we say that A is\n ⊢-deducible.\n X is said to be\n ⊢-consistent\n iff not X\n ⊢\n 0. It is easy to establish that (I) can be replaced by the following\naxiom schema (induction axiom schema): Let us first establish that (I) is a derived rule of the proof\nsystem based on (A1), (A2), (A3), (A4) and (A5): Let us next establish that (A5) is\n ⊢-deducible: The axiomatization of PDL based on axiom schemas (A1), (A2), (A3),\n(A4) and (A5) has been proposed in Segerberg [1977]. It is immediate\nfrom the definitions above that ⊢ is sound with respect to\n⊨, i.e. The proof proceeds by induction on the length of A’s\ndeduction in  ⊢.\n \nThe question of the completeness of ⊢  with respect to\n⊨,  i.e., was pursued by several logicians. The line of reasoning presented\nin Segerberg [1977] was the first attempt to prove the completeness of\n⊢. Soon, Parikh came up with a proof, too. When early 1978\nSegerberg found a flaw in his argument (which he repaired eventually),\nParikh published what can be considered the first proof of the\ncompleteness of ⊢ in Parikh [1978]. Different proofs of\ncompleteness of ⊢ have been published since, e.g. Kozen and\nParikh [1981]. Different alternative proof theories of PDL have also been sought\nafter. Even early on, notably in Pratt [1978]. Let us then also\nmention the completeness of related theories by Nishimura [1979] and\nVakarelov [1983]. \nAn alternative formulation of a deducibility predicate for PDL permits\nthe use of an infinitary rule of inference, as for instance in\nGoldblatt [1992a]. (An infinitary rule of inference takes an infinite\nnumber of premises.) Let ⊢′ be the deducibility predicate\ncorresponding in the language of propositional dynamic logic to the\nleast normal modal logic containing every instance of the axiom\nschemas (A1), (A2), (A3) and (A4) and closed under the following\ninfinitary rule of inference: It can be proved that\n ⊢′\n is both sound and complete with respect\n ⊨,\n i.e., In other words, as far as generating the set of all valid formulas\nis concerned, the proof systems\n ⊢\n and\n ⊢′\n are equivalent. \nThe aim of the complexity theory is to establish the computability of\nthe property sat A in terms of resources of time or\nspace. The complexity of a logic L is often identified with\nthe problem of deciding the satisfiability of its formulas, defined\nas: In this section, we investigate the complexity of the following\ndecision problem: The complete axiomatization of PDL is a recursive definition of the\nset of valid PDL formulas, or in other words, of the set of formulas\nwhose negation is not satisfiable. Hence, concerning the problem\n(PDL-SAT), we have a sub-procedure that would answer “no” if\nthe PDL formula A were not satisfiable. The sub-procedure\n(SP1) consists in enumerating all the formulas ⊢-deducible,\nstarting from the axioms and inferring other theorems with the help of\nthe inference rules. Given enough time, if a formula is\n⊢-deducible, the sub-procedure would find it eventually. Thus,\nif A is not satisfiable, (SP1) must eventually find\n¬A, and answer “no” when it does. However, if the formula A is satisfiable, then (SP1) would\nnever find ¬A. It would run forever, and one could not be\nsure about it at any time. But there is a way out of this\nuncertainty. We can also think of a second sub-procedure that answers\n“yes” if a PDL formula is satisfiable. Indeed, one of the\nearliest results on PDL was the proof that PDL has the finite\nmodel property, i.e., \nThe finite model property offers a basis for a sub-procedure (SP2)\nthat consists in enumerating one by one the finite models of PDL and\ntesting whether one of them satisfies the formula. (For all\nformulas A and for all finite models M, it is easy\nto test if M sat A by applying the definition\nof V(A).)  Thus, if A is satisfiable, it\nmust eventually find a model\nM such that M sat A, and answer\n“yes” when it does. Symmetrically to the first sub-procedure\n(SP1), if the formula A is not satisfiable, then (SP2) will\nnever find a model satisfying it, it will run forever, and one could\nnot be sure about it at any time.\n \nNow, combining (SP1) and (SP2) together we have a way of deciding\nwhether a PDL formula A is satisfiable. It suffices to run\nthem in parallel: if A is satisfiable then (SP2) will\neventually answer “yes”, if A is not satisfiable\nthen (SP1) will eventually answer “no”. The procedure\nhalts when either (SP1) or (SP2) provides an answer. If the procedure that is obtained is sufficient to conclude that\nthe problem (PDL-SAT) is decidable, it is very ineffective in\npractice. There is a result—due to Fischer and Ladner [1979] and\nKozen and Parikh [1981]— stronger than the finite model\nproperty, that is small model property: This means that we would now know when to stop looking for a model\nsatisfying a formula in the procedure (SP2). Hence, we can use (SP2)\nto test whether a formula is satisfiable, but once we have exhausted\nall small models, we can conclude that the formula is not\nsatisfiable. This yields a procedure that runs non-deterministically\nin exponential time (NEXPTIME): guess a model of size at most singly\nexponential, and check whether it satisfies the formula.\n\nBut the key results in the complexity theory of PDL come from Fischer\nand Ladner [1979] and Pratt [1980a]. Observing that a formula of PDL\ncan efficiently describe the computation of a\nlinear-space–bounded alternating Turing machine, Fischer and\nLadner [1979] first established the lower bound of exponential time of\n(PDL-SAT). The EXPTIME upper bound of (PDL-SAT) has been obtained by Pratt\n[1980a], who used the equivalent for PDL of the method of\ntableaux. Thus, (PDL-SAT) is EXPTIME-complete. (An algorithm more\nefficient in practice, although still running in deterministic\nexponential time in the worst case, is proposed in De Giacomo and\nMassacci [2000].)\n \nHistorically, logics of programs stem from the work in the late 1960s\nof computer scientists interested in assigning meaning to programming\nlanguages and finding a rigorous standard for proofs about\nthe programs. For example such proofs may be about the correctness of a\nprogram with respect to an expected behavior, or about the\ntermination of a program. A seminal paper is Floyd [1967] which\npresents an analysis of the properties of structured computer programs\nusing flowcharts.  Some early work such as Yanov [1959] or\nEngeler [1967] had advanced and studied formal languages in which the\nproperties of program connectives can be expressed. The formalism of\nHoare [1969] was a milestone in the advent of PDL. It was proposed as\na rigorous axiomatic interpretation of Floyd’s flowcharts. We often\ntalk about Hoare logic, or Floyd-Hoare logic, or Hoare calculus when\nreferring to this formalism. Hoare calculus is concerned with the\ntruth of statements (“Hoare triples”), such as\n{A}α{B} which establishes a connection between\na precondition A, a program α, and a\npost-condition B. It indicates that whenever A holds\nas a precondition of the execution of α, then B holds\nas a post-condition after the successful execution of α. \nIt was true some decades ago, and it is still the case: validating a\nprogram is more often than not done by testing it on a reasonable\nvariety of inputs. When an input does not yield the expected output,\nthe “bug” is fixed. If eventually for every tested input\nwe obtain the expected output, one has a reasonable belief that the\nprogram has no error. However, this is a time consuming method of\nvalidation, and it leaves place for untested inputs that would fail.\nFinding these errors after the program has been implemented and gone\ninto use is even more costly in resources.  Reasoning about program\ncorrectness with formal methods is crucial for critical systems since\nit offers a way of proving exhaustively that a program has no\nerrors. To illustrate the sort of principles of programs captured by the\nrules in the Hoare calculus it is enough to consult some of\nthem. (N.B.: the rules mean that if all the statements above the rule\nline hold—the premises—then also the statement under the\nrule line—the conclusion— holds.) The rule of composition captures the elementary sequential\ncomposition of programs. As premises, we have two assumptions about\nthe partial correctness of two programs α1 and\nα2. The first assumption is that when\nα1 is executed in a state satisfying A, then it will\nfinish in a state satisfying B, whenever it halts. The second\nassumption is that when α2 is executed in a state\nsatisfying B, then it will finish in a state satisfying\nC, whenever it halts. The conclusion of the rule is about the\npartial correctness of the program\nα1;α2 (i.e., α1\nsequentially composed with α2), that follows from the\ntwo assumptions. Namely, we can conclude that if\nα1;α2 is executed in a state\nsatisfying A, then it finishes in a state satisfying\nC, whenever it halts.\n \nThe rule of iteration is an important one because it captures the\nessential ability of programs to execute some portion of code\nrepeatedly until a certain condition ceases to hold. Finally, the two rules of consequence are fundamental to give a\nformal basis to intuitively clear reasoning involving weaker\npost-conditions and stronger preconditions respectively. From the formalism presented in Hoare [1969], we leave out its\naxiom schemas as it would require a first-order language. Finally, in\nsubsequent work on Hoare logic, more rules are also often added. See\nApt [1979] for an early overview. Dynamic logics come from Pratt’s interpretation of Hoare triples\nand Hoare calculus in the formalism of modal logic. With the modality\n[α], we can express formally that all states reachable by\nexecuting α satisfy the formula A. This is done by\nwriting [α]A. Thus, the Hoare triple\n{A}α{B} is simply captured by the PDL\nformula \nIn addition, important programming constructs are easily introduced in PDL by\ndefinitional abbreviation:  \nThus, it seems that with PDL we are well-equipped to logically prove\nthe correctness of structured programs. Beyond this rather hand-waving\nconnection between PDL and Hoare calculus, perhaps it is not yet clear\nhow they relate formally. PDL is in fact a generalization of Hoare\ncalculus in the sense that all the rules of the Hoare calculus can be\nproven in the axiomatic system of PDL. (Rigorously, the Hoare calculus\ncontains axioms that would require the extended language of\nfirst-order Dynamic Logic.) This is quite remarkable, so we will show\nhere the two above rules to serve as examples. \nThe proofs start by assuming the premises of the rules. Then by using\nthese assumptions, axioms and rules of PDL, and nothing else, the\nobjective is to establish that the conclusion of the rules logically\nfollows. Hence, for the rule of composition, we start by assuming\n{A}α1{B}, that is A →\n[α1]B in its PDL formulation, and by\nassuming {B}α2{C}, that is\nB → [α2]C. The objective is to\nprove that\n{A}α1;α2{C}. Precisely,\nwe want to establish that A →\n[α1;α2]C is\n⊢-deducible from the set of formulas {A →\n[α1]B, B →\n[α2]C}. \nThe proof of the rule of iteration is slightly more involved.\n In the context of PDL, the two rules of consequence are in fact\nspecial cases of the rule of composition. To obtain the first rule,\nsubstitute α1 with α and α2\nwith skip. To obtain the second rule, substitute\nα1 with skip and α2\nwith α. It suffices to apply the axiom schema (A4), and to\nremark that [α;skip]A ↔\n[α]A and [α;skip]A\n↔ [α]A are also ⊢-deducible for\nall A and all α.\n \nBy Hoare’s own admission in Hoare [1979], his original calculus was\nmerely a starting point and suffered quite a few\nlimitations. Particularly, it only allows one to reason about\npartial correctness. That is, the truth of a statement\n{A}α{B} only makes sure that all executions of\nα starting in a state satisfying A will end in a state\nsatisfying B, or will not halt. That is, a partially\ncorrect program may have non-terminating executions. (In fact, a\nprogram that has no terminating execution will always be partially\ncorrect. This is the case for example of the program\nwhile 1 do\nskip. The formula A →\n[while 1 do\nskip]B is deducible for all formulas\nA and B.) The calculus offers no basis for a proof\nthat a program terminates. It can be modified so as to account for\ntotal correctness of programs: partial correctness plus\ntermination. It is achieved by amending the rule of iteration. We do\nnot present it here and refer the interested reader to Apt [1981]. Let us first observe that for deterministic programs, one\ncan already capture total correctness via formulas of the kind The expression <α>B means that there is an\nexecution of α that terminates in a state that satisfies\nB. Moreover, if α is deterministic, this possible\nterminating execution is the unique execution of α. Thus, if one\nfirst manages to prove that a program is deterministic, this trick\nworks well enough to prove its total correctness. A general solution to the problem of total correctness exists in\nthe realm of PDL. But we need to extend it a little. Pratt had already\nalluded in Pratt [1980b] that PDL is not expressive enough to capture\nthe infinite looping of programs. In reaction, PDL with repeating\n(RPDL) was introduced by Streett [1982]. It contains, for all programs\nα, the expression Δα standing for a new proposition\nwith semantics Streett [1982] conjectured that RPDL can be axiomatized by adding to the\nproof system of PDL precisely the following axiom schemas. The proof of the conjecture was provided in Sakalauskaite and\nValiev [1990]. (A version of the conjecture in the variant of\ncombinatory PDL was also proved in Gargov and Passy [1988].) It is easy to see that in the Hoare calculus presented above, non\ntermination can only come from the rule of iteration. Analogously,\nnon termination of a PDL program can only come from the use of the\nunbounded iteration. The expression Δα indicates that\nα* can diverge, and this is just the kind of notion we need. We\ncan now inductively define a predicate ∞ such that for a program\nα, the formula ∞(α) will be true exactly when\nα can enter a non-terminating computation. Finally, the total correctness of a program can be expressed via\nformulas of the kind which means literally that if A is the case, then the\nprogram α cannot run forever and every successful execution will\nend in a state satisfying B.  Results concerning comparative power of expression, decidability,\ncomplexity, axiomatization and completeness of a number of variants of\nPDL obtained by extending or restricting its syntax and its semantics\nconstitute the subject of a wealth of literature. We can only say so\nmuch and we will address just a few of these variants leaving out\nbig chunks of otherwise important work in dynamic logic. The axiom schema [A?]B ↔ (A →\nB) seems to indicate that for every formula C, there\nexists an equivalent test-free formula C′—i.e.,\nthere is a test-free formula C′ such that\n ⊨ C ↔\nC′. It is interesting to observe that this assertion is\nuntrue. Let PDL0 be the restriction of PDL to test-free\nregular programs, i.e. programs which do not contain tests. Berman and\nPaterson [1981] considered the PDL formula\n<(p?;π)*;¬p?;π;p?>1, which\nis and proved that there is no PDL0 formula equivalent to\nit. Hence, PDL has more expressive power than PDL0. Their\nargument actually can be generalized as follows. For all\nn ≥ 0, let PDLn+1 be the\nsubset of PDL in which programs can contain tests A? only if\nA is a PDLn formula. For all\nn ≥ 0, Berman and Paterson considered the\nPDLn+1 formula An+1\ndefined by where A0 = p and\nπ0 = π and proved that for all\nn ≥ 0, there is no PDLn\nformula equivalent to An+1. Hence, for\nall n ≥ 0, PDLn+1 has\nmore expressive power than PDLn. CPDL is the extension of PDL with converse. It is a construct that\nhas been considered since the beginning of PDL. For all programs\nα, let α-1 stand for a new program with\nsemantics The converse construct allows us to express facts about states\npreceding the current one and to reason backward about programs. For\ninstance, [α-1]A means that before executing\nα, A had to hold.\n \nWe have The addition of the converse construct does not change the\nproperties of PDL in any significant way. By adding every instance of\nthe following axiom schemas: to the proof system of PDL, we obtain a sound and complete\ndeducibility predicate in the extended language. See Parikh [1978]\nfor details. CPDL has the small model property and (CPDL-SAT) is\nEXPTIME-complete. It is easy to remark that CPDL has more expressive power than PDL. To see this,\nconsider the CPDL formula <π-1>1 and the LTSs\nM = (W, R, V)\nand\nM′ = (W′, R′, V′)\nwhere W = {x,y},\nR(π) = {(x,y)},\nW′ = {y′},\nR′(π) = ∅\n and V(x) = V(y)\n = V′(y′) =\n ∅. Since M, y sat <π-1>1,\n not M′, y′ sat\n <π-1>1, and because for all PDL\n formulas A it is the case that\nM, y sat A iff M′,\ny′ sat A, then it is clear that no PDL formula is\nequivalent to <π-1>1. We have already exposed the power of repeating in\nsection 3.3 by introducing RPDL. Here, we\nsummarize more results about RPDL and its connection with other\nvariations on the notion of repeating programs. Concerning the complexity theory of RPDL, Streett [1982] had\nalready established that RPDL had the finite model property; precisely\nthat every RPDL satisfiable formula A is satisfiable in\na model of size at most triply exponential in the length\nof A. An automata-theoretic argument permitted to conclude\nthat the problem (RPDL-SAT) can be solved in deterministic triple\nexponential time (3-EXPTIME). The gap between this upper bound for\ndeciding (RPDL-SAT) and the simple exponential-time lower bound for\ndeciding (PDL-SAT) was thus open. The problem found itself greatly\nconnected to the growing interest of computer scientists in\nestablishing the complexity of temporal logics, and more specifically\nof the (propositional) modal μ-calculus (MMC) due to Kozen [1983],\nbecause RPDL has a linear blow-up translation to MMC. Moreover,\nStreett’s argument somewhat set a precedent in the now pervasive use\nof automata techniques in proving computational properties of logics\nof programs and of temporal logics. In Vardi and Stockmeyer [1985], an\nupper bound in non-deterministic exponential time was shown. In\nEmerson and Jutla [1988] and in its final form in Emerson and Jutla\n[1999], it was shown that (MMC-SAT) and (RPDL-SAT) are\nEXPTIME-complete. If we add the converse operator\nof section 4.2 one obtains CRPDL. The complexity\nof (CRPDL-SAT) remained open for a few years but it can be shown to be\nEXPTIME-complete, too. This is achieved by combining the techniques of\nEmerson and Jutla [1988] and Vardi [1985], as in Vardi [1998]. In section 3.3 we have defined a predicate\n∞, where ∞(α) means that α can have\nnon-terminating computation. We call LPDL the logic obtained by\naugmenting PDL with the predicate ∞. Clearly, RPDL is at least\nas expressive as LPDL; The inductive definition of ∞(α) in\nthe language of RPDL is witness of it. RPDL is in fact strictly more\nexpressive than LPDL. This was shown in Harel and Sherman [1982].\n\nAs it can be suspected, both RPDL and LPDL have more expressive power\nthan PDL. It is established by proving that some formulas of RPDL and\nof LPDL have no equivalent expression in PDL.\n\nThe proof involves the technique of filtration which is\ndesigned to collapse an LTS to a finite model while leaving invariant\nthe truth or falsity of certain formulas. For some set of PDL\nformulas X, it consists in grouping into equivalence classes\nthe states of an LTS that satisfy exactly the same formulas\nin X. The set of equivalence classes of states thus obtained\nbecomes the set of states of the filtrate model, and a transition is built\nappropriately over them. \nWith a carefully chosen set FL(A) that depends on a\nPDL formula A (the so-called Fischer-Ladner closure of the\nset of sub-formulas of A), a filtration of an LTS M\nyields a finite filtrate M′, such that A is\nsatisfiable at a world u in M if and only if it is\nsatisfiable in the equivalence class containing u in the\nfiltrate. (See Fischer and Ladner [1979].)\n We can now consider the filtrations of the\nLTS M = (W, R,V)\nwhere In one sentence, what goes on in M is that from the\nworld u, there is an infinite number of finite π-paths of\ngrowing length. We have both M, u sat\n¬Δπ and M, u sat\n¬∞(π*). Yet, for every PDL formula A, we\nwill have both Δπ and ∞(π*) that are satisfied at\nthe equivalence class of u in the model obtained by\nfiltration of M with FL(A). Indeed, the filtration\nmust collapse some states of M and create some loops. Thus,\nthere exists no PDL formula that can express either Δπ or\n∞(π*).\n\nand yet, we will have both Δπ and ∞(π*) that are\nsatisfied at the equivalence class of u in any finite\nfiltrate of M. Thus, neither Δπ nor ∞(π*)\ncan be expressed in PDL. There are other ways of making possible the assertion that a\nprogram can execute forever. For instance, Danecki [1984a] proposed a\npredicate sloop to qualify programs that can enter in\nstrong loops, that is: Let us call SLPDL the logic obtained by augmenting PDL\nwith sloop(α). RPDL and SLPDL are essentially\nincomparable: the predicate Δ is not definable in SLPDL, and the\npredicate sloop is not definable in RPDL. SLPDL does\nnot possess the finite model property. For example, the formula is satisfiable in infinite LTSs only. Nonetheless, Danecki [1984a]\nestablished the decidability of (SLPDL-SAT) formulas in\ndeterministic exponential time.  Another construct has been studied: the intersection of programs.\nBy adding intersection of programs to PDL, we obtain the logic\nIPDL. In IPDL, for all programs α, β, the expression\nα∩β stands for a new program with semantics For instance, the intended reading of\n<α∩β>A is that if we execute α and\nβ in the present state then there exists a state reachable by\nboth programs which satisfies A. As a result, we have but, in general, we have Although intersection of programs plays an important role in\nvarious applications of PDL to artificial intelligence and computer\nscience, the proof theory and the complexity theory of PDL with\nintersection remained unexplored for several years. Concerning the\ncomplexity theory of IPDL, difficulties appear when one considers the\nfinite model property.\n\nIn fact the construct sloop(α) can be\nexpressed in IPDL. In propositional dynamic logic with intersection it is\nequivalent to <α∩1?>1. We can thus adapt the formula of  \nIPDL of section 4.3, and we have that is satisfiable in infinite LTSs only. In other words, IPDL does not\npossess the finite model property. Danecki [1984b] investigated the\ncomplexity theory of IPDL and showed that deciding (IPDL-SAT) can be\ndone in deterministic double exponential time. (A modern proof\nis presented in Göller, Lohrey and Lutz [2007].) The complexity\ngap between this double exponential-time upper bound for deciding\n(IPDL-SAT) and the simple exponential-time lower bound for deciding\n(PDL-SAT) obtained by Fischer and Ladner [1979] remained open for more\nthan twenty years. In 2004, Lange [2005] established the lower bound\nof exponential space of (IPDL-SAT). In 2006, Lange and Lutz [2005]\ngave a proof of a double exponential-time lower bound of the\nsatisfiability problem for IPDL without tests by a reduction from the\nword problem of exponentially space-bounded alternating Turing\nmachines. In this reduction, the role of the iteration construct is\nessential since, according to Massacci [2001], the satisfiability\nproblem for iteration-free IPDL without tests is only\nPSPACE-complete. Adding the converse construct to IPDL, we obtain\nICPDL. The satisfiability problem of ICPDL has been proved to be\n2-EXPTIME-complete by Göller, Lohrey and Lutz [2007]. Concerning the proof theory of IPDL, difficulties appear when we\nrealize that no axiom schema, in the language of PDL with\nintersection, “corresponds” to the semantics\n xR(α∩β)y iff\nxR(α)y and\nxR(β)y of the program\nα∩β. That is, not in the same way for example, that the\naxiom schemas (A1) and (A2) respectively “correspond” to\nthe semantics of the programs α;β and\nα∪β.  For this reason, the axiomatization of PDL with\nintersection was open until the complete proof system developed in\nBalbiani and Vakarelov [2003]. In another variant of PDL, due to Peleg [1987] and further studied\nby Goldblatt [1992b], the expression α∩β is interpreted\n“do α and β in parallel”. In this context, the\nbinary relations R(α) and R(β) are no\nlonger sets of pairs of the form (x,y) with\nx, y worlds, but rather sets of pairs of the form\n(x,Y) with x a world and Y a set\nof worlds. It was inspired by the Game Logic of Parikh [1985], an\nintepretation of PDL with “programs as games”. Game Logic\nprovides an additional program construct that dualizes programs, thus\npermitting to define the intersection of programs as the dual of the\nnon-deterministic choice between programs. This article has focused on propositional dynamic logic and some of\nits significant variants.\n\nThere are by now a number of books—Goldblatt [1982], Goldblatt\n[1992a], Harel [1979] and Harel, Kozen and Tiuryn [2000]—and\nsurvey papers—Harel [1984], Kozen and Tiuryn [1990], Parikh\n[1983] —treating PDL and related formalisms.\n\nThe body of research on PDL is certainly instrumental in developing\nmany logical theories of system dynamics. However, these theories are arguably out\nof the scope of the present article.\n\nVan Eijck and Stokhof [2006] is a more recent overview of topics\nmaking use of dynamic logic, addressing various themes that are of\ncertain interest for philosophers: e.g., dynamics of communication, or\nnatural language semantics.\n\nRecent books are going in much details on newer topics, such as\ndynamic logic of knowledge (dynamic epistemic logic) in Van Ditmarsch,\nVan Der Hoek and Kooi [2007], and the dynamic logic of continuous and\nhybrid systems (differential dynamic logic) in Platzer [2010].\n\nPDL was conceived primarily for reasoning about programs. There are\nmany other applications of modal logic to reasoning about\nprograms. Algorithmic logic is closer to PDL since it allows one to\ntalk explicitly about programs. The reader is invited to consult the\nwork studied in Mirkowska and Salwicki [1987]. Temporal logics are now\nthe chief logics in theoretical computer science and have a close\nconnection with logics of programs. They allow one to express the\ntemporal behavior of transition systems with a language that abstracts\naway from the labels (hence the programs). See for instance Schneider\n[2004] for an overview of the foundations in this research area.","contact.mail":"ntroquard@unibz.it","contact.domain":"unibz.it"}]
