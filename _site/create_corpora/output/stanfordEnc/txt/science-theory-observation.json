[{"date.published":"2009-01-06","date.changed":"2017-03-28","url":"https://plato.stanford.edu/entries/science-theory-observation/","author1":"James Bogen","entry":"science-theory-observation","body.text":"\n\n\nScientists obtain a great deal of the evidence they use by observing\nnatural and experimentally generated objects and effects. Much of the\nstandard philosophical literature on this subject comes from\n20th century logical empiricists, their followers, and\ncritics who embraced their issues and accepted some of their\nassumptions even as they objected to specific views. Their discussions\nof observational evidence tend to focus on epistemological questions\nabout its role in theory testing. This entry follows their lead even\nthough observational evidence also plays important and philosophically\ninteresting roles in other areas including scientific discovery, the\ndevelopment of experimental tools and techniques, and the application\nof scientific theories to practical problems.\n\n\nThe issues that get the most attention in the standard philosophical\nliterature on observation and theory have to do with the distinction\nbetween observables and unobservables, the form and content of\nobservation reports, and the epistemic bearing of observational\nevidence on theories it is used to evaluate. This entry discusses\nthese topics under the following headings:\n\nReasoning from observations has been important to scientific practice\nat least since the time of Aristotle who mentions a number of sources\nof observational evidence including animal dissection (Aristotle(a)\n763a/30–b/15, Aristotle(b) 511b/20–25). But philosophers\ndidn’t talk about observation as extensively, in as much detail, or in\nthe way we have become accustomed to, until the 20th\ncentury when logical empiricists transformed philosophical thinking\nabout it. \nThe first transformation was accomplished by ignoring the implications\nof a long standing distinction between observing and experimenting. To\nexperiment is to isolate, prepare, and manipulate things in hopes of\nproducing epistemically useful evidence. It had been customary to\nthink of observing as noticing and attending to interesting details of\nthings perceived under more or less natural conditions, or by\nextension, things perceived during the course of an experiment. To\nlook at a berry on a vine and attend to its color and shape would be\nto observe it. To extract its juice and apply reagents to test for the\npresence of copper compounds would be to perform an experiment.\nContrivance and manipulation influence epistemically significant\nfeatures of observable experimental results to such an extent that\nepistemologists ignore them at their peril. Robert Boyle (1661), John\nHerschell (1830), Bruno Latour and Steve Woolgar (1979), Ian Hacking\n(1983), Harry Collins (1985) Allan Franklin (1986), Peter Galison\n(1987), Jim Bogen and Jim Woodward (1988), and Hans-Jörg\nRheinberger(1997), are some of the philosophers and philosophically\nminded scientists, historians, and sociologists of science who gave\nserious consideration to the distinction between observing and\nexperimenting. The logical empiricists tended to ignore it. \nA second transformation, characteristic of the linguistic turn in\nphilosophy, was to shift attention away from things observed in\nnatural or experimental settings and concentrate instead on the logic\nof observation reports. The shift developed from the assumption that a\nscientific theory is a system of sentences or sentence like structures\n(propositions, statements, claims, and so on) to be tested by\ncomparison to observational evidence. Secondly it was assumed that the\ncomparisons must be understood in terms of inferential relations. If\ninferential relations hold only between sentence like structures, it\nfollows that theories must be tested, not against observations or\nthings observed, but against sentences, propositions, etc. used to\nreport observations. (Hempel 1935, 50–51. Schlick 1935) \nFriends of this line of thought theorized about the syntax, semantics,\nand pragmatics of observation sentences, and inferential connections\nbetween observation and theoretical sentences. In doing so they hoped\nto articulate and explain the authoritativeness widely conceded to the\nbest natural, social and behavioral scientific theories. Some\npronouncements from astrologers, medical quacks, and other pseudo\nscientists gain wide acceptance, as do those of religious leaders who\nrest their cases on faith or personal revelation, and rulers and\ngovernmental officials who use their political power to secure assent.\nBut such claims do not enjoy the kind of credibility that scientific\ntheories can attain. The logical empiricists tried to account for this\nby appeal to the objectivity and accessibility of observation reports,\nand the logic of theory testing. \nPart of what they meant by calling observational evidence objective\nwas that cultural and ethnic factors have no bearing on what can\nvalidly be inferred about the merits of a theory from observation\nreports. So conceived, objectivity was important to the logical\nempiricists’ criticism of the Nazi idea that Jews and Aryans have\nfundamentally different thought processes such that physical theories\nsuitable for Einstein and his kind should not be inflicted on German\nstudents. In response to this rationale for ethnic and cultural\npurging of the German educational system the logical empiricists\nargued that because of its objectivity, observational evidence, rather\nthan ethnic and cultual factors should be used to evaluate scientific\ntheories.(Galison 1990). Less dramatically, the efforts working\nscientists put into producing objective evidence attest to the\nimportance they attach to objectivity. Furthermore it is possible, in\nprinciple at least, to make observation reports and the reasoning used\nto draw conclusions from them available for public scrutiny. If\nobservational evidence is objective in this sense , it can provide\npeople with what they need to decide for themselves which theories to\naccept without having to rely unquestioningly on authorities. \nFrancis Bacon argued long ago that the best way to discover things\nabout nature is to use experiences (his term for observations as well\nas experimental results) to develop and improve scientific theories\n(Bacon1620 49ff). The role of observational evidence in scientific\ndiscovery was an important topic for Whewell (1858) and Mill (1872)\namong others in the 19th century. Recently, Judea Pearl,\nClark Glymour, and their students and associates addressed it\nrigorously in the course of developing techniques for inferring claims\nabout causal structures from statistical features of the data they\ngive rise to (Pearl, 2000; Spirtes, Glymour, and Scheines 2000). But\nsuch work is exceptional. For the most part, philosophers followed\nKarl Popper who maintained, contrary to the title of one of his best\nknown books, that there is no such thing as a ‘logic of\ndiscovery’.(Popper 1959, 31) Drawing a sharp distinction between\ndiscovery and justification, the standard philosophical literature\ndevotes most of its attention to the latter. \nTheories are customarily represented as collections of sentences,\npropositions, statements or beliefs, etc., and their logical\nconsequences. Among these are maximally general explanatory and\npredictive laws (Coulomb’s law of electrical attraction and repulsion,\nand Maxwellian electromagnetism equations for example), along with\nlesser generalizations that describe more limited natural and\nexperimental phenomena (e.g., the ideal gas equations describing\nrelations between temperatures and pressures of enclosed gasses, and\ngeneral descriptions of positional astronomical regularities).\nObservations are used in testing generalizations of both kinds. \nSome philosophers prefer to represent theories as collections of\n‘states of physical or phenomenal systems’ and laws. The\nlaws for any given theory are \nSo conceived, a theory can be adequately represented by more than one\nlinguistic formulation because it is not a system of sentences or\npropositions. Instead, it is a non-linguistic structure which can\nfunction as a semantic model of its sentential or propositional\nrepresentations. (Suppe 1977, 221–230) This entry treats\ntheories as collections of sentences or sentential structures with or\nwithout deductive closure. But the questions it takes up arise in\npretty much the same way when theories are represented in accordance\nwith this semantic account. \nOne answer to this question assumes that observation is a perceptual\nprocess so that to observe is to look at, listen to, touch, taste, or\nsmell something, attending to details of the resulting perceptual\nexperience. Observers may have the good fortune to obtain useful\nperceptual evidence simply by noticing what’s going on around them,\nbut in many cases they must arrange and manipulate things to produce\ninformative perceptible results. In either case, observation sentences\ndescribe perceptions or things perceived. \nObservers use magnifying glasses, microscopes, or telescopes to see\nthings that are too small or far away to be seen, or seen clearly\nenough, without them. Similarly, amplification devices are used to\nhear faint sounds. But if to observe something is to perceive it, not\nevery use of instruments to augment the senses qualifies as\nobservational. Philosophers agree that you can observe the moons of\nJupiter with a telescope, or a heart beat with a stethoscope. But\nminimalist empiricists like Bas Van Fraassen (1980, 16–17) deny\nthat one can observe things that can be visualized only by using\nelectron (and perhaps even) light microscopes. Many philosophers don’t\nmind microscopes but find it unnatural to say that high energy\nphysicists observe particles or particle interactions when they look\nat bubble chamber photographs. Their intuitions come from the\nplausible assumption that one can observe only what one can see by\nlooking, hear by listening, feel by touching, and so on. Investigators\ncan neither look at (direct their gazes toward and attend to) nor\nvisually experience charged particles moving through a bubble chamber.\nInstead they can look at and see tracks in the chamber, or in bubble\nchamber photographs. \nThe identification of observation and perceptual experience persisted\nwell into the 20th century—so much so that Carl\nHempel could characterize the scientific enterprise as an attempt to\npredict and explain the deliverances of the senses (Hempel 1952, 653).\nThis was to be accomplished by using laws or lawlike generalizations\nalong with descriptions of initial conditions, correspondence rules,\nand auxiliary hypotheses to derive observation sentences describing\nthe sensory deliverances of interest. Theory testing was treated as a\nmatter of comparing observation sentences describing observations made\nin natural or laboratory settings to observation sentences that should\nbe true according to the theory to be tested. This makes it imperative\nto ask what observation sentences report. Even though scientists often\nrecord their evidence non-sententially, e.g., in the form of pictures,\ngraphs, and tables of numbers, some of what Hempel says about the\nmeanings of observation sentences applies to non-sentential\nobservational records as well. \nAccording to what Hempel called the phenomenalist account, observation\nreports describe the observer’s subjective perceptual experiences. \nThis view is motivated by the assumption that the epistemic value of\nan observation report depends upon its truth or accuracy, and that\nwith regard to perception, the only thing observers can know with\ncertainty to be true or accurate is how things appear to them. This\nmeans that we can’t be confident that observation reports are true or\naccurate if they describe anything beyond the observer’s own\nperceptual experience.\n Presumably\n one’s confidence in a conclusion should not exceed one’s confidence\nin one’s best reasons to believe it. For the phenomenalist it follows\nthat reports of subjective experience can provide better reasons to\nbelieve claims they support than reports of other kinds of evidence.\nFurthermore, if C.I. Lewis had been right to think that probabilities\ncannot be established on the basis of dubitable evidence, (Lewis 1950,\n182) observation sentences would have no evidential value unless they\nreport the observer’s subjective\n experiences.[1] \nBut given the expressive limitations of the language available for\nreporting subjective experiences we can’t expect phenomenalistic\nreports to be precise and unambiguous enough to test theoretical\nclaims whose evaluation requires accurate, fine- grained perceptual\ndiscriminations. Worse yet, if experiences are directly available only\nto those who have them, there is room to doubt whether different\npeople can understand the same observation sentence in the same way.\nSuppose you had to evaluate a claim on the basis of someone else’s\nsubjective report of how a litmus solution looked to her when she\ndripped a liquid of unknown acidity into it. How could you decide\nwhether her visual experience was the same as the one you would use\nher words to report? \nSuch considerations led Hempel to propose, contrary to the\nphenomenalists, that observation sentences report ‘directly\nobservable’, ‘intersubjectively ascertainable’ facts\nabout physical objects \nObservers do sometmes have trouble making fine pointer position and\ncolor discriminations but such things are more susceptible to precise,\nintersubjectively understandable descriptions than subjective\nexperiences. How much precision and what degree of intersubjective\nagreement are required in any given case depends on what is being\ntested and how the observation sentence is used to evaluate it. But\nall things being equal, we can’t expect data whose acceptability\ndepends upon delicate subjective discriminations to be as reliable as\ndata whose acceptability depends upon facts that can be ascertained\nintersubjectively. And similarly for non-sentential records; a drawing\nof what the observer takes to be the position of a pointer can be more\nreliable and easier to assess than a drawing that purports to capture\nher subjective visual experience of the pointer. \nThe fact that science is seldom a solitary pursuit suggests that one\nmight be able to use pragmatic considerations to finesse questions\nabout what observation reports express. Scientific\nclaims—especially those with practical and policy\napplications—are typically used for purposes that are best\nserved by public evaluation. Furthermore the development and\napplication of a scientific theory typically requires collaboration\nand in many cases is promoted by competition. This, together with the\nfact that investigators must agree to accept putative evidence before\nthey use it to test a theoretical claim, imposes a pragmatic condition\non observation reports: an observation report must be such that\ninvestigators can reach agreement relatively quickly and relatively\neasily about whether it provides good evidence with which to test a\ntheory (Cf. Neurath 1913). Feyerabend took this requirement seriously\nenough to characterize observation sentences pragmatically in terms of\nwidespread decidability. In order to be an observation sentence, he\nsaid, a sentence must be contingently true or false, and such that\ncompetent speakers of the relevant language can quickly and\nunanimously decide whether to accept or reject it on the basis what\nhappens when they look, listen, etc. in the appropriate way under the\nappropriate observation conditions (Feyerabend 1959, 18ff). \nThe requirement of quick, easy decidability and general agreement\nfavors Hempel’s account of what observation sentences report over the\nphenomenalist’s. But one shouldn’t rely on data whose only virtue is\nwidespread acceptance. Presumably the data must possess additional\nfeatures by virtue of which it can serve as an epistemically\ntrustworthy guide to a theory’s acceptability. If epistemic\ntrustworthiness requires certainty, this requirement favors the\nphenomenalists. Even if trustworthiness doesn’t require certainty, it\nis not the same thing as quick and easy decidability. Philosophers\nneed to address the question of how these two requirements can be\nmutually satisfied. \nMany of the things scientists investigate do not interact with human\nperceptual systems as required to produce perceptual experiences of\nthem. The methods investigators use to study such things argue against\nthe idea—however plausible it may once have seemed—that\nscientists do or should rely exclusively on their perceptual systems\nto obtain the evidence they need. Thus Feyerabend proposed as a\nthought experiment that if measuring equipment was rigged up to\nregister the magnitude of a quantity of interest, a theory could be\ntested just as well against its outputs as against records of human\nperceptions (Feyerabend 1969, 132–137). \nFeyerabend could have made his point with historical examples instead\nof thought experiments. A century earlier Helmholtz estimated the\nspeed of excitatory impulses traveling through a motor nerve. To\ninitiate impulses whose speed could be estimated, he implanted an\nelectrode into one end of a nerve fiber and ran a current into it from\na coil. The other end was attached to a bit of muscle whose\ncontraction signaled the arrival of the impulse. To find out how long\nit took the impulse to reach the muscle he had to know when the\nstimulating current reached the nerve. But \nand so Helmholtz had to resort to what he called ‘artificial\nmethods of observation’ (Olesko and Holmes 1994, 84). This meant\narranging things so that current from the coil could deflect a\ngalvanometer needle. Assuming that the magnitude of the deflection is\nproportional to the duration of current passing from the coil,\nHelmholtz could use the deflection to estimate the duration he could\nnot see (ibid). This ‘artificial observation’ is\nnot to be confused e.g., with using magnifying glasses or telescopes\nto see tiny or distant objects. Such devices enable the observer to\nscrutinize visible objects. The miniscule duration of the current flow\nis not a visible object. Helmholtz studied it by looking at and seeing\nsomething else. (Hooke (1705, 16–17) argued for and designed\ninstruments to execute the same kind of strategy in the\n17th century.) The moral of Feyerabend’s thought experiment\nand Helmholtz’s distinction between perception and artificial\nobservation is that working scientists are happy to call things that\nregister on their experimental equipment observables even if they\ndon’t or can’t register on their senses. \nSome evidence is produced by processes so convoluted that it’s hard to\ndecide what, if anything has been observed. Consider functional\nmagnetic resonance images (fMRI) of the brain decorated with colors to\nindicate magnitudes of electrical activity in different regions during\nthe performance of a cognitive task. To produce these images, brief\nmagnetic pulses are applied to the subject’s brain. The magnetic force\ncoordinates the precessions of protons in hemoglobin and other bodily\nstuffs to make them emit radio signals strong enough for the equipment\nto respond to. When the magnetic force is relaxed, the signals from\nprotons in highly oxygenated hemoglobin deteriorate at a detectably\ndifferent rate than signals from blood that carries less oxygen.\nElaborate algorithms are applied to radio signal records to estimate\nblood oxygen levels at the places from which the signals are\ncalculated to have originated. There is good reason to believe that\nblood flowing just downstream from spiking neurons carries appreciably\nmore oxygen than blood in the vicinity of resting neurons. Assumptions\nabout the relevant spatial and temporal relations are used to estimate\nlevels of electrical activity in small regions of the brain\ncorresponding to pixels in the finished image. The results of all of\nthese computations are used to assign the appropriate colors to pixels\nin a computer generated image of the brain. The role of the senses in\nfMRI data production is limited to such things as monitoring the\nequipment and keeping an eye on the subject. Their epistemic role is\nlimited to discriminating the colors in the finished image, reading\ntables of numbers the computer used to assign them, and so on. \nIf fMRI images record observations, it’s hard to say what was\nobserved—neuronal activity, blood oxygen levels, proton\nprecessions, radio signals, or something else. (If anything is\nobserved, the radio signals that interact directly with the equipment\nwould seem to be better candidates than blood oxygen levels or\nneuronal activity.) Furthermore, it’s hard to reconcile the idea that\nfMRI images record observations with the traditional empiricist notion\nthat much as they may be needed to draw conclusions from observational\nevidence, calculations involving theoretical assumptions and\nbackground beliefs must not be allowed (on pain of loss of\nobjectively) to intrude into the process of data production. The\nproduction of fMRI images requires extensive statistical manipulation\nbased on theories about the radio signals, and a variety of factors\nhaving to do with their detection along with beliefs about relations\nbetween blood oxygen levels and neuronal activity, sources of\nsystematic error, and so on. \nIn view of all of this, functional brain imaging differs, e.g., from\nlooking and seeing, photographing, and measuring with a thermometer or\na galvanometer in ways that make it uninformative to call it\nobservation at all. And similarly for many other methods scientists\nuse to produce non-perceptual evidence. \nTerms like ‘observation’ and ‘observation\nreports’ don’t occur nearly as much in scientific as in\nphilosophical writings. In their place, working scientists tend to\ntalk about data. Philosophers who adopt this usage are free\nto think about standard examples of observation as members of a large,\ndiverse, and growing family of data production methods. Instead of\ntrying to decide which methods to classify as observational and which\nthings qualify as observables, philosophers can then concentrate on\nthe epistemic influence of the factors that differentiate members of\nthe family. In particular, they can focus their attention on what\nquestions data produced by a given method can be used to answer, what\nmust be done to use that data fruitfully, and the credibility of the\nanswers they afford (Bogen 2016). \nIt is of interest that records of perceptual observation are not\nalways epistemically superior to data from experimental equipment.\nIndeed it is not unusual for investigators to use non-perceptual\nevidence to evaluate perceptual data and correct for its errors. For\nexample, Rutherford and Pettersson conducted similar experiments to\nfind out if certain elements disintegrated to emit charged particles\nunder radioactive bombardment. To detect emissions, observers watched\na scintillation screen for faint flashes produced by particle strikes.\nPettersson’s assistants reported seeing flashes from silicon and\ncertain other elements. Rutherford’s did not. Rutherford’s colleague,\nJames Chadwick, visited Petterson’s laboratory to evaluate his data.\nInstead of watching the screen and checking Pettersson’s data against\nwhat he saw, Chadwick arranged to have Pettersson’s assistants watch\nthe screen while unbeknownst to them he manipulated the equipment,\nalternating normal operating conditions with a condition in which\nparticles, if any, could not hit the screen. Pettersson’s data were\ndiscredited by the fact that his assistants reported flashes at close\nto the same rate in both conditions (Steuwer 1985, 284–288). \nRelated considerations apply to the distinction between observable and\nunobservable objects of investigation. Some data are produced to help\nanswer questions about things that do not themselves register on the\nsenses or experimental equipment. Solar neutrino fluxes are a\nfrequently discussed case in point. Neutrinos cannot interact directly\nwith the senses or measuring equipment to produce recordable effects.\nFluxes in their emission were studied by trapping the neutrinos and\nallowing them to interact with chlorine to produce a radioactive argon\nisotope. Experimentalists could then calculate fluxes in solar\nneutrino emission from Geiger counter measurements of radiation from\nthe isotope. The epistemic significance of the neutrinos’\nunobservability depends upon factors having to do with the reliability\nof the data the investigators managed to produce, and its validity as\na source of information about the fluxes. It’s validity will\ndepend, among many other things, on the correctness of the\ninvestigators ideas about how neutrinos interact with chlorine (Pinch\n1985). But there are also unobservables that cannot be detected, and\nwhose features cannot be inferred from data of any kind. These are the\nonly unobservables that are epistemically unavailable. Whether they\nremain so depends upon whether scientists can figure out how to\nproduce data to study them. Such unobservables are discussed in the\nhistory of particle physics (see e.g. Morrison 2015) and neuro-science\n(see e.g., Valenstein 2005). \nEmpirically minded philosophers assume that the evidential value of an\nobservation or observational process depends on how sensitive it is to\nwhatever it is used to study. But this in turn depends on the adequacy\nof any theoretical claims its sensitivity may depend on. For example\nwe can challenge the use of a thermometer reading, e, to\nsupport a description, prediction, or explanation of a patient’s\ntemperature, t, by challenging theoretical claims, C,\nhaving to do with whether a reading from a thermometer like this one,\napplied in the same way under similar conditions, should indicate the\npatient’s temperature well enough to count in favor of or against\nt. At least some of the Cwill be such that regardless of\nwhether an investigator explicitly endorses, or is even aware of them,\nher use of e would be undermined by their falsity. All observations\nand uses of observations evidence are theory laden in this sense. (Cf.\nChang 2005), Azzouni 2004.) As the example of the thermometer\nillustrates, analogues of Norwood Hanson’claim that seeing is a theory\nladen undertaking apply just as well to equipment generated\nobservations.(Hanson 1958, 19). But if all observations and\nobservational processes are theory laden, how can they provide reality\nbased, objective epistemic constraints on scientific reasoning? One\nthing to say about this is that the theoretical claims the epistemic\nvalue of a parcel of observational evidence depends on may be\nquite correct. If so, even if we don’t know, or have no way to\nestablish their correctness, the evidence may be good enough for the\nuses to which we put it. But this is cold comfort for investigators\nwho can’t establish it. The next thing to say is that scientific\ninvestigation is an ongoing process during the course of which\ntheoretical claims whose unacceptability would reduce the epistemic\nvalue of a parcel of evidence can be challenged and defended in\ndifferent ways at different times as new considerations and\ninvestigative techniques are introduced. We can hope that the\nacceptability of the evidence can be established relative to one or\nmore stretches of time even though success in dealing with challenges\nat one time is no guarantee that all future challenges can be\nsatisfactorily dealt with. Thus as long as scientists continue their\nwork there need be no time at which the epistemic value of a parcel\nof evidence can be established once and for all. This should come as\nno surprise to anyone who is aware that science is fallible. But it is\nno grounds for skepticism. It can be perfectly reasonable to trust the\nevidence available at present even though it is logically possible for\nepistemic troubles to arise in the future. \nThomas Kuhn (1962), Norwood Hanson (1958), Paul Feyerabend (1959) and\nothers cast suspicion on the objectivity of observational evidence in\nanother way by arguing that one can’t use empirical evidence to teat a\ntheory without committing oneself to that very theory. Although some\nof the examples they use to present their case feature equipment\ngenerated evidence, they tend to talk about observation as a\nperceptual process. Kuhn’s writings contain three different versions\nof this idea. \nK1. Perceptual Theory Loading. Perceptual\npsychologists, Bruner and Postman, found that subjects who were\nbriefly shown anomalous playing cards, e.g., a black four of hearts,\nreported having seen their normal counterparts e.g., a red four of\nhearts. It took repeated exposures to get subjects to say the\nanomalous cards didn’t look right, and eventually, to describe\nthem correctly. (Kuhn 1962, 63). Kuhn took such studies to indicate\nthat things don’t look the same to observers with different\nconceptual resources. (For a more up-to-date discussion of theory\nand conceptual perceptual loading see Lupyan 2015.) If so, black hearts\ndidn’t look like black hearts until repeated exposures somehow\nallowed subjects to acquire the concept of a black heart. By analogy,\nKuhn supposed, when observers working in conflicting paradigms look at\nthe same thing, their conceptual limitations should keep them from\nhaving the same visual experiences (Kuhn 1962, 111, 113–114,\n115, 120–1). This would mean, for example, that when Priestley\nand Lavoisier watched the same experiment, Lavioisier should have seen\nwhat accorded with his theory that combustion and respiration are\noxidation processes, while Priestley’s visual experiences should\nhave agreed with his theory that burning and respiration are processes\nof phlogiston release. \nK2. Semantical Theory Loading: Kuhn argued that\ntheoretical commitments exert a strong influence on observation\ndescriptions, and what they are understood to mean (Kuhn 1962, 127ff,\nLongino 1979,38-42). If so, proponents of a caloric account of heat\nwon’t describe or understand descriptions of observed results of heat\nexperiments in the same way as investigators who think of heat in\nterms of mean kinetic energy or radiation. They might all use the same\nwords (e.g., ‘temperature’) to report an observation\nwithout understanding them in the same way. \nK3. Salience: Kuhn claimed that if Galileo and an\nAristotelian physicist had watched the same pendulum experiment, they\nwould not have looked at or attended to the same things. The\nAristotelian’s paradigm would have required the experimenter to\nmeasure \nand ignore radius, angular displacement, and time per swing (Kuhn\n1962, 124). \nThese last were salient to Galileo because he treated pendulum swings\nas constrained circular motions. The Galilean quantities would be of\nno interest to an Aristotelian who treats the stone as falling under\nconstraint toward the center of the earth (Kuhn 1962, 123). Thus\nGalileo and the Aristotelian would not have collected the same data.\n(Absent records of Aristotelian pendulum experiments we can think of\nthis as a thought experiment.) \nTaking K1, K2, and K3 in order of plausibility, K3 points to an\nimportant fact about scientific practice. Data production (including\nexperimental design and execution) is heavily influenced by\ninvestigators’ background assumptions. Sometimes these include\ntheoretical commitments that lead experimentalists to produce\nnon-illuminating or misleading evidence. In other cases they may lead\nexperimentalists to ignore, or even fail to produce useful evidence.\nFor example, in order to obtain data on orgasms in female stumptail\nmacaques, one researcher wired up females to produce radio records of\norgasmic muscle contractions, heart rate increases, etc. But as\nElisabeth Lloyd reports, “… the researcher … wired\nup the heart rate of the male macaques as the signal to start\nrecording the female orgasms. When I pointed out that the vast\nmajority of female stumptail orgasms occurred during sex among the\nfemales alone, he replied that yes he knew that, but he was only\ninterested in important orgasms” (Lloyd 1993, 142). Although\nfemale stumptail orgasms occuring during sex with males are atypical,\nthe experimental design was driven by the assumption that what makes\nfeatures of female sexuality worth studying is their contribution to\nreproduction (Lloyd 1993, 139). \nFortunately, such things don’t always happen. When they do,\ninvestigators are often able eventually to make corrections, and come\nto appreciate the significance of data that had not originally been\nsalient to them. Thus paradigms and theoretical commitments actually\ndo influence saliency, but their influence is neither inevitable nor\nirremediable. \nWith regard to semantic theory loading (K2), it’s important to bear in\nmind that observers don’t always use declarative sentences to report\nobservational and experimental results. They often draw, photograph,\nmake audio recordings, etc. instead or set up their experimental\ndevices to generate graphs, pictorial images, tables of numbers, and\nother non-sentential records. Obviously investigators’ conceptual\nresources and theoretical biases can exert epistemically significant\ninfluences on what they record (or set their equipment to record),\nwhich details they include or emphasize, and which forms of\nrepresentation they choose (Daston and Galison 2007,115–190\n309–361). But disagreements about the epistemic import of a\ngraph, picture or other non-sentential bit of data often turn on\ncausal rather than semantical considerations. Anatomists may have to\ndecide whether a dark spot in a micrograph was caused by a staining\nartifact or by light reflected from an anatomically significant\nstructure. Physicists may wonder whether a blip in a Geiger counter\nrecord reflects the causal influence of the radiation they wanted to\nmonitor, or a surge in ambient radiation. Chemists may worry about the\npurity of samples used to obtain data. Such questions are not, and are\nnot well represented as, semantic questions to which K2 is relevant.\nLate 20th century philosophers may have ignored such cases\nand exaggerated the influence of semantic theory loading because they\nthought of theory testing in terms of inferential relations between\nobservation and theoretical sentences.  \nWith regard to sentential observation reports, the significance of\nsemantic theory loading is less ubiquitous than one might expect. The\ninterpretation of verbal reports often depends on ideas about causal\nstructure rather than the meanings of signs. Rather than worrying\nabout the meaning of words used to describe their observations,\nscientists are more likely to wonder whether the observers made up or\nwithheld information, whether one or more details were artifacts of\nobservation conditions, whether the specimens were atypical, and so\non. \nKuhnian paradigms are heterogeneous collections of experimental\npractices, theoretical principles, problems selected for\ninvestigation, approaches to their solution, etc. Connections between\ncomponents are loose enough to allow investigators who disagree\nprofoundly over one or more theoretical claims to agree about how to\ndesign, execute, and record the results of their experiments. That is\nwhy neuroscientists who disagreed about whether nerve impulses\nconsisted of electrical currents could measure the same electrical\nquantities, and agree on the linguistic meaning and the accuracy of\nobservation reports including such terms as ‘potential’,\n‘resistance’, ‘voltage’ and\n‘current’. \nThe issues this section touches on are distant, linguistic descendents\nof issues that arose in connection with Locke’s view that mundane and\nscientific concepts (the empiricists called them ideas) derive their\ncontents from experience (Locke 1700, 104–121,162–164,\n404–408). \nLooking at a patient with red spots and a fever, an investigator might\nreport having seen the spots, or measles symptoms, or a patient with\nmeasles. Watching an unknown liquid dripping into a litmus solution an\nobserver might report seeing a change in color, a liquid with a PH of\nless than 7, or an acid. The appropriateness of a description of a\ntest outcome depends on how the relevant concepts are operationalized.\nWhat justifies an observer to report having observed a case of measles\naccording to one operationalization might require her to say no more\nthan that she had observed measles symptoms, or just red spots\naccording to another. \nIn keeping with Percy Bridgman’s view that \none might suppose that operationalizations are definitions or meaning\nrules such that it is analytically true, e.g., that every liquid that\nturns litmus red in a properly conducted test is acidic. But it is\nmore faithful to actual scientific practice to think of\noperationalizations as defeasible rules for the application of a\nconcept such that both the rules and their applications are subject to\nrevision on the basis of new empirical or theoretical developments. So\nunderstood, to operationalize is to adopt verbal and related practices\nfor the purpose of enabling scientists to do their work.\nOperationalizations are thus sensitive and subject to change on the\nbasis of findings that influence their usefulness (Feest, 2005). \nDefinitional or not, investigators in different research traditions\nmay be trained to report their observations in conformity with\nconflicting operationalizations. Thus instead of training observers to\ndescribe what they see in a bubble chamber as a whitish streak or a\ntrail, one might train them to say they see a particle track or even a\nparticle. This may reflect what Kuhn meant by suggesting that some\nobservers might be justified or even required to describe themselves\nas having seen oxygen, transparent and colorless though it is, or\natoms, invisible though they are. (Kuhn 1962, 127ff) To the contrary,\none might object that what one sees should not be confused with what\none is trained to say when one sees it, and therefore that talking\nabout seeing a colorless gas or an invisible particle may be nothing\nmore than a picturesque way of talking about what certain\noperationalizations entitle observers to say. Strictly speaking, the\nobjection concludes, the term ‘observation report’ should\nbe reserved for descriptionsthat are neutral with respect to\nconflicting operationalizations. \nIf observational data are just those utterances that meet Feyerabend’s\ndecidability and agreeability conditions, the import of semantic\ntheory loading depends upon how quickly, and for which sentences\nreasonably sophisticated language users who stand in different\nparadigms can non-inferentially reach the same decisions about what to\nassert or deny. Some would expect enough agreement to secure the\nobjectivity of observational data. Others would not. Still others\nwould try to supply different standards for objectivity. \nThe example of Pettersson’s and Rutherford’s scintillation screen\nevidence (above) attests to the fact that observers working in\ndifferent laboratories sometimes report seeing different things under\nsimilar conditions. It’s plausible that their expectations influence\ntheir reports. It’s plausible that their expectations are shaped by\ntheir training and by their supervisors’ and associates’ theory driven\nbehavior. But as happens in other cases as well, all parties to the\ndispute agreed to reject Pettersson’s data by appeal to results of\nmechanical manipulations both laboratories could obtain and interpret\nin the same way without compromising their theoretical\ncommitments. \nFurthermore proponents of incompatible theories often produce\nimpressively similar observational data. Much as they disagreed about\nthe nature of respiration and combustion, Priestley and Lavoisier gave\nquantitatively similar reports of how long their mice stayed alive and\ntheir candles kept burning in closed bell jars. Priestley taught\nLavoisier how to obtain what he took to be measurements of the\nphlogiston content of an unknown gas. A sample of the gas to be tested\nis run into a graduated tube filled with water and inverted over a\nwater bath. After noting the height of the water remaining in the\ntube, the observer adds “nitrous air” (we call it nitric\noxide) and checks the water level again. Priestley, who thought there\nwas no such thing as oxygen, believed the change in water level\nindicated how much phlogiston the gas contained. Lavoisier reported\nobserving the same water levels as Priestley even after he abandoned\nphlogiston theory and became convinced that changes in water level\nindicated free oxygen content (Conant 1957, 74–109). \nThe moral of these examples is that although paradigms or theoretical\ncommitments sometimes have an epistemically significant influence on\nwhat observers perceive, it can be relatively easy to nullify or\ncorrect for their effects. \nTypical responses to this question maintain that the acceptability of\ntheoretical claims depends upon whether they are true (approximately\ntrue, probable, or significantly more probable than their competitors)\nor whether they “save” observable phenomena. They then try\nto explain how observational data argue for or against the possession\nof one or more of these virtues. \nTruth. It’s natural to think that computability, range of application,\nand other things being equal, true theories are better than false\nones, good approximations are better than bad ones, and highly\nprobable theoretical claims are better than less probable ones. One\nway to decide whether a theory or a theoretical claim is true, close\nto the truth, or acceptably probable is to derive predictions from it\nand use observational data to evaluate them. Hypothetico-Deductive\n(HD) confirmation theorists propose that observational evidence argues\nfor the truth of theories whose deductive consequences it verifies,\nand against those whose consequences it falsifies (Popper 1959,\n32–34). But laws and theoretical generalization seldom if ever\nentail observational predictions unless they are conjoined with one or\nmore auxiliary hypotheses taken from the theory they belong to. When\nthe prediction turns to be false, HD has trouble explaining which of\nthe conjuncts is to blame. If a theory entails a true prediction, it\nwill continue to do so in conjunction with arbitrarily selected\nirrelevant claims. HD has trouble explaining why the prediction\ndoesn’t confirm the irrelevancies along with the theory of\ninterest. \nIgnoring details, large and small, bootstrapping confirmation theories\nhold that an observation report confirms a theoretical generalization\nif an instance of the generalization follows from the observation\nreport conjoined with auxiliary hypotheses from the theory the\ngeneralization belongs to. Observation counts against a theoretical\nclaim if the conjunction entails a counter-instance. Here, as with HD,\nan observation argues for or against a theoretical claim only on the\nassumption that the auxiliary hypotheses are true (Glymour 1980,\n110–175). \nBayesians hold that the evidential bearing of observational evidence\non a theoretical claim is to be understood in terms of likelihood or\nconditional probability. For example, whether observational evidence\nargues for a theoretical claim might be thought to depend upon whether\nit is more probable (and if so how much more probable) than its denial\nconditional on a description of the evidence together with background\nbeliefs, including theoretical commitments. But by Bayes’ theorem, the\nconditional probability of the claim of interest will depend in part\nupon that claim’s prior probability. Once again, one’s use of evidence\nto evaluate a theory depends in part upon one’s theoretical\ncommitments. (Earman 1992, 33–86. Roush 2005, 149–186) \nFrancis Bacon (Bacon 1620, 70) said that allowing one’s commitment to\na theory to determine what one takes to be the epistemic bearing of\nobservational evidence on that very theory is, if anything, even worse\nthan ignoring the evidence altogether. HD, Bootstrap, Bayesian, and\nrelated accounts of conformation run the risk of earning Bacon’s\ndisapproval. According to all of them it can be reasonable for\nadherents of competing theories to disagree about how observational\ndata bear on the same claims. As a matter of historical fact, such\ndisagreements do occur. The moral of this fact depends upon whether\nand how such disagreements can be resolved. Because some of the\ncomponents of a theory are logically and more or less\nprobabilistically independent of one another, adherents of competing\ntheories can often can find ways to bring themselves into close enough\nagreement about auxiliary hypotheses or prior probabilities to draw\nthe same conclusions from the evidence. \nSaving observable phenomena. Theories are said to save observable\nphenomena if they satisfactorily predict, describe, or systematize\nthem. How well a theory performs any of these tasks need not depend\nupon the truth or accuracy of its basic principles. Thus according to\nOsiander’s preface to Copernicus’ On the Revolutions, a locus\nclassicus, astronomers ‘…cannot in any way attain to true\ncauses’ of the regularities among observable astronomical\nevents, and must content themselves with saving the phenomena in the\nsense of using \nTheorists are to use those assumptions as calculating tools without\ncommitting themselves to their truth. In particular, the assumption\nthat the planets rotate around the sun must be evaluated solely in\nterms of how useful it is in calculating their observable relative\npositions to a satisfactory approximation. \nPierre Duhem’s Aim and Structure of Physical Theory\narticulates a related conception. For Duhem a physical theory \n‘Experimental laws’ are general, mathematical descriptions\nof observable experimental results. Investigators produce them by\nperforming measuring and other experimental operations and assigning\nsymbols to perceptible results according to pre-established\noperational definitions (Duhem 1906, 19). For Duhem, the main function\nof a physical theory is to help us store and retrieve information\nabout observables we would not otherwise be able to keep track of. If\nthat’s what a theory is supposed to accomplish, its main virtue should\nbe intellectual economy. Theorists are to replace reports of\nindividual observations with experimental laws and devise higher level\nlaws (the fewer, the better) from which experimental laws (the more,\nthe better) can be mathematically derived (Duhem 1906, 21ff). \nA theory’s experimental laws can be tested for accuracy and\ncomprehensiveness by comparing them to observational data. Let EL be\none or more experimental laws that perform acceptably well on such\ntests. Higher level laws can then be evaluated on the basis of how\nwell they integrate EL into the rest of the theory. Some data that\ndon’t fit integrated experimental laws won’t be interesting enough to\nworry about. Other data may need to be accommodated by replacing or\nmodifying one or more experimental laws or adding new ones. If the\nrequired additions, modifications or replacements deliver experimental\nlaws that are harder to integrate, the data count against the theory.\nIf the required changes are conducive to improved systematization the\ndata count in favor of it. If the required changes make no difference,\nthe data don’t argue for or against the theory. \nIt is an unwelcome fact for all of these ideas about theory testing\nthat data are typically produced in ways that make it impossible to\npredict them from the generalizations they are used to test, or to\nderive instances of those generalizations from data and non ad hoc\nauxiliary hypotheses. Indeed, it’s unusual for many members of a set\nof reasonably precise quantitative data to agree with one another, let\nalone with a quantitative prediction. That is because precise,\npublicly accessible data typically cannot be produced except through\nprocesses whose results reflect the influence of causal factors that\nare too numerous, too different in kind, and too irregular in behavior\nfor any single theory to account for them. When Bernard Katz recorded\nelectrical activity in nerve fiber preparations, the numerical values\nof his data were influenced by factors peculiar to the operation of\nhis galvanometers and other pieces of equipment, variations among the\npositions of the stimulating and recording electrodes that had to be\ninserted into the nerve, the physiological effects of their insertion,\nand changes in the condition of the nerve as it deteriorated during\nthe course of the experiment. There were variations in the\ninvestigators’ handling of the equipment. Vibrations shook the\nequipment in response to a variety of irregularly occurring causes\nranging from random error sources to the heavy tread of Katz’s\nteacher, A.V. Hill, walking up and down the stairs outside of the\nlaboratory. That’s a short list. To make matters worse, many of these\nfactors influenced the data as parts of irregularly occurring,\ntransient, and shifting assemblies of causal influences. \nWith regard to kinds of data that should be of interest to\nphilosophers of physics, consider how many extraneous causes\ninfluenced radiation data in solar neutrino detection experiments, or\nspark chamber photographs produced to detect particle interactions.\nThe effects of systematic and random sources of error are typically\nsuch that considerable analysis and interpretation are required to\ntake investigators from data sets to conclusions that can be used to\nevaluate theoretical claims. \nThis applies as much to clear cases of perceptual data as to machine\nproduced records. When 19th and early 20th\ncentury astronomers looked through telescopes and pushed buttons to\nrecord the time at which they saw a moon pass a crosshair, the values\nof their data points depended, not only upon light reflected from the\nmoon, but also upon features of perceptual processes, reaction times,\nand other psychological factors that varied non-systematically from\ntime to time and observer to observer. No astronomical theory has the\nresources to take such things into account. Similar considerations\napply to the probabilities of specific data points conditional on\ntheoretical principles, and the probabilities of confirming or\ndisconfirming instances of theoretical claims conditional on the\nvalues of specific data points. \nInstead of testing theoretical claims by direct comparison to raw\ndata, investigators use data to infer facts about phenomena, i.e.,\nevents, regularities, processes, etc. whose instances, are uniform and\nuncomplicated enough to make them susceptible to systematic prediction\nand explanation (Bogen and Woodward 1988, 317). The fact that lead\nmelts at temperatures at or close to 327.5 C is an example of a\nphenomenon, as are widespread regularities among electrical quantities\ninvolved in the action potential, the periods and orbital paths of the\nplanets, etc. Theories that cannot be expected to predict or explain\nsuch things as individual temperature readings can nevertheless be\nevaluated on the basis of how useful they they are in predicting or\nexplaining phenomena they are used to detect. The same holds for the\naction potential as opposed to the electrical data from which its\nfeatures are calculated, and the orbits of the planets in contrast to\nthe data of positional astronomy. It’s reasonable to ask a genetic\ntheory how probable it is (given similar upbringings in similar\nenvironments) that the offspring of a schizophrenic parent or parents\nwill develop one or more symptoms the DSM classifies as indicative of\nschizophrenia. But it would be quite unreasonable to ask it to predict\nor explain one patient’s numerical score on one trial of a particular\ndiagnostic test, or why a diagnostician wrote a particular entry in\nher report of an interview with an offspring of a schizophrenic\nparents (Bogen and Woodward, 1988, 319–326). \nThe fact that theories are better at predicting and explaining facts\nabout or features of phenomena than data isn’t such a bad thing. For\nmany purposes, theories that predict and explain phenomena would be\nmore illuminating, and more useful for practical purposes than\ntheories (if there were any) that predicted or explained members of a\ndata set. Suppose you could choose between a theory that predicted or\nexplained the way in which neurotransmitter release relates to\nneuronal spiking (e.g., the fact that on average, transmitters are\nreleased roughly once for every 10 spikes) and a theory which\nexplained or predicted the numbers displayed on the relevant\nexperimental equipment in one, or a few single cases. For most\npurposes, the former theory would be preferable to the latter at the\nvery least because it applies to so many more cases. And similarly for\ntheories that predict or explain something about the probability of\nschizophrenia conditional on some genetic factor or a theory that\npredicted or explained the probability of faulty diagnoses of\nschizophrenia conditional on facts about the psychiatrist’s training.\nFor most purposes, these would be preferable to a theory that\npredicted specific descriptions in a case history. \nIn view of all of this, together with the fact that a great many\ntheoretical claims can only be tested directly against facts about\nphenomena, it behooves epistemologists to think about how data are\nused to answer questions about phenomena. Lacking space for a detailed\ndiscussion, the most this entry can do is to mention two main kinds of\nthings investigators do in order to draw conclusions from data. The\nfirst is causal analysis carried out with or without the use of\nstatistical techniques. The second is non-causal statistical\nanalysis. \nFirst, investigators must distinguish features of the data that are\nindicative of facts about the phenomenon of interest from those which\ncan safely be ignored, and those which must be corrected for.\nSometimes background knowledge makes this easy. Under normal\ncircumstances investigators know that their thermometers are sensitive\nto temperature, and their pressure gauges, to pressure. An astronomer\nor a chemist who knows what spectrographic equipment does, and what\nshe has applied it to will know what her data indicate. Sometimes it’s\nless obvious. When Ramon y Cajal looked through his microscope at a\nthin slice of stained nerve tissue, he had to figure out which if any\nof the fibers he could see at one focal length connected to or\nextended from things he could see only at another focal length, or in\nanother slice. \nAnalogous considerations apply to quantitative data. It was easy for\nKatz to tell when his equipment was responding more to Hill’s\nfootfalls on the stairs than to the electrical quantities is was set\nup to measure. It can be harder to tell whether an abrupt jump in the\namplitude of a high frequency EEG oscillation was due to a feature of\nthe subjects brain activity or an artifact of extraneous electrical\nactivity in the laboratory or operating room where the measurements\nwere made. The answers to questions about which features of numerical\nand non-numerical data are indicative of a phenomenon of interest\ntypically depend at least in part on what is known about the causes\nthat conspire to produce the data. \nStatistical arguments are often used to deal with questions about the\ninfluence of epistemically relevant causal factors. For example, when\nit is known that similar data can be produced by factors that have\nnothing to do with the phenomenon of interest, Monte Carlo\nsimulations, regression analyses of sample data, and a variety of\nother statistical techniques sometimes provide investigators with\ntheir best chance of deciding how seriously to take a putatively\nilluminating feature of their data. \nBut statistical techniques are also required for purposes other than\ncausal analysis. To calculate the magnitude of a quantity like the\nmelting point of lead from a scatter of numerical data, investigators\nthrow out outliers, calculate the mean and the standard deviation,\netc., and establish confidence and significance levels. Regression and\nother techniques are applied to the results to estimate how far from\nthe mean the magnitude of interest can be expected to fall in the\npopulation of interest (e.g., the range of temperatures at which pure\nsamples of lead can be expected to melt). \nThe fact that little can be learned from data without causal,\nstatistical, and related argumentation has interesting consequences\nfor received ideas about how the use of observational evidence\ndistinguishes science from pseudo science, religion, and other\nnon-scientific cognitive endeavors.First, scientists aren’t the only\nones who use observational evidence to support their claims;\nastrologers and medical quacks use them too. To find epistemically\nsignificant differences, one must carefully consider what sorts of\ndata they use, where it comes from, and how it is employed. The\nvirtues of scientific as opposed to non-scientific theory evaluations\ndepend not only on its reliance on empirical data, but also on how the\ndata are produced, analyzed and interpreted to draw conclusions\nagainst which theories can be evaluated. Secondly, it doesn’t take\nmany examples to refute the notion that adherence to a single,\nuniversally applicable “scientific method” differentiates\nthe sciences from the non-sciences. Data are produced, and used in far\ntoo many different ways to treat informatively as instance of any\nsingle method. Thirdly, it is usually, if not always, impossible for\ninvestigators to draw conclusions to test theories against\nobservational data without explicit or implicit reliance on\ntheoretical principles. This means that when counterparts to Kuhnian\nquestions about theory loading and its epistemic significance arise in\nconnection with the analysis and interpretation of observational\nevidence, such questions must be answered by appeal to details that\nvary from case to case. \nGrammatical variants of the term ‘observation’ have been\napplied to impressively different perceptual and non-perceptual\nprocess and to records of the results they produce. Their diversity is\na reason to doubt whether general philosophical accounts of\nobservation, observables, and observational data can tell\nepistemologists as much as local accounts grounded in close studies of\nspecific kinds of cases. Furthermore, scientists continue to find ways\nto produce data that can’t be called observational without stretching\nthe term to the point of vagueness. \nIt’s plausible that philosophers who value the kind of rigor,\nprecision, and generality to which l logical empiricists and other\nexact philosophers aspired could do better by examining and developing\ntechniques and results from logic, probability theory, statistics,\nmachine learning, and computer modeling, etc. than by trying to\nconstruct highly general theories of observation and its role in\nscience. Logic and the rest seem unable to deliver satisfactory,\nuniversally applicable accounts of scientific reasoning. But they have\nilluminating local applications, some of which can be of use to\nscientists as well as philosophers.","contact.mail":"rtjbog@comcast.net","contact.domain":"comcast.net"}]
