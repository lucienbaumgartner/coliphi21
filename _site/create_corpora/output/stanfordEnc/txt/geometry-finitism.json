[{"date.published":"2002-04-03","date.changed":"2019-09-12","url":"https://plato.stanford.edu/entries/geometry-finitism/","author1":"Jean Paul Van Bendegem","author1.info":"http://www.vub.ac.be/CLWF/members/jean/index.shtml","entry":"geometry-finitism","body.text":"\n\n\nIn our representations of the world, especially in physics,\n(mathematical) infinities play a crucial role. The continuum of the\nreal numbers, \\(\\Re\\), as a representation of time or of\none-dimensional space is surely the best known example and, by\nextension, the \\(n\\)-fold cartesian product, \\(\\Re^{n}\\), for\n\\(n\\)-dimensional space. However, these same infinities also cause\nproblems. One just has to think about Zeno’s paradoxes or the\npresent-day continuation of that discussion, namely the discussion\nabout supertasks, to see the difficulties (see\nthe entry on supertasks in this\nencyclopedia for a full treatment). Hence, it is a very tempting\nidea to investigate whether it is possible to eliminate these\ninfinities and still be able to do physics. The first step towards an\nanswer to that question is to examine whether or not a discrete\ngeometry is possible that can approximate classical continuous\ngeometry as closely as possible. For, if such is the case, the latter\ngeometry can easily be replaced by a discrete version in any physical\ntheory that makes use of this particular mathematical background.\n\nStraightforward as the task may seem, there are however at least\ntwo ways in which the concept of approximation can be\nunderstood. Suppose that \\(T\\) is a physical theory that is based on\nclassical geometry. Then an approximation to \\(T\\) can mean two\ndifferent things:\n\nFor all concepts in \\(T\\), including the geometrical concepts, a\ndiscrete analog is proposed (if such a thing exists), or\n\nAn underlying theory \\(T^\\prime\\) is formulated using possibly\ndifferent concepts in such a way that the classical concepts can be\nderived from \\(T^\\prime\\).\n\nIn the sections that follow an overview will be presented of (some\nof) the various attempts that fall under (a) or (b). However, before\nembarking on this journey, several caveats have to be\nmentioned.\n\nThe most important thing to take into account is, given a\nparticular proposal for a discrete geometry, what the scientific\nand/or philosophical background is of the author(s) and, related to\nthat, what their intentions are. Are they logicians, mathematicians,\ncomputer scientists, physicists or philosophers (to list the five most\nfrequently occurring cases)? Do they want to solve a mere technical, a\nphysical or a philosophical problem? Are they worried about\nfoundational aspects or is the object of their research to further\ndevelop existing theories? It is worthwhile to go into some more\ndetail for each of the five types of author(s) mentioned to illustrate\nthese questions. Logicians are often interested in displaying the underlying logical\nstructure of a theory, physical or mathematical, and in exploring\nwhether or not there are alternatives, usually by changing the\nunderlying logical principles. One could imagine a geometry based not\non classical logic, but, e.g., on intuitionistic logic, where\nprinciples such as the excluded third, i.e., \\(p\\) or not-\\(p\\), for\nany statement \\(p\\), or double negation, i.e., if not-not-\\(p\\) then\n\\(p\\), no longer hold. Often the goal is to find a complete\nclassification of all possibilities. This approach implies that the\nlogician working on and developing discrete models, does not\nnecessarily believe that these models are correct or true in some\nsense. They merely help to understand better what classical geometry\nis. A perfect illustration of such an approach is the work on spatial\nlogic, see Aiello et al. (2007) for an excellent overview. The authors\ncompare their approach to the work done in temporal logic (see\nthe entry on temporal logic in this\nencyclopedia). There are plenty of ways to model time: with a\nstarting and/or final point, discrete or continuous, linear, cyclic or\nbranching, …. The logical task is to construct a language that\nallows one to “talk” about all these structures and to be\nable to differentiate between them. In temporal logic such a language\nuses the operators \\(Fp\\) (“I will be the case that\n\\(p\\)”) and \\(Pp\\) (“It has been the case that\n\\(p\\)”). One example: if time is linear in the future, then this\nproperty can be expressed as follows. Suppose that \\(Fp\\) and \\(Fq\\)\nare given, then only three things are possible: either \\(F(p \\amp\nq)\\), i.e., \\(p\\) and \\(q\\) will be the case, or \\(F(p \\amp Fq)\\),\ni.e., \\(p\\) will happen first and then \\(q\\), or \\(F(Fp \\amp q)\\),\ni.e., the other way round.  In one formula: \\((Fp \\amp Fq) \\rightarrow\n(F(p \\amp q)\\) or \\(F(p \\amp Fq)\\) or \\(F(Fp \\amp q))\\). In an\nentirely similar way, to construct such a language is what spatial\nlogic wants to achieve for geometry and is thus related to the\nproposals that we will discuss in section\n3. A mathematician might be looking at or studying a discrete or\nfinite counterpart of an existing theory just to see, e.g., what\ntheorems remain provable in both cases. This in itself is interesting\nfrom the perspective of so-called reverse mathematics. The core\nquestion is to find out what is necessarily required to prove certain\ntheorems? See, e.g., Simpson (2005) and Stillwell (2016). Proofs that also hold in a\ndiscrete geometry are thus independent from any assumption about\ndiscreteness or continuity.  One might however go deeper into the\nfoundations of mathematics and study finite geometries from a\nfoundational perspective. One such approach is strict finitism\n(although sometimes the terms ultra-finitism or ultra-intuitionism are\nused as well) that is not meant as a subtheory of other foundational\ntheories but as an alternative on its own. It shares with the many\nforms of constructivism the fundamental view that mathematical objects\nand concepts have to be accessible to the mathematician in terms of\nconstructions that can be executed or performed. The various forms are\ndistinguished from one another as to how the concepts of\n“execution” or “performance” are to be\nunderstood. Most constructivists allow for the potentially infinite,\ni.e., if a procedure or algorithm will (provably) terminate at some\nmoment in the future, then the outcome is accepted as\nconstructable. See Bridges & Richman\n(1987) for an overview\nand the entry on\n  constructive mathematics.\nStrict finitism wants to go one step further and argues that an\nindefinite outcome is not be accepted as an outcome, since, as all\ncomputational resources are finite, it could very well be that these\nresources have been used up before the outcome has been reached. The\nadditional qualification serves to make the distinction with\nHilbert’s finitism which, roughly speaking, can be seen as a\nform of finitism on the meta-level (e.g., although mathematical\ntheories can talk about infinite structures, still the proofs in such\ntheories must have a finite length). As might be expected, strict\nfinitism is not a popular view in the philosophy of\nmathematics. Nevertheless a number of proposals have been put\nforward. A history and an account of the actual (though now somewhat\ndated) state of affairs can be found in Welti\n(1987). In section 2 more will be said\nabout such proposals. In the computer sciences the theories and proposals that have been\nput forward are of a quite different nature than the logical and\nmathematical ones, although they do inspire one another. The problem\none faces here is precisely to set up a translation from a classical\ngeometrical, analogous model to a model whereof the domain (usually)\nconsists of the finite set of pixels or cells that make up the\n(computer) screen. The obvious drawback (from the perspective of this\nentry) is that nearly all these models assume the classical (infinite)\nmodel in the background and, hence, do not have a proper foundation of\ntheir own—a situation quite analogous to numerical analysis that\nrelies on classical analysis for proving the correctness of the\nprocedures. Most attention is paid to the problem of proving\ncorrespondences between the original and the discrete model to make\nsure that the image obtained is, in certain respects, faithful to the\noriginal. A simple mathematical example concerns the number of holes\nin a 3-dimensional Euclidean surface. One wants to be sure that every\nhole that shows up in the digital picture does indeed correspond to a\nhole in the original mathematical object. See Borwein & Devlin\n(2009) for more examples. However, that being said, there is some work being done that does not want to rely on the classical continuous background but instead looks for “proper” axiomatisations and/or formalisations of a pixel geometry. See Kulpa (1979) and, more recently, Danielsson (2002) for some nice examples. Note also that these theories should not be confused with computer\nprograms that have the ability to reason about geometrical\nobjects. This is part of the research area of automated\nreasoning—see Chou et al. (1994) for a nice introduction —\nand its basic objects are proofs, not necessarily the mathematical\nobjects the proofs are about. As is commonly known, one of the hot topics in physics is the\nsearch for the unification of quantum (field) theory and general\nrelativity theory. If successful, the famous “Theory of\nEverything” would result. As is equally well-known, the hardest\nproblem to solve is how to deal with space-time. Quantum (field)\ntheory requires space and time as a background, whereas in general\nrelativity the structure of space-time is largely determined by the\nmasses and the energy present.  One way out—and most\nof section 3 deals with such\nexamples—is to find a “deeper” structure that\nunderlies both theories and that, in a sense, generates space and time\nfrom more fundamental concepts. Clearly, if such a theory were to be\nfound, it would not merely produce “just” a model, but it\nwould actually be considered as a genuine representation of\nreality. Most of these models, speculative as some of them may be at\nthe present moment, turn out to be discrete and hence these proposals,\nin contradistinction, e.g., with the logicians, do claim to be a\ncorrect description. For a recent informal overview, see Rovelli (2016), especially chapter 11, “The End of Infinity”. From the historical perspective, it must be added that on and off\nsome physicist tried to find out what discrete counterparts of\nexisting classical physical theories could look like. Usually the\nphilosophical underpinnings of such an attempt tend to be rather\nidiosyncratic. In section 2 one such\nexample will be presented. Typically such attempts did not create a\nmajor stir, they quickly disappeared into the background, but\nnevertheless they do contain some interesting and relevant ideas. In a rather straightforward sense, all of the above involves\nphilosophers as well. Discussions about logical systems, about\nfoundational mathematical theories, about Zeno paradoxes, about\nsupertasks, about what a model and a representation are, …, are\ntypically topics that belong to the domain of the philosophers. In\naddition they bring in arguments from other philosophical and/or\nscientific domains. Suppose that there are excellent arguments from an\nepistemological or ontological perspective, claiming that the world\nshould be considered discrete, then these arguments can support the\nsearch for such a discrete worldview, including the elaboration of a\ndiscrete geometry. Even if from the mathematical point of view, the\ntheory looks rather clumsy or difficult to work with, nevertheless,\nbecause of the philosophical considerations, it has to be so. Without\nsuch supporting arguments, one’s position in such a case would\nbe much weaker. Finally, they also pay attention to the historical\nside of the matter. It is rather striking, but this will not be\npresented here, to see that many proposals have been put forward in\nthe course of our history to demonstrate that space, time and man\nshould be considered finite and/or discrete. See, e.g., Sorabji (1983)\nand Moore (1993) for excellent historical overviews, White (1992)\nfor twentieth-century developments, and Franklin (2017) and Lyons (2017) for some recent contributions. As said, these five groups are the most important ones so\ncompleteness has not been demonstrated and neither has mutual\nexclusiveness been shown. This short overview only meant to list the\ndifferent intentions, motivations, purposes and methodologies of the\nparties involved. The first question to settle is what the classical theory will be.\nAs most of the work that has been done has been limited to the plane,\nthis presentation will also be restricted to that particular case (in\nmost proposals the extension to higher dimensional geometries is\nconsidered to be completely straightforward). But that is not\nsufficient, for there are different routes to follow as to the\npresentation of plane geometry. One possibility is to take any\naxiomatisation of the (Euclidean) plane—say, Hilbert’s\nformulation of 1899 in his Grundlagen der Geometrie—and\nshow what changes are required to have (a) finite models of the\naxiomatic theory, and (b) finite models that approximate the classical\n(infinite, Euclidean) models as closely as possible. One of the very\nfirst attempts dates back to the late 40s, early 50s and will\ntherefore be presented here as an exemplar (in the sense that it has\nboth all the positive qualities required as well as the oddities that\nseem to go together with such attempts). More specifically, it\nconcerns the work of Paul Kustaanheimo in partial collaboration with\nG. Järnefelt in the period between 1949 and 1957. Next a recent\nproposal will be discussed, along totally different lines, of Patrick\nSuppes and a somewhat older proposal of Ludwik Silberstein, where the\ngeometry is directly imbedded in a physical theory, special relativity\ntheory to be precise. The concluding section of this part deals with\nsome specific problems and tentative solutions. What does a Hilbert-type axiomatisation look like? The first thing\none has to do is to fix a (formal) language. Usually one chooses\nfirst-order predicate logic with identity, i.e., a language containing\nnames for variables (and, possibly, for constants), names for\nfunctions (if necessary), names for predicates including the identity\npredicate, logical connectives and quantifiers, and a set of\ngrammatical rules to form sentences. The restriction to first-order\nlogic means that only variables can be quantified over. Without going\ninto details, it should be remarked that a more expressive language\ncan be chosen, e.g., whereby quantification over predicates is allowed\nas well. Once a language has been chosen, the next problem is to determine\nthe primitive terms of the language. For plane Euclidean geometry,\nthese are points and lines, although sometimes lines are defined as\nparticular sets of points. Next the basic predicates have to be\nselected. There exist a number of different axiomatisations at the\npresent moment. The most frequently used predicates are: the incidence\nrelation (“a point \\(a\\) lies on a line \\(A\\)”), the\nbetweenness relation (“point \\(a\\) lies between points \\(b\\) and\n\\(c\\)”), the equidistance relation (“the distance from\npoint \\(a\\) to \\(b\\) is the same as the distance from point \\(c\\) to\n\\(d\\)”), the congruence relation (“a part of a line,\ndetermined by two point \\(a\\) and \\(b\\) is congruent to a part of a\nline, determined by two points \\(c\\) and \\(d\\)”). Note that it\nis not necessary that all of them occur in an axiomatisation. As an\nexample, if lines are not introduced as primitive terms, then usually\nthere is no incidence relation. The next step is the introduction of a set of axioms to determine\ncertain properties of the above mentioned relations. As an example, if\nthe axiomatisation uses the incidence relation, then the typical\naxioms for that relation are: Finally, one looks for an interpretation or a model of the\naxiomatisation. This means that we search for a meaning of the\nprimitive terms, such as points and lines, of the functions (if any)\nand of the predicates in such a way that the axioms become true\nstatements relative to the interpretation. Although we often have a\nparticular interpretation in mind when we develop an axiomatisation,\nit does not exclude the possibility of the existence of rather\nunexpected models. In a sense finitist models rely on this very\npossibility as the next paragraph shows. Paul Kustaanheimo was a member of a group of mathematicians based\nat Helsinki, who were all interested in some form of finite\ngeometry. The most prominent members were G. Järnefelt,\nP. Kustaanheimo, and R.  Lehti. The origin of their inspiration is to\nbe found in the work of J.T. Hjelmslev who developed so-called\n“natural” geometry (“Die natürliche\nGeometrie”, see his 1923 book), also referred to sometimes\nas “physical” geometry. Their approach has not known any continuation, one exception being Reisler and Smith (1969). However, in a strange way there is a\nconnection with Suppes’ approach to be discussed later in the\nsense that geometry is primarily seen as (almost) an experimental\nscience, i.e., the geometer deals with rulers and compasses, creates\nflat surfaces to measure, and so on. Of course, since we humans can\nonly manipulate finite objects in finite ways, a discrete geometry\nmust result. Kustaanheimo’s proposal—I reproduce here in rough\noutline the excellent presentation of his proposal in Welti (1987:\n487–521), which is far more accessible than the original\nwork—is based on the following line of reasoning. A standard\nmodel for the classical axiomatic theory of Euclidean geometry\nconsists of the cartesian product of the real numbers with itself. Or,\nas it is usually formulated, a point in the plane is mapped onto a\ncouple of real numbers, its coordinates. The real numbers have the\nmathematical structure of an infinite field. But finite fields exist\nas well. So why not replace the infinite real number field with a\nfinite field, a so-called Galois field? The best result one could obtain would be that every finite Galois\nfield satisfies most of the axioms of Euclidean geometry. That however\nis not the case. The outcome of Kustaanheimo’s research is\nslightly more complicated: In short, one cannot claim that any finite field will do, but only\nsome and for that matter only part of it. This approach raises some important philosophical questions: In defense of Kustaanheimo’s approach it must be said that\nthe connections between infinite and finite models are usually far\nmore complex than one expects. A finite model is not merely a\nscaled-down version of an infinite model. Very often a different\nstructure appears.  As an analogy take the (infinite set of) natural\nnumbers. Take a finite part, say the numbers 1 up to \\(L\\). In the\nfinite case it makes sense to talk about small and large numbers\ncompared to \\(L\\).  This is classically not possible. So one finds\nadditional structure.  Metaphorically speaking, by making things\nfinite, a more detailed or “fine-grained” structure\nappears, that is wiped out in the presence of infinities. Perhaps the\ndistinction between “good” and “bad”\ngeometrical objects is such an additional feature that disappears in\nthe classical Euclidean model.  Thus perhaps the prime numbers do have\na significance. But still the question remains: is this a new sort of\nPythagoreanism? More details about Kustaanheimo’s approach are\nto be found in the supplementary document:\nFinite Fields as Models for Euclidean Plane Geometry. The originality of Suppes’ approach resides in the fact that\nhe proposes to formulate geometry as a practice of constructions,\ncomparable to Hjelmslev’s work yet quite distinct. A\nconstruction is here to be understood in the elementary sense of\nproducing drawings or diagrams, using certain instruments, such as a\nruler and/or a compass, and not in the modern sense in foundational\nterms, i.e., a constructive, axiomatic foundation for geometry. Two elements are important from the (strict) finitist perspective.\nFirstly, constructions can be formulated in a quantifier-free way; the\nexpression “draw a line” does not imply that we need to\nspeak about the complete set of lines in a plane. “Draw a\nline” will result in a specific finite object, namely a line\nfragment on, e.g., a piece of paper. Secondly, all models considered\nwill be finite, because no matter what constructions are performed,\nthe starting point will always be a finite set of points. Suppes considers two basic operations: the operation \\(B\\), that\ncorresponds with bisecting a line \\(ab\\) and the operation \\(D\\), that\ncorresponds with doubling a line \\(ab\\). A step \\(C_{i}\\) in a\nconstruction consists of three elements: the first element is the\n(new) point to be constructed, the second element is a pair of points\nthat are already present, and the third element is either \\(B\\) or\n\\(D\\), according to what operation is selected. The starting position\nconsists of three given points, \\(a, b\\), and \\(c\\). Example: consider the construction \\(((d, ac, B), (e, bd, D))\\)\nconsisting of two steps. The first step says to start with \\(ac\\) and\nconstruct the mid-point \\(d\\), and in the second step we take the\nsegment \\(bd\\) and double it. A diagrammatic representation makes\nclear what is happening: Figure 1 Starting from the triple \\(a, b\\), and \\(c\\), we have constructed\nthe parallelogram abce. Of course, merely listing a set of constructions is not sufficient\nto talk about a geometrical theory, so it has to be shown, as it is\nindeed done by Suppes, that a formal-axiomatic treatment is possible.\nIt suffices to list a set of necessary axioms about the \\(B\\) and\n\\(D\\) operations, so that one can prove that the figure drawn in the\nexample above is indeed a parallelogram. In addition a representation\ntheorem is proven such that points are attributed rational\ncoordinates. Two important comments must be made. First, it remains to be shown\nthat this elementary geometrical theory can be expanded all the way\ninto a full-fledged geometrical theory that can be considered a\nplausible alternative to classical geometry. Suppes himself seems\nquite confident as he writes: my own conviction is that one can go the entire\ndistance, or certainly almost the entire distance, in a purely\nfinitistic way, … (2001: 136) Secondly, the focus on constructions opens up a novel way to deal\nwith the problem of the distance function. We do not need a general\ndistance function, but, for each separate case, we have to be able to\nattribute coordinates to the points present in the diagram and nothing\nmore. It remains to be seen however whether the basic operations,\n\\(B\\) and \\(D\\), can be extended without losing this important\nproperty. In section 2.5, I will return to the\ndistance problem to present some other solutions that have been put\nforward. First, however, a quite different approach from the physical\nside. In 1936 Silberstein proposes a fairly straightforward discrete\ntheory. The only thing we use in physics are labels, \\(x, y, z, t\\)\nand, when discrete, these can always be labelled with integers. In the\nshort booklet that brings together the five lectures on this theme,\nSilberstein restricts himself to one spatial and one time\nparameter. Although he acknowledges the problem (1936: 15) of higher\ndimensions, he does not deal with it. So the distance problem becomes\nrather trivial since on a line, the discrete distance function and the\nEuclidean distance function coincide. His proposal is elementary in\nthe sense that the smallest distance, viz. the distance between two\nadjacent points \\(x_{i}\\) and \\(x_{i+1}\\) is equal to 1 and likewise\nfor the time coordinate, so that 1 becomes the maximum velocity, put\nequal to \\(c\\), so \\(c = 1\\). Analogs for derivatives are defined,\ndifferential equations are replaced by difference equations, an analog\nin terms of finite differences is derived of the Taylor series and\nmost of classical physics can be imitated. It is worth mentioning that\nthe lectures include a rough calculation of the size of the chronons,\ni.e., the smallest unit of time, and hodons, i.e., the smallest unit\nof (one-dimensional) space. Suppose that \\(a\\) is the number of hodons\nin one centimetre and \\(b\\) the number of chronons in one second, then\n\\[ \\frac{(1/a)}{(1/b)} = \\frac{b}{a} = c = 3.10^{10}\\text{cm/s,}\\quad\n\\text{ or }\\quad b = 3.10^{10}\\cdot a.\\] If we fix a lower limit for\n\\(a\\), say \\(10^{-8}\\) cm (this is actually Silberstein’s\nsuggestion!), then \\(b = 3.10^{10}\\cdot a \\geq 3.10^{18}\\), being the\nnumber of chronons in one second. He further applies the discrete\nspacetime framework to special relativity and here too, an analog is\nfound. Quite interesting in this approach is the fact that additional\nconditions appear that are not needed in the classical case. Here is\none illustration. Special relativity theory relies on the expression, here restricted\nto one spatial dimension, viz., \\(x^{2} - c^{2}t^{2}\\). Thus any\nchange to new coordinates \\(x'\\), \\(t'\\), has to satisfy \\(x^{2} -\nc^{2}t^{2} = x'^{2} - c^{2}t'^{2}\\). Suppose that we write \\(x = ax' +\nbt'\\) and \\(t = cx' + dt'\\), then the inverse relations will be \\[x' =\n\\frac{(dx' - bt')}{(ad - bc)} \\quad\\text{ and }\\quad t' = \\frac{(ax' -\nct')}{(ad - bc)}.\\] If however, \\(x\\), \\(x'\\), \\(t\\) and \\(t'\\) all\nhave to be integers, then necessarily \\(ad - bc = 1\\). This last\ncondition is a pure consequence of the fact that we are thinking in a\ndiscrete way, using integers. In this section three specific problems will be discussed that need\nto be solved if any proposal for a discrete geometry is to be taken\nseriously: the distance function problem, the dimension problem, the\nanisotropy problem, and the identification problem. The distance function problem. There is a rather\ndevastating argument that shows the impossibility of a genuine\ndistance function for a discrete geometry. It dates back to 1949 and\nwas first formulated by Hermann Weyl: If a square is built up of miniature tiles, then\nthere are as many tiles along the diagonal as there are along the\nsides; thus the diagonal should be equal in length to the side. (Weyl\n1949: 43) At least three solutions to this problem have been formulated.  Van Bendegem (1987) argued that in a finite geometry it should be\na basic fact that lines and points have extensions. In particular,\nlines are supposed to have a constant width (independent of the\norientation of the line) \\(N_{D}\\) Thus \\(N_{D}\\) represents a large\n(finite) number, corresponding to the number of squares that form\n\\(N_{D}\\). Given a line, the width is always defined as perpendicular\nto that line. Now suppose that the line has an orientation\ncorresponding to an angle \\(\\alpha\\) between the line and the\n\\(x\\)-axis. Then the width \\(N_{D}\\) of that line, when projected on\nthe \\(x\\)-axis will be \\(\\left[\\frac{N_{D}}{\\sin \\alpha}\\right]\\)\nwhere the expression \\([x]\\) indicates the greatest integer less than\nor equal to \\(x\\).   Figure 2 The distance \\(d\\) between two points \\(p\\) and \\(q\\) is then\ndefined as the number of squares in the rectangle formed by the line\nfrom \\(p\\) to \\(q\\) and the width \\(N_{D}\\), divided by \\(N_{D}\\). The\nidea is that, although in a discrete geometry lines must necessarily\nhave a width, this is not an essential feature, so it can be divided\nout.  Hence: \\(N_{L}\\) here corresponds to the number of layers parallel to the\n\\(x\\)-axis between \\(p\\) and \\(q\\) and \\(n (\\mathrm{div}\\, m)\\) is the\nquotient of the division of \\(n\\) by \\(m.\\)  As an illustration, consider the Weyl problem. Figure 3. We have a right-angled triangle pqr such that for\nsimplicity the right sides \\(pq\\) and \\(qr\\) are equal to one another\nand are aligned with the axes of the grid. Suppose that the number of\nsquares in the right sides is \\(N_{L}\\).  Then since, of course, \\([N_{D}]\\) = \\(N_{D}\\).  However, the hypotenuse\nhas an angle of \\(\\alpha = \\frac{\\sqrt{2}}{2}\\).  Thus, where \\([r]_{n}\\) means the number \\(r\\) up to \\(n\\) decimals. No\ncalculations are needed to show that (a close approximation of) the\nPythagorean theorem holds, i.e., \\(d^{2}(p,q) + d^{2}(q,r) =\nd^{2}(p,r)\\). Finally, there is an easy explanation why the Weyl\nproblem occurs: it corresponds to the limiting case \\(N_{D} =\n1\\). When \\(N_{D} = 1\\), then \\([\\sqrt{2} \\cdot N_{D}] = [\\sqrt{2}] =\n1\\), hence \\(d(p,r) = N_{L} \\cdot 1 = N_{L}\\) and Pythagoras’\ntheorem fails. Although the introduction of a width \\(N_{D}\\) apparently solves\nthe problem, it is equally clear what the drawbacks are. Without\nclassical Euclidean geometry in the background, there is really no way\nto get the construction going. There is no definition of a line in\nterms of the discrete geometry itself, and, above all, the projected\nwidth on the \\(x\\)-axis of a line \\(L\\) is calculated according to a\nEuclidean distance function that is not explicitly mentioned. In\nshort, there is a mixture of two distance functions. Peter Forrest (1995) presents another solution. He starts by\nintroducing a family of discrete spaces \\(E_{n,m}\\), where \\(n\\)\ncorresponds to the “classical” dimension of space and\n\\(m\\) is a scale factor, to be understood as follows: \\(m\\) is a\nparameter to decide when two points are or are not adjacent, which is\nthe basic (and sole) concept of his geometry. Thus in the case \\(n =\n2\\), points are labeled by couples of integers \\((i,j)\\) and two\npoints \\((i, j)\\) and \\((i', j')\\) are adjacent if they are distinct,\nand \\((i-i')^{2} + (j-j') ^{2} \\le m^{2}\\). Once adjacency has been stipulated, a distance function can be\neasily derived: the distance between \\(p\\) and \\(q\\), \\(d(p,q)\\), is\nthe smallest number of “links” in a chain of points\nconnecting \\(p\\) and \\(q\\) such that each one is adjacent to the\nprevious one. Next there is no problem to show that a straight line\npassing through two points is that chain of points that has the\nshortest distance. If the parameter \\(m\\) has a small value, then the resulting\ndistance function is not Euclidean. More specifically, if \\(m = 1\\),\nthen we have, once again, the situation presented by Weyl. But if,\nsay, \\(m = 10^{30}\\) (the figure proposed by Forrest himself), then\nthe situation changes. Then it is possible to show that the distance\nfunction on the discrete space will approximate the Euclidean distance\nfunction as close as one wants. Without presenting all the details,\none can show that a Euclidean distance function \\(d_{E}\\) and the\ndiscrete distance function \\(d\\) are related by a scale factor, i.e.,\n\\(d_{E} \\frac{(p,q)}{d(p, q)} = \\mbox{constant} (m)\\), where the\nconstant is determined by the value of \\(m\\). No calculations are\nneeded once again, to show that the original distance function \\(d\\)\nsatisfies the Pythagorean theorem. If one is looking for a weak point in this approach, then\ninevitably one must end up with the basic notion of adjacency. What is\nthe reason for defining adjacency in Euclidean terms? For, after all,\na condition such as \\((i-i')^{2} + (j-j')^{2} \\le m^{2}\\) looks as\nEuclidean as can be. A possible way out is suggested in Van Bendegem\n(1997). One of the\nadvantages of a discrete approach—and, as a matter of fact, this\nseems to hold in general for strict finitist proposals—is that\ndefinitions that are classically equivalent turn out to be distinct in\na strict finitist framework. Thus, more specifically, a circle can be\ndefined in (at least) two ways: Classically speaking, these two definitions are\nequivalent. However, they are not in a discrete geometry. If, e.g.,\nthe distance function is defined as the lowest number of hodons that\nconnect two given points, then the two definitions are not\nequivalent. Using definition (a), the circle will have the shape of a\nsquare (a well-known fact in so-called taxicab geometry) and thus\nuseless to define adjacency as done above.  Definition (b) on the\nother hand produces a figure that can approximate a Euclidean circle\nas close as one likes. In that way Forrest’s definition for\nadjacency is acceptable within a discrete framework, as no reference\nis made to a Euclidean distance function. The third solution is to be found in Crouse and Skufca (2019),\nwhich presents an interesting synthesis of the two previous proposals\nto solve the distance function problem. What they suggest is a kind of\nphysical interpretation that makes three things possible. Firstly, it\nallows to determine the lowest sizes for hodons and chronons in terms\nof Planck length and time. Secondly, it suggests a definition of the\ndistance from A to B in terms of the distance travelled by a\n“test” hodon (in discrete minimal steps, of course). This\nsolves immediately the anisotropy problem as no directions are\nprivileged. Thirdly, it does not suppose the a priori existence\nof a grid (or a similar structure) as an absolute frame of\nreference. This opens up the possibility to reformulate special\nrelativity theory, which they do. Although Silberstein’s approach\n(see section 2.4 above) is not mentioned, it\nis clearly related and can be considered to be an improvement, as the\nphysical basis is philosophically better motivated. If these proposals and suggestions can be considered to be adequate\nresponses to Weyl’s tile problem, recently another fine example\nof a no-go approach (and accompanying theorem) is to be found in Fritz\n(2013). Start out with an abstract formulation of a periodic graph,\ni.e., a set of vertices and a set of edges. For practical purposes,\nthe periodicity can be thought of as a crystalline structure. This\nmeans that we have a basic finite unit that can cover the whole of the\ngraph through iterated copies of that basic unit. Take as an example a\ntwo-dimensional structure. The vertices can be labeled or\n“weighted” by two numbers \\((i, j)\\). A trajectory\n\\((f_{n})_{n\\in N}\\) is a sequence of weights of vertices, such that\nthe vertices carrying \\(f_{n}\\) and \\(f_{n+1}\\) are connected by an\nedge. Next we define the (macroscopic) velocity of such a trajectory\nas which sounds perfectly acceptable. Example: the trajectory such\nthat \\(f_{n} = (n, 0)\\), starting from \\(f_{0} = (0, 0)\\) will have\nmacroscopic velocity 1, as \\(f_{n} - f_{0} = (n, 0)\\) and, divided by\n\\(n\\), this leaves (1, 0). Without going into the details, he then\nshows that the geometrical structure of all (macroscopic) velocities\nin such a graph cannot correspond to that of Euclidean space. The\nreason is quite simple (though the proofs are not): in the graph there\nwill always be singled-out, “special” directions and\nanisotropy will remain detectable even at the macroscopic\nlevel. Therefore a transition from the discrete level to the\nmacroscopic, continuous, Euclidean and isotropic level is\nexcluded. This is a truly interesting result as it casts a shadow on\nall attempts to use a direct, often rather naive transition from the\ndiscrete to the continuous level. At the same time, it pleads in favor\nof more complex transitions from the microscopic to the macroscopic\nlevel, e.g., by taking into account the width of a line. The dimension problem. Not much attention has been paid to\nthis problem although it is fundamental. If the plane consists of a\ndiscrete set of elements, hodons or atoms, then this set must have\ndimension zero. For, in order to determine the dimension, this set\nmust be equipped with a topology and the only possible candidate is\nthe discrete topology. This entails that the dimension is zero. Either\none takes the option to simply drop the notion of dimension on the\nbasis of the argument that the concept of dimension presupposes a\nconcept of continuity and topology and hence has no finitist\nmeaning. Or one searches for an analog, but it is not clear at all\nwhat that could be.  Something one should not try to do is to derive a\nnotion of dimension from an ordering relation. Suppose that the hodons\nare labeled by integers \\((i, j)\\) in some appropriate coordinate\nsystem, such that \\(-L\\le i\\), \\(j\\le L\\), where \\(L\\) is some upper\nbound. Then quite different ordering relations are possible. One\npossibility is to define \\((i, j) \\lt(k, l)\\) if and only if \\(i + j\n\\lt k + l\\). But another possibility is to define \\((i, j) \\lt(k, l)\\)\nif and only if either \\(i \\lt k\\) or, if \\(i = k\\), then \\(j \\lt\nl\\). It therefore requires additional arguments to claim that among\nall possible order relations on a given set, one and only one has a\nspecial status. However in section 3 we\nwill see that, using the tools of graph theory, a definition of\ndimension can indeed be given. The isotropy problem. If the plane is built up from square\nhodons, as in the paragraph above, then the hodons are arranged in\nsuch a way that every hodon touches four other hodons, i.e., the plane\ncan be modeled as a square grid, then it is obvious that there are\npreferred directions, in this case, there will be two preferred\ndirections. However if instead of squares, hexagons are taken as\nhodons, then there are three preferred directions. Thus no matter what\nthe shape is of the hodon, there will be preferred directions and this\nimplies that the space is anisotropic. Note that these cases are\nnothing but special instances of the general approach of Tobias Fritz,\ndiscussed above. However, for physical applications one would like to\nhave isotropy (or at least as close as possible). Two approaches are possible, that do not fall under the Fritz no-go\ntheorem. Either the hodons have a definite shape or they do not. In\nthe first case it has been suggested that instead of a regular\nperiodic tiling of the plane, one should look for an irregular\naperiodic tiling, such as the Penrose tiling. Figure 4 Although no worked-out examples are available, it seems a promising\nline of attack. In the case of the Penrose tiling it is interesting to\nsee that there are no classically straight lines anymore, precisely\nbecause of the aperiodicity. In the second case vagueness is a\npossible way out. As Peter Forrest in his (1995), and Crouse and Skufca in their (2019) defend, the whole\nidea of a specific representation of a discrete space, e.g., as built\nup from tiny squares is fundamentally mistaken. If a hodon has a\nspecific form, then one cannot avoid asking questions about parts of a\nhodon, such as its border, but that does not make sense if hodons are\nthe smallest spatial entities possible. An intermediate position\ndefended in Van Bendegem (1997) is to consider a series of discrete\ngeometries \\(G_{i}\\), each with a hodon of a particular size,\n\\(h_{i}\\), such that \\(h_{i}\\ne h_{j}\\), for \\(i\\ne j\\) and, in\naddition, there are \\(M\\) and \\(N\\) such that \\(M \\lt h_{i} \\lt N\\),\nfor all \\(i\\). One can then apply a supervaluation technique to the\nseries. This means that a statement will be True (False) if it is true\n(false) in every geometry \\(G_{i}\\).  In all other cases it is\nUndecided, i.e., true in some and false in some others. Now if \\(A\\)\nis the statement “hodons have size \\(\\alpha\\)” (where\n\\(\\alpha\\) is a specific number), this will be Undecided, if a\ncorresponds to at least one of the \\(h_{i}\\). Such an approach however\nintroduces all problems connected with vagueness into the discussion,\nwhich is not necessarily an encouraging situation. For this problem\ntoo, an original answer can be given from within the framework of\ngraph theory. The identification problem. Suppose that we do have a\nfull-fledged discrete geometry and suppose that we replace the\nclassical geometry of a physical theory with the discrete version. We\nwill now be talking about hodons and chronons. The\n“natural” question that arises is what is to be identified\nwith what? Imagine that, in line with Silberstein, we are a bit\nnaïve and would be tempted to identify the hodon with the Planck\nlength, \\(l_{p} = 10^{-35}\\text{m}\\) and the chronon with Planck time,\n\\(t_{p} = 10^{-43}\\text{s}\\). If one now accepts that the maximum\nspeed is one hodon per chronon, then what comes out of this\nidentification is that the maximum speed is indeed \\(c =\n3.10^{8}\\text{m/s}\\). (Note: nothing amazing is happening here, since\nin classical physics, \\(l_{p}\\) is defined as \\(\\sqrt{\\hbar G/c^3},\\)\nand \\(t_{p}\\) as \\(\\sqrt{\\hbar G/c^5},\\) so that it is immediately\nobvious that \\(l_{p}/t_{p} = c\\). Now ask the simple question what\nthe next speed will be, just below \\(c\\)? The answer must be: one\nhodon per two chronons, but that means a velocity of \\(c/2\\). We seem\nto have missed out the whole range between \\(c/2\\) and \\(c\\). There is\na way out, but it supposes that “jerky” motion is\nconsidered possible, an aesthetically quite ugly idea. An object moves\ntwo hodons in two chronons and then waits for one chronon and then\nrepeats the same motion. The average velocity is then \\(2c/3\\). One\npossible way out, that will be briefly mentioned\nin section 3.2, is to introduce an element\nof randomness into the structure. For an appreciation of the full complexity of this topic, going beyond merely numerical relationships, see the excellent overview and discussion of Hagar (2014). As stated in section 1, here we will\ndiscuss proposals that search for a theory or model, underlying a\ngeometrical theory, such that therefrom the classical geometrical\nconcepts can be derived. Obviously one needs to be extremely careful\nas the “danger” is constantly present that infinities\nenter into the picture somewhere unseen or unnoticed. Suppose, to give\na simple example, that only a set of finite points is allowed for, but\nalso an operation that generates between any pair of points a third\npoint different from all points present and there are no restrictions\non the number of times the operation can be applied, then clearly we\nhave here an in infinite number of points “in\ndisguise”. To call such a model a discrete geometrical model\nseems quite inappropriate. One also needs to be very careful about, e.g., claims that quantum\nmechanics deals with discrete values, usually in relation to\nHeisenberg uncertainty principles, hence physics at the basic level is\na discrete theory. That, however, is extremely misleading. It is\nsufficient to consult any handbook on quantum mechanics to observe\nthat the mathematics used requires the full use of infinities. No\nmatter whether one uses Heisenberg’s matrix approach,\nHilbert’s operator formalism, Schrödinger’s wave\nequation or some other formalism, the mathematics involves integrals,\nderivatives, infinite (convergent) sums, spaces with infinite\ndimension, and so on (see the entry on  \nquantum mechanics). \nNot much discreteness to be found here.  This implies\nthat for quantum mechanics as well it is a genuine problem to find a\ndiscrete counterpart. That is clearly demonstrated by the attempts of\nGerard ’t Hooft to reformulate quantum mechanics in a truly\ndiscrete fashion, see ’t Hooft (2014). Interesting to note is\nthat it affects issues such as determinism versus indeterminism. From the historical point of view, no doubt the work of Tullio\nRegge can be seen as a first attempt to develop a model out of which\ngeometrical concepts could be developed. The original paper dates from\n1961, see Regge (1961). More specifically, we are concerned here with\ngeneral relativity theory (GRT). Although the original intention of\nRegge was to construct techniques for solving the equations of GRT in\nthe “difficult” cases, i.e., where there is no symmetry\npresent and perturbation theory is not applicable. Rather than\ntranscribing the differential equations of GRT into difference\nequations, Regge looked for a technique that leads to different\nequations altogether. Without presenting the full details, the core\nconcept of his approach is the “deficit angle”. In GRT we\nare dealing with curved spaces. Take a two-dimensional curved surface.\nIf it is flat, then it can be covered with triangles. If it is curved,\nit can be approximated with triangles, but with an important\ndifference. Suppose that triangles meet at vertices, then we can look\nat one particular point and all the triangles that meet in that point.\nIf that part of the surface is flattened out, there will be a gap\nsomewhere. To this gap corresponds an angle and that is precisely the\ndeficit angle. The larger the curvature, the larger the deficit angle.\nThe same technique works for the four-dimensional case, where instead\nof triangles, simplexes are used. The beauty of this approach is that\nthe equations of GRT can be rewritten in terms of deficit angles and\nlengths of the edges of the simplexes and solved in terms of these\nconcepts. Misner et al. (1973) contains a chapter (42: “The\nRegge Calculus”) that explains Regge’s approach in a\ncompact and perfectly accessible way. Today there is a rather impressive amount of attempts being made.\nMost of them are to be considered as highly speculative as they truly\nreflect the present state of affairs in full development. However\nthere is a remaining set of approaches that slowly start to emerge and\nthat seems to be viable candidates and of interest for a finitist view\nof geometry (in terms of spacetime). It should be noted that for the\nauthors concerned their principal aim is not so much to formulate a\ndiscrete form of geometry but rather to establish whether this or that\nmodel will serve as a common foundation to quantum (field) theory and\nGRT, hence to the whole of physics, so to speak or, if one likes, the\n“Theory of Everything”. Our concern here is actually more\nmodest: do these models tell us anything about how discrete geometries\ncan be formulated such that they generate classical geometry? So, even\nif the physicists were to reject such a model on the basis of good\nsolid physical reasons, it might still be of interest to the question\nof the possibility of discrete geometry. Huggett & Wuthrich (2013a) presents a nice overview of the\npresent-day situation as far as the remaining set is concerned. It is\nworth mentioning that this paper is part of a special issue, Huggett\n& Wuthrich (2013b), on the emergence of spacetime in quantum\ntheories of gravity. Altogether they discuss and evaluate six types of\nproposals but we will consider here only three. The remaining three\nare either too speculative at the present moment or do not involve\ndiscrete spacetimes (such as string theory and non-commutative\ngeometry). The three approaches relevant for our topic are: In order to appreciate how quickly things are evolving in this\nresearch area, one should make a comparison between Huggett &\nWüthrich (2013a) and Meschini et al. (2005), also meant to be a\nsurvey paper. Interestingly enough, Huggett and Wüthrich describe\ntheir survey as complementary to the other one. In the latter paper\nthe work of Manfred Requardt is briefly presented and this will serve\nas a prototypical example because it does not introduce the physical\nside of things right from the start. To have a taste of more\nsophisticated approaches that do involve physics right from the start,\nsee Smolin (2018), where also quantum loop gravity, mentioned directly\nabove, is discussed. Although such approaches, both the basic and the\nsophisticated cases, are not mentioned in the literature on spatial\nlogics, nevertheless the connections between the two are very deep and\nclose and definitely need to be explored further. The starting point is a discrete graph \\(G = \\langle N, C\\rangle\\)\nconsisting of a set \\(N\\) of nodes, \\(n_{i}\\), and a set \\(C\\) of\nconnections, \\(c_{ij}\\), such that no node is connected to itself and\nnodes \\(n_{i}\\) and \\(n_{j}\\) have one connection at most. What seems\nmost obvious is how to define a distance function and in nearly all\nproposals, this is indeed the strategy followed (similar to the\ndefinitions proposed in section\n2.5): \n\\(D(n_{i}, n_{j}\\)) = the smallest number of connections\nthat lead from \\(n_{i}\\) to \\(n_{j}\\).\n It is easy to see that the classical properties of a distance\nfunction are satisfied: At first sight it is not obvious at all how one should proceed\nfurther, but, if one reads the \\(n_{i}\\) and the \\(c_{ij}\\) as a kind\nof vector, then linear combinations can be formed, where \\(f_{i}\\) and\n\\(g_{ij}\\) are, e.g., natural or rational numbers: These two expressions can be read as functions over \\(n_{i}\\) and\n\\(c_{ij}\\). What one needs now is a relation between nodes and\nconnections, so introduce a special function \\(d\\): It is quite interesting to see what happens if we extend the\nfunction \\(d\\) in a linear way so that it can be applied to arbitrary\nfunctions \\(f\\): If we now stipulate that \\(c_{ik} = -c_{ki}\\) (as a kind of vector\nequation, stating that the connections have a direction) then the\nabove expression can be rewritten as follows (take into account that,\nsince no loops are allowed, \\(c_{ii} = 0)\\): Although it is still a long way off, this expression \\(df\\) already\nhas some nice properties that reminds one of a derivative of a\nfunction \\(f\\): However, as is easy to check with the above definitions, the\nproduct rule fails, i.e., \\(d(f\\cdot g)\\) is not equal to \\(df\\cdot g\n+ f\\cdot dg\\). So, to a certain extent, it is possible to construct a basic form\nof calculus on discrete graphs. It does require some ingenuity and\ncreative thought to find the “right” counterparts, but\nthis simple example shows that quite a lot of structure can be derived\nfrom a discrete graph. There is actually more. Discrete graphs allow\nfor a nice solution to the dimension problem, that was mentioned\nin section 2.5. This is the rough\noutline of the idea: Consider a node \\(n_{i}\\), then \\(U_{1}\\) is the set of nodes\n\\(n_{j}\\) such that \\(D(n_{i}, n_{j}) = 1\\), i.e.,\n\\(U_{1}\\) brings together the closest neighbours of\n\\(n_{i}\\). Likewise, we can define \\(U_{2}\\) as the set of nodes\n\\(n_{k}\\) such that \\(D(n_{i}, n_{k})\\) is at most 2. It\nfollows that \\(U_{n} \\subseteq U_{n+1}\\) and so we obtain a nested\nseries of neighbourhoods of \\(n_{i}\\). If one understands dimension as\na measure of the “growth” of the neighbourhoods, then\ndimension can be defined as: One of the interesting features of this definition is that it need\nnot be uniform over the whole graph, for all depends on the choice of\nthe initial node \\(n_{i}\\). But in the case where the graph is\nsufficiently uniform, the dimension will be a constant.  Furthermore\nif we take a classical case, such as 3-dimensional Euclidean space,\nthen the dimensions match. Suppose we have a regular lattice as the\nunderlying graph, then a particular node has a cube as the set of\nnearest neighbours \\(U_{1}\\) consisting of \\(3^{3} = 27\\) points, and\na neighbourhood \\(U_{m}\\) will count \\((m+2)^{3}\\)\nnodes. Therefore Since for \\(m\\) sufficiently large, \\(\\frac{\\ln (m+2)}{\\ln m}\\)\napproximates 1, it follows that \\(\\mbox{Dim} = 3\\). What this shows is\nthat, starting from discrete graphs, we have obtained an extension of\nthe concept of dimension. One may have noticed that this type of\ndefinition is quite similar to some of the definitions used to define\nthe dimension of fractal images. In addition, discrete graphs make it possible to handle the\nanisotropy problem as well. It is sufficient to introduce an element\nof randomness in the network by, e.g., taking averages over a\nconnected set of nodes, to avoid any privileged directions. There are\nclearly similarities here with the irregular tiling scheme or the\nintroduction of vagueness, but the important distinction is that\nstatistical and probabilistic concepts are (fairly) well understood,\nwhereas the tiling problem is, as mentioned, an open problem, and\nvagueness remains a notoriously difficult concept to grasp (see\nthe entry on vagueness in this encyclopedia). It would be a mistake to believe that the different attempts listed\nabove, somehow form a complete catalogue that allows to classify all\npossible approaches. In this paragraph such an exotic example,\nviz. the combinatorial hierarchy, is briefly presented. In this\napproach the focus is not on the equations of physics themselves, but\non the physical constants occurring in them, such as the velocity of\nlight \\(c\\), the Planck constant \\(h\\), the mass of the electron\n\\(m_{e}\\), and so on. As these values are necessarily finite, it seems\nworthwhile to investigate whether a finitist approach can explain why\nthese constants have the values they happen to have.  Such approaches\nare sometimes referred to as “number games”. Let me give one very simple example. Starting from a universe\nconsisting of a finite number of bits, i.e., either 0 or 1, a basic\noperation is introduced, viz., to make a “discrimination”.\nTo express this operation, another operation is needed: addition\nmodulo 2: \\(0 + 0 = 1 + 1 = 0\\) and \\(0 + 1 = 1 + 0 = 1\\). If the\noutcome is 0, then the elements of the sum are not distinguished, else\nthey are. Look now at sets that contain 0 and/or 1, and such that, if\ntwo elements are distinguishable, that element belongs to the set as\nwell. There are exactly 3 \\((= 2^{2}-1)\\) such sets: \\(\\{0\\}, \\{1\\}\\)\nand \\(\\{0,1\\}\\). If these 3 elements are now taken as a new basis\ninstead of 0 and 1, a clever construction shows that 7 \\((= 2^{3}-1)\\)\nsuch sets exists and, in a next step, 127 \\((= 2^{7}-1)\\) pops up.\nNow \\(3 + 7 + 127 = 137\\) and that number is close to the\nelectromagnetic coupling constant. The success of this program has been rather modest as these models\ndo not connect easily to existing physical theories. A self-contained\npresentation of this program is to be found in Bastin & Kilmister\n(1995). There is a very strong similarity with the work of A.S.\nEddington. Not very surprisingly, a presentation of the work of\nEddington on his fundamental theory has been written by Kilmister\n(1994). So far we have explored several theoretical possibilities of a\ndiscrete geometry as a counterpart of classical geometry. Given the\nexamples we discussed in the preceding sections, the relevance for\nphysics seems obvious. Although one might be tempted to believe that\nthe discreteness of space and/or time is a purely theoretical matter,\nnevertheless it is an intriguing question whether the matter could\nalso be of an empirical nature. More concretely, is it imaginable that\nsomehow we could design an experiment such that the outcome is either\nthat space is discrete or that space is continuous? This might sound\nreally far-fetched, but nevertheless the matter has drawn the\nattention of philosophers and a specific experiment has indeed been\nproposed, though at present the circumstances to execute the\nexperiment are unfortunately not feasible. It is quite interesting to see that already in 1961 Paul Feyerabend\nsuggested such a possibility. However not much more is said, as the difficulty of the present situation seems to\nlie in the fact that discrete alternatives for the mathematics, which\nat the present moment is being used in physics, are missing. (1961:\n160) Equally interesting is the fact that Feyerabend too mentions the\nstandard argument that the lack of a Pythagorean theorem is a genuine\nproblem.  His proposal is that we need only assume that measurements in different\ndirections do not commute; and then perhaps we can retain the theorem\nas an operator equation. (1961: 161) Here too, unfortunately, nothing more is said. Peter Forrest (1995)\nmaintains that such an experiment is possible. The fundamental reason\nis that classical mathematics uses continuous variables whereas strict\nfinitist mathematics uses discrete variables. Thus for differentation\nand integration finite analogs must be found and they will approximate\nthe classical case, but never coincide with it. Hence, there will\nalways be small differences and it cannot be excluded that these could\nbe detectable. One such possibility for detection concerns the following curious\nphenomenon. Take the differential equation, \\(df/dx = ax(1 - x)\\). It\nis a straightforward exercise to solve it and one will find a very\nneat continuous solution, whereas if one takes for the discrete case\nthe corresponding difference equation, \\(\\Delta f/\\Delta x = ax(1 -\nx)\\), depending on the value of the parameter \\(a\\), the behaviour of\nthe function \\(f\\) produces chaotic effects, which are absent in the\ncontinuous case. See Van Bendegem (2000) and Welti (1987:\n516–518). The outcome of such an experiment would not be as\nclear-cut as wished for, but to observe chaotic effects means that\nspace is discrete, whereas to observe no chaotic effects means that\neither space is continuous or the hodons are far smaller than we\nimagined. No further progress is to be reported at the present\nmoment. It has been indicated several times in this lemma that different\nscientists with different intentions and aims and with different\nbackgrounds have proposed or propose equally different ideas about\ndiscrete geometry as an alternative for classical geometry. Many\nauthors do not necessarily present more or less complete theories, but\nrather limit themselves to making suggestions and exploring some\nparticular idea. These papers are to be seen as sources of inspiration\nin the search for a full-fledged theory. A few examples are: Hahn\n(1934), Biser (1941), Coish (1959), Ahmavaara (1965a,b), Finkelstein\n(1969) (this is the first of a five paper series with the same title\nin the same journal), Dadić & Pisk (1979), Finkelstein &\nRodriguez (1986), Meessen (1989), Buot (1989), to name but a very\nfew. For the period 1925–1936, Kragh and Carazza (1994) is an\nexcellent overview showing that many physicists were playing around\nwith finitist ideas. The first task to do seems rather straightforward: take any of the\nproposals presented here and elaborate them into a full-fledged\ngeometry. Then it will be possible to make a comparison with, e.g.,\nHilbert’s axiomatisation that was mentioned. The second task\nseems rather forbidding: using this discrete geometry, show how to do\nphysics. In general terms, this is indeed a huge undertaking, but\nthere are two possible routes to follow. The first route is to show\nthat this approach works, say, for classical mechanics. If successful,\nthis would surely count as a major argument in favor of discrete\nproposals. As it happens, some very important work has already been\ndone, for what we will need, is a fully formalized version of\nclassical mechanics, not the textbook versions that leave many things\nunmentioned, but that might prove to be crucial for the underlying\ngeometry. Such versions exist at the present moment, see, e.g., Ax\n(1978), Andréka et al. (2008), Benda (2008), for just a few\nexamples. As it happens, one of the earliest versions involves Patrick\nSuppes, see McKinsey, Sugar & Suppes (1953). Thus the enterprise\nseems to be a genuine possibility. The second route is to explore the\nfundamental research going on in the search for a unification of QFT\nand GRT. Up to some years ago this was all highly speculative, today a\nfew serious contestants are emerging and worth following up. That\nbeing said, both on the mathematical as on the physical level an\nenormous amount of work remains to be done. Probably the best way to\ncharacterize the present-day situation is that some\n“famous” objections to a discrete or finitist approach in\ngeometry have been (partially) answered and that a host of\nmathematical, physical and philosophical suggestions and ideas have\nbeen presented, and partial models have been developed or are being\nelaborated. In other words, the conditions are satisfied that make it\ninteresting to continue this research program.","contact.mail":"jpvbende@vub.ac.be","contact.domain":"vub.ac.be"}]
