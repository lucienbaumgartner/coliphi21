[{"date.published":"2020-08-24","url":"https://plato.stanford.edu/entries/causation-physics/","author1":"Mathias Frisch","author1.info":"https://www.philos.uni-hannover.de/frisch.html","entry":"causation-physics","body.text":"\n\n\nWhat role, if any, do causal notions play in physics? On the one hand,\nit might appear intuitively obvious that physics aims to provide us\nwith causal knowledge of the world and that causal claims are an\nintegral part of physics. On the other hand, there is an influential\nphilosophical tradition, dating back to Ernst Mach and to Bertrand\nRussell’s extremely influential article “On the Notion of\nCause” (1912), denying the applicability or at least the\nusefulness of causal notions in physics. While this tradition is\nperhaps not as dominant today than it once was, there continues to be\na lively and active philosophical debate on whether causal notions can\nplay a legitimate role in physics and, if yes, what role that might\nbe. This entry surveys the main arguments in this debate focusing in\nparticular on arguments appealing to putatively distinguishing\ncharacteristics of theorizing in physics.\n\nIn discussing the role of causation in physics or in our conception of\nthe world more generally we may be engaged in several different\nphilosophical projects (Woodward 2014): a metaphysical\nproject, a descriptive project, and what Woodward calls\na “functional project”. While there are obvious\npoints of contact among these projects and a philosophical account may\ncontribute to more than one project simultaneously, the three projects\nhave distinctly different core aims and are characterized by different\nmethodologies. \nThe aim of the metaphysical project is to uncover the\nmetaphysical grounds or truth-makers for causal claims. The main\ndivision in the metaphysics of causation is between broadly Humean and\nnon-Humean accounts of causation. Humean accounts deny the existence\nof fundamental modalities and maintain that fundamentally the universe\nis composed of a distribution of categorical properties and relations\ninstantiated by localized entities—what David Lewis called the\n“Humean mosaic” (Lewis 1973; Loewer 2012). On the Humean\nview, all true modal claims, including causal claims, are grounded in\nnon-modal features of the mosaic. Even though Humeans deny that modal\nproperties, including causal properties, are part of the world’s\nfundamental ontology, they may allow for the existence of\nnon-fundamental causal facts that are reducible to fundamental\nphysical properties. Thus, Humeans can be—and many of them\nare—non-fundamentalists rather than\neliminativists about\n causation.[1] \nNon-Humeans, by contrast, take fundamental properties to include modal\nproperties, such as nomic necessitation relations, dispositional\nessences, or causal properties. For non-Humeans causal features can be\namong the fundamental building blocks of the world. Some non-Humeans\nhold that the dynamical laws of physics are fundamentally causal laws\nin virtue of which earlier states of a system or of the world produce\nlater states (Maudlin 2007). Others maintain that objects possess\nfundamental dispositions, capacities, or essences that are causal in\nnature (Cartwright 1989; Bird 2007). \nIn contrast with the metaphysical project, the descriptive\nproject aims to describe our causal reasoning practices.\nTraditionally philosophers have tended to conceive of this project as\nhaving as its core aim to provide conceptual analyses of our everyday\nconcept or concepts of cause. A conceptual analysis offers necessary and\nsufficient conditions for claims of the form “c causes\ne”. Regularity accounts, Mackie’s INUS\ncondition account, or David Lewis’s counterfactual analysis are\nall examples of the descriptive project. In principle, the project\ncould appeal to a broad range of data, including empirical work by\npsychologists and cognitive scientists. Generally, however, the\ndescriptive project has focused almost exclusively on probing what\nphilosophers upon reflection take to be commonsense intuitions\nconcerning causal judgements (often involving Billy and Suzy throwing\nrocks or assassins pouring poison in drinks). Those developing\nconceptual analyses tend to focus their analyses on commonsense causal\nclaims rather than on the use of causal notions in physics or in the\nsciences more generally. \nA third project, the functional project, which Woodward\noutlines and defends in (Woodward 2014), asks what kind of functional\nrole causal concepts play in our cognitive architecture and what\npurposes and goals causal cognition can serve. An influential argument\nfor the indispensability of causal concepts is Nancy\nCartwright’s argument that causal notions play a crucial role in\ndistinguishing effective from ineffective strategies (Cartwright\n1979). \nThe functional project has close affinities to what in recent years\nhas been discussed under the term conceptual engineering\n(Cappelen 2018). Conceptual engineering aims to develop precise\nphilosophical concepts that fulfil certain cognitive goals, often\ntaking an existing concept as its starting point, offering a\nphilosophical precissification of this concept and then engaging in an\nassessment of the precissified concept’s usefulness. In taking\nexisting concepts of causation as its starting point the functional\nproject concerning causation engages primarily in what David Chalmers\ncalls “re-engineering” rather than “de novo\nengineering” (Chalmers 2018, see\n Other Internet Resources).\n Unlike the descriptive project, the functional project possesses a\nmethodological or normative dimension, evaluating the usefulness of\ncausal concepts and of types of causal reasoning. \nWoodward (2014) distinguishes “how does causation fit with\nphysics” as a separate philosophical project on a par with the\nmetaphysical, descriptive, and functional projects. Yet the question\nconcerning the fit with physics is best thought of as a question to\nbe addressed within each of the three projects. Indeed, philosophical\ndiscussions examining the fit of causal notions with physics can\nbenefit from distinguishing carefully—and perhaps more carefully\nthan it is often done—among the different projects within which\nthe discussions take\n place.[2] \nThe fit with physics question seems unavoidable for the\nmetaphysical project more generally: if a certain\nmetaphysical account could be shown to be incompatible with the\nfundamental physical theories we accept, then this would constitute a\nreason for rejecting the account, since compatibility with physics\narguably is a condition of adequacy for any metaphysical account of\ncausation. \nFor any metaphysical account compatible with physics the\nquestion arises, what the truth-makers of causal claims are or what\ngrounds these claims. There are three options: (i) either the truth-makers of causal claims\nare physical features of the world, (ii) or they supervene on physical\nfeatures of the world, (iii) or they are non-physical features of the\nworld that do not supervene on physical features of the world. If the\ntruth-makers of causal claims are either physical features or\nsupervene on such features, then the metaphysical account is\ncompatible with the thesis of the completeness of the physical. On the\nthird option, however, the account is incompatible with the\ncompleteness of the physical. \nCausal eliminativists argue that there is no metaphysical\naccount of causation compatible with physics or compatible with the\ncompleteness of physics and, hence, that causal notions should, as\nBertrand Russell (1912) urged, be expunged from the philosophical\nvocabulary. Causal non-eliminativists who are also causal\nnon-fundamentalists can come in various stripes. Some\nnon-fundamentalists allow that non-fundamental causal concepts can be\na legitimate part of at least some domains of physics. Other\nnon-fundamentalists deny the latter claim and reject that causal\nnotions and causal judgements can play a legitimate role within\nphysics. John Norton is a non-fundamentalist who appears to be\nendorsing the former view, arguing that while causal fundamentalism is\nfalse “in appropriately restricted circumstances our science\nentails that nature will conform to one or other form of our causal\nexpectations” (Norton 2003: 13). Yet Norton also seems to have\nsome sympathies for causal eliminativism, since he likens causal\nconcepts to the concept of caloric—a concept that no longer is\naccepted as playing a legitimate role in science. \nWithin the descriptive project we can distinguish two\ndifferent ways of engaging with the fit-with-physics question. Most\nobviously (and what is more prominent in the philosophical literature)\nwe can propose a conceptual analysis of our intuitive, commonsense\nnotion of cause and then ask whether and to what extent the analysans\nalso plays a legitimate role in physics. For example, we might ask to\nwhat extent Lewis’s notion of causal dependence analyzed in\nterms of time-asymmetric counterfactual dependence plays a role in\nreasoning in physics. As we will see below, prominent arguments\ndenying that causal notions fit with physics are most plausibly\nunderstood as engaging in this version of a descriptive project. \nAlternatively, a descriptive project may take physicists’ own\nwidespread use of causal notions, both in research articles and in\nphysics textbooks, as its starting point and proposes an analysis of\nthe underlying causal concepts. Fritz Rohrlich’s proposal that\ncausality has three different meanings in classical physics arguably\nis an example of this project. According to Rohrlich the three\nmeanings are:  \n(a) predictability or Newtonian causality, (b) restriction of signal\nvelocities to those not exceeding the velocity of light, and (c) the\nabsence of “advanced” effects of fields with finite\npropagation velocity. (2007: 50)  \nthe last of which concerns the temporal asymmetry of causation. To\nsome extent Yemima Ben-Menahem (2018) also engages in this project,\nwhen she argues that the concepts of determinism, stability, locality,\nsymmetry and conservation law are all causal concepts. \nSimilarly, we can distinguish two approaches to the fit-with-physics\nquestion within the functional project. For one, we may\nexamine whether certain causal concepts that play useful cognitive\nroles in everyday contexts or in the special sciences also afford a\nlegitimate role to causal reasoning in physics. Woodward\n (2007) takes this approach to the\nfunctional project and explores to what extent interventionist causal\nconcepts that play an essential role in how we navigate the world fit\nwith theorizing in physics. Alternatively, we can take the practices\nof physical theorizing and model-building as starting points and\nexamine whether we can “engineer” causal concepts that\nfulfil certain cognitive functions within these contexts. Ben-Menahem\n(2018) is one of very few philosophers who take this approach to the\nfunctional project. \nSeveral of the most widely-discussed arguments aimed at establishing\nthat there is no legitimate place for causal notions in physics can be\ntraced to the writings of Ernst Mach (1900, 1905) and to Bertrand\nRussell’s extremely influential article “On the Notion of\nCause” (1912). Russell’s target is the notion of cause in\ngeneral, even though some of his arguments appeal to purported\nfeatures of physical theorizing. Mach’s arguments focus more\ndirectly on physics, arguing that there is something distinct about\nphysics that makes it especially inhospitable to causal notions.\nContemporary defenders of neo-Machian and neo-Russellian arguments\ninclude Huw Price (1997; Price & Weslake 2009), Hartry Field\n(2003), John Earman (2011), and, to some extent, John Norton (2003;\n2007;\n 2009).[3] \nNeo-Machian and neo-Russellian arguments have a common structure. They\npoint to some putative conceptual feature of causal relations and then\nargue that suitably fundamental theories of physics are incapable of\ngrounding or incorporating these features (Ney 2016). The following\nfive arguments have been particularly influential: \nThe nineteenth-century physicists Kirchhoff and Mach objected that\ncausal notions are “infected by vagueness” (Kirchhoff\n1876: v, my translation) and “lack the precision” (Mach\n1905: 278, my translation) of the mathematical functional dependencies\nassociated with physical theories. This criticism is echoed in the\ntwenty-first century by John Norton (2003) and John Earman (2011),\namong others. \nWithin the descriptive project the vagueness challenge can be\nunderstood as arguing that our intuitive, commonsense notion or\nnotions of cause are too vague to be given philosophical analyses\nprecise enough to be able to play a legitimate role in the\nmathematized sciences. To the extent that physicists themselves engage\nin causal talk, this has to be understood as part of an informal\nframework within which physicists talk about theories but not as part\nof the formally rigorous and precise content of physical theories\nthemselves (Earman 2011). One could imagine an analogous challenge as\npart of the functional project, even though here the criticism, if\nsuccessful, would point to limits of the project of conceptually\nre-engineering causal notions and would show that causal concepts are\nso vague as to resist sufficient philosophical precissification. \nWithin the metaphysical project the vagueness challenge arguably looms\nespecially large for defenders of metaphysically “rich”\ncausal notions, such as notions of causal production. Here the\nchallenge may be part of more general empiricist scruples about rich\ncausal notions of production or “bringing about” along the\nlines of what has traditionally been taken to be Hume’s\ncriticism of causation. Yet the vagueness challenge can also be\npresented as a challenge to broadly Humean accounts of causation, such\nas David Lewis’s account (Lewis 1973). \nOn most accounts of causation causal claims closely track\ncounterfactual claims. But counterfactual claims are notoriously vague\nand appear to be highly context-dependent. Consider the following\nexample of how the vagueness challenge for counterfactual claims may\narise in combination with the time-asymmetry challenge: imagine a\nfully elastic collision between two billiard balls on a frictionless\nplane. What, if anything, can single out putatively causal\ncounterfactuals of the form “If the balls’ initial state\nprior to the collision had been different, their final state after the\ncollision would be different” from putatively anti-causal\nbacktracking counterfactuals of the form “If the balls’\nfinal state were different, their initial state would have to have\nbeen different”? Newton’s laws underwrite both kinds of\ncounterfactual equally: just as different initial states are\nassociated with different final states, differences in the\nsystem’s final state have to be correlated with differences in\nthe initial state. Within the context of an initial value problem, in\nwhich the initial state of the balls is given and Newton’s laws\nare used to calculate the subsequent motion of the balls, the former\ntype of counterfactual is the appropriate one, while the context of a\nfinal value problem (which asks us to calculate the balls’ prior\nmotion given their final state) suggests the latter type of\ncounterfactual. \nSimilarly, we might ask if hitting one of the balls with a hammer\nexactly as they collide will result in changes to the balls’\nmotion after they collide or before they collide.\nIntuitively it seems that the force exerted by the hammer will\ncausally influence the ball’s subsequent motion. But it is not\nobvious how this verdict is borne out purely by considering\nNewton’s equations: singling out the forward-looking\ncounterfactual as the correct one seems arbitrary. As John Earman\nargues, \nthe exercise of trying to divine the truth value of such\ncounterfactual assertions, even when it is agreed at the outset what\nthe basic laws are, is an invitation to a contest of conflicting\nintuitions about cotenability of conditions and the closeness of\npossible worlds. (Earman 2011: 494) \nDavid Lewis proposes an answer to this concern, arguing that the\ntime-asymmetry of counterfactuals is secured by an asymmetric\noverdetermination of the present by the future (Lewis 1979), but\nLewis’s overdetermination thesis is false in the context of the\ndeterministic theories he considers (Frisch 2005: ch. 8; Loewer 2007).\n \nA successful response to the vagueness challenge would have to show\nthat there exist causal notions that can be reconstructed in a manner\nsufficiently precise to allow these notions to play a role in\nmathematized sciences such as physics. Bayes-net or structural\naccounts of causation (Pearl 2000; Spirtes, Glymour, and Scheines 1993\n[2000]) take up this challenge (see\n section 3\n below). \nMany paradigmatically causal claims relate one cause (or at most a\nvery small set of causal factors) to an effect. Often discussed\nexamples in the literature include “the short circuit caused the\nfire” or “Suzy’s throwing the rock caused the window\nto break”. If one takes it to be an essential characteristic of\ncausal claims that they involve only a small set of fairly localized\ncausally relevant factors—what Norton calls “the dominant\ncauses” (Norton 2003: 17)—acting along clearly\ndistinguishable causal routes, then this gives rise to the following\nargument against the applicability of causal notions in physics (Field\n2003). \nIf we assume that a system is governed by deterministic physical laws,\nthen the laws allow us to derive the occurrence of some event E\nfrom appropriate initial and boundary conditions. What combination of\ninitial and boundary conditions are required depends on the type of\nmathematical equation that express the laws. In the case of hyperbolic\nequations, such as the wave equation, we can formulate a pure initial\nvalue problem. In this case, the event E occurring at spatial\nlocation x and time \\(t_1\\) is derivable from an earlier state\nS specified on a complete initial value surface in a region\nsurrounding x at time \\(t_0.\\) What is important is that\nnothing less than a complete specification of the state on the initial\nvalue surface will allow E to be derived from the\nlaws—the laws are silent on how a system with incompletely\nspecified initial conditions may evolve. That is, (a) we need to\nspecify the initial state in the relevant region completely and in\nwhatever detail the laws at issue require; and (b) the relevant region\ncomprising the initial value surface may be quite large. In the case\nof relativistic theories initial value surfaces consist of entire\ncross sections of the backward lightcone of E. (The backward\nlightcone consists of those events from which a signal traveling at\nmost at the speed of light could reach E.) In the case of\nclassical Newtonian theories, which allow for signals propagating at\narbitrarily high speeds, S would have to amount to the state of\nthe entire universe at some time \\(t_0\\) prior to E. \nIn his seminal article (1912), Russell uses similar considerations to\nargue that the causal law “same cause, same effect” is\neither trivial or false: if the cause of an event E is taken to\ninclude less than a complete specification of all the putatively\ncausal factors relevant to the E’s occurrence, then the\nlaw is false, since then the occurrence of E could then still\nbe disrupted by some external influence not captured within the\nspecification of the set of E’s causes. But once the\nstate S on an initial value surface is fully specified in\nsufficient detail including the entire environment of E, this\nstate will generally be so complex that it is highly likely that a\nstate of exactly this kind will never again occur in the history of\nthe universe. That is, true causal regularities of the form\n“whenever S is instantiated E will occur”\nwill be instantiated at most once. \nWhat, then, is the cause of an event E? It is not enough for\ndefenders of causation simply to give up the principle “same\ncause, same effect”. The challenge, according to the\ndominant cause argument, is to find a criterion that somehow\nallows us to distill a small set of causes from the complete goings-on\non an initial value surface S. And causal skeptics argue that\nphysical theories themselves cannot provide such a criterion. If\ncauses determine their effects, nothing short of the complete state on\nS will classify as the cause or the set of causes of E.\nThis leaves three options, all of which may seem unpalatable for a\ndefender of causation in physics. \nEither we take the entire state on S to be the single cause of\nE. But then causes will in general be highly non-localized\nevents. Or we allow for a very large and potentially infinite set of\ncauses of E at all times t prior to E. But then\nwe have given up on the idea that it is part of the concept of cause\nto single out a small set of factors as being responsible for an\nevent. Or, finally, we concede that whatever considerations allow us\nto single out a small set of factors come from outside of physics. But\nthen, it seems, we have to concede that causal notions do not play a\nrole within physics proper. Isolating a small set of factors as\nthe causes or the dominant causes of an event presupposes a\ndistinction between causes and background conditions. For example, we\nmight take the short-circuit to be a cause of the fire, relegating the\npresence of oxygen and of flammable materials and the prevailing\nmeteorological conditions to the background conditions. Yet, the\nargument claims, such a distinction cannot be drawn on purely physical\ngrounds. Any reason for singling out the short circuit goes beyond a\npurely physical description of the situation and must be driven by\nadding context-dependent or pragmatic considerations. \nThe dominant cause challenge can be raised both as part of the\ndescriptive project and as part of the functional project. Within the\ndescriptive project the claim is that it is part of our commonsense\nnotion of causation that events only have a small number of causes.\nWithin the functional project the claim becomes that singling out a\nsmall set of events as an event’s causes serves important\npurposes in our cognitive architecture that would not be fulfilled by\nany notion of cause allowing for an event to have an arbitrarily large\nset of causes. This claim might be supported by pointing out that\ncausal claims are used to assign responsibility or blame, to single\nout factors that are particularly amenable to interventions into a\nsystem and for control, or to single out factors that we may find\nparticularly salient in a given context—functions that all\nappear to require zeroing in on only a small number of dominant\nfactors as an event’s causes. \nIn response to the dominant cause challenge one can argue that (either\ndescriptively or functionally) we ought to distinguish between more\nstrongly pragmatic causal notions and an objective—or at least\nless context-dependent—core concept of causation. The fact that\na small set of particularly salient or explanatorily relevant causal\nfactors, in a given context, are often singled out as the\ncauses of an event points to a pragmatic dimension of causal talk. Yet\nthis is compatible with allowing for much more complex and\nfine-grained underlying structures, which are causal in a\nnon-pragmatic (or at least less pragmatic) sense of\n“cause”. Our physical theories, according to this view,\ndescribe an arbitrarily complex and appropriately objective causal\nweb, yet in any given explanatory context only an extremely small\nsubset of the web’s nodes is singled out as pragmatically\nsalient causes. \nWithin the descriptive project the reply would have to argue that our\ncommonsense concept of cause is multidimensional in this sense. Within\nthe functional project, the reply could concede that focusing on a\nsmall set of causal factors fulfills certain pragmatic and context\ndependent roles yet maintain that these are not the only functions of\ncausal concepts and causal judgements and that there are other\nfunctions that are compatible with—or even require—a\nbroader notion of what counts as an event’s causes. \nCauses are often taken to act deterministically in accord with the\nprinciple “same cause—same effect”. Indeed, that\ncauses determine their effects is built into many philosophical\naccounts of causation, such as Hume’s regularity account. We\nhave already seen that the demand that causes determine their effects\nputs pressure on the idea that paradigmatic causal claims relate a\nsmall number of localized events to one another. But even considered\non its own the association between determinism and causation can be\nmarshalled in support of an anti-causal argument. \nOne version of the determinism challenge proceeds from the following\ntwo premises. First, according to the most promising accounts of\ncausation, causes act deterministically: a complete set of causes\ndetermines its effects. Second, mature theories of physics are not\ndeterministic. From these premises the argument concludes that\ncause-effect relations cannot be part of our mature theories of\nphysics. \nNorton presents the determinism challenge as part of a more general\nchallenge that any defender of causal notions in physics faces, which\nhe puts in terms of the following dilemma: \nEITHER conforming a science to cause and effect places a restriction\non the factual content of a science; OR it does not. […] In the\nfirst horn, we must find some restriction on factual content that can\nbe properly applied to all sciences; but no appropriate restriction is\nforthcoming. In the second horn, since the imposition of the causal\nframework makes no difference to the factual content of the sciences,\nit is revealed as an empty honorific. (2003: 3–4) \nFor causal notions to play a legitimate role in physics, Norton claims\nthey must do so as part of an acceptable “principle of\ncausality” that provides a universal constraint on all physical\ntheories. What form might such a principle take? The physicist Erwin\nSchrödinger proposed a causal principle that combines some of the\noptions canvased by Norton—determinism, locality, and temporal\nasymmetry: \nthe exact situation at any point P at a given moment is\nunambiguously determined by the exact physical situation within a\ncertain surrounding of P at any previous time, say \\(t -\n\\tau.\\) (Schrödinger 1951: 28). \nIt follows from the existence of successful physical theories that\nviolate the principle either that we have yet to find the\ncorrect principle of causality or that there is no such\nprinciple that constitutes a universal causal constraint. This, Norton\nargues, entails that “the notion of cause is dispensable”\n(Norton 2003: 8). \nThat a principle of determinism is violated in physics receives\nsupport from quantum mechanics—or at least from any\ninterpretation according to which the theory is indeterministic. Yet\nif quantum mechanics were cited as reason for the failure of a\nprinciple of causality, one can try to rescue the principle by\nintroducing a notion of probabilistic causation: causes do not\ndetermine their effects but determine the probabilities of an\neffect’s occurrence. Here, too, Schrödinger can serve as\nexample, who later maintained that \nwhat do change [in the evolution of a quantum state and as a result of\nquantum measurements are] the probabilities; these, moreover,\ncausally. (Schrödinger 1935: 809; quoted in Ben-Menahem 2018:\n92) \nPartly motivated by the probabilistic nature of quantum mechanics,\nphilosophers have developed probabilistic accounts of causation\n(Suppes 1970), according to which the presence of a causes raises (or\nat least changes) the probabilities of its effects. \nNorton (2003) argues that this defense is unsuccessful, since\ndeterminism comes under pressure even in what is often taken to be the\nparadigm of a deterministic theory, Newtonian physics. Norton’s\nexample of an non-deterministic Newtonian system is that of a mass,\nsubject only to gravitational force, initially at rest sitting at the\napex of a dome whose height h depends on the its radius\nr according to \\(h=(2/3g)r^{3/2}.\\) Norton shows that this\nsystem has an infinity of solutions, each corresponding to the mass\nsliding down the dome in some arbitrary radial direction \\(\\cdot\\) at\nsome arbitrary time T. Hence the system is indeterministic and\nfor each particular solution there is nothing to which we can point as\nthe cause of the mass’s beginning to slide down the dome in\ndirection \\(\\cdot\\) at time T. \nIt is unclear, however, whether examples such as this do indeed show\nthat Newtonian mechanics is indeterministic. The force acting on the\nmass, which is given by \\(F=r^{1/2},\\) does not satisfy a continuity\ncondition for \\(r=0\\)—the so-called Lipschitz\ncondition. According to the Cauchy-Lipschitz theorem, the\nLipschitz continuity condition (which, intuitively, restricts how fast\na function can change) is a sufficient condition for the initial value\nproblem to have a unique solution—that is, for the system at\nissue to behave deterministically (“Cauchy-Lipschitz\ntheorem” in\n Other Internet References).\n And one can argue that conditions constraining the allowable force\nfunctions in Newton’s law, such as the Lipschitz condition, are\nan integral part of the content of Newtonian physics. Thus, whether we\ntake Newtonian physics to be deterministic depends on what we take the\ncontent of the theory to be. If what counts as a Newtonian system is\nnot given by Newton’s laws alone but depends on additional\nconditions, including the Lipschitz condition, then the theory is\ndeterministic after all (Fletcher 2012). If the content of the theory\nis given merely by the conjunction of Newton’s laws without\nadditional constraints on allowable force functions, then\nNorton’s example shows that the theory is not deterministic. \nThe determinism challenge can be raised as part of each of the three\nphilosophical projects we distinguished: one might argue that our\nintuitive concept of cause is deterministic or that only a\ndeterministic concept of cause could serve fulfil certain useful\ncognitive functions. But Norton’s dilemma that a causal\nconstraint either has to place a constraint on all\nsciences—that is, is a universal constraint—or\nwould amount to a mere honorific is perhaps most easily resisted\nwithin the functional project. As Woodward (2014) emphasizes, it is\ncompatible with causal judgments playing an important cognitive role\nin some domains that there are limits to the scope of causal thinking\nand that causal concepts are not universally applicable. Thus, the\nusefulness of deterministic causal reasoning might be restricted to\nsome contexts—contexts that may include some theoretical\ncontexts in physics—while there may also be domains in physics\nin which deterministic causal notions are not applicable. Norton\nassumes that a constraint that is not universal is no constraint at\nall, but this assumption can be\n denied. \nNorton’s demand that any causal principle needs to be a\nuniversal principle may be on a stronger footing within the\nmetaphysical project and in fact Norton himself calls his argument\n“the fundamentalist’s dilemma”: If a metaphysical\naccount of causation is committed to the principle “same\ncause–same effect” or even just to a probabilistic version\nof this principle, then the existence of genuine indeterminism in\nphysics of the kind discussed by Norton would pose a serious threat to\nthat account.  \nAccording to many conceptions of causation, causes are local in\nvarious senses: First, causes are synchronically local: they are\n“smallish,” spatially localized events—or at least\ntheir size is proportionate to the size of the effect under\nconsideration. If we demand locality in this sense, then this puts\ninto sharper focus one of the horns of the trilemma posed by the\ndominant cause: we cannot identify the state on an entire\ntime-slice S as the cause of an event in the future of S\non pains of violating the locality constraint that causes be\nspatio-temporally localized. \nCausal relations are also often assumed to satisfy diachronic locality\nconstraints. Broadly such constraints come in two types: according to\nthe first type of constraint causes do not act where they are not.\nThat is, causes do not act across spatial or temporal gaps. According\nto the second type of constraint causal influences do not propagate\ninfinitely fast. The two types of constraint are logically\nindependent. Newtonian gravitational theory violates both types of\nconstraint, but rigid body mechanics violates only the finite-speed\nconstraint while action-at-a-distance versions of classical\nelectrodynamics (that posit particles but not fields) satisfy the\nfinite speed constraint but posit propagation of electromagnetic\ninfluences across spatio-temporal gaps. Classical electrodynamics as\nclassical particle-field theory is the paradigm of a local theory:\ninteractions among charged particles propagate at a finite\nspeed—the speed of light—and are mediated by the\nelectromagnetic field (Frisch 2002). \nLocality constraints come under pressure in quantum mechanics (see\n section 7\n below). One can use this fact as a premise in an anti-causal argument\nparalleling the argument appealing to failures of determinism. \nIn analogy to the case of the determinism challenge, one can resist\nthe conclusion of the argument by denying premise 1 and maintain that\ncausal constraints can play a legitimate and useful role in physical\ntheorizing even if they are not part of a universal principle of\ncausality. Thus, one could maintain that the relativistic constraint\nthat influences do not propagate faster than the speed of light is a\ngenuinely causal constraint, which functions as a desideratum on\nphysical theories but does not lose its legitimacy and importance\nshould it not be satisfied by all successful theories of physics. \nAgain, the challenge may be raised within each of the three\nphilosophical projects, with subtle but important different in each\ncase. Within the descriptive project the argument would aim to show\nthat a certain feature of our common-sense notion of cause does not\nallow this notion to at least some theoretical frameworks in\nphysics. \nWithin the functional project one could argue in defense of premises 2\nand 3 that local causal relations satisfy certain crucial desiderata\nnot satisfied by non-local, putatively causal relations. Some\nwell-known remarks by Albert Einstein concerning the role of locality\nsuggest one route such an argument could take. According to Einstein,\nin a world that is not synchronically and diachronically local\n“physical thought” and “the establishment of\nempirically testable laws in the sense familiar to us” would be\nimpossible (1948: 322; quoted in Howard 1985:\n187–8). Einstein’s remarks suggest an argument according\nto which only causal relations satisfying various locality principles\ncan fulfil cognitively useful functions such as allowing for testable\npredictions and guiding interventions. Yet this line of argument comes\nunder pressure to the extent that quantum systems violate certain\nlocality principles yet allow for testable predictions and\nexperimental interventions (see\n section 7). \nPerhaps the most influential argument for the claim that causal\nnotions cannot play a legitimate role in physics appeals to the fact\nthat the causal relation is generally understood to be asymmetric.\nThis asymmetry is often assumed to coincide with a temporal asymmetry\naccording to which effects do not precede their\n causes.[4]\n This gives rise to the time asymmetry challenge that contrasts the\ntime-asymmetry of causal relations with the purported fact that\nphysical laws make no distinction between the past and future\ndirection. This contrast is offered as a reason for why causal\nrelations cannot be a part of physical theorizing. The time-asymmetry\nchallenge can be represented in premise-conclusion form as\nfollows: \nSome authors respond to this argument by rejecting premise 1, positing\na symmetric notion of causal dependence, which for non-simultaneous\ncause-effect pairs is also time-symmetric (Ney 2009). A potential\nproblem for this response is that it appears to collapse the\ndistinction between the notions of dependence and causation and may\nhave difficulties explaining how a symmetric notion of causal\ndependence (as opposed to an asymmetric notion of causation) can play\na role in elucidating the apparently asymmetric notions of\nintervention, responsibility, or explanation. These problems appear\nespecially pressing from the perspective of the functional project.\nThus, Ney’s proposal is most promisingly considered as part of a\nmetaphysical project of uncovering the metaphysical grounds of causal\nclaims. \nWhat is it for laws to have the same character in the future and past\ndirections? Farr and Reutlinger (2013) point out that this can be made\nprecise in two logically independent ways and that we have to\ndistinguish the claim (i) that the laws are both future and past\ndeterministic from the claim (ii) that the laws are time-reversal\ninvariant. Russell is often interpreted as appealing to (ii), when he\nsays that \nin the motion of mutually gravitating bodies, there is nothing that\ncan be called a cause and nothing that can be called an effect; there\nis merely a formula. (Russell 1927 [2012: 141]) \nMaudlin (2007) points out that on reading (ii) premise 2 is false,\nsince not all the fundamental laws of physics are in fact\ntime-reversal invariant. According to the CPT-Theorem, any plausible\nquantum theory will be invariant under the combination of parity\ntransformation plus charge conjugation plus time reversal. Since there\nis experimental evidence for CP-violations, we should conclude that\nquantum theories violate time-reversal invariance. \nIt has also been argued that even when considering time-reversal\ninvariance the argument applies only to deterministic theories, since\ntheories with non-trivial probabilistic state-transition laws are\ninherently time-asymmetric. As Satosi Watanabe (1965) shows, there can\nbe no genuinely probabilistic theory with both non-trivial forward and\nbackward transition probabilities (see also Healey 1983; Callender\n2000). Thus, if quantum mechanics is understood as a fundamentally\nprobabilistic theory, the argument’s scope is limited to what by\nthe argument defenders’ own lights are the less fundamental\ndeterministic theories of classical physics. \nThe time-asymmetry challenge is sometimes raised in the context of\ndiscussing the interpretation of a theory’s so-called\n“Green’s function”, which specifies how a system\nresponds to a localized point-like disturbance. For example, the\nGreen’s function associated with the wave equation describes the\ncircular ripples on a pond’s surface after a small pebble was\ndropped in. When a theory’s equations are linear, the overall\nresponse of a system to multiple point-like disturbances can be\ncalculated by summing or integrating over all disturbances. The\nimportant mathematical result is that any solution to the\ntheory’s equations can be represented as a sum of two\ncomponents: a sum or integral over the Green’s function for all\nthe point-like disturbances plus a solution to the source-free\nequations. That is, the most general solution to the wave equation\napplied to our pond will consist of sums of ripples associated with\nany pebbles being dropped into the pond plus source-free waves on the\npond not associated with any pebble as their “source”. \nPutting the same point somewhat more formally, any linear differential\noperator L associated with an inhomogeneous differential equation\n\\(\\mathrm{L}y=f(x)\\) and with constant coefficients possesses a\nfundamental solution or Green’s function G, which is a solution\nto the inhomogeneous differential equation \\(\\mathrm{LG}=\\delta (x),\\)\nwhere \\(\\delta(x)\\) is the delta function, a generalized function that\nis zero everywhere except at \\(x=0.\\) The Green’s function tells\nus what the contribution of introducing a point-disturbance or\nperturbation into a system at \\((x', t')\\) is to the state of the\nsystem at some other point \\((x, t).\\) The overall response of a\nsystem at \\((x, t)\\) to multiple perturbations is calculated by\nsumming or integrating over all point-like disturbances. The most\ngeneral solution to a theory is given by adding to this response to\ndisturbances a solution to the homogenous equation\n\\(\\mathrm{L}y=0.\\) \nGreen’s functions, which are broadly applicable in physics, are\nquite naturally interpreted in causal terms, allowing us to represent\nthe state at \\((x, t)\\) as sum of different disturbances as its\ncauses. In fact, Green’s functions provide “a primary\nlocus for causal claims within physics texts” (Smith 2013: 667).\nThe causal significance of the Green function formalism has been\nchallenged, however, by invoking a version of the time-asymmetry\nchallenge. In the case of systems governed by the time-reversal\ninvariant hyperbolic equations (such as the wave equation\nwhich can be derived from the Maxwell-Lorentz equations in classical\nelectrodynamics) any state of a system can be represented either as a\nsum of “causal” or so-called retarded\nGreen’s functions and a solution to an initial value problem of\nthe homogenous, source-free equation \\(\\mathrm{LG}=0;\\) or as a sum of\n“anti-causal” or advanced Green’s functions\nand a solution to a final value problem of the homogenous, source-free\nequation. Both representations are mathematically equivalent\nrepresentations of one and the same state of the system. From this observation the\ntime asymmetry challenge concludes that nothing in the mathematical\nformalism can legitimately distinguish between the different\nrepresentations to single out one representation as the correct causal\nrepresentation. Since interpreting both retarded and advanced\nrepresentations causally is incompatible with the causal asymmetry,\nneither representation ought to be interpreted causally. \nWhile the time asymmetry challenge can be raised for the Green’s\nfunction associated with hyperbolic equations, it is worth pointing\nout that there are also theories or theoretical frameworks in physics\nwith time-asymmetric Green’s functions, chiefly among them\nlinear response theory. There is no philosophical\nconsensus on the causal status of the Green’s function\nformalism. Frisch (2009a; 2009b; 2014) argues for a causal\ninterpretation of the Green’s function formalism, both in the\ncase of the time-reversal invariant wave equation and in the case of\nthe explicitly time-asymmetric linear response theory, while Norton\n(2009) and Smith (2013) are critical of causal interpretations of the\nformalism. \nSome authors have challenged premise 5 of the time-asymmetry\nchallenge, according to which only those features that can be grounded\nin physical laws can play a proper role in physics. In effect, this\npremise implies that the proper content of physics is restricted to\nphysical laws, thereby denying that initial, final, or boundary\nconditions are an integral part of the content of physics. One\nmotivation for this restriction might be the thought that initial or\nfinal conditions are contingent “one-off” states, and\nhence should not count as part of the content of physics, which\nconsists of general claims about the physical world: that a billiard\nball was at rest on a specific spot on a billiard table when it was\nstruck by a second ball is not part of physics but the laws of elastic\ncollision are. But this line of thought ignores that initial\nconditions can also have more general features that are shared across\na wide class of conditions. In fact, many physical situations are\ncharacterized by an asymmetry between prevailing initial and final\nconditions, according to which initial conditions are random while\nfinal conditions are not. And this asymmetry arguably is closely\nrelated to a causal asymmetry (Arntzenius 1992; Maudlin 2007). \nUnder certain plausible assumptions an initial independence or initial\nrandomness assumption allows us to derive a principle of the common\ncause (first proposed by Hans Reichenbach (1956)), according to which\nspatially distant correlated events A and B that are not\nrelated as cause and effect possess a common cause in their past that\nexplains the correlation and screens off the correlation between\nA and B (Arntzenius 1999 [2010]). That is, formally,\nif \nThen there is some event C in the past of A and B\nthat explains the correlation between A and B and which\nsatisfies: \nA central feature of common cause reasoning is that it allows\ninferences from local data without full knowledge of the state of the\nworld (or the state of a larger system) on a complete final value\nsurface—states to which we very often do not have full access.\nCommon-cause reasoning not only is a core function of causal\nrepresentations in commonsense contexts but also is a central and\nineliminable inference pattern in physics. \nAs a particularly vivid example illustrating common-cause inferences\nfrom very limited knowledge of the state of the universe on a final\nvalue surface consider the detection of gravitational waves in 2016,\nwhich, physicists concluded, were emitted by two colliding black\nholes. If we wanted to derive the black hole event within General\nRelativity from knowledge of the data on a complete final value\nsurface, we would have to know the precise state of the universe in a\nsphere with a diameter of many, many light-years—something that\nis obviously impossible for us to know. Instead researchers inferred\nthe black-hole event from the two signals detected locally in the LIGO\ndetectors in Washington and Louisiana, arguing that the extremely\nstrong correlations between the signals detected at both detectors\nsimultaneously are evidence for the colliding black holes as the\nsignals’ common cause. \nImplicit in this causal inference is the assumption that there was no\n“carefully calibrated” gravitational wave coming in from\npast infinity, converging on the location of the postulated black-hole\nevent, and then re-diverging—thereby mimicking a wave produced\nby two colliding black holes. This alternative explanation of the\nsimultaneously detected signals is ruled out as utterly implausible,\nbecause a source free gravitational field coming in from past infinity\nthat mimicked the field associated with the black hole event would\nhave required absurdly strongly correlated initial conditions in\nremote parts of spacetime. By positing an initial randomness\nassumption such seemingly miraculous correlations are effectively\nexcluded. \nNotice, however, that, by contrast with correlations among initial\nconditions, we do not find “absurdly strongly correlated”\nfinal conditions implausible: indeed, correlated final\nconditions are just what we expect as joint effects of a common cause\nsuch as the collapsing of the black holes. \nThe principle of the common cause can be derived within the context of\ndeterministic laws. Yet deterministic laws also appear to undercut the\ntime-asymmetry of common cause inferences. Under determinism, if there\nis an event C in the past of two events A and B\nthat screens A and B off from each other, then there\nwill also be an event C* taking place after A and\nB that occurs exactly if C occurs and that renders the\ntwo events conditionally independent (Arntzenius 1992). In reply to\nthis worry one can argue that future screening-off events, unlike\nthose in the past, will in general be highly non-natural and\nnon-localized (Woodward 2007). Demanding that appropriate physical\nvariables represent localized and not highly gerrymandered events\nallows us to preserve the asymmetry induced by the initial randomness\nassumption. \nThere is broad agreement in the literature that our universe is\ncharacterized by an asymmetry between prevailing initial and final\nconditions, yet there is an ongoing debate what precisely this\nasymmetry entails for the status of the causal asymmetry and for the\ntime-asymmetry challenge (see also\n section 5). \nWhile some authors suggest that time-asymmetric causal relations might\nbe strictly incompatible with time-reversal invariant dynamical laws,\nit is more promising to try and argue that adding time-asymmetric\ncausal relations to physics cannot be justified within physics. It is\nthis latter claim that an appeal to initial conditions and their role\nin underwriting common cause reasoning is meant to challenge. From the\nperspective of the functional project, the central role of\ncommon-cause reasoning both in commonsense and in physics contexts\nprovides perhaps the strongest argument for the claim that the very\nsame—or at least very closely related—causal concepts are\noperative in common sense causal judgements and in causal reasoning in\nphysics. \nWithin the metaphysical project, granting that an asymmetry in initial\nconditions can justify an appeal to causal judgments is compatible\nwith two distinct types of view on the metaphysics of causation. Some\nauthors take the asymmetry between prevailing initial and final\nconditions to be metaphysically primary and maintain that it is this\nasymmetry which grounds our ability to reason causally. Consequently,\non this view, causal relations are metaphysically not on a par with\nnomic relations: while physical laws are nomologically necessary,\ncausal relations are contingent, since the asymmetry between initial\nand final conditions, from which causal relations are derived, is\nmerely a de facto, nomologically contingent asymmetry. This\nview suggests a weaker version of the time-asymmetry argument, which\npoints to the time-reversal invariance of the laws to conclude that\ncausal relations cannot be grounded in the laws but only in a de\nfacto asymmetry between prevailing initial and final conditions.\nThe argument does not deny that causal judgments play a legitimate\nrole in physics but denies that causal relations are metaphysically\nfundamental and affords them a modally weaker status than that of\nphysical laws. That initial conditions are contingent is denied,\nhowever, by Barry Loewer (2007), who argues that the initial\nrandomness assumption comes out as a law according to Lewis’s\nbest system account of laws. \nOther authors, by contrast, take the causal asymmetry (rather than the\ninitial randomness assumption) to be primary, and argue that the\ncausal asymmetry can then explain, account for, or ground the\nasymmetry between prevailing initial and final conditions. Thus,\nHausman and Woodward (1999) argue that the reason why the values of\ninitial variables characterizing initial states are uncorrelated is\nthat these variables do not have common causes in their past. The\ncausal asymmetry, on this view, is explanatorily prior to the\nasymmetry between initial and final states. Similarly, Pearl (2009)\nargues against the view that the initial randomness assumption allows\nus to derive the causal asymmetry from a non-causal premise that the\ninitial randomness assumption should itself be thought of as a causal\nassumption. Maudlin (2007: 133) argues that the asymmetry between\ninitial and final conditions is a manifestation of a more fundamental\nnomic asymmetry, which he however characterizes in strongly causal\nterms as an asymmetry of later states being nomically produced by or\ngenerated from earlier states. \nThe approaches to causation most widely discussed in the philosophical\nliterature in recent decades have been the Bayes net or structural\nmodel accounts of causation developed by Peter Spirtes and his\nco-authors (Spirtes, Glymour, & Scheines 1993 [2000]) and by Judea\nPearl (2000; 2009). The account’s formal framework is also at\nthe heart of Woodward’s highly influential interventionist\naccount of causation and explanation (Woodward 2003a). \nStructural model accounts propose mathematically rigorous and precise\nrepresentations of causal structures. On Pearl’s account, a\nstructural causal model (SCM) consists of a directed acyclic graph\n(representable in terms of a “blobs-and-arrows” diagram)\nover a set of variables \\(V={X, Y, \\ldots}\\) consisting of \nIt is part of the definition of a structural model that the exogenous\nvariables are probabilistically independent of one another (e.g.,\nPearl 2000: 44). From this together with the assumption that a causal\nmodel is complete one can derive the causal Markov condition,\nwhich is a generalized common cause condition and states that for\nevery variable X in V, X is probabilistically\nindependent of the variables in the set \\((V -\n\\textrm{Descendants}(X))\\) conditional on the parents of X. \nThere is a debate in the literature to what extent structural model\naccounts can be applied in physics and what implications these\naccounts have for the role of causation in physics. Frisch\n (2014) proposes that we can\nconstruct causal representations of physical systems by identifying\nthe variables characterizing a system’s initial state with the\nexogenous variables in a causal model and the theory’s\nGreen’s functions with the model’s structural equations\n(see also Lloyd 1996). \nOne can then use the machinery of structural models to derive a common\ncause principle from the initial randomness assumption. In particular,\nthe initial randomness assumption can be used to break the symmetry\nbetween the retarded and advanced Green’s functions for\nhyperbolic equations: Causal model constructed with retarded\nGreen’s functions as structural equations satisfy the\nprobabilistic independence assumption required in the structural model\nframework, while putatively causal models constructed with\n“anti-causal” or advanced Green’s functions violate\nthe probabilistic independence assumption, since in such models the\nhighly correlated variables characterizing a system’s final\nstate functions as exogenous variables. Thus structural model\naccounts may provide an appropriate framework to support the claim that\ncausal inferences and judgments play an important role in physics. \nBy contrast, Pearl (2000) and Woodward (2007) point to an aspect of\nstructural causal models that may make the framework fit less well\nwith at least some aspects of theorizing in physics. Structural causal\nmodels make perspicuous the tight connections between the notions of\ncause and intervention or manipulation. A structural causal model\nprovides us with information on how the values of variables change\nunder external interventions into a system, while causal discovery\nalgorithms allow us to construct causal models from information about\nprobability distributions over the values of variables characterizing\nthe system and information about the effects of interventions. On\nWoodward’s account the notion of causation is spelled out in\nterms of so-called “hard” or “arrow-breaking”\ninterventions. Arrow-breaking interventions allow us to investigate\nhow changes to a variable V percolate through a system, when we\nplace V under the full control of an intervention variable and\nbreak all other causal arrows into V. Yet arrow-breaking\ninterventions may not be possible within the context of certain\nphysical theories. Newtonian gravitational forces, for example, cannot\nbe turned off.  In reply to this worry one can argue that interventions into\nphysical systems may be more adequately modeled in term of\n“soft”, non-arrow breaking interventions, as investigated\nin Eberhardt and Scheines (2007). What the comparative merits of\ncharacterizing causal structures in terms of “hard” or\n“soft” interventions are, is the subject of an ongoing\ndebate. \nPearl (2000) also argues that any account of causation that closely\nlinks causal notions and the notion of interventions cannot be applied\nin the context of a truly fundamental physics that includes models of\nthe universe as a whole. The reason is that global models of the\nuniverse as a whole do not have an “outside” that could be\nrepresented by an intervention variable and from which an intervention\ninto the universe could take place. Yet Pearl’s own do-calculus\nfirst introduces interventions formally in a way that does not posit\nintervention variables external to the causal model of interest.\nNonetheless, interventions into the universe as a whole are not\nphysically possible. Here the question concerning interventions in\nfundamental physics makes contact with another issue on which there is\nan active debate: the question on appropriate constraints on allowable\ninterventions and the question to what extent interventions need to be\nphysically or conceptually possible. \nTaking a somewhat broader view, the worry concerning global models\narises from a conception of physics that is widely held by\nphilosophers—a conception according to which one of the\nfundamental aims of physics is to present us with global dynamical\nmodels of the dynamical laws that adequately represent the universe as\na whole. The worry then is that causal models, in particular on an\ninterventionist conception of cause, cannot get a foothold within such\na globalist conception of physics. This globalist conception can be\ncontrasted with one according to which the laws of physics are\nunderstood as rules governing localized subsystems of the universe\n(Ismael 2016; see also Cartwright 1999). Defenders of the latter\nconception would argue not only that it can more easily accommodate\ncausal reasoning than the globalist picture but also that it fits the\nday-to-day practice of most of physics considerably better than the\nglobalist conception. \nConserved quantity accounts of causation are reductive accounts of\ncausation that are explicitly designed to locate causation within the\nrealm of physics avoiding the vagueness challenge. Most\nprominent here is the causal process account first proposed by Wesley\nSalmon (1984) and developed further in Phil Dowe’s conserved\nquantity account (Dowe 2000; see also Kistler 1999 [2006]). Proponents\nof conserved quantity accounts take their accounts to contribute to\nthe metaphysical project of determining objective causal structures\nthat serve as truth-makers of causal claims. \nDowe distinguishes causal processes and causal interactions, which he\ndefines as follows: \nConserved quantities are those quantities, such as energy, momentum,\nmass, or charge, that are conserved according to our physical\ntheories. By deriving its inspiration from physics, where conservation\nlaws play a central role, conserved quantity accounts promise to be\nable to meet the neo-Machian and neo-Russellian challenges. In fact,\nsince, according to Noether’s First Theorem, there is a\nconservation law associated with each continuous symmetry property of\na system, there seems to be a clear formal route for locating causal\nclaims within physics. \nIt is unclear, however, how broadly applicable Dowe’s account\nis. Classical electrodynamics satisfies energy-momentum conservation.\nYet while charged particles are associated with world lines, the\nelectromagnetic field, with which charged particles interacts, cannot\nbe associated with a world line along which energy is conserved. As\nMarc Lange (2002) has argued, it is problematic to think of the\nelectromagnetic field energy as a kind of “stuff” that\nflows in a uniquely identifiable manner among different field-regions.\nThus, Dowe’s conserved quantity account appears to be designed\nfor an ontology of discrete objects and it is unclear how the account\nmight be extended to cover field theories as well. \nWhile conserved quantity accounts offer an analysis of the notion of\nbeing causally related, they do not, on their own, provide a\ndistinction between cause and effect. To introduce the direction of\nthe causal relation, Dowe supplements his conserved quantity account\nby appealing to Reichenbach’s fork asymmetry (1956).\nReichenbach distinguishes forks that are temporally open from forks\nthat are closed. If there is an event C occurring in past that\nscreens off A from B, but there is no screening-off\nevent in the future of A and B, then this constitutes an\nopen fork. If there is an event C in the past and in addition\nan event \\(C'\\) in the future of A and B that screen off\nA from B, we have a closed fork. Now,\nReichenbach’s fork asymmetry thesis consists in the claim that\nall open forks are open toward the future. Dowe (2000: 204) defines\nthe direction of causal processes by the direction of the majority of\nopen forks (thereby, in principle, allowing for the possibility of\nbackward causation).  \nThus, in order to define the direction of causation, the conserved\nquantity accounts need to be supplemented by probabilistic\ninformation. It has also been argued that conserved quantity accounts\ncannot adequately distinguish those features of a process that are\nexplanatorily relevant from those that are not without relying on\ncounterfactuals (Woodward 2003b [2019]). Earman (2014) argues that the\nmost appropriate way to characterize causal processes is in terms of\nsystems governed by equations that allow for a well-posed initial\nvalue formulation, which are systems governed by hyperbolic equations\n(see also Woodward 2016). \nSeveral authors have argued that the causal asymmetry and the\ndirection of causation are closely related to the thermodynamic\nasymmetry that the entropy of a closed system does not decrease. An\nearly discussion of possible connection between the two\n“temporal arrows” occurs in Reichenbach (1956). More\nrecent discussions of connections between the two arrows argue more\nperspicuously that the thermodynamic and the time-asymmetry of\ncausation have as their common origin the initial randomness\nassumption or the assumption of initial microscopic chaos. The\nassumption of initial microscopic chaos is a central assumption in\nneo-Boltzmannian accounts of the thermodynamic asymmetry. These\naccounts posit a cosmological hypothesis, according to which the\nuniverse began its life in an extremely low entropy state \\(M(0),\\)\nwhich Richard Feynman has dubbed the Past Hypothesis (1965),\ntogether with an equiprobability distribution over all microstates\ncompatible with \\(M(0).\\) David Albert and Barry Loewer argue that the\npackage consisting of past hypothesis, probability postulate, and the\ndynamical laws on the microlevel—a package they call the\nMentaculus after the Coen Brother’s movie A Serious\nMan—not only can account for the thermodynamic asymmetry\nbut also provides the probabilities for every macroscopic\ngeneralization as well as the machinery to ground the causal asymmetry\nand epistemic asymmetries concerning our access to past and future\nevents (Albert 2000, 2015; Loewer 2007, 2012). \nWhile on Albert and Loewer’s account the causal asymmetry is\nultimately grounded in the probability postulate, they attempt to\nderive this asymmetry via a somewhat circuitous route. The first step\nis to argue that the Mentaculus implies a branching tree structure\ntoward the future on the macrolevel, according to which the\nuniverse’s macrostate at a time is compatible with many more\ndifferent macro-evolutions toward the future than macro-evolutions\ntoward the past. In a second step they argue that this branching tree\nstructure underwrites an asymmetry of counterfactual dependence on the\nmacro-level and thereby supports a broadly Lewisian counterfactual\nanalysis of the temporal arrow of causation. The claim that the\nMentaculus implies a temporally asymmetric branching tree structure of\nthe kind postulated by Loewer is criticized in Frisch (2010): since\nfuture higher entropy macro states occupy vastly larger regions of\nphase space than lower entropy past states, thermodynamically normal\nevolutions, if anything, suggest an upside-down tree\n structure. \nOther authors have proposed more direct arguments for deriving the\ncausal asymmetry from assumptions made in the foundations of\nthermodynamics, than the one developed by Albert and Loewer, arguing\nthat we can derive the common cause principle and thereby the\ndirection of causation directly from the assumption of initial\nprobabilistic independence. For a large class of microscopic\nconditions the probabilistic independence assumption follows from the\nassumption of initial microscopic chaos (Horwich 1987; Papineau\n1985). In particular, as Arntzenius argues, the probabilistic\nindependence assumption will be satisfied for spatially separated\nmicrostates if we assume initial microscopic chaos (Arntzenius 1999\n[2010]). There is also an active debate in the literature on how the\ncausal and thermodynamic asymmetries relate to various epistemic\nasymmetries, such as an asymmetry of records or an asymmetry\nconcerning our epistemic access to the past and to the future. For\ndifferent accounts of the knowledge asymmetry and an asymmetry of\nrecords see Horwich 1987; Albert 2000, 2015; Loewer 2007; Frisch 2007,\n2014; and Ismael 2016. \nMost authors exploring the connection between the thermodynamic and\ncausal asymmetries argue that the causal asymmetry is ultimately\ngrounded in some facts about the initial state of the universe. Some\nauthors, however, have argued that the explanatory direction is\nreversed and that the causal asymmetry accounts for the asymmetry\nbetween prevailing initial and final conditions. Maudlin has argued\nthat the difference between initial and final conditions is a\nreflection of causal laws that, he maintains, underwrite the passage\nof time (Maudlin 2007: 131).  \nElectromagnetic radiation phenomena exhibit a temporal asymmetry: we\nobserve radiation coherently diverging from a radiating source, such\nthe light emitted by a star, but we do not observe radiation\ncoherently converging into a source, unless we delicately set up such\na system. What can explain this asymmetry? And how is the asymmetry\nrelated to the causal asymmetry, on the one hand, and the\nthermodynamic asymmetry, on the other? Debates on these questions have\na long history. On one side we find both physicists and philosophers\nwho maintain—in the case of physicists sometimes more, sometimes\nless explicitly—that the “arrow of radiation” is a\nmanifestation of a causal asymmetry (Ritz 1908; Einstein 1909a;\nJackson 1999; Griffiths 2017; Rohrlich 2006; Frisch 2005; 2006;\n2014). On the other side, there are physicists and philosophers who\nmaintain that the arrow of radiation has the same root as the\nthermodynamic arrow, an asymmetry between prevailing initial and final\nconditions (Einstein 1909b; Wheeler & Feynman 1945; Price 1997;\n2006; North 2003; Zeh 2007; Earman \n2011).[5] \nThis debate is far from settled. The laws of classical\nelectrodynamics, the Maxwell-Lorentz equations, imply a wave equation,\nwhich is a time-reversal invariant hyperbolic equation of motion and\nis standardly solved using the Green’s functions formalism.\nThus, the disagreement is partly a disagreement over the question\nwhether the radiation field’s causal or retarded Green’s\nfunction captures important features of how charged particles and\nelectromagnetic fields interact that are not properly captured by the\n“anti-causal” or advanced Green’s functions. \nSome authors argue that the asymmetry of radiation is, like the\nthermodynamic asymmetry purely a macroscopic phenomenon (Price 1997;\nField 2003). But this claim is not borne out by how physicists treat\ninteractions between charges and fields. To the extent that\nmicroscopic charged particles can be (and in fact are) modeled\nclassically, their interactions with fields are modeled as exhibiting\ntemporal asymmetries just as macroscopic field sources do (Jackson\n1999). These asymmetries include the fact that accelerating\nmicroscopic charged particles are damped (since they radiate off part\nof the energy they receive), rather than being anti-damped (extracting\nadditional energy from the surrounding field) (Rohrlich 2007). Thus, whatever the correct account of the\nasymmetry of radiation is, it has to apply to microscopic charged\nparticles as well as to macroscopic collections of charges. \nAuthors who try to derive the radiation arrow from probabilistic\nconsiderations sometimes argue that coherently converging waves do not\noccur because such waves would require a radically improbable\ncoordinated behavior of incoming waves (Earman 2011; see also Atkinson\n2006). But this line of argument is in danger of committing what Price\nhas called “the temporal double-standard fallacy” (Price\n1997). From an acausal perspective the coordinated behavior of\noutgoing waves in the future of a radiating source should appear to be\nno less improbable than coordinated behavior of incoming waves in the\npast of the source. Thus, probabilistic accounts that deny a\nfundamental causal asymmetry need to be careful to avoid probabilistic\narguments for the asymmetry ultimately driven by causal intuitions and\npresumably have to be content with positing the initial randomness\nassumption as a fundamental de facto asymmetry that cannot be\nfurther justified. \nIt is important here, too, to be clear on what is at stake in the\ndebate. Within the metaphysical project, the debate concerns the\nquestion what the fundamental grounds for the asymmetry of radiation\nphenomena are: is the asymmetry an expression of a fundamental causal\nasymmetry or is it due to an asymmetry between prevailing initial and\nfinal conditions? \nFrom the perspective of a purely functional project, by contrast,\nthere is less disagreement between these two views than it may\ninitially seem. From a functionalist perspective, defenders of a\ncausal picture and defenders of a probabilistic account can be\nunderstood as emphasizing two different aspects that both are integral\nfeatures of causal models: an initial independence assumption and\ndirected causal relationships among variables. Thus, certain\ncriticisms of causal accounts of the asymmetry of radiation, such as\nEarman (2011), are most charitably understood as attacking a\nmetaphysical account of the role of causation in accounting for\nradiation phenomena. Earman’s criticism cannot undermine a\nfunctional account of causation in physics, since it invokes the very\nsame probabilistic considerations that, on a functional account,\nunderwrite representing radiation phenomena in terms of causal\nmodels. \nIt is often argued that quantum mechanics is particularly inhospitable\nto causal notions. Early discussions of a putative tension between\ncausal notions and quantum mechanics focused mainly on the\nindeterminism of quantum mechanics. More recent discussions by\ncontrast, focus on the problem that nonlocal quantum correlations\nviolate Bell inequalities as presenting a challenge to causal\nanalyses. In a standard setup of a Bell-type experiment one considers\ntwo observers who perform experiments in two spatially separated\nlaboratories on two entangled subsystems. The two experiments are\nperformed independently but can have outcomes that can be correlated\nin ways that are not readily accounted for by classical causal models.\nThere are different strategies for deriving Bell inequalities.\nParticularly helpful analyses for the status of various causal\nassumptions are developed in Wiseman and Cavalcanti (2017) and Wood\nand Spekkens (2015), who examine how to apply Pearl’s structural\ncausal models to Bell experiments (Myrvold, Genovese, & Shimony\n2019). Simplifying somewhat, Wiseman and Cavalcanti assume that Bell\nexperiments take place in Minkowski spacetime and have real outcomes\nthat are not relative to anything. They then show that the quantum\ncorrelations predicted for Bell experiments conflict with the\nconjunction of three postulates: relativistic causality,\naccording to which an event’s causal past is its past lightcone;\nfree choice, which states that measurement settings can be\nfreely chosen and, hence, have no causes within the system under\nconsideration; and Reichenbach’s principle of a common\ncause, according to which correlations among events that are not\nrelated as cause and effect are explained by a common cause in their\njoint past that screens off the correlation. \nIf we want to accept the quantum mechanical predictions, which appear\nto be empirically well-confirmed, we have to reject at least one of\nthe postulates. Rejecting free choice amounts to accepting\nsuperdeterminism, according to which measurement settings cannot be\nfreely chosen. Alternatively, we can give up relativistic\ncausality, either by allowing for superluminal influences from\nthe outcomes at one wing on that at the other wing, or by positing\nretro-causal relations, which allow measurement outcomes to influence\nthe earlier state of the source (see, e.g., Price 2012; and references\nin Friederich & Evans 2019). \nWhile these strategies allow us to retain Reichenbach’s\nprinciple that correlations among non-causally related events are\nexplained by a common cause that screens off these correlations, they\ncome at a price and, as Wood and Spekkens (2015) show, violate a\ncondition that goes by the names of faithfulness (Spirtes,\nGlymour, & Scheines 1993 [2000: 35]), stability (Pearl\n2009: 49), or no-fine-tuning and which states that every\ncausal dependence implies a probabilistic dependence. Wood and\nSpekkens show that faithfulness, the causal Markov condition, and the\nassumptions that the quantum predictions are correct form an\ninconsistent set. Thus, at least one of the two\nconditions—faithfulness or the Markov condition—has to be\ngiven up. \nWhat speaks for retaining faithfulness is that it is a central\nassumption in many causal discovery algorithms. Yet there are also\narguments suggesting that faithfulness cannot be a necessary condition\non causal models (Cartwright 2001). Paradigmatic cases of violations\nof faithfulness involve cancelations among different causal paths, as\nthey occur in feedback-control structures. For example, ambient\ntemperature is causally relevant to human body temperature, even\nthough body temperature is probabilistically independent of ambient\ntemperature over a wide range of ambient temperatures, since the human\nbody responds to changes in ambient temperatures through various\nmechanisms along different causal routes, which are fine-tuned in a\nway that allow the body to maintain a constant core temperature. Thus,\nfaithfulness arguably is not a necessary condition for causal\nmodels. \nOne might reply, however, that canceling path violations of\nfaithfulness result from a system’s specific causal structure:\nthe causal structures at issue appear to be designed precisely to\nallow for what amounts to violations of faithfulness. By contrast,\nWood and Spekkens show that if we hold on to the Markov condition,\nthen violations of faithfulness have to be a generic feature of\nquantum causal systems that violate the Bell inequalities. It is\nunclear, whether a plausible account of such generic violations of\nfaithfulness in quantum systems involving cancelling paths can be\ngiven. Näger (2016) explores several alternative ways in which\nfaithfulness might be violated in quantum causal systems. By contrast,\nGlymour (2006) argues that instead of giving up faithfulness, we ought\nto reject the Markov condition in quantum contexts. \nAnother response to the problem of embedding correlations among\noutcomes in a causal structure has been to assume a type of holism\nwhich prohibits treating the spatially separated parts of the\nentangled system as distinct subsystems. The suggestion is instead to\nthink of the measurement results at the two wings of the experiment as\n“a single indivisible non-local event” (Skyrms 1984).\nHausman and Woodward (1999) argue that it also follows from an\ninterventionist analysis that the measurement outcomes at the two\nwings of the experiment ought to be treated as a single non-local\nevent. How to causally model entangled states remains a debated\nquestion. \nOne might want to conclude from the fact that quantum correlations are\nincompatible with the conjunction of faithfulness and the Markov\ncondition that causal notions are inapplicable in the quantum realm.\nYet we can experimentally interact with quantum systems and can\nintervene in and control such systems in ways that appear to be causal\nin similar ways to our interactions with classical physical systems.\nMoreover, as Sally Shrapnel (2014) has argued, there are macroscopic\nphenomena, such as the avian magneto-compass, that seem to require\nmulti-level explanations that include quantum causal effects, which\nplay an apparently causal, difference-making role. Efforts, such as\nWood and Spekkens (2015) to try to develop causal representations of\nour interactions with quantum systems have led to the emergence of a\nresearch field devoted to extending the framework of structural causal\nmodels to quantum mechanics and to develop quantum causal models\n(Costa & Shrapnel 2016; Allen et al. 2017; Shrapnel 2019). From\nthe perspective of the three philosophical projects we distinguished\nabove, these efforts are most naturally seen as engaging in the\nfunctional project of developing (and de novo engineering)\ncausal concepts appropriate for the quantum realm and showing how such\nconcepts can play a useful role in explanations and in capturing the\nways in which we can manipulate and control quantum systems. \nThe philosophical literature on causal explanation in general and in\nphysics, more specifically, has developed largely independently of,\nand without engaging with, philosophical discussions in the\nneo-Russellian tradition questioning the legitimacy of causal concepts\nin physics (with Woodward’s work being a notable exception). In\nfact, while neo-Russellian arguments have attracted renewed attention\nsince the turn of the twenty-first century and continue to be widely\nendorsed, causal or causal-mechanical theories of explanation, which\nwere developed in response to problems faced by the\ndeductive-nomological model of scientific explanation developed by\nCarl Hempel (Hempel & Oppenheim 1948), arguably have become the\ndefault view in the philosophical literature on scientific explanation\n(Woodward 2003b [2019]). In fact, one central recent debate within\nthis literature takes for granted that there are causal explanations\nand then discusses whether all scientific explanations are\ncausal (Lewis 1986; Skow 2014) or whether there is room for genuinely\nnon-causal scientific explanations as well (Lange 2016). \nEarlier defenders of causal accounts of explanation took one\ndistinguishing feature of causal accounts to be their metaphysical,\nor—as Alberto Coffa called it—ontic conception of\nexplanation. The goal of explanation, on this conception is to locate\na phenomenon within the objective “causal nexus” (Salmon\n1984: 120). Yet as Woodward’s (2003a) work shows, is that it\nalso possible to investigate the relation between explanation and\ncausation within the functional project of examining the cognitive\nrole of explanatory and causal judgments and their connection to\nprediction, manipulation, and control. \nCausal imperialists, as we might call them, argue that all\nscientific explanations are fundamentally causal. Neo-Russellians, by\ncontrast, deny that causal notions and causal explanation can play any\nrole in suitably fundamental theories of physics. Yet, despite their\nstark disagreement, neo-Russellians and causal imperialists share a\ncommitment to what Woodward has called “the hidden structure\nstrategy” (Woodward 2003b [2019]). Both views are committed to\nthe existence of what Peter Railton has called an “ideal\nexplanatory text” (Railton 1981) that contains all the\ninformation relevant to a complete explanation of some phenomenon.\nWhile actual explanations may fall short of providing us with the\ncomplete information contained in the ideal explanatory text, they are\nexplanatory, according to the hidden structure strategy, in virtue of\nproviding us with some information about the text. \nFor the neo-Russellian, the fundamental explanatory structures consist\nof microphysically complete dynamical models of the backward lightcone\nof a given explanandum. While the neo-Russellian view is\ncompatible with the claim that in some non-fundamental domains and for\npragmatic reasons information about the ideal explanatory text may\nfruitfully be presented in causal terms, the view holds that ideal\nphysical explanations are not causal. Causal imperialism turns this\npicture on its head: for Lewis and others the underlying ideal\nexplanatory structures are causal structures. Hence all explanations\nare causal in virtue of the fact that they provide information about\nthis structure, even though the information provided in an actual\nexplanation may not be presented in causal terms. \nAs Woodward (2003b [2019]) has argued, a problem for the hidden\nstructure strategy is to explain how hidden structures that are\nepistemically inaccessible to us can account for the explanatory\nimport of the explanatory accounts we give. For the neo-Russellian the\nproblem is that we seem to be able to provide successful causal\nexplanations of phenomena even when the complete initial data that are\npart of the ideal explanatory text are in principle inaccessible to\nus. The causal imperialist’s version of the hidden structure\nstrategy faces an analogous problem. There are apparently successful\nexplanations of phenomena that do not identify causes of the\nphenomenon. \nConsider for example an explanation of the heat capacity of metals\nand, in particular, of the fact that the heat capacity is much lower\nthan predicted classically (Kittel 2005: 141ff). The explanation\nappeals to the Pauli exclusion principle and shows how the heat\ncapacity depends on particle statistics. In order to get the correct\nresult for the heat capacity, we need to model free electrons in the\nmetal as satisfying the quantum-mechanical Fermi-Dirac statistics and\nthe exclusion principle. The explanation appeals to the structure of\nthe phase-space available to the electrons. \nAccording to causal imperialists, such as Lewis, this explanation is\ncausal by virtue of the fact that it provides information about the\ncausal history of a sample of metal. Does this construal of the\nexplanation as pointing to a hidden causal structure allow us to make\nperspicuous its explanatory import? As we have seen, Pearl’s and\nWoodward’s accounts of causation emphasize two features as\ncharacteristic functions of causal notions. First, knowledge of causal\nstructures allows us to identify relationships amenable to\nmanipulation and control; and second, common cause reasoning enables\nus to draw inferences from one time to another even when we possess\nonly incomplete knowledge of the state of a system on an initial or\nfinal value surface. \nNow, the explanation of the heat capacity embeds its\nexplanandum into patterns of functional dependencies and\nallows us to answer how the heat capacity would change if the\navailable phase space were different. That is, the explanation does\nenable us to answer what Woodward calls\nwhat-if-things-had-been-different questions (Woodward 1979),\nwhich, according to Woodward’s account of explanation is an\nimportant feature of causal explanations. Yet the counterfactuals at\nissue cannot be interpreted in terms of interventions or manipulations\non the electron states. Indeed, the fact that the value of the heat\ncapacity of metals follows from structural features of the\nelectrons’ phase space and is not something that, even in\nprinciple, is open to manipulation or control arguably is itself\nexplanatorily relevant. Thus, one might worry that by classifying\nexplanations such as this as causal the causal imperialist obliterates\nwhat is an important distinction between different explanatory\nfunctions and epistemic goals.","contact.mail":"mathias.frisch@philos.uni-hannover.de","contact.domain":"philos.uni-hannover.de"}]
