[{"date.published":"2006-08-14","date.changed":"2019-06-03","url":"https://plato.stanford.edu/entries/belief/","author1":"Eric Schwitzgebel","author1.info":"http://www.faculty.ucr.edu/~eschwitz/","entry":"belief","body.text":"\n\n\nContemporary Anglophone philosophers of mind generally use the term\n“belief” to refer to the attitude we have, roughly,\nwhenever we take something to be the case or regard it as true. To\nbelieve something, in this sense, needn’t involve actively\nreflecting on it: Of the vast number of things ordinary adults\nbelieve, only a few can be at the fore of the mind at any single time.\nNor does the term “belief”, in standard philosophical\nusage, imply any uncertainty or any extended reflection about the\nmatter in question (as it sometimes does in ordinary English usage).\nMany of the things we believe, in the relevant sense, are quite\nmundane: that we have heads, that it’s the 21st century, that a\ncoffee mug is on the desk. Forming beliefs is thus one of the most\nbasic and important features of the mind, and the concept of belief\nplays a crucial role in both philosophy of mind and epistemology. The\n“mind-body problem”, for example, so central to philosophy\nof mind, is in part the question of whether and how a purely physical\norganism can have beliefs. Much of epistemology revolves around\nquestions about when and how our beliefs are justified or qualify as\nknowledge.\n\n\nMost contemporary philosophers characterize belief as a\n“propositional attitude”. Propositions are generally taken\nto be whatever it is that sentences express (see the entry on\n propositions).\n For example, if two sentences mean the same thing (e.g., “snow\nis white” in English, “Schnee ist weiss” in German),\nthey express the same proposition, and if two sentences differ in\nmeaning, they express different propositions. (Here we are setting\naside some complications about that might arise in connection with\nindexicals; see the entry on\n indexicals.)\n A propositional attitude, then, is the mental state of\nhaving some attitude, stance, take, or opinion about a proposition or\nabout the potential state of affairs in which that proposition is\ntrue—a mental state of the sort canonically expressible in the\nform “S A that P”, where\nS picks out the individual possessing the mental state,\nA picks out the attitude, and P is a sentence\nexpressing a proposition. For example: Ahmed [the subject] hopes [the\nattitude] that Alpha Centauri hosts intelligent life [the\nproposition], or Yifeng [the subject] doubts [the attitude] that New\nYork City will exist in four hundred years. What one person doubts or\nhopes, another might fear, or believe, or desire, or\nintend—different attitudes, all toward the same proposition.\nContemporary discussions of belief are often embedded in more general\ndiscussions of the propositional attitudes; and treatments of the\npropositional attitudes often take belief as the first and foremost\nexample.\n\nIt is common to think of believing as involving\nentities—beliefs—that are in some sense contained in the\nmind. When someone learns a particular fact, for example, when Kai\nreads that astronomers no longer classify Pluto as a planet, he\nacquires a new belief (in this case, the belief that astronomers no\nlonger classify Pluto as a planet). The fact in question—or more\naccurately, a representation, symbol, or marker of that fact—may\nbe stored in memory and accessed or recalled when necessary. In one\nway of speaking, the belief just is the fact or proposition\nrepresented, or the particular stored token of that fact or\nproposition; in another way of speaking, the more standard in\nphilosophical discussion, the belief is the state of having such a\nfact or representation stored. (Despite the ease with which we slide\nbetween these different ways of speaking, they are importantly\ndistinct: Contrast the state of having hot water in one’s water\nheater—the state of being “hot-water ready”,\nsay—with the stuff actually contained in the heater, that\nparticular mass of water, or water in general.) \nIt is also common to suppose that beliefs play a causal role in the\nproduction of behavior. Continuing the example, we might imagine that\nafter learning about the demotion of Pluto, Kai naturally turns his\nattention elsewhere, not consciously considering the matter for\nseveral days, until when reading an old science textbook he encounters\nthe sentence “our solar system contains nine planets”.\nInvoluntarily, his new knowledge about Pluto is called up from memory.\nHe finds himself doubting the truth of the textbook’s claim, and\nhe says, “actually, astronomers no longer accept that”. It\nseems plausible to say that Kai’s belief about Pluto, or his\npossession of that belief, caused, or figured in a causal explanation\nof, his utterance. \nVarious elements of this intuitive characterization of belief have\nbeen challenged by philosophers, but it is probably fair to say that\nthe majority of contemporary philosophers of mind accept the bulk of\nthis picture, which embodies the core ideas of the\nrepresentational approach to belief, according to which\ncentral cases of belief involve someone’s having in her head or\nmind a representation with the same propositional content as the\nbelief. (But see §2.2, below, for some caveats, and see the entry\non\n mental representation.)\n As discussed below, representationalists may diverge in their\naccounts of the nature of representation, and they need not agree\nabout what further conditions, besides possessing such a\nrepresentation, are necessary if a being is to qualify as having a\nbelief. Among the more prominent advocates of a representational\napproach to belief are Fodor (1975, 1981, 1987, 1990), Millikan (1984,\n1993), Dretske (1988), Cummins (1996), Burge (2010), Mandelbaum (2016;\nQuilty-Dunn and Mandelbaum 2018), and Zimmerman (2018). \nOne strand of representationalism, endorsed by Fodor, takes mental\nrepresentations to be sentences in an internal language of\nthought. To get a sense of what this view amounts to, it is\nhelpful to start with an analogy. Computers are sometimes\ncharacterized as operating by manipulating sentences in “machine\nlanguage” in accordance with certain rules. Consider a\nsimplified description of what happens as one enters numbers into a\nspreadsheet. Inputs from the keyboard cause the computer, depending on\nthe programs it is running and its internal state, to instantiate or\n“token” a sentence (in machine language) with the content\n(translated into English) of, for example, “numerical value 4 in\ncell A1”. In accordance with certain rules, the machine then\ndisplays the shape “4” in a certain location on the\nmonitor, and perhaps, if it is implementing the rule “the values\nof column B are to be twice the values of column A”, it tokens\nthe sentence “numerical value 8 in cell B1” and displays\nthe shape “8” in another location on the monitor. If we\nsomeday construct a robot whose behavior resembles that of a human\nbeing, we might imagine it to operate along broadly the lines\ndescribed above—that is, by manipulating machine-language\nsentences in accordance with rules, in connection with various\npotential inputs and outputs. Such a robot might somewhere store the\nmachine-language sentence whose English translation is “the\nchemical formula for water is H2O”. We might suppose\nthis robot is able to act as does a human who possesses this belief\nbecause it is disposed to access this sentence appropriately on\nrelevant occasions: When asked “of what chemical elements is\nwater compounded?”, the robot accesses the water sentence and\nmanipulates it and other relevant sentences in such a way that it\nproduces an appropriate response. \nAccording to the language of thought hypothesis (see the entry on the\n language of thought hypothesis),\n our cognition proceeds rather like such a robot’s. The formulae\nwe manipulate are not in “machine language”, of course,\nbut rather in a species-wide “language of thought”. A\nsentence in the language of thought with some particular propositional\ncontent P is a “representation” of P. On\nthis view, a subject believes that P just in case she has a\nrepresentation of P that plays the right kind of role—a\n“belief-like” role—in her cognition. That is, the\nrepresentation must not merely be instantiated somewhere in the mind\nor brain, but it must be deployed, or apt to be deployed, in ways we\nregard as characteristic of belief. For example, it must be apt to be\ncalled up for use in theoretical inferences toward which it is\nrelevant. It must be ready for appropriate deployment in deliberation\nabout means to desired ends. It is sometimes said, in such a case,\nthat the subject has the proposition P, or a representation\nof that proposition, tokened in her “belief box” (though\nof course it is not assumed that there is any literal box-like\nstructure in the head). \nDretske’s view centers on the idea of representational systems\nas systems with the function of tracking features of the world (for\nsimilar views, see Millikan 1984, 2017; Neander 2017). Organisms,\nespecially mobile ones, generally need to keep track of features of\ntheir environment to be evolutionarily successful. Consequently, they\ngenerally possess internal systems whose function it is to covary in\ncertain ways with the environment. For example, certain marine\nbacteria contain internal magnets that align with the Earth’s\nmagnetic field. In the northern hemisphere, these bacteria, guided by\nthe magnets, propel themselves toward magnetic north. Since in the\nnorthern hemisphere magnetic north tends downward, they are thus\ncarried toward deeper water and sediment, and away from toxic,\noxygen-rich surface water. We might thus say that the magnetic system\nof these bacteria is a representational system that functions to\nindicate the direction of benign or oxygen-poor environments. In\ngeneral, on Dretske’s view, an organism can be said to represent\nP just in case that organism contains a subsystem whose\nfunction it is to enter state A only if P holds, and\nthat subsystem is in state A. \nTo have beliefs, Dretske suggests, is to have an integrated manifold\nof such representational systems, acquired in part through associative\nlearning, poised to guide behavior. Given the lack of such a complex,\nand the lack of associative learning, magnetosome bacteria cannot, on\nDretske’s view, rightly be regarded as literally possessing\nfull-fledged beliefs. But exactly how rich an organism’s\nrepresentational structure must be for it to have beliefs, and in what\nways, Dretske does not address, regarding it as a terminological\nboundary dispute, rather than a matter of deep ontological\nsignificance. (For more on belief in non-human animals see §4\nbelow.) \nIf one accepts a representational view of belief, it’s plausible\nto suppose that the relevant representations are structured\nin some way—that the belief that P & Q,\nfor instance, shares something structurally in common with the belief\nthat P. To say this is not merely to say that the belief that\nP & Q has the following property: It cannot be\ntrue unless the belief that P is true. Consider the following\npossible development of Dretske’s representational approach: An\norganism has developed a system that functions to detect whether\nP is or is not the case. It’s supposed to enter state\nalpha when P is true; its being in alpha has the function of\nindicating P. Also, the organism has developed a separate\nsystem for detecting whether P & Q is the case.\nIt’s supposed to enter state beta when P &\nQ is true; its being in beta has the function of indicating\nP & Q. But alpha and beta have nothing important\nin common other than what, in the outside world, they are supposed to\nrepresent; they have no structural similarity; one is not compounded\nin part from the other. Conceivably, all our beliefs could be set up\nin this way, having as little in common as alpha and beta—one\ninternally unstructured representational state after another. To say\nthat mental representations are structured is in part to deny that our\nminds work like that. \nAmong the reasons to suppose that our representations are structured,\nFodor argues, are the productivity and systematicity\nof thought (Fodor 1987; Fodor and Pylyshyn 1988; Aizawa 2003). Thought\nand belief are “productive” in the sense that we can\npotentially think or believe an indefinitely large number of things:\nthat elephants despise bowling, that 245 + 382 = 627, that river\nbottoms are usually not composed of blue beads. If representations are\nunstructured, each of these different potential beliefs must, once\nbelieved, be an entirely new state, not constructed from\nrepresentational elements previously available. Similarly, thought and\nbelief are “systematic” in the sense that an organism who\nthinks or believes that Mengzi repudiated Gaozi will normally also\nhave the capacity (if not necessarily the inclination) to think or\nbelieve that Gaozi repudiated Mengzi; an organism who thinks or\nbelieves that dogs are insipid and cats are resplendent will normally\nalso have the capacity to think or believe that dogs are resplendent\nand cats are insipid. If representations are structured, if they have\nelements that can be shuffled and recombined, the productivity and\nsystematicity of thought and belief seem naturally to follow.\nConversely, someone who holds that representations are unstructured\nhas, at least, some explaining to do to account for these features of\nthought. (So also, apparently, does someone who denies that belief is\nunderwritten or implemented by a representational system of any\nsort.) \nSupposing representations are structured, then, what kind of\nstructure do they have? Fodor notes that productivity and\nsystematicity are features not just of thought but also of language,\nand concludes that representational structure must be linguistic. He\nendorses the idea of an innate, species-wide language of thought (as\ndiscussed briefly in §1.1 above); others tie the structure more\nclosely to the thinker’s own natural (learned) language (Harman\n1973; Field 1978; Carruthers 1996). However, still others assert that\nthe representational structure underwriting belief isn’t\nlanguage-like at all. \nA number of philosophers have argued that our cognitive\nrepresentations have, or can have, a map-like rather than a\nlinguistic structure (Lewis 1994; Braddon-Mitchell and Jackson 1996;\nCamp 2007, 2018; Rescorla 2009; though see Blumson 2012 and Johnson\n2015 for concerns about whether map-like and language-like structures\nare importantly distinct). Map-like representational systems are both\nproductive and systematic: By recombination and repetition of its\nelements, a map can represent indefinitely many potential states of\naffairs; and a map-like system that has the capacity, for example, to\nrepresent the river as north of the mountain will normally also have\nthe capacity to represent, by a re-arrangement of its parts, the\nmountain as north of the river. Although maps may sometimes involve\nwords or symbols, nothing linguistic seems to be essential to the\nnature of map-like representation: Some maps are purely pictorial or\ncombine pictorial elements with symbolic elements, like coloration to\nrepresent altitude, that we don’t ordinarily think of as\nlinguistic. \nThe maps view makes nice sense of the fact that when a person changes\none belief, a multitude of other beliefs seem also to change\nsimultaneously and effortlessly: If you shift a mountain farther north\non a map, for example, you immediately and automatically change many\nother aspects of the representational system (the distance between the\nmountain and the north coast, the direction one must hike to go from\nthe mountain to the oasis, etc.). In contrast, if you change the\nlinguistic representation “the mountain peak is 15 km north of\nthe river” to “the mountain peak is 20 km north of the\nriver”, no other representation necessarily changes: It takes a\ncertain amount of inferential work to ramify the consequences\nthrough the rest of the system. Since it doesn’t seem like\nwe’re constantly making such a plethora of inferences, the maps\nview might have an advantage here. On the other hand, perhaps just\nbecause the linguistic view requires inference for what appears to\nhappen automatically on the maps view, the linguistic view can more\neasily account for failures of rationality, in which not all the\nnecessary changes are made and the subject ends up with an\ninconsistent view. Indeed generally speaking it’s unclear how\nthe map view can accommodate inconsistent beliefs unless one allows a\nproliferation of maps, with the complications that ensue (like\nredundancy and mechanisms for relating the maps). Certain sorts of\nindeterminacy may also be more difficult to accommodate in map-like\nthan in language-like structures. A linguistic representation like\n“there are some lakes east of the mountain” can leave\ncompletely unspecified how many lakes, of what shape, and where; a map\ndoes not, it seems, as easily do this. One further point of apparent\ndifference between the two views will be discussed in §2.2 below.\nGenerally speaking, one might worry that the maps view\novergenerates and overspecifies beliefs, while the\nlinguistic view undergenerates and underspecifies\nthem. \nA third and very different way of thinking about representational\nstructure arises from the perspective of connectionism, a\nposition in cognitive science and computational theory. According to\nconnectionism, cognition proceeds by activation streaming through a\nseries of “nodes” connected by adjustable\n“connection weights”—somewhat as neural networks in\nthe brain can have different levels of activation and different\nstrengths of connection between each other. It is sometimes suggested\n(e.g., by van Gelder 1990; Smolensky 1995; Shea 2007) that the\nstructure of connectionist networks is representational but\nnon-linguistic or non-“compositional”; and perhaps so also\nis human representational structure. However, it would take us too far\nafield to enter this technical issue here. (For more on this topic see\nthe entry on\n connectionism.) \nRecent representational approaches sometimes especially emphasize the\nnormative dimension of belief. That is, they emphasize the idea that\nit is central to a mental state’s being a belief as\nopposed to some other mental state (e.g., a supposition, an imagining,\na desire) that it is necessarily defective in a certain way if it is\nfalse. Shah and Velleman (2005) argue that conceiving of an attitude\nas a belief that P entails conceiving of it as governed by a\nnorm of truth, that is, as an attitude that is correct if and\nonly if P is true. Engel (2018) argues that among\npropositional attitudes, belief is the only one whose\n“correctness condition” is truth, distinguishing it from\nother closely related mental states, such as acceptances and epistemic\nfeelings. Burge (2010) argues that the “primary constitutive\nfunction” of believing is the production of veridical\npropositional representations. A related literature addresses whether\nbelief is essentially subject to a norm of truth (Wedgwood 2002;\nMcHugh and Whiting 2010; Gluer and Wikforss 2013). \nRepresentationalist normativism has roots in the idea that\nrepresentational systems are functional systems of a certain sort\n(Millikan 1984; Dretske 1988): Function appears to be a normative\nconcept, implying at least a contrast with malfunction. Similarly, but\nwith no commitment to representationalism specifically, belief has\noften been described as having a “direction of fit” in the\nsense that beliefs (unlike, for example, desires) ought to fit with,\nor get it right about, or match up to, the states of affairs they\ndescribe or represent (Anscombe 1957/1963; Searle 1983; Humberstone\n1992; Frost 2014). If you believe that P and P is false,\nyou have erred or made a mistake, whereas if you desire that P\nand P is false, you have not in the same way erred or made a\nmistake. \nWhile representationalists like Fodor, Dretske, and Mandelbaum contend\nthat having the right internal, representational structure is\nessential to having beliefs, another group of philosophers treats the\ninternal structure of the mind as of only incidental relevance to the\nquestion of whether a being is properly described as believing. One\nway to highlight the difference between this view and\nrepresentationalism is this: Imagine that we discover an alien being,\nof unknown constitution and origin, whose behavior and overall\nbehavioral dispositions are perfectly normal by human standards.\n“Rudolfo”, say, emerges from a spacecraft and integrates\nseamlessly into U.S. society, becoming a tax lawyer, football fan, and\nDemocratic Party activist. Even if we know next to nothing about what\nis going on inside his head, it may seem natural to say that Rudolfo\nhas beliefs much like ours—for example, that the 1040 is\nnormally due April 15, that a field goal is worth 3 points, and that\nlabor unions tend to support Democratic candidates. Perhaps we can\ncoherently imagine that Rudolfo does not manipulate sentences in a\nlanguage of thought or possess internal representational structures of\nthe right sort. Perhaps it is conceptually, even if not physically,\npossible that he has no complex, internal, cognitive organ, no real\nbrain. But even if it is granted that a creature must have human-like\nrepresentations in order to behave thoroughly like a human being, one\nmight still think that it is the pattern of actual and potential\nbehavior that is fundamental in belief—that representations\nare essential to belief only because, and to the extent to, they\nground such a pattern. Dispositionalists and\ninterpretationists are drawn to this way of thinking. \nTraditional dispositional views of belief assert that for someone to\nbelieve some proposition P is for that person to possess one\nor more particular behavioral dispositions pertaining to P.\nOften cited is the disposition to assent to utterances of P\nin the right sorts of circumstances (if one understands the language,\nwishes to reveal one’s true opinion, is not physically\nincapacitated, etc.). Other relevant dispositions might include the\ndisposition to exhibit surprise should the falsity of P make\nitself evident, the disposition to assent to Q if one is\nshown that P implies Q, and the disposition to\ndepend on P’s truth in executing one’s plans.\nPerhaps all such dispositions can be brought under a single heading,\nwhich is, most generally, being disposed to act as though P\nis the case. Such actions are normally taken to be at least pretty\ngood prima facie evidence of belief in P;\nthe question is whether being disposed, overall, so to act is\ntantamount to believing P, as the dispositionalist\nthinks, or whether it is merely an outward sign of belief. Braithwaite\n(1932–1933) and Marcus (1990) are prominent advocates of the\ntraditional dispositional approach to belief (though Braithwaite\nemphasizes in his analysis another form of belief, rather like\n“occurrent” belief as described in §2.1 below). \nThere are two standard objections to traditional dispositional\naccounts of belief. The first, tracing back at least to Chisholm\n(1957), assumes that the dispositionalist’s aim is to\nreduce or analyze facts about belief entirely into\nfacts about outward behavior, facts specifiable without reference to\nother beliefs, desires, inner feelings, and so forth (see the entry on\nphilosophical\n behaviorism).\n Such a reduction or analysis appears impossible for the following\nreason: People with the same belief may behave very differently,\ndepending on their other beliefs, desires, and so forth. For example,\na person who believes that it will rain will only be disposed to take\nan umbrella if she also believes that the umbrella will ward off the\nwater and if she doesn’t want to get wet. Change the surrounding\nbeliefs and desires and very different behavior may result. A\ndispositionalist attempting to specify the particular behavioral\ndispositions associated with, for example, the belief that it’s\nraining will then either get it wrong about the dispositions of some\npeople (such as those who like to get wet) or will be forced to\nincorporate into her dispositional analysis conditional antecedents\ninvoking the very ideas she is trying to analyze or reduce\naway—saying, for example, that the person who believes that\nP will behave in such-and-such a way if she also\nbelieves X and desires Y—apparently dooming\nthe reductionist project. (It may be possible to avoid this objection\nby invoking a “Ramsey”-like approach to the reduction [see\nthe section on Functional States and Ramsey Sentences in the entry on\n functionalism\n and Lewis 1972], but this type of analysis was not widely discussed\nuntil after traditional dispositional approaches to belief had gone\nlargely out of fashion.) \nThe second standard objection to traditional dispositional accounts of\nbelief is to note the loose connection between belief and behavior in\nsome cases—for example, in a recently paralyzed person, or in\nsomeone who wants to keep a private opinion (e.g., a Muscovite who\nbelieves, in 1937, that Stalin’s purges are morally wrong), or\nin matters of very little practical relevance (e.g., an American\nhomebody’s belief that there is at least one church in Nice).\nAgain, the traditional dispositionist seems faced with a choice\nbetween oversimplifying (and thus mischaracterizing some\npeople’s dispositions) and loading the dispositions with\npotentially problematic or unwieldy conditional antecedents (e.g.,\nshe’d get the umbrella if her paralysis healed;\nhe’d speak up if the political climate changed). On the\nother hand, however, the demand for an absolutely precise\nspecification of the conditions under which a disposition will be\nmanifested, without exception, may be excessive. As Cartwright (1983)\nhas noted, even perfectly respectable claims in the physical sciences\noften hold only ceteris paribus or “all else being\nequal”. \nIn light of these concerns and others, most recent philosophers\nsympathetic with the view described in the first paragraph of this\nsection have abandoned traditional dispositionalism. They divide into\nroughly two classes, which we may call liberal\ndispositionalists and interpretationists. Liberal\ndispositionalists avoid the first objection by abandoning the\nreductionist project associated with traditional dispositionalism.\nThey permit appeal to other mental states in specifying the\ndispositions relevant to any particular belief—including other\nbeliefs and desires. They also broaden the range of dispositions\nconsidered relevant to the possession of a belief so as to include at\nleast some dispositions to undergo private mental episodes that do not\nmanifest in outwardly observable behavior—dispositions, for\nexample, for the subject to feel (and not just exhibit) surprise\nshould she discover the falsity of P, for her privately to\ndraw conclusions from P, to feel confidence in the truth of\nP, to utter P silently to herself in inner speech,\nand so forth. This appears also to mitigate the second objection to\nsome extent: The Muscovite possesses his belief about Stalin’s\npurges at least as much in virtue of the things he says silently to\nhimself and the disapproval he privately feels as in virtue of his\ndisposition to express that opinion were the political climate to\nchange. Advocates of views of this sort include Price (1969), Audi\n(1972), Baker (1995), Schwitzgebel (2002, 2013), and arguably Ryle\n(1949) and Ramsey (1926 [1990], 1927–1929 [1991]; see Wright\n2017). \nHowever, a philosopher approaching belief with the specific goal of\ndefending physicalism or materialism—the view that everything in\nthe world, including the mind, is wholly physical or material (see\n physicalism)—might\n have reason to be dissatisfied with liberal dispositionalism, for the\nvery reason that it abandons the reductionist project. Although\nliberal dispositional accounts of belief are consistent with\nphysicalism, they do not substantially advance that thesis,\nsince they relate belief to other mental states that may or may not be\nseen as physical. The defense of physicalism was one of the driving\nforces in philosophy of mind in the period during which the most\ninfluential approaches to belief in contemporary analytic philosophy\nof mind were developed—the 1960s through the 1980s—and it\nwas one of the principal reasons philosophers were interested in\naccounts of propositional attitudes such as belief. Consequently, the\nfailure of liberal dispositionalism to advance the physicalist thesis\nmight be seen as an important drawback. \nInterpretationism shares with dispositionalism the emphasis on\npatterns of action and reaction, rather than internal representational\nstructures, but retains the focus, abandoned by the liberal\ndispositionalist, on observable behavior—behavior\ninterpretable by an outside observer. Since behavior is widely assumed\nto be physical, interpretationism can thus more easily be seen as\nadvancing the physicalist project. The two most prominent\ninterpretationists have been Dennett (1978, 1987, 1991) and Davidson\n(1984; see\n Donald Davidson;\n also see Lewis 1974). \nTo gain a sense of Dennett’s view, consider three different\nmethods we can use to predict the behavior of a human being. One\nmethod, which involves taking what Dennett calls the “physical\nstance”, is to apply our knowledge of physical law. We can\npredict that a diver will trace a roughly parabolic trajectory to the\nwater because we know how objects of approximately that mass and size\nbehave in fall near the surface of the Earth. A second method, which\ninvolves taking the “design stance”, is to attribute\nfunctions to the system or its parts and to predict that the system\nwill function properly. We can predict that a jogger’s pulse\nwill increase as she heads up the hill because of what we know about\nexercise and the proper function of the circulatory system. A third\nmethod, which involves taking the “intentional stance”, is\nto attribute beliefs and desires to the person, and then to predict\nthat they will behave rationally, given those beliefs and desires.\nMuch of our prediction of human behavior appears to involve such\nattribution (though see Andrews 2012). Certainly, treating people as\nmere physical bodies or as biological machines will not, as a\npractical matter, get us very far in predicting what is important to\nus. \nOn Dennett’s view, a system with beliefs is a system whose\nbehavior, while complex and difficult to predict when viewed from the\nphysical or the design stance, falls into patterns that may be\ncaptured with relative simplicity and substantial if not perfect\naccuracy by means of the intentional stance. The system has the\nparticular belief that P if its behavior conforms to a\npattern that may be effectively captured by taking the intentional\nstance and attributing the belief that P. For example, we can\nsay that Heddy believes that a hurricane may be coming because\nattributing her that belief (along with other related beliefs and\ndesires) helps reveal the pattern, invisible from the physical and\ndesign stances, behind her boarding up her windows, making certain\nphone calls, stocking up provisions, etc. All there is to having\nbeliefs, according to Dennett, is embodying patterns of this sort.\nDennett acknowledges that his view has the unintuitive consequence\nthat a sufficiently sophisticated chess-playing machine would have\nbeliefs if its behavior is very complicated from the design stance\n(which would involve appeal to its programmed strategies) but\npredictable with relative accuracy and simplicity from the intentional\nstance (attributing the desire to defend its queen, the belief that\nyou won’t sacrifice a rook for a pawn, etc.). \nDavidson also characterizes belief in terms of practices of belief\nattribution. He invites us to imagine encountering a being with a\nwholly unfamiliar language and then attempting the task of\nconstructing, from observation of the being’s behavior in its\nenvironment, an understanding of that language (e.g., 1984, p.\n135–137). Success in this enterprise would necessarily involve\nattributing beliefs and desires to the being in question, in light of\nwhich its utterances make sense. An entity with beliefs is a being for\nwhom such a project is practicable in principle—a being that\nemits, or is disposed to emit, a complex pattern of behavior that can\nproductively be interpreted as linguistic, rational, and expressive of\nbeliefs and desires. \nDennett and Davidson both endorse the “indeterminacy” of\nbelief attributions: In at least some cases, multiple incompatible\ninterpretive schemes may be equally good, and thus there may be no\nfact of the matter which of those schemes is “really” the\ncorrect one, and thus whether the subject “really”\nbelieves P, if belief that P is attributed by one\nscheme but not by the other. \nMany philosophers identify themselves as functionalists (see\n functionalism)\n about mental states in general or belief in particular. Functionalism\nabout mental states is the view that what makes something a mental\nstate of a particular type are its actual and potential, or its\ntypical, causal relations to sensory stimulations, behavior, and other\nmental states (seminal sources include Armstrong 1968; Fodor 1968;\nLewis 1972, 1980; Putnam 1975; Block 1978). Functionalists generally\ncontrast their view with the view that what makes something a mental\nstate of a particular type are facts about its internal structure. To\nunderstand this distinction, it may be helpful to begin with some\nnon-mental examples. Arguably, what makes something a streptococcal\nbacterium, or a cube, is its shape or internal structure; its causal\nhistory or proneness to produce particular effects on particular\noccasions is only secondarily relevant, if at all. In contrast,\nwhether something is a hard drive or not is not principally a matter\nof internal structure. A hard drive could be made of plastic or steel,\nemploy magnetic tape or lasers. What matters are the causal\nrelationships it’s prone to enter with a computer: Under certain\npromptings, it enters states such that, under certain further\npromptings, it will generate outputs of a certain sort. Internal\nstructure is relevant only secondarily, insofar as it grounds these\ncausal capacities. Likewise, according to the functionalist, what\nmakes a state pain is not its particular neural\nconfiguration. People and animals with very different neural\nconfigurations could all equally be in pain (even, conceivably, a\nMartian with an internal structure radically different from ours could\nsuffer pain). What matters is that the subject is in a state that\n(roughly) is apt to be caused by tissue damage or tissue stress and\nthat, in turn, is apt to cause signs of distress, withdrawal, future\navoidance of the painful stimulus, and (in verbal subjects) thoughts\nand utterances like “that hurts!”. \nPhilosophers frequently endorse functionalism about belief without\neven briefly sketching out the various particular functional\nrelationships that are supposed to be involved, though Loar (1981) is\na notable exception to this tendency (see also Leitgeb 2017). However,\namong the causal relationships contemporary philosophers have often\nseen as characteristic of belief are the following (these are sketched\nhere only roughly; they come in many versions differing in\nnuance): \n(1) Reflection on propositions (e.g., [Q] and [if Q\nthen P]) from which P straightforwardly follows, if\none believes those propositions and is not antecedently committed to\nthe falsity of P, typically causes the belief that\nP. \n(2) Directing perceptual attention to the perceptible properties of\nthings, events, or states of affairs, in conditions favorable to\naccurate perception, typically causes the belief that those things,\nevents, or states of affairs have those properties (e.g., visually\nattending to a red shirt in good viewing conditions will typically\ncause the belief that the shirt is red). \n(3) Believing that performing action A would lead to event or\nstate of affairs E, conjoined with a desire for E\nand no overriding contrary desire, will typically cause an intention\nto do A. \n(4) Believing that P, in conditions favoring sincere\nexpression of that belief, will typically lead to an assertion of\nP. \nLoar emphasizes versions of (2) and (3) over (1) and (4), but one sees\nconditions of this sort at least briefly alluded to by a number of\nfunctionalist philosophers, including Dennett (1969, 1978), Armstrong\n(1973), Stalnaker (1984), Fodor (1990), Pettit (1993), Shoemaker\n(2003), and Zimmerman (2018). For the functionalist, to believe just\nis to be in a state that plays (something like) this sort of causal\nrole. \nAs the list of names of the previous paragraph suggests, functionalism\nis compatible with either a representationalist approach to belief (as\nin Fodor) or an interpretationist one (as in Dennett). (The\ninterpretationist, of course, will have to treat the relevant\nfunctional states as posits of an interpretative theory or scheme.)\nDispositional accounts of belief, too, can be functionalist. Indeed,\ndispositional accounts can be seen as a special or limiting case of\nfunctional accounts. To see this, it’s helpful to divide the\ncausal relations appealed to by functionalism into the\nbackward-looking and the forward-looking.\nBackward-looking causal relations pertain to what actually,\npotentially, or typically causes the state in question;\nforward-looking causal relations pertain to what effects the\nstate in question actually, potentially, or typically has. Thus (1)\nand (2) above are backward-looking causal relations, while (3) and (4)\nare forward-looking. We might, then, see the dispositionalist as a\nfunctionalist who thinks only the forward-looking causal relations are\ndefinitive of belief: To believe is to be in a state apt to cause\nsuch-and-such behavioral (or other) manifestations. (This view is, of\ncourse, compatible with accepting the existence of regularities like\n(1) and (2), as long as they are not regarded as defining\ncharacteristics of belief.) Two caveats, however, should accompany\nthis reduction of dispositionalism to functionalism: First, insofar as\nfunctionalism about belief requires a causal relationship\nbetween the belief state and its manifestations in behavior (or in\nother mental states), it will exclude dispositionalists like Ryle\n(1949) who don’t view the disposition-manifestation relationship\ncausally (for discussion, see Section 6 (‘The causal efficacy\nof dispositions’) of the entry on\n dispositions).\n Second, the liberal dispositionalist may wish to demur from the\nfunctionalist’s usual commitment to the reducibility of facts\nabout functionally-definable mental states, en masse and in\nprinciple (allowing for the intricate network of interrelationships\namong them), to facts about sensory inputs and outward behavior. \nThe compatibility of functionalism and representationalism is not\nevident on its face, though a number of prominent contemporary\nphilosophers appear to embrace both positions (e.g., Fodor 1968, 1975,\n1981, 1990; Armstrong 1973; Harman 1973; Lycan 1981a, 1981b; Stalnaker\n1984; Lewis 1994). As Millikan (1984), Papineau (1984), and others\nhave suggested, it seems one thing to say that to believe is to be in\na state that fills a particular causal role, and it seems\nquite another to say that beliefs are essentially states that\nrepresent how things stand in the world. How can something\nrepresent the world outside simply by virtue of playing a certain\ncausal role in a cognitive system? Suppose, for example, that a state\nrepresents by virtue of having an indicator function of the sort\ndescribed at the end of §1.1 above. The indicator function of an\ninternal state or system would seem, at least sometimes and in part,\nto depend constitutively on the evolutionary history of that state or\nsystem, or its learning history, and not simply on the causal\nrelationships it is currently disposed to enter. Despite the\nword “function” in “functionalism”, it’s\nnot clear that standard functionalist accounts, limited as they are to\nappeal to a state’s actual, potential, or typical causal roles,\ncan incorporate facts about a system’s evolutionary history or\nlearning history: Conceivably, for example, two states in different\nindividuals may have exactly analogous causal roles, yet differ in\ntheir (as Millikan says) “proper function” because of\ndifferences in the evolutionary or learning history of those\nsystems. \nThree escapes from this potential difficulty suggest themselves. One\nis to endorse a version of “conceptual [or functional] role\nsemantics” according to which the representational status and\ncontent of a mental state is reducible just to facts about what is apt\nto cause and to be caused by the mental state in question—that\nis, to deny the relevance of remote evolutionary or learning history\nto mental representation as not part of a proper functional\ncharacterization (e.g., Harman 1973, 1987). Another is to accept that\ncausal role determines the representational status of a\nmental state (i.e., that it is a representation) but does not\nfully specify representational content (i.e. how that\nrepresentation represents things as being); but this seems to involve\nabandoning full-blown functionalism. A third is to interpret more\nliberally what it is for a mental state to be “typically\ncaused” (or perhaps “normally caused”) by some event\nor state of affairs: Perhaps it is enough that in the young organism,\nor its evolutionary ancestors, mental states of that sort were caused\nin a particular way, or the system was selected to be responsive to\ncertain sorts of environmental factors. Such claims may be more easily\nreconcilable with certain canonical statements of functionalism (such\nas Lewis 1980) than with others (such as Putnam 1975). The issue has\nnot been as fully discussed as it should be. \nSome philosophers have denied the existence of beliefs altogether.\nAdvocates of this view, generally known as eliminativism,\ninclude Churchland (1981), Stich (in his 1983 book; he subsequently\nmoderated his opinion), and Jenson (2016). On this view,\npeople’s everyday conception of the mind, their “folk\npsychology”, is a theory on par with folk theories about the\norigin of the universe or the nature of physical bodies. And just as\nour pre-scientific theories on the latter topics were shown to be\nradically wrong by scientific cosmology and physics, so also will folk\npsychology, which is essentially still pre-scientific, be overthrown\nby scientific psychology and neuroscience once they have advanced far\nenough. \nAccording to eliminativism, once folk psychology is overthrown, strict\nscientific usage will have no place for reference to most of the\nentities postulated by folk psychology, such as belief. Beliefs, then,\nlike “celestial spheres” or “phlogiston”, will\nbe judged not actually to exist, but rather to be the mistaken posits\nof a radically false theory. We may still find it convenient to speak\nof “belief” in informal contexts, if scientific usage is\ncumbersome, much as we still speak of “the sun going\ndown”, but if the concept of belief does not map onto the\ncategories described by a mature scientific understanding of the mind,\nthen, literally speaking, no one believes anything. \nInstrumentalists about belief regard belief attributions as\nuseful for certain purposes, but hold that there are no definite\nunderlying facts about what people really believe, or that beliefs are\nnot robustly real, or that belief attributions are never in the\nstrictest sense true (these are not exactly equivalent positions,\nthough they are closely related). One sort of\ninstrumentalism—what we might call hard\ninstrumentalism—denies that beliefs exist in any sense.\nHard instrumentalism is thus a form of eliminativism, conjoined with\nthe thesis that belief-talk is nonetheless instrumentally useful\n(e.g., Quine 1960, p. 221 [but for a caveat see p. 262–266]).\nAnother type of instrumentalism, which we might call soft\ninstrumentalism, grants that beliefs are real, but only in a less\nrobust sense than is ordinarily thought. Dennett (1991) articulates a\nview of this sort. Consider as an analogy: Is the equator real? Well,\nnot in the sense that there’s a red stripe running through the\nCongo; but saying that a country is on the equator says something true\nabout its position relative to other countries and how it travels on\nthe spinning Earth. Are beliefs real? Well, not perhaps in the sense\nof being representations stored somewhere in the mind; but attributing\na belief to someone says something true about that person’s\npatterns of behavior and response. Beliefs are as real as equators, or\ncenters of gravity, or the average Canadian. The soft instrumentalist\nholds that such things are not robustly real (if that makes\nsense)—not as real as mountains or masses or individual, actual\nCanadians. They are in some sense inventions that capture something\nuseful in the structure of more robustly real phenomena; and yet at\nthe same time they are not mere fictions. Soft\ninstrumentalism in this sense comports naturally with approaches to\nbelief such as dispositionalism and interpretationism, to the extent\nthose positions treat belief attribution simply as a convenient means\nof pointing toward certain patterns in a subject’s real and\nhypothetical behavior. \nFor further discussion of eliminativism and the considerations for and\nagainst it, see the entry on\n eliminative materialism. \nPhilosophers often distinguish dispositional from\noccurrent believing. This distinction depends on the more\ngeneral distinction between dispositions and\noccurrences. Examples of dispositional statements\ninclude: \n(1a) Corina runs a six-minute mile, \n(1b) Leopold is excitable, \n(1c) salt dissolves in water.  \nThese statements can all be true even if, at the time they are\nuttered, Corina is asleep, Leopold is relaxed, and no salt is actually\ndissolved in any water. They thus contrast with statements about\nparticular occurrences, such as: \n(2a) Corina is running a six-minute mile, \n(2b) Leopold is excited, \n(2c) some salt is dissolving in water.  \nAlthough (1a-c) can be true while (2a-c) are false, (1a-c) cannot be\ntrue unless there are conditions under which (2a-c) would be true. We\ncannot say that Corina runs a six-minute mile unless there are\nconditions under which she would in fact do so. A dispositional claim\nis a claim, not about anything that is actually occurring at the time,\nbut rather that some particular thing is prone to occur,\nunder certain circumstances. \nSuppose Harry thinks plaid ties are hideous. Only rarely does the\nthought or judgment that they are hideous actually come to the\nforefront of his mind. When it does, he possesses the belief\noccurrently. The rest of the time, Harry possesses the belief only\ndispositionally. The occurrent belief comes and goes, depending on\nwhether circumstances elicit it; the dispositional belief endures. The\ncommon representationalist warehouse model of memory and belief\nsuggests a way of thinking about this. A subject dispositionally\nbelieves P if a representation with the content P is\nstored in her memory or “belief box” (in the central,\n“explicit” case: see §2.2). When that representation\nis retrieved from memory for active deployment in reasoning or\nplanning, the subject occurrently believes P. As soon as she\nmoves to the next topic, the occurrent belief ceases. \nAs the last paragraph suggests, one needn’t adopt a\ndispositional approach to belief in general to regard some beliefs as\ndispositional in the sense here described. In fact, a strict\ndispositionalism may entail the impossibility of occurrent belief: If\nto believe something is to embody a particular dispositional\nstructure, then a thought or judgment might not belong to the right\ncategory of things to count as a belief. The thought or judgment,\nP, may be a manifestation of an overall\ndispositional structure characteristic of the belief that P,\nbut it itself is not that structure. \nThough the distinction between occurrent and dispositional belief is\nwidely employed, it is rarely treated in detail. A few important\ndiscussions are Price (1969), Armstrong (1973), Lycan (1986), Searle\n(1992), and Audi (1994). David Hume (1740) famously offers an account\nof belief that treats beliefs principally as occurrences (see the\nsection on Causation: The Positive Phase in\n Hume),\n in which he is partly followed by Braithwaite (1932–1933). \nIt seems natural to say that you believe that the number of planets is\nless than 9, and also that the number of planets is less than 10, and\nalso that the number of planets is less than 11, and so on, for any\nnumber greater than 8 that one cares to name. On a simplistic reading\nof the representational approach, this presents a difficulty. If each\nbelief is stored individually in representational format somewhere in\nthe mind, it would seem that we must have a huge number of stored\nrepresentations relevant to the number of planets—more than it\nseems plausible or necessary to attribute to an ordinary human being.\nAnd of course this problem generalizes easily. \nThe advocate of the maps view of representational structure (see\n§1.1.1, above) can, perhaps, avoid this difficulty entirely,\nsince it seems a map of the solar system does represent all\nthese facts about the number of planets within a simple, tractable\nsystem. However, representationalists have more commonly responded to\nthis issue by drawing a distinction between explicit and implicit\nbelief. One believes P explicitly if a\nrepresentation with that content is actually present in the mind in\nthe right sort of way—for example, if a sentence with that\ncontent is inscribed in the “belief box” (see §1.1\nabove). One believes P implicitly (or\ntacitly) if one believes P, but the mind does not\npossess, in a belief-like way, a representation with that content.\n(Philosophers sometimes use the term dispositional to refer\nto beliefs that are implicit in the present sense—but this\ninvites confusion with the occurrent-dispositional distinction\ndiscussed above (§2.1). Implicit beliefs are, perhaps,\nnecessarily dispositional in the sense of the previous subsection, if\noccurrently deploying a belief requires explicitly tokening a\nrepresentation of it; but explicit beliefs may plausibly be\ndispositional or occurrent.) \nPerhaps all that’s required to implicitly believe something is\nthat the relevant content be swiftly derivable from something one\nexplicitly believes (Dennett 1978, 1987). Thus, in the planets case,\nwe may say that you believe explicitly that the number of planets is 8\nand only implicitly that the number of planets is less than 9, less\nthan 10, etc. Of course, if swift derivability is the criterion, then\nalthough there may be a sharp line between explicit and implicit\nbeliefs (depending on whether the representation is stored or not),\nthere will not be a sharp line between what one believes implicitly\nand what, though derivable from one’s beliefs, one does not\nactually believe, since swiftness is a matter of degree (see Field\n1978; Lycan 1986). \nThe representationalist may also grant the possibility of implicit\nbelief, or belief without explicit representation, in cases of the\nfollowing sort (discussed in Dennett 1978; Fodor 1987). A\nchess-playing computer is explicitly programmed with a large number of\nspecific strategies, in consequence of which it almost always ends up\ntrying to get its queen out early; but nowhere is there any explicitly\nprogrammed representation with the content “get the queen out\nearly”, or any explicitly programmed representation from which\n“get the queen out early” is swiftly derivable. The\npattern emerges as a product of various features of the hardware and\nsoftware, despite its not being explicitly encoded. While most\nphilosophers would not want to say that any currently existing\nchess-playing computer literally has the belief that it should get its\nqueen out early, it is clear that an analogous possibility could arise\nin the human case and thus threaten representationalism, unless\nrepresentationalism makes room for a kind of emergent, implicit belief\nthat arises from more basic structural facts in this way. However, if\nthe representationalist grants the presence of belief\nwhenever there is a belief-like pattern of actual or\npotential behavior, regardless of underlying representational\nstructure, then the position risks collapsing into dispositionalism or\ninterpretationism. The issue of how to account for apparent cases of\nbelief without explicit representation poses an underexplored\nchallenge to representationalism. \nEmpirical psychologists have drawn a contrast between implicit and\nexplicit memory or knowledge, but this distinction does not map neatly\nonto the implicit/explicit belief distinction described in Section\n2.2.1. In the psychologists’ sense, explicit memory involves the\nconscious recollection of previously presented information, while\nimplicit memory involves the facilitation of a task or a change in\nperformance as a result of previous exposure to information, without,\nor at least not as a result of, conscious recollection (Schacter 1987;\nSchacter and Tulving 1994; though see Squire 2004). For example, if a\nsubject is asked to memorize a list of word pairs—bird/truck,\nstove/desk, etc.—and is then cued with one word and asked to\nprovide the other, the subject’s explicit memory is being\ntested. If the subject is brought back two weeks later, and has no\nconscious recollection of most of the word pairs on the list, then she\nhas no explicit memory of them. However, implicit memory of the\nword-pairs would be revealed if she found it easier to learn the\n“forgotten” pairs a second time. Knowledge that is\n“implicit” in this sense will normally not be\nimplicit in the sense of the previous subsection (if it were swiftly\nderivable from what one explicitly believes, presumably one could\nanswer the test questions correctly); it’s also at least\nconceptually possible that some such psychologically implicit\nknowledge may be stored stored “explicitly” in the sense\nof the previous subsection. \nA rather different empirical literature addresses the issue of\n“implicit attitudes”, for example implicit racism or\nsexism, which are often held to conflict with verbally or consciously\nespoused attitudes. Such implicit attitudes might be revealed by\nemotional reactions (e.g., more negative affect among white\nparticipants when assigned to a co-operative task with a black person\nthan with a white person) or by association or priming tasks (e.g.,\nfaster categorization responses when white participants are asked to\npair negative words with dark-skinned faces and positive words with\nlight-skinned faces than vice versa). (For reviews, see Wittenbrink\nand Schwarz, eds., 2007; Petty, Fazio, and Briñol, eds., 2009.)\nHowever, it remains controversial to what extent tests of this sort\nreveal subjects’ (implicit) beliefs, as opposed to\nmerely culturally-given associations or attitudes other than\nfull-blown belief (Wilson, Lindsey, and Schooler 2000; Kihlstrom 2004;\nLane et al. 2007; Hunter 2011; Tumulty 2014; Levy 2015; Machery 2016;\nMadva 2016; Zimmerman 2018). Gendler, for example, suggests that we\nregard such implicit attitudes as arational and automatic\naliefs rather than genuine evidence-responsive\nbeliefs (Gendler 2008a–b; for critique see Schwitzgebel\n2010; Mandelbaum 2013). \nQuine (1956) introduced contemporary philosophy of mind to the\ndistinction between de re and de dicto belief\nattributions (as it is now generally called) by means of examples like\nthe following. Ralph sees a suspicious-looking man in a trenchcoat,\nand concludes that that man is a spy. Unbeknownst to him, however, the\nman in the trenchcoat is the newly elected mayor, Bernard J. Ortcutt,\nand Ralph would sincerely deny the claim that “the mayor is a\nspy”. So does Ralph believe that the mayor is a spy? There\nappears to be a sense in which he does and a sense in which he does\nnot. Philosophers have attempted to characterize the difference\nbetween these two senses by saying that Ralph believes de re,\nof that man (the man in the trenchcoat who happens also to be the\nmayor), that “he is a spy”, while he does not believe\nde dicto that “the mayor a spy”. \nThe standard test for distinguishing de re from de\ndicto attributions is referential transparency or\nopacity. A sentence, or more accurately a position in a\nsentence, is held to be referentially transparent if terms or phrases\nin that position that refer to the same object can be freely\nsubstituted without altering the truth of the sentence. The\n(non-belief attributing) sentence “Jill kicked X”\nis naturally read as referentially transparent in this sense. If\n“Jill kicked the ball” is true, then so also is any\nsentence in which “the ball” is replaced by a term or\nphrase that refers to that same ball, e.g., “Jill kicked\nDavy’s favorite birthday present”, “Jill kicked the\nthing we bought at Toys ‘R’ Us on August 26”.\nSentences, or positions, are referentially opaque just in case they\nare not transparent, that is, if the substitution of co-referring\nterms or phrases could potentially alter their truth value. De\ndicto belief attribution is held to be referentially opaque in\nthis sense. On the de dicto reading of belief, “Ralph\nbelieves that the man in the trenchcoat is a spy” may be true\nwhile “Ralph believes that the mayor is a spy” is false.\nLikewise, “Lois Lane believes that Superman is strong” may\nbe true while “Lois believes that Clark Kent is strong” is\nfalse, even if Superman and Clark Kent are, unbeknownst to Lois, one\nand the same person. (Regarding the Lois example, however, see also\n§3.4, on Frege’s Puzzle, below.) \nIn some contexts, the liberal substitution of co-referential terms or\nphrases seems permissible in ascribing belief. Shifting example,\nsuppose Davy is a preschooler who has just met a new teacher, Mrs.\nSanchez, who is Mexican, and he finds her too strict. Davy’s\nmother, in reporting this fact to his father, might say “Davy\nthinks Mrs. Sanchez is too strict” or “Davy thinks the new\nMexican teacher is too strict”, even though Davy does not know\nthe teacher’s name or that she is Mexican. Similarly, if Ralph\neventually discovers that the man in the trenchcoat was Ortcutt, he\nmight, in recounting the incident to his friends later, laughingly\nsay, “For a moment, I thought the mayor was a spy!” or\n“For a moment, I thought Ortcutt was a spy”. In a de\nre mood, then, we can say that Davy believes, of X, that\nshe is too strict and Ralph believes, of Y, that he is a spy,\nwhere X is replaced by any term or phrase that picks out Mrs.\nSanchez and Y is replaced by any term or phrase that picks\nout Ortcutt—though of course, depending on the situation,\npragmatic considerations will favor the use of some terms or phrases\nover others. In a strict de re sense, perhaps we can even say\nthat Lois believes, of Clark Kent, that he is strong (though she may\nalso simultaneously believe of him that he is not strong). \nThe standard view, then, takes belief-attributing sentences to be\nsystematically ambiguous between a referentially opaque, de\ndicto structure and a referentially transparent, de re\nstructure. Sometimes this view is conjoined with the view that de\nre but not de dicto belief requires some kind of direct\nacquaintance with the object of belief. \nThe majority of the literature on the de re / de\ndicto distinction since at least the 1980s has challenged this\nstandard view in one way or another. The challenges are sufficiently\ndiverse that they resist brief classification, except perhaps to\nremark that a number of them invoke pragmatics or conversational\ncontext, instead of an ambiguity in the term “belief”, or\nin the structure of belief ascriptions, to explain the fact that it\nseems in some way appropriate and in some way inappropriate to say\nthat Ralph believes the mayor is a spy. \nAmong the more important discussions of the de re / de\ndicto distinction are Quine (1956), Kaplan (1968), Burge (1977),\nLewis (1979), Stich (1983), Dennett (1987), Crimmins (1992), Brandom\n(1994), Jeshion (2002), Taylor (2002), and Keshet (2010). See also the\nsection on the De Re/De Dicto Distinction in the entry on\n propositional attitude reports. \nJessie believes that Stalin was originally a Tsarist mole among the\nBolsheviks, that her son is at school, and that she is eating a\ntomato. She feels different degrees of confidence with respect to\nthese different propositions. The first she recognizes to be a\nspeculative historical conjecture; the second she takes for granted,\nthough she knows it could be false; the third she regards as a\nnear-certainty. Consequently, Jessie is more confident of the second\nproposition than the first and more confident of the third than the\nsecond. We might suppose that every subject holds each of her beliefs\nwith some particular degree of confidence. In general, the greater the\nconfidence one has in a proposition, the more willing one is to depend\non it in one’s actions. \nOne common way of formalizing this idea is by means of a scale from 0\nto 1, where 0 indicates absolute certainty in the falsity of a\nproposition, 1 indicates absolute certainty in its truth, and .5\nindicates that the subject regards the proposition just as likely to\nbe true as false. This number then indicates one’s\n“credence” or “degree of belief”. Standard\napproaches equate degree of belief with the maximum amount the subject\nwould, or alternatively should, be willing to wager on a bet that pays\nnothing if the proposition is false and 1 unit if the proposition is\ntrue. So, for example, if the subject thinks that the proposition\n“the restaurant is open” is three times more likely to be\ntrue than false, she should be willing to pay no more than $0.75 for a\nwager that pays nothing if the restaurant is closed and $1 if it is\nopen. Consequently, the subject’s degree of belief is .75, or\n75%. Such a formalized approach to degree of belief has proven useful\nin decision theory, game theory, and economics. Standard philosophical\ntreatments of this topic include Jeffrey (1983) and Skyrms (2000). \nHowever, the phrase “degree of belief” may be misleading,\nbecause the relationship between confidence, betting behavior, and\nbelief is not straightforward. The dispositionalist or\ninterpretationist, for example, might regard exhibitions of confidence\nand attitudes toward risk as only part of the overall pattern\nunderwriting belief ascription. Similarly, the representationalist\nmight hold that readiness to deploy a representation in belief-like\nways need not line up perfectly with betting behavior. Some people\nalso find it intuitive to say that a rational person holding a ticket\nin a fair lottery may not actually believe that she will lose, but\ninstead regard it as an open question, despite having a “degree\nof belief” of, say, .9999 that she will lose. If this person\ngenuinely believes some other propositions, such as that her son is at\nschool, with a “degree of belief” considerably less than\n.9999, then it appears to follow that a rational person may in some\ncases have a higher “degree of belief” in a proposition\nthat she does not believe than in a proposition she does believe (see\nHarman 1986; Sturgeon 2008; Buchak 2014; Leitgeb 2017; Friedman\nforthcoming). \nPhilosophers have sometimes drawn a distinction between\nacceptance and belief. Generally speaking,\nacceptance is held to be more under the voluntary control of the\nsubject than belief and more directly tied to a particular practical\naction in a context. For example, a scientist, faced with evidence\nsupporting a theory, evidence acknowledged not to be completely\ndecisive, may choose to accept the theory or not to accept it. If the\ntheory is accepted, the scientist ceases inquiring into its truth and\nbecomes willing to ground her own research and interpretations in that\ntheory; the contrary if the theory is not accepted. If one is about to\nuse a ladder to climb to a height, one may check the stability of the\nladder in various ways. At some point, one accepts that the ladder is\nstable and climbs it. In both of these examples, acceptance involves a\ndecision to cease inquiry and to act as though the matter is settled.\nThis does not, of course, rule out the possibility of re-opening the\nquestion if new evidence comes to light or a new set of risks\narise. \nThe distinction between acceptance and belief can be supported by\nappeal to cases in which one accepts a proposition without believing\nit and cases in which one believes a proposition without accepting it.\nVan Fraassen (1980) has argued that the former attitude is common in\nscience: the scientist often does not think that some particular\ntheory on which her work depends is the literal truth, and thus does\nnot believe it, but she nonetheless accepts it as an adequate basis\nfor research. The ladder case, due to Bratman (1999), may involve\nbelief without acceptance: One may genuinely believe, even before\nchecking it, that the ladder is stable, but because so much depends on\nit and because it is good general policy, one nonetheless does not\naccept that the ladder is stable until one has checked it more\ncarefully. \nImportant discussions of acceptance include van Fraassen (1980),\nHarman (1986), Cohen (1989, 1992), Lehrer (1990), Bratman (1999),\nVelleman (2000), and Frankish (2004). \nThe traditional analysis of knowledge, brought into contemporary\ndiscussion (and famously criticized) by Gettier (1963), takes\npropositional knowledge to be a species of belief—specifically,\njustified true belief. Most contemporary treatments of knowledge are\nmodifications or qualifications of the traditional analysis and\nconsequently also treat knowledge as a species of belief. (For a\ndetailed treatment of this topic see the entry on the\n analysis of knowledge.\n For critique of the view that propositional knowledge entails belief,\nsee Radford 1966; Murray, Sytsma, and Livengood 2013; Myers-Schulz and\nSchwitzgebel 2013) \nThere may also be types of knowledge that are not types of belief,\nthough they have received less attention from epistemologists. Ryle\n(1949), for example, emphasizes the distinction between knowing\nhow to do something (e.g., ride a bicycle) and knowing\nthat some particular proposition is true (e.g., that Seoul is\nthe capital of Korea). In contemporary psychology, a similar\ndistinction is sometimes drawn between procedural knowledge\nand semantic, or declarative, knowledge (see Squire\n1987; Schacter, Wagner, and Buckner 2000; also the entry on\n memory).\n Although knowledge-that or declarative knowledge may plausibly be a\nkind of belief, it is not easy to see how procedural knowledge or\nknowledge-how could be so, unless one holds that people have a myriad\nof beliefs about minute and non-obvious procedural details. At least,\nthere is no readily apparent relation between knowledge-how and\n“belief-how” that runs parallel to the relation\nepistemologists generally accept between knowledge-that and\nbelief-that. (For an influential attempt to subsume knowledge-how\nunder knowledge-that, see Stanley and Williamson 2001; Stanley\n2011.) \nThe standard reference text in psychiatry, the Diagnostic and\nStatistical Manual of Mental Disorders (DSM-V, 2013)\ncharacterizes delusions (e.g., persecutory delusions, delusions of\ngrandiosity) as beliefs. However, delusions often do not appear to\nconnect with behavior in the usual way. For example, a victim of\nCapgras delusion—a delusion in which the subject asserts that a\nfamily member or close friend has been replaced by an\nidentical-looking imposter—may continue to live with the\n“imposter” and make little effort to find the supposedly\nmissing loved one. Some philosophers have therefore suggested that\ndelusions do not occupy quite the functional role characteristic of\nbelief and thus are not, in fact, beliefs (e.g., Currie 2000; Stephens\nand Graham 2004; Gallagher 2009; Matthews 2013). Others have defended\nthe view that delusions are beliefs (e.g., Campbell 2001; Bayne and\nPacherie 2005; Bortolotti 2010, 2012) or in-between cases, with some\nfeatures of belief but not other features (e.g., Egan 2009; Tumulty\n2011). See the entry on\n delusion,\n especially §4.2\n Are Delusions Beliefs?\n  \nPhilosophers generally say that the belief that P has the\n(propositional) content P. A variety of issues arise\nabout how to characterize those contents and what determines them. \nThe standard view that the contents of beliefs are propositions gives\nrise to a debate about belief contents parallel to, and closely\nrelated to, a debate about the metaphysics of propositions. One\nstandard view of propositions takes propositions to be sets of\npossible worlds; another takes propositions to have something more\nclosely resembling a linguistic logical structure (see\n structured propositions\n for a detailed exposition of this issue). \nStalnaker (1984) endorses the possible-worlds view of propositions and\nimports it directly into his discussion of belief content: He contends\nthe content of a belief is specified by the set of “possible\nworlds” at which that belief is true (see Lewis 1979 for a\nsimilar approach). The structure of belief content is thus the\nstructure of set theory. Among the advantages Stalnaker claims for\nthis view is its smooth accommodation of gradual change and of what\nmight, from the point of view of a discrete linguistic structure, be\nseen as problematically indeterminate belief contents. Developing an\nexample from Dennett (1969), he describes the gradual transition from\na child’s learning to say (without really understanding) that\n“Daddy is a doctor” to having a full, adult appreciation\nof the fact that her father is a doctor. At some point, Stalnaker\nsuggests, it’s best to say that child “sort of” or\n“half” believes the proposition in question. It’s\nnot clear how to characterize such gradual shifts by means of a\nlinguistic or quasi-linguistic propositional structure (1984, p.\n64–65; see also Schwitzgebel 2001). On Stalnaker’s view,\nthe child’s half-belief is handled by attributing her the\ncapacity to rule out some but not all of the possibilities\nincompatible with Daddy’s being a doctor: As her knowledge\ngrows, so does her sense of the excluded possibilities. \nThe possible worlds approach to belief content is sometimes referred\nto as a “coarse-grained” approach because it implies that\nany two beliefs that would be true in exactly the same set of possible\nworlds have the same content—as opposed to a\n“fine-grained” approach on which beliefs that would be\ntrue at exactly the same set of possible worlds may nonetheless differ\nin content. The difference between these two approaches is brought out\nmost starkly by considering mathematical propositions. On standard\naccounts of possibility, all mathematically true propositions are true\nin exactly the same set of possible worlds—every world.\nIt seems to follow, on the coarse-grained view, that the belief that 1\n+ 1 = 2 has exactly the same content as the belief that the cosine of\n0 is 1, and thus that anyone who believes (or fails to believe) the\none accordingly believes (or fails to believe) the other. And that\nseems absurd. \nStalnaker attempts to escape this difficulty by characterizing\nmathematical belief as belief about sentences: The belief\nthat the sentence “1 + 1 = 2” expresses a truth\nand the belief that the sentence “the cosine of 0 is\n1” expresses a truth have different content and may differ in\ntruth value between possible worlds (due simply to possible variations\nin the meanings of terms, if nothing else). However, it’s\nprobably fair to say that few philosophers follow Stalnaker in this\nview (see discussion in Robbins 2004; and Rayo 2013 for a recent view\nsimilar to Stalnaker’s). The apparent difficulty of sustaining\nsuch a view of belief is often held to reflect badly on the a\ncoarse-grained possible-worlds view of propositions in general, since\nit’s generally thought that one of the principal metaphysical\nfunctions of propositions is to serve as the contents of belief and\nother “propositional attitudes” (e.g., Field 1978; Soames\n1987). \nAni believes that salmon are fish; not knowing that whales are\nmammals, she also believes that whales are fish. Sanjay, like Ani,\nbelieves that salmon are fish, but he denies that whales are fish. Do\nAni and Sanjay share exactly the same belief about\nsalmon—namely, that they are fish—or is the content of\ntheir belief somehow subtly different in virtue of their different\nattitude toward whales? With certain caveats, the atomist\nwill say the former, the holist the latter. In general, the\natomist holds that the content of one’s beliefs does not depend\nin any general way on one’s related beliefs (though it may\ndepend on the contents of a few specially related beliefs such as\ndefinitions) and thus, consequently, that people who sincerely and\ncomprehendingly accept the same sentence normally have exactly the\nsame belief. Holism is the contrary view that the content of every\nbelief depends to a large degree on a broad range of one’s\nrelated beliefs, and consequently that two people will rarely believe\nexactly the same thing. \nHolism may be defended by a slippery-slope argument. It seems that we\ncan imagine Sanjay’s and Ani’s beliefs about the nature of\nfish and the members of the class of fish slowly diverging. At some\npoint, it will seem plainly correct to say that even though they may\nboth say “salmon are fish”, they are not expressing the\nsame belief by that sentence. As an extreme case, we might imagine Ani\nto be so benighted as to hold that to be a “fish” is\nneither more nor less than to be an Earthly animal in regular contact\nwith Martians, and that only salmon, whales, leopards, and banana\nslugs are in such contact. But if we deny, in the extreme case, that\nAni and Sanjay share the same belief, expressed by the sentence\n“salmon are fish”, it seems artificial to draw a sharp\nline anywhere in the progression of divergence, on one side of which\nthey share exactly the same belief about salmon and on the other side\nof which they have divergent beliefs. One is thus led to the\nconclusion that similarity in belief is a matter of degree, and it may\nthen be difficult to avoid accepting that even a relatively small\ndivergence in surrounding beliefs may be sufficient to generate subtle\ndifferences between two beliefs expressed in the same words. Similar\nslippery slope arguments can be constructed that emphasize gradual\nbelief change in concept acquisition (“Leibniz was a\nmetaphysician” agreed to before and after learning philosophy)\nor gradual change in surrounding theory or in the meaning of a term\n(“electrons have orbits” as uttered by Niels Bohr in 1913\nand as uttered by Richard Feynman in 1980). (This argument is similar\nin some ways to Stalnaker’s argument for a possible-worlds\nanalysis of the propositional contents of belief—see §3.1,\nabove—and indeed Stalnaker takes himself, there, to be committed\nto holism.) \nDispositional and interpretational approaches to belief tend to be\nholist. On these views, recall, to believe is to be disposed to\nexhibit patterns of behavior interpretable or classifiable by means of\nvarious belief attributions (see §1.2 and §1.3 above). It is\nplausible to suppose that a subject’s match to the relevant\npatterns will generally be a matter of degree. There may be few actual\ncases in which two subjects exactly match in their behavioral patterns\nregarding P, even if it gets matters approximately right to\nattribute to each of them the belief that P. Since behavioral\ndispositions are interlaced in a complex way, divergence in any of a\nvariety of attitudes related to P may be sufficient to ensure\ndivergence in the patterns relevant to P itself. As\nAni’s associated beliefs grow stranger, her overall behavioral\npattern, or dispositional structure, begins to look less and less like\none that we would associate with believing that salmon are fish. \nIt is sometimes objected to holism that, intuitively, both Shakespeare\nand contemporary physicians believe that blood is red, while on the\nholist view it is hard to see how their beliefs could even be similar,\ngiven that they have so many different surrounding beliefs about both\nblood and redness. Although in principle a holist could respond to\nthis objection by describing what sort of differences in surrounding\nbelief create only minor divergences and what differences create major\nones, there have been no influential attempts at such a project. It\nmay be possible to address the Shakespeare case by suggesting that the\ncontent of both Shakespeare’s and the contemporary\nphysician’s belief is partly determined\nexternalistically by the actual nature of blood and the\nactual nature of redness, despite the different conceptualizations\nover time (see §3.3 below). Since neither blood nor redness have\nchanged much since Shakespeare’s day, Shakespeare’s and\nthe contemporary physician’s belief may be similar—though,\nof course, if one holds them to be exactly the same, one\ncannot be a holist. \nHolism appears to be incompatible with a certain variety of\nrepresentationalism about belief. If beliefs, or the representations\nunderlying them, are stored symbols in the mind, somewhat like\nsentences on a chalkboard or objects in a box (to use standard\nFodorian metaphors), then it is natural to suppose that those beliefs\ncan, in principle, exist independently of each other. Whether one\nbelieves P depends on whether a representation with the\ncontent “P” is present in the right sort of way\nin the mind, which would not seem to be directly affected by whether\nQ or not-Q, or R or not-R, is also\nrepresented. If there is, in addition, an innate language of thought\nof the sort advocated by Fodor and others, then the basic terms of\nthat language may also be exactly the same from person to person. If a\nview of this sort about the mind can be sufficiently well supported,\nholism would have to be rejected. Conversely, if holism is plausible,\nit cuts against the more atomistic forms of representationalism. \nFodor and Lepore (1992) contains an excellent if dated review and\ncritique of arguments for holism. The foremost defenders of holism are\nprobably Quine (1951) and Davidson (1984). \nA number of philosophers have suggested that the content of\none’s beliefs depends entirely on things going on inside\none’s head, and not at all on the external world, except via the\neffects of the latter on one’s brain. Consequently, if a genius\nneuroscientist were to create a molecule-for-molecule duplicate of\nyour brain and maintain it in a vat, stimulating it artificially so\nthat it underwent exactly the same sequence of electrical and chemical\nevents as your actual brain, that brain would have exactly the same\nbeliefs as you. Those who accept this position are\ninternalists about belief content. Those who reject it are\nexternalists. \nSeveral arguments against internalism have prompted considerable\ndebate in philosophy of mind. Here is a condensed version of one\nargument, due to Putnam (1975; though it should be said that\nPutnam’s original emphasis was on linguistic meaning, not on\nbelief). Suppose that in 1750, in a far-off region of the universe,\nthere existed a planet that was physically identical to Earth,\nmolecule-for-molecule, in every respect but one: Where Earth had\nwater, composed of H2O, Twin Earth had something else\ninstead, “twater”, coming down as rain and filling\nstreams, behaving identically to water by all the chemical tests then\navailable, but having a different atomic formula, XYZ. Intuitively, it\nseems that the inhabitants of Earth in 1750 would have beliefs about\nwater and no beliefs about twater, while the inhabitants of Twin Earth\nwould have beliefs about twater and no beliefs about water. By\nhypothesis, however, each inhabitant of Earth will have a molecularly\nidentical counterpart on Twin Earth with exactly the same brain\nstructures (except, of course, that their brains will contain XYZ\ninstead of H2O, but reflection on analogous examples\nregarding chemicals not contained in the brain suggests that this fact\nis irrelevant). Consequently, the argument goes, the contents of\none’s beliefs do not depend entirely on internal properties of\none’s brain. \nFor further detail on the debate between internalists and\nexternalists, see the entries on\n content externalism\n and\n narrow content. \nRecall that in the de dicto sense (see §2.3 above) it\nseemed plausible to say that Lois Lane, who does not know that Clark\nKent is Superman, believes that Superman is strong but does not\nbelieve that Clark Kent is strong. Despite the intuitive appeal of\nthis view, some widely accepted “Russellian” views in the\nphilosophy of language appear committed to attributing to Lois exactly\nthe same beliefs about Clark Kent as she has about Superman. On such\nviews, the semantic content of a name, or the contribution it makes to\nthe meaning or truth conditions of a sentence, depends only on the\nindividual picked out by that name. Since the names\n“Superman” and “Clark Kent” pick out the same\nindividual, it follows that the sentence “Lois believes Superman\nis strong” could not have a different meaning or truth value\nfrom the sentence “Lois believes Clark Kent is strong”.\nPhilosophers of language have discussed this issue, known as\n“Frege’s Puzzle”, extensively since the 1970s.\nAlthough the issues here arise for all the propositional attitudes (at\nleast), generally the puzzle is framed and discussed in terms of\nbelief. See the entry on\n propositional attitude reports. \nA number of philosophers have argued that beings without language,\nnotably human infants and non-human animals, cannot have beliefs. The\nmost influential case for this view has been Davidson’s (1982,\n1984; Heil 1992). Three primary arguments in favor of the necessity of\nlanguage for belief can be extracted from Davidson. \nThe first starts from the observation that if we are to ascribe a\nbelief to a being without language—a dog, say, who is barking up\na tree into which he has just seen a squirrel run—we must\nascribe a belief with some particular content. At first blush, it\nseems natural to say that, in the case described, the dog believes\nthat the squirrel is in the tree. However, on reflection, that\nattribution may seem to be not quite right. The dog does not really\nhave the concept of a squirrel or a tree in the human sense. He may\nnot know, for instance, that trees have roots and require water to\ngrow. Consequently, according to Davidson, it is not really accurate\nto say that he believes that the squirrel is in the\ntree (at least in the de dicto sense: see §2.3\nabove). However, Davidson argues, neither does the dog have any\nother particular belief. Embracing holism (see §3.2\nabove), Davidson asserts that to have a belief with a specific\ncontent, that belief must be embedded in a rich network of other\nbeliefs with specific contents, but a dog’s cognitive life is\nnot complex enough to support such a network. “Belief”\ntalk thus cannot get traction (cf. Dennett 1969; Stich 1979,\n1983). \nSeveral philosophers (e.g., Routley 1981; Smith 1982; Allen 1992;\nGlock 2010) have objected to this argument on the grounds that the\ndog’s cognition about things such as trees, while perhaps not\nmuch like ours, is nonetheless relatively rich, involving a number of\nelements generally neglected by us, such as their scent and their use\nin marking territory. The dog’s understanding of a tree may be\nat least as rich as the human understanding of some objects about\nwhich we seem to have beliefs. For example, it seems that a chemically\nuntrained person may believe that boron is a chemical element without\nknowing very much about boron apart from that fact. Since we have no\nlanguage for doggy concepts, our belief ascriptions to dogs can only\nbe approximate—but if one accepts holism, then belief ascription\nto other human beings may be similarly approximate. \nDavidson also argues that to have a belief one must have the\nconcept of belief, which involves the ability to recognize\nthat beliefs can be false or that there is a mind-independent reality\nbeyond one’s beliefs; and one cannot have all that without\nlanguage. However, Davidson offers little support for the claim that\nbelief requires the concept of belief. On the face of it, it is not\nevident why this should be so, any more than having a bad temper\nrequires the concept of a bad temper. Furthermore, many developmental\npsychologists have suggested that children do not understand the\nappearance-reality distinction and do not recognize that beliefs can\nbe false until they are at least three years old, well after they have\nbegun to talk (Perner 1991; Wellman, Cross, and Watson 2001; though\nsee Southgate, Senju, and Csibra 2007; Scott and Baillargeon 2017).\nDavidson’s view thus requires him either to reject this\nempirical thesis or embrace the seemingly implausible view that young\nthree-year-olds have no beliefs (see also Andrews 2002). \nThe view that belief requires language is a natural consequence of the\nview that belief attribution is inextricably intertwined with the\ninterpretation of a subject’s linguistic utterances. Davidson,\nas described above (§1.3), argues that the interpretation of\ncreature’s beliefs, desires, and its language must come\ntogether as a package. This provides a third Davidsonian reason for\nrejecting belief without language (a reason that, however, remains\nlargely implicit in Davidson): Creatures without language are missing\npart of what is essential to a behavioral pattern of the sort that can\nunderwrite proper belief ascription (and recall that on an\ninterpretational view, all there is to having a belief is having a\npattern of behavior that is interpretable in that way to an outside\nobserver). Any view that ties belief attribution and the\nsubject’s language as closely together as Davidson’s\ndoes—Sellars (1956, 1969), Brandom (1994), and Wettstein (2004)\nalso offer views of this sort—will have difficulty accommodating\nthe possibility of belief in creatures without language. Thus,\nwhatever draws us to such views will also provide reason to deny\nbelief (or at least robust, full-blown belief) to languageless\ncreatures. \nPositive arguments for attributing beliefs to (at least) human infants\nand non-linguistic mammals have tended to focus on the general\nbiological and behavioral similarity between adult human beings, human\ninfants, and non-human mammals; the intuitive naturalness of\ndescribing the behavior of infants and non-linguistic mammals in terms\nof their beliefs and desires; and the difficulty of usefully\ncharacterizing their mental lives without relying on the ascription of\npropositional attitudes (e.g., Routley 1981; Marcus 1995; Allen and\nBekoff 1997; Zimmerman 2018).","contact.mail":"eschwitz@citrus.ucr.edu","contact.domain":"citrus.ucr.edu"}]
